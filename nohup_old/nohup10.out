Graph(num_nodes=20, num_edges=292,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)})
cuda:1
Namespace(print_freq=5, tb_freq=1, save_freq=1, batch_size=32, num_workers=12, num_copies=6, num_samples=2000, epochs=100, optimizer='adam', learning_rate=0.005, lr_decay_epochs=[120, 160, 200], lr_decay_rate=0.0, beta1=0.9, beta2=0.999, weight_decay=1e-05, momentum=0.9, clip_norm=1.0, resume='', aug='1st', exp='Pretrain', dataset='dgl', model='gin', num_layer=5, readout='avg', set2set_lstm_layer=3, set2set_iter=6, norm=True, nce_k=16384, nce_t=0.07, rw_hops=256, subgraph_size=128, restart_prob=0.8, hidden_size=64, positional_embedding_size=32, max_node_freq=16, max_edge_freq=16, max_degree=512, freq_embedding_size=16, degree_embedding_size=16, model_path='saved', tb_path='tensorboard', load_path=None, moco=True, finetune=False, alpha=0.999, gpu=3, seed=0, fold_idx=0, cv=False, cvrun=-1, positional_embedding_multi=3, model_name='Pretrain_moco_True_dgl_gin_layer_5_lr_0.005_decay_1e-05_bsz_32_hid_64_samples_2000_nce_t_0.07_nce_k_16384_rw_hops_256_restart_prob_0.8_aug_1st_ft_False_deg_16_pos_32_multi_3_momentum_0.999', model_folder='saved/Pretrain_moco_True_dgl_gin_layer_5_lr_0.005_decay_1e-05_bsz_32_hid_64_samples_2000_nce_t_0.07_nce_k_16384_rw_hops_256_restart_prob_0.8_aug_1st_ft_False_deg_16_pos_32_multi_3_momentum_0.999', tb_folder='tensorboard/Pretrain_moco_True_dgl_gin_layer_5_lr_0.005_decay_1e-05_bsz_32_hid_64_samples_2000_nce_t_0.07_nce_k_16384_rw_hops_256_restart_prob_0.8_aug_1st_ft_False_deg_16_pos_32_multi_3_momentum_0.999')
Pretrain_moco_True_dgl_gin_layer_5_lr_0.005_decay_1e-05_bsz_32_hid_64_samples_2000_nce_t_0.07_nce_k_16384_rw_hops_256_restart_prob_0.8_aug_1st_ft_False_deg_16_pos_32_multi_3_momentum_0.999
Use GPU: 3 for training
setting random seeds
before construct dataset 26.760948181152344
load graph done
before construct dataloader 26.760948181152344
before training 26.760948181152344
output 64
output 64
using queue shape: (16384,64)
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [0][1/750]	BT 25.543 (25.543)	DT 24.305 (24.305)	loss 5.485 (5.485)	prob 5.817 (5.8166)	GS 31.078 (31.078)	mem 62.706
Train: [0][5/750]	BT 0.210 (5.436)	DT 0.003 (5.065)	loss 6.230 (6.230)	prob 6.507 (6.5069)	GS 39.203 (39.203)	mem 59.895
Train: [0][10/750]	BT 0.212 (2.806)	DT 0.003 (2.538)	loss 6.851 (6.851)	prob 6.157 (6.1574)	GS 33.375 (33.375)	mem 58.089
Train: [0][15/750]	BT 0.247 (2.723)	DT 0.009 (2.491)	loss 7.622 (7.622)	prob 5.752 (5.7524)	GS 34.203 (34.203)	mem 59.679
Train: [0][20/750]	BT 0.078 (2.512)	DT 0.002 (2.309)	loss 7.711 (7.711)	prob 5.407 (5.4070)	GS 34.453 (34.453)	mem 61.564
Train: [0][25/750]	BT 0.098 (2.036)	DT 0.001 (1.848)	loss 7.125 (7.125)	prob 6.965 (6.9652)	GS 31.312 (31.312)	mem 61.840
Train: [0][30/750]	BT 0.099 (2.049)	DT 0.002 (1.867)	loss 7.810 (7.810)	prob 5.397 (5.3973)	GS 30.547 (30.547)	mem 63.866
Train: [0][35/750]	BT 0.118 (1.780)	DT 0.001 (1.602)	loss 8.200 (8.200)	prob 5.092 (5.0916)	GS 30.031 (30.031)	mem 63.938
Train: [0][40/750]	BT 0.259 (1.823)	DT 0.002 (1.644)	loss 8.232 (8.232)	prob 5.383 (5.3831)	GS 33.109 (33.109)	mem 64.096
Train: [0][45/750]	BT 0.094 (1.642)	DT 0.002 (1.462)	loss 8.418 (8.418)	prob 5.406 (5.4056)	GS 30.109 (30.109)	mem 64.079
Train: [0][50/750]	BT 12.890 (1.755)	DT 12.768 (1.572)	loss 8.517 (8.517)	prob 4.672 (4.6718)	GS 37.656 (37.656)	mem 64.205
Train: [0][55/750]	BT 0.245 (1.613)	DT 0.002 (1.430)	loss 8.618 (8.618)	prob 5.264 (5.2636)	GS 31.375 (31.375)	mem 64.302
Train: [0][60/750]	BT 0.419 (1.496)	DT 0.014 (1.311)	loss 8.500 (8.500)	prob 5.055 (5.0548)	GS 36.734 (36.734)	mem 64.116
Train: [0][65/750]	BT 0.111 (1.587)	DT 0.004 (1.405)	loss 8.569 (8.569)	prob 4.909 (4.9087)	GS 32.562 (32.562)	mem 64.392
Train: [0][70/750]	BT 0.133 (1.512)	DT 0.005 (1.329)	loss 8.729 (8.729)	prob 4.699 (4.6994)	GS 34.266 (34.266)	mem 64.247
Train: [0][75/750]	BT 0.207 (1.514)	DT 0.004 (1.333)	loss 8.434 (8.434)	prob 4.930 (4.9297)	GS 37.734 (37.734)	mem 58.094
Train: [0][80/750]	BT 0.094 (1.493)	DT 0.003 (1.315)	loss 9.188 (9.188)	prob 4.263 (4.2628)	GS 34.141 (34.141)	mem 58.904
Train: [0][85/750]	BT 0.223 (1.415)	DT 0.018 (1.238)	loss 8.272 (8.272)	prob 5.545 (5.5452)	GS 28.734 (28.734)	mem 59.058
Train: [0][90/750]	BT 1.531 (1.472)	DT 1.291 (1.297)	loss 9.571 (9.571)	prob 4.220 (4.2198)	GS 28.406 (28.406)	mem 61.386
Train: [0][95/750]	BT 0.134 (1.411)	DT 0.018 (1.239)	loss 8.961 (8.961)	prob 4.877 (4.8770)	GS 29.859 (29.859)	mem 61.565
Train: [0][100/750]	BT 7.293 (1.469)	DT 7.180 (1.298)	loss 8.749 (8.749)	prob 5.111 (5.1107)	GS 34.469 (34.469)	mem 63.463
Train: [0][105/750]	BT 0.202 (1.407)	DT 0.029 (1.236)	loss 8.313 (8.313)	prob 5.919 (5.9191)	GS 31.047 (31.047)	mem 63.465
Train: [0][110/750]	BT 4.065 (1.424)	DT 3.904 (1.250)	loss 8.968 (8.968)	prob 4.817 (4.8174)	GS 35.156 (35.156)	mem 58.560
Train: [0][115/750]	BT 0.102 (1.447)	DT 0.002 (1.276)	loss 9.122 (9.122)	prob 4.765 (4.7649)	GS 32.500 (32.500)	mem 60.694
Train: [0][120/750]	BT 3.099 (1.418)	DT 2.951 (1.248)	loss 10.449 (10.449)	prob 3.588 (3.5880)	GS 34.500 (34.500)	mem 61.555
Train: [0][125/750]	BT 0.196 (1.428)	DT 0.007 (1.259)	loss 8.813 (8.813)	prob 5.119 (5.1192)	GS 33.344 (33.344)	mem 63.275
Train: [0][130/750]	BT 0.109 (1.381)	DT 0.003 (1.213)	loss 8.777 (8.777)	prob 4.555 (4.5546)	GS 33.547 (33.547)	mem 63.476
Train: [0][135/750]	BT 0.173 (1.384)	DT 0.003 (1.213)	loss 9.505 (9.505)	prob 4.395 (4.3952)	GS 31.625 (31.625)	mem 64.356
Train: [0][140/750]	BT 1.618 (1.378)	DT 1.438 (1.210)	loss 9.585 (9.585)	prob 3.994 (3.9940)	GS 29.719 (29.719)	mem 64.337
Train: [0][145/750]	BT 0.195 (1.357)	DT 0.008 (1.189)	loss 9.126 (9.126)	prob 4.705 (4.7049)	GS 33.156 (33.156)	mem 64.353
Train: [0][150/750]	BT 0.187 (1.373)	DT 0.003 (1.205)	loss 9.491 (9.491)	prob 4.485 (4.4848)	GS 32.844 (32.844)	mem 64.364
Train: [0][155/750]	BT 0.253 (1.342)	DT 0.007 (1.175)	loss 9.050 (9.050)	prob 4.794 (4.7936)	GS 35.250 (35.250)	mem 64.347
Train: [0][160/750]	BT 6.111 (1.382)	DT 5.892 (1.213)	loss 9.425 (9.425)	prob 4.473 (4.4730)	GS 31.328 (31.328)	mem 64.524
Train: [0][165/750]	BT 0.216 (1.351)	DT 0.005 (1.182)	loss 9.725 (9.725)	prob 3.425 (3.4250)	GS 32.547 (32.547)	mem 64.400
Train: [0][170/750]	BT 3.887 (1.345)	DT 3.684 (1.175)	loss 9.089 (9.089)	prob 4.620 (4.6204)	GS 33.375 (33.375)	mem 64.566
Train: [0][175/750]	BT 0.103 (1.357)	DT 0.011 (1.188)	loss 9.561 (9.561)	prob 4.126 (4.1255)	GS 37.547 (37.547)	mem 59.065
Train: [0][180/750]	BT 0.134 (1.329)	DT 0.002 (1.162)	loss 9.732 (9.732)	prob 3.780 (3.7798)	GS 34.250 (34.250)	mem 59.210
Train: [0][185/750]	BT 0.084 (1.350)	DT 0.001 (1.183)	loss 9.405 (9.405)	prob 4.433 (4.4331)	GS 29.906 (29.906)	mem 61.278
Train: [0][190/750]	BT 0.085 (1.339)	DT 0.002 (1.173)	loss 9.890 (9.890)	prob 4.212 (4.2124)	GS 33.188 (33.188)	mem 62.098
Train: [0][195/750]	BT 0.145 (1.309)	DT 0.014 (1.143)	loss 9.428 (9.428)	prob 4.614 (4.6139)	GS 34.406 (34.406)	mem 62.291
Train: [0][200/750]	BT 2.956 (1.343)	DT 2.808 (1.176)	loss 9.893 (9.893)	prob 4.126 (4.1260)	GS 34.422 (34.422)	mem 63.534
Train: [0][205/750]	BT 0.159 (1.315)	DT 0.002 (1.148)	loss 9.421 (9.421)	prob 4.964 (4.9636)	GS 29.609 (29.609)	mem 59.538
Train: [0][210/750]	BT 0.540 (1.326)	DT 0.275 (1.159)	loss 8.733 (8.733)	prob 4.958 (4.9583)	GS 35.484 (35.484)	mem 59.292
Train: [0][215/750]	BT 0.240 (1.307)	DT 0.041 (1.140)	loss 9.536 (9.536)	prob 4.367 (4.3672)	GS 29.953 (29.953)	mem 60.041
Train: [0][220/750]	BT 13.355 (1.342)	DT 13.276 (1.175)	loss 9.630 (9.630)	prob 4.847 (4.8473)	GS 36.266 (36.266)	mem 62.448
Train: [0][225/750]	BT 0.182 (1.319)	DT 0.012 (1.153)	loss 10.422 (10.422)	prob 3.049 (3.0489)	GS 28.375 (28.375)	mem 62.784
Train: [0][230/750]	BT 0.260 (1.294)	DT 0.023 (1.128)	loss 9.868 (9.868)	prob 3.792 (3.7924)	GS 32.062 (32.062)	mem 63.147
Train: [0][235/750]	BT 0.167 (1.316)	DT 0.010 (1.150)	loss 10.270 (10.270)	prob 3.455 (3.4548)	GS 31.641 (31.641)	mem 64.595
Train: [0][240/750]	BT 0.100 (1.305)	DT 0.001 (1.139)	loss 9.887 (9.887)	prob 4.342 (4.3422)	GS 32.719 (32.719)	mem 64.503
Train: [0][245/750]	BT 0.167 (1.323)	DT 0.022 (1.157)	loss 9.971 (9.971)	prob 4.195 (4.1946)	GS 31.750 (31.750)	mem 64.598
Train: [0][250/750]	BT 0.189 (1.308)	DT 0.098 (1.141)	loss 9.287 (9.287)	prob 4.583 (4.5828)	GS 30.641 (30.641)	mem 64.351
Train: [0][255/750]	BT 0.109 (1.291)	DT 0.012 (1.124)	loss 9.459 (9.459)	prob 3.488 (3.4882)	GS 28.547 (28.547)	mem 64.334
Train: [0][260/750]	BT 0.132 (1.319)	DT 0.001 (1.153)	loss 9.678 (9.678)	prob 4.109 (4.1092)	GS 37.500 (37.500)	mem 64.525
Train: [0][265/750]	BT 0.172 (1.298)	DT 0.002 (1.132)	loss 9.172 (9.172)	prob 5.324 (5.3238)	GS 35.156 (35.156)	mem 64.468
Train: [0][270/750]	BT 0.124 (1.321)	DT 0.003 (1.155)	loss 9.775 (9.775)	prob 4.198 (4.1978)	GS 32.719 (32.719)	mem 59.182
Train: [0][275/750]	BT 0.185 (1.307)	DT 0.005 (1.142)	loss 10.059 (10.059)	prob 4.182 (4.1825)	GS 28.969 (28.969)	mem 59.774
Train: [0][280/750]	BT 10.937 (1.325)	DT 10.847 (1.160)	loss 9.757 (9.757)	prob 4.249 (4.2493)	GS 35.125 (35.125)	mem 61.957
Train: [0][285/750]	BT 0.137 (1.303)	DT 0.001 (1.140)	loss 10.113 (10.113)	prob 4.754 (4.7538)	GS 30.016 (30.016)	mem 62.163
Train: [0][290/750]	BT 0.315 (1.289)	DT 0.012 (1.125)	loss 10.244 (10.244)	prob 4.304 (4.3040)	GS 31.734 (31.734)	mem 62.713
Train: [0][295/750]	BT 0.137 (1.315)	DT 0.014 (1.151)	loss 9.464 (9.464)	prob 4.209 (4.2090)	GS 33.734 (33.734)	mem 58.438
Train: [0][300/750]	BT 0.227 (1.295)	DT 0.004 (1.132)	loss 10.469 (10.469)	prob 2.713 (2.7130)	GS 36.562 (36.562)	mem 58.584
Train: [0][305/750]	BT 0.160 (1.316)	DT 0.004 (1.153)	loss 10.844 (10.844)	prob 3.900 (3.8997)	GS 31.266 (31.266)	mem 61.048
Train: [0][310/750]	BT 1.332 (1.305)	DT 1.219 (1.143)	loss 9.822 (9.822)	prob 4.388 (4.3883)	GS 35.250 (35.250)	mem 61.811
Train: [0][315/750]	BT 0.237 (1.287)	DT 0.002 (1.125)	loss 10.214 (10.214)	prob 3.437 (3.4370)	GS 31.141 (31.141)	mem 61.926
Train: [0][320/750]	BT 0.089 (1.309)	DT 0.005 (1.148)	loss 10.015 (10.015)	prob 3.865 (3.8654)	GS 28.922 (28.922)	mem 64.255
Train: [0][325/750]	BT 0.208 (1.291)	DT 0.002 (1.130)	loss 10.006 (10.006)	prob 3.593 (3.5930)	GS 28.297 (28.297)	mem 64.260
Train: [0][330/750]	BT 4.548 (1.313)	DT 4.452 (1.151)	loss 10.090 (10.090)	prob 3.447 (3.4470)	GS 34.578 (34.578)	mem 64.379
Train: [0][335/750]	BT 0.200 (1.295)	DT 0.005 (1.134)	loss 10.310 (10.310)	prob 3.436 (3.4362)	GS 30.578 (30.578)	mem 64.382
Train: [0][340/750]	BT 8.879 (1.304)	DT 8.657 (1.143)	loss 9.191 (9.191)	prob 4.631 (4.6312)	GS 31.016 (31.016)	mem 64.413
Train: [0][345/750]	BT 0.119 (1.299)	DT 0.003 (1.138)	loss 10.343 (10.343)	prob 2.978 (2.9781)	GS 35.453 (35.453)	mem 64.463
Train: [0][350/750]	BT 0.175 (1.283)	DT 0.005 (1.122)	loss 10.406 (10.406)	prob 3.227 (3.2270)	GS 33.719 (33.719)	mem 64.352
Train: [0][355/750]	BT 0.161 (1.300)	DT 0.002 (1.140)	loss 9.681 (9.681)	prob 4.660 (4.6603)	GS 33.781 (33.781)	mem 57.748
Train: [0][360/750]	BT 0.126 (1.287)	DT 0.002 (1.127)	loss 10.290 (10.290)	prob 3.187 (3.1866)	GS 32.312 (32.312)	mem 58.092
Train: [0][365/750]	BT 0.155 (1.293)	DT 0.002 (1.133)	loss 10.290 (10.290)	prob 4.328 (4.3284)	GS 31.234 (31.234)	mem 59.602
Train: [0][370/750]	BT 1.941 (1.289)	DT 1.772 (1.130)	loss 10.120 (10.120)	prob 3.591 (3.5914)	GS 33.219 (33.219)	mem 60.430
Train: [0][375/750]	BT 0.148 (1.274)	DT 0.001 (1.115)	loss 10.184 (10.184)	prob 2.821 (2.8213)	GS 33.016 (33.016)	mem 60.570
Train: [0][380/750]	BT 0.152 (1.286)	DT 0.003 (1.127)	loss 10.217 (10.217)	prob 3.451 (3.4509)	GS 34.859 (34.859)	mem 62.728
Train: [0][385/750]	BT 0.161 (1.271)	DT 0.004 (1.113)	loss 10.626 (10.626)	prob 3.121 (3.1213)	GS 32.562 (32.562)	mem 62.818
Train: [0][390/750]	BT 0.111 (1.290)	DT 0.002 (1.132)	loss 9.869 (9.869)	prob 3.492 (3.4918)	GS 34.781 (34.781)	mem 58.382
Train: [0][395/750]	BT 0.183 (1.277)	DT 0.011 (1.119)	loss 10.128 (10.128)	prob 2.885 (2.8851)	GS 35.734 (35.734)	mem 58.546
Train: [0][400/750]	BT 16.438 (1.304)	DT 16.335 (1.146)	loss 10.247 (10.247)	prob 3.144 (3.1440)	GS 33.359 (33.359)	mem 62.365
Train: [0][405/750]	BT 0.079 (1.289)	DT 0.004 (1.132)	loss 10.350 (10.350)	prob 3.771 (3.7709)	GS 27.703 (27.703)	mem 62.426
Train: [0][410/750]	BT 0.162 (1.276)	DT 0.034 (1.119)	loss 9.968 (9.968)	prob 3.012 (3.0119)	GS 34.969 (34.969)	mem 62.575
Train: [0][415/750]	BT 0.111 (1.293)	DT 0.009 (1.136)	loss 9.816 (9.816)	prob 4.630 (4.6298)	GS 31.281 (31.281)	mem 64.434
Train: [0][420/750]	BT 0.089 (1.279)	DT 0.001 (1.122)	loss 9.740 (9.740)	prob 3.760 (3.7605)	GS 36.047 (36.047)	mem 64.487
Train: [0][425/750]	BT 0.244 (1.287)	DT 0.001 (1.131)	loss 10.199 (10.199)	prob 3.319 (3.3186)	GS 30.844 (30.844)	mem 64.707
Train: [0][430/750]	BT 0.134 (1.274)	DT 0.001 (1.118)	loss 11.141 (11.141)	prob 1.665 (1.6648)	GS 32.547 (32.547)	mem 64.466
Train: [0][435/750]	BT 0.114 (1.262)	DT 0.003 (1.105)	loss 9.697 (9.697)	prob 3.990 (3.9903)	GS 34.062 (34.062)	mem 64.466
Train: [0][440/750]	BT 0.131 (1.279)	DT 0.003 (1.121)	loss 10.738 (10.738)	prob 2.457 (2.4569)	GS 34.781 (34.781)	mem 64.493
Train: [0][445/750]	BT 0.146 (1.266)	DT 0.001 (1.109)	loss 10.112 (10.112)	prob 4.020 (4.0197)	GS 36.766 (36.766)	mem 64.498
Train: [0][450/750]	BT 0.116 (1.278)	DT 0.001 (1.121)	loss 10.522 (10.522)	prob 2.133 (2.1333)	GS 33.375 (33.375)	mem 57.788
Train: [0][455/750]	BT 0.115 (1.266)	DT 0.002 (1.108)	loss 10.260 (10.260)	prob 3.538 (3.5384)	GS 25.000 (25.000)	mem 57.994
Train: [0][460/750]	BT 13.993 (1.290)	DT 13.877 (1.133)	loss 10.603 (10.603)	prob 3.185 (3.1854)	GS 36.516 (36.516)	mem 60.720
Train: [0][465/750]	BT 0.204 (1.278)	DT 0.036 (1.121)	loss 10.308 (10.308)	prob 3.773 (3.7731)	GS 36.391 (36.391)	mem 60.919
Train: [0][470/750]	BT 0.094 (1.266)	DT 0.004 (1.109)	loss 9.901 (9.901)	prob 3.765 (3.7652)	GS 30.625 (30.625)	mem 61.058
Train: [0][475/750]	BT 0.105 (1.282)	DT 0.009 (1.125)	loss 10.356 (10.356)	prob 3.446 (3.4456)	GS 38.000 (38.000)	mem 63.612
Train: [0][480/750]	BT 0.215 (1.270)	DT 0.001 (1.114)	loss 10.894 (10.894)	prob 2.266 (2.2655)	GS 34.062 (34.062)	mem 63.711
Train: [0][485/750]	BT 0.227 (1.285)	DT 0.006 (1.128)	loss 10.078 (10.078)	prob 4.272 (4.2724)	GS 34.078 (34.078)	mem 59.513
Train: [0][490/750]	BT 0.122 (1.274)	DT 0.004 (1.117)	loss 10.332 (10.332)	prob 3.062 (3.0622)	GS 31.625 (31.625)	mem 59.669
Train: [0][495/750]	BT 0.107 (1.263)	DT 0.003 (1.106)	loss 10.914 (10.914)	prob 2.577 (2.5772)	GS 28.938 (28.938)	mem 59.951
Train: [0][500/750]	BT 0.120 (1.273)	DT 0.002 (1.116)	loss 10.971 (10.971)	prob 2.538 (2.5378)	GS 35.891 (35.891)	mem 61.964
Train: [0][505/750]	BT 0.151 (1.262)	DT 0.003 (1.105)	loss 10.344 (10.344)	prob 2.775 (2.7747)	GS 27.938 (27.938)	mem 62.166
Train: [0][510/750]	BT 0.260 (1.274)	DT 0.023 (1.117)	loss 10.760 (10.760)	prob 2.644 (2.6438)	GS 31.328 (31.328)	mem 64.298
Train: [0][515/750]	BT 0.093 (1.265)	DT 0.001 (1.108)	loss 10.292 (10.292)	prob 2.992 (2.9924)	GS 32.750 (32.750)	mem 64.490
Train: [0][520/750]	BT 4.646 (1.280)	DT 4.540 (1.123)	loss 10.107 (10.107)	prob 2.058 (2.0575)	GS 33.828 (33.828)	mem 64.434
Train: [0][525/750]	BT 0.143 (1.270)	DT 0.003 (1.112)	loss 10.197 (10.197)	prob 2.376 (2.3764)	GS 31.828 (31.828)	mem 64.364
Train: [0][530/750]	BT 10.378 (1.279)	DT 10.089 (1.121)	loss 10.827 (10.827)	prob 0.957 (0.9567)	GS 30.953 (30.953)	mem 64.628
Train: [0][535/750]	BT 0.241 (1.275)	DT 0.002 (1.117)	loss 10.652 (10.652)	prob 1.735 (1.7350)	GS 31.000 (31.000)	mem 64.682
Train: [0][540/750]	BT 0.200 (1.265)	DT 0.003 (1.107)	loss 10.802 (10.802)	prob 1.432 (1.4324)	GS 34.281 (34.281)	mem 64.583
Train: [0][545/750]	BT 0.112 (1.281)	DT 0.002 (1.123)	loss 10.783 (10.783)	prob 0.806 (0.8061)	GS 32.234 (32.234)	mem 58.473
Train: [0][550/750]	BT 0.101 (1.270)	DT 0.006 (1.113)	loss 10.251 (10.251)	prob 1.417 (1.4168)	GS 33.766 (33.766)	mem 58.556
Train: [0][555/750]	BT 0.097 (1.277)	DT 0.003 (1.120)	loss 10.801 (10.801)	prob 0.016 (0.0159)	GS 29.609 (29.609)	mem 60.408
Train: [0][560/750]	BT 0.094 (1.272)	DT 0.006 (1.115)	loss 11.145 (11.145)	prob 0.219 (0.2193)	GS 34.094 (34.094)	mem 61.035
Train: [0][565/750]	BT 0.145 (1.262)	DT 0.002 (1.105)	loss 9.462 (9.462)	prob 2.756 (2.7561)	GS 33.406 (33.406)	mem 61.243
Train: [0][570/750]	BT 0.126 (1.274)	DT 0.017 (1.116)	loss 10.574 (10.574)	prob 2.311 (2.3108)	GS 35.656 (35.656)	mem 63.357
Train: [0][575/750]	BT 0.120 (1.264)	DT 0.008 (1.107)	loss 10.751 (10.751)	prob 1.348 (1.3478)	GS 27.484 (27.484)	mem 63.576
Train: [0][580/750]	BT 4.530 (1.279)	DT 4.436 (1.122)	loss 10.616 (10.616)	prob 2.097 (2.0970)	GS 32.328 (32.328)	mem 59.532
Train: [0][585/750]	BT 0.107 (1.269)	DT 0.007 (1.112)	loss 10.770 (10.770)	prob 1.360 (1.3603)	GS 29.594 (29.594)	mem 59.736
Train: [0][590/750]	BT 8.140 (1.274)	DT 7.988 (1.117)	loss 10.244 (10.244)	prob 1.095 (1.0955)	GS 38.109 (38.109)	mem 61.320
Train: [0][595/750]	BT 0.076 (1.278)	DT 0.001 (1.120)	loss 10.374 (10.374)	prob 0.938 (0.9381)	GS 31.234 (31.234)	mem 63.232
Train: [0][600/750]	BT 0.166 (1.268)	DT 0.009 (1.111)	loss 10.363 (10.363)	prob 0.698 (0.6975)	GS 33.219 (33.219)	mem 63.437
Train: [0][605/750]	BT 0.129 (1.281)	DT 0.002 (1.123)	loss 10.999 (10.999)	prob -0.187 (-0.1874)	GS 31.641 (31.641)	mem 64.391
Train: [0][610/750]	BT 0.140 (1.272)	DT 0.001 (1.115)	loss 10.173 (10.173)	prob 1.286 (1.2859)	GS 32.156 (32.156)	mem 64.432
Train: [0][615/750]	BT 0.106 (1.263)	DT 0.001 (1.106)	loss 10.113 (10.113)	prob 1.919 (1.9185)	GS 31.578 (31.578)	mem 64.473
Train: [0][620/750]	BT 0.172 (1.273)	DT 0.011 (1.116)	loss 10.757 (10.757)	prob 1.222 (1.2222)	GS 36.875 (36.875)	mem 64.407
Train: [0][625/750]	BT 0.110 (1.264)	DT 0.003 (1.107)	loss 10.522 (10.522)	prob 1.213 (1.2129)	GS 30.641 (30.641)	mem 64.296
Train: [0][630/750]	BT 1.593 (1.278)	DT 1.451 (1.122)	loss 10.146 (10.146)	prob 1.530 (1.5299)	GS 36.781 (36.781)	mem 64.402
Train: [0][635/750]	BT 0.120 (1.270)	DT 0.002 (1.113)	loss 10.378 (10.378)	prob 1.938 (1.9382)	GS 30.359 (30.359)	mem 64.405
Train: [0][640/750]	BT 14.481 (1.283)	DT 14.263 (1.126)	loss 10.073 (10.073)	prob 1.351 (1.3514)	GS 36.141 (36.141)	mem 60.190
Train: [0][645/750]	BT 0.186 (1.274)	DT 0.014 (1.118)	loss 11.351 (11.351)	prob 0.964 (0.9636)	GS 36.141 (36.141)	mem 60.279
Train: [0][650/750]	BT 0.225 (1.266)	DT 0.011 (1.109)	loss 10.734 (10.734)	prob 0.159 (0.1588)	GS 31.312 (31.312)	mem 60.344
arpack error, retry= 0
arpack error, retry= 0
arpack error, retry= 0
Train: [0][655/750]	BT 0.090 (1.276)	DT 0.002 (1.120)	loss 10.561 (10.561)	prob 0.632 (0.6319)	GS 32.016 (32.016)	mem 62.705
Train: [0][660/750]	BT 0.158 (1.267)	DT 0.003 (1.111)	loss 10.409 (10.409)	prob 0.396 (0.3957)	GS 33.938 (33.938)	mem 62.870
Train: [0][665/750]	BT 0.111 (1.278)	DT 0.001 (1.122)	loss 10.466 (10.466)	prob 0.936 (0.9360)	GS 30.891 (30.891)	mem 58.735
Train: [0][670/750]	BT 0.305 (1.270)	DT 0.004 (1.114)	loss 10.648 (10.648)	prob 0.064 (0.0635)	GS 32.109 (32.109)	mem 58.973
Train: [0][675/750]	BT 0.128 (1.262)	DT 0.018 (1.106)	loss 10.039 (10.039)	prob 1.195 (1.1947)	GS 32.625 (32.625)	mem 58.809
Train: [0][680/750]	BT 0.138 (1.280)	DT 0.002 (1.123)	loss 9.904 (9.904)	prob 1.893 (1.8928)	GS 33.500 (33.500)	mem 62.278
Train: [0][685/750]	BT 0.084 (1.271)	DT 0.002 (1.115)	loss 10.760 (10.760)	prob 1.693 (1.6931)	GS 32.625 (32.625)	mem 62.330
Train: [0][690/750]	BT 9.545 (1.282)	DT 9.386 (1.126)	loss 10.806 (10.806)	prob 0.861 (0.8606)	GS 36.594 (36.594)	mem 64.507
Train: [0][695/750]	BT 0.232 (1.274)	DT 0.004 (1.118)	loss 9.759 (9.759)	prob 1.902 (1.9016)	GS 31.156 (31.156)	mem 64.546
Train: [0][700/750]	BT 5.031 (1.273)	DT 4.853 (1.117)	loss 10.165 (10.165)	prob 0.653 (0.6529)	GS 30.609 (30.609)	mem 64.533
Train: [0][705/750]	BT 0.164 (1.278)	DT 0.006 (1.122)	loss 10.571 (10.571)	prob 0.592 (0.5923)	GS 35.562 (35.562)	mem 64.517
Train: [0][710/750]	BT 0.145 (1.270)	DT 0.007 (1.114)	loss 10.028 (10.028)	prob 1.837 (1.8372)	GS 34.281 (34.281)	mem 64.522
Train: [0][715/750]	BT 0.145 (1.279)	DT 0.001 (1.124)	loss 10.661 (10.661)	prob -0.311 (-0.3112)	GS 36.859 (36.859)	mem 64.542
Train: [0][720/750]	BT 0.182 (1.271)	DT 0.001 (1.116)	loss 10.380 (10.380)	prob 0.075 (0.0745)	GS 35.812 (35.812)	mem 64.470
Train: [0][725/750]	BT 0.215 (1.264)	DT 0.003 (1.108)	loss 10.170 (10.170)	prob 0.663 (0.6630)	GS 24.188 (24.188)	mem 64.550
Train: [0][730/750]	BT 0.113 (1.269)	DT 0.017 (1.113)	loss 11.121 (11.121)	prob -0.202 (-0.2017)	GS 33.031 (33.031)	mem 58.243
Train: [0][735/750]	BT 0.135 (1.261)	DT 0.002 (1.106)	loss 10.435 (10.435)	prob 1.133 (1.1331)	GS 33.000 (33.000)	mem 58.389
Train: [0][740/750]	BT 0.129 (1.266)	DT 0.001 (1.111)	loss 10.232 (10.232)	prob 2.368 (2.3676)	GS 32.656 (32.656)	mem 31.883
Train: [0][745/750]	BT 0.066 (1.258)	DT 0.001 (1.104)	loss 10.011 (10.011)	prob 2.738 (2.7381)	GS 27.312 (27.312)	mem 32.003
Train: [0][750/750]	BT 3.294 (1.255)	DT 3.201 (1.101)	loss 9.949 (9.949)	prob 3.213 (3.2127)	GS 36.375 (36.375)	mem 30.471
Train: [0][755/750]	BT 0.085 (1.247)	DT 0.001 (1.093)	loss 10.213 (10.213)	prob 2.565 (2.5650)	GS 33.781 (33.781)	mem 30.604
epoch 0, total time 941.84
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [1][1/750]	BT 23.102 (23.102)	DT 22.784 (22.784)	loss 10.166 (10.166)	prob 2.890 (2.8901)	GS 34.719 (34.719)	mem 61.418
Train: [1][5/750]	BT 0.150 (5.334)	DT 0.003 (5.122)	loss 10.952 (10.952)	prob 2.281 (2.2811)	GS 29.781 (29.781)	mem 62.215
Train: [1][10/750]	BT 0.112 (2.841)	DT 0.001 (2.677)	loss 9.878 (9.878)	prob 3.115 (3.1150)	GS 35.094 (35.094)	mem 62.532
Train: [1][15/750]	BT 0.094 (2.644)	DT 0.001 (2.493)	loss 10.498 (10.498)	prob 2.071 (2.0710)	GS 32.953 (32.953)	mem 63.345
Train: [1][20/750]	BT 2.269 (2.169)	DT 2.119 (2.016)	loss 10.897 (10.897)	prob 1.144 (1.1441)	GS 31.266 (31.266)	mem 63.558
Train: [1][25/750]	BT 4.329 (1.933)	DT 4.127 (1.779)	loss 10.916 (10.916)	prob 0.160 (0.1595)	GS 32.234 (32.234)	mem 63.413
Train: [1][30/750]	BT 4.325 (2.016)	DT 4.223 (1.854)	loss 10.697 (10.697)	prob 0.348 (0.3484)	GS 33.297 (33.297)	mem 63.435
Train: [1][35/750]	BT 0.153 (1.762)	DT 0.019 (1.602)	loss 9.903 (9.903)	prob 2.099 (2.0993)	GS 38.062 (38.062)	mem 63.455
Train: [1][40/750]	BT 0.331 (1.828)	DT 0.008 (1.664)	loss 10.453 (10.453)	prob 1.223 (1.2230)	GS 31.938 (31.938)	mem 63.689
Train: [1][45/750]	BT 0.121 (1.642)	DT 0.008 (1.481)	loss 10.541 (10.541)	prob 2.130 (2.1296)	GS 27.266 (27.266)	mem 63.489
Train: [1][50/750]	BT 13.656 (1.765)	DT 13.523 (1.604)	loss 11.379 (11.379)	prob 1.062 (1.0620)	GS 33.469 (33.469)	mem 58.912
Train: [1][55/750]	BT 0.148 (1.619)	DT 0.009 (1.459)	loss 10.231 (10.231)	prob 2.922 (2.9217)	GS 30.344 (30.344)	mem 59.010
Train: [1][60/750]	BT 0.092 (1.505)	DT 0.003 (1.349)	loss 10.558 (10.558)	prob 2.304 (2.3038)	GS 29.734 (29.734)	mem 59.380
Train: [1][65/750]	BT 0.123 (1.542)	DT 0.002 (1.387)	loss 10.604 (10.604)	prob 2.978 (2.9783)	GS 28.781 (28.781)	mem 60.888
Train: [1][70/750]	BT 0.106 (1.486)	DT 0.002 (1.333)	loss 10.708 (10.708)	prob 2.295 (2.2949)	GS 29.297 (29.297)	mem 61.539
Train: [1][75/750]	BT 0.203 (1.588)	DT 0.008 (1.434)	loss 10.649 (10.649)	prob 1.922 (1.9216)	GS 31.719 (31.719)	mem 57.234
Train: [1][80/750]	BT 0.268 (1.501)	DT 0.125 (1.346)	loss 10.182 (10.182)	prob 2.441 (2.4411)	GS 30.250 (30.250)	mem 57.525
Train: [1][85/750]	BT 0.118 (1.422)	DT 0.007 (1.268)	loss 10.227 (10.227)	prob 3.041 (3.0408)	GS 29.828 (29.828)	mem 57.662
Train: [1][90/750]	BT 0.128 (1.479)	DT 0.002 (1.327)	loss 10.682 (10.682)	prob 2.450 (2.4499)	GS 36.438 (36.438)	mem 60.058
Train: [1][95/750]	BT 0.163 (1.410)	DT 0.009 (1.258)	loss 10.622 (10.622)	prob 3.198 (3.1981)	GS 30.391 (30.391)	mem 60.174
Train: [1][100/750]	BT 0.101 (1.464)	DT 0.001 (1.313)	loss 10.692 (10.692)	prob 2.367 (2.3675)	GS 37.547 (37.547)	mem 62.404
Train: [1][105/750]	BT 0.086 (1.403)	DT 0.003 (1.254)	loss 10.320 (10.320)	prob 2.215 (2.2153)	GS 28.031 (28.031)	mem 62.569
Train: [1][110/750]	BT 15.209 (1.484)	DT 15.063 (1.334)	loss 9.707 (9.707)	prob 2.726 (2.7264)	GS 35.062 (35.062)	mem 63.806
Train: [1][115/750]	BT 0.198 (1.427)	DT 0.002 (1.277)	loss 10.152 (10.152)	prob 2.281 (2.2808)	GS 26.203 (26.203)	mem 63.657
Train: [1][120/750]	BT 0.108 (1.374)	DT 0.001 (1.224)	loss 10.480 (10.480)	prob 2.460 (2.4603)	GS 32.859 (32.859)	mem 63.734
Train: [1][125/750]	BT 0.152 (1.401)	DT 0.010 (1.251)	loss 10.175 (10.175)	prob 2.926 (2.9261)	GS 27.250 (27.250)	mem 63.704
Train: [1][130/750]	BT 0.117 (1.377)	DT 0.013 (1.226)	loss 10.055 (10.055)	prob 3.320 (3.3202)	GS 32.188 (32.188)	mem 63.759
Train: [1][135/750]	BT 0.113 (1.383)	DT 0.001 (1.233)	loss 10.561 (10.561)	prob 2.920 (2.9198)	GS 28.953 (28.953)	mem 63.723
Train: [1][140/750]	BT 2.405 (1.366)	DT 2.293 (1.217)	loss 11.622 (11.622)	prob 0.661 (0.6611)	GS 29.141 (29.141)	mem 63.781
Train: [1][145/750]	BT 0.149 (1.326)	DT 0.001 (1.175)	loss 10.504 (10.504)	prob 3.109 (3.1095)	GS 29.375 (29.375)	mem 63.669
Train: [1][150/750]	BT 0.087 (1.361)	DT 0.004 (1.212)	loss 11.639 (11.639)	prob 2.251 (2.2509)	GS 32.203 (32.203)	mem 58.756
Train: [1][155/750]	BT 0.110 (1.351)	DT 0.001 (1.202)	loss 10.433 (10.433)	prob 2.791 (2.7908)	GS 35.672 (35.672)	mem 59.878
Train: [1][160/750]	BT 2.285 (1.363)	DT 2.090 (1.213)	loss 10.546 (10.546)	prob 1.655 (1.6553)	GS 30.359 (30.359)	mem 61.335
Train: [1][165/750]	BT 0.218 (1.347)	DT 0.010 (1.197)	loss 10.749 (10.749)	prob 2.728 (2.7284)	GS 33.391 (33.391)	mem 62.107
Train: [1][170/750]	BT 7.441 (1.356)	DT 7.261 (1.204)	loss 10.177 (10.177)	prob 1.951 (1.9509)	GS 34.484 (34.484)	mem 63.061
Train: [1][175/750]	BT 0.184 (1.370)	DT 0.011 (1.217)	loss 10.202 (10.202)	prob 1.643 (1.6432)	GS 32.297 (32.297)	mem 58.109
Train: [1][180/750]	BT 0.236 (1.337)	DT 0.027 (1.184)	loss 10.302 (10.302)	prob 1.995 (1.9949)	GS 36.125 (36.125)	mem 58.273
Train: [1][185/750]	BT 0.135 (1.392)	DT 0.002 (1.238)	loss 10.734 (10.734)	prob 1.423 (1.4230)	GS 29.234 (29.234)	mem 61.621
Train: [1][190/750]	BT 0.119 (1.359)	DT 0.005 (1.206)	loss 10.310 (10.310)	prob 1.564 (1.5645)	GS 29.188 (29.188)	mem 61.684
Train: [1][195/750]	BT 0.194 (1.340)	DT 0.007 (1.187)	loss 10.299 (10.299)	prob 2.639 (2.6387)	GS 34.734 (34.734)	mem 62.339
Train: [1][200/750]	BT 0.148 (1.350)	DT 0.021 (1.197)	loss 10.360 (10.360)	prob 2.106 (2.1060)	GS 30.797 (30.797)	mem 64.166
Train: [1][205/750]	BT 0.154 (1.320)	DT 0.002 (1.168)	loss 9.892 (9.892)	prob 2.059 (2.0586)	GS 28.766 (28.766)	mem 64.245
Train: [1][210/750]	BT 0.207 (1.339)	DT 0.002 (1.186)	loss 10.828 (10.828)	prob 2.012 (2.0121)	GS 32.969 (32.969)	mem 64.469
Train: [1][215/750]	BT 0.253 (1.314)	DT 0.004 (1.158)	loss 10.457 (10.457)	prob 3.384 (3.3838)	GS 31.500 (31.500)	mem 64.538
Train: [1][220/750]	BT 8.518 (1.347)	DT 8.368 (1.192)	loss 10.264 (10.264)	prob 1.631 (1.6309)	GS 35.938 (35.938)	mem 64.399
Train: [1][225/750]	BT 0.258 (1.321)	DT 0.004 (1.165)	loss 9.931 (9.931)	prob 2.370 (2.3700)	GS 40.922 (40.922)	mem 64.780
Train: [1][230/750]	BT 4.492 (1.316)	DT 4.269 (1.159)	loss 10.487 (10.487)	prob 2.803 (2.8029)	GS 33.000 (33.000)	mem 64.602
Train: [1][235/750]	BT 0.226 (1.336)	DT 0.031 (1.178)	loss 10.303 (10.303)	prob 1.738 (1.7382)	GS 31.406 (31.406)	mem 64.441
Train: [1][240/750]	BT 0.182 (1.312)	DT 0.015 (1.154)	loss 10.506 (10.506)	prob 0.168 (0.1678)	GS 36.297 (36.297)	mem 64.429
Train: [1][245/750]	BT 0.122 (1.351)	DT 0.002 (1.193)	loss 10.521 (10.521)	prob 2.191 (2.1911)	GS 30.188 (30.188)	mem 60.204
Train: [1][250/750]	BT 0.200 (1.327)	DT 0.002 (1.169)	loss 10.339 (10.339)	prob 2.453 (2.4533)	GS 35.375 (35.375)	mem 60.345
Train: [1][255/750]	BT 0.153 (1.304)	DT 0.020 (1.146)	loss 10.438 (10.438)	prob 3.271 (3.2712)	GS 28.516 (28.516)	mem 60.455
Train: [1][260/750]	BT 0.140 (1.324)	DT 0.003 (1.167)	loss 10.835 (10.835)	prob 1.144 (1.1442)	GS 31.766 (31.766)	mem 62.650
Train: [1][265/750]	BT 0.161 (1.302)	DT 0.002 (1.145)	loss 10.194 (10.194)	prob 2.801 (2.8010)	GS 31.500 (31.500)	mem 62.786
Train: [1][270/750]	BT 0.166 (1.319)	DT 0.002 (1.163)	loss 10.409 (10.409)	prob 2.190 (2.1901)	GS 33.875 (33.875)	mem 59.629
Train: [1][275/750]	BT 0.192 (1.298)	DT 0.014 (1.142)	loss 10.448 (10.448)	prob 3.173 (3.1731)	GS 35.422 (35.422)	mem 59.044
Train: [1][280/750]	BT 13.511 (1.326)	DT 13.403 (1.170)	loss 10.388 (10.388)	prob 2.989 (2.9890)	GS 33.203 (33.203)	mem 60.487
Train: [1][285/750]	BT 0.092 (1.305)	DT 0.004 (1.149)	loss 10.419 (10.419)	prob 3.865 (3.8652)	GS 27.953 (27.953)	mem 60.577
Train: [1][290/750]	BT 0.326 (1.293)	DT 0.002 (1.137)	loss 10.968 (10.968)	prob 2.323 (2.3231)	GS 32.344 (32.344)	mem 61.332
Train: [1][295/750]	BT 0.167 (1.306)	DT 0.003 (1.150)	loss 10.800 (10.800)	prob 2.882 (2.8822)	GS 28.984 (28.984)	mem 63.118
Train: [1][300/750]	BT 0.125 (1.298)	DT 0.003 (1.142)	loss 10.322 (10.322)	prob 2.892 (2.8918)	GS 30.641 (30.641)	mem 63.944
Train: [1][305/750]	BT 0.163 (1.307)	DT 0.004 (1.150)	loss 10.582 (10.582)	prob 3.332 (3.3319)	GS 30.719 (30.719)	mem 64.472
Train: [1][310/750]	BT 3.522 (1.299)	DT 3.245 (1.142)	loss 10.815 (10.815)	prob 2.878 (2.8784)	GS 35.844 (35.844)	mem 64.562
Train: [1][315/750]	BT 0.135 (1.282)	DT 0.030 (1.125)	loss 10.249 (10.249)	prob 2.778 (2.7783)	GS 30.781 (30.781)	mem 64.497
Train: [1][320/750]	BT 0.091 (1.281)	DT 0.001 (1.124)	loss 11.099 (11.099)	prob 1.978 (1.9784)	GS 32.844 (32.844)	mem 64.477
Train: [1][325/750]	BT 0.227 (1.279)	DT 0.014 (1.122)	loss 10.016 (10.016)	prob 2.852 (2.8517)	GS 32.328 (32.328)	mem 64.485
Train: [1][330/750]	BT 0.185 (1.272)	DT 0.003 (1.115)	loss 11.104 (11.104)	prob 1.101 (1.1013)	GS 29.125 (29.125)	mem 64.499
Train: [1][335/750]	BT 0.163 (1.272)	DT 0.004 (1.115)	loss 10.557 (10.557)	prob 2.367 (2.3670)	GS 28.875 (28.875)	mem 64.505
Train: [1][340/750]	BT 7.674 (1.286)	DT 7.476 (1.128)	loss 10.509 (10.509)	prob 2.563 (2.5630)	GS 34.234 (34.234)	mem 57.851
Train: [1][345/750]	BT 0.227 (1.269)	DT 0.009 (1.112)	loss 10.429 (10.429)	prob 2.748 (2.7476)	GS 31.484 (31.484)	mem 58.092
Train: [1][350/750]	BT 0.087 (1.276)	DT 0.002 (1.119)	loss 10.066 (10.066)	prob 2.835 (2.8347)	GS 30.625 (30.625)	mem 59.659
Train: [1][355/750]	BT 0.090 (1.287)	DT 0.009 (1.131)	loss 11.111 (11.111)	prob 1.906 (1.9056)	GS 26.688 (26.688)	mem 61.688
Train: [1][360/750]	BT 0.452 (1.272)	DT 0.300 (1.116)	loss 10.456 (10.456)	prob 2.188 (2.1882)	GS 29.656 (29.656)	mem 61.904
Train: [1][365/750]	BT 0.234 (1.284)	DT 0.003 (1.127)	loss 10.004 (10.004)	prob 3.739 (3.7386)	GS 31.406 (31.406)	mem 63.665
Train: [1][370/750]	BT 0.145 (1.268)	DT 0.016 (1.112)	loss 10.333 (10.333)	prob 1.741 (1.7411)	GS 31.953 (31.953)	mem 63.692
Train: [1][375/750]	BT 0.087 (1.254)	DT 0.001 (1.098)	loss 10.494 (10.494)	prob 2.815 (2.8151)	GS 29.656 (29.656)	mem 63.742
Train: [1][380/750]	BT 0.122 (1.269)	DT 0.003 (1.113)	loss 10.044 (10.044)	prob 2.184 (2.1839)	GS 34.406 (34.406)	mem 59.474
Train: [1][385/750]	BT 0.112 (1.267)	DT 0.004 (1.112)	loss 10.551 (10.551)	prob 1.607 (1.6071)	GS 31.891 (31.891)	mem 60.591
Train: [1][390/750]	BT 0.163 (1.263)	DT 0.002 (1.108)	loss 10.744 (10.744)	prob 2.066 (2.0660)	GS 31.766 (31.766)	mem 61.687
Train: [1][395/750]	BT 0.112 (1.277)	DT 0.004 (1.122)	loss 10.409 (10.409)	prob 1.434 (1.4337)	GS 31.531 (31.531)	mem 63.884
Train: [1][400/750]	BT 4.972 (1.275)	DT 4.823 (1.120)	loss 10.121 (10.121)	prob 2.427 (2.4267)	GS 39.109 (39.109)	mem 64.469
Train: [1][405/750]	BT 0.204 (1.261)	DT 0.005 (1.106)	loss 9.944 (9.944)	prob 2.405 (2.4047)	GS 29.062 (29.062)	mem 64.447
Train: [1][410/750]	BT 0.134 (1.261)	DT 0.003 (1.106)	loss 10.497 (10.497)	prob 2.020 (2.0197)	GS 29.766 (29.766)	mem 64.532
Train: [1][415/750]	BT 0.251 (1.259)	DT 0.026 (1.103)	loss 10.053 (10.053)	prob 2.812 (2.8116)	GS 33.766 (33.766)	mem 64.434
Train: [1][420/750]	BT 0.145 (1.263)	DT 0.002 (1.108)	loss 10.787 (10.787)	prob 1.843 (1.8426)	GS 33.453 (33.453)	mem 64.431
Train: [1][425/750]	BT 0.186 (1.257)	DT 0.003 (1.101)	loss 10.257 (10.257)	prob 2.235 (2.2350)	GS 34.000 (34.000)	mem 64.783
Train: [1][430/750]	BT 9.896 (1.266)	DT 9.765 (1.110)	loss 10.486 (10.486)	prob 1.069 (1.0692)	GS 32.344 (32.344)	mem 64.495
Train: [1][435/750]	BT 0.208 (1.254)	DT 0.013 (1.098)	loss 10.370 (10.370)	prob 1.856 (1.8558)	GS 28.266 (28.266)	mem 64.495
Train: [1][440/750]	BT 0.243 (1.247)	DT 0.008 (1.091)	loss 10.499 (10.499)	prob 1.685 (1.6854)	GS 37.750 (37.750)	mem 64.687
Train: [1][445/750]	BT 0.133 (1.265)	DT 0.015 (1.109)	loss 10.883 (10.883)	prob 1.406 (1.4064)	GS 30.734 (30.734)	mem 60.084
Train: [1][450/750]	BT 0.103 (1.253)	DT 0.002 (1.097)	loss 11.094 (11.094)	prob 1.002 (1.0021)	GS 28.969 (28.969)	mem 60.351
Train: [1][455/750]	BT 0.073 (1.271)	DT 0.001 (1.115)	loss 10.301 (10.301)	prob 1.973 (1.9728)	GS 27.062 (27.062)	mem 62.871
Train: [1][460/750]	BT 0.126 (1.258)	DT 0.001 (1.103)	loss 10.440 (10.440)	prob 1.539 (1.5386)	GS 32.141 (32.141)	mem 63.006
Train: [1][465/750]	BT 0.294 (1.247)	DT 0.002 (1.092)	loss 10.251 (10.251)	prob 1.828 (1.8284)	GS 34.953 (34.953)	mem 63.258
Train: [1][470/750]	BT 0.181 (1.262)	DT 0.002 (1.107)	loss 10.265 (10.265)	prob 2.301 (2.3014)	GS 33.141 (33.141)	mem 58.936
Train: [1][475/750]	BT 0.101 (1.250)	DT 0.002 (1.096)	loss 10.626 (10.626)	prob 2.560 (2.5596)	GS 32.438 (32.438)	mem 59.100
Train: [1][480/750]	BT 0.223 (1.265)	DT 0.015 (1.110)	loss 9.790 (9.790)	prob 2.994 (2.9940)	GS 33.859 (33.859)	mem 61.759
Train: [1][485/750]	BT 0.109 (1.253)	DT 0.007 (1.098)	loss 10.163 (10.163)	prob 3.468 (3.4678)	GS 27.609 (27.609)	mem 61.797
Train: [1][490/750]	BT 12.505 (1.267)	DT 12.385 (1.112)	loss 10.753 (10.753)	prob 1.260 (1.2600)	GS 36.547 (36.547)	mem 63.920
Train: [1][495/750]	BT 0.139 (1.255)	DT 0.005 (1.101)	loss 10.641 (10.641)	prob 1.478 (1.4776)	GS 28.016 (28.016)	mem 64.115
Train: [1][500/750]	BT 0.101 (1.244)	DT 0.002 (1.090)	loss 10.383 (10.383)	prob 1.394 (1.3940)	GS 31.453 (31.453)	mem 64.181
Train: [1][505/750]	BT 0.213 (1.262)	DT 0.017 (1.108)	loss 9.420 (9.420)	prob 3.574 (3.5740)	GS 26.125 (26.125)	mem 64.536
Train: [1][510/750]	BT 0.205 (1.251)	DT 0.002 (1.097)	loss 11.085 (11.085)	prob 1.514 (1.5144)	GS 27.109 (27.109)	mem 64.537
Train: [1][515/750]	BT 0.097 (1.266)	DT 0.002 (1.112)	loss 10.481 (10.481)	prob 1.822 (1.8225)	GS 32.672 (32.672)	mem 64.470
Train: [1][520/750]	BT 0.104 (1.255)	DT 0.001 (1.101)	loss 10.577 (10.577)	prob 1.862 (1.8617)	GS 31.938 (31.938)	mem 64.659
Train: [1][525/750]	BT 0.120 (1.244)	DT 0.001 (1.091)	loss 10.768 (10.768)	prob 2.050 (2.0503)	GS 31.984 (31.984)	mem 64.421
Train: [1][530/750]	BT 0.125 (1.262)	DT 0.004 (1.109)	loss 10.802 (10.802)	prob 0.811 (0.8106)	GS 35.047 (35.047)	mem 59.114
Train: [1][535/750]	BT 0.309 (1.252)	DT 0.032 (1.098)	loss 10.819 (10.819)	prob 1.847 (1.8468)	GS 34.000 (34.000)	mem 59.299
Train: [1][540/750]	BT 0.100 (1.265)	DT 0.002 (1.111)	loss 9.923 (9.923)	prob 1.741 (1.7407)	GS 37.312 (37.312)	mem 61.712
Train: [1][545/750]	BT 0.087 (1.254)	DT 0.002 (1.101)	loss 10.024 (10.024)	prob 0.776 (0.7755)	GS 32.812 (32.812)	mem 61.827
Train: [1][550/750]	BT 14.493 (1.270)	DT 14.420 (1.117)	loss 10.185 (10.185)	prob 1.203 (1.2030)	GS 34.984 (34.984)	mem 57.967
Train: [1][555/750]	BT 0.085 (1.259)	DT 0.001 (1.107)	loss 10.442 (10.442)	prob 2.337 (2.3370)	GS 32.031 (32.031)	mem 58.092
Train: [1][560/750]	BT 0.087 (1.249)	DT 0.002 (1.098)	loss 10.554 (10.554)	prob -0.432 (-0.4321)	GS 37.391 (37.391)	mem 58.185
Train: [1][565/750]	BT 0.212 (1.262)	DT 0.004 (1.111)	loss 10.745 (10.745)	prob -0.011 (-0.0111)	GS 33.188 (33.188)	mem 60.804
Train: [1][570/750]	BT 0.122 (1.252)	DT 0.002 (1.101)	loss 10.348 (10.348)	prob 1.226 (1.2261)	GS 30.312 (30.312)	mem 60.976
Train: [1][575/750]	BT 0.152 (1.266)	DT 0.001 (1.114)	loss 10.534 (10.534)	prob 1.503 (1.5033)	GS 32.766 (32.766)	mem 63.795
Train: [1][580/750]	BT 0.193 (1.256)	DT 0.002 (1.104)	loss 10.340 (10.340)	prob 1.084 (1.0843)	GS 31.797 (31.797)	mem 63.944
Train: [1][585/750]	BT 0.131 (1.246)	DT 0.001 (1.095)	loss 10.499 (10.499)	prob 1.601 (1.6012)	GS 33.156 (33.156)	mem 64.049
Train: [1][590/750]	BT 0.089 (1.253)	DT 0.001 (1.102)	loss 9.920 (9.920)	prob 1.577 (1.5772)	GS 35.188 (35.188)	mem 64.532
Train: [1][595/750]	BT 0.159 (1.244)	DT 0.010 (1.093)	loss 10.448 (10.448)	prob 1.925 (1.9251)	GS 33.656 (33.656)	mem 64.574
Train: [1][600/750]	BT 0.156 (1.258)	DT 0.010 (1.106)	loss 10.635 (10.635)	prob 1.418 (1.4185)	GS 34.203 (34.203)	mem 64.443
Train: [1][605/750]	BT 0.177 (1.249)	DT 0.020 (1.097)	loss 10.427 (10.427)	prob 2.531 (2.5315)	GS 34.859 (34.859)	mem 64.466
Train: [1][610/750]	BT 10.843 (1.258)	DT 10.628 (1.106)	loss 10.691 (10.691)	prob 2.437 (2.4375)	GS 34.734 (34.734)	mem 64.563
Train: [1][615/750]	BT 0.206 (1.249)	DT 0.003 (1.097)	loss 10.649 (10.649)	prob 3.557 (3.5567)	GS 30.344 (30.344)	mem 64.522
Train: [1][620/750]	BT 0.112 (1.241)	DT 0.001 (1.088)	loss 10.643 (10.643)	prob 2.362 (2.3620)	GS 33.125 (33.125)	mem 64.521
Train: [1][625/750]	BT 0.151 (1.253)	DT 0.004 (1.101)	loss 10.052 (10.052)	prob 3.401 (3.4006)	GS 30.453 (30.453)	mem 59.236
Train: [1][630/750]	BT 0.110 (1.244)	DT 0.005 (1.092)	loss 11.107 (11.107)	prob 2.513 (2.5125)	GS 35.781 (35.781)	mem 59.198
Train: [1][635/750]	BT 0.171 (1.253)	DT 0.002 (1.101)	loss 10.588 (10.588)	prob 2.527 (2.5275)	GS 33.125 (33.125)	mem 61.451
Train: [1][640/750]	BT 0.123 (1.245)	DT 0.017 (1.093)	loss 10.411 (10.411)	prob 1.183 (1.1834)	GS 27.453 (27.453)	mem 61.621
Train: [1][645/750]	BT 0.269 (1.237)	DT 0.015 (1.085)	loss 10.415 (10.415)	prob 2.106 (2.1063)	GS 29.844 (29.844)	mem 61.696
Train: [1][650/750]	BT 0.119 (1.248)	DT 0.005 (1.096)	loss 10.023 (10.023)	prob 3.119 (3.1188)	GS 33.594 (33.594)	mem 63.745
Train: [1][655/750]	BT 0.252 (1.240)	DT 0.004 (1.088)	loss 10.005 (10.005)	prob 3.247 (3.2472)	GS 32.297 (32.297)	mem 63.814
Train: [1][660/750]	BT 2.191 (1.250)	DT 2.058 (1.097)	loss 10.243 (10.243)	prob 1.979 (1.9795)	GS 33.359 (33.359)	mem 59.777
Train: [1][665/750]	BT 0.162 (1.241)	DT 0.007 (1.089)	loss 10.576 (10.576)	prob 1.825 (1.8247)	GS 30.656 (30.656)	mem 59.822
Train: [1][670/750]	BT 11.865 (1.251)	DT 11.755 (1.099)	loss 10.887 (10.887)	prob 1.430 (1.4298)	GS 34.422 (34.422)	mem 62.058
Train: [1][675/750]	BT 0.072 (1.243)	DT 0.002 (1.091)	loss 9.963 (9.963)	prob 3.060 (3.0597)	GS 29.797 (29.797)	mem 62.303
Train: [1][680/750]	BT 0.140 (1.235)	DT 0.001 (1.083)	loss 10.399 (10.399)	prob 1.968 (1.9675)	GS 39.703 (39.703)	mem 62.449
Train: [1][685/750]	BT 0.083 (1.243)	DT 0.001 (1.092)	loss 10.501 (10.501)	prob 2.452 (2.4516)	GS 29.703 (29.703)	mem 64.620
Train: [1][690/750]	BT 0.229 (1.236)	DT 0.003 (1.084)	loss 10.826 (10.826)	prob 2.197 (2.1970)	GS 35.781 (35.781)	mem 64.730
Train: [1][695/750]	BT 0.141 (1.244)	DT 0.018 (1.092)	loss 10.502 (10.502)	prob 3.023 (3.0235)	GS 30.500 (30.500)	mem 64.487
Train: [1][700/750]	BT 0.252 (1.236)	DT 0.013 (1.084)	loss 10.559 (10.559)	prob 2.106 (2.1061)	GS 35.281 (35.281)	mem 64.514
Train: [1][705/750]	BT 0.103 (1.228)	DT 0.002 (1.076)	loss 10.324 (10.324)	prob 2.058 (2.0581)	GS 40.953 (40.953)	mem 64.517
Train: [1][710/750]	BT 0.340 (1.238)	DT 0.217 (1.085)	loss 11.188 (11.188)	prob 0.827 (0.8272)	GS 32.812 (32.812)	mem 64.644
Train: [1][715/750]	BT 0.180 (1.236)	DT 0.016 (1.084)	loss 10.431 (10.431)	prob 0.657 (0.6568)	GS 35.844 (35.844)	mem 64.546
Train: [1][720/750]	BT 0.113 (1.241)	DT 0.007 (1.088)	loss 10.172 (10.172)	prob 1.376 (1.3761)	GS 32.531 (32.531)	mem 57.679
Train: [1][725/750]	BT 0.136 (1.235)	DT 0.003 (1.082)	loss 11.323 (11.323)	prob 2.378 (2.3784)	GS 32.531 (32.531)	mem 58.020
Train: [1][730/750]	BT 5.638 (1.240)	DT 5.556 (1.087)	loss 10.370 (10.370)	prob 2.129 (2.1292)	GS 33.438 (33.438)	mem 59.718
Train: [1][735/750]	BT 0.099 (1.233)	DT 0.002 (1.080)	loss 9.858 (9.858)	prob 2.226 (2.2262)	GS 30.000 (30.000)	mem 59.813
Train: [1][740/750]	BT 1.528 (1.231)	DT 1.410 (1.078)	loss 11.083 (11.083)	prob 0.051 (0.0507)	GS 29.234 (29.234)	mem 46.339
Train: [1][745/750]	BT 0.089 (1.232)	DT 0.002 (1.080)	loss 9.828 (9.828)	prob 0.422 (0.4217)	GS 29.750 (29.750)	mem 33.690
Train: [1][750/750]	BT 0.084 (1.225)	DT 0.006 (1.072)	loss 10.835 (10.835)	prob 0.814 (0.8142)	GS 37.062 (37.062)	mem 33.792
Train: [1][755/750]	BT 0.077 (1.221)	DT 0.002 (1.070)	loss 9.698 (9.698)	prob 2.470 (2.4701)	GS 32.906 (32.906)	mem 29.813
epoch 1, total time 922.52
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [2][1/750]	BT 26.126 (26.126)	DT 26.011 (26.011)	loss 10.008 (10.008)	prob 2.297 (2.2974)	GS 37.625 (37.625)	mem 63.302
Train: [2][5/750]	BT 0.121 (5.353)	DT 0.002 (5.215)	loss 10.471 (10.471)	prob 2.841 (2.8406)	GS 30.828 (30.828)	mem 63.126
Train: [2][10/750]	BT 0.148 (2.759)	DT 0.020 (2.610)	loss 10.509 (10.509)	prob 2.422 (2.4218)	GS 35.828 (35.828)	mem 63.140
Train: [2][15/750]	BT 0.151 (3.189)	DT 0.010 (3.038)	loss 10.302 (10.302)	prob 2.761 (2.7614)	GS 30.938 (30.938)	mem 63.316
Train: [2][20/750]	BT 0.144 (2.426)	DT 0.004 (2.280)	loss 10.452 (10.452)	prob 1.464 (1.4635)	GS 33.406 (33.406)	mem 63.313
Train: [2][25/750]	BT 9.360 (2.353)	DT 9.236 (2.194)	loss 10.796 (10.796)	prob 1.030 (1.0297)	GS 32.578 (32.578)	mem 63.475
Train: [2][30/750]	BT 0.152 (2.096)	DT 0.016 (1.934)	loss 9.908 (9.908)	prob 1.032 (1.0322)	GS 33.672 (33.672)	mem 63.405
Train: [2][35/750]	BT 0.331 (1.826)	DT 0.004 (1.660)	loss 10.497 (10.497)	prob 0.171 (0.1706)	GS 31.266 (31.266)	mem 63.457
Train: [2][40/750]	BT 0.092 (1.950)	DT 0.005 (1.786)	loss 10.363 (10.363)	prob 1.005 (1.0046)	GS 35.469 (35.469)	mem 58.174
Train: [2][45/750]	BT 0.155 (1.753)	DT 0.005 (1.588)	loss 10.539 (10.539)	prob 1.481 (1.4812)	GS 33.469 (33.469)	mem 58.293
Train: [2][50/750]	BT 10.766 (1.850)	DT 10.625 (1.686)	loss 10.453 (10.453)	prob 1.164 (1.1641)	GS 33.812 (33.812)	mem 60.505
Train: [2][55/750]	BT 0.078 (1.695)	DT 0.002 (1.533)	loss 10.282 (10.282)	prob 1.479 (1.4788)	GS 30.266 (30.266)	mem 60.621
Train: [2][60/750]	BT 0.121 (1.600)	DT 0.002 (1.441)	loss 10.572 (10.572)	prob 1.650 (1.6495)	GS 31.797 (31.797)	mem 61.056
Train: [2][65/750]	BT 0.160 (1.680)	DT 0.013 (1.521)	loss 10.032 (10.032)	prob 3.383 (3.3833)	GS 34.641 (34.641)	mem 61.604
Train: [2][70/750]	BT 1.465 (1.594)	DT 1.319 (1.432)	loss 10.596 (10.596)	prob 0.507 (0.5071)	GS 35.672 (35.672)	mem 59.979
Train: [2][75/750]	BT 0.173 (1.659)	DT 0.011 (1.495)	loss 10.284 (10.284)	prob 1.898 (1.8977)	GS 31.938 (31.938)	mem 59.761
Train: [2][80/750]	BT 0.116 (1.574)	DT 0.008 (1.411)	loss 10.245 (10.245)	prob 1.120 (1.1202)	GS 30.344 (30.344)	mem 59.951
Train: [2][85/750]	BT 0.162 (1.515)	DT 0.001 (1.353)	loss 10.566 (10.566)	prob 1.399 (1.3991)	GS 34.812 (34.812)	mem 60.556
Train: [2][90/750]	BT 0.235 (1.588)	DT 0.003 (1.425)	loss 10.657 (10.657)	prob 1.221 (1.2214)	GS 32.484 (32.484)	mem 63.606
Train: [2][95/750]	BT 0.085 (1.511)	DT 0.004 (1.351)	loss 10.521 (10.521)	prob 1.794 (1.7938)	GS 27.922 (27.922)	mem 63.797
Train: [2][100/750]	BT 1.574 (1.557)	DT 1.439 (1.398)	loss 11.431 (11.431)	prob 1.120 (1.1200)	GS 32.172 (32.172)	mem 64.236
Train: [2][105/750]	BT 0.300 (1.491)	DT 0.004 (1.332)	loss 10.623 (10.623)	prob 2.153 (2.1528)	GS 31.812 (31.812)	mem 64.488
Train: [2][110/750]	BT 9.242 (1.514)	DT 9.049 (1.353)	loss 10.188 (10.188)	prob 1.976 (1.9765)	GS 33.375 (33.375)	mem 64.500
Train: [2][115/750]	BT 0.162 (1.488)	DT 0.002 (1.325)	loss 10.152 (10.152)	prob 3.599 (3.5987)	GS 34.828 (34.828)	mem 64.131
Train: [2][120/750]	BT 0.197 (1.434)	DT 0.001 (1.270)	loss 10.825 (10.825)	prob 2.345 (2.3452)	GS 36.672 (36.672)	mem 64.284
Train: [2][125/750]	BT 0.120 (1.500)	DT 0.001 (1.336)	loss 10.633 (10.633)	prob 2.008 (2.0077)	GS 41.219 (41.219)	mem 64.278
Train: [2][130/750]	BT 0.124 (1.448)	DT 0.002 (1.285)	loss 10.488 (10.488)	prob 2.534 (2.5337)	GS 31.375 (31.375)	mem 64.277
Train: [2][135/750]	BT 0.311 (1.446)	DT 0.018 (1.282)	loss 10.282 (10.282)	prob 2.925 (2.9251)	GS 27.828 (27.828)	mem 58.548
Train: [2][140/750]	BT 0.145 (1.463)	DT 0.001 (1.301)	loss 10.261 (10.261)	prob 2.512 (2.5121)	GS 31.406 (31.406)	mem 60.326
Train: [2][145/750]	BT 0.103 (1.418)	DT 0.007 (1.257)	loss 10.284 (10.284)	prob 2.599 (2.5986)	GS 33.172 (33.172)	mem 60.620
Train: [2][150/750]	BT 0.126 (1.465)	DT 0.009 (1.305)	loss 10.564 (10.564)	prob 2.925 (2.9252)	GS 32.234 (32.234)	mem 63.054
Train: [2][155/750]	BT 0.180 (1.421)	DT 0.013 (1.263)	loss 10.608 (10.608)	prob 2.692 (2.6920)	GS 33.047 (33.047)	mem 63.237
Train: [2][160/750]	BT 14.187 (1.481)	DT 14.119 (1.323)	loss 10.737 (10.737)	prob 2.413 (2.4131)	GS 35.672 (35.672)	mem 59.713
Train: [2][165/750]	BT 0.082 (1.440)	DT 0.003 (1.283)	loss 9.994 (9.994)	prob 3.433 (3.4326)	GS 31.391 (31.391)	mem 59.898
Train: [2][170/750]	BT 1.285 (1.407)	DT 1.177 (1.253)	loss 10.269 (10.269)	prob 2.173 (2.1732)	GS 34.078 (34.078)	mem 59.990
Train: [2][175/750]	BT 0.139 (1.425)	DT 0.016 (1.270)	loss 10.233 (10.233)	prob 1.817 (1.8174)	GS 32.328 (32.328)	mem 62.131
Train: [2][180/750]	BT 0.119 (1.390)	DT 0.005 (1.235)	loss 10.417 (10.417)	prob 1.585 (1.5849)	GS 31.172 (31.172)	mem 62.182
Train: [2][185/750]	BT 0.150 (1.438)	DT 0.003 (1.284)	loss 10.586 (10.586)	prob 1.794 (1.7938)	GS 34.297 (34.297)	mem 64.384
Train: [2][190/750]	BT 0.095 (1.406)	DT 0.002 (1.250)	loss 10.150 (10.150)	prob 2.557 (2.5568)	GS 34.203 (34.203)	mem 64.386
Train: [2][195/750]	BT 0.098 (1.374)	DT 0.002 (1.219)	loss 10.409 (10.409)	prob 3.155 (3.1554)	GS 30.766 (30.766)	mem 64.387
Train: [2][200/750]	BT 0.157 (1.412)	DT 0.008 (1.257)	loss 10.397 (10.397)	prob 1.788 (1.7878)	GS 32.328 (32.328)	mem 64.352
Train: [2][205/750]	BT 0.209 (1.382)	DT 0.002 (1.226)	loss 10.442 (10.442)	prob 1.555 (1.5548)	GS 34.516 (34.516)	mem 64.423
Train: [2][210/750]	BT 0.156 (1.421)	DT 0.002 (1.266)	loss 10.273 (10.273)	prob 1.056 (1.0565)	GS 33.578 (33.578)	mem 64.274
Train: [2][215/750]	BT 0.092 (1.391)	DT 0.001 (1.237)	loss 10.622 (10.622)	prob 0.319 (0.3188)	GS 27.922 (27.922)	mem 64.280
Train: [2][220/750]	BT 14.502 (1.429)	DT 14.408 (1.274)	loss 10.606 (10.606)	prob 1.030 (1.0300)	GS 33.594 (33.594)	mem 58.748
Train: [2][225/750]	BT 0.091 (1.400)	DT 0.004 (1.246)	loss 10.283 (10.283)	prob 2.142 (2.1420)	GS 33.953 (33.953)	mem 58.835
Train: [2][230/750]	BT 0.100 (1.372)	DT 0.001 (1.219)	loss 10.241 (10.241)	prob 1.908 (1.9079)	GS 30.531 (30.531)	mem 58.955
Train: [2][235/750]	BT 0.185 (1.400)	DT 0.019 (1.247)	loss 10.569 (10.569)	prob 0.853 (0.8532)	GS 29.438 (29.438)	mem 61.266
Train: [2][240/750]	BT 0.099 (1.375)	DT 0.003 (1.222)	loss 10.823 (10.823)	prob 1.058 (1.0581)	GS 33.500 (33.500)	mem 61.409
Train: [2][245/750]	BT 0.193 (1.403)	DT 0.004 (1.250)	loss 10.480 (10.480)	prob 1.498 (1.4976)	GS 40.547 (40.547)	mem 63.526
Train: [2][250/750]	BT 0.223 (1.378)	DT 0.002 (1.225)	loss 10.080 (10.080)	prob 1.972 (1.9719)	GS 34.719 (34.719)	mem 63.628
Train: [2][255/750]	BT 0.308 (1.355)	DT 0.002 (1.201)	loss 10.396 (10.396)	prob 1.470 (1.4704)	GS 30.781 (30.781)	mem 63.755
Train: [2][260/750]	BT 0.292 (1.375)	DT 0.001 (1.221)	loss 10.331 (10.331)	prob 1.411 (1.4105)	GS 32.375 (32.375)	mem 59.598
Train: [2][265/750]	BT 0.123 (1.352)	DT 0.010 (1.198)	loss 10.170 (10.170)	prob 1.819 (1.8194)	GS 30.797 (30.797)	mem 59.804
Train: [2][270/750]	BT 0.096 (1.376)	DT 0.004 (1.223)	loss 9.896 (9.896)	prob 2.469 (2.4686)	GS 32.641 (32.641)	mem 62.166
Train: [2][275/750]	BT 0.210 (1.354)	DT 0.003 (1.200)	loss 10.867 (10.867)	prob 2.353 (2.3529)	GS 32.094 (32.094)	mem 62.284
Train: [2][280/750]	BT 15.521 (1.386)	DT 15.420 (1.234)	loss 10.624 (10.624)	prob 1.391 (1.3906)	GS 36.328 (36.328)	mem 64.406
Train: [2][285/750]	BT 0.120 (1.364)	DT 0.006 (1.213)	loss 10.560 (10.560)	prob 2.292 (2.2916)	GS 31.047 (31.047)	mem 64.448
Train: [2][290/750]	BT 0.263 (1.344)	DT 0.002 (1.192)	loss 10.930 (10.930)	prob 1.153 (1.1527)	GS 33.891 (33.891)	mem 64.526
Train: [2][295/750]	BT 0.142 (1.363)	DT 0.003 (1.210)	loss 10.645 (10.645)	prob 1.164 (1.1642)	GS 30.031 (30.031)	mem 64.449
Train: [2][300/750]	BT 0.162 (1.343)	DT 0.008 (1.190)	loss 10.229 (10.229)	prob 1.653 (1.6525)	GS 36.781 (36.781)	mem 64.427
Train: [2][305/750]	BT 0.109 (1.362)	DT 0.002 (1.210)	loss 10.372 (10.372)	prob 1.868 (1.8679)	GS 29.125 (29.125)	mem 64.554
Train: [2][310/750]	BT 0.166 (1.343)	DT 0.006 (1.191)	loss 10.773 (10.773)	prob 1.406 (1.4058)	GS 33.328 (33.328)	mem 64.526
Train: [2][315/750]	BT 0.170 (1.324)	DT 0.002 (1.172)	loss 10.735 (10.735)	prob 1.984 (1.9838)	GS 34.500 (34.500)	mem 64.471
Train: [2][320/750]	BT 0.127 (1.340)	DT 0.016 (1.188)	loss 10.444 (10.444)	prob 1.694 (1.6943)	GS 33.281 (33.281)	mem 58.599
Train: [2][325/750]	BT 0.233 (1.322)	DT 0.002 (1.170)	loss 10.475 (10.475)	prob 1.760 (1.7600)	GS 28.391 (28.391)	mem 58.757
Train: [2][330/750]	BT 0.441 (1.339)	DT 0.278 (1.187)	loss 11.111 (11.111)	prob 0.737 (0.7372)	GS 32.234 (32.234)	mem 60.464
Train: [2][335/750]	BT 0.195 (1.321)	DT 0.004 (1.169)	loss 10.441 (10.441)	prob 1.667 (1.6665)	GS 32.797 (32.797)	mem 60.593
Train: [2][340/750]	BT 12.226 (1.340)	DT 12.098 (1.188)	loss 10.651 (10.651)	prob 0.387 (0.3867)	GS 31.969 (31.969)	mem 62.935
Train: [2][345/750]	BT 0.111 (1.322)	DT 0.002 (1.170)	loss 10.541 (10.541)	prob 0.981 (0.9813)	GS 35.750 (35.750)	mem 63.097
Train: [2][350/750]	BT 5.033 (1.319)	DT 4.909 (1.168)	loss 10.583 (10.583)	prob 1.358 (1.3584)	GS 36.141 (36.141)	mem 63.734
Train: [2][355/750]	BT 0.117 (1.333)	DT 0.002 (1.182)	loss 10.923 (10.923)	prob 0.955 (0.9553)	GS 30.156 (30.156)	mem 59.493
Train: [2][360/750]	BT 0.130 (1.317)	DT 0.002 (1.166)	loss 11.147 (11.147)	prob 0.953 (0.9530)	GS 36.062 (36.062)	mem 59.700
Train: [2][365/750]	BT 0.146 (1.332)	DT 0.001 (1.181)	loss 9.875 (9.875)	prob 2.437 (2.4368)	GS 31.938 (31.938)	mem 62.171
Train: [2][370/750]	BT 0.143 (1.315)	DT 0.002 (1.165)	loss 10.232 (10.232)	prob 1.747 (1.7471)	GS 32.453 (32.453)	mem 62.302
Train: [2][375/750]	BT 0.166 (1.305)	DT 0.004 (1.155)	loss 10.254 (10.254)	prob 1.687 (1.6871)	GS 27.984 (27.984)	mem 62.798
Train: [2][380/750]	BT 0.112 (1.319)	DT 0.001 (1.170)	loss 10.729 (10.729)	prob 1.330 (1.3299)	GS 30.906 (30.906)	mem 64.464
Train: [2][385/750]	BT 0.267 (1.305)	DT 0.005 (1.155)	loss 10.144 (10.144)	prob 2.385 (2.3853)	GS 30.688 (30.688)	mem 64.479
Train: [2][390/750]	BT 0.116 (1.328)	DT 0.008 (1.178)	loss 10.339 (10.339)	prob 1.114 (1.1138)	GS 37.078 (37.078)	mem 64.604
Train: [2][395/750]	BT 0.229 (1.314)	DT 0.004 (1.163)	loss 10.483 (10.483)	prob 2.120 (2.1203)	GS 31.328 (31.328)	mem 64.496
Train: [2][400/750]	BT 12.820 (1.331)	DT 12.589 (1.180)	loss 10.202 (10.202)	prob 2.283 (2.2828)	GS 33.422 (33.422)	mem 64.475
Train: [2][405/750]	BT 0.124 (1.317)	DT 0.004 (1.165)	loss 10.278 (10.278)	prob 2.685 (2.6849)	GS 28.656 (28.656)	mem 64.522
Train: [2][410/750]	BT 0.158 (1.302)	DT 0.009 (1.151)	loss 10.208 (10.208)	prob 3.197 (3.1966)	GS 33.094 (33.094)	mem 64.525
Train: [2][415/750]	BT 0.203 (1.315)	DT 0.001 (1.164)	loss 10.455 (10.455)	prob 2.104 (2.1045)	GS 30.719 (30.719)	mem 58.389
Train: [2][420/750]	BT 0.107 (1.301)	DT 0.020 (1.150)	loss 9.796 (9.796)	prob 2.648 (2.6479)	GS 31.875 (31.875)	mem 58.383
Train: [2][425/750]	BT 0.174 (1.315)	DT 0.006 (1.164)	loss 9.977 (9.977)	prob 3.116 (3.1160)	GS 32.141 (32.141)	mem 60.328
Train: [2][430/750]	BT 0.123 (1.308)	DT 0.008 (1.157)	loss 10.760 (10.760)	prob 1.689 (1.6892)	GS 35.672 (35.672)	mem 61.127
Train: [2][435/750]	BT 0.140 (1.294)	DT 0.014 (1.144)	loss 10.227 (10.227)	prob 2.797 (2.7966)	GS 31.812 (31.812)	mem 61.265
Train: [2][440/750]	BT 1.835 (1.319)	DT 1.670 (1.169)	loss 10.189 (10.189)	prob 2.189 (2.1887)	GS 37.219 (37.219)	mem 62.634
Train: [2][445/750]	BT 0.232 (1.307)	DT 0.031 (1.156)	loss 10.119 (10.119)	prob 2.948 (2.9479)	GS 37.984 (37.984)	mem 62.403
Train: [2][450/750]	BT 0.225 (1.320)	DT 0.008 (1.169)	loss 10.283 (10.283)	prob 1.955 (1.9553)	GS 35.766 (35.766)	mem 60.323
Train: [2][455/750]	BT 0.109 (1.307)	DT 0.012 (1.157)	loss 10.390 (10.390)	prob 2.784 (2.7836)	GS 28.094 (28.094)	mem 60.440
Train: [2][460/750]	BT 11.863 (1.320)	DT 11.770 (1.170)	loss 10.420 (10.420)	prob 2.147 (2.1475)	GS 32.734 (32.734)	mem 62.908
Train: [2][465/750]	BT 0.125 (1.308)	DT 0.001 (1.159)	loss 9.897 (9.897)	prob 2.388 (2.3879)	GS 30.672 (30.672)	mem 63.203
Train: [2][470/750]	BT 0.105 (1.296)	DT 0.001 (1.146)	loss 11.175 (11.175)	prob 0.979 (0.9791)	GS 28.469 (28.469)	mem 63.369
Train: [2][475/750]	BT 0.088 (1.316)	DT 0.001 (1.167)	loss 10.170 (10.170)	prob 2.223 (2.2232)	GS 31.031 (31.031)	mem 64.587
Train: [2][480/750]	BT 0.080 (1.304)	DT 0.001 (1.155)	loss 10.635 (10.635)	prob 1.506 (1.5057)	GS 33.625 (33.625)	mem 64.565
Train: [2][485/750]	BT 0.224 (1.311)	DT 0.002 (1.161)	loss 10.563 (10.563)	prob 2.213 (2.2134)	GS 31.359 (31.359)	mem 64.521
Train: [2][490/750]	BT 0.146 (1.299)	DT 0.001 (1.150)	loss 10.744 (10.744)	prob 2.326 (2.3262)	GS 33.219 (33.219)	mem 64.518
Train: [2][495/750]	BT 0.176 (1.288)	DT 0.004 (1.138)	loss 10.215 (10.215)	prob 2.303 (2.3033)	GS 32.078 (32.078)	mem 64.551
Train: [2][500/750]	BT 5.608 (1.308)	DT 5.511 (1.158)	loss 10.788 (10.788)	prob 1.426 (1.4264)	GS 35.359 (35.359)	mem 64.541
Train: [2][505/750]	BT 0.169 (1.297)	DT 0.017 (1.147)	loss 10.650 (10.650)	prob 2.281 (2.2808)	GS 33.922 (33.922)	mem 64.530
Train: [2][510/750]	BT 0.151 (1.302)	DT 0.002 (1.151)	loss 10.755 (10.755)	prob 2.080 (2.0805)	GS 32.297 (32.297)	mem 59.002
Train: [2][515/750]	BT 0.130 (1.301)	DT 0.008 (1.151)	loss 10.367 (10.367)	prob 1.971 (1.9707)	GS 30.656 (30.656)	mem 60.172
Train: [2][520/750]	BT 6.199 (1.302)	DT 6.103 (1.151)	loss 10.225 (10.225)	prob 2.434 (2.4342)	GS 31.516 (31.516)	mem 61.840
Train: [2][525/750]	BT 0.123 (1.303)	DT 0.005 (1.153)	loss 10.692 (10.692)	prob 1.893 (1.8931)	GS 29.500 (29.500)	mem 62.934
Train: [2][530/750]	BT 0.315 (1.293)	DT 0.030 (1.142)	loss 10.253 (10.253)	prob 2.572 (2.5721)	GS 30.125 (30.125)	mem 63.014
Train: [2][535/750]	BT 0.241 (1.292)	DT 0.029 (1.141)	loss 10.166 (10.166)	prob 3.136 (3.1358)	GS 26.203 (26.203)	mem 63.715
Train: [2][540/750]	BT 0.127 (1.298)	DT 0.009 (1.148)	loss 10.825 (10.825)	prob 1.291 (1.2912)	GS 37.500 (37.500)	mem 59.079
Train: [2][545/750]	BT 0.102 (1.298)	DT 0.002 (1.148)	loss 10.521 (10.521)	prob 1.840 (1.8404)	GS 30.359 (30.359)	mem 60.393
Train: [2][550/750]	BT 0.133 (1.300)	DT 0.009 (1.150)	loss 9.807 (9.807)	prob 1.847 (1.8475)	GS 32.109 (32.109)	mem 61.992
Train: [2][555/750]	BT 0.117 (1.289)	DT 0.002 (1.139)	loss 10.322 (10.322)	prob 1.342 (1.3419)	GS 34.250 (34.250)	mem 62.215
Train: [2][560/750]	BT 9.950 (1.301)	DT 9.798 (1.151)	loss 10.396 (10.396)	prob 1.557 (1.5566)	GS 35.312 (35.312)	mem 64.482
Train: [2][565/750]	BT 0.262 (1.291)	DT 0.014 (1.141)	loss 10.076 (10.076)	prob 2.483 (2.4827)	GS 29.719 (29.719)	mem 64.652
Train: [2][570/750]	BT 0.253 (1.284)	DT 0.026 (1.134)	loss 10.384 (10.384)	prob 1.032 (1.0324)	GS 36.219 (36.219)	mem 64.558
Train: [2][575/750]	BT 0.123 (1.295)	DT 0.013 (1.145)	loss 9.803 (9.803)	prob 2.241 (2.2409)	GS 29.562 (29.562)	mem 64.543
Train: [2][580/750]	BT 3.578 (1.291)	DT 3.366 (1.141)	loss 10.541 (10.541)	prob 2.235 (2.2354)	GS 36.578 (36.578)	mem 64.452
Train: [2][585/750]	BT 0.131 (1.294)	DT 0.005 (1.143)	loss 9.797 (9.797)	prob 3.422 (3.4216)	GS 27.625 (27.625)	mem 64.564
Train: [2][590/750]	BT 0.241 (1.284)	DT 0.004 (1.134)	loss 10.643 (10.643)	prob 1.542 (1.5417)	GS 34.656 (34.656)	mem 64.613
Train: [2][595/750]	BT 0.219 (1.285)	DT 0.005 (1.133)	loss 10.025 (10.025)	prob 2.535 (2.5346)	GS 29.750 (29.750)	mem 64.641
Train: [2][600/750]	BT 0.092 (1.290)	DT 0.003 (1.139)	loss 11.236 (11.236)	prob 1.407 (1.4071)	GS 35.578 (35.578)	mem 58.603
Train: [2][605/750]	BT 0.181 (1.290)	DT 0.006 (1.139)	loss 10.371 (10.371)	prob 2.157 (2.1572)	GS 33.672 (33.672)	mem 59.524
Train: [2][610/750]	BT 0.110 (1.291)	DT 0.010 (1.140)	loss 10.687 (10.687)	prob 1.705 (1.7051)	GS 36.172 (36.172)	mem 60.994
Train: [2][615/750]	BT 0.131 (1.282)	DT 0.002 (1.131)	loss 10.430 (10.430)	prob 2.999 (2.9994)	GS 37.641 (37.641)	mem 61.075
Train: [2][620/750]	BT 9.814 (1.291)	DT 9.658 (1.140)	loss 10.424 (10.424)	prob 2.530 (2.5296)	GS 35.000 (35.000)	mem 63.157
Train: [2][625/750]	BT 0.132 (1.281)	DT 0.003 (1.131)	loss 10.546 (10.546)	prob 2.975 (2.9753)	GS 34.000 (34.000)	mem 63.472
Train: [2][630/750]	BT 0.173 (1.276)	DT 0.002 (1.125)	loss 10.005 (10.005)	prob 2.863 (2.8629)	GS 31.438 (31.438)	mem 63.781
Train: [2][635/750]	BT 0.215 (1.288)	DT 0.015 (1.138)	loss 11.123 (11.123)	prob 0.541 (0.5411)	GS 29.312 (29.312)	mem 59.881
Train: [2][640/750]	BT 1.143 (1.281)	DT 0.972 (1.130)	loss 10.251 (10.251)	prob 2.094 (2.0940)	GS 36.547 (36.547)	mem 60.334
Train: [2][645/750]	BT 0.113 (1.291)	DT 0.002 (1.140)	loss 9.972 (9.972)	prob 2.628 (2.6276)	GS 30.234 (30.234)	mem 62.570
arpack error, retry= 0
Train: [2][650/750]	BT 0.108 (1.282)	DT 0.007 (1.132)	loss 10.075 (10.075)	prob 2.621 (2.6213)	GS 33.812 (33.812)	mem 62.763
Train: [2][655/750]	BT 0.111 (1.273)	DT 0.003 (1.123)	loss 10.426 (10.426)	prob 1.584 (1.5839)	GS 30.547 (30.547)	mem 63.049
Train: [2][660/750]	BT 0.217 (1.287)	DT 0.001 (1.137)	loss 10.642 (10.642)	prob 2.084 (2.0842)	GS 34.234 (34.234)	mem 64.559
Train: [2][665/750]	BT 0.251 (1.279)	DT 0.054 (1.128)	loss 10.565 (10.565)	prob 2.876 (2.8760)	GS 37.141 (37.141)	mem 64.550
Train: [2][670/750]	BT 0.179 (1.284)	DT 0.003 (1.133)	loss 10.499 (10.499)	prob 2.365 (2.3645)	GS 30.844 (30.844)	mem 64.455
Train: [2][675/750]	BT 0.282 (1.276)	DT 0.020 (1.125)	loss 10.695 (10.695)	prob 3.119 (3.1191)	GS 34.125 (34.125)	mem 64.609
Train: [2][680/750]	BT 15.210 (1.291)	DT 15.075 (1.139)	loss 10.369 (10.369)	prob 2.469 (2.4686)	GS 38.609 (38.609)	mem 64.423
Train: [2][685/750]	BT 0.112 (1.283)	DT 0.008 (1.131)	loss 10.191 (10.191)	prob 3.810 (3.8095)	GS 34.141 (34.141)	mem 64.421
Train: [2][690/750]	BT 0.259 (1.275)	DT 0.020 (1.123)	loss 10.749 (10.749)	prob 2.251 (2.2512)	GS 33.594 (33.594)	mem 64.448
Train: [2][695/750]	BT 0.139 (1.287)	DT 0.007 (1.135)	loss 10.339 (10.339)	prob 3.280 (3.2803)	GS 30.750 (30.750)	mem 58.552
Train: [2][700/750]	BT 0.153 (1.279)	DT 0.022 (1.127)	loss 10.491 (10.491)	prob 3.087 (3.0870)	GS 31.406 (31.406)	mem 58.640
Train: [2][705/750]	BT 0.154 (1.289)	DT 0.002 (1.138)	loss 10.181 (10.181)	prob 4.174 (4.1738)	GS 32.125 (32.125)	mem 61.088
Train: [2][710/750]	BT 0.272 (1.281)	DT 0.011 (1.130)	loss 10.248 (10.248)	prob 3.289 (3.2888)	GS 36.453 (36.453)	mem 61.392
Train: [2][715/750]	BT 0.120 (1.273)	DT 0.015 (1.122)	loss 10.473 (10.473)	prob 2.834 (2.8341)	GS 30.297 (30.297)	mem 61.371
Train: [2][720/750]	BT 0.163 (1.284)	DT 0.012 (1.133)	loss 10.613 (10.613)	prob 1.293 (1.2926)	GS 35.312 (35.312)	mem 63.697
Train: [2][725/750]	BT 0.104 (1.276)	DT 0.003 (1.125)	loss 9.976 (9.976)	prob 1.471 (1.4708)	GS 30.156 (30.156)	mem 63.885
Train: [2][730/750]	BT 0.081 (1.281)	DT 0.002 (1.131)	loss 10.276 (10.276)	prob 1.277 (1.2770)	GS 34.312 (34.312)	mem 59.171
Train: [2][735/750]	BT 0.101 (1.274)	DT 0.001 (1.123)	loss 10.628 (10.628)	prob 2.354 (2.3536)	GS 32.188 (32.188)	mem 59.370
Train: [2][740/750]	BT 7.492 (1.276)	DT 7.402 (1.126)	loss 10.144 (10.144)	prob 2.931 (2.9307)	GS 27.844 (27.844)	mem 29.906
Train: [2][745/750]	BT 0.090 (1.268)	DT 0.002 (1.118)	loss 10.900 (10.900)	prob 2.410 (2.4101)	GS 30.250 (30.250)	mem 30.202
Train: [2][750/750]	BT 0.080 (1.260)	DT 0.001 (1.111)	loss 10.689 (10.689)	prob 3.272 (3.2722)	GS 34.469 (34.469)	mem 30.196
Train: [2][755/750]	BT 0.097 (1.254)	DT 0.001 (1.106)	loss 10.072 (10.072)	prob 3.934 (3.9335)	GS 24.062 (24.062)	mem 31.250
epoch 2, total time 947.34
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [3][1/750]	BT 24.059 (24.059)	DT 23.729 (23.729)	loss 10.321 (10.321)	prob 3.190 (3.1903)	GS 31.281 (31.281)	mem 63.047
Train: [3][5/750]	BT 0.228 (5.385)	DT 0.002 (5.166)	loss 10.242 (10.242)	prob 3.018 (3.0175)	GS 31.609 (31.609)	mem 63.192
Train: [3][10/750]	BT 0.189 (2.801)	DT 0.009 (2.588)	loss 10.121 (10.121)	prob 2.711 (2.7110)	GS 35.469 (35.469)	mem 63.428
Train: [3][15/750]	BT 0.183 (2.517)	DT 0.009 (2.320)	loss 9.893 (9.893)	prob 3.249 (3.2495)	GS 31.109 (31.109)	mem 57.135
Train: [3][20/750]	BT 2.948 (2.330)	DT 2.846 (2.143)	loss 10.067 (10.067)	prob 1.614 (1.6137)	GS 36.312 (36.312)	mem 58.717
Train: [3][25/750]	BT 0.276 (1.898)	DT 0.005 (1.715)	loss 10.332 (10.332)	prob 2.022 (2.0220)	GS 31.828 (31.828)	mem 58.816
Train: [3][30/750]	BT 0.287 (1.898)	DT 0.014 (1.703)	loss 9.989 (9.989)	prob 2.578 (2.5778)	GS 34.203 (34.203)	mem 60.455
Train: [3][35/750]	BT 0.106 (1.730)	DT 0.001 (1.547)	loss 10.076 (10.076)	prob 2.118 (2.1185)	GS 30.797 (30.797)	mem 61.239
Train: [3][40/750]	BT 2.560 (1.744)	DT 2.330 (1.564)	loss 10.693 (10.693)	prob 2.080 (2.0797)	GS 33.875 (33.875)	mem 62.692
Train: [3][45/750]	BT 0.176 (1.717)	DT 0.007 (1.541)	loss 10.550 (10.550)	prob 2.305 (2.3053)	GS 30.375 (30.375)	mem 57.328
Train: [3][50/750]	BT 5.184 (1.659)	DT 5.033 (1.487)	loss 10.420 (10.420)	prob 2.425 (2.4246)	GS 32.125 (32.125)	mem 58.542
Train: [3][55/750]	BT 0.240 (1.525)	DT 0.034 (1.355)	loss 10.457 (10.457)	prob 2.549 (2.5493)	GS 36.203 (36.203)	mem 58.516
Train: [3][60/750]	BT 0.103 (1.553)	DT 0.004 (1.387)	loss 10.145 (10.145)	prob 3.175 (3.1750)	GS 34.125 (34.125)	mem 60.476
Train: [3][65/750]	BT 0.310 (1.545)	DT 0.004 (1.380)	loss 10.523 (10.523)	prob 3.450 (3.4500)	GS 35.234 (35.234)	mem 62.098
Train: [3][70/750]	BT 0.234 (1.546)	DT 0.002 (1.381)	loss 10.189 (10.189)	prob 2.269 (2.2688)	GS 35.875 (35.875)	mem 63.530
Train: [3][75/750]	BT 0.118 (1.535)	DT 0.001 (1.371)	loss 9.846 (9.846)	prob 3.426 (3.4258)	GS 30.781 (30.781)	mem 63.619
Train: [3][80/750]	BT 3.862 (1.494)	DT 3.659 (1.331)	loss 10.687 (10.687)	prob 2.351 (2.3514)	GS 34.062 (34.062)	mem 63.810
Train: [3][85/750]	BT 0.235 (1.419)	DT 0.007 (1.253)	loss 9.403 (9.403)	prob 3.116 (3.1156)	GS 28.469 (28.469)	mem 63.742
Train: [3][90/750]	BT 0.102 (1.471)	DT 0.001 (1.307)	loss 10.388 (10.388)	prob 1.637 (1.6372)	GS 31.797 (31.797)	mem 63.702
Train: [3][95/750]	BT 0.213 (1.450)	DT 0.017 (1.287)	loss 10.483 (10.483)	prob 1.782 (1.7821)	GS 32.438 (32.438)	mem 63.818
Train: [3][100/750]	BT 0.144 (1.438)	DT 0.006 (1.276)	loss 10.310 (10.310)	prob 2.641 (2.6414)	GS 36.125 (36.125)	mem 63.628
Train: [3][105/750]	BT 0.164 (1.439)	DT 0.005 (1.276)	loss 10.431 (10.431)	prob 1.964 (1.9642)	GS 30.875 (30.875)	mem 57.128
Train: [3][110/750]	BT 7.949 (1.449)	DT 7.784 (1.289)	loss 10.451 (10.451)	prob 1.345 (1.3450)	GS 32.719 (32.719)	mem 58.899
Train: [3][115/750]	BT 0.137 (1.393)	DT 0.006 (1.233)	loss 10.114 (10.114)	prob 1.376 (1.3760)	GS 32.875 (32.875)	mem 58.907
Train: [3][120/750]	BT 0.117 (1.379)	DT 0.001 (1.219)	loss 10.356 (10.356)	prob 1.646 (1.6459)	GS 32.906 (32.906)	mem 59.790
Train: [3][125/750]	BT 0.145 (1.394)	DT 0.001 (1.235)	loss 10.193 (10.193)	prob 2.844 (2.8440)	GS 26.750 (26.750)	mem 61.395
Train: [3][130/750]	BT 0.149 (1.409)	DT 0.001 (1.250)	loss 10.755 (10.755)	prob 2.153 (2.1529)	GS 37.484 (37.484)	mem 62.932
Train: [3][135/750]	BT 0.116 (1.405)	DT 0.002 (1.245)	loss 10.147 (10.147)	prob 1.188 (1.1879)	GS 32.891 (32.891)	mem 57.657
Train: [3][140/750]	BT 8.886 (1.424)	DT 8.789 (1.263)	loss 10.269 (10.269)	prob 1.548 (1.5477)	GS 33.406 (33.406)	mem 59.559
Train: [3][145/750]	BT 0.121 (1.380)	DT 0.014 (1.220)	loss 10.022 (10.022)	prob 2.460 (2.4598)	GS 35.219 (35.219)	mem 59.712
Train: [3][150/750]	BT 0.176 (1.363)	DT 0.003 (1.204)	loss 10.321 (10.321)	prob 2.605 (2.6054)	GS 31.516 (31.516)	mem 60.324
Train: [3][155/750]	BT 0.141 (1.370)	DT 0.001 (1.211)	loss 9.956 (9.956)	prob 1.460 (1.4600)	GS 32.172 (32.172)	mem 61.943
Train: [3][160/750]	BT 4.880 (1.399)	DT 4.778 (1.239)	loss 10.328 (10.328)	prob 1.896 (1.8955)	GS 34.422 (34.422)	mem 63.775
Train: [3][165/750]	BT 0.167 (1.361)	DT 0.016 (1.202)	loss 10.578 (10.578)	prob 1.689 (1.6890)	GS 33.703 (33.703)	mem 63.941
Train: [3][170/750]	BT 9.513 (1.383)	DT 9.382 (1.222)	loss 10.489 (10.489)	prob 1.260 (1.2599)	GS 30.125 (30.125)	mem 63.840
Train: [3][175/750]	BT 0.099 (1.354)	DT 0.002 (1.194)	loss 9.993 (9.993)	prob 2.852 (2.8521)	GS 30.266 (30.266)	mem 63.862
Train: [3][180/750]	BT 0.120 (1.336)	DT 0.003 (1.177)	loss 10.292 (10.292)	prob 2.960 (2.9601)	GS 35.531 (35.531)	mem 63.810
Train: [3][185/750]	BT 0.109 (1.341)	DT 0.002 (1.182)	loss 9.996 (9.996)	prob 3.170 (3.1699)	GS 30.516 (30.516)	mem 63.856
Train: [3][190/750]	BT 0.306 (1.363)	DT 0.004 (1.204)	loss 10.291 (10.291)	prob 2.767 (2.7672)	GS 36.281 (36.281)	mem 64.052
Train: [3][195/750]	BT 0.110 (1.358)	DT 0.002 (1.200)	loss 9.970 (9.970)	prob 1.919 (1.9189)	GS 31.078 (31.078)	mem 57.324
Train: [3][200/750]	BT 4.096 (1.347)	DT 3.953 (1.190)	loss 9.904 (9.904)	prob 2.113 (2.1132)	GS 30.828 (30.828)	mem 58.249
Train: [3][205/750]	BT 0.143 (1.318)	DT 0.001 (1.161)	loss 10.392 (10.392)	prob 1.959 (1.9594)	GS 30.531 (30.531)	mem 58.339
Train: [3][210/750]	BT 0.222 (1.324)	DT 0.003 (1.166)	loss 9.659 (9.659)	prob 2.595 (2.5948)	GS 36.641 (36.641)	mem 59.817
Train: [3][215/750]	BT 0.104 (1.318)	DT 0.009 (1.162)	loss 10.601 (10.601)	prob 2.006 (2.0064)	GS 35.297 (35.297)	mem 60.930
Train: [3][220/750]	BT 3.850 (1.324)	DT 3.751 (1.167)	loss 10.008 (10.008)	prob 3.492 (3.4922)	GS 34.797 (34.797)	mem 62.316
Train: [3][225/750]	BT 0.242 (1.314)	DT 0.004 (1.157)	loss 10.333 (10.333)	prob 3.719 (3.7186)	GS 33.484 (33.484)	mem 62.947
Train: [3][230/750]	BT 5.972 (1.315)	DT 5.721 (1.156)	loss 10.471 (10.471)	prob 2.704 (2.7035)	GS 32.641 (32.641)	mem 63.322
Train: [3][235/750]	BT 0.134 (1.310)	DT 0.003 (1.152)	loss 10.037 (10.037)	prob 3.118 (3.1180)	GS 29.719 (29.719)	mem 58.326
Train: [3][240/750]	BT 0.126 (1.304)	DT 0.008 (1.146)	loss 10.734 (10.734)	prob 2.369 (2.3694)	GS 35.719 (35.719)	mem 59.333
Train: [3][245/750]	BT 0.094 (1.318)	DT 0.001 (1.160)	loss 10.295 (10.295)	prob 2.531 (2.5314)	GS 31.891 (31.891)	mem 61.592
Train: [3][250/750]	BT 0.143 (1.313)	DT 0.001 (1.155)	loss 9.970 (9.970)	prob 3.598 (3.5979)	GS 25.125 (25.125)	mem 62.812
Train: [3][255/750]	BT 0.260 (1.291)	DT 0.007 (1.133)	loss 10.444 (10.444)	prob 3.534 (3.5340)	GS 28.703 (28.703)	mem 63.164
Train: [3][260/750]	BT 7.383 (1.328)	DT 7.239 (1.170)	loss 10.299 (10.299)	prob 2.934 (2.9340)	GS 35.328 (35.328)	mem 64.473
Train: [3][265/750]	BT 0.191 (1.306)	DT 0.023 (1.148)	loss 10.120 (10.120)	prob 3.389 (3.3890)	GS 29.266 (29.266)	mem 64.474
Train: [3][270/750]	BT 0.098 (1.318)	DT 0.001 (1.161)	loss 10.442 (10.442)	prob 2.823 (2.8229)	GS 30.797 (30.797)	mem 64.421
Train: [3][275/750]	BT 0.142 (1.306)	DT 0.002 (1.149)	loss 10.530 (10.530)	prob 2.908 (2.9075)	GS 28.969 (28.969)	mem 64.378
Train: [3][280/750]	BT 6.662 (1.310)	DT 6.535 (1.152)	loss 10.229 (10.229)	prob 3.003 (3.0030)	GS 31.281 (31.281)	mem 64.664
Train: [3][285/750]	BT 0.135 (1.314)	DT 0.003 (1.157)	loss 9.936 (9.936)	prob 3.441 (3.4410)	GS 27.781 (27.781)	mem 64.539
Train: [3][290/750]	BT 0.161 (1.295)	DT 0.002 (1.137)	loss 10.569 (10.569)	prob 2.103 (2.1034)	GS 34.812 (34.812)	mem 64.677
Train: [3][295/750]	BT 0.114 (1.313)	DT 0.012 (1.156)	loss 10.839 (10.839)	prob 2.137 (2.1368)	GS 33.750 (33.750)	mem 59.646
Train: [3][300/750]	BT 0.141 (1.297)	DT 0.003 (1.141)	loss 10.614 (10.614)	prob 2.200 (2.2003)	GS 35.484 (35.484)	mem 60.075
Train: [3][305/750]	BT 0.177 (1.318)	DT 0.010 (1.161)	loss 10.128 (10.128)	prob 2.466 (2.4661)	GS 34.516 (34.516)	mem 62.612
Train: [3][310/750]	BT 0.151 (1.299)	DT 0.030 (1.142)	loss 10.447 (10.447)	prob 1.550 (1.5502)	GS 39.781 (39.781)	mem 62.792
Train: [3][315/750]	BT 0.210 (1.281)	DT 0.009 (1.124)	loss 9.806 (9.806)	prob 3.348 (3.3479)	GS 31.109 (31.109)	mem 62.923
Train: [3][320/750]	BT 3.637 (1.312)	DT 3.479 (1.154)	loss 10.577 (10.577)	prob 1.840 (1.8402)	GS 32.281 (32.281)	mem 58.653
Train: [3][325/750]	BT 0.242 (1.295)	DT 0.001 (1.137)	loss 10.105 (10.105)	prob 1.278 (1.2775)	GS 34.875 (34.875)	mem 58.900
Train: [3][330/750]	BT 0.208 (1.309)	DT 0.001 (1.152)	loss 10.273 (10.273)	prob 1.765 (1.7649)	GS 31.797 (31.797)	mem 60.870
Train: [3][335/750]	BT 0.166 (1.297)	DT 0.003 (1.140)	loss 10.931 (10.931)	prob 1.765 (1.7646)	GS 31.188 (31.188)	mem 61.563
Train: [3][340/750]	BT 10.711 (1.311)	DT 10.594 (1.154)	loss 10.263 (10.263)	prob 1.652 (1.6521)	GS 34.484 (34.484)	mem 63.823
Train: [3][345/750]	BT 0.226 (1.303)	DT 0.021 (1.146)	loss 10.438 (10.438)	prob 0.954 (0.9541)	GS 32.906 (32.906)	mem 64.342
Train: [3][350/750]	BT 0.228 (1.288)	DT 0.004 (1.130)	loss 10.382 (10.382)	prob 1.772 (1.7715)	GS 35.000 (35.000)	mem 64.481
Train: [3][355/750]	BT 0.098 (1.291)	DT 0.003 (1.133)	loss 10.483 (10.483)	prob 1.390 (1.3904)	GS 33.484 (33.484)	mem 64.631
Train: [3][360/750]	BT 0.160 (1.283)	DT 0.003 (1.125)	loss 9.594 (9.594)	prob 2.630 (2.6297)	GS 34.328 (34.328)	mem 64.593
Train: [3][365/750]	BT 0.200 (1.288)	DT 0.025 (1.131)	loss 10.364 (10.364)	prob 2.376 (2.3760)	GS 31.000 (31.000)	mem 64.611
Train: [3][370/750]	BT 0.137 (1.285)	DT 0.003 (1.127)	loss 10.325 (10.325)	prob 1.694 (1.6942)	GS 32.859 (32.859)	mem 64.611
Train: [3][375/750]	BT 0.114 (1.269)	DT 0.002 (1.112)	loss 10.198 (10.198)	prob 2.050 (2.0500)	GS 31.094 (31.094)	mem 64.666
Train: [3][380/750]	BT 5.201 (1.289)	DT 5.099 (1.132)	loss 10.102 (10.102)	prob 1.814 (1.8140)	GS 33.562 (33.562)	mem 64.576
Train: [3][385/750]	BT 0.171 (1.274)	DT 0.029 (1.117)	loss 10.309 (10.309)	prob 1.805 (1.8047)	GS 32.906 (32.906)	mem 64.693
Train: [3][390/750]	BT 0.207 (1.275)	DT 0.003 (1.118)	loss 10.212 (10.212)	prob 2.036 (2.0356)	GS 33.250 (33.250)	mem 58.740
Train: [3][395/750]	BT 0.096 (1.285)	DT 0.004 (1.128)	loss 10.468 (10.468)	prob 0.294 (0.2935)	GS 30.531 (30.531)	mem 60.458
Train: [3][400/750]	BT 8.493 (1.292)	DT 8.238 (1.135)	loss 10.417 (10.417)	prob 1.571 (1.5713)	GS 36.891 (36.891)	mem 62.173
Train: [3][405/750]	BT 0.105 (1.284)	DT 0.006 (1.127)	loss 10.536 (10.536)	prob 0.932 (0.9317)	GS 31.203 (31.203)	mem 62.695
Train: [3][410/750]	BT 0.096 (1.270)	DT 0.004 (1.114)	loss 10.239 (10.239)	prob 1.219 (1.2190)	GS 31.875 (31.875)	mem 63.065
Train: [3][415/750]	BT 0.169 (1.280)	DT 0.002 (1.124)	loss 10.252 (10.252)	prob 2.345 (2.3446)	GS 27.891 (27.891)	mem 59.232
Train: [3][420/750]	BT 0.196 (1.268)	DT 0.013 (1.113)	loss 10.200 (10.200)	prob 1.564 (1.5643)	GS 32.938 (32.938)	mem 58.296
Train: [3][425/750]	BT 0.079 (1.287)	DT 0.001 (1.132)	loss 9.913 (9.913)	prob 2.275 (2.2750)	GS 35.844 (35.844)	mem 60.727
Train: [3][430/750]	BT 3.831 (1.283)	DT 3.719 (1.128)	loss 10.272 (10.272)	prob 2.084 (2.0838)	GS 34.844 (34.844)	mem 61.856
Train: [3][435/750]	BT 0.096 (1.270)	DT 0.001 (1.115)	loss 10.046 (10.046)	prob 1.796 (1.7961)	GS 32.578 (32.578)	mem 62.036
Train: [3][440/750]	BT 0.088 (1.277)	DT 0.007 (1.122)	loss 9.863 (9.863)	prob 1.519 (1.5194)	GS 33.031 (33.031)	mem 63.586
Train: [3][445/750]	BT 0.205 (1.279)	DT 0.005 (1.124)	loss 10.138 (10.138)	prob 1.597 (1.5965)	GS 31.875 (31.875)	mem 64.475
Train: [3][450/750]	BT 0.114 (1.275)	DT 0.004 (1.119)	loss 10.134 (10.134)	prob 0.830 (0.8303)	GS 34.031 (34.031)	mem 64.491
Train: [3][455/750]	BT 0.216 (1.288)	DT 0.016 (1.132)	loss 10.267 (10.267)	prob 1.037 (1.0371)	GS 33.266 (33.266)	mem 64.481
Train: [3][460/750]	BT 1.931 (1.280)	DT 1.663 (1.123)	loss 10.327 (10.327)	prob 0.858 (0.8584)	GS 32.500 (32.500)	mem 64.624
Train: [3][465/750]	BT 0.135 (1.268)	DT 0.001 (1.111)	loss 9.866 (9.866)	prob 2.244 (2.2436)	GS 31.562 (31.562)	mem 64.460
Train: [3][470/750]	BT 0.172 (1.279)	DT 0.002 (1.122)	loss 10.568 (10.568)	prob 1.114 (1.1137)	GS 38.078 (38.078)	mem 64.525
Train: [3][475/750]	BT 0.192 (1.276)	DT 0.005 (1.119)	loss 10.376 (10.376)	prob 1.204 (1.2041)	GS 41.375 (41.375)	mem 64.495
Train: [3][480/750]	BT 0.195 (1.289)	DT 0.005 (1.132)	loss 10.199 (10.199)	prob 1.925 (1.9249)	GS 34.047 (34.047)	mem 58.728
Train: [3][485/750]	BT 0.196 (1.285)	DT 0.001 (1.128)	loss 10.468 (10.468)	prob 1.533 (1.5328)	GS 28.547 (28.547)	mem 59.562
Train: [3][490/750]	BT 9.167 (1.292)	DT 8.972 (1.134)	loss 10.073 (10.073)	prob 1.519 (1.5188)	GS 34.578 (34.578)	mem 61.226
Train: [3][495/750]	BT 0.135 (1.280)	DT 0.001 (1.123)	loss 9.941 (9.941)	prob 1.265 (1.2646)	GS 35.125 (35.125)	mem 61.372
Train: [3][500/750]	BT 0.124 (1.274)	DT 0.005 (1.117)	loss 10.216 (10.216)	prob 2.085 (2.0847)	GS 31.016 (31.016)	mem 61.975
Train: [3][505/750]	BT 0.132 (1.284)	DT 0.004 (1.128)	loss 9.558 (9.558)	prob 1.831 (1.8309)	GS 32.594 (32.594)	mem 63.831
Train: [3][510/750]	BT 0.225 (1.277)	DT 0.059 (1.121)	loss 9.788 (9.788)	prob 2.738 (2.7383)	GS 36.281 (36.281)	mem 63.611
Train: [3][515/750]	BT 0.173 (1.287)	DT 0.015 (1.130)	loss 9.784 (9.784)	prob 3.003 (3.0028)	GS 29.312 (29.312)	mem 60.091
Train: [3][520/750]	BT 0.213 (1.276)	DT 0.043 (1.119)	loss 10.245 (10.245)	prob 2.041 (2.0406)	GS 29.297 (29.297)	mem 60.376
Train: [3][525/750]	BT 0.162 (1.265)	DT 0.024 (1.109)	loss 9.995 (9.995)	prob 2.435 (2.4355)	GS 32.641 (32.641)	mem 60.388
Train: [3][530/750]	BT 0.176 (1.278)	DT 0.002 (1.121)	loss 10.446 (10.446)	prob 1.829 (1.8285)	GS 38.781 (38.781)	mem 63.088
Train: [3][535/750]	BT 0.153 (1.271)	DT 0.007 (1.115)	loss 10.009 (10.009)	prob 3.060 (3.0601)	GS 28.234 (28.234)	mem 63.771
Train: [3][540/750]	BT 0.291 (1.281)	DT 0.007 (1.124)	loss 10.094 (10.094)	prob 2.776 (2.7763)	GS 29.531 (29.531)	mem 64.441
Train: [3][545/750]	BT 0.093 (1.276)	DT 0.002 (1.119)	loss 10.385 (10.385)	prob 2.171 (2.1708)	GS 34.031 (34.031)	mem 64.538
Train: [3][550/750]	BT 7.689 (1.280)	DT 7.550 (1.123)	loss 9.545 (9.545)	prob 3.108 (3.1085)	GS 33.859 (33.859)	mem 64.666
Train: [3][555/750]	BT 0.164 (1.270)	DT 0.018 (1.113)	loss 10.469 (10.469)	prob 1.427 (1.4274)	GS 32.469 (32.469)	mem 64.696
Train: [3][560/750]	BT 0.256 (1.276)	DT 0.030 (1.120)	loss 10.056 (10.056)	prob 2.342 (2.3418)	GS 32.500 (32.500)	mem 64.649
Train: [3][565/750]	BT 0.212 (1.272)	DT 0.023 (1.115)	loss 10.467 (10.467)	prob 3.065 (3.0650)	GS 33.688 (33.688)	mem 64.656
Train: [3][570/750]	BT 0.109 (1.275)	DT 0.002 (1.117)	loss 9.485 (9.485)	prob 3.002 (3.0019)	GS 35.609 (35.609)	mem 58.183
Train: [3][575/750]	BT 0.138 (1.279)	DT 0.002 (1.122)	loss 9.794 (9.794)	prob 2.394 (2.3935)	GS 32.375 (32.375)	mem 59.807
Train: [3][580/750]	BT 4.163 (1.276)	DT 4.047 (1.119)	loss 9.704 (9.704)	prob 2.276 (2.2756)	GS 31.859 (31.859)	mem 60.477
Train: [3][585/750]	BT 0.143 (1.267)	DT 0.014 (1.110)	loss 9.736 (9.736)	prob 2.395 (2.3949)	GS 31.359 (31.359)	mem 60.659
Train: [3][590/750]	BT 0.092 (1.274)	DT 0.003 (1.117)	loss 10.349 (10.349)	prob 2.068 (2.0679)	GS 36.391 (36.391)	mem 62.778
Train: [3][595/750]	BT 0.191 (1.268)	DT 0.010 (1.112)	loss 10.234 (10.234)	prob 1.915 (1.9152)	GS 31.594 (31.594)	mem 63.237
Train: [3][600/750]	BT 0.096 (1.285)	DT 0.011 (1.129)	loss 9.838 (9.838)	prob 1.652 (1.6521)	GS 31.359 (31.359)	mem 59.386
Train: [3][605/750]	BT 0.232 (1.275)	DT 0.009 (1.119)	loss 9.877 (9.877)	prob 2.855 (2.8549)	GS 33.375 (33.375)	mem 59.874
Train: [3][610/750]	BT 12.700 (1.286)	DT 12.550 (1.131)	loss 10.316 (10.316)	prob 2.045 (2.0450)	GS 31.891 (31.891)	mem 62.182
Train: [3][615/750]	BT 0.232 (1.277)	DT 0.001 (1.122)	loss 9.930 (9.930)	prob 1.782 (1.7818)	GS 26.875 (26.875)	mem 62.403
Train: [3][620/750]	BT 0.084 (1.267)	DT 0.002 (1.113)	loss 10.339 (10.339)	prob 0.375 (0.3752)	GS 30.281 (30.281)	mem 62.637
Train: [3][625/750]	BT 0.152 (1.275)	DT 0.009 (1.121)	loss 9.430 (9.430)	prob 1.824 (1.8239)	GS 28.312 (28.312)	mem 64.636
Train: [3][630/750]	BT 0.154 (1.267)	DT 0.001 (1.112)	loss 10.219 (10.219)	prob 0.734 (0.7343)	GS 34.109 (34.109)	mem 64.511
Train: [3][635/750]	BT 0.113 (1.275)	DT 0.003 (1.121)	loss 10.063 (10.063)	prob 0.474 (0.4738)	GS 29.516 (29.516)	mem 64.652
Train: [3][640/750]	BT 0.689 (1.267)	DT 0.572 (1.113)	loss 9.971 (9.971)	prob 1.416 (1.4156)	GS 32.641 (32.641)	mem 64.566
Train: [3][645/750]	BT 0.225 (1.258)	DT 0.016 (1.104)	loss 10.043 (10.043)	prob 0.693 (0.6934)	GS 24.453 (24.453)	mem 64.569
Train: [3][650/750]	BT 0.138 (1.272)	DT 0.001 (1.118)	loss 9.787 (9.787)	prob 1.766 (1.7659)	GS 32.547 (32.547)	mem 64.489
Train: [3][655/750]	BT 0.177 (1.264)	DT 0.006 (1.110)	loss 9.738 (9.738)	prob 2.429 (2.4290)	GS 33.750 (33.750)	mem 64.515
Train: [3][660/750]	BT 0.073 (1.273)	DT 0.002 (1.120)	loss 10.097 (10.097)	prob 1.413 (1.4131)	GS 30.469 (30.469)	mem 57.942
Train: [3][665/750]	BT 0.181 (1.265)	DT 0.019 (1.111)	loss 10.562 (10.562)	prob 0.730 (0.7295)	GS 34.422 (34.422)	mem 58.128
Train: [3][670/750]	BT 13.965 (1.277)	DT 13.860 (1.124)	loss 10.128 (10.128)	prob 0.238 (0.2377)	GS 40.391 (40.391)	mem 60.756
Train: [3][675/750]	BT 0.127 (1.269)	DT 0.003 (1.116)	loss 10.097 (10.097)	prob 1.502 (1.5021)	GS 30.422 (30.422)	mem 60.931
Train: [3][680/750]	BT 0.111 (1.261)	DT 0.006 (1.107)	loss 10.542 (10.542)	prob 1.494 (1.4943)	GS 33.797 (33.797)	mem 61.180
Train: [3][685/750]	BT 0.141 (1.272)	DT 0.007 (1.120)	loss 10.358 (10.358)	prob 1.721 (1.7205)	GS 30.094 (30.094)	mem 63.721
Train: [3][690/750]	BT 0.103 (1.264)	DT 0.003 (1.111)	loss 9.981 (9.981)	prob 1.720 (1.7198)	GS 33.828 (33.828)	mem 63.728
Train: [3][695/750]	BT 0.080 (1.275)	DT 0.001 (1.122)	loss 10.395 (10.395)	prob 1.765 (1.7651)	GS 30.312 (30.312)	mem 59.798
Train: [3][700/750]	BT 0.176 (1.267)	DT 0.009 (1.115)	loss 9.820 (9.820)	prob 1.659 (1.6593)	GS 30.016 (30.016)	mem 59.973
Train: [3][705/750]	BT 0.203 (1.259)	DT 0.006 (1.107)	loss 10.123 (10.123)	prob 1.843 (1.8435)	GS 34.203 (34.203)	mem 60.238
Train: [3][710/750]	BT 0.114 (1.270)	DT 0.001 (1.119)	loss 10.005 (10.005)	prob 1.518 (1.5180)	GS 34.156 (34.156)	mem 63.563
Train: [3][715/750]	BT 0.224 (1.262)	DT 0.002 (1.111)	loss 9.613 (9.613)	prob 2.697 (2.6974)	GS 27.594 (27.594)	mem 64.130
Train: [3][720/750]	BT 0.182 (1.267)	DT 0.005 (1.115)	loss 10.209 (10.209)	prob 1.534 (1.5340)	GS 32.922 (32.922)	mem 64.717
Train: [3][725/750]	BT 0.157 (1.259)	DT 0.003 (1.107)	loss 9.790 (9.790)	prob 1.859 (1.8586)	GS 31.062 (31.062)	mem 64.563
Train: [3][730/750]	BT 12.575 (1.269)	DT 12.478 (1.117)	loss 10.364 (10.364)	prob 1.095 (1.0953)	GS 34.766 (34.766)	mem 63.989
Train: [3][735/750]	BT 0.092 (1.261)	DT 0.003 (1.109)	loss 9.894 (9.894)	prob 0.965 (0.9650)	GS 28.281 (28.281)	mem 63.996
Train: [3][740/750]	BT 0.091 (1.253)	DT 0.002 (1.101)	loss 9.995 (9.995)	prob 1.017 (1.0174)	GS 30.609 (30.609)	mem 63.999
Train: [3][745/750]	BT 0.096 (1.254)	DT 0.001 (1.103)	loss 9.908 (9.908)	prob 1.184 (1.1844)	GS 28.438 (28.438)	mem 32.205
Train: [3][750/750]	BT 0.115 (1.246)	DT 0.001 (1.096)	loss 9.923 (9.923)	prob 2.194 (2.1939)	GS 34.156 (34.156)	mem 32.211
Train: [3][755/750]	BT 0.093 (1.242)	DT 0.002 (1.092)	loss 10.239 (10.239)	prob 2.159 (2.1593)	GS 33.750 (33.750)	mem 25.410
epoch 3, total time 937.82
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [4][1/750]	BT 24.728 (24.728)	DT 24.486 (24.486)	loss 10.228 (10.228)	prob 2.041 (2.0411)	GS 29.266 (29.266)	mem 62.394
Train: [4][5/750]	BT 0.210 (5.459)	DT 0.007 (5.252)	loss 9.918 (9.918)	prob 2.347 (2.3468)	GS 30.656 (30.656)	mem 59.565
Train: [4][10/750]	BT 0.094 (2.905)	DT 0.002 (2.721)	loss 9.676 (9.676)	prob 1.690 (1.6900)	GS 33.391 (33.391)	mem 56.823
Train: [4][15/750]	BT 0.251 (2.734)	DT 0.013 (2.553)	loss 9.251 (9.251)	prob 1.904 (1.9036)	GS 25.922 (25.922)	mem 59.283
Train: [4][20/750]	BT 0.110 (2.325)	DT 0.002 (2.148)	loss 10.116 (10.116)	prob 0.394 (0.3941)	GS 35.891 (35.891)	mem 60.244
Train: [4][25/750]	BT 0.376 (1.901)	DT 0.094 (1.723)	loss 10.075 (10.075)	prob 1.389 (1.3887)	GS 32.859 (32.859)	mem 60.597
Train: [4][30/750]	BT 0.176 (2.136)	DT 0.016 (1.965)	loss 9.708 (9.708)	prob 1.142 (1.1421)	GS 32.438 (32.438)	mem 63.351
Train: [4][35/750]	BT 0.089 (1.847)	DT 0.002 (1.685)	loss 9.738 (9.738)	prob 0.616 (0.6158)	GS 26.906 (26.906)	mem 63.499
Train: [4][40/750]	BT 12.021 (2.080)	DT 11.921 (1.913)	loss 9.177 (9.177)	prob 1.534 (1.5336)	GS 30.812 (30.812)	mem 63.636
Train: [4][45/750]	BT 0.167 (1.869)	DT 0.003 (1.701)	loss 9.694 (9.694)	prob 0.954 (0.9538)	GS 37.891 (37.891)	mem 63.577
Train: [4][50/750]	BT 1.767 (1.726)	DT 1.564 (1.563)	loss 9.498 (9.498)	prob 1.070 (1.0697)	GS 30.766 (30.766)	mem 63.594
Train: [4][55/750]	BT 0.188 (1.776)	DT 0.013 (1.612)	loss 10.132 (10.132)	prob 1.143 (1.1428)	GS 30.328 (30.328)	mem 63.720
Train: [4][60/750]	BT 0.205 (1.643)	DT 0.004 (1.478)	loss 9.925 (9.925)	prob 1.611 (1.6107)	GS 35.141 (35.141)	mem 63.647
Train: [4][65/750]	BT 0.162 (1.727)	DT 0.009 (1.559)	loss 10.434 (10.434)	prob 1.108 (1.1084)	GS 31.312 (31.312)	mem 57.250
Train: [4][70/750]	BT 0.157 (1.614)	DT 0.002 (1.448)	loss 9.768 (9.768)	prob 1.736 (1.7358)	GS 34.281 (34.281)	mem 57.395
Train: [4][75/750]	BT 0.168 (1.567)	DT 0.001 (1.402)	loss 10.260 (10.260)	prob 1.258 (1.2579)	GS 29.516 (29.516)	mem 58.152
Train: [4][80/750]	BT 0.086 (1.598)	DT 0.002 (1.438)	loss 9.233 (9.233)	prob 1.759 (1.7588)	GS 36.094 (36.094)	mem 60.239
Train: [4][85/750]	BT 0.123 (1.513)	DT 0.004 (1.354)	loss 9.883 (9.883)	prob 1.257 (1.2574)	GS 28.891 (28.891)	mem 60.397
Train: [4][90/750]	BT 0.104 (1.595)	DT 0.005 (1.438)	loss 9.598 (9.598)	prob 0.941 (0.9409)	GS 32.938 (32.938)	mem 63.002
Train: [4][95/750]	BT 0.172 (1.519)	DT 0.002 (1.363)	loss 9.114 (9.114)	prob 2.143 (2.1426)	GS 28.016 (28.016)	mem 62.933
Train: [4][100/750]	BT 17.889 (1.628)	DT 17.778 (1.473)	loss 9.485 (9.485)	prob 1.328 (1.3276)	GS 36.328 (36.328)	mem 59.975
Train: [4][105/750]	BT 0.119 (1.556)	DT 0.001 (1.403)	loss 10.171 (10.171)	prob 0.390 (0.3902)	GS 32.547 (32.547)	mem 60.090
Train: [4][110/750]	BT 0.141 (1.491)	DT 0.008 (1.340)	loss 9.622 (9.622)	prob 0.730 (0.7300)	GS 38.781 (38.781)	mem 60.217
Train: [4][115/750]	BT 0.068 (1.570)	DT 0.001 (1.421)	loss 9.545 (9.545)	prob 0.194 (0.1941)	GS 30.625 (30.625)	mem 63.859
Train: [4][120/750]	BT 0.212 (1.510)	DT 0.002 (1.362)	loss 9.875 (9.875)	prob 0.085 (0.0850)	GS 33.031 (33.031)	mem 63.970
Train: [4][125/750]	BT 0.162 (1.534)	DT 0.012 (1.383)	loss 9.153 (9.153)	prob 2.023 (2.0227)	GS 30.438 (30.438)	mem 64.081
Train: [4][130/750]	BT 0.176 (1.481)	DT 0.007 (1.330)	loss 9.335 (9.335)	prob 1.058 (1.0584)	GS 31.828 (31.828)	mem 64.211
Train: [4][135/750]	BT 0.150 (1.432)	DT 0.002 (1.281)	loss 9.352 (9.352)	prob 2.565 (2.5646)	GS 28.234 (28.234)	mem 64.134
Train: [4][140/750]	BT 0.155 (1.494)	DT 0.001 (1.345)	loss 8.875 (8.875)	prob 2.063 (2.0629)	GS 34.734 (34.734)	mem 64.158
Train: [4][145/750]	BT 0.132 (1.447)	DT 0.007 (1.299)	loss 10.156 (10.156)	prob 0.457 (0.4569)	GS 29.234 (29.234)	mem 64.163
Train: [4][150/750]	BT 0.141 (1.480)	DT 0.001 (1.332)	loss 10.445 (10.445)	prob -0.664 (-0.6639)	GS 33.828 (33.828)	mem 58.019
Train: [4][155/750]	BT 0.189 (1.436)	DT 0.005 (1.289)	loss 9.859 (9.859)	prob 0.557 (0.5568)	GS 28.047 (28.047)	mem 57.634
Train: [4][160/750]	BT 13.670 (1.480)	DT 13.543 (1.333)	loss 8.700 (8.700)	prob 0.882 (0.8823)	GS 29.906 (29.906)	mem 60.264
Train: [4][165/750]	BT 0.186 (1.439)	DT 0.015 (1.293)	loss 9.976 (9.976)	prob -0.239 (-0.2389)	GS 32.484 (32.484)	mem 60.449
Train: [4][170/750]	BT 0.095 (1.401)	DT 0.004 (1.255)	loss 9.442 (9.442)	prob 0.595 (0.5951)	GS 34.953 (34.953)	mem 60.603
Train: [4][175/750]	BT 0.090 (1.435)	DT 0.002 (1.291)	loss 9.574 (9.574)	prob 0.834 (0.8339)	GS 32.328 (32.328)	mem 63.140
Train: [4][180/750]	BT 0.121 (1.400)	DT 0.004 (1.255)	loss 9.757 (9.757)	prob 0.706 (0.7064)	GS 33.922 (33.922)	mem 63.292
Train: [4][185/750]	BT 0.083 (1.424)	DT 0.002 (1.280)	loss 9.524 (9.524)	prob -0.064 (-0.0644)	GS 28.938 (28.938)	mem 58.581
Train: [4][190/750]	BT 0.222 (1.391)	DT 0.004 (1.246)	loss 9.602 (9.602)	prob -0.181 (-0.1815)	GS 30.688 (30.688)	mem 58.761
Train: [4][195/750]	BT 0.179 (1.359)	DT 0.010 (1.215)	loss 9.881 (9.881)	prob 0.775 (0.7753)	GS 28.953 (28.953)	mem 58.847
Train: [4][200/750]	BT 0.089 (1.410)	DT 0.001 (1.266)	loss 9.692 (9.692)	prob 0.594 (0.5939)	GS 35.750 (35.750)	mem 62.559
Train: [4][205/750]	BT 0.211 (1.379)	DT 0.016 (1.236)	loss 9.372 (9.372)	prob 1.060 (1.0600)	GS 26.844 (26.844)	mem 62.883
Train: [4][210/750]	BT 0.205 (1.420)	DT 0.008 (1.277)	loss 8.950 (8.950)	prob 1.303 (1.3033)	GS 30.859 (30.859)	mem 64.423
Train: [4][215/750]	BT 0.111 (1.391)	DT 0.002 (1.248)	loss 9.303 (9.303)	prob 0.405 (0.4047)	GS 28.938 (28.938)	mem 64.426
Train: [4][220/750]	BT 11.294 (1.413)	DT 11.163 (1.270)	loss 9.354 (9.354)	prob 0.070 (0.0698)	GS 34.266 (34.266)	mem 64.442
Train: [4][225/750]	BT 0.128 (1.386)	DT 0.003 (1.242)	loss 9.163 (9.163)	prob 0.056 (0.0558)	GS 36.688 (36.688)	mem 64.431
Train: [4][230/750]	BT 0.178 (1.360)	DT 0.002 (1.215)	loss 9.780 (9.780)	prob -0.064 (-0.0645)	GS 34.812 (34.812)	mem 64.573
Train: [4][235/750]	BT 0.121 (1.390)	DT 0.003 (1.246)	loss 9.590 (9.590)	prob -0.665 (-0.6646)	GS 35.594 (35.594)	mem 64.473
Train: [4][240/750]	BT 0.136 (1.364)	DT 0.004 (1.220)	loss 9.484 (9.484)	prob 0.051 (0.0511)	GS 33.375 (33.375)	mem 64.522
Train: [4][245/750]	BT 0.166 (1.390)	DT 0.004 (1.245)	loss 9.489 (9.489)	prob 0.202 (0.2024)	GS 28.984 (28.984)	mem 58.812
Train: [4][250/750]	BT 0.320 (1.366)	DT 0.017 (1.221)	loss 9.661 (9.661)	prob 0.476 (0.4765)	GS 36.578 (36.578)	mem 58.976
Train: [4][255/750]	BT 0.122 (1.342)	DT 0.003 (1.197)	loss 9.605 (9.605)	prob 0.323 (0.3225)	GS 46.469 (46.469)	mem 59.171
Train: [4][260/750]	BT 0.151 (1.363)	DT 0.002 (1.218)	loss 8.888 (8.888)	prob 0.390 (0.3901)	GS 38.297 (38.297)	mem 61.288
Train: [4][265/750]	BT 0.338 (1.340)	DT 0.005 (1.195)	loss 8.991 (8.991)	prob 1.660 (1.6605)	GS 32.438 (32.438)	mem 61.420
Train: [4][270/750]	BT 0.096 (1.357)	DT 0.009 (1.213)	loss 9.052 (9.052)	prob 0.939 (0.9395)	GS 36.094 (36.094)	mem 63.213
Train: [4][275/750]	BT 0.261 (1.336)	DT 0.002 (1.191)	loss 9.219 (9.219)	prob 0.179 (0.1787)	GS 28.688 (28.688)	mem 63.293
Train: [4][280/750]	BT 10.828 (1.352)	DT 10.603 (1.208)	loss 8.842 (8.842)	prob 0.876 (0.8758)	GS 37.391 (37.391)	mem 58.525
Train: [4][285/750]	BT 0.128 (1.331)	DT 0.010 (1.187)	loss 9.558 (9.558)	prob -0.347 (-0.3469)	GS 34.906 (34.906)	mem 58.761
Train: [4][290/750]	BT 0.086 (1.326)	DT 0.002 (1.182)	loss 9.396 (9.396)	prob 0.051 (0.0514)	GS 31.156 (31.156)	mem 59.590
Train: [4][295/750]	BT 0.148 (1.332)	DT 0.001 (1.188)	loss 9.559 (9.559)	prob -0.436 (-0.4358)	GS 31.906 (31.906)	mem 60.976
Train: [4][300/750]	BT 1.550 (1.327)	DT 1.392 (1.183)	loss 9.125 (9.125)	prob 0.369 (0.3686)	GS 37.547 (37.547)	mem 62.165
Train: [4][305/750]	BT 0.252 (1.333)	DT 0.027 (1.189)	loss 9.279 (9.279)	prob 0.939 (0.9389)	GS 26.391 (26.391)	mem 63.813
Train: [4][310/750]	BT 0.142 (1.339)	DT 0.005 (1.194)	loss 9.379 (9.379)	prob -0.883 (-0.8831)	GS 35.594 (35.594)	mem 64.574
Train: [4][315/750]	BT 0.187 (1.320)	DT 0.001 (1.176)	loss 9.071 (9.071)	prob -0.288 (-0.2883)	GS 29.047 (29.047)	mem 64.523
Train: [4][320/750]	BT 1.941 (1.340)	DT 1.806 (1.195)	loss 9.692 (9.692)	prob -0.475 (-0.4747)	GS 31.844 (31.844)	mem 64.499
Train: [4][325/750]	BT 0.158 (1.322)	DT 0.012 (1.177)	loss 9.669 (9.669)	prob -0.804 (-0.8038)	GS 32.688 (32.688)	mem 64.805
Train: [4][330/750]	BT 5.142 (1.332)	DT 4.968 (1.186)	loss 9.734 (9.734)	prob 0.551 (0.5513)	GS 30.094 (30.094)	mem 64.550
Train: [4][335/750]	BT 0.142 (1.324)	DT 0.002 (1.177)	loss 9.005 (9.005)	prob 0.706 (0.7063)	GS 30.953 (30.953)	mem 64.437
Train: [4][340/750]	BT 4.098 (1.319)	DT 3.984 (1.172)	loss 9.095 (9.095)	prob 0.657 (0.6567)	GS 34.594 (34.594)	mem 64.484
Train: [4][345/750]	BT 0.143 (1.335)	DT 0.002 (1.187)	loss nan (nan)	prob nan (nan)	GS 30.797 (30.797)	mem 58.658
Train: [4][350/750]	BT 0.139 (1.318)	DT 0.007 (1.171)	loss nan (nan)	prob nan (nan)	GS 32.516 (32.516)	mem 58.793
Train: [4][355/750]	BT 0.102 (1.321)	DT 0.001 (1.174)	loss nan (nan)	prob nan (nan)	GS 30.062 (30.062)	mem 60.136
Train: [4][360/750]	BT 0.141 (1.324)	DT 0.007 (1.177)	loss nan (nan)	prob nan (nan)	GS 34.109 (34.109)	mem 61.617
Train: [4][365/750]	BT 0.126 (1.316)	DT 0.016 (1.169)	loss nan (nan)	prob nan (nan)	GS 27.703 (27.703)	mem 62.154
Train: [4][370/750]	BT 0.106 (1.325)	DT 0.002 (1.178)	loss nan (nan)	prob nan (nan)	GS 33.625 (33.625)	mem 63.734
Train: [4][375/750]	BT 0.089 (1.312)	DT 0.002 (1.166)	loss nan (nan)	prob nan (nan)	GS 34.109 (34.109)	mem 63.626
Train: [4][380/750]	BT 7.137 (1.333)	DT 7.036 (1.187)	loss nan (nan)	prob nan (nan)	GS 30.703 (30.703)	mem 60.448
Train: [4][385/750]	BT 0.089 (1.317)	DT 0.004 (1.172)	loss nan (nan)	prob nan (nan)	GS 30.188 (30.188)	mem 60.457
Train: [4][390/750]	BT 0.116 (1.311)	DT 0.020 (1.166)	loss nan (nan)	prob nan (nan)	GS 35.875 (35.875)	mem 61.519
Train: [4][395/750]	BT 0.158 (1.317)	DT 0.010 (1.172)	loss nan (nan)	prob nan (nan)	GS 33.094 (33.094)	mem 63.326
Train: [4][400/750]	BT 5.429 (1.318)	DT 5.313 (1.173)	loss nan (nan)	prob nan (nan)	GS 33.344 (33.344)	mem 64.449
Train: [4][405/750]	BT 0.107 (1.320)	DT 0.001 (1.175)	loss nan (nan)	prob nan (nan)	GS 29.078 (29.078)	mem 64.574
Train: [4][410/750]	BT 0.203 (1.306)	DT 0.004 (1.161)	loss nan (nan)	prob nan (nan)	GS 35.750 (35.750)	mem 64.576
Train: [4][415/750]	BT 0.303 (1.312)	DT 0.018 (1.166)	loss nan (nan)	prob nan (nan)	GS 35.516 (35.516)	mem 64.582
Train: [4][420/750]	BT 0.251 (1.309)	DT 0.006 (1.163)	loss nan (nan)	prob nan (nan)	GS 31.484 (31.484)	mem 64.533
Train: [4][425/750]	BT 0.173 (1.313)	DT 0.002 (1.166)	loss nan (nan)	prob nan (nan)	GS 34.969 (34.969)	mem 64.550
Train: [4][430/750]	BT 0.313 (1.304)	DT 0.146 (1.157)	loss nan (nan)	prob nan (nan)	GS 32.719 (32.719)	mem 64.582
Train: [4][435/750]	BT 0.215 (1.293)	DT 0.008 (1.145)	loss nan (nan)	prob nan (nan)	GS 33.531 (33.531)	mem 64.626
Train: [4][440/750]	BT 0.100 (1.307)	DT 0.002 (1.159)	loss nan (nan)	prob nan (nan)	GS 34.891 (34.891)	mem 58.477
Train: [4][445/750]	BT 0.191 (1.299)	DT 0.020 (1.151)	loss nan (nan)	prob nan (nan)	GS 31.656 (31.656)	mem 58.875
Train: [4][450/750]	BT 0.141 (1.307)	DT 0.001 (1.159)	loss nan (nan)	prob nan (nan)	GS 32.203 (32.203)	mem 60.785
Train: [4][455/750]	BT 0.149 (1.299)	DT 0.003 (1.152)	loss nan (nan)	prob nan (nan)	GS 31.328 (31.328)	mem 61.481
Train: [4][460/750]	BT 3.646 (1.298)	DT 3.561 (1.151)	loss nan (nan)	prob nan (nan)	GS 28.328 (28.328)	mem 62.440
Train: [4][465/750]	BT 0.122 (1.297)	DT 0.002 (1.150)	loss nan (nan)	prob nan (nan)	GS 33.328 (33.328)	mem 63.140
Train: [4][470/750]	BT 0.139 (1.302)	DT 0.016 (1.154)	loss nan (nan)	prob nan (nan)	GS 34.469 (34.469)	mem 59.354
Train: [4][475/750]	BT 0.092 (1.290)	DT 0.010 (1.144)	loss nan (nan)	prob nan (nan)	GS 39.812 (39.812)	mem 58.046
Train: [4][480/750]	BT 6.678 (1.307)	DT 6.554 (1.160)	loss nan (nan)	prob nan (nan)	GS 33.266 (33.266)	mem 60.721
Train: [4][485/750]	BT 0.172 (1.295)	DT 0.006 (1.148)	loss nan (nan)	prob nan (nan)	GS 31.547 (31.547)	mem 60.797
Train: [4][490/750]	BT 0.333 (1.294)	DT 0.004 (1.147)	loss nan (nan)	prob nan (nan)	GS 32.422 (32.422)	mem 62.189
Train: [4][495/750]	BT 0.180 (1.300)	DT 0.008 (1.153)	loss nan (nan)	prob nan (nan)	GS 33.516 (33.516)	mem 64.064
Train: [4][500/750]	BT 11.381 (1.311)	DT 11.292 (1.164)	loss nan (nan)	prob nan (nan)	GS 36.375 (36.375)	mem 64.426
Train: [4][505/750]	BT 0.150 (1.304)	DT 0.001 (1.157)	loss nan (nan)	prob nan (nan)	GS 29.797 (29.797)	mem 64.480
Train: [4][510/750]	BT 0.199 (1.292)	DT 0.002 (1.146)	loss nan (nan)	prob nan (nan)	GS 35.531 (35.531)	mem 64.480
Train: [4][515/750]	BT 0.139 (1.299)	DT 0.003 (1.151)	loss nan (nan)	prob nan (nan)	GS 27.656 (27.656)	mem 64.587
Train: [4][520/750]	BT 0.254 (1.296)	DT 0.003 (1.149)	loss nan (nan)	prob nan (nan)	GS 32.828 (32.828)	mem 64.697
Train: [4][525/750]	BT 0.285 (1.306)	DT 0.002 (1.158)	loss nan (nan)	prob nan (nan)	GS 31.484 (31.484)	mem 64.831
Train: [4][530/750]	BT 0.132 (1.296)	DT 0.002 (1.147)	loss nan (nan)	prob nan (nan)	GS 32.281 (32.281)	mem 64.509
Train: [4][535/750]	BT 0.269 (1.286)	DT 0.019 (1.136)	loss nan (nan)	prob nan (nan)	GS 34.531 (34.531)	mem 64.511
Train: [4][540/750]	BT 0.117 (1.301)	DT 0.009 (1.151)	loss nan (nan)	prob nan (nan)	GS 32.938 (32.938)	mem 59.875
Train: [4][545/750]	BT 0.319 (1.290)	DT 0.024 (1.141)	loss nan (nan)	prob nan (nan)	GS 30.891 (30.891)	mem 59.964
Train: [4][550/750]	BT 0.086 (1.304)	DT 0.005 (1.155)	loss nan (nan)	prob nan (nan)	GS 31.469 (31.469)	mem 62.653
Train: [4][555/750]	BT 0.208 (1.293)	DT 0.014 (1.144)	loss nan (nan)	prob nan (nan)	GS 30.406 (30.406)	mem 62.713
Train: [4][560/750]	BT 16.469 (1.312)	DT 16.359 (1.163)	loss nan (nan)	prob nan (nan)	GS 34.438 (34.438)	mem 59.006
Train: [4][565/750]	BT 0.121 (1.302)	DT 0.005 (1.153)	loss nan (nan)	prob nan (nan)	GS 26.000 (26.000)	mem 59.168
Train: [4][570/750]	BT 0.151 (1.292)	DT 0.011 (1.143)	loss nan (nan)	prob nan (nan)	GS 30.781 (30.781)	mem 59.368
Train: [4][575/750]	BT 0.164 (1.300)	DT 0.003 (1.152)	loss nan (nan)	prob nan (nan)	GS 32.859 (32.859)	mem 61.648
Train: [4][580/750]	BT 0.158 (1.290)	DT 0.002 (1.142)	loss nan (nan)	prob nan (nan)	GS 37.594 (37.594)	mem 61.772
Train: [4][585/750]	BT 0.113 (1.300)	DT 0.002 (1.153)	loss nan (nan)	prob nan (nan)	GS 28.766 (28.766)	mem 64.080
Train: [4][590/750]	BT 0.112 (1.290)	DT 0.002 (1.143)	loss nan (nan)	prob nan (nan)	GS 30.422 (30.422)	mem 64.231
Train: [4][595/750]	BT 0.259 (1.281)	DT 0.011 (1.133)	loss nan (nan)	prob nan (nan)	GS 31.422 (31.422)	mem 64.368
Train: [4][600/750]	BT 0.141 (1.294)	DT 0.025 (1.146)	loss nan (nan)	prob nan (nan)	GS 32.719 (32.719)	mem 64.583
Train: [4][605/750]	BT 0.173 (1.284)	DT 0.005 (1.137)	loss nan (nan)	prob nan (nan)	GS 30.094 (30.094)	mem 64.438
Train: [4][610/750]	BT 0.803 (1.295)	DT 0.694 (1.147)	loss nan (nan)	prob nan (nan)	GS 35.312 (35.312)	mem 64.412
Train: [4][615/750]	BT 0.160 (1.286)	DT 0.006 (1.138)	loss nan (nan)	prob nan (nan)	GS 26.531 (26.531)	mem 64.416
Train: [4][620/750]	BT 13.221 (1.298)	DT 13.118 (1.150)	loss nan (nan)	prob nan (nan)	GS 34.703 (34.703)	mem 58.203
Train: [4][625/750]	BT 0.094 (1.288)	DT 0.003 (1.141)	loss nan (nan)	prob nan (nan)	GS 30.312 (30.312)	mem 58.325
Train: [4][630/750]	BT 0.137 (1.279)	DT 0.021 (1.132)	loss nan (nan)	prob nan (nan)	GS 36.672 (36.672)	mem 58.435
Train: [4][635/750]	BT 0.136 (1.289)	DT 0.002 (1.142)	loss nan (nan)	prob nan (nan)	GS 30.375 (30.375)	mem 60.854
Train: [4][640/750]	BT 0.111 (1.280)	DT 0.023 (1.133)	loss nan (nan)	prob nan (nan)	GS 31.578 (31.578)	mem 61.051
Train: [4][645/750]	BT 0.117 (1.293)	DT 0.003 (1.146)	loss nan (nan)	prob nan (nan)	GS 28.750 (28.750)	mem 63.615
Train: [4][650/750]	BT 0.200 (1.284)	DT 0.014 (1.137)	loss nan (nan)	prob nan (nan)	GS 33.172 (33.172)	mem 63.764
Train: [4][655/750]	BT 0.213 (1.284)	DT 0.012 (1.137)	loss nan (nan)	prob nan (nan)	GS 31.281 (31.281)	mem 58.184
Train: [4][660/750]	BT 0.147 (1.291)	DT 0.001 (1.144)	loss nan (nan)	prob nan (nan)	GS 37.750 (37.750)	mem 60.692
Train: [4][665/750]	BT 0.149 (1.282)	DT 0.001 (1.136)	loss nan (nan)	prob nan (nan)	GS 30.969 (30.969)	mem 60.824
Train: [4][670/750]	BT 1.498 (1.291)	DT 1.394 (1.145)	loss nan (nan)	prob nan (nan)	GS 35.391 (35.391)	mem 63.412
Train: [4][675/750]	BT 0.118 (1.283)	DT 0.002 (1.136)	loss nan (nan)	prob nan (nan)	GS 32.328 (32.328)	mem 63.565
Train: [4][680/750]	BT 11.875 (1.292)	DT 11.536 (1.145)	loss nan (nan)	prob nan (nan)	GS 35.312 (35.312)	mem 64.568
arpack error, retry= 0
Train: [4][685/750]	BT 0.115 (1.287)	DT 0.002 (1.141)	loss nan (nan)	prob nan (nan)	GS 28.453 (28.453)	mem 64.868
Train: [4][690/750]	BT 0.132 (1.279)	DT 0.020 (1.132)	loss nan (nan)	prob nan (nan)	GS 33.922 (33.922)	mem 64.586
Train: [4][695/750]	BT 0.099 (1.287)	DT 0.004 (1.139)	loss nan (nan)	prob nan (nan)	GS 32.406 (32.406)	mem 64.559
Train: [4][700/750]	BT 0.159 (1.278)	DT 0.014 (1.131)	loss nan (nan)	prob nan (nan)	GS 30.391 (30.391)	mem 64.559
Train: [4][705/750]	BT 0.223 (1.278)	DT 0.003 (1.131)	loss nan (nan)	prob nan (nan)	GS 25.328 (25.328)	mem 64.430
Train: [4][710/750]	BT 0.366 (1.285)	DT 0.006 (1.137)	loss nan (nan)	prob nan (nan)	GS 34.031 (34.031)	mem 64.531
Train: [4][715/750]	BT 0.133 (1.277)	DT 0.002 (1.129)	loss nan (nan)	prob nan (nan)	GS 34.109 (34.109)	mem 64.472
Train: [4][720/750]	BT 0.102 (1.288)	DT 0.001 (1.140)	loss nan (nan)	prob nan (nan)	GS 31.094 (31.094)	mem 58.979
Train: [4][725/750]	BT 0.228 (1.280)	DT 0.008 (1.132)	loss nan (nan)	prob nan (nan)	GS 30.625 (30.625)	mem 59.217
Train: [4][730/750]	BT 8.636 (1.290)	DT 8.552 (1.141)	loss nan (nan)	prob nan (nan)	GS 31.719 (31.719)	mem 61.352
Train: [4][735/750]	BT 0.113 (1.282)	DT 0.003 (1.134)	loss nan (nan)	prob nan (nan)	GS 30.047 (30.047)	mem 61.550
Train: [4][740/750]	BT 2.004 (1.276)	DT 1.877 (1.129)	loss nan (nan)	prob nan (nan)	GS 35.109 (35.109)	mem 42.377
Train: [4][745/750]	BT 0.081 (1.275)	DT 0.007 (1.128)	loss nan (nan)	prob nan (nan)	GS 32.094 (32.094)	mem 30.411
Train: [4][750/750]	BT 0.071 (1.267)	DT 0.001 (1.120)	loss nan (nan)	prob nan (nan)	GS 27.688 (27.688)	mem 25.638
Train: [4][755/750]	BT 0.068 (1.263)	DT 0.001 (1.117)	loss nan (nan)	prob nan (nan)	GS 28.250 (28.250)	mem 26.856
epoch 4, total time 954.18
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [5][1/750]	BT 21.654 (21.654)	DT 21.468 (21.468)	loss nan (nan)	prob nan (nan)	GS 28.453 (28.453)	mem 63.331
Train: [5][5/750]	BT 0.147 (4.895)	DT 0.010 (4.707)	loss nan (nan)	prob nan (nan)	GS 26.859 (26.859)	mem 63.116
Train: [5][10/750]	BT 0.210 (2.612)	DT 0.016 (2.436)	loss nan (nan)	prob nan (nan)	GS 35.344 (35.344)	mem 63.282
Train: [5][15/750]	BT 0.280 (2.484)	DT 0.004 (2.295)	loss nan (nan)	prob nan (nan)	GS 27.547 (27.547)	mem 63.389
Train: [5][20/750]	BT 0.123 (1.913)	DT 0.002 (1.724)	loss nan (nan)	prob nan (nan)	GS 35.203 (35.203)	mem 63.439
Train: [5][25/750]	BT 3.523 (1.888)	DT 3.366 (1.697)	loss nan (nan)	prob nan (nan)	GS 36.453 (36.453)	mem 63.672
Train: [5][30/750]	BT 1.080 (1.770)	DT 0.965 (1.582)	loss nan (nan)	prob nan (nan)	GS 33.844 (33.844)	mem 63.469
Train: [5][35/750]	BT 0.159 (1.693)	DT 0.002 (1.504)	loss nan (nan)	prob nan (nan)	GS 33.859 (33.859)	mem 61.456
Train: [5][40/750]	BT 8.525 (1.776)	DT 8.375 (1.590)	loss nan (nan)	prob nan (nan)	GS 38.016 (38.016)	mem 59.075
Train: [5][45/750]	BT 0.116 (1.593)	DT 0.002 (1.414)	loss nan (nan)	prob nan (nan)	GS 32.516 (32.516)	mem 59.283
Train: [5][50/750]	BT 0.457 (1.511)	DT 0.296 (1.331)	loss nan (nan)	prob nan (nan)	GS 33.109 (33.109)	mem 59.746
Train: [5][55/750]	BT 0.206 (1.577)	DT 0.009 (1.396)	loss nan (nan)	prob nan (nan)	GS 32.828 (32.828)	mem 61.446
Train: [5][60/750]	BT 1.360 (1.511)	DT 1.175 (1.331)	loss nan (nan)	prob nan (nan)	GS 35.188 (35.188)	mem 62.171
Train: [5][65/750]	BT 0.148 (1.549)	DT 0.002 (1.370)	loss nan (nan)	prob nan (nan)	GS 33.750 (33.750)	mem 62.006
Train: [5][70/750]	BT 2.000 (1.493)	DT 1.890 (1.314)	loss nan (nan)	prob nan (nan)	GS 33.969 (33.969)	mem 58.910
Train: [5][75/750]	BT 1.889 (1.441)	DT 1.713 (1.265)	loss nan (nan)	prob nan (nan)	GS 29.156 (29.156)	mem 58.435
Train: [5][80/750]	BT 0.083 (1.455)	DT 0.001 (1.282)	loss nan (nan)	prob nan (nan)	GS 31.656 (31.656)	mem 60.393
Train: [5][85/750]	BT 0.130 (1.400)	DT 0.001 (1.229)	loss nan (nan)	prob nan (nan)	GS 31.406 (31.406)	mem 60.864
Train: [5][90/750]	BT 0.157 (1.457)	DT 0.006 (1.287)	loss nan (nan)	prob nan (nan)	GS 38.250 (38.250)	mem 63.518
Train: [5][95/750]	BT 0.092 (1.389)	DT 0.003 (1.220)	loss nan (nan)	prob nan (nan)	GS 32.703 (32.703)	mem 63.646
Train: [5][100/750]	BT 7.993 (1.452)	DT 7.815 (1.280)	loss nan (nan)	prob nan (nan)	GS 40.109 (40.109)	mem 64.162
Train: [5][105/750]	BT 0.185 (1.390)	DT 0.001 (1.220)	loss nan (nan)	prob nan (nan)	GS 30.656 (30.656)	mem 64.171
Train: [5][110/750]	BT 0.208 (1.354)	DT 0.008 (1.184)	loss nan (nan)	prob nan (nan)	GS 34.312 (34.312)	mem 64.191
Train: [5][115/750]	BT 0.225 (1.405)	DT 0.018 (1.236)	loss nan (nan)	prob nan (nan)	GS 30.984 (30.984)	mem 64.289
Train: [5][120/750]	BT 0.298 (1.355)	DT 0.164 (1.186)	loss nan (nan)	prob nan (nan)	GS 40.422 (40.422)	mem 64.288
Train: [5][125/750]	BT 0.099 (1.422)	DT 0.002 (1.253)	loss nan (nan)	prob nan (nan)	GS 30.875 (30.875)	mem 63.903
Train: [5][130/750]	BT 0.135 (1.372)	DT 0.001 (1.205)	loss nan (nan)	prob nan (nan)	GS 37.375 (37.375)	mem 58.794
Train: [5][135/750]	BT 0.182 (1.327)	DT 0.027 (1.160)	loss nan (nan)	prob nan (nan)	GS 27.547 (27.547)	mem 57.784
Train: [5][140/750]	BT 0.157 (1.382)	DT 0.002 (1.217)	loss nan (nan)	prob nan (nan)	GS 30.812 (30.812)	mem 60.377
Train: [5][145/750]	BT 0.089 (1.340)	DT 0.004 (1.175)	loss nan (nan)	prob nan (nan)	GS 35.406 (35.406)	mem 60.714
Train: [5][150/750]	BT 4.783 (1.390)	DT 4.683 (1.226)	loss nan (nan)	prob nan (nan)	GS 34.656 (34.656)	mem 63.194
Train: [5][155/750]	BT 0.087 (1.349)	DT 0.002 (1.187)	loss nan (nan)	prob nan (nan)	GS 31.125 (31.125)	mem 63.271
Train: [5][160/750]	BT 6.486 (1.351)	DT 6.339 (1.190)	loss nan (nan)	prob nan (nan)	GS 36.438 (36.438)	mem 57.795
Train: [5][165/750]	BT 0.100 (1.357)	DT 0.003 (1.197)	loss nan (nan)	prob nan (nan)	GS 32.094 (32.094)	mem 59.278
Train: [5][170/750]	BT 0.223 (1.322)	DT 0.019 (1.162)	loss nan (nan)	prob nan (nan)	GS 35.891 (35.891)	mem 59.550
Train: [5][175/750]	BT 0.104 (1.375)	DT 0.001 (1.216)	loss nan (nan)	prob nan (nan)	GS 37.812 (37.812)	mem 63.070
Train: [5][180/750]	BT 0.106 (1.341)	DT 0.001 (1.183)	loss nan (nan)	prob nan (nan)	GS 33.578 (33.578)	mem 63.232
Train: [5][185/750]	BT 0.153 (1.349)	DT 0.002 (1.191)	loss nan (nan)	prob nan (nan)	GS 29.922 (29.922)	mem 64.436
Train: [5][190/750]	BT 0.180 (1.335)	DT 0.003 (1.176)	loss nan (nan)	prob nan (nan)	GS 31.422 (31.422)	mem 64.447
Train: [5][195/750]	BT 0.203 (1.305)	DT 0.027 (1.146)	loss nan (nan)	prob nan (nan)	GS 28.594 (28.594)	mem 64.449
Train: [5][200/750]	BT 0.149 (1.344)	DT 0.001 (1.186)	loss nan (nan)	prob nan (nan)	GS 33.547 (33.547)	mem 64.447
Train: [5][205/750]	BT 0.239 (1.315)	DT 0.006 (1.157)	loss nan (nan)	prob nan (nan)	GS 31.547 (31.547)	mem 64.450
Train: [5][210/750]	BT 0.107 (1.352)	DT 0.005 (1.193)	loss nan (nan)	prob nan (nan)	GS 35.000 (35.000)	mem 64.495
Train: [5][215/750]	BT 0.127 (1.323)	DT 0.001 (1.165)	loss nan (nan)	prob nan (nan)	GS 34.078 (34.078)	mem 64.565
Train: [5][220/750]	BT 11.240 (1.347)	DT 11.061 (1.189)	loss nan (nan)	prob nan (nan)	GS 31.484 (31.484)	mem 59.027
Train: [5][225/750]	BT 0.185 (1.320)	DT 0.017 (1.163)	loss nan (nan)	prob nan (nan)	GS 34.531 (34.531)	mem 59.185
Train: [5][230/750]	BT 0.157 (1.294)	DT 0.002 (1.138)	loss nan (nan)	prob nan (nan)	GS 34.734 (34.734)	mem 59.473
Train: [5][235/750]	BT 0.079 (1.319)	DT 0.001 (1.164)	loss nan (nan)	prob nan (nan)	GS 26.297 (26.297)	mem 61.731
Train: [5][240/750]	BT 0.091 (1.294)	DT 0.004 (1.140)	loss nan (nan)	prob nan (nan)	GS 31.672 (31.672)	mem 61.901
Train: [5][245/750]	BT 0.104 (1.315)	DT 0.007 (1.162)	loss nan (nan)	prob nan (nan)	GS 34.047 (34.047)	mem 63.756
Train: [5][250/750]	BT 0.135 (1.292)	DT 0.002 (1.138)	loss nan (nan)	prob nan (nan)	GS 34.156 (34.156)	mem 63.668
Train: [5][255/750]	BT 0.169 (1.269)	DT 0.013 (1.116)	loss nan (nan)	prob nan (nan)	GS 27.250 (27.250)	mem 63.715
Train: [5][260/750]	BT 0.229 (1.291)	DT 0.004 (1.138)	loss nan (nan)	prob nan (nan)	GS 33.797 (33.797)	mem 59.552
Train: [5][265/750]	BT 0.274 (1.270)	DT 0.084 (1.117)	loss nan (nan)	prob nan (nan)	GS 28.656 (28.656)	mem 59.605
Train: [5][270/750]	BT 0.086 (1.306)	DT 0.002 (1.154)	loss nan (nan)	prob nan (nan)	GS 31.594 (31.594)	mem 62.820
Train: [5][275/750]	BT 0.152 (1.285)	DT 0.004 (1.133)	loss nan (nan)	prob nan (nan)	GS 32.141 (32.141)	mem 63.121
Train: [5][280/750]	BT 11.132 (1.304)	DT 10.993 (1.152)	loss nan (nan)	prob nan (nan)	GS 34.844 (34.844)	mem 64.471
Train: [5][285/750]	BT 0.099 (1.283)	DT 0.001 (1.132)	loss nan (nan)	prob nan (nan)	GS 29.562 (29.562)	mem 64.483
Train: [5][290/750]	BT 0.156 (1.265)	DT 0.007 (1.113)	loss nan (nan)	prob nan (nan)	GS 37.000 (37.000)	mem 64.471
Train: [5][295/750]	BT 0.117 (1.292)	DT 0.001 (1.139)	loss nan (nan)	prob nan (nan)	GS 34.234 (34.234)	mem 64.770
Train: [5][300/750]	BT 0.267 (1.274)	DT 0.015 (1.120)	loss nan (nan)	prob nan (nan)	GS 31.281 (31.281)	mem 64.482
Train: [5][305/750]	BT 0.102 (1.266)	DT 0.002 (1.113)	loss nan (nan)	prob nan (nan)	GS 30.453 (30.453)	mem 64.535
Train: [5][310/750]	BT 0.142 (1.264)	DT 0.007 (1.108)	loss nan (nan)	prob nan (nan)	GS 35.875 (35.875)	mem 64.507
Train: [5][315/750]	BT 0.166 (1.246)	DT 0.003 (1.091)	loss nan (nan)	prob nan (nan)	GS 29.984 (29.984)	mem 64.442
Train: [5][320/750]	BT 0.118 (1.268)	DT 0.012 (1.113)	loss nan (nan)	prob nan (nan)	GS 35.047 (35.047)	mem 58.380
Train: [5][325/750]	BT 0.119 (1.251)	DT 0.006 (1.096)	loss nan (nan)	prob nan (nan)	GS 30.172 (30.172)	mem 58.298
Train: [5][330/750]	BT 6.210 (1.263)	DT 6.068 (1.107)	loss nan (nan)	prob nan (nan)	GS 31.594 (31.594)	mem 60.216
Train: [5][335/750]	BT 0.302 (1.246)	DT 0.003 (1.091)	loss nan (nan)	prob nan (nan)	GS 30.172 (30.172)	mem 60.343
Train: [5][340/750]	BT 8.449 (1.254)	DT 8.279 (1.099)	loss nan (nan)	prob nan (nan)	GS 35.078 (35.078)	mem 61.946
Train: [5][345/750]	BT 0.191 (1.258)	DT 0.001 (1.103)	loss nan (nan)	prob nan (nan)	GS 32.094 (32.094)	mem 63.327
Train: [5][350/750]	BT 0.105 (1.242)	DT 0.002 (1.087)	loss nan (nan)	prob nan (nan)	GS 29.000 (29.000)	mem 63.454
Train: [5][355/750]	BT 0.089 (1.267)	DT 0.002 (1.112)	loss nan (nan)	prob nan (nan)	GS 30.828 (30.828)	mem 59.027
Train: [5][360/750]	BT 0.205 (1.252)	DT 0.003 (1.097)	loss nan (nan)	prob nan (nan)	GS 35.594 (35.594)	mem 59.183
Train: [5][365/750]	BT 0.207 (1.256)	DT 0.004 (1.101)	loss nan (nan)	prob nan (nan)	GS 33.625 (33.625)	mem 60.508
Train: [5][370/750]	BT 0.160 (1.260)	DT 0.007 (1.105)	loss nan (nan)	prob nan (nan)	GS 35.781 (35.781)	mem 62.074
Train: [5][375/750]	BT 0.157 (1.245)	DT 0.018 (1.090)	loss nan (nan)	prob nan (nan)	GS 31.672 (31.672)	mem 62.183
Train: [5][380/750]	BT 2.332 (1.266)	DT 2.176 (1.111)	loss nan (nan)	prob nan (nan)	GS 32.312 (32.312)	mem 64.485
Train: [5][385/750]	BT 0.109 (1.252)	DT 0.002 (1.097)	loss nan (nan)	prob nan (nan)	GS 30.188 (30.188)	mem 64.482
Train: [5][390/750]	BT 3.005 (1.261)	DT 2.866 (1.106)	loss nan (nan)	prob nan (nan)	GS 35.531 (35.531)	mem 64.419
Train: [5][395/750]	BT 0.346 (1.251)	DT 0.019 (1.095)	loss nan (nan)	prob nan (nan)	GS 36.516 (36.516)	mem 64.471
Train: [5][400/750]	BT 11.147 (1.265)	DT 11.015 (1.109)	loss nan (nan)	prob nan (nan)	GS 33.750 (33.750)	mem 64.881
Train: [5][405/750]	BT 0.110 (1.257)	DT 0.001 (1.102)	loss nan (nan)	prob nan (nan)	GS 28.500 (28.500)	mem 64.505
Train: [5][410/750]	BT 0.117 (1.244)	DT 0.004 (1.088)	loss nan (nan)	prob nan (nan)	GS 34.516 (34.516)	mem 64.460
Train: [5][415/750]	BT 0.122 (1.258)	DT 0.001 (1.104)	loss nan (nan)	prob nan (nan)	GS 29.875 (29.875)	mem 57.781
Train: [5][420/750]	BT 0.093 (1.247)	DT 0.001 (1.092)	loss nan (nan)	prob nan (nan)	GS 33.188 (33.188)	mem 58.148
Train: [5][425/750]	BT 0.104 (1.255)	DT 0.009 (1.101)	loss nan (nan)	prob nan (nan)	GS 33.312 (33.312)	mem 59.839
Train: [5][430/750]	BT 0.266 (1.252)	DT 0.005 (1.097)	loss nan (nan)	prob nan (nan)	GS 33.266 (33.266)	mem 60.703
Train: [5][435/750]	BT 0.358 (1.240)	DT 0.001 (1.085)	loss nan (nan)	prob nan (nan)	GS 30.859 (30.859)	mem 60.909
Train: [5][440/750]	BT 4.481 (1.264)	DT 4.279 (1.109)	loss nan (nan)	prob nan (nan)	GS 35.094 (35.094)	mem 63.178
Train: [5][445/750]	BT 0.125 (1.256)	DT 0.003 (1.102)	loss nan (nan)	prob nan (nan)	GS 29.531 (29.531)	mem 63.472
Train: [5][450/750]	BT 0.153 (1.258)	DT 0.012 (1.103)	loss nan (nan)	prob nan (nan)	GS 33.422 (33.422)	mem 58.009
Train: [5][455/750]	BT 0.642 (1.254)	DT 0.410 (1.099)	loss nan (nan)	prob nan (nan)	GS 30.438 (30.438)	mem 59.055
Train: [5][460/750]	BT 9.235 (1.262)	DT 9.148 (1.107)	loss nan (nan)	prob nan (nan)	GS 34.328 (34.328)	mem 60.974
Train: [5][465/750]	BT 0.153 (1.256)	DT 0.003 (1.102)	loss nan (nan)	prob nan (nan)	GS 29.641 (29.641)	mem 61.886
Train: [5][470/750]	BT 0.164 (1.244)	DT 0.002 (1.090)	loss nan (nan)	prob nan (nan)	GS 33.109 (33.109)	mem 62.031
Train: [5][475/750]	BT 0.122 (1.256)	DT 0.002 (1.102)	loss nan (nan)	prob nan (nan)	GS 29.125 (29.125)	mem 64.301
Train: [5][480/750]	BT 0.225 (1.245)	DT 0.008 (1.091)	loss nan (nan)	prob nan (nan)	GS 38.125 (38.125)	mem 64.368
Train: [5][485/750]	BT 0.189 (1.261)	DT 0.006 (1.106)	loss nan (nan)	prob nan (nan)	GS 32.047 (32.047)	mem 64.517
Train: [5][490/750]	BT 0.203 (1.251)	DT 0.002 (1.095)	loss nan (nan)	prob nan (nan)	GS 38.531 (38.531)	mem 64.376
Train: [5][495/750]	BT 0.217 (1.240)	DT 0.005 (1.084)	loss nan (nan)	prob nan (nan)	GS 35.797 (35.797)	mem 64.489
Train: [5][500/750]	BT 3.474 (1.264)	DT 3.290 (1.108)	loss nan (nan)	prob nan (nan)	GS 35.422 (35.422)	mem 64.625
Train: [5][505/750]	BT 0.153 (1.253)	DT 0.001 (1.097)	loss nan (nan)	prob nan (nan)	GS 42.188 (42.188)	mem 64.480
Train: [5][510/750]	BT 3.944 (1.261)	DT 3.621 (1.105)	loss nan (nan)	prob nan (nan)	GS 34.641 (34.641)	mem 64.654
Train: [5][515/750]	BT 0.124 (1.254)	DT 0.002 (1.097)	loss nan (nan)	prob nan (nan)	GS 31.125 (31.125)	mem 57.834
Train: [5][520/750]	BT 9.636 (1.261)	DT 9.436 (1.105)	loss nan (nan)	prob nan (nan)	GS 40.406 (40.406)	mem 59.584
Train: [5][525/750]	BT 0.198 (1.255)	DT 0.015 (1.099)	loss nan (nan)	prob nan (nan)	GS 28.969 (28.969)	mem 60.312
Train: [5][530/750]	BT 0.163 (1.244)	DT 0.005 (1.088)	loss nan (nan)	prob nan (nan)	GS 35.344 (35.344)	mem 60.353
Train: [5][535/750]	BT 0.108 (1.260)	DT 0.005 (1.104)	loss nan (nan)	prob nan (nan)	GS 32.594 (32.594)	mem 63.145
Train: [5][540/750]	BT 0.231 (1.250)	DT 0.023 (1.094)	loss nan (nan)	prob nan (nan)	GS 34.250 (34.250)	mem 63.291
Train: [5][545/750]	BT 0.089 (1.263)	DT 0.004 (1.108)	loss nan (nan)	prob nan (nan)	GS 32.641 (32.641)	mem 58.985
Train: [5][550/750]	BT 0.124 (1.254)	DT 0.001 (1.098)	loss nan (nan)	prob nan (nan)	GS 29.250 (29.250)	mem 59.099
Train: [5][555/750]	BT 0.100 (1.243)	DT 0.018 (1.088)	loss nan (nan)	prob nan (nan)	GS 33.672 (33.672)	mem 59.070
Train: [5][560/750]	BT 4.104 (1.265)	DT 4.031 (1.111)	loss nan (nan)	prob nan (nan)	GS 39.719 (39.719)	mem 62.786
Train: [5][565/750]	BT 0.284 (1.256)	DT 0.005 (1.101)	loss nan (nan)	prob nan (nan)	GS 27.578 (27.578)	mem 62.855
Train: [5][570/750]	BT 0.159 (1.259)	DT 0.003 (1.104)	loss nan (nan)	prob nan (nan)	GS 31.750 (31.750)	mem 64.479
Train: [5][575/750]	BT 0.086 (1.261)	DT 0.003 (1.106)	loss nan (nan)	prob nan (nan)	GS 32.781 (32.781)	mem 64.586
Train: [5][580/750]	BT 6.697 (1.263)	DT 6.578 (1.108)	loss nan (nan)	prob nan (nan)	GS 37.172 (37.172)	mem 64.510
Train: [5][585/750]	BT 0.258 (1.266)	DT 0.002 (1.111)	loss nan (nan)	prob nan (nan)	GS 32.328 (32.328)	mem 64.583
Train: [5][590/750]	BT 0.147 (1.257)	DT 0.001 (1.102)	loss nan (nan)	prob nan (nan)	GS 34.109 (34.109)	mem 64.551
Train: [5][595/750]	BT 0.266 (1.260)	DT 0.002 (1.105)	loss nan (nan)	prob nan (nan)	GS 34.109 (34.109)	mem 64.708
Train: [5][600/750]	BT 0.109 (1.260)	DT 0.002 (1.104)	loss nan (nan)	prob nan (nan)	GS 36.828 (36.828)	mem 64.670
Train: [5][605/750]	BT 0.157 (1.258)	DT 0.006 (1.102)	loss nan (nan)	prob nan (nan)	GS 35.141 (35.141)	mem 58.014
Train: [5][610/750]	BT 0.182 (1.266)	DT 0.012 (1.111)	loss nan (nan)	prob nan (nan)	GS 33.172 (33.172)	mem 60.039
Train: [5][615/750]	BT 0.115 (1.257)	DT 0.003 (1.102)	loss nan (nan)	prob nan (nan)	GS 28.312 (28.312)	mem 60.181
Train: [5][620/750]	BT 7.067 (1.274)	DT 6.957 (1.119)	loss nan (nan)	prob nan (nan)	GS 35.422 (35.422)	mem 63.638
Train: [5][625/750]	BT 0.116 (1.265)	DT 0.001 (1.110)	loss nan (nan)	prob nan (nan)	GS 32.344 (32.344)	mem 63.421
Train: [5][630/750]	BT 9.997 (1.272)	DT 9.869 (1.117)	loss nan (nan)	prob nan (nan)	GS 36.297 (36.297)	mem 58.599
Train: [5][635/750]	BT 0.148 (1.268)	DT 0.004 (1.114)	loss nan (nan)	prob nan (nan)	GS 33.797 (33.797)	mem 59.839
Train: [5][640/750]	BT 0.116 (1.259)	DT 0.009 (1.105)	loss nan (nan)	prob nan (nan)	GS 30.172 (30.172)	mem 60.026
Train: [5][645/750]	BT 0.141 (1.266)	DT 0.002 (1.112)	loss nan (nan)	prob nan (nan)	GS 32.625 (32.625)	mem 62.104
Train: [5][650/750]	BT 0.143 (1.257)	DT 0.001 (1.103)	loss nan (nan)	prob nan (nan)	GS 30.438 (30.438)	mem 62.265
Train: [5][655/750]	BT 0.099 (1.267)	DT 0.001 (1.113)	loss nan (nan)	prob nan (nan)	GS 27.703 (27.703)	mem 64.406
Train: [5][660/750]	BT 0.131 (1.262)	DT 0.001 (1.108)	loss nan (nan)	prob nan (nan)	GS 31.562 (31.562)	mem 64.478
Train: [5][665/750]	BT 0.107 (1.253)	DT 0.002 (1.100)	loss nan (nan)	prob nan (nan)	GS 33.578 (33.578)	mem 64.494
Train: [5][670/750]	BT 0.136 (1.260)	DT 0.002 (1.107)	loss nan (nan)	prob nan (nan)	GS 33.688 (33.688)	mem 64.540
Train: [5][675/750]	BT 0.208 (1.252)	DT 0.001 (1.099)	loss nan (nan)	prob nan (nan)	GS 31.609 (31.609)	mem 64.641
Train: [5][680/750]	BT 4.218 (1.266)	DT 4.056 (1.112)	loss nan (nan)	prob nan (nan)	GS 34.766 (34.766)	mem 64.595
Train: [5][685/750]	BT 0.158 (1.257)	DT 0.001 (1.104)	loss nan (nan)	prob nan (nan)	GS 26.672 (26.672)	mem 64.484
Train: [5][690/750]	BT 9.855 (1.263)	DT 9.677 (1.110)	loss nan (nan)	prob nan (nan)	GS 34.984 (34.984)	mem 58.095
Train: [5][695/750]	BT 0.258 (1.256)	DT 0.004 (1.102)	loss nan (nan)	prob nan (nan)	GS 32.203 (32.203)	mem 58.401
Train: [5][700/750]	BT 0.235 (1.248)	DT 0.002 (1.094)	loss nan (nan)	prob nan (nan)	GS 31.797 (31.797)	mem 58.417
Train: [5][705/750]	BT 0.109 (1.261)	DT 0.009 (1.107)	loss nan (nan)	prob nan (nan)	GS 31.297 (31.297)	mem 61.429
Train: [5][710/750]	BT 0.084 (1.252)	DT 0.001 (1.099)	loss nan (nan)	prob nan (nan)	GS 33.625 (33.625)	mem 61.444
Train: [5][715/750]	BT 0.187 (1.259)	DT 0.004 (1.106)	loss nan (nan)	prob nan (nan)	GS 29.656 (29.656)	mem 63.463
Train: [5][720/750]	BT 0.143 (1.252)	DT 0.006 (1.099)	loss nan (nan)	prob nan (nan)	GS 35.531 (35.531)	mem 63.394
Train: [5][725/750]	BT 0.097 (1.244)	DT 0.002 (1.091)	loss nan (nan)	prob nan (nan)	GS 32.672 (32.672)	mem 63.638
Train: [5][730/750]	BT 0.121 (1.254)	DT 0.002 (1.102)	loss nan (nan)	prob nan (nan)	GS 36.922 (36.922)	mem 58.787
Train: [5][735/750]	BT 0.109 (1.246)	DT 0.001 (1.094)	loss nan (nan)	prob nan (nan)	GS 28.266 (28.266)	mem 59.056
Train: [5][740/750]	BT 3.379 (1.251)	DT 3.286 (1.100)	loss nan (nan)	prob nan (nan)	GS 38.094 (38.094)	mem 33.071
Train: [5][745/750]	BT 0.091 (1.243)	DT 0.011 (1.093)	loss nan (nan)	prob nan (nan)	GS 38.031 (38.031)	mem 33.214
Train: [5][750/750]	BT 0.338 (1.236)	DT 0.230 (1.086)	loss nan (nan)	prob nan (nan)	GS 39.656 (39.656)	mem 33.419
Train: [5][755/750]	BT 0.072 (1.232)	DT 0.001 (1.082)	loss nan (nan)	prob nan (nan)	GS 29.000 (29.000)	mem 31.755
epoch 5, total time 930.20
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [6][1/750]	BT 24.952 (24.952)	DT 24.747 (24.747)	loss nan (nan)	prob nan (nan)	GS 34.344 (34.344)	mem 63.181
Train: [6][5/750]	BT 0.123 (5.338)	DT 0.003 (5.167)	loss nan (nan)	prob nan (nan)	GS 29.703 (29.703)	mem 63.245
Train: [6][10/750]	BT 0.095 (2.763)	DT 0.006 (2.593)	loss nan (nan)	prob nan (nan)	GS 34.156 (34.156)	mem 63.383
Train: [6][15/750]	BT 0.110 (3.117)	DT 0.003 (2.936)	loss nan (nan)	prob nan (nan)	GS 27.641 (27.641)	mem 59.177
Train: [6][20/750]	BT 0.186 (2.501)	DT 0.011 (2.331)	loss nan (nan)	prob nan (nan)	GS 35.375 (35.375)	mem 59.962
Train: [6][25/750]	BT 0.258 (2.047)	DT 0.003 (1.866)	loss nan (nan)	prob nan (nan)	GS 29.531 (29.531)	mem 60.252
Train: [6][30/750]	BT 0.082 (2.152)	DT 0.003 (1.975)	loss nan (nan)	prob nan (nan)	GS 36.141 (36.141)	mem 62.527
Train: [6][35/750]	BT 0.177 (1.863)	DT 0.002 (1.693)	loss nan (nan)	prob nan (nan)	GS 29.125 (29.125)	mem 62.575
Train: [6][40/750]	BT 0.109 (1.992)	DT 0.001 (1.823)	loss nan (nan)	prob nan (nan)	GS 33.688 (33.688)	mem 58.378
Train: [6][45/750]	BT 0.112 (1.789)	DT 0.002 (1.621)	loss nan (nan)	prob nan (nan)	GS 31.062 (31.062)	mem 58.536
Train: [6][50/750]	BT 10.188 (1.826)	DT 9.965 (1.659)	loss nan (nan)	prob nan (nan)	GS 29.703 (29.703)	mem 60.634
Train: [6][55/750]	BT 0.089 (1.811)	DT 0.001 (1.649)	loss nan (nan)	prob nan (nan)	GS 34.094 (34.094)	mem 62.702
Train: [6][60/750]	BT 0.169 (1.672)	DT 0.002 (1.512)	loss nan (nan)	prob nan (nan)	GS 34.875 (34.875)	mem 62.829
Train: [6][65/750]	BT 0.074 (1.768)	DT 0.001 (1.608)	loss nan (nan)	prob nan (nan)	GS 32.469 (32.469)	mem 63.924
Train: [6][70/750]	BT 0.256 (1.656)	DT 0.006 (1.494)	loss nan (nan)	prob nan (nan)	GS 41.328 (41.328)	mem 63.936
Train: [6][75/750]	BT 0.193 (1.560)	DT 0.001 (1.395)	loss nan (nan)	prob nan (nan)	GS 32.234 (32.234)	mem 63.757
Train: [6][80/750]	BT 0.099 (1.593)	DT 0.003 (1.429)	loss nan (nan)	prob nan (nan)	GS 32.484 (32.484)	mem 63.790
Train: [6][85/750]	BT 0.273 (1.513)	DT 0.003 (1.346)	loss nan (nan)	prob nan (nan)	GS 28.938 (28.938)	mem 63.690
Train: [6][90/750]	BT 0.173 (1.559)	DT 0.003 (1.390)	loss nan (nan)	prob nan (nan)	GS 34.906 (34.906)	mem 63.743
Train: [6][95/750]	BT 0.146 (1.485)	DT 0.007 (1.317)	loss nan (nan)	prob nan (nan)	GS 34.875 (34.875)	mem 63.773
Train: [6][100/750]	BT 8.702 (1.543)	DT 8.588 (1.373)	loss nan (nan)	prob nan (nan)	GS 29.875 (29.875)	mem 58.196
Train: [6][105/750]	BT 0.145 (1.476)	DT 0.045 (1.308)	loss nan (nan)	prob nan (nan)	GS 26.156 (26.156)	mem 58.520
Train: [6][110/750]	BT 3.909 (1.451)	DT 3.706 (1.283)	loss nan (nan)	prob nan (nan)	GS 28.750 (28.750)	mem 59.464
Train: [6][115/750]	BT 0.090 (1.500)	DT 0.015 (1.335)	loss nan (nan)	prob nan (nan)	GS 29.188 (29.188)	mem 61.738
Train: [6][120/750]	BT 0.238 (1.445)	DT 0.003 (1.279)	loss nan (nan)	prob nan (nan)	GS 34.859 (34.859)	mem 62.036
Train: [6][125/750]	BT 0.086 (1.506)	DT 0.001 (1.341)	loss nan (nan)	prob nan (nan)	GS 30.859 (30.859)	mem 57.893
Train: [6][130/750]	BT 0.124 (1.454)	DT 0.010 (1.290)	loss nan (nan)	prob nan (nan)	GS 32.875 (32.875)	mem 58.060
Train: [6][135/750]	BT 0.336 (1.444)	DT 0.018 (1.280)	loss nan (nan)	prob nan (nan)	GS 32.562 (32.562)	mem 59.228
Train: [6][140/750]	BT 0.098 (1.458)	DT 0.001 (1.295)	loss nan (nan)	prob nan (nan)	GS 36.062 (36.062)	mem 60.947
Train: [6][145/750]	BT 0.180 (1.412)	DT 0.014 (1.251)	loss nan (nan)	prob nan (nan)	GS 32.125 (32.125)	mem 61.135
Train: [6][150/750]	BT 0.128 (1.469)	DT 0.010 (1.308)	loss nan (nan)	prob nan (nan)	GS 35.125 (35.125)	mem 63.945
Train: [6][155/750]	BT 0.239 (1.426)	DT 0.002 (1.266)	loss nan (nan)	prob nan (nan)	GS 32.312 (32.312)	mem 64.074
Train: [6][160/750]	BT 14.073 (1.475)	DT 13.965 (1.314)	loss nan (nan)	prob nan (nan)	GS 35.672 (35.672)	mem 64.166
Train: [6][165/750]	BT 0.223 (1.434)	DT 0.015 (1.274)	loss nan (nan)	prob nan (nan)	GS 33.266 (33.266)	mem 64.094
Train: [6][170/750]	BT 0.157 (1.397)	DT 0.004 (1.237)	loss nan (nan)	prob nan (nan)	GS 31.047 (31.047)	mem 64.104
Train: [6][175/750]	BT 0.279 (1.411)	DT 0.002 (1.251)	loss nan (nan)	prob nan (nan)	GS 36.938 (36.938)	mem 64.303
Train: [6][180/750]	BT 0.142 (1.376)	DT 0.002 (1.216)	loss nan (nan)	prob nan (nan)	GS 35.641 (35.641)	mem 64.198
Train: [6][185/750]	BT 0.114 (1.404)	DT 0.005 (1.244)	loss nan (nan)	prob nan (nan)	GS 28.781 (28.781)	mem 64.268
Train: [6][190/750]	BT 0.181 (1.370)	DT 0.002 (1.212)	loss nan (nan)	prob nan (nan)	GS 31.578 (31.578)	mem 62.887
Train: [6][195/750]	BT 0.176 (1.338)	DT 0.005 (1.181)	loss nan (nan)	prob nan (nan)	GS 29.734 (29.734)	mem 57.381
Train: [6][200/750]	BT 0.174 (1.382)	DT 0.020 (1.224)	loss nan (nan)	prob nan (nan)	GS 28.875 (28.875)	mem 59.882
Train: [6][205/750]	BT 0.225 (1.353)	DT 0.003 (1.194)	loss nan (nan)	prob nan (nan)	GS 32.109 (32.109)	mem 60.006
Train: [6][210/750]	BT 0.195 (1.387)	DT 0.003 (1.228)	loss nan (nan)	prob nan (nan)	GS 34.219 (34.219)	mem 62.534
Train: [6][215/750]	BT 0.177 (1.359)	DT 0.002 (1.200)	loss nan (nan)	prob nan (nan)	GS 29.781 (29.781)	mem 62.651
Train: [6][220/750]	BT 18.411 (1.414)	DT 18.300 (1.256)	loss nan (nan)	prob nan (nan)	GS 35.641 (35.641)	mem 59.770
Train: [6][225/750]	BT 0.132 (1.385)	DT 0.002 (1.228)	loss nan (nan)	prob nan (nan)	GS 28.969 (28.969)	mem 59.797
Train: [6][230/750]	BT 0.256 (1.359)	DT 0.002 (1.202)	loss nan (nan)	prob nan (nan)	GS 29.078 (29.078)	mem 60.060
Train: [6][235/750]	BT 0.107 (1.377)	DT 0.001 (1.220)	loss nan (nan)	prob nan (nan)	GS 27.641 (27.641)	mem 62.149
Train: [6][240/750]	BT 0.094 (1.350)	DT 0.005 (1.195)	loss nan (nan)	prob nan (nan)	GS 30.938 (30.938)	mem 62.304
Train: [6][245/750]	BT 0.219 (1.378)	DT 0.001 (1.221)	loss nan (nan)	prob nan (nan)	GS 28.625 (28.625)	mem 64.415
Train: [6][250/750]	BT 0.148 (1.353)	DT 0.003 (1.197)	loss nan (nan)	prob nan (nan)	GS 35.875 (35.875)	mem 64.441
Train: [6][255/750]	BT 0.253 (1.331)	DT 0.003 (1.173)	loss nan (nan)	prob nan (nan)	GS 35.828 (35.828)	mem 64.479
Train: [6][260/750]	BT 0.088 (1.349)	DT 0.001 (1.192)	loss nan (nan)	prob nan (nan)	GS 33.922 (33.922)	mem 64.495
Train: [6][265/750]	BT 0.214 (1.327)	DT 0.017 (1.169)	loss nan (nan)	prob nan (nan)	GS 30.781 (30.781)	mem 64.496
Train: [6][270/750]	BT 0.160 (1.337)	DT 0.010 (1.179)	loss nan (nan)	prob nan (nan)	GS 29.984 (29.984)	mem 64.733
Train: [6][275/750]	BT 0.193 (1.317)	DT 0.007 (1.158)	loss nan (nan)	prob nan (nan)	GS 31.203 (31.203)	mem 64.561
Train: [6][280/750]	BT 12.324 (1.339)	DT 12.220 (1.181)	loss nan (nan)	prob nan (nan)	GS 36.141 (36.141)	mem 64.447
Train: [6][285/750]	BT 0.229 (1.320)	DT 0.014 (1.161)	loss nan (nan)	prob nan (nan)	GS 28.344 (28.344)	mem 64.556
Train: [6][290/750]	BT 0.126 (1.300)	DT 0.008 (1.141)	loss nan (nan)	prob nan (nan)	GS 33.266 (33.266)	mem 64.418
Train: [6][295/750]	BT 0.114 (1.327)	DT 0.012 (1.168)	loss nan (nan)	prob nan (nan)	GS 36.500 (36.500)	mem 59.503
Train: [6][300/750]	BT 0.124 (1.308)	DT 0.001 (1.149)	loss nan (nan)	prob nan (nan)	GS 36.391 (36.391)	mem 59.564
Train: [6][305/750]	BT 0.111 (1.332)	DT 0.011 (1.173)	loss nan (nan)	prob nan (nan)	GS 29.812 (29.812)	mem 61.874
Train: [6][310/750]	BT 0.157 (1.313)	DT 0.008 (1.154)	loss nan (nan)	prob nan (nan)	GS 33.562 (33.562)	mem 62.019
Train: [6][315/750]	BT 0.192 (1.296)	DT 0.002 (1.137)	loss nan (nan)	prob nan (nan)	GS 32.688 (32.688)	mem 62.382
Train: [6][320/750]	BT 0.173 (1.327)	DT 0.002 (1.169)	loss nan (nan)	prob nan (nan)	GS 30.750 (30.750)	mem 58.584
Train: [6][325/750]	BT 0.257 (1.310)	DT 0.030 (1.151)	loss nan (nan)	prob nan (nan)	GS 28.078 (28.078)	mem 58.695
Train: [6][330/750]	BT 0.147 (1.336)	DT 0.002 (1.177)	loss nan (nan)	prob nan (nan)	GS 32.969 (32.969)	mem 62.192
Train: [6][335/750]	BT 0.138 (1.318)	DT 0.008 (1.160)	loss nan (nan)	prob nan (nan)	GS 35.672 (35.672)	mem 62.307
Train: [6][340/750]	BT 11.655 (1.335)	DT 11.404 (1.176)	loss nan (nan)	prob nan (nan)	GS 33.594 (33.594)	mem 64.403
Train: [6][345/750]	BT 0.201 (1.320)	DT 0.003 (1.160)	loss nan (nan)	prob nan (nan)	GS 33.906 (33.906)	mem 64.493
Train: [6][350/750]	BT 0.104 (1.309)	DT 0.002 (1.149)	loss nan (nan)	prob nan (nan)	GS 33.875 (33.875)	mem 64.523
Train: [6][355/750]	BT 0.187 (1.327)	DT 0.015 (1.167)	loss nan (nan)	prob nan (nan)	GS 29.188 (29.188)	mem 64.493
Train: [6][360/750]	BT 0.133 (1.314)	DT 0.001 (1.153)	loss nan (nan)	prob nan (nan)	GS 32.781 (32.781)	mem 64.436
Train: [6][365/750]	BT 0.171 (1.321)	DT 0.012 (1.160)	loss nan (nan)	prob nan (nan)	GS 33.266 (33.266)	mem 64.572
Train: [6][370/750]	BT 6.288 (1.322)	DT 6.152 (1.161)	loss nan (nan)	prob nan (nan)	GS 35.469 (35.469)	mem 64.628
Train: [6][375/750]	BT 0.125 (1.307)	DT 0.002 (1.146)	loss nan (nan)	prob nan (nan)	GS 30.875 (30.875)	mem 64.533
Train: [6][380/750]	BT 0.225 (1.297)	DT 0.007 (1.136)	loss nan (nan)	prob nan (nan)	GS 33.688 (33.688)	mem 64.857
Train: [6][385/750]	BT 0.164 (1.307)	DT 0.001 (1.145)	loss nan (nan)	prob nan (nan)	GS 33.312 (33.312)	mem 58.609
Train: [6][390/750]	BT 0.087 (1.309)	DT 0.007 (1.147)	loss nan (nan)	prob nan (nan)	GS 32.312 (32.312)	mem 60.025
Train: [6][395/750]	BT 0.212 (1.310)	DT 0.003 (1.148)	loss nan (nan)	prob nan (nan)	GS 37.250 (37.250)	mem 61.602
Train: [6][400/750]	BT 6.044 (1.310)	DT 5.877 (1.148)	loss nan (nan)	prob nan (nan)	GS 35.719 (35.719)	mem 62.437
Train: [6][405/750]	BT 0.122 (1.296)	DT 0.002 (1.134)	loss nan (nan)	prob nan (nan)	GS 30.000 (30.000)	mem 62.621
Train: [6][410/750]	BT 0.147 (1.304)	DT 0.005 (1.143)	loss nan (nan)	prob nan (nan)	GS 34.859 (34.859)	mem 63.740
Train: [6][415/750]	BT 0.090 (1.300)	DT 0.002 (1.139)	loss nan (nan)	prob nan (nan)	GS 29.688 (29.688)	mem 58.391
Train: [6][420/750]	BT 3.449 (1.310)	DT 3.343 (1.149)	loss nan (nan)	prob nan (nan)	GS 34.578 (34.578)	mem 60.476
Train: [6][425/750]	BT 0.097 (1.297)	DT 0.005 (1.137)	loss nan (nan)	prob nan (nan)	GS 30.656 (30.656)	mem 60.719
Train: [6][430/750]	BT 12.809 (1.313)	DT 12.724 (1.154)	loss nan (nan)	prob nan (nan)	GS 35.406 (35.406)	mem 63.501
Train: [6][435/750]	BT 0.179 (1.300)	DT 0.043 (1.141)	loss nan (nan)	prob nan (nan)	GS 30.281 (30.281)	mem 63.655
Train: [6][440/750]	BT 0.078 (1.286)	DT 0.003 (1.128)	loss nan (nan)	prob nan (nan)	GS 34.406 (34.406)	mem 63.781
Train: [6][445/750]	BT 0.272 (1.308)	DT 0.001 (1.149)	loss nan (nan)	prob nan (nan)	GS 31.875 (31.875)	mem 64.477
Train: [6][450/750]	BT 0.216 (1.295)	DT 0.010 (1.136)	loss nan (nan)	prob nan (nan)	GS 34.141 (34.141)	mem 64.533
Train: [6][455/750]	BT 0.178 (1.305)	DT 0.002 (1.146)	loss nan (nan)	prob nan (nan)	GS 31.156 (31.156)	mem 64.568
Train: [6][460/750]	BT 0.227 (1.293)	DT 0.007 (1.134)	loss nan (nan)	prob nan (nan)	GS 33.172 (33.172)	mem 64.570
Train: [6][465/750]	BT 0.198 (1.281)	DT 0.017 (1.122)	loss nan (nan)	prob nan (nan)	GS 29.375 (29.375)	mem 64.613
Train: [6][470/750]	BT 0.097 (1.294)	DT 0.001 (1.135)	loss nan (nan)	prob nan (nan)	GS 31.594 (31.594)	mem 64.585
Train: [6][475/750]	BT 0.205 (1.285)	DT 0.005 (1.126)	loss nan (nan)	prob nan (nan)	GS 30.766 (30.766)	mem 64.675
Train: [6][480/750]	BT 0.378 (1.295)	DT 0.230 (1.135)	loss nan (nan)	prob nan (nan)	GS 34.578 (34.578)	mem 59.419
Train: [6][485/750]	BT 0.097 (1.284)	DT 0.002 (1.126)	loss nan (nan)	prob nan (nan)	GS 29.750 (29.750)	mem 59.892
Train: [6][490/750]	BT 11.010 (1.295)	DT 10.841 (1.136)	loss nan (nan)	prob nan (nan)	GS 34.156 (34.156)	mem 61.774
Train: [6][495/750]	BT 0.195 (1.283)	DT 0.005 (1.125)	loss nan (nan)	prob nan (nan)	GS 31.531 (31.531)	mem 61.907
Train: [6][500/750]	BT 0.233 (1.280)	DT 0.023 (1.121)	loss nan (nan)	prob nan (nan)	GS 33.766 (33.766)	mem 62.827
Train: [6][505/750]	BT 0.156 (1.298)	DT 0.002 (1.139)	loss nan (nan)	prob nan (nan)	GS 29.156 (29.156)	mem 58.603
Train: [6][510/750]	BT 0.140 (1.287)	DT 0.004 (1.128)	loss nan (nan)	prob nan (nan)	GS 31.172 (31.172)	mem 58.685
Train: [6][515/750]	BT 0.103 (1.293)	DT 0.002 (1.134)	loss nan (nan)	prob nan (nan)	GS 30.734 (30.734)	mem 60.510
Train: [6][520/750]	BT 5.440 (1.292)	DT 5.352 (1.134)	loss nan (nan)	prob nan (nan)	GS 33.516 (33.516)	mem 61.884
Train: [6][525/750]	BT 0.248 (1.281)	DT 0.002 (1.123)	loss nan (nan)	prob nan (nan)	GS 32.391 (32.391)	mem 62.139
Train: [6][530/750]	BT 0.159 (1.282)	DT 0.002 (1.124)	loss nan (nan)	prob nan (nan)	GS 31.891 (31.891)	mem 63.655
Train: [6][535/750]	BT 0.105 (1.284)	DT 0.009 (1.127)	loss nan (nan)	prob nan (nan)	GS 28.578 (28.578)	mem 64.561
Train: [6][540/750]	BT 1.670 (1.276)	DT 1.441 (1.119)	loss nan (nan)	prob nan (nan)	GS 28.766 (28.766)	mem 64.590
Train: [6][545/750]	BT 0.177 (1.284)	DT 0.010 (1.126)	loss nan (nan)	prob nan (nan)	GS 34.438 (34.438)	mem 64.589
Train: [6][550/750]	BT 0.109 (1.274)	DT 0.009 (1.116)	loss nan (nan)	prob nan (nan)	GS 31.484 (31.484)	mem 64.591
Train: [6][555/750]	BT 0.126 (1.267)	DT 0.006 (1.109)	loss nan (nan)	prob nan (nan)	GS 35.844 (35.844)	mem 64.692
Train: [6][560/750]	BT 0.123 (1.280)	DT 0.002 (1.122)	loss nan (nan)	prob nan (nan)	GS 34.453 (34.453)	mem 64.664
Train: [6][565/750]	BT 0.244 (1.270)	DT 0.001 (1.112)	loss nan (nan)	prob nan (nan)	GS 28.953 (28.953)	mem 64.706
Train: [6][570/750]	BT 0.089 (1.285)	DT 0.002 (1.127)	loss nan (nan)	prob nan (nan)	GS 32.938 (32.938)	mem 58.701
Train: [6][575/750]	BT 0.091 (1.275)	DT 0.002 (1.117)	loss nan (nan)	prob nan (nan)	GS 37.297 (37.297)	mem 58.806
Train: [6][580/750]	BT 11.659 (1.285)	DT 11.515 (1.127)	loss nan (nan)	prob nan (nan)	GS 27.484 (27.484)	mem 61.113
Train: [6][585/750]	BT 0.144 (1.275)	DT 0.016 (1.118)	loss nan (nan)	prob nan (nan)	GS 32.047 (32.047)	mem 61.210
Train: [6][590/750]	BT 0.217 (1.265)	DT 0.020 (1.108)	loss nan (nan)	prob nan (nan)	GS 35.531 (35.531)	mem 61.394
Train: [6][595/750]	BT 0.173 (1.275)	DT 0.002 (1.118)	loss nan (nan)	prob nan (nan)	GS 33.016 (33.016)	mem 63.452
Train: [6][600/750]	BT 0.122 (1.265)	DT 0.039 (1.109)	loss nan (nan)	prob nan (nan)	GS 31.578 (31.578)	mem 63.768
Train: [6][605/750]	BT 0.135 (1.276)	DT 0.011 (1.119)	loss nan (nan)	prob nan (nan)	GS 35.500 (35.500)	mem 59.047
Train: [6][610/750]	BT 0.148 (1.266)	DT 0.001 (1.110)	loss nan (nan)	prob nan (nan)	GS 34.766 (34.766)	mem 59.372
Train: [6][615/750]	BT 0.101 (1.257)	DT 0.002 (1.102)	loss nan (nan)	prob nan (nan)	GS 35.453 (35.453)	mem 59.287
Train: [6][620/750]	BT 0.089 (1.271)	DT 0.002 (1.116)	loss nan (nan)	prob nan (nan)	GS 33.000 (33.000)	mem 62.341
Train: [6][625/750]	BT 0.296 (1.263)	DT 0.008 (1.107)	loss nan (nan)	prob nan (nan)	GS 31.328 (31.328)	mem 62.736
Train: [6][630/750]	BT 0.167 (1.276)	DT 0.009 (1.120)	loss nan (nan)	prob nan (nan)	GS 36.016 (36.016)	mem 64.449
Train: [6][635/750]	BT 0.230 (1.267)	DT 0.001 (1.111)	loss nan (nan)	prob nan (nan)	GS 32.531 (32.531)	mem 64.490
Train: [6][640/750]	BT 11.970 (1.277)	DT 11.816 (1.121)	loss nan (nan)	prob nan (nan)	GS 34.141 (34.141)	mem 64.511
Train: [6][645/750]	BT 0.129 (1.268)	DT 0.009 (1.112)	loss nan (nan)	prob nan (nan)	GS 31.219 (31.219)	mem 64.527
Train: [6][650/750]	BT 0.206 (1.260)	DT 0.008 (1.104)	loss nan (nan)	prob nan (nan)	GS 34.797 (34.797)	mem 64.571
Train: [6][655/750]	BT 0.105 (1.269)	DT 0.003 (1.112)	loss nan (nan)	prob nan (nan)	GS 32.797 (32.797)	mem 64.524
Train: [6][660/750]	BT 0.173 (1.260)	DT 0.002 (1.104)	loss nan (nan)	prob nan (nan)	GS 34.078 (34.078)	mem 64.526
Train: [6][665/750]	BT 0.090 (1.270)	DT 0.002 (1.114)	loss nan (nan)	prob nan (nan)	GS 29.562 (29.562)	mem 58.618
Train: [6][670/750]	BT 0.117 (1.261)	DT 0.004 (1.106)	loss nan (nan)	prob nan (nan)	GS 33.703 (33.703)	mem 58.816
Train: [6][675/750]	BT 0.178 (1.253)	DT 0.002 (1.098)	loss nan (nan)	prob nan (nan)	GS 28.391 (28.391)	mem 58.999
Train: [6][680/750]	BT 0.095 (1.266)	DT 0.004 (1.111)	loss nan (nan)	prob nan (nan)	GS 34.812 (34.812)	mem 61.484
Train: [6][685/750]	BT 0.267 (1.258)	DT 0.010 (1.103)	loss nan (nan)	prob nan (nan)	GS 32.094 (32.094)	mem 61.782
Train: [6][690/750]	BT 0.133 (1.267)	DT 0.003 (1.111)	loss nan (nan)	prob nan (nan)	GS 36.188 (36.188)	mem 63.665
Train: [6][695/750]	BT 0.182 (1.259)	DT 0.004 (1.104)	loss nan (nan)	prob nan (nan)	GS 29.031 (29.031)	mem 63.774
Train: [6][700/750]	BT 13.581 (1.271)	DT 13.462 (1.115)	loss nan (nan)	prob nan (nan)	GS 36.797 (36.797)	mem 59.795
Train: [6][705/750]	BT 0.167 (1.263)	DT 0.004 (1.107)	loss nan (nan)	prob nan (nan)	GS 34.828 (34.828)	mem 60.209
arpack error, retry= 0
Train: [6][710/750]	BT 0.173 (1.255)	DT 0.004 (1.099)	loss nan (nan)	prob nan (nan)	GS 31.781 (31.781)	mem 60.150
Train: [6][715/750]	BT 0.131 (1.264)	DT 0.002 (1.108)	loss nan (nan)	prob nan (nan)	GS 34.938 (34.938)	mem 62.175
Train: [6][720/750]	BT 1.520 (1.258)	DT 1.397 (1.102)	loss nan (nan)	prob nan (nan)	GS 38.719 (38.719)	mem 62.692
Train: [6][725/750]	BT 0.115 (1.261)	DT 0.006 (1.106)	loss nan (nan)	prob nan (nan)	GS 27.547 (27.547)	mem 64.312
Train: [6][730/750]	BT 0.194 (1.256)	DT 0.006 (1.101)	loss nan (nan)	prob nan (nan)	GS 35.094 (35.094)	mem 64.346
Train: [6][735/750]	BT 0.137 (1.249)	DT 0.004 (1.094)	loss nan (nan)	prob nan (nan)	GS 32.641 (32.641)	mem 64.580
Train: [6][740/750]	BT 0.074 (1.254)	DT 0.001 (1.099)	loss nan (nan)	prob nan (nan)	GS 36.000 (36.000)	mem 38.254
Train: [6][745/750]	BT 0.135 (1.246)	DT 0.007 (1.092)	loss nan (nan)	prob nan (nan)	GS 27.312 (27.312)	mem 38.256
Train: [6][750/750]	BT 3.127 (1.244)	DT 3.038 (1.089)	loss nan (nan)	prob nan (nan)	GS 32.531 (32.531)	mem 32.266
Train: [6][755/750]	BT 0.082 (1.236)	DT 0.001 (1.082)	loss nan (nan)	prob nan (nan)	GS 35.219 (35.219)	mem 32.267
epoch 6, total time 933.63
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [7][1/750]	BT 27.016 (27.016)	DT 26.812 (26.812)	loss nan (nan)	prob nan (nan)	GS 31.047 (31.047)	mem 60.644
Train: [7][5/750]	BT 0.151 (6.014)	DT 0.004 (5.851)	loss nan (nan)	prob nan (nan)	GS 29.922 (29.922)	mem 61.128
Train: [7][10/750]	BT 0.151 (3.875)	DT 0.003 (3.701)	loss nan (nan)	prob nan (nan)	GS 35.094 (35.094)	mem 62.522
Train: [7][15/750]	BT 1.255 (2.710)	DT 1.173 (2.553)	loss nan (nan)	prob nan (nan)	GS 34.234 (34.234)	mem 62.550
Train: [7][20/750]	BT 0.251 (2.317)	DT 0.018 (2.152)	loss nan (nan)	prob nan (nan)	GS 34.672 (34.672)	mem 57.099
Train: [7][25/750]	BT 0.200 (2.154)	DT 0.001 (1.989)	loss nan (nan)	prob nan (nan)	GS 33.031 (33.031)	mem 58.361
Train: [7][30/750]	BT 0.213 (2.109)	DT 0.005 (1.945)	loss nan (nan)	prob nan (nan)	GS 36.641 (36.641)	mem 60.330
Train: [7][35/750]	BT 0.141 (1.935)	DT 0.007 (1.772)	loss nan (nan)	prob nan (nan)	GS 30.625 (30.625)	mem 61.178
Train: [7][40/750]	BT 6.452 (2.005)	DT 6.197 (1.844)	loss nan (nan)	prob nan (nan)	GS 31.312 (31.312)	mem 63.263
Train: [7][45/750]	BT 0.093 (1.796)	DT 0.003 (1.642)	loss nan (nan)	prob nan (nan)	GS 29.047 (29.047)	mem 63.376
Train: [7][50/750]	BT 8.909 (1.804)	DT 8.744 (1.653)	loss nan (nan)	prob nan (nan)	GS 30.797 (30.797)	mem 63.640
Train: [7][55/750]	BT 0.301 (1.705)	DT 0.003 (1.548)	loss nan (nan)	prob nan (nan)	GS 29.531 (29.531)	mem 63.652
Train: [7][60/750]	BT 0.112 (1.580)	DT 0.001 (1.420)	loss nan (nan)	prob nan (nan)	GS 33.594 (33.594)	mem 63.655
Train: [7][65/750]	BT 0.142 (1.666)	DT 0.002 (1.509)	loss nan (nan)	prob nan (nan)	GS 30.156 (30.156)	mem 63.643
Train: [7][70/750]	BT 0.180 (1.561)	DT 0.002 (1.402)	loss nan (nan)	prob nan (nan)	GS 34.438 (34.438)	mem 63.653
Train: [7][75/750]	BT 0.198 (1.603)	DT 0.002 (1.446)	loss nan (nan)	prob nan (nan)	GS 28.328 (28.328)	mem 63.969
Train: [7][80/750]	BT 0.077 (1.576)	DT 0.002 (1.419)	loss nan (nan)	prob nan (nan)	GS 33.516 (33.516)	mem 57.231
Train: [7][85/750]	BT 0.109 (1.490)	DT 0.003 (1.336)	loss nan (nan)	prob nan (nan)	GS 28.250 (28.250)	mem 57.555
Train: [7][90/750]	BT 0.097 (1.572)	DT 0.003 (1.420)	loss nan (nan)	prob nan (nan)	GS 30.922 (30.922)	mem 60.012
Train: [7][95/750]	BT 0.171 (1.499)	DT 0.005 (1.346)	loss nan (nan)	prob nan (nan)	GS 36.688 (36.688)	mem 60.108
Train: [7][100/750]	BT 0.089 (1.551)	DT 0.002 (1.401)	loss nan (nan)	prob nan (nan)	GS 33.906 (33.906)	mem 62.715
Train: [7][105/750]	BT 0.089 (1.483)	DT 0.002 (1.334)	loss nan (nan)	prob nan (nan)	GS 31.562 (31.562)	mem 62.883
Train: [7][110/750]	BT 19.004 (1.596)	DT 18.913 (1.446)	loss nan (nan)	prob nan (nan)	GS 35.109 (35.109)	mem 58.992
Train: [7][115/750]	BT 0.139 (1.533)	DT 0.016 (1.383)	loss nan (nan)	prob nan (nan)	GS 29.766 (29.766)	mem 59.118
Train: [7][120/750]	BT 0.093 (1.475)	DT 0.007 (1.326)	loss nan (nan)	prob nan (nan)	GS 29.875 (29.875)	mem 59.478
Train: [7][125/750]	BT 0.174 (1.518)	DT 0.002 (1.369)	loss nan (nan)	prob nan (nan)	GS 43.562 (43.562)	mem 61.967
Train: [7][130/750]	BT 0.085 (1.474)	DT 0.001 (1.327)	loss nan (nan)	prob nan (nan)	GS 30.062 (30.062)	mem 62.413
Train: [7][135/750]	BT 0.162 (1.497)	DT 0.002 (1.349)	loss nan (nan)	prob nan (nan)	GS 26.969 (26.969)	mem 64.343
Train: [7][140/750]	BT 0.183 (1.472)	DT 0.002 (1.324)	loss nan (nan)	prob nan (nan)	GS 33.125 (33.125)	mem 64.396
Train: [7][145/750]	BT 0.146 (1.427)	DT 0.003 (1.279)	loss nan (nan)	prob nan (nan)	GS 29.641 (29.641)	mem 64.478
Train: [7][150/750]	BT 4.305 (1.471)	DT 4.153 (1.321)	loss nan (nan)	prob nan (nan)	GS 33.375 (33.375)	mem 64.292
Train: [7][155/750]	BT 0.197 (1.428)	DT 0.003 (1.279)	loss nan (nan)	prob nan (nan)	GS 31.875 (31.875)	mem 64.382
Train: [7][160/750]	BT 0.127 (1.421)	DT 0.004 (1.271)	loss nan (nan)	prob nan (nan)	GS 33.375 (33.375)	mem 64.422
Train: [7][165/750]	BT 0.096 (1.410)	DT 0.007 (1.260)	loss nan (nan)	prob nan (nan)	GS 33.078 (33.078)	mem 64.388
Train: [7][170/750]	BT 10.350 (1.434)	DT 10.172 (1.283)	loss nan (nan)	prob nan (nan)	GS 36.344 (36.344)	mem 64.956
Train: [7][175/750]	BT 0.066 (1.438)	DT 0.002 (1.287)	loss nan (nan)	prob nan (nan)	GS 31.047 (31.047)	mem 58.841
Train: [7][180/750]	BT 0.213 (1.402)	DT 0.015 (1.251)	loss nan (nan)	prob nan (nan)	GS 34.188 (34.188)	mem 58.987
Train: [7][185/750]	BT 0.131 (1.391)	DT 0.002 (1.240)	loss nan (nan)	prob nan (nan)	GS 29.984 (29.984)	mem 59.859
Train: [7][190/750]	BT 0.098 (1.416)	DT 0.002 (1.265)	loss nan (nan)	prob nan (nan)	GS 38.266 (38.266)	mem 62.009
Train: [7][195/750]	BT 0.107 (1.392)	DT 0.003 (1.242)	loss nan (nan)	prob nan (nan)	GS 31.328 (31.328)	mem 62.394
Train: [7][200/750]	BT 0.132 (1.421)	DT 0.001 (1.272)	loss nan (nan)	prob nan (nan)	GS 32.922 (32.922)	mem 59.435
Train: [7][205/750]	BT 0.100 (1.389)	DT 0.004 (1.241)	loss nan (nan)	prob nan (nan)	GS 27.812 (27.812)	mem 58.156
Train: [7][210/750]	BT 12.348 (1.431)	DT 12.170 (1.284)	loss nan (nan)	prob nan (nan)	GS 34.391 (34.391)	mem 61.375
Train: [7][215/750]	BT 0.218 (1.402)	DT 0.002 (1.254)	loss nan (nan)	prob nan (nan)	GS 28.531 (28.531)	mem 61.651
Train: [7][220/750]	BT 0.176 (1.374)	DT 0.001 (1.227)	loss nan (nan)	prob nan (nan)	GS 31.969 (31.969)	mem 61.717
Train: [7][225/750]	BT 0.215 (1.409)	DT 0.010 (1.260)	loss nan (nan)	prob nan (nan)	GS 27.906 (27.906)	mem 64.380
Train: [7][230/750]	BT 0.143 (1.382)	DT 0.001 (1.233)	loss nan (nan)	prob nan (nan)	GS 29.891 (29.891)	mem 64.436
Train: [7][235/750]	BT 0.162 (1.408)	DT 0.025 (1.258)	loss nan (nan)	prob nan (nan)	GS 30.297 (30.297)	mem 64.488
Train: [7][240/750]	BT 0.190 (1.381)	DT 0.017 (1.232)	loss nan (nan)	prob nan (nan)	GS 30.031 (30.031)	mem 64.490
Train: [7][245/750]	BT 0.294 (1.357)	DT 0.031 (1.207)	loss nan (nan)	prob nan (nan)	GS 30.156 (30.156)	mem 64.537
Train: [7][250/750]	BT 0.102 (1.384)	DT 0.003 (1.234)	loss nan (nan)	prob nan (nan)	GS 37.453 (37.453)	mem 64.476
Train: [7][255/750]	BT 0.122 (1.360)	DT 0.001 (1.210)	loss nan (nan)	prob nan (nan)	GS 32.328 (32.328)	mem 64.559
Train: [7][260/750]	BT 0.116 (1.386)	DT 0.032 (1.236)	loss nan (nan)	prob nan (nan)	GS 31.500 (31.500)	mem 58.156
Train: [7][265/750]	BT 0.122 (1.362)	DT 0.002 (1.213)	loss nan (nan)	prob nan (nan)	GS 31.656 (31.656)	mem 58.319
Train: [7][270/750]	BT 12.422 (1.385)	DT 12.339 (1.236)	loss nan (nan)	prob nan (nan)	GS 36.969 (36.969)	mem 60.627
Train: [7][275/750]	BT 0.205 (1.363)	DT 0.030 (1.214)	loss nan (nan)	prob nan (nan)	GS 30.094 (30.094)	mem 60.796
Train: [7][280/750]	BT 0.112 (1.341)	DT 0.003 (1.192)	loss nan (nan)	prob nan (nan)	GS 35.922 (35.922)	mem 60.972
Train: [7][285/750]	BT 0.132 (1.360)	DT 0.001 (1.212)	loss nan (nan)	prob nan (nan)	GS 29.719 (29.719)	mem 63.140
Train: [7][290/750]	BT 0.169 (1.339)	DT 0.001 (1.191)	loss nan (nan)	prob nan (nan)	GS 35.359 (35.359)	mem 63.269
Train: [7][295/750]	BT 0.096 (1.368)	DT 0.001 (1.220)	loss nan (nan)	prob nan (nan)	GS 33.219 (33.219)	mem 59.177
Train: [7][300/750]	BT 0.133 (1.347)	DT 0.005 (1.200)	loss nan (nan)	prob nan (nan)	GS 34.094 (34.094)	mem 59.429
Train: [7][305/750]	BT 0.148 (1.328)	DT 0.020 (1.180)	loss nan (nan)	prob nan (nan)	GS 28.422 (28.422)	mem 59.763
Train: [7][310/750]	BT 0.067 (1.345)	DT 0.002 (1.198)	loss nan (nan)	prob nan (nan)	GS 37.922 (37.922)	mem 62.192
Train: [7][315/750]	BT 0.206 (1.326)	DT 0.002 (1.180)	loss nan (nan)	prob nan (nan)	GS 32.938 (32.938)	mem 62.511
Train: [7][320/750]	BT 0.139 (1.342)	DT 0.002 (1.196)	loss nan (nan)	prob nan (nan)	GS 33.453 (33.453)	mem 64.530
Train: [7][325/750]	BT 0.274 (1.324)	DT 0.003 (1.177)	loss nan (nan)	prob nan (nan)	GS 31.031 (31.031)	mem 64.450
Train: [7][330/750]	BT 11.274 (1.340)	DT 11.058 (1.193)	loss nan (nan)	prob nan (nan)	GS 27.812 (27.812)	mem 64.508
Train: [7][335/750]	BT 0.129 (1.323)	DT 0.004 (1.176)	loss nan (nan)	prob nan (nan)	GS 28.250 (28.250)	mem 64.604
Train: [7][340/750]	BT 0.103 (1.319)	DT 0.002 (1.171)	loss nan (nan)	prob nan (nan)	GS 36.016 (36.016)	mem 64.562
Train: [7][345/750]	BT 0.116 (1.322)	DT 0.002 (1.173)	loss nan (nan)	prob nan (nan)	GS 35.469 (35.469)	mem 64.591
Train: [7][350/750]	BT 0.174 (1.332)	DT 0.016 (1.183)	loss nan (nan)	prob nan (nan)	GS 32.188 (32.188)	mem 64.797
Train: [7][355/750]	BT 0.149 (1.324)	DT 0.002 (1.176)	loss nan (nan)	prob nan (nan)	GS 30.578 (30.578)	mem 64.451
Train: [7][360/750]	BT 8.473 (1.332)	DT 8.348 (1.183)	loss nan (nan)	prob nan (nan)	GS 32.047 (32.047)	mem 59.038
Train: [7][365/750]	BT 0.203 (1.315)	DT 0.002 (1.167)	loss nan (nan)	prob nan (nan)	GS 28.125 (28.125)	mem 59.077
Train: [7][370/750]	BT 0.185 (1.316)	DT 0.007 (1.168)	loss nan (nan)	prob nan (nan)	GS 31.359 (31.359)	mem 60.444
Train: [7][375/750]	BT 0.129 (1.308)	DT 0.010 (1.160)	loss nan (nan)	prob nan (nan)	GS 31.922 (31.922)	mem 61.128
Train: [7][380/750]	BT 0.176 (1.319)	DT 0.002 (1.171)	loss nan (nan)	prob nan (nan)	GS 37.562 (37.562)	mem 62.961
Train: [7][385/750]	BT 0.131 (1.309)	DT 0.004 (1.161)	loss nan (nan)	prob nan (nan)	GS 31.125 (31.125)	mem 63.262
Train: [7][390/750]	BT 9.195 (1.318)	DT 9.063 (1.170)	loss nan (nan)	prob nan (nan)	GS 29.984 (29.984)	mem 58.141
Train: [7][395/750]	BT 0.117 (1.303)	DT 0.013 (1.155)	loss nan (nan)	prob nan (nan)	GS 33.156 (33.156)	mem 58.343
Train: [7][400/750]	BT 0.135 (1.297)	DT 0.008 (1.149)	loss nan (nan)	prob nan (nan)	GS 39.266 (39.266)	mem 59.075
Train: [7][405/750]	BT 0.112 (1.302)	DT 0.005 (1.154)	loss nan (nan)	prob nan (nan)	GS 34.094 (34.094)	mem 60.929
Train: [7][410/750]	BT 0.165 (1.292)	DT 0.003 (1.145)	loss nan (nan)	prob nan (nan)	GS 31.234 (31.234)	mem 61.615
Train: [7][415/750]	BT 0.105 (1.299)	DT 0.004 (1.151)	loss nan (nan)	prob nan (nan)	GS 31.859 (31.859)	mem 63.311
Train: [7][420/750]	BT 3.956 (1.293)	DT 3.819 (1.147)	loss nan (nan)	prob nan (nan)	GS 28.062 (28.062)	mem 64.192
Train: [7][425/750]	BT 0.099 (1.279)	DT 0.002 (1.133)	loss nan (nan)	prob nan (nan)	GS 32.266 (32.266)	mem 64.264
Train: [7][430/750]	BT 0.107 (1.288)	DT 0.001 (1.141)	loss nan (nan)	prob nan (nan)	GS 29.375 (29.375)	mem 64.576
Train: [7][435/750]	BT 0.302 (1.285)	DT 0.001 (1.138)	loss nan (nan)	prob nan (nan)	GS 30.000 (30.000)	mem 64.779
Train: [7][440/750]	BT 0.086 (1.288)	DT 0.004 (1.141)	loss nan (nan)	prob nan (nan)	GS 34.891 (34.891)	mem 64.553
Train: [7][445/750]	BT 0.139 (1.290)	DT 0.004 (1.143)	loss nan (nan)	prob nan (nan)	GS 34.828 (34.828)	mem 64.554
Train: [7][450/750]	BT 6.867 (1.293)	DT 6.669 (1.145)	loss nan (nan)	prob nan (nan)	GS 33.125 (33.125)	mem 64.632
Train: [7][455/750]	BT 0.200 (1.281)	DT 0.009 (1.133)	loss nan (nan)	prob nan (nan)	GS 30.609 (30.609)	mem 64.606
Train: [7][460/750]	BT 0.196 (1.280)	DT 0.028 (1.132)	loss nan (nan)	prob nan (nan)	GS 36.156 (36.156)	mem 59.637
Train: [7][465/750]	BT 0.198 (1.280)	DT 0.002 (1.132)	loss nan (nan)	prob nan (nan)	GS 32.797 (32.797)	mem 58.870
Train: [7][470/750]	BT 0.091 (1.283)	DT 0.001 (1.134)	loss nan (nan)	prob nan (nan)	GS 33.453 (33.453)	mem 60.136
Train: [7][475/750]	BT 0.146 (1.278)	DT 0.005 (1.130)	loss nan (nan)	prob nan (nan)	GS 30.578 (30.578)	mem 60.998
Train: [7][480/750]	BT 9.330 (1.286)	DT 9.172 (1.138)	loss nan (nan)	prob nan (nan)	GS 34.062 (34.062)	mem 62.697
Train: [7][485/750]	BT 0.312 (1.275)	DT 0.002 (1.126)	loss nan (nan)	prob nan (nan)	GS 40.016 (40.016)	mem 62.962
Train: [7][490/750]	BT 0.105 (1.276)	DT 0.006 (1.127)	loss nan (nan)	prob nan (nan)	GS 33.906 (33.906)	mem 63.419
Train: [7][495/750]	BT 0.187 (1.280)	DT 0.003 (1.131)	loss nan (nan)	prob nan (nan)	GS 29.781 (29.781)	mem 59.024
Train: [7][500/750]	BT 0.283 (1.269)	DT 0.004 (1.121)	loss nan (nan)	prob nan (nan)	GS 36.609 (36.609)	mem 59.257
Train: [7][505/750]	BT 0.212 (1.279)	DT 0.002 (1.131)	loss nan (nan)	prob nan (nan)	GS 32.375 (32.375)	mem 61.444
Train: [7][510/750]	BT 1.084 (1.270)	DT 0.976 (1.122)	loss nan (nan)	prob nan (nan)	GS 32.828 (32.828)	mem 61.953
Train: [7][515/750]	BT 0.251 (1.269)	DT 0.002 (1.119)	loss nan (nan)	prob nan (nan)	GS 31.469 (31.469)	mem 63.052
Train: [7][520/750]	BT 0.109 (1.280)	DT 0.007 (1.130)	loss nan (nan)	prob nan (nan)	GS 30.703 (30.703)	mem 64.509
Train: [7][525/750]	BT 0.188 (1.269)	DT 0.002 (1.119)	loss nan (nan)	prob nan (nan)	GS 29.812 (29.812)	mem 64.588
Train: [7][530/750]	BT 0.134 (1.286)	DT 0.005 (1.136)	loss nan (nan)	prob nan (nan)	GS 32.453 (32.453)	mem 64.621
Train: [7][535/750]	BT 0.206 (1.276)	DT 0.024 (1.126)	loss nan (nan)	prob nan (nan)	GS 33.000 (33.000)	mem 64.657
Train: [7][540/750]	BT 8.924 (1.282)	DT 8.704 (1.131)	loss nan (nan)	prob nan (nan)	GS 30.875 (30.875)	mem 64.618
Train: [7][545/750]	BT 0.171 (1.272)	DT 0.001 (1.121)	loss nan (nan)	prob nan (nan)	GS 27.469 (27.469)	mem 64.711
Train: [7][550/750]	BT 1.784 (1.265)	DT 1.610 (1.114)	loss nan (nan)	prob nan (nan)	GS 33.797 (33.797)	mem 64.662
Train: [7][555/750]	BT 0.084 (1.274)	DT 0.002 (1.122)	loss nan (nan)	prob nan (nan)	GS 33.281 (33.281)	mem 58.257
Train: [7][560/750]	BT 0.156 (1.265)	DT 0.011 (1.113)	loss nan (nan)	prob nan (nan)	GS 33.359 (33.359)	mem 58.652
Train: [7][565/750]	BT 0.254 (1.272)	DT 0.022 (1.121)	loss nan (nan)	prob nan (nan)	GS 29.797 (29.797)	mem 60.047
Train: [7][570/750]	BT 7.596 (1.276)	DT 7.473 (1.124)	loss nan (nan)	prob nan (nan)	GS 33.047 (33.047)	mem 61.534
Train: [7][575/750]	BT 0.232 (1.266)	DT 0.008 (1.114)	loss nan (nan)	prob nan (nan)	GS 30.172 (30.172)	mem 61.674
Train: [7][580/750]	BT 0.103 (1.267)	DT 0.005 (1.115)	loss nan (nan)	prob nan (nan)	GS 36.453 (36.453)	mem 62.733
Train: [7][585/750]	BT 0.128 (1.278)	DT 0.005 (1.126)	loss nan (nan)	prob nan (nan)	GS 27.875 (27.875)	mem 58.367
Train: [7][590/750]	BT 0.167 (1.273)	DT 0.013 (1.121)	loss nan (nan)	prob nan (nan)	GS 35.688 (35.688)	mem 59.018
Train: [7][595/750]	BT 0.151 (1.283)	DT 0.002 (1.130)	loss nan (nan)	prob nan (nan)	GS 32.844 (32.844)	mem 61.681
Train: [7][600/750]	BT 0.827 (1.274)	DT 0.652 (1.122)	loss nan (nan)	prob nan (nan)	GS 32.594 (32.594)	mem 61.982
Train: [7][605/750]	BT 0.152 (1.265)	DT 0.029 (1.113)	loss nan (nan)	prob nan (nan)	GS 28.203 (28.203)	mem 62.367
Train: [7][610/750]	BT 0.163 (1.282)	DT 0.004 (1.130)	loss nan (nan)	prob nan (nan)	GS 34.281 (34.281)	mem 64.527
Train: [7][615/750]	BT 0.145 (1.272)	DT 0.001 (1.121)	loss nan (nan)	prob nan (nan)	GS 30.172 (30.172)	mem 64.560
Train: [7][620/750]	BT 0.111 (1.285)	DT 0.003 (1.133)	loss nan (nan)	prob nan (nan)	GS 35.109 (35.109)	mem 64.582
Train: [7][625/750]	BT 0.101 (1.276)	DT 0.002 (1.124)	loss nan (nan)	prob nan (nan)	GS 32.062 (32.062)	mem 64.613
Train: [7][630/750]	BT 11.263 (1.284)	DT 11.103 (1.133)	loss nan (nan)	prob nan (nan)	GS 34.375 (34.375)	mem 64.519
Train: [7][635/750]	BT 0.125 (1.276)	DT 0.011 (1.124)	loss nan (nan)	prob nan (nan)	GS 32.266 (32.266)	mem 64.523
Train: [7][640/750]	BT 0.127 (1.267)	DT 0.001 (1.115)	loss nan (nan)	prob nan (nan)	GS 32.938 (32.938)	mem 64.562
Train: [7][645/750]	BT 0.165 (1.277)	DT 0.004 (1.125)	loss nan (nan)	prob nan (nan)	GS 28.094 (28.094)	mem 58.541
Train: [7][650/750]	BT 0.084 (1.269)	DT 0.003 (1.117)	loss nan (nan)	prob nan (nan)	GS 34.203 (34.203)	mem 58.647
Train: [7][655/750]	BT 0.116 (1.284)	DT 0.002 (1.132)	loss nan (nan)	prob nan (nan)	GS 28.859 (28.859)	mem 61.907
Train: [7][660/750]	BT 0.127 (1.275)	DT 0.011 (1.123)	loss nan (nan)	prob nan (nan)	GS 33.219 (33.219)	mem 61.993
Train: [7][665/750]	BT 0.175 (1.267)	DT 0.003 (1.115)	loss nan (nan)	prob nan (nan)	GS 32.328 (32.328)	mem 61.981
Train: [7][670/750]	BT 0.145 (1.278)	DT 0.003 (1.126)	loss nan (nan)	prob nan (nan)	GS 33.094 (33.094)	mem 63.397
Train: [7][675/750]	BT 0.286 (1.269)	DT 0.002 (1.118)	loss nan (nan)	prob nan (nan)	GS 35.125 (35.125)	mem 62.157
Train: [7][680/750]	BT 0.116 (1.283)	DT 0.001 (1.131)	loss nan (nan)	prob nan (nan)	GS 37.578 (37.578)	mem 60.486
Train: [7][685/750]	BT 0.186 (1.275)	DT 0.007 (1.123)	loss nan (nan)	prob nan (nan)	GS 29.609 (29.609)	mem 60.560
Train: [7][690/750]	BT 13.312 (1.286)	DT 13.171 (1.134)	loss nan (nan)	prob nan (nan)	GS 32.078 (32.078)	mem 63.423
Train: [7][695/750]	BT 0.109 (1.277)	DT 0.004 (1.126)	loss nan (nan)	prob nan (nan)	GS 32.172 (32.172)	mem 63.465
Train: [7][700/750]	BT 0.212 (1.269)	DT 0.017 (1.118)	loss nan (nan)	prob nan (nan)	GS 34.156 (34.156)	mem 63.654
Train: [7][705/750]	BT 0.100 (1.276)	DT 0.001 (1.125)	loss nan (nan)	prob nan (nan)	GS 29.609 (29.609)	mem 64.632
arpack error, retry= 0
Train: [7][710/750]	BT 1.112 (1.270)	DT 0.901 (1.118)	loss nan (nan)	prob nan (nan)	GS 35.234 (35.234)	mem 64.677
Train: [7][715/750]	BT 0.164 (1.284)	DT 0.010 (1.131)	loss nan (nan)	prob nan (nan)	GS 34.000 (34.000)	mem 64.691
Train: [7][720/750]	BT 0.161 (1.276)	DT 0.029 (1.124)	loss nan (nan)	prob nan (nan)	GS 35.031 (35.031)	mem 64.628
Train: [7][725/750]	BT 0.218 (1.268)	DT 0.001 (1.116)	loss nan (nan)	prob nan (nan)	GS 29.484 (29.484)	mem 64.624
Train: [7][730/750]	BT 0.170 (1.275)	DT 0.004 (1.122)	loss nan (nan)	prob nan (nan)	GS 36.188 (36.188)	mem 64.355
Train: [7][735/750]	BT 0.105 (1.267)	DT 0.001 (1.115)	loss nan (nan)	prob nan (nan)	GS 34.266 (34.266)	mem 64.384
Train: [7][740/750]	BT 0.066 (1.271)	DT 0.001 (1.119)	loss nan (nan)	prob nan (nan)	GS 36.875 (36.875)	mem 27.033
Train: [7][745/750]	BT 0.071 (1.263)	DT 0.002 (1.112)	loss nan (nan)	prob nan (nan)	GS 30.594 (30.594)	mem 27.219
Train: [7][750/750]	BT 1.778 (1.257)	DT 1.667 (1.106)	loss nan (nan)	prob nan (nan)	GS 33.688 (33.688)	mem 28.033
Train: [7][755/750]	BT 0.071 (1.250)	DT 0.001 (1.099)	loss nan (nan)	prob nan (nan)	GS 24.219 (24.219)	mem 28.143
epoch 7, total time 943.68
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [8][1/750]	BT 28.191 (28.191)	DT 28.076 (28.076)	loss nan (nan)	prob nan (nan)	GS 35.938 (35.938)	mem 60.069
Train: [8][5/750]	BT 0.184 (5.742)	DT 0.011 (5.620)	loss nan (nan)	prob nan (nan)	GS 33.984 (33.984)	mem 60.178
Train: [8][10/750]	BT 0.263 (3.228)	DT 0.025 (3.064)	loss nan (nan)	prob nan (nan)	GS 31.969 (31.969)	mem 60.526
Train: [8][15/750]	BT 0.562 (2.878)	DT 0.462 (2.703)	loss nan (nan)	prob nan (nan)	GS 38.969 (38.969)	mem 62.812
Train: [8][20/750]	BT 1.498 (2.437)	DT 1.394 (2.276)	loss nan (nan)	prob nan (nan)	GS 34.734 (34.734)	mem 63.608
Train: [8][25/750]	BT 2.029 (2.060)	DT 1.888 (1.897)	loss nan (nan)	prob nan (nan)	GS 31.828 (31.828)	mem 64.074
Train: [8][30/750]	BT 0.212 (2.100)	DT 0.003 (1.930)	loss nan (nan)	prob nan (nan)	GS 34.062 (34.062)	mem 64.153
Train: [8][35/750]	BT 0.123 (1.820)	DT 0.002 (1.655)	loss nan (nan)	prob nan (nan)	GS 34.250 (34.250)	mem 64.084
Train: [8][40/750]	BT 0.153 (2.000)	DT 0.012 (1.834)	loss nan (nan)	prob nan (nan)	GS 33.547 (33.547)	mem 64.191
Train: [8][45/750]	BT 0.093 (1.798)	DT 0.003 (1.632)	loss nan (nan)	prob nan (nan)	GS 35.266 (35.266)	mem 64.193
Train: [8][50/750]	BT 3.359 (1.699)	DT 3.038 (1.529)	loss nan (nan)	prob nan (nan)	GS 32.484 (32.484)	mem 64.202
Train: [8][55/750]	BT 0.196 (1.712)	DT 0.007 (1.540)	loss nan (nan)	prob nan (nan)	GS 28.719 (28.719)	mem 64.262
Train: [8][60/750]	BT 0.363 (1.600)	DT 0.014 (1.423)	loss nan (nan)	prob nan (nan)	GS 34.312 (34.312)	mem 62.058
Train: [8][65/750]	BT 0.100 (1.705)	DT 0.003 (1.529)	loss nan (nan)	prob nan (nan)	GS 35.656 (35.656)	mem 59.336
Train: [8][70/750]	BT 0.081 (1.632)	DT 0.001 (1.460)	loss nan (nan)	prob nan (nan)	GS 37.094 (37.094)	mem 60.008
Train: [8][75/750]	BT 0.180 (1.532)	DT 0.010 (1.363)	loss nan (nan)	prob nan (nan)	GS 29.734 (29.734)	mem 60.191
Train: [8][80/750]	BT 4.092 (1.604)	DT 3.931 (1.438)	loss nan (nan)	prob nan (nan)	GS 33.656 (33.656)	mem 62.843
Train: [8][85/750]	BT 0.180 (1.518)	DT 0.012 (1.354)	loss nan (nan)	prob nan (nan)	GS 30.516 (30.516)	mem 62.810
Train: [8][90/750]	BT 0.191 (1.537)	DT 0.004 (1.370)	loss nan (nan)	prob nan (nan)	GS 32.641 (32.641)	mem 60.769
Train: [8][95/750]	BT 0.093 (1.480)	DT 0.002 (1.313)	loss nan (nan)	prob nan (nan)	GS 31.953 (31.953)	mem 58.914
Train: [8][100/750]	BT 7.438 (1.540)	DT 7.302 (1.376)	loss nan (nan)	prob nan (nan)	GS 31.312 (31.312)	mem 60.733
Train: [8][105/750]	BT 0.113 (1.493)	DT 0.017 (1.330)	loss nan (nan)	prob nan (nan)	GS 32.047 (32.047)	mem 61.298
Train: [8][110/750]	BT 0.777 (1.438)	DT 0.641 (1.276)	loss nan (nan)	prob nan (nan)	GS 38.094 (38.094)	mem 61.849
Train: [8][115/750]	BT 0.121 (1.469)	DT 0.002 (1.309)	loss nan (nan)	prob nan (nan)	GS 31.969 (31.969)	mem 63.816
Train: [8][120/750]	BT 0.120 (1.414)	DT 0.003 (1.255)	loss nan (nan)	prob nan (nan)	GS 38.797 (38.797)	mem 63.980
Train: [8][125/750]	BT 0.108 (1.504)	DT 0.001 (1.346)	loss nan (nan)	prob nan (nan)	GS 32.594 (32.594)	mem 64.352
Train: [8][130/750]	BT 0.206 (1.451)	DT 0.017 (1.294)	loss nan (nan)	prob nan (nan)	GS 31.984 (31.984)	mem 64.356
Train: [8][135/750]	BT 0.147 (1.403)	DT 0.001 (1.246)	loss nan (nan)	prob nan (nan)	GS 26.469 (26.469)	mem 64.419
Train: [8][140/750]	BT 0.153 (1.432)	DT 0.006 (1.275)	loss nan (nan)	prob nan (nan)	GS 33.516 (33.516)	mem 64.372
Train: [8][145/750]	BT 0.149 (1.390)	DT 0.009 (1.231)	loss nan (nan)	prob nan (nan)	GS 25.562 (25.562)	mem 64.335
Train: [8][150/750]	BT 0.129 (1.421)	DT 0.002 (1.261)	loss nan (nan)	prob nan (nan)	GS 29.250 (29.250)	mem 57.958
Train: [8][155/750]	BT 0.205 (1.381)	DT 0.003 (1.221)	loss nan (nan)	prob nan (nan)	GS 30.797 (30.797)	mem 58.036
Train: [8][160/750]	BT 7.796 (1.391)	DT 7.698 (1.231)	loss nan (nan)	prob nan (nan)	GS 32.516 (32.516)	mem 59.670
Train: [8][165/750]	BT 0.198 (1.361)	DT 0.029 (1.201)	loss nan (nan)	prob nan (nan)	GS 33.609 (33.609)	mem 59.879
Train: [8][170/750]	BT 0.226 (1.327)	DT 0.011 (1.166)	loss nan (nan)	prob nan (nan)	GS 31.500 (31.500)	mem 60.042
Train: [8][175/750]	BT 0.120 (1.365)	DT 0.026 (1.204)	loss nan (nan)	prob nan (nan)	GS 29.500 (29.500)	mem 62.003
Train: [8][180/750]	BT 0.987 (1.347)	DT 0.834 (1.185)	loss nan (nan)	prob nan (nan)	GS 37.031 (37.031)	mem 62.846
Train: [8][185/750]	BT 0.099 (1.388)	DT 0.002 (1.228)	loss nan (nan)	prob nan (nan)	GS 35.828 (35.828)	mem 58.282
Train: [8][190/750]	BT 0.223 (1.355)	DT 0.001 (1.196)	loss nan (nan)	prob nan (nan)	GS 33.688 (33.688)	mem 58.650
Train: [8][195/750]	BT 0.122 (1.360)	DT 0.004 (1.201)	loss nan (nan)	prob nan (nan)	GS 31.078 (31.078)	mem 59.953
Train: [8][200/750]	BT 1.596 (1.365)	DT 1.368 (1.206)	loss nan (nan)	prob nan (nan)	GS 36.562 (36.562)	mem 61.531
Train: [8][205/750]	BT 0.128 (1.360)	DT 0.012 (1.201)	loss nan (nan)	prob nan (nan)	GS 38.828 (38.828)	mem 62.595
Train: [8][210/750]	BT 0.119 (1.363)	DT 0.002 (1.205)	loss nan (nan)	prob nan (nan)	GS 32.406 (32.406)	mem 64.139
Train: [8][215/750]	BT 0.106 (1.335)	DT 0.004 (1.177)	loss nan (nan)	prob nan (nan)	GS 28.906 (28.906)	mem 64.158
Train: [8][220/750]	BT 6.176 (1.358)	DT 6.072 (1.200)	loss nan (nan)	prob nan (nan)	GS 34.000 (34.000)	mem 64.446
Train: [8][225/750]	BT 0.286 (1.331)	DT 0.017 (1.174)	loss nan (nan)	prob nan (nan)	GS 34.359 (34.359)	mem 64.451
Train: [8][230/750]	BT 0.147 (1.348)	DT 0.007 (1.190)	loss nan (nan)	prob nan (nan)	GS 33.484 (33.484)	mem 64.468
Train: [8][235/750]	BT 0.116 (1.330)	DT 0.003 (1.172)	loss nan (nan)	prob nan (nan)	GS 36.609 (36.609)	mem 64.346
Train: [8][240/750]	BT 10.597 (1.351)	DT 10.456 (1.192)	loss nan (nan)	prob nan (nan)	GS 33.141 (33.141)	mem 64.500
Train: [8][245/750]	BT 0.146 (1.327)	DT 0.005 (1.167)	loss nan (nan)	prob nan (nan)	GS 30.094 (30.094)	mem 64.524
Train: [8][250/750]	BT 0.170 (1.306)	DT 0.001 (1.147)	loss nan (nan)	prob nan (nan)	GS 33.562 (33.562)	mem 64.462
Train: [8][255/750]	BT 0.188 (1.322)	DT 0.013 (1.162)	loss nan (nan)	prob nan (nan)	GS 34.641 (34.641)	mem 58.805
Train: [8][260/750]	BT 1.795 (1.314)	DT 1.659 (1.154)	loss nan (nan)	prob nan (nan)	GS 35.672 (35.672)	mem 59.652
Train: [8][265/750]	BT 0.102 (1.328)	DT 0.002 (1.169)	loss nan (nan)	prob nan (nan)	GS 29.844 (29.844)	mem 61.730
Train: [8][270/750]	BT 0.152 (1.315)	DT 0.015 (1.156)	loss nan (nan)	prob nan (nan)	GS 33.188 (33.188)	mem 62.169
Train: [8][275/750]	BT 0.219 (1.294)	DT 0.002 (1.135)	loss nan (nan)	prob nan (nan)	GS 33.812 (33.812)	mem 62.428
Train: [8][280/750]	BT 0.081 (1.318)	DT 0.001 (1.160)	loss nan (nan)	prob nan (nan)	GS 32.156 (32.156)	mem 58.692
Train: [8][285/750]	BT 0.115 (1.297)	DT 0.006 (1.140)	loss nan (nan)	prob nan (nan)	GS 33.625 (33.625)	mem 58.022
Train: [8][290/750]	BT 0.171 (1.319)	DT 0.001 (1.162)	loss nan (nan)	prob nan (nan)	GS 34.719 (34.719)	mem 60.576
Train: [8][295/750]	BT 0.152 (1.311)	DT 0.002 (1.154)	loss nan (nan)	prob nan (nan)	GS 31.312 (31.312)	mem 61.236
Train: [8][300/750]	BT 8.427 (1.319)	DT 8.293 (1.163)	loss nan (nan)	prob nan (nan)	GS 32.547 (32.547)	mem 63.565
Train: [8][305/750]	BT 0.230 (1.302)	DT 0.008 (1.146)	loss nan (nan)	prob nan (nan)	GS 31.172 (31.172)	mem 63.516
Train: [8][310/750]	BT 0.241 (1.302)	DT 0.007 (1.144)	loss nan (nan)	prob nan (nan)	GS 35.281 (35.281)	mem 64.405
Train: [8][315/750]	BT 0.121 (1.307)	DT 0.003 (1.149)	loss nan (nan)	prob nan (nan)	GS 30.500 (30.500)	mem 64.778
Train: [8][320/750]	BT 0.198 (1.311)	DT 0.004 (1.153)	loss nan (nan)	prob nan (nan)	GS 29.734 (29.734)	mem 64.525
Train: [8][325/750]	BT 0.189 (1.315)	DT 0.002 (1.156)	loss nan (nan)	prob nan (nan)	GS 29.656 (29.656)	mem 64.540
Train: [8][330/750]	BT 4.224 (1.311)	DT 4.127 (1.151)	loss nan (nan)	prob nan (nan)	GS 33.938 (33.938)	mem 64.573
Train: [8][335/750]	BT 0.163 (1.294)	DT 0.003 (1.134)	loss nan (nan)	prob nan (nan)	GS 34.781 (34.781)	mem 64.573
Train: [8][340/750]	BT 0.209 (1.303)	DT 0.003 (1.142)	loss nan (nan)	prob nan (nan)	GS 31.625 (31.625)	mem 64.516
Train: [8][345/750]	BT 0.174 (1.297)	DT 0.003 (1.136)	loss nan (nan)	prob nan (nan)	GS 35.219 (35.219)	mem 64.558
Train: [8][350/750]	BT 0.142 (1.301)	DT 0.008 (1.141)	loss nan (nan)	prob nan (nan)	GS 32.172 (32.172)	mem 58.760
Train: [8][355/750]	BT 0.089 (1.302)	DT 0.001 (1.142)	loss nan (nan)	prob nan (nan)	GS 35.125 (35.125)	mem 60.124
Train: [8][360/750]	BT 7.099 (1.305)	DT 7.010 (1.146)	loss nan (nan)	prob nan (nan)	GS 34.859 (34.859)	mem 61.560
Train: [8][365/750]	BT 0.246 (1.290)	DT 0.003 (1.130)	loss nan (nan)	prob nan (nan)	GS 28.281 (28.281)	mem 61.858
Train: [8][370/750]	BT 0.085 (1.286)	DT 0.001 (1.126)	loss nan (nan)	prob nan (nan)	GS 36.125 (36.125)	mem 62.808
Train: [8][375/750]	BT 0.266 (1.291)	DT 0.016 (1.131)	loss nan (nan)	prob nan (nan)	GS 26.953 (26.953)	mem 63.762
Train: [8][380/750]	BT 0.098 (1.286)	DT 0.008 (1.127)	loss nan (nan)	prob nan (nan)	GS 31.125 (31.125)	mem 58.153
Train: [8][385/750]	BT 0.105 (1.309)	DT 0.001 (1.150)	loss nan (nan)	prob nan (nan)	GS 33.188 (33.188)	mem 61.443
Train: [8][390/750]	BT 0.095 (1.294)	DT 0.002 (1.136)	loss nan (nan)	prob nan (nan)	GS 28.906 (28.906)	mem 61.753
Train: [8][395/750]	BT 0.160 (1.279)	DT 0.002 (1.121)	loss nan (nan)	prob nan (nan)	GS 31.562 (31.562)	mem 61.892
Train: [8][400/750]	BT 0.088 (1.294)	DT 0.001 (1.136)	loss nan (nan)	prob nan (nan)	GS 33.172 (33.172)	mem 64.110
Train: [8][405/750]	BT 0.198 (1.280)	DT 0.009 (1.122)	loss nan (nan)	prob nan (nan)	GS 29.438 (29.438)	mem 64.279
Train: [8][410/750]	BT 0.091 (1.311)	DT 0.001 (1.153)	loss nan (nan)	prob nan (nan)	GS 36.297 (36.297)	mem 64.532
Train: [8][415/750]	BT 0.207 (1.298)	DT 0.003 (1.139)	loss nan (nan)	prob nan (nan)	GS 33.359 (33.359)	mem 64.463
Train: [8][420/750]	BT 11.770 (1.312)	DT 11.581 (1.153)	loss nan (nan)	prob nan (nan)	GS 36.875 (36.875)	mem 64.556
Train: [8][425/750]	BT 0.246 (1.299)	DT 0.002 (1.140)	loss nan (nan)	prob nan (nan)	GS 29.453 (29.453)	mem 64.676
Train: [8][430/750]	BT 0.190 (1.286)	DT 0.002 (1.127)	loss nan (nan)	prob nan (nan)	GS 31.562 (31.562)	mem 64.470
Train: [8][435/750]	BT 0.086 (1.299)	DT 0.006 (1.140)	loss nan (nan)	prob nan (nan)	GS 29.594 (29.594)	mem 64.559
Train: [8][440/750]	BT 0.149 (1.286)	DT 0.005 (1.127)	loss nan (nan)	prob nan (nan)	GS 36.562 (36.562)	mem 64.562
Train: [8][445/750]	BT 0.113 (1.304)	DT 0.001 (1.145)	loss nan (nan)	prob nan (nan)	GS 29.938 (29.938)	mem 59.516
Train: [8][450/750]	BT 0.185 (1.291)	DT 0.029 (1.133)	loss nan (nan)	prob nan (nan)	GS 33.500 (33.500)	mem 59.738
Train: [8][455/750]	BT 0.086 (1.279)	DT 0.004 (1.120)	loss nan (nan)	prob nan (nan)	GS 30.359 (30.359)	mem 60.010
Train: [8][460/750]	BT 0.125 (1.291)	DT 0.002 (1.133)	loss nan (nan)	prob nan (nan)	GS 34.172 (34.172)	mem 61.874
Train: [8][465/750]	BT 0.129 (1.278)	DT 0.002 (1.120)	loss nan (nan)	prob nan (nan)	GS 32.203 (32.203)	mem 62.050
Train: [8][470/750]	BT 0.133 (1.293)	DT 0.005 (1.135)	loss nan (nan)	prob nan (nan)	GS 31.031 (31.031)	mem 63.826
Train: [8][475/750]	BT 0.175 (1.281)	DT 0.011 (1.123)	loss nan (nan)	prob nan (nan)	GS 30.016 (30.016)	mem 63.458
Train: [8][480/750]	BT 12.641 (1.295)	DT 12.515 (1.138)	loss nan (nan)	prob nan (nan)	GS 29.406 (29.406)	mem 59.907
Train: [8][485/750]	BT 0.158 (1.283)	DT 0.012 (1.126)	loss nan (nan)	prob nan (nan)	GS 27.281 (27.281)	mem 60.091
Train: [8][490/750]	BT 1.383 (1.274)	DT 1.239 (1.117)	loss nan (nan)	prob nan (nan)	GS 31.047 (31.047)	mem 60.524
Train: [8][495/750]	BT 0.125 (1.286)	DT 0.003 (1.129)	loss nan (nan)	prob nan (nan)	GS 32.703 (32.703)	mem 62.785
Train: [8][500/750]	BT 0.162 (1.275)	DT 0.007 (1.118)	loss nan (nan)	prob nan (nan)	GS 30.922 (30.922)	mem 63.150
Train: [8][505/750]	BT 0.130 (1.290)	DT 0.011 (1.133)	loss nan (nan)	prob nan (nan)	GS 35.953 (35.953)	mem 64.625
Train: [8][510/750]	BT 0.237 (1.279)	DT 0.033 (1.122)	loss nan (nan)	prob nan (nan)	GS 36.703 (36.703)	mem 64.664
Train: [8][515/750]	BT 0.237 (1.269)	DT 0.007 (1.112)	loss nan (nan)	prob nan (nan)	GS 29.078 (29.078)	mem 64.680
Train: [8][520/750]	BT 0.141 (1.294)	DT 0.003 (1.137)	loss nan (nan)	prob nan (nan)	GS 32.188 (32.188)	mem 64.567
Train: [8][525/750]	BT 0.138 (1.283)	DT 0.002 (1.126)	loss nan (nan)	prob nan (nan)	GS 38.219 (38.219)	mem 64.608
Train: [8][530/750]	BT 0.087 (1.299)	DT 0.001 (1.142)	loss nan (nan)	prob nan (nan)	GS 35.047 (35.047)	mem 57.997
Train: [8][535/750]	BT 0.084 (1.288)	DT 0.002 (1.131)	loss nan (nan)	prob nan (nan)	GS 28.953 (28.953)	mem 58.008
Train: [8][540/750]	BT 13.807 (1.303)	DT 13.709 (1.146)	loss nan (nan)	prob nan (nan)	GS 36.531 (36.531)	mem 60.567
Train: [8][545/750]	BT 0.149 (1.292)	DT 0.015 (1.136)	loss nan (nan)	prob nan (nan)	GS 33.469 (33.469)	mem 60.749
Train: [8][550/750]	BT 0.189 (1.281)	DT 0.002 (1.126)	loss nan (nan)	prob nan (nan)	GS 32.984 (32.984)	mem 61.055
Train: [8][555/750]	BT 0.177 (1.288)	DT 0.013 (1.132)	loss nan (nan)	prob nan (nan)	GS 33.781 (33.781)	mem 62.812
Train: [8][560/750]	BT 0.107 (1.278)	DT 0.003 (1.122)	loss nan (nan)	prob nan (nan)	GS 31.422 (31.422)	mem 62.947
Train: [8][565/750]	BT 0.080 (1.294)	DT 0.001 (1.138)	loss nan (nan)	prob nan (nan)	GS 29.250 (29.250)	mem 58.908
Train: [8][570/750]	BT 0.142 (1.283)	DT 0.001 (1.128)	loss nan (nan)	prob nan (nan)	GS 37.750 (37.750)	mem 59.079
Train: [8][575/750]	BT 0.101 (1.275)	DT 0.002 (1.120)	loss nan (nan)	prob nan (nan)	GS 30.844 (30.844)	mem 59.330
Train: [8][580/750]	BT 0.135 (1.290)	DT 0.005 (1.135)	loss nan (nan)	prob nan (nan)	GS 35.453 (35.453)	mem 62.403
Train: [8][585/750]	BT 0.125 (1.280)	DT 0.016 (1.125)	loss nan (nan)	prob nan (nan)	GS 30.828 (30.828)	mem 62.641
Train: [8][590/750]	BT 0.180 (1.289)	DT 0.010 (1.134)	loss nan (nan)	prob nan (nan)	GS 33.922 (33.922)	mem 64.487
Train: [8][595/750]	BT 0.202 (1.279)	DT 0.006 (1.124)	loss nan (nan)	prob nan (nan)	GS 32.797 (32.797)	mem 64.538
Train: [8][600/750]	BT 10.033 (1.293)	DT 9.869 (1.138)	loss nan (nan)	prob nan (nan)	GS 32.641 (32.641)	mem 64.731
Train: [8][605/750]	BT 0.140 (1.284)	DT 0.007 (1.129)	loss nan (nan)	prob nan (nan)	GS 31.938 (31.938)	mem 64.741
Train: [8][610/750]	BT 1.661 (1.277)	DT 1.474 (1.122)	loss nan (nan)	prob nan (nan)	GS 36.031 (36.031)	mem 64.726
Train: [8][615/750]	BT 0.176 (1.293)	DT 0.003 (1.138)	loss nan (nan)	prob nan (nan)	GS 29.562 (29.562)	mem 64.723
Train: [8][620/750]	BT 0.123 (1.284)	DT 0.002 (1.129)	loss nan (nan)	prob nan (nan)	GS 30.375 (30.375)	mem 64.834
Train: [8][625/750]	BT 0.211 (1.305)	DT 0.008 (1.149)	loss nan (nan)	prob nan (nan)	GS 42.719 (42.719)	mem 58.680
Train: [8][630/750]	BT 0.084 (1.296)	DT 0.001 (1.140)	loss nan (nan)	prob nan (nan)	GS 35.656 (35.656)	mem 58.842
Train: [8][635/750]	BT 0.146 (1.287)	DT 0.015 (1.131)	loss nan (nan)	prob nan (nan)	GS 33.609 (33.609)	mem 58.971
Train: [8][640/750]	BT 0.136 (1.295)	DT 0.012 (1.140)	loss nan (nan)	prob nan (nan)	GS 29.906 (29.906)	mem 60.979
Train: [8][645/750]	BT 0.113 (1.286)	DT 0.020 (1.131)	loss nan (nan)	prob nan (nan)	GS 32.062 (32.062)	mem 61.127
Train: [8][650/750]	BT 0.162 (1.298)	DT 0.002 (1.143)	loss nan (nan)	prob nan (nan)	GS 32.953 (32.953)	mem 63.468
Train: [8][655/750]	BT 0.092 (1.289)	DT 0.001 (1.134)	loss nan (nan)	prob nan (nan)	GS 33.922 (33.922)	mem 63.599
Train: [8][660/750]	BT 9.573 (1.297)	DT 9.486 (1.143)	loss nan (nan)	prob nan (nan)	GS 35.078 (35.078)	mem 58.998
Train: [8][665/750]	BT 0.238 (1.288)	DT 0.006 (1.134)	loss nan (nan)	prob nan (nan)	GS 31.766 (31.766)	mem 59.223
Train: [8][670/750]	BT 8.188 (1.292)	DT 8.030 (1.138)	loss nan (nan)	prob nan (nan)	GS 32.078 (32.078)	mem 60.647
Train: [8][675/750]	BT 0.169 (1.296)	DT 0.001 (1.142)	loss nan (nan)	prob nan (nan)	GS 25.906 (25.906)	mem 62.559
Train: [8][680/750]	BT 0.084 (1.288)	DT 0.001 (1.134)	loss nan (nan)	prob nan (nan)	GS 33.016 (33.016)	mem 62.795
Train: [8][685/750]	BT 0.094 (1.299)	DT 0.001 (1.145)	loss nan (nan)	prob nan (nan)	GS 37.750 (37.750)	mem 64.647
Train: [8][690/750]	BT 0.305 (1.291)	DT 0.003 (1.136)	loss nan (nan)	prob nan (nan)	GS 34.969 (34.969)	mem 64.670
Train: [8][695/750]	BT 0.223 (1.293)	DT 0.003 (1.138)	loss nan (nan)	prob nan (nan)	GS 30.078 (30.078)	mem 64.861
Train: [8][700/750]	BT 0.201 (1.290)	DT 0.002 (1.135)	loss nan (nan)	prob nan (nan)	GS 30.734 (30.734)	mem 64.774
Train: [8][705/750]	BT 0.219 (1.282)	DT 0.001 (1.127)	loss nan (nan)	prob nan (nan)	GS 31.719 (31.719)	mem 64.685
Train: [8][710/750]	BT 0.184 (1.293)	DT 0.007 (1.138)	loss nan (nan)	prob nan (nan)	GS 32.859 (32.859)	mem 64.631
arpack error, retry= 0
Train: [8][715/750]	BT 0.133 (1.290)	DT 0.001 (1.135)	loss nan (nan)	prob nan (nan)	GS 38.234 (38.234)	mem 64.641
Train: [8][720/750]	BT 4.467 (1.294)	DT 4.246 (1.139)	loss nan (nan)	prob nan (nan)	GS 31.953 (31.953)	mem 58.084
Train: [8][725/750]	BT 0.199 (1.287)	DT 0.016 (1.131)	loss nan (nan)	prob nan (nan)	GS 28.562 (28.562)	mem 58.265
Train: [8][730/750]	BT 2.501 (1.287)	DT 2.411 (1.131)	loss nan (nan)	prob nan (nan)	GS 28.484 (28.484)	mem 59.243
Train: [8][735/750]	BT 0.112 (1.284)	DT 0.014 (1.129)	loss nan (nan)	prob nan (nan)	GS 37.297 (37.297)	mem 60.056
Train: [8][740/750]	BT 0.079 (1.279)	DT 0.001 (1.124)	loss nan (nan)	prob nan (nan)	GS 32.609 (32.609)	mem 35.053
Train: [8][745/750]	BT 0.073 (1.279)	DT 0.001 (1.125)	loss nan (nan)	prob nan (nan)	GS 28.688 (28.688)	mem 31.019
Train: [8][750/750]	BT 0.088 (1.271)	DT 0.002 (1.117)	loss nan (nan)	prob nan (nan)	GS 33.406 (33.406)	mem 31.167
Train: [8][755/750]	BT 0.071 (1.263)	DT 0.001 (1.110)	loss nan (nan)	prob nan (nan)	GS 26.906 (26.906)	mem 31.286
epoch 8, total time 956.47
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [9][1/750]	BT 24.743 (24.743)	DT 24.583 (24.583)	loss nan (nan)	prob nan (nan)	GS 30.609 (30.609)	mem 62.985
Train: [9][5/750]	BT 2.879 (5.657)	DT 2.551 (5.429)	loss nan (nan)	prob nan (nan)	GS 36.500 (36.500)	mem 63.127
Train: [9][10/750]	BT 0.123 (2.905)	DT 0.009 (2.717)	loss nan (nan)	prob nan (nan)	GS 34.109 (34.109)	mem 63.108
Train: [9][15/750]	BT 0.103 (2.339)	DT 0.003 (2.170)	loss nan (nan)	prob nan (nan)	GS 28.859 (28.859)	mem 63.234
Train: [9][20/750]	BT 0.146 (2.310)	DT 0.012 (2.133)	loss nan (nan)	prob nan (nan)	GS 28.766 (28.766)	mem 63.330
Train: [9][25/750]	BT 0.249 (1.884)	DT 0.001 (1.707)	loss nan (nan)	prob nan (nan)	GS 28.578 (28.578)	mem 63.387
Train: [9][30/750]	BT 6.598 (1.998)	DT 6.459 (1.824)	loss nan (nan)	prob nan (nan)	GS 33.516 (33.516)	mem 63.620
Train: [9][35/750]	BT 0.193 (1.759)	DT 0.009 (1.587)	loss nan (nan)	prob nan (nan)	GS 29.406 (29.406)	mem 63.517
Train: [9][40/750]	BT 4.180 (1.696)	DT 4.049 (1.526)	loss nan (nan)	prob nan (nan)	GS 33.812 (33.812)	mem 61.986
Train: [9][45/750]	BT 0.194 (1.656)	DT 0.004 (1.484)	loss nan (nan)	prob nan (nan)	GS 30.750 (30.750)	mem 57.806
Train: [9][50/750]	BT 4.786 (1.601)	DT 4.609 (1.434)	loss nan (nan)	prob nan (nan)	GS 33.359 (33.359)	mem 58.807
Train: [9][55/750]	BT 0.209 (1.599)	DT 0.005 (1.431)	loss nan (nan)	prob nan (nan)	GS 32.234 (32.234)	mem 60.086
Train: [9][60/750]	BT 0.114 (1.480)	DT 0.001 (1.313)	loss nan (nan)	prob nan (nan)	GS 34.062 (34.062)	mem 60.255
Train: [9][65/750]	BT 0.102 (1.485)	DT 0.002 (1.323)	loss nan (nan)	prob nan (nan)	GS 33.984 (33.984)	mem 61.640
Train: [9][70/750]	BT 0.295 (1.573)	DT 0.008 (1.405)	loss nan (nan)	prob nan (nan)	GS 36.172 (36.172)	mem 58.886
Train: [9][75/750]	BT 0.154 (1.535)	DT 0.002 (1.368)	loss nan (nan)	prob nan (nan)	GS 33.609 (33.609)	mem 57.894
Train: [9][80/750]	BT 0.106 (1.558)	DT 0.001 (1.393)	loss nan (nan)	prob nan (nan)	GS 37.062 (37.062)	mem 59.883
Train: [9][85/750]	BT 0.145 (1.475)	DT 0.001 (1.312)	loss nan (nan)	prob nan (nan)	GS 34.703 (34.703)	mem 60.164
Train: [9][90/750]	BT 5.960 (1.499)	DT 5.770 (1.336)	loss nan (nan)	prob nan (nan)	GS 33.703 (33.703)	mem 61.909
Train: [9][95/750]	BT 0.167 (1.455)	DT 0.002 (1.293)	loss nan (nan)	prob nan (nan)	GS 25.672 (25.672)	mem 62.793
Train: [9][100/750]	BT 1.044 (1.432)	DT 0.788 (1.268)	loss nan (nan)	prob nan (nan)	GS 33.328 (33.328)	mem 63.563
Train: [9][105/750]	BT 0.219 (1.438)	DT 0.012 (1.272)	loss nan (nan)	prob nan (nan)	GS 32.547 (32.547)	mem 63.704
Train: [9][110/750]	BT 5.966 (1.440)	DT 5.819 (1.275)	loss nan (nan)	prob nan (nan)	GS 32.906 (32.906)	mem 63.704
Train: [9][115/750]	BT 0.151 (1.460)	DT 0.002 (1.294)	loss nan (nan)	prob nan (nan)	GS 32.719 (32.719)	mem 63.967
Train: [9][120/750]	BT 0.194 (1.404)	DT 0.001 (1.240)	loss nan (nan)	prob nan (nan)	GS 32.375 (32.375)	mem 63.978
Train: [9][125/750]	BT 0.179 (1.395)	DT 0.004 (1.231)	loss nan (nan)	prob nan (nan)	GS 30.969 (30.969)	mem 63.821
Train: [9][130/750]	BT 0.168 (1.374)	DT 0.015 (1.210)	loss nan (nan)	prob nan (nan)	GS 33.000 (33.000)	mem 64.012
Train: [9][135/750]	BT 0.093 (1.422)	DT 0.001 (1.258)	loss nan (nan)	prob nan (nan)	GS 29.797 (29.797)	mem 57.696
Train: [9][140/750]	BT 0.087 (1.375)	DT 0.003 (1.213)	loss nan (nan)	prob nan (nan)	GS 31.781 (31.781)	mem 57.834
Train: [9][145/750]	BT 0.190 (1.345)	DT 0.011 (1.184)	loss nan (nan)	prob nan (nan)	GS 30.625 (30.625)	mem 58.212
Train: [9][150/750]	BT 0.151 (1.372)	DT 0.001 (1.212)	loss nan (nan)	prob nan (nan)	GS 32.422 (32.422)	mem 60.238
Train: [9][155/750]	BT 0.155 (1.359)	DT 0.017 (1.199)	loss nan (nan)	prob nan (nan)	GS 29.469 (29.469)	mem 61.247
Train: [9][160/750]	BT 4.755 (1.382)	DT 4.661 (1.224)	loss nan (nan)	prob nan (nan)	GS 35.828 (35.828)	mem 63.116
Train: [9][165/750]	BT 0.102 (1.352)	DT 0.002 (1.193)	loss nan (nan)	prob nan (nan)	GS 34.812 (34.812)	mem 63.374
Train: [9][170/750]	BT 0.174 (1.352)	DT 0.008 (1.195)	loss nan (nan)	prob nan (nan)	GS 28.594 (28.594)	mem 58.282
Train: [9][175/750]	BT 0.098 (1.393)	DT 0.003 (1.236)	loss nan (nan)	prob nan (nan)	GS 27.625 (27.625)	mem 60.965
Train: [9][180/750]	BT 0.135 (1.364)	DT 0.005 (1.208)	loss nan (nan)	prob nan (nan)	GS 28.062 (28.062)	mem 61.584
Train: [9][185/750]	BT 0.167 (1.331)	DT 0.003 (1.176)	loss nan (nan)	prob nan (nan)	GS 32.703 (32.703)	mem 61.754
Train: [9][190/750]	BT 1.028 (1.364)	DT 0.920 (1.210)	loss nan (nan)	prob nan (nan)	GS 31.406 (31.406)	mem 64.224
Train: [9][195/750]	BT 0.160 (1.333)	DT 0.001 (1.179)	loss nan (nan)	prob nan (nan)	GS 28.266 (28.266)	mem 64.244
Train: [9][200/750]	BT 0.143 (1.375)	DT 0.006 (1.220)	loss nan (nan)	prob nan (nan)	GS 35.016 (35.016)	mem 64.388
Train: [9][205/750]	BT 0.160 (1.351)	DT 0.030 (1.197)	loss nan (nan)	prob nan (nan)	GS 27.781 (27.781)	mem 64.490
Train: [9][210/750]	BT 9.336 (1.366)	DT 9.217 (1.212)	loss nan (nan)	prob nan (nan)	GS 31.188 (31.188)	mem 64.386
Train: [9][215/750]	BT 0.174 (1.350)	DT 0.007 (1.195)	loss nan (nan)	prob nan (nan)	GS 33.047 (33.047)	mem 64.348
Train: [9][220/750]	BT 0.171 (1.323)	DT 0.009 (1.168)	loss nan (nan)	prob nan (nan)	GS 35.297 (35.297)	mem 64.482
Train: [9][225/750]	BT 0.208 (1.324)	DT 0.002 (1.168)	loss nan (nan)	prob nan (nan)	GS 34.984 (34.984)	mem 64.394
Train: [9][230/750]	BT 0.158 (1.327)	DT 0.002 (1.172)	loss nan (nan)	prob nan (nan)	GS 33.188 (33.188)	mem 58.195
Train: [9][235/750]	BT 0.182 (1.325)	DT 0.026 (1.170)	loss nan (nan)	prob nan (nan)	GS 25.219 (25.219)	mem 59.239
Train: [9][240/750]	BT 4.188 (1.337)	DT 4.104 (1.182)	loss nan (nan)	prob nan (nan)	GS 34.812 (34.812)	mem 60.983
Train: [9][245/750]	BT 0.091 (1.325)	DT 0.002 (1.170)	loss nan (nan)	prob nan (nan)	GS 28.250 (28.250)	mem 61.567
Train: [9][250/750]	BT 4.441 (1.319)	DT 4.246 (1.163)	loss nan (nan)	prob nan (nan)	GS 30.328 (30.328)	mem 62.746
Train: [9][255/750]	BT 0.331 (1.307)	DT 0.026 (1.150)	loss nan (nan)	prob nan (nan)	GS 30.844 (30.844)	mem 63.319
Train: [9][260/750]	BT 0.162 (1.314)	DT 0.031 (1.158)	loss nan (nan)	prob nan (nan)	GS 35.266 (35.266)	mem 59.539
Train: [9][265/750]	BT 0.272 (1.322)	DT 0.008 (1.166)	loss nan (nan)	prob nan (nan)	GS 34.656 (34.656)	mem 59.840
Train: [9][270/750]	BT 0.182 (1.339)	DT 0.001 (1.183)	loss nan (nan)	prob nan (nan)	GS 32.812 (32.812)	mem 62.242
Train: [9][275/750]	BT 0.128 (1.317)	DT 0.004 (1.161)	loss nan (nan)	prob nan (nan)	GS 31.047 (31.047)	mem 62.361
Train: [9][280/750]	BT 11.807 (1.337)	DT 11.579 (1.182)	loss nan (nan)	prob nan (nan)	GS 33.891 (33.891)	mem 64.516
Train: [9][285/750]	BT 0.188 (1.318)	DT 0.004 (1.161)	loss nan (nan)	prob nan (nan)	GS 30.953 (30.953)	mem 64.640
Train: [9][290/750]	BT 0.135 (1.314)	DT 0.004 (1.158)	loss nan (nan)	prob nan (nan)	GS 31.484 (31.484)	mem 64.480
Train: [9][295/750]	BT 0.191 (1.309)	DT 0.013 (1.152)	loss nan (nan)	prob nan (nan)	GS 33.875 (33.875)	mem 64.525
Train: [9][300/750]	BT 2.230 (1.308)	DT 2.044 (1.151)	loss nan (nan)	prob nan (nan)	GS 31.484 (31.484)	mem 64.544
Train: [9][305/750]	BT 0.106 (1.309)	DT 0.001 (1.153)	loss nan (nan)	prob nan (nan)	GS 36.688 (36.688)	mem 64.576
Train: [9][310/750]	BT 3.432 (1.301)	DT 3.248 (1.144)	loss nan (nan)	prob nan (nan)	GS 31.234 (31.234)	mem 64.564
Train: [9][315/750]	BT 0.194 (1.293)	DT 0.005 (1.136)	loss nan (nan)	prob nan (nan)	GS 28.844 (28.844)	mem 64.593
Train: [9][320/750]	BT 0.362 (1.286)	DT 0.072 (1.127)	loss nan (nan)	prob nan (nan)	GS 35.719 (35.719)	mem 64.594
Train: [9][325/750]	BT 0.109 (1.304)	DT 0.001 (1.146)	loss nan (nan)	prob nan (nan)	GS 35.922 (35.922)	mem 58.612
Train: [9][330/750]	BT 0.136 (1.286)	DT 0.001 (1.129)	loss nan (nan)	prob nan (nan)	GS 31.281 (31.281)	mem 58.736
Train: [9][335/750]	BT 0.198 (1.296)	DT 0.002 (1.138)	loss nan (nan)	prob nan (nan)	GS 29.516 (29.516)	mem 60.652
Train: [9][340/750]	BT 0.903 (1.293)	DT 0.815 (1.136)	loss nan (nan)	prob nan (nan)	GS 28.094 (28.094)	mem 61.535
Train: [9][345/750]	BT 0.212 (1.299)	DT 0.009 (1.141)	loss nan (nan)	prob nan (nan)	GS 31.344 (31.344)	mem 62.820
Train: [9][350/750]	BT 0.129 (1.301)	DT 0.005 (1.143)	loss nan (nan)	prob nan (nan)	GS 31.828 (31.828)	mem 63.523
Train: [9][355/750]	BT 0.193 (1.285)	DT 0.007 (1.127)	loss nan (nan)	prob nan (nan)	GS 28.703 (28.703)	mem 63.619
Train: [9][360/750]	BT 0.155 (1.315)	DT 0.001 (1.158)	loss nan (nan)	prob nan (nan)	GS 39.531 (39.531)	mem 60.118
Train: [9][365/750]	BT 0.145 (1.300)	DT 0.006 (1.142)	loss nan (nan)	prob nan (nan)	GS 36.625 (36.625)	mem 60.327
Train: [9][370/750]	BT 0.211 (1.306)	DT 0.005 (1.149)	loss nan (nan)	prob nan (nan)	GS 28.641 (28.641)	mem 62.154
Train: [9][375/750]	BT 0.199 (1.296)	DT 0.003 (1.139)	loss nan (nan)	prob nan (nan)	GS 33.172 (33.172)	mem 62.677
Train: [9][380/750]	BT 6.830 (1.302)	DT 6.737 (1.145)	loss nan (nan)	prob nan (nan)	GS 32.250 (32.250)	mem 64.242
Train: [9][385/750]	BT 0.247 (1.312)	DT 0.003 (1.154)	loss nan (nan)	prob nan (nan)	GS 31.500 (31.500)	mem 64.371
Train: [9][390/750]	BT 0.170 (1.297)	DT 0.015 (1.140)	loss nan (nan)	prob nan (nan)	GS 33.516 (33.516)	mem 64.571
Train: [9][395/750]	BT 0.232 (1.304)	DT 0.018 (1.146)	loss nan (nan)	prob nan (nan)	GS 32.953 (32.953)	mem 64.449
Train: [9][400/750]	BT 0.114 (1.294)	DT 0.003 (1.136)	loss nan (nan)	prob nan (nan)	GS 31.359 (31.359)	mem 64.683
Train: [9][405/750]	BT 0.152 (1.292)	DT 0.026 (1.133)	loss nan (nan)	prob nan (nan)	GS 30.703 (30.703)	mem 64.565
Train: [9][410/750]	BT 0.172 (1.295)	DT 0.010 (1.136)	loss nan (nan)	prob nan (nan)	GS 35.562 (35.562)	mem 64.526
Train: [9][415/750]	BT 0.123 (1.281)	DT 0.011 (1.122)	loss nan (nan)	prob nan (nan)	GS 32.203 (32.203)	mem 64.537
Train: [9][420/750]	BT 3.117 (1.296)	DT 2.936 (1.138)	loss nan (nan)	prob nan (nan)	GS 36.625 (36.625)	mem 58.905
Train: [9][425/750]	BT 0.135 (1.282)	DT 0.001 (1.125)	loss nan (nan)	prob nan (nan)	GS 30.266 (30.266)	mem 58.912
Train: [9][430/750]	BT 5.024 (1.300)	DT 4.931 (1.142)	loss nan (nan)	prob nan (nan)	GS 35.500 (35.500)	mem 61.463
Train: [9][435/750]	BT 0.162 (1.295)	DT 0.004 (1.138)	loss nan (nan)	prob nan (nan)	GS 30.766 (30.766)	mem 62.563
Train: [9][440/750]	BT 2.909 (1.288)	DT 2.803 (1.131)	loss nan (nan)	prob nan (nan)	GS 33.422 (33.422)	mem 63.183
Train: [9][445/750]	BT 0.250 (1.300)	DT 0.004 (1.143)	loss nan (nan)	prob nan (nan)	GS 31.219 (31.219)	mem 58.638
Train: [9][450/750]	BT 0.136 (1.287)	DT 0.002 (1.130)	loss nan (nan)	prob nan (nan)	GS 28.875 (28.875)	mem 58.617
Train: [9][455/750]	BT 0.183 (1.295)	DT 0.002 (1.138)	loss nan (nan)	prob nan (nan)	GS 31.375 (31.375)	mem 60.461
Train: [9][460/750]	BT 0.120 (1.297)	DT 0.003 (1.141)	loss nan (nan)	prob nan (nan)	GS 34.156 (34.156)	mem 62.382
Train: [9][465/750]	BT 0.229 (1.285)	DT 0.002 (1.129)	loss nan (nan)	prob nan (nan)	GS 33.016 (33.016)	mem 62.401
Train: [9][470/750]	BT 0.097 (1.302)	DT 0.001 (1.145)	loss nan (nan)	prob nan (nan)	GS 35.422 (35.422)	mem 64.630
Train: [9][475/750]	BT 0.139 (1.289)	DT 0.003 (1.133)	loss nan (nan)	prob nan (nan)	GS 37.719 (37.719)	mem 64.589
Train: [9][480/750]	BT 11.703 (1.308)	DT 11.551 (1.152)	loss nan (nan)	prob nan (nan)	GS 31.641 (31.641)	mem 64.584
Train: [9][485/750]	BT 0.178 (1.296)	DT 0.002 (1.140)	loss nan (nan)	prob nan (nan)	GS 34.344 (34.344)	mem 64.588
Train: [9][490/750]	BT 3.914 (1.293)	DT 3.706 (1.136)	loss nan (nan)	prob nan (nan)	GS 32.781 (32.781)	mem 64.662
Train: [9][495/750]	BT 0.149 (1.300)	DT 0.001 (1.142)	loss nan (nan)	prob nan (nan)	GS 42.438 (42.438)	mem 64.670
Train: [9][500/750]	BT 0.254 (1.289)	DT 0.012 (1.131)	loss nan (nan)	prob nan (nan)	GS 32.672 (32.672)	mem 64.658
Train: [9][505/750]	BT 0.091 (1.302)	DT 0.002 (1.144)	loss nan (nan)	prob nan (nan)	GS 32.312 (32.312)	mem 58.195
Train: [9][510/750]	BT 0.112 (1.290)	DT 0.001 (1.133)	loss nan (nan)	prob nan (nan)	GS 33.609 (33.609)	mem 58.308
Train: [9][515/750]	BT 0.333 (1.284)	DT 0.002 (1.126)	loss nan (nan)	prob nan (nan)	GS 28.797 (28.797)	mem 58.698
Train: [9][520/750]	BT 0.150 (1.290)	DT 0.020 (1.132)	loss nan (nan)	prob nan (nan)	GS 35.000 (35.000)	mem 60.276
Train: [9][525/750]	BT 0.258 (1.280)	DT 0.014 (1.121)	loss nan (nan)	prob nan (nan)	GS 28.250 (28.250)	mem 60.642
Train: [9][530/750]	BT 0.093 (1.294)	DT 0.003 (1.135)	loss nan (nan)	prob nan (nan)	GS 33.438 (33.438)	mem 62.786
Train: [9][535/750]	BT 0.263 (1.283)	DT 0.013 (1.125)	loss nan (nan)	prob nan (nan)	GS 31.203 (31.203)	mem 62.915
Train: [9][540/750]	BT 10.668 (1.307)	DT 10.434 (1.148)	loss nan (nan)	prob nan (nan)	GS 40.562 (40.562)	mem 59.070
Train: [9][545/750]	BT 0.166 (1.296)	DT 0.010 (1.137)	loss nan (nan)	prob nan (nan)	GS 30.812 (30.812)	mem 59.209
Train: [9][550/750]	BT 7.868 (1.300)	DT 7.692 (1.141)	loss nan (nan)	prob nan (nan)	GS 31.156 (31.156)	mem 60.797
Train: [9][555/750]	BT 0.247 (1.300)	DT 0.002 (1.141)	loss nan (nan)	prob nan (nan)	GS 31.953 (31.953)	mem 62.425
Train: [9][560/750]	BT 0.100 (1.289)	DT 0.012 (1.131)	loss nan (nan)	prob nan (nan)	GS 35.875 (35.875)	mem 62.348
Train: [9][565/750]	BT 0.365 (1.302)	DT 0.003 (1.144)	loss nan (nan)	prob nan (nan)	GS 34.578 (34.578)	mem 64.490
Train: [9][570/750]	BT 0.098 (1.293)	DT 0.008 (1.134)	loss nan (nan)	prob nan (nan)	GS 36.172 (36.172)	mem 64.568
Train: [9][575/750]	BT 0.149 (1.296)	DT 0.002 (1.136)	loss nan (nan)	prob nan (nan)	GS 29.578 (29.578)	mem 64.723
Train: [9][580/750]	BT 0.213 (1.301)	DT 0.002 (1.142)	loss nan (nan)	prob nan (nan)	GS 33.703 (33.703)	mem 64.547
Train: [9][585/750]	BT 0.106 (1.291)	DT 0.001 (1.132)	loss nan (nan)	prob nan (nan)	GS 27.438 (27.438)	mem 64.550
Train: [9][590/750]	BT 0.130 (1.304)	DT 0.003 (1.145)	loss nan (nan)	prob nan (nan)	GS 36.641 (36.641)	mem 64.404
Train: [9][595/750]	BT 0.146 (1.294)	DT 0.001 (1.135)	loss nan (nan)	prob nan (nan)	GS 28.781 (28.781)	mem 64.447
Train: [9][600/750]	BT 11.821 (1.304)	DT 11.710 (1.145)	loss nan (nan)	prob nan (nan)	GS 32.797 (32.797)	mem 59.370
Train: [9][605/750]	BT 0.133 (1.295)	DT 0.001 (1.136)	loss nan (nan)	prob nan (nan)	GS 32.250 (32.250)	mem 59.756
Train: [9][610/750]	BT 1.062 (1.287)	DT 0.921 (1.128)	loss nan (nan)	prob nan (nan)	GS 36.375 (36.375)	mem 59.748
Train: [9][615/750]	BT 0.159 (1.298)	DT 0.002 (1.139)	loss nan (nan)	prob nan (nan)	GS 35.219 (35.219)	mem 61.729
Train: [9][620/750]	BT 0.115 (1.288)	DT 0.005 (1.130)	loss nan (nan)	prob nan (nan)	GS 31.875 (31.875)	mem 61.787
Train: [9][625/750]	BT 0.118 (1.298)	DT 0.001 (1.139)	loss nan (nan)	prob nan (nan)	GS 31.688 (31.688)	mem 63.824
Train: [9][630/750]	BT 0.165 (1.288)	DT 0.008 (1.130)	loss nan (nan)	prob nan (nan)	GS 34.922 (34.922)	mem 63.802
Train: [9][635/750]	BT 0.119 (1.280)	DT 0.003 (1.122)	loss nan (nan)	prob nan (nan)	GS 31.016 (31.016)	mem 60.911
Train: [9][640/750]	BT 0.090 (1.289)	DT 0.002 (1.131)	loss nan (nan)	prob nan (nan)	GS 39.016 (39.016)	mem 59.931
Train: [9][645/750]	BT 0.156 (1.280)	DT 0.002 (1.122)	loss nan (nan)	prob nan (nan)	GS 32.531 (32.531)	mem 60.161
Train: [9][650/750]	BT 0.292 (1.288)	DT 0.013 (1.130)	loss nan (nan)	prob nan (nan)	GS 33.312 (33.312)	mem 62.722
Train: [9][655/750]	BT 0.193 (1.280)	DT 0.009 (1.122)	loss nan (nan)	prob nan (nan)	GS 33.375 (33.375)	mem 62.869
Train: [9][660/750]	BT 7.503 (1.292)	DT 7.265 (1.133)	loss nan (nan)	prob nan (nan)	GS 32.766 (32.766)	mem 64.556
Train: [9][665/750]	BT 0.209 (1.283)	DT 0.007 (1.125)	loss nan (nan)	prob nan (nan)	GS 35.844 (35.844)	mem 64.566
Train: [9][670/750]	BT 6.634 (1.285)	DT 6.246 (1.126)	loss nan (nan)	prob nan (nan)	GS 38.812 (38.812)	mem 64.578
Train: [9][675/750]	BT 0.140 (1.290)	DT 0.001 (1.131)	loss nan (nan)	prob nan (nan)	GS 32.688 (32.688)	mem 64.682
Train: [9][680/750]	BT 0.245 (1.282)	DT 0.003 (1.123)	loss nan (nan)	prob nan (nan)	GS 33.312 (33.312)	mem 64.710
Train: [9][685/750]	BT 0.188 (1.295)	DT 0.003 (1.137)	loss nan (nan)	prob nan (nan)	GS 34.609 (34.609)	mem 64.639
Train: [9][690/750]	BT 0.091 (1.287)	DT 0.002 (1.128)	loss nan (nan)	prob nan (nan)	GS 35.016 (35.016)	mem 64.578
Train: [9][695/750]	BT 0.175 (1.279)	DT 0.013 (1.120)	loss nan (nan)	prob nan (nan)	GS 29.188 (29.188)	mem 64.469
Train: [9][700/750]	BT 0.098 (1.289)	DT 0.002 (1.131)	loss nan (nan)	prob nan (nan)	GS 38.266 (38.266)	mem 60.341
Train: [9][705/750]	BT 0.103 (1.281)	DT 0.003 (1.123)	loss nan (nan)	prob nan (nan)	GS 30.297 (30.297)	mem 60.481
Train: [9][710/750]	BT 0.136 (1.290)	DT 0.003 (1.132)	loss nan (nan)	prob nan (nan)	GS 34.469 (34.469)	mem 62.748
arpack error, retry= 0
arpack error, retry= 0
Train: [9][715/750]	BT 0.171 (1.282)	DT 0.009 (1.124)	loss nan (nan)	prob nan (nan)	GS 31.156 (31.156)	mem 62.945
Train: [9][720/750]	BT 15.215 (1.295)	DT 15.141 (1.138)	loss nan (nan)	prob nan (nan)	GS 38.406 (38.406)	mem 58.870
Train: [9][725/750]	BT 0.126 (1.287)	DT 0.007 (1.130)	loss nan (nan)	prob nan (nan)	GS 31.156 (31.156)	mem 59.194
Train: [9][730/750]	BT 0.139 (1.279)	DT 0.017 (1.122)	loss nan (nan)	prob nan (nan)	GS 31.578 (31.578)	mem 59.140
Train: [9][735/750]	BT 0.080 (1.284)	DT 0.001 (1.128)	loss nan (nan)	prob nan (nan)	GS 28.000 (28.000)	mem 61.574
Train: [9][740/750]	BT 0.077 (1.276)	DT 0.001 (1.120)	loss nan (nan)	prob nan (nan)	GS 32.828 (32.828)	mem 61.627
Train: [9][745/750]	BT 0.104 (1.275)	DT 0.002 (1.120)	loss nan (nan)	prob nan (nan)	GS 29.281 (29.281)	mem 32.045
Train: [9][750/750]	BT 0.074 (1.267)	DT 0.001 (1.112)	loss nan (nan)	prob nan (nan)	GS 32.344 (32.344)	mem 32.143
Train: [9][755/750]	BT 0.064 (1.260)	DT 0.001 (1.105)	loss nan (nan)	prob nan (nan)	GS 33.125 (33.125)	mem 32.200
epoch 9, total time 953.45
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [10][1/750]	BT 23.049 (23.049)	DT 22.897 (22.897)	loss nan (nan)	prob nan (nan)	GS 29.219 (29.219)	mem 56.896
Train: [10][5/750]	BT 0.150 (5.969)	DT 0.002 (5.777)	loss nan (nan)	prob nan (nan)	GS 32.109 (32.109)	mem 58.063
Train: [10][10/750]	BT 0.133 (3.048)	DT 0.001 (2.892)	loss nan (nan)	prob nan (nan)	GS 37.000 (37.000)	mem 58.240
Train: [10][15/750]	BT 0.165 (3.198)	DT 0.006 (3.050)	loss nan (nan)	prob nan (nan)	GS 31.406 (31.406)	mem 61.453
Train: [10][20/750]	BT 0.209 (2.440)	DT 0.008 (2.289)	loss nan (nan)	prob nan (nan)	GS 36.266 (36.266)	mem 61.597
Train: [10][25/750]	BT 0.155 (1.997)	DT 0.002 (1.836)	loss nan (nan)	prob nan (nan)	GS 31.172 (31.172)	mem 61.886
Train: [10][30/750]	BT 0.222 (2.137)	DT 0.008 (1.977)	loss nan (nan)	prob nan (nan)	GS 32.000 (32.000)	mem 58.712
Train: [10][35/750]	BT 0.106 (1.909)	DT 0.016 (1.755)	loss nan (nan)	prob nan (nan)	GS 30.344 (30.344)	mem 57.652
Train: [10][40/750]	BT 0.135 (2.003)	DT 0.002 (1.847)	loss nan (nan)	prob nan (nan)	GS 31.734 (31.734)	mem 60.916
Train: [10][45/750]	BT 0.103 (1.794)	DT 0.005 (1.642)	loss nan (nan)	prob nan (nan)	GS 34.297 (34.297)	mem 61.116
Train: [10][50/750]	BT 12.456 (1.875)	DT 12.315 (1.725)	loss nan (nan)	prob nan (nan)	GS 34.812 (34.812)	mem 63.775
Train: [10][55/750]	BT 0.098 (1.721)	DT 0.005 (1.569)	loss nan (nan)	prob nan (nan)	GS 33.938 (33.938)	mem 63.964
Train: [10][60/750]	BT 1.910 (1.619)	DT 1.616 (1.466)	loss nan (nan)	prob nan (nan)	GS 31.156 (31.156)	mem 64.436
Train: [10][65/750]	BT 0.194 (1.653)	DT 0.003 (1.500)	loss nan (nan)	prob nan (nan)	GS 26.750 (26.750)	mem 64.320
Train: [10][70/750]	BT 0.159 (1.549)	DT 0.030 (1.394)	loss nan (nan)	prob nan (nan)	GS 31.984 (31.984)	mem 64.270
Train: [10][75/750]	BT 0.173 (1.608)	DT 0.018 (1.452)	loss nan (nan)	prob nan (nan)	GS 29.203 (29.203)	mem 64.149
Train: [10][80/750]	BT 0.191 (1.517)	DT 0.003 (1.362)	loss nan (nan)	prob nan (nan)	GS 38.109 (38.109)	mem 64.198
Train: [10][85/750]	BT 0.130 (1.477)	DT 0.007 (1.320)	loss nan (nan)	prob nan (nan)	GS 31.797 (31.797)	mem 64.190
Train: [10][90/750]	BT 0.137 (1.516)	DT 0.008 (1.361)	loss nan (nan)	prob nan (nan)	GS 34.219 (34.219)	mem 64.211
Train: [10][95/750]	BT 0.141 (1.444)	DT 0.002 (1.290)	loss nan (nan)	prob nan (nan)	GS 35.047 (35.047)	mem 64.210
Train: [10][100/750]	BT 0.181 (1.516)	DT 0.003 (1.361)	loss nan (nan)	prob nan (nan)	GS 38.203 (38.203)	mem 59.991
Train: [10][105/750]	BT 0.096 (1.450)	DT 0.008 (1.296)	loss nan (nan)	prob nan (nan)	GS 31.531 (31.531)	mem 59.731
Train: [10][110/750]	BT 13.025 (1.509)	DT 12.904 (1.355)	loss nan (nan)	prob nan (nan)	GS 30.094 (30.094)	mem 62.381
Train: [10][115/750]	BT 0.097 (1.449)	DT 0.004 (1.296)	loss nan (nan)	prob nan (nan)	GS 26.578 (26.578)	mem 62.538
Train: [10][120/750]	BT 0.860 (1.400)	DT 0.703 (1.248)	loss nan (nan)	prob nan (nan)	GS 31.828 (31.828)	mem 62.777
Train: [10][125/750]	BT 0.110 (1.454)	DT 0.003 (1.302)	loss nan (nan)	prob nan (nan)	GS 29.156 (29.156)	mem 58.159
Train: [10][130/750]	BT 0.129 (1.404)	DT 0.007 (1.252)	loss nan (nan)	prob nan (nan)	GS 31.109 (31.109)	mem 58.423
Train: [10][135/750]	BT 0.170 (1.459)	DT 0.012 (1.308)	loss nan (nan)	prob nan (nan)	GS 27.891 (27.891)	mem 60.820
Train: [10][140/750]	BT 0.202 (1.413)	DT 0.009 (1.261)	loss nan (nan)	prob nan (nan)	GS 37.422 (37.422)	mem 61.093
Train: [10][145/750]	BT 0.248 (1.372)	DT 0.010 (1.218)	loss nan (nan)	prob nan (nan)	GS 32.625 (32.625)	mem 61.204
Train: [10][150/750]	BT 0.099 (1.406)	DT 0.003 (1.254)	loss nan (nan)	prob nan (nan)	GS 31.203 (31.203)	mem 63.346
Train: [10][155/750]	BT 0.227 (1.367)	DT 0.001 (1.214)	loss nan (nan)	prob nan (nan)	GS 44.141 (44.141)	mem 63.561
Train: [10][160/750]	BT 0.167 (1.406)	DT 0.018 (1.252)	loss nan (nan)	prob nan (nan)	GS 29.609 (29.609)	mem 64.390
Train: [10][165/750]	BT 0.183 (1.368)	DT 0.002 (1.214)	loss nan (nan)	prob nan (nan)	GS 30.219 (30.219)	mem 64.400
Train: [10][170/750]	BT 11.412 (1.415)	DT 11.237 (1.261)	loss nan (nan)	prob nan (nan)	GS 36.344 (36.344)	mem 64.385
Train: [10][175/750]	BT 0.156 (1.378)	DT 0.007 (1.225)	loss nan (nan)	prob nan (nan)	GS 29.984 (29.984)	mem 64.409
Train: [10][180/750]	BT 1.561 (1.353)	DT 1.192 (1.197)	loss nan (nan)	prob nan (nan)	GS 36.453 (36.453)	mem 64.474
Train: [10][185/750]	BT 0.210 (1.387)	DT 0.002 (1.232)	loss nan (nan)	prob nan (nan)	GS 32.781 (32.781)	mem 64.513
Train: [10][190/750]	BT 0.118 (1.354)	DT 0.003 (1.199)	loss nan (nan)	prob nan (nan)	GS 35.141 (35.141)	mem 64.418
Train: [10][195/750]	BT 0.133 (1.385)	DT 0.006 (1.230)	loss nan (nan)	prob nan (nan)	GS 36.969 (36.969)	mem 59.442
Train: [10][200/750]	BT 0.132 (1.354)	DT 0.002 (1.200)	loss nan (nan)	prob nan (nan)	GS 34.609 (34.609)	mem 59.657
Train: [10][205/750]	BT 0.132 (1.325)	DT 0.006 (1.171)	loss nan (nan)	prob nan (nan)	GS 30.484 (30.484)	mem 59.733
Train: [10][210/750]	BT 0.167 (1.354)	DT 0.002 (1.200)	loss nan (nan)	prob nan (nan)	GS 37.109 (37.109)	mem 61.843
Train: [10][215/750]	BT 0.137 (1.326)	DT 0.001 (1.172)	loss nan (nan)	prob nan (nan)	GS 31.125 (31.125)	mem 62.292
Train: [10][220/750]	BT 0.083 (1.356)	DT 0.004 (1.203)	loss nan (nan)	prob nan (nan)	GS 36.547 (36.547)	mem 62.799
Train: [10][225/750]	BT 0.098 (1.348)	DT 0.002 (1.196)	loss nan (nan)	prob nan (nan)	GS 29.797 (29.797)	mem 58.613
Train: [10][230/750]	BT 11.754 (1.372)	DT 11.663 (1.221)	loss nan (nan)	prob nan (nan)	GS 32.156 (32.156)	mem 60.869
Train: [10][235/750]	BT 0.147 (1.346)	DT 0.007 (1.195)	loss nan (nan)	prob nan (nan)	GS 34.047 (34.047)	mem 60.988
Train: [10][240/750]	BT 0.161 (1.320)	DT 0.013 (1.170)	loss nan (nan)	prob nan (nan)	GS 31.469 (31.469)	mem 61.203
Train: [10][245/750]	BT 0.109 (1.338)	DT 0.002 (1.188)	loss nan (nan)	prob nan (nan)	GS 33.094 (33.094)	mem 63.721
Train: [10][250/750]	BT 0.098 (1.314)	DT 0.004 (1.165)	loss nan (nan)	prob nan (nan)	GS 31.547 (31.547)	mem 63.771
Train: [10][255/750]	BT 0.258 (1.330)	DT 0.004 (1.181)	loss nan (nan)	prob nan (nan)	GS 27.844 (27.844)	mem 64.502
Train: [10][260/750]	BT 0.192 (1.322)	DT 0.008 (1.172)	loss nan (nan)	prob nan (nan)	GS 34.219 (34.219)	mem 64.487
Train: [10][265/750]	BT 0.256 (1.301)	DT 0.008 (1.150)	loss nan (nan)	prob nan (nan)	GS 31.672 (31.672)	mem 64.584
Train: [10][270/750]	BT 2.562 (1.327)	DT 2.465 (1.176)	loss nan (nan)	prob nan (nan)	GS 36.906 (36.906)	mem 64.837
Train: [10][275/750]	BT 0.139 (1.306)	DT 0.001 (1.155)	loss nan (nan)	prob nan (nan)	GS 30.781 (30.781)	mem 64.580
Train: [10][280/750]	BT 0.157 (1.315)	DT 0.007 (1.164)	loss nan (nan)	prob nan (nan)	GS 35.828 (35.828)	mem 64.666
Train: [10][285/750]	BT 0.111 (1.311)	DT 0.006 (1.161)	loss nan (nan)	prob nan (nan)	GS 32.266 (32.266)	mem 57.672
Train: [10][290/750]	BT 4.407 (1.306)	DT 4.291 (1.156)	loss nan (nan)	prob nan (nan)	GS 34.438 (34.438)	mem 58.724
Train: [10][295/750]	BT 0.097 (1.329)	DT 0.001 (1.178)	loss nan (nan)	prob nan (nan)	GS 34.062 (34.062)	mem 61.318
Train: [10][300/750]	BT 0.260 (1.310)	DT 0.001 (1.158)	loss nan (nan)	prob nan (nan)	GS 32.484 (32.484)	mem 61.405
Train: [10][305/750]	BT 0.113 (1.290)	DT 0.001 (1.139)	loss nan (nan)	prob nan (nan)	GS 31.531 (31.531)	mem 61.542
Train: [10][310/750]	BT 0.121 (1.316)	DT 0.002 (1.165)	loss nan (nan)	prob nan (nan)	GS 33.422 (33.422)	mem 63.726
Train: [10][315/750]	BT 0.156 (1.301)	DT 0.001 (1.150)	loss nan (nan)	prob nan (nan)	GS 32.266 (32.266)	mem 62.231
Train: [10][320/750]	BT 0.176 (1.323)	DT 0.001 (1.173)	loss nan (nan)	prob nan (nan)	GS 39.609 (39.609)	mem 60.244
Train: [10][325/750]	BT 0.111 (1.305)	DT 0.001 (1.155)	loss nan (nan)	prob nan (nan)	GS 32.672 (32.672)	mem 60.272
Train: [10][330/750]	BT 11.189 (1.322)	DT 11.043 (1.172)	loss nan (nan)	prob nan (nan)	GS 29.625 (29.625)	mem 62.966
Train: [10][335/750]	BT 0.094 (1.305)	DT 0.003 (1.154)	loss nan (nan)	prob nan (nan)	GS 42.438 (42.438)	mem 63.108
Train: [10][340/750]	BT 0.156 (1.288)	DT 0.003 (1.138)	loss nan (nan)	prob nan (nan)	GS 31.141 (31.141)	mem 63.422
Train: [10][345/750]	BT 0.202 (1.296)	DT 0.003 (1.145)	loss nan (nan)	prob nan (nan)	GS 27.750 (27.750)	mem 64.843
Train: [10][350/750]	BT 0.285 (1.281)	DT 0.015 (1.129)	loss nan (nan)	prob nan (nan)	GS 30.938 (30.938)	mem 64.610
Train: [10][355/750]	BT 0.175 (1.303)	DT 0.002 (1.151)	loss nan (nan)	prob nan (nan)	GS 31.547 (31.547)	mem 64.642
Train: [10][360/750]	BT 0.143 (1.287)	DT 0.002 (1.135)	loss nan (nan)	prob nan (nan)	GS 31.047 (31.047)	mem 64.644
Train: [10][365/750]	BT 0.326 (1.273)	DT 0.012 (1.119)	loss nan (nan)	prob nan (nan)	GS 31.156 (31.156)	mem 64.724
Train: [10][370/750]	BT 0.105 (1.294)	DT 0.004 (1.141)	loss nan (nan)	prob nan (nan)	GS 34.641 (34.641)	mem 64.552
Train: [10][375/750]	BT 0.133 (1.278)	DT 0.002 (1.125)	loss nan (nan)	prob nan (nan)	GS 31.000 (31.000)	mem 64.557
Train: [10][380/750]	BT 0.107 (1.293)	DT 0.001 (1.140)	loss nan (nan)	prob nan (nan)	GS 34.703 (34.703)	mem 57.963
Train: [10][385/750]	BT 0.171 (1.278)	DT 0.012 (1.125)	loss nan (nan)	prob nan (nan)	GS 30.344 (30.344)	mem 58.130
Train: [10][390/750]	BT 12.689 (1.296)	DT 12.568 (1.143)	loss nan (nan)	prob nan (nan)	GS 34.000 (34.000)	mem 60.421
Train: [10][395/750]	BT 0.169 (1.281)	DT 0.021 (1.129)	loss nan (nan)	prob nan (nan)	GS 29.453 (29.453)	mem 60.514
Train: [10][400/750]	BT 0.181 (1.266)	DT 0.001 (1.115)	loss nan (nan)	prob nan (nan)	GS 35.156 (35.156)	mem 60.649
Train: [10][405/750]	BT 0.151 (1.282)	DT 0.011 (1.131)	loss nan (nan)	prob nan (nan)	GS 29.969 (29.969)	mem 63.268
Train: [10][410/750]	BT 0.162 (1.268)	DT 0.002 (1.117)	loss nan (nan)	prob nan (nan)	GS 34.609 (34.609)	mem 63.306
Train: [10][415/750]	BT 0.119 (1.288)	DT 0.002 (1.137)	loss nan (nan)	prob nan (nan)	GS 30.797 (30.797)	mem 59.127
Train: [10][420/750]	BT 0.182 (1.274)	DT 0.017 (1.124)	loss nan (nan)	prob nan (nan)	GS 35.406 (35.406)	mem 59.269
Train: [10][425/750]	BT 0.157 (1.262)	DT 0.005 (1.111)	loss nan (nan)	prob nan (nan)	GS 25.859 (25.859)	mem 59.712
Train: [10][430/750]	BT 0.094 (1.280)	DT 0.004 (1.129)	loss nan (nan)	prob nan (nan)	GS 35.219 (35.219)	mem 62.384
Train: [10][435/750]	BT 0.082 (1.267)	DT 0.001 (1.117)	loss nan (nan)	prob nan (nan)	GS 31.438 (31.438)	mem 62.581
Train: [10][440/750]	BT 0.095 (1.279)	DT 0.001 (1.129)	loss nan (nan)	prob nan (nan)	GS 36.359 (36.359)	mem 64.603
Train: [10][445/750]	BT 0.267 (1.266)	DT 0.017 (1.116)	loss nan (nan)	prob nan (nan)	GS 30.203 (30.203)	mem 64.613
Train: [10][450/750]	BT 9.572 (1.276)	DT 9.436 (1.125)	loss nan (nan)	prob nan (nan)	GS 34.031 (34.031)	mem 64.609
Train: [10][455/750]	BT 0.228 (1.264)	DT 0.006 (1.113)	loss nan (nan)	prob nan (nan)	GS 36.344 (36.344)	mem 64.633
Train: [10][460/750]	BT 0.168 (1.252)	DT 0.005 (1.101)	loss nan (nan)	prob nan (nan)	GS 33.281 (33.281)	mem 64.699
Train: [10][465/750]	BT 0.144 (1.268)	DT 0.001 (1.116)	loss nan (nan)	prob nan (nan)	GS 28.516 (28.516)	mem 64.684
Train: [10][470/750]	BT 0.151 (1.256)	DT 0.001 (1.104)	loss nan (nan)	prob nan (nan)	GS 29.516 (29.516)	mem 64.570
Train: [10][475/750]	BT 0.116 (1.271)	DT 0.009 (1.118)	loss nan (nan)	prob nan (nan)	GS 33.438 (33.438)	mem 64.644
Train: [10][480/750]	BT 0.191 (1.260)	DT 0.004 (1.107)	loss nan (nan)	prob nan (nan)	GS 33.969 (33.969)	mem 64.698
Train: [10][485/750]	BT 0.175 (1.249)	DT 0.004 (1.096)	loss nan (nan)	prob nan (nan)	GS 32.953 (32.953)	mem 64.625
Train: [10][490/750]	BT 0.138 (1.266)	DT 0.004 (1.112)	loss nan (nan)	prob nan (nan)	GS 36.328 (36.328)	mem 59.882
Train: [10][495/750]	BT 0.097 (1.254)	DT 0.005 (1.101)	loss nan (nan)	prob nan (nan)	GS 33.906 (33.906)	mem 60.108
Train: [10][500/750]	BT 0.137 (1.267)	DT 0.001 (1.114)	loss nan (nan)	prob nan (nan)	GS 30.156 (30.156)	mem 62.511
Train: [10][505/750]	BT 0.258 (1.257)	DT 0.002 (1.103)	loss nan (nan)	prob nan (nan)	GS 31.766 (31.766)	mem 62.634
Train: [10][510/750]	BT 16.256 (1.278)	DT 16.147 (1.124)	loss nan (nan)	prob nan (nan)	GS 33.016 (33.016)	mem 58.813
Train: [10][515/750]	BT 0.165 (1.267)	DT 0.002 (1.113)	loss nan (nan)	prob nan (nan)	GS 30.953 (30.953)	mem 58.947
Train: [10][520/750]	BT 0.139 (1.256)	DT 0.003 (1.103)	loss nan (nan)	prob nan (nan)	GS 35.406 (35.406)	mem 59.207
Train: [10][525/750]	BT 0.154 (1.272)	DT 0.051 (1.119)	loss nan (nan)	prob nan (nan)	GS 31.531 (31.531)	mem 62.302
Train: [10][530/750]	BT 0.200 (1.261)	DT 0.002 (1.109)	loss nan (nan)	prob nan (nan)	GS 32.547 (32.547)	mem 62.455
Train: [10][535/750]	BT 0.210 (1.272)	DT 0.005 (1.120)	loss nan (nan)	prob nan (nan)	GS 32.609 (32.609)	mem 64.615
Train: [10][540/750]	BT 0.130 (1.262)	DT 0.003 (1.109)	loss nan (nan)	prob nan (nan)	GS 38.438 (38.438)	mem 64.656
Train: [10][545/750]	BT 0.306 (1.252)	DT 0.010 (1.099)	loss nan (nan)	prob nan (nan)	GS 27.500 (27.500)	mem 64.659
Train: [10][550/750]	BT 0.138 (1.265)	DT 0.004 (1.112)	loss nan (nan)	prob nan (nan)	GS 28.547 (28.547)	mem 64.614
Train: [10][555/750]	BT 0.295 (1.256)	DT 0.009 (1.102)	loss nan (nan)	prob nan (nan)	GS 31.641 (31.641)	mem 64.646
Train: [10][560/750]	BT 0.161 (1.272)	DT 0.001 (1.118)	loss nan (nan)	prob nan (nan)	GS 35.781 (35.781)	mem 64.622
Train: [10][565/750]	BT 0.230 (1.262)	DT 0.001 (1.108)	loss nan (nan)	prob nan (nan)	GS 32.328 (32.328)	mem 64.742
Train: [10][570/750]	BT 11.966 (1.274)	DT 11.897 (1.119)	loss nan (nan)	prob nan (nan)	GS 40.141 (40.141)	mem 58.303
Train: [10][575/750]	BT 0.092 (1.264)	DT 0.005 (1.110)	loss nan (nan)	prob nan (nan)	GS 32.672 (32.672)	mem 58.125
Train: [10][580/750]	BT 0.126 (1.255)	DT 0.002 (1.101)	loss nan (nan)	prob nan (nan)	GS 29.203 (29.203)	mem 58.317
Train: [10][585/750]	BT 0.097 (1.265)	DT 0.001 (1.111)	loss nan (nan)	prob nan (nan)	GS 29.594 (29.594)	mem 60.203
Train: [10][590/750]	BT 0.186 (1.256)	DT 0.003 (1.102)	loss nan (nan)	prob nan (nan)	GS 36.172 (36.172)	mem 60.355
Train: [10][595/750]	BT 0.104 (1.268)	DT 0.002 (1.115)	loss nan (nan)	prob nan (nan)	GS 33.000 (33.000)	mem 62.830
Train: [10][600/750]	BT 0.114 (1.261)	DT 0.001 (1.108)	loss nan (nan)	prob nan (nan)	GS 36.719 (36.719)	mem 63.352
Train: [10][605/750]	BT 0.167 (1.252)	DT 0.009 (1.099)	loss nan (nan)	prob nan (nan)	GS 30.922 (30.922)	mem 63.435
Train: [10][610/750]	BT 0.108 (1.267)	DT 0.004 (1.115)	loss nan (nan)	prob nan (nan)	GS 31.875 (31.875)	mem 59.604
Train: [10][615/750]	BT 0.120 (1.258)	DT 0.002 (1.106)	loss nan (nan)	prob nan (nan)	GS 29.078 (29.078)	mem 59.730
Train: [10][620/750]	BT 0.105 (1.271)	DT 0.010 (1.119)	loss nan (nan)	prob nan (nan)	GS 34.172 (34.172)	mem 62.432
Train: [10][625/750]	BT 0.095 (1.262)	DT 0.004 (1.110)	loss nan (nan)	prob nan (nan)	GS 31.734 (31.734)	mem 62.479
Train: [10][630/750]	BT 11.320 (1.271)	DT 11.190 (1.119)	loss nan (nan)	prob nan (nan)	GS 34.375 (34.375)	mem 64.620
Train: [10][635/750]	BT 0.111 (1.262)	DT 0.004 (1.110)	loss nan (nan)	prob nan (nan)	GS 31.672 (31.672)	mem 64.681
Train: [10][640/750]	BT 0.224 (1.253)	DT 0.003 (1.101)	loss nan (nan)	prob nan (nan)	GS 33.047 (33.047)	mem 64.625
Train: [10][645/750]	BT 0.115 (1.267)	DT 0.003 (1.115)	loss nan (nan)	prob nan (nan)	GS 29.781 (29.781)	mem 64.663
Train: [10][650/750]	BT 0.220 (1.259)	DT 0.004 (1.107)	loss nan (nan)	prob nan (nan)	GS 37.625 (37.625)	mem 64.641
Train: [10][655/750]	BT 0.142 (1.267)	DT 0.010 (1.116)	loss nan (nan)	prob nan (nan)	GS 31.344 (31.344)	mem 64.652
Train: [10][660/750]	BT 0.134 (1.265)	DT 0.001 (1.114)	loss nan (nan)	prob nan (nan)	GS 33.625 (33.625)	mem 64.519
Train: [10][665/750]	BT 0.165 (1.257)	DT 0.019 (1.106)	loss nan (nan)	prob nan (nan)	GS 33.047 (33.047)	mem 64.467
Train: [10][670/750]	BT 0.182 (1.265)	DT 0.002 (1.113)	loss nan (nan)	prob nan (nan)	GS 33.000 (33.000)	mem 59.484
Train: [10][675/750]	BT 0.205 (1.257)	DT 0.012 (1.105)	loss nan (nan)	prob nan (nan)	GS 30.219 (30.219)	mem 59.727
Train: [10][680/750]	BT 4.064 (1.266)	DT 3.963 (1.114)	loss nan (nan)	prob nan (nan)	GS 35.609 (35.609)	mem 61.910
Train: [10][685/750]	BT 0.288 (1.258)	DT 0.004 (1.106)	loss nan (nan)	prob nan (nan)	GS 35.859 (35.859)	mem 61.958
Train: [10][690/750]	BT 5.783 (1.258)	DT 5.680 (1.106)	loss nan (nan)	prob nan (nan)	GS 33.656 (33.656)	mem 63.097
Train: [10][695/750]	BT 0.125 (1.262)	DT 0.006 (1.111)	loss nan (nan)	prob nan (nan)	GS 30.047 (30.047)	mem 59.862
Train: [10][700/750]	BT 0.173 (1.254)	DT 0.009 (1.103)	loss nan (nan)	prob nan (nan)	GS 33.047 (33.047)	mem 59.645
Train: [10][705/750]	BT 0.141 (1.263)	DT 0.011 (1.112)	loss nan (nan)	prob nan (nan)	GS 29.281 (29.281)	mem 60.727
arpack error, retry= 0
Train: [10][710/750]	BT 0.070 (1.255)	DT 0.001 (1.104)	loss nan (nan)	prob nan (nan)	GS 30.359 (30.359)	mem 60.811
Train: [10][715/750]	BT 0.197 (1.270)	DT 0.006 (1.119)	loss nan (nan)	prob nan (nan)	GS 38.203 (38.203)	mem 64.259
Train: [10][720/750]	BT 0.286 (1.262)	DT 0.005 (1.111)	loss nan (nan)	prob nan (nan)	GS 32.656 (32.656)	mem 64.500
Train: [10][725/750]	BT 0.134 (1.254)	DT 0.005 (1.103)	loss nan (nan)	prob nan (nan)	GS 29.578 (29.578)	mem 64.580
Train: [10][730/750]	BT 0.141 (1.260)	DT 0.004 (1.110)	loss nan (nan)	prob nan (nan)	GS 34.547 (34.547)	mem 64.404
Train: [10][735/750]	BT 0.105 (1.253)	DT 0.001 (1.102)	loss nan (nan)	prob nan (nan)	GS 29.984 (29.984)	mem 64.394
Train: [10][740/750]	BT 0.074 (1.255)	DT 0.001 (1.105)	loss nan (nan)	prob nan (nan)	GS 31.234 (31.234)	mem 35.256
Train: [10][745/750]	BT 0.073 (1.247)	DT 0.001 (1.097)	loss nan (nan)	prob nan (nan)	GS 29.312 (29.312)	mem 35.213
Train: [10][750/750]	BT 1.954 (1.242)	DT 1.854 (1.092)	loss nan (nan)	prob nan (nan)	GS 30.312 (30.312)	mem 32.237
Train: [10][755/750]	BT 0.075 (1.234)	DT 0.001 (1.085)	loss nan (nan)	prob nan (nan)	GS 22.906 (22.906)	mem 32.238
epoch 10, total time 932.08
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [11][1/750]	BT 23.598 (23.598)	DT 23.376 (23.376)	loss nan (nan)	prob nan (nan)	GS 27.281 (27.281)	mem 61.222
Train: [11][5/750]	BT 0.171 (5.677)	DT 0.011 (5.468)	loss nan (nan)	prob nan (nan)	GS 24.969 (24.969)	mem 62.093
Train: [11][10/750]	BT 0.290 (2.922)	DT 0.008 (2.737)	loss nan (nan)	prob nan (nan)	GS 32.219 (32.219)	mem 62.355
Train: [11][15/750]	BT 0.228 (2.784)	DT 0.007 (2.610)	loss nan (nan)	prob nan (nan)	GS 34.734 (34.734)	mem 42.370
Train: [11][20/750]	BT 0.115 (2.124)	DT 0.001 (1.958)	loss nan (nan)	prob nan (nan)	GS 31.734 (31.734)	mem 42.095
Train: [11][25/750]	BT 3.858 (1.912)	DT 3.742 (1.755)	loss nan (nan)	prob nan (nan)	GS 28.609 (28.609)	mem 42.262
Train: [11][30/750]	BT 0.200 (1.990)	DT 0.002 (1.824)	loss nan (nan)	prob nan (nan)	GS 35.141 (35.141)	mem 42.179
Train: [11][35/750]	BT 0.122 (1.726)	DT 0.006 (1.564)	loss nan (nan)	prob nan (nan)	GS 32.625 (32.625)	mem 42.169
Train: [11][40/750]	BT 0.074 (1.846)	DT 0.002 (1.685)	loss nan (nan)	prob nan (nan)	GS 34.953 (34.953)	mem 42.210
Train: [11][45/750]	BT 0.155 (1.659)	DT 0.004 (1.498)	loss nan (nan)	prob nan (nan)	GS 31.062 (31.062)	mem 42.217
Train: [11][50/750]	BT 9.538 (1.729)	DT 9.456 (1.569)	loss nan (nan)	prob nan (nan)	GS 36.109 (36.109)	mem 42.222
Train: [11][55/750]	BT 0.097 (1.582)	DT 0.001 (1.427)	loss nan (nan)	prob nan (nan)	GS 31.125 (31.125)	mem 42.475
Train: [11][60/750]	BT 0.135 (1.461)	DT 0.009 (1.308)	loss nan (nan)	prob nan (nan)	GS 35.094 (35.094)	mem 42.334
Train: [11][65/750]	BT 0.136 (1.543)	DT 0.008 (1.392)	loss nan (nan)	prob nan (nan)	GS 30.406 (30.406)	mem 42.304
Train: [11][70/750]	BT 0.085 (1.439)	DT 0.002 (1.293)	loss nan (nan)	prob nan (nan)	GS 31.953 (31.953)	mem 42.276
Train: [11][75/750]	BT 0.089 (1.519)	DT 0.002 (1.374)	loss nan (nan)	prob nan (nan)	GS 27.781 (27.781)	mem 42.449
Train: [11][80/750]	BT 0.095 (1.430)	DT 0.001 (1.288)	loss nan (nan)	prob nan (nan)	GS 38.391 (38.391)	mem 42.316
Train: [11][85/750]	BT 0.180 (1.355)	DT 0.002 (1.213)	loss nan (nan)	prob nan (nan)	GS 31.656 (31.656)	mem 42.365
Train: [11][90/750]	BT 0.084 (1.421)	DT 0.002 (1.280)	loss nan (nan)	prob nan (nan)	GS 32.969 (32.969)	mem 42.479
Train: [11][95/750]	BT 0.180 (1.356)	DT 0.025 (1.213)	loss nan (nan)	prob nan (nan)	GS 28.688 (28.688)	mem 42.397
Train: [11][100/750]	BT 0.147 (1.425)	DT 0.042 (1.283)	loss nan (nan)	prob nan (nan)	GS 34.422 (34.422)	mem 42.359
Train: [11][105/750]	BT 0.163 (1.363)	DT 0.014 (1.222)	loss nan (nan)	prob nan (nan)	GS 31.484 (31.484)	mem 42.361
Train: [11][110/750]	BT 11.799 (1.412)	DT 11.698 (1.273)	loss nan (nan)	prob nan (nan)	GS 35.562 (35.562)	mem 42.437
Train: [11][115/750]	BT 0.148 (1.372)	DT 0.002 (1.233)	loss nan (nan)	prob nan (nan)	GS 29.188 (29.188)	mem 42.346
Train: [11][120/750]	BT 0.078 (1.319)	DT 0.003 (1.182)	loss nan (nan)	prob nan (nan)	GS 37.031 (37.031)	mem 42.480
Train: [11][125/750]	BT 0.206 (1.378)	DT 0.022 (1.241)	loss nan (nan)	prob nan (nan)	GS 32.219 (32.219)	mem 42.439
Train: [11][130/750]	BT 0.095 (1.330)	DT 0.005 (1.193)	loss nan (nan)	prob nan (nan)	GS 36.047 (36.047)	mem 42.601
Train: [11][135/750]	BT 0.074 (1.358)	DT 0.001 (1.222)	loss nan (nan)	prob nan (nan)	GS 29.781 (29.781)	mem 42.623
Train: [11][140/750]	BT 0.082 (1.340)	DT 0.001 (1.204)	loss nan (nan)	prob nan (nan)	GS 35.250 (35.250)	mem 42.701
Train: [11][145/750]	BT 0.101 (1.300)	DT 0.012 (1.163)	loss nan (nan)	prob nan (nan)	GS 26.938 (26.938)	mem 42.642
Train: [11][150/750]	BT 0.084 (1.359)	DT 0.003 (1.222)	loss nan (nan)	prob nan (nan)	GS 36.906 (36.906)	mem 42.788
Train: [11][155/750]	BT 0.159 (1.319)	DT 0.001 (1.183)	loss nan (nan)	prob nan (nan)	GS 34.172 (34.172)	mem 42.845
Train: [11][160/750]	BT 11.349 (1.364)	DT 11.258 (1.227)	loss nan (nan)	prob nan (nan)	GS 35.344 (35.344)	mem 42.983
Train: [11][165/750]	BT 0.077 (1.325)	DT 0.002 (1.190)	loss nan (nan)	prob nan (nan)	GS 32.109 (32.109)	mem 42.794
Train: [11][170/750]	BT 1.604 (1.299)	DT 1.420 (1.164)	loss nan (nan)	prob nan (nan)	GS 36.891 (36.891)	mem 42.966
Train: [11][175/750]	BT 0.131 (1.325)	DT 0.026 (1.191)	loss nan (nan)	prob nan (nan)	GS 31.719 (31.719)	mem 42.860
Train: [11][180/750]	BT 0.089 (1.292)	DT 0.002 (1.158)	loss nan (nan)	prob nan (nan)	GS 34.516 (34.516)	mem 42.829
Train: [11][185/750]	BT 0.131 (1.330)	DT 0.001 (1.196)	loss nan (nan)	prob nan (nan)	GS 33.703 (33.703)	mem 42.758
Train: [11][190/750]	BT 0.108 (1.298)	DT 0.001 (1.165)	loss nan (nan)	prob nan (nan)	GS 32.859 (32.859)	mem 42.760
Train: [11][195/750]	BT 0.187 (1.287)	DT 0.025 (1.153)	loss nan (nan)	prob nan (nan)	GS 31.922 (31.922)	mem 42.829
Train: [11][200/750]	BT 0.116 (1.282)	DT 0.007 (1.148)	loss nan (nan)	prob nan (nan)	GS 32.891 (32.891)	mem 43.024
Train: [11][205/750]	BT 0.113 (1.253)	DT 0.007 (1.121)	loss nan (nan)	prob nan (nan)	GS 27.453 (27.453)	mem 43.022
Train: [11][210/750]	BT 0.184 (1.271)	DT 0.004 (1.136)	loss nan (nan)	prob nan (nan)	GS 35.625 (35.625)	mem 43.120
Train: [11][215/750]	BT 0.094 (1.244)	DT 0.002 (1.110)	loss nan (nan)	prob nan (nan)	GS 31.453 (31.453)	mem 43.085
Train: [11][220/750]	BT 5.911 (1.280)	DT 5.806 (1.146)	loss nan (nan)	prob nan (nan)	GS 37.031 (37.031)	mem 43.099
Train: [11][225/750]	BT 0.126 (1.254)	DT 0.009 (1.121)	loss nan (nan)	prob nan (nan)	GS 26.219 (26.219)	mem 43.120
Train: [11][230/750]	BT 5.657 (1.254)	DT 5.564 (1.121)	loss nan (nan)	prob nan (nan)	GS 30.141 (30.141)	mem 43.079
Train: [11][235/750]	BT 0.100 (1.264)	DT 0.003 (1.131)	loss nan (nan)	prob nan (nan)	GS 31.312 (31.312)	mem 43.042
Train: [11][240/750]	BT 0.086 (1.240)	DT 0.004 (1.108)	loss nan (nan)	prob nan (nan)	GS 35.203 (35.203)	mem 43.017
Train: [11][245/750]	BT 0.100 (1.257)	DT 0.014 (1.125)	loss nan (nan)	prob nan (nan)	GS 31.797 (31.797)	mem 43.014
Train: [11][250/750]	BT 0.150 (1.235)	DT 0.001 (1.103)	loss nan (nan)	prob nan (nan)	GS 38.750 (38.750)	mem 43.016
Train: [11][255/750]	BT 0.101 (1.239)	DT 0.002 (1.107)	loss nan (nan)	prob nan (nan)	GS 29.875 (29.875)	mem 43.018
Train: [11][260/750]	BT 0.162 (1.237)	DT 0.003 (1.105)	loss nan (nan)	prob nan (nan)	GS 33.719 (33.719)	mem 43.067
Train: [11][265/750]	BT 0.126 (1.216)	DT 0.023 (1.084)	loss nan (nan)	prob nan (nan)	GS 29.250 (29.250)	mem 43.357
Train: [11][270/750]	BT 0.150 (1.237)	DT 0.002 (1.104)	loss nan (nan)	prob nan (nan)	GS 32.844 (32.844)	mem 43.082
Train: [11][275/750]	BT 0.231 (1.217)	DT 0.001 (1.084)	loss nan (nan)	prob nan (nan)	GS 28.812 (28.812)	mem 43.232
Train: [11][280/750]	BT 4.934 (1.228)	DT 4.835 (1.096)	loss nan (nan)	prob nan (nan)	GS 32.062 (32.062)	mem 43.143
Train: [11][285/750]	BT 0.130 (1.209)	DT 0.002 (1.077)	loss nan (nan)	prob nan (nan)	GS 33.109 (33.109)	mem 43.104
Train: [11][290/750]	BT 6.416 (1.219)	DT 6.287 (1.087)	loss nan (nan)	prob nan (nan)	GS 35.719 (35.719)	mem 43.191
Train: [11][295/750]	BT 0.153 (1.205)	DT 0.002 (1.072)	loss nan (nan)	prob nan (nan)	GS 30.891 (30.891)	mem 43.250
Train: [11][300/750]	BT 7.320 (1.219)	DT 7.127 (1.086)	loss nan (nan)	prob nan (nan)	GS 35.344 (35.344)	mem 43.097
Train: [11][305/750]	BT 0.121 (1.208)	DT 0.008 (1.075)	loss nan (nan)	prob nan (nan)	GS 32.656 (32.656)	mem 43.338
Train: [11][310/750]	BT 1.788 (1.199)	DT 1.639 (1.066)	loss nan (nan)	prob nan (nan)	GS 34.828 (34.828)	mem 43.212
Train: [11][315/750]	BT 0.169 (1.221)	DT 0.002 (1.088)	loss nan (nan)	prob nan (nan)	GS 30.734 (30.734)	mem 43.361
Train: [11][320/750]	BT 2.972 (1.213)	DT 2.787 (1.080)	loss nan (nan)	prob nan (nan)	GS 37.875 (37.875)	mem 43.252
Train: [11][325/750]	BT 0.173 (1.211)	DT 0.015 (1.078)	loss nan (nan)	prob nan (nan)	GS 29.875 (29.875)	mem 43.238
Train: [11][330/750]	BT 0.178 (1.210)	DT 0.012 (1.076)	loss nan (nan)	prob nan (nan)	GS 33.438 (33.438)	mem 43.274
Train: [11][335/750]	BT 0.211 (1.198)	DT 0.017 (1.064)	loss nan (nan)	prob nan (nan)	GS 29.641 (29.641)	mem 43.282
Train: [11][340/750]	BT 0.102 (1.219)	DT 0.001 (1.085)	loss nan (nan)	prob nan (nan)	GS 34.719 (34.719)	mem 43.203
Train: [11][345/750]	BT 0.092 (1.203)	DT 0.006 (1.069)	loss nan (nan)	prob nan (nan)	GS 41.562 (41.562)	mem 43.197
Train: [11][350/750]	BT 5.093 (1.219)	DT 5.011 (1.085)	loss nan (nan)	prob nan (nan)	GS 33.125 (33.125)	mem 43.190
Train: [11][355/750]	BT 0.098 (1.204)	DT 0.005 (1.070)	loss nan (nan)	prob nan (nan)	GS 27.156 (27.156)	mem 43.204
Train: [11][360/750]	BT 4.940 (1.202)	DT 4.719 (1.068)	loss nan (nan)	prob nan (nan)	GS 33.500 (33.500)	mem 43.118
Train: [11][365/750]	BT 0.071 (1.208)	DT 0.001 (1.073)	loss nan (nan)	prob nan (nan)	GS 27.844 (27.844)	mem 43.038
Train: [11][370/750]	BT 0.112 (1.193)	DT 0.002 (1.059)	loss nan (nan)	prob nan (nan)	GS 37.250 (37.250)	mem 43.038
Train: [11][375/750]	BT 0.114 (1.207)	DT 0.002 (1.073)	loss nan (nan)	prob nan (nan)	GS 34.406 (34.406)	mem 43.093
Train: [11][380/750]	BT 1.648 (1.197)	DT 1.542 (1.063)	loss nan (nan)	prob nan (nan)	GS 32.422 (32.422)	mem 43.164
Train: [11][385/750]	BT 0.151 (1.200)	DT 0.005 (1.066)	loss nan (nan)	prob nan (nan)	GS 31.953 (31.953)	mem 43.078
Train: [11][390/750]	BT 0.120 (1.196)	DT 0.033 (1.062)	loss nan (nan)	prob nan (nan)	GS 32.109 (32.109)	mem 43.323
Train: [11][395/750]	BT 0.117 (1.190)	DT 0.002 (1.056)	loss nan (nan)	prob nan (nan)	GS 33.094 (33.094)	mem 43.131
Train: [11][400/750]	BT 0.170 (1.198)	DT 0.006 (1.064)	loss nan (nan)	prob nan (nan)	GS 32.719 (32.719)	mem 43.099
Train: [11][405/750]	BT 0.133 (1.201)	DT 0.005 (1.067)	loss nan (nan)	prob nan (nan)	GS 32.578 (32.578)	mem 43.027
Train: [11][410/750]	BT 4.947 (1.200)	DT 4.827 (1.065)	loss nan (nan)	prob nan (nan)	GS 34.375 (34.375)	mem 43.095
Train: [11][415/750]	BT 0.133 (1.191)	DT 0.002 (1.057)	loss nan (nan)	prob nan (nan)	GS 33.297 (33.297)	mem 43.183
Train: [11][420/750]	BT 5.201 (1.200)	DT 5.082 (1.066)	loss nan (nan)	prob nan (nan)	GS 36.859 (36.859)	mem 43.111
Train: [11][425/750]	BT 0.100 (1.203)	DT 0.015 (1.069)	loss nan (nan)	prob nan (nan)	GS 26.078 (26.078)	mem 43.121
Train: [11][430/750]	BT 1.292 (1.194)	DT 1.158 (1.060)	loss nan (nan)	prob nan (nan)	GS 41.250 (41.250)	mem 43.080
Train: [11][435/750]	BT 0.184 (1.207)	DT 0.016 (1.072)	loss nan (nan)	prob nan (nan)	GS 35.297 (35.297)	mem 43.256
Train: [11][440/750]	BT 2.681 (1.200)	DT 2.594 (1.066)	loss nan (nan)	prob nan (nan)	GS 32.344 (32.344)	mem 43.054
Train: [11][445/750]	BT 0.110 (1.194)	DT 0.002 (1.059)	loss nan (nan)	prob nan (nan)	GS 31.672 (31.672)	mem 43.175
Train: [11][450/750]	BT 0.166 (1.199)	DT 0.005 (1.064)	loss nan (nan)	prob nan (nan)	GS 30.578 (30.578)	mem 43.198
Train: [11][455/750]	BT 0.174 (1.188)	DT 0.004 (1.053)	loss nan (nan)	prob nan (nan)	GS 28.844 (28.844)	mem 43.176
Train: [11][460/750]	BT 0.161 (1.207)	DT 0.002 (1.072)	loss nan (nan)	prob nan (nan)	GS 36.453 (36.453)	mem 43.161
Train: [11][465/750]	BT 0.150 (1.196)	DT 0.004 (1.060)	loss nan (nan)	prob nan (nan)	GS 27.906 (27.906)	mem 43.165
Train: [11][470/750]	BT 6.328 (1.209)	DT 6.227 (1.073)	loss nan (nan)	prob nan (nan)	GS 32.797 (32.797)	mem 43.237
Train: [11][475/750]	BT 0.186 (1.197)	DT 0.001 (1.062)	loss nan (nan)	prob nan (nan)	GS 31.859 (31.859)	mem 43.475
Train: [11][480/750]	BT 6.436 (1.199)	DT 6.291 (1.064)	loss nan (nan)	prob nan (nan)	GS 32.750 (32.750)	mem 43.200
Train: [11][485/750]	BT 0.144 (1.199)	DT 0.001 (1.064)	loss nan (nan)	prob nan (nan)	GS 30.906 (30.906)	mem 43.261
Train: [11][490/750]	BT 0.277 (1.189)	DT 0.002 (1.054)	loss nan (nan)	prob nan (nan)	GS 31.531 (31.531)	mem 43.154
Train: [11][495/750]	BT 0.099 (1.206)	DT 0.010 (1.070)	loss nan (nan)	prob nan (nan)	GS 31.453 (31.453)	mem 43.232
Train: [11][500/750]	BT 0.167 (1.195)	DT 0.003 (1.060)	loss nan (nan)	prob nan (nan)	GS 36.922 (36.922)	mem 43.233
Train: [11][505/750]	BT 0.107 (1.192)	DT 0.005 (1.057)	loss nan (nan)	prob nan (nan)	GS 25.344 (25.344)	mem 43.237
Train: [11][510/750]	BT 0.094 (1.197)	DT 0.004 (1.062)	loss nan (nan)	prob nan (nan)	GS 30.047 (30.047)	mem 43.156
Train: [11][515/750]	BT 0.143 (1.187)	DT 0.005 (1.052)	loss nan (nan)	prob nan (nan)	GS 31.953 (31.953)	mem 43.167
Train: [11][520/750]	BT 0.141 (1.197)	DT 0.001 (1.063)	loss nan (nan)	prob nan (nan)	GS 33.922 (33.922)	mem 43.385
Train: [11][525/750]	BT 0.178 (1.191)	DT 0.013 (1.056)	loss nan (nan)	prob nan (nan)	GS 30.906 (30.906)	mem 43.255
Train: [11][530/750]	BT 4.166 (1.195)	DT 4.035 (1.060)	loss nan (nan)	prob nan (nan)	GS 33.422 (33.422)	mem 43.270
Train: [11][535/750]	BT 0.198 (1.185)	DT 0.007 (1.050)	loss nan (nan)	prob nan (nan)	GS 31.812 (31.812)	mem 43.269
Train: [11][540/750]	BT 4.202 (1.191)	DT 4.080 (1.056)	loss nan (nan)	prob nan (nan)	GS 34.109 (34.109)	mem 43.170
Train: [11][545/750]	BT 0.174 (1.187)	DT 0.008 (1.052)	loss nan (nan)	prob nan (nan)	GS 33.969 (33.969)	mem 43.154
Train: [11][550/750]	BT 0.144 (1.182)	DT 0.006 (1.048)	loss nan (nan)	prob nan (nan)	GS 31.125 (31.125)	mem 43.360
Train: [11][555/750]	BT 0.089 (1.191)	DT 0.001 (1.056)	loss nan (nan)	prob nan (nan)	GS 32.562 (32.562)	mem 43.141
Train: [11][560/750]	BT 0.160 (1.182)	DT 0.003 (1.047)	loss nan (nan)	prob nan (nan)	GS 35.188 (35.188)	mem 43.251
Train: [11][565/750]	BT 0.160 (1.186)	DT 0.001 (1.051)	loss nan (nan)	prob nan (nan)	GS 31.766 (31.766)	mem 43.203
Train: [11][570/750]	BT 0.104 (1.179)	DT 0.002 (1.044)	loss nan (nan)	prob nan (nan)	GS 33.266 (33.266)	mem 43.131
Train: [11][575/750]	BT 0.149 (1.179)	DT 0.017 (1.044)	loss nan (nan)	prob nan (nan)	GS 34.891 (34.891)	mem 43.217
Train: [11][580/750]	BT 0.116 (1.177)	DT 0.001 (1.042)	loss nan (nan)	prob nan (nan)	GS 29.312 (29.312)	mem 43.078
Train: [11][585/750]	BT 0.129 (1.176)	DT 0.003 (1.041)	loss nan (nan)	prob nan (nan)	GS 32.719 (32.719)	mem 43.184
Train: [11][590/750]	BT 5.967 (1.180)	DT 5.813 (1.046)	loss nan (nan)	prob nan (nan)	GS 35.797 (35.797)	mem 41.609
Train: [11][595/750]	BT 0.095 (1.172)	DT 0.011 (1.037)	loss nan (nan)	prob nan (nan)	GS 34.656 (34.656)	mem 41.614
Train: [11][600/750]	BT 1.150 (1.168)	DT 0.896 (1.034)	loss nan (nan)	prob nan (nan)	GS 35.688 (35.688)	mem 41.635
Train: [11][605/750]	BT 0.115 (1.171)	DT 0.024 (1.036)	loss nan (nan)	prob nan (nan)	GS 32.984 (32.984)	mem 41.650
Train: [11][610/750]	BT 0.082 (1.175)	DT 0.002 (1.040)	loss nan (nan)	prob nan (nan)	GS 34.297 (34.297)	mem 41.612
Train: [11][615/750]	BT 0.141 (1.169)	DT 0.008 (1.034)	loss nan (nan)	prob nan (nan)	GS 28.266 (28.266)	mem 41.598
Train: [11][620/750]	BT 7.254 (1.177)	DT 7.166 (1.042)	loss nan (nan)	prob nan (nan)	GS 32.906 (32.906)	mem 41.695
Train: [11][625/750]	BT 0.226 (1.169)	DT 0.015 (1.034)	loss nan (nan)	prob nan (nan)	GS 29.531 (29.531)	mem 41.708
Train: [11][630/750]	BT 1.485 (1.168)	DT 1.371 (1.033)	loss nan (nan)	prob nan (nan)	GS 31.094 (31.094)	mem 41.648
Train: [11][635/750]	BT 0.113 (1.174)	DT 0.001 (1.039)	loss nan (nan)	prob nan (nan)	GS 33.938 (33.938)	mem 41.683
Train: [11][640/750]	BT 0.085 (1.169)	DT 0.001 (1.034)	loss nan (nan)	prob nan (nan)	GS 32.703 (32.703)	mem 41.826
Train: [11][645/750]	BT 0.091 (1.174)	DT 0.003 (1.039)	loss nan (nan)	prob nan (nan)	GS 31.266 (31.266)	mem 41.691
Train: [11][650/750]	BT 5.620 (1.174)	DT 5.409 (1.039)	loss nan (nan)	prob nan (nan)	GS 35.578 (35.578)	mem 41.693
Train: [11][655/750]	BT 0.102 (1.166)	DT 0.003 (1.031)	loss nan (nan)	prob nan (nan)	GS 30.000 (30.000)	mem 41.695
Train: [11][660/750]	BT 0.112 (1.165)	DT 0.005 (1.030)	loss nan (nan)	prob nan (nan)	GS 33.125 (33.125)	mem 41.914
Train: [11][665/750]	BT 0.152 (1.176)	DT 0.012 (1.041)	loss nan (nan)	prob nan (nan)	GS 33.641 (33.641)	mem 41.634
Train: [11][670/750]	BT 0.165 (1.170)	DT 0.004 (1.034)	loss nan (nan)	prob nan (nan)	GS 34.922 (34.922)	mem 41.592
Train: [11][675/750]	BT 0.143 (1.177)	DT 0.001 (1.041)	loss nan (nan)	prob nan (nan)	GS 25.594 (25.594)	mem 41.576
Train: [11][680/750]	BT 3.585 (1.174)	DT 3.472 (1.039)	loss nan (nan)	prob nan (nan)	GS 34.031 (34.031)	mem 41.597
Train: [11][685/750]	BT 0.146 (1.167)	DT 0.012 (1.031)	loss nan (nan)	prob nan (nan)	GS 31.031 (31.031)	mem 41.613
Train: [11][690/750]	BT 0.131 (1.171)	DT 0.002 (1.036)	loss nan (nan)	prob nan (nan)	GS 30.859 (30.859)	mem 41.722
Train: [11][695/750]	BT 0.148 (1.170)	DT 0.025 (1.035)	loss nan (nan)	prob nan (nan)	GS 27.484 (27.484)	mem 41.595
Train: [11][700/750]	BT 0.259 (1.172)	DT 0.002 (1.037)	loss nan (nan)	prob nan (nan)	GS 34.531 (34.531)	mem 41.708
Train: [11][705/750]	BT 0.089 (1.169)	DT 0.003 (1.035)	loss nan (nan)	prob nan (nan)	GS 29.656 (29.656)	mem 41.666
arpack error, retry= 0
arpack error, retry= 0
arpack error, retry= 0
Train: [11][710/750]	BT 7.926 (1.173)	DT 7.667 (1.038)	loss nan (nan)	prob nan (nan)	GS 36.500 (36.500)	mem 41.665
Train: [11][715/750]	BT 0.089 (1.166)	DT 0.002 (1.031)	loss nan (nan)	prob nan (nan)	GS 31.172 (31.172)	mem 41.703
Train: [11][720/750]	BT 0.197 (1.166)	DT 0.001 (1.031)	loss nan (nan)	prob nan (nan)	GS 35.250 (35.250)	mem 41.698
Train: [11][725/750]	BT 0.233 (1.165)	DT 0.026 (1.030)	loss nan (nan)	prob nan (nan)	GS 33.234 (33.234)	mem 41.793
Train: [11][730/750]	BT 0.118 (1.172)	DT 0.009 (1.037)	loss nan (nan)	prob nan (nan)	GS 31.938 (31.938)	mem 41.280
Train: [11][735/750]	BT 0.127 (1.165)	DT 0.001 (1.030)	loss nan (nan)	prob nan (nan)	GS 34.641 (34.641)	mem 41.246
Train: [11][740/750]	BT 7.003 (1.167)	DT 6.914 (1.032)	loss nan (nan)	prob nan (nan)	GS 32.672 (32.672)	mem 9.325
Train: [11][745/750]	BT 0.066 (1.159)	DT 0.001 (1.025)	loss nan (nan)	prob nan (nan)	GS 25.906 (25.906)	mem 9.324
Train: [11][750/750]	BT 0.117 (1.152)	DT 0.002 (1.019)	loss nan (nan)	prob nan (nan)	GS 29.000 (29.000)	mem 9.332
Train: [11][755/750]	BT 0.067 (1.147)	DT 0.002 (1.014)	loss nan (nan)	prob nan (nan)	GS 32.156 (32.156)	mem 9.338
epoch 11, total time 866.37
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [12][1/750]	BT 21.219 (21.219)	DT 21.031 (21.031)	loss nan (nan)	prob nan (nan)	GS 28.750 (28.750)	mem 40.450
Train: [12][5/750]	BT 0.117 (5.293)	DT 0.003 (5.150)	loss nan (nan)	prob nan (nan)	GS 31.672 (31.672)	mem 40.367
Train: [12][10/750]	BT 0.101 (2.740)	DT 0.006 (2.578)	loss nan (nan)	prob nan (nan)	GS 29.344 (29.344)	mem 40.382
Train: [12][15/750]	BT 0.126 (2.752)	DT 0.002 (2.592)	loss nan (nan)	prob nan (nan)	GS 33.109 (33.109)	mem 40.812
Train: [12][20/750]	BT 0.221 (2.111)	DT 0.024 (1.947)	loss nan (nan)	prob nan (nan)	GS 32.750 (32.750)	mem 40.722
Train: [12][25/750]	BT 0.162 (1.812)	DT 0.005 (1.652)	loss nan (nan)	prob nan (nan)	GS 31.609 (31.609)	mem 40.809
Train: [12][30/750]	BT 0.257 (1.831)	DT 0.004 (1.672)	loss nan (nan)	prob nan (nan)	GS 36.797 (36.797)	mem 40.903
Train: [12][35/750]	BT 0.154 (1.699)	DT 0.001 (1.545)	loss nan (nan)	prob nan (nan)	GS 38.125 (38.125)	mem 40.793
Train: [12][40/750]	BT 1.753 (1.766)	DT 1.581 (1.613)	loss nan (nan)	prob nan (nan)	GS 37.156 (37.156)	mem 40.867
Train: [12][45/750]	BT 0.124 (1.588)	DT 0.007 (1.435)	loss nan (nan)	prob nan (nan)	GS 35.094 (35.094)	mem 40.924
Train: [12][50/750]	BT 11.423 (1.671)	DT 11.310 (1.518)	loss nan (nan)	prob nan (nan)	GS 33.484 (33.484)	mem 40.777
Train: [12][55/750]	BT 0.235 (1.549)	DT 0.009 (1.398)	loss nan (nan)	prob nan (nan)	GS 30.312 (30.312)	mem 40.853
Train: [12][60/750]	BT 0.149 (1.432)	DT 0.001 (1.282)	loss nan (nan)	prob nan (nan)	GS 31.953 (31.953)	mem 40.902
Train: [12][65/750]	BT 0.205 (1.504)	DT 0.003 (1.355)	loss nan (nan)	prob nan (nan)	GS 27.375 (27.375)	mem 40.809
Train: [12][70/750]	BT 0.466 (1.409)	DT 0.358 (1.263)	loss nan (nan)	prob nan (nan)	GS 35.469 (35.469)	mem 40.810
Train: [12][75/750]	BT 0.099 (1.503)	DT 0.002 (1.359)	loss nan (nan)	prob nan (nan)	GS 33.562 (33.562)	mem 41.244
Train: [12][80/750]	BT 0.095 (1.416)	DT 0.001 (1.274)	loss nan (nan)	prob nan (nan)	GS 32.609 (32.609)	mem 40.992
Train: [12][85/750]	BT 0.176 (1.340)	DT 0.001 (1.199)	loss nan (nan)	prob nan (nan)	GS 29.766 (29.766)	mem 41.232
Train: [12][90/750]	BT 0.076 (1.414)	DT 0.001 (1.276)	loss nan (nan)	prob nan (nan)	GS 31.328 (31.328)	mem 40.376
Train: [12][95/750]	BT 0.097 (1.346)	DT 0.002 (1.209)	loss nan (nan)	prob nan (nan)	GS 35.391 (35.391)	mem 40.327
Train: [12][100/750]	BT 0.086 (1.390)	DT 0.001 (1.253)	loss nan (nan)	prob nan (nan)	GS 29.750 (29.750)	mem 40.378
Train: [12][105/750]	BT 0.144 (1.330)	DT 0.001 (1.193)	loss nan (nan)	prob nan (nan)	GS 29.391 (29.391)	mem 40.381
Train: [12][110/750]	BT 11.123 (1.375)	DT 10.956 (1.239)	loss nan (nan)	prob nan (nan)	GS 34.250 (34.250)	mem 40.685
Train: [12][115/750]	BT 0.093 (1.320)	DT 0.001 (1.185)	loss nan (nan)	prob nan (nan)	GS 32.984 (32.984)	mem 40.585
Train: [12][120/750]	BT 0.082 (1.270)	DT 0.004 (1.136)	loss nan (nan)	prob nan (nan)	GS 31.906 (31.906)	mem 40.607
Train: [12][125/750]	BT 0.123 (1.315)	DT 0.016 (1.181)	loss nan (nan)	prob nan (nan)	GS 33.859 (33.859)	mem 40.670
Train: [12][130/750]	BT 0.111 (1.284)	DT 0.006 (1.150)	loss nan (nan)	prob nan (nan)	GS 34.562 (34.562)	mem 40.677
Train: [12][135/750]	BT 0.103 (1.307)	DT 0.001 (1.173)	loss nan (nan)	prob nan (nan)	GS 31.391 (31.391)	mem 40.662
Train: [12][140/750]	BT 0.133 (1.265)	DT 0.005 (1.132)	loss nan (nan)	prob nan (nan)	GS 30.609 (30.609)	mem 40.666
Train: [12][145/750]	BT 0.159 (1.226)	DT 0.004 (1.093)	loss nan (nan)	prob nan (nan)	GS 33.828 (33.828)	mem 40.673
Train: [12][150/750]	BT 0.133 (1.282)	DT 0.002 (1.151)	loss nan (nan)	prob nan (nan)	GS 35.406 (35.406)	mem 40.592
Train: [12][155/750]	BT 0.140 (1.246)	DT 0.002 (1.114)	loss nan (nan)	prob nan (nan)	GS 29.156 (29.156)	mem 40.652
Train: [12][160/750]	BT 0.169 (1.279)	DT 0.001 (1.147)	loss nan (nan)	prob nan (nan)	GS 35.094 (35.094)	mem 40.699
Train: [12][165/750]	BT 0.103 (1.244)	DT 0.002 (1.112)	loss nan (nan)	prob nan (nan)	GS 33.734 (33.734)	mem 40.658
Train: [12][170/750]	BT 13.979 (1.293)	DT 13.903 (1.161)	loss nan (nan)	prob nan (nan)	GS 33.219 (33.219)	mem 40.687
Train: [12][175/750]	BT 0.093 (1.259)	DT 0.012 (1.128)	loss nan (nan)	prob nan (nan)	GS 42.281 (42.281)	mem 40.688
Train: [12][180/750]	BT 0.189 (1.228)	DT 0.023 (1.097)	loss nan (nan)	prob nan (nan)	GS 34.203 (34.203)	mem 40.689
Train: [12][185/750]	BT 0.099 (1.265)	DT 0.002 (1.134)	loss nan (nan)	prob nan (nan)	GS 28.016 (28.016)	mem 40.694
Train: [12][190/750]	BT 5.375 (1.262)	DT 5.199 (1.132)	loss nan (nan)	prob nan (nan)	GS 36.984 (36.984)	mem 40.811
Train: [12][195/750]	BT 0.133 (1.260)	DT 0.012 (1.130)	loss nan (nan)	prob nan (nan)	GS 31.891 (31.891)	mem 40.711
Train: [12][200/750]	BT 0.132 (1.232)	DT 0.003 (1.102)	loss nan (nan)	prob nan (nan)	GS 31.266 (31.266)	mem 40.710
Train: [12][205/750]	BT 0.100 (1.228)	DT 0.004 (1.098)	loss nan (nan)	prob nan (nan)	GS 35.000 (35.000)	mem 40.833
Train: [12][210/750]	BT 0.099 (1.239)	DT 0.004 (1.110)	loss nan (nan)	prob nan (nan)	GS 30.750 (30.750)	mem 40.720
Train: [12][215/750]	BT 0.161 (1.229)	DT 0.002 (1.100)	loss nan (nan)	prob nan (nan)	GS 30.453 (30.453)	mem 40.725
Train: [12][220/750]	BT 0.127 (1.242)	DT 0.004 (1.113)	loss nan (nan)	prob nan (nan)	GS 33.953 (33.953)	mem 40.737
Train: [12][225/750]	BT 0.184 (1.219)	DT 0.009 (1.088)	loss nan (nan)	prob nan (nan)	GS 34.969 (34.969)	mem 40.696
Train: [12][230/750]	BT 10.043 (1.253)	DT 9.880 (1.122)	loss nan (nan)	prob nan (nan)	GS 33.516 (33.516)	mem 40.764
Train: [12][235/750]	BT 0.141 (1.229)	DT 0.001 (1.098)	loss nan (nan)	prob nan (nan)	GS 30.047 (30.047)	mem 40.824
Train: [12][240/750]	BT 0.106 (1.209)	DT 0.006 (1.079)	loss nan (nan)	prob nan (nan)	GS 35.906 (35.906)	mem 40.776
Train: [12][245/750]	BT 0.126 (1.229)	DT 0.001 (1.098)	loss nan (nan)	prob nan (nan)	GS 34.094 (34.094)	mem 40.875
Train: [12][250/750]	BT 1.053 (1.211)	DT 0.893 (1.080)	loss nan (nan)	prob nan (nan)	GS 35.672 (35.672)	mem 40.816
Train: [12][255/750]	BT 0.151 (1.232)	DT 0.022 (1.101)	loss nan (nan)	prob nan (nan)	GS 26.312 (26.312)	mem 40.811
Train: [12][260/750]	BT 0.082 (1.211)	DT 0.002 (1.080)	loss nan (nan)	prob nan (nan)	GS 35.281 (35.281)	mem 40.922
Train: [12][265/750]	BT 0.090 (1.191)	DT 0.002 (1.060)	loss nan (nan)	prob nan (nan)	GS 35.000 (35.000)	mem 40.803
Train: [12][270/750]	BT 0.099 (1.217)	DT 0.010 (1.087)	loss nan (nan)	prob nan (nan)	GS 35.984 (35.984)	mem 40.811
Train: [12][275/750]	BT 0.169 (1.200)	DT 0.005 (1.069)	loss nan (nan)	prob nan (nan)	GS 32.234 (32.234)	mem 40.947
Train: [12][280/750]	BT 0.132 (1.216)	DT 0.001 (1.086)	loss nan (nan)	prob nan (nan)	GS 29.422 (29.422)	mem 40.838
Train: [12][285/750]	BT 0.137 (1.196)	DT 0.002 (1.067)	loss nan (nan)	prob nan (nan)	GS 42.656 (42.656)	mem 40.908
Train: [12][290/750]	BT 9.068 (1.217)	DT 8.993 (1.088)	loss nan (nan)	prob nan (nan)	GS 31.938 (31.938)	mem 41.188
Train: [12][295/750]	BT 0.084 (1.198)	DT 0.001 (1.070)	loss nan (nan)	prob nan (nan)	GS 36.516 (36.516)	mem 41.007
Train: [12][300/750]	BT 0.100 (1.187)	DT 0.001 (1.058)	loss nan (nan)	prob nan (nan)	GS 26.969 (26.969)	mem 40.890
Train: [12][305/750]	BT 0.154 (1.214)	DT 0.001 (1.085)	loss nan (nan)	prob nan (nan)	GS 32.266 (32.266)	mem 40.910
Train: [12][310/750]	BT 0.091 (1.197)	DT 0.013 (1.068)	loss nan (nan)	prob nan (nan)	GS 30.938 (30.938)	mem 40.844
Train: [12][315/750]	BT 0.201 (1.214)	DT 0.010 (1.085)	loss nan (nan)	prob nan (nan)	GS 48.547 (48.547)	mem 41.116
Train: [12][320/750]	BT 0.127 (1.198)	DT 0.002 (1.068)	loss nan (nan)	prob nan (nan)	GS 34.422 (34.422)	mem 41.030
Train: [12][325/750]	BT 0.142 (1.182)	DT 0.002 (1.052)	loss nan (nan)	prob nan (nan)	GS 28.672 (28.672)	mem 40.929
Train: [12][330/750]	BT 0.162 (1.198)	DT 0.002 (1.067)	loss nan (nan)	prob nan (nan)	GS 35.391 (35.391)	mem 40.939
Train: [12][335/750]	BT 0.141 (1.190)	DT 0.002 (1.060)	loss nan (nan)	prob nan (nan)	GS 31.500 (31.500)	mem 40.940
Train: [12][340/750]	BT 0.123 (1.209)	DT 0.002 (1.079)	loss nan (nan)	prob nan (nan)	GS 32.016 (32.016)	mem 40.868
Train: [12][345/750]	BT 0.155 (1.194)	DT 0.014 (1.063)	loss nan (nan)	prob nan (nan)	GS 30.641 (30.641)	mem 40.869
Train: [12][350/750]	BT 10.778 (1.209)	DT 10.539 (1.078)	loss nan (nan)	prob nan (nan)	GS 28.734 (28.734)	mem 40.879
Train: [12][355/750]	BT 0.104 (1.194)	DT 0.002 (1.063)	loss nan (nan)	prob nan (nan)	GS 31.125 (31.125)	mem 40.843
Train: [12][360/750]	BT 0.099 (1.181)	DT 0.012 (1.050)	loss nan (nan)	prob nan (nan)	GS 31.703 (31.703)	mem 40.930
Train: [12][365/750]	BT 0.064 (1.198)	DT 0.001 (1.067)	loss nan (nan)	prob nan (nan)	GS 29.812 (29.812)	mem 40.941
Train: [12][370/750]	BT 0.226 (1.184)	DT 0.047 (1.053)	loss nan (nan)	prob nan (nan)	GS 31.484 (31.484)	mem 41.064
Train: [12][375/750]	BT 0.094 (1.202)	DT 0.001 (1.072)	loss nan (nan)	prob nan (nan)	GS 36.156 (36.156)	mem 41.054
Train: [12][380/750]	BT 0.123 (1.190)	DT 0.002 (1.060)	loss nan (nan)	prob nan (nan)	GS 33.750 (33.750)	mem 40.994
Train: [12][385/750]	BT 0.176 (1.176)	DT 0.002 (1.046)	loss nan (nan)	prob nan (nan)	GS 31.188 (31.188)	mem 41.021
Train: [12][390/750]	BT 1.478 (1.192)	DT 1.384 (1.062)	loss nan (nan)	prob nan (nan)	GS 33.453 (33.453)	mem 41.011
Train: [12][395/750]	BT 0.268 (1.179)	DT 0.011 (1.049)	loss nan (nan)	prob nan (nan)	GS 33.719 (33.719)	mem 40.832
Train: [12][400/750]	BT 0.074 (1.196)	DT 0.001 (1.066)	loss nan (nan)	prob nan (nan)	GS 33.297 (33.297)	mem 40.879
Train: [12][405/750]	BT 0.092 (1.183)	DT 0.002 (1.053)	loss nan (nan)	prob nan (nan)	GS 32.719 (32.719)	mem 41.122
Train: [12][410/750]	BT 10.936 (1.197)	DT 10.820 (1.067)	loss nan (nan)	prob nan (nan)	GS 32.406 (32.406)	mem 40.920
Train: [12][415/750]	BT 0.085 (1.186)	DT 0.002 (1.055)	loss nan (nan)	prob nan (nan)	GS 30.234 (30.234)	mem 40.857
Train: [12][420/750]	BT 0.120 (1.173)	DT 0.002 (1.043)	loss nan (nan)	prob nan (nan)	GS 31.797 (31.797)	mem 40.897
Train: [12][425/750]	BT 0.092 (1.192)	DT 0.007 (1.062)	loss nan (nan)	prob nan (nan)	GS 35.531 (35.531)	mem 40.885
Train: [12][430/750]	BT 0.110 (1.179)	DT 0.002 (1.049)	loss nan (nan)	prob nan (nan)	GS 32.062 (32.062)	mem 40.888
Train: [12][435/750]	BT 0.092 (1.197)	DT 0.020 (1.067)	loss nan (nan)	prob nan (nan)	GS 32.234 (32.234)	mem 41.003
Train: [12][440/750]	BT 0.138 (1.185)	DT 0.027 (1.055)	loss nan (nan)	prob nan (nan)	GS 33.484 (33.484)	mem 41.005
Train: [12][445/750]	BT 0.148 (1.173)	DT 0.010 (1.043)	loss nan (nan)	prob nan (nan)	GS 30.609 (30.609)	mem 41.252
Train: [12][450/750]	BT 0.146 (1.184)	DT 0.008 (1.055)	loss nan (nan)	prob nan (nan)	GS 35.062 (35.062)	mem 40.954
Train: [12][455/750]	BT 0.264 (1.173)	DT 0.002 (1.043)	loss nan (nan)	prob nan (nan)	GS 25.891 (25.891)	mem 41.175
Train: [12][460/750]	BT 0.098 (1.189)	DT 0.002 (1.059)	loss nan (nan)	prob nan (nan)	GS 36.344 (36.344)	mem 40.990
Train: [12][465/750]	BT 0.136 (1.177)	DT 0.012 (1.047)	loss nan (nan)	prob nan (nan)	GS 30.859 (30.859)	mem 40.992
Train: [12][470/750]	BT 12.921 (1.193)	DT 12.835 (1.064)	loss nan (nan)	prob nan (nan)	GS 32.781 (32.781)	mem 41.090
Train: [12][475/750]	BT 0.136 (1.182)	DT 0.001 (1.052)	loss nan (nan)	prob nan (nan)	GS 33.672 (33.672)	mem 41.092
Train: [12][480/750]	BT 0.096 (1.170)	DT 0.002 (1.042)	loss nan (nan)	prob nan (nan)	GS 35.438 (35.438)	mem 41.091
Train: [12][485/750]	BT 0.078 (1.181)	DT 0.001 (1.053)	loss nan (nan)	prob nan (nan)	GS 37.828 (37.828)	mem 40.930
Train: [12][490/750]	BT 0.103 (1.170)	DT 0.002 (1.042)	loss nan (nan)	prob nan (nan)	GS 32.312 (32.312)	mem 40.930
Train: [12][495/750]	BT 0.276 (1.178)	DT 0.003 (1.050)	loss nan (nan)	prob nan (nan)	GS 32.547 (32.547)	mem 41.335
Train: [12][500/750]	BT 0.155 (1.168)	DT 0.002 (1.039)	loss nan (nan)	prob nan (nan)	GS 32.672 (32.672)	mem 41.032
Train: [12][505/750]	BT 0.122 (1.158)	DT 0.002 (1.029)	loss nan (nan)	prob nan (nan)	GS 32.859 (32.859)	mem 41.033
Train: [12][510/750]	BT 0.081 (1.169)	DT 0.001 (1.040)	loss nan (nan)	prob nan (nan)	GS 31.094 (31.094)	mem 41.032
Train: [12][515/750]	BT 0.120 (1.159)	DT 0.001 (1.030)	loss nan (nan)	prob nan (nan)	GS 31.344 (31.344)	mem 41.032
Train: [12][520/750]	BT 0.079 (1.171)	DT 0.001 (1.043)	loss nan (nan)	prob nan (nan)	GS 33.516 (33.516)	mem 41.010
Train: [12][525/750]	BT 0.134 (1.161)	DT 0.002 (1.033)	loss nan (nan)	prob nan (nan)	GS 34.359 (34.359)	mem 40.976
Train: [12][530/750]	BT 11.391 (1.173)	DT 11.289 (1.044)	loss nan (nan)	prob nan (nan)	GS 34.984 (34.984)	mem 40.949
Train: [12][535/750]	BT 0.106 (1.163)	DT 0.001 (1.035)	loss nan (nan)	prob nan (nan)	GS 26.766 (26.766)	mem 40.949
Train: [12][540/750]	BT 0.105 (1.153)	DT 0.002 (1.025)	loss nan (nan)	prob nan (nan)	GS 30.547 (30.547)	mem 40.951
Train: [12][545/750]	BT 0.105 (1.160)	DT 0.011 (1.032)	loss nan (nan)	prob nan (nan)	GS 30.500 (30.500)	mem 41.028
Train: [12][550/750]	BT 0.160 (1.151)	DT 0.008 (1.022)	loss nan (nan)	prob nan (nan)	GS 29.016 (29.016)	mem 41.030
Train: [12][555/750]	BT 0.148 (1.162)	DT 0.001 (1.034)	loss nan (nan)	prob nan (nan)	GS 30.469 (30.469)	mem 41.031
Train: [12][560/750]	BT 0.100 (1.153)	DT 0.006 (1.025)	loss nan (nan)	prob nan (nan)	GS 33.109 (33.109)	mem 41.033
Train: [12][565/750]	BT 0.178 (1.144)	DT 0.002 (1.015)	loss nan (nan)	prob nan (nan)	GS 29.125 (29.125)	mem 41.170
Train: [12][570/750]	BT 0.080 (1.156)	DT 0.001 (1.028)	loss nan (nan)	prob nan (nan)	GS 34.078 (34.078)	mem 40.919
Train: [12][575/750]	BT 0.142 (1.147)	DT 0.010 (1.019)	loss nan (nan)	prob nan (nan)	GS 33.719 (33.719)	mem 40.961
Train: [12][580/750]	BT 0.129 (1.157)	DT 0.001 (1.029)	loss nan (nan)	prob nan (nan)	GS 36.938 (36.938)	mem 41.288
Train: [12][585/750]	BT 0.103 (1.148)	DT 0.009 (1.020)	loss nan (nan)	prob nan (nan)	GS 30.219 (30.219)	mem 41.034
Train: [12][590/750]	BT 6.511 (1.157)	DT 6.379 (1.028)	loss nan (nan)	prob nan (nan)	GS 31.266 (31.266)	mem 40.962
Train: [12][595/750]	BT 0.118 (1.148)	DT 0.002 (1.020)	loss nan (nan)	prob nan (nan)	GS 28.719 (28.719)	mem 41.040
Train: [12][600/750]	BT 10.062 (1.156)	DT 9.986 (1.028)	loss nan (nan)	prob nan (nan)	GS 32.516 (32.516)	mem 41.078
Train: [12][605/750]	BT 0.134 (1.151)	DT 0.002 (1.023)	loss nan (nan)	prob nan (nan)	GS 25.297 (25.297)	mem 40.973
Train: [12][610/750]	BT 0.155 (1.143)	DT 0.007 (1.014)	loss nan (nan)	prob nan (nan)	GS 28.672 (28.672)	mem 40.974
Train: [12][615/750]	BT 0.112 (1.152)	DT 0.010 (1.024)	loss nan (nan)	prob nan (nan)	GS 31.000 (31.000)	mem 41.039
Train: [12][620/750]	BT 0.127 (1.144)	DT 0.010 (1.016)	loss nan (nan)	prob nan (nan)	GS 30.859 (30.859)	mem 41.087
Train: [12][625/750]	BT 0.073 (1.155)	DT 0.001 (1.027)	loss nan (nan)	prob nan (nan)	GS 32.500 (32.500)	mem 40.885
Train: [12][630/750]	BT 0.107 (1.147)	DT 0.005 (1.019)	loss nan (nan)	prob nan (nan)	GS 31.016 (31.016)	mem 40.861
Train: [12][635/750]	BT 0.233 (1.142)	DT 0.007 (1.013)	loss nan (nan)	prob nan (nan)	GS 29.578 (29.578)	mem 40.907
Train: [12][640/750]	BT 0.094 (1.150)	DT 0.001 (1.021)	loss nan (nan)	prob nan (nan)	GS 36.016 (36.016)	mem 40.819
Train: [12][645/750]	BT 0.260 (1.143)	DT 0.029 (1.014)	loss nan (nan)	prob nan (nan)	GS 47.969 (47.969)	mem 40.770
Train: [12][650/750]	BT 0.090 (1.155)	DT 0.002 (1.025)	loss nan (nan)	prob nan (nan)	GS 29.031 (29.031)	mem 40.839
Train: [12][655/750]	BT 0.123 (1.147)	DT 0.002 (1.018)	loss nan (nan)	prob nan (nan)	GS 33.234 (33.234)	mem 40.837
Train: [12][660/750]	BT 11.658 (1.156)	DT 11.507 (1.027)	loss nan (nan)	prob nan (nan)	GS 35.328 (35.328)	mem 40.876
Train: [12][665/750]	BT 0.163 (1.149)	DT 0.029 (1.020)	loss nan (nan)	prob nan (nan)	GS 34.016 (34.016)	mem 40.880
Train: [12][670/750]	BT 0.122 (1.141)	DT 0.001 (1.012)	loss nan (nan)	prob nan (nan)	GS 33.875 (33.875)	mem 40.881
Train: [12][675/750]	BT 0.126 (1.151)	DT 0.001 (1.022)	loss nan (nan)	prob nan (nan)	GS 32.031 (32.031)	mem 41.000
Train: [12][680/750]	BT 0.118 (1.144)	DT 0.002 (1.014)	loss nan (nan)	prob nan (nan)	GS 37.875 (37.875)	mem 40.893
Train: [12][685/750]	BT 0.156 (1.156)	DT 0.002 (1.027)	loss nan (nan)	prob nan (nan)	GS 29.172 (29.172)	mem 40.859
Train: [12][690/750]	BT 0.086 (1.149)	DT 0.002 (1.019)	loss nan (nan)	prob nan (nan)	GS 32.234 (32.234)	mem 40.860
Train: [12][695/750]	BT 0.218 (1.141)	DT 0.002 (1.012)	loss nan (nan)	prob nan (nan)	GS 35.719 (35.719)	mem 40.956
Train: [12][700/750]	BT 0.088 (1.153)	DT 0.006 (1.023)	loss nan (nan)	prob nan (nan)	GS 35.172 (35.172)	mem 40.953
Train: [12][705/750]	BT 0.117 (1.145)	DT 0.002 (1.016)	loss nan (nan)	prob nan (nan)	GS 28.562 (28.562)	mem 40.967
arpack error, retry= 0
arpack error, retry= 0
Train: [12][710/750]	BT 0.137 (1.154)	DT 0.004 (1.025)	loss nan (nan)	prob nan (nan)	GS 32.641 (32.641)	mem 40.843
Train: [12][715/750]	BT 0.097 (1.147)	DT 0.002 (1.018)	loss nan (nan)	prob nan (nan)	GS 35.281 (35.281)	mem 40.914
Train: [12][720/750]	BT 13.247 (1.158)	DT 13.169 (1.029)	loss nan (nan)	prob nan (nan)	GS 34.500 (34.500)	mem 40.923
Train: [12][725/750]	BT 0.088 (1.151)	DT 0.002 (1.022)	loss nan (nan)	prob nan (nan)	GS 32.500 (32.500)	mem 40.858
Train: [12][730/750]	BT 0.096 (1.144)	DT 0.002 (1.015)	loss nan (nan)	prob nan (nan)	GS 34.156 (34.156)	mem 40.858
Train: [12][735/750]	BT 0.062 (1.147)	DT 0.001 (1.018)	loss nan (nan)	prob nan (nan)	GS 30.453 (30.453)	mem 40.259
Train: [12][740/750]	BT 0.076 (1.139)	DT 0.001 (1.011)	loss nan (nan)	prob nan (nan)	GS 32.891 (32.891)	mem 40.223
Train: [12][745/750]	BT 0.060 (1.138)	DT 0.001 (1.010)	loss nan (nan)	prob nan (nan)	GS 31.625 (31.625)	mem 8.527
Train: [12][750/750]	BT 0.067 (1.131)	DT 0.001 (1.004)	loss nan (nan)	prob nan (nan)	GS 36.531 (36.531)	mem 8.528
Train: [12][755/750]	BT 0.077 (1.124)	DT 0.001 (0.997)	loss nan (nan)	prob nan (nan)	GS 34.531 (34.531)	mem 8.556
epoch 12, total time 851.04
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [13][1/750]	BT 21.013 (21.013)	DT 20.832 (20.832)	loss nan (nan)	prob nan (nan)	GS 29.547 (29.547)	mem 39.758
Train: [13][5/750]	BT 0.137 (4.506)	DT 0.001 (4.355)	loss nan (nan)	prob nan (nan)	GS 29.922 (29.922)	mem 40.068
Train: [13][10/750]	BT 4.436 (2.779)	DT 4.214 (2.603)	loss nan (nan)	prob nan (nan)	GS 37.031 (37.031)	mem 40.201
Train: [13][15/750]	BT 0.097 (2.256)	DT 0.010 (2.093)	loss nan (nan)	prob nan (nan)	GS 25.984 (25.984)	mem 40.258
Train: [13][20/750]	BT 2.763 (1.925)	DT 2.558 (1.769)	loss nan (nan)	prob nan (nan)	GS 32.625 (32.625)	mem 40.362
Train: [13][25/750]	BT 0.140 (1.731)	DT 0.002 (1.570)	loss nan (nan)	prob nan (nan)	GS 29.266 (29.266)	mem 40.304
Train: [13][30/750]	BT 0.166 (1.719)	DT 0.004 (1.559)	loss nan (nan)	prob nan (nan)	GS 36.844 (36.844)	mem 40.459
Train: [13][35/750]	BT 0.113 (1.738)	DT 0.002 (1.583)	loss nan (nan)	prob nan (nan)	GS 32.141 (32.141)	mem 40.474
Train: [13][40/750]	BT 0.809 (1.673)	DT 0.615 (1.520)	loss nan (nan)	prob nan (nan)	GS 35.969 (35.969)	mem 40.498
Train: [13][45/750]	BT 0.228 (1.601)	DT 0.009 (1.447)	loss nan (nan)	prob nan (nan)	GS 33.422 (33.422)	mem 40.452
Train: [13][50/750]	BT 4.894 (1.590)	DT 4.786 (1.436)	loss nan (nan)	prob nan (nan)	GS 33.484 (33.484)	mem 40.544
Train: [13][55/750]	BT 0.261 (1.485)	DT 0.003 (1.331)	loss nan (nan)	prob nan (nan)	GS 36.859 (36.859)	mem 40.698
Train: [13][60/750]	BT 0.116 (1.505)	DT 0.002 (1.353)	loss nan (nan)	prob nan (nan)	GS 35.875 (35.875)	mem 41.086
Train: [13][65/750]	BT 0.087 (1.466)	DT 0.001 (1.314)	loss nan (nan)	prob nan (nan)	GS 32.109 (32.109)	mem 40.505
Train: [13][70/750]	BT 4.713 (1.522)	DT 4.541 (1.372)	loss nan (nan)	prob nan (nan)	GS 35.219 (35.219)	mem 40.648
Train: [13][75/750]	BT 0.143 (1.428)	DT 0.002 (1.281)	loss nan (nan)	prob nan (nan)	GS 32.047 (32.047)	mem 40.605
Train: [13][80/750]	BT 2.222 (1.386)	DT 2.111 (1.242)	loss nan (nan)	prob nan (nan)	GS 34.484 (34.484)	mem 40.505
Train: [13][85/750]	BT 0.175 (1.428)	DT 0.007 (1.284)	loss nan (nan)	prob nan (nan)	GS 31.781 (31.781)	mem 40.572
Train: [13][90/750]	BT 0.192 (1.356)	DT 0.002 (1.213)	loss nan (nan)	prob nan (nan)	GS 36.125 (36.125)	mem 40.574
Train: [13][95/750]	BT 0.080 (1.413)	DT 0.002 (1.271)	loss nan (nan)	prob nan (nan)	GS 29.453 (29.453)	mem 40.705
Train: [13][100/750]	BT 0.233 (1.350)	DT 0.052 (1.208)	loss nan (nan)	prob nan (nan)	GS 37.594 (37.594)	mem 40.679
Train: [13][105/750]	BT 0.102 (1.337)	DT 0.003 (1.194)	loss nan (nan)	prob nan (nan)	GS 32.000 (32.000)	mem 40.648
Train: [13][110/750]	BT 0.131 (1.360)	DT 0.001 (1.218)	loss nan (nan)	prob nan (nan)	GS 34.578 (34.578)	mem 40.736
Train: [13][115/750]	BT 0.097 (1.316)	DT 0.002 (1.175)	loss nan (nan)	prob nan (nan)	GS 31.219 (31.219)	mem 40.704
Train: [13][120/750]	BT 0.157 (1.349)	DT 0.001 (1.209)	loss nan (nan)	prob nan (nan)	GS 34.609 (34.609)	mem 40.707
Train: [13][125/750]	BT 0.112 (1.322)	DT 0.008 (1.182)	loss nan (nan)	prob nan (nan)	GS 29.453 (29.453)	mem 40.748
Train: [13][130/750]	BT 9.117 (1.345)	DT 9.039 (1.206)	loss nan (nan)	prob nan (nan)	GS 34.141 (34.141)	mem 40.798
Train: [13][135/750]	BT 0.119 (1.299)	DT 0.001 (1.161)	loss nan (nan)	prob nan (nan)	GS 29.125 (29.125)	mem 40.797
Train: [13][140/750]	BT 1.285 (1.275)	DT 1.168 (1.138)	loss nan (nan)	prob nan (nan)	GS 37.266 (37.266)	mem 40.861
Train: [13][145/750]	BT 0.121 (1.296)	DT 0.002 (1.158)	loss nan (nan)	prob nan (nan)	GS 29.531 (29.531)	mem 40.826
Train: [13][150/750]	BT 0.166 (1.276)	DT 0.010 (1.139)	loss nan (nan)	prob nan (nan)	GS 30.609 (30.609)	mem 40.772
Train: [13][155/750]	BT 0.117 (1.312)	DT 0.002 (1.176)	loss nan (nan)	prob nan (nan)	GS 25.734 (25.734)	mem 40.730
Train: [13][160/750]	BT 0.625 (1.278)	DT 0.462 (1.142)	loss nan (nan)	prob nan (nan)	GS 34.703 (34.703)	mem 40.857
Train: [13][165/750]	BT 0.190 (1.243)	DT 0.001 (1.107)	loss nan (nan)	prob nan (nan)	GS 33.141 (33.141)	mem 40.793
Train: [13][170/750]	BT 0.124 (1.280)	DT 0.001 (1.145)	loss nan (nan)	prob nan (nan)	GS 35.641 (35.641)	mem 40.806
Train: [13][175/750]	BT 0.207 (1.249)	DT 0.010 (1.113)	loss nan (nan)	prob nan (nan)	GS 34.594 (34.594)	mem 40.840
Train: [13][180/750]	BT 0.083 (1.304)	DT 0.001 (1.168)	loss nan (nan)	prob nan (nan)	GS 34.797 (34.797)	mem 40.930
Train: [13][185/750]	BT 0.199 (1.272)	DT 0.011 (1.136)	loss nan (nan)	prob nan (nan)	GS 28.406 (28.406)	mem 40.866
Train: [13][190/750]	BT 13.188 (1.311)	DT 13.048 (1.175)	loss nan (nan)	prob nan (nan)	GS 35.188 (35.188)	mem 41.202
Train: [13][195/750]	BT 0.143 (1.280)	DT 0.005 (1.146)	loss nan (nan)	prob nan (nan)	GS 29.969 (29.969)	mem 41.111
Train: [13][200/750]	BT 0.149 (1.251)	DT 0.002 (1.117)	loss nan (nan)	prob nan (nan)	GS 40.875 (40.875)	mem 41.234
Train: [13][205/750]	BT 0.196 (1.288)	DT 0.001 (1.154)	loss nan (nan)	prob nan (nan)	GS 27.844 (27.844)	mem 40.834
Train: [13][210/750]	BT 0.153 (1.260)	DT 0.001 (1.126)	loss nan (nan)	prob nan (nan)	GS 37.891 (37.891)	mem 40.863
Train: [13][215/750]	BT 0.204 (1.292)	DT 0.013 (1.158)	loss nan (nan)	prob nan (nan)	GS 29.328 (29.328)	mem 40.898
Train: [13][220/750]	BT 0.174 (1.266)	DT 0.001 (1.131)	loss nan (nan)	prob nan (nan)	GS 34.359 (34.359)	mem 41.038
Train: [13][225/750]	BT 0.163 (1.240)	DT 0.001 (1.106)	loss nan (nan)	prob nan (nan)	GS 32.266 (32.266)	mem 40.943
Train: [13][230/750]	BT 0.169 (1.274)	DT 0.020 (1.141)	loss nan (nan)	prob nan (nan)	GS 35.422 (35.422)	mem 40.985
Train: [13][235/750]	BT 0.164 (1.250)	DT 0.001 (1.117)	loss nan (nan)	prob nan (nan)	GS 30.406 (30.406)	mem 40.946
Train: [13][240/750]	BT 0.062 (1.266)	DT 0.002 (1.132)	loss nan (nan)	prob nan (nan)	GS 34.531 (34.531)	mem 40.982
Train: [13][245/750]	BT 0.100 (1.242)	DT 0.004 (1.109)	loss nan (nan)	prob nan (nan)	GS 26.891 (26.891)	mem 40.920
Train: [13][250/750]	BT 10.354 (1.261)	DT 10.230 (1.128)	loss nan (nan)	prob nan (nan)	GS 33.516 (33.516)	mem 40.925
Train: [13][255/750]	BT 0.327 (1.239)	DT 0.054 (1.106)	loss nan (nan)	prob nan (nan)	GS 31.672 (31.672)	mem 41.151
Train: [13][260/750]	BT 0.138 (1.218)	DT 0.001 (1.085)	loss nan (nan)	prob nan (nan)	GS 36.422 (36.422)	mem 41.052
Train: [13][265/750]	BT 0.097 (1.238)	DT 0.005 (1.105)	loss nan (nan)	prob nan (nan)	GS 31.500 (31.500)	mem 41.037
Train: [13][270/750]	BT 0.087 (1.217)	DT 0.001 (1.085)	loss nan (nan)	prob nan (nan)	GS 37.859 (37.859)	mem 40.760
Train: [13][275/750]	BT 0.138 (1.246)	DT 0.002 (1.113)	loss nan (nan)	prob nan (nan)	GS 30.266 (30.266)	mem 40.729
Train: [13][280/750]	BT 0.120 (1.226)	DT 0.013 (1.093)	loss nan (nan)	prob nan (nan)	GS 38.828 (38.828)	mem 40.819
Train: [13][285/750]	BT 0.111 (1.207)	DT 0.011 (1.074)	loss nan (nan)	prob nan (nan)	GS 33.031 (33.031)	mem 40.791
Train: [13][290/750]	BT 0.099 (1.230)	DT 0.004 (1.097)	loss nan (nan)	prob nan (nan)	GS 34.422 (34.422)	mem 40.837
Train: [13][295/750]	BT 0.183 (1.212)	DT 0.015 (1.079)	loss nan (nan)	prob nan (nan)	GS 31.328 (31.328)	mem 40.892
Train: [13][300/750]	BT 0.079 (1.231)	DT 0.001 (1.098)	loss nan (nan)	prob nan (nan)	GS 35.438 (35.438)	mem 40.881
Train: [13][305/750]	BT 0.090 (1.223)	DT 0.002 (1.090)	loss nan (nan)	prob nan (nan)	GS 27.469 (27.469)	mem 40.840
Train: [13][310/750]	BT 8.146 (1.231)	DT 7.870 (1.098)	loss nan (nan)	prob nan (nan)	GS 30.922 (30.922)	mem 40.909
Train: [13][315/750]	BT 0.177 (1.214)	DT 0.001 (1.081)	loss nan (nan)	prob nan (nan)	GS 30.781 (30.781)	mem 40.909
Train: [13][320/750]	BT 0.099 (1.213)	DT 0.002 (1.079)	loss nan (nan)	prob nan (nan)	GS 32.234 (32.234)	mem 40.969
Train: [13][325/750]	BT 0.112 (1.217)	DT 0.002 (1.084)	loss nan (nan)	prob nan (nan)	GS 33.609 (33.609)	mem 41.331
Train: [13][330/750]	BT 0.100 (1.222)	DT 0.010 (1.089)	loss nan (nan)	prob nan (nan)	GS 31.453 (31.453)	mem 41.664
Train: [13][335/750]	BT 0.151 (1.212)	DT 0.002 (1.079)	loss nan (nan)	prob nan (nan)	GS 29.953 (29.953)	mem 42.026
Train: [13][340/750]	BT 3.570 (1.218)	DT 3.402 (1.086)	loss nan (nan)	prob nan (nan)	GS 33.250 (33.250)	mem 42.966
Train: [13][345/750]	BT 0.224 (1.203)	DT 0.002 (1.070)	loss nan (nan)	prob nan (nan)	GS 31.344 (31.344)	mem 43.138
Train: [13][350/750]	BT 2.700 (1.214)	DT 2.589 (1.082)	loss nan (nan)	prob nan (nan)	GS 30.750 (30.750)	mem 42.860
Train: [13][355/750]	BT 0.213 (1.203)	DT 0.008 (1.069)	loss nan (nan)	prob nan (nan)	GS 29.828 (29.828)	mem 42.881
Train: [13][360/750]	BT 0.159 (1.208)	DT 0.001 (1.074)	loss nan (nan)	prob nan (nan)	GS 30.047 (30.047)	mem 42.809
Train: [13][365/750]	BT 0.213 (1.201)	DT 0.041 (1.066)	loss nan (nan)	prob nan (nan)	GS 28.438 (28.438)	mem 42.886
Train: [13][370/750]	BT 4.246 (1.211)	DT 4.138 (1.076)	loss nan (nan)	prob nan (nan)	GS 31.969 (31.969)	mem 42.600
Train: [13][375/750]	BT 0.089 (1.196)	DT 0.002 (1.062)	loss nan (nan)	prob nan (nan)	GS 35.219 (35.219)	mem 42.726
Train: [13][380/750]	BT 2.763 (1.199)	DT 2.519 (1.064)	loss nan (nan)	prob nan (nan)	GS 35.172 (35.172)	mem 42.749
Train: [13][385/750]	BT 0.099 (1.208)	DT 0.007 (1.073)	loss nan (nan)	prob nan (nan)	GS 30.953 (30.953)	mem 42.696
Train: [13][390/750]	BT 0.187 (1.195)	DT 0.051 (1.060)	loss nan (nan)	prob nan (nan)	GS 32.406 (32.406)	mem 42.881
Train: [13][395/750]	BT 0.089 (1.206)	DT 0.002 (1.071)	loss nan (nan)	prob nan (nan)	GS 31.281 (31.281)	mem 42.546
Train: [13][400/750]	BT 0.122 (1.193)	DT 0.034 (1.058)	loss nan (nan)	prob nan (nan)	GS 31.359 (31.359)	mem 42.631
Train: [13][405/750]	BT 0.120 (1.186)	DT 0.002 (1.051)	loss nan (nan)	prob nan (nan)	GS 32.578 (32.578)	mem 42.567
Train: [13][410/750]	BT 0.082 (1.202)	DT 0.001 (1.067)	loss nan (nan)	prob nan (nan)	GS 31.281 (31.281)	mem 42.437
Train: [13][415/750]	BT 0.114 (1.189)	DT 0.009 (1.054)	loss nan (nan)	prob nan (nan)	GS 29.594 (29.594)	mem 42.500
Train: [13][420/750]	BT 0.093 (1.208)	DT 0.001 (1.074)	loss nan (nan)	prob nan (nan)	GS 33.875 (33.875)	mem 42.350
Train: [13][425/750]	BT 0.104 (1.196)	DT 0.001 (1.062)	loss nan (nan)	prob nan (nan)	GS 30.219 (30.219)	mem 42.352
Train: [13][430/750]	BT 10.801 (1.209)	DT 10.639 (1.074)	loss nan (nan)	prob nan (nan)	GS 31.812 (31.812)	mem 42.380
Train: [13][435/750]	BT 0.127 (1.196)	DT 0.002 (1.062)	loss nan (nan)	prob nan (nan)	GS 34.562 (34.562)	mem 42.375
Train: [13][440/750]	BT 0.171 (1.187)	DT 0.005 (1.053)	loss nan (nan)	prob nan (nan)	GS 34.719 (34.719)	mem 42.443
Train: [13][445/750]	BT 0.120 (1.204)	DT 0.005 (1.069)	loss nan (nan)	prob nan (nan)	GS 29.641 (29.641)	mem 42.398
Train: [13][450/750]	BT 1.259 (1.195)	DT 1.134 (1.060)	loss nan (nan)	prob nan (nan)	GS 34.172 (34.172)	mem 42.377
Train: [13][455/750]	BT 0.071 (1.207)	DT 0.002 (1.073)	loss nan (nan)	prob nan (nan)	GS 38.328 (38.328)	mem 42.403
Train: [13][460/750]	BT 0.152 (1.196)	DT 0.003 (1.061)	loss nan (nan)	prob nan (nan)	GS 34.656 (34.656)	mem 42.402
Train: [13][465/750]	BT 0.136 (1.192)	DT 0.002 (1.058)	loss nan (nan)	prob nan (nan)	GS 33.047 (33.047)	mem 42.535
Train: [13][470/750]	BT 0.117 (1.196)	DT 0.004 (1.062)	loss nan (nan)	prob nan (nan)	GS 31.281 (31.281)	mem 42.285
Train: [13][475/750]	BT 0.163 (1.190)	DT 0.002 (1.056)	loss nan (nan)	prob nan (nan)	GS 33.422 (33.422)	mem 42.332
Train: [13][480/750]	BT 0.110 (1.197)	DT 0.011 (1.062)	loss nan (nan)	prob nan (nan)	GS 33.891 (33.891)	mem 42.291
Train: [13][485/750]	BT 0.255 (1.186)	DT 0.010 (1.051)	loss nan (nan)	prob nan (nan)	GS 31.750 (31.750)	mem 42.306
Train: [13][490/750]	BT 13.286 (1.205)	DT 13.211 (1.071)	loss nan (nan)	prob nan (nan)	GS 35.203 (35.203)	mem 42.386
Train: [13][495/750]	BT 0.175 (1.194)	DT 0.002 (1.060)	loss nan (nan)	prob nan (nan)	GS 31.078 (31.078)	mem 42.324
Train: [13][500/750]	BT 0.091 (1.183)	DT 0.002 (1.049)	loss nan (nan)	prob nan (nan)	GS 33.453 (33.453)	mem 42.507
Train: [13][505/750]	BT 0.081 (1.191)	DT 0.002 (1.058)	loss nan (nan)	prob nan (nan)	GS 32.391 (32.391)	mem 42.399
Train: [13][510/750]	BT 5.368 (1.191)	DT 5.291 (1.058)	loss nan (nan)	prob nan (nan)	GS 33.969 (33.969)	mem 42.626
Train: [13][515/750]	BT 0.135 (1.192)	DT 0.002 (1.059)	loss nan (nan)	prob nan (nan)	GS 31.938 (31.938)	mem 42.371
Train: [13][520/750]	BT 0.165 (1.183)	DT 0.012 (1.049)	loss nan (nan)	prob nan (nan)	GS 28.953 (28.953)	mem 42.513
Train: [13][525/750]	BT 0.211 (1.175)	DT 0.012 (1.041)	loss nan (nan)	prob nan (nan)	GS 35.141 (35.141)	mem 42.530
Train: [13][530/750]	BT 0.089 (1.184)	DT 0.002 (1.051)	loss nan (nan)	prob nan (nan)	GS 36.719 (36.719)	mem 42.424
Train: [13][535/750]	BT 0.261 (1.174)	DT 0.014 (1.041)	loss nan (nan)	prob nan (nan)	GS 31.266 (31.266)	mem 42.659
Train: [13][540/750]	BT 1.128 (1.189)	DT 1.031 (1.055)	loss nan (nan)	prob nan (nan)	GS 33.312 (33.312)	mem 42.420
Train: [13][545/750]	BT 0.112 (1.179)	DT 0.001 (1.046)	loss nan (nan)	prob nan (nan)	GS 31.844 (31.844)	mem 42.421
Train: [13][550/750]	BT 8.826 (1.186)	DT 8.618 (1.052)	loss nan (nan)	prob nan (nan)	GS 28.891 (28.891)	mem 42.572
Train: [13][555/750]	BT 0.105 (1.176)	DT 0.002 (1.043)	loss nan (nan)	prob nan (nan)	GS 33.312 (33.312)	mem 42.449
Train: [13][560/750]	BT 0.119 (1.167)	DT 0.002 (1.033)	loss nan (nan)	prob nan (nan)	GS 35.875 (35.875)	mem 42.408
Train: [13][565/750]	BT 0.095 (1.186)	DT 0.005 (1.053)	loss nan (nan)	prob nan (nan)	GS 33.781 (33.781)	mem 42.430
Train: [13][570/750]	BT 0.119 (1.176)	DT 0.002 (1.043)	loss nan (nan)	prob nan (nan)	GS 34.234 (34.234)	mem 42.463
Train: [13][575/750]	BT 0.157 (1.185)	DT 0.002 (1.052)	loss nan (nan)	prob nan (nan)	GS 29.547 (29.547)	mem 42.525
Train: [13][580/750]	BT 0.131 (1.176)	DT 0.002 (1.043)	loss nan (nan)	prob nan (nan)	GS 34.125 (34.125)	mem 42.492
Train: [13][585/750]	BT 0.089 (1.167)	DT 0.007 (1.034)	loss nan (nan)	prob nan (nan)	GS 29.938 (29.938)	mem 42.461
Train: [13][590/750]	BT 0.148 (1.178)	DT 0.008 (1.046)	loss nan (nan)	prob nan (nan)	GS 35.641 (35.641)	mem 42.543
Train: [13][595/750]	BT 0.106 (1.169)	DT 0.005 (1.037)	loss nan (nan)	prob nan (nan)	GS 29.922 (29.922)	mem 42.453
Train: [13][600/750]	BT 0.136 (1.182)	DT 0.005 (1.049)	loss nan (nan)	prob nan (nan)	GS 30.547 (30.547)	mem 42.663
Train: [13][605/750]	BT 0.080 (1.173)	DT 0.001 (1.041)	loss nan (nan)	prob nan (nan)	GS 35.375 (35.375)	mem 42.530
Train: [13][610/750]	BT 13.294 (1.186)	DT 13.188 (1.054)	loss nan (nan)	prob nan (nan)	GS 33.891 (33.891)	mem 42.434
Train: [13][615/750]	BT 0.112 (1.177)	DT 0.002 (1.045)	loss nan (nan)	prob nan (nan)	GS 30.734 (30.734)	mem 42.543
Train: [13][620/750]	BT 0.174 (1.169)	DT 0.001 (1.037)	loss nan (nan)	prob nan (nan)	GS 32.469 (32.469)	mem 42.471
Train: [13][625/750]	BT 0.115 (1.181)	DT 0.001 (1.050)	loss nan (nan)	prob nan (nan)	GS 39.672 (39.672)	mem 42.640
Train: [13][630/750]	BT 0.215 (1.173)	DT 0.004 (1.041)	loss nan (nan)	prob nan (nan)	GS 35.750 (35.750)	mem 42.811
Train: [13][635/750]	BT 0.109 (1.180)	DT 0.003 (1.048)	loss nan (nan)	prob nan (nan)	GS 29.219 (29.219)	mem 42.377
Train: [13][640/750]	BT 0.205 (1.172)	DT 0.002 (1.040)	loss nan (nan)	prob nan (nan)	GS 32.594 (32.594)	mem 42.412
Train: [13][645/750]	BT 0.083 (1.164)	DT 0.002 (1.032)	loss nan (nan)	prob nan (nan)	GS 30.875 (30.875)	mem 42.379
Train: [13][650/750]	BT 0.094 (1.175)	DT 0.009 (1.043)	loss nan (nan)	prob nan (nan)	GS 32.297 (32.297)	mem 42.380
Train: [13][655/750]	BT 0.214 (1.167)	DT 0.005 (1.035)	loss nan (nan)	prob nan (nan)	GS 51.500 (51.500)	mem 42.411
Train: [13][660/750]	BT 0.128 (1.181)	DT 0.010 (1.049)	loss nan (nan)	prob nan (nan)	GS 30.344 (30.344)	mem 42.450
Train: [13][665/750]	BT 0.094 (1.173)	DT 0.003 (1.041)	loss nan (nan)	prob nan (nan)	GS 38.406 (38.406)	mem 42.450
Train: [13][670/750]	BT 8.818 (1.178)	DT 8.694 (1.046)	loss nan (nan)	prob nan (nan)	GS 34.297 (34.297)	mem 42.695
Train: [13][675/750]	BT 0.216 (1.178)	DT 0.009 (1.046)	loss nan (nan)	prob nan (nan)	GS 32.375 (32.375)	mem 42.459
Train: [13][680/750]	BT 0.131 (1.170)	DT 0.005 (1.039)	loss nan (nan)	prob nan (nan)	GS 35.906 (35.906)	mem 42.480
Train: [13][685/750]	BT 0.127 (1.174)	DT 0.024 (1.042)	loss nan (nan)	prob nan (nan)	GS 30.078 (30.078)	mem 42.387
Train: [13][690/750]	BT 0.122 (1.176)	DT 0.006 (1.044)	loss nan (nan)	prob nan (nan)	GS 31.172 (31.172)	mem 42.422
Train: [13][695/750]	BT 0.189 (1.175)	DT 0.002 (1.043)	loss nan (nan)	prob nan (nan)	GS 28.406 (28.406)	mem 42.397
Train: [13][700/750]	BT 0.173 (1.176)	DT 0.005 (1.044)	loss nan (nan)	prob nan (nan)	GS 32.406 (32.406)	mem 42.398
Train: [13][705/750]	BT 0.083 (1.168)	DT 0.002 (1.037)	loss nan (nan)	prob nan (nan)	GS 30.016 (30.016)	mem 42.515
Train: [13][710/750]	BT 3.347 (1.176)	DT 3.176 (1.044)	loss nan (nan)	prob nan (nan)	GS 35.359 (35.359)	mem 42.464
Train: [13][715/750]	BT 0.214 (1.169)	DT 0.010 (1.037)	loss nan (nan)	prob nan (nan)	GS 32.297 (32.297)	mem 42.490
Train: [13][720/750]	BT 0.159 (1.176)	DT 0.001 (1.045)	loss nan (nan)	prob nan (nan)	GS 35.234 (35.234)	mem 42.388
Train: [13][725/750]	BT 0.148 (1.174)	DT 0.002 (1.042)	loss nan (nan)	prob nan (nan)	GS 34.219 (34.219)	mem 42.412
Train: [13][730/750]	BT 7.761 (1.177)	DT 7.670 (1.046)	loss nan (nan)	prob nan (nan)	GS 29.656 (29.656)	mem 41.965
Train: [13][735/750]	BT 0.094 (1.174)	DT 0.002 (1.043)	loss nan (nan)	prob nan (nan)	GS 25.766 (25.766)	mem 38.957
Train: [13][740/750]	BT 0.072 (1.167)	DT 0.002 (1.036)	loss nan (nan)	prob nan (nan)	GS 33.188 (33.188)	mem 38.883
Train: [13][745/750]	BT 0.070 (1.164)	DT 0.001 (1.033)	loss nan (nan)	prob nan (nan)	GS 29.812 (29.812)	mem 10.129
Train: [13][750/750]	BT 0.056 (1.156)	DT 0.001 (1.026)	loss nan (nan)	prob nan (nan)	GS 38.688 (38.688)	mem 10.129
Train: [13][755/750]	BT 0.071 (1.151)	DT 0.002 (1.021)	loss nan (nan)	prob nan (nan)	GS 37.250 (37.250)	mem 10.094
epoch 13, total time 869.23
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [14][1/750]	BT 21.241 (21.241)	DT 21.125 (21.125)	loss nan (nan)	prob nan (nan)	GS 30.438 (30.438)	mem 41.326
Train: [14][5/750]	BT 2.147 (5.327)	DT 1.988 (5.174)	loss nan (nan)	prob nan (nan)	GS 34.266 (34.266)	mem 41.311
Train: [14][10/750]	BT 0.157 (2.747)	DT 0.002 (2.588)	loss nan (nan)	prob nan (nan)	GS 36.922 (36.922)	mem 41.371
Train: [14][15/750]	BT 0.082 (2.748)	DT 0.001 (2.585)	loss nan (nan)	prob nan (nan)	GS 30.484 (30.484)	mem 41.352
Train: [14][20/750]	BT 0.097 (2.265)	DT 0.002 (2.114)	loss nan (nan)	prob nan (nan)	GS 29.531 (29.531)	mem 41.423
Train: [14][25/750]	BT 0.139 (1.842)	DT 0.013 (1.692)	loss nan (nan)	prob nan (nan)	GS 32.172 (32.172)	mem 41.360
Train: [14][30/750]	BT 0.080 (1.922)	DT 0.002 (1.780)	loss nan (nan)	prob nan (nan)	GS 32.016 (32.016)	mem 41.488
Train: [14][35/750]	BT 0.141 (1.664)	DT 0.002 (1.527)	loss nan (nan)	prob nan (nan)	GS 32.719 (32.719)	mem 41.451
Train: [14][40/750]	BT 0.105 (1.794)	DT 0.001 (1.658)	loss nan (nan)	prob nan (nan)	GS 35.391 (35.391)	mem 41.446
Train: [14][45/750]	BT 0.134 (1.611)	DT 0.006 (1.474)	loss nan (nan)	prob nan (nan)	GS 29.453 (29.453)	mem 41.449
Train: [14][50/750]	BT 9.708 (1.657)	DT 9.492 (1.517)	loss nan (nan)	prob nan (nan)	GS 32.938 (32.938)	mem 41.544
Train: [14][55/750]	BT 0.348 (1.532)	DT 0.002 (1.387)	loss nan (nan)	prob nan (nan)	GS 28.812 (28.812)	mem 41.594
Train: [14][60/750]	BT 0.220 (1.415)	DT 0.021 (1.272)	loss nan (nan)	prob nan (nan)	GS 32.516 (32.516)	mem 41.578
Train: [14][65/750]	BT 0.115 (1.476)	DT 0.004 (1.334)	loss nan (nan)	prob nan (nan)	GS 31.547 (31.547)	mem 41.522
Train: [14][70/750]	BT 0.163 (1.380)	DT 0.008 (1.239)	loss nan (nan)	prob nan (nan)	GS 34.062 (34.062)	mem 41.527
Train: [14][75/750]	BT 0.114 (1.401)	DT 0.002 (1.260)	loss nan (nan)	prob nan (nan)	GS 32.422 (32.422)	mem 41.622
Train: [14][80/750]	BT 0.100 (1.365)	DT 0.007 (1.225)	loss nan (nan)	prob nan (nan)	GS 36.969 (36.969)	mem 41.642
Train: [14][85/750]	BT 0.101 (1.294)	DT 0.001 (1.153)	loss nan (nan)	prob nan (nan)	GS 27.031 (27.031)	mem 41.644
Train: [14][90/750]	BT 0.109 (1.339)	DT 0.002 (1.199)	loss nan (nan)	prob nan (nan)	GS 32.484 (32.484)	mem 41.737
Train: [14][95/750]	BT 0.161 (1.278)	DT 0.005 (1.137)	loss nan (nan)	prob nan (nan)	GS 30.781 (30.781)	mem 41.630
Train: [14][100/750]	BT 3.773 (1.349)	DT 3.664 (1.208)	loss nan (nan)	prob nan (nan)	GS 34.469 (34.469)	mem 41.709
Train: [14][105/750]	BT 0.147 (1.291)	DT 0.002 (1.151)	loss nan (nan)	prob nan (nan)	GS 34.719 (34.719)	mem 41.875
Train: [14][110/750]	BT 9.611 (1.325)	DT 9.480 (1.185)	loss nan (nan)	prob nan (nan)	GS 33.031 (33.031)	mem 41.594
Train: [14][115/750]	BT 0.157 (1.281)	DT 0.013 (1.141)	loss nan (nan)	prob nan (nan)	GS 33.250 (33.250)	mem 41.857
Train: [14][120/750]	BT 0.126 (1.233)	DT 0.006 (1.093)	loss nan (nan)	prob nan (nan)	GS 35.375 (35.375)	mem 41.601
Train: [14][125/750]	BT 0.116 (1.284)	DT 0.002 (1.143)	loss nan (nan)	prob nan (nan)	GS 31.578 (31.578)	mem 41.850
Train: [14][130/750]	BT 0.280 (1.241)	DT 0.067 (1.100)	loss nan (nan)	prob nan (nan)	GS 31.938 (31.938)	mem 41.869
Train: [14][135/750]	BT 0.120 (1.288)	DT 0.021 (1.147)	loss nan (nan)	prob nan (nan)	GS 28.109 (28.109)	mem 41.832
Train: [14][140/750]	BT 0.090 (1.255)	DT 0.006 (1.115)	loss nan (nan)	prob nan (nan)	GS 31.812 (31.812)	mem 41.958
Train: [14][145/750]	BT 0.081 (1.217)	DT 0.002 (1.076)	loss nan (nan)	prob nan (nan)	GS 31.438 (31.438)	mem 41.861
Train: [14][150/750]	BT 0.119 (1.276)	DT 0.001 (1.136)	loss nan (nan)	prob nan (nan)	GS 33.734 (33.734)	mem 41.832
Train: [14][155/750]	BT 0.121 (1.238)	DT 0.002 (1.100)	loss nan (nan)	prob nan (nan)	GS 29.812 (29.812)	mem 41.795
Train: [14][160/750]	BT 0.932 (1.278)	DT 0.761 (1.139)	loss nan (nan)	prob nan (nan)	GS 30.719 (30.719)	mem 42.085
Train: [14][165/750]	BT 0.163 (1.243)	DT 0.028 (1.105)	loss nan (nan)	prob nan (nan)	GS 31.172 (31.172)	mem 42.092
Train: [14][170/750]	BT 9.905 (1.268)	DT 9.832 (1.130)	loss nan (nan)	prob nan (nan)	GS 33.891 (33.891)	mem 42.151
Train: [14][175/750]	BT 0.128 (1.235)	DT 0.001 (1.098)	loss nan (nan)	prob nan (nan)	GS 30.422 (30.422)	mem 42.151
Train: [14][180/750]	BT 0.089 (1.204)	DT 0.001 (1.068)	loss nan (nan)	prob nan (nan)	GS 32.688 (32.688)	mem 42.372
Train: [14][185/750]	BT 0.133 (1.239)	DT 0.001 (1.103)	loss nan (nan)	prob nan (nan)	GS 33.328 (33.328)	mem 42.352
Train: [14][190/750]	BT 0.179 (1.210)	DT 0.001 (1.075)	loss nan (nan)	prob nan (nan)	GS 32.953 (32.953)	mem 42.195
Train: [14][195/750]	BT 0.109 (1.235)	DT 0.001 (1.100)	loss nan (nan)	prob nan (nan)	GS 31.250 (31.250)	mem 42.104
Train: [14][200/750]	BT 0.103 (1.206)	DT 0.001 (1.072)	loss nan (nan)	prob nan (nan)	GS 30.469 (30.469)	mem 42.168
Train: [14][205/750]	BT 0.184 (1.181)	DT 0.007 (1.046)	loss nan (nan)	prob nan (nan)	GS 29.609 (29.609)	mem 42.170
Train: [14][210/750]	BT 0.110 (1.218)	DT 0.002 (1.083)	loss nan (nan)	prob nan (nan)	GS 29.297 (29.297)	mem 42.168
Train: [14][215/750]	BT 0.113 (1.192)	DT 0.001 (1.058)	loss nan (nan)	prob nan (nan)	GS 29.922 (29.922)	mem 42.171
Train: [14][220/750]	BT 1.293 (1.223)	DT 1.222 (1.090)	loss nan (nan)	prob nan (nan)	GS 36.781 (36.781)	mem 42.052
Train: [14][225/750]	BT 0.102 (1.199)	DT 0.002 (1.066)	loss nan (nan)	prob nan (nan)	GS 29.500 (29.500)	mem 42.210
Train: [14][230/750]	BT 10.450 (1.221)	DT 10.315 (1.088)	loss nan (nan)	prob nan (nan)	GS 36.000 (36.000)	mem 42.188
Train: [14][235/750]	BT 0.114 (1.208)	DT 0.004 (1.075)	loss nan (nan)	prob nan (nan)	GS 39.188 (39.188)	mem 42.183
Train: [14][240/750]	BT 0.087 (1.185)	DT 0.002 (1.053)	loss nan (nan)	prob nan (nan)	GS 30.984 (30.984)	mem 42.112
Train: [14][245/750]	BT 0.198 (1.214)	DT 0.022 (1.081)	loss nan (nan)	prob nan (nan)	GS 33.406 (33.406)	mem 42.216
Train: [14][250/750]	BT 0.082 (1.193)	DT 0.001 (1.060)	loss nan (nan)	prob nan (nan)	GS 34.219 (34.219)	mem 42.142
Train: [14][255/750]	BT 0.124 (1.188)	DT 0.002 (1.055)	loss nan (nan)	prob nan (nan)	GS 32.172 (32.172)	mem 42.097
Train: [14][260/750]	BT 0.107 (1.191)	DT 0.001 (1.059)	loss nan (nan)	prob nan (nan)	GS 30.484 (30.484)	mem 42.140
Train: [14][265/750]	BT 0.154 (1.172)	DT 0.001 (1.039)	loss nan (nan)	prob nan (nan)	GS 30.141 (30.141)	mem 42.265
Train: [14][270/750]	BT 0.094 (1.190)	DT 0.001 (1.057)	loss nan (nan)	prob nan (nan)	GS 33.656 (33.656)	mem 42.173
Train: [14][275/750]	BT 0.113 (1.171)	DT 0.004 (1.038)	loss nan (nan)	prob nan (nan)	GS 32.562 (32.562)	mem 42.265
Train: [14][280/750]	BT 5.618 (1.195)	DT 5.423 (1.062)	loss nan (nan)	prob nan (nan)	GS 33.203 (33.203)	mem 42.217
Train: [14][285/750]	BT 0.153 (1.176)	DT 0.002 (1.044)	loss nan (nan)	prob nan (nan)	GS 35.250 (35.250)	mem 42.353
Train: [14][290/750]	BT 6.295 (1.180)	DT 6.078 (1.047)	loss nan (nan)	prob nan (nan)	GS 32.891 (32.891)	mem 42.318
Train: [14][295/750]	BT 0.136 (1.174)	DT 0.005 (1.041)	loss nan (nan)	prob nan (nan)	GS 29.688 (29.688)	mem 42.275
Train: [14][300/750]	BT 0.101 (1.156)	DT 0.001 (1.024)	loss nan (nan)	prob nan (nan)	GS 33.859 (33.859)	mem 42.279
Train: [14][305/750]	BT 0.099 (1.176)	DT 0.002 (1.043)	loss nan (nan)	prob nan (nan)	GS 32.906 (32.906)	mem 42.341
Train: [14][310/750]	BT 0.202 (1.160)	DT 0.009 (1.027)	loss nan (nan)	prob nan (nan)	GS 34.625 (34.625)	mem 42.303
Train: [14][315/750]	BT 0.132 (1.165)	DT 0.002 (1.031)	loss nan (nan)	prob nan (nan)	GS 35.422 (35.422)	mem 42.428
Train: [14][320/750]	BT 0.119 (1.168)	DT 0.002 (1.035)	loss nan (nan)	prob nan (nan)	GS 35.578 (35.578)	mem 42.469
Train: [14][325/750]	BT 0.131 (1.153)	DT 0.002 (1.020)	loss nan (nan)	prob nan (nan)	GS 30.656 (30.656)	mem 42.340
Train: [14][330/750]	BT 2.510 (1.170)	DT 2.266 (1.037)	loss nan (nan)	prob nan (nan)	GS 29.688 (29.688)	mem 42.308
Train: [14][335/750]	BT 0.113 (1.155)	DT 0.002 (1.021)	loss nan (nan)	prob nan (nan)	GS 25.625 (25.625)	mem 42.492
Train: [14][340/750]	BT 4.882 (1.163)	DT 4.755 (1.029)	loss nan (nan)	prob nan (nan)	GS 33.016 (33.016)	mem 42.285
Train: [14][345/750]	BT 0.097 (1.158)	DT 0.002 (1.025)	loss nan (nan)	prob nan (nan)	GS 31.109 (31.109)	mem 42.270
Train: [14][350/750]	BT 2.670 (1.152)	DT 2.502 (1.018)	loss nan (nan)	prob nan (nan)	GS 30.953 (30.953)	mem 42.305
Train: [14][355/750]	BT 0.089 (1.168)	DT 0.001 (1.035)	loss nan (nan)	prob nan (nan)	GS 31.453 (31.453)	mem 42.252
Train: [14][360/750]	BT 0.113 (1.153)	DT 0.005 (1.020)	loss nan (nan)	prob nan (nan)	GS 34.188 (34.188)	mem 42.273
Train: [14][365/750]	BT 0.119 (1.157)	DT 0.009 (1.024)	loss nan (nan)	prob nan (nan)	GS 30.922 (30.922)	mem 42.226
Train: [14][370/750]	BT 0.254 (1.157)	DT 0.002 (1.024)	loss nan (nan)	prob nan (nan)	GS 29.859 (29.859)	mem 42.286
Train: [14][375/750]	BT 0.105 (1.144)	DT 0.015 (1.010)	loss nan (nan)	prob nan (nan)	GS 35.859 (35.859)	mem 42.582
Train: [14][380/750]	BT 1.191 (1.162)	DT 1.104 (1.029)	loss nan (nan)	prob nan (nan)	GS 31.016 (31.016)	mem 42.322
Train: [14][385/750]	BT 0.256 (1.149)	DT 0.002 (1.016)	loss nan (nan)	prob nan (nan)	GS 29.984 (29.984)	mem 42.407
Train: [14][390/750]	BT 7.680 (1.168)	DT 7.563 (1.035)	loss nan (nan)	prob nan (nan)	GS 32.422 (32.422)	mem 42.317
Train: [14][395/750]	BT 0.083 (1.155)	DT 0.002 (1.022)	loss nan (nan)	prob nan (nan)	GS 29.141 (29.141)	mem 42.441
Train: [14][400/750]	BT 5.216 (1.155)	DT 4.812 (1.021)	loss nan (nan)	prob nan (nan)	GS 37.375 (37.375)	mem 42.348
Train: [14][405/750]	BT 0.345 (1.157)	DT 0.025 (1.023)	loss nan (nan)	prob nan (nan)	GS 33.219 (33.219)	mem 42.272
Train: [14][410/750]	BT 0.116 (1.144)	DT 0.002 (1.010)	loss nan (nan)	prob nan (nan)	GS 33.844 (33.844)	mem 42.283
Train: [14][415/750]	BT 0.184 (1.163)	DT 0.003 (1.029)	loss nan (nan)	prob nan (nan)	GS 29.047 (29.047)	mem 42.287
Train: [14][420/750]	BT 0.234 (1.150)	DT 0.006 (1.017)	loss nan (nan)	prob nan (nan)	GS 31.281 (31.281)	mem 42.288
Train: [14][425/750]	BT 0.094 (1.153)	DT 0.001 (1.020)	loss nan (nan)	prob nan (nan)	GS 35.797 (35.797)	mem 42.401
Train: [14][430/750]	BT 0.171 (1.152)	DT 0.002 (1.018)	loss nan (nan)	prob nan (nan)	GS 36.109 (36.109)	mem 42.337
Train: [14][435/750]	BT 0.227 (1.141)	DT 0.013 (1.007)	loss nan (nan)	prob nan (nan)	GS 33.609 (33.609)	mem 42.337
Train: [14][440/750]	BT 0.075 (1.164)	DT 0.001 (1.030)	loss nan (nan)	prob nan (nan)	GS 33.672 (33.672)	mem 42.410
Train: [14][445/750]	BT 0.307 (1.153)	DT 0.002 (1.019)	loss nan (nan)	prob nan (nan)	GS 35.609 (35.609)	mem 42.379
Train: [14][450/750]	BT 6.701 (1.164)	DT 6.613 (1.031)	loss nan (nan)	prob nan (nan)	GS 31.391 (31.391)	mem 42.473
Train: [14][455/750]	BT 0.281 (1.153)	DT 0.015 (1.019)	loss nan (nan)	prob nan (nan)	GS 28.922 (28.922)	mem 42.385
Train: [14][460/750]	BT 4.941 (1.153)	DT 4.774 (1.019)	loss nan (nan)	prob nan (nan)	GS 34.734 (34.734)	mem 42.730
Train: [14][465/750]	BT 0.141 (1.151)	DT 0.002 (1.017)	loss nan (nan)	prob nan (nan)	GS 31.000 (31.000)	mem 42.421
Train: [14][470/750]	BT 0.074 (1.140)	DT 0.001 (1.006)	loss nan (nan)	prob nan (nan)	GS 33.750 (33.750)	mem 42.362
Train: [14][475/750]	BT 0.090 (1.154)	DT 0.001 (1.019)	loss nan (nan)	prob nan (nan)	GS 32.047 (32.047)	mem 42.400
Train: [14][480/750]	BT 0.123 (1.144)	DT 0.002 (1.009)	loss nan (nan)	prob nan (nan)	GS 33.891 (33.891)	mem 42.403
Train: [14][485/750]	BT 0.138 (1.143)	DT 0.011 (1.009)	loss nan (nan)	prob nan (nan)	GS 26.234 (26.234)	mem 42.516
Train: [14][490/750]	BT 0.111 (1.151)	DT 0.001 (1.017)	loss nan (nan)	prob nan (nan)	GS 32.781 (32.781)	mem 42.399
Train: [14][495/750]	BT 0.150 (1.141)	DT 0.001 (1.006)	loss nan (nan)	prob nan (nan)	GS 34.344 (34.344)	mem 42.409
Train: [14][500/750]	BT 0.149 (1.152)	DT 0.012 (1.018)	loss nan (nan)	prob nan (nan)	GS 33.562 (33.562)	mem 42.384
Train: [14][505/750]	BT 0.175 (1.143)	DT 0.006 (1.008)	loss nan (nan)	prob nan (nan)	GS 32.781 (32.781)	mem 42.692
Train: [14][510/750]	BT 7.308 (1.164)	DT 7.167 (1.029)	loss nan (nan)	prob nan (nan)	GS 34.188 (34.188)	mem 42.394
Train: [14][515/750]	BT 0.141 (1.154)	DT 0.002 (1.019)	loss nan (nan)	prob nan (nan)	GS 29.234 (29.234)	mem 42.822
Train: [14][520/750]	BT 0.855 (1.145)	DT 0.603 (1.010)	loss nan (nan)	prob nan (nan)	GS 32.859 (32.859)	mem 42.712
Train: [14][525/750]	BT 0.099 (1.159)	DT 0.006 (1.024)	loss nan (nan)	prob nan (nan)	GS 28.188 (28.188)	mem 42.376
Train: [14][530/750]	BT 0.073 (1.150)	DT 0.001 (1.015)	loss nan (nan)	prob nan (nan)	GS 36.844 (36.844)	mem 42.394
Train: [14][535/750]	BT 0.097 (1.163)	DT 0.001 (1.028)	loss nan (nan)	prob nan (nan)	GS 30.234 (30.234)	mem 42.409
Train: [14][540/750]	BT 0.145 (1.153)	DT 0.010 (1.019)	loss nan (nan)	prob nan (nan)	GS 35.297 (35.297)	mem 42.639
Train: [14][545/750]	BT 0.149 (1.144)	DT 0.005 (1.009)	loss nan (nan)	prob nan (nan)	GS 29.500 (29.500)	mem 42.491
Train: [14][550/750]	BT 0.069 (1.164)	DT 0.001 (1.030)	loss nan (nan)	prob nan (nan)	GS 30.516 (30.516)	mem 42.220
Train: [14][555/750]	BT 0.113 (1.155)	DT 0.011 (1.021)	loss nan (nan)	prob nan (nan)	GS 29.656 (29.656)	mem 42.238
Train: [14][560/750]	BT 0.067 (1.168)	DT 0.001 (1.034)	loss nan (nan)	prob nan (nan)	GS 32.969 (32.969)	mem 42.369
Train: [14][565/750]	BT 0.080 (1.159)	DT 0.002 (1.025)	loss nan (nan)	prob nan (nan)	GS 27.922 (27.922)	mem 42.328
Train: [14][570/750]	BT 12.847 (1.172)	DT 12.751 (1.038)	loss nan (nan)	prob nan (nan)	GS 30.281 (30.281)	mem 42.480
Train: [14][575/750]	BT 0.103 (1.163)	DT 0.001 (1.029)	loss nan (nan)	prob nan (nan)	GS 28.969 (28.969)	mem 42.430
Train: [14][580/750]	BT 0.196 (1.154)	DT 0.001 (1.021)	loss nan (nan)	prob nan (nan)	GS 31.156 (31.156)	mem 42.434
Train: [14][585/750]	BT 0.111 (1.165)	DT 0.002 (1.032)	loss nan (nan)	prob nan (nan)	GS 36.422 (36.422)	mem 42.312
Train: [14][590/750]	BT 0.142 (1.156)	DT 0.002 (1.023)	loss nan (nan)	prob nan (nan)	GS 32.609 (32.609)	mem 42.370
Train: [14][595/750]	BT 0.097 (1.166)	DT 0.004 (1.034)	loss nan (nan)	prob nan (nan)	GS 39.594 (39.594)	mem 42.410
Train: [14][600/750]	BT 0.144 (1.158)	DT 0.012 (1.025)	loss nan (nan)	prob nan (nan)	GS 36.062 (36.062)	mem 42.432
Train: [14][605/750]	BT 0.230 (1.150)	DT 0.017 (1.017)	loss nan (nan)	prob nan (nan)	GS 29.859 (29.859)	mem 42.622
Train: [14][610/750]	BT 0.114 (1.161)	DT 0.005 (1.029)	loss nan (nan)	prob nan (nan)	GS 33.688 (33.688)	mem 42.403
Train: [14][615/750]	BT 0.080 (1.153)	DT 0.003 (1.020)	loss nan (nan)	prob nan (nan)	GS 33.766 (33.766)	mem 42.289
Train: [14][620/750]	BT 0.088 (1.165)	DT 0.001 (1.033)	loss nan (nan)	prob nan (nan)	GS 30.953 (30.953)	mem 42.375
Train: [14][625/750]	BT 0.087 (1.157)	DT 0.001 (1.024)	loss nan (nan)	prob nan (nan)	GS 31.484 (31.484)	mem 42.304
Train: [14][630/750]	BT 11.969 (1.167)	DT 11.868 (1.035)	loss nan (nan)	prob nan (nan)	GS 35.750 (35.750)	mem 42.357
Train: [14][635/750]	BT 0.114 (1.159)	DT 0.002 (1.027)	loss nan (nan)	prob nan (nan)	GS 28.922 (28.922)	mem 42.359
Train: [14][640/750]	BT 0.185 (1.151)	DT 0.002 (1.019)	loss nan (nan)	prob nan (nan)	GS 35.344 (35.344)	mem 42.423
Train: [14][645/750]	BT 0.095 (1.160)	DT 0.010 (1.028)	loss nan (nan)	prob nan (nan)	GS 35.062 (35.062)	mem 42.361
Train: [14][650/750]	BT 0.246 (1.152)	DT 0.002 (1.020)	loss nan (nan)	prob nan (nan)	GS 38.297 (38.297)	mem 42.394
Train: [14][655/750]	BT 0.117 (1.166)	DT 0.001 (1.034)	loss nan (nan)	prob nan (nan)	GS 31.812 (31.812)	mem 42.277
Train: [14][660/750]	BT 0.099 (1.157)	DT 0.001 (1.026)	loss nan (nan)	prob nan (nan)	GS 31.609 (31.609)	mem 42.279
Train: [14][665/750]	BT 0.128 (1.150)	DT 0.002 (1.018)	loss nan (nan)	prob nan (nan)	GS 33.359 (33.359)	mem 42.313
Train: [14][670/750]	BT 0.101 (1.157)	DT 0.002 (1.026)	loss nan (nan)	prob nan (nan)	GS 35.547 (35.547)	mem 42.575
Train: [14][675/750]	BT 0.157 (1.149)	DT 0.007 (1.018)	loss nan (nan)	prob nan (nan)	GS 29.328 (29.328)	mem 42.427
Train: [14][680/750]	BT 0.122 (1.163)	DT 0.001 (1.032)	loss nan (nan)	prob nan (nan)	GS 35.266 (35.266)	mem 42.398
Train: [14][685/750]	BT 0.230 (1.155)	DT 0.012 (1.024)	loss nan (nan)	prob nan (nan)	GS 28.406 (28.406)	mem 42.649
Train: [14][690/750]	BT 10.330 (1.163)	DT 10.231 (1.032)	loss nan (nan)	prob nan (nan)	GS 31.266 (31.266)	mem 42.327
Train: [14][695/750]	BT 0.134 (1.156)	DT 0.008 (1.024)	loss nan (nan)	prob nan (nan)	GS 30.203 (30.203)	mem 42.366
Train: [14][700/750]	BT 0.165 (1.148)	DT 0.002 (1.017)	loss nan (nan)	prob nan (nan)	GS 34.406 (34.406)	mem 42.366
Train: [14][705/750]	BT 0.071 (1.160)	DT 0.001 (1.029)	loss nan (nan)	prob nan (nan)	GS 28.922 (28.922)	mem 42.191
arpack error, retry= 0
arpack error, retry= 0
arpack error, retry= 0
Train: [14][710/750]	BT 0.079 (1.153)	DT 0.001 (1.022)	loss nan (nan)	prob nan (nan)	GS 30.203 (30.203)	mem 42.191
Train: [14][715/750]	BT 0.076 (1.165)	DT 0.001 (1.034)	loss nan (nan)	prob nan (nan)	GS 35.375 (35.375)	mem 42.315
Train: [14][720/750]	BT 0.112 (1.158)	DT 0.007 (1.027)	loss nan (nan)	prob nan (nan)	GS 31.406 (31.406)	mem 42.260
Train: [14][725/750]	BT 0.158 (1.150)	DT 0.002 (1.020)	loss nan (nan)	prob nan (nan)	GS 28.484 (28.484)	mem 42.316
Train: [14][730/750]	BT 0.111 (1.157)	DT 0.002 (1.026)	loss nan (nan)	prob nan (nan)	GS 34.250 (34.250)	mem 42.228
Train: [14][735/750]	BT 0.119 (1.149)	DT 0.002 (1.019)	loss nan (nan)	prob nan (nan)	GS 29.719 (29.719)	mem 42.080
Train: [14][740/750]	BT 0.091 (1.151)	DT 0.001 (1.021)	loss nan (nan)	prob nan (nan)	GS 31.406 (31.406)	mem 10.059
Train: [14][745/750]	BT 0.064 (1.144)	DT 0.001 (1.015)	loss nan (nan)	prob nan (nan)	GS 36.781 (36.781)	mem 10.060
Train: [14][750/750]	BT 2.168 (1.140)	DT 2.094 (1.011)	loss nan (nan)	prob nan (nan)	GS 36.594 (36.594)	mem 9.926
Train: [14][755/750]	BT 0.072 (1.132)	DT 0.001 (1.004)	loss nan (nan)	prob nan (nan)	GS 26.406 (26.406)	mem 9.926
epoch 14, total time 855.31
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [15][1/750]	BT 23.935 (23.935)	DT 23.649 (23.649)	loss nan (nan)	prob nan (nan)	GS 32.125 (32.125)	mem 41.256
Train: [15][5/750]	BT 0.184 (5.076)	DT 0.005 (4.901)	loss nan (nan)	prob nan (nan)	GS 32.484 (32.484)	mem 41.044
Train: [15][10/750]	BT 0.962 (2.707)	DT 0.850 (2.543)	loss nan (nan)	prob nan (nan)	GS 35.188 (35.188)	mem 41.032
Train: [15][15/750]	BT 0.212 (2.971)	DT 0.006 (2.814)	loss nan (nan)	prob nan (nan)	GS 35.953 (35.953)	mem 41.204
Train: [15][20/750]	BT 0.192 (2.266)	DT 0.006 (2.111)	loss nan (nan)	prob nan (nan)	GS 37.672 (37.672)	mem 41.274
Train: [15][25/750]	BT 0.112 (1.835)	DT 0.002 (1.689)	loss nan (nan)	prob nan (nan)	GS 29.438 (29.438)	mem 41.250
Train: [15][30/750]	BT 0.085 (2.084)	DT 0.008 (1.942)	loss nan (nan)	prob nan (nan)	GS 32.812 (32.812)	mem 41.502
Train: [15][35/750]	BT 0.086 (1.806)	DT 0.002 (1.665)	loss nan (nan)	prob nan (nan)	GS 36.188 (36.188)	mem 41.509
Train: [15][40/750]	BT 0.087 (1.917)	DT 0.001 (1.781)	loss nan (nan)	prob nan (nan)	GS 31.469 (31.469)	mem 41.729
Train: [15][45/750]	BT 0.144 (1.718)	DT 0.006 (1.584)	loss nan (nan)	prob nan (nan)	GS 34.625 (34.625)	mem 41.731
Train: [15][50/750]	BT 11.687 (1.790)	DT 11.539 (1.657)	loss nan (nan)	prob nan (nan)	GS 36.875 (36.875)	mem 42.046
Train: [15][55/750]	BT 0.093 (1.638)	DT 0.001 (1.506)	loss nan (nan)	prob nan (nan)	GS 33.781 (33.781)	mem 42.081
Train: [15][60/750]	BT 0.210 (1.511)	DT 0.004 (1.381)	loss nan (nan)	prob nan (nan)	GS 32.453 (32.453)	mem 42.305
Train: [15][65/750]	BT 0.148 (1.585)	DT 0.002 (1.452)	loss nan (nan)	prob nan (nan)	GS 30.156 (30.156)	mem 42.056
Train: [15][70/750]	BT 0.169 (1.481)	DT 0.007 (1.349)	loss nan (nan)	prob nan (nan)	GS 31.359 (31.359)	mem 41.996
Train: [15][75/750]	BT 0.080 (1.537)	DT 0.001 (1.407)	loss nan (nan)	prob nan (nan)	GS 29.938 (29.938)	mem 42.075
Train: [15][80/750]	BT 0.233 (1.451)	DT 0.002 (1.320)	loss nan (nan)	prob nan (nan)	GS 36.484 (36.484)	mem 42.076
Train: [15][85/750]	BT 0.181 (1.375)	DT 0.002 (1.242)	loss nan (nan)	prob nan (nan)	GS 31.766 (31.766)	mem 42.022
Train: [15][90/750]	BT 0.127 (1.463)	DT 0.001 (1.331)	loss nan (nan)	prob nan (nan)	GS 33.062 (33.062)	mem 42.070
Train: [15][95/750]	BT 0.142 (1.395)	DT 0.002 (1.261)	loss nan (nan)	prob nan (nan)	GS 37.234 (37.234)	mem 41.993
Train: [15][100/750]	BT 0.076 (1.431)	DT 0.001 (1.299)	loss nan (nan)	prob nan (nan)	GS 35.281 (35.281)	mem 42.063
Train: [15][105/750]	BT 0.199 (1.369)	DT 0.012 (1.237)	loss nan (nan)	prob nan (nan)	GS 28.984 (28.984)	mem 42.217
Train: [15][110/750]	BT 13.752 (1.436)	DT 13.670 (1.305)	loss nan (nan)	prob nan (nan)	GS 31.672 (31.672)	mem 42.059
Train: [15][115/750]	BT 0.113 (1.378)	DT 0.009 (1.249)	loss nan (nan)	prob nan (nan)	GS 30.172 (30.172)	mem 42.060
Train: [15][120/750]	BT 0.150 (1.324)	DT 0.020 (1.197)	loss nan (nan)	prob nan (nan)	GS 33.656 (33.656)	mem 42.042
Train: [15][125/750]	BT 0.188 (1.338)	DT 0.008 (1.209)	loss nan (nan)	prob nan (nan)	GS 30.875 (30.875)	mem 42.301
Train: [15][130/750]	BT 0.537 (1.297)	DT 0.377 (1.166)	loss nan (nan)	prob nan (nan)	GS 33.484 (33.484)	mem 42.061
Train: [15][135/750]	BT 0.065 (1.349)	DT 0.001 (1.218)	loss nan (nan)	prob nan (nan)	GS 33.578 (33.578)	mem 42.178
Train: [15][140/750]	BT 0.122 (1.305)	DT 0.001 (1.175)	loss nan (nan)	prob nan (nan)	GS 32.016 (32.016)	mem 42.221
Train: [15][145/750]	BT 0.115 (1.264)	DT 0.007 (1.134)	loss nan (nan)	prob nan (nan)	GS 31.484 (31.484)	mem 42.360
Train: [15][150/750]	BT 0.078 (1.299)	DT 0.005 (1.171)	loss nan (nan)	prob nan (nan)	GS 33.422 (33.422)	mem 42.151
Train: [15][155/750]	BT 0.150 (1.262)	DT 0.002 (1.134)	loss nan (nan)	prob nan (nan)	GS 28.016 (28.016)	mem 42.190
Train: [15][160/750]	BT 0.088 (1.292)	DT 0.002 (1.165)	loss nan (nan)	prob nan (nan)	GS 30.719 (30.719)	mem 42.243
Train: [15][165/750]	BT 0.161 (1.257)	DT 0.001 (1.129)	loss nan (nan)	prob nan (nan)	GS 30.297 (30.297)	mem 42.209
Train: [15][170/750]	BT 13.826 (1.304)	DT 13.751 (1.177)	loss nan (nan)	prob nan (nan)	GS 30.406 (30.406)	mem 42.169
Train: [15][175/750]	BT 0.117 (1.270)	DT 0.001 (1.144)	loss nan (nan)	prob nan (nan)	GS 30.797 (30.797)	mem 42.169
Train: [15][180/750]	BT 0.153 (1.240)	DT 0.001 (1.112)	loss nan (nan)	prob nan (nan)	GS 33.891 (33.891)	mem 42.169
Train: [15][185/750]	BT 0.201 (1.261)	DT 0.002 (1.133)	loss nan (nan)	prob nan (nan)	GS 28.219 (28.219)	mem 42.318
Train: [15][190/750]	BT 0.088 (1.231)	DT 0.002 (1.103)	loss nan (nan)	prob nan (nan)	GS 33.250 (33.250)	mem 42.270
Train: [15][195/750]	BT 0.092 (1.254)	DT 0.004 (1.126)	loss nan (nan)	prob nan (nan)	GS 28.000 (28.000)	mem 42.286
Train: [15][200/750]	BT 0.156 (1.225)	DT 0.001 (1.098)	loss nan (nan)	prob nan (nan)	GS 33.266 (33.266)	mem 42.286
Train: [15][205/750]	BT 0.138 (1.205)	DT 0.022 (1.078)	loss nan (nan)	prob nan (nan)	GS 31.891 (31.891)	mem 42.295
Train: [15][210/750]	BT 0.082 (1.244)	DT 0.014 (1.119)	loss nan (nan)	prob nan (nan)	GS 34.297 (34.297)	mem 42.349
Train: [15][215/750]	BT 0.131 (1.218)	DT 0.002 (1.093)	loss nan (nan)	prob nan (nan)	GS 34.078 (34.078)	mem 42.351
Train: [15][220/750]	BT 0.071 (1.250)	DT 0.002 (1.125)	loss nan (nan)	prob nan (nan)	GS 32.406 (32.406)	mem 42.353
Train: [15][225/750]	BT 0.090 (1.225)	DT 0.006 (1.100)	loss nan (nan)	prob nan (nan)	GS 30.516 (30.516)	mem 42.355
Train: [15][230/750]	BT 10.442 (1.246)	DT 10.299 (1.121)	loss nan (nan)	prob nan (nan)	GS 30.250 (30.250)	mem 42.344
Train: [15][235/750]	BT 0.161 (1.222)	DT 0.009 (1.097)	loss nan (nan)	prob nan (nan)	GS 29.594 (29.594)	mem 42.430
Train: [15][240/750]	BT 0.105 (1.199)	DT 0.002 (1.074)	loss nan (nan)	prob nan (nan)	GS 32.531 (32.531)	mem 42.395
Train: [15][245/750]	BT 0.138 (1.219)	DT 0.001 (1.095)	loss nan (nan)	prob nan (nan)	GS 29.516 (29.516)	mem 42.353
Train: [15][250/750]	BT 0.112 (1.197)	DT 0.001 (1.073)	loss nan (nan)	prob nan (nan)	GS 33.953 (33.953)	mem 42.357
Train: [15][255/750]	BT 0.094 (1.222)	DT 0.001 (1.098)	loss nan (nan)	prob nan (nan)	GS 32.578 (32.578)	mem 42.253
Train: [15][260/750]	BT 0.094 (1.201)	DT 0.002 (1.077)	loss nan (nan)	prob nan (nan)	GS 31.766 (31.766)	mem 42.267
Train: [15][265/750]	BT 0.184 (1.181)	DT 0.018 (1.057)	loss nan (nan)	prob nan (nan)	GS 30.219 (30.219)	mem 42.565
Train: [15][270/750]	BT 0.128 (1.205)	DT 0.001 (1.081)	loss nan (nan)	prob nan (nan)	GS 37.031 (37.031)	mem 42.347
Train: [15][275/750]	BT 0.188 (1.185)	DT 0.002 (1.062)	loss nan (nan)	prob nan (nan)	GS 28.656 (28.656)	mem 42.318
Train: [15][280/750]	BT 0.140 (1.207)	DT 0.012 (1.084)	loss nan (nan)	prob nan (nan)	GS 39.984 (39.984)	mem 42.419
Train: [15][285/750]	BT 0.144 (1.188)	DT 0.002 (1.065)	loss nan (nan)	prob nan (nan)	GS 35.250 (35.250)	mem 42.470
Train: [15][290/750]	BT 10.740 (1.206)	DT 10.588 (1.083)	loss nan (nan)	prob nan (nan)	GS 32.844 (32.844)	mem 42.455
Train: [15][295/750]	BT 0.092 (1.188)	DT 0.001 (1.065)	loss nan (nan)	prob nan (nan)	GS 30.688 (30.688)	mem 42.499
Train: [15][300/750]	BT 0.087 (1.170)	DT 0.002 (1.047)	loss nan (nan)	prob nan (nan)	GS 35.047 (35.047)	mem 42.462
Train: [15][305/750]	BT 0.137 (1.178)	DT 0.005 (1.055)	loss nan (nan)	prob nan (nan)	GS 32.156 (32.156)	mem 42.437
Train: [15][310/750]	BT 0.156 (1.162)	DT 0.010 (1.038)	loss nan (nan)	prob nan (nan)	GS 33.750 (33.750)	mem 42.435
Train: [15][315/750]	BT 0.248 (1.174)	DT 0.011 (1.049)	loss nan (nan)	prob nan (nan)	GS 30.812 (30.812)	mem 42.341
Train: [15][320/750]	BT 0.159 (1.158)	DT 0.002 (1.033)	loss nan (nan)	prob nan (nan)	GS 32.453 (32.453)	mem 42.420
Train: [15][325/750]	BT 0.147 (1.143)	DT 0.013 (1.017)	loss nan (nan)	prob nan (nan)	GS 32.156 (32.156)	mem 42.443
Train: [15][330/750]	BT 0.086 (1.167)	DT 0.002 (1.042)	loss nan (nan)	prob nan (nan)	GS 33.641 (33.641)	mem 42.377
Train: [15][335/750]	BT 0.112 (1.152)	DT 0.003 (1.027)	loss nan (nan)	prob nan (nan)	GS 32.094 (32.094)	mem 42.453
Train: [15][340/750]	BT 0.077 (1.175)	DT 0.001 (1.049)	loss nan (nan)	prob nan (nan)	GS 33.531 (33.531)	mem 42.382
Train: [15][345/750]	BT 0.185 (1.160)	DT 0.014 (1.034)	loss nan (nan)	prob nan (nan)	GS 32.703 (32.703)	mem 42.406
Train: [15][350/750]	BT 14.905 (1.187)	DT 14.818 (1.062)	loss nan (nan)	prob nan (nan)	GS 32.359 (32.359)	mem 42.287
Train: [15][355/750]	BT 0.099 (1.172)	DT 0.011 (1.047)	loss nan (nan)	prob nan (nan)	GS 34.828 (34.828)	mem 42.289
Train: [15][360/750]	BT 0.115 (1.157)	DT 0.002 (1.033)	loss nan (nan)	prob nan (nan)	GS 32.656 (32.656)	mem 42.379
Train: [15][365/750]	BT 0.162 (1.171)	DT 0.004 (1.046)	loss nan (nan)	prob nan (nan)	GS 45.547 (45.547)	mem 42.453
Train: [15][370/750]	BT 0.164 (1.166)	DT 0.003 (1.040)	loss nan (nan)	prob nan (nan)	GS 33.016 (33.016)	mem 42.407
Train: [15][375/750]	BT 0.147 (1.178)	DT 0.001 (1.052)	loss nan (nan)	prob nan (nan)	GS 32.844 (32.844)	mem 42.294
Train: [15][380/750]	BT 0.205 (1.165)	DT 0.004 (1.039)	loss nan (nan)	prob nan (nan)	GS 32.656 (32.656)	mem 42.340
Train: [15][385/750]	BT 0.208 (1.152)	DT 0.008 (1.026)	loss nan (nan)	prob nan (nan)	GS 28.016 (28.016)	mem 42.340
Train: [15][390/750]	BT 0.131 (1.167)	DT 0.016 (1.041)	loss nan (nan)	prob nan (nan)	GS 35.391 (35.391)	mem 42.388
Train: [15][395/750]	BT 0.129 (1.154)	DT 0.001 (1.028)	loss nan (nan)	prob nan (nan)	GS 29.141 (29.141)	mem 42.527
Train: [15][400/750]	BT 0.110 (1.176)	DT 0.001 (1.051)	loss nan (nan)	prob nan (nan)	GS 33.875 (33.875)	mem 42.450
Train: [15][405/750]	BT 0.080 (1.167)	DT 0.003 (1.041)	loss nan (nan)	prob nan (nan)	GS 31.719 (31.719)	mem 42.584
Train: [15][410/750]	BT 9.928 (1.179)	DT 9.782 (1.053)	loss nan (nan)	prob nan (nan)	GS 31.938 (31.938)	mem 42.473
Train: [15][415/750]	BT 0.137 (1.166)	DT 0.016 (1.040)	loss nan (nan)	prob nan (nan)	GS 28.625 (28.625)	mem 42.415
Train: [15][420/750]	BT 0.132 (1.154)	DT 0.003 (1.028)	loss nan (nan)	prob nan (nan)	GS 38.797 (38.797)	mem 42.526
Train: [15][425/750]	BT 0.160 (1.166)	DT 0.002 (1.040)	loss nan (nan)	prob nan (nan)	GS 31.828 (31.828)	mem 42.570
Train: [15][430/750]	BT 0.081 (1.160)	DT 0.002 (1.034)	loss nan (nan)	prob nan (nan)	GS 34.828 (34.828)	mem 42.491
Train: [15][435/750]	BT 0.110 (1.169)	DT 0.001 (1.043)	loss nan (nan)	prob nan (nan)	GS 32.000 (32.000)	mem 42.401
Train: [15][440/750]	BT 0.149 (1.158)	DT 0.015 (1.031)	loss nan (nan)	prob nan (nan)	GS 34.234 (34.234)	mem 42.344
Train: [15][445/750]	BT 0.093 (1.147)	DT 0.002 (1.020)	loss nan (nan)	prob nan (nan)	GS 32.000 (32.000)	mem 42.352
Train: [15][450/750]	BT 0.627 (1.163)	DT 0.562 (1.036)	loss nan (nan)	prob nan (nan)	GS 33.125 (33.125)	mem 42.332
Train: [15][455/750]	BT 0.170 (1.151)	DT 0.002 (1.024)	loss nan (nan)	prob nan (nan)	GS 31.078 (31.078)	mem 42.336
Train: [15][460/750]	BT 0.122 (1.166)	DT 0.001 (1.039)	loss nan (nan)	prob nan (nan)	GS 36.953 (36.953)	mem 42.193
Train: [15][465/750]	BT 0.142 (1.155)	DT 0.002 (1.028)	loss nan (nan)	prob nan (nan)	GS 34.500 (34.500)	mem 42.236
Train: [15][470/750]	BT 10.464 (1.166)	DT 10.390 (1.039)	loss nan (nan)	prob nan (nan)	GS 32.344 (32.344)	mem 42.351
Train: [15][475/750]	BT 0.126 (1.158)	DT 0.012 (1.030)	loss nan (nan)	prob nan (nan)	GS 37.484 (37.484)	mem 42.343
Train: [15][480/750]	BT 0.157 (1.147)	DT 0.008 (1.019)	loss nan (nan)	prob nan (nan)	GS 36.875 (36.875)	mem 42.271
Train: [15][485/750]	BT 0.107 (1.161)	DT 0.002 (1.033)	loss nan (nan)	prob nan (nan)	GS 31.172 (31.172)	mem 42.325
Train: [15][490/750]	BT 0.219 (1.150)	DT 0.008 (1.023)	loss nan (nan)	prob nan (nan)	GS 31.109 (31.109)	mem 42.363
Train: [15][495/750]	BT 0.136 (1.159)	DT 0.001 (1.032)	loss nan (nan)	prob nan (nan)	GS 28.469 (28.469)	mem 42.335
Train: [15][500/750]	BT 0.108 (1.158)	DT 0.001 (1.031)	loss nan (nan)	prob nan (nan)	GS 36.906 (36.906)	mem 42.430
Train: [15][505/750]	BT 0.247 (1.149)	DT 0.009 (1.021)	loss nan (nan)	prob nan (nan)	GS 33.781 (33.781)	mem 42.355
Train: [15][510/750]	BT 2.158 (1.166)	DT 2.085 (1.039)	loss nan (nan)	prob nan (nan)	GS 36.562 (36.562)	mem 42.277
Train: [15][515/750]	BT 0.120 (1.156)	DT 0.006 (1.029)	loss nan (nan)	prob nan (nan)	GS 28.250 (28.250)	mem 42.195
Train: [15][520/750]	BT 5.975 (1.159)	DT 5.832 (1.032)	loss nan (nan)	prob nan (nan)	GS 29.281 (29.281)	mem 42.288
Train: [15][525/750]	BT 0.094 (1.159)	DT 0.001 (1.033)	loss nan (nan)	prob nan (nan)	GS 30.422 (30.422)	mem 42.336
Train: [15][530/750]	BT 3.037 (1.155)	DT 2.901 (1.028)	loss nan (nan)	prob nan (nan)	GS 33.672 (33.672)	mem 42.643
Train: [15][535/750]	BT 0.123 (1.165)	DT 0.001 (1.038)	loss nan (nan)	prob nan (nan)	GS 27.719 (27.719)	mem 42.492
Train: [15][540/750]	BT 0.115 (1.155)	DT 0.002 (1.028)	loss nan (nan)	prob nan (nan)	GS 34.797 (34.797)	mem 42.325
Train: [15][545/750]	BT 0.168 (1.158)	DT 0.001 (1.031)	loss nan (nan)	prob nan (nan)	GS 34.859 (34.859)	mem 42.325
Train: [15][550/750]	BT 0.191 (1.157)	DT 0.001 (1.030)	loss nan (nan)	prob nan (nan)	GS 33.453 (33.453)	mem 42.311
Train: [15][555/750]	BT 0.182 (1.155)	DT 0.001 (1.028)	loss nan (nan)	prob nan (nan)	GS 30.641 (30.641)	mem 42.333
Train: [15][560/750]	BT 0.115 (1.161)	DT 0.003 (1.034)	loss nan (nan)	prob nan (nan)	GS 33.297 (33.297)	mem 42.431
Train: [15][565/750]	BT 0.116 (1.152)	DT 0.001 (1.024)	loss nan (nan)	prob nan (nan)	GS 31.406 (31.406)	mem 42.390
Train: [15][570/750]	BT 7.112 (1.159)	DT 7.036 (1.031)	loss nan (nan)	prob nan (nan)	GS 34.062 (34.062)	mem 42.395
Train: [15][575/750]	BT 0.096 (1.150)	DT 0.002 (1.023)	loss nan (nan)	prob nan (nan)	GS 31.188 (31.188)	mem 42.396
Train: [15][580/750]	BT 0.210 (1.153)	DT 0.002 (1.024)	loss nan (nan)	prob nan (nan)	GS 34.188 (34.188)	mem 42.331
Train: [15][585/750]	BT 0.188 (1.151)	DT 0.013 (1.023)	loss nan (nan)	prob nan (nan)	GS 35.703 (35.703)	mem 42.413
Train: [15][590/750]	BT 5.733 (1.152)	DT 5.503 (1.024)	loss nan (nan)	prob nan (nan)	GS 32.891 (32.891)	mem 42.429
Train: [15][595/750]	BT 0.092 (1.154)	DT 0.010 (1.025)	loss nan (nan)	prob nan (nan)	GS 34.250 (34.250)	mem 42.481
Train: [15][600/750]	BT 0.097 (1.145)	DT 0.002 (1.016)	loss nan (nan)	prob nan (nan)	GS 35.938 (35.938)	mem 42.435
Train: [15][605/750]	BT 0.133 (1.151)	DT 0.004 (1.022)	loss nan (nan)	prob nan (nan)	GS 32.719 (32.719)	mem 42.309
Train: [15][610/750]	BT 0.152 (1.147)	DT 0.001 (1.018)	loss nan (nan)	prob nan (nan)	GS 34.094 (34.094)	mem 42.357
Train: [15][615/750]	BT 0.075 (1.158)	DT 0.009 (1.029)	loss nan (nan)	prob nan (nan)	GS 36.547 (36.547)	mem 42.391
Train: [15][620/750]	BT 0.104 (1.150)	DT 0.002 (1.021)	loss nan (nan)	prob nan (nan)	GS 34.266 (34.266)	mem 42.687
Train: [15][625/750]	BT 0.207 (1.142)	DT 0.004 (1.013)	loss nan (nan)	prob nan (nan)	GS 30.250 (30.250)	mem 42.545
Train: [15][630/750]	BT 0.136 (1.153)	DT 0.001 (1.024)	loss nan (nan)	prob nan (nan)	GS 33.266 (33.266)	mem 42.439
Train: [15][635/750]	BT 0.142 (1.145)	DT 0.004 (1.016)	loss nan (nan)	prob nan (nan)	GS 26.547 (26.547)	mem 42.476
Train: [15][640/750]	BT 0.082 (1.156)	DT 0.001 (1.027)	loss nan (nan)	prob nan (nan)	GS 34.875 (34.875)	mem 42.372
Train: [15][645/750]	BT 0.150 (1.148)	DT 0.002 (1.019)	loss nan (nan)	prob nan (nan)	GS 24.953 (24.953)	mem 42.376
Train: [15][650/750]	BT 10.008 (1.156)	DT 9.933 (1.027)	loss nan (nan)	prob nan (nan)	GS 33.719 (33.719)	mem 42.384
Train: [15][655/750]	BT 0.106 (1.148)	DT 0.002 (1.019)	loss nan (nan)	prob nan (nan)	GS 34.984 (34.984)	mem 42.506
Train: [15][660/750]	BT 0.119 (1.141)	DT 0.011 (1.011)	loss nan (nan)	prob nan (nan)	GS 31.484 (31.484)	mem 42.430
Train: [15][665/750]	BT 0.206 (1.154)	DT 0.002 (1.025)	loss nan (nan)	prob nan (nan)	GS 27.969 (27.969)	mem 42.374
Train: [15][670/750]	BT 0.221 (1.146)	DT 0.071 (1.017)	loss nan (nan)	prob nan (nan)	GS 34.641 (34.641)	mem 42.236
Train: [15][675/750]	BT 0.197 (1.154)	DT 0.004 (1.024)	loss nan (nan)	prob nan (nan)	GS 35.875 (35.875)	mem 42.467
Train: [15][680/750]	BT 0.135 (1.151)	DT 0.006 (1.021)	loss nan (nan)	prob nan (nan)	GS 35.891 (35.891)	mem 42.728
Train: [15][685/750]	BT 0.140 (1.147)	DT 0.013 (1.018)	loss nan (nan)	prob nan (nan)	GS 31.156 (31.156)	mem 42.305
Train: [15][690/750]	BT 0.380 (1.150)	DT 0.222 (1.020)	loss nan (nan)	prob nan (nan)	GS 34.703 (34.703)	mem 42.398
Train: [15][695/750]	BT 0.180 (1.153)	DT 0.010 (1.023)	loss nan (nan)	prob nan (nan)	GS 30.828 (30.828)	mem 42.327
Train: [15][700/750]	BT 0.136 (1.150)	DT 0.010 (1.021)	loss nan (nan)	prob nan (nan)	GS 32.375 (32.375)	mem 42.374
Train: [15][705/750]	BT 0.163 (1.143)	DT 0.002 (1.014)	loss nan (nan)	prob nan (nan)	GS 24.078 (24.078)	mem 42.376
arpack error, retry= 0
Train: [15][710/750]	BT 0.195 (1.152)	DT 0.001 (1.022)	loss nan (nan)	prob nan (nan)	GS 34.297 (34.297)	mem 42.232
Train: [15][715/750]	BT 0.195 (1.145)	DT 0.023 (1.015)	loss nan (nan)	prob nan (nan)	GS 29.609 (29.609)	mem 42.260
Train: [15][720/750]	BT 0.281 (1.152)	DT 0.002 (1.021)	loss nan (nan)	prob nan (nan)	GS 31.281 (31.281)	mem 42.401
Train: [15][725/750]	BT 0.180 (1.147)	DT 0.004 (1.016)	loss nan (nan)	prob nan (nan)	GS 33.391 (33.391)	mem 42.236
Train: [15][730/750]	BT 10.716 (1.154)	DT 10.582 (1.024)	loss nan (nan)	prob nan (nan)	GS 32.234 (32.234)	mem 41.994
Train: [15][735/750]	BT 0.108 (1.147)	DT 0.001 (1.017)	loss nan (nan)	prob nan (nan)	GS 37.734 (37.734)	mem 42.034
Train: [15][740/750]	BT 0.171 (1.140)	DT 0.012 (1.010)	loss nan (nan)	prob nan (nan)	GS 34.953 (34.953)	mem 42.062
Train: [15][745/750]	BT 0.078 (1.141)	DT 0.003 (1.011)	loss nan (nan)	prob nan (nan)	GS 34.656 (34.656)	mem 10.036
Train: [15][750/750]	BT 0.079 (1.134)	DT 0.001 (1.004)	loss nan (nan)	prob nan (nan)	GS 33.688 (33.688)	mem 10.056
Train: [15][755/750]	BT 0.061 (1.129)	DT 0.001 (1.000)	loss nan (nan)	prob nan (nan)	GS 37.688 (37.688)	mem 10.055
epoch 15, total time 853.01
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [16][1/750]	BT 25.009 (25.009)	DT 24.840 (24.840)	loss nan (nan)	prob nan (nan)	GS 32.656 (32.656)	mem 41.160
Train: [16][5/750]	BT 0.217 (5.158)	DT 0.015 (4.973)	loss nan (nan)	prob nan (nan)	GS 39.094 (39.094)	mem 41.166
Train: [16][10/750]	BT 0.138 (2.629)	DT 0.031 (2.490)	loss nan (nan)	prob nan (nan)	GS 30.188 (30.188)	mem 41.188
Train: [16][15/750]	BT 0.173 (2.517)	DT 0.001 (2.374)	loss nan (nan)	prob nan (nan)	GS 31.062 (31.062)	mem 41.333
Train: [16][20/750]	BT 0.274 (1.945)	DT 0.030 (1.784)	loss nan (nan)	prob nan (nan)	GS 34.688 (34.688)	mem 41.310
Train: [16][25/750]	BT 8.572 (1.954)	DT 8.434 (1.801)	loss nan (nan)	prob nan (nan)	GS 33.875 (33.875)	mem 41.392
Train: [16][30/750]	BT 1.315 (1.716)	DT 1.101 (1.560)	loss nan (nan)	prob nan (nan)	GS 33.844 (33.844)	mem 41.436
Train: [16][35/750]	BT 0.198 (1.535)	DT 0.006 (1.373)	loss nan (nan)	prob nan (nan)	GS 30.156 (30.156)	mem 41.462
Train: [16][40/750]	BT 2.804 (1.546)	DT 2.697 (1.389)	loss nan (nan)	prob nan (nan)	GS 34.984 (34.984)	mem 41.451
Train: [16][45/750]	BT 0.109 (1.500)	DT 0.010 (1.347)	loss nan (nan)	prob nan (nan)	GS 30.734 (30.734)	mem 41.423
Train: [16][50/750]	BT 2.845 (1.433)	DT 2.689 (1.283)	loss nan (nan)	prob nan (nan)	GS 36.312 (36.312)	mem 41.444
Train: [16][55/750]	BT 0.108 (1.419)	DT 0.001 (1.269)	loss nan (nan)	prob nan (nan)	GS 33.734 (33.734)	mem 41.491
Train: [16][60/750]	BT 0.288 (1.360)	DT 0.177 (1.207)	loss nan (nan)	prob nan (nan)	GS 31.672 (31.672)	mem 41.624
Train: [16][65/750]	BT 0.104 (1.388)	DT 0.008 (1.239)	loss nan (nan)	prob nan (nan)	GS 30.078 (30.078)	mem 41.609
Train: [16][70/750]	BT 0.172 (1.374)	DT 0.003 (1.225)	loss nan (nan)	prob nan (nan)	GS 30.047 (30.047)	mem 41.620
Train: [16][75/750]	BT 0.156 (1.435)	DT 0.001 (1.287)	loss nan (nan)	prob nan (nan)	GS 31.922 (31.922)	mem 41.751
Train: [16][80/750]	BT 2.382 (1.383)	DT 2.233 (1.236)	loss nan (nan)	prob nan (nan)	GS 35.406 (35.406)	mem 41.747
Train: [16][85/750]	BT 0.137 (1.310)	DT 0.002 (1.164)	loss nan (nan)	prob nan (nan)	GS 34.453 (34.453)	mem 41.736
Train: [16][90/750]	BT 0.091 (1.372)	DT 0.002 (1.229)	loss nan (nan)	prob nan (nan)	GS 35.875 (35.875)	mem 41.627
Train: [16][95/750]	BT 0.191 (1.310)	DT 0.002 (1.165)	loss nan (nan)	prob nan (nan)	GS 34.547 (34.547)	mem 41.641
Train: [16][100/750]	BT 2.137 (1.362)	DT 1.983 (1.215)	loss nan (nan)	prob nan (nan)	GS 33.062 (33.062)	mem 41.687
Train: [16][105/750]	BT 0.155 (1.304)	DT 0.001 (1.158)	loss nan (nan)	prob nan (nan)	GS 31.828 (31.828)	mem 41.755
Train: [16][110/750]	BT 11.663 (1.354)	DT 11.539 (1.211)	loss nan (nan)	prob nan (nan)	GS 35.781 (35.781)	mem 41.863
Train: [16][115/750]	BT 0.121 (1.299)	DT 0.001 (1.158)	loss nan (nan)	prob nan (nan)	GS 29.609 (29.609)	mem 41.743
Train: [16][120/750]	BT 0.095 (1.259)	DT 0.001 (1.119)	loss nan (nan)	prob nan (nan)	GS 35.109 (35.109)	mem 41.710
Train: [16][125/750]	BT 0.094 (1.318)	DT 0.001 (1.180)	loss nan (nan)	prob nan (nan)	GS 33.656 (33.656)	mem 41.721
Train: [16][130/750]	BT 0.114 (1.294)	DT 0.001 (1.156)	loss nan (nan)	prob nan (nan)	GS 35.719 (35.719)	mem 41.725
Train: [16][135/750]	BT 0.137 (1.308)	DT 0.001 (1.172)	loss nan (nan)	prob nan (nan)	GS 28.109 (28.109)	mem 41.802
Train: [16][140/750]	BT 7.208 (1.317)	DT 7.115 (1.181)	loss nan (nan)	prob nan (nan)	GS 35.156 (35.156)	mem 41.886
Train: [16][145/750]	BT 0.265 (1.278)	DT 0.007 (1.140)	loss nan (nan)	prob nan (nan)	GS 26.391 (26.391)	mem 41.862
Train: [16][150/750]	BT 0.157 (1.269)	DT 0.012 (1.130)	loss nan (nan)	prob nan (nan)	GS 32.516 (32.516)	mem 41.867
Train: [16][155/750]	BT 0.123 (1.287)	DT 0.001 (1.148)	loss nan (nan)	prob nan (nan)	GS 28.406 (28.406)	mem 42.111
Train: [16][160/750]	BT 0.157 (1.281)	DT 0.009 (1.143)	loss nan (nan)	prob nan (nan)	GS 33.297 (33.297)	mem 42.066
Train: [16][165/750]	BT 0.158 (1.282)	DT 0.010 (1.144)	loss nan (nan)	prob nan (nan)	GS 28.219 (28.219)	mem 42.214
Train: [16][170/750]	BT 5.994 (1.284)	DT 5.869 (1.145)	loss nan (nan)	prob nan (nan)	GS 36.141 (36.141)	mem 42.094
Train: [16][175/750]	BT 0.181 (1.251)	DT 0.002 (1.113)	loss nan (nan)	prob nan (nan)	GS 31.328 (31.328)	mem 42.179
Train: [16][180/750]	BT 0.069 (1.277)	DT 0.001 (1.139)	loss nan (nan)	prob nan (nan)	GS 34.750 (34.750)	mem 42.088
Train: [16][185/750]	BT 0.184 (1.247)	DT 0.010 (1.110)	loss nan (nan)	prob nan (nan)	GS 31.094 (31.094)	mem 42.299
Train: [16][190/750]	BT 0.084 (1.274)	DT 0.001 (1.137)	loss nan (nan)	prob nan (nan)	GS 31.281 (31.281)	mem 42.105
Train: [16][195/750]	BT 0.106 (1.244)	DT 0.006 (1.108)	loss nan (nan)	prob nan (nan)	GS 29.438 (29.438)	mem 42.141
Train: [16][200/750]	BT 8.161 (1.257)	DT 7.951 (1.120)	loss nan (nan)	prob nan (nan)	GS 31.875 (31.875)	mem 42.325
Train: [16][205/750]	BT 0.083 (1.230)	DT 0.002 (1.093)	loss nan (nan)	prob nan (nan)	GS 30.391 (30.391)	mem 42.319
Train: [16][210/750]	BT 0.144 (1.205)	DT 0.024 (1.067)	loss nan (nan)	prob nan (nan)	GS 31.891 (31.891)	mem 42.266
Train: [16][215/750]	BT 0.116 (1.236)	DT 0.002 (1.099)	loss nan (nan)	prob nan (nan)	GS 30.859 (30.859)	mem 42.306
Train: [16][220/750]	BT 0.211 (1.212)	DT 0.005 (1.074)	loss nan (nan)	prob nan (nan)	GS 36.875 (36.875)	mem 42.310
Train: [16][225/750]	BT 0.125 (1.223)	DT 0.001 (1.086)	loss nan (nan)	prob nan (nan)	GS 30.250 (30.250)	mem 42.454
Train: [16][230/750]	BT 2.771 (1.211)	DT 2.642 (1.074)	loss nan (nan)	prob nan (nan)	GS 34.703 (34.703)	mem 42.417
Train: [16][235/750]	BT 0.210 (1.191)	DT 0.005 (1.055)	loss nan (nan)	prob nan (nan)	GS 33.500 (33.500)	mem 42.419
Train: [16][240/750]	BT 0.184 (1.196)	DT 0.002 (1.059)	loss nan (nan)	prob nan (nan)	GS 34.297 (34.297)	mem 42.539
Train: [16][245/750]	BT 0.102 (1.206)	DT 0.010 (1.070)	loss nan (nan)	prob nan (nan)	GS 30.094 (30.094)	mem 42.272
Train: [16][250/750]	BT 1.103 (1.198)	DT 0.965 (1.062)	loss nan (nan)	prob nan (nan)	GS 37.500 (37.500)	mem 42.274
Train: [16][255/750]	BT 0.092 (1.202)	DT 0.001 (1.067)	loss nan (nan)	prob nan (nan)	GS 32.516 (32.516)	mem 42.425
Train: [16][260/750]	BT 5.119 (1.206)	DT 4.995 (1.070)	loss nan (nan)	prob nan (nan)	GS 29.641 (29.641)	mem 42.212
Train: [16][265/750]	BT 0.120 (1.186)	DT 0.003 (1.050)	loss nan (nan)	prob nan (nan)	GS 33.578 (33.578)	mem 42.213
Train: [16][270/750]	BT 0.111 (1.187)	DT 0.002 (1.051)	loss nan (nan)	prob nan (nan)	GS 34.000 (34.000)	mem 42.273
Train: [16][275/750]	BT 0.151 (1.180)	DT 0.016 (1.044)	loss nan (nan)	prob nan (nan)	GS 32.391 (32.391)	mem 42.271
Train: [16][280/750]	BT 0.158 (1.204)	DT 0.009 (1.068)	loss nan (nan)	prob nan (nan)	GS 37.047 (37.047)	mem 42.392
Train: [16][285/750]	BT 0.184 (1.185)	DT 0.007 (1.049)	loss nan (nan)	prob nan (nan)	GS 32.406 (32.406)	mem 42.315
Train: [16][290/750]	BT 9.443 (1.211)	DT 9.347 (1.075)	loss nan (nan)	prob nan (nan)	GS 31.609 (31.609)	mem 42.299
Train: [16][295/750]	BT 0.120 (1.193)	DT 0.020 (1.057)	loss nan (nan)	prob nan (nan)	GS 28.094 (28.094)	mem 42.302
Train: [16][300/750]	BT 1.524 (1.186)	DT 1.397 (1.050)	loss nan (nan)	prob nan (nan)	GS 36.906 (36.906)	mem 42.362
Train: [16][305/750]	BT 0.112 (1.199)	DT 0.001 (1.063)	loss nan (nan)	prob nan (nan)	GS 44.859 (44.859)	mem 42.348
Train: [16][310/750]	BT 3.992 (1.194)	DT 3.791 (1.058)	loss nan (nan)	prob nan (nan)	GS 32.422 (32.422)	mem 42.328
Train: [16][315/750]	BT 0.100 (1.190)	DT 0.001 (1.053)	loss nan (nan)	prob nan (nan)	GS 27.000 (27.000)	mem 42.600
Train: [16][320/750]	BT 0.143 (1.173)	DT 0.001 (1.037)	loss nan (nan)	prob nan (nan)	GS 32.250 (32.250)	mem 42.411
Train: [16][325/750]	BT 0.125 (1.191)	DT 0.027 (1.054)	loss nan (nan)	prob nan (nan)	GS 33.766 (33.766)	mem 42.348
Train: [16][330/750]	BT 0.116 (1.177)	DT 0.009 (1.041)	loss nan (nan)	prob nan (nan)	GS 26.688 (26.688)	mem 42.401
Train: [16][335/750]	BT 0.085 (1.194)	DT 0.006 (1.058)	loss nan (nan)	prob nan (nan)	GS 31.766 (31.766)	mem 42.478
Train: [16][340/750]	BT 0.088 (1.180)	DT 0.001 (1.045)	loss nan (nan)	prob nan (nan)	GS 35.125 (35.125)	mem 42.429
Train: [16][345/750]	BT 0.127 (1.165)	DT 0.001 (1.030)	loss nan (nan)	prob nan (nan)	GS 36.516 (36.516)	mem 42.431
Train: [16][350/750]	BT 2.392 (1.182)	DT 2.257 (1.047)	loss nan (nan)	prob nan (nan)	GS 36.547 (36.547)	mem 42.413
Train: [16][355/750]	BT 0.114 (1.168)	DT 0.002 (1.032)	loss nan (nan)	prob nan (nan)	GS 27.641 (27.641)	mem 42.654
Train: [16][360/750]	BT 0.166 (1.182)	DT 0.001 (1.046)	loss nan (nan)	prob nan (nan)	GS 31.109 (31.109)	mem 42.432
Train: [16][365/750]	BT 0.141 (1.169)	DT 0.001 (1.034)	loss nan (nan)	prob nan (nan)	GS 33.906 (33.906)	mem 42.369
Train: [16][370/750]	BT 11.662 (1.187)	DT 11.587 (1.051)	loss nan (nan)	prob nan (nan)	GS 34.125 (34.125)	mem 42.418
Train: [16][375/750]	BT 0.074 (1.177)	DT 0.002 (1.042)	loss nan (nan)	prob nan (nan)	GS 31.156 (31.156)	mem 42.431
Train: [16][380/750]	BT 0.101 (1.163)	DT 0.001 (1.028)	loss nan (nan)	prob nan (nan)	GS 35.281 (35.281)	mem 42.444
Train: [16][385/750]	BT 0.177 (1.174)	DT 0.008 (1.040)	loss nan (nan)	prob nan (nan)	GS 33.344 (33.344)	mem 42.462
Train: [16][390/750]	BT 0.161 (1.168)	DT 0.024 (1.033)	loss nan (nan)	prob nan (nan)	GS 33.750 (33.750)	mem 42.325
Train: [16][395/750]	BT 0.118 (1.179)	DT 0.002 (1.044)	loss nan (nan)	prob nan (nan)	GS 27.859 (27.859)	mem 42.503
Train: [16][400/750]	BT 0.082 (1.165)	DT 0.002 (1.031)	loss nan (nan)	prob nan (nan)	GS 27.922 (27.922)	mem 42.412
Train: [16][405/750]	BT 0.146 (1.153)	DT 0.008 (1.018)	loss nan (nan)	prob nan (nan)	GS 28.500 (28.500)	mem 42.443
Train: [16][410/750]	BT 0.143 (1.164)	DT 0.001 (1.029)	loss nan (nan)	prob nan (nan)	GS 34.719 (34.719)	mem 42.385
Train: [16][415/750]	BT 0.088 (1.152)	DT 0.002 (1.017)	loss nan (nan)	prob nan (nan)	GS 31.531 (31.531)	mem 42.406
Train: [16][420/750]	BT 0.100 (1.168)	DT 0.001 (1.033)	loss nan (nan)	prob nan (nan)	GS 31.016 (31.016)	mem 42.308
Train: [16][425/750]	BT 0.141 (1.156)	DT 0.002 (1.020)	loss nan (nan)	prob nan (nan)	GS 28.344 (28.344)	mem 42.309
Train: [16][430/750]	BT 9.186 (1.165)	DT 8.984 (1.030)	loss nan (nan)	prob nan (nan)	GS 31.578 (31.578)	mem 42.413
Train: [16][435/750]	BT 0.104 (1.154)	DT 0.005 (1.019)	loss nan (nan)	prob nan (nan)	GS 30.875 (30.875)	mem 42.403
Train: [16][440/750]	BT 0.135 (1.142)	DT 0.002 (1.007)	loss nan (nan)	prob nan (nan)	GS 36.047 (36.047)	mem 42.387
Train: [16][445/750]	BT 0.137 (1.163)	DT 0.004 (1.028)	loss nan (nan)	prob nan (nan)	GS 37.219 (37.219)	mem 42.404
Train: [16][450/750]	BT 0.105 (1.151)	DT 0.002 (1.016)	loss nan (nan)	prob nan (nan)	GS 34.469 (34.469)	mem 42.672
Train: [16][455/750]	BT 0.147 (1.168)	DT 0.008 (1.034)	loss nan (nan)	prob nan (nan)	GS 32.453 (32.453)	mem 42.382
Train: [16][460/750]	BT 0.085 (1.157)	DT 0.001 (1.023)	loss nan (nan)	prob nan (nan)	GS 32.109 (32.109)	mem 42.382
Train: [16][465/750]	BT 0.271 (1.146)	DT 0.008 (1.012)	loss nan (nan)	prob nan (nan)	GS 28.719 (28.719)	mem 42.450
Train: [16][470/750]	BT 0.160 (1.155)	DT 0.001 (1.020)	loss nan (nan)	prob nan (nan)	GS 32.938 (32.938)	mem 42.624
Train: [16][475/750]	BT 0.101 (1.144)	DT 0.009 (1.010)	loss nan (nan)	prob nan (nan)	GS 31.938 (31.938)	mem 42.448
Train: [16][480/750]	BT 0.094 (1.160)	DT 0.003 (1.026)	loss nan (nan)	prob nan (nan)	GS 30.797 (30.797)	mem 42.458
Train: [16][485/750]	BT 0.108 (1.149)	DT 0.001 (1.016)	loss nan (nan)	prob nan (nan)	GS 36.312 (36.312)	mem 42.527
Train: [16][490/750]	BT 13.919 (1.167)	DT 13.822 (1.034)	loss nan (nan)	prob nan (nan)	GS 36.109 (36.109)	mem 42.464
Train: [16][495/750]	BT 0.097 (1.157)	DT 0.004 (1.023)	loss nan (nan)	prob nan (nan)	GS 29.656 (29.656)	mem 42.442
Train: [16][500/750]	BT 0.126 (1.147)	DT 0.002 (1.013)	loss nan (nan)	prob nan (nan)	GS 31.328 (31.328)	mem 42.558
Train: [16][505/750]	BT 0.169 (1.159)	DT 0.009 (1.025)	loss nan (nan)	prob nan (nan)	GS 26.266 (26.266)	mem 42.435
Train: [16][510/750]	BT 0.098 (1.149)	DT 0.010 (1.015)	loss nan (nan)	prob nan (nan)	GS 30.016 (30.016)	mem 42.526
Train: [16][515/750]	BT 0.125 (1.159)	DT 0.001 (1.025)	loss nan (nan)	prob nan (nan)	GS 29.938 (29.938)	mem 42.422
Train: [16][520/750]	BT 0.195 (1.149)	DT 0.004 (1.015)	loss nan (nan)	prob nan (nan)	GS 31.484 (31.484)	mem 42.621
Train: [16][525/750]	BT 0.256 (1.140)	DT 0.005 (1.005)	loss nan (nan)	prob nan (nan)	GS 38.797 (38.797)	mem 42.551
Train: [16][530/750]	BT 0.092 (1.155)	DT 0.001 (1.021)	loss nan (nan)	prob nan (nan)	GS 33.766 (33.766)	mem 42.490
Train: [16][535/750]	BT 0.112 (1.146)	DT 0.004 (1.011)	loss nan (nan)	prob nan (nan)	GS 33.094 (33.094)	mem 42.348
Train: [16][540/750]	BT 0.094 (1.157)	DT 0.002 (1.022)	loss nan (nan)	prob nan (nan)	GS 33.859 (33.859)	mem 42.403
Train: [16][545/750]	BT 0.112 (1.147)	DT 0.010 (1.013)	loss nan (nan)	prob nan (nan)	GS 29.156 (29.156)	mem 42.401
Train: [16][550/750]	BT 13.519 (1.163)	DT 13.405 (1.028)	loss nan (nan)	prob nan (nan)	GS 36.969 (36.969)	mem 42.489
Train: [16][555/750]	BT 0.260 (1.153)	DT 0.007 (1.019)	loss nan (nan)	prob nan (nan)	GS 29.438 (29.438)	mem 42.461
Train: [16][560/750]	BT 0.136 (1.144)	DT 0.001 (1.010)	loss nan (nan)	prob nan (nan)	GS 36.703 (36.703)	mem 42.539
Train: [16][565/750]	BT 0.212 (1.157)	DT 0.005 (1.022)	loss nan (nan)	prob nan (nan)	GS 38.047 (38.047)	mem 42.488
Train: [16][570/750]	BT 0.088 (1.148)	DT 0.004 (1.013)	loss nan (nan)	prob nan (nan)	GS 34.562 (34.562)	mem 42.647
Train: [16][575/750]	BT 0.094 (1.159)	DT 0.001 (1.024)	loss nan (nan)	prob nan (nan)	GS 33.484 (33.484)	mem 42.486
Train: [16][580/750]	BT 0.123 (1.150)	DT 0.002 (1.015)	loss nan (nan)	prob nan (nan)	GS 31.359 (31.359)	mem 42.493
Train: [16][585/750]	BT 0.164 (1.142)	DT 0.003 (1.007)	loss nan (nan)	prob nan (nan)	GS 27.484 (27.484)	mem 42.658
Train: [16][590/750]	BT 0.093 (1.154)	DT 0.001 (1.019)	loss nan (nan)	prob nan (nan)	GS 33.969 (33.969)	mem 42.458
Train: [16][595/750]	BT 0.139 (1.145)	DT 0.006 (1.011)	loss nan (nan)	prob nan (nan)	GS 34.562 (34.562)	mem 42.637
Train: [16][600/750]	BT 0.136 (1.157)	DT 0.002 (1.022)	loss nan (nan)	prob nan (nan)	GS 34.828 (34.828)	mem 42.492
Train: [16][605/750]	BT 0.180 (1.148)	DT 0.002 (1.014)	loss nan (nan)	prob nan (nan)	GS 29.531 (29.531)	mem 42.538
Train: [16][610/750]	BT 12.048 (1.160)	DT 11.950 (1.025)	loss nan (nan)	prob nan (nan)	GS 37.578 (37.578)	mem 42.479
Train: [16][615/750]	BT 0.088 (1.151)	DT 0.001 (1.017)	loss nan (nan)	prob nan (nan)	GS 32.594 (32.594)	mem 42.587
Train: [16][620/750]	BT 0.123 (1.143)	DT 0.018 (1.009)	loss nan (nan)	prob nan (nan)	GS 33.109 (33.109)	mem 42.691
Train: [16][625/750]	BT 0.143 (1.154)	DT 0.023 (1.020)	loss nan (nan)	prob nan (nan)	GS 27.438 (27.438)	mem 42.552
Train: [16][630/750]	BT 0.191 (1.146)	DT 0.002 (1.012)	loss nan (nan)	prob nan (nan)	GS 34.891 (34.891)	mem 42.620
Train: [16][635/750]	BT 0.098 (1.153)	DT 0.002 (1.019)	loss nan (nan)	prob nan (nan)	GS 27.078 (27.078)	mem 42.536
Train: [16][640/750]	BT 0.132 (1.145)	DT 0.003 (1.011)	loss nan (nan)	prob nan (nan)	GS 31.359 (31.359)	mem 42.557
Train: [16][645/750]	BT 0.103 (1.137)	DT 0.011 (1.003)	loss nan (nan)	prob nan (nan)	GS 30.172 (30.172)	mem 42.541
Train: [16][650/750]	BT 0.132 (1.147)	DT 0.001 (1.014)	loss nan (nan)	prob nan (nan)	GS 37.125 (37.125)	mem 42.609
Train: [16][655/750]	BT 0.209 (1.140)	DT 0.001 (1.006)	loss nan (nan)	prob nan (nan)	GS 35.000 (35.000)	mem 42.517
Train: [16][660/750]	BT 0.097 (1.149)	DT 0.001 (1.015)	loss nan (nan)	prob nan (nan)	GS 32.984 (32.984)	mem 42.543
Train: [16][665/750]	BT 0.089 (1.141)	DT 0.002 (1.007)	loss nan (nan)	prob nan (nan)	GS 35.531 (35.531)	mem 42.683
Train: [16][670/750]	BT 12.197 (1.151)	DT 12.120 (1.018)	loss nan (nan)	prob nan (nan)	GS 35.750 (35.750)	mem 42.512
Train: [16][675/750]	BT 0.191 (1.144)	DT 0.009 (1.010)	loss nan (nan)	prob nan (nan)	GS 34.844 (34.844)	mem 42.552
Train: [16][680/750]	BT 0.288 (1.137)	DT 0.001 (1.003)	loss nan (nan)	prob nan (nan)	GS 35.141 (35.141)	mem 42.553
Train: [16][685/750]	BT 0.122 (1.144)	DT 0.012 (1.011)	loss nan (nan)	prob nan (nan)	GS 30.891 (30.891)	mem 42.501
Train: [16][690/750]	BT 0.113 (1.137)	DT 0.015 (1.003)	loss nan (nan)	prob nan (nan)	GS 38.172 (38.172)	mem 42.503
Train: [16][695/750]	BT 0.118 (1.152)	DT 0.001 (1.018)	loss nan (nan)	prob nan (nan)	GS 37.562 (37.562)	mem 42.467
Train: [16][700/750]	BT 0.094 (1.145)	DT 0.002 (1.011)	loss nan (nan)	prob nan (nan)	GS 34.016 (34.016)	mem 42.576
Train: [16][705/750]	BT 0.177 (1.138)	DT 0.001 (1.004)	loss nan (nan)	prob nan (nan)	GS 28.984 (28.984)	mem 42.603
arpack error, retry= 0
arpack error, retry= 0
Train: [16][710/750]	BT 0.248 (1.145)	DT 0.012 (1.011)	loss nan (nan)	prob nan (nan)	GS 35.031 (35.031)	mem 42.607
Train: [16][715/750]	BT 0.146 (1.138)	DT 0.010 (1.004)	loss nan (nan)	prob nan (nan)	GS 42.484 (42.484)	mem 42.520
Train: [16][720/750]	BT 0.862 (1.148)	DT 0.775 (1.014)	loss nan (nan)	prob nan (nan)	GS 36.297 (36.297)	mem 42.530
Train: [16][725/750]	BT 0.174 (1.141)	DT 0.006 (1.007)	loss nan (nan)	prob nan (nan)	GS 32.859 (32.859)	mem 42.569
Train: [16][730/750]	BT 9.195 (1.147)	DT 9.067 (1.013)	loss nan (nan)	prob nan (nan)	GS 30.344 (30.344)	mem 42.145
Train: [16][735/750]	BT 0.124 (1.144)	DT 0.001 (1.010)	loss nan (nan)	prob nan (nan)	GS 32.219 (32.219)	mem 42.104
Train: [16][740/750]	BT 0.066 (1.137)	DT 0.001 (1.004)	loss nan (nan)	prob nan (nan)	GS 32.984 (32.984)	mem 39.266
Train: [16][745/750]	BT 0.088 (1.137)	DT 0.001 (1.004)	loss nan (nan)	prob nan (nan)	GS 31.375 (31.375)	mem 13.070
Train: [16][750/750]	BT 0.071 (1.130)	DT 0.001 (0.997)	loss nan (nan)	prob nan (nan)	GS 31.562 (31.562)	mem 13.070
Train: [16][755/750]	BT 0.068 (1.125)	DT 0.001 (0.993)	loss nan (nan)	prob nan (nan)	GS 31.812 (31.812)	mem 13.011
epoch 16, total time 851.08
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [17][1/750]	BT 23.856 (23.856)	DT 23.612 (23.612)	loss nan (nan)	prob nan (nan)	GS 35.953 (35.953)	mem 41.102
Train: [17][5/750]	BT 0.141 (6.860)	DT 0.002 (6.683)	loss nan (nan)	prob nan (nan)	GS 30.141 (30.141)	mem 41.208
Train: [17][10/750]	BT 0.136 (3.506)	DT 0.002 (3.343)	loss nan (nan)	prob nan (nan)	GS 31.203 (31.203)	mem 41.211
Train: [17][15/750]	BT 6.699 (2.999)	DT 6.451 (2.833)	loss nan (nan)	prob nan (nan)	GS 30.766 (30.766)	mem 41.568
Train: [17][20/750]	BT 0.156 (2.285)	DT 0.026 (2.128)	loss nan (nan)	prob nan (nan)	GS 34.969 (34.969)	mem 41.652
Train: [17][25/750]	BT 0.119 (1.854)	DT 0.011 (1.704)	loss nan (nan)	prob nan (nan)	GS 32.031 (32.031)	mem 41.543
Train: [17][30/750]	BT 0.781 (1.907)	DT 0.643 (1.757)	loss nan (nan)	prob nan (nan)	GS 33.672 (33.672)	mem 41.675
Train: [17][35/750]	BT 0.278 (1.729)	DT 0.016 (1.576)	loss nan (nan)	prob nan (nan)	GS 32.422 (32.422)	mem 41.762
Train: [17][40/750]	BT 0.172 (1.742)	DT 0.002 (1.590)	loss nan (nan)	prob nan (nan)	GS 30.609 (30.609)	mem 42.685
Train: [17][45/750]	BT 0.154 (1.806)	DT 0.001 (1.656)	loss nan (nan)	prob nan (nan)	GS 28.797 (28.797)	mem 43.315
Train: [17][50/750]	BT 1.877 (1.675)	DT 1.682 (1.525)	loss nan (nan)	prob nan (nan)	GS 30.531 (30.531)	mem 43.336
Train: [17][55/750]	BT 0.105 (1.601)	DT 0.001 (1.455)	loss nan (nan)	prob nan (nan)	GS 25.875 (25.875)	mem 43.288
Train: [17][60/750]	BT 0.124 (1.594)	DT 0.002 (1.448)	loss nan (nan)	prob nan (nan)	GS 35.281 (35.281)	mem 43.446
Train: [17][65/750]	BT 0.218 (1.552)	DT 0.002 (1.404)	loss nan (nan)	prob nan (nan)	GS 30.969 (30.969)	mem 43.234
Train: [17][70/750]	BT 0.123 (1.560)	DT 0.014 (1.414)	loss nan (nan)	prob nan (nan)	GS 31.797 (31.797)	mem 43.411
Train: [17][75/750]	BT 0.150 (1.514)	DT 0.004 (1.368)	loss nan (nan)	prob nan (nan)	GS 33.188 (33.188)	mem 43.681
Train: [17][80/750]	BT 8.594 (1.533)	DT 8.473 (1.389)	loss nan (nan)	prob nan (nan)	GS 37.000 (37.000)	mem 43.694
Train: [17][85/750]	BT 0.110 (1.450)	DT 0.001 (1.307)	loss nan (nan)	prob nan (nan)	GS 30.422 (30.422)	mem 43.523
Train: [17][90/750]	BT 0.115 (1.406)	DT 0.002 (1.263)	loss nan (nan)	prob nan (nan)	GS 35.000 (35.000)	mem 43.587
Train: [17][95/750]	BT 0.087 (1.429)	DT 0.002 (1.287)	loss nan (nan)	prob nan (nan)	GS 35.719 (35.719)	mem 43.720
Train: [17][100/750]	BT 0.210 (1.395)	DT 0.002 (1.253)	loss nan (nan)	prob nan (nan)	GS 30.688 (30.688)	mem 43.708
Train: [17][105/750]	BT 0.164 (1.456)	DT 0.002 (1.315)	loss nan (nan)	prob nan (nan)	GS 31.266 (31.266)	mem 43.660
Train: [17][110/750]	BT 0.866 (1.402)	DT 0.755 (1.262)	loss nan (nan)	prob nan (nan)	GS 36.562 (36.562)	mem 43.601
Train: [17][115/750]	BT 0.174 (1.347)	DT 0.003 (1.207)	loss nan (nan)	prob nan (nan)	GS 33.391 (33.391)	mem 43.698
Train: [17][120/750]	BT 0.161 (1.366)	DT 0.001 (1.228)	loss nan (nan)	prob nan (nan)	GS 32.531 (32.531)	mem 43.595
Train: [17][125/750]	BT 0.116 (1.375)	DT 0.004 (1.237)	loss nan (nan)	prob nan (nan)	GS 32.766 (32.766)	mem 43.480
Train: [17][130/750]	BT 0.106 (1.382)	DT 0.002 (1.245)	loss nan (nan)	prob nan (nan)	GS 31.016 (31.016)	mem 43.539
Train: [17][135/750]	BT 0.117 (1.355)	DT 0.007 (1.218)	loss nan (nan)	prob nan (nan)	GS 28.062 (28.062)	mem 43.542
Train: [17][140/750]	BT 11.266 (1.390)	DT 10.961 (1.253)	loss nan (nan)	prob nan (nan)	GS 35.719 (35.719)	mem 43.491
Train: [17][145/750]	BT 0.125 (1.348)	DT 0.011 (1.210)	loss nan (nan)	prob nan (nan)	GS 34.016 (34.016)	mem 43.561
Train: [17][150/750]	BT 0.166 (1.326)	DT 0.001 (1.188)	loss nan (nan)	prob nan (nan)	GS 31.109 (31.109)	mem 43.500
Train: [17][155/750]	BT 0.175 (1.340)	DT 0.001 (1.202)	loss nan (nan)	prob nan (nan)	GS 30.375 (30.375)	mem 43.481
Train: [17][160/750]	BT 0.108 (1.351)	DT 0.010 (1.213)	loss nan (nan)	prob nan (nan)	GS 29.984 (29.984)	mem 43.456
Train: [17][165/750]	BT 0.129 (1.347)	DT 0.006 (1.207)	loss nan (nan)	prob nan (nan)	GS 32.938 (32.938)	mem 43.578
Train: [17][170/750]	BT 6.887 (1.350)	DT 6.798 (1.212)	loss nan (nan)	prob nan (nan)	GS 31.484 (31.484)	mem 43.551
Train: [17][175/750]	BT 0.116 (1.316)	DT 0.019 (1.177)	loss nan (nan)	prob nan (nan)	GS 29.531 (29.531)	mem 43.580
Train: [17][180/750]	BT 0.087 (1.309)	DT 0.002 (1.171)	loss nan (nan)	prob nan (nan)	GS 31.484 (31.484)	mem 43.619
Train: [17][185/750]	BT 0.190 (1.318)	DT 0.009 (1.181)	loss nan (nan)	prob nan (nan)	GS 34.234 (34.234)	mem 43.653
Train: [17][190/750]	BT 0.098 (1.294)	DT 0.008 (1.157)	loss nan (nan)	prob nan (nan)	GS 35.688 (35.688)	mem 43.657
Train: [17][195/750]	BT 0.153 (1.305)	DT 0.002 (1.168)	loss nan (nan)	prob nan (nan)	GS 32.766 (32.766)	mem 43.909
Train: [17][200/750]	BT 5.960 (1.305)	DT 5.853 (1.168)	loss nan (nan)	prob nan (nan)	GS 32.438 (32.438)	mem 43.690
Train: [17][205/750]	BT 0.204 (1.279)	DT 0.015 (1.140)	loss nan (nan)	prob nan (nan)	GS 30.500 (30.500)	mem 43.693
Train: [17][210/750]	BT 0.127 (1.275)	DT 0.002 (1.136)	loss nan (nan)	prob nan (nan)	GS 34.922 (34.922)	mem 43.712
Train: [17][215/750]	BT 0.297 (1.272)	DT 0.009 (1.133)	loss nan (nan)	prob nan (nan)	GS 32.547 (32.547)	mem 43.627
Train: [17][220/750]	BT 0.080 (1.267)	DT 0.001 (1.130)	loss nan (nan)	prob nan (nan)	GS 29.172 (29.172)	mem 43.704
Train: [17][225/750]	BT 0.140 (1.263)	DT 0.001 (1.126)	loss nan (nan)	prob nan (nan)	GS 31.172 (31.172)	mem 43.706
Train: [17][230/750]	BT 5.047 (1.261)	DT 4.896 (1.123)	loss nan (nan)	prob nan (nan)	GS 31.500 (31.500)	mem 43.763
Train: [17][235/750]	BT 0.127 (1.238)	DT 0.003 (1.099)	loss nan (nan)	prob nan (nan)	GS 29.625 (29.625)	mem 43.727
Train: [17][240/750]	BT 0.107 (1.255)	DT 0.002 (1.116)	loss nan (nan)	prob nan (nan)	GS 32.641 (32.641)	mem 43.786
Train: [17][245/750]	BT 0.107 (1.247)	DT 0.002 (1.108)	loss nan (nan)	prob nan (nan)	GS 33.859 (33.859)	mem 43.752
Train: [17][250/750]	BT 0.093 (1.259)	DT 0.002 (1.120)	loss nan (nan)	prob nan (nan)	GS 32.984 (32.984)	mem 43.956
Train: [17][255/750]	BT 0.096 (1.257)	DT 0.001 (1.118)	loss nan (nan)	prob nan (nan)	GS 31.344 (31.344)	mem 43.704
Train: [17][260/750]	BT 7.109 (1.262)	DT 6.949 (1.124)	loss nan (nan)	prob nan (nan)	GS 33.281 (33.281)	mem 44.007
Train: [17][265/750]	BT 0.181 (1.240)	DT 0.002 (1.102)	loss nan (nan)	prob nan (nan)	GS 32.547 (32.547)	mem 43.820
Train: [17][270/750]	BT 0.077 (1.235)	DT 0.006 (1.097)	loss nan (nan)	prob nan (nan)	GS 28.734 (28.734)	mem 43.650
Train: [17][275/750]	BT 0.174 (1.251)	DT 0.011 (1.112)	loss nan (nan)	prob nan (nan)	GS 33.172 (33.172)	mem 42.334
Train: [17][280/750]	BT 0.096 (1.246)	DT 0.003 (1.107)	loss nan (nan)	prob nan (nan)	GS 32.109 (32.109)	mem 42.297
Train: [17][285/750]	BT 0.131 (1.258)	DT 0.012 (1.119)	loss nan (nan)	prob nan (nan)	GS 29.203 (29.203)	mem 42.411
Train: [17][290/750]	BT 1.500 (1.244)	DT 1.377 (1.105)	loss nan (nan)	prob nan (nan)	GS 33.500 (33.500)	mem 42.355
Train: [17][295/750]	BT 0.144 (1.225)	DT 0.012 (1.086)	loss nan (nan)	prob nan (nan)	GS 36.281 (36.281)	mem 42.315
Train: [17][300/750]	BT 0.098 (1.241)	DT 0.003 (1.103)	loss nan (nan)	prob nan (nan)	GS 32.469 (32.469)	mem 42.382
Train: [17][305/750]	BT 0.195 (1.229)	DT 0.024 (1.091)	loss nan (nan)	prob nan (nan)	GS 29.266 (29.266)	mem 42.396
Train: [17][310/750]	BT 0.072 (1.249)	DT 0.002 (1.111)	loss nan (nan)	prob nan (nan)	GS 30.516 (30.516)	mem 42.377
Train: [17][315/750]	BT 0.137 (1.231)	DT 0.010 (1.093)	loss nan (nan)	prob nan (nan)	GS 32.188 (32.188)	mem 42.387
Train: [17][320/750]	BT 13.313 (1.255)	DT 13.225 (1.118)	loss nan (nan)	prob nan (nan)	GS 33.344 (33.344)	mem 42.345
Train: [17][325/750]	BT 0.072 (1.237)	DT 0.001 (1.100)	loss nan (nan)	prob nan (nan)	GS 40.562 (40.562)	mem 42.345
Train: [17][330/750]	BT 0.156 (1.221)	DT 0.006 (1.084)	loss nan (nan)	prob nan (nan)	GS 33.719 (33.719)	mem 42.346
Train: [17][335/750]	BT 0.187 (1.236)	DT 0.006 (1.099)	loss nan (nan)	prob nan (nan)	GS 29.109 (29.109)	mem 42.396
Train: [17][340/750]	BT 0.110 (1.220)	DT 0.002 (1.083)	loss nan (nan)	prob nan (nan)	GS 31.391 (31.391)	mem 42.376
Train: [17][345/750]	BT 0.078 (1.240)	DT 0.001 (1.102)	loss nan (nan)	prob nan (nan)	GS 26.750 (26.750)	mem 42.344
Train: [17][350/750]	BT 0.132 (1.223)	DT 0.001 (1.087)	loss nan (nan)	prob nan (nan)	GS 33.844 (33.844)	mem 42.278
Train: [17][355/750]	BT 0.130 (1.208)	DT 0.005 (1.071)	loss nan (nan)	prob nan (nan)	GS 29.734 (29.734)	mem 42.291
Train: [17][360/750]	BT 0.082 (1.228)	DT 0.001 (1.093)	loss nan (nan)	prob nan (nan)	GS 37.344 (37.344)	mem 42.353
Train: [17][365/750]	BT 0.196 (1.213)	DT 0.001 (1.078)	loss nan (nan)	prob nan (nan)	GS 31.797 (31.797)	mem 42.457
Train: [17][370/750]	BT 0.061 (1.232)	DT 0.001 (1.097)	loss nan (nan)	prob nan (nan)	GS 36.000 (36.000)	mem 42.426
Train: [17][375/750]	BT 0.111 (1.217)	DT 0.002 (1.082)	loss nan (nan)	prob nan (nan)	GS 30.500 (30.500)	mem 42.482
Train: [17][380/750]	BT 11.054 (1.231)	DT 10.879 (1.097)	loss nan (nan)	prob nan (nan)	GS 35.578 (35.578)	mem 42.501
Train: [17][385/750]	BT 0.141 (1.217)	DT 0.015 (1.083)	loss nan (nan)	prob nan (nan)	GS 33.062 (33.062)	mem 42.504
Train: [17][390/750]	BT 0.072 (1.203)	DT 0.001 (1.069)	loss nan (nan)	prob nan (nan)	GS 33.688 (33.688)	mem 42.504
Train: [17][395/750]	BT 0.144 (1.217)	DT 0.010 (1.082)	loss nan (nan)	prob nan (nan)	GS 33.750 (33.750)	mem 42.506
Train: [17][400/750]	BT 0.178 (1.207)	DT 0.006 (1.073)	loss nan (nan)	prob nan (nan)	GS 32.406 (32.406)	mem 42.641
Train: [17][405/750]	BT 0.119 (1.212)	DT 0.001 (1.077)	loss nan (nan)	prob nan (nan)	GS 29.375 (29.375)	mem 42.539
Train: [17][410/750]	BT 5.794 (1.212)	DT 5.709 (1.078)	loss nan (nan)	prob nan (nan)	GS 36.359 (36.359)	mem 42.448
Train: [17][415/750]	BT 0.176 (1.199)	DT 0.002 (1.065)	loss nan (nan)	prob nan (nan)	GS 28.688 (28.688)	mem 42.691
Train: [17][420/750]	BT 0.107 (1.196)	DT 0.002 (1.062)	loss nan (nan)	prob nan (nan)	GS 30.547 (30.547)	mem 42.482
Train: [17][425/750]	BT 0.091 (1.204)	DT 0.004 (1.069)	loss nan (nan)	prob nan (nan)	GS 31.734 (31.734)	mem 42.473
Train: [17][430/750]	BT 0.176 (1.200)	DT 0.002 (1.065)	loss nan (nan)	prob nan (nan)	GS 36.766 (36.766)	mem 42.475
Train: [17][435/750]	BT 0.159 (1.208)	DT 0.001 (1.073)	loss nan (nan)	prob nan (nan)	GS 26.672 (26.672)	mem 42.467
Train: [17][440/750]	BT 3.760 (1.203)	DT 3.579 (1.069)	loss nan (nan)	prob nan (nan)	GS 36.984 (36.984)	mem 42.799
Train: [17][445/750]	BT 0.136 (1.191)	DT 0.023 (1.057)	loss nan (nan)	prob nan (nan)	GS 28.531 (28.531)	mem 42.559
Train: [17][450/750]	BT 0.204 (1.190)	DT 0.034 (1.056)	loss nan (nan)	prob nan (nan)	GS 31.703 (31.703)	mem 42.587
Train: [17][455/750]	BT 0.225 (1.189)	DT 0.003 (1.054)	loss nan (nan)	prob nan (nan)	GS 35.656 (35.656)	mem 42.550
Train: [17][460/750]	BT 0.091 (1.201)	DT 0.005 (1.067)	loss nan (nan)	prob nan (nan)	GS 32.594 (32.594)	mem 42.481
Train: [17][465/750]	BT 0.089 (1.189)	DT 0.001 (1.055)	loss nan (nan)	prob nan (nan)	GS 33.000 (33.000)	mem 42.511
Train: [17][470/750]	BT 8.988 (1.197)	DT 8.826 (1.063)	loss nan (nan)	prob nan (nan)	GS 32.891 (32.891)	mem 42.556
Train: [17][475/750]	BT 0.181 (1.185)	DT 0.008 (1.052)	loss nan (nan)	prob nan (nan)	GS 30.609 (30.609)	mem 42.632
Train: [17][480/750]	BT 0.139 (1.180)	DT 0.002 (1.046)	loss nan (nan)	prob nan (nan)	GS 33.797 (33.797)	mem 42.449
Train: [17][485/750]	BT 0.161 (1.187)	DT 0.039 (1.053)	loss nan (nan)	prob nan (nan)	GS 27.828 (27.828)	mem 42.489
Train: [17][490/750]	BT 0.256 (1.185)	DT 0.017 (1.051)	loss nan (nan)	prob nan (nan)	GS 31.938 (31.938)	mem 42.486
Train: [17][495/750]	BT 0.144 (1.195)	DT 0.001 (1.062)	loss nan (nan)	prob nan (nan)	GS 33.141 (33.141)	mem 42.473
Train: [17][500/750]	BT 0.451 (1.186)	DT 0.360 (1.052)	loss nan (nan)	prob nan (nan)	GS 32.969 (32.969)	mem 42.519
Train: [17][505/750]	BT 0.085 (1.175)	DT 0.001 (1.041)	loss nan (nan)	prob nan (nan)	GS 34.078 (34.078)	mem 42.490
Train: [17][510/750]	BT 0.208 (1.188)	DT 0.009 (1.054)	loss nan (nan)	prob nan (nan)	GS 34.234 (34.234)	mem 42.549
Train: [17][515/750]	BT 0.109 (1.183)	DT 0.017 (1.049)	loss nan (nan)	prob nan (nan)	GS 25.125 (25.125)	mem 42.520
Train: [17][520/750]	BT 0.136 (1.195)	DT 0.002 (1.061)	loss nan (nan)	prob nan (nan)	GS 32.453 (32.453)	mem 42.629
Train: [17][525/750]	BT 0.092 (1.185)	DT 0.002 (1.051)	loss nan (nan)	prob nan (nan)	GS 32.625 (32.625)	mem 42.523
Train: [17][530/750]	BT 9.734 (1.193)	DT 9.589 (1.059)	loss nan (nan)	prob nan (nan)	GS 35.875 (35.875)	mem 42.475
Train: [17][535/750]	BT 0.202 (1.183)	DT 0.010 (1.049)	loss nan (nan)	prob nan (nan)	GS 30.031 (30.031)	mem 42.515
Train: [17][540/750]	BT 0.089 (1.176)	DT 0.001 (1.043)	loss nan (nan)	prob nan (nan)	GS 31.875 (31.875)	mem 42.479
Train: [17][545/750]	BT 0.096 (1.185)	DT 0.001 (1.052)	loss nan (nan)	prob nan (nan)	GS 26.953 (26.953)	mem 42.685
Train: [17][550/750]	BT 0.165 (1.176)	DT 0.006 (1.043)	loss nan (nan)	prob nan (nan)	GS 31.719 (31.719)	mem 42.670
Train: [17][555/750]	BT 0.149 (1.186)	DT 0.009 (1.052)	loss nan (nan)	prob nan (nan)	GS 29.422 (29.422)	mem 42.513
Train: [17][560/750]	BT 0.146 (1.176)	DT 0.010 (1.043)	loss nan (nan)	prob nan (nan)	GS 35.812 (35.812)	mem 42.647
Train: [17][565/750]	BT 0.106 (1.166)	DT 0.002 (1.033)	loss nan (nan)	prob nan (nan)	GS 25.062 (25.062)	mem 42.514
Train: [17][570/750]	BT 0.087 (1.175)	DT 0.002 (1.042)	loss nan (nan)	prob nan (nan)	GS 29.656 (29.656)	mem 42.554
Train: [17][575/750]	BT 0.128 (1.167)	DT 0.018 (1.034)	loss nan (nan)	prob nan (nan)	GS 29.984 (29.984)	mem 42.554
Train: [17][580/750]	BT 0.132 (1.177)	DT 0.001 (1.044)	loss nan (nan)	prob nan (nan)	GS 33.672 (33.672)	mem 42.632
Train: [17][585/750]	BT 0.137 (1.169)	DT 0.010 (1.036)	loss nan (nan)	prob nan (nan)	GS 27.609 (27.609)	mem 42.465
Train: [17][590/750]	BT 11.267 (1.179)	DT 11.114 (1.046)	loss nan (nan)	prob nan (nan)	GS 28.891 (28.891)	mem 42.430
Train: [17][595/750]	BT 0.093 (1.170)	DT 0.006 (1.037)	loss nan (nan)	prob nan (nan)	GS 32.641 (32.641)	mem 42.474
Train: [17][600/750]	BT 0.212 (1.161)	DT 0.002 (1.028)	loss nan (nan)	prob nan (nan)	GS 33.125 (33.125)	mem 42.545
Train: [17][605/750]	BT 0.186 (1.171)	DT 0.005 (1.038)	loss nan (nan)	prob nan (nan)	GS 29.688 (29.688)	mem 42.479
Train: [17][610/750]	BT 0.135 (1.162)	DT 0.010 (1.030)	loss nan (nan)	prob nan (nan)	GS 33.656 (33.656)	mem 42.489
Train: [17][615/750]	BT 0.122 (1.173)	DT 0.002 (1.041)	loss nan (nan)	prob nan (nan)	GS 30.094 (30.094)	mem 42.476
Train: [17][620/750]	BT 0.202 (1.165)	DT 0.002 (1.032)	loss nan (nan)	prob nan (nan)	GS 33.094 (33.094)	mem 42.706
Train: [17][625/750]	BT 0.095 (1.157)	DT 0.002 (1.024)	loss nan (nan)	prob nan (nan)	GS 29.375 (29.375)	mem 42.554
Train: [17][630/750]	BT 0.176 (1.167)	DT 0.053 (1.035)	loss nan (nan)	prob nan (nan)	GS 33.234 (33.234)	mem 42.343
Train: [17][635/750]	BT 0.127 (1.159)	DT 0.003 (1.027)	loss nan (nan)	prob nan (nan)	GS 36.438 (36.438)	mem 42.359
Train: [17][640/750]	BT 0.147 (1.169)	DT 0.001 (1.037)	loss nan (nan)	prob nan (nan)	GS 32.906 (32.906)	mem 42.461
Train: [17][645/750]	BT 0.154 (1.161)	DT 0.003 (1.029)	loss nan (nan)	prob nan (nan)	GS 35.422 (35.422)	mem 42.931
Train: [17][650/750]	BT 11.436 (1.170)	DT 11.294 (1.038)	loss nan (nan)	prob nan (nan)	GS 28.953 (28.953)	mem 42.481
Train: [17][655/750]	BT 0.092 (1.162)	DT 0.015 (1.030)	loss nan (nan)	prob nan (nan)	GS 33.234 (33.234)	mem 42.497
Train: [17][660/750]	BT 0.105 (1.154)	DT 0.002 (1.023)	loss nan (nan)	prob nan (nan)	GS 34.766 (34.766)	mem 42.698
Train: [17][665/750]	BT 0.083 (1.164)	DT 0.001 (1.033)	loss nan (nan)	prob nan (nan)	GS 32.188 (32.188)	mem 42.451
Train: [17][670/750]	BT 0.639 (1.157)	DT 0.474 (1.026)	loss nan (nan)	prob nan (nan)	GS 34.016 (34.016)	mem 42.405
Train: [17][675/750]	BT 0.079 (1.170)	DT 0.002 (1.039)	loss nan (nan)	prob nan (nan)	GS 33.594 (33.594)	mem 42.463
Train: [17][680/750]	BT 0.089 (1.162)	DT 0.001 (1.031)	loss nan (nan)	prob nan (nan)	GS 33.875 (33.875)	mem 42.449
Train: [17][685/750]	BT 0.158 (1.155)	DT 0.025 (1.024)	loss nan (nan)	prob nan (nan)	GS 33.781 (33.781)	mem 42.463
Train: [17][690/750]	BT 0.065 (1.164)	DT 0.001 (1.033)	loss nan (nan)	prob nan (nan)	GS 32.969 (32.969)	mem 42.454
Train: [17][695/750]	BT 0.223 (1.157)	DT 0.002 (1.026)	loss nan (nan)	prob nan (nan)	GS 33.781 (33.781)	mem 42.522
Train: [17][700/750]	BT 0.120 (1.169)	DT 0.002 (1.038)	loss nan (nan)	prob nan (nan)	GS 28.688 (28.688)	mem 42.469
Train: [17][705/750]	BT 0.193 (1.162)	DT 0.038 (1.031)	loss nan (nan)	prob nan (nan)	GS 31.375 (31.375)	mem 42.471
Train: [17][710/750]	BT 12.570 (1.172)	DT 12.503 (1.041)	loss nan (nan)	prob nan (nan)	GS 35.250 (35.250)	mem 42.376
Train: [17][715/750]	BT 0.126 (1.165)	DT 0.001 (1.034)	loss nan (nan)	prob nan (nan)	GS 31.812 (31.812)	mem 42.416
Train: [17][720/750]	BT 0.166 (1.158)	DT 0.025 (1.027)	loss nan (nan)	prob nan (nan)	GS 30.938 (30.938)	mem 42.421
Train: [17][725/750]	BT 0.103 (1.167)	DT 0.002 (1.036)	loss nan (nan)	prob nan (nan)	GS 32.891 (32.891)	mem 42.317
Train: [17][730/750]	BT 0.163 (1.160)	DT 0.005 (1.029)	loss nan (nan)	prob nan (nan)	GS 33.766 (33.766)	mem 42.211
Train: [17][735/750]	BT 0.074 (1.162)	DT 0.001 (1.032)	loss nan (nan)	prob nan (nan)	GS 27.469 (27.469)	mem 38.980
Train: [17][740/750]	BT 0.597 (1.155)	DT 0.524 (1.025)	loss nan (nan)	prob nan (nan)	GS 32.438 (32.438)	mem 17.218
Train: [17][745/750]	BT 0.098 (1.148)	DT 0.005 (1.019)	loss nan (nan)	prob nan (nan)	GS 23.281 (23.281)	mem 16.084
Train: [17][750/750]	BT 0.088 (1.144)	DT 0.001 (1.014)	loss nan (nan)	prob nan (nan)	GS 39.781 (39.781)	mem 13.077
Train: [17][755/750]	BT 0.062 (1.137)	DT 0.001 (1.008)	loss nan (nan)	prob nan (nan)	GS 33.031 (33.031)	mem 10.110
epoch 17, total time 858.67
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [18][1/750]	BT 21.917 (21.917)	DT 21.771 (21.771)	loss nan (nan)	prob nan (nan)	GS 31.141 (31.141)	mem 41.700
Train: [18][5/750]	BT 0.159 (4.491)	DT 0.002 (4.358)	loss nan (nan)	prob nan (nan)	GS 30.547 (30.547)	mem 41.820
Train: [18][10/750]	BT 2.109 (2.528)	DT 2.005 (2.384)	loss nan (nan)	prob nan (nan)	GS 34.234 (34.234)	mem 41.712
Train: [18][15/750]	BT 0.154 (2.411)	DT 0.001 (2.276)	loss nan (nan)	prob nan (nan)	GS 32.734 (32.734)	mem 41.958
Train: [18][20/750]	BT 0.115 (1.844)	DT 0.015 (1.709)	loss nan (nan)	prob nan (nan)	GS 32.734 (32.734)	mem 41.955
Train: [18][25/750]	BT 0.186 (1.738)	DT 0.003 (1.605)	loss nan (nan)	prob nan (nan)	GS 30.719 (30.719)	mem 41.985
Train: [18][30/750]	BT 4.158 (1.808)	DT 4.026 (1.667)	loss nan (nan)	prob nan (nan)	GS 40.359 (40.359)	mem 42.079
Train: [18][35/750]	BT 0.157 (1.640)	DT 0.002 (1.503)	loss nan (nan)	prob nan (nan)	GS 28.625 (28.625)	mem 41.998
Train: [18][40/750]	BT 0.222 (1.592)	DT 0.012 (1.456)	loss nan (nan)	prob nan (nan)	GS 32.219 (32.219)	mem 42.010
Train: [18][45/750]	BT 0.102 (1.582)	DT 0.013 (1.446)	loss nan (nan)	prob nan (nan)	GS 32.016 (32.016)	mem 42.065
Train: [18][50/750]	BT 4.663 (1.527)	DT 4.594 (1.393)	loss nan (nan)	prob nan (nan)	GS 30.672 (30.672)	mem 42.121
Train: [18][55/750]	BT 0.218 (1.527)	DT 0.005 (1.389)	loss nan (nan)	prob nan (nan)	GS 32.875 (32.875)	mem 42.067
Train: [18][60/750]	BT 0.096 (1.410)	DT 0.002 (1.274)	loss nan (nan)	prob nan (nan)	GS 30.578 (30.578)	mem 42.076
Train: [18][65/750]	BT 0.167 (1.376)	DT 0.006 (1.238)	loss nan (nan)	prob nan (nan)	GS 32.609 (32.609)	mem 42.108
Train: [18][70/750]	BT 0.089 (1.384)	DT 0.001 (1.248)	loss nan (nan)	prob nan (nan)	GS 30.500 (30.500)	mem 42.249
Train: [18][75/750]	BT 0.166 (1.354)	DT 0.001 (1.220)	loss nan (nan)	prob nan (nan)	GS 30.016 (30.016)	mem 42.255
Train: [18][80/750]	BT 0.125 (1.334)	DT 0.016 (1.200)	loss nan (nan)	prob nan (nan)	GS 35.906 (35.906)	mem 42.178
Train: [18][85/750]	BT 0.175 (1.273)	DT 0.002 (1.138)	loss nan (nan)	prob nan (nan)	GS 30.125 (30.125)	mem 42.192
Train: [18][90/750]	BT 9.425 (1.374)	DT 9.329 (1.239)	loss nan (nan)	prob nan (nan)	GS 38.000 (38.000)	mem 42.182
Train: [18][95/750]	BT 0.284 (1.309)	DT 0.016 (1.175)	loss nan (nan)	prob nan (nan)	GS 32.656 (32.656)	mem 42.549
Train: [18][100/750]	BT 0.118 (1.317)	DT 0.002 (1.183)	loss nan (nan)	prob nan (nan)	GS 35.766 (35.766)	mem 42.188
Train: [18][105/750]	BT 0.073 (1.329)	DT 0.002 (1.196)	loss nan (nan)	prob nan (nan)	GS 30.750 (30.750)	mem 42.094
Train: [18][110/750]	BT 5.492 (1.323)	DT 5.404 (1.191)	loss nan (nan)	prob nan (nan)	GS 33.500 (33.500)	mem 42.272
Train: [18][115/750]	BT 0.220 (1.359)	DT 0.016 (1.226)	loss nan (nan)	prob nan (nan)	GS 34.969 (34.969)	mem 42.592
Train: [18][120/750]	BT 0.127 (1.307)	DT 0.001 (1.175)	loss nan (nan)	prob nan (nan)	GS 33.516 (33.516)	mem 42.305
Train: [18][125/750]	BT 0.090 (1.264)	DT 0.002 (1.132)	loss nan (nan)	prob nan (nan)	GS 30.906 (30.906)	mem 42.225
Train: [18][130/750]	BT 0.126 (1.315)	DT 0.001 (1.184)	loss nan (nan)	prob nan (nan)	GS 35.766 (35.766)	mem 42.387
Train: [18][135/750]	BT 0.232 (1.272)	DT 0.005 (1.140)	loss nan (nan)	prob nan (nan)	GS 31.297 (31.297)	mem 42.464
Train: [18][140/750]	BT 0.128 (1.301)	DT 0.002 (1.170)	loss nan (nan)	prob nan (nan)	GS 35.859 (35.859)	mem 42.505
Train: [18][145/750]	BT 0.120 (1.264)	DT 0.008 (1.130)	loss nan (nan)	prob nan (nan)	GS 32.844 (32.844)	mem 42.626
Train: [18][150/750]	BT 3.852 (1.300)	DT 3.747 (1.167)	loss nan (nan)	prob nan (nan)	GS 36.188 (36.188)	mem 42.383
Train: [18][155/750]	BT 0.128 (1.262)	DT 0.020 (1.129)	loss nan (nan)	prob nan (nan)	GS 33.531 (33.531)	mem 42.490
Train: [18][160/750]	BT 0.159 (1.280)	DT 0.002 (1.146)	loss nan (nan)	prob nan (nan)	GS 37.391 (37.391)	mem 42.403
Train: [18][165/750]	BT 0.105 (1.262)	DT 0.001 (1.129)	loss nan (nan)	prob nan (nan)	GS 31.531 (31.531)	mem 42.477
Train: [18][170/750]	BT 13.493 (1.308)	DT 13.397 (1.175)	loss nan (nan)	prob nan (nan)	GS 37.141 (37.141)	mem 42.486
Train: [18][175/750]	BT 0.225 (1.275)	DT 0.005 (1.142)	loss nan (nan)	prob nan (nan)	GS 34.125 (34.125)	mem 42.487
Train: [18][180/750]	BT 0.145 (1.243)	DT 0.002 (1.110)	loss nan (nan)	prob nan (nan)	GS 33.188 (33.188)	mem 42.603
Train: [18][185/750]	BT 0.107 (1.269)	DT 0.002 (1.136)	loss nan (nan)	prob nan (nan)	GS 38.531 (38.531)	mem 42.488
Train: [18][190/750]	BT 0.159 (1.247)	DT 0.002 (1.114)	loss nan (nan)	prob nan (nan)	GS 32.516 (32.516)	mem 42.618
Train: [18][195/750]	BT 0.100 (1.277)	DT 0.004 (1.144)	loss nan (nan)	prob nan (nan)	GS 29.891 (29.891)	mem 42.377
Train: [18][200/750]	BT 0.157 (1.248)	DT 0.002 (1.116)	loss nan (nan)	prob nan (nan)	GS 34.594 (34.594)	mem 42.377
Train: [18][205/750]	BT 0.152 (1.221)	DT 0.009 (1.089)	loss nan (nan)	prob nan (nan)	GS 37.000 (37.000)	mem 42.378
Train: [18][210/750]	BT 0.119 (1.266)	DT 0.001 (1.133)	loss nan (nan)	prob nan (nan)	GS 37.406 (37.406)	mem 42.354
Train: [18][215/750]	BT 0.199 (1.239)	DT 0.002 (1.107)	loss nan (nan)	prob nan (nan)	GS 31.109 (31.109)	mem 42.358
Train: [18][220/750]	BT 0.131 (1.267)	DT 0.004 (1.136)	loss nan (nan)	prob nan (nan)	GS 31.188 (31.188)	mem 42.399
Train: [18][225/750]	BT 0.067 (1.242)	DT 0.002 (1.111)	loss nan (nan)	prob nan (nan)	GS 32.781 (32.781)	mem 42.429
Train: [18][230/750]	BT 10.844 (1.265)	DT 10.705 (1.134)	loss nan (nan)	prob nan (nan)	GS 32.719 (32.719)	mem 42.723
Train: [18][235/750]	BT 0.090 (1.241)	DT 0.003 (1.110)	loss nan (nan)	prob nan (nan)	GS 28.578 (28.578)	mem 42.454
Train: [18][240/750]	BT 0.207 (1.218)	DT 0.002 (1.086)	loss nan (nan)	prob nan (nan)	GS 34.344 (34.344)	mem 42.456
Train: [18][245/750]	BT 0.081 (1.246)	DT 0.001 (1.115)	loss nan (nan)	prob nan (nan)	GS 29.719 (29.719)	mem 42.302
Train: [18][250/750]	BT 0.081 (1.224)	DT 0.002 (1.093)	loss nan (nan)	prob nan (nan)	GS 38.516 (38.516)	mem 42.325
Train: [18][255/750]	BT 0.191 (1.249)	DT 0.001 (1.118)	loss nan (nan)	prob nan (nan)	GS 31.375 (31.375)	mem 42.420
Train: [18][260/750]	BT 0.277 (1.228)	DT 0.015 (1.097)	loss nan (nan)	prob nan (nan)	GS 34.891 (34.891)	mem 42.391
Train: [18][265/750]	BT 0.152 (1.207)	DT 0.017 (1.076)	loss nan (nan)	prob nan (nan)	GS 29.453 (29.453)	mem 42.402
Train: [18][270/750]	BT 0.094 (1.229)	DT 0.001 (1.098)	loss nan (nan)	prob nan (nan)	GS 35.906 (35.906)	mem 42.592
Train: [18][275/750]	BT 0.219 (1.209)	DT 0.004 (1.078)	loss nan (nan)	prob nan (nan)	GS 31.469 (31.469)	mem 42.537
Train: [18][280/750]	BT 0.085 (1.227)	DT 0.002 (1.096)	loss nan (nan)	prob nan (nan)	GS 32.719 (32.719)	mem 42.397
Train: [18][285/750]	BT 0.145 (1.208)	DT 0.016 (1.077)	loss nan (nan)	prob nan (nan)	GS 31.938 (31.938)	mem 42.356
Train: [18][290/750]	BT 6.413 (1.226)	DT 6.336 (1.095)	loss nan (nan)	prob nan (nan)	GS 31.297 (31.297)	mem 42.500
Train: [18][295/750]	BT 0.082 (1.207)	DT 0.002 (1.077)	loss nan (nan)	prob nan (nan)	GS 31.547 (31.547)	mem 42.440
Train: [18][300/750]	BT 0.128 (1.215)	DT 0.002 (1.084)	loss nan (nan)	prob nan (nan)	GS 33.969 (33.969)	mem 42.456
Train: [18][305/750]	BT 0.089 (1.204)	DT 0.002 (1.073)	loss nan (nan)	prob nan (nan)	GS 30.094 (30.094)	mem 42.378
Train: [18][310/750]	BT 0.142 (1.213)	DT 0.003 (1.082)	loss nan (nan)	prob nan (nan)	GS 35.469 (35.469)	mem 42.514
Train: [18][315/750]	BT 0.131 (1.210)	DT 0.004 (1.079)	loss nan (nan)	prob nan (nan)	GS 26.156 (26.156)	mem 42.538
Train: [18][320/750]	BT 10.430 (1.224)	DT 10.344 (1.095)	loss nan (nan)	prob nan (nan)	GS 34.250 (34.250)	mem 42.408
Train: [18][325/750]	BT 0.113 (1.207)	DT 0.001 (1.078)	loss nan (nan)	prob nan (nan)	GS 27.688 (27.688)	mem 42.435
Train: [18][330/750]	BT 0.185 (1.192)	DT 0.010 (1.063)	loss nan (nan)	prob nan (nan)	GS 33.219 (33.219)	mem 42.503
Train: [18][335/750]	BT 0.098 (1.206)	DT 0.004 (1.077)	loss nan (nan)	prob nan (nan)	GS 29.594 (29.594)	mem 42.297
Train: [18][340/750]	BT 0.948 (1.192)	DT 0.833 (1.064)	loss nan (nan)	prob nan (nan)	GS 31.844 (31.844)	mem 42.326
Train: [18][345/750]	BT 0.155 (1.204)	DT 0.001 (1.076)	loss nan (nan)	prob nan (nan)	GS 32.000 (32.000)	mem 42.393
Train: [18][350/750]	BT 0.102 (1.197)	DT 0.001 (1.068)	loss nan (nan)	prob nan (nan)	GS 31.141 (31.141)	mem 42.447
Train: [18][355/750]	BT 0.110 (1.182)	DT 0.008 (1.053)	loss nan (nan)	prob nan (nan)	GS 30.625 (30.625)	mem 42.380
Train: [18][360/750]	BT 0.756 (1.198)	DT 0.660 (1.069)	loss nan (nan)	prob nan (nan)	GS 31.234 (31.234)	mem 42.444
Train: [18][365/750]	BT 0.129 (1.188)	DT 0.006 (1.059)	loss nan (nan)	prob nan (nan)	GS 34.844 (34.844)	mem 42.432
Train: [18][370/750]	BT 0.149 (1.201)	DT 0.010 (1.072)	loss nan (nan)	prob nan (nan)	GS 33.344 (33.344)	mem 42.610
Train: [18][375/750]	BT 0.157 (1.187)	DT 0.002 (1.057)	loss nan (nan)	prob nan (nan)	GS 32.469 (32.469)	mem 42.467
Train: [18][380/750]	BT 6.671 (1.201)	DT 6.474 (1.071)	loss nan (nan)	prob nan (nan)	GS 27.531 (27.531)	mem 42.437
Train: [18][385/750]	BT 0.094 (1.188)	DT 0.001 (1.057)	loss nan (nan)	prob nan (nan)	GS 28.703 (28.703)	mem 42.500
Train: [18][390/750]	BT 2.753 (1.194)	DT 2.664 (1.063)	loss nan (nan)	prob nan (nan)	GS 34.688 (34.688)	mem 42.383
Train: [18][395/750]	BT 0.151 (1.188)	DT 0.009 (1.058)	loss nan (nan)	prob nan (nan)	GS 31.609 (31.609)	mem 42.421
Train: [18][400/750]	BT 4.649 (1.190)	DT 4.528 (1.060)	loss nan (nan)	prob nan (nan)	GS 32.094 (32.094)	mem 42.475
Train: [18][405/750]	BT 0.184 (1.187)	DT 0.002 (1.057)	loss nan (nan)	prob nan (nan)	GS 30.250 (30.250)	mem 42.372
Train: [18][410/750]	BT 0.233 (1.182)	DT 0.008 (1.052)	loss nan (nan)	prob nan (nan)	GS 33.125 (33.125)	mem 42.364
Train: [18][415/750]	BT 0.127 (1.195)	DT 0.006 (1.064)	loss nan (nan)	prob nan (nan)	GS 29.375 (29.375)	mem 42.511
Train: [18][420/750]	BT 0.267 (1.182)	DT 0.017 (1.052)	loss nan (nan)	prob nan (nan)	GS 33.141 (33.141)	mem 42.493
Train: [18][425/750]	BT 0.104 (1.180)	DT 0.001 (1.049)	loss nan (nan)	prob nan (nan)	GS 30.500 (30.500)	mem 42.606
Train: [18][430/750]	BT 0.141 (1.187)	DT 0.001 (1.056)	loss nan (nan)	prob nan (nan)	GS 33.766 (33.766)	mem 42.457
Train: [18][435/750]	BT 0.112 (1.175)	DT 0.006 (1.044)	loss nan (nan)	prob nan (nan)	GS 36.031 (36.031)	mem 42.450
Train: [18][440/750]	BT 0.149 (1.186)	DT 0.002 (1.056)	loss nan (nan)	prob nan (nan)	GS 31.672 (31.672)	mem 42.482
Train: [18][445/750]	BT 0.144 (1.177)	DT 0.002 (1.047)	loss nan (nan)	prob nan (nan)	GS 30.719 (30.719)	mem 42.414
Train: [18][450/750]	BT 8.873 (1.193)	DT 8.791 (1.063)	loss nan (nan)	prob nan (nan)	GS 32.438 (32.438)	mem 42.361
Train: [18][455/750]	BT 0.106 (1.181)	DT 0.001 (1.051)	loss nan (nan)	prob nan (nan)	GS 30.672 (30.672)	mem 42.525
Train: [18][460/750]	BT 1.845 (1.174)	DT 1.567 (1.043)	loss nan (nan)	prob nan (nan)	GS 33.562 (33.562)	mem 42.405
Train: [18][465/750]	BT 0.109 (1.188)	DT 0.003 (1.057)	loss nan (nan)	prob nan (nan)	GS 27.875 (27.875)	mem 42.412
Train: [18][470/750]	BT 0.179 (1.177)	DT 0.009 (1.046)	loss nan (nan)	prob nan (nan)	GS 36.906 (36.906)	mem 42.629
Train: [18][475/750]	BT 0.182 (1.190)	DT 0.014 (1.059)	loss nan (nan)	prob nan (nan)	GS 31.094 (31.094)	mem 42.593
Train: [18][480/750]	BT 0.194 (1.179)	DT 0.002 (1.048)	loss nan (nan)	prob nan (nan)	GS 31.844 (31.844)	mem 42.460
Train: [18][485/750]	BT 0.174 (1.168)	DT 0.001 (1.038)	loss nan (nan)	prob nan (nan)	GS 36.141 (36.141)	mem 42.491
Train: [18][490/750]	BT 0.091 (1.178)	DT 0.011 (1.048)	loss nan (nan)	prob nan (nan)	GS 37.875 (37.875)	mem 42.473
Train: [18][495/750]	BT 0.138 (1.169)	DT 0.002 (1.038)	loss nan (nan)	prob nan (nan)	GS 30.703 (30.703)	mem 42.522
Train: [18][500/750]	BT 0.098 (1.185)	DT 0.002 (1.055)	loss nan (nan)	prob nan (nan)	GS 33.062 (33.062)	mem 42.453
Train: [18][505/750]	BT 0.088 (1.175)	DT 0.002 (1.044)	loss nan (nan)	prob nan (nan)	GS 32.578 (32.578)	mem 42.436
Train: [18][510/750]	BT 11.847 (1.188)	DT 11.698 (1.057)	loss nan (nan)	prob nan (nan)	GS 32.859 (32.859)	mem 42.457
Train: [18][515/750]	BT 0.132 (1.177)	DT 0.002 (1.047)	loss nan (nan)	prob nan (nan)	GS 36.516 (36.516)	mem 42.521
Train: [18][520/750]	BT 0.126 (1.167)	DT 0.001 (1.037)	loss nan (nan)	prob nan (nan)	GS 32.453 (32.453)	mem 42.578
Train: [18][525/750]	BT 0.096 (1.184)	DT 0.001 (1.054)	loss nan (nan)	prob nan (nan)	GS 34.641 (34.641)	mem 42.531
Train: [18][530/750]	BT 0.151 (1.174)	DT 0.014 (1.044)	loss nan (nan)	prob nan (nan)	GS 33.203 (33.203)	mem 42.485
Train: [18][535/750]	BT 0.092 (1.185)	DT 0.002 (1.055)	loss nan (nan)	prob nan (nan)	GS 28.484 (28.484)	mem 42.458
Train: [18][540/750]	BT 0.175 (1.175)	DT 0.041 (1.045)	loss nan (nan)	prob nan (nan)	GS 35.516 (35.516)	mem 42.423
Train: [18][545/750]	BT 0.161 (1.166)	DT 0.007 (1.036)	loss nan (nan)	prob nan (nan)	GS 29.750 (29.750)	mem 42.437
Train: [18][550/750]	BT 0.089 (1.179)	DT 0.001 (1.049)	loss nan (nan)	prob nan (nan)	GS 35.516 (35.516)	mem 42.367
Train: [18][555/750]	BT 0.185 (1.169)	DT 0.002 (1.039)	loss nan (nan)	prob nan (nan)	GS 33.391 (33.391)	mem 42.524
Train: [18][560/750]	BT 0.123 (1.180)	DT 0.001 (1.050)	loss nan (nan)	prob nan (nan)	GS 34.656 (34.656)	mem 42.451
Train: [18][565/750]	BT 0.098 (1.175)	DT 0.001 (1.045)	loss nan (nan)	prob nan (nan)	GS 28.328 (28.328)	mem 42.521
Train: [18][570/750]	BT 8.430 (1.181)	DT 8.252 (1.051)	loss nan (nan)	prob nan (nan)	GS 34.281 (34.281)	mem 42.495
Train: [18][575/750]	BT 0.148 (1.172)	DT 0.001 (1.042)	loss nan (nan)	prob nan (nan)	GS 28.562 (28.562)	mem 42.508
Train: [18][580/750]	BT 0.087 (1.172)	DT 0.002 (1.042)	loss nan (nan)	prob nan (nan)	GS 33.016 (33.016)	mem 42.358
Train: [18][585/750]	BT 0.174 (1.172)	DT 0.004 (1.043)	loss nan (nan)	prob nan (nan)	GS 33.016 (33.016)	mem 42.549
Train: [18][590/750]	BT 0.098 (1.179)	DT 0.001 (1.049)	loss nan (nan)	prob nan (nan)	GS 35.797 (35.797)	mem 42.448
Train: [18][595/750]	BT 0.103 (1.172)	DT 0.011 (1.043)	loss nan (nan)	prob nan (nan)	GS 32.500 (32.500)	mem 42.938
Train: [18][600/750]	BT 13.651 (1.186)	DT 13.538 (1.056)	loss nan (nan)	prob nan (nan)	GS 40.141 (40.141)	mem 42.438
Train: [18][605/750]	BT 0.206 (1.177)	DT 0.016 (1.048)	loss nan (nan)	prob nan (nan)	GS 40.156 (40.156)	mem 42.482
Train: [18][610/750]	BT 0.096 (1.169)	DT 0.002 (1.039)	loss nan (nan)	prob nan (nan)	GS 32.828 (32.828)	mem 42.520
Train: [18][615/750]	BT 0.181 (1.179)	DT 0.001 (1.049)	loss nan (nan)	prob nan (nan)	GS 31.062 (31.062)	mem 42.563
Train: [18][620/750]	BT 0.129 (1.170)	DT 0.013 (1.041)	loss nan (nan)	prob nan (nan)	GS 27.297 (27.297)	mem 42.430
Train: [18][625/750]	BT 0.095 (1.182)	DT 0.009 (1.053)	loss nan (nan)	prob nan (nan)	GS 32.000 (32.000)	mem 42.483
Train: [18][630/750]	BT 0.083 (1.174)	DT 0.001 (1.044)	loss nan (nan)	prob nan (nan)	GS 34.250 (34.250)	mem 42.547
Train: [18][635/750]	BT 0.164 (1.165)	DT 0.028 (1.036)	loss nan (nan)	prob nan (nan)	GS 30.297 (30.297)	mem 42.560
Train: [18][640/750]	BT 0.102 (1.179)	DT 0.006 (1.050)	loss nan (nan)	prob nan (nan)	GS 28.719 (28.719)	mem 42.463
Train: [18][645/750]	BT 0.106 (1.171)	DT 0.002 (1.042)	loss nan (nan)	prob nan (nan)	GS 29.016 (29.016)	mem 42.465
Train: [18][650/750]	BT 0.090 (1.180)	DT 0.001 (1.051)	loss nan (nan)	prob nan (nan)	GS 30.562 (30.562)	mem 42.521
Train: [18][655/750]	BT 0.107 (1.173)	DT 0.002 (1.045)	loss nan (nan)	prob nan (nan)	GS 30.281 (30.281)	mem 42.494
Train: [18][660/750]	BT 13.557 (1.186)	DT 13.461 (1.057)	loss nan (nan)	prob nan (nan)	GS 36.219 (36.219)	mem 42.395
Train: [18][665/750]	BT 0.129 (1.178)	DT 0.002 (1.049)	loss nan (nan)	prob nan (nan)	GS 27.234 (27.234)	mem 42.424
Train: [18][670/750]	BT 0.183 (1.170)	DT 0.010 (1.042)	loss nan (nan)	prob nan (nan)	GS 35.656 (35.656)	mem 42.525
Train: [18][675/750]	BT 0.071 (1.182)	DT 0.001 (1.054)	loss nan (nan)	prob nan (nan)	GS 28.328 (28.328)	mem 42.452
Train: [18][680/750]	BT 0.088 (1.174)	DT 0.002 (1.046)	loss nan (nan)	prob nan (nan)	GS 33.719 (33.719)	mem 42.503
Train: [18][685/750]	BT 0.088 (1.183)	DT 0.002 (1.055)	loss nan (nan)	prob nan (nan)	GS 30.266 (30.266)	mem 42.539
Train: [18][690/750]	BT 0.187 (1.175)	DT 0.007 (1.047)	loss nan (nan)	prob nan (nan)	GS 32.172 (32.172)	mem 42.542
Train: [18][695/750]	BT 0.143 (1.168)	DT 0.003 (1.040)	loss nan (nan)	prob nan (nan)	GS 33.828 (33.828)	mem 42.545
Train: [18][700/750]	BT 0.089 (1.179)	DT 0.001 (1.051)	loss nan (nan)	prob nan (nan)	GS 34.516 (34.516)	mem 42.468
Train: [18][705/750]	BT 0.221 (1.172)	DT 0.002 (1.044)	loss nan (nan)	prob nan (nan)	GS 28.000 (28.000)	mem 42.471
arpack error, retry= 0
Train: [18][710/750]	BT 0.155 (1.185)	DT 0.001 (1.057)	loss nan (nan)	prob nan (nan)	GS 30.250 (30.250)	mem 42.551
Train: [18][715/750]	BT 0.096 (1.178)	DT 0.007 (1.050)	loss nan (nan)	prob nan (nan)	GS 34.938 (34.938)	mem 42.507
Train: [18][720/750]	BT 12.506 (1.188)	DT 12.382 (1.060)	loss nan (nan)	prob nan (nan)	GS 33.828 (33.828)	mem 42.448
Train: [18][725/750]	BT 0.221 (1.180)	DT 0.010 (1.053)	loss nan (nan)	prob nan (nan)	GS 32.484 (32.484)	mem 42.488
Train: [18][730/750]	BT 0.084 (1.173)	DT 0.002 (1.045)	loss nan (nan)	prob nan (nan)	GS 38.328 (38.328)	mem 42.535
Train: [18][735/750]	BT 0.054 (1.177)	DT 0.001 (1.050)	loss nan (nan)	prob nan (nan)	GS 30.656 (30.656)	mem 41.755
Train: [18][740/750]	BT 0.079 (1.170)	DT 0.002 (1.043)	loss nan (nan)	prob nan (nan)	GS 31.812 (31.812)	mem 41.794
Train: [18][745/750]	BT 0.061 (1.167)	DT 0.001 (1.041)	loss nan (nan)	prob nan (nan)	GS 33.719 (33.719)	mem 10.155
Train: [18][750/750]	BT 0.065 (1.160)	DT 0.001 (1.034)	loss nan (nan)	prob nan (nan)	GS 28.719 (28.719)	mem 10.159
Train: [18][755/750]	BT 0.103 (1.153)	DT 0.001 (1.027)	loss nan (nan)	prob nan (nan)	GS 33.188 (33.188)	mem 10.161
epoch 18, total time 872.64
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [19][1/750]	BT 20.047 (20.047)	DT 19.894 (19.894)	loss nan (nan)	prob nan (nan)	GS 30.516 (30.516)	mem 41.017
Train: [19][5/750]	BT 0.123 (5.331)	DT 0.002 (5.191)	loss nan (nan)	prob nan (nan)	GS 35.062 (35.062)	mem 41.203
Train: [19][10/750]	BT 0.082 (2.735)	DT 0.001 (2.598)	loss nan (nan)	prob nan (nan)	GS 37.188 (37.188)	mem 41.193
Train: [19][15/750]	BT 0.114 (2.395)	DT 0.002 (2.246)	loss nan (nan)	prob nan (nan)	GS 33.703 (33.703)	mem 41.346
Train: [19][20/750]	BT 0.125 (2.007)	DT 0.002 (1.862)	loss nan (nan)	prob nan (nan)	GS 30.031 (30.031)	mem 41.332
Train: [19][25/750]	BT 4.791 (1.815)	DT 4.613 (1.674)	loss nan (nan)	prob nan (nan)	GS 33.016 (33.016)	mem 41.408
Train: [19][30/750]	BT 0.199 (1.726)	DT 0.079 (1.589)	loss nan (nan)	prob nan (nan)	GS 34.734 (34.734)	mem 41.353
Train: [19][35/750]	BT 0.087 (1.637)	DT 0.002 (1.501)	loss nan (nan)	prob nan (nan)	GS 30.531 (30.531)	mem 41.375
Train: [19][40/750]	BT 0.984 (1.617)	DT 0.840 (1.485)	loss nan (nan)	prob nan (nan)	GS 32.516 (32.516)	mem 41.589
Train: [19][45/750]	BT 0.158 (1.597)	DT 0.008 (1.465)	loss nan (nan)	prob nan (nan)	GS 33.906 (33.906)	mem 41.570
Train: [19][50/750]	BT 2.220 (1.494)	DT 2.004 (1.359)	loss nan (nan)	prob nan (nan)	GS 27.969 (27.969)	mem 41.551
Train: [19][55/750]	BT 0.139 (1.450)	DT 0.001 (1.318)	loss nan (nan)	prob nan (nan)	GS 30.047 (30.047)	mem 41.467
Train: [19][60/750]	BT 0.348 (1.428)	DT 0.017 (1.291)	loss nan (nan)	prob nan (nan)	GS 33.078 (33.078)	mem 41.510
Train: [19][65/750]	BT 0.100 (1.426)	DT 0.001 (1.288)	loss nan (nan)	prob nan (nan)	GS 33.344 (33.344)	mem 41.664
Train: [19][70/750]	BT 0.272 (1.408)	DT 0.025 (1.270)	loss nan (nan)	prob nan (nan)	GS 37.016 (37.016)	mem 41.526
Train: [19][75/750]	BT 0.116 (1.381)	DT 0.001 (1.241)	loss nan (nan)	prob nan (nan)	GS 30.609 (30.609)	mem 41.614
Train: [19][80/750]	BT 4.736 (1.421)	DT 4.610 (1.282)	loss nan (nan)	prob nan (nan)	GS 34.812 (34.812)	mem 41.596
Train: [19][85/750]	BT 0.112 (1.346)	DT 0.010 (1.207)	loss nan (nan)	prob nan (nan)	GS 31.844 (31.844)	mem 41.607
Train: [19][90/750]	BT 3.531 (1.373)	DT 3.365 (1.234)	loss nan (nan)	prob nan (nan)	GS 31.703 (31.703)	mem 41.575
Train: [19][95/750]	BT 0.145 (1.360)	DT 0.001 (1.223)	loss nan (nan)	prob nan (nan)	GS 40.453 (40.453)	mem 41.552
Train: [19][100/750]	BT 3.410 (1.337)	DT 3.300 (1.200)	loss nan (nan)	prob nan (nan)	GS 36.453 (36.453)	mem 41.656
Train: [19][105/750]	BT 0.084 (1.330)	DT 0.002 (1.194)	loss nan (nan)	prob nan (nan)	GS 25.719 (25.719)	mem 41.842
Train: [19][110/750]	BT 4.494 (1.313)	DT 4.357 (1.179)	loss nan (nan)	prob nan (nan)	GS 31.172 (31.172)	mem 41.665
Train: [19][115/750]	BT 0.163 (1.313)	DT 0.020 (1.177)	loss nan (nan)	prob nan (nan)	GS 34.312 (34.312)	mem 41.796
Train: [19][120/750]	BT 0.154 (1.264)	DT 0.002 (1.129)	loss nan (nan)	prob nan (nan)	GS 33.781 (33.781)	mem 41.735
Train: [19][125/750]	BT 0.230 (1.251)	DT 0.018 (1.114)	loss nan (nan)	prob nan (nan)	GS 33.625 (33.625)	mem 41.953
Train: [19][130/750]	BT 0.149 (1.288)	DT 0.003 (1.151)	loss nan (nan)	prob nan (nan)	GS 34.469 (34.469)	mem 41.879
Train: [19][135/750]	BT 0.107 (1.245)	DT 0.004 (1.109)	loss nan (nan)	prob nan (nan)	GS 32.188 (32.188)	mem 41.998
Train: [19][140/750]	BT 0.115 (1.278)	DT 0.002 (1.142)	loss nan (nan)	prob nan (nan)	GS 32.750 (32.750)	mem 42.039
Train: [19][145/750]	BT 0.088 (1.239)	DT 0.002 (1.103)	loss nan (nan)	prob nan (nan)	GS 30.375 (30.375)	mem 42.043
Train: [19][150/750]	BT 11.859 (1.280)	DT 11.757 (1.145)	loss nan (nan)	prob nan (nan)	GS 31.516 (31.516)	mem 42.229
Train: [19][155/750]	BT 0.090 (1.243)	DT 0.001 (1.109)	loss nan (nan)	prob nan (nan)	GS 30.125 (30.125)	mem 42.226
Train: [19][160/750]	BT 0.784 (1.213)	DT 0.578 (1.078)	loss nan (nan)	prob nan (nan)	GS 30.703 (30.703)	mem 42.206
Train: [19][165/750]	BT 0.151 (1.252)	DT 0.002 (1.117)	loss nan (nan)	prob nan (nan)	GS 29.422 (29.422)	mem 42.385
Train: [19][170/750]	BT 0.131 (1.219)	DT 0.017 (1.085)	loss nan (nan)	prob nan (nan)	GS 31.438 (31.438)	mem 42.247
Train: [19][175/750]	BT 0.166 (1.257)	DT 0.002 (1.123)	loss nan (nan)	prob nan (nan)	GS 24.953 (24.953)	mem 42.159
Train: [19][180/750]	BT 0.148 (1.226)	DT 0.005 (1.092)	loss nan (nan)	prob nan (nan)	GS 32.953 (32.953)	mem 42.141
Train: [19][185/750]	BT 0.115 (1.196)	DT 0.002 (1.062)	loss nan (nan)	prob nan (nan)	GS 32.453 (32.453)	mem 42.142
Train: [19][190/750]	BT 0.156 (1.217)	DT 0.012 (1.083)	loss nan (nan)	prob nan (nan)	GS 32.078 (32.078)	mem 42.209
Train: [19][195/750]	BT 0.247 (1.199)	DT 0.009 (1.065)	loss nan (nan)	prob nan (nan)	GS 33.844 (33.844)	mem 42.178
Train: [19][200/750]	BT 0.084 (1.215)	DT 0.004 (1.081)	loss nan (nan)	prob nan (nan)	GS 36.344 (36.344)	mem 42.260
Train: [19][205/750]	BT 0.102 (1.188)	DT 0.002 (1.055)	loss nan (nan)	prob nan (nan)	GS 29.797 (29.797)	mem 42.262
Train: [19][210/750]	BT 3.421 (1.216)	DT 3.295 (1.084)	loss nan (nan)	prob nan (nan)	GS 32.141 (32.141)	mem 42.253
Train: [19][215/750]	BT 0.128 (1.204)	DT 0.011 (1.071)	loss nan (nan)	prob nan (nan)	GS 30.875 (30.875)	mem 42.240
Train: [19][220/750]	BT 4.986 (1.205)	DT 4.780 (1.073)	loss nan (nan)	prob nan (nan)	GS 32.625 (32.625)	mem 42.387
Train: [19][225/750]	BT 0.170 (1.207)	DT 0.016 (1.074)	loss nan (nan)	prob nan (nan)	GS 33.562 (33.562)	mem 42.151
Train: [19][230/750]	BT 1.535 (1.189)	DT 1.422 (1.057)	loss nan (nan)	prob nan (nan)	GS 34.125 (34.125)	mem 42.199
Train: [19][235/750]	BT 0.161 (1.215)	DT 0.008 (1.082)	loss nan (nan)	prob nan (nan)	GS 31.406 (31.406)	mem 42.175
Train: [19][240/750]	BT 0.187 (1.192)	DT 0.001 (1.059)	loss nan (nan)	prob nan (nan)	GS 29.750 (29.750)	mem 42.320
Train: [19][245/750]	BT 0.188 (1.171)	DT 0.003 (1.039)	loss nan (nan)	prob nan (nan)	GS 35.438 (35.438)	mem 42.181
Train: [19][250/750]	BT 0.088 (1.196)	DT 0.002 (1.064)	loss nan (nan)	prob nan (nan)	GS 31.359 (31.359)	mem 42.309
Train: [19][255/750]	BT 0.080 (1.174)	DT 0.001 (1.043)	loss nan (nan)	prob nan (nan)	GS 31.906 (31.906)	mem 42.378
Train: [19][260/750]	BT 0.163 (1.200)	DT 0.006 (1.068)	loss nan (nan)	prob nan (nan)	GS 33.062 (33.062)	mem 42.300
Train: [19][265/750]	BT 0.076 (1.179)	DT 0.001 (1.048)	loss nan (nan)	prob nan (nan)	GS 34.312 (34.312)	mem 42.309
Train: [19][270/750]	BT 9.296 (1.203)	DT 9.155 (1.071)	loss nan (nan)	prob nan (nan)	GS 33.406 (33.406)	mem 42.243
Train: [19][275/750]	BT 0.115 (1.183)	DT 0.002 (1.052)	loss nan (nan)	prob nan (nan)	GS 30.203 (30.203)	mem 42.245
Train: [19][280/750]	BT 0.208 (1.165)	DT 0.045 (1.033)	loss nan (nan)	prob nan (nan)	GS 32.031 (32.031)	mem 42.248
Train: [19][285/750]	BT 0.176 (1.180)	DT 0.002 (1.049)	loss nan (nan)	prob nan (nan)	GS 31.469 (31.469)	mem 42.376
Train: [19][290/750]	BT 0.084 (1.161)	DT 0.001 (1.031)	loss nan (nan)	prob nan (nan)	GS 31.969 (31.969)	mem 42.347
Train: [19][295/750]	BT 0.081 (1.181)	DT 0.001 (1.050)	loss nan (nan)	prob nan (nan)	GS 35.469 (35.469)	mem 42.341
Train: [19][300/750]	BT 0.157 (1.164)	DT 0.002 (1.032)	loss nan (nan)	prob nan (nan)	GS 32.328 (32.328)	mem 42.346
Train: [19][305/750]	BT 0.110 (1.172)	DT 0.002 (1.041)	loss nan (nan)	prob nan (nan)	GS 33.938 (33.938)	mem 42.470
Train: [19][310/750]	BT 0.161 (1.162)	DT 0.064 (1.031)	loss nan (nan)	prob nan (nan)	GS 30.344 (30.344)	mem 42.542
Train: [19][315/750]	BT 0.298 (1.146)	DT 0.014 (1.015)	loss nan (nan)	prob nan (nan)	GS 31.062 (31.062)	mem 42.453
Train: [19][320/750]	BT 0.179 (1.160)	DT 0.012 (1.028)	loss nan (nan)	prob nan (nan)	GS 38.312 (38.312)	mem 42.333
Train: [19][325/750]	BT 0.117 (1.147)	DT 0.029 (1.016)	loss nan (nan)	prob nan (nan)	GS 34.109 (34.109)	mem 42.354
Train: [19][330/750]	BT 0.077 (1.165)	DT 0.004 (1.034)	loss nan (nan)	prob nan (nan)	GS 30.547 (30.547)	mem 42.553
Train: [19][335/750]	BT 0.152 (1.159)	DT 0.004 (1.028)	loss nan (nan)	prob nan (nan)	GS 29.172 (29.172)	mem 42.440
Train: [19][340/750]	BT 4.741 (1.159)	DT 4.650 (1.027)	loss nan (nan)	prob nan (nan)	GS 29.219 (29.219)	mem 42.552
Train: [19][345/750]	BT 0.209 (1.150)	DT 0.001 (1.018)	loss nan (nan)	prob nan (nan)	GS 32.656 (32.656)	mem 42.454
Train: [19][350/750]	BT 0.082 (1.148)	DT 0.001 (1.016)	loss nan (nan)	prob nan (nan)	GS 32.766 (32.766)	mem 42.444
Train: [19][355/750]	BT 0.088 (1.146)	DT 0.003 (1.015)	loss nan (nan)	prob nan (nan)	GS 26.391 (26.391)	mem 42.443
Train: [19][360/750]	BT 0.214 (1.153)	DT 0.004 (1.021)	loss nan (nan)	prob nan (nan)	GS 34.531 (34.531)	mem 42.661
Train: [19][365/750]	BT 0.143 (1.154)	DT 0.004 (1.022)	loss nan (nan)	prob nan (nan)	GS 31.719 (31.719)	mem 42.473
Train: [19][370/750]	BT 7.204 (1.160)	DT 7.038 (1.027)	loss nan (nan)	prob nan (nan)	GS 31.375 (31.375)	mem 42.411
Train: [19][375/750]	BT 0.267 (1.147)	DT 0.018 (1.013)	loss nan (nan)	prob nan (nan)	GS 28.453 (28.453)	mem 42.432
Train: [19][380/750]	BT 0.075 (1.144)	DT 0.001 (1.011)	loss nan (nan)	prob nan (nan)	GS 32.922 (32.922)	mem 42.479
Train: [19][385/750]	BT 0.189 (1.154)	DT 0.002 (1.021)	loss nan (nan)	prob nan (nan)	GS 31.922 (31.922)	mem 42.549
Train: [19][390/750]	BT 0.089 (1.143)	DT 0.002 (1.009)	loss nan (nan)	prob nan (nan)	GS 30.062 (30.062)	mem 42.423
Train: [19][395/750]	BT 0.098 (1.155)	DT 0.002 (1.021)	loss nan (nan)	prob nan (nan)	GS 29.984 (29.984)	mem 42.375
Train: [19][400/750]	BT 1.389 (1.145)	DT 1.301 (1.012)	loss nan (nan)	prob nan (nan)	GS 32.719 (32.719)	mem 42.442
Train: [19][405/750]	BT 0.245 (1.133)	DT 0.001 (0.999)	loss nan (nan)	prob nan (nan)	GS 35.734 (35.734)	mem 42.641
Train: [19][410/750]	BT 0.113 (1.143)	DT 0.015 (1.009)	loss nan (nan)	prob nan (nan)	GS 33.438 (33.438)	mem 42.465
Train: [19][415/750]	BT 0.176 (1.141)	DT 0.002 (1.007)	loss nan (nan)	prob nan (nan)	GS 31.234 (31.234)	mem 42.489
Train: [19][420/750]	BT 0.108 (1.152)	DT 0.002 (1.019)	loss nan (nan)	prob nan (nan)	GS 31.219 (31.219)	mem 42.508
Train: [19][425/750]	BT 0.128 (1.163)	DT 0.009 (1.029)	loss nan (nan)	prob nan (nan)	GS 32.953 (32.953)	mem 42.452
Train: [19][430/750]	BT 0.102 (1.151)	DT 0.008 (1.017)	loss nan (nan)	prob nan (nan)	GS 34.203 (34.203)	mem 42.510
Train: [19][435/750]	BT 0.293 (1.140)	DT 0.006 (1.006)	loss nan (nan)	prob nan (nan)	GS 29.609 (29.609)	mem 42.460
Train: [19][440/750]	BT 0.080 (1.157)	DT 0.002 (1.024)	loss nan (nan)	prob nan (nan)	GS 35.594 (35.594)	mem 42.396
Train: [19][445/750]	BT 0.117 (1.146)	DT 0.002 (1.012)	loss nan (nan)	prob nan (nan)	GS 30.672 (30.672)	mem 42.399
Train: [19][450/750]	BT 0.098 (1.162)	DT 0.001 (1.028)	loss nan (nan)	prob nan (nan)	GS 30.109 (30.109)	mem 42.441
Train: [19][455/750]	BT 0.116 (1.151)	DT 0.003 (1.017)	loss nan (nan)	prob nan (nan)	GS 31.391 (31.391)	mem 42.412
Train: [19][460/750]	BT 12.196 (1.166)	DT 12.102 (1.032)	loss nan (nan)	prob nan (nan)	GS 36.094 (36.094)	mem 42.342
Train: [19][465/750]	BT 0.077 (1.155)	DT 0.004 (1.021)	loss nan (nan)	prob nan (nan)	GS 35.906 (35.906)	mem 42.367
Train: [19][470/750]	BT 0.164 (1.144)	DT 0.006 (1.011)	loss nan (nan)	prob nan (nan)	GS 35.828 (35.828)	mem 42.355
Train: [19][475/750]	BT 0.143 (1.153)	DT 0.017 (1.020)	loss nan (nan)	prob nan (nan)	GS 31.188 (31.188)	mem 42.696
Train: [19][480/750]	BT 0.092 (1.142)	DT 0.002 (1.010)	loss nan (nan)	prob nan (nan)	GS 34.359 (34.359)	mem 42.697
Train: [19][485/750]	BT 0.187 (1.157)	DT 0.002 (1.024)	loss nan (nan)	prob nan (nan)	GS 28.922 (28.922)	mem 42.608
Train: [19][490/750]	BT 2.347 (1.151)	DT 2.246 (1.018)	loss nan (nan)	prob nan (nan)	GS 34.906 (34.906)	mem 42.446
Train: [19][495/750]	BT 0.162 (1.141)	DT 0.013 (1.008)	loss nan (nan)	prob nan (nan)	GS 35.031 (35.031)	mem 42.489
Train: [19][500/750]	BT 0.164 (1.154)	DT 0.002 (1.021)	loss nan (nan)	prob nan (nan)	GS 33.953 (33.953)	mem 42.543
Train: [19][505/750]	BT 0.097 (1.144)	DT 0.002 (1.011)	loss nan (nan)	prob nan (nan)	GS 34.656 (34.656)	mem 42.544
Train: [19][510/750]	BT 0.124 (1.157)	DT 0.002 (1.024)	loss nan (nan)	prob nan (nan)	GS 31.266 (31.266)	mem 42.545
Train: [19][515/750]	BT 0.160 (1.149)	DT 0.001 (1.017)	loss nan (nan)	prob nan (nan)	GS 31.312 (31.312)	mem 42.544
Train: [19][520/750]	BT 8.497 (1.155)	DT 8.344 (1.023)	loss nan (nan)	prob nan (nan)	GS 31.859 (31.859)	mem 42.616
Train: [19][525/750]	BT 0.181 (1.147)	DT 0.003 (1.015)	loss nan (nan)	prob nan (nan)	GS 27.766 (27.766)	mem 42.490
Train: [19][530/750]	BT 0.169 (1.139)	DT 0.011 (1.007)	loss nan (nan)	prob nan (nan)	GS 32.953 (32.953)	mem 42.449
Train: [19][535/750]	BT 0.124 (1.154)	DT 0.016 (1.021)	loss nan (nan)	prob nan (nan)	GS 31.219 (31.219)	mem 42.501
Train: [19][540/750]	BT 0.113 (1.144)	DT 0.002 (1.012)	loss nan (nan)	prob nan (nan)	GS 32.594 (32.594)	mem 42.471
Train: [19][545/750]	BT 0.082 (1.158)	DT 0.001 (1.025)	loss nan (nan)	prob nan (nan)	GS 28.047 (28.047)	mem 42.538
Train: [19][550/750]	BT 0.096 (1.148)	DT 0.002 (1.016)	loss nan (nan)	prob nan (nan)	GS 32.797 (32.797)	mem 42.537
Train: [19][555/750]	BT 0.083 (1.139)	DT 0.002 (1.007)	loss nan (nan)	prob nan (nan)	GS 31.422 (31.422)	mem 42.524
Train: [19][560/750]	BT 5.174 (1.159)	DT 5.055 (1.027)	loss nan (nan)	prob nan (nan)	GS 36.250 (36.250)	mem 42.486
Train: [19][565/750]	BT 0.078 (1.150)	DT 0.002 (1.018)	loss nan (nan)	prob nan (nan)	GS 34.906 (34.906)	mem 42.415
Train: [19][570/750]	BT 0.131 (1.147)	DT 0.001 (1.015)	loss nan (nan)	prob nan (nan)	GS 31.000 (31.000)	mem 42.535
Train: [19][575/750]	BT 0.167 (1.152)	DT 0.002 (1.020)	loss nan (nan)	prob nan (nan)	GS 29.469 (29.469)	mem 42.475
Train: [19][580/750]	BT 3.920 (1.149)	DT 3.803 (1.018)	loss nan (nan)	prob nan (nan)	GS 36.422 (36.422)	mem 42.561
Train: [19][585/750]	BT 0.171 (1.152)	DT 0.002 (1.020)	loss nan (nan)	prob nan (nan)	GS 25.281 (25.281)	mem 42.475
Train: [19][590/750]	BT 0.119 (1.143)	DT 0.006 (1.012)	loss nan (nan)	prob nan (nan)	GS 34.172 (34.172)	mem 42.494
Train: [19][595/750]	BT 0.088 (1.150)	DT 0.002 (1.018)	loss nan (nan)	prob nan (nan)	GS 32.203 (32.203)	mem 42.507
Train: [19][600/750]	BT 0.108 (1.142)	DT 0.001 (1.010)	loss nan (nan)	prob nan (nan)	GS 37.094 (37.094)	mem 42.519
Train: [19][605/750]	BT 0.123 (1.142)	DT 0.002 (1.010)	loss nan (nan)	prob nan (nan)	GS 31.016 (31.016)	mem 42.380
Train: [19][610/750]	BT 0.103 (1.147)	DT 0.001 (1.015)	loss nan (nan)	prob nan (nan)	GS 32.422 (32.422)	mem 42.709
Train: [19][615/750]	BT 0.210 (1.139)	DT 0.035 (1.007)	loss nan (nan)	prob nan (nan)	GS 31.922 (31.922)	mem 42.530
Train: [19][620/750]	BT 0.201 (1.154)	DT 0.004 (1.022)	loss nan (nan)	prob nan (nan)	GS 34.031 (34.031)	mem 42.479
Train: [19][625/750]	BT 0.084 (1.146)	DT 0.002 (1.014)	loss nan (nan)	prob nan (nan)	GS 33.766 (33.766)	mem 42.463
Train: [19][630/750]	BT 10.621 (1.156)	DT 10.442 (1.024)	loss nan (nan)	prob nan (nan)	GS 35.203 (35.203)	mem 42.465
Train: [19][635/750]	BT 0.087 (1.148)	DT 0.002 (1.016)	loss nan (nan)	prob nan (nan)	GS 29.391 (29.391)	mem 42.466
Train: [19][640/750]	BT 2.809 (1.144)	DT 2.659 (1.012)	loss nan (nan)	prob nan (nan)	GS 33.797 (33.797)	mem 42.414
Train: [19][645/750]	BT 0.067 (1.154)	DT 0.001 (1.022)	loss nan (nan)	prob nan (nan)	GS 31.219 (31.219)	mem 42.387
Train: [19][650/750]	BT 0.146 (1.146)	DT 0.005 (1.014)	loss nan (nan)	prob nan (nan)	GS 36.031 (36.031)	mem 42.389
Train: [19][655/750]	BT 0.172 (1.149)	DT 0.033 (1.018)	loss nan (nan)	prob nan (nan)	GS 28.328 (28.328)	mem 42.401
Train: [19][660/750]	BT 0.125 (1.148)	DT 0.014 (1.017)	loss nan (nan)	prob nan (nan)	GS 34.719 (34.719)	mem 42.294
Train: [19][665/750]	BT 0.218 (1.140)	DT 0.006 (1.009)	loss nan (nan)	prob nan (nan)	GS 28.531 (28.531)	mem 42.312
Train: [19][670/750]	BT 0.142 (1.146)	DT 0.001 (1.014)	loss nan (nan)	prob nan (nan)	GS 33.984 (33.984)	mem 42.464
Train: [19][675/750]	BT 0.162 (1.138)	DT 0.004 (1.007)	loss nan (nan)	prob nan (nan)	GS 30.875 (30.875)	mem 42.490
Train: [19][680/750]	BT 2.977 (1.147)	DT 2.829 (1.016)	loss nan (nan)	prob nan (nan)	GS 33.000 (33.000)	mem 42.379
Train: [19][685/750]	BT 0.184 (1.140)	DT 0.031 (1.009)	loss nan (nan)	prob nan (nan)	GS 26.797 (26.797)	mem 42.406
Train: [19][690/750]	BT 7.294 (1.144)	DT 7.159 (1.012)	loss nan (nan)	prob nan (nan)	GS 35.859 (35.859)	mem 42.450
Train: [19][695/750]	BT 0.087 (1.141)	DT 0.002 (1.010)	loss nan (nan)	prob nan (nan)	GS 29.188 (29.188)	mem 42.455
Train: [19][700/750]	BT 1.926 (1.136)	DT 1.818 (1.005)	loss nan (nan)	prob nan (nan)	GS 31.312 (31.312)	mem 42.525
Train: [19][705/750]	BT 0.090 (1.144)	DT 0.002 (1.012)	loss nan (nan)	prob nan (nan)	GS 28.266 (28.266)	mem 42.556
arpack error, retry= 0
Train: [19][710/750]	BT 0.128 (1.137)	DT 0.002 (1.005)	loss nan (nan)	prob nan (nan)	GS 33.078 (33.078)	mem 42.546
Train: [19][715/750]	BT 0.113 (1.143)	DT 0.002 (1.012)	loss nan (nan)	prob nan (nan)	GS 32.141 (32.141)	mem 42.412
Train: [19][720/750]	BT 0.144 (1.136)	DT 0.002 (1.005)	loss nan (nan)	prob nan (nan)	GS 32.453 (32.453)	mem 42.448
Train: [19][725/750]	BT 0.081 (1.136)	DT 0.002 (1.005)	loss nan (nan)	prob nan (nan)	GS 31.391 (31.391)	mem 42.191
Train: [19][730/750]	BT 0.114 (1.138)	DT 0.001 (1.007)	loss nan (nan)	prob nan (nan)	GS 35.625 (35.625)	mem 42.155
Train: [19][735/750]	BT 0.185 (1.131)	DT 0.002 (1.000)	loss nan (nan)	prob nan (nan)	GS 34.469 (34.469)	mem 42.155
Train: [19][740/750]	BT 0.099 (1.136)	DT 0.007 (1.005)	loss nan (nan)	prob nan (nan)	GS 33.328 (33.328)	mem 13.081
Train: [19][745/750]	BT 0.073 (1.129)	DT 0.001 (0.998)	loss nan (nan)	prob nan (nan)	GS 32.500 (32.500)	mem 13.045
Train: [19][750/750]	BT 2.707 (1.125)	DT 2.643 (0.995)	loss nan (nan)	prob nan (nan)	GS 36.750 (36.750)	mem 10.074
Train: [19][755/750]	BT 0.071 (1.118)	DT 0.001 (0.988)	loss nan (nan)	prob nan (nan)	GS 28.531 (28.531)	mem 10.075
epoch 19, total time 844.42
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [20][1/750]	BT 21.559 (21.559)	DT 21.408 (21.408)	loss nan (nan)	prob nan (nan)	GS 27.312 (27.312)	mem 41.131
Train: [20][5/750]	BT 0.138 (4.714)	DT 0.002 (4.592)	loss nan (nan)	prob nan (nan)	GS 29.531 (29.531)	mem 41.141
Train: [20][10/750]	BT 0.083 (2.550)	DT 0.005 (2.420)	loss nan (nan)	prob nan (nan)	GS 35.766 (35.766)	mem 41.069
Train: [20][15/750]	BT 0.108 (2.328)	DT 0.002 (2.197)	loss nan (nan)	prob nan (nan)	GS 27.125 (27.125)	mem 41.319
Train: [20][20/750]	BT 0.199 (2.029)	DT 0.001 (1.890)	loss nan (nan)	prob nan (nan)	GS 29.656 (29.656)	mem 41.404
Train: [20][25/750]	BT 2.401 (1.742)	DT 2.216 (1.601)	loss nan (nan)	prob nan (nan)	GS 35.438 (35.438)	mem 41.458
Train: [20][30/750]	BT 0.272 (1.795)	DT 0.017 (1.651)	loss nan (nan)	prob nan (nan)	GS 32.359 (32.359)	mem 41.377
Train: [20][35/750]	BT 0.166 (1.558)	DT 0.002 (1.416)	loss nan (nan)	prob nan (nan)	GS 32.875 (32.875)	mem 41.386
Train: [20][40/750]	BT 0.167 (1.711)	DT 0.001 (1.568)	loss nan (nan)	prob nan (nan)	GS 35.281 (35.281)	mem 41.957
Train: [20][45/750]	BT 0.108 (1.559)	DT 0.002 (1.417)	loss nan (nan)	prob nan (nan)	GS 32.594 (32.594)	mem 41.926
Train: [20][50/750]	BT 8.584 (1.586)	DT 8.415 (1.444)	loss nan (nan)	prob nan (nan)	GS 29.531 (29.531)	mem 42.098
Train: [20][55/750]	BT 0.111 (1.491)	DT 0.009 (1.346)	loss nan (nan)	prob nan (nan)	GS 31.109 (31.109)	mem 42.041
Train: [20][60/750]	BT 0.217 (1.381)	DT 0.123 (1.236)	loss nan (nan)	prob nan (nan)	GS 34.391 (34.391)	mem 42.042
Train: [20][65/750]	BT 0.128 (1.478)	DT 0.001 (1.332)	loss nan (nan)	prob nan (nan)	GS 31.281 (31.281)	mem 42.093
Train: [20][70/750]	BT 0.097 (1.385)	DT 0.003 (1.238)	loss nan (nan)	prob nan (nan)	GS 38.562 (38.562)	mem 42.094
Train: [20][75/750]	BT 0.115 (1.446)	DT 0.007 (1.298)	loss nan (nan)	prob nan (nan)	GS 31.906 (31.906)	mem 42.049
Train: [20][80/750]	BT 0.106 (1.388)	DT 0.007 (1.241)	loss nan (nan)	prob nan (nan)	GS 32.375 (32.375)	mem 42.075
Train: [20][85/750]	BT 0.085 (1.313)	DT 0.002 (1.168)	loss nan (nan)	prob nan (nan)	GS 33.906 (33.906)	mem 42.114
Train: [20][90/750]	BT 3.234 (1.353)	DT 3.145 (1.210)	loss nan (nan)	prob nan (nan)	GS 30.406 (30.406)	mem 42.271
Train: [20][95/750]	BT 0.086 (1.287)	DT 0.002 (1.146)	loss nan (nan)	prob nan (nan)	GS 33.500 (33.500)	mem 42.095
Train: [20][100/750]	BT 0.075 (1.333)	DT 0.001 (1.195)	loss nan (nan)	prob nan (nan)	GS 31.156 (31.156)	mem 42.195
Train: [20][105/750]	BT 0.206 (1.302)	DT 0.004 (1.163)	loss nan (nan)	prob nan (nan)	GS 43.688 (43.688)	mem 42.184
Train: [20][110/750]	BT 7.898 (1.358)	DT 7.811 (1.219)	loss nan (nan)	prob nan (nan)	GS 38.000 (38.000)	mem 42.178
Train: [20][115/750]	BT 0.135 (1.308)	DT 0.005 (1.168)	loss nan (nan)	prob nan (nan)	GS 27.797 (27.797)	mem 42.135
Train: [20][120/750]	BT 0.343 (1.261)	DT 0.210 (1.121)	loss nan (nan)	prob nan (nan)	GS 33.422 (33.422)	mem 42.134
Train: [20][125/750]	BT 0.098 (1.294)	DT 0.009 (1.154)	loss nan (nan)	prob nan (nan)	GS 32.234 (32.234)	mem 42.141
Train: [20][130/750]	BT 0.151 (1.249)	DT 0.011 (1.110)	loss nan (nan)	prob nan (nan)	GS 34.156 (34.156)	mem 42.142
Train: [20][135/750]	BT 0.161 (1.303)	DT 0.002 (1.163)	loss nan (nan)	prob nan (nan)	GS 32.156 (32.156)	mem 42.257
Train: [20][140/750]	BT 0.173 (1.262)	DT 0.006 (1.122)	loss nan (nan)	prob nan (nan)	GS 35.969 (35.969)	mem 42.259
Train: [20][145/750]	BT 0.076 (1.241)	DT 0.001 (1.101)	loss nan (nan)	prob nan (nan)	GS 29.781 (29.781)	mem 42.316
Train: [20][150/750]	BT 0.133 (1.253)	DT 0.041 (1.114)	loss nan (nan)	prob nan (nan)	GS 33.062 (33.062)	mem 42.325
Train: [20][155/750]	BT 0.124 (1.218)	DT 0.002 (1.078)	loss nan (nan)	prob nan (nan)	GS 31.594 (31.594)	mem 42.413
Train: [20][160/750]	BT 0.093 (1.267)	DT 0.002 (1.128)	loss nan (nan)	prob nan (nan)	GS 29.531 (29.531)	mem 42.344
Train: [20][165/750]	BT 0.153 (1.233)	DT 0.002 (1.094)	loss nan (nan)	prob nan (nan)	GS 32.797 (32.797)	mem 42.347
Train: [20][170/750]	BT 2.207 (1.262)	DT 2.120 (1.124)	loss nan (nan)	prob nan (nan)	GS 28.891 (28.891)	mem 42.479
Train: [20][175/750]	BT 0.131 (1.229)	DT 0.002 (1.092)	loss nan (nan)	prob nan (nan)	GS 31.500 (31.500)	mem 42.340
Train: [20][180/750]	BT 11.055 (1.260)	DT 10.873 (1.122)	loss nan (nan)	prob nan (nan)	GS 32.578 (32.578)	mem 42.411
Train: [20][185/750]	BT 0.090 (1.243)	DT 0.002 (1.105)	loss nan (nan)	prob nan (nan)	GS 29.609 (29.609)	mem 42.360
Train: [20][190/750]	BT 0.216 (1.213)	DT 0.002 (1.076)	loss nan (nan)	prob nan (nan)	GS 33.562 (33.562)	mem 42.445
Train: [20][195/750]	BT 0.126 (1.239)	DT 0.002 (1.101)	loss nan (nan)	prob nan (nan)	GS 34.062 (34.062)	mem 42.505
Train: [20][200/750]	BT 0.128 (1.212)	DT 0.026 (1.075)	loss nan (nan)	prob nan (nan)	GS 34.500 (34.500)	mem 42.399
Train: [20][205/750]	BT 0.075 (1.249)	DT 0.002 (1.112)	loss nan (nan)	prob nan (nan)	GS 33.219 (33.219)	mem 42.343
Train: [20][210/750]	BT 0.123 (1.222)	DT 0.024 (1.085)	loss nan (nan)	prob nan (nan)	GS 37.078 (37.078)	mem 42.561
Train: [20][215/750]	BT 0.242 (1.198)	DT 0.002 (1.060)	loss nan (nan)	prob nan (nan)	GS 27.125 (27.125)	mem 42.374
Train: [20][220/750]	BT 0.082 (1.223)	DT 0.001 (1.086)	loss nan (nan)	prob nan (nan)	GS 40.531 (40.531)	mem 42.451
Train: [20][225/750]	BT 0.131 (1.199)	DT 0.004 (1.062)	loss nan (nan)	prob nan (nan)	GS 28.562 (28.562)	mem 42.522
Train: [20][230/750]	BT 0.077 (1.225)	DT 0.001 (1.089)	loss nan (nan)	prob nan (nan)	GS 32.859 (32.859)	mem 42.429
Train: [20][235/750]	BT 0.162 (1.202)	DT 0.002 (1.066)	loss nan (nan)	prob nan (nan)	GS 28.562 (28.562)	mem 42.430
Train: [20][240/750]	BT 9.994 (1.221)	DT 9.790 (1.085)	loss nan (nan)	prob nan (nan)	GS 33.500 (33.500)	mem 42.689
Train: [20][245/750]	BT 0.091 (1.201)	DT 0.002 (1.065)	loss nan (nan)	prob nan (nan)	GS 31.609 (31.609)	mem 42.433
Train: [20][250/750]	BT 0.137 (1.194)	DT 0.008 (1.059)	loss nan (nan)	prob nan (nan)	GS 35.594 (35.594)	mem 42.432
Train: [20][255/750]	BT 0.086 (1.203)	DT 0.002 (1.068)	loss nan (nan)	prob nan (nan)	GS 33.016 (33.016)	mem 42.489
Train: [20][260/750]	BT 0.160 (1.215)	DT 0.009 (1.080)	loss nan (nan)	prob nan (nan)	GS 33.812 (33.812)	mem 42.380
Train: [20][265/750]	BT 0.157 (1.199)	DT 0.017 (1.065)	loss nan (nan)	prob nan (nan)	GS 34.781 (34.781)	mem 42.486
Train: [20][270/750]	BT 9.877 (1.216)	DT 9.786 (1.082)	loss nan (nan)	prob nan (nan)	GS 32.125 (32.125)	mem 42.330
Train: [20][275/750]	BT 0.112 (1.195)	DT 0.001 (1.062)	loss nan (nan)	prob nan (nan)	GS 33.750 (33.750)	mem 42.379
Train: [20][280/750]	BT 0.115 (1.177)	DT 0.006 (1.044)	loss nan (nan)	prob nan (nan)	GS 32.406 (32.406)	mem 42.388
Train: [20][285/750]	BT 0.074 (1.203)	DT 0.001 (1.070)	loss nan (nan)	prob nan (nan)	GS 30.734 (30.734)	mem 42.404
Train: [20][290/750]	BT 0.086 (1.190)	DT 0.001 (1.058)	loss nan (nan)	prob nan (nan)	GS 32.234 (32.234)	mem 42.402
Train: [20][295/750]	BT 0.062 (1.205)	DT 0.001 (1.072)	loss nan (nan)	prob nan (nan)	GS 28.219 (28.219)	mem 42.417
Train: [20][300/750]	BT 0.092 (1.186)	DT 0.002 (1.054)	loss nan (nan)	prob nan (nan)	GS 32.750 (32.750)	mem 42.418
Train: [20][305/750]	BT 0.098 (1.169)	DT 0.001 (1.037)	loss nan (nan)	prob nan (nan)	GS 30.188 (30.188)	mem 42.418
Train: [20][310/750]	BT 0.143 (1.201)	DT 0.001 (1.071)	loss nan (nan)	prob nan (nan)	GS 33.250 (33.250)	mem 42.539
Train: [20][315/750]	BT 0.138 (1.185)	DT 0.002 (1.054)	loss nan (nan)	prob nan (nan)	GS 31.062 (31.062)	mem 42.417
Train: [20][320/750]	BT 0.127 (1.197)	DT 0.013 (1.065)	loss nan (nan)	prob nan (nan)	GS 34.312 (34.312)	mem 42.512
Train: [20][325/750]	BT 0.168 (1.181)	DT 0.002 (1.049)	loss nan (nan)	prob nan (nan)	GS 32.812 (32.812)	mem 42.492
Train: [20][330/750]	BT 14.351 (1.208)	DT 14.267 (1.077)	loss nan (nan)	prob nan (nan)	GS 32.875 (32.875)	mem 42.333
Train: [20][335/750]	BT 0.088 (1.192)	DT 0.001 (1.061)	loss nan (nan)	prob nan (nan)	GS 31.500 (31.500)	mem 42.392
Train: [20][340/750]	BT 0.144 (1.176)	DT 0.005 (1.045)	loss nan (nan)	prob nan (nan)	GS 30.812 (30.812)	mem 42.347
Train: [20][345/750]	BT 0.146 (1.190)	DT 0.002 (1.059)	loss nan (nan)	prob nan (nan)	GS 26.219 (26.219)	mem 42.472
Train: [20][350/750]	BT 0.154 (1.175)	DT 0.003 (1.044)	loss nan (nan)	prob nan (nan)	GS 26.516 (26.516)	mem 42.525
Train: [20][355/750]	BT 0.117 (1.186)	DT 0.001 (1.055)	loss nan (nan)	prob nan (nan)	GS 27.094 (27.094)	mem 42.357
Train: [20][360/750]	BT 0.099 (1.171)	DT 0.002 (1.040)	loss nan (nan)	prob nan (nan)	GS 29.219 (29.219)	mem 42.314
Train: [20][365/750]	BT 0.149 (1.157)	DT 0.004 (1.026)	loss nan (nan)	prob nan (nan)	GS 33.125 (33.125)	mem 42.349
Train: [20][370/750]	BT 0.182 (1.177)	DT 0.001 (1.046)	loss nan (nan)	prob nan (nan)	GS 32.266 (32.266)	mem 42.429
Train: [20][375/750]	BT 0.117 (1.163)	DT 0.002 (1.032)	loss nan (nan)	prob nan (nan)	GS 29.188 (29.188)	mem 42.374
Train: [20][380/750]	BT 0.149 (1.182)	DT 0.003 (1.051)	loss nan (nan)	prob nan (nan)	GS 38.562 (38.562)	mem 42.364
Train: [20][385/750]	BT 0.128 (1.175)	DT 0.002 (1.044)	loss nan (nan)	prob nan (nan)	GS 29.594 (29.594)	mem 42.363
Train: [20][390/750]	BT 6.207 (1.177)	DT 6.082 (1.046)	loss nan (nan)	prob nan (nan)	GS 33.047 (33.047)	mem 42.425
Train: [20][395/750]	BT 0.123 (1.170)	DT 0.002 (1.040)	loss nan (nan)	prob nan (nan)	GS 26.156 (26.156)	mem 42.428
Train: [20][400/750]	BT 0.123 (1.164)	DT 0.009 (1.033)	loss nan (nan)	prob nan (nan)	GS 27.703 (27.703)	mem 42.520
Train: [20][405/750]	BT 0.130 (1.175)	DT 0.005 (1.044)	loss nan (nan)	prob nan (nan)	GS 28.859 (28.859)	mem 42.482
Train: [20][410/750]	BT 0.086 (1.172)	DT 0.005 (1.041)	loss nan (nan)	prob nan (nan)	GS 35.250 (35.250)	mem 42.443
Train: [20][415/750]	BT 0.138 (1.171)	DT 0.001 (1.039)	loss nan (nan)	prob nan (nan)	GS 26.578 (26.578)	mem 42.447
Train: [20][420/750]	BT 5.499 (1.172)	DT 5.398 (1.040)	loss nan (nan)	prob nan (nan)	GS 34.453 (34.453)	mem 42.452
Train: [20][425/750]	BT 0.131 (1.159)	DT 0.002 (1.028)	loss nan (nan)	prob nan (nan)	GS 31.156 (31.156)	mem 42.456
Train: [20][430/750]	BT 0.072 (1.166)	DT 0.002 (1.034)	loss nan (nan)	prob nan (nan)	GS 34.391 (34.391)	mem 42.463
Train: [20][435/750]	BT 0.108 (1.157)	DT 0.005 (1.025)	loss nan (nan)	prob nan (nan)	GS 29.328 (29.328)	mem 42.461
Train: [20][440/750]	BT 8.007 (1.168)	DT 7.852 (1.036)	loss nan (nan)	prob nan (nan)	GS 34.609 (34.609)	mem 42.447
Train: [20][445/750]	BT 0.144 (1.160)	DT 0.002 (1.028)	loss nan (nan)	prob nan (nan)	GS 29.078 (29.078)	mem 42.454
Train: [20][450/750]	BT 0.207 (1.149)	DT 0.024 (1.016)	loss nan (nan)	prob nan (nan)	GS 35.703 (35.703)	mem 42.454
Train: [20][455/750]	BT 0.103 (1.155)	DT 0.002 (1.022)	loss nan (nan)	prob nan (nan)	GS 26.438 (26.438)	mem 42.344
Train: [20][460/750]	BT 0.151 (1.144)	DT 0.003 (1.011)	loss nan (nan)	prob nan (nan)	GS 39.672 (39.672)	mem 42.414
Train: [20][465/750]	BT 0.090 (1.158)	DT 0.001 (1.025)	loss nan (nan)	prob nan (nan)	GS 26.703 (26.703)	mem 42.440
Train: [20][470/750]	BT 0.092 (1.150)	DT 0.003 (1.017)	loss nan (nan)	prob nan (nan)	GS 33.656 (33.656)	mem 42.444
Train: [20][475/750]	BT 0.140 (1.144)	DT 0.005 (1.012)	loss nan (nan)	prob nan (nan)	GS 31.250 (31.250)	mem 42.450
Train: [20][480/750]	BT 1.753 (1.156)	DT 1.647 (1.024)	loss nan (nan)	prob nan (nan)	GS 36.609 (36.609)	mem 42.403
Train: [20][485/750]	BT 0.206 (1.146)	DT 0.008 (1.013)	loss nan (nan)	prob nan (nan)	GS 32.359 (32.359)	mem 42.439
Train: [20][490/750]	BT 5.740 (1.157)	DT 5.607 (1.024)	loss nan (nan)	prob nan (nan)	GS 28.531 (28.531)	mem 42.447
Train: [20][495/750]	BT 0.139 (1.147)	DT 0.001 (1.013)	loss nan (nan)	prob nan (nan)	GS 32.109 (32.109)	mem 42.506
Train: [20][500/750]	BT 2.577 (1.146)	DT 2.434 (1.013)	loss nan (nan)	prob nan (nan)	GS 37.484 (37.484)	mem 42.572
Train: [20][505/750]	BT 0.201 (1.150)	DT 0.007 (1.017)	loss nan (nan)	prob nan (nan)	GS 32.781 (32.781)	mem 42.559
Train: [20][510/750]	BT 2.591 (1.146)	DT 2.448 (1.012)	loss nan (nan)	prob nan (nan)	GS 32.125 (32.125)	mem 42.518
Train: [20][515/750]	BT 0.170 (1.148)	DT 0.002 (1.014)	loss nan (nan)	prob nan (nan)	GS 34.672 (34.672)	mem 42.498
Train: [20][520/750]	BT 1.116 (1.140)	DT 1.008 (1.006)	loss nan (nan)	prob nan (nan)	GS 33.547 (33.547)	mem 42.434
Train: [20][525/750]	BT 0.083 (1.146)	DT 0.001 (1.012)	loss nan (nan)	prob nan (nan)	GS 30.500 (30.500)	mem 42.491
Train: [20][530/750]	BT 0.143 (1.141)	DT 0.001 (1.007)	loss nan (nan)	prob nan (nan)	GS 30.719 (30.719)	mem 42.530
Train: [20][535/750]	BT 0.073 (1.139)	DT 0.002 (1.006)	loss nan (nan)	prob nan (nan)	GS 34.062 (34.062)	mem 42.369
Train: [20][540/750]	BT 2.803 (1.152)	DT 2.717 (1.018)	loss nan (nan)	prob nan (nan)	GS 37.531 (37.531)	mem 42.435
Train: [20][545/750]	BT 0.140 (1.142)	DT 0.017 (1.009)	loss nan (nan)	prob nan (nan)	GS 33.172 (33.172)	mem 42.438
Train: [20][550/750]	BT 1.447 (1.143)	DT 1.094 (1.010)	loss nan (nan)	prob nan (nan)	GS 33.516 (33.516)	mem 42.539
Train: [20][555/750]	BT 0.089 (1.143)	DT 0.002 (1.009)	loss nan (nan)	prob nan (nan)	GS 29.203 (29.203)	mem 42.451
Train: [20][560/750]	BT 4.971 (1.142)	DT 4.819 (1.009)	loss nan (nan)	prob nan (nan)	GS 36.031 (36.031)	mem 42.455
Train: [20][565/750]	BT 0.117 (1.144)	DT 0.008 (1.011)	loss nan (nan)	prob nan (nan)	GS 32.422 (32.422)	mem 42.472
Train: [20][570/750]	BT 0.112 (1.136)	DT 0.002 (1.002)	loss nan (nan)	prob nan (nan)	GS 35.312 (35.312)	mem 42.473
Train: [20][575/750]	BT 0.268 (1.142)	DT 0.014 (1.008)	loss nan (nan)	prob nan (nan)	GS 32.422 (32.422)	mem 42.495
Train: [20][580/750]	BT 0.178 (1.138)	DT 0.001 (1.004)	loss nan (nan)	prob nan (nan)	GS 32.688 (32.688)	mem 42.572
Train: [20][585/750]	BT 0.079 (1.144)	DT 0.002 (1.010)	loss nan (nan)	prob nan (nan)	GS 27.500 (27.500)	mem 42.468
Train: [20][590/750]	BT 0.165 (1.138)	DT 0.001 (1.003)	loss nan (nan)	prob nan (nan)	GS 35.969 (35.969)	mem 42.744
Train: [20][595/750]	BT 0.173 (1.129)	DT 0.001 (0.995)	loss nan (nan)	prob nan (nan)	GS 32.203 (32.203)	mem 42.465
Train: [20][600/750]	BT 3.340 (1.143)	DT 3.222 (1.009)	loss nan (nan)	prob nan (nan)	GS 30.938 (30.938)	mem 42.507
Train: [20][605/750]	BT 0.104 (1.135)	DT 0.011 (1.000)	loss nan (nan)	prob nan (nan)	GS 32.484 (32.484)	mem 42.551
Train: [20][610/750]	BT 0.110 (1.144)	DT 0.001 (1.010)	loss nan (nan)	prob nan (nan)	GS 32.406 (32.406)	mem 42.495
Train: [20][615/750]	BT 0.221 (1.138)	DT 0.002 (1.004)	loss nan (nan)	prob nan (nan)	GS 33.672 (33.672)	mem 42.500
Train: [20][620/750]	BT 9.533 (1.145)	DT 9.349 (1.011)	loss nan (nan)	prob nan (nan)	GS 34.656 (34.656)	mem 42.528
Train: [20][625/750]	BT 0.088 (1.146)	DT 0.002 (1.012)	loss nan (nan)	prob nan (nan)	GS 26.906 (26.906)	mem 42.604
Train: [20][630/750]	BT 0.265 (1.138)	DT 0.003 (1.004)	loss nan (nan)	prob nan (nan)	GS 33.656 (33.656)	mem 42.496
Train: [20][635/750]	BT 0.216 (1.140)	DT 0.002 (1.005)	loss nan (nan)	prob nan (nan)	GS 30.562 (30.562)	mem 42.822
Train: [20][640/750]	BT 0.089 (1.142)	DT 0.002 (1.007)	loss nan (nan)	prob nan (nan)	GS 34.938 (34.938)	mem 42.420
Train: [20][645/750]	BT 0.243 (1.145)	DT 0.001 (1.010)	loss nan (nan)	prob nan (nan)	GS 30.812 (30.812)	mem 42.399
Train: [20][650/750]	BT 0.091 (1.142)	DT 0.001 (1.008)	loss nan (nan)	prob nan (nan)	GS 33.609 (33.609)	mem 42.444
Train: [20][655/750]	BT 0.208 (1.135)	DT 0.002 (1.000)	loss nan (nan)	prob nan (nan)	GS 30.281 (30.281)	mem 42.446
Train: [20][660/750]	BT 6.912 (1.145)	DT 6.825 (1.010)	loss nan (nan)	prob nan (nan)	GS 33.000 (33.000)	mem 42.420
Train: [20][665/750]	BT 0.089 (1.137)	DT 0.002 (1.003)	loss nan (nan)	prob nan (nan)	GS 32.625 (32.625)	mem 42.423
Train: [20][670/750]	BT 0.105 (1.140)	DT 0.002 (1.006)	loss nan (nan)	prob nan (nan)	GS 29.438 (29.438)	mem 42.493
Train: [20][675/750]	BT 0.080 (1.136)	DT 0.002 (1.001)	loss nan (nan)	prob nan (nan)	GS 37.656 (37.656)	mem 42.525
Train: [20][680/750]	BT 7.911 (1.140)	DT 7.812 (1.006)	loss nan (nan)	prob nan (nan)	GS 34.047 (34.047)	mem 42.456
Train: [20][685/750]	BT 0.095 (1.136)	DT 0.009 (1.001)	loss nan (nan)	prob nan (nan)	GS 28.922 (28.922)	mem 42.488
Train: [20][690/750]	BT 0.101 (1.130)	DT 0.002 (0.995)	loss nan (nan)	prob nan (nan)	GS 34.438 (34.438)	mem 42.491
Train: [20][695/750]	BT 0.126 (1.140)	DT 0.009 (1.005)	loss nan (nan)	prob nan (nan)	GS 29.750 (29.750)	mem 42.471
Train: [20][700/750]	BT 0.141 (1.132)	DT 0.001 (0.998)	loss nan (nan)	prob nan (nan)	GS 34.516 (34.516)	mem 42.472
Train: [20][705/750]	BT 0.179 (1.138)	DT 0.001 (1.003)	loss nan (nan)	prob nan (nan)	GS 28.734 (28.734)	mem 42.511
arpack error, retry= 0
Train: [20][710/750]	BT 0.163 (1.131)	DT 0.011 (0.996)	loss nan (nan)	prob nan (nan)	GS 30.625 (30.625)	mem 42.653
Train: [20][715/750]	BT 0.239 (1.124)	DT 0.005 (0.989)	loss nan (nan)	prob nan (nan)	GS 31.594 (31.594)	mem 42.553
Train: [20][720/750]	BT 0.176 (1.135)	DT 0.026 (1.000)	loss nan (nan)	prob nan (nan)	GS 33.703 (33.703)	mem 42.422
Train: [20][725/750]	BT 0.123 (1.128)	DT 0.007 (0.993)	loss nan (nan)	prob nan (nan)	GS 30.609 (30.609)	mem 42.536
Train: [20][730/750]	BT 0.120 (1.134)	DT 0.001 (0.999)	loss nan (nan)	prob nan (nan)	GS 34.922 (34.922)	mem 42.068
Train: [20][735/750]	BT 0.139 (1.127)	DT 0.007 (0.992)	loss nan (nan)	prob nan (nan)	GS 36.188 (36.188)	mem 42.067
Train: [20][740/750]	BT 6.063 (1.128)	DT 5.933 (0.994)	loss nan (nan)	prob nan (nan)	GS 26.125 (26.125)	mem 16.088
Train: [20][745/750]	BT 0.087 (1.121)	DT 0.002 (0.987)	loss nan (nan)	prob nan (nan)	GS 33.000 (33.000)	mem 16.103
Train: [20][750/750]	BT 0.076 (1.114)	DT 0.001 (0.981)	loss nan (nan)	prob nan (nan)	GS 31.531 (31.531)	mem 16.121
Train: [20][755/750]	BT 0.077 (1.110)	DT 0.001 (0.977)	loss nan (nan)	prob nan (nan)	GS 33.125 (33.125)	mem 13.076
epoch 20, total time 838.79
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [21][1/750]	BT 21.263 (21.263)	DT 21.088 (21.088)	loss nan (nan)	prob nan (nan)	GS 32.531 (32.531)	mem 41.502
Train: [21][5/750]	BT 0.175 (5.611)	DT 0.010 (5.458)	loss nan (nan)	prob nan (nan)	GS 32.703 (32.703)	mem 41.174
Train: [21][10/750]	BT 0.207 (2.876)	DT 0.004 (2.732)	loss nan (nan)	prob nan (nan)	GS 32.797 (32.797)	mem 41.176
Train: [21][15/750]	BT 0.076 (2.190)	DT 0.002 (2.051)	loss nan (nan)	prob nan (nan)	GS 30.125 (30.125)	mem 41.275
Train: [21][20/750]	BT 0.204 (2.258)	DT 0.002 (2.110)	loss nan (nan)	prob nan (nan)	GS 32.359 (32.359)	mem 41.417
Train: [21][25/750]	BT 0.143 (1.832)	DT 0.010 (1.690)	loss nan (nan)	prob nan (nan)	GS 28.703 (28.703)	mem 41.419
Train: [21][30/750]	BT 0.073 (2.102)	DT 0.002 (1.963)	loss nan (nan)	prob nan (nan)	GS 35.188 (35.188)	mem 41.829
Train: [21][35/750]	BT 0.118 (1.822)	DT 0.004 (1.684)	loss nan (nan)	prob nan (nan)	GS 33.141 (33.141)	mem 41.469
Train: [21][40/750]	BT 11.483 (1.899)	DT 11.343 (1.757)	loss nan (nan)	prob nan (nan)	GS 31.828 (31.828)	mem 41.559
Train: [21][45/750]	BT 0.070 (1.698)	DT 0.001 (1.562)	loss nan (nan)	prob nan (nan)	GS 34.578 (34.578)	mem 41.447
Train: [21][50/750]	BT 0.145 (1.539)	DT 0.002 (1.407)	loss nan (nan)	prob nan (nan)	GS 32.938 (32.938)	mem 41.685
Train: [21][55/750]	BT 0.089 (1.649)	DT 0.014 (1.519)	loss nan (nan)	prob nan (nan)	GS 27.266 (27.266)	mem 41.462
Train: [21][60/750]	BT 0.188 (1.523)	DT 0.009 (1.393)	loss nan (nan)	prob nan (nan)	GS 31.438 (31.438)	mem 41.464
Train: [21][65/750]	BT 0.088 (1.578)	DT 0.002 (1.449)	loss nan (nan)	prob nan (nan)	GS 29.062 (29.062)	mem 41.610
Train: [21][70/750]	BT 0.105 (1.473)	DT 0.001 (1.346)	loss nan (nan)	prob nan (nan)	GS 35.297 (35.297)	mem 41.612
Train: [21][75/750]	BT 0.143 (1.385)	DT 0.003 (1.256)	loss nan (nan)	prob nan (nan)	GS 29.938 (29.938)	mem 41.549
Train: [21][80/750]	BT 0.172 (1.437)	DT 0.002 (1.308)	loss nan (nan)	prob nan (nan)	GS 32.219 (32.219)	mem 41.633
Train: [21][85/750]	BT 0.235 (1.363)	DT 0.013 (1.232)	loss nan (nan)	prob nan (nan)	GS 33.000 (33.000)	mem 41.658
Train: [21][90/750]	BT 0.091 (1.459)	DT 0.001 (1.329)	loss nan (nan)	prob nan (nan)	GS 33.750 (33.750)	mem 41.671
Train: [21][95/750]	BT 0.131 (1.389)	DT 0.007 (1.259)	loss nan (nan)	prob nan (nan)	GS 32.328 (32.328)	mem 41.680
Train: [21][100/750]	BT 10.838 (1.433)	DT 10.696 (1.303)	loss nan (nan)	prob nan (nan)	GS 36.016 (36.016)	mem 41.721
Train: [21][105/750]	BT 0.114 (1.370)	DT 0.007 (1.242)	loss nan (nan)	prob nan (nan)	GS 31.609 (31.609)	mem 41.857
Train: [21][110/750]	BT 0.224 (1.313)	DT 0.002 (1.185)	loss nan (nan)	prob nan (nan)	GS 37.891 (37.891)	mem 41.936
Train: [21][115/750]	BT 0.068 (1.383)	DT 0.001 (1.257)	loss nan (nan)	prob nan (nan)	GS 31.344 (31.344)	mem 41.701
Train: [21][120/750]	BT 0.129 (1.330)	DT 0.012 (1.205)	loss nan (nan)	prob nan (nan)	GS 37.219 (37.219)	mem 41.702
Train: [21][125/750]	BT 0.063 (1.381)	DT 0.001 (1.255)	loss nan (nan)	prob nan (nan)	GS 25.094 (25.094)	mem 41.686
Train: [21][130/750]	BT 0.130 (1.331)	DT 0.003 (1.207)	loss nan (nan)	prob nan (nan)	GS 35.000 (35.000)	mem 41.691
Train: [21][135/750]	BT 0.088 (1.286)	DT 0.002 (1.163)	loss nan (nan)	prob nan (nan)	GS 29.703 (29.703)	mem 41.691
Train: [21][140/750]	BT 0.095 (1.307)	DT 0.002 (1.185)	loss nan (nan)	prob nan (nan)	GS 28.266 (28.266)	mem 41.839
Train: [21][145/750]	BT 0.145 (1.267)	DT 0.002 (1.145)	loss nan (nan)	prob nan (nan)	GS 28.641 (28.641)	mem 41.646
Train: [21][150/750]	BT 0.083 (1.320)	DT 0.001 (1.198)	loss nan (nan)	prob nan (nan)	GS 36.969 (36.969)	mem 41.739
Train: [21][155/750]	BT 0.150 (1.281)	DT 0.002 (1.160)	loss nan (nan)	prob nan (nan)	GS 34.906 (34.906)	mem 41.746
Train: [21][160/750]	BT 12.474 (1.323)	DT 12.399 (1.201)	loss nan (nan)	prob nan (nan)	GS 33.422 (33.422)	mem 42.030
Train: [21][165/750]	BT 0.107 (1.286)	DT 0.002 (1.165)	loss nan (nan)	prob nan (nan)	GS 31.109 (31.109)	mem 42.000
Train: [21][170/750]	BT 0.229 (1.253)	DT 0.007 (1.131)	loss nan (nan)	prob nan (nan)	GS 34.953 (34.953)	mem 42.035
Train: [21][175/750]	BT 0.190 (1.269)	DT 0.008 (1.145)	loss nan (nan)	prob nan (nan)	GS 33.359 (33.359)	mem 41.983
Train: [21][180/750]	BT 0.182 (1.238)	DT 0.008 (1.114)	loss nan (nan)	prob nan (nan)	GS 35.344 (35.344)	mem 42.005
Train: [21][185/750]	BT 0.078 (1.282)	DT 0.001 (1.157)	loss nan (nan)	prob nan (nan)	GS 31.344 (31.344)	mem 41.858
Train: [21][190/750]	BT 0.170 (1.253)	DT 0.002 (1.126)	loss nan (nan)	prob nan (nan)	GS 31.031 (31.031)	mem 41.938
Train: [21][195/750]	BT 0.241 (1.225)	DT 0.002 (1.097)	loss nan (nan)	prob nan (nan)	GS 29.875 (29.875)	mem 42.010
Train: [21][200/750]	BT 0.109 (1.261)	DT 0.009 (1.134)	loss nan (nan)	prob nan (nan)	GS 35.562 (35.562)	mem 41.867
Train: [21][205/750]	BT 0.080 (1.234)	DT 0.001 (1.107)	loss nan (nan)	prob nan (nan)	GS 32.516 (32.516)	mem 41.872
Train: [21][210/750]	BT 0.219 (1.268)	DT 0.024 (1.140)	loss nan (nan)	prob nan (nan)	GS 30.000 (30.000)	mem 42.151
Train: [21][215/750]	BT 0.133 (1.241)	DT 0.010 (1.113)	loss nan (nan)	prob nan (nan)	GS 29.578 (29.578)	mem 42.104
Train: [21][220/750]	BT 11.078 (1.265)	DT 10.997 (1.138)	loss nan (nan)	prob nan (nan)	GS 35.422 (35.422)	mem 42.246
Train: [21][225/750]	BT 0.158 (1.240)	DT 0.004 (1.113)	loss nan (nan)	prob nan (nan)	GS 31.078 (31.078)	mem 42.315
Train: [21][230/750]	BT 0.124 (1.216)	DT 0.019 (1.089)	loss nan (nan)	prob nan (nan)	GS 36.875 (36.875)	mem 42.268
Train: [21][235/750]	BT 0.071 (1.248)	DT 0.001 (1.121)	loss nan (nan)	prob nan (nan)	GS 29.453 (29.453)	mem 42.293
Train: [21][240/750]	BT 0.173 (1.225)	DT 0.001 (1.098)	loss nan (nan)	prob nan (nan)	GS 31.469 (31.469)	mem 42.293
Train: [21][245/750]	BT 0.073 (1.248)	DT 0.001 (1.122)	loss nan (nan)	prob nan (nan)	GS 28.891 (28.891)	mem 42.389
Train: [21][250/750]	BT 0.081 (1.225)	DT 0.001 (1.099)	loss nan (nan)	prob nan (nan)	GS 33.312 (33.312)	mem 42.333
Train: [21][255/750]	BT 0.132 (1.204)	DT 0.003 (1.078)	loss nan (nan)	prob nan (nan)	GS 32.438 (32.438)	mem 42.268
Train: [21][260/750]	BT 0.161 (1.223)	DT 0.005 (1.097)	loss nan (nan)	prob nan (nan)	GS 33.016 (33.016)	mem 42.213
Train: [21][265/750]	BT 0.142 (1.203)	DT 0.005 (1.077)	loss nan (nan)	prob nan (nan)	GS 31.703 (31.703)	mem 42.181
Train: [21][270/750]	BT 0.080 (1.228)	DT 0.001 (1.102)	loss nan (nan)	prob nan (nan)	GS 31.172 (31.172)	mem 42.299
Train: [21][275/750]	BT 0.105 (1.208)	DT 0.001 (1.082)	loss nan (nan)	prob nan (nan)	GS 29.969 (29.969)	mem 42.228
Train: [21][280/750]	BT 13.995 (1.238)	DT 13.922 (1.113)	loss nan (nan)	prob nan (nan)	GS 38.359 (38.359)	mem 42.251
Train: [21][285/750]	BT 0.076 (1.218)	DT 0.002 (1.093)	loss nan (nan)	prob nan (nan)	GS 30.578 (30.578)	mem 42.362
Train: [21][290/750]	BT 0.300 (1.200)	DT 0.007 (1.075)	loss nan (nan)	prob nan (nan)	GS 35.594 (35.594)	mem 42.431
Train: [21][295/750]	BT 0.127 (1.224)	DT 0.002 (1.098)	loss nan (nan)	prob nan (nan)	GS 30.516 (30.516)	mem 42.345
Train: [21][300/750]	BT 0.183 (1.206)	DT 0.002 (1.080)	loss nan (nan)	prob nan (nan)	GS 35.547 (35.547)	mem 42.336
Train: [21][305/750]	BT 0.073 (1.232)	DT 0.003 (1.106)	loss nan (nan)	prob nan (nan)	GS 30.719 (30.719)	mem 42.283
Train: [21][310/750]	BT 0.094 (1.214)	DT 0.001 (1.088)	loss nan (nan)	prob nan (nan)	GS 32.703 (32.703)	mem 42.301
Train: [21][315/750]	BT 0.204 (1.197)	DT 0.042 (1.071)	loss nan (nan)	prob nan (nan)	GS 32.141 (32.141)	mem 42.240
Train: [21][320/750]	BT 0.199 (1.213)	DT 0.002 (1.087)	loss nan (nan)	prob nan (nan)	GS 31.547 (31.547)	mem 42.403
Train: [21][325/750]	BT 0.125 (1.199)	DT 0.005 (1.073)	loss nan (nan)	prob nan (nan)	GS 29.656 (29.656)	mem 42.279
Train: [21][330/750]	BT 0.081 (1.223)	DT 0.002 (1.098)	loss nan (nan)	prob nan (nan)	GS 34.000 (34.000)	mem 42.331
Train: [21][335/750]	BT 0.120 (1.207)	DT 0.002 (1.082)	loss nan (nan)	prob nan (nan)	GS 34.656 (34.656)	mem 42.332
Train: [21][340/750]	BT 13.832 (1.231)	DT 13.762 (1.106)	loss nan (nan)	prob nan (nan)	GS 33.062 (33.062)	mem 42.276
Train: [21][345/750]	BT 0.143 (1.215)	DT 0.002 (1.090)	loss nan (nan)	prob nan (nan)	GS 30.797 (30.797)	mem 42.288
Train: [21][350/750]	BT 0.134 (1.199)	DT 0.014 (1.075)	loss nan (nan)	prob nan (nan)	GS 33.500 (33.500)	mem 42.290
Train: [21][355/750]	BT 0.141 (1.217)	DT 0.002 (1.093)	loss nan (nan)	prob nan (nan)	GS 31.953 (31.953)	mem 42.361
Train: [21][360/750]	BT 0.120 (1.202)	DT 0.002 (1.078)	loss nan (nan)	prob nan (nan)	GS 32.828 (32.828)	mem 42.301
Train: [21][365/750]	BT 0.087 (1.221)	DT 0.001 (1.097)	loss nan (nan)	prob nan (nan)	GS 31.625 (31.625)	mem 42.305
Train: [21][370/750]	BT 0.093 (1.206)	DT 0.003 (1.082)	loss nan (nan)	prob nan (nan)	GS 34.688 (34.688)	mem 42.316
Train: [21][375/750]	BT 0.178 (1.192)	DT 0.010 (1.068)	loss nan (nan)	prob nan (nan)	GS 29.766 (29.766)	mem 42.368
Train: [21][380/750]	BT 0.070 (1.205)	DT 0.001 (1.083)	loss nan (nan)	prob nan (nan)	GS 33.500 (33.500)	mem 42.424
Train: [21][385/750]	BT 0.107 (1.191)	DT 0.001 (1.069)	loss nan (nan)	prob nan (nan)	GS 27.828 (27.828)	mem 42.411
Train: [21][390/750]	BT 0.163 (1.209)	DT 0.002 (1.086)	loss nan (nan)	prob nan (nan)	GS 29.312 (29.312)	mem 42.370
Train: [21][395/750]	BT 0.095 (1.195)	DT 0.002 (1.073)	loss nan (nan)	prob nan (nan)	GS 32.516 (32.516)	mem 42.371
Train: [21][400/750]	BT 9.623 (1.205)	DT 9.423 (1.083)	loss nan (nan)	prob nan (nan)	GS 31.938 (31.938)	mem 42.381
Train: [21][405/750]	BT 0.109 (1.192)	DT 0.002 (1.069)	loss nan (nan)	prob nan (nan)	GS 31.594 (31.594)	mem 42.404
Train: [21][410/750]	BT 0.172 (1.179)	DT 0.004 (1.056)	loss nan (nan)	prob nan (nan)	GS 37.750 (37.750)	mem 42.404
Train: [21][415/750]	BT 0.138 (1.196)	DT 0.001 (1.073)	loss nan (nan)	prob nan (nan)	GS 31.406 (31.406)	mem 42.379
Train: [21][420/750]	BT 0.063 (1.183)	DT 0.003 (1.061)	loss nan (nan)	prob nan (nan)	GS 33.422 (33.422)	mem 42.427
Train: [21][425/750]	BT 0.068 (1.201)	DT 0.001 (1.079)	loss nan (nan)	prob nan (nan)	GS 29.125 (29.125)	mem 42.404
Train: [21][430/750]	BT 0.133 (1.189)	DT 0.001 (1.067)	loss nan (nan)	prob nan (nan)	GS 34.156 (34.156)	mem 42.425
Train: [21][435/750]	BT 0.099 (1.177)	DT 0.011 (1.055)	loss nan (nan)	prob nan (nan)	GS 27.625 (27.625)	mem 42.428
Train: [21][440/750]	BT 0.125 (1.194)	DT 0.004 (1.072)	loss nan (nan)	prob nan (nan)	GS 30.719 (30.719)	mem 42.479
Train: [21][445/750]	BT 0.157 (1.182)	DT 0.001 (1.060)	loss nan (nan)	prob nan (nan)	GS 30.297 (30.297)	mem 42.604
Train: [21][450/750]	BT 0.076 (1.186)	DT 0.010 (1.064)	loss nan (nan)	prob nan (nan)	GS 34.703 (34.703)	mem 42.439
Train: [21][455/750]	BT 0.176 (1.174)	DT 0.003 (1.052)	loss nan (nan)	prob nan (nan)	GS 32.562 (32.562)	mem 42.443
Train: [21][460/750]	BT 11.499 (1.188)	DT 11.379 (1.066)	loss nan (nan)	prob nan (nan)	GS 35.328 (35.328)	mem 42.442
Train: [21][465/750]	BT 0.118 (1.176)	DT 0.004 (1.054)	loss nan (nan)	prob nan (nan)	GS 35.422 (35.422)	mem 42.444
Train: [21][470/750]	BT 0.088 (1.166)	DT 0.002 (1.044)	loss nan (nan)	prob nan (nan)	GS 34.891 (34.891)	mem 42.366
Train: [21][475/750]	BT 0.181 (1.182)	DT 0.002 (1.060)	loss nan (nan)	prob nan (nan)	GS 30.797 (30.797)	mem 42.463
Train: [21][480/750]	BT 0.106 (1.171)	DT 0.014 (1.049)	loss nan (nan)	prob nan (nan)	GS 31.609 (31.609)	mem 42.360
Train: [21][485/750]	BT 0.096 (1.180)	DT 0.002 (1.058)	loss nan (nan)	prob nan (nan)	GS 31.438 (31.438)	mem 42.453
Train: [21][490/750]	BT 0.105 (1.168)	DT 0.001 (1.047)	loss nan (nan)	prob nan (nan)	GS 34.922 (34.922)	mem 42.451
Train: [21][495/750]	BT 0.160 (1.162)	DT 0.001 (1.041)	loss nan (nan)	prob nan (nan)	GS 32.234 (32.234)	mem 42.406
Train: [21][500/750]	BT 0.147 (1.177)	DT 0.003 (1.055)	loss nan (nan)	prob nan (nan)	GS 34.688 (34.688)	mem 42.512
Train: [21][505/750]	BT 0.177 (1.167)	DT 0.002 (1.045)	loss nan (nan)	prob nan (nan)	GS 26.219 (26.219)	mem 42.413
Train: [21][510/750]	BT 0.068 (1.177)	DT 0.001 (1.055)	loss nan (nan)	prob nan (nan)	GS 26.734 (26.734)	mem 42.438
Train: [21][515/750]	BT 0.109 (1.166)	DT 0.001 (1.044)	loss nan (nan)	prob nan (nan)	GS 31.141 (31.141)	mem 42.408
Train: [21][520/750]	BT 7.765 (1.176)	DT 7.614 (1.054)	loss nan (nan)	prob nan (nan)	GS 35.359 (35.359)	mem 42.443
Train: [21][525/750]	BT 0.130 (1.166)	DT 0.002 (1.044)	loss nan (nan)	prob nan (nan)	GS 31.906 (31.906)	mem 42.434
Train: [21][530/750]	BT 0.168 (1.168)	DT 0.002 (1.046)	loss nan (nan)	prob nan (nan)	GS 34.094 (34.094)	mem 42.438
Train: [21][535/750]	BT 0.079 (1.172)	DT 0.001 (1.050)	loss nan (nan)	prob nan (nan)	GS 29.703 (29.703)	mem 42.431
Train: [21][540/750]	BT 4.425 (1.171)	DT 4.267 (1.048)	loss nan (nan)	prob nan (nan)	GS 36.812 (36.812)	mem 42.458
Train: [21][545/750]	BT 0.130 (1.178)	DT 0.001 (1.055)	loss nan (nan)	prob nan (nan)	GS 32.891 (32.891)	mem 42.375
Train: [21][550/750]	BT 0.188 (1.169)	DT 0.014 (1.045)	loss nan (nan)	prob nan (nan)	GS 35.656 (35.656)	mem 42.390
Train: [21][555/750]	BT 0.089 (1.159)	DT 0.002 (1.036)	loss nan (nan)	prob nan (nan)	GS 38.703 (38.703)	mem 42.354
Train: [21][560/750]	BT 0.104 (1.168)	DT 0.001 (1.045)	loss nan (nan)	prob nan (nan)	GS 34.641 (34.641)	mem 42.433
Train: [21][565/750]	BT 0.269 (1.160)	DT 0.027 (1.037)	loss nan (nan)	prob nan (nan)	GS 31.891 (31.891)	mem 42.442
Train: [21][570/750]	BT 0.103 (1.172)	DT 0.001 (1.048)	loss nan (nan)	prob nan (nan)	GS 34.375 (34.375)	mem 42.487
Train: [21][575/750]	BT 0.153 (1.163)	DT 0.002 (1.039)	loss nan (nan)	prob nan (nan)	GS 30.625 (30.625)	mem 42.452
Train: [21][580/750]	BT 10.122 (1.176)	DT 10.034 (1.052)	loss nan (nan)	prob nan (nan)	GS 35.406 (35.406)	mem 42.451
Train: [21][585/750]	BT 0.121 (1.167)	DT 0.006 (1.043)	loss nan (nan)	prob nan (nan)	GS 30.547 (30.547)	mem 42.453
Train: [21][590/750]	BT 0.164 (1.160)	DT 0.002 (1.036)	loss nan (nan)	prob nan (nan)	GS 35.344 (35.344)	mem 42.537
Train: [21][595/750]	BT 0.078 (1.174)	DT 0.001 (1.051)	loss nan (nan)	prob nan (nan)	GS 30.016 (30.016)	mem 42.295
Train: [21][600/750]	BT 0.096 (1.165)	DT 0.008 (1.042)	loss nan (nan)	prob nan (nan)	GS 34.688 (34.688)	mem 42.359
Train: [21][605/750]	BT 0.118 (1.178)	DT 0.001 (1.054)	loss nan (nan)	prob nan (nan)	GS 33.766 (33.766)	mem 42.473
Train: [21][610/750]	BT 0.170 (1.169)	DT 0.007 (1.046)	loss nan (nan)	prob nan (nan)	GS 31.719 (31.719)	mem 42.646
Train: [21][615/750]	BT 0.206 (1.161)	DT 0.008 (1.037)	loss nan (nan)	prob nan (nan)	GS 32.062 (32.062)	mem 42.476
Train: [21][620/750]	BT 0.108 (1.169)	DT 0.002 (1.046)	loss nan (nan)	prob nan (nan)	GS 33.562 (33.562)	mem 42.363
Train: [21][625/750]	BT 0.271 (1.162)	DT 0.010 (1.038)	loss nan (nan)	prob nan (nan)	GS 33.516 (33.516)	mem 42.374
Train: [21][630/750]	BT 0.097 (1.167)	DT 0.001 (1.043)	loss nan (nan)	prob nan (nan)	GS 31.766 (31.766)	mem 42.469
Train: [21][635/750]	BT 0.265 (1.159)	DT 0.002 (1.034)	loss nan (nan)	prob nan (nan)	GS 30.984 (30.984)	mem 42.465
Train: [21][640/750]	BT 9.822 (1.170)	DT 9.744 (1.046)	loss nan (nan)	prob nan (nan)	GS 34.984 (34.984)	mem 42.370
Train: [21][645/750]	BT 0.245 (1.162)	DT 0.001 (1.038)	loss nan (nan)	prob nan (nan)	GS 36.031 (36.031)	mem 42.415
Train: [21][650/750]	BT 0.121 (1.154)	DT 0.002 (1.030)	loss nan (nan)	prob nan (nan)	GS 32.000 (32.000)	mem 42.453
Train: [21][655/750]	BT 0.134 (1.164)	DT 0.001 (1.040)	loss nan (nan)	prob nan (nan)	GS 30.516 (30.516)	mem 42.434
Train: [21][660/750]	BT 0.166 (1.157)	DT 0.050 (1.032)	loss nan (nan)	prob nan (nan)	GS 33.578 (33.578)	mem 42.434
Train: [21][665/750]	BT 0.130 (1.167)	DT 0.001 (1.043)	loss nan (nan)	prob nan (nan)	GS 34.656 (34.656)	mem 42.452
Train: [21][670/750]	BT 0.095 (1.159)	DT 0.020 (1.035)	loss nan (nan)	prob nan (nan)	GS 37.719 (37.719)	mem 42.452
Train: [21][675/750]	BT 0.183 (1.152)	DT 0.002 (1.028)	loss nan (nan)	prob nan (nan)	GS 28.562 (28.562)	mem 42.486
Train: [21][680/750]	BT 0.165 (1.162)	DT 0.029 (1.037)	loss nan (nan)	prob nan (nan)	GS 36.156 (36.156)	mem 42.327
Train: [21][685/750]	BT 0.206 (1.154)	DT 0.006 (1.030)	loss nan (nan)	prob nan (nan)	GS 29.281 (29.281)	mem 42.352
Train: [21][690/750]	BT 0.123 (1.165)	DT 0.001 (1.040)	loss nan (nan)	prob nan (nan)	GS 31.344 (31.344)	mem 42.455
Train: [21][695/750]	BT 0.144 (1.157)	DT 0.013 (1.033)	loss nan (nan)	prob nan (nan)	GS 32.875 (32.875)	mem 42.395
Train: [21][700/750]	BT 10.533 (1.165)	DT 10.415 (1.040)	loss nan (nan)	prob nan (nan)	GS 30.281 (30.281)	mem 42.474
Train: [21][705/750]	BT 0.084 (1.161)	DT 0.002 (1.036)	loss nan (nan)	prob nan (nan)	GS 32.281 (32.281)	mem 42.441
Train: [21][710/750]	BT 0.134 (1.154)	DT 0.001 (1.029)	loss nan (nan)	prob nan (nan)	GS 35.672 (35.672)	mem 42.376
Train: [21][715/750]	BT 0.102 (1.160)	DT 0.010 (1.035)	loss nan (nan)	prob nan (nan)	GS 33.578 (33.578)	mem 42.370
Train: [21][720/750]	BT 0.210 (1.153)	DT 0.014 (1.028)	loss nan (nan)	prob nan (nan)	GS 39.281 (39.281)	mem 42.372
Train: [21][725/750]	BT 0.202 (1.160)	DT 0.024 (1.035)	loss nan (nan)	prob nan (nan)	GS 26.047 (26.047)	mem 42.217
Train: [21][730/750]	BT 0.128 (1.153)	DT 0.002 (1.028)	loss nan (nan)	prob nan (nan)	GS 33.375 (33.375)	mem 42.217
Train: [21][735/750]	BT 0.145 (1.146)	DT 0.001 (1.021)	loss nan (nan)	prob nan (nan)	GS 31.969 (31.969)	mem 42.257
Train: [21][740/750]	BT 0.107 (1.149)	DT 0.012 (1.024)	loss nan (nan)	prob nan (nan)	GS 34.688 (34.688)	mem 16.055
Train: [21][745/750]	BT 0.068 (1.142)	DT 0.002 (1.017)	loss nan (nan)	prob nan (nan)	GS 32.750 (32.750)	mem 16.055
Train: [21][750/750]	BT 0.063 (1.138)	DT 0.001 (1.013)	loss nan (nan)	prob nan (nan)	GS 30.812 (30.812)	mem 13.042
Train: [21][755/750]	BT 0.089 (1.131)	DT 0.001 (1.007)	loss nan (nan)	prob nan (nan)	GS 30.906 (30.906)	mem 10.063
epoch 21, total time 853.83
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [22][1/750]	BT 23.250 (23.250)	DT 23.091 (23.091)	loss nan (nan)	prob nan (nan)	GS 37.062 (37.062)	mem 41.206
Train: [22][5/750]	BT 0.094 (5.595)	DT 0.002 (5.472)	loss nan (nan)	prob nan (nan)	GS 31.297 (31.297)	mem 41.210
Train: [22][10/750]	BT 0.095 (2.893)	DT 0.001 (2.738)	loss nan (nan)	prob nan (nan)	GS 35.750 (35.750)	mem 41.221
Train: [22][15/750]	BT 0.187 (2.554)	DT 0.049 (2.395)	loss nan (nan)	prob nan (nan)	GS 27.094 (27.094)	mem 41.374
Train: [22][20/750]	BT 0.096 (2.120)	DT 0.009 (1.969)	loss nan (nan)	prob nan (nan)	GS 33.109 (33.109)	mem 41.483
Train: [22][25/750]	BT 5.207 (1.932)	DT 5.084 (1.780)	loss nan (nan)	prob nan (nan)	GS 31.578 (31.578)	mem 41.455
Train: [22][30/750]	BT 0.103 (2.039)	DT 0.001 (1.896)	loss nan (nan)	prob nan (nan)	GS 35.312 (35.312)	mem 41.509
Train: [22][35/750]	BT 0.092 (1.771)	DT 0.002 (1.626)	loss nan (nan)	prob nan (nan)	GS 34.953 (34.953)	mem 41.701
Train: [22][40/750]	BT 4.078 (1.851)	DT 3.963 (1.712)	loss nan (nan)	prob nan (nan)	GS 35.281 (35.281)	mem 41.539
Train: [22][45/750]	BT 0.093 (1.659)	DT 0.001 (1.522)	loss nan (nan)	prob nan (nan)	GS 34.688 (34.688)	mem 41.541
Train: [22][50/750]	BT 5.954 (1.623)	DT 5.823 (1.486)	loss nan (nan)	prob nan (nan)	GS 36.000 (36.000)	mem 41.515
Train: [22][55/750]	BT 0.096 (1.625)	DT 0.002 (1.488)	loss nan (nan)	prob nan (nan)	GS 30.672 (30.672)	mem 41.484
Train: [22][60/750]	BT 0.178 (1.502)	DT 0.010 (1.365)	loss nan (nan)	prob nan (nan)	GS 36.078 (36.078)	mem 41.543
Train: [22][65/750]	BT 0.154 (1.569)	DT 0.010 (1.433)	loss nan (nan)	prob nan (nan)	GS 32.078 (32.078)	mem 41.557
Train: [22][70/750]	BT 0.247 (1.468)	DT 0.009 (1.331)	loss nan (nan)	prob nan (nan)	GS 33.781 (33.781)	mem 41.520
Train: [22][75/750]	BT 0.190 (1.499)	DT 0.002 (1.361)	loss nan (nan)	prob nan (nan)	GS 31.844 (31.844)	mem 41.573
Train: [22][80/750]	BT 0.093 (1.420)	DT 0.003 (1.282)	loss nan (nan)	prob nan (nan)	GS 32.672 (32.672)	mem 41.702
Train: [22][85/750]	BT 0.110 (1.344)	DT 0.002 (1.207)	loss nan (nan)	prob nan (nan)	GS 30.109 (30.109)	mem 41.673
Train: [22][90/750]	BT 2.112 (1.421)	DT 2.017 (1.285)	loss nan (nan)	prob nan (nan)	GS 39.578 (39.578)	mem 41.794
Train: [22][95/750]	BT 0.127 (1.354)	DT 0.003 (1.217)	loss nan (nan)	prob nan (nan)	GS 33.844 (33.844)	mem 41.795
Train: [22][100/750]	BT 0.080 (1.394)	DT 0.002 (1.259)	loss nan (nan)	prob nan (nan)	GS 42.938 (42.938)	mem 42.020
Train: [22][105/750]	BT 0.098 (1.333)	DT 0.002 (1.199)	loss nan (nan)	prob nan (nan)	GS 30.344 (30.344)	mem 42.020
Train: [22][110/750]	BT 12.349 (1.391)	DT 12.253 (1.257)	loss nan (nan)	prob nan (nan)	GS 34.141 (34.141)	mem 42.250
Train: [22][115/750]	BT 0.097 (1.358)	DT 0.004 (1.225)	loss nan (nan)	prob nan (nan)	GS 45.703 (45.703)	mem 42.164
Train: [22][120/750]	BT 0.150 (1.308)	DT 0.002 (1.174)	loss nan (nan)	prob nan (nan)	GS 34.188 (34.188)	mem 42.176
Train: [22][125/750]	BT 0.131 (1.351)	DT 0.001 (1.218)	loss nan (nan)	prob nan (nan)	GS 31.172 (31.172)	mem 42.238
Train: [22][130/750]	BT 0.085 (1.304)	DT 0.001 (1.171)	loss nan (nan)	prob nan (nan)	GS 35.391 (35.391)	mem 42.189
Train: [22][135/750]	BT 0.138 (1.332)	DT 0.003 (1.198)	loss nan (nan)	prob nan (nan)	GS 28.094 (28.094)	mem 42.202
Train: [22][140/750]	BT 0.094 (1.318)	DT 0.001 (1.186)	loss nan (nan)	prob nan (nan)	GS 33.938 (33.938)	mem 42.108
Train: [22][145/750]	BT 0.110 (1.279)	DT 0.011 (1.146)	loss nan (nan)	prob nan (nan)	GS 29.266 (29.266)	mem 42.142
Train: [22][150/750]	BT 0.306 (1.310)	DT 0.202 (1.178)	loss nan (nan)	prob nan (nan)	GS 35.000 (35.000)	mem 42.170
Train: [22][155/750]	BT 0.131 (1.271)	DT 0.001 (1.140)	loss nan (nan)	prob nan (nan)	GS 32.047 (32.047)	mem 42.188
Train: [22][160/750]	BT 3.952 (1.322)	DT 3.781 (1.191)	loss nan (nan)	prob nan (nan)	GS 33.984 (33.984)	mem 42.226
Train: [22][165/750]	BT 0.135 (1.288)	DT 0.018 (1.155)	loss nan (nan)	prob nan (nan)	GS 28.938 (28.938)	mem 42.274
Train: [22][170/750]	BT 5.234 (1.285)	DT 5.084 (1.151)	loss nan (nan)	prob nan (nan)	GS 36.328 (36.328)	mem 42.223
Train: [22][175/750]	BT 0.124 (1.278)	DT 0.016 (1.144)	loss nan (nan)	prob nan (nan)	GS 31.188 (31.188)	mem 42.190
Train: [22][180/750]	BT 0.246 (1.247)	DT 0.014 (1.113)	loss nan (nan)	prob nan (nan)	GS 33.219 (33.219)	mem 42.196
Train: [22][185/750]	BT 0.107 (1.277)	DT 0.002 (1.143)	loss nan (nan)	prob nan (nan)	GS 28.750 (28.750)	mem 42.270
Train: [22][190/750]	BT 0.095 (1.247)	DT 0.015 (1.113)	loss nan (nan)	prob nan (nan)	GS 31.469 (31.469)	mem 42.271
Train: [22][195/750]	BT 0.112 (1.239)	DT 0.003 (1.104)	loss nan (nan)	prob nan (nan)	GS 33.859 (33.859)	mem 42.278
Train: [22][200/750]	BT 0.124 (1.244)	DT 0.016 (1.109)	loss nan (nan)	prob nan (nan)	GS 34.547 (34.547)	mem 42.259
Train: [22][205/750]	BT 0.072 (1.239)	DT 0.002 (1.104)	loss nan (nan)	prob nan (nan)	GS 27.297 (27.297)	mem 42.283
Train: [22][210/750]	BT 0.112 (1.249)	DT 0.003 (1.113)	loss nan (nan)	prob nan (nan)	GS 36.109 (36.109)	mem 42.365
Train: [22][215/750]	BT 0.109 (1.241)	DT 0.003 (1.106)	loss nan (nan)	prob nan (nan)	GS 30.953 (30.953)	mem 42.271
Train: [22][220/750]	BT 5.890 (1.244)	DT 5.779 (1.109)	loss nan (nan)	prob nan (nan)	GS 31.422 (31.422)	mem 42.272
Train: [22][225/750]	BT 0.088 (1.218)	DT 0.002 (1.084)	loss nan (nan)	prob nan (nan)	GS 36.812 (36.812)	mem 42.276
Train: [22][230/750]	BT 0.078 (1.240)	DT 0.001 (1.107)	loss nan (nan)	prob nan (nan)	GS 33.891 (33.891)	mem 42.317
Train: [22][235/750]	BT 0.067 (1.235)	DT 0.001 (1.103)	loss nan (nan)	prob nan (nan)	GS 29.234 (29.234)	mem 42.397
Train: [22][240/750]	BT 0.110 (1.227)	DT 0.001 (1.094)	loss nan (nan)	prob nan (nan)	GS 28.516 (28.516)	mem 42.402
Train: [22][245/750]	BT 0.125 (1.245)	DT 0.016 (1.112)	loss nan (nan)	prob nan (nan)	GS 29.219 (29.219)	mem 42.351
Train: [22][250/750]	BT 0.085 (1.222)	DT 0.001 (1.090)	loss nan (nan)	prob nan (nan)	GS 30.375 (30.375)	mem 42.353
Train: [22][255/750]	BT 0.416 (1.202)	DT 0.005 (1.068)	loss nan (nan)	prob nan (nan)	GS 30.844 (30.844)	mem 42.477
Train: [22][260/750]	BT 0.127 (1.223)	DT 0.001 (1.091)	loss nan (nan)	prob nan (nan)	GS 37.234 (37.234)	mem 42.526
Train: [22][265/750]	BT 0.071 (1.203)	DT 0.001 (1.071)	loss nan (nan)	prob nan (nan)	GS 36.062 (36.062)	mem 42.560
Train: [22][270/750]	BT 0.144 (1.225)	DT 0.004 (1.092)	loss nan (nan)	prob nan (nan)	GS 37.875 (37.875)	mem 42.415
Train: [22][275/750]	BT 0.090 (1.217)	DT 0.001 (1.084)	loss nan (nan)	prob nan (nan)	GS 28.781 (28.781)	mem 42.349
Train: [22][280/750]	BT 5.989 (1.218)	DT 5.840 (1.085)	loss nan (nan)	prob nan (nan)	GS 35.641 (35.641)	mem 42.384
Train: [22][285/750]	BT 0.123 (1.200)	DT 0.001 (1.066)	loss nan (nan)	prob nan (nan)	GS 31.156 (31.156)	mem 42.387
Train: [22][290/750]	BT 0.103 (1.198)	DT 0.005 (1.065)	loss nan (nan)	prob nan (nan)	GS 32.016 (32.016)	mem 42.426
Train: [22][295/750]	BT 0.111 (1.195)	DT 0.008 (1.061)	loss nan (nan)	prob nan (nan)	GS 32.875 (32.875)	mem 42.613
Train: [22][300/750]	BT 0.126 (1.208)	DT 0.014 (1.074)	loss nan (nan)	prob nan (nan)	GS 30.297 (30.297)	mem 42.505
Train: [22][305/750]	BT 0.115 (1.206)	DT 0.001 (1.072)	loss nan (nan)	prob nan (nan)	GS 31.594 (31.594)	mem 42.387
Train: [22][310/750]	BT 10.403 (1.222)	DT 10.273 (1.088)	loss nan (nan)	prob nan (nan)	GS 35.906 (35.906)	mem 42.316
Train: [22][315/750]	BT 0.157 (1.204)	DT 0.007 (1.071)	loss nan (nan)	prob nan (nan)	GS 33.031 (33.031)	mem 42.319
Train: [22][320/750]	BT 0.221 (1.192)	DT 0.047 (1.058)	loss nan (nan)	prob nan (nan)	GS 30.438 (30.438)	mem 42.337
Train: [22][325/750]	BT 0.155 (1.209)	DT 0.002 (1.075)	loss nan (nan)	prob nan (nan)	GS 33.500 (33.500)	mem 42.409
Train: [22][330/750]	BT 0.095 (1.196)	DT 0.002 (1.063)	loss nan (nan)	prob nan (nan)	GS 31.484 (31.484)	mem 42.613
Train: [22][335/750]	BT 0.077 (1.212)	DT 0.001 (1.079)	loss nan (nan)	prob nan (nan)	GS 28.797 (28.797)	mem 42.371
Train: [22][340/750]	BT 2.378 (1.203)	DT 2.288 (1.070)	loss nan (nan)	prob nan (nan)	GS 35.594 (35.594)	mem 42.357
Train: [22][345/750]	BT 0.125 (1.187)	DT 0.001 (1.054)	loss nan (nan)	prob nan (nan)	GS 36.375 (36.375)	mem 42.402
Train: [22][350/750]	BT 0.110 (1.201)	DT 0.002 (1.068)	loss nan (nan)	prob nan (nan)	GS 28.094 (28.094)	mem 42.419
Train: [22][355/750]	BT 0.215 (1.200)	DT 0.015 (1.067)	loss nan (nan)	prob nan (nan)	GS 31.578 (31.578)	mem 42.429
Train: [22][360/750]	BT 0.131 (1.201)	DT 0.020 (1.067)	loss nan (nan)	prob nan (nan)	GS 30.562 (30.562)	mem 42.385
Train: [22][365/750]	BT 0.174 (1.205)	DT 0.004 (1.071)	loss nan (nan)	prob nan (nan)	GS 34.984 (34.984)	mem 42.459
Train: [22][370/750]	BT 3.363 (1.199)	DT 3.155 (1.065)	loss nan (nan)	prob nan (nan)	GS 31.469 (31.469)	mem 42.458
Train: [22][375/750]	BT 0.106 (1.185)	DT 0.002 (1.051)	loss nan (nan)	prob nan (nan)	GS 31.219 (31.219)	mem 42.452
Train: [22][380/750]	BT 0.136 (1.201)	DT 0.001 (1.068)	loss nan (nan)	prob nan (nan)	GS 33.438 (33.438)	mem 42.380
Train: [22][385/750]	BT 0.113 (1.189)	DT 0.002 (1.056)	loss nan (nan)	prob nan (nan)	GS 33.156 (33.156)	mem 42.409
Train: [22][390/750]	BT 0.110 (1.206)	DT 0.008 (1.073)	loss nan (nan)	prob nan (nan)	GS 30.266 (30.266)	mem 42.416
Train: [22][395/750]	BT 0.088 (1.194)	DT 0.005 (1.062)	loss nan (nan)	prob nan (nan)	GS 32.812 (32.812)	mem 42.389
Train: [22][400/750]	BT 9.497 (1.204)	DT 9.405 (1.072)	loss nan (nan)	prob nan (nan)	GS 34.250 (34.250)	mem 42.361
Train: [22][405/750]	BT 0.125 (1.192)	DT 0.002 (1.059)	loss nan (nan)	prob nan (nan)	GS 36.156 (36.156)	mem 42.574
Train: [22][410/750]	BT 0.128 (1.191)	DT 0.002 (1.058)	loss nan (nan)	prob nan (nan)	GS 32.938 (32.938)	mem 42.328
Train: [22][415/750]	BT 0.145 (1.195)	DT 0.003 (1.062)	loss nan (nan)	prob nan (nan)	GS 30.703 (30.703)	mem 42.450
Train: [22][420/750]	BT 0.159 (1.188)	DT 0.009 (1.055)	loss nan (nan)	prob nan (nan)	GS 32.453 (32.453)	mem 42.443
Train: [22][425/750]	BT 0.088 (1.201)	DT 0.002 (1.068)	loss nan (nan)	prob nan (nan)	GS 32.391 (32.391)	mem 42.282
Train: [22][430/750]	BT 0.854 (1.190)	DT 0.745 (1.058)	loss nan (nan)	prob nan (nan)	GS 33.406 (33.406)	mem 42.316
Train: [22][435/750]	BT 0.114 (1.178)	DT 0.003 (1.046)	loss nan (nan)	prob nan (nan)	GS 32.469 (32.469)	mem 42.319
Train: [22][440/750]	BT 0.134 (1.192)	DT 0.002 (1.060)	loss nan (nan)	prob nan (nan)	GS 36.078 (36.078)	mem 42.280
Train: [22][445/750]	BT 0.128 (1.180)	DT 0.002 (1.048)	loss nan (nan)	prob nan (nan)	GS 30.969 (30.969)	mem 42.290
Train: [22][450/750]	BT 0.087 (1.195)	DT 0.001 (1.063)	loss nan (nan)	prob nan (nan)	GS 33.641 (33.641)	mem 42.368
Train: [22][455/750]	BT 0.145 (1.184)	DT 0.002 (1.052)	loss nan (nan)	prob nan (nan)	GS 30.797 (30.797)	mem 42.592
Train: [22][460/750]	BT 11.370 (1.197)	DT 11.195 (1.064)	loss nan (nan)	prob nan (nan)	GS 34.438 (34.438)	mem 42.415
Train: [22][465/750]	BT 0.113 (1.185)	DT 0.002 (1.053)	loss nan (nan)	prob nan (nan)	GS 30.031 (30.031)	mem 42.398
Train: [22][470/750]	BT 0.077 (1.174)	DT 0.001 (1.042)	loss nan (nan)	prob nan (nan)	GS 31.531 (31.531)	mem 42.401
Train: [22][475/750]	BT 0.067 (1.186)	DT 0.001 (1.054)	loss nan (nan)	prob nan (nan)	GS 29.750 (29.750)	mem 42.315
Train: [22][480/750]	BT 0.139 (1.175)	DT 0.002 (1.043)	loss nan (nan)	prob nan (nan)	GS 31.359 (31.359)	mem 42.389
Train: [22][485/750]	BT 0.124 (1.188)	DT 0.002 (1.055)	loss nan (nan)	prob nan (nan)	GS 33.641 (33.641)	mem 42.314
Train: [22][490/750]	BT 3.917 (1.185)	DT 3.792 (1.052)	loss nan (nan)	prob nan (nan)	GS 34.234 (34.234)	mem 42.472
Train: [22][495/750]	BT 0.091 (1.174)	DT 0.003 (1.042)	loss nan (nan)	prob nan (nan)	GS 34.438 (34.438)	mem 42.429
Train: [22][500/750]	BT 3.468 (1.184)	DT 3.340 (1.051)	loss nan (nan)	prob nan (nan)	GS 37.094 (37.094)	mem 42.365
Train: [22][505/750]	BT 0.182 (1.173)	DT 0.006 (1.041)	loss nan (nan)	prob nan (nan)	GS 33.797 (33.797)	mem 42.405
Train: [22][510/750]	BT 0.246 (1.179)	DT 0.002 (1.047)	loss nan (nan)	prob nan (nan)	GS 33.891 (33.891)	mem 42.347
Train: [22][515/750]	BT 0.189 (1.178)	DT 0.006 (1.045)	loss nan (nan)	prob nan (nan)	GS 29.516 (29.516)	mem 42.292
Train: [22][520/750]	BT 8.988 (1.185)	DT 8.867 (1.053)	loss nan (nan)	prob nan (nan)	GS 37.172 (37.172)	mem 42.325
Train: [22][525/750]	BT 0.156 (1.180)	DT 0.002 (1.047)	loss nan (nan)	prob nan (nan)	GS 33.328 (33.328)	mem 42.330
Train: [22][530/750]	BT 0.251 (1.170)	DT 0.010 (1.037)	loss nan (nan)	prob nan (nan)	GS 30.781 (30.781)	mem 42.333
Train: [22][535/750]	BT 0.092 (1.178)	DT 0.002 (1.045)	loss nan (nan)	prob nan (nan)	GS 33.016 (33.016)	mem 42.396
Train: [22][540/750]	BT 0.121 (1.176)	DT 0.002 (1.044)	loss nan (nan)	prob nan (nan)	GS 30.891 (30.891)	mem 42.248
Train: [22][545/750]	BT 0.112 (1.183)	DT 0.004 (1.051)	loss nan (nan)	prob nan (nan)	GS 27.453 (27.453)	mem 42.366
Train: [22][550/750]	BT 1.993 (1.177)	DT 1.785 (1.045)	loss nan (nan)	prob nan (nan)	GS 33.172 (33.172)	mem 42.288
Train: [22][555/750]	BT 0.081 (1.168)	DT 0.002 (1.035)	loss nan (nan)	prob nan (nan)	GS 37.219 (37.219)	mem 42.298
Train: [22][560/750]	BT 0.125 (1.180)	DT 0.005 (1.048)	loss nan (nan)	prob nan (nan)	GS 36.312 (36.312)	mem 42.342
Train: [22][565/750]	BT 0.162 (1.172)	DT 0.001 (1.039)	loss nan (nan)	prob nan (nan)	GS 34.891 (34.891)	mem 42.535
Train: [22][570/750]	BT 0.130 (1.176)	DT 0.004 (1.044)	loss nan (nan)	prob nan (nan)	GS 34.531 (34.531)	mem 42.360
Train: [22][575/750]	BT 0.146 (1.172)	DT 0.023 (1.040)	loss nan (nan)	prob nan (nan)	GS 31.969 (31.969)	mem 42.372
Train: [22][580/750]	BT 8.498 (1.178)	DT 8.387 (1.046)	loss nan (nan)	prob nan (nan)	GS 32.547 (32.547)	mem 42.368
Train: [22][585/750]	BT 0.087 (1.181)	DT 0.001 (1.049)	loss nan (nan)	prob nan (nan)	GS 31.359 (31.359)	mem 42.275
Train: [22][590/750]	BT 0.087 (1.172)	DT 0.002 (1.040)	loss nan (nan)	prob nan (nan)	GS 38.922 (38.922)	mem 42.322
Train: [22][595/750]	BT 0.115 (1.170)	DT 0.002 (1.038)	loss nan (nan)	prob nan (nan)	GS 34.344 (34.344)	mem 42.567
Train: [22][600/750]	BT 0.160 (1.174)	DT 0.002 (1.041)	loss nan (nan)	prob nan (nan)	GS 35.531 (35.531)	mem 42.348
Train: [22][605/750]	BT 0.188 (1.171)	DT 0.010 (1.038)	loss nan (nan)	prob nan (nan)	GS 30.406 (30.406)	mem 42.316
Train: [22][610/750]	BT 0.167 (1.180)	DT 0.001 (1.047)	loss nan (nan)	prob nan (nan)	GS 29.500 (29.500)	mem 42.349
Train: [22][615/750]	BT 0.169 (1.172)	DT 0.005 (1.039)	loss nan (nan)	prob nan (nan)	GS 28.297 (28.297)	mem 42.480
Train: [22][620/750]	BT 5.837 (1.182)	DT 5.660 (1.049)	loss nan (nan)	prob nan (nan)	GS 36.469 (36.469)	mem 42.463
Train: [22][625/750]	BT 0.075 (1.173)	DT 0.002 (1.040)	loss nan (nan)	prob nan (nan)	GS 32.219 (32.219)	mem 42.483
Train: [22][630/750]	BT 4.131 (1.171)	DT 3.980 (1.039)	loss nan (nan)	prob nan (nan)	GS 31.266 (31.266)	mem 42.424
Train: [22][635/750]	BT 0.125 (1.178)	DT 0.001 (1.045)	loss nan (nan)	prob nan (nan)	GS 29.609 (29.609)	mem 42.454
Train: [22][640/750]	BT 0.221 (1.170)	DT 0.003 (1.037)	loss nan (nan)	prob nan (nan)	GS 34.469 (34.469)	mem 42.462
Train: [22][645/750]	BT 0.082 (1.176)	DT 0.001 (1.043)	loss nan (nan)	prob nan (nan)	GS 31.859 (31.859)	mem 42.730
Train: [22][650/750]	BT 0.095 (1.168)	DT 0.001 (1.035)	loss nan (nan)	prob nan (nan)	GS 30.156 (30.156)	mem 42.500
Train: [22][655/750]	BT 0.136 (1.175)	DT 0.002 (1.042)	loss nan (nan)	prob nan (nan)	GS 30.391 (30.391)	mem 42.432
Train: [22][660/750]	BT 0.092 (1.170)	DT 0.001 (1.037)	loss nan (nan)	prob nan (nan)	GS 33.312 (33.312)	mem 42.423
Train: [22][665/750]	BT 0.222 (1.162)	DT 0.001 (1.029)	loss nan (nan)	prob nan (nan)	GS 26.500 (26.500)	mem 42.456
Train: [22][670/750]	BT 0.150 (1.174)	DT 0.001 (1.041)	loss nan (nan)	prob nan (nan)	GS 33.281 (33.281)	mem 42.349
Train: [22][675/750]	BT 0.169 (1.166)	DT 0.002 (1.033)	loss nan (nan)	prob nan (nan)	GS 28.797 (28.797)	mem 42.354
Train: [22][680/750]	BT 0.097 (1.175)	DT 0.008 (1.042)	loss nan (nan)	prob nan (nan)	GS 34.266 (34.266)	mem 42.207
Train: [22][685/750]	BT 0.138 (1.167)	DT 0.001 (1.034)	loss nan (nan)	prob nan (nan)	GS 30.266 (30.266)	mem 42.334
Train: [22][690/750]	BT 12.933 (1.178)	DT 12.843 (1.045)	loss nan (nan)	prob nan (nan)	GS 34.156 (34.156)	mem 42.620
Train: [22][695/750]	BT 0.132 (1.170)	DT 0.012 (1.038)	loss nan (nan)	prob nan (nan)	GS 31.516 (31.516)	mem 42.377
Train: [22][700/750]	BT 0.094 (1.163)	DT 0.002 (1.031)	loss nan (nan)	prob nan (nan)	GS 35.266 (35.266)	mem 42.366
Train: [22][705/750]	BT 0.096 (1.171)	DT 0.001 (1.039)	loss nan (nan)	prob nan (nan)	GS 29.953 (29.953)	mem 42.353
arpack error, retry= 0
arpack error, retry= 0
Train: [22][710/750]	BT 0.129 (1.164)	DT 0.005 (1.032)	loss nan (nan)	prob nan (nan)	GS 32.109 (32.109)	mem 42.357
Train: [22][715/750]	BT 0.067 (1.174)	DT 0.001 (1.042)	loss nan (nan)	prob nan (nan)	GS 32.656 (32.656)	mem 42.439
Train: [22][720/750]	BT 0.086 (1.166)	DT 0.001 (1.035)	loss nan (nan)	prob nan (nan)	GS 32.078 (32.078)	mem 42.439
Train: [22][725/750]	BT 0.107 (1.159)	DT 0.007 (1.028)	loss nan (nan)	prob nan (nan)	GS 29.297 (29.297)	mem 42.440
Train: [22][730/750]	BT 0.082 (1.166)	DT 0.001 (1.035)	loss nan (nan)	prob nan (nan)	GS 33.734 (33.734)	mem 42.200
Train: [22][735/750]	BT 0.189 (1.159)	DT 0.022 (1.028)	loss nan (nan)	prob nan (nan)	GS 36.984 (36.984)	mem 42.163
Train: [22][740/750]	BT 0.052 (1.161)	DT 0.001 (1.030)	loss nan (nan)	prob nan (nan)	GS 33.328 (33.328)	mem 13.041
Train: [22][745/750]	BT 0.051 (1.153)	DT 0.001 (1.023)	loss nan (nan)	prob nan (nan)	GS 33.312 (33.312)	mem 13.041
Train: [22][750/750]	BT 1.551 (1.148)	DT 1.476 (1.018)	loss nan (nan)	prob nan (nan)	GS 29.250 (29.250)	mem 10.090
Train: [22][755/750]	BT 0.063 (1.141)	DT 0.001 (1.011)	loss nan (nan)	prob nan (nan)	GS 32.094 (32.094)	mem 10.088
epoch 22, total time 861.70
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [23][1/750]	BT 23.760 (23.760)	DT 23.661 (23.661)	loss nan (nan)	prob nan (nan)	GS 30.047 (30.047)	mem 41.651
Train: [23][5/750]	BT 0.122 (5.015)	DT 0.001 (4.857)	loss nan (nan)	prob nan (nan)	GS 35.875 (35.875)	mem 41.594
Train: [23][10/750]	BT 0.160 (2.589)	DT 0.016 (2.431)	loss nan (nan)	prob nan (nan)	GS 33.859 (33.859)	mem 41.690
Train: [23][15/750]	BT 0.150 (2.329)	DT 0.002 (2.167)	loss nan (nan)	prob nan (nan)	GS 26.734 (26.734)	mem 41.888
Train: [23][20/750]	BT 0.070 (2.190)	DT 0.001 (2.035)	loss nan (nan)	prob nan (nan)	GS 32.422 (32.422)	mem 41.972
Train: [23][25/750]	BT 0.205 (1.777)	DT 0.017 (1.629)	loss nan (nan)	prob nan (nan)	GS 30.797 (30.797)	mem 41.981
Train: [23][30/750]	BT 0.086 (1.891)	DT 0.002 (1.740)	loss nan (nan)	prob nan (nan)	GS 36.812 (36.812)	mem 41.996
Train: [23][35/750]	BT 0.119 (1.636)	DT 0.002 (1.492)	loss nan (nan)	prob nan (nan)	GS 31.062 (31.062)	mem 42.151
Train: [23][40/750]	BT 10.682 (1.807)	DT 10.587 (1.656)	loss nan (nan)	prob nan (nan)	GS 32.422 (32.422)	mem 42.114
Train: [23][45/750]	BT 0.088 (1.617)	DT 0.002 (1.472)	loss nan (nan)	prob nan (nan)	GS 25.641 (25.641)	mem 42.115
Train: [23][50/750]	BT 0.145 (1.468)	DT 0.008 (1.325)	loss nan (nan)	prob nan (nan)	GS 32.312 (32.312)	mem 42.116
Train: [23][55/750]	BT 0.118 (1.514)	DT 0.001 (1.372)	loss nan (nan)	prob nan (nan)	GS 28.641 (28.641)	mem 42.235
Train: [23][60/750]	BT 0.137 (1.399)	DT 0.002 (1.258)	loss nan (nan)	prob nan (nan)	GS 30.703 (30.703)	mem 42.192
Train: [23][65/750]	BT 0.178 (1.506)	DT 0.005 (1.360)	loss nan (nan)	prob nan (nan)	GS 33.344 (33.344)	mem 42.225
Train: [23][70/750]	BT 0.119 (1.446)	DT 0.011 (1.300)	loss nan (nan)	prob nan (nan)	GS 31.609 (31.609)	mem 42.219
Train: [23][75/750]	BT 0.132 (1.369)	DT 0.001 (1.226)	loss nan (nan)	prob nan (nan)	GS 31.312 (31.312)	mem 42.282
Train: [23][80/750]	BT 4.902 (1.447)	DT 4.823 (1.304)	loss nan (nan)	prob nan (nan)	GS 35.344 (35.344)	mem 42.235
Train: [23][85/750]	BT 0.081 (1.369)	DT 0.004 (1.227)	loss nan (nan)	prob nan (nan)	GS 43.094 (43.094)	mem 42.235
Train: [23][90/750]	BT 0.137 (1.330)	DT 0.015 (1.188)	loss nan (nan)	prob nan (nan)	GS 36.344 (36.344)	mem 42.265
Train: [23][95/750]	BT 0.076 (1.360)	DT 0.001 (1.221)	loss nan (nan)	prob nan (nan)	GS 31.719 (31.719)	mem 42.263
Train: [23][100/750]	BT 1.878 (1.318)	DT 1.654 (1.176)	loss nan (nan)	prob nan (nan)	GS 37.641 (37.641)	mem 42.276
Train: [23][105/750]	BT 0.092 (1.342)	DT 0.002 (1.202)	loss nan (nan)	prob nan (nan)	GS 40.562 (40.562)	mem 42.283
Train: [23][110/750]	BT 5.703 (1.339)	DT 5.606 (1.199)	loss nan (nan)	prob nan (nan)	GS 35.578 (35.578)	mem 42.177
Train: [23][115/750]	BT 0.176 (1.287)	DT 0.010 (1.147)	loss nan (nan)	prob nan (nan)	GS 32.609 (32.609)	mem 42.189
Train: [23][120/750]	BT 0.104 (1.277)	DT 0.006 (1.136)	loss nan (nan)	prob nan (nan)	GS 33.672 (33.672)	mem 42.332
Train: [23][125/750]	BT 0.121 (1.290)	DT 0.002 (1.150)	loss nan (nan)	prob nan (nan)	GS 33.484 (33.484)	mem 42.285
Train: [23][130/750]	BT 0.182 (1.286)	DT 0.011 (1.146)	loss nan (nan)	prob nan (nan)	GS 33.688 (33.688)	mem 42.351
Train: [23][135/750]	BT 0.131 (1.287)	DT 0.020 (1.146)	loss nan (nan)	prob nan (nan)	GS 31.531 (31.531)	mem 42.443
Train: [23][140/750]	BT 3.312 (1.282)	DT 3.101 (1.141)	loss nan (nan)	prob nan (nan)	GS 31.453 (31.453)	mem 42.342
Train: [23][145/750]	BT 0.119 (1.243)	DT 0.002 (1.101)	loss nan (nan)	prob nan (nan)	GS 29.641 (29.641)	mem 42.414
Train: [23][150/750]	BT 0.075 (1.259)	DT 0.002 (1.118)	loss nan (nan)	prob nan (nan)	GS 33.078 (33.078)	mem 42.326
Train: [23][155/750]	BT 0.184 (1.231)	DT 0.002 (1.091)	loss nan (nan)	prob nan (nan)	GS 33.719 (33.719)	mem 42.359
Train: [23][160/750]	BT 0.394 (1.260)	DT 0.259 (1.121)	loss nan (nan)	prob nan (nan)	GS 35.891 (35.891)	mem 42.348
Train: [23][165/750]	BT 0.128 (1.255)	DT 0.001 (1.116)	loss nan (nan)	prob nan (nan)	GS 28.953 (28.953)	mem 42.466
Train: [23][170/750]	BT 4.653 (1.249)	DT 4.554 (1.110)	loss nan (nan)	prob nan (nan)	GS 33.391 (33.391)	mem 42.382
Train: [23][175/750]	BT 0.184 (1.234)	DT 0.003 (1.095)	loss nan (nan)	prob nan (nan)	GS 26.766 (26.766)	mem 42.395
Train: [23][180/750]	BT 0.215 (1.217)	DT 0.002 (1.077)	loss nan (nan)	prob nan (nan)	GS 32.734 (32.734)	mem 42.437
Train: [23][185/750]	BT 0.091 (1.234)	DT 0.004 (1.095)	loss nan (nan)	prob nan (nan)	GS 29.484 (29.484)	mem 42.465
Train: [23][190/750]	BT 0.090 (1.227)	DT 0.002 (1.089)	loss nan (nan)	prob nan (nan)	GS 33.094 (33.094)	mem 42.726
Train: [23][195/750]	BT 0.123 (1.245)	DT 0.002 (1.107)	loss nan (nan)	prob nan (nan)	GS 33.781 (33.781)	mem 42.435
Train: [23][200/750]	BT 3.164 (1.232)	DT 3.067 (1.095)	loss nan (nan)	prob nan (nan)	GS 38.922 (38.922)	mem 42.466
Train: [23][205/750]	BT 0.137 (1.206)	DT 0.037 (1.069)	loss nan (nan)	prob nan (nan)	GS 33.234 (33.234)	mem 42.469
Train: [23][210/750]	BT 0.090 (1.220)	DT 0.001 (1.085)	loss nan (nan)	prob nan (nan)	GS 34.234 (34.234)	mem 42.467
Train: [23][215/750]	BT 0.129 (1.217)	DT 0.001 (1.081)	loss nan (nan)	prob nan (nan)	GS 31.609 (31.609)	mem 42.443
Train: [23][220/750]	BT 0.108 (1.242)	DT 0.001 (1.107)	loss nan (nan)	prob nan (nan)	GS 36.500 (36.500)	mem 42.466
Train: [23][225/750]	BT 0.155 (1.218)	DT 0.007 (1.083)	loss nan (nan)	prob nan (nan)	GS 31.062 (31.062)	mem 42.483
Train: [23][230/750]	BT 8.770 (1.233)	DT 8.581 (1.097)	loss nan (nan)	prob nan (nan)	GS 36.781 (36.781)	mem 42.381
Train: [23][235/750]	BT 0.200 (1.209)	DT 0.002 (1.073)	loss nan (nan)	prob nan (nan)	GS 39.359 (39.359)	mem 42.386
Train: [23][240/750]	BT 0.086 (1.194)	DT 0.002 (1.058)	loss nan (nan)	prob nan (nan)	GS 31.984 (31.984)	mem 42.406
Train: [23][245/750]	BT 0.097 (1.203)	DT 0.003 (1.067)	loss nan (nan)	prob nan (nan)	GS 31.047 (31.047)	mem 42.312
Train: [23][250/750]	BT 0.089 (1.200)	DT 0.005 (1.064)	loss nan (nan)	prob nan (nan)	GS 37.938 (37.938)	mem 42.397
Train: [23][255/750]	BT 0.142 (1.218)	DT 0.002 (1.082)	loss nan (nan)	prob nan (nan)	GS 32.188 (32.188)	mem 42.459
Train: [23][260/750]	BT 3.543 (1.210)	DT 3.389 (1.075)	loss nan (nan)	prob nan (nan)	GS 30.953 (30.953)	mem 42.571
Train: [23][265/750]	BT 0.124 (1.190)	DT 0.009 (1.055)	loss nan (nan)	prob nan (nan)	GS 35.938 (35.938)	mem 42.225
Train: [23][270/750]	BT 0.087 (1.200)	DT 0.002 (1.065)	loss nan (nan)	prob nan (nan)	GS 31.312 (31.312)	mem 42.340
Train: [23][275/750]	BT 0.195 (1.193)	DT 0.018 (1.058)	loss nan (nan)	prob nan (nan)	GS 31.000 (31.000)	mem 42.514
Train: [23][280/750]	BT 0.187 (1.198)	DT 0.001 (1.062)	loss nan (nan)	prob nan (nan)	GS 34.703 (34.703)	mem 42.390
Train: [23][285/750]	BT 0.131 (1.189)	DT 0.002 (1.054)	loss nan (nan)	prob nan (nan)	GS 36.266 (36.266)	mem 42.507
Train: [23][290/750]	BT 7.639 (1.196)	DT 7.530 (1.062)	loss nan (nan)	prob nan (nan)	GS 31.641 (31.641)	mem 42.493
Train: [23][295/750]	BT 0.100 (1.178)	DT 0.010 (1.044)	loss nan (nan)	prob nan (nan)	GS 29.703 (29.703)	mem 42.390
Train: [23][300/750]	BT 0.143 (1.171)	DT 0.002 (1.037)	loss nan (nan)	prob nan (nan)	GS 30.375 (30.375)	mem 42.328
Train: [23][305/750]	BT 0.126 (1.186)	DT 0.008 (1.053)	loss nan (nan)	prob nan (nan)	GS 29.734 (29.734)	mem 42.406
Train: [23][310/750]	BT 0.166 (1.174)	DT 0.004 (1.040)	loss nan (nan)	prob nan (nan)	GS 35.250 (35.250)	mem 42.603
Train: [23][315/750]	BT 0.086 (1.198)	DT 0.002 (1.064)	loss nan (nan)	prob nan (nan)	GS 34.219 (34.219)	mem 42.369
Train: [23][320/750]	BT 0.873 (1.183)	DT 0.724 (1.050)	loss nan (nan)	prob nan (nan)	GS 32.922 (32.922)	mem 42.314
Train: [23][325/750]	BT 0.184 (1.167)	DT 0.002 (1.034)	loss nan (nan)	prob nan (nan)	GS 29.047 (29.047)	mem 42.397
Train: [23][330/750]	BT 0.072 (1.181)	DT 0.001 (1.049)	loss nan (nan)	prob nan (nan)	GS 31.484 (31.484)	mem 42.314
Train: [23][335/750]	BT 0.128 (1.171)	DT 0.008 (1.039)	loss nan (nan)	prob nan (nan)	GS 33.453 (33.453)	mem 42.379
Train: [23][340/750]	BT 0.173 (1.185)	DT 0.002 (1.053)	loss nan (nan)	prob nan (nan)	GS 36.281 (36.281)	mem 42.428
Train: [23][345/750]	BT 0.102 (1.173)	DT 0.002 (1.040)	loss nan (nan)	prob nan (nan)	GS 26.562 (26.562)	mem 42.271
Train: [23][350/750]	BT 8.363 (1.181)	DT 8.238 (1.049)	loss nan (nan)	prob nan (nan)	GS 32.359 (32.359)	mem 42.349
Train: [23][355/750]	BT 0.111 (1.166)	DT 0.009 (1.034)	loss nan (nan)	prob nan (nan)	GS 33.703 (33.703)	mem 42.368
Train: [23][360/750]	BT 0.235 (1.160)	DT 0.012 (1.028)	loss nan (nan)	prob nan (nan)	GS 32.734 (32.734)	mem 42.295
Train: [23][365/750]	BT 0.179 (1.168)	DT 0.004 (1.036)	loss nan (nan)	prob nan (nan)	GS 33.891 (33.891)	mem 42.481
Train: [23][370/750]	BT 0.168 (1.155)	DT 0.005 (1.022)	loss nan (nan)	prob nan (nan)	GS 33.828 (33.828)	mem 42.397
Train: [23][375/750]	BT 0.102 (1.163)	DT 0.002 (1.030)	loss nan (nan)	prob nan (nan)	GS 28.250 (28.250)	mem 42.424
Train: [23][380/750]	BT 0.844 (1.152)	DT 0.717 (1.019)	loss nan (nan)	prob nan (nan)	GS 33.391 (33.391)	mem 42.461
Train: [23][385/750]	BT 0.089 (1.138)	DT 0.002 (1.006)	loss nan (nan)	prob nan (nan)	GS 29.625 (29.625)	mem 42.487
Train: [23][390/750]	BT 0.188 (1.159)	DT 0.002 (1.027)	loss nan (nan)	prob nan (nan)	GS 32.375 (32.375)	mem 42.361
Train: [23][395/750]	BT 0.144 (1.147)	DT 0.002 (1.014)	loss nan (nan)	prob nan (nan)	GS 28.281 (28.281)	mem 42.360
Train: [23][400/750]	BT 0.080 (1.163)	DT 0.001 (1.030)	loss nan (nan)	prob nan (nan)	GS 34.547 (34.547)	mem 42.394
Train: [23][405/750]	BT 0.155 (1.151)	DT 0.009 (1.018)	loss nan (nan)	prob nan (nan)	GS 35.797 (35.797)	mem 42.410
Train: [23][410/750]	BT 12.355 (1.168)	DT 12.237 (1.035)	loss nan (nan)	prob nan (nan)	GS 34.531 (34.531)	mem 42.285
Train: [23][415/750]	BT 0.111 (1.156)	DT 0.005 (1.023)	loss nan (nan)	prob nan (nan)	GS 28.828 (28.828)	mem 42.315
Train: [23][420/750]	BT 0.100 (1.143)	DT 0.002 (1.011)	loss nan (nan)	prob nan (nan)	GS 36.516 (36.516)	mem 42.319
Train: [23][425/750]	BT 0.114 (1.161)	DT 0.017 (1.029)	loss nan (nan)	prob nan (nan)	GS 29.594 (29.594)	mem 42.561
Train: [23][430/750]	BT 0.152 (1.149)	DT 0.003 (1.017)	loss nan (nan)	prob nan (nan)	GS 39.141 (39.141)	mem 42.547
Train: [23][435/750]	BT 0.065 (1.163)	DT 0.001 (1.031)	loss nan (nan)	prob nan (nan)	GS 34.672 (34.672)	mem 42.401
Train: [23][440/750]	BT 0.113 (1.151)	DT 0.002 (1.020)	loss nan (nan)	prob nan (nan)	GS 37.250 (37.250)	mem 42.400
Train: [23][445/750]	BT 0.133 (1.142)	DT 0.004 (1.011)	loss nan (nan)	prob nan (nan)	GS 37.062 (37.062)	mem 42.405
Train: [23][450/750]	BT 0.088 (1.161)	DT 0.002 (1.029)	loss nan (nan)	prob nan (nan)	GS 32.062 (32.062)	mem 42.565
Train: [23][455/750]	BT 0.116 (1.149)	DT 0.001 (1.018)	loss nan (nan)	prob nan (nan)	GS 30.203 (30.203)	mem 42.433
Train: [23][460/750]	BT 0.119 (1.166)	DT 0.002 (1.035)	loss nan (nan)	prob nan (nan)	GS 31.453 (31.453)	mem 42.366
Train: [23][465/750]	BT 0.127 (1.155)	DT 0.002 (1.024)	loss nan (nan)	prob nan (nan)	GS 26.891 (26.891)	mem 42.339
Train: [23][470/750]	BT 11.840 (1.173)	DT 11.712 (1.041)	loss nan (nan)	prob nan (nan)	GS 31.859 (31.859)	mem 42.741
Train: [23][475/750]	BT 0.080 (1.161)	DT 0.001 (1.030)	loss nan (nan)	prob nan (nan)	GS 47.078 (47.078)	mem 42.387
Train: [23][480/750]	BT 0.262 (1.150)	DT 0.010 (1.020)	loss nan (nan)	prob nan (nan)	GS 35.281 (35.281)	mem 42.415
Train: [23][485/750]	BT 0.100 (1.164)	DT 0.011 (1.033)	loss nan (nan)	prob nan (nan)	GS 30.438 (30.438)	mem 42.444
Train: [23][490/750]	BT 0.155 (1.153)	DT 0.005 (1.023)	loss nan (nan)	prob nan (nan)	GS 36.141 (36.141)	mem 42.409
Train: [23][495/750]	BT 0.058 (1.168)	DT 0.001 (1.038)	loss nan (nan)	prob nan (nan)	GS 30.969 (30.969)	mem 42.341
Train: [23][500/750]	BT 0.177 (1.158)	DT 0.014 (1.028)	loss nan (nan)	prob nan (nan)	GS 33.688 (33.688)	mem 42.366
Train: [23][505/750]	BT 0.123 (1.148)	DT 0.002 (1.018)	loss nan (nan)	prob nan (nan)	GS 31.094 (31.094)	mem 42.415
Train: [23][510/750]	BT 0.110 (1.158)	DT 0.006 (1.028)	loss nan (nan)	prob nan (nan)	GS 32.656 (32.656)	mem 42.376
Train: [23][515/750]	BT 0.299 (1.149)	DT 0.049 (1.018)	loss nan (nan)	prob nan (nan)	GS 30.719 (30.719)	mem 42.516
Train: [23][520/750]	BT 0.156 (1.156)	DT 0.012 (1.025)	loss nan (nan)	prob nan (nan)	GS 34.922 (34.922)	mem 42.546
Train: [23][525/750]	BT 0.100 (1.146)	DT 0.016 (1.016)	loss nan (nan)	prob nan (nan)	GS 33.297 (33.297)	mem 42.430
Train: [23][530/750]	BT 11.555 (1.158)	DT 11.443 (1.028)	loss nan (nan)	prob nan (nan)	GS 31.797 (31.797)	mem 42.464
Train: [23][535/750]	BT 0.083 (1.149)	DT 0.002 (1.018)	loss nan (nan)	prob nan (nan)	GS 34.656 (34.656)	mem 42.466
Train: [23][540/750]	BT 0.157 (1.140)	DT 0.001 (1.009)	loss nan (nan)	prob nan (nan)	GS 32.656 (32.656)	mem 42.468
Train: [23][545/750]	BT 0.071 (1.151)	DT 0.002 (1.020)	loss nan (nan)	prob nan (nan)	GS 32.891 (32.891)	mem 42.484
Train: [23][550/750]	BT 0.118 (1.142)	DT 0.029 (1.011)	loss nan (nan)	prob nan (nan)	GS 32.281 (32.281)	mem 42.576
Train: [23][555/750]	BT 0.118 (1.150)	DT 0.007 (1.020)	loss nan (nan)	prob nan (nan)	GS 30.766 (30.766)	mem 42.484
Train: [23][560/750]	BT 0.092 (1.141)	DT 0.002 (1.011)	loss nan (nan)	prob nan (nan)	GS 33.062 (33.062)	mem 42.485
Train: [23][565/750]	BT 0.107 (1.136)	DT 0.001 (1.006)	loss nan (nan)	prob nan (nan)	GS 32.016 (32.016)	mem 42.536
Train: [23][570/750]	BT 0.125 (1.150)	DT 0.002 (1.020)	loss nan (nan)	prob nan (nan)	GS 33.531 (33.531)	mem 42.301
Train: [23][575/750]	BT 0.098 (1.141)	DT 0.002 (1.011)	loss nan (nan)	prob nan (nan)	GS 28.781 (28.781)	mem 42.336
Train: [23][580/750]	BT 0.248 (1.150)	DT 0.010 (1.020)	loss nan (nan)	prob nan (nan)	GS 32.125 (32.125)	mem 42.380
Train: [23][585/750]	BT 0.161 (1.141)	DT 0.008 (1.011)	loss nan (nan)	prob nan (nan)	GS 30.422 (30.422)	mem 42.414
Train: [23][590/750]	BT 14.875 (1.158)	DT 14.799 (1.028)	loss nan (nan)	prob nan (nan)	GS 36.781 (36.781)	mem 42.461
Train: [23][595/750]	BT 0.107 (1.149)	DT 0.002 (1.019)	loss nan (nan)	prob nan (nan)	GS 29.516 (29.516)	mem 42.503
Train: [23][600/750]	BT 0.087 (1.141)	DT 0.001 (1.011)	loss nan (nan)	prob nan (nan)	GS 36.391 (36.391)	mem 42.468
Train: [23][605/750]	BT 0.109 (1.148)	DT 0.001 (1.018)	loss nan (nan)	prob nan (nan)	GS 31.141 (31.141)	mem 42.498
Train: [23][610/750]	BT 0.135 (1.140)	DT 0.003 (1.009)	loss nan (nan)	prob nan (nan)	GS 32.469 (32.469)	mem 42.614
Train: [23][615/750]	BT 0.156 (1.157)	DT 0.001 (1.026)	loss nan (nan)	prob nan (nan)	GS 32.828 (32.828)	mem 42.419
Train: [23][620/750]	BT 0.233 (1.149)	DT 0.002 (1.018)	loss nan (nan)	prob nan (nan)	GS 33.844 (33.844)	mem 42.430
Train: [23][625/750]	BT 0.216 (1.141)	DT 0.015 (1.010)	loss nan (nan)	prob nan (nan)	GS 27.359 (27.359)	mem 42.529
Train: [23][630/750]	BT 0.163 (1.155)	DT 0.002 (1.025)	loss nan (nan)	prob nan (nan)	GS 30.094 (30.094)	mem 42.415
Train: [23][635/750]	BT 0.171 (1.147)	DT 0.002 (1.016)	loss nan (nan)	prob nan (nan)	GS 33.953 (33.953)	mem 42.623
Train: [23][640/750]	BT 0.081 (1.156)	DT 0.002 (1.025)	loss nan (nan)	prob nan (nan)	GS 34.078 (34.078)	mem 42.568
Train: [23][645/750]	BT 0.144 (1.148)	DT 0.018 (1.017)	loss nan (nan)	prob nan (nan)	GS 27.609 (27.609)	mem 42.659
Train: [23][650/750]	BT 9.646 (1.155)	DT 9.537 (1.024)	loss nan (nan)	prob nan (nan)	GS 31.609 (31.609)	mem 42.447
Train: [23][655/750]	BT 0.165 (1.147)	DT 0.002 (1.016)	loss nan (nan)	prob nan (nan)	GS 34.422 (34.422)	mem 42.358
Train: [23][660/750]	BT 0.157 (1.140)	DT 0.003 (1.009)	loss nan (nan)	prob nan (nan)	GS 31.875 (31.875)	mem 42.360
Train: [23][665/750]	BT 0.088 (1.151)	DT 0.002 (1.020)	loss nan (nan)	prob nan (nan)	GS 30.656 (30.656)	mem 42.490
Train: [23][670/750]	BT 0.180 (1.144)	DT 0.002 (1.013)	loss nan (nan)	prob nan (nan)	GS 32.969 (32.969)	mem 42.488
Train: [23][675/750]	BT 0.138 (1.151)	DT 0.002 (1.020)	loss nan (nan)	prob nan (nan)	GS 38.562 (38.562)	mem 42.519
Train: [23][680/750]	BT 0.207 (1.143)	DT 0.002 (1.013)	loss nan (nan)	prob nan (nan)	GS 31.797 (31.797)	mem 42.520
Train: [23][685/750]	BT 0.130 (1.137)	DT 0.002 (1.006)	loss nan (nan)	prob nan (nan)	GS 35.812 (35.812)	mem 42.705
Train: [23][690/750]	BT 0.090 (1.147)	DT 0.001 (1.016)	loss nan (nan)	prob nan (nan)	GS 33.078 (33.078)	mem 42.495
Train: [23][695/750]	BT 0.269 (1.140)	DT 0.038 (1.009)	loss nan (nan)	prob nan (nan)	GS 28.000 (28.000)	mem 42.792
Train: [23][700/750]	BT 0.126 (1.153)	DT 0.010 (1.022)	loss nan (nan)	prob nan (nan)	GS 37.266 (37.266)	mem 42.358
Train: [23][705/750]	BT 0.121 (1.145)	DT 0.001 (1.015)	loss nan (nan)	prob nan (nan)	GS 32.797 (32.797)	mem 42.359
arpack error, retry= 0
arpack error, retry= 0
Train: [23][710/750]	BT 8.744 (1.152)	DT 8.556 (1.021)	loss nan (nan)	prob nan (nan)	GS 31.172 (31.172)	mem 42.460
Train: [23][715/750]	BT 0.175 (1.145)	DT 0.011 (1.014)	loss nan (nan)	prob nan (nan)	GS 31.844 (31.844)	mem 42.643
Train: [23][720/750]	BT 3.345 (1.142)	DT 3.183 (1.011)	loss nan (nan)	prob nan (nan)	GS 33.438 (33.438)	mem 42.469
Train: [23][725/750]	BT 0.102 (1.145)	DT 0.002 (1.015)	loss nan (nan)	prob nan (nan)	GS 31.531 (31.531)	mem 42.369
Train: [23][730/750]	BT 0.114 (1.138)	DT 0.002 (1.008)	loss nan (nan)	prob nan (nan)	GS 35.984 (35.984)	mem 42.369
Train: [23][735/750]	BT 0.061 (1.143)	DT 0.001 (1.013)	loss nan (nan)	prob nan (nan)	GS 30.547 (30.547)	mem 39.025
Train: [23][740/750]	BT 0.096 (1.136)	DT 0.001 (1.006)	loss nan (nan)	prob nan (nan)	GS 33.656 (33.656)	mem 39.022
Train: [23][745/750]	BT 0.127 (1.132)	DT 0.001 (1.002)	loss nan (nan)	prob nan (nan)	GS 25.938 (25.938)	mem 13.112
Train: [23][750/750]	BT 0.054 (1.125)	DT 0.001 (0.995)	loss nan (nan)	prob nan (nan)	GS 41.156 (41.156)	mem 13.076
Train: [23][755/750]	BT 0.055 (1.118)	DT 0.001 (0.989)	loss nan (nan)	prob nan (nan)	GS 32.844 (32.844)	mem 13.084
epoch 23, total time 846.47
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [24][1/750]	BT 24.071 (24.071)	DT 23.840 (23.840)	loss nan (nan)	prob nan (nan)	GS 29.938 (29.938)	mem 41.224
Train: [24][5/750]	BT 0.135 (5.307)	DT 0.001 (5.129)	loss nan (nan)	prob nan (nan)	GS 27.359 (27.359)	mem 41.239
Train: [24][10/750]	BT 0.134 (2.757)	DT 0.002 (2.590)	loss nan (nan)	prob nan (nan)	GS 33.844 (33.844)	mem 41.290
Train: [24][15/750]	BT 0.090 (2.379)	DT 0.002 (2.230)	loss nan (nan)	prob nan (nan)	GS 28.719 (28.719)	mem 41.298
Train: [24][20/750]	BT 0.102 (2.070)	DT 0.002 (1.928)	loss nan (nan)	prob nan (nan)	GS 31.828 (31.828)	mem 41.457
Train: [24][25/750]	BT 3.287 (1.811)	DT 3.129 (1.669)	loss nan (nan)	prob nan (nan)	GS 28.453 (28.453)	mem 41.487
Train: [24][30/750]	BT 0.120 (2.041)	DT 0.003 (1.897)	loss nan (nan)	prob nan (nan)	GS 34.516 (34.516)	mem 41.428
Train: [24][35/750]	BT 0.075 (1.767)	DT 0.001 (1.627)	loss nan (nan)	prob nan (nan)	GS 31.109 (31.109)	mem 41.432
Train: [24][40/750]	BT 10.322 (1.855)	DT 10.177 (1.720)	loss nan (nan)	prob nan (nan)	GS 35.266 (35.266)	mem 41.383
Train: [24][45/750]	BT 0.076 (1.663)	DT 0.001 (1.529)	loss nan (nan)	prob nan (nan)	GS 30.719 (30.719)	mem 41.393
Train: [24][50/750]	BT 1.211 (1.529)	DT 1.074 (1.398)	loss nan (nan)	prob nan (nan)	GS 33.703 (33.703)	mem 41.315
Train: [24][55/750]	BT 0.114 (1.594)	DT 0.002 (1.462)	loss nan (nan)	prob nan (nan)	GS 31.438 (31.438)	mem 41.465
Train: [24][60/750]	BT 0.125 (1.471)	DT 0.001 (1.340)	loss nan (nan)	prob nan (nan)	GS 32.297 (32.297)	mem 41.467
Train: [24][65/750]	BT 0.118 (1.538)	DT 0.002 (1.407)	loss nan (nan)	prob nan (nan)	GS 34.438 (34.438)	mem 41.506
Train: [24][70/750]	BT 0.151 (1.439)	DT 0.004 (1.307)	loss nan (nan)	prob nan (nan)	GS 31.359 (31.359)	mem 41.666
Train: [24][75/750]	BT 0.075 (1.349)	DT 0.001 (1.220)	loss nan (nan)	prob nan (nan)	GS 32.578 (32.578)	mem 41.460
Train: [24][80/750]	BT 0.081 (1.425)	DT 0.002 (1.297)	loss nan (nan)	prob nan (nan)	GS 37.969 (37.969)	mem 41.483
Train: [24][85/750]	BT 0.112 (1.348)	DT 0.004 (1.221)	loss nan (nan)	prob nan (nan)	GS 33.375 (33.375)	mem 41.487
Train: [24][90/750]	BT 0.113 (1.412)	DT 0.001 (1.286)	loss nan (nan)	prob nan (nan)	GS 36.031 (36.031)	mem 41.521
Train: [24][95/750]	BT 0.096 (1.345)	DT 0.001 (1.218)	loss nan (nan)	prob nan (nan)	GS 27.297 (27.297)	mem 41.527
Train: [24][100/750]	BT 10.643 (1.389)	DT 10.413 (1.262)	loss nan (nan)	prob nan (nan)	GS 31.172 (31.172)	mem 41.574
Train: [24][105/750]	BT 0.144 (1.329)	DT 0.018 (1.202)	loss nan (nan)	prob nan (nan)	GS 30.031 (30.031)	mem 41.576
Train: [24][110/750]	BT 0.092 (1.274)	DT 0.002 (1.147)	loss nan (nan)	prob nan (nan)	GS 32.047 (32.047)	mem 41.531
Train: [24][115/750]	BT 0.121 (1.345)	DT 0.002 (1.219)	loss nan (nan)	prob nan (nan)	GS 30.625 (30.625)	mem 41.699
Train: [24][120/750]	BT 0.119 (1.293)	DT 0.001 (1.169)	loss nan (nan)	prob nan (nan)	GS 34.906 (34.906)	mem 41.746
Train: [24][125/750]	BT 0.129 (1.327)	DT 0.005 (1.203)	loss nan (nan)	prob nan (nan)	GS 28.047 (28.047)	mem 41.914
Train: [24][130/750]	BT 0.106 (1.281)	DT 0.004 (1.157)	loss nan (nan)	prob nan (nan)	GS 32.750 (32.750)	mem 41.918
Train: [24][135/750]	BT 0.079 (1.237)	DT 0.001 (1.114)	loss nan (nan)	prob nan (nan)	GS 32.859 (32.859)	mem 41.951
Train: [24][140/750]	BT 0.087 (1.280)	DT 0.002 (1.157)	loss nan (nan)	prob nan (nan)	GS 34.047 (34.047)	mem 41.788
Train: [24][145/750]	BT 0.193 (1.240)	DT 0.008 (1.118)	loss nan (nan)	prob nan (nan)	GS 26.156 (26.156)	mem 41.803
Train: [24][150/750]	BT 0.080 (1.277)	DT 0.002 (1.156)	loss nan (nan)	prob nan (nan)	GS 30.328 (30.328)	mem 41.880
Train: [24][155/750]	BT 0.096 (1.240)	DT 0.004 (1.119)	loss nan (nan)	prob nan (nan)	GS 28.484 (28.484)	mem 41.906
Train: [24][160/750]	BT 13.385 (1.289)	DT 13.266 (1.167)	loss nan (nan)	prob nan (nan)	GS 39.875 (39.875)	mem 41.918
Train: [24][165/750]	BT 0.287 (1.255)	DT 0.004 (1.132)	loss nan (nan)	prob nan (nan)	GS 38.297 (38.297)	mem 41.966
Train: [24][170/750]	BT 0.170 (1.222)	DT 0.008 (1.098)	loss nan (nan)	prob nan (nan)	GS 30.359 (30.359)	mem 41.942
Train: [24][175/750]	BT 0.077 (1.253)	DT 0.001 (1.130)	loss nan (nan)	prob nan (nan)	GS 30.688 (30.688)	mem 42.163
Train: [24][180/750]	BT 0.218 (1.222)	DT 0.002 (1.098)	loss nan (nan)	prob nan (nan)	GS 35.875 (35.875)	mem 42.166
Train: [24][185/750]	BT 0.092 (1.253)	DT 0.002 (1.130)	loss nan (nan)	prob nan (nan)	GS 31.016 (31.016)	mem 42.228
Train: [24][190/750]	BT 0.100 (1.224)	DT 0.001 (1.101)	loss nan (nan)	prob nan (nan)	GS 30.953 (30.953)	mem 42.229
Train: [24][195/750]	BT 0.129 (1.196)	DT 0.003 (1.072)	loss nan (nan)	prob nan (nan)	GS 30.812 (30.812)	mem 42.233
Train: [24][200/750]	BT 0.218 (1.226)	DT 0.024 (1.102)	loss nan (nan)	prob nan (nan)	GS 35.516 (35.516)	mem 42.165
Train: [24][205/750]	BT 0.177 (1.200)	DT 0.002 (1.076)	loss nan (nan)	prob nan (nan)	GS 29.812 (29.812)	mem 42.218
Train: [24][210/750]	BT 0.070 (1.227)	DT 0.001 (1.103)	loss nan (nan)	prob nan (nan)	GS 30.469 (30.469)	mem 42.206
Train: [24][215/750]	BT 0.240 (1.202)	DT 0.039 (1.078)	loss nan (nan)	prob nan (nan)	GS 30.109 (30.109)	mem 42.209
Train: [24][220/750]	BT 13.991 (1.241)	DT 13.895 (1.117)	loss nan (nan)	prob nan (nan)	GS 32.688 (32.688)	mem 42.270
Train: [24][225/750]	BT 0.100 (1.217)	DT 0.001 (1.092)	loss nan (nan)	prob nan (nan)	GS 26.812 (26.812)	mem 42.271
Train: [24][230/750]	BT 0.123 (1.193)	DT 0.001 (1.068)	loss nan (nan)	prob nan (nan)	GS 32.625 (32.625)	mem 42.295
Train: [24][235/750]	BT 0.088 (1.222)	DT 0.001 (1.098)	loss nan (nan)	prob nan (nan)	GS 29.984 (29.984)	mem 42.238
Train: [24][240/750]	BT 0.168 (1.200)	DT 0.001 (1.075)	loss nan (nan)	prob nan (nan)	GS 33.062 (33.062)	mem 42.299
Train: [24][245/750]	BT 0.093 (1.226)	DT 0.001 (1.102)	loss nan (nan)	prob nan (nan)	GS 32.625 (32.625)	mem 42.293
Train: [24][250/750]	BT 0.099 (1.204)	DT 0.001 (1.080)	loss nan (nan)	prob nan (nan)	GS 31.328 (31.328)	mem 42.297
Train: [24][255/750]	BT 0.108 (1.183)	DT 0.002 (1.059)	loss nan (nan)	prob nan (nan)	GS 33.047 (33.047)	mem 42.300
Train: [24][260/750]	BT 0.103 (1.202)	DT 0.001 (1.078)	loss nan (nan)	prob nan (nan)	GS 33.344 (33.344)	mem 42.361
Train: [24][265/750]	BT 0.138 (1.182)	DT 0.004 (1.058)	loss nan (nan)	prob nan (nan)	GS 31.484 (31.484)	mem 42.367
Train: [24][270/750]	BT 0.088 (1.217)	DT 0.001 (1.093)	loss nan (nan)	prob nan (nan)	GS 34.812 (34.812)	mem 42.348
Train: [24][275/750]	BT 0.102 (1.197)	DT 0.008 (1.073)	loss nan (nan)	prob nan (nan)	GS 32.516 (32.516)	mem 42.178
Train: [24][280/750]	BT 9.663 (1.213)	DT 9.495 (1.088)	loss nan (nan)	prob nan (nan)	GS 33.781 (33.781)	mem 42.334
Train: [24][285/750]	BT 0.088 (1.193)	DT 0.002 (1.069)	loss nan (nan)	prob nan (nan)	GS 34.500 (34.500)	mem 42.299
Train: [24][290/750]	BT 0.176 (1.175)	DT 0.002 (1.051)	loss nan (nan)	prob nan (nan)	GS 30.797 (30.797)	mem 42.301
Train: [24][295/750]	BT 0.136 (1.198)	DT 0.002 (1.074)	loss nan (nan)	prob nan (nan)	GS 32.594 (32.594)	mem 42.371
Train: [24][300/750]	BT 0.247 (1.181)	DT 0.002 (1.056)	loss nan (nan)	prob nan (nan)	GS 31.172 (31.172)	mem 42.374
Train: [24][305/750]	BT 0.138 (1.207)	DT 0.001 (1.081)	loss nan (nan)	prob nan (nan)	GS 28.672 (28.672)	mem 42.305
Train: [24][310/750]	BT 0.111 (1.189)	DT 0.001 (1.064)	loss nan (nan)	prob nan (nan)	GS 38.109 (38.109)	mem 42.308
Train: [24][315/750]	BT 0.153 (1.172)	DT 0.009 (1.047)	loss nan (nan)	prob nan (nan)	GS 28.719 (28.719)	mem 42.358
Train: [24][320/750]	BT 0.122 (1.197)	DT 0.017 (1.073)	loss nan (nan)	prob nan (nan)	GS 36.109 (36.109)	mem 42.267
Train: [24][325/750]	BT 0.157 (1.180)	DT 0.001 (1.056)	loss nan (nan)	prob nan (nan)	GS 31.812 (31.812)	mem 42.259
Train: [24][330/750]	BT 0.122 (1.194)	DT 0.002 (1.070)	loss nan (nan)	prob nan (nan)	GS 35.781 (35.781)	mem 42.378
Train: [24][335/750]	BT 0.058 (1.178)	DT 0.001 (1.054)	loss nan (nan)	prob nan (nan)	GS 33.047 (33.047)	mem 42.379
Train: [24][340/750]	BT 12.076 (1.198)	DT 11.974 (1.074)	loss nan (nan)	prob nan (nan)	GS 33.844 (33.844)	mem 42.229
Train: [24][345/750]	BT 0.087 (1.182)	DT 0.001 (1.058)	loss nan (nan)	prob nan (nan)	GS 27.188 (27.188)	mem 42.194
Train: [24][350/750]	BT 0.111 (1.167)	DT 0.002 (1.043)	loss nan (nan)	prob nan (nan)	GS 36.188 (36.188)	mem 42.178
Train: [24][355/750]	BT 0.067 (1.187)	DT 0.001 (1.064)	loss nan (nan)	prob nan (nan)	GS 29.500 (29.500)	mem 42.142
Train: [24][360/750]	BT 0.112 (1.172)	DT 0.002 (1.049)	loss nan (nan)	prob nan (nan)	GS 31.203 (31.203)	mem 42.089
Train: [24][365/750]	BT 0.104 (1.183)	DT 0.011 (1.060)	loss nan (nan)	prob nan (nan)	GS 31.438 (31.438)	mem 42.260
Train: [24][370/750]	BT 0.159 (1.169)	DT 0.010 (1.045)	loss nan (nan)	prob nan (nan)	GS 33.594 (33.594)	mem 42.431
Train: [24][375/750]	BT 0.140 (1.155)	DT 0.002 (1.031)	loss nan (nan)	prob nan (nan)	GS 29.156 (29.156)	mem 42.373
Train: [24][380/750]	BT 0.078 (1.175)	DT 0.007 (1.051)	loss nan (nan)	prob nan (nan)	GS 34.391 (34.391)	mem 42.147
Train: [24][385/750]	BT 0.211 (1.162)	DT 0.003 (1.038)	loss nan (nan)	prob nan (nan)	GS 33.984 (33.984)	mem 42.202
Train: [24][390/750]	BT 0.085 (1.174)	DT 0.001 (1.050)	loss nan (nan)	prob nan (nan)	GS 37.641 (37.641)	mem 42.320
Train: [24][395/750]	BT 0.170 (1.161)	DT 0.006 (1.037)	loss nan (nan)	prob nan (nan)	GS 33.516 (33.516)	mem 42.318
Train: [24][400/750]	BT 10.262 (1.174)	DT 10.189 (1.050)	loss nan (nan)	prob nan (nan)	GS 30.078 (30.078)	mem 42.302
Train: [24][405/750]	BT 0.101 (1.160)	DT 0.001 (1.037)	loss nan (nan)	prob nan (nan)	GS 31.719 (31.719)	mem 42.368
Train: [24][410/750]	BT 0.180 (1.148)	DT 0.002 (1.024)	loss nan (nan)	prob nan (nan)	GS 35.047 (35.047)	mem 42.479
Train: [24][415/750]	BT 0.080 (1.163)	DT 0.002 (1.039)	loss nan (nan)	prob nan (nan)	GS 34.219 (34.219)	mem 42.396
Train: [24][420/750]	BT 0.093 (1.150)	DT 0.001 (1.027)	loss nan (nan)	prob nan (nan)	GS 33.938 (33.938)	mem 42.395
Train: [24][425/750]	BT 0.071 (1.171)	DT 0.002 (1.048)	loss nan (nan)	prob nan (nan)	GS 32.078 (32.078)	mem 42.347
Train: [24][430/750]	BT 0.107 (1.158)	DT 0.003 (1.035)	loss nan (nan)	prob nan (nan)	GS 32.859 (32.859)	mem 42.347
Train: [24][435/750]	BT 0.206 (1.147)	DT 0.003 (1.024)	loss nan (nan)	prob nan (nan)	GS 35.625 (35.625)	mem 42.478
Train: [24][440/750]	BT 0.101 (1.167)	DT 0.007 (1.043)	loss nan (nan)	prob nan (nan)	GS 37.562 (37.562)	mem 42.394
Train: [24][445/750]	BT 0.079 (1.155)	DT 0.002 (1.032)	loss nan (nan)	prob nan (nan)	GS 35.203 (35.203)	mem 42.383
Train: [24][450/750]	BT 0.207 (1.168)	DT 0.009 (1.044)	loss nan (nan)	prob nan (nan)	GS 37.938 (37.938)	mem 42.328
Train: [24][455/750]	BT 0.124 (1.156)	DT 0.002 (1.033)	loss nan (nan)	prob nan (nan)	GS 34.641 (34.641)	mem 42.327
Train: [24][460/750]	BT 7.291 (1.165)	DT 7.137 (1.042)	loss nan (nan)	prob nan (nan)	GS 30.828 (30.828)	mem 42.513
Train: [24][465/750]	BT 0.119 (1.154)	DT 0.002 (1.031)	loss nan (nan)	prob nan (nan)	GS 32.094 (32.094)	mem 42.412
Train: [24][470/750]	BT 3.150 (1.150)	DT 3.050 (1.026)	loss nan (nan)	prob nan (nan)	GS 36.625 (36.625)	mem 42.427
Train: [24][475/750]	BT 0.123 (1.160)	DT 0.016 (1.035)	loss nan (nan)	prob nan (nan)	GS 33.281 (33.281)	mem 42.769
Train: [24][480/750]	BT 0.128 (1.151)	DT 0.002 (1.026)	loss nan (nan)	prob nan (nan)	GS 32.531 (32.531)	mem 42.338
Train: [24][485/750]	BT 0.097 (1.164)	DT 0.002 (1.040)	loss nan (nan)	prob nan (nan)	GS 33.188 (33.188)	mem 42.373
Train: [24][490/750]	BT 1.891 (1.157)	DT 1.757 (1.033)	loss nan (nan)	prob nan (nan)	GS 37.844 (37.844)	mem 42.328
Train: [24][495/750]	BT 0.165 (1.147)	DT 0.013 (1.022)	loss nan (nan)	prob nan (nan)	GS 32.703 (32.703)	mem 42.364
Train: [24][500/750]	BT 0.148 (1.153)	DT 0.002 (1.028)	loss nan (nan)	prob nan (nan)	GS 34.859 (34.859)	mem 42.437
Train: [24][505/750]	BT 0.143 (1.149)	DT 0.002 (1.024)	loss nan (nan)	prob nan (nan)	GS 30.625 (30.625)	mem 42.487
Train: [24][510/750]	BT 0.133 (1.154)	DT 0.002 (1.029)	loss nan (nan)	prob nan (nan)	GS 33.578 (33.578)	mem 42.525
Train: [24][515/750]	BT 0.120 (1.151)	DT 0.007 (1.025)	loss nan (nan)	prob nan (nan)	GS 34.359 (34.359)	mem 42.429
Train: [24][520/750]	BT 8.151 (1.156)	DT 8.043 (1.031)	loss nan (nan)	prob nan (nan)	GS 35.031 (35.031)	mem 42.423
Train: [24][525/750]	BT 0.130 (1.147)	DT 0.002 (1.021)	loss nan (nan)	prob nan (nan)	GS 31.688 (31.688)	mem 42.532
Train: [24][530/750]	BT 0.116 (1.141)	DT 0.002 (1.016)	loss nan (nan)	prob nan (nan)	GS 34.609 (34.609)	mem 42.634
Train: [24][535/750]	BT 0.091 (1.143)	DT 0.003 (1.017)	loss nan (nan)	prob nan (nan)	GS 32.688 (32.688)	mem 42.460
Train: [24][540/750]	BT 0.079 (1.146)	DT 0.002 (1.020)	loss nan (nan)	prob nan (nan)	GS 35.672 (35.672)	mem 42.444
Train: [24][545/750]	BT 0.142 (1.142)	DT 0.001 (1.016)	loss nan (nan)	prob nan (nan)	GS 31.094 (31.094)	mem 42.407
Train: [24][550/750]	BT 4.490 (1.145)	DT 4.360 (1.019)	loss nan (nan)	prob nan (nan)	GS 32.781 (32.781)	mem 42.437
Train: [24][555/750]	BT 0.120 (1.149)	DT 0.002 (1.024)	loss nan (nan)	prob nan (nan)	GS 31.391 (31.391)	mem 42.419
Train: [24][560/750]	BT 0.113 (1.140)	DT 0.002 (1.015)	loss nan (nan)	prob nan (nan)	GS 31.797 (31.797)	mem 42.357
Train: [24][565/750]	BT 0.120 (1.138)	DT 0.005 (1.013)	loss nan (nan)	prob nan (nan)	GS 31.719 (31.719)	mem 42.589
Train: [24][570/750]	BT 0.894 (1.145)	DT 0.803 (1.019)	loss nan (nan)	prob nan (nan)	GS 33.281 (33.281)	mem 42.564
Train: [24][575/750]	BT 0.172 (1.143)	DT 0.011 (1.018)	loss nan (nan)	prob nan (nan)	GS 28.422 (28.422)	mem 42.468
Train: [24][580/750]	BT 0.120 (1.143)	DT 0.001 (1.017)	loss nan (nan)	prob nan (nan)	GS 32.047 (32.047)	mem 42.452
Train: [24][585/750]	BT 0.218 (1.140)	DT 0.011 (1.014)	loss nan (nan)	prob nan (nan)	GS 32.641 (32.641)	mem 42.468
Train: [24][590/750]	BT 7.315 (1.146)	DT 7.230 (1.020)	loss nan (nan)	prob nan (nan)	GS 33.766 (33.766)	mem 42.371
Train: [24][595/750]	BT 0.121 (1.141)	DT 0.001 (1.015)	loss nan (nan)	prob nan (nan)	GS 31.969 (31.969)	mem 42.403
Train: [24][600/750]	BT 0.093 (1.142)	DT 0.006 (1.016)	loss nan (nan)	prob nan (nan)	GS 34.766 (34.766)	mem 42.726
Train: [24][605/750]	BT 0.178 (1.138)	DT 0.001 (1.012)	loss nan (nan)	prob nan (nan)	GS 33.906 (33.906)	mem 42.664
Train: [24][610/750]	BT 4.361 (1.146)	DT 4.183 (1.020)	loss nan (nan)	prob nan (nan)	GS 36.578 (36.578)	mem 42.501
Train: [24][615/750]	BT 0.093 (1.146)	DT 0.001 (1.020)	loss nan (nan)	prob nan (nan)	GS 31.578 (31.578)	mem 42.559
Train: [24][620/750]	BT 0.116 (1.147)	DT 0.014 (1.021)	loss nan (nan)	prob nan (nan)	GS 36.234 (36.234)	mem 42.325
Train: [24][625/750]	BT 0.091 (1.147)	DT 0.002 (1.021)	loss nan (nan)	prob nan (nan)	GS 28.422 (28.422)	mem 42.309
Train: [24][630/750]	BT 3.933 (1.145)	DT 3.826 (1.019)	loss nan (nan)	prob nan (nan)	GS 30.906 (30.906)	mem 42.352
Train: [24][635/750]	BT 0.102 (1.152)	DT 0.002 (1.026)	loss nan (nan)	prob nan (nan)	GS 33.125 (33.125)	mem 42.295
Train: [24][640/750]	BT 2.731 (1.148)	DT 2.540 (1.022)	loss nan (nan)	prob nan (nan)	GS 37.078 (37.078)	mem 42.360
Train: [24][645/750]	BT 0.147 (1.140)	DT 0.001 (1.014)	loss nan (nan)	prob nan (nan)	GS 27.750 (27.750)	mem 42.363
Train: [24][650/750]	BT 0.164 (1.142)	DT 0.058 (1.015)	loss nan (nan)	prob nan (nan)	GS 34.656 (34.656)	mem 42.397
Train: [24][655/750]	BT 0.205 (1.143)	DT 0.001 (1.016)	loss nan (nan)	prob nan (nan)	GS 32.750 (32.750)	mem 42.441
Train: [24][660/750]	BT 0.161 (1.143)	DT 0.002 (1.016)	loss nan (nan)	prob nan (nan)	GS 34.766 (34.766)	mem 42.402
Train: [24][665/750]	BT 0.138 (1.145)	DT 0.006 (1.018)	loss nan (nan)	prob nan (nan)	GS 33.781 (33.781)	mem 42.419
Train: [24][670/750]	BT 2.990 (1.142)	DT 2.848 (1.014)	loss nan (nan)	prob nan (nan)	GS 33.719 (33.719)	mem 42.309
Train: [24][675/750]	BT 0.087 (1.145)	DT 0.002 (1.018)	loss nan (nan)	prob nan (nan)	GS 36.859 (36.859)	mem 42.322
Train: [24][680/750]	BT 0.189 (1.144)	DT 0.002 (1.016)	loss nan (nan)	prob nan (nan)	GS 37.562 (37.562)	mem 42.365
Train: [24][685/750]	BT 0.165 (1.139)	DT 0.005 (1.011)	loss nan (nan)	prob nan (nan)	GS 32.375 (32.375)	mem 42.381
Train: [24][690/750]	BT 0.153 (1.145)	DT 0.001 (1.017)	loss nan (nan)	prob nan (nan)	GS 32.969 (32.969)	mem 42.611
Train: [24][695/750]	BT 0.104 (1.140)	DT 0.002 (1.012)	loss nan (nan)	prob nan (nan)	GS 34.344 (34.344)	mem 42.565
Train: [24][700/750]	BT 5.429 (1.148)	DT 5.260 (1.020)	loss nan (nan)	prob nan (nan)	GS 34.781 (34.781)	mem 42.448
Train: [24][705/750]	BT 0.171 (1.141)	DT 0.006 (1.013)	loss nan (nan)	prob nan (nan)	GS 31.078 (31.078)	mem 42.513
arpack error, retry= 0
Train: [24][710/750]	BT 1.888 (1.140)	DT 1.697 (1.012)	loss nan (nan)	prob nan (nan)	GS 33.625 (33.625)	mem 42.539
Train: [24][715/750]	BT 0.136 (1.143)	DT 0.003 (1.015)	loss nan (nan)	prob nan (nan)	GS 32.312 (32.312)	mem 42.419
Train: [24][720/750]	BT 0.108 (1.144)	DT 0.007 (1.015)	loss nan (nan)	prob nan (nan)	GS 34.125 (34.125)	mem 42.369
Train: [24][725/750]	BT 0.219 (1.147)	DT 0.026 (1.018)	loss nan (nan)	prob nan (nan)	GS 28.953 (28.953)	mem 42.293
Train: [24][730/750]	BT 0.813 (1.140)	DT 0.663 (1.012)	loss nan (nan)	prob nan (nan)	GS 31.219 (31.219)	mem 42.153
Train: [24][735/750]	BT 0.164 (1.137)	DT 0.002 (1.009)	loss nan (nan)	prob nan (nan)	GS 31.688 (31.688)	mem 39.150
Train: [24][740/750]	BT 0.071 (1.141)	DT 0.001 (1.012)	loss nan (nan)	prob nan (nan)	GS 31.625 (31.625)	mem 18.966
Train: [24][745/750]	BT 0.068 (1.135)	DT 0.001 (1.007)	loss nan (nan)	prob nan (nan)	GS 33.656 (33.656)	mem 18.878
Train: [24][750/750]	BT 1.107 (1.130)	DT 1.011 (1.002)	loss nan (nan)	prob nan (nan)	GS 33.438 (33.438)	mem 15.945
Train: [24][755/750]	BT 0.065 (1.125)	DT 0.001 (0.997)	loss nan (nan)	prob nan (nan)	GS 32.125 (32.125)	mem 9.984
epoch 24, total time 849.30
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [25][1/750]	BT 22.079 (22.079)	DT 21.890 (21.890)	loss nan (nan)	prob nan (nan)	GS 32.328 (32.328)	mem 41.058
Train: [25][5/750]	BT 0.128 (4.751)	DT 0.002 (4.620)	loss nan (nan)	prob nan (nan)	GS 31.047 (31.047)	mem 41.143
Train: [25][10/750]	BT 0.226 (2.460)	DT 0.002 (2.313)	loss nan (nan)	prob nan (nan)	GS 34.906 (34.906)	mem 41.445
Train: [25][15/750]	BT 0.286 (2.779)	DT 0.010 (2.604)	loss nan (nan)	prob nan (nan)	GS 32.656 (32.656)	mem 41.338
Train: [25][20/750]	BT 0.112 (2.119)	DT 0.011 (1.955)	loss nan (nan)	prob nan (nan)	GS 34.266 (34.266)	mem 41.305
Train: [25][25/750]	BT 2.436 (1.813)	DT 2.310 (1.657)	loss nan (nan)	prob nan (nan)	GS 35.641 (35.641)	mem 41.337
Train: [25][30/750]	BT 0.292 (1.848)	DT 0.010 (1.685)	loss nan (nan)	prob nan (nan)	GS 36.531 (36.531)	mem 41.420
Train: [25][35/750]	BT 0.226 (1.602)	DT 0.002 (1.445)	loss nan (nan)	prob nan (nan)	GS 31.312 (31.312)	mem 41.424
Train: [25][40/750]	BT 0.219 (1.707)	DT 0.018 (1.552)	loss nan (nan)	prob nan (nan)	GS 30.734 (30.734)	mem 41.486
Train: [25][45/750]	BT 0.090 (1.529)	DT 0.003 (1.380)	loss nan (nan)	prob nan (nan)	GS 29.359 (29.359)	mem 41.516
Train: [25][50/750]	BT 11.914 (1.625)	DT 11.763 (1.477)	loss nan (nan)	prob nan (nan)	GS 36.984 (36.984)	mem 41.859
Train: [25][55/750]	BT 0.111 (1.488)	DT 0.001 (1.344)	loss nan (nan)	prob nan (nan)	GS 32.734 (32.734)	mem 41.717
Train: [25][60/750]	BT 0.182 (1.375)	DT 0.004 (1.232)	loss nan (nan)	prob nan (nan)	GS 31.359 (31.359)	mem 41.978
Train: [25][65/750]	BT 0.075 (1.502)	DT 0.002 (1.362)	loss nan (nan)	prob nan (nan)	GS 26.672 (26.672)	mem 42.038
Train: [25][70/750]	BT 0.064 (1.402)	DT 0.001 (1.265)	loss nan (nan)	prob nan (nan)	GS 37.516 (37.516)	mem 41.965
Train: [25][75/750]	BT 0.083 (1.482)	DT 0.003 (1.347)	loss nan (nan)	prob nan (nan)	GS 29.547 (29.547)	mem 42.170
Train: [25][80/750]	BT 0.124 (1.396)	DT 0.021 (1.263)	loss nan (nan)	prob nan (nan)	GS 33.625 (33.625)	mem 42.175
Train: [25][85/750]	BT 0.128 (1.321)	DT 0.002 (1.189)	loss nan (nan)	prob nan (nan)	GS 29.781 (29.781)	mem 42.177
Train: [25][90/750]	BT 0.134 (1.373)	DT 0.003 (1.240)	loss nan (nan)	prob nan (nan)	GS 32.547 (32.547)	mem 42.203
Train: [25][95/750]	BT 0.198 (1.309)	DT 0.001 (1.175)	loss nan (nan)	prob nan (nan)	GS 27.953 (27.953)	mem 42.172
Train: [25][100/750]	BT 0.162 (1.388)	DT 0.039 (1.255)	loss nan (nan)	prob nan (nan)	GS 34.031 (34.031)	mem 42.429
Train: [25][105/750]	BT 0.093 (1.328)	DT 0.001 (1.195)	loss nan (nan)	prob nan (nan)	GS 29.094 (29.094)	mem 42.214
Train: [25][110/750]	BT 10.820 (1.373)	DT 10.726 (1.239)	loss nan (nan)	prob nan (nan)	GS 33.297 (33.297)	mem 42.324
Train: [25][115/750]	BT 0.089 (1.318)	DT 0.002 (1.185)	loss nan (nan)	prob nan (nan)	GS 25.875 (25.875)	mem 42.402
Train: [25][120/750]	BT 0.127 (1.269)	DT 0.001 (1.136)	loss nan (nan)	prob nan (nan)	GS 35.297 (35.297)	mem 42.292
Train: [25][125/750]	BT 0.085 (1.312)	DT 0.002 (1.181)	loss nan (nan)	prob nan (nan)	GS 32.547 (32.547)	mem 42.262
Train: [25][130/750]	BT 0.149 (1.267)	DT 0.002 (1.135)	loss nan (nan)	prob nan (nan)	GS 38.000 (38.000)	mem 42.260
Train: [25][135/750]	BT 0.059 (1.326)	DT 0.001 (1.196)	loss nan (nan)	prob nan (nan)	GS 29.484 (29.484)	mem 42.246
Train: [25][140/750]	BT 0.105 (1.282)	DT 0.018 (1.153)	loss nan (nan)	prob nan (nan)	GS 31.328 (31.328)	mem 42.249
Train: [25][145/750]	BT 0.171 (1.242)	DT 0.005 (1.113)	loss nan (nan)	prob nan (nan)	GS 27.688 (27.688)	mem 42.279
Train: [25][150/750]	BT 0.102 (1.287)	DT 0.001 (1.160)	loss nan (nan)	prob nan (nan)	GS 36.344 (36.344)	mem 42.249
Train: [25][155/750]	BT 0.149 (1.250)	DT 0.001 (1.122)	loss nan (nan)	prob nan (nan)	GS 30.672 (30.672)	mem 42.256
Train: [25][160/750]	BT 0.076 (1.284)	DT 0.001 (1.158)	loss nan (nan)	prob nan (nan)	GS 32.453 (32.453)	mem 42.318
Train: [25][165/750]	BT 0.099 (1.248)	DT 0.003 (1.123)	loss nan (nan)	prob nan (nan)	GS 31.328 (31.328)	mem 42.318
Train: [25][170/750]	BT 11.379 (1.281)	DT 11.246 (1.156)	loss nan (nan)	prob nan (nan)	GS 36.516 (36.516)	mem 42.300
Train: [25][175/750]	BT 0.112 (1.248)	DT 0.002 (1.123)	loss nan (nan)	prob nan (nan)	GS 32.062 (32.062)	mem 42.229
Train: [25][180/750]	BT 0.134 (1.217)	DT 0.005 (1.092)	loss nan (nan)	prob nan (nan)	GS 34.906 (34.906)	mem 42.232
Train: [25][185/750]	BT 0.073 (1.254)	DT 0.001 (1.130)	loss nan (nan)	prob nan (nan)	GS 29.156 (29.156)	mem 42.315
Train: [25][190/750]	BT 0.105 (1.224)	DT 0.001 (1.101)	loss nan (nan)	prob nan (nan)	GS 35.844 (35.844)	mem 42.315
Train: [25][195/750]	BT 0.078 (1.255)	DT 0.001 (1.132)	loss nan (nan)	prob nan (nan)	GS 33.062 (33.062)	mem 42.310
Train: [25][200/750]	BT 0.088 (1.226)	DT 0.001 (1.104)	loss nan (nan)	prob nan (nan)	GS 38.391 (38.391)	mem 42.312
Train: [25][205/750]	BT 0.114 (1.198)	DT 0.001 (1.077)	loss nan (nan)	prob nan (nan)	GS 31.531 (31.531)	mem 42.322
Train: [25][210/750]	BT 0.095 (1.224)	DT 0.003 (1.104)	loss nan (nan)	prob nan (nan)	GS 29.688 (29.688)	mem 42.390
Train: [25][215/750]	BT 0.143 (1.199)	DT 0.003 (1.078)	loss nan (nan)	prob nan (nan)	GS 34.125 (34.125)	mem 42.296
Train: [25][220/750]	BT 0.103 (1.251)	DT 0.001 (1.130)	loss nan (nan)	prob nan (nan)	GS 32.984 (32.984)	mem 42.348
Train: [25][225/750]	BT 0.133 (1.225)	DT 0.007 (1.105)	loss nan (nan)	prob nan (nan)	GS 30.250 (30.250)	mem 42.403
Train: [25][230/750]	BT 11.917 (1.253)	DT 11.840 (1.133)	loss nan (nan)	prob nan (nan)	GS 36.109 (36.109)	mem 42.469
Train: [25][235/750]	BT 0.184 (1.229)	DT 0.020 (1.109)	loss nan (nan)	prob nan (nan)	GS 31.406 (31.406)	mem 42.407
Train: [25][240/750]	BT 0.138 (1.206)	DT 0.002 (1.086)	loss nan (nan)	prob nan (nan)	GS 34.828 (34.828)	mem 42.424
Train: [25][245/750]	BT 0.079 (1.228)	DT 0.002 (1.109)	loss nan (nan)	prob nan (nan)	GS 32.609 (32.609)	mem 42.452
Train: [25][250/750]	BT 0.135 (1.206)	DT 0.001 (1.087)	loss nan (nan)	prob nan (nan)	GS 31.656 (31.656)	mem 42.559
Train: [25][255/750]	BT 0.098 (1.236)	DT 0.002 (1.117)	loss nan (nan)	prob nan (nan)	GS 29.234 (29.234)	mem 42.337
Train: [25][260/750]	BT 0.130 (1.215)	DT 0.002 (1.096)	loss nan (nan)	prob nan (nan)	GS 32.875 (32.875)	mem 42.356
Train: [25][265/750]	BT 0.155 (1.194)	DT 0.009 (1.075)	loss nan (nan)	prob nan (nan)	GS 31.031 (31.031)	mem 42.212
Train: [25][270/750]	BT 0.087 (1.212)	DT 0.002 (1.092)	loss nan (nan)	prob nan (nan)	GS 35.641 (35.641)	mem 42.333
Train: [25][275/750]	BT 0.122 (1.192)	DT 0.002 (1.072)	loss nan (nan)	prob nan (nan)	GS 32.766 (32.766)	mem 42.575
Train: [25][280/750]	BT 0.108 (1.225)	DT 0.002 (1.105)	loss nan (nan)	prob nan (nan)	GS 35.172 (35.172)	mem 42.352
Train: [25][285/750]	BT 0.095 (1.205)	DT 0.001 (1.086)	loss nan (nan)	prob nan (nan)	GS 31.641 (31.641)	mem 42.354
Train: [25][290/750]	BT 10.360 (1.222)	DT 10.158 (1.102)	loss nan (nan)	prob nan (nan)	GS 35.594 (35.594)	mem 42.378
Train: [25][295/750]	BT 0.192 (1.204)	DT 0.002 (1.084)	loss nan (nan)	prob nan (nan)	GS 30.141 (30.141)	mem 42.406
Train: [25][300/750]	BT 0.119 (1.186)	DT 0.014 (1.066)	loss nan (nan)	prob nan (nan)	GS 32.281 (32.281)	mem 42.349
Train: [25][305/750]	BT 0.100 (1.198)	DT 0.017 (1.077)	loss nan (nan)	prob nan (nan)	GS 33.438 (33.438)	mem 42.457
Train: [25][310/750]	BT 0.091 (1.180)	DT 0.001 (1.060)	loss nan (nan)	prob nan (nan)	GS 28.672 (28.672)	mem 42.456
Train: [25][315/750]	BT 0.115 (1.201)	DT 0.019 (1.081)	loss nan (nan)	prob nan (nan)	GS 29.141 (29.141)	mem 42.541
Train: [25][320/750]	BT 0.104 (1.185)	DT 0.001 (1.064)	loss nan (nan)	prob nan (nan)	GS 34.625 (34.625)	mem 42.547
Train: [25][325/750]	BT 0.198 (1.169)	DT 0.002 (1.047)	loss nan (nan)	prob nan (nan)	GS 40.438 (40.438)	mem 42.819
Train: [25][330/750]	BT 0.121 (1.191)	DT 0.002 (1.071)	loss nan (nan)	prob nan (nan)	GS 37.766 (37.766)	mem 42.518
Train: [25][335/750]	BT 0.161 (1.176)	DT 0.007 (1.055)	loss nan (nan)	prob nan (nan)	GS 29.391 (29.391)	mem 42.438
Train: [25][340/750]	BT 0.089 (1.195)	DT 0.002 (1.074)	loss nan (nan)	prob nan (nan)	GS 31.469 (31.469)	mem 42.451
Train: [25][345/750]	BT 0.094 (1.179)	DT 0.001 (1.058)	loss nan (nan)	prob nan (nan)	GS 35.906 (35.906)	mem 42.412
Train: [25][350/750]	BT 11.115 (1.196)	DT 11.025 (1.075)	loss nan (nan)	prob nan (nan)	GS 33.859 (33.859)	mem 42.403
Train: [25][355/750]	BT 0.098 (1.181)	DT 0.002 (1.060)	loss nan (nan)	prob nan (nan)	GS 31.422 (31.422)	mem 42.404
Train: [25][360/750]	BT 0.086 (1.166)	DT 0.001 (1.045)	loss nan (nan)	prob nan (nan)	GS 38.031 (38.031)	mem 42.470
Train: [25][365/750]	BT 0.174 (1.175)	DT 0.002 (1.054)	loss nan (nan)	prob nan (nan)	GS 33.516 (33.516)	mem 42.465
Train: [25][370/750]	BT 0.129 (1.162)	DT 0.006 (1.040)	loss nan (nan)	prob nan (nan)	GS 34.203 (34.203)	mem 42.675
Train: [25][375/750]	BT 0.112 (1.181)	DT 0.010 (1.059)	loss nan (nan)	prob nan (nan)	GS 30.469 (30.469)	mem 42.413
Train: [25][380/750]	BT 0.142 (1.167)	DT 0.002 (1.045)	loss nan (nan)	prob nan (nan)	GS 35.203 (35.203)	mem 42.427
Train: [25][385/750]	BT 0.107 (1.154)	DT 0.002 (1.032)	loss nan (nan)	prob nan (nan)	GS 30.766 (30.766)	mem 42.432
Train: [25][390/750]	BT 0.192 (1.169)	DT 0.001 (1.047)	loss nan (nan)	prob nan (nan)	GS 30.141 (30.141)	mem 42.555
Train: [25][395/750]	BT 0.130 (1.156)	DT 0.001 (1.034)	loss nan (nan)	prob nan (nan)	GS 29.766 (29.766)	mem 42.460
Train: [25][400/750]	BT 0.099 (1.174)	DT 0.003 (1.053)	loss nan (nan)	prob nan (nan)	GS 34.453 (34.453)	mem 42.416
Train: [25][405/750]	BT 0.214 (1.162)	DT 0.022 (1.040)	loss nan (nan)	prob nan (nan)	GS 34.703 (34.703)	mem 42.359
Train: [25][410/750]	BT 11.336 (1.176)	DT 11.161 (1.054)	loss nan (nan)	prob nan (nan)	GS 32.031 (32.031)	mem 42.394
Train: [25][415/750]	BT 0.124 (1.164)	DT 0.008 (1.042)	loss nan (nan)	prob nan (nan)	GS 32.156 (32.156)	mem 42.329
Train: [25][420/750]	BT 0.080 (1.151)	DT 0.005 (1.029)	loss nan (nan)	prob nan (nan)	GS 32.672 (32.672)	mem 42.470
Train: [25][425/750]	BT 0.084 (1.168)	DT 0.002 (1.046)	loss nan (nan)	prob nan (nan)	GS 31.219 (31.219)	mem 42.326
Train: [25][430/750]	BT 0.087 (1.156)	DT 0.001 (1.034)	loss nan (nan)	prob nan (nan)	GS 33.406 (33.406)	mem 42.436
Train: [25][435/750]	BT 0.184 (1.169)	DT 0.002 (1.047)	loss nan (nan)	prob nan (nan)	GS 32.750 (32.750)	mem 42.392
Train: [25][440/750]	BT 1.434 (1.161)	DT 1.205 (1.038)	loss nan (nan)	prob nan (nan)	GS 35.625 (35.625)	mem 42.498
Train: [25][445/750]	BT 0.097 (1.149)	DT 0.002 (1.026)	loss nan (nan)	prob nan (nan)	GS 30.094 (30.094)	mem 42.392
Train: [25][450/750]	BT 0.145 (1.163)	DT 0.002 (1.040)	loss nan (nan)	prob nan (nan)	GS 38.656 (38.656)	mem 42.381
Train: [25][455/750]	BT 0.162 (1.152)	DT 0.003 (1.030)	loss nan (nan)	prob nan (nan)	GS 29.516 (29.516)	mem 42.539
Train: [25][460/750]	BT 0.139 (1.172)	DT 0.013 (1.050)	loss nan (nan)	prob nan (nan)	GS 33.406 (33.406)	mem 42.325
Train: [25][465/750]	BT 0.111 (1.161)	DT 0.001 (1.039)	loss nan (nan)	prob nan (nan)	GS 33.281 (33.281)	mem 42.336
Train: [25][470/750]	BT 10.725 (1.173)	DT 10.525 (1.050)	loss nan (nan)	prob nan (nan)	GS 30.297 (30.297)	mem 42.483
Train: [25][475/750]	BT 0.103 (1.162)	DT 0.002 (1.039)	loss nan (nan)	prob nan (nan)	GS 28.375 (28.375)	mem 42.424
Train: [25][480/750]	BT 0.147 (1.151)	DT 0.006 (1.028)	loss nan (nan)	prob nan (nan)	GS 34.422 (34.422)	mem 42.453
Train: [25][485/750]	BT 0.117 (1.160)	DT 0.013 (1.037)	loss nan (nan)	prob nan (nan)	GS 30.141 (30.141)	mem 42.549
Train: [25][490/750]	BT 0.096 (1.150)	DT 0.006 (1.027)	loss nan (nan)	prob nan (nan)	GS 32.531 (32.531)	mem 42.440
Train: [25][495/750]	BT 0.128 (1.159)	DT 0.002 (1.036)	loss nan (nan)	prob nan (nan)	GS 31.016 (31.016)	mem 42.439
Train: [25][500/750]	BT 0.116 (1.150)	DT 0.003 (1.027)	loss nan (nan)	prob nan (nan)	GS 36.375 (36.375)	mem 42.342
Train: [25][505/750]	BT 0.293 (1.150)	DT 0.026 (1.026)	loss nan (nan)	prob nan (nan)	GS 30.406 (30.406)	mem 42.423
Train: [25][510/750]	BT 0.169 (1.151)	DT 0.010 (1.027)	loss nan (nan)	prob nan (nan)	GS 30.047 (30.047)	mem 42.354
Train: [25][515/750]	BT 0.187 (1.141)	DT 0.012 (1.017)	loss nan (nan)	prob nan (nan)	GS 25.828 (25.828)	mem 42.376
Train: [25][520/750]	BT 3.669 (1.155)	DT 3.505 (1.031)	loss nan (nan)	prob nan (nan)	GS 34.375 (34.375)	mem 42.378
Train: [25][525/750]	BT 0.158 (1.146)	DT 0.007 (1.021)	loss nan (nan)	prob nan (nan)	GS 26.672 (26.672)	mem 42.389
Train: [25][530/750]	BT 2.466 (1.151)	DT 2.380 (1.026)	loss nan (nan)	prob nan (nan)	GS 34.500 (34.500)	mem 42.524
Train: [25][535/750]	BT 0.133 (1.152)	DT 0.009 (1.027)	loss nan (nan)	prob nan (nan)	GS 33.703 (33.703)	mem 42.440
Train: [25][540/750]	BT 6.182 (1.154)	DT 6.058 (1.029)	loss nan (nan)	prob nan (nan)	GS 33.094 (33.094)	mem 42.450
Train: [25][545/750]	BT 0.113 (1.152)	DT 0.008 (1.027)	loss nan (nan)	prob nan (nan)	GS 32.062 (32.062)	mem 42.409
Train: [25][550/750]	BT 0.090 (1.144)	DT 0.016 (1.018)	loss nan (nan)	prob nan (nan)	GS 30.719 (30.719)	mem 42.413
Train: [25][555/750]	BT 0.221 (1.148)	DT 0.002 (1.021)	loss nan (nan)	prob nan (nan)	GS 33.016 (33.016)	mem 42.488
Train: [25][560/750]	BT 0.148 (1.147)	DT 0.002 (1.021)	loss nan (nan)	prob nan (nan)	GS 34.719 (34.719)	mem 42.483
Train: [25][565/750]	BT 0.099 (1.153)	DT 0.003 (1.027)	loss nan (nan)	prob nan (nan)	GS 30.266 (30.266)	mem 42.779
Train: [25][570/750]	BT 0.074 (1.147)	DT 0.001 (1.021)	loss nan (nan)	prob nan (nan)	GS 32.172 (32.172)	mem 42.485
Train: [25][575/750]	BT 0.138 (1.139)	DT 0.011 (1.012)	loss nan (nan)	prob nan (nan)	GS 31.672 (31.672)	mem 42.485
Train: [25][580/750]	BT 2.384 (1.148)	DT 2.296 (1.022)	loss nan (nan)	prob nan (nan)	GS 31.359 (31.359)	mem 42.546
Train: [25][585/750]	BT 0.125 (1.141)	DT 0.001 (1.014)	loss nan (nan)	prob nan (nan)	GS 33.719 (33.719)	mem 42.387
Train: [25][590/750]	BT 0.091 (1.148)	DT 0.002 (1.021)	loss nan (nan)	prob nan (nan)	GS 32.812 (32.812)	mem 42.763
Train: [25][595/750]	BT 0.128 (1.141)	DT 0.002 (1.014)	loss nan (nan)	prob nan (nan)	GS 29.922 (29.922)	mem 42.399
Train: [25][600/750]	BT 10.132 (1.154)	DT 10.030 (1.027)	loss nan (nan)	prob nan (nan)	GS 37.859 (37.859)	mem 42.395
Train: [25][605/750]	BT 0.101 (1.145)	DT 0.002 (1.019)	loss nan (nan)	prob nan (nan)	GS 28.828 (28.828)	mem 42.340
Train: [25][610/750]	BT 0.149 (1.139)	DT 0.001 (1.013)	loss nan (nan)	prob nan (nan)	GS 36.703 (36.703)	mem 42.335
Train: [25][615/750]	BT 0.073 (1.149)	DT 0.002 (1.023)	loss nan (nan)	prob nan (nan)	GS 30.828 (30.828)	mem 42.318
Train: [25][620/750]	BT 0.131 (1.141)	DT 0.040 (1.015)	loss nan (nan)	prob nan (nan)	GS 35.328 (35.328)	mem 42.244
Train: [25][625/750]	BT 0.196 (1.148)	DT 0.002 (1.022)	loss nan (nan)	prob nan (nan)	GS 34.859 (34.859)	mem 42.380
Train: [25][630/750]	BT 0.219 (1.143)	DT 0.004 (1.016)	loss nan (nan)	prob nan (nan)	GS 33.125 (33.125)	mem 42.402
Train: [25][635/750]	BT 0.289 (1.136)	DT 0.038 (1.010)	loss nan (nan)	prob nan (nan)	GS 29.844 (29.844)	mem 42.309
Train: [25][640/750]	BT 0.697 (1.144)	DT 0.604 (1.018)	loss nan (nan)	prob nan (nan)	GS 35.203 (35.203)	mem 42.283
Train: [25][645/750]	BT 0.128 (1.142)	DT 0.002 (1.015)	loss nan (nan)	prob nan (nan)	GS 31.688 (31.688)	mem 42.306
Train: [25][650/750]	BT 0.116 (1.150)	DT 0.007 (1.024)	loss nan (nan)	prob nan (nan)	GS 31.312 (31.312)	mem 42.332
Train: [25][655/750]	BT 0.138 (1.142)	DT 0.001 (1.016)	loss nan (nan)	prob nan (nan)	GS 30.719 (30.719)	mem 42.307
Train: [25][660/750]	BT 13.471 (1.155)	DT 13.343 (1.028)	loss nan (nan)	prob nan (nan)	GS 35.453 (35.453)	mem 42.280
Train: [25][665/750]	BT 0.101 (1.147)	DT 0.002 (1.021)	loss nan (nan)	prob nan (nan)	GS 23.922 (23.922)	mem 42.198
Train: [25][670/750]	BT 0.183 (1.139)	DT 0.001 (1.013)	loss nan (nan)	prob nan (nan)	GS 39.906 (39.906)	mem 42.249
Train: [25][675/750]	BT 0.190 (1.148)	DT 0.008 (1.022)	loss nan (nan)	prob nan (nan)	GS 29.219 (29.219)	mem 42.428
Train: [25][680/750]	BT 0.126 (1.141)	DT 0.001 (1.015)	loss nan (nan)	prob nan (nan)	GS 36.750 (36.750)	mem 42.428
Train: [25][685/750]	BT 0.100 (1.149)	DT 0.001 (1.023)	loss nan (nan)	prob nan (nan)	GS 33.219 (33.219)	mem 42.493
Train: [25][690/750]	BT 0.151 (1.141)	DT 0.002 (1.015)	loss nan (nan)	prob nan (nan)	GS 30.359 (30.359)	mem 42.421
Train: [25][695/750]	BT 0.186 (1.135)	DT 0.012 (1.008)	loss nan (nan)	prob nan (nan)	GS 30.781 (30.781)	mem 42.640
Train: [25][700/750]	BT 0.121 (1.142)	DT 0.001 (1.015)	loss nan (nan)	prob nan (nan)	GS 34.672 (34.672)	mem 42.447
Train: [25][705/750]	BT 0.143 (1.137)	DT 0.002 (1.011)	loss nan (nan)	prob nan (nan)	GS 33.547 (33.547)	mem 42.449
arpack error, retry= 0
arpack error, retry= 0
arpack error, retry= 0
Train: [25][710/750]	BT 1.434 (1.141)	DT 1.345 (1.015)	loss nan (nan)	prob nan (nan)	GS 32.297 (32.297)	mem 42.462
Train: [25][715/750]	BT 0.199 (1.134)	DT 0.035 (1.008)	loss nan (nan)	prob nan (nan)	GS 29.516 (29.516)	mem 42.463
Train: [25][720/750]	BT 4.537 (1.143)	DT 4.446 (1.017)	loss nan (nan)	prob nan (nan)	GS 33.406 (33.406)	mem 42.582
Train: [25][725/750]	BT 0.086 (1.137)	DT 0.001 (1.011)	loss nan (nan)	prob nan (nan)	GS 31.016 (31.016)	mem 42.552
Train: [25][730/750]	BT 3.749 (1.142)	DT 3.660 (1.015)	loss nan (nan)	prob nan (nan)	GS 35.703 (35.703)	mem 42.051
Train: [25][735/750]	BT 0.091 (1.139)	DT 0.002 (1.013)	loss nan (nan)	prob nan (nan)	GS 29.656 (29.656)	mem 39.133
Train: [25][740/750]	BT 1.286 (1.133)	DT 1.172 (1.007)	loss nan (nan)	prob nan (nan)	GS 34.125 (34.125)	mem 19.100
Train: [25][745/750]	BT 0.073 (1.131)	DT 0.001 (1.005)	loss nan (nan)	prob nan (nan)	GS 30.281 (30.281)	mem 13.166
Train: [25][750/750]	BT 0.071 (1.124)	DT 0.001 (0.998)	loss nan (nan)	prob nan (nan)	GS 36.062 (36.062)	mem 13.134
Train: [25][755/750]	BT 0.059 (1.120)	DT 0.001 (0.995)	loss nan (nan)	prob nan (nan)	GS 27.469 (27.469)	mem 13.032
epoch 25, total time 846.52
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [26][1/750]	BT 21.716 (21.716)	DT 21.538 (21.538)	loss nan (nan)	prob nan (nan)	GS 33.438 (33.438)	mem 40.936
Train: [26][5/750]	BT 0.189 (4.883)	DT 0.008 (4.730)	loss nan (nan)	prob nan (nan)	GS 32.516 (32.516)	mem 41.034
Train: [26][10/750]	BT 0.186 (2.512)	DT 0.002 (2.368)	loss nan (nan)	prob nan (nan)	GS 36.438 (36.438)	mem 41.131
Train: [26][15/750]	BT 3.580 (2.494)	DT 3.499 (2.362)	loss nan (nan)	prob nan (nan)	GS 30.266 (30.266)	mem 41.315
Train: [26][20/750]	BT 0.161 (1.969)	DT 0.013 (1.831)	loss nan (nan)	prob nan (nan)	GS 32.141 (32.141)	mem 41.387
Train: [26][25/750]	BT 2.356 (1.696)	DT 2.231 (1.554)	loss nan (nan)	prob nan (nan)	GS 29.797 (29.797)	mem 41.410
Train: [26][30/750]	BT 0.089 (1.749)	DT 0.001 (1.605)	loss nan (nan)	prob nan (nan)	GS 28.531 (28.531)	mem 41.392
Train: [26][35/750]	BT 0.170 (1.524)	DT 0.002 (1.377)	loss nan (nan)	prob nan (nan)	GS 28.125 (28.125)	mem 41.428
Train: [26][40/750]	BT 7.526 (1.697)	DT 7.325 (1.549)	loss nan (nan)	prob nan (nan)	GS 35.234 (35.234)	mem 41.468
Train: [26][45/750]	BT 0.085 (1.523)	DT 0.004 (1.377)	loss nan (nan)	prob nan (nan)	GS 28.266 (28.266)	mem 41.469
Train: [26][50/750]	BT 4.696 (1.476)	DT 4.611 (1.332)	loss nan (nan)	prob nan (nan)	GS 32.969 (32.969)	mem 41.528
Train: [26][55/750]	BT 0.227 (1.469)	DT 0.005 (1.326)	loss nan (nan)	prob nan (nan)	GS 31.062 (31.062)	mem 41.558
Train: [26][60/750]	BT 0.131 (1.357)	DT 0.006 (1.215)	loss nan (nan)	prob nan (nan)	GS 33.016 (33.016)	mem 41.560
Train: [26][65/750]	BT 0.159 (1.491)	DT 0.007 (1.351)	loss nan (nan)	prob nan (nan)	GS 27.219 (27.219)	mem 41.621
Train: [26][70/750]	BT 0.124 (1.393)	DT 0.001 (1.255)	loss nan (nan)	prob nan (nan)	GS 32.219 (32.219)	mem 41.652
Train: [26][75/750]	BT 0.188 (1.313)	DT 0.010 (1.172)	loss nan (nan)	prob nan (nan)	GS 31.922 (31.922)	mem 41.660
Train: [26][80/750]	BT 0.107 (1.421)	DT 0.001 (1.283)	loss nan (nan)	prob nan (nan)	GS 31.344 (31.344)	mem 41.637
Train: [26][85/750]	BT 0.090 (1.347)	DT 0.002 (1.208)	loss nan (nan)	prob nan (nan)	GS 32.672 (32.672)	mem 41.639
Train: [26][90/750]	BT 0.098 (1.392)	DT 0.002 (1.252)	loss nan (nan)	prob nan (nan)	GS 31.828 (31.828)	mem 41.694
Train: [26][95/750]	BT 0.130 (1.325)	DT 0.007 (1.186)	loss nan (nan)	prob nan (nan)	GS 30.047 (30.047)	mem 41.661
Train: [26][100/750]	BT 5.423 (1.389)	DT 5.351 (1.251)	loss nan (nan)	prob nan (nan)	GS 31.797 (31.797)	mem 41.702
Train: [26][105/750]	BT 0.139 (1.329)	DT 0.004 (1.191)	loss nan (nan)	prob nan (nan)	GS 32.859 (32.859)	mem 41.676
Train: [26][110/750]	BT 7.653 (1.343)	DT 7.549 (1.206)	loss nan (nan)	prob nan (nan)	GS 33.844 (33.844)	mem 41.776
Train: [26][115/750]	BT 0.091 (1.316)	DT 0.002 (1.179)	loss nan (nan)	prob nan (nan)	GS 35.750 (35.750)	mem 41.855
Train: [26][120/750]	BT 0.329 (1.272)	DT 0.208 (1.136)	loss nan (nan)	prob nan (nan)	GS 36.484 (36.484)	mem 41.646
Train: [26][125/750]	BT 0.096 (1.313)	DT 0.001 (1.179)	loss nan (nan)	prob nan (nan)	GS 32.281 (32.281)	mem 41.704
Train: [26][130/750]	BT 2.583 (1.287)	DT 2.497 (1.153)	loss nan (nan)	prob nan (nan)	GS 34.250 (34.250)	mem 41.752
Train: [26][135/750]	BT 0.085 (1.326)	DT 0.002 (1.191)	loss nan (nan)	prob nan (nan)	GS 30.797 (30.797)	mem 41.836
Train: [26][140/750]	BT 0.090 (1.283)	DT 0.002 (1.149)	loss nan (nan)	prob nan (nan)	GS 31.453 (31.453)	mem 41.913
Train: [26][145/750]	BT 0.271 (1.260)	DT 0.010 (1.125)	loss nan (nan)	prob nan (nan)	GS 31.422 (31.422)	mem 41.843
Train: [26][150/750]	BT 1.116 (1.286)	DT 0.965 (1.152)	loss nan (nan)	prob nan (nan)	GS 33.406 (33.406)	mem 41.821
Train: [26][155/750]	BT 0.105 (1.262)	DT 0.008 (1.128)	loss nan (nan)	prob nan (nan)	GS 31.453 (31.453)	mem 41.741
Train: [26][160/750]	BT 0.095 (1.290)	DT 0.001 (1.156)	loss nan (nan)	prob nan (nan)	GS 34.172 (34.172)	mem 42.205
Train: [26][165/750]	BT 0.159 (1.255)	DT 0.004 (1.121)	loss nan (nan)	prob nan (nan)	GS 31.125 (31.125)	mem 42.369
Train: [26][170/750]	BT 12.120 (1.308)	DT 12.050 (1.174)	loss nan (nan)	prob nan (nan)	GS 37.359 (37.359)	mem 41.758
Train: [26][175/750]	BT 0.188 (1.275)	DT 0.019 (1.141)	loss nan (nan)	prob nan (nan)	GS 28.016 (28.016)	mem 41.760
Train: [26][180/750]	BT 0.130 (1.243)	DT 0.017 (1.109)	loss nan (nan)	prob nan (nan)	GS 35.703 (35.703)	mem 41.761
Train: [26][185/750]	BT 0.248 (1.278)	DT 0.002 (1.145)	loss nan (nan)	prob nan (nan)	GS 32.750 (32.750)	mem 42.262
Train: [26][190/750]	BT 5.183 (1.274)	DT 5.050 (1.142)	loss nan (nan)	prob nan (nan)	GS 36.328 (36.328)	mem 42.019
Train: [26][195/750]	BT 0.168 (1.272)	DT 0.002 (1.139)	loss nan (nan)	prob nan (nan)	GS 33.312 (33.312)	mem 42.072
Train: [26][200/750]	BT 0.107 (1.256)	DT 0.009 (1.123)	loss nan (nan)	prob nan (nan)	GS 35.875 (35.875)	mem 41.957
Train: [26][205/750]	BT 0.296 (1.250)	DT 0.025 (1.117)	loss nan (nan)	prob nan (nan)	GS 33.484 (33.484)	mem 42.012
Train: [26][210/750]	BT 0.283 (1.254)	DT 0.002 (1.119)	loss nan (nan)	prob nan (nan)	GS 33.672 (33.672)	mem 42.037
Train: [26][215/750]	BT 0.136 (1.246)	DT 0.011 (1.112)	loss nan (nan)	prob nan (nan)	GS 34.391 (34.391)	mem 41.982
Train: [26][220/750]	BT 0.167 (1.253)	DT 0.002 (1.118)	loss nan (nan)	prob nan (nan)	GS 31.703 (31.703)	mem 42.055
Train: [26][225/750]	BT 0.090 (1.228)	DT 0.001 (1.094)	loss nan (nan)	prob nan (nan)	GS 32.500 (32.500)	mem 42.076
Train: [26][230/750]	BT 11.105 (1.266)	DT 10.971 (1.131)	loss nan (nan)	prob nan (nan)	GS 38.484 (38.484)	mem 42.013
Train: [26][235/750]	BT 0.152 (1.242)	DT 0.023 (1.107)	loss nan (nan)	prob nan (nan)	GS 35.766 (35.766)	mem 42.015
Train: [26][240/750]	BT 0.138 (1.219)	DT 0.006 (1.084)	loss nan (nan)	prob nan (nan)	GS 31.234 (31.234)	mem 42.017
Train: [26][245/750]	BT 0.083 (1.241)	DT 0.002 (1.106)	loss nan (nan)	prob nan (nan)	GS 30.750 (30.750)	mem 42.055
Train: [26][250/750]	BT 0.134 (1.219)	DT 0.012 (1.084)	loss nan (nan)	prob nan (nan)	GS 34.203 (34.203)	mem 41.997
Train: [26][255/750]	BT 0.154 (1.249)	DT 0.001 (1.114)	loss nan (nan)	prob nan (nan)	GS 32.469 (32.469)	mem 42.204
Train: [26][260/750]	BT 0.090 (1.227)	DT 0.005 (1.093)	loss nan (nan)	prob nan (nan)	GS 35.750 (35.750)	mem 42.152
Train: [26][265/750]	BT 0.096 (1.207)	DT 0.008 (1.072)	loss nan (nan)	prob nan (nan)	GS 32.250 (32.250)	mem 42.156
Train: [26][270/750]	BT 0.089 (1.236)	DT 0.001 (1.102)	loss nan (nan)	prob nan (nan)	GS 34.219 (34.219)	mem 42.343
Train: [26][275/750]	BT 0.106 (1.215)	DT 0.002 (1.082)	loss nan (nan)	prob nan (nan)	GS 34.438 (34.438)	mem 42.441
Train: [26][280/750]	BT 0.136 (1.237)	DT 0.003 (1.104)	loss nan (nan)	prob nan (nan)	GS 35.656 (35.656)	mem 42.171
Train: [26][285/750]	BT 0.098 (1.217)	DT 0.003 (1.085)	loss nan (nan)	prob nan (nan)	GS 34.359 (34.359)	mem 42.206
Train: [26][290/750]	BT 8.577 (1.228)	DT 8.422 (1.095)	loss nan (nan)	prob nan (nan)	GS 31.750 (31.750)	mem 42.688
Train: [26][295/750]	BT 0.136 (1.210)	DT 0.002 (1.077)	loss nan (nan)	prob nan (nan)	GS 33.312 (33.312)	mem 42.337
Train: [26][300/750]	BT 0.315 (1.194)	DT 0.002 (1.060)	loss nan (nan)	prob nan (nan)	GS 30.516 (30.516)	mem 42.273
Train: [26][305/750]	BT 0.075 (1.213)	DT 0.003 (1.079)	loss nan (nan)	prob nan (nan)	GS 30.703 (30.703)	mem 42.304
Train: [26][310/750]	BT 2.563 (1.204)	DT 2.392 (1.069)	loss nan (nan)	prob nan (nan)	GS 33.016 (33.016)	mem 42.383
Train: [26][315/750]	BT 0.136 (1.220)	DT 0.002 (1.086)	loss nan (nan)	prob nan (nan)	GS 31.719 (31.719)	mem 42.246
Train: [26][320/750]	BT 0.094 (1.203)	DT 0.016 (1.069)	loss nan (nan)	prob nan (nan)	GS 31.266 (31.266)	mem 42.262
Train: [26][325/750]	BT 0.145 (1.187)	DT 0.020 (1.053)	loss nan (nan)	prob nan (nan)	GS 29.938 (29.938)	mem 42.288
Train: [26][330/750]	BT 0.124 (1.201)	DT 0.001 (1.068)	loss nan (nan)	prob nan (nan)	GS 37.250 (37.250)	mem 42.354
Train: [26][335/750]	BT 0.093 (1.186)	DT 0.001 (1.052)	loss nan (nan)	prob nan (nan)	GS 31.484 (31.484)	mem 42.388
Train: [26][340/750]	BT 0.106 (1.197)	DT 0.002 (1.064)	loss nan (nan)	prob nan (nan)	GS 35.734 (35.734)	mem 42.370
Train: [26][345/750]	BT 0.094 (1.182)	DT 0.002 (1.048)	loss nan (nan)	prob nan (nan)	GS 32.203 (32.203)	mem 42.526
Train: [26][350/750]	BT 8.614 (1.196)	DT 8.484 (1.062)	loss nan (nan)	prob nan (nan)	GS 32.188 (32.188)	mem 42.685
Train: [26][355/750]	BT 0.146 (1.181)	DT 0.002 (1.047)	loss nan (nan)	prob nan (nan)	GS 30.328 (30.328)	mem 42.346
Train: [26][360/750]	BT 0.134 (1.183)	DT 0.007 (1.049)	loss nan (nan)	prob nan (nan)	GS 28.625 (28.625)	mem 42.438
Train: [26][365/750]	BT 0.086 (1.181)	DT 0.001 (1.048)	loss nan (nan)	prob nan (nan)	GS 30.500 (30.500)	mem 42.432
Train: [26][370/750]	BT 6.236 (1.183)	DT 6.128 (1.050)	loss nan (nan)	prob nan (nan)	GS 35.234 (35.234)	mem 42.358
Train: [26][375/750]	BT 0.091 (1.182)	DT 0.001 (1.049)	loss nan (nan)	prob nan (nan)	GS 35.281 (35.281)	mem 42.360
Train: [26][380/750]	BT 0.156 (1.172)	DT 0.009 (1.039)	loss nan (nan)	prob nan (nan)	GS 29.312 (29.312)	mem 42.367
Train: [26][385/750]	BT 0.100 (1.170)	DT 0.002 (1.037)	loss nan (nan)	prob nan (nan)	GS 32.766 (32.766)	mem 42.406
Train: [26][390/750]	BT 0.087 (1.177)	DT 0.002 (1.044)	loss nan (nan)	prob nan (nan)	GS 33.828 (33.828)	mem 42.281
Train: [26][395/750]	BT 0.097 (1.168)	DT 0.006 (1.035)	loss nan (nan)	prob nan (nan)	GS 31.391 (31.391)	mem 42.308
Train: [26][400/750]	BT 0.145 (1.173)	DT 0.012 (1.040)	loss nan (nan)	prob nan (nan)	GS 35.219 (35.219)	mem 42.382
Train: [26][405/750]	BT 0.142 (1.168)	DT 0.014 (1.035)	loss nan (nan)	prob nan (nan)	GS 34.984 (34.984)	mem 42.307
Train: [26][410/750]	BT 5.036 (1.171)	DT 4.910 (1.038)	loss nan (nan)	prob nan (nan)	GS 30.453 (30.453)	mem 42.446
Train: [26][415/750]	BT 0.128 (1.171)	DT 0.010 (1.037)	loss nan (nan)	prob nan (nan)	GS 30.719 (30.719)	mem 42.273
Train: [26][420/750]	BT 0.089 (1.158)	DT 0.002 (1.025)	loss nan (nan)	prob nan (nan)	GS 33.688 (33.688)	mem 42.230
Train: [26][425/750]	BT 0.089 (1.168)	DT 0.002 (1.034)	loss nan (nan)	prob nan (nan)	GS 33.031 (33.031)	mem 42.361
Train: [26][430/750]	BT 0.093 (1.166)	DT 0.004 (1.033)	loss nan (nan)	prob nan (nan)	GS 32.781 (32.781)	mem 42.509
Train: [26][435/750]	BT 0.111 (1.180)	DT 0.001 (1.047)	loss nan (nan)	prob nan (nan)	GS 29.984 (29.984)	mem 42.400
Train: [26][440/750]	BT 0.123 (1.170)	DT 0.003 (1.036)	loss nan (nan)	prob nan (nan)	GS 34.906 (34.906)	mem 42.350
Train: [26][445/750]	BT 0.132 (1.158)	DT 0.002 (1.025)	loss nan (nan)	prob nan (nan)	GS 30.297 (30.297)	mem 42.352
Train: [26][450/750]	BT 4.911 (1.175)	DT 4.786 (1.041)	loss nan (nan)	prob nan (nan)	GS 35.734 (35.734)	mem 42.427
Train: [26][455/750]	BT 0.141 (1.163)	DT 0.017 (1.030)	loss nan (nan)	prob nan (nan)	GS 28.484 (28.484)	mem 42.324
Train: [26][460/750]	BT 0.130 (1.167)	DT 0.001 (1.034)	loss nan (nan)	prob nan (nan)	GS 32.438 (32.438)	mem 42.432
Train: [26][465/750]	BT 0.150 (1.158)	DT 0.010 (1.025)	loss nan (nan)	prob nan (nan)	GS 32.062 (32.062)	mem 42.434
Train: [26][470/750]	BT 6.671 (1.167)	DT 6.457 (1.033)	loss nan (nan)	prob nan (nan)	GS 34.828 (34.828)	mem 42.422
Train: [26][475/750]	BT 0.181 (1.157)	DT 0.013 (1.023)	loss nan (nan)	prob nan (nan)	GS 29.672 (29.672)	mem 42.358
Train: [26][480/750]	BT 0.169 (1.151)	DT 0.004 (1.018)	loss nan (nan)	prob nan (nan)	GS 34.797 (34.797)	mem 42.454
Train: [26][485/750]	BT 0.130 (1.158)	DT 0.002 (1.025)	loss nan (nan)	prob nan (nan)	GS 34.594 (34.594)	mem 42.386
Train: [26][490/750]	BT 2.794 (1.154)	DT 2.639 (1.021)	loss nan (nan)	prob nan (nan)	GS 35.391 (35.391)	mem 42.411
Train: [26][495/750]	BT 0.114 (1.168)	DT 0.013 (1.034)	loss nan (nan)	prob nan (nan)	GS 31.031 (31.031)	mem 42.459
Train: [26][500/750]	BT 0.148 (1.158)	DT 0.019 (1.024)	loss nan (nan)	prob nan (nan)	GS 31.078 (31.078)	mem 42.477
Train: [26][505/750]	BT 0.114 (1.152)	DT 0.009 (1.018)	loss nan (nan)	prob nan (nan)	GS 27.266 (27.266)	mem 42.429
Train: [26][510/750]	BT 0.155 (1.161)	DT 0.002 (1.027)	loss nan (nan)	prob nan (nan)	GS 32.734 (32.734)	mem 42.447
Train: [26][515/750]	BT 0.084 (1.151)	DT 0.002 (1.017)	loss nan (nan)	prob nan (nan)	GS 30.625 (30.625)	mem 42.462
Train: [26][520/750]	BT 0.134 (1.168)	DT 0.002 (1.034)	loss nan (nan)	prob nan (nan)	GS 37.375 (37.375)	mem 42.496
Train: [26][525/750]	BT 0.077 (1.157)	DT 0.002 (1.024)	loss nan (nan)	prob nan (nan)	GS 30.641 (30.641)	mem 42.552
Train: [26][530/750]	BT 9.370 (1.165)	DT 9.258 (1.032)	loss nan (nan)	prob nan (nan)	GS 31.984 (31.984)	mem 42.461
Train: [26][535/750]	BT 0.200 (1.156)	DT 0.002 (1.022)	loss nan (nan)	prob nan (nan)	GS 35.156 (35.156)	mem 42.470
Train: [26][540/750]	BT 0.148 (1.146)	DT 0.043 (1.013)	loss nan (nan)	prob nan (nan)	GS 35.219 (35.219)	mem 42.405
Train: [26][545/750]	BT 0.188 (1.154)	DT 0.050 (1.021)	loss nan (nan)	prob nan (nan)	GS 27.797 (27.797)	mem 42.525
Train: [26][550/750]	BT 1.368 (1.147)	DT 1.234 (1.014)	loss nan (nan)	prob nan (nan)	GS 32.641 (32.641)	mem 42.529
Train: [26][555/750]	BT 0.188 (1.155)	DT 0.001 (1.021)	loss nan (nan)	prob nan (nan)	GS 35.125 (35.125)	mem 42.578
Train: [26][560/750]	BT 0.138 (1.146)	DT 0.001 (1.012)	loss nan (nan)	prob nan (nan)	GS 32.156 (32.156)	mem 42.567
Train: [26][565/750]	BT 0.137 (1.143)	DT 0.002 (1.009)	loss nan (nan)	prob nan (nan)	GS 31.234 (31.234)	mem 42.514
Train: [26][570/750]	BT 0.115 (1.145)	DT 0.003 (1.011)	loss nan (nan)	prob nan (nan)	GS 31.859 (31.859)	mem 42.591
Train: [26][575/750]	BT 0.082 (1.146)	DT 0.001 (1.012)	loss nan (nan)	prob nan (nan)	GS 29.266 (29.266)	mem 42.738
Train: [26][580/750]	BT 4.949 (1.151)	DT 4.849 (1.018)	loss nan (nan)	prob nan (nan)	GS 32.953 (32.953)	mem 42.465
Train: [26][585/750]	BT 0.150 (1.143)	DT 0.016 (1.009)	loss nan (nan)	prob nan (nan)	GS 35.891 (35.891)	mem 42.428
Train: [26][590/750]	BT 0.199 (1.143)	DT 0.004 (1.009)	loss nan (nan)	prob nan (nan)	GS 29.672 (29.672)	mem 42.465
Train: [26][595/750]	BT 0.083 (1.151)	DT 0.002 (1.017)	loss nan (nan)	prob nan (nan)	GS 34.688 (34.688)	mem 42.406
Train: [26][600/750]	BT 0.121 (1.143)	DT 0.001 (1.009)	loss nan (nan)	prob nan (nan)	GS 36.875 (36.875)	mem 42.300
Train: [26][605/750]	BT 0.078 (1.156)	DT 0.002 (1.022)	loss nan (nan)	prob nan (nan)	GS 34.703 (34.703)	mem 42.464
Train: [26][610/750]	BT 0.397 (1.148)	DT 0.249 (1.014)	loss nan (nan)	prob nan (nan)	GS 36.688 (36.688)	mem 42.389
Train: [26][615/750]	BT 0.150 (1.140)	DT 0.002 (1.006)	loss nan (nan)	prob nan (nan)	GS 28.234 (28.234)	mem 42.426
Train: [26][620/750]	BT 0.197 (1.150)	DT 0.047 (1.017)	loss nan (nan)	prob nan (nan)	GS 38.250 (38.250)	mem 42.270
Train: [26][625/750]	BT 0.139 (1.142)	DT 0.004 (1.009)	loss nan (nan)	prob nan (nan)	GS 29.641 (29.641)	mem 42.281
Train: [26][630/750]	BT 0.135 (1.149)	DT 0.002 (1.016)	loss nan (nan)	prob nan (nan)	GS 30.938 (30.938)	mem 42.558
Train: [26][635/750]	BT 0.258 (1.150)	DT 0.003 (1.016)	loss nan (nan)	prob nan (nan)	GS 27.812 (27.812)	mem 42.353
Train: [26][640/750]	BT 9.032 (1.156)	DT 8.835 (1.022)	loss nan (nan)	prob nan (nan)	GS 33.938 (33.938)	mem 42.418
Train: [26][645/750]	BT 0.148 (1.153)	DT 0.001 (1.019)	loss nan (nan)	prob nan (nan)	GS 34.344 (34.344)	mem 42.364
Train: [26][650/750]	BT 0.193 (1.145)	DT 0.005 (1.011)	loss nan (nan)	prob nan (nan)	GS 36.844 (36.844)	mem 42.405
Train: [26][655/750]	BT 0.088 (1.149)	DT 0.002 (1.014)	loss nan (nan)	prob nan (nan)	GS 32.484 (32.484)	mem 42.393
Train: [26][660/750]	BT 0.149 (1.143)	DT 0.002 (1.009)	loss nan (nan)	prob nan (nan)	GS 34.109 (34.109)	mem 42.713
Train: [26][665/750]	BT 0.181 (1.153)	DT 0.001 (1.019)	loss nan (nan)	prob nan (nan)	GS 34.344 (34.344)	mem 42.381
Train: [26][670/750]	BT 0.180 (1.145)	DT 0.006 (1.011)	loss nan (nan)	prob nan (nan)	GS 35.031 (35.031)	mem 42.384
Train: [26][675/750]	BT 0.211 (1.138)	DT 0.002 (1.004)	loss nan (nan)	prob nan (nan)	GS 29.891 (29.891)	mem 42.393
Train: [26][680/750]	BT 0.155 (1.151)	DT 0.001 (1.017)	loss nan (nan)	prob nan (nan)	GS 35.109 (35.109)	mem 42.447
Train: [26][685/750]	BT 0.157 (1.144)	DT 0.004 (1.010)	loss nan (nan)	prob nan (nan)	GS 32.031 (32.031)	mem 42.490
Train: [26][690/750]	BT 0.088 (1.154)	DT 0.002 (1.020)	loss nan (nan)	prob nan (nan)	GS 32.297 (32.297)	mem 42.633
Train: [26][695/750]	BT 0.139 (1.147)	DT 0.006 (1.012)	loss nan (nan)	prob nan (nan)	GS 27.531 (27.531)	mem 42.652
Train: [26][700/750]	BT 13.902 (1.159)	DT 13.825 (1.025)	loss nan (nan)	prob nan (nan)	GS 32.969 (32.969)	mem 42.477
Train: [26][705/750]	BT 0.104 (1.152)	DT 0.002 (1.018)	loss nan (nan)	prob nan (nan)	GS 35.312 (35.312)	mem 42.479
arpack error, retry= 0
arpack error, retry= 0
Train: [26][710/750]	BT 0.129 (1.144)	DT 0.002 (1.011)	loss nan (nan)	prob nan (nan)	GS 36.969 (36.969)	mem 42.749
Train: [26][715/750]	BT 0.105 (1.156)	DT 0.009 (1.022)	loss nan (nan)	prob nan (nan)	GS 34.469 (34.469)	mem 42.490
Train: [26][720/750]	BT 0.100 (1.149)	DT 0.016 (1.015)	loss nan (nan)	prob nan (nan)	GS 33.234 (33.234)	mem 42.499
Train: [26][725/750]	BT 0.081 (1.157)	DT 0.005 (1.024)	loss nan (nan)	prob nan (nan)	GS 32.062 (32.062)	mem 42.396
Train: [26][730/750]	BT 0.180 (1.150)	DT 0.007 (1.017)	loss nan (nan)	prob nan (nan)	GS 35.641 (35.641)	mem 42.310
Train: [26][735/750]	BT 0.090 (1.143)	DT 0.001 (1.010)	loss nan (nan)	prob nan (nan)	GS 30.438 (30.438)	mem 42.360
Train: [26][740/750]	BT 0.081 (1.145)	DT 0.001 (1.012)	loss nan (nan)	prob nan (nan)	GS 31.297 (31.297)	mem 21.849
Train: [26][745/750]	BT 0.063 (1.138)	DT 0.002 (1.005)	loss nan (nan)	prob nan (nan)	GS 33.312 (33.312)	mem 21.793
Train: [26][750/750]	BT 0.081 (1.133)	DT 0.001 (1.000)	loss nan (nan)	prob nan (nan)	GS 34.594 (34.594)	mem 10.067
Train: [26][755/750]	BT 0.073 (1.126)	DT 0.001 (0.994)	loss nan (nan)	prob nan (nan)	GS 30.469 (30.469)	mem 10.067
epoch 26, total time 850.21
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [27][1/750]	BT 22.813 (22.813)	DT 22.610 (22.610)	loss nan (nan)	prob nan (nan)	GS 33.547 (33.547)	mem 41.111
Train: [27][5/750]	BT 0.100 (4.925)	DT 0.002 (4.790)	loss nan (nan)	prob nan (nan)	GS 34.438 (34.438)	mem 41.130
Train: [27][10/750]	BT 0.117 (2.584)	DT 0.002 (2.457)	loss nan (nan)	prob nan (nan)	GS 32.266 (32.266)	mem 41.198
Train: [27][15/750]	BT 0.101 (2.738)	DT 0.002 (2.609)	loss nan (nan)	prob nan (nan)	GS 31.141 (31.141)	mem 41.415
Train: [27][20/750]	BT 0.108 (2.098)	DT 0.006 (1.959)	loss nan (nan)	prob nan (nan)	GS 32.172 (32.172)	mem 41.427
Train: [27][25/750]	BT 0.135 (1.704)	DT 0.002 (1.568)	loss nan (nan)	prob nan (nan)	GS 29.266 (29.266)	mem 41.534
Train: [27][30/750]	BT 1.197 (1.866)	DT 0.977 (1.725)	loss nan (nan)	prob nan (nan)	GS 37.547 (37.547)	mem 41.469
Train: [27][35/750]	BT 0.241 (1.621)	DT 0.010 (1.480)	loss nan (nan)	prob nan (nan)	GS 32.953 (32.953)	mem 41.769
Train: [27][40/750]	BT 0.100 (1.745)	DT 0.001 (1.608)	loss nan (nan)	prob nan (nan)	GS 30.500 (30.500)	mem 41.535
Train: [27][45/750]	BT 0.096 (1.597)	DT 0.006 (1.463)	loss nan (nan)	prob nan (nan)	GS 29.438 (29.438)	mem 41.558
Train: [27][50/750]	BT 9.951 (1.648)	DT 9.795 (1.513)	loss nan (nan)	prob nan (nan)	GS 32.219 (32.219)	mem 41.572
Train: [27][55/750]	BT 0.071 (1.553)	DT 0.001 (1.418)	loss nan (nan)	prob nan (nan)	GS 32.062 (32.062)	mem 41.676
Train: [27][60/750]	BT 0.095 (1.432)	DT 0.001 (1.300)	loss nan (nan)	prob nan (nan)	GS 34.812 (34.812)	mem 41.530
Train: [27][65/750]	BT 0.159 (1.437)	DT 0.029 (1.302)	loss nan (nan)	prob nan (nan)	GS 29.859 (29.859)	mem 41.597
Train: [27][70/750]	BT 0.135 (1.401)	DT 0.002 (1.266)	loss nan (nan)	prob nan (nan)	GS 33.844 (33.844)	mem 41.759
Train: [27][75/750]	BT 0.087 (1.421)	DT 0.002 (1.288)	loss nan (nan)	prob nan (nan)	GS 33.438 (33.438)	mem 41.624
Train: [27][80/750]	BT 0.093 (1.384)	DT 0.002 (1.253)	loss nan (nan)	prob nan (nan)	GS 34.703 (34.703)	mem 41.651
Train: [27][85/750]	BT 0.157 (1.311)	DT 0.002 (1.180)	loss nan (nan)	prob nan (nan)	GS 32.984 (32.984)	mem 41.654
Train: [27][90/750]	BT 5.063 (1.365)	DT 4.954 (1.233)	loss nan (nan)	prob nan (nan)	GS 31.172 (31.172)	mem 41.694
Train: [27][95/750]	BT 0.115 (1.301)	DT 0.002 (1.168)	loss nan (nan)	prob nan (nan)	GS 31.922 (31.922)	mem 41.730
Train: [27][100/750]	BT 0.109 (1.305)	DT 0.001 (1.171)	loss nan (nan)	prob nan (nan)	GS 35.672 (35.672)	mem 41.728
Train: [27][105/750]	BT 0.210 (1.337)	DT 0.002 (1.203)	loss nan (nan)	prob nan (nan)	GS 30.969 (30.969)	mem 41.743
Train: [27][110/750]	BT 3.665 (1.315)	DT 3.562 (1.181)	loss nan (nan)	prob nan (nan)	GS 33.562 (33.562)	mem 42.153
Train: [27][115/750]	BT 0.143 (1.314)	DT 0.004 (1.180)	loss nan (nan)	prob nan (nan)	GS 31.438 (31.438)	mem 41.860
Train: [27][120/750]	BT 0.152 (1.266)	DT 0.002 (1.131)	loss nan (nan)	prob nan (nan)	GS 37.547 (37.547)	mem 42.033
Train: [27][125/750]	BT 0.190 (1.257)	DT 0.002 (1.122)	loss nan (nan)	prob nan (nan)	GS 33.625 (33.625)	mem 41.977
Train: [27][130/750]	BT 0.083 (1.293)	DT 0.001 (1.156)	loss nan (nan)	prob nan (nan)	GS 36.203 (36.203)	mem 42.354
Train: [27][135/750]	BT 0.192 (1.272)	DT 0.017 (1.135)	loss nan (nan)	prob nan (nan)	GS 28.750 (28.750)	mem 42.843
Train: [27][140/750]	BT 0.158 (1.314)	DT 0.004 (1.176)	loss nan (nan)	prob nan (nan)	GS 34.875 (34.875)	mem 43.874
Train: [27][145/750]	BT 0.165 (1.274)	DT 0.008 (1.136)	loss nan (nan)	prob nan (nan)	GS 28.250 (28.250)	mem 44.183
Train: [27][150/750]	BT 13.563 (1.337)	DT 13.485 (1.198)	loss nan (nan)	prob nan (nan)	GS 36.703 (36.703)	mem 43.947
Train: [27][155/750]	BT 0.104 (1.299)	DT 0.002 (1.160)	loss nan (nan)	prob nan (nan)	GS 35.828 (35.828)	mem 43.905
Train: [27][160/750]	BT 0.143 (1.262)	DT 0.002 (1.124)	loss nan (nan)	prob nan (nan)	GS 32.359 (32.359)	mem 43.953
Train: [27][165/750]	BT 0.067 (1.296)	DT 0.001 (1.159)	loss nan (nan)	prob nan (nan)	GS 33.547 (33.547)	mem 43.966
Train: [27][170/750]	BT 0.117 (1.261)	DT 0.002 (1.125)	loss nan (nan)	prob nan (nan)	GS 33.266 (33.266)	mem 43.974
Train: [27][175/750]	BT 0.086 (1.306)	DT 0.001 (1.169)	loss nan (nan)	prob nan (nan)	GS 34.766 (34.766)	mem 44.027
Train: [27][180/750]	BT 0.187 (1.273)	DT 0.001 (1.137)	loss nan (nan)	prob nan (nan)	GS 34.703 (34.703)	mem 43.950
Train: [27][185/750]	BT 0.219 (1.245)	DT 0.006 (1.106)	loss nan (nan)	prob nan (nan)	GS 32.109 (32.109)	mem 43.957
Train: [27][190/750]	BT 0.076 (1.278)	DT 0.001 (1.141)	loss nan (nan)	prob nan (nan)	GS 34.156 (34.156)	mem 44.109
Train: [27][195/750]	BT 0.157 (1.249)	DT 0.002 (1.112)	loss nan (nan)	prob nan (nan)	GS 33.078 (33.078)	mem 43.966
Train: [27][200/750]	BT 0.134 (1.265)	DT 0.007 (1.127)	loss nan (nan)	prob nan (nan)	GS 31.422 (31.422)	mem 43.996
Train: [27][205/750]	BT 0.152 (1.237)	DT 0.002 (1.100)	loss nan (nan)	prob nan (nan)	GS 24.594 (24.594)	mem 44.061
Train: [27][210/750]	BT 13.579 (1.275)	DT 13.505 (1.138)	loss nan (nan)	prob nan (nan)	GS 31.359 (31.359)	mem 43.973
Train: [27][215/750]	BT 0.158 (1.249)	DT 0.002 (1.111)	loss nan (nan)	prob nan (nan)	GS 32.188 (32.188)	mem 43.975
Train: [27][220/750]	BT 0.077 (1.223)	DT 0.001 (1.086)	loss nan (nan)	prob nan (nan)	GS 33.875 (33.875)	mem 43.976
Train: [27][225/750]	BT 0.114 (1.262)	DT 0.027 (1.126)	loss nan (nan)	prob nan (nan)	GS 29.047 (29.047)	mem 43.815
Train: [27][230/750]	BT 0.138 (1.236)	DT 0.001 (1.102)	loss nan (nan)	prob nan (nan)	GS 34.828 (34.828)	mem 43.816
Train: [27][235/750]	BT 0.062 (1.260)	DT 0.001 (1.125)	loss nan (nan)	prob nan (nan)	GS 26.141 (26.141)	mem 43.865
Train: [27][240/750]	BT 0.117 (1.236)	DT 0.001 (1.102)	loss nan (nan)	prob nan (nan)	GS 33.734 (33.734)	mem 43.913
Train: [27][245/750]	BT 0.128 (1.213)	DT 0.002 (1.080)	loss nan (nan)	prob nan (nan)	GS 32.234 (32.234)	mem 43.871
Train: [27][250/750]	BT 0.074 (1.236)	DT 0.002 (1.103)	loss nan (nan)	prob nan (nan)	GS 32.047 (32.047)	mem 43.829
Train: [27][255/750]	BT 0.114 (1.214)	DT 0.001 (1.082)	loss nan (nan)	prob nan (nan)	GS 31.453 (31.453)	mem 44.043
Train: [27][260/750]	BT 0.181 (1.229)	DT 0.002 (1.097)	loss nan (nan)	prob nan (nan)	GS 33.859 (33.859)	mem 44.143
Train: [27][265/750]	BT 0.085 (1.208)	DT 0.003 (1.076)	loss nan (nan)	prob nan (nan)	GS 31.984 (31.984)	mem 43.927
Train: [27][270/750]	BT 10.025 (1.225)	DT 9.938 (1.093)	loss nan (nan)	prob nan (nan)	GS 29.375 (29.375)	mem 43.942
Train: [27][275/750]	BT 0.131 (1.206)	DT 0.006 (1.073)	loss nan (nan)	prob nan (nan)	GS 29.688 (29.688)	mem 43.945
Train: [27][280/750]	BT 0.100 (1.187)	DT 0.002 (1.054)	loss nan (nan)	prob nan (nan)	GS 35.359 (35.359)	mem 43.948
Train: [27][285/750]	BT 0.173 (1.205)	DT 0.017 (1.073)	loss nan (nan)	prob nan (nan)	GS 31.500 (31.500)	mem 43.946
Train: [27][290/750]	BT 0.186 (1.187)	DT 0.004 (1.054)	loss nan (nan)	prob nan (nan)	GS 31.266 (31.266)	mem 43.955
Train: [27][295/750]	BT 0.124 (1.220)	DT 0.002 (1.087)	loss nan (nan)	prob nan (nan)	GS 27.062 (27.062)	mem 44.002
Train: [27][300/750]	BT 0.168 (1.202)	DT 0.001 (1.069)	loss nan (nan)	prob nan (nan)	GS 31.922 (31.922)	mem 44.005
Train: [27][305/750]	BT 0.096 (1.184)	DT 0.010 (1.052)	loss nan (nan)	prob nan (nan)	GS 36.078 (36.078)	mem 44.034
Train: [27][310/750]	BT 0.268 (1.205)	DT 0.023 (1.072)	loss nan (nan)	prob nan (nan)	GS 28.672 (28.672)	mem 44.102
Train: [27][315/750]	BT 0.076 (1.188)	DT 0.002 (1.055)	loss nan (nan)	prob nan (nan)	GS 34.953 (34.953)	mem 43.940
Train: [27][320/750]	BT 0.095 (1.208)	DT 0.002 (1.075)	loss nan (nan)	prob nan (nan)	GS 31.297 (31.297)	mem 43.927
Train: [27][325/750]	BT 0.078 (1.191)	DT 0.002 (1.059)	loss nan (nan)	prob nan (nan)	GS 25.953 (25.953)	mem 44.129
Train: [27][330/750]	BT 12.581 (1.212)	DT 12.480 (1.081)	loss nan (nan)	prob nan (nan)	GS 36.812 (36.812)	mem 43.947
Train: [27][335/750]	BT 0.173 (1.196)	DT 0.001 (1.064)	loss nan (nan)	prob nan (nan)	GS 27.625 (27.625)	mem 43.949
Train: [27][340/750]	BT 0.151 (1.180)	DT 0.031 (1.049)	loss nan (nan)	prob nan (nan)	GS 33.438 (33.438)	mem 44.022
Train: [27][345/750]	BT 0.200 (1.191)	DT 0.002 (1.059)	loss nan (nan)	prob nan (nan)	GS 28.438 (28.438)	mem 43.965
Train: [27][350/750]	BT 0.085 (1.175)	DT 0.002 (1.044)	loss nan (nan)	prob nan (nan)	GS 37.547 (37.547)	mem 43.965
Train: [27][355/750]	BT 0.114 (1.193)	DT 0.003 (1.061)	loss nan (nan)	prob nan (nan)	GS 28.406 (28.406)	mem 43.970
Train: [27][360/750]	BT 0.120 (1.178)	DT 0.002 (1.047)	loss nan (nan)	prob nan (nan)	GS 32.656 (32.656)	mem 44.125
Train: [27][365/750]	BT 0.106 (1.163)	DT 0.002 (1.032)	loss nan (nan)	prob nan (nan)	GS 27.844 (27.844)	mem 43.972
Train: [27][370/750]	BT 0.096 (1.184)	DT 0.002 (1.053)	loss nan (nan)	prob nan (nan)	GS 32.047 (32.047)	mem 43.995
Train: [27][375/750]	BT 0.183 (1.170)	DT 0.022 (1.039)	loss nan (nan)	prob nan (nan)	GS 32.500 (32.500)	mem 44.171
Train: [27][380/750]	BT 0.160 (1.187)	DT 0.001 (1.056)	loss nan (nan)	prob nan (nan)	GS 37.828 (37.828)	mem 43.957
Train: [27][385/750]	BT 0.157 (1.174)	DT 0.004 (1.043)	loss nan (nan)	prob nan (nan)	GS 22.469 (22.469)	mem 43.959
Train: [27][390/750]	BT 11.947 (1.191)	DT 11.821 (1.060)	loss nan (nan)	prob nan (nan)	GS 34.281 (34.281)	mem 42.497
Train: [27][395/750]	BT 0.080 (1.177)	DT 0.002 (1.046)	loss nan (nan)	prob nan (nan)	GS 30.938 (30.938)	mem 42.500
Train: [27][400/750]	BT 0.103 (1.164)	DT 0.001 (1.033)	loss nan (nan)	prob nan (nan)	GS 33.188 (33.188)	mem 42.500
Train: [27][405/750]	BT 0.076 (1.177)	DT 0.002 (1.047)	loss nan (nan)	prob nan (nan)	GS 29.328 (29.328)	mem 42.542
Train: [27][410/750]	BT 0.156 (1.164)	DT 0.002 (1.034)	loss nan (nan)	prob nan (nan)	GS 33.703 (33.703)	mem 42.632
Train: [27][415/750]	BT 0.073 (1.182)	DT 0.001 (1.051)	loss nan (nan)	prob nan (nan)	GS 32.953 (32.953)	mem 42.366
Train: [27][420/750]	BT 0.208 (1.169)	DT 0.005 (1.039)	loss nan (nan)	prob nan (nan)	GS 32.609 (32.609)	mem 42.389
Train: [27][425/750]	BT 0.190 (1.158)	DT 0.002 (1.027)	loss nan (nan)	prob nan (nan)	GS 32.594 (32.594)	mem 42.404
Train: [27][430/750]	BT 0.081 (1.171)	DT 0.001 (1.041)	loss nan (nan)	prob nan (nan)	GS 33.062 (33.062)	mem 42.439
Train: [27][435/750]	BT 0.118 (1.159)	DT 0.002 (1.029)	loss nan (nan)	prob nan (nan)	GS 31.609 (31.609)	mem 42.495
Train: [27][440/750]	BT 0.090 (1.177)	DT 0.001 (1.046)	loss nan (nan)	prob nan (nan)	GS 34.203 (34.203)	mem 42.488
Train: [27][445/750]	BT 0.098 (1.165)	DT 0.002 (1.034)	loss nan (nan)	prob nan (nan)	GS 33.797 (33.797)	mem 42.517
Train: [27][450/750]	BT 11.158 (1.178)	DT 11.030 (1.047)	loss nan (nan)	prob nan (nan)	GS 34.031 (34.031)	mem 42.577
Train: [27][455/750]	BT 0.073 (1.167)	DT 0.002 (1.036)	loss nan (nan)	prob nan (nan)	GS 29.656 (29.656)	mem 42.580
Train: [27][460/750]	BT 0.130 (1.155)	DT 0.008 (1.024)	loss nan (nan)	prob nan (nan)	GS 36.484 (36.484)	mem 42.615
Train: [27][465/750]	BT 0.130 (1.162)	DT 0.019 (1.031)	loss nan (nan)	prob nan (nan)	GS 29.375 (29.375)	mem 42.488
Train: [27][470/750]	BT 0.263 (1.151)	DT 0.025 (1.020)	loss nan (nan)	prob nan (nan)	GS 30.156 (30.156)	mem 42.619
Train: [27][475/750]	BT 0.086 (1.164)	DT 0.001 (1.032)	loss nan (nan)	prob nan (nan)	GS 29.172 (29.172)	mem 42.433
Train: [27][480/750]	BT 0.076 (1.153)	DT 0.001 (1.022)	loss nan (nan)	prob nan (nan)	GS 30.906 (30.906)	mem 42.450
Train: [27][485/750]	BT 0.152 (1.142)	DT 0.001 (1.011)	loss nan (nan)	prob nan (nan)	GS 30.688 (30.688)	mem 42.446
Train: [27][490/750]	BT 0.174 (1.159)	DT 0.007 (1.028)	loss nan (nan)	prob nan (nan)	GS 35.234 (35.234)	mem 42.474
Train: [27][495/750]	BT 0.301 (1.149)	DT 0.028 (1.018)	loss nan (nan)	prob nan (nan)	GS 31.141 (31.141)	mem 42.474
Train: [27][500/750]	BT 0.110 (1.162)	DT 0.013 (1.030)	loss nan (nan)	prob nan (nan)	GS 38.906 (38.906)	mem 42.603
Train: [27][505/750]	BT 0.132 (1.152)	DT 0.012 (1.020)	loss nan (nan)	prob nan (nan)	GS 29.703 (29.703)	mem 42.436
Train: [27][510/750]	BT 12.141 (1.166)	DT 11.954 (1.034)	loss nan (nan)	prob nan (nan)	GS 33.797 (33.797)	mem 42.545
Train: [27][515/750]	BT 0.163 (1.159)	DT 0.012 (1.027)	loss nan (nan)	prob nan (nan)	GS 31.844 (31.844)	mem 42.730
Train: [27][520/750]	BT 0.195 (1.149)	DT 0.002 (1.017)	loss nan (nan)	prob nan (nan)	GS 36.906 (36.906)	mem 42.643
Train: [27][525/750]	BT 0.103 (1.159)	DT 0.001 (1.026)	loss nan (nan)	prob nan (nan)	GS 31.531 (31.531)	mem 42.533
Train: [27][530/750]	BT 0.130 (1.149)	DT 0.002 (1.016)	loss nan (nan)	prob nan (nan)	GS 33.297 (33.297)	mem 42.605
Train: [27][535/750]	BT 0.245 (1.159)	DT 0.058 (1.027)	loss nan (nan)	prob nan (nan)	GS 25.953 (25.953)	mem 42.545
Train: [27][540/750]	BT 0.168 (1.152)	DT 0.003 (1.020)	loss nan (nan)	prob nan (nan)	GS 32.234 (32.234)	mem 42.565
Train: [27][545/750]	BT 0.162 (1.143)	DT 0.002 (1.010)	loss nan (nan)	prob nan (nan)	GS 29.906 (29.906)	mem 42.625
Train: [27][550/750]	BT 0.192 (1.155)	DT 0.016 (1.022)	loss nan (nan)	prob nan (nan)	GS 31.781 (31.781)	mem 42.692
Train: [27][555/750]	BT 0.136 (1.146)	DT 0.003 (1.013)	loss nan (nan)	prob nan (nan)	GS 31.469 (31.469)	mem 42.573
Train: [27][560/750]	BT 0.161 (1.158)	DT 0.002 (1.026)	loss nan (nan)	prob nan (nan)	GS 31.812 (31.812)	mem 42.492
Train: [27][565/750]	BT 0.174 (1.150)	DT 0.002 (1.017)	loss nan (nan)	prob nan (nan)	GS 31.984 (31.984)	mem 42.484
Train: [27][570/750]	BT 6.462 (1.152)	DT 6.348 (1.019)	loss nan (nan)	prob nan (nan)	GS 32.891 (32.891)	mem 42.529
Train: [27][575/750]	BT 0.231 (1.151)	DT 0.002 (1.018)	loss nan (nan)	prob nan (nan)	GS 31.906 (31.906)	mem 42.538
Train: [27][580/750]	BT 0.146 (1.142)	DT 0.012 (1.009)	loss nan (nan)	prob nan (nan)	GS 30.125 (30.125)	mem 42.610
Train: [27][585/750]	BT 0.160 (1.153)	DT 0.001 (1.020)	loss nan (nan)	prob nan (nan)	GS 29.922 (29.922)	mem 42.539
Train: [27][590/750]	BT 0.134 (1.146)	DT 0.010 (1.013)	loss nan (nan)	prob nan (nan)	GS 33.484 (33.484)	mem 42.567
Train: [27][595/750]	BT 0.170 (1.151)	DT 0.035 (1.017)	loss nan (nan)	prob nan (nan)	GS 35.125 (35.125)	mem 42.637
Train: [27][600/750]	BT 2.542 (1.149)	DT 2.431 (1.015)	loss nan (nan)	prob nan (nan)	GS 33.203 (33.203)	mem 42.845
Train: [27][605/750]	BT 0.085 (1.140)	DT 0.001 (1.007)	loss nan (nan)	prob nan (nan)	GS 34.031 (34.031)	mem 42.660
Train: [27][610/750]	BT 0.149 (1.145)	DT 0.003 (1.012)	loss nan (nan)	prob nan (nan)	GS 39.969 (39.969)	mem 42.724
Train: [27][615/750]	BT 0.093 (1.142)	DT 0.001 (1.009)	loss nan (nan)	prob nan (nan)	GS 30.688 (30.688)	mem 42.610
Train: [27][620/750]	BT 0.197 (1.147)	DT 0.058 (1.014)	loss nan (nan)	prob nan (nan)	GS 33.938 (33.938)	mem 42.797
Train: [27][625/750]	BT 0.085 (1.143)	DT 0.002 (1.010)	loss nan (nan)	prob nan (nan)	GS 26.766 (26.766)	mem 42.598
Train: [27][630/750]	BT 7.844 (1.148)	DT 7.753 (1.014)	loss nan (nan)	prob nan (nan)	GS 33.438 (33.438)	mem 42.522
Train: [27][635/750]	BT 0.104 (1.144)	DT 0.001 (1.011)	loss nan (nan)	prob nan (nan)	GS 29.031 (29.031)	mem 42.485
Train: [27][640/750]	BT 0.090 (1.141)	DT 0.006 (1.008)	loss nan (nan)	prob nan (nan)	GS 35.000 (35.000)	mem 42.513
Train: [27][645/750]	BT 0.098 (1.143)	DT 0.002 (1.010)	loss nan (nan)	prob nan (nan)	GS 29.656 (29.656)	mem 42.561
Train: [27][650/750]	BT 0.132 (1.143)	DT 0.002 (1.010)	loss nan (nan)	prob nan (nan)	GS 33.734 (33.734)	mem 42.562
Train: [27][655/750]	BT 0.105 (1.144)	DT 0.006 (1.011)	loss nan (nan)	prob nan (nan)	GS 29.516 (29.516)	mem 42.727
Train: [27][660/750]	BT 8.040 (1.149)	DT 7.840 (1.016)	loss nan (nan)	prob nan (nan)	GS 34.047 (34.047)	mem 42.639
Train: [27][665/750]	BT 0.112 (1.141)	DT 0.001 (1.008)	loss nan (nan)	prob nan (nan)	GS 30.328 (30.328)	mem 42.640
Train: [27][670/750]	BT 0.087 (1.139)	DT 0.002 (1.006)	loss nan (nan)	prob nan (nan)	GS 32.766 (32.766)	mem 42.595
Train: [27][675/750]	BT 0.108 (1.145)	DT 0.001 (1.012)	loss nan (nan)	prob nan (nan)	GS 30.641 (30.641)	mem 42.669
Train: [27][680/750]	BT 0.365 (1.142)	DT 0.247 (1.009)	loss nan (nan)	prob nan (nan)	GS 36.750 (36.750)	mem 42.615
Train: [27][685/750]	BT 0.156 (1.147)	DT 0.001 (1.014)	loss nan (nan)	prob nan (nan)	GS 28.734 (28.734)	mem 42.602
Train: [27][690/750]	BT 1.124 (1.141)	DT 0.980 (1.008)	loss nan (nan)	prob nan (nan)	GS 31.875 (31.875)	mem 42.593
Train: [27][695/750]	BT 0.209 (1.134)	DT 0.002 (1.001)	loss nan (nan)	prob nan (nan)	GS 29.828 (29.828)	mem 42.692
Train: [27][700/750]	BT 0.091 (1.143)	DT 0.002 (1.010)	loss nan (nan)	prob nan (nan)	GS 30.859 (30.859)	mem 42.749
Train: [27][705/750]	BT 0.203 (1.136)	DT 0.002 (1.003)	loss nan (nan)	prob nan (nan)	GS 34.234 (34.234)	mem 42.656
arpack error, retry= 0
Train: [27][710/750]	BT 0.088 (1.147)	DT 0.002 (1.014)	loss nan (nan)	prob nan (nan)	GS 30.531 (30.531)	mem 42.818
Train: [27][715/750]	BT 0.081 (1.143)	DT 0.002 (1.011)	loss nan (nan)	prob nan (nan)	GS 29.844 (29.844)	mem 42.611
Train: [27][720/750]	BT 9.194 (1.149)	DT 9.084 (1.016)	loss nan (nan)	prob nan (nan)	GS 33.297 (33.297)	mem 42.610
Train: [27][725/750]	BT 0.143 (1.142)	DT 0.005 (1.009)	loss nan (nan)	prob nan (nan)	GS 31.297 (31.297)	mem 42.561
Train: [27][730/750]	BT 0.104 (1.140)	DT 0.001 (1.007)	loss nan (nan)	prob nan (nan)	GS 33.391 (33.391)	mem 42.392
Train: [27][735/750]	BT 0.131 (1.143)	DT 0.001 (1.010)	loss nan (nan)	prob nan (nan)	GS 35.859 (35.859)	mem 42.183
Train: [27][740/750]	BT 0.099 (1.136)	DT 0.002 (1.004)	loss nan (nan)	prob nan (nan)	GS 33.625 (33.625)	mem 30.587
Train: [27][745/750]	BT 0.066 (1.135)	DT 0.001 (1.003)	loss nan (nan)	prob nan (nan)	GS 26.656 (26.656)	mem 10.268
Train: [27][750/750]	BT 0.057 (1.128)	DT 0.001 (0.996)	loss nan (nan)	prob nan (nan)	GS 31.156 (31.156)	mem 10.268
Train: [27][755/750]	BT 0.088 (1.121)	DT 0.001 (0.989)	loss nan (nan)	prob nan (nan)	GS 31.094 (31.094)	mem 10.268
epoch 27, total time 849.01
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [28][1/750]	BT 21.907 (21.907)	DT 21.791 (21.791)	loss nan (nan)	prob nan (nan)	GS 35.578 (35.578)	mem 41.081
Train: [28][5/750]	BT 0.179 (5.020)	DT 0.009 (4.872)	loss nan (nan)	prob nan (nan)	GS 32.484 (32.484)	mem 41.196
Train: [28][10/750]	BT 0.225 (2.604)	DT 0.145 (2.452)	loss nan (nan)	prob nan (nan)	GS 32.906 (32.906)	mem 41.200
Train: [28][15/750]	BT 0.108 (2.795)	DT 0.008 (2.658)	loss nan (nan)	prob nan (nan)	GS 28.234 (28.234)	mem 41.538
Train: [28][20/750]	BT 0.138 (2.132)	DT 0.008 (1.996)	loss nan (nan)	prob nan (nan)	GS 37.859 (37.859)	mem 41.460
Train: [28][25/750]	BT 0.127 (1.734)	DT 0.009 (1.597)	loss nan (nan)	prob nan (nan)	GS 31.484 (31.484)	mem 41.461
Train: [28][30/750]	BT 0.314 (1.849)	DT 0.039 (1.711)	loss nan (nan)	prob nan (nan)	GS 34.969 (34.969)	mem 41.733
Train: [28][35/750]	BT 0.077 (1.605)	DT 0.002 (1.467)	loss nan (nan)	prob nan (nan)	GS 26.906 (26.906)	mem 41.812
Train: [28][40/750]	BT 0.189 (1.683)	DT 0.009 (1.541)	loss nan (nan)	prob nan (nan)	GS 25.125 (25.125)	mem 42.189
Train: [28][45/750]	BT 0.145 (1.529)	DT 0.002 (1.388)	loss nan (nan)	prob nan (nan)	GS 28.844 (28.844)	mem 42.206
Train: [28][50/750]	BT 8.387 (1.557)	DT 8.292 (1.415)	loss nan (nan)	prob nan (nan)	GS 31.953 (31.953)	mem 42.285
Train: [28][55/750]	BT 0.094 (1.426)	DT 0.005 (1.287)	loss nan (nan)	prob nan (nan)	GS 31.250 (31.250)	mem 42.284
Train: [28][60/750]	BT 0.117 (1.321)	DT 0.002 (1.181)	loss nan (nan)	prob nan (nan)	GS 36.984 (36.984)	mem 42.399
Train: [28][65/750]	BT 0.150 (1.399)	DT 0.001 (1.260)	loss nan (nan)	prob nan (nan)	GS 32.484 (32.484)	mem 42.307
Train: [28][70/750]	BT 0.100 (1.350)	DT 0.002 (1.212)	loss nan (nan)	prob nan (nan)	GS 34.656 (34.656)	mem 42.296
Train: [28][75/750]	BT 0.217 (1.354)	DT 0.001 (1.217)	loss nan (nan)	prob nan (nan)	GS 30.500 (30.500)	mem 42.571
Train: [28][80/750]	BT 6.269 (1.355)	DT 6.041 (1.216)	loss nan (nan)	prob nan (nan)	GS 34.000 (34.000)	mem 42.305
Train: [28][85/750]	BT 0.154 (1.282)	DT 0.009 (1.145)	loss nan (nan)	prob nan (nan)	GS 37.266 (37.266)	mem 42.305
Train: [28][90/750]	BT 4.171 (1.281)	DT 4.029 (1.142)	loss nan (nan)	prob nan (nan)	GS 38.000 (38.000)	mem 42.325
Train: [28][95/750]	BT 0.070 (1.319)	DT 0.001 (1.182)	loss nan (nan)	prob nan (nan)	GS 32.453 (32.453)	mem 42.390
Train: [28][100/750]	BT 0.167 (1.273)	DT 0.002 (1.135)	loss nan (nan)	prob nan (nan)	GS 32.812 (32.812)	mem 42.245
Train: [28][105/750]	BT 0.088 (1.290)	DT 0.001 (1.154)	loss nan (nan)	prob nan (nan)	GS 34.156 (34.156)	mem 42.306
Train: [28][110/750]	BT 1.392 (1.249)	DT 1.212 (1.112)	loss nan (nan)	prob nan (nan)	GS 35.578 (35.578)	mem 42.563
Train: [28][115/750]	BT 0.141 (1.224)	DT 0.001 (1.088)	loss nan (nan)	prob nan (nan)	GS 34.094 (34.094)	mem 42.342
Train: [28][120/750]	BT 0.143 (1.241)	DT 0.001 (1.106)	loss nan (nan)	prob nan (nan)	GS 35.375 (35.375)	mem 42.401
Train: [28][125/750]	BT 0.077 (1.206)	DT 0.001 (1.073)	loss nan (nan)	prob nan (nan)	GS 33.203 (33.203)	mem 42.297
Train: [28][130/750]	BT 0.108 (1.232)	DT 0.001 (1.100)	loss nan (nan)	prob nan (nan)	GS 33.203 (33.203)	mem 42.564
Train: [28][135/750]	BT 0.104 (1.214)	DT 0.002 (1.082)	loss nan (nan)	prob nan (nan)	GS 35.484 (35.484)	mem 42.331
Train: [28][140/750]	BT 2.528 (1.224)	DT 2.449 (1.092)	loss nan (nan)	prob nan (nan)	GS 31.547 (31.547)	mem 42.370
Train: [28][145/750]	BT 0.166 (1.187)	DT 0.002 (1.055)	loss nan (nan)	prob nan (nan)	GS 29.156 (29.156)	mem 42.392
Train: [28][150/750]	BT 10.134 (1.220)	DT 9.973 (1.086)	loss nan (nan)	prob nan (nan)	GS 30.844 (30.844)	mem 42.602
Train: [28][155/750]	BT 0.117 (1.203)	DT 0.002 (1.070)	loss nan (nan)	prob nan (nan)	GS 29.344 (29.344)	mem 42.610
Train: [28][160/750]	BT 0.155 (1.170)	DT 0.007 (1.037)	loss nan (nan)	prob nan (nan)	GS 28.562 (28.562)	mem 42.414
Train: [28][165/750]	BT 0.172 (1.190)	DT 0.003 (1.056)	loss nan (nan)	prob nan (nan)	GS 33.391 (33.391)	mem 42.507
Train: [28][170/750]	BT 3.421 (1.184)	DT 3.264 (1.049)	loss nan (nan)	prob nan (nan)	GS 33.969 (33.969)	mem 42.434
Train: [28][175/750]	BT 0.097 (1.183)	DT 0.002 (1.049)	loss nan (nan)	prob nan (nan)	GS 29.016 (29.016)	mem 42.531
Train: [28][180/750]	BT 7.125 (1.193)	DT 6.981 (1.059)	loss nan (nan)	prob nan (nan)	GS 37.562 (37.562)	mem 42.495
Train: [28][185/750]	BT 0.096 (1.166)	DT 0.018 (1.031)	loss nan (nan)	prob nan (nan)	GS 32.219 (32.219)	mem 42.634
Train: [28][190/750]	BT 0.104 (1.176)	DT 0.002 (1.041)	loss nan (nan)	prob nan (nan)	GS 34.234 (34.234)	mem 42.575
Train: [28][195/750]	BT 0.072 (1.184)	DT 0.001 (1.049)	loss nan (nan)	prob nan (nan)	GS 31.547 (31.547)	mem 42.586
Train: [28][200/750]	BT 2.602 (1.190)	DT 2.486 (1.054)	loss nan (nan)	prob nan (nan)	GS 32.609 (32.609)	mem 42.525
Train: [28][205/750]	BT 0.090 (1.203)	DT 0.002 (1.067)	loss nan (nan)	prob nan (nan)	GS 34.844 (34.844)	mem 42.519
Train: [28][210/750]	BT 1.030 (1.181)	DT 0.889 (1.046)	loss nan (nan)	prob nan (nan)	GS 35.438 (35.438)	mem 42.525
Train: [28][215/750]	BT 0.156 (1.158)	DT 0.002 (1.023)	loss nan (nan)	prob nan (nan)	GS 30.906 (30.906)	mem 42.541
Train: [28][220/750]	BT 0.075 (1.183)	DT 0.001 (1.050)	loss nan (nan)	prob nan (nan)	GS 32.422 (32.422)	mem 42.537
Train: [28][225/750]	BT 0.116 (1.164)	DT 0.001 (1.030)	loss nan (nan)	prob nan (nan)	GS 29.828 (29.828)	mem 42.567
Train: [28][230/750]	BT 0.087 (1.180)	DT 0.002 (1.047)	loss nan (nan)	prob nan (nan)	GS 31.656 (31.656)	mem 42.638
Train: [28][235/750]	BT 0.080 (1.168)	DT 0.004 (1.034)	loss nan (nan)	prob nan (nan)	GS 32.891 (32.891)	mem 42.540
Train: [28][240/750]	BT 8.675 (1.196)	DT 8.500 (1.063)	loss nan (nan)	prob nan (nan)	GS 34.812 (34.812)	mem 42.581
Train: [28][245/750]	BT 0.137 (1.175)	DT 0.002 (1.042)	loss nan (nan)	prob nan (nan)	GS 34.859 (34.859)	mem 42.632
Train: [28][250/750]	BT 0.134 (1.172)	DT 0.001 (1.039)	loss nan (nan)	prob nan (nan)	GS 34.891 (34.891)	mem 42.632
Train: [28][255/750]	BT 0.075 (1.170)	DT 0.002 (1.036)	loss nan (nan)	prob nan (nan)	GS 38.281 (38.281)	mem 42.454
Train: [28][260/750]	BT 1.942 (1.171)	DT 1.823 (1.037)	loss nan (nan)	prob nan (nan)	GS 32.094 (32.094)	mem 42.475
Train: [28][265/750]	BT 0.090 (1.175)	DT 0.002 (1.040)	loss nan (nan)	prob nan (nan)	GS 30.359 (30.359)	mem 42.631
Train: [28][270/750]	BT 0.191 (1.176)	DT 0.016 (1.042)	loss nan (nan)	prob nan (nan)	GS 30.672 (30.672)	mem 42.516
Train: [28][275/750]	BT 0.098 (1.159)	DT 0.010 (1.025)	loss nan (nan)	prob nan (nan)	GS 34.000 (34.000)	mem 42.452
Train: [28][280/750]	BT 4.823 (1.179)	DT 4.713 (1.045)	loss nan (nan)	prob nan (nan)	GS 36.969 (36.969)	mem 42.463
Train: [28][285/750]	BT 0.102 (1.165)	DT 0.001 (1.031)	loss nan (nan)	prob nan (nan)	GS 28.609 (28.609)	mem 42.352
Train: [28][290/750]	BT 1.043 (1.162)	DT 0.767 (1.028)	loss nan (nan)	prob nan (nan)	GS 35.344 (35.344)	mem 42.514
Train: [28][295/750]	BT 0.144 (1.161)	DT 0.002 (1.027)	loss nan (nan)	prob nan (nan)	GS 32.219 (32.219)	mem 42.560
Train: [28][300/750]	BT 0.150 (1.160)	DT 0.024 (1.026)	loss nan (nan)	prob nan (nan)	GS 32.250 (32.250)	mem 42.634
Train: [28][305/750]	BT 0.070 (1.156)	DT 0.001 (1.022)	loss nan (nan)	prob nan (nan)	GS 29.266 (29.266)	mem 42.692
Train: [28][310/750]	BT 0.754 (1.157)	DT 0.584 (1.022)	loss nan (nan)	prob nan (nan)	GS 30.859 (30.859)	mem 42.778
Train: [28][315/750]	BT 0.106 (1.153)	DT 0.004 (1.019)	loss nan (nan)	prob nan (nan)	GS 32.500 (32.500)	mem 42.492
Train: [28][320/750]	BT 9.610 (1.166)	DT 9.497 (1.033)	loss nan (nan)	prob nan (nan)	GS 37.078 (37.078)	mem 42.641
Train: [28][325/750]	BT 0.177 (1.153)	DT 0.016 (1.020)	loss nan (nan)	prob nan (nan)	GS 28.781 (28.781)	mem 42.576
Train: [28][330/750]	BT 0.106 (1.138)	DT 0.001 (1.005)	loss nan (nan)	prob nan (nan)	GS 31.172 (31.172)	mem 42.602
Train: [28][335/750]	BT 0.115 (1.164)	DT 0.005 (1.031)	loss nan (nan)	prob nan (nan)	GS 31.750 (31.750)	mem 42.521
Train: [28][340/750]	BT 0.303 (1.149)	DT 0.005 (1.016)	loss nan (nan)	prob nan (nan)	GS 35.438 (35.438)	mem 42.481
Train: [28][345/750]	BT 0.167 (1.165)	DT 0.002 (1.032)	loss nan (nan)	prob nan (nan)	GS 31.141 (31.141)	mem 42.507
Train: [28][350/750]	BT 0.190 (1.151)	DT 0.002 (1.018)	loss nan (nan)	prob nan (nan)	GS 33.969 (33.969)	mem 42.403
Train: [28][355/750]	BT 0.239 (1.139)	DT 0.026 (1.005)	loss nan (nan)	prob nan (nan)	GS 31.438 (31.438)	mem 42.409
Train: [28][360/750]	BT 0.092 (1.166)	DT 0.002 (1.033)	loss nan (nan)	prob nan (nan)	GS 32.656 (32.656)	mem 42.496
Train: [28][365/750]	BT 0.137 (1.152)	DT 0.001 (1.019)	loss nan (nan)	prob nan (nan)	GS 33.750 (33.750)	mem 42.496
Train: [28][370/750]	BT 2.628 (1.164)	DT 2.393 (1.030)	loss nan (nan)	prob nan (nan)	GS 32.484 (32.484)	mem 42.507
Train: [28][375/750]	BT 0.123 (1.150)	DT 0.010 (1.017)	loss nan (nan)	prob nan (nan)	GS 32.516 (32.516)	mem 42.511
Train: [28][380/750]	BT 7.125 (1.155)	DT 7.006 (1.022)	loss nan (nan)	prob nan (nan)	GS 36.312 (36.312)	mem 42.486
Train: [28][385/750]	BT 0.083 (1.153)	DT 0.001 (1.020)	loss nan (nan)	prob nan (nan)	GS 25.359 (25.359)	mem 42.391
Train: [28][390/750]	BT 0.228 (1.140)	DT 0.002 (1.007)	loss nan (nan)	prob nan (nan)	GS 31.656 (31.656)	mem 42.442
Train: [28][395/750]	BT 0.114 (1.158)	DT 0.001 (1.026)	loss nan (nan)	prob nan (nan)	GS 30.344 (30.344)	mem 42.547
Train: [28][400/750]	BT 0.131 (1.146)	DT 0.001 (1.013)	loss nan (nan)	prob nan (nan)	GS 31.172 (31.172)	mem 42.567
Train: [28][405/750]	BT 0.102 (1.159)	DT 0.016 (1.027)	loss nan (nan)	prob nan (nan)	GS 29.922 (29.922)	mem 42.652
Train: [28][410/750]	BT 0.127 (1.147)	DT 0.001 (1.015)	loss nan (nan)	prob nan (nan)	GS 34.125 (34.125)	mem 42.556
Train: [28][415/750]	BT 0.171 (1.135)	DT 0.002 (1.002)	loss nan (nan)	prob nan (nan)	GS 29.734 (29.734)	mem 42.557
Train: [28][420/750]	BT 0.134 (1.149)	DT 0.002 (1.016)	loss nan (nan)	prob nan (nan)	GS 32.406 (32.406)	mem 42.560
Train: [28][425/750]	BT 0.139 (1.140)	DT 0.005 (1.008)	loss nan (nan)	prob nan (nan)	GS 31.391 (31.391)	mem 42.826
Train: [28][430/750]	BT 4.944 (1.161)	DT 4.841 (1.029)	loss nan (nan)	prob nan (nan)	GS 34.328 (34.328)	mem 42.595
Train: [28][435/750]	BT 0.188 (1.150)	DT 0.004 (1.018)	loss nan (nan)	prob nan (nan)	GS 31.000 (31.000)	mem 42.595
Train: [28][440/750]	BT 6.978 (1.156)	DT 6.816 (1.024)	loss nan (nan)	prob nan (nan)	GS 34.750 (34.750)	mem 42.717
Train: [28][445/750]	BT 0.121 (1.159)	DT 0.002 (1.027)	loss nan (nan)	prob nan (nan)	GS 28.453 (28.453)	mem 42.665
Train: [28][450/750]	BT 0.085 (1.148)	DT 0.001 (1.016)	loss nan (nan)	prob nan (nan)	GS 37.938 (37.938)	mem 42.608
Train: [28][455/750]	BT 0.164 (1.158)	DT 0.002 (1.026)	loss nan (nan)	prob nan (nan)	GS 30.891 (30.891)	mem 42.622
Train: [28][460/750]	BT 4.315 (1.156)	DT 4.244 (1.024)	loss nan (nan)	prob nan (nan)	GS 29.750 (29.750)	mem 42.638
Train: [28][465/750]	BT 0.117 (1.145)	DT 0.002 (1.013)	loss nan (nan)	prob nan (nan)	GS 30.656 (30.656)	mem 42.728
Train: [28][470/750]	BT 0.143 (1.155)	DT 0.001 (1.023)	loss nan (nan)	prob nan (nan)	GS 32.500 (32.500)	mem 42.653
Train: [28][475/750]	BT 0.110 (1.154)	DT 0.005 (1.023)	loss nan (nan)	prob nan (nan)	GS 32.141 (32.141)	mem 42.737
Train: [28][480/750]	BT 0.101 (1.163)	DT 0.002 (1.031)	loss nan (nan)	prob nan (nan)	GS 37.969 (37.969)	mem 42.646
Train: [28][485/750]	BT 0.214 (1.161)	DT 0.008 (1.030)	loss nan (nan)	prob nan (nan)	GS 29.625 (29.625)	mem 42.804
Train: [28][490/750]	BT 9.056 (1.170)	DT 8.943 (1.037)	loss nan (nan)	prob nan (nan)	GS 36.969 (36.969)	mem 42.681
Train: [28][495/750]	BT 0.125 (1.159)	DT 0.002 (1.027)	loss nan (nan)	prob nan (nan)	GS 33.297 (33.297)	mem 42.577
Train: [28][500/750]	BT 0.125 (1.149)	DT 0.002 (1.017)	loss nan (nan)	prob nan (nan)	GS 36.547 (36.547)	mem 42.591
Train: [28][505/750]	BT 0.102 (1.171)	DT 0.001 (1.040)	loss nan (nan)	prob nan (nan)	GS 31.969 (31.969)	mem 42.607
Train: [28][510/750]	BT 0.133 (1.161)	DT 0.013 (1.030)	loss nan (nan)	prob nan (nan)	GS 32.312 (32.312)	mem 42.610
Train: [28][515/750]	BT 0.152 (1.176)	DT 0.002 (1.044)	loss nan (nan)	prob nan (nan)	GS 27.828 (27.828)	mem 42.586
Train: [28][520/750]	BT 0.103 (1.166)	DT 0.002 (1.034)	loss nan (nan)	prob nan (nan)	GS 35.516 (35.516)	mem 42.589
Train: [28][525/750]	BT 0.222 (1.156)	DT 0.002 (1.024)	loss nan (nan)	prob nan (nan)	GS 34.750 (34.750)	mem 42.590
Train: [28][530/750]	BT 0.175 (1.164)	DT 0.004 (1.032)	loss nan (nan)	prob nan (nan)	GS 34.250 (34.250)	mem 42.544
Train: [28][535/750]	BT 0.162 (1.156)	DT 0.005 (1.023)	loss nan (nan)	prob nan (nan)	GS 32.500 (32.500)	mem 42.553
Train: [28][540/750]	BT 0.102 (1.165)	DT 0.002 (1.032)	loss nan (nan)	prob nan (nan)	GS 36.016 (36.016)	mem 42.742
Train: [28][545/750]	BT 0.164 (1.156)	DT 0.002 (1.023)	loss nan (nan)	prob nan (nan)	GS 33.797 (33.797)	mem 42.614
Train: [28][550/750]	BT 13.529 (1.171)	DT 13.416 (1.038)	loss nan (nan)	prob nan (nan)	GS 34.656 (34.656)	mem 42.789
Train: [28][555/750]	BT 0.148 (1.162)	DT 0.011 (1.029)	loss nan (nan)	prob nan (nan)	GS 31.625 (31.625)	mem 42.597
Train: [28][560/750]	BT 0.138 (1.152)	DT 0.002 (1.020)	loss nan (nan)	prob nan (nan)	GS 35.750 (35.750)	mem 42.590
Train: [28][565/750]	BT 0.131 (1.160)	DT 0.002 (1.027)	loss nan (nan)	prob nan (nan)	GS 31.875 (31.875)	mem 42.707
Train: [28][570/750]	BT 0.109 (1.151)	DT 0.003 (1.018)	loss nan (nan)	prob nan (nan)	GS 38.016 (38.016)	mem 42.576
Train: [28][575/750]	BT 0.078 (1.165)	DT 0.001 (1.032)	loss nan (nan)	prob nan (nan)	GS 33.047 (33.047)	mem 42.544
Train: [28][580/750]	BT 0.141 (1.156)	DT 0.001 (1.024)	loss nan (nan)	prob nan (nan)	GS 34.516 (34.516)	mem 42.855
Train: [28][585/750]	BT 0.104 (1.147)	DT 0.005 (1.015)	loss nan (nan)	prob nan (nan)	GS 29.812 (29.812)	mem 42.720
Train: [28][590/750]	BT 0.132 (1.161)	DT 0.001 (1.029)	loss nan (nan)	prob nan (nan)	GS 35.688 (35.688)	mem 42.587
Train: [28][595/750]	BT 0.133 (1.153)	DT 0.002 (1.021)	loss nan (nan)	prob nan (nan)	GS 30.234 (30.234)	mem 42.542
Train: [28][600/750]	BT 0.123 (1.164)	DT 0.002 (1.032)	loss nan (nan)	prob nan (nan)	GS 37.969 (37.969)	mem 42.654
Train: [28][605/750]	BT 0.145 (1.157)	DT 0.011 (1.025)	loss nan (nan)	prob nan (nan)	GS 34.125 (34.125)	mem 42.573
Train: [28][610/750]	BT 11.347 (1.167)	DT 11.222 (1.035)	loss nan (nan)	prob nan (nan)	GS 33.469 (33.469)	mem 42.654
Train: [28][615/750]	BT 0.219 (1.159)	DT 0.006 (1.027)	loss nan (nan)	prob nan (nan)	GS 32.984 (32.984)	mem 42.804
Train: [28][620/750]	BT 0.130 (1.154)	DT 0.002 (1.022)	loss nan (nan)	prob nan (nan)	GS 31.891 (31.891)	mem 42.639
Train: [28][625/750]	BT 0.081 (1.164)	DT 0.002 (1.031)	loss nan (nan)	prob nan (nan)	GS 36.062 (36.062)	mem 42.708
Train: [28][630/750]	BT 0.211 (1.156)	DT 0.001 (1.024)	loss nan (nan)	prob nan (nan)	GS 37.109 (37.109)	mem 42.877
Train: [28][635/750]	BT 0.150 (1.162)	DT 0.002 (1.030)	loss nan (nan)	prob nan (nan)	GS 30.234 (30.234)	mem 42.895
Train: [28][640/750]	BT 0.187 (1.156)	DT 0.020 (1.024)	loss nan (nan)	prob nan (nan)	GS 31.953 (31.953)	mem 42.624
Train: [28][645/750]	BT 0.246 (1.149)	DT 0.002 (1.016)	loss nan (nan)	prob nan (nan)	GS 26.891 (26.891)	mem 42.711
Train: [28][650/750]	BT 0.165 (1.157)	DT 0.001 (1.025)	loss nan (nan)	prob nan (nan)	GS 34.375 (34.375)	mem 42.665
Train: [28][655/750]	BT 0.216 (1.154)	DT 0.002 (1.021)	loss nan (nan)	prob nan (nan)	GS 30.359 (30.359)	mem 42.794
Train: [28][660/750]	BT 4.154 (1.165)	DT 4.052 (1.032)	loss nan (nan)	prob nan (nan)	GS 30.391 (30.391)	mem 42.784
Train: [28][665/750]	BT 0.085 (1.157)	DT 0.002 (1.024)	loss nan (nan)	prob nan (nan)	GS 30.062 (30.062)	mem 42.746
Train: [28][670/750]	BT 6.560 (1.158)	DT 6.453 (1.026)	loss nan (nan)	prob nan (nan)	GS 34.688 (34.688)	mem 42.682
Train: [28][675/750]	BT 0.127 (1.161)	DT 0.002 (1.028)	loss nan (nan)	prob nan (nan)	GS 30.672 (30.672)	mem 42.622
Train: [28][680/750]	BT 0.124 (1.153)	DT 0.020 (1.021)	loss nan (nan)	prob nan (nan)	GS 35.734 (35.734)	mem 42.790
Train: [28][685/750]	BT 0.133 (1.164)	DT 0.015 (1.032)	loss nan (nan)	prob nan (nan)	GS 30.719 (30.719)	mem 42.537
Train: [28][690/750]	BT 0.086 (1.156)	DT 0.002 (1.024)	loss nan (nan)	prob nan (nan)	GS 34.531 (34.531)	mem 42.553
Train: [28][695/750]	BT 0.305 (1.154)	DT 0.002 (1.022)	loss nan (nan)	prob nan (nan)	GS 34.375 (34.375)	mem 42.702
Train: [28][700/750]	BT 0.104 (1.161)	DT 0.002 (1.029)	loss nan (nan)	prob nan (nan)	GS 35.641 (35.641)	mem 42.651
Train: [28][705/750]	BT 0.121 (1.154)	DT 0.007 (1.021)	loss nan (nan)	prob nan (nan)	GS 33.203 (33.203)	mem 42.731
Train: [28][710/750]	BT 0.137 (1.163)	DT 0.004 (1.030)	loss nan (nan)	prob nan (nan)	GS 38.625 (38.625)	mem 42.716
Train: [28][715/750]	BT 0.182 (1.156)	DT 0.003 (1.023)	loss nan (nan)	prob nan (nan)	GS 27.734 (27.734)	mem 42.737
Train: [28][720/750]	BT 6.517 (1.169)	DT 6.434 (1.036)	loss nan (nan)	prob nan (nan)	GS 33.234 (33.234)	mem 42.641
Train: [28][725/750]	BT 0.235 (1.162)	DT 0.002 (1.029)	loss nan (nan)	prob nan (nan)	GS 29.953 (29.953)	mem 42.642
Train: [28][730/750]	BT 4.816 (1.161)	DT 4.743 (1.028)	loss nan (nan)	prob nan (nan)	GS 32.266 (32.266)	mem 42.287
Train: [28][735/750]	BT 0.079 (1.160)	DT 0.001 (1.027)	loss nan (nan)	prob nan (nan)	GS 35.219 (35.219)	mem 41.998
Train: [28][740/750]	BT 0.081 (1.152)	DT 0.001 (1.020)	loss nan (nan)	prob nan (nan)	GS 34.891 (34.891)	mem 41.958
Train: [28][745/750]	BT 0.053 (1.152)	DT 0.001 (1.020)	loss nan (nan)	prob nan (nan)	GS 34.156 (34.156)	mem 13.306
Train: [28][750/750]	BT 0.054 (1.144)	DT 0.001 (1.013)	loss nan (nan)	prob nan (nan)	GS 33.438 (33.438)	mem 13.306
Train: [28][755/750]	BT 0.084 (1.139)	DT 0.001 (1.009)	loss nan (nan)	prob nan (nan)	GS 36.844 (36.844)	mem 13.212
epoch 28, total time 861.83
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [29][1/750]	BT 23.302 (23.302)	DT 23.171 (23.171)	loss nan (nan)	prob nan (nan)	GS 32.547 (32.547)	mem 41.186
Train: [29][5/750]	BT 0.106 (4.994)	DT 0.002 (4.862)	loss nan (nan)	prob nan (nan)	GS 28.719 (28.719)	mem 41.201
Train: [29][10/750]	BT 0.135 (2.602)	DT 0.001 (2.436)	loss nan (nan)	prob nan (nan)	GS 33.438 (33.438)	mem 41.193
Train: [29][15/750]	BT 0.139 (2.705)	DT 0.035 (2.549)	loss nan (nan)	prob nan (nan)	GS 43.359 (43.359)	mem 41.433
Train: [29][20/750]	BT 0.251 (2.082)	DT 0.001 (1.914)	loss nan (nan)	prob nan (nan)	GS 33.016 (33.016)	mem 41.574
Train: [29][25/750]	BT 0.374 (1.701)	DT 0.280 (1.543)	loss nan (nan)	prob nan (nan)	GS 31.484 (31.484)	mem 41.522
Train: [29][30/750]	BT 0.107 (1.821)	DT 0.001 (1.663)	loss nan (nan)	prob nan (nan)	GS 30.609 (30.609)	mem 41.507
Train: [29][35/750]	BT 0.106 (1.575)	DT 0.001 (1.426)	loss nan (nan)	prob nan (nan)	GS 32.516 (32.516)	mem 41.618
Train: [29][40/750]	BT 0.114 (1.703)	DT 0.002 (1.555)	loss nan (nan)	prob nan (nan)	GS 34.906 (34.906)	mem 41.508
Train: [29][45/750]	BT 0.100 (1.527)	DT 0.020 (1.383)	loss nan (nan)	prob nan (nan)	GS 34.547 (34.547)	mem 41.509
Train: [29][50/750]	BT 11.679 (1.619)	DT 11.543 (1.475)	loss nan (nan)	prob nan (nan)	GS 30.500 (30.500)	mem 41.619
Train: [29][55/750]	BT 0.170 (1.483)	DT 0.004 (1.342)	loss nan (nan)	prob nan (nan)	GS 29.875 (29.875)	mem 41.649
Train: [29][60/750]	BT 0.090 (1.372)	DT 0.001 (1.231)	loss nan (nan)	prob nan (nan)	GS 36.344 (36.344)	mem 41.758
Train: [29][65/750]	BT 0.112 (1.441)	DT 0.003 (1.301)	loss nan (nan)	prob nan (nan)	GS 32.266 (32.266)	mem 41.713
Train: [29][70/750]	BT 0.088 (1.419)	DT 0.002 (1.282)	loss nan (nan)	prob nan (nan)	GS 31.578 (31.578)	mem 41.791
Train: [29][75/750]	BT 0.100 (1.413)	DT 0.005 (1.278)	loss nan (nan)	prob nan (nan)	GS 26.391 (26.391)	mem 41.760
Train: [29][80/750]	BT 5.774 (1.406)	DT 5.612 (1.268)	loss nan (nan)	prob nan (nan)	GS 32.375 (32.375)	mem 41.768
Train: [29][85/750]	BT 0.139 (1.332)	DT 0.002 (1.195)	loss nan (nan)	prob nan (nan)	GS 30.969 (30.969)	mem 41.769
Train: [29][90/750]	BT 0.121 (1.303)	DT 0.001 (1.167)	loss nan (nan)	prob nan (nan)	GS 32.344 (32.344)	mem 41.718
Train: [29][95/750]	BT 0.149 (1.312)	DT 0.002 (1.177)	loss nan (nan)	prob nan (nan)	GS 36.859 (36.859)	mem 41.850
Train: [29][100/750]	BT 4.097 (1.325)	DT 3.937 (1.190)	loss nan (nan)	prob nan (nan)	GS 34.078 (34.078)	mem 41.900
Train: [29][105/750]	BT 0.064 (1.323)	DT 0.001 (1.188)	loss nan (nan)	prob nan (nan)	GS 29.172 (29.172)	mem 41.799
Train: [29][110/750]	BT 0.161 (1.273)	DT 0.002 (1.134)	loss nan (nan)	prob nan (nan)	GS 31.062 (31.062)	mem 41.800
Train: [29][115/750]	BT 0.089 (1.263)	DT 0.002 (1.125)	loss nan (nan)	prob nan (nan)	GS 34.531 (34.531)	mem 41.830
Train: [29][120/750]	BT 1.069 (1.281)	DT 0.976 (1.144)	loss nan (nan)	prob nan (nan)	GS 35.953 (35.953)	mem 41.870
Train: [29][125/750]	BT 0.095 (1.244)	DT 0.011 (1.106)	loss nan (nan)	prob nan (nan)	GS 35.172 (35.172)	mem 41.823
Train: [29][130/750]	BT 0.117 (1.289)	DT 0.009 (1.150)	loss nan (nan)	prob nan (nan)	GS 32.469 (32.469)	mem 41.828
Train: [29][135/750]	BT 0.129 (1.247)	DT 0.008 (1.108)	loss nan (nan)	prob nan (nan)	GS 29.188 (29.188)	mem 41.829
Train: [29][140/750]	BT 6.060 (1.305)	DT 5.897 (1.165)	loss nan (nan)	prob nan (nan)	GS 36.547 (36.547)	mem 41.883
Train: [29][145/750]	BT 0.106 (1.264)	DT 0.003 (1.125)	loss nan (nan)	prob nan (nan)	GS 37.219 (37.219)	mem 41.947
Train: [29][150/750]	BT 3.132 (1.247)	DT 3.034 (1.108)	loss nan (nan)	prob nan (nan)	GS 32.594 (32.594)	mem 42.376
Train: [29][155/750]	BT 0.085 (1.280)	DT 0.001 (1.142)	loss nan (nan)	prob nan (nan)	GS 36.578 (36.578)	mem 42.183
Train: [29][160/750]	BT 0.133 (1.244)	DT 0.001 (1.107)	loss nan (nan)	prob nan (nan)	GS 34.688 (34.688)	mem 42.201
Train: [29][165/750]	BT 0.182 (1.268)	DT 0.004 (1.131)	loss nan (nan)	prob nan (nan)	GS 34.312 (34.312)	mem 42.217
Train: [29][170/750]	BT 0.109 (1.235)	DT 0.005 (1.098)	loss nan (nan)	prob nan (nan)	GS 36.391 (36.391)	mem 42.350
Train: [29][175/750]	BT 0.135 (1.209)	DT 0.017 (1.072)	loss nan (nan)	prob nan (nan)	GS 28.422 (28.422)	mem 42.135
Train: [29][180/750]	BT 0.114 (1.255)	DT 0.001 (1.118)	loss nan (nan)	prob nan (nan)	GS 35.406 (35.406)	mem 42.250
Train: [29][185/750]	BT 0.227 (1.226)	DT 0.002 (1.088)	loss nan (nan)	prob nan (nan)	GS 30.266 (30.266)	mem 42.416
Train: [29][190/750]	BT 0.108 (1.269)	DT 0.016 (1.132)	loss nan (nan)	prob nan (nan)	GS 37.922 (37.922)	mem 42.473
Train: [29][195/750]	BT 0.109 (1.241)	DT 0.002 (1.103)	loss nan (nan)	prob nan (nan)	GS 36.391 (36.391)	mem 42.305
Train: [29][200/750]	BT 9.112 (1.260)	DT 9.012 (1.121)	loss nan (nan)	prob nan (nan)	GS 38.234 (38.234)	mem 42.451
Train: [29][205/750]	BT 0.098 (1.232)	DT 0.007 (1.093)	loss nan (nan)	prob nan (nan)	GS 35.891 (35.891)	mem 42.410
Train: [29][210/750]	BT 0.182 (1.206)	DT 0.001 (1.067)	loss nan (nan)	prob nan (nan)	GS 36.766 (36.766)	mem 42.557
Train: [29][215/750]	BT 0.146 (1.230)	DT 0.006 (1.091)	loss nan (nan)	prob nan (nan)	GS 36.859 (36.859)	mem 42.502
Train: [29][220/750]	BT 0.192 (1.211)	DT 0.001 (1.072)	loss nan (nan)	prob nan (nan)	GS 38.047 (38.047)	mem 42.705
Train: [29][225/750]	BT 0.104 (1.229)	DT 0.001 (1.090)	loss nan (nan)	prob nan (nan)	GS 28.859 (28.859)	mem 42.528
Train: [29][230/750]	BT 0.198 (1.206)	DT 0.058 (1.068)	loss nan (nan)	prob nan (nan)	GS 36.359 (36.359)	mem 42.534
Train: [29][235/750]	BT 0.094 (1.182)	DT 0.001 (1.045)	loss nan (nan)	prob nan (nan)	GS 30.734 (30.734)	mem 42.467
Train: [29][240/750]	BT 1.572 (1.207)	DT 1.436 (1.070)	loss nan (nan)	prob nan (nan)	GS 32.500 (32.500)	mem 42.542
Train: [29][245/750]	BT 0.095 (1.188)	DT 0.002 (1.051)	loss nan (nan)	prob nan (nan)	GS 34.109 (34.109)	mem 42.528
Train: [29][250/750]	BT 0.133 (1.197)	DT 0.018 (1.061)	loss nan (nan)	prob nan (nan)	GS 31.828 (31.828)	mem 42.528
Train: [29][255/750]	BT 0.122 (1.199)	DT 0.011 (1.063)	loss nan (nan)	prob nan (nan)	GS 27.359 (27.359)	mem 42.503
Train: [29][260/750]	BT 7.849 (1.208)	DT 7.717 (1.072)	loss nan (nan)	prob nan (nan)	GS 39.234 (39.234)	mem 42.530
Train: [29][265/750]	BT 0.127 (1.203)	DT 0.010 (1.068)	loss nan (nan)	prob nan (nan)	GS 30.891 (30.891)	mem 42.513
Train: [29][270/750]	BT 0.082 (1.185)	DT 0.002 (1.050)	loss nan (nan)	prob nan (nan)	GS 33.828 (33.828)	mem 42.494
Train: [29][275/750]	BT 0.081 (1.180)	DT 0.001 (1.045)	loss nan (nan)	prob nan (nan)	GS 35.609 (35.609)	mem 42.552
Train: [29][280/750]	BT 0.118 (1.198)	DT 0.008 (1.063)	loss nan (nan)	prob nan (nan)	GS 34.531 (34.531)	mem 42.239
Train: [29][285/750]	BT 0.182 (1.182)	DT 0.007 (1.047)	loss nan (nan)	prob nan (nan)	GS 32.062 (32.062)	mem 42.280
Train: [29][290/750]	BT 3.449 (1.204)	DT 3.362 (1.069)	loss nan (nan)	prob nan (nan)	GS 36.938 (36.938)	mem 42.297
Train: [29][295/750]	BT 0.081 (1.186)	DT 0.002 (1.051)	loss nan (nan)	prob nan (nan)	GS 36.984 (36.984)	mem 42.298
Train: [29][300/750]	BT 11.604 (1.206)	DT 11.411 (1.071)	loss nan (nan)	prob nan (nan)	GS 36.719 (36.719)	mem 43.026
Train: [29][305/750]	BT 0.142 (1.199)	DT 0.002 (1.065)	loss nan (nan)	prob nan (nan)	GS 31.266 (31.266)	mem 42.664
Train: [29][310/750]	BT 0.134 (1.183)	DT 0.003 (1.048)	loss nan (nan)	prob nan (nan)	GS 37.703 (37.703)	mem 42.740
Train: [29][315/750]	BT 0.148 (1.202)	DT 0.010 (1.067)	loss nan (nan)	prob nan (nan)	GS 28.781 (28.781)	mem 44.202
Train: [29][320/750]	BT 0.139 (1.186)	DT 0.011 (1.050)	loss nan (nan)	prob nan (nan)	GS 33.734 (33.734)	mem 44.432
Train: [29][325/750]	BT 0.145 (1.206)	DT 0.003 (1.071)	loss nan (nan)	prob nan (nan)	GS 30.922 (30.922)	mem 44.092
Train: [29][330/750]	BT 0.069 (1.189)	DT 0.001 (1.055)	loss nan (nan)	prob nan (nan)	GS 29.562 (29.562)	mem 44.101
Train: [29][335/750]	BT 0.122 (1.173)	DT 0.011 (1.039)	loss nan (nan)	prob nan (nan)	GS 28.547 (28.547)	mem 44.125
Train: [29][340/750]	BT 0.076 (1.194)	DT 0.001 (1.060)	loss nan (nan)	prob nan (nan)	GS 32.062 (32.062)	mem 44.040
Train: [29][345/750]	BT 0.175 (1.178)	DT 0.035 (1.045)	loss nan (nan)	prob nan (nan)	GS 29.750 (29.750)	mem 44.006
Train: [29][350/750]	BT 0.081 (1.191)	DT 0.001 (1.058)	loss nan (nan)	prob nan (nan)	GS 33.797 (33.797)	mem 44.046
Train: [29][355/750]	BT 0.173 (1.176)	DT 0.003 (1.043)	loss nan (nan)	prob nan (nan)	GS 30.359 (30.359)	mem 44.075
Train: [29][360/750]	BT 13.036 (1.198)	DT 12.967 (1.065)	loss nan (nan)	prob nan (nan)	GS 33.859 (33.859)	mem 43.987
Train: [29][365/750]	BT 0.170 (1.183)	DT 0.020 (1.050)	loss nan (nan)	prob nan (nan)	GS 28.344 (28.344)	mem 44.032
Train: [29][370/750]	BT 0.294 (1.170)	DT 0.005 (1.036)	loss nan (nan)	prob nan (nan)	GS 33.297 (33.297)	mem 44.060
Train: [29][375/750]	BT 0.160 (1.186)	DT 0.002 (1.052)	loss nan (nan)	prob nan (nan)	GS 31.781 (31.781)	mem 43.956
Train: [29][380/750]	BT 0.098 (1.172)	DT 0.001 (1.038)	loss nan (nan)	prob nan (nan)	GS 34.688 (34.688)	mem 44.054
Train: [29][385/750]	BT 0.091 (1.189)	DT 0.001 (1.055)	loss nan (nan)	prob nan (nan)	GS 34.016 (34.016)	mem 43.962
Train: [29][390/750]	BT 0.069 (1.176)	DT 0.001 (1.041)	loss nan (nan)	prob nan (nan)	GS 35.000 (35.000)	mem 43.964
Train: [29][395/750]	BT 0.114 (1.162)	DT 0.001 (1.028)	loss nan (nan)	prob nan (nan)	GS 30.500 (30.500)	mem 44.061
Train: [29][400/750]	BT 0.088 (1.171)	DT 0.002 (1.037)	loss nan (nan)	prob nan (nan)	GS 30.281 (30.281)	mem 44.101
Train: [29][405/750]	BT 0.204 (1.159)	DT 0.006 (1.025)	loss nan (nan)	prob nan (nan)	GS 34.391 (34.391)	mem 43.944
Train: [29][410/750]	BT 0.085 (1.174)	DT 0.001 (1.040)	loss nan (nan)	prob nan (nan)	GS 35.203 (35.203)	mem 44.188
Train: [29][415/750]	BT 0.124 (1.161)	DT 0.011 (1.027)	loss nan (nan)	prob nan (nan)	GS 32.578 (32.578)	mem 43.894
Train: [29][420/750]	BT 11.054 (1.178)	DT 10.958 (1.044)	loss nan (nan)	prob nan (nan)	GS 31.672 (31.672)	mem 43.781
Train: [29][425/750]	BT 0.133 (1.165)	DT 0.003 (1.032)	loss nan (nan)	prob nan (nan)	GS 34.859 (34.859)	mem 43.838
Train: [29][430/750]	BT 0.092 (1.153)	DT 0.002 (1.020)	loss nan (nan)	prob nan (nan)	GS 36.188 (36.188)	mem 43.851
Train: [29][435/750]	BT 0.080 (1.172)	DT 0.002 (1.038)	loss nan (nan)	prob nan (nan)	GS 32.875 (32.875)	mem 43.936
Train: [29][440/750]	BT 0.085 (1.160)	DT 0.001 (1.027)	loss nan (nan)	prob nan (nan)	GS 34.844 (34.844)	mem 43.935
Train: [29][445/750]	BT 0.115 (1.176)	DT 0.002 (1.043)	loss nan (nan)	prob nan (nan)	GS 28.203 (28.203)	mem 43.893
Train: [29][450/750]	BT 0.114 (1.164)	DT 0.002 (1.031)	loss nan (nan)	prob nan (nan)	GS 33.281 (33.281)	mem 43.910
Train: [29][455/750]	BT 0.101 (1.153)	DT 0.002 (1.020)	loss nan (nan)	prob nan (nan)	GS 32.719 (32.719)	mem 44.019
Train: [29][460/750]	BT 0.174 (1.167)	DT 0.012 (1.034)	loss nan (nan)	prob nan (nan)	GS 36.922 (36.922)	mem 43.920
Train: [29][465/750]	BT 0.223 (1.156)	DT 0.003 (1.023)	loss nan (nan)	prob nan (nan)	GS 33.984 (33.984)	mem 43.956
Train: [29][470/750]	BT 0.168 (1.171)	DT 0.005 (1.039)	loss nan (nan)	prob nan (nan)	GS 34.062 (34.062)	mem 43.941
Train: [29][475/750]	BT 0.074 (1.160)	DT 0.002 (1.028)	loss nan (nan)	prob nan (nan)	GS 32.953 (32.953)	mem 43.943
Train: [29][480/750]	BT 11.786 (1.174)	DT 11.607 (1.041)	loss nan (nan)	prob nan (nan)	GS 31.891 (31.891)	mem 43.889
Train: [29][485/750]	BT 0.124 (1.163)	DT 0.002 (1.031)	loss nan (nan)	prob nan (nan)	GS 31.719 (31.719)	mem 43.897
Train: [29][490/750]	BT 0.133 (1.153)	DT 0.002 (1.020)	loss nan (nan)	prob nan (nan)	GS 36.031 (36.031)	mem 43.910
Train: [29][495/750]	BT 0.067 (1.164)	DT 0.001 (1.032)	loss nan (nan)	prob nan (nan)	GS 30.172 (30.172)	mem 43.957
Train: [29][500/750]	BT 0.075 (1.153)	DT 0.002 (1.021)	loss nan (nan)	prob nan (nan)	GS 31.266 (31.266)	mem 43.926
Train: [29][505/750]	BT 0.064 (1.164)	DT 0.001 (1.032)	loss nan (nan)	prob nan (nan)	GS 27.562 (27.562)	mem 43.835
Train: [29][510/750]	BT 0.118 (1.154)	DT 0.001 (1.022)	loss nan (nan)	prob nan (nan)	GS 36.500 (36.500)	mem 43.875
Train: [29][515/750]	BT 0.198 (1.144)	DT 0.019 (1.012)	loss nan (nan)	prob nan (nan)	GS 27.500 (27.500)	mem 43.887
Train: [29][520/750]	BT 0.108 (1.156)	DT 0.004 (1.025)	loss nan (nan)	prob nan (nan)	GS 35.328 (35.328)	mem 43.891
Train: [29][525/750]	BT 0.203 (1.146)	DT 0.002 (1.015)	loss nan (nan)	prob nan (nan)	GS 29.562 (29.562)	mem 44.046
Train: [29][530/750]	BT 4.436 (1.162)	DT 4.346 (1.031)	loss nan (nan)	prob nan (nan)	GS 35.453 (35.453)	mem 43.965
Train: [29][535/750]	BT 0.093 (1.152)	DT 0.002 (1.021)	loss nan (nan)	prob nan (nan)	GS 26.469 (26.469)	mem 43.981
Train: [29][540/750]	BT 4.971 (1.152)	DT 4.812 (1.021)	loss nan (nan)	prob nan (nan)	GS 34.344 (34.344)	mem 44.132
Train: [29][545/750]	BT 0.093 (1.154)	DT 0.002 (1.023)	loss nan (nan)	prob nan (nan)	GS 31.875 (31.875)	mem 44.380
Train: [29][550/750]	BT 0.090 (1.145)	DT 0.002 (1.014)	loss nan (nan)	prob nan (nan)	GS 33.266 (33.266)	mem 43.854
Train: [29][555/750]	BT 0.102 (1.158)	DT 0.002 (1.026)	loss nan (nan)	prob nan (nan)	GS 34.016 (34.016)	mem 43.220
Train: [29][560/750]	BT 0.117 (1.149)	DT 0.004 (1.017)	loss nan (nan)	prob nan (nan)	GS 36.594 (36.594)	mem 43.275
Train: [29][565/750]	BT 0.141 (1.152)	DT 0.012 (1.021)	loss nan (nan)	prob nan (nan)	GS 33.250 (33.250)	mem 43.337
Train: [29][570/750]	BT 0.124 (1.157)	DT 0.002 (1.026)	loss nan (nan)	prob nan (nan)	GS 31.125 (31.125)	mem 41.770
Train: [29][575/750]	BT 0.100 (1.148)	DT 0.010 (1.017)	loss nan (nan)	prob nan (nan)	GS 27.297 (27.297)	mem 41.827
Train: [29][580/750]	BT 0.159 (1.161)	DT 0.002 (1.030)	loss nan (nan)	prob nan (nan)	GS 33.625 (33.625)	mem 41.824
Train: [29][585/750]	BT 0.077 (1.152)	DT 0.001 (1.021)	loss nan (nan)	prob nan (nan)	GS 25.781 (25.781)	mem 41.752
Train: [29][590/750]	BT 8.471 (1.162)	DT 8.311 (1.031)	loss nan (nan)	prob nan (nan)	GS 30.031 (30.031)	mem 41.810
Train: [29][595/750]	BT 0.113 (1.153)	DT 0.001 (1.023)	loss nan (nan)	prob nan (nan)	GS 26.875 (26.875)	mem 41.748
Train: [29][600/750]	BT 5.984 (1.155)	DT 5.829 (1.024)	loss nan (nan)	prob nan (nan)	GS 33.328 (33.328)	mem 42.079
Train: [29][605/750]	BT 0.125 (1.156)	DT 0.002 (1.026)	loss nan (nan)	prob nan (nan)	GS 29.922 (29.922)	mem 41.673
Train: [29][610/750]	BT 0.194 (1.148)	DT 0.001 (1.017)	loss nan (nan)	prob nan (nan)	GS 30.922 (30.922)	mem 41.674
Train: [29][615/750]	BT 0.101 (1.159)	DT 0.002 (1.028)	loss nan (nan)	prob nan (nan)	GS 29.578 (29.578)	mem 41.836
Train: [29][620/750]	BT 0.130 (1.151)	DT 0.001 (1.020)	loss nan (nan)	prob nan (nan)	GS 31.281 (31.281)	mem 41.756
Train: [29][625/750]	BT 0.109 (1.146)	DT 0.002 (1.015)	loss nan (nan)	prob nan (nan)	GS 33.375 (33.375)	mem 41.771
Train: [29][630/750]	BT 0.192 (1.153)	DT 0.001 (1.022)	loss nan (nan)	prob nan (nan)	GS 33.953 (33.953)	mem 41.693
Train: [29][635/750]	BT 0.172 (1.145)	DT 0.002 (1.014)	loss nan (nan)	prob nan (nan)	GS 30.250 (30.250)	mem 41.786
Train: [29][640/750]	BT 0.090 (1.156)	DT 0.002 (1.025)	loss nan (nan)	prob nan (nan)	GS 34.641 (34.641)	mem 41.874
Train: [29][645/750]	BT 0.106 (1.148)	DT 0.002 (1.017)	loss nan (nan)	prob nan (nan)	GS 27.250 (27.250)	mem 41.731
Train: [29][650/750]	BT 11.584 (1.158)	DT 11.510 (1.027)	loss nan (nan)	prob nan (nan)	GS 33.750 (33.750)	mem 41.723
Train: [29][655/750]	BT 0.092 (1.150)	DT 0.002 (1.019)	loss nan (nan)	prob nan (nan)	GS 26.953 (26.953)	mem 41.906
Train: [29][660/750]	BT 0.342 (1.142)	DT 0.214 (1.012)	loss nan (nan)	prob nan (nan)	GS 36.328 (36.328)	mem 41.742
Train: [29][665/750]	BT 0.068 (1.153)	DT 0.001 (1.023)	loss nan (nan)	prob nan (nan)	GS 31.969 (31.969)	mem 41.786
Train: [29][670/750]	BT 0.190 (1.146)	DT 0.002 (1.015)	loss nan (nan)	prob nan (nan)	GS 31.047 (31.047)	mem 41.833
Train: [29][675/750]	BT 0.075 (1.156)	DT 0.001 (1.026)	loss nan (nan)	prob nan (nan)	GS 29.219 (29.219)	mem 41.722
Train: [29][680/750]	BT 0.155 (1.148)	DT 0.002 (1.018)	loss nan (nan)	prob nan (nan)	GS 33.719 (33.719)	mem 41.908
Train: [29][685/750]	BT 0.155 (1.141)	DT 0.011 (1.011)	loss nan (nan)	prob nan (nan)	GS 31.297 (31.297)	mem 41.752
Train: [29][690/750]	BT 0.145 (1.150)	DT 0.002 (1.020)	loss nan (nan)	prob nan (nan)	GS 35.359 (35.359)	mem 41.830
Train: [29][695/750]	BT 0.110 (1.143)	DT 0.001 (1.013)	loss nan (nan)	prob nan (nan)	GS 32.828 (32.828)	mem 41.788
Train: [29][700/750]	BT 0.077 (1.151)	DT 0.002 (1.021)	loss nan (nan)	prob nan (nan)	GS 35.641 (35.641)	mem 41.685
Train: [29][705/750]	BT 0.143 (1.143)	DT 0.002 (1.014)	loss nan (nan)	prob nan (nan)	GS 27.156 (27.156)	mem 41.644
arpack error, retry= 0
Train: [29][710/750]	BT 10.868 (1.154)	DT 10.776 (1.024)	loss nan (nan)	prob nan (nan)	GS 35.641 (35.641)	mem 41.720
Train: [29][715/750]	BT 0.116 (1.147)	DT 0.002 (1.017)	loss nan (nan)	prob nan (nan)	GS 29.750 (29.750)	mem 41.658
Train: [29][720/750]	BT 7.677 (1.150)	DT 7.564 (1.020)	loss nan (nan)	prob nan (nan)	GS 37.000 (37.000)	mem 42.013
Train: [29][725/750]	BT 0.084 (1.150)	DT 0.001 (1.020)	loss nan (nan)	prob nan (nan)	GS 29.953 (29.953)	mem 41.684
Train: [29][730/750]	BT 0.165 (1.143)	DT 0.019 (1.013)	loss nan (nan)	prob nan (nan)	GS 36.312 (36.312)	mem 41.646
Train: [29][735/750]	BT 0.078 (1.147)	DT 0.006 (1.018)	loss nan (nan)	prob nan (nan)	GS 32.312 (32.312)	mem 38.318
Train: [29][740/750]	BT 0.072 (1.140)	DT 0.002 (1.011)	loss nan (nan)	prob nan (nan)	GS 32.531 (32.531)	mem 38.320
Train: [29][745/750]	BT 0.076 (1.138)	DT 0.008 (1.009)	loss nan (nan)	prob nan (nan)	GS 32.000 (32.000)	mem 12.392
Train: [29][750/750]	BT 0.058 (1.131)	DT 0.002 (1.003)	loss nan (nan)	prob nan (nan)	GS 34.125 (34.125)	mem 12.254
Train: [29][755/750]	BT 0.048 (1.124)	DT 0.001 (0.996)	loss nan (nan)	prob nan (nan)	GS 29.000 (29.000)	mem 12.254
epoch 29, total time 851.12
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [30][1/750]	BT 29.926 (29.926)	DT 29.685 (29.685)	loss nan (nan)	prob nan (nan)	GS 39.500 (39.500)	mem 40.377
Train: [30][5/750]	BT 0.145 (6.120)	DT 0.014 (5.945)	loss nan (nan)	prob nan (nan)	GS 31.312 (31.312)	mem 40.443
Train: [30][10/750]	BT 0.106 (3.126)	DT 0.001 (2.974)	loss nan (nan)	prob nan (nan)	GS 32.609 (32.609)	mem 40.364
Train: [30][15/750]	BT 0.152 (2.937)	DT 0.002 (2.790)	loss nan (nan)	prob nan (nan)	GS 27.438 (27.438)	mem 40.785
Train: [30][20/750]	BT 3.226 (2.449)	DT 3.056 (2.307)	loss nan (nan)	prob nan (nan)	GS 39.016 (39.016)	mem 40.924
Train: [30][25/750]	BT 6.407 (2.241)	DT 6.249 (2.097)	loss nan (nan)	prob nan (nan)	GS 31.203 (31.203)	mem 40.752
Train: [30][30/750]	BT 2.059 (1.975)	DT 1.951 (1.833)	loss nan (nan)	prob nan (nan)	GS 36.422 (36.422)	mem 40.756
Train: [30][35/750]	BT 0.096 (1.837)	DT 0.001 (1.694)	loss nan (nan)	prob nan (nan)	GS 33.141 (33.141)	mem 40.785
Train: [30][40/750]	BT 0.151 (1.792)	DT 0.001 (1.649)	loss nan (nan)	prob nan (nan)	GS 36.797 (36.797)	mem 40.771
Train: [30][45/750]	BT 0.107 (1.758)	DT 0.005 (1.618)	loss nan (nan)	prob nan (nan)	GS 31.406 (31.406)	mem 40.861
Train: [30][50/750]	BT 3.494 (1.660)	DT 3.326 (1.523)	loss nan (nan)	prob nan (nan)	GS 33.062 (33.062)	mem 40.847
Train: [30][55/750]	BT 0.132 (1.542)	DT 0.002 (1.405)	loss nan (nan)	prob nan (nan)	GS 32.734 (32.734)	mem 40.728
Train: [30][60/750]	BT 0.093 (1.573)	DT 0.002 (1.438)	loss nan (nan)	prob nan (nan)	GS 34.078 (34.078)	mem 41.060
Train: [30][65/750]	BT 0.156 (1.532)	DT 0.002 (1.398)	loss nan (nan)	prob nan (nan)	GS 32.375 (32.375)	mem 41.056
Train: [30][70/750]	BT 0.107 (1.537)	DT 0.002 (1.404)	loss nan (nan)	prob nan (nan)	GS 34.000 (34.000)	mem 41.276
Train: [30][75/750]	BT 0.096 (1.484)	DT 0.001 (1.350)	loss nan (nan)	prob nan (nan)	GS 31.688 (31.688)	mem 41.499
Train: [30][80/750]	BT 10.643 (1.530)	DT 10.550 (1.398)	loss nan (nan)	prob nan (nan)	GS 36.625 (36.625)	mem 41.318
Train: [30][85/750]	BT 0.091 (1.448)	DT 0.007 (1.316)	loss nan (nan)	prob nan (nan)	GS 29.688 (29.688)	mem 41.329
Train: [30][90/750]	BT 0.091 (1.373)	DT 0.001 (1.243)	loss nan (nan)	prob nan (nan)	GS 34.016 (34.016)	mem 41.447
Train: [30][95/750]	BT 0.117 (1.452)	DT 0.005 (1.319)	loss nan (nan)	prob nan (nan)	GS 33.359 (33.359)	mem 41.465
Train: [30][100/750]	BT 0.164 (1.386)	DT 0.024 (1.254)	loss nan (nan)	prob nan (nan)	GS 37.281 (37.281)	mem 41.484
Train: [30][105/750]	BT 0.102 (1.437)	DT 0.001 (1.306)	loss nan (nan)	prob nan (nan)	GS 31.797 (31.797)	mem 41.515
Train: [30][110/750]	BT 1.385 (1.389)	DT 1.298 (1.259)	loss nan (nan)	prob nan (nan)	GS 35.922 (35.922)	mem 41.382
Train: [30][115/750]	BT 0.119 (1.335)	DT 0.011 (1.204)	loss nan (nan)	prob nan (nan)	GS 35.984 (35.984)	mem 41.478
Train: [30][120/750]	BT 0.176 (1.373)	DT 0.009 (1.242)	loss nan (nan)	prob nan (nan)	GS 38.016 (38.016)	mem 41.417
Train: [30][125/750]	BT 0.123 (1.331)	DT 0.002 (1.201)	loss nan (nan)	prob nan (nan)	GS 30.031 (30.031)	mem 41.444
Train: [30][130/750]	BT 0.113 (1.363)	DT 0.001 (1.232)	loss nan (nan)	prob nan (nan)	GS 33.281 (33.281)	mem 41.499
Train: [30][135/750]	BT 0.110 (1.321)	DT 0.002 (1.190)	loss nan (nan)	prob nan (nan)	GS 34.359 (34.359)	mem 41.454
Train: [30][140/750]	BT 10.801 (1.355)	DT 10.737 (1.224)	loss nan (nan)	prob nan (nan)	GS 34.312 (34.312)	mem 41.435
Train: [30][145/750]	BT 0.207 (1.312)	DT 0.011 (1.182)	loss nan (nan)	prob nan (nan)	GS 33.078 (33.078)	mem 41.661
Train: [30][150/750]	BT 0.138 (1.297)	DT 0.001 (1.167)	loss nan (nan)	prob nan (nan)	GS 34.219 (34.219)	mem 41.397
Train: [30][155/750]	BT 0.131 (1.304)	DT 0.008 (1.173)	loss nan (nan)	prob nan (nan)	GS 29.750 (29.750)	mem 41.537
Train: [30][160/750]	BT 0.083 (1.300)	DT 0.002 (1.170)	loss nan (nan)	prob nan (nan)	GS 31.172 (31.172)	mem 41.588
Train: [30][165/750]	BT 0.114 (1.315)	DT 0.001 (1.185)	loss nan (nan)	prob nan (nan)	GS 30.469 (30.469)	mem 41.520
Train: [30][170/750]	BT 5.832 (1.314)	DT 5.724 (1.184)	loss nan (nan)	prob nan (nan)	GS 37.688 (37.688)	mem 41.630
Train: [30][175/750]	BT 0.126 (1.280)	DT 0.004 (1.151)	loss nan (nan)	prob nan (nan)	GS 31.172 (31.172)	mem 41.579
Train: [30][180/750]	BT 0.089 (1.284)	DT 0.002 (1.154)	loss nan (nan)	prob nan (nan)	GS 35.938 (35.938)	mem 41.603
Train: [30][185/750]	BT 0.142 (1.290)	DT 0.002 (1.161)	loss nan (nan)	prob nan (nan)	GS 33.109 (33.109)	mem 41.598
Train: [30][190/750]	BT 0.092 (1.290)	DT 0.001 (1.161)	loss nan (nan)	prob nan (nan)	GS 29.781 (29.781)	mem 41.620
Train: [30][195/750]	BT 0.167 (1.281)	DT 0.004 (1.151)	loss nan (nan)	prob nan (nan)	GS 30.797 (30.797)	mem 41.598
Train: [30][200/750]	BT 4.732 (1.276)	DT 4.602 (1.146)	loss nan (nan)	prob nan (nan)	GS 36.266 (36.266)	mem 41.637
Train: [30][205/750]	BT 0.268 (1.251)	DT 0.024 (1.118)	loss nan (nan)	prob nan (nan)	GS 31.188 (31.188)	mem 41.704
Train: [30][210/750]	BT 0.131 (1.262)	DT 0.033 (1.128)	loss nan (nan)	prob nan (nan)	GS 30.359 (30.359)	mem 41.892
Train: [30][215/750]	BT 0.145 (1.258)	DT 0.002 (1.125)	loss nan (nan)	prob nan (nan)	GS 41.438 (41.438)	mem 41.721
Train: [30][220/750]	BT 0.127 (1.272)	DT 0.002 (1.138)	loss nan (nan)	prob nan (nan)	GS 31.781 (31.781)	mem 41.751
Train: [30][225/750]	BT 0.093 (1.274)	DT 0.002 (1.141)	loss nan (nan)	prob nan (nan)	GS 32.281 (32.281)	mem 41.951
Train: [30][230/750]	BT 5.778 (1.274)	DT 5.573 (1.141)	loss nan (nan)	prob nan (nan)	GS 35.609 (35.609)	mem 41.782
Train: [30][235/750]	BT 0.093 (1.249)	DT 0.005 (1.117)	loss nan (nan)	prob nan (nan)	GS 31.000 (31.000)	mem 41.761
Train: [30][240/750]	BT 0.134 (1.263)	DT 0.001 (1.131)	loss nan (nan)	prob nan (nan)	GS 35.562 (35.562)	mem 41.828
Train: [30][245/750]	BT 0.082 (1.240)	DT 0.002 (1.108)	loss nan (nan)	prob nan (nan)	GS 28.375 (28.375)	mem 41.745
Train: [30][250/750]	BT 0.178 (1.256)	DT 0.008 (1.125)	loss nan (nan)	prob nan (nan)	GS 33.672 (33.672)	mem 42.079
Train: [30][255/750]	BT 0.208 (1.235)	DT 0.007 (1.103)	loss nan (nan)	prob nan (nan)	GS 27.938 (27.938)	mem 41.820
Train: [30][260/750]	BT 9.236 (1.249)	DT 8.985 (1.116)	loss nan (nan)	prob nan (nan)	GS 34.797 (34.797)	mem 41.724
Train: [30][265/750]	BT 0.152 (1.228)	DT 0.001 (1.095)	loss nan (nan)	prob nan (nan)	GS 36.219 (36.219)	mem 41.729
Train: [30][270/750]	BT 0.202 (1.235)	DT 0.007 (1.102)	loss nan (nan)	prob nan (nan)	GS 34.750 (34.750)	mem 41.757
Train: [30][275/750]	BT 0.184 (1.228)	DT 0.006 (1.096)	loss nan (nan)	prob nan (nan)	GS 28.812 (28.812)	mem 41.713
Train: [30][280/750]	BT 0.148 (1.236)	DT 0.001 (1.103)	loss nan (nan)	prob nan (nan)	GS 33.750 (33.750)	mem 41.682
Train: [30][285/750]	BT 0.213 (1.234)	DT 0.015 (1.100)	loss nan (nan)	prob nan (nan)	GS 29.516 (29.516)	mem 41.715
Train: [30][290/750]	BT 9.039 (1.246)	DT 8.891 (1.111)	loss nan (nan)	prob nan (nan)	GS 33.141 (33.141)	mem 41.715
Train: [30][295/750]	BT 0.139 (1.227)	DT 0.002 (1.093)	loss nan (nan)	prob nan (nan)	GS 37.594 (37.594)	mem 41.633
Train: [30][300/750]	BT 0.195 (1.218)	DT 0.002 (1.084)	loss nan (nan)	prob nan (nan)	GS 35.328 (35.328)	mem 41.597
Train: [30][305/750]	BT 0.083 (1.225)	DT 0.002 (1.091)	loss nan (nan)	prob nan (nan)	GS 35.344 (35.344)	mem 41.660
Train: [30][310/750]	BT 0.226 (1.221)	DT 0.002 (1.087)	loss nan (nan)	prob nan (nan)	GS 27.547 (27.547)	mem 41.815
Train: [30][315/750]	BT 0.200 (1.227)	DT 0.001 (1.093)	loss nan (nan)	prob nan (nan)	GS 33.297 (33.297)	mem 41.729
Train: [30][320/750]	BT 5.068 (1.226)	DT 4.934 (1.091)	loss nan (nan)	prob nan (nan)	GS 36.172 (36.172)	mem 41.734
Train: [30][325/750]	BT 0.100 (1.209)	DT 0.002 (1.075)	loss nan (nan)	prob nan (nan)	GS 26.844 (26.844)	mem 41.910
Train: [30][330/750]	BT 0.172 (1.208)	DT 0.019 (1.073)	loss nan (nan)	prob nan (nan)	GS 32.797 (32.797)	mem 41.761
Train: [30][335/750]	BT 0.182 (1.205)	DT 0.018 (1.070)	loss nan (nan)	prob nan (nan)	GS 32.203 (32.203)	mem 41.750
Train: [30][340/750]	BT 0.076 (1.208)	DT 0.001 (1.073)	loss nan (nan)	prob nan (nan)	GS 34.859 (34.859)	mem 41.684
Train: [30][345/750]	BT 0.164 (1.216)	DT 0.001 (1.081)	loss nan (nan)	prob nan (nan)	GS 31.938 (31.938)	mem 42.048
Train: [30][350/750]	BT 3.341 (1.210)	DT 3.257 (1.075)	loss nan (nan)	prob nan (nan)	GS 31.844 (31.844)	mem 41.692
Train: [30][355/750]	BT 0.076 (1.195)	DT 0.002 (1.060)	loss nan (nan)	prob nan (nan)	GS 32.250 (32.250)	mem 41.708
Train: [30][360/750]	BT 0.130 (1.206)	DT 0.030 (1.071)	loss nan (nan)	prob nan (nan)	GS 33.438 (33.438)	mem 41.709
Train: [30][365/750]	BT 0.164 (1.200)	DT 0.002 (1.065)	loss nan (nan)	prob nan (nan)	GS 33.031 (33.031)	mem 41.716
Train: [30][370/750]	BT 0.084 (1.211)	DT 0.002 (1.077)	loss nan (nan)	prob nan (nan)	GS 32.531 (32.531)	mem 41.666
Train: [30][375/750]	BT 0.120 (1.197)	DT 0.009 (1.063)	loss nan (nan)	prob nan (nan)	GS 32.641 (32.641)	mem 41.618
Train: [30][380/750]	BT 12.909 (1.216)	DT 12.808 (1.082)	loss nan (nan)	prob nan (nan)	GS 33.266 (33.266)	mem 41.628
Train: [30][385/750]	BT 0.114 (1.202)	DT 0.009 (1.068)	loss nan (nan)	prob nan (nan)	GS 36.031 (36.031)	mem 41.641
Train: [30][390/750]	BT 0.227 (1.189)	DT 0.007 (1.055)	loss nan (nan)	prob nan (nan)	GS 32.531 (32.531)	mem 41.659
Train: [30][395/750]	BT 0.084 (1.204)	DT 0.002 (1.070)	loss nan (nan)	prob nan (nan)	GS 33.016 (33.016)	mem 41.667
Train: [30][400/750]	BT 0.135 (1.190)	DT 0.005 (1.057)	loss nan (nan)	prob nan (nan)	GS 35.656 (35.656)	mem 41.846
Train: [30][405/750]	BT 0.224 (1.213)	DT 0.050 (1.080)	loss nan (nan)	prob nan (nan)	GS 31.734 (31.734)	mem 41.769
Train: [30][410/750]	BT 0.157 (1.200)	DT 0.002 (1.067)	loss nan (nan)	prob nan (nan)	GS 34.062 (34.062)	mem 41.734
Train: [30][415/750]	BT 0.162 (1.187)	DT 0.002 (1.054)	loss nan (nan)	prob nan (nan)	GS 30.984 (30.984)	mem 41.738
Train: [30][420/750]	BT 0.156 (1.199)	DT 0.002 (1.065)	loss nan (nan)	prob nan (nan)	GS 34.047 (34.047)	mem 41.769
Train: [30][425/750]	BT 0.104 (1.187)	DT 0.002 (1.054)	loss nan (nan)	prob nan (nan)	GS 32.734 (32.734)	mem 41.679
Train: [30][430/750]	BT 0.109 (1.211)	DT 0.001 (1.078)	loss nan (nan)	prob nan (nan)	GS 33.719 (33.719)	mem 41.713
Train: [30][435/750]	BT 0.108 (1.199)	DT 0.015 (1.066)	loss nan (nan)	prob nan (nan)	GS 31.781 (31.781)	mem 41.709
Train: [30][440/750]	BT 12.176 (1.215)	DT 12.068 (1.081)	loss nan (nan)	prob nan (nan)	GS 33.734 (33.734)	mem 41.765
Train: [30][445/750]	BT 0.075 (1.202)	DT 0.002 (1.069)	loss nan (nan)	prob nan (nan)	GS 33.672 (33.672)	mem 41.701
Train: [30][450/750]	BT 0.216 (1.190)	DT 0.001 (1.057)	loss nan (nan)	prob nan (nan)	GS 31.703 (31.703)	mem 41.820
Train: [30][455/750]	BT 0.091 (1.204)	DT 0.002 (1.072)	loss nan (nan)	prob nan (nan)	GS 32.531 (32.531)	mem 41.687
Train: [30][460/750]	BT 0.119 (1.192)	DT 0.021 (1.060)	loss nan (nan)	prob nan (nan)	GS 28.188 (28.188)	mem 41.839
Train: [30][465/750]	BT 0.129 (1.205)	DT 0.007 (1.072)	loss nan (nan)	prob nan (nan)	GS 35.359 (35.359)	mem 41.787
Train: [30][470/750]	BT 0.183 (1.194)	DT 0.001 (1.061)	loss nan (nan)	prob nan (nan)	GS 31.312 (31.312)	mem 41.670
Train: [30][475/750]	BT 0.134 (1.182)	DT 0.002 (1.049)	loss nan (nan)	prob nan (nan)	GS 32.906 (32.906)	mem 41.694
Train: [30][480/750]	BT 0.123 (1.193)	DT 0.001 (1.061)	loss nan (nan)	prob nan (nan)	GS 35.188 (35.188)	mem 41.723
Train: [30][485/750]	BT 0.112 (1.182)	DT 0.001 (1.050)	loss nan (nan)	prob nan (nan)	GS 35.094 (35.094)	mem 41.665
Train: [30][490/750]	BT 0.083 (1.196)	DT 0.002 (1.064)	loss nan (nan)	prob nan (nan)	GS 36.594 (36.594)	mem 41.579
Train: [30][495/750]	BT 0.236 (1.185)	DT 0.002 (1.053)	loss nan (nan)	prob nan (nan)	GS 34.312 (34.312)	mem 41.724
Train: [30][500/750]	BT 9.288 (1.193)	DT 9.046 (1.061)	loss nan (nan)	prob nan (nan)	GS 33.562 (33.562)	mem 41.698
Train: [30][505/750]	BT 0.127 (1.183)	DT 0.002 (1.050)	loss nan (nan)	prob nan (nan)	GS 25.438 (25.438)	mem 41.696
Train: [30][510/750]	BT 0.096 (1.173)	DT 0.002 (1.040)	loss nan (nan)	prob nan (nan)	GS 33.844 (33.844)	mem 41.728
Train: [30][515/750]	BT 0.157 (1.186)	DT 0.001 (1.053)	loss nan (nan)	prob nan (nan)	GS 30.812 (30.812)	mem 41.728
Train: [30][520/750]	BT 0.234 (1.177)	DT 0.008 (1.044)	loss nan (nan)	prob nan (nan)	GS 34.578 (34.578)	mem 41.678
Train: [30][525/750]	BT 0.059 (1.187)	DT 0.003 (1.055)	loss nan (nan)	prob nan (nan)	GS 33.688 (33.688)	mem 41.663
Train: [30][530/750]	BT 0.108 (1.177)	DT 0.001 (1.045)	loss nan (nan)	prob nan (nan)	GS 38.156 (38.156)	mem 41.624
Train: [30][535/750]	BT 0.091 (1.168)	DT 0.013 (1.035)	loss nan (nan)	prob nan (nan)	GS 28.266 (28.266)	mem 41.631
Train: [30][540/750]	BT 0.109 (1.180)	DT 0.001 (1.048)	loss nan (nan)	prob nan (nan)	GS 33.125 (33.125)	mem 41.799
Train: [30][545/750]	BT 0.115 (1.171)	DT 0.029 (1.038)	loss nan (nan)	prob nan (nan)	GS 34.844 (34.844)	mem 41.709
Train: [30][550/750]	BT 0.159 (1.184)	DT 0.001 (1.052)	loss nan (nan)	prob nan (nan)	GS 34.422 (34.422)	mem 41.595
Train: [30][555/750]	BT 0.113 (1.175)	DT 0.006 (1.042)	loss nan (nan)	prob nan (nan)	GS 30.453 (30.453)	mem 41.695
Train: [30][560/750]	BT 13.671 (1.190)	DT 13.584 (1.057)	loss nan (nan)	prob nan (nan)	GS 35.281 (35.281)	mem 41.705
Train: [30][565/750]	BT 0.109 (1.180)	DT 0.006 (1.048)	loss nan (nan)	prob nan (nan)	GS 33.703 (33.703)	mem 41.706
Train: [30][570/750]	BT 0.225 (1.171)	DT 0.014 (1.039)	loss nan (nan)	prob nan (nan)	GS 33.453 (33.453)	mem 41.706
Train: [30][575/750]	BT 0.180 (1.177)	DT 0.002 (1.045)	loss nan (nan)	prob nan (nan)	GS 34.984 (34.984)	mem 41.735
Train: [30][580/750]	BT 0.188 (1.168)	DT 0.002 (1.036)	loss nan (nan)	prob nan (nan)	GS 36.391 (36.391)	mem 41.681
Train: [30][585/750]	BT 0.170 (1.180)	DT 0.002 (1.048)	loss nan (nan)	prob nan (nan)	GS 28.750 (28.750)	mem 41.994
Train: [30][590/750]	BT 0.133 (1.171)	DT 0.001 (1.039)	loss nan (nan)	prob nan (nan)	GS 34.453 (34.453)	mem 41.749
Train: [30][595/750]	BT 0.205 (1.162)	DT 0.001 (1.030)	loss nan (nan)	prob nan (nan)	GS 32.672 (32.672)	mem 41.768
Train: [30][600/750]	BT 1.028 (1.171)	DT 0.938 (1.039)	loss nan (nan)	prob nan (nan)	GS 38.172 (38.172)	mem 41.753
Train: [30][605/750]	BT 0.144 (1.163)	DT 0.016 (1.030)	loss nan (nan)	prob nan (nan)	GS 29.625 (29.625)	mem 41.821
Train: [30][610/750]	BT 0.081 (1.174)	DT 0.001 (1.042)	loss nan (nan)	prob nan (nan)	GS 34.359 (34.359)	mem 41.795
Train: [30][615/750]	BT 0.145 (1.168)	DT 0.026 (1.035)	loss nan (nan)	prob nan (nan)	GS 34.344 (34.344)	mem 41.938
Train: [30][620/750]	BT 14.149 (1.182)	DT 14.050 (1.050)	loss nan (nan)	prob nan (nan)	GS 37.500 (37.500)	mem 41.778
Train: [30][625/750]	BT 0.189 (1.173)	DT 0.041 (1.041)	loss nan (nan)	prob nan (nan)	GS 29.469 (29.469)	mem 41.782
Train: [30][630/750]	BT 0.083 (1.165)	DT 0.002 (1.033)	loss nan (nan)	prob nan (nan)	GS 31.844 (31.844)	mem 42.030
Train: [30][635/750]	BT 0.080 (1.174)	DT 0.002 (1.042)	loss nan (nan)	prob nan (nan)	GS 30.375 (30.375)	mem 41.930
Train: [30][640/750]	BT 0.177 (1.166)	DT 0.002 (1.034)	loss nan (nan)	prob nan (nan)	GS 35.984 (35.984)	mem 42.112
Train: [30][645/750]	BT 0.086 (1.177)	DT 0.001 (1.045)	loss nan (nan)	prob nan (nan)	GS 33.516 (33.516)	mem 41.953
Train: [30][650/750]	BT 0.168 (1.169)	DT 0.003 (1.037)	loss nan (nan)	prob nan (nan)	GS 29.359 (29.359)	mem 41.994
Train: [30][655/750]	BT 0.204 (1.161)	DT 0.002 (1.029)	loss nan (nan)	prob nan (nan)	GS 30.906 (30.906)	mem 41.959
Train: [30][660/750]	BT 0.130 (1.169)	DT 0.002 (1.037)	loss nan (nan)	prob nan (nan)	GS 31.844 (31.844)	mem 42.056
Train: [30][665/750]	BT 0.089 (1.161)	DT 0.002 (1.029)	loss nan (nan)	prob nan (nan)	GS 29.125 (29.125)	mem 42.142
Train: [30][670/750]	BT 0.221 (1.171)	DT 0.006 (1.039)	loss nan (nan)	prob nan (nan)	GS 35.031 (35.031)	mem 43.013
Train: [30][675/750]	BT 0.129 (1.164)	DT 0.013 (1.032)	loss nan (nan)	prob nan (nan)	GS 27.578 (27.578)	mem 41.892
Train: [30][680/750]	BT 12.871 (1.176)	DT 12.771 (1.043)	loss nan (nan)	prob nan (nan)	GS 31.109 (31.109)	mem 41.824
Train: [30][685/750]	BT 0.136 (1.169)	DT 0.007 (1.036)	loss nan (nan)	prob nan (nan)	GS 35.703 (35.703)	mem 41.814
Train: [30][690/750]	BT 0.117 (1.161)	DT 0.009 (1.029)	loss nan (nan)	prob nan (nan)	GS 35.703 (35.703)	mem 41.829
Train: [30][695/750]	BT 0.111 (1.172)	DT 0.001 (1.040)	loss nan (nan)	prob nan (nan)	GS 33.656 (33.656)	mem 41.667
Train: [30][700/750]	BT 0.101 (1.165)	DT 0.007 (1.033)	loss nan (nan)	prob nan (nan)	GS 29.781 (29.781)	mem 41.716
Train: [30][705/750]	BT 0.070 (1.172)	DT 0.001 (1.040)	loss nan (nan)	prob nan (nan)	GS 33.438 (33.438)	mem 42.251
arpack error, retry= 0
Train: [30][710/750]	BT 0.204 (1.167)	DT 0.015 (1.035)	loss nan (nan)	prob nan (nan)	GS 31.969 (31.969)	mem 42.115
Train: [30][715/750]	BT 0.144 (1.160)	DT 0.001 (1.028)	loss nan (nan)	prob nan (nan)	GS 31.969 (31.969)	mem 42.206
Train: [30][720/750]	BT 2.235 (1.170)	DT 2.086 (1.038)	loss nan (nan)	prob nan (nan)	GS 32.000 (32.000)	mem 43.801
Train: [30][725/750]	BT 0.142 (1.162)	DT 0.007 (1.030)	loss nan (nan)	prob nan (nan)	GS 28.062 (28.062)	mem 43.553
Train: [30][730/750]	BT 0.076 (1.164)	DT 0.001 (1.032)	loss nan (nan)	prob nan (nan)	GS 31.500 (31.500)	mem 43.017
Train: [30][735/750]	BT 0.088 (1.161)	DT 0.001 (1.029)	loss nan (nan)	prob nan (nan)	GS 33.859 (33.859)	mem 42.919
Train: [30][740/750]	BT 3.022 (1.157)	DT 2.915 (1.026)	loss nan (nan)	prob nan (nan)	GS 34.984 (34.984)	mem 17.232
Train: [30][745/750]	BT 0.080 (1.153)	DT 0.001 (1.022)	loss nan (nan)	prob nan (nan)	GS 34.188 (34.188)	mem 14.307
Train: [30][750/750]	BT 0.125 (1.146)	DT 0.007 (1.016)	loss nan (nan)	prob nan (nan)	GS 33.500 (33.500)	mem 14.270
Train: [30][755/750]	BT 0.065 (1.140)	DT 0.001 (1.009)	loss nan (nan)	prob nan (nan)	GS 31.312 (31.312)	mem 14.227
epoch 30, total time 862.53
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [31][1/750]	BT 20.646 (20.646)	DT 20.511 (20.511)	loss nan (nan)	prob nan (nan)	GS 35.000 (35.000)	mem 42.010
Train: [31][5/750]	BT 0.079 (5.014)	DT 0.001 (4.894)	loss nan (nan)	prob nan (nan)	GS 28.234 (28.234)	mem 42.074
Train: [31][10/750]	BT 0.111 (2.597)	DT 0.002 (2.451)	loss nan (nan)	prob nan (nan)	GS 30.312 (30.312)	mem 42.189
Train: [31][15/750]	BT 0.110 (2.561)	DT 0.002 (2.417)	loss nan (nan)	prob nan (nan)	GS 32.953 (32.953)	mem 42.280
Train: [31][20/750]	BT 0.083 (1.961)	DT 0.001 (1.826)	loss nan (nan)	prob nan (nan)	GS 30.828 (30.828)	mem 42.391
Train: [31][25/750]	BT 0.133 (1.599)	DT 0.014 (1.462)	loss nan (nan)	prob nan (nan)	GS 30.031 (30.031)	mem 42.357
Train: [31][30/750]	BT 0.117 (1.886)	DT 0.002 (1.754)	loss nan (nan)	prob nan (nan)	GS 33.359 (33.359)	mem 42.254
Train: [31][35/750]	BT 0.148 (1.636)	DT 0.015 (1.504)	loss nan (nan)	prob nan (nan)	GS 30.609 (30.609)	mem 42.224
Train: [31][40/750]	BT 0.120 (1.742)	DT 0.001 (1.608)	loss nan (nan)	prob nan (nan)	GS 34.281 (34.281)	mem 42.263
Train: [31][45/750]	BT 0.171 (1.562)	DT 0.002 (1.429)	loss nan (nan)	prob nan (nan)	GS 32.797 (32.797)	mem 42.269
Train: [31][50/750]	BT 11.857 (1.657)	DT 11.755 (1.522)	loss nan (nan)	prob nan (nan)	GS 32.938 (32.938)	mem 42.430
Train: [31][55/750]	BT 0.099 (1.517)	DT 0.009 (1.384)	loss nan (nan)	prob nan (nan)	GS 29.922 (29.922)	mem 42.339
Train: [31][60/750]	BT 0.088 (1.398)	DT 0.001 (1.269)	loss nan (nan)	prob nan (nan)	GS 34.344 (34.344)	mem 42.394
Train: [31][65/750]	BT 0.121 (1.469)	DT 0.002 (1.338)	loss nan (nan)	prob nan (nan)	GS 30.484 (30.484)	mem 42.413
Train: [31][70/750]	BT 0.136 (1.373)	DT 0.010 (1.243)	loss nan (nan)	prob nan (nan)	GS 35.625 (35.625)	mem 42.411
Train: [31][75/750]	BT 0.115 (1.493)	DT 0.001 (1.363)	loss nan (nan)	prob nan (nan)	GS 28.234 (28.234)	mem 42.379
Train: [31][80/750]	BT 0.068 (1.405)	DT 0.001 (1.278)	loss nan (nan)	prob nan (nan)	GS 35.062 (35.062)	mem 42.472
Train: [31][85/750]	BT 0.153 (1.329)	DT 0.002 (1.203)	loss nan (nan)	prob nan (nan)	GS 41.859 (41.859)	mem 42.440
Train: [31][90/750]	BT 0.072 (1.416)	DT 0.001 (1.292)	loss nan (nan)	prob nan (nan)	GS 35.734 (35.734)	mem 42.487
Train: [31][95/750]	BT 0.179 (1.347)	DT 0.002 (1.224)	loss nan (nan)	prob nan (nan)	GS 31.594 (31.594)	mem 42.493
Train: [31][100/750]	BT 0.151 (1.408)	DT 0.002 (1.284)	loss nan (nan)	prob nan (nan)	GS 35.828 (35.828)	mem 42.419
Train: [31][105/750]	BT 0.118 (1.348)	DT 0.013 (1.223)	loss nan (nan)	prob nan (nan)	GS 31.266 (31.266)	mem 42.422
Train: [31][110/750]	BT 11.682 (1.398)	DT 11.578 (1.273)	loss nan (nan)	prob nan (nan)	GS 38.469 (38.469)	mem 42.425
Train: [31][115/750]	BT 0.101 (1.344)	DT 0.002 (1.218)	loss nan (nan)	prob nan (nan)	GS 31.828 (31.828)	mem 42.532
Train: [31][120/750]	BT 0.124 (1.295)	DT 0.001 (1.167)	loss nan (nan)	prob nan (nan)	GS 36.125 (36.125)	mem 42.443
Train: [31][125/750]	BT 0.128 (1.339)	DT 0.002 (1.212)	loss nan (nan)	prob nan (nan)	GS 30.922 (30.922)	mem 42.397
Train: [31][130/750]	BT 0.154 (1.292)	DT 0.002 (1.165)	loss nan (nan)	prob nan (nan)	GS 33.094 (33.094)	mem 42.487
Train: [31][135/750]	BT 0.123 (1.334)	DT 0.005 (1.207)	loss nan (nan)	prob nan (nan)	GS 28.531 (28.531)	mem 40.987
Train: [31][140/750]	BT 0.097 (1.291)	DT 0.001 (1.164)	loss nan (nan)	prob nan (nan)	GS 32.328 (32.328)	mem 40.870
Train: [31][145/750]	BT 0.217 (1.253)	DT 0.007 (1.124)	loss nan (nan)	prob nan (nan)	GS 27.094 (27.094)	mem 40.903
Train: [31][150/750]	BT 0.151 (1.289)	DT 0.019 (1.160)	loss nan (nan)	prob nan (nan)	GS 30.953 (30.953)	mem 41.014
Train: [31][155/750]	BT 0.089 (1.253)	DT 0.002 (1.123)	loss nan (nan)	prob nan (nan)	GS 28.812 (28.812)	mem 40.924
Train: [31][160/750]	BT 0.161 (1.285)	DT 0.020 (1.155)	loss nan (nan)	prob nan (nan)	GS 35.953 (35.953)	mem 41.093
Train: [31][165/750]	BT 0.119 (1.250)	DT 0.002 (1.121)	loss nan (nan)	prob nan (nan)	GS 31.500 (31.500)	mem 41.038
Train: [31][170/750]	BT 15.734 (1.309)	DT 15.601 (1.180)	loss nan (nan)	prob nan (nan)	GS 34.891 (34.891)	mem 40.979
Train: [31][175/750]	BT 0.114 (1.275)	DT 0.002 (1.146)	loss nan (nan)	prob nan (nan)	GS 33.422 (33.422)	mem 40.939
Train: [31][180/750]	BT 0.097 (1.243)	DT 0.002 (1.115)	loss nan (nan)	prob nan (nan)	GS 36.562 (36.562)	mem 40.985
Train: [31][185/750]	BT 0.082 (1.288)	DT 0.001 (1.160)	loss nan (nan)	prob nan (nan)	GS 33.891 (33.891)	mem 41.078
Train: [31][190/750]	BT 0.102 (1.258)	DT 0.002 (1.129)	loss nan (nan)	prob nan (nan)	GS 37.078 (37.078)	mem 41.130
Train: [31][195/750]	BT 0.064 (1.291)	DT 0.001 (1.162)	loss nan (nan)	prob nan (nan)	GS 32.312 (32.312)	mem 41.125
Train: [31][200/750]	BT 0.102 (1.261)	DT 0.002 (1.133)	loss nan (nan)	prob nan (nan)	GS 33.047 (33.047)	mem 41.158
Train: [31][205/750]	BT 0.123 (1.234)	DT 0.002 (1.106)	loss nan (nan)	prob nan (nan)	GS 27.781 (27.781)	mem 41.178
Train: [31][210/750]	BT 0.173 (1.253)	DT 0.014 (1.124)	loss nan (nan)	prob nan (nan)	GS 34.359 (34.359)	mem 41.302
Train: [31][215/750]	BT 0.185 (1.227)	DT 0.013 (1.098)	loss nan (nan)	prob nan (nan)	GS 33.359 (33.359)	mem 41.355
Train: [31][220/750]	BT 0.275 (1.266)	DT 0.018 (1.137)	loss nan (nan)	prob nan (nan)	GS 34.250 (34.250)	mem 41.198
Train: [31][225/750]	BT 0.102 (1.240)	DT 0.001 (1.112)	loss nan (nan)	prob nan (nan)	GS 32.625 (32.625)	mem 41.203
Train: [31][230/750]	BT 11.667 (1.266)	DT 11.586 (1.138)	loss nan (nan)	prob nan (nan)	GS 33.656 (33.656)	mem 41.344
Train: [31][235/750]	BT 0.193 (1.242)	DT 0.002 (1.114)	loss nan (nan)	prob nan (nan)	GS 30.266 (30.266)	mem 41.637
Train: [31][240/750]	BT 0.339 (1.220)	DT 0.037 (1.091)	loss nan (nan)	prob nan (nan)	GS 32.656 (32.656)	mem 41.371
Train: [31][245/750]	BT 0.142 (1.247)	DT 0.008 (1.118)	loss nan (nan)	prob nan (nan)	GS 32.469 (32.469)	mem 41.393
Train: [31][250/750]	BT 0.302 (1.226)	DT 0.002 (1.096)	loss nan (nan)	prob nan (nan)	GS 32.828 (32.828)	mem 41.610
Train: [31][255/750]	BT 0.104 (1.253)	DT 0.002 (1.123)	loss nan (nan)	prob nan (nan)	GS 29.453 (29.453)	mem 41.525
Train: [31][260/750]	BT 0.086 (1.231)	DT 0.012 (1.102)	loss nan (nan)	prob nan (nan)	GS 36.406 (36.406)	mem 41.570
Train: [31][265/750]	BT 0.156 (1.211)	DT 0.012 (1.081)	loss nan (nan)	prob nan (nan)	GS 31.422 (31.422)	mem 41.578
Train: [31][270/750]	BT 0.175 (1.237)	DT 0.002 (1.107)	loss nan (nan)	prob nan (nan)	GS 37.719 (37.719)	mem 41.572
Train: [31][275/750]	BT 0.153 (1.217)	DT 0.001 (1.087)	loss nan (nan)	prob nan (nan)	GS 32.891 (32.891)	mem 41.666
Train: [31][280/750]	BT 0.108 (1.240)	DT 0.011 (1.110)	loss nan (nan)	prob nan (nan)	GS 32.453 (32.453)	mem 41.593
Train: [31][285/750]	BT 0.135 (1.220)	DT 0.004 (1.091)	loss nan (nan)	prob nan (nan)	GS 35.266 (35.266)	mem 41.576
Train: [31][290/750]	BT 13.023 (1.246)	DT 12.873 (1.116)	loss nan (nan)	prob nan (nan)	GS 39.203 (39.203)	mem 41.624
Train: [31][295/750]	BT 0.106 (1.226)	DT 0.011 (1.098)	loss nan (nan)	prob nan (nan)	GS 32.703 (32.703)	mem 41.576
Train: [31][300/750]	BT 0.111 (1.208)	DT 0.001 (1.079)	loss nan (nan)	prob nan (nan)	GS 32.312 (32.312)	mem 41.437
Train: [31][305/750]	BT 0.091 (1.225)	DT 0.002 (1.097)	loss nan (nan)	prob nan (nan)	GS 29.141 (29.141)	mem 41.770
Train: [31][310/750]	BT 0.690 (1.209)	DT 0.613 (1.081)	loss nan (nan)	prob nan (nan)	GS 36.719 (36.719)	mem 41.641
Train: [31][315/750]	BT 0.087 (1.230)	DT 0.010 (1.102)	loss nan (nan)	prob nan (nan)	GS 33.156 (33.156)	mem 41.655
Train: [31][320/750]	BT 0.119 (1.213)	DT 0.008 (1.085)	loss nan (nan)	prob nan (nan)	GS 31.828 (31.828)	mem 41.700
Train: [31][325/750]	BT 0.128 (1.196)	DT 0.002 (1.068)	loss nan (nan)	prob nan (nan)	GS 28.875 (28.875)	mem 41.659
Train: [31][330/750]	BT 0.088 (1.215)	DT 0.001 (1.088)	loss nan (nan)	prob nan (nan)	GS 34.766 (34.766)	mem 40.135
Train: [31][335/750]	BT 0.136 (1.200)	DT 0.005 (1.072)	loss nan (nan)	prob nan (nan)	GS 29.422 (29.422)	mem 40.148
Train: [31][340/750]	BT 0.147 (1.221)	DT 0.006 (1.093)	loss nan (nan)	prob nan (nan)	GS 33.906 (33.906)	mem 40.103
Train: [31][345/750]	BT 0.080 (1.205)	DT 0.002 (1.077)	loss nan (nan)	prob nan (nan)	GS 30.578 (30.578)	mem 40.145
Train: [31][350/750]	BT 13.513 (1.227)	DT 13.417 (1.100)	loss nan (nan)	prob nan (nan)	GS 30.531 (30.531)	mem 40.144
Train: [31][355/750]	BT 0.087 (1.212)	DT 0.001 (1.084)	loss nan (nan)	prob nan (nan)	GS 27.297 (27.297)	mem 40.185
Train: [31][360/750]	BT 0.157 (1.196)	DT 0.006 (1.069)	loss nan (nan)	prob nan (nan)	GS 31.797 (31.797)	mem 40.150
Train: [31][365/750]	BT 0.084 (1.209)	DT 0.002 (1.082)	loss nan (nan)	prob nan (nan)	GS 28.906 (28.906)	mem 40.230
Train: [31][370/750]	BT 0.177 (1.194)	DT 0.081 (1.068)	loss nan (nan)	prob nan (nan)	GS 34.016 (34.016)	mem 40.178
Train: [31][375/750]	BT 0.092 (1.213)	DT 0.002 (1.087)	loss nan (nan)	prob nan (nan)	GS 32.891 (32.891)	mem 40.347
Train: [31][380/750]	BT 0.124 (1.201)	DT 0.001 (1.076)	loss nan (nan)	prob nan (nan)	GS 32.859 (32.859)	mem 40.269
Train: [31][385/750]	BT 0.177 (1.188)	DT 0.004 (1.062)	loss nan (nan)	prob nan (nan)	GS 33.125 (33.125)	mem 40.274
Train: [31][390/750]	BT 0.075 (1.205)	DT 0.001 (1.079)	loss nan (nan)	prob nan (nan)	GS 31.406 (31.406)	mem 40.069
Train: [31][395/750]	BT 0.122 (1.191)	DT 0.025 (1.066)	loss nan (nan)	prob nan (nan)	GS 28.000 (28.000)	mem 40.093
Train: [31][400/750]	BT 3.355 (1.211)	DT 3.223 (1.086)	loss nan (nan)	prob nan (nan)	GS 35.484 (35.484)	mem 40.093
Train: [31][405/750]	BT 0.089 (1.197)	DT 0.003 (1.072)	loss nan (nan)	prob nan (nan)	GS 30.562 (30.562)	mem 40.096
Train: [31][410/750]	BT 6.940 (1.201)	DT 6.777 (1.076)	loss nan (nan)	prob nan (nan)	GS 29.391 (29.391)	mem 40.206
Train: [31][415/750]	BT 0.089 (1.196)	DT 0.002 (1.070)	loss nan (nan)	prob nan (nan)	GS 29.891 (29.891)	mem 40.324
Train: [31][420/750]	BT 0.145 (1.183)	DT 0.009 (1.058)	loss nan (nan)	prob nan (nan)	GS 31.766 (31.766)	mem 40.407
Train: [31][425/750]	BT 0.099 (1.207)	DT 0.001 (1.081)	loss nan (nan)	prob nan (nan)	GS 30.375 (30.375)	mem 40.212
Train: [31][430/750]	BT 0.068 (1.194)	DT 0.001 (1.069)	loss nan (nan)	prob nan (nan)	GS 35.562 (35.562)	mem 40.181
Train: [31][435/750]	BT 0.083 (1.209)	DT 0.001 (1.084)	loss nan (nan)	prob nan (nan)	GS 30.172 (30.172)	mem 40.162
Train: [31][440/750]	BT 0.075 (1.196)	DT 0.001 (1.072)	loss nan (nan)	prob nan (nan)	GS 33.438 (33.438)	mem 40.171
Train: [31][445/750]	BT 0.183 (1.185)	DT 0.025 (1.060)	loss nan (nan)	prob nan (nan)	GS 35.031 (35.031)	mem 40.190
Train: [31][450/750]	BT 0.096 (1.195)	DT 0.002 (1.071)	loss nan (nan)	prob nan (nan)	GS 30.547 (30.547)	mem 40.383
Train: [31][455/750]	BT 0.166 (1.184)	DT 0.003 (1.060)	loss nan (nan)	prob nan (nan)	GS 30.859 (30.859)	mem 40.334
Train: [31][460/750]	BT 0.148 (1.198)	DT 0.002 (1.073)	loss nan (nan)	prob nan (nan)	GS 34.688 (34.688)	mem 40.244
Train: [31][465/750]	BT 0.089 (1.186)	DT 0.002 (1.062)	loss nan (nan)	prob nan (nan)	GS 29.641 (29.641)	mem 40.367
Train: [31][470/750]	BT 11.584 (1.199)	DT 11.494 (1.075)	loss nan (nan)	prob nan (nan)	GS 30.141 (30.141)	mem 40.328
Train: [31][475/750]	BT 0.152 (1.188)	DT 0.003 (1.064)	loss nan (nan)	prob nan (nan)	GS 32.703 (32.703)	mem 40.286
Train: [31][480/750]	BT 0.189 (1.177)	DT 0.002 (1.053)	loss nan (nan)	prob nan (nan)	GS 29.000 (29.000)	mem 40.288
Train: [31][485/750]	BT 0.117 (1.187)	DT 0.002 (1.063)	loss nan (nan)	prob nan (nan)	GS 32.578 (32.578)	mem 40.254
Train: [31][490/750]	BT 0.181 (1.176)	DT 0.001 (1.052)	loss nan (nan)	prob nan (nan)	GS 35.859 (35.859)	mem 40.396
Train: [31][495/750]	BT 0.106 (1.189)	DT 0.001 (1.064)	loss nan (nan)	prob nan (nan)	GS 28.328 (28.328)	mem 40.466
Train: [31][500/750]	BT 0.093 (1.178)	DT 0.002 (1.054)	loss nan (nan)	prob nan (nan)	GS 34.562 (34.562)	mem 40.280
Train: [31][505/750]	BT 0.090 (1.168)	DT 0.001 (1.044)	loss nan (nan)	prob nan (nan)	GS 32.266 (32.266)	mem 40.279
Train: [31][510/750]	BT 0.088 (1.181)	DT 0.001 (1.057)	loss nan (nan)	prob nan (nan)	GS 33.031 (33.031)	mem 40.324
Train: [31][515/750]	BT 0.110 (1.171)	DT 0.002 (1.047)	loss nan (nan)	prob nan (nan)	GS 24.922 (24.922)	mem 40.290
Train: [31][520/750]	BT 0.170 (1.187)	DT 0.004 (1.063)	loss nan (nan)	prob nan (nan)	GS 31.953 (31.953)	mem 40.400
Train: [31][525/750]	BT 0.186 (1.177)	DT 0.011 (1.053)	loss nan (nan)	prob nan (nan)	GS 29.625 (29.625)	mem 40.325
Train: [31][530/750]	BT 13.610 (1.192)	DT 13.406 (1.068)	loss nan (nan)	prob nan (nan)	GS 33.359 (33.359)	mem 40.178
Train: [31][535/750]	BT 0.108 (1.182)	DT 0.002 (1.058)	loss nan (nan)	prob nan (nan)	GS 26.078 (26.078)	mem 40.142
Train: [31][540/750]	BT 0.236 (1.173)	DT 0.056 (1.048)	loss nan (nan)	prob nan (nan)	GS 32.250 (32.250)	mem 40.154
Train: [31][545/750]	BT 0.097 (1.185)	DT 0.002 (1.060)	loss nan (nan)	prob nan (nan)	GS 28.109 (28.109)	mem 40.229
Train: [31][550/750]	BT 0.115 (1.176)	DT 0.011 (1.051)	loss nan (nan)	prob nan (nan)	GS 32.906 (32.906)	mem 40.232
Train: [31][555/750]	BT 0.070 (1.191)	DT 0.001 (1.066)	loss nan (nan)	prob nan (nan)	GS 33.625 (33.625)	mem 40.050
Train: [31][560/750]	BT 0.120 (1.181)	DT 0.001 (1.057)	loss nan (nan)	prob nan (nan)	GS 31.875 (31.875)	mem 40.087
Train: [31][565/750]	BT 0.157 (1.172)	DT 0.011 (1.047)	loss nan (nan)	prob nan (nan)	GS 31.219 (31.219)	mem 40.185
Train: [31][570/750]	BT 0.146 (1.187)	DT 0.009 (1.062)	loss nan (nan)	prob nan (nan)	GS 34.016 (34.016)	mem 40.242
Train: [31][575/750]	BT 0.150 (1.178)	DT 0.002 (1.053)	loss nan (nan)	prob nan (nan)	GS 34.844 (34.844)	mem 40.276
Train: [31][580/750]	BT 0.151 (1.189)	DT 0.001 (1.064)	loss nan (nan)	prob nan (nan)	GS 36.609 (36.609)	mem 40.246
Train: [31][585/750]	BT 0.094 (1.180)	DT 0.007 (1.055)	loss nan (nan)	prob nan (nan)	GS 30.141 (30.141)	mem 40.177
Train: [31][590/750]	BT 10.461 (1.188)	DT 10.218 (1.063)	loss nan (nan)	prob nan (nan)	GS 32.578 (32.578)	mem 40.073
Train: [31][595/750]	BT 0.152 (1.179)	DT 0.026 (1.054)	loss nan (nan)	prob nan (nan)	GS 31.688 (31.688)	mem 40.090
Train: [31][600/750]	BT 0.173 (1.171)	DT 0.010 (1.046)	loss nan (nan)	prob nan (nan)	GS 32.609 (32.609)	mem 40.047
Train: [31][605/750]	BT 0.134 (1.183)	DT 0.001 (1.058)	loss nan (nan)	prob nan (nan)	GS 32.594 (32.594)	mem 40.341
Train: [31][610/750]	BT 0.098 (1.174)	DT 0.002 (1.049)	loss nan (nan)	prob nan (nan)	GS 29.625 (29.625)	mem 40.122
Train: [31][615/750]	BT 0.082 (1.184)	DT 0.002 (1.059)	loss nan (nan)	prob nan (nan)	GS 30.125 (30.125)	mem 39.999
Train: [31][620/750]	BT 0.143 (1.176)	DT 0.015 (1.051)	loss nan (nan)	prob nan (nan)	GS 34.500 (34.500)	mem 40.104
Train: [31][625/750]	BT 0.123 (1.167)	DT 0.001 (1.043)	loss nan (nan)	prob nan (nan)	GS 29.734 (29.734)	mem 39.952
Train: [31][630/750]	BT 0.099 (1.178)	DT 0.002 (1.054)	loss nan (nan)	prob nan (nan)	GS 37.016 (37.016)	mem 39.979
Train: [31][635/750]	BT 0.082 (1.170)	DT 0.001 (1.045)	loss nan (nan)	prob nan (nan)	GS 28.406 (28.406)	mem 39.874
Train: [31][640/750]	BT 0.120 (1.180)	DT 0.002 (1.056)	loss nan (nan)	prob nan (nan)	GS 36.328 (36.328)	mem 40.352
Train: [31][645/750]	BT 0.221 (1.172)	DT 0.017 (1.047)	loss nan (nan)	prob nan (nan)	GS 33.469 (33.469)	mem 40.224
Train: [31][650/750]	BT 10.713 (1.180)	DT 10.629 (1.056)	loss nan (nan)	prob nan (nan)	GS 35.250 (35.250)	mem 39.884
Train: [31][655/750]	BT 0.115 (1.172)	DT 0.002 (1.048)	loss nan (nan)	prob nan (nan)	GS 37.984 (37.984)	mem 39.885
Train: [31][660/750]	BT 0.129 (1.165)	DT 0.012 (1.040)	loss nan (nan)	prob nan (nan)	GS 35.172 (35.172)	mem 39.911
Train: [31][665/750]	BT 0.172 (1.174)	DT 0.002 (1.049)	loss nan (nan)	prob nan (nan)	GS 29.938 (29.938)	mem 40.058
Train: [31][670/750]	BT 0.274 (1.167)	DT 0.018 (1.041)	loss nan (nan)	prob nan (nan)	GS 34.062 (34.062)	mem 39.914
Train: [31][675/750]	BT 0.083 (1.180)	DT 0.002 (1.054)	loss nan (nan)	prob nan (nan)	GS 30.750 (30.750)	mem 40.014
Train: [31][680/750]	BT 0.214 (1.173)	DT 0.002 (1.047)	loss nan (nan)	prob nan (nan)	GS 34.109 (34.109)	mem 40.016
Train: [31][685/750]	BT 0.156 (1.165)	DT 0.001 (1.039)	loss nan (nan)	prob nan (nan)	GS 48.250 (48.250)	mem 40.195
Train: [31][690/750]	BT 0.093 (1.176)	DT 0.001 (1.050)	loss nan (nan)	prob nan (nan)	GS 33.078 (33.078)	mem 39.867
Train: [31][695/750]	BT 0.093 (1.168)	DT 0.003 (1.043)	loss nan (nan)	prob nan (nan)	GS 29.281 (29.281)	mem 39.882
Train: [31][700/750]	BT 0.076 (1.180)	DT 0.001 (1.055)	loss nan (nan)	prob nan (nan)	GS 30.797 (30.797)	mem 39.852
Train: [31][705/750]	BT 0.144 (1.173)	DT 0.002 (1.048)	loss nan (nan)	prob nan (nan)	GS 34.922 (34.922)	mem 39.862
arpack error, retry= 0
arpack error, retry= 0
Train: [31][710/750]	BT 10.457 (1.180)	DT 10.377 (1.055)	loss nan (nan)	prob nan (nan)	GS 33.828 (33.828)	mem 39.967
Train: [31][715/750]	BT 0.170 (1.172)	DT 0.006 (1.048)	loss nan (nan)	prob nan (nan)	GS 29.188 (29.188)	mem 39.986
Train: [31][720/750]	BT 0.112 (1.165)	DT 0.006 (1.040)	loss nan (nan)	prob nan (nan)	GS 31.562 (31.562)	mem 39.996
Train: [31][725/750]	BT 0.108 (1.176)	DT 0.004 (1.052)	loss nan (nan)	prob nan (nan)	GS 33.625 (33.625)	mem 39.907
Train: [31][730/750]	BT 0.168 (1.169)	DT 0.010 (1.044)	loss nan (nan)	prob nan (nan)	GS 31.703 (31.703)	mem 39.910
Train: [31][735/750]	BT 0.065 (1.172)	DT 0.001 (1.048)	loss nan (nan)	prob nan (nan)	GS 42.656 (42.656)	mem 36.520
Train: [31][740/750]	BT 0.071 (1.165)	DT 0.001 (1.041)	loss nan (nan)	prob nan (nan)	GS 35.844 (35.844)	mem 36.523
Train: [31][745/750]	BT 0.061 (1.157)	DT 0.001 (1.034)	loss nan (nan)	prob nan (nan)	GS 33.188 (33.188)	mem 36.528
Train: [31][750/750]	BT 0.070 (1.152)	DT 0.001 (1.029)	loss nan (nan)	prob nan (nan)	GS 29.156 (29.156)	mem 7.662
Train: [31][755/750]	BT 0.071 (1.145)	DT 0.001 (1.022)	loss nan (nan)	prob nan (nan)	GS 26.281 (26.281)	mem 7.662
epoch 31, total time 864.89
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [32][1/750]	BT 21.393 (21.393)	DT 21.192 (21.192)	loss nan (nan)	prob nan (nan)	GS 32.375 (32.375)	mem 38.832
Train: [32][5/750]	BT 0.087 (5.152)	DT 0.002 (5.032)	loss nan (nan)	prob nan (nan)	GS 31.766 (31.766)	mem 38.681
Train: [32][10/750]	BT 0.179 (2.644)	DT 0.001 (2.518)	loss nan (nan)	prob nan (nan)	GS 33.844 (33.844)	mem 38.685
Train: [32][15/750]	BT 0.141 (2.484)	DT 0.002 (2.362)	loss nan (nan)	prob nan (nan)	GS 34.859 (34.859)	mem 38.870
Train: [32][20/750]	BT 0.144 (2.072)	DT 0.019 (1.945)	loss nan (nan)	prob nan (nan)	GS 34.969 (34.969)	mem 38.908
Train: [32][25/750]	BT 1.454 (1.732)	DT 1.324 (1.609)	loss nan (nan)	prob nan (nan)	GS 36.516 (36.516)	mem 38.916
Train: [32][30/750]	BT 0.837 (1.822)	DT 0.594 (1.690)	loss nan (nan)	prob nan (nan)	GS 29.766 (29.766)	mem 38.988
Train: [32][35/750]	BT 0.092 (1.598)	DT 0.001 (1.462)	loss nan (nan)	prob nan (nan)	GS 29.016 (29.016)	mem 38.989
Train: [32][40/750]	BT 0.169 (1.653)	DT 0.002 (1.513)	loss nan (nan)	prob nan (nan)	GS 33.188 (33.188)	mem 39.021
Train: [32][45/750]	BT 0.148 (1.617)	DT 0.003 (1.473)	loss nan (nan)	prob nan (nan)	GS 27.891 (27.891)	mem 39.000
Train: [32][50/750]	BT 7.856 (1.621)	DT 7.692 (1.480)	loss nan (nan)	prob nan (nan)	GS 34.141 (34.141)	mem 39.013
Train: [32][55/750]	BT 0.145 (1.523)	DT 0.001 (1.379)	loss nan (nan)	prob nan (nan)	GS 33.094 (33.094)	mem 39.140
Train: [32][60/750]	BT 0.235 (1.410)	DT 0.009 (1.265)	loss nan (nan)	prob nan (nan)	GS 32.422 (32.422)	mem 39.064
Train: [32][65/750]	BT 0.161 (1.453)	DT 0.018 (1.307)	loss nan (nan)	prob nan (nan)	GS 29.391 (29.391)	mem 39.274
Train: [32][70/750]	BT 0.187 (1.373)	DT 0.002 (1.226)	loss nan (nan)	prob nan (nan)	GS 33.703 (33.703)	mem 39.213
Train: [32][75/750]	BT 0.238 (1.461)	DT 0.012 (1.313)	loss nan (nan)	prob nan (nan)	GS 31.844 (31.844)	mem 39.173
Train: [32][80/750]	BT 0.172 (1.391)	DT 0.003 (1.244)	loss nan (nan)	prob nan (nan)	GS 34.281 (34.281)	mem 39.306
Train: [32][85/750]	BT 0.091 (1.316)	DT 0.002 (1.171)	loss nan (nan)	prob nan (nan)	GS 32.281 (32.281)	mem 39.141
Train: [32][90/750]	BT 2.208 (1.401)	DT 2.095 (1.254)	loss nan (nan)	prob nan (nan)	GS 36.469 (36.469)	mem 39.331
Train: [32][95/750]	BT 0.116 (1.335)	DT 0.008 (1.189)	loss nan (nan)	prob nan (nan)	GS 33.516 (33.516)	mem 39.264
Train: [32][100/750]	BT 0.211 (1.363)	DT 0.001 (1.216)	loss nan (nan)	prob nan (nan)	GS 29.344 (29.344)	mem 39.458
Train: [32][105/750]	BT 0.073 (1.337)	DT 0.002 (1.192)	loss nan (nan)	prob nan (nan)	GS 29.500 (29.500)	mem 39.512
Train: [32][110/750]	BT 5.271 (1.329)	DT 5.164 (1.185)	loss nan (nan)	prob nan (nan)	GS 30.172 (30.172)	mem 39.500
Train: [32][115/750]	BT 0.160 (1.319)	DT 0.002 (1.174)	loss nan (nan)	prob nan (nan)	GS 33.844 (33.844)	mem 39.500
Train: [32][120/750]	BT 0.172 (1.270)	DT 0.002 (1.125)	loss nan (nan)	prob nan (nan)	GS 37.719 (37.719)	mem 39.540
Train: [32][125/750]	BT 0.080 (1.332)	DT 0.001 (1.188)	loss nan (nan)	prob nan (nan)	GS 32.688 (32.688)	mem 39.600
Train: [32][130/750]	BT 0.198 (1.286)	DT 0.010 (1.142)	loss nan (nan)	prob nan (nan)	GS 33.469 (33.469)	mem 39.658
Train: [32][135/750]	BT 0.083 (1.326)	DT 0.002 (1.182)	loss nan (nan)	prob nan (nan)	GS 30.828 (30.828)	mem 39.903
Train: [32][140/750]	BT 0.136 (1.283)	DT 0.010 (1.140)	loss nan (nan)	prob nan (nan)	GS 34.750 (34.750)	mem 39.875
Train: [32][145/750]	BT 0.108 (1.244)	DT 0.001 (1.101)	loss nan (nan)	prob nan (nan)	GS 30.547 (30.547)	mem 39.797
Train: [32][150/750]	BT 0.119 (1.299)	DT 0.005 (1.156)	loss nan (nan)	prob nan (nan)	GS 33.391 (33.391)	mem 39.891
Train: [32][155/750]	BT 0.205 (1.261)	DT 0.002 (1.119)	loss nan (nan)	prob nan (nan)	GS 32.375 (32.375)	mem 39.910
Train: [32][160/750]	BT 0.103 (1.313)	DT 0.001 (1.172)	loss nan (nan)	prob nan (nan)	GS 35.578 (35.578)	mem 39.852
Train: [32][165/750]	BT 0.090 (1.277)	DT 0.002 (1.137)	loss nan (nan)	prob nan (nan)	GS 32.875 (32.875)	mem 39.794
Train: [32][170/750]	BT 12.574 (1.317)	DT 12.476 (1.177)	loss nan (nan)	prob nan (nan)	GS 31.406 (31.406)	mem 39.927
Train: [32][175/750]	BT 0.213 (1.283)	DT 0.009 (1.143)	loss nan (nan)	prob nan (nan)	GS 34.438 (34.438)	mem 40.023
Train: [32][180/750]	BT 0.184 (1.252)	DT 0.002 (1.112)	loss nan (nan)	prob nan (nan)	GS 32.703 (32.703)	mem 39.948
Train: [32][185/750]	BT 0.110 (1.290)	DT 0.002 (1.150)	loss nan (nan)	prob nan (nan)	GS 49.953 (49.953)	mem 39.897
Train: [32][190/750]	BT 0.093 (1.258)	DT 0.001 (1.120)	loss nan (nan)	prob nan (nan)	GS 39.656 (39.656)	mem 39.932
Train: [32][195/750]	BT 0.084 (1.295)	DT 0.002 (1.157)	loss nan (nan)	prob nan (nan)	GS 30.828 (30.828)	mem 39.877
Train: [32][200/750]	BT 0.081 (1.265)	DT 0.002 (1.128)	loss nan (nan)	prob nan (nan)	GS 30.172 (30.172)	mem 39.876
Train: [32][205/750]	BT 0.159 (1.236)	DT 0.002 (1.100)	loss nan (nan)	prob nan (nan)	GS 29.047 (29.047)	mem 39.940
Train: [32][210/750]	BT 0.090 (1.252)	DT 0.002 (1.116)	loss nan (nan)	prob nan (nan)	GS 35.750 (35.750)	mem 39.984
Train: [32][215/750]	BT 0.102 (1.233)	DT 0.016 (1.097)	loss nan (nan)	prob nan (nan)	GS 31.766 (31.766)	mem 39.963
Train: [32][220/750]	BT 0.097 (1.256)	DT 0.003 (1.121)	loss nan (nan)	prob nan (nan)	GS 35.047 (35.047)	mem 40.125
Train: [32][225/750]	BT 0.124 (1.232)	DT 0.010 (1.097)	loss nan (nan)	prob nan (nan)	GS 30.438 (30.438)	mem 40.006
Train: [32][230/750]	BT 11.018 (1.256)	DT 10.920 (1.121)	loss nan (nan)	prob nan (nan)	GS 34.328 (34.328)	mem 40.092
Train: [32][235/750]	BT 0.119 (1.232)	DT 0.013 (1.097)	loss nan (nan)	prob nan (nan)	GS 32.156 (32.156)	mem 40.020
Train: [32][240/750]	BT 0.136 (1.208)	DT 0.001 (1.074)	loss nan (nan)	prob nan (nan)	GS 31.422 (31.422)	mem 40.019
Train: [32][245/750]	BT 0.082 (1.227)	DT 0.002 (1.093)	loss nan (nan)	prob nan (nan)	GS 33.188 (33.188)	mem 40.001
Train: [32][250/750]	BT 0.074 (1.205)	DT 0.002 (1.071)	loss nan (nan)	prob nan (nan)	GS 30.953 (30.953)	mem 40.028
Train: [32][255/750]	BT 0.127 (1.228)	DT 0.001 (1.094)	loss nan (nan)	prob nan (nan)	GS 34.344 (34.344)	mem 39.991
Train: [32][260/750]	BT 1.026 (1.210)	DT 0.933 (1.076)	loss nan (nan)	prob nan (nan)	GS 34.703 (34.703)	mem 39.997
Train: [32][265/750]	BT 0.143 (1.190)	DT 0.023 (1.056)	loss nan (nan)	prob nan (nan)	GS 28.750 (28.750)	mem 40.058
Train: [32][270/750]	BT 0.082 (1.220)	DT 0.001 (1.088)	loss nan (nan)	prob nan (nan)	GS 35.516 (35.516)	mem 39.973
Train: [32][275/750]	BT 0.119 (1.200)	DT 0.002 (1.068)	loss nan (nan)	prob nan (nan)	GS 34.125 (34.125)	mem 40.090
Train: [32][280/750]	BT 0.172 (1.218)	DT 0.024 (1.085)	loss nan (nan)	prob nan (nan)	GS 36.500 (36.500)	mem 40.016
Train: [32][285/750]	BT 0.184 (1.200)	DT 0.001 (1.066)	loss nan (nan)	prob nan (nan)	GS 30.891 (30.891)	mem 40.037
Train: [32][290/750]	BT 12.362 (1.224)	DT 12.288 (1.090)	loss nan (nan)	prob nan (nan)	GS 35.844 (35.844)	mem 40.199
Train: [32][295/750]	BT 0.153 (1.205)	DT 0.003 (1.072)	loss nan (nan)	prob nan (nan)	GS 30.781 (30.781)	mem 40.031
Train: [32][300/750]	BT 0.158 (1.189)	DT 0.008 (1.056)	loss nan (nan)	prob nan (nan)	GS 32.422 (32.422)	mem 40.388
Train: [32][305/750]	BT 0.215 (1.206)	DT 0.004 (1.072)	loss nan (nan)	prob nan (nan)	GS 25.391 (25.391)	mem 39.999
Train: [32][310/750]	BT 0.121 (1.190)	DT 0.002 (1.055)	loss nan (nan)	prob nan (nan)	GS 36.531 (36.531)	mem 40.104
Train: [32][315/750]	BT 0.187 (1.203)	DT 0.007 (1.068)	loss nan (nan)	prob nan (nan)	GS 33.406 (33.406)	mem 40.041
Train: [32][320/750]	BT 1.932 (1.192)	DT 1.795 (1.057)	loss nan (nan)	prob nan (nan)	GS 33.297 (33.297)	mem 40.055
Train: [32][325/750]	BT 0.177 (1.183)	DT 0.029 (1.049)	loss nan (nan)	prob nan (nan)	GS 29.062 (29.062)	mem 40.046
Train: [32][330/750]	BT 0.082 (1.192)	DT 0.001 (1.058)	loss nan (nan)	prob nan (nan)	GS 35.578 (35.578)	mem 40.048
Train: [32][335/750]	BT 0.211 (1.176)	DT 0.061 (1.042)	loss nan (nan)	prob nan (nan)	GS 32.000 (32.000)	mem 40.053
Train: [32][340/750]	BT 0.091 (1.190)	DT 0.002 (1.056)	loss nan (nan)	prob nan (nan)	GS 31.359 (31.359)	mem 39.918
Train: [32][345/750]	BT 0.111 (1.179)	DT 0.001 (1.046)	loss nan (nan)	prob nan (nan)	GS 30.172 (30.172)	mem 40.032
Train: [32][350/750]	BT 2.713 (1.192)	DT 2.585 (1.060)	loss nan (nan)	prob nan (nan)	GS 31.500 (31.500)	mem 40.017
Train: [32][355/750]	BT 0.219 (1.178)	DT 0.012 (1.045)	loss nan (nan)	prob nan (nan)	GS 29.547 (29.547)	mem 40.335
Train: [32][360/750]	BT 5.779 (1.184)	DT 5.669 (1.052)	loss nan (nan)	prob nan (nan)	GS 34.469 (34.469)	mem 39.887
Train: [32][365/750]	BT 0.118 (1.186)	DT 0.002 (1.053)	loss nan (nan)	prob nan (nan)	GS 36.812 (36.812)	mem 40.173
Train: [32][370/750]	BT 0.128 (1.172)	DT 0.016 (1.039)	loss nan (nan)	prob nan (nan)	GS 30.344 (30.344)	mem 39.940
Train: [32][375/750]	BT 0.086 (1.190)	DT 0.002 (1.057)	loss nan (nan)	prob nan (nan)	GS 32.469 (32.469)	mem 39.983
Train: [32][380/750]	BT 0.993 (1.178)	DT 0.820 (1.046)	loss nan (nan)	prob nan (nan)	GS 34.219 (34.219)	mem 39.997
Train: [32][385/750]	BT 0.232 (1.187)	DT 0.005 (1.054)	loss nan (nan)	prob nan (nan)	GS 33.609 (33.609)	mem 39.968
Train: [32][390/750]	BT 0.154 (1.173)	DT 0.023 (1.041)	loss nan (nan)	prob nan (nan)	GS 29.328 (29.328)	mem 40.085
Train: [32][395/750]	BT 0.094 (1.169)	DT 0.002 (1.037)	loss nan (nan)	prob nan (nan)	GS 31.812 (31.812)	mem 39.973
Train: [32][400/750]	BT 0.111 (1.174)	DT 0.002 (1.041)	loss nan (nan)	prob nan (nan)	GS 34.375 (34.375)	mem 39.971
Train: [32][405/750]	BT 0.179 (1.169)	DT 0.002 (1.035)	loss nan (nan)	prob nan (nan)	GS 28.359 (28.359)	mem 39.857
Train: [32][410/750]	BT 3.119 (1.180)	DT 3.032 (1.047)	loss nan (nan)	prob nan (nan)	GS 34.312 (34.312)	mem 39.927
Train: [32][415/750]	BT 0.179 (1.174)	DT 0.008 (1.041)	loss nan (nan)	prob nan (nan)	GS 27.719 (27.719)	mem 39.879
Train: [32][420/750]	BT 8.456 (1.182)	DT 8.251 (1.049)	loss nan (nan)	prob nan (nan)	GS 39.312 (39.312)	mem 39.903
Train: [32][425/750]	BT 0.102 (1.171)	DT 0.006 (1.038)	loss nan (nan)	prob nan (nan)	GS 29.844 (29.844)	mem 40.036
Train: [32][430/750]	BT 0.162 (1.171)	DT 0.001 (1.038)	loss nan (nan)	prob nan (nan)	GS 35.469 (35.469)	mem 39.859
Train: [32][435/750]	BT 0.199 (1.177)	DT 0.049 (1.044)	loss nan (nan)	prob nan (nan)	GS 28.828 (28.828)	mem 39.973
Train: [32][440/750]	BT 3.812 (1.179)	DT 3.657 (1.046)	loss nan (nan)	prob nan (nan)	GS 34.766 (34.766)	mem 39.931
Train: [32][445/750]	BT 0.120 (1.179)	DT 0.002 (1.046)	loss nan (nan)	prob nan (nan)	GS 31.469 (31.469)	mem 40.019
Train: [32][450/750]	BT 4.130 (1.176)	DT 3.958 (1.043)	loss nan (nan)	prob nan (nan)	GS 34.297 (34.297)	mem 39.952
Train: [32][455/750]	BT 0.127 (1.170)	DT 0.004 (1.037)	loss nan (nan)	prob nan (nan)	GS 30.375 (30.375)	mem 40.080
Train: [32][460/750]	BT 0.085 (1.164)	DT 0.004 (1.030)	loss nan (nan)	prob nan (nan)	GS 32.641 (32.641)	mem 40.003
Train: [32][465/750]	BT 0.104 (1.175)	DT 0.017 (1.042)	loss nan (nan)	prob nan (nan)	GS 32.547 (32.547)	mem 39.910
Train: [32][470/750]	BT 0.116 (1.168)	DT 0.002 (1.035)	loss nan (nan)	prob nan (nan)	GS 35.656 (35.656)	mem 40.031
Train: [32][475/750]	BT 0.082 (1.180)	DT 0.001 (1.046)	loss nan (nan)	prob nan (nan)	GS 35.141 (35.141)	mem 39.949
Train: [32][480/750]	BT 1.262 (1.171)	DT 1.104 (1.038)	loss nan (nan)	prob nan (nan)	GS 35.312 (35.312)	mem 39.988
Train: [32][485/750]	BT 0.097 (1.160)	DT 0.001 (1.027)	loss nan (nan)	prob nan (nan)	GS 37.562 (37.562)	mem 39.992
Train: [32][490/750]	BT 0.082 (1.172)	DT 0.001 (1.039)	loss nan (nan)	prob nan (nan)	GS 36.281 (36.281)	mem 40.017
Train: [32][495/750]	BT 0.108 (1.161)	DT 0.005 (1.029)	loss nan (nan)	prob nan (nan)	GS 31.094 (31.094)	mem 40.022
Train: [32][500/750]	BT 0.191 (1.175)	DT 0.005 (1.042)	loss nan (nan)	prob nan (nan)	GS 36.656 (36.656)	mem 39.964
Train: [32][505/750]	BT 0.089 (1.164)	DT 0.002 (1.032)	loss nan (nan)	prob nan (nan)	GS 26.828 (26.828)	mem 39.979
Train: [32][510/750]	BT 10.685 (1.175)	DT 10.549 (1.042)	loss nan (nan)	prob nan (nan)	GS 34.984 (34.984)	mem 39.952
Train: [32][515/750]	BT 0.117 (1.164)	DT 0.001 (1.032)	loss nan (nan)	prob nan (nan)	GS 29.594 (29.594)	mem 40.021
Train: [32][520/750]	BT 0.147 (1.154)	DT 0.002 (1.022)	loss nan (nan)	prob nan (nan)	GS 34.484 (34.484)	mem 39.959
Train: [32][525/750]	BT 0.132 (1.164)	DT 0.002 (1.031)	loss nan (nan)	prob nan (nan)	GS 27.312 (27.312)	mem 40.025
Train: [32][530/750]	BT 0.137 (1.157)	DT 0.002 (1.025)	loss nan (nan)	prob nan (nan)	GS 30.812 (30.812)	mem 39.995
Train: [32][535/750]	BT 0.107 (1.158)	DT 0.006 (1.026)	loss nan (nan)	prob nan (nan)	GS 28.641 (28.641)	mem 39.999
Train: [32][540/750]	BT 7.131 (1.162)	DT 7.052 (1.030)	loss nan (nan)	prob nan (nan)	GS 38.938 (38.938)	mem 39.895
Train: [32][545/750]	BT 0.119 (1.152)	DT 0.002 (1.020)	loss nan (nan)	prob nan (nan)	GS 34.375 (34.375)	mem 39.897
Train: [32][550/750]	BT 0.114 (1.149)	DT 0.002 (1.017)	loss nan (nan)	prob nan (nan)	GS 34.000 (34.000)	mem 40.041
Train: [32][555/750]	BT 0.084 (1.154)	DT 0.001 (1.022)	loss nan (nan)	prob nan (nan)	GS 35.891 (35.891)	mem 39.966
Train: [32][560/750]	BT 0.189 (1.149)	DT 0.006 (1.017)	loss nan (nan)	prob nan (nan)	GS 35.969 (35.969)	mem 40.007
Train: [32][565/750]	BT 0.086 (1.159)	DT 0.001 (1.027)	loss nan (nan)	prob nan (nan)	GS 28.250 (28.250)	mem 40.140
Train: [32][570/750]	BT 2.554 (1.154)	DT 2.459 (1.022)	loss nan (nan)	prob nan (nan)	GS 34.344 (34.344)	mem 39.901
Train: [32][575/750]	BT 0.098 (1.145)	DT 0.010 (1.013)	loss nan (nan)	prob nan (nan)	GS 31.094 (31.094)	mem 39.987
Train: [32][580/750]	BT 0.094 (1.153)	DT 0.008 (1.022)	loss nan (nan)	prob nan (nan)	GS 32.469 (32.469)	mem 39.802
Train: [32][585/750]	BT 0.059 (1.144)	DT 0.001 (1.013)	loss nan (nan)	prob nan (nan)	GS 35.062 (35.062)	mem 39.864
Train: [32][590/750]	BT 1.667 (1.157)	DT 1.599 (1.025)	loss nan (nan)	prob nan (nan)	GS 32.250 (32.250)	mem 39.938
Train: [32][595/750]	BT 0.115 (1.148)	DT 0.002 (1.017)	loss nan (nan)	prob nan (nan)	GS 31.938 (31.938)	mem 39.877
Train: [32][600/750]	BT 9.648 (1.155)	DT 9.486 (1.024)	loss nan (nan)	prob nan (nan)	GS 34.297 (34.297)	mem 40.071
Train: [32][605/750]	BT 0.173 (1.154)	DT 0.001 (1.022)	loss nan (nan)	prob nan (nan)	GS 28.391 (28.391)	mem 39.934
Train: [32][610/750]	BT 0.148 (1.145)	DT 0.023 (1.014)	loss nan (nan)	prob nan (nan)	GS 37.328 (37.328)	mem 39.939
Train: [32][615/750]	BT 0.071 (1.158)	DT 0.001 (1.027)	loss nan (nan)	prob nan (nan)	GS 45.531 (45.531)	mem 40.006
Train: [32][620/750]	BT 0.081 (1.150)	DT 0.001 (1.019)	loss nan (nan)	prob nan (nan)	GS 36.609 (36.609)	mem 40.005
Train: [32][625/750]	BT 0.157 (1.145)	DT 0.002 (1.013)	loss nan (nan)	prob nan (nan)	GS 30.469 (30.469)	mem 40.041
Train: [32][630/750]	BT 0.128 (1.149)	DT 0.002 (1.017)	loss nan (nan)	prob nan (nan)	GS 33.531 (33.531)	mem 40.020
Train: [32][635/750]	BT 0.101 (1.151)	DT 0.010 (1.019)	loss nan (nan)	prob nan (nan)	GS 33.969 (33.969)	mem 39.986
Train: [32][640/750]	BT 0.151 (1.150)	DT 0.001 (1.018)	loss nan (nan)	prob nan (nan)	GS 36.828 (36.828)	mem 40.144
Train: [32][645/750]	BT 0.100 (1.142)	DT 0.001 (1.011)	loss nan (nan)	prob nan (nan)	GS 29.859 (29.859)	mem 39.983
Train: [32][650/750]	BT 8.006 (1.154)	DT 7.909 (1.022)	loss nan (nan)	prob nan (nan)	GS 37.438 (37.438)	mem 39.927
Train: [32][655/750]	BT 0.159 (1.146)	DT 0.019 (1.015)	loss nan (nan)	prob nan (nan)	GS 28.219 (28.219)	mem 39.938
Train: [32][660/750]	BT 1.487 (1.141)	DT 1.370 (1.009)	loss nan (nan)	prob nan (nan)	GS 32.453 (32.453)	mem 39.982
Train: [32][665/750]	BT 0.138 (1.150)	DT 0.002 (1.019)	loss nan (nan)	prob nan (nan)	GS 28.828 (28.828)	mem 39.973
Train: [32][670/750]	BT 0.151 (1.143)	DT 0.020 (1.011)	loss nan (nan)	prob nan (nan)	GS 36.281 (36.281)	mem 39.994
Train: [32][675/750]	BT 0.228 (1.150)	DT 0.002 (1.018)	loss nan (nan)	prob nan (nan)	GS 30.531 (30.531)	mem 40.076
Train: [32][680/750]	BT 0.080 (1.142)	DT 0.001 (1.011)	loss nan (nan)	prob nan (nan)	GS 37.078 (37.078)	mem 40.045
Train: [32][685/750]	BT 0.102 (1.139)	DT 0.001 (1.008)	loss nan (nan)	prob nan (nan)	GS 32.703 (32.703)	mem 40.015
Train: [32][690/750]	BT 0.093 (1.146)	DT 0.001 (1.015)	loss nan (nan)	prob nan (nan)	GS 38.469 (38.469)	mem 40.059
Train: [32][695/750]	BT 0.238 (1.139)	DT 0.002 (1.008)	loss nan (nan)	prob nan (nan)	GS 30.641 (30.641)	mem 40.039
Train: [32][700/750]	BT 0.100 (1.149)	DT 0.006 (1.018)	loss nan (nan)	prob nan (nan)	GS 33.078 (33.078)	mem 39.991
Train: [32][705/750]	BT 0.295 (1.143)	DT 0.002 (1.012)	loss nan (nan)	prob nan (nan)	GS 29.250 (29.250)	mem 39.958
arpack error, retry= 0
Train: [32][710/750]	BT 10.102 (1.151)	DT 9.954 (1.019)	loss nan (nan)	prob nan (nan)	GS 34.000 (34.000)	mem 40.056
Train: [32][715/750]	BT 0.123 (1.145)	DT 0.010 (1.013)	loss nan (nan)	prob nan (nan)	GS 27.938 (27.938)	mem 40.034
Train: [32][720/750]	BT 1.532 (1.140)	DT 1.404 (1.008)	loss nan (nan)	prob nan (nan)	GS 36.297 (36.297)	mem 40.104
Train: [32][725/750]	BT 0.156 (1.147)	DT 0.041 (1.016)	loss nan (nan)	prob nan (nan)	GS 31.906 (31.906)	mem 40.003
Train: [32][730/750]	BT 0.233 (1.141)	DT 0.013 (1.009)	loss nan (nan)	prob nan (nan)	GS 36.781 (36.781)	mem 40.002
Train: [32][735/750]	BT 0.080 (1.145)	DT 0.002 (1.013)	loss nan (nan)	prob nan (nan)	GS 31.000 (31.000)	mem 37.034
Train: [32][740/750]	BT 0.086 (1.140)	DT 0.011 (1.008)	loss nan (nan)	prob nan (nan)	GS 31.578 (31.578)	mem 19.562
Train: [32][745/750]	BT 0.089 (1.133)	DT 0.001 (1.002)	loss nan (nan)	prob nan (nan)	GS 34.438 (34.438)	mem 16.629
Train: [32][750/750]	BT 0.096 (1.130)	DT 0.012 (0.999)	loss nan (nan)	prob nan (nan)	GS 38.000 (38.000)	mem 11.981
Train: [32][755/750]	BT 0.055 (1.123)	DT 0.001 (0.993)	loss nan (nan)	prob nan (nan)	GS 35.344 (35.344)	mem 7.689
epoch 32, total time 848.05
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [33][1/750]	BT 24.869 (24.869)	DT 24.639 (24.639)	loss nan (nan)	prob nan (nan)	GS 32.125 (32.125)	mem 38.770
Train: [33][5/750]	BT 0.254 (5.126)	DT 0.003 (4.936)	loss nan (nan)	prob nan (nan)	GS 32.594 (32.594)	mem 38.666
Train: [33][10/750]	BT 1.611 (2.784)	DT 1.513 (2.629)	loss nan (nan)	prob nan (nan)	GS 34.797 (34.797)	mem 38.775
Train: [33][15/750]	BT 0.121 (2.399)	DT 0.011 (2.231)	loss nan (nan)	prob nan (nan)	GS 30.562 (30.562)	mem 38.899
Train: [33][20/750]	BT 0.098 (2.010)	DT 0.011 (1.845)	loss nan (nan)	prob nan (nan)	GS 34.266 (34.266)	mem 38.925
Train: [33][25/750]	BT 2.768 (1.872)	DT 2.650 (1.713)	loss nan (nan)	prob nan (nan)	GS 33.297 (33.297)	mem 39.131
Train: [33][30/750]	BT 1.661 (1.775)	DT 1.501 (1.615)	loss nan (nan)	prob nan (nan)	GS 32.453 (32.453)	mem 39.070
Train: [33][35/750]	BT 0.225 (1.683)	DT 0.016 (1.521)	loss nan (nan)	prob nan (nan)	GS 28.281 (28.281)	mem 39.260
Train: [33][40/750]	BT 0.142 (1.582)	DT 0.003 (1.418)	loss nan (nan)	prob nan (nan)	GS 31.094 (31.094)	mem 39.512
Train: [33][45/750]	BT 0.101 (1.440)	DT 0.005 (1.283)	loss nan (nan)	prob nan (nan)	GS 30.938 (30.938)	mem 39.580
Train: [33][50/750]	BT 6.301 (1.536)	DT 6.097 (1.380)	loss nan (nan)	prob nan (nan)	GS 29.625 (29.625)	mem 39.756
Train: [33][55/750]	BT 0.190 (1.415)	DT 0.009 (1.256)	loss nan (nan)	prob nan (nan)	GS 32.344 (32.344)	mem 39.657
Train: [33][60/750]	BT 0.127 (1.430)	DT 0.004 (1.269)	loss nan (nan)	prob nan (nan)	GS 36.797 (36.797)	mem 39.708
Train: [33][65/750]	BT 0.143 (1.412)	DT 0.001 (1.254)	loss nan (nan)	prob nan (nan)	GS 31.422 (31.422)	mem 39.647
Train: [33][70/750]	BT 3.680 (1.370)	DT 3.449 (1.213)	loss nan (nan)	prob nan (nan)	GS 33.109 (33.109)	mem 39.685
Train: [33][75/750]	BT 0.137 (1.354)	DT 0.017 (1.199)	loss nan (nan)	prob nan (nan)	GS 34.906 (34.906)	mem 39.872
Train: [33][80/750]	BT 0.133 (1.303)	DT 0.002 (1.151)	loss nan (nan)	prob nan (nan)	GS 34.047 (34.047)	mem 39.715
Train: [33][85/750]	BT 0.094 (1.329)	DT 0.002 (1.177)	loss nan (nan)	prob nan (nan)	GS 33.969 (33.969)	mem 39.902
Train: [33][90/750]	BT 3.078 (1.295)	DT 2.968 (1.145)	loss nan (nan)	prob nan (nan)	GS 35.125 (35.125)	mem 39.841
Train: [33][95/750]	BT 0.160 (1.305)	DT 0.006 (1.155)	loss nan (nan)	prob nan (nan)	GS 33.141 (33.141)	mem 39.911
Train: [33][100/750]	BT 0.210 (1.278)	DT 0.003 (1.127)	loss nan (nan)	prob nan (nan)	GS 30.797 (30.797)	mem 39.741
Train: [33][105/750]	BT 0.137 (1.264)	DT 0.002 (1.112)	loss nan (nan)	prob nan (nan)	GS 27.172 (27.172)	mem 39.789
Train: [33][110/750]	BT 0.100 (1.256)	DT 0.001 (1.104)	loss nan (nan)	prob nan (nan)	GS 34.000 (34.000)	mem 39.881
Train: [33][115/750]	BT 0.102 (1.254)	DT 0.002 (1.102)	loss nan (nan)	prob nan (nan)	GS 30.547 (30.547)	mem 39.813
Train: [33][120/750]	BT 0.141 (1.252)	DT 0.014 (1.101)	loss nan (nan)	prob nan (nan)	GS 37.938 (37.938)	mem 39.902
Train: [33][125/750]	BT 0.105 (1.217)	DT 0.005 (1.068)	loss nan (nan)	prob nan (nan)	GS 34.469 (34.469)	mem 39.789
Train: [33][130/750]	BT 4.818 (1.235)	DT 4.724 (1.087)	loss nan (nan)	prob nan (nan)	GS 29.969 (29.969)	mem 39.988
Train: [33][135/750]	BT 0.122 (1.226)	DT 0.011 (1.080)	loss nan (nan)	prob nan (nan)	GS 29.438 (29.438)	mem 39.815
Train: [33][140/750]	BT 0.233 (1.195)	DT 0.002 (1.049)	loss nan (nan)	prob nan (nan)	GS 32.562 (32.562)	mem 39.963
Train: [33][145/750]	BT 0.311 (1.195)	DT 0.055 (1.047)	loss nan (nan)	prob nan (nan)	GS 33.328 (33.328)	mem 39.903
Train: [33][150/750]	BT 4.320 (1.213)	DT 4.202 (1.067)	loss nan (nan)	prob nan (nan)	GS 33.141 (33.141)	mem 39.936
Train: [33][155/750]	BT 0.182 (1.191)	DT 0.013 (1.045)	loss nan (nan)	prob nan (nan)	GS 29.828 (29.828)	mem 39.835
Train: [33][160/750]	BT 0.895 (1.210)	DT 0.805 (1.066)	loss nan (nan)	prob nan (nan)	GS 38.906 (38.906)	mem 39.789
Train: [33][165/750]	BT 0.076 (1.191)	DT 0.001 (1.047)	loss nan (nan)	prob nan (nan)	GS 29.984 (29.984)	mem 39.865
Train: [33][170/750]	BT 4.351 (1.196)	DT 4.257 (1.054)	loss nan (nan)	prob nan (nan)	GS 29.594 (29.594)	mem 39.905
Train: [33][175/750]	BT 0.222 (1.194)	DT 0.003 (1.052)	loss nan (nan)	prob nan (nan)	GS 31.172 (31.172)	mem 40.676
Train: [33][180/750]	BT 0.072 (1.189)	DT 0.001 (1.047)	loss nan (nan)	prob nan (nan)	GS 29.516 (29.516)	mem 39.887
Train: [33][185/750]	BT 0.097 (1.206)	DT 0.005 (1.064)	loss nan (nan)	prob nan (nan)	GS 28.094 (28.094)	mem 39.856
Train: [33][190/750]	BT 1.863 (1.188)	DT 1.686 (1.045)	loss nan (nan)	prob nan (nan)	GS 35.172 (35.172)	mem 39.886
Train: [33][195/750]	BT 0.114 (1.207)	DT 0.002 (1.065)	loss nan (nan)	prob nan (nan)	GS 32.062 (32.062)	mem 39.937
Train: [33][200/750]	BT 0.182 (1.187)	DT 0.009 (1.045)	loss nan (nan)	prob nan (nan)	GS 36.703 (36.703)	mem 40.180
Train: [33][205/750]	BT 0.120 (1.193)	DT 0.002 (1.051)	loss nan (nan)	prob nan (nan)	GS 34.875 (34.875)	mem 40.088
Train: [33][210/750]	BT 0.160 (1.196)	DT 0.002 (1.053)	loss nan (nan)	prob nan (nan)	GS 32.938 (32.938)	mem 39.973
Train: [33][215/750]	BT 0.141 (1.203)	DT 0.002 (1.061)	loss nan (nan)	prob nan (nan)	GS 32.422 (32.422)	mem 39.989
Train: [33][220/750]	BT 0.125 (1.193)	DT 0.001 (1.050)	loss nan (nan)	prob nan (nan)	GS 26.703 (26.703)	mem 39.991
Train: [33][225/750]	BT 0.127 (1.169)	DT 0.002 (1.027)	loss nan (nan)	prob nan (nan)	GS 34.297 (34.297)	mem 39.993
Train: [33][230/750]	BT 5.094 (1.202)	DT 4.995 (1.061)	loss nan (nan)	prob nan (nan)	GS 28.562 (28.562)	mem 40.032
Train: [33][235/750]	BT 0.186 (1.179)	DT 0.001 (1.039)	loss nan (nan)	prob nan (nan)	GS 31.375 (31.375)	mem 40.124
Train: [33][240/750]	BT 2.119 (1.190)	DT 2.007 (1.050)	loss nan (nan)	prob nan (nan)	GS 35.391 (35.391)	mem 39.948
Train: [33][245/750]	BT 0.089 (1.178)	DT 0.002 (1.038)	loss nan (nan)	prob nan (nan)	GS 36.016 (36.016)	mem 40.009
Train: [33][250/750]	BT 4.882 (1.184)	DT 4.806 (1.044)	loss nan (nan)	prob nan (nan)	GS 35.109 (35.109)	mem 39.957
Train: [33][255/750]	BT 0.081 (1.171)	DT 0.004 (1.032)	loss nan (nan)	prob nan (nan)	GS 31.812 (31.812)	mem 39.988
Train: [33][260/750]	BT 0.096 (1.185)	DT 0.004 (1.046)	loss nan (nan)	prob nan (nan)	GS 34.625 (34.625)	mem 39.945
Train: [33][265/750]	BT 0.205 (1.170)	DT 0.007 (1.031)	loss nan (nan)	prob nan (nan)	GS 29.281 (29.281)	mem 39.934
Train: [33][270/750]	BT 3.704 (1.178)	DT 3.554 (1.038)	loss nan (nan)	prob nan (nan)	GS 29.625 (29.625)	mem 39.932
Train: [33][275/750]	BT 0.134 (1.182)	DT 0.027 (1.041)	loss nan (nan)	prob nan (nan)	GS 32.859 (32.859)	mem 39.928
Train: [33][280/750]	BT 0.145 (1.167)	DT 0.002 (1.026)	loss nan (nan)	prob nan (nan)	GS 33.875 (33.875)	mem 39.935
Train: [33][285/750]	BT 0.150 (1.167)	DT 0.006 (1.026)	loss nan (nan)	prob nan (nan)	GS 30.672 (30.672)	mem 40.075
Train: [33][290/750]	BT 0.159 (1.181)	DT 0.007 (1.040)	loss nan (nan)	prob nan (nan)	GS 34.953 (34.953)	mem 39.944
Train: [33][295/750]	BT 0.087 (1.163)	DT 0.001 (1.023)	loss nan (nan)	prob nan (nan)	GS 29.422 (29.422)	mem 39.948
Train: [33][300/750]	BT 0.124 (1.192)	DT 0.004 (1.052)	loss nan (nan)	prob nan (nan)	GS 32.391 (32.391)	mem 39.926
Train: [33][305/750]	BT 0.127 (1.175)	DT 0.002 (1.035)	loss nan (nan)	prob nan (nan)	GS 31.938 (31.938)	mem 39.971
Train: [33][310/750]	BT 12.183 (1.197)	DT 12.068 (1.058)	loss nan (nan)	prob nan (nan)	GS 34.391 (34.391)	mem 40.005
Train: [33][315/750]	BT 0.090 (1.180)	DT 0.001 (1.041)	loss nan (nan)	prob nan (nan)	GS 32.453 (32.453)	mem 39.981
Train: [33][320/750]	BT 0.769 (1.165)	DT 0.685 (1.027)	loss nan (nan)	prob nan (nan)	GS 39.625 (39.625)	mem 39.874
Train: [33][325/750]	BT 0.143 (1.187)	DT 0.009 (1.050)	loss nan (nan)	prob nan (nan)	GS 29.562 (29.562)	mem 39.839
Train: [33][330/750]	BT 0.094 (1.171)	DT 0.001 (1.034)	loss nan (nan)	prob nan (nan)	GS 34.500 (34.500)	mem 39.865
Train: [33][335/750]	BT 0.118 (1.191)	DT 0.002 (1.054)	loss nan (nan)	prob nan (nan)	GS 32.453 (32.453)	mem 39.933
Train: [33][340/750]	BT 0.136 (1.175)	DT 0.004 (1.038)	loss nan (nan)	prob nan (nan)	GS 33.578 (33.578)	mem 39.933
Train: [33][345/750]	BT 0.183 (1.160)	DT 0.005 (1.023)	loss nan (nan)	prob nan (nan)	GS 32.781 (32.781)	mem 39.933
Train: [33][350/750]	BT 0.137 (1.177)	DT 0.002 (1.041)	loss nan (nan)	prob nan (nan)	GS 30.047 (30.047)	mem 39.995
Train: [33][355/750]	BT 0.175 (1.163)	DT 0.007 (1.026)	loss nan (nan)	prob nan (nan)	GS 31.219 (31.219)	mem 40.029
Train: [33][360/750]	BT 0.084 (1.175)	DT 0.001 (1.039)	loss nan (nan)	prob nan (nan)	GS 26.578 (26.578)	mem 40.008
Train: [33][365/750]	BT 0.080 (1.161)	DT 0.004 (1.025)	loss nan (nan)	prob nan (nan)	GS 30.500 (30.500)	mem 40.009
Train: [33][370/750]	BT 12.705 (1.180)	DT 12.588 (1.045)	loss nan (nan)	prob nan (nan)	GS 36.703 (36.703)	mem 39.961
Train: [33][375/750]	BT 0.209 (1.166)	DT 0.002 (1.031)	loss nan (nan)	prob nan (nan)	GS 30.531 (30.531)	mem 40.027
Train: [33][380/750]	BT 0.160 (1.153)	DT 0.009 (1.018)	loss nan (nan)	prob nan (nan)	GS 31.891 (31.891)	mem 40.039
Train: [33][385/750]	BT 0.073 (1.171)	DT 0.001 (1.037)	loss nan (nan)	prob nan (nan)	GS 31.516 (31.516)	mem 40.018
Train: [33][390/750]	BT 0.097 (1.157)	DT 0.008 (1.024)	loss nan (nan)	prob nan (nan)	GS 34.062 (34.062)	mem 40.021
Train: [33][395/750]	BT 0.121 (1.168)	DT 0.002 (1.035)	loss nan (nan)	prob nan (nan)	GS 31.516 (31.516)	mem 40.160
Train: [33][400/750]	BT 0.122 (1.167)	DT 0.002 (1.033)	loss nan (nan)	prob nan (nan)	GS 34.062 (34.062)	mem 40.043
Train: [33][405/750]	BT 0.100 (1.153)	DT 0.001 (1.020)	loss nan (nan)	prob nan (nan)	GS 29.469 (29.469)	mem 40.014
Train: [33][410/750]	BT 7.373 (1.166)	DT 7.266 (1.033)	loss nan (nan)	prob nan (nan)	GS 30.953 (30.953)	mem 40.008
Train: [33][415/750]	BT 0.168 (1.154)	DT 0.001 (1.021)	loss nan (nan)	prob nan (nan)	GS 28.328 (28.328)	mem 40.013
Train: [33][420/750]	BT 0.122 (1.156)	DT 0.002 (1.024)	loss nan (nan)	prob nan (nan)	GS 35.547 (35.547)	mem 40.189
Train: [33][425/750]	BT 0.066 (1.169)	DT 0.001 (1.037)	loss nan (nan)	prob nan (nan)	GS 41.125 (41.125)	mem 40.127
Train: [33][430/750]	BT 2.717 (1.163)	DT 2.583 (1.031)	loss nan (nan)	prob nan (nan)	GS 31.953 (31.953)	mem 40.141
Train: [33][435/750]	BT 0.108 (1.172)	DT 0.005 (1.040)	loss nan (nan)	prob nan (nan)	GS 33.875 (33.875)	mem 40.106
Train: [33][440/750]	BT 0.095 (1.160)	DT 0.002 (1.029)	loss nan (nan)	prob nan (nan)	GS 33.641 (33.641)	mem 40.109
Train: [33][445/750]	BT 0.163 (1.158)	DT 0.001 (1.027)	loss nan (nan)	prob nan (nan)	GS 31.438 (31.438)	mem 40.169
Train: [33][450/750]	BT 0.126 (1.167)	DT 0.005 (1.035)	loss nan (nan)	prob nan (nan)	GS 33.297 (33.297)	mem 40.160
Train: [33][455/750]	BT 0.137 (1.161)	DT 0.001 (1.029)	loss nan (nan)	prob nan (nan)	GS 30.125 (30.125)	mem 40.118
Train: [33][460/750]	BT 0.237 (1.164)	DT 0.001 (1.032)	loss nan (nan)	prob nan (nan)	GS 37.281 (37.281)	mem 40.236
Train: [33][465/750]	BT 0.118 (1.153)	DT 0.002 (1.021)	loss nan (nan)	prob nan (nan)	GS 31.797 (31.797)	mem 40.149
Train: [33][470/750]	BT 8.770 (1.167)	DT 8.682 (1.036)	loss nan (nan)	prob nan (nan)	GS 31.703 (31.703)	mem 40.081
Train: [33][475/750]	BT 0.137 (1.156)	DT 0.029 (1.025)	loss nan (nan)	prob nan (nan)	GS 30.344 (30.344)	mem 40.083
Train: [33][480/750]	BT 0.137 (1.146)	DT 0.003 (1.015)	loss nan (nan)	prob nan (nan)	GS 36.922 (36.922)	mem 40.084
Train: [33][485/750]	BT 0.157 (1.156)	DT 0.001 (1.025)	loss nan (nan)	prob nan (nan)	GS 31.969 (31.969)	mem 40.115
Train: [33][490/750]	BT 4.746 (1.155)	DT 4.653 (1.024)	loss nan (nan)	prob nan (nan)	GS 31.438 (31.438)	mem 40.128
Train: [33][495/750]	BT 0.080 (1.163)	DT 0.001 (1.032)	loss nan (nan)	prob nan (nan)	GS 30.328 (30.328)	mem 40.134
Train: [33][500/750]	BT 0.096 (1.153)	DT 0.001 (1.022)	loss nan (nan)	prob nan (nan)	GS 32.875 (32.875)	mem 40.133
Train: [33][505/750]	BT 0.258 (1.143)	DT 0.001 (1.012)	loss nan (nan)	prob nan (nan)	GS 30.047 (30.047)	mem 40.191
Train: [33][510/750]	BT 0.084 (1.158)	DT 0.001 (1.027)	loss nan (nan)	prob nan (nan)	GS 32.875 (32.875)	mem 40.160
Train: [33][515/750]	BT 0.134 (1.148)	DT 0.006 (1.017)	loss nan (nan)	prob nan (nan)	GS 32.828 (32.828)	mem 40.163
Train: [33][520/750]	BT 0.069 (1.163)	DT 0.001 (1.032)	loss nan (nan)	prob nan (nan)	GS 33.422 (33.422)	mem 40.069
Train: [33][525/750]	BT 0.097 (1.153)	DT 0.001 (1.022)	loss nan (nan)	prob nan (nan)	GS 33.234 (33.234)	mem 40.068
Train: [33][530/750]	BT 10.169 (1.162)	DT 10.012 (1.031)	loss nan (nan)	prob nan (nan)	GS 36.453 (36.453)	mem 40.127
Train: [33][535/750]	BT 0.219 (1.153)	DT 0.002 (1.022)	loss nan (nan)	prob nan (nan)	GS 32.391 (32.391)	mem 40.129
Train: [33][540/750]	BT 0.117 (1.143)	DT 0.002 (1.012)	loss nan (nan)	prob nan (nan)	GS 35.297 (35.297)	mem 40.174
Train: [33][545/750]	BT 0.117 (1.156)	DT 0.005 (1.025)	loss nan (nan)	prob nan (nan)	GS 31.562 (31.562)	mem 40.229
Train: [33][550/750]	BT 0.240 (1.147)	DT 0.014 (1.016)	loss nan (nan)	prob nan (nan)	GS 29.969 (29.969)	mem 40.136
Train: [33][555/750]	BT 0.153 (1.161)	DT 0.001 (1.030)	loss nan (nan)	prob nan (nan)	GS 29.797 (29.797)	mem 40.160
Train: [33][560/750]	BT 0.118 (1.152)	DT 0.007 (1.021)	loss nan (nan)	prob nan (nan)	GS 35.156 (35.156)	mem 40.161
Train: [33][565/750]	BT 0.108 (1.143)	DT 0.002 (1.012)	loss nan (nan)	prob nan (nan)	GS 34.172 (34.172)	mem 40.160
Train: [33][570/750]	BT 0.115 (1.150)	DT 0.002 (1.018)	loss nan (nan)	prob nan (nan)	GS 35.219 (35.219)	mem 40.143
Train: [33][575/750]	BT 0.209 (1.142)	DT 0.019 (1.010)	loss nan (nan)	prob nan (nan)	GS 31.250 (31.250)	mem 40.151
Train: [33][580/750]	BT 0.139 (1.155)	DT 0.003 (1.023)	loss nan (nan)	prob nan (nan)	GS 36.906 (36.906)	mem 40.100
Train: [33][585/750]	BT 0.109 (1.146)	DT 0.006 (1.014)	loss nan (nan)	prob nan (nan)	GS 33.516 (33.516)	mem 40.164
Train: [33][590/750]	BT 10.928 (1.156)	DT 10.822 (1.024)	loss nan (nan)	prob nan (nan)	GS 31.891 (31.891)	mem 40.285
Train: [33][595/750]	BT 0.145 (1.147)	DT 0.002 (1.016)	loss nan (nan)	prob nan (nan)	GS 31.969 (31.969)	mem 40.337
Train: [33][600/750]	BT 0.091 (1.139)	DT 0.002 (1.007)	loss nan (nan)	prob nan (nan)	GS 30.891 (30.891)	mem 40.239
Train: [33][605/750]	BT 0.087 (1.146)	DT 0.002 (1.014)	loss nan (nan)	prob nan (nan)	GS 32.688 (32.688)	mem 40.178
Train: [33][610/750]	BT 1.642 (1.140)	DT 1.523 (1.008)	loss nan (nan)	prob nan (nan)	GS 35.500 (35.500)	mem 40.181
Train: [33][615/750]	BT 0.092 (1.151)	DT 0.009 (1.019)	loss nan (nan)	prob nan (nan)	GS 27.812 (27.812)	mem 40.157
Train: [33][620/750]	BT 0.131 (1.143)	DT 0.002 (1.011)	loss nan (nan)	prob nan (nan)	GS 38.047 (38.047)	mem 40.181
Train: [33][625/750]	BT 0.136 (1.135)	DT 0.029 (1.003)	loss nan (nan)	prob nan (nan)	GS 30.688 (30.688)	mem 40.206
Train: [33][630/750]	BT 0.135 (1.150)	DT 0.002 (1.018)	loss nan (nan)	prob nan (nan)	GS 35.703 (35.703)	mem 40.166
Train: [33][635/750]	BT 0.138 (1.142)	DT 0.002 (1.010)	loss nan (nan)	prob nan (nan)	GS 34.109 (34.109)	mem 40.175
Train: [33][640/750]	BT 0.146 (1.156)	DT 0.001 (1.024)	loss nan (nan)	prob nan (nan)	GS 35.953 (35.953)	mem 40.067
Train: [33][645/750]	BT 0.090 (1.147)	DT 0.001 (1.016)	loss nan (nan)	prob nan (nan)	GS 37.312 (37.312)	mem 40.157
Train: [33][650/750]	BT 9.534 (1.154)	DT 9.453 (1.023)	loss nan (nan)	prob nan (nan)	GS 26.234 (26.234)	mem 40.053
Train: [33][655/750]	BT 0.171 (1.146)	DT 0.002 (1.015)	loss nan (nan)	prob nan (nan)	GS 30.453 (30.453)	mem 40.173
Train: [33][660/750]	BT 0.173 (1.139)	DT 0.002 (1.007)	loss nan (nan)	prob nan (nan)	GS 30.688 (30.688)	mem 40.056
Train: [33][665/750]	BT 0.105 (1.149)	DT 0.002 (1.018)	loss nan (nan)	prob nan (nan)	GS 30.172 (30.172)	mem 40.147
Train: [33][670/750]	BT 0.153 (1.141)	DT 0.009 (1.010)	loss nan (nan)	prob nan (nan)	GS 32.234 (32.234)	mem 40.244
Train: [33][675/750]	BT 0.081 (1.153)	DT 0.001 (1.022)	loss nan (nan)	prob nan (nan)	GS 30.688 (30.688)	mem 40.085
Train: [33][680/750]	BT 0.101 (1.146)	DT 0.003 (1.015)	loss nan (nan)	prob nan (nan)	GS 28.922 (28.922)	mem 40.098
Train: [33][685/750]	BT 0.126 (1.138)	DT 0.002 (1.007)	loss nan (nan)	prob nan (nan)	GS 30.000 (30.000)	mem 40.142
Train: [33][690/750]	BT 0.174 (1.153)	DT 0.001 (1.022)	loss nan (nan)	prob nan (nan)	GS 34.672 (34.672)	mem 40.179
Train: [33][695/750]	BT 0.093 (1.146)	DT 0.001 (1.015)	loss nan (nan)	prob nan (nan)	GS 29.281 (29.281)	mem 40.180
Train: [33][700/750]	BT 0.171 (1.154)	DT 0.002 (1.024)	loss nan (nan)	prob nan (nan)	GS 36.453 (36.453)	mem 40.207
Train: [33][705/750]	BT 0.218 (1.147)	DT 0.017 (1.017)	loss nan (nan)	prob nan (nan)	GS 31.844 (31.844)	mem 40.226
arpack error, retry= 0
Train: [33][710/750]	BT 13.531 (1.159)	DT 13.459 (1.028)	loss nan (nan)	prob nan (nan)	GS 36.438 (36.438)	mem 40.164
Train: [33][715/750]	BT 0.082 (1.152)	DT 0.001 (1.021)	loss nan (nan)	prob nan (nan)	GS 33.938 (33.938)	mem 40.268
Train: [33][720/750]	BT 0.139 (1.144)	DT 0.002 (1.014)	loss nan (nan)	prob nan (nan)	GS 36.781 (36.781)	mem 40.139
Train: [33][725/750]	BT 0.117 (1.155)	DT 0.002 (1.025)	loss nan (nan)	prob nan (nan)	GS 28.625 (28.625)	mem 39.976
Train: [33][730/750]	BT 0.131 (1.148)	DT 0.014 (1.018)	loss nan (nan)	prob nan (nan)	GS 33.656 (33.656)	mem 40.004
Train: [33][735/750]	BT 0.074 (1.154)	DT 0.001 (1.024)	loss nan (nan)	prob nan (nan)	GS 30.469 (30.469)	mem 36.282
Train: [33][740/750]	BT 0.068 (1.147)	DT 0.008 (1.017)	loss nan (nan)	prob nan (nan)	GS 32.969 (32.969)	mem 36.324
Train: [33][745/750]	BT 0.089 (1.140)	DT 0.001 (1.010)	loss nan (nan)	prob nan (nan)	GS 27.312 (27.312)	mem 36.331
Train: [33][750/750]	BT 0.068 (1.135)	DT 0.001 (1.006)	loss nan (nan)	prob nan (nan)	GS 40.781 (40.781)	mem 7.623
Train: [33][755/750]	BT 0.066 (1.128)	DT 0.001 (1.000)	loss nan (nan)	prob nan (nan)	GS 35.875 (35.875)	mem 7.624
epoch 33, total time 852.12
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [34][1/750]	BT 21.791 (21.791)	DT 21.676 (21.676)	loss nan (nan)	prob nan (nan)	GS 28.875 (28.875)	mem 38.719
Train: [34][5/750]	BT 0.192 (4.957)	DT 0.002 (4.762)	loss nan (nan)	prob nan (nan)	GS 31.453 (31.453)	mem 38.628
Train: [34][10/750]	BT 2.282 (2.804)	DT 2.158 (2.630)	loss nan (nan)	prob nan (nan)	GS 32.031 (32.031)	mem 38.697
Train: [34][15/750]	BT 0.215 (2.219)	DT 0.006 (2.045)	loss nan (nan)	prob nan (nan)	GS 31.484 (31.484)	mem 39.019
Train: [34][20/750]	BT 1.949 (1.926)	DT 1.783 (1.758)	loss nan (nan)	prob nan (nan)	GS 36.703 (36.703)	mem 38.873
Train: [34][25/750]	BT 1.265 (1.819)	DT 1.091 (1.652)	loss nan (nan)	prob nan (nan)	GS 31.750 (31.750)	mem 39.016
Train: [34][30/750]	BT 4.598 (1.761)	DT 4.369 (1.600)	loss nan (nan)	prob nan (nan)	GS 36.781 (36.781)	mem 38.982
Train: [34][35/750]	BT 0.102 (1.526)	DT 0.001 (1.373)	loss nan (nan)	prob nan (nan)	GS 31.062 (31.062)	mem 39.031
Train: [34][40/750]	BT 4.516 (1.652)	DT 4.418 (1.504)	loss nan (nan)	prob nan (nan)	GS 36.938 (36.938)	mem 38.984
Train: [34][45/750]	BT 0.130 (1.487)	DT 0.001 (1.337)	loss nan (nan)	prob nan (nan)	GS 32.141 (32.141)	mem 39.182
Train: [34][50/750]	BT 0.145 (1.514)	DT 0.001 (1.364)	loss nan (nan)	prob nan (nan)	GS 34.094 (34.094)	mem 39.095
Train: [34][55/750]	BT 0.110 (1.461)	DT 0.002 (1.312)	loss nan (nan)	prob nan (nan)	GS 30.641 (30.641)	mem 39.072
Train: [34][60/750]	BT 0.249 (1.445)	DT 0.008 (1.296)	loss nan (nan)	prob nan (nan)	GS 33.312 (33.312)	mem 39.177
Train: [34][65/750]	BT 0.266 (1.457)	DT 0.003 (1.308)	loss nan (nan)	prob nan (nan)	GS 31.359 (31.359)	mem 39.202
Train: [34][70/750]	BT 3.110 (1.408)	DT 2.889 (1.257)	loss nan (nan)	prob nan (nan)	GS 34.359 (34.359)	mem 39.016
Train: [34][75/750]	BT 0.111 (1.323)	DT 0.001 (1.174)	loss nan (nan)	prob nan (nan)	GS 31.344 (31.344)	mem 39.033
Train: [34][80/750]	BT 0.184 (1.328)	DT 0.026 (1.177)	loss nan (nan)	prob nan (nan)	GS 34.828 (34.828)	mem 39.179
Train: [34][85/750]	BT 0.098 (1.300)	DT 0.017 (1.152)	loss nan (nan)	prob nan (nan)	GS 33.359 (33.359)	mem 39.129
Train: [34][90/750]	BT 0.158 (1.306)	DT 0.055 (1.157)	loss nan (nan)	prob nan (nan)	GS 35.469 (35.469)	mem 39.281
Train: [34][95/750]	BT 0.137 (1.295)	DT 0.009 (1.147)	loss nan (nan)	prob nan (nan)	GS 29.812 (29.812)	mem 39.127
Train: [34][100/750]	BT 2.425 (1.323)	DT 2.182 (1.172)	loss nan (nan)	prob nan (nan)	GS 34.984 (34.984)	mem 39.108
Train: [34][105/750]	BT 0.102 (1.264)	DT 0.001 (1.116)	loss nan (nan)	prob nan (nan)	GS 34.625 (34.625)	mem 39.161
Train: [34][110/750]	BT 4.203 (1.295)	DT 4.088 (1.145)	loss nan (nan)	prob nan (nan)	GS 33.984 (33.984)	mem 39.147
Train: [34][115/750]	BT 0.221 (1.269)	DT 0.026 (1.120)	loss nan (nan)	prob nan (nan)	GS 34.203 (34.203)	mem 39.158
Train: [34][120/750]	BT 0.147 (1.294)	DT 0.001 (1.147)	loss nan (nan)	prob nan (nan)	GS 34.703 (34.703)	mem 39.250
Train: [34][125/750]	BT 0.124 (1.263)	DT 0.001 (1.117)	loss nan (nan)	prob nan (nan)	GS 29.953 (29.953)	mem 39.165
Train: [34][130/750]	BT 6.341 (1.268)	DT 6.120 (1.121)	loss nan (nan)	prob nan (nan)	GS 32.859 (32.859)	mem 39.355
Train: [34][135/750]	BT 0.147 (1.269)	DT 0.004 (1.123)	loss nan (nan)	prob nan (nan)	GS 32.781 (32.781)	mem 39.307
Train: [34][140/750]	BT 0.108 (1.229)	DT 0.002 (1.083)	loss nan (nan)	prob nan (nan)	GS 35.094 (35.094)	mem 39.212
Train: [34][145/750]	BT 0.156 (1.212)	DT 0.007 (1.066)	loss nan (nan)	prob nan (nan)	GS 32.297 (32.297)	mem 39.226
Train: [34][150/750]	BT 0.190 (1.242)	DT 0.002 (1.095)	loss nan (nan)	prob nan (nan)	GS 32.266 (32.266)	mem 39.284
Train: [34][155/750]	BT 0.081 (1.246)	DT 0.004 (1.101)	loss nan (nan)	prob nan (nan)	GS 28.875 (28.875)	mem 39.342
Train: [34][160/750]	BT 0.149 (1.236)	DT 0.002 (1.091)	loss nan (nan)	prob nan (nan)	GS 35.328 (35.328)	mem 39.359
Train: [34][165/750]	BT 0.091 (1.202)	DT 0.002 (1.059)	loss nan (nan)	prob nan (nan)	GS 33.406 (33.406)	mem 39.418
Train: [34][170/750]	BT 3.707 (1.253)	DT 3.625 (1.110)	loss nan (nan)	prob nan (nan)	GS 35.859 (35.859)	mem 39.516
Train: [34][175/750]	BT 0.175 (1.221)	DT 0.007 (1.078)	loss nan (nan)	prob nan (nan)	GS 36.938 (36.938)	mem 39.575
Train: [34][180/750]	BT 0.086 (1.232)	DT 0.002 (1.087)	loss nan (nan)	prob nan (nan)	GS 32.125 (32.125)	mem 39.587
Train: [34][185/750]	BT 0.064 (1.228)	DT 0.001 (1.085)	loss nan (nan)	prob nan (nan)	GS 30.719 (30.719)	mem 39.525
Train: [34][190/750]	BT 7.128 (1.237)	DT 7.002 (1.094)	loss nan (nan)	prob nan (nan)	GS 36.312 (36.312)	mem 39.626
Train: [34][195/750]	BT 0.179 (1.223)	DT 0.023 (1.079)	loss nan (nan)	prob nan (nan)	GS 32.016 (32.016)	mem 39.503
Train: [34][200/750]	BT 0.075 (1.195)	DT 0.002 (1.052)	loss nan (nan)	prob nan (nan)	GS 31.328 (31.328)	mem 39.516
Train: [34][205/750]	BT 0.172 (1.216)	DT 0.001 (1.073)	loss nan (nan)	prob nan (nan)	GS 31.984 (31.984)	mem 39.586
Train: [34][210/750]	BT 0.099 (1.205)	DT 0.001 (1.063)	loss nan (nan)	prob nan (nan)	GS 36.828 (36.828)	mem 39.705
Train: [34][215/750]	BT 0.130 (1.218)	DT 0.008 (1.077)	loss nan (nan)	prob nan (nan)	GS 30.688 (30.688)	mem 39.563
Train: [34][220/750]	BT 0.165 (1.216)	DT 0.003 (1.074)	loss nan (nan)	prob nan (nan)	GS 37.516 (37.516)	mem 39.718
Train: [34][225/750]	BT 0.168 (1.192)	DT 0.024 (1.051)	loss nan (nan)	prob nan (nan)	GS 35.859 (35.859)	mem 39.603
Train: [34][230/750]	BT 11.883 (1.233)	DT 11.653 (1.090)	loss nan (nan)	prob nan (nan)	GS 36.938 (36.938)	mem 40.324
Train: [34][235/750]	BT 0.100 (1.209)	DT 0.001 (1.067)	loss nan (nan)	prob nan (nan)	GS 31.266 (31.266)	mem 39.915
Train: [34][240/750]	BT 0.165 (1.187)	DT 0.015 (1.045)	loss nan (nan)	prob nan (nan)	GS 35.422 (35.422)	mem 39.782
Train: [34][245/750]	BT 0.063 (1.217)	DT 0.001 (1.076)	loss nan (nan)	prob nan (nan)	GS 28.109 (28.109)	mem 39.804
Train: [34][250/750]	BT 0.094 (1.195)	DT 0.010 (1.054)	loss nan (nan)	prob nan (nan)	GS 29.531 (29.531)	mem 39.809
Train: [34][255/750]	BT 0.140 (1.206)	DT 0.007 (1.065)	loss nan (nan)	prob nan (nan)	GS 31.562 (31.562)	mem 39.921
Train: [34][260/750]	BT 0.105 (1.186)	DT 0.005 (1.045)	loss nan (nan)	prob nan (nan)	GS 37.641 (37.641)	mem 39.971
Train: [34][265/750]	BT 0.099 (1.170)	DT 0.002 (1.030)	loss nan (nan)	prob nan (nan)	GS 33.891 (33.891)	mem 39.992
Train: [34][270/750]	BT 0.105 (1.190)	DT 0.002 (1.050)	loss nan (nan)	prob nan (nan)	GS 32.000 (32.000)	mem 39.971
Train: [34][275/750]	BT 0.105 (1.195)	DT 0.014 (1.054)	loss nan (nan)	prob nan (nan)	GS 28.500 (28.500)	mem 39.979
Train: [34][280/750]	BT 0.210 (1.191)	DT 0.002 (1.051)	loss nan (nan)	prob nan (nan)	GS 35.016 (35.016)	mem 40.167
Train: [34][285/750]	BT 0.187 (1.173)	DT 0.016 (1.032)	loss nan (nan)	prob nan (nan)	GS 31.797 (31.797)	mem 39.935
Train: [34][290/750]	BT 3.645 (1.200)	DT 3.549 (1.060)	loss nan (nan)	prob nan (nan)	GS 36.000 (36.000)	mem 39.901
Train: [34][295/750]	BT 0.212 (1.182)	DT 0.020 (1.042)	loss nan (nan)	prob nan (nan)	GS 29.078 (29.078)	mem 39.904
Train: [34][300/750]	BT 0.100 (1.189)	DT 0.001 (1.049)	loss nan (nan)	prob nan (nan)	GS 35.656 (35.656)	mem 40.157
Train: [34][305/750]	BT 0.146 (1.182)	DT 0.001 (1.042)	loss nan (nan)	prob nan (nan)	GS 36.359 (36.359)	mem 39.924
Train: [34][310/750]	BT 9.678 (1.196)	DT 9.591 (1.056)	loss nan (nan)	prob nan (nan)	GS 37.094 (37.094)	mem 39.890
Train: [34][315/750]	BT 0.093 (1.180)	DT 0.002 (1.040)	loss nan (nan)	prob nan (nan)	GS 36.203 (36.203)	mem 39.894
Train: [34][320/750]	BT 0.776 (1.170)	DT 0.550 (1.030)	loss nan (nan)	prob nan (nan)	GS 35.062 (35.062)	mem 40.064
Train: [34][325/750]	BT 0.198 (1.186)	DT 0.002 (1.046)	loss nan (nan)	prob nan (nan)	GS 32.203 (32.203)	mem 39.991
Train: [34][330/750]	BT 0.625 (1.174)	DT 0.425 (1.034)	loss nan (nan)	prob nan (nan)	GS 31.578 (31.578)	mem 40.056
Train: [34][335/750]	BT 0.088 (1.191)	DT 0.001 (1.051)	loss nan (nan)	prob nan (nan)	GS 31.766 (31.766)	mem 40.015
Train: [34][340/750]	BT 0.105 (1.176)	DT 0.001 (1.036)	loss nan (nan)	prob nan (nan)	GS 36.141 (36.141)	mem 39.918
Train: [34][345/750]	BT 0.178 (1.166)	DT 0.001 (1.026)	loss nan (nan)	prob nan (nan)	GS 32.344 (32.344)	mem 40.051
Train: [34][350/750]	BT 0.174 (1.185)	DT 0.002 (1.045)	loss nan (nan)	prob nan (nan)	GS 34.031 (34.031)	mem 39.901
Train: [34][355/750]	BT 0.247 (1.171)	DT 0.044 (1.031)	loss nan (nan)	prob nan (nan)	GS 29.531 (29.531)	mem 40.094
Train: [34][360/750]	BT 0.206 (1.183)	DT 0.011 (1.043)	loss nan (nan)	prob nan (nan)	GS 31.141 (31.141)	mem 39.964
Train: [34][365/750]	BT 0.228 (1.169)	DT 0.009 (1.029)	loss nan (nan)	prob nan (nan)	GS 31.188 (31.188)	mem 40.002
Train: [34][370/750]	BT 6.034 (1.191)	DT 5.944 (1.049)	loss nan (nan)	prob nan (nan)	GS 30.703 (30.703)	mem 40.009
Train: [34][375/750]	BT 0.188 (1.178)	DT 0.002 (1.037)	loss nan (nan)	prob nan (nan)	GS 29.734 (29.734)	mem 40.008
Train: [34][380/750]	BT 12.314 (1.196)	DT 12.193 (1.055)	loss nan (nan)	prob nan (nan)	GS 36.203 (36.203)	mem 39.912
Train: [34][385/750]	BT 0.113 (1.182)	DT 0.001 (1.042)	loss nan (nan)	prob nan (nan)	GS 30.594 (30.594)	mem 39.914
Train: [34][390/750]	BT 0.087 (1.169)	DT 0.003 (1.028)	loss nan (nan)	prob nan (nan)	GS 33.922 (33.922)	mem 39.998
Train: [34][395/750]	BT 0.109 (1.187)	DT 0.007 (1.047)	loss nan (nan)	prob nan (nan)	GS 28.234 (28.234)	mem 39.885
Train: [34][400/750]	BT 0.144 (1.173)	DT 0.011 (1.034)	loss nan (nan)	prob nan (nan)	GS 34.547 (34.547)	mem 39.899
Train: [34][405/750]	BT 0.149 (1.188)	DT 0.003 (1.049)	loss nan (nan)	prob nan (nan)	GS 27.938 (27.938)	mem 39.974
Train: [34][410/750]	BT 0.137 (1.175)	DT 0.015 (1.037)	loss nan (nan)	prob nan (nan)	GS 37.906 (37.906)	mem 40.023
Train: [34][415/750]	BT 0.306 (1.163)	DT 0.002 (1.024)	loss nan (nan)	prob nan (nan)	GS 31.078 (31.078)	mem 39.970
Train: [34][420/750]	BT 0.102 (1.179)	DT 0.002 (1.039)	loss nan (nan)	prob nan (nan)	GS 35.938 (35.938)	mem 39.983
Train: [34][425/750]	BT 0.098 (1.167)	DT 0.002 (1.027)	loss nan (nan)	prob nan (nan)	GS 37.359 (37.359)	mem 40.061
Train: [34][430/750]	BT 1.719 (1.180)	DT 1.619 (1.041)	loss nan (nan)	prob nan (nan)	GS 33.828 (33.828)	mem 40.046
Train: [34][435/750]	BT 0.088 (1.173)	DT 0.002 (1.034)	loss nan (nan)	prob nan (nan)	GS 25.734 (25.734)	mem 40.053
Train: [34][440/750]	BT 6.055 (1.175)	DT 5.857 (1.036)	loss nan (nan)	prob nan (nan)	GS 33.484 (33.484)	mem 40.111
Train: [34][445/750]	BT 0.247 (1.172)	DT 0.016 (1.032)	loss nan (nan)	prob nan (nan)	GS 35.625 (35.625)	mem 40.124
Train: [34][450/750]	BT 0.073 (1.167)	DT 0.002 (1.028)	loss nan (nan)	prob nan (nan)	GS 32.578 (32.578)	mem 39.993
Train: [34][455/750]	BT 0.243 (1.173)	DT 0.002 (1.034)	loss nan (nan)	prob nan (nan)	GS 32.953 (32.953)	mem 40.465
Train: [34][460/750]	BT 5.815 (1.176)	DT 5.701 (1.037)	loss nan (nan)	prob nan (nan)	GS 29.578 (29.578)	mem 40.121
Train: [34][465/750]	BT 0.153 (1.168)	DT 0.012 (1.029)	loss nan (nan)	prob nan (nan)	GS 29.484 (29.484)	mem 39.991
Train: [34][470/750]	BT 0.167 (1.164)	DT 0.002 (1.025)	loss nan (nan)	prob nan (nan)	GS 32.859 (32.859)	mem 40.082
Train: [34][475/750]	BT 0.143 (1.165)	DT 0.012 (1.026)	loss nan (nan)	prob nan (nan)	GS 29.234 (29.234)	mem 40.068
Train: [34][480/750]	BT 0.155 (1.165)	DT 0.001 (1.026)	loss nan (nan)	prob nan (nan)	GS 33.000 (33.000)	mem 39.950
Train: [34][485/750]	BT 0.101 (1.167)	DT 0.002 (1.029)	loss nan (nan)	prob nan (nan)	GS 28.656 (28.656)	mem 39.961
Train: [34][490/750]	BT 0.081 (1.166)	DT 0.002 (1.028)	loss nan (nan)	prob nan (nan)	GS 32.203 (32.203)	mem 39.984
Train: [34][495/750]	BT 0.188 (1.165)	DT 0.021 (1.027)	loss nan (nan)	prob nan (nan)	GS 29.422 (29.422)	mem 40.095
Train: [34][500/750]	BT 7.479 (1.171)	DT 7.240 (1.032)	loss nan (nan)	prob nan (nan)	GS 31.125 (31.125)	mem 40.085
Train: [34][505/750]	BT 0.115 (1.160)	DT 0.002 (1.022)	loss nan (nan)	prob nan (nan)	GS 27.031 (27.031)	mem 40.060
Train: [34][510/750]	BT 0.154 (1.159)	DT 0.017 (1.020)	loss nan (nan)	prob nan (nan)	GS 33.047 (33.047)	mem 40.001
Train: [34][515/750]	BT 0.081 (1.165)	DT 0.001 (1.027)	loss nan (nan)	prob nan (nan)	GS 34.672 (34.672)	mem 40.070
Train: [34][520/750]	BT 0.215 (1.163)	DT 0.017 (1.025)	loss nan (nan)	prob nan (nan)	GS 32.391 (32.391)	mem 40.033
Train: [34][525/750]	BT 0.123 (1.167)	DT 0.002 (1.029)	loss nan (nan)	prob nan (nan)	GS 29.266 (29.266)	mem 40.043
Train: [34][530/750]	BT 4.971 (1.166)	DT 4.895 (1.029)	loss nan (nan)	prob nan (nan)	GS 35.766 (35.766)	mem 39.976
Train: [34][535/750]	BT 0.185 (1.157)	DT 0.002 (1.019)	loss nan (nan)	prob nan (nan)	GS 35.016 (35.016)	mem 39.979
Train: [34][540/750]	BT 0.233 (1.160)	DT 0.022 (1.022)	loss nan (nan)	prob nan (nan)	GS 38.641 (38.641)	mem 40.087
Train: [34][545/750]	BT 0.081 (1.162)	DT 0.001 (1.025)	loss nan (nan)	prob nan (nan)	GS 33.406 (33.406)	mem 39.943
Train: [34][550/750]	BT 0.072 (1.161)	DT 0.001 (1.024)	loss nan (nan)	prob nan (nan)	GS 35.344 (35.344)	mem 39.932
Train: [34][555/750]	BT 0.074 (1.178)	DT 0.001 (1.041)	loss nan (nan)	prob nan (nan)	GS 35.406 (35.406)	mem 39.981
Train: [34][560/750]	BT 0.111 (1.168)	DT 0.002 (1.031)	loss nan (nan)	prob nan (nan)	GS 34.172 (34.172)	mem 40.241
Train: [34][565/750]	BT 0.081 (1.159)	DT 0.001 (1.022)	loss nan (nan)	prob nan (nan)	GS 31.953 (31.953)	mem 39.922
Train: [34][570/750]	BT 0.149 (1.166)	DT 0.002 (1.029)	loss nan (nan)	prob nan (nan)	GS 34.578 (34.578)	mem 40.042
Train: [34][575/750]	BT 0.147 (1.159)	DT 0.006 (1.021)	loss nan (nan)	prob nan (nan)	GS 28.938 (28.938)	mem 40.041
Train: [34][580/750]	BT 0.090 (1.171)	DT 0.002 (1.034)	loss nan (nan)	prob nan (nan)	GS 31.141 (31.141)	mem 39.898
Train: [34][585/750]	BT 0.208 (1.162)	DT 0.011 (1.025)	loss nan (nan)	prob nan (nan)	GS 34.922 (34.922)	mem 40.071
Train: [34][590/750]	BT 11.193 (1.172)	DT 11.111 (1.035)	loss nan (nan)	prob nan (nan)	GS 31.547 (31.547)	mem 39.940
Train: [34][595/750]	BT 0.107 (1.163)	DT 0.002 (1.026)	loss nan (nan)	prob nan (nan)	GS 29.109 (29.109)	mem 39.939
Train: [34][600/750]	BT 0.247 (1.161)	DT 0.010 (1.024)	loss nan (nan)	prob nan (nan)	GS 32.891 (32.891)	mem 40.107
Train: [34][605/750]	BT 0.107 (1.168)	DT 0.002 (1.031)	loss nan (nan)	prob nan (nan)	GS 31.031 (31.031)	mem 40.168
Train: [34][610/750]	BT 0.166 (1.162)	DT 0.004 (1.026)	loss nan (nan)	prob nan (nan)	GS 33.219 (33.219)	mem 40.139
Train: [34][615/750]	BT 0.128 (1.171)	DT 0.007 (1.034)	loss nan (nan)	prob nan (nan)	GS 30.531 (30.531)	mem 40.260
Train: [34][620/750]	BT 0.129 (1.162)	DT 0.010 (1.026)	loss nan (nan)	prob nan (nan)	GS 36.266 (36.266)	mem 40.095
Train: [34][625/750]	BT 0.197 (1.154)	DT 0.002 (1.018)	loss nan (nan)	prob nan (nan)	GS 30.328 (30.328)	mem 40.154
Train: [34][630/750]	BT 3.152 (1.165)	DT 3.085 (1.029)	loss nan (nan)	prob nan (nan)	GS 31.875 (31.875)	mem 39.965
Train: [34][635/750]	BT 0.099 (1.157)	DT 0.009 (1.021)	loss nan (nan)	prob nan (nan)	GS 31.625 (31.625)	mem 40.115
Train: [34][640/750]	BT 0.074 (1.166)	DT 0.001 (1.029)	loss nan (nan)	prob nan (nan)	GS 32.781 (32.781)	mem 40.374
Train: [34][645/750]	BT 0.205 (1.162)	DT 0.002 (1.025)	loss nan (nan)	prob nan (nan)	GS 33.453 (33.453)	mem 40.031
Train: [34][650/750]	BT 10.623 (1.170)	DT 10.460 (1.033)	loss nan (nan)	prob nan (nan)	GS 33.781 (33.781)	mem 40.043
Train: [34][655/750]	BT 0.119 (1.162)	DT 0.002 (1.026)	loss nan (nan)	prob nan (nan)	GS 29.500 (29.500)	mem 40.007
Train: [34][660/750]	BT 0.133 (1.160)	DT 0.010 (1.024)	loss nan (nan)	prob nan (nan)	GS 32.250 (32.250)	mem 39.874
Train: [34][665/750]	BT 0.139 (1.160)	DT 0.002 (1.024)	loss nan (nan)	prob nan (nan)	GS 27.828 (27.828)	mem 39.992
Train: [34][670/750]	BT 6.058 (1.162)	DT 5.922 (1.026)	loss nan (nan)	prob nan (nan)	GS 32.156 (32.156)	mem 40.178
Train: [34][675/750]	BT 0.129 (1.159)	DT 0.001 (1.022)	loss nan (nan)	prob nan (nan)	GS 26.438 (26.438)	mem 39.934
Train: [34][680/750]	BT 0.216 (1.158)	DT 0.002 (1.022)	loss nan (nan)	prob nan (nan)	GS 30.469 (30.469)	mem 40.005
Train: [34][685/750]	BT 0.116 (1.154)	DT 0.009 (1.018)	loss nan (nan)	prob nan (nan)	GS 30.500 (30.500)	mem 40.019
Train: [34][690/750]	BT 4.837 (1.160)	DT 4.705 (1.024)	loss nan (nan)	prob nan (nan)	GS 31.469 (31.469)	mem 40.007
Train: [34][695/750]	BT 0.087 (1.153)	DT 0.001 (1.017)	loss nan (nan)	prob nan (nan)	GS 29.734 (29.734)	mem 40.008
Train: [34][700/750]	BT 0.123 (1.154)	DT 0.002 (1.018)	loss nan (nan)	prob nan (nan)	GS 34.641 (34.641)	mem 40.023
Train: [34][705/750]	BT 0.124 (1.157)	DT 0.022 (1.021)	loss nan (nan)	prob nan (nan)	GS 27.875 (27.875)	mem 39.941
Train: [34][710/750]	BT 4.512 (1.158)	DT 4.405 (1.022)	loss nan (nan)	prob nan (nan)	GS 34.828 (34.828)	mem 40.014
Train: [34][715/750]	BT 0.070 (1.159)	DT 0.001 (1.023)	loss nan (nan)	prob nan (nan)	GS 34.188 (34.188)	mem 40.069
Train: [34][720/750]	BT 0.156 (1.157)	DT 0.009 (1.021)	loss nan (nan)	prob nan (nan)	GS 31.188 (31.188)	mem 40.016
Train: [34][725/750]	BT 0.097 (1.157)	DT 0.002 (1.021)	loss nan (nan)	prob nan (nan)	GS 28.875 (28.875)	mem 39.890
Train: [34][730/750]	BT 1.150 (1.157)	DT 1.047 (1.021)	loss nan (nan)	prob nan (nan)	GS 34.391 (34.391)	mem 39.883
Train: [34][735/750]	BT 0.078 (1.155)	DT 0.001 (1.020)	loss nan (nan)	prob nan (nan)	GS 32.047 (32.047)	mem 36.806
Train: [34][740/750]	BT 0.560 (1.152)	DT 0.450 (1.017)	loss nan (nan)	prob nan (nan)	GS 29.453 (29.453)	mem 16.597
Train: [34][745/750]	BT 0.075 (1.146)	DT 0.001 (1.011)	loss nan (nan)	prob nan (nan)	GS 32.344 (32.344)	mem 16.608
Train: [34][750/750]	BT 2.313 (1.141)	DT 2.241 (1.007)	loss nan (nan)	prob nan (nan)	GS 37.469 (37.469)	mem 7.703
Train: [34][755/750]	BT 0.088 (1.134)	DT 0.001 (1.001)	loss nan (nan)	prob nan (nan)	GS 34.781 (34.781)	mem 7.702
epoch 34, total time 856.79
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [35][1/750]	BT 20.071 (20.071)	DT 19.897 (19.897)	loss nan (nan)	prob nan (nan)	GS 30.812 (30.812)	mem 38.516
Train: [35][5/750]	BT 0.121 (5.512)	DT 0.002 (5.353)	loss nan (nan)	prob nan (nan)	GS 30.719 (30.719)	mem 38.680
Train: [35][10/750]	BT 0.130 (2.818)	DT 0.002 (2.678)	loss nan (nan)	prob nan (nan)	GS 38.547 (38.547)	mem 38.878
Train: [35][15/750]	BT 4.443 (2.677)	DT 4.190 (2.522)	loss nan (nan)	prob nan (nan)	GS 30.516 (30.516)	mem 38.928
Train: [35][20/750]	BT 0.134 (2.043)	DT 0.007 (1.893)	loss nan (nan)	prob nan (nan)	GS 32.453 (32.453)	mem 39.072
Train: [35][25/750]	BT 0.076 (1.767)	DT 0.002 (1.621)	loss nan (nan)	prob nan (nan)	GS 30.719 (30.719)	mem 38.996
Train: [35][30/750]	BT 0.141 (1.736)	DT 0.001 (1.588)	loss nan (nan)	prob nan (nan)	GS 33.469 (33.469)	mem 38.888
Train: [35][35/750]	BT 0.103 (1.680)	DT 0.002 (1.531)	loss nan (nan)	prob nan (nan)	GS 30.656 (30.656)	mem 39.048
Train: [35][40/750]	BT 0.221 (1.667)	DT 0.006 (1.515)	loss nan (nan)	prob nan (nan)	GS 26.500 (26.500)	mem 39.117
Train: [35][45/750]	BT 0.223 (1.502)	DT 0.013 (1.348)	loss nan (nan)	prob nan (nan)	GS 27.281 (27.281)	mem 39.113
Train: [35][50/750]	BT 3.210 (1.615)	DT 3.053 (1.465)	loss nan (nan)	prob nan (nan)	GS 33.312 (33.312)	mem 39.133
Train: [35][55/750]	BT 0.274 (1.483)	DT 0.001 (1.332)	loss nan (nan)	prob nan (nan)	GS 31.266 (31.266)	mem 39.165
Train: [35][60/750]	BT 0.183 (1.537)	DT 0.002 (1.388)	loss nan (nan)	prob nan (nan)	GS 33.547 (33.547)	mem 39.224
Train: [35][65/750]	BT 0.243 (1.490)	DT 0.063 (1.343)	loss nan (nan)	prob nan (nan)	GS 36.016 (36.016)	mem 39.567
Train: [35][70/750]	BT 9.338 (1.526)	DT 9.264 (1.379)	loss nan (nan)	prob nan (nan)	GS 33.844 (33.844)	mem 39.231
Train: [35][75/750]	BT 0.186 (1.478)	DT 0.002 (1.333)	loss nan (nan)	prob nan (nan)	GS 35.953 (35.953)	mem 39.133
Train: [35][80/750]	BT 0.080 (1.394)	DT 0.002 (1.250)	loss nan (nan)	prob nan (nan)	GS 33.906 (33.906)	mem 39.220
Train: [35][85/750]	BT 0.158 (1.429)	DT 0.006 (1.286)	loss nan (nan)	prob nan (nan)	GS 28.891 (28.891)	mem 39.226
Train: [35][90/750]	BT 0.186 (1.385)	DT 0.002 (1.243)	loss nan (nan)	prob nan (nan)	GS 33.969 (33.969)	mem 39.232
Train: [35][95/750]	BT 0.133 (1.402)	DT 0.007 (1.259)	loss nan (nan)	prob nan (nan)	GS 36.234 (36.234)	mem 39.321
Train: [35][100/750]	BT 0.116 (1.391)	DT 0.002 (1.249)	loss nan (nan)	prob nan (nan)	GS 38.203 (38.203)	mem 39.563
Train: [35][105/750]	BT 0.134 (1.332)	DT 0.001 (1.190)	loss nan (nan)	prob nan (nan)	GS 32.672 (32.672)	mem 39.569
Train: [35][110/750]	BT 1.764 (1.363)	DT 1.537 (1.220)	loss nan (nan)	prob nan (nan)	GS 29.891 (29.891)	mem 39.519
Train: [35][115/750]	BT 0.097 (1.309)	DT 0.002 (1.167)	loss nan (nan)	prob nan (nan)	GS 38.156 (38.156)	mem 39.564
Train: [35][120/750]	BT 0.158 (1.344)	DT 0.013 (1.201)	loss nan (nan)	prob nan (nan)	GS 31.109 (31.109)	mem 39.647
Train: [35][125/750]	BT 0.090 (1.316)	DT 0.002 (1.175)	loss nan (nan)	prob nan (nan)	GS 30.641 (30.641)	mem 39.618
Train: [35][130/750]	BT 8.963 (1.338)	DT 8.866 (1.198)	loss nan (nan)	prob nan (nan)	GS 34.703 (34.703)	mem 40.128
Train: [35][135/750]	BT 0.088 (1.317)	DT 0.002 (1.178)	loss nan (nan)	prob nan (nan)	GS 32.688 (32.688)	mem 40.046
Train: [35][140/750]	BT 0.114 (1.288)	DT 0.013 (1.149)	loss nan (nan)	prob nan (nan)	GS 38.141 (38.141)	mem 39.823
Train: [35][145/750]	BT 0.163 (1.307)	DT 0.002 (1.169)	loss nan (nan)	prob nan (nan)	GS 33.938 (33.938)	mem 40.040
Train: [35][150/750]	BT 0.159 (1.286)	DT 0.003 (1.148)	loss nan (nan)	prob nan (nan)	GS 34.188 (34.188)	mem 39.842
Train: [35][155/750]	BT 0.241 (1.302)	DT 0.005 (1.163)	loss nan (nan)	prob nan (nan)	GS 31.625 (31.625)	mem 39.965
Train: [35][160/750]	BT 0.141 (1.291)	DT 0.002 (1.152)	loss nan (nan)	prob nan (nan)	GS 32.141 (32.141)	mem 39.947
Train: [35][165/750]	BT 0.168 (1.255)	DT 0.030 (1.118)	loss nan (nan)	prob nan (nan)	GS 38.297 (38.297)	mem 39.837
Train: [35][170/750]	BT 6.433 (1.293)	DT 6.342 (1.156)	loss nan (nan)	prob nan (nan)	GS 31.344 (31.344)	mem 39.857
Train: [35][175/750]	BT 0.197 (1.265)	DT 0.006 (1.127)	loss nan (nan)	prob nan (nan)	GS 36.109 (36.109)	mem 39.754
Train: [35][180/750]	BT 0.161 (1.255)	DT 0.005 (1.117)	loss nan (nan)	prob nan (nan)	GS 33.203 (33.203)	mem 40.028
Train: [35][185/750]	BT 0.119 (1.261)	DT 0.005 (1.124)	loss nan (nan)	prob nan (nan)	GS 31.234 (31.234)	mem 39.835
Train: [35][190/750]	BT 7.800 (1.272)	DT 7.662 (1.135)	loss nan (nan)	prob nan (nan)	GS 36.844 (36.844)	mem 39.919
Train: [35][195/750]	BT 0.070 (1.267)	DT 0.001 (1.130)	loss nan (nan)	prob nan (nan)	GS 28.328 (28.328)	mem 39.904
Train: [35][200/750]	BT 0.547 (1.241)	DT 0.463 (1.104)	loss nan (nan)	prob nan (nan)	GS 36.531 (36.531)	mem 39.848
Train: [35][205/750]	BT 0.134 (1.244)	DT 0.002 (1.107)	loss nan (nan)	prob nan (nan)	GS 30.797 (30.797)	mem 39.903
Train: [35][210/750]	BT 0.121 (1.247)	DT 0.002 (1.110)	loss nan (nan)	prob nan (nan)	GS 33.562 (33.562)	mem 39.904
Train: [35][215/750]	BT 0.270 (1.252)	DT 0.012 (1.114)	loss nan (nan)	prob nan (nan)	GS 35.938 (35.938)	mem 39.838
Train: [35][220/750]	BT 0.158 (1.250)	DT 0.001 (1.113)	loss nan (nan)	prob nan (nan)	GS 37.078 (37.078)	mem 39.859
Train: [35][225/750]	BT 0.194 (1.225)	DT 0.002 (1.088)	loss nan (nan)	prob nan (nan)	GS 46.062 (46.062)	mem 39.861
Train: [35][230/750]	BT 8.761 (1.259)	DT 8.616 (1.122)	loss nan (nan)	prob nan (nan)	GS 29.766 (29.766)	mem 39.857
Train: [35][235/750]	BT 0.108 (1.235)	DT 0.005 (1.098)	loss nan (nan)	prob nan (nan)	GS 28.062 (28.062)	mem 39.924
Train: [35][240/750]	BT 0.227 (1.212)	DT 0.031 (1.076)	loss nan (nan)	prob nan (nan)	GS 35.203 (35.203)	mem 39.868
Train: [35][245/750]	BT 0.138 (1.240)	DT 0.002 (1.103)	loss nan (nan)	prob nan (nan)	GS 32.812 (32.812)	mem 39.928
Train: [35][250/750]	BT 0.414 (1.219)	DT 0.282 (1.082)	loss nan (nan)	prob nan (nan)	GS 34.641 (34.641)	mem 39.947
Train: [35][255/750]	BT 0.098 (1.242)	DT 0.002 (1.106)	loss nan (nan)	prob nan (nan)	GS 34.797 (34.797)	mem 40.078
Train: [35][260/750]	BT 0.132 (1.221)	DT 0.021 (1.085)	loss nan (nan)	prob nan (nan)	GS 32.031 (32.031)	mem 39.841
Train: [35][265/750]	BT 0.124 (1.201)	DT 0.001 (1.066)	loss nan (nan)	prob nan (nan)	GS 28.344 (28.344)	mem 39.972
Train: [35][270/750]	BT 0.086 (1.226)	DT 0.001 (1.091)	loss nan (nan)	prob nan (nan)	GS 33.406 (33.406)	mem 39.939
Train: [35][275/750]	BT 0.135 (1.206)	DT 0.002 (1.071)	loss nan (nan)	prob nan (nan)	GS 30.594 (30.594)	mem 39.863
Train: [35][280/750]	BT 0.132 (1.230)	DT 0.001 (1.095)	loss nan (nan)	prob nan (nan)	GS 36.281 (36.281)	mem 40.058
Train: [35][285/750]	BT 0.110 (1.210)	DT 0.012 (1.076)	loss nan (nan)	prob nan (nan)	GS 32.094 (32.094)	mem 40.206
Train: [35][290/750]	BT 7.471 (1.231)	DT 7.277 (1.097)	loss nan (nan)	prob nan (nan)	GS 31.281 (31.281)	mem 40.054
Train: [35][295/750]	BT 0.145 (1.212)	DT 0.009 (1.078)	loss nan (nan)	prob nan (nan)	GS 34.578 (34.578)	mem 40.063
Train: [35][300/750]	BT 7.898 (1.221)	DT 7.724 (1.087)	loss nan (nan)	prob nan (nan)	GS 35.859 (35.859)	mem 39.875
Train: [35][305/750]	BT 0.147 (1.216)	DT 0.010 (1.082)	loss nan (nan)	prob nan (nan)	GS 32.969 (32.969)	mem 39.904
Train: [35][310/750]	BT 0.131 (1.203)	DT 0.005 (1.070)	loss nan (nan)	prob nan (nan)	GS 34.703 (34.703)	mem 39.870
Train: [35][315/750]	BT 0.098 (1.225)	DT 0.002 (1.091)	loss nan (nan)	prob nan (nan)	GS 29.812 (29.812)	mem 39.840
Train: [35][320/750]	BT 0.243 (1.209)	DT 0.076 (1.075)	loss nan (nan)	prob nan (nan)	GS 33.734 (33.734)	mem 39.792
Train: [35][325/750]	BT 0.094 (1.201)	DT 0.003 (1.067)	loss nan (nan)	prob nan (nan)	GS 32.500 (32.500)	mem 39.933
Train: [35][330/750]	BT 0.087 (1.208)	DT 0.002 (1.074)	loss nan (nan)	prob nan (nan)	GS 37.062 (37.062)	mem 39.934
Train: [35][335/750]	BT 0.108 (1.213)	DT 0.002 (1.080)	loss nan (nan)	prob nan (nan)	GS 29.828 (29.828)	mem 40.012
Train: [35][340/750]	BT 0.113 (1.204)	DT 0.008 (1.070)	loss nan (nan)	prob nan (nan)	GS 31.734 (31.734)	mem 39.915
Train: [35][345/750]	BT 0.106 (1.203)	DT 0.001 (1.070)	loss nan (nan)	prob nan (nan)	GS 29.406 (29.406)	mem 39.931
Train: [35][350/750]	BT 4.920 (1.209)	DT 4.827 (1.075)	loss nan (nan)	prob nan (nan)	GS 33.891 (33.891)	mem 39.909
Train: [35][355/750]	BT 0.108 (1.202)	DT 0.003 (1.069)	loss nan (nan)	prob nan (nan)	GS 35.094 (35.094)	mem 39.964
Train: [35][360/750]	BT 0.128 (1.204)	DT 0.001 (1.070)	loss nan (nan)	prob nan (nan)	GS 27.562 (27.562)	mem 39.922
Train: [35][365/750]	BT 0.083 (1.191)	DT 0.002 (1.058)	loss nan (nan)	prob nan (nan)	GS 30.484 (30.484)	mem 39.930
Train: [35][370/750]	BT 2.111 (1.203)	DT 1.966 (1.070)	loss nan (nan)	prob nan (nan)	GS 33.328 (33.328)	mem 40.128
Train: [35][375/750]	BT 0.182 (1.196)	DT 0.002 (1.063)	loss nan (nan)	prob nan (nan)	GS 28.516 (28.516)	mem 40.017
Train: [35][380/750]	BT 0.128 (1.205)	DT 0.010 (1.072)	loss nan (nan)	prob nan (nan)	GS 31.031 (31.031)	mem 40.062
Train: [35][385/750]	BT 0.095 (1.194)	DT 0.010 (1.061)	loss nan (nan)	prob nan (nan)	GS 30.359 (30.359)	mem 39.985
Train: [35][390/750]	BT 8.068 (1.204)	DT 7.969 (1.071)	loss nan (nan)	prob nan (nan)	GS 31.500 (31.500)	mem 39.952
Train: [35][395/750]	BT 0.121 (1.192)	DT 0.002 (1.059)	loss nan (nan)	prob nan (nan)	GS 33.312 (33.312)	mem 40.008
Train: [35][400/750]	BT 0.117 (1.187)	DT 0.005 (1.054)	loss nan (nan)	prob nan (nan)	GS 29.734 (29.734)	mem 39.974
Train: [35][405/750]	BT 0.142 (1.192)	DT 0.001 (1.060)	loss nan (nan)	prob nan (nan)	GS 34.703 (34.703)	mem 40.118
Train: [35][410/750]	BT 1.984 (1.190)	DT 1.879 (1.058)	loss nan (nan)	prob nan (nan)	GS 35.875 (35.875)	mem 39.932
Train: [35][415/750]	BT 0.141 (1.195)	DT 0.002 (1.063)	loss nan (nan)	prob nan (nan)	GS 30.203 (30.203)	mem 39.947
Train: [35][420/750]	BT 3.890 (1.192)	DT 3.796 (1.059)	loss nan (nan)	prob nan (nan)	GS 34.484 (34.484)	mem 39.974
Train: [35][425/750]	BT 0.220 (1.189)	DT 0.005 (1.056)	loss nan (nan)	prob nan (nan)	GS 30.375 (30.375)	mem 39.934
Train: [35][430/750]	BT 0.150 (1.184)	DT 0.002 (1.052)	loss nan (nan)	prob nan (nan)	GS 31.219 (31.219)	mem 39.975
Train: [35][435/750]	BT 0.171 (1.187)	DT 0.002 (1.054)	loss nan (nan)	prob nan (nan)	GS 30.688 (30.688)	mem 40.014
Train: [35][440/750]	BT 0.158 (1.187)	DT 0.002 (1.054)	loss nan (nan)	prob nan (nan)	GS 36.719 (36.719)	mem 40.161
Train: [35][445/750]	BT 0.089 (1.188)	DT 0.002 (1.056)	loss nan (nan)	prob nan (nan)	GS 31.531 (31.531)	mem 39.984
Train: [35][450/750]	BT 4.021 (1.185)	DT 3.934 (1.053)	loss nan (nan)	prob nan (nan)	GS 28.891 (28.891)	mem 40.275
Train: [35][455/750]	BT 0.319 (1.175)	DT 0.012 (1.041)	loss nan (nan)	prob nan (nan)	GS 34.547 (34.547)	mem 40.109
Train: [35][460/750]	BT 0.166 (1.188)	DT 0.010 (1.055)	loss nan (nan)	prob nan (nan)	GS 32.141 (32.141)	mem 40.005
Train: [35][465/750]	BT 0.113 (1.177)	DT 0.026 (1.044)	loss nan (nan)	prob nan (nan)	GS 29.312 (29.312)	mem 40.051
Train: [35][470/750]	BT 0.087 (1.184)	DT 0.013 (1.051)	loss nan (nan)	prob nan (nan)	GS 35.578 (35.578)	mem 40.025
Train: [35][475/750]	BT 0.122 (1.173)	DT 0.003 (1.040)	loss nan (nan)	prob nan (nan)	GS 30.906 (30.906)	mem 40.053
Train: [35][480/750]	BT 2.855 (1.186)	DT 2.753 (1.052)	loss nan (nan)	prob nan (nan)	GS 32.391 (32.391)	mem 40.108
Train: [35][485/750]	BT 0.163 (1.175)	DT 0.001 (1.041)	loss nan (nan)	prob nan (nan)	GS 29.438 (29.438)	mem 40.100
Train: [35][490/750]	BT 5.730 (1.176)	DT 5.640 (1.042)	loss nan (nan)	prob nan (nan)	GS 35.016 (35.016)	mem 40.122
Train: [35][495/750]	BT 0.153 (1.178)	DT 0.002 (1.044)	loss nan (nan)	prob nan (nan)	GS 32.078 (32.078)	mem 39.976
Train: [35][500/750]	BT 0.145 (1.167)	DT 0.001 (1.034)	loss nan (nan)	prob nan (nan)	GS 36.594 (36.594)	mem 39.946
Train: [35][505/750]	BT 0.124 (1.182)	DT 0.002 (1.049)	loss nan (nan)	prob nan (nan)	GS 37.500 (37.500)	mem 40.155
Train: [35][510/750]	BT 0.114 (1.171)	DT 0.008 (1.038)	loss nan (nan)	prob nan (nan)	GS 34.828 (34.828)	mem 40.129
Train: [35][515/750]	BT 0.158 (1.167)	DT 0.029 (1.034)	loss nan (nan)	prob nan (nan)	GS 29.844 (29.844)	mem 40.054
Train: [35][520/750]	BT 0.094 (1.179)	DT 0.004 (1.045)	loss nan (nan)	prob nan (nan)	GS 33.516 (33.516)	mem 40.020
Train: [35][525/750]	BT 0.148 (1.169)	DT 0.004 (1.036)	loss nan (nan)	prob nan (nan)	GS 30.047 (30.047)	mem 40.073
Train: [35][530/750]	BT 0.159 (1.185)	DT 0.001 (1.052)	loss nan (nan)	prob nan (nan)	GS 33.859 (33.859)	mem 39.925
Train: [35][535/750]	BT 0.111 (1.175)	DT 0.028 (1.043)	loss nan (nan)	prob nan (nan)	GS 31.156 (31.156)	mem 39.929
Train: [35][540/750]	BT 10.825 (1.185)	DT 10.740 (1.053)	loss nan (nan)	prob nan (nan)	GS 30.969 (30.969)	mem 40.014
Train: [35][545/750]	BT 0.087 (1.175)	DT 0.002 (1.043)	loss nan (nan)	prob nan (nan)	GS 28.672 (28.672)	mem 40.016
Train: [35][550/750]	BT 0.109 (1.166)	DT 0.013 (1.034)	loss nan (nan)	prob nan (nan)	GS 34.562 (34.562)	mem 40.051
Train: [35][555/750]	BT 0.122 (1.177)	DT 0.002 (1.045)	loss nan (nan)	prob nan (nan)	GS 30.703 (30.703)	mem 39.939
Train: [35][560/750]	BT 0.084 (1.168)	DT 0.007 (1.036)	loss nan (nan)	prob nan (nan)	GS 38.031 (38.031)	mem 39.890
Train: [35][565/750]	BT 0.161 (1.180)	DT 0.002 (1.049)	loss nan (nan)	prob nan (nan)	GS 33.703 (33.703)	mem 39.886
Train: [35][570/750]	BT 0.156 (1.171)	DT 0.001 (1.039)	loss nan (nan)	prob nan (nan)	GS 33.250 (33.250)	mem 40.039
Train: [35][575/750]	BT 0.184 (1.162)	DT 0.002 (1.030)	loss nan (nan)	prob nan (nan)	GS 28.234 (28.234)	mem 40.052
Train: [35][580/750]	BT 0.142 (1.176)	DT 0.001 (1.044)	loss nan (nan)	prob nan (nan)	GS 30.016 (30.016)	mem 39.962
Train: [35][585/750]	BT 0.317 (1.168)	DT 0.016 (1.035)	loss nan (nan)	prob nan (nan)	GS 34.328 (34.328)	mem 39.963
Train: [35][590/750]	BT 0.084 (1.175)	DT 0.001 (1.043)	loss nan (nan)	prob nan (nan)	GS 36.828 (36.828)	mem 39.974
Train: [35][595/750]	BT 0.110 (1.166)	DT 0.001 (1.034)	loss nan (nan)	prob nan (nan)	GS 27.734 (27.734)	mem 40.024
Train: [35][600/750]	BT 9.103 (1.172)	DT 8.958 (1.040)	loss nan (nan)	prob nan (nan)	GS 31.797 (31.797)	mem 40.058
Train: [35][605/750]	BT 0.186 (1.164)	DT 0.002 (1.032)	loss nan (nan)	prob nan (nan)	GS 35.703 (35.703)	mem 40.208
Train: [35][610/750]	BT 0.110 (1.155)	DT 0.002 (1.023)	loss nan (nan)	prob nan (nan)	GS 36.891 (36.891)	mem 40.151
Train: [35][615/750]	BT 0.084 (1.169)	DT 0.002 (1.037)	loss nan (nan)	prob nan (nan)	GS 34.438 (34.438)	mem 40.082
Train: [35][620/750]	BT 0.095 (1.160)	DT 0.001 (1.029)	loss nan (nan)	prob nan (nan)	GS 29.219 (29.219)	mem 40.020
Train: [35][625/750]	BT 0.168 (1.169)	DT 0.002 (1.038)	loss nan (nan)	prob nan (nan)	GS 34.094 (34.094)	mem 40.081
Train: [35][630/750]	BT 0.951 (1.162)	DT 0.801 (1.031)	loss nan (nan)	prob nan (nan)	GS 38.125 (38.125)	mem 40.083
Train: [35][635/750]	BT 0.168 (1.154)	DT 0.014 (1.023)	loss nan (nan)	prob nan (nan)	GS 28.625 (28.625)	mem 40.074
Train: [35][640/750]	BT 0.119 (1.162)	DT 0.001 (1.031)	loss nan (nan)	prob nan (nan)	GS 35.984 (35.984)	mem 40.037
Train: [35][645/750]	BT 0.084 (1.157)	DT 0.006 (1.026)	loss nan (nan)	prob nan (nan)	GS 30.453 (30.453)	mem 40.048
Train: [35][650/750]	BT 0.086 (1.170)	DT 0.011 (1.039)	loss nan (nan)	prob nan (nan)	GS 34.406 (34.406)	mem 40.013
Train: [35][655/750]	BT 0.188 (1.162)	DT 0.010 (1.031)	loss nan (nan)	prob nan (nan)	GS 33.188 (33.188)	mem 40.151
Train: [35][660/750]	BT 12.454 (1.173)	DT 12.374 (1.042)	loss nan (nan)	prob nan (nan)	GS 32.719 (32.719)	mem 40.134
Train: [35][665/750]	BT 0.072 (1.165)	DT 0.001 (1.034)	loss nan (nan)	prob nan (nan)	GS 39.922 (39.922)	mem 39.998
Train: [35][670/750]	BT 0.081 (1.158)	DT 0.001 (1.026)	loss nan (nan)	prob nan (nan)	GS 28.672 (28.672)	mem 39.983
Train: [35][675/750]	BT 0.155 (1.165)	DT 0.008 (1.033)	loss nan (nan)	prob nan (nan)	GS 35.188 (35.188)	mem 40.087
Train: [35][680/750]	BT 0.088 (1.157)	DT 0.001 (1.026)	loss nan (nan)	prob nan (nan)	GS 34.547 (34.547)	mem 40.088
Train: [35][685/750]	BT 0.159 (1.167)	DT 0.001 (1.035)	loss nan (nan)	prob nan (nan)	GS 35.688 (35.688)	mem 40.176
Train: [35][690/750]	BT 3.808 (1.164)	DT 3.734 (1.033)	loss nan (nan)	prob nan (nan)	GS 34.891 (34.891)	mem 40.125
Train: [35][695/750]	BT 0.103 (1.157)	DT 0.016 (1.026)	loss nan (nan)	prob nan (nan)	GS 32.594 (32.594)	mem 40.237
Train: [35][700/750]	BT 0.135 (1.158)	DT 0.003 (1.028)	loss nan (nan)	prob nan (nan)	GS 33.875 (33.875)	mem 40.033
Train: [35][705/750]	BT 0.201 (1.165)	DT 0.022 (1.034)	loss nan (nan)	prob nan (nan)	GS 33.062 (33.062)	mem 40.279
arpack error, retry= 0
Train: [35][710/750]	BT 0.126 (1.163)	DT 0.002 (1.032)	loss nan (nan)	prob nan (nan)	GS 36.297 (36.297)	mem 39.978
Train: [35][715/750]	BT 0.128 (1.167)	DT 0.002 (1.036)	loss nan (nan)	prob nan (nan)	GS 32.797 (32.797)	mem 39.974
Train: [35][720/750]	BT 4.768 (1.167)	DT 4.686 (1.035)	loss nan (nan)	prob nan (nan)	GS 30.188 (30.188)	mem 40.026
Train: [35][725/750]	BT 0.142 (1.160)	DT 0.021 (1.028)	loss nan (nan)	prob nan (nan)	GS 38.969 (38.969)	mem 40.030
Train: [35][730/750]	BT 0.099 (1.159)	DT 0.001 (1.028)	loss nan (nan)	prob nan (nan)	GS 36.562 (36.562)	mem 39.895
Train: [35][735/750]	BT 0.098 (1.159)	DT 0.001 (1.028)	loss nan (nan)	prob nan (nan)	GS 26.547 (26.547)	mem 39.563
Train: [35][740/750]	BT 0.075 (1.158)	DT 0.001 (1.027)	loss nan (nan)	prob nan (nan)	GS 34.469 (34.469)	mem 10.726
Train: [35][745/750]	BT 0.063 (1.153)	DT 0.001 (1.022)	loss nan (nan)	prob nan (nan)	GS 30.594 (30.594)	mem 10.693
Train: [35][750/750]	BT 1.116 (1.147)	DT 1.030 (1.017)	loss nan (nan)	prob nan (nan)	GS 36.438 (36.438)	mem 10.637
Train: [35][755/750]	BT 0.071 (1.140)	DT 0.002 (1.010)	loss nan (nan)	prob nan (nan)	GS 32.344 (32.344)	mem 10.638
epoch 35, total time 862.06
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [36][1/750]	BT 21.650 (21.650)	DT 21.481 (21.481)	loss nan (nan)	prob nan (nan)	GS 32.797 (32.797)	mem 38.696
Train: [36][5/750]	BT 0.216 (5.113)	DT 0.002 (4.909)	loss nan (nan)	prob nan (nan)	GS 33.422 (33.422)	mem 38.763
Train: [36][10/750]	BT 0.100 (2.631)	DT 0.002 (2.458)	loss nan (nan)	prob nan (nan)	GS 30.188 (30.188)	mem 38.785
Train: [36][15/750]	BT 0.207 (2.342)	DT 0.002 (2.180)	loss nan (nan)	prob nan (nan)	GS 28.094 (28.094)	mem 38.979
Train: [36][20/750]	BT 0.102 (2.114)	DT 0.004 (1.965)	loss nan (nan)	prob nan (nan)	GS 32.734 (32.734)	mem 38.915
Train: [36][25/750]	BT 0.952 (1.750)	DT 0.858 (1.608)	loss nan (nan)	prob nan (nan)	GS 27.891 (27.891)	mem 39.102
Train: [36][30/750]	BT 2.273 (1.809)	DT 2.154 (1.669)	loss nan (nan)	prob nan (nan)	GS 33.609 (33.609)	mem 39.536
Train: [36][35/750]	BT 0.267 (1.647)	DT 0.006 (1.501)	loss nan (nan)	prob nan (nan)	GS 29.547 (29.547)	mem 39.668
Train: [36][40/750]	BT 0.088 (1.717)	DT 0.001 (1.571)	loss nan (nan)	prob nan (nan)	GS 29.938 (29.938)	mem 39.643
Train: [36][45/750]	BT 0.187 (1.578)	DT 0.049 (1.429)	loss nan (nan)	prob nan (nan)	GS 28.875 (28.875)	mem 39.658
Train: [36][50/750]	BT 9.469 (1.622)	DT 9.360 (1.474)	loss nan (nan)	prob nan (nan)	GS 34.578 (34.578)	mem 39.646
Train: [36][55/750]	BT 0.240 (1.490)	DT 0.001 (1.342)	loss nan (nan)	prob nan (nan)	GS 29.906 (29.906)	mem 39.691
Train: [36][60/750]	BT 0.095 (1.425)	DT 0.003 (1.280)	loss nan (nan)	prob nan (nan)	GS 35.219 (35.219)	mem 39.746
Train: [36][65/750]	BT 0.143 (1.467)	DT 0.002 (1.326)	loss nan (nan)	prob nan (nan)	GS 29.875 (29.875)	mem 39.615
Train: [36][70/750]	BT 0.697 (1.389)	DT 0.609 (1.249)	loss nan (nan)	prob nan (nan)	GS 36.156 (36.156)	mem 39.544
Train: [36][75/750]	BT 0.098 (1.430)	DT 0.002 (1.292)	loss nan (nan)	prob nan (nan)	GS 33.047 (33.047)	mem 39.605
Train: [36][80/750]	BT 0.114 (1.372)	DT 0.005 (1.235)	loss nan (nan)	prob nan (nan)	GS 32.438 (32.438)	mem 39.643
Train: [36][85/750]	BT 0.172 (1.341)	DT 0.010 (1.204)	loss nan (nan)	prob nan (nan)	GS 28.109 (28.109)	mem 39.648
Train: [36][90/750]	BT 0.098 (1.371)	DT 0.002 (1.234)	loss nan (nan)	prob nan (nan)	GS 31.906 (31.906)	mem 39.848
Train: [36][95/750]	BT 0.078 (1.363)	DT 0.005 (1.226)	loss nan (nan)	prob nan (nan)	GS 31.406 (31.406)	mem 39.725
Train: [36][100/750]	BT 0.082 (1.374)	DT 0.002 (1.238)	loss nan (nan)	prob nan (nan)	GS 37.125 (37.125)	mem 39.926
Train: [36][105/750]	BT 0.206 (1.316)	DT 0.005 (1.179)	loss nan (nan)	prob nan (nan)	GS 32.078 (32.078)	mem 39.773
Train: [36][110/750]	BT 6.344 (1.366)	DT 6.273 (1.229)	loss nan (nan)	prob nan (nan)	GS 31.953 (31.953)	mem 39.755
Train: [36][115/750]	BT 0.127 (1.312)	DT 0.002 (1.176)	loss nan (nan)	prob nan (nan)	GS 32.016 (32.016)	mem 39.760
Train: [36][120/750]	BT 0.180 (1.301)	DT 0.020 (1.163)	loss nan (nan)	prob nan (nan)	GS 32.266 (32.266)	mem 40.089
Train: [36][125/750]	BT 0.104 (1.316)	DT 0.002 (1.179)	loss nan (nan)	prob nan (nan)	GS 35.578 (35.578)	mem 39.724
Train: [36][130/750]	BT 2.201 (1.287)	DT 2.119 (1.150)	loss nan (nan)	prob nan (nan)	GS 30.984 (30.984)	mem 39.999
Train: [36][135/750]	BT 0.118 (1.311)	DT 0.001 (1.174)	loss nan (nan)	prob nan (nan)	GS 31.094 (31.094)	mem 39.805
Train: [36][140/750]	BT 0.092 (1.268)	DT 0.002 (1.133)	loss nan (nan)	prob nan (nan)	GS 32.672 (32.672)	mem 39.806
Train: [36][145/750]	BT 0.176 (1.229)	DT 0.019 (1.094)	loss nan (nan)	prob nan (nan)	GS 33.531 (33.531)	mem 39.816
Train: [36][150/750]	BT 0.930 (1.281)	DT 0.851 (1.147)	loss nan (nan)	prob nan (nan)	GS 33.984 (33.984)	mem 39.744
Train: [36][155/750]	BT 0.140 (1.244)	DT 0.004 (1.110)	loss nan (nan)	prob nan (nan)	GS 29.562 (29.562)	mem 39.748
Train: [36][160/750]	BT 0.116 (1.277)	DT 0.013 (1.142)	loss nan (nan)	prob nan (nan)	GS 33.656 (33.656)	mem 39.882
Train: [36][165/750]	BT 0.079 (1.258)	DT 0.001 (1.125)	loss nan (nan)	prob nan (nan)	GS 31.062 (31.062)	mem 39.918
Train: [36][170/750]	BT 10.368 (1.286)	DT 10.183 (1.152)	loss nan (nan)	prob nan (nan)	GS 34.359 (34.359)	mem 39.894
Train: [36][175/750]	BT 0.118 (1.276)	DT 0.007 (1.142)	loss nan (nan)	prob nan (nan)	GS 28.938 (28.938)	mem 39.937
Train: [36][180/750]	BT 0.130 (1.244)	DT 0.013 (1.111)	loss nan (nan)	prob nan (nan)	GS 30.047 (30.047)	mem 39.937
Train: [36][185/750]	BT 0.087 (1.249)	DT 0.001 (1.116)	loss nan (nan)	prob nan (nan)	GS 30.125 (30.125)	mem 39.910
Train: [36][190/750]	BT 0.193 (1.241)	DT 0.007 (1.107)	loss nan (nan)	prob nan (nan)	GS 34.891 (34.891)	mem 39.897
Train: [36][195/750]	BT 0.132 (1.240)	DT 0.001 (1.106)	loss nan (nan)	prob nan (nan)	GS 35.969 (35.969)	mem 39.904
Train: [36][200/750]	BT 0.103 (1.259)	DT 0.009 (1.126)	loss nan (nan)	prob nan (nan)	GS 36.594 (36.594)	mem 39.932
Train: [36][205/750]	BT 0.250 (1.232)	DT 0.011 (1.099)	loss nan (nan)	prob nan (nan)	GS 32.328 (32.328)	mem 40.030
Train: [36][210/750]	BT 8.617 (1.252)	DT 8.507 (1.118)	loss nan (nan)	prob nan (nan)	GS 33.422 (33.422)	mem 39.907
Train: [36][215/750]	BT 0.076 (1.227)	DT 0.003 (1.092)	loss nan (nan)	prob nan (nan)	GS 29.641 (29.641)	mem 39.911
Train: [36][220/750]	BT 0.117 (1.205)	DT 0.005 (1.071)	loss nan (nan)	prob nan (nan)	GS 33.594 (33.594)	mem 40.138
Train: [36][225/750]	BT 0.095 (1.222)	DT 0.009 (1.089)	loss nan (nan)	prob nan (nan)	GS 32.562 (32.562)	mem 39.773
Train: [36][230/750]	BT 6.667 (1.227)	DT 6.514 (1.094)	loss nan (nan)	prob nan (nan)	GS 36.812 (36.812)	mem 40.006
Train: [36][235/750]	BT 0.186 (1.227)	DT 0.003 (1.093)	loss nan (nan)	prob nan (nan)	GS 25.094 (25.094)	mem 40.027
Train: [36][240/750]	BT 0.106 (1.203)	DT 0.002 (1.070)	loss nan (nan)	prob nan (nan)	GS 36.922 (36.922)	mem 39.944
Train: [36][245/750]	BT 0.151 (1.209)	DT 0.002 (1.075)	loss nan (nan)	prob nan (nan)	GS 32.578 (32.578)	mem 40.001
Train: [36][250/750]	BT 0.067 (1.213)	DT 0.001 (1.080)	loss nan (nan)	prob nan (nan)	GS 33.469 (33.469)	mem 39.961
Train: [36][255/750]	BT 0.111 (1.209)	DT 0.006 (1.075)	loss nan (nan)	prob nan (nan)	GS 34.531 (34.531)	mem 39.942
Train: [36][260/750]	BT 0.110 (1.200)	DT 0.008 (1.067)	loss nan (nan)	prob nan (nan)	GS 35.172 (35.172)	mem 40.096
Train: [36][265/750]	BT 0.099 (1.179)	DT 0.001 (1.047)	loss nan (nan)	prob nan (nan)	GS 32.453 (32.453)	mem 39.980
Train: [36][270/750]	BT 1.519 (1.191)	DT 1.322 (1.059)	loss nan (nan)	prob nan (nan)	GS 31.344 (31.344)	mem 40.030
Train: [36][275/750]	BT 0.096 (1.172)	DT 0.002 (1.039)	loss nan (nan)	prob nan (nan)	GS 37.422 (37.422)	mem 40.095
Train: [36][280/750]	BT 0.172 (1.187)	DT 0.002 (1.054)	loss nan (nan)	prob nan (nan)	GS 36.078 (36.078)	mem 39.957
Train: [36][285/750]	BT 0.097 (1.186)	DT 0.001 (1.053)	loss nan (nan)	prob nan (nan)	GS 30.594 (30.594)	mem 40.009
Train: [36][290/750]	BT 4.858 (1.184)	DT 4.779 (1.052)	loss nan (nan)	prob nan (nan)	GS 31.516 (31.516)	mem 40.041
Train: [36][295/750]	BT 0.084 (1.184)	DT 0.001 (1.052)	loss nan (nan)	prob nan (nan)	GS 36.688 (36.688)	mem 40.032
Train: [36][300/750]	BT 0.079 (1.167)	DT 0.002 (1.034)	loss nan (nan)	prob nan (nan)	GS 35.016 (35.016)	mem 40.035
Train: [36][305/750]	BT 0.088 (1.186)	DT 0.001 (1.054)	loss nan (nan)	prob nan (nan)	GS 30.562 (30.562)	mem 39.966
Train: [36][310/750]	BT 0.126 (1.175)	DT 0.001 (1.043)	loss nan (nan)	prob nan (nan)	GS 37.484 (37.484)	mem 40.010
Train: [36][315/750]	BT 0.086 (1.183)	DT 0.002 (1.051)	loss nan (nan)	prob nan (nan)	GS 36.672 (36.672)	mem 40.071
Train: [36][320/750]	BT 1.780 (1.184)	DT 1.692 (1.052)	loss nan (nan)	prob nan (nan)	GS 34.562 (34.562)	mem 40.018
Train: [36][325/750]	BT 0.091 (1.167)	DT 0.002 (1.036)	loss nan (nan)	prob nan (nan)	GS 30.172 (30.172)	mem 40.197
Train: [36][330/750]	BT 1.389 (1.178)	DT 1.088 (1.046)	loss nan (nan)	prob nan (nan)	GS 29.031 (29.031)	mem 40.161
Train: [36][335/750]	BT 0.112 (1.174)	DT 0.002 (1.042)	loss nan (nan)	prob nan (nan)	GS 33.375 (33.375)	mem 39.917
Train: [36][340/750]	BT 0.092 (1.171)	DT 0.002 (1.040)	loss nan (nan)	prob nan (nan)	GS 32.156 (32.156)	mem 40.079
Train: [36][345/750]	BT 0.163 (1.175)	DT 0.002 (1.044)	loss nan (nan)	prob nan (nan)	GS 29.500 (29.500)	mem 40.035
Train: [36][350/750]	BT 5.178 (1.175)	DT 5.029 (1.043)	loss nan (nan)	prob nan (nan)	GS 31.922 (31.922)	mem 40.045
Train: [36][355/750]	BT 0.189 (1.162)	DT 0.007 (1.030)	loss nan (nan)	prob nan (nan)	GS 32.172 (32.172)	mem 40.099
Train: [36][360/750]	BT 0.167 (1.170)	DT 0.002 (1.037)	loss nan (nan)	prob nan (nan)	GS 34.953 (34.953)	mem 39.980
Train: [36][365/750]	BT 0.167 (1.169)	DT 0.002 (1.036)	loss nan (nan)	prob nan (nan)	GS 29.906 (29.906)	mem 40.043
Train: [36][370/750]	BT 0.148 (1.165)	DT 0.002 (1.033)	loss nan (nan)	prob nan (nan)	GS 31.859 (31.859)	mem 40.086
Train: [36][375/750]	BT 0.173 (1.177)	DT 0.028 (1.045)	loss nan (nan)	prob nan (nan)	GS 35.234 (35.234)	mem 40.031
Train: [36][380/750]	BT 0.674 (1.168)	DT 0.596 (1.036)	loss nan (nan)	prob nan (nan)	GS 35.516 (35.516)	mem 40.013
Train: [36][385/750]	BT 0.180 (1.155)	DT 0.002 (1.023)	loss nan (nan)	prob nan (nan)	GS 26.500 (26.500)	mem 40.059
Train: [36][390/750]	BT 4.507 (1.171)	DT 4.370 (1.039)	loss nan (nan)	prob nan (nan)	GS 32.672 (32.672)	mem 40.024
Train: [36][395/750]	BT 0.142 (1.161)	DT 0.002 (1.028)	loss nan (nan)	prob nan (nan)	GS 30.812 (30.812)	mem 40.052
Train: [36][400/750]	BT 0.193 (1.168)	DT 0.001 (1.036)	loss nan (nan)	prob nan (nan)	GS 34.297 (34.297)	mem 40.122
Train: [36][405/750]	BT 0.101 (1.173)	DT 0.005 (1.040)	loss nan (nan)	prob nan (nan)	GS 29.594 (29.594)	mem 40.103
Train: [36][410/750]	BT 4.023 (1.170)	DT 3.922 (1.037)	loss nan (nan)	prob nan (nan)	GS 31.328 (31.328)	mem 40.278
Train: [36][415/750]	BT 0.226 (1.158)	DT 0.006 (1.025)	loss nan (nan)	prob nan (nan)	GS 29.438 (29.438)	mem 40.075
Train: [36][420/750]	BT 0.195 (1.165)	DT 0.005 (1.031)	loss nan (nan)	prob nan (nan)	GS 36.750 (36.750)	mem 40.111
Train: [36][425/750]	BT 0.095 (1.157)	DT 0.002 (1.024)	loss nan (nan)	prob nan (nan)	GS 33.656 (33.656)	mem 40.011
Train: [36][430/750]	BT 0.111 (1.166)	DT 0.001 (1.033)	loss nan (nan)	prob nan (nan)	GS 27.297 (27.297)	mem 40.035
Train: [36][435/750]	BT 0.135 (1.161)	DT 0.001 (1.029)	loss nan (nan)	prob nan (nan)	GS 29.859 (29.859)	mem 40.006
Train: [36][440/750]	BT 7.743 (1.167)	DT 7.649 (1.034)	loss nan (nan)	prob nan (nan)	GS 33.859 (33.859)	mem 40.242
Train: [36][445/750]	BT 0.159 (1.155)	DT 0.007 (1.023)	loss nan (nan)	prob nan (nan)	GS 33.328 (33.328)	mem 40.204
Train: [36][450/750]	BT 0.170 (1.156)	DT 0.002 (1.024)	loss nan (nan)	prob nan (nan)	GS 37.438 (37.438)	mem 39.975
Train: [36][455/750]	BT 0.132 (1.158)	DT 0.002 (1.025)	loss nan (nan)	prob nan (nan)	GS 30.062 (30.062)	mem 40.061
Train: [36][460/750]	BT 0.090 (1.160)	DT 0.002 (1.027)	loss nan (nan)	prob nan (nan)	GS 31.594 (31.594)	mem 40.086
Train: [36][465/750]	BT 0.137 (1.159)	DT 0.002 (1.027)	loss nan (nan)	prob nan (nan)	GS 26.766 (26.766)	mem 40.101
Train: [36][470/750]	BT 6.971 (1.163)	DT 6.882 (1.031)	loss nan (nan)	prob nan (nan)	GS 35.625 (35.625)	mem 39.950
Train: [36][475/750]	BT 0.269 (1.155)	DT 0.007 (1.022)	loss nan (nan)	prob nan (nan)	GS 32.578 (32.578)	mem 39.969
Train: [36][480/750]	BT 0.115 (1.153)	DT 0.001 (1.020)	loss nan (nan)	prob nan (nan)	GS 30.781 (30.781)	mem 40.000
Train: [36][485/750]	BT 0.076 (1.157)	DT 0.001 (1.024)	loss nan (nan)	prob nan (nan)	GS 34.031 (34.031)	mem 39.982
Train: [36][490/750]	BT 0.200 (1.154)	DT 0.021 (1.022)	loss nan (nan)	prob nan (nan)	GS 34.281 (34.281)	mem 39.956
Train: [36][495/750]	BT 0.081 (1.163)	DT 0.001 (1.031)	loss nan (nan)	prob nan (nan)	GS 30.500 (30.500)	mem 39.966
Train: [36][500/750]	BT 0.694 (1.154)	DT 0.504 (1.021)	loss nan (nan)	prob nan (nan)	GS 31.500 (31.500)	mem 40.034
Train: [36][505/750]	BT 0.193 (1.144)	DT 0.015 (1.011)	loss nan (nan)	prob nan (nan)	GS 29.062 (29.062)	mem 40.029
Train: [36][510/750]	BT 0.084 (1.157)	DT 0.001 (1.026)	loss nan (nan)	prob nan (nan)	GS 34.328 (34.328)	mem 40.066
Train: [36][515/750]	BT 0.157 (1.147)	DT 0.005 (1.016)	loss nan (nan)	prob nan (nan)	GS 33.094 (33.094)	mem 40.075
Train: [36][520/750]	BT 0.090 (1.160)	DT 0.001 (1.028)	loss nan (nan)	prob nan (nan)	GS 32.844 (32.844)	mem 40.030
Train: [36][525/750]	BT 0.148 (1.150)	DT 0.005 (1.018)	loss nan (nan)	prob nan (nan)	GS 28.500 (28.500)	mem 40.091
Train: [36][530/750]	BT 10.236 (1.159)	DT 10.092 (1.028)	loss nan (nan)	prob nan (nan)	GS 30.719 (30.719)	mem 40.062
Train: [36][535/750]	BT 0.157 (1.150)	DT 0.004 (1.018)	loss nan (nan)	prob nan (nan)	GS 35.781 (35.781)	mem 40.063
Train: [36][540/750]	BT 0.148 (1.142)	DT 0.006 (1.010)	loss nan (nan)	prob nan (nan)	GS 34.844 (34.844)	mem 40.015
Train: [36][545/750]	BT 0.222 (1.157)	DT 0.001 (1.025)	loss nan (nan)	prob nan (nan)	GS 31.109 (31.109)	mem 40.255
Train: [36][550/750]	BT 0.128 (1.149)	DT 0.005 (1.017)	loss nan (nan)	prob nan (nan)	GS 32.125 (32.125)	mem 40.010
Train: [36][555/750]	BT 0.219 (1.157)	DT 0.015 (1.025)	loss nan (nan)	prob nan (nan)	GS 31.391 (31.391)	mem 40.259
Train: [36][560/750]	BT 2.998 (1.154)	DT 2.770 (1.021)	loss nan (nan)	prob nan (nan)	GS 36.516 (36.516)	mem 40.297
Train: [36][565/750]	BT 0.227 (1.145)	DT 0.012 (1.012)	loss nan (nan)	prob nan (nan)	GS 24.766 (24.766)	mem 40.051
Train: [36][570/750]	BT 0.109 (1.155)	DT 0.011 (1.022)	loss nan (nan)	prob nan (nan)	GS 31.422 (31.422)	mem 40.294
Train: [36][575/750]	BT 0.126 (1.147)	DT 0.004 (1.013)	loss nan (nan)	prob nan (nan)	GS 29.812 (29.812)	mem 40.219
Train: [36][580/750]	BT 0.071 (1.156)	DT 0.001 (1.023)	loss nan (nan)	prob nan (nan)	GS 34.703 (34.703)	mem 40.016
Train: [36][585/750]	BT 0.128 (1.153)	DT 0.008 (1.020)	loss nan (nan)	prob nan (nan)	GS 34.062 (34.062)	mem 40.065
Train: [36][590/750]	BT 7.910 (1.157)	DT 7.798 (1.024)	loss nan (nan)	prob nan (nan)	GS 35.578 (35.578)	mem 40.065
Train: [36][595/750]	BT 0.197 (1.149)	DT 0.005 (1.016)	loss nan (nan)	prob nan (nan)	GS 27.453 (27.453)	mem 40.060
Train: [36][600/750]	BT 0.177 (1.148)	DT 0.002 (1.014)	loss nan (nan)	prob nan (nan)	GS 33.078 (33.078)	mem 40.048
Train: [36][605/750]	BT 0.136 (1.148)	DT 0.005 (1.015)	loss nan (nan)	prob nan (nan)	GS 27.578 (27.578)	mem 40.014
Train: [36][610/750]	BT 0.110 (1.145)	DT 0.002 (1.011)	loss nan (nan)	prob nan (nan)	GS 37.938 (37.938)	mem 40.013
Train: [36][615/750]	BT 0.145 (1.156)	DT 0.001 (1.022)	loss nan (nan)	prob nan (nan)	GS 34.703 (34.703)	mem 39.983
Train: [36][620/750]	BT 0.169 (1.148)	DT 0.008 (1.014)	loss nan (nan)	prob nan (nan)	GS 35.188 (35.188)	mem 40.028
Train: [36][625/750]	BT 0.086 (1.144)	DT 0.002 (1.010)	loss nan (nan)	prob nan (nan)	GS 31.969 (31.969)	mem 39.867
Train: [36][630/750]	BT 0.172 (1.147)	DT 0.001 (1.013)	loss nan (nan)	prob nan (nan)	GS 31.969 (31.969)	mem 39.832
Train: [36][635/750]	BT 0.132 (1.139)	DT 0.010 (1.005)	loss nan (nan)	prob nan (nan)	GS 31.750 (31.750)	mem 39.838
Train: [36][640/750]	BT 0.115 (1.152)	DT 0.002 (1.019)	loss nan (nan)	prob nan (nan)	GS 34.828 (34.828)	mem 40.018
Train: [36][645/750]	BT 0.110 (1.145)	DT 0.002 (1.011)	loss nan (nan)	prob nan (nan)	GS 30.406 (30.406)	mem 39.978
Train: [36][650/750]	BT 10.018 (1.152)	DT 9.888 (1.019)	loss nan (nan)	prob nan (nan)	GS 34.000 (34.000)	mem 39.990
Train: [36][655/750]	BT 0.225 (1.146)	DT 0.005 (1.012)	loss nan (nan)	prob nan (nan)	GS 30.969 (30.969)	mem 40.057
Train: [36][660/750]	BT 2.701 (1.142)	DT 2.590 (1.008)	loss nan (nan)	prob nan (nan)	GS 36.312 (36.312)	mem 39.895
Train: [36][665/750]	BT 0.191 (1.149)	DT 0.010 (1.015)	loss nan (nan)	prob nan (nan)	GS 30.125 (30.125)	mem 40.008
Train: [36][670/750]	BT 0.088 (1.141)	DT 0.002 (1.008)	loss nan (nan)	prob nan (nan)	GS 34.688 (34.688)	mem 40.009
Train: [36][675/750]	BT 0.090 (1.148)	DT 0.007 (1.015)	loss nan (nan)	prob nan (nan)	GS 31.141 (31.141)	mem 40.022
Train: [36][680/750]	BT 0.083 (1.144)	DT 0.002 (1.012)	loss nan (nan)	prob nan (nan)	GS 37.781 (37.781)	mem 40.026
Train: [36][685/750]	BT 0.253 (1.138)	DT 0.012 (1.005)	loss nan (nan)	prob nan (nan)	GS 29.922 (29.922)	mem 39.980
Train: [36][690/750]	BT 0.085 (1.146)	DT 0.001 (1.013)	loss nan (nan)	prob nan (nan)	GS 35.109 (35.109)	mem 40.016
Train: [36][695/750]	BT 0.113 (1.139)	DT 0.007 (1.005)	loss nan (nan)	prob nan (nan)	GS 28.141 (28.141)	mem 40.019
Train: [36][700/750]	BT 0.127 (1.147)	DT 0.018 (1.014)	loss nan (nan)	prob nan (nan)	GS 33.938 (33.938)	mem 40.012
Train: [36][705/750]	BT 0.126 (1.140)	DT 0.035 (1.006)	loss nan (nan)	prob nan (nan)	GS 32.781 (32.781)	mem 39.945
Train: [36][710/750]	BT 9.741 (1.149)	DT 9.633 (1.016)	loss nan (nan)	prob nan (nan)	GS 36.016 (36.016)	mem 39.977
Train: [36][715/750]	BT 0.140 (1.142)	DT 0.015 (1.009)	loss nan (nan)	prob nan (nan)	GS 30.234 (30.234)	mem 40.062
Train: [36][720/750]	BT 0.422 (1.135)	DT 0.274 (1.002)	loss nan (nan)	prob nan (nan)	GS 35.047 (35.047)	mem 40.056
Train: [36][725/750]	BT 0.216 (1.142)	DT 0.002 (1.009)	loss nan (nan)	prob nan (nan)	GS 31.094 (31.094)	mem 39.891
Train: [36][730/750]	BT 0.126 (1.135)	DT 0.006 (1.002)	loss nan (nan)	prob nan (nan)	GS 32.016 (32.016)	mem 39.892
Train: [36][735/750]	BT 0.090 (1.139)	DT 0.018 (1.005)	loss nan (nan)	prob nan (nan)	GS 32.172 (32.172)	mem 36.511
Train: [36][740/750]	BT 0.079 (1.132)	DT 0.001 (0.999)	loss nan (nan)	prob nan (nan)	GS 27.438 (27.438)	mem 36.483
Train: [36][745/750]	BT 0.058 (1.129)	DT 0.001 (0.996)	loss nan (nan)	prob nan (nan)	GS 35.219 (35.219)	mem 7.687
Train: [36][750/750]	BT 0.064 (1.122)	DT 0.001 (0.989)	loss nan (nan)	prob nan (nan)	GS 37.156 (37.156)	mem 7.687
Train: [36][755/750]	BT 0.061 (1.115)	DT 0.002 (0.983)	loss nan (nan)	prob nan (nan)	GS 29.938 (29.938)	mem 7.687
epoch 36, total time 843.02
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [37][1/750]	BT 21.537 (21.537)	DT 21.336 (21.336)	loss nan (nan)	prob nan (nan)	GS 34.156 (34.156)	mem 38.708
Train: [37][5/750]	BT 0.154 (5.052)	DT 0.001 (4.896)	loss nan (nan)	prob nan (nan)	GS 31.016 (31.016)	mem 38.853
Train: [37][10/750]	BT 0.271 (2.620)	DT 0.044 (2.454)	loss nan (nan)	prob nan (nan)	GS 37.062 (37.062)	mem 38.968
Train: [37][15/750]	BT 2.419 (2.497)	DT 2.295 (2.342)	loss nan (nan)	prob nan (nan)	GS 28.531 (28.531)	mem 38.873
Train: [37][20/750]	BT 0.207 (1.906)	DT 0.015 (1.757)	loss nan (nan)	prob nan (nan)	GS 28.359 (28.359)	mem 39.190
Train: [37][25/750]	BT 2.208 (1.889)	DT 2.106 (1.734)	loss nan (nan)	prob nan (nan)	GS 31.422 (31.422)	mem 38.992
Train: [37][30/750]	BT 1.929 (1.740)	DT 1.818 (1.590)	loss nan (nan)	prob nan (nan)	GS 35.828 (35.828)	mem 38.978
Train: [37][35/750]	BT 0.195 (1.702)	DT 0.001 (1.551)	loss nan (nan)	prob nan (nan)	GS 29.156 (29.156)	mem 38.979
Train: [37][40/750]	BT 0.096 (1.610)	DT 0.002 (1.459)	loss nan (nan)	prob nan (nan)	GS 36.641 (36.641)	mem 39.076
Train: [37][45/750]	BT 0.184 (1.463)	DT 0.008 (1.317)	loss nan (nan)	prob nan (nan)	GS 33.391 (33.391)	mem 39.013
Train: [37][50/750]	BT 4.329 (1.617)	DT 4.243 (1.464)	loss nan (nan)	prob nan (nan)	GS 34.031 (34.031)	mem 39.127
Train: [37][55/750]	BT 0.277 (1.485)	DT 0.014 (1.332)	loss nan (nan)	prob nan (nan)	GS 29.922 (29.922)	mem 39.128
Train: [37][60/750]	BT 6.313 (1.570)	DT 6.244 (1.415)	loss nan (nan)	prob nan (nan)	GS 34.266 (34.266)	mem 39.163
Train: [37][65/750]	BT 0.284 (1.460)	DT 0.002 (1.307)	loss nan (nan)	prob nan (nan)	GS 28.422 (28.422)	mem 39.266
Train: [37][70/750]	BT 8.112 (1.484)	DT 7.985 (1.328)	loss nan (nan)	prob nan (nan)	GS 37.516 (37.516)	mem 39.196
Train: [37][75/750]	BT 0.103 (1.429)	DT 0.002 (1.275)	loss nan (nan)	prob nan (nan)	GS 34.750 (34.750)	mem 39.159
Train: [37][80/750]	BT 0.088 (1.347)	DT 0.002 (1.195)	loss nan (nan)	prob nan (nan)	GS 33.938 (33.938)	mem 39.391
Train: [37][85/750]	BT 0.182 (1.423)	DT 0.003 (1.271)	loss nan (nan)	prob nan (nan)	GS 33.109 (33.109)	mem 39.241
Train: [37][90/750]	BT 0.177 (1.367)	DT 0.009 (1.214)	loss nan (nan)	prob nan (nan)	GS 32.938 (32.938)	mem 39.194
Train: [37][95/750]	BT 0.177 (1.341)	DT 0.002 (1.186)	loss nan (nan)	prob nan (nan)	GS 30.094 (30.094)	mem 39.470
Train: [37][100/750]	BT 0.191 (1.349)	DT 0.003 (1.196)	loss nan (nan)	prob nan (nan)	GS 35.609 (35.609)	mem 39.254
Train: [37][105/750]	BT 0.093 (1.289)	DT 0.004 (1.139)	loss nan (nan)	prob nan (nan)	GS 29.625 (29.625)	mem 39.522
Train: [37][110/750]	BT 0.104 (1.347)	DT 0.007 (1.198)	loss nan (nan)	prob nan (nan)	GS 34.094 (34.094)	mem 39.248
Train: [37][115/750]	BT 0.188 (1.295)	DT 0.021 (1.146)	loss nan (nan)	prob nan (nan)	GS 34.094 (34.094)	mem 39.311
Train: [37][120/750]	BT 8.223 (1.354)	DT 8.145 (1.207)	loss nan (nan)	prob nan (nan)	GS 37.578 (37.578)	mem 39.247
Train: [37][125/750]	BT 0.158 (1.304)	DT 0.008 (1.159)	loss nan (nan)	prob nan (nan)	GS 28.234 (28.234)	mem 39.244
Train: [37][130/750]	BT 3.616 (1.287)	DT 3.516 (1.141)	loss nan (nan)	prob nan (nan)	GS 33.156 (33.156)	mem 39.255
Train: [37][135/750]	BT 0.166 (1.303)	DT 0.007 (1.158)	loss nan (nan)	prob nan (nan)	GS 29.625 (29.625)	mem 39.232
Train: [37][140/750]	BT 0.221 (1.263)	DT 0.002 (1.116)	loss nan (nan)	prob nan (nan)	GS 34.875 (34.875)	mem 39.270
Train: [37][145/750]	BT 0.124 (1.283)	DT 0.002 (1.137)	loss nan (nan)	prob nan (nan)	GS 31.219 (31.219)	mem 39.374
Train: [37][150/750]	BT 0.087 (1.261)	DT 0.002 (1.116)	loss nan (nan)	prob nan (nan)	GS 31.031 (31.031)	mem 39.411
Train: [37][155/750]	BT 0.133 (1.251)	DT 0.001 (1.103)	loss nan (nan)	prob nan (nan)	GS 33.641 (33.641)	mem 39.618
Train: [37][160/750]	BT 0.122 (1.257)	DT 0.005 (1.111)	loss nan (nan)	prob nan (nan)	GS 32.344 (32.344)	mem 39.948
Train: [37][165/750]	BT 0.147 (1.224)	DT 0.016 (1.077)	loss nan (nan)	prob nan (nan)	GS 27.953 (27.953)	mem 39.640
Train: [37][170/750]	BT 4.861 (1.274)	DT 4.767 (1.129)	loss nan (nan)	prob nan (nan)	GS 40.828 (40.828)	mem 39.615
Train: [37][175/750]	BT 0.167 (1.241)	DT 0.021 (1.097)	loss nan (nan)	prob nan (nan)	GS 31.453 (31.453)	mem 39.555
Train: [37][180/750]	BT 9.147 (1.260)	DT 9.053 (1.117)	loss nan (nan)	prob nan (nan)	GS 35.719 (35.719)	mem 39.602
Train: [37][185/750]	BT 0.155 (1.240)	DT 0.013 (1.096)	loss nan (nan)	prob nan (nan)	GS 33.109 (33.109)	mem 39.607
Train: [37][190/750]	BT 0.113 (1.210)	DT 0.002 (1.067)	loss nan (nan)	prob nan (nan)	GS 32.094 (32.094)	mem 39.754
Train: [37][195/750]	BT 0.097 (1.242)	DT 0.001 (1.100)	loss nan (nan)	prob nan (nan)	GS 31.281 (31.281)	mem 39.912
Train: [37][200/750]	BT 0.090 (1.215)	DT 0.002 (1.072)	loss nan (nan)	prob nan (nan)	GS 31.281 (31.281)	mem 40.005
Train: [37][205/750]	BT 0.100 (1.237)	DT 0.002 (1.094)	loss nan (nan)	prob nan (nan)	GS 31.234 (31.234)	mem 39.960
Train: [37][210/750]	BT 0.099 (1.217)	DT 0.002 (1.076)	loss nan (nan)	prob nan (nan)	GS 37.109 (37.109)	mem 40.053
Train: [37][215/750]	BT 0.146 (1.192)	DT 0.002 (1.051)	loss nan (nan)	prob nan (nan)	GS 33.906 (33.906)	mem 39.968
Train: [37][220/750]	BT 0.129 (1.219)	DT 0.005 (1.077)	loss nan (nan)	prob nan (nan)	GS 34.422 (34.422)	mem 40.098
Train: [37][225/750]	BT 0.095 (1.194)	DT 0.001 (1.053)	loss nan (nan)	prob nan (nan)	GS 32.500 (32.500)	mem 39.968
Train: [37][230/750]	BT 6.034 (1.232)	DT 5.929 (1.091)	loss nan (nan)	prob nan (nan)	GS 34.188 (34.188)	mem 39.828
Train: [37][235/750]	BT 0.110 (1.208)	DT 0.002 (1.068)	loss nan (nan)	prob nan (nan)	GS 32.109 (32.109)	mem 39.886
Train: [37][240/750]	BT 6.202 (1.211)	DT 6.061 (1.071)	loss nan (nan)	prob nan (nan)	GS 31.188 (31.188)	mem 39.907
Train: [37][245/750]	BT 0.118 (1.220)	DT 0.002 (1.080)	loss nan (nan)	prob nan (nan)	GS 32.406 (32.406)	mem 40.041
Train: [37][250/750]	BT 0.109 (1.198)	DT 0.001 (1.059)	loss nan (nan)	prob nan (nan)	GS 35.438 (35.438)	mem 39.989
Train: [37][255/750]	BT 0.163 (1.222)	DT 0.003 (1.082)	loss nan (nan)	prob nan (nan)	GS 29.266 (29.266)	mem 39.882
Train: [37][260/750]	BT 0.086 (1.201)	DT 0.004 (1.061)	loss nan (nan)	prob nan (nan)	GS 33.344 (33.344)	mem 39.889
Train: [37][265/750]	BT 0.102 (1.194)	DT 0.002 (1.055)	loss nan (nan)	prob nan (nan)	GS 32.859 (32.859)	mem 39.868
Train: [37][270/750]	BT 0.171 (1.197)	DT 0.002 (1.058)	loss nan (nan)	prob nan (nan)	GS 31.594 (31.594)	mem 40.057
Train: [37][275/750]	BT 0.079 (1.188)	DT 0.001 (1.049)	loss nan (nan)	prob nan (nan)	GS 28.500 (28.500)	mem 39.882
Train: [37][280/750]	BT 0.114 (1.195)	DT 0.002 (1.057)	loss nan (nan)	prob nan (nan)	GS 35.578 (35.578)	mem 39.987
Train: [37][285/750]	BT 0.211 (1.178)	DT 0.002 (1.039)	loss nan (nan)	prob nan (nan)	GS 32.828 (32.828)	mem 39.990
Train: [37][290/750]	BT 0.141 (1.202)	DT 0.009 (1.062)	loss nan (nan)	prob nan (nan)	GS 29.781 (29.781)	mem 39.921
Train: [37][295/750]	BT 0.122 (1.183)	DT 0.002 (1.044)	loss nan (nan)	prob nan (nan)	GS 36.344 (36.344)	mem 39.922
Train: [37][300/750]	BT 9.687 (1.207)	DT 9.542 (1.068)	loss nan (nan)	prob nan (nan)	GS 36.719 (36.719)	mem 40.140
Train: [37][305/750]	BT 0.118 (1.190)	DT 0.002 (1.051)	loss nan (nan)	prob nan (nan)	GS 33.969 (33.969)	mem 40.001
Train: [37][310/750]	BT 5.310 (1.190)	DT 5.193 (1.051)	loss nan (nan)	prob nan (nan)	GS 36.469 (36.469)	mem 40.049
Train: [37][315/750]	BT 0.168 (1.194)	DT 0.001 (1.055)	loss nan (nan)	prob nan (nan)	GS 33.531 (33.531)	mem 40.214
Train: [37][320/750]	BT 0.085 (1.177)	DT 0.001 (1.038)	loss nan (nan)	prob nan (nan)	GS 37.438 (37.438)	mem 40.048
Train: [37][325/750]	BT 0.067 (1.193)	DT 0.001 (1.056)	loss nan (nan)	prob nan (nan)	GS 28.719 (28.719)	mem 40.032
Train: [37][330/750]	BT 0.103 (1.177)	DT 0.002 (1.040)	loss nan (nan)	prob nan (nan)	GS 38.312 (38.312)	mem 40.034
Train: [37][335/750]	BT 0.154 (1.197)	DT 0.002 (1.060)	loss nan (nan)	prob nan (nan)	GS 32.109 (32.109)	mem 40.046
Train: [37][340/750]	BT 0.084 (1.181)	DT 0.010 (1.044)	loss nan (nan)	prob nan (nan)	GS 32.484 (32.484)	mem 40.129
Train: [37][345/750]	BT 0.160 (1.165)	DT 0.002 (1.029)	loss nan (nan)	prob nan (nan)	GS 31.094 (31.094)	mem 40.101
Train: [37][350/750]	BT 0.080 (1.183)	DT 0.001 (1.047)	loss nan (nan)	prob nan (nan)	GS 33.578 (33.578)	mem 40.004
Train: [37][355/750]	BT 0.087 (1.176)	DT 0.002 (1.041)	loss nan (nan)	prob nan (nan)	GS 33.000 (33.000)	mem 39.939
Train: [37][360/750]	BT 0.144 (1.185)	DT 0.001 (1.050)	loss nan (nan)	prob nan (nan)	GS 33.562 (33.562)	mem 39.940
Train: [37][365/750]	BT 0.080 (1.178)	DT 0.001 (1.042)	loss nan (nan)	prob nan (nan)	GS 33.344 (33.344)	mem 39.923
Train: [37][370/750]	BT 11.317 (1.193)	DT 11.147 (1.058)	loss nan (nan)	prob nan (nan)	GS 35.812 (35.812)	mem 39.987
Train: [37][375/750]	BT 0.143 (1.179)	DT 0.002 (1.044)	loss nan (nan)	prob nan (nan)	GS 31.172 (31.172)	mem 39.953
Train: [37][380/750]	BT 0.105 (1.171)	DT 0.001 (1.036)	loss nan (nan)	prob nan (nan)	GS 36.344 (36.344)	mem 39.969
Train: [37][385/750]	BT 0.154 (1.182)	DT 0.002 (1.047)	loss nan (nan)	prob nan (nan)	GS 31.422 (31.422)	mem 39.925
Train: [37][390/750]	BT 0.099 (1.177)	DT 0.002 (1.042)	loss nan (nan)	prob nan (nan)	GS 29.078 (29.078)	mem 39.897
Train: [37][395/750]	BT 0.084 (1.177)	DT 0.001 (1.043)	loss nan (nan)	prob nan (nan)	GS 30.453 (30.453)	mem 39.960
Train: [37][400/750]	BT 6.158 (1.181)	DT 5.954 (1.046)	loss nan (nan)	prob nan (nan)	GS 34.281 (34.281)	mem 39.936
Train: [37][405/750]	BT 0.143 (1.168)	DT 0.002 (1.033)	loss nan (nan)	prob nan (nan)	GS 32.031 (32.031)	mem 39.967
Train: [37][410/750]	BT 0.119 (1.166)	DT 0.006 (1.030)	loss nan (nan)	prob nan (nan)	GS 36.375 (36.375)	mem 39.926
Train: [37][415/750]	BT 0.114 (1.170)	DT 0.023 (1.034)	loss nan (nan)	prob nan (nan)	GS 34.312 (34.312)	mem 39.979
Train: [37][420/750]	BT 0.190 (1.168)	DT 0.079 (1.032)	loss nan (nan)	prob nan (nan)	GS 33.109 (33.109)	mem 40.012
Train: [37][425/750]	BT 0.080 (1.176)	DT 0.002 (1.041)	loss nan (nan)	prob nan (nan)	GS 34.219 (34.219)	mem 39.908
Train: [37][430/750]	BT 3.003 (1.170)	DT 2.846 (1.036)	loss nan (nan)	prob nan (nan)	GS 37.453 (37.453)	mem 40.005
Train: [37][435/750]	BT 0.084 (1.158)	DT 0.002 (1.024)	loss nan (nan)	prob nan (nan)	GS 31.703 (31.703)	mem 40.142
Train: [37][440/750]	BT 0.092 (1.165)	DT 0.002 (1.031)	loss nan (nan)	prob nan (nan)	GS 34.406 (34.406)	mem 40.043
Train: [37][445/750]	BT 0.162 (1.158)	DT 0.014 (1.023)	loss nan (nan)	prob nan (nan)	GS 32.672 (32.672)	mem 39.900
Train: [37][450/750]	BT 0.124 (1.171)	DT 0.001 (1.036)	loss nan (nan)	prob nan (nan)	GS 37.109 (37.109)	mem 40.042
Train: [37][455/750]	BT 0.135 (1.164)	DT 0.008 (1.029)	loss nan (nan)	prob nan (nan)	GS 31.828 (31.828)	mem 40.043
Train: [37][460/750]	BT 8.262 (1.171)	DT 8.155 (1.036)	loss nan (nan)	prob nan (nan)	GS 33.234 (33.234)	mem 40.014
Train: [37][465/750]	BT 0.244 (1.160)	DT 0.002 (1.025)	loss nan (nan)	prob nan (nan)	GS 32.719 (32.719)	mem 40.015
Train: [37][470/750]	BT 0.072 (1.153)	DT 0.001 (1.018)	loss nan (nan)	prob nan (nan)	GS 31.828 (31.828)	mem 39.966
Train: [37][475/750]	BT 0.088 (1.159)	DT 0.002 (1.024)	loss nan (nan)	prob nan (nan)	GS 36.625 (36.625)	mem 39.933
Train: [37][480/750]	BT 0.151 (1.155)	DT 0.002 (1.020)	loss nan (nan)	prob nan (nan)	GS 30.719 (30.719)	mem 39.978
Train: [37][485/750]	BT 0.112 (1.158)	DT 0.002 (1.023)	loss nan (nan)	prob nan (nan)	GS 40.656 (40.656)	mem 39.950
Train: [37][490/750]	BT 1.756 (1.151)	DT 1.646 (1.016)	loss nan (nan)	prob nan (nan)	GS 31.703 (31.703)	mem 39.962
Train: [37][495/750]	BT 0.102 (1.145)	DT 0.004 (1.010)	loss nan (nan)	prob nan (nan)	GS 32.641 (32.641)	mem 39.993
Train: [37][500/750]	BT 0.199 (1.152)	DT 0.001 (1.017)	loss nan (nan)	prob nan (nan)	GS 34.328 (34.328)	mem 39.924
Train: [37][505/750]	BT 0.150 (1.143)	DT 0.002 (1.008)	loss nan (nan)	prob nan (nan)	GS 36.875 (36.875)	mem 40.043
Train: [37][510/750]	BT 0.109 (1.153)	DT 0.007 (1.018)	loss nan (nan)	prob nan (nan)	GS 32.078 (32.078)	mem 39.954
Train: [37][515/750]	BT 0.083 (1.147)	DT 0.001 (1.012)	loss nan (nan)	prob nan (nan)	GS 36.141 (36.141)	mem 39.904
Train: [37][520/750]	BT 8.896 (1.154)	DT 8.783 (1.019)	loss nan (nan)	prob nan (nan)	GS 31.266 (31.266)	mem 39.975
Train: [37][525/750]	BT 0.173 (1.145)	DT 0.007 (1.010)	loss nan (nan)	prob nan (nan)	GS 34.078 (34.078)	mem 40.008
Train: [37][530/750]	BT 0.146 (1.144)	DT 0.023 (1.008)	loss nan (nan)	prob nan (nan)	GS 35.891 (35.891)	mem 39.994
Train: [37][535/750]	BT 0.185 (1.146)	DT 0.002 (1.011)	loss nan (nan)	prob nan (nan)	GS 40.609 (40.609)	mem 39.972
Train: [37][540/750]	BT 0.098 (1.146)	DT 0.002 (1.011)	loss nan (nan)	prob nan (nan)	GS 33.391 (33.391)	mem 40.013
Train: [37][545/750]	BT 0.105 (1.152)	DT 0.002 (1.016)	loss nan (nan)	prob nan (nan)	GS 30.906 (30.906)	mem 40.023
Train: [37][550/750]	BT 3.946 (1.149)	DT 3.837 (1.014)	loss nan (nan)	prob nan (nan)	GS 35.734 (35.734)	mem 40.203
Train: [37][555/750]	BT 0.102 (1.140)	DT 0.007 (1.005)	loss nan (nan)	prob nan (nan)	GS 30.484 (30.484)	mem 40.088
Train: [37][560/750]	BT 0.112 (1.148)	DT 0.001 (1.013)	loss nan (nan)	prob nan (nan)	GS 30.672 (30.672)	mem 40.054
Train: [37][565/750]	BT 0.105 (1.139)	DT 0.005 (1.004)	loss nan (nan)	prob nan (nan)	GS 34.141 (34.141)	mem 40.227
Train: [37][570/750]	BT 0.124 (1.149)	DT 0.007 (1.015)	loss nan (nan)	prob nan (nan)	GS 34.234 (34.234)	mem 40.054
Train: [37][575/750]	BT 0.082 (1.147)	DT 0.001 (1.013)	loss nan (nan)	prob nan (nan)	GS 29.562 (29.562)	mem 40.018
Train: [37][580/750]	BT 8.167 (1.153)	DT 8.083 (1.018)	loss nan (nan)	prob nan (nan)	GS 35.031 (35.031)	mem 40.075
Train: [37][585/750]	BT 0.127 (1.144)	DT 0.011 (1.010)	loss nan (nan)	prob nan (nan)	GS 31.812 (31.812)	mem 40.079
Train: [37][590/750]	BT 0.079 (1.141)	DT 0.002 (1.007)	loss nan (nan)	prob nan (nan)	GS 31.531 (31.531)	mem 39.990
Train: [37][595/750]	BT 0.078 (1.148)	DT 0.002 (1.014)	loss nan (nan)	prob nan (nan)	GS 34.281 (34.281)	mem 39.999
Train: [37][600/750]	BT 0.116 (1.143)	DT 0.001 (1.009)	loss nan (nan)	prob nan (nan)	GS 36.047 (36.047)	mem 40.117
Train: [37][605/750]	BT 0.112 (1.152)	DT 0.022 (1.018)	loss nan (nan)	prob nan (nan)	GS 28.125 (28.125)	mem 40.050
Train: [37][610/750]	BT 1.203 (1.145)	DT 1.092 (1.011)	loss nan (nan)	prob nan (nan)	GS 33.156 (33.156)	mem 39.982
Train: [37][615/750]	BT 0.222 (1.137)	DT 0.011 (1.003)	loss nan (nan)	prob nan (nan)	GS 37.016 (37.016)	mem 39.995
Train: [37][620/750]	BT 0.210 (1.143)	DT 0.001 (1.009)	loss nan (nan)	prob nan (nan)	GS 33.828 (33.828)	mem 40.067
Train: [37][625/750]	BT 0.073 (1.142)	DT 0.002 (1.008)	loss nan (nan)	prob nan (nan)	GS 32.500 (32.500)	mem 39.954
Train: [37][630/750]	BT 0.092 (1.147)	DT 0.001 (1.014)	loss nan (nan)	prob nan (nan)	GS 31.938 (31.938)	mem 39.905
Train: [37][635/750]	BT 0.103 (1.147)	DT 0.002 (1.013)	loss nan (nan)	prob nan (nan)	GS 35.781 (35.781)	mem 39.974
Train: [37][640/750]	BT 8.416 (1.152)	DT 8.228 (1.018)	loss nan (nan)	prob nan (nan)	GS 30.391 (30.391)	mem 40.045
Train: [37][645/750]	BT 0.129 (1.144)	DT 0.001 (1.010)	loss nan (nan)	prob nan (nan)	GS 27.234 (27.234)	mem 39.961
Train: [37][650/750]	BT 0.083 (1.139)	DT 0.001 (1.006)	loss nan (nan)	prob nan (nan)	GS 34.453 (34.453)	mem 40.206
Train: [37][655/750]	BT 0.185 (1.141)	DT 0.010 (1.007)	loss nan (nan)	prob nan (nan)	GS 33.016 (33.016)	mem 40.066
Train: [37][660/750]	BT 0.177 (1.143)	DT 0.001 (1.009)	loss nan (nan)	prob nan (nan)	GS 30.672 (30.672)	mem 40.056
Train: [37][665/750]	BT 0.139 (1.143)	DT 0.018 (1.010)	loss nan (nan)	prob nan (nan)	GS 29.422 (29.422)	mem 40.140
Train: [37][670/750]	BT 5.180 (1.143)	DT 5.028 (1.010)	loss nan (nan)	prob nan (nan)	GS 33.016 (33.016)	mem 40.159
Train: [37][675/750]	BT 0.134 (1.136)	DT 0.006 (1.002)	loss nan (nan)	prob nan (nan)	GS 30.578 (30.578)	mem 40.021
Train: [37][680/750]	BT 0.092 (1.139)	DT 0.001 (1.006)	loss nan (nan)	prob nan (nan)	GS 31.500 (31.500)	mem 40.141
Train: [37][685/750]	BT 0.075 (1.136)	DT 0.002 (1.003)	loss nan (nan)	prob nan (nan)	GS 32.203 (32.203)	mem 40.057
Train: [37][690/750]	BT 0.186 (1.141)	DT 0.007 (1.008)	loss nan (nan)	prob nan (nan)	GS 33.234 (33.234)	mem 40.110
Train: [37][695/750]	BT 0.185 (1.141)	DT 0.001 (1.008)	loss nan (nan)	prob nan (nan)	GS 31.422 (31.422)	mem 39.985
Train: [37][700/750]	BT 7.042 (1.144)	DT 6.815 (1.010)	loss nan (nan)	prob nan (nan)	GS 35.250 (35.250)	mem 40.324
Train: [37][705/750]	BT 0.094 (1.137)	DT 0.008 (1.003)	loss nan (nan)	prob nan (nan)	GS 31.766 (31.766)	mem 40.080
arpack error, retry= 0
arpack error, retry= 0
Train: [37][710/750]	BT 0.229 (1.138)	DT 0.001 (1.004)	loss nan (nan)	prob nan (nan)	GS 38.156 (38.156)	mem 40.119
Train: [37][715/750]	BT 0.191 (1.137)	DT 0.008 (1.004)	loss nan (nan)	prob nan (nan)	GS 40.000 (40.000)	mem 40.130
Train: [37][720/750]	BT 0.132 (1.138)	DT 0.002 (1.004)	loss nan (nan)	prob nan (nan)	GS 30.031 (30.031)	mem 39.984
Train: [37][725/750]	BT 0.102 (1.139)	DT 0.001 (1.006)	loss nan (nan)	prob nan (nan)	GS 30.750 (30.750)	mem 40.003
Train: [37][730/750]	BT 2.893 (1.136)	DT 2.782 (1.003)	loss nan (nan)	prob nan (nan)	GS 33.953 (33.953)	mem 40.086
Train: [37][735/750]	BT 0.206 (1.129)	DT 0.002 (0.996)	loss nan (nan)	prob nan (nan)	GS 32.047 (32.047)	mem 40.109
Train: [37][740/750]	BT 0.217 (1.129)	DT 0.012 (0.996)	loss nan (nan)	prob nan (nan)	GS 29.281 (29.281)	mem 19.512
Train: [37][745/750]	BT 0.063 (1.127)	DT 0.001 (0.995)	loss nan (nan)	prob nan (nan)	GS 31.344 (31.344)	mem 10.756
Train: [37][750/750]	BT 0.108 (1.120)	DT 0.022 (0.988)	loss nan (nan)	prob nan (nan)	GS 40.875 (40.875)	mem 10.759
Train: [37][755/750]	BT 0.079 (1.117)	DT 0.001 (0.985)	loss nan (nan)	prob nan (nan)	GS 33.750 (33.750)	mem 7.698
epoch 37, total time 843.92
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [38][1/750]	BT 20.112 (20.112)	DT 19.974 (19.974)	loss nan (nan)	prob nan (nan)	GS 34.641 (34.641)	mem 38.710
Train: [38][5/750]	BT 0.174 (5.014)	DT 0.002 (4.870)	loss nan (nan)	prob nan (nan)	GS 28.906 (28.906)	mem 38.738
Train: [38][10/750]	BT 0.192 (2.670)	DT 0.046 (2.541)	loss nan (nan)	prob nan (nan)	GS 34.578 (34.578)	mem 38.794
Train: [38][15/750]	BT 0.116 (2.676)	DT 0.001 (2.542)	loss nan (nan)	prob nan (nan)	GS 30.219 (30.219)	mem 39.064
Train: [38][20/750]	BT 0.123 (2.036)	DT 0.021 (1.908)	loss nan (nan)	prob nan (nan)	GS 34.344 (34.344)	mem 38.926
Train: [38][25/750]	BT 9.048 (2.072)	DT 8.958 (1.945)	loss nan (nan)	prob nan (nan)	GS 41.984 (41.984)	mem 39.090
Train: [38][30/750]	BT 0.100 (1.767)	DT 0.002 (1.645)	loss nan (nan)	prob nan (nan)	GS 33.234 (33.234)	mem 39.046
Train: [38][35/750]	BT 0.139 (1.651)	DT 0.009 (1.527)	loss nan (nan)	prob nan (nan)	GS 31.688 (31.688)	mem 39.068
Train: [38][40/750]	BT 0.209 (1.694)	DT 0.004 (1.567)	loss nan (nan)	prob nan (nan)	GS 28.547 (28.547)	mem 39.047
Train: [38][45/750]	BT 0.163 (1.583)	DT 0.006 (1.457)	loss nan (nan)	prob nan (nan)	GS 28.781 (28.781)	mem 39.254
Train: [38][50/750]	BT 6.811 (1.571)	DT 6.649 (1.445)	loss nan (nan)	prob nan (nan)	GS 32.453 (32.453)	mem 39.044
Train: [38][55/750]	BT 0.087 (1.438)	DT 0.001 (1.314)	loss nan (nan)	prob nan (nan)	GS 30.281 (30.281)	mem 39.053
Train: [38][60/750]	BT 0.154 (1.379)	DT 0.001 (1.255)	loss nan (nan)	prob nan (nan)	GS 36.406 (36.406)	mem 39.133
Train: [38][65/750]	BT 0.174 (1.401)	DT 0.030 (1.274)	loss nan (nan)	prob nan (nan)	GS 30.719 (30.719)	mem 39.160
Train: [38][70/750]	BT 0.090 (1.409)	DT 0.002 (1.282)	loss nan (nan)	prob nan (nan)	GS 30.234 (30.234)	mem 39.176
Train: [38][75/750]	BT 0.087 (1.330)	DT 0.002 (1.204)	loss nan (nan)	prob nan (nan)	GS 28.609 (28.609)	mem 39.215
Train: [38][80/750]	BT 6.922 (1.392)	DT 6.803 (1.266)	loss nan (nan)	prob nan (nan)	GS 32.062 (32.062)	mem 39.416
Train: [38][85/750]	BT 0.123 (1.327)	DT 0.002 (1.200)	loss nan (nan)	prob nan (nan)	GS 37.297 (37.297)	mem 39.365
Train: [38][90/750]	BT 1.803 (1.319)	DT 1.627 (1.190)	loss nan (nan)	prob nan (nan)	GS 27.484 (27.484)	mem 39.530
Train: [38][95/750]	BT 0.072 (1.322)	DT 0.001 (1.194)	loss nan (nan)	prob nan (nan)	GS 28.750 (28.750)	mem 39.528
Train: [38][100/750]	BT 0.398 (1.275)	DT 0.294 (1.146)	loss nan (nan)	prob nan (nan)	GS 34.797 (34.797)	mem 39.536
Train: [38][105/750]	BT 0.119 (1.323)	DT 0.002 (1.194)	loss nan (nan)	prob nan (nan)	GS 32.359 (32.359)	mem 39.619
Train: [38][110/750]	BT 0.084 (1.290)	DT 0.002 (1.162)	loss nan (nan)	prob nan (nan)	GS 33.641 (33.641)	mem 39.725
Train: [38][115/750]	BT 0.163 (1.243)	DT 0.002 (1.113)	loss nan (nan)	prob nan (nan)	GS 31.828 (31.828)	mem 39.708
Train: [38][120/750]	BT 0.082 (1.290)	DT 0.001 (1.161)	loss nan (nan)	prob nan (nan)	GS 31.406 (31.406)	mem 39.760
Train: [38][125/750]	BT 0.120 (1.243)	DT 0.002 (1.114)	loss nan (nan)	prob nan (nan)	GS 30.641 (30.641)	mem 39.763
Train: [38][130/750]	BT 2.672 (1.279)	DT 2.570 (1.151)	loss nan (nan)	prob nan (nan)	GS 35.719 (35.719)	mem 39.788
Train: [38][135/750]	BT 0.141 (1.237)	DT 0.010 (1.108)	loss nan (nan)	prob nan (nan)	GS 29.938 (29.938)	mem 39.789
Train: [38][140/750]	BT 7.322 (1.251)	DT 7.213 (1.121)	loss nan (nan)	prob nan (nan)	GS 34.094 (34.094)	mem 39.813
Train: [38][145/750]	BT 0.131 (1.244)	DT 0.006 (1.114)	loss nan (nan)	prob nan (nan)	GS 29.094 (29.094)	mem 39.749
Train: [38][150/750]	BT 0.294 (1.207)	DT 0.002 (1.077)	loss nan (nan)	prob nan (nan)	GS 32.781 (32.781)	mem 39.762
Train: [38][155/750]	BT 0.121 (1.269)	DT 0.002 (1.138)	loss nan (nan)	prob nan (nan)	GS 28.797 (28.797)	mem 39.715
Train: [38][160/750]	BT 0.158 (1.233)	DT 0.001 (1.103)	loss nan (nan)	prob nan (nan)	GS 35.188 (35.188)	mem 39.735
Train: [38][165/750]	BT 0.100 (1.204)	DT 0.002 (1.074)	loss nan (nan)	prob nan (nan)	GS 34.734 (34.734)	mem 39.829
Train: [38][170/750]	BT 0.089 (1.236)	DT 0.008 (1.107)	loss nan (nan)	prob nan (nan)	GS 37.953 (37.953)	mem 39.811
Train: [38][175/750]	BT 0.111 (1.204)	DT 0.001 (1.075)	loss nan (nan)	prob nan (nan)	GS 29.609 (29.609)	mem 39.896
Train: [38][180/750]	BT 0.124 (1.233)	DT 0.006 (1.104)	loss nan (nan)	prob nan (nan)	GS 37.109 (37.109)	mem 39.846
Train: [38][185/750]	BT 0.158 (1.204)	DT 0.012 (1.074)	loss nan (nan)	prob nan (nan)	GS 30.688 (30.688)	mem 39.955
Train: [38][190/750]	BT 5.799 (1.234)	DT 5.714 (1.104)	loss nan (nan)	prob nan (nan)	GS 32.750 (32.750)	mem 39.809
Train: [38][195/750]	BT 0.093 (1.205)	DT 0.002 (1.076)	loss nan (nan)	prob nan (nan)	GS 30.031 (30.031)	mem 39.886
Train: [38][200/750]	BT 2.321 (1.203)	DT 2.225 (1.074)	loss nan (nan)	prob nan (nan)	GS 35.094 (35.094)	mem 39.861
Train: [38][205/750]	BT 0.139 (1.215)	DT 0.012 (1.086)	loss nan (nan)	prob nan (nan)	GS 31.484 (31.484)	mem 39.923
Train: [38][210/750]	BT 0.095 (1.190)	DT 0.019 (1.061)	loss nan (nan)	prob nan (nan)	GS 30.375 (30.375)	mem 39.923
Train: [38][215/750]	BT 0.134 (1.216)	DT 0.008 (1.087)	loss nan (nan)	prob nan (nan)	GS 28.422 (28.422)	mem 39.995
Train: [38][220/750]	BT 0.171 (1.192)	DT 0.002 (1.062)	loss nan (nan)	prob nan (nan)	GS 30.625 (30.625)	mem 40.105
Train: [38][225/750]	BT 0.187 (1.201)	DT 0.006 (1.071)	loss nan (nan)	prob nan (nan)	GS 32.688 (32.688)	mem 39.828
Train: [38][230/750]	BT 0.281 (1.190)	DT 0.010 (1.059)	loss nan (nan)	prob nan (nan)	GS 30.125 (30.125)	mem 39.862
Train: [38][235/750]	BT 0.075 (1.206)	DT 0.002 (1.075)	loss nan (nan)	prob nan (nan)	GS 27.109 (27.109)	mem 39.915
Train: [38][240/750]	BT 0.141 (1.205)	DT 0.007 (1.073)	loss nan (nan)	prob nan (nan)	GS 29.875 (29.875)	mem 39.866
Train: [38][245/750]	BT 0.124 (1.183)	DT 0.004 (1.052)	loss nan (nan)	prob nan (nan)	GS 29.578 (29.578)	mem 39.869
Train: [38][250/750]	BT 6.366 (1.204)	DT 6.288 (1.073)	loss nan (nan)	prob nan (nan)	GS 33.562 (33.562)	mem 39.886
Train: [38][255/750]	BT 0.087 (1.183)	DT 0.002 (1.052)	loss nan (nan)	prob nan (nan)	GS 35.719 (35.719)	mem 39.887
Train: [38][260/750]	BT 2.243 (1.201)	DT 2.158 (1.070)	loss nan (nan)	prob nan (nan)	GS 36.750 (36.750)	mem 39.944
Train: [38][265/750]	BT 0.107 (1.192)	DT 0.002 (1.061)	loss nan (nan)	prob nan (nan)	GS 27.359 (27.359)	mem 39.931
Train: [38][270/750]	BT 3.699 (1.185)	DT 3.518 (1.054)	loss nan (nan)	prob nan (nan)	GS 35.641 (35.641)	mem 39.920
Train: [38][275/750]	BT 0.190 (1.197)	DT 0.001 (1.066)	loss nan (nan)	prob nan (nan)	GS 30.234 (30.234)	mem 40.032
Train: [38][280/750]	BT 0.159 (1.179)	DT 0.022 (1.047)	loss nan (nan)	prob nan (nan)	GS 38.312 (38.312)	mem 40.361
Train: [38][285/750]	BT 0.173 (1.198)	DT 0.002 (1.066)	loss nan (nan)	prob nan (nan)	GS 31.859 (31.859)	mem 39.914
Train: [38][290/750]	BT 0.111 (1.198)	DT 0.003 (1.066)	loss nan (nan)	prob nan (nan)	GS 32.062 (32.062)	mem 39.885
Train: [38][295/750]	BT 0.139 (1.180)	DT 0.001 (1.048)	loss nan (nan)	prob nan (nan)	GS 30.625 (30.625)	mem 39.902
Train: [38][300/750]	BT 0.102 (1.210)	DT 0.002 (1.078)	loss nan (nan)	prob nan (nan)	GS 34.594 (34.594)	mem 39.884
Train: [38][305/750]	BT 0.161 (1.193)	DT 0.001 (1.060)	loss nan (nan)	prob nan (nan)	GS 28.891 (28.891)	mem 39.968
Train: [38][310/750]	BT 11.217 (1.219)	DT 11.097 (1.087)	loss nan (nan)	prob nan (nan)	GS 27.453 (27.453)	mem 40.025
Train: [38][315/750]	BT 0.241 (1.203)	DT 0.007 (1.070)	loss nan (nan)	prob nan (nan)	GS 30.969 (30.969)	mem 40.129
Train: [38][320/750]	BT 0.731 (1.187)	DT 0.629 (1.055)	loss nan (nan)	prob nan (nan)	GS 30.125 (30.125)	mem 40.011
Train: [38][325/750]	BT 0.093 (1.205)	DT 0.005 (1.072)	loss nan (nan)	prob nan (nan)	GS 30.797 (30.797)	mem 39.984
Train: [38][330/750]	BT 0.078 (1.189)	DT 0.001 (1.056)	loss nan (nan)	prob nan (nan)	GS 32.625 (32.625)	mem 39.959
Train: [38][335/750]	BT 0.117 (1.208)	DT 0.002 (1.076)	loss nan (nan)	prob nan (nan)	GS 32.125 (32.125)	mem 39.894
Train: [38][340/750]	BT 0.178 (1.193)	DT 0.001 (1.060)	loss nan (nan)	prob nan (nan)	GS 34.297 (34.297)	mem 39.845
Train: [38][345/750]	BT 0.102 (1.178)	DT 0.001 (1.045)	loss nan (nan)	prob nan (nan)	GS 29.516 (29.516)	mem 39.887
Train: [38][350/750]	BT 0.223 (1.199)	DT 0.001 (1.066)	loss nan (nan)	prob nan (nan)	GS 30.422 (30.422)	mem 40.100
Train: [38][355/750]	BT 0.109 (1.184)	DT 0.009 (1.051)	loss nan (nan)	prob nan (nan)	GS 28.734 (28.734)	mem 39.918
Train: [38][360/750]	BT 0.107 (1.196)	DT 0.001 (1.064)	loss nan (nan)	prob nan (nan)	GS 31.734 (31.734)	mem 39.878
Train: [38][365/750]	BT 0.098 (1.181)	DT 0.001 (1.050)	loss nan (nan)	prob nan (nan)	GS 26.656 (26.656)	mem 39.882
Train: [38][370/750]	BT 8.318 (1.196)	DT 8.137 (1.064)	loss nan (nan)	prob nan (nan)	GS 34.266 (34.266)	mem 40.059
Train: [38][375/750]	BT 0.178 (1.182)	DT 0.002 (1.050)	loss nan (nan)	prob nan (nan)	GS 30.406 (30.406)	mem 39.964
Train: [38][380/750]	BT 4.793 (1.180)	DT 4.567 (1.049)	loss nan (nan)	prob nan (nan)	GS 35.406 (35.406)	mem 39.945
Train: [38][385/750]	BT 0.189 (1.186)	DT 0.004 (1.055)	loss nan (nan)	prob nan (nan)	GS 31.203 (31.203)	mem 40.008
Train: [38][390/750]	BT 0.118 (1.173)	DT 0.009 (1.041)	loss nan (nan)	prob nan (nan)	GS 33.469 (33.469)	mem 39.995
Train: [38][395/750]	BT 0.134 (1.183)	DT 0.010 (1.051)	loss nan (nan)	prob nan (nan)	GS 29.594 (29.594)	mem 39.929
Train: [38][400/750]	BT 0.093 (1.177)	DT 0.005 (1.046)	loss nan (nan)	prob nan (nan)	GS 34.203 (34.203)	mem 40.009
Train: [38][405/750]	BT 0.112 (1.173)	DT 0.002 (1.042)	loss nan (nan)	prob nan (nan)	GS 32.250 (32.250)	mem 40.012
Train: [38][410/750]	BT 0.136 (1.175)	DT 0.001 (1.044)	loss nan (nan)	prob nan (nan)	GS 26.969 (26.969)	mem 40.079
Train: [38][415/750]	BT 0.145 (1.163)	DT 0.001 (1.031)	loss nan (nan)	prob nan (nan)	GS 30.844 (30.844)	mem 40.056
Train: [38][420/750]	BT 1.562 (1.177)	DT 1.487 (1.045)	loss nan (nan)	prob nan (nan)	GS 27.125 (27.125)	mem 40.011
Train: [38][425/750]	BT 0.116 (1.165)	DT 0.002 (1.033)	loss nan (nan)	prob nan (nan)	GS 30.891 (30.891)	mem 40.117
Train: [38][430/750]	BT 0.164 (1.175)	DT 0.014 (1.043)	loss nan (nan)	prob nan (nan)	GS 36.453 (36.453)	mem 39.930
Train: [38][435/750]	BT 0.159 (1.166)	DT 0.026 (1.034)	loss nan (nan)	prob nan (nan)	GS 28.656 (28.656)	mem 39.996
Train: [38][440/750]	BT 9.931 (1.177)	DT 9.825 (1.045)	loss nan (nan)	prob nan (nan)	GS 37.281 (37.281)	mem 40.208
Train: [38][445/750]	BT 0.134 (1.165)	DT 0.017 (1.033)	loss nan (nan)	prob nan (nan)	GS 39.531 (39.531)	mem 40.008
Train: [38][450/750]	BT 0.120 (1.163)	DT 0.002 (1.031)	loss nan (nan)	prob nan (nan)	GS 29.297 (29.297)	mem 40.013
Train: [38][455/750]	BT 0.190 (1.166)	DT 0.006 (1.034)	loss nan (nan)	prob nan (nan)	GS 33.344 (33.344)	mem 40.070
Train: [38][460/750]	BT 0.231 (1.172)	DT 0.005 (1.040)	loss nan (nan)	prob nan (nan)	GS 35.609 (35.609)	mem 40.296
Train: [38][465/750]	BT 0.106 (1.164)	DT 0.002 (1.032)	loss nan (nan)	prob nan (nan)	GS 30.875 (30.875)	mem 40.048
Train: [38][470/750]	BT 9.664 (1.177)	DT 9.579 (1.045)	loss nan (nan)	prob nan (nan)	GS 36.141 (36.141)	mem 39.948
Train: [38][475/750]	BT 0.116 (1.166)	DT 0.001 (1.035)	loss nan (nan)	prob nan (nan)	GS 31.938 (31.938)	mem 39.952
Train: [38][480/750]	BT 5.147 (1.166)	DT 4.945 (1.034)	loss nan (nan)	prob nan (nan)	GS 34.906 (34.906)	mem 40.085
Train: [38][485/750]	BT 0.157 (1.175)	DT 0.004 (1.044)	loss nan (nan)	prob nan (nan)	GS 29.656 (29.656)	mem 40.092
Train: [38][490/750]	BT 0.115 (1.164)	DT 0.002 (1.033)	loss nan (nan)	prob nan (nan)	GS 30.031 (30.031)	mem 40.094
Train: [38][495/750]	BT 0.083 (1.176)	DT 0.001 (1.045)	loss nan (nan)	prob nan (nan)	GS 34.516 (34.516)	mem 40.004
Train: [38][500/750]	BT 0.208 (1.166)	DT 0.002 (1.035)	loss nan (nan)	prob nan (nan)	GS 35.406 (35.406)	mem 40.016
Train: [38][505/750]	BT 0.112 (1.156)	DT 0.006 (1.025)	loss nan (nan)	prob nan (nan)	GS 32.750 (32.750)	mem 40.022
Train: [38][510/750]	BT 0.113 (1.168)	DT 0.002 (1.037)	loss nan (nan)	prob nan (nan)	GS 31.391 (31.391)	mem 40.061
Train: [38][515/750]	BT 0.221 (1.158)	DT 0.001 (1.027)	loss nan (nan)	prob nan (nan)	GS 29.766 (29.766)	mem 40.063
Train: [38][520/750]	BT 0.080 (1.170)	DT 0.002 (1.039)	loss nan (nan)	prob nan (nan)	GS 35.328 (35.328)	mem 40.104
Train: [38][525/750]	BT 0.120 (1.160)	DT 0.002 (1.029)	loss nan (nan)	prob nan (nan)	GS 31.484 (31.484)	mem 40.269
Train: [38][530/750]	BT 13.397 (1.175)	DT 13.300 (1.045)	loss nan (nan)	prob nan (nan)	GS 40.297 (40.297)	mem 39.928
Train: [38][535/750]	BT 0.182 (1.166)	DT 0.002 (1.035)	loss nan (nan)	prob nan (nan)	GS 30.156 (30.156)	mem 39.932
Train: [38][540/750]	BT 0.086 (1.156)	DT 0.001 (1.025)	loss nan (nan)	prob nan (nan)	GS 34.766 (34.766)	mem 39.950
Train: [38][545/750]	BT 0.080 (1.172)	DT 0.001 (1.042)	loss nan (nan)	prob nan (nan)	GS 30.016 (30.016)	mem 40.097
Train: [38][550/750]	BT 0.223 (1.163)	DT 0.012 (1.033)	loss nan (nan)	prob nan (nan)	GS 38.266 (38.266)	mem 40.098
Train: [38][555/750]	BT 0.085 (1.170)	DT 0.001 (1.041)	loss nan (nan)	prob nan (nan)	GS 32.406 (32.406)	mem 40.077
Train: [38][560/750]	BT 0.086 (1.162)	DT 0.002 (1.031)	loss nan (nan)	prob nan (nan)	GS 37.156 (37.156)	mem 40.089
Train: [38][565/750]	BT 0.083 (1.152)	DT 0.002 (1.022)	loss nan (nan)	prob nan (nan)	GS 29.938 (29.938)	mem 40.045
Train: [38][570/750]	BT 0.162 (1.164)	DT 0.005 (1.034)	loss nan (nan)	prob nan (nan)	GS 32.047 (32.047)	mem 40.100
Train: [38][575/750]	BT 0.252 (1.156)	DT 0.005 (1.025)	loss nan (nan)	prob nan (nan)	GS 29.359 (29.359)	mem 40.130
Train: [38][580/750]	BT 0.165 (1.171)	DT 0.001 (1.040)	loss nan (nan)	prob nan (nan)	GS 32.078 (32.078)	mem 40.066
Train: [38][585/750]	BT 0.150 (1.162)	DT 0.002 (1.032)	loss nan (nan)	prob nan (nan)	GS 28.828 (28.828)	mem 40.186
Train: [38][590/750]	BT 12.372 (1.174)	DT 12.243 (1.044)	loss nan (nan)	prob nan (nan)	GS 35.750 (35.750)	mem 40.103
Train: [38][595/750]	BT 0.129 (1.165)	DT 0.012 (1.035)	loss nan (nan)	prob nan (nan)	GS 31.250 (31.250)	mem 40.135
Train: [38][600/750]	BT 0.147 (1.156)	DT 0.007 (1.026)	loss nan (nan)	prob nan (nan)	GS 35.750 (35.750)	mem 40.183
Train: [38][605/750]	BT 0.156 (1.167)	DT 0.011 (1.037)	loss nan (nan)	prob nan (nan)	GS 32.609 (32.609)	mem 40.101
Train: [38][610/750]	BT 0.107 (1.159)	DT 0.008 (1.029)	loss nan (nan)	prob nan (nan)	GS 34.500 (34.500)	mem 40.112
Train: [38][615/750]	BT 0.115 (1.168)	DT 0.019 (1.038)	loss nan (nan)	prob nan (nan)	GS 32.859 (32.859)	mem 40.146
Train: [38][620/750]	BT 0.089 (1.159)	DT 0.002 (1.029)	loss nan (nan)	prob nan (nan)	GS 36.781 (36.781)	mem 40.149
Train: [38][625/750]	BT 0.124 (1.151)	DT 0.002 (1.021)	loss nan (nan)	prob nan (nan)	GS 34.391 (34.391)	mem 40.158
Train: [38][630/750]	BT 0.140 (1.163)	DT 0.001 (1.033)	loss nan (nan)	prob nan (nan)	GS 31.562 (31.562)	mem 40.119
Train: [38][635/750]	BT 0.095 (1.155)	DT 0.002 (1.025)	loss nan (nan)	prob nan (nan)	GS 30.734 (30.734)	mem 40.121
Train: [38][640/750]	BT 0.094 (1.166)	DT 0.001 (1.036)	loss nan (nan)	prob nan (nan)	GS 28.719 (28.719)	mem 40.089
Train: [38][645/750]	BT 0.137 (1.158)	DT 0.002 (1.028)	loss nan (nan)	prob nan (nan)	GS 29.031 (29.031)	mem 40.090
Train: [38][650/750]	BT 13.147 (1.170)	DT 13.067 (1.040)	loss nan (nan)	prob nan (nan)	GS 35.531 (35.531)	mem 40.091
Train: [38][655/750]	BT 0.130 (1.162)	DT 0.001 (1.032)	loss nan (nan)	prob nan (nan)	GS 32.641 (32.641)	mem 40.038
Train: [38][660/750]	BT 0.285 (1.155)	DT 0.058 (1.025)	loss nan (nan)	prob nan (nan)	GS 27.656 (27.656)	mem 40.085
Train: [38][665/750]	BT 0.127 (1.160)	DT 0.001 (1.030)	loss nan (nan)	prob nan (nan)	GS 32.547 (32.547)	mem 40.281
Train: [38][670/750]	BT 0.084 (1.153)	DT 0.001 (1.022)	loss nan (nan)	prob nan (nan)	GS 34.094 (34.094)	mem 40.252
Train: [38][675/750]	BT 0.171 (1.160)	DT 0.002 (1.029)	loss nan (nan)	prob nan (nan)	GS 29.422 (29.422)	mem 40.062
Train: [38][680/750]	BT 1.297 (1.154)	DT 1.192 (1.024)	loss nan (nan)	prob nan (nan)	GS 33.781 (33.781)	mem 40.026
Train: [38][685/750]	BT 0.229 (1.147)	DT 0.002 (1.016)	loss nan (nan)	prob nan (nan)	GS 32.922 (32.922)	mem 40.189
Train: [38][690/750]	BT 0.223 (1.154)	DT 0.002 (1.023)	loss nan (nan)	prob nan (nan)	GS 32.094 (32.094)	mem 40.026
Train: [38][695/750]	BT 0.260 (1.147)	DT 0.027 (1.016)	loss nan (nan)	prob nan (nan)	GS 30.984 (30.984)	mem 40.032
Train: [38][700/750]	BT 5.463 (1.157)	DT 5.366 (1.025)	loss nan (nan)	prob nan (nan)	GS 35.672 (35.672)	mem 39.998
Train: [38][705/750]	BT 0.249 (1.149)	DT 0.005 (1.018)	loss nan (nan)	prob nan (nan)	GS 32.859 (32.859)	mem 39.987
arpack error, retry= 0
Train: [38][710/750]	BT 6.488 (1.151)	DT 6.345 (1.020)	loss nan (nan)	prob nan (nan)	GS 31.531 (31.531)	mem 40.119
Train: [38][715/750]	BT 0.199 (1.151)	DT 0.024 (1.019)	loss nan (nan)	prob nan (nan)	GS 36.516 (36.516)	mem 40.054
Train: [38][720/750]	BT 0.082 (1.144)	DT 0.001 (1.012)	loss nan (nan)	prob nan (nan)	GS 32.266 (32.266)	mem 40.223
Train: [38][725/750]	BT 0.084 (1.153)	DT 0.001 (1.021)	loss nan (nan)	prob nan (nan)	GS 31.172 (31.172)	mem 39.857
Train: [38][730/750]	BT 0.119 (1.146)	DT 0.002 (1.014)	loss nan (nan)	prob nan (nan)	GS 36.812 (36.812)	mem 39.937
Train: [38][735/750]	BT 0.146 (1.141)	DT 0.001 (1.010)	loss nan (nan)	prob nan (nan)	GS 34.766 (34.766)	mem 37.009
Train: [38][740/750]	BT 0.082 (1.143)	DT 0.002 (1.013)	loss nan (nan)	prob nan (nan)	GS 33.219 (33.219)	mem 19.411
Train: [38][745/750]	BT 0.067 (1.136)	DT 0.001 (1.006)	loss nan (nan)	prob nan (nan)	GS 31.812 (31.812)	mem 19.410
Train: [38][750/750]	BT 0.062 (1.131)	DT 0.001 (1.001)	loss nan (nan)	prob nan (nan)	GS 35.406 (35.406)	mem 10.542
Train: [38][755/750]	BT 0.082 (1.124)	DT 0.001 (0.994)	loss nan (nan)	prob nan (nan)	GS 38.625 (38.625)	mem 7.625
epoch 38, total time 848.84
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [39][1/750]	BT 22.040 (22.040)	DT 21.738 (21.738)	loss nan (nan)	prob nan (nan)	GS 31.422 (31.422)	mem 38.569
Train: [39][5/750]	BT 3.256 (5.362)	DT 3.138 (5.161)	loss nan (nan)	prob nan (nan)	GS 34.422 (34.422)	mem 38.926
Train: [39][10/750]	BT 0.150 (2.737)	DT 0.011 (2.583)	loss nan (nan)	prob nan (nan)	GS 36.172 (36.172)	mem 39.112
Train: [39][15/750]	BT 0.120 (2.417)	DT 0.007 (2.254)	loss nan (nan)	prob nan (nan)	GS 30.562 (30.562)	mem 39.602
Train: [39][20/750]	BT 0.183 (1.852)	DT 0.033 (1.693)	loss nan (nan)	prob nan (nan)	GS 31.078 (31.078)	mem 39.481
Train: [39][25/750]	BT 2.642 (1.617)	DT 2.437 (1.454)	loss nan (nan)	prob nan (nan)	GS 29.703 (29.703)	mem 39.508
Train: [39][30/750]	BT 0.103 (1.686)	DT 0.002 (1.524)	loss nan (nan)	prob nan (nan)	GS 31.391 (31.391)	mem 39.617
Train: [39][35/750]	BT 0.137 (1.463)	DT 0.010 (1.307)	loss nan (nan)	prob nan (nan)	GS 29.547 (29.547)	mem 39.747
Train: [39][40/750]	BT 0.156 (1.556)	DT 0.001 (1.403)	loss nan (nan)	prob nan (nan)	GS 31.188 (31.188)	mem 39.757
Train: [39][45/750]	BT 0.232 (1.424)	DT 0.010 (1.270)	loss nan (nan)	prob nan (nan)	GS 32.250 (32.250)	mem 39.715
Train: [39][50/750]	BT 6.084 (1.554)	DT 5.992 (1.404)	loss nan (nan)	prob nan (nan)	GS 33.516 (33.516)	mem 39.680
Train: [39][55/750]	BT 0.119 (1.423)	DT 0.003 (1.278)	loss nan (nan)	prob nan (nan)	GS 28.859 (28.859)	mem 39.683
Train: [39][60/750]	BT 7.127 (1.430)	DT 6.918 (1.287)	loss nan (nan)	prob nan (nan)	GS 32.109 (32.109)	mem 39.760
Train: [39][65/750]	BT 0.112 (1.448)	DT 0.010 (1.306)	loss nan (nan)	prob nan (nan)	GS 32.562 (32.562)	mem 39.752
Train: [39][70/750]	BT 0.175 (1.356)	DT 0.019 (1.213)	loss nan (nan)	prob nan (nan)	GS 33.141 (33.141)	mem 39.756
Train: [39][75/750]	BT 0.109 (1.423)	DT 0.001 (1.282)	loss nan (nan)	prob nan (nan)	GS 30.141 (30.141)	mem 39.820
Train: [39][80/750]	BT 0.096 (1.342)	DT 0.007 (1.202)	loss nan (nan)	prob nan (nan)	GS 30.812 (30.812)	mem 39.909
Train: [39][85/750]	BT 0.068 (1.325)	DT 0.001 (1.184)	loss nan (nan)	prob nan (nan)	GS 33.000 (33.000)	mem 39.872
Train: [39][90/750]	BT 0.183 (1.360)	DT 0.002 (1.220)	loss nan (nan)	prob nan (nan)	GS 35.875 (35.875)	mem 39.830
Train: [39][95/750]	BT 0.086 (1.296)	DT 0.003 (1.156)	loss nan (nan)	prob nan (nan)	GS 27.609 (27.609)	mem 39.840
Train: [39][100/750]	BT 0.090 (1.354)	DT 0.001 (1.215)	loss nan (nan)	prob nan (nan)	GS 33.328 (33.328)	mem 39.847
Train: [39][105/750]	BT 0.182 (1.297)	DT 0.002 (1.157)	loss nan (nan)	prob nan (nan)	GS 33.031 (33.031)	mem 40.072
Train: [39][110/750]	BT 8.018 (1.355)	DT 7.957 (1.214)	loss nan (nan)	prob nan (nan)	GS 31.703 (31.703)	mem 39.865
Train: [39][115/750]	BT 0.110 (1.300)	DT 0.001 (1.161)	loss nan (nan)	prob nan (nan)	GS 33.000 (33.000)	mem 39.888
Train: [39][120/750]	BT 3.881 (1.283)	DT 3.639 (1.143)	loss nan (nan)	prob nan (nan)	GS 35.047 (35.047)	mem 39.876
Train: [39][125/750]	BT 0.127 (1.301)	DT 0.002 (1.163)	loss nan (nan)	prob nan (nan)	GS 35.469 (35.469)	mem 39.919
Train: [39][130/750]	BT 2.130 (1.272)	DT 1.948 (1.133)	loss nan (nan)	prob nan (nan)	GS 34.234 (34.234)	mem 39.766
Train: [39][135/750]	BT 0.201 (1.278)	DT 0.011 (1.139)	loss nan (nan)	prob nan (nan)	GS 31.141 (31.141)	mem 39.980
Train: [39][140/750]	BT 0.147 (1.236)	DT 0.022 (1.098)	loss nan (nan)	prob nan (nan)	GS 34.984 (34.984)	mem 39.954
Train: [39][145/750]	BT 0.182 (1.265)	DT 0.007 (1.127)	loss nan (nan)	prob nan (nan)	GS 31.406 (31.406)	mem 40.085
Train: [39][150/750]	BT 0.157 (1.255)	DT 0.002 (1.117)	loss nan (nan)	prob nan (nan)	GS 34.406 (34.406)	mem 39.939
Train: [39][155/750]	BT 0.289 (1.249)	DT 0.002 (1.110)	loss nan (nan)	prob nan (nan)	GS 30.125 (30.125)	mem 39.923
Train: [39][160/750]	BT 0.230 (1.270)	DT 0.002 (1.131)	loss nan (nan)	prob nan (nan)	GS 30.500 (30.500)	mem 40.207
Train: [39][165/750]	BT 0.227 (1.236)	DT 0.002 (1.097)	loss nan (nan)	prob nan (nan)	GS 36.344 (36.344)	mem 40.099
Train: [39][170/750]	BT 3.647 (1.281)	DT 3.478 (1.141)	loss nan (nan)	prob nan (nan)	GS 39.000 (39.000)	mem 40.018
Train: [39][175/750]	BT 0.107 (1.249)	DT 0.002 (1.109)	loss nan (nan)	prob nan (nan)	GS 29.562 (29.562)	mem 40.020
Train: [39][180/750]	BT 9.672 (1.273)	DT 9.557 (1.132)	loss nan (nan)	prob nan (nan)	GS 35.484 (35.484)	mem 39.963
Train: [39][185/750]	BT 0.208 (1.247)	DT 0.029 (1.107)	loss nan (nan)	prob nan (nan)	GS 30.734 (30.734)	mem 39.993
Train: [39][190/750]	BT 0.204 (1.218)	DT 0.030 (1.078)	loss nan (nan)	prob nan (nan)	GS 36.203 (36.203)	mem 39.998
Train: [39][195/750]	BT 0.088 (1.253)	DT 0.002 (1.114)	loss nan (nan)	prob nan (nan)	GS 31.156 (31.156)	mem 40.248
Train: [39][200/750]	BT 0.111 (1.225)	DT 0.011 (1.086)	loss nan (nan)	prob nan (nan)	GS 37.234 (37.234)	mem 40.104
Train: [39][205/750]	BT 0.120 (1.234)	DT 0.002 (1.095)	loss nan (nan)	prob nan (nan)	GS 28.562 (28.562)	mem 40.051
Train: [39][210/750]	BT 0.126 (1.239)	DT 0.002 (1.101)	loss nan (nan)	prob nan (nan)	GS 31.547 (31.547)	mem 40.012
Train: [39][215/750]	BT 0.273 (1.214)	DT 0.004 (1.076)	loss nan (nan)	prob nan (nan)	GS 29.984 (29.984)	mem 40.013
Train: [39][220/750]	BT 0.104 (1.254)	DT 0.007 (1.115)	loss nan (nan)	prob nan (nan)	GS 37.000 (37.000)	mem 39.890
Train: [39][225/750]	BT 0.093 (1.229)	DT 0.002 (1.091)	loss nan (nan)	prob nan (nan)	GS 35.125 (35.125)	mem 40.000
Train: [39][230/750]	BT 5.339 (1.262)	DT 5.266 (1.124)	loss nan (nan)	prob nan (nan)	GS 34.797 (34.797)	mem 40.069
Train: [39][235/750]	BT 0.116 (1.238)	DT 0.004 (1.100)	loss nan (nan)	prob nan (nan)	GS 33.219 (33.219)	mem 40.020
Train: [39][240/750]	BT 4.991 (1.235)	DT 4.759 (1.097)	loss nan (nan)	prob nan (nan)	GS 34.859 (34.859)	mem 39.992
Train: [39][245/750]	BT 0.105 (1.231)	DT 0.011 (1.093)	loss nan (nan)	prob nan (nan)	GS 40.297 (40.297)	mem 40.047
Train: [39][250/750]	BT 0.194 (1.209)	DT 0.024 (1.071)	loss nan (nan)	prob nan (nan)	GS 37.250 (37.250)	mem 40.100
Train: [39][255/750]	BT 0.113 (1.224)	DT 0.002 (1.087)	loss nan (nan)	prob nan (nan)	GS 32.750 (32.750)	mem 40.129
Train: [39][260/750]	BT 0.115 (1.204)	DT 0.005 (1.066)	loss nan (nan)	prob nan (nan)	GS 38.641 (38.641)	mem 40.078
Train: [39][265/750]	BT 0.080 (1.233)	DT 0.002 (1.095)	loss nan (nan)	prob nan (nan)	GS 37.281 (37.281)	mem 39.932
Train: [39][270/750]	BT 0.169 (1.212)	DT 0.002 (1.075)	loss nan (nan)	prob nan (nan)	GS 34.656 (34.656)	mem 39.926
Train: [39][275/750]	BT 0.183 (1.217)	DT 0.002 (1.079)	loss nan (nan)	prob nan (nan)	GS 29.984 (29.984)	mem 39.957
Train: [39][280/750]	BT 2.210 (1.210)	DT 2.120 (1.073)	loss nan (nan)	prob nan (nan)	GS 35.141 (35.141)	mem 40.141
Train: [39][285/750]	BT 0.107 (1.191)	DT 0.009 (1.054)	loss nan (nan)	prob nan (nan)	GS 30.984 (30.984)	mem 40.106
Train: [39][290/750]	BT 1.263 (1.213)	DT 1.134 (1.076)	loss nan (nan)	prob nan (nan)	GS 37.828 (37.828)	mem 40.062
Train: [39][295/750]	BT 0.291 (1.201)	DT 0.020 (1.064)	loss nan (nan)	prob nan (nan)	GS 33.797 (33.797)	mem 40.025
Train: [39][300/750]	BT 0.116 (1.220)	DT 0.011 (1.083)	loss nan (nan)	prob nan (nan)	GS 32.531 (32.531)	mem 40.092
Train: [39][305/750]	BT 0.087 (1.207)	DT 0.002 (1.071)	loss nan (nan)	prob nan (nan)	GS 30.328 (30.328)	mem 39.999
Train: [39][310/750]	BT 8.346 (1.216)	DT 8.245 (1.080)	loss nan (nan)	prob nan (nan)	GS 32.875 (32.875)	mem 39.979
Train: [39][315/750]	BT 0.173 (1.212)	DT 0.010 (1.076)	loss nan (nan)	prob nan (nan)	GS 31.172 (31.172)	mem 39.991
Train: [39][320/750]	BT 0.180 (1.195)	DT 0.024 (1.059)	loss nan (nan)	prob nan (nan)	GS 34.828 (34.828)	mem 39.991
Train: [39][325/750]	BT 0.152 (1.204)	DT 0.002 (1.066)	loss nan (nan)	prob nan (nan)	GS 31.594 (31.594)	mem 40.060
Train: [39][330/750]	BT 0.225 (1.199)	DT 0.009 (1.062)	loss nan (nan)	prob nan (nan)	GS 36.109 (36.109)	mem 39.879
Train: [39][335/750]	BT 0.249 (1.204)	DT 0.002 (1.066)	loss nan (nan)	prob nan (nan)	GS 30.047 (30.047)	mem 39.954
Train: [39][340/750]	BT 0.189 (1.206)	DT 0.064 (1.069)	loss nan (nan)	prob nan (nan)	GS 31.094 (31.094)	mem 40.182
Train: [39][345/750]	BT 0.141 (1.190)	DT 0.017 (1.053)	loss nan (nan)	prob nan (nan)	GS 33.031 (33.031)	mem 40.000
Train: [39][350/750]	BT 8.402 (1.209)	DT 8.300 (1.072)	loss nan (nan)	prob nan (nan)	GS 30.781 (30.781)	mem 39.965
Train: [39][355/750]	BT 0.132 (1.194)	DT 0.006 (1.057)	loss nan (nan)	prob nan (nan)	GS 30.688 (30.688)	mem 39.967
Train: [39][360/750]	BT 0.148 (1.190)	DT 0.002 (1.052)	loss nan (nan)	prob nan (nan)	GS 34.078 (34.078)	mem 39.972
Train: [39][365/750]	BT 0.150 (1.196)	DT 0.002 (1.058)	loss nan (nan)	prob nan (nan)	GS 31.656 (31.656)	mem 40.057
Train: [39][370/750]	BT 2.911 (1.189)	DT 2.724 (1.051)	loss nan (nan)	prob nan (nan)	GS 31.453 (31.453)	mem 40.128
Train: [39][375/750]	BT 0.121 (1.208)	DT 0.011 (1.070)	loss nan (nan)	prob nan (nan)	GS 30.938 (30.938)	mem 39.958
Train: [39][380/750]	BT 0.218 (1.194)	DT 0.009 (1.056)	loss nan (nan)	prob nan (nan)	GS 34.938 (34.938)	mem 40.057
Train: [39][385/750]	BT 0.107 (1.180)	DT 0.010 (1.043)	loss nan (nan)	prob nan (nan)	GS 29.094 (29.094)	mem 40.055
Train: [39][390/750]	BT 0.106 (1.197)	DT 0.016 (1.059)	loss nan (nan)	prob nan (nan)	GS 32.188 (32.188)	mem 40.079
Train: [39][395/750]	BT 0.119 (1.183)	DT 0.002 (1.046)	loss nan (nan)	prob nan (nan)	GS 37.438 (37.438)	mem 40.082
Train: [39][400/750]	BT 0.208 (1.193)	DT 0.002 (1.056)	loss nan (nan)	prob nan (nan)	GS 34.047 (34.047)	mem 40.036
Train: [39][405/750]	BT 0.194 (1.180)	DT 0.027 (1.043)	loss nan (nan)	prob nan (nan)	GS 33.938 (33.938)	mem 39.976
Train: [39][410/750]	BT 9.819 (1.191)	DT 9.730 (1.054)	loss nan (nan)	prob nan (nan)	GS 28.828 (28.828)	mem 40.046
Train: [39][415/750]	BT 0.125 (1.187)	DT 0.002 (1.050)	loss nan (nan)	prob nan (nan)	GS 29.484 (29.484)	mem 39.984
Train: [39][420/750]	BT 0.103 (1.174)	DT 0.005 (1.037)	loss nan (nan)	prob nan (nan)	GS 33.812 (33.812)	mem 39.997
Train: [39][425/750]	BT 0.093 (1.191)	DT 0.001 (1.053)	loss nan (nan)	prob nan (nan)	GS 34.969 (34.969)	mem 40.034
Train: [39][430/750]	BT 0.146 (1.178)	DT 0.001 (1.041)	loss nan (nan)	prob nan (nan)	GS 36.172 (36.172)	mem 39.917
Train: [39][435/750]	BT 0.212 (1.177)	DT 0.026 (1.040)	loss nan (nan)	prob nan (nan)	GS 28.047 (28.047)	mem 40.104
Train: [39][440/750]	BT 0.092 (1.185)	DT 0.002 (1.048)	loss nan (nan)	prob nan (nan)	GS 30.516 (30.516)	mem 39.945
Train: [39][445/750]	BT 0.107 (1.173)	DT 0.002 (1.036)	loss nan (nan)	prob nan (nan)	GS 32.453 (32.453)	mem 39.977
Train: [39][450/750]	BT 2.744 (1.192)	DT 2.624 (1.055)	loss nan (nan)	prob nan (nan)	GS 31.766 (31.766)	mem 39.961
Train: [39][455/750]	BT 0.213 (1.181)	DT 0.002 (1.043)	loss nan (nan)	prob nan (nan)	GS 35.141 (35.141)	mem 39.962
Train: [39][460/750]	BT 9.997 (1.192)	DT 9.799 (1.054)	loss nan (nan)	prob nan (nan)	GS 32.188 (32.188)	mem 40.060
Train: [39][465/750]	BT 0.161 (1.187)	DT 0.001 (1.049)	loss nan (nan)	prob nan (nan)	GS 27.906 (27.906)	mem 40.108
Train: [39][470/750]	BT 0.089 (1.175)	DT 0.001 (1.038)	loss nan (nan)	prob nan (nan)	GS 32.719 (32.719)	mem 40.001
Train: [39][475/750]	BT 0.174 (1.188)	DT 0.002 (1.050)	loss nan (nan)	prob nan (nan)	GS 38.734 (38.734)	mem 40.023
Train: [39][480/750]	BT 0.082 (1.181)	DT 0.001 (1.044)	loss nan (nan)	prob nan (nan)	GS 34.641 (34.641)	mem 40.025
Train: [39][485/750]	BT 0.083 (1.184)	DT 0.001 (1.047)	loss nan (nan)	prob nan (nan)	GS 31.328 (31.328)	mem 40.007
Train: [39][490/750]	BT 0.086 (1.184)	DT 0.002 (1.047)	loss nan (nan)	prob nan (nan)	GS 32.234 (32.234)	mem 40.009
Train: [39][495/750]	BT 0.176 (1.174)	DT 0.001 (1.037)	loss nan (nan)	prob nan (nan)	GS 31.344 (31.344)	mem 40.209
Train: [39][500/750]	BT 0.096 (1.189)	DT 0.001 (1.051)	loss nan (nan)	prob nan (nan)	GS 35.703 (35.703)	mem 40.047
Train: [39][505/750]	BT 0.106 (1.178)	DT 0.010 (1.041)	loss nan (nan)	prob nan (nan)	GS 28.609 (28.609)	mem 40.086
Train: [39][510/750]	BT 7.275 (1.188)	DT 7.124 (1.051)	loss nan (nan)	prob nan (nan)	GS 33.047 (33.047)	mem 40.149
Train: [39][515/750]	BT 0.120 (1.177)	DT 0.006 (1.040)	loss nan (nan)	prob nan (nan)	GS 30.578 (30.578)	mem 40.058
Train: [39][520/750]	BT 2.071 (1.171)	DT 1.820 (1.034)	loss nan (nan)	prob nan (nan)	GS 30.016 (30.016)	mem 40.000
Train: [39][525/750]	BT 0.130 (1.176)	DT 0.010 (1.039)	loss nan (nan)	prob nan (nan)	GS 33.281 (33.281)	mem 40.021
Train: [39][530/750]	BT 0.131 (1.169)	DT 0.002 (1.033)	loss nan (nan)	prob nan (nan)	GS 34.891 (34.891)	mem 40.030
Train: [39][535/750]	BT 0.233 (1.177)	DT 0.003 (1.040)	loss nan (nan)	prob nan (nan)	GS 31.844 (31.844)	mem 39.989
Train: [39][540/750]	BT 0.156 (1.177)	DT 0.005 (1.040)	loss nan (nan)	prob nan (nan)	GS 33.125 (33.125)	mem 39.986
Train: [39][545/750]	BT 0.181 (1.168)	DT 0.002 (1.030)	loss nan (nan)	prob nan (nan)	GS 31.188 (31.188)	mem 39.923
Train: [39][550/750]	BT 4.621 (1.175)	DT 4.529 (1.037)	loss nan (nan)	prob nan (nan)	GS 29.688 (29.688)	mem 40.020
Train: [39][555/750]	BT 0.135 (1.165)	DT 0.007 (1.028)	loss nan (nan)	prob nan (nan)	GS 31.797 (31.797)	mem 39.912
Train: [39][560/750]	BT 0.092 (1.172)	DT 0.002 (1.035)	loss nan (nan)	prob nan (nan)	GS 33.172 (33.172)	mem 39.992
Train: [39][565/750]	BT 0.075 (1.172)	DT 0.001 (1.035)	loss nan (nan)	prob nan (nan)	GS 30.062 (30.062)	mem 39.971
Train: [39][570/750]	BT 3.247 (1.168)	DT 3.125 (1.031)	loss nan (nan)	prob nan (nan)	GS 36.031 (36.031)	mem 40.089
Train: [39][575/750]	BT 0.081 (1.174)	DT 0.002 (1.037)	loss nan (nan)	prob nan (nan)	GS 33.438 (33.438)	mem 39.985
Train: [39][580/750]	BT 0.130 (1.165)	DT 0.001 (1.028)	loss nan (nan)	prob nan (nan)	GS 37.312 (37.312)	mem 40.003
Train: [39][585/750]	BT 0.115 (1.161)	DT 0.002 (1.024)	loss nan (nan)	prob nan (nan)	GS 32.203 (32.203)	mem 40.014
Train: [39][590/750]	BT 0.121 (1.166)	DT 0.001 (1.030)	loss nan (nan)	prob nan (nan)	GS 31.953 (31.953)	mem 40.020
Train: [39][595/750]	BT 0.144 (1.166)	DT 0.002 (1.029)	loss nan (nan)	prob nan (nan)	GS 30.219 (30.219)	mem 39.962
Train: [39][600/750]	BT 0.085 (1.164)	DT 0.001 (1.028)	loss nan (nan)	prob nan (nan)	GS 33.188 (33.188)	mem 40.039
Train: [39][605/750]	BT 0.179 (1.156)	DT 0.014 (1.019)	loss nan (nan)	prob nan (nan)	GS 31.328 (31.328)	mem 40.127
Train: [39][610/750]	BT 3.212 (1.165)	DT 2.996 (1.028)	loss nan (nan)	prob nan (nan)	GS 33.844 (33.844)	mem 40.145
Train: [39][615/750]	BT 0.136 (1.157)	DT 0.011 (1.020)	loss nan (nan)	prob nan (nan)	GS 32.891 (32.891)	mem 40.029
Train: [39][620/750]	BT 0.096 (1.164)	DT 0.003 (1.027)	loss nan (nan)	prob nan (nan)	GS 33.688 (33.688)	mem 40.033
Train: [39][625/750]	BT 0.104 (1.156)	DT 0.002 (1.019)	loss nan (nan)	prob nan (nan)	GS 30.641 (30.641)	mem 40.032
Train: [39][630/750]	BT 10.701 (1.168)	DT 10.627 (1.032)	loss nan (nan)	prob nan (nan)	GS 32.984 (32.984)	mem 40.085
Train: [39][635/750]	BT 0.193 (1.162)	DT 0.023 (1.025)	loss nan (nan)	prob nan (nan)	GS 29.562 (29.562)	mem 40.031
Train: [39][640/750]	BT 0.384 (1.155)	DT 0.211 (1.018)	loss nan (nan)	prob nan (nan)	GS 31.578 (31.578)	mem 40.030
Train: [39][645/750]	BT 0.103 (1.161)	DT 0.009 (1.024)	loss nan (nan)	prob nan (nan)	GS 28.938 (28.938)	mem 40.008
Train: [39][650/750]	BT 0.145 (1.153)	DT 0.001 (1.016)	loss nan (nan)	prob nan (nan)	GS 32.672 (32.672)	mem 40.010
Train: [39][655/750]	BT 0.116 (1.163)	DT 0.002 (1.026)	loss nan (nan)	prob nan (nan)	GS 28.828 (28.828)	mem 40.034
Train: [39][660/750]	BT 0.164 (1.155)	DT 0.010 (1.018)	loss nan (nan)	prob nan (nan)	GS 31.875 (31.875)	mem 40.090
Train: [39][665/750]	BT 0.161 (1.151)	DT 0.002 (1.015)	loss nan (nan)	prob nan (nan)	GS 34.516 (34.516)	mem 40.045
Train: [39][670/750]	BT 0.111 (1.156)	DT 0.015 (1.020)	loss nan (nan)	prob nan (nan)	GS 34.188 (34.188)	mem 40.100
Train: [39][675/750]	BT 0.122 (1.148)	DT 0.002 (1.012)	loss nan (nan)	prob nan (nan)	GS 28.625 (28.625)	mem 40.047
Train: [39][680/750]	BT 2.167 (1.159)	DT 2.092 (1.023)	loss nan (nan)	prob nan (nan)	GS 32.969 (32.969)	mem 40.186
Train: [39][685/750]	BT 0.166 (1.152)	DT 0.005 (1.016)	loss nan (nan)	prob nan (nan)	GS 33.438 (33.438)	mem 40.119
Train: [39][690/750]	BT 7.277 (1.158)	DT 7.125 (1.022)	loss nan (nan)	prob nan (nan)	GS 33.234 (33.234)	mem 40.244
Train: [39][695/750]	BT 0.112 (1.152)	DT 0.001 (1.016)	loss nan (nan)	prob nan (nan)	GS 30.141 (30.141)	mem 40.047
Train: [39][700/750]	BT 5.313 (1.153)	DT 5.215 (1.017)	loss nan (nan)	prob nan (nan)	GS 30.016 (30.016)	mem 40.181
Train: [39][705/750]	BT 0.149 (1.154)	DT 0.002 (1.018)	loss nan (nan)	prob nan (nan)	GS 32.609 (32.609)	mem 40.050
arpack error, retry= 0
Train: [39][710/750]	BT 0.145 (1.149)	DT 0.002 (1.014)	loss nan (nan)	prob nan (nan)	GS 34.750 (34.750)	mem 40.097
Train: [39][715/750]	BT 0.084 (1.160)	DT 0.002 (1.025)	loss nan (nan)	prob nan (nan)	GS 27.891 (27.891)	mem 40.059
Train: [39][720/750]	BT 0.264 (1.153)	DT 0.015 (1.018)	loss nan (nan)	prob nan (nan)	GS 35.516 (35.516)	mem 39.993
Train: [39][725/750]	BT 0.136 (1.152)	DT 0.001 (1.016)	loss nan (nan)	prob nan (nan)	GS 27.578 (27.578)	mem 40.051
Train: [39][730/750]	BT 0.153 (1.155)	DT 0.001 (1.020)	loss nan (nan)	prob nan (nan)	GS 34.375 (34.375)	mem 40.001
Train: [39][735/750]	BT 0.119 (1.149)	DT 0.002 (1.013)	loss nan (nan)	prob nan (nan)	GS 30.375 (30.375)	mem 39.983
Train: [39][740/750]	BT 0.130 (1.152)	DT 0.009 (1.017)	loss nan (nan)	prob nan (nan)	GS 30.812 (30.812)	mem 16.652
Train: [39][745/750]	BT 0.102 (1.145)	DT 0.001 (1.010)	loss nan (nan)	prob nan (nan)	GS 35.156 (35.156)	mem 16.614
Train: [39][750/750]	BT 2.725 (1.142)	DT 2.658 (1.007)	loss nan (nan)	prob nan (nan)	GS 39.438 (39.438)	mem 10.667
Train: [39][755/750]	BT 0.065 (1.135)	DT 0.001 (1.000)	loss nan (nan)	prob nan (nan)	GS 33.781 (33.781)	mem 10.631
epoch 39, total time 856.92
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [40][1/750]	BT 21.057 (21.057)	DT 20.773 (20.773)	loss nan (nan)	prob nan (nan)	GS 30.734 (30.734)	mem 38.470
Train: [40][5/750]	BT 0.142 (4.323)	DT 0.002 (4.164)	loss nan (nan)	prob nan (nan)	GS 29.891 (29.891)	mem 38.433
Train: [40][10/750]	BT 0.098 (2.358)	DT 0.001 (2.230)	loss nan (nan)	prob nan (nan)	GS 33.812 (33.812)	mem 38.587
Train: [40][15/750]	BT 1.999 (2.112)	DT 1.849 (1.970)	loss nan (nan)	prob nan (nan)	GS 28.984 (28.984)	mem 38.710
Train: [40][20/750]	BT 0.096 (1.871)	DT 0.001 (1.730)	loss nan (nan)	prob nan (nan)	GS 28.859 (28.859)	mem 38.818
Train: [40][25/750]	BT 1.016 (1.565)	DT 0.912 (1.421)	loss nan (nan)	prob nan (nan)	GS 32.234 (32.234)	mem 38.806
Train: [40][30/750]	BT 0.232 (1.765)	DT 0.005 (1.616)	loss nan (nan)	prob nan (nan)	GS 32.750 (32.750)	mem 39.043
Train: [40][35/750]	BT 0.108 (1.533)	DT 0.002 (1.386)	loss nan (nan)	prob nan (nan)	GS 29.203 (29.203)	mem 39.062
Train: [40][40/750]	BT 9.540 (1.704)	DT 9.367 (1.554)	loss nan (nan)	prob nan (nan)	GS 35.828 (35.828)	mem 39.061
Train: [40][45/750]	BT 0.097 (1.530)	DT 0.001 (1.382)	loss nan (nan)	prob nan (nan)	GS 27.953 (27.953)	mem 39.074
Train: [40][50/750]	BT 3.493 (1.464)	DT 3.362 (1.312)	loss nan (nan)	prob nan (nan)	GS 35.188 (35.188)	mem 39.128
Train: [40][55/750]	BT 0.108 (1.512)	DT 0.001 (1.365)	loss nan (nan)	prob nan (nan)	GS 35.266 (35.266)	mem 39.148
Train: [40][60/750]	BT 0.144 (1.399)	DT 0.014 (1.252)	loss nan (nan)	prob nan (nan)	GS 32.891 (32.891)	mem 39.200
Train: [40][65/750]	BT 0.119 (1.435)	DT 0.001 (1.289)	loss nan (nan)	prob nan (nan)	GS 36.078 (36.078)	mem 39.206
Train: [40][70/750]	BT 0.093 (1.345)	DT 0.011 (1.198)	loss nan (nan)	prob nan (nan)	GS 34.906 (34.906)	mem 39.126
Train: [40][75/750]	BT 0.114 (1.310)	DT 0.005 (1.163)	loss nan (nan)	prob nan (nan)	GS 32.984 (32.984)	mem 39.159
Train: [40][80/750]	BT 0.117 (1.332)	DT 0.001 (1.186)	loss nan (nan)	prob nan (nan)	GS 35.281 (35.281)	mem 39.323
Train: [40][85/750]	BT 0.118 (1.264)	DT 0.007 (1.117)	loss nan (nan)	prob nan (nan)	GS 32.719 (32.719)	mem 39.171
Train: [40][90/750]	BT 0.165 (1.391)	DT 0.004 (1.244)	loss nan (nan)	prob nan (nan)	GS 33.547 (33.547)	mem 39.294
Train: [40][95/750]	BT 0.103 (1.324)	DT 0.008 (1.179)	loss nan (nan)	prob nan (nan)	GS 29.719 (29.719)	mem 39.264
Train: [40][100/750]	BT 7.984 (1.354)	DT 7.882 (1.209)	loss nan (nan)	prob nan (nan)	GS 33.828 (33.828)	mem 39.345
Train: [40][105/750]	BT 0.158 (1.297)	DT 0.010 (1.152)	loss nan (nan)	prob nan (nan)	GS 35.328 (35.328)	mem 39.352
Train: [40][110/750]	BT 4.485 (1.284)	DT 4.306 (1.139)	loss nan (nan)	prob nan (nan)	GS 37.406 (37.406)	mem 39.313
Train: [40][115/750]	BT 0.152 (1.308)	DT 0.002 (1.164)	loss nan (nan)	prob nan (nan)	GS 32.984 (32.984)	mem 39.403
Train: [40][120/750]	BT 0.123 (1.259)	DT 0.004 (1.116)	loss nan (nan)	prob nan (nan)	GS 33.828 (33.828)	mem 39.337
Train: [40][125/750]	BT 0.089 (1.327)	DT 0.002 (1.186)	loss nan (nan)	prob nan (nan)	GS 33.516 (33.516)	mem 39.412
Train: [40][130/750]	BT 0.088 (1.293)	DT 0.001 (1.154)	loss nan (nan)	prob nan (nan)	GS 33.922 (33.922)	mem 39.297
Train: [40][135/750]	BT 0.207 (1.294)	DT 0.002 (1.155)	loss nan (nan)	prob nan (nan)	GS 28.531 (28.531)	mem 39.401
Train: [40][140/750]	BT 0.203 (1.272)	DT 0.015 (1.134)	loss nan (nan)	prob nan (nan)	GS 34.469 (34.469)	mem 39.467
Train: [40][145/750]	BT 0.097 (1.232)	DT 0.002 (1.095)	loss nan (nan)	prob nan (nan)	GS 31.500 (31.500)	mem 39.387
Train: [40][150/750]	BT 2.354 (1.267)	DT 2.214 (1.130)	loss nan (nan)	prob nan (nan)	GS 36.078 (36.078)	mem 39.436
Train: [40][155/750]	BT 0.129 (1.230)	DT 0.014 (1.093)	loss nan (nan)	prob nan (nan)	GS 28.484 (28.484)	mem 39.462
Train: [40][160/750]	BT 0.106 (1.283)	DT 0.002 (1.147)	loss nan (nan)	prob nan (nan)	GS 31.344 (31.344)	mem 39.527
Train: [40][165/750]	BT 0.124 (1.248)	DT 0.002 (1.113)	loss nan (nan)	prob nan (nan)	GS 32.234 (32.234)	mem 39.540
Train: [40][170/750]	BT 11.159 (1.280)	DT 11.026 (1.145)	loss nan (nan)	prob nan (nan)	GS 32.406 (32.406)	mem 39.818
Train: [40][175/750]	BT 0.107 (1.248)	DT 0.005 (1.113)	loss nan (nan)	prob nan (nan)	GS 32.938 (32.938)	mem 39.803
Train: [40][180/750]	BT 0.301 (1.219)	DT 0.002 (1.082)	loss nan (nan)	prob nan (nan)	GS 35.250 (35.250)	mem 39.804
Train: [40][185/750]	BT 0.124 (1.259)	DT 0.002 (1.122)	loss nan (nan)	prob nan (nan)	GS 32.781 (32.781)	mem 39.730
Train: [40][190/750]	BT 0.130 (1.229)	DT 0.005 (1.092)	loss nan (nan)	prob nan (nan)	GS 38.188 (38.188)	mem 39.596
Train: [40][195/750]	BT 0.110 (1.274)	DT 0.002 (1.137)	loss nan (nan)	prob nan (nan)	GS 35.078 (35.078)	mem 39.678
Train: [40][200/750]	BT 0.097 (1.245)	DT 0.002 (1.109)	loss nan (nan)	prob nan (nan)	GS 36.516 (36.516)	mem 39.680
Train: [40][205/750]	BT 0.143 (1.218)	DT 0.002 (1.082)	loss nan (nan)	prob nan (nan)	GS 30.609 (30.609)	mem 39.681
Train: [40][210/750]	BT 0.084 (1.247)	DT 0.001 (1.112)	loss nan (nan)	prob nan (nan)	GS 34.000 (34.000)	mem 39.847
Train: [40][215/750]	BT 0.225 (1.221)	DT 0.010 (1.086)	loss nan (nan)	prob nan (nan)	GS 30.219 (30.219)	mem 40.016
Train: [40][220/750]	BT 0.140 (1.249)	DT 0.010 (1.115)	loss nan (nan)	prob nan (nan)	GS 34.938 (34.938)	mem 39.779
Train: [40][225/750]	BT 0.177 (1.225)	DT 0.005 (1.090)	loss nan (nan)	prob nan (nan)	GS 30.234 (30.234)	mem 39.950
Train: [40][230/750]	BT 12.811 (1.257)	DT 12.744 (1.122)	loss nan (nan)	prob nan (nan)	GS 33.000 (33.000)	mem 39.970
Train: [40][235/750]	BT 0.142 (1.233)	DT 0.007 (1.098)	loss nan (nan)	prob nan (nan)	GS 34.141 (34.141)	mem 39.749
Train: [40][240/750]	BT 0.161 (1.210)	DT 0.007 (1.075)	loss nan (nan)	prob nan (nan)	GS 35.891 (35.891)	mem 39.752
Train: [40][245/750]	BT 0.067 (1.233)	DT 0.001 (1.100)	loss nan (nan)	prob nan (nan)	GS 26.156 (26.156)	mem 39.813
Train: [40][250/750]	BT 0.131 (1.211)	DT 0.010 (1.078)	loss nan (nan)	prob nan (nan)	GS 35.531 (35.531)	mem 39.850
Train: [40][255/750]	BT 0.075 (1.233)	DT 0.001 (1.100)	loss nan (nan)	prob nan (nan)	GS 31.406 (31.406)	mem 39.823
Train: [40][260/750]	BT 0.173 (1.212)	DT 0.002 (1.079)	loss nan (nan)	prob nan (nan)	GS 32.812 (32.812)	mem 39.824
Train: [40][265/750]	BT 0.167 (1.192)	DT 0.001 (1.058)	loss nan (nan)	prob nan (nan)	GS 31.312 (31.312)	mem 39.935
Train: [40][270/750]	BT 0.140 (1.220)	DT 0.001 (1.087)	loss nan (nan)	prob nan (nan)	GS 32.125 (32.125)	mem 39.806
Train: [40][275/750]	BT 0.091 (1.200)	DT 0.002 (1.067)	loss nan (nan)	prob nan (nan)	GS 32.875 (32.875)	mem 39.827
Train: [40][280/750]	BT 0.197 (1.218)	DT 0.002 (1.086)	loss nan (nan)	prob nan (nan)	GS 32.328 (32.328)	mem 40.043
Train: [40][285/750]	BT 0.078 (1.199)	DT 0.001 (1.067)	loss nan (nan)	prob nan (nan)	GS 38.578 (38.578)	mem 39.937
Train: [40][290/750]	BT 10.107 (1.214)	DT 9.950 (1.083)	loss nan (nan)	prob nan (nan)	GS 35.969 (35.969)	mem 39.946
Train: [40][295/750]	BT 0.177 (1.196)	DT 0.002 (1.065)	loss nan (nan)	prob nan (nan)	GS 32.422 (32.422)	mem 39.948
Train: [40][300/750]	BT 0.126 (1.179)	DT 0.002 (1.047)	loss nan (nan)	prob nan (nan)	GS 31.453 (31.453)	mem 39.947
Train: [40][305/750]	BT 0.170 (1.204)	DT 0.002 (1.072)	loss nan (nan)	prob nan (nan)	GS 32.047 (32.047)	mem 40.221
Train: [40][310/750]	BT 0.110 (1.187)	DT 0.002 (1.055)	loss nan (nan)	prob nan (nan)	GS 35.938 (35.938)	mem 39.931
Train: [40][315/750]	BT 0.159 (1.205)	DT 0.007 (1.074)	loss nan (nan)	prob nan (nan)	GS 29.406 (29.406)	mem 39.812
Train: [40][320/750]	BT 0.090 (1.188)	DT 0.009 (1.057)	loss nan (nan)	prob nan (nan)	GS 30.328 (30.328)	mem 39.752
Train: [40][325/750]	BT 0.142 (1.171)	DT 0.012 (1.041)	loss nan (nan)	prob nan (nan)	GS 35.359 (35.359)	mem 39.758
Train: [40][330/750]	BT 0.138 (1.198)	DT 0.001 (1.067)	loss nan (nan)	prob nan (nan)	GS 33.500 (33.500)	mem 39.887
Train: [40][335/750]	BT 0.161 (1.183)	DT 0.002 (1.052)	loss nan (nan)	prob nan (nan)	GS 35.703 (35.703)	mem 39.889
Train: [40][340/750]	BT 0.481 (1.195)	DT 0.314 (1.062)	loss nan (nan)	prob nan (nan)	GS 34.438 (34.438)	mem 39.916
Train: [40][345/750]	BT 0.125 (1.179)	DT 0.009 (1.047)	loss nan (nan)	prob nan (nan)	GS 27.922 (27.922)	mem 39.921
Train: [40][350/750]	BT 11.546 (1.197)	DT 11.469 (1.065)	loss nan (nan)	prob nan (nan)	GS 28.266 (28.266)	mem 39.948
Train: [40][355/750]	BT 0.204 (1.183)	DT 0.009 (1.050)	loss nan (nan)	prob nan (nan)	GS 29.219 (29.219)	mem 39.952
Train: [40][360/750]	BT 0.102 (1.168)	DT 0.001 (1.036)	loss nan (nan)	prob nan (nan)	GS 30.609 (30.609)	mem 39.965
Train: [40][365/750]	BT 0.161 (1.188)	DT 0.029 (1.056)	loss nan (nan)	prob nan (nan)	GS 29.359 (29.359)	mem 39.882
Train: [40][370/750]	BT 0.143 (1.174)	DT 0.002 (1.042)	loss nan (nan)	prob nan (nan)	GS 31.156 (31.156)	mem 40.099
Train: [40][375/750]	BT 0.192 (1.192)	DT 0.030 (1.060)	loss nan (nan)	prob nan (nan)	GS 35.016 (35.016)	mem 39.969
Train: [40][380/750]	BT 0.093 (1.182)	DT 0.001 (1.050)	loss nan (nan)	prob nan (nan)	GS 31.375 (31.375)	mem 39.864
Train: [40][385/750]	BT 0.102 (1.168)	DT 0.001 (1.036)	loss nan (nan)	prob nan (nan)	GS 29.078 (29.078)	mem 39.798
Train: [40][390/750]	BT 0.102 (1.193)	DT 0.001 (1.062)	loss nan (nan)	prob nan (nan)	GS 32.938 (32.938)	mem 39.868
Train: [40][395/750]	BT 0.100 (1.180)	DT 0.001 (1.048)	loss nan (nan)	prob nan (nan)	GS 30.812 (30.812)	mem 39.930
Train: [40][400/750]	BT 0.284 (1.193)	DT 0.069 (1.062)	loss nan (nan)	prob nan (nan)	GS 37.250 (37.250)	mem 40.143
Train: [40][405/750]	BT 0.145 (1.180)	DT 0.009 (1.049)	loss nan (nan)	prob nan (nan)	GS 34.859 (34.859)	mem 40.141
Train: [40][410/750]	BT 12.884 (1.199)	DT 12.736 (1.067)	loss nan (nan)	prob nan (nan)	GS 31.906 (31.906)	mem 40.011
Train: [40][415/750]	BT 0.119 (1.185)	DT 0.001 (1.054)	loss nan (nan)	prob nan (nan)	GS 34.047 (34.047)	mem 39.993
Train: [40][420/750]	BT 0.148 (1.173)	DT 0.002 (1.042)	loss nan (nan)	prob nan (nan)	GS 31.375 (31.375)	mem 39.887
Train: [40][425/750]	BT 0.113 (1.192)	DT 0.002 (1.061)	loss nan (nan)	prob nan (nan)	GS 37.141 (37.141)	mem 40.035
Train: [40][430/750]	BT 0.178 (1.180)	DT 0.006 (1.049)	loss nan (nan)	prob nan (nan)	GS 29.031 (29.031)	mem 40.081
Train: [40][435/750]	BT 0.117 (1.193)	DT 0.008 (1.062)	loss nan (nan)	prob nan (nan)	GS 32.406 (32.406)	mem 40.040
Train: [40][440/750]	BT 0.076 (1.181)	DT 0.001 (1.050)	loss nan (nan)	prob nan (nan)	GS 36.328 (36.328)	mem 40.064
Train: [40][445/750]	BT 0.101 (1.169)	DT 0.002 (1.039)	loss nan (nan)	prob nan (nan)	GS 30.906 (30.906)	mem 40.050
Train: [40][450/750]	BT 0.143 (1.178)	DT 0.009 (1.047)	loss nan (nan)	prob nan (nan)	GS 35.156 (35.156)	mem 40.021
Train: [40][455/750]	BT 0.129 (1.166)	DT 0.002 (1.036)	loss nan (nan)	prob nan (nan)	GS 29.188 (29.188)	mem 39.973
Train: [40][460/750]	BT 0.099 (1.179)	DT 0.001 (1.049)	loss nan (nan)	prob nan (nan)	GS 33.422 (33.422)	mem 39.999
Train: [40][465/750]	BT 0.110 (1.168)	DT 0.004 (1.038)	loss nan (nan)	prob nan (nan)	GS 32.828 (32.828)	mem 40.006
Train: [40][470/750]	BT 12.038 (1.182)	DT 11.970 (1.052)	loss nan (nan)	prob nan (nan)	GS 33.844 (33.844)	mem 40.082
Train: [40][475/750]	BT 0.169 (1.171)	DT 0.001 (1.041)	loss nan (nan)	prob nan (nan)	GS 29.078 (29.078)	mem 40.156
Train: [40][480/750]	BT 0.091 (1.160)	DT 0.002 (1.030)	loss nan (nan)	prob nan (nan)	GS 31.453 (31.453)	mem 40.013
Train: [40][485/750]	BT 0.205 (1.175)	DT 0.008 (1.045)	loss nan (nan)	prob nan (nan)	GS 32.406 (32.406)	mem 40.183
Train: [40][490/750]	BT 0.088 (1.164)	DT 0.002 (1.035)	loss nan (nan)	prob nan (nan)	GS 38.078 (38.078)	mem 40.261
Train: [40][495/750]	BT 0.092 (1.175)	DT 0.002 (1.046)	loss nan (nan)	prob nan (nan)	GS 31.312 (31.312)	mem 40.080
Train: [40][500/750]	BT 0.111 (1.165)	DT 0.029 (1.035)	loss nan (nan)	prob nan (nan)	GS 33.938 (33.938)	mem 39.958
Train: [40][505/750]	BT 0.192 (1.155)	DT 0.002 (1.025)	loss nan (nan)	prob nan (nan)	GS 36.828 (36.828)	mem 40.000
Train: [40][510/750]	BT 0.119 (1.169)	DT 0.002 (1.040)	loss nan (nan)	prob nan (nan)	GS 34.703 (34.703)	mem 40.086
Train: [40][515/750]	BT 0.189 (1.160)	DT 0.002 (1.030)	loss nan (nan)	prob nan (nan)	GS 29.344 (29.344)	mem 40.025
Train: [40][520/750]	BT 0.098 (1.174)	DT 0.005 (1.044)	loss nan (nan)	prob nan (nan)	GS 29.531 (29.531)	mem 40.074
Train: [40][525/750]	BT 0.157 (1.174)	DT 0.002 (1.044)	loss nan (nan)	prob nan (nan)	GS 32.359 (32.359)	mem 40.059
Train: [40][530/750]	BT 7.106 (1.177)	DT 7.015 (1.047)	loss nan (nan)	prob nan (nan)	GS 34.625 (34.625)	mem 40.024
Train: [40][535/750]	BT 0.168 (1.167)	DT 0.001 (1.037)	loss nan (nan)	prob nan (nan)	GS 36.578 (36.578)	mem 40.028
Train: [40][540/750]	BT 0.086 (1.168)	DT 0.007 (1.038)	loss nan (nan)	prob nan (nan)	GS 31.719 (31.719)	mem 40.058
Train: [40][545/750]	BT 0.124 (1.170)	DT 0.014 (1.040)	loss nan (nan)	prob nan (nan)	GS 29.047 (29.047)	mem 40.068
Train: [40][550/750]	BT 0.087 (1.168)	DT 0.001 (1.038)	loss nan (nan)	prob nan (nan)	GS 34.906 (34.906)	mem 40.094
Train: [40][555/750]	BT 0.097 (1.173)	DT 0.002 (1.043)	loss nan (nan)	prob nan (nan)	GS 30.297 (30.297)	mem 40.133
Train: [40][560/750]	BT 6.676 (1.176)	DT 6.579 (1.045)	loss nan (nan)	prob nan (nan)	GS 35.391 (35.391)	mem 40.054
Train: [40][565/750]	BT 0.262 (1.167)	DT 0.014 (1.036)	loss nan (nan)	prob nan (nan)	GS 31.266 (31.266)	mem 39.959
Train: [40][570/750]	BT 0.131 (1.170)	DT 0.001 (1.040)	loss nan (nan)	prob nan (nan)	GS 33.078 (33.078)	mem 39.979
Train: [40][575/750]	BT 0.131 (1.165)	DT 0.001 (1.035)	loss nan (nan)	prob nan (nan)	GS 32.188 (32.188)	mem 39.932
Train: [40][580/750]	BT 0.075 (1.175)	DT 0.001 (1.045)	loss nan (nan)	prob nan (nan)	GS 34.422 (34.422)	mem 39.967
Train: [40][585/750]	BT 0.167 (1.168)	DT 0.004 (1.038)	loss nan (nan)	prob nan (nan)	GS 29.000 (29.000)	mem 40.047
Train: [40][590/750]	BT 9.219 (1.175)	DT 9.143 (1.045)	loss nan (nan)	prob nan (nan)	GS 34.812 (34.812)	mem 40.072
Train: [40][595/750]	BT 0.098 (1.166)	DT 0.004 (1.036)	loss nan (nan)	prob nan (nan)	GS 40.703 (40.703)	mem 39.996
Train: [40][600/750]	BT 0.216 (1.161)	DT 0.008 (1.031)	loss nan (nan)	prob nan (nan)	GS 34.922 (34.922)	mem 40.045
Train: [40][605/750]	BT 0.110 (1.164)	DT 0.011 (1.034)	loss nan (nan)	prob nan (nan)	GS 32.453 (32.453)	mem 40.127
Train: [40][610/750]	BT 0.073 (1.172)	DT 0.001 (1.042)	loss nan (nan)	prob nan (nan)	GS 36.875 (36.875)	mem 40.018
Train: [40][615/750]	BT 0.148 (1.167)	DT 0.011 (1.037)	loss nan (nan)	prob nan (nan)	GS 35.641 (35.641)	mem 40.075
Train: [40][620/750]	BT 8.991 (1.173)	DT 8.899 (1.043)	loss nan (nan)	prob nan (nan)	GS 34.828 (34.828)	mem 40.049
Train: [40][625/750]	BT 0.269 (1.165)	DT 0.012 (1.035)	loss nan (nan)	prob nan (nan)	GS 46.859 (46.859)	mem 40.135
Train: [40][630/750]	BT 0.127 (1.158)	DT 0.001 (1.028)	loss nan (nan)	prob nan (nan)	GS 32.812 (32.812)	mem 40.182
Train: [40][635/750]	BT 0.173 (1.167)	DT 0.002 (1.037)	loss nan (nan)	prob nan (nan)	GS 31.703 (31.703)	mem 40.202
Train: [40][640/750]	BT 0.076 (1.163)	DT 0.002 (1.034)	loss nan (nan)	prob nan (nan)	GS 33.766 (33.766)	mem 39.921
Train: [40][645/750]	BT 0.088 (1.169)	DT 0.002 (1.039)	loss nan (nan)	prob nan (nan)	GS 31.594 (31.594)	mem 40.115
Train: [40][650/750]	BT 4.937 (1.168)	DT 4.852 (1.039)	loss nan (nan)	prob nan (nan)	GS 33.344 (33.344)	mem 40.060
Train: [40][655/750]	BT 0.321 (1.161)	DT 0.035 (1.031)	loss nan (nan)	prob nan (nan)	GS 30.828 (30.828)	mem 40.089
Train: [40][660/750]	BT 0.165 (1.160)	DT 0.001 (1.031)	loss nan (nan)	prob nan (nan)	GS 29.234 (29.234)	mem 40.083
Train: [40][665/750]	BT 0.113 (1.168)	DT 0.002 (1.038)	loss nan (nan)	prob nan (nan)	GS 29.938 (29.938)	mem 40.037
Train: [40][670/750]	BT 0.169 (1.168)	DT 0.006 (1.038)	loss nan (nan)	prob nan (nan)	GS 34.172 (34.172)	mem 40.043
Train: [40][675/750]	BT 0.145 (1.168)	DT 0.001 (1.039)	loss nan (nan)	prob nan (nan)	GS 32.109 (32.109)	mem 40.106
Train: [40][680/750]	BT 7.007 (1.170)	DT 6.799 (1.041)	loss nan (nan)	prob nan (nan)	GS 35.062 (35.062)	mem 40.108
Train: [40][685/750]	BT 0.155 (1.163)	DT 0.002 (1.033)	loss nan (nan)	prob nan (nan)	GS 34.703 (34.703)	mem 40.145
Train: [40][690/750]	BT 0.088 (1.161)	DT 0.001 (1.032)	loss nan (nan)	prob nan (nan)	GS 32.922 (32.922)	mem 40.110
Train: [40][695/750]	BT 0.272 (1.163)	DT 0.019 (1.034)	loss nan (nan)	prob nan (nan)	GS 32.062 (32.062)	mem 40.085
Train: [40][700/750]	BT 0.183 (1.165)	DT 0.006 (1.035)	loss nan (nan)	prob nan (nan)	GS 33.297 (33.297)	mem 40.097
Train: [40][705/750]	BT 0.094 (1.167)	DT 0.007 (1.038)	loss nan (nan)	prob nan (nan)	GS 28.109 (28.109)	mem 40.100
arpack error, retry= 0
Train: [40][710/750]	BT 0.513 (1.161)	DT 0.418 (1.031)	loss nan (nan)	prob nan (nan)	GS 32.297 (32.297)	mem 40.033
Train: [40][715/750]	BT 0.207 (1.154)	DT 0.032 (1.024)	loss nan (nan)	prob nan (nan)	GS 31.828 (31.828)	mem 40.119
Train: [40][720/750]	BT 0.100 (1.159)	DT 0.002 (1.029)	loss nan (nan)	prob nan (nan)	GS 32.734 (32.734)	mem 40.099
Train: [40][725/750]	BT 0.152 (1.157)	DT 0.009 (1.027)	loss nan (nan)	prob nan (nan)	GS 29.438 (29.438)	mem 40.030
Train: [40][730/750]	BT 0.087 (1.157)	DT 0.002 (1.028)	loss nan (nan)	prob nan (nan)	GS 30.797 (30.797)	mem 40.178
Train: [40][735/750]	BT 0.070 (1.158)	DT 0.002 (1.029)	loss nan (nan)	prob nan (nan)	GS 32.078 (32.078)	mem 36.860
Train: [40][740/750]	BT 1.842 (1.156)	DT 1.734 (1.027)	loss nan (nan)	prob nan (nan)	GS 30.234 (30.234)	mem 19.624
Train: [40][745/750]	BT 0.095 (1.149)	DT 0.009 (1.020)	loss nan (nan)	prob nan (nan)	GS 33.750 (33.750)	mem 19.632
Train: [40][750/750]	BT 1.950 (1.145)	DT 1.862 (1.017)	loss nan (nan)	prob nan (nan)	GS 34.906 (34.906)	mem 9.296
Train: [40][755/750]	BT 0.072 (1.138)	DT 0.002 (1.010)	loss nan (nan)	prob nan (nan)	GS 33.250 (33.250)	mem 7.686
epoch 40, total time 859.50
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [41][1/750]	BT 20.772 (20.772)	DT 20.637 (20.637)	loss nan (nan)	prob nan (nan)	GS 26.422 (26.422)	mem 38.603
Train: [41][5/750]	BT 0.143 (5.254)	DT 0.003 (5.059)	loss nan (nan)	prob nan (nan)	GS 32.312 (32.312)	mem 38.877
Train: [41][10/750]	BT 0.127 (2.759)	DT 0.019 (2.593)	loss nan (nan)	prob nan (nan)	GS 29.812 (29.812)	mem 38.709
Train: [41][15/750]	BT 0.093 (2.221)	DT 0.002 (2.063)	loss nan (nan)	prob nan (nan)	GS 32.234 (32.234)	mem 38.913
Train: [41][20/750]	BT 1.459 (2.082)	DT 1.266 (1.919)	loss nan (nan)	prob nan (nan)	GS 35.641 (35.641)	mem 39.078
Train: [41][25/750]	BT 9.343 (2.064)	DT 9.175 (1.904)	loss nan (nan)	prob nan (nan)	GS 51.562 (51.562)	mem 38.852
Train: [41][30/750]	BT 0.125 (1.749)	DT 0.005 (1.587)	loss nan (nan)	prob nan (nan)	GS 31.906 (31.906)	mem 38.922
Train: [41][35/750]	BT 0.107 (1.651)	DT 0.011 (1.495)	loss nan (nan)	prob nan (nan)	GS 30.938 (30.938)	mem 38.973
Train: [41][40/750]	BT 0.121 (1.670)	DT 0.002 (1.520)	loss nan (nan)	prob nan (nan)	GS 32.812 (32.812)	mem 39.019
Train: [41][45/750]	BT 0.164 (1.567)	DT 0.002 (1.418)	loss nan (nan)	prob nan (nan)	GS 26.812 (26.812)	mem 39.032
Train: [41][50/750]	BT 0.126 (1.532)	DT 0.002 (1.385)	loss nan (nan)	prob nan (nan)	GS 35.141 (35.141)	mem 38.979
Train: [41][55/750]	BT 0.166 (1.408)	DT 0.002 (1.260)	loss nan (nan)	prob nan (nan)	GS 27.781 (27.781)	mem 39.060
Train: [41][60/750]	BT 0.155 (1.400)	DT 0.001 (1.254)	loss nan (nan)	prob nan (nan)	GS 33.766 (33.766)	mem 38.998
Train: [41][65/750]	BT 0.091 (1.407)	DT 0.002 (1.263)	loss nan (nan)	prob nan (nan)	GS 31.172 (31.172)	mem 39.003
Train: [41][70/750]	BT 0.191 (1.377)	DT 0.007 (1.230)	loss nan (nan)	prob nan (nan)	GS 38.078 (38.078)	mem 39.341
Train: [41][75/750]	BT 0.096 (1.403)	DT 0.012 (1.257)	loss nan (nan)	prob nan (nan)	GS 31.844 (31.844)	mem 39.277
Train: [41][80/750]	BT 2.823 (1.380)	DT 2.727 (1.236)	loss nan (nan)	prob nan (nan)	GS 33.656 (33.656)	mem 39.623
Train: [41][85/750]	BT 0.119 (1.307)	DT 0.002 (1.164)	loss nan (nan)	prob nan (nan)	GS 29.625 (29.625)	mem 39.584
Train: [41][90/750]	BT 8.106 (1.398)	DT 7.995 (1.255)	loss nan (nan)	prob nan (nan)	GS 36.109 (36.109)	mem 39.562
Train: [41][95/750]	BT 0.117 (1.332)	DT 0.002 (1.190)	loss nan (nan)	prob nan (nan)	GS 34.891 (34.891)	mem 39.608
Train: [41][100/750]	BT 0.098 (1.326)	DT 0.002 (1.181)	loss nan (nan)	prob nan (nan)	GS 32.203 (32.203)	mem 39.562
Train: [41][105/750]	BT 0.084 (1.313)	DT 0.006 (1.169)	loss nan (nan)	prob nan (nan)	GS 27.781 (27.781)	mem 39.619
Train: [41][110/750]	BT 9.141 (1.342)	DT 9.044 (1.198)	loss nan (nan)	prob nan (nan)	GS 35.547 (35.547)	mem 39.692
Train: [41][115/750]	BT 0.072 (1.345)	DT 0.001 (1.203)	loss nan (nan)	prob nan (nan)	GS 27.328 (27.328)	mem 39.678
Train: [41][120/750]	BT 0.214 (1.294)	DT 0.002 (1.152)	loss nan (nan)	prob nan (nan)	GS 36.250 (36.250)	mem 39.709
Train: [41][125/750]	BT 0.097 (1.316)	DT 0.002 (1.174)	loss nan (nan)	prob nan (nan)	GS 29.984 (29.984)	mem 39.651
Train: [41][130/750]	BT 0.153 (1.286)	DT 0.010 (1.145)	loss nan (nan)	prob nan (nan)	GS 34.141 (34.141)	mem 39.554
Train: [41][135/750]	BT 0.062 (1.316)	DT 0.001 (1.177)	loss nan (nan)	prob nan (nan)	GS 32.094 (32.094)	mem 39.712
Train: [41][140/750]	BT 0.167 (1.274)	DT 0.001 (1.136)	loss nan (nan)	prob nan (nan)	GS 32.266 (32.266)	mem 39.815
Train: [41][145/750]	BT 0.135 (1.236)	DT 0.002 (1.097)	loss nan (nan)	prob nan (nan)	GS 30.391 (30.391)	mem 39.808
Train: [41][150/750]	BT 2.906 (1.299)	DT 2.754 (1.160)	loss nan (nan)	prob nan (nan)	GS 33.219 (33.219)	mem 40.042
Train: [41][155/750]	BT 0.234 (1.262)	DT 0.002 (1.122)	loss nan (nan)	prob nan (nan)	GS 30.578 (30.578)	mem 39.908
Train: [41][160/750]	BT 0.144 (1.285)	DT 0.010 (1.146)	loss nan (nan)	prob nan (nan)	GS 35.266 (35.266)	mem 39.844
Train: [41][165/750]	BT 0.110 (1.260)	DT 0.001 (1.122)	loss nan (nan)	prob nan (nan)	GS 29.156 (29.156)	mem 40.103
Train: [41][170/750]	BT 13.058 (1.304)	DT 12.958 (1.165)	loss nan (nan)	prob nan (nan)	GS 32.453 (32.453)	mem 39.845
Train: [41][175/750]	BT 0.083 (1.289)	DT 0.002 (1.150)	loss nan (nan)	prob nan (nan)	GS 30.062 (30.062)	mem 39.893
Train: [41][180/750]	BT 0.180 (1.257)	DT 0.006 (1.118)	loss nan (nan)	prob nan (nan)	GS 36.391 (36.391)	mem 39.991
Train: [41][185/750]	BT 0.131 (1.283)	DT 0.003 (1.145)	loss nan (nan)	prob nan (nan)	GS 30.266 (30.266)	mem 39.977
Train: [41][190/750]	BT 0.087 (1.272)	DT 0.001 (1.134)	loss nan (nan)	prob nan (nan)	GS 30.797 (30.797)	mem 39.943
Train: [41][195/750]	BT 0.130 (1.294)	DT 0.002 (1.157)	loss nan (nan)	prob nan (nan)	GS 32.438 (32.438)	mem 39.919
Train: [41][200/750]	BT 0.148 (1.278)	DT 0.001 (1.141)	loss nan (nan)	prob nan (nan)	GS 38.484 (38.484)	mem 40.102
Train: [41][205/750]	BT 0.164 (1.250)	DT 0.001 (1.113)	loss nan (nan)	prob nan (nan)	GS 32.844 (32.844)	mem 39.814
Train: [41][210/750]	BT 0.621 (1.269)	DT 0.536 (1.132)	loss nan (nan)	prob nan (nan)	GS 31.156 (31.156)	mem 39.866
Train: [41][215/750]	BT 0.176 (1.242)	DT 0.009 (1.106)	loss nan (nan)	prob nan (nan)	GS 31.984 (31.984)	mem 40.229
Train: [41][220/750]	BT 0.102 (1.265)	DT 0.005 (1.129)	loss nan (nan)	prob nan (nan)	GS 32.125 (32.125)	mem 39.874
Train: [41][225/750]	BT 0.095 (1.240)	DT 0.002 (1.104)	loss nan (nan)	prob nan (nan)	GS 28.578 (28.578)	mem 39.917
Train: [41][230/750]	BT 11.839 (1.267)	DT 11.730 (1.131)	loss nan (nan)	prob nan (nan)	GS 35.031 (35.031)	mem 39.952
Train: [41][235/750]	BT 0.154 (1.243)	DT 0.010 (1.107)	loss nan (nan)	prob nan (nan)	GS 29.047 (29.047)	mem 40.011
Train: [41][240/750]	BT 0.124 (1.220)	DT 0.001 (1.084)	loss nan (nan)	prob nan (nan)	GS 30.438 (30.438)	mem 40.148
Train: [41][245/750]	BT 0.086 (1.244)	DT 0.002 (1.108)	loss nan (nan)	prob nan (nan)	GS 31.359 (31.359)	mem 39.968
Train: [41][250/750]	BT 0.107 (1.221)	DT 0.014 (1.086)	loss nan (nan)	prob nan (nan)	GS 37.516 (37.516)	mem 39.860
Train: [41][255/750]	BT 0.083 (1.254)	DT 0.001 (1.120)	loss nan (nan)	prob nan (nan)	GS 32.359 (32.359)	mem 39.883
Train: [41][260/750]	BT 0.229 (1.234)	DT 0.010 (1.099)	loss nan (nan)	prob nan (nan)	GS 35.703 (35.703)	mem 39.922
Train: [41][265/750]	BT 0.130 (1.215)	DT 0.004 (1.081)	loss nan (nan)	prob nan (nan)	GS 32.312 (32.312)	mem 39.844
Train: [41][270/750]	BT 0.091 (1.245)	DT 0.002 (1.112)	loss nan (nan)	prob nan (nan)	GS 35.250 (35.250)	mem 39.872
Train: [41][275/750]	BT 0.176 (1.230)	DT 0.024 (1.096)	loss nan (nan)	prob nan (nan)	GS 28.797 (28.797)	mem 39.915
Train: [41][280/750]	BT 0.904 (1.240)	DT 0.772 (1.107)	loss nan (nan)	prob nan (nan)	GS 32.828 (32.828)	mem 39.986
Train: [41][285/750]	BT 0.105 (1.220)	DT 0.002 (1.088)	loss nan (nan)	prob nan (nan)	GS 32.438 (32.438)	mem 39.894
Train: [41][290/750]	BT 7.836 (1.240)	DT 7.769 (1.107)	loss nan (nan)	prob nan (nan)	GS 37.578 (37.578)	mem 39.870
Train: [41][295/750]	BT 0.168 (1.227)	DT 0.017 (1.094)	loss nan (nan)	prob nan (nan)	GS 30.906 (30.906)	mem 39.898
Train: [41][300/750]	BT 0.138 (1.211)	DT 0.011 (1.078)	loss nan (nan)	prob nan (nan)	GS 35.219 (35.219)	mem 39.885
Train: [41][305/750]	BT 0.090 (1.230)	DT 0.001 (1.097)	loss nan (nan)	prob nan (nan)	GS 29.125 (29.125)	mem 39.911
Train: [41][310/750]	BT 0.252 (1.213)	DT 0.030 (1.080)	loss nan (nan)	prob nan (nan)	GS 34.750 (34.750)	mem 39.896
Train: [41][315/750]	BT 0.089 (1.202)	DT 0.002 (1.069)	loss nan (nan)	prob nan (nan)	GS 28.422 (28.422)	mem 39.903
Train: [41][320/750]	BT 0.091 (1.207)	DT 0.002 (1.074)	loss nan (nan)	prob nan (nan)	GS 34.156 (34.156)	mem 39.992
Train: [41][325/750]	BT 0.133 (1.198)	DT 0.008 (1.065)	loss nan (nan)	prob nan (nan)	GS 29.953 (29.953)	mem 40.066
Train: [41][330/750]	BT 0.522 (1.203)	DT 0.423 (1.070)	loss nan (nan)	prob nan (nan)	GS 36.984 (36.984)	mem 40.026
Train: [41][335/750]	BT 0.130 (1.210)	DT 0.003 (1.077)	loss nan (nan)	prob nan (nan)	GS 28.609 (28.609)	mem 40.249
Train: [41][340/750]	BT 0.081 (1.201)	DT 0.001 (1.069)	loss nan (nan)	prob nan (nan)	GS 32.781 (32.781)	mem 40.035
Train: [41][345/750]	BT 0.147 (1.187)	DT 0.006 (1.054)	loss nan (nan)	prob nan (nan)	GS 30.078 (30.078)	mem 40.036
Train: [41][350/750]	BT 0.827 (1.200)	DT 0.704 (1.068)	loss nan (nan)	prob nan (nan)	GS 32.281 (32.281)	mem 39.986
Train: [41][355/750]	BT 0.135 (1.186)	DT 0.007 (1.053)	loss nan (nan)	prob nan (nan)	GS 29.062 (29.062)	mem 40.167
Train: [41][360/750]	BT 0.119 (1.202)	DT 0.005 (1.069)	loss nan (nan)	prob nan (nan)	GS 35.234 (35.234)	mem 40.075
Train: [41][365/750]	BT 0.185 (1.188)	DT 0.002 (1.055)	loss nan (nan)	prob nan (nan)	GS 32.750 (32.750)	mem 39.978
Train: [41][370/750]	BT 10.068 (1.203)	DT 9.930 (1.070)	loss nan (nan)	prob nan (nan)	GS 35.172 (35.172)	mem 39.986
Train: [41][375/750]	BT 0.149 (1.189)	DT 0.002 (1.056)	loss nan (nan)	prob nan (nan)	GS 29.750 (29.750)	mem 40.031
Train: [41][380/750]	BT 0.083 (1.175)	DT 0.002 (1.042)	loss nan (nan)	prob nan (nan)	GS 35.141 (35.141)	mem 40.095
Train: [41][385/750]	BT 0.081 (1.189)	DT 0.001 (1.056)	loss nan (nan)	prob nan (nan)	GS 28.766 (28.766)	mem 40.065
Train: [41][390/750]	BT 0.218 (1.176)	DT 0.008 (1.043)	loss nan (nan)	prob nan (nan)	GS 34.938 (34.938)	mem 40.159
Train: [41][395/750]	BT 0.142 (1.195)	DT 0.002 (1.062)	loss nan (nan)	prob nan (nan)	GS 33.750 (33.750)	mem 40.039
Train: [41][400/750]	BT 0.157 (1.181)	DT 0.001 (1.049)	loss nan (nan)	prob nan (nan)	GS 31.875 (31.875)	mem 40.040
Train: [41][405/750]	BT 0.250 (1.169)	DT 0.002 (1.036)	loss nan (nan)	prob nan (nan)	GS 30.688 (30.688)	mem 40.043
Train: [41][410/750]	BT 0.100 (1.188)	DT 0.002 (1.054)	loss nan (nan)	prob nan (nan)	GS 36.812 (36.812)	mem 40.042
Train: [41][415/750]	BT 0.152 (1.175)	DT 0.002 (1.042)	loss nan (nan)	prob nan (nan)	GS 34.781 (34.781)	mem 40.045
Train: [41][420/750]	BT 0.123 (1.186)	DT 0.001 (1.052)	loss nan (nan)	prob nan (nan)	GS 34.969 (34.969)	mem 40.166
Train: [41][425/750]	BT 0.087 (1.173)	DT 0.002 (1.040)	loss nan (nan)	prob nan (nan)	GS 30.016 (30.016)	mem 40.067
Train: [41][430/750]	BT 7.416 (1.183)	DT 7.261 (1.050)	loss nan (nan)	prob nan (nan)	GS 37.875 (37.875)	mem 40.097
Train: [41][435/750]	BT 0.122 (1.180)	DT 0.004 (1.046)	loss nan (nan)	prob nan (nan)	GS 39.969 (39.969)	mem 40.088
Train: [41][440/750]	BT 0.091 (1.173)	DT 0.002 (1.039)	loss nan (nan)	prob nan (nan)	GS 32.906 (32.906)	mem 40.040
Train: [41][445/750]	BT 0.140 (1.175)	DT 0.002 (1.041)	loss nan (nan)	prob nan (nan)	GS 30.859 (30.859)	mem 40.095
Train: [41][450/750]	BT 0.277 (1.169)	DT 0.026 (1.035)	loss nan (nan)	prob nan (nan)	GS 35.531 (35.531)	mem 40.149
Train: [41][455/750]	BT 0.139 (1.182)	DT 0.002 (1.049)	loss nan (nan)	prob nan (nan)	GS 32.406 (32.406)	mem 40.103
Train: [41][460/750]	BT 0.119 (1.171)	DT 0.002 (1.037)	loss nan (nan)	prob nan (nan)	GS 34.375 (34.375)	mem 40.203
Train: [41][465/750]	BT 0.088 (1.166)	DT 0.002 (1.032)	loss nan (nan)	prob nan (nan)	GS 30.594 (30.594)	mem 39.998
Train: [41][470/750]	BT 0.352 (1.173)	DT 0.138 (1.039)	loss nan (nan)	prob nan (nan)	GS 30.375 (30.375)	mem 40.093
Train: [41][475/750]	BT 0.120 (1.168)	DT 0.002 (1.034)	loss nan (nan)	prob nan (nan)	GS 27.391 (27.391)	mem 39.998
Train: [41][480/750]	BT 0.152 (1.173)	DT 0.001 (1.039)	loss nan (nan)	prob nan (nan)	GS 34.625 (34.625)	mem 40.146
Train: [41][485/750]	BT 0.117 (1.162)	DT 0.007 (1.028)	loss nan (nan)	prob nan (nan)	GS 33.156 (33.156)	mem 40.017
Train: [41][490/750]	BT 5.294 (1.176)	DT 5.165 (1.042)	loss nan (nan)	prob nan (nan)	GS 32.328 (32.328)	mem 40.044
Train: [41][495/750]	BT 0.099 (1.165)	DT 0.001 (1.031)	loss nan (nan)	prob nan (nan)	GS 34.109 (34.109)	mem 40.053
Train: [41][500/750]	BT 0.134 (1.165)	DT 0.008 (1.032)	loss nan (nan)	prob nan (nan)	GS 33.828 (33.828)	mem 39.986
Train: [41][505/750]	BT 0.207 (1.162)	DT 0.009 (1.028)	loss nan (nan)	prob nan (nan)	GS 33.578 (33.578)	mem 40.057
Train: [41][510/750]	BT 0.612 (1.161)	DT 0.416 (1.027)	loss nan (nan)	prob nan (nan)	GS 33.016 (33.016)	mem 40.201
Train: [41][515/750]	BT 0.097 (1.163)	DT 0.002 (1.028)	loss nan (nan)	prob nan (nan)	GS 27.984 (27.984)	mem 40.061
Train: [41][520/750]	BT 0.179 (1.165)	DT 0.001 (1.030)	loss nan (nan)	prob nan (nan)	GS 36.516 (36.516)	mem 40.130
Train: [41][525/750]	BT 0.189 (1.158)	DT 0.007 (1.023)	loss nan (nan)	prob nan (nan)	GS 35.062 (35.062)	mem 40.134
Train: [41][530/750]	BT 3.581 (1.162)	DT 3.501 (1.027)	loss nan (nan)	prob nan (nan)	GS 27.688 (27.688)	mem 40.012
Train: [41][535/750]	BT 0.143 (1.152)	DT 0.025 (1.018)	loss nan (nan)	prob nan (nan)	GS 31.609 (31.609)	mem 40.036
Train: [41][540/750]	BT 0.139 (1.157)	DT 0.035 (1.022)	loss nan (nan)	prob nan (nan)	GS 36.438 (36.438)	mem 40.185
Train: [41][545/750]	BT 0.110 (1.150)	DT 0.002 (1.015)	loss nan (nan)	prob nan (nan)	GS 26.844 (26.844)	mem 40.091
Train: [41][550/750]	BT 4.940 (1.162)	DT 4.785 (1.027)	loss nan (nan)	prob nan (nan)	GS 35.859 (35.859)	mem 40.023
Train: [41][555/750]	BT 0.084 (1.153)	DT 0.001 (1.018)	loss nan (nan)	prob nan (nan)	GS 32.484 (32.484)	mem 40.028
Train: [41][560/750]	BT 10.865 (1.163)	DT 10.760 (1.028)	loss nan (nan)	prob nan (nan)	GS 38.188 (38.188)	mem 40.246
Train: [41][565/750]	BT 0.140 (1.154)	DT 0.002 (1.019)	loss nan (nan)	prob nan (nan)	GS 29.750 (29.750)	mem 40.065
Train: [41][570/750]	BT 2.011 (1.148)	DT 1.860 (1.014)	loss nan (nan)	prob nan (nan)	GS 33.234 (33.234)	mem 39.962
Train: [41][575/750]	BT 0.096 (1.160)	DT 0.001 (1.025)	loss nan (nan)	prob nan (nan)	GS 31.594 (31.594)	mem 39.973
Train: [41][580/750]	BT 0.087 (1.151)	DT 0.002 (1.016)	loss nan (nan)	prob nan (nan)	GS 35.688 (35.688)	mem 39.980
Train: [41][585/750]	BT 0.097 (1.161)	DT 0.001 (1.026)	loss nan (nan)	prob nan (nan)	GS 49.406 (49.406)	mem 40.035
Train: [41][590/750]	BT 0.165 (1.158)	DT 0.010 (1.024)	loss nan (nan)	prob nan (nan)	GS 33.578 (33.578)	mem 40.055
Train: [41][595/750]	BT 0.167 (1.150)	DT 0.018 (1.015)	loss nan (nan)	prob nan (nan)	GS 31.812 (31.812)	mem 40.047
Train: [41][600/750]	BT 0.191 (1.158)	DT 0.002 (1.024)	loss nan (nan)	prob nan (nan)	GS 33.312 (33.312)	mem 40.080
Train: [41][605/750]	BT 0.239 (1.150)	DT 0.004 (1.015)	loss nan (nan)	prob nan (nan)	GS 34.781 (34.781)	mem 40.084
Train: [41][610/750]	BT 0.077 (1.164)	DT 0.001 (1.030)	loss nan (nan)	prob nan (nan)	GS 36.922 (36.922)	mem 39.985
Train: [41][615/750]	BT 0.116 (1.156)	DT 0.001 (1.021)	loss nan (nan)	prob nan (nan)	GS 32.688 (32.688)	mem 40.007
Train: [41][620/750]	BT 11.141 (1.165)	DT 11.026 (1.031)	loss nan (nan)	prob nan (nan)	GS 38.625 (38.625)	mem 39.932
Train: [41][625/750]	BT 0.238 (1.157)	DT 0.004 (1.023)	loss nan (nan)	prob nan (nan)	GS 30.625 (30.625)	mem 39.931
Train: [41][630/750]	BT 1.727 (1.151)	DT 1.630 (1.017)	loss nan (nan)	prob nan (nan)	GS 36.781 (36.781)	mem 39.950
Train: [41][635/750]	BT 0.152 (1.157)	DT 0.002 (1.023)	loss nan (nan)	prob nan (nan)	GS 30.609 (30.609)	mem 40.268
Train: [41][640/750]	BT 0.167 (1.149)	DT 0.002 (1.015)	loss nan (nan)	prob nan (nan)	GS 30.656 (30.656)	mem 40.084
Train: [41][645/750]	BT 0.141 (1.157)	DT 0.001 (1.023)	loss nan (nan)	prob nan (nan)	GS 34.484 (34.484)	mem 39.973
Train: [41][650/750]	BT 0.098 (1.149)	DT 0.004 (1.015)	loss nan (nan)	prob nan (nan)	GS 32.766 (32.766)	mem 39.949
Train: [41][655/750]	BT 0.132 (1.151)	DT 0.009 (1.017)	loss nan (nan)	prob nan (nan)	GS 32.219 (32.219)	mem 39.945
Train: [41][660/750]	BT 0.081 (1.154)	DT 0.002 (1.020)	loss nan (nan)	prob nan (nan)	GS 33.219 (33.219)	mem 39.937
Train: [41][665/750]	BT 0.225 (1.147)	DT 0.007 (1.013)	loss nan (nan)	prob nan (nan)	GS 29.531 (29.531)	mem 39.879
Train: [41][670/750]	BT 0.093 (1.154)	DT 0.005 (1.020)	loss nan (nan)	prob nan (nan)	GS 33.703 (33.703)	mem 39.916
Train: [41][675/750]	BT 0.125 (1.147)	DT 0.009 (1.013)	loss nan (nan)	prob nan (nan)	GS 29.297 (29.297)	mem 39.982
Train: [41][680/750]	BT 7.064 (1.157)	DT 6.945 (1.022)	loss nan (nan)	prob nan (nan)	GS 33.812 (33.812)	mem 40.137
Train: [41][685/750]	BT 0.255 (1.149)	DT 0.003 (1.015)	loss nan (nan)	prob nan (nan)	GS 30.906 (30.906)	mem 40.131
Train: [41][690/750]	BT 2.897 (1.146)	DT 2.750 (1.012)	loss nan (nan)	prob nan (nan)	GS 28.750 (28.750)	mem 40.043
Train: [41][695/750]	BT 0.133 (1.150)	DT 0.002 (1.015)	loss nan (nan)	prob nan (nan)	GS 30.406 (30.406)	mem 39.964
Train: [41][700/750]	BT 0.151 (1.144)	DT 0.002 (1.009)	loss nan (nan)	prob nan (nan)	GS 31.156 (31.156)	mem 40.006
Train: [41][705/750]	BT 0.114 (1.154)	DT 0.008 (1.020)	loss nan (nan)	prob nan (nan)	GS 36.156 (36.156)	mem 39.993
Train: [41][710/750]	BT 0.113 (1.147)	DT 0.002 (1.013)	loss nan (nan)	prob nan (nan)	GS 31.688 (31.688)	mem 40.000
Train: [41][715/750]	BT 0.156 (1.150)	DT 0.014 (1.016)	loss nan (nan)	prob nan (nan)	GS 32.094 (32.094)	mem 39.964
Train: [41][720/750]	BT 0.112 (1.155)	DT 0.001 (1.021)	loss nan (nan)	prob nan (nan)	GS 36.703 (36.703)	mem 39.865
Train: [41][725/750]	BT 0.127 (1.148)	DT 0.002 (1.014)	loss nan (nan)	prob nan (nan)	GS 30.109 (30.109)	mem 39.872
Train: [41][730/750]	BT 0.085 (1.154)	DT 0.009 (1.020)	loss nan (nan)	prob nan (nan)	GS 34.344 (34.344)	mem 39.632
Train: [41][735/750]	BT 0.115 (1.147)	DT 0.002 (1.013)	loss nan (nan)	prob nan (nan)	GS 31.297 (31.297)	mem 39.635
Train: [41][740/750]	BT 0.091 (1.147)	DT 0.011 (1.014)	loss nan (nan)	prob nan (nan)	GS 31.062 (31.062)	mem 10.675
Train: [41][745/750]	BT 0.078 (1.140)	DT 0.002 (1.007)	loss nan (nan)	prob nan (nan)	GS 34.938 (34.938)	mem 10.676
Train: [41][750/750]	BT 1.739 (1.135)	DT 1.671 (1.003)	loss nan (nan)	prob nan (nan)	GS 31.562 (31.562)	mem 10.551
Train: [41][755/750]	BT 0.065 (1.128)	DT 0.002 (0.996)	loss nan (nan)	prob nan (nan)	GS 30.906 (30.906)	mem 7.672
epoch 41, total time 852.11
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [42][1/750]	BT 19.249 (19.249)	DT 19.020 (19.020)	loss nan (nan)	prob nan (nan)	GS 31.938 (31.938)	mem 38.634
Train: [42][5/750]	BT 0.130 (4.710)	DT 0.008 (4.549)	loss nan (nan)	prob nan (nan)	GS 29.531 (29.531)	mem 38.692
Train: [42][10/750]	BT 0.091 (2.435)	DT 0.001 (2.286)	loss nan (nan)	prob nan (nan)	GS 33.844 (33.844)	mem 38.768
Train: [42][15/750]	BT 0.062 (2.673)	DT 0.001 (2.533)	loss nan (nan)	prob nan (nan)	GS 32.734 (32.734)	mem 38.815
Train: [42][20/750]	BT 0.100 (2.029)	DT 0.002 (1.901)	loss nan (nan)	prob nan (nan)	GS 31.984 (31.984)	mem 38.818
Train: [42][25/750]	BT 0.198 (1.654)	DT 0.002 (1.521)	loss nan (nan)	prob nan (nan)	GS 29.062 (29.062)	mem 38.862
Train: [42][30/750]	BT 0.097 (1.842)	DT 0.001 (1.707)	loss nan (nan)	prob nan (nan)	GS 36.094 (36.094)	mem 39.144
Train: [42][35/750]	BT 0.135 (1.597)	DT 0.002 (1.463)	loss nan (nan)	prob nan (nan)	GS 31.141 (31.141)	mem 39.150
Train: [42][40/750]	BT 0.077 (1.719)	DT 0.001 (1.590)	loss nan (nan)	prob nan (nan)	GS 36.344 (36.344)	mem 39.041
Train: [42][45/750]	BT 0.173 (1.542)	DT 0.001 (1.413)	loss nan (nan)	prob nan (nan)	GS 32.266 (32.266)	mem 39.140
Train: [42][50/750]	BT 13.220 (1.665)	DT 13.109 (1.535)	loss nan (nan)	prob nan (nan)	GS 33.984 (33.984)	mem 39.109
Train: [42][55/750]	BT 0.103 (1.521)	DT 0.001 (1.396)	loss nan (nan)	prob nan (nan)	GS 29.000 (29.000)	mem 39.218
Train: [42][60/750]	BT 0.118 (1.405)	DT 0.001 (1.280)	loss nan (nan)	prob nan (nan)	GS 32.031 (32.031)	mem 39.116
Train: [42][65/750]	BT 0.155 (1.454)	DT 0.002 (1.326)	loss nan (nan)	prob nan (nan)	GS 31.719 (31.719)	mem 39.248
Train: [42][70/750]	BT 0.071 (1.399)	DT 0.001 (1.273)	loss nan (nan)	prob nan (nan)	GS 26.812 (26.812)	mem 39.260
Train: [42][75/750]	BT 0.160 (1.435)	DT 0.029 (1.307)	loss nan (nan)	prob nan (nan)	GS 35.266 (35.266)	mem 39.377
Train: [42][80/750]	BT 5.095 (1.414)	DT 5.004 (1.288)	loss nan (nan)	prob nan (nan)	GS 38.766 (38.766)	mem 39.133
Train: [42][85/750]	BT 0.116 (1.338)	DT 0.006 (1.212)	loss nan (nan)	prob nan (nan)	GS 30.250 (30.250)	mem 39.133
Train: [42][90/750]	BT 0.134 (1.355)	DT 0.002 (1.228)	loss nan (nan)	prob nan (nan)	GS 32.359 (32.359)	mem 39.266
Train: [42][95/750]	BT 0.227 (1.345)	DT 0.002 (1.218)	loss nan (nan)	prob nan (nan)	GS 32.391 (32.391)	mem 39.302
Train: [42][100/750]	BT 0.115 (1.335)	DT 0.007 (1.209)	loss nan (nan)	prob nan (nan)	GS 36.750 (36.750)	mem 39.192
Train: [42][105/750]	BT 0.127 (1.313)	DT 0.001 (1.186)	loss nan (nan)	prob nan (nan)	GS 38.281 (38.281)	mem 39.239
Train: [42][110/750]	BT 4.564 (1.300)	DT 4.483 (1.173)	loss nan (nan)	prob nan (nan)	GS 34.297 (34.297)	mem 39.207
Train: [42][115/750]	BT 0.122 (1.311)	DT 0.005 (1.183)	loss nan (nan)	prob nan (nan)	GS 31.922 (31.922)	mem 39.276
Train: [42][120/750]	BT 0.262 (1.275)	DT 0.002 (1.145)	loss nan (nan)	prob nan (nan)	GS 34.547 (34.547)	mem 39.225
Train: [42][125/750]	BT 0.156 (1.236)	DT 0.008 (1.105)	loss nan (nan)	prob nan (nan)	GS 29.391 (29.391)	mem 39.176
Train: [42][130/750]	BT 0.136 (1.291)	DT 0.001 (1.159)	loss nan (nan)	prob nan (nan)	GS 35.344 (35.344)	mem 39.342
Train: [42][135/750]	BT 0.154 (1.247)	DT 0.001 (1.116)	loss nan (nan)	prob nan (nan)	GS 41.109 (41.109)	mem 39.344
Train: [42][140/750]	BT 0.082 (1.299)	DT 0.002 (1.169)	loss nan (nan)	prob nan (nan)	GS 33.562 (33.562)	mem 39.407
Train: [42][145/750]	BT 0.136 (1.258)	DT 0.001 (1.128)	loss nan (nan)	prob nan (nan)	GS 35.266 (35.266)	mem 39.402
Train: [42][150/750]	BT 9.761 (1.284)	DT 9.652 (1.155)	loss nan (nan)	prob nan (nan)	GS 32.875 (32.875)	mem 39.462
Train: [42][155/750]	BT 0.101 (1.247)	DT 0.002 (1.118)	loss nan (nan)	prob nan (nan)	GS 31.797 (31.797)	mem 39.418
Train: [42][160/750]	BT 2.153 (1.226)	DT 1.971 (1.096)	loss nan (nan)	prob nan (nan)	GS 34.906 (34.906)	mem 39.399
Train: [42][165/750]	BT 0.091 (1.246)	DT 0.002 (1.117)	loss nan (nan)	prob nan (nan)	GS 26.547 (26.547)	mem 39.892
Train: [42][170/750]	BT 0.072 (1.215)	DT 0.001 (1.086)	loss nan (nan)	prob nan (nan)	GS 30.844 (30.844)	mem 39.405
Train: [42][175/750]	BT 0.091 (1.245)	DT 0.001 (1.117)	loss nan (nan)	prob nan (nan)	GS 31.469 (31.469)	mem 39.522
Train: [42][180/750]	BT 0.166 (1.222)	DT 0.008 (1.093)	loss nan (nan)	prob nan (nan)	GS 33.719 (33.719)	mem 39.438
Train: [42][185/750]	BT 0.129 (1.233)	DT 0.002 (1.103)	loss nan (nan)	prob nan (nan)	GS 30.547 (30.547)	mem 39.506
Train: [42][190/750]	BT 0.090 (1.217)	DT 0.002 (1.087)	loss nan (nan)	prob nan (nan)	GS 35.703 (35.703)	mem 39.691
Train: [42][195/750]	BT 0.148 (1.194)	DT 0.005 (1.065)	loss nan (nan)	prob nan (nan)	GS 28.625 (28.625)	mem 39.759
Train: [42][200/750]	BT 0.083 (1.217)	DT 0.001 (1.087)	loss nan (nan)	prob nan (nan)	GS 36.359 (36.359)	mem 39.699
Train: [42][205/750]	BT 0.157 (1.190)	DT 0.005 (1.061)	loss nan (nan)	prob nan (nan)	GS 30.422 (30.422)	mem 39.689
Train: [42][210/750]	BT 1.113 (1.211)	DT 0.947 (1.082)	loss nan (nan)	prob nan (nan)	GS 32.578 (32.578)	mem 39.761
Train: [42][215/750]	BT 0.138 (1.193)	DT 0.001 (1.063)	loss nan (nan)	prob nan (nan)	GS 26.797 (26.797)	mem 39.801
Train: [42][220/750]	BT 6.160 (1.203)	DT 6.083 (1.073)	loss nan (nan)	prob nan (nan)	GS 35.453 (35.453)	mem 39.705
Train: [42][225/750]	BT 0.089 (1.207)	DT 0.002 (1.078)	loss nan (nan)	prob nan (nan)	GS 30.219 (30.219)	mem 39.705
Train: [42][230/750]	BT 3.282 (1.200)	DT 3.137 (1.071)	loss nan (nan)	prob nan (nan)	GS 35.250 (35.250)	mem 39.721
Train: [42][235/750]	BT 0.087 (1.215)	DT 0.002 (1.087)	loss nan (nan)	prob nan (nan)	GS 31.094 (31.094)	mem 39.798
Train: [42][240/750]	BT 1.697 (1.199)	DT 1.587 (1.071)	loss nan (nan)	prob nan (nan)	GS 33.062 (33.062)	mem 39.847
Train: [42][245/750]	BT 0.137 (1.202)	DT 0.004 (1.074)	loss nan (nan)	prob nan (nan)	GS 44.391 (44.391)	mem 39.722
Train: [42][250/750]	BT 0.167 (1.201)	DT 0.011 (1.073)	loss nan (nan)	prob nan (nan)	GS 37.484 (37.484)	mem 39.717
Train: [42][255/750]	BT 0.082 (1.203)	DT 0.002 (1.075)	loss nan (nan)	prob nan (nan)	GS 27.766 (27.766)	mem 39.908
Train: [42][260/750]	BT 0.126 (1.198)	DT 0.002 (1.070)	loss nan (nan)	prob nan (nan)	GS 31.438 (31.438)	mem 39.912
Train: [42][265/750]	BT 0.107 (1.178)	DT 0.009 (1.050)	loss nan (nan)	prob nan (nan)	GS 30.875 (30.875)	mem 39.913
Train: [42][270/750]	BT 7.085 (1.221)	DT 6.991 (1.093)	loss nan (nan)	prob nan (nan)	GS 38.500 (38.500)	mem 40.031
Train: [42][275/750]	BT 0.158 (1.202)	DT 0.020 (1.073)	loss nan (nan)	prob nan (nan)	GS 31.703 (31.703)	mem 40.040
Train: [42][280/750]	BT 0.135 (1.204)	DT 0.002 (1.075)	loss nan (nan)	prob nan (nan)	GS 34.766 (34.766)	mem 40.001
Train: [42][285/750]	BT 0.115 (1.194)	DT 0.025 (1.065)	loss nan (nan)	prob nan (nan)	GS 29.172 (29.172)	mem 40.082
Train: [42][290/750]	BT 10.591 (1.212)	DT 10.493 (1.083)	loss nan (nan)	prob nan (nan)	GS 32.656 (32.656)	mem 39.938
Train: [42][295/750]	BT 0.236 (1.196)	DT 0.001 (1.067)	loss nan (nan)	prob nan (nan)	GS 30.438 (30.438)	mem 40.007
Train: [42][300/750]	BT 0.120 (1.178)	DT 0.025 (1.049)	loss nan (nan)	prob nan (nan)	GS 34.422 (34.422)	mem 39.943
Train: [42][305/750]	BT 0.103 (1.189)	DT 0.008 (1.060)	loss nan (nan)	prob nan (nan)	GS 33.047 (33.047)	mem 40.019
Train: [42][310/750]	BT 0.086 (1.181)	DT 0.002 (1.052)	loss nan (nan)	prob nan (nan)	GS 36.281 (36.281)	mem 40.064
Train: [42][315/750]	BT 0.132 (1.189)	DT 0.001 (1.061)	loss nan (nan)	prob nan (nan)	GS 28.766 (28.766)	mem 40.234
Train: [42][320/750]	BT 0.144 (1.186)	DT 0.008 (1.057)	loss nan (nan)	prob nan (nan)	GS 32.203 (32.203)	mem 39.975
Train: [42][325/750]	BT 0.164 (1.182)	DT 0.017 (1.053)	loss nan (nan)	prob nan (nan)	GS 29.203 (29.203)	mem 39.959
Train: [42][330/750]	BT 3.553 (1.187)	DT 3.438 (1.057)	loss nan (nan)	prob nan (nan)	GS 38.188 (38.188)	mem 40.047
Train: [42][335/750]	BT 0.127 (1.171)	DT 0.002 (1.041)	loss nan (nan)	prob nan (nan)	GS 29.188 (29.188)	mem 40.011
Train: [42][340/750]	BT 0.224 (1.182)	DT 0.008 (1.052)	loss nan (nan)	prob nan (nan)	GS 31.047 (31.047)	mem 39.961
Train: [42][345/750]	BT 0.075 (1.170)	DT 0.001 (1.041)	loss nan (nan)	prob nan (nan)	GS 35.078 (35.078)	mem 39.981
Train: [42][350/750]	BT 1.613 (1.187)	DT 1.497 (1.057)	loss nan (nan)	prob nan (nan)	GS 33.469 (33.469)	mem 40.019
Train: [42][355/750]	BT 0.170 (1.173)	DT 0.016 (1.043)	loss nan (nan)	prob nan (nan)	GS 30.500 (30.500)	mem 40.020
Train: [42][360/750]	BT 9.540 (1.184)	DT 9.416 (1.054)	loss nan (nan)	prob nan (nan)	GS 33.250 (33.250)	mem 40.107
Train: [42][365/750]	BT 0.093 (1.181)	DT 0.005 (1.052)	loss nan (nan)	prob nan (nan)	GS 28.422 (28.422)	mem 40.048
Train: [42][370/750]	BT 0.108 (1.171)	DT 0.005 (1.041)	loss nan (nan)	prob nan (nan)	GS 37.266 (37.266)	mem 40.052
Train: [42][375/750]	BT 0.153 (1.195)	DT 0.010 (1.065)	loss nan (nan)	prob nan (nan)	GS 32.953 (32.953)	mem 40.087
Train: [42][380/750]	BT 0.123 (1.181)	DT 0.001 (1.051)	loss nan (nan)	prob nan (nan)	GS 33.906 (33.906)	mem 40.054
Train: [42][385/750]	BT 0.095 (1.179)	DT 0.004 (1.049)	loss nan (nan)	prob nan (nan)	GS 35.578 (35.578)	mem 40.037
Train: [42][390/750]	BT 0.074 (1.186)	DT 0.002 (1.056)	loss nan (nan)	prob nan (nan)	GS 33.438 (33.438)	mem 39.976
Train: [42][395/750]	BT 0.192 (1.173)	DT 0.014 (1.043)	loss nan (nan)	prob nan (nan)	GS 31.141 (31.141)	mem 40.064
Train: [42][400/750]	BT 0.080 (1.191)	DT 0.003 (1.060)	loss nan (nan)	prob nan (nan)	GS 32.469 (32.469)	mem 40.000
Train: [42][405/750]	BT 0.109 (1.178)	DT 0.002 (1.047)	loss nan (nan)	prob nan (nan)	GS 34.516 (34.516)	mem 40.000
Train: [42][410/750]	BT 8.270 (1.191)	DT 8.145 (1.060)	loss nan (nan)	prob nan (nan)	GS 31.172 (31.172)	mem 40.014
Train: [42][415/750]	BT 0.141 (1.179)	DT 0.007 (1.048)	loss nan (nan)	prob nan (nan)	GS 30.453 (30.453)	mem 40.032
Train: [42][420/750]	BT 1.040 (1.169)	DT 0.949 (1.037)	loss nan (nan)	prob nan (nan)	GS 32.594 (32.594)	mem 40.235
Train: [42][425/750]	BT 0.150 (1.182)	DT 0.002 (1.050)	loss nan (nan)	prob nan (nan)	GS 30.328 (30.328)	mem 39.976
Train: [42][430/750]	BT 0.106 (1.170)	DT 0.004 (1.038)	loss nan (nan)	prob nan (nan)	GS 36.156 (36.156)	mem 39.998
Train: [42][435/750]	BT 0.116 (1.185)	DT 0.002 (1.053)	loss nan (nan)	prob nan (nan)	GS 32.734 (32.734)	mem 40.014
Train: [42][440/750]	BT 0.155 (1.173)	DT 0.020 (1.041)	loss nan (nan)	prob nan (nan)	GS 36.844 (36.844)	mem 40.052
Train: [42][445/750]	BT 0.249 (1.161)	DT 0.002 (1.030)	loss nan (nan)	prob nan (nan)	GS 29.656 (29.656)	mem 39.978
Train: [42][450/750]	BT 0.169 (1.176)	DT 0.007 (1.045)	loss nan (nan)	prob nan (nan)	GS 35.750 (35.750)	mem 40.091
Train: [42][455/750]	BT 0.078 (1.164)	DT 0.005 (1.033)	loss nan (nan)	prob nan (nan)	GS 34.812 (34.812)	mem 40.057
Train: [42][460/750]	BT 0.075 (1.179)	DT 0.001 (1.048)	loss nan (nan)	prob nan (nan)	GS 31.562 (31.562)	mem 39.971
Train: [42][465/750]	BT 0.075 (1.167)	DT 0.001 (1.037)	loss nan (nan)	prob nan (nan)	GS 27.141 (27.141)	mem 40.016
Train: [42][470/750]	BT 12.451 (1.182)	DT 12.301 (1.052)	loss nan (nan)	prob nan (nan)	GS 34.984 (34.984)	mem 40.058
Train: [42][475/750]	BT 0.092 (1.171)	DT 0.001 (1.041)	loss nan (nan)	prob nan (nan)	GS 31.859 (31.859)	mem 40.060
Train: [42][480/750]	BT 0.143 (1.160)	DT 0.013 (1.030)	loss nan (nan)	prob nan (nan)	GS 33.375 (33.375)	mem 40.106
Train: [42][485/750]	BT 0.154 (1.174)	DT 0.025 (1.044)	loss nan (nan)	prob nan (nan)	GS 29.250 (29.250)	mem 40.087
Train: [42][490/750]	BT 0.083 (1.163)	DT 0.001 (1.033)	loss nan (nan)	prob nan (nan)	GS 33.938 (33.938)	mem 40.085
Train: [42][495/750]	BT 0.083 (1.177)	DT 0.001 (1.048)	loss nan (nan)	prob nan (nan)	GS 29.109 (29.109)	mem 40.077
Train: [42][500/750]	BT 0.079 (1.166)	DT 0.001 (1.037)	loss nan (nan)	prob nan (nan)	GS 34.094 (34.094)	mem 40.124
Train: [42][505/750]	BT 0.224 (1.156)	DT 0.006 (1.027)	loss nan (nan)	prob nan (nan)	GS 37.781 (37.781)	mem 40.189
Train: [42][510/750]	BT 0.109 (1.166)	DT 0.009 (1.037)	loss nan (nan)	prob nan (nan)	GS 32.688 (32.688)	mem 40.027
Train: [42][515/750]	BT 0.085 (1.156)	DT 0.003 (1.027)	loss nan (nan)	prob nan (nan)	GS 29.688 (29.688)	mem 40.030
Train: [42][520/750]	BT 0.192 (1.168)	DT 0.002 (1.039)	loss nan (nan)	prob nan (nan)	GS 37.875 (37.875)	mem 40.086
Train: [42][525/750]	BT 0.082 (1.158)	DT 0.002 (1.029)	loss nan (nan)	prob nan (nan)	GS 32.312 (32.312)	mem 40.086
Train: [42][530/750]	BT 9.686 (1.167)	DT 9.560 (1.037)	loss nan (nan)	prob nan (nan)	GS 27.422 (27.422)	mem 40.080
Train: [42][535/750]	BT 0.087 (1.157)	DT 0.010 (1.028)	loss nan (nan)	prob nan (nan)	GS 32.906 (32.906)	mem 40.082
Train: [42][540/750]	BT 0.123 (1.147)	DT 0.001 (1.018)	loss nan (nan)	prob nan (nan)	GS 34.359 (34.359)	mem 40.159
Train: [42][545/750]	BT 0.083 (1.164)	DT 0.001 (1.035)	loss nan (nan)	prob nan (nan)	GS 35.078 (35.078)	mem 40.070
Train: [42][550/750]	BT 0.239 (1.154)	DT 0.001 (1.026)	loss nan (nan)	prob nan (nan)	GS 31.422 (31.422)	mem 40.071
Train: [42][555/750]	BT 0.082 (1.166)	DT 0.001 (1.038)	loss nan (nan)	prob nan (nan)	GS 40.453 (40.453)	mem 39.979
Train: [42][560/750]	BT 0.098 (1.157)	DT 0.001 (1.029)	loss nan (nan)	prob nan (nan)	GS 31.234 (31.234)	mem 39.929
Train: [42][565/750]	BT 0.153 (1.147)	DT 0.002 (1.020)	loss nan (nan)	prob nan (nan)	GS 31.203 (31.203)	mem 39.930
Train: [42][570/750]	BT 0.102 (1.159)	DT 0.006 (1.032)	loss nan (nan)	prob nan (nan)	GS 37.953 (37.953)	mem 40.036
Train: [42][575/750]	BT 0.157 (1.150)	DT 0.001 (1.023)	loss nan (nan)	prob nan (nan)	GS 33.734 (33.734)	mem 40.038
Train: [42][580/750]	BT 0.121 (1.165)	DT 0.001 (1.037)	loss nan (nan)	prob nan (nan)	GS 32.688 (32.688)	mem 40.216
Train: [42][585/750]	BT 0.166 (1.156)	DT 0.002 (1.029)	loss nan (nan)	prob nan (nan)	GS 36.734 (36.734)	mem 40.048
Train: [42][590/750]	BT 13.831 (1.171)	DT 13.698 (1.043)	loss nan (nan)	prob nan (nan)	GS 32.438 (32.438)	mem 40.429
Train: [42][595/750]	BT 0.115 (1.162)	DT 0.005 (1.034)	loss nan (nan)	prob nan (nan)	GS 28.812 (28.812)	mem 40.016
Train: [42][600/750]	BT 0.099 (1.153)	DT 0.002 (1.026)	loss nan (nan)	prob nan (nan)	GS 35.000 (35.000)	mem 40.021
Train: [42][605/750]	BT 0.074 (1.166)	DT 0.001 (1.040)	loss nan (nan)	prob nan (nan)	GS 30.766 (30.766)	mem 40.062
Train: [42][610/750]	BT 0.091 (1.158)	DT 0.007 (1.031)	loss nan (nan)	prob nan (nan)	GS 29.875 (29.875)	mem 40.062
Train: [42][615/750]	BT 0.120 (1.169)	DT 0.001 (1.042)	loss nan (nan)	prob nan (nan)	GS 35.000 (35.000)	mem 39.962
Train: [42][620/750]	BT 0.178 (1.160)	DT 0.001 (1.034)	loss nan (nan)	prob nan (nan)	GS 35.781 (35.781)	mem 40.149
Train: [42][625/750]	BT 0.203 (1.152)	DT 0.002 (1.026)	loss nan (nan)	prob nan (nan)	GS 27.938 (27.938)	mem 39.994
Train: [42][630/750]	BT 0.082 (1.162)	DT 0.001 (1.036)	loss nan (nan)	prob nan (nan)	GS 36.016 (36.016)	mem 39.957
Train: [42][635/750]	BT 0.197 (1.154)	DT 0.003 (1.028)	loss nan (nan)	prob nan (nan)	GS 39.422 (39.422)	mem 39.993
Train: [42][640/750]	BT 0.090 (1.168)	DT 0.001 (1.042)	loss nan (nan)	prob nan (nan)	GS 33.703 (33.703)	mem 40.022
Train: [42][645/750]	BT 0.139 (1.160)	DT 0.002 (1.034)	loss nan (nan)	prob nan (nan)	GS 34.484 (34.484)	mem 40.104
Train: [42][650/750]	BT 12.246 (1.171)	DT 12.153 (1.045)	loss nan (nan)	prob nan (nan)	GS 37.188 (37.188)	mem 40.130
Train: [42][655/750]	BT 0.108 (1.163)	DT 0.001 (1.037)	loss nan (nan)	prob nan (nan)	GS 33.016 (33.016)	mem 40.120
Train: [42][660/750]	BT 0.103 (1.155)	DT 0.008 (1.029)	loss nan (nan)	prob nan (nan)	GS 31.969 (31.969)	mem 40.115
Train: [42][665/750]	BT 0.186 (1.162)	DT 0.009 (1.036)	loss nan (nan)	prob nan (nan)	GS 32.516 (32.516)	mem 40.061
Train: [42][670/750]	BT 0.121 (1.154)	DT 0.002 (1.028)	loss nan (nan)	prob nan (nan)	GS 31.109 (31.109)	mem 40.061
Train: [42][675/750]	BT 0.088 (1.165)	DT 0.014 (1.038)	loss nan (nan)	prob nan (nan)	GS 33.797 (33.797)	mem 40.083
Train: [42][680/750]	BT 0.112 (1.157)	DT 0.010 (1.031)	loss nan (nan)	prob nan (nan)	GS 28.656 (28.656)	mem 40.086
Train: [42][685/750]	BT 0.114 (1.150)	DT 0.006 (1.023)	loss nan (nan)	prob nan (nan)	GS 28.609 (28.609)	mem 40.087
Train: [42][690/750]	BT 0.109 (1.156)	DT 0.002 (1.030)	loss nan (nan)	prob nan (nan)	GS 31.344 (31.344)	mem 40.277
Train: [42][695/750]	BT 0.131 (1.149)	DT 0.005 (1.022)	loss nan (nan)	prob nan (nan)	GS 32.000 (32.000)	mem 40.311
Train: [42][700/750]	BT 0.779 (1.155)	DT 0.659 (1.029)	loss nan (nan)	prob nan (nan)	GS 32.391 (32.391)	mem 40.072
Train: [42][705/750]	BT 0.169 (1.148)	DT 0.002 (1.021)	loss nan (nan)	prob nan (nan)	GS 30.844 (30.844)	mem 40.154
arpack error, retry= 0
Train: [42][710/750]	BT 11.767 (1.157)	DT 11.680 (1.031)	loss nan (nan)	prob nan (nan)	GS 30.062 (30.062)	mem 39.982
Train: [42][715/750]	BT 0.196 (1.157)	DT 0.002 (1.030)	loss nan (nan)	prob nan (nan)	GS 28.312 (28.312)	mem 40.099
Train: [42][720/750]	BT 0.112 (1.149)	DT 0.002 (1.023)	loss nan (nan)	prob nan (nan)	GS 34.391 (34.391)	mem 40.075
Train: [42][725/750]	BT 0.167 (1.155)	DT 0.001 (1.029)	loss nan (nan)	prob nan (nan)	GS 28.203 (28.203)	mem 40.076
Train: [42][730/750]	BT 0.108 (1.148)	DT 0.002 (1.022)	loss nan (nan)	prob nan (nan)	GS 33.641 (33.641)	mem 40.117
Train: [42][735/750]	BT 0.116 (1.151)	DT 0.002 (1.024)	loss nan (nan)	prob nan (nan)	GS 27.062 (27.062)	mem 36.791
Train: [42][740/750]	BT 0.131 (1.146)	DT 0.002 (1.020)	loss nan (nan)	prob nan (nan)	GS 32.203 (32.203)	mem 25.281
Train: [42][745/750]	BT 0.170 (1.139)	DT 0.016 (1.013)	loss nan (nan)	prob nan (nan)	GS 29.906 (29.906)	mem 25.282
Train: [42][750/750]	BT 0.089 (1.134)	DT 0.002 (1.008)	loss nan (nan)	prob nan (nan)	GS 34.781 (34.781)	mem 13.637
Train: [42][755/750]	BT 0.068 (1.128)	DT 0.001 (1.002)	loss nan (nan)	prob nan (nan)	GS 32.781 (32.781)	mem 7.696
epoch 42, total time 851.73
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [43][1/750]	BT 21.288 (21.288)	DT 21.131 (21.131)	loss nan (nan)	prob nan (nan)	GS 29.594 (29.594)	mem 38.679
Train: [43][5/750]	BT 3.121 (5.507)	DT 2.989 (5.357)	loss nan (nan)	prob nan (nan)	GS 36.625 (36.625)	mem 38.808
Train: [43][10/750]	BT 0.136 (2.833)	DT 0.004 (2.681)	loss nan (nan)	prob nan (nan)	GS 34.672 (34.672)	mem 38.898
Train: [43][15/750]	BT 0.090 (2.288)	DT 0.004 (2.144)	loss nan (nan)	prob nan (nan)	GS 30.047 (30.047)	mem 38.857
Train: [43][20/750]	BT 0.168 (2.000)	DT 0.006 (1.854)	loss nan (nan)	prob nan (nan)	GS 33.797 (33.797)	mem 38.896
Train: [43][25/750]	BT 0.841 (1.669)	DT 0.737 (1.514)	loss nan (nan)	prob nan (nan)	GS 29.141 (29.141)	mem 38.951
Train: [43][30/750]	BT 3.200 (1.842)	DT 3.016 (1.688)	loss nan (nan)	prob nan (nan)	GS 34.219 (34.219)	mem 39.101
Train: [43][35/750]	BT 0.108 (1.766)	DT 0.004 (1.614)	loss nan (nan)	prob nan (nan)	GS 26.547 (26.547)	mem 39.217
Train: [43][40/750]	BT 4.395 (1.667)	DT 4.235 (1.518)	loss nan (nan)	prob nan (nan)	GS 36.141 (36.141)	mem 39.080
Train: [43][45/750]	BT 0.087 (1.628)	DT 0.004 (1.483)	loss nan (nan)	prob nan (nan)	GS 32.656 (32.656)	mem 39.092
Train: [43][50/750]	BT 0.123 (1.479)	DT 0.002 (1.335)	loss nan (nan)	prob nan (nan)	GS 31.281 (31.281)	mem 39.325
Train: [43][55/750]	BT 0.133 (1.607)	DT 0.018 (1.464)	loss nan (nan)	prob nan (nan)	GS 33.188 (33.188)	mem 39.102
Train: [43][60/750]	BT 0.179 (1.488)	DT 0.002 (1.343)	loss nan (nan)	prob nan (nan)	GS 33.312 (33.312)	mem 39.309
Train: [43][65/750]	BT 0.125 (1.529)	DT 0.008 (1.384)	loss nan (nan)	prob nan (nan)	GS 30.312 (30.312)	mem 39.114
Train: [43][70/750]	BT 0.122 (1.472)	DT 0.002 (1.330)	loss nan (nan)	prob nan (nan)	GS 33.594 (33.594)	mem 39.140
Train: [43][75/750]	BT 0.155 (1.384)	DT 0.002 (1.242)	loss nan (nan)	prob nan (nan)	GS 30.156 (30.156)	mem 39.145
Train: [43][80/750]	BT 1.783 (1.512)	DT 1.594 (1.369)	loss nan (nan)	prob nan (nan)	GS 37.547 (37.547)	mem 39.273
Train: [43][85/750]	BT 0.109 (1.432)	DT 0.004 (1.289)	loss nan (nan)	prob nan (nan)	GS 31.234 (31.234)	mem 39.336
Train: [43][90/750]	BT 9.805 (1.483)	DT 9.663 (1.338)	loss nan (nan)	prob nan (nan)	GS 32.828 (32.828)	mem 39.342
Train: [43][95/750]	BT 0.138 (1.418)	DT 0.011 (1.276)	loss nan (nan)	prob nan (nan)	GS 26.766 (26.766)	mem 39.374
Train: [43][100/750]	BT 2.370 (1.377)	DT 2.279 (1.235)	loss nan (nan)	prob nan (nan)	GS 32.719 (32.719)	mem 39.361
Train: [43][105/750]	BT 0.101 (1.436)	DT 0.002 (1.295)	loss nan (nan)	prob nan (nan)	GS 31.781 (31.781)	mem 39.509
Train: [43][110/750]	BT 0.094 (1.376)	DT 0.001 (1.237)	loss nan (nan)	prob nan (nan)	GS 34.047 (34.047)	mem 39.485
Train: [43][115/750]	BT 0.116 (1.332)	DT 0.001 (1.193)	loss nan (nan)	prob nan (nan)	GS 30.484 (30.484)	mem 39.778
Train: [43][120/750]	BT 0.090 (1.390)	DT 0.001 (1.252)	loss nan (nan)	prob nan (nan)	GS 37.234 (37.234)	mem 39.512
Train: [43][125/750]	BT 0.158 (1.340)	DT 0.002 (1.203)	loss nan (nan)	prob nan (nan)	GS 33.219 (33.219)	mem 39.582
Train: [43][130/750]	BT 0.098 (1.374)	DT 0.004 (1.239)	loss nan (nan)	prob nan (nan)	GS 30.656 (30.656)	mem 39.553
Train: [43][135/750]	BT 0.086 (1.328)	DT 0.002 (1.193)	loss nan (nan)	prob nan (nan)	GS 28.578 (28.578)	mem 39.714
Train: [43][140/750]	BT 9.797 (1.356)	DT 9.691 (1.220)	loss nan (nan)	prob nan (nan)	GS 32.969 (32.969)	mem 39.804
Train: [43][145/750]	BT 0.177 (1.314)	DT 0.012 (1.178)	loss nan (nan)	prob nan (nan)	GS 28.594 (28.594)	mem 39.757
Train: [43][150/750]	BT 5.713 (1.311)	DT 5.579 (1.176)	loss nan (nan)	prob nan (nan)	GS 34.703 (34.703)	mem 39.824
Train: [43][155/750]	BT 0.113 (1.321)	DT 0.001 (1.187)	loss nan (nan)	prob nan (nan)	GS 25.922 (25.922)	mem 39.727
Train: [43][160/750]	BT 0.088 (1.284)	DT 0.002 (1.150)	loss nan (nan)	prob nan (nan)	GS 35.953 (35.953)	mem 39.777
Train: [43][165/750]	BT 0.170 (1.298)	DT 0.001 (1.163)	loss nan (nan)	prob nan (nan)	GS 29.906 (29.906)	mem 39.865
Train: [43][170/750]	BT 0.085 (1.262)	DT 0.001 (1.129)	loss nan (nan)	prob nan (nan)	GS 32.641 (32.641)	mem 39.863
Train: [43][175/750]	BT 0.114 (1.299)	DT 0.002 (1.166)	loss nan (nan)	prob nan (nan)	GS 31.234 (31.234)	mem 39.846
Train: [43][180/750]	BT 0.243 (1.267)	DT 0.003 (1.134)	loss nan (nan)	prob nan (nan)	GS 36.000 (36.000)	mem 39.807
Train: [43][185/750]	BT 0.096 (1.242)	DT 0.009 (1.108)	loss nan (nan)	prob nan (nan)	GS 28.625 (28.625)	mem 39.884
Train: [43][190/750]	BT 0.120 (1.280)	DT 0.002 (1.146)	loss nan (nan)	prob nan (nan)	GS 31.938 (31.938)	mem 39.938
Train: [43][195/750]	BT 0.321 (1.252)	DT 0.007 (1.116)	loss nan (nan)	prob nan (nan)	GS 31.062 (31.062)	mem 39.841
Train: [43][200/750]	BT 0.094 (1.292)	DT 0.001 (1.157)	loss nan (nan)	prob nan (nan)	GS 28.547 (28.547)	mem 39.770
Train: [43][205/750]	BT 0.088 (1.263)	DT 0.002 (1.129)	loss nan (nan)	prob nan (nan)	GS 30.266 (30.266)	mem 39.771
Train: [43][210/750]	BT 10.536 (1.285)	DT 10.459 (1.152)	loss nan (nan)	prob nan (nan)	GS 33.375 (33.375)	mem 39.831
Train: [43][215/750]	BT 0.088 (1.258)	DT 0.002 (1.126)	loss nan (nan)	prob nan (nan)	GS 32.219 (32.219)	mem 40.012
Train: [43][220/750]	BT 0.251 (1.233)	DT 0.059 (1.100)	loss nan (nan)	prob nan (nan)	GS 29.297 (29.297)	mem 39.912
Train: [43][225/750]	BT 0.137 (1.261)	DT 0.014 (1.128)	loss nan (nan)	prob nan (nan)	GS 31.234 (31.234)	mem 40.076
Train: [43][230/750]	BT 0.093 (1.236)	DT 0.002 (1.104)	loss nan (nan)	prob nan (nan)	GS 33.672 (33.672)	mem 39.782
Train: [43][235/750]	BT 0.066 (1.267)	DT 0.001 (1.135)	loss nan (nan)	prob nan (nan)	GS 31.297 (31.297)	mem 39.846
Train: [43][240/750]	BT 0.190 (1.243)	DT 0.001 (1.111)	loss nan (nan)	prob nan (nan)	GS 30.953 (30.953)	mem 39.952
Train: [43][245/750]	BT 0.139 (1.221)	DT 0.002 (1.089)	loss nan (nan)	prob nan (nan)	GS 30.797 (30.797)	mem 39.941
Train: [43][250/750]	BT 0.171 (1.256)	DT 0.002 (1.124)	loss nan (nan)	prob nan (nan)	GS 34.312 (34.312)	mem 39.834
Train: [43][255/750]	BT 0.117 (1.235)	DT 0.013 (1.103)	loss nan (nan)	prob nan (nan)	GS 30.250 (30.250)	mem 39.915
Train: [43][260/750]	BT 0.116 (1.264)	DT 0.001 (1.132)	loss nan (nan)	prob nan (nan)	GS 36.078 (36.078)	mem 39.961
Train: [43][265/750]	BT 0.078 (1.242)	DT 0.001 (1.110)	loss nan (nan)	prob nan (nan)	GS 35.672 (35.672)	mem 39.963
Train: [43][270/750]	BT 12.908 (1.269)	DT 12.812 (1.137)	loss nan (nan)	prob nan (nan)	GS 33.812 (33.812)	mem 39.956
Train: [43][275/750]	BT 0.111 (1.248)	DT 0.001 (1.117)	loss nan (nan)	prob nan (nan)	GS 31.359 (31.359)	mem 40.054
Train: [43][280/750]	BT 0.111 (1.229)	DT 0.001 (1.097)	loss nan (nan)	prob nan (nan)	GS 34.625 (34.625)	mem 39.979
Train: [43][285/750]	BT 0.121 (1.254)	DT 0.001 (1.123)	loss nan (nan)	prob nan (nan)	GS 36.078 (36.078)	mem 40.017
Train: [43][290/750]	BT 0.125 (1.235)	DT 0.002 (1.104)	loss nan (nan)	prob nan (nan)	GS 32.547 (32.547)	mem 40.021
Train: [43][295/750]	BT 0.085 (1.258)	DT 0.001 (1.127)	loss nan (nan)	prob nan (nan)	GS 31.047 (31.047)	mem 39.972
Train: [43][300/750]	BT 0.065 (1.238)	DT 0.001 (1.108)	loss nan (nan)	prob nan (nan)	GS 39.453 (39.453)	mem 39.973
Train: [43][305/750]	BT 0.108 (1.220)	DT 0.003 (1.090)	loss nan (nan)	prob nan (nan)	GS 35.469 (35.469)	mem 39.999
Train: [43][310/750]	BT 0.093 (1.234)	DT 0.003 (1.104)	loss nan (nan)	prob nan (nan)	GS 34.562 (34.562)	mem 40.073
Train: [43][315/750]	BT 0.138 (1.216)	DT 0.002 (1.087)	loss nan (nan)	prob nan (nan)	GS 36.391 (36.391)	mem 40.045
Train: [43][320/750]	BT 0.068 (1.237)	DT 0.001 (1.108)	loss nan (nan)	prob nan (nan)	GS 34.922 (34.922)	mem 40.063
Train: [43][325/750]	BT 0.207 (1.220)	DT 0.002 (1.091)	loss nan (nan)	prob nan (nan)	GS 31.562 (31.562)	mem 40.034
Train: [43][330/750]	BT 11.766 (1.240)	DT 11.678 (1.110)	loss nan (nan)	prob nan (nan)	GS 30.438 (30.438)	mem 40.036
Train: [43][335/750]	BT 0.186 (1.224)	DT 0.005 (1.093)	loss nan (nan)	prob nan (nan)	GS 30.078 (30.078)	mem 39.981
Train: [43][340/750]	BT 0.142 (1.208)	DT 0.001 (1.077)	loss nan (nan)	prob nan (nan)	GS 31.125 (31.125)	mem 40.034
Train: [43][345/750]	BT 0.118 (1.221)	DT 0.005 (1.091)	loss nan (nan)	prob nan (nan)	GS 31.391 (31.391)	mem 39.981
Train: [43][350/750]	BT 0.148 (1.206)	DT 0.002 (1.076)	loss nan (nan)	prob nan (nan)	GS 31.656 (31.656)	mem 40.098
Train: [43][355/750]	BT 0.104 (1.219)	DT 0.001 (1.089)	loss nan (nan)	prob nan (nan)	GS 29.219 (29.219)	mem 40.025
Train: [43][360/750]	BT 0.154 (1.205)	DT 0.002 (1.074)	loss nan (nan)	prob nan (nan)	GS 28.188 (28.188)	mem 39.976
Train: [43][365/750]	BT 0.097 (1.190)	DT 0.002 (1.059)	loss nan (nan)	prob nan (nan)	GS 34.234 (34.234)	mem 39.979
Train: [43][370/750]	BT 0.112 (1.207)	DT 0.002 (1.077)	loss nan (nan)	prob nan (nan)	GS 36.328 (36.328)	mem 39.968
Train: [43][375/750]	BT 0.111 (1.193)	DT 0.001 (1.062)	loss nan (nan)	prob nan (nan)	GS 28.281 (28.281)	mem 39.989
Train: [43][380/750]	BT 0.150 (1.209)	DT 0.005 (1.078)	loss nan (nan)	prob nan (nan)	GS 34.453 (34.453)	mem 40.539
Train: [43][385/750]	BT 0.110 (1.195)	DT 0.006 (1.064)	loss nan (nan)	prob nan (nan)	GS 32.750 (32.750)	mem 40.020
Train: [43][390/750]	BT 10.316 (1.207)	DT 10.228 (1.076)	loss nan (nan)	prob nan (nan)	GS 34.578 (34.578)	mem 40.168
Train: [43][395/750]	BT 0.181 (1.193)	DT 0.001 (1.063)	loss nan (nan)	prob nan (nan)	GS 30.656 (30.656)	mem 40.119
Train: [43][400/750]	BT 0.094 (1.180)	DT 0.009 (1.050)	loss nan (nan)	prob nan (nan)	GS 34.719 (34.719)	mem 40.037
Train: [43][405/750]	BT 0.079 (1.205)	DT 0.003 (1.075)	loss nan (nan)	prob nan (nan)	GS 27.250 (27.250)	mem 39.931
Train: [43][410/750]	BT 0.222 (1.192)	DT 0.003 (1.062)	loss nan (nan)	prob nan (nan)	GS 34.812 (34.812)	mem 39.950
Train: [43][415/750]	BT 0.186 (1.201)	DT 0.014 (1.071)	loss nan (nan)	prob nan (nan)	GS 29.672 (29.672)	mem 40.027
Train: [43][420/750]	BT 0.084 (1.188)	DT 0.003 (1.059)	loss nan (nan)	prob nan (nan)	GS 30.500 (30.500)	mem 39.994
Train: [43][425/750]	BT 0.073 (1.176)	DT 0.002 (1.046)	loss nan (nan)	prob nan (nan)	GS 30.453 (30.453)	mem 40.004
Train: [43][430/750]	BT 0.124 (1.185)	DT 0.001 (1.055)	loss nan (nan)	prob nan (nan)	GS 31.266 (31.266)	mem 40.082
Train: [43][435/750]	BT 0.100 (1.173)	DT 0.002 (1.043)	loss nan (nan)	prob nan (nan)	GS 30.938 (30.938)	mem 40.052
Train: [43][440/750]	BT 0.169 (1.187)	DT 0.002 (1.057)	loss nan (nan)	prob nan (nan)	GS 34.641 (34.641)	mem 39.959
Train: [43][445/750]	BT 0.140 (1.175)	DT 0.002 (1.045)	loss nan (nan)	prob nan (nan)	GS 32.516 (32.516)	mem 39.980
Train: [43][450/750]	BT 11.664 (1.189)	DT 11.520 (1.059)	loss nan (nan)	prob nan (nan)	GS 38.219 (38.219)	mem 39.968
Train: [43][455/750]	BT 0.180 (1.188)	DT 0.002 (1.058)	loss nan (nan)	prob nan (nan)	GS 28.531 (28.531)	mem 39.996
Train: [43][460/750]	BT 0.083 (1.176)	DT 0.005 (1.047)	loss nan (nan)	prob nan (nan)	GS 35.953 (35.953)	mem 40.049
Train: [43][465/750]	BT 0.140 (1.193)	DT 0.002 (1.064)	loss nan (nan)	prob nan (nan)	GS 31.562 (31.562)	mem 40.159
Train: [43][470/750]	BT 0.234 (1.182)	DT 0.012 (1.052)	loss nan (nan)	prob nan (nan)	GS 34.359 (34.359)	mem 40.065
Train: [43][475/750]	BT 0.108 (1.178)	DT 0.002 (1.048)	loss nan (nan)	prob nan (nan)	GS 30.922 (30.922)	mem 40.008
Train: [43][480/750]	BT 0.081 (1.185)	DT 0.002 (1.056)	loss nan (nan)	prob nan (nan)	GS 32.000 (32.000)	mem 40.244
Train: [43][485/750]	BT 0.150 (1.175)	DT 0.005 (1.045)	loss nan (nan)	prob nan (nan)	GS 34.500 (34.500)	mem 39.995
Train: [43][490/750]	BT 0.204 (1.183)	DT 0.013 (1.053)	loss nan (nan)	prob nan (nan)	GS 34.703 (34.703)	mem 40.057
Train: [43][495/750]	BT 0.102 (1.172)	DT 0.007 (1.042)	loss nan (nan)	prob nan (nan)	GS 33.672 (33.672)	mem 40.069
Train: [43][500/750]	BT 7.466 (1.185)	DT 7.380 (1.055)	loss nan (nan)	prob nan (nan)	GS 35.172 (35.172)	mem 40.130
Train: [43][505/750]	BT 0.179 (1.175)	DT 0.001 (1.045)	loss nan (nan)	prob nan (nan)	GS 32.156 (32.156)	mem 40.257
Train: [43][510/750]	BT 3.276 (1.171)	DT 3.189 (1.041)	loss nan (nan)	prob nan (nan)	GS 32.016 (32.016)	mem 40.019
Train: [43][515/750]	BT 0.131 (1.181)	DT 0.002 (1.050)	loss nan (nan)	prob nan (nan)	GS 35.234 (35.234)	mem 40.084
Train: [43][520/750]	BT 0.079 (1.171)	DT 0.002 (1.040)	loss nan (nan)	prob nan (nan)	GS 33.109 (33.109)	mem 40.042
Train: [43][525/750]	BT 0.073 (1.184)	DT 0.002 (1.053)	loss nan (nan)	prob nan (nan)	GS 33.047 (33.047)	mem 40.044
Train: [43][530/750]	BT 0.124 (1.174)	DT 0.001 (1.043)	loss nan (nan)	prob nan (nan)	GS 31.719 (31.719)	mem 40.044
Train: [43][535/750]	BT 0.129 (1.164)	DT 0.001 (1.033)	loss nan (nan)	prob nan (nan)	GS 30.219 (30.219)	mem 40.044
Train: [43][540/750]	BT 0.163 (1.173)	DT 0.004 (1.041)	loss nan (nan)	prob nan (nan)	GS 33.891 (33.891)	mem 40.227
Train: [43][545/750]	BT 0.138 (1.163)	DT 0.011 (1.032)	loss nan (nan)	prob nan (nan)	GS 29.359 (29.359)	mem 40.187
Train: [43][550/750]	BT 0.153 (1.174)	DT 0.012 (1.043)	loss nan (nan)	prob nan (nan)	GS 32.000 (32.000)	mem 40.107
Train: [43][555/750]	BT 0.092 (1.165)	DT 0.002 (1.034)	loss nan (nan)	prob nan (nan)	GS 32.312 (32.312)	mem 40.109
Train: [43][560/750]	BT 10.836 (1.180)	DT 10.684 (1.050)	loss nan (nan)	prob nan (nan)	GS 35.844 (35.844)	mem 40.150
Train: [43][565/750]	BT 0.115 (1.171)	DT 0.003 (1.040)	loss nan (nan)	prob nan (nan)	GS 25.688 (25.688)	mem 40.093
Train: [43][570/750]	BT 0.334 (1.162)	DT 0.198 (1.032)	loss nan (nan)	prob nan (nan)	GS 31.000 (31.000)	mem 40.093
Train: [43][575/750]	BT 0.102 (1.175)	DT 0.001 (1.045)	loss nan (nan)	prob nan (nan)	GS 30.281 (30.281)	mem 40.127
Train: [43][580/750]	BT 0.110 (1.166)	DT 0.002 (1.036)	loss nan (nan)	prob nan (nan)	GS 35.094 (35.094)	mem 40.273
Train: [43][585/750]	BT 0.070 (1.181)	DT 0.001 (1.050)	loss nan (nan)	prob nan (nan)	GS 30.531 (30.531)	mem 40.041
Train: [43][590/750]	BT 0.085 (1.172)	DT 0.001 (1.041)	loss nan (nan)	prob nan (nan)	GS 33.062 (33.062)	mem 40.065
Train: [43][595/750]	BT 0.092 (1.163)	DT 0.001 (1.032)	loss nan (nan)	prob nan (nan)	GS 32.906 (32.906)	mem 40.066
Train: [43][600/750]	BT 0.087 (1.169)	DT 0.002 (1.039)	loss nan (nan)	prob nan (nan)	GS 36.531 (36.531)	mem 40.176
Train: [43][605/750]	BT 0.122 (1.161)	DT 0.002 (1.031)	loss nan (nan)	prob nan (nan)	GS 30.234 (30.234)	mem 40.177
Train: [43][610/750]	BT 0.127 (1.170)	DT 0.001 (1.040)	loss nan (nan)	prob nan (nan)	GS 33.562 (33.562)	mem 40.116
Train: [43][615/750]	BT 0.085 (1.161)	DT 0.002 (1.032)	loss nan (nan)	prob nan (nan)	GS 34.391 (34.391)	mem 40.306
Train: [43][620/750]	BT 9.703 (1.173)	DT 9.624 (1.044)	loss nan (nan)	prob nan (nan)	GS 33.812 (33.812)	mem 40.223
Train: [43][625/750]	BT 0.299 (1.165)	DT 0.002 (1.036)	loss nan (nan)	prob nan (nan)	GS 28.000 (28.000)	mem 40.168
Train: [43][630/750]	BT 0.217 (1.157)	DT 0.024 (1.027)	loss nan (nan)	prob nan (nan)	GS 33.031 (33.031)	mem 40.381
Train: [43][635/750]	BT 0.175 (1.165)	DT 0.002 (1.035)	loss nan (nan)	prob nan (nan)	GS 36.906 (36.906)	mem 40.040
Train: [43][640/750]	BT 0.121 (1.156)	DT 0.004 (1.027)	loss nan (nan)	prob nan (nan)	GS 32.203 (32.203)	mem 40.042
Train: [43][645/750]	BT 0.096 (1.165)	DT 0.002 (1.035)	loss nan (nan)	prob nan (nan)	GS 32.469 (32.469)	mem 40.081
Train: [43][650/750]	BT 0.062 (1.157)	DT 0.001 (1.027)	loss nan (nan)	prob nan (nan)	GS 27.859 (27.859)	mem 40.087
Train: [43][655/750]	BT 0.246 (1.152)	DT 0.002 (1.023)	loss nan (nan)	prob nan (nan)	GS 29.562 (29.562)	mem 40.107
Train: [43][660/750]	BT 0.090 (1.162)	DT 0.002 (1.033)	loss nan (nan)	prob nan (nan)	GS 35.781 (35.781)	mem 39.942
Train: [43][665/750]	BT 0.114 (1.154)	DT 0.002 (1.025)	loss nan (nan)	prob nan (nan)	GS 32.875 (32.875)	mem 39.936
Train: [43][670/750]	BT 0.072 (1.162)	DT 0.002 (1.033)	loss nan (nan)	prob nan (nan)	GS 33.047 (33.047)	mem 40.083
Train: [43][675/750]	BT 0.135 (1.156)	DT 0.002 (1.027)	loss nan (nan)	prob nan (nan)	GS 33.766 (33.766)	mem 40.009
Train: [43][680/750]	BT 8.958 (1.168)	DT 8.894 (1.039)	loss nan (nan)	prob nan (nan)	GS 33.844 (33.844)	mem 40.101
Train: [43][685/750]	BT 0.078 (1.161)	DT 0.001 (1.032)	loss nan (nan)	prob nan (nan)	GS 31.953 (31.953)	mem 40.151
Train: [43][690/750]	BT 0.410 (1.153)	DT 0.179 (1.024)	loss nan (nan)	prob nan (nan)	GS 33.172 (33.172)	mem 40.471
Train: [43][695/750]	BT 0.134 (1.167)	DT 0.026 (1.038)	loss nan (nan)	prob nan (nan)	GS 33.422 (33.422)	mem 40.079
Train: [43][700/750]	BT 0.081 (1.160)	DT 0.001 (1.031)	loss nan (nan)	prob nan (nan)	GS 33.500 (33.500)	mem 40.080
Train: [43][705/750]	BT 0.103 (1.172)	DT 0.001 (1.043)	loss nan (nan)	prob nan (nan)	GS 28.734 (28.734)	mem 40.182
arpack error, retry= 0
arpack error, retry= 0
Train: [43][710/750]	BT 0.112 (1.165)	DT 0.006 (1.036)	loss nan (nan)	prob nan (nan)	GS 36.438 (36.438)	mem 40.049
Train: [43][715/750]	BT 0.123 (1.158)	DT 0.001 (1.029)	loss nan (nan)	prob nan (nan)	GS 33.109 (33.109)	mem 40.062
Train: [43][720/750]	BT 0.161 (1.167)	DT 0.001 (1.039)	loss nan (nan)	prob nan (nan)	GS 35.406 (35.406)	mem 40.020
Train: [43][725/750]	BT 0.190 (1.160)	DT 0.004 (1.031)	loss nan (nan)	prob nan (nan)	GS 34.969 (34.969)	mem 40.024
Train: [43][730/750]	BT 0.134 (1.165)	DT 0.008 (1.036)	loss nan (nan)	prob nan (nan)	GS 33.703 (33.703)	mem 39.563
Train: [43][735/750]	BT 0.128 (1.158)	DT 0.005 (1.029)	loss nan (nan)	prob nan (nan)	GS 30.812 (30.812)	mem 39.562
Train: [43][740/750]	BT 4.998 (1.157)	DT 4.932 (1.029)	loss nan (nan)	prob nan (nan)	GS 28.125 (28.125)	mem 7.696
Train: [43][745/750]	BT 0.107 (1.150)	DT 0.002 (1.022)	loss nan (nan)	prob nan (nan)	GS 32.906 (32.906)	mem 7.696
Train: [43][750/750]	BT 0.066 (1.143)	DT 0.005 (1.015)	loss nan (nan)	prob nan (nan)	GS 28.875 (28.875)	mem 7.698
Train: [43][755/750]	BT 0.087 (1.137)	DT 0.001 (1.010)	loss nan (nan)	prob nan (nan)	GS 30.625 (30.625)	mem 7.625
epoch 43, total time 858.80
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [44][1/750]	BT 23.461 (23.461)	DT 23.223 (23.223)	loss nan (nan)	prob nan (nan)	GS 29.500 (29.500)	mem 38.717
Train: [44][5/750]	BT 0.183 (5.396)	DT 0.003 (5.206)	loss nan (nan)	prob nan (nan)	GS 32.734 (32.734)	mem 38.831
Train: [44][10/750]	BT 0.190 (2.795)	DT 0.023 (2.608)	loss nan (nan)	prob nan (nan)	GS 33.578 (33.578)	mem 38.932
Train: [44][15/750]	BT 0.119 (2.758)	DT 0.001 (2.595)	loss nan (nan)	prob nan (nan)	GS 34.328 (34.328)	mem 38.840
Train: [44][20/750]	BT 0.163 (2.113)	DT 0.004 (1.947)	loss nan (nan)	prob nan (nan)	GS 32.266 (32.266)	mem 38.888
Train: [44][25/750]	BT 1.499 (1.774)	DT 1.388 (1.614)	loss nan (nan)	prob nan (nan)	GS 30.922 (30.922)	mem 39.037
Train: [44][30/750]	BT 0.089 (1.857)	DT 0.002 (1.703)	loss nan (nan)	prob nan (nan)	GS 31.344 (31.344)	mem 39.547
Train: [44][35/750]	BT 0.186 (1.619)	DT 0.008 (1.461)	loss nan (nan)	prob nan (nan)	GS 31.172 (31.172)	mem 39.557
Train: [44][40/750]	BT 0.061 (1.754)	DT 0.001 (1.606)	loss nan (nan)	prob nan (nan)	GS 33.969 (33.969)	mem 39.762
Train: [44][45/750]	BT 0.101 (1.572)	DT 0.002 (1.428)	loss nan (nan)	prob nan (nan)	GS 29.828 (29.828)	mem 39.575
Train: [44][50/750]	BT 10.018 (1.627)	DT 9.951 (1.484)	loss nan (nan)	prob nan (nan)	GS 34.359 (34.359)	mem 39.675
Train: [44][55/750]	BT 0.089 (1.529)	DT 0.002 (1.388)	loss nan (nan)	prob nan (nan)	GS 29.969 (29.969)	mem 39.653
Train: [44][60/750]	BT 0.187 (1.416)	DT 0.002 (1.273)	loss nan (nan)	prob nan (nan)	GS 32.859 (32.859)	mem 39.655
Train: [44][65/750]	BT 0.150 (1.446)	DT 0.010 (1.302)	loss nan (nan)	prob nan (nan)	GS 28.688 (28.688)	mem 39.667
Train: [44][70/750]	BT 0.088 (1.353)	DT 0.002 (1.209)	loss nan (nan)	prob nan (nan)	GS 34.312 (34.312)	mem 39.684
Train: [44][75/750]	BT 0.086 (1.436)	DT 0.002 (1.293)	loss nan (nan)	prob nan (nan)	GS 35.094 (35.094)	mem 39.702
Train: [44][80/750]	BT 0.128 (1.355)	DT 0.012 (1.213)	loss nan (nan)	prob nan (nan)	GS 31.406 (31.406)	mem 39.837
Train: [44][85/750]	BT 0.157 (1.285)	DT 0.009 (1.142)	loss nan (nan)	prob nan (nan)	GS 33.953 (33.953)	mem 39.806
Train: [44][90/750]	BT 0.225 (1.338)	DT 0.032 (1.196)	loss nan (nan)	prob nan (nan)	GS 35.594 (35.594)	mem 39.703
Train: [44][95/750]	BT 0.275 (1.276)	DT 0.011 (1.133)	loss nan (nan)	prob nan (nan)	GS 32.656 (32.656)	mem 39.718
Train: [44][100/750]	BT 1.144 (1.327)	DT 1.051 (1.187)	loss nan (nan)	prob nan (nan)	GS 35.000 (35.000)	mem 39.638
Train: [44][105/750]	BT 0.203 (1.271)	DT 0.004 (1.130)	loss nan (nan)	prob nan (nan)	GS 31.141 (31.141)	mem 39.656
Train: [44][110/750]	BT 10.760 (1.314)	DT 10.625 (1.176)	loss nan (nan)	prob nan (nan)	GS 32.500 (32.500)	mem 39.773
Train: [44][115/750]	BT 0.132 (1.296)	DT 0.022 (1.160)	loss nan (nan)	prob nan (nan)	GS 31.500 (31.500)	mem 40.012
Train: [44][120/750]	BT 0.315 (1.250)	DT 0.005 (1.112)	loss nan (nan)	prob nan (nan)	GS 35.969 (35.969)	mem 39.914
Train: [44][125/750]	BT 0.193 (1.304)	DT 0.004 (1.165)	loss nan (nan)	prob nan (nan)	GS 32.000 (32.000)	mem 39.835
Train: [44][130/750]	BT 0.192 (1.260)	DT 0.012 (1.121)	loss nan (nan)	prob nan (nan)	GS 35.875 (35.875)	mem 39.773
Train: [44][135/750]	BT 0.162 (1.233)	DT 0.005 (1.094)	loss nan (nan)	prob nan (nan)	GS 31.438 (31.438)	mem 39.730
Train: [44][140/750]	BT 0.188 (1.256)	DT 0.001 (1.116)	loss nan (nan)	prob nan (nan)	GS 30.359 (30.359)	mem 39.790
Train: [44][145/750]	BT 0.157 (1.217)	DT 0.002 (1.078)	loss nan (nan)	prob nan (nan)	GS 29.594 (29.594)	mem 39.793
Train: [44][150/750]	BT 0.096 (1.261)	DT 0.005 (1.122)	loss nan (nan)	prob nan (nan)	GS 32.672 (32.672)	mem 39.861
Train: [44][155/750]	BT 0.132 (1.225)	DT 0.005 (1.087)	loss nan (nan)	prob nan (nan)	GS 30.766 (30.766)	mem 39.880
Train: [44][160/750]	BT 7.523 (1.258)	DT 7.278 (1.119)	loss nan (nan)	prob nan (nan)	GS 31.859 (31.859)	mem 40.125
Train: [44][165/750]	BT 0.075 (1.224)	DT 0.001 (1.085)	loss nan (nan)	prob nan (nan)	GS 34.781 (34.781)	mem 39.974
Train: [44][170/750]	BT 8.784 (1.243)	DT 8.704 (1.105)	loss nan (nan)	prob nan (nan)	GS 36.969 (36.969)	mem 39.890
Train: [44][175/750]	BT 0.090 (1.247)	DT 0.001 (1.109)	loss nan (nan)	prob nan (nan)	GS 33.641 (33.641)	mem 39.946
Train: [44][180/750]	BT 0.120 (1.217)	DT 0.011 (1.079)	loss nan (nan)	prob nan (nan)	GS 31.016 (31.016)	mem 39.950
Train: [44][185/750]	BT 0.113 (1.251)	DT 0.002 (1.113)	loss nan (nan)	prob nan (nan)	GS 33.344 (33.344)	mem 39.899
Train: [44][190/750]	BT 0.129 (1.222)	DT 0.002 (1.084)	loss nan (nan)	prob nan (nan)	GS 34.875 (34.875)	mem 39.843
Train: [44][195/750]	BT 0.104 (1.220)	DT 0.019 (1.082)	loss nan (nan)	prob nan (nan)	GS 27.094 (27.094)	mem 39.916
Train: [44][200/750]	BT 0.090 (1.228)	DT 0.001 (1.091)	loss nan (nan)	prob nan (nan)	GS 35.672 (35.672)	mem 39.934
Train: [44][205/750]	BT 0.170 (1.202)	DT 0.002 (1.065)	loss nan (nan)	prob nan (nan)	GS 33.141 (33.141)	mem 39.950
Train: [44][210/750]	BT 0.089 (1.225)	DT 0.001 (1.089)	loss nan (nan)	prob nan (nan)	GS 35.859 (35.859)	mem 40.028
Train: [44][215/750]	BT 0.083 (1.198)	DT 0.002 (1.064)	loss nan (nan)	prob nan (nan)	GS 31.453 (31.453)	mem 40.030
Train: [44][220/750]	BT 8.126 (1.228)	DT 8.039 (1.094)	loss nan (nan)	prob nan (nan)	GS 32.984 (32.984)	mem 39.986
Train: [44][225/750]	BT 0.144 (1.204)	DT 0.001 (1.070)	loss nan (nan)	prob nan (nan)	GS 31.125 (31.125)	mem 40.008
Train: [44][230/750]	BT 4.700 (1.200)	DT 4.575 (1.067)	loss nan (nan)	prob nan (nan)	GS 33.109 (33.109)	mem 39.936
Train: [44][235/750]	BT 0.159 (1.205)	DT 0.003 (1.073)	loss nan (nan)	prob nan (nan)	GS 29.703 (29.703)	mem 39.948
Train: [44][240/750]	BT 0.191 (1.183)	DT 0.001 (1.051)	loss nan (nan)	prob nan (nan)	GS 34.344 (34.344)	mem 39.941
Train: [44][245/750]	BT 0.136 (1.203)	DT 0.002 (1.071)	loss nan (nan)	prob nan (nan)	GS 35.844 (35.844)	mem 39.996
Train: [44][250/750]	BT 0.096 (1.181)	DT 0.007 (1.049)	loss nan (nan)	prob nan (nan)	GS 34.828 (34.828)	mem 39.997
Train: [44][255/750]	BT 0.156 (1.168)	DT 0.002 (1.036)	loss nan (nan)	prob nan (nan)	GS 30.531 (30.531)	mem 40.031
Train: [44][260/750]	BT 0.094 (1.177)	DT 0.002 (1.044)	loss nan (nan)	prob nan (nan)	GS 33.984 (33.984)	mem 40.002
Train: [44][265/750]	BT 0.122 (1.157)	DT 0.002 (1.025)	loss nan (nan)	prob nan (nan)	GS 33.281 (33.281)	mem 39.996
Train: [44][270/750]	BT 0.116 (1.178)	DT 0.002 (1.045)	loss nan (nan)	prob nan (nan)	GS 34.062 (34.062)	mem 40.017
Train: [44][275/750]	BT 0.100 (1.159)	DT 0.001 (1.026)	loss nan (nan)	prob nan (nan)	GS 32.219 (32.219)	mem 40.194
Train: [44][280/750]	BT 0.799 (1.176)	DT 0.706 (1.044)	loss nan (nan)	prob nan (nan)	GS 32.422 (32.422)	mem 39.961
Train: [44][285/750]	BT 0.192 (1.160)	DT 0.001 (1.028)	loss nan (nan)	prob nan (nan)	GS 31.422 (31.422)	mem 40.158
Train: [44][290/750]	BT 9.473 (1.175)	DT 9.319 (1.043)	loss nan (nan)	prob nan (nan)	GS 34.547 (34.547)	mem 40.059
Train: [44][295/750]	BT 0.143 (1.165)	DT 0.004 (1.033)	loss nan (nan)	prob nan (nan)	GS 34.812 (34.812)	mem 40.145
Train: [44][300/750]	BT 0.162 (1.148)	DT 0.002 (1.016)	loss nan (nan)	prob nan (nan)	GS 32.750 (32.750)	mem 40.041
Train: [44][305/750]	BT 0.090 (1.173)	DT 0.002 (1.041)	loss nan (nan)	prob nan (nan)	GS 27.188 (27.188)	mem 39.938
Train: [44][310/750]	BT 0.103 (1.157)	DT 0.002 (1.025)	loss nan (nan)	prob nan (nan)	GS 32.203 (32.203)	mem 40.022
Train: [44][315/750]	BT 0.149 (1.173)	DT 0.002 (1.041)	loss nan (nan)	prob nan (nan)	GS 33.000 (33.000)	mem 39.928
Train: [44][320/750]	BT 0.151 (1.162)	DT 0.001 (1.030)	loss nan (nan)	prob nan (nan)	GS 32.812 (32.812)	mem 39.951
Train: [44][325/750]	BT 0.302 (1.147)	DT 0.002 (1.014)	loss nan (nan)	prob nan (nan)	GS 30.453 (30.453)	mem 39.995
Train: [44][330/750]	BT 0.119 (1.167)	DT 0.002 (1.034)	loss nan (nan)	prob nan (nan)	GS 34.641 (34.641)	mem 39.970
Train: [44][335/750]	BT 0.137 (1.151)	DT 0.002 (1.018)	loss nan (nan)	prob nan (nan)	GS 29.828 (29.828)	mem 39.973
Train: [44][340/750]	BT 0.147 (1.168)	DT 0.002 (1.035)	loss nan (nan)	prob nan (nan)	GS 32.688 (32.688)	mem 39.932
Train: [44][345/750]	BT 0.135 (1.153)	DT 0.002 (1.020)	loss nan (nan)	prob nan (nan)	GS 30.828 (30.828)	mem 39.992
Train: [44][350/750]	BT 11.720 (1.172)	DT 11.584 (1.039)	loss nan (nan)	prob nan (nan)	GS 32.516 (32.516)	mem 40.121
Train: [44][355/750]	BT 0.105 (1.162)	DT 0.003 (1.029)	loss nan (nan)	prob nan (nan)	GS 30.656 (30.656)	mem 40.023
Train: [44][360/750]	BT 0.120 (1.148)	DT 0.013 (1.015)	loss nan (nan)	prob nan (nan)	GS 34.750 (34.750)	mem 39.990
Train: [44][365/750]	BT 0.229 (1.159)	DT 0.005 (1.026)	loss nan (nan)	prob nan (nan)	GS 35.250 (35.250)	mem 40.033
Train: [44][370/750]	BT 0.102 (1.148)	DT 0.002 (1.016)	loss nan (nan)	prob nan (nan)	GS 33.984 (33.984)	mem 40.013
Train: [44][375/750]	BT 0.111 (1.161)	DT 0.002 (1.028)	loss nan (nan)	prob nan (nan)	GS 33.859 (33.859)	mem 40.121
Train: [44][380/750]	BT 0.130 (1.155)	DT 0.001 (1.023)	loss nan (nan)	prob nan (nan)	GS 32.469 (32.469)	mem 40.081
Train: [44][385/750]	BT 0.109 (1.143)	DT 0.002 (1.009)	loss nan (nan)	prob nan (nan)	GS 28.047 (28.047)	mem 40.044
Train: [44][390/750]	BT 4.171 (1.163)	DT 4.084 (1.029)	loss nan (nan)	prob nan (nan)	GS 33.828 (33.828)	mem 40.000
Train: [44][395/750]	BT 0.113 (1.150)	DT 0.005 (1.016)	loss nan (nan)	prob nan (nan)	GS 30.828 (30.828)	mem 40.026
Train: [44][400/750]	BT 1.107 (1.151)	DT 1.005 (1.018)	loss nan (nan)	prob nan (nan)	GS 32.828 (32.828)	mem 39.947
Train: [44][405/750]	BT 0.121 (1.156)	DT 0.003 (1.023)	loss nan (nan)	prob nan (nan)	GS 26.906 (26.906)	mem 39.945
Train: [44][410/750]	BT 1.823 (1.148)	DT 1.711 (1.015)	loss nan (nan)	prob nan (nan)	GS 34.094 (34.094)	mem 39.955
Train: [44][415/750]	BT 0.127 (1.160)	DT 0.002 (1.027)	loss nan (nan)	prob nan (nan)	GS 30.328 (30.328)	mem 40.046
Train: [44][420/750]	BT 0.187 (1.148)	DT 0.027 (1.015)	loss nan (nan)	prob nan (nan)	GS 32.656 (32.656)	mem 39.993
Train: [44][425/750]	BT 0.095 (1.148)	DT 0.001 (1.016)	loss nan (nan)	prob nan (nan)	GS 29.828 (29.828)	mem 40.037
Train: [44][430/750]	BT 0.127 (1.153)	DT 0.007 (1.020)	loss nan (nan)	prob nan (nan)	GS 35.078 (35.078)	mem 39.943
Train: [44][435/750]	BT 0.087 (1.141)	DT 0.002 (1.008)	loss nan (nan)	prob nan (nan)	GS 36.750 (36.750)	mem 39.965
Train: [44][440/750]	BT 0.117 (1.149)	DT 0.001 (1.016)	loss nan (nan)	prob nan (nan)	GS 34.484 (34.484)	mem 39.970
Train: [44][445/750]	BT 0.183 (1.137)	DT 0.005 (1.005)	loss nan (nan)	prob nan (nan)	GS 30.953 (30.953)	mem 40.136
Train: [44][450/750]	BT 2.020 (1.152)	DT 1.915 (1.019)	loss nan (nan)	prob nan (nan)	GS 33.719 (33.719)	mem 39.926
Train: [44][455/750]	BT 0.136 (1.141)	DT 0.009 (1.008)	loss nan (nan)	prob nan (nan)	GS 26.734 (26.734)	mem 39.897
Train: [44][460/750]	BT 3.648 (1.152)	DT 3.546 (1.019)	loss nan (nan)	prob nan (nan)	GS 30.219 (30.219)	mem 40.090
Train: [44][465/750]	BT 0.087 (1.142)	DT 0.002 (1.010)	loss nan (nan)	prob nan (nan)	GS 27.906 (27.906)	mem 39.900
Train: [44][470/750]	BT 9.476 (1.152)	DT 9.282 (1.019)	loss nan (nan)	prob nan (nan)	GS 34.719 (34.719)	mem 39.976
Train: [44][475/750]	BT 0.095 (1.146)	DT 0.001 (1.013)	loss nan (nan)	prob nan (nan)	GS 33.953 (33.953)	mem 40.078
Train: [44][480/750]	BT 0.126 (1.138)	DT 0.005 (1.005)	loss nan (nan)	prob nan (nan)	GS 32.859 (32.859)	mem 40.234
Train: [44][485/750]	BT 0.110 (1.138)	DT 0.001 (1.005)	loss nan (nan)	prob nan (nan)	GS 30.641 (30.641)	mem 40.023
Train: [44][490/750]	BT 2.051 (1.143)	DT 1.906 (1.011)	loss nan (nan)	prob nan (nan)	GS 35.250 (35.250)	mem 39.948
Train: [44][495/750]	BT 0.075 (1.146)	DT 0.002 (1.013)	loss nan (nan)	prob nan (nan)	GS 30.531 (30.531)	mem 39.998
Train: [44][500/750]	BT 0.302 (1.140)	DT 0.120 (1.007)	loss nan (nan)	prob nan (nan)	GS 36.219 (36.219)	mem 39.920
Train: [44][505/750]	BT 0.176 (1.141)	DT 0.021 (1.008)	loss nan (nan)	prob nan (nan)	GS 28.484 (28.484)	mem 39.964
Train: [44][510/750]	BT 3.604 (1.141)	DT 3.512 (1.008)	loss nan (nan)	prob nan (nan)	GS 32.031 (32.031)	mem 39.985
Train: [44][515/750]	BT 0.101 (1.147)	DT 0.002 (1.014)	loss nan (nan)	prob nan (nan)	GS 33.797 (33.797)	mem 40.001
Train: [44][520/750]	BT 0.153 (1.141)	DT 0.008 (1.008)	loss nan (nan)	prob nan (nan)	GS 34.844 (34.844)	mem 40.028
Train: [44][525/750]	BT 0.090 (1.138)	DT 0.002 (1.005)	loss nan (nan)	prob nan (nan)	GS 28.969 (28.969)	mem 39.924
Train: [44][530/750]	BT 4.752 (1.144)	DT 4.503 (1.011)	loss nan (nan)	prob nan (nan)	GS 37.156 (37.156)	mem 40.052
Train: [44][535/750]	BT 0.073 (1.142)	DT 0.002 (1.009)	loss nan (nan)	prob nan (nan)	GS 32.984 (32.984)	mem 40.001
Train: [44][540/750]	BT 0.155 (1.140)	DT 0.002 (1.007)	loss nan (nan)	prob nan (nan)	GS 32.500 (32.500)	mem 40.031
Train: [44][545/750]	BT 0.089 (1.135)	DT 0.005 (1.002)	loss nan (nan)	prob nan (nan)	GS 31.859 (31.859)	mem 39.928
Train: [44][550/750]	BT 7.223 (1.143)	DT 7.014 (1.010)	loss nan (nan)	prob nan (nan)	GS 34.328 (34.328)	mem 39.950
Train: [44][555/750]	BT 0.090 (1.135)	DT 0.002 (1.002)	loss nan (nan)	prob nan (nan)	GS 31.141 (31.141)	mem 39.874
Train: [44][560/750]	BT 0.161 (1.136)	DT 0.006 (1.003)	loss nan (nan)	prob nan (nan)	GS 29.469 (29.469)	mem 40.002
Train: [44][565/750]	BT 0.122 (1.138)	DT 0.002 (1.005)	loss nan (nan)	prob nan (nan)	GS 29.203 (29.203)	mem 39.890
Train: [44][570/750]	BT 2.026 (1.136)	DT 1.867 (1.003)	loss nan (nan)	prob nan (nan)	GS 35.281 (35.281)	mem 39.943
Train: [44][575/750]	BT 0.086 (1.136)	DT 0.003 (1.003)	loss nan (nan)	prob nan (nan)	GS 36.547 (36.547)	mem 39.917
Train: [44][580/750]	BT 5.019 (1.138)	DT 4.904 (1.005)	loss nan (nan)	prob nan (nan)	GS 33.906 (33.906)	mem 39.967
Train: [44][585/750]	BT 0.161 (1.130)	DT 0.001 (0.997)	loss nan (nan)	prob nan (nan)	GS 31.094 (31.094)	mem 39.981
Train: [44][590/750]	BT 4.453 (1.134)	DT 4.337 (1.001)	loss nan (nan)	prob nan (nan)	GS 36.109 (36.109)	mem 40.066
Train: [44][595/750]	BT 0.112 (1.135)	DT 0.005 (1.002)	loss nan (nan)	prob nan (nan)	GS 31.203 (31.203)	mem 40.009
Train: [44][600/750]	BT 0.117 (1.130)	DT 0.010 (0.997)	loss nan (nan)	prob nan (nan)	GS 33.469 (33.469)	mem 40.125
Train: [44][605/750]	BT 0.089 (1.136)	DT 0.001 (1.003)	loss nan (nan)	prob nan (nan)	GS 34.297 (34.297)	mem 40.062
Train: [44][610/750]	BT 0.164 (1.136)	DT 0.001 (1.003)	loss nan (nan)	prob nan (nan)	GS 32.688 (32.688)	mem 40.045
Train: [44][615/750]	BT 0.185 (1.129)	DT 0.030 (0.996)	loss nan (nan)	prob nan (nan)	GS 31.500 (31.500)	mem 39.977
Train: [44][620/750]	BT 0.167 (1.138)	DT 0.023 (1.005)	loss nan (nan)	prob nan (nan)	GS 34.625 (34.625)	mem 40.122
Train: [44][625/750]	BT 0.215 (1.136)	DT 0.010 (1.002)	loss nan (nan)	prob nan (nan)	GS 30.906 (30.906)	mem 39.983
Train: [44][630/750]	BT 4.117 (1.146)	DT 3.950 (1.012)	loss nan (nan)	prob nan (nan)	GS 35.672 (35.672)	mem 39.984
Train: [44][635/750]	BT 0.092 (1.140)	DT 0.002 (1.006)	loss nan (nan)	prob nan (nan)	GS 28.812 (28.812)	mem 40.060
Train: [44][640/750]	BT 8.129 (1.144)	DT 8.020 (1.011)	loss nan (nan)	prob nan (nan)	GS 35.297 (35.297)	mem 39.953
Train: [44][645/750]	BT 0.129 (1.139)	DT 0.001 (1.005)	loss nan (nan)	prob nan (nan)	GS 33.406 (33.406)	mem 40.081
Train: [44][650/750]	BT 0.107 (1.131)	DT 0.002 (0.998)	loss nan (nan)	prob nan (nan)	GS 34.172 (34.172)	mem 39.862
Train: [44][655/750]	BT 0.177 (1.140)	DT 0.002 (1.006)	loss nan (nan)	prob nan (nan)	GS 26.250 (26.250)	mem 39.981
Train: [44][660/750]	BT 0.092 (1.132)	DT 0.007 (0.999)	loss nan (nan)	prob nan (nan)	GS 34.469 (34.469)	mem 39.980
Train: [44][665/750]	BT 0.121 (1.141)	DT 0.002 (1.007)	loss nan (nan)	prob nan (nan)	GS 28.719 (28.719)	mem 40.073
Train: [44][670/750]	BT 0.250 (1.135)	DT 0.056 (1.001)	loss nan (nan)	prob nan (nan)	GS 32.062 (32.062)	mem 39.897
Train: [44][675/750]	BT 0.141 (1.128)	DT 0.002 (0.994)	loss nan (nan)	prob nan (nan)	GS 29.688 (29.688)	mem 39.863
Train: [44][680/750]	BT 0.259 (1.139)	DT 0.011 (1.005)	loss nan (nan)	prob nan (nan)	GS 32.484 (32.484)	mem 39.931
Train: [44][685/750]	BT 0.172 (1.132)	DT 0.009 (0.998)	loss nan (nan)	prob nan (nan)	GS 32.781 (32.781)	mem 39.982
Train: [44][690/750]	BT 3.824 (1.142)	DT 3.689 (1.008)	loss nan (nan)	prob nan (nan)	GS 34.281 (34.281)	mem 40.072
Train: [44][695/750]	BT 0.089 (1.135)	DT 0.002 (1.001)	loss nan (nan)	prob nan (nan)	GS 35.438 (35.438)	mem 40.142
Train: [44][700/750]	BT 4.505 (1.134)	DT 4.365 (1.000)	loss nan (nan)	prob nan (nan)	GS 30.328 (30.328)	mem 39.967
Train: [44][705/750]	BT 0.179 (1.139)	DT 0.002 (1.006)	loss nan (nan)	prob nan (nan)	GS 31.797 (31.797)	mem 40.184
Train: [44][710/750]	BT 0.178 (1.132)	DT 0.002 (0.999)	loss nan (nan)	prob nan (nan)	GS 30.688 (30.688)	mem 39.944
Train: [44][715/750]	BT 0.093 (1.143)	DT 0.001 (1.010)	loss nan (nan)	prob nan (nan)	GS 29.359 (29.359)	mem 39.876
Train: [44][720/750]	BT 0.136 (1.136)	DT 0.001 (1.003)	loss nan (nan)	prob nan (nan)	GS 30.281 (30.281)	mem 39.873
Train: [44][725/750]	BT 0.104 (1.129)	DT 0.005 (0.996)	loss nan (nan)	prob nan (nan)	GS 30.750 (30.750)	mem 39.892
Train: [44][730/750]	BT 0.123 (1.135)	DT 0.007 (1.002)	loss nan (nan)	prob nan (nan)	GS 29.016 (29.016)	mem 39.810
Train: [44][735/750]	BT 0.078 (1.128)	DT 0.002 (0.995)	loss nan (nan)	prob nan (nan)	GS 31.750 (31.750)	mem 39.719
Train: [44][740/750]	BT 0.102 (1.129)	DT 0.002 (0.997)	loss nan (nan)	prob nan (nan)	GS 35.750 (35.750)	mem 16.595
Train: [44][745/750]	BT 0.091 (1.122)	DT 0.009 (0.990)	loss nan (nan)	prob nan (nan)	GS 30.719 (30.719)	mem 16.595
Train: [44][750/750]	BT 2.810 (1.119)	DT 2.733 (0.987)	loss nan (nan)	prob nan (nan)	GS 38.688 (38.688)	mem 7.674
Train: [44][755/750]	BT 0.054 (1.112)	DT 0.001 (0.981)	loss nan (nan)	prob nan (nan)	GS 29.562 (29.562)	mem 7.674
epoch 44, total time 839.96
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [45][1/750]	BT 22.308 (22.308)	DT 22.175 (22.175)	loss nan (nan)	prob nan (nan)	GS 33.328 (33.328)	mem 38.770
Train: [45][5/750]	BT 0.105 (5.052)	DT 0.010 (4.900)	loss nan (nan)	prob nan (nan)	GS 32.172 (32.172)	mem 38.896
Train: [45][10/750]	BT 0.353 (2.899)	DT 0.009 (2.727)	loss nan (nan)	prob nan (nan)	GS 33.234 (33.234)	mem 39.022
Train: [45][15/750]	BT 2.987 (2.346)	DT 2.891 (2.167)	loss nan (nan)	prob nan (nan)	GS 35.141 (35.141)	mem 38.954
Train: [45][20/750]	BT 0.104 (2.228)	DT 0.006 (2.062)	loss nan (nan)	prob nan (nan)	GS 31.297 (31.297)	mem 39.115
Train: [45][25/750]	BT 0.167 (1.822)	DT 0.010 (1.650)	loss nan (nan)	prob nan (nan)	GS 31.719 (31.719)	mem 39.033
Train: [45][30/750]	BT 7.633 (1.976)	DT 7.553 (1.804)	loss nan (nan)	prob nan (nan)	GS 31.469 (31.469)	mem 38.912
Train: [45][35/750]	BT 0.088 (1.713)	DT 0.001 (1.547)	loss nan (nan)	prob nan (nan)	GS 33.812 (33.812)	mem 38.954
Train: [45][40/750]	BT 0.105 (1.516)	DT 0.005 (1.354)	loss nan (nan)	prob nan (nan)	GS 34.500 (34.500)	mem 38.980
Train: [45][45/750]	BT 0.137 (1.555)	DT 0.008 (1.392)	loss nan (nan)	prob nan (nan)	GS 31.141 (31.141)	mem 39.039
Train: [45][50/750]	BT 0.153 (1.411)	DT 0.065 (1.255)	loss nan (nan)	prob nan (nan)	GS 30.734 (30.734)	mem 38.981
Train: [45][55/750]	BT 0.172 (1.425)	DT 0.019 (1.273)	loss nan (nan)	prob nan (nan)	GS 33.297 (33.297)	mem 39.076
Train: [45][60/750]	BT 0.114 (1.324)	DT 0.002 (1.173)	loss nan (nan)	prob nan (nan)	GS 32.062 (32.062)	mem 39.248
Train: [45][65/750]	BT 0.100 (1.258)	DT 0.002 (1.108)	loss nan (nan)	prob nan (nan)	GS 35.594 (35.594)	mem 39.142
Train: [45][70/750]	BT 0.130 (1.375)	DT 0.010 (1.228)	loss nan (nan)	prob nan (nan)	GS 34.375 (34.375)	mem 39.113
Train: [45][75/750]	BT 0.310 (1.293)	DT 0.002 (1.146)	loss nan (nan)	prob nan (nan)	GS 32.016 (32.016)	mem 39.343
Train: [45][80/750]	BT 5.130 (1.398)	DT 5.028 (1.249)	loss nan (nan)	prob nan (nan)	GS 35.594 (35.594)	mem 39.192
Train: [45][85/750]	BT 0.089 (1.324)	DT 0.002 (1.176)	loss nan (nan)	prob nan (nan)	GS 28.359 (28.359)	mem 39.218
Train: [45][90/750]	BT 4.223 (1.302)	DT 3.989 (1.155)	loss nan (nan)	prob nan (nan)	GS 27.234 (27.234)	mem 39.344
Train: [45][95/750]	BT 0.087 (1.305)	DT 0.006 (1.158)	loss nan (nan)	prob nan (nan)	GS 31.969 (31.969)	mem 39.258
Train: [45][100/750]	BT 0.093 (1.247)	DT 0.007 (1.100)	loss nan (nan)	prob nan (nan)	GS 32.297 (32.297)	mem 39.261
Train: [45][105/750]	BT 0.088 (1.308)	DT 0.002 (1.162)	loss nan (nan)	prob nan (nan)	GS 28.062 (28.062)	mem 39.319
Train: [45][110/750]	BT 0.668 (1.260)	DT 0.376 (1.112)	loss nan (nan)	prob nan (nan)	GS 33.922 (33.922)	mem 39.318
Train: [45][115/750]	BT 0.159 (1.254)	DT 0.014 (1.107)	loss nan (nan)	prob nan (nan)	GS 31.547 (31.547)	mem 39.331
Train: [45][120/750]	BT 0.161 (1.275)	DT 0.001 (1.129)	loss nan (nan)	prob nan (nan)	GS 37.516 (37.516)	mem 39.204
Train: [45][125/750]	BT 0.120 (1.228)	DT 0.002 (1.084)	loss nan (nan)	prob nan (nan)	GS 32.844 (32.844)	mem 39.273
Train: [45][130/750]	BT 0.136 (1.278)	DT 0.003 (1.135)	loss nan (nan)	prob nan (nan)	GS 34.156 (34.156)	mem 39.288
Train: [45][135/750]	BT 0.158 (1.235)	DT 0.004 (1.093)	loss nan (nan)	prob nan (nan)	GS 28.312 (28.312)	mem 39.341
Train: [45][140/750]	BT 6.138 (1.279)	DT 6.041 (1.138)	loss nan (nan)	prob nan (nan)	GS 37.844 (37.844)	mem 39.424
Train: [45][145/750]	BT 0.150 (1.240)	DT 0.002 (1.099)	loss nan (nan)	prob nan (nan)	GS 34.375 (34.375)	mem 39.393
Train: [45][150/750]	BT 3.607 (1.226)	DT 3.470 (1.086)	loss nan (nan)	prob nan (nan)	GS 31.734 (31.734)	mem 39.377
Train: [45][155/750]	BT 0.117 (1.236)	DT 0.002 (1.095)	loss nan (nan)	prob nan (nan)	GS 27.797 (27.797)	mem 39.625
Train: [45][160/750]	BT 0.080 (1.211)	DT 0.002 (1.072)	loss nan (nan)	prob nan (nan)	GS 32.797 (32.797)	mem 39.674
Train: [45][165/750]	BT 0.103 (1.240)	DT 0.003 (1.100)	loss nan (nan)	prob nan (nan)	GS 29.125 (29.125)	mem 39.681
Train: [45][170/750]	BT 0.154 (1.217)	DT 0.001 (1.076)	loss nan (nan)	prob nan (nan)	GS 30.062 (30.062)	mem 39.685
Train: [45][175/750]	BT 0.145 (1.203)	DT 0.002 (1.062)	loss nan (nan)	prob nan (nan)	GS 31.188 (31.188)	mem 39.691
Train: [45][180/750]	BT 0.128 (1.233)	DT 0.060 (1.093)	loss nan (nan)	prob nan (nan)	GS 35.469 (35.469)	mem 39.658
Train: [45][185/750]	BT 0.161 (1.203)	DT 0.009 (1.063)	loss nan (nan)	prob nan (nan)	GS 29.766 (29.766)	mem 39.659
Train: [45][190/750]	BT 0.105 (1.235)	DT 0.001 (1.096)	loss nan (nan)	prob nan (nan)	GS 32.000 (32.000)	mem 39.707
Train: [45][195/750]	BT 0.235 (1.208)	DT 0.002 (1.068)	loss nan (nan)	prob nan (nan)	GS 33.312 (33.312)	mem 40.031
Train: [45][200/750]	BT 10.401 (1.246)	DT 10.254 (1.107)	loss nan (nan)	prob nan (nan)	GS 36.984 (36.984)	mem 39.908
Train: [45][205/750]	BT 0.144 (1.218)	DT 0.004 (1.080)	loss nan (nan)	prob nan (nan)	GS 41.859 (41.859)	mem 40.054
Train: [45][210/750]	BT 3.672 (1.209)	DT 3.477 (1.071)	loss nan (nan)	prob nan (nan)	GS 33.406 (33.406)	mem 40.527
Train: [45][215/750]	BT 0.117 (1.214)	DT 0.001 (1.075)	loss nan (nan)	prob nan (nan)	GS 32.844 (32.844)	mem 39.979
Train: [45][220/750]	BT 0.108 (1.190)	DT 0.006 (1.051)	loss nan (nan)	prob nan (nan)	GS 33.781 (33.781)	mem 40.085
Train: [45][225/750]	BT 0.134 (1.231)	DT 0.001 (1.093)	loss nan (nan)	prob nan (nan)	GS 30.250 (30.250)	mem 40.002
Train: [45][230/750]	BT 0.118 (1.207)	DT 0.001 (1.069)	loss nan (nan)	prob nan (nan)	GS 37.078 (37.078)	mem 39.896
Train: [45][235/750]	BT 0.153 (1.191)	DT 0.008 (1.053)	loss nan (nan)	prob nan (nan)	GS 27.203 (27.203)	mem 39.923
Train: [45][240/750]	BT 0.104 (1.205)	DT 0.001 (1.068)	loss nan (nan)	prob nan (nan)	GS 32.125 (32.125)	mem 39.852
Train: [45][245/750]	BT 0.079 (1.183)	DT 0.001 (1.047)	loss nan (nan)	prob nan (nan)	GS 34.375 (34.375)	mem 39.982
Train: [45][250/750]	BT 0.105 (1.209)	DT 0.001 (1.073)	loss nan (nan)	prob nan (nan)	GS 33.125 (33.125)	mem 39.919
Train: [45][255/750]	BT 0.131 (1.187)	DT 0.009 (1.052)	loss nan (nan)	prob nan (nan)	GS 33.656 (33.656)	mem 39.889
Train: [45][260/750]	BT 9.711 (1.204)	DT 9.467 (1.068)	loss nan (nan)	prob nan (nan)	GS 34.406 (34.406)	mem 39.971
Train: [45][265/750]	BT 0.093 (1.184)	DT 0.007 (1.048)	loss nan (nan)	prob nan (nan)	GS 32.844 (32.844)	mem 39.917
Train: [45][270/750]	BT 5.049 (1.182)	DT 4.927 (1.047)	loss nan (nan)	prob nan (nan)	GS 37.750 (37.750)	mem 39.953
Train: [45][275/750]	BT 0.123 (1.196)	DT 0.005 (1.060)	loss nan (nan)	prob nan (nan)	GS 32.562 (32.562)	mem 40.175
Train: [45][280/750]	BT 0.134 (1.176)	DT 0.004 (1.041)	loss nan (nan)	prob nan (nan)	GS 34.453 (34.453)	mem 39.941
Train: [45][285/750]	BT 0.113 (1.199)	DT 0.003 (1.064)	loss nan (nan)	prob nan (nan)	GS 31.047 (31.047)	mem 39.965
Train: [45][290/750]	BT 0.145 (1.181)	DT 0.001 (1.046)	loss nan (nan)	prob nan (nan)	GS 32.438 (32.438)	mem 39.991
Train: [45][295/750]	BT 0.120 (1.170)	DT 0.030 (1.035)	loss nan (nan)	prob nan (nan)	GS 36.312 (36.312)	mem 40.033
Train: [45][300/750]	BT 0.193 (1.181)	DT 0.014 (1.046)	loss nan (nan)	prob nan (nan)	GS 34.688 (34.688)	mem 39.918
Train: [45][305/750]	BT 0.095 (1.163)	DT 0.001 (1.029)	loss nan (nan)	prob nan (nan)	GS 28.953 (28.953)	mem 39.920
Train: [45][310/750]	BT 0.092 (1.176)	DT 0.007 (1.042)	loss nan (nan)	prob nan (nan)	GS 30.766 (30.766)	mem 39.935
Train: [45][315/750]	BT 0.145 (1.160)	DT 0.002 (1.025)	loss nan (nan)	prob nan (nan)	GS 29.078 (29.078)	mem 39.937
Train: [45][320/750]	BT 3.816 (1.182)	DT 3.696 (1.047)	loss nan (nan)	prob nan (nan)	GS 34.344 (34.344)	mem 39.968
Train: [45][325/750]	BT 0.150 (1.165)	DT 0.005 (1.031)	loss nan (nan)	prob nan (nan)	GS 30.750 (30.750)	mem 39.970
Train: [45][330/750]	BT 6.492 (1.169)	DT 6.382 (1.035)	loss nan (nan)	prob nan (nan)	GS 36.438 (36.438)	mem 39.984
Train: [45][335/750]	BT 0.230 (1.180)	DT 0.018 (1.045)	loss nan (nan)	prob nan (nan)	GS 29.469 (29.469)	mem 40.016
Train: [45][340/750]	BT 0.157 (1.165)	DT 0.035 (1.030)	loss nan (nan)	prob nan (nan)	GS 30.672 (30.672)	mem 40.023
Train: [45][345/750]	BT 0.253 (1.175)	DT 0.013 (1.040)	loss nan (nan)	prob nan (nan)	GS 31.906 (31.906)	mem 39.953
Train: [45][350/750]	BT 0.084 (1.161)	DT 0.007 (1.025)	loss nan (nan)	prob nan (nan)	GS 35.281 (35.281)	mem 39.956
Train: [45][355/750]	BT 0.150 (1.171)	DT 0.001 (1.036)	loss nan (nan)	prob nan (nan)	GS 30.375 (30.375)	mem 39.813
Train: [45][360/750]	BT 3.922 (1.167)	DT 3.781 (1.032)	loss nan (nan)	prob nan (nan)	GS 35.062 (35.062)	mem 39.882
Train: [45][365/750]	BT 0.144 (1.153)	DT 0.017 (1.018)	loss nan (nan)	prob nan (nan)	GS 31.109 (31.109)	mem 39.900
Train: [45][370/750]	BT 0.181 (1.162)	DT 0.002 (1.027)	loss nan (nan)	prob nan (nan)	GS 35.625 (35.625)	mem 40.037
Train: [45][375/750]	BT 0.188 (1.161)	DT 0.026 (1.026)	loss nan (nan)	prob nan (nan)	GS 32.516 (32.516)	mem 39.940
Train: [45][380/750]	BT 0.090 (1.162)	DT 0.002 (1.027)	loss nan (nan)	prob nan (nan)	GS 31.734 (31.734)	mem 39.921
Train: [45][385/750]	BT 0.098 (1.163)	DT 0.002 (1.028)	loss nan (nan)	prob nan (nan)	GS 30.719 (30.719)	mem 39.967
Train: [45][390/750]	BT 4.113 (1.160)	DT 3.940 (1.025)	loss nan (nan)	prob nan (nan)	GS 35.641 (35.641)	mem 40.032
Train: [45][395/750]	BT 0.176 (1.147)	DT 0.004 (1.012)	loss nan (nan)	prob nan (nan)	GS 27.297 (27.297)	mem 40.001
Train: [45][400/750]	BT 0.111 (1.152)	DT 0.001 (1.017)	loss nan (nan)	prob nan (nan)	GS 36.156 (36.156)	mem 40.197
Train: [45][405/750]	BT 0.143 (1.153)	DT 0.012 (1.018)	loss nan (nan)	prob nan (nan)	GS 29.391 (29.391)	mem 39.941
Train: [45][410/750]	BT 0.085 (1.152)	DT 0.001 (1.017)	loss nan (nan)	prob nan (nan)	GS 31.484 (31.484)	mem 40.018
Train: [45][415/750]	BT 0.106 (1.162)	DT 0.002 (1.027)	loss nan (nan)	prob nan (nan)	GS 34.109 (34.109)	mem 39.989
Train: [45][420/750]	BT 0.147 (1.150)	DT 0.018 (1.015)	loss nan (nan)	prob nan (nan)	GS 33.266 (33.266)	mem 40.005
Train: [45][425/750]	BT 0.074 (1.138)	DT 0.002 (1.003)	loss nan (nan)	prob nan (nan)	GS 30.406 (30.406)	mem 40.044
Train: [45][430/750]	BT 0.129 (1.151)	DT 0.001 (1.016)	loss nan (nan)	prob nan (nan)	GS 32.922 (32.922)	mem 40.126
Train: [45][435/750]	BT 0.117 (1.145)	DT 0.001 (1.010)	loss nan (nan)	prob nan (nan)	GS 34.281 (34.281)	mem 40.112
Train: [45][440/750]	BT 2.069 (1.159)	DT 1.944 (1.023)	loss nan (nan)	prob nan (nan)	GS 34.953 (34.953)	mem 39.982
Train: [45][445/750]	BT 0.146 (1.158)	DT 0.002 (1.022)	loss nan (nan)	prob nan (nan)	GS 35.906 (35.906)	mem 40.014
Train: [45][450/750]	BT 5.568 (1.159)	DT 5.467 (1.023)	loss nan (nan)	prob nan (nan)	GS 31.453 (31.453)	mem 40.050
Train: [45][455/750]	BT 0.123 (1.156)	DT 0.002 (1.021)	loss nan (nan)	prob nan (nan)	GS 33.094 (33.094)	mem 40.017
Train: [45][460/750]	BT 0.074 (1.149)	DT 0.001 (1.014)	loss nan (nan)	prob nan (nan)	GS 33.156 (33.156)	mem 39.965
Train: [45][465/750]	BT 0.083 (1.157)	DT 0.009 (1.022)	loss nan (nan)	prob nan (nan)	GS 31.250 (31.250)	mem 40.031
Train: [45][470/750]	BT 0.131 (1.148)	DT 0.007 (1.013)	loss nan (nan)	prob nan (nan)	GS 33.828 (33.828)	mem 40.170
Train: [45][475/750]	BT 0.087 (1.157)	DT 0.002 (1.022)	loss nan (nan)	prob nan (nan)	GS 31.859 (31.859)	mem 40.026
Train: [45][480/750]	BT 2.226 (1.151)	DT 2.060 (1.016)	loss nan (nan)	prob nan (nan)	GS 32.141 (32.141)	mem 40.028
Train: [45][485/750]	BT 0.180 (1.141)	DT 0.011 (1.006)	loss nan (nan)	prob nan (nan)	GS 32.328 (32.328)	mem 40.053
Train: [45][490/750]	BT 0.156 (1.148)	DT 0.007 (1.012)	loss nan (nan)	prob nan (nan)	GS 38.422 (38.422)	mem 40.083
Train: [45][495/750]	BT 0.219 (1.140)	DT 0.014 (1.005)	loss nan (nan)	prob nan (nan)	GS 28.156 (28.156)	mem 40.088
Train: [45][500/750]	BT 0.184 (1.154)	DT 0.010 (1.018)	loss nan (nan)	prob nan (nan)	GS 31.891 (31.891)	mem 39.900
Train: [45][505/750]	BT 0.107 (1.151)	DT 0.001 (1.016)	loss nan (nan)	prob nan (nan)	GS 31.109 (31.109)	mem 39.825
Train: [45][510/750]	BT 6.056 (1.153)	DT 5.979 (1.018)	loss nan (nan)	prob nan (nan)	GS 33.500 (33.500)	mem 39.885
Train: [45][515/750]	BT 0.111 (1.143)	DT 0.002 (1.008)	loss nan (nan)	prob nan (nan)	GS 31.516 (31.516)	mem 39.952
Train: [45][520/750]	BT 0.093 (1.140)	DT 0.002 (1.005)	loss nan (nan)	prob nan (nan)	GS 31.781 (31.781)	mem 39.928
Train: [45][525/750]	BT 0.140 (1.141)	DT 0.002 (1.006)	loss nan (nan)	prob nan (nan)	GS 32.812 (32.812)	mem 40.039
Train: [45][530/750]	BT 0.131 (1.144)	DT 0.011 (1.008)	loss nan (nan)	prob nan (nan)	GS 28.797 (28.797)	mem 39.951
Train: [45][535/750]	BT 0.178 (1.146)	DT 0.009 (1.010)	loss nan (nan)	prob nan (nan)	GS 31.875 (31.875)	mem 40.132
Train: [45][540/750]	BT 5.199 (1.146)	DT 5.023 (1.010)	loss nan (nan)	prob nan (nan)	GS 30.422 (30.422)	mem 40.177
Train: [45][545/750]	BT 0.127 (1.141)	DT 0.002 (1.004)	loss nan (nan)	prob nan (nan)	GS 31.000 (31.000)	mem 40.112
Train: [45][550/750]	BT 1.001 (1.138)	DT 0.904 (1.002)	loss nan (nan)	prob nan (nan)	GS 35.812 (35.812)	mem 40.032
Train: [45][555/750]	BT 0.099 (1.145)	DT 0.002 (1.009)	loss nan (nan)	prob nan (nan)	GS 26.891 (26.891)	mem 40.153
Train: [45][560/750]	BT 0.078 (1.140)	DT 0.002 (1.004)	loss nan (nan)	prob nan (nan)	GS 29.578 (29.578)	mem 40.044
Train: [45][565/750]	BT 0.169 (1.147)	DT 0.001 (1.011)	loss nan (nan)	prob nan (nan)	GS 27.875 (27.875)	mem 39.952
Train: [45][570/750]	BT 0.127 (1.141)	DT 0.035 (1.005)	loss nan (nan)	prob nan (nan)	GS 30.766 (30.766)	mem 39.969
Train: [45][575/750]	BT 0.102 (1.147)	DT 0.007 (1.011)	loss nan (nan)	prob nan (nan)	GS 31.266 (31.266)	mem 40.128
Train: [45][580/750]	BT 3.037 (1.145)	DT 2.967 (1.009)	loss nan (nan)	prob nan (nan)	GS 33.969 (33.969)	mem 40.046
Train: [45][585/750]	BT 0.141 (1.137)	DT 0.003 (1.001)	loss nan (nan)	prob nan (nan)	GS 33.969 (33.969)	mem 40.072
Train: [45][590/750]	BT 0.140 (1.146)	DT 0.002 (1.010)	loss nan (nan)	prob nan (nan)	GS 33.406 (33.406)	mem 39.991
Train: [45][595/750]	BT 0.108 (1.138)	DT 0.001 (1.002)	loss nan (nan)	prob nan (nan)	GS 30.406 (30.406)	mem 39.943
Train: [45][600/750]	BT 4.755 (1.148)	DT 4.673 (1.013)	loss nan (nan)	prob nan (nan)	GS 37.797 (37.797)	mem 40.070
Train: [45][605/750]	BT 0.157 (1.140)	DT 0.018 (1.004)	loss nan (nan)	prob nan (nan)	GS 31.594 (31.594)	mem 40.363
Train: [45][610/750]	BT 5.615 (1.141)	DT 5.491 (1.005)	loss nan (nan)	prob nan (nan)	GS 36.938 (36.938)	mem 39.969
Train: [45][615/750]	BT 0.131 (1.144)	DT 0.001 (1.008)	loss nan (nan)	prob nan (nan)	GS 28.719 (28.719)	mem 39.952
Train: [45][620/750]	BT 0.183 (1.136)	DT 0.008 (1.000)	loss nan (nan)	prob nan (nan)	GS 32.000 (32.000)	mem 39.952
Train: [45][625/750]	BT 0.128 (1.144)	DT 0.004 (1.008)	loss nan (nan)	prob nan (nan)	GS 31.000 (31.000)	mem 39.920
Train: [45][630/750]	BT 0.101 (1.136)	DT 0.002 (1.000)	loss nan (nan)	prob nan (nan)	GS 38.234 (38.234)	mem 40.170
Train: [45][635/750]	BT 0.112 (1.132)	DT 0.002 (0.997)	loss nan (nan)	prob nan (nan)	GS 36.375 (36.375)	mem 39.993
Train: [45][640/750]	BT 0.213 (1.136)	DT 0.059 (1.000)	loss nan (nan)	prob nan (nan)	GS 33.031 (33.031)	mem 40.082
Train: [45][645/750]	BT 0.315 (1.128)	DT 0.006 (0.992)	loss nan (nan)	prob nan (nan)	GS 30.312 (30.312)	mem 40.083
Train: [45][650/750]	BT 0.121 (1.140)	DT 0.001 (1.004)	loss nan (nan)	prob nan (nan)	GS 34.297 (34.297)	mem 39.960
Train: [45][655/750]	BT 0.240 (1.132)	DT 0.002 (0.997)	loss nan (nan)	prob nan (nan)	GS 26.594 (26.594)	mem 39.994
Train: [45][660/750]	BT 2.429 (1.143)	DT 2.318 (1.008)	loss nan (nan)	prob nan (nan)	GS 30.172 (30.172)	mem 40.035
Train: [45][665/750]	BT 0.116 (1.136)	DT 0.002 (1.000)	loss nan (nan)	prob nan (nan)	GS 31.844 (31.844)	mem 40.036
Train: [45][670/750]	BT 9.236 (1.142)	DT 9.066 (1.006)	loss nan (nan)	prob nan (nan)	GS 34.984 (34.984)	mem 40.103
Train: [45][675/750]	BT 0.100 (1.136)	DT 0.002 (1.001)	loss nan (nan)	prob nan (nan)	GS 35.188 (35.188)	mem 40.350
Train: [45][680/750]	BT 0.142 (1.129)	DT 0.012 (0.993)	loss nan (nan)	prob nan (nan)	GS 30.031 (30.031)	mem 40.108
Train: [45][685/750]	BT 0.135 (1.135)	DT 0.002 (0.999)	loss nan (nan)	prob nan (nan)	GS 29.516 (29.516)	mem 40.069
Train: [45][690/750]	BT 0.132 (1.130)	DT 0.001 (0.994)	loss nan (nan)	prob nan (nan)	GS 36.609 (36.609)	mem 40.050
Train: [45][695/750]	BT 0.104 (1.131)	DT 0.002 (0.996)	loss nan (nan)	prob nan (nan)	GS 30.516 (30.516)	mem 40.184
Train: [45][700/750]	BT 0.162 (1.132)	DT 0.002 (0.996)	loss nan (nan)	prob nan (nan)	GS 34.391 (34.391)	mem 40.064
Train: [45][705/750]	BT 0.140 (1.126)	DT 0.002 (0.990)	loss nan (nan)	prob nan (nan)	GS 32.344 (32.344)	mem 40.002
arpack error, retry= 0
Train: [45][710/750]	BT 1.693 (1.137)	DT 1.580 (1.001)	loss nan (nan)	prob nan (nan)	GS 33.297 (33.297)	mem 40.082
Train: [45][715/750]	BT 0.142 (1.130)	DT 0.001 (0.994)	loss nan (nan)	prob nan (nan)	GS 41.953 (41.953)	mem 40.043
Train: [45][720/750]	BT 0.458 (1.137)	DT 0.366 (1.002)	loss nan (nan)	prob nan (nan)	GS 35.922 (35.922)	mem 40.058
Train: [45][725/750]	BT 0.156 (1.130)	DT 0.002 (0.995)	loss nan (nan)	prob nan (nan)	GS 28.031 (28.031)	mem 40.135
Train: [45][730/750]	BT 7.511 (1.134)	DT 7.345 (0.998)	loss nan (nan)	prob nan (nan)	GS 35.781 (35.781)	mem 39.649
Train: [45][735/750]	BT 0.078 (1.127)	DT 0.001 (0.992)	loss nan (nan)	prob nan (nan)	GS 23.547 (23.547)	mem 36.806
Train: [45][740/750]	BT 0.151 (1.120)	DT 0.002 (0.985)	loss nan (nan)	prob nan (nan)	GS 33.250 (33.250)	mem 37.283
Train: [45][745/750]	BT 0.079 (1.124)	DT 0.002 (0.989)	loss nan (nan)	prob nan (nan)	GS 26.062 (26.062)	mem 10.800
Train: [45][750/750]	BT 0.092 (1.117)	DT 0.001 (0.982)	loss nan (nan)	prob nan (nan)	GS 34.188 (34.188)	mem 10.733
Train: [45][755/750]	BT 0.064 (1.112)	DT 0.001 (0.978)	loss nan (nan)	prob nan (nan)	GS 35.250 (35.250)	mem 7.717
epoch 45, total time 840.06
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [46][1/750]	BT 21.470 (21.470)	DT 21.275 (21.275)	loss nan (nan)	prob nan (nan)	GS 34.266 (34.266)	mem 38.335
Train: [46][5/750]	BT 0.128 (4.749)	DT 0.005 (4.584)	loss nan (nan)	prob nan (nan)	GS 30.469 (30.469)	mem 38.875
Train: [46][10/750]	BT 0.096 (2.458)	DT 0.003 (2.310)	loss nan (nan)	prob nan (nan)	GS 33.844 (33.844)	mem 38.579
Train: [46][15/750]	BT 0.116 (2.578)	DT 0.002 (2.420)	loss nan (nan)	prob nan (nan)	GS 30.531 (30.531)	mem 38.959
Train: [46][20/750]	BT 1.406 (2.112)	DT 1.287 (1.958)	loss nan (nan)	prob nan (nan)	GS 36.359 (36.359)	mem 38.992
Train: [46][25/750]	BT 0.094 (1.721)	DT 0.002 (1.567)	loss nan (nan)	prob nan (nan)	GS 33.062 (33.062)	mem 39.043
Train: [46][30/750]	BT 0.101 (1.784)	DT 0.001 (1.639)	loss nan (nan)	prob nan (nan)	GS 32.422 (32.422)	mem 39.015
Train: [46][35/750]	BT 0.147 (1.564)	DT 0.004 (1.418)	loss nan (nan)	prob nan (nan)	GS 29.859 (29.859)	mem 39.019
Train: [46][40/750]	BT 4.317 (1.751)	DT 4.156 (1.606)	loss nan (nan)	prob nan (nan)	GS 33.172 (33.172)	mem 39.044
Train: [46][45/750]	BT 0.103 (1.568)	DT 0.002 (1.428)	loss nan (nan)	prob nan (nan)	GS 30.859 (30.859)	mem 39.059
Train: [46][50/750]	BT 8.066 (1.584)	DT 7.974 (1.445)	loss nan (nan)	prob nan (nan)	GS 34.578 (34.578)	mem 39.166
Train: [46][55/750]	BT 0.222 (1.532)	DT 0.001 (1.391)	loss nan (nan)	prob nan (nan)	GS 29.203 (29.203)	mem 39.075
Train: [46][60/750]	BT 0.104 (1.414)	DT 0.004 (1.276)	loss nan (nan)	prob nan (nan)	GS 33.906 (33.906)	mem 39.076
Train: [46][65/750]	BT 0.183 (1.480)	DT 0.002 (1.343)	loss nan (nan)	prob nan (nan)	GS 32.531 (32.531)	mem 39.211
Train: [46][70/750]	BT 2.731 (1.419)	DT 2.476 (1.283)	loss nan (nan)	prob nan (nan)	GS 34.797 (34.797)	mem 39.128
Train: [46][75/750]	BT 0.082 (1.450)	DT 0.001 (1.316)	loss nan (nan)	prob nan (nan)	GS 33.578 (33.578)	mem 39.412
Train: [46][80/750]	BT 0.165 (1.383)	DT 0.001 (1.250)	loss nan (nan)	prob nan (nan)	GS 34.562 (34.562)	mem 39.484
Train: [46][85/750]	BT 0.146 (1.312)	DT 0.012 (1.176)	loss nan (nan)	prob nan (nan)	GS 33.438 (33.438)	mem 39.436
Train: [46][90/750]	BT 0.099 (1.412)	DT 0.014 (1.278)	loss nan (nan)	prob nan (nan)	GS 33.922 (33.922)	mem 39.545
Train: [46][95/750]	BT 0.104 (1.345)	DT 0.002 (1.211)	loss nan (nan)	prob nan (nan)	GS 29.531 (29.531)	mem 39.624
Train: [46][100/750]	BT 0.138 (1.421)	DT 0.054 (1.287)	loss nan (nan)	prob nan (nan)	GS 35.656 (35.656)	mem 40.146
Train: [46][105/750]	BT 0.103 (1.360)	DT 0.002 (1.226)	loss nan (nan)	prob nan (nan)	GS 31.969 (31.969)	mem 39.805
Train: [46][110/750]	BT 12.109 (1.412)	DT 12.014 (1.280)	loss nan (nan)	prob nan (nan)	GS 33.719 (33.719)	mem 39.763
Train: [46][115/750]	BT 0.238 (1.366)	DT 0.001 (1.235)	loss nan (nan)	prob nan (nan)	GS 34.234 (34.234)	mem 39.832
Train: [46][120/750]	BT 0.105 (1.316)	DT 0.001 (1.184)	loss nan (nan)	prob nan (nan)	GS 35.469 (35.469)	mem 39.943
Train: [46][125/750]	BT 0.086 (1.357)	DT 0.002 (1.223)	loss nan (nan)	prob nan (nan)	GS 32.109 (32.109)	mem 39.804
Train: [46][130/750]	BT 0.148 (1.310)	DT 0.016 (1.176)	loss nan (nan)	prob nan (nan)	GS 39.000 (39.000)	mem 39.804
Train: [46][135/750]	BT 0.144 (1.313)	DT 0.002 (1.179)	loss nan (nan)	prob nan (nan)	GS 29.422 (29.422)	mem 39.817
Train: [46][140/750]	BT 0.115 (1.285)	DT 0.001 (1.151)	loss nan (nan)	prob nan (nan)	GS 33.141 (33.141)	mem 39.857
Train: [46][145/750]	BT 0.206 (1.246)	DT 0.002 (1.112)	loss nan (nan)	prob nan (nan)	GS 33.484 (33.484)	mem 39.762
Train: [46][150/750]	BT 0.171 (1.304)	DT 0.003 (1.170)	loss nan (nan)	prob nan (nan)	GS 35.531 (35.531)	mem 39.817
Train: [46][155/750]	BT 0.221 (1.265)	DT 0.002 (1.132)	loss nan (nan)	prob nan (nan)	GS 28.656 (28.656)	mem 39.820
Train: [46][160/750]	BT 0.151 (1.309)	DT 0.001 (1.177)	loss nan (nan)	prob nan (nan)	GS 34.344 (34.344)	mem 39.906
Train: [46][165/750]	BT 0.164 (1.274)	DT 0.004 (1.141)	loss nan (nan)	prob nan (nan)	GS 34.750 (34.750)	mem 39.910
Train: [46][170/750]	BT 11.143 (1.305)	DT 11.071 (1.173)	loss nan (nan)	prob nan (nan)	GS 35.781 (35.781)	mem 39.926
Train: [46][175/750]	BT 0.140 (1.271)	DT 0.002 (1.140)	loss nan (nan)	prob nan (nan)	GS 31.906 (31.906)	mem 39.926
Train: [46][180/750]	BT 0.116 (1.240)	DT 0.002 (1.108)	loss nan (nan)	prob nan (nan)	GS 35.609 (35.609)	mem 39.927
Train: [46][185/750]	BT 0.147 (1.267)	DT 0.002 (1.135)	loss nan (nan)	prob nan (nan)	GS 30.953 (30.953)	mem 39.878
Train: [46][190/750]	BT 0.115 (1.238)	DT 0.012 (1.105)	loss nan (nan)	prob nan (nan)	GS 34.219 (34.219)	mem 39.975
Train: [46][195/750]	BT 0.071 (1.272)	DT 0.001 (1.140)	loss nan (nan)	prob nan (nan)	GS 30.891 (30.891)	mem 39.920
Train: [46][200/750]	BT 0.116 (1.250)	DT 0.003 (1.118)	loss nan (nan)	prob nan (nan)	GS 35.812 (35.812)	mem 40.021
Train: [46][205/750]	BT 0.121 (1.223)	DT 0.015 (1.091)	loss nan (nan)	prob nan (nan)	GS 31.938 (31.938)	mem 39.928
Train: [46][210/750]	BT 0.121 (1.257)	DT 0.001 (1.124)	loss nan (nan)	prob nan (nan)	GS 35.344 (35.344)	mem 39.892
Train: [46][215/750]	BT 0.141 (1.232)	DT 0.002 (1.098)	loss nan (nan)	prob nan (nan)	GS 29.484 (29.484)	mem 39.892
Train: [46][220/750]	BT 0.129 (1.253)	DT 0.022 (1.120)	loss nan (nan)	prob nan (nan)	GS 36.266 (36.266)	mem 39.926
Train: [46][225/750]	BT 0.189 (1.229)	DT 0.014 (1.096)	loss nan (nan)	prob nan (nan)	GS 33.438 (33.438)	mem 39.979
Train: [46][230/750]	BT 10.235 (1.248)	DT 10.128 (1.116)	loss nan (nan)	prob nan (nan)	GS 30.203 (30.203)	mem 40.138
Train: [46][235/750]	BT 0.086 (1.227)	DT 0.002 (1.095)	loss nan (nan)	prob nan (nan)	GS 30.203 (30.203)	mem 39.997
Train: [46][240/750]	BT 0.163 (1.205)	DT 0.001 (1.072)	loss nan (nan)	prob nan (nan)	GS 31.859 (31.859)	mem 40.095
Train: [46][245/750]	BT 0.086 (1.236)	DT 0.022 (1.103)	loss nan (nan)	prob nan (nan)	GS 32.000 (32.000)	mem 39.967
Train: [46][250/750]	BT 0.133 (1.215)	DT 0.007 (1.081)	loss nan (nan)	prob nan (nan)	GS 36.781 (36.781)	mem 40.077
Train: [46][255/750]	BT 0.168 (1.204)	DT 0.004 (1.071)	loss nan (nan)	prob nan (nan)	GS 35.984 (35.984)	mem 40.197
Train: [46][260/750]	BT 0.109 (1.223)	DT 0.001 (1.091)	loss nan (nan)	prob nan (nan)	GS 31.406 (31.406)	mem 39.870
Train: [46][265/750]	BT 0.168 (1.203)	DT 0.002 (1.071)	loss nan (nan)	prob nan (nan)	GS 31.156 (31.156)	mem 39.872
Train: [46][270/750]	BT 0.111 (1.233)	DT 0.011 (1.101)	loss nan (nan)	prob nan (nan)	GS 32.234 (32.234)	mem 39.983
Train: [46][275/750]	BT 0.162 (1.213)	DT 0.002 (1.081)	loss nan (nan)	prob nan (nan)	GS 31.484 (31.484)	mem 39.976
Train: [46][280/750]	BT 11.914 (1.236)	DT 11.821 (1.104)	loss nan (nan)	prob nan (nan)	GS 32.922 (32.922)	mem 39.999
Train: [46][285/750]	BT 0.114 (1.216)	DT 0.002 (1.084)	loss nan (nan)	prob nan (nan)	GS 31.281 (31.281)	mem 40.000
Train: [46][290/750]	BT 0.123 (1.198)	DT 0.019 (1.066)	loss nan (nan)	prob nan (nan)	GS 34.109 (34.109)	mem 40.009
Train: [46][295/750]	BT 0.151 (1.224)	DT 0.001 (1.092)	loss nan (nan)	prob nan (nan)	GS 33.375 (33.375)	mem 39.987
Train: [46][300/750]	BT 0.115 (1.206)	DT 0.001 (1.074)	loss nan (nan)	prob nan (nan)	GS 30.578 (30.578)	mem 39.957
Train: [46][305/750]	BT 0.063 (1.229)	DT 0.001 (1.098)	loss nan (nan)	prob nan (nan)	GS 31.953 (31.953)	mem 39.932
Train: [46][310/750]	BT 0.095 (1.211)	DT 0.001 (1.080)	loss nan (nan)	prob nan (nan)	GS 31.547 (31.547)	mem 39.930
Train: [46][315/750]	BT 0.095 (1.203)	DT 0.002 (1.073)	loss nan (nan)	prob nan (nan)	GS 28.984 (28.984)	mem 39.961
Train: [46][320/750]	BT 0.094 (1.206)	DT 0.002 (1.076)	loss nan (nan)	prob nan (nan)	GS 34.000 (34.000)	mem 40.217
Train: [46][325/750]	BT 0.132 (1.190)	DT 0.001 (1.060)	loss nan (nan)	prob nan (nan)	GS 35.156 (35.156)	mem 40.002
Train: [46][330/750]	BT 0.233 (1.206)	DT 0.001 (1.075)	loss nan (nan)	prob nan (nan)	GS 32.234 (32.234)	mem 40.019
Train: [46][335/750]	BT 0.152 (1.190)	DT 0.002 (1.059)	loss nan (nan)	prob nan (nan)	GS 31.484 (31.484)	mem 40.021
Train: [46][340/750]	BT 9.175 (1.206)	DT 9.066 (1.076)	loss nan (nan)	prob nan (nan)	GS 34.156 (34.156)	mem 40.020
Train: [46][345/750]	BT 0.108 (1.190)	DT 0.004 (1.060)	loss nan (nan)	prob nan (nan)	GS 32.109 (32.109)	mem 39.940
Train: [46][350/750]	BT 0.384 (1.176)	DT 0.189 (1.046)	loss nan (nan)	prob nan (nan)	GS 34.016 (34.016)	mem 40.110
Train: [46][355/750]	BT 0.080 (1.191)	DT 0.002 (1.061)	loss nan (nan)	prob nan (nan)	GS 32.797 (32.797)	mem 40.031
Train: [46][360/750]	BT 0.108 (1.177)	DT 0.011 (1.047)	loss nan (nan)	prob nan (nan)	GS 33.672 (33.672)	mem 40.039
Train: [46][365/750]	BT 0.125 (1.203)	DT 0.012 (1.072)	loss nan (nan)	prob nan (nan)	GS 32.125 (32.125)	mem 40.018
Train: [46][370/750]	BT 0.115 (1.188)	DT 0.001 (1.058)	loss nan (nan)	prob nan (nan)	GS 31.844 (31.844)	mem 40.000
Train: [46][375/750]	BT 0.172 (1.174)	DT 0.010 (1.044)	loss nan (nan)	prob nan (nan)	GS 30.984 (30.984)	mem 40.067
Train: [46][380/750]	BT 0.068 (1.192)	DT 0.001 (1.063)	loss nan (nan)	prob nan (nan)	GS 35.797 (35.797)	mem 39.942
Train: [46][385/750]	BT 0.084 (1.178)	DT 0.002 (1.049)	loss nan (nan)	prob nan (nan)	GS 35.656 (35.656)	mem 39.981
Train: [46][390/750]	BT 0.145 (1.195)	DT 0.001 (1.066)	loss nan (nan)	prob nan (nan)	GS 28.094 (28.094)	mem 40.040
Train: [46][395/750]	BT 0.153 (1.182)	DT 0.001 (1.053)	loss nan (nan)	prob nan (nan)	GS 29.875 (29.875)	mem 40.018
Train: [46][400/750]	BT 11.223 (1.196)	DT 11.124 (1.068)	loss nan (nan)	prob nan (nan)	GS 34.750 (34.750)	mem 40.124
Train: [46][405/750]	BT 0.070 (1.183)	DT 0.001 (1.054)	loss nan (nan)	prob nan (nan)	GS 29.344 (29.344)	mem 40.022
Train: [46][410/750]	BT 0.121 (1.170)	DT 0.001 (1.042)	loss nan (nan)	prob nan (nan)	GS 30.531 (30.531)	mem 39.974
Train: [46][415/750]	BT 0.107 (1.184)	DT 0.002 (1.057)	loss nan (nan)	prob nan (nan)	GS 35.922 (35.922)	mem 40.006
Train: [46][420/750]	BT 0.114 (1.171)	DT 0.001 (1.044)	loss nan (nan)	prob nan (nan)	GS 31.047 (31.047)	mem 40.118
Train: [46][425/750]	BT 0.103 (1.186)	DT 0.014 (1.058)	loss nan (nan)	prob nan (nan)	GS 36.609 (36.609)	mem 40.186
Train: [46][430/750]	BT 0.220 (1.175)	DT 0.007 (1.046)	loss nan (nan)	prob nan (nan)	GS 35.797 (35.797)	mem 40.571
Train: [46][435/750]	BT 0.094 (1.163)	DT 0.003 (1.034)	loss nan (nan)	prob nan (nan)	GS 31.422 (31.422)	mem 40.148
Train: [46][440/750]	BT 0.171 (1.171)	DT 0.009 (1.043)	loss nan (nan)	prob nan (nan)	GS 33.203 (33.203)	mem 40.090
Train: [46][445/750]	BT 0.111 (1.161)	DT 0.010 (1.031)	loss nan (nan)	prob nan (nan)	GS 35.500 (35.500)	mem 40.048
Train: [46][450/750]	BT 0.126 (1.184)	DT 0.002 (1.054)	loss nan (nan)	prob nan (nan)	GS 35.688 (35.688)	mem 40.142
Train: [46][455/750]	BT 0.147 (1.172)	DT 0.002 (1.043)	loss nan (nan)	prob nan (nan)	GS 34.688 (34.688)	mem 40.207
Train: [46][460/750]	BT 13.244 (1.189)	DT 13.125 (1.060)	loss nan (nan)	prob nan (nan)	GS 34.578 (34.578)	mem 39.904
Train: [46][465/750]	BT 0.091 (1.177)	DT 0.001 (1.049)	loss nan (nan)	prob nan (nan)	GS 27.281 (27.281)	mem 39.930
Train: [46][470/750]	BT 0.169 (1.167)	DT 0.025 (1.038)	loss nan (nan)	prob nan (nan)	GS 37.000 (37.000)	mem 39.928
Train: [46][475/750]	BT 0.102 (1.179)	DT 0.011 (1.050)	loss nan (nan)	prob nan (nan)	GS 30.562 (30.562)	mem 40.052
Train: [46][480/750]	BT 0.260 (1.168)	DT 0.001 (1.039)	loss nan (nan)	prob nan (nan)	GS 32.609 (32.609)	mem 40.059
Train: [46][485/750]	BT 0.106 (1.181)	DT 0.002 (1.052)	loss nan (nan)	prob nan (nan)	GS 35.078 (35.078)	mem 40.142
Train: [46][490/750]	BT 0.107 (1.170)	DT 0.002 (1.041)	loss nan (nan)	prob nan (nan)	GS 33.281 (33.281)	mem 40.147
Train: [46][495/750]	BT 0.225 (1.164)	DT 0.011 (1.034)	loss nan (nan)	prob nan (nan)	GS 33.469 (33.469)	mem 40.073
Train: [46][500/750]	BT 0.073 (1.172)	DT 0.002 (1.043)	loss nan (nan)	prob nan (nan)	GS 29.281 (29.281)	mem 40.032
Train: [46][505/750]	BT 0.153 (1.161)	DT 0.001 (1.032)	loss nan (nan)	prob nan (nan)	GS 31.156 (31.156)	mem 40.031
Train: [46][510/750]	BT 0.162 (1.178)	DT 0.008 (1.049)	loss nan (nan)	prob nan (nan)	GS 29.609 (29.609)	mem 40.055
Train: [46][515/750]	BT 4.412 (1.176)	DT 4.204 (1.047)	loss nan (nan)	prob nan (nan)	GS 48.656 (48.656)	mem 40.008
Train: [46][520/750]	BT 9.101 (1.184)	DT 8.988 (1.054)	loss nan (nan)	prob nan (nan)	GS 34.297 (34.297)	mem 40.074
Train: [46][525/750]	BT 0.178 (1.174)	DT 0.012 (1.044)	loss nan (nan)	prob nan (nan)	GS 35.625 (35.625)	mem 40.095
Train: [46][530/750]	BT 0.096 (1.164)	DT 0.001 (1.034)	loss nan (nan)	prob nan (nan)	GS 34.312 (34.312)	mem 40.073
Train: [46][535/750]	BT 0.109 (1.176)	DT 0.001 (1.046)	loss nan (nan)	prob nan (nan)	GS 30.609 (30.609)	mem 39.991
Train: [46][540/750]	BT 0.087 (1.166)	DT 0.002 (1.037)	loss nan (nan)	prob nan (nan)	GS 32.562 (32.562)	mem 40.040
Train: [46][545/750]	BT 0.122 (1.182)	DT 0.002 (1.053)	loss nan (nan)	prob nan (nan)	GS 31.094 (31.094)	mem 40.205
Train: [46][550/750]	BT 0.099 (1.172)	DT 0.010 (1.043)	loss nan (nan)	prob nan (nan)	GS 34.000 (34.000)	mem 40.061
Train: [46][555/750]	BT 0.200 (1.163)	DT 0.002 (1.034)	loss nan (nan)	prob nan (nan)	GS 29.547 (29.547)	mem 40.056
Train: [46][560/750]	BT 0.078 (1.174)	DT 0.002 (1.046)	loss nan (nan)	prob nan (nan)	GS 35.031 (35.031)	mem 39.960
Train: [46][565/750]	BT 0.243 (1.166)	DT 0.012 (1.037)	loss nan (nan)	prob nan (nan)	GS 31.797 (31.797)	mem 39.928
Train: [46][570/750]	BT 0.125 (1.181)	DT 0.002 (1.053)	loss nan (nan)	prob nan (nan)	GS 31.641 (31.641)	mem 39.885
Train: [46][575/750]	BT 0.097 (1.172)	DT 0.005 (1.043)	loss nan (nan)	prob nan (nan)	GS 31.031 (31.031)	mem 39.887
Train: [46][580/750]	BT 11.023 (1.182)	DT 10.849 (1.053)	loss nan (nan)	prob nan (nan)	GS 30.344 (30.344)	mem 39.970
Train: [46][585/750]	BT 0.127 (1.173)	DT 0.010 (1.044)	loss nan (nan)	prob nan (nan)	GS 30.266 (30.266)	mem 39.970
Train: [46][590/750]	BT 0.104 (1.165)	DT 0.003 (1.036)	loss nan (nan)	prob nan (nan)	GS 35.875 (35.875)	mem 40.000
Train: [46][595/750]	BT 0.127 (1.178)	DT 0.002 (1.049)	loss nan (nan)	prob nan (nan)	GS 33.453 (33.453)	mem 39.967
Train: [46][600/750]	BT 0.154 (1.169)	DT 0.002 (1.040)	loss nan (nan)	prob nan (nan)	GS 34.812 (34.812)	mem 40.029
Train: [46][605/750]	BT 0.143 (1.175)	DT 0.011 (1.046)	loss nan (nan)	prob nan (nan)	GS 31.344 (31.344)	mem 40.057
Train: [46][610/750]	BT 0.149 (1.167)	DT 0.007 (1.038)	loss nan (nan)	prob nan (nan)	GS 35.719 (35.719)	mem 40.194
Train: [46][615/750]	BT 0.089 (1.159)	DT 0.001 (1.029)	loss nan (nan)	prob nan (nan)	GS 32.438 (32.438)	mem 40.008
Train: [46][620/750]	BT 0.220 (1.169)	DT 0.002 (1.039)	loss nan (nan)	prob nan (nan)	GS 38.250 (38.250)	mem 39.902
Train: [46][625/750]	BT 0.084 (1.161)	DT 0.013 (1.031)	loss nan (nan)	prob nan (nan)	GS 32.344 (32.344)	mem 39.936
Train: [46][630/750]	BT 0.093 (1.176)	DT 0.002 (1.046)	loss nan (nan)	prob nan (nan)	GS 37.000 (37.000)	mem 39.875
Train: [46][635/750]	BT 0.080 (1.168)	DT 0.001 (1.038)	loss nan (nan)	prob nan (nan)	GS 34.203 (34.203)	mem 39.928
Train: [46][640/750]	BT 12.558 (1.179)	DT 12.437 (1.049)	loss nan (nan)	prob nan (nan)	GS 34.953 (34.953)	mem 40.072
Train: [46][645/750]	BT 0.077 (1.171)	DT 0.002 (1.041)	loss nan (nan)	prob nan (nan)	GS 34.266 (34.266)	mem 40.045
Train: [46][650/750]	BT 0.100 (1.163)	DT 0.002 (1.033)	loss nan (nan)	prob nan (nan)	GS 32.172 (32.172)	mem 40.036
Train: [46][655/750]	BT 0.139 (1.171)	DT 0.002 (1.042)	loss nan (nan)	prob nan (nan)	GS 25.766 (25.766)	mem 40.178
Train: [46][660/750]	BT 0.180 (1.163)	DT 0.002 (1.034)	loss nan (nan)	prob nan (nan)	GS 33.875 (33.875)	mem 40.101
Train: [46][665/750]	BT 0.073 (1.173)	DT 0.001 (1.044)	loss nan (nan)	prob nan (nan)	GS 31.719 (31.719)	mem 39.894
Train: [46][670/750]	BT 0.158 (1.165)	DT 0.001 (1.036)	loss nan (nan)	prob nan (nan)	GS 32.703 (32.703)	mem 39.891
Train: [46][675/750]	BT 0.131 (1.158)	DT 0.004 (1.028)	loss nan (nan)	prob nan (nan)	GS 30.219 (30.219)	mem 39.920
Train: [46][680/750]	BT 0.209 (1.169)	DT 0.002 (1.040)	loss nan (nan)	prob nan (nan)	GS 32.406 (32.406)	mem 40.034
Train: [46][685/750]	BT 0.128 (1.162)	DT 0.003 (1.032)	loss nan (nan)	prob nan (nan)	GS 32.531 (32.531)	mem 39.994
Train: [46][690/750]	BT 0.071 (1.170)	DT 0.002 (1.040)	loss nan (nan)	prob nan (nan)	GS 35.344 (35.344)	mem 40.049
Train: [46][695/750]	BT 0.134 (1.162)	DT 0.002 (1.033)	loss nan (nan)	prob nan (nan)	GS 30.000 (30.000)	mem 40.153
Train: [46][700/750]	BT 12.090 (1.172)	DT 11.994 (1.042)	loss nan (nan)	prob nan (nan)	GS 34.391 (34.391)	mem 40.100
Train: [46][705/750]	BT 0.080 (1.164)	DT 0.004 (1.035)	loss nan (nan)	prob nan (nan)	GS 28.594 (28.594)	mem 40.093
Train: [46][710/750]	BT 0.090 (1.157)	DT 0.001 (1.028)	loss nan (nan)	prob nan (nan)	GS 32.281 (32.281)	mem 40.052
Train: [46][715/750]	BT 0.138 (1.164)	DT 0.002 (1.035)	loss nan (nan)	prob nan (nan)	GS 32.906 (32.906)	mem 40.085
Train: [46][720/750]	BT 0.142 (1.157)	DT 0.002 (1.028)	loss nan (nan)	prob nan (nan)	GS 29.453 (29.453)	mem 40.012
Train: [46][725/750]	BT 0.117 (1.167)	DT 0.002 (1.038)	loss nan (nan)	prob nan (nan)	GS 30.469 (30.469)	mem 39.865
Train: [46][730/750]	BT 0.117 (1.161)	DT 0.001 (1.032)	loss nan (nan)	prob nan (nan)	GS 36.812 (36.812)	mem 39.728
Train: [46][735/750]	BT 0.089 (1.154)	DT 0.002 (1.025)	loss nan (nan)	prob nan (nan)	GS 33.578 (33.578)	mem 39.794
Train: [46][740/750]	BT 0.484 (1.155)	DT 0.404 (1.027)	loss nan (nan)	prob nan (nan)	GS 31.016 (31.016)	mem 10.676
Train: [46][745/750]	BT 0.063 (1.148)	DT 0.001 (1.020)	loss nan (nan)	prob nan (nan)	GS 32.125 (32.125)	mem 10.690
Train: [46][750/750]	BT 0.066 (1.143)	DT 0.001 (1.015)	loss nan (nan)	prob nan (nan)	GS 33.188 (33.188)	mem 10.623
Train: [46][755/750]	BT 0.077 (1.137)	DT 0.002 (1.009)	loss nan (nan)	prob nan (nan)	GS 37.688 (37.688)	mem 7.588
epoch 46, total time 858.40
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [47][1/750]	BT 21.778 (21.778)	DT 21.646 (21.646)	loss nan (nan)	prob nan (nan)	GS 30.641 (30.641)	mem 39.160
Train: [47][5/750]	BT 0.168 (4.703)	DT 0.001 (4.577)	loss nan (nan)	prob nan (nan)	GS 29.094 (29.094)	mem 39.410
Train: [47][10/750]	BT 0.107 (2.531)	DT 0.001 (2.417)	loss nan (nan)	prob nan (nan)	GS 35.969 (35.969)	mem 39.393
Train: [47][15/750]	BT 0.260 (2.410)	DT 0.071 (2.284)	loss nan (nan)	prob nan (nan)	GS 32.047 (32.047)	mem 39.502
Train: [47][20/750]	BT 0.117 (1.844)	DT 0.006 (1.714)	loss nan (nan)	prob nan (nan)	GS 33.562 (33.562)	mem 39.490
Train: [47][25/750]	BT 2.780 (1.613)	DT 2.596 (1.476)	loss nan (nan)	prob nan (nan)	GS 31.281 (31.281)	mem 39.758
Train: [47][30/750]	BT 0.187 (1.746)	DT 0.024 (1.609)	loss nan (nan)	prob nan (nan)	GS 36.531 (36.531)	mem 39.570
Train: [47][35/750]	BT 0.207 (1.517)	DT 0.011 (1.380)	loss nan (nan)	prob nan (nan)	GS 31.719 (31.719)	mem 39.575
Train: [47][40/750]	BT 0.132 (1.717)	DT 0.005 (1.582)	loss nan (nan)	prob nan (nan)	GS 34.062 (34.062)	mem 39.638
Train: [47][45/750]	BT 0.153 (1.544)	DT 0.002 (1.406)	loss nan (nan)	prob nan (nan)	GS 31.453 (31.453)	mem 39.654
Train: [47][50/750]	BT 11.870 (1.637)	DT 11.782 (1.502)	loss nan (nan)	prob nan (nan)	GS 31.844 (31.844)	mem 39.652
Train: [47][55/750]	BT 0.142 (1.497)	DT 0.004 (1.366)	loss nan (nan)	prob nan (nan)	GS 30.797 (30.797)	mem 39.732
Train: [47][60/750]	BT 0.205 (1.385)	DT 0.001 (1.252)	loss nan (nan)	prob nan (nan)	GS 33.297 (33.297)	mem 39.972
Train: [47][65/750]	BT 0.084 (1.512)	DT 0.001 (1.380)	loss nan (nan)	prob nan (nan)	GS 39.484 (39.484)	mem 39.726
Train: [47][70/750]	BT 0.100 (1.409)	DT 0.001 (1.281)	loss nan (nan)	prob nan (nan)	GS 32.859 (32.859)	mem 39.734
Train: [47][75/750]	BT 0.116 (1.467)	DT 0.002 (1.336)	loss nan (nan)	prob nan (nan)	GS 26.812 (26.812)	mem 39.750
Train: [47][80/750]	BT 0.108 (1.382)	DT 0.001 (1.253)	loss nan (nan)	prob nan (nan)	GS 33.828 (33.828)	mem 39.754
Train: [47][85/750]	BT 0.159 (1.310)	DT 0.005 (1.179)	loss nan (nan)	prob nan (nan)	GS 33.031 (33.031)	mem 39.764
Train: [47][90/750]	BT 0.075 (1.388)	DT 0.001 (1.260)	loss nan (nan)	prob nan (nan)	GS 34.297 (34.297)	mem 39.805
Train: [47][95/750]	BT 0.105 (1.321)	DT 0.006 (1.194)	loss nan (nan)	prob nan (nan)	GS 25.734 (25.734)	mem 39.760
Train: [47][100/750]	BT 0.095 (1.372)	DT 0.002 (1.246)	loss nan (nan)	prob nan (nan)	GS 34.609 (34.609)	mem 39.812
Train: [47][105/750]	BT 0.144 (1.314)	DT 0.007 (1.187)	loss nan (nan)	prob nan (nan)	GS 31.359 (31.359)	mem 39.919
Train: [47][110/750]	BT 10.545 (1.356)	DT 10.292 (1.227)	loss nan (nan)	prob nan (nan)	GS 34.156 (34.156)	mem 39.910
Train: [47][115/750]	BT 0.119 (1.304)	DT 0.002 (1.174)	loss nan (nan)	prob nan (nan)	GS 32.344 (32.344)	mem 39.890
Train: [47][120/750]	BT 0.118 (1.254)	DT 0.006 (1.125)	loss nan (nan)	prob nan (nan)	GS 37.656 (37.656)	mem 39.802
Train: [47][125/750]	BT 0.082 (1.304)	DT 0.002 (1.176)	loss nan (nan)	prob nan (nan)	GS 42.672 (42.672)	mem 39.847
Train: [47][130/750]	BT 0.081 (1.258)	DT 0.002 (1.131)	loss nan (nan)	prob nan (nan)	GS 33.781 (33.781)	mem 39.851
Train: [47][135/750]	BT 0.086 (1.285)	DT 0.001 (1.158)	loss nan (nan)	prob nan (nan)	GS 30.328 (30.328)	mem 39.857
Train: [47][140/750]	BT 0.086 (1.245)	DT 0.002 (1.117)	loss nan (nan)	prob nan (nan)	GS 35.094 (35.094)	mem 39.967
Train: [47][145/750]	BT 0.095 (1.206)	DT 0.001 (1.079)	loss nan (nan)	prob nan (nan)	GS 31.578 (31.578)	mem 39.861
Train: [47][150/750]	BT 0.110 (1.254)	DT 0.004 (1.127)	loss nan (nan)	prob nan (nan)	GS 34.297 (34.297)	mem 39.920
Train: [47][155/750]	BT 0.098 (1.219)	DT 0.002 (1.091)	loss nan (nan)	prob nan (nan)	GS 30.531 (30.531)	mem 39.874
Train: [47][160/750]	BT 0.135 (1.272)	DT 0.002 (1.144)	loss nan (nan)	prob nan (nan)	GS 34.672 (34.672)	mem 40.012
Train: [47][165/750]	BT 0.137 (1.238)	DT 0.007 (1.109)	loss nan (nan)	prob nan (nan)	GS 29.250 (29.250)	mem 39.965
Train: [47][170/750]	BT 13.071 (1.283)	DT 12.905 (1.153)	loss nan (nan)	prob nan (nan)	GS 36.312 (36.312)	mem 39.961
Train: [47][175/750]	BT 0.124 (1.250)	DT 0.002 (1.120)	loss nan (nan)	prob nan (nan)	GS 32.516 (32.516)	mem 39.971
Train: [47][180/750]	BT 0.101 (1.220)	DT 0.002 (1.089)	loss nan (nan)	prob nan (nan)	GS 34.141 (34.141)	mem 39.977
Train: [47][185/750]	BT 0.089 (1.244)	DT 0.002 (1.114)	loss nan (nan)	prob nan (nan)	GS 31.875 (31.875)	mem 40.038
Train: [47][190/750]	BT 0.090 (1.215)	DT 0.003 (1.084)	loss nan (nan)	prob nan (nan)	GS 31.062 (31.062)	mem 40.110
Train: [47][195/750]	BT 0.104 (1.260)	DT 0.002 (1.130)	loss nan (nan)	prob nan (nan)	GS 28.750 (28.750)	mem 40.097
Train: [47][200/750]	BT 0.095 (1.232)	DT 0.006 (1.102)	loss nan (nan)	prob nan (nan)	GS 34.938 (34.938)	mem 40.029
Train: [47][205/750]	BT 0.143 (1.205)	DT 0.010 (1.076)	loss nan (nan)	prob nan (nan)	GS 30.531 (30.531)	mem 40.105
Train: [47][210/750]	BT 0.080 (1.229)	DT 0.001 (1.099)	loss nan (nan)	prob nan (nan)	GS 32.156 (32.156)	mem 40.038
Train: [47][215/750]	BT 0.082 (1.204)	DT 0.002 (1.074)	loss nan (nan)	prob nan (nan)	GS 30.219 (30.219)	mem 40.184
Train: [47][220/750]	BT 0.097 (1.224)	DT 0.002 (1.095)	loss nan (nan)	prob nan (nan)	GS 33.688 (33.688)	mem 40.025
Train: [47][225/750]	BT 0.134 (1.201)	DT 0.005 (1.071)	loss nan (nan)	prob nan (nan)	GS 30.422 (30.422)	mem 40.027
Train: [47][230/750]	BT 10.973 (1.226)	DT 10.886 (1.096)	loss nan (nan)	prob nan (nan)	GS 28.438 (28.438)	mem 39.991
Train: [47][235/750]	BT 0.094 (1.202)	DT 0.002 (1.073)	loss nan (nan)	prob nan (nan)	GS 29.141 (29.141)	mem 39.991
Train: [47][240/750]	BT 0.807 (1.186)	DT 0.579 (1.055)	loss nan (nan)	prob nan (nan)	GS 33.688 (33.688)	mem 40.080
Train: [47][245/750]	BT 0.205 (1.202)	DT 0.006 (1.071)	loss nan (nan)	prob nan (nan)	GS 34.281 (34.281)	mem 40.118
Train: [47][250/750]	BT 0.079 (1.181)	DT 0.009 (1.050)	loss nan (nan)	prob nan (nan)	GS 33.453 (33.453)	mem 40.096
Train: [47][255/750]	BT 0.130 (1.209)	DT 0.002 (1.079)	loss nan (nan)	prob nan (nan)	GS 30.328 (30.328)	mem 40.062
Train: [47][260/750]	BT 0.173 (1.188)	DT 0.002 (1.058)	loss nan (nan)	prob nan (nan)	GS 34.359 (34.359)	mem 40.066
Train: [47][265/750]	BT 0.122 (1.185)	DT 0.002 (1.055)	loss nan (nan)	prob nan (nan)	GS 28.062 (28.062)	mem 40.031
Train: [47][270/750]	BT 0.081 (1.204)	DT 0.002 (1.075)	loss nan (nan)	prob nan (nan)	GS 32.609 (32.609)	mem 40.015
Train: [47][275/750]	BT 0.112 (1.184)	DT 0.001 (1.055)	loss nan (nan)	prob nan (nan)	GS 34.562 (34.562)	mem 40.058
Train: [47][280/750]	BT 0.116 (1.203)	DT 0.002 (1.074)	loss nan (nan)	prob nan (nan)	GS 31.719 (31.719)	mem 40.267
Train: [47][285/750]	BT 0.143 (1.184)	DT 0.001 (1.055)	loss nan (nan)	prob nan (nan)	GS 31.672 (31.672)	mem 40.252
Train: [47][290/750]	BT 10.478 (1.208)	DT 10.382 (1.080)	loss nan (nan)	prob nan (nan)	GS 35.562 (35.562)	mem 40.018
Train: [47][295/750]	BT 0.096 (1.189)	DT 0.012 (1.061)	loss nan (nan)	prob nan (nan)	GS 32.062 (32.062)	mem 40.026
Train: [47][300/750]	BT 0.397 (1.172)	DT 0.184 (1.044)	loss nan (nan)	prob nan (nan)	GS 32.625 (32.625)	mem 39.955
Train: [47][305/750]	BT 0.101 (1.197)	DT 0.003 (1.070)	loss nan (nan)	prob nan (nan)	GS 36.438 (36.438)	mem 40.015
Train: [47][310/750]	BT 0.179 (1.180)	DT 0.002 (1.052)	loss nan (nan)	prob nan (nan)	GS 34.047 (34.047)	mem 40.152
Train: [47][315/750]	BT 0.098 (1.201)	DT 0.001 (1.074)	loss nan (nan)	prob nan (nan)	GS 35.359 (35.359)	mem 40.089
Train: [47][320/750]	BT 0.205 (1.184)	DT 0.046 (1.057)	loss nan (nan)	prob nan (nan)	GS 31.562 (31.562)	mem 40.093
Train: [47][325/750]	BT 0.146 (1.168)	DT 0.007 (1.041)	loss nan (nan)	prob nan (nan)	GS 32.578 (32.578)	mem 39.956
Train: [47][330/750]	BT 0.103 (1.182)	DT 0.002 (1.055)	loss nan (nan)	prob nan (nan)	GS 34.656 (34.656)	mem 39.946
Train: [47][335/750]	BT 0.220 (1.167)	DT 0.006 (1.039)	loss nan (nan)	prob nan (nan)	GS 32.703 (32.703)	mem 39.946
Train: [47][340/750]	BT 0.151 (1.189)	DT 0.001 (1.062)	loss nan (nan)	prob nan (nan)	GS 34.344 (34.344)	mem 40.058
Train: [47][345/750]	BT 0.099 (1.174)	DT 0.009 (1.047)	loss nan (nan)	prob nan (nan)	GS 31.125 (31.125)	mem 40.056
Train: [47][350/750]	BT 9.963 (1.188)	DT 9.831 (1.060)	loss nan (nan)	prob nan (nan)	GS 30.672 (30.672)	mem 39.960
Train: [47][355/750]	BT 0.098 (1.173)	DT 0.004 (1.045)	loss nan (nan)	prob nan (nan)	GS 28.969 (28.969)	mem 39.962
Train: [47][360/750]	BT 0.150 (1.169)	DT 0.004 (1.041)	loss nan (nan)	prob nan (nan)	GS 30.125 (30.125)	mem 40.005
Train: [47][365/750]	BT 0.202 (1.179)	DT 0.018 (1.051)	loss nan (nan)	prob nan (nan)	GS 32.000 (32.000)	mem 40.014
Train: [47][370/750]	BT 0.118 (1.182)	DT 0.002 (1.053)	loss nan (nan)	prob nan (nan)	GS 32.984 (32.984)	mem 40.040
Train: [47][375/750]	BT 0.251 (1.174)	DT 0.004 (1.045)	loss nan (nan)	prob nan (nan)	GS 32.453 (32.453)	mem 40.174
Train: [47][380/750]	BT 11.490 (1.190)	DT 11.292 (1.061)	loss nan (nan)	prob nan (nan)	GS 32.469 (32.469)	mem 40.052
Train: [47][385/750]	BT 0.118 (1.176)	DT 0.009 (1.047)	loss nan (nan)	prob nan (nan)	GS 30.469 (30.469)	mem 40.057
Train: [47][390/750]	BT 0.244 (1.167)	DT 0.005 (1.037)	loss nan (nan)	prob nan (nan)	GS 31.062 (31.062)	mem 40.136
Train: [47][395/750]	BT 0.084 (1.177)	DT 0.001 (1.047)	loss nan (nan)	prob nan (nan)	GS 27.625 (27.625)	mem 40.099
Train: [47][400/750]	BT 0.172 (1.172)	DT 0.006 (1.041)	loss nan (nan)	prob nan (nan)	GS 34.062 (34.062)	mem 40.100
Train: [47][405/750]	BT 0.162 (1.189)	DT 0.001 (1.059)	loss nan (nan)	prob nan (nan)	GS 33.312 (33.312)	mem 39.995
Train: [47][410/750]	BT 0.124 (1.176)	DT 0.009 (1.046)	loss nan (nan)	prob nan (nan)	GS 30.047 (30.047)	mem 40.011
Train: [47][415/750]	BT 0.208 (1.167)	DT 0.017 (1.037)	loss nan (nan)	prob nan (nan)	GS 30.797 (30.797)	mem 40.235
Train: [47][420/750]	BT 0.217 (1.177)	DT 0.002 (1.047)	loss nan (nan)	prob nan (nan)	GS 32.016 (32.016)	mem 40.171
Train: [47][425/750]	BT 0.093 (1.178)	DT 0.002 (1.048)	loss nan (nan)	prob nan (nan)	GS 31.578 (31.578)	mem 40.022
Train: [47][430/750]	BT 0.112 (1.175)	DT 0.001 (1.045)	loss nan (nan)	prob nan (nan)	GS 31.828 (31.828)	mem 40.103
Train: [47][435/750]	BT 0.200 (1.162)	DT 0.002 (1.033)	loss nan (nan)	prob nan (nan)	GS 34.938 (34.938)	mem 40.064
Train: [47][440/750]	BT 2.919 (1.171)	DT 2.833 (1.041)	loss nan (nan)	prob nan (nan)	GS 34.891 (34.891)	mem 40.106
Train: [47][445/750]	BT 0.242 (1.165)	DT 0.006 (1.035)	loss nan (nan)	prob nan (nan)	GS 30.094 (30.094)	mem 40.005
Train: [47][450/750]	BT 0.171 (1.175)	DT 0.005 (1.045)	loss nan (nan)	prob nan (nan)	GS 35.312 (35.312)	mem 39.920
Train: [47][455/750]	BT 0.237 (1.164)	DT 0.005 (1.034)	loss nan (nan)	prob nan (nan)	GS 29.906 (29.906)	mem 39.920
Train: [47][460/750]	BT 9.724 (1.174)	DT 9.568 (1.044)	loss nan (nan)	prob nan (nan)	GS 29.234 (29.234)	mem 39.955
Train: [47][465/750]	BT 0.088 (1.166)	DT 0.002 (1.035)	loss nan (nan)	prob nan (nan)	GS 33.031 (33.031)	mem 39.928
Train: [47][470/750]	BT 0.130 (1.160)	DT 0.005 (1.029)	loss nan (nan)	prob nan (nan)	GS 37.094 (37.094)	mem 40.004
Train: [47][475/750]	BT 0.136 (1.166)	DT 0.013 (1.035)	loss nan (nan)	prob nan (nan)	GS 32.938 (32.938)	mem 40.068
Train: [47][480/750]	BT 0.114 (1.166)	DT 0.001 (1.035)	loss nan (nan)	prob nan (nan)	GS 33.516 (33.516)	mem 40.013
Train: [47][485/750]	BT 0.108 (1.161)	DT 0.002 (1.029)	loss nan (nan)	prob nan (nan)	GS 37.484 (37.484)	mem 40.063
Train: [47][490/750]	BT 5.736 (1.167)	DT 5.626 (1.036)	loss nan (nan)	prob nan (nan)	GS 33.781 (33.781)	mem 40.093
Train: [47][495/750]	BT 0.123 (1.157)	DT 0.001 (1.026)	loss nan (nan)	prob nan (nan)	GS 30.016 (30.016)	mem 40.135
Train: [47][500/750]	BT 0.085 (1.163)	DT 0.001 (1.032)	loss nan (nan)	prob nan (nan)	GS 34.156 (34.156)	mem 40.045
Train: [47][505/750]	BT 0.144 (1.159)	DT 0.001 (1.028)	loss nan (nan)	prob nan (nan)	GS 32.000 (32.000)	mem 40.076
Train: [47][510/750]	BT 6.896 (1.172)	DT 6.804 (1.041)	loss nan (nan)	prob nan (nan)	GS 35.156 (35.156)	mem 40.097
Train: [47][515/750]	BT 0.125 (1.162)	DT 0.001 (1.031)	loss nan (nan)	prob nan (nan)	GS 31.781 (31.781)	mem 40.403
Train: [47][520/750]	BT 3.987 (1.160)	DT 3.781 (1.029)	loss nan (nan)	prob nan (nan)	GS 34.781 (34.781)	mem 40.057
Train: [47][525/750]	BT 0.129 (1.164)	DT 0.007 (1.032)	loss nan (nan)	prob nan (nan)	GS 35.312 (35.312)	mem 40.350
Train: [47][530/750]	BT 0.084 (1.159)	DT 0.001 (1.028)	loss nan (nan)	prob nan (nan)	GS 35.109 (35.109)	mem 40.173
Train: [47][535/750]	BT 0.194 (1.162)	DT 0.004 (1.030)	loss nan (nan)	prob nan (nan)	GS 33.641 (33.641)	mem 40.094
Train: [47][540/750]	BT 0.137 (1.166)	DT 0.012 (1.034)	loss nan (nan)	prob nan (nan)	GS 29.859 (29.859)	mem 40.129
Train: [47][545/750]	BT 0.134 (1.160)	DT 0.009 (1.028)	loss nan (nan)	prob nan (nan)	GS 29.953 (29.953)	mem 40.224
Train: [47][550/750]	BT 7.902 (1.170)	DT 7.776 (1.038)	loss nan (nan)	prob nan (nan)	GS 33.406 (33.406)	mem 40.129
Train: [47][555/750]	BT 0.096 (1.160)	DT 0.009 (1.028)	loss nan (nan)	prob nan (nan)	GS 28.188 (28.188)	mem 40.024
Train: [47][560/750]	BT 2.911 (1.159)	DT 2.678 (1.027)	loss nan (nan)	prob nan (nan)	GS 33.047 (33.047)	mem 40.254
Train: [47][565/750]	BT 0.095 (1.162)	DT 0.002 (1.030)	loss nan (nan)	prob nan (nan)	GS 32.953 (32.953)	mem 39.997
Train: [47][570/750]	BT 2.241 (1.158)	DT 2.052 (1.025)	loss nan (nan)	prob nan (nan)	GS 35.203 (35.203)	mem 40.252
Train: [47][575/750]	BT 0.079 (1.164)	DT 0.001 (1.032)	loss nan (nan)	prob nan (nan)	GS 32.625 (32.625)	mem 39.952
Train: [47][580/750]	BT 0.100 (1.156)	DT 0.002 (1.023)	loss nan (nan)	prob nan (nan)	GS 35.734 (35.734)	mem 40.050
Train: [47][585/750]	BT 0.093 (1.151)	DT 0.006 (1.019)	loss nan (nan)	prob nan (nan)	GS 29.828 (29.828)	mem 39.954
Train: [47][590/750]	BT 0.213 (1.159)	DT 0.003 (1.027)	loss nan (nan)	prob nan (nan)	GS 33.047 (33.047)	mem 39.990
Train: [47][595/750]	BT 0.210 (1.150)	DT 0.004 (1.018)	loss nan (nan)	prob nan (nan)	GS 26.938 (26.938)	mem 40.161
Train: [47][600/750]	BT 0.163 (1.161)	DT 0.001 (1.029)	loss nan (nan)	prob nan (nan)	GS 38.938 (38.938)	mem 39.995
Train: [47][605/750]	BT 0.167 (1.153)	DT 0.001 (1.021)	loss nan (nan)	prob nan (nan)	GS 32.078 (32.078)	mem 40.033
Train: [47][610/750]	BT 4.445 (1.167)	DT 4.299 (1.034)	loss nan (nan)	prob nan (nan)	GS 38.266 (38.266)	mem 39.959
Train: [47][615/750]	BT 0.129 (1.158)	DT 0.003 (1.026)	loss nan (nan)	prob nan (nan)	GS 30.359 (30.359)	mem 40.059
Train: [47][620/750]	BT 4.775 (1.157)	DT 4.660 (1.025)	loss nan (nan)	prob nan (nan)	GS 33.344 (33.344)	mem 40.083
Train: [47][625/750]	BT 0.100 (1.159)	DT 0.001 (1.027)	loss nan (nan)	prob nan (nan)	GS 35.234 (35.234)	mem 40.064
Train: [47][630/750]	BT 0.120 (1.151)	DT 0.005 (1.019)	loss nan (nan)	prob nan (nan)	GS 32.984 (32.984)	mem 40.071
Train: [47][635/750]	BT 0.110 (1.166)	DT 0.001 (1.034)	loss nan (nan)	prob nan (nan)	GS 34.500 (34.500)	mem 40.036
Train: [47][640/750]	BT 0.073 (1.157)	DT 0.001 (1.026)	loss nan (nan)	prob nan (nan)	GS 31.203 (31.203)	mem 39.977
Train: [47][645/750]	BT 0.224 (1.150)	DT 0.004 (1.018)	loss nan (nan)	prob nan (nan)	GS 33.969 (33.969)	mem 40.017
Train: [47][650/750]	BT 0.118 (1.161)	DT 0.001 (1.029)	loss nan (nan)	prob nan (nan)	GS 33.906 (33.906)	mem 39.997
Train: [47][655/750]	BT 0.087 (1.153)	DT 0.002 (1.021)	loss nan (nan)	prob nan (nan)	GS 29.922 (29.922)	mem 40.006
Train: [47][660/750]	BT 0.119 (1.159)	DT 0.001 (1.028)	loss nan (nan)	prob nan (nan)	GS 34.562 (34.562)	mem 40.125
Train: [47][665/750]	BT 0.167 (1.151)	DT 0.012 (1.020)	loss nan (nan)	prob nan (nan)	GS 34.859 (34.859)	mem 40.056
Train: [47][670/750]	BT 8.224 (1.166)	DT 8.134 (1.035)	loss nan (nan)	prob nan (nan)	GS 33.516 (33.516)	mem 40.027
Train: [47][675/750]	BT 0.097 (1.158)	DT 0.001 (1.027)	loss nan (nan)	prob nan (nan)	GS 31.234 (31.234)	mem 39.987
Train: [47][680/750]	BT 3.451 (1.155)	DT 3.285 (1.024)	loss nan (nan)	prob nan (nan)	GS 36.172 (36.172)	mem 40.030
Train: [47][685/750]	BT 0.138 (1.164)	DT 0.001 (1.034)	loss nan (nan)	prob nan (nan)	GS 30.594 (30.594)	mem 39.879
Train: [47][690/750]	BT 0.061 (1.156)	DT 0.001 (1.026)	loss nan (nan)	prob nan (nan)	GS 33.609 (33.609)	mem 39.925
Train: [47][695/750]	BT 0.076 (1.164)	DT 0.002 (1.035)	loss nan (nan)	prob nan (nan)	GS 31.469 (31.469)	mem 39.995
Train: [47][700/750]	BT 0.130 (1.157)	DT 0.001 (1.027)	loss nan (nan)	prob nan (nan)	GS 32.922 (32.922)	mem 40.025
Train: [47][705/750]	BT 0.093 (1.150)	DT 0.002 (1.020)	loss nan (nan)	prob nan (nan)	GS 32.375 (32.375)	mem 40.046
arpack error, retry= 0
Train: [47][710/750]	BT 0.067 (1.159)	DT 0.001 (1.030)	loss nan (nan)	prob nan (nan)	GS 29.719 (29.719)	mem 40.130
Train: [47][715/750]	BT 0.077 (1.152)	DT 0.002 (1.022)	loss nan (nan)	prob nan (nan)	GS 30.344 (30.344)	mem 40.006
Train: [47][720/750]	BT 0.083 (1.161)	DT 0.002 (1.031)	loss nan (nan)	prob nan (nan)	GS 34.766 (34.766)	mem 40.091
Train: [47][725/750]	BT 0.307 (1.154)	DT 0.004 (1.024)	loss nan (nan)	prob nan (nan)	GS 29.859 (29.859)	mem 40.092
Train: [47][730/750]	BT 8.229 (1.158)	DT 8.149 (1.028)	loss nan (nan)	prob nan (nan)	GS 34.000 (34.000)	mem 39.433
Train: [47][735/750]	BT 0.079 (1.151)	DT 0.001 (1.021)	loss nan (nan)	prob nan (nan)	GS 30.844 (30.844)	mem 39.440
Train: [47][740/750]	BT 1.628 (1.146)	DT 1.530 (1.017)	loss nan (nan)	prob nan (nan)	GS 31.781 (31.781)	mem 16.651
Train: [47][745/750]	BT 0.050 (1.146)	DT 0.001 (1.017)	loss nan (nan)	prob nan (nan)	GS 31.844 (31.844)	mem 7.705
Train: [47][750/750]	BT 0.060 (1.139)	DT 0.001 (1.011)	loss nan (nan)	prob nan (nan)	GS 30.688 (30.688)	mem 7.705
Train: [47][755/750]	BT 0.085 (1.134)	DT 0.001 (1.006)	loss nan (nan)	prob nan (nan)	GS 33.469 (33.469)	mem 7.669
epoch 47, total time 856.54
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [48][1/750]	BT 21.721 (21.721)	DT 21.551 (21.551)	loss nan (nan)	prob nan (nan)	GS 32.203 (32.203)	mem 38.631
Train: [48][5/750]	BT 0.212 (5.375)	DT 0.003 (5.186)	loss nan (nan)	prob nan (nan)	GS 31.906 (31.906)	mem 38.781
Train: [48][10/750]	BT 0.153 (2.777)	DT 0.004 (2.601)	loss nan (nan)	prob nan (nan)	GS 36.844 (36.844)	mem 38.782
Train: [48][15/750]	BT 0.088 (2.126)	DT 0.002 (1.963)	loss nan (nan)	prob nan (nan)	GS 32.500 (32.500)	mem 39.038
Train: [48][20/750]	BT 0.110 (2.040)	DT 0.002 (1.880)	loss nan (nan)	prob nan (nan)	GS 32.266 (32.266)	mem 39.030
Train: [48][25/750]	BT 0.098 (1.661)	DT 0.001 (1.507)	loss nan (nan)	prob nan (nan)	GS 29.984 (29.984)	mem 38.975
Train: [48][30/750]	BT 0.117 (1.898)	DT 0.001 (1.743)	loss nan (nan)	prob nan (nan)	GS 35.703 (35.703)	mem 38.991
Train: [48][35/750]	BT 0.116 (1.649)	DT 0.009 (1.496)	loss nan (nan)	prob nan (nan)	GS 28.234 (28.234)	mem 39.000
Train: [48][40/750]	BT 9.517 (1.732)	DT 9.419 (1.584)	loss nan (nan)	prob nan (nan)	GS 36.141 (36.141)	mem 39.141
Train: [48][45/750]	BT 0.165 (1.554)	DT 0.003 (1.409)	loss nan (nan)	prob nan (nan)	GS 30.391 (30.391)	mem 39.075
Train: [48][50/750]	BT 1.157 (1.460)	DT 1.052 (1.314)	loss nan (nan)	prob nan (nan)	GS 34.875 (34.875)	mem 39.106
Train: [48][55/750]	BT 0.094 (1.490)	DT 0.002 (1.348)	loss nan (nan)	prob nan (nan)	GS 30.094 (30.094)	mem 39.053
Train: [48][60/750]	BT 2.398 (1.422)	DT 2.174 (1.278)	loss nan (nan)	prob nan (nan)	GS 30.688 (30.688)	mem 39.048
Train: [48][65/750]	BT 0.067 (1.460)	DT 0.001 (1.317)	loss nan (nan)	prob nan (nan)	GS 30.875 (30.875)	mem 39.109
Train: [48][70/750]	BT 0.235 (1.365)	DT 0.002 (1.223)	loss nan (nan)	prob nan (nan)	GS 37.422 (37.422)	mem 39.170
Train: [48][75/750]	BT 0.202 (1.383)	DT 0.002 (1.239)	loss nan (nan)	prob nan (nan)	GS 35.797 (35.797)	mem 39.364
Train: [48][80/750]	BT 0.093 (1.341)	DT 0.002 (1.200)	loss nan (nan)	prob nan (nan)	GS 32.609 (32.609)	mem 39.197
Train: [48][85/750]	BT 0.105 (1.306)	DT 0.014 (1.167)	loss nan (nan)	prob nan (nan)	GS 35.484 (35.484)	mem 39.163
Train: [48][90/750]	BT 0.137 (1.382)	DT 0.001 (1.244)	loss nan (nan)	prob nan (nan)	GS 39.078 (39.078)	mem 39.265
Train: [48][95/750]	BT 0.119 (1.314)	DT 0.001 (1.179)	loss nan (nan)	prob nan (nan)	GS 28.797 (28.797)	mem 39.160
Train: [48][100/750]	BT 4.263 (1.364)	DT 4.159 (1.229)	loss nan (nan)	prob nan (nan)	GS 34.844 (34.844)	mem 39.195
Train: [48][105/750]	BT 0.317 (1.308)	DT 0.003 (1.171)	loss nan (nan)	prob nan (nan)	GS 32.156 (32.156)	mem 39.198
Train: [48][110/750]	BT 10.811 (1.352)	DT 10.593 (1.214)	loss nan (nan)	prob nan (nan)	GS 36.656 (36.656)	mem 39.229
Train: [48][115/750]	BT 0.093 (1.325)	DT 0.003 (1.187)	loss nan (nan)	prob nan (nan)	GS 33.500 (33.500)	mem 39.565
Train: [48][120/750]	BT 0.206 (1.276)	DT 0.002 (1.138)	loss nan (nan)	prob nan (nan)	GS 33.109 (33.109)	mem 39.559
Train: [48][125/750]	BT 0.125 (1.327)	DT 0.002 (1.189)	loss nan (nan)	prob nan (nan)	GS 32.516 (32.516)	mem 39.430
Train: [48][130/750]	BT 0.087 (1.280)	DT 0.002 (1.144)	loss nan (nan)	prob nan (nan)	GS 33.125 (33.125)	mem 39.429
Train: [48][135/750]	BT 0.165 (1.313)	DT 0.001 (1.178)	loss nan (nan)	prob nan (nan)	GS 31.172 (31.172)	mem 39.440
Train: [48][140/750]	BT 0.088 (1.279)	DT 0.004 (1.142)	loss nan (nan)	prob nan (nan)	GS 31.906 (31.906)	mem 39.495
Train: [48][145/750]	BT 0.148 (1.240)	DT 0.018 (1.103)	loss nan (nan)	prob nan (nan)	GS 33.312 (33.312)	mem 39.494
Train: [48][150/750]	BT 0.148 (1.276)	DT 0.002 (1.139)	loss nan (nan)	prob nan (nan)	GS 33.078 (33.078)	mem 39.800
Train: [48][155/750]	BT 0.114 (1.241)	DT 0.002 (1.104)	loss nan (nan)	prob nan (nan)	GS 33.875 (33.875)	mem 39.744
Train: [48][160/750]	BT 1.865 (1.290)	DT 1.772 (1.153)	loss nan (nan)	prob nan (nan)	GS 33.688 (33.688)	mem 40.150
Train: [48][165/750]	BT 0.119 (1.254)	DT 0.001 (1.118)	loss nan (nan)	prob nan (nan)	GS 31.984 (31.984)	mem 39.959
Train: [48][170/750]	BT 8.024 (1.268)	DT 7.936 (1.132)	loss nan (nan)	prob nan (nan)	GS 30.812 (30.812)	mem 39.893
Train: [48][175/750]	BT 0.116 (1.246)	DT 0.006 (1.111)	loss nan (nan)	prob nan (nan)	GS 30.047 (30.047)	mem 39.914
Train: [48][180/750]	BT 0.126 (1.230)	DT 0.002 (1.095)	loss nan (nan)	prob nan (nan)	GS 32.547 (32.547)	mem 39.847
Train: [48][185/750]	BT 0.072 (1.263)	DT 0.001 (1.129)	loss nan (nan)	prob nan (nan)	GS 28.500 (28.500)	mem 39.846
Train: [48][190/750]	BT 0.239 (1.234)	DT 0.145 (1.100)	loss nan (nan)	prob nan (nan)	GS 32.250 (32.250)	mem 39.958
Train: [48][195/750]	BT 0.120 (1.256)	DT 0.006 (1.122)	loss nan (nan)	prob nan (nan)	GS 26.578 (26.578)	mem 39.825
Train: [48][200/750]	BT 0.111 (1.227)	DT 0.005 (1.094)	loss nan (nan)	prob nan (nan)	GS 39.703 (39.703)	mem 39.841
Train: [48][205/750]	BT 0.111 (1.208)	DT 0.001 (1.074)	loss nan (nan)	prob nan (nan)	GS 29.969 (29.969)	mem 39.920
Train: [48][210/750]	BT 0.172 (1.231)	DT 0.004 (1.097)	loss nan (nan)	prob nan (nan)	GS 31.688 (31.688)	mem 39.902
Train: [48][215/750]	BT 0.166 (1.210)	DT 0.002 (1.076)	loss nan (nan)	prob nan (nan)	GS 32.297 (32.297)	mem 39.845
Train: [48][220/750]	BT 1.203 (1.233)	DT 1.065 (1.100)	loss nan (nan)	prob nan (nan)	GS 35.750 (35.750)	mem 39.894
Train: [48][225/750]	BT 0.082 (1.208)	DT 0.001 (1.076)	loss nan (nan)	prob nan (nan)	GS 30.453 (30.453)	mem 39.895
Train: [48][230/750]	BT 13.615 (1.243)	DT 13.480 (1.111)	loss nan (nan)	prob nan (nan)	GS 35.203 (35.203)	mem 39.816
Train: [48][235/750]	BT 0.107 (1.224)	DT 0.011 (1.092)	loss nan (nan)	prob nan (nan)	GS 30.391 (30.391)	mem 40.185
Train: [48][240/750]	BT 0.095 (1.200)	DT 0.008 (1.070)	loss nan (nan)	prob nan (nan)	GS 35.406 (35.406)	mem 39.870
Train: [48][245/750]	BT 0.108 (1.229)	DT 0.003 (1.098)	loss nan (nan)	prob nan (nan)	GS 42.078 (42.078)	mem 39.908
Train: [48][250/750]	BT 0.087 (1.207)	DT 0.002 (1.076)	loss nan (nan)	prob nan (nan)	GS 31.156 (31.156)	mem 39.909
Train: [48][255/750]	BT 0.130 (1.214)	DT 0.009 (1.083)	loss nan (nan)	prob nan (nan)	GS 29.234 (29.234)	mem 39.908
Train: [48][260/750]	BT 0.136 (1.216)	DT 0.001 (1.085)	loss nan (nan)	prob nan (nan)	GS 36.531 (36.531)	mem 39.884
Train: [48][265/750]	BT 0.102 (1.195)	DT 0.002 (1.064)	loss nan (nan)	prob nan (nan)	GS 30.766 (30.766)	mem 39.903
Train: [48][270/750]	BT 0.075 (1.215)	DT 0.001 (1.084)	loss nan (nan)	prob nan (nan)	GS 36.547 (36.547)	mem 39.989
Train: [48][275/750]	BT 0.099 (1.195)	DT 0.001 (1.064)	loss nan (nan)	prob nan (nan)	GS 31.422 (31.422)	mem 39.960
Train: [48][280/750]	BT 9.871 (1.224)	DT 9.790 (1.094)	loss nan (nan)	prob nan (nan)	GS 36.312 (36.312)	mem 39.902
Train: [48][285/750]	BT 0.095 (1.205)	DT 0.002 (1.074)	loss nan (nan)	prob nan (nan)	GS 29.406 (29.406)	mem 39.922
Train: [48][290/750]	BT 0.157 (1.187)	DT 0.008 (1.056)	loss nan (nan)	prob nan (nan)	GS 33.906 (33.906)	mem 39.979
Train: [48][295/750]	BT 0.111 (1.219)	DT 0.002 (1.089)	loss nan (nan)	prob nan (nan)	GS 29.781 (29.781)	mem 39.872
Train: [48][300/750]	BT 0.110 (1.201)	DT 0.006 (1.071)	loss nan (nan)	prob nan (nan)	GS 33.375 (33.375)	mem 39.920
Train: [48][305/750]	BT 0.077 (1.226)	DT 0.001 (1.096)	loss nan (nan)	prob nan (nan)	GS 29.469 (29.469)	mem 39.858
Train: [48][310/750]	BT 0.194 (1.208)	DT 0.054 (1.079)	loss nan (nan)	prob nan (nan)	GS 34.453 (34.453)	mem 39.861
Train: [48][315/750]	BT 0.183 (1.191)	DT 0.001 (1.062)	loss nan (nan)	prob nan (nan)	GS 35.391 (35.391)	mem 39.880
Train: [48][320/750]	BT 0.109 (1.212)	DT 0.001 (1.083)	loss nan (nan)	prob nan (nan)	GS 30.141 (30.141)	mem 39.918
Train: [48][325/750]	BT 0.138 (1.195)	DT 0.002 (1.067)	loss nan (nan)	prob nan (nan)	GS 28.922 (28.922)	mem 40.146
Train: [48][330/750]	BT 0.113 (1.214)	DT 0.001 (1.085)	loss nan (nan)	prob nan (nan)	GS 34.562 (34.562)	mem 39.945
Train: [48][335/750]	BT 0.112 (1.197)	DT 0.002 (1.069)	loss nan (nan)	prob nan (nan)	GS 27.000 (27.000)	mem 39.971
Train: [48][340/750]	BT 13.810 (1.222)	DT 13.723 (1.093)	loss nan (nan)	prob nan (nan)	GS 38.438 (38.438)	mem 39.898
Train: [48][345/750]	BT 0.167 (1.206)	DT 0.001 (1.078)	loss nan (nan)	prob nan (nan)	GS 28.453 (28.453)	mem 40.010
Train: [48][350/750]	BT 0.145 (1.191)	DT 0.001 (1.062)	loss nan (nan)	prob nan (nan)	GS 32.016 (32.016)	mem 39.869
Train: [48][355/750]	BT 0.121 (1.209)	DT 0.002 (1.081)	loss nan (nan)	prob nan (nan)	GS 31.766 (31.766)	mem 39.956
Train: [48][360/750]	BT 0.101 (1.194)	DT 0.007 (1.066)	loss nan (nan)	prob nan (nan)	GS 35.344 (35.344)	mem 39.937
Train: [48][365/750]	BT 0.138 (1.198)	DT 0.001 (1.069)	loss nan (nan)	prob nan (nan)	GS 32.609 (32.609)	mem 39.930
Train: [48][370/750]	BT 0.111 (1.184)	DT 0.018 (1.055)	loss nan (nan)	prob nan (nan)	GS 30.766 (30.766)	mem 39.958
Train: [48][375/750]	BT 0.213 (1.170)	DT 0.002 (1.041)	loss nan (nan)	prob nan (nan)	GS 32.922 (32.922)	mem 40.108
Train: [48][380/750]	BT 0.065 (1.188)	DT 0.001 (1.059)	loss nan (nan)	prob nan (nan)	GS 32.812 (32.812)	mem 39.980
Train: [48][385/750]	BT 0.158 (1.174)	DT 0.002 (1.045)	loss nan (nan)	prob nan (nan)	GS 22.797 (22.797)	mem 40.015
Train: [48][390/750]	BT 0.073 (1.188)	DT 0.001 (1.059)	loss nan (nan)	prob nan (nan)	GS 33.484 (33.484)	mem 39.968
Train: [48][395/750]	BT 0.155 (1.174)	DT 0.012 (1.045)	loss nan (nan)	prob nan (nan)	GS 30.000 (30.000)	mem 39.976
Train: [48][400/750]	BT 13.455 (1.195)	DT 13.351 (1.066)	loss nan (nan)	prob nan (nan)	GS 33.078 (33.078)	mem 40.043
Train: [48][405/750]	BT 0.096 (1.182)	DT 0.010 (1.053)	loss nan (nan)	prob nan (nan)	GS 26.922 (26.922)	mem 40.047
Train: [48][410/750]	BT 0.192 (1.169)	DT 0.025 (1.040)	loss nan (nan)	prob nan (nan)	GS 29.062 (29.062)	mem 40.119
Train: [48][415/750]	BT 0.079 (1.190)	DT 0.001 (1.061)	loss nan (nan)	prob nan (nan)	GS 27.484 (27.484)	mem 39.955
Train: [48][420/750]	BT 0.091 (1.177)	DT 0.002 (1.048)	loss nan (nan)	prob nan (nan)	GS 29.750 (29.750)	mem 40.043
Train: [48][425/750]	BT 0.079 (1.200)	DT 0.001 (1.072)	loss nan (nan)	prob nan (nan)	GS 32.500 (32.500)	mem 39.972
Train: [48][430/750]	BT 0.073 (1.187)	DT 0.002 (1.059)	loss nan (nan)	prob nan (nan)	GS 33.953 (33.953)	mem 39.973
Train: [48][435/750]	BT 0.084 (1.175)	DT 0.002 (1.047)	loss nan (nan)	prob nan (nan)	GS 30.734 (30.734)	mem 39.976
Train: [48][440/750]	BT 0.088 (1.192)	DT 0.001 (1.064)	loss nan (nan)	prob nan (nan)	GS 32.156 (32.156)	mem 40.085
Train: [48][445/750]	BT 0.164 (1.180)	DT 0.003 (1.052)	loss nan (nan)	prob nan (nan)	GS 31.578 (31.578)	mem 40.204
Train: [48][450/750]	BT 0.103 (1.197)	DT 0.001 (1.069)	loss nan (nan)	prob nan (nan)	GS 33.047 (33.047)	mem 40.116
Train: [48][455/750]	BT 0.127 (1.185)	DT 0.002 (1.057)	loss nan (nan)	prob nan (nan)	GS 30.406 (30.406)	mem 40.078
Train: [48][460/750]	BT 10.420 (1.196)	DT 10.280 (1.068)	loss nan (nan)	prob nan (nan)	GS 29.391 (29.391)	mem 40.032
Train: [48][465/750]	BT 0.150 (1.184)	DT 0.002 (1.056)	loss nan (nan)	prob nan (nan)	GS 33.516 (33.516)	mem 40.173
Train: [48][470/750]	BT 0.213 (1.174)	DT 0.002 (1.045)	loss nan (nan)	prob nan (nan)	GS 33.078 (33.078)	mem 40.300
Train: [48][475/750]	BT 0.122 (1.186)	DT 0.001 (1.057)	loss nan (nan)	prob nan (nan)	GS 28.438 (28.438)	mem 40.081
Train: [48][480/750]	BT 0.091 (1.175)	DT 0.007 (1.047)	loss nan (nan)	prob nan (nan)	GS 31.578 (31.578)	mem 40.060
Train: [48][485/750]	BT 0.080 (1.192)	DT 0.002 (1.064)	loss nan (nan)	prob nan (nan)	GS 26.125 (26.125)	mem 40.122
Train: [48][490/750]	BT 0.090 (1.181)	DT 0.002 (1.053)	loss nan (nan)	prob nan (nan)	GS 37.219 (37.219)	mem 40.123
Train: [48][495/750]	BT 0.148 (1.171)	DT 0.001 (1.043)	loss nan (nan)	prob nan (nan)	GS 33.125 (33.125)	mem 40.140
Train: [48][500/750]	BT 0.073 (1.190)	DT 0.002 (1.063)	loss nan (nan)	prob nan (nan)	GS 40.078 (40.078)	mem 40.055
Train: [48][505/750]	BT 0.089 (1.180)	DT 0.002 (1.052)	loss nan (nan)	prob nan (nan)	GS 33.125 (33.125)	mem 39.985
Train: [48][510/750]	BT 0.123 (1.192)	DT 0.002 (1.065)	loss nan (nan)	prob nan (nan)	GS 32.922 (32.922)	mem 40.094
Train: [48][515/750]	BT 0.123 (1.181)	DT 0.001 (1.055)	loss nan (nan)	prob nan (nan)	GS 31.219 (31.219)	mem 40.108
Train: [48][520/750]	BT 11.018 (1.193)	DT 10.875 (1.066)	loss nan (nan)	prob nan (nan)	GS 33.406 (33.406)	mem 40.394
Train: [48][525/750]	BT 0.194 (1.182)	DT 0.020 (1.056)	loss nan (nan)	prob nan (nan)	GS 28.797 (28.797)	mem 40.125
Train: [48][530/750]	BT 0.281 (1.173)	DT 0.064 (1.046)	loss nan (nan)	prob nan (nan)	GS 35.391 (35.391)	mem 40.181
Train: [48][535/750]	BT 0.249 (1.184)	DT 0.021 (1.056)	loss nan (nan)	prob nan (nan)	GS 30.078 (30.078)	mem 40.174
Train: [48][540/750]	BT 0.100 (1.174)	DT 0.002 (1.047)	loss nan (nan)	prob nan (nan)	GS 29.156 (29.156)	mem 40.237
Train: [48][545/750]	BT 0.105 (1.182)	DT 0.007 (1.054)	loss nan (nan)	prob nan (nan)	GS 37.453 (37.453)	mem 40.066
Train: [48][550/750]	BT 0.282 (1.172)	DT 0.012 (1.045)	loss nan (nan)	prob nan (nan)	GS 28.359 (28.359)	mem 40.110
Train: [48][555/750]	BT 0.105 (1.163)	DT 0.004 (1.036)	loss nan (nan)	prob nan (nan)	GS 31.672 (31.672)	mem 40.078
Train: [48][560/750]	BT 0.136 (1.173)	DT 0.006 (1.046)	loss nan (nan)	prob nan (nan)	GS 36.484 (36.484)	mem 40.116
Train: [48][565/750]	BT 0.136 (1.164)	DT 0.002 (1.036)	loss nan (nan)	prob nan (nan)	GS 29.203 (29.203)	mem 40.034
Train: [48][570/750]	BT 0.092 (1.172)	DT 0.002 (1.045)	loss nan (nan)	prob nan (nan)	GS 36.781 (36.781)	mem 40.031
Train: [48][575/750]	BT 0.111 (1.163)	DT 0.009 (1.036)	loss nan (nan)	prob nan (nan)	GS 28.656 (28.656)	mem 40.037
Train: [48][580/750]	BT 7.001 (1.170)	DT 6.935 (1.043)	loss nan (nan)	prob nan (nan)	GS 32.469 (32.469)	mem 40.069
Train: [48][585/750]	BT 0.163 (1.161)	DT 0.010 (1.034)	loss nan (nan)	prob nan (nan)	GS 32.094 (32.094)	mem 40.072
Train: [48][590/750]	BT 0.087 (1.164)	DT 0.002 (1.035)	loss nan (nan)	prob nan (nan)	GS 34.234 (34.234)	mem 40.026
Train: [48][595/750]	BT 0.211 (1.163)	DT 0.002 (1.035)	loss nan (nan)	prob nan (nan)	GS 30.031 (30.031)	mem 40.134
Train: [48][600/750]	BT 4.317 (1.168)	DT 4.222 (1.040)	loss nan (nan)	prob nan (nan)	GS 34.766 (34.766)	mem 40.075
Train: [48][605/750]	BT 0.109 (1.163)	DT 0.001 (1.035)	loss nan (nan)	prob nan (nan)	GS 33.781 (33.781)	mem 39.965
Train: [48][610/750]	BT 0.091 (1.162)	DT 0.002 (1.034)	loss nan (nan)	prob nan (nan)	GS 36.203 (36.203)	mem 40.050
Train: [48][615/750]	BT 0.130 (1.163)	DT 0.001 (1.035)	loss nan (nan)	prob nan (nan)	GS 34.094 (34.094)	mem 40.110
Train: [48][620/750]	BT 0.098 (1.159)	DT 0.002 (1.031)	loss nan (nan)	prob nan (nan)	GS 29.641 (29.641)	mem 40.061
Train: [48][625/750]	BT 0.151 (1.169)	DT 0.002 (1.041)	loss nan (nan)	prob nan (nan)	GS 31.609 (31.609)	mem 40.007
Train: [48][630/750]	BT 1.041 (1.162)	DT 0.929 (1.034)	loss nan (nan)	prob nan (nan)	GS 35.281 (35.281)	mem 40.060
Train: [48][635/750]	BT 0.228 (1.154)	DT 0.042 (1.026)	loss nan (nan)	prob nan (nan)	GS 31.141 (31.141)	mem 40.065
Train: [48][640/750]	BT 0.089 (1.163)	DT 0.001 (1.035)	loss nan (nan)	prob nan (nan)	GS 34.844 (34.844)	mem 40.016
Train: [48][645/750]	BT 0.115 (1.157)	DT 0.015 (1.029)	loss nan (nan)	prob nan (nan)	GS 29.438 (29.438)	mem 40.100
Train: [48][650/750]	BT 0.089 (1.169)	DT 0.001 (1.041)	loss nan (nan)	prob nan (nan)	GS 36.734 (36.734)	mem 40.093
Train: [48][655/750]	BT 0.134 (1.161)	DT 0.007 (1.033)	loss nan (nan)	prob nan (nan)	GS 30.172 (30.172)	mem 40.128
Train: [48][660/750]	BT 14.804 (1.175)	DT 14.707 (1.047)	loss nan (nan)	prob nan (nan)	GS 34.125 (34.125)	mem 40.161
Train: [48][665/750]	BT 0.113 (1.167)	DT 0.001 (1.039)	loss nan (nan)	prob nan (nan)	GS 35.547 (35.547)	mem 40.034
Train: [48][670/750]	BT 0.127 (1.159)	DT 0.005 (1.031)	loss nan (nan)	prob nan (nan)	GS 33.406 (33.406)	mem 40.043
Train: [48][675/750]	BT 0.097 (1.169)	DT 0.001 (1.041)	loss nan (nan)	prob nan (nan)	GS 29.094 (29.094)	mem 40.073
Train: [48][680/750]	BT 0.097 (1.161)	DT 0.002 (1.034)	loss nan (nan)	prob nan (nan)	GS 33.484 (33.484)	mem 40.138
Train: [48][685/750]	BT 0.070 (1.172)	DT 0.001 (1.044)	loss nan (nan)	prob nan (nan)	GS 31.938 (31.938)	mem 40.110
Train: [48][690/750]	BT 0.116 (1.164)	DT 0.003 (1.037)	loss nan (nan)	prob nan (nan)	GS 31.656 (31.656)	mem 40.108
Train: [48][695/750]	BT 0.131 (1.157)	DT 0.005 (1.029)	loss nan (nan)	prob nan (nan)	GS 32.141 (32.141)	mem 40.151
Train: [48][700/750]	BT 0.085 (1.164)	DT 0.001 (1.036)	loss nan (nan)	prob nan (nan)	GS 33.031 (33.031)	mem 40.056
Train: [48][705/750]	BT 0.176 (1.156)	DT 0.001 (1.029)	loss nan (nan)	prob nan (nan)	GS 29.672 (29.672)	mem 40.153
Train: [48][710/750]	BT 0.078 (1.169)	DT 0.001 (1.042)	loss nan (nan)	prob nan (nan)	GS 30.609 (30.609)	mem 39.972
Train: [48][715/750]	BT 0.082 (1.161)	DT 0.001 (1.035)	loss nan (nan)	prob nan (nan)	GS 24.562 (24.562)	mem 40.000
Train: [48][720/750]	BT 12.614 (1.172)	DT 12.546 (1.045)	loss nan (nan)	prob nan (nan)	GS 33.812 (33.812)	mem 40.055
Train: [48][725/750]	BT 0.079 (1.164)	DT 0.001 (1.038)	loss nan (nan)	prob nan (nan)	GS 34.844 (34.844)	mem 40.058
Train: [48][730/750]	BT 0.182 (1.157)	DT 0.005 (1.031)	loss nan (nan)	prob nan (nan)	GS 33.938 (33.938)	mem 40.091
Train: [48][735/750]	BT 0.081 (1.162)	DT 0.001 (1.036)	loss nan (nan)	prob nan (nan)	GS 33.875 (33.875)	mem 39.353
Train: [48][740/750]	BT 0.091 (1.155)	DT 0.001 (1.029)	loss nan (nan)	prob nan (nan)	GS 33.719 (33.719)	mem 39.315
Train: [48][745/750]	BT 0.063 (1.154)	DT 0.001 (1.028)	loss nan (nan)	prob nan (nan)	GS 35.906 (35.906)	mem 7.730
Train: [48][750/750]	BT 0.076 (1.146)	DT 0.001 (1.021)	loss nan (nan)	prob nan (nan)	GS 35.719 (35.719)	mem 7.730
Train: [48][755/750]	BT 0.058 (1.139)	DT 0.001 (1.015)	loss nan (nan)	prob nan (nan)	GS 29.781 (29.781)	mem 7.730
epoch 48, total time 862.38
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [49][1/750]	BT 23.608 (23.608)	DT 23.396 (23.396)	loss nan (nan)	prob nan (nan)	GS 38.141 (38.141)	mem 38.726
Train: [49][5/750]	BT 0.088 (4.834)	DT 0.001 (4.682)	loss nan (nan)	prob nan (nan)	GS 31.906 (31.906)	mem 38.739
Train: [49][10/750]	BT 0.261 (2.496)	DT 0.002 (2.342)	loss nan (nan)	prob nan (nan)	GS 29.953 (29.953)	mem 38.741
Train: [49][15/750]	BT 0.302 (2.314)	DT 0.010 (2.154)	loss nan (nan)	prob nan (nan)	GS 30.031 (30.031)	mem 38.905
Train: [49][20/750]	BT 0.133 (1.764)	DT 0.002 (1.617)	loss nan (nan)	prob nan (nan)	GS 33.562 (33.562)	mem 38.946
Train: [49][25/750]	BT 7.216 (1.809)	DT 7.129 (1.667)	loss nan (nan)	prob nan (nan)	GS 29.500 (29.500)	mem 39.159
Train: [49][30/750]	BT 0.209 (1.689)	DT 0.004 (1.550)	loss nan (nan)	prob nan (nan)	GS 36.656 (36.656)	mem 39.059
Train: [49][35/750]	BT 0.140 (1.466)	DT 0.017 (1.330)	loss nan (nan)	prob nan (nan)	GS 36.047 (36.047)	mem 38.965
Train: [49][40/750]	BT 0.104 (1.712)	DT 0.001 (1.577)	loss nan (nan)	prob nan (nan)	GS 29.172 (29.172)	mem 39.438
Train: [49][45/750]	BT 0.145 (1.538)	DT 0.002 (1.402)	loss nan (nan)	prob nan (nan)	GS 28.250 (28.250)	mem 39.504
Train: [49][50/750]	BT 13.151 (1.661)	DT 13.066 (1.524)	loss nan (nan)	prob nan (nan)	GS 33.766 (33.766)	mem 39.649
Train: [49][55/750]	BT 0.087 (1.524)	DT 0.002 (1.385)	loss nan (nan)	prob nan (nan)	GS 28.953 (28.953)	mem 39.637
Train: [49][60/750]	BT 0.263 (1.411)	DT 0.009 (1.270)	loss nan (nan)	prob nan (nan)	GS 32.641 (32.641)	mem 39.678
Train: [49][65/750]	BT 0.238 (1.480)	DT 0.027 (1.337)	loss nan (nan)	prob nan (nan)	GS 29.047 (29.047)	mem 39.638
Train: [49][70/750]	BT 0.203 (1.385)	DT 0.026 (1.242)	loss nan (nan)	prob nan (nan)	GS 35.281 (35.281)	mem 39.641
Train: [49][75/750]	BT 0.145 (1.484)	DT 0.003 (1.341)	loss nan (nan)	prob nan (nan)	GS 30.406 (30.406)	mem 39.597
Train: [49][80/750]	BT 0.157 (1.400)	DT 0.004 (1.257)	loss nan (nan)	prob nan (nan)	GS 36.656 (36.656)	mem 39.611
Train: [49][85/750]	BT 0.088 (1.326)	DT 0.001 (1.184)	loss nan (nan)	prob nan (nan)	GS 49.203 (49.203)	mem 39.637
Train: [49][90/750]	BT 0.107 (1.392)	DT 0.001 (1.252)	loss nan (nan)	prob nan (nan)	GS 34.688 (34.688)	mem 39.616
Train: [49][95/750]	BT 0.103 (1.327)	DT 0.002 (1.186)	loss nan (nan)	prob nan (nan)	GS 29.734 (29.734)	mem 39.634
Train: [49][100/750]	BT 0.094 (1.390)	DT 0.001 (1.250)	loss nan (nan)	prob nan (nan)	GS 34.609 (34.609)	mem 39.748
Train: [49][105/750]	BT 0.115 (1.330)	DT 0.002 (1.190)	loss nan (nan)	prob nan (nan)	GS 28.719 (28.719)	mem 39.907
Train: [49][110/750]	BT 12.327 (1.387)	DT 12.195 (1.247)	loss nan (nan)	prob nan (nan)	GS 38.000 (38.000)	mem 39.733
Train: [49][115/750]	BT 0.145 (1.333)	DT 0.004 (1.193)	loss nan (nan)	prob nan (nan)	GS 30.078 (30.078)	mem 39.739
Train: [49][120/750]	BT 0.227 (1.284)	DT 0.033 (1.144)	loss nan (nan)	prob nan (nan)	GS 39.047 (39.047)	mem 39.935
Train: [49][125/750]	BT 0.156 (1.314)	DT 0.002 (1.176)	loss nan (nan)	prob nan (nan)	GS 30.328 (30.328)	mem 39.859
Train: [49][130/750]	BT 0.325 (1.270)	DT 0.014 (1.131)	loss nan (nan)	prob nan (nan)	GS 31.953 (31.953)	mem 39.911
Train: [49][135/750]	BT 0.095 (1.317)	DT 0.010 (1.179)	loss nan (nan)	prob nan (nan)	GS 27.828 (27.828)	mem 39.820
Train: [49][140/750]	BT 0.098 (1.273)	DT 0.002 (1.137)	loss nan (nan)	prob nan (nan)	GS 29.125 (29.125)	mem 39.815
Train: [49][145/750]	BT 0.119 (1.234)	DT 0.001 (1.098)	loss nan (nan)	prob nan (nan)	GS 29.875 (29.875)	mem 39.825
Train: [49][150/750]	BT 0.070 (1.289)	DT 0.001 (1.155)	loss nan (nan)	prob nan (nan)	GS 33.828 (33.828)	mem 39.815
Train: [49][155/750]	BT 0.203 (1.252)	DT 0.003 (1.118)	loss nan (nan)	prob nan (nan)	GS 33.234 (33.234)	mem 39.931
Train: [49][160/750]	BT 0.069 (1.308)	DT 0.001 (1.175)	loss nan (nan)	prob nan (nan)	GS 34.828 (34.828)	mem 39.949
Train: [49][165/750]	BT 0.153 (1.271)	DT 0.005 (1.139)	loss nan (nan)	prob nan (nan)	GS 37.609 (37.609)	mem 40.043
Train: [49][170/750]	BT 9.921 (1.296)	DT 9.762 (1.163)	loss nan (nan)	prob nan (nan)	GS 33.609 (33.609)	mem 39.967
Train: [49][175/750]	BT 0.116 (1.262)	DT 0.002 (1.130)	loss nan (nan)	prob nan (nan)	GS 37.266 (37.266)	mem 40.034
Train: [49][180/750]	BT 0.097 (1.230)	DT 0.001 (1.099)	loss nan (nan)	prob nan (nan)	GS 34.391 (34.391)	mem 39.861
Train: [49][185/750]	BT 0.102 (1.277)	DT 0.002 (1.146)	loss nan (nan)	prob nan (nan)	GS 33.250 (33.250)	mem 40.007
Train: [49][190/750]	BT 0.211 (1.247)	DT 0.006 (1.116)	loss nan (nan)	prob nan (nan)	GS 36.250 (36.250)	mem 40.197
Train: [49][195/750]	BT 0.157 (1.277)	DT 0.017 (1.145)	loss nan (nan)	prob nan (nan)	GS 32.641 (32.641)	mem 40.046
Train: [49][200/750]	BT 0.122 (1.249)	DT 0.006 (1.116)	loss nan (nan)	prob nan (nan)	GS 36.625 (36.625)	mem 40.049
Train: [49][205/750]	BT 0.090 (1.222)	DT 0.005 (1.089)	loss nan (nan)	prob nan (nan)	GS 30.891 (30.891)	mem 40.076
Train: [49][210/750]	BT 0.093 (1.244)	DT 0.001 (1.112)	loss nan (nan)	prob nan (nan)	GS 30.391 (30.391)	mem 40.141
Train: [49][215/750]	BT 0.242 (1.219)	DT 0.005 (1.086)	loss nan (nan)	prob nan (nan)	GS 30.969 (30.969)	mem 40.202
Train: [49][220/750]	BT 0.233 (1.243)	DT 0.008 (1.111)	loss nan (nan)	prob nan (nan)	GS 33.531 (33.531)	mem 40.116
Train: [49][225/750]	BT 0.179 (1.221)	DT 0.001 (1.088)	loss nan (nan)	prob nan (nan)	GS 31.562 (31.562)	mem 40.223
Train: [49][230/750]	BT 11.304 (1.246)	DT 11.208 (1.113)	loss nan (nan)	prob nan (nan)	GS 37.719 (37.719)	mem 40.205
Train: [49][235/750]	BT 0.060 (1.229)	DT 0.002 (1.096)	loss nan (nan)	prob nan (nan)	GS 33.109 (33.109)	mem 40.067
Train: [49][240/750]	BT 0.201 (1.206)	DT 0.009 (1.073)	loss nan (nan)	prob nan (nan)	GS 30.734 (30.734)	mem 39.936
Train: [49][245/750]	BT 0.143 (1.230)	DT 0.002 (1.098)	loss nan (nan)	prob nan (nan)	GS 32.188 (32.188)	mem 40.169
Train: [49][250/750]	BT 0.166 (1.208)	DT 0.001 (1.076)	loss nan (nan)	prob nan (nan)	GS 38.328 (38.328)	mem 40.003
Train: [49][255/750]	BT 0.153 (1.229)	DT 0.002 (1.097)	loss nan (nan)	prob nan (nan)	GS 35.328 (35.328)	mem 40.094
Train: [49][260/750]	BT 0.062 (1.216)	DT 0.001 (1.085)	loss nan (nan)	prob nan (nan)	GS 35.969 (35.969)	mem 40.193
Train: [49][265/750]	BT 0.120 (1.196)	DT 0.002 (1.065)	loss nan (nan)	prob nan (nan)	GS 34.016 (34.016)	mem 40.128
Train: [49][270/750]	BT 5.736 (1.230)	DT 5.552 (1.098)	loss nan (nan)	prob nan (nan)	GS 35.172 (35.172)	mem 39.904
Train: [49][275/750]	BT 0.260 (1.210)	DT 0.005 (1.078)	loss nan (nan)	prob nan (nan)	GS 42.062 (42.062)	mem 39.942
Train: [49][280/750]	BT 0.293 (1.211)	DT 0.002 (1.078)	loss nan (nan)	prob nan (nan)	GS 32.922 (32.922)	mem 40.006
Train: [49][285/750]	BT 0.096 (1.210)	DT 0.002 (1.077)	loss nan (nan)	prob nan (nan)	GS 31.484 (31.484)	mem 39.997
Train: [49][290/750]	BT 6.384 (1.213)	DT 6.209 (1.080)	loss nan (nan)	prob nan (nan)	GS 33.781 (33.781)	mem 40.009
Train: [49][295/750]	BT 0.117 (1.203)	DT 0.005 (1.069)	loss nan (nan)	prob nan (nan)	GS 34.250 (34.250)	mem 40.046
Train: [49][300/750]	BT 0.078 (1.184)	DT 0.002 (1.052)	loss nan (nan)	prob nan (nan)	GS 37.984 (37.984)	mem 40.104
Train: [49][305/750]	BT 0.125 (1.200)	DT 0.002 (1.067)	loss nan (nan)	prob nan (nan)	GS 30.203 (30.203)	mem 40.105
Train: [49][310/750]	BT 0.091 (1.201)	DT 0.003 (1.068)	loss nan (nan)	prob nan (nan)	GS 34.234 (34.234)	mem 40.068
Train: [49][315/750]	BT 0.084 (1.214)	DT 0.002 (1.082)	loss nan (nan)	prob nan (nan)	GS 32.500 (32.500)	mem 40.029
Train: [49][320/750]	BT 0.130 (1.214)	DT 0.002 (1.082)	loss nan (nan)	prob nan (nan)	GS 35.438 (35.438)	mem 40.096
Train: [49][325/750]	BT 0.106 (1.197)	DT 0.002 (1.065)	loss nan (nan)	prob nan (nan)	GS 30.906 (30.906)	mem 40.305
Train: [49][330/750]	BT 4.883 (1.215)	DT 4.745 (1.084)	loss nan (nan)	prob nan (nan)	GS 35.672 (35.672)	mem 40.256
Train: [49][335/750]	BT 0.108 (1.199)	DT 0.002 (1.068)	loss nan (nan)	prob nan (nan)	GS 29.750 (29.750)	mem 40.183
Train: [49][340/750]	BT 0.114 (1.208)	DT 0.002 (1.076)	loss nan (nan)	prob nan (nan)	GS 39.375 (39.375)	mem 40.069
Train: [49][345/750]	BT 0.151 (1.204)	DT 0.005 (1.072)	loss nan (nan)	prob nan (nan)	GS 31.641 (31.641)	mem 39.978
Train: [49][350/750]	BT 10.595 (1.219)	DT 10.481 (1.087)	loss nan (nan)	prob nan (nan)	GS 31.859 (31.859)	mem 40.078
Train: [49][355/750]	BT 0.103 (1.215)	DT 0.001 (1.083)	loss nan (nan)	prob nan (nan)	GS 35.625 (35.625)	mem 40.079
Train: [49][360/750]	BT 0.118 (1.200)	DT 0.017 (1.068)	loss nan (nan)	prob nan (nan)	GS 33.125 (33.125)	mem 39.929
Train: [49][365/750]	BT 0.131 (1.198)	DT 0.001 (1.066)	loss nan (nan)	prob nan (nan)	GS 30.219 (30.219)	mem 39.951
Train: [49][370/750]	BT 0.127 (1.203)	DT 0.002 (1.071)	loss nan (nan)	prob nan (nan)	GS 31.547 (31.547)	mem 40.232
Train: [49][375/750]	BT 0.084 (1.201)	DT 0.002 (1.069)	loss nan (nan)	prob nan (nan)	GS 30.781 (30.781)	mem 39.903
Train: [49][380/750]	BT 0.171 (1.203)	DT 0.001 (1.071)	loss nan (nan)	prob nan (nan)	GS 35.922 (35.922)	mem 39.919
Train: [49][385/750]	BT 0.079 (1.189)	DT 0.002 (1.057)	loss nan (nan)	prob nan (nan)	GS 34.859 (34.859)	mem 39.921
Train: [49][390/750]	BT 4.249 (1.204)	DT 4.072 (1.072)	loss nan (nan)	prob nan (nan)	GS 31.656 (31.656)	mem 39.907
Train: [49][395/750]	BT 0.125 (1.191)	DT 0.003 (1.059)	loss nan (nan)	prob nan (nan)	GS 34.109 (34.109)	mem 39.912
Train: [49][400/750]	BT 5.978 (1.193)	DT 5.862 (1.060)	loss nan (nan)	prob nan (nan)	GS 33.234 (33.234)	mem 39.988
Train: [49][405/750]	BT 0.125 (1.197)	DT 0.002 (1.065)	loss nan (nan)	prob nan (nan)	GS 32.047 (32.047)	mem 39.896
Train: [49][410/750]	BT 0.151 (1.184)	DT 0.001 (1.052)	loss nan (nan)	prob nan (nan)	GS 34.594 (34.594)	mem 40.023
Train: [49][415/750]	BT 0.144 (1.192)	DT 0.018 (1.060)	loss nan (nan)	prob nan (nan)	GS 35.703 (35.703)	mem 40.016
Train: [49][420/750]	BT 0.140 (1.180)	DT 0.004 (1.047)	loss nan (nan)	prob nan (nan)	GS 35.281 (35.281)	mem 40.149
Train: [49][425/750]	BT 0.185 (1.188)	DT 0.005 (1.056)	loss nan (nan)	prob nan (nan)	GS 31.875 (31.875)	mem 40.014
Train: [49][430/750]	BT 0.165 (1.183)	DT 0.023 (1.051)	loss nan (nan)	prob nan (nan)	GS 37.828 (37.828)	mem 40.475
Train: [49][435/750]	BT 0.118 (1.184)	DT 0.003 (1.051)	loss nan (nan)	prob nan (nan)	GS 34.703 (34.703)	mem 39.989
Train: [49][440/750]	BT 0.168 (1.191)	DT 0.001 (1.058)	loss nan (nan)	prob nan (nan)	GS 32.969 (32.969)	mem 39.953
Train: [49][445/750]	BT 0.161 (1.179)	DT 0.001 (1.046)	loss nan (nan)	prob nan (nan)	GS 35.094 (35.094)	mem 40.100
Train: [49][450/750]	BT 5.779 (1.193)	DT 5.665 (1.061)	loss nan (nan)	prob nan (nan)	GS 35.188 (35.188)	mem 40.203
Train: [49][455/750]	BT 0.074 (1.182)	DT 0.002 (1.049)	loss nan (nan)	prob nan (nan)	GS 28.234 (28.234)	mem 39.972
Train: [49][460/750]	BT 0.988 (1.184)	DT 0.799 (1.051)	loss nan (nan)	prob nan (nan)	GS 30.359 (30.359)	mem 40.008
Train: [49][465/750]	BT 0.140 (1.191)	DT 0.001 (1.059)	loss nan (nan)	prob nan (nan)	GS 24.750 (24.750)	mem 39.969
Train: [49][470/750]	BT 2.535 (1.185)	DT 2.426 (1.053)	loss nan (nan)	prob nan (nan)	GS 32.484 (32.484)	mem 40.015
Train: [49][475/750]	BT 0.095 (1.190)	DT 0.015 (1.057)	loss nan (nan)	prob nan (nan)	GS 26.953 (26.953)	mem 39.968
Train: [49][480/750]	BT 0.112 (1.178)	DT 0.002 (1.046)	loss nan (nan)	prob nan (nan)	GS 33.719 (33.719)	mem 39.972
Train: [49][485/750]	BT 0.172 (1.178)	DT 0.002 (1.046)	loss nan (nan)	prob nan (nan)	GS 34.297 (34.297)	mem 39.927
Train: [49][490/750]	BT 0.120 (1.176)	DT 0.007 (1.044)	loss nan (nan)	prob nan (nan)	GS 35.953 (35.953)	mem 39.951
Train: [49][495/750]	BT 0.116 (1.182)	DT 0.012 (1.050)	loss nan (nan)	prob nan (nan)	GS 33.484 (33.484)	mem 40.033
Train: [49][500/750]	BT 0.080 (1.175)	DT 0.001 (1.043)	loss nan (nan)	prob nan (nan)	GS 35.422 (35.422)	mem 40.049
Train: [49][505/750]	BT 0.246 (1.168)	DT 0.003 (1.036)	loss nan (nan)	prob nan (nan)	GS 28.281 (28.281)	mem 40.139
Train: [49][510/750]	BT 1.596 (1.174)	DT 1.468 (1.042)	loss nan (nan)	prob nan (nan)	GS 30.438 (30.438)	mem 40.111
Train: [49][515/750]	BT 0.141 (1.169)	DT 0.016 (1.037)	loss nan (nan)	prob nan (nan)	GS 30.969 (30.969)	mem 40.092
Train: [49][520/750]	BT 1.088 (1.175)	DT 0.898 (1.043)	loss nan (nan)	prob nan (nan)	GS 37.062 (37.062)	mem 40.110
Train: [49][525/750]	BT 0.085 (1.168)	DT 0.001 (1.036)	loss nan (nan)	prob nan (nan)	GS 30.062 (30.062)	mem 40.058
Train: [49][530/750]	BT 10.161 (1.180)	DT 10.062 (1.047)	loss nan (nan)	prob nan (nan)	GS 30.781 (30.781)	mem 40.029
Train: [49][535/750]	BT 0.098 (1.170)	DT 0.005 (1.038)	loss nan (nan)	prob nan (nan)	GS 25.859 (25.859)	mem 40.026
Train: [49][540/750]	BT 0.113 (1.160)	DT 0.005 (1.028)	loss nan (nan)	prob nan (nan)	GS 34.438 (34.438)	mem 40.014
Train: [49][545/750]	BT 0.077 (1.174)	DT 0.003 (1.043)	loss nan (nan)	prob nan (nan)	GS 30.875 (30.875)	mem 39.798
Train: [49][550/750]	BT 0.133 (1.165)	DT 0.002 (1.033)	loss nan (nan)	prob nan (nan)	GS 36.094 (36.094)	mem 39.804
Train: [49][555/750]	BT 0.196 (1.171)	DT 0.001 (1.040)	loss nan (nan)	prob nan (nan)	GS 32.188 (32.188)	mem 40.151
Train: [49][560/750]	BT 0.097 (1.168)	DT 0.002 (1.036)	loss nan (nan)	prob nan (nan)	GS 33.594 (33.594)	mem 40.021
Train: [49][565/750]	BT 0.168 (1.159)	DT 0.004 (1.027)	loss nan (nan)	prob nan (nan)	GS 32.453 (32.453)	mem 40.027
Train: [49][570/750]	BT 6.438 (1.175)	DT 6.351 (1.043)	loss nan (nan)	prob nan (nan)	GS 37.562 (37.562)	mem 40.049
Train: [49][575/750]	BT 0.188 (1.166)	DT 0.007 (1.034)	loss nan (nan)	prob nan (nan)	GS 28.531 (28.531)	mem 40.145
Train: [49][580/750]	BT 0.175 (1.164)	DT 0.070 (1.032)	loss nan (nan)	prob nan (nan)	GS 31.031 (31.031)	mem 39.996
Train: [49][585/750]	BT 0.098 (1.171)	DT 0.001 (1.039)	loss nan (nan)	prob nan (nan)	GS 28.125 (28.125)	mem 40.002
Train: [49][590/750]	BT 0.114 (1.162)	DT 0.009 (1.031)	loss nan (nan)	prob nan (nan)	GS 29.641 (29.641)	mem 40.046
Train: [49][595/750]	BT 0.196 (1.169)	DT 0.005 (1.037)	loss nan (nan)	prob nan (nan)	GS 31.312 (31.312)	mem 40.025
Train: [49][600/750]	BT 0.113 (1.161)	DT 0.001 (1.029)	loss nan (nan)	prob nan (nan)	GS 37.469 (37.469)	mem 40.127
Train: [49][605/750]	BT 0.236 (1.163)	DT 0.002 (1.030)	loss nan (nan)	prob nan (nan)	GS 28.531 (28.531)	mem 40.158
Train: [49][610/750]	BT 0.092 (1.166)	DT 0.002 (1.034)	loss nan (nan)	prob nan (nan)	GS 31.594 (31.594)	mem 40.060
Train: [49][615/750]	BT 0.106 (1.158)	DT 0.010 (1.026)	loss nan (nan)	prob nan (nan)	GS 34.906 (34.906)	mem 40.068
Train: [49][620/750]	BT 0.097 (1.171)	DT 0.002 (1.039)	loss nan (nan)	prob nan (nan)	GS 34.984 (34.984)	mem 39.988
Train: [49][625/750]	BT 0.098 (1.163)	DT 0.005 (1.031)	loss nan (nan)	prob nan (nan)	GS 31.047 (31.047)	mem 40.093
Train: [49][630/750]	BT 1.831 (1.170)	DT 1.643 (1.038)	loss nan (nan)	prob nan (nan)	GS 28.375 (28.375)	mem 40.621
Train: [49][635/750]	BT 0.135 (1.162)	DT 0.008 (1.030)	loss nan (nan)	prob nan (nan)	GS 34.078 (34.078)	mem 40.089
Train: [49][640/750]	BT 8.174 (1.167)	DT 8.035 (1.035)	loss nan (nan)	prob nan (nan)	GS 30.516 (30.516)	mem 40.251
Train: [49][645/750]	BT 0.103 (1.165)	DT 0.005 (1.032)	loss nan (nan)	prob nan (nan)	GS 29.281 (29.281)	mem 40.058
Train: [49][650/750]	BT 0.125 (1.157)	DT 0.002 (1.025)	loss nan (nan)	prob nan (nan)	GS 33.250 (33.250)	mem 39.941
Train: [49][655/750]	BT 0.135 (1.163)	DT 0.002 (1.031)	loss nan (nan)	prob nan (nan)	GS 26.656 (26.656)	mem 40.107
Train: [49][660/750]	BT 0.134 (1.155)	DT 0.004 (1.023)	loss nan (nan)	prob nan (nan)	GS 37.938 (37.938)	mem 40.056
Train: [49][665/750]	BT 0.157 (1.160)	DT 0.001 (1.028)	loss nan (nan)	prob nan (nan)	GS 32.344 (32.344)	mem 40.049
Train: [49][670/750]	BT 0.149 (1.159)	DT 0.010 (1.026)	loss nan (nan)	prob nan (nan)	GS 31.594 (31.594)	mem 40.076
Train: [49][675/750]	BT 0.114 (1.151)	DT 0.002 (1.019)	loss nan (nan)	prob nan (nan)	GS 31.953 (31.953)	mem 40.092
Train: [49][680/750]	BT 0.068 (1.161)	DT 0.001 (1.029)	loss nan (nan)	prob nan (nan)	GS 29.500 (29.500)	mem 40.002
Train: [49][685/750]	BT 0.092 (1.154)	DT 0.007 (1.022)	loss nan (nan)	prob nan (nan)	GS 27.875 (27.875)	mem 40.002
Train: [49][690/750]	BT 9.352 (1.162)	DT 9.201 (1.030)	loss nan (nan)	prob nan (nan)	GS 30.781 (30.781)	mem 40.030
Train: [49][695/750]	BT 0.192 (1.155)	DT 0.013 (1.023)	loss nan (nan)	prob nan (nan)	GS 35.031 (35.031)	mem 40.032
Train: [49][700/750]	BT 5.467 (1.155)	DT 5.316 (1.023)	loss nan (nan)	prob nan (nan)	GS 36.344 (36.344)	mem 40.100
Train: [49][705/750]	BT 0.076 (1.153)	DT 0.001 (1.021)	loss nan (nan)	prob nan (nan)	GS 31.906 (31.906)	mem 40.098
Train: [49][710/750]	BT 0.197 (1.146)	DT 0.007 (1.014)	loss nan (nan)	prob nan (nan)	GS 35.734 (35.734)	mem 40.098
Train: [49][715/750]	BT 0.214 (1.157)	DT 0.001 (1.024)	loss nan (nan)	prob nan (nan)	GS 34.391 (34.391)	mem 40.073
Train: [49][720/750]	BT 0.302 (1.150)	DT 0.007 (1.017)	loss nan (nan)	prob nan (nan)	GS 30.297 (30.297)	mem 40.125
Train: [49][725/750]	BT 0.125 (1.156)	DT 0.002 (1.023)	loss nan (nan)	prob nan (nan)	GS 28.484 (28.484)	mem 39.948
Train: [49][730/750]	BT 0.165 (1.152)	DT 0.002 (1.018)	loss nan (nan)	prob nan (nan)	GS 34.078 (34.078)	mem 40.126
Train: [49][735/750]	BT 0.091 (1.146)	DT 0.001 (1.013)	loss nan (nan)	prob nan (nan)	GS 32.250 (32.250)	mem 37.009
Train: [49][740/750]	BT 0.074 (1.146)	DT 0.001 (1.014)	loss nan (nan)	prob nan (nan)	GS 34.578 (34.578)	mem 13.653
Train: [49][745/750]	BT 0.066 (1.139)	DT 0.001 (1.007)	loss nan (nan)	prob nan (nan)	GS 34.875 (34.875)	mem 13.653
Train: [49][750/750]	BT 0.464 (1.135)	DT 0.394 (1.003)	loss nan (nan)	prob nan (nan)	GS 36.156 (36.156)	mem 10.668
Train: [49][755/750]	BT 0.072 (1.128)	DT 0.001 (0.996)	loss nan (nan)	prob nan (nan)	GS 28.000 (28.000)	mem 10.529
epoch 49, total time 851.86
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [50][1/750]	BT 20.091 (20.091)	DT 19.863 (19.863)	loss nan (nan)	prob nan (nan)	GS 33.328 (33.328)	mem 38.726
Train: [50][5/750]	BT 0.155 (5.108)	DT 0.005 (4.944)	loss nan (nan)	prob nan (nan)	GS 30.094 (30.094)	mem 38.694
Train: [50][10/750]	BT 0.146 (2.780)	DT 0.017 (2.628)	loss nan (nan)	prob nan (nan)	GS 32.516 (32.516)	mem 38.705
Train: [50][15/750]	BT 0.160 (2.291)	DT 0.001 (2.139)	loss nan (nan)	prob nan (nan)	GS 33.703 (33.703)	mem 38.994
Train: [50][20/750]	BT 0.238 (1.995)	DT 0.002 (1.840)	loss nan (nan)	prob nan (nan)	GS 33.031 (33.031)	mem 39.144
Train: [50][25/750]	BT 1.435 (1.769)	DT 1.238 (1.613)	loss nan (nan)	prob nan (nan)	GS 34.562 (34.562)	mem 38.995
Train: [50][30/750]	BT 0.825 (1.688)	DT 0.696 (1.538)	loss nan (nan)	prob nan (nan)	GS 29.891 (29.891)	mem 39.159
Train: [50][35/750]	BT 0.129 (1.634)	DT 0.004 (1.482)	loss nan (nan)	prob nan (nan)	GS 35.219 (35.219)	mem 39.064
Train: [50][40/750]	BT 2.642 (1.568)	DT 2.460 (1.415)	loss nan (nan)	prob nan (nan)	GS 30.844 (30.844)	mem 39.109
Train: [50][45/750]	BT 0.100 (1.437)	DT 0.002 (1.284)	loss nan (nan)	prob nan (nan)	GS 27.672 (27.672)	mem 39.053
Train: [50][50/750]	BT 2.487 (1.509)	DT 2.320 (1.358)	loss nan (nan)	prob nan (nan)	GS 31.906 (31.906)	mem 39.128
Train: [50][55/750]	BT 0.076 (1.382)	DT 0.001 (1.234)	loss nan (nan)	prob nan (nan)	GS 29.641 (29.641)	mem 39.167
Train: [50][60/750]	BT 0.268 (1.439)	DT 0.006 (1.289)	loss nan (nan)	prob nan (nan)	GS 32.344 (32.344)	mem 39.117
Train: [50][65/750]	BT 0.129 (1.380)	DT 0.004 (1.232)	loss nan (nan)	prob nan (nan)	GS 30.156 (30.156)	mem 39.210
Train: [50][70/750]	BT 6.551 (1.425)	DT 6.468 (1.279)	loss nan (nan)	prob nan (nan)	GS 33.250 (33.250)	mem 39.171
Train: [50][75/750]	BT 0.199 (1.339)	DT 0.002 (1.195)	loss nan (nan)	prob nan (nan)	GS 31.656 (31.656)	mem 39.152
Train: [50][80/750]	BT 0.126 (1.341)	DT 0.002 (1.198)	loss nan (nan)	prob nan (nan)	GS 36.266 (36.266)	mem 39.064
Train: [50][85/750]	BT 0.163 (1.353)	DT 0.004 (1.211)	loss nan (nan)	prob nan (nan)	GS 35.250 (35.250)	mem 39.082
Train: [50][90/750]	BT 5.116 (1.357)	DT 5.009 (1.215)	loss nan (nan)	prob nan (nan)	GS 35.438 (35.438)	mem 39.390
Train: [50][95/750]	BT 0.164 (1.340)	DT 0.002 (1.198)	loss nan (nan)	prob nan (nan)	GS 32.734 (32.734)	mem 39.224
Train: [50][100/750]	BT 0.485 (1.286)	DT 0.378 (1.142)	loss nan (nan)	prob nan (nan)	GS 36.828 (36.828)	mem 39.267
Train: [50][105/750]	BT 0.098 (1.334)	DT 0.002 (1.190)	loss nan (nan)	prob nan (nan)	GS 34.562 (34.562)	mem 39.211
Train: [50][110/750]	BT 0.223 (1.296)	DT 0.006 (1.153)	loss nan (nan)	prob nan (nan)	GS 34.891 (34.891)	mem 39.360
Train: [50][115/750]	BT 0.074 (1.334)	DT 0.002 (1.192)	loss nan (nan)	prob nan (nan)	GS 35.922 (35.922)	mem 39.289
Train: [50][120/750]	BT 0.105 (1.284)	DT 0.001 (1.142)	loss nan (nan)	prob nan (nan)	GS 32.844 (32.844)	mem 39.291
Train: [50][125/750]	BT 0.162 (1.251)	DT 0.004 (1.109)	loss nan (nan)	prob nan (nan)	GS 31.312 (31.312)	mem 39.200
Train: [50][130/750]	BT 0.116 (1.282)	DT 0.001 (1.140)	loss nan (nan)	prob nan (nan)	GS 32.891 (32.891)	mem 39.207
Train: [50][135/750]	BT 0.219 (1.286)	DT 0.001 (1.144)	loss nan (nan)	prob nan (nan)	GS 26.500 (26.500)	mem 39.253
Train: [50][140/750]	BT 6.031 (1.311)	DT 5.876 (1.169)	loss nan (nan)	prob nan (nan)	GS 33.109 (33.109)	mem 39.296
Train: [50][145/750]	BT 0.086 (1.271)	DT 0.002 (1.129)	loss nan (nan)	prob nan (nan)	GS 29.781 (29.781)	mem 39.338
Train: [50][150/750]	BT 5.100 (1.296)	DT 4.834 (1.155)	loss nan (nan)	prob nan (nan)	GS 36.828 (36.828)	mem 39.517
Train: [50][155/750]	BT 0.099 (1.292)	DT 0.001 (1.153)	loss nan (nan)	prob nan (nan)	GS 30.234 (30.234)	mem 39.535
Train: [50][160/750]	BT 0.137 (1.259)	DT 0.001 (1.118)	loss nan (nan)	prob nan (nan)	GS 33.844 (33.844)	mem 39.538
Train: [50][165/750]	BT 0.130 (1.312)	DT 0.004 (1.172)	loss nan (nan)	prob nan (nan)	GS 30.891 (30.891)	mem 39.572
Train: [50][170/750]	BT 0.159 (1.278)	DT 0.008 (1.138)	loss nan (nan)	prob nan (nan)	GS 35.047 (35.047)	mem 39.512
Train: [50][175/750]	BT 0.159 (1.296)	DT 0.014 (1.156)	loss nan (nan)	prob nan (nan)	GS 36.391 (36.391)	mem 39.521
Train: [50][180/750]	BT 0.121 (1.264)	DT 0.002 (1.124)	loss nan (nan)	prob nan (nan)	GS 33.125 (33.125)	mem 39.560
Train: [50][185/750]	BT 0.093 (1.235)	DT 0.002 (1.096)	loss nan (nan)	prob nan (nan)	GS 27.531 (27.531)	mem 39.502
Train: [50][190/750]	BT 0.129 (1.266)	DT 0.004 (1.126)	loss nan (nan)	prob nan (nan)	GS 32.141 (32.141)	mem 39.560
Train: [50][195/750]	BT 0.104 (1.237)	DT 0.002 (1.098)	loss nan (nan)	prob nan (nan)	GS 29.594 (29.594)	mem 39.591
Train: [50][200/750]	BT 0.178 (1.276)	DT 0.016 (1.137)	loss nan (nan)	prob nan (nan)	GS 32.250 (32.250)	mem 39.813
Train: [50][205/750]	BT 0.132 (1.247)	DT 0.001 (1.109)	loss nan (nan)	prob nan (nan)	GS 31.500 (31.500)	mem 39.814
Train: [50][210/750]	BT 9.511 (1.267)	DT 9.366 (1.128)	loss nan (nan)	prob nan (nan)	GS 38.656 (38.656)	mem 39.989
Train: [50][215/750]	BT 0.188 (1.240)	DT 0.015 (1.102)	loss nan (nan)	prob nan (nan)	GS 33.703 (33.703)	mem 39.933
Train: [50][220/750]	BT 0.535 (1.218)	DT 0.248 (1.078)	loss nan (nan)	prob nan (nan)	GS 32.141 (32.141)	mem 40.030
Train: [50][225/750]	BT 0.094 (1.251)	DT 0.007 (1.112)	loss nan (nan)	prob nan (nan)	GS 31.906 (31.906)	mem 39.838
Train: [50][230/750]	BT 0.085 (1.226)	DT 0.004 (1.088)	loss nan (nan)	prob nan (nan)	GS 35.281 (35.281)	mem 39.839
Train: [50][235/750]	BT 0.120 (1.248)	DT 0.001 (1.109)	loss nan (nan)	prob nan (nan)	GS 31.906 (31.906)	mem 39.909
Train: [50][240/750]	BT 0.113 (1.224)	DT 0.002 (1.086)	loss nan (nan)	prob nan (nan)	GS 36.562 (36.562)	mem 39.864
Train: [50][245/750]	BT 0.231 (1.203)	DT 0.025 (1.064)	loss nan (nan)	prob nan (nan)	GS 35.094 (35.094)	mem 39.868
Train: [50][250/750]	BT 0.081 (1.231)	DT 0.002 (1.093)	loss nan (nan)	prob nan (nan)	GS 33.281 (33.281)	mem 39.854
Train: [50][255/750]	BT 0.090 (1.209)	DT 0.002 (1.072)	loss nan (nan)	prob nan (nan)	GS 31.969 (31.969)	mem 40.012
Train: [50][260/750]	BT 0.093 (1.236)	DT 0.002 (1.098)	loss nan (nan)	prob nan (nan)	GS 35.438 (35.438)	mem 39.904
Train: [50][265/750]	BT 0.186 (1.214)	DT 0.010 (1.078)	loss nan (nan)	prob nan (nan)	GS 31.266 (31.266)	mem 39.906
Train: [50][270/750]	BT 10.902 (1.234)	DT 10.790 (1.098)	loss nan (nan)	prob nan (nan)	GS 34.406 (34.406)	mem 40.139
Train: [50][275/750]	BT 0.254 (1.214)	DT 0.001 (1.078)	loss nan (nan)	prob nan (nan)	GS 30.109 (30.109)	mem 39.959
Train: [50][280/750]	BT 3.668 (1.208)	DT 3.564 (1.072)	loss nan (nan)	prob nan (nan)	GS 36.016 (36.016)	mem 39.987
Train: [50][285/750]	BT 0.070 (1.224)	DT 0.002 (1.088)	loss nan (nan)	prob nan (nan)	GS 27.359 (27.359)	mem 39.880
Train: [50][290/750]	BT 0.102 (1.205)	DT 0.001 (1.070)	loss nan (nan)	prob nan (nan)	GS 30.188 (30.188)	mem 39.940
Train: [50][295/750]	BT 0.092 (1.218)	DT 0.001 (1.083)	loss nan (nan)	prob nan (nan)	GS 27.391 (27.391)	mem 39.991
Train: [50][300/750]	BT 0.131 (1.200)	DT 0.002 (1.065)	loss nan (nan)	prob nan (nan)	GS 31.844 (31.844)	mem 39.990
Train: [50][305/750]	BT 0.174 (1.183)	DT 0.011 (1.048)	loss nan (nan)	prob nan (nan)	GS 32.594 (32.594)	mem 39.992
Train: [50][310/750]	BT 0.120 (1.202)	DT 0.002 (1.067)	loss nan (nan)	prob nan (nan)	GS 29.875 (29.875)	mem 40.127
Train: [50][315/750]	BT 0.155 (1.186)	DT 0.007 (1.050)	loss nan (nan)	prob nan (nan)	GS 33.375 (33.375)	mem 40.041
Train: [50][320/750]	BT 0.141 (1.205)	DT 0.009 (1.069)	loss nan (nan)	prob nan (nan)	GS 33.203 (33.203)	mem 40.043
Train: [50][325/750]	BT 0.185 (1.189)	DT 0.002 (1.053)	loss nan (nan)	prob nan (nan)	GS 32.391 (32.391)	mem 40.060
Train: [50][330/750]	BT 13.953 (1.215)	DT 13.876 (1.079)	loss nan (nan)	prob nan (nan)	GS 36.156 (36.156)	mem 40.076
Train: [50][335/750]	BT 0.081 (1.201)	DT 0.001 (1.066)	loss nan (nan)	prob nan (nan)	GS 30.312 (30.312)	mem 39.969
Train: [50][340/750]	BT 0.104 (1.186)	DT 0.004 (1.051)	loss nan (nan)	prob nan (nan)	GS 31.125 (31.125)	mem 40.096
Train: [50][345/750]	BT 0.077 (1.203)	DT 0.001 (1.068)	loss nan (nan)	prob nan (nan)	GS 28.484 (28.484)	mem 39.993
Train: [50][350/750]	BT 0.077 (1.187)	DT 0.001 (1.053)	loss nan (nan)	prob nan (nan)	GS 29.484 (29.484)	mem 39.952
Train: [50][355/750]	BT 0.248 (1.199)	DT 0.015 (1.064)	loss nan (nan)	prob nan (nan)	GS 29.703 (29.703)	mem 40.014
Train: [50][360/750]	BT 0.109 (1.193)	DT 0.009 (1.058)	loss nan (nan)	prob nan (nan)	GS 32.562 (32.562)	mem 39.973
Train: [50][365/750]	BT 0.245 (1.179)	DT 0.041 (1.044)	loss nan (nan)	prob nan (nan)	GS 35.312 (35.312)	mem 39.978
Train: [50][370/750]	BT 0.081 (1.197)	DT 0.002 (1.062)	loss nan (nan)	prob nan (nan)	GS 32.125 (32.125)	mem 40.017
Train: [50][375/750]	BT 0.157 (1.183)	DT 0.014 (1.048)	loss nan (nan)	prob nan (nan)	GS 28.000 (28.000)	mem 40.061
Train: [50][380/750]	BT 1.819 (1.197)	DT 1.659 (1.062)	loss nan (nan)	prob nan (nan)	GS 34.797 (34.797)	mem 40.176
Train: [50][385/750]	BT 0.104 (1.183)	DT 0.002 (1.048)	loss nan (nan)	prob nan (nan)	GS 30.859 (30.859)	mem 39.971
Train: [50][390/750]	BT 9.155 (1.192)	DT 9.058 (1.058)	loss nan (nan)	prob nan (nan)	GS 31.531 (31.531)	mem 39.951
Train: [50][395/750]	BT 0.081 (1.183)	DT 0.001 (1.048)	loss nan (nan)	prob nan (nan)	GS 30.734 (30.734)	mem 40.001
Train: [50][400/750]	BT 0.092 (1.169)	DT 0.009 (1.035)	loss nan (nan)	prob nan (nan)	GS 32.719 (32.719)	mem 39.941
Train: [50][405/750]	BT 0.092 (1.190)	DT 0.009 (1.057)	loss nan (nan)	prob nan (nan)	GS 35.281 (35.281)	mem 39.981
Train: [50][410/750]	BT 0.100 (1.177)	DT 0.002 (1.044)	loss nan (nan)	prob nan (nan)	GS 32.547 (32.547)	mem 39.996
Train: [50][415/750]	BT 0.192 (1.178)	DT 0.012 (1.044)	loss nan (nan)	prob nan (nan)	GS 29.047 (29.047)	mem 39.894
Train: [50][420/750]	BT 0.172 (1.176)	DT 0.001 (1.043)	loss nan (nan)	prob nan (nan)	GS 32.219 (32.219)	mem 40.035
Train: [50][425/750]	BT 0.090 (1.164)	DT 0.002 (1.031)	loss nan (nan)	prob nan (nan)	GS 30.969 (30.969)	mem 40.309
Train: [50][430/750]	BT 0.110 (1.176)	DT 0.002 (1.042)	loss nan (nan)	prob nan (nan)	GS 36.188 (36.188)	mem 39.999
Train: [50][435/750]	BT 0.167 (1.164)	DT 0.006 (1.030)	loss nan (nan)	prob nan (nan)	GS 29.938 (29.938)	mem 40.189
Train: [50][440/750]	BT 6.653 (1.178)	DT 6.565 (1.045)	loss nan (nan)	prob nan (nan)	GS 37.484 (37.484)	mem 40.169
Train: [50][445/750]	BT 0.151 (1.167)	DT 0.001 (1.033)	loss nan (nan)	prob nan (nan)	GS 32.812 (32.812)	mem 40.030
Train: [50][450/750]	BT 3.645 (1.163)	DT 3.525 (1.029)	loss nan (nan)	prob nan (nan)	GS 31.875 (31.875)	mem 40.043
Train: [50][455/750]	BT 0.155 (1.170)	DT 0.001 (1.037)	loss nan (nan)	prob nan (nan)	GS 30.078 (30.078)	mem 40.021
Train: [50][460/750]	BT 0.237 (1.159)	DT 0.002 (1.025)	loss nan (nan)	prob nan (nan)	GS 31.438 (31.438)	mem 40.022
Train: [50][465/750]	BT 0.095 (1.174)	DT 0.002 (1.040)	loss nan (nan)	prob nan (nan)	GS 36.344 (36.344)	mem 40.088
Train: [50][470/750]	BT 0.140 (1.162)	DT 0.001 (1.029)	loss nan (nan)	prob nan (nan)	GS 32.703 (32.703)	mem 40.023
Train: [50][475/750]	BT 0.145 (1.158)	DT 0.002 (1.025)	loss nan (nan)	prob nan (nan)	GS 31.094 (31.094)	mem 39.980
Train: [50][480/750]	BT 0.089 (1.170)	DT 0.002 (1.037)	loss nan (nan)	prob nan (nan)	GS 35.109 (35.109)	mem 40.017
Train: [50][485/750]	BT 0.122 (1.164)	DT 0.011 (1.032)	loss nan (nan)	prob nan (nan)	GS 36.906 (36.906)	mem 40.147
Train: [50][490/750]	BT 0.151 (1.177)	DT 0.022 (1.045)	loss nan (nan)	prob nan (nan)	GS 31.422 (31.422)	mem 40.105
Train: [50][495/750]	BT 0.086 (1.167)	DT 0.002 (1.034)	loss nan (nan)	prob nan (nan)	GS 34.391 (34.391)	mem 40.105
Train: [50][500/750]	BT 11.909 (1.189)	DT 11.839 (1.056)	loss nan (nan)	prob nan (nan)	GS 36.469 (36.469)	mem 40.018
Train: [50][505/750]	BT 0.069 (1.178)	DT 0.001 (1.046)	loss nan (nan)	prob nan (nan)	GS 30.266 (30.266)	mem 40.000
Train: [50][510/750]	BT 0.249 (1.168)	DT 0.002 (1.035)	loss nan (nan)	prob nan (nan)	GS 32.266 (32.266)	mem 39.981
Train: [50][515/750]	BT 0.141 (1.177)	DT 0.001 (1.044)	loss nan (nan)	prob nan (nan)	GS 34.469 (34.469)	mem 40.077
Train: [50][520/750]	BT 0.132 (1.167)	DT 0.002 (1.034)	loss nan (nan)	prob nan (nan)	GS 31.422 (31.422)	mem 40.199
Train: [50][525/750]	BT 0.082 (1.185)	DT 0.001 (1.052)	loss nan (nan)	prob nan (nan)	GS 33.703 (33.703)	mem 39.964
Train: [50][530/750]	BT 0.093 (1.175)	DT 0.001 (1.042)	loss nan (nan)	prob nan (nan)	GS 34.125 (34.125)	mem 39.964
Train: [50][535/750]	BT 0.190 (1.165)	DT 0.002 (1.033)	loss nan (nan)	prob nan (nan)	GS 30.172 (30.172)	mem 40.078
Train: [50][540/750]	BT 0.062 (1.176)	DT 0.001 (1.044)	loss nan (nan)	prob nan (nan)	GS 37.328 (37.328)	mem 40.005
Train: [50][545/750]	BT 0.179 (1.166)	DT 0.007 (1.035)	loss nan (nan)	prob nan (nan)	GS 32.828 (32.828)	mem 40.060
Train: [50][550/750]	BT 0.109 (1.178)	DT 0.001 (1.047)	loss nan (nan)	prob nan (nan)	GS 33.094 (33.094)	mem 40.082
Train: [50][555/750]	BT 0.092 (1.168)	DT 0.002 (1.037)	loss nan (nan)	prob nan (nan)	GS 32.984 (32.984)	mem 40.085
Train: [50][560/750]	BT 9.455 (1.176)	DT 9.252 (1.044)	loss nan (nan)	prob nan (nan)	GS 29.938 (29.938)	mem 40.142
Train: [50][565/750]	BT 0.151 (1.167)	DT 0.006 (1.035)	loss nan (nan)	prob nan (nan)	GS 29.266 (29.266)	mem 40.113
Train: [50][570/750]	BT 0.211 (1.158)	DT 0.002 (1.026)	loss nan (nan)	prob nan (nan)	GS 30.219 (30.219)	mem 40.112
Train: [50][575/750]	BT 0.117 (1.173)	DT 0.021 (1.042)	loss nan (nan)	prob nan (nan)	GS 28.375 (28.375)	mem 40.254
Train: [50][580/750]	BT 0.109 (1.164)	DT 0.007 (1.033)	loss nan (nan)	prob nan (nan)	GS 32.328 (32.328)	mem 40.194
Train: [50][585/750]	BT 0.085 (1.179)	DT 0.001 (1.047)	loss nan (nan)	prob nan (nan)	GS 35.344 (35.344)	mem 39.979
Train: [50][590/750]	BT 0.158 (1.170)	DT 0.001 (1.039)	loss nan (nan)	prob nan (nan)	GS 36.859 (36.859)	mem 40.240
Train: [50][595/750]	BT 0.263 (1.161)	DT 0.051 (1.030)	loss nan (nan)	prob nan (nan)	GS 30.469 (30.469)	mem 39.999
Train: [50][600/750]	BT 0.094 (1.175)	DT 0.001 (1.045)	loss nan (nan)	prob nan (nan)	GS 35.578 (35.578)	mem 40.029
Train: [50][605/750]	BT 0.177 (1.167)	DT 0.001 (1.036)	loss nan (nan)	prob nan (nan)	GS 29.422 (29.422)	mem 39.969
Train: [50][610/750]	BT 0.070 (1.179)	DT 0.001 (1.049)	loss nan (nan)	prob nan (nan)	GS 33.266 (33.266)	mem 39.978
Train: [50][615/750]	BT 0.116 (1.171)	DT 0.002 (1.041)	loss nan (nan)	prob nan (nan)	GS 31.531 (31.531)	mem 39.979
Train: [50][620/750]	BT 14.763 (1.186)	DT 14.696 (1.056)	loss nan (nan)	prob nan (nan)	GS 37.766 (37.766)	mem 39.926
Train: [50][625/750]	BT 0.081 (1.177)	DT 0.001 (1.048)	loss nan (nan)	prob nan (nan)	GS 34.141 (34.141)	mem 40.013
Train: [50][630/750]	BT 0.116 (1.169)	DT 0.004 (1.039)	loss nan (nan)	prob nan (nan)	GS 34.281 (34.281)	mem 40.176
Train: [50][635/750]	BT 0.098 (1.179)	DT 0.001 (1.050)	loss nan (nan)	prob nan (nan)	GS 26.312 (26.312)	mem 40.058
Train: [50][640/750]	BT 0.095 (1.171)	DT 0.004 (1.042)	loss nan (nan)	prob nan (nan)	GS 33.578 (33.578)	mem 40.061
Train: [50][645/750]	BT 0.076 (1.179)	DT 0.001 (1.050)	loss nan (nan)	prob nan (nan)	GS 31.938 (31.938)	mem 40.112
Train: [50][650/750]	BT 0.208 (1.171)	DT 0.001 (1.042)	loss nan (nan)	prob nan (nan)	GS 30.906 (30.906)	mem 40.221
Train: [50][655/750]	BT 0.270 (1.163)	DT 0.051 (1.034)	loss nan (nan)	prob nan (nan)	GS 30.688 (30.688)	mem 40.278
Train: [50][660/750]	BT 0.067 (1.174)	DT 0.001 (1.046)	loss nan (nan)	prob nan (nan)	GS 35.125 (35.125)	mem 39.915
Train: [50][665/750]	BT 0.111 (1.166)	DT 0.001 (1.038)	loss nan (nan)	prob nan (nan)	GS 33.922 (33.922)	mem 39.915
Train: [50][670/750]	BT 0.085 (1.176)	DT 0.017 (1.048)	loss nan (nan)	prob nan (nan)	GS 30.734 (30.734)	mem 40.052
Train: [50][675/750]	BT 0.109 (1.168)	DT 0.001 (1.040)	loss nan (nan)	prob nan (nan)	GS 32.922 (32.922)	mem 40.051
Train: [50][680/750]	BT 11.906 (1.178)	DT 11.791 (1.050)	loss nan (nan)	prob nan (nan)	GS 32.906 (32.906)	mem 40.130
Train: [50][685/750]	BT 0.120 (1.170)	DT 0.001 (1.042)	loss nan (nan)	prob nan (nan)	GS 32.172 (32.172)	mem 40.071
Train: [50][690/750]	BT 0.113 (1.163)	DT 0.002 (1.035)	loss nan (nan)	prob nan (nan)	GS 35.734 (35.734)	mem 40.041
Train: [50][695/750]	BT 0.165 (1.173)	DT 0.012 (1.045)	loss nan (nan)	prob nan (nan)	GS 29.297 (29.297)	mem 40.214
Train: [50][700/750]	BT 0.229 (1.166)	DT 0.001 (1.037)	loss nan (nan)	prob nan (nan)	GS 32.500 (32.500)	mem 40.215
Train: [50][705/750]	BT 0.119 (1.178)	DT 0.003 (1.049)	loss nan (nan)	prob nan (nan)	GS 32.047 (32.047)	mem 40.178
arpack error, retry= 0
Train: [50][710/750]	BT 0.167 (1.170)	DT 0.014 (1.042)	loss nan (nan)	prob nan (nan)	GS 35.688 (35.688)	mem 40.140
Train: [50][715/750]	BT 0.089 (1.163)	DT 0.001 (1.035)	loss nan (nan)	prob nan (nan)	GS 43.531 (43.531)	mem 40.032
Train: [50][720/750]	BT 0.109 (1.175)	DT 0.001 (1.046)	loss nan (nan)	prob nan (nan)	GS 33.438 (33.438)	mem 40.107
Train: [50][725/750]	BT 0.120 (1.168)	DT 0.004 (1.039)	loss nan (nan)	prob nan (nan)	GS 31.359 (31.359)	mem 39.986
Train: [50][730/750]	BT 0.089 (1.173)	DT 0.001 (1.045)	loss nan (nan)	prob nan (nan)	GS 30.188 (30.188)	mem 39.696
Train: [50][735/750]	BT 0.066 (1.166)	DT 0.001 (1.038)	loss nan (nan)	prob nan (nan)	GS 29.781 (29.781)	mem 39.590
Train: [50][740/750]	BT 6.559 (1.168)	DT 6.480 (1.040)	loss nan (nan)	prob nan (nan)	GS 32.719 (32.719)	mem 7.694
Train: [50][745/750]	BT 0.065 (1.161)	DT 0.001 (1.033)	loss nan (nan)	prob nan (nan)	GS 32.000 (32.000)	mem 7.694
Train: [50][750/750]	BT 0.089 (1.153)	DT 0.002 (1.026)	loss nan (nan)	prob nan (nan)	GS 32.688 (32.688)	mem 7.780
Train: [50][755/750]	BT 0.076 (1.149)	DT 0.001 (1.022)	loss nan (nan)	prob nan (nan)	GS 34.281 (34.281)	mem 7.660
epoch 50, total time 868.06
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [51][1/750]	BT 22.001 (22.001)	DT 21.748 (21.748)	loss nan (nan)	prob nan (nan)	GS 32.203 (32.203)	mem 38.666
Train: [51][5/750]	BT 0.243 (4.522)	DT 0.031 (4.357)	loss nan (nan)	prob nan (nan)	GS 30.969 (30.969)	mem 38.648
Train: [51][10/750]	BT 0.210 (2.341)	DT 0.003 (2.183)	loss nan (nan)	prob nan (nan)	GS 32.812 (32.812)	mem 38.665
Train: [51][15/750]	BT 0.077 (2.111)	DT 0.002 (1.970)	loss nan (nan)	prob nan (nan)	GS 26.000 (26.000)	mem 38.785
Train: [51][20/750]	BT 0.096 (1.997)	DT 0.007 (1.850)	loss nan (nan)	prob nan (nan)	GS 35.219 (35.219)	mem 38.960
Train: [51][25/750]	BT 0.153 (1.745)	DT 0.007 (1.607)	loss nan (nan)	prob nan (nan)	GS 37.234 (37.234)	mem 38.942
Train: [51][30/750]	BT 0.164 (1.658)	DT 0.005 (1.521)	loss nan (nan)	prob nan (nan)	GS 32.406 (32.406)	mem 39.037
Train: [51][35/750]	BT 0.181 (1.439)	DT 0.006 (1.304)	loss nan (nan)	prob nan (nan)	GS 31.000 (31.000)	mem 38.950
Train: [51][40/750]	BT 7.294 (1.650)	DT 7.119 (1.516)	loss nan (nan)	prob nan (nan)	GS 29.484 (29.484)	mem 39.019
Train: [51][45/750]	BT 0.107 (1.479)	DT 0.001 (1.348)	loss nan (nan)	prob nan (nan)	GS 33.391 (33.391)	mem 39.069
Train: [51][50/750]	BT 3.592 (1.413)	DT 3.429 (1.282)	loss nan (nan)	prob nan (nan)	GS 35.062 (35.062)	mem 39.028
Train: [51][55/750]	BT 0.159 (1.412)	DT 0.007 (1.279)	loss nan (nan)	prob nan (nan)	GS 27.891 (27.891)	mem 39.038
Train: [51][60/750]	BT 1.243 (1.326)	DT 1.156 (1.192)	loss nan (nan)	prob nan (nan)	GS 35.312 (35.312)	mem 39.090
Train: [51][65/750]	BT 0.146 (1.365)	DT 0.001 (1.230)	loss nan (nan)	prob nan (nan)	GS 26.547 (26.547)	mem 39.274
Train: [51][70/750]	BT 0.076 (1.281)	DT 0.001 (1.143)	loss nan (nan)	prob nan (nan)	GS 36.672 (36.672)	mem 39.157
Train: [51][75/750]	BT 0.142 (1.292)	DT 0.001 (1.152)	loss nan (nan)	prob nan (nan)	GS 31.062 (31.062)	mem 39.257
Train: [51][80/750]	BT 0.108 (1.288)	DT 0.004 (1.148)	loss nan (nan)	prob nan (nan)	GS 28.656 (28.656)	mem 39.159
Train: [51][85/750]	BT 0.100 (1.240)	DT 0.006 (1.099)	loss nan (nan)	prob nan (nan)	GS 31.672 (31.672)	mem 39.210
Train: [51][90/750]	BT 2.642 (1.291)	DT 2.473 (1.148)	loss nan (nan)	prob nan (nan)	GS 35.344 (35.344)	mem 39.365
Train: [51][95/750]	BT 0.082 (1.231)	DT 0.001 (1.088)	loss nan (nan)	prob nan (nan)	GS 34.672 (34.672)	mem 39.370
Train: [51][100/750]	BT 2.024 (1.258)	DT 1.751 (1.114)	loss nan (nan)	prob nan (nan)	GS 31.828 (31.828)	mem 39.549
Train: [51][105/750]	BT 0.234 (1.252)	DT 0.021 (1.106)	loss nan (nan)	prob nan (nan)	GS 31.406 (31.406)	mem 39.486
Train: [51][110/750]	BT 0.138 (1.239)	DT 0.011 (1.093)	loss nan (nan)	prob nan (nan)	GS 36.859 (36.859)	mem 39.614
Train: [51][115/750]	BT 0.077 (1.268)	DT 0.002 (1.124)	loss nan (nan)	prob nan (nan)	GS 29.609 (29.609)	mem 39.723
Train: [51][120/750]	BT 0.676 (1.225)	DT 0.507 (1.082)	loss nan (nan)	prob nan (nan)	GS 38.172 (38.172)	mem 39.783
Train: [51][125/750]	BT 0.158 (1.233)	DT 0.008 (1.089)	loss nan (nan)	prob nan (nan)	GS 44.406 (44.406)	mem 39.747
Train: [51][130/750]	BT 0.575 (1.229)	DT 0.363 (1.086)	loss nan (nan)	prob nan (nan)	GS 35.094 (35.094)	mem 39.786
Train: [51][135/750]	BT 0.111 (1.188)	DT 0.002 (1.046)	loss nan (nan)	prob nan (nan)	GS 26.422 (26.422)	mem 39.904
Train: [51][140/750]	BT 0.086 (1.244)	DT 0.001 (1.104)	loss nan (nan)	prob nan (nan)	GS 30.312 (30.312)	mem 39.677
Train: [51][145/750]	BT 0.128 (1.211)	DT 0.010 (1.072)	loss nan (nan)	prob nan (nan)	GS 33.812 (33.812)	mem 39.702
Train: [51][150/750]	BT 10.572 (1.248)	DT 10.505 (1.108)	loss nan (nan)	prob nan (nan)	GS 33.484 (33.484)	mem 39.795
Train: [51][155/750]	BT 0.088 (1.211)	DT 0.002 (1.072)	loss nan (nan)	prob nan (nan)	GS 27.766 (27.766)	mem 39.825
Train: [51][160/750]	BT 2.146 (1.190)	DT 1.996 (1.052)	loss nan (nan)	prob nan (nan)	GS 33.469 (33.469)	mem 39.848
Train: [51][165/750]	BT 0.115 (1.232)	DT 0.002 (1.094)	loss nan (nan)	prob nan (nan)	GS 29.500 (29.500)	mem 39.807
Train: [51][170/750]	BT 0.228 (1.201)	DT 0.022 (1.062)	loss nan (nan)	prob nan (nan)	GS 33.359 (33.359)	mem 39.730
Train: [51][175/750]	BT 0.149 (1.237)	DT 0.010 (1.099)	loss nan (nan)	prob nan (nan)	GS 33.609 (33.609)	mem 39.769
Train: [51][180/750]	BT 0.066 (1.206)	DT 0.001 (1.069)	loss nan (nan)	prob nan (nan)	GS 36.938 (36.938)	mem 39.861
Train: [51][185/750]	BT 0.371 (1.179)	DT 0.005 (1.040)	loss nan (nan)	prob nan (nan)	GS 33.984 (33.984)	mem 39.825
Train: [51][190/750]	BT 0.078 (1.214)	DT 0.002 (1.076)	loss nan (nan)	prob nan (nan)	GS 30.062 (30.062)	mem 39.777
Train: [51][195/750]	BT 0.111 (1.186)	DT 0.002 (1.048)	loss nan (nan)	prob nan (nan)	GS 30.812 (30.812)	mem 39.810
Train: [51][200/750]	BT 0.118 (1.210)	DT 0.002 (1.073)	loss nan (nan)	prob nan (nan)	GS 29.656 (29.656)	mem 39.907
Train: [51][205/750]	BT 0.133 (1.189)	DT 0.003 (1.052)	loss nan (nan)	prob nan (nan)	GS 29.359 (29.359)	mem 39.851
Train: [51][210/750]	BT 8.584 (1.205)	DT 8.486 (1.068)	loss nan (nan)	prob nan (nan)	GS 34.484 (34.484)	mem 39.885
Train: [51][215/750]	BT 0.227 (1.186)	DT 0.038 (1.049)	loss nan (nan)	prob nan (nan)	GS 41.703 (41.703)	mem 39.887
Train: [51][220/750]	BT 2.084 (1.175)	DT 1.994 (1.039)	loss nan (nan)	prob nan (nan)	GS 35.578 (35.578)	mem 39.977
Train: [51][225/750]	BT 0.141 (1.191)	DT 0.023 (1.055)	loss nan (nan)	prob nan (nan)	GS 31.422 (31.422)	mem 39.894
Train: [51][230/750]	BT 0.257 (1.176)	DT 0.021 (1.040)	loss nan (nan)	prob nan (nan)	GS 32.531 (32.531)	mem 39.957
Train: [51][235/750]	BT 0.156 (1.199)	DT 0.002 (1.062)	loss nan (nan)	prob nan (nan)	GS 32.703 (32.703)	mem 39.971
Train: [51][240/750]	BT 3.080 (1.190)	DT 2.948 (1.054)	loss nan (nan)	prob nan (nan)	GS 32.453 (32.453)	mem 39.920
Train: [51][245/750]	BT 0.127 (1.168)	DT 0.010 (1.032)	loss nan (nan)	prob nan (nan)	GS 31.172 (31.172)	mem 39.941
Train: [51][250/750]	BT 2.443 (1.181)	DT 2.335 (1.046)	loss nan (nan)	prob nan (nan)	GS 32.781 (32.781)	mem 40.006
Train: [51][255/750]	BT 0.126 (1.167)	DT 0.001 (1.032)	loss nan (nan)	prob nan (nan)	GS 26.688 (26.688)	mem 40.148
Train: [51][260/750]	BT 0.261 (1.165)	DT 0.009 (1.029)	loss nan (nan)	prob nan (nan)	GS 35.797 (35.797)	mem 40.116
Train: [51][265/750]	BT 0.067 (1.181)	DT 0.001 (1.046)	loss nan (nan)	prob nan (nan)	GS 36.547 (36.547)	mem 39.984
Train: [51][270/750]	BT 0.089 (1.161)	DT 0.002 (1.027)	loss nan (nan)	prob nan (nan)	GS 32.156 (32.156)	mem 40.231
Train: [51][275/750]	BT 0.116 (1.191)	DT 0.002 (1.057)	loss nan (nan)	prob nan (nan)	GS 30.219 (30.219)	mem 40.004
Train: [51][280/750]	BT 0.085 (1.174)	DT 0.002 (1.040)	loss nan (nan)	prob nan (nan)	GS 34.656 (34.656)	mem 40.004
Train: [51][285/750]	BT 0.133 (1.166)	DT 0.002 (1.032)	loss nan (nan)	prob nan (nan)	GS 36.250 (36.250)	mem 40.073
Train: [51][290/750]	BT 0.130 (1.184)	DT 0.002 (1.050)	loss nan (nan)	prob nan (nan)	GS 32.328 (32.328)	mem 39.731
Train: [51][295/750]	BT 0.116 (1.166)	DT 0.001 (1.033)	loss nan (nan)	prob nan (nan)	GS 33.656 (33.656)	mem 39.873
Train: [51][300/750]	BT 2.534 (1.192)	DT 2.328 (1.058)	loss nan (nan)	prob nan (nan)	GS 34.625 (34.625)	mem 40.125
Train: [51][305/750]	BT 0.187 (1.174)	DT 0.007 (1.041)	loss nan (nan)	prob nan (nan)	GS 30.922 (30.922)	mem 40.021
Train: [51][310/750]	BT 11.363 (1.194)	DT 11.216 (1.060)	loss nan (nan)	prob nan (nan)	GS 34.766 (34.766)	mem 39.967
Train: [51][315/750]	BT 0.100 (1.179)	DT 0.001 (1.046)	loss nan (nan)	prob nan (nan)	GS 31.406 (31.406)	mem 39.904
Train: [51][320/750]	BT 0.182 (1.163)	DT 0.008 (1.030)	loss nan (nan)	prob nan (nan)	GS 28.859 (28.859)	mem 39.847
Train: [51][325/750]	BT 0.073 (1.195)	DT 0.001 (1.062)	loss nan (nan)	prob nan (nan)	GS 31.906 (31.906)	mem 40.006
Train: [51][330/750]	BT 0.123 (1.179)	DT 0.003 (1.045)	loss nan (nan)	prob nan (nan)	GS 35.938 (35.938)	mem 40.003
Train: [51][335/750]	BT 0.115 (1.197)	DT 0.010 (1.064)	loss nan (nan)	prob nan (nan)	GS 29.031 (29.031)	mem 39.891
Train: [51][340/750]	BT 0.110 (1.181)	DT 0.010 (1.048)	loss nan (nan)	prob nan (nan)	GS 37.344 (37.344)	mem 39.895
Train: [51][345/750]	BT 0.092 (1.165)	DT 0.002 (1.033)	loss nan (nan)	prob nan (nan)	GS 35.172 (35.172)	mem 40.020
Train: [51][350/750]	BT 0.072 (1.179)	DT 0.002 (1.048)	loss nan (nan)	prob nan (nan)	GS 30.688 (30.688)	mem 39.903
Train: [51][355/750]	BT 0.132 (1.164)	DT 0.001 (1.033)	loss nan (nan)	prob nan (nan)	GS 39.672 (39.672)	mem 40.044
Train: [51][360/750]	BT 0.093 (1.180)	DT 0.001 (1.049)	loss nan (nan)	prob nan (nan)	GS 33.078 (33.078)	mem 40.000
Train: [51][365/750]	BT 0.166 (1.166)	DT 0.001 (1.035)	loss nan (nan)	prob nan (nan)	GS 31.281 (31.281)	mem 40.003
Train: [51][370/750]	BT 10.450 (1.180)	DT 10.255 (1.049)	loss nan (nan)	prob nan (nan)	GS 33.281 (33.281)	mem 40.027
Train: [51][375/750]	BT 0.116 (1.166)	DT 0.006 (1.035)	loss nan (nan)	prob nan (nan)	GS 27.750 (27.750)	mem 40.033
Train: [51][380/750]	BT 0.142 (1.152)	DT 0.015 (1.021)	loss nan (nan)	prob nan (nan)	GS 33.484 (33.484)	mem 40.070
Train: [51][385/750]	BT 0.090 (1.167)	DT 0.002 (1.037)	loss nan (nan)	prob nan (nan)	GS 28.719 (28.719)	mem 39.984
Train: [51][390/750]	BT 0.141 (1.154)	DT 0.001 (1.024)	loss nan (nan)	prob nan (nan)	GS 32.531 (32.531)	mem 39.995
Train: [51][395/750]	BT 0.153 (1.172)	DT 0.002 (1.041)	loss nan (nan)	prob nan (nan)	GS 38.406 (38.406)	mem 39.844
Train: [51][400/750]	BT 0.131 (1.159)	DT 0.007 (1.028)	loss nan (nan)	prob nan (nan)	GS 33.141 (33.141)	mem 39.844
Train: [51][405/750]	BT 0.150 (1.146)	DT 0.001 (1.016)	loss nan (nan)	prob nan (nan)	GS 33.641 (33.641)	mem 39.951
Train: [51][410/750]	BT 0.089 (1.165)	DT 0.001 (1.035)	loss nan (nan)	prob nan (nan)	GS 36.078 (36.078)	mem 39.967
Train: [51][415/750]	BT 0.203 (1.152)	DT 0.001 (1.023)	loss nan (nan)	prob nan (nan)	GS 30.219 (30.219)	mem 39.982
Train: [51][420/750]	BT 0.115 (1.166)	DT 0.002 (1.036)	loss nan (nan)	prob nan (nan)	GS 30.750 (30.750)	mem 40.023
Train: [51][425/750]	BT 0.119 (1.154)	DT 0.006 (1.024)	loss nan (nan)	prob nan (nan)	GS 32.656 (32.656)	mem 39.986
Train: [51][430/750]	BT 11.929 (1.169)	DT 11.799 (1.039)	loss nan (nan)	prob nan (nan)	GS 31.516 (31.516)	mem 40.037
Train: [51][435/750]	BT 0.159 (1.158)	DT 0.010 (1.028)	loss nan (nan)	prob nan (nan)	GS 27.344 (27.344)	mem 39.955
Train: [51][440/750]	BT 0.116 (1.146)	DT 0.002 (1.016)	loss nan (nan)	prob nan (nan)	GS 33.734 (33.734)	mem 39.955
Train: [51][445/750]	BT 0.097 (1.159)	DT 0.001 (1.029)	loss nan (nan)	prob nan (nan)	GS 26.531 (26.531)	mem 40.127
Train: [51][450/750]	BT 0.085 (1.149)	DT 0.002 (1.019)	loss nan (nan)	prob nan (nan)	GS 34.859 (34.859)	mem 40.009
Train: [51][455/750]	BT 0.148 (1.164)	DT 0.001 (1.033)	loss nan (nan)	prob nan (nan)	GS 30.953 (30.953)	mem 39.958
Train: [51][460/750]	BT 0.138 (1.152)	DT 0.015 (1.022)	loss nan (nan)	prob nan (nan)	GS 36.469 (36.469)	mem 39.865
Train: [51][465/750]	BT 0.135 (1.142)	DT 0.002 (1.011)	loss nan (nan)	prob nan (nan)	GS 30.234 (30.234)	mem 39.914
Train: [51][470/750]	BT 0.476 (1.156)	DT 0.360 (1.026)	loss nan (nan)	prob nan (nan)	GS 27.188 (27.188)	mem 40.012
Train: [51][475/750]	BT 0.125 (1.146)	DT 0.004 (1.015)	loss nan (nan)	prob nan (nan)	GS 32.297 (32.297)	mem 40.018
Train: [51][480/750]	BT 0.180 (1.157)	DT 0.001 (1.026)	loss nan (nan)	prob nan (nan)	GS 32.922 (32.922)	mem 40.017
Train: [51][485/750]	BT 0.170 (1.158)	DT 0.002 (1.027)	loss nan (nan)	prob nan (nan)	GS 36.453 (36.453)	mem 39.915
Train: [51][490/750]	BT 4.740 (1.157)	DT 4.607 (1.026)	loss nan (nan)	prob nan (nan)	GS 33.078 (33.078)	mem 39.980
Train: [51][495/750]	BT 0.136 (1.167)	DT 0.012 (1.036)	loss nan (nan)	prob nan (nan)	GS 32.953 (32.953)	mem 39.933
Train: [51][500/750]	BT 0.210 (1.157)	DT 0.002 (1.026)	loss nan (nan)	prob nan (nan)	GS 34.641 (34.641)	mem 39.945
Train: [51][505/750]	BT 0.101 (1.146)	DT 0.002 (1.016)	loss nan (nan)	prob nan (nan)	GS 29.969 (29.969)	mem 39.946
Train: [51][510/750]	BT 0.092 (1.159)	DT 0.002 (1.028)	loss nan (nan)	prob nan (nan)	GS 39.250 (39.250)	mem 39.956
Train: [51][515/750]	BT 0.101 (1.149)	DT 0.008 (1.019)	loss nan (nan)	prob nan (nan)	GS 33.172 (33.172)	mem 39.957
Train: [51][520/750]	BT 0.080 (1.167)	DT 0.001 (1.036)	loss nan (nan)	prob nan (nan)	GS 34.375 (34.375)	mem 39.943
Train: [51][525/750]	BT 0.132 (1.157)	DT 0.011 (1.027)	loss nan (nan)	prob nan (nan)	GS 35.844 (35.844)	mem 39.945
Train: [51][530/750]	BT 10.946 (1.168)	DT 10.839 (1.037)	loss nan (nan)	prob nan (nan)	GS 36.594 (36.594)	mem 40.018
Train: [51][535/750]	BT 0.194 (1.158)	DT 0.004 (1.028)	loss nan (nan)	prob nan (nan)	GS 25.984 (25.984)	mem 40.074
Train: [51][540/750]	BT 0.088 (1.149)	DT 0.001 (1.018)	loss nan (nan)	prob nan (nan)	GS 31.859 (31.859)	mem 40.293
Train: [51][545/750]	BT 0.091 (1.160)	DT 0.006 (1.030)	loss nan (nan)	prob nan (nan)	GS 31.188 (31.188)	mem 40.028
Train: [51][550/750]	BT 0.155 (1.151)	DT 0.002 (1.020)	loss nan (nan)	prob nan (nan)	GS 34.203 (34.203)	mem 40.039
Train: [51][555/750]	BT 0.156 (1.165)	DT 0.006 (1.034)	loss nan (nan)	prob nan (nan)	GS 29.359 (29.359)	mem 40.045
Train: [51][560/750]	BT 0.067 (1.155)	DT 0.001 (1.025)	loss nan (nan)	prob nan (nan)	GS 34.047 (34.047)	mem 40.141
Train: [51][565/750]	BT 0.089 (1.146)	DT 0.001 (1.016)	loss nan (nan)	prob nan (nan)	GS 29.172 (29.172)	mem 40.053
Train: [51][570/750]	BT 0.118 (1.160)	DT 0.001 (1.030)	loss nan (nan)	prob nan (nan)	GS 33.156 (33.156)	mem 39.961
Train: [51][575/750]	BT 0.140 (1.151)	DT 0.012 (1.021)	loss nan (nan)	prob nan (nan)	GS 30.391 (30.391)	mem 39.985
Train: [51][580/750]	BT 0.083 (1.161)	DT 0.002 (1.032)	loss nan (nan)	prob nan (nan)	GS 35.297 (35.297)	mem 40.066
Train: [51][585/750]	BT 0.216 (1.153)	DT 0.012 (1.023)	loss nan (nan)	prob nan (nan)	GS 28.422 (28.422)	mem 40.069
Train: [51][590/750]	BT 10.258 (1.161)	DT 10.127 (1.031)	loss nan (nan)	prob nan (nan)	GS 30.516 (30.516)	mem 40.019
Train: [51][595/750]	BT 0.258 (1.153)	DT 0.022 (1.023)	loss nan (nan)	prob nan (nan)	GS 31.125 (31.125)	mem 40.061
Train: [51][600/750]	BT 1.772 (1.147)	DT 1.583 (1.017)	loss nan (nan)	prob nan (nan)	GS 35.016 (35.016)	mem 40.080
Train: [51][605/750]	BT 0.149 (1.156)	DT 0.001 (1.027)	loss nan (nan)	prob nan (nan)	GS 33.016 (33.016)	mem 40.092
Train: [51][610/750]	BT 0.155 (1.148)	DT 0.002 (1.019)	loss nan (nan)	prob nan (nan)	GS 35.719 (35.719)	mem 40.094
Train: [51][615/750]	BT 0.109 (1.158)	DT 0.003 (1.028)	loss nan (nan)	prob nan (nan)	GS 31.875 (31.875)	mem 40.260
Train: [51][620/750]	BT 0.107 (1.150)	DT 0.002 (1.020)	loss nan (nan)	prob nan (nan)	GS 36.625 (36.625)	mem 40.038
Train: [51][625/750]	BT 0.073 (1.146)	DT 0.002 (1.016)	loss nan (nan)	prob nan (nan)	GS 30.469 (30.469)	mem 40.070
Train: [51][630/750]	BT 0.080 (1.150)	DT 0.002 (1.020)	loss nan (nan)	prob nan (nan)	GS 35.531 (35.531)	mem 40.056
Train: [51][635/750]	BT 0.160 (1.144)	DT 0.002 (1.014)	loss nan (nan)	prob nan (nan)	GS 30.859 (30.859)	mem 40.113
Train: [51][640/750]	BT 0.116 (1.153)	DT 0.001 (1.024)	loss nan (nan)	prob nan (nan)	GS 36.359 (36.359)	mem 40.068
Train: [51][645/750]	BT 0.097 (1.145)	DT 0.002 (1.016)	loss nan (nan)	prob nan (nan)	GS 34.516 (34.516)	mem 40.071
Train: [51][650/750]	BT 11.242 (1.155)	DT 11.168 (1.025)	loss nan (nan)	prob nan (nan)	GS 34.109 (34.109)	mem 40.041
Train: [51][655/750]	BT 0.134 (1.147)	DT 0.002 (1.017)	loss nan (nan)	prob nan (nan)	GS 31.312 (31.312)	mem 40.060
Train: [51][660/750]	BT 0.152 (1.140)	DT 0.002 (1.010)	loss nan (nan)	prob nan (nan)	GS 31.594 (31.594)	mem 40.126
Train: [51][665/750]	BT 0.152 (1.148)	DT 0.005 (1.018)	loss nan (nan)	prob nan (nan)	GS 32.141 (32.141)	mem 40.108
Train: [51][670/750]	BT 0.130 (1.141)	DT 0.026 (1.011)	loss nan (nan)	prob nan (nan)	GS 31.609 (31.609)	mem 40.109
Train: [51][675/750]	BT 0.086 (1.151)	DT 0.001 (1.021)	loss nan (nan)	prob nan (nan)	GS 33.453 (33.453)	mem 40.002
Train: [51][680/750]	BT 0.144 (1.144)	DT 0.002 (1.014)	loss nan (nan)	prob nan (nan)	GS 36.953 (36.953)	mem 39.990
Train: [51][685/750]	BT 0.111 (1.138)	DT 0.013 (1.008)	loss nan (nan)	prob nan (nan)	GS 29.797 (29.797)	mem 40.033
Train: [51][690/750]	BT 0.078 (1.147)	DT 0.002 (1.018)	loss nan (nan)	prob nan (nan)	GS 31.031 (31.031)	mem 40.062
Train: [51][695/750]	BT 0.107 (1.140)	DT 0.002 (1.010)	loss nan (nan)	prob nan (nan)	GS 32.000 (32.000)	mem 40.079
Train: [51][700/750]	BT 1.772 (1.153)	DT 1.605 (1.024)	loss nan (nan)	prob nan (nan)	GS 36.031 (36.031)	mem 40.063
Train: [51][705/750]	BT 0.095 (1.146)	DT 0.002 (1.017)	loss nan (nan)	prob nan (nan)	GS 32.656 (32.656)	mem 40.089
arpack error, retry= 0
arpack error, retry= 0
Train: [51][710/750]	BT 10.458 (1.153)	DT 10.309 (1.024)	loss nan (nan)	prob nan (nan)	GS 34.453 (34.453)	mem 40.071
Train: [51][715/750]	BT 0.146 (1.150)	DT 0.017 (1.021)	loss nan (nan)	prob nan (nan)	GS 34.438 (34.438)	mem 40.058
Train: [51][720/750]	BT 0.112 (1.143)	DT 0.006 (1.014)	loss nan (nan)	prob nan (nan)	GS 35.250 (35.250)	mem 40.057
Train: [51][725/750]	BT 0.130 (1.151)	DT 0.010 (1.022)	loss nan (nan)	prob nan (nan)	GS 30.906 (30.906)	mem 39.977
Train: [51][730/750]	BT 0.105 (1.144)	DT 0.001 (1.015)	loss nan (nan)	prob nan (nan)	GS 32.891 (32.891)	mem 40.027
Train: [51][735/750]	BT 0.106 (1.149)	DT 0.012 (1.020)	loss nan (nan)	prob nan (nan)	GS 29.469 (29.469)	mem 36.735
Train: [51][740/750]	BT 0.104 (1.142)	DT 0.001 (1.014)	loss nan (nan)	prob nan (nan)	GS 35.016 (35.016)	mem 36.966
Train: [51][745/750]	BT 0.156 (1.135)	DT 0.014 (1.007)	loss nan (nan)	prob nan (nan)	GS 33.281 (33.281)	mem 36.742
Train: [51][750/750]	BT 0.063 (1.133)	DT 0.001 (1.005)	loss nan (nan)	prob nan (nan)	GS 36.031 (36.031)	mem 7.633
Train: [51][755/750]	BT 0.074 (1.126)	DT 0.001 (0.999)	loss nan (nan)	prob nan (nan)	GS 34.219 (34.219)	mem 7.632
epoch 51, total time 850.63
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [52][1/750]	BT 20.931 (20.931)	DT 20.743 (20.743)	loss nan (nan)	prob nan (nan)	GS 31.406 (31.406)	mem 39.226
Train: [52][5/750]	BT 0.190 (4.801)	DT 0.012 (4.624)	loss nan (nan)	prob nan (nan)	GS 27.031 (27.031)	mem 39.284
Train: [52][10/750]	BT 0.083 (2.519)	DT 0.001 (2.376)	loss nan (nan)	prob nan (nan)	GS 33.516 (33.516)	mem 39.556
Train: [52][15/750]	BT 0.098 (2.563)	DT 0.011 (2.403)	loss nan (nan)	prob nan (nan)	GS 32.516 (32.516)	mem 39.485
Train: [52][20/750]	BT 0.133 (2.008)	DT 0.008 (1.858)	loss nan (nan)	prob nan (nan)	GS 31.281 (31.281)	mem 39.504
Train: [52][25/750]	BT 0.160 (1.629)	DT 0.020 (1.487)	loss nan (nan)	prob nan (nan)	GS 34.953 (34.953)	mem 39.516
Train: [52][30/750]	BT 0.202 (1.773)	DT 0.001 (1.627)	loss nan (nan)	prob nan (nan)	GS 33.453 (33.453)	mem 39.560
Train: [52][35/750]	BT 0.207 (1.541)	DT 0.002 (1.395)	loss nan (nan)	prob nan (nan)	GS 32.547 (32.547)	mem 39.777
Train: [52][40/750]	BT 0.177 (1.617)	DT 0.001 (1.475)	loss nan (nan)	prob nan (nan)	GS 32.047 (32.047)	mem 39.595
Train: [52][45/750]	BT 0.110 (1.450)	DT 0.008 (1.311)	loss nan (nan)	prob nan (nan)	GS 31.359 (31.359)	mem 39.598
Train: [52][50/750]	BT 11.878 (1.566)	DT 11.773 (1.427)	loss nan (nan)	prob nan (nan)	GS 34.328 (34.328)	mem 39.767
Train: [52][55/750]	BT 0.185 (1.438)	DT 0.001 (1.297)	loss nan (nan)	prob nan (nan)	GS 31.578 (31.578)	mem 39.738
Train: [52][60/750]	BT 0.136 (1.334)	DT 0.004 (1.195)	loss nan (nan)	prob nan (nan)	GS 35.188 (35.188)	mem 39.613
Train: [52][65/750]	BT 0.106 (1.497)	DT 0.001 (1.358)	loss nan (nan)	prob nan (nan)	GS 28.391 (28.391)	mem 39.761
Train: [52][70/750]	BT 0.078 (1.398)	DT 0.002 (1.261)	loss nan (nan)	prob nan (nan)	GS 35.828 (35.828)	mem 39.764
Train: [52][75/750]	BT 0.096 (1.480)	DT 0.002 (1.346)	loss nan (nan)	prob nan (nan)	GS 32.281 (32.281)	mem 39.819
Train: [52][80/750]	BT 0.109 (1.394)	DT 0.001 (1.262)	loss nan (nan)	prob nan (nan)	GS 30.438 (30.438)	mem 39.819
Train: [52][85/750]	BT 0.090 (1.319)	DT 0.002 (1.188)	loss nan (nan)	prob nan (nan)	GS 32.141 (32.141)	mem 39.858
Train: [52][90/750]	BT 0.151 (1.424)	DT 0.010 (1.291)	loss nan (nan)	prob nan (nan)	GS 37.125 (37.125)	mem 39.834
Train: [52][95/750]	BT 0.178 (1.355)	DT 0.001 (1.224)	loss nan (nan)	prob nan (nan)	GS 29.984 (29.984)	mem 39.774
Train: [52][100/750]	BT 0.079 (1.429)	DT 0.001 (1.300)	loss nan (nan)	prob nan (nan)	GS 33.062 (33.062)	mem 39.862
Train: [52][105/750]	BT 0.080 (1.365)	DT 0.001 (1.238)	loss nan (nan)	prob nan (nan)	GS 34.547 (34.547)	mem 39.863
Train: [52][110/750]	BT 13.496 (1.429)	DT 13.392 (1.303)	loss nan (nan)	prob nan (nan)	GS 34.609 (34.609)	mem 39.882
Train: [52][115/750]	BT 0.086 (1.372)	DT 0.002 (1.247)	loss nan (nan)	prob nan (nan)	GS 32.875 (32.875)	mem 39.887
Train: [52][120/750]	BT 0.148 (1.322)	DT 0.002 (1.195)	loss nan (nan)	prob nan (nan)	GS 36.203 (36.203)	mem 39.949
Train: [52][125/750]	BT 0.085 (1.365)	DT 0.001 (1.239)	loss nan (nan)	prob nan (nan)	GS 29.109 (29.109)	mem 39.966
Train: [52][130/750]	BT 0.151 (1.318)	DT 0.001 (1.192)	loss nan (nan)	prob nan (nan)	GS 36.734 (36.734)	mem 39.888
Train: [52][135/750]	BT 0.095 (1.360)	DT 0.001 (1.232)	loss nan (nan)	prob nan (nan)	GS 30.328 (30.328)	mem 39.930
Train: [52][140/750]	BT 0.110 (1.315)	DT 0.001 (1.188)	loss nan (nan)	prob nan (nan)	GS 31.812 (31.812)	mem 39.940
Train: [52][145/750]	BT 0.204 (1.274)	DT 0.002 (1.148)	loss nan (nan)	prob nan (nan)	GS 32.328 (32.328)	mem 40.153
Train: [52][150/750]	BT 0.138 (1.310)	DT 0.002 (1.184)	loss nan (nan)	prob nan (nan)	GS 37.219 (37.219)	mem 39.958
Train: [52][155/750]	BT 0.222 (1.273)	DT 0.002 (1.146)	loss nan (nan)	prob nan (nan)	GS 29.547 (29.547)	mem 39.959
Train: [52][160/750]	BT 0.134 (1.299)	DT 0.011 (1.172)	loss nan (nan)	prob nan (nan)	GS 34.156 (34.156)	mem 40.113
Train: [52][165/750]	BT 0.105 (1.263)	DT 0.001 (1.137)	loss nan (nan)	prob nan (nan)	GS 29.406 (29.406)	mem 40.046
Train: [52][170/750]	BT 12.399 (1.301)	DT 12.281 (1.176)	loss nan (nan)	prob nan (nan)	GS 32.922 (32.922)	mem 39.951
Train: [52][175/750]	BT 0.118 (1.267)	DT 0.001 (1.142)	loss nan (nan)	prob nan (nan)	GS 33.969 (33.969)	mem 40.007
Train: [52][180/750]	BT 0.146 (1.236)	DT 0.002 (1.111)	loss nan (nan)	prob nan (nan)	GS 34.500 (34.500)	mem 39.959
Train: [52][185/750]	BT 0.098 (1.275)	DT 0.001 (1.149)	loss nan (nan)	prob nan (nan)	GS 28.141 (28.141)	mem 39.988
Train: [52][190/750]	BT 0.245 (1.245)	DT 0.005 (1.119)	loss nan (nan)	prob nan (nan)	GS 33.484 (33.484)	mem 40.242
Train: [52][195/750]	BT 0.091 (1.284)	DT 0.009 (1.159)	loss nan (nan)	prob nan (nan)	GS 31.141 (31.141)	mem 39.840
Train: [52][200/750]	BT 0.088 (1.255)	DT 0.002 (1.130)	loss nan (nan)	prob nan (nan)	GS 32.734 (32.734)	mem 39.894
Train: [52][205/750]	BT 0.191 (1.229)	DT 0.014 (1.103)	loss nan (nan)	prob nan (nan)	GS 33.094 (33.094)	mem 39.896
Train: [52][210/750]	BT 0.151 (1.271)	DT 0.062 (1.146)	loss nan (nan)	prob nan (nan)	GS 33.891 (33.891)	mem 39.753
Train: [52][215/750]	BT 0.104 (1.244)	DT 0.002 (1.119)	loss nan (nan)	prob nan (nan)	GS 31.969 (31.969)	mem 39.782
Train: [52][220/750]	BT 0.104 (1.274)	DT 0.001 (1.149)	loss nan (nan)	prob nan (nan)	GS 35.047 (35.047)	mem 39.898
Train: [52][225/750]	BT 0.096 (1.248)	DT 0.002 (1.124)	loss nan (nan)	prob nan (nan)	GS 30.875 (30.875)	mem 39.900
Train: [52][230/750]	BT 12.871 (1.279)	DT 12.752 (1.155)	loss nan (nan)	prob nan (nan)	GS 36.344 (36.344)	mem 39.843
Train: [52][235/750]	BT 0.099 (1.254)	DT 0.007 (1.130)	loss nan (nan)	prob nan (nan)	GS 27.516 (27.516)	mem 39.778
Train: [52][240/750]	BT 0.091 (1.231)	DT 0.002 (1.107)	loss nan (nan)	prob nan (nan)	GS 35.172 (35.172)	mem 39.869
Train: [52][245/750]	BT 0.061 (1.258)	DT 0.001 (1.134)	loss nan (nan)	prob nan (nan)	GS 37.719 (37.719)	mem 39.915
Train: [52][250/750]	BT 0.142 (1.235)	DT 0.001 (1.112)	loss nan (nan)	prob nan (nan)	GS 31.641 (31.641)	mem 39.916
Train: [52][255/750]	BT 0.103 (1.273)	DT 0.001 (1.149)	loss nan (nan)	prob nan (nan)	GS 31.250 (31.250)	mem 39.875
Train: [52][260/750]	BT 0.143 (1.250)	DT 0.002 (1.127)	loss nan (nan)	prob nan (nan)	GS 36.328 (36.328)	mem 39.934
Train: [52][265/750]	BT 0.146 (1.228)	DT 0.020 (1.106)	loss nan (nan)	prob nan (nan)	GS 32.062 (32.062)	mem 39.844
Train: [52][270/750]	BT 0.075 (1.257)	DT 0.002 (1.135)	loss nan (nan)	prob nan (nan)	GS 35.266 (35.266)	mem 39.802
Train: [52][275/750]	BT 0.084 (1.236)	DT 0.002 (1.114)	loss nan (nan)	prob nan (nan)	GS 28.672 (28.672)	mem 39.848
Train: [52][280/750]	BT 0.205 (1.256)	DT 0.002 (1.134)	loss nan (nan)	prob nan (nan)	GS 30.172 (30.172)	mem 40.024
Train: [52][285/750]	BT 0.095 (1.237)	DT 0.001 (1.115)	loss nan (nan)	prob nan (nan)	GS 30.875 (30.875)	mem 39.972
Train: [52][290/750]	BT 14.349 (1.267)	DT 14.242 (1.145)	loss nan (nan)	prob nan (nan)	GS 34.250 (34.250)	mem 39.963
Train: [52][295/750]	BT 0.126 (1.247)	DT 0.016 (1.125)	loss nan (nan)	prob nan (nan)	GS 30.391 (30.391)	mem 40.070
Train: [52][300/750]	BT 0.144 (1.228)	DT 0.002 (1.107)	loss nan (nan)	prob nan (nan)	GS 36.188 (36.188)	mem 39.991
Train: [52][305/750]	BT 0.086 (1.256)	DT 0.002 (1.134)	loss nan (nan)	prob nan (nan)	GS 30.609 (30.609)	mem 39.832
Train: [52][310/750]	BT 0.195 (1.239)	DT 0.012 (1.116)	loss nan (nan)	prob nan (nan)	GS 39.812 (39.812)	mem 40.144
Train: [52][315/750]	BT 0.085 (1.261)	DT 0.001 (1.139)	loss nan (nan)	prob nan (nan)	GS 30.266 (30.266)	mem 39.947
Train: [52][320/750]	BT 0.110 (1.243)	DT 0.001 (1.121)	loss nan (nan)	prob nan (nan)	GS 34.812 (34.812)	mem 39.881
Train: [52][325/750]	BT 0.147 (1.227)	DT 0.004 (1.104)	loss nan (nan)	prob nan (nan)	GS 28.297 (28.297)	mem 39.952
Train: [52][330/750]	BT 0.085 (1.247)	DT 0.002 (1.124)	loss nan (nan)	prob nan (nan)	GS 35.594 (35.594)	mem 39.803
Train: [52][335/750]	BT 0.118 (1.230)	DT 0.016 (1.107)	loss nan (nan)	prob nan (nan)	GS 32.484 (32.484)	mem 39.838
Train: [52][340/750]	BT 0.106 (1.250)	DT 0.002 (1.128)	loss nan (nan)	prob nan (nan)	GS 33.391 (33.391)	mem 39.930
Train: [52][345/750]	BT 0.098 (1.233)	DT 0.002 (1.111)	loss nan (nan)	prob nan (nan)	GS 32.031 (32.031)	mem 39.887
Train: [52][350/750]	BT 11.656 (1.250)	DT 11.578 (1.129)	loss nan (nan)	prob nan (nan)	GS 34.641 (34.641)	mem 40.014
Train: [52][355/750]	BT 0.099 (1.234)	DT 0.001 (1.113)	loss nan (nan)	prob nan (nan)	GS 28.297 (28.297)	mem 40.017
Train: [52][360/750]	BT 0.150 (1.219)	DT 0.002 (1.097)	loss nan (nan)	prob nan (nan)	GS 35.000 (35.000)	mem 40.018
Train: [52][365/750]	BT 0.082 (1.239)	DT 0.001 (1.118)	loss nan (nan)	prob nan (nan)	GS 34.281 (34.281)	mem 40.053
Train: [52][370/750]	BT 0.153 (1.224)	DT 0.004 (1.103)	loss nan (nan)	prob nan (nan)	GS 33.062 (33.062)	mem 40.143
Train: [52][375/750]	BT 0.073 (1.243)	DT 0.001 (1.123)	loss nan (nan)	prob nan (nan)	GS 29.625 (29.625)	mem 39.877
Train: [52][380/750]	BT 0.082 (1.228)	DT 0.001 (1.108)	loss nan (nan)	prob nan (nan)	GS 35.922 (35.922)	mem 39.889
Train: [52][385/750]	BT 0.084 (1.213)	DT 0.001 (1.094)	loss nan (nan)	prob nan (nan)	GS 31.609 (31.609)	mem 39.908
Train: [52][390/750]	BT 0.146 (1.227)	DT 0.001 (1.108)	loss nan (nan)	prob nan (nan)	GS 31.953 (31.953)	mem 39.967
Train: [52][395/750]	BT 0.080 (1.213)	DT 0.001 (1.094)	loss nan (nan)	prob nan (nan)	GS 32.094 (32.094)	mem 40.010
Train: [52][400/750]	BT 0.132 (1.226)	DT 0.010 (1.106)	loss nan (nan)	prob nan (nan)	GS 33.047 (33.047)	mem 40.077
Train: [52][405/750]	BT 0.108 (1.212)	DT 0.009 (1.093)	loss nan (nan)	prob nan (nan)	GS 30.016 (30.016)	mem 40.084
Train: [52][410/750]	BT 11.112 (1.226)	DT 11.034 (1.106)	loss nan (nan)	prob nan (nan)	GS 34.141 (34.141)	mem 40.020
Train: [52][415/750]	BT 0.088 (1.212)	DT 0.002 (1.093)	loss nan (nan)	prob nan (nan)	GS 27.688 (27.688)	mem 40.031
Train: [52][420/750]	BT 0.108 (1.200)	DT 0.002 (1.080)	loss nan (nan)	prob nan (nan)	GS 32.391 (32.391)	mem 40.065
Train: [52][425/750]	BT 0.170 (1.210)	DT 0.001 (1.090)	loss nan (nan)	prob nan (nan)	GS 34.125 (34.125)	mem 40.029
Train: [52][430/750]	BT 0.121 (1.198)	DT 0.002 (1.077)	loss nan (nan)	prob nan (nan)	GS 36.844 (36.844)	mem 40.030
Train: [52][435/750]	BT 0.083 (1.214)	DT 0.005 (1.093)	loss nan (nan)	prob nan (nan)	GS 32.859 (32.859)	mem 39.954
Train: [52][440/750]	BT 0.086 (1.201)	DT 0.008 (1.081)	loss nan (nan)	prob nan (nan)	GS 36.359 (36.359)	mem 39.953
Train: [52][445/750]	BT 0.111 (1.189)	DT 0.001 (1.069)	loss nan (nan)	prob nan (nan)	GS 27.781 (27.781)	mem 40.063
Train: [52][450/750]	BT 0.205 (1.199)	DT 0.002 (1.079)	loss nan (nan)	prob nan (nan)	GS 35.188 (35.188)	mem 40.033
Train: [52][455/750]	BT 0.110 (1.187)	DT 0.006 (1.067)	loss nan (nan)	prob nan (nan)	GS 28.859 (28.859)	mem 39.990
Train: [52][460/750]	BT 0.107 (1.204)	DT 0.001 (1.083)	loss nan (nan)	prob nan (nan)	GS 35.031 (35.031)	mem 39.975
Train: [52][465/750]	BT 0.214 (1.192)	DT 0.006 (1.072)	loss nan (nan)	prob nan (nan)	GS 30.078 (30.078)	mem 40.038
Train: [52][470/750]	BT 11.307 (1.205)	DT 11.173 (1.084)	loss nan (nan)	prob nan (nan)	GS 36.047 (36.047)	mem 40.001
Train: [52][475/750]	BT 0.069 (1.193)	DT 0.001 (1.073)	loss nan (nan)	prob nan (nan)	GS 28.156 (28.156)	mem 39.987
Train: [52][480/750]	BT 0.104 (1.182)	DT 0.002 (1.062)	loss nan (nan)	prob nan (nan)	GS 32.969 (32.969)	mem 39.988
Train: [52][485/750]	BT 0.199 (1.191)	DT 0.002 (1.070)	loss nan (nan)	prob nan (nan)	GS 31.703 (31.703)	mem 40.199
Train: [52][490/750]	BT 0.159 (1.180)	DT 0.004 (1.059)	loss nan (nan)	prob nan (nan)	GS 32.484 (32.484)	mem 40.056
Train: [52][495/750]	BT 0.205 (1.196)	DT 0.001 (1.074)	loss nan (nan)	prob nan (nan)	GS 33.500 (33.500)	mem 39.914
Train: [52][500/750]	BT 0.102 (1.185)	DT 0.002 (1.064)	loss nan (nan)	prob nan (nan)	GS 28.312 (28.312)	mem 39.971
Train: [52][505/750]	BT 0.188 (1.175)	DT 0.002 (1.053)	loss nan (nan)	prob nan (nan)	GS 30.922 (30.922)	mem 39.948
Train: [52][510/750]	BT 0.083 (1.190)	DT 0.001 (1.068)	loss nan (nan)	prob nan (nan)	GS 34.766 (34.766)	mem 39.972
Train: [52][515/750]	BT 0.250 (1.180)	DT 0.018 (1.058)	loss nan (nan)	prob nan (nan)	GS 28.984 (28.984)	mem 39.993
Train: [52][520/750]	BT 0.120 (1.201)	DT 0.007 (1.079)	loss nan (nan)	prob nan (nan)	GS 33.984 (33.984)	mem 40.034
Train: [52][525/750]	BT 0.075 (1.191)	DT 0.002 (1.068)	loss nan (nan)	prob nan (nan)	GS 31.125 (31.125)	mem 39.961
Train: [52][530/750]	BT 8.312 (1.196)	DT 8.059 (1.074)	loss nan (nan)	prob nan (nan)	GS 29.578 (29.578)	mem 39.933
Train: [52][535/750]	BT 0.199 (1.186)	DT 0.001 (1.064)	loss nan (nan)	prob nan (nan)	GS 29.156 (29.156)	mem 40.138
Train: [52][540/750]	BT 0.136 (1.176)	DT 0.005 (1.054)	loss nan (nan)	prob nan (nan)	GS 32.828 (32.828)	mem 39.971
Train: [52][545/750]	BT 0.121 (1.191)	DT 0.008 (1.069)	loss nan (nan)	prob nan (nan)	GS 33.094 (33.094)	mem 40.035
Train: [52][550/750]	BT 0.227 (1.181)	DT 0.009 (1.059)	loss nan (nan)	prob nan (nan)	GS 34.688 (34.688)	mem 40.047
Train: [52][555/750]	BT 0.226 (1.192)	DT 0.017 (1.069)	loss nan (nan)	prob nan (nan)	GS 32.906 (32.906)	mem 40.005
Train: [52][560/750]	BT 0.118 (1.182)	DT 0.001 (1.059)	loss nan (nan)	prob nan (nan)	GS 35.875 (35.875)	mem 39.974
Train: [52][565/750]	BT 0.140 (1.173)	DT 0.001 (1.050)	loss nan (nan)	prob nan (nan)	GS 32.062 (32.062)	mem 39.979
Train: [52][570/750]	BT 0.352 (1.184)	DT 0.008 (1.061)	loss nan (nan)	prob nan (nan)	GS 32.922 (32.922)	mem 40.072
Train: [52][575/750]	BT 0.107 (1.175)	DT 0.003 (1.052)	loss nan (nan)	prob nan (nan)	GS 29.938 (29.938)	mem 39.930
Train: [52][580/750]	BT 0.115 (1.188)	DT 0.002 (1.065)	loss nan (nan)	prob nan (nan)	GS 36.969 (36.969)	mem 40.173
Train: [52][585/750]	BT 0.137 (1.179)	DT 0.006 (1.056)	loss nan (nan)	prob nan (nan)	GS 33.172 (33.172)	mem 40.157
Train: [52][590/750]	BT 11.209 (1.189)	DT 11.120 (1.066)	loss nan (nan)	prob nan (nan)	GS 33.078 (33.078)	mem 40.067
Train: [52][595/750]	BT 0.129 (1.180)	DT 0.007 (1.057)	loss nan (nan)	prob nan (nan)	GS 27.953 (27.953)	mem 40.061
Train: [52][600/750]	BT 0.084 (1.171)	DT 0.001 (1.049)	loss nan (nan)	prob nan (nan)	GS 34.984 (34.984)	mem 39.996
Train: [52][605/750]	BT 0.096 (1.184)	DT 0.002 (1.061)	loss nan (nan)	prob nan (nan)	GS 32.281 (32.281)	mem 39.918
Train: [52][610/750]	BT 0.119 (1.175)	DT 0.004 (1.052)	loss nan (nan)	prob nan (nan)	GS 30.547 (30.547)	mem 39.917
Train: [52][615/750]	BT 0.092 (1.183)	DT 0.002 (1.060)	loss nan (nan)	prob nan (nan)	GS 29.797 (29.797)	mem 40.046
Train: [52][620/750]	BT 0.088 (1.174)	DT 0.002 (1.052)	loss nan (nan)	prob nan (nan)	GS 34.969 (34.969)	mem 40.000
Train: [52][625/750]	BT 0.219 (1.166)	DT 0.005 (1.043)	loss nan (nan)	prob nan (nan)	GS 31.031 (31.031)	mem 40.004
Train: [52][630/750]	BT 0.090 (1.176)	DT 0.001 (1.054)	loss nan (nan)	prob nan (nan)	GS 33.594 (33.594)	mem 39.996
Train: [52][635/750]	BT 0.091 (1.168)	DT 0.002 (1.045)	loss nan (nan)	prob nan (nan)	GS 25.391 (25.391)	mem 40.003
Train: [52][640/750]	BT 0.116 (1.178)	DT 0.005 (1.055)	loss nan (nan)	prob nan (nan)	GS 35.281 (35.281)	mem 39.927
Train: [52][645/750]	BT 0.135 (1.170)	DT 0.002 (1.047)	loss nan (nan)	prob nan (nan)	GS 28.828 (28.828)	mem 39.960
Train: [52][650/750]	BT 13.050 (1.182)	DT 12.948 (1.059)	loss nan (nan)	prob nan (nan)	GS 34.812 (34.812)	mem 39.934
Train: [52][655/750]	BT 0.169 (1.174)	DT 0.001 (1.051)	loss nan (nan)	prob nan (nan)	GS 28.688 (28.688)	mem 39.965
Train: [52][660/750]	BT 0.078 (1.166)	DT 0.001 (1.043)	loss nan (nan)	prob nan (nan)	GS 31.562 (31.562)	mem 39.968
Train: [52][665/750]	BT 0.173 (1.172)	DT 0.001 (1.050)	loss nan (nan)	prob nan (nan)	GS 32.031 (32.031)	mem 40.134
Train: [52][670/750]	BT 0.183 (1.165)	DT 0.002 (1.042)	loss nan (nan)	prob nan (nan)	GS 33.938 (33.938)	mem 40.271
Train: [52][675/750]	BT 0.107 (1.175)	DT 0.002 (1.052)	loss nan (nan)	prob nan (nan)	GS 40.125 (40.125)	mem 40.040
Train: [52][680/750]	BT 0.703 (1.168)	DT 0.497 (1.045)	loss nan (nan)	prob nan (nan)	GS 37.422 (37.422)	mem 40.225
Train: [52][685/750]	BT 0.194 (1.160)	DT 0.002 (1.037)	loss nan (nan)	prob nan (nan)	GS 30.688 (30.688)	mem 40.184
Train: [52][690/750]	BT 0.077 (1.172)	DT 0.001 (1.049)	loss nan (nan)	prob nan (nan)	GS 36.875 (36.875)	mem 39.990
Train: [52][695/750]	BT 0.110 (1.164)	DT 0.002 (1.041)	loss nan (nan)	prob nan (nan)	GS 28.594 (28.594)	mem 39.994
Train: [52][700/750]	BT 0.071 (1.175)	DT 0.001 (1.053)	loss nan (nan)	prob nan (nan)	GS 33.734 (33.734)	mem 40.009
Train: [52][705/750]	BT 0.199 (1.168)	DT 0.035 (1.045)	loss nan (nan)	prob nan (nan)	GS 32.266 (32.266)	mem 40.011
arpack error, retry= 0
arpack error, retry= 0
Train: [52][710/750]	BT 11.646 (1.177)	DT 11.465 (1.054)	loss nan (nan)	prob nan (nan)	GS 33.547 (33.547)	mem 40.098
Train: [52][715/750]	BT 0.194 (1.169)	DT 0.002 (1.047)	loss nan (nan)	prob nan (nan)	GS 29.812 (29.812)	mem 40.169
Train: [52][720/750]	BT 0.108 (1.162)	DT 0.001 (1.040)	loss nan (nan)	prob nan (nan)	GS 31.766 (31.766)	mem 40.101
Train: [52][725/750]	BT 0.113 (1.173)	DT 0.011 (1.050)	loss nan (nan)	prob nan (nan)	GS 30.000 (30.000)	mem 40.344
Train: [52][730/750]	BT 0.144 (1.166)	DT 0.001 (1.043)	loss nan (nan)	prob nan (nan)	GS 33.453 (33.453)	mem 40.010
Train: [52][735/750]	BT 0.087 (1.168)	DT 0.007 (1.046)	loss nan (nan)	prob nan (nan)	GS 29.891 (29.891)	mem 36.516
Train: [52][740/750]	BT 0.169 (1.161)	DT 0.023 (1.039)	loss nan (nan)	prob nan (nan)	GS 31.844 (31.844)	mem 31.714
Train: [52][745/750]	BT 0.075 (1.154)	DT 0.001 (1.032)	loss nan (nan)	prob nan (nan)	GS 35.312 (35.312)	mem 22.184
Train: [52][750/750]	BT 0.069 (1.151)	DT 0.001 (1.029)	loss nan (nan)	prob nan (nan)	GS 32.344 (32.344)	mem 7.641
Train: [52][755/750]	BT 0.070 (1.144)	DT 0.001 (1.022)	loss nan (nan)	prob nan (nan)	GS 30.906 (30.906)	mem 7.641
epoch 52, total time 863.67
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [53][1/750]	BT 21.316 (21.316)	DT 21.105 (21.105)	loss nan (nan)	prob nan (nan)	GS 35.359 (35.359)	mem 38.637
Train: [53][5/750]	BT 0.066 (4.462)	DT 0.001 (4.333)	loss nan (nan)	prob nan (nan)	GS 31.547 (31.547)	mem 38.648
Train: [53][10/750]	BT 0.114 (2.284)	DT 0.001 (2.167)	loss nan (nan)	prob nan (nan)	GS 32.828 (32.828)	mem 38.651
Train: [53][15/750]	BT 0.120 (2.107)	DT 0.008 (1.986)	loss nan (nan)	prob nan (nan)	GS 33.312 (33.312)	mem 38.905
Train: [53][20/750]	BT 0.222 (1.928)	DT 0.002 (1.805)	loss nan (nan)	prob nan (nan)	GS 35.953 (35.953)	mem 38.894
Train: [53][25/750]	BT 4.255 (1.735)	DT 4.139 (1.610)	loss nan (nan)	prob nan (nan)	GS 26.922 (26.922)	mem 38.917
Train: [53][30/750]	BT 0.150 (1.688)	DT 0.002 (1.558)	loss nan (nan)	prob nan (nan)	GS 29.812 (29.812)	mem 38.964
Train: [53][35/750]	BT 0.118 (1.467)	DT 0.002 (1.335)	loss nan (nan)	prob nan (nan)	GS 30.266 (30.266)	mem 38.967
Train: [53][40/750]	BT 0.205 (1.644)	DT 0.004 (1.507)	loss nan (nan)	prob nan (nan)	GS 36.109 (36.109)	mem 39.130
Train: [53][45/750]	BT 0.180 (1.630)	DT 0.022 (1.495)	loss nan (nan)	prob nan (nan)	GS 30.469 (30.469)	mem 39.026
Train: [53][50/750]	BT 7.566 (1.628)	DT 7.333 (1.492)	loss nan (nan)	prob nan (nan)	GS 33.516 (33.516)	mem 39.080
Train: [53][55/750]	BT 0.114 (1.491)	DT 0.002 (1.357)	loss nan (nan)	prob nan (nan)	GS 32.125 (32.125)	mem 39.154
Train: [53][60/750]	BT 0.204 (1.462)	DT 0.005 (1.325)	loss nan (nan)	prob nan (nan)	GS 29.516 (29.516)	mem 39.101
Train: [53][65/750]	BT 0.093 (1.468)	DT 0.001 (1.334)	loss nan (nan)	prob nan (nan)	GS 36.344 (36.344)	mem 39.240
Train: [53][70/750]	BT 0.155 (1.404)	DT 0.005 (1.269)	loss nan (nan)	prob nan (nan)	GS 33.781 (33.781)	mem 39.133
Train: [53][75/750]	BT 0.102 (1.442)	DT 0.007 (1.307)	loss nan (nan)	prob nan (nan)	GS 32.188 (32.188)	mem 39.390
Train: [53][80/750]	BT 2.689 (1.393)	DT 2.531 (1.258)	loss nan (nan)	prob nan (nan)	GS 35.141 (35.141)	mem 39.092
Train: [53][85/750]	BT 0.128 (1.320)	DT 0.002 (1.184)	loss nan (nan)	prob nan (nan)	GS 35.219 (35.219)	mem 39.086
Train: [53][90/750]	BT 0.167 (1.388)	DT 0.002 (1.252)	loss nan (nan)	prob nan (nan)	GS 34.125 (34.125)	mem 39.141
Train: [53][95/750]	BT 0.176 (1.323)	DT 0.006 (1.186)	loss nan (nan)	prob nan (nan)	GS 27.438 (27.438)	mem 39.052
Train: [53][100/750]	BT 3.683 (1.384)	DT 3.587 (1.248)	loss nan (nan)	prob nan (nan)	GS 32.359 (32.359)	mem 39.197
Train: [53][105/750]	BT 0.153 (1.323)	DT 0.002 (1.189)	loss nan (nan)	prob nan (nan)	GS 34.641 (34.641)	mem 39.207
Train: [53][110/750]	BT 7.843 (1.365)	DT 7.681 (1.231)	loss nan (nan)	prob nan (nan)	GS 36.062 (36.062)	mem 39.440
Train: [53][115/750]	BT 0.130 (1.376)	DT 0.002 (1.243)	loss nan (nan)	prob nan (nan)	GS 29.703 (29.703)	mem 39.351
Train: [53][120/750]	BT 0.102 (1.324)	DT 0.018 (1.191)	loss nan (nan)	prob nan (nan)	GS 39.031 (39.031)	mem 39.356
Train: [53][125/750]	BT 0.090 (1.394)	DT 0.002 (1.260)	loss nan (nan)	prob nan (nan)	GS 31.500 (31.500)	mem 39.498
Train: [53][130/750]	BT 0.192 (1.345)	DT 0.017 (1.211)	loss nan (nan)	prob nan (nan)	GS 36.531 (36.531)	mem 39.501
Train: [53][135/750]	BT 0.147 (1.301)	DT 0.008 (1.167)	loss nan (nan)	prob nan (nan)	GS 29.562 (29.562)	mem 39.500
Train: [53][140/750]	BT 0.295 (1.333)	DT 0.007 (1.199)	loss nan (nan)	prob nan (nan)	GS 30.625 (30.625)	mem 39.593
Train: [53][145/750]	BT 0.094 (1.291)	DT 0.002 (1.157)	loss nan (nan)	prob nan (nan)	GS 29.250 (29.250)	mem 39.682
Train: [53][150/750]	BT 0.096 (1.332)	DT 0.001 (1.200)	loss nan (nan)	prob nan (nan)	GS 35.219 (35.219)	mem 39.704
Train: [53][155/750]	BT 0.088 (1.293)	DT 0.002 (1.161)	loss nan (nan)	prob nan (nan)	GS 30.109 (30.109)	mem 39.710
Train: [53][160/750]	BT 14.970 (1.350)	DT 14.847 (1.218)	loss nan (nan)	prob nan (nan)	GS 35.391 (35.391)	mem 39.819
Train: [53][165/750]	BT 0.225 (1.313)	DT 0.002 (1.181)	loss nan (nan)	prob nan (nan)	GS 36.188 (36.188)	mem 39.848
Train: [53][170/750]	BT 0.152 (1.279)	DT 0.004 (1.147)	loss nan (nan)	prob nan (nan)	GS 32.625 (32.625)	mem 39.821
Train: [53][175/750]	BT 0.114 (1.328)	DT 0.002 (1.197)	loss nan (nan)	prob nan (nan)	GS 29.219 (29.219)	mem 39.798
Train: [53][180/750]	BT 0.203 (1.295)	DT 0.001 (1.164)	loss nan (nan)	prob nan (nan)	GS 30.516 (30.516)	mem 39.802
Train: [53][185/750]	BT 0.093 (1.322)	DT 0.001 (1.190)	loss nan (nan)	prob nan (nan)	GS 29.062 (29.062)	mem 40.032
Train: [53][190/750]	BT 0.107 (1.290)	DT 0.001 (1.159)	loss nan (nan)	prob nan (nan)	GS 32.516 (32.516)	mem 39.893
Train: [53][195/750]	BT 0.170 (1.261)	DT 0.003 (1.129)	loss nan (nan)	prob nan (nan)	GS 33.062 (33.062)	mem 39.919
Train: [53][200/750]	BT 0.130 (1.298)	DT 0.001 (1.167)	loss nan (nan)	prob nan (nan)	GS 34.266 (34.266)	mem 39.977
Train: [53][205/750]	BT 0.109 (1.269)	DT 0.001 (1.139)	loss nan (nan)	prob nan (nan)	GS 31.688 (31.688)	mem 39.919
Train: [53][210/750]	BT 0.121 (1.291)	DT 0.001 (1.161)	loss nan (nan)	prob nan (nan)	GS 31.391 (31.391)	mem 39.923
Train: [53][215/750]	BT 0.119 (1.264)	DT 0.001 (1.134)	loss nan (nan)	prob nan (nan)	GS 39.938 (39.938)	mem 39.936
Train: [53][220/750]	BT 12.444 (1.295)	DT 12.339 (1.164)	loss nan (nan)	prob nan (nan)	GS 33.016 (33.016)	mem 39.940
Train: [53][225/750]	BT 0.138 (1.269)	DT 0.011 (1.139)	loss nan (nan)	prob nan (nan)	GS 30.281 (30.281)	mem 39.945
Train: [53][230/750]	BT 0.176 (1.245)	DT 0.002 (1.114)	loss nan (nan)	prob nan (nan)	GS 35.125 (35.125)	mem 40.008
Train: [53][235/750]	BT 0.184 (1.261)	DT 0.007 (1.130)	loss nan (nan)	prob nan (nan)	GS 27.031 (27.031)	mem 40.004
Train: [53][240/750]	BT 0.244 (1.238)	DT 0.001 (1.107)	loss nan (nan)	prob nan (nan)	GS 33.781 (33.781)	mem 40.006
Train: [53][245/750]	BT 0.253 (1.253)	DT 0.005 (1.121)	loss nan (nan)	prob nan (nan)	GS 32.125 (32.125)	mem 40.088
Train: [53][250/750]	BT 0.095 (1.230)	DT 0.009 (1.099)	loss nan (nan)	prob nan (nan)	GS 29.219 (29.219)	mem 39.943
Train: [53][255/750]	BT 0.132 (1.208)	DT 0.005 (1.077)	loss nan (nan)	prob nan (nan)	GS 28.641 (28.641)	mem 40.044
Train: [53][260/750]	BT 0.206 (1.226)	DT 0.002 (1.095)	loss nan (nan)	prob nan (nan)	GS 41.359 (41.359)	mem 40.059
Train: [53][265/750]	BT 0.115 (1.205)	DT 0.002 (1.074)	loss nan (nan)	prob nan (nan)	GS 34.984 (34.984)	mem 39.980
Train: [53][270/750]	BT 0.172 (1.243)	DT 0.001 (1.113)	loss nan (nan)	prob nan (nan)	GS 31.734 (31.734)	mem 39.990
Train: [53][275/750]	BT 0.142 (1.222)	DT 0.002 (1.092)	loss nan (nan)	prob nan (nan)	GS 37.203 (37.203)	mem 39.991
Train: [53][280/750]	BT 9.223 (1.235)	DT 9.068 (1.106)	loss nan (nan)	prob nan (nan)	GS 31.188 (31.188)	mem 40.122
Train: [53][285/750]	BT 0.081 (1.225)	DT 0.002 (1.095)	loss nan (nan)	prob nan (nan)	GS 33.656 (33.656)	mem 39.929
Train: [53][290/750]	BT 0.156 (1.206)	DT 0.014 (1.076)	loss nan (nan)	prob nan (nan)	GS 32.375 (32.375)	mem 40.027
Train: [53][295/750]	BT 0.145 (1.225)	DT 0.008 (1.096)	loss nan (nan)	prob nan (nan)	GS 33.359 (33.359)	mem 40.173
Train: [53][300/750]	BT 0.064 (1.217)	DT 0.001 (1.088)	loss nan (nan)	prob nan (nan)	GS 31.359 (31.359)	mem 40.007
Train: [53][305/750]	BT 0.070 (1.235)	DT 0.001 (1.107)	loss nan (nan)	prob nan (nan)	GS 42.812 (42.812)	mem 40.072
Train: [53][310/750]	BT 0.178 (1.223)	DT 0.034 (1.095)	loss nan (nan)	prob nan (nan)	GS 33.938 (33.938)	mem 39.996
Train: [53][315/750]	BT 0.112 (1.206)	DT 0.001 (1.077)	loss nan (nan)	prob nan (nan)	GS 32.469 (32.469)	mem 39.994
Train: [53][320/750]	BT 4.745 (1.226)	DT 4.486 (1.097)	loss nan (nan)	prob nan (nan)	GS 31.938 (31.938)	mem 39.969
Train: [53][325/750]	BT 0.178 (1.210)	DT 0.002 (1.080)	loss nan (nan)	prob nan (nan)	GS 32.656 (32.656)	mem 39.995
Train: [53][330/750]	BT 0.084 (1.206)	DT 0.001 (1.077)	loss nan (nan)	prob nan (nan)	GS 28.938 (28.938)	mem 39.972
Train: [53][335/750]	BT 0.234 (1.210)	DT 0.002 (1.081)	loss nan (nan)	prob nan (nan)	GS 36.828 (36.828)	mem 40.011
Train: [53][340/750]	BT 3.337 (1.204)	DT 3.241 (1.075)	loss nan (nan)	prob nan (nan)	GS 33.562 (33.562)	mem 39.959
Train: [53][345/750]	BT 0.123 (1.208)	DT 0.001 (1.079)	loss nan (nan)	prob nan (nan)	GS 31.312 (31.312)	mem 40.076
Train: [53][350/750]	BT 0.137 (1.193)	DT 0.001 (1.063)	loss nan (nan)	prob nan (nan)	GS 30.000 (30.000)	mem 39.933
Train: [53][355/750]	BT 0.168 (1.195)	DT 0.002 (1.065)	loss nan (nan)	prob nan (nan)	GS 28.500 (28.500)	mem 40.097
Train: [53][360/750]	BT 0.253 (1.196)	DT 0.012 (1.066)	loss nan (nan)	prob nan (nan)	GS 32.047 (32.047)	mem 39.892
Train: [53][365/750]	BT 0.089 (1.200)	DT 0.002 (1.070)	loss nan (nan)	prob nan (nan)	GS 31.562 (31.562)	mem 39.980
Train: [53][370/750]	BT 3.050 (1.197)	DT 2.936 (1.067)	loss nan (nan)	prob nan (nan)	GS 33.422 (33.422)	mem 39.988
Train: [53][375/750]	BT 0.086 (1.183)	DT 0.002 (1.053)	loss nan (nan)	prob nan (nan)	GS 33.406 (33.406)	mem 39.933
Train: [53][380/750]	BT 0.865 (1.193)	DT 0.701 (1.063)	loss nan (nan)	prob nan (nan)	GS 31.391 (31.391)	mem 40.095
Train: [53][385/750]	BT 0.100 (1.196)	DT 0.001 (1.066)	loss nan (nan)	prob nan (nan)	GS 27.797 (27.797)	mem 40.056
Train: [53][390/750]	BT 0.206 (1.200)	DT 0.008 (1.070)	loss nan (nan)	prob nan (nan)	GS 33.562 (33.562)	mem 40.139
Train: [53][395/750]	BT 0.126 (1.198)	DT 0.002 (1.068)	loss nan (nan)	prob nan (nan)	GS 39.703 (39.703)	mem 40.039
Train: [53][400/750]	BT 4.595 (1.196)	DT 4.438 (1.066)	loss nan (nan)	prob nan (nan)	GS 34.672 (34.672)	mem 40.019
Train: [53][405/750]	BT 0.169 (1.183)	DT 0.002 (1.053)	loss nan (nan)	prob nan (nan)	GS 32.156 (32.156)	mem 40.039
Train: [53][410/750]	BT 0.109 (1.185)	DT 0.006 (1.054)	loss nan (nan)	prob nan (nan)	GS 35.406 (35.406)	mem 40.016
Train: [53][415/750]	BT 0.105 (1.188)	DT 0.003 (1.057)	loss nan (nan)	prob nan (nan)	GS 31.750 (31.750)	mem 40.113
Train: [53][420/750]	BT 0.154 (1.186)	DT 0.007 (1.055)	loss nan (nan)	prob nan (nan)	GS 34.812 (34.812)	mem 40.087
Train: [53][425/750]	BT 0.092 (1.189)	DT 0.005 (1.058)	loss nan (nan)	prob nan (nan)	GS 30.250 (30.250)	mem 40.182
Train: [53][430/750]	BT 3.879 (1.185)	DT 3.612 (1.054)	loss nan (nan)	prob nan (nan)	GS 29.594 (29.594)	mem 40.261
Train: [53][435/750]	BT 0.155 (1.173)	DT 0.004 (1.042)	loss nan (nan)	prob nan (nan)	GS 35.484 (35.484)	mem 39.937
Train: [53][440/750]	BT 0.100 (1.180)	DT 0.001 (1.048)	loss nan (nan)	prob nan (nan)	GS 35.688 (35.688)	mem 39.975
Train: [53][445/750]	BT 0.156 (1.177)	DT 0.002 (1.045)	loss nan (nan)	prob nan (nan)	GS 30.688 (30.688)	mem 39.957
Train: [53][450/750]	BT 0.175 (1.183)	DT 0.032 (1.051)	loss nan (nan)	prob nan (nan)	GS 30.812 (30.812)	mem 39.943
Train: [53][455/750]	BT 0.223 (1.176)	DT 0.001 (1.044)	loss nan (nan)	prob nan (nan)	GS 35.625 (35.625)	mem 40.018
Train: [53][460/750]	BT 5.185 (1.176)	DT 5.019 (1.043)	loss nan (nan)	prob nan (nan)	GS 33.734 (33.734)	mem 40.149
Train: [53][465/750]	BT 0.163 (1.164)	DT 0.002 (1.032)	loss nan (nan)	prob nan (nan)	GS 32.672 (32.672)	mem 40.253
Train: [53][470/750]	BT 0.156 (1.169)	DT 0.014 (1.037)	loss nan (nan)	prob nan (nan)	GS 29.297 (29.297)	mem 40.069
Train: [53][475/750]	BT 0.149 (1.161)	DT 0.002 (1.029)	loss nan (nan)	prob nan (nan)	GS 31.750 (31.750)	mem 40.071
Train: [53][480/750]	BT 0.150 (1.170)	DT 0.015 (1.038)	loss nan (nan)	prob nan (nan)	GS 34.984 (34.984)	mem 40.148
Train: [53][485/750]	BT 0.180 (1.161)	DT 0.001 (1.029)	loss nan (nan)	prob nan (nan)	GS 28.781 (28.781)	mem 40.287
Train: [53][490/750]	BT 11.138 (1.175)	DT 11.048 (1.043)	loss nan (nan)	prob nan (nan)	GS 35.266 (35.266)	mem 40.144
Train: [53][495/750]	BT 0.120 (1.164)	DT 0.007 (1.032)	loss nan (nan)	prob nan (nan)	GS 28.500 (28.500)	mem 40.004
Train: [53][500/750]	BT 0.090 (1.154)	DT 0.002 (1.022)	loss nan (nan)	prob nan (nan)	GS 34.578 (34.578)	mem 40.037
Train: [53][505/750]	BT 0.096 (1.165)	DT 0.001 (1.033)	loss nan (nan)	prob nan (nan)	GS 25.875 (25.875)	mem 40.089
Train: [53][510/750]	BT 0.196 (1.155)	DT 0.019 (1.023)	loss nan (nan)	prob nan (nan)	GS 29.422 (29.422)	mem 40.086
Train: [53][515/750]	BT 0.060 (1.165)	DT 0.001 (1.033)	loss nan (nan)	prob nan (nan)	GS 28.406 (28.406)	mem 40.152
Train: [53][520/750]	BT 0.086 (1.155)	DT 0.002 (1.023)	loss nan (nan)	prob nan (nan)	GS 31.219 (31.219)	mem 40.112
Train: [53][525/750]	BT 0.102 (1.145)	DT 0.001 (1.014)	loss nan (nan)	prob nan (nan)	GS 31.547 (31.547)	mem 40.196
Train: [53][530/750]	BT 0.078 (1.166)	DT 0.002 (1.035)	loss nan (nan)	prob nan (nan)	GS 33.234 (33.234)	mem 40.100
Train: [53][535/750]	BT 0.110 (1.156)	DT 0.002 (1.026)	loss nan (nan)	prob nan (nan)	GS 34.531 (34.531)	mem 39.977
Train: [53][540/750]	BT 0.087 (1.166)	DT 0.002 (1.035)	loss nan (nan)	prob nan (nan)	GS 32.797 (32.797)	mem 39.933
Train: [53][545/750]	BT 0.090 (1.156)	DT 0.002 (1.026)	loss nan (nan)	prob nan (nan)	GS 45.406 (45.406)	mem 40.117
Train: [53][550/750]	BT 8.344 (1.166)	DT 8.227 (1.036)	loss nan (nan)	prob nan (nan)	GS 31.656 (31.656)	mem 39.947
Train: [53][555/750]	BT 0.072 (1.157)	DT 0.001 (1.027)	loss nan (nan)	prob nan (nan)	GS 31.766 (31.766)	mem 40.013
Train: [53][560/750]	BT 0.175 (1.152)	DT 0.002 (1.022)	loss nan (nan)	prob nan (nan)	GS 32.812 (32.812)	mem 40.002
Train: [53][565/750]	BT 0.173 (1.159)	DT 0.002 (1.029)	loss nan (nan)	prob nan (nan)	GS 28.812 (28.812)	mem 39.995
Train: [53][570/750]	BT 1.082 (1.153)	DT 0.856 (1.023)	loss nan (nan)	prob nan (nan)	GS 36.203 (36.203)	mem 39.983
Train: [53][575/750]	BT 0.132 (1.165)	DT 0.001 (1.035)	loss nan (nan)	prob nan (nan)	GS 31.594 (31.594)	mem 39.890
Train: [53][580/750]	BT 0.084 (1.156)	DT 0.001 (1.026)	loss nan (nan)	prob nan (nan)	GS 28.562 (28.562)	mem 39.847
Train: [53][585/750]	BT 0.139 (1.147)	DT 0.001 (1.017)	loss nan (nan)	prob nan (nan)	GS 33.297 (33.297)	mem 39.916
Train: [53][590/750]	BT 0.146 (1.160)	DT 0.010 (1.030)	loss nan (nan)	prob nan (nan)	GS 31.797 (31.797)	mem 39.903
Train: [53][595/750]	BT 0.085 (1.151)	DT 0.002 (1.021)	loss nan (nan)	prob nan (nan)	GS 28.234 (28.234)	mem 40.053
Train: [53][600/750]	BT 0.080 (1.164)	DT 0.004 (1.034)	loss nan (nan)	prob nan (nan)	GS 32.812 (32.812)	mem 39.864
Train: [53][605/750]	BT 0.084 (1.155)	DT 0.002 (1.025)	loss nan (nan)	prob nan (nan)	GS 31.922 (31.922)	mem 39.900
Train: [53][610/750]	BT 5.693 (1.159)	DT 5.578 (1.030)	loss nan (nan)	prob nan (nan)	GS 33.062 (33.062)	mem 39.908
Train: [53][615/750]	BT 0.120 (1.151)	DT 0.002 (1.021)	loss nan (nan)	prob nan (nan)	GS 34.000 (34.000)	mem 39.958
Train: [53][620/750]	BT 7.209 (1.155)	DT 7.014 (1.025)	loss nan (nan)	prob nan (nan)	GS 34.078 (34.078)	mem 40.019
Train: [53][625/750]	BT 0.309 (1.154)	DT 0.005 (1.024)	loss nan (nan)	prob nan (nan)	GS 30.969 (30.969)	mem 40.033
Train: [53][630/750]	BT 3.882 (1.152)	DT 3.707 (1.022)	loss nan (nan)	prob nan (nan)	GS 34.609 (34.609)	mem 40.026
Train: [53][635/750]	BT 0.084 (1.155)	DT 0.007 (1.024)	loss nan (nan)	prob nan (nan)	GS 32.328 (32.328)	mem 40.130
Train: [53][640/750]	BT 0.153 (1.147)	DT 0.007 (1.016)	loss nan (nan)	prob nan (nan)	GS 30.094 (30.094)	mem 39.997
Train: [53][645/750]	BT 0.113 (1.160)	DT 0.004 (1.029)	loss nan (nan)	prob nan (nan)	GS 35.250 (35.250)	mem 39.960
Train: [53][650/750]	BT 0.086 (1.151)	DT 0.001 (1.022)	loss nan (nan)	prob nan (nan)	GS 38.469 (38.469)	mem 40.001
Train: [53][655/750]	BT 0.227 (1.148)	DT 0.002 (1.018)	loss nan (nan)	prob nan (nan)	GS 28.531 (28.531)	mem 40.018
Train: [53][660/750]	BT 0.205 (1.155)	DT 0.014 (1.025)	loss nan (nan)	prob nan (nan)	GS 36.594 (36.594)	mem 39.997
Train: [53][665/750]	BT 0.221 (1.147)	DT 0.002 (1.017)	loss nan (nan)	prob nan (nan)	GS 29.484 (29.484)	mem 40.124
Train: [53][670/750]	BT 0.086 (1.154)	DT 0.001 (1.024)	loss nan (nan)	prob nan (nan)	GS 35.281 (35.281)	mem 39.959
Train: [53][675/750]	BT 0.135 (1.146)	DT 0.010 (1.016)	loss nan (nan)	prob nan (nan)	GS 35.688 (35.688)	mem 40.037
Train: [53][680/750]	BT 6.940 (1.157)	DT 6.754 (1.027)	loss nan (nan)	prob nan (nan)	GS 35.047 (35.047)	mem 40.000
Train: [53][685/750]	BT 0.230 (1.150)	DT 0.003 (1.020)	loss nan (nan)	prob nan (nan)	GS 27.766 (27.766)	mem 40.044
Train: [53][690/750]	BT 4.204 (1.149)	DT 4.002 (1.018)	loss nan (nan)	prob nan (nan)	GS 33.375 (33.375)	mem 40.041
Train: [53][695/750]	BT 0.088 (1.154)	DT 0.001 (1.024)	loss nan (nan)	prob nan (nan)	GS 27.938 (27.938)	mem 39.987
Train: [53][700/750]	BT 0.131 (1.146)	DT 0.002 (1.016)	loss nan (nan)	prob nan (nan)	GS 33.875 (33.875)	mem 39.987
Train: [53][705/750]	BT 0.122 (1.154)	DT 0.002 (1.024)	loss nan (nan)	prob nan (nan)	GS 31.984 (31.984)	mem 40.191
Train: [53][710/750]	BT 0.142 (1.147)	DT 0.001 (1.017)	loss nan (nan)	prob nan (nan)	GS 34.594 (34.594)	mem 40.178
Train: [53][715/750]	BT 0.172 (1.150)	DT 0.002 (1.020)	loss nan (nan)	prob nan (nan)	GS 32.062 (32.062)	mem 39.982
Train: [53][720/750]	BT 0.116 (1.149)	DT 0.006 (1.019)	loss nan (nan)	prob nan (nan)	GS 36.922 (36.922)	mem 39.983
Train: [53][725/750]	BT 0.125 (1.142)	DT 0.009 (1.012)	loss nan (nan)	prob nan (nan)	GS 30.969 (30.969)	mem 39.938
Train: [53][730/750]	BT 0.116 (1.147)	DT 0.002 (1.017)	loss nan (nan)	prob nan (nan)	GS 33.906 (33.906)	mem 39.653
Train: [53][735/750]	BT 0.100 (1.140)	DT 0.002 (1.010)	loss nan (nan)	prob nan (nan)	GS 33.375 (33.375)	mem 39.707
Train: [53][740/750]	BT 1.671 (1.141)	DT 1.576 (1.011)	loss nan (nan)	prob nan (nan)	GS 34.797 (34.797)	mem 13.692
Train: [53][745/750]	BT 0.056 (1.135)	DT 0.001 (1.005)	loss nan (nan)	prob nan (nan)	GS 31.875 (31.875)	mem 13.692
Train: [53][750/750]	BT 0.955 (1.129)	DT 0.870 (1.000)	loss nan (nan)	prob nan (nan)	GS 36.938 (36.938)	mem 13.621
Train: [53][755/750]	BT 0.090 (1.124)	DT 0.001 (0.995)	loss nan (nan)	prob nan (nan)	GS 39.000 (39.000)	mem 7.642
epoch 53, total time 848.82
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [54][1/750]	BT 22.083 (22.083)	DT 21.932 (21.932)	loss nan (nan)	prob nan (nan)	GS 30.984 (30.984)	mem 38.673
Train: [54][5/750]	BT 0.086 (4.898)	DT 0.002 (4.759)	loss nan (nan)	prob nan (nan)	GS 31.375 (31.375)	mem 38.849
Train: [54][10/750]	BT 2.103 (2.729)	DT 1.931 (2.576)	loss nan (nan)	prob nan (nan)	GS 31.891 (31.891)	mem 38.805
Train: [54][15/750]	BT 0.203 (2.383)	DT 0.050 (2.236)	loss nan (nan)	prob nan (nan)	GS 30.734 (30.734)	mem 38.934
Train: [54][20/750]	BT 3.299 (1.981)	DT 2.922 (1.830)	loss nan (nan)	prob nan (nan)	GS 35.547 (35.547)	mem 38.900
Train: [54][25/750]	BT 6.244 (1.855)	DT 5.974 (1.704)	loss nan (nan)	prob nan (nan)	GS 29.078 (29.078)	mem 39.329
Train: [54][30/750]	BT 0.102 (1.751)	DT 0.001 (1.601)	loss nan (nan)	prob nan (nan)	GS 33.078 (33.078)	mem 38.967
Train: [54][35/750]	BT 0.117 (1.573)	DT 0.002 (1.428)	loss nan (nan)	prob nan (nan)	GS 30.469 (30.469)	mem 39.007
Train: [54][40/750]	BT 0.089 (1.660)	DT 0.009 (1.515)	loss nan (nan)	prob nan (nan)	GS 35.031 (35.031)	mem 39.042
Train: [54][45/750]	BT 0.155 (1.488)	DT 0.002 (1.347)	loss nan (nan)	prob nan (nan)	GS 32.188 (32.188)	mem 39.152
Train: [54][50/750]	BT 12.613 (1.607)	DT 12.527 (1.464)	loss nan (nan)	prob nan (nan)	GS 31.797 (31.797)	mem 39.342
Train: [54][55/750]	BT 0.123 (1.471)	DT 0.002 (1.331)	loss nan (nan)	prob nan (nan)	GS 31.984 (31.984)	mem 39.381
Train: [54][60/750]	BT 0.115 (1.362)	DT 0.009 (1.220)	loss nan (nan)	prob nan (nan)	GS 31.641 (31.641)	mem 39.331
Train: [54][65/750]	BT 0.120 (1.435)	DT 0.009 (1.297)	loss nan (nan)	prob nan (nan)	GS 32.938 (32.938)	mem 39.547
Train: [54][70/750]	BT 0.132 (1.344)	DT 0.009 (1.205)	loss nan (nan)	prob nan (nan)	GS 30.922 (30.922)	mem 39.510
Train: [54][75/750]	BT 0.094 (1.454)	DT 0.002 (1.316)	loss nan (nan)	prob nan (nan)	GS 33.547 (33.547)	mem 39.681
Train: [54][80/750]	BT 0.091 (1.370)	DT 0.001 (1.234)	loss nan (nan)	prob nan (nan)	GS 34.906 (34.906)	mem 39.654
Train: [54][85/750]	BT 0.138 (1.299)	DT 0.002 (1.162)	loss nan (nan)	prob nan (nan)	GS 28.047 (28.047)	mem 39.701
Train: [54][90/750]	BT 0.096 (1.374)	DT 0.001 (1.238)	loss nan (nan)	prob nan (nan)	GS 30.984 (30.984)	mem 39.735
Train: [54][95/750]	BT 0.140 (1.308)	DT 0.004 (1.174)	loss nan (nan)	prob nan (nan)	GS 31.625 (31.625)	mem 39.704
Train: [54][100/750]	BT 0.093 (1.351)	DT 0.023 (1.218)	loss nan (nan)	prob nan (nan)	GS 33.891 (33.891)	mem 39.755
Train: [54][105/750]	BT 0.079 (1.292)	DT 0.002 (1.160)	loss nan (nan)	prob nan (nan)	GS 32.344 (32.344)	mem 39.767
Train: [54][110/750]	BT 10.970 (1.337)	DT 10.741 (1.206)	loss nan (nan)	prob nan (nan)	GS 35.062 (35.062)	mem 39.713
Train: [54][115/750]	BT 0.121 (1.287)	DT 0.002 (1.156)	loss nan (nan)	prob nan (nan)	GS 29.531 (29.531)	mem 39.748
Train: [54][120/750]	BT 0.117 (1.238)	DT 0.001 (1.108)	loss nan (nan)	prob nan (nan)	GS 34.266 (34.266)	mem 39.681
Train: [54][125/750]	BT 0.122 (1.282)	DT 0.001 (1.153)	loss nan (nan)	prob nan (nan)	GS 28.656 (28.656)	mem 39.753
Train: [54][130/750]	BT 0.098 (1.238)	DT 0.002 (1.109)	loss nan (nan)	prob nan (nan)	GS 34.812 (34.812)	mem 39.755
Train: [54][135/750]	BT 0.178 (1.292)	DT 0.020 (1.163)	loss nan (nan)	prob nan (nan)	GS 30.922 (30.922)	mem 39.805
Train: [54][140/750]	BT 0.336 (1.251)	DT 0.019 (1.121)	loss nan (nan)	prob nan (nan)	GS 34.750 (34.750)	mem 39.807
Train: [54][145/750]	BT 0.147 (1.212)	DT 0.002 (1.083)	loss nan (nan)	prob nan (nan)	GS 32.062 (32.062)	mem 39.862
Train: [54][150/750]	BT 0.078 (1.252)	DT 0.002 (1.124)	loss nan (nan)	prob nan (nan)	GS 31.734 (31.734)	mem 39.848
Train: [54][155/750]	BT 0.092 (1.216)	DT 0.002 (1.088)	loss nan (nan)	prob nan (nan)	GS 34.000 (34.000)	mem 39.870
Train: [54][160/750]	BT 0.151 (1.243)	DT 0.001 (1.113)	loss nan (nan)	prob nan (nan)	GS 31.812 (31.812)	mem 39.844
Train: [54][165/750]	BT 0.151 (1.209)	DT 0.002 (1.079)	loss nan (nan)	prob nan (nan)	GS 30.391 (30.391)	mem 39.919
Train: [54][170/750]	BT 11.283 (1.244)	DT 11.117 (1.113)	loss nan (nan)	prob nan (nan)	GS 33.172 (33.172)	mem 39.793
Train: [54][175/750]	BT 0.116 (1.214)	DT 0.001 (1.084)	loss nan (nan)	prob nan (nan)	GS 36.031 (36.031)	mem 39.867
Train: [54][180/750]	BT 0.163 (1.185)	DT 0.002 (1.054)	loss nan (nan)	prob nan (nan)	GS 31.500 (31.500)	mem 39.965
Train: [54][185/750]	BT 0.096 (1.227)	DT 0.003 (1.097)	loss nan (nan)	prob nan (nan)	GS 30.203 (30.203)	mem 40.266
Train: [54][190/750]	BT 0.146 (1.198)	DT 0.004 (1.068)	loss nan (nan)	prob nan (nan)	GS 35.422 (35.422)	mem 39.860
Train: [54][195/750]	BT 0.083 (1.247)	DT 0.002 (1.117)	loss nan (nan)	prob nan (nan)	GS 30.297 (30.297)	mem 39.929
Train: [54][200/750]	BT 0.125 (1.218)	DT 0.002 (1.089)	loss nan (nan)	prob nan (nan)	GS 32.219 (32.219)	mem 39.943
Train: [54][205/750]	BT 0.194 (1.192)	DT 0.003 (1.063)	loss nan (nan)	prob nan (nan)	GS 32.656 (32.656)	mem 39.952
Train: [54][210/750]	BT 0.083 (1.222)	DT 0.002 (1.093)	loss nan (nan)	prob nan (nan)	GS 37.672 (37.672)	mem 39.951
Train: [54][215/750]	BT 0.087 (1.196)	DT 0.002 (1.068)	loss nan (nan)	prob nan (nan)	GS 26.156 (26.156)	mem 39.955
Train: [54][220/750]	BT 0.079 (1.224)	DT 0.001 (1.096)	loss nan (nan)	prob nan (nan)	GS 35.828 (35.828)	mem 39.984
Train: [54][225/750]	BT 0.088 (1.199)	DT 0.002 (1.072)	loss nan (nan)	prob nan (nan)	GS 28.141 (28.141)	mem 39.986
Train: [54][230/750]	BT 13.406 (1.233)	DT 13.285 (1.107)	loss nan (nan)	prob nan (nan)	GS 34.953 (34.953)	mem 39.985
Train: [54][235/750]	BT 0.108 (1.210)	DT 0.001 (1.083)	loss nan (nan)	prob nan (nan)	GS 28.219 (28.219)	mem 39.996
Train: [54][240/750]	BT 0.087 (1.188)	DT 0.002 (1.061)	loss nan (nan)	prob nan (nan)	GS 28.656 (28.656)	mem 40.000
Train: [54][245/750]	BT 0.097 (1.219)	DT 0.007 (1.092)	loss nan (nan)	prob nan (nan)	GS 27.000 (27.000)	mem 40.026
Train: [54][250/750]	BT 0.101 (1.197)	DT 0.002 (1.070)	loss nan (nan)	prob nan (nan)	GS 37.453 (37.453)	mem 40.030
Train: [54][255/750]	BT 0.119 (1.218)	DT 0.004 (1.092)	loss nan (nan)	prob nan (nan)	GS 32.391 (32.391)	mem 40.007
Train: [54][260/750]	BT 0.101 (1.197)	DT 0.004 (1.071)	loss nan (nan)	prob nan (nan)	GS 32.844 (32.844)	mem 40.009
Train: [54][265/750]	BT 0.183 (1.177)	DT 0.002 (1.051)	loss nan (nan)	prob nan (nan)	GS 34.297 (34.297)	mem 40.011
Train: [54][270/750]	BT 0.105 (1.200)	DT 0.002 (1.075)	loss nan (nan)	prob nan (nan)	GS 30.719 (30.719)	mem 39.983
Train: [54][275/750]	BT 0.110 (1.181)	DT 0.002 (1.055)	loss nan (nan)	prob nan (nan)	GS 31.891 (31.891)	mem 39.948
Train: [54][280/750]	BT 0.188 (1.203)	DT 0.001 (1.077)	loss nan (nan)	prob nan (nan)	GS 36.469 (36.469)	mem 39.939
Train: [54][285/750]	BT 0.209 (1.185)	DT 0.001 (1.058)	loss nan (nan)	prob nan (nan)	GS 28.422 (28.422)	mem 39.964
Train: [54][290/750]	BT 12.275 (1.209)	DT 12.181 (1.082)	loss nan (nan)	prob nan (nan)	GS 32.281 (32.281)	mem 40.029
Train: [54][295/750]	BT 0.091 (1.191)	DT 0.002 (1.064)	loss nan (nan)	prob nan (nan)	GS 31.016 (31.016)	mem 39.978
Train: [54][300/750]	BT 0.163 (1.173)	DT 0.002 (1.046)	loss nan (nan)	prob nan (nan)	GS 34.000 (34.000)	mem 39.948
Train: [54][305/750]	BT 0.138 (1.198)	DT 0.043 (1.071)	loss nan (nan)	prob nan (nan)	GS 30.328 (30.328)	mem 39.941
Train: [54][310/750]	BT 0.311 (1.181)	DT 0.010 (1.054)	loss nan (nan)	prob nan (nan)	GS 35.922 (35.922)	mem 40.093
Train: [54][315/750]	BT 0.098 (1.202)	DT 0.002 (1.074)	loss nan (nan)	prob nan (nan)	GS 32.234 (32.234)	mem 39.834
Train: [54][320/750]	BT 0.190 (1.185)	DT 0.005 (1.058)	loss nan (nan)	prob nan (nan)	GS 34.828 (34.828)	mem 39.898
Train: [54][325/750]	BT 0.164 (1.169)	DT 0.009 (1.042)	loss nan (nan)	prob nan (nan)	GS 29.938 (29.938)	mem 39.890
Train: [54][330/750]	BT 0.136 (1.187)	DT 0.001 (1.061)	loss nan (nan)	prob nan (nan)	GS 30.156 (30.156)	mem 39.866
Train: [54][335/750]	BT 0.123 (1.171)	DT 0.002 (1.045)	loss nan (nan)	prob nan (nan)	GS 27.141 (27.141)	mem 39.908
Train: [54][340/750]	BT 0.078 (1.185)	DT 0.001 (1.059)	loss nan (nan)	prob nan (nan)	GS 33.891 (33.891)	mem 39.966
Train: [54][345/750]	BT 0.100 (1.169)	DT 0.002 (1.044)	loss nan (nan)	prob nan (nan)	GS 31.781 (31.781)	mem 39.966
Train: [54][350/750]	BT 8.595 (1.179)	DT 8.456 (1.053)	loss nan (nan)	prob nan (nan)	GS 31.938 (31.938)	mem 40.066
Train: [54][355/750]	BT 0.180 (1.170)	DT 0.008 (1.043)	loss nan (nan)	prob nan (nan)	GS 27.766 (27.766)	mem 40.135
Train: [54][360/750]	BT 0.105 (1.156)	DT 0.013 (1.029)	loss nan (nan)	prob nan (nan)	GS 32.031 (32.031)	mem 39.977
Train: [54][365/750]	BT 0.082 (1.177)	DT 0.001 (1.051)	loss nan (nan)	prob nan (nan)	GS 27.750 (27.750)	mem 39.923
Train: [54][370/750]	BT 0.098 (1.163)	DT 0.002 (1.037)	loss nan (nan)	prob nan (nan)	GS 37.328 (37.328)	mem 39.942
Train: [54][375/750]	BT 0.093 (1.173)	DT 0.002 (1.047)	loss nan (nan)	prob nan (nan)	GS 28.906 (28.906)	mem 40.351
Train: [54][380/750]	BT 0.084 (1.181)	DT 0.007 (1.055)	loss nan (nan)	prob nan (nan)	GS 37.406 (37.406)	mem 39.979
Train: [54][385/750]	BT 0.088 (1.167)	DT 0.002 (1.041)	loss nan (nan)	prob nan (nan)	GS 37.234 (37.234)	mem 39.988
Train: [54][390/750]	BT 0.214 (1.181)	DT 0.037 (1.056)	loss nan (nan)	prob nan (nan)	GS 33.656 (33.656)	mem 40.030
Train: [54][395/750]	BT 0.118 (1.168)	DT 0.008 (1.042)	loss nan (nan)	prob nan (nan)	GS 33.250 (33.250)	mem 40.234
Train: [54][400/750]	BT 11.742 (1.189)	DT 11.662 (1.064)	loss nan (nan)	prob nan (nan)	GS 34.250 (34.250)	mem 39.974
Train: [54][405/750]	BT 0.072 (1.176)	DT 0.001 (1.050)	loss nan (nan)	prob nan (nan)	GS 26.562 (26.562)	mem 40.025
Train: [54][410/750]	BT 0.204 (1.163)	DT 0.002 (1.038)	loss nan (nan)	prob nan (nan)	GS 30.516 (30.516)	mem 39.998
Train: [54][415/750]	BT 0.095 (1.184)	DT 0.001 (1.059)	loss nan (nan)	prob nan (nan)	GS 31.359 (31.359)	mem 39.939
Train: [54][420/750]	BT 0.093 (1.171)	DT 0.001 (1.046)	loss nan (nan)	prob nan (nan)	GS 33.016 (33.016)	mem 40.012
Train: [54][425/750]	BT 0.157 (1.179)	DT 0.007 (1.054)	loss nan (nan)	prob nan (nan)	GS 32.812 (32.812)	mem 39.980
Train: [54][430/750]	BT 0.112 (1.167)	DT 0.002 (1.042)	loss nan (nan)	prob nan (nan)	GS 32.703 (32.703)	mem 40.042
Train: [54][435/750]	BT 0.132 (1.155)	DT 0.011 (1.030)	loss nan (nan)	prob nan (nan)	GS 30.953 (30.953)	mem 39.988
Train: [54][440/750]	BT 0.144 (1.172)	DT 0.001 (1.046)	loss nan (nan)	prob nan (nan)	GS 32.781 (32.781)	mem 40.058
Train: [54][445/750]	BT 0.168 (1.160)	DT 0.021 (1.035)	loss nan (nan)	prob nan (nan)	GS 34.078 (34.078)	mem 40.153
Train: [54][450/750]	BT 0.136 (1.174)	DT 0.001 (1.049)	loss nan (nan)	prob nan (nan)	GS 35.422 (35.422)	mem 40.227
Train: [54][455/750]	BT 0.077 (1.163)	DT 0.004 (1.037)	loss nan (nan)	prob nan (nan)	GS 29.203 (29.203)	mem 39.997
Train: [54][460/750]	BT 13.281 (1.180)	DT 13.063 (1.054)	loss nan (nan)	prob nan (nan)	GS 31.656 (31.656)	mem 40.058
Train: [54][465/750]	BT 0.085 (1.168)	DT 0.001 (1.043)	loss nan (nan)	prob nan (nan)	GS 41.500 (41.500)	mem 40.048
Train: [54][470/750]	BT 0.087 (1.157)	DT 0.002 (1.032)	loss nan (nan)	prob nan (nan)	GS 33.312 (33.312)	mem 40.047
Train: [54][475/750]	BT 0.156 (1.177)	DT 0.009 (1.052)	loss nan (nan)	prob nan (nan)	GS 32.172 (32.172)	mem 39.997
Train: [54][480/750]	BT 0.071 (1.165)	DT 0.002 (1.041)	loss nan (nan)	prob nan (nan)	GS 34.234 (34.234)	mem 39.940
Train: [54][485/750]	BT 0.142 (1.176)	DT 0.002 (1.051)	loss nan (nan)	prob nan (nan)	GS 31.438 (31.438)	mem 40.037
Train: [54][490/750]	BT 0.088 (1.165)	DT 0.002 (1.041)	loss nan (nan)	prob nan (nan)	GS 31.750 (31.750)	mem 40.039
Train: [54][495/750]	BT 0.105 (1.155)	DT 0.007 (1.030)	loss nan (nan)	prob nan (nan)	GS 29.328 (29.328)	mem 40.038
Train: [54][500/750]	BT 0.091 (1.167)	DT 0.002 (1.043)	loss nan (nan)	prob nan (nan)	GS 34.016 (34.016)	mem 40.007
Train: [54][505/750]	BT 0.139 (1.157)	DT 0.001 (1.032)	loss nan (nan)	prob nan (nan)	GS 31.922 (31.922)	mem 40.008
Train: [54][510/750]	BT 0.079 (1.167)	DT 0.001 (1.042)	loss nan (nan)	prob nan (nan)	GS 34.188 (34.188)	mem 40.110
Train: [54][515/750]	BT 0.141 (1.157)	DT 0.008 (1.032)	loss nan (nan)	prob nan (nan)	GS 30.828 (30.828)	mem 40.082
Train: [54][520/750]	BT 12.370 (1.171)	DT 12.236 (1.046)	loss nan (nan)	prob nan (nan)	GS 34.125 (34.125)	mem 40.025
Train: [54][525/750]	BT 0.090 (1.160)	DT 0.002 (1.036)	loss nan (nan)	prob nan (nan)	GS 30.172 (30.172)	mem 40.027
Train: [54][530/750]	BT 0.156 (1.151)	DT 0.002 (1.026)	loss nan (nan)	prob nan (nan)	GS 28.156 (28.156)	mem 40.030
Train: [54][535/750]	BT 0.175 (1.158)	DT 0.002 (1.034)	loss nan (nan)	prob nan (nan)	GS 33.188 (33.188)	mem 40.079
Train: [54][540/750]	BT 4.948 (1.158)	DT 4.874 (1.033)	loss nan (nan)	prob nan (nan)	GS 37.766 (37.766)	mem 40.017
Train: [54][545/750]	BT 0.092 (1.165)	DT 0.002 (1.041)	loss nan (nan)	prob nan (nan)	GS 29.344 (29.344)	mem 40.014
Train: [54][550/750]	BT 0.235 (1.156)	DT 0.007 (1.031)	loss nan (nan)	prob nan (nan)	GS 40.516 (40.516)	mem 40.153
Train: [54][555/750]	BT 0.213 (1.152)	DT 0.004 (1.027)	loss nan (nan)	prob nan (nan)	GS 30.078 (30.078)	mem 40.031
Train: [54][560/750]	BT 0.145 (1.160)	DT 0.002 (1.035)	loss nan (nan)	prob nan (nan)	GS 36.484 (36.484)	mem 40.142
Train: [54][565/750]	BT 0.093 (1.152)	DT 0.002 (1.027)	loss nan (nan)	prob nan (nan)	GS 33.000 (33.000)	mem 40.133
Train: [54][570/750]	BT 0.115 (1.159)	DT 0.002 (1.034)	loss nan (nan)	prob nan (nan)	GS 32.734 (32.734)	mem 40.159
Train: [54][575/750]	BT 0.229 (1.150)	DT 0.014 (1.025)	loss nan (nan)	prob nan (nan)	GS 29.453 (29.453)	mem 40.082
Train: [54][580/750]	BT 11.964 (1.164)	DT 11.888 (1.039)	loss nan (nan)	prob nan (nan)	GS 31.875 (31.875)	mem 40.122
Train: [54][585/750]	BT 0.139 (1.155)	DT 0.013 (1.030)	loss nan (nan)	prob nan (nan)	GS 32.578 (32.578)	mem 39.980
Train: [54][590/750]	BT 0.098 (1.146)	DT 0.007 (1.021)	loss nan (nan)	prob nan (nan)	GS 34.953 (34.953)	mem 40.009
Train: [54][595/750]	BT 0.133 (1.157)	DT 0.010 (1.032)	loss nan (nan)	prob nan (nan)	GS 34.531 (34.531)	mem 40.109
Train: [54][600/750]	BT 0.116 (1.148)	DT 0.013 (1.024)	loss nan (nan)	prob nan (nan)	GS 34.016 (34.016)	mem 40.261
Train: [54][605/750]	BT 0.107 (1.162)	DT 0.001 (1.037)	loss nan (nan)	prob nan (nan)	GS 31.219 (31.219)	mem 40.149
Train: [54][610/750]	BT 0.152 (1.153)	DT 0.025 (1.028)	loss nan (nan)	prob nan (nan)	GS 36.688 (36.688)	mem 40.109
Train: [54][615/750]	BT 0.109 (1.145)	DT 0.001 (1.020)	loss nan (nan)	prob nan (nan)	GS 34.438 (34.438)	mem 40.245
Train: [54][620/750]	BT 0.080 (1.154)	DT 0.005 (1.029)	loss nan (nan)	prob nan (nan)	GS 35.266 (35.266)	mem 40.060
Train: [54][625/750]	BT 0.165 (1.146)	DT 0.038 (1.021)	loss nan (nan)	prob nan (nan)	GS 34.703 (34.703)	mem 40.064
Train: [54][630/750]	BT 0.101 (1.152)	DT 0.009 (1.027)	loss nan (nan)	prob nan (nan)	GS 33.000 (33.000)	mem 40.059
Train: [54][635/750]	BT 0.102 (1.144)	DT 0.002 (1.019)	loss nan (nan)	prob nan (nan)	GS 34.297 (34.297)	mem 40.097
Train: [54][640/750]	BT 9.696 (1.155)	DT 9.598 (1.030)	loss nan (nan)	prob nan (nan)	GS 37.391 (37.391)	mem 40.064
Train: [54][645/750]	BT 0.156 (1.148)	DT 0.023 (1.022)	loss nan (nan)	prob nan (nan)	GS 30.328 (30.328)	mem 40.048
Train: [54][650/750]	BT 0.251 (1.143)	DT 0.002 (1.017)	loss nan (nan)	prob nan (nan)	GS 35.547 (35.547)	mem 40.076
Train: [54][655/750]	BT 0.120 (1.147)	DT 0.002 (1.022)	loss nan (nan)	prob nan (nan)	GS 31.562 (31.562)	mem 40.029
Train: [54][660/750]	BT 2.735 (1.143)	DT 2.650 (1.018)	loss nan (nan)	prob nan (nan)	GS 32.406 (32.406)	mem 40.056
Train: [54][665/750]	BT 0.096 (1.154)	DT 0.002 (1.028)	loss nan (nan)	prob nan (nan)	GS 30.828 (30.828)	mem 39.817
Train: [54][670/750]	BT 0.096 (1.146)	DT 0.001 (1.021)	loss nan (nan)	prob nan (nan)	GS 32.000 (32.000)	mem 39.834
Train: [54][675/750]	BT 0.108 (1.138)	DT 0.009 (1.013)	loss nan (nan)	prob nan (nan)	GS 28.375 (28.375)	mem 39.846
Train: [54][680/750]	BT 0.085 (1.146)	DT 0.001 (1.021)	loss nan (nan)	prob nan (nan)	GS 33.484 (33.484)	mem 39.982
Train: [54][685/750]	BT 0.128 (1.138)	DT 0.025 (1.013)	loss nan (nan)	prob nan (nan)	GS 32.906 (32.906)	mem 40.129
Train: [54][690/750]	BT 0.190 (1.145)	DT 0.002 (1.019)	loss nan (nan)	prob nan (nan)	GS 36.266 (36.266)	mem 40.069
Train: [54][695/750]	BT 0.109 (1.137)	DT 0.029 (1.012)	loss nan (nan)	prob nan (nan)	GS 26.906 (26.906)	mem 40.027
Train: [54][700/750]	BT 3.835 (1.146)	DT 3.704 (1.021)	loss nan (nan)	prob nan (nan)	GS 30.844 (30.844)	mem 40.169
Train: [54][705/750]	BT 0.192 (1.139)	DT 0.008 (1.013)	loss nan (nan)	prob nan (nan)	GS 31.938 (31.938)	mem 40.148
Train: [54][710/750]	BT 0.206 (1.144)	DT 0.012 (1.018)	loss nan (nan)	prob nan (nan)	GS 32.000 (32.000)	mem 40.089
Train: [54][715/750]	BT 0.090 (1.137)	DT 0.002 (1.011)	loss nan (nan)	prob nan (nan)	GS 36.406 (36.406)	mem 40.041
Train: [54][720/750]	BT 10.129 (1.145)	DT 10.017 (1.019)	loss nan (nan)	prob nan (nan)	GS 36.953 (36.953)	mem 40.116
Train: [54][725/750]	BT 0.119 (1.142)	DT 0.002 (1.017)	loss nan (nan)	prob nan (nan)	GS 27.859 (27.859)	mem 39.969
Train: [54][730/750]	BT 0.929 (1.136)	DT 0.831 (1.011)	loss nan (nan)	prob nan (nan)	GS 35.453 (35.453)	mem 39.804
Train: [54][735/750]	BT 0.068 (1.139)	DT 0.002 (1.013)	loss nan (nan)	prob nan (nan)	GS 30.266 (30.266)	mem 39.572
Train: [54][740/750]	BT 0.096 (1.135)	DT 0.001 (1.010)	loss nan (nan)	prob nan (nan)	GS 33.734 (33.734)	mem 19.587
Train: [54][745/750]	BT 0.087 (1.135)	DT 0.001 (1.010)	loss nan (nan)	prob nan (nan)	GS 36.000 (36.000)	mem 7.755
Train: [54][750/750]	BT 0.098 (1.128)	DT 0.001 (1.004)	loss nan (nan)	prob nan (nan)	GS 38.812 (38.812)	mem 7.753
Train: [54][755/750]	BT 0.071 (1.121)	DT 0.001 (0.997)	loss nan (nan)	prob nan (nan)	GS 38.125 (38.125)	mem 7.753
epoch 54, total time 848.04
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [55][1/750]	BT 21.034 (21.034)	DT 20.805 (20.805)	loss nan (nan)	prob nan (nan)	GS 36.781 (36.781)	mem 38.705
Train: [55][5/750]	BT 0.162 (4.986)	DT 0.002 (4.792)	loss nan (nan)	prob nan (nan)	GS 37.625 (37.625)	mem 38.679
Train: [55][10/750]	BT 0.150 (2.627)	DT 0.003 (2.441)	loss nan (nan)	prob nan (nan)	GS 33.688 (33.688)	mem 38.754
Train: [55][15/750]	BT 0.151 (2.614)	DT 0.003 (2.442)	loss nan (nan)	prob nan (nan)	GS 34.734 (34.734)	mem 38.994
Train: [55][20/750]	BT 0.192 (1.991)	DT 0.010 (1.833)	loss nan (nan)	prob nan (nan)	GS 35.641 (35.641)	mem 39.005
Train: [55][25/750]	BT 0.129 (1.772)	DT 0.002 (1.618)	loss nan (nan)	prob nan (nan)	GS 28.344 (28.344)	mem 39.025
Train: [55][30/750]	BT 0.080 (1.766)	DT 0.002 (1.617)	loss nan (nan)	prob nan (nan)	GS 34.094 (34.094)	mem 39.007
Train: [55][35/750]	BT 0.096 (1.546)	DT 0.002 (1.399)	loss nan (nan)	prob nan (nan)	GS 32.094 (32.094)	mem 39.034
Train: [55][40/750]	BT 2.743 (1.694)	DT 2.644 (1.544)	loss nan (nan)	prob nan (nan)	GS 33.812 (33.812)	mem 39.125
Train: [55][45/750]	BT 0.099 (1.520)	DT 0.001 (1.373)	loss nan (nan)	prob nan (nan)	GS 34.547 (34.547)	mem 39.115
Train: [55][50/750]	BT 9.059 (1.639)	DT 8.929 (1.492)	loss nan (nan)	prob nan (nan)	GS 32.328 (32.328)	mem 39.153
Train: [55][55/750]	BT 0.259 (1.507)	DT 0.005 (1.358)	loss nan (nan)	prob nan (nan)	GS 34.312 (34.312)	mem 39.154
Train: [55][60/750]	BT 2.058 (1.425)	DT 1.898 (1.276)	loss nan (nan)	prob nan (nan)	GS 31.703 (31.703)	mem 39.182
Train: [55][65/750]	BT 0.140 (1.457)	DT 0.005 (1.311)	loss nan (nan)	prob nan (nan)	GS 28.656 (28.656)	mem 39.234
Train: [55][70/750]	BT 0.272 (1.397)	DT 0.010 (1.248)	loss nan (nan)	prob nan (nan)	GS 31.297 (31.297)	mem 39.199
Train: [55][75/750]	BT 0.160 (1.428)	DT 0.007 (1.281)	loss nan (nan)	prob nan (nan)	GS 29.625 (29.625)	mem 39.224
Train: [55][80/750]	BT 2.157 (1.373)	DT 2.007 (1.227)	loss nan (nan)	prob nan (nan)	GS 36.844 (36.844)	mem 39.262
Train: [55][85/750]	BT 0.114 (1.378)	DT 0.001 (1.232)	loss nan (nan)	prob nan (nan)	GS 35.344 (35.344)	mem 39.417
Train: [55][90/750]	BT 0.838 (1.352)	DT 0.688 (1.205)	loss nan (nan)	prob nan (nan)	GS 36.844 (36.844)	mem 39.283
Train: [55][95/750]	BT 0.206 (1.320)	DT 0.026 (1.172)	loss nan (nan)	prob nan (nan)	GS 29.766 (29.766)	mem 39.229
Train: [55][100/750]	BT 0.364 (1.335)	DT 0.030 (1.187)	loss nan (nan)	prob nan (nan)	GS 33.781 (33.781)	mem 39.257
Train: [55][105/750]	BT 0.146 (1.299)	DT 0.002 (1.150)	loss nan (nan)	prob nan (nan)	GS 33.703 (33.703)	mem 39.320
Train: [55][110/750]	BT 6.283 (1.341)	DT 6.151 (1.194)	loss nan (nan)	prob nan (nan)	GS 33.125 (33.125)	mem 39.190
Train: [55][115/750]	BT 0.152 (1.290)	DT 0.013 (1.143)	loss nan (nan)	prob nan (nan)	GS 35.641 (35.641)	mem 39.275
Train: [55][120/750]	BT 0.607 (1.256)	DT 0.513 (1.110)	loss nan (nan)	prob nan (nan)	GS 32.578 (32.578)	mem 39.216
Train: [55][125/750]	BT 0.117 (1.294)	DT 0.002 (1.148)	loss nan (nan)	prob nan (nan)	GS 26.984 (26.984)	mem 39.274
Train: [55][130/750]	BT 0.131 (1.266)	DT 0.005 (1.120)	loss nan (nan)	prob nan (nan)	GS 36.266 (36.266)	mem 39.363
Train: [55][135/750]	BT 0.107 (1.308)	DT 0.009 (1.162)	loss nan (nan)	prob nan (nan)	GS 33.391 (33.391)	mem 39.249
Train: [55][140/750]	BT 0.079 (1.266)	DT 0.011 (1.121)	loss nan (nan)	prob nan (nan)	GS 31.484 (31.484)	mem 39.230
Train: [55][145/750]	BT 0.161 (1.228)	DT 0.026 (1.083)	loss nan (nan)	prob nan (nan)	GS 33.094 (33.094)	mem 39.347
Train: [55][150/750]	BT 0.091 (1.264)	DT 0.002 (1.119)	loss nan (nan)	prob nan (nan)	GS 30.031 (30.031)	mem 39.218
Train: [55][155/750]	BT 0.096 (1.233)	DT 0.002 (1.090)	loss nan (nan)	prob nan (nan)	GS 33.938 (33.938)	mem 39.315
Train: [55][160/750]	BT 0.164 (1.291)	DT 0.006 (1.147)	loss nan (nan)	prob nan (nan)	GS 32.875 (32.875)	mem 39.435
Train: [55][165/750]	BT 0.146 (1.256)	DT 0.013 (1.112)	loss nan (nan)	prob nan (nan)	GS 33.344 (33.344)	mem 39.481
Train: [55][170/750]	BT 11.977 (1.292)	DT 11.884 (1.150)	loss nan (nan)	prob nan (nan)	GS 32.156 (32.156)	mem 39.476
Train: [55][175/750]	BT 0.088 (1.259)	DT 0.006 (1.117)	loss nan (nan)	prob nan (nan)	GS 31.062 (31.062)	mem 39.476
Train: [55][180/750]	BT 0.095 (1.227)	DT 0.002 (1.086)	loss nan (nan)	prob nan (nan)	GS 31.203 (31.203)	mem 39.753
Train: [55][185/750]	BT 0.111 (1.287)	DT 0.001 (1.147)	loss nan (nan)	prob nan (nan)	GS 31.547 (31.547)	mem 39.597
Train: [55][190/750]	BT 0.068 (1.257)	DT 0.001 (1.117)	loss nan (nan)	prob nan (nan)	GS 31.656 (31.656)	mem 39.600
Train: [55][195/750]	BT 0.119 (1.293)	DT 0.002 (1.154)	loss nan (nan)	prob nan (nan)	GS 33.391 (33.391)	mem 39.751
Train: [55][200/750]	BT 0.088 (1.264)	DT 0.001 (1.125)	loss nan (nan)	prob nan (nan)	GS 35.531 (35.531)	mem 39.622
Train: [55][205/750]	BT 0.167 (1.237)	DT 0.002 (1.098)	loss nan (nan)	prob nan (nan)	GS 32.219 (32.219)	mem 39.636
Train: [55][210/750]	BT 0.092 (1.272)	DT 0.001 (1.134)	loss nan (nan)	prob nan (nan)	GS 34.656 (34.656)	mem 39.717
Train: [55][215/750]	BT 0.065 (1.245)	DT 0.001 (1.107)	loss nan (nan)	prob nan (nan)	GS 32.453 (32.453)	mem 39.719
Train: [55][220/750]	BT 0.110 (1.274)	DT 0.001 (1.137)	loss nan (nan)	prob nan (nan)	GS 40.500 (40.500)	mem 39.672
Train: [55][225/750]	BT 0.125 (1.248)	DT 0.003 (1.112)	loss nan (nan)	prob nan (nan)	GS 35.250 (35.250)	mem 39.685
Train: [55][230/750]	BT 13.596 (1.282)	DT 13.531 (1.147)	loss nan (nan)	prob nan (nan)	GS 33.406 (33.406)	mem 39.867
Train: [55][235/750]	BT 0.085 (1.256)	DT 0.008 (1.123)	loss nan (nan)	prob nan (nan)	GS 31.219 (31.219)	mem 39.882
Train: [55][240/750]	BT 0.105 (1.233)	DT 0.001 (1.099)	loss nan (nan)	prob nan (nan)	GS 33.594 (33.594)	mem 39.873
Train: [55][245/750]	BT 0.090 (1.252)	DT 0.015 (1.120)	loss nan (nan)	prob nan (nan)	GS 30.625 (30.625)	mem 39.896
Train: [55][250/750]	BT 0.202 (1.230)	DT 0.008 (1.097)	loss nan (nan)	prob nan (nan)	GS 34.812 (34.812)	mem 39.928
Train: [55][255/750]	BT 0.161 (1.244)	DT 0.001 (1.111)	loss nan (nan)	prob nan (nan)	GS 33.219 (33.219)	mem 40.019
Train: [55][260/750]	BT 0.163 (1.223)	DT 0.007 (1.090)	loss nan (nan)	prob nan (nan)	GS 34.094 (34.094)	mem 40.023
Train: [55][265/750]	BT 0.121 (1.203)	DT 0.007 (1.070)	loss nan (nan)	prob nan (nan)	GS 33.484 (33.484)	mem 39.975
Train: [55][270/750]	BT 0.091 (1.230)	DT 0.002 (1.097)	loss nan (nan)	prob nan (nan)	GS 35.234 (35.234)	mem 40.028
Train: [55][275/750]	BT 0.110 (1.209)	DT 0.004 (1.077)	loss nan (nan)	prob nan (nan)	GS 27.875 (27.875)	mem 39.934
Train: [55][280/750]	BT 0.193 (1.232)	DT 0.006 (1.099)	loss nan (nan)	prob nan (nan)	GS 33.547 (33.547)	mem 39.939
Train: [55][285/750]	BT 0.086 (1.213)	DT 0.002 (1.080)	loss nan (nan)	prob nan (nan)	GS 27.312 (27.312)	mem 40.022
Train: [55][290/750]	BT 9.037 (1.234)	DT 8.956 (1.101)	loss nan (nan)	prob nan (nan)	GS 31.859 (31.859)	mem 39.931
Train: [55][295/750]	BT 0.112 (1.216)	DT 0.009 (1.083)	loss nan (nan)	prob nan (nan)	GS 31.359 (31.359)	mem 39.935
Train: [55][300/750]	BT 1.242 (1.202)	DT 1.166 (1.069)	loss nan (nan)	prob nan (nan)	GS 35.438 (35.438)	mem 39.939
Train: [55][305/750]	BT 0.113 (1.217)	DT 0.026 (1.085)	loss nan (nan)	prob nan (nan)	GS 33.109 (33.109)	mem 40.025
Train: [55][310/750]	BT 0.128 (1.199)	DT 0.002 (1.067)	loss nan (nan)	prob nan (nan)	GS 27.969 (27.969)	mem 40.069
Train: [55][315/750]	BT 0.070 (1.232)	DT 0.001 (1.100)	loss nan (nan)	prob nan (nan)	GS 29.266 (29.266)	mem 40.045
Train: [55][320/750]	BT 0.075 (1.214)	DT 0.002 (1.083)	loss nan (nan)	prob nan (nan)	GS 36.641 (36.641)	mem 40.046
Train: [55][325/750]	BT 0.088 (1.198)	DT 0.004 (1.067)	loss nan (nan)	prob nan (nan)	GS 31.938 (31.938)	mem 40.050
Train: [55][330/750]	BT 0.161 (1.216)	DT 0.001 (1.085)	loss nan (nan)	prob nan (nan)	GS 34.094 (34.094)	mem 39.998
Train: [55][335/750]	BT 0.245 (1.200)	DT 0.002 (1.069)	loss nan (nan)	prob nan (nan)	GS 31.328 (31.328)	mem 40.104
Train: [55][340/750]	BT 0.165 (1.218)	DT 0.001 (1.087)	loss nan (nan)	prob nan (nan)	GS 35.531 (35.531)	mem 40.127
Train: [55][345/750]	BT 0.081 (1.203)	DT 0.002 (1.071)	loss nan (nan)	prob nan (nan)	GS 31.094 (31.094)	mem 40.136
Train: [55][350/750]	BT 4.848 (1.224)	DT 4.775 (1.091)	loss nan (nan)	prob nan (nan)	GS 34.781 (34.781)	mem 40.092
Train: [55][355/750]	BT 0.115 (1.208)	DT 0.014 (1.076)	loss nan (nan)	prob nan (nan)	GS 32.281 (32.281)	mem 40.162
Train: [55][360/750]	BT 4.570 (1.206)	DT 4.402 (1.073)	loss nan (nan)	prob nan (nan)	GS 29.438 (29.438)	mem 40.089
Train: [55][365/750]	BT 0.089 (1.206)	DT 0.002 (1.074)	loss nan (nan)	prob nan (nan)	GS 30.266 (30.266)	mem 40.018
Train: [55][370/750]	BT 0.076 (1.192)	DT 0.001 (1.060)	loss nan (nan)	prob nan (nan)	GS 35.109 (35.109)	mem 40.017
Train: [55][375/750]	BT 0.076 (1.215)	DT 0.002 (1.083)	loss nan (nan)	prob nan (nan)	GS 31.484 (31.484)	mem 39.985
Train: [55][380/750]	BT 0.150 (1.200)	DT 0.002 (1.069)	loss nan (nan)	prob nan (nan)	GS 32.422 (32.422)	mem 39.922
Train: [55][385/750]	BT 0.086 (1.192)	DT 0.002 (1.061)	loss nan (nan)	prob nan (nan)	GS 32.500 (32.500)	mem 39.962
Train: [55][390/750]	BT 0.114 (1.196)	DT 0.008 (1.065)	loss nan (nan)	prob nan (nan)	GS 33.938 (33.938)	mem 40.136
Train: [55][395/750]	BT 0.090 (1.182)	DT 0.002 (1.052)	loss nan (nan)	prob nan (nan)	GS 32.609 (32.609)	mem 40.044
Train: [55][400/750]	BT 0.218 (1.196)	DT 0.004 (1.065)	loss nan (nan)	prob nan (nan)	GS 38.219 (38.219)	mem 40.100
Train: [55][405/750]	BT 0.106 (1.183)	DT 0.005 (1.052)	loss nan (nan)	prob nan (nan)	GS 32.156 (32.156)	mem 40.007
Train: [55][410/750]	BT 9.026 (1.201)	DT 8.894 (1.069)	loss nan (nan)	prob nan (nan)	GS 35.766 (35.766)	mem 39.993
Train: [55][415/750]	BT 0.269 (1.189)	DT 0.007 (1.056)	loss nan (nan)	prob nan (nan)	GS 28.250 (28.250)	mem 39.992
Train: [55][420/750]	BT 3.070 (1.183)	DT 2.946 (1.051)	loss nan (nan)	prob nan (nan)	GS 32.266 (32.266)	mem 39.989
Train: [55][425/750]	BT 0.078 (1.194)	DT 0.001 (1.062)	loss nan (nan)	prob nan (nan)	GS 30.375 (30.375)	mem 39.899
Train: [55][430/750]	BT 0.159 (1.182)	DT 0.002 (1.050)	loss nan (nan)	prob nan (nan)	GS 34.234 (34.234)	mem 39.858
Train: [55][435/750]	BT 0.084 (1.201)	DT 0.001 (1.069)	loss nan (nan)	prob nan (nan)	GS 25.781 (25.781)	mem 39.909
Train: [55][440/750]	BT 0.084 (1.188)	DT 0.011 (1.057)	loss nan (nan)	prob nan (nan)	GS 34.641 (34.641)	mem 39.942
Train: [55][445/750]	BT 0.118 (1.177)	DT 0.002 (1.046)	loss nan (nan)	prob nan (nan)	GS 31.391 (31.391)	mem 40.033
Train: [55][450/750]	BT 0.107 (1.188)	DT 0.002 (1.057)	loss nan (nan)	prob nan (nan)	GS 32.250 (32.250)	mem 39.986
Train: [55][455/750]	BT 0.131 (1.176)	DT 0.001 (1.046)	loss nan (nan)	prob nan (nan)	GS 35.016 (35.016)	mem 40.040
Train: [55][460/750]	BT 0.108 (1.191)	DT 0.007 (1.060)	loss nan (nan)	prob nan (nan)	GS 33.406 (33.406)	mem 39.973
Train: [55][465/750]	BT 0.110 (1.180)	DT 0.013 (1.049)	loss nan (nan)	prob nan (nan)	GS 34.125 (34.125)	mem 40.052
Train: [55][470/750]	BT 5.419 (1.192)	DT 5.302 (1.061)	loss nan (nan)	prob nan (nan)	GS 34.375 (34.375)	mem 40.059
Train: [55][475/750]	BT 0.172 (1.181)	DT 0.011 (1.050)	loss nan (nan)	prob nan (nan)	GS 40.219 (40.219)	mem 40.062
Train: [55][480/750]	BT 7.670 (1.186)	DT 7.521 (1.055)	loss nan (nan)	prob nan (nan)	GS 33.609 (33.609)	mem 40.082
Train: [55][485/750]	BT 0.089 (1.180)	DT 0.002 (1.049)	loss nan (nan)	prob nan (nan)	GS 33.656 (33.656)	mem 40.084
Train: [55][490/750]	BT 0.163 (1.169)	DT 0.022 (1.038)	loss nan (nan)	prob nan (nan)	GS 35.438 (35.438)	mem 40.087
Train: [55][495/750]	BT 0.191 (1.189)	DT 0.002 (1.058)	loss nan (nan)	prob nan (nan)	GS 31.266 (31.266)	mem 40.153
Train: [55][500/750]	BT 0.127 (1.178)	DT 0.001 (1.048)	loss nan (nan)	prob nan (nan)	GS 31.547 (31.547)	mem 40.029
Train: [55][505/750]	BT 0.092 (1.174)	DT 0.002 (1.044)	loss nan (nan)	prob nan (nan)	GS 29.812 (29.812)	mem 40.157
Train: [55][510/750]	BT 0.084 (1.186)	DT 0.002 (1.056)	loss nan (nan)	prob nan (nan)	GS 31.875 (31.875)	mem 40.029
Train: [55][515/750]	BT 0.081 (1.175)	DT 0.002 (1.046)	loss nan (nan)	prob nan (nan)	GS 27.938 (27.938)	mem 40.030
Train: [55][520/750]	BT 0.098 (1.182)	DT 0.002 (1.053)	loss nan (nan)	prob nan (nan)	GS 34.391 (34.391)	mem 40.210
Train: [55][525/750]	BT 0.124 (1.173)	DT 0.001 (1.043)	loss nan (nan)	prob nan (nan)	GS 32.734 (32.734)	mem 40.047
Train: [55][530/750]	BT 11.871 (1.186)	DT 11.799 (1.056)	loss nan (nan)	prob nan (nan)	GS 33.609 (33.609)	mem 40.052
Train: [55][535/750]	BT 0.189 (1.176)	DT 0.008 (1.046)	loss nan (nan)	prob nan (nan)	GS 32.844 (32.844)	mem 40.055
Train: [55][540/750]	BT 0.130 (1.167)	DT 0.009 (1.036)	loss nan (nan)	prob nan (nan)	GS 32.125 (32.125)	mem 40.066
Train: [55][545/750]	BT 0.085 (1.182)	DT 0.001 (1.051)	loss nan (nan)	prob nan (nan)	GS 31.297 (31.297)	mem 40.081
Train: [55][550/750]	BT 0.114 (1.172)	DT 0.002 (1.042)	loss nan (nan)	prob nan (nan)	GS 32.516 (32.516)	mem 40.305
Train: [55][555/750]	BT 0.069 (1.190)	DT 0.002 (1.060)	loss nan (nan)	prob nan (nan)	GS 33.984 (33.984)	mem 40.022
Train: [55][560/750]	BT 0.207 (1.181)	DT 0.001 (1.050)	loss nan (nan)	prob nan (nan)	GS 33.797 (33.797)	mem 39.997
Train: [55][565/750]	BT 0.176 (1.172)	DT 0.005 (1.041)	loss nan (nan)	prob nan (nan)	GS 27.828 (27.828)	mem 39.999
Train: [55][570/750]	BT 0.111 (1.183)	DT 0.008 (1.052)	loss nan (nan)	prob nan (nan)	GS 34.875 (34.875)	mem 40.143
Train: [55][575/750]	BT 0.134 (1.173)	DT 0.002 (1.043)	loss nan (nan)	prob nan (nan)	GS 29.609 (29.609)	mem 40.050
Train: [55][580/750]	BT 0.084 (1.186)	DT 0.001 (1.055)	loss nan (nan)	prob nan (nan)	GS 31.938 (31.938)	mem 40.000
Train: [55][585/750]	BT 0.108 (1.177)	DT 0.002 (1.046)	loss nan (nan)	prob nan (nan)	GS 31.812 (31.812)	mem 40.002
Train: [55][590/750]	BT 11.797 (1.187)	DT 11.721 (1.057)	loss nan (nan)	prob nan (nan)	GS 35.062 (35.062)	mem 39.997
Train: [55][595/750]	BT 0.075 (1.178)	DT 0.001 (1.048)	loss nan (nan)	prob nan (nan)	GS 29.734 (29.734)	mem 40.035
Train: [55][600/750]	BT 0.226 (1.169)	DT 0.015 (1.040)	loss nan (nan)	prob nan (nan)	GS 37.000 (37.000)	mem 40.311
Train: [55][605/750]	BT 0.080 (1.179)	DT 0.007 (1.049)	loss nan (nan)	prob nan (nan)	GS 29.766 (29.766)	mem 40.063
Train: [55][610/750]	BT 0.090 (1.170)	DT 0.006 (1.041)	loss nan (nan)	prob nan (nan)	GS 34.906 (34.906)	mem 40.096
Train: [55][615/750]	BT 0.161 (1.180)	DT 0.001 (1.051)	loss nan (nan)	prob nan (nan)	GS 28.109 (28.109)	mem 40.151
Train: [55][620/750]	BT 0.142 (1.171)	DT 0.002 (1.042)	loss nan (nan)	prob nan (nan)	GS 36.391 (36.391)	mem 40.166
Train: [55][625/750]	BT 0.217 (1.171)	DT 0.006 (1.042)	loss nan (nan)	prob nan (nan)	GS 32.531 (32.531)	mem 40.102
Train: [55][630/750]	BT 0.117 (1.172)	DT 0.002 (1.043)	loss nan (nan)	prob nan (nan)	GS 32.047 (32.047)	mem 40.114
Train: [55][635/750]	BT 0.172 (1.167)	DT 0.002 (1.038)	loss nan (nan)	prob nan (nan)	GS 29.562 (29.562)	mem 40.130
Train: [55][640/750]	BT 2.830 (1.177)	DT 2.740 (1.048)	loss nan (nan)	prob nan (nan)	GS 33.734 (33.734)	mem 40.009
Train: [55][645/750]	BT 0.117 (1.169)	DT 0.001 (1.040)	loss nan (nan)	prob nan (nan)	GS 31.609 (31.609)	mem 40.021
Train: [55][650/750]	BT 8.014 (1.173)	DT 7.932 (1.045)	loss nan (nan)	prob nan (nan)	GS 35.438 (35.438)	mem 40.130
Train: [55][655/750]	BT 0.086 (1.169)	DT 0.002 (1.041)	loss nan (nan)	prob nan (nan)	GS 28.312 (28.312)	mem 40.121
Train: [55][660/750]	BT 0.159 (1.164)	DT 0.002 (1.036)	loss nan (nan)	prob nan (nan)	GS 35.219 (35.219)	mem 40.142
Train: [55][665/750]	BT 0.071 (1.176)	DT 0.001 (1.048)	loss nan (nan)	prob nan (nan)	GS 30.891 (30.891)	mem 39.932
Train: [55][670/750]	BT 0.096 (1.168)	DT 0.002 (1.040)	loss nan (nan)	prob nan (nan)	GS 31.406 (31.406)	mem 39.879
Train: [55][675/750]	BT 0.198 (1.167)	DT 0.014 (1.039)	loss nan (nan)	prob nan (nan)	GS 31.359 (31.359)	mem 39.975
Train: [55][680/750]	BT 0.092 (1.171)	DT 0.001 (1.043)	loss nan (nan)	prob nan (nan)	GS 33.141 (33.141)	mem 40.095
Train: [55][685/750]	BT 0.128 (1.165)	DT 0.002 (1.037)	loss nan (nan)	prob nan (nan)	GS 30.094 (30.094)	mem 40.050
Train: [55][690/750]	BT 0.143 (1.171)	DT 0.001 (1.043)	loss nan (nan)	prob nan (nan)	GS 32.875 (32.875)	mem 40.071
Train: [55][695/750]	BT 0.210 (1.164)	DT 0.002 (1.036)	loss nan (nan)	prob nan (nan)	GS 32.922 (32.922)	mem 40.089
Train: [55][700/750]	BT 2.460 (1.172)	DT 2.358 (1.044)	loss nan (nan)	prob nan (nan)	GS 35.141 (35.141)	mem 40.003
Train: [55][705/750]	BT 0.119 (1.165)	DT 0.002 (1.037)	loss nan (nan)	prob nan (nan)	GS 31.469 (31.469)	mem 39.956
arpack error, retry= 0
arpack error, retry= 0
arpack error, retry= 0
arpack error, retry= 0
Train: [55][710/750]	BT 3.030 (1.172)	DT 2.878 (1.044)	loss nan (nan)	prob nan (nan)	GS 30.938 (30.938)	mem 40.051
Train: [55][715/750]	BT 0.090 (1.171)	DT 0.002 (1.043)	loss nan (nan)	prob nan (nan)	GS 28.125 (28.125)	mem 40.021
Train: [55][720/750]	BT 6.230 (1.172)	DT 6.012 (1.044)	loss nan (nan)	prob nan (nan)	GS 35.078 (35.078)	mem 40.024
Train: [55][725/750]	BT 0.064 (1.172)	DT 0.001 (1.044)	loss nan (nan)	prob nan (nan)	GS 32.344 (32.344)	mem 39.922
Train: [55][730/750]	BT 0.130 (1.164)	DT 0.014 (1.037)	loss nan (nan)	prob nan (nan)	GS 32.094 (32.094)	mem 39.989
Train: [55][735/750]	BT 0.166 (1.165)	DT 0.004 (1.038)	loss nan (nan)	prob nan (nan)	GS 33.406 (33.406)	mem 36.779
Train: [55][740/750]	BT 0.178 (1.161)	DT 0.014 (1.034)	loss nan (nan)	prob nan (nan)	GS 36.250 (36.250)	mem 24.393
Train: [55][745/750]	BT 0.077 (1.158)	DT 0.001 (1.031)	loss nan (nan)	prob nan (nan)	GS 36.250 (36.250)	mem 13.651
Train: [55][750/750]	BT 0.085 (1.152)	DT 0.001 (1.025)	loss nan (nan)	prob nan (nan)	GS 39.188 (39.188)	mem 10.599
Train: [55][755/750]	BT 0.085 (1.145)	DT 0.001 (1.018)	loss nan (nan)	prob nan (nan)	GS 28.125 (28.125)	mem 10.600
epoch 55, total time 866.24
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [56][1/750]	BT 23.879 (23.879)	DT 23.692 (23.692)	loss nan (nan)	prob nan (nan)	GS 32.656 (32.656)	mem 38.592
Train: [56][5/750]	BT 0.211 (5.180)	DT 0.004 (5.021)	loss nan (nan)	prob nan (nan)	GS 29.344 (29.344)	mem 38.703
Train: [56][10/750]	BT 1.445 (2.788)	DT 1.331 (2.653)	loss nan (nan)	prob nan (nan)	GS 36.938 (36.938)	mem 38.912
Train: [56][15/750]	BT 0.103 (2.692)	DT 0.001 (2.554)	loss nan (nan)	prob nan (nan)	GS 25.797 (25.797)	mem 38.926
Train: [56][20/750]	BT 0.235 (2.048)	DT 0.002 (1.916)	loss nan (nan)	prob nan (nan)	GS 32.625 (32.625)	mem 38.949
Train: [56][25/750]	BT 0.176 (1.716)	DT 0.043 (1.585)	loss nan (nan)	prob nan (nan)	GS 34.141 (34.141)	mem 38.965
Train: [56][30/750]	BT 0.161 (1.830)	DT 0.001 (1.694)	loss nan (nan)	prob nan (nan)	GS 33.766 (33.766)	mem 39.124
Train: [56][35/750]	BT 0.095 (1.587)	DT 0.002 (1.452)	loss nan (nan)	prob nan (nan)	GS 33.141 (33.141)	mem 39.101
Train: [56][40/750]	BT 0.158 (1.676)	DT 0.009 (1.541)	loss nan (nan)	prob nan (nan)	GS 34.047 (34.047)	mem 39.118
Train: [56][45/750]	BT 0.230 (1.503)	DT 0.002 (1.370)	loss nan (nan)	prob nan (nan)	GS 30.641 (30.641)	mem 39.365
Train: [56][50/750]	BT 12.430 (1.615)	DT 12.352 (1.481)	loss nan (nan)	prob nan (nan)	GS 31.766 (31.766)	mem 39.136
Train: [56][55/750]	BT 0.081 (1.479)	DT 0.002 (1.347)	loss nan (nan)	prob nan (nan)	GS 29.672 (29.672)	mem 39.138
Train: [56][60/750]	BT 0.094 (1.421)	DT 0.001 (1.291)	loss nan (nan)	prob nan (nan)	GS 35.938 (35.938)	mem 39.168
Train: [56][65/750]	BT 0.110 (1.445)	DT 0.009 (1.315)	loss nan (nan)	prob nan (nan)	GS 33.203 (33.203)	mem 39.140
Train: [56][70/750]	BT 3.348 (1.397)	DT 3.252 (1.268)	loss nan (nan)	prob nan (nan)	GS 32.078 (32.078)	mem 39.210
Train: [56][75/750]	BT 0.120 (1.431)	DT 0.002 (1.301)	loss nan (nan)	prob nan (nan)	GS 46.438 (46.438)	mem 39.226
Train: [56][80/750]	BT 0.087 (1.349)	DT 0.002 (1.220)	loss nan (nan)	prob nan (nan)	GS 35.672 (35.672)	mem 39.237
Train: [56][85/750]	BT 0.100 (1.308)	DT 0.004 (1.178)	loss nan (nan)	prob nan (nan)	GS 28.500 (28.500)	mem 39.466
Train: [56][90/750]	BT 0.088 (1.391)	DT 0.002 (1.264)	loss nan (nan)	prob nan (nan)	GS 35.344 (35.344)	mem 39.218
Train: [56][95/750]	BT 0.232 (1.326)	DT 0.050 (1.198)	loss nan (nan)	prob nan (nan)	GS 31.125 (31.125)	mem 39.229
Train: [56][100/750]	BT 0.090 (1.403)	DT 0.003 (1.276)	loss nan (nan)	prob nan (nan)	GS 33.625 (33.625)	mem 39.645
Train: [56][105/750]	BT 0.172 (1.343)	DT 0.020 (1.215)	loss nan (nan)	prob nan (nan)	GS 31.062 (31.062)	mem 39.610
Train: [56][110/750]	BT 11.325 (1.391)	DT 10.989 (1.260)	loss nan (nan)	prob nan (nan)	GS 32.250 (32.250)	mem 39.666
Train: [56][115/750]	BT 0.099 (1.335)	DT 0.001 (1.205)	loss nan (nan)	prob nan (nan)	GS 34.625 (34.625)	mem 39.558
Train: [56][120/750]	BT 0.074 (1.285)	DT 0.001 (1.155)	loss nan (nan)	prob nan (nan)	GS 40.156 (40.156)	mem 39.570
Train: [56][125/750]	BT 0.072 (1.362)	DT 0.001 (1.234)	loss nan (nan)	prob nan (nan)	GS 27.719 (27.719)	mem 39.609
Train: [56][130/750]	BT 0.084 (1.313)	DT 0.001 (1.187)	loss nan (nan)	prob nan (nan)	GS 35.359 (35.359)	mem 39.546
Train: [56][135/750]	BT 0.150 (1.348)	DT 0.003 (1.222)	loss nan (nan)	prob nan (nan)	GS 27.844 (27.844)	mem 39.949
Train: [56][140/750]	BT 0.174 (1.304)	DT 0.001 (1.178)	loss nan (nan)	prob nan (nan)	GS 36.000 (36.000)	mem 39.892
Train: [56][145/750]	BT 0.098 (1.264)	DT 0.002 (1.138)	loss nan (nan)	prob nan (nan)	GS 30.375 (30.375)	mem 39.848
Train: [56][150/750]	BT 0.177 (1.316)	DT 0.010 (1.191)	loss nan (nan)	prob nan (nan)	GS 29.562 (29.562)	mem 39.981
Train: [56][155/750]	BT 0.110 (1.278)	DT 0.014 (1.152)	loss nan (nan)	prob nan (nan)	GS 29.984 (29.984)	mem 39.874
Train: [56][160/750]	BT 0.135 (1.329)	DT 0.001 (1.204)	loss nan (nan)	prob nan (nan)	GS 32.047 (32.047)	mem 39.847
Train: [56][165/750]	BT 0.155 (1.293)	DT 0.001 (1.168)	loss nan (nan)	prob nan (nan)	GS 38.844 (38.844)	mem 39.848
Train: [56][170/750]	BT 8.116 (1.306)	DT 7.862 (1.180)	loss nan (nan)	prob nan (nan)	GS 31.609 (31.609)	mem 39.934
Train: [56][175/750]	BT 0.354 (1.277)	DT 0.004 (1.146)	loss nan (nan)	prob nan (nan)	GS 33.469 (33.469)	mem 40.004
Train: [56][180/750]	BT 0.117 (1.246)	DT 0.002 (1.115)	loss nan (nan)	prob nan (nan)	GS 33.578 (33.578)	mem 40.001
Train: [56][185/750]	BT 0.140 (1.296)	DT 0.002 (1.165)	loss nan (nan)	prob nan (nan)	GS 41.219 (41.219)	mem 39.878
Train: [56][190/750]	BT 0.200 (1.265)	DT 0.051 (1.135)	loss nan (nan)	prob nan (nan)	GS 37.750 (37.750)	mem 39.879
Train: [56][195/750]	BT 0.213 (1.294)	DT 0.012 (1.164)	loss nan (nan)	prob nan (nan)	GS 31.484 (31.484)	mem 39.998
Train: [56][200/750]	BT 0.081 (1.264)	DT 0.001 (1.135)	loss nan (nan)	prob nan (nan)	GS 40.438 (40.438)	mem 39.923
Train: [56][205/750]	BT 0.206 (1.236)	DT 0.001 (1.107)	loss nan (nan)	prob nan (nan)	GS 31.531 (31.531)	mem 39.926
Train: [56][210/750]	BT 0.119 (1.273)	DT 0.017 (1.144)	loss nan (nan)	prob nan (nan)	GS 34.625 (34.625)	mem 39.913
Train: [56][215/750]	BT 0.212 (1.247)	DT 0.007 (1.117)	loss nan (nan)	prob nan (nan)	GS 27.500 (27.500)	mem 39.877
Train: [56][220/750]	BT 0.091 (1.267)	DT 0.001 (1.138)	loss nan (nan)	prob nan (nan)	GS 30.484 (30.484)	mem 40.028
Train: [56][225/750]	BT 0.130 (1.242)	DT 0.001 (1.113)	loss nan (nan)	prob nan (nan)	GS 29.250 (29.250)	mem 40.241
Train: [56][230/750]	BT 13.447 (1.276)	DT 13.261 (1.147)	loss nan (nan)	prob nan (nan)	GS 31.844 (31.844)	mem 40.097
Train: [56][235/750]	BT 0.131 (1.251)	DT 0.008 (1.122)	loss nan (nan)	prob nan (nan)	GS 30.188 (30.188)	mem 40.029
Train: [56][240/750]	BT 0.164 (1.234)	DT 0.001 (1.105)	loss nan (nan)	prob nan (nan)	GS 32.609 (32.609)	mem 40.065
Train: [56][245/750]	BT 0.159 (1.251)	DT 0.002 (1.123)	loss nan (nan)	prob nan (nan)	GS 30.953 (30.953)	mem 40.111
Train: [56][250/750]	BT 0.083 (1.241)	DT 0.001 (1.112)	loss nan (nan)	prob nan (nan)	GS 30.656 (30.656)	mem 40.074
Train: [56][255/750]	BT 0.156 (1.259)	DT 0.005 (1.129)	loss nan (nan)	prob nan (nan)	GS 28.094 (28.094)	mem 40.175
Train: [56][260/750]	BT 2.793 (1.247)	DT 2.650 (1.118)	loss nan (nan)	prob nan (nan)	GS 32.516 (32.516)	mem 40.084
Train: [56][265/750]	BT 0.116 (1.226)	DT 0.017 (1.097)	loss nan (nan)	prob nan (nan)	GS 30.812 (30.812)	mem 40.084
Train: [56][270/750]	BT 0.086 (1.236)	DT 0.001 (1.106)	loss nan (nan)	prob nan (nan)	GS 32.859 (32.859)	mem 40.134
Train: [56][275/750]	BT 0.104 (1.223)	DT 0.009 (1.093)	loss nan (nan)	prob nan (nan)	GS 35.219 (35.219)	mem 40.029
Train: [56][280/750]	BT 0.139 (1.231)	DT 0.004 (1.102)	loss nan (nan)	prob nan (nan)	GS 29.281 (29.281)	mem 40.066
Train: [56][285/750]	BT 0.091 (1.216)	DT 0.008 (1.087)	loss nan (nan)	prob nan (nan)	GS 30.484 (30.484)	mem 40.147
Train: [56][290/750]	BT 11.973 (1.239)	DT 11.893 (1.110)	loss nan (nan)	prob nan (nan)	GS 33.266 (33.266)	mem 40.123
Train: [56][295/750]	BT 0.106 (1.220)	DT 0.002 (1.091)	loss nan (nan)	prob nan (nan)	GS 34.750 (34.750)	mem 40.134
Train: [56][300/750]	BT 0.103 (1.202)	DT 0.008 (1.073)	loss nan (nan)	prob nan (nan)	GS 37.750 (37.750)	mem 40.061
Train: [56][305/750]	BT 0.208 (1.219)	DT 0.025 (1.089)	loss nan (nan)	prob nan (nan)	GS 33.922 (33.922)	mem 40.111
Train: [56][310/750]	BT 0.122 (1.201)	DT 0.002 (1.072)	loss nan (nan)	prob nan (nan)	GS 31.781 (31.781)	mem 40.193
Train: [56][315/750]	BT 0.116 (1.222)	DT 0.001 (1.094)	loss nan (nan)	prob nan (nan)	GS 29.188 (29.188)	mem 40.077
Train: [56][320/750]	BT 0.083 (1.205)	DT 0.002 (1.077)	loss nan (nan)	prob nan (nan)	GS 30.953 (30.953)	mem 40.077
Train: [56][325/750]	BT 0.121 (1.189)	DT 0.001 (1.060)	loss nan (nan)	prob nan (nan)	GS 31.125 (31.125)	mem 40.082
Train: [56][330/750]	BT 0.100 (1.206)	DT 0.002 (1.078)	loss nan (nan)	prob nan (nan)	GS 33.688 (33.688)	mem 40.266
Train: [56][335/750]	BT 0.251 (1.190)	DT 0.002 (1.062)	loss nan (nan)	prob nan (nan)	GS 28.062 (28.062)	mem 40.124
Train: [56][340/750]	BT 0.121 (1.215)	DT 0.008 (1.086)	loss nan (nan)	prob nan (nan)	GS 31.953 (31.953)	mem 40.052
Train: [56][345/750]	BT 0.123 (1.199)	DT 0.002 (1.071)	loss nan (nan)	prob nan (nan)	GS 32.688 (32.688)	mem 40.103
Train: [56][350/750]	BT 12.950 (1.220)	DT 12.879 (1.092)	loss nan (nan)	prob nan (nan)	GS 35.516 (35.516)	mem 40.140
Train: [56][355/750]	BT 0.076 (1.204)	DT 0.004 (1.077)	loss nan (nan)	prob nan (nan)	GS 30.250 (30.250)	mem 40.194
Train: [56][360/750]	BT 0.213 (1.190)	DT 0.002 (1.062)	loss nan (nan)	prob nan (nan)	GS 31.625 (31.625)	mem 40.210
Train: [56][365/750]	BT 0.069 (1.212)	DT 0.001 (1.085)	loss nan (nan)	prob nan (nan)	GS 32.750 (32.750)	mem 40.039
Train: [56][370/750]	BT 0.130 (1.198)	DT 0.003 (1.071)	loss nan (nan)	prob nan (nan)	GS 35.266 (35.266)	mem 40.154
Train: [56][375/750]	BT 0.110 (1.210)	DT 0.002 (1.083)	loss nan (nan)	prob nan (nan)	GS 34.078 (34.078)	mem 40.103
Train: [56][380/750]	BT 0.141 (1.196)	DT 0.011 (1.069)	loss nan (nan)	prob nan (nan)	GS 36.984 (36.984)	mem 40.116
Train: [56][385/750]	BT 0.119 (1.182)	DT 0.002 (1.055)	loss nan (nan)	prob nan (nan)	GS 34.234 (34.234)	mem 40.296
Train: [56][390/750]	BT 0.097 (1.202)	DT 0.002 (1.076)	loss nan (nan)	prob nan (nan)	GS 35.047 (35.047)	mem 39.977
Train: [56][395/750]	BT 0.086 (1.189)	DT 0.002 (1.063)	loss nan (nan)	prob nan (nan)	GS 30.656 (30.656)	mem 39.994
Train: [56][400/750]	BT 0.117 (1.208)	DT 0.002 (1.082)	loss nan (nan)	prob nan (nan)	GS 36.125 (36.125)	mem 40.061
Train: [56][405/750]	BT 0.144 (1.194)	DT 0.002 (1.068)	loss nan (nan)	prob nan (nan)	GS 32.297 (32.297)	mem 40.103
Train: [56][410/750]	BT 12.723 (1.212)	DT 12.654 (1.086)	loss nan (nan)	prob nan (nan)	GS 35.328 (35.328)	mem 40.061
Train: [56][415/750]	BT 0.072 (1.199)	DT 0.001 (1.073)	loss nan (nan)	prob nan (nan)	GS 32.234 (32.234)	mem 40.065
Train: [56][420/750]	BT 0.088 (1.186)	DT 0.002 (1.060)	loss nan (nan)	prob nan (nan)	GS 34.562 (34.562)	mem 40.113
Train: [56][425/750]	BT 0.139 (1.199)	DT 0.009 (1.074)	loss nan (nan)	prob nan (nan)	GS 37.672 (37.672)	mem 40.023
Train: [56][430/750]	BT 0.242 (1.187)	DT 0.008 (1.061)	loss nan (nan)	prob nan (nan)	GS 35.844 (35.844)	mem 40.024
Train: [56][435/750]	BT 0.066 (1.203)	DT 0.002 (1.078)	loss nan (nan)	prob nan (nan)	GS 31.141 (31.141)	mem 39.951
Train: [56][440/750]	BT 0.078 (1.191)	DT 0.002 (1.066)	loss nan (nan)	prob nan (nan)	GS 35.438 (35.438)	mem 40.014
Train: [56][445/750]	BT 0.108 (1.179)	DT 0.001 (1.054)	loss nan (nan)	prob nan (nan)	GS 33.891 (33.891)	mem 40.032
Train: [56][450/750]	BT 0.126 (1.190)	DT 0.005 (1.065)	loss nan (nan)	prob nan (nan)	GS 31.250 (31.250)	mem 40.068
Train: [56][455/750]	BT 0.093 (1.178)	DT 0.002 (1.053)	loss nan (nan)	prob nan (nan)	GS 33.438 (33.438)	mem 40.106
Train: [56][460/750]	BT 0.085 (1.189)	DT 0.002 (1.064)	loss nan (nan)	prob nan (nan)	GS 34.094 (34.094)	mem 40.078
Train: [56][465/750]	BT 0.099 (1.178)	DT 0.005 (1.053)	loss nan (nan)	prob nan (nan)	GS 29.031 (29.031)	mem 40.079
Train: [56][470/750]	BT 11.361 (1.191)	DT 11.211 (1.066)	loss nan (nan)	prob nan (nan)	GS 33.031 (33.031)	mem 40.062
Train: [56][475/750]	BT 0.165 (1.180)	DT 0.004 (1.055)	loss nan (nan)	prob nan (nan)	GS 30.062 (30.062)	mem 39.972
Train: [56][480/750]	BT 0.169 (1.169)	DT 0.017 (1.044)	loss nan (nan)	prob nan (nan)	GS 32.922 (32.922)	mem 39.984
Train: [56][485/750]	BT 0.131 (1.178)	DT 0.002 (1.053)	loss nan (nan)	prob nan (nan)	GS 30.391 (30.391)	mem 40.168
Train: [56][490/750]	BT 0.119 (1.168)	DT 0.002 (1.042)	loss nan (nan)	prob nan (nan)	GS 36.859 (36.859)	mem 40.013
Train: [56][495/750]	BT 0.117 (1.188)	DT 0.017 (1.061)	loss nan (nan)	prob nan (nan)	GS 30.828 (30.828)	mem 39.914
Train: [56][500/750]	BT 0.190 (1.177)	DT 0.002 (1.051)	loss nan (nan)	prob nan (nan)	GS 32.500 (32.500)	mem 39.916
Train: [56][505/750]	BT 0.130 (1.167)	DT 0.002 (1.041)	loss nan (nan)	prob nan (nan)	GS 31.453 (31.453)	mem 39.917
Train: [56][510/750]	BT 0.130 (1.176)	DT 0.003 (1.049)	loss nan (nan)	prob nan (nan)	GS 32.297 (32.297)	mem 40.375
Train: [56][515/750]	BT 0.121 (1.167)	DT 0.002 (1.040)	loss nan (nan)	prob nan (nan)	GS 28.266 (28.266)	mem 40.220
Train: [56][520/750]	BT 0.103 (1.181)	DT 0.002 (1.054)	loss nan (nan)	prob nan (nan)	GS 32.469 (32.469)	mem 40.002
Train: [56][525/750]	BT 0.223 (1.171)	DT 0.002 (1.044)	loss nan (nan)	prob nan (nan)	GS 30.656 (30.656)	mem 40.065
Train: [56][530/750]	BT 13.357 (1.186)	DT 13.202 (1.059)	loss nan (nan)	prob nan (nan)	GS 33.828 (33.828)	mem 40.062
Train: [56][535/750]	BT 0.135 (1.176)	DT 0.007 (1.050)	loss nan (nan)	prob nan (nan)	GS 32.328 (32.328)	mem 40.008
Train: [56][540/750]	BT 0.121 (1.167)	DT 0.001 (1.040)	loss nan (nan)	prob nan (nan)	GS 36.000 (36.000)	mem 39.993
Train: [56][545/750]	BT 0.084 (1.175)	DT 0.002 (1.048)	loss nan (nan)	prob nan (nan)	GS 29.906 (29.906)	mem 40.104
Train: [56][550/750]	BT 0.096 (1.171)	DT 0.002 (1.045)	loss nan (nan)	prob nan (nan)	GS 27.672 (27.672)	mem 40.150
Train: [56][555/750]	BT 0.200 (1.174)	DT 0.010 (1.047)	loss nan (nan)	prob nan (nan)	GS 30.922 (30.922)	mem 40.352
Train: [56][560/750]	BT 0.122 (1.176)	DT 0.003 (1.049)	loss nan (nan)	prob nan (nan)	GS 29.453 (29.453)	mem 40.185
Train: [56][565/750]	BT 0.130 (1.167)	DT 0.013 (1.040)	loss nan (nan)	prob nan (nan)	GS 31.797 (31.797)	mem 40.051
Train: [56][570/750]	BT 5.492 (1.172)	DT 5.411 (1.046)	loss nan (nan)	prob nan (nan)	GS 35.969 (35.969)	mem 40.135
Train: [56][575/750]	BT 0.126 (1.163)	DT 0.002 (1.037)	loss nan (nan)	prob nan (nan)	GS 33.344 (33.344)	mem 40.135
Train: [56][580/750]	BT 0.224 (1.166)	DT 0.024 (1.040)	loss nan (nan)	prob nan (nan)	GS 33.797 (33.797)	mem 40.086
Train: [56][585/750]	BT 0.103 (1.163)	DT 0.010 (1.037)	loss nan (nan)	prob nan (nan)	GS 31.484 (31.484)	mem 40.032
Train: [56][590/750]	BT 11.308 (1.173)	DT 11.163 (1.047)	loss nan (nan)	prob nan (nan)	GS 33.531 (33.531)	mem 40.149
Train: [56][595/750]	BT 0.235 (1.167)	DT 0.001 (1.040)	loss nan (nan)	prob nan (nan)	GS 30.516 (30.516)	mem 40.204
Train: [56][600/750]	BT 0.194 (1.159)	DT 0.005 (1.032)	loss nan (nan)	prob nan (nan)	GS 31.203 (31.203)	mem 40.081
Train: [56][605/750]	BT 0.151 (1.169)	DT 0.013 (1.042)	loss nan (nan)	prob nan (nan)	GS 31.484 (31.484)	mem 40.125
Train: [56][610/750]	BT 0.080 (1.164)	DT 0.001 (1.038)	loss nan (nan)	prob nan (nan)	GS 36.656 (36.656)	mem 40.063
Train: [56][615/750]	BT 0.164 (1.170)	DT 0.004 (1.044)	loss nan (nan)	prob nan (nan)	GS 29.875 (29.875)	mem 40.061
Train: [56][620/750]	BT 0.101 (1.166)	DT 0.014 (1.040)	loss nan (nan)	prob nan (nan)	GS 32.078 (32.078)	mem 40.012
Train: [56][625/750]	BT 0.262 (1.157)	DT 0.002 (1.031)	loss nan (nan)	prob nan (nan)	GS 29.750 (29.750)	mem 40.018
Train: [56][630/750]	BT 3.312 (1.164)	DT 3.195 (1.038)	loss nan (nan)	prob nan (nan)	GS 34.562 (34.562)	mem 40.089
Train: [56][635/750]	BT 0.334 (1.157)	DT 0.005 (1.030)	loss nan (nan)	prob nan (nan)	GS 28.781 (28.781)	mem 40.278
Train: [56][640/750]	BT 0.105 (1.166)	DT 0.014 (1.039)	loss nan (nan)	prob nan (nan)	GS 36.578 (36.578)	mem 40.049
Train: [56][645/750]	BT 0.123 (1.160)	DT 0.003 (1.033)	loss nan (nan)	prob nan (nan)	GS 30.484 (30.484)	mem 40.133
Train: [56][650/750]	BT 10.542 (1.168)	DT 10.440 (1.042)	loss nan (nan)	prob nan (nan)	GS 35.062 (35.062)	mem 40.170
Train: [56][655/750]	BT 0.109 (1.161)	DT 0.010 (1.034)	loss nan (nan)	prob nan (nan)	GS 28.469 (28.469)	mem 40.095
Train: [56][660/750]	BT 0.148 (1.153)	DT 0.010 (1.026)	loss nan (nan)	prob nan (nan)	GS 36.609 (36.609)	mem 40.175
Train: [56][665/750]	BT 0.143 (1.164)	DT 0.001 (1.038)	loss nan (nan)	prob nan (nan)	GS 28.703 (28.703)	mem 40.178
Train: [56][670/750]	BT 0.177 (1.157)	DT 0.013 (1.030)	loss nan (nan)	prob nan (nan)	GS 32.609 (32.609)	mem 40.085
Train: [56][675/750]	BT 0.149 (1.167)	DT 0.001 (1.040)	loss nan (nan)	prob nan (nan)	GS 35.859 (35.859)	mem 40.135
Train: [56][680/750]	BT 0.090 (1.161)	DT 0.001 (1.035)	loss nan (nan)	prob nan (nan)	GS 36.484 (36.484)	mem 40.200
Train: [56][685/750]	BT 0.158 (1.154)	DT 0.002 (1.027)	loss nan (nan)	prob nan (nan)	GS 35.641 (35.641)	mem 40.138
Train: [56][690/750]	BT 0.157 (1.161)	DT 0.004 (1.035)	loss nan (nan)	prob nan (nan)	GS 31.047 (31.047)	mem 40.148
Train: [56][695/750]	BT 0.164 (1.154)	DT 0.002 (1.027)	loss nan (nan)	prob nan (nan)	GS 34.094 (34.094)	mem 40.225
Train: [56][700/750]	BT 0.077 (1.164)	DT 0.001 (1.037)	loss nan (nan)	prob nan (nan)	GS 31.734 (31.734)	mem 40.107
Train: [56][705/750]	BT 0.128 (1.157)	DT 0.019 (1.030)	loss nan (nan)	prob nan (nan)	GS 28.891 (28.891)	mem 40.087
Train: [56][710/750]	BT 13.910 (1.169)	DT 13.762 (1.042)	loss nan (nan)	prob nan (nan)	GS 33.953 (33.953)	mem 40.072
Train: [56][715/750]	BT 0.136 (1.162)	DT 0.012 (1.035)	loss nan (nan)	prob nan (nan)	GS 28.688 (28.688)	mem 40.170
Train: [56][720/750]	BT 0.114 (1.154)	DT 0.002 (1.028)	loss nan (nan)	prob nan (nan)	GS 31.641 (31.641)	mem 40.163
Train: [56][725/750]	BT 0.137 (1.162)	DT 0.001 (1.035)	loss nan (nan)	prob nan (nan)	GS 29.797 (29.797)	mem 40.057
Train: [56][730/750]	BT 0.114 (1.155)	DT 0.001 (1.028)	loss nan (nan)	prob nan (nan)	GS 33.656 (33.656)	mem 40.058
Train: [56][735/750]	BT 0.100 (1.160)	DT 0.001 (1.033)	loss nan (nan)	prob nan (nan)	GS 37.250 (37.250)	mem 36.681
Train: [56][740/750]	BT 0.070 (1.153)	DT 0.002 (1.026)	loss nan (nan)	prob nan (nan)	GS 32.547 (32.547)	mem 36.645
Train: [56][745/750]	BT 0.194 (1.146)	DT 0.001 (1.019)	loss nan (nan)	prob nan (nan)	GS 22.125 (22.125)	mem 36.647
Train: [56][750/750]	BT 0.083 (1.142)	DT 0.001 (1.016)	loss nan (nan)	prob nan (nan)	GS 33.656 (33.656)	mem 7.636
Train: [56][755/750]	BT 0.086 (1.135)	DT 0.002 (1.010)	loss nan (nan)	prob nan (nan)	GS 28.750 (28.750)	mem 7.663
epoch 56, total time 857.44
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [57][1/750]	BT 33.856 (33.856)	DT 33.614 (33.614)	loss nan (nan)	prob nan (nan)	GS 54.312 (54.312)	mem 38.828
Train: [57][5/750]	BT 0.127 (6.873)	DT 0.004 (6.726)	loss nan (nan)	prob nan (nan)	GS 30.281 (30.281)	mem 38.832
Train: [57][10/750]	BT 0.183 (3.490)	DT 0.002 (3.364)	loss nan (nan)	prob nan (nan)	GS 35.891 (35.891)	mem 38.841
Train: [57][15/750]	BT 0.187 (2.899)	DT 0.002 (2.774)	loss nan (nan)	prob nan (nan)	GS 32.875 (32.875)	mem 39.263
Train: [57][20/750]	BT 0.173 (2.215)	DT 0.010 (2.082)	loss nan (nan)	prob nan (nan)	GS 33.078 (33.078)	mem 39.431
Train: [57][25/750]	BT 4.047 (2.119)	DT 3.891 (1.982)	loss nan (nan)	prob nan (nan)	GS 35.062 (35.062)	mem 39.537
Train: [57][30/750]	BT 0.194 (1.794)	DT 0.009 (1.654)	loss nan (nan)	prob nan (nan)	GS 33.094 (33.094)	mem 39.531
Train: [57][35/750]	BT 0.176 (1.742)	DT 0.002 (1.604)	loss nan (nan)	prob nan (nan)	GS 34.656 (34.656)	mem 39.638
Train: [57][40/750]	BT 2.948 (1.753)	DT 2.752 (1.615)	loss nan (nan)	prob nan (nan)	GS 36.125 (36.125)	mem 39.657
Train: [57][45/750]	BT 0.157 (1.575)	DT 0.002 (1.436)	loss nan (nan)	prob nan (nan)	GS 31.500 (31.500)	mem 39.887
Train: [57][50/750]	BT 0.209 (1.543)	DT 0.002 (1.403)	loss nan (nan)	prob nan (nan)	GS 31.766 (31.766)	mem 39.708
Train: [57][55/750]	BT 0.132 (1.513)	DT 0.007 (1.374)	loss nan (nan)	prob nan (nan)	GS 34.422 (34.422)	mem 39.576
Train: [57][60/750]	BT 0.217 (1.516)	DT 0.009 (1.375)	loss nan (nan)	prob nan (nan)	GS 32.234 (32.234)	mem 39.772
Train: [57][65/750]	BT 0.102 (1.479)	DT 0.002 (1.342)	loss nan (nan)	prob nan (nan)	GS 32.359 (32.359)	mem 39.750
Train: [57][70/750]	BT 5.722 (1.464)	DT 5.602 (1.326)	loss nan (nan)	prob nan (nan)	GS 32.109 (32.109)	mem 39.850
Train: [57][75/750]	BT 0.126 (1.375)	DT 0.006 (1.238)	loss nan (nan)	prob nan (nan)	GS 34.500 (34.500)	mem 39.800
Train: [57][80/750]	BT 0.118 (1.380)	DT 0.001 (1.244)	loss nan (nan)	prob nan (nan)	GS 36.375 (36.375)	mem 39.769
Train: [57][85/750]	BT 0.160 (1.383)	DT 0.002 (1.247)	loss nan (nan)	prob nan (nan)	GS 37.016 (37.016)	mem 39.763
Train: [57][90/750]	BT 2.553 (1.371)	DT 2.468 (1.235)	loss nan (nan)	prob nan (nan)	GS 32.641 (32.641)	mem 39.790
Train: [57][95/750]	BT 0.177 (1.403)	DT 0.007 (1.267)	loss nan (nan)	prob nan (nan)	GS 29.703 (29.703)	mem 39.770
Train: [57][100/750]	BT 1.118 (1.349)	DT 0.984 (1.213)	loss nan (nan)	prob nan (nan)	GS 36.875 (36.875)	mem 39.830
Train: [57][105/750]	BT 0.170 (1.332)	DT 0.001 (1.195)	loss nan (nan)	prob nan (nan)	GS 29.750 (29.750)	mem 39.836
Train: [57][110/750]	BT 0.173 (1.344)	DT 0.002 (1.206)	loss nan (nan)	prob nan (nan)	GS 34.781 (34.781)	mem 39.894
Train: [57][115/750]	BT 0.128 (1.352)	DT 0.002 (1.214)	loss nan (nan)	prob nan (nan)	GS 34.297 (34.297)	mem 39.900
Train: [57][120/750]	BT 0.096 (1.353)	DT 0.003 (1.213)	loss nan (nan)	prob nan (nan)	GS 33.016 (33.016)	mem 39.905
Train: [57][125/750]	BT 0.134 (1.334)	DT 0.002 (1.194)	loss nan (nan)	prob nan (nan)	GS 29.891 (29.891)	mem 39.869
Train: [57][130/750]	BT 8.514 (1.354)	DT 8.350 (1.212)	loss nan (nan)	prob nan (nan)	GS 31.766 (31.766)	mem 39.933
Train: [57][135/750]	BT 0.188 (1.310)	DT 0.001 (1.168)	loss nan (nan)	prob nan (nan)	GS 32.547 (32.547)	mem 39.935
Train: [57][140/750]	BT 0.121 (1.282)	DT 0.001 (1.141)	loss nan (nan)	prob nan (nan)	GS 30.688 (30.688)	mem 39.913
Train: [57][145/750]	BT 0.084 (1.296)	DT 0.001 (1.155)	loss nan (nan)	prob nan (nan)	GS 36.781 (36.781)	mem 39.962
Train: [57][150/750]	BT 0.184 (1.289)	DT 0.005 (1.148)	loss nan (nan)	prob nan (nan)	GS 36.094 (36.094)	mem 39.953
Train: [57][155/750]	BT 0.092 (1.290)	DT 0.002 (1.150)	loss nan (nan)	prob nan (nan)	GS 29.578 (29.578)	mem 39.915
Train: [57][160/750]	BT 7.412 (1.299)	DT 7.320 (1.160)	loss nan (nan)	prob nan (nan)	GS 29.328 (29.328)	mem 39.921
Train: [57][165/750]	BT 0.167 (1.264)	DT 0.017 (1.125)	loss nan (nan)	prob nan (nan)	GS 28.422 (28.422)	mem 39.875
Train: [57][170/750]	BT 0.185 (1.250)	DT 0.009 (1.112)	loss nan (nan)	prob nan (nan)	GS 29.047 (29.047)	mem 40.175
Train: [57][175/750]	BT 0.165 (1.262)	DT 0.010 (1.124)	loss nan (nan)	prob nan (nan)	GS 31.375 (31.375)	mem 39.930
Train: [57][180/750]	BT 0.106 (1.256)	DT 0.002 (1.117)	loss nan (nan)	prob nan (nan)	GS 35.141 (35.141)	mem 39.890
Train: [57][185/750]	BT 0.125 (1.278)	DT 0.005 (1.139)	loss nan (nan)	prob nan (nan)	GS 28.875 (28.875)	mem 39.884
Train: [57][190/750]	BT 3.450 (1.266)	DT 3.373 (1.127)	loss nan (nan)	prob nan (nan)	GS 34.391 (34.391)	mem 39.837
Train: [57][195/750]	BT 0.107 (1.237)	DT 0.021 (1.098)	loss nan (nan)	prob nan (nan)	GS 27.125 (27.125)	mem 40.039
Train: [57][200/750]	BT 0.115 (1.260)	DT 0.014 (1.122)	loss nan (nan)	prob nan (nan)	GS 30.422 (30.422)	mem 39.959
Train: [57][205/750]	BT 0.211 (1.245)	DT 0.021 (1.106)	loss nan (nan)	prob nan (nan)	GS 32.500 (32.500)	mem 39.917
Train: [57][210/750]	BT 0.131 (1.280)	DT 0.002 (1.141)	loss nan (nan)	prob nan (nan)	GS 34.062 (34.062)	mem 39.957
Train: [57][215/750]	BT 0.111 (1.253)	DT 0.002 (1.114)	loss nan (nan)	prob nan (nan)	GS 31.141 (31.141)	mem 39.948
Train: [57][220/750]	BT 13.097 (1.287)	DT 13.012 (1.148)	loss nan (nan)	prob nan (nan)	GS 32.969 (32.969)	mem 39.938
Train: [57][225/750]	BT 0.156 (1.261)	DT 0.020 (1.123)	loss nan (nan)	prob nan (nan)	GS 28.125 (28.125)	mem 39.939
Train: [57][230/750]	BT 0.130 (1.236)	DT 0.008 (1.099)	loss nan (nan)	prob nan (nan)	GS 35.406 (35.406)	mem 39.943
Train: [57][235/750]	BT 0.180 (1.258)	DT 0.001 (1.120)	loss nan (nan)	prob nan (nan)	GS 33.859 (33.859)	mem 40.037
Train: [57][240/750]	BT 0.137 (1.235)	DT 0.002 (1.097)	loss nan (nan)	prob nan (nan)	GS 30.406 (30.406)	mem 39.907
Train: [57][245/750]	BT 0.116 (1.249)	DT 0.013 (1.112)	loss nan (nan)	prob nan (nan)	GS 28.609 (28.609)	mem 39.956
Train: [57][250/750]	BT 4.376 (1.244)	DT 4.298 (1.107)	loss nan (nan)	prob nan (nan)	GS 33.328 (33.328)	mem 39.940
Train: [57][255/750]	BT 0.095 (1.223)	DT 0.002 (1.086)	loss nan (nan)	prob nan (nan)	GS 32.094 (32.094)	mem 40.152
Train: [57][260/750]	BT 0.108 (1.225)	DT 0.006 (1.088)	loss nan (nan)	prob nan (nan)	GS 34.125 (34.125)	mem 39.971
Train: [57][265/750]	BT 0.114 (1.224)	DT 0.002 (1.087)	loss nan (nan)	prob nan (nan)	GS 33.000 (33.000)	mem 39.889
Train: [57][270/750]	BT 0.169 (1.222)	DT 0.002 (1.086)	loss nan (nan)	prob nan (nan)	GS 33.891 (33.891)	mem 39.961
Train: [57][275/750]	BT 0.071 (1.227)	DT 0.001 (1.091)	loss nan (nan)	prob nan (nan)	GS 36.516 (36.516)	mem 39.987
Train: [57][280/750]	BT 6.919 (1.231)	DT 6.706 (1.096)	loss nan (nan)	prob nan (nan)	GS 31.250 (31.250)	mem 40.142
Train: [57][285/750]	BT 0.169 (1.212)	DT 0.005 (1.077)	loss nan (nan)	prob nan (nan)	GS 40.328 (40.328)	mem 39.989
Train: [57][290/750]	BT 0.093 (1.213)	DT 0.001 (1.077)	loss nan (nan)	prob nan (nan)	GS 39.172 (39.172)	mem 39.986
Train: [57][295/750]	BT 0.121 (1.215)	DT 0.009 (1.080)	loss nan (nan)	prob nan (nan)	GS 32.016 (32.016)	mem 40.010
Train: [57][300/750]	BT 0.122 (1.211)	DT 0.006 (1.076)	loss nan (nan)	prob nan (nan)	GS 36.047 (36.047)	mem 40.030
Train: [57][305/750]	BT 0.139 (1.220)	DT 0.006 (1.086)	loss nan (nan)	prob nan (nan)	GS 34.422 (34.422)	mem 40.029
Train: [57][310/750]	BT 0.074 (1.202)	DT 0.001 (1.068)	loss nan (nan)	prob nan (nan)	GS 31.656 (31.656)	mem 39.832
Train: [57][315/750]	BT 0.200 (1.185)	DT 0.010 (1.051)	loss nan (nan)	prob nan (nan)	GS 33.547 (33.547)	mem 39.812
Train: [57][320/750]	BT 0.172 (1.201)	DT 0.002 (1.067)	loss nan (nan)	prob nan (nan)	GS 31.281 (31.281)	mem 40.169
Train: [57][325/750]	BT 0.190 (1.190)	DT 0.014 (1.056)	loss nan (nan)	prob nan (nan)	GS 43.156 (43.156)	mem 40.028
Train: [57][330/750]	BT 0.188 (1.208)	DT 0.002 (1.073)	loss nan (nan)	prob nan (nan)	GS 33.531 (33.531)	mem 39.861
Train: [57][335/750]	BT 0.112 (1.192)	DT 0.008 (1.057)	loss nan (nan)	prob nan (nan)	GS 33.062 (33.062)	mem 39.896
Train: [57][340/750]	BT 8.692 (1.212)	DT 8.563 (1.077)	loss nan (nan)	prob nan (nan)	GS 34.078 (34.078)	mem 40.062
Train: [57][345/750]	BT 0.100 (1.196)	DT 0.010 (1.062)	loss nan (nan)	prob nan (nan)	GS 26.953 (26.953)	mem 39.979
Train: [57][350/750]	BT 4.435 (1.193)	DT 4.297 (1.059)	loss nan (nan)	prob nan (nan)	GS 32.656 (32.656)	mem 39.986
Train: [57][355/750]	BT 0.105 (1.200)	DT 0.004 (1.065)	loss nan (nan)	prob nan (nan)	GS 29.562 (29.562)	mem 39.891
Train: [57][360/750]	BT 0.149 (1.185)	DT 0.002 (1.050)	loss nan (nan)	prob nan (nan)	GS 36.062 (36.062)	mem 39.945
Train: [57][365/750]	BT 0.082 (1.208)	DT 0.001 (1.073)	loss nan (nan)	prob nan (nan)	GS 32.906 (32.906)	mem 40.000
Train: [57][370/750]	BT 0.076 (1.193)	DT 0.004 (1.059)	loss nan (nan)	prob nan (nan)	GS 29.109 (29.109)	mem 40.001
Train: [57][375/750]	BT 0.080 (1.179)	DT 0.001 (1.045)	loss nan (nan)	prob nan (nan)	GS 31.250 (31.250)	mem 40.017
Train: [57][380/750]	BT 0.201 (1.194)	DT 0.001 (1.059)	loss nan (nan)	prob nan (nan)	GS 32.469 (32.469)	mem 40.233
Train: [57][385/750]	BT 0.088 (1.180)	DT 0.005 (1.046)	loss nan (nan)	prob nan (nan)	GS 30.969 (30.969)	mem 40.303
Train: [57][390/750]	BT 0.108 (1.206)	DT 0.004 (1.072)	loss nan (nan)	prob nan (nan)	GS 33.281 (33.281)	mem 40.080
Train: [57][395/750]	BT 0.106 (1.193)	DT 0.001 (1.059)	loss nan (nan)	prob nan (nan)	GS 34.156 (34.156)	mem 39.987
Train: [57][400/750]	BT 11.324 (1.208)	DT 11.151 (1.074)	loss nan (nan)	prob nan (nan)	GS 32.875 (32.875)	mem 40.082
Train: [57][405/750]	BT 0.148 (1.195)	DT 0.015 (1.060)	loss nan (nan)	prob nan (nan)	GS 34.078 (34.078)	mem 40.104
Train: [57][410/750]	BT 0.152 (1.182)	DT 0.014 (1.048)	loss nan (nan)	prob nan (nan)	GS 31.891 (31.891)	mem 40.022
Train: [57][415/750]	BT 0.133 (1.194)	DT 0.001 (1.060)	loss nan (nan)	prob nan (nan)	GS 33.984 (33.984)	mem 40.004
Train: [57][420/750]	BT 0.089 (1.181)	DT 0.002 (1.047)	loss nan (nan)	prob nan (nan)	GS 33.078 (33.078)	mem 40.071
Train: [57][425/750]	BT 0.080 (1.190)	DT 0.001 (1.057)	loss nan (nan)	prob nan (nan)	GS 33.859 (33.859)	mem 40.087
Train: [57][430/750]	BT 0.103 (1.178)	DT 0.001 (1.045)	loss nan (nan)	prob nan (nan)	GS 36.125 (36.125)	mem 40.043
Train: [57][435/750]	BT 0.099 (1.166)	DT 0.005 (1.033)	loss nan (nan)	prob nan (nan)	GS 34.078 (34.078)	mem 40.055
Train: [57][440/750]	BT 0.092 (1.184)	DT 0.002 (1.051)	loss nan (nan)	prob nan (nan)	GS 34.672 (34.672)	mem 40.027
Train: [57][445/750]	BT 0.219 (1.172)	DT 0.027 (1.039)	loss nan (nan)	prob nan (nan)	GS 32.859 (32.859)	mem 40.228
Train: [57][450/750]	BT 0.119 (1.192)	DT 0.001 (1.059)	loss nan (nan)	prob nan (nan)	GS 34.969 (34.969)	mem 39.955
Train: [57][455/750]	BT 0.204 (1.180)	DT 0.002 (1.047)	loss nan (nan)	prob nan (nan)	GS 34.766 (34.766)	mem 40.094
Train: [57][460/750]	BT 12.543 (1.199)	DT 12.391 (1.065)	loss nan (nan)	prob nan (nan)	GS 36.375 (36.375)	mem 40.046
Train: [57][465/750]	BT 0.066 (1.187)	DT 0.001 (1.054)	loss nan (nan)	prob nan (nan)	GS 26.281 (26.281)	mem 40.048
Train: [57][470/750]	BT 0.110 (1.176)	DT 0.003 (1.043)	loss nan (nan)	prob nan (nan)	GS 33.641 (33.641)	mem 40.151
Train: [57][475/750]	BT 0.074 (1.189)	DT 0.001 (1.056)	loss nan (nan)	prob nan (nan)	GS 32.188 (32.188)	mem 40.063
Train: [57][480/750]	BT 0.125 (1.178)	DT 0.013 (1.046)	loss nan (nan)	prob nan (nan)	GS 32.328 (32.328)	mem 40.086
Train: [57][485/750]	BT 0.125 (1.191)	DT 0.001 (1.059)	loss nan (nan)	prob nan (nan)	GS 32.469 (32.469)	mem 40.095
Train: [57][490/750]	BT 0.111 (1.181)	DT 0.016 (1.048)	loss nan (nan)	prob nan (nan)	GS 34.828 (34.828)	mem 40.032
Train: [57][495/750]	BT 0.150 (1.170)	DT 0.001 (1.038)	loss nan (nan)	prob nan (nan)	GS 33.906 (33.906)	mem 40.047
Train: [57][500/750]	BT 0.128 (1.182)	DT 0.002 (1.049)	loss nan (nan)	prob nan (nan)	GS 32.109 (32.109)	mem 39.993
Train: [57][505/750]	BT 0.092 (1.171)	DT 0.002 (1.039)	loss nan (nan)	prob nan (nan)	GS 30.141 (30.141)	mem 39.935
Train: [57][510/750]	BT 0.133 (1.185)	DT 0.002 (1.053)	loss nan (nan)	prob nan (nan)	GS 32.766 (32.766)	mem 40.101
Train: [57][515/750]	BT 0.111 (1.175)	DT 0.001 (1.043)	loss nan (nan)	prob nan (nan)	GS 31.250 (31.250)	mem 40.002
Train: [57][520/750]	BT 8.601 (1.181)	DT 8.384 (1.049)	loss nan (nan)	prob nan (nan)	GS 28.484 (28.484)	mem 40.059
Train: [57][525/750]	BT 0.260 (1.171)	DT 0.009 (1.039)	loss nan (nan)	prob nan (nan)	GS 30.531 (30.531)	mem 40.028
Train: [57][530/750]	BT 2.861 (1.167)	DT 2.736 (1.034)	loss nan (nan)	prob nan (nan)	GS 36.453 (36.453)	mem 40.076
Train: [57][535/750]	BT 0.079 (1.176)	DT 0.002 (1.044)	loss nan (nan)	prob nan (nan)	GS 33.891 (33.891)	mem 40.061
Train: [57][540/750]	BT 0.102 (1.166)	DT 0.002 (1.034)	loss nan (nan)	prob nan (nan)	GS 32.969 (32.969)	mem 40.075
Train: [57][545/750]	BT 0.098 (1.180)	DT 0.001 (1.047)	loss nan (nan)	prob nan (nan)	GS 29.844 (29.844)	mem 40.097
Train: [57][550/750]	BT 0.168 (1.170)	DT 0.005 (1.038)	loss nan (nan)	prob nan (nan)	GS 35.938 (35.938)	mem 40.235
Train: [57][555/750]	BT 0.178 (1.161)	DT 0.005 (1.029)	loss nan (nan)	prob nan (nan)	GS 33.203 (33.203)	mem 40.212
Train: [57][560/750]	BT 2.254 (1.170)	DT 2.115 (1.038)	loss nan (nan)	prob nan (nan)	GS 34.266 (34.266)	mem 39.958
Train: [57][565/750]	BT 0.130 (1.161)	DT 0.005 (1.029)	loss nan (nan)	prob nan (nan)	GS 31.547 (31.547)	mem 39.966
Train: [57][570/750]	BT 3.077 (1.170)	DT 2.954 (1.038)	loss nan (nan)	prob nan (nan)	GS 32.969 (32.969)	mem 40.116
Train: [57][575/750]	BT 0.187 (1.165)	DT 0.002 (1.032)	loss nan (nan)	prob nan (nan)	GS 29.328 (29.328)	mem 40.108
Train: [57][580/750]	BT 8.222 (1.170)	DT 7.978 (1.037)	loss nan (nan)	prob nan (nan)	GS 33.562 (33.562)	mem 40.237
Train: [57][585/750]	BT 0.204 (1.167)	DT 0.001 (1.034)	loss nan (nan)	prob nan (nan)	GS 25.312 (25.312)	mem 40.128
Train: [57][590/750]	BT 3.014 (1.163)	DT 2.874 (1.030)	loss nan (nan)	prob nan (nan)	GS 32.297 (32.297)	mem 39.965
Train: [57][595/750]	BT 0.169 (1.168)	DT 0.004 (1.035)	loss nan (nan)	prob nan (nan)	GS 35.719 (35.719)	mem 40.032
Train: [57][600/750]	BT 0.128 (1.162)	DT 0.009 (1.028)	loss nan (nan)	prob nan (nan)	GS 33.031 (33.031)	mem 40.111
Train: [57][605/750]	BT 0.190 (1.160)	DT 0.002 (1.026)	loss nan (nan)	prob nan (nan)	GS 34.094 (34.094)	mem 40.220
Train: [57][610/750]	BT 0.085 (1.165)	DT 0.002 (1.031)	loss nan (nan)	prob nan (nan)	GS 31.000 (31.000)	mem 40.061
Train: [57][615/750]	BT 0.190 (1.156)	DT 0.006 (1.023)	loss nan (nan)	prob nan (nan)	GS 32.750 (32.750)	mem 40.446
Train: [57][620/750]	BT 4.019 (1.165)	DT 3.926 (1.032)	loss nan (nan)	prob nan (nan)	GS 37.703 (37.703)	mem 40.011
Train: [57][625/750]	BT 0.150 (1.157)	DT 0.001 (1.023)	loss nan (nan)	prob nan (nan)	GS 28.109 (28.109)	mem 40.018
Train: [57][630/750]	BT 0.131 (1.157)	DT 0.012 (1.023)	loss nan (nan)	prob nan (nan)	GS 36.703 (36.703)	mem 40.117
Train: [57][635/750]	BT 0.118 (1.156)	DT 0.002 (1.022)	loss nan (nan)	prob nan (nan)	GS 34.766 (34.766)	mem 40.002
Train: [57][640/750]	BT 0.129 (1.161)	DT 0.003 (1.027)	loss nan (nan)	prob nan (nan)	GS 31.844 (31.844)	mem 40.109
Train: [57][645/750]	BT 0.088 (1.161)	DT 0.002 (1.027)	loss nan (nan)	prob nan (nan)	GS 33.625 (33.625)	mem 39.980
Train: [57][650/750]	BT 7.360 (1.164)	DT 7.257 (1.030)	loss nan (nan)	prob nan (nan)	GS 35.141 (35.141)	mem 40.063
Train: [57][655/750]	BT 0.158 (1.159)	DT 0.011 (1.026)	loss nan (nan)	prob nan (nan)	GS 26.562 (26.562)	mem 40.020
Train: [57][660/750]	BT 0.131 (1.163)	DT 0.006 (1.030)	loss nan (nan)	prob nan (nan)	GS 34.656 (34.656)	mem 40.094
Train: [57][665/750]	BT 0.129 (1.156)	DT 0.007 (1.023)	loss nan (nan)	prob nan (nan)	GS 30.938 (30.938)	mem 39.978
Train: [57][670/750]	BT 0.526 (1.167)	DT 0.416 (1.034)	loss nan (nan)	prob nan (nan)	GS 35.203 (35.203)	mem 40.041
Train: [57][675/750]	BT 0.085 (1.160)	DT 0.002 (1.026)	loss nan (nan)	prob nan (nan)	GS 27.016 (27.016)	mem 39.946
Train: [57][680/750]	BT 11.430 (1.172)	DT 11.315 (1.038)	loss nan (nan)	prob nan (nan)	GS 36.078 (36.078)	mem 40.008
Train: [57][685/750]	BT 0.155 (1.164)	DT 0.004 (1.031)	loss nan (nan)	prob nan (nan)	GS 31.969 (31.969)	mem 40.007
Train: [57][690/750]	BT 0.287 (1.157)	DT 0.050 (1.024)	loss nan (nan)	prob nan (nan)	GS 31.078 (31.078)	mem 40.008
Train: [57][695/750]	BT 0.075 (1.167)	DT 0.002 (1.033)	loss nan (nan)	prob nan (nan)	GS 32.453 (32.453)	mem 40.044
Train: [57][700/750]	BT 0.172 (1.159)	DT 0.021 (1.026)	loss nan (nan)	prob nan (nan)	GS 34.359 (34.359)	mem 40.006
Train: [57][705/750]	BT 0.065 (1.170)	DT 0.002 (1.037)	loss nan (nan)	prob nan (nan)	GS 29.766 (29.766)	mem 40.082
Train: [57][710/750]	BT 0.120 (1.163)	DT 0.001 (1.030)	loss nan (nan)	prob nan (nan)	GS 32.719 (32.719)	mem 40.117
Train: [57][715/750]	BT 0.161 (1.156)	DT 0.002 (1.023)	loss nan (nan)	prob nan (nan)	GS 35.578 (35.578)	mem 40.163
Train: [57][720/750]	BT 0.126 (1.161)	DT 0.010 (1.028)	loss nan (nan)	prob nan (nan)	GS 32.484 (32.484)	mem 40.063
Train: [57][725/750]	BT 0.093 (1.154)	DT 0.002 (1.021)	loss nan (nan)	prob nan (nan)	GS 34.469 (34.469)	mem 40.129
Train: [57][730/750]	BT 1.284 (1.164)	DT 1.209 (1.031)	loss nan (nan)	prob nan (nan)	GS 32.922 (32.922)	mem 39.576
Train: [57][735/750]	BT 0.120 (1.157)	DT 0.009 (1.024)	loss nan (nan)	prob nan (nan)	GS 28.156 (28.156)	mem 39.517
Train: [57][740/750]	BT 5.127 (1.157)	DT 5.034 (1.024)	loss nan (nan)	prob nan (nan)	GS 34.438 (34.438)	mem 10.659
Train: [57][745/750]	BT 0.106 (1.152)	DT 0.002 (1.020)	loss nan (nan)	prob nan (nan)	GS 36.219 (36.219)	mem 10.660
Train: [57][750/750]	BT 0.088 (1.145)	DT 0.001 (1.013)	loss nan (nan)	prob nan (nan)	GS 33.219 (33.219)	mem 10.588
Train: [57][755/750]	BT 0.055 (1.140)	DT 0.001 (1.009)	loss nan (nan)	prob nan (nan)	GS 30.250 (30.250)	mem 7.609
epoch 57, total time 861.22
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [58][1/750]	BT 21.036 (21.036)	DT 20.696 (20.696)	loss nan (nan)	prob nan (nan)	GS 31.312 (31.312)	mem 38.721
Train: [58][5/750]	BT 0.207 (4.589)	DT 0.026 (4.376)	loss nan (nan)	prob nan (nan)	GS 29.234 (29.234)	mem 38.631
Train: [58][10/750]	BT 0.124 (2.674)	DT 0.002 (2.508)	loss nan (nan)	prob nan (nan)	GS 32.766 (32.766)	mem 38.791
Train: [58][15/750]	BT 0.102 (2.459)	DT 0.002 (2.308)	loss nan (nan)	prob nan (nan)	GS 29.203 (29.203)	mem 38.922
Train: [58][20/750]	BT 0.093 (2.218)	DT 0.002 (2.079)	loss nan (nan)	prob nan (nan)	GS 33.500 (33.500)	mem 39.029
Train: [58][25/750]	BT 0.206 (1.807)	DT 0.007 (1.666)	loss nan (nan)	prob nan (nan)	GS 29.766 (29.766)	mem 39.029
Train: [58][30/750]	BT 1.603 (1.878)	DT 1.512 (1.743)	loss nan (nan)	prob nan (nan)	GS 32.984 (32.984)	mem 38.997
Train: [58][35/750]	BT 0.254 (1.630)	DT 0.017 (1.495)	loss nan (nan)	prob nan (nan)	GS 32.312 (32.312)	mem 38.998
Train: [58][40/750]	BT 0.186 (1.687)	DT 0.002 (1.551)	loss nan (nan)	prob nan (nan)	GS 29.875 (29.875)	mem 39.047
Train: [58][45/750]	BT 0.118 (1.594)	DT 0.002 (1.459)	loss nan (nan)	prob nan (nan)	GS 35.172 (35.172)	mem 39.055
Train: [58][50/750]	BT 8.963 (1.623)	DT 8.771 (1.489)	loss nan (nan)	prob nan (nan)	GS 33.078 (33.078)	mem 39.064
Train: [58][55/750]	BT 0.240 (1.547)	DT 0.002 (1.411)	loss nan (nan)	prob nan (nan)	GS 30.578 (30.578)	mem 39.026
Train: [58][60/750]	BT 0.266 (1.431)	DT 0.042 (1.294)	loss nan (nan)	prob nan (nan)	GS 36.516 (36.516)	mem 39.039
Train: [58][65/750]	BT 0.087 (1.438)	DT 0.002 (1.301)	loss nan (nan)	prob nan (nan)	GS 31.828 (31.828)	mem 39.073
Train: [58][70/750]	BT 0.123 (1.430)	DT 0.002 (1.295)	loss nan (nan)	prob nan (nan)	GS 31.344 (31.344)	mem 39.129
Train: [58][75/750]	BT 0.133 (1.403)	DT 0.002 (1.268)	loss nan (nan)	prob nan (nan)	GS 29.625 (29.625)	mem 39.128
Train: [58][80/750]	BT 0.218 (1.419)	DT 0.002 (1.283)	loss nan (nan)	prob nan (nan)	GS 36.406 (36.406)	mem 39.197
Train: [58][85/750]	BT 0.157 (1.345)	DT 0.005 (1.208)	loss nan (nan)	prob nan (nan)	GS 30.672 (30.672)	mem 39.277
Train: [58][90/750]	BT 10.414 (1.426)	DT 10.291 (1.289)	loss nan (nan)	prob nan (nan)	GS 37.656 (37.656)	mem 39.203
Train: [58][95/750]	BT 0.085 (1.356)	DT 0.002 (1.221)	loss nan (nan)	prob nan (nan)	GS 34.594 (34.594)	mem 39.367
Train: [58][100/750]	BT 0.084 (1.325)	DT 0.001 (1.190)	loss nan (nan)	prob nan (nan)	GS 33.719 (33.719)	mem 39.222
Train: [58][105/750]	BT 0.113 (1.334)	DT 0.002 (1.200)	loss nan (nan)	prob nan (nan)	GS 32.656 (32.656)	mem 39.337
Train: [58][110/750]	BT 10.659 (1.377)	DT 10.557 (1.242)	loss nan (nan)	prob nan (nan)	GS 37.844 (37.844)	mem 39.312
Train: [58][115/750]	BT 0.064 (1.332)	DT 0.001 (1.198)	loss nan (nan)	prob nan (nan)	GS 33.875 (33.875)	mem 39.253
Train: [58][120/750]	BT 0.164 (1.282)	DT 0.010 (1.148)	loss nan (nan)	prob nan (nan)	GS 37.250 (37.250)	mem 39.293
Train: [58][125/750]	BT 0.165 (1.320)	DT 0.004 (1.185)	loss nan (nan)	prob nan (nan)	GS 30.516 (30.516)	mem 39.306
Train: [58][130/750]	BT 0.342 (1.277)	DT 0.222 (1.142)	loss nan (nan)	prob nan (nan)	GS 34.062 (34.062)	mem 39.246
Train: [58][135/750]	BT 0.156 (1.334)	DT 0.001 (1.199)	loss nan (nan)	prob nan (nan)	GS 31.656 (31.656)	mem 39.600
Train: [58][140/750]	BT 0.185 (1.291)	DT 0.100 (1.157)	loss nan (nan)	prob nan (nan)	GS 34.344 (34.344)	mem 39.529
Train: [58][145/750]	BT 0.221 (1.251)	DT 0.006 (1.117)	loss nan (nan)	prob nan (nan)	GS 31.094 (31.094)	mem 39.462
Train: [58][150/750]	BT 0.118 (1.292)	DT 0.002 (1.158)	loss nan (nan)	prob nan (nan)	GS 37.062 (37.062)	mem 39.551
Train: [58][155/750]	BT 0.103 (1.255)	DT 0.001 (1.121)	loss nan (nan)	prob nan (nan)	GS 30.141 (30.141)	mem 39.567
Train: [58][160/750]	BT 0.092 (1.281)	DT 0.002 (1.147)	loss nan (nan)	prob nan (nan)	GS 33.859 (33.859)	mem 39.573
Train: [58][165/750]	BT 0.149 (1.246)	DT 0.002 (1.112)	loss nan (nan)	prob nan (nan)	GS 29.141 (29.141)	mem 39.575
Train: [58][170/750]	BT 10.994 (1.277)	DT 10.887 (1.144)	loss nan (nan)	prob nan (nan)	GS 32.781 (32.781)	mem 39.723
Train: [58][175/750]	BT 0.111 (1.244)	DT 0.002 (1.111)	loss nan (nan)	prob nan (nan)	GS 32.578 (32.578)	mem 39.742
Train: [58][180/750]	BT 0.108 (1.215)	DT 0.009 (1.083)	loss nan (nan)	prob nan (nan)	GS 37.156 (37.156)	mem 39.531
Train: [58][185/750]	BT 0.095 (1.241)	DT 0.001 (1.109)	loss nan (nan)	prob nan (nan)	GS 28.406 (28.406)	mem 39.722
Train: [58][190/750]	BT 0.122 (1.218)	DT 0.002 (1.087)	loss nan (nan)	prob nan (nan)	GS 31.062 (31.062)	mem 39.579
Train: [58][195/750]	BT 0.225 (1.224)	DT 0.016 (1.091)	loss nan (nan)	prob nan (nan)	GS 32.891 (32.891)	mem 39.917
Train: [58][200/750]	BT 0.079 (1.247)	DT 0.001 (1.114)	loss nan (nan)	prob nan (nan)	GS 32.406 (32.406)	mem 39.810
Train: [58][205/750]	BT 0.098 (1.220)	DT 0.006 (1.087)	loss nan (nan)	prob nan (nan)	GS 25.562 (25.562)	mem 39.843
Train: [58][210/750]	BT 16.131 (1.273)	DT 16.053 (1.139)	loss nan (nan)	prob nan (nan)	GS 37.953 (37.953)	mem 39.942
Train: [58][215/750]	BT 0.183 (1.246)	DT 0.002 (1.113)	loss nan (nan)	prob nan (nan)	GS 31.000 (31.000)	mem 39.995
Train: [58][220/750]	BT 0.113 (1.222)	DT 0.002 (1.089)	loss nan (nan)	prob nan (nan)	GS 32.953 (32.953)	mem 39.979
Train: [58][225/750]	BT 0.099 (1.254)	DT 0.001 (1.122)	loss nan (nan)	prob nan (nan)	GS 39.453 (39.453)	mem 39.970
Train: [58][230/750]	BT 0.140 (1.231)	DT 0.004 (1.098)	loss nan (nan)	prob nan (nan)	GS 35.266 (35.266)	mem 39.850
Train: [58][235/750]	BT 0.109 (1.247)	DT 0.001 (1.114)	loss nan (nan)	prob nan (nan)	GS 28.078 (28.078)	mem 40.041
Train: [58][240/750]	BT 0.132 (1.224)	DT 0.001 (1.091)	loss nan (nan)	prob nan (nan)	GS 27.047 (27.047)	mem 39.983
Train: [58][245/750]	BT 0.199 (1.203)	DT 0.002 (1.071)	loss nan (nan)	prob nan (nan)	GS 31.141 (31.141)	mem 40.001
Train: [58][250/750]	BT 0.139 (1.225)	DT 0.014 (1.094)	loss nan (nan)	prob nan (nan)	GS 35.797 (35.797)	mem 40.014
Train: [58][255/750]	BT 0.084 (1.204)	DT 0.002 (1.072)	loss nan (nan)	prob nan (nan)	GS 27.562 (27.562)	mem 39.962
Train: [58][260/750]	BT 0.141 (1.233)	DT 0.001 (1.103)	loss nan (nan)	prob nan (nan)	GS 35.484 (35.484)	mem 39.946
Train: [58][265/750]	BT 0.119 (1.212)	DT 0.007 (1.082)	loss nan (nan)	prob nan (nan)	GS 29.141 (29.141)	mem 39.977
Train: [58][270/750]	BT 11.420 (1.234)	DT 11.325 (1.104)	loss nan (nan)	prob nan (nan)	GS 32.891 (32.891)	mem 39.956
Train: [58][275/750]	BT 0.086 (1.213)	DT 0.003 (1.084)	loss nan (nan)	prob nan (nan)	GS 29.938 (29.938)	mem 39.969
Train: [58][280/750]	BT 0.203 (1.194)	DT 0.005 (1.064)	loss nan (nan)	prob nan (nan)	GS 32.219 (32.219)	mem 39.992
Train: [58][285/750]	BT 0.127 (1.214)	DT 0.003 (1.084)	loss nan (nan)	prob nan (nan)	GS 28.422 (28.422)	mem 40.146
Train: [58][290/750]	BT 0.085 (1.194)	DT 0.001 (1.065)	loss nan (nan)	prob nan (nan)	GS 33.609 (33.609)	mem 40.009
Train: [58][295/750]	BT 0.091 (1.225)	DT 0.002 (1.096)	loss nan (nan)	prob nan (nan)	GS 32.359 (32.359)	mem 40.214
Train: [58][300/750]	BT 0.143 (1.206)	DT 0.001 (1.077)	loss nan (nan)	prob nan (nan)	GS 30.797 (30.797)	mem 40.215
Train: [58][305/750]	BT 0.167 (1.188)	DT 0.008 (1.060)	loss nan (nan)	prob nan (nan)	GS 30.422 (30.422)	mem 40.093
Train: [58][310/750]	BT 1.636 (1.211)	DT 1.455 (1.082)	loss nan (nan)	prob nan (nan)	GS 33.969 (33.969)	mem 40.063
Train: [58][315/750]	BT 0.204 (1.195)	DT 0.005 (1.064)	loss nan (nan)	prob nan (nan)	GS 29.031 (29.031)	mem 40.066
Train: [58][320/750]	BT 0.137 (1.209)	DT 0.001 (1.078)	loss nan (nan)	prob nan (nan)	GS 31.250 (31.250)	mem 40.098
Train: [58][325/750]	BT 0.123 (1.194)	DT 0.002 (1.064)	loss nan (nan)	prob nan (nan)	GS 29.859 (29.859)	mem 40.121
Train: [58][330/750]	BT 10.652 (1.210)	DT 10.560 (1.080)	loss nan (nan)	prob nan (nan)	GS 32.359 (32.359)	mem 40.089
Train: [58][335/750]	BT 0.100 (1.198)	DT 0.006 (1.068)	loss nan (nan)	prob nan (nan)	GS 32.219 (32.219)	mem 40.042
Train: [58][340/750]	BT 0.092 (1.182)	DT 0.005 (1.052)	loss nan (nan)	prob nan (nan)	GS 30.578 (30.578)	mem 40.039
Train: [58][345/750]	BT 0.092 (1.195)	DT 0.004 (1.066)	loss nan (nan)	prob nan (nan)	GS 30.359 (30.359)	mem 40.079
Train: [58][350/750]	BT 0.080 (1.184)	DT 0.002 (1.055)	loss nan (nan)	prob nan (nan)	GS 33.078 (33.078)	mem 40.078
Train: [58][355/750]	BT 0.125 (1.198)	DT 0.008 (1.069)	loss nan (nan)	prob nan (nan)	GS 29.812 (29.812)	mem 40.007
Train: [58][360/750]	BT 0.148 (1.183)	DT 0.002 (1.054)	loss nan (nan)	prob nan (nan)	GS 37.375 (37.375)	mem 40.009
Train: [58][365/750]	BT 0.159 (1.168)	DT 0.007 (1.039)	loss nan (nan)	prob nan (nan)	GS 27.328 (27.328)	mem 40.177
Train: [58][370/750]	BT 0.084 (1.188)	DT 0.001 (1.059)	loss nan (nan)	prob nan (nan)	GS 32.672 (32.672)	mem 40.130
Train: [58][375/750]	BT 0.156 (1.174)	DT 0.010 (1.045)	loss nan (nan)	prob nan (nan)	GS 30.719 (30.719)	mem 40.096
Train: [58][380/750]	BT 0.089 (1.189)	DT 0.001 (1.060)	loss nan (nan)	prob nan (nan)	GS 33.578 (33.578)	mem 39.980
Train: [58][385/750]	BT 0.152 (1.175)	DT 0.002 (1.047)	loss nan (nan)	prob nan (nan)	GS 28.406 (28.406)	mem 40.048
Train: [58][390/750]	BT 11.523 (1.190)	DT 11.414 (1.063)	loss nan (nan)	prob nan (nan)	GS 32.359 (32.359)	mem 40.122
Train: [58][395/750]	BT 0.082 (1.176)	DT 0.002 (1.049)	loss nan (nan)	prob nan (nan)	GS 30.828 (30.828)	mem 40.041
Train: [58][400/750]	BT 0.246 (1.164)	DT 0.015 (1.036)	loss nan (nan)	prob nan (nan)	GS 28.562 (28.562)	mem 40.073
Train: [58][405/750]	BT 0.103 (1.181)	DT 0.002 (1.053)	loss nan (nan)	prob nan (nan)	GS 34.031 (34.031)	mem 40.052
Train: [58][410/750]	BT 0.126 (1.168)	DT 0.002 (1.041)	loss nan (nan)	prob nan (nan)	GS 37.109 (37.109)	mem 39.972
Train: [58][415/750]	BT 0.106 (1.185)	DT 0.001 (1.057)	loss nan (nan)	prob nan (nan)	GS 31.391 (31.391)	mem 40.055
Train: [58][420/750]	BT 0.090 (1.172)	DT 0.002 (1.044)	loss nan (nan)	prob nan (nan)	GS 33.453 (33.453)	mem 40.054
Train: [58][425/750]	BT 0.079 (1.160)	DT 0.002 (1.032)	loss nan (nan)	prob nan (nan)	GS 30.406 (30.406)	mem 40.057
Train: [58][430/750]	BT 1.510 (1.168)	DT 1.272 (1.040)	loss nan (nan)	prob nan (nan)	GS 34.891 (34.891)	mem 40.067
Train: [58][435/750]	BT 0.183 (1.156)	DT 0.001 (1.028)	loss nan (nan)	prob nan (nan)	GS 36.797 (36.797)	mem 40.262
Train: [58][440/750]	BT 0.093 (1.172)	DT 0.002 (1.044)	loss nan (nan)	prob nan (nan)	GS 34.656 (34.656)	mem 40.137
Train: [58][445/750]	BT 0.093 (1.161)	DT 0.002 (1.033)	loss nan (nan)	prob nan (nan)	GS 34.516 (34.516)	mem 40.087
Train: [58][450/750]	BT 9.331 (1.177)	DT 9.202 (1.049)	loss nan (nan)	prob nan (nan)	GS 34.516 (34.516)	mem 40.265
Train: [58][455/750]	BT 0.162 (1.167)	DT 0.003 (1.038)	loss nan (nan)	prob nan (nan)	GS 34.766 (34.766)	mem 40.146
Train: [58][460/750]	BT 0.120 (1.164)	DT 0.005 (1.035)	loss nan (nan)	prob nan (nan)	GS 37.938 (37.938)	mem 40.202
Train: [58][465/750]	BT 0.128 (1.170)	DT 0.006 (1.041)	loss nan (nan)	prob nan (nan)	GS 31.906 (31.906)	mem 40.289
Train: [58][470/750]	BT 3.870 (1.167)	DT 3.762 (1.038)	loss nan (nan)	prob nan (nan)	GS 33.188 (33.188)	mem 40.055
Train: [58][475/750]	BT 0.064 (1.178)	DT 0.001 (1.049)	loss nan (nan)	prob nan (nan)	GS 29.875 (29.875)	mem 40.123
Train: [58][480/750]	BT 0.097 (1.167)	DT 0.002 (1.038)	loss nan (nan)	prob nan (nan)	GS 35.703 (35.703)	mem 40.104
Train: [58][485/750]	BT 0.292 (1.158)	DT 0.090 (1.029)	loss nan (nan)	prob nan (nan)	GS 31.484 (31.484)	mem 40.422
Train: [58][490/750]	BT 0.087 (1.177)	DT 0.001 (1.048)	loss nan (nan)	prob nan (nan)	GS 36.891 (36.891)	mem 40.043
Train: [58][495/750]	BT 0.124 (1.166)	DT 0.001 (1.037)	loss nan (nan)	prob nan (nan)	GS 32.922 (32.922)	mem 40.061
Train: [58][500/750]	BT 0.072 (1.177)	DT 0.007 (1.049)	loss nan (nan)	prob nan (nan)	GS 37.297 (37.297)	mem 40.141
Train: [58][505/750]	BT 0.121 (1.167)	DT 0.002 (1.038)	loss nan (nan)	prob nan (nan)	GS 36.891 (36.891)	mem 40.132
Train: [58][510/750]	BT 13.583 (1.183)	DT 13.506 (1.055)	loss nan (nan)	prob nan (nan)	GS 33.594 (33.594)	mem 40.110
Train: [58][515/750]	BT 0.189 (1.173)	DT 0.001 (1.044)	loss nan (nan)	prob nan (nan)	GS 36.172 (36.172)	mem 40.077
Train: [58][520/750]	BT 0.109 (1.163)	DT 0.020 (1.034)	loss nan (nan)	prob nan (nan)	GS 31.859 (31.859)	mem 40.117
Train: [58][525/750]	BT 0.133 (1.173)	DT 0.001 (1.045)	loss nan (nan)	prob nan (nan)	GS 25.969 (25.969)	mem 40.107
Train: [58][530/750]	BT 0.078 (1.163)	DT 0.002 (1.035)	loss nan (nan)	prob nan (nan)	GS 33.703 (33.703)	mem 40.139
Train: [58][535/750]	BT 0.100 (1.177)	DT 0.001 (1.048)	loss nan (nan)	prob nan (nan)	GS 30.781 (30.781)	mem 40.117
Train: [58][540/750]	BT 0.121 (1.167)	DT 0.001 (1.038)	loss nan (nan)	prob nan (nan)	GS 35.266 (35.266)	mem 40.082
Train: [58][545/750]	BT 0.113 (1.158)	DT 0.017 (1.029)	loss nan (nan)	prob nan (nan)	GS 36.906 (36.906)	mem 40.081
Train: [58][550/750]	BT 0.164 (1.169)	DT 0.027 (1.040)	loss nan (nan)	prob nan (nan)	GS 35.047 (35.047)	mem 40.006
Train: [58][555/750]	BT 0.284 (1.160)	DT 0.009 (1.030)	loss nan (nan)	prob nan (nan)	GS 30.844 (30.844)	mem 40.070
Train: [58][560/750]	BT 0.170 (1.170)	DT 0.008 (1.040)	loss nan (nan)	prob nan (nan)	GS 36.328 (36.328)	mem 40.078
Train: [58][565/750]	BT 0.117 (1.161)	DT 0.002 (1.031)	loss nan (nan)	prob nan (nan)	GS 32.906 (32.906)	mem 40.077
Train: [58][570/750]	BT 10.017 (1.169)	DT 9.897 (1.039)	loss nan (nan)	prob nan (nan)	GS 34.625 (34.625)	mem 39.924
Train: [58][575/750]	BT 0.198 (1.160)	DT 0.002 (1.030)	loss nan (nan)	prob nan (nan)	GS 31.875 (31.875)	mem 40.128
Train: [58][580/750]	BT 0.100 (1.151)	DT 0.002 (1.021)	loss nan (nan)	prob nan (nan)	GS 33.656 (33.656)	mem 39.948
Train: [58][585/750]	BT 0.195 (1.165)	DT 0.008 (1.035)	loss nan (nan)	prob nan (nan)	GS 32.031 (32.031)	mem 40.048
Train: [58][590/750]	BT 0.111 (1.156)	DT 0.002 (1.027)	loss nan (nan)	prob nan (nan)	GS 35.906 (35.906)	mem 40.049
Train: [58][595/750]	BT 0.115 (1.165)	DT 0.001 (1.035)	loss nan (nan)	prob nan (nan)	GS 30.891 (30.891)	mem 40.068
Train: [58][600/750]	BT 0.097 (1.156)	DT 0.001 (1.026)	loss nan (nan)	prob nan (nan)	GS 34.781 (34.781)	mem 40.086
Train: [58][605/750]	BT 0.146 (1.148)	DT 0.017 (1.018)	loss nan (nan)	prob nan (nan)	GS 30.188 (30.188)	mem 40.111
Train: [58][610/750]	BT 0.086 (1.160)	DT 0.002 (1.030)	loss nan (nan)	prob nan (nan)	GS 33.312 (33.312)	mem 40.042
Train: [58][615/750]	BT 0.157 (1.152)	DT 0.007 (1.022)	loss nan (nan)	prob nan (nan)	GS 33.422 (33.422)	mem 40.042
Train: [58][620/750]	BT 0.110 (1.160)	DT 0.002 (1.029)	loss nan (nan)	prob nan (nan)	GS 34.781 (34.781)	mem 39.981
Train: [58][625/750]	BT 0.220 (1.152)	DT 0.002 (1.021)	loss nan (nan)	prob nan (nan)	GS 30.359 (30.359)	mem 40.162
Train: [58][630/750]	BT 13.479 (1.165)	DT 13.392 (1.034)	loss nan (nan)	prob nan (nan)	GS 40.141 (40.141)	mem 39.992
Train: [58][635/750]	BT 0.089 (1.157)	DT 0.002 (1.026)	loss nan (nan)	prob nan (nan)	GS 27.062 (27.062)	mem 39.998
Train: [58][640/750]	BT 0.221 (1.149)	DT 0.003 (1.018)	loss nan (nan)	prob nan (nan)	GS 37.516 (37.516)	mem 40.061
Train: [58][645/750]	BT 0.074 (1.160)	DT 0.001 (1.030)	loss nan (nan)	prob nan (nan)	GS 32.297 (32.297)	mem 40.065
Train: [58][650/750]	BT 0.083 (1.152)	DT 0.002 (1.022)	loss nan (nan)	prob nan (nan)	GS 33.297 (33.297)	mem 40.027
Train: [58][655/750]	BT 0.134 (1.159)	DT 0.005 (1.028)	loss nan (nan)	prob nan (nan)	GS 30.359 (30.359)	mem 40.039
Train: [58][660/750]	BT 0.087 (1.151)	DT 0.003 (1.021)	loss nan (nan)	prob nan (nan)	GS 33.344 (33.344)	mem 40.066
Train: [58][665/750]	BT 0.275 (1.144)	DT 0.010 (1.013)	loss nan (nan)	prob nan (nan)	GS 34.953 (34.953)	mem 40.340
Train: [58][670/750]	BT 0.966 (1.152)	DT 0.809 (1.021)	loss nan (nan)	prob nan (nan)	GS 32.266 (32.266)	mem 40.147
Train: [58][675/750]	BT 0.087 (1.147)	DT 0.002 (1.016)	loss nan (nan)	prob nan (nan)	GS 31.000 (31.000)	mem 40.040
Train: [58][680/750]	BT 0.119 (1.155)	DT 0.002 (1.024)	loss nan (nan)	prob nan (nan)	GS 33.953 (33.953)	mem 40.081
Train: [58][685/750]	BT 0.193 (1.148)	DT 0.002 (1.016)	loss nan (nan)	prob nan (nan)	GS 32.844 (32.844)	mem 40.086
Train: [58][690/750]	BT 4.891 (1.155)	DT 4.756 (1.024)	loss nan (nan)	prob nan (nan)	GS 33.172 (33.172)	mem 40.345
Train: [58][695/750]	BT 0.085 (1.148)	DT 0.001 (1.017)	loss nan (nan)	prob nan (nan)	GS 34.453 (34.453)	mem 40.107
Train: [58][700/750]	BT 0.222 (1.151)	DT 0.015 (1.019)	loss nan (nan)	prob nan (nan)	GS 32.859 (32.859)	mem 40.126
Train: [58][705/750]	BT 0.103 (1.149)	DT 0.012 (1.018)	loss nan (nan)	prob nan (nan)	GS 32.031 (32.031)	mem 40.118
Train: [58][710/750]	BT 7.308 (1.152)	DT 7.164 (1.020)	loss nan (nan)	prob nan (nan)	GS 33.188 (33.188)	mem 40.110
Train: [58][715/750]	BT 0.166 (1.147)	DT 0.002 (1.016)	loss nan (nan)	prob nan (nan)	GS 29.312 (29.312)	mem 40.110
Train: [58][720/750]	BT 0.142 (1.143)	DT 0.002 (1.012)	loss nan (nan)	prob nan (nan)	GS 34.719 (34.719)	mem 40.228
Train: [58][725/750]	BT 0.198 (1.146)	DT 0.001 (1.015)	loss nan (nan)	prob nan (nan)	GS 30.000 (30.000)	mem 39.996
Train: [58][730/750]	BT 1.846 (1.144)	DT 1.660 (1.013)	loss nan (nan)	prob nan (nan)	GS 34.562 (34.562)	mem 40.136
Train: [58][735/750]	BT 0.093 (1.143)	DT 0.004 (1.011)	loss nan (nan)	prob nan (nan)	GS 31.656 (31.656)	mem 36.772
Train: [58][740/750]	BT 0.117 (1.138)	DT 0.002 (1.007)	loss nan (nan)	prob nan (nan)	GS 27.938 (27.938)	mem 19.630
Train: [58][745/750]	BT 0.089 (1.132)	DT 0.001 (1.001)	loss nan (nan)	prob nan (nan)	GS 32.031 (32.031)	mem 16.658
Train: [58][750/750]	BT 1.700 (1.128)	DT 1.632 (0.997)	loss nan (nan)	prob nan (nan)	GS 28.594 (28.594)	mem 10.634
Train: [58][755/750]	BT 0.047 (1.121)	DT 0.001 (0.991)	loss nan (nan)	prob nan (nan)	GS 27.438 (27.438)	mem 7.648
epoch 58, total time 846.90
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [59][1/750]	BT 19.643 (19.643)	DT 19.548 (19.548)	loss nan (nan)	prob nan (nan)	GS 30.375 (30.375)	mem 38.451
Train: [59][5/750]	BT 0.080 (4.678)	DT 0.002 (4.583)	loss nan (nan)	prob nan (nan)	GS 29.719 (29.719)	mem 38.776
Train: [59][10/750]	BT 0.187 (2.573)	DT 0.002 (2.446)	loss nan (nan)	prob nan (nan)	GS 35.703 (35.703)	mem 38.623
Train: [59][15/750]	BT 0.128 (2.820)	DT 0.016 (2.671)	loss nan (nan)	prob nan (nan)	GS 28.016 (28.016)	mem 38.854
Train: [59][20/750]	BT 0.108 (2.142)	DT 0.004 (2.004)	loss nan (nan)	prob nan (nan)	GS 29.797 (29.797)	mem 38.857
Train: [59][25/750]	BT 0.144 (1.745)	DT 0.002 (1.606)	loss nan (nan)	prob nan (nan)	GS 30.078 (30.078)	mem 38.970
Train: [59][30/750]	BT 0.134 (1.850)	DT 0.006 (1.714)	loss nan (nan)	prob nan (nan)	GS 36.375 (36.375)	mem 39.074
Train: [59][35/750]	BT 0.264 (1.656)	DT 0.017 (1.511)	loss nan (nan)	prob nan (nan)	GS 31.203 (31.203)	mem 39.070
Train: [59][40/750]	BT 0.119 (1.715)	DT 0.001 (1.573)	loss nan (nan)	prob nan (nan)	GS 27.516 (27.516)	mem 39.138
Train: [59][45/750]	BT 0.107 (1.536)	DT 0.010 (1.398)	loss nan (nan)	prob nan (nan)	GS 31.969 (31.969)	mem 39.045
Train: [59][50/750]	BT 13.309 (1.671)	DT 13.198 (1.537)	loss nan (nan)	prob nan (nan)	GS 31.047 (31.047)	mem 39.089
Train: [59][55/750]	BT 0.114 (1.528)	DT 0.005 (1.397)	loss nan (nan)	prob nan (nan)	GS 34.125 (34.125)	mem 39.039
Train: [59][60/750]	BT 0.115 (1.412)	DT 0.008 (1.281)	loss nan (nan)	prob nan (nan)	GS 34.953 (34.953)	mem 39.049
Train: [59][65/750]	BT 0.067 (1.512)	DT 0.001 (1.385)	loss nan (nan)	prob nan (nan)	GS 31.469 (31.469)	mem 39.363
Train: [59][70/750]	BT 0.215 (1.413)	DT 0.003 (1.286)	loss nan (nan)	prob nan (nan)	GS 31.094 (31.094)	mem 39.688
Train: [59][75/750]	BT 0.176 (1.498)	DT 0.008 (1.367)	loss nan (nan)	prob nan (nan)	GS 32.625 (32.625)	mem 39.476
Train: [59][80/750]	BT 0.113 (1.412)	DT 0.004 (1.282)	loss nan (nan)	prob nan (nan)	GS 37.594 (37.594)	mem 39.478
Train: [59][85/750]	BT 0.176 (1.341)	DT 0.002 (1.207)	loss nan (nan)	prob nan (nan)	GS 33.734 (33.734)	mem 39.481
Train: [59][90/750]	BT 0.092 (1.392)	DT 0.001 (1.258)	loss nan (nan)	prob nan (nan)	GS 32.500 (32.500)	mem 39.753
Train: [59][95/750]	BT 0.143 (1.326)	DT 0.006 (1.192)	loss nan (nan)	prob nan (nan)	GS 31.453 (31.453)	mem 39.947
Train: [59][100/750]	BT 0.119 (1.375)	DT 0.009 (1.241)	loss nan (nan)	prob nan (nan)	GS 33.219 (33.219)	mem 39.853
Train: [59][105/750]	BT 0.148 (1.315)	DT 0.002 (1.182)	loss nan (nan)	prob nan (nan)	GS 30.484 (30.484)	mem 39.798
Train: [59][110/750]	BT 12.167 (1.369)	DT 12.023 (1.238)	loss nan (nan)	prob nan (nan)	GS 34.062 (34.062)	mem 39.857
Train: [59][115/750]	BT 0.116 (1.316)	DT 0.001 (1.184)	loss nan (nan)	prob nan (nan)	GS 31.922 (31.922)	mem 39.893
Train: [59][120/750]	BT 0.107 (1.266)	DT 0.009 (1.135)	loss nan (nan)	prob nan (nan)	GS 32.266 (32.266)	mem 39.862
Train: [59][125/750]	BT 0.085 (1.324)	DT 0.002 (1.193)	loss nan (nan)	prob nan (nan)	GS 31.891 (31.891)	mem 39.872
Train: [59][130/750]	BT 0.162 (1.277)	DT 0.014 (1.148)	loss nan (nan)	prob nan (nan)	GS 33.359 (33.359)	mem 39.943
Train: [59][135/750]	BT 0.117 (1.315)	DT 0.017 (1.186)	loss nan (nan)	prob nan (nan)	GS 29.109 (29.109)	mem 40.155
Train: [59][140/750]	BT 0.170 (1.273)	DT 0.005 (1.144)	loss nan (nan)	prob nan (nan)	GS 36.203 (36.203)	mem 40.038
Train: [59][145/750]	BT 0.114 (1.233)	DT 0.002 (1.105)	loss nan (nan)	prob nan (nan)	GS 33.312 (33.312)	mem 39.907
Train: [59][150/750]	BT 0.099 (1.260)	DT 0.002 (1.130)	loss nan (nan)	prob nan (nan)	GS 31.328 (31.328)	mem 39.951
Train: [59][155/750]	BT 0.134 (1.223)	DT 0.007 (1.094)	loss nan (nan)	prob nan (nan)	GS 32.109 (32.109)	mem 39.879
Train: [59][160/750]	BT 0.142 (1.270)	DT 0.009 (1.141)	loss nan (nan)	prob nan (nan)	GS 34.797 (34.797)	mem 39.879
Train: [59][165/750]	BT 0.093 (1.234)	DT 0.002 (1.106)	loss nan (nan)	prob nan (nan)	GS 29.578 (29.578)	mem 39.953
Train: [59][170/750]	BT 11.726 (1.272)	DT 11.647 (1.142)	loss nan (nan)	prob nan (nan)	GS 35.266 (35.266)	mem 39.928
Train: [59][175/750]	BT 0.096 (1.239)	DT 0.004 (1.110)	loss nan (nan)	prob nan (nan)	GS 30.828 (30.828)	mem 39.909
Train: [59][180/750]	BT 0.157 (1.208)	DT 0.002 (1.079)	loss nan (nan)	prob nan (nan)	GS 35.266 (35.266)	mem 39.954
Train: [59][185/750]	BT 0.087 (1.243)	DT 0.002 (1.113)	loss nan (nan)	prob nan (nan)	GS 33.578 (33.578)	mem 39.835
Train: [59][190/750]	BT 0.119 (1.213)	DT 0.002 (1.084)	loss nan (nan)	prob nan (nan)	GS 31.000 (31.000)	mem 39.953
Train: [59][195/750]	BT 0.117 (1.239)	DT 0.009 (1.111)	loss nan (nan)	prob nan (nan)	GS 29.922 (29.922)	mem 39.930
Train: [59][200/750]	BT 0.115 (1.211)	DT 0.001 (1.083)	loss nan (nan)	prob nan (nan)	GS 37.016 (37.016)	mem 40.025
Train: [59][205/750]	BT 0.132 (1.185)	DT 0.002 (1.057)	loss nan (nan)	prob nan (nan)	GS 31.656 (31.656)	mem 40.064
Train: [59][210/750]	BT 0.102 (1.220)	DT 0.002 (1.092)	loss nan (nan)	prob nan (nan)	GS 32.203 (32.203)	mem 39.956
Train: [59][215/750]	BT 0.118 (1.194)	DT 0.001 (1.067)	loss nan (nan)	prob nan (nan)	GS 29.078 (29.078)	mem 39.968
Train: [59][220/750]	BT 0.161 (1.221)	DT 0.002 (1.094)	loss nan (nan)	prob nan (nan)	GS 33.719 (33.719)	mem 39.954
Train: [59][225/750]	BT 0.187 (1.197)	DT 0.005 (1.070)	loss nan (nan)	prob nan (nan)	GS 30.797 (30.797)	mem 40.154
Train: [59][230/750]	BT 9.747 (1.216)	DT 9.602 (1.089)	loss nan (nan)	prob nan (nan)	GS 29.250 (29.250)	mem 39.995
Train: [59][235/750]	BT 0.143 (1.195)	DT 0.010 (1.067)	loss nan (nan)	prob nan (nan)	GS 30.484 (30.484)	mem 40.013
Train: [59][240/750]	BT 0.105 (1.173)	DT 0.002 (1.045)	loss nan (nan)	prob nan (nan)	GS 34.375 (34.375)	mem 40.077
Train: [59][245/750]	BT 0.183 (1.210)	DT 0.003 (1.083)	loss nan (nan)	prob nan (nan)	GS 28.750 (28.750)	mem 40.010
Train: [59][250/750]	BT 0.084 (1.188)	DT 0.003 (1.061)	loss nan (nan)	prob nan (nan)	GS 33.656 (33.656)	mem 40.108
Train: [59][255/750]	BT 0.112 (1.217)	DT 0.001 (1.090)	loss nan (nan)	prob nan (nan)	GS 29.188 (29.188)	mem 40.084
Train: [59][260/750]	BT 0.092 (1.195)	DT 0.001 (1.069)	loss nan (nan)	prob nan (nan)	GS 32.844 (32.844)	mem 39.980
Train: [59][265/750]	BT 0.132 (1.175)	DT 0.004 (1.049)	loss nan (nan)	prob nan (nan)	GS 34.906 (34.906)	mem 39.981
Train: [59][270/750]	BT 0.102 (1.191)	DT 0.005 (1.065)	loss nan (nan)	prob nan (nan)	GS 37.406 (37.406)	mem 40.044
Train: [59][275/750]	BT 0.102 (1.172)	DT 0.004 (1.046)	loss nan (nan)	prob nan (nan)	GS 34.234 (34.234)	mem 40.045
Train: [59][280/750]	BT 0.084 (1.211)	DT 0.001 (1.085)	loss nan (nan)	prob nan (nan)	GS 32.578 (32.578)	mem 40.003
Train: [59][285/750]	BT 0.066 (1.191)	DT 0.001 (1.066)	loss nan (nan)	prob nan (nan)	GS 35.047 (35.047)	mem 40.004
Train: [59][290/750]	BT 9.138 (1.205)	DT 9.020 (1.079)	loss nan (nan)	prob nan (nan)	GS 33.234 (33.234)	mem 40.058
Train: [59][295/750]	BT 0.143 (1.187)	DT 0.002 (1.061)	loss nan (nan)	prob nan (nan)	GS 28.031 (28.031)	mem 40.198
Train: [59][300/750]	BT 0.129 (1.169)	DT 0.002 (1.043)	loss nan (nan)	prob nan (nan)	GS 32.359 (32.359)	mem 40.115
Train: [59][305/750]	BT 0.078 (1.183)	DT 0.001 (1.057)	loss nan (nan)	prob nan (nan)	GS 34.625 (34.625)	mem 39.923
Train: [59][310/750]	BT 0.139 (1.166)	DT 0.018 (1.041)	loss nan (nan)	prob nan (nan)	GS 34.000 (34.000)	mem 39.999
Train: [59][315/750]	BT 0.072 (1.186)	DT 0.002 (1.061)	loss nan (nan)	prob nan (nan)	GS 31.625 (31.625)	mem 39.987
Train: [59][320/750]	BT 0.094 (1.180)	DT 0.002 (1.055)	loss nan (nan)	prob nan (nan)	GS 31.531 (31.531)	mem 40.026
Train: [59][325/750]	BT 0.117 (1.164)	DT 0.002 (1.039)	loss nan (nan)	prob nan (nan)	GS 33.344 (33.344)	mem 40.027
Train: [59][330/750]	BT 10.135 (1.198)	DT 9.989 (1.072)	loss nan (nan)	prob nan (nan)	GS 35.547 (35.547)	mem 39.830
Train: [59][335/750]	BT 0.143 (1.182)	DT 0.010 (1.056)	loss nan (nan)	prob nan (nan)	GS 33.875 (33.875)	mem 39.831
Train: [59][340/750]	BT 0.324 (1.168)	DT 0.232 (1.041)	loss nan (nan)	prob nan (nan)	GS 35.719 (35.719)	mem 39.877
Train: [59][345/750]	BT 0.126 (1.183)	DT 0.010 (1.058)	loss nan (nan)	prob nan (nan)	GS 32.125 (32.125)	mem 39.878
Train: [59][350/750]	BT 0.137 (1.168)	DT 0.014 (1.043)	loss nan (nan)	prob nan (nan)	GS 31.875 (31.875)	mem 39.946
Train: [59][355/750]	BT 0.093 (1.184)	DT 0.002 (1.058)	loss nan (nan)	prob nan (nan)	GS 29.719 (29.719)	mem 39.813
Train: [59][360/750]	BT 0.146 (1.169)	DT 0.003 (1.044)	loss nan (nan)	prob nan (nan)	GS 34.875 (34.875)	mem 39.866
Train: [59][365/750]	BT 0.117 (1.167)	DT 0.007 (1.041)	loss nan (nan)	prob nan (nan)	GS 27.344 (27.344)	mem 39.838
Train: [59][370/750]	BT 0.085 (1.172)	DT 0.002 (1.046)	loss nan (nan)	prob nan (nan)	GS 35.172 (35.172)	mem 39.931
Train: [59][375/750]	BT 0.149 (1.159)	DT 0.003 (1.033)	loss nan (nan)	prob nan (nan)	GS 30.000 (30.000)	mem 39.975
Train: [59][380/750]	BT 0.139 (1.180)	DT 0.008 (1.054)	loss nan (nan)	prob nan (nan)	GS 36.172 (36.172)	mem 39.936
Train: [59][385/750]	BT 0.212 (1.166)	DT 0.002 (1.040)	loss nan (nan)	prob nan (nan)	GS 28.828 (28.828)	mem 39.923
Train: [59][390/750]	BT 0.994 (1.173)	DT 0.802 (1.047)	loss nan (nan)	prob nan (nan)	GS 31.594 (31.594)	mem 39.972
Train: [59][395/750]	BT 0.347 (1.161)	DT 0.010 (1.034)	loss nan (nan)	prob nan (nan)	GS 39.203 (39.203)	mem 39.940
Train: [59][400/750]	BT 5.795 (1.174)	DT 5.640 (1.047)	loss nan (nan)	prob nan (nan)	GS 34.844 (34.844)	mem 39.899
Train: [59][405/750]	BT 0.125 (1.164)	DT 0.013 (1.037)	loss nan (nan)	prob nan (nan)	GS 31.328 (31.328)	mem 39.873
Train: [59][410/750]	BT 6.684 (1.168)	DT 6.562 (1.040)	loss nan (nan)	prob nan (nan)	GS 34.078 (34.078)	mem 39.865
Train: [59][415/750]	BT 0.156 (1.164)	DT 0.002 (1.037)	loss nan (nan)	prob nan (nan)	GS 27.562 (27.562)	mem 39.908
Train: [59][420/750]	BT 0.120 (1.152)	DT 0.003 (1.025)	loss nan (nan)	prob nan (nan)	GS 33.141 (33.141)	mem 40.061
Train: [59][425/750]	BT 0.131 (1.171)	DT 0.007 (1.043)	loss nan (nan)	prob nan (nan)	GS 32.812 (32.812)	mem 40.237
Train: [59][430/750]	BT 0.120 (1.159)	DT 0.013 (1.031)	loss nan (nan)	prob nan (nan)	GS 33.500 (33.500)	mem 39.885
Train: [59][435/750]	BT 0.192 (1.164)	DT 0.002 (1.035)	loss nan (nan)	prob nan (nan)	GS 31.438 (31.438)	mem 40.021
Train: [59][440/750]	BT 0.087 (1.161)	DT 0.016 (1.033)	loss nan (nan)	prob nan (nan)	GS 31.766 (31.766)	mem 39.998
Train: [59][445/750]	BT 0.218 (1.153)	DT 0.002 (1.024)	loss nan (nan)	prob nan (nan)	GS 35.625 (35.625)	mem 40.117
Train: [59][450/750]	BT 0.109 (1.162)	DT 0.006 (1.034)	loss nan (nan)	prob nan (nan)	GS 35.719 (35.719)	mem 40.003
Train: [59][455/750]	BT 0.171 (1.157)	DT 0.002 (1.027)	loss nan (nan)	prob nan (nan)	GS 29.672 (29.672)	mem 40.002
Train: [59][460/750]	BT 9.166 (1.169)	DT 9.049 (1.040)	loss nan (nan)	prob nan (nan)	GS 37.594 (37.594)	mem 40.064
Train: [59][465/750]	BT 0.146 (1.160)	DT 0.003 (1.031)	loss nan (nan)	prob nan (nan)	GS 33.031 (33.031)	mem 40.202
Train: [59][470/750]	BT 5.125 (1.160)	DT 4.953 (1.031)	loss nan (nan)	prob nan (nan)	GS 39.938 (39.938)	mem 40.015
Train: [59][475/750]	BT 0.104 (1.163)	DT 0.004 (1.034)	loss nan (nan)	prob nan (nan)	GS 31.250 (31.250)	mem 40.028
Train: [59][480/750]	BT 0.144 (1.152)	DT 0.001 (1.023)	loss nan (nan)	prob nan (nan)	GS 30.906 (30.906)	mem 40.080
Train: [59][485/750]	BT 0.243 (1.159)	DT 0.010 (1.029)	loss nan (nan)	prob nan (nan)	GS 35.188 (35.188)	mem 40.050
Train: [59][490/750]	BT 0.096 (1.157)	DT 0.002 (1.027)	loss nan (nan)	prob nan (nan)	GS 35.281 (35.281)	mem 40.013
Train: [59][495/750]	BT 0.192 (1.147)	DT 0.015 (1.017)	loss nan (nan)	prob nan (nan)	GS 29.250 (29.250)	mem 40.027
Train: [59][500/750]	BT 0.106 (1.159)	DT 0.007 (1.029)	loss nan (nan)	prob nan (nan)	GS 36.266 (36.266)	mem 40.182
Train: [59][505/750]	BT 0.163 (1.148)	DT 0.002 (1.018)	loss nan (nan)	prob nan (nan)	GS 30.969 (30.969)	mem 40.046
Train: [59][510/750]	BT 11.307 (1.165)	DT 11.236 (1.035)	loss nan (nan)	prob nan (nan)	GS 29.547 (29.547)	mem 39.970
Train: [59][515/750]	BT 0.155 (1.155)	DT 0.014 (1.025)	loss nan (nan)	prob nan (nan)	GS 33.703 (33.703)	mem 39.995
Train: [59][520/750]	BT 0.146 (1.145)	DT 0.008 (1.015)	loss nan (nan)	prob nan (nan)	GS 36.328 (36.328)	mem 40.038
Train: [59][525/750]	BT 0.087 (1.155)	DT 0.002 (1.025)	loss nan (nan)	prob nan (nan)	GS 33.812 (33.812)	mem 40.025
Train: [59][530/750]	BT 0.084 (1.145)	DT 0.001 (1.015)	loss nan (nan)	prob nan (nan)	GS 32.203 (32.203)	mem 40.011
Train: [59][535/750]	BT 0.089 (1.151)	DT 0.001 (1.021)	loss nan (nan)	prob nan (nan)	GS 31.438 (31.438)	mem 40.065
Train: [59][540/750]	BT 0.082 (1.141)	DT 0.001 (1.012)	loss nan (nan)	prob nan (nan)	GS 34.406 (34.406)	mem 40.138
Train: [59][545/750]	BT 0.078 (1.137)	DT 0.001 (1.007)	loss nan (nan)	prob nan (nan)	GS 27.578 (27.578)	mem 40.035
Train: [59][550/750]	BT 0.147 (1.142)	DT 0.002 (1.012)	loss nan (nan)	prob nan (nan)	GS 34.516 (34.516)	mem 40.103
Train: [59][555/750]	BT 0.078 (1.133)	DT 0.001 (1.003)	loss nan (nan)	prob nan (nan)	GS 32.078 (32.078)	mem 40.060
Train: [59][560/750]	BT 0.145 (1.147)	DT 0.009 (1.017)	loss nan (nan)	prob nan (nan)	GS 32.641 (32.641)	mem 40.156
Train: [59][565/750]	BT 0.093 (1.138)	DT 0.002 (1.008)	loss nan (nan)	prob nan (nan)	GS 33.594 (33.594)	mem 40.161
Train: [59][570/750]	BT 10.412 (1.153)	DT 10.306 (1.023)	loss nan (nan)	prob nan (nan)	GS 37.844 (37.844)	mem 40.074
Train: [59][575/750]	BT 0.150 (1.144)	DT 0.020 (1.014)	loss nan (nan)	prob nan (nan)	GS 31.484 (31.484)	mem 40.076
Train: [59][580/750]	BT 0.455 (1.135)	DT 0.310 (1.006)	loss nan (nan)	prob nan (nan)	GS 34.141 (34.141)	mem 40.332
Train: [59][585/750]	BT 0.198 (1.144)	DT 0.002 (1.014)	loss nan (nan)	prob nan (nan)	GS 35.547 (35.547)	mem 40.104
Train: [59][590/750]	BT 5.881 (1.144)	DT 5.776 (1.015)	loss nan (nan)	prob nan (nan)	GS 35.859 (35.859)	mem 40.011
Train: [59][595/750]	BT 0.114 (1.147)	DT 0.002 (1.017)	loss nan (nan)	prob nan (nan)	GS 29.891 (29.891)	mem 40.051
Train: [59][600/750]	BT 0.088 (1.138)	DT 0.004 (1.009)	loss nan (nan)	prob nan (nan)	GS 36.938 (36.938)	mem 40.121
Train: [59][605/750]	BT 0.159 (1.144)	DT 0.002 (1.014)	loss nan (nan)	prob nan (nan)	GS 36.875 (36.875)	mem 40.138
Train: [59][610/750]	BT 0.117 (1.142)	DT 0.002 (1.012)	loss nan (nan)	prob nan (nan)	GS 36.672 (36.672)	mem 40.026
Train: [59][615/750]	BT 0.178 (1.146)	DT 0.002 (1.016)	loss nan (nan)	prob nan (nan)	GS 33.406 (33.406)	mem 40.056
Train: [59][620/750]	BT 0.090 (1.147)	DT 0.001 (1.017)	loss nan (nan)	prob nan (nan)	GS 31.344 (31.344)	mem 40.056
Train: [59][625/750]	BT 0.104 (1.139)	DT 0.016 (1.009)	loss nan (nan)	prob nan (nan)	GS 30.922 (30.922)	mem 40.162
Train: [59][630/750]	BT 7.790 (1.153)	DT 7.671 (1.023)	loss nan (nan)	prob nan (nan)	GS 35.812 (35.812)	mem 40.087
Train: [59][635/750]	BT 0.174 (1.145)	DT 0.005 (1.015)	loss nan (nan)	prob nan (nan)	GS 31.094 (31.094)	mem 40.098
Train: [59][640/750]	BT 0.222 (1.144)	DT 0.002 (1.014)	loss nan (nan)	prob nan (nan)	GS 35.453 (35.453)	mem 40.116
Train: [59][645/750]	BT 0.130 (1.143)	DT 0.002 (1.013)	loss nan (nan)	prob nan (nan)	GS 34.016 (34.016)	mem 40.132
Train: [59][650/750]	BT 6.189 (1.144)	DT 6.092 (1.015)	loss nan (nan)	prob nan (nan)	GS 32.266 (32.266)	mem 40.215
Train: [59][655/750]	BT 0.112 (1.145)	DT 0.004 (1.014)	loss nan (nan)	prob nan (nan)	GS 31.391 (31.391)	mem 40.027
Train: [59][660/750]	BT 0.198 (1.137)	DT 0.002 (1.007)	loss nan (nan)	prob nan (nan)	GS 37.422 (37.422)	mem 40.122
Train: [59][665/750]	BT 0.106 (1.144)	DT 0.001 (1.014)	loss nan (nan)	prob nan (nan)	GS 27.344 (27.344)	mem 40.004
Train: [59][670/750]	BT 0.186 (1.141)	DT 0.010 (1.010)	loss nan (nan)	prob nan (nan)	GS 36.375 (36.375)	mem 40.164
Train: [59][675/750]	BT 0.080 (1.147)	DT 0.005 (1.017)	loss nan (nan)	prob nan (nan)	GS 35.859 (35.859)	mem 39.974
Train: [59][680/750]	BT 0.239 (1.140)	DT 0.017 (1.009)	loss nan (nan)	prob nan (nan)	GS 35.375 (35.375)	mem 40.051
Train: [59][685/750]	BT 0.181 (1.132)	DT 0.002 (1.002)	loss nan (nan)	prob nan (nan)	GS 29.703 (29.703)	mem 39.998
Train: [59][690/750]	BT 0.992 (1.143)	DT 0.835 (1.013)	loss nan (nan)	prob nan (nan)	GS 32.984 (32.984)	mem 40.005
Train: [59][695/750]	BT 0.219 (1.136)	DT 0.007 (1.006)	loss nan (nan)	prob nan (nan)	GS 30.891 (30.891)	mem 40.098
Train: [59][700/750]	BT 0.588 (1.143)	DT 0.468 (1.013)	loss nan (nan)	prob nan (nan)	GS 35.000 (35.000)	mem 40.081
Train: [59][705/750]	BT 0.167 (1.141)	DT 0.004 (1.010)	loss nan (nan)	prob nan (nan)	GS 33.672 (33.672)	mem 40.015
arpack error, retry= 0
Train: [59][710/750]	BT 5.970 (1.146)	DT 5.825 (1.015)	loss nan (nan)	prob nan (nan)	GS 36.906 (36.906)	mem 40.086
Train: [59][715/750]	BT 0.088 (1.142)	DT 0.002 (1.012)	loss nan (nan)	prob nan (nan)	GS 33.656 (33.656)	mem 40.186
Train: [59][720/750]	BT 0.110 (1.139)	DT 0.002 (1.008)	loss nan (nan)	prob nan (nan)	GS 33.125 (33.125)	mem 40.086
Train: [59][725/750]	BT 0.168 (1.141)	DT 0.002 (1.010)	loss nan (nan)	prob nan (nan)	GS 33.391 (33.391)	mem 39.952
Train: [59][730/750]	BT 3.495 (1.139)	DT 3.246 (1.008)	loss nan (nan)	prob nan (nan)	GS 32.969 (32.969)	mem 40.087
Train: [59][735/750]	BT 0.069 (1.140)	DT 0.001 (1.010)	loss nan (nan)	prob nan (nan)	GS 32.172 (32.172)	mem 36.798
Train: [59][740/750]	BT 0.122 (1.133)	DT 0.002 (1.003)	loss nan (nan)	prob nan (nan)	GS 33.906 (33.906)	mem 36.769
Train: [59][745/750]	BT 0.061 (1.131)	DT 0.001 (1.001)	loss nan (nan)	prob nan (nan)	GS 34.250 (34.250)	mem 10.695
Train: [59][750/750]	BT 0.090 (1.124)	DT 0.001 (0.994)	loss nan (nan)	prob nan (nan)	GS 36.156 (36.156)	mem 10.624
Train: [59][755/750]	BT 0.070 (1.119)	DT 0.001 (0.990)	loss nan (nan)	prob nan (nan)	GS 31.531 (31.531)	mem 7.682
epoch 59, total time 845.24
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [60][1/750]	BT 23.475 (23.475)	DT 23.311 (23.311)	loss nan (nan)	prob nan (nan)	GS 34.062 (34.062)	mem 38.714
Train: [60][5/750]	BT 0.160 (4.844)	DT 0.004 (4.702)	loss nan (nan)	prob nan (nan)	GS 28.750 (28.750)	mem 38.891
Train: [60][10/750]	BT 0.204 (2.846)	DT 0.052 (2.712)	loss nan (nan)	prob nan (nan)	GS 36.719 (36.719)	mem 38.881
Train: [60][15/750]	BT 0.162 (2.773)	DT 0.008 (2.624)	loss nan (nan)	prob nan (nan)	GS 28.797 (28.797)	mem 38.973
Train: [60][20/750]	BT 3.190 (2.273)	DT 3.059 (2.121)	loss nan (nan)	prob nan (nan)	GS 32.062 (32.062)	mem 38.968
Train: [60][25/750]	BT 0.109 (1.843)	DT 0.002 (1.698)	loss nan (nan)	prob nan (nan)	GS 31.234 (31.234)	mem 39.051
Train: [60][30/750]	BT 0.089 (1.894)	DT 0.001 (1.751)	loss nan (nan)	prob nan (nan)	GS 34.141 (34.141)	mem 39.075
Train: [60][35/750]	BT 0.105 (1.723)	DT 0.002 (1.583)	loss nan (nan)	prob nan (nan)	GS 30.375 (30.375)	mem 38.961
Train: [60][40/750]	BT 0.084 (1.710)	DT 0.001 (1.571)	loss nan (nan)	prob nan (nan)	GS 35.922 (35.922)	mem 39.033
Train: [60][45/750]	BT 0.081 (1.728)	DT 0.002 (1.593)	loss nan (nan)	prob nan (nan)	GS 30.344 (30.344)	mem 39.073
Train: [60][50/750]	BT 1.422 (1.591)	DT 1.229 (1.458)	loss nan (nan)	prob nan (nan)	GS 32.359 (32.359)	mem 39.175
Train: [60][55/750]	BT 0.172 (1.459)	DT 0.003 (1.326)	loss nan (nan)	prob nan (nan)	GS 36.094 (36.094)	mem 39.128
Train: [60][60/750]	BT 0.082 (1.553)	DT 0.001 (1.423)	loss nan (nan)	prob nan (nan)	GS 34.547 (34.547)	mem 39.099
Train: [60][65/750]	BT 0.083 (1.443)	DT 0.001 (1.314)	loss nan (nan)	prob nan (nan)	GS 29.641 (29.641)	mem 39.121
Train: [60][70/750]	BT 0.070 (1.540)	DT 0.001 (1.411)	loss nan (nan)	prob nan (nan)	GS 32.688 (32.688)	mem 39.201
Train: [60][75/750]	BT 0.083 (1.444)	DT 0.001 (1.317)	loss nan (nan)	prob nan (nan)	GS 33.109 (33.109)	mem 39.226
Train: [60][80/750]	BT 9.131 (1.475)	DT 9.001 (1.348)	loss nan (nan)	prob nan (nan)	GS 34.703 (34.703)	mem 39.282
Train: [60][85/750]	BT 0.154 (1.397)	DT 0.028 (1.269)	loss nan (nan)	prob nan (nan)	GS 28.984 (28.984)	mem 39.284
Train: [60][90/750]	BT 0.072 (1.326)	DT 0.003 (1.198)	loss nan (nan)	prob nan (nan)	GS 28.938 (28.938)	mem 39.292
Train: [60][95/750]	BT 0.139 (1.394)	DT 0.010 (1.267)	loss nan (nan)	prob nan (nan)	GS 33.469 (33.469)	mem 39.168
Train: [60][100/750]	BT 0.088 (1.335)	DT 0.001 (1.209)	loss nan (nan)	prob nan (nan)	GS 35.922 (35.922)	mem 39.175
Train: [60][105/750]	BT 0.093 (1.369)	DT 0.001 (1.245)	loss nan (nan)	prob nan (nan)	GS 35.984 (35.984)	mem 39.210
Train: [60][110/750]	BT 3.149 (1.341)	DT 2.996 (1.216)	loss nan (nan)	prob nan (nan)	GS 30.891 (30.891)	mem 39.280
Train: [60][115/750]	BT 0.169 (1.289)	DT 0.002 (1.163)	loss nan (nan)	prob nan (nan)	GS 31.281 (31.281)	mem 39.255
Train: [60][120/750]	BT 0.103 (1.306)	DT 0.002 (1.181)	loss nan (nan)	prob nan (nan)	GS 37.344 (37.344)	mem 39.210
Train: [60][125/750]	BT 0.091 (1.308)	DT 0.001 (1.185)	loss nan (nan)	prob nan (nan)	GS 29.672 (29.672)	mem 39.254
Train: [60][130/750]	BT 0.148 (1.324)	DT 0.002 (1.201)	loss nan (nan)	prob nan (nan)	GS 35.859 (35.859)	mem 39.425
Train: [60][135/750]	BT 0.111 (1.312)	DT 0.001 (1.188)	loss nan (nan)	prob nan (nan)	GS 29.672 (29.672)	mem 39.245
Train: [60][140/750]	BT 7.718 (1.324)	DT 7.593 (1.200)	loss nan (nan)	prob nan (nan)	GS 33.172 (33.172)	mem 39.325
Train: [60][145/750]	BT 0.150 (1.283)	DT 0.012 (1.159)	loss nan (nan)	prob nan (nan)	GS 31.688 (31.688)	mem 39.367
Train: [60][150/750]	BT 0.123 (1.276)	DT 0.006 (1.152)	loss nan (nan)	prob nan (nan)	GS 31.984 (31.984)	mem 39.290
Train: [60][155/750]	BT 0.137 (1.293)	DT 0.009 (1.168)	loss nan (nan)	prob nan (nan)	GS 33.594 (33.594)	mem 39.447
Train: [60][160/750]	BT 0.248 (1.276)	DT 0.002 (1.150)	loss nan (nan)	prob nan (nan)	GS 32.141 (32.141)	mem 39.422
Train: [60][165/750]	BT 0.115 (1.260)	DT 0.002 (1.135)	loss nan (nan)	prob nan (nan)	GS 32.375 (32.375)	mem 39.795
Train: [60][170/750]	BT 6.663 (1.267)	DT 6.514 (1.140)	loss nan (nan)	prob nan (nan)	GS 35.000 (35.000)	mem 39.439
Train: [60][175/750]	BT 0.079 (1.234)	DT 0.002 (1.107)	loss nan (nan)	prob nan (nan)	GS 29.547 (29.547)	mem 39.437
Train: [60][180/750]	BT 0.198 (1.231)	DT 0.003 (1.104)	loss nan (nan)	prob nan (nan)	GS 31.781 (31.781)	mem 39.352
Train: [60][185/750]	BT 0.120 (1.258)	DT 0.001 (1.131)	loss nan (nan)	prob nan (nan)	GS 36.078 (36.078)	mem 39.575
Train: [60][190/750]	BT 0.258 (1.243)	DT 0.006 (1.116)	loss nan (nan)	prob nan (nan)	GS 35.438 (35.438)	mem 39.583
Train: [60][195/750]	BT 0.073 (1.262)	DT 0.002 (1.135)	loss nan (nan)	prob nan (nan)	GS 26.953 (26.953)	mem 39.695
Train: [60][200/750]	BT 3.282 (1.250)	DT 3.058 (1.122)	loss nan (nan)	prob nan (nan)	GS 38.469 (38.469)	mem 39.671
Train: [60][205/750]	BT 0.093 (1.222)	DT 0.002 (1.094)	loss nan (nan)	prob nan (nan)	GS 27.812 (27.812)	mem 39.625
Train: [60][210/750]	BT 0.085 (1.230)	DT 0.002 (1.102)	loss nan (nan)	prob nan (nan)	GS 34.125 (34.125)	mem 39.588
Train: [60][215/750]	BT 0.098 (1.223)	DT 0.002 (1.094)	loss nan (nan)	prob nan (nan)	GS 33.016 (33.016)	mem 39.583
Train: [60][220/750]	BT 0.167 (1.228)	DT 0.004 (1.099)	loss nan (nan)	prob nan (nan)	GS 30.750 (30.750)	mem 39.638
Train: [60][225/750]	BT 0.205 (1.235)	DT 0.001 (1.106)	loss nan (nan)	prob nan (nan)	GS 31.391 (31.391)	mem 39.691
Train: [60][230/750]	BT 1.994 (1.220)	DT 1.843 (1.090)	loss nan (nan)	prob nan (nan)	GS 35.266 (35.266)	mem 39.656
Train: [60][235/750]	BT 0.184 (1.197)	DT 0.001 (1.067)	loss nan (nan)	prob nan (nan)	GS 32.594 (32.594)	mem 39.716
Train: [60][240/750]	BT 0.139 (1.206)	DT 0.001 (1.075)	loss nan (nan)	prob nan (nan)	GS 34.766 (34.766)	mem 39.750
Train: [60][245/750]	BT 0.137 (1.204)	DT 0.009 (1.072)	loss nan (nan)	prob nan (nan)	GS 31.938 (31.938)	mem 39.831
Train: [60][250/750]	BT 0.072 (1.217)	DT 0.001 (1.086)	loss nan (nan)	prob nan (nan)	GS 33.047 (33.047)	mem 39.909
Train: [60][255/750]	BT 0.128 (1.204)	DT 0.002 (1.072)	loss nan (nan)	prob nan (nan)	GS 30.281 (30.281)	mem 39.877
Train: [60][260/750]	BT 9.010 (1.217)	DT 8.866 (1.086)	loss nan (nan)	prob nan (nan)	GS 34.281 (34.281)	mem 39.964
Train: [60][265/750]	BT 0.099 (1.197)	DT 0.002 (1.065)	loss nan (nan)	prob nan (nan)	GS 27.906 (27.906)	mem 39.963
Train: [60][270/750]	BT 0.164 (1.190)	DT 0.009 (1.059)	loss nan (nan)	prob nan (nan)	GS 36.391 (36.391)	mem 40.254
Train: [60][275/750]	BT 0.148 (1.203)	DT 0.002 (1.070)	loss nan (nan)	prob nan (nan)	GS 30.438 (30.438)	mem 39.969
Train: [60][280/750]	BT 6.902 (1.214)	DT 6.784 (1.081)	loss nan (nan)	prob nan (nan)	GS 35.906 (35.906)	mem 40.006
Train: [60][285/750]	BT 0.084 (1.196)	DT 0.002 (1.064)	loss nan (nan)	prob nan (nan)	GS 34.312 (34.312)	mem 39.887
Train: [60][290/750]	BT 0.605 (1.180)	DT 0.446 (1.048)	loss nan (nan)	prob nan (nan)	GS 29.438 (29.438)	mem 39.918
Train: [60][295/750]	BT 0.195 (1.204)	DT 0.007 (1.072)	loss nan (nan)	prob nan (nan)	GS 32.797 (32.797)	mem 40.134
Train: [60][300/750]	BT 0.231 (1.186)	DT 0.001 (1.054)	loss nan (nan)	prob nan (nan)	GS 39.375 (39.375)	mem 39.947
Train: [60][305/750]	BT 0.078 (1.212)	DT 0.002 (1.081)	loss nan (nan)	prob nan (nan)	GS 37.859 (37.859)	mem 40.052
Train: [60][310/750]	BT 0.168 (1.194)	DT 0.009 (1.063)	loss nan (nan)	prob nan (nan)	GS 34.500 (34.500)	mem 40.053
Train: [60][315/750]	BT 0.135 (1.178)	DT 0.001 (1.047)	loss nan (nan)	prob nan (nan)	GS 31.375 (31.375)	mem 40.055
Train: [60][320/750]	BT 0.138 (1.195)	DT 0.001 (1.065)	loss nan (nan)	prob nan (nan)	GS 34.391 (34.391)	mem 40.083
Train: [60][325/750]	BT 0.211 (1.179)	DT 0.002 (1.048)	loss nan (nan)	prob nan (nan)	GS 30.906 (30.906)	mem 40.085
Train: [60][330/750]	BT 0.089 (1.204)	DT 0.001 (1.073)	loss nan (nan)	prob nan (nan)	GS 35.219 (35.219)	mem 39.956
Train: [60][335/750]	BT 0.144 (1.187)	DT 0.016 (1.057)	loss nan (nan)	prob nan (nan)	GS 27.859 (27.859)	mem 40.024
Train: [60][340/750]	BT 10.754 (1.203)	DT 10.650 (1.073)	loss nan (nan)	prob nan (nan)	GS 32.891 (32.891)	mem 40.087
Train: [60][345/750]	BT 0.089 (1.188)	DT 0.001 (1.057)	loss nan (nan)	prob nan (nan)	GS 31.453 (31.453)	mem 40.088
Train: [60][350/750]	BT 0.090 (1.172)	DT 0.001 (1.042)	loss nan (nan)	prob nan (nan)	GS 29.312 (29.312)	mem 40.116
Train: [60][355/750]	BT 0.205 (1.190)	DT 0.007 (1.060)	loss nan (nan)	prob nan (nan)	GS 28.453 (28.453)	mem 40.184
Train: [60][360/750]	BT 0.115 (1.175)	DT 0.009 (1.045)	loss nan (nan)	prob nan (nan)	GS 29.562 (29.562)	mem 40.293
Train: [60][365/750]	BT 0.115 (1.187)	DT 0.002 (1.057)	loss nan (nan)	prob nan (nan)	GS 31.516 (31.516)	mem 40.107
Train: [60][370/750]	BT 0.118 (1.173)	DT 0.007 (1.043)	loss nan (nan)	prob nan (nan)	GS 32.531 (32.531)	mem 40.134
Train: [60][375/750]	BT 0.105 (1.162)	DT 0.002 (1.032)	loss nan (nan)	prob nan (nan)	GS 29.375 (29.375)	mem 40.136
Train: [60][380/750]	BT 0.133 (1.178)	DT 0.008 (1.048)	loss nan (nan)	prob nan (nan)	GS 29.469 (29.469)	mem 40.112
Train: [60][385/750]	BT 0.095 (1.164)	DT 0.002 (1.034)	loss nan (nan)	prob nan (nan)	GS 28.609 (28.609)	mem 40.166
Train: [60][390/750]	BT 0.998 (1.173)	DT 0.813 (1.043)	loss nan (nan)	prob nan (nan)	GS 34.781 (34.781)	mem 40.030
Train: [60][395/750]	BT 0.157 (1.161)	DT 0.002 (1.030)	loss nan (nan)	prob nan (nan)	GS 31.469 (31.469)	mem 40.198
Train: [60][400/750]	BT 4.560 (1.170)	DT 4.408 (1.038)	loss nan (nan)	prob nan (nan)	GS 30.047 (30.047)	mem 40.215
Train: [60][405/750]	BT 0.162 (1.164)	DT 0.002 (1.032)	loss nan (nan)	prob nan (nan)	GS 35.875 (35.875)	mem 40.172
Train: [60][410/750]	BT 2.814 (1.159)	DT 2.651 (1.027)	loss nan (nan)	prob nan (nan)	GS 30.500 (30.500)	mem 40.053
Train: [60][415/750]	BT 0.301 (1.160)	DT 0.022 (1.027)	loss nan (nan)	prob nan (nan)	GS 36.156 (36.156)	mem 40.315
Train: [60][420/750]	BT 5.027 (1.163)	DT 4.936 (1.031)	loss nan (nan)	prob nan (nan)	GS 32.031 (32.031)	mem 40.074
Train: [60][425/750]	BT 0.109 (1.153)	DT 0.001 (1.021)	loss nan (nan)	prob nan (nan)	GS 37.219 (37.219)	mem 40.118
Train: [60][430/750]	BT 0.147 (1.151)	DT 0.017 (1.019)	loss nan (nan)	prob nan (nan)	GS 29.719 (29.719)	mem 40.088
Train: [60][435/750]	BT 0.153 (1.157)	DT 0.008 (1.025)	loss nan (nan)	prob nan (nan)	GS 32.094 (32.094)	mem 40.098
Train: [60][440/750]	BT 2.024 (1.152)	DT 1.914 (1.020)	loss nan (nan)	prob nan (nan)	GS 34.906 (34.906)	mem 40.200
Train: [60][445/750]	BT 0.106 (1.164)	DT 0.002 (1.032)	loss nan (nan)	prob nan (nan)	GS 30.703 (30.703)	mem 39.997
Train: [60][450/750]	BT 0.124 (1.154)	DT 0.001 (1.021)	loss nan (nan)	prob nan (nan)	GS 30.672 (30.672)	mem 39.955
Train: [60][455/750]	BT 0.135 (1.142)	DT 0.002 (1.010)	loss nan (nan)	prob nan (nan)	GS 35.812 (35.812)	mem 39.964
Train: [60][460/750]	BT 0.103 (1.152)	DT 0.006 (1.020)	loss nan (nan)	prob nan (nan)	GS 28.359 (28.359)	mem 40.066
Train: [60][465/750]	BT 0.168 (1.146)	DT 0.003 (1.014)	loss nan (nan)	prob nan (nan)	GS 31.469 (31.469)	mem 40.006
Train: [60][470/750]	BT 0.123 (1.161)	DT 0.001 (1.028)	loss nan (nan)	prob nan (nan)	GS 28.609 (28.609)	mem 40.152
Train: [60][475/750]	BT 0.129 (1.160)	DT 0.002 (1.026)	loss nan (nan)	prob nan (nan)	GS 28.641 (28.641)	mem 40.085
Train: [60][480/750]	BT 7.815 (1.165)	DT 7.643 (1.032)	loss nan (nan)	prob nan (nan)	GS 34.781 (34.781)	mem 40.375
Train: [60][485/750]	BT 0.150 (1.162)	DT 0.002 (1.029)	loss nan (nan)	prob nan (nan)	GS 36.297 (36.297)	mem 40.028
Train: [60][490/750]	BT 0.122 (1.154)	DT 0.002 (1.021)	loss nan (nan)	prob nan (nan)	GS 35.969 (35.969)	mem 39.958
Train: [60][495/750]	BT 0.089 (1.154)	DT 0.002 (1.021)	loss nan (nan)	prob nan (nan)	GS 30.125 (30.125)	mem 40.033
Train: [60][500/750]	BT 0.239 (1.156)	DT 0.017 (1.022)	loss nan (nan)	prob nan (nan)	GS 28.797 (28.797)	mem 40.145
Train: [60][505/750]	BT 0.096 (1.151)	DT 0.002 (1.017)	loss nan (nan)	prob nan (nan)	GS 28.609 (28.609)	mem 40.117
Train: [60][510/750]	BT 5.050 (1.162)	DT 4.892 (1.028)	loss nan (nan)	prob nan (nan)	GS 35.359 (35.359)	mem 39.988
Train: [60][515/750]	BT 0.129 (1.152)	DT 0.004 (1.018)	loss nan (nan)	prob nan (nan)	GS 32.000 (32.000)	mem 39.990
Train: [60][520/750]	BT 9.369 (1.161)	DT 9.282 (1.027)	loss nan (nan)	prob nan (nan)	GS 34.969 (34.969)	mem 40.064
Train: [60][525/750]	BT 0.109 (1.157)	DT 0.007 (1.024)	loss nan (nan)	prob nan (nan)	GS 31.703 (31.703)	mem 40.200
Train: [60][530/750]	BT 0.108 (1.150)	DT 0.001 (1.017)	loss nan (nan)	prob nan (nan)	GS 34.906 (34.906)	mem 40.030
Train: [60][535/750]	BT 0.139 (1.164)	DT 0.001 (1.030)	loss nan (nan)	prob nan (nan)	GS 28.672 (28.672)	mem 39.977
Train: [60][540/750]	BT 0.088 (1.154)	DT 0.001 (1.021)	loss nan (nan)	prob nan (nan)	GS 30.203 (30.203)	mem 40.044
Train: [60][545/750]	BT 0.186 (1.161)	DT 0.017 (1.027)	loss nan (nan)	prob nan (nan)	GS 30.219 (30.219)	mem 40.286
Train: [60][550/750]	BT 0.132 (1.158)	DT 0.011 (1.024)	loss nan (nan)	prob nan (nan)	GS 31.438 (31.438)	mem 40.162
Train: [60][555/750]	BT 0.125 (1.149)	DT 0.007 (1.015)	loss nan (nan)	prob nan (nan)	GS 31.391 (31.391)	mem 40.120
Train: [60][560/750]	BT 1.855 (1.159)	DT 1.705 (1.026)	loss nan (nan)	prob nan (nan)	GS 36.438 (36.438)	mem 40.187
Train: [60][565/750]	BT 0.161 (1.150)	DT 0.025 (1.017)	loss nan (nan)	prob nan (nan)	GS 29.969 (29.969)	mem 40.153
Train: [60][570/750]	BT 0.123 (1.157)	DT 0.002 (1.024)	loss nan (nan)	prob nan (nan)	GS 34.031 (34.031)	mem 40.155
Train: [60][575/750]	BT 0.085 (1.148)	DT 0.005 (1.015)	loss nan (nan)	prob nan (nan)	GS 33.328 (33.328)	mem 40.156
Train: [60][580/750]	BT 13.306 (1.162)	DT 13.218 (1.029)	loss nan (nan)	prob nan (nan)	GS 32.188 (32.188)	mem 40.111
Train: [60][585/750]	BT 0.205 (1.153)	DT 0.017 (1.020)	loss nan (nan)	prob nan (nan)	GS 29.641 (29.641)	mem 40.236
Train: [60][590/750]	BT 0.251 (1.145)	DT 0.001 (1.012)	loss nan (nan)	prob nan (nan)	GS 31.547 (31.547)	mem 40.326
Train: [60][595/750]	BT 0.127 (1.155)	DT 0.006 (1.022)	loss nan (nan)	prob nan (nan)	GS 28.688 (28.688)	mem 40.085
Train: [60][600/750]	BT 0.082 (1.147)	DT 0.001 (1.014)	loss nan (nan)	prob nan (nan)	GS 38.703 (38.703)	mem 40.086
Train: [60][605/750]	BT 0.145 (1.162)	DT 0.002 (1.029)	loss nan (nan)	prob nan (nan)	GS 31.609 (31.609)	mem 40.093
Train: [60][610/750]	BT 0.110 (1.153)	DT 0.002 (1.021)	loss nan (nan)	prob nan (nan)	GS 35.328 (35.328)	mem 40.069
Train: [60][615/750]	BT 0.141 (1.144)	DT 0.002 (1.012)	loss nan (nan)	prob nan (nan)	GS 32.016 (32.016)	mem 40.005
Train: [60][620/750]	BT 0.221 (1.149)	DT 0.131 (1.017)	loss nan (nan)	prob nan (nan)	GS 38.156 (38.156)	mem 40.076
Train: [60][625/750]	BT 0.122 (1.141)	DT 0.001 (1.009)	loss nan (nan)	prob nan (nan)	GS 34.484 (34.484)	mem 40.085
Train: [60][630/750]	BT 0.086 (1.154)	DT 0.001 (1.022)	loss nan (nan)	prob nan (nan)	GS 32.594 (32.594)	mem 40.116
Train: [60][635/750]	BT 0.148 (1.146)	DT 0.018 (1.014)	loss nan (nan)	prob nan (nan)	GS 27.875 (27.875)	mem 40.110
Train: [60][640/750]	BT 10.745 (1.156)	DT 10.597 (1.024)	loss nan (nan)	prob nan (nan)	GS 35.328 (35.328)	mem 40.136
Train: [60][645/750]	BT 0.172 (1.150)	DT 0.002 (1.018)	loss nan (nan)	prob nan (nan)	GS 34.703 (34.703)	mem 40.076
Train: [60][650/750]	BT 0.175 (1.144)	DT 0.010 (1.012)	loss nan (nan)	prob nan (nan)	GS 35.969 (35.969)	mem 40.358
Train: [60][655/750]	BT 0.108 (1.147)	DT 0.006 (1.015)	loss nan (nan)	prob nan (nan)	GS 33.031 (33.031)	mem 40.112
Train: [60][660/750]	BT 0.093 (1.148)	DT 0.004 (1.016)	loss nan (nan)	prob nan (nan)	GS 35.656 (35.656)	mem 40.140
Train: [60][665/750]	BT 0.136 (1.145)	DT 0.018 (1.013)	loss nan (nan)	prob nan (nan)	GS 33.328 (33.328)	mem 40.156
Train: [60][670/750]	BT 0.131 (1.146)	DT 0.002 (1.015)	loss nan (nan)	prob nan (nan)	GS 36.672 (36.672)	mem 40.136
Train: [60][675/750]	BT 0.240 (1.139)	DT 0.005 (1.007)	loss nan (nan)	prob nan (nan)	GS 30.906 (30.906)	mem 40.091
Train: [60][680/750]	BT 8.132 (1.149)	DT 8.027 (1.017)	loss nan (nan)	prob nan (nan)	GS 30.703 (30.703)	mem 40.030
Train: [60][685/750]	BT 0.145 (1.143)	DT 0.001 (1.011)	loss nan (nan)	prob nan (nan)	GS 34.172 (34.172)	mem 40.039
Train: [60][690/750]	BT 5.905 (1.144)	DT 5.746 (1.012)	loss nan (nan)	prob nan (nan)	GS 38.828 (38.828)	mem 40.092
Train: [60][695/750]	BT 0.165 (1.145)	DT 0.002 (1.013)	loss nan (nan)	prob nan (nan)	GS 30.312 (30.312)	mem 39.985
Train: [60][700/750]	BT 0.320 (1.138)	DT 0.002 (1.006)	loss nan (nan)	prob nan (nan)	GS 31.188 (31.188)	mem 39.988
Train: [60][705/750]	BT 0.081 (1.149)	DT 0.002 (1.016)	loss nan (nan)	prob nan (nan)	GS 30.453 (30.453)	mem 39.950
Train: [60][710/750]	BT 0.113 (1.141)	DT 0.008 (1.009)	loss nan (nan)	prob nan (nan)	GS 31.062 (31.062)	mem 40.009
Train: [60][715/750]	BT 0.179 (1.141)	DT 0.002 (1.009)	loss nan (nan)	prob nan (nan)	GS 34.375 (34.375)	mem 40.059
Train: [60][720/750]	BT 3.139 (1.144)	DT 3.055 (1.012)	loss nan (nan)	prob nan (nan)	GS 35.594 (35.594)	mem 40.033
Train: [60][725/750]	BT 0.175 (1.138)	DT 0.009 (1.005)	loss nan (nan)	prob nan (nan)	GS 30.344 (30.344)	mem 40.131
Train: [60][730/750]	BT 0.107 (1.140)	DT 0.002 (1.007)	loss nan (nan)	prob nan (nan)	GS 30.281 (30.281)	mem 39.753
Train: [60][735/750]	BT 0.103 (1.138)	DT 0.001 (1.006)	loss nan (nan)	prob nan (nan)	GS 32.672 (32.672)	mem 39.642
Train: [60][740/750]	BT 4.425 (1.138)	DT 4.321 (1.006)	loss nan (nan)	prob nan (nan)	GS 38.625 (38.625)	mem 10.669
Train: [60][745/750]	BT 0.060 (1.135)	DT 0.001 (1.003)	loss nan (nan)	prob nan (nan)	GS 28.000 (28.000)	mem 10.604
Train: [60][750/750]	BT 0.064 (1.128)	DT 0.001 (0.996)	loss nan (nan)	prob nan (nan)	GS 37.719 (37.719)	mem 10.634
Train: [60][755/750]	BT 0.074 (1.121)	DT 0.001 (0.990)	loss nan (nan)	prob nan (nan)	GS 50.531 (50.531)	mem 10.597
epoch 60, total time 848.25
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [61][1/750]	BT 22.744 (22.744)	DT 22.532 (22.532)	loss nan (nan)	prob nan (nan)	GS 34.938 (34.938)	mem 38.656
Train: [61][5/750]	BT 0.581 (4.725)	DT 0.458 (4.600)	loss nan (nan)	prob nan (nan)	GS 32.781 (32.781)	mem 39.070
Train: [61][10/750]	BT 2.704 (2.706)	DT 2.531 (2.566)	loss nan (nan)	prob nan (nan)	GS 34.000 (34.000)	mem 38.939
Train: [61][15/750]	BT 0.167 (2.321)	DT 0.023 (2.179)	loss nan (nan)	prob nan (nan)	GS 30.531 (30.531)	mem 39.003
Train: [61][20/750]	BT 0.252 (1.852)	DT 0.012 (1.699)	loss nan (nan)	prob nan (nan)	GS 32.656 (32.656)	mem 39.025
Train: [61][25/750]	BT 6.892 (1.982)	DT 6.706 (1.818)	loss nan (nan)	prob nan (nan)	GS 31.125 (31.125)	mem 39.103
Train: [61][30/750]	BT 0.328 (1.682)	DT 0.002 (1.515)	loss nan (nan)	prob nan (nan)	GS 35.031 (35.031)	mem 39.045
Train: [61][35/750]	BT 0.159 (1.591)	DT 0.001 (1.424)	loss nan (nan)	prob nan (nan)	GS 33.719 (33.719)	mem 39.062
Train: [61][40/750]	BT 1.114 (1.574)	DT 0.981 (1.411)	loss nan (nan)	prob nan (nan)	GS 35.812 (35.812)	mem 38.997
Train: [61][45/750]	BT 0.090 (1.413)	DT 0.001 (1.255)	loss nan (nan)	prob nan (nan)	GS 32.453 (32.453)	mem 39.001
Train: [61][50/750]	BT 7.114 (1.551)	DT 6.965 (1.395)	loss nan (nan)	prob nan (nan)	GS 30.516 (30.516)	mem 39.164
Train: [61][55/750]	BT 0.126 (1.477)	DT 0.002 (1.324)	loss nan (nan)	prob nan (nan)	GS 34.266 (34.266)	mem 39.270
Train: [61][60/750]	BT 1.698 (1.437)	DT 1.573 (1.280)	loss nan (nan)	prob nan (nan)	GS 34.906 (34.906)	mem 39.243
Train: [61][65/750]	BT 0.129 (1.425)	DT 0.010 (1.272)	loss nan (nan)	prob nan (nan)	GS 28.672 (28.672)	mem 39.282
Train: [61][70/750]	BT 4.707 (1.400)	DT 4.478 (1.245)	loss nan (nan)	prob nan (nan)	GS 34.203 (34.203)	mem 39.243
Train: [61][75/750]	BT 0.127 (1.439)	DT 0.001 (1.284)	loss nan (nan)	prob nan (nan)	GS 28.438 (28.438)	mem 39.190
Train: [61][80/750]	BT 0.123 (1.357)	DT 0.008 (1.204)	loss nan (nan)	prob nan (nan)	GS 33.453 (33.453)	mem 39.192
Train: [61][85/750]	BT 0.111 (1.327)	DT 0.003 (1.175)	loss nan (nan)	prob nan (nan)	GS 26.562 (26.562)	mem 39.220
Train: [61][90/750]	BT 0.086 (1.350)	DT 0.001 (1.201)	loss nan (nan)	prob nan (nan)	GS 30.891 (30.891)	mem 39.266
Train: [61][95/750]	BT 0.230 (1.288)	DT 0.002 (1.138)	loss nan (nan)	prob nan (nan)	GS 28.703 (28.703)	mem 39.283
Train: [61][100/750]	BT 0.074 (1.341)	DT 0.001 (1.194)	loss nan (nan)	prob nan (nan)	GS 37.125 (37.125)	mem 39.185
Train: [61][105/750]	BT 0.124 (1.284)	DT 0.003 (1.138)	loss nan (nan)	prob nan (nan)	GS 31.281 (31.281)	mem 39.215
Train: [61][110/750]	BT 6.450 (1.341)	DT 6.334 (1.195)	loss nan (nan)	prob nan (nan)	GS 36.562 (36.562)	mem 39.392
Train: [61][115/750]	BT 0.093 (1.288)	DT 0.001 (1.143)	loss nan (nan)	prob nan (nan)	GS 28.266 (28.266)	mem 39.731
Train: [61][120/750]	BT 4.036 (1.281)	DT 3.879 (1.136)	loss nan (nan)	prob nan (nan)	GS 31.719 (31.719)	mem 39.559
Train: [61][125/750]	BT 0.124 (1.279)	DT 0.007 (1.134)	loss nan (nan)	prob nan (nan)	GS 31.469 (31.469)	mem 39.497
Train: [61][130/750]	BT 0.299 (1.237)	DT 0.191 (1.092)	loss nan (nan)	prob nan (nan)	GS 33.984 (33.984)	mem 39.542
Train: [61][135/750]	BT 0.109 (1.285)	DT 0.005 (1.141)	loss nan (nan)	prob nan (nan)	GS 32.984 (32.984)	mem 39.425
Train: [61][140/750]	BT 0.128 (1.244)	DT 0.005 (1.101)	loss nan (nan)	prob nan (nan)	GS 32.922 (32.922)	mem 39.479
Train: [61][145/750]	BT 0.176 (1.237)	DT 0.001 (1.093)	loss nan (nan)	prob nan (nan)	GS 38.875 (38.875)	mem 39.508
Train: [61][150/750]	BT 1.802 (1.253)	DT 1.704 (1.111)	loss nan (nan)	prob nan (nan)	GS 32.500 (32.500)	mem 39.616
Train: [61][155/750]	BT 0.119 (1.218)	DT 0.002 (1.075)	loss nan (nan)	prob nan (nan)	GS 28.672 (28.672)	mem 39.696
Train: [61][160/750]	BT 4.101 (1.240)	DT 3.990 (1.097)	loss nan (nan)	prob nan (nan)	GS 33.266 (33.266)	mem 39.817
Train: [61][165/750]	BT 0.110 (1.242)	DT 0.009 (1.099)	loss nan (nan)	prob nan (nan)	GS 29.125 (29.125)	mem 39.805
Train: [61][170/750]	BT 0.263 (1.209)	DT 0.171 (1.068)	loss nan (nan)	prob nan (nan)	GS 34.203 (34.203)	mem 39.792
Train: [61][175/750]	BT 0.151 (1.256)	DT 0.002 (1.114)	loss nan (nan)	prob nan (nan)	GS 33.812 (33.812)	mem 39.895
Train: [61][180/750]	BT 0.144 (1.225)	DT 0.007 (1.083)	loss nan (nan)	prob nan (nan)	GS 34.906 (34.906)	mem 39.860
Train: [61][185/750]	BT 0.210 (1.222)	DT 0.015 (1.080)	loss nan (nan)	prob nan (nan)	GS 32.656 (32.656)	mem 39.758
Train: [61][190/750]	BT 0.161 (1.235)	DT 0.015 (1.094)	loss nan (nan)	prob nan (nan)	GS 36.359 (36.359)	mem 39.849
Train: [61][195/750]	BT 0.112 (1.206)	DT 0.010 (1.066)	loss nan (nan)	prob nan (nan)	GS 29.750 (29.750)	mem 39.852
Train: [61][200/750]	BT 0.057 (1.230)	DT 0.001 (1.091)	loss nan (nan)	prob nan (nan)	GS 38.453 (38.453)	mem 39.841
Train: [61][205/750]	BT 0.092 (1.204)	DT 0.002 (1.065)	loss nan (nan)	prob nan (nan)	GS 30.969 (30.969)	mem 39.874
Train: [61][210/750]	BT 4.836 (1.251)	DT 4.719 (1.112)	loss nan (nan)	prob nan (nan)	GS 30.562 (30.562)	mem 39.786
Train: [61][215/750]	BT 0.140 (1.224)	DT 0.001 (1.086)	loss nan (nan)	prob nan (nan)	GS 29.344 (29.344)	mem 39.688
Train: [61][220/750]	BT 1.972 (1.208)	DT 1.891 (1.070)	loss nan (nan)	prob nan (nan)	GS 31.281 (31.281)	mem 39.750
Train: [61][225/750]	BT 0.074 (1.231)	DT 0.001 (1.094)	loss nan (nan)	prob nan (nan)	GS 35.359 (35.359)	mem 39.756
Train: [61][230/750]	BT 0.146 (1.208)	DT 0.003 (1.070)	loss nan (nan)	prob nan (nan)	GS 36.703 (36.703)	mem 39.798
Train: [61][235/750]	BT 0.140 (1.230)	DT 0.018 (1.093)	loss nan (nan)	prob nan (nan)	GS 28.469 (28.469)	mem 39.867
Train: [61][240/750]	BT 0.187 (1.207)	DT 0.008 (1.070)	loss nan (nan)	prob nan (nan)	GS 37.875 (37.875)	mem 39.787
Train: [61][245/750]	BT 0.119 (1.188)	DT 0.012 (1.053)	loss nan (nan)	prob nan (nan)	GS 29.297 (29.297)	mem 39.801
Train: [61][250/750]	BT 0.127 (1.214)	DT 0.017 (1.077)	loss nan (nan)	prob nan (nan)	GS 30.344 (30.344)	mem 39.741
Train: [61][255/750]	BT 0.078 (1.192)	DT 0.002 (1.056)	loss nan (nan)	prob nan (nan)	GS 26.391 (26.391)	mem 39.744
Train: [61][260/750]	BT 0.093 (1.214)	DT 0.002 (1.079)	loss nan (nan)	prob nan (nan)	GS 34.203 (34.203)	mem 39.874
Train: [61][265/750]	BT 0.164 (1.194)	DT 0.010 (1.059)	loss nan (nan)	prob nan (nan)	GS 34.766 (34.766)	mem 39.907
Train: [61][270/750]	BT 11.326 (1.215)	DT 11.196 (1.081)	loss nan (nan)	prob nan (nan)	GS 30.875 (30.875)	mem 40.053
Train: [61][275/750]	BT 0.198 (1.196)	DT 0.020 (1.061)	loss nan (nan)	prob nan (nan)	GS 31.719 (31.719)	mem 39.998
Train: [61][280/750]	BT 1.083 (1.179)	DT 0.992 (1.046)	loss nan (nan)	prob nan (nan)	GS 35.859 (35.859)	mem 39.953
Train: [61][285/750]	BT 0.127 (1.201)	DT 0.001 (1.068)	loss nan (nan)	prob nan (nan)	GS 28.578 (28.578)	mem 40.056
Train: [61][290/750]	BT 0.094 (1.183)	DT 0.002 (1.050)	loss nan (nan)	prob nan (nan)	GS 37.078 (37.078)	mem 39.997
Train: [61][295/750]	BT 0.069 (1.214)	DT 0.002 (1.081)	loss nan (nan)	prob nan (nan)	GS 34.672 (34.672)	mem 40.001
Train: [61][300/750]	BT 0.067 (1.195)	DT 0.001 (1.063)	loss nan (nan)	prob nan (nan)	GS 32.047 (32.047)	mem 39.929
Train: [61][305/750]	BT 0.187 (1.181)	DT 0.017 (1.050)	loss nan (nan)	prob nan (nan)	GS 30.391 (30.391)	mem 39.985
Train: [61][310/750]	BT 0.098 (1.196)	DT 0.002 (1.064)	loss nan (nan)	prob nan (nan)	GS 34.469 (34.469)	mem 39.974
Train: [61][315/750]	BT 0.097 (1.179)	DT 0.002 (1.047)	loss nan (nan)	prob nan (nan)	GS 30.844 (30.844)	mem 40.083
Train: [61][320/750]	BT 0.099 (1.201)	DT 0.001 (1.070)	loss nan (nan)	prob nan (nan)	GS 35.047 (35.047)	mem 39.831
Train: [61][325/750]	BT 0.112 (1.185)	DT 0.007 (1.054)	loss nan (nan)	prob nan (nan)	GS 29.047 (29.047)	mem 39.833
Train: [61][330/750]	BT 13.559 (1.209)	DT 13.466 (1.078)	loss nan (nan)	prob nan (nan)	GS 36.578 (36.578)	mem 40.011
Train: [61][335/750]	BT 0.082 (1.193)	DT 0.001 (1.062)	loss nan (nan)	prob nan (nan)	GS 34.234 (34.234)	mem 39.920
Train: [61][340/750]	BT 0.183 (1.178)	DT 0.013 (1.047)	loss nan (nan)	prob nan (nan)	GS 34.094 (34.094)	mem 40.024
Train: [61][345/750]	BT 0.086 (1.192)	DT 0.003 (1.061)	loss nan (nan)	prob nan (nan)	GS 29.969 (29.969)	mem 40.041
Train: [61][350/750]	BT 0.082 (1.176)	DT 0.001 (1.046)	loss nan (nan)	prob nan (nan)	GS 31.781 (31.781)	mem 40.060
Train: [61][355/750]	BT 0.083 (1.196)	DT 0.001 (1.066)	loss nan (nan)	prob nan (nan)	GS 42.531 (42.531)	mem 40.065
Train: [61][360/750]	BT 0.166 (1.181)	DT 0.002 (1.052)	loss nan (nan)	prob nan (nan)	GS 31.141 (31.141)	mem 40.105
Train: [61][365/750]	BT 0.099 (1.167)	DT 0.002 (1.037)	loss nan (nan)	prob nan (nan)	GS 28.797 (28.797)	mem 40.155
Train: [61][370/750]	BT 0.115 (1.187)	DT 0.001 (1.058)	loss nan (nan)	prob nan (nan)	GS 34.688 (34.688)	mem 40.036
Train: [61][375/750]	BT 0.123 (1.173)	DT 0.010 (1.044)	loss nan (nan)	prob nan (nan)	GS 30.266 (30.266)	mem 39.941
Train: [61][380/750]	BT 0.168 (1.186)	DT 0.001 (1.057)	loss nan (nan)	prob nan (nan)	GS 34.359 (34.359)	mem 40.104
Train: [61][385/750]	BT 0.125 (1.172)	DT 0.001 (1.043)	loss nan (nan)	prob nan (nan)	GS 36.812 (36.812)	mem 40.032
Train: [61][390/750]	BT 9.528 (1.183)	DT 9.418 (1.054)	loss nan (nan)	prob nan (nan)	GS 36.250 (36.250)	mem 40.008
Train: [61][395/750]	BT 0.106 (1.170)	DT 0.002 (1.041)	loss nan (nan)	prob nan (nan)	GS 28.453 (28.453)	mem 40.122
Train: [61][400/750]	BT 0.138 (1.157)	DT 0.017 (1.028)	loss nan (nan)	prob nan (nan)	GS 34.000 (34.000)	mem 40.049
Train: [61][405/750]	BT 0.152 (1.172)	DT 0.001 (1.042)	loss nan (nan)	prob nan (nan)	GS 31.703 (31.703)	mem 40.102
Train: [61][410/750]	BT 0.105 (1.159)	DT 0.001 (1.030)	loss nan (nan)	prob nan (nan)	GS 34.812 (34.812)	mem 39.988
Train: [61][415/750]	BT 0.066 (1.174)	DT 0.001 (1.045)	loss nan (nan)	prob nan (nan)	GS 30.547 (30.547)	mem 40.092
Train: [61][420/750]	BT 0.141 (1.161)	DT 0.001 (1.033)	loss nan (nan)	prob nan (nan)	GS 29.797 (29.797)	mem 40.047
Train: [61][425/750]	BT 0.089 (1.172)	DT 0.002 (1.044)	loss nan (nan)	prob nan (nan)	GS 30.312 (30.312)	mem 40.091
Train: [61][430/750]	BT 0.113 (1.164)	DT 0.001 (1.036)	loss nan (nan)	prob nan (nan)	GS 34.906 (34.906)	mem 40.006
Train: [61][435/750]	BT 0.111 (1.152)	DT 0.008 (1.024)	loss nan (nan)	prob nan (nan)	GS 36.016 (36.016)	mem 40.012
Train: [61][440/750]	BT 0.144 (1.168)	DT 0.011 (1.039)	loss nan (nan)	prob nan (nan)	GS 33.672 (33.672)	mem 40.042
Train: [61][445/750]	BT 0.235 (1.156)	DT 0.002 (1.028)	loss nan (nan)	prob nan (nan)	GS 33.859 (33.859)	mem 40.038
Train: [61][450/750]	BT 2.478 (1.172)	DT 2.294 (1.044)	loss nan (nan)	prob nan (nan)	GS 34.156 (34.156)	mem 39.935
Train: [61][455/750]	BT 0.101 (1.161)	DT 0.002 (1.032)	loss nan (nan)	prob nan (nan)	GS 27.828 (27.828)	mem 39.878
Train: [61][460/750]	BT 8.135 (1.168)	DT 8.005 (1.039)	loss nan (nan)	prob nan (nan)	GS 34.391 (34.391)	mem 39.926
Train: [61][465/750]	BT 0.100 (1.161)	DT 0.002 (1.032)	loss nan (nan)	prob nan (nan)	GS 29.156 (29.156)	mem 39.945
Train: [61][470/750]	BT 0.072 (1.150)	DT 0.001 (1.021)	loss nan (nan)	prob nan (nan)	GS 31.047 (31.047)	mem 39.998
Train: [61][475/750]	BT 0.098 (1.168)	DT 0.001 (1.039)	loss nan (nan)	prob nan (nan)	GS 33.391 (33.391)	mem 39.955
Train: [61][480/750]	BT 0.127 (1.157)	DT 0.002 (1.028)	loss nan (nan)	prob nan (nan)	GS 31.328 (31.328)	mem 40.000
Train: [61][485/750]	BT 0.255 (1.165)	DT 0.027 (1.036)	loss nan (nan)	prob nan (nan)	GS 29.906 (29.906)	mem 40.019
Train: [61][490/750]	BT 0.074 (1.154)	DT 0.001 (1.025)	loss nan (nan)	prob nan (nan)	GS 37.516 (37.516)	mem 40.056
Train: [61][495/750]	BT 0.176 (1.144)	DT 0.006 (1.015)	loss nan (nan)	prob nan (nan)	GS 30.750 (30.750)	mem 40.204
Train: [61][500/750]	BT 0.128 (1.162)	DT 0.003 (1.034)	loss nan (nan)	prob nan (nan)	GS 32.688 (32.688)	mem 39.952
Train: [61][505/750]	BT 0.135 (1.153)	DT 0.020 (1.023)	loss nan (nan)	prob nan (nan)	GS 30.344 (30.344)	mem 39.955
Train: [61][510/750]	BT 0.094 (1.164)	DT 0.001 (1.034)	loss nan (nan)	prob nan (nan)	GS 30.719 (30.719)	mem 39.999
Train: [61][515/750]	BT 0.200 (1.154)	DT 0.002 (1.024)	loss nan (nan)	prob nan (nan)	GS 47.031 (47.031)	mem 40.000
Train: [61][520/750]	BT 12.749 (1.169)	DT 12.601 (1.039)	loss nan (nan)	prob nan (nan)	GS 33.062 (33.062)	mem 39.949
Train: [61][525/750]	BT 0.081 (1.159)	DT 0.001 (1.029)	loss nan (nan)	prob nan (nan)	GS 30.297 (30.297)	mem 39.951
Train: [61][530/750]	BT 0.171 (1.149)	DT 0.002 (1.019)	loss nan (nan)	prob nan (nan)	GS 36.750 (36.750)	mem 40.057
Train: [61][535/750]	BT 0.103 (1.163)	DT 0.002 (1.033)	loss nan (nan)	prob nan (nan)	GS 34.969 (34.969)	mem 40.035
Train: [61][540/750]	BT 0.137 (1.153)	DT 0.005 (1.024)	loss nan (nan)	prob nan (nan)	GS 36.844 (36.844)	mem 39.982
Train: [61][545/750]	BT 0.123 (1.161)	DT 0.001 (1.031)	loss nan (nan)	prob nan (nan)	GS 30.703 (30.703)	mem 40.173
Train: [61][550/750]	BT 0.099 (1.162)	DT 0.001 (1.032)	loss nan (nan)	prob nan (nan)	GS 32.719 (32.719)	mem 40.015
Train: [61][555/750]	BT 0.164 (1.152)	DT 0.002 (1.023)	loss nan (nan)	prob nan (nan)	GS 32.297 (32.297)	mem 39.946
Train: [61][560/750]	BT 0.074 (1.168)	DT 0.002 (1.039)	loss nan (nan)	prob nan (nan)	GS 32.922 (32.922)	mem 39.824
Train: [61][565/750]	BT 0.143 (1.159)	DT 0.001 (1.029)	loss nan (nan)	prob nan (nan)	GS 31.641 (31.641)	mem 39.849
Train: [61][570/750]	BT 6.728 (1.170)	DT 6.583 (1.040)	loss nan (nan)	prob nan (nan)	GS 35.016 (35.016)	mem 39.924
Train: [61][575/750]	BT 0.197 (1.161)	DT 0.002 (1.031)	loss nan (nan)	prob nan (nan)	GS 27.562 (27.562)	mem 39.964
Train: [61][580/750]	BT 7.668 (1.166)	DT 7.527 (1.036)	loss nan (nan)	prob nan (nan)	GS 30.516 (30.516)	mem 40.001
Train: [61][585/750]	BT 0.075 (1.162)	DT 0.001 (1.032)	loss nan (nan)	prob nan (nan)	GS 30.188 (30.188)	mem 40.028
Train: [61][590/750]	BT 0.252 (1.154)	DT 0.002 (1.024)	loss nan (nan)	prob nan (nan)	GS 33.391 (33.391)	mem 39.952
Train: [61][595/750]	BT 0.177 (1.162)	DT 0.005 (1.031)	loss nan (nan)	prob nan (nan)	GS 29.312 (29.312)	mem 40.003
Train: [61][600/750]	BT 0.080 (1.153)	DT 0.001 (1.023)	loss nan (nan)	prob nan (nan)	GS 31.766 (31.766)	mem 40.122
Train: [61][605/750]	BT 0.143 (1.164)	DT 0.003 (1.034)	loss nan (nan)	prob nan (nan)	GS 33.797 (33.797)	mem 40.094
Train: [61][610/750]	BT 0.076 (1.156)	DT 0.001 (1.026)	loss nan (nan)	prob nan (nan)	GS 35.109 (35.109)	mem 40.016
Train: [61][615/750]	BT 0.093 (1.147)	DT 0.001 (1.017)	loss nan (nan)	prob nan (nan)	GS 28.984 (28.984)	mem 40.017
Train: [61][620/750]	BT 0.131 (1.157)	DT 0.003 (1.027)	loss nan (nan)	prob nan (nan)	GS 33.734 (33.734)	mem 40.047
Train: [61][625/750]	BT 0.132 (1.149)	DT 0.001 (1.019)	loss nan (nan)	prob nan (nan)	GS 33.906 (33.906)	mem 39.987
Train: [61][630/750]	BT 0.086 (1.159)	DT 0.001 (1.029)	loss nan (nan)	prob nan (nan)	GS 34.625 (34.625)	mem 39.960
Train: [61][635/750]	BT 0.081 (1.150)	DT 0.001 (1.021)	loss nan (nan)	prob nan (nan)	GS 28.906 (28.906)	mem 39.960
Train: [61][640/750]	BT 14.171 (1.165)	DT 14.007 (1.035)	loss nan (nan)	prob nan (nan)	GS 34.875 (34.875)	mem 40.141
Train: [61][645/750]	BT 0.083 (1.156)	DT 0.003 (1.027)	loss nan (nan)	prob nan (nan)	GS 30.844 (30.844)	mem 40.085
Train: [61][650/750]	BT 0.087 (1.148)	DT 0.003 (1.019)	loss nan (nan)	prob nan (nan)	GS 36.672 (36.672)	mem 40.087
Train: [61][655/750]	BT 0.136 (1.158)	DT 0.002 (1.028)	loss nan (nan)	prob nan (nan)	GS 29.297 (29.297)	mem 40.085
Train: [61][660/750]	BT 0.078 (1.150)	DT 0.001 (1.020)	loss nan (nan)	prob nan (nan)	GS 33.953 (33.953)	mem 40.079
Train: [61][665/750]	BT 0.089 (1.159)	DT 0.002 (1.030)	loss nan (nan)	prob nan (nan)	GS 30.031 (30.031)	mem 40.045
Train: [61][670/750]	BT 0.071 (1.151)	DT 0.001 (1.022)	loss nan (nan)	prob nan (nan)	GS 33.703 (33.703)	mem 40.059
Train: [61][675/750]	BT 0.142 (1.143)	DT 0.008 (1.014)	loss nan (nan)	prob nan (nan)	GS 25.406 (25.406)	mem 40.144
Train: [61][680/750]	BT 0.069 (1.151)	DT 0.001 (1.022)	loss nan (nan)	prob nan (nan)	GS 30.859 (30.859)	mem 40.114
Train: [61][685/750]	BT 0.178 (1.144)	DT 0.001 (1.015)	loss nan (nan)	prob nan (nan)	GS 34.938 (34.938)	mem 40.116
Train: [61][690/750]	BT 0.053 (1.155)	DT 0.001 (1.026)	loss nan (nan)	prob nan (nan)	GS 30.500 (30.500)	mem 40.065
Train: [61][695/750]	BT 0.118 (1.147)	DT 0.001 (1.019)	loss nan (nan)	prob nan (nan)	GS 28.125 (28.125)	mem 40.090
Train: [61][700/750]	BT 12.606 (1.157)	DT 12.369 (1.029)	loss nan (nan)	prob nan (nan)	GS 34.391 (34.391)	mem 40.151
Train: [61][705/750]	BT 0.087 (1.150)	DT 0.002 (1.022)	loss nan (nan)	prob nan (nan)	GS 29.719 (29.719)	mem 40.085
arpack error, retry= 0
Train: [61][710/750]	BT 0.152 (1.143)	DT 0.013 (1.015)	loss nan (nan)	prob nan (nan)	GS 34.297 (34.297)	mem 40.062
Train: [61][715/750]	BT 0.132 (1.150)	DT 0.002 (1.022)	loss nan (nan)	prob nan (nan)	GS 31.609 (31.609)	mem 40.094
Train: [61][720/750]	BT 0.120 (1.142)	DT 0.001 (1.014)	loss nan (nan)	prob nan (nan)	GS 36.266 (36.266)	mem 40.143
Train: [61][725/750]	BT 0.123 (1.149)	DT 0.001 (1.021)	loss nan (nan)	prob nan (nan)	GS 28.438 (28.438)	mem 39.927
Train: [61][730/750]	BT 0.099 (1.142)	DT 0.002 (1.014)	loss nan (nan)	prob nan (nan)	GS 32.000 (32.000)	mem 39.954
Train: [61][735/750]	BT 0.163 (1.135)	DT 0.001 (1.007)	loss nan (nan)	prob nan (nan)	GS 33.016 (33.016)	mem 39.989
Train: [61][740/750]	BT 0.075 (1.139)	DT 0.001 (1.011)	loss nan (nan)	prob nan (nan)	GS 31.953 (31.953)	mem 10.704
Train: [61][745/750]	BT 0.073 (1.132)	DT 0.001 (1.005)	loss nan (nan)	prob nan (nan)	GS 25.219 (25.219)	mem 11.012
Train: [61][750/750]	BT 0.056 (1.127)	DT 0.001 (1.001)	loss nan (nan)	prob nan (nan)	GS 34.062 (34.062)	mem 10.681
Train: [61][755/750]	BT 0.080 (1.121)	DT 0.001 (0.994)	loss nan (nan)	prob nan (nan)	GS 37.688 (37.688)	mem 10.632
epoch 61, total time 846.49
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [62][1/750]	BT 20.846 (20.846)	DT 20.695 (20.695)	loss nan (nan)	prob nan (nan)	GS 33.406 (33.406)	mem 38.821
Train: [62][5/750]	BT 0.154 (5.000)	DT 0.002 (4.880)	loss nan (nan)	prob nan (nan)	GS 28.891 (28.891)	mem 38.796
Train: [62][10/750]	BT 2.527 (2.819)	DT 2.343 (2.678)	loss nan (nan)	prob nan (nan)	GS 35.578 (35.578)	mem 38.828
Train: [62][15/750]	BT 0.234 (2.442)	DT 0.005 (2.295)	loss nan (nan)	prob nan (nan)	GS 27.891 (27.891)	mem 38.900
Train: [62][20/750]	BT 0.179 (1.893)	DT 0.004 (1.753)	loss nan (nan)	prob nan (nan)	GS 35.422 (35.422)	mem 39.005
Train: [62][25/750]	BT 0.752 (1.629)	DT 0.634 (1.486)	loss nan (nan)	prob nan (nan)	GS 33.891 (33.891)	mem 38.991
Train: [62][30/750]	BT 0.143 (1.841)	DT 0.001 (1.699)	loss nan (nan)	prob nan (nan)	GS 30.031 (30.031)	mem 39.118
Train: [62][35/750]	BT 0.071 (1.603)	DT 0.001 (1.457)	loss nan (nan)	prob nan (nan)	GS 29.875 (29.875)	mem 39.033
Train: [62][40/750]	BT 0.090 (1.647)	DT 0.001 (1.504)	loss nan (nan)	prob nan (nan)	GS 28.109 (28.109)	mem 39.104
Train: [62][45/750]	BT 0.107 (1.480)	DT 0.002 (1.337)	loss nan (nan)	prob nan (nan)	GS 30.547 (30.547)	mem 39.203
Train: [62][50/750]	BT 9.557 (1.594)	DT 9.376 (1.451)	loss nan (nan)	prob nan (nan)	GS 36.281 (36.281)	mem 39.785
Train: [62][55/750]	BT 0.136 (1.460)	DT 0.008 (1.320)	loss nan (nan)	prob nan (nan)	GS 28.516 (28.516)	mem 39.652
Train: [62][60/750]	BT 0.086 (1.397)	DT 0.002 (1.259)	loss nan (nan)	prob nan (nan)	GS 35.172 (35.172)	mem 39.705
Train: [62][65/750]	BT 0.154 (1.447)	DT 0.003 (1.309)	loss nan (nan)	prob nan (nan)	GS 30.469 (30.469)	mem 39.707
Train: [62][70/750]	BT 0.914 (1.364)	DT 0.836 (1.228)	loss nan (nan)	prob nan (nan)	GS 34.625 (34.625)	mem 39.694
Train: [62][75/750]	BT 0.130 (1.429)	DT 0.001 (1.291)	loss nan (nan)	prob nan (nan)	GS 29.406 (29.406)	mem 39.658
Train: [62][80/750]	BT 0.137 (1.348)	DT 0.002 (1.210)	loss nan (nan)	prob nan (nan)	GS 36.016 (36.016)	mem 39.696
Train: [62][85/750]	BT 0.103 (1.277)	DT 0.002 (1.139)	loss nan (nan)	prob nan (nan)	GS 30.906 (30.906)	mem 39.699
Train: [62][90/750]	BT 0.090 (1.368)	DT 0.002 (1.232)	loss nan (nan)	prob nan (nan)	GS 33.000 (33.000)	mem 39.741
Train: [62][95/750]	BT 0.123 (1.302)	DT 0.001 (1.167)	loss nan (nan)	prob nan (nan)	GS 31.469 (31.469)	mem 39.773
Train: [62][100/750]	BT 0.089 (1.351)	DT 0.001 (1.215)	loss nan (nan)	prob nan (nan)	GS 34.250 (34.250)	mem 39.725
Train: [62][105/750]	BT 0.232 (1.295)	DT 0.006 (1.158)	loss nan (nan)	prob nan (nan)	GS 32.672 (32.672)	mem 39.780
Train: [62][110/750]	BT 12.050 (1.351)	DT 11.955 (1.214)	loss nan (nan)	prob nan (nan)	GS 35.938 (35.938)	mem 39.694
Train: [62][115/750]	BT 0.140 (1.298)	DT 0.001 (1.162)	loss nan (nan)	prob nan (nan)	GS 32.078 (32.078)	mem 39.773
Train: [62][120/750]	BT 0.184 (1.251)	DT 0.001 (1.114)	loss nan (nan)	prob nan (nan)	GS 33.797 (33.797)	mem 39.700
Train: [62][125/750]	BT 0.207 (1.326)	DT 0.017 (1.189)	loss nan (nan)	prob nan (nan)	GS 29.172 (29.172)	mem 39.742
Train: [62][130/750]	BT 0.093 (1.279)	DT 0.002 (1.143)	loss nan (nan)	prob nan (nan)	GS 33.141 (33.141)	mem 39.782
Train: [62][135/750]	BT 0.167 (1.308)	DT 0.010 (1.173)	loss nan (nan)	prob nan (nan)	GS 27.812 (27.812)	mem 39.819
Train: [62][140/750]	BT 0.137 (1.265)	DT 0.001 (1.131)	loss nan (nan)	prob nan (nan)	GS 37.344 (37.344)	mem 39.828
Train: [62][145/750]	BT 0.129 (1.226)	DT 0.006 (1.092)	loss nan (nan)	prob nan (nan)	GS 35.781 (35.781)	mem 39.843
Train: [62][150/750]	BT 0.090 (1.264)	DT 0.002 (1.131)	loss nan (nan)	prob nan (nan)	GS 31.891 (31.891)	mem 39.808
Train: [62][155/750]	BT 0.112 (1.226)	DT 0.004 (1.095)	loss nan (nan)	prob nan (nan)	GS 28.234 (28.234)	mem 39.811
Train: [62][160/750]	BT 0.067 (1.265)	DT 0.001 (1.135)	loss nan (nan)	prob nan (nan)	GS 31.094 (31.094)	mem 39.968
Train: [62][165/750]	BT 0.122 (1.232)	DT 0.006 (1.100)	loss nan (nan)	prob nan (nan)	GS 30.844 (30.844)	mem 39.872
Train: [62][170/750]	BT 12.377 (1.272)	DT 12.288 (1.140)	loss nan (nan)	prob nan (nan)	GS 30.297 (30.297)	mem 39.975
Train: [62][175/750]	BT 0.136 (1.239)	DT 0.012 (1.108)	loss nan (nan)	prob nan (nan)	GS 26.938 (26.938)	mem 39.910
Train: [62][180/750]	BT 0.234 (1.209)	DT 0.016 (1.077)	loss nan (nan)	prob nan (nan)	GS 33.344 (33.344)	mem 39.946
Train: [62][185/750]	BT 0.087 (1.237)	DT 0.005 (1.105)	loss nan (nan)	prob nan (nan)	GS 31.094 (31.094)	mem 39.976
Train: [62][190/750]	BT 0.112 (1.209)	DT 0.008 (1.077)	loss nan (nan)	prob nan (nan)	GS 35.781 (35.781)	mem 40.298
Train: [62][195/750]	BT 0.076 (1.244)	DT 0.001 (1.112)	loss nan (nan)	prob nan (nan)	GS 30.172 (30.172)	mem 40.007
Train: [62][200/750]	BT 0.163 (1.217)	DT 0.026 (1.085)	loss nan (nan)	prob nan (nan)	GS 34.000 (34.000)	mem 39.984
Train: [62][205/750]	BT 0.096 (1.190)	DT 0.002 (1.058)	loss nan (nan)	prob nan (nan)	GS 32.266 (32.266)	mem 40.089
Train: [62][210/750]	BT 0.078 (1.223)	DT 0.002 (1.093)	loss nan (nan)	prob nan (nan)	GS 31.500 (31.500)	mem 40.163
Train: [62][215/750]	BT 0.309 (1.200)	DT 0.001 (1.069)	loss nan (nan)	prob nan (nan)	GS 31.859 (31.859)	mem 40.043
Train: [62][220/750]	BT 0.088 (1.216)	DT 0.002 (1.084)	loss nan (nan)	prob nan (nan)	GS 33.094 (33.094)	mem 40.095
Train: [62][225/750]	BT 0.136 (1.192)	DT 0.002 (1.060)	loss nan (nan)	prob nan (nan)	GS 31.328 (31.328)	mem 40.061
Train: [62][230/750]	BT 11.984 (1.221)	DT 11.879 (1.089)	loss nan (nan)	prob nan (nan)	GS 30.969 (30.969)	mem 40.051
Train: [62][235/750]	BT 0.106 (1.197)	DT 0.002 (1.066)	loss nan (nan)	prob nan (nan)	GS 29.219 (29.219)	mem 40.055
Train: [62][240/750]	BT 0.126 (1.175)	DT 0.001 (1.044)	loss nan (nan)	prob nan (nan)	GS 30.344 (30.344)	mem 40.201
Train: [62][245/750]	BT 0.085 (1.193)	DT 0.001 (1.062)	loss nan (nan)	prob nan (nan)	GS 33.719 (33.719)	mem 40.044
Train: [62][250/750]	BT 0.209 (1.173)	DT 0.018 (1.041)	loss nan (nan)	prob nan (nan)	GS 36.109 (36.109)	mem 40.039
Train: [62][255/750]	BT 0.132 (1.205)	DT 0.004 (1.073)	loss nan (nan)	prob nan (nan)	GS 26.547 (26.547)	mem 39.939
Train: [62][260/750]	BT 0.121 (1.184)	DT 0.002 (1.052)	loss nan (nan)	prob nan (nan)	GS 31.406 (31.406)	mem 39.940
Train: [62][265/750]	BT 0.194 (1.164)	DT 0.005 (1.033)	loss nan (nan)	prob nan (nan)	GS 32.703 (32.703)	mem 40.065
Train: [62][270/750]	BT 0.089 (1.196)	DT 0.001 (1.065)	loss nan (nan)	prob nan (nan)	GS 33.594 (33.594)	mem 39.928
Train: [62][275/750]	BT 0.079 (1.176)	DT 0.006 (1.046)	loss nan (nan)	prob nan (nan)	GS 29.484 (29.484)	mem 39.938
Train: [62][280/750]	BT 0.154 (1.185)	DT 0.005 (1.054)	loss nan (nan)	prob nan (nan)	GS 31.422 (31.422)	mem 40.070
Train: [62][285/750]	BT 0.125 (1.169)	DT 0.015 (1.039)	loss nan (nan)	prob nan (nan)	GS 32.172 (32.172)	mem 40.002
Train: [62][290/750]	BT 8.720 (1.181)	DT 8.606 (1.051)	loss nan (nan)	prob nan (nan)	GS 33.391 (33.391)	mem 40.000
Train: [62][295/750]	BT 0.119 (1.164)	DT 0.002 (1.033)	loss nan (nan)	prob nan (nan)	GS 30.438 (30.438)	mem 40.002
Train: [62][300/750]	BT 0.084 (1.156)	DT 0.001 (1.026)	loss nan (nan)	prob nan (nan)	GS 35.859 (35.859)	mem 40.009
Train: [62][305/750]	BT 0.110 (1.171)	DT 0.001 (1.042)	loss nan (nan)	prob nan (nan)	GS 27.891 (27.891)	mem 40.007
Train: [62][310/750]	BT 0.079 (1.155)	DT 0.002 (1.025)	loss nan (nan)	prob nan (nan)	GS 34.875 (34.875)	mem 39.999
Train: [62][315/750]	BT 0.096 (1.168)	DT 0.001 (1.039)	loss nan (nan)	prob nan (nan)	GS 32.312 (32.312)	mem 40.011
Train: [62][320/750]	BT 3.949 (1.165)	DT 3.818 (1.035)	loss nan (nan)	prob nan (nan)	GS 33.797 (33.797)	mem 39.971
Train: [62][325/750]	BT 0.236 (1.149)	DT 0.006 (1.019)	loss nan (nan)	prob nan (nan)	GS 31.266 (31.266)	mem 40.046
Train: [62][330/750]	BT 0.152 (1.153)	DT 0.002 (1.024)	loss nan (nan)	prob nan (nan)	GS 32.922 (32.922)	mem 39.965
Train: [62][335/750]	BT 0.093 (1.148)	DT 0.014 (1.019)	loss nan (nan)	prob nan (nan)	GS 33.500 (33.500)	mem 39.995
Train: [62][340/750]	BT 0.098 (1.158)	DT 0.002 (1.028)	loss nan (nan)	prob nan (nan)	GS 32.703 (32.703)	mem 39.912
Train: [62][345/750]	BT 0.309 (1.156)	DT 0.020 (1.026)	loss nan (nan)	prob nan (nan)	GS 30.984 (30.984)	mem 40.000
Train: [62][350/750]	BT 6.311 (1.158)	DT 6.085 (1.029)	loss nan (nan)	prob nan (nan)	GS 27.281 (27.281)	mem 39.871
Train: [62][355/750]	BT 0.189 (1.144)	DT 0.002 (1.014)	loss nan (nan)	prob nan (nan)	GS 27.469 (27.469)	mem 39.872
Train: [62][360/750]	BT 0.170 (1.147)	DT 0.013 (1.017)	loss nan (nan)	prob nan (nan)	GS 33.516 (33.516)	mem 39.916
Train: [62][365/750]	BT 0.085 (1.151)	DT 0.002 (1.021)	loss nan (nan)	prob nan (nan)	GS 30.828 (30.828)	mem 39.944
Train: [62][370/750]	BT 0.161 (1.155)	DT 0.002 (1.025)	loss nan (nan)	prob nan (nan)	GS 35.922 (35.922)	mem 40.012
Train: [62][375/750]	BT 0.113 (1.153)	DT 0.002 (1.023)	loss nan (nan)	prob nan (nan)	GS 35.953 (35.953)	mem 39.866
Train: [62][380/750]	BT 6.220 (1.156)	DT 6.134 (1.026)	loss nan (nan)	prob nan (nan)	GS 35.344 (35.344)	mem 39.860
Train: [62][385/750]	BT 0.078 (1.143)	DT 0.001 (1.013)	loss nan (nan)	prob nan (nan)	GS 34.469 (34.469)	mem 39.862
Train: [62][390/750]	BT 0.094 (1.144)	DT 0.002 (1.014)	loss nan (nan)	prob nan (nan)	GS 34.781 (34.781)	mem 39.812
Train: [62][395/750]	BT 0.128 (1.142)	DT 0.008 (1.012)	loss nan (nan)	prob nan (nan)	GS 32.875 (32.875)	mem 39.858
Train: [62][400/750]	BT 0.069 (1.145)	DT 0.001 (1.015)	loss nan (nan)	prob nan (nan)	GS 35.469 (35.469)	mem 39.935
Train: [62][405/750]	BT 0.106 (1.144)	DT 0.002 (1.014)	loss nan (nan)	prob nan (nan)	GS 28.734 (28.734)	mem 39.920
Train: [62][410/750]	BT 6.240 (1.146)	DT 6.147 (1.016)	loss nan (nan)	prob nan (nan)	GS 32.312 (32.312)	mem 39.961
Train: [62][415/750]	BT 0.108 (1.134)	DT 0.002 (1.005)	loss nan (nan)	prob nan (nan)	GS 28.641 (28.641)	mem 39.830
Train: [62][420/750]	BT 0.090 (1.136)	DT 0.002 (1.008)	loss nan (nan)	prob nan (nan)	GS 32.328 (32.328)	mem 39.940
Train: [62][425/750]	BT 0.198 (1.129)	DT 0.002 (1.000)	loss nan (nan)	prob nan (nan)	GS 31.344 (31.344)	mem 39.944
Train: [62][430/750]	BT 0.082 (1.141)	DT 0.002 (1.011)	loss nan (nan)	prob nan (nan)	GS 34.703 (34.703)	mem 40.164
Train: [62][435/750]	BT 0.093 (1.132)	DT 0.002 (1.003)	loss nan (nan)	prob nan (nan)	GS 28.891 (28.891)	mem 40.017
Train: [62][440/750]	BT 5.503 (1.138)	DT 5.414 (1.009)	loss nan (nan)	prob nan (nan)	GS 30.688 (30.688)	mem 40.085
Train: [62][445/750]	BT 0.378 (1.127)	DT 0.025 (0.998)	loss nan (nan)	prob nan (nan)	GS 27.344 (27.344)	mem 40.482
Train: [62][450/750]	BT 0.186 (1.135)	DT 0.009 (1.006)	loss nan (nan)	prob nan (nan)	GS 31.656 (31.656)	mem 40.121
Train: [62][455/750]	BT 0.117 (1.126)	DT 0.004 (0.997)	loss nan (nan)	prob nan (nan)	GS 30.125 (30.125)	mem 40.100
Train: [62][460/750]	BT 4.235 (1.143)	DT 4.125 (1.014)	loss nan (nan)	prob nan (nan)	GS 34.109 (34.109)	mem 39.913
Train: [62][465/750]	BT 0.104 (1.132)	DT 0.002 (1.003)	loss nan (nan)	prob nan (nan)	GS 29.703 (29.703)	mem 39.917
Train: [62][470/750]	BT 6.717 (1.136)	DT 6.589 (1.006)	loss nan (nan)	prob nan (nan)	GS 31.828 (31.828)	mem 39.860
Train: [62][475/750]	BT 0.101 (1.134)	DT 0.001 (1.005)	loss nan (nan)	prob nan (nan)	GS 27.781 (27.781)	mem 39.967
Train: [62][480/750]	BT 0.213 (1.124)	DT 0.001 (0.995)	loss nan (nan)	prob nan (nan)	GS 33.875 (33.875)	mem 40.037
Train: [62][485/750]	BT 0.096 (1.138)	DT 0.002 (1.009)	loss nan (nan)	prob nan (nan)	GS 25.656 (25.656)	mem 40.246
Train: [62][490/750]	BT 0.184 (1.128)	DT 0.002 (0.999)	loss nan (nan)	prob nan (nan)	GS 34.781 (34.781)	mem 40.452
Train: [62][495/750]	BT 0.235 (1.131)	DT 0.011 (1.002)	loss nan (nan)	prob nan (nan)	GS 30.641 (30.641)	mem 40.036
Train: [62][500/750]	BT 0.130 (1.130)	DT 0.006 (1.001)	loss nan (nan)	prob nan (nan)	GS 29.594 (29.594)	mem 40.021
Train: [62][505/750]	BT 0.080 (1.120)	DT 0.002 (0.991)	loss nan (nan)	prob nan (nan)	GS 30.797 (30.797)	mem 40.150
Train: [62][510/750]	BT 0.141 (1.131)	DT 0.005 (1.002)	loss nan (nan)	prob nan (nan)	GS 35.562 (35.562)	mem 39.984
Train: [62][515/750]	BT 0.172 (1.121)	DT 0.002 (0.992)	loss nan (nan)	prob nan (nan)	GS 31.094 (31.094)	mem 40.163
Train: [62][520/750]	BT 0.124 (1.133)	DT 0.010 (1.004)	loss nan (nan)	prob nan (nan)	GS 33.094 (33.094)	mem 39.940
Train: [62][525/750]	BT 0.161 (1.124)	DT 0.002 (0.995)	loss nan (nan)	prob nan (nan)	GS 33.422 (33.422)	mem 39.868
Train: [62][530/750]	BT 11.713 (1.136)	DT 11.634 (1.008)	loss nan (nan)	prob nan (nan)	GS 35.344 (35.344)	mem 40.023
Train: [62][535/750]	BT 0.112 (1.127)	DT 0.009 (0.999)	loss nan (nan)	prob nan (nan)	GS 31.078 (31.078)	mem 40.050
Train: [62][540/750]	BT 0.164 (1.118)	DT 0.001 (0.990)	loss nan (nan)	prob nan (nan)	GS 33.219 (33.219)	mem 40.019
Train: [62][545/750]	BT 0.122 (1.128)	DT 0.001 (0.999)	loss nan (nan)	prob nan (nan)	GS 28.375 (28.375)	mem 40.173
Train: [62][550/750]	BT 0.173 (1.119)	DT 0.001 (0.991)	loss nan (nan)	prob nan (nan)	GS 34.547 (34.547)	mem 40.000
Train: [62][555/750]	BT 0.142 (1.132)	DT 0.007 (1.003)	loss nan (nan)	prob nan (nan)	GS 29.812 (29.812)	mem 39.902
Train: [62][560/750]	BT 0.069 (1.126)	DT 0.001 (0.997)	loss nan (nan)	prob nan (nan)	GS 34.969 (34.969)	mem 39.982
Train: [62][565/750]	BT 0.176 (1.117)	DT 0.003 (0.989)	loss nan (nan)	prob nan (nan)	GS 29.312 (29.312)	mem 40.014
Train: [62][570/750]	BT 0.168 (1.129)	DT 0.001 (1.001)	loss nan (nan)	prob nan (nan)	GS 35.625 (35.625)	mem 39.983
Train: [62][575/750]	BT 0.188 (1.121)	DT 0.002 (0.992)	loss nan (nan)	prob nan (nan)	GS 32.406 (32.406)	mem 40.038
Train: [62][580/750]	BT 4.005 (1.130)	DT 3.895 (1.001)	loss nan (nan)	prob nan (nan)	GS 33.109 (33.109)	mem 40.011
Train: [62][585/750]	BT 0.125 (1.121)	DT 0.001 (0.993)	loss nan (nan)	prob nan (nan)	GS 33.375 (33.375)	mem 40.022
Train: [62][590/750]	BT 8.716 (1.128)	DT 8.569 (0.999)	loss nan (nan)	prob nan (nan)	GS 29.984 (29.984)	mem 40.060
Train: [62][595/750]	BT 0.139 (1.128)	DT 0.001 (1.000)	loss nan (nan)	prob nan (nan)	GS 26.203 (26.203)	mem 40.023
Train: [62][600/750]	BT 0.076 (1.120)	DT 0.002 (0.992)	loss nan (nan)	prob nan (nan)	GS 32.250 (32.250)	mem 40.070
Train: [62][605/750]	BT 0.157 (1.130)	DT 0.005 (1.001)	loss nan (nan)	prob nan (nan)	GS 31.391 (31.391)	mem 40.056
Train: [62][610/750]	BT 2.179 (1.125)	DT 2.011 (0.997)	loss nan (nan)	prob nan (nan)	GS 33.281 (33.281)	mem 40.086
Train: [62][615/750]	BT 0.086 (1.133)	DT 0.002 (1.004)	loss nan (nan)	prob nan (nan)	GS 32.797 (32.797)	mem 40.132
Train: [62][620/750]	BT 0.108 (1.124)	DT 0.003 (0.996)	loss nan (nan)	prob nan (nan)	GS 33.312 (33.312)	mem 40.066
Train: [62][625/750]	BT 0.113 (1.120)	DT 0.009 (0.992)	loss nan (nan)	prob nan (nan)	GS 29.672 (29.672)	mem 40.087
Train: [62][630/750]	BT 0.123 (1.127)	DT 0.002 (0.999)	loss nan (nan)	prob nan (nan)	GS 31.469 (31.469)	mem 40.063
Train: [62][635/750]	BT 0.148 (1.124)	DT 0.001 (0.996)	loss nan (nan)	prob nan (nan)	GS 33.031 (33.031)	mem 40.127
Train: [62][640/750]	BT 3.246 (1.131)	DT 3.132 (1.003)	loss nan (nan)	prob nan (nan)	GS 32.438 (32.438)	mem 40.135
Train: [62][645/750]	BT 0.118 (1.123)	DT 0.002 (0.995)	loss nan (nan)	prob nan (nan)	GS 29.047 (29.047)	mem 40.290
Train: [62][650/750]	BT 4.081 (1.130)	DT 3.931 (1.002)	loss nan (nan)	prob nan (nan)	GS 30.625 (30.625)	mem 40.092
Train: [62][655/750]	BT 0.091 (1.125)	DT 0.002 (0.996)	loss nan (nan)	prob nan (nan)	GS 29.672 (29.672)	mem 40.027
Train: [62][660/750]	BT 0.211 (1.132)	DT 0.022 (1.003)	loss nan (nan)	prob nan (nan)	GS 35.359 (35.359)	mem 40.125
Train: [62][665/750]	BT 0.137 (1.130)	DT 0.001 (1.002)	loss nan (nan)	prob nan (nan)	GS 33.375 (33.375)	mem 40.100
Train: [62][670/750]	BT 9.553 (1.137)	DT 9.441 (1.008)	loss nan (nan)	prob nan (nan)	GS 35.125 (35.125)	mem 40.069
Train: [62][675/750]	BT 0.158 (1.130)	DT 0.007 (1.001)	loss nan (nan)	prob nan (nan)	GS 27.609 (27.609)	mem 40.188
Train: [62][680/750]	BT 0.090 (1.127)	DT 0.002 (0.998)	loss nan (nan)	prob nan (nan)	GS 34.000 (34.000)	mem 40.034
Train: [62][685/750]	BT 0.084 (1.133)	DT 0.002 (1.004)	loss nan (nan)	prob nan (nan)	GS 30.609 (30.609)	mem 40.098
Train: [62][690/750]	BT 0.120 (1.126)	DT 0.011 (0.997)	loss nan (nan)	prob nan (nan)	GS 31.969 (31.969)	mem 40.109
Train: [62][695/750]	BT 0.117 (1.135)	DT 0.002 (1.006)	loss nan (nan)	prob nan (nan)	GS 31.609 (31.609)	mem 40.200
Train: [62][700/750]	BT 0.133 (1.128)	DT 0.001 (0.999)	loss nan (nan)	prob nan (nan)	GS 30.094 (30.094)	mem 40.092
Train: [62][705/750]	BT 0.138 (1.121)	DT 0.001 (0.992)	loss nan (nan)	prob nan (nan)	GS 33.891 (33.891)	mem 40.326
arpack error, retry= 0
Train: [62][710/750]	BT 0.163 (1.130)	DT 0.002 (1.000)	loss nan (nan)	prob nan (nan)	GS 34.297 (34.297)	mem 39.954
Train: [62][715/750]	BT 0.141 (1.124)	DT 0.010 (0.995)	loss nan (nan)	prob nan (nan)	GS 30.578 (30.578)	mem 40.022
Train: [62][720/750]	BT 0.160 (1.134)	DT 0.001 (1.005)	loss nan (nan)	prob nan (nan)	GS 30.406 (30.406)	mem 40.205
Train: [62][725/750]	BT 0.144 (1.129)	DT 0.002 (0.999)	loss nan (nan)	prob nan (nan)	GS 32.641 (32.641)	mem 39.939
Train: [62][730/750]	BT 7.254 (1.132)	DT 7.178 (1.003)	loss nan (nan)	prob nan (nan)	GS 34.109 (34.109)	mem 39.434
Train: [62][735/750]	BT 0.106 (1.125)	DT 0.001 (0.996)	loss nan (nan)	prob nan (nan)	GS 32.922 (32.922)	mem 39.436
Train: [62][740/750]	BT 0.129 (1.122)	DT 0.002 (0.993)	loss nan (nan)	prob nan (nan)	GS 34.422 (34.422)	mem 16.637
Train: [62][745/750]	BT 0.072 (1.118)	DT 0.001 (0.990)	loss nan (nan)	prob nan (nan)	GS 30.656 (30.656)	mem 7.748
Train: [62][750/750]	BT 0.074 (1.111)	DT 0.001 (0.983)	loss nan (nan)	prob nan (nan)	GS 27.875 (27.875)	mem 7.749
Train: [62][755/750]	BT 0.061 (1.107)	DT 0.001 (0.979)	loss nan (nan)	prob nan (nan)	GS 31.875 (31.875)	mem 7.688
epoch 62, total time 835.67
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [63][1/750]	BT 19.799 (19.799)	DT 19.668 (19.668)	loss nan (nan)	prob nan (nan)	GS 28.750 (28.750)	mem 38.487
Train: [63][5/750]	BT 0.212 (4.374)	DT 0.009 (4.223)	loss nan (nan)	prob nan (nan)	GS 25.906 (25.906)	mem 38.493
Train: [63][10/750]	BT 0.133 (2.317)	DT 0.002 (2.171)	loss nan (nan)	prob nan (nan)	GS 32.812 (32.812)	mem 38.682
Train: [63][15/750]	BT 0.144 (2.435)	DT 0.012 (2.286)	loss nan (nan)	prob nan (nan)	GS 29.750 (29.750)	mem 38.993
Train: [63][20/750]	BT 0.125 (1.873)	DT 0.029 (1.720)	loss nan (nan)	prob nan (nan)	GS 31.297 (31.297)	mem 38.893
Train: [63][25/750]	BT 4.487 (1.699)	DT 4.345 (1.551)	loss nan (nan)	prob nan (nan)	GS 29.453 (29.453)	mem 38.900
Train: [63][30/750]	BT 2.867 (1.702)	DT 2.791 (1.556)	loss nan (nan)	prob nan (nan)	GS 33.938 (33.938)	mem 39.147
Train: [63][35/750]	BT 0.099 (1.512)	DT 0.002 (1.367)	loss nan (nan)	prob nan (nan)	GS 32.859 (32.859)	mem 39.018
Train: [63][40/750]	BT 0.102 (1.606)	DT 0.005 (1.465)	loss nan (nan)	prob nan (nan)	GS 29.141 (29.141)	mem 39.047
Train: [63][45/750]	BT 0.211 (1.444)	DT 0.011 (1.303)	loss nan (nan)	prob nan (nan)	GS 32.344 (32.344)	mem 39.372
Train: [63][50/750]	BT 12.073 (1.550)	DT 11.918 (1.412)	loss nan (nan)	prob nan (nan)	GS 32.109 (32.109)	mem 39.003
Train: [63][55/750]	BT 0.216 (1.442)	DT 0.032 (1.304)	loss nan (nan)	prob nan (nan)	GS 27.281 (27.281)	mem 38.970
Train: [63][60/750]	BT 0.217 (1.339)	DT 0.002 (1.196)	loss nan (nan)	prob nan (nan)	GS 33.953 (33.953)	mem 38.993
Train: [63][65/750]	BT 0.143 (1.445)	DT 0.002 (1.304)	loss nan (nan)	prob nan (nan)	GS 28.406 (28.406)	mem 39.097
Train: [63][70/750]	BT 0.097 (1.354)	DT 0.001 (1.215)	loss nan (nan)	prob nan (nan)	GS 36.109 (36.109)	mem 39.151
Train: [63][75/750]	BT 0.082 (1.408)	DT 0.002 (1.270)	loss nan (nan)	prob nan (nan)	GS 33.281 (33.281)	mem 39.123
Train: [63][80/750]	BT 1.104 (1.351)	DT 0.965 (1.214)	loss nan (nan)	prob nan (nan)	GS 33.359 (33.359)	mem 39.162
Train: [63][85/750]	BT 0.097 (1.278)	DT 0.002 (1.143)	loss nan (nan)	prob nan (nan)	GS 29.531 (29.531)	mem 39.276
Train: [63][90/750]	BT 0.107 (1.326)	DT 0.001 (1.192)	loss nan (nan)	prob nan (nan)	GS 33.203 (33.203)	mem 39.033
Train: [63][95/750]	BT 0.095 (1.269)	DT 0.002 (1.137)	loss nan (nan)	prob nan (nan)	GS 28.547 (28.547)	mem 39.101
Train: [63][100/750]	BT 0.100 (1.344)	DT 0.001 (1.211)	loss nan (nan)	prob nan (nan)	GS 34.578 (34.578)	mem 39.182
Train: [63][105/750]	BT 0.158 (1.287)	DT 0.007 (1.154)	loss nan (nan)	prob nan (nan)	GS 29.375 (29.375)	mem 39.137
Train: [63][110/750]	BT 10.661 (1.331)	DT 10.584 (1.197)	loss nan (nan)	prob nan (nan)	GS 33.734 (33.734)	mem 39.231
Train: [63][115/750]	BT 0.097 (1.279)	DT 0.003 (1.145)	loss nan (nan)	prob nan (nan)	GS 29.906 (29.906)	mem 39.285
Train: [63][120/750]	BT 0.097 (1.231)	DT 0.002 (1.098)	loss nan (nan)	prob nan (nan)	GS 35.234 (35.234)	mem 39.246
Train: [63][125/750]	BT 0.086 (1.276)	DT 0.002 (1.143)	loss nan (nan)	prob nan (nan)	GS 31.219 (31.219)	mem 39.172
Train: [63][130/750]	BT 0.109 (1.232)	DT 0.001 (1.099)	loss nan (nan)	prob nan (nan)	GS 35.391 (35.391)	mem 39.139
Train: [63][135/750]	BT 0.183 (1.299)	DT 0.002 (1.167)	loss nan (nan)	prob nan (nan)	GS 34.516 (34.516)	mem 39.147
Train: [63][140/750]	BT 0.166 (1.257)	DT 0.001 (1.126)	loss nan (nan)	prob nan (nan)	GS 35.922 (35.922)	mem 39.225
Train: [63][145/750]	BT 0.133 (1.219)	DT 0.002 (1.087)	loss nan (nan)	prob nan (nan)	GS 34.016 (34.016)	mem 39.149
Train: [63][150/750]	BT 0.086 (1.255)	DT 0.002 (1.124)	loss nan (nan)	prob nan (nan)	GS 34.594 (34.594)	mem 39.240
Train: [63][155/750]	BT 0.196 (1.220)	DT 0.002 (1.088)	loss nan (nan)	prob nan (nan)	GS 31.406 (31.406)	mem 39.560
Train: [63][160/750]	BT 0.169 (1.254)	DT 0.001 (1.122)	loss nan (nan)	prob nan (nan)	GS 32.156 (32.156)	mem 39.284
Train: [63][165/750]	BT 0.124 (1.219)	DT 0.001 (1.088)	loss nan (nan)	prob nan (nan)	GS 28.672 (28.672)	mem 39.288
Train: [63][170/750]	BT 11.085 (1.252)	DT 10.961 (1.121)	loss nan (nan)	prob nan (nan)	GS 34.875 (34.875)	mem 39.488
Train: [63][175/750]	BT 0.122 (1.219)	DT 0.008 (1.089)	loss nan (nan)	prob nan (nan)	GS 31.953 (31.953)	mem 39.488
Train: [63][180/750]	BT 0.164 (1.189)	DT 0.002 (1.059)	loss nan (nan)	prob nan (nan)	GS 37.047 (37.047)	mem 39.490
Train: [63][185/750]	BT 0.142 (1.232)	DT 0.022 (1.102)	loss nan (nan)	prob nan (nan)	GS 32.172 (32.172)	mem 39.551
Train: [63][190/750]	BT 0.228 (1.205)	DT 0.020 (1.074)	loss nan (nan)	prob nan (nan)	GS 35.547 (35.547)	mem 39.568
Train: [63][195/750]	BT 0.074 (1.230)	DT 0.002 (1.099)	loss nan (nan)	prob nan (nan)	GS 25.344 (25.344)	mem 39.581
Train: [63][200/750]	BT 0.151 (1.209)	DT 0.005 (1.078)	loss nan (nan)	prob nan (nan)	GS 32.750 (32.750)	mem 39.519
Train: [63][205/750]	BT 0.103 (1.182)	DT 0.001 (1.051)	loss nan (nan)	prob nan (nan)	GS 34.547 (34.547)	mem 39.659
Train: [63][210/750]	BT 0.208 (1.218)	DT 0.001 (1.087)	loss nan (nan)	prob nan (nan)	GS 28.688 (28.688)	mem 39.563
Train: [63][215/750]	BT 0.157 (1.193)	DT 0.006 (1.062)	loss nan (nan)	prob nan (nan)	GS 35.406 (35.406)	mem 39.586
Train: [63][220/750]	BT 5.371 (1.221)	DT 5.220 (1.089)	loss nan (nan)	prob nan (nan)	GS 33.516 (33.516)	mem 39.777
Train: [63][225/750]	BT 0.171 (1.198)	DT 0.012 (1.065)	loss nan (nan)	prob nan (nan)	GS 31.375 (31.375)	mem 39.704
Train: [63][230/750]	BT 8.604 (1.211)	DT 8.500 (1.079)	loss nan (nan)	prob nan (nan)	GS 34.312 (34.312)	mem 39.826
Train: [63][235/750]	BT 0.123 (1.189)	DT 0.002 (1.057)	loss nan (nan)	prob nan (nan)	GS 29.359 (29.359)	mem 39.848
Train: [63][240/750]	BT 0.087 (1.166)	DT 0.001 (1.035)	loss nan (nan)	prob nan (nan)	GS 33.719 (33.719)	mem 39.739
Train: [63][245/750]	BT 0.181 (1.198)	DT 0.001 (1.068)	loss nan (nan)	prob nan (nan)	GS 28.938 (28.938)	mem 39.859
Train: [63][250/750]	BT 0.180 (1.176)	DT 0.002 (1.047)	loss nan (nan)	prob nan (nan)	GS 36.375 (36.375)	mem 40.003
Train: [63][255/750]	BT 0.085 (1.200)	DT 0.002 (1.071)	loss nan (nan)	prob nan (nan)	GS 33.859 (33.859)	mem 39.924
Train: [63][260/750]	BT 0.096 (1.179)	DT 0.002 (1.050)	loss nan (nan)	prob nan (nan)	GS 32.062 (32.062)	mem 39.925
Train: [63][265/750]	BT 0.218 (1.160)	DT 0.005 (1.031)	loss nan (nan)	prob nan (nan)	GS 30.469 (30.469)	mem 39.924
Train: [63][270/750]	BT 0.097 (1.202)	DT 0.014 (1.073)	loss nan (nan)	prob nan (nan)	GS 34.875 (34.875)	mem 39.827
Train: [63][275/750]	BT 0.211 (1.182)	DT 0.012 (1.054)	loss nan (nan)	prob nan (nan)	GS 31.672 (31.672)	mem 39.829
Train: [63][280/750]	BT 0.067 (1.209)	DT 0.001 (1.080)	loss nan (nan)	prob nan (nan)	GS 35.172 (35.172)	mem 39.893
Train: [63][285/750]	BT 0.156 (1.190)	DT 0.002 (1.061)	loss nan (nan)	prob nan (nan)	GS 30.609 (30.609)	mem 39.931
Train: [63][290/750]	BT 12.902 (1.215)	DT 12.710 (1.087)	loss nan (nan)	prob nan (nan)	GS 34.609 (34.609)	mem 39.816
Train: [63][295/750]	BT 0.076 (1.197)	DT 0.002 (1.069)	loss nan (nan)	prob nan (nan)	GS 28.797 (28.797)	mem 39.817
Train: [63][300/750]	BT 0.063 (1.178)	DT 0.001 (1.051)	loss nan (nan)	prob nan (nan)	GS 34.000 (34.000)	mem 39.818
Train: [63][305/750]	BT 0.156 (1.204)	DT 0.002 (1.077)	loss nan (nan)	prob nan (nan)	GS 28.547 (28.547)	mem 39.943
Train: [63][310/750]	BT 0.126 (1.186)	DT 0.008 (1.059)	loss nan (nan)	prob nan (nan)	GS 33.094 (33.094)	mem 39.944
Train: [63][315/750]	BT 0.114 (1.206)	DT 0.008 (1.079)	loss nan (nan)	prob nan (nan)	GS 32.578 (32.578)	mem 39.952
Train: [63][320/750]	BT 0.096 (1.188)	DT 0.002 (1.062)	loss nan (nan)	prob nan (nan)	GS 34.578 (34.578)	mem 39.953
Train: [63][325/750]	BT 0.154 (1.172)	DT 0.002 (1.045)	loss nan (nan)	prob nan (nan)	GS 32.328 (32.328)	mem 39.954
Train: [63][330/750]	BT 0.108 (1.198)	DT 0.002 (1.071)	loss nan (nan)	prob nan (nan)	GS 31.328 (31.328)	mem 39.986
Train: [63][335/750]	BT 0.082 (1.182)	DT 0.014 (1.055)	loss nan (nan)	prob nan (nan)	GS 35.922 (35.922)	mem 39.935
Train: [63][340/750]	BT 0.088 (1.200)	DT 0.002 (1.074)	loss nan (nan)	prob nan (nan)	GS 32.031 (32.031)	mem 39.971
Train: [63][345/750]	BT 0.090 (1.184)	DT 0.002 (1.059)	loss nan (nan)	prob nan (nan)	GS 31.453 (31.453)	mem 39.905
Train: [63][350/750]	BT 10.041 (1.197)	DT 9.950 (1.072)	loss nan (nan)	prob nan (nan)	GS 29.891 (29.891)	mem 39.979
Train: [63][355/750]	BT 0.187 (1.182)	DT 0.001 (1.057)	loss nan (nan)	prob nan (nan)	GS 34.078 (34.078)	mem 40.207
Train: [63][360/750]	BT 0.103 (1.167)	DT 0.001 (1.042)	loss nan (nan)	prob nan (nan)	GS 34.938 (34.938)	mem 40.003
Train: [63][365/750]	BT 0.098 (1.189)	DT 0.003 (1.064)	loss nan (nan)	prob nan (nan)	GS 29.328 (29.328)	mem 39.941
Train: [63][370/750]	BT 0.075 (1.175)	DT 0.002 (1.050)	loss nan (nan)	prob nan (nan)	GS 31.438 (31.438)	mem 39.953
Train: [63][375/750]	BT 0.079 (1.185)	DT 0.001 (1.061)	loss nan (nan)	prob nan (nan)	GS 31.641 (31.641)	mem 39.958
Train: [63][380/750]	BT 0.725 (1.173)	DT 0.421 (1.048)	loss nan (nan)	prob nan (nan)	GS 34.688 (34.688)	mem 39.957
Train: [63][385/750]	BT 0.119 (1.160)	DT 0.002 (1.034)	loss nan (nan)	prob nan (nan)	GS 34.906 (34.906)	mem 39.989
Train: [63][390/750]	BT 0.087 (1.167)	DT 0.006 (1.042)	loss nan (nan)	prob nan (nan)	GS 37.875 (37.875)	mem 40.037
Train: [63][395/750]	BT 0.115 (1.169)	DT 0.001 (1.043)	loss nan (nan)	prob nan (nan)	GS 30.984 (30.984)	mem 39.929
Train: [63][400/750]	BT 0.253 (1.163)	DT 0.014 (1.036)	loss nan (nan)	prob nan (nan)	GS 30.266 (30.266)	mem 39.941
Train: [63][405/750]	BT 0.189 (1.175)	DT 0.006 (1.047)	loss nan (nan)	prob nan (nan)	GS 29.141 (29.141)	mem 40.009
Train: [63][410/750]	BT 3.814 (1.172)	DT 3.648 (1.044)	loss nan (nan)	prob nan (nan)	GS 32.891 (32.891)	mem 40.057
Train: [63][415/750]	BT 0.189 (1.159)	DT 0.002 (1.031)	loss nan (nan)	prob nan (nan)	GS 34.328 (34.328)	mem 40.000
Train: [63][420/750]	BT 0.117 (1.161)	DT 0.002 (1.033)	loss nan (nan)	prob nan (nan)	GS 32.172 (32.172)	mem 40.065
Train: [63][425/750]	BT 0.199 (1.162)	DT 0.002 (1.034)	loss nan (nan)	prob nan (nan)	GS 37.500 (37.500)	mem 40.273
Train: [63][430/750]	BT 0.241 (1.161)	DT 0.003 (1.033)	loss nan (nan)	prob nan (nan)	GS 33.484 (33.484)	mem 40.047
Train: [63][435/750]	BT 0.074 (1.167)	DT 0.001 (1.038)	loss nan (nan)	prob nan (nan)	GS 33.312 (33.312)	mem 40.039
Train: [63][440/750]	BT 3.121 (1.162)	DT 2.983 (1.033)	loss nan (nan)	prob nan (nan)	GS 34.078 (34.078)	mem 40.061
Train: [63][445/750]	BT 0.200 (1.151)	DT 0.006 (1.022)	loss nan (nan)	prob nan (nan)	GS 31.547 (31.547)	mem 40.062
Train: [63][450/750]	BT 0.111 (1.161)	DT 0.001 (1.032)	loss nan (nan)	prob nan (nan)	GS 34.188 (34.188)	mem 40.040
Train: [63][455/750]	BT 0.096 (1.156)	DT 0.002 (1.027)	loss nan (nan)	prob nan (nan)	GS 30.156 (30.156)	mem 40.066
Train: [63][460/750]	BT 0.068 (1.170)	DT 0.001 (1.041)	loss nan (nan)	prob nan (nan)	GS 34.219 (34.219)	mem 40.075
Train: [63][465/750]	BT 0.119 (1.161)	DT 0.016 (1.033)	loss nan (nan)	prob nan (nan)	GS 29.062 (29.062)	mem 40.077
Train: [63][470/750]	BT 9.725 (1.171)	DT 9.643 (1.042)	loss nan (nan)	prob nan (nan)	GS 34.062 (34.062)	mem 40.086
Train: [63][475/750]	BT 0.089 (1.159)	DT 0.002 (1.031)	loss nan (nan)	prob nan (nan)	GS 33.438 (33.438)	mem 40.216
Train: [63][480/750]	BT 0.101 (1.151)	DT 0.003 (1.023)	loss nan (nan)	prob nan (nan)	GS 33.125 (33.125)	mem 40.115
Train: [63][485/750]	BT 0.102 (1.164)	DT 0.001 (1.036)	loss nan (nan)	prob nan (nan)	GS 35.219 (35.219)	mem 40.039
Train: [63][490/750]	BT 0.162 (1.154)	DT 0.008 (1.025)	loss nan (nan)	prob nan (nan)	GS 32.578 (32.578)	mem 40.381
Train: [63][495/750]	BT 0.087 (1.166)	DT 0.001 (1.038)	loss nan (nan)	prob nan (nan)	GS 32.312 (32.312)	mem 40.075
Train: [63][500/750]	BT 0.461 (1.156)	DT 0.348 (1.028)	loss nan (nan)	prob nan (nan)	GS 35.391 (35.391)	mem 40.015
Train: [63][505/750]	BT 0.137 (1.152)	DT 0.002 (1.024)	loss nan (nan)	prob nan (nan)	GS 27.859 (27.859)	mem 40.063
Train: [63][510/750]	BT 0.141 (1.161)	DT 0.005 (1.034)	loss nan (nan)	prob nan (nan)	GS 31.594 (31.594)	mem 39.981
Train: [63][515/750]	BT 0.105 (1.151)	DT 0.002 (1.024)	loss nan (nan)	prob nan (nan)	GS 31.406 (31.406)	mem 40.022
Train: [63][520/750]	BT 0.164 (1.162)	DT 0.011 (1.034)	loss nan (nan)	prob nan (nan)	GS 39.406 (39.406)	mem 40.161
Train: [63][525/750]	BT 0.077 (1.152)	DT 0.002 (1.024)	loss nan (nan)	prob nan (nan)	GS 30.250 (30.250)	mem 40.072
Train: [63][530/750]	BT 13.094 (1.167)	DT 13.016 (1.040)	loss nan (nan)	prob nan (nan)	GS 32.234 (32.234)	mem 40.043
Train: [63][535/750]	BT 0.073 (1.157)	DT 0.001 (1.030)	loss nan (nan)	prob nan (nan)	GS 33.906 (33.906)	mem 40.059
Train: [63][540/750]	BT 0.162 (1.147)	DT 0.001 (1.020)	loss nan (nan)	prob nan (nan)	GS 33.234 (33.234)	mem 40.063
Train: [63][545/750]	BT 0.109 (1.160)	DT 0.001 (1.033)	loss nan (nan)	prob nan (nan)	GS 31.453 (31.453)	mem 40.041
Train: [63][550/750]	BT 0.069 (1.151)	DT 0.001 (1.024)	loss nan (nan)	prob nan (nan)	GS 32.797 (32.797)	mem 40.001
Train: [63][555/750]	BT 0.173 (1.164)	DT 0.002 (1.038)	loss nan (nan)	prob nan (nan)	GS 32.297 (32.297)	mem 40.008
Train: [63][560/750]	BT 0.099 (1.155)	DT 0.008 (1.029)	loss nan (nan)	prob nan (nan)	GS 31.469 (31.469)	mem 40.094
Train: [63][565/750]	BT 0.182 (1.146)	DT 0.002 (1.019)	loss nan (nan)	prob nan (nan)	GS 31.438 (31.438)	mem 40.018
Train: [63][570/750]	BT 0.099 (1.154)	DT 0.002 (1.027)	loss nan (nan)	prob nan (nan)	GS 30.531 (30.531)	mem 40.399
Train: [63][575/750]	BT 0.191 (1.145)	DT 0.004 (1.019)	loss nan (nan)	prob nan (nan)	GS 30.953 (30.953)	mem 40.000
Train: [63][580/750]	BT 0.095 (1.156)	DT 0.010 (1.030)	loss nan (nan)	prob nan (nan)	GS 33.469 (33.469)	mem 39.892
Train: [63][585/750]	BT 0.187 (1.148)	DT 0.002 (1.021)	loss nan (nan)	prob nan (nan)	GS 33.266 (33.266)	mem 40.008
Train: [63][590/750]	BT 11.704 (1.159)	DT 11.603 (1.032)	loss nan (nan)	prob nan (nan)	GS 34.547 (34.547)	mem 40.003
Train: [63][595/750]	BT 0.155 (1.150)	DT 0.002 (1.023)	loss nan (nan)	prob nan (nan)	GS 28.828 (28.828)	mem 40.013
Train: [63][600/750]	BT 0.144 (1.145)	DT 0.007 (1.018)	loss nan (nan)	prob nan (nan)	GS 34.000 (34.000)	mem 39.977
Train: [63][605/750]	BT 0.075 (1.147)	DT 0.002 (1.020)	loss nan (nan)	prob nan (nan)	GS 31.781 (31.781)	mem 39.939
Train: [63][610/750]	BT 0.153 (1.151)	DT 0.002 (1.024)	loss nan (nan)	prob nan (nan)	GS 30.844 (30.844)	mem 39.889
Train: [63][615/750]	BT 0.099 (1.143)	DT 0.002 (1.016)	loss nan (nan)	prob nan (nan)	GS 27.828 (27.828)	mem 39.902
Train: [63][620/750]	BT 8.767 (1.152)	DT 8.573 (1.025)	loss nan (nan)	prob nan (nan)	GS 32.031 (32.031)	mem 40.023
Train: [63][625/750]	BT 0.088 (1.144)	DT 0.002 (1.017)	loss nan (nan)	prob nan (nan)	GS 27.078 (27.078)	mem 39.980
Train: [63][630/750]	BT 0.297 (1.143)	DT 0.004 (1.015)	loss nan (nan)	prob nan (nan)	GS 35.250 (35.250)	mem 39.779
Train: [63][635/750]	BT 0.128 (1.149)	DT 0.001 (1.021)	loss nan (nan)	prob nan (nan)	GS 32.016 (32.016)	mem 39.908
Train: [63][640/750]	BT 10.475 (1.157)	DT 10.389 (1.030)	loss nan (nan)	prob nan (nan)	GS 36.172 (36.172)	mem 39.933
Train: [63][645/750]	BT 0.177 (1.152)	DT 0.001 (1.024)	loss nan (nan)	prob nan (nan)	GS 32.188 (32.188)	mem 40.063
Train: [63][650/750]	BT 0.176 (1.144)	DT 0.048 (1.016)	loss nan (nan)	prob nan (nan)	GS 35.031 (35.031)	mem 40.091
Train: [63][655/750]	BT 0.114 (1.150)	DT 0.001 (1.022)	loss nan (nan)	prob nan (nan)	GS 39.219 (39.219)	mem 40.110
Train: [63][660/750]	BT 0.163 (1.147)	DT 0.001 (1.020)	loss nan (nan)	prob nan (nan)	GS 33.672 (33.672)	mem 40.086
Train: [63][665/750]	BT 0.086 (1.155)	DT 0.002 (1.028)	loss nan (nan)	prob nan (nan)	GS 40.672 (40.672)	mem 39.931
Train: [63][670/750]	BT 0.094 (1.149)	DT 0.002 (1.021)	loss nan (nan)	prob nan (nan)	GS 35.938 (35.938)	mem 39.995
Train: [63][675/750]	BT 0.098 (1.146)	DT 0.001 (1.018)	loss nan (nan)	prob nan (nan)	GS 29.406 (29.406)	mem 40.113
Train: [63][680/750]	BT 3.357 (1.157)	DT 3.105 (1.029)	loss nan (nan)	prob nan (nan)	GS 31.047 (31.047)	mem 39.908
Train: [63][685/750]	BT 0.086 (1.149)	DT 0.002 (1.022)	loss nan (nan)	prob nan (nan)	GS 27.875 (27.875)	mem 39.861
Train: [63][690/750]	BT 0.220 (1.157)	DT 0.002 (1.029)	loss nan (nan)	prob nan (nan)	GS 32.531 (32.531)	mem 39.897
Train: [63][695/750]	BT 0.186 (1.153)	DT 0.010 (1.025)	loss nan (nan)	prob nan (nan)	GS 31.016 (31.016)	mem 39.831
Train: [63][700/750]	BT 11.822 (1.162)	DT 11.621 (1.035)	loss nan (nan)	prob nan (nan)	GS 38.750 (38.750)	mem 39.959
Train: [63][705/750]	BT 0.174 (1.155)	DT 0.009 (1.027)	loss nan (nan)	prob nan (nan)	GS 32.812 (32.812)	mem 39.852
Train: [63][710/750]	BT 0.228 (1.148)	DT 0.003 (1.020)	loss nan (nan)	prob nan (nan)	GS 31.719 (31.719)	mem 39.860
Train: [63][715/750]	BT 0.070 (1.160)	DT 0.001 (1.033)	loss nan (nan)	prob nan (nan)	GS 28.875 (28.875)	mem 40.025
Train: [63][720/750]	BT 0.132 (1.153)	DT 0.008 (1.025)	loss nan (nan)	prob nan (nan)	GS 37.688 (37.688)	mem 39.963
Train: [63][725/750]	BT 0.077 (1.159)	DT 0.002 (1.031)	loss nan (nan)	prob nan (nan)	GS 31.547 (31.547)	mem 39.810
Train: [63][730/750]	BT 0.109 (1.152)	DT 0.001 (1.024)	loss nan (nan)	prob nan (nan)	GS 36.016 (36.016)	mem 40.028
Train: [63][735/750]	BT 0.207 (1.145)	DT 0.012 (1.017)	loss nan (nan)	prob nan (nan)	GS 30.156 (30.156)	mem 39.812
Train: [63][740/750]	BT 0.087 (1.145)	DT 0.011 (1.018)	loss nan (nan)	prob nan (nan)	GS 34.938 (34.938)	mem 24.300
Train: [63][745/750]	BT 0.114 (1.139)	DT 0.013 (1.011)	loss nan (nan)	prob nan (nan)	GS 30.062 (30.062)	mem 19.599
Train: [63][750/750]	BT 0.454 (1.135)	DT 0.385 (1.008)	loss nan (nan)	prob nan (nan)	GS 37.844 (37.844)	mem 10.598
Train: [63][755/750]	BT 0.077 (1.128)	DT 0.001 (1.001)	loss nan (nan)	prob nan (nan)	GS 35.906 (35.906)	mem 7.675
epoch 63, total time 852.07
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [64][1/750]	BT 20.150 (20.150)	DT 20.027 (20.027)	loss nan (nan)	prob nan (nan)	GS 30.516 (30.516)	mem 38.613
Train: [64][5/750]	BT 0.087 (4.733)	DT 0.002 (4.613)	loss nan (nan)	prob nan (nan)	GS 34.453 (34.453)	mem 38.713
Train: [64][10/750]	BT 0.163 (2.586)	DT 0.002 (2.460)	loss nan (nan)	prob nan (nan)	GS 33.047 (33.047)	mem 38.681
Train: [64][15/750]	BT 0.171 (2.578)	DT 0.004 (2.443)	loss nan (nan)	prob nan (nan)	GS 34.000 (34.000)	mem 38.873
Train: [64][20/750]	BT 5.110 (2.220)	DT 4.948 (2.083)	loss nan (nan)	prob nan (nan)	GS 32.719 (32.719)	mem 38.824
Train: [64][25/750]	BT 0.330 (1.807)	DT 0.002 (1.667)	loss nan (nan)	prob nan (nan)	GS 27.469 (27.469)	mem 38.954
Train: [64][30/750]	BT 1.638 (1.764)	DT 1.505 (1.622)	loss nan (nan)	prob nan (nan)	GS 38.531 (38.531)	mem 38.877
Train: [64][35/750]	BT 0.075 (1.660)	DT 0.001 (1.520)	loss nan (nan)	prob nan (nan)	GS 31.828 (31.828)	mem 38.979
Train: [64][40/750]	BT 1.815 (1.606)	DT 1.718 (1.470)	loss nan (nan)	prob nan (nan)	GS 33.984 (33.984)	mem 38.996
Train: [64][45/750]	BT 0.080 (1.592)	DT 0.001 (1.457)	loss nan (nan)	prob nan (nan)	GS 32.172 (32.172)	mem 39.041
Train: [64][50/750]	BT 1.539 (1.476)	DT 1.410 (1.340)	loss nan (nan)	prob nan (nan)	GS 33.984 (33.984)	mem 39.134
Train: [64][55/750]	BT 0.122 (1.437)	DT 0.002 (1.302)	loss nan (nan)	prob nan (nan)	GS 31.609 (31.609)	mem 39.090
Train: [64][60/750]	BT 0.149 (1.392)	DT 0.018 (1.258)	loss nan (nan)	prob nan (nan)	GS 31.188 (31.188)	mem 39.111
Train: [64][65/750]	BT 0.077 (1.486)	DT 0.001 (1.351)	loss nan (nan)	prob nan (nan)	GS 30.531 (30.531)	mem 39.087
Train: [64][70/750]	BT 0.126 (1.386)	DT 0.001 (1.255)	loss nan (nan)	prob nan (nan)	GS 37.062 (37.062)	mem 39.008
Train: [64][75/750]	BT 0.098 (1.304)	DT 0.002 (1.172)	loss nan (nan)	prob nan (nan)	GS 34.250 (34.250)	mem 39.025
Train: [64][80/750]	BT 0.104 (1.399)	DT 0.002 (1.270)	loss nan (nan)	prob nan (nan)	GS 31.953 (31.953)	mem 39.028
Train: [64][85/750]	BT 0.073 (1.324)	DT 0.001 (1.196)	loss nan (nan)	prob nan (nan)	GS 35.938 (35.938)	mem 39.093
Train: [64][90/750]	BT 0.132 (1.383)	DT 0.001 (1.254)	loss nan (nan)	prob nan (nan)	GS 36.141 (36.141)	mem 39.729
Train: [64][95/750]	BT 0.092 (1.316)	DT 0.001 (1.188)	loss nan (nan)	prob nan (nan)	GS 31.172 (31.172)	mem 39.472
Train: [64][100/750]	BT 12.124 (1.375)	DT 12.050 (1.250)	loss nan (nan)	prob nan (nan)	GS 31.000 (31.000)	mem 39.543
Train: [64][105/750]	BT 0.113 (1.315)	DT 0.001 (1.190)	loss nan (nan)	prob nan (nan)	GS 29.219 (29.219)	mem 39.450
Train: [64][110/750]	BT 0.160 (1.262)	DT 0.012 (1.136)	loss nan (nan)	prob nan (nan)	GS 33.812 (33.812)	mem 39.404
Train: [64][115/750]	BT 0.120 (1.293)	DT 0.005 (1.167)	loss nan (nan)	prob nan (nan)	GS 32.828 (32.828)	mem 39.746
Train: [64][120/750]	BT 0.144 (1.246)	DT 0.002 (1.119)	loss nan (nan)	prob nan (nan)	GS 34.766 (34.766)	mem 39.600
Train: [64][125/750]	BT 0.084 (1.301)	DT 0.002 (1.174)	loss nan (nan)	prob nan (nan)	GS 31.594 (31.594)	mem 39.734
Train: [64][130/750]	BT 0.174 (1.256)	DT 0.005 (1.129)	loss nan (nan)	prob nan (nan)	GS 30.656 (30.656)	mem 39.744
Train: [64][135/750]	BT 0.125 (1.214)	DT 0.002 (1.088)	loss nan (nan)	prob nan (nan)	GS 27.062 (27.062)	mem 39.767
Train: [64][140/750]	BT 0.208 (1.268)	DT 0.010 (1.141)	loss nan (nan)	prob nan (nan)	GS 33.969 (33.969)	mem 39.704
Train: [64][145/750]	BT 0.100 (1.229)	DT 0.001 (1.102)	loss nan (nan)	prob nan (nan)	GS 34.281 (34.281)	mem 39.737
Train: [64][150/750]	BT 0.245 (1.253)	DT 0.011 (1.125)	loss nan (nan)	prob nan (nan)	GS 37.375 (37.375)	mem 39.797
Train: [64][155/750]	BT 0.191 (1.239)	DT 0.001 (1.111)	loss nan (nan)	prob nan (nan)	GS 33.922 (33.922)	mem 39.744
Train: [64][160/750]	BT 4.732 (1.237)	DT 4.591 (1.107)	loss nan (nan)	prob nan (nan)	GS 30.422 (30.422)	mem 39.962
Train: [64][165/750]	BT 0.164 (1.243)	DT 0.001 (1.113)	loss nan (nan)	prob nan (nan)	GS 27.734 (27.734)	mem 39.839
Train: [64][170/750]	BT 0.130 (1.210)	DT 0.001 (1.080)	loss nan (nan)	prob nan (nan)	GS 36.344 (36.344)	mem 39.808
Train: [64][175/750]	BT 0.173 (1.222)	DT 0.008 (1.091)	loss nan (nan)	prob nan (nan)	GS 29.141 (29.141)	mem 39.899
Train: [64][180/750]	BT 0.115 (1.214)	DT 0.008 (1.082)	loss nan (nan)	prob nan (nan)	GS 35.000 (35.000)	mem 39.810
Train: [64][185/750]	BT 0.095 (1.236)	DT 0.002 (1.104)	loss nan (nan)	prob nan (nan)	GS 34.828 (34.828)	mem 39.799
Train: [64][190/750]	BT 0.089 (1.228)	DT 0.001 (1.097)	loss nan (nan)	prob nan (nan)	GS 33.156 (33.156)	mem 39.796
Train: [64][195/750]	BT 0.234 (1.200)	DT 0.010 (1.069)	loss nan (nan)	prob nan (nan)	GS 27.672 (27.672)	mem 39.772
Train: [64][200/750]	BT 7.596 (1.239)	DT 7.483 (1.108)	loss nan (nan)	prob nan (nan)	GS 32.266 (32.266)	mem 39.808
Train: [64][205/750]	BT 0.233 (1.212)	DT 0.023 (1.081)	loss nan (nan)	prob nan (nan)	GS 28.812 (28.812)	mem 40.013
Train: [64][210/750]	BT 0.138 (1.210)	DT 0.002 (1.079)	loss nan (nan)	prob nan (nan)	GS 34.516 (34.516)	mem 39.839
Train: [64][215/750]	BT 0.108 (1.213)	DT 0.001 (1.083)	loss nan (nan)	prob nan (nan)	GS 29.781 (29.781)	mem 39.896
Train: [64][220/750]	BT 1.721 (1.196)	DT 1.600 (1.065)	loss nan (nan)	prob nan (nan)	GS 35.625 (35.625)	mem 39.894
Train: [64][225/750]	BT 0.092 (1.221)	DT 0.001 (1.091)	loss nan (nan)	prob nan (nan)	GS 31.531 (31.531)	mem 39.950
Train: [64][230/750]	BT 0.135 (1.198)	DT 0.014 (1.068)	loss nan (nan)	prob nan (nan)	GS 30.766 (30.766)	mem 39.968
Train: [64][235/750]	BT 0.143 (1.176)	DT 0.001 (1.046)	loss nan (nan)	prob nan (nan)	GS 24.406 (24.406)	mem 39.890
Train: [64][240/750]	BT 0.101 (1.204)	DT 0.001 (1.075)	loss nan (nan)	prob nan (nan)	GS 31.438 (31.438)	mem 39.946
Train: [64][245/750]	BT 0.110 (1.181)	DT 0.001 (1.053)	loss nan (nan)	prob nan (nan)	GS 29.641 (29.641)	mem 39.977
Train: [64][250/750]	BT 0.198 (1.212)	DT 0.002 (1.084)	loss nan (nan)	prob nan (nan)	GS 25.500 (25.500)	mem 40.089
Train: [64][255/750]	BT 0.222 (1.191)	DT 0.007 (1.062)	loss nan (nan)	prob nan (nan)	GS 30.953 (30.953)	mem 40.022
Train: [64][260/750]	BT 11.416 (1.216)	DT 11.278 (1.087)	loss nan (nan)	prob nan (nan)	GS 32.922 (32.922)	mem 40.043
Train: [64][265/750]	BT 0.092 (1.195)	DT 0.002 (1.067)	loss nan (nan)	prob nan (nan)	GS 37.094 (37.094)	mem 40.210
Train: [64][270/750]	BT 0.173 (1.182)	DT 0.001 (1.054)	loss nan (nan)	prob nan (nan)	GS 34.375 (34.375)	mem 40.199
Train: [64][275/750]	BT 0.101 (1.197)	DT 0.002 (1.069)	loss nan (nan)	prob nan (nan)	GS 28.656 (28.656)	mem 40.056
Train: [64][280/750]	BT 0.951 (1.181)	DT 0.849 (1.053)	loss nan (nan)	prob nan (nan)	GS 30.328 (30.328)	mem 40.059
Train: [64][285/750]	BT 0.290 (1.199)	DT 0.001 (1.070)	loss nan (nan)	prob nan (nan)	GS 32.188 (32.188)	mem 39.994
Train: [64][290/750]	BT 0.151 (1.180)	DT 0.002 (1.052)	loss nan (nan)	prob nan (nan)	GS 39.656 (39.656)	mem 40.113
Train: [64][295/750]	BT 0.141 (1.164)	DT 0.001 (1.036)	loss nan (nan)	prob nan (nan)	GS 30.484 (30.484)	mem 40.009
Train: [64][300/750]	BT 0.113 (1.189)	DT 0.003 (1.060)	loss nan (nan)	prob nan (nan)	GS 35.156 (35.156)	mem 40.029
Train: [64][305/750]	BT 0.153 (1.171)	DT 0.001 (1.043)	loss nan (nan)	prob nan (nan)	GS 30.078 (30.078)	mem 40.152
Train: [64][310/750]	BT 0.119 (1.191)	DT 0.002 (1.063)	loss nan (nan)	prob nan (nan)	GS 37.406 (37.406)	mem 40.013
Train: [64][315/750]	BT 0.098 (1.174)	DT 0.002 (1.046)	loss nan (nan)	prob nan (nan)	GS 34.406 (34.406)	mem 40.020
Train: [64][320/750]	BT 10.490 (1.191)	DT 10.369 (1.062)	loss nan (nan)	prob nan (nan)	GS 28.344 (28.344)	mem 40.083
Train: [64][325/750]	BT 0.096 (1.174)	DT 0.001 (1.046)	loss nan (nan)	prob nan (nan)	GS 32.844 (32.844)	mem 40.037
Train: [64][330/750]	BT 0.333 (1.159)	DT 0.209 (1.030)	loss nan (nan)	prob nan (nan)	GS 35.969 (35.969)	mem 40.270
Train: [64][335/750]	BT 0.252 (1.175)	DT 0.030 (1.046)	loss nan (nan)	prob nan (nan)	GS 32.531 (32.531)	mem 40.090
Train: [64][340/750]	BT 0.092 (1.161)	DT 0.002 (1.033)	loss nan (nan)	prob nan (nan)	GS 34.703 (34.703)	mem 40.054
Train: [64][345/750]	BT 0.100 (1.191)	DT 0.005 (1.063)	loss nan (nan)	prob nan (nan)	GS 30.969 (30.969)	mem 39.887
Train: [64][350/750]	BT 0.161 (1.176)	DT 0.002 (1.048)	loss nan (nan)	prob nan (nan)	GS 30.766 (30.766)	mem 39.897
Train: [64][355/750]	BT 0.203 (1.162)	DT 0.004 (1.033)	loss nan (nan)	prob nan (nan)	GS 31.469 (31.469)	mem 40.305
Train: [64][360/750]	BT 0.099 (1.181)	DT 0.002 (1.052)	loss nan (nan)	prob nan (nan)	GS 35.297 (35.297)	mem 40.194
Train: [64][365/750]	BT 0.095 (1.166)	DT 0.001 (1.038)	loss nan (nan)	prob nan (nan)	GS 30.531 (30.531)	mem 39.931
Train: [64][370/750]	BT 0.133 (1.183)	DT 0.002 (1.054)	loss nan (nan)	prob nan (nan)	GS 35.297 (35.297)	mem 40.015
Train: [64][375/750]	BT 0.168 (1.169)	DT 0.014 (1.040)	loss nan (nan)	prob nan (nan)	GS 30.844 (30.844)	mem 39.966
Train: [64][380/750]	BT 9.318 (1.184)	DT 9.253 (1.054)	loss nan (nan)	prob nan (nan)	GS 32.984 (32.984)	mem 39.826
Train: [64][385/750]	BT 0.136 (1.170)	DT 0.013 (1.041)	loss nan (nan)	prob nan (nan)	GS 31.375 (31.375)	mem 39.893
Train: [64][390/750]	BT 0.068 (1.157)	DT 0.007 (1.028)	loss nan (nan)	prob nan (nan)	GS 32.531 (32.531)	mem 39.895
Train: [64][395/750]	BT 0.117 (1.178)	DT 0.004 (1.049)	loss nan (nan)	prob nan (nan)	GS 29.047 (29.047)	mem 39.896
Train: [64][400/750]	BT 0.249 (1.165)	DT 0.013 (1.036)	loss nan (nan)	prob nan (nan)	GS 36.422 (36.422)	mem 39.903
Train: [64][405/750]	BT 0.075 (1.181)	DT 0.001 (1.052)	loss nan (nan)	prob nan (nan)	GS 30.781 (30.781)	mem 40.036
Train: [64][410/750]	BT 0.082 (1.168)	DT 0.001 (1.039)	loss nan (nan)	prob nan (nan)	GS 28.297 (28.297)	mem 40.010
Train: [64][415/750]	BT 0.152 (1.156)	DT 0.002 (1.027)	loss nan (nan)	prob nan (nan)	GS 30.656 (30.656)	mem 39.997
Train: [64][420/750]	BT 0.076 (1.176)	DT 0.001 (1.048)	loss nan (nan)	prob nan (nan)	GS 30.750 (30.750)	mem 39.912
Train: [64][425/750]	BT 0.145 (1.164)	DT 0.001 (1.036)	loss nan (nan)	prob nan (nan)	GS 32.625 (32.625)	mem 39.980
Train: [64][430/750]	BT 0.173 (1.175)	DT 0.006 (1.047)	loss nan (nan)	prob nan (nan)	GS 34.672 (34.672)	mem 40.099
Train: [64][435/750]	BT 0.227 (1.163)	DT 0.004 (1.035)	loss nan (nan)	prob nan (nan)	GS 34.188 (34.188)	mem 40.017
Train: [64][440/750]	BT 12.879 (1.183)	DT 12.807 (1.055)	loss nan (nan)	prob nan (nan)	GS 35.250 (35.250)	mem 39.974
Train: [64][445/750]	BT 0.129 (1.171)	DT 0.002 (1.043)	loss nan (nan)	prob nan (nan)	GS 30.328 (30.328)	mem 40.033
Train: [64][450/750]	BT 0.111 (1.160)	DT 0.001 (1.031)	loss nan (nan)	prob nan (nan)	GS 34.062 (34.062)	mem 39.994
Train: [64][455/750]	BT 0.092 (1.174)	DT 0.009 (1.046)	loss nan (nan)	prob nan (nan)	GS 30.375 (30.375)	mem 39.988
Train: [64][460/750]	BT 0.108 (1.163)	DT 0.005 (1.035)	loss nan (nan)	prob nan (nan)	GS 31.781 (31.781)	mem 39.990
Train: [64][465/750]	BT 0.096 (1.175)	DT 0.001 (1.048)	loss nan (nan)	prob nan (nan)	GS 32.938 (32.938)	mem 40.075
Train: [64][470/750]	BT 0.105 (1.164)	DT 0.007 (1.037)	loss nan (nan)	prob nan (nan)	GS 30.406 (30.406)	mem 39.971
Train: [64][475/750]	BT 0.226 (1.158)	DT 0.002 (1.031)	loss nan (nan)	prob nan (nan)	GS 29.797 (29.797)	mem 40.205
Train: [64][480/750]	BT 0.081 (1.165)	DT 0.001 (1.038)	loss nan (nan)	prob nan (nan)	GS 31.922 (31.922)	mem 40.074
Train: [64][485/750]	BT 0.093 (1.154)	DT 0.002 (1.027)	loss nan (nan)	prob nan (nan)	GS 32.078 (32.078)	mem 40.073
Train: [64][490/750]	BT 0.093 (1.164)	DT 0.002 (1.037)	loss nan (nan)	prob nan (nan)	GS 32.438 (32.438)	mem 40.216
Train: [64][495/750]	BT 0.117 (1.154)	DT 0.001 (1.026)	loss nan (nan)	prob nan (nan)	GS 34.328 (34.328)	mem 40.186
Train: [64][500/750]	BT 12.352 (1.172)	DT 12.220 (1.044)	loss nan (nan)	prob nan (nan)	GS 36.406 (36.406)	mem 39.993
Train: [64][505/750]	BT 0.159 (1.162)	DT 0.002 (1.034)	loss nan (nan)	prob nan (nan)	GS 30.422 (30.422)	mem 40.016
Train: [64][510/750]	BT 0.274 (1.152)	DT 0.180 (1.024)	loss nan (nan)	prob nan (nan)	GS 33.672 (33.672)	mem 39.986
Train: [64][515/750]	BT 0.057 (1.168)	DT 0.001 (1.040)	loss nan (nan)	prob nan (nan)	GS 30.578 (30.578)	mem 39.993
Train: [64][520/750]	BT 0.177 (1.158)	DT 0.002 (1.030)	loss nan (nan)	prob nan (nan)	GS 36.875 (36.875)	mem 40.034
Train: [64][525/750]	BT 0.104 (1.178)	DT 0.002 (1.051)	loss nan (nan)	prob nan (nan)	GS 30.234 (30.234)	mem 39.957
Train: [64][530/750]	BT 0.093 (1.168)	DT 0.002 (1.041)	loss nan (nan)	prob nan (nan)	GS 34.328 (34.328)	mem 39.978
Train: [64][535/750]	BT 0.072 (1.159)	DT 0.001 (1.031)	loss nan (nan)	prob nan (nan)	GS 30.016 (30.016)	mem 39.978
Train: [64][540/750]	BT 0.114 (1.166)	DT 0.002 (1.038)	loss nan (nan)	prob nan (nan)	GS 36.844 (36.844)	mem 40.065
Train: [64][545/750]	BT 0.061 (1.156)	DT 0.001 (1.029)	loss nan (nan)	prob nan (nan)	GS 30.672 (30.672)	mem 40.165
Train: [64][550/750]	BT 0.177 (1.165)	DT 0.001 (1.038)	loss nan (nan)	prob nan (nan)	GS 31.000 (31.000)	mem 40.059
Train: [64][555/750]	BT 0.127 (1.156)	DT 0.004 (1.029)	loss nan (nan)	prob nan (nan)	GS 28.516 (28.516)	mem 40.155
Train: [64][560/750]	BT 12.346 (1.169)	DT 12.236 (1.041)	loss nan (nan)	prob nan (nan)	GS 35.250 (35.250)	mem 40.059
Train: [64][565/750]	BT 0.088 (1.160)	DT 0.001 (1.032)	loss nan (nan)	prob nan (nan)	GS 31.953 (31.953)	mem 40.028
Train: [64][570/750]	BT 0.194 (1.151)	DT 0.002 (1.023)	loss nan (nan)	prob nan (nan)	GS 34.828 (34.828)	mem 40.029
Train: [64][575/750]	BT 0.080 (1.161)	DT 0.001 (1.034)	loss nan (nan)	prob nan (nan)	GS 45.703 (45.703)	mem 40.043
Train: [64][580/750]	BT 0.206 (1.152)	DT 0.011 (1.025)	loss nan (nan)	prob nan (nan)	GS 32.750 (32.750)	mem 40.271
Train: [64][585/750]	BT 0.227 (1.162)	DT 0.004 (1.034)	loss nan (nan)	prob nan (nan)	GS 31.672 (31.672)	mem 40.103
Train: [64][590/750]	BT 0.108 (1.153)	DT 0.002 (1.025)	loss nan (nan)	prob nan (nan)	GS 35.531 (35.531)	mem 40.150
Train: [64][595/750]	BT 0.279 (1.145)	DT 0.002 (1.017)	loss nan (nan)	prob nan (nan)	GS 32.625 (32.625)	mem 40.078
Train: [64][600/750]	BT 0.133 (1.157)	DT 0.002 (1.029)	loss nan (nan)	prob nan (nan)	GS 32.891 (32.891)	mem 40.110
Train: [64][605/750]	BT 0.190 (1.154)	DT 0.036 (1.026)	loss nan (nan)	prob nan (nan)	GS 30.438 (30.438)	mem 40.209
Train: [64][610/750]	BT 0.084 (1.164)	DT 0.001 (1.036)	loss nan (nan)	prob nan (nan)	GS 34.453 (34.453)	mem 39.904
Train: [64][615/750]	BT 0.102 (1.155)	DT 0.001 (1.027)	loss nan (nan)	prob nan (nan)	GS 32.125 (32.125)	mem 39.948
Train: [64][620/750]	BT 10.563 (1.164)	DT 10.439 (1.036)	loss nan (nan)	prob nan (nan)	GS 35.812 (35.812)	mem 40.113
Train: [64][625/750]	BT 0.129 (1.156)	DT 0.008 (1.028)	loss nan (nan)	prob nan (nan)	GS 35.203 (35.203)	mem 40.022
Train: [64][630/750]	BT 0.139 (1.148)	DT 0.004 (1.019)	loss nan (nan)	prob nan (nan)	GS 35.578 (35.578)	mem 40.048
Train: [64][635/750]	BT 0.084 (1.159)	DT 0.001 (1.031)	loss nan (nan)	prob nan (nan)	GS 26.922 (26.922)	mem 40.042
Train: [64][640/750]	BT 0.105 (1.150)	DT 0.019 (1.023)	loss nan (nan)	prob nan (nan)	GS 35.297 (35.297)	mem 40.088
Train: [64][645/750]	BT 0.137 (1.163)	DT 0.020 (1.035)	loss nan (nan)	prob nan (nan)	GS 30.547 (30.547)	mem 40.059
Train: [64][650/750]	BT 0.144 (1.155)	DT 0.001 (1.027)	loss nan (nan)	prob nan (nan)	GS 34.391 (34.391)	mem 40.059
Train: [64][655/750]	BT 0.161 (1.147)	DT 0.013 (1.019)	loss nan (nan)	prob nan (nan)	GS 29.281 (29.281)	mem 40.094
Train: [64][660/750]	BT 0.094 (1.152)	DT 0.001 (1.024)	loss nan (nan)	prob nan (nan)	GS 31.672 (31.672)	mem 40.111
Train: [64][665/750]	BT 0.178 (1.146)	DT 0.033 (1.018)	loss nan (nan)	prob nan (nan)	GS 30.609 (30.609)	mem 40.048
Train: [64][670/750]	BT 0.096 (1.159)	DT 0.001 (1.031)	loss nan (nan)	prob nan (nan)	GS 34.281 (34.281)	mem 40.199
Train: [64][675/750]	BT 0.065 (1.151)	DT 0.001 (1.023)	loss nan (nan)	prob nan (nan)	GS 29.844 (29.844)	mem 40.152
Train: [64][680/750]	BT 8.380 (1.159)	DT 8.292 (1.032)	loss nan (nan)	prob nan (nan)	GS 35.531 (35.531)	mem 40.123
Train: [64][685/750]	BT 0.168 (1.152)	DT 0.002 (1.025)	loss nan (nan)	prob nan (nan)	GS 33.750 (33.750)	mem 40.196
Train: [64][690/750]	BT 0.178 (1.149)	DT 0.001 (1.021)	loss nan (nan)	prob nan (nan)	GS 31.203 (31.203)	mem 40.231
Train: [64][695/750]	BT 0.184 (1.152)	DT 0.002 (1.025)	loss nan (nan)	prob nan (nan)	GS 33.672 (33.672)	mem 40.077
Train: [64][700/750]	BT 2.519 (1.149)	DT 2.446 (1.021)	loss nan (nan)	prob nan (nan)	GS 31.812 (31.812)	mem 40.058
Train: [64][705/750]	BT 0.066 (1.155)	DT 0.002 (1.027)	loss nan (nan)	prob nan (nan)	GS 30.594 (30.594)	mem 40.122
arpack error, retry= 0
Train: [64][710/750]	BT 0.092 (1.148)	DT 0.002 (1.020)	loss nan (nan)	prob nan (nan)	GS 34.797 (34.797)	mem 40.048
Train: [64][715/750]	BT 0.209 (1.144)	DT 0.003 (1.017)	loss nan (nan)	prob nan (nan)	GS 28.250 (28.250)	mem 40.098
Train: [64][720/750]	BT 0.098 (1.152)	DT 0.002 (1.024)	loss nan (nan)	prob nan (nan)	GS 32.156 (32.156)	mem 40.211
Train: [64][725/750]	BT 0.164 (1.152)	DT 0.004 (1.024)	loss nan (nan)	prob nan (nan)	GS 38.094 (38.094)	mem 39.916
Train: [64][730/750]	BT 0.070 (1.154)	DT 0.001 (1.026)	loss nan (nan)	prob nan (nan)	GS 31.219 (31.219)	mem 39.709
Train: [64][735/750]	BT 0.087 (1.146)	DT 0.002 (1.019)	loss nan (nan)	prob nan (nan)	GS 30.547 (30.547)	mem 39.903
Train: [64][740/750]	BT 4.764 (1.147)	DT 4.685 (1.020)	loss nan (nan)	prob nan (nan)	GS 35.125 (35.125)	mem 7.762
Train: [64][745/750]	BT 0.074 (1.140)	DT 0.002 (1.013)	loss nan (nan)	prob nan (nan)	GS 29.625 (29.625)	mem 7.762
Train: [64][750/750]	BT 0.069 (1.133)	DT 0.001 (1.007)	loss nan (nan)	prob nan (nan)	GS 35.938 (35.938)	mem 7.762
Train: [64][755/750]	BT 0.069 (1.129)	DT 0.001 (1.003)	loss nan (nan)	prob nan (nan)	GS 35.125 (35.125)	mem 7.726
epoch 64, total time 852.77
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [65][1/750]	BT 20.657 (20.657)	DT 20.348 (20.348)	loss nan (nan)	prob nan (nan)	GS 30.750 (30.750)	mem 38.911
Train: [65][5/750]	BT 0.103 (4.952)	DT 0.002 (4.795)	loss nan (nan)	prob nan (nan)	GS 32.875 (32.875)	mem 39.022
Train: [65][10/750]	BT 0.089 (2.538)	DT 0.002 (2.400)	loss nan (nan)	prob nan (nan)	GS 29.891 (29.891)	mem 39.113
Train: [65][15/750]	BT 0.108 (2.508)	DT 0.001 (2.368)	loss nan (nan)	prob nan (nan)	GS 30.688 (30.688)	mem 39.577
Train: [65][20/750]	BT 0.263 (1.917)	DT 0.061 (1.780)	loss nan (nan)	prob nan (nan)	GS 36.672 (36.672)	mem 39.629
Train: [65][25/750]	BT 1.918 (1.656)	DT 1.753 (1.519)	loss nan (nan)	prob nan (nan)	GS 39.500 (39.500)	mem 39.710
Train: [65][30/750]	BT 0.088 (1.840)	DT 0.010 (1.704)	loss nan (nan)	prob nan (nan)	GS 34.797 (34.797)	mem 39.634
Train: [65][35/750]	BT 0.089 (1.599)	DT 0.002 (1.461)	loss nan (nan)	prob nan (nan)	GS 30.797 (30.797)	mem 39.636
Train: [65][40/750]	BT 0.104 (1.701)	DT 0.001 (1.566)	loss nan (nan)	prob nan (nan)	GS 29.703 (29.703)	mem 39.677
Train: [65][45/750]	BT 0.097 (1.534)	DT 0.002 (1.403)	loss nan (nan)	prob nan (nan)	GS 40.031 (40.031)	mem 39.682
Train: [65][50/750]	BT 9.667 (1.584)	DT 9.546 (1.454)	loss nan (nan)	prob nan (nan)	GS 31.906 (31.906)	mem 39.738
Train: [65][55/750]	BT 0.173 (1.454)	DT 0.002 (1.323)	loss nan (nan)	prob nan (nan)	GS 32.078 (32.078)	mem 39.741
Train: [65][60/750]	BT 0.138 (1.345)	DT 0.003 (1.213)	loss nan (nan)	prob nan (nan)	GS 30.266 (30.266)	mem 39.744
Train: [65][65/750]	BT 0.101 (1.410)	DT 0.002 (1.279)	loss nan (nan)	prob nan (nan)	GS 29.047 (29.047)	mem 39.829
Train: [65][70/750]	BT 0.103 (1.327)	DT 0.002 (1.196)	loss nan (nan)	prob nan (nan)	GS 31.219 (31.219)	mem 39.985
Train: [65][75/750]	BT 0.109 (1.390)	DT 0.006 (1.260)	loss nan (nan)	prob nan (nan)	GS 28.641 (28.641)	mem 39.886
Train: [65][80/750]	BT 0.210 (1.326)	DT 0.002 (1.196)	loss nan (nan)	prob nan (nan)	GS 32.562 (32.562)	mem 39.834
Train: [65][85/750]	BT 0.103 (1.255)	DT 0.002 (1.126)	loss nan (nan)	prob nan (nan)	GS 31.938 (31.938)	mem 39.954
Train: [65][90/750]	BT 0.137 (1.329)	DT 0.002 (1.198)	loss nan (nan)	prob nan (nan)	GS 33.250 (33.250)	mem 39.914
Train: [65][95/750]	BT 0.111 (1.268)	DT 0.002 (1.135)	loss nan (nan)	prob nan (nan)	GS 32.859 (32.859)	mem 40.025
Train: [65][100/750]	BT 0.120 (1.324)	DT 0.002 (1.192)	loss nan (nan)	prob nan (nan)	GS 37.266 (37.266)	mem 39.875
Train: [65][105/750]	BT 0.086 (1.274)	DT 0.001 (1.140)	loss nan (nan)	prob nan (nan)	GS 28.062 (28.062)	mem 39.856
Train: [65][110/750]	BT 11.057 (1.320)	DT 10.939 (1.188)	loss nan (nan)	prob nan (nan)	GS 33.859 (33.859)	mem 40.057
Train: [65][115/750]	BT 0.085 (1.274)	DT 0.001 (1.144)	loss nan (nan)	prob nan (nan)	GS 36.109 (36.109)	mem 39.854
Train: [65][120/750]	BT 0.223 (1.227)	DT 0.002 (1.096)	loss nan (nan)	prob nan (nan)	GS 37.031 (37.031)	mem 39.861
Train: [65][125/750]	BT 0.163 (1.286)	DT 0.002 (1.155)	loss nan (nan)	prob nan (nan)	GS 31.750 (31.750)	mem 39.893
Train: [65][130/750]	BT 0.084 (1.243)	DT 0.003 (1.111)	loss nan (nan)	prob nan (nan)	GS 34.844 (34.844)	mem 39.945
Train: [65][135/750]	BT 0.091 (1.223)	DT 0.002 (1.091)	loss nan (nan)	prob nan (nan)	GS 30.281 (30.281)	mem 39.931
Train: [65][140/750]	BT 0.081 (1.225)	DT 0.002 (1.093)	loss nan (nan)	prob nan (nan)	GS 33.219 (33.219)	mem 39.923
Train: [65][145/750]	BT 0.135 (1.188)	DT 0.006 (1.055)	loss nan (nan)	prob nan (nan)	GS 31.125 (31.125)	mem 40.035
Train: [65][150/750]	BT 2.823 (1.242)	DT 2.699 (1.109)	loss nan (nan)	prob nan (nan)	GS 35.156 (35.156)	mem 39.861
Train: [65][155/750]	BT 0.175 (1.207)	DT 0.017 (1.073)	loss nan (nan)	prob nan (nan)	GS 32.188 (32.188)	mem 39.936
Train: [65][160/750]	BT 3.948 (1.224)	DT 3.824 (1.089)	loss nan (nan)	prob nan (nan)	GS 32.766 (32.766)	mem 39.974
Train: [65][165/750]	BT 0.090 (1.215)	DT 0.002 (1.080)	loss nan (nan)	prob nan (nan)	GS 31.172 (31.172)	mem 39.904
Train: [65][170/750]	BT 3.425 (1.202)	DT 3.230 (1.067)	loss nan (nan)	prob nan (nan)	GS 34.797 (34.797)	mem 40.044
Train: [65][175/750]	BT 0.064 (1.213)	DT 0.001 (1.079)	loss nan (nan)	prob nan (nan)	GS 30.422 (30.422)	mem 40.078
Train: [65][180/750]	BT 0.086 (1.183)	DT 0.001 (1.049)	loss nan (nan)	prob nan (nan)	GS 31.000 (31.000)	mem 39.994
Train: [65][185/750]	BT 0.122 (1.213)	DT 0.001 (1.079)	loss nan (nan)	prob nan (nan)	GS 28.391 (28.391)	mem 39.973
Train: [65][190/750]	BT 0.174 (1.192)	DT 0.003 (1.058)	loss nan (nan)	prob nan (nan)	GS 35.953 (35.953)	mem 40.040
Train: [65][195/750]	BT 0.183 (1.179)	DT 0.002 (1.044)	loss nan (nan)	prob nan (nan)	GS 33.594 (33.594)	mem 40.120
Train: [65][200/750]	BT 0.105 (1.214)	DT 0.001 (1.079)	loss nan (nan)	prob nan (nan)	GS 40.422 (40.422)	mem 40.040
Train: [65][205/750]	BT 0.089 (1.188)	DT 0.002 (1.053)	loss nan (nan)	prob nan (nan)	GS 29.812 (29.812)	mem 39.977
Train: [65][210/750]	BT 2.970 (1.216)	DT 2.819 (1.081)	loss nan (nan)	prob nan (nan)	GS 31.906 (31.906)	mem 39.943
Train: [65][215/750]	BT 0.238 (1.191)	DT 0.004 (1.056)	loss nan (nan)	prob nan (nan)	GS 31.375 (31.375)	mem 40.004
Train: [65][220/750]	BT 7.505 (1.201)	DT 7.406 (1.066)	loss nan (nan)	prob nan (nan)	GS 37.062 (37.062)	mem 39.974
Train: [65][225/750]	BT 0.207 (1.195)	DT 0.022 (1.060)	loss nan (nan)	prob nan (nan)	GS 39.359 (39.359)	mem 39.944
Train: [65][230/750]	BT 0.126 (1.172)	DT 0.002 (1.037)	loss nan (nan)	prob nan (nan)	GS 34.359 (34.359)	mem 39.956
Train: [65][235/750]	BT 0.078 (1.198)	DT 0.001 (1.064)	loss nan (nan)	prob nan (nan)	GS 28.438 (28.438)	mem 39.932
Train: [65][240/750]	BT 0.078 (1.176)	DT 0.001 (1.042)	loss nan (nan)	prob nan (nan)	GS 30.672 (30.672)	mem 39.936
Train: [65][245/750]	BT 0.183 (1.185)	DT 0.008 (1.052)	loss nan (nan)	prob nan (nan)	GS 37.438 (37.438)	mem 39.885
Train: [65][250/750]	BT 0.079 (1.181)	DT 0.001 (1.048)	loss nan (nan)	prob nan (nan)	GS 37.781 (37.781)	mem 40.105
Train: [65][255/750]	BT 0.111 (1.161)	DT 0.002 (1.028)	loss nan (nan)	prob nan (nan)	GS 31.281 (31.281)	mem 40.282
Train: [65][260/750]	BT 0.113 (1.193)	DT 0.002 (1.061)	loss nan (nan)	prob nan (nan)	GS 37.078 (37.078)	mem 39.972
Train: [65][265/750]	BT 0.150 (1.173)	DT 0.009 (1.041)	loss nan (nan)	prob nan (nan)	GS 27.359 (27.359)	mem 40.080
Train: [65][270/750]	BT 0.475 (1.202)	DT 0.318 (1.069)	loss nan (nan)	prob nan (nan)	GS 33.078 (33.078)	mem 40.021
Train: [65][275/750]	BT 0.181 (1.182)	DT 0.002 (1.050)	loss nan (nan)	prob nan (nan)	GS 30.562 (30.562)	mem 40.072
Train: [65][280/750]	BT 11.031 (1.203)	DT 10.762 (1.070)	loss nan (nan)	prob nan (nan)	GS 32.406 (32.406)	mem 40.013
Train: [65][285/750]	BT 0.124 (1.184)	DT 0.002 (1.051)	loss nan (nan)	prob nan (nan)	GS 30.781 (30.781)	mem 39.980
Train: [65][290/750]	BT 0.116 (1.166)	DT 0.025 (1.033)	loss nan (nan)	prob nan (nan)	GS 35.141 (35.141)	mem 39.983
Train: [65][295/750]	BT 0.133 (1.196)	DT 0.001 (1.064)	loss nan (nan)	prob nan (nan)	GS 31.812 (31.812)	mem 40.020
Train: [65][300/750]	BT 0.114 (1.178)	DT 0.001 (1.046)	loss nan (nan)	prob nan (nan)	GS 37.797 (37.797)	mem 40.023
Train: [65][305/750]	BT 0.075 (1.192)	DT 0.001 (1.059)	loss nan (nan)	prob nan (nan)	GS 32.422 (32.422)	mem 40.065
Train: [65][310/750]	BT 0.109 (1.175)	DT 0.010 (1.042)	loss nan (nan)	prob nan (nan)	GS 33.484 (33.484)	mem 40.066
Train: [65][315/750]	BT 0.287 (1.158)	DT 0.002 (1.026)	loss nan (nan)	prob nan (nan)	GS 25.125 (25.125)	mem 40.068
Train: [65][320/750]	BT 0.110 (1.182)	DT 0.002 (1.051)	loss nan (nan)	prob nan (nan)	GS 30.281 (30.281)	mem 39.962
Train: [65][325/750]	BT 0.143 (1.166)	DT 0.001 (1.034)	loss nan (nan)	prob nan (nan)	GS 33.391 (33.391)	mem 39.995
Train: [65][330/750]	BT 0.106 (1.178)	DT 0.001 (1.047)	loss nan (nan)	prob nan (nan)	GS 33.500 (33.500)	mem 40.032
Train: [65][335/750]	BT 0.127 (1.162)	DT 0.002 (1.031)	loss nan (nan)	prob nan (nan)	GS 32.672 (32.672)	mem 40.032
Train: [65][340/750]	BT 11.619 (1.180)	DT 11.421 (1.050)	loss nan (nan)	prob nan (nan)	GS 30.000 (30.000)	mem 40.043
Train: [65][345/750]	BT 0.082 (1.167)	DT 0.001 (1.037)	loss nan (nan)	prob nan (nan)	GS 31.766 (31.766)	mem 40.045
Train: [65][350/750]	BT 0.208 (1.153)	DT 0.013 (1.023)	loss nan (nan)	prob nan (nan)	GS 35.547 (35.547)	mem 40.111
Train: [65][355/750]	BT 0.130 (1.168)	DT 0.009 (1.038)	loss nan (nan)	prob nan (nan)	GS 35.016 (35.016)	mem 40.073
Train: [65][360/750]	BT 0.090 (1.155)	DT 0.002 (1.024)	loss nan (nan)	prob nan (nan)	GS 35.062 (35.062)	mem 40.108
Train: [65][365/750]	BT 0.178 (1.168)	DT 0.010 (1.037)	loss nan (nan)	prob nan (nan)	GS 27.266 (27.266)	mem 40.192
Train: [65][370/750]	BT 1.140 (1.160)	DT 0.985 (1.029)	loss nan (nan)	prob nan (nan)	GS 33.984 (33.984)	mem 40.122
Train: [65][375/750]	BT 0.108 (1.147)	DT 0.002 (1.015)	loss nan (nan)	prob nan (nan)	GS 35.312 (35.312)	mem 40.119
Train: [65][380/750]	BT 0.071 (1.159)	DT 0.002 (1.028)	loss nan (nan)	prob nan (nan)	GS 29.750 (29.750)	mem 40.100
Train: [65][385/750]	BT 0.177 (1.146)	DT 0.002 (1.015)	loss nan (nan)	prob nan (nan)	GS 32.281 (32.281)	mem 40.100
Train: [65][390/750]	BT 2.747 (1.166)	DT 2.566 (1.035)	loss nan (nan)	prob nan (nan)	GS 36.516 (36.516)	mem 40.170
Train: [65][395/750]	BT 0.135 (1.155)	DT 0.008 (1.024)	loss nan (nan)	prob nan (nan)	GS 34.516 (34.516)	mem 40.115
Train: [65][400/750]	BT 2.680 (1.153)	DT 2.428 (1.021)	loss nan (nan)	prob nan (nan)	GS 33.922 (33.922)	mem 40.320
Train: [65][405/750]	BT 0.249 (1.164)	DT 0.012 (1.032)	loss nan (nan)	prob nan (nan)	GS 30.391 (30.391)	mem 40.244
Train: [65][410/750]	BT 0.088 (1.154)	DT 0.001 (1.022)	loss nan (nan)	prob nan (nan)	GS 36.688 (36.688)	mem 40.140
Train: [65][415/750]	BT 0.236 (1.153)	DT 0.002 (1.021)	loss nan (nan)	prob nan (nan)	GS 30.156 (30.156)	mem 40.205
Train: [65][420/750]	BT 4.224 (1.156)	DT 4.035 (1.024)	loss nan (nan)	prob nan (nan)	GS 36.500 (36.500)	mem 40.020
Train: [65][425/750]	BT 0.146 (1.148)	DT 0.011 (1.016)	loss nan (nan)	prob nan (nan)	GS 31.641 (31.641)	mem 40.147
Train: [65][430/750]	BT 0.135 (1.154)	DT 0.001 (1.022)	loss nan (nan)	prob nan (nan)	GS 36.688 (36.688)	mem 40.214
Train: [65][435/750]	BT 0.172 (1.154)	DT 0.011 (1.022)	loss nan (nan)	prob nan (nan)	GS 28.188 (28.188)	mem 40.158
Train: [65][440/750]	BT 6.440 (1.157)	DT 6.229 (1.025)	loss nan (nan)	prob nan (nan)	GS 32.281 (32.281)	mem 40.070
Train: [65][445/750]	BT 0.090 (1.146)	DT 0.002 (1.013)	loss nan (nan)	prob nan (nan)	GS 31.078 (31.078)	mem 40.073
Train: [65][450/750]	BT 2.361 (1.146)	DT 2.242 (1.014)	loss nan (nan)	prob nan (nan)	GS 30.469 (30.469)	mem 40.232
Train: [65][455/750]	BT 0.147 (1.159)	DT 0.002 (1.027)	loss nan (nan)	prob nan (nan)	GS 31.859 (31.859)	mem 40.048
Train: [65][460/750]	BT 0.128 (1.148)	DT 0.010 (1.016)	loss nan (nan)	prob nan (nan)	GS 32.469 (32.469)	mem 40.176
Train: [65][465/750]	BT 0.225 (1.160)	DT 0.001 (1.028)	loss nan (nan)	prob nan (nan)	GS 28.391 (28.391)	mem 40.116
Train: [65][470/750]	BT 0.311 (1.150)	DT 0.197 (1.017)	loss nan (nan)	prob nan (nan)	GS 33.281 (33.281)	mem 40.251
Train: [65][475/750]	BT 0.086 (1.139)	DT 0.002 (1.007)	loss nan (nan)	prob nan (nan)	GS 30.891 (30.891)	mem 40.172
Train: [65][480/750]	BT 0.178 (1.156)	DT 0.002 (1.023)	loss nan (nan)	prob nan (nan)	GS 36.531 (36.531)	mem 40.149
Train: [65][485/750]	BT 0.146 (1.145)	DT 0.001 (1.013)	loss nan (nan)	prob nan (nan)	GS 29.094 (29.094)	mem 40.338
Train: [65][490/750]	BT 0.065 (1.158)	DT 0.001 (1.027)	loss nan (nan)	prob nan (nan)	GS 36.984 (36.984)	mem 40.113
Train: [65][495/750]	BT 0.086 (1.148)	DT 0.004 (1.016)	loss nan (nan)	prob nan (nan)	GS 34.031 (34.031)	mem 40.119
Train: [65][500/750]	BT 8.805 (1.156)	DT 8.649 (1.024)	loss nan (nan)	prob nan (nan)	GS 29.203 (29.203)	mem 40.135
Train: [65][505/750]	BT 0.256 (1.153)	DT 0.005 (1.020)	loss nan (nan)	prob nan (nan)	GS 34.609 (34.609)	mem 40.152
Train: [65][510/750]	BT 0.096 (1.143)	DT 0.001 (1.010)	loss nan (nan)	prob nan (nan)	GS 31.953 (31.953)	mem 40.271
Train: [65][515/750]	BT 0.093 (1.146)	DT 0.002 (1.014)	loss nan (nan)	prob nan (nan)	GS 25.266 (25.266)	mem 40.264
Train: [65][520/750]	BT 0.223 (1.148)	DT 0.015 (1.015)	loss nan (nan)	prob nan (nan)	GS 32.250 (32.250)	mem 40.222
Train: [65][525/750]	BT 0.126 (1.155)	DT 0.004 (1.023)	loss nan (nan)	prob nan (nan)	GS 31.516 (31.516)	mem 40.060
Train: [65][530/750]	BT 0.112 (1.145)	DT 0.001 (1.013)	loss nan (nan)	prob nan (nan)	GS 33.891 (33.891)	mem 40.110
Train: [65][535/750]	BT 0.314 (1.136)	DT 0.006 (1.004)	loss nan (nan)	prob nan (nan)	GS 31.391 (31.391)	mem 40.105
Train: [65][540/750]	BT 1.796 (1.156)	DT 1.690 (1.024)	loss nan (nan)	prob nan (nan)	GS 32.391 (32.391)	mem 40.093
Train: [65][545/750]	BT 0.215 (1.147)	DT 0.011 (1.014)	loss nan (nan)	prob nan (nan)	GS 34.219 (34.219)	mem 40.129
Train: [65][550/750]	BT 0.108 (1.148)	DT 0.002 (1.015)	loss nan (nan)	prob nan (nan)	GS 33.609 (33.609)	mem 40.106
Train: [65][555/750]	BT 0.129 (1.146)	DT 0.002 (1.014)	loss nan (nan)	prob nan (nan)	GS 33.688 (33.688)	mem 40.088
Train: [65][560/750]	BT 8.388 (1.151)	DT 8.245 (1.019)	loss nan (nan)	prob nan (nan)	GS 36.000 (36.000)	mem 40.341
Train: [65][565/750]	BT 0.099 (1.146)	DT 0.002 (1.014)	loss nan (nan)	prob nan (nan)	GS 29.797 (29.797)	mem 40.083
Train: [65][570/750]	BT 0.126 (1.137)	DT 0.002 (1.005)	loss nan (nan)	prob nan (nan)	GS 34.375 (34.375)	mem 40.084
Train: [65][575/750]	BT 0.157 (1.143)	DT 0.001 (1.011)	loss nan (nan)	prob nan (nan)	GS 30.750 (30.750)	mem 40.091
Train: [65][580/750]	BT 0.134 (1.140)	DT 0.013 (1.008)	loss nan (nan)	prob nan (nan)	GS 34.438 (34.438)	mem 40.053
Train: [65][585/750]	BT 0.158 (1.144)	DT 0.001 (1.012)	loss nan (nan)	prob nan (nan)	GS 33.156 (33.156)	mem 40.201
Train: [65][590/750]	BT 3.988 (1.144)	DT 3.844 (1.012)	loss nan (nan)	prob nan (nan)	GS 36.078 (36.078)	mem 40.194
Train: [65][595/750]	BT 0.241 (1.135)	DT 0.001 (1.004)	loss nan (nan)	prob nan (nan)	GS 31.906 (31.906)	mem 40.258
Train: [65][600/750]	BT 0.366 (1.140)	DT 0.265 (1.008)	loss nan (nan)	prob nan (nan)	GS 32.625 (32.625)	mem 40.145
Train: [65][605/750]	BT 0.148 (1.143)	DT 0.002 (1.010)	loss nan (nan)	prob nan (nan)	GS 31.141 (31.141)	mem 40.311
Train: [65][610/750]	BT 0.078 (1.148)	DT 0.001 (1.016)	loss nan (nan)	prob nan (nan)	GS 33.750 (33.750)	mem 40.261
Train: [65][615/750]	BT 0.091 (1.144)	DT 0.002 (1.012)	loss nan (nan)	prob nan (nan)	GS 29.609 (29.609)	mem 39.982
Train: [65][620/750]	BT 8.755 (1.150)	DT 8.628 (1.018)	loss nan (nan)	prob nan (nan)	GS 33.438 (33.438)	mem 40.083
Train: [65][625/750]	BT 0.096 (1.141)	DT 0.002 (1.010)	loss nan (nan)	prob nan (nan)	GS 31.297 (31.297)	mem 40.083
Train: [65][630/750]	BT 0.183 (1.144)	DT 0.019 (1.012)	loss nan (nan)	prob nan (nan)	GS 35.031 (35.031)	mem 40.161
Train: [65][635/750]	BT 0.074 (1.136)	DT 0.001 (1.004)	loss nan (nan)	prob nan (nan)	GS 31.094 (31.094)	mem 40.068
Train: [65][640/750]	BT 0.083 (1.147)	DT 0.002 (1.016)	loss nan (nan)	prob nan (nan)	GS 31.625 (31.625)	mem 40.198
Train: [65][645/750]	BT 0.173 (1.139)	DT 0.010 (1.008)	loss nan (nan)	prob nan (nan)	GS 33.219 (33.219)	mem 40.345
Train: [65][650/750]	BT 11.576 (1.151)	DT 11.475 (1.020)	loss nan (nan)	prob nan (nan)	GS 34.828 (34.828)	mem 40.072
Train: [65][655/750]	BT 0.150 (1.143)	DT 0.016 (1.012)	loss nan (nan)	prob nan (nan)	GS 28.984 (28.984)	mem 40.076
Train: [65][660/750]	BT 0.128 (1.136)	DT 0.011 (1.004)	loss nan (nan)	prob nan (nan)	GS 35.219 (35.219)	mem 40.077
Train: [65][665/750]	BT 0.198 (1.145)	DT 0.002 (1.014)	loss nan (nan)	prob nan (nan)	GS 30.312 (30.312)	mem 40.336
Train: [65][670/750]	BT 0.097 (1.138)	DT 0.001 (1.007)	loss nan (nan)	prob nan (nan)	GS 36.734 (36.734)	mem 40.104
Train: [65][675/750]	BT 0.143 (1.148)	DT 0.008 (1.017)	loss nan (nan)	prob nan (nan)	GS 34.531 (34.531)	mem 40.060
Train: [65][680/750]	BT 0.130 (1.140)	DT 0.010 (1.009)	loss nan (nan)	prob nan (nan)	GS 34.609 (34.609)	mem 40.088
Train: [65][685/750]	BT 0.189 (1.138)	DT 0.002 (1.007)	loss nan (nan)	prob nan (nan)	GS 25.922 (25.922)	mem 40.094
Train: [65][690/750]	BT 0.072 (1.145)	DT 0.001 (1.014)	loss nan (nan)	prob nan (nan)	GS 34.000 (34.000)	mem 40.022
Train: [65][695/750]	BT 0.227 (1.138)	DT 0.038 (1.007)	loss nan (nan)	prob nan (nan)	GS 29.938 (29.938)	mem 40.344
Train: [65][700/750]	BT 0.094 (1.147)	DT 0.001 (1.017)	loss nan (nan)	prob nan (nan)	GS 33.375 (33.375)	mem 39.970
Train: [65][705/750]	BT 0.125 (1.140)	DT 0.002 (1.009)	loss nan (nan)	prob nan (nan)	GS 35.406 (35.406)	mem 39.974
Train: [65][710/750]	BT 8.907 (1.146)	DT 8.767 (1.015)	loss nan (nan)	prob nan (nan)	GS 31.781 (31.781)	mem 40.069
Train: [65][715/750]	BT 0.087 (1.139)	DT 0.001 (1.008)	loss nan (nan)	prob nan (nan)	GS 27.969 (27.969)	mem 39.994
Train: [65][720/750]	BT 2.677 (1.135)	DT 2.575 (1.005)	loss nan (nan)	prob nan (nan)	GS 33.281 (33.281)	mem 40.072
Train: [65][725/750]	BT 0.113 (1.142)	DT 0.001 (1.011)	loss nan (nan)	prob nan (nan)	GS 29.938 (29.938)	mem 39.897
Train: [65][730/750]	BT 0.094 (1.135)	DT 0.002 (1.004)	loss nan (nan)	prob nan (nan)	GS 33.594 (33.594)	mem 39.903
Train: [65][735/750]	BT 0.090 (1.141)	DT 0.001 (1.010)	loss nan (nan)	prob nan (nan)	GS 37.000 (37.000)	mem 36.582
Train: [65][740/750]	BT 0.071 (1.133)	DT 0.001 (1.003)	loss nan (nan)	prob nan (nan)	GS 33.891 (33.891)	mem 36.483
Train: [65][745/750]	BT 0.091 (1.127)	DT 0.001 (0.997)	loss nan (nan)	prob nan (nan)	GS 34.719 (34.719)	mem 10.669
Train: [65][750/750]	BT 0.070 (1.123)	DT 0.002 (0.993)	loss nan (nan)	prob nan (nan)	GS 38.344 (38.344)	mem 10.633
Train: [65][755/750]	BT 0.058 (1.116)	DT 0.001 (0.987)	loss nan (nan)	prob nan (nan)	GS 29.750 (29.750)	mem 10.597
epoch 65, total time 842.91
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [66][1/750]	BT 20.959 (20.959)	DT 20.853 (20.853)	loss nan (nan)	prob nan (nan)	GS 30.719 (30.719)	mem 38.632
Train: [66][5/750]	BT 0.196 (5.474)	DT 0.009 (5.314)	loss nan (nan)	prob nan (nan)	GS 29.828 (29.828)	mem 38.753
Train: [66][10/750]	BT 0.226 (2.818)	DT 0.008 (2.659)	loss nan (nan)	prob nan (nan)	GS 37.250 (37.250)	mem 39.093
Train: [66][15/750]	BT 0.096 (2.541)	DT 0.001 (2.378)	loss nan (nan)	prob nan (nan)	GS 26.672 (26.672)	mem 38.793
Train: [66][20/750]	BT 0.146 (1.958)	DT 0.013 (1.786)	loss nan (nan)	prob nan (nan)	GS 32.469 (32.469)	mem 38.834
Train: [66][25/750]	BT 0.120 (1.685)	DT 0.034 (1.517)	loss nan (nan)	prob nan (nan)	GS 30.781 (30.781)	mem 39.139
Train: [66][30/750]	BT 0.187 (1.951)	DT 0.003 (1.790)	loss nan (nan)	prob nan (nan)	GS 30.984 (30.984)	mem 39.134
Train: [66][35/750]	BT 0.111 (1.695)	DT 0.002 (1.534)	loss nan (nan)	prob nan (nan)	GS 29.438 (29.438)	mem 38.976
Train: [66][40/750]	BT 0.105 (1.758)	DT 0.004 (1.602)	loss nan (nan)	prob nan (nan)	GS 35.859 (35.859)	mem 38.954
Train: [66][45/750]	BT 0.118 (1.578)	DT 0.002 (1.424)	loss nan (nan)	prob nan (nan)	GS 27.734 (27.734)	mem 39.071
Train: [66][50/750]	BT 9.690 (1.629)	DT 9.571 (1.474)	loss nan (nan)	prob nan (nan)	GS 32.875 (32.875)	mem 39.138
Train: [66][55/750]	BT 0.088 (1.490)	DT 0.001 (1.340)	loss nan (nan)	prob nan (nan)	GS 33.297 (33.297)	mem 39.033
Train: [66][60/750]	BT 0.164 (1.446)	DT 0.005 (1.295)	loss nan (nan)	prob nan (nan)	GS 32.922 (32.922)	mem 39.047
Train: [66][65/750]	BT 0.210 (1.446)	DT 0.002 (1.296)	loss nan (nan)	prob nan (nan)	GS 27.719 (27.719)	mem 39.144
Train: [66][70/750]	BT 4.371 (1.443)	DT 4.265 (1.295)	loss nan (nan)	prob nan (nan)	GS 34.297 (34.297)	mem 39.056
Train: [66][75/750]	BT 0.201 (1.384)	DT 0.002 (1.238)	loss nan (nan)	prob nan (nan)	GS 29.203 (29.203)	mem 39.182
Train: [66][80/750]	BT 6.227 (1.420)	DT 6.140 (1.274)	loss nan (nan)	prob nan (nan)	GS 34.562 (34.562)	mem 39.152
Train: [66][85/750]	BT 0.241 (1.363)	DT 0.019 (1.217)	loss nan (nan)	prob nan (nan)	GS 28.875 (28.875)	mem 39.180
Train: [66][90/750]	BT 0.238 (1.349)	DT 0.002 (1.203)	loss nan (nan)	prob nan (nan)	GS 34.109 (34.109)	mem 39.460
Train: [66][95/750]	BT 0.076 (1.370)	DT 0.001 (1.224)	loss nan (nan)	prob nan (nan)	GS 32.578 (32.578)	mem 39.232
Train: [66][100/750]	BT 6.806 (1.376)	DT 6.692 (1.231)	loss nan (nan)	prob nan (nan)	GS 35.062 (35.062)	mem 39.356
Train: [66][105/750]	BT 0.122 (1.315)	DT 0.001 (1.172)	loss nan (nan)	prob nan (nan)	GS 31.203 (31.203)	mem 39.232
Train: [66][110/750]	BT 0.199 (1.320)	DT 0.051 (1.177)	loss nan (nan)	prob nan (nan)	GS 33.953 (33.953)	mem 39.486
Train: [66][115/750]	BT 0.170 (1.340)	DT 0.001 (1.197)	loss nan (nan)	prob nan (nan)	GS 35.672 (35.672)	mem 39.177
Train: [66][120/750]	BT 0.103 (1.289)	DT 0.001 (1.147)	loss nan (nan)	prob nan (nan)	GS 35.359 (35.359)	mem 39.239
Train: [66][125/750]	BT 0.151 (1.321)	DT 0.002 (1.178)	loss nan (nan)	prob nan (nan)	GS 32.016 (32.016)	mem 39.314
Train: [66][130/750]	BT 4.414 (1.309)	DT 4.242 (1.166)	loss nan (nan)	prob nan (nan)	GS 36.312 (36.312)	mem 39.549
Train: [66][135/750]	BT 0.099 (1.265)	DT 0.008 (1.123)	loss nan (nan)	prob nan (nan)	GS 27.391 (27.391)	mem 39.358
Train: [66][140/750]	BT 2.981 (1.281)	DT 2.794 (1.139)	loss nan (nan)	prob nan (nan)	GS 35.359 (35.359)	mem 39.597
Train: [66][145/750]	BT 0.192 (1.258)	DT 0.002 (1.117)	loss nan (nan)	prob nan (nan)	GS 33.234 (33.234)	mem 39.558
Train: [66][150/750]	BT 0.208 (1.309)	DT 0.002 (1.169)	loss nan (nan)	prob nan (nan)	GS 34.703 (34.703)	mem 39.685
Train: [66][155/750]	BT 0.086 (1.274)	DT 0.001 (1.134)	loss nan (nan)	prob nan (nan)	GS 31.469 (31.469)	mem 39.521
Train: [66][160/750]	BT 8.269 (1.308)	DT 8.121 (1.169)	loss nan (nan)	prob nan (nan)	GS 32.109 (32.109)	mem 39.799
Train: [66][165/750]	BT 0.122 (1.284)	DT 0.020 (1.145)	loss nan (nan)	prob nan (nan)	GS 31.234 (31.234)	mem 39.545
Train: [66][170/750]	BT 1.744 (1.259)	DT 1.640 (1.121)	loss nan (nan)	prob nan (nan)	GS 35.531 (35.531)	mem 39.678
Train: [66][175/750]	BT 0.224 (1.292)	DT 0.011 (1.153)	loss nan (nan)	prob nan (nan)	GS 31.078 (31.078)	mem 39.593
Train: [66][180/750]	BT 0.125 (1.260)	DT 0.002 (1.121)	loss nan (nan)	prob nan (nan)	GS 34.547 (34.547)	mem 39.600
Train: [66][185/750]	BT 0.132 (1.271)	DT 0.026 (1.132)	loss nan (nan)	prob nan (nan)	GS 28.781 (28.781)	mem 39.881
Train: [66][190/750]	BT 0.075 (1.271)	DT 0.001 (1.133)	loss nan (nan)	prob nan (nan)	GS 34.812 (34.812)	mem 39.851
Train: [66][195/750]	BT 0.155 (1.242)	DT 0.002 (1.104)	loss nan (nan)	prob nan (nan)	GS 35.891 (35.891)	mem 39.850
Train: [66][200/750]	BT 0.371 (1.275)	DT 0.259 (1.135)	loss nan (nan)	prob nan (nan)	GS 36.203 (36.203)	mem 39.856
Train: [66][205/750]	BT 0.230 (1.247)	DT 0.008 (1.108)	loss nan (nan)	prob nan (nan)	GS 29.922 (29.922)	mem 39.812
Train: [66][210/750]	BT 6.503 (1.272)	DT 6.400 (1.133)	loss nan (nan)	prob nan (nan)	GS 35.172 (35.172)	mem 39.876
Train: [66][215/750]	BT 0.156 (1.252)	DT 0.002 (1.113)	loss nan (nan)	prob nan (nan)	GS 26.812 (26.812)	mem 39.860
Train: [66][220/750]	BT 0.095 (1.235)	DT 0.002 (1.098)	loss nan (nan)	prob nan (nan)	GS 33.234 (33.234)	mem 39.997
Train: [66][225/750]	BT 0.111 (1.244)	DT 0.002 (1.107)	loss nan (nan)	prob nan (nan)	GS 32.562 (32.562)	mem 39.895
Train: [66][230/750]	BT 0.228 (1.226)	DT 0.050 (1.089)	loss nan (nan)	prob nan (nan)	GS 33.031 (33.031)	mem 39.948
Train: [66][235/750]	BT 0.084 (1.235)	DT 0.002 (1.099)	loss nan (nan)	prob nan (nan)	GS 31.016 (31.016)	mem 39.870
Train: [66][240/750]	BT 0.092 (1.228)	DT 0.002 (1.093)	loss nan (nan)	prob nan (nan)	GS 31.438 (31.438)	mem 39.929
Train: [66][245/750]	BT 0.136 (1.234)	DT 0.004 (1.099)	loss nan (nan)	prob nan (nan)	GS 29.453 (29.453)	mem 39.942
Train: [66][250/750]	BT 2.883 (1.223)	DT 2.763 (1.088)	loss nan (nan)	prob nan (nan)	GS 35.750 (35.750)	mem 39.971
Train: [66][255/750]	BT 0.133 (1.204)	DT 0.012 (1.070)	loss nan (nan)	prob nan (nan)	GS 34.297 (34.297)	mem 39.912
Train: [66][260/750]	BT 0.743 (1.216)	DT 0.554 (1.081)	loss nan (nan)	prob nan (nan)	GS 31.422 (31.422)	mem 40.011
Train: [66][265/750]	BT 0.115 (1.225)	DT 0.003 (1.090)	loss nan (nan)	prob nan (nan)	GS 34.188 (34.188)	mem 39.913
Train: [66][270/750]	BT 3.987 (1.220)	DT 3.864 (1.086)	loss nan (nan)	prob nan (nan)	GS 35.609 (35.609)	mem 39.974
Train: [66][275/750]	BT 0.202 (1.221)	DT 0.001 (1.086)	loss nan (nan)	prob nan (nan)	GS 37.734 (37.734)	mem 39.999
Train: [66][280/750]	BT 4.402 (1.217)	DT 4.265 (1.082)	loss nan (nan)	prob nan (nan)	GS 35.531 (35.531)	mem 39.929
Train: [66][285/750]	BT 0.155 (1.210)	DT 0.004 (1.075)	loss nan (nan)	prob nan (nan)	GS 34.984 (34.984)	mem 40.018
Train: [66][290/750]	BT 0.093 (1.209)	DT 0.002 (1.074)	loss nan (nan)	prob nan (nan)	GS 34.547 (34.547)	mem 39.984
Train: [66][295/750]	BT 0.069 (1.229)	DT 0.001 (1.095)	loss nan (nan)	prob nan (nan)	GS 33.266 (33.266)	mem 39.958
Train: [66][300/750]	BT 0.130 (1.211)	DT 0.001 (1.077)	loss nan (nan)	prob nan (nan)	GS 34.156 (34.156)	mem 39.960
Train: [66][305/750]	BT 0.138 (1.217)	DT 0.006 (1.083)	loss nan (nan)	prob nan (nan)	GS 30.906 (30.906)	mem 40.029
Train: [66][310/750]	BT 0.075 (1.212)	DT 0.001 (1.078)	loss nan (nan)	prob nan (nan)	GS 33.422 (33.422)	mem 40.070
Train: [66][315/750]	BT 0.101 (1.194)	DT 0.002 (1.061)	loss nan (nan)	prob nan (nan)	GS 32.156 (32.156)	mem 40.017
Train: [66][320/750]	BT 0.126 (1.210)	DT 0.001 (1.077)	loss nan (nan)	prob nan (nan)	GS 28.906 (28.906)	mem 40.080
Train: [66][325/750]	BT 0.171 (1.193)	DT 0.002 (1.060)	loss nan (nan)	prob nan (nan)	GS 29.516 (29.516)	mem 40.191
Train: [66][330/750]	BT 1.242 (1.223)	DT 1.161 (1.090)	loss nan (nan)	prob nan (nan)	GS 34.562 (34.562)	mem 40.167
Train: [66][335/750]	BT 0.099 (1.207)	DT 0.005 (1.074)	loss nan (nan)	prob nan (nan)	GS 30.812 (30.812)	mem 40.074
Train: [66][340/750]	BT 11.232 (1.224)	DT 11.140 (1.091)	loss nan (nan)	prob nan (nan)	GS 27.078 (27.078)	mem 40.075
Train: [66][345/750]	BT 0.121 (1.208)	DT 0.002 (1.076)	loss nan (nan)	prob nan (nan)	GS 35.391 (35.391)	mem 40.022
Train: [66][350/750]	BT 0.089 (1.193)	DT 0.001 (1.060)	loss nan (nan)	prob nan (nan)	GS 34.172 (34.172)	mem 40.025
Train: [66][355/750]	BT 0.190 (1.211)	DT 0.002 (1.079)	loss nan (nan)	prob nan (nan)	GS 32.047 (32.047)	mem 40.214
Train: [66][360/750]	BT 0.212 (1.197)	DT 0.007 (1.064)	loss nan (nan)	prob nan (nan)	GS 28.406 (28.406)	mem 40.097
Train: [66][365/750]	BT 0.125 (1.213)	DT 0.002 (1.079)	loss nan (nan)	prob nan (nan)	GS 30.203 (30.203)	mem 40.163
Train: [66][370/750]	BT 0.144 (1.202)	DT 0.001 (1.069)	loss nan (nan)	prob nan (nan)	GS 29.891 (29.891)	mem 40.113
Train: [66][375/750]	BT 0.157 (1.188)	DT 0.001 (1.055)	loss nan (nan)	prob nan (nan)	GS 33.750 (33.750)	mem 40.091
Train: [66][380/750]	BT 0.092 (1.205)	DT 0.001 (1.073)	loss nan (nan)	prob nan (nan)	GS 35.703 (35.703)	mem 40.049
Train: [66][385/750]	BT 0.089 (1.191)	DT 0.001 (1.059)	loss nan (nan)	prob nan (nan)	GS 28.469 (28.469)	mem 40.051
Train: [66][390/750]	BT 0.518 (1.205)	DT 0.320 (1.072)	loss nan (nan)	prob nan (nan)	GS 33.359 (33.359)	mem 40.237
Train: [66][395/750]	BT 0.089 (1.191)	DT 0.001 (1.059)	loss nan (nan)	prob nan (nan)	GS 25.547 (25.547)	mem 40.134
Train: [66][400/750]	BT 12.551 (1.209)	DT 12.419 (1.077)	loss nan (nan)	prob nan (nan)	GS 37.391 (37.391)	mem 40.110
Train: [66][405/750]	BT 0.155 (1.196)	DT 0.002 (1.064)	loss nan (nan)	prob nan (nan)	GS 34.469 (34.469)	mem 40.233
Train: [66][410/750]	BT 0.134 (1.183)	DT 0.005 (1.051)	loss nan (nan)	prob nan (nan)	GS 36.609 (36.609)	mem 40.176
Train: [66][415/750]	BT 0.082 (1.196)	DT 0.002 (1.063)	loss nan (nan)	prob nan (nan)	GS 30.625 (30.625)	mem 40.044
Train: [66][420/750]	BT 0.080 (1.183)	DT 0.002 (1.051)	loss nan (nan)	prob nan (nan)	GS 32.453 (32.453)	mem 40.044
Train: [66][425/750]	BT 0.120 (1.201)	DT 0.002 (1.069)	loss nan (nan)	prob nan (nan)	GS 38.406 (38.406)	mem 40.337
Train: [66][430/750]	BT 0.140 (1.190)	DT 0.007 (1.058)	loss nan (nan)	prob nan (nan)	GS 31.172 (31.172)	mem 40.099
Train: [66][435/750]	BT 0.140 (1.178)	DT 0.002 (1.045)	loss nan (nan)	prob nan (nan)	GS 35.797 (35.797)	mem 40.099
Train: [66][440/750]	BT 0.096 (1.193)	DT 0.001 (1.061)	loss nan (nan)	prob nan (nan)	GS 38.469 (38.469)	mem 40.113
Train: [66][445/750]	BT 0.298 (1.182)	DT 0.016 (1.049)	loss nan (nan)	prob nan (nan)	GS 50.000 (50.000)	mem 40.115
Train: [66][450/750]	BT 4.039 (1.199)	DT 3.949 (1.066)	loss nan (nan)	prob nan (nan)	GS 33.766 (33.766)	mem 40.071
Train: [66][455/750]	BT 0.095 (1.187)	DT 0.004 (1.054)	loss nan (nan)	prob nan (nan)	GS 29.797 (29.797)	mem 40.121
Train: [66][460/750]	BT 8.042 (1.193)	DT 7.883 (1.060)	loss nan (nan)	prob nan (nan)	GS 34.297 (34.297)	mem 40.278
Train: [66][465/750]	BT 0.108 (1.188)	DT 0.002 (1.055)	loss nan (nan)	prob nan (nan)	GS 30.547 (30.547)	mem 40.104
Train: [66][470/750]	BT 0.189 (1.178)	DT 0.002 (1.044)	loss nan (nan)	prob nan (nan)	GS 35.562 (35.562)	mem 40.137
Train: [66][475/750]	BT 0.266 (1.193)	DT 0.027 (1.059)	loss nan (nan)	prob nan (nan)	GS 28.641 (28.641)	mem 40.144
Train: [66][480/750]	BT 0.177 (1.182)	DT 0.012 (1.048)	loss nan (nan)	prob nan (nan)	GS 32.031 (32.031)	mem 40.368
Train: [66][485/750]	BT 0.126 (1.185)	DT 0.002 (1.050)	loss nan (nan)	prob nan (nan)	GS 34.016 (34.016)	mem 40.445
Train: [66][490/750]	BT 0.154 (1.185)	DT 0.001 (1.051)	loss nan (nan)	prob nan (nan)	GS 30.844 (30.844)	mem 40.075
Train: [66][495/750]	BT 0.106 (1.174)	DT 0.003 (1.041)	loss nan (nan)	prob nan (nan)	GS 30.500 (30.500)	mem 40.076
Train: [66][500/750]	BT 0.159 (1.181)	DT 0.011 (1.047)	loss nan (nan)	prob nan (nan)	GS 36.078 (36.078)	mem 40.067
Train: [66][505/750]	BT 0.130 (1.171)	DT 0.002 (1.036)	loss nan (nan)	prob nan (nan)	GS 31.453 (31.453)	mem 40.057
Train: [66][510/750]	BT 2.431 (1.180)	DT 2.270 (1.045)	loss nan (nan)	prob nan (nan)	GS 33.391 (33.391)	mem 40.064
Train: [66][515/750]	BT 0.127 (1.169)	DT 0.006 (1.035)	loss nan (nan)	prob nan (nan)	GS 28.734 (28.734)	mem 40.081
Train: [66][520/750]	BT 6.529 (1.171)	DT 6.426 (1.038)	loss nan (nan)	prob nan (nan)	GS 33.797 (33.797)	mem 40.099
Train: [66][525/750]	BT 0.122 (1.171)	DT 0.002 (1.037)	loss nan (nan)	prob nan (nan)	GS 31.922 (31.922)	mem 40.195
Train: [66][530/750]	BT 0.182 (1.161)	DT 0.005 (1.028)	loss nan (nan)	prob nan (nan)	GS 33.438 (33.438)	mem 40.283
Train: [66][535/750]	BT 0.170 (1.170)	DT 0.001 (1.036)	loss nan (nan)	prob nan (nan)	GS 33.453 (33.453)	mem 39.955
Train: [66][540/750]	BT 0.129 (1.161)	DT 0.002 (1.027)	loss nan (nan)	prob nan (nan)	GS 34.766 (34.766)	mem 40.081
Train: [66][545/750]	BT 0.085 (1.168)	DT 0.002 (1.035)	loss nan (nan)	prob nan (nan)	GS 33.000 (33.000)	mem 40.030
Train: [66][550/750]	BT 0.186 (1.166)	DT 0.001 (1.032)	loss nan (nan)	prob nan (nan)	GS 38.453 (38.453)	mem 39.980
Train: [66][555/750]	BT 0.140 (1.156)	DT 0.002 (1.023)	loss nan (nan)	prob nan (nan)	GS 27.953 (27.953)	mem 39.981
Train: [66][560/750]	BT 0.122 (1.172)	DT 0.002 (1.039)	loss nan (nan)	prob nan (nan)	GS 33.953 (33.953)	mem 39.986
Train: [66][565/750]	BT 0.126 (1.163)	DT 0.002 (1.030)	loss nan (nan)	prob nan (nan)	GS 32.953 (32.953)	mem 39.986
Train: [66][570/750]	BT 8.245 (1.173)	DT 8.171 (1.040)	loss nan (nan)	prob nan (nan)	GS 32.188 (32.188)	mem 39.982
Train: [66][575/750]	BT 0.101 (1.170)	DT 0.004 (1.037)	loss nan (nan)	prob nan (nan)	GS 33.016 (33.016)	mem 39.934
Train: [66][580/750]	BT 0.858 (1.162)	DT 0.749 (1.029)	loss nan (nan)	prob nan (nan)	GS 33.406 (33.406)	mem 40.102
Train: [66][585/750]	BT 0.175 (1.163)	DT 0.002 (1.031)	loss nan (nan)	prob nan (nan)	GS 30.922 (30.922)	mem 40.034
Train: [66][590/750]	BT 0.088 (1.167)	DT 0.006 (1.034)	loss nan (nan)	prob nan (nan)	GS 36.031 (36.031)	mem 39.995
Train: [66][595/750]	BT 0.154 (1.165)	DT 0.005 (1.032)	loss nan (nan)	prob nan (nan)	GS 36.438 (36.438)	mem 40.109
Train: [66][600/750]	BT 0.087 (1.172)	DT 0.002 (1.039)	loss nan (nan)	prob nan (nan)	GS 37.609 (37.609)	mem 39.985
Train: [66][605/750]	BT 0.105 (1.163)	DT 0.002 (1.031)	loss nan (nan)	prob nan (nan)	GS 28.344 (28.344)	mem 39.988
Train: [66][610/750]	BT 7.935 (1.169)	DT 7.781 (1.037)	loss nan (nan)	prob nan (nan)	GS 36.859 (36.859)	mem 40.007
Train: [66][615/750]	BT 0.202 (1.161)	DT 0.015 (1.028)	loss nan (nan)	prob nan (nan)	GS 30.297 (30.297)	mem 40.018
Train: [66][620/750]	BT 5.181 (1.167)	DT 5.015 (1.034)	loss nan (nan)	prob nan (nan)	GS 37.453 (37.453)	mem 39.978
Train: [66][625/750]	BT 0.098 (1.164)	DT 0.009 (1.031)	loss nan (nan)	prob nan (nan)	GS 34.484 (34.484)	mem 40.092
Train: [66][630/750]	BT 0.286 (1.156)	DT 0.131 (1.023)	loss nan (nan)	prob nan (nan)	GS 33.547 (33.547)	mem 40.051
Train: [66][635/750]	BT 0.076 (1.165)	DT 0.005 (1.033)	loss nan (nan)	prob nan (nan)	GS 28.047 (28.047)	mem 40.048
Train: [66][640/750]	BT 0.090 (1.157)	DT 0.002 (1.025)	loss nan (nan)	prob nan (nan)	GS 29.172 (29.172)	mem 40.052
Train: [66][645/750]	BT 0.088 (1.153)	DT 0.002 (1.020)	loss nan (nan)	prob nan (nan)	GS 32.094 (32.094)	mem 40.076
Train: [66][650/750]	BT 0.086 (1.160)	DT 0.007 (1.027)	loss nan (nan)	prob nan (nan)	GS 37.328 (37.328)	mem 40.005
Train: [66][655/750]	BT 0.204 (1.152)	DT 0.010 (1.020)	loss nan (nan)	prob nan (nan)	GS 31.453 (31.453)	mem 40.050
Train: [66][660/750]	BT 0.170 (1.164)	DT 0.006 (1.031)	loss nan (nan)	prob nan (nan)	GS 29.641 (29.641)	mem 40.100
Train: [66][665/750]	BT 0.238 (1.157)	DT 0.001 (1.024)	loss nan (nan)	prob nan (nan)	GS 28.562 (28.562)	mem 40.038
Train: [66][670/750]	BT 5.781 (1.164)	DT 5.655 (1.031)	loss nan (nan)	prob nan (nan)	GS 35.000 (35.000)	mem 40.101
Train: [66][675/750]	BT 0.083 (1.157)	DT 0.001 (1.023)	loss nan (nan)	prob nan (nan)	GS 33.484 (33.484)	mem 40.093
Train: [66][680/750]	BT 3.580 (1.156)	DT 3.507 (1.023)	loss nan (nan)	prob nan (nan)	GS 31.828 (31.828)	mem 40.093
Train: [66][685/750]	BT 0.103 (1.158)	DT 0.002 (1.025)	loss nan (nan)	prob nan (nan)	GS 34.438 (34.438)	mem 40.049
Train: [66][690/750]	BT 1.750 (1.153)	DT 1.528 (1.020)	loss nan (nan)	prob nan (nan)	GS 34.234 (34.234)	mem 40.089
Train: [66][695/750]	BT 0.268 (1.158)	DT 0.019 (1.024)	loss nan (nan)	prob nan (nan)	GS 32.484 (32.484)	mem 40.101
Train: [66][700/750]	BT 0.104 (1.150)	DT 0.002 (1.017)	loss nan (nan)	prob nan (nan)	GS 29.625 (29.625)	mem 40.103
Train: [66][705/750]	BT 0.098 (1.154)	DT 0.005 (1.020)	loss nan (nan)	prob nan (nan)	GS 33.438 (33.438)	mem 40.033
arpack error, retry= 0
Train: [66][710/750]	BT 0.085 (1.152)	DT 0.001 (1.018)	loss nan (nan)	prob nan (nan)	GS 35.344 (35.344)	mem 40.025
Train: [66][715/750]	BT 0.086 (1.145)	DT 0.005 (1.012)	loss nan (nan)	prob nan (nan)	GS 32.953 (32.953)	mem 40.069
Train: [66][720/750]	BT 0.094 (1.154)	DT 0.002 (1.020)	loss nan (nan)	prob nan (nan)	GS 28.953 (28.953)	mem 40.135
Train: [66][725/750]	BT 0.100 (1.146)	DT 0.002 (1.013)	loss nan (nan)	prob nan (nan)	GS 32.062 (32.062)	mem 40.136
Train: [66][730/750]	BT 0.988 (1.155)	DT 0.893 (1.022)	loss nan (nan)	prob nan (nan)	GS 33.547 (33.547)	mem 39.589
Train: [66][735/750]	BT 0.135 (1.148)	DT 0.017 (1.016)	loss nan (nan)	prob nan (nan)	GS 31.703 (31.703)	mem 39.603
Train: [66][740/750]	BT 3.622 (1.146)	DT 3.531 (1.013)	loss nan (nan)	prob nan (nan)	GS 28.828 (28.828)	mem 13.905
Train: [66][745/750]	BT 0.056 (1.143)	DT 0.001 (1.011)	loss nan (nan)	prob nan (nan)	GS 27.656 (27.656)	mem 10.699
Train: [66][750/750]	BT 0.112 (1.136)	DT 0.002 (1.004)	loss nan (nan)	prob nan (nan)	GS 31.281 (31.281)	mem 10.628
Train: [66][755/750]	BT 0.066 (1.131)	DT 0.001 (1.000)	loss nan (nan)	prob nan (nan)	GS 31.438 (31.438)	mem 7.666
epoch 66, total time 854.20
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [67][1/750]	BT 23.652 (23.652)	DT 23.558 (23.558)	loss nan (nan)	prob nan (nan)	GS 32.438 (32.438)	mem 38.654
Train: [67][5/750]	BT 0.103 (4.816)	DT 0.002 (4.714)	loss nan (nan)	prob nan (nan)	GS 32.797 (32.797)	mem 38.729
Train: [67][10/750]	BT 0.145 (2.516)	DT 0.010 (2.398)	loss nan (nan)	prob nan (nan)	GS 32.953 (32.953)	mem 38.895
Train: [67][15/750]	BT 0.172 (2.264)	DT 0.004 (2.131)	loss nan (nan)	prob nan (nan)	GS 29.625 (29.625)	mem 38.917
Train: [67][20/750]	BT 5.817 (2.029)	DT 5.677 (1.890)	loss nan (nan)	prob nan (nan)	GS 35.141 (35.141)	mem 38.880
Train: [67][25/750]	BT 2.786 (1.768)	DT 2.597 (1.622)	loss nan (nan)	prob nan (nan)	GS 34.578 (34.578)	mem 38.978
Train: [67][30/750]	BT 0.138 (1.600)	DT 0.002 (1.453)	loss nan (nan)	prob nan (nan)	GS 33.828 (33.828)	mem 39.012
Train: [67][35/750]	BT 0.120 (1.560)	DT 0.002 (1.414)	loss nan (nan)	prob nan (nan)	GS 33.000 (33.000)	mem 39.118
Train: [67][40/750]	BT 0.147 (1.649)	DT 0.001 (1.507)	loss nan (nan)	prob nan (nan)	GS 31.891 (31.891)	mem 39.193
Train: [67][45/750]	BT 0.091 (1.482)	DT 0.001 (1.340)	loss nan (nan)	prob nan (nan)	GS 32.875 (32.875)	mem 39.049
Train: [67][50/750]	BT 8.990 (1.585)	DT 8.864 (1.438)	loss nan (nan)	prob nan (nan)	GS 27.781 (27.781)	mem 39.150
Train: [67][55/750]	BT 0.160 (1.454)	DT 0.001 (1.308)	loss nan (nan)	prob nan (nan)	GS 28.188 (28.188)	mem 39.170
Train: [67][60/750]	BT 0.792 (1.352)	DT 0.644 (1.210)	loss nan (nan)	prob nan (nan)	GS 36.891 (36.891)	mem 39.163
Train: [67][65/750]	BT 0.103 (1.467)	DT 0.004 (1.327)	loss nan (nan)	prob nan (nan)	GS 33.656 (33.656)	mem 39.575
Train: [67][70/750]	BT 0.124 (1.372)	DT 0.001 (1.233)	loss nan (nan)	prob nan (nan)	GS 32.484 (32.484)	mem 39.590
Train: [67][75/750]	BT 0.096 (1.409)	DT 0.005 (1.270)	loss nan (nan)	prob nan (nan)	GS 34.016 (34.016)	mem 39.702
Train: [67][80/750]	BT 0.103 (1.327)	DT 0.002 (1.191)	loss nan (nan)	prob nan (nan)	GS 31.953 (31.953)	mem 39.702
Train: [67][85/750]	BT 0.134 (1.320)	DT 0.002 (1.186)	loss nan (nan)	prob nan (nan)	GS 32.641 (32.641)	mem 39.718
Train: [67][90/750]	BT 0.170 (1.301)	DT 0.002 (1.166)	loss nan (nan)	prob nan (nan)	GS 34.016 (34.016)	mem 39.909
Train: [67][95/750]	BT 0.197 (1.330)	DT 0.010 (1.193)	loss nan (nan)	prob nan (nan)	GS 31.766 (31.766)	mem 39.652
Train: [67][100/750]	BT 0.170 (1.290)	DT 0.010 (1.151)	loss nan (nan)	prob nan (nan)	GS 35.125 (35.125)	mem 39.761
Train: [67][105/750]	BT 0.102 (1.270)	DT 0.003 (1.130)	loss nan (nan)	prob nan (nan)	GS 31.547 (31.547)	mem 39.842
Train: [67][110/750]	BT 1.286 (1.290)	DT 1.108 (1.151)	loss nan (nan)	prob nan (nan)	GS 37.250 (37.250)	mem 39.649
Train: [67][115/750]	BT 0.159 (1.297)	DT 0.020 (1.159)	loss nan (nan)	prob nan (nan)	GS 28.938 (28.938)	mem 39.830
Train: [67][120/750]	BT 4.720 (1.299)	DT 4.594 (1.161)	loss nan (nan)	prob nan (nan)	GS 37.688 (37.688)	mem 39.839
Train: [67][125/750]	BT 0.147 (1.296)	DT 0.012 (1.159)	loss nan (nan)	prob nan (nan)	GS 30.703 (30.703)	mem 39.879
Train: [67][130/750]	BT 0.601 (1.254)	DT 0.443 (1.117)	loss nan (nan)	prob nan (nan)	GS 32.422 (32.422)	mem 39.825
Train: [67][135/750]	BT 0.297 (1.253)	DT 0.009 (1.114)	loss nan (nan)	prob nan (nan)	GS 29.656 (29.656)	mem 39.867
Train: [67][140/750]	BT 0.131 (1.263)	DT 0.001 (1.124)	loss nan (nan)	prob nan (nan)	GS 33.984 (33.984)	mem 39.826
Train: [67][145/750]	BT 0.112 (1.268)	DT 0.004 (1.131)	loss nan (nan)	prob nan (nan)	GS 33.422 (33.422)	mem 39.776
Train: [67][150/750]	BT 0.125 (1.267)	DT 0.002 (1.129)	loss nan (nan)	prob nan (nan)	GS 34.953 (34.953)	mem 39.765
Train: [67][155/750]	BT 0.178 (1.245)	DT 0.002 (1.105)	loss nan (nan)	prob nan (nan)	GS 29.875 (29.875)	mem 39.718
Train: [67][160/750]	BT 3.055 (1.259)	DT 2.932 (1.120)	loss nan (nan)	prob nan (nan)	GS 33.203 (33.203)	mem 39.880
Train: [67][165/750]	BT 0.119 (1.225)	DT 0.001 (1.086)	loss nan (nan)	prob nan (nan)	GS 31.203 (31.203)	mem 39.771
Train: [67][170/750]	BT 0.195 (1.246)	DT 0.002 (1.107)	loss nan (nan)	prob nan (nan)	GS 33.125 (33.125)	mem 40.017
Train: [67][175/750]	BT 0.134 (1.215)	DT 0.002 (1.076)	loss nan (nan)	prob nan (nan)	GS 36.734 (36.734)	mem 39.843
Train: [67][180/750]	BT 8.389 (1.254)	DT 8.293 (1.115)	loss nan (nan)	prob nan (nan)	GS 33.422 (33.422)	mem 39.760
Train: [67][185/750]	BT 0.094 (1.223)	DT 0.002 (1.085)	loss nan (nan)	prob nan (nan)	GS 31.406 (31.406)	mem 39.818
Train: [67][190/750]	BT 5.653 (1.235)	DT 5.484 (1.097)	loss nan (nan)	prob nan (nan)	GS 33.922 (33.922)	mem 39.923
Train: [67][195/750]	BT 0.174 (1.238)	DT 0.027 (1.101)	loss nan (nan)	prob nan (nan)	GS 35.625 (35.625)	mem 40.007
Train: [67][200/750]	BT 2.311 (1.221)	DT 2.126 (1.084)	loss nan (nan)	prob nan (nan)	GS 36.188 (36.188)	mem 40.174
Train: [67][205/750]	BT 0.158 (1.228)	DT 0.013 (1.091)	loss nan (nan)	prob nan (nan)	GS 29.000 (29.000)	mem 39.907
Train: [67][210/750]	BT 0.139 (1.225)	DT 0.002 (1.088)	loss nan (nan)	prob nan (nan)	GS 28.781 (28.781)	mem 40.198
Train: [67][215/750]	BT 0.081 (1.218)	DT 0.002 (1.081)	loss nan (nan)	prob nan (nan)	GS 36.797 (36.797)	mem 39.927
Train: [67][220/750]	BT 2.332 (1.219)	DT 2.193 (1.082)	loss nan (nan)	prob nan (nan)	GS 29.844 (29.844)	mem 40.011
Train: [67][225/750]	BT 0.125 (1.220)	DT 0.009 (1.083)	loss nan (nan)	prob nan (nan)	GS 29.234 (29.234)	mem 40.299
Train: [67][230/750]	BT 0.188 (1.223)	DT 0.006 (1.086)	loss nan (nan)	prob nan (nan)	GS 34.375 (34.375)	mem 40.016
Train: [67][235/750]	BT 0.202 (1.206)	DT 0.001 (1.070)	loss nan (nan)	prob nan (nan)	GS 29.125 (29.125)	mem 40.089
Train: [67][240/750]	BT 2.593 (1.215)	DT 2.444 (1.078)	loss nan (nan)	prob nan (nan)	GS 29.891 (29.891)	mem 39.880
Train: [67][245/750]	BT 0.146 (1.208)	DT 0.010 (1.071)	loss nan (nan)	prob nan (nan)	GS 29.797 (29.797)	mem 39.950
Train: [67][250/750]	BT 0.578 (1.196)	DT 0.445 (1.058)	loss nan (nan)	prob nan (nan)	GS 27.547 (27.547)	mem 39.968
Train: [67][255/750]	BT 0.106 (1.200)	DT 0.007 (1.063)	loss nan (nan)	prob nan (nan)	GS 31.312 (31.312)	mem 40.025
Train: [67][260/750]	BT 1.935 (1.195)	DT 1.775 (1.058)	loss nan (nan)	prob nan (nan)	GS 36.312 (36.312)	mem 39.956
Train: [67][265/750]	BT 0.168 (1.205)	DT 0.002 (1.067)	loss nan (nan)	prob nan (nan)	GS 30.984 (30.984)	mem 39.924
Train: [67][270/750]	BT 0.069 (1.192)	DT 0.001 (1.054)	loss nan (nan)	prob nan (nan)	GS 33.797 (33.797)	mem 39.983
Train: [67][275/750]	BT 0.078 (1.193)	DT 0.002 (1.055)	loss nan (nan)	prob nan (nan)	GS 30.141 (30.141)	mem 39.960
Train: [67][280/750]	BT 1.430 (1.191)	DT 1.334 (1.053)	loss nan (nan)	prob nan (nan)	GS 34.469 (34.469)	mem 39.829
Train: [67][285/750]	BT 0.103 (1.188)	DT 0.002 (1.051)	loss nan (nan)	prob nan (nan)	GS 29.344 (29.344)	mem 39.874
Train: [67][290/750]	BT 0.094 (1.196)	DT 0.001 (1.059)	loss nan (nan)	prob nan (nan)	GS 34.156 (34.156)	mem 39.888
Train: [67][295/750]	BT 0.149 (1.192)	DT 0.006 (1.055)	loss nan (nan)	prob nan (nan)	GS 30.234 (30.234)	mem 39.786
Train: [67][300/750]	BT 3.644 (1.195)	DT 3.549 (1.058)	loss nan (nan)	prob nan (nan)	GS 36.297 (36.297)	mem 40.050
Train: [67][305/750]	BT 0.107 (1.191)	DT 0.002 (1.054)	loss nan (nan)	prob nan (nan)	GS 32.625 (32.625)	mem 39.889
Train: [67][310/750]	BT 0.266 (1.185)	DT 0.001 (1.047)	loss nan (nan)	prob nan (nan)	GS 32.531 (32.531)	mem 40.043
Train: [67][315/750]	BT 0.165 (1.192)	DT 0.001 (1.055)	loss nan (nan)	prob nan (nan)	GS 30.484 (30.484)	mem 39.934
Train: [67][320/750]	BT 1.135 (1.183)	DT 0.972 (1.047)	loss nan (nan)	prob nan (nan)	GS 33.516 (33.516)	mem 39.874
Train: [67][325/750]	BT 0.128 (1.189)	DT 0.026 (1.053)	loss nan (nan)	prob nan (nan)	GS 28.750 (28.750)	mem 39.989
Train: [67][330/750]	BT 0.084 (1.184)	DT 0.001 (1.049)	loss nan (nan)	prob nan (nan)	GS 35.625 (35.625)	mem 39.945
Train: [67][335/750]	BT 0.109 (1.178)	DT 0.005 (1.042)	loss nan (nan)	prob nan (nan)	GS 32.594 (32.594)	mem 39.870
Train: [67][340/750]	BT 0.117 (1.187)	DT 0.006 (1.051)	loss nan (nan)	prob nan (nan)	GS 34.016 (34.016)	mem 39.855
Train: [67][345/750]	BT 0.075 (1.176)	DT 0.002 (1.041)	loss nan (nan)	prob nan (nan)	GS 31.422 (31.422)	mem 39.856
Train: [67][350/750]	BT 0.093 (1.195)	DT 0.001 (1.060)	loss nan (nan)	prob nan (nan)	GS 34.766 (34.766)	mem 39.948
Train: [67][355/750]	BT 0.157 (1.183)	DT 0.006 (1.048)	loss nan (nan)	prob nan (nan)	GS 31.297 (31.297)	mem 39.942
Train: [67][360/750]	BT 11.349 (1.200)	DT 11.216 (1.064)	loss nan (nan)	prob nan (nan)	GS 30.672 (30.672)	mem 39.911
Train: [67][365/750]	BT 0.102 (1.185)	DT 0.002 (1.050)	loss nan (nan)	prob nan (nan)	GS 31.875 (31.875)	mem 39.849
Train: [67][370/750]	BT 1.769 (1.175)	DT 1.642 (1.040)	loss nan (nan)	prob nan (nan)	GS 38.031 (38.031)	mem 39.905
Train: [67][375/750]	BT 0.192 (1.190)	DT 0.004 (1.054)	loss nan (nan)	prob nan (nan)	GS 30.391 (30.391)	mem 40.045
Train: [67][380/750]	BT 1.837 (1.180)	DT 1.760 (1.045)	loss nan (nan)	prob nan (nan)	GS 37.016 (37.016)	mem 39.916
Train: [67][385/750]	BT 0.086 (1.193)	DT 0.002 (1.058)	loss nan (nan)	prob nan (nan)	GS 27.359 (27.359)	mem 39.999
Train: [67][390/750]	BT 0.083 (1.182)	DT 0.001 (1.047)	loss nan (nan)	prob nan (nan)	GS 32.156 (32.156)	mem 40.047
Train: [67][395/750]	BT 0.139 (1.170)	DT 0.008 (1.035)	loss nan (nan)	prob nan (nan)	GS 31.062 (31.062)	mem 39.920
Train: [67][400/750]	BT 0.084 (1.189)	DT 0.002 (1.054)	loss nan (nan)	prob nan (nan)	GS 37.547 (37.547)	mem 39.997
Train: [67][405/750]	BT 0.080 (1.178)	DT 0.002 (1.043)	loss nan (nan)	prob nan (nan)	GS 36.406 (36.406)	mem 39.998
Train: [67][410/750]	BT 5.882 (1.189)	DT 5.800 (1.054)	loss nan (nan)	prob nan (nan)	GS 32.750 (32.750)	mem 40.309
Train: [67][415/750]	BT 0.128 (1.176)	DT 0.004 (1.042)	loss nan (nan)	prob nan (nan)	GS 28.078 (28.078)	mem 40.141
Train: [67][420/750]	BT 1.380 (1.171)	DT 1.265 (1.037)	loss nan (nan)	prob nan (nan)	GS 34.688 (34.688)	mem 40.014
Train: [67][425/750]	BT 0.186 (1.180)	DT 0.005 (1.045)	loss nan (nan)	prob nan (nan)	GS 33.875 (33.875)	mem 40.093
Train: [67][430/750]	BT 0.160 (1.177)	DT 0.003 (1.042)	loss nan (nan)	prob nan (nan)	GS 34.266 (34.266)	mem 39.987
Train: [67][435/750]	BT 0.129 (1.187)	DT 0.001 (1.052)	loss nan (nan)	prob nan (nan)	GS 32.188 (32.188)	mem 39.952
Train: [67][440/750]	BT 1.742 (1.179)	DT 1.584 (1.044)	loss nan (nan)	prob nan (nan)	GS 34.047 (34.047)	mem 39.962
Train: [67][445/750]	BT 0.088 (1.167)	DT 0.002 (1.032)	loss nan (nan)	prob nan (nan)	GS 30.672 (30.672)	mem 40.048
Train: [67][450/750]	BT 0.174 (1.180)	DT 0.009 (1.045)	loss nan (nan)	prob nan (nan)	GS 29.844 (29.844)	mem 40.107
Train: [67][455/750]	BT 0.116 (1.168)	DT 0.002 (1.034)	loss nan (nan)	prob nan (nan)	GS 29.250 (29.250)	mem 39.875
Train: [67][460/750]	BT 0.138 (1.182)	DT 0.002 (1.048)	loss nan (nan)	prob nan (nan)	GS 28.859 (28.859)	mem 39.930
Train: [67][465/750]	BT 0.126 (1.171)	DT 0.002 (1.037)	loss nan (nan)	prob nan (nan)	GS 29.062 (29.062)	mem 40.005
Train: [67][470/750]	BT 12.151 (1.185)	DT 11.966 (1.051)	loss nan (nan)	prob nan (nan)	GS 30.719 (30.719)	mem 40.065
Train: [67][475/750]	BT 0.128 (1.174)	DT 0.004 (1.040)	loss nan (nan)	prob nan (nan)	GS 32.266 (32.266)	mem 39.890
Train: [67][480/750]	BT 0.211 (1.164)	DT 0.004 (1.030)	loss nan (nan)	prob nan (nan)	GS 32.031 (32.031)	mem 39.863
Train: [67][485/750]	BT 0.075 (1.175)	DT 0.001 (1.041)	loss nan (nan)	prob nan (nan)	GS 30.906 (30.906)	mem 39.988
Train: [67][490/750]	BT 2.002 (1.168)	DT 1.866 (1.034)	loss nan (nan)	prob nan (nan)	GS 35.656 (35.656)	mem 39.943
Train: [67][495/750]	BT 0.088 (1.173)	DT 0.002 (1.039)	loss nan (nan)	prob nan (nan)	GS 34.703 (34.703)	mem 40.052
Train: [67][500/750]	BT 0.165 (1.168)	DT 0.002 (1.035)	loss nan (nan)	prob nan (nan)	GS 31.297 (31.297)	mem 40.238
Train: [67][505/750]	BT 0.091 (1.161)	DT 0.003 (1.027)	loss nan (nan)	prob nan (nan)	GS 29.594 (29.594)	mem 40.040
Train: [67][510/750]	BT 1.292 (1.171)	DT 1.106 (1.037)	loss nan (nan)	prob nan (nan)	GS 32.266 (32.266)	mem 40.157
Train: [67][515/750]	BT 0.103 (1.161)	DT 0.002 (1.027)	loss nan (nan)	prob nan (nan)	GS 28.422 (28.422)	mem 39.973
Train: [67][520/750]	BT 0.164 (1.167)	DT 0.009 (1.033)	loss nan (nan)	prob nan (nan)	GS 34.203 (34.203)	mem 40.028
Train: [67][525/750]	BT 0.158 (1.167)	DT 0.002 (1.032)	loss nan (nan)	prob nan (nan)	GS 30.484 (30.484)	mem 40.187
Train: [67][530/750]	BT 6.118 (1.169)	DT 6.043 (1.034)	loss nan (nan)	prob nan (nan)	GS 35.297 (35.297)	mem 39.965
Train: [67][535/750]	BT 0.154 (1.167)	DT 0.001 (1.032)	loss nan (nan)	prob nan (nan)	GS 31.047 (31.047)	mem 39.922
Train: [67][540/750]	BT 0.144 (1.158)	DT 0.001 (1.023)	loss nan (nan)	prob nan (nan)	GS 29.922 (29.922)	mem 39.996
Train: [67][545/750]	BT 0.092 (1.168)	DT 0.001 (1.033)	loss nan (nan)	prob nan (nan)	GS 32.656 (32.656)	mem 39.986
Train: [67][550/750]	BT 0.193 (1.159)	DT 0.001 (1.024)	loss nan (nan)	prob nan (nan)	GS 33.656 (33.656)	mem 40.081
Train: [67][555/750]	BT 0.138 (1.172)	DT 0.001 (1.037)	loss nan (nan)	prob nan (nan)	GS 29.969 (29.969)	mem 40.009
Train: [67][560/750]	BT 0.078 (1.163)	DT 0.002 (1.028)	loss nan (nan)	prob nan (nan)	GS 33.016 (33.016)	mem 40.014
Train: [67][565/750]	BT 0.193 (1.154)	DT 0.002 (1.019)	loss nan (nan)	prob nan (nan)	GS 31.766 (31.766)	mem 40.062
Train: [67][570/750]	BT 0.135 (1.162)	DT 0.009 (1.027)	loss nan (nan)	prob nan (nan)	GS 32.500 (32.500)	mem 39.986
Train: [67][575/750]	BT 0.107 (1.153)	DT 0.002 (1.018)	loss nan (nan)	prob nan (nan)	GS 36.312 (36.312)	mem 39.997
Train: [67][580/750]	BT 0.164 (1.166)	DT 0.001 (1.031)	loss nan (nan)	prob nan (nan)	GS 31.297 (31.297)	mem 39.973
Train: [67][585/750]	BT 0.084 (1.157)	DT 0.001 (1.022)	loss nan (nan)	prob nan (nan)	GS 30.297 (30.297)	mem 39.985
Train: [67][590/750]	BT 5.874 (1.164)	DT 5.738 (1.030)	loss nan (nan)	prob nan (nan)	GS 31.406 (31.406)	mem 40.212
Train: [67][595/750]	BT 0.108 (1.156)	DT 0.001 (1.021)	loss nan (nan)	prob nan (nan)	GS 33.328 (33.328)	mem 40.101
Train: [67][600/750]	BT 5.472 (1.156)	DT 5.357 (1.022)	loss nan (nan)	prob nan (nan)	GS 34.859 (34.859)	mem 39.958
Train: [67][605/750]	BT 0.113 (1.156)	DT 0.002 (1.021)	loss nan (nan)	prob nan (nan)	GS 33.531 (33.531)	mem 40.045
Train: [67][610/750]	BT 0.125 (1.150)	DT 0.002 (1.016)	loss nan (nan)	prob nan (nan)	GS 34.984 (34.984)	mem 40.024
Train: [67][615/750]	BT 0.104 (1.155)	DT 0.001 (1.021)	loss nan (nan)	prob nan (nan)	GS 29.812 (29.812)	mem 40.100
Train: [67][620/750]	BT 0.096 (1.150)	DT 0.002 (1.016)	loss nan (nan)	prob nan (nan)	GS 32.969 (32.969)	mem 40.097
Train: [67][625/750]	BT 0.249 (1.154)	DT 0.007 (1.020)	loss nan (nan)	prob nan (nan)	GS 33.219 (33.219)	mem 40.166
Train: [67][630/750]	BT 7.523 (1.160)	DT 7.371 (1.025)	loss nan (nan)	prob nan (nan)	GS 38.578 (38.578)	mem 39.965
Train: [67][635/750]	BT 0.209 (1.152)	DT 0.002 (1.017)	loss nan (nan)	prob nan (nan)	GS 29.938 (29.938)	mem 39.976
Train: [67][640/750]	BT 0.120 (1.148)	DT 0.001 (1.014)	loss nan (nan)	prob nan (nan)	GS 31.500 (31.500)	mem 39.940
Train: [67][645/750]	BT 0.089 (1.151)	DT 0.005 (1.017)	loss nan (nan)	prob nan (nan)	GS 33.156 (33.156)	mem 40.122
Train: [67][650/750]	BT 0.101 (1.151)	DT 0.014 (1.017)	loss nan (nan)	prob nan (nan)	GS 32.266 (32.266)	mem 40.055
Train: [67][655/750]	BT 0.097 (1.154)	DT 0.002 (1.020)	loss nan (nan)	prob nan (nan)	GS 42.250 (42.250)	mem 40.320
Train: [67][660/750]	BT 6.975 (1.156)	DT 6.874 (1.022)	loss nan (nan)	prob nan (nan)	GS 40.078 (40.078)	mem 40.042
Train: [67][665/750]	BT 0.149 (1.149)	DT 0.009 (1.015)	loss nan (nan)	prob nan (nan)	GS 29.109 (29.109)	mem 40.045
Train: [67][670/750]	BT 0.176 (1.145)	DT 0.010 (1.011)	loss nan (nan)	prob nan (nan)	GS 32.641 (32.641)	mem 40.162
Train: [67][675/750]	BT 0.076 (1.152)	DT 0.002 (1.018)	loss nan (nan)	prob nan (nan)	GS 32.000 (32.000)	mem 40.072
Train: [67][680/750]	BT 0.176 (1.146)	DT 0.002 (1.012)	loss nan (nan)	prob nan (nan)	GS 35.406 (35.406)	mem 40.084
Train: [67][685/750]	BT 0.107 (1.154)	DT 0.002 (1.020)	loss nan (nan)	prob nan (nan)	GS 29.578 (29.578)	mem 40.016
Train: [67][690/750]	BT 0.267 (1.146)	DT 0.176 (1.012)	loss nan (nan)	prob nan (nan)	GS 30.594 (30.594)	mem 40.043
Train: [67][695/750]	BT 0.156 (1.139)	DT 0.002 (1.005)	loss nan (nan)	prob nan (nan)	GS 26.016 (26.016)	mem 40.046
Train: [67][700/750]	BT 0.237 (1.149)	DT 0.061 (1.015)	loss nan (nan)	prob nan (nan)	GS 29.828 (29.828)	mem 40.043
Train: [67][705/750]	BT 0.164 (1.143)	DT 0.002 (1.009)	loss nan (nan)	prob nan (nan)	GS 30.172 (30.172)	mem 40.040
arpack error, retry= 0
Train: [67][710/750]	BT 0.091 (1.149)	DT 0.001 (1.015)	loss nan (nan)	prob nan (nan)	GS 36.922 (36.922)	mem 39.998
Train: [67][715/750]	BT 0.129 (1.146)	DT 0.002 (1.012)	loss nan (nan)	prob nan (nan)	GS 35.547 (35.547)	mem 40.075
Train: [67][720/750]	BT 8.441 (1.150)	DT 8.344 (1.016)	loss nan (nan)	prob nan (nan)	GS 34.188 (34.188)	mem 40.117
Train: [67][725/750]	BT 0.066 (1.145)	DT 0.001 (1.011)	loss nan (nan)	prob nan (nan)	GS 30.047 (30.047)	mem 40.115
Train: [67][730/750]	BT 0.100 (1.139)	DT 0.004 (1.005)	loss nan (nan)	prob nan (nan)	GS 35.609 (35.609)	mem 40.262
Train: [67][735/750]	BT 0.132 (1.143)	DT 0.002 (1.010)	loss nan (nan)	prob nan (nan)	GS 33.375 (33.375)	mem 39.589
Train: [67][740/750]	BT 0.084 (1.140)	DT 0.001 (1.007)	loss nan (nan)	prob nan (nan)	GS 33.922 (33.922)	mem 19.708
Train: [67][745/750]	BT 0.106 (1.139)	DT 0.002 (1.006)	loss nan (nan)	prob nan (nan)	GS 26.656 (26.656)	mem 7.739
Train: [67][750/750]	BT 0.073 (1.132)	DT 0.001 (0.999)	loss nan (nan)	prob nan (nan)	GS 38.094 (38.094)	mem 7.754
Train: [67][755/750]	BT 0.063 (1.125)	DT 0.001 (0.993)	loss nan (nan)	prob nan (nan)	GS 32.438 (32.438)	mem 7.759
epoch 67, total time 851.86
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [68][1/750]	BT 21.581 (21.581)	DT 21.418 (21.418)	loss nan (nan)	prob nan (nan)	GS 26.000 (26.000)	mem 38.794
Train: [68][5/750]	BT 0.252 (5.421)	DT 0.004 (5.271)	loss nan (nan)	prob nan (nan)	GS 34.156 (34.156)	mem 38.801
Train: [68][10/750]	BT 0.181 (2.802)	DT 0.001 (2.666)	loss nan (nan)	prob nan (nan)	GS 32.984 (32.984)	mem 38.948
Train: [68][15/750]	BT 0.125 (2.613)	DT 0.004 (2.475)	loss nan (nan)	prob nan (nan)	GS 29.328 (29.328)	mem 39.038
Train: [68][20/750]	BT 0.101 (2.337)	DT 0.009 (2.196)	loss nan (nan)	prob nan (nan)	GS 35.453 (35.453)	mem 38.924
Train: [68][25/750]	BT 0.163 (1.905)	DT 0.002 (1.758)	loss nan (nan)	prob nan (nan)	GS 30.656 (30.656)	mem 38.945
Train: [68][30/750]	BT 8.053 (2.104)	DT 7.883 (1.963)	loss nan (nan)	prob nan (nan)	GS 36.016 (36.016)	mem 39.019
Train: [68][35/750]	BT 0.242 (1.828)	DT 0.002 (1.683)	loss nan (nan)	prob nan (nan)	GS 31.641 (31.641)	mem 39.013
Train: [68][40/750]	BT 0.170 (1.667)	DT 0.014 (1.517)	loss nan (nan)	prob nan (nan)	GS 29.688 (29.688)	mem 39.122
Train: [68][45/750]	BT 0.136 (1.726)	DT 0.002 (1.579)	loss nan (nan)	prob nan (nan)	GS 39.234 (39.234)	mem 39.089
Train: [68][50/750]	BT 0.164 (1.564)	DT 0.009 (1.421)	loss nan (nan)	prob nan (nan)	GS 29.219 (29.219)	mem 39.251
Train: [68][55/750]	BT 0.104 (1.626)	DT 0.002 (1.484)	loss nan (nan)	prob nan (nan)	GS 30.891 (30.891)	mem 39.115
Train: [68][60/750]	BT 0.156 (1.502)	DT 0.002 (1.361)	loss nan (nan)	prob nan (nan)	GS 34.859 (34.859)	mem 39.271
Train: [68][65/750]	BT 0.121 (1.397)	DT 0.002 (1.258)	loss nan (nan)	prob nan (nan)	GS 32.906 (32.906)	mem 39.121
Train: [68][70/750]	BT 0.224 (1.422)	DT 0.001 (1.283)	loss nan (nan)	prob nan (nan)	GS 35.469 (35.469)	mem 39.174
Train: [68][75/750]	BT 0.120 (1.363)	DT 0.001 (1.225)	loss nan (nan)	prob nan (nan)	GS 28.406 (28.406)	mem 39.264
Train: [68][80/750]	BT 0.086 (1.406)	DT 0.005 (1.270)	loss nan (nan)	prob nan (nan)	GS 30.703 (30.703)	mem 39.108
Train: [68][85/750]	BT 0.111 (1.334)	DT 0.002 (1.196)	loss nan (nan)	prob nan (nan)	GS 35.406 (35.406)	mem 39.087
Train: [68][90/750]	BT 11.606 (1.402)	DT 11.508 (1.265)	loss nan (nan)	prob nan (nan)	GS 30.938 (30.938)	mem 39.146
Train: [68][95/750]	BT 0.123 (1.334)	DT 0.011 (1.199)	loss nan (nan)	prob nan (nan)	GS 34.859 (34.859)	mem 39.152
Train: [68][100/750]	BT 0.158 (1.278)	DT 0.002 (1.142)	loss nan (nan)	prob nan (nan)	GS 33.609 (33.609)	mem 39.159
Train: [68][105/750]	BT 0.262 (1.337)	DT 0.002 (1.200)	loss nan (nan)	prob nan (nan)	GS 30.234 (30.234)	mem 39.334
Train: [68][110/750]	BT 4.625 (1.324)	DT 4.528 (1.187)	loss nan (nan)	prob nan (nan)	GS 38.938 (38.938)	mem 39.103
Train: [68][115/750]	BT 0.105 (1.363)	DT 0.007 (1.227)	loss nan (nan)	prob nan (nan)	GS 33.312 (33.312)	mem 39.329
Train: [68][120/750]	BT 0.103 (1.312)	DT 0.015 (1.176)	loss nan (nan)	prob nan (nan)	GS 33.766 (33.766)	mem 39.252
Train: [68][125/750]	BT 0.108 (1.287)	DT 0.003 (1.150)	loss nan (nan)	prob nan (nan)	GS 33.016 (33.016)	mem 39.209
Train: [68][130/750]	BT 0.150 (1.315)	DT 0.013 (1.179)	loss nan (nan)	prob nan (nan)	GS 35.281 (35.281)	mem 39.320
Train: [68][135/750]	BT 0.165 (1.309)	DT 0.001 (1.174)	loss nan (nan)	prob nan (nan)	GS 36.609 (36.609)	mem 39.302
Train: [68][140/750]	BT 0.217 (1.304)	DT 0.003 (1.168)	loss nan (nan)	prob nan (nan)	GS 35.703 (35.703)	mem 39.328
Train: [68][145/750]	BT 0.346 (1.265)	DT 0.061 (1.128)	loss nan (nan)	prob nan (nan)	GS 30.172 (30.172)	mem 39.420
Train: [68][150/750]	BT 1.620 (1.295)	DT 1.532 (1.160)	loss nan (nan)	prob nan (nan)	GS 32.891 (32.891)	mem 39.322
Train: [68][155/750]	BT 0.119 (1.258)	DT 0.023 (1.122)	loss nan (nan)	prob nan (nan)	GS 31.953 (31.953)	mem 39.297
Train: [68][160/750]	BT 0.179 (1.268)	DT 0.001 (1.132)	loss nan (nan)	prob nan (nan)	GS 31.406 (31.406)	mem 39.439
Train: [68][165/750]	BT 0.144 (1.276)	DT 0.022 (1.139)	loss nan (nan)	prob nan (nan)	GS 30.438 (30.438)	mem 39.428
Train: [68][170/750]	BT 2.928 (1.258)	DT 2.833 (1.122)	loss nan (nan)	prob nan (nan)	GS 33.031 (33.031)	mem 39.371
Train: [68][175/750]	BT 0.121 (1.279)	DT 0.002 (1.142)	loss nan (nan)	prob nan (nan)	GS 31.281 (31.281)	mem 39.417
Train: [68][180/750]	BT 0.116 (1.246)	DT 0.001 (1.111)	loss nan (nan)	prob nan (nan)	GS 33.672 (33.672)	mem 39.435
Train: [68][185/750]	BT 0.287 (1.220)	DT 0.003 (1.084)	loss nan (nan)	prob nan (nan)	GS 27.500 (27.500)	mem 39.479
Train: [68][190/750]	BT 0.088 (1.267)	DT 0.001 (1.132)	loss nan (nan)	prob nan (nan)	GS 28.750 (28.750)	mem 39.482
Train: [68][195/750]	BT 0.145 (1.237)	DT 0.011 (1.103)	loss nan (nan)	prob nan (nan)	GS 31.516 (31.516)	mem 39.523
Train: [68][200/750]	BT 0.122 (1.269)	DT 0.002 (1.136)	loss nan (nan)	prob nan (nan)	GS 38.344 (38.344)	mem 39.548
Train: [68][205/750]	BT 0.158 (1.241)	DT 0.002 (1.108)	loss nan (nan)	prob nan (nan)	GS 30.516 (30.516)	mem 39.635
Train: [68][210/750]	BT 11.143 (1.267)	DT 10.995 (1.134)	loss nan (nan)	prob nan (nan)	GS 35.391 (35.391)	mem 39.563
Train: [68][215/750]	BT 0.160 (1.240)	DT 0.002 (1.108)	loss nan (nan)	prob nan (nan)	GS 30.609 (30.609)	mem 39.593
Train: [68][220/750]	BT 0.233 (1.216)	DT 0.003 (1.083)	loss nan (nan)	prob nan (nan)	GS 36.234 (36.234)	mem 39.608
Train: [68][225/750]	BT 0.113 (1.246)	DT 0.002 (1.114)	loss nan (nan)	prob nan (nan)	GS 41.641 (41.641)	mem 39.639
Train: [68][230/750]	BT 0.126 (1.222)	DT 0.001 (1.090)	loss nan (nan)	prob nan (nan)	GS 36.781 (36.781)	mem 39.639
Train: [68][235/750]	BT 0.122 (1.241)	DT 0.002 (1.108)	loss nan (nan)	prob nan (nan)	GS 30.250 (30.250)	mem 39.694
Train: [68][240/750]	BT 0.261 (1.218)	DT 0.081 (1.086)	loss nan (nan)	prob nan (nan)	GS 37.953 (37.953)	mem 39.718
Train: [68][245/750]	BT 0.159 (1.196)	DT 0.002 (1.064)	loss nan (nan)	prob nan (nan)	GS 26.188 (26.188)	mem 39.812
Train: [68][250/750]	BT 0.074 (1.229)	DT 0.002 (1.096)	loss nan (nan)	prob nan (nan)	GS 34.938 (34.938)	mem 39.919
Train: [68][255/750]	BT 0.214 (1.215)	DT 0.002 (1.082)	loss nan (nan)	prob nan (nan)	GS 33.625 (33.625)	mem 39.975
Train: [68][260/750]	BT 0.079 (1.237)	DT 0.004 (1.105)	loss nan (nan)	prob nan (nan)	GS 35.719 (35.719)	mem 39.971
Train: [68][265/750]	BT 0.087 (1.215)	DT 0.001 (1.084)	loss nan (nan)	prob nan (nan)	GS 31.797 (31.797)	mem 40.013
Train: [68][270/750]	BT 13.181 (1.245)	DT 13.085 (1.112)	loss nan (nan)	prob nan (nan)	GS 33.500 (33.500)	mem 39.965
Train: [68][275/750]	BT 0.093 (1.224)	DT 0.001 (1.092)	loss nan (nan)	prob nan (nan)	GS 36.531 (36.531)	mem 39.967
Train: [68][280/750]	BT 0.129 (1.205)	DT 0.002 (1.073)	loss nan (nan)	prob nan (nan)	GS 35.562 (35.562)	mem 39.967
Train: [68][285/750]	BT 0.160 (1.223)	DT 0.009 (1.091)	loss nan (nan)	prob nan (nan)	GS 31.531 (31.531)	mem 40.119
Train: [68][290/750]	BT 0.136 (1.204)	DT 0.001 (1.072)	loss nan (nan)	prob nan (nan)	GS 32.094 (32.094)	mem 40.031
Train: [68][295/750]	BT 0.086 (1.221)	DT 0.002 (1.089)	loss nan (nan)	prob nan (nan)	GS 30.016 (30.016)	mem 40.107
Train: [68][300/750]	BT 0.499 (1.204)	DT 0.317 (1.072)	loss nan (nan)	prob nan (nan)	GS 36.828 (36.828)	mem 39.999
Train: [68][305/750]	BT 0.180 (1.187)	DT 0.002 (1.055)	loss nan (nan)	prob nan (nan)	GS 30.609 (30.609)	mem 40.091
Train: [68][310/750]	BT 0.125 (1.213)	DT 0.008 (1.082)	loss nan (nan)	prob nan (nan)	GS 32.906 (32.906)	mem 40.001
Train: [68][315/750]	BT 0.117 (1.197)	DT 0.002 (1.066)	loss nan (nan)	prob nan (nan)	GS 34.828 (34.828)	mem 40.007
Train: [68][320/750]	BT 0.151 (1.217)	DT 0.001 (1.086)	loss nan (nan)	prob nan (nan)	GS 33.812 (33.812)	mem 39.972
Train: [68][325/750]	BT 0.140 (1.200)	DT 0.009 (1.069)	loss nan (nan)	prob nan (nan)	GS 28.406 (28.406)	mem 39.969
Train: [68][330/750]	BT 13.198 (1.224)	DT 13.106 (1.093)	loss nan (nan)	prob nan (nan)	GS 32.594 (32.594)	mem 39.972
Train: [68][335/750]	BT 0.119 (1.207)	DT 0.001 (1.077)	loss nan (nan)	prob nan (nan)	GS 31.109 (31.109)	mem 39.973
Train: [68][340/750]	BT 0.149 (1.191)	DT 0.001 (1.061)	loss nan (nan)	prob nan (nan)	GS 35.812 (35.812)	mem 39.983
Train: [68][345/750]	BT 0.092 (1.207)	DT 0.002 (1.078)	loss nan (nan)	prob nan (nan)	GS 31.906 (31.906)	mem 39.989
Train: [68][350/750]	BT 0.190 (1.192)	DT 0.015 (1.062)	loss nan (nan)	prob nan (nan)	GS 30.516 (30.516)	mem 39.990
Train: [68][355/750]	BT 0.113 (1.208)	DT 0.003 (1.078)	loss nan (nan)	prob nan (nan)	GS 28.203 (28.203)	mem 40.034
Train: [68][360/750]	BT 0.079 (1.193)	DT 0.001 (1.063)	loss nan (nan)	prob nan (nan)	GS 34.906 (34.906)	mem 39.918
Train: [68][365/750]	BT 0.145 (1.179)	DT 0.009 (1.049)	loss nan (nan)	prob nan (nan)	GS 31.297 (31.297)	mem 39.973
Train: [68][370/750]	BT 0.062 (1.203)	DT 0.001 (1.074)	loss nan (nan)	prob nan (nan)	GS 34.609 (34.609)	mem 40.049
Train: [68][375/750]	BT 0.227 (1.189)	DT 0.002 (1.059)	loss nan (nan)	prob nan (nan)	GS 33.578 (33.578)	mem 40.070
Train: [68][380/750]	BT 0.069 (1.201)	DT 0.001 (1.072)	loss nan (nan)	prob nan (nan)	GS 35.984 (35.984)	mem 40.144
Train: [68][385/750]	BT 0.178 (1.188)	DT 0.002 (1.058)	loss nan (nan)	prob nan (nan)	GS 29.734 (29.734)	mem 40.065
Train: [68][390/750]	BT 10.947 (1.201)	DT 10.822 (1.073)	loss nan (nan)	prob nan (nan)	GS 32.484 (32.484)	mem 40.108
Train: [68][395/750]	BT 0.162 (1.188)	DT 0.005 (1.059)	loss nan (nan)	prob nan (nan)	GS 31.844 (31.844)	mem 40.259
Train: [68][400/750]	BT 0.192 (1.175)	DT 0.002 (1.046)	loss nan (nan)	prob nan (nan)	GS 35.438 (35.438)	mem 41.107
Train: [68][405/750]	BT 0.121 (1.186)	DT 0.002 (1.057)	loss nan (nan)	prob nan (nan)	GS 32.500 (32.500)	mem 40.040
Train: [68][410/750]	BT 0.117 (1.173)	DT 0.001 (1.044)	loss nan (nan)	prob nan (nan)	GS 31.547 (31.547)	mem 40.062
Train: [68][415/750]	BT 0.081 (1.190)	DT 0.001 (1.062)	loss nan (nan)	prob nan (nan)	GS 28.969 (28.969)	mem 40.098
Train: [68][420/750]	BT 0.282 (1.178)	DT 0.003 (1.049)	loss nan (nan)	prob nan (nan)	GS 35.469 (35.469)	mem 40.019
Train: [68][425/750]	BT 0.226 (1.166)	DT 0.002 (1.037)	loss nan (nan)	prob nan (nan)	GS 31.891 (31.891)	mem 40.119
Train: [68][430/750]	BT 0.133 (1.180)	DT 0.001 (1.051)	loss nan (nan)	prob nan (nan)	GS 35.141 (35.141)	mem 40.067
Train: [68][435/750]	BT 0.123 (1.168)	DT 0.004 (1.039)	loss nan (nan)	prob nan (nan)	GS 31.922 (31.922)	mem 40.095
Train: [68][440/750]	BT 2.638 (1.186)	DT 2.549 (1.056)	loss nan (nan)	prob nan (nan)	GS 36.000 (36.000)	mem 39.960
Train: [68][445/750]	BT 0.126 (1.174)	DT 0.009 (1.045)	loss nan (nan)	prob nan (nan)	GS 27.781 (27.781)	mem 40.012
Train: [68][450/750]	BT 10.427 (1.185)	DT 10.318 (1.056)	loss nan (nan)	prob nan (nan)	GS 35.094 (35.094)	mem 39.961
Train: [68][455/750]	BT 0.113 (1.173)	DT 0.001 (1.044)	loss nan (nan)	prob nan (nan)	GS 30.844 (30.844)	mem 39.947
Train: [68][460/750]	BT 0.171 (1.162)	DT 0.012 (1.033)	loss nan (nan)	prob nan (nan)	GS 32.703 (32.703)	mem 40.146
Train: [68][465/750]	BT 0.101 (1.179)	DT 0.001 (1.050)	loss nan (nan)	prob nan (nan)	GS 28.453 (28.453)	mem 40.058
Train: [68][470/750]	BT 0.100 (1.168)	DT 0.001 (1.039)	loss nan (nan)	prob nan (nan)	GS 30.609 (30.609)	mem 40.062
Train: [68][475/750]	BT 0.216 (1.177)	DT 0.008 (1.049)	loss nan (nan)	prob nan (nan)	GS 32.641 (32.641)	mem 40.062
Train: [68][480/750]	BT 0.140 (1.172)	DT 0.014 (1.044)	loss nan (nan)	prob nan (nan)	GS 32.812 (32.812)	mem 40.115
Train: [68][485/750]	BT 0.205 (1.162)	DT 0.009 (1.033)	loss nan (nan)	prob nan (nan)	GS 34.859 (34.859)	mem 40.115
Train: [68][490/750]	BT 0.083 (1.175)	DT 0.002 (1.046)	loss nan (nan)	prob nan (nan)	GS 34.688 (34.688)	mem 40.063
Train: [68][495/750]	BT 0.101 (1.164)	DT 0.002 (1.036)	loss nan (nan)	prob nan (nan)	GS 24.703 (24.703)	mem 40.065
Train: [68][500/750]	BT 6.247 (1.175)	DT 6.154 (1.046)	loss nan (nan)	prob nan (nan)	GS 34.766 (34.766)	mem 40.083
Train: [68][505/750]	BT 0.135 (1.165)	DT 0.002 (1.036)	loss nan (nan)	prob nan (nan)	GS 30.344 (30.344)	mem 40.078
Train: [68][510/750]	BT 8.021 (1.171)	DT 7.889 (1.041)	loss nan (nan)	prob nan (nan)	GS 34.125 (34.125)	mem 40.078
Train: [68][515/750]	BT 0.092 (1.163)	DT 0.002 (1.034)	loss nan (nan)	prob nan (nan)	GS 28.250 (28.250)	mem 40.099
Train: [68][520/750]	BT 0.389 (1.154)	DT 0.016 (1.024)	loss nan (nan)	prob nan (nan)	GS 34.938 (34.938)	mem 40.129
Train: [68][525/750]	BT 0.113 (1.165)	DT 0.001 (1.036)	loss nan (nan)	prob nan (nan)	GS 31.438 (31.438)	mem 40.125
Train: [68][530/750]	BT 0.187 (1.158)	DT 0.002 (1.027)	loss nan (nan)	prob nan (nan)	GS 34.312 (34.312)	mem 40.054
Train: [68][535/750]	BT 0.096 (1.166)	DT 0.001 (1.036)	loss nan (nan)	prob nan (nan)	GS 28.406 (28.406)	mem 40.030
Train: [68][540/750]	BT 2.079 (1.160)	DT 1.961 (1.030)	loss nan (nan)	prob nan (nan)	GS 31.344 (31.344)	mem 40.045
Train: [68][545/750]	BT 0.106 (1.150)	DT 0.001 (1.021)	loss nan (nan)	prob nan (nan)	GS 30.219 (30.219)	mem 40.046
Train: [68][550/750]	BT 0.090 (1.159)	DT 0.002 (1.029)	loss nan (nan)	prob nan (nan)	GS 31.828 (31.828)	mem 40.130
Train: [68][555/750]	BT 0.168 (1.150)	DT 0.002 (1.021)	loss nan (nan)	prob nan (nan)	GS 35.203 (35.203)	mem 40.063
Train: [68][560/750]	BT 0.840 (1.162)	DT 0.657 (1.032)	loss nan (nan)	prob nan (nan)	GS 36.328 (36.328)	mem 40.144
Train: [68][565/750]	BT 0.143 (1.155)	DT 0.003 (1.025)	loss nan (nan)	prob nan (nan)	GS 30.656 (30.656)	mem 40.012
Train: [68][570/750]	BT 8.209 (1.160)	DT 8.072 (1.031)	loss nan (nan)	prob nan (nan)	GS 40.672 (40.672)	mem 40.106
Train: [68][575/750]	BT 0.089 (1.156)	DT 0.002 (1.026)	loss nan (nan)	prob nan (nan)	GS 31.500 (31.500)	mem 40.062
Train: [68][580/750]	BT 0.201 (1.148)	DT 0.006 (1.018)	loss nan (nan)	prob nan (nan)	GS 30.844 (30.844)	mem 40.065
Train: [68][585/750]	BT 0.134 (1.158)	DT 0.001 (1.029)	loss nan (nan)	prob nan (nan)	GS 32.047 (32.047)	mem 40.020
Train: [68][590/750]	BT 0.126 (1.153)	DT 0.003 (1.023)	loss nan (nan)	prob nan (nan)	GS 33.938 (33.938)	mem 39.992
Train: [68][595/750]	BT 0.111 (1.163)	DT 0.009 (1.033)	loss nan (nan)	prob nan (nan)	GS 27.656 (27.656)	mem 40.033
Train: [68][600/750]	BT 0.145 (1.155)	DT 0.021 (1.025)	loss nan (nan)	prob nan (nan)	GS 35.016 (35.016)	mem 40.003
Train: [68][605/750]	BT 0.218 (1.146)	DT 0.009 (1.016)	loss nan (nan)	prob nan (nan)	GS 33.719 (33.719)	mem 40.015
Train: [68][610/750]	BT 0.116 (1.156)	DT 0.002 (1.026)	loss nan (nan)	prob nan (nan)	GS 36.438 (36.438)	mem 40.159
Train: [68][615/750]	BT 0.304 (1.148)	DT 0.011 (1.018)	loss nan (nan)	prob nan (nan)	GS 30.250 (30.250)	mem 40.648
Train: [68][620/750]	BT 0.094 (1.166)	DT 0.001 (1.036)	loss nan (nan)	prob nan (nan)	GS 36.000 (36.000)	mem 39.994
Train: [68][625/750]	BT 0.149 (1.158)	DT 0.002 (1.028)	loss nan (nan)	prob nan (nan)	GS 38.938 (38.938)	mem 40.033
Train: [68][630/750]	BT 12.028 (1.168)	DT 11.903 (1.039)	loss nan (nan)	prob nan (nan)	GS 33.094 (33.094)	mem 40.053
Train: [68][635/750]	BT 0.160 (1.160)	DT 0.012 (1.030)	loss nan (nan)	prob nan (nan)	GS 28.469 (28.469)	mem 40.034
Train: [68][640/750]	BT 0.103 (1.152)	DT 0.001 (1.022)	loss nan (nan)	prob nan (nan)	GS 30.016 (30.016)	mem 40.070
Train: [68][645/750]	BT 0.087 (1.164)	DT 0.001 (1.035)	loss nan (nan)	prob nan (nan)	GS 34.484 (34.484)	mem 40.016
Train: [68][650/750]	BT 0.090 (1.156)	DT 0.002 (1.027)	loss nan (nan)	prob nan (nan)	GS 32.969 (32.969)	mem 39.985
Train: [68][655/750]	BT 0.155 (1.162)	DT 0.002 (1.033)	loss nan (nan)	prob nan (nan)	GS 30.266 (30.266)	mem 40.062
Train: [68][660/750]	BT 0.241 (1.155)	DT 0.012 (1.026)	loss nan (nan)	prob nan (nan)	GS 34.000 (34.000)	mem 40.215
Train: [68][665/750]	BT 0.150 (1.147)	DT 0.002 (1.018)	loss nan (nan)	prob nan (nan)	GS 29.719 (29.719)	mem 40.035
Train: [68][670/750]	BT 0.226 (1.157)	DT 0.003 (1.028)	loss nan (nan)	prob nan (nan)	GS 36.484 (36.484)	mem 40.123
Train: [68][675/750]	BT 0.157 (1.151)	DT 0.001 (1.022)	loss nan (nan)	prob nan (nan)	GS 30.906 (30.906)	mem 40.008
Train: [68][680/750]	BT 0.174 (1.157)	DT 0.002 (1.027)	loss nan (nan)	prob nan (nan)	GS 34.328 (34.328)	mem 40.064
Train: [68][685/750]	BT 0.145 (1.155)	DT 0.002 (1.025)	loss nan (nan)	prob nan (nan)	GS 44.406 (44.406)	mem 40.073
Train: [68][690/750]	BT 9.290 (1.161)	DT 9.155 (1.031)	loss nan (nan)	prob nan (nan)	GS 34.812 (34.812)	mem 40.058
Train: [68][695/750]	BT 0.101 (1.153)	DT 0.007 (1.023)	loss nan (nan)	prob nan (nan)	GS 27.484 (27.484)	mem 40.058
Train: [68][700/750]	BT 0.147 (1.150)	DT 0.001 (1.020)	loss nan (nan)	prob nan (nan)	GS 31.594 (31.594)	mem 40.021
Train: [68][705/750]	BT 0.281 (1.153)	DT 0.012 (1.023)	loss nan (nan)	prob nan (nan)	GS 27.875 (27.875)	mem 40.175
Train: [68][710/750]	BT 0.157 (1.154)	DT 0.008 (1.024)	loss nan (nan)	prob nan (nan)	GS 33.328 (33.328)	mem 40.058
Train: [68][715/750]	BT 0.135 (1.154)	DT 0.001 (1.025)	loss nan (nan)	prob nan (nan)	GS 32.797 (32.797)	mem 40.021
Train: [68][720/750]	BT 5.956 (1.156)	DT 5.737 (1.026)	loss nan (nan)	prob nan (nan)	GS 32.297 (32.297)	mem 40.006
Train: [68][725/750]	BT 0.189 (1.149)	DT 0.003 (1.018)	loss nan (nan)	prob nan (nan)	GS 30.688 (30.688)	mem 40.008
Train: [68][730/750]	BT 0.101 (1.149)	DT 0.002 (1.019)	loss nan (nan)	prob nan (nan)	GS 32.812 (32.812)	mem 40.072
Train: [68][735/750]	BT 0.077 (1.153)	DT 0.002 (1.023)	loss nan (nan)	prob nan (nan)	GS 32.844 (32.844)	mem 39.383
Train: [68][740/750]	BT 0.082 (1.147)	DT 0.001 (1.017)	loss nan (nan)	prob nan (nan)	GS 32.406 (32.406)	mem 13.676
Train: [68][745/750]	BT 0.068 (1.145)	DT 0.001 (1.016)	loss nan (nan)	prob nan (nan)	GS 36.281 (36.281)	mem 7.714
Train: [68][750/750]	BT 0.073 (1.138)	DT 0.001 (1.009)	loss nan (nan)	prob nan (nan)	GS 32.250 (32.250)	mem 7.714
Train: [68][755/750]	BT 0.070 (1.131)	DT 0.001 (1.002)	loss nan (nan)	prob nan (nan)	GS 25.156 (25.156)	mem 7.714
epoch 68, total time 855.72
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [69][1/750]	BT 20.750 (20.750)	DT 20.580 (20.580)	loss nan (nan)	prob nan (nan)	GS 26.531 (26.531)	mem 38.599
Train: [69][5/750]	BT 0.115 (5.712)	DT 0.001 (5.600)	loss nan (nan)	prob nan (nan)	GS 27.297 (27.297)	mem 38.736
Train: [69][10/750]	BT 0.114 (2.942)	DT 0.006 (2.803)	loss nan (nan)	prob nan (nan)	GS 36.141 (36.141)	mem 38.673
Train: [69][15/750]	BT 0.137 (2.977)	DT 0.002 (2.846)	loss nan (nan)	prob nan (nan)	GS 31.578 (31.578)	mem 39.018
Train: [69][20/750]	BT 0.157 (2.273)	DT 0.001 (2.135)	loss nan (nan)	prob nan (nan)	GS 32.656 (32.656)	mem 38.940
Train: [69][25/750]	BT 0.165 (1.848)	DT 0.003 (1.712)	loss nan (nan)	prob nan (nan)	GS 38.969 (38.969)	mem 38.857
Train: [69][30/750]	BT 0.092 (1.963)	DT 0.002 (1.830)	loss nan (nan)	prob nan (nan)	GS 35.141 (35.141)	mem 39.043
Train: [69][35/750]	BT 0.093 (1.699)	DT 0.002 (1.569)	loss nan (nan)	prob nan (nan)	GS 28.516 (28.516)	mem 39.048
Train: [69][40/750]	BT 0.055 (1.892)	DT 0.001 (1.766)	loss nan (nan)	prob nan (nan)	GS 33.109 (33.109)	mem 39.033
Train: [69][45/750]	BT 0.093 (1.696)	DT 0.001 (1.570)	loss nan (nan)	prob nan (nan)	GS 30.781 (30.781)	mem 39.088
Train: [69][50/750]	BT 11.403 (1.767)	DT 11.321 (1.640)	loss nan (nan)	prob nan (nan)	GS 31.906 (31.906)	mem 39.143
Train: [69][55/750]	BT 0.085 (1.615)	DT 0.002 (1.491)	loss nan (nan)	prob nan (nan)	GS 31.328 (31.328)	mem 39.145
Train: [69][60/750]	BT 0.084 (1.491)	DT 0.002 (1.368)	loss nan (nan)	prob nan (nan)	GS 33.547 (33.547)	mem 39.122
Train: [69][65/750]	BT 0.097 (1.554)	DT 0.006 (1.429)	loss nan (nan)	prob nan (nan)	GS 36.344 (36.344)	mem 39.339
Train: [69][70/750]	BT 0.134 (1.452)	DT 0.004 (1.328)	loss nan (nan)	prob nan (nan)	GS 32.016 (32.016)	mem 39.177
Train: [69][75/750]	BT 0.094 (1.523)	DT 0.002 (1.399)	loss nan (nan)	prob nan (nan)	GS 35.219 (35.219)	mem 39.194
Train: [69][80/750]	BT 0.189 (1.439)	DT 0.003 (1.312)	loss nan (nan)	prob nan (nan)	GS 32.172 (32.172)	mem 39.205
Train: [69][85/750]	BT 0.181 (1.365)	DT 0.011 (1.235)	loss nan (nan)	prob nan (nan)	GS 31.219 (31.219)	mem 39.292
Train: [69][90/750]	BT 0.097 (1.434)	DT 0.001 (1.308)	loss nan (nan)	prob nan (nan)	GS 35.391 (35.391)	mem 39.251
Train: [69][95/750]	BT 0.096 (1.366)	DT 0.010 (1.239)	loss nan (nan)	prob nan (nan)	GS 31.578 (31.578)	mem 39.287
Train: [69][100/750]	BT 0.078 (1.439)	DT 0.001 (1.312)	loss nan (nan)	prob nan (nan)	GS 33.906 (33.906)	mem 39.473
Train: [69][105/750]	BT 0.184 (1.378)	DT 0.002 (1.250)	loss nan (nan)	prob nan (nan)	GS 29.375 (29.375)	mem 39.403
Train: [69][110/750]	BT 11.825 (1.427)	DT 11.708 (1.299)	loss nan (nan)	prob nan (nan)	GS 36.328 (36.328)	mem 39.611
Train: [69][115/750]	BT 0.128 (1.371)	DT 0.002 (1.243)	loss nan (nan)	prob nan (nan)	GS 33.078 (33.078)	mem 39.658
Train: [69][120/750]	BT 0.140 (1.319)	DT 0.018 (1.191)	loss nan (nan)	prob nan (nan)	GS 34.484 (34.484)	mem 39.805
Train: [69][125/750]	BT 0.088 (1.356)	DT 0.002 (1.227)	loss nan (nan)	prob nan (nan)	GS 27.547 (27.547)	mem 39.572
Train: [69][130/750]	BT 0.138 (1.309)	DT 0.001 (1.180)	loss nan (nan)	prob nan (nan)	GS 34.219 (34.219)	mem 39.561
Train: [69][135/750]	BT 0.098 (1.370)	DT 0.002 (1.242)	loss nan (nan)	prob nan (nan)	GS 25.547 (25.547)	mem 39.756
Train: [69][140/750]	BT 0.075 (1.324)	DT 0.001 (1.198)	loss nan (nan)	prob nan (nan)	GS 33.219 (33.219)	mem 39.700
Train: [69][145/750]	BT 0.198 (1.283)	DT 0.016 (1.157)	loss nan (nan)	prob nan (nan)	GS 33.094 (33.094)	mem 39.821
Train: [69][150/750]	BT 0.106 (1.317)	DT 0.024 (1.191)	loss nan (nan)	prob nan (nan)	GS 34.250 (34.250)	mem 39.883
Train: [69][155/750]	BT 0.230 (1.279)	DT 0.031 (1.153)	loss nan (nan)	prob nan (nan)	GS 27.141 (27.141)	mem 39.848
Train: [69][160/750]	BT 0.183 (1.328)	DT 0.002 (1.201)	loss nan (nan)	prob nan (nan)	GS 31.938 (31.938)	mem 39.966
Train: [69][165/750]	BT 0.122 (1.291)	DT 0.002 (1.165)	loss nan (nan)	prob nan (nan)	GS 28.281 (28.281)	mem 40.001
Train: [69][170/750]	BT 9.643 (1.312)	DT 9.426 (1.186)	loss nan (nan)	prob nan (nan)	GS 38.688 (38.688)	mem 40.133
Train: [69][175/750]	BT 0.085 (1.277)	DT 0.002 (1.152)	loss nan (nan)	prob nan (nan)	GS 31.516 (31.516)	mem 39.934
Train: [69][180/750]	BT 0.239 (1.245)	DT 0.011 (1.120)	loss nan (nan)	prob nan (nan)	GS 38.422 (38.422)	mem 40.066
Train: [69][185/750]	BT 0.087 (1.289)	DT 0.001 (1.165)	loss nan (nan)	prob nan (nan)	GS 29.234 (29.234)	mem 39.973
Train: [69][190/750]	BT 0.160 (1.259)	DT 0.002 (1.135)	loss nan (nan)	prob nan (nan)	GS 34.859 (34.859)	mem 39.975
Train: [69][195/750]	BT 0.078 (1.289)	DT 0.002 (1.165)	loss nan (nan)	prob nan (nan)	GS 42.328 (42.328)	mem 39.953
Train: [69][200/750]	BT 0.112 (1.259)	DT 0.001 (1.136)	loss nan (nan)	prob nan (nan)	GS 33.250 (33.250)	mem 39.956
Train: [69][205/750]	BT 0.083 (1.231)	DT 0.002 (1.108)	loss nan (nan)	prob nan (nan)	GS 33.797 (33.797)	mem 39.965
Train: [69][210/750]	BT 0.116 (1.262)	DT 0.001 (1.139)	loss nan (nan)	prob nan (nan)	GS 31.312 (31.312)	mem 39.997
Train: [69][215/750]	BT 0.094 (1.236)	DT 0.017 (1.113)	loss nan (nan)	prob nan (nan)	GS 31.453 (31.453)	mem 39.996
Train: [69][220/750]	BT 0.168 (1.266)	DT 0.008 (1.142)	loss nan (nan)	prob nan (nan)	GS 36.312 (36.312)	mem 39.989
Train: [69][225/750]	BT 0.067 (1.240)	DT 0.002 (1.117)	loss nan (nan)	prob nan (nan)	GS 25.234 (25.234)	mem 40.029
Train: [69][230/750]	BT 11.655 (1.266)	DT 11.570 (1.143)	loss nan (nan)	prob nan (nan)	GS 34.109 (34.109)	mem 40.085
Train: [69][235/750]	BT 0.088 (1.242)	DT 0.002 (1.118)	loss nan (nan)	prob nan (nan)	GS 31.906 (31.906)	mem 40.026
Train: [69][240/750]	BT 0.076 (1.218)	DT 0.001 (1.095)	loss nan (nan)	prob nan (nan)	GS 37.219 (37.219)	mem 39.966
Train: [69][245/750]	BT 0.167 (1.237)	DT 0.025 (1.114)	loss nan (nan)	prob nan (nan)	GS 30.172 (30.172)	mem 40.055
Train: [69][250/750]	BT 0.108 (1.215)	DT 0.002 (1.092)	loss nan (nan)	prob nan (nan)	GS 32.547 (32.547)	mem 40.060
Train: [69][255/750]	BT 0.074 (1.233)	DT 0.002 (1.111)	loss nan (nan)	prob nan (nan)	GS 28.266 (28.266)	mem 40.071
Train: [69][260/750]	BT 0.294 (1.213)	DT 0.017 (1.090)	loss nan (nan)	prob nan (nan)	GS 33.891 (33.891)	mem 40.066
Train: [69][265/750]	BT 0.155 (1.193)	DT 0.002 (1.069)	loss nan (nan)	prob nan (nan)	GS 30.750 (30.750)	mem 40.067
Train: [69][270/750]	BT 0.404 (1.209)	DT 0.004 (1.084)	loss nan (nan)	prob nan (nan)	GS 32.703 (32.703)	mem 39.979
Train: [69][275/750]	BT 0.102 (1.189)	DT 0.002 (1.064)	loss nan (nan)	prob nan (nan)	GS 28.719 (28.719)	mem 40.019
Train: [69][280/750]	BT 0.191 (1.208)	DT 0.002 (1.082)	loss nan (nan)	prob nan (nan)	GS 34.375 (34.375)	mem 40.086
Train: [69][285/750]	BT 0.232 (1.190)	DT 0.016 (1.064)	loss nan (nan)	prob nan (nan)	GS 32.844 (32.844)	mem 40.088
Train: [69][290/750]	BT 17.062 (1.231)	DT 16.935 (1.104)	loss nan (nan)	prob nan (nan)	GS 36.719 (36.719)	mem 40.015
Train: [69][295/750]	BT 0.125 (1.213)	DT 0.004 (1.086)	loss nan (nan)	prob nan (nan)	GS 28.312 (28.312)	mem 40.077
Train: [69][300/750]	BT 0.080 (1.195)	DT 0.003 (1.068)	loss nan (nan)	prob nan (nan)	GS 33.359 (33.359)	mem 40.024
Train: [69][305/750]	BT 0.088 (1.209)	DT 0.002 (1.082)	loss nan (nan)	prob nan (nan)	GS 28.938 (28.938)	mem 40.049
Train: [69][310/750]	BT 0.182 (1.191)	DT 0.002 (1.065)	loss nan (nan)	prob nan (nan)	GS 35.219 (35.219)	mem 40.058
Train: [69][315/750]	BT 0.175 (1.215)	DT 0.001 (1.088)	loss nan (nan)	prob nan (nan)	GS 29.016 (29.016)	mem 39.906
Train: [69][320/750]	BT 0.087 (1.198)	DT 0.002 (1.071)	loss nan (nan)	prob nan (nan)	GS 36.969 (36.969)	mem 39.982
Train: [69][325/750]	BT 0.135 (1.181)	DT 0.004 (1.055)	loss nan (nan)	prob nan (nan)	GS 29.125 (29.125)	mem 39.983
Train: [69][330/750]	BT 0.093 (1.195)	DT 0.001 (1.069)	loss nan (nan)	prob nan (nan)	GS 33.719 (33.719)	mem 40.057
Train: [69][335/750]	BT 0.254 (1.179)	DT 0.001 (1.053)	loss nan (nan)	prob nan (nan)	GS 30.203 (30.203)	mem 40.061
Train: [69][340/750]	BT 0.095 (1.202)	DT 0.001 (1.075)	loss nan (nan)	prob nan (nan)	GS 31.391 (31.391)	mem 40.021
Train: [69][345/750]	BT 0.111 (1.186)	DT 0.007 (1.060)	loss nan (nan)	prob nan (nan)	GS 29.797 (29.797)	mem 40.052
Train: [69][350/750]	BT 12.166 (1.206)	DT 11.995 (1.079)	loss nan (nan)	prob nan (nan)	GS 32.250 (32.250)	mem 40.119
Train: [69][355/750]	BT 0.117 (1.190)	DT 0.002 (1.064)	loss nan (nan)	prob nan (nan)	GS 29.609 (29.609)	mem 40.010
Train: [69][360/750]	BT 0.086 (1.176)	DT 0.001 (1.049)	loss nan (nan)	prob nan (nan)	GS 35.422 (35.422)	mem 39.933
Train: [69][365/750]	BT 0.234 (1.193)	DT 0.002 (1.066)	loss nan (nan)	prob nan (nan)	GS 33.984 (33.984)	mem 40.087
Train: [69][370/750]	BT 0.164 (1.179)	DT 0.011 (1.051)	loss nan (nan)	prob nan (nan)	GS 37.234 (37.234)	mem 40.026
Train: [69][375/750]	BT 0.106 (1.196)	DT 0.001 (1.069)	loss nan (nan)	prob nan (nan)	GS 28.828 (28.828)	mem 40.020
Train: [69][380/750]	BT 0.086 (1.181)	DT 0.001 (1.055)	loss nan (nan)	prob nan (nan)	GS 37.703 (37.703)	mem 40.176
Train: [69][385/750]	BT 0.142 (1.167)	DT 0.002 (1.041)	loss nan (nan)	prob nan (nan)	GS 28.719 (28.719)	mem 40.041
Train: [69][390/750]	BT 0.088 (1.184)	DT 0.001 (1.058)	loss nan (nan)	prob nan (nan)	GS 36.266 (36.266)	mem 40.003
Train: [69][395/750]	BT 0.126 (1.171)	DT 0.023 (1.044)	loss nan (nan)	prob nan (nan)	GS 31.875 (31.875)	mem 40.011
Train: [69][400/750]	BT 0.176 (1.189)	DT 0.002 (1.062)	loss nan (nan)	prob nan (nan)	GS 32.641 (32.641)	mem 40.241
Train: [69][405/750]	BT 0.135 (1.176)	DT 0.015 (1.049)	loss nan (nan)	prob nan (nan)	GS 37.938 (37.938)	mem 40.009
Train: [69][410/750]	BT 10.205 (1.188)	DT 9.980 (1.061)	loss nan (nan)	prob nan (nan)	GS 34.625 (34.625)	mem 39.930
Train: [69][415/750]	BT 0.094 (1.175)	DT 0.002 (1.048)	loss nan (nan)	prob nan (nan)	GS 30.594 (30.594)	mem 39.931
Train: [69][420/750]	BT 0.355 (1.163)	DT 0.007 (1.035)	loss nan (nan)	prob nan (nan)	GS 33.719 (33.719)	mem 39.981
Train: [69][425/750]	BT 0.081 (1.179)	DT 0.005 (1.051)	loss nan (nan)	prob nan (nan)	GS 31.516 (31.516)	mem 39.870
Train: [69][430/750]	BT 0.216 (1.167)	DT 0.009 (1.039)	loss nan (nan)	prob nan (nan)	GS 31.375 (31.375)	mem 39.896
Train: [69][435/750]	BT 0.089 (1.177)	DT 0.002 (1.049)	loss nan (nan)	prob nan (nan)	GS 35.500 (35.500)	mem 40.109
Train: [69][440/750]	BT 0.089 (1.165)	DT 0.002 (1.037)	loss nan (nan)	prob nan (nan)	GS 33.703 (33.703)	mem 40.010
Train: [69][445/750]	BT 0.179 (1.154)	DT 0.005 (1.026)	loss nan (nan)	prob nan (nan)	GS 27.766 (27.766)	mem 39.936
Train: [69][450/750]	BT 0.165 (1.172)	DT 0.008 (1.044)	loss nan (nan)	prob nan (nan)	GS 32.344 (32.344)	mem 39.951
Train: [69][455/750]	BT 0.134 (1.161)	DT 0.040 (1.032)	loss nan (nan)	prob nan (nan)	GS 37.422 (37.422)	mem 39.898
Train: [69][460/750]	BT 0.102 (1.177)	DT 0.007 (1.049)	loss nan (nan)	prob nan (nan)	GS 35.156 (35.156)	mem 39.856
Train: [69][465/750]	BT 0.084 (1.166)	DT 0.002 (1.037)	loss nan (nan)	prob nan (nan)	GS 30.078 (30.078)	mem 39.909
Train: [69][470/750]	BT 9.247 (1.175)	DT 9.125 (1.046)	loss nan (nan)	prob nan (nan)	GS 33.484 (33.484)	mem 39.908
Train: [69][475/750]	BT 0.098 (1.163)	DT 0.001 (1.035)	loss nan (nan)	prob nan (nan)	GS 31.875 (31.875)	mem 39.984
Train: [69][480/750]	BT 0.196 (1.153)	DT 0.051 (1.024)	loss nan (nan)	prob nan (nan)	GS 35.094 (35.094)	mem 40.144
Train: [69][485/750]	BT 0.229 (1.169)	DT 0.001 (1.040)	loss nan (nan)	prob nan (nan)	GS 31.953 (31.953)	mem 39.999
Train: [69][490/750]	BT 0.152 (1.158)	DT 0.023 (1.030)	loss nan (nan)	prob nan (nan)	GS 33.734 (33.734)	mem 40.003
Train: [69][495/750]	BT 0.071 (1.167)	DT 0.002 (1.039)	loss nan (nan)	prob nan (nan)	GS 30.125 (30.125)	mem 40.089
Train: [69][500/750]	BT 0.100 (1.157)	DT 0.006 (1.029)	loss nan (nan)	prob nan (nan)	GS 34.328 (34.328)	mem 40.007
Train: [69][505/750]	BT 0.125 (1.146)	DT 0.002 (1.019)	loss nan (nan)	prob nan (nan)	GS 31.406 (31.406)	mem 40.008
Train: [69][510/750]	BT 0.201 (1.164)	DT 0.001 (1.036)	loss nan (nan)	prob nan (nan)	GS 31.656 (31.656)	mem 40.010
Train: [69][515/750]	BT 0.176 (1.154)	DT 0.007 (1.026)	loss nan (nan)	prob nan (nan)	GS 29.688 (29.688)	mem 40.097
Train: [69][520/750]	BT 0.076 (1.163)	DT 0.001 (1.036)	loss nan (nan)	prob nan (nan)	GS 30.438 (30.438)	mem 40.037
Train: [69][525/750]	BT 0.248 (1.154)	DT 0.002 (1.027)	loss nan (nan)	prob nan (nan)	GS 31.422 (31.422)	mem 40.127
Train: [69][530/750]	BT 14.449 (1.172)	DT 14.269 (1.044)	loss nan (nan)	prob nan (nan)	GS 36.672 (36.672)	mem 39.866
Train: [69][535/750]	BT 0.069 (1.162)	DT 0.001 (1.034)	loss nan (nan)	prob nan (nan)	GS 34.672 (34.672)	mem 39.928
Train: [69][540/750]	BT 0.147 (1.152)	DT 0.002 (1.025)	loss nan (nan)	prob nan (nan)	GS 34.812 (34.812)	mem 39.908
Train: [69][545/750]	BT 0.070 (1.165)	DT 0.001 (1.038)	loss nan (nan)	prob nan (nan)	GS 32.516 (32.516)	mem 39.975
Train: [69][550/750]	BT 0.124 (1.156)	DT 0.010 (1.028)	loss nan (nan)	prob nan (nan)	GS 30.188 (30.188)	mem 40.007
Train: [69][555/750]	BT 0.072 (1.171)	DT 0.001 (1.044)	loss nan (nan)	prob nan (nan)	GS 33.594 (33.594)	mem 40.054
Train: [69][560/750]	BT 0.073 (1.161)	DT 0.001 (1.034)	loss nan (nan)	prob nan (nan)	GS 31.141 (31.141)	mem 40.166
Train: [69][565/750]	BT 0.102 (1.152)	DT 0.002 (1.025)	loss nan (nan)	prob nan (nan)	GS 29.625 (29.625)	mem 40.056
Train: [69][570/750]	BT 0.067 (1.165)	DT 0.001 (1.039)	loss nan (nan)	prob nan (nan)	GS 34.594 (34.594)	mem 40.123
Train: [69][575/750]	BT 0.090 (1.156)	DT 0.002 (1.030)	loss nan (nan)	prob nan (nan)	GS 31.641 (31.641)	mem 40.137
Train: [69][580/750]	BT 0.164 (1.169)	DT 0.012 (1.043)	loss nan (nan)	prob nan (nan)	GS 34.422 (34.422)	mem 40.074
Train: [69][585/750]	BT 0.132 (1.160)	DT 0.001 (1.034)	loss nan (nan)	prob nan (nan)	GS 32.516 (32.516)	mem 40.075
Train: [69][590/750]	BT 10.414 (1.169)	DT 10.311 (1.042)	loss nan (nan)	prob nan (nan)	GS 37.516 (37.516)	mem 40.091
Train: [69][595/750]	BT 0.148 (1.160)	DT 0.005 (1.034)	loss nan (nan)	prob nan (nan)	GS 32.047 (32.047)	mem 40.295
Train: [69][600/750]	BT 0.166 (1.151)	DT 0.002 (1.025)	loss nan (nan)	prob nan (nan)	GS 37.109 (37.109)	mem 40.094
Train: [69][605/750]	BT 0.160 (1.163)	DT 0.004 (1.037)	loss nan (nan)	prob nan (nan)	GS 32.219 (32.219)	mem 40.059
Train: [69][610/750]	BT 0.155 (1.155)	DT 0.006 (1.029)	loss nan (nan)	prob nan (nan)	GS 33.547 (33.547)	mem 40.062
Train: [69][615/750]	BT 0.092 (1.167)	DT 0.002 (1.041)	loss nan (nan)	prob nan (nan)	GS 32.234 (32.234)	mem 40.032
Train: [69][620/750]	BT 0.113 (1.159)	DT 0.001 (1.032)	loss nan (nan)	prob nan (nan)	GS 33.578 (33.578)	mem 40.030
Train: [69][625/750]	BT 0.230 (1.151)	DT 0.028 (1.024)	loss nan (nan)	prob nan (nan)	GS 37.406 (37.406)	mem 40.033
Train: [69][630/750]	BT 0.074 (1.162)	DT 0.001 (1.036)	loss nan (nan)	prob nan (nan)	GS 37.531 (37.531)	mem 40.039
Train: [69][635/750]	BT 0.168 (1.154)	DT 0.003 (1.027)	loss nan (nan)	prob nan (nan)	GS 29.984 (29.984)	mem 40.038
Train: [69][640/750]	BT 0.199 (1.160)	DT 0.003 (1.033)	loss nan (nan)	prob nan (nan)	GS 38.188 (38.188)	mem 40.064
Train: [69][645/750]	BT 0.085 (1.152)	DT 0.002 (1.025)	loss nan (nan)	prob nan (nan)	GS 32.812 (32.812)	mem 40.062
Train: [69][650/750]	BT 13.711 (1.165)	DT 13.564 (1.038)	loss nan (nan)	prob nan (nan)	GS 31.750 (31.750)	mem 40.149
Train: [69][655/750]	BT 0.115 (1.157)	DT 0.002 (1.030)	loss nan (nan)	prob nan (nan)	GS 33.891 (33.891)	mem 40.099
Train: [69][660/750]	BT 0.089 (1.150)	DT 0.002 (1.024)	loss nan (nan)	prob nan (nan)	GS 33.766 (33.766)	mem 40.058
Train: [69][665/750]	BT 0.145 (1.158)	DT 0.002 (1.032)	loss nan (nan)	prob nan (nan)	GS 35.156 (35.156)	mem 40.209
Train: [69][670/750]	BT 0.086 (1.151)	DT 0.004 (1.024)	loss nan (nan)	prob nan (nan)	GS 35.922 (35.922)	mem 40.140
Train: [69][675/750]	BT 0.183 (1.160)	DT 0.004 (1.034)	loss nan (nan)	prob nan (nan)	GS 32.031 (32.031)	mem 40.247
Train: [69][680/750]	BT 0.742 (1.154)	DT 0.638 (1.027)	loss nan (nan)	prob nan (nan)	GS 36.609 (36.609)	mem 40.226
Train: [69][685/750]	BT 0.089 (1.146)	DT 0.001 (1.020)	loss nan (nan)	prob nan (nan)	GS 34.938 (34.938)	mem 40.239
Train: [69][690/750]	BT 0.158 (1.151)	DT 0.004 (1.024)	loss nan (nan)	prob nan (nan)	GS 35.031 (35.031)	mem 40.094
Train: [69][695/750]	BT 0.093 (1.154)	DT 0.001 (1.028)	loss nan (nan)	prob nan (nan)	GS 34.297 (34.297)	mem 40.144
Train: [69][700/750]	BT 0.137 (1.147)	DT 0.002 (1.020)	loss nan (nan)	prob nan (nan)	GS 32.125 (32.125)	mem 40.159
Train: [69][705/750]	BT 0.088 (1.157)	DT 0.002 (1.030)	loss nan (nan)	prob nan (nan)	GS 32.703 (32.703)	mem 40.172
arpack error, retry= 0
Train: [69][710/750]	BT 1.013 (1.151)	DT 0.867 (1.024)	loss nan (nan)	prob nan (nan)	GS 34.938 (34.938)	mem 40.161
Train: [69][715/750]	BT 0.102 (1.144)	DT 0.003 (1.017)	loss nan (nan)	prob nan (nan)	GS 35.547 (35.547)	mem 40.208
Train: [69][720/750]	BT 0.099 (1.156)	DT 0.004 (1.029)	loss nan (nan)	prob nan (nan)	GS 30.375 (30.375)	mem 40.169
Train: [69][725/750]	BT 0.180 (1.149)	DT 0.016 (1.022)	loss nan (nan)	prob nan (nan)	GS 31.797 (31.797)	mem 40.194
Train: [69][730/750]	BT 0.159 (1.156)	DT 0.016 (1.030)	loss nan (nan)	prob nan (nan)	GS 38.344 (38.344)	mem 40.088
Train: [69][735/750]	BT 0.119 (1.149)	DT 0.002 (1.023)	loss nan (nan)	prob nan (nan)	GS 29.547 (29.547)	mem 39.880
Train: [69][740/750]	BT 6.123 (1.150)	DT 6.027 (1.024)	loss nan (nan)	prob nan (nan)	GS 33.203 (33.203)	mem 7.759
Train: [69][745/750]	BT 0.088 (1.143)	DT 0.002 (1.017)	loss nan (nan)	prob nan (nan)	GS 37.094 (37.094)	mem 7.759
Train: [69][750/750]	BT 0.083 (1.136)	DT 0.001 (1.010)	loss nan (nan)	prob nan (nan)	GS 40.469 (40.469)	mem 8.037
Train: [69][755/750]	BT 0.066 (1.132)	DT 0.001 (1.006)	loss nan (nan)	prob nan (nan)	GS 36.875 (36.875)	mem 7.688
epoch 69, total time 854.74
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [70][1/750]	BT 22.586 (22.586)	DT 22.404 (22.404)	loss nan (nan)	prob nan (nan)	GS 34.094 (34.094)	mem 38.879
Train: [70][5/750]	BT 0.164 (5.449)	DT 0.002 (5.289)	loss nan (nan)	prob nan (nan)	GS 31.422 (31.422)	mem 38.776
Train: [70][10/750]	BT 0.085 (2.869)	DT 0.002 (2.718)	loss nan (nan)	prob nan (nan)	GS 36.094 (36.094)	mem 38.822
Train: [70][15/750]	BT 0.195 (2.487)	DT 0.020 (2.334)	loss nan (nan)	prob nan (nan)	GS 36.984 (36.984)	mem 38.968
Train: [70][20/750]	BT 0.141 (2.243)	DT 0.008 (2.101)	loss nan (nan)	prob nan (nan)	GS 32.141 (32.141)	mem 39.032
Train: [70][25/750]	BT 1.942 (1.901)	DT 1.718 (1.750)	loss nan (nan)	prob nan (nan)	GS 29.547 (29.547)	mem 39.066
Train: [70][30/750]	BT 0.154 (1.956)	DT 0.004 (1.802)	loss nan (nan)	prob nan (nan)	GS 30.016 (30.016)	mem 39.305
Train: [70][35/750]	BT 0.108 (1.701)	DT 0.002 (1.547)	loss nan (nan)	prob nan (nan)	GS 30.250 (30.250)	mem 39.373
Train: [70][40/750]	BT 9.847 (1.763)	DT 9.736 (1.612)	loss nan (nan)	prob nan (nan)	GS 35.078 (35.078)	mem 39.743
Train: [70][45/750]	BT 0.182 (1.638)	DT 0.002 (1.487)	loss nan (nan)	prob nan (nan)	GS 29.922 (29.922)	mem 39.821
Train: [70][50/750]	BT 2.670 (1.539)	DT 2.562 (1.391)	loss nan (nan)	prob nan (nan)	GS 32.609 (32.609)	mem 39.720
Train: [70][55/750]	BT 0.212 (1.574)	DT 0.010 (1.426)	loss nan (nan)	prob nan (nan)	GS 29.766 (29.766)	mem 40.024
Train: [70][60/750]	BT 0.093 (1.456)	DT 0.001 (1.307)	loss nan (nan)	prob nan (nan)	GS 31.594 (31.594)	mem 39.718
Train: [70][65/750]	BT 0.125 (1.511)	DT 0.003 (1.364)	loss nan (nan)	prob nan (nan)	GS 32.422 (32.422)	mem 39.763
Train: [70][70/750]	BT 2.624 (1.448)	DT 2.516 (1.302)	loss nan (nan)	prob nan (nan)	GS 33.016 (33.016)	mem 39.819
Train: [70][75/750]	BT 0.105 (1.418)	DT 0.002 (1.272)	loss nan (nan)	prob nan (nan)	GS 44.359 (44.359)	mem 39.786
Train: [70][80/750]	BT 0.183 (1.443)	DT 0.002 (1.299)	loss nan (nan)	prob nan (nan)	GS 37.375 (37.375)	mem 39.810
Train: [70][85/750]	BT 0.140 (1.371)	DT 0.001 (1.228)	loss nan (nan)	prob nan (nan)	GS 30.203 (30.203)	mem 39.829
Train: [70][90/750]	BT 0.114 (1.427)	DT 0.002 (1.284)	loss nan (nan)	prob nan (nan)	GS 28.797 (28.797)	mem 39.968
Train: [70][95/750]	BT 0.189 (1.386)	DT 0.001 (1.244)	loss nan (nan)	prob nan (nan)	GS 31.547 (31.547)	mem 39.793
Train: [70][100/750]	BT 7.830 (1.406)	DT 7.689 (1.264)	loss nan (nan)	prob nan (nan)	GS 31.562 (31.562)	mem 40.074
Train: [70][105/750]	BT 0.102 (1.364)	DT 0.012 (1.223)	loss nan (nan)	prob nan (nan)	GS 30.703 (30.703)	mem 39.769
Train: [70][110/750]	BT 0.133 (1.330)	DT 0.011 (1.190)	loss nan (nan)	prob nan (nan)	GS 34.859 (34.859)	mem 39.790
Train: [70][115/750]	BT 0.099 (1.337)	DT 0.002 (1.196)	loss nan (nan)	prob nan (nan)	GS 33.875 (33.875)	mem 39.902
Train: [70][120/750]	BT 0.071 (1.352)	DT 0.001 (1.212)	loss nan (nan)	prob nan (nan)	GS 31.328 (31.328)	mem 39.868
Train: [70][125/750]	BT 0.104 (1.328)	DT 0.002 (1.189)	loss nan (nan)	prob nan (nan)	GS 29.406 (29.406)	mem 39.992
Train: [70][130/750]	BT 10.026 (1.359)	DT 9.883 (1.219)	loss nan (nan)	prob nan (nan)	GS 33.984 (33.984)	mem 39.842
Train: [70][135/750]	BT 0.103 (1.314)	DT 0.002 (1.174)	loss nan (nan)	prob nan (nan)	GS 26.938 (26.938)	mem 39.804
Train: [70][140/750]	BT 0.110 (1.279)	DT 0.002 (1.139)	loss nan (nan)	prob nan (nan)	GS 35.781 (35.781)	mem 39.871
Train: [70][145/750]	BT 0.087 (1.287)	DT 0.002 (1.147)	loss nan (nan)	prob nan (nan)	GS 33.531 (33.531)	mem 39.818
Train: [70][150/750]	BT 4.636 (1.292)	DT 4.403 (1.151)	loss nan (nan)	prob nan (nan)	GS 33.422 (33.422)	mem 40.016
Train: [70][155/750]	BT 0.118 (1.298)	DT 0.002 (1.158)	loss nan (nan)	prob nan (nan)	GS 27.109 (27.109)	mem 39.870
Train: [70][160/750]	BT 1.739 (1.272)	DT 1.492 (1.131)	loss nan (nan)	prob nan (nan)	GS 34.922 (34.922)	mem 39.917
Train: [70][165/750]	BT 0.086 (1.271)	DT 0.002 (1.130)	loss nan (nan)	prob nan (nan)	GS 31.531 (31.531)	mem 39.813
Train: [70][170/750]	BT 0.173 (1.272)	DT 0.002 (1.132)	loss nan (nan)	prob nan (nan)	GS 31.984 (31.984)	mem 40.102
Train: [70][175/750]	BT 0.211 (1.280)	DT 0.002 (1.139)	loss nan (nan)	prob nan (nan)	GS 33.281 (33.281)	mem 39.890
Train: [70][180/750]	BT 0.104 (1.290)	DT 0.001 (1.150)	loss nan (nan)	prob nan (nan)	GS 38.266 (38.266)	mem 39.878
Train: [70][185/750]	BT 0.092 (1.259)	DT 0.006 (1.119)	loss nan (nan)	prob nan (nan)	GS 30.250 (30.250)	mem 39.878
Train: [70][190/750]	BT 9.991 (1.305)	DT 9.888 (1.164)	loss nan (nan)	prob nan (nan)	GS 33.062 (33.062)	mem 39.909
Train: [70][195/750]	BT 0.131 (1.274)	DT 0.001 (1.135)	loss nan (nan)	prob nan (nan)	GS 31.609 (31.609)	mem 39.911
Train: [70][200/750]	BT 0.114 (1.259)	DT 0.002 (1.120)	loss nan (nan)	prob nan (nan)	GS 36.234 (36.234)	mem 39.934
Train: [70][205/750]	BT 0.108 (1.278)	DT 0.001 (1.138)	loss nan (nan)	prob nan (nan)	GS 29.016 (29.016)	mem 39.988
Train: [70][210/750]	BT 2.769 (1.263)	DT 2.658 (1.124)	loss nan (nan)	prob nan (nan)	GS 33.562 (33.562)	mem 39.940
Train: [70][215/750]	BT 0.166 (1.277)	DT 0.001 (1.138)	loss nan (nan)	prob nan (nan)	GS 31.203 (31.203)	mem 39.976
Train: [70][220/750]	BT 0.206 (1.252)	DT 0.010 (1.113)	loss nan (nan)	prob nan (nan)	GS 36.922 (36.922)	mem 39.964
Train: [70][225/750]	BT 0.164 (1.248)	DT 0.002 (1.110)	loss nan (nan)	prob nan (nan)	GS 32.000 (32.000)	mem 39.962
Train: [70][230/750]	BT 0.093 (1.252)	DT 0.002 (1.114)	loss nan (nan)	prob nan (nan)	GS 34.625 (34.625)	mem 40.020
Train: [70][235/750]	BT 0.140 (1.245)	DT 0.006 (1.108)	loss nan (nan)	prob nan (nan)	GS 24.625 (24.625)	mem 40.009
Train: [70][240/750]	BT 0.141 (1.254)	DT 0.004 (1.118)	loss nan (nan)	prob nan (nan)	GS 38.406 (38.406)	mem 39.923
Train: [70][245/750]	BT 0.151 (1.231)	DT 0.002 (1.095)	loss nan (nan)	prob nan (nan)	GS 31.953 (31.953)	mem 39.990
Train: [70][250/750]	BT 9.101 (1.258)	DT 9.005 (1.121)	loss nan (nan)	prob nan (nan)	GS 37.047 (37.047)	mem 39.921
Train: [70][255/750]	BT 0.091 (1.235)	DT 0.004 (1.099)	loss nan (nan)	prob nan (nan)	GS 27.922 (27.922)	mem 39.953
Train: [70][260/750]	BT 0.192 (1.220)	DT 0.013 (1.084)	loss nan (nan)	prob nan (nan)	GS 35.984 (35.984)	mem 39.909
Train: [70][265/750]	BT 0.199 (1.248)	DT 0.002 (1.111)	loss nan (nan)	prob nan (nan)	GS 30.203 (30.203)	mem 39.978
Train: [70][270/750]	BT 0.102 (1.227)	DT 0.001 (1.091)	loss nan (nan)	prob nan (nan)	GS 30.859 (30.859)	mem 39.983
Train: [70][275/750]	BT 0.159 (1.252)	DT 0.003 (1.116)	loss nan (nan)	prob nan (nan)	GS 30.047 (30.047)	mem 39.990
Train: [70][280/750]	BT 0.087 (1.231)	DT 0.001 (1.096)	loss nan (nan)	prob nan (nan)	GS 31.688 (31.688)	mem 39.993
Train: [70][285/750]	BT 0.079 (1.212)	DT 0.001 (1.077)	loss nan (nan)	prob nan (nan)	GS 31.922 (31.922)	mem 39.991
Train: [70][290/750]	BT 0.128 (1.241)	DT 0.001 (1.106)	loss nan (nan)	prob nan (nan)	GS 34.766 (34.766)	mem 40.005
Train: [70][295/750]	BT 0.101 (1.222)	DT 0.007 (1.088)	loss nan (nan)	prob nan (nan)	GS 32.328 (32.328)	mem 40.036
Train: [70][300/750]	BT 0.245 (1.238)	DT 0.012 (1.104)	loss nan (nan)	prob nan (nan)	GS 30.562 (30.562)	mem 40.266
Train: [70][305/750]	BT 0.129 (1.220)	DT 0.008 (1.086)	loss nan (nan)	prob nan (nan)	GS 28.547 (28.547)	mem 39.955
Train: [70][310/750]	BT 9.276 (1.233)	DT 9.191 (1.098)	loss nan (nan)	prob nan (nan)	GS 33.531 (33.531)	mem 40.037
Train: [70][315/750]	BT 0.098 (1.215)	DT 0.004 (1.080)	loss nan (nan)	prob nan (nan)	GS 34.109 (34.109)	mem 40.039
Train: [70][320/750]	BT 0.135 (1.198)	DT 0.011 (1.064)	loss nan (nan)	prob nan (nan)	GS 34.594 (34.594)	mem 40.039
Train: [70][325/750]	BT 0.112 (1.222)	DT 0.003 (1.088)	loss nan (nan)	prob nan (nan)	GS 33.578 (33.578)	mem 40.045
Train: [70][330/750]	BT 0.179 (1.206)	DT 0.002 (1.072)	loss nan (nan)	prob nan (nan)	GS 33.875 (33.875)	mem 40.071
Train: [70][335/750]	BT 0.173 (1.237)	DT 0.026 (1.103)	loss nan (nan)	prob nan (nan)	GS 30.688 (30.688)	mem 39.929
Train: [70][340/750]	BT 0.103 (1.221)	DT 0.003 (1.086)	loss nan (nan)	prob nan (nan)	GS 34.891 (34.891)	mem 39.943
Train: [70][345/750]	BT 0.077 (1.204)	DT 0.002 (1.071)	loss nan (nan)	prob nan (nan)	GS 29.984 (29.984)	mem 40.093
Train: [70][350/750]	BT 0.098 (1.221)	DT 0.001 (1.087)	loss nan (nan)	prob nan (nan)	GS 33.906 (33.906)	mem 40.010
Train: [70][355/750]	BT 0.161 (1.205)	DT 0.024 (1.072)	loss nan (nan)	prob nan (nan)	GS 32.562 (32.562)	mem 40.009
Train: [70][360/750]	BT 0.153 (1.220)	DT 0.003 (1.087)	loss nan (nan)	prob nan (nan)	GS 35.609 (35.609)	mem 39.978
Train: [70][365/750]	BT 0.146 (1.205)	DT 0.002 (1.072)	loss nan (nan)	prob nan (nan)	GS 32.828 (32.828)	mem 40.032
Train: [70][370/750]	BT 14.206 (1.229)	DT 14.124 (1.095)	loss nan (nan)	prob nan (nan)	GS 34.078 (34.078)	mem 40.043
Train: [70][375/750]	BT 0.121 (1.214)	DT 0.004 (1.081)	loss nan (nan)	prob nan (nan)	GS 32.547 (32.547)	mem 40.055
Train: [70][380/750]	BT 0.120 (1.199)	DT 0.001 (1.067)	loss nan (nan)	prob nan (nan)	GS 34.156 (34.156)	mem 40.061
Train: [70][385/750]	BT 0.179 (1.212)	DT 0.002 (1.079)	loss nan (nan)	prob nan (nan)	GS 30.750 (30.750)	mem 39.998
Train: [70][390/750]	BT 0.157 (1.199)	DT 0.005 (1.065)	loss nan (nan)	prob nan (nan)	GS 34.125 (34.125)	mem 40.158
Train: [70][395/750]	BT 0.112 (1.219)	DT 0.002 (1.086)	loss nan (nan)	prob nan (nan)	GS 47.953 (47.953)	mem 40.009
Train: [70][400/750]	BT 0.095 (1.205)	DT 0.002 (1.072)	loss nan (nan)	prob nan (nan)	GS 32.234 (32.234)	mem 40.098
Train: [70][405/750]	BT 0.100 (1.192)	DT 0.005 (1.059)	loss nan (nan)	prob nan (nan)	GS 30.859 (30.859)	mem 40.075
Train: [70][410/750]	BT 0.197 (1.203)	DT 0.002 (1.070)	loss nan (nan)	prob nan (nan)	GS 31.906 (31.906)	mem 40.103
Train: [70][415/750]	BT 0.150 (1.191)	DT 0.001 (1.058)	loss nan (nan)	prob nan (nan)	GS 27.859 (27.859)	mem 40.145
Train: [70][420/750]	BT 5.017 (1.206)	DT 4.923 (1.073)	loss nan (nan)	prob nan (nan)	GS 34.969 (34.969)	mem 40.141
Train: [70][425/750]	BT 0.086 (1.193)	DT 0.002 (1.060)	loss nan (nan)	prob nan (nan)	GS 31.844 (31.844)	mem 39.981
Train: [70][430/750]	BT 8.100 (1.199)	DT 7.938 (1.066)	loss nan (nan)	prob nan (nan)	GS 34.312 (34.312)	mem 39.994
Train: [70][435/750]	BT 0.110 (1.196)	DT 0.001 (1.063)	loss nan (nan)	prob nan (nan)	GS 32.344 (32.344)	mem 40.049
Train: [70][440/750]	BT 0.075 (1.184)	DT 0.002 (1.051)	loss nan (nan)	prob nan (nan)	GS 30.953 (30.953)	mem 40.140
Train: [70][445/750]	BT 0.087 (1.202)	DT 0.002 (1.070)	loss nan (nan)	prob nan (nan)	GS 33.016 (33.016)	mem 40.016
Train: [70][450/750]	BT 0.131 (1.190)	DT 0.005 (1.058)	loss nan (nan)	prob nan (nan)	GS 32.500 (32.500)	mem 40.017
Train: [70][455/750]	BT 0.204 (1.187)	DT 0.002 (1.055)	loss nan (nan)	prob nan (nan)	GS 32.047 (32.047)	mem 40.036
Train: [70][460/750]	BT 0.125 (1.191)	DT 0.001 (1.059)	loss nan (nan)	prob nan (nan)	GS 31.062 (31.062)	mem 39.991
Train: [70][465/750]	BT 0.116 (1.179)	DT 0.003 (1.048)	loss nan (nan)	prob nan (nan)	GS 29.969 (29.969)	mem 40.074
Train: [70][470/750]	BT 0.265 (1.187)	DT 0.002 (1.055)	loss nan (nan)	prob nan (nan)	GS 34.922 (34.922)	mem 40.041
Train: [70][475/750]	BT 0.170 (1.176)	DT 0.002 (1.045)	loss nan (nan)	prob nan (nan)	GS 28.375 (28.375)	mem 40.120
Train: [70][480/750]	BT 6.664 (1.189)	DT 6.478 (1.057)	loss nan (nan)	prob nan (nan)	GS 32.531 (32.531)	mem 40.014
Train: [70][485/750]	BT 0.143 (1.178)	DT 0.002 (1.046)	loss nan (nan)	prob nan (nan)	GS 32.141 (32.141)	mem 40.106
Train: [70][490/750]	BT 4.370 (1.177)	DT 4.285 (1.045)	loss nan (nan)	prob nan (nan)	GS 34.625 (34.625)	mem 40.089
Train: [70][495/750]	BT 0.156 (1.183)	DT 0.018 (1.051)	loss nan (nan)	prob nan (nan)	GS 30.625 (30.625)	mem 39.947
Train: [70][500/750]	BT 0.140 (1.173)	DT 0.013 (1.041)	loss nan (nan)	prob nan (nan)	GS 34.641 (34.641)	mem 39.923
Train: [70][505/750]	BT 0.155 (1.184)	DT 0.002 (1.052)	loss nan (nan)	prob nan (nan)	GS 32.891 (32.891)	mem 40.070
Train: [70][510/750]	BT 0.087 (1.174)	DT 0.002 (1.042)	loss nan (nan)	prob nan (nan)	GS 34.828 (34.828)	mem 40.035
Train: [70][515/750]	BT 0.148 (1.177)	DT 0.009 (1.045)	loss nan (nan)	prob nan (nan)	GS 37.031 (37.031)	mem 40.181
Train: [70][520/750]	BT 0.098 (1.174)	DT 0.001 (1.041)	loss nan (nan)	prob nan (nan)	GS 34.375 (34.375)	mem 40.105
Train: [70][525/750]	BT 0.337 (1.165)	DT 0.051 (1.033)	loss nan (nan)	prob nan (nan)	GS 26.031 (26.031)	mem 40.084
Train: [70][530/750]	BT 0.088 (1.174)	DT 0.002 (1.042)	loss nan (nan)	prob nan (nan)	GS 31.828 (31.828)	mem 40.136
Train: [70][535/750]	BT 0.098 (1.171)	DT 0.002 (1.039)	loss nan (nan)	prob nan (nan)	GS 26.984 (26.984)	mem 40.067
Train: [70][540/750]	BT 0.090 (1.179)	DT 0.002 (1.047)	loss nan (nan)	prob nan (nan)	GS 30.891 (30.891)	mem 40.229
Train: [70][545/750]	BT 0.226 (1.170)	DT 0.003 (1.038)	loss nan (nan)	prob nan (nan)	GS 32.797 (32.797)	mem 40.265
Train: [70][550/750]	BT 7.271 (1.181)	DT 7.180 (1.049)	loss nan (nan)	prob nan (nan)	GS 35.844 (35.844)	mem 40.123
Train: [70][555/750]	BT 0.196 (1.172)	DT 0.002 (1.040)	loss nan (nan)	prob nan (nan)	GS 32.156 (32.156)	mem 40.216
Train: [70][560/750]	BT 0.095 (1.166)	DT 0.002 (1.034)	loss nan (nan)	prob nan (nan)	GS 33.625 (33.625)	mem 40.170
Train: [70][565/750]	BT 0.168 (1.174)	DT 0.002 (1.042)	loss nan (nan)	prob nan (nan)	GS 27.109 (27.109)	mem 40.224
Train: [70][570/750]	BT 3.041 (1.170)	DT 2.962 (1.038)	loss nan (nan)	prob nan (nan)	GS 34.234 (34.234)	mem 40.198
Train: [70][575/750]	BT 0.109 (1.179)	DT 0.001 (1.047)	loss nan (nan)	prob nan (nan)	GS 32.531 (32.531)	mem 40.089
Train: [70][580/750]	BT 0.120 (1.170)	DT 0.001 (1.038)	loss nan (nan)	prob nan (nan)	GS 33.688 (33.688)	mem 40.026
Train: [70][585/750]	BT 0.205 (1.161)	DT 0.002 (1.029)	loss nan (nan)	prob nan (nan)	GS 32.250 (32.250)	mem 40.209
Train: [70][590/750]	BT 0.126 (1.175)	DT 0.001 (1.043)	loss nan (nan)	prob nan (nan)	GS 29.578 (29.578)	mem 40.097
Train: [70][595/750]	BT 0.154 (1.166)	DT 0.001 (1.035)	loss nan (nan)	prob nan (nan)	GS 34.000 (34.000)	mem 39.983
Train: [70][600/750]	BT 0.123 (1.176)	DT 0.007 (1.045)	loss nan (nan)	prob nan (nan)	GS 34.516 (34.516)	mem 40.058
Train: [70][605/750]	BT 0.179 (1.168)	DT 0.009 (1.036)	loss nan (nan)	prob nan (nan)	GS 32.359 (32.359)	mem 40.062
Train: [70][610/750]	BT 12.740 (1.180)	DT 12.588 (1.049)	loss nan (nan)	prob nan (nan)	GS 38.188 (38.188)	mem 40.078
Train: [70][615/750]	BT 0.232 (1.171)	DT 0.020 (1.040)	loss nan (nan)	prob nan (nan)	GS 29.953 (29.953)	mem 40.273
Train: [70][620/750]	BT 0.098 (1.163)	DT 0.002 (1.032)	loss nan (nan)	prob nan (nan)	GS 37.219 (37.219)	mem 40.214
Train: [70][625/750]	BT 0.134 (1.172)	DT 0.002 (1.041)	loss nan (nan)	prob nan (nan)	GS 35.391 (35.391)	mem 40.025
Train: [70][630/750]	BT 0.155 (1.164)	DT 0.009 (1.033)	loss nan (nan)	prob nan (nan)	GS 34.156 (34.156)	mem 40.028
Train: [70][635/750]	BT 0.180 (1.176)	DT 0.001 (1.045)	loss nan (nan)	prob nan (nan)	GS 30.688 (30.688)	mem 40.119
Train: [70][640/750]	BT 0.083 (1.168)	DT 0.002 (1.037)	loss nan (nan)	prob nan (nan)	GS 34.766 (34.766)	mem 40.069
Train: [70][645/750]	BT 0.215 (1.160)	DT 0.002 (1.029)	loss nan (nan)	prob nan (nan)	GS 30.656 (30.656)	mem 40.294
Train: [70][650/750]	BT 0.137 (1.171)	DT 0.002 (1.040)	loss nan (nan)	prob nan (nan)	GS 32.141 (32.141)	mem 40.080
Train: [70][655/750]	BT 0.109 (1.163)	DT 0.014 (1.032)	loss nan (nan)	prob nan (nan)	GS 36.938 (36.938)	mem 40.074
Train: [70][660/750]	BT 0.068 (1.172)	DT 0.001 (1.041)	loss nan (nan)	prob nan (nan)	GS 36.969 (36.969)	mem 40.032
Train: [70][665/750]	BT 0.158 (1.164)	DT 0.014 (1.033)	loss nan (nan)	prob nan (nan)	GS 35.984 (35.984)	mem 40.036
Train: [70][670/750]	BT 13.178 (1.176)	DT 13.035 (1.045)	loss nan (nan)	prob nan (nan)	GS 32.812 (32.812)	mem 40.228
Train: [70][675/750]	BT 0.080 (1.168)	DT 0.002 (1.037)	loss nan (nan)	prob nan (nan)	GS 30.547 (30.547)	mem 40.047
Train: [70][680/750]	BT 0.090 (1.161)	DT 0.001 (1.030)	loss nan (nan)	prob nan (nan)	GS 33.266 (33.266)	mem 40.064
Train: [70][685/750]	BT 0.104 (1.172)	DT 0.002 (1.041)	loss nan (nan)	prob nan (nan)	GS 28.375 (28.375)	mem 40.010
Train: [70][690/750]	BT 0.182 (1.164)	DT 0.034 (1.034)	loss nan (nan)	prob nan (nan)	GS 35.406 (35.406)	mem 40.013
Train: [70][695/750]	BT 0.094 (1.177)	DT 0.001 (1.046)	loss nan (nan)	prob nan (nan)	GS 37.047 (37.047)	mem 40.047
Train: [70][700/750]	BT 0.093 (1.169)	DT 0.006 (1.039)	loss nan (nan)	prob nan (nan)	GS 39.484 (39.484)	mem 40.047
Train: [70][705/750]	BT 0.097 (1.161)	DT 0.002 (1.032)	loss nan (nan)	prob nan (nan)	GS 29.906 (29.906)	mem 40.050
Train: [70][710/750]	BT 0.066 (1.173)	DT 0.001 (1.044)	loss nan (nan)	prob nan (nan)	GS 34.953 (34.953)	mem 39.885
Train: [70][715/750]	BT 0.060 (1.165)	DT 0.001 (1.036)	loss nan (nan)	prob nan (nan)	GS 30.453 (30.453)	mem 39.900
Train: [70][720/750]	BT 0.087 (1.170)	DT 0.001 (1.040)	loss nan (nan)	prob nan (nan)	GS 31.203 (31.203)	mem 39.998
Train: [70][725/750]	BT 0.157 (1.163)	DT 0.003 (1.033)	loss nan (nan)	prob nan (nan)	GS 28.906 (28.906)	mem 40.056
Train: [70][730/750]	BT 8.720 (1.167)	DT 8.626 (1.038)	loss nan (nan)	prob nan (nan)	GS 33.906 (33.906)	mem 39.483
Train: [70][735/750]	BT 0.085 (1.160)	DT 0.001 (1.031)	loss nan (nan)	prob nan (nan)	GS 36.109 (36.109)	mem 39.479
Train: [70][740/750]	BT 0.097 (1.153)	DT 0.001 (1.024)	loss nan (nan)	prob nan (nan)	GS 29.625 (29.625)	mem 39.477
Train: [70][745/750]	BT 0.065 (1.153)	DT 0.002 (1.024)	loss nan (nan)	prob nan (nan)	GS 33.500 (33.500)	mem 10.690
Train: [70][750/750]	BT 0.083 (1.145)	DT 0.002 (1.017)	loss nan (nan)	prob nan (nan)	GS 33.938 (33.938)	mem 10.788
Train: [70][755/750]	BT 0.082 (1.141)	DT 0.001 (1.012)	loss nan (nan)	prob nan (nan)	GS 35.000 (35.000)	mem 10.655
epoch 70, total time 861.61
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [71][1/750]	BT 22.544 (22.544)	DT 22.343 (22.343)	loss nan (nan)	prob nan (nan)	GS 28.406 (28.406)	mem 38.691
Train: [71][5/750]	BT 0.677 (5.128)	DT 0.545 (4.968)	loss nan (nan)	prob nan (nan)	GS 34.672 (34.672)	mem 38.735
Train: [71][10/750]	BT 0.220 (2.647)	DT 0.023 (2.489)	loss nan (nan)	prob nan (nan)	GS 35.078 (35.078)	mem 38.823
Train: [71][15/750]	BT 0.164 (2.894)	DT 0.001 (2.742)	loss nan (nan)	prob nan (nan)	GS 26.844 (26.844)	mem 38.985
Train: [71][20/750]	BT 0.145 (2.200)	DT 0.002 (2.057)	loss nan (nan)	prob nan (nan)	GS 38.297 (38.297)	mem 38.939
Train: [71][25/750]	BT 0.128 (1.916)	DT 0.001 (1.777)	loss nan (nan)	prob nan (nan)	GS 30.750 (30.750)	mem 38.905
Train: [71][30/750]	BT 0.099 (1.880)	DT 0.002 (1.745)	loss nan (nan)	prob nan (nan)	GS 29.812 (29.812)	mem 39.012
Train: [71][35/750]	BT 0.160 (1.631)	DT 0.061 (1.498)	loss nan (nan)	prob nan (nan)	GS 31.109 (31.109)	mem 39.014
Train: [71][40/750]	BT 0.129 (1.751)	DT 0.005 (1.618)	loss nan (nan)	prob nan (nan)	GS 32.953 (32.953)	mem 39.037
Train: [71][45/750]	BT 0.154 (1.578)	DT 0.005 (1.438)	loss nan (nan)	prob nan (nan)	GS 30.328 (30.328)	mem 39.046
Train: [71][50/750]	BT 11.938 (1.668)	DT 11.782 (1.530)	loss nan (nan)	prob nan (nan)	GS 31.203 (31.203)	mem 39.100
Train: [71][55/750]	BT 0.206 (1.529)	DT 0.020 (1.392)	loss nan (nan)	prob nan (nan)	GS 29.891 (29.891)	mem 39.103
Train: [71][60/750]	BT 0.120 (1.418)	DT 0.002 (1.277)	loss nan (nan)	prob nan (nan)	GS 30.250 (30.250)	mem 39.106
Train: [71][65/750]	BT 0.094 (1.474)	DT 0.002 (1.335)	loss nan (nan)	prob nan (nan)	GS 28.594 (28.594)	mem 39.423
Train: [71][70/750]	BT 0.577 (1.384)	DT 0.357 (1.245)	loss nan (nan)	prob nan (nan)	GS 33.359 (33.359)	mem 39.150
Train: [71][75/750]	BT 0.132 (1.463)	DT 0.001 (1.324)	loss nan (nan)	prob nan (nan)	GS 33.188 (33.188)	mem 39.141
Train: [71][80/750]	BT 0.081 (1.380)	DT 0.004 (1.241)	loss nan (nan)	prob nan (nan)	GS 29.406 (29.406)	mem 39.127
Train: [71][85/750]	BT 0.211 (1.327)	DT 0.009 (1.185)	loss nan (nan)	prob nan (nan)	GS 34.656 (34.656)	mem 39.248
Train: [71][90/750]	BT 0.146 (1.368)	DT 0.011 (1.227)	loss nan (nan)	prob nan (nan)	GS 30.531 (30.531)	mem 39.097
Train: [71][95/750]	BT 0.188 (1.309)	DT 0.022 (1.168)	loss nan (nan)	prob nan (nan)	GS 30.328 (30.328)	mem 39.210
Train: [71][100/750]	BT 0.242 (1.343)	DT 0.010 (1.202)	loss nan (nan)	prob nan (nan)	GS 30.625 (30.625)	mem 39.339
Train: [71][105/750]	BT 0.117 (1.329)	DT 0.002 (1.188)	loss nan (nan)	prob nan (nan)	GS 31.594 (31.594)	mem 39.132
Train: [71][110/750]	BT 6.402 (1.334)	DT 6.250 (1.191)	loss nan (nan)	prob nan (nan)	GS 37.641 (37.641)	mem 39.233
Train: [71][115/750]	BT 0.158 (1.327)	DT 0.001 (1.185)	loss nan (nan)	prob nan (nan)	GS 31.656 (31.656)	mem 39.378
Train: [71][120/750]	BT 0.137 (1.276)	DT 0.001 (1.135)	loss nan (nan)	prob nan (nan)	GS 34.391 (34.391)	mem 39.295
Train: [71][125/750]	BT 0.096 (1.265)	DT 0.001 (1.125)	loss nan (nan)	prob nan (nan)	GS 37.516 (37.516)	mem 39.242
Train: [71][130/750]	BT 0.176 (1.285)	DT 0.010 (1.146)	loss nan (nan)	prob nan (nan)	GS 33.891 (33.891)	mem 39.291
Train: [71][135/750]	BT 0.222 (1.283)	DT 0.005 (1.144)	loss nan (nan)	prob nan (nan)	GS 29.734 (29.734)	mem 39.262
Train: [71][140/750]	BT 0.119 (1.280)	DT 0.001 (1.142)	loss nan (nan)	prob nan (nan)	GS 35.078 (35.078)	mem 39.328
Train: [71][145/750]	BT 0.107 (1.240)	DT 0.006 (1.103)	loss nan (nan)	prob nan (nan)	GS 35.703 (35.703)	mem 39.404
Train: [71][150/750]	BT 5.368 (1.278)	DT 5.252 (1.142)	loss nan (nan)	prob nan (nan)	GS 32.016 (32.016)	mem 39.483
Train: [71][155/750]	BT 0.157 (1.242)	DT 0.006 (1.105)	loss nan (nan)	prob nan (nan)	GS 29.750 (29.750)	mem 39.604
Train: [71][160/750]	BT 0.093 (1.240)	DT 0.006 (1.103)	loss nan (nan)	prob nan (nan)	GS 34.469 (34.469)	mem 39.523
Train: [71][165/750]	BT 0.154 (1.251)	DT 0.002 (1.114)	loss nan (nan)	prob nan (nan)	GS 29.391 (29.391)	mem 39.771
Train: [71][170/750]	BT 2.823 (1.234)	DT 2.636 (1.097)	loss nan (nan)	prob nan (nan)	GS 36.562 (36.562)	mem 39.566
Train: [71][175/750]	BT 0.244 (1.250)	DT 0.001 (1.112)	loss nan (nan)	prob nan (nan)	GS 31.703 (31.703)	mem 39.540
Train: [71][180/750]	BT 0.097 (1.218)	DT 0.002 (1.082)	loss nan (nan)	prob nan (nan)	GS 30.141 (30.141)	mem 39.548
Train: [71][185/750]	BT 0.189 (1.199)	DT 0.001 (1.062)	loss nan (nan)	prob nan (nan)	GS 29.266 (29.266)	mem 39.698
Train: [71][190/750]	BT 0.102 (1.228)	DT 0.001 (1.092)	loss nan (nan)	prob nan (nan)	GS 29.688 (29.688)	mem 39.706
Train: [71][195/750]	BT 0.115 (1.211)	DT 0.005 (1.074)	loss nan (nan)	prob nan (nan)	GS 32.125 (32.125)	mem 39.625
Train: [71][200/750]	BT 0.090 (1.234)	DT 0.002 (1.097)	loss nan (nan)	prob nan (nan)	GS 36.016 (36.016)	mem 39.893
Train: [71][205/750]	BT 0.152 (1.208)	DT 0.001 (1.070)	loss nan (nan)	prob nan (nan)	GS 36.406 (36.406)	mem 39.796
Train: [71][210/750]	BT 12.970 (1.248)	DT 12.854 (1.111)	loss nan (nan)	prob nan (nan)	GS 29.125 (29.125)	mem 39.827
Train: [71][215/750]	BT 0.069 (1.222)	DT 0.001 (1.085)	loss nan (nan)	prob nan (nan)	GS 34.156 (34.156)	mem 39.910
Train: [71][220/750]	BT 0.151 (1.197)	DT 0.039 (1.061)	loss nan (nan)	prob nan (nan)	GS 33.188 (33.188)	mem 39.822
Train: [71][225/750]	BT 0.089 (1.230)	DT 0.002 (1.094)	loss nan (nan)	prob nan (nan)	GS 32.359 (32.359)	mem 39.945
Train: [71][230/750]	BT 0.132 (1.206)	DT 0.001 (1.070)	loss nan (nan)	prob nan (nan)	GS 30.203 (30.203)	mem 39.863
Train: [71][235/750]	BT 0.103 (1.233)	DT 0.003 (1.098)	loss nan (nan)	prob nan (nan)	GS 34.391 (34.391)	mem 39.964
Train: [71][240/750]	BT 0.176 (1.209)	DT 0.006 (1.075)	loss nan (nan)	prob nan (nan)	GS 30.875 (30.875)	mem 39.881
Train: [71][245/750]	BT 0.228 (1.200)	DT 0.010 (1.065)	loss nan (nan)	prob nan (nan)	GS 28.156 (28.156)	mem 40.021
Train: [71][250/750]	BT 0.115 (1.217)	DT 0.002 (1.083)	loss nan (nan)	prob nan (nan)	GS 35.297 (35.297)	mem 40.119
Train: [71][255/750]	BT 0.147 (1.195)	DT 0.005 (1.062)	loss nan (nan)	prob nan (nan)	GS 29.312 (29.312)	mem 40.012
Train: [71][260/750]	BT 0.101 (1.228)	DT 0.001 (1.095)	loss nan (nan)	prob nan (nan)	GS 35.047 (35.047)	mem 39.830
Train: [71][265/750]	BT 0.083 (1.207)	DT 0.003 (1.074)	loss nan (nan)	prob nan (nan)	GS 34.047 (34.047)	mem 39.860
Train: [71][270/750]	BT 10.477 (1.231)	DT 10.382 (1.098)	loss nan (nan)	prob nan (nan)	GS 35.469 (35.469)	mem 39.971
Train: [71][275/750]	BT 0.116 (1.210)	DT 0.017 (1.078)	loss nan (nan)	prob nan (nan)	GS 36.250 (36.250)	mem 39.910
Train: [71][280/750]	BT 0.280 (1.192)	DT 0.159 (1.059)	loss nan (nan)	prob nan (nan)	GS 31.188 (31.188)	mem 39.910
Train: [71][285/750]	BT 0.129 (1.205)	DT 0.002 (1.073)	loss nan (nan)	prob nan (nan)	GS 34.766 (34.766)	mem 39.952
Train: [71][290/750]	BT 0.107 (1.186)	DT 0.002 (1.055)	loss nan (nan)	prob nan (nan)	GS 33.125 (33.125)	mem 39.958
Train: [71][295/750]	BT 0.089 (1.206)	DT 0.002 (1.073)	loss nan (nan)	prob nan (nan)	GS 31.172 (31.172)	mem 39.942
Train: [71][300/750]	BT 0.157 (1.188)	DT 0.035 (1.056)	loss nan (nan)	prob nan (nan)	GS 32.375 (32.375)	mem 40.168
Train: [71][305/750]	BT 0.147 (1.190)	DT 0.002 (1.058)	loss nan (nan)	prob nan (nan)	GS 29.672 (29.672)	mem 40.072
Train: [71][310/750]	BT 0.121 (1.196)	DT 0.004 (1.064)	loss nan (nan)	prob nan (nan)	GS 32.953 (32.953)	mem 39.863
Train: [71][315/750]	BT 0.228 (1.180)	DT 0.010 (1.048)	loss nan (nan)	prob nan (nan)	GS 38.828 (38.828)	mem 39.864
Train: [71][320/750]	BT 0.140 (1.197)	DT 0.006 (1.065)	loss nan (nan)	prob nan (nan)	GS 33.266 (33.266)	mem 39.938
Train: [71][325/750]	BT 0.172 (1.181)	DT 0.002 (1.048)	loss nan (nan)	prob nan (nan)	GS 27.016 (27.016)	mem 40.127
Train: [71][330/750]	BT 9.191 (1.199)	DT 9.089 (1.067)	loss nan (nan)	prob nan (nan)	GS 35.047 (35.047)	mem 40.010
Train: [71][335/750]	BT 0.101 (1.183)	DT 0.002 (1.051)	loss nan (nan)	prob nan (nan)	GS 32.078 (32.078)	mem 39.984
Train: [71][340/750]	BT 0.247 (1.168)	DT 0.038 (1.036)	loss nan (nan)	prob nan (nan)	GS 29.344 (29.344)	mem 39.985
Train: [71][345/750]	BT 0.095 (1.182)	DT 0.001 (1.050)	loss nan (nan)	prob nan (nan)	GS 31.594 (31.594)	mem 40.008
Train: [71][350/750]	BT 0.139 (1.167)	DT 0.002 (1.035)	loss nan (nan)	prob nan (nan)	GS 31.688 (31.688)	mem 40.025
Train: [71][355/750]	BT 0.090 (1.177)	DT 0.001 (1.045)	loss nan (nan)	prob nan (nan)	GS 35.766 (35.766)	mem 40.035
Train: [71][360/750]	BT 0.086 (1.173)	DT 0.001 (1.042)	loss nan (nan)	prob nan (nan)	GS 35.516 (35.516)	mem 39.986
Train: [71][365/750]	BT 0.147 (1.168)	DT 0.001 (1.036)	loss nan (nan)	prob nan (nan)	GS 30.859 (30.859)	mem 40.006
Train: [71][370/750]	BT 0.167 (1.174)	DT 0.001 (1.042)	loss nan (nan)	prob nan (nan)	GS 33.859 (33.859)	mem 40.091
Train: [71][375/750]	BT 0.147 (1.161)	DT 0.005 (1.028)	loss nan (nan)	prob nan (nan)	GS 27.828 (27.828)	mem 39.987
Train: [71][380/750]	BT 5.349 (1.185)	DT 5.249 (1.053)	loss nan (nan)	prob nan (nan)	GS 34.875 (34.875)	mem 39.917
Train: [71][385/750]	BT 0.091 (1.171)	DT 0.002 (1.039)	loss nan (nan)	prob nan (nan)	GS 29.656 (29.656)	mem 40.044
Train: [71][390/750]	BT 2.407 (1.171)	DT 2.215 (1.038)	loss nan (nan)	prob nan (nan)	GS 34.516 (34.516)	mem 40.057
Train: [71][395/750]	BT 0.092 (1.171)	DT 0.002 (1.038)	loss nan (nan)	prob nan (nan)	GS 32.422 (32.422)	mem 40.015
Train: [71][400/750]	BT 6.650 (1.175)	DT 6.546 (1.042)	loss nan (nan)	prob nan (nan)	GS 37.484 (37.484)	mem 40.050
Train: [71][405/750]	BT 0.077 (1.170)	DT 0.003 (1.037)	loss nan (nan)	prob nan (nan)	GS 30.609 (30.609)	mem 39.891
Train: [71][410/750]	BT 0.135 (1.158)	DT 0.002 (1.025)	loss nan (nan)	prob nan (nan)	GS 31.031 (31.031)	mem 39.895
Train: [71][415/750]	BT 0.179 (1.167)	DT 0.008 (1.034)	loss nan (nan)	prob nan (nan)	GS 32.797 (32.797)	mem 39.967
Train: [71][420/750]	BT 0.120 (1.161)	DT 0.005 (1.028)	loss nan (nan)	prob nan (nan)	GS 32.156 (32.156)	mem 39.991
Train: [71][425/750]	BT 0.217 (1.167)	DT 0.011 (1.034)	loss nan (nan)	prob nan (nan)	GS 33.438 (33.438)	mem 40.143
Train: [71][430/750]	BT 0.073 (1.165)	DT 0.001 (1.033)	loss nan (nan)	prob nan (nan)	GS 31.172 (31.172)	mem 39.980
Train: [71][435/750]	BT 0.227 (1.154)	DT 0.017 (1.021)	loss nan (nan)	prob nan (nan)	GS 35.078 (35.078)	mem 39.999
Train: [71][440/750]	BT 2.583 (1.168)	DT 2.492 (1.035)	loss nan (nan)	prob nan (nan)	GS 35.297 (35.297)	mem 40.000
Train: [71][445/750]	BT 0.117 (1.157)	DT 0.011 (1.023)	loss nan (nan)	prob nan (nan)	GS 29.812 (29.812)	mem 40.019
Train: [71][450/750]	BT 0.947 (1.158)	DT 0.651 (1.024)	loss nan (nan)	prob nan (nan)	GS 29.375 (29.375)	mem 40.014
Train: [71][455/750]	BT 0.127 (1.165)	DT 0.001 (1.032)	loss nan (nan)	prob nan (nan)	GS 32.688 (32.688)	mem 40.052
Train: [71][460/750]	BT 2.069 (1.158)	DT 1.986 (1.025)	loss nan (nan)	prob nan (nan)	GS 29.641 (29.641)	mem 40.083
Train: [71][465/750]	BT 0.150 (1.162)	DT 0.002 (1.029)	loss nan (nan)	prob nan (nan)	GS 30.219 (30.219)	mem 39.943
Train: [71][470/750]	BT 0.128 (1.151)	DT 0.002 (1.018)	loss nan (nan)	prob nan (nan)	GS 31.906 (31.906)	mem 39.985
Train: [71][475/750]	BT 0.116 (1.155)	DT 0.025 (1.022)	loss nan (nan)	prob nan (nan)	GS 24.859 (24.859)	mem 39.954
Train: [71][480/750]	BT 0.096 (1.157)	DT 0.003 (1.024)	loss nan (nan)	prob nan (nan)	GS 32.016 (32.016)	mem 39.992
Train: [71][485/750]	BT 0.090 (1.160)	DT 0.002 (1.027)	loss nan (nan)	prob nan (nan)	GS 27.875 (27.875)	mem 39.971
Train: [71][490/750]	BT 0.115 (1.157)	DT 0.001 (1.025)	loss nan (nan)	prob nan (nan)	GS 31.766 (31.766)	mem 40.049
Train: [71][495/750]	BT 0.181 (1.147)	DT 0.002 (1.014)	loss nan (nan)	prob nan (nan)	GS 30.312 (30.312)	mem 40.007
Train: [71][500/750]	BT 7.095 (1.165)	DT 6.999 (1.032)	loss nan (nan)	prob nan (nan)	GS 35.188 (35.188)	mem 39.934
Train: [71][505/750]	BT 0.164 (1.155)	DT 0.010 (1.022)	loss nan (nan)	prob nan (nan)	GS 30.375 (30.375)	mem 40.000
Train: [71][510/750]	BT 0.117 (1.151)	DT 0.005 (1.018)	loss nan (nan)	prob nan (nan)	GS 33.609 (33.609)	mem 40.246
Train: [71][515/750]	BT 0.167 (1.160)	DT 0.001 (1.028)	loss nan (nan)	prob nan (nan)	GS 32.609 (32.609)	mem 40.113
Train: [71][520/750]	BT 5.770 (1.161)	DT 5.685 (1.029)	loss nan (nan)	prob nan (nan)	GS 33.984 (33.984)	mem 39.934
Train: [71][525/750]	BT 0.288 (1.162)	DT 0.024 (1.029)	loss nan (nan)	prob nan (nan)	GS 30.000 (30.000)	mem 39.985
Train: [71][530/750]	BT 0.120 (1.152)	DT 0.003 (1.019)	loss nan (nan)	prob nan (nan)	GS 32.141 (32.141)	mem 40.055
Train: [71][535/750]	BT 0.158 (1.148)	DT 0.002 (1.015)	loss nan (nan)	prob nan (nan)	GS 36.297 (36.297)	mem 39.923
Train: [71][540/750]	BT 0.088 (1.162)	DT 0.001 (1.029)	loss nan (nan)	prob nan (nan)	GS 33.719 (33.719)	mem 39.851
Train: [71][545/750]	BT 0.163 (1.153)	DT 0.010 (1.021)	loss nan (nan)	prob nan (nan)	GS 41.516 (41.516)	mem 39.790
Train: [71][550/750]	BT 0.095 (1.168)	DT 0.002 (1.036)	loss nan (nan)	prob nan (nan)	GS 32.938 (32.938)	mem 39.961
Train: [71][555/750]	BT 0.157 (1.159)	DT 0.007 (1.026)	loss nan (nan)	prob nan (nan)	GS 31.734 (31.734)	mem 39.966
Train: [71][560/750]	BT 8.055 (1.164)	DT 7.950 (1.031)	loss nan (nan)	prob nan (nan)	GS 35.141 (35.141)	mem 39.996
Train: [71][565/750]	BT 0.080 (1.155)	DT 0.001 (1.022)	loss nan (nan)	prob nan (nan)	GS 35.562 (35.562)	mem 40.043
Train: [71][570/750]	BT 0.092 (1.161)	DT 0.004 (1.029)	loss nan (nan)	prob nan (nan)	GS 35.656 (35.656)	mem 39.949
Train: [71][575/750]	BT 0.118 (1.153)	DT 0.002 (1.021)	loss nan (nan)	prob nan (nan)	GS 29.016 (29.016)	mem 39.982
Train: [71][580/750]	BT 11.534 (1.164)	DT 11.459 (1.032)	loss nan (nan)	prob nan (nan)	GS 36.719 (36.719)	mem 40.058
Train: [71][585/750]	BT 0.144 (1.155)	DT 0.014 (1.023)	loss nan (nan)	prob nan (nan)	GS 34.016 (34.016)	mem 39.970
Train: [71][590/750]	BT 0.237 (1.146)	DT 0.002 (1.014)	loss nan (nan)	prob nan (nan)	GS 35.375 (35.375)	mem 39.983
Train: [71][595/750]	BT 0.188 (1.156)	DT 0.002 (1.024)	loss nan (nan)	prob nan (nan)	GS 36.625 (36.625)	mem 40.108
Train: [71][600/750]	BT 0.087 (1.148)	DT 0.001 (1.016)	loss nan (nan)	prob nan (nan)	GS 33.406 (33.406)	mem 40.084
Train: [71][605/750]	BT 0.079 (1.159)	DT 0.001 (1.028)	loss nan (nan)	prob nan (nan)	GS 30.453 (30.453)	mem 39.952
Train: [71][610/750]	BT 0.109 (1.151)	DT 0.002 (1.019)	loss nan (nan)	prob nan (nan)	GS 37.438 (37.438)	mem 39.973
Train: [71][615/750]	BT 0.154 (1.143)	DT 0.005 (1.011)	loss nan (nan)	prob nan (nan)	GS 32.969 (32.969)	mem 40.107
Train: [71][620/750]	BT 0.152 (1.158)	DT 0.001 (1.027)	loss nan (nan)	prob nan (nan)	GS 38.109 (38.109)	mem 40.103
Train: [71][625/750]	BT 0.153 (1.150)	DT 0.005 (1.019)	loss nan (nan)	prob nan (nan)	GS 31.391 (31.391)	mem 40.059
Train: [71][630/750]	BT 0.106 (1.162)	DT 0.001 (1.031)	loss nan (nan)	prob nan (nan)	GS 35.312 (35.312)	mem 39.986
Train: [71][635/750]	BT 0.108 (1.154)	DT 0.002 (1.023)	loss nan (nan)	prob nan (nan)	GS 31.828 (31.828)	mem 40.048
Train: [71][640/750]	BT 11.466 (1.163)	DT 11.323 (1.032)	loss nan (nan)	prob nan (nan)	GS 34.641 (34.641)	mem 39.995
Train: [71][645/750]	BT 0.178 (1.155)	DT 0.002 (1.024)	loss nan (nan)	prob nan (nan)	GS 31.562 (31.562)	mem 40.001
Train: [71][650/750]	BT 0.106 (1.148)	DT 0.001 (1.016)	loss nan (nan)	prob nan (nan)	GS 32.531 (32.531)	mem 40.081
Train: [71][655/750]	BT 0.098 (1.154)	DT 0.001 (1.023)	loss nan (nan)	prob nan (nan)	GS 35.531 (35.531)	mem 39.950
Train: [71][660/750]	BT 0.185 (1.149)	DT 0.002 (1.018)	loss nan (nan)	prob nan (nan)	GS 34.438 (34.438)	mem 39.954
Train: [71][665/750]	BT 0.086 (1.156)	DT 0.001 (1.025)	loss nan (nan)	prob nan (nan)	GS 30.203 (30.203)	mem 39.970
Train: [71][670/750]	BT 0.153 (1.151)	DT 0.008 (1.020)	loss nan (nan)	prob nan (nan)	GS 34.484 (34.484)	mem 40.011
Train: [71][675/750]	BT 0.109 (1.144)	DT 0.002 (1.013)	loss nan (nan)	prob nan (nan)	GS 26.047 (26.047)	mem 40.082
Train: [71][680/750]	BT 6.808 (1.161)	DT 6.591 (1.030)	loss nan (nan)	prob nan (nan)	GS 35.453 (35.453)	mem 40.156
Train: [71][685/750]	BT 0.132 (1.153)	DT 0.001 (1.022)	loss nan (nan)	prob nan (nan)	GS 30.438 (30.438)	mem 39.986
Train: [71][690/750]	BT 2.576 (1.152)	DT 2.392 (1.021)	loss nan (nan)	prob nan (nan)	GS 35.078 (35.078)	mem 40.017
Train: [71][695/750]	BT 0.077 (1.160)	DT 0.001 (1.028)	loss nan (nan)	prob nan (nan)	GS 34.641 (34.641)	mem 40.055
Train: [71][700/750]	BT 0.166 (1.152)	DT 0.001 (1.021)	loss nan (nan)	prob nan (nan)	GS 35.609 (35.609)	mem 40.182
Train: [71][705/750]	BT 0.105 (1.163)	DT 0.001 (1.032)	loss nan (nan)	prob nan (nan)	GS 30.797 (30.797)	mem 40.106
arpack error, retry= 0
Train: [71][710/750]	BT 0.069 (1.156)	DT 0.001 (1.024)	loss nan (nan)	prob nan (nan)	GS 36.203 (36.203)	mem 40.036
Train: [71][715/750]	BT 0.147 (1.149)	DT 0.012 (1.017)	loss nan (nan)	prob nan (nan)	GS 30.234 (30.234)	mem 40.038
Train: [71][720/750]	BT 0.114 (1.158)	DT 0.001 (1.027)	loss nan (nan)	prob nan (nan)	GS 32.641 (32.641)	mem 39.992
Train: [71][725/750]	BT 0.199 (1.151)	DT 0.001 (1.020)	loss nan (nan)	prob nan (nan)	GS 33.281 (33.281)	mem 40.002
Train: [71][730/750]	BT 0.096 (1.158)	DT 0.007 (1.027)	loss nan (nan)	prob nan (nan)	GS 33.719 (33.719)	mem 39.608
Train: [71][735/750]	BT 0.066 (1.151)	DT 0.002 (1.020)	loss nan (nan)	prob nan (nan)	GS 33.281 (33.281)	mem 39.608
Train: [71][740/750]	BT 5.641 (1.151)	DT 5.558 (1.021)	loss nan (nan)	prob nan (nan)	GS 30.188 (30.188)	mem 7.666
Train: [71][745/750]	BT 0.068 (1.144)	DT 0.001 (1.014)	loss nan (nan)	prob nan (nan)	GS 31.562 (31.562)	mem 7.684
Train: [71][750/750]	BT 0.076 (1.137)	DT 0.001 (1.007)	loss nan (nan)	prob nan (nan)	GS 36.406 (36.406)	mem 7.717
Train: [71][755/750]	BT 0.065 (1.133)	DT 0.001 (1.004)	loss nan (nan)	prob nan (nan)	GS 34.438 (34.438)	mem 7.682
epoch 71, total time 855.95
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [72][1/750]	BT 20.642 (20.642)	DT 20.532 (20.532)	loss nan (nan)	prob nan (nan)	GS 32.234 (32.234)	mem 38.703
Train: [72][5/750]	BT 1.821 (4.964)	DT 1.713 (4.799)	loss nan (nan)	prob nan (nan)	GS 37.203 (37.203)	mem 38.762
Train: [72][10/750]	BT 0.083 (2.547)	DT 0.002 (2.402)	loss nan (nan)	prob nan (nan)	GS 31.312 (31.312)	mem 38.762
Train: [72][15/750]	BT 0.083 (2.197)	DT 0.001 (2.056)	loss nan (nan)	prob nan (nan)	GS 33.641 (33.641)	mem 38.904
Train: [72][20/750]	BT 0.760 (1.970)	DT 0.527 (1.821)	loss nan (nan)	prob nan (nan)	GS 37.750 (37.750)	mem 38.906
Train: [72][25/750]	BT 1.137 (1.640)	DT 0.937 (1.495)	loss nan (nan)	prob nan (nan)	GS 31.406 (31.406)	mem 38.921
Train: [72][30/750]	BT 3.401 (1.845)	DT 3.264 (1.698)	loss nan (nan)	prob nan (nan)	GS 34.453 (34.453)	mem 39.000
Train: [72][35/750]	BT 0.201 (1.611)	DT 0.006 (1.456)	loss nan (nan)	prob nan (nan)	GS 28.969 (28.969)	mem 39.004
Train: [72][40/750]	BT 3.149 (1.580)	DT 3.043 (1.430)	loss nan (nan)	prob nan (nan)	GS 34.469 (34.469)	mem 39.047
Train: [72][45/750]	BT 0.129 (1.500)	DT 0.016 (1.351)	loss nan (nan)	prob nan (nan)	GS 32.750 (32.750)	mem 39.058
Train: [72][50/750]	BT 1.944 (1.485)	DT 1.821 (1.338)	loss nan (nan)	prob nan (nan)	GS 32.094 (32.094)	mem 39.184
Train: [72][55/750]	BT 0.181 (1.437)	DT 0.002 (1.290)	loss nan (nan)	prob nan (nan)	GS 29.703 (29.703)	mem 39.193
Train: [72][60/750]	BT 0.103 (1.418)	DT 0.002 (1.271)	loss nan (nan)	prob nan (nan)	GS 33.719 (33.719)	mem 39.213
Train: [72][65/750]	BT 0.101 (1.393)	DT 0.001 (1.246)	loss nan (nan)	prob nan (nan)	GS 28.531 (28.531)	mem 39.200
Train: [72][70/750]	BT 2.347 (1.383)	DT 2.257 (1.238)	loss nan (nan)	prob nan (nan)	GS 35.500 (35.500)	mem 39.519
Train: [72][75/750]	BT 0.100 (1.385)	DT 0.002 (1.243)	loss nan (nan)	prob nan (nan)	GS 31.891 (31.891)	mem 39.814
Train: [72][80/750]	BT 0.108 (1.346)	DT 0.004 (1.205)	loss nan (nan)	prob nan (nan)	GS 35.797 (35.797)	mem 39.521
Train: [72][85/750]	BT 0.088 (1.276)	DT 0.002 (1.136)	loss nan (nan)	prob nan (nan)	GS 31.656 (31.656)	mem 39.521
Train: [72][90/750]	BT 0.113 (1.322)	DT 0.001 (1.184)	loss nan (nan)	prob nan (nan)	GS 33.188 (33.188)	mem 39.800
Train: [72][95/750]	BT 0.116 (1.259)	DT 0.002 (1.122)	loss nan (nan)	prob nan (nan)	GS 32.047 (32.047)	mem 39.852
Train: [72][100/750]	BT 7.193 (1.343)	DT 7.036 (1.206)	loss nan (nan)	prob nan (nan)	GS 32.828 (32.828)	mem 39.673
Train: [72][105/750]	BT 0.095 (1.284)	DT 0.002 (1.149)	loss nan (nan)	prob nan (nan)	GS 35.203 (35.203)	mem 39.728
Train: [72][110/750]	BT 5.559 (1.280)	DT 5.413 (1.146)	loss nan (nan)	prob nan (nan)	GS 38.656 (38.656)	mem 39.804
Train: [72][115/750]	BT 0.114 (1.287)	DT 0.002 (1.152)	loss nan (nan)	prob nan (nan)	GS 26.984 (26.984)	mem 39.875
Train: [72][120/750]	BT 0.193 (1.245)	DT 0.005 (1.108)	loss nan (nan)	prob nan (nan)	GS 33.984 (33.984)	mem 39.875
Train: [72][125/750]	BT 0.066 (1.287)	DT 0.001 (1.151)	loss nan (nan)	prob nan (nan)	GS 31.906 (31.906)	mem 39.770
Train: [72][130/750]	BT 0.119 (1.259)	DT 0.002 (1.124)	loss nan (nan)	prob nan (nan)	GS 35.156 (35.156)	mem 39.742
Train: [72][135/750]	BT 0.112 (1.220)	DT 0.014 (1.084)	loss nan (nan)	prob nan (nan)	GS 31.656 (31.656)	mem 39.770
Train: [72][140/750]	BT 7.348 (1.289)	DT 7.269 (1.152)	loss nan (nan)	prob nan (nan)	GS 32.188 (32.188)	mem 39.846
Train: [72][145/750]	BT 0.210 (1.250)	DT 0.005 (1.113)	loss nan (nan)	prob nan (nan)	GS 30.328 (30.328)	mem 39.971
Train: [72][150/750]	BT 1.286 (1.244)	DT 1.130 (1.107)	loss nan (nan)	prob nan (nan)	GS 36.484 (36.484)	mem 39.894
Train: [72][155/750]	BT 0.109 (1.243)	DT 0.006 (1.106)	loss nan (nan)	prob nan (nan)	GS 28.391 (28.391)	mem 39.906
Train: [72][160/750]	BT 1.122 (1.238)	DT 1.032 (1.101)	loss nan (nan)	prob nan (nan)	GS 29.609 (29.609)	mem 39.912
Train: [72][165/750]	BT 0.172 (1.259)	DT 0.002 (1.123)	loss nan (nan)	prob nan (nan)	GS 33.109 (33.109)	mem 39.905
Train: [72][170/750]	BT 0.153 (1.227)	DT 0.034 (1.091)	loss nan (nan)	prob nan (nan)	GS 31.391 (31.391)	mem 39.971
Train: [72][175/750]	BT 0.119 (1.204)	DT 0.004 (1.067)	loss nan (nan)	prob nan (nan)	GS 29.141 (29.141)	mem 39.810
Train: [72][180/750]	BT 0.083 (1.243)	DT 0.001 (1.108)	loss nan (nan)	prob nan (nan)	GS 35.922 (35.922)	mem 39.888
Train: [72][185/750]	BT 0.120 (1.213)	DT 0.005 (1.078)	loss nan (nan)	prob nan (nan)	GS 28.750 (28.750)	mem 39.931
Train: [72][190/750]	BT 2.446 (1.249)	DT 2.290 (1.114)	loss nan (nan)	prob nan (nan)	GS 34.172 (34.172)	mem 39.928
Train: [72][195/750]	BT 0.220 (1.221)	DT 0.006 (1.086)	loss nan (nan)	prob nan (nan)	GS 36.984 (36.984)	mem 40.095
Train: [72][200/750]	BT 5.115 (1.243)	DT 4.976 (1.108)	loss nan (nan)	prob nan (nan)	GS 32.422 (32.422)	mem 39.924
Train: [72][205/750]	BT 0.085 (1.227)	DT 0.002 (1.092)	loss nan (nan)	prob nan (nan)	GS 27.328 (27.328)	mem 39.977
Train: [72][210/750]	BT 2.201 (1.211)	DT 1.965 (1.075)	loss nan (nan)	prob nan (nan)	GS 35.469 (35.469)	mem 39.987
Train: [72][215/750]	BT 0.093 (1.235)	DT 0.015 (1.101)	loss nan (nan)	prob nan (nan)	GS 28.922 (28.922)	mem 39.853
Train: [72][220/750]	BT 0.090 (1.210)	DT 0.004 (1.076)	loss nan (nan)	prob nan (nan)	GS 33.906 (33.906)	mem 39.866
Train: [72][225/750]	BT 0.116 (1.258)	DT 0.002 (1.125)	loss nan (nan)	prob nan (nan)	GS 30.188 (30.188)	mem 39.904
Train: [72][230/750]	BT 0.079 (1.233)	DT 0.001 (1.100)	loss nan (nan)	prob nan (nan)	GS 32.391 (32.391)	mem 39.924
Train: [72][235/750]	BT 0.156 (1.210)	DT 0.020 (1.077)	loss nan (nan)	prob nan (nan)	GS 27.016 (27.016)	mem 39.877
Train: [72][240/750]	BT 0.144 (1.235)	DT 0.009 (1.102)	loss nan (nan)	prob nan (nan)	GS 34.125 (34.125)	mem 39.907
Train: [72][245/750]	BT 0.181 (1.213)	DT 0.019 (1.080)	loss nan (nan)	prob nan (nan)	GS 23.312 (23.312)	mem 39.936
Train: [72][250/750]	BT 0.077 (1.234)	DT 0.002 (1.101)	loss nan (nan)	prob nan (nan)	GS 32.656 (32.656)	mem 40.016
Train: [72][255/750]	BT 0.184 (1.213)	DT 0.001 (1.079)	loss nan (nan)	prob nan (nan)	GS 29.453 (29.453)	mem 40.021
Train: [72][260/750]	BT 11.924 (1.238)	DT 11.814 (1.104)	loss nan (nan)	prob nan (nan)	GS 33.719 (33.719)	mem 39.876
Train: [72][265/750]	BT 0.102 (1.217)	DT 0.001 (1.083)	loss nan (nan)	prob nan (nan)	GS 30.594 (30.594)	mem 39.882
Train: [72][270/750]	BT 0.109 (1.197)	DT 0.002 (1.063)	loss nan (nan)	prob nan (nan)	GS 31.344 (31.344)	mem 39.882
Train: [72][275/750]	BT 0.117 (1.232)	DT 0.002 (1.099)	loss nan (nan)	prob nan (nan)	GS 34.047 (34.047)	mem 39.863
Train: [72][280/750]	BT 0.227 (1.213)	DT 0.002 (1.079)	loss nan (nan)	prob nan (nan)	GS 37.984 (37.984)	mem 39.847
Train: [72][285/750]	BT 0.182 (1.234)	DT 0.001 (1.100)	loss nan (nan)	prob nan (nan)	GS 26.156 (26.156)	mem 39.915
Train: [72][290/750]	BT 0.106 (1.215)	DT 0.008 (1.081)	loss nan (nan)	prob nan (nan)	GS 35.859 (35.859)	mem 40.134
Train: [72][295/750]	BT 0.192 (1.198)	DT 0.045 (1.063)	loss nan (nan)	prob nan (nan)	GS 31.438 (31.438)	mem 39.924
Train: [72][300/750]	BT 0.120 (1.219)	DT 0.001 (1.085)	loss nan (nan)	prob nan (nan)	GS 30.938 (30.938)	mem 39.954
Train: [72][305/750]	BT 0.185 (1.202)	DT 0.001 (1.067)	loss nan (nan)	prob nan (nan)	GS 32.641 (32.641)	mem 40.116
Train: [72][310/750]	BT 0.099 (1.226)	DT 0.001 (1.092)	loss nan (nan)	prob nan (nan)	GS 35.781 (35.781)	mem 39.914
Train: [72][315/750]	BT 0.076 (1.208)	DT 0.002 (1.075)	loss nan (nan)	prob nan (nan)	GS 35.109 (35.109)	mem 39.966
Train: [72][320/750]	BT 12.285 (1.230)	DT 12.212 (1.096)	loss nan (nan)	prob nan (nan)	GS 34.984 (34.984)	mem 40.000
Train: [72][325/750]	BT 0.086 (1.212)	DT 0.001 (1.079)	loss nan (nan)	prob nan (nan)	GS 29.500 (29.500)	mem 40.032
Train: [72][330/750]	BT 0.097 (1.196)	DT 0.005 (1.063)	loss nan (nan)	prob nan (nan)	GS 31.750 (31.750)	mem 40.003
Train: [72][335/750]	BT 0.074 (1.219)	DT 0.001 (1.087)	loss nan (nan)	prob nan (nan)	GS 27.234 (27.234)	mem 39.864
Train: [72][340/750]	BT 0.143 (1.202)	DT 0.002 (1.071)	loss nan (nan)	prob nan (nan)	GS 31.266 (31.266)	mem 39.867
Train: [72][345/750]	BT 0.130 (1.218)	DT 0.001 (1.087)	loss nan (nan)	prob nan (nan)	GS 33.297 (33.297)	mem 39.992
Train: [72][350/750]	BT 0.151 (1.203)	DT 0.013 (1.071)	loss nan (nan)	prob nan (nan)	GS 30.406 (30.406)	mem 39.993
Train: [72][355/750]	BT 0.208 (1.188)	DT 0.001 (1.056)	loss nan (nan)	prob nan (nan)	GS 31.172 (31.172)	mem 40.049
Train: [72][360/750]	BT 0.152 (1.206)	DT 0.001 (1.075)	loss nan (nan)	prob nan (nan)	GS 30.906 (30.906)	mem 39.965
Train: [72][365/750]	BT 0.114 (1.192)	DT 0.002 (1.061)	loss nan (nan)	prob nan (nan)	GS 30.953 (30.953)	mem 40.037
Train: [72][370/750]	BT 0.104 (1.210)	DT 0.001 (1.079)	loss nan (nan)	prob nan (nan)	GS 33.766 (33.766)	mem 39.995
Train: [72][375/750]	BT 0.134 (1.195)	DT 0.009 (1.065)	loss nan (nan)	prob nan (nan)	GS 29.469 (29.469)	mem 39.903
Train: [72][380/750]	BT 11.739 (1.212)	DT 11.630 (1.081)	loss nan (nan)	prob nan (nan)	GS 32.109 (32.109)	mem 40.089
Train: [72][385/750]	BT 0.106 (1.198)	DT 0.002 (1.067)	loss nan (nan)	prob nan (nan)	GS 36.672 (36.672)	mem 40.007
Train: [72][390/750]	BT 0.221 (1.184)	DT 0.002 (1.054)	loss nan (nan)	prob nan (nan)	GS 39.688 (39.688)	mem 40.084
Train: [72][395/750]	BT 0.128 (1.199)	DT 0.002 (1.069)	loss nan (nan)	prob nan (nan)	GS 31.156 (31.156)	mem 40.065
Train: [72][400/750]	BT 0.175 (1.186)	DT 0.008 (1.056)	loss nan (nan)	prob nan (nan)	GS 37.391 (37.391)	mem 40.105
Train: [72][405/750]	BT 0.112 (1.203)	DT 0.001 (1.073)	loss nan (nan)	prob nan (nan)	GS 31.219 (31.219)	mem 40.042
Train: [72][410/750]	BT 0.084 (1.190)	DT 0.001 (1.060)	loss nan (nan)	prob nan (nan)	GS 34.234 (34.234)	mem 40.001
Train: [72][415/750]	BT 0.109 (1.177)	DT 0.004 (1.048)	loss nan (nan)	prob nan (nan)	GS 30.859 (30.859)	mem 40.017
Train: [72][420/750]	BT 0.136 (1.202)	DT 0.011 (1.073)	loss nan (nan)	prob nan (nan)	GS 33.094 (33.094)	mem 39.937
Train: [72][425/750]	BT 0.168 (1.189)	DT 0.006 (1.060)	loss nan (nan)	prob nan (nan)	GS 33.828 (33.828)	mem 40.033
Train: [72][430/750]	BT 0.082 (1.205)	DT 0.001 (1.076)	loss nan (nan)	prob nan (nan)	GS 35.672 (35.672)	mem 40.252
Train: [72][435/750]	BT 0.085 (1.192)	DT 0.001 (1.064)	loss nan (nan)	prob nan (nan)	GS 31.516 (31.516)	mem 40.091
Train: [72][440/750]	BT 11.604 (1.207)	DT 11.494 (1.078)	loss nan (nan)	prob nan (nan)	GS 35.484 (35.484)	mem 40.086
Train: [72][445/750]	BT 0.123 (1.195)	DT 0.002 (1.066)	loss nan (nan)	prob nan (nan)	GS 27.453 (27.453)	mem 40.086
Train: [72][450/750]	BT 0.116 (1.183)	DT 0.002 (1.054)	loss nan (nan)	prob nan (nan)	GS 36.844 (36.844)	mem 40.123
Train: [72][455/750]	BT 0.067 (1.200)	DT 0.002 (1.072)	loss nan (nan)	prob nan (nan)	GS 31.844 (31.844)	mem 40.015
Train: [72][460/750]	BT 0.102 (1.188)	DT 0.008 (1.060)	loss nan (nan)	prob nan (nan)	GS 32.000 (32.000)	mem 40.046
Train: [72][465/750]	BT 0.104 (1.197)	DT 0.002 (1.069)	loss nan (nan)	prob nan (nan)	GS 31.984 (31.984)	mem 40.115
Train: [72][470/750]	BT 0.195 (1.186)	DT 0.002 (1.057)	loss nan (nan)	prob nan (nan)	GS 31.688 (31.688)	mem 40.061
Train: [72][475/750]	BT 0.095 (1.174)	DT 0.001 (1.046)	loss nan (nan)	prob nan (nan)	GS 31.219 (31.219)	mem 39.994
Train: [72][480/750]	BT 0.240 (1.184)	DT 0.002 (1.056)	loss nan (nan)	prob nan (nan)	GS 37.594 (37.594)	mem 40.055
Train: [72][485/750]	BT 0.109 (1.174)	DT 0.001 (1.045)	loss nan (nan)	prob nan (nan)	GS 34.062 (34.062)	mem 40.168
Train: [72][490/750]	BT 0.131 (1.188)	DT 0.001 (1.060)	loss nan (nan)	prob nan (nan)	GS 37.266 (37.266)	mem 40.044
Train: [72][495/750]	BT 0.144 (1.178)	DT 0.001 (1.050)	loss nan (nan)	prob nan (nan)	GS 42.125 (42.125)	mem 40.010
Train: [72][500/750]	BT 10.794 (1.189)	DT 10.674 (1.060)	loss nan (nan)	prob nan (nan)	GS 35.562 (35.562)	mem 40.036
Train: [72][505/750]	BT 0.099 (1.183)	DT 0.002 (1.054)	loss nan (nan)	prob nan (nan)	GS 30.047 (30.047)	mem 39.991
Train: [72][510/750]	BT 0.191 (1.172)	DT 0.002 (1.044)	loss nan (nan)	prob nan (nan)	GS 31.781 (31.781)	mem 40.014
Train: [72][515/750]	BT 0.139 (1.178)	DT 0.002 (1.050)	loss nan (nan)	prob nan (nan)	GS 31.047 (31.047)	mem 40.048
Train: [72][520/750]	BT 0.137 (1.171)	DT 0.002 (1.042)	loss nan (nan)	prob nan (nan)	GS 32.547 (32.547)	mem 40.122
Train: [72][525/750]	BT 0.092 (1.180)	DT 0.001 (1.051)	loss nan (nan)	prob nan (nan)	GS 31.859 (31.859)	mem 40.067
Train: [72][530/750]	BT 0.093 (1.173)	DT 0.002 (1.044)	loss nan (nan)	prob nan (nan)	GS 35.656 (35.656)	mem 40.005
Train: [72][535/750]	BT 0.088 (1.163)	DT 0.002 (1.035)	loss nan (nan)	prob nan (nan)	GS 29.375 (29.375)	mem 40.011
Train: [72][540/750]	BT 1.437 (1.179)	DT 1.269 (1.051)	loss nan (nan)	prob nan (nan)	GS 36.859 (36.859)	mem 40.038
Train: [72][545/750]	BT 0.121 (1.169)	DT 0.010 (1.041)	loss nan (nan)	prob nan (nan)	GS 36.719 (36.719)	mem 40.079
Train: [72][550/750]	BT 0.136 (1.185)	DT 0.004 (1.056)	loss nan (nan)	prob nan (nan)	GS 36.469 (36.469)	mem 39.954
Train: [72][555/750]	BT 0.114 (1.175)	DT 0.002 (1.047)	loss nan (nan)	prob nan (nan)	GS 32.359 (32.359)	mem 40.098
Train: [72][560/750]	BT 10.205 (1.184)	DT 10.131 (1.056)	loss nan (nan)	prob nan (nan)	GS 35.719 (35.719)	mem 40.121
Train: [72][565/750]	BT 0.112 (1.174)	DT 0.008 (1.046)	loss nan (nan)	prob nan (nan)	GS 33.375 (33.375)	mem 40.057
Train: [72][570/750]	BT 0.242 (1.165)	DT 0.037 (1.037)	loss nan (nan)	prob nan (nan)	GS 32.641 (32.641)	mem 40.085
Train: [72][575/750]	BT 0.152 (1.180)	DT 0.002 (1.052)	loss nan (nan)	prob nan (nan)	GS 32.547 (32.547)	mem 40.000
Train: [72][580/750]	BT 0.189 (1.172)	DT 0.002 (1.044)	loss nan (nan)	prob nan (nan)	GS 34.938 (34.938)	mem 40.009
Train: [72][585/750]	BT 0.163 (1.180)	DT 0.002 (1.052)	loss nan (nan)	prob nan (nan)	GS 35.703 (35.703)	mem 40.096
Train: [72][590/750]	BT 0.132 (1.173)	DT 0.002 (1.045)	loss nan (nan)	prob nan (nan)	GS 31.750 (31.750)	mem 40.037
Train: [72][595/750]	BT 0.206 (1.165)	DT 0.002 (1.037)	loss nan (nan)	prob nan (nan)	GS 28.547 (28.547)	mem 40.041
Train: [72][600/750]	BT 1.863 (1.175)	DT 1.749 (1.047)	loss nan (nan)	prob nan (nan)	GS 29.578 (29.578)	mem 40.138
Train: [72][605/750]	BT 0.172 (1.167)	DT 0.007 (1.039)	loss nan (nan)	prob nan (nan)	GS 30.891 (30.891)	mem 40.121
Train: [72][610/750]	BT 0.165 (1.181)	DT 0.006 (1.053)	loss nan (nan)	prob nan (nan)	GS 36.344 (36.344)	mem 40.083
Train: [72][615/750]	BT 0.139 (1.173)	DT 0.002 (1.045)	loss nan (nan)	prob nan (nan)	GS 30.594 (30.594)	mem 40.085
Train: [72][620/750]	BT 10.754 (1.181)	DT 10.620 (1.054)	loss nan (nan)	prob nan (nan)	GS 32.406 (32.406)	mem 40.102
Train: [72][625/750]	BT 0.154 (1.173)	DT 0.002 (1.045)	loss nan (nan)	prob nan (nan)	GS 32.703 (32.703)	mem 40.209
Train: [72][630/750]	BT 0.130 (1.165)	DT 0.014 (1.037)	loss nan (nan)	prob nan (nan)	GS 32.969 (32.969)	mem 40.239
Train: [72][635/750]	BT 0.116 (1.178)	DT 0.009 (1.050)	loss nan (nan)	prob nan (nan)	GS 31.578 (31.578)	mem 40.050
Train: [72][640/750]	BT 0.097 (1.169)	DT 0.008 (1.042)	loss nan (nan)	prob nan (nan)	GS 38.141 (38.141)	mem 40.111
Train: [72][645/750]	BT 0.162 (1.174)	DT 0.027 (1.046)	loss nan (nan)	prob nan (nan)	GS 29.891 (29.891)	mem 40.143
Train: [72][650/750]	BT 3.803 (1.172)	DT 3.639 (1.044)	loss nan (nan)	prob nan (nan)	GS 33.266 (33.266)	mem 40.099
Train: [72][655/750]	BT 0.085 (1.163)	DT 0.002 (1.036)	loss nan (nan)	prob nan (nan)	GS 34.094 (34.094)	mem 40.054
Train: [72][660/750]	BT 0.182 (1.166)	DT 0.001 (1.039)	loss nan (nan)	prob nan (nan)	GS 31.391 (31.391)	mem 40.192
Train: [72][665/750]	BT 0.089 (1.168)	DT 0.002 (1.040)	loss nan (nan)	prob nan (nan)	GS 32.266 (32.266)	mem 40.117
Train: [72][670/750]	BT 0.172 (1.167)	DT 0.045 (1.039)	loss nan (nan)	prob nan (nan)	GS 31.469 (31.469)	mem 40.175
Train: [72][675/750]	BT 0.099 (1.162)	DT 0.002 (1.035)	loss nan (nan)	prob nan (nan)	GS 30.172 (30.172)	mem 40.090
Train: [72][680/750]	BT 9.345 (1.169)	DT 9.263 (1.041)	loss nan (nan)	prob nan (nan)	GS 30.844 (30.844)	mem 40.039
Train: [72][685/750]	BT 0.194 (1.161)	DT 0.006 (1.033)	loss nan (nan)	prob nan (nan)	GS 31.500 (31.500)	mem 40.039
Train: [72][690/750]	BT 0.260 (1.155)	DT 0.002 (1.027)	loss nan (nan)	prob nan (nan)	GS 33.188 (33.188)	mem 40.079
Train: [72][695/750]	BT 0.165 (1.164)	DT 0.002 (1.035)	loss nan (nan)	prob nan (nan)	GS 32.734 (32.734)	mem 40.115
Train: [72][700/750]	BT 2.178 (1.160)	DT 2.101 (1.031)	loss nan (nan)	prob nan (nan)	GS 32.688 (32.688)	mem 40.129
Train: [72][705/750]	BT 0.125 (1.172)	DT 0.003 (1.044)	loss nan (nan)	prob nan (nan)	GS 32.031 (32.031)	mem 40.070
arpack error, retry= 0
arpack error, retry= 0
Train: [72][710/750]	BT 0.312 (1.165)	DT 0.121 (1.037)	loss nan (nan)	prob nan (nan)	GS 35.578 (35.578)	mem 40.070
Train: [72][715/750]	BT 0.139 (1.158)	DT 0.008 (1.030)	loss nan (nan)	prob nan (nan)	GS 35.938 (35.938)	mem 40.070
Train: [72][720/750]	BT 0.072 (1.164)	DT 0.001 (1.036)	loss nan (nan)	prob nan (nan)	GS 34.328 (34.328)	mem 40.154
Train: [72][725/750]	BT 0.115 (1.164)	DT 0.002 (1.036)	loss nan (nan)	prob nan (nan)	GS 30.875 (30.875)	mem 39.835
Train: [72][730/750]	BT 0.126 (1.166)	DT 0.001 (1.038)	loss nan (nan)	prob nan (nan)	GS 30.766 (30.766)	mem 39.802
Train: [72][735/750]	BT 0.086 (1.161)	DT 0.002 (1.034)	loss nan (nan)	prob nan (nan)	GS 34.344 (34.344)	mem 36.895
Train: [72][740/750]	BT 5.922 (1.162)	DT 5.841 (1.035)	loss nan (nan)	prob nan (nan)	GS 35.406 (35.406)	mem 10.765
Train: [72][745/750]	BT 0.053 (1.155)	DT 0.001 (1.028)	loss nan (nan)	prob nan (nan)	GS 32.875 (32.875)	mem 10.764
Train: [72][750/750]	BT 0.064 (1.147)	DT 0.001 (1.021)	loss nan (nan)	prob nan (nan)	GS 39.469 (39.469)	mem 10.728
Train: [72][755/750]	BT 0.064 (1.142)	DT 0.001 (1.016)	loss nan (nan)	prob nan (nan)	GS 30.188 (30.188)	mem 7.732
epoch 72, total time 862.71
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [73][1/750]	BT 21.006 (21.006)	DT 20.850 (20.850)	loss nan (nan)	prob nan (nan)	GS 30.953 (30.953)	mem 38.717
Train: [73][5/750]	BT 0.099 (5.549)	DT 0.002 (5.429)	loss nan (nan)	prob nan (nan)	GS 30.516 (30.516)	mem 38.670
Train: [73][10/750]	BT 0.128 (2.837)	DT 0.001 (2.715)	loss nan (nan)	prob nan (nan)	GS 32.438 (32.438)	mem 38.735
Train: [73][15/750]	BT 0.180 (2.425)	DT 0.001 (2.300)	loss nan (nan)	prob nan (nan)	GS 26.500 (26.500)	mem 38.875
Train: [73][20/750]	BT 0.123 (2.134)	DT 0.004 (2.008)	loss nan (nan)	prob nan (nan)	GS 35.500 (35.500)	mem 38.879
Train: [73][25/750]	BT 0.103 (1.732)	DT 0.002 (1.607)	loss nan (nan)	prob nan (nan)	GS 34.172 (34.172)	mem 39.082
Train: [73][30/750]	BT 0.138 (1.885)	DT 0.014 (1.758)	loss nan (nan)	prob nan (nan)	GS 32.688 (32.688)	mem 38.885
Train: [73][35/750]	BT 0.236 (1.636)	DT 0.002 (1.508)	loss nan (nan)	prob nan (nan)	GS 33.516 (33.516)	mem 39.012
Train: [73][40/750]	BT 6.450 (1.719)	DT 6.364 (1.585)	loss nan (nan)	prob nan (nan)	GS 28.906 (28.906)	mem 39.119
Train: [73][45/750]	BT 0.093 (1.559)	DT 0.002 (1.428)	loss nan (nan)	prob nan (nan)	GS 31.203 (31.203)	mem 39.025
Train: [73][50/750]	BT 6.204 (1.535)	DT 6.043 (1.407)	loss nan (nan)	prob nan (nan)	GS 33.266 (33.266)	mem 39.097
Train: [73][55/750]	BT 0.137 (1.530)	DT 0.006 (1.399)	loss nan (nan)	prob nan (nan)	GS 37.734 (37.734)	mem 39.001
Train: [73][60/750]	BT 0.094 (1.447)	DT 0.002 (1.317)	loss nan (nan)	prob nan (nan)	GS 34.531 (34.531)	mem 39.239
Train: [73][65/750]	BT 0.090 (1.445)	DT 0.002 (1.316)	loss nan (nan)	prob nan (nan)	GS 33.562 (33.562)	mem 39.046
Train: [73][70/750]	BT 0.206 (1.433)	DT 0.011 (1.304)	loss nan (nan)	prob nan (nan)	GS 35.141 (35.141)	mem 39.265
Train: [73][75/750]	BT 0.226 (1.354)	DT 0.018 (1.223)	loss nan (nan)	prob nan (nan)	GS 34.172 (34.172)	mem 39.074
Train: [73][80/750]	BT 3.198 (1.389)	DT 3.085 (1.255)	loss nan (nan)	prob nan (nan)	GS 33.594 (33.594)	mem 39.200
Train: [73][85/750]	BT 0.274 (1.317)	DT 0.004 (1.182)	loss nan (nan)	prob nan (nan)	GS 28.344 (28.344)	mem 39.414
Train: [73][90/750]	BT 2.917 (1.338)	DT 2.800 (1.203)	loss nan (nan)	prob nan (nan)	GS 32.562 (32.562)	mem 39.174
Train: [73][95/750]	BT 0.118 (1.302)	DT 0.004 (1.168)	loss nan (nan)	prob nan (nan)	GS 35.438 (35.438)	mem 39.224
Train: [73][100/750]	BT 0.349 (1.322)	DT 0.245 (1.188)	loss nan (nan)	prob nan (nan)	GS 32.266 (32.266)	mem 39.370
Train: [73][105/750]	BT 0.096 (1.293)	DT 0.009 (1.159)	loss nan (nan)	prob nan (nan)	GS 31.641 (31.641)	mem 39.441
Train: [73][110/750]	BT 11.699 (1.347)	DT 11.585 (1.212)	loss nan (nan)	prob nan (nan)	GS 34.734 (34.734)	mem 39.442
Train: [73][115/750]	BT 0.080 (1.303)	DT 0.004 (1.169)	loss nan (nan)	prob nan (nan)	GS 31.828 (31.828)	mem 39.543
Train: [73][120/750]	BT 0.096 (1.264)	DT 0.004 (1.128)	loss nan (nan)	prob nan (nan)	GS 33.188 (33.188)	mem 39.440
Train: [73][125/750]	BT 0.091 (1.307)	DT 0.002 (1.173)	loss nan (nan)	prob nan (nan)	GS 33.297 (33.297)	mem 39.465
Train: [73][130/750]	BT 0.113 (1.261)	DT 0.002 (1.128)	loss nan (nan)	prob nan (nan)	GS 38.750 (38.750)	mem 39.471
Train: [73][135/750]	BT 0.157 (1.290)	DT 0.001 (1.157)	loss nan (nan)	prob nan (nan)	GS 27.609 (27.609)	mem 39.585
Train: [73][140/750]	BT 0.183 (1.270)	DT 0.005 (1.136)	loss nan (nan)	prob nan (nan)	GS 34.844 (34.844)	mem 39.486
Train: [73][145/750]	BT 0.188 (1.231)	DT 0.003 (1.097)	loss nan (nan)	prob nan (nan)	GS 31.047 (31.047)	mem 39.667
Train: [73][150/750]	BT 4.054 (1.271)	DT 3.986 (1.136)	loss nan (nan)	prob nan (nan)	GS 33.516 (33.516)	mem 39.546
Train: [73][155/750]	BT 0.097 (1.234)	DT 0.002 (1.100)	loss nan (nan)	prob nan (nan)	GS 33.109 (33.109)	mem 39.550
Train: [73][160/750]	BT 0.071 (1.246)	DT 0.002 (1.113)	loss nan (nan)	prob nan (nan)	GS 31.516 (31.516)	mem 39.560
Train: [73][165/750]	BT 0.084 (1.223)	DT 0.001 (1.090)	loss nan (nan)	prob nan (nan)	GS 33.609 (33.609)	mem 39.661
Train: [73][170/750]	BT 10.737 (1.253)	DT 10.635 (1.120)	loss nan (nan)	prob nan (nan)	GS 34.609 (34.609)	mem 39.579
Train: [73][175/750]	BT 0.084 (1.242)	DT 0.001 (1.110)	loss nan (nan)	prob nan (nan)	GS 29.844 (29.844)	mem 39.885
Train: [73][180/750]	BT 0.193 (1.210)	DT 0.002 (1.079)	loss nan (nan)	prob nan (nan)	GS 34.078 (34.078)	mem 40.006
Train: [73][185/750]	BT 0.084 (1.238)	DT 0.010 (1.107)	loss nan (nan)	prob nan (nan)	GS 30.094 (30.094)	mem 40.882
Train: [73][190/750]	BT 0.145 (1.231)	DT 0.005 (1.099)	loss nan (nan)	prob nan (nan)	GS 34.531 (34.531)	mem 41.543
Train: [73][195/750]	BT 0.159 (1.238)	DT 0.019 (1.107)	loss nan (nan)	prob nan (nan)	GS 26.797 (26.797)	mem 41.944
Train: [73][200/750]	BT 0.197 (1.237)	DT 0.011 (1.106)	loss nan (nan)	prob nan (nan)	GS 35.578 (35.578)	mem 41.710
Train: [73][205/750]	BT 0.122 (1.211)	DT 0.007 (1.079)	loss nan (nan)	prob nan (nan)	GS 31.906 (31.906)	mem 41.719
Train: [73][210/750]	BT 7.275 (1.250)	DT 7.178 (1.119)	loss nan (nan)	prob nan (nan)	GS 36.047 (36.047)	mem 41.598
Train: [73][215/750]	BT 0.164 (1.225)	DT 0.009 (1.093)	loss nan (nan)	prob nan (nan)	GS 34.016 (34.016)	mem 41.630
Train: [73][220/750]	BT 0.120 (1.215)	DT 0.001 (1.084)	loss nan (nan)	prob nan (nan)	GS 32.766 (32.766)	mem 41.672
Train: [73][225/750]	BT 0.082 (1.222)	DT 0.002 (1.091)	loss nan (nan)	prob nan (nan)	GS 29.781 (29.781)	mem 41.588
Train: [73][230/750]	BT 3.816 (1.214)	DT 3.586 (1.083)	loss nan (nan)	prob nan (nan)	GS 34.109 (34.109)	mem 41.525
Train: [73][235/750]	BT 0.093 (1.224)	DT 0.002 (1.093)	loss nan (nan)	prob nan (nan)	GS 35.703 (35.703)	mem 41.799
Train: [73][240/750]	BT 0.300 (1.202)	DT 0.051 (1.071)	loss nan (nan)	prob nan (nan)	GS 31.641 (31.641)	mem 41.853
Train: [73][245/750]	BT 0.121 (1.197)	DT 0.001 (1.066)	loss nan (nan)	prob nan (nan)	GS 32.844 (32.844)	mem 41.657
Train: [73][250/750]	BT 0.103 (1.196)	DT 0.002 (1.066)	loss nan (nan)	prob nan (nan)	GS 32.359 (32.359)	mem 41.746
Train: [73][255/750]	BT 0.118 (1.201)	DT 0.002 (1.071)	loss nan (nan)	prob nan (nan)	GS 30.078 (30.078)	mem 41.877
Train: [73][260/750]	BT 0.394 (1.195)	DT 0.013 (1.064)	loss nan (nan)	prob nan (nan)	GS 33.125 (33.125)	mem 42.053
Train: [73][265/750]	BT 0.231 (1.175)	DT 0.008 (1.044)	loss nan (nan)	prob nan (nan)	GS 32.750 (32.750)	mem 41.916
Train: [73][270/750]	BT 3.746 (1.197)	DT 3.609 (1.066)	loss nan (nan)	prob nan (nan)	GS 32.641 (32.641)	mem 41.807
Train: [73][275/750]	BT 0.147 (1.178)	DT 0.017 (1.046)	loss nan (nan)	prob nan (nan)	GS 30.156 (30.156)	mem 41.807
Train: [73][280/750]	BT 0.089 (1.189)	DT 0.002 (1.059)	loss nan (nan)	prob nan (nan)	GS 34.109 (34.109)	mem 42.033
Train: [73][285/750]	BT 0.140 (1.183)	DT 0.002 (1.052)	loss nan (nan)	prob nan (nan)	GS 33.125 (33.125)	mem 41.826
Train: [73][290/750]	BT 9.608 (1.198)	DT 9.478 (1.067)	loss nan (nan)	prob nan (nan)	GS 37.016 (37.016)	mem 41.846
Train: [73][295/750]	BT 0.146 (1.184)	DT 0.013 (1.053)	loss nan (nan)	prob nan (nan)	GS 33.500 (33.500)	mem 41.867
Train: [73][300/750]	BT 0.112 (1.182)	DT 0.001 (1.051)	loss nan (nan)	prob nan (nan)	GS 34.375 (34.375)	mem 41.855
Train: [73][305/750]	BT 0.170 (1.179)	DT 0.015 (1.047)	loss nan (nan)	prob nan (nan)	GS 31.828 (31.828)	mem 41.920
Train: [73][310/750]	BT 0.091 (1.183)	DT 0.002 (1.052)	loss nan (nan)	prob nan (nan)	GS 32.547 (32.547)	mem 41.926
Train: [73][315/750]	BT 0.142 (1.191)	DT 0.005 (1.060)	loss nan (nan)	prob nan (nan)	GS 27.484 (27.484)	mem 41.873
Train: [73][320/750]	BT 2.097 (1.181)	DT 1.981 (1.049)	loss nan (nan)	prob nan (nan)	GS 33.109 (33.109)	mem 41.943
Train: [73][325/750]	BT 0.164 (1.165)	DT 0.002 (1.033)	loss nan (nan)	prob nan (nan)	GS 29.156 (29.156)	mem 42.051
Train: [73][330/750]	BT 0.090 (1.185)	DT 0.002 (1.053)	loss nan (nan)	prob nan (nan)	GS 36.078 (36.078)	mem 41.809
Train: [73][335/750]	BT 0.204 (1.173)	DT 0.004 (1.040)	loss nan (nan)	prob nan (nan)	GS 31.922 (31.922)	mem 41.984
Train: [73][340/750]	BT 0.083 (1.195)	DT 0.013 (1.063)	loss nan (nan)	prob nan (nan)	GS 32.312 (32.312)	mem 41.913
Train: [73][345/750]	BT 0.124 (1.180)	DT 0.010 (1.047)	loss nan (nan)	prob nan (nan)	GS 31.094 (31.094)	mem 42.024
Train: [73][350/750]	BT 11.115 (1.196)	DT 10.987 (1.064)	loss nan (nan)	prob nan (nan)	GS 34.328 (34.328)	mem 42.066
Train: [73][355/750]	BT 0.094 (1.181)	DT 0.004 (1.049)	loss nan (nan)	prob nan (nan)	GS 28.797 (28.797)	mem 41.921
Train: [73][360/750]	BT 0.095 (1.166)	DT 0.002 (1.034)	loss nan (nan)	prob nan (nan)	GS 34.031 (34.031)	mem 41.904
Train: [73][365/750]	BT 0.083 (1.186)	DT 0.001 (1.055)	loss nan (nan)	prob nan (nan)	GS 32.734 (32.734)	mem 41.918
Train: [73][370/750]	BT 0.200 (1.172)	DT 0.003 (1.041)	loss nan (nan)	prob nan (nan)	GS 34.484 (34.484)	mem 42.077
Train: [73][375/750]	BT 0.093 (1.190)	DT 0.002 (1.057)	loss nan (nan)	prob nan (nan)	GS 30.719 (30.719)	mem 41.952
Train: [73][380/750]	BT 0.158 (1.176)	DT 0.018 (1.044)	loss nan (nan)	prob nan (nan)	GS 35.516 (35.516)	mem 41.893
Train: [73][385/750]	BT 0.129 (1.163)	DT 0.003 (1.030)	loss nan (nan)	prob nan (nan)	GS 29.594 (29.594)	mem 41.914
Train: [73][390/750]	BT 0.098 (1.179)	DT 0.001 (1.047)	loss nan (nan)	prob nan (nan)	GS 31.562 (31.562)	mem 41.839
Train: [73][395/750]	BT 0.269 (1.167)	DT 0.010 (1.034)	loss nan (nan)	prob nan (nan)	GS 32.484 (32.484)	mem 41.805
Train: [73][400/750]	BT 0.139 (1.184)	DT 0.002 (1.052)	loss nan (nan)	prob nan (nan)	GS 33.391 (33.391)	mem 41.912
Train: [73][405/750]	BT 0.097 (1.178)	DT 0.001 (1.046)	loss nan (nan)	prob nan (nan)	GS 32.156 (32.156)	mem 41.842
Train: [73][410/750]	BT 12.484 (1.195)	DT 12.383 (1.063)	loss nan (nan)	prob nan (nan)	GS 32.125 (32.125)	mem 41.757
Train: [73][415/750]	BT 0.157 (1.182)	DT 0.001 (1.051)	loss nan (nan)	prob nan (nan)	GS 32.672 (32.672)	mem 41.808
Train: [73][420/750]	BT 0.173 (1.170)	DT 0.007 (1.038)	loss nan (nan)	prob nan (nan)	GS 32.500 (32.500)	mem 41.854
Train: [73][425/750]	BT 0.094 (1.184)	DT 0.003 (1.052)	loss nan (nan)	prob nan (nan)	GS 32.672 (32.672)	mem 41.734
Train: [73][430/750]	BT 0.088 (1.172)	DT 0.003 (1.040)	loss nan (nan)	prob nan (nan)	GS 35.781 (35.781)	mem 41.763
Train: [73][435/750]	BT 0.150 (1.186)	DT 0.002 (1.054)	loss nan (nan)	prob nan (nan)	GS 32.641 (32.641)	mem 41.851
Train: [73][440/750]	BT 0.234 (1.174)	DT 0.015 (1.042)	loss nan (nan)	prob nan (nan)	GS 29.562 (29.562)	mem 41.873
Train: [73][445/750]	BT 0.120 (1.162)	DT 0.001 (1.031)	loss nan (nan)	prob nan (nan)	GS 35.625 (35.625)	mem 41.875
Train: [73][450/750]	BT 0.156 (1.185)	DT 0.002 (1.053)	loss nan (nan)	prob nan (nan)	GS 37.750 (37.750)	mem 42.021
Train: [73][455/750]	BT 0.094 (1.173)	DT 0.002 (1.042)	loss nan (nan)	prob nan (nan)	GS 30.781 (30.781)	mem 41.915
Train: [73][460/750]	BT 0.090 (1.189)	DT 0.002 (1.058)	loss nan (nan)	prob nan (nan)	GS 34.156 (34.156)	mem 41.959
Train: [73][465/750]	BT 0.093 (1.177)	DT 0.002 (1.047)	loss nan (nan)	prob nan (nan)	GS 34.453 (34.453)	mem 41.960
Train: [73][470/750]	BT 11.023 (1.189)	DT 10.879 (1.059)	loss nan (nan)	prob nan (nan)	GS 32.547 (32.547)	mem 41.956
Train: [73][475/750]	BT 0.142 (1.178)	DT 0.001 (1.048)	loss nan (nan)	prob nan (nan)	GS 32.484 (32.484)	mem 41.959
Train: [73][480/750]	BT 0.175 (1.167)	DT 0.003 (1.037)	loss nan (nan)	prob nan (nan)	GS 32.359 (32.359)	mem 41.893
Train: [73][485/750]	BT 0.225 (1.181)	DT 0.005 (1.050)	loss nan (nan)	prob nan (nan)	GS 32.844 (32.844)	mem 42.585
Train: [73][490/750]	BT 0.210 (1.171)	DT 0.010 (1.040)	loss nan (nan)	prob nan (nan)	GS 35.422 (35.422)	mem 43.172
Train: [73][495/750]	BT 0.116 (1.193)	DT 0.013 (1.062)	loss nan (nan)	prob nan (nan)	GS 30.375 (30.375)	mem 44.986
Train: [73][500/750]	BT 0.226 (1.183)	DT 0.009 (1.051)	loss nan (nan)	prob nan (nan)	GS 35.891 (35.891)	mem 45.097
Train: [73][505/750]	BT 0.117 (1.173)	DT 0.012 (1.041)	loss nan (nan)	prob nan (nan)	GS 32.953 (32.953)	mem 45.165
Train: [73][510/750]	BT 0.087 (1.192)	DT 0.002 (1.060)	loss nan (nan)	prob nan (nan)	GS 35.844 (35.844)	mem 45.191
Train: [73][515/750]	BT 0.163 (1.183)	DT 0.012 (1.050)	loss nan (nan)	prob nan (nan)	GS 33.328 (33.328)	mem 45.272
Train: [73][520/750]	BT 0.087 (1.208)	DT 0.002 (1.076)	loss nan (nan)	prob nan (nan)	GS 31.266 (31.266)	mem 45.482
Train: [73][525/750]	BT 0.112 (1.198)	DT 0.003 (1.065)	loss nan (nan)	prob nan (nan)	GS 36.203 (36.203)	mem 45.489
Train: [73][530/750]	BT 16.856 (1.219)	DT 16.714 (1.087)	loss nan (nan)	prob nan (nan)	GS 39.266 (39.266)	mem 45.599
Train: [73][535/750]	BT 0.094 (1.209)	DT 0.002 (1.077)	loss nan (nan)	prob nan (nan)	GS 29.625 (29.625)	mem 45.560
Train: [73][540/750]	BT 0.223 (1.199)	DT 0.003 (1.067)	loss nan (nan)	prob nan (nan)	GS 33.719 (33.719)	mem 45.780
Train: [73][545/750]	BT 0.129 (1.214)	DT 0.005 (1.082)	loss nan (nan)	prob nan (nan)	GS 30.016 (30.016)	mem 42.106
Train: [73][550/750]	BT 0.090 (1.204)	DT 0.002 (1.072)	loss nan (nan)	prob nan (nan)	GS 33.438 (33.438)	mem 42.032
Train: [73][555/750]	BT 0.134 (1.213)	DT 0.003 (1.080)	loss nan (nan)	prob nan (nan)	GS 29.609 (29.609)	mem 42.078
Train: [73][560/750]	BT 0.094 (1.203)	DT 0.002 (1.071)	loss nan (nan)	prob nan (nan)	GS 33.891 (33.891)	mem 42.200
Train: [73][565/750]	BT 0.087 (1.194)	DT 0.001 (1.061)	loss nan (nan)	prob nan (nan)	GS 30.625 (30.625)	mem 42.060
Train: [73][570/750]	BT 0.121 (1.206)	DT 0.007 (1.073)	loss nan (nan)	prob nan (nan)	GS 34.469 (34.469)	mem 42.372
Train: [73][575/750]	BT 0.144 (1.196)	DT 0.003 (1.064)	loss nan (nan)	prob nan (nan)	GS 30.453 (30.453)	mem 42.073
Train: [73][580/750]	BT 0.071 (1.211)	DT 0.001 (1.079)	loss nan (nan)	prob nan (nan)	GS 30.906 (30.906)	mem 41.951
Train: [73][585/750]	BT 0.168 (1.202)	DT 0.002 (1.070)	loss nan (nan)	prob nan (nan)	GS 33.234 (33.234)	mem 41.930
Train: [73][590/750]	BT 11.525 (1.212)	DT 11.427 (1.080)	loss nan (nan)	prob nan (nan)	GS 32.094 (32.094)	mem 42.045
Train: [73][595/750]	BT 0.111 (1.203)	DT 0.004 (1.071)	loss nan (nan)	prob nan (nan)	GS 32.500 (32.500)	mem 42.047
Train: [73][600/750]	BT 0.142 (1.194)	DT 0.003 (1.062)	loss nan (nan)	prob nan (nan)	GS 30.312 (30.312)	mem 42.211
Train: [73][605/750]	BT 0.139 (1.202)	DT 0.006 (1.070)	loss nan (nan)	prob nan (nan)	GS 31.438 (31.438)	mem 42.088
Train: [73][610/750]	BT 0.115 (1.199)	DT 0.005 (1.067)	loss nan (nan)	prob nan (nan)	GS 32.484 (32.484)	mem 42.172
Train: [73][615/750]	BT 0.177 (1.203)	DT 0.002 (1.071)	loss nan (nan)	prob nan (nan)	GS 33.625 (33.625)	mem 42.176
Train: [73][620/750]	BT 4.355 (1.201)	DT 4.228 (1.069)	loss nan (nan)	prob nan (nan)	GS 34.516 (34.516)	mem 42.166
Train: [73][625/750]	BT 0.088 (1.192)	DT 0.002 (1.060)	loss nan (nan)	prob nan (nan)	GS 32.781 (32.781)	mem 42.168
Train: [73][630/750]	BT 0.170 (1.194)	DT 0.001 (1.062)	loss nan (nan)	prob nan (nan)	GS 26.578 (26.578)	mem 42.095
Train: [73][635/750]	BT 0.080 (1.198)	DT 0.002 (1.067)	loss nan (nan)	prob nan (nan)	GS 28.156 (28.156)	mem 42.051
Train: [73][640/750]	BT 0.087 (1.194)	DT 0.002 (1.062)	loss nan (nan)	prob nan (nan)	GS 35.250 (35.250)	mem 41.997
Train: [73][645/750]	BT 0.122 (1.212)	DT 0.018 (1.080)	loss nan (nan)	prob nan (nan)	GS 33.281 (33.281)	mem 41.954
Train: [73][650/750]	BT 0.201 (1.204)	DT 0.012 (1.072)	loss nan (nan)	prob nan (nan)	GS 38.594 (38.594)	mem 41.999
Train: [73][655/750]	BT 0.152 (1.196)	DT 0.002 (1.064)	loss nan (nan)	prob nan (nan)	GS 30.141 (30.141)	mem 42.043
Train: [73][660/750]	BT 0.119 (1.205)	DT 0.005 (1.073)	loss nan (nan)	prob nan (nan)	GS 36.562 (36.562)	mem 42.021
Train: [73][665/750]	BT 0.148 (1.197)	DT 0.001 (1.065)	loss nan (nan)	prob nan (nan)	GS 32.375 (32.375)	mem 41.948
Train: [73][670/750]	BT 0.081 (1.206)	DT 0.002 (1.075)	loss nan (nan)	prob nan (nan)	GS 36.594 (36.594)	mem 42.022
Train: [73][675/750]	BT 0.093 (1.198)	DT 0.002 (1.067)	loss nan (nan)	prob nan (nan)	GS 35.188 (35.188)	mem 42.035
Train: [73][680/750]	BT 14.330 (1.211)	DT 14.247 (1.080)	loss nan (nan)	prob nan (nan)	GS 33.250 (33.250)	mem 41.935
Train: [73][685/750]	BT 0.097 (1.203)	DT 0.002 (1.072)	loss nan (nan)	prob nan (nan)	GS 30.875 (30.875)	mem 41.936
Train: [73][690/750]	BT 0.141 (1.195)	DT 0.001 (1.064)	loss nan (nan)	prob nan (nan)	GS 36.297 (36.297)	mem 41.936
Train: [73][695/750]	BT 0.132 (1.202)	DT 0.008 (1.070)	loss nan (nan)	prob nan (nan)	GS 34.781 (34.781)	mem 42.084
Train: [73][700/750]	BT 0.097 (1.194)	DT 0.002 (1.063)	loss nan (nan)	prob nan (nan)	GS 33.641 (33.641)	mem 41.929
Train: [73][705/750]	BT 0.166 (1.202)	DT 0.002 (1.071)	loss nan (nan)	prob nan (nan)	GS 29.984 (29.984)	mem 41.920
Train: [73][710/750]	BT 0.101 (1.194)	DT 0.003 (1.063)	loss nan (nan)	prob nan (nan)	GS 30.500 (30.500)	mem 41.919
Train: [73][715/750]	BT 0.137 (1.187)	DT 0.003 (1.056)	loss nan (nan)	prob nan (nan)	GS 31.266 (31.266)	mem 41.925
Train: [73][720/750]	BT 0.106 (1.195)	DT 0.001 (1.064)	loss nan (nan)	prob nan (nan)	GS 32.016 (32.016)	mem 42.036
Train: [73][725/750]	BT 0.172 (1.188)	DT 0.002 (1.057)	loss nan (nan)	prob nan (nan)	GS 28.906 (28.906)	mem 42.040
Train: [73][730/750]	BT 0.084 (1.193)	DT 0.002 (1.062)	loss nan (nan)	prob nan (nan)	GS 30.922 (30.922)	mem 41.695
Train: [73][735/750]	BT 0.113 (1.185)	DT 0.001 (1.055)	loss nan (nan)	prob nan (nan)	GS 31.594 (31.594)	mem 41.759
Train: [73][740/750]	BT 5.573 (1.185)	DT 5.508 (1.055)	loss nan (nan)	prob nan (nan)	GS 32.406 (32.406)	mem 15.702
Train: [73][745/750]	BT 0.090 (1.178)	DT 0.002 (1.048)	loss nan (nan)	prob nan (nan)	GS 29.781 (29.781)	mem 15.705
Train: [73][750/750]	BT 0.113 (1.171)	DT 0.002 (1.041)	loss nan (nan)	prob nan (nan)	GS 38.906 (38.906)	mem 15.670
Train: [73][755/750]	BT 0.071 (1.166)	DT 0.002 (1.037)	loss nan (nan)	prob nan (nan)	GS 29.719 (29.719)	mem 9.706
epoch 73, total time 880.97
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [74][1/750]	BT 22.768 (22.768)	DT 22.675 (22.675)	loss nan (nan)	prob nan (nan)	GS 34.016 (34.016)	mem 40.638
Train: [74][5/750]	BT 0.133 (5.239)	DT 0.002 (5.128)	loss nan (nan)	prob nan (nan)	GS 30.391 (30.391)	mem 40.696
Train: [74][10/750]	BT 0.202 (2.700)	DT 0.011 (2.567)	loss nan (nan)	prob nan (nan)	GS 31.656 (31.656)	mem 40.795
Train: [74][15/750]	BT 0.134 (2.306)	DT 0.001 (2.175)	loss nan (nan)	prob nan (nan)	GS 27.062 (27.062)	mem 40.922
Train: [74][20/750]	BT 0.244 (1.967)	DT 0.001 (1.834)	loss nan (nan)	prob nan (nan)	GS 30.203 (30.203)	mem 41.112
Train: [74][25/750]	BT 6.500 (1.868)	DT 6.325 (1.722)	loss nan (nan)	prob nan (nan)	GS 30.453 (30.453)	mem 41.076
Train: [74][30/750]	BT 2.128 (1.728)	DT 1.986 (1.586)	loss nan (nan)	prob nan (nan)	GS 34.047 (34.047)	mem 41.096
Train: [74][35/750]	BT 0.242 (1.503)	DT 0.021 (1.361)	loss nan (nan)	prob nan (nan)	GS 32.141 (32.141)	mem 41.094
Train: [74][40/750]	BT 0.144 (1.575)	DT 0.009 (1.434)	loss nan (nan)	prob nan (nan)	GS 35.422 (35.422)	mem 41.113
Train: [74][45/750]	BT 0.207 (1.490)	DT 0.002 (1.348)	loss nan (nan)	prob nan (nan)	GS 26.812 (26.812)	mem 41.204
Train: [74][50/750]	BT 8.857 (1.598)	DT 8.709 (1.454)	loss nan (nan)	prob nan (nan)	GS 35.078 (35.078)	mem 41.235
Train: [74][55/750]	BT 0.093 (1.476)	DT 0.002 (1.331)	loss nan (nan)	prob nan (nan)	GS 34.469 (34.469)	mem 41.237
Train: [74][60/750]	BT 0.225 (1.365)	DT 0.003 (1.220)	loss nan (nan)	prob nan (nan)	GS 33.219 (33.219)	mem 41.238
Train: [74][65/750]	BT 0.075 (1.410)	DT 0.002 (1.267)	loss nan (nan)	prob nan (nan)	GS 30.750 (30.750)	mem 41.205
Train: [74][70/750]	BT 0.108 (1.350)	DT 0.002 (1.208)	loss nan (nan)	prob nan (nan)	GS 33.578 (33.578)	mem 41.385
Train: [74][75/750]	BT 0.157 (1.411)	DT 0.011 (1.270)	loss nan (nan)	prob nan (nan)	GS 28.953 (28.953)	mem 41.213
Train: [74][80/750]	BT 0.195 (1.332)	DT 0.013 (1.191)	loss nan (nan)	prob nan (nan)	GS 33.812 (33.812)	mem 41.294
Train: [74][85/750]	BT 0.123 (1.262)	DT 0.002 (1.121)	loss nan (nan)	prob nan (nan)	GS 31.344 (31.344)	mem 41.256
Train: [74][90/750]	BT 0.512 (1.378)	DT 0.344 (1.237)	loss nan (nan)	prob nan (nan)	GS 35.188 (35.188)	mem 41.306
Train: [74][95/750]	BT 0.162 (1.314)	DT 0.014 (1.173)	loss nan (nan)	prob nan (nan)	GS 33.609 (33.609)	mem 41.499
Train: [74][100/750]	BT 0.175 (1.393)	DT 0.028 (1.254)	loss nan (nan)	prob nan (nan)	GS 35.844 (35.844)	mem 41.307
Train: [74][105/750]	BT 0.195 (1.335)	DT 0.001 (1.194)	loss nan (nan)	prob nan (nan)	GS 28.000 (28.000)	mem 41.335
Train: [74][110/750]	BT 17.446 (1.437)	DT 17.333 (1.298)	loss nan (nan)	prob nan (nan)	GS 37.609 (37.609)	mem 44.366
Train: [74][115/750]	BT 0.123 (1.380)	DT 0.008 (1.242)	loss nan (nan)	prob nan (nan)	GS 31.734 (31.734)	mem 44.379
Train: [74][120/750]	BT 0.230 (1.329)	DT 0.006 (1.190)	loss nan (nan)	prob nan (nan)	GS 30.844 (30.844)	mem 44.409
Train: [74][125/750]	BT 0.170 (1.377)	DT 0.002 (1.238)	loss nan (nan)	prob nan (nan)	GS 31.516 (31.516)	mem 44.844
Train: [74][130/750]	BT 0.149 (1.330)	DT 0.008 (1.190)	loss nan (nan)	prob nan (nan)	GS 33.719 (33.719)	mem 44.887
Train: [74][135/750]	BT 0.129 (1.407)	DT 0.004 (1.265)	loss nan (nan)	prob nan (nan)	GS 29.812 (29.812)	mem 45.971
Train: [74][140/750]	BT 0.091 (1.363)	DT 0.002 (1.220)	loss nan (nan)	prob nan (nan)	GS 32.094 (32.094)	mem 46.116
Train: [74][145/750]	BT 0.200 (1.322)	DT 0.032 (1.179)	loss nan (nan)	prob nan (nan)	GS 44.281 (44.281)	mem 46.180
Train: [74][150/750]	BT 0.119 (1.428)	DT 0.017 (1.287)	loss nan (nan)	prob nan (nan)	GS 33.781 (33.781)	mem 46.452
Train: [74][155/750]	BT 0.148 (1.387)	DT 0.004 (1.245)	loss nan (nan)	prob nan (nan)	GS 33.000 (33.000)	mem 46.561
Train: [74][160/750]	BT 0.312 (1.422)	DT 0.017 (1.277)	loss nan (nan)	prob nan (nan)	GS 35.078 (35.078)	mem 46.635
Train: [74][165/750]	BT 0.301 (1.388)	DT 0.032 (1.239)	loss nan (nan)	prob nan (nan)	GS 27.031 (27.031)	mem 46.540
Train: [74][170/750]	BT 12.953 (1.428)	DT 12.794 (1.278)	loss nan (nan)	prob nan (nan)	GS 34.359 (34.359)	mem 46.595
Train: [74][175/750]	BT 0.311 (1.392)	DT 0.008 (1.242)	loss nan (nan)	prob nan (nan)	GS 39.453 (39.453)	mem 46.738
Train: [74][180/750]	BT 0.087 (1.358)	DT 0.002 (1.207)	loss nan (nan)	prob nan (nan)	GS 34.469 (34.469)	mem 47.398
Train: [74][185/750]	BT 0.093 (1.385)	DT 0.002 (1.234)	loss nan (nan)	prob nan (nan)	GS 28.719 (28.719)	mem 64.720
Train: [74][190/750]	BT 0.256 (1.355)	DT 0.009 (1.204)	loss nan (nan)	prob nan (nan)	GS 32.734 (32.734)	mem 66.557
Train: [74][195/750]	BT 0.188 (1.386)	DT 0.003 (1.233)	loss nan (nan)	prob nan (nan)	GS 30.922 (30.922)	mem 69.682
Train: [74][200/750]	BT 5.381 (1.382)	DT 5.252 (1.229)	loss nan (nan)	prob nan (nan)	GS 33.188 (33.188)	mem 69.899
Train: [74][205/750]	BT 0.190 (1.361)	DT 0.025 (1.209)	loss nan (nan)	prob nan (nan)	GS 29.922 (29.922)	mem 69.693
Train: [74][210/750]	BT 0.092 (1.379)	DT 0.001 (1.227)	loss nan (nan)	prob nan (nan)	GS 33.312 (33.312)	mem 69.523
Train: [74][215/750]	BT 0.125 (1.350)	DT 0.002 (1.198)	loss nan (nan)	prob nan (nan)	GS 32.516 (32.516)	mem 69.509
Train: [74][220/750]	BT 0.695 (1.383)	DT 0.531 (1.233)	loss nan (nan)	prob nan (nan)	GS 33.141 (33.141)	mem 69.549
Train: [74][225/750]	BT 0.113 (1.356)	DT 0.003 (1.206)	loss nan (nan)	prob nan (nan)	GS 27.516 (27.516)	mem 69.522
Train: [74][230/750]	BT 5.367 (1.384)	DT 5.287 (1.233)	loss nan (nan)	prob nan (nan)	GS 33.797 (33.797)	mem 69.599
Train: [74][235/750]	BT 0.104 (1.374)	DT 0.006 (1.224)	loss nan (nan)	prob nan (nan)	GS 30.984 (30.984)	mem 69.626
Train: [74][240/750]	BT 3.456 (1.362)	DT 3.325 (1.213)	loss nan (nan)	prob nan (nan)	GS 29.891 (29.891)	mem 69.586
Train: [74][245/750]	BT 0.135 (1.378)	DT 0.018 (1.230)	loss nan (nan)	prob nan (nan)	GS 29.797 (29.797)	mem 69.631
Train: [74][250/750]	BT 0.139 (1.363)	DT 0.003 (1.215)	loss nan (nan)	prob nan (nan)	GS 33.469 (33.469)	mem 69.712
Train: [74][255/750]	BT 0.188 (1.365)	DT 0.003 (1.218)	loss nan (nan)	prob nan (nan)	GS 33.609 (33.609)	mem 69.847
Train: [74][260/750]	BT 0.163 (1.381)	DT 0.003 (1.233)	loss nan (nan)	prob nan (nan)	GS 35.344 (35.344)	mem 69.649
Train: [74][265/750]	BT 0.153 (1.358)	DT 0.002 (1.210)	loss nan (nan)	prob nan (nan)	GS 29.516 (29.516)	mem 69.705
Train: [74][270/750]	BT 5.559 (1.383)	DT 5.430 (1.236)	loss nan (nan)	prob nan (nan)	GS 34.594 (34.594)	mem 69.739
Train: [74][275/750]	BT 0.178 (1.361)	DT 0.001 (1.213)	loss nan (nan)	prob nan (nan)	GS 29.062 (29.062)	mem 69.742
Train: [74][280/750]	BT 4.000 (1.372)	DT 3.905 (1.224)	loss nan (nan)	prob nan (nan)	GS 32.328 (32.328)	mem 69.782
Train: [74][285/750]	BT 0.188 (1.378)	DT 0.009 (1.231)	loss nan (nan)	prob nan (nan)	GS 35.438 (35.438)	mem 69.814
Train: [74][290/750]	BT 0.162 (1.357)	DT 0.005 (1.210)	loss nan (nan)	prob nan (nan)	GS 33.891 (33.891)	mem 69.749
Train: [74][295/750]	BT 0.106 (1.372)	DT 0.007 (1.225)	loss nan (nan)	prob nan (nan)	GS 32.781 (32.781)	mem 43.123
Train: [74][300/750]	BT 0.085 (1.356)	DT 0.007 (1.209)	loss nan (nan)	prob nan (nan)	GS 33.859 (33.859)	mem 43.071
Train: [74][305/750]	BT 0.159 (1.356)	DT 0.019 (1.209)	loss nan (nan)	prob nan (nan)	GS 32.375 (32.375)	mem 43.498
Train: [74][310/750]	BT 0.089 (1.360)	DT 0.002 (1.214)	loss nan (nan)	prob nan (nan)	GS 36.500 (36.500)	mem 43.235
Train: [74][315/750]	BT 0.098 (1.340)	DT 0.002 (1.194)	loss nan (nan)	prob nan (nan)	GS 32.641 (32.641)	mem 43.099
Train: [74][320/750]	BT 0.087 (1.355)	DT 0.002 (1.210)	loss nan (nan)	prob nan (nan)	GS 28.969 (28.969)	mem 43.228
Train: [74][325/750]	BT 0.110 (1.337)	DT 0.003 (1.191)	loss nan (nan)	prob nan (nan)	GS 31.031 (31.031)	mem 43.152
Train: [74][330/750]	BT 6.619 (1.349)	DT 6.427 (1.203)	loss nan (nan)	prob nan (nan)	GS 34.141 (34.141)	mem 43.214
Train: [74][335/750]	BT 0.095 (1.336)	DT 0.002 (1.191)	loss nan (nan)	prob nan (nan)	GS 30.969 (30.969)	mem 43.109
Train: [74][340/750]	BT 4.138 (1.331)	DT 4.027 (1.186)	loss nan (nan)	prob nan (nan)	GS 32.844 (32.844)	mem 43.042
Train: [74][345/750]	BT 0.080 (1.344)	DT 0.002 (1.199)	loss nan (nan)	prob nan (nan)	GS 31.938 (31.938)	mem 43.140
Train: [74][350/750]	BT 0.143 (1.326)	DT 0.005 (1.181)	loss nan (nan)	prob nan (nan)	GS 32.750 (32.750)	mem 43.131
Train: [74][355/750]	BT 0.075 (1.347)	DT 0.002 (1.203)	loss nan (nan)	prob nan (nan)	GS 30.422 (30.422)	mem 43.111
Train: [74][360/750]	BT 0.172 (1.330)	DT 0.002 (1.186)	loss nan (nan)	prob nan (nan)	GS 34.547 (34.547)	mem 43.177
Train: [74][365/750]	BT 0.158 (1.315)	DT 0.019 (1.170)	loss nan (nan)	prob nan (nan)	GS 33.266 (33.266)	mem 43.101
Train: [74][370/750]	BT 0.112 (1.324)	DT 0.001 (1.180)	loss nan (nan)	prob nan (nan)	GS 33.391 (33.391)	mem 43.164
Train: [74][375/750]	BT 0.189 (1.309)	DT 0.006 (1.164)	loss nan (nan)	prob nan (nan)	GS 25.531 (25.531)	mem 43.259
Train: [74][380/750]	BT 0.158 (1.327)	DT 0.009 (1.183)	loss nan (nan)	prob nan (nan)	GS 35.281 (35.281)	mem 43.127
Train: [74][385/750]	BT 0.175 (1.312)	DT 0.010 (1.168)	loss nan (nan)	prob nan (nan)	GS 30.484 (30.484)	mem 43.195
Train: [74][390/750]	BT 12.681 (1.329)	DT 12.582 (1.185)	loss nan (nan)	prob nan (nan)	GS 37.734 (37.734)	mem 43.195
Train: [74][395/750]	BT 0.079 (1.313)	DT 0.002 (1.170)	loss nan (nan)	prob nan (nan)	GS 41.484 (41.484)	mem 43.151
Train: [74][400/750]	BT 0.091 (1.298)	DT 0.005 (1.156)	loss nan (nan)	prob nan (nan)	GS 33.906 (33.906)	mem 43.199
Train: [74][405/750]	BT 0.129 (1.314)	DT 0.003 (1.171)	loss nan (nan)	prob nan (nan)	GS 29.141 (29.141)	mem 43.190
Train: [74][410/750]	BT 0.107 (1.299)	DT 0.003 (1.157)	loss nan (nan)	prob nan (nan)	GS 32.844 (32.844)	mem 43.122
Train: [74][415/750]	BT 0.308 (1.307)	DT 0.013 (1.165)	loss nan (nan)	prob nan (nan)	GS 30.516 (30.516)	mem 43.428
Train: [74][420/750]	BT 0.082 (1.294)	DT 0.001 (1.151)	loss nan (nan)	prob nan (nan)	GS 33.859 (33.859)	mem 43.072
Train: [74][425/750]	BT 0.136 (1.280)	DT 0.003 (1.138)	loss nan (nan)	prob nan (nan)	GS 32.156 (32.156)	mem 43.113
Train: [74][430/750]	BT 0.096 (1.289)	DT 0.001 (1.147)	loss nan (nan)	prob nan (nan)	GS 32.625 (32.625)	mem 43.176
Train: [74][435/750]	BT 0.072 (1.276)	DT 0.002 (1.134)	loss nan (nan)	prob nan (nan)	GS 28.844 (28.844)	mem 43.225
Train: [74][440/750]	BT 0.206 (1.295)	DT 0.009 (1.153)	loss nan (nan)	prob nan (nan)	GS 36.094 (36.094)	mem 44.027
Train: [74][445/750]	BT 0.153 (1.283)	DT 0.002 (1.140)	loss nan (nan)	prob nan (nan)	GS 31.312 (31.312)	mem 44.291
Train: [74][450/750]	BT 16.785 (1.308)	DT 16.648 (1.165)	loss nan (nan)	prob nan (nan)	GS 38.641 (38.641)	mem 45.000
Train: [74][455/750]	BT 0.084 (1.294)	DT 0.001 (1.152)	loss nan (nan)	prob nan (nan)	GS 32.891 (32.891)	mem 45.005
Train: [74][460/750]	BT 0.224 (1.282)	DT 0.028 (1.139)	loss nan (nan)	prob nan (nan)	GS 35.641 (35.641)	mem 45.271
Train: [74][465/750]	BT 0.098 (1.296)	DT 0.002 (1.154)	loss nan (nan)	prob nan (nan)	GS 37.703 (37.703)	mem 44.945
Train: [74][470/750]	BT 0.153 (1.283)	DT 0.003 (1.141)	loss nan (nan)	prob nan (nan)	GS 32.031 (32.031)	mem 44.871
Train: [74][475/750]	BT 0.109 (1.300)	DT 0.002 (1.159)	loss nan (nan)	prob nan (nan)	GS 30.438 (30.438)	mem 44.895
Train: [74][480/750]	BT 0.182 (1.288)	DT 0.011 (1.147)	loss nan (nan)	prob nan (nan)	GS 37.609 (37.609)	mem 44.831
Train: [74][485/750]	BT 0.178 (1.276)	DT 0.010 (1.135)	loss nan (nan)	prob nan (nan)	GS 31.797 (31.797)	mem 44.802
Train: [74][490/750]	BT 0.113 (1.290)	DT 0.001 (1.149)	loss nan (nan)	prob nan (nan)	GS 30.719 (30.719)	mem 44.740
Train: [74][495/750]	BT 0.085 (1.278)	DT 0.002 (1.137)	loss nan (nan)	prob nan (nan)	GS 33.953 (33.953)	mem 44.672
Train: [74][500/750]	BT 0.106 (1.282)	DT 0.002 (1.142)	loss nan (nan)	prob nan (nan)	GS 35.062 (35.062)	mem 43.146
Train: [74][505/750]	BT 0.279 (1.271)	DT 0.006 (1.130)	loss nan (nan)	prob nan (nan)	GS 29.547 (29.547)	mem 43.090
Train: [74][510/750]	BT 11.647 (1.282)	DT 11.494 (1.142)	loss nan (nan)	prob nan (nan)	GS 30.516 (30.516)	mem 43.174
Train: [74][515/750]	BT 0.143 (1.271)	DT 0.003 (1.131)	loss nan (nan)	prob nan (nan)	GS 40.094 (40.094)	mem 43.269
Train: [74][520/750]	BT 0.137 (1.261)	DT 0.003 (1.120)	loss nan (nan)	prob nan (nan)	GS 31.406 (31.406)	mem 43.136
Train: [74][525/750]	BT 0.068 (1.275)	DT 0.001 (1.135)	loss nan (nan)	prob nan (nan)	GS 31.438 (31.438)	mem 43.077
Train: [74][530/750]	BT 0.183 (1.264)	DT 0.028 (1.124)	loss nan (nan)	prob nan (nan)	GS 35.625 (35.625)	mem 43.118
Train: [74][535/750]	BT 0.077 (1.266)	DT 0.002 (1.127)	loss nan (nan)	prob nan (nan)	GS 32.750 (32.750)	mem 43.122
Train: [74][540/750]	BT 0.113 (1.267)	DT 0.003 (1.128)	loss nan (nan)	prob nan (nan)	GS 34.109 (34.109)	mem 43.250
Train: [74][545/750]	BT 0.191 (1.257)	DT 0.014 (1.117)	loss nan (nan)	prob nan (nan)	GS 34.266 (34.266)	mem 43.134
Train: [74][550/750]	BT 0.159 (1.270)	DT 0.002 (1.131)	loss nan (nan)	prob nan (nan)	GS 36.641 (36.641)	mem 43.299
Train: [74][555/750]	BT 0.096 (1.260)	DT 0.003 (1.121)	loss nan (nan)	prob nan (nan)	GS 32.656 (32.656)	mem 43.458
Train: [74][560/750]	BT 11.691 (1.278)	DT 11.532 (1.139)	loss nan (nan)	prob nan (nan)	GS 37.938 (37.938)	mem 43.282
Train: [74][565/750]	BT 0.086 (1.268)	DT 0.002 (1.129)	loss nan (nan)	prob nan (nan)	GS 31.641 (31.641)	mem 43.169
Train: [74][570/750]	BT 0.079 (1.258)	DT 0.003 (1.119)	loss nan (nan)	prob nan (nan)	GS 33.609 (33.609)	mem 43.157
Train: [74][575/750]	BT 0.064 (1.272)	DT 0.001 (1.133)	loss nan (nan)	prob nan (nan)	GS 28.859 (28.859)	mem 43.021
Train: [74][580/750]	BT 0.133 (1.262)	DT 0.016 (1.124)	loss nan (nan)	prob nan (nan)	GS 35.922 (35.922)	mem 43.021
Train: [74][585/750]	BT 0.134 (1.275)	DT 0.001 (1.136)	loss nan (nan)	prob nan (nan)	GS 34.000 (34.000)	mem 43.051
Train: [74][590/750]	BT 0.126 (1.265)	DT 0.002 (1.127)	loss nan (nan)	prob nan (nan)	GS 31.906 (31.906)	mem 43.077
Train: [74][595/750]	BT 0.221 (1.256)	DT 0.011 (1.117)	loss nan (nan)	prob nan (nan)	GS 31.422 (31.422)	mem 43.143
Train: [74][600/750]	BT 0.096 (1.266)	DT 0.002 (1.127)	loss nan (nan)	prob nan (nan)	GS 33.328 (33.328)	mem 43.233
Train: [74][605/750]	BT 0.118 (1.256)	DT 0.001 (1.118)	loss nan (nan)	prob nan (nan)	GS 32.281 (32.281)	mem 43.286
Train: [74][610/750]	BT 0.135 (1.264)	DT 0.001 (1.126)	loss nan (nan)	prob nan (nan)	GS 31.531 (31.531)	mem 43.240
Train: [74][615/750]	BT 0.187 (1.255)	DT 0.029 (1.117)	loss nan (nan)	prob nan (nan)	GS 32.812 (32.812)	mem 43.211
Train: [74][620/750]	BT 13.633 (1.268)	DT 13.489 (1.130)	loss nan (nan)	prob nan (nan)	GS 36.359 (36.359)	mem 43.082
Train: [74][625/750]	BT 0.184 (1.259)	DT 0.009 (1.121)	loss nan (nan)	prob nan (nan)	GS 30.328 (30.328)	mem 43.093
Train: [74][630/750]	BT 0.227 (1.250)	DT 0.007 (1.112)	loss nan (nan)	prob nan (nan)	GS 35.141 (35.141)	mem 43.177
Train: [74][635/750]	BT 0.177 (1.260)	DT 0.011 (1.122)	loss nan (nan)	prob nan (nan)	GS 32.125 (32.125)	mem 43.156
Train: [74][640/750]	BT 0.123 (1.251)	DT 0.002 (1.113)	loss nan (nan)	prob nan (nan)	GS 28.719 (28.719)	mem 43.274
Train: [74][645/750]	BT 0.093 (1.257)	DT 0.001 (1.119)	loss nan (nan)	prob nan (nan)	GS 31.203 (31.203)	mem 43.254
Train: [74][650/750]	BT 0.088 (1.248)	DT 0.001 (1.111)	loss nan (nan)	prob nan (nan)	GS 35.312 (35.312)	mem 43.067
Train: [74][655/750]	BT 0.126 (1.240)	DT 0.008 (1.102)	loss nan (nan)	prob nan (nan)	GS 29.469 (29.469)	mem 43.105
Train: [74][660/750]	BT 0.085 (1.248)	DT 0.001 (1.111)	loss nan (nan)	prob nan (nan)	GS 36.281 (36.281)	mem 43.280
Train: [74][665/750]	BT 0.085 (1.239)	DT 0.002 (1.103)	loss nan (nan)	prob nan (nan)	GS 33.625 (33.625)	mem 43.270
Train: [74][670/750]	BT 0.100 (1.248)	DT 0.002 (1.111)	loss nan (nan)	prob nan (nan)	GS 29.781 (29.781)	mem 43.121
Train: [74][675/750]	BT 0.201 (1.240)	DT 0.016 (1.103)	loss nan (nan)	prob nan (nan)	GS 33.609 (33.609)	mem 43.121
Train: [74][680/750]	BT 12.941 (1.250)	DT 12.821 (1.114)	loss nan (nan)	prob nan (nan)	GS 33.516 (33.516)	mem 43.332
Train: [74][685/750]	BT 0.191 (1.242)	DT 0.002 (1.106)	loss nan (nan)	prob nan (nan)	GS 30.188 (30.188)	mem 43.246
Train: [74][690/750]	BT 0.114 (1.234)	DT 0.013 (1.098)	loss nan (nan)	prob nan (nan)	GS 33.719 (33.719)	mem 43.169
Train: [74][695/750]	BT 0.150 (1.246)	DT 0.008 (1.110)	loss nan (nan)	prob nan (nan)	GS 32.031 (32.031)	mem 41.633
Train: [74][700/750]	BT 0.136 (1.238)	DT 0.002 (1.102)	loss nan (nan)	prob nan (nan)	GS 31.922 (31.922)	mem 41.831
Train: [74][705/750]	BT 0.076 (1.246)	DT 0.002 (1.110)	loss nan (nan)	prob nan (nan)	GS 29.219 (29.219)	mem 41.631
Train: [74][710/750]	BT 0.100 (1.238)	DT 0.001 (1.102)	loss nan (nan)	prob nan (nan)	GS 28.672 (28.672)	mem 41.644
Train: [74][715/750]	BT 0.089 (1.231)	DT 0.002 (1.095)	loss nan (nan)	prob nan (nan)	GS 38.719 (38.719)	mem 41.685
Train: [74][720/750]	BT 0.080 (1.240)	DT 0.003 (1.105)	loss nan (nan)	prob nan (nan)	GS 34.047 (34.047)	mem 41.647
Train: [74][725/750]	BT 0.210 (1.233)	DT 0.012 (1.097)	loss nan (nan)	prob nan (nan)	GS 31.094 (31.094)	mem 41.648
Train: [74][730/750]	BT 0.128 (1.237)	DT 0.019 (1.101)	loss nan (nan)	prob nan (nan)	GS 35.219 (35.219)	mem 41.523
Train: [74][735/750]	BT 0.075 (1.231)	DT 0.006 (1.095)	loss nan (nan)	prob nan (nan)	GS 33.234 (33.234)	mem 38.543
Train: [74][740/750]	BT 3.746 (1.231)	DT 3.577 (1.095)	loss nan (nan)	prob nan (nan)	GS 26.625 (26.625)	mem 15.278
Train: [74][745/750]	BT 0.061 (1.224)	DT 0.001 (1.089)	loss nan (nan)	prob nan (nan)	GS 29.000 (29.000)	mem 12.236
Train: [74][750/750]	BT 0.068 (1.216)	DT 0.001 (1.081)	loss nan (nan)	prob nan (nan)	GS 37.344 (37.344)	mem 12.243
Train: [74][755/750]	BT 0.050 (1.212)	DT 0.001 (1.077)	loss nan (nan)	prob nan (nan)	GS 34.625 (34.625)	mem 9.182
epoch 74, total time 915.39
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [75][1/750]	BT 20.681 (20.681)	DT 20.482 (20.482)	loss nan (nan)	prob nan (nan)	GS 33.547 (33.547)	mem 40.131
Train: [75][5/750]	BT 0.135 (4.248)	DT 0.015 (4.106)	loss nan (nan)	prob nan (nan)	GS 29.516 (29.516)	mem 40.155
Train: [75][10/750]	BT 0.126 (2.387)	DT 0.002 (2.236)	loss nan (nan)	prob nan (nan)	GS 31.016 (31.016)	mem 40.370
Train: [75][15/750]	BT 0.139 (2.213)	DT 0.006 (2.069)	loss nan (nan)	prob nan (nan)	GS 30.234 (30.234)	mem 40.990
Train: [75][20/750]	BT 0.313 (1.906)	DT 0.200 (1.766)	loss nan (nan)	prob nan (nan)	GS 31.109 (31.109)	mem 41.157
Train: [75][25/750]	BT 6.197 (1.800)	DT 5.983 (1.653)	loss nan (nan)	prob nan (nan)	GS 31.766 (31.766)	mem 41.097
Train: [75][30/750]	BT 1.150 (1.700)	DT 1.066 (1.558)	loss nan (nan)	prob nan (nan)	GS 32.906 (32.906)	mem 41.102
Train: [75][35/750]	BT 0.159 (1.603)	DT 0.011 (1.465)	loss nan (nan)	prob nan (nan)	GS 34.078 (34.078)	mem 41.074
Train: [75][40/750]	BT 0.086 (1.559)	DT 0.001 (1.422)	loss nan (nan)	prob nan (nan)	GS 35.734 (35.734)	mem 41.337
Train: [75][45/750]	BT 0.189 (1.518)	DT 0.001 (1.380)	loss nan (nan)	prob nan (nan)	GS 33.281 (33.281)	mem 41.987
Train: [75][50/750]	BT 2.346 (1.426)	DT 2.162 (1.287)	loss nan (nan)	prob nan (nan)	GS 33.672 (33.672)	mem 42.436
Train: [75][55/750]	BT 0.282 (1.385)	DT 0.003 (1.241)	loss nan (nan)	prob nan (nan)	GS 31.156 (31.156)	mem 54.700
Train: [75][60/750]	BT 2.748 (1.392)	DT 2.601 (1.249)	loss nan (nan)	prob nan (nan)	GS 30.812 (30.812)	mem 48.798
Train: [75][65/750]	BT 0.321 (1.357)	DT 0.002 (1.210)	loss nan (nan)	prob nan (nan)	GS 31.547 (31.547)	mem 54.239
Train: [75][70/750]	BT 0.108 (1.383)	DT 0.006 (1.234)	loss nan (nan)	prob nan (nan)	GS 34.359 (34.359)	mem 41.549
Train: [75][75/750]	BT 0.185 (1.368)	DT 0.004 (1.221)	loss nan (nan)	prob nan (nan)	GS 32.766 (32.766)	mem 41.293
Train: [75][80/750]	BT 3.596 (1.335)	DT 3.444 (1.188)	loss nan (nan)	prob nan (nan)	GS 29.156 (29.156)	mem 41.328
Train: [75][85/750]	BT 0.123 (1.282)	DT 0.003 (1.136)	loss nan (nan)	prob nan (nan)	GS 28.703 (28.703)	mem 41.335
Train: [75][90/750]	BT 0.243 (1.289)	DT 0.012 (1.144)	loss nan (nan)	prob nan (nan)	GS 31.734 (31.734)	mem 41.310
Train: [75][95/750]	BT 0.144 (1.268)	DT 0.002 (1.123)	loss nan (nan)	prob nan (nan)	GS 29.125 (29.125)	mem 41.379
Train: [75][100/750]	BT 0.138 (1.300)	DT 0.009 (1.156)	loss nan (nan)	prob nan (nan)	GS 30.891 (30.891)	mem 41.921
Train: [75][105/750]	BT 0.118 (1.247)	DT 0.002 (1.102)	loss nan (nan)	prob nan (nan)	GS 30.125 (30.125)	mem 41.824
Train: [75][110/750]	BT 6.846 (1.296)	DT 6.719 (1.151)	loss nan (nan)	prob nan (nan)	GS 39.203 (39.203)	mem 42.686
Train: [75][115/750]	BT 0.125 (1.245)	DT 0.003 (1.101)	loss nan (nan)	prob nan (nan)	GS 32.547 (32.547)	mem 42.791
Train: [75][120/750]	BT 2.807 (1.255)	DT 2.508 (1.109)	loss nan (nan)	prob nan (nan)	GS 34.062 (34.062)	mem 43.359
Train: [75][125/750]	BT 0.242 (1.241)	DT 0.015 (1.095)	loss nan (nan)	prob nan (nan)	GS 36.469 (36.469)	mem 43.386
Train: [75][130/750]	BT 0.079 (1.266)	DT 0.002 (1.121)	loss nan (nan)	prob nan (nan)	GS 32.078 (32.078)	mem 43.475
Train: [75][135/750]	BT 0.106 (1.248)	DT 0.003 (1.102)	loss nan (nan)	prob nan (nan)	GS 32.750 (32.750)	mem 43.400
Train: [75][140/750]	BT 9.260 (1.273)	DT 9.143 (1.128)	loss nan (nan)	prob nan (nan)	GS 34.672 (34.672)	mem 43.265
Train: [75][145/750]	BT 0.088 (1.233)	DT 0.002 (1.090)	loss nan (nan)	prob nan (nan)	GS 33.656 (33.656)	mem 43.351
Train: [75][150/750]	BT 0.211 (1.236)	DT 0.023 (1.092)	loss nan (nan)	prob nan (nan)	GS 35.156 (35.156)	mem 43.313
Train: [75][155/750]	BT 0.156 (1.249)	DT 0.002 (1.105)	loss nan (nan)	prob nan (nan)	GS 35.062 (35.062)	mem 43.267
Train: [75][160/750]	BT 0.201 (1.237)	DT 0.001 (1.092)	loss nan (nan)	prob nan (nan)	GS 33.297 (33.297)	mem 43.380
Train: [75][165/750]	BT 0.111 (1.269)	DT 0.001 (1.124)	loss nan (nan)	prob nan (nan)	GS 31.344 (31.344)	mem 43.433
Train: [75][170/750]	BT 0.533 (1.238)	DT 0.395 (1.093)	loss nan (nan)	prob nan (nan)	GS 33.188 (33.188)	mem 43.354
Train: [75][175/750]	BT 0.169 (1.206)	DT 0.008 (1.062)	loss nan (nan)	prob nan (nan)	GS 33.547 (33.547)	mem 43.354
Train: [75][180/750]	BT 0.153 (1.234)	DT 0.007 (1.091)	loss nan (nan)	prob nan (nan)	GS 35.891 (35.891)	mem 43.293
Train: [75][185/750]	BT 0.098 (1.227)	DT 0.002 (1.084)	loss nan (nan)	prob nan (nan)	GS 31.031 (31.031)	mem 43.234
Train: [75][190/750]	BT 0.157 (1.229)	DT 0.044 (1.087)	loss nan (nan)	prob nan (nan)	GS 34.875 (34.875)	mem 43.242
Train: [75][195/750]	BT 0.119 (1.249)	DT 0.005 (1.107)	loss nan (nan)	prob nan (nan)	GS 32.109 (32.109)	mem 43.174
Train: [75][200/750]	BT 1.668 (1.229)	DT 1.522 (1.087)	loss nan (nan)	prob nan (nan)	GS 39.562 (39.562)	mem 43.126
Train: [75][205/750]	BT 0.122 (1.218)	DT 0.002 (1.076)	loss nan (nan)	prob nan (nan)	GS 33.812 (33.812)	mem 43.193
Train: [75][210/750]	BT 0.131 (1.221)	DT 0.003 (1.081)	loss nan (nan)	prob nan (nan)	GS 27.656 (27.656)	mem 43.043
Train: [75][215/750]	BT 0.087 (1.217)	DT 0.001 (1.076)	loss nan (nan)	prob nan (nan)	GS 30.500 (30.500)	mem 43.072
Train: [75][220/750]	BT 0.130 (1.216)	DT 0.002 (1.075)	loss nan (nan)	prob nan (nan)	GS 34.516 (34.516)	mem 43.166
Train: [75][225/750]	BT 0.187 (1.209)	DT 0.001 (1.069)	loss nan (nan)	prob nan (nan)	GS 30.484 (30.484)	mem 41.628
Train: [75][230/750]	BT 2.548 (1.213)	DT 2.451 (1.073)	loss nan (nan)	prob nan (nan)	GS 35.781 (35.781)	mem 41.562
Train: [75][235/750]	BT 0.163 (1.191)	DT 0.037 (1.050)	loss nan (nan)	prob nan (nan)	GS 33.812 (33.812)	mem 41.763
Train: [75][240/750]	BT 0.095 (1.211)	DT 0.002 (1.070)	loss nan (nan)	prob nan (nan)	GS 33.500 (33.500)	mem 41.637
Train: [75][245/750]	BT 0.180 (1.196)	DT 0.002 (1.055)	loss nan (nan)	prob nan (nan)	GS 33.141 (33.141)	mem 41.603
Train: [75][250/750]	BT 7.045 (1.213)	DT 6.892 (1.072)	loss nan (nan)	prob nan (nan)	GS 33.875 (33.875)	mem 41.633
Train: [75][255/750]	BT 0.101 (1.191)	DT 0.001 (1.052)	loss nan (nan)	prob nan (nan)	GS 34.234 (34.234)	mem 41.708
Train: [75][260/750]	BT 1.957 (1.178)	DT 1.878 (1.039)	loss nan (nan)	prob nan (nan)	GS 31.438 (31.438)	mem 41.642
Train: [75][265/750]	BT 0.109 (1.192)	DT 0.001 (1.053)	loss nan (nan)	prob nan (nan)	GS 28.625 (28.625)	mem 42.716
Train: [75][270/750]	BT 0.103 (1.175)	DT 0.001 (1.037)	loss nan (nan)	prob nan (nan)	GS 32.516 (32.516)	mem 43.091
Train: [75][275/750]	BT 0.141 (1.191)	DT 0.007 (1.051)	loss nan (nan)	prob nan (nan)	GS 25.719 (25.719)	mem 50.021
Train: [75][280/750]	BT 0.084 (1.181)	DT 0.001 (1.043)	loss nan (nan)	prob nan (nan)	GS 29.359 (29.359)	mem 55.551
Train: [75][285/750]	BT 0.126 (1.182)	DT 0.001 (1.043)	loss nan (nan)	prob nan (nan)	GS 31.094 (31.094)	mem 60.132
Train: [75][290/750]	BT 2.211 (1.187)	DT 2.111 (1.048)	loss nan (nan)	prob nan (nan)	GS 33.516 (33.516)	mem 60.221
Train: [75][295/750]	BT 0.201 (1.169)	DT 0.003 (1.031)	loss nan (nan)	prob nan (nan)	GS 29.438 (29.438)	mem 60.245
Train: [75][300/750]	BT 0.205 (1.194)	DT 0.002 (1.054)	loss nan (nan)	prob nan (nan)	GS 36.922 (36.922)	mem 60.173
Train: [75][305/750]	BT 0.086 (1.183)	DT 0.004 (1.044)	loss nan (nan)	prob nan (nan)	GS 31.703 (31.703)	mem 60.111
Train: [75][310/750]	BT 0.831 (1.186)	DT 0.674 (1.045)	loss nan (nan)	prob nan (nan)	GS 29.969 (29.969)	mem 60.289
Train: [75][315/750]	BT 0.253 (1.194)	DT 0.011 (1.053)	loss nan (nan)	prob nan (nan)	GS 33.234 (33.234)	mem 60.183
Train: [75][320/750]	BT 2.994 (1.186)	DT 2.876 (1.046)	loss nan (nan)	prob nan (nan)	GS 32.531 (32.531)	mem 59.821
Train: [75][325/750]	BT 0.190 (1.186)	DT 0.010 (1.045)	loss nan (nan)	prob nan (nan)	GS 32.359 (32.359)	mem 60.359
Train: [75][330/750]	BT 0.163 (1.188)	DT 0.002 (1.047)	loss nan (nan)	prob nan (nan)	GS 33.594 (33.594)	mem 60.705
Train: [75][335/750]	BT 0.132 (1.185)	DT 0.003 (1.044)	loss nan (nan)	prob nan (nan)	GS 28.266 (28.266)	mem 60.790
Train: [75][340/750]	BT 0.128 (1.192)	DT 0.002 (1.051)	loss nan (nan)	prob nan (nan)	GS 32.953 (32.953)	mem 60.718
Train: [75][345/750]	BT 0.176 (1.177)	DT 0.005 (1.036)	loss nan (nan)	prob nan (nan)	GS 33.062 (33.062)	mem 60.718
Train: [75][350/750]	BT 13.264 (1.207)	DT 13.125 (1.066)	loss nan (nan)	prob nan (nan)	GS 36.906 (36.906)	mem 60.733
Train: [75][355/750]	BT 0.195 (1.192)	DT 0.006 (1.051)	loss nan (nan)	prob nan (nan)	GS 30.016 (30.016)	mem 60.736
Train: [75][360/750]	BT 0.107 (1.178)	DT 0.003 (1.037)	loss nan (nan)	prob nan (nan)	GS 29.484 (29.484)	mem 60.736
Train: [75][365/750]	BT 0.100 (1.190)	DT 0.004 (1.048)	loss nan (nan)	prob nan (nan)	GS 28.969 (28.969)	mem 60.333
Train: [75][370/750]	BT 5.109 (1.189)	DT 5.001 (1.048)	loss nan (nan)	prob nan (nan)	GS 37.281 (37.281)	mem 60.301
Train: [75][375/750]	BT 0.108 (1.195)	DT 0.002 (1.054)	loss nan (nan)	prob nan (nan)	GS 33.625 (33.625)	mem 60.196
Train: [75][380/750]	BT 0.197 (1.182)	DT 0.001 (1.040)	loss nan (nan)	prob nan (nan)	GS 34.906 (34.906)	mem 60.188
Train: [75][385/750]	BT 0.072 (1.183)	DT 0.001 (1.042)	loss nan (nan)	prob nan (nan)	GS 31.516 (31.516)	mem 41.558
Train: [75][390/750]	BT 0.104 (1.185)	DT 0.005 (1.044)	loss nan (nan)	prob nan (nan)	GS 35.500 (35.500)	mem 41.668
Train: [75][395/750]	BT 0.089 (1.182)	DT 0.003 (1.041)	loss nan (nan)	prob nan (nan)	GS 30.188 (30.188)	mem 41.683
Train: [75][400/750]	BT 0.127 (1.190)	DT 0.002 (1.049)	loss nan (nan)	prob nan (nan)	GS 31.125 (31.125)	mem 41.629
Train: [75][405/750]	BT 0.092 (1.177)	DT 0.002 (1.036)	loss nan (nan)	prob nan (nan)	GS 30.641 (30.641)	mem 41.687
Train: [75][410/750]	BT 7.032 (1.190)	DT 6.868 (1.050)	loss nan (nan)	prob nan (nan)	GS 33.781 (33.781)	mem 41.558
Train: [75][415/750]	BT 0.165 (1.177)	DT 0.008 (1.037)	loss nan (nan)	prob nan (nan)	GS 30.328 (30.328)	mem 41.734
Train: [75][420/750]	BT 0.080 (1.178)	DT 0.001 (1.037)	loss nan (nan)	prob nan (nan)	GS 35.297 (35.297)	mem 41.564
Train: [75][425/750]	BT 0.114 (1.189)	DT 0.002 (1.049)	loss nan (nan)	prob nan (nan)	GS 31.047 (31.047)	mem 41.643
Train: [75][430/750]	BT 0.099 (1.177)	DT 0.009 (1.037)	loss nan (nan)	prob nan (nan)	GS 31.812 (31.812)	mem 41.580
Train: [75][435/750]	BT 0.120 (1.192)	DT 0.010 (1.052)	loss nan (nan)	prob nan (nan)	GS 31.703 (31.703)	mem 41.860
Train: [75][440/750]	BT 0.089 (1.180)	DT 0.001 (1.040)	loss nan (nan)	prob nan (nan)	GS 30.609 (30.609)	mem 41.635
Train: [75][445/750]	BT 0.154 (1.168)	DT 0.013 (1.029)	loss nan (nan)	prob nan (nan)	GS 30.750 (30.750)	mem 41.581
Train: [75][450/750]	BT 0.097 (1.180)	DT 0.004 (1.041)	loss nan (nan)	prob nan (nan)	GS 32.203 (32.203)	mem 41.486
Train: [75][455/750]	BT 0.122 (1.168)	DT 0.001 (1.030)	loss nan (nan)	prob nan (nan)	GS 32.984 (32.984)	mem 41.512
Train: [75][460/750]	BT 0.067 (1.186)	DT 0.001 (1.048)	loss nan (nan)	prob nan (nan)	GS 34.688 (34.688)	mem 41.505
Train: [75][465/750]	BT 0.133 (1.175)	DT 0.016 (1.037)	loss nan (nan)	prob nan (nan)	GS 37.188 (37.188)	mem 41.651
Train: [75][470/750]	BT 10.129 (1.185)	DT 10.047 (1.048)	loss nan (nan)	prob nan (nan)	GS 32.297 (32.297)	mem 41.580
Train: [75][475/750]	BT 0.079 (1.174)	DT 0.001 (1.037)	loss nan (nan)	prob nan (nan)	GS 35.781 (35.781)	mem 41.419
Train: [75][480/750]	BT 0.141 (1.163)	DT 0.002 (1.026)	loss nan (nan)	prob nan (nan)	GS 33.188 (33.188)	mem 41.416
Train: [75][485/750]	BT 0.098 (1.177)	DT 0.001 (1.040)	loss nan (nan)	prob nan (nan)	GS 29.938 (29.938)	mem 41.571
Train: [75][490/750]	BT 0.136 (1.166)	DT 0.001 (1.029)	loss nan (nan)	prob nan (nan)	GS 31.062 (31.062)	mem 41.526
Train: [75][495/750]	BT 0.268 (1.185)	DT 0.040 (1.048)	loss nan (nan)	prob nan (nan)	GS 30.734 (30.734)	mem 41.693
Train: [75][500/750]	BT 0.216 (1.175)	DT 0.005 (1.038)	loss nan (nan)	prob nan (nan)	GS 39.141 (39.141)	mem 41.600
Train: [75][505/750]	BT 0.105 (1.165)	DT 0.002 (1.028)	loss nan (nan)	prob nan (nan)	GS 31.422 (31.422)	mem 41.598
Train: [75][510/750]	BT 0.195 (1.174)	DT 0.002 (1.037)	loss nan (nan)	prob nan (nan)	GS 32.047 (32.047)	mem 41.623
Train: [75][515/750]	BT 0.098 (1.164)	DT 0.002 (1.027)	loss nan (nan)	prob nan (nan)	GS 28.625 (28.625)	mem 41.621
Train: [75][520/750]	BT 0.090 (1.179)	DT 0.008 (1.042)	loss nan (nan)	prob nan (nan)	GS 35.297 (35.297)	mem 41.420
Train: [75][525/750]	BT 0.174 (1.169)	DT 0.001 (1.032)	loss nan (nan)	prob nan (nan)	GS 30.859 (30.859)	mem 41.579
Train: [75][530/750]	BT 11.584 (1.181)	DT 11.486 (1.044)	loss nan (nan)	prob nan (nan)	GS 32.750 (32.750)	mem 41.553
Train: [75][535/750]	BT 0.078 (1.171)	DT 0.004 (1.034)	loss nan (nan)	prob nan (nan)	GS 34.094 (34.094)	mem 41.561
Train: [75][540/750]	BT 0.148 (1.166)	DT 0.010 (1.030)	loss nan (nan)	prob nan (nan)	GS 34.000 (34.000)	mem 41.643
Train: [75][545/750]	BT 0.106 (1.172)	DT 0.002 (1.036)	loss nan (nan)	prob nan (nan)	GS 30.188 (30.188)	mem 41.527
Train: [75][550/750]	BT 0.485 (1.163)	DT 0.348 (1.027)	loss nan (nan)	prob nan (nan)	GS 31.406 (31.406)	mem 41.566
Train: [75][555/750]	BT 0.150 (1.172)	DT 0.012 (1.036)	loss nan (nan)	prob nan (nan)	GS 30.359 (30.359)	mem 41.568
Train: [75][560/750]	BT 0.232 (1.163)	DT 0.016 (1.027)	loss nan (nan)	prob nan (nan)	GS 34.734 (34.734)	mem 41.508
Train: [75][565/750]	BT 0.098 (1.155)	DT 0.003 (1.018)	loss nan (nan)	prob nan (nan)	GS 29.688 (29.688)	mem 41.541
Train: [75][570/750]	BT 0.152 (1.173)	DT 0.003 (1.036)	loss nan (nan)	prob nan (nan)	GS 33.641 (33.641)	mem 41.625
Train: [75][575/750]	BT 0.128 (1.165)	DT 0.001 (1.029)	loss nan (nan)	prob nan (nan)	GS 28.484 (28.484)	mem 41.538
Train: [75][580/750]	BT 0.081 (1.177)	DT 0.005 (1.041)	loss nan (nan)	prob nan (nan)	GS 32.859 (32.859)	mem 41.590
Train: [75][585/750]	BT 0.116 (1.168)	DT 0.002 (1.033)	loss nan (nan)	prob nan (nan)	GS 30.344 (30.344)	mem 41.594
Train: [75][590/750]	BT 10.888 (1.178)	DT 10.792 (1.042)	loss nan (nan)	prob nan (nan)	GS 34.844 (34.844)	mem 41.616
Train: [75][595/750]	BT 0.134 (1.169)	DT 0.012 (1.033)	loss nan (nan)	prob nan (nan)	GS 31.719 (31.719)	mem 41.588
Train: [75][600/750]	BT 0.095 (1.160)	DT 0.002 (1.025)	loss nan (nan)	prob nan (nan)	GS 33.266 (33.266)	mem 41.601
Train: [75][605/750]	BT 0.117 (1.168)	DT 0.002 (1.033)	loss nan (nan)	prob nan (nan)	GS 27.484 (27.484)	mem 41.603
Train: [75][610/750]	BT 0.097 (1.160)	DT 0.002 (1.025)	loss nan (nan)	prob nan (nan)	GS 32.094 (32.094)	mem 41.558
Train: [75][615/750]	BT 0.092 (1.174)	DT 0.010 (1.039)	loss nan (nan)	prob nan (nan)	GS 34.828 (34.828)	mem 41.656
Train: [75][620/750]	BT 0.122 (1.166)	DT 0.002 (1.031)	loss nan (nan)	prob nan (nan)	GS 33.828 (33.828)	mem 41.616
Train: [75][625/750]	BT 0.136 (1.157)	DT 0.004 (1.022)	loss nan (nan)	prob nan (nan)	GS 31.672 (31.672)	mem 41.619
Train: [75][630/750]	BT 0.101 (1.171)	DT 0.002 (1.037)	loss nan (nan)	prob nan (nan)	GS 34.859 (34.859)	mem 41.650
Train: [75][635/750]	BT 0.115 (1.163)	DT 0.010 (1.028)	loss nan (nan)	prob nan (nan)	GS 33.125 (33.125)	mem 41.620
Train: [75][640/750]	BT 0.083 (1.169)	DT 0.002 (1.035)	loss nan (nan)	prob nan (nan)	GS 31.641 (31.641)	mem 41.664
Train: [75][645/750]	BT 0.159 (1.161)	DT 0.010 (1.027)	loss nan (nan)	prob nan (nan)	GS 27.859 (27.859)	mem 41.724
Train: [75][650/750]	BT 8.524 (1.167)	DT 8.435 (1.032)	loss nan (nan)	prob nan (nan)	GS 30.453 (30.453)	mem 41.609
Train: [75][655/750]	BT 0.082 (1.159)	DT 0.002 (1.024)	loss nan (nan)	prob nan (nan)	GS 33.016 (33.016)	mem 41.607
Train: [75][660/750]	BT 0.141 (1.151)	DT 0.009 (1.017)	loss nan (nan)	prob nan (nan)	GS 39.062 (39.062)	mem 41.611
Train: [75][665/750]	BT 0.096 (1.162)	DT 0.001 (1.028)	loss nan (nan)	prob nan (nan)	GS 33.938 (33.938)	mem 42.225
Train: [75][670/750]	BT 0.125 (1.154)	DT 0.002 (1.020)	loss nan (nan)	prob nan (nan)	GS 35.344 (35.344)	mem 42.072
Train: [75][675/750]	BT 0.235 (1.162)	DT 0.001 (1.028)	loss nan (nan)	prob nan (nan)	GS 31.031 (31.031)	mem 42.849
Train: [75][680/750]	BT 0.170 (1.155)	DT 0.015 (1.020)	loss nan (nan)	prob nan (nan)	GS 38.641 (38.641)	mem 42.789
Train: [75][685/750]	BT 0.231 (1.148)	DT 0.003 (1.013)	loss nan (nan)	prob nan (nan)	GS 31.125 (31.125)	mem 42.955
Train: [75][690/750]	BT 0.148 (1.155)	DT 0.017 (1.020)	loss nan (nan)	prob nan (nan)	GS 27.844 (27.844)	mem 43.378
Train: [75][695/750]	BT 0.230 (1.148)	DT 0.003 (1.013)	loss nan (nan)	prob nan (nan)	GS 39.656 (39.656)	mem 43.384
Train: [75][700/750]	BT 0.200 (1.155)	DT 0.001 (1.020)	loss nan (nan)	prob nan (nan)	GS 36.406 (36.406)	mem 43.381
Train: [75][705/750]	BT 0.093 (1.148)	DT 0.002 (1.013)	loss nan (nan)	prob nan (nan)	GS 29.125 (29.125)	mem 43.357
Train: [75][710/750]	BT 10.015 (1.157)	DT 9.856 (1.021)	loss nan (nan)	prob nan (nan)	GS 35.953 (35.953)	mem 43.303
Train: [75][715/750]	BT 0.079 (1.149)	DT 0.001 (1.014)	loss nan (nan)	prob nan (nan)	GS 32.422 (32.422)	mem 43.347
Train: [75][720/750]	BT 6.172 (1.151)	DT 6.049 (1.015)	loss nan (nan)	prob nan (nan)	GS 34.516 (34.516)	mem 43.480
Train: [75][725/750]	BT 0.089 (1.150)	DT 0.002 (1.015)	loss nan (nan)	prob nan (nan)	GS 29.219 (29.219)	mem 43.025
Train: [75][730/750]	BT 0.537 (1.144)	DT 0.354 (1.008)	loss nan (nan)	prob nan (nan)	GS 36.125 (36.125)	mem 43.195
Train: [75][735/750]	BT 0.089 (1.149)	DT 0.002 (1.013)	loss nan (nan)	prob nan (nan)	GS 32.953 (32.953)	mem 39.913
Train: [75][740/750]	BT 0.094 (1.142)	DT 0.002 (1.007)	loss nan (nan)	prob nan (nan)	GS 31.391 (31.391)	mem 37.011
Train: [75][745/750]	BT 0.060 (1.139)	DT 0.002 (1.004)	loss nan (nan)	prob nan (nan)	GS 29.312 (29.312)	mem 13.894
Train: [75][750/750]	BT 0.070 (1.132)	DT 0.001 (0.997)	loss nan (nan)	prob nan (nan)	GS 37.812 (37.812)	mem 13.894
Train: [75][755/750]	BT 0.086 (1.126)	DT 0.001 (0.992)	loss nan (nan)	prob nan (nan)	GS 28.188 (28.188)	mem 13.847
epoch 75, total time 851.35
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [76][1/750]	BT 20.644 (20.644)	DT 20.453 (20.453)	loss nan (nan)	prob nan (nan)	GS 32.734 (32.734)	mem 41.597
Train: [76][5/750]	BT 0.162 (5.884)	DT 0.003 (5.744)	loss nan (nan)	prob nan (nan)	GS 32.219 (32.219)	mem 41.879
Train: [76][10/750]	BT 0.091 (3.010)	DT 0.002 (2.873)	loss nan (nan)	prob nan (nan)	GS 30.969 (30.969)	mem 41.799
Train: [76][15/750]	BT 0.242 (3.058)	DT 0.029 (2.912)	loss nan (nan)	prob nan (nan)	GS 32.734 (32.734)	mem 42.029
Train: [76][20/750]	BT 0.104 (2.325)	DT 0.001 (2.185)	loss nan (nan)	prob nan (nan)	GS 33.656 (33.656)	mem 41.993
Train: [76][25/750]	BT 0.077 (1.882)	DT 0.001 (1.750)	loss nan (nan)	prob nan (nan)	GS 32.047 (32.047)	mem 42.042
Train: [76][30/750]	BT 0.133 (1.968)	DT 0.004 (1.836)	loss nan (nan)	prob nan (nan)	GS 35.656 (35.656)	mem 42.129
Train: [76][35/750]	BT 0.155 (1.707)	DT 0.024 (1.576)	loss nan (nan)	prob nan (nan)	GS 29.047 (29.047)	mem 42.176
Train: [76][40/750]	BT 0.104 (1.816)	DT 0.001 (1.686)	loss nan (nan)	prob nan (nan)	GS 32.875 (32.875)	mem 42.160
Train: [76][45/750]	BT 0.209 (1.634)	DT 0.026 (1.500)	loss nan (nan)	prob nan (nan)	GS 29.578 (29.578)	mem 42.224
Train: [76][50/750]	BT 10.845 (1.725)	DT 10.739 (1.589)	loss nan (nan)	prob nan (nan)	GS 34.562 (34.562)	mem 42.145
Train: [76][55/750]	BT 0.145 (1.585)	DT 0.001 (1.448)	loss nan (nan)	prob nan (nan)	GS 33.969 (33.969)	mem 42.208
Train: [76][60/750]	BT 4.028 (1.531)	DT 3.788 (1.391)	loss nan (nan)	prob nan (nan)	GS 37.281 (37.281)	mem 42.249
Train: [76][65/750]	BT 0.137 (1.550)	DT 0.009 (1.410)	loss nan (nan)	prob nan (nan)	GS 29.922 (29.922)	mem 42.118
Train: [76][70/750]	BT 0.204 (1.451)	DT 0.012 (1.310)	loss nan (nan)	prob nan (nan)	GS 32.750 (32.750)	mem 42.118
Train: [76][75/750]	BT 0.094 (1.497)	DT 0.003 (1.356)	loss nan (nan)	prob nan (nan)	GS 28.219 (28.219)	mem 42.159
Train: [76][80/750]	BT 0.179 (1.415)	DT 0.006 (1.271)	loss nan (nan)	prob nan (nan)	GS 31.547 (31.547)	mem 42.231
Train: [76][85/750]	BT 0.116 (1.398)	DT 0.002 (1.252)	loss nan (nan)	prob nan (nan)	GS 29.062 (29.062)	mem 42.214
Train: [76][90/750]	BT 0.120 (1.426)	DT 0.020 (1.283)	loss nan (nan)	prob nan (nan)	GS 35.031 (35.031)	mem 42.241
Train: [76][95/750]	BT 0.128 (1.358)	DT 0.003 (1.215)	loss nan (nan)	prob nan (nan)	GS 35.328 (35.328)	mem 42.242
Train: [76][100/750]	BT 0.073 (1.468)	DT 0.004 (1.325)	loss nan (nan)	prob nan (nan)	GS 35.438 (35.438)	mem 42.307
Train: [76][105/750]	BT 0.173 (1.406)	DT 0.001 (1.262)	loss nan (nan)	prob nan (nan)	GS 28.984 (28.984)	mem 42.321
Train: [76][110/750]	BT 9.879 (1.438)	DT 9.793 (1.294)	loss nan (nan)	prob nan (nan)	GS 32.672 (32.672)	mem 42.325
Train: [76][115/750]	BT 0.094 (1.381)	DT 0.002 (1.238)	loss nan (nan)	prob nan (nan)	GS 34.188 (34.188)	mem 42.306
Train: [76][120/750]	BT 2.317 (1.347)	DT 2.191 (1.205)	loss nan (nan)	prob nan (nan)	GS 33.891 (33.891)	mem 42.636
Train: [76][125/750]	BT 0.203 (1.366)	DT 0.006 (1.224)	loss nan (nan)	prob nan (nan)	GS 33.234 (33.234)	mem 42.388
Train: [76][130/750]	BT 0.131 (1.320)	DT 0.002 (1.177)	loss nan (nan)	prob nan (nan)	GS 37.172 (37.172)	mem 42.463
Train: [76][135/750]	BT 0.132 (1.370)	DT 0.004 (1.227)	loss nan (nan)	prob nan (nan)	GS 31.359 (31.359)	mem 42.608
Train: [76][140/750]	BT 0.125 (1.327)	DT 0.014 (1.183)	loss nan (nan)	prob nan (nan)	GS 35.312 (35.312)	mem 42.530
Train: [76][145/750]	BT 0.109 (1.331)	DT 0.012 (1.188)	loss nan (nan)	prob nan (nan)	GS 28.469 (28.469)	mem 42.642
Train: [76][150/750]	BT 0.095 (1.313)	DT 0.002 (1.171)	loss nan (nan)	prob nan (nan)	GS 31.391 (31.391)	mem 42.648
Train: [76][155/750]	BT 0.138 (1.276)	DT 0.003 (1.133)	loss nan (nan)	prob nan (nan)	GS 28.969 (28.969)	mem 42.831
Train: [76][160/750]	BT 0.104 (1.321)	DT 0.002 (1.178)	loss nan (nan)	prob nan (nan)	GS 33.625 (33.625)	mem 42.610
Train: [76][165/750]	BT 0.145 (1.285)	DT 0.017 (1.143)	loss nan (nan)	prob nan (nan)	GS 33.109 (33.109)	mem 42.634
Train: [76][170/750]	BT 4.765 (1.314)	DT 4.669 (1.172)	loss nan (nan)	prob nan (nan)	GS 32.625 (32.625)	mem 42.676
Train: [76][175/750]	BT 0.113 (1.280)	DT 0.002 (1.138)	loss nan (nan)	prob nan (nan)	GS 47.359 (47.359)	mem 42.794
Train: [76][180/750]	BT 4.691 (1.274)	DT 4.557 (1.132)	loss nan (nan)	prob nan (nan)	GS 32.562 (32.562)	mem 42.700
Train: [76][185/750]	BT 0.128 (1.283)	DT 0.001 (1.142)	loss nan (nan)	prob nan (nan)	GS 31.219 (31.219)	mem 42.619
Train: [76][190/750]	BT 0.090 (1.252)	DT 0.002 (1.112)	loss nan (nan)	prob nan (nan)	GS 36.047 (36.047)	mem 42.766
Train: [76][195/750]	BT 0.078 (1.281)	DT 0.007 (1.142)	loss nan (nan)	prob nan (nan)	GS 29.875 (29.875)	mem 43.027
Train: [76][200/750]	BT 0.340 (1.254)	DT 0.005 (1.113)	loss nan (nan)	prob nan (nan)	GS 38.438 (38.438)	mem 43.273
Train: [76][205/750]	BT 0.162 (1.250)	DT 0.002 (1.109)	loss nan (nan)	prob nan (nan)	GS 35.688 (35.688)	mem 44.268
Train: [76][210/750]	BT 0.096 (1.247)	DT 0.003 (1.106)	loss nan (nan)	prob nan (nan)	GS 36.969 (36.969)	mem 45.944
Train: [76][215/750]	BT 0.123 (1.227)	DT 0.002 (1.085)	loss nan (nan)	prob nan (nan)	GS 29.125 (29.125)	mem 45.973
Train: [76][220/750]	BT 0.175 (1.251)	DT 0.008 (1.110)	loss nan (nan)	prob nan (nan)	GS 34.406 (34.406)	mem 42.896
Traceback (most recent call last):
  File "/home/shakir/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1120, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/usr/local/anaconda3/lib/python3.9/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/usr/local/anaconda3/lib/python3.9/multiprocessing/connection.py", line 262, in poll
    return self._poll(timeout)
  File "/usr/local/anaconda3/lib/python3.9/multiprocessing/connection.py", line 429, in _poll
    r = wait([self], timeout)
  File "/usr/local/anaconda3/lib/python3.9/multiprocessing/connection.py", line 936, in wait
    ready = selector.select(timeout)
  File "/usr/local/anaconda3/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/home/shakir/.local/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 1800103) is killed by signal: Killed. 

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/shakir/simplical_complices_gcc/train.py", line 951, in <module>
    main(args)
  File "/home/shakir/simplical_complices_gcc/train.py", line 835, in main
    loss = train_moco(
  File "/home/shakir/simplical_complices_gcc/train.py", line 447, in train_moco
    for idx, batch in enumerate(train_loader):
  File "/home/shakir/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/home/shakir/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1316, in _next_data
    idx, data = self._get_data()
  File "/home/shakir/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1282, in _get_data
    success, data = self._try_get_data()
  File "/home/shakir/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1133, in _try_get_data
    raise RuntimeError('DataLoader worker (pid(s) {}) exited unexpectedly'.format(pids_str)) from e
RuntimeError: DataLoader worker (pid(s) 1800103) exited unexpectedly
