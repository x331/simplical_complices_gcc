Graph(num_nodes=20, num_edges=292,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)})
cuda:1
Namespace(print_freq=5, tb_freq=1, save_freq=1, batch_size=32, num_workers=12, num_copies=6, num_samples=2000, epochs=100, optimizer='adam', learning_rate=0.005, lr_decay_epochs=[120, 160, 200], lr_decay_rate=0.0, beta1=0.9, beta2=0.999, weight_decay=1e-05, momentum=0.9, clip_norm=1.0, resume='', aug='1st', exp='Pretrain', dataset='dgl', model='gin', num_layer=5, readout='avg', set2set_lstm_layer=3, set2set_iter=6, norm=True, nce_k=16384, nce_t=0.07, rw_hops=256, subgraph_size=128, restart_prob=0.8, hidden_size=128, positional_embedding_size=32, max_node_freq=16, max_edge_freq=16, max_degree=512, freq_embedding_size=16, degree_embedding_size=16, model_path='saved', tb_path='tensorboard', load_path=None, moco=True, finetune=False, alpha=0.999, gpu=3, seed=0, fold_idx=0, cv=False, cvrun=-1, positional_embedding_multi=3, model_name='Pretrain_moco_True_dgl_gin_layer_5_lr_0.005_decay_1e-05_bsz_32_hid_128_samples_2000_nce_t_0.07_nce_k_16384_rw_hops_256_restart_prob_0.8_aug_1st_ft_False_deg_16_pos_32_multi_3_momentum_0.999', model_folder='saved/Pretrain_moco_True_dgl_gin_layer_5_lr_0.005_decay_1e-05_bsz_32_hid_128_samples_2000_nce_t_0.07_nce_k_16384_rw_hops_256_restart_prob_0.8_aug_1st_ft_False_deg_16_pos_32_multi_3_momentum_0.999', tb_folder='tensorboard/Pretrain_moco_True_dgl_gin_layer_5_lr_0.005_decay_1e-05_bsz_32_hid_128_samples_2000_nce_t_0.07_nce_k_16384_rw_hops_256_restart_prob_0.8_aug_1st_ft_False_deg_16_pos_32_multi_3_momentum_0.999')
Pretrain_moco_True_dgl_gin_layer_5_lr_0.005_decay_1e-05_bsz_32_hid_128_samples_2000_nce_t_0.07_nce_k_16384_rw_hops_256_restart_prob_0.8_aug_1st_ft_False_deg_16_pos_32_multi_3_momentum_0.999
Use GPU: 3 for training
setting random seeds
before construct dataset 10.654518127441406
load graph done
before construct dataloader 10.654518127441406
before training 10.654518127441406
using queue shape: (16384,128)
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [0][1/750]	BT 21.610 (21.610)	DT 20.590 (20.590)	loss 5.498 (5.498)	prob 5.005 (5.005)	GS 30.312 (30.312)	mem 46.608
Train: [0][5/750]	BT 0.040 (6.143)	DT 0.010 (5.894)	loss 9.609 (9.609)	prob 0.096 (0.096)	GS 32.953 (32.953)	mem 46.711
Train: [0][10/750]	BT 0.081 (3.112)	DT 0.008 (2.953)	loss 9.478 (9.478)	prob 0.232 (0.232)	GS 33.688 (33.688)	mem 46.731
Train: [0][15/750]	BT 0.728 (2.155)	DT 0.670 (2.027)	loss 9.360 (9.360)	prob 0.361 (0.361)	GS 31.203 (31.203)	mem 46.816
Train: [0][20/750]	BT 0.045 (2.224)	DT 0.002 (2.111)	loss 9.169 (9.169)	prob 0.569 (0.569)	GS 40.156 (40.156)	mem 47.431
Train: [0][25/750]	BT 0.055 (1.796)	DT 0.011 (1.693)	loss 9.066 (9.066)	prob 0.721 (0.721)	GS 38.062 (38.062)	mem 47.465
Train: [0][30/750]	BT 0.034 (1.969)	DT 0.001 (1.875)	loss 8.977 (8.977)	prob 0.809 (0.809)	GS 31.938 (31.938)	mem 47.651
Train: [0][35/750]	BT 0.060 (1.695)	DT 0.013 (1.608)	loss 8.930 (8.930)	prob 0.901 (0.901)	GS 36.266 (36.266)	mem 47.579
Train: [0][40/750]	BT 13.781 (1.850)	DT 13.663 (1.766)	loss 8.852 (8.852)	prob 1.008 (1.008)	GS 32.375 (32.375)	mem 48.121
Train: [0][45/750]	BT 0.075 (1.650)	DT 0.005 (1.570)	loss 8.679 (8.679)	prob 1.241 (1.241)	GS 30.625 (30.625)	mem 48.198
Train: [0][50/750]	BT 3.994 (1.568)	DT 3.969 (1.493)	loss 8.857 (8.857)	prob 1.088 (1.088)	GS 40.406 (40.406)	mem 47.397
Train: [0][55/750]	BT 0.028 (1.609)	DT 0.001 (1.539)	loss 8.658 (8.658)	prob 1.368 (1.368)	GS 29.844 (29.844)	mem 47.425
Train: [0][60/750]	BT 0.074 (1.481)	DT 0.009 (1.411)	loss 8.625 (8.625)	prob 1.481 (1.481)	GS 33.625 (33.625)	mem 47.490
Train: [0][65/750]	BT 0.026 (1.620)	DT 0.005 (1.553)	loss 8.605 (8.605)	prob 1.516 (1.516)	GS 31.609 (31.609)	mem 47.706
Train: [0][70/750]	BT 0.047 (1.507)	DT 0.009 (1.442)	loss 8.588 (8.588)	prob 1.557 (1.557)	GS 31.672 (31.672)	mem 47.716
Train: [0][75/750]	BT 0.069 (1.410)	DT 0.002 (1.346)	loss 8.593 (8.593)	prob 1.623 (1.623)	GS 33.469 (33.469)	mem 47.720
Train: [0][80/750]	BT 0.037 (1.503)	DT 0.006 (1.441)	loss 8.506 (8.506)	prob 1.794 (1.794)	GS 35.562 (35.562)	mem 47.723
Train: [0][85/750]	BT 0.038 (1.418)	DT 0.003 (1.357)	loss 8.598 (8.598)	prob 1.866 (1.866)	GS 41.266 (41.266)	mem 47.829
Train: [0][90/750]	BT 0.031 (1.502)	DT 0.001 (1.442)	loss 8.754 (8.754)	prob 1.583 (1.583)	GS 35.172 (35.172)	mem 47.942
Train: [0][95/750]	BT 0.033 (1.425)	DT 0.001 (1.367)	loss 8.754 (8.754)	prob 1.666 (1.666)	GS 28.891 (28.891)	mem 47.950
Train: [0][100/750]	BT 14.874 (1.503)	DT 14.829 (1.447)	loss 8.775 (8.775)	prob 1.577 (1.577)	GS 34.656 (34.656)	mem 47.550
Train: [0][105/750]	BT 0.050 (1.433)	DT 0.009 (1.378)	loss 8.682 (8.682)	prob 1.816 (1.816)	GS 29.844 (29.844)	mem 47.553
Train: [0][110/750]	BT 0.056 (1.370)	DT 0.007 (1.316)	loss 8.659 (8.659)	prob 1.855 (1.855)	GS 34.016 (34.016)	mem 47.557
Train: [0][115/750]	BT 0.042 (1.417)	DT 0.003 (1.363)	loss 8.643 (8.643)	prob 2.042 (2.042)	GS 36.359 (36.359)	mem 47.655
Train: [0][120/750]	BT 0.062 (1.359)	DT 0.004 (1.306)	loss 8.756 (8.756)	prob 1.939 (1.939)	GS 37.906 (37.906)	mem 47.659
Train: [0][125/750]	BT 0.043 (1.409)	DT 0.010 (1.354)	loss 8.866 (8.866)	prob 1.757 (1.757)	GS 33.188 (33.188)	mem 47.772
Train: [0][130/750]	BT 0.052 (1.356)	DT 0.003 (1.302)	loss 8.927 (8.927)	prob 1.601 (1.601)	GS 36.328 (36.328)	mem 47.777
Train: [0][135/750]	BT 0.038 (1.307)	DT 0.001 (1.254)	loss 8.851 (8.851)	prob 1.873 (1.873)	GS 31.641 (31.641)	mem 47.886
Train: [0][140/750]	BT 0.057 (1.347)	DT 0.007 (1.295)	loss 8.832 (8.832)	prob 1.924 (1.924)	GS 29.047 (29.047)	mem 47.874
Train: [0][145/750]	BT 0.045 (1.302)	DT 0.001 (1.250)	loss 8.864 (8.864)	prob 1.919 (1.919)	GS 32.781 (32.781)	mem 47.874
Train: [0][150/750]	BT 0.031 (1.343)	DT 0.001 (1.291)	loss 8.957 (8.957)	prob 1.802 (1.802)	GS 36.547 (36.547)	mem 47.898
Train: [0][155/750]	BT 0.081 (1.301)	DT 0.004 (1.250)	loss 8.778 (8.778)	prob 2.038 (2.038)	GS 26.984 (26.984)	mem 47.947
Train: [0][160/750]	BT 10.883 (1.330)	DT 10.842 (1.279)	loss 8.978 (8.978)	prob 1.703 (1.703)	GS 31.297 (31.297)	mem 46.887
Train: [0][165/750]	BT 0.087 (1.291)	DT 0.011 (1.240)	loss 9.067 (9.067)	prob 1.901 (1.901)	GS 33.359 (33.359)	mem 46.617
Train: [0][170/750]	BT 0.034 (1.254)	DT 0.001 (1.204)	loss 8.945 (8.945)	prob 1.881 (1.881)	GS 35.500 (35.500)	mem 46.618
Train: [0][175/750]	BT 0.091 (1.285)	DT 0.002 (1.234)	loss 8.923 (8.923)	prob 2.056 (2.056)	GS 35.328 (35.328)	mem 46.776
Train: [0][180/750]	BT 0.066 (1.251)	DT 0.010 (1.200)	loss 9.032 (9.032)	prob 1.830 (1.830)	GS 31.359 (31.359)	mem 46.639
Train: [0][185/750]	BT 0.085 (1.279)	DT 0.006 (1.228)	loss 9.027 (9.027)	prob 1.935 (1.935)	GS 33.688 (33.688)	mem 46.596
Train: [0][190/750]	BT 0.046 (1.246)	DT 0.003 (1.196)	loss 9.203 (9.203)	prob 1.708 (1.708)	GS 33.219 (33.219)	mem 46.600
Train: [0][195/750]	BT 0.029 (1.216)	DT 0.003 (1.166)	loss 9.020 (9.020)	prob 2.105 (2.105)	GS 36.766 (36.766)	mem 46.692
Train: [0][200/750]	BT 0.111 (1.249)	DT 0.002 (1.198)	loss 9.016 (9.016)	prob 2.035 (2.035)	GS 37.344 (37.344)	mem 46.697
Train: [0][205/750]	BT 0.075 (1.220)	DT 0.007 (1.169)	loss 9.192 (9.192)	prob 1.947 (1.947)	GS 26.453 (26.453)	mem 46.732
Train: [0][210/750]	BT 0.042 (1.251)	DT 0.003 (1.200)	loss 9.068 (9.068)	prob 2.019 (2.019)	GS 32.141 (32.141)	mem 45.970
Train: [0][215/750]	BT 0.077 (1.224)	DT 0.011 (1.173)	loss 9.116 (9.116)	prob 1.946 (1.946)	GS 30.719 (30.719)	mem 45.864
Train: [0][220/750]	BT 11.671 (1.250)	DT 11.637 (1.200)	loss 9.142 (9.142)	prob 1.990 (1.990)	GS 30.344 (30.344)	mem 46.016
Train: [0][225/750]	BT 0.044 (1.223)	DT 0.003 (1.173)	loss 9.208 (9.208)	prob 1.925 (1.925)	GS 36.812 (36.812)	mem 46.054
Train: [0][230/750]	BT 0.123 (1.202)	DT 0.009 (1.151)	loss 9.314 (9.314)	prob 1.764 (1.764)	GS 31.812 (31.812)	mem 45.983
Train: [0][235/750]	BT 0.069 (1.219)	DT 0.001 (1.168)	loss 9.397 (9.397)	prob 1.813 (1.813)	GS 28.188 (28.188)	mem 46.073
Train: [0][240/750]	BT 0.036 (1.208)	DT 0.002 (1.157)	loss 9.466 (9.466)	prob 1.736 (1.736)	GS 33.219 (33.219)	mem 46.025
Train: [0][245/750]	BT 0.042 (1.231)	DT 0.002 (1.181)	loss 9.296 (9.296)	prob 2.025 (2.025)	GS 31.562 (31.562)	mem 45.987
Train: [0][250/750]	BT 1.661 (1.214)	DT 1.624 (1.164)	loss 9.192 (9.192)	prob 2.172 (2.172)	GS 33.547 (33.547)	mem 45.967
Train: [0][255/750]	BT 0.031 (1.191)	DT 0.001 (1.141)	loss 9.472 (9.472)	prob 1.675 (1.675)	GS 31.891 (31.891)	mem 45.968
Train: [0][260/750]	BT 0.085 (1.205)	DT 0.008 (1.154)	loss 9.419 (9.419)	prob 1.626 (1.626)	GS 36.531 (36.531)	mem 46.055
Train: [0][265/750]	BT 0.051 (1.193)	DT 0.010 (1.143)	loss 9.637 (9.637)	prob 1.468 (1.468)	GS 32.359 (32.359)	mem 46.037
Train: [0][270/750]	BT 0.025 (1.214)	DT 0.001 (1.164)	loss 9.366 (9.366)	prob 1.671 (1.671)	GS 35.797 (35.797)	mem 45.947
Train: [0][275/750]	BT 0.034 (1.201)	DT 0.002 (1.151)	loss 9.494 (9.494)	prob 1.845 (1.845)	GS 35.938 (35.938)	mem 46.037
Train: [0][280/750]	BT 11.310 (1.221)	DT 11.287 (1.171)	loss 9.478 (9.478)	prob 1.517 (1.517)	GS 31.531 (31.531)	mem 45.955
Train: [0][285/750]	BT 0.027 (1.200)	DT 0.001 (1.151)	loss 9.429 (9.429)	prob 1.999 (1.999)	GS 27.062 (27.062)	mem 45.955
Train: [0][290/750]	BT 0.039 (1.183)	DT 0.001 (1.134)	loss 9.541 (9.541)	prob 1.725 (1.725)	GS 36.031 (36.031)	mem 45.959
Train: [0][295/750]	BT 0.042 (1.196)	DT 0.001 (1.147)	loss 9.383 (9.383)	prob 2.148 (2.148)	GS 33.531 (33.531)	mem 45.971
Train: [0][300/750]	BT 0.050 (1.182)	DT 0.003 (1.133)	loss 9.522 (9.522)	prob 1.942 (1.942)	GS 35.625 (35.625)	mem 45.910
Train: [0][305/750]	BT 0.024 (1.200)	DT 0.001 (1.152)	loss 9.718 (9.718)	prob 1.694 (1.694)	GS 29.031 (29.031)	mem 45.938
Train: [0][310/750]	BT 1.175 (1.185)	DT 1.143 (1.137)	loss 9.789 (9.789)	prob 1.569 (1.569)	GS 35.719 (35.719)	mem 44.853
Train: [0][315/750]	BT 0.034 (1.167)	DT 0.003 (1.119)	loss 9.444 (9.444)	prob 1.873 (1.873)	GS 28.250 (28.250)	mem 44.758
Train: [0][320/750]	BT 0.060 (1.187)	DT 0.002 (1.139)	loss 9.478 (9.478)	prob 1.890 (1.890)	GS 33.281 (33.281)	mem 44.869
Train: [0][325/750]	BT 0.037 (1.178)	DT 0.012 (1.130)	loss 9.485 (9.485)	prob 1.987 (1.987)	GS 33.094 (33.094)	mem 44.771
Train: [0][330/750]	BT 0.032 (1.197)	DT 0.001 (1.149)	loss 9.748 (9.748)	prob 1.510 (1.510)	GS 31.734 (31.734)	mem 44.661
Train: [0][335/750]	BT 0.093 (1.180)	DT 0.013 (1.132)	loss 9.740 (9.740)	prob 1.638 (1.638)	GS 32.594 (32.594)	mem 44.663
Train: [0][340/750]	BT 15.227 (1.208)	DT 15.201 (1.160)	loss 9.524 (9.524)	prob 1.601 (1.601)	GS 33.750 (33.750)	mem 44.582
Train: [0][345/750]	BT 0.034 (1.191)	DT 0.003 (1.144)	loss 9.893 (9.893)	prob 1.785 (1.785)	GS 28.000 (28.000)	mem 44.581
Train: [0][350/750]	BT 0.037 (1.174)	DT 0.003 (1.127)	loss 9.800 (9.800)	prob 1.496 (1.496)	GS 29.969 (29.969)	mem 44.582
Train: [0][355/750]	BT 0.034 (1.193)	DT 0.002 (1.145)	loss 9.848 (9.848)	prob 1.380 (1.380)	GS 39.312 (39.312)	mem 44.852
Train: [0][360/750]	BT 0.032 (1.177)	DT 0.005 (1.130)	loss 9.734 (9.734)	prob 1.199 (1.199)	GS 29.391 (29.391)	mem 44.727
Train: [0][365/750]	BT 0.063 (1.201)	DT 0.018 (1.154)	loss 9.401 (9.401)	prob 2.241 (2.241)	GS 28.781 (28.781)	mem 44.616
Train: [0][370/750]	BT 0.050 (1.185)	DT 0.010 (1.138)	loss 9.872 (9.872)	prob 1.467 (1.467)	GS 32.109 (32.109)	mem 44.615
Train: [0][375/750]	BT 0.035 (1.170)	DT 0.003 (1.123)	loss 9.774 (9.774)	prob 1.741 (1.741)	GS 28.594 (28.594)	mem 44.615
Train: [0][380/750]	BT 0.048 (1.186)	DT 0.014 (1.140)	loss 9.732 (9.732)	prob 1.731 (1.731)	GS 33.297 (33.297)	mem 44.747
Train: [0][385/750]	BT 0.128 (1.172)	DT 0.009 (1.125)	loss 10.165 (10.165)	prob 1.439 (1.439)	GS 27.188 (27.188)	mem 44.923
Train: [0][390/750]	BT 0.032 (1.184)	DT 0.010 (1.137)	loss 9.768 (9.768)	prob 1.785 (1.785)	GS 29.625 (29.625)	mem 44.730
Train: [0][395/750]	BT 0.038 (1.170)	DT 0.002 (1.123)	loss 10.005 (10.005)	prob 1.817 (1.817)	GS 29.078 (29.078)	mem 44.731
Train: [0][400/750]	BT 12.710 (1.187)	DT 12.677 (1.141)	loss 10.373 (10.373)	prob 0.851 (0.851)	GS 33.344 (33.344)	mem 44.742
Train: [0][405/750]	BT 0.040 (1.173)	DT 0.002 (1.126)	loss 10.042 (10.042)	prob 1.668 (1.668)	GS 30.688 (30.688)	mem 44.742
Train: [0][410/750]	BT 0.023 (1.159)	DT 0.001 (1.113)	loss 9.969 (9.969)	prob 1.655 (1.655)	GS 28.484 (28.484)	mem 44.743
Train: [0][415/750]	BT 0.084 (1.173)	DT 0.010 (1.127)	loss 9.514 (9.514)	prob 2.126 (2.126)	GS 30.109 (30.109)	mem 44.782
Train: [0][420/750]	BT 0.058 (1.160)	DT 0.014 (1.113)	loss 9.771 (9.771)	prob 1.644 (1.644)	GS 32.047 (32.047)	mem 44.767
Train: [0][425/750]	BT 0.030 (1.185)	DT 0.001 (1.138)	loss 9.885 (9.885)	prob 1.435 (1.435)	GS 34.500 (34.500)	mem 44.908
Train: [0][430/750]	BT 0.069 (1.171)	DT 0.001 (1.125)	loss 9.946 (9.946)	prob 1.281 (1.281)	GS 35.281 (35.281)	mem 44.871
Train: [0][435/750]	BT 0.034 (1.158)	DT 0.002 (1.112)	loss 10.269 (10.269)	prob 1.459 (1.459)	GS 30.969 (30.969)	mem 44.873
Train: [0][440/750]	BT 0.031 (1.176)	DT 0.001 (1.130)	loss 9.872 (9.872)	prob 1.424 (1.424)	GS 33.469 (33.469)	mem 44.947
Train: [0][445/750]	BT 0.057 (1.163)	DT 0.006 (1.118)	loss 10.240 (10.240)	prob 1.512 (1.512)	GS 32.594 (32.594)	mem 44.881
Train: [0][450/750]	BT 0.032 (1.180)	DT 0.002 (1.134)	loss 9.639 (9.639)	prob 1.803 (1.803)	GS 32.859 (32.859)	mem 44.805
Train: [0][455/750]	BT 0.037 (1.168)	DT 0.001 (1.122)	loss 10.237 (10.237)	prob 1.088 (1.088)	GS 30.000 (30.000)	mem 44.804
Train: [0][460/750]	BT 12.903 (1.183)	DT 12.858 (1.137)	loss 10.300 (10.300)	prob 1.129 (1.129)	GS 33.766 (33.766)	mem 44.867
Train: [0][465/750]	BT 0.027 (1.171)	DT 0.001 (1.125)	loss 10.881 (10.881)	prob 0.512 (0.512)	GS 30.734 (30.734)	mem 44.815
Train: [0][470/750]	BT 0.024 (1.159)	DT 0.001 (1.113)	loss 10.294 (10.294)	prob 0.907 (0.907)	GS 35.641 (35.641)	mem 44.860
Train: [0][475/750]	BT 0.035 (1.174)	DT 0.001 (1.129)	loss 10.641 (10.641)	prob 0.850 (0.850)	GS 36.203 (36.203)	mem 45.229
Train: [0][480/750]	BT 0.043 (1.163)	DT 0.001 (1.117)	loss 10.093 (10.093)	prob 1.164 (1.164)	GS 32.016 (32.016)	mem 45.146
Train: [0][485/750]	BT 0.030 (1.177)	DT 0.001 (1.132)	loss 10.864 (10.864)	prob 0.250 (0.250)	GS 31.375 (31.375)	mem 44.909
Train: [0][490/750]	BT 0.031 (1.166)	DT 0.002 (1.121)	loss 10.343 (10.343)	prob 0.697 (0.697)	GS 35.875 (35.875)	mem 44.815
Train: [0][495/750]	BT 0.051 (1.155)	DT 0.005 (1.109)	loss 10.244 (10.244)	prob 0.874 (0.874)	GS 30.781 (30.781)	mem 44.816
Train: [0][500/750]	BT 0.058 (1.169)	DT 0.020 (1.124)	loss 10.487 (10.487)	prob 0.495 (0.495)	GS 35.281 (35.281)	mem 44.821
Train: [0][505/750]	BT 0.053 (1.158)	DT 0.009 (1.113)	loss 9.891 (9.891)	prob 0.816 (0.816)	GS 29.859 (29.859)	mem 44.863
Train: [0][510/750]	BT 0.029 (1.175)	DT 0.001 (1.130)	loss 10.203 (10.203)	prob 0.546 (0.546)	GS 30.812 (30.812)	mem 44.820
Train: [0][515/750]	BT 0.068 (1.164)	DT 0.018 (1.119)	loss 10.431 (10.431)	prob 0.378 (0.378)	GS 43.531 (43.531)	mem 44.821
Train: [0][520/750]	BT 14.117 (1.181)	DT 14.084 (1.135)	loss 10.164 (10.164)	prob 0.505 (0.505)	GS 30.953 (30.953)	mem 45.497
Train: [0][525/750]	BT 0.053 (1.170)	DT 0.002 (1.125)	loss 10.236 (10.236)	prob 0.935 (0.935)	GS 34.359 (34.359)	mem 45.512
Train: [0][530/750]	BT 0.043 (1.159)	DT 0.002 (1.114)	loss 10.101 (10.101)	prob 0.364 (0.364)	GS 33.594 (33.594)	mem 45.708
Train: [0][535/750]	BT 0.048 (1.171)	DT 0.002 (1.125)	loss 10.256 (10.256)	prob -0.094 (-0.094)	GS 33.953 (33.953)	mem 46.252
Train: [0][540/750]	BT 0.081 (1.160)	DT 0.003 (1.115)	loss 10.479 (10.479)	prob -0.205 (-0.205)	GS 36.047 (36.047)	mem 46.286
Train: [0][545/750]	BT 0.028 (1.176)	DT 0.001 (1.131)	loss 10.421 (10.421)	prob 0.167 (0.167)	GS 30.172 (30.172)	mem 46.298
Train: [0][550/750]	BT 0.032 (1.166)	DT 0.002 (1.121)	loss 10.103 (10.103)	prob 0.552 (0.552)	GS 30.500 (30.500)	mem 46.299
Train: [0][555/750]	BT 0.072 (1.156)	DT 0.007 (1.111)	loss 9.996 (9.996)	prob 0.899 (0.899)	GS 32.703 (32.703)	mem 46.298
Train: [0][560/750]	BT 0.043 (1.167)	DT 0.004 (1.122)	loss 10.395 (10.395)	prob 0.433 (0.433)	GS 37.344 (37.344)	mem 46.253
Train: [0][565/750]	BT 0.062 (1.157)	DT 0.017 (1.112)	loss 9.818 (9.818)	prob 1.110 (1.110)	GS 34.109 (34.109)	mem 46.254
Train: [0][570/750]	BT 0.057 (1.170)	DT 0.009 (1.125)	loss 10.076 (10.076)	prob 0.135 (0.135)	GS 31.297 (31.297)	mem 46.106
Train: [0][575/750]	BT 0.035 (1.160)	DT 0.001 (1.115)	loss 10.289 (10.289)	prob 0.549 (0.549)	GS 35.422 (35.422)	mem 46.108
Train: [0][580/750]	BT 11.245 (1.170)	DT 11.183 (1.125)	loss 10.579 (10.579)	prob -0.277 (-0.277)	GS 32.641 (32.641)	mem 46.067
Train: [0][585/750]	BT 0.162 (1.160)	DT 0.004 (1.115)	loss 10.360 (10.360)	prob 0.399 (0.399)	GS 28.422 (28.422)	mem 46.066
Train: [0][590/750]	BT 0.907 (1.153)	DT 0.876 (1.107)	loss 11.088 (11.088)	prob -0.834 (-0.834)	GS 36.375 (36.375)	mem 46.030
Train: [0][595/750]	BT 0.031 (1.160)	DT 0.001 (1.115)	loss 9.993 (9.993)	prob 0.514 (0.514)	GS 30.609 (30.609)	mem 46.096
Train: [0][600/750]	BT 1.620 (1.154)	DT 1.586 (1.109)	loss 10.601 (10.601)	prob -0.249 (-0.249)	GS 38.031 (38.031)	mem 46.046
Train: [0][605/750]	BT 0.056 (1.166)	DT 0.007 (1.121)	loss 10.204 (10.204)	prob 0.421 (0.421)	GS 27.750 (27.750)	mem 46.147
Train: [0][610/750]	BT 0.049 (1.157)	DT 0.001 (1.111)	loss 10.511 (10.511)	prob -0.172 (-0.172)	GS 38.922 (38.922)	mem 46.023
Train: [0][615/750]	BT 0.082 (1.152)	DT 0.016 (1.107)	loss 10.358 (10.358)	prob 0.133 (0.133)	GS 32.609 (32.609)	mem 46.305
Train: [0][620/750]	BT 0.034 (1.155)	DT 0.002 (1.110)	loss 10.372 (10.372)	prob 0.061 (0.061)	GS 32.953 (32.953)	mem 46.093
Train: [0][625/750]	BT 0.101 (1.155)	DT 0.003 (1.109)	loss 10.237 (10.237)	prob 0.469 (0.469)	GS 29.719 (29.719)	mem 46.185
Train: [0][630/750]	BT 0.070 (1.155)	DT 0.009 (1.110)	loss 10.129 (10.129)	prob 0.338 (0.338)	GS 33.234 (33.234)	mem 45.937
Train: [0][635/750]	BT 0.083 (1.147)	DT 0.027 (1.101)	loss 9.899 (9.899)	prob 1.226 (1.226)	GS 29.641 (29.641)	mem 45.882
Train: [0][640/750]	BT 3.012 (1.159)	DT 2.870 (1.113)	loss 10.198 (10.198)	prob 0.332 (0.332)	GS 34.875 (34.875)	mem 45.994
Train: [0][645/750]	BT 0.049 (1.150)	DT 0.001 (1.104)	loss 10.288 (10.288)	prob 0.354 (0.354)	GS 36.078 (36.078)	mem 45.935
Train: [0][650/750]	BT 0.060 (1.159)	DT 0.003 (1.114)	loss 10.388 (10.388)	prob -0.401 (-0.401)	GS 33.594 (33.594)	mem 45.956
Train: [0][655/750]	BT 0.034 (1.153)	DT 0.002 (1.107)	loss 10.421 (10.421)	prob -0.115 (-0.115)	GS 31.203 (31.203)	mem 45.967
Train: [0][660/750]	BT 12.529 (1.163)	DT 12.502 (1.118)	loss 10.206 (10.206)	prob 0.501 (0.501)	GS 30.922 (30.922)	mem 46.025
Train: [0][665/750]	BT 0.031 (1.161)	DT 0.001 (1.116)	loss 10.606 (10.606)	prob 0.184 (0.184)	GS 30.469 (30.469)	mem 45.964
Train: [0][670/750]	BT 0.060 (1.153)	DT 0.005 (1.107)	loss 10.152 (10.152)	prob 0.051 (0.051)	GS 33.828 (33.828)	mem 46.034
Train: [0][675/750]	BT 0.041 (1.163)	DT 0.002 (1.118)	loss 10.456 (10.456)	prob -0.130 (-0.130)	GS 29.172 (29.172)	mem 46.278
Train: [0][680/750]	BT 0.026 (1.159)	DT 0.001 (1.113)	loss 10.703 (10.703)	prob -0.188 (-0.188)	GS 38.750 (38.750)	mem 46.017
Train: [0][685/750]	BT 0.036 (1.165)	DT 0.004 (1.119)	loss 10.166 (10.166)	prob 0.105 (0.105)	GS 26.547 (26.547)	mem 46.056
Train: [0][690/750]	BT 0.025 (1.159)	DT 0.001 (1.113)	loss 10.357 (10.357)	prob -0.128 (-0.128)	GS 30.422 (30.422)	mem 46.002
Train: [0][695/750]	BT 0.054 (1.151)	DT 0.006 (1.105)	loss 10.173 (10.173)	prob 0.354 (0.354)	GS 36.219 (36.219)	mem 46.004
Train: [0][700/750]	BT 7.495 (1.163)	DT 7.456 (1.118)	loss 10.530 (10.530)	prob -0.201 (-0.201)	GS 33.078 (33.078)	mem 45.897
Train: [0][705/750]	BT 0.025 (1.155)	DT 0.001 (1.110)	loss 10.385 (10.385)	prob 0.174 (0.174)	GS 31.016 (31.016)	mem 45.898
Train: [0][710/750]	BT 0.022 (1.155)	DT 0.001 (1.110)	loss 10.270 (10.270)	prob 0.255 (0.255)	GS 34.500 (34.500)	mem 45.968
Train: [0][715/750]	BT 0.031 (1.155)	DT 0.002 (1.110)	loss 10.324 (10.324)	prob 0.386 (0.386)	GS 32.359 (32.359)	mem 45.995
Train: [0][720/750]	BT 4.459 (1.153)	DT 4.427 (1.108)	loss 10.307 (10.307)	prob 0.127 (0.127)	GS 34.219 (34.219)	mem 46.043
Train: [0][725/750]	BT 0.026 (1.157)	DT 0.001 (1.112)	loss 10.530 (10.530)	prob 0.657 (0.657)	GS 28.797 (28.797)	mem 45.810
Train: [0][730/750]	BT 0.033 (1.149)	DT 0.001 (1.104)	loss 10.883 (10.883)	prob -0.381 (-0.381)	GS 32.047 (32.047)	mem 45.814
Train: [0][735/750]	BT 0.030 (1.147)	DT 0.002 (1.102)	loss 10.477 (10.477)	prob 0.497 (0.497)	GS 30.125 (30.125)	mem 45.480
Train: [0][740/750]	BT 0.024 (1.144)	DT 0.001 (1.099)	loss 10.105 (10.105)	prob 0.208 (0.208)	GS 32.797 (32.797)	mem 20.430
Train: [0][745/750]	BT 0.034 (1.141)	DT 0.001 (1.096)	loss 10.799 (10.799)	prob -0.667 (-0.667)	GS 36.500 (36.500)	mem 13.706
Train: [0][750/750]	BT 0.035 (1.134)	DT 0.007 (1.089)	loss 10.400 (10.400)	prob -0.011 (-0.011)	GS 33.562 (33.562)	mem 13.706
Train: [0][755/750]	BT 0.029 (1.126)	DT 0.001 (1.082)	loss 9.718 (9.718)	prob 1.445 (1.445)	GS 24.344 (24.344)	mem 13.706
epoch 0, total time 853.49
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [1][1/750]	BT 24.680 (24.680)	DT 24.634 (24.634)	loss 10.230 (10.230)	prob 0.641 (0.641)	GS 33.109 (33.109)	mem 44.752
Train: [1][5/750]	BT 0.088 (4.974)	DT 0.007 (4.929)	loss 10.742 (10.742)	prob 0.554 (0.554)	GS 35.922 (35.922)	mem 44.950
Train: [1][10/750]	BT 0.065 (2.606)	DT 0.006 (2.547)	loss 10.792 (10.792)	prob 0.456 (0.456)	GS 31.344 (31.344)	mem 44.700
Train: [1][15/750]	BT 0.034 (2.436)	DT 0.001 (2.377)	loss 10.449 (10.449)	prob 0.135 (0.135)	GS 33.859 (33.859)	mem 44.904
Train: [1][20/750]	BT 0.052 (2.000)	DT 0.003 (1.946)	loss 10.137 (10.137)	prob -0.049 (-0.049)	GS 34.656 (34.656)	mem 44.880
Train: [1][25/750]	BT 5.524 (1.830)	DT 5.493 (1.777)	loss 10.514 (10.514)	prob -0.034 (-0.034)	GS 26.359 (26.359)	mem 44.971
Train: [1][30/750]	BT 0.053 (1.758)	DT 0.001 (1.704)	loss 10.407 (10.407)	prob -0.188 (-0.188)	GS 29.875 (29.875)	mem 45.085
Train: [1][35/750]	BT 0.038 (1.518)	DT 0.003 (1.461)	loss 10.607 (10.607)	prob -0.271 (-0.271)	GS 29.953 (29.953)	mem 45.174
Train: [1][40/750]	BT 3.103 (1.601)	DT 3.069 (1.547)	loss 10.342 (10.342)	prob -0.181 (-0.181)	GS 29.641 (29.641)	mem 45.076
Train: [1][45/750]	BT 0.133 (1.457)	DT 0.007 (1.400)	loss 10.282 (10.282)	prob -0.233 (-0.233)	GS 30.562 (30.562)	mem 45.170
Train: [1][50/750]	BT 10.242 (1.526)	DT 10.210 (1.470)	loss 10.735 (10.735)	prob -0.357 (-0.357)	GS 33.656 (33.656)	mem 45.183
Train: [1][55/750]	BT 0.037 (1.436)	DT 0.001 (1.381)	loss 10.497 (10.497)	prob -0.405 (-0.405)	GS 30.266 (30.266)	mem 45.112
Train: [1][60/750]	BT 0.116 (1.399)	DT 0.042 (1.345)	loss 10.308 (10.308)	prob 0.164 (0.164)	GS 35.062 (35.062)	mem 45.110
Train: [1][65/750]	BT 0.061 (1.401)	DT 0.005 (1.347)	loss 10.518 (10.518)	prob -0.288 (-0.288)	GS 31.172 (31.172)	mem 45.185
Train: [1][70/750]	BT 3.607 (1.401)	DT 3.571 (1.348)	loss 10.250 (10.250)	prob -0.052 (-0.052)	GS 34.703 (34.703)	mem 45.177
Train: [1][75/750]	BT 0.104 (1.333)	DT 0.030 (1.280)	loss 10.252 (10.252)	prob 0.014 (0.014)	GS 28.406 (28.406)	mem 45.196
Train: [1][80/750]	BT 0.077 (1.300)	DT 0.006 (1.247)	loss 10.248 (10.248)	prob -0.161 (-0.161)	GS 39.141 (39.141)	mem 45.207
Train: [1][85/750]	BT 9.133 (1.379)	DT 9.015 (1.326)	loss 10.469 (10.469)	prob -0.321 (-0.321)	GS 46.891 (46.891)	mem 45.253
Train: [1][90/750]	BT 0.554 (1.311)	DT 0.515 (1.259)	loss 9.882 (9.882)	prob 0.323 (0.323)	GS 33.531 (33.531)	mem 45.198
Train: [1][95/750]	BT 0.074 (1.291)	DT 0.005 (1.237)	loss 9.950 (9.950)	prob -0.074 (-0.074)	GS 31.875 (31.875)	mem 45.114
Train: [1][100/750]	BT 0.033 (1.333)	DT 0.002 (1.280)	loss 10.361 (10.361)	prob -0.001 (-0.001)	GS 36.609 (36.609)	mem 45.178
Train: [1][105/750]	BT 0.045 (1.273)	DT 0.002 (1.220)	loss 10.254 (10.254)	prob 0.793 (0.793)	GS 25.156 (25.156)	mem 45.176
Train: [1][110/750]	BT 0.076 (1.288)	DT 0.006 (1.234)	loss 10.069 (10.069)	prob 0.451 (0.451)	GS 34.266 (34.266)	mem 45.703
Train: [1][115/750]	BT 0.106 (1.289)	DT 0.015 (1.233)	loss 9.885 (9.885)	prob 0.414 (0.414)	GS 32.281 (32.281)	mem 45.305
Train: [1][120/750]	BT 0.032 (1.238)	DT 0.007 (1.182)	loss 10.544 (10.544)	prob 0.152 (0.152)	GS 31.281 (31.281)	mem 45.220
Train: [1][125/750]	BT 0.030 (1.265)	DT 0.001 (1.210)	loss 9.957 (9.957)	prob 0.481 (0.481)	GS 35.641 (35.641)	mem 45.256
Train: [1][130/750]	BT 0.368 (1.221)	DT 0.322 (1.166)	loss 9.765 (9.765)	prob 0.553 (0.553)	GS 33.750 (33.750)	mem 45.257
Train: [1][135/750]	BT 0.079 (1.238)	DT 0.010 (1.183)	loss 10.345 (10.345)	prob 0.615 (0.615)	GS 26.797 (26.797)	mem 45.426
Train: [1][140/750]	BT 0.064 (1.203)	DT 0.007 (1.149)	loss 10.455 (10.455)	prob 0.267 (0.267)	GS 31.812 (31.812)	mem 45.422
Train: [1][145/750]	BT 0.067 (1.198)	DT 0.005 (1.143)	loss 10.369 (10.369)	prob 0.287 (0.287)	GS 29.328 (29.328)	mem 45.368
Train: [1][150/750]	BT 0.032 (1.211)	DT 0.002 (1.156)	loss 10.602 (10.602)	prob -0.409 (-0.409)	GS 33.781 (33.781)	mem 45.351
Train: [1][155/750]	BT 0.066 (1.202)	DT 0.002 (1.147)	loss 10.470 (10.470)	prob -0.681 (-0.681)	GS 35.188 (35.188)	mem 45.453
Train: [1][160/750]	BT 0.026 (1.235)	DT 0.001 (1.182)	loss 10.408 (10.408)	prob -0.334 (-0.334)	GS 35.078 (35.078)	mem 45.420
Train: [1][165/750]	BT 0.039 (1.209)	DT 0.014 (1.155)	loss 10.220 (10.220)	prob 0.021 (0.021)	GS 32.938 (32.938)	mem 45.451
Train: [1][170/750]	BT 10.062 (1.233)	DT 10.012 (1.180)	loss 10.129 (10.129)	prob 0.155 (0.155)	GS 29.469 (29.469)	mem 45.444
Train: [1][175/750]	BT 0.031 (1.200)	DT 0.002 (1.147)	loss 10.483 (10.483)	prob -0.180 (-0.180)	GS 31.922 (31.922)	mem 45.446
Train: [1][180/750]	BT 0.131 (1.195)	DT 0.001 (1.142)	loss 10.026 (10.026)	prob 0.093 (0.093)	GS 33.344 (33.344)	mem 45.435
Train: [1][185/750]	BT 0.040 (1.212)	DT 0.002 (1.160)	loss 10.188 (10.188)	prob 0.058 (0.058)	GS 30.922 (30.922)	mem 45.519
Train: [1][190/750]	BT 0.038 (1.225)	DT 0.001 (1.173)	loss 10.165 (10.165)	prob 0.048 (0.048)	GS 34.578 (34.578)	mem 45.453
Train: [1][195/750]	BT 0.056 (1.212)	DT 0.001 (1.160)	loss 10.327 (10.327)	prob 0.100 (0.100)	GS 31.625 (31.625)	mem 45.503
Train: [1][200/750]	BT 6.664 (1.216)	DT 6.590 (1.164)	loss 9.753 (9.753)	prob 0.710 (0.710)	GS 31.922 (31.922)	mem 45.589
Train: [1][205/750]	BT 0.063 (1.204)	DT 0.012 (1.152)	loss 10.271 (10.271)	prob 0.703 (0.703)	GS 31.984 (31.984)	mem 45.756
Train: [1][210/750]	BT 0.029 (1.192)	DT 0.001 (1.140)	loss 10.365 (10.365)	prob 0.433 (0.433)	GS 33.656 (33.656)	mem 45.910
Train: [1][215/750]	BT 0.079 (1.185)	DT 0.014 (1.133)	loss 10.193 (10.193)	prob 1.020 (1.020)	GS 30.016 (30.016)	mem 45.776
Train: [1][220/750]	BT 0.073 (1.197)	DT 0.001 (1.145)	loss 10.254 (10.254)	prob 0.610 (0.610)	GS 33.203 (33.203)	mem 45.777
Train: [1][225/750]	BT 0.038 (1.197)	DT 0.002 (1.146)	loss 10.029 (10.029)	prob 0.572 (0.572)	GS 31.547 (31.547)	mem 45.734
Train: [1][230/750]	BT 7.678 (1.205)	DT 7.642 (1.154)	loss 10.212 (10.212)	prob 0.167 (0.167)	GS 34.484 (34.484)	mem 45.720
Train: [1][235/750]	BT 0.055 (1.181)	DT 0.014 (1.129)	loss 10.017 (10.017)	prob 0.152 (0.152)	GS 30.203 (30.203)	mem 45.721
Train: [1][240/750]	BT 0.104 (1.183)	DT 0.011 (1.132)	loss 10.526 (10.526)	prob -0.191 (-0.191)	GS 30.125 (30.125)	mem 45.773
Train: [1][245/750]	BT 0.034 (1.178)	DT 0.003 (1.127)	loss 10.376 (10.376)	prob 0.748 (0.748)	GS 34.297 (34.297)	mem 45.712
Train: [1][250/750]	BT 0.032 (1.193)	DT 0.002 (1.142)	loss 10.119 (10.119)	prob 0.308 (0.308)	GS 35.422 (35.422)	mem 45.750
Train: [1][255/750]	BT 0.056 (1.174)	DT 0.017 (1.123)	loss 10.308 (10.308)	prob -0.089 (-0.089)	GS 31.938 (31.938)	mem 45.787
Train: [1][260/750]	BT 9.776 (1.200)	DT 9.745 (1.149)	loss 10.535 (10.535)	prob -0.636 (-0.636)	GS 36.453 (36.453)	mem 45.792
Train: [1][265/750]	BT 0.029 (1.178)	DT 0.001 (1.127)	loss 10.103 (10.103)	prob 0.407 (0.407)	GS 34.828 (34.828)	mem 45.947
Train: [1][270/750]	BT 0.033 (1.171)	DT 0.001 (1.120)	loss 10.640 (10.640)	prob -0.492 (-0.492)	GS 31.391 (31.391)	mem 45.886
Train: [1][275/750]	BT 0.030 (1.186)	DT 0.001 (1.135)	loss 9.878 (9.878)	prob 1.215 (1.215)	GS 31.578 (31.578)	mem 45.887
Train: [1][280/750]	BT 2.869 (1.175)	DT 2.829 (1.125)	loss 10.322 (10.322)	prob 0.709 (0.709)	GS 36.094 (36.094)	mem 45.937
Train: [1][285/750]	BT 0.084 (1.187)	DT 0.011 (1.137)	loss 10.677 (10.677)	prob 0.128 (0.128)	GS 31.672 (31.672)	mem 46.047
Train: [1][290/750]	BT 0.058 (1.168)	DT 0.002 (1.117)	loss 10.487 (10.487)	prob 0.046 (0.046)	GS 32.641 (32.641)	mem 45.990
Train: [1][295/750]	BT 0.035 (1.178)	DT 0.003 (1.127)	loss 10.556 (10.556)	prob 0.440 (0.440)	GS 26.188 (26.188)	mem 45.981
Train: [1][300/750]	BT 0.033 (1.164)	DT 0.001 (1.114)	loss 10.355 (10.355)	prob 0.737 (0.737)	GS 34.125 (34.125)	mem 45.986
Train: [1][305/750]	BT 0.142 (1.186)	DT 0.023 (1.135)	loss 10.840 (10.840)	prob -0.120 (-0.120)	GS 31.203 (31.203)	mem 46.157
Train: [1][310/750]	BT 0.025 (1.176)	DT 0.001 (1.126)	loss 9.975 (9.975)	prob 1.094 (1.094)	GS 28.000 (28.000)	mem 46.058
Train: [1][315/750]	BT 0.026 (1.158)	DT 0.001 (1.108)	loss 10.136 (10.136)	prob 0.914 (0.914)	GS 30.391 (30.391)	mem 46.059
Train: [1][320/750]	BT 4.138 (1.179)	DT 4.096 (1.128)	loss 10.829 (10.829)	prob -0.159 (-0.159)	GS 34.516 (34.516)	mem 46.025
Train: [1][325/750]	BT 0.038 (1.161)	DT 0.007 (1.111)	loss 9.960 (9.960)	prob 1.186 (1.186)	GS 26.500 (26.500)	mem 46.097
Train: [1][330/750]	BT 0.024 (1.168)	DT 0.001 (1.118)	loss 10.383 (10.383)	prob 0.102 (0.102)	GS 35.703 (35.703)	mem 46.110
Train: [1][335/750]	BT 0.025 (1.161)	DT 0.001 (1.111)	loss 10.500 (10.500)	prob -0.253 (-0.253)	GS 34.594 (34.594)	mem 46.105
Train: [1][340/750]	BT 9.092 (1.171)	DT 9.041 (1.121)	loss 10.525 (10.525)	prob 0.314 (0.314)	GS 33.812 (33.812)	mem 46.145
Train: [1][345/750]	BT 0.083 (1.164)	DT 0.001 (1.114)	loss 10.349 (10.349)	prob -0.032 (-0.032)	GS 26.406 (26.406)	mem 46.061
Train: [1][350/750]	BT 0.036 (1.148)	DT 0.002 (1.098)	loss 10.507 (10.507)	prob 0.101 (0.101)	GS 34.891 (34.891)	mem 46.061
Train: [1][355/750]	BT 0.032 (1.157)	DT 0.002 (1.108)	loss 10.062 (10.062)	prob -0.143 (-0.143)	GS 30.719 (30.719)	mem 46.137
Train: [1][360/750]	BT 0.026 (1.152)	DT 0.001 (1.103)	loss 10.177 (10.177)	prob -0.343 (-0.343)	GS 31.625 (31.625)	mem 46.078
Train: [1][365/750]	BT 0.071 (1.170)	DT 0.013 (1.120)	loss 9.935 (9.935)	prob 0.241 (0.241)	GS 31.781 (31.781)	mem 46.025
Train: [1][370/750]	BT 0.057 (1.155)	DT 0.002 (1.106)	loss 9.947 (9.947)	prob 0.336 (0.336)	GS 37.344 (37.344)	mem 46.060
Train: [1][375/750]	BT 0.045 (1.141)	DT 0.001 (1.091)	loss 10.087 (10.087)	prob 0.432 (0.432)	GS 29.281 (29.281)	mem 46.029
Train: [1][380/750]	BT 6.507 (1.171)	DT 6.427 (1.121)	loss 10.421 (10.421)	prob -0.073 (-0.073)	GS 38.594 (38.594)	mem 45.968
Train: [1][385/750]	BT 0.033 (1.156)	DT 0.002 (1.107)	loss 10.002 (10.002)	prob 0.534 (0.534)	GS 34.297 (34.297)	mem 45.967
Train: [1][390/750]	BT 0.061 (1.151)	DT 0.005 (1.102)	loss 10.280 (10.280)	prob 0.351 (0.351)	GS 34.734 (34.734)	mem 45.996
Train: [1][395/750]	BT 0.027 (1.161)	DT 0.002 (1.112)	loss 10.267 (10.267)	prob 0.301 (0.301)	GS 29.406 (29.406)	mem 45.935
Train: [1][400/750]	BT 3.126 (1.155)	DT 3.075 (1.106)	loss 10.404 (10.404)	prob 0.400 (0.400)	GS 32.797 (32.797)	mem 45.932
Train: [1][405/750]	BT 0.035 (1.165)	DT 0.004 (1.115)	loss 10.414 (10.414)	prob 0.476 (0.476)	GS 28.062 (28.062)	mem 46.032
Train: [1][410/750]	BT 0.038 (1.151)	DT 0.001 (1.102)	loss 10.025 (10.025)	prob 0.631 (0.631)	GS 32.047 (32.047)	mem 46.033
Train: [1][415/750]	BT 0.054 (1.142)	DT 0.011 (1.093)	loss 9.875 (9.875)	prob 0.312 (0.312)	GS 30.938 (30.938)	mem 45.995
Train: [1][420/750]	BT 0.057 (1.164)	DT 0.001 (1.115)	loss 9.948 (9.948)	prob -0.100 (-0.100)	GS 30.922 (30.922)	mem 46.056
Train: [1][425/750]	BT 0.080 (1.154)	DT 0.017 (1.105)	loss 10.517 (10.517)	prob -0.334 (-0.334)	GS 30.859 (30.859)	mem 46.130
Train: [1][430/750]	BT 0.054 (1.163)	DT 0.005 (1.114)	loss 10.107 (10.107)	prob 0.338 (0.338)	GS 31.359 (31.359)	mem 46.231
Train: [1][435/750]	BT 0.135 (1.150)	DT 0.022 (1.101)	loss 10.330 (10.330)	prob 0.492 (0.492)	GS 29.812 (29.812)	mem 46.144
Train: [1][440/750]	BT 10.952 (1.168)	DT 10.919 (1.118)	loss 10.078 (10.078)	prob 0.767 (0.767)	GS 34.562 (34.562)	mem 46.195
Train: [1][445/750]	BT 0.065 (1.155)	DT 0.008 (1.106)	loss 10.184 (10.184)	prob 0.560 (0.560)	GS 31.750 (31.750)	mem 46.262
Train: [1][450/750]	BT 0.081 (1.150)	DT 0.004 (1.100)	loss 10.530 (10.530)	prob 0.019 (0.019)	GS 36.156 (36.156)	mem 46.343
Train: [1][455/750]	BT 0.026 (1.165)	DT 0.001 (1.116)	loss 10.443 (10.443)	prob 0.198 (0.198)	GS 35.859 (35.859)	mem 46.317
Train: [1][460/750]	BT 0.036 (1.153)	DT 0.002 (1.104)	loss 10.717 (10.717)	prob -0.235 (-0.235)	GS 31.906 (31.906)	mem 46.286
Train: [1][465/750]	BT 0.083 (1.162)	DT 0.030 (1.113)	loss 10.179 (10.179)	prob 0.546 (0.546)	GS 31.828 (31.828)	mem 46.283
Train: [1][470/750]	BT 0.029 (1.152)	DT 0.003 (1.102)	loss 9.953 (9.953)	prob 0.712 (0.712)	GS 29.156 (29.156)	mem 46.286
Train: [1][475/750]	BT 0.039 (1.146)	DT 0.002 (1.097)	loss 10.297 (10.297)	prob 0.419 (0.419)	GS 28.891 (28.891)	mem 46.366
Train: [1][480/750]	BT 0.033 (1.155)	DT 0.002 (1.105)	loss 10.913 (10.913)	prob -0.413 (-0.413)	GS 33.312 (33.312)	mem 46.227
Train: [1][485/750]	BT 0.073 (1.144)	DT 0.009 (1.095)	loss 10.426 (10.426)	prob 0.302 (0.302)	GS 34.250 (34.250)	mem 46.230
Train: [1][490/750]	BT 0.033 (1.157)	DT 0.001 (1.108)	loss 10.141 (10.141)	prob 0.481 (0.481)	GS 32.844 (32.844)	mem 46.292
Train: [1][495/750]	BT 0.039 (1.146)	DT 0.002 (1.097)	loss 10.360 (10.360)	prob -0.274 (-0.274)	GS 31.203 (31.203)	mem 46.256
Train: [1][500/750]	BT 9.659 (1.159)	DT 9.613 (1.110)	loss 10.110 (10.110)	prob 0.182 (0.182)	GS 34.812 (34.812)	mem 46.289
Train: [1][505/750]	BT 0.066 (1.152)	DT 0.002 (1.103)	loss 10.150 (10.150)	prob -0.000 (-0.000)	GS 30.391 (30.391)	mem 46.297
Train: [1][510/750]	BT 0.064 (1.143)	DT 0.001 (1.094)	loss 10.429 (10.429)	prob 0.599 (0.599)	GS 31.234 (31.234)	mem 46.449
Train: [1][515/750]	BT 0.031 (1.152)	DT 0.002 (1.103)	loss 10.211 (10.211)	prob 0.204 (0.204)	GS 33.406 (33.406)	mem 46.341
Train: [1][520/750]	BT 3.268 (1.152)	DT 3.222 (1.103)	loss 10.222 (10.222)	prob -0.070 (-0.070)	GS 35.062 (35.062)	mem 46.358
Train: [1][525/750]	BT 0.038 (1.146)	DT 0.004 (1.097)	loss 10.159 (10.159)	prob 0.525 (0.525)	GS 32.875 (32.875)	mem 46.158
Train: [1][530/750]	BT 1.579 (1.150)	DT 1.498 (1.101)	loss 10.349 (10.349)	prob 0.134 (0.134)	GS 32.359 (32.359)	mem 46.265
Train: [1][535/750]	BT 0.059 (1.140)	DT 0.004 (1.091)	loss 10.283 (10.283)	prob 0.223 (0.223)	GS 33.109 (33.109)	mem 46.208
Train: [1][540/750]	BT 0.045 (1.153)	DT 0.001 (1.104)	loss 10.190 (10.190)	prob 0.149 (0.149)	GS 30.828 (30.828)	mem 46.084
Train: [1][545/750]	BT 0.038 (1.143)	DT 0.002 (1.094)	loss 10.346 (10.346)	prob 0.342 (0.342)	GS 32.922 (32.922)	mem 46.098
Train: [1][550/750]	BT 10.591 (1.159)	DT 10.562 (1.109)	loss 10.413 (10.413)	prob 0.510 (0.510)	GS 30.734 (30.734)	mem 46.176
Train: [1][555/750]	BT 0.033 (1.149)	DT 0.002 (1.100)	loss 10.588 (10.588)	prob 0.500 (0.500)	GS 34.156 (34.156)	mem 46.177
Train: [1][560/750]	BT 0.368 (1.140)	DT 0.334 (1.091)	loss 10.400 (10.400)	prob 0.315 (0.315)	GS 33.031 (33.031)	mem 46.088
Train: [1][565/750]	BT 0.022 (1.154)	DT 0.001 (1.105)	loss 10.454 (10.454)	prob 0.429 (0.429)	GS 26.453 (26.453)	mem 46.176
Train: [1][570/750]	BT 0.068 (1.144)	DT 0.010 (1.095)	loss 10.028 (10.028)	prob 0.907 (0.907)	GS 36.016 (36.016)	mem 46.180
Train: [1][575/750]	BT 0.023 (1.157)	DT 0.001 (1.108)	loss 10.515 (10.515)	prob 0.363 (0.363)	GS 31.766 (31.766)	mem 46.383
Train: [1][580/750]	BT 0.033 (1.148)	DT 0.001 (1.099)	loss 10.692 (10.692)	prob -0.020 (-0.020)	GS 34.938 (34.938)	mem 46.568
Train: [1][585/750]	BT 0.035 (1.138)	DT 0.001 (1.089)	loss 9.790 (9.790)	prob 0.895 (0.895)	GS 29.016 (29.016)	mem 46.321
Train: [1][590/750]	BT 0.049 (1.150)	DT 0.004 (1.102)	loss 10.124 (10.124)	prob 0.393 (0.393)	GS 33.656 (33.656)	mem 46.507
Train: [1][595/750]	BT 0.053 (1.141)	DT 0.009 (1.092)	loss 10.570 (10.570)	prob 0.426 (0.426)	GS 31.578 (31.578)	mem 46.423
Train: [1][600/750]	BT 0.031 (1.155)	DT 0.001 (1.107)	loss 10.305 (10.305)	prob 0.391 (0.391)	GS 33.828 (33.828)	mem 46.395
Train: [1][605/750]	BT 0.030 (1.146)	DT 0.001 (1.098)	loss 10.561 (10.561)	prob 0.230 (0.230)	GS 29.781 (29.781)	mem 46.397
Train: [1][610/750]	BT 12.667 (1.158)	DT 12.647 (1.109)	loss 10.056 (10.056)	prob 1.088 (1.088)	GS 35.000 (35.000)	mem 46.442
Train: [1][615/750]	BT 0.033 (1.148)	DT 0.002 (1.100)	loss 10.124 (10.124)	prob 0.358 (0.358)	GS 29.797 (29.797)	mem 46.511
Train: [1][620/750]	BT 0.052 (1.139)	DT 0.002 (1.091)	loss 9.934 (9.934)	prob 0.519 (0.519)	GS 35.062 (35.062)	mem 46.437
Train: [1][625/750]	BT 0.020 (1.151)	DT 0.001 (1.103)	loss 10.280 (10.280)	prob 0.429 (0.429)	GS 33.031 (33.031)	mem 46.394
Train: [1][630/750]	BT 0.058 (1.143)	DT 0.014 (1.095)	loss 10.004 (10.004)	prob -0.012 (-0.012)	GS 33.391 (33.391)	mem 46.412
Train: [1][635/750]	BT 0.032 (1.156)	DT 0.001 (1.108)	loss 9.983 (9.983)	prob 0.156 (0.156)	GS 31.188 (31.188)	mem 46.463
Train: [1][640/750]	BT 0.851 (1.148)	DT 0.787 (1.100)	loss 10.363 (10.363)	prob 0.082 (0.082)	GS 36.469 (36.469)	mem 46.509
Train: [1][645/750]	BT 0.035 (1.140)	DT 0.001 (1.092)	loss 10.166 (10.166)	prob 0.234 (0.234)	GS 28.781 (28.781)	mem 46.550
Train: [1][650/750]	BT 0.057 (1.150)	DT 0.012 (1.102)	loss 10.391 (10.391)	prob 0.168 (0.168)	GS 32.875 (32.875)	mem 46.454
Train: [1][655/750]	BT 0.056 (1.146)	DT 0.013 (1.098)	loss 10.443 (10.443)	prob -0.424 (-0.424)	GS 27.266 (27.266)	mem 46.432
Train: [1][660/750]	BT 0.029 (1.155)	DT 0.001 (1.107)	loss 10.389 (10.389)	prob -0.368 (-0.368)	GS 33.500 (33.500)	mem 46.391
Train: [1][665/750]	BT 0.045 (1.147)	DT 0.008 (1.099)	loss 10.436 (10.436)	prob 0.552 (0.552)	GS 28.469 (28.469)	mem 46.393
Train: [1][670/750]	BT 12.855 (1.158)	DT 12.792 (1.110)	loss 10.302 (10.302)	prob -0.002 (-0.002)	GS 33.828 (33.828)	mem 46.382
Train: [1][675/750]	BT 0.036 (1.150)	DT 0.002 (1.102)	loss 10.436 (10.436)	prob 0.194 (0.194)	GS 30.609 (30.609)	mem 46.467
Train: [1][680/750]	BT 0.035 (1.141)	DT 0.003 (1.094)	loss 10.536 (10.536)	prob 0.318 (0.318)	GS 34.875 (34.875)	mem 46.390
Train: [1][685/750]	BT 0.032 (1.152)	DT 0.003 (1.104)	loss 9.952 (9.952)	prob 0.635 (0.635)	GS 31.031 (31.031)	mem 46.474
Train: [1][690/750]	BT 0.031 (1.146)	DT 0.001 (1.099)	loss 10.048 (10.048)	prob 0.245 (0.245)	GS 36.172 (36.172)	mem 46.383
Train: [1][695/750]	BT 0.052 (1.153)	DT 0.004 (1.105)	loss 10.529 (10.529)	prob 0.061 (0.061)	GS 32.469 (32.469)	mem 46.411
Train: [1][700/750]	BT 2.185 (1.148)	DT 2.146 (1.101)	loss 10.385 (10.385)	prob 0.142 (0.142)	GS 35.344 (35.344)	mem 46.424
Train: [1][705/750]	BT 0.031 (1.140)	DT 0.001 (1.093)	loss 10.209 (10.209)	prob 0.577 (0.577)	GS 31.750 (31.750)	mem 46.426
Train: [1][710/750]	BT 0.029 (1.149)	DT 0.001 (1.101)	loss 10.395 (10.395)	prob -0.084 (-0.084)	GS 32.453 (32.453)	mem 46.329
Train: [1][715/750]	BT 0.040 (1.141)	DT 0.001 (1.094)	loss 10.242 (10.242)	prob 0.260 (0.260)	GS 31.844 (31.844)	mem 46.328
Train: [1][720/750]	BT 0.041 (1.148)	DT 0.001 (1.101)	loss 9.992 (9.992)	prob 0.264 (0.264)	GS 35.281 (35.281)	mem 46.307
Train: [1][725/750]	BT 0.031 (1.140)	DT 0.006 (1.094)	loss 10.619 (10.619)	prob 0.138 (0.138)	GS 33.594 (33.594)	mem 46.310
Train: [1][730/750]	BT 9.495 (1.146)	DT 9.465 (1.099)	loss 9.876 (9.876)	prob 0.753 (0.753)	GS 32.750 (32.750)	mem 45.891
Train: [1][735/750]	BT 0.033 (1.138)	DT 0.002 (1.092)	loss 10.156 (10.156)	prob 0.936 (0.936)	GS 32.141 (32.141)	mem 45.892
Train: [1][740/750]	BT 0.033 (1.131)	DT 0.002 (1.084)	loss 10.421 (10.421)	prob -0.264 (-0.264)	GS 33.438 (33.438)	mem 45.950
Train: [1][745/750]	BT 0.029 (1.133)	DT 0.001 (1.086)	loss 10.214 (10.214)	prob 0.205 (0.205)	GS 32.125 (32.125)	mem 14.083
Train: [1][750/750]	BT 0.026 (1.125)	DT 0.001 (1.079)	loss 10.523 (10.523)	prob -0.146 (-0.146)	GS 32.156 (32.156)	mem 14.081
Train: [1][755/750]	BT 0.025 (1.121)	DT 0.001 (1.074)	loss 10.050 (10.050)	prob 1.053 (1.053)	GS 30.438 (30.438)	mem 14.045
epoch 1, total time 846.32
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [2][1/750]	BT 21.229 (21.229)	DT 21.121 (21.121)	loss 10.564 (10.564)	prob 0.374 (0.374)	GS 29.672 (29.672)	mem 45.018
Train: [2][5/750]	BT 0.059 (5.066)	DT 0.003 (5.014)	loss 10.155 (10.155)	prob 0.824 (0.824)	GS 36.469 (36.469)	mem 45.081
Train: [2][10/750]	BT 0.090 (3.561)	DT 0.004 (3.505)	loss 10.520 (10.520)	prob 0.201 (0.201)	GS 34.266 (34.266)	mem 45.146
Train: [2][15/750]	BT 0.048 (2.808)	DT 0.001 (2.752)	loss 10.154 (10.154)	prob -0.264 (-0.264)	GS 30.578 (30.578)	mem 45.010
Train: [2][20/750]	BT 0.530 (2.143)	DT 0.496 (2.089)	loss 10.253 (10.253)	prob -0.145 (-0.145)	GS 36.062 (36.062)	mem 45.014
Train: [2][25/750]	BT 0.052 (1.857)	DT 0.005 (1.805)	loss 10.335 (10.335)	prob -0.420 (-0.420)	GS 27.422 (27.422)	mem 45.374
Train: [2][30/750]	BT 0.038 (1.951)	DT 0.001 (1.903)	loss 10.511 (10.511)	prob -0.566 (-0.566)	GS 31.828 (31.828)	mem 45.232
Train: [2][35/750]	BT 0.030 (1.697)	DT 0.001 (1.649)	loss 10.334 (10.334)	prob 0.451 (0.451)	GS 30.203 (30.203)	mem 45.241
Train: [2][40/750]	BT 0.025 (1.883)	DT 0.001 (1.837)	loss 10.193 (10.193)	prob 0.153 (0.153)	GS 33.938 (33.938)	mem 45.271
Train: [2][45/750]	BT 0.032 (1.679)	DT 0.001 (1.633)	loss 10.354 (10.354)	prob -0.020 (-0.020)	GS 29.281 (29.281)	mem 45.273
Train: [2][50/750]	BT 14.213 (1.799)	DT 14.147 (1.753)	loss 10.443 (10.443)	prob -0.049 (-0.049)	GS 35.547 (35.547)	mem 45.489
Train: [2][55/750]	BT 0.031 (1.640)	DT 0.002 (1.594)	loss 10.729 (10.729)	prob -0.150 (-0.150)	GS 33.062 (33.062)	mem 45.343
Train: [2][60/750]	BT 0.138 (1.508)	DT 0.004 (1.461)	loss 10.258 (10.258)	prob -0.114 (-0.114)	GS 35.500 (35.500)	mem 45.342
Train: [2][65/750]	BT 0.054 (1.648)	DT 0.002 (1.602)	loss 10.720 (10.720)	prob -0.516 (-0.516)	GS 35.219 (35.219)	mem 45.325
Train: [2][70/750]	BT 0.034 (1.533)	DT 0.002 (1.488)	loss 9.945 (9.945)	prob 0.103 (0.103)	GS 33.562 (33.562)	mem 45.326
Train: [2][75/750]	BT 0.046 (1.567)	DT 0.006 (1.522)	loss 10.356 (10.356)	prob 0.059 (0.059)	GS 30.922 (30.922)	mem 45.316
Train: [2][80/750]	BT 0.038 (1.471)	DT 0.016 (1.427)	loss 10.286 (10.286)	prob -0.099 (-0.099)	GS 32.156 (32.156)	mem 45.316
Train: [2][85/750]	BT 0.031 (1.387)	DT 0.002 (1.344)	loss 10.469 (10.469)	prob -0.181 (-0.181)	GS 28.688 (28.688)	mem 45.315
Train: [2][90/750]	BT 0.024 (1.465)	DT 0.001 (1.423)	loss 10.141 (10.141)	prob 0.558 (0.558)	GS 31.531 (31.531)	mem 45.169
Train: [2][95/750]	BT 0.030 (1.390)	DT 0.001 (1.348)	loss 10.398 (10.398)	prob 0.099 (0.099)	GS 29.266 (29.266)	mem 45.170
Train: [2][100/750]	BT 0.039 (1.447)	DT 0.002 (1.406)	loss 10.037 (10.037)	prob 0.586 (0.586)	GS 36.031 (36.031)	mem 45.292
Train: [2][105/750]	BT 0.087 (1.382)	DT 0.006 (1.339)	loss 9.928 (9.928)	prob 1.024 (1.024)	GS 32.906 (32.906)	mem 45.294
Train: [2][110/750]	BT 12.149 (1.430)	DT 12.103 (1.388)	loss 10.507 (10.507)	prob -0.020 (-0.020)	GS 32.047 (32.047)	mem 45.320
Train: [2][115/750]	BT 0.027 (1.370)	DT 0.001 (1.328)	loss 10.856 (10.856)	prob -0.081 (-0.081)	GS 29.500 (29.500)	mem 45.292
Train: [2][120/750]	BT 0.071 (1.315)	DT 0.012 (1.273)	loss 10.190 (10.190)	prob 0.177 (0.177)	GS 34.500 (34.500)	mem 45.293
Train: [2][125/750]	BT 0.028 (1.335)	DT 0.001 (1.294)	loss 10.196 (10.196)	prob -0.583 (-0.583)	GS 31.219 (31.219)	mem 45.318
Train: [2][130/750]	BT 0.030 (1.286)	DT 0.001 (1.245)	loss 10.345 (10.345)	prob -0.260 (-0.260)	GS 35.516 (35.516)	mem 45.320
Train: [2][135/750]	BT 0.045 (1.342)	DT 0.024 (1.302)	loss 9.998 (9.998)	prob 0.562 (0.562)	GS 28.094 (28.094)	mem 45.231
Train: [2][140/750]	BT 0.032 (1.296)	DT 0.001 (1.255)	loss 10.578 (10.578)	prob 0.074 (0.074)	GS 35.375 (35.375)	mem 45.234
Train: [2][145/750]	BT 0.067 (1.253)	DT 0.001 (1.212)	loss 10.056 (10.056)	prob 1.110 (1.110)	GS 27.906 (27.906)	mem 45.238
Train: [2][150/750]	BT 0.030 (1.325)	DT 0.001 (1.285)	loss 10.350 (10.350)	prob 0.706 (0.706)	GS 29.312 (29.312)	mem 45.265
Train: [2][155/750]	BT 0.030 (1.284)	DT 0.001 (1.243)	loss 10.498 (10.498)	prob 0.477 (0.477)	GS 34.672 (34.672)	mem 45.266
Train: [2][160/750]	BT 0.031 (1.335)	DT 0.001 (1.295)	loss 9.909 (9.909)	prob 0.953 (0.953)	GS 37.031 (37.031)	mem 45.515
Train: [2][165/750]	BT 0.043 (1.296)	DT 0.011 (1.256)	loss 10.122 (10.122)	prob 0.106 (0.106)	GS 29.625 (29.625)	mem 45.522
Train: [2][170/750]	BT 12.813 (1.334)	DT 12.782 (1.294)	loss 10.201 (10.201)	prob 0.018 (0.018)	GS 37.766 (37.766)	mem 45.555
Train: [2][175/750]	BT 0.028 (1.297)	DT 0.001 (1.257)	loss 10.392 (10.392)	prob -0.010 (-0.010)	GS 30.938 (30.938)	mem 45.556
Train: [2][180/750]	BT 0.064 (1.262)	DT 0.001 (1.222)	loss 10.159 (10.159)	prob 0.229 (0.229)	GS 29.547 (29.547)	mem 45.568
Train: [2][185/750]	BT 0.049 (1.295)	DT 0.002 (1.256)	loss 10.204 (10.204)	prob 0.499 (0.499)	GS 31.875 (31.875)	mem 45.736
Train: [2][190/750]	BT 0.032 (1.263)	DT 0.001 (1.223)	loss 10.217 (10.217)	prob 0.233 (0.233)	GS 37.734 (37.734)	mem 45.736
Train: [2][195/750]	BT 0.061 (1.294)	DT 0.004 (1.253)	loss 10.246 (10.246)	prob 0.014 (0.014)	GS 27.250 (27.250)	mem 45.692
Train: [2][200/750]	BT 0.027 (1.262)	DT 0.001 (1.222)	loss 9.844 (9.844)	prob 0.537 (0.537)	GS 38.141 (38.141)	mem 45.692
Train: [2][205/750]	BT 0.085 (1.233)	DT 0.038 (1.193)	loss 10.282 (10.282)	prob -0.168 (-0.168)	GS 34.953 (34.953)	mem 45.737
Train: [2][210/750]	BT 0.046 (1.264)	DT 0.014 (1.224)	loss 10.181 (10.181)	prob -0.080 (-0.080)	GS 30.094 (30.094)	mem 45.823
Train: [2][215/750]	BT 0.100 (1.236)	DT 0.036 (1.196)	loss 10.054 (10.054)	prob 0.601 (0.601)	GS 30.219 (30.219)	mem 45.760
Train: [2][220/750]	BT 0.026 (1.261)	DT 0.001 (1.220)	loss 10.815 (10.815)	prob 0.060 (0.060)	GS 35.062 (35.062)	mem 45.774
Train: [2][225/750]	BT 0.032 (1.233)	DT 0.003 (1.193)	loss 10.251 (10.251)	prob 0.172 (0.172)	GS 33.891 (33.891)	mem 45.775
Train: [2][230/750]	BT 13.981 (1.268)	DT 13.949 (1.228)	loss 9.955 (9.955)	prob 0.840 (0.840)	GS 36.438 (36.438)	mem 45.986
Train: [2][235/750]	BT 0.033 (1.242)	DT 0.001 (1.202)	loss 10.368 (10.368)	prob 0.054 (0.054)	GS 37.984 (37.984)	mem 45.967
Train: [2][240/750]	BT 0.033 (1.218)	DT 0.002 (1.177)	loss 9.861 (9.861)	prob 0.437 (0.437)	GS 33.344 (33.344)	mem 45.969
Train: [2][245/750]	BT 0.033 (1.236)	DT 0.001 (1.195)	loss 10.684 (10.684)	prob -0.691 (-0.691)	GS 31.906 (31.906)	mem 46.168
Train: [2][250/750]	BT 0.035 (1.213)	DT 0.012 (1.172)	loss 10.289 (10.289)	prob -0.611 (-0.611)	GS 31.172 (31.172)	mem 46.022
Train: [2][255/750]	BT 0.036 (1.235)	DT 0.002 (1.194)	loss 10.398 (10.398)	prob -0.579 (-0.579)	GS 28.719 (28.719)	mem 45.985
Train: [2][260/750]	BT 0.129 (1.212)	DT 0.001 (1.171)	loss 10.479 (10.479)	prob -0.544 (-0.544)	GS 32.578 (32.578)	mem 46.093
Train: [2][265/750]	BT 0.115 (1.191)	DT 0.022 (1.149)	loss 10.604 (10.604)	prob -0.968 (-0.968)	GS 30.125 (30.125)	mem 46.136
Train: [2][270/750]	BT 0.061 (1.212)	DT 0.001 (1.170)	loss 9.828 (9.828)	prob 0.245 (0.245)	GS 29.312 (29.312)	mem 45.969
Train: [2][275/750]	BT 0.044 (1.191)	DT 0.001 (1.149)	loss 10.283 (10.283)	prob -0.068 (-0.068)	GS 32.766 (32.766)	mem 46.148
Train: [2][280/750]	BT 0.860 (1.209)	DT 0.814 (1.167)	loss 10.921 (10.921)	prob -0.437 (-0.437)	GS 32.781 (32.781)	mem 46.094
Train: [2][285/750]	BT 0.055 (1.201)	DT 0.005 (1.159)	loss 10.305 (10.305)	prob 0.022 (0.022)	GS 31.656 (31.656)	mem 46.126
Train: [2][290/750]	BT 8.277 (1.210)	DT 8.217 (1.167)	loss 10.515 (10.515)	prob 0.007 (0.007)	GS 36.781 (36.781)	mem 46.193
Train: [2][295/750]	BT 0.033 (1.202)	DT 0.002 (1.160)	loss 10.496 (10.496)	prob 0.207 (0.207)	GS 33.688 (33.688)	mem 46.078
Train: [2][300/750]	BT 0.044 (1.186)	DT 0.001 (1.143)	loss 10.349 (10.349)	prob 0.110 (0.110)	GS 32.203 (32.203)	mem 46.073
Train: [2][305/750]	BT 0.070 (1.210)	DT 0.009 (1.167)	loss 9.991 (9.991)	prob 0.517 (0.517)	GS 30.266 (30.266)	mem 46.254
Train: [2][310/750]	BT 0.062 (1.199)	DT 0.004 (1.156)	loss 9.843 (9.843)	prob 0.128 (0.128)	GS 33.500 (33.500)	mem 46.176
Train: [2][315/750]	BT 0.033 (1.201)	DT 0.001 (1.158)	loss 10.383 (10.383)	prob -0.023 (-0.023)	GS 26.344 (26.344)	mem 46.194
Train: [2][320/750]	BT 2.515 (1.201)	DT 2.455 (1.158)	loss 9.951 (9.951)	prob 0.196 (0.196)	GS 30.781 (30.781)	mem 46.257
Train: [2][325/750]	BT 0.060 (1.184)	DT 0.003 (1.140)	loss 10.083 (10.083)	prob 0.330 (0.330)	GS 32.250 (32.250)	mem 46.298
Train: [2][330/750]	BT 0.043 (1.191)	DT 0.004 (1.148)	loss 10.497 (10.497)	prob -0.244 (-0.244)	GS 33.156 (33.156)	mem 46.221
Train: [2][335/750]	BT 0.041 (1.183)	DT 0.002 (1.140)	loss 10.294 (10.294)	prob 0.281 (0.281)	GS 29.375 (29.375)	mem 46.226
Train: [2][340/750]	BT 0.060 (1.187)	DT 0.002 (1.143)	loss 10.386 (10.386)	prob 0.495 (0.495)	GS 34.234 (34.234)	mem 46.234
Train: [2][345/750]	BT 0.050 (1.185)	DT 0.013 (1.141)	loss 10.423 (10.423)	prob 0.446 (0.446)	GS 30.203 (30.203)	mem 46.208
Train: [2][350/750]	BT 10.561 (1.199)	DT 10.530 (1.155)	loss 10.056 (10.056)	prob 0.271 (0.271)	GS 34.594 (34.594)	mem 46.322
Train: [2][355/750]	BT 0.031 (1.182)	DT 0.001 (1.139)	loss 9.960 (9.960)	prob 0.511 (0.511)	GS 31.375 (31.375)	mem 46.249
Train: [2][360/750]	BT 0.026 (1.173)	DT 0.001 (1.129)	loss 10.562 (10.562)	prob -0.426 (-0.426)	GS 35.406 (35.406)	mem 46.232
Train: [2][365/750]	BT 0.028 (1.187)	DT 0.001 (1.143)	loss 10.914 (10.914)	prob -0.308 (-0.308)	GS 40.375 (40.375)	mem 46.274
Train: [2][370/750]	BT 0.036 (1.172)	DT 0.002 (1.128)	loss 9.905 (9.905)	prob 0.316 (0.316)	GS 35.203 (35.203)	mem 46.208
Train: [2][375/750]	BT 0.026 (1.189)	DT 0.001 (1.146)	loss 10.368 (10.368)	prob 0.344 (0.344)	GS 24.812 (24.812)	mem 46.275
Train: [2][380/750]	BT 0.415 (1.174)	DT 0.358 (1.131)	loss 10.095 (10.095)	prob 0.476 (0.476)	GS 36.469 (36.469)	mem 46.605
Train: [2][385/750]	BT 0.050 (1.160)	DT 0.006 (1.117)	loss 10.241 (10.241)	prob 0.304 (0.304)	GS 30.938 (30.938)	mem 46.272
Train: [2][390/750]	BT 0.028 (1.181)	DT 0.001 (1.138)	loss 10.725 (10.725)	prob -0.218 (-0.218)	GS 32.453 (32.453)	mem 46.210
Train: [2][395/750]	BT 0.071 (1.167)	DT 0.002 (1.124)	loss 10.348 (10.348)	prob 0.528 (0.528)	GS 30.484 (30.484)	mem 46.317
Train: [2][400/750]	BT 0.065 (1.183)	DT 0.004 (1.140)	loss 10.141 (10.141)	prob 0.658 (0.658)	GS 35.125 (35.125)	mem 46.323
Train: [2][405/750]	BT 0.048 (1.169)	DT 0.004 (1.126)	loss 10.712 (10.712)	prob -0.288 (-0.288)	GS 34.016 (34.016)	mem 46.446
Train: [2][410/750]	BT 12.481 (1.186)	DT 12.440 (1.143)	loss 10.328 (10.328)	prob 0.585 (0.585)	GS 33.938 (33.938)	mem 46.271
Train: [2][415/750]	BT 0.041 (1.172)	DT 0.001 (1.129)	loss 10.043 (10.043)	prob 0.531 (0.531)	GS 27.688 (27.688)	mem 46.173
Train: [2][420/750]	BT 0.036 (1.159)	DT 0.002 (1.116)	loss 9.863 (9.863)	prob 0.649 (0.649)	GS 27.500 (27.500)	mem 46.238
Train: [2][425/750]	BT 0.049 (1.173)	DT 0.015 (1.130)	loss 9.793 (9.793)	prob 0.685 (0.685)	GS 26.141 (26.141)	mem 46.228
Train: [2][430/750]	BT 0.027 (1.160)	DT 0.001 (1.117)	loss 10.122 (10.122)	prob -0.140 (-0.140)	GS 34.406 (34.406)	mem 46.192
Train: [2][435/750]	BT 0.032 (1.176)	DT 0.001 (1.133)	loss 10.304 (10.304)	prob -0.010 (-0.010)	GS 35.047 (35.047)	mem 46.159
Train: [2][440/750]	BT 0.058 (1.163)	DT 0.008 (1.120)	loss 10.391 (10.391)	prob 0.188 (0.188)	GS 27.312 (27.312)	mem 46.160
Train: [2][445/750]	BT 0.072 (1.151)	DT 0.012 (1.107)	loss 10.437 (10.437)	prob 0.182 (0.182)	GS 31.359 (31.359)	mem 46.165
Train: [2][450/750]	BT 0.031 (1.170)	DT 0.001 (1.127)	loss 10.265 (10.265)	prob -0.265 (-0.265)	GS 36.734 (36.734)	mem 46.108
Train: [2][455/750]	BT 0.054 (1.158)	DT 0.012 (1.115)	loss 10.407 (10.407)	prob -0.248 (-0.248)	GS 35.938 (35.938)	mem 46.142
Train: [2][460/750]	BT 0.037 (1.182)	DT 0.001 (1.139)	loss 10.072 (10.072)	prob 0.094 (0.094)	GS 32.578 (32.578)	mem 46.083
Train: [2][465/750]	BT 0.026 (1.170)	DT 0.001 (1.127)	loss 10.460 (10.460)	prob -0.504 (-0.504)	GS 35.359 (35.359)	mem 46.158
Train: [2][470/750]	BT 13.074 (1.186)	DT 13.043 (1.142)	loss 10.111 (10.111)	prob -0.158 (-0.158)	GS 34.891 (34.891)	mem 46.247
Train: [2][475/750]	BT 0.056 (1.174)	DT 0.001 (1.130)	loss 9.920 (9.920)	prob -0.046 (-0.046)	GS 34.000 (34.000)	mem 46.342
Train: [2][480/750]	BT 0.045 (1.162)	DT 0.003 (1.119)	loss 9.766 (9.766)	prob -0.225 (-0.225)	GS 34.219 (34.219)	mem 46.250
Train: [2][485/750]	BT 0.034 (1.172)	DT 0.001 (1.129)	loss 10.699 (10.699)	prob -0.738 (-0.738)	GS 35.969 (35.969)	mem 46.319
Train: [2][490/750]	BT 0.051 (1.160)	DT 0.001 (1.117)	loss 10.240 (10.240)	prob -0.092 (-0.092)	GS 34.531 (34.531)	mem 46.286
Train: [2][495/750]	BT 0.058 (1.178)	DT 0.019 (1.135)	loss 10.282 (10.282)	prob -0.005 (-0.005)	GS 29.438 (29.438)	mem 46.299
Train: [2][500/750]	BT 0.069 (1.167)	DT 0.013 (1.124)	loss 9.557 (9.557)	prob 0.563 (0.563)	GS 33.250 (33.250)	mem 46.254
Train: [2][505/750]	BT 0.032 (1.156)	DT 0.002 (1.113)	loss 10.473 (10.473)	prob -0.170 (-0.170)	GS 32.531 (32.531)	mem 46.254
Train: [2][510/750]	BT 0.030 (1.170)	DT 0.001 (1.127)	loss 10.087 (10.087)	prob -0.051 (-0.051)	GS 30.781 (30.781)	mem 46.318
Train: [2][515/750]	BT 0.030 (1.159)	DT 0.001 (1.117)	loss 10.131 (10.131)	prob 0.367 (0.367)	GS 28.859 (28.859)	mem 46.318
Train: [2][520/750]	BT 0.043 (1.175)	DT 0.009 (1.132)	loss 10.274 (10.274)	prob -0.051 (-0.051)	GS 33.578 (33.578)	mem 46.314
Train: [2][525/750]	BT 0.024 (1.164)	DT 0.001 (1.121)	loss 10.416 (10.416)	prob -0.797 (-0.797)	GS 30.547 (30.547)	mem 46.313
Train: [2][530/750]	BT 12.802 (1.177)	DT 12.770 (1.135)	loss 10.251 (10.251)	prob -0.610 (-0.610)	GS 34.250 (34.250)	mem 46.279
Train: [2][535/750]	BT 0.051 (1.167)	DT 0.009 (1.124)	loss 10.148 (10.148)	prob -0.341 (-0.341)	GS 35.984 (35.984)	mem 46.255
Train: [2][540/750]	BT 0.065 (1.156)	DT 0.002 (1.114)	loss 10.398 (10.398)	prob -0.940 (-0.940)	GS 32.672 (32.672)	mem 46.298
Train: [2][545/750]	BT 0.036 (1.168)	DT 0.001 (1.126)	loss 10.117 (10.117)	prob -0.410 (-0.410)	GS 30.484 (30.484)	mem 46.328
Train: [2][550/750]	BT 0.024 (1.158)	DT 0.001 (1.116)	loss 9.980 (9.980)	prob -0.267 (-0.267)	GS 34.375 (34.375)	mem 46.296
Train: [2][555/750]	BT 0.048 (1.171)	DT 0.007 (1.129)	loss 10.249 (10.249)	prob -0.398 (-0.398)	GS 33.672 (33.672)	mem 46.314
Train: [2][560/750]	BT 0.023 (1.161)	DT 0.001 (1.119)	loss 10.243 (10.243)	prob 0.153 (0.153)	GS 35.594 (35.594)	mem 46.357
Train: [2][565/750]	BT 0.132 (1.152)	DT 0.009 (1.109)	loss 9.985 (9.985)	prob 0.163 (0.163)	GS 30.234 (30.234)	mem 46.316
Train: [2][570/750]	BT 0.037 (1.167)	DT 0.002 (1.124)	loss 10.150 (10.150)	prob 0.169 (0.169)	GS 33.938 (33.938)	mem 46.324
Train: [2][575/750]	BT 0.135 (1.157)	DT 0.001 (1.114)	loss 10.536 (10.536)	prob -0.807 (-0.807)	GS 31.953 (31.953)	mem 46.321
Train: [2][580/750]	BT 0.034 (1.170)	DT 0.001 (1.127)	loss 10.151 (10.151)	prob 0.023 (0.023)	GS 32.406 (32.406)	mem 46.257
Train: [2][585/750]	BT 0.054 (1.160)	DT 0.006 (1.117)	loss 10.511 (10.511)	prob 0.123 (0.123)	GS 28.953 (28.953)	mem 46.258
Train: [2][590/750]	BT 12.772 (1.172)	DT 12.733 (1.130)	loss 10.296 (10.296)	prob 0.321 (0.321)	GS 33.328 (33.328)	mem 46.333
Train: [2][595/750]	BT 0.058 (1.162)	DT 0.006 (1.120)	loss 10.519 (10.519)	prob 0.261 (0.261)	GS 30.219 (30.219)	mem 46.332
Train: [2][600/750]	BT 0.093 (1.153)	DT 0.005 (1.111)	loss 10.346 (10.346)	prob 0.155 (0.155)	GS 37.719 (37.719)	mem 46.335
Train: [2][605/750]	BT 0.034 (1.166)	DT 0.001 (1.123)	loss 10.461 (10.461)	prob 0.297 (0.297)	GS 37.875 (37.875)	mem 46.184
Train: [2][610/750]	BT 0.051 (1.156)	DT 0.011 (1.114)	loss 10.253 (10.253)	prob 0.727 (0.727)	GS 34.156 (34.156)	mem 46.186
Train: [2][615/750]	BT 0.091 (1.165)	DT 0.001 (1.122)	loss 10.566 (10.566)	prob -0.262 (-0.262)	GS 32.125 (32.125)	mem 46.304
Train: [2][620/750]	BT 0.089 (1.156)	DT 0.013 (1.113)	loss 10.306 (10.306)	prob 0.301 (0.301)	GS 31.312 (31.312)	mem 46.269
Train: [2][625/750]	BT 0.054 (1.147)	DT 0.003 (1.104)	loss 10.322 (10.322)	prob -0.298 (-0.298)	GS 31.203 (31.203)	mem 46.269
Train: [2][630/750]	BT 0.035 (1.159)	DT 0.001 (1.117)	loss 9.708 (9.708)	prob 0.884 (0.884)	GS 32.969 (32.969)	mem 46.283
Train: [2][635/750]	BT 0.033 (1.150)	DT 0.003 (1.108)	loss 10.914 (10.914)	prob -0.534 (-0.534)	GS 39.141 (39.141)	mem 46.282
Train: [2][640/750]	BT 0.023 (1.162)	DT 0.001 (1.120)	loss 10.286 (10.286)	prob -0.058 (-0.058)	GS 33.688 (33.688)	mem 46.325
Train: [2][645/750]	BT 0.034 (1.154)	DT 0.003 (1.111)	loss 10.290 (10.290)	prob 0.302 (0.302)	GS 33.578 (33.578)	mem 46.233
arpack error, retry= 0
Train: [2][650/750]	BT 12.286 (1.164)	DT 12.245 (1.122)	loss 10.387 (10.387)	prob -0.431 (-0.431)	GS 34.062 (34.062)	mem 46.318
Train: [2][655/750]	BT 0.049 (1.156)	DT 0.016 (1.113)	loss 10.410 (10.410)	prob -0.035 (-0.035)	GS 31.969 (31.969)	mem 46.326
Train: [2][660/750]	BT 0.030 (1.147)	DT 0.001 (1.105)	loss 10.086 (10.086)	prob 0.263 (0.263)	GS 33.031 (33.031)	mem 46.327
Train: [2][665/750]	BT 0.028 (1.160)	DT 0.001 (1.118)	loss 10.529 (10.529)	prob 0.479 (0.479)	GS 34.609 (34.609)	mem 46.218
Train: [2][670/750]	BT 0.030 (1.152)	DT 0.007 (1.110)	loss 9.958 (9.958)	prob 0.248 (0.248)	GS 33.047 (33.047)	mem 46.259
Train: [2][675/750]	BT 0.048 (1.162)	DT 0.001 (1.120)	loss 10.226 (10.226)	prob 0.103 (0.103)	GS 28.484 (28.484)	mem 46.256
Train: [2][680/750]	BT 0.045 (1.154)	DT 0.002 (1.112)	loss 10.291 (10.291)	prob -0.098 (-0.098)	GS 36.641 (36.641)	mem 46.189
Train: [2][685/750]	BT 0.090 (1.146)	DT 0.024 (1.103)	loss 10.053 (10.053)	prob 0.559 (0.559)	GS 27.969 (27.969)	mem 46.190
Train: [2][690/750]	BT 0.041 (1.152)	DT 0.003 (1.110)	loss 10.409 (10.409)	prob -0.260 (-0.260)	GS 36.594 (36.594)	mem 46.234
Train: [2][695/750]	BT 0.124 (1.144)	DT 0.015 (1.102)	loss 10.575 (10.575)	prob -0.401 (-0.401)	GS 30.625 (30.625)	mem 46.418
Train: [2][700/750]	BT 0.042 (1.159)	DT 0.005 (1.117)	loss 9.918 (9.918)	prob 0.395 (0.395)	GS 32.625 (32.625)	mem 46.163
Train: [2][705/750]	BT 0.029 (1.151)	DT 0.001 (1.109)	loss 10.506 (10.506)	prob -0.437 (-0.437)	GS 33.297 (33.297)	mem 46.163
Train: [2][710/750]	BT 14.162 (1.163)	DT 14.131 (1.121)	loss 10.083 (10.083)	prob -0.063 (-0.063)	GS 32.781 (32.781)	mem 46.160
Train: [2][715/750]	BT 0.025 (1.155)	DT 0.001 (1.113)	loss 10.273 (10.273)	prob -0.412 (-0.412)	GS 34.453 (34.453)	mem 46.176
Train: [2][720/750]	BT 0.027 (1.148)	DT 0.002 (1.106)	loss 9.820 (9.820)	prob 0.626 (0.626)	GS 31.062 (31.062)	mem 46.160
Train: [2][725/750]	BT 0.034 (1.161)	DT 0.002 (1.119)	loss 10.157 (10.157)	prob -0.332 (-0.332)	GS 30.656 (30.656)	mem 45.980
Train: [2][730/750]	BT 0.030 (1.153)	DT 0.001 (1.111)	loss 10.214 (10.214)	prob -0.484 (-0.484)	GS 33.312 (33.312)	mem 45.981
Train: [2][735/750]	BT 0.042 (1.158)	DT 0.002 (1.117)	loss 10.159 (10.159)	prob -0.133 (-0.133)	GS 29.859 (29.859)	mem 42.653
Train: [2][740/750]	BT 0.029 (1.151)	DT 0.002 (1.109)	loss 10.344 (10.344)	prob -0.315 (-0.315)	GS 36.734 (36.734)	mem 42.654
Train: [2][745/750]	BT 0.056 (1.143)	DT 0.002 (1.102)	loss 10.261 (10.261)	prob -0.035 (-0.035)	GS 31.188 (31.188)	mem 42.655
Train: [2][750/750]	BT 0.035 (1.139)	DT 0.002 (1.098)	loss 10.522 (10.522)	prob -0.366 (-0.366)	GS 30.875 (30.875)	mem 13.844
Train: [2][755/750]	BT 0.027 (1.132)	DT 0.001 (1.090)	loss 10.063 (10.063)	prob 0.884 (0.884)	GS 28.156 (28.156)	mem 13.844
epoch 2, total time 854.76
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [3][1/750]	BT 23.790 (23.790)	DT 23.743 (23.743)	loss 10.150 (10.150)	prob 1.012 (1.012)	GS 35.703 (35.703)	mem 44.830
Train: [3][5/750]	BT 0.836 (4.973)	DT 0.698 (4.891)	loss 10.140 (10.140)	prob 0.403 (0.403)	GS 29.328 (29.328)	mem 44.903
Train: [3][10/750]	BT 0.037 (2.642)	DT 0.003 (2.574)	loss 10.266 (10.266)	prob -0.030 (-0.030)	GS 32.719 (32.719)	mem 44.893
Train: [3][15/750]	BT 0.035 (2.581)	DT 0.002 (2.514)	loss 10.162 (10.162)	prob -0.187 (-0.187)	GS 28.109 (28.109)	mem 45.060
Train: [3][20/750]	BT 2.262 (2.063)	DT 2.096 (1.991)	loss 10.147 (10.147)	prob -0.002 (-0.002)	GS 34.547 (34.547)	mem 45.131
Train: [3][25/750]	BT 1.309 (1.712)	DT 1.250 (1.644)	loss 10.269 (10.269)	prob 0.139 (0.139)	GS 29.438 (29.438)	mem 45.038
Train: [3][30/750]	BT 0.614 (1.740)	DT 0.575 (1.674)	loss 10.264 (10.264)	prob 0.158 (0.158)	GS 38.781 (38.781)	mem 45.194
Train: [3][35/750]	BT 0.033 (1.552)	DT 0.002 (1.487)	loss 10.104 (10.104)	prob 0.372 (0.372)	GS 30.938 (30.938)	mem 45.163
Train: [3][40/750]	BT 0.034 (1.708)	DT 0.004 (1.646)	loss 9.878 (9.878)	prob 0.470 (0.470)	GS 32.828 (32.828)	mem 45.215
Train: [3][45/750]	BT 0.027 (1.544)	DT 0.001 (1.486)	loss 10.302 (10.302)	prob -0.212 (-0.212)	GS 28.047 (28.047)	mem 45.226
Train: [3][50/750]	BT 10.784 (1.617)	DT 10.741 (1.560)	loss 10.457 (10.457)	prob -0.845 (-0.845)	GS 32.141 (32.141)	mem 45.290
Train: [3][55/750]	BT 0.030 (1.475)	DT 0.001 (1.419)	loss 9.897 (9.897)	prob 0.071 (0.071)	GS 29.391 (29.391)	mem 45.270
Train: [3][60/750]	BT 0.032 (1.390)	DT 0.001 (1.334)	loss 9.774 (9.774)	prob -0.050 (-0.050)	GS 34.266 (34.266)	mem 45.266
Train: [3][65/750]	BT 0.087 (1.428)	DT 0.024 (1.372)	loss 10.153 (10.153)	prob -0.256 (-0.256)	GS 29.484 (29.484)	mem 45.288
Train: [3][70/750]	BT 0.068 (1.388)	DT 0.014 (1.333)	loss 10.250 (10.250)	prob -0.355 (-0.355)	GS 32.453 (32.453)	mem 45.316
Train: [3][75/750]	BT 0.032 (1.439)	DT 0.001 (1.385)	loss 10.065 (10.065)	prob -0.142 (-0.142)	GS 27.047 (27.047)	mem 45.321
Train: [3][80/750]	BT 2.478 (1.382)	DT 2.431 (1.329)	loss 10.532 (10.532)	prob -0.847 (-0.847)	GS 35.641 (35.641)	mem 45.276
Train: [3][85/750]	BT 0.035 (1.302)	DT 0.001 (1.251)	loss 10.311 (10.311)	prob -0.092 (-0.092)	GS 33.156 (33.156)	mem 45.382
Train: [3][90/750]	BT 0.027 (1.392)	DT 0.007 (1.342)	loss 9.972 (9.972)	prob -0.082 (-0.082)	GS 34.859 (34.859)	mem 45.366
Train: [3][95/750]	BT 0.034 (1.321)	DT 0.002 (1.272)	loss 10.249 (10.249)	prob -0.163 (-0.163)	GS 32.750 (32.750)	mem 45.648
Train: [3][100/750]	BT 0.030 (1.343)	DT 0.001 (1.293)	loss 10.582 (10.582)	prob -0.117 (-0.117)	GS 35.375 (35.375)	mem 45.370
Train: [3][105/750]	BT 0.034 (1.319)	DT 0.003 (1.270)	loss 10.513 (10.513)	prob -0.737 (-0.737)	GS 30.609 (30.609)	mem 45.343
Train: [3][110/750]	BT 8.157 (1.335)	DT 8.080 (1.286)	loss 10.457 (10.457)	prob -0.530 (-0.530)	GS 32.812 (32.812)	mem 45.527
Train: [3][115/750]	BT 0.087 (1.282)	DT 0.009 (1.231)	loss 10.562 (10.562)	prob -0.337 (-0.337)	GS 30.859 (30.859)	mem 45.562
Train: [3][120/750]	BT 1.170 (1.302)	DT 1.134 (1.252)	loss 10.168 (10.168)	prob -0.378 (-0.378)	GS 37.812 (37.812)	mem 45.459
Train: [3][125/750]	BT 0.034 (1.264)	DT 0.001 (1.214)	loss 10.270 (10.270)	prob 0.009 (0.009)	GS 30.625 (30.625)	mem 45.583
Train: [3][130/750]	BT 0.025 (1.301)	DT 0.001 (1.252)	loss 10.806 (10.806)	prob 0.160 (0.160)	GS 33.391 (33.391)	mem 45.696
Train: [3][135/750]	BT 0.073 (1.280)	DT 0.004 (1.231)	loss 9.969 (9.969)	prob 0.084 (0.084)	GS 31.453 (31.453)	mem 45.764
Train: [3][140/750]	BT 9.437 (1.303)	DT 9.403 (1.255)	loss 9.841 (9.841)	prob 0.699 (0.699)	GS 36.984 (36.984)	mem 45.641
Train: [3][145/750]	BT 0.034 (1.264)	DT 0.002 (1.216)	loss 10.477 (10.477)	prob -0.719 (-0.719)	GS 32.531 (32.531)	mem 45.654
Train: [3][150/750]	BT 0.025 (1.234)	DT 0.001 (1.186)	loss 9.932 (9.932)	prob 0.424 (0.424)	GS 37.453 (37.453)	mem 45.679
Train: [3][155/750]	BT 0.032 (1.265)	DT 0.001 (1.218)	loss 10.192 (10.192)	prob 0.589 (0.589)	GS 31.031 (31.031)	mem 45.674
Train: [3][160/750]	BT 0.034 (1.247)	DT 0.002 (1.201)	loss 10.041 (10.041)	prob -0.112 (-0.112)	GS 34.672 (34.672)	mem 45.906
Train: [3][165/750]	BT 0.045 (1.272)	DT 0.001 (1.224)	loss 10.347 (10.347)	prob -0.660 (-0.660)	GS 35.484 (35.484)	mem 45.900
Train: [3][170/750]	BT 0.033 (1.261)	DT 0.001 (1.214)	loss 9.830 (9.830)	prob 0.063 (0.063)	GS 34.375 (34.375)	mem 45.935
Train: [3][175/750]	BT 0.117 (1.227)	DT 0.045 (1.179)	loss 10.124 (10.124)	prob -0.080 (-0.080)	GS 35.406 (35.406)	mem 45.866
Train: [3][180/750]	BT 8.078 (1.279)	DT 8.039 (1.232)	loss 10.201 (10.201)	prob -0.002 (-0.002)	GS 37.406 (37.406)	mem 46.018
Train: [3][185/750]	BT 0.032 (1.246)	DT 0.002 (1.198)	loss 9.938 (9.938)	prob 0.698 (0.698)	GS 28.797 (28.797)	mem 46.069
Train: [3][190/750]	BT 0.025 (1.218)	DT 0.001 (1.171)	loss 10.364 (10.364)	prob -0.259 (-0.259)	GS 34.000 (34.000)	mem 45.970
Train: [3][195/750]	BT 0.034 (1.248)	DT 0.001 (1.201)	loss 10.505 (10.505)	prob -0.709 (-0.709)	GS 32.344 (32.344)	mem 46.003
Train: [3][200/750]	BT 1.539 (1.225)	DT 1.506 (1.179)	loss 10.211 (10.211)	prob -0.255 (-0.255)	GS 32.125 (32.125)	mem 46.048
Train: [3][205/750]	BT 0.068 (1.244)	DT 0.006 (1.198)	loss 9.774 (9.774)	prob 0.616 (0.616)	GS 31.547 (31.547)	mem 46.474
Train: [3][210/750]	BT 0.038 (1.216)	DT 0.010 (1.169)	loss 9.967 (9.967)	prob 0.350 (0.350)	GS 34.891 (34.891)	mem 46.027
Train: [3][215/750]	BT 0.143 (1.189)	DT 0.009 (1.142)	loss 10.107 (10.107)	prob 0.352 (0.352)	GS 32.078 (32.078)	mem 46.049
Train: [3][220/750]	BT 0.047 (1.217)	DT 0.010 (1.170)	loss 10.312 (10.312)	prob -0.111 (-0.111)	GS 34.531 (34.531)	mem 46.345
Train: [3][225/750]	BT 0.034 (1.202)	DT 0.002 (1.155)	loss 9.801 (9.801)	prob 0.268 (0.268)	GS 31.422 (31.422)	mem 46.083
Train: [3][230/750]	BT 0.059 (1.222)	DT 0.012 (1.174)	loss 9.961 (9.961)	prob -0.034 (-0.034)	GS 28.500 (28.500)	mem 45.981
Train: [3][235/750]	BT 0.104 (1.197)	DT 0.001 (1.150)	loss 10.178 (10.178)	prob -0.596 (-0.596)	GS 35.031 (35.031)	mem 45.982
Train: [3][240/750]	BT 12.608 (1.233)	DT 12.556 (1.186)	loss 10.214 (10.214)	prob -0.529 (-0.529)	GS 37.203 (37.203)	mem 46.184
Train: [3][245/750]	BT 0.093 (1.209)	DT 0.002 (1.162)	loss 9.611 (9.611)	prob 0.095 (0.095)	GS 32.641 (32.641)	mem 46.078
Train: [3][250/750]	BT 0.028 (1.195)	DT 0.001 (1.148)	loss 10.229 (10.229)	prob -0.423 (-0.423)	GS 30.656 (30.656)	mem 46.075
Train: [3][255/750]	BT 0.032 (1.221)	DT 0.001 (1.174)	loss 10.379 (10.379)	prob -0.109 (-0.109)	GS 33.781 (33.781)	mem 46.095
Train: [3][260/750]	BT 1.010 (1.203)	DT 0.975 (1.155)	loss 10.198 (10.198)	prob -0.177 (-0.177)	GS 36.109 (36.109)	mem 46.109
Train: [3][265/750]	BT 0.037 (1.225)	DT 0.003 (1.177)	loss 10.370 (10.370)	prob -0.932 (-0.932)	GS 32.984 (32.984)	mem 46.566
Train: [3][270/750]	BT 0.073 (1.203)	DT 0.002 (1.155)	loss 9.964 (9.964)	prob 0.095 (0.095)	GS 34.203 (34.203)	mem 46.262
Train: [3][275/750]	BT 0.063 (1.195)	DT 0.007 (1.148)	loss 10.649 (10.649)	prob -1.108 (-1.108)	GS 36.766 (36.766)	mem 46.269
Train: [3][280/750]	BT 0.032 (1.207)	DT 0.001 (1.159)	loss 10.292 (10.292)	prob -0.469 (-0.469)	GS 36.422 (36.422)	mem 46.159
Train: [3][285/750]	BT 0.029 (1.196)	DT 0.001 (1.149)	loss 10.655 (10.655)	prob -0.843 (-0.843)	GS 30.531 (30.531)	mem 46.139
Train: [3][290/750]	BT 0.033 (1.200)	DT 0.002 (1.154)	loss 10.576 (10.576)	prob -0.917 (-0.917)	GS 33.672 (33.672)	mem 46.200
Train: [3][295/750]	BT 0.038 (1.181)	DT 0.005 (1.134)	loss 10.355 (10.355)	prob -0.692 (-0.692)	GS 33.375 (33.375)	mem 46.485
Train: [3][300/750]	BT 9.750 (1.204)	DT 9.714 (1.158)	loss 9.715 (9.715)	prob -0.090 (-0.090)	GS 32.281 (32.281)	mem 46.198
Train: [3][305/750]	BT 0.071 (1.185)	DT 0.002 (1.139)	loss 9.940 (9.940)	prob 0.302 (0.302)	GS 35.031 (35.031)	mem 46.200
Train: [3][310/750]	BT 0.064 (1.192)	DT 0.010 (1.145)	loss 10.126 (10.126)	prob -0.335 (-0.335)	GS 33.891 (33.891)	mem 46.275
Train: [3][315/750]	BT 0.051 (1.186)	DT 0.003 (1.139)	loss 9.819 (9.819)	prob -0.286 (-0.286)	GS 31.922 (31.922)	mem 46.239
Train: [3][320/750]	BT 7.474 (1.191)	DT 7.395 (1.145)	loss 10.295 (10.295)	prob -0.818 (-0.818)	GS 31.266 (31.266)	mem 46.357
Train: [3][325/750]	BT 0.039 (1.189)	DT 0.004 (1.142)	loss 10.628 (10.628)	prob -1.132 (-1.132)	GS 27.422 (27.422)	mem 46.342
Train: [3][330/750]	BT 0.029 (1.172)	DT 0.003 (1.125)	loss 9.862 (9.862)	prob -0.753 (-0.753)	GS 31.656 (31.656)	mem 46.252
Train: [3][335/750]	BT 0.035 (1.180)	DT 0.002 (1.133)	loss 10.790 (10.790)	prob -1.335 (-1.335)	GS 32.266 (32.266)	mem 46.261
Train: [3][340/750]	BT 0.053 (1.183)	DT 0.001 (1.136)	loss 10.204 (10.204)	prob -0.897 (-0.897)	GS 34.312 (34.312)	mem 46.202
Train: [3][345/750]	BT 0.027 (1.187)	DT 0.001 (1.140)	loss 10.239 (10.239)	prob -0.849 (-0.849)	GS 29.516 (29.516)	mem 46.209
Train: [3][350/750]	BT 0.064 (1.197)	DT 0.002 (1.150)	loss 10.016 (10.016)	prob -0.533 (-0.533)	GS 30.906 (30.906)	mem 46.293
Train: [3][355/750]	BT 0.141 (1.181)	DT 0.007 (1.134)	loss 10.252 (10.252)	prob -0.795 (-0.795)	GS 30.531 (30.531)	mem 46.210
Train: [3][360/750]	BT 12.272 (1.205)	DT 12.250 (1.158)	loss 9.912 (9.912)	prob -0.162 (-0.162)	GS 31.062 (31.062)	mem 46.194
Train: [3][365/750]	BT 0.046 (1.189)	DT 0.002 (1.142)	loss 10.172 (10.172)	prob -0.803 (-0.803)	GS 34.531 (34.531)	mem 46.195
Train: [3][370/750]	BT 0.066 (1.174)	DT 0.002 (1.127)	loss 10.007 (10.007)	prob -0.269 (-0.269)	GS 38.516 (38.516)	mem 46.242
Train: [3][375/750]	BT 0.030 (1.197)	DT 0.001 (1.150)	loss 9.965 (9.965)	prob -0.542 (-0.542)	GS 32.109 (32.109)	mem 46.138
Train: [3][380/750]	BT 0.038 (1.182)	DT 0.003 (1.135)	loss 9.924 (9.924)	prob -0.087 (-0.087)	GS 30.016 (30.016)	mem 46.141
Train: [3][385/750]	BT 0.030 (1.201)	DT 0.002 (1.154)	loss 9.777 (9.777)	prob -0.161 (-0.161)	GS 30.203 (30.203)	mem 46.098
Train: [3][390/750]	BT 0.032 (1.186)	DT 0.002 (1.139)	loss 9.884 (9.884)	prob -0.222 (-0.222)	GS 33.797 (33.797)	mem 46.099
Train: [3][395/750]	BT 0.062 (1.172)	DT 0.007 (1.125)	loss 10.159 (10.159)	prob -0.661 (-0.661)	GS 30.359 (30.359)	mem 46.162
Train: [3][400/750]	BT 0.067 (1.188)	DT 0.002 (1.140)	loss 9.556 (9.556)	prob -0.098 (-0.098)	GS 34.500 (34.500)	mem 46.203
Train: [3][405/750]	BT 0.042 (1.173)	DT 0.002 (1.126)	loss 10.338 (10.338)	prob -0.923 (-0.923)	GS 32.641 (32.641)	mem 46.206
Train: [3][410/750]	BT 0.032 (1.187)	DT 0.001 (1.139)	loss 10.110 (10.110)	prob -0.817 (-0.817)	GS 35.984 (35.984)	mem 46.229
Train: [3][415/750]	BT 0.046 (1.173)	DT 0.010 (1.125)	loss 10.158 (10.158)	prob -0.959 (-0.959)	GS 30.656 (30.656)	mem 46.224
Train: [3][420/750]	BT 11.202 (1.193)	DT 11.166 (1.145)	loss 10.169 (10.169)	prob -0.528 (-0.528)	GS 32.969 (32.969)	mem 46.203
Train: [3][425/750]	BT 0.030 (1.179)	DT 0.001 (1.132)	loss 10.080 (10.080)	prob -0.576 (-0.576)	GS 31.359 (31.359)	mem 46.282
Train: [3][430/750]	BT 0.033 (1.172)	DT 0.003 (1.124)	loss 10.232 (10.232)	prob -0.329 (-0.329)	GS 32.266 (32.266)	mem 46.144
Train: [3][435/750]	BT 0.043 (1.192)	DT 0.001 (1.145)	loss 9.945 (9.945)	prob -0.243 (-0.243)	GS 34.016 (34.016)	mem 46.189
Train: [3][440/750]	BT 0.902 (1.181)	DT 0.796 (1.133)	loss 10.154 (10.154)	prob 0.068 (0.068)	GS 34.578 (34.578)	mem 46.006
Train: [3][445/750]	BT 0.029 (1.199)	DT 0.001 (1.152)	loss 10.194 (10.194)	prob -0.075 (-0.075)	GS 30.172 (30.172)	mem 46.070
Train: [3][450/750]	BT 0.031 (1.186)	DT 0.001 (1.139)	loss 10.265 (10.265)	prob -0.455 (-0.455)	GS 36.453 (36.453)	mem 46.071
Train: [3][455/750]	BT 0.037 (1.174)	DT 0.003 (1.127)	loss 10.361 (10.361)	prob -0.374 (-0.374)	GS 30.016 (30.016)	mem 46.087
Train: [3][460/750]	BT 0.027 (1.188)	DT 0.001 (1.142)	loss 10.312 (10.312)	prob -0.810 (-0.810)	GS 33.703 (33.703)	mem 46.066
Train: [3][465/750]	BT 0.031 (1.176)	DT 0.002 (1.130)	loss 9.593 (9.593)	prob 0.171 (0.171)	GS 26.438 (26.438)	mem 46.067
Train: [3][470/750]	BT 0.020 (1.190)	DT 0.001 (1.143)	loss 10.111 (10.111)	prob -0.561 (-0.561)	GS 30.453 (30.453)	mem 46.170
Train: [3][475/750]	BT 0.048 (1.177)	DT 0.001 (1.131)	loss 10.050 (10.050)	prob -0.259 (-0.259)	GS 35.156 (35.156)	mem 46.241
Train: [3][480/750]	BT 12.339 (1.191)	DT 12.313 (1.145)	loss 9.836 (9.836)	prob -0.236 (-0.236)	GS 33.516 (33.516)	mem 46.186
Train: [3][485/750]	BT 0.053 (1.179)	DT 0.016 (1.133)	loss 10.418 (10.418)	prob -0.822 (-0.822)	GS 32.188 (32.188)	mem 46.186
Train: [3][490/750]	BT 0.031 (1.168)	DT 0.001 (1.122)	loss 10.324 (10.324)	prob -0.549 (-0.549)	GS 36.719 (36.719)	mem 46.186
Train: [3][495/750]	BT 0.030 (1.179)	DT 0.001 (1.133)	loss 9.921 (9.921)	prob -0.764 (-0.764)	GS 22.953 (22.953)	mem 46.342
Train: [3][500/750]	BT 0.167 (1.168)	DT 0.124 (1.122)	loss 9.892 (9.892)	prob -0.497 (-0.497)	GS 34.031 (34.031)	mem 46.235
Train: [3][505/750]	BT 0.033 (1.181)	DT 0.002 (1.135)	loss 10.260 (10.260)	prob -0.474 (-0.474)	GS 27.016 (27.016)	mem 46.194
Train: [3][510/750]	BT 0.067 (1.170)	DT 0.002 (1.124)	loss 10.436 (10.436)	prob -0.664 (-0.664)	GS 30.703 (30.703)	mem 46.193
Train: [3][515/750]	BT 0.116 (1.163)	DT 0.034 (1.117)	loss 10.157 (10.157)	prob -0.480 (-0.480)	GS 29.000 (29.000)	mem 46.206
Train: [3][520/750]	BT 0.059 (1.174)	DT 0.014 (1.127)	loss 10.667 (10.667)	prob -0.936 (-0.936)	GS 36.484 (36.484)	mem 46.125
Train: [3][525/750]	BT 0.036 (1.171)	DT 0.002 (1.125)	loss 10.168 (10.168)	prob -0.395 (-0.395)	GS 34.172 (34.172)	mem 46.203
Train: [3][530/750]	BT 0.052 (1.177)	DT 0.002 (1.131)	loss 10.059 (10.059)	prob -0.121 (-0.121)	GS 28.297 (28.297)	mem 46.133
Train: [3][535/750]	BT 0.062 (1.167)	DT 0.012 (1.120)	loss 10.070 (10.070)	prob -0.901 (-0.901)	GS 28.578 (28.578)	mem 46.156
Train: [3][540/750]	BT 4.373 (1.179)	DT 4.290 (1.132)	loss 10.442 (10.442)	prob -1.018 (-1.018)	GS 32.188 (32.188)	mem 46.265
Train: [3][545/750]	BT 0.030 (1.168)	DT 0.003 (1.122)	loss 10.202 (10.202)	prob -0.668 (-0.668)	GS 33.031 (33.031)	mem 46.147
Train: [3][550/750]	BT 0.034 (1.171)	DT 0.003 (1.125)	loss 10.304 (10.304)	prob -0.785 (-0.785)	GS 32.562 (32.562)	mem 46.243
Train: [3][555/750]	BT 0.042 (1.173)	DT 0.015 (1.127)	loss 10.528 (10.528)	prob -1.002 (-1.002)	GS 31.391 (31.391)	mem 46.222
Train: [3][560/750]	BT 4.464 (1.171)	DT 4.432 (1.125)	loss 9.855 (9.855)	prob -0.085 (-0.085)	GS 32.844 (32.844)	mem 46.193
Train: [3][565/750]	BT 0.036 (1.170)	DT 0.001 (1.123)	loss 10.189 (10.189)	prob -0.627 (-0.627)	GS 34.312 (34.312)	mem 46.214
Train: [3][570/750]	BT 0.072 (1.160)	DT 0.002 (1.114)	loss 10.625 (10.625)	prob -1.005 (-1.005)	GS 35.703 (35.703)	mem 46.339
Train: [3][575/750]	BT 0.047 (1.163)	DT 0.004 (1.116)	loss 9.918 (9.918)	prob -0.719 (-0.719)	GS 31.203 (31.203)	mem 46.134
Train: [3][580/750]	BT 0.032 (1.162)	DT 0.002 (1.115)	loss 10.143 (10.143)	prob -0.872 (-0.872)	GS 32.766 (32.766)	mem 46.228
Train: [3][585/750]	BT 0.050 (1.170)	DT 0.002 (1.124)	loss 10.063 (10.063)	prob -0.575 (-0.575)	GS 34.219 (34.219)	mem 46.366
Train: [3][590/750]	BT 0.050 (1.161)	DT 0.005 (1.115)	loss 10.069 (10.069)	prob -0.324 (-0.324)	GS 36.297 (36.297)	mem 46.160
Train: [3][595/750]	BT 0.047 (1.154)	DT 0.004 (1.108)	loss 10.103 (10.103)	prob -0.446 (-0.446)	GS 34.469 (34.469)	mem 46.297
Train: [3][600/750]	BT 0.041 (1.165)	DT 0.001 (1.119)	loss 10.157 (10.157)	prob -0.874 (-0.874)	GS 31.297 (31.297)	mem 46.443
Train: [3][605/750]	BT 0.031 (1.156)	DT 0.002 (1.109)	loss 9.809 (9.809)	prob -0.680 (-0.680)	GS 31.672 (31.672)	mem 46.226
Train: [3][610/750]	BT 0.041 (1.168)	DT 0.002 (1.122)	loss 10.025 (10.025)	prob -0.609 (-0.609)	GS 35.203 (35.203)	mem 46.165
Train: [3][615/750]	BT 0.046 (1.159)	DT 0.002 (1.113)	loss 9.771 (9.771)	prob -0.423 (-0.423)	GS 32.844 (32.844)	mem 46.197
Train: [3][620/750]	BT 15.307 (1.175)	DT 15.252 (1.128)	loss 10.258 (10.258)	prob -0.761 (-0.761)	GS 32.062 (32.062)	mem 46.252
Train: [3][625/750]	BT 0.033 (1.166)	DT 0.001 (1.119)	loss 10.259 (10.259)	prob -0.482 (-0.482)	GS 48.172 (48.172)	mem 46.177
Train: [3][630/750]	BT 0.041 (1.161)	DT 0.002 (1.114)	loss 10.121 (10.121)	prob -0.484 (-0.484)	GS 34.703 (34.703)	mem 46.186
Train: [3][635/750]	BT 0.037 (1.167)	DT 0.001 (1.120)	loss 10.582 (10.582)	prob -0.891 (-0.891)	GS 29.578 (29.578)	mem 46.177
Train: [3][640/750]	BT 6.955 (1.169)	DT 6.872 (1.122)	loss 10.024 (10.024)	prob -0.401 (-0.401)	GS 34.312 (34.312)	mem 46.291
Train: [3][645/750]	BT 0.073 (1.167)	DT 0.007 (1.120)	loss 9.929 (9.929)	prob -0.659 (-0.659)	GS 31.094 (31.094)	mem 46.255
Train: [3][650/750]	BT 0.054 (1.159)	DT 0.010 (1.112)	loss 9.540 (9.540)	prob -0.255 (-0.255)	GS 33.672 (33.672)	mem 46.351
Train: [3][655/750]	BT 0.031 (1.169)	DT 0.001 (1.122)	loss 10.029 (10.029)	prob -0.619 (-0.619)	GS 27.484 (27.484)	mem 46.224
Train: [3][660/750]	BT 0.081 (1.160)	DT 0.007 (1.113)	loss 9.943 (9.943)	prob -0.582 (-0.582)	GS 34.938 (34.938)	mem 46.225
Train: [3][665/750]	BT 0.031 (1.172)	DT 0.005 (1.125)	loss 10.103 (10.103)	prob -0.476 (-0.476)	GS 33.656 (33.656)	mem 46.260
Train: [3][670/750]	BT 0.036 (1.164)	DT 0.008 (1.117)	loss 10.047 (10.047)	prob -0.683 (-0.683)	GS 32.672 (32.672)	mem 46.260
Train: [3][675/750]	BT 0.035 (1.156)	DT 0.005 (1.109)	loss 10.081 (10.081)	prob -0.802 (-0.802)	GS 33.375 (33.375)	mem 46.260
Train: [3][680/750]	BT 0.242 (1.165)	DT 0.195 (1.118)	loss 10.056 (10.056)	prob -0.572 (-0.572)	GS 35.109 (35.109)	mem 46.205
Train: [3][685/750]	BT 0.041 (1.160)	DT 0.003 (1.114)	loss 10.294 (10.294)	prob -1.016 (-1.016)	GS 34.000 (34.000)	mem 46.249
Train: [3][690/750]	BT 0.047 (1.169)	DT 0.009 (1.122)	loss 9.880 (9.880)	prob -0.582 (-0.582)	GS 36.391 (36.391)	mem 46.225
Train: [3][695/750]	BT 0.021 (1.161)	DT 0.001 (1.114)	loss 10.200 (10.200)	prob -0.959 (-0.959)	GS 29.188 (29.188)	mem 46.166
Train: [3][700/750]	BT 10.098 (1.170)	DT 10.068 (1.123)	loss 10.176 (10.176)	prob -1.048 (-1.048)	GS 33.781 (33.781)	mem 46.240
Train: [3][705/750]	BT 0.063 (1.162)	DT 0.012 (1.115)	loss 10.260 (10.260)	prob -1.177 (-1.177)	GS 29.672 (29.672)	mem 46.452
Train: [3][710/750]	BT 0.050 (1.157)	DT 0.005 (1.110)	loss 10.144 (10.144)	prob -0.812 (-0.812)	GS 37.328 (37.328)	mem 46.245
Train: [3][715/750]	BT 0.088 (1.163)	DT 0.001 (1.116)	loss 10.480 (10.480)	prob -1.636 (-1.636)	GS 31.109 (31.109)	mem 46.298
Train: [3][720/750]	BT 4.806 (1.162)	DT 4.752 (1.115)	loss 10.287 (10.287)	prob -1.251 (-1.251)	GS 37.625 (37.625)	mem 46.253
Train: [3][725/750]	BT 0.041 (1.165)	DT 0.004 (1.118)	loss 10.025 (10.025)	prob -0.757 (-0.757)	GS 31.391 (31.391)	mem 46.055
Train: [3][730/750]	BT 0.028 (1.157)	DT 0.001 (1.111)	loss 9.930 (9.930)	prob -0.768 (-0.768)	GS 31.875 (31.875)	mem 46.133
Train: [3][735/750]	BT 0.025 (1.158)	DT 0.001 (1.111)	loss 10.169 (10.169)	prob -0.839 (-0.839)	GS 31.734 (31.734)	mem 42.984
Train: [3][740/750]	BT 0.032 (1.156)	DT 0.001 (1.109)	loss 9.928 (9.928)	prob -0.573 (-0.573)	GS 30.016 (30.016)	mem 20.022
Train: [3][745/750]	BT 0.033 (1.150)	DT 0.002 (1.103)	loss 10.323 (10.323)	prob -1.027 (-1.027)	GS 33.469 (33.469)	mem 16.894
Train: [3][750/750]	BT 0.035 (1.145)	DT 0.001 (1.098)	loss 10.289 (10.289)	prob -0.723 (-0.723)	GS 33.625 (33.625)	mem 16.857
Train: [3][755/750]	BT 0.026 (1.137)	DT 0.001 (1.091)	loss 10.406 (10.406)	prob -0.805 (-0.805)	GS 30.406 (30.406)	mem 16.857
epoch 3, total time 859.86
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [4][1/750]	BT 23.810 (23.810)	DT 23.751 (23.751)	loss 9.994 (9.994)	prob -0.293 (-0.293)	GS 33.469 (33.469)	mem 45.960
Train: [4][5/750]	BT 0.034 (5.330)	DT 0.001 (5.286)	loss 9.994 (9.994)	prob -0.644 (-0.644)	GS 27.719 (27.719)	mem 45.994
Train: [4][10/750]	BT 0.061 (3.056)	DT 0.008 (3.016)	loss 10.085 (10.085)	prob -0.590 (-0.590)	GS 32.562 (32.562)	mem 44.911
Train: [4][15/750]	BT 0.075 (2.653)	DT 0.013 (2.608)	loss 10.186 (10.186)	prob -0.957 (-0.957)	GS 33.297 (33.297)	mem 45.100
Train: [4][20/750]	BT 0.035 (2.108)	DT 0.002 (2.064)	loss 9.562 (9.562)	prob -0.562 (-0.562)	GS 31.047 (31.047)	mem 45.240
Train: [4][25/750]	BT 2.954 (1.850)	DT 2.922 (1.804)	loss 9.508 (9.508)	prob -0.395 (-0.395)	GS 32.625 (32.625)	mem 45.124
Train: [4][30/750]	BT 2.287 (1.885)	DT 2.246 (1.840)	loss 9.475 (9.475)	prob -0.761 (-0.761)	GS 32.219 (32.219)	mem 45.179
Train: [4][35/750]	BT 0.135 (1.624)	DT 0.006 (1.578)	loss 9.779 (9.779)	prob -0.497 (-0.497)	GS 30.578 (30.578)	mem 45.186
Train: [4][40/750]	BT 2.870 (1.761)	DT 2.835 (1.715)	loss 9.928 (9.928)	prob -0.808 (-0.808)	GS 34.656 (34.656)	mem 45.254
Train: [4][45/750]	BT 0.031 (1.570)	DT 0.002 (1.525)	loss 9.984 (9.984)	prob -0.960 (-0.960)	GS 33.469 (33.469)	mem 45.293
Train: [4][50/750]	BT 7.537 (1.618)	DT 7.502 (1.575)	loss 9.650 (9.650)	prob -0.435 (-0.435)	GS 33.312 (33.312)	mem 45.300
Train: [4][55/750]	BT 0.069 (1.525)	DT 0.013 (1.479)	loss 9.352 (9.352)	prob -0.246 (-0.246)	GS 28.938 (28.938)	mem 45.264
Train: [4][60/750]	BT 0.057 (1.404)	DT 0.005 (1.356)	loss 9.146 (9.146)	prob -0.188 (-0.188)	GS 29.953 (29.953)	mem 45.267
Train: [4][65/750]	BT 0.086 (1.456)	DT 0.004 (1.408)	loss 9.856 (9.856)	prob -0.973 (-0.973)	GS 30.328 (30.328)	mem 45.333
Train: [4][70/750]	BT 0.088 (1.371)	DT 0.002 (1.322)	loss 9.412 (9.412)	prob -0.492 (-0.492)	GS 30.906 (30.906)	mem 45.456
Train: [4][75/750]	BT 0.022 (1.426)	DT 0.001 (1.379)	loss 9.612 (9.612)	prob -0.857 (-0.857)	GS 29.891 (29.891)	mem 45.459
Train: [4][80/750]	BT 0.034 (1.385)	DT 0.002 (1.338)	loss 9.789 (9.789)	prob -0.995 (-0.995)	GS 31.688 (31.688)	mem 45.535
Train: [4][85/750]	BT 0.027 (1.306)	DT 0.001 (1.259)	loss 10.098 (10.098)	prob -1.429 (-1.429)	GS 29.094 (29.094)	mem 45.668
Train: [4][90/750]	BT 0.098 (1.408)	DT 0.002 (1.361)	loss 9.886 (9.886)	prob -1.350 (-1.350)	GS 30.703 (30.703)	mem 45.640
Train: [4][95/750]	BT 0.028 (1.337)	DT 0.002 (1.289)	loss 9.494 (9.494)	prob -0.828 (-0.828)	GS 33.062 (33.062)	mem 45.640
Train: [4][100/750]	BT 9.370 (1.434)	DT 9.339 (1.388)	loss 9.383 (9.383)	prob -0.712 (-0.712)	GS 34.406 (34.406)	mem 45.775
Train: [4][105/750]	BT 0.032 (1.368)	DT 0.002 (1.322)	loss 9.702 (9.702)	prob -0.620 (-0.620)	GS 32.406 (32.406)	mem 45.774
Train: [4][110/750]	BT 0.097 (1.309)	DT 0.058 (1.262)	loss 9.371 (9.371)	prob -0.701 (-0.701)	GS 30.453 (30.453)	mem 45.776
Train: [4][115/750]	BT 0.047 (1.352)	DT 0.015 (1.306)	loss 9.757 (9.757)	prob -1.002 (-1.002)	GS 30.047 (30.047)	mem 45.918
Train: [4][120/750]	BT 0.127 (1.298)	DT 0.032 (1.252)	loss 10.006 (10.006)	prob -1.412 (-1.412)	GS 33.609 (33.609)	mem 45.935
Train: [4][125/750]	BT 0.025 (1.358)	DT 0.001 (1.312)	loss 9.467 (9.467)	prob -1.041 (-1.041)	GS 28.812 (28.812)	mem 45.918
Train: [4][130/750]	BT 0.034 (1.308)	DT 0.001 (1.262)	loss 9.689 (9.689)	prob -1.109 (-1.109)	GS 37.000 (37.000)	mem 45.918
Train: [4][135/750]	BT 0.062 (1.262)	DT 0.014 (1.216)	loss 9.763 (9.763)	prob -1.099 (-1.099)	GS 28.781 (28.781)	mem 45.972
Train: [4][140/750]	BT 0.022 (1.318)	DT 0.001 (1.272)	loss 10.166 (10.166)	prob -1.218 (-1.218)	GS 30.297 (30.297)	mem 45.917
Train: [4][145/750]	BT 0.031 (1.274)	DT 0.001 (1.228)	loss 10.013 (10.013)	prob -0.994 (-0.994)	GS 30.797 (30.797)	mem 45.918
Train: [4][150/750]	BT 0.022 (1.308)	DT 0.001 (1.263)	loss 9.931 (9.931)	prob -1.146 (-1.146)	GS 33.375 (33.375)	mem 46.052
Train: [4][155/750]	BT 0.027 (1.267)	DT 0.001 (1.223)	loss 9.761 (9.761)	prob -1.161 (-1.161)	GS 37.406 (37.406)	mem 45.999
Train: [4][160/750]	BT 12.239 (1.306)	DT 12.208 (1.261)	loss 9.798 (9.798)	prob -0.945 (-0.945)	GS 34.312 (34.312)	mem 46.077
Train: [4][165/750]	BT 0.064 (1.268)	DT 0.017 (1.223)	loss 9.814 (9.814)	prob -1.019 (-1.019)	GS 29.109 (29.109)	mem 46.133
Train: [4][170/750]	BT 0.102 (1.233)	DT 0.027 (1.188)	loss 9.537 (9.537)	prob -0.787 (-0.787)	GS 35.797 (35.797)	mem 46.047
Train: [4][175/750]	BT 0.043 (1.280)	DT 0.006 (1.235)	loss 10.001 (10.001)	prob -1.140 (-1.140)	GS 35.422 (35.422)	mem 46.083
Train: [4][180/750]	BT 0.040 (1.245)	DT 0.002 (1.200)	loss 9.706 (9.706)	prob -0.835 (-0.835)	GS 32.234 (32.234)	mem 46.000
Train: [4][185/750]	BT 0.031 (1.294)	DT 0.002 (1.249)	loss 9.954 (9.954)	prob -1.312 (-1.312)	GS 25.969 (25.969)	mem 46.054
Train: [4][190/750]	BT 0.049 (1.261)	DT 0.009 (1.216)	loss 9.708 (9.708)	prob -0.883 (-0.883)	GS 32.188 (32.188)	mem 46.054
Train: [4][195/750]	BT 0.044 (1.230)	DT 0.001 (1.185)	loss 10.109 (10.109)	prob -1.420 (-1.420)	GS 32.562 (32.562)	mem 46.104
Train: [4][200/750]	BT 0.051 (1.253)	DT 0.002 (1.209)	loss 9.404 (9.404)	prob -0.659 (-0.659)	GS 38.094 (38.094)	mem 46.099
Train: [4][205/750]	BT 0.093 (1.224)	DT 0.001 (1.179)	loss 9.607 (9.607)	prob -0.931 (-0.931)	GS 28.500 (28.500)	mem 46.135
Train: [4][210/750]	BT 0.034 (1.260)	DT 0.001 (1.215)	loss 9.502 (9.502)	prob -1.113 (-1.113)	GS 31.359 (31.359)	mem 46.340
Train: [4][215/750]	BT 0.073 (1.232)	DT 0.015 (1.187)	loss 9.577 (9.577)	prob -0.922 (-0.922)	GS 30.922 (30.922)	mem 46.135
Train: [4][220/750]	BT 13.779 (1.278)	DT 13.756 (1.232)	loss 9.645 (9.645)	prob -0.423 (-0.423)	GS 35.562 (35.562)	mem 46.169
Train: [4][225/750]	BT 0.049 (1.250)	DT 0.011 (1.205)	loss 10.032 (10.032)	prob -1.422 (-1.422)	GS 33.422 (33.422)	mem 46.179
Train: [4][230/750]	BT 1.945 (1.232)	DT 1.828 (1.187)	loss 9.800 (9.800)	prob -1.077 (-1.077)	GS 38.391 (38.391)	mem 46.393
Train: [4][235/750]	BT 0.057 (1.250)	DT 0.011 (1.204)	loss 9.493 (9.493)	prob -0.832 (-0.832)	GS 29.188 (29.188)	mem 46.390
Train: [4][240/750]	BT 0.126 (1.226)	DT 0.017 (1.180)	loss 9.853 (9.853)	prob -1.243 (-1.243)	GS 37.266 (37.266)	mem 46.437
Train: [4][245/750]	BT 0.033 (1.259)	DT 0.001 (1.213)	loss 8.955 (8.955)	prob -0.529 (-0.529)	GS 30.703 (30.703)	mem 44.533
Train: [4][250/750]	BT 0.040 (1.234)	DT 0.001 (1.188)	loss 10.326 (10.326)	prob -1.766 (-1.766)	GS 34.531 (34.531)	mem 44.492
Train: [4][255/750]	BT 0.137 (1.216)	DT 0.062 (1.170)	loss 9.603 (9.603)	prob -1.294 (-1.294)	GS 32.734 (32.734)	mem 44.499
Train: [4][260/750]	BT 0.034 (1.233)	DT 0.001 (1.187)	loss 9.709 (9.709)	prob -1.133 (-1.133)	GS 33.750 (33.750)	mem 44.538
Train: [4][265/750]	BT 0.033 (1.210)	DT 0.001 (1.165)	loss 9.510 (9.510)	prob -0.917 (-0.917)	GS 30.641 (30.641)	mem 44.592
Train: [4][270/750]	BT 0.022 (1.238)	DT 0.001 (1.193)	loss 9.680 (9.680)	prob -0.850 (-0.850)	GS 36.188 (36.188)	mem 44.607
Train: [4][275/750]	BT 0.065 (1.217)	DT 0.014 (1.171)	loss 9.631 (9.631)	prob -0.905 (-0.905)	GS 30.062 (30.062)	mem 44.632
Train: [4][280/750]	BT 13.518 (1.244)	DT 13.450 (1.199)	loss 9.525 (9.525)	prob -0.784 (-0.784)	GS 34.672 (34.672)	mem 44.611
Train: [4][285/750]	BT 0.066 (1.224)	DT 0.011 (1.178)	loss 9.512 (9.512)	prob -0.824 (-0.824)	GS 28.516 (28.516)	mem 44.613
Train: [4][290/750]	BT 0.115 (1.203)	DT 0.076 (1.158)	loss 9.831 (9.831)	prob -0.827 (-0.827)	GS 35.594 (35.594)	mem 44.613
Train: [4][295/750]	BT 0.064 (1.230)	DT 0.027 (1.185)	loss 9.297 (9.297)	prob -0.460 (-0.460)	GS 31.359 (31.359)	mem 44.486
Train: [4][300/750]	BT 0.048 (1.210)	DT 0.009 (1.166)	loss 9.137 (9.137)	prob -0.253 (-0.253)	GS 36.984 (36.984)	mem 44.486
Train: [4][305/750]	BT 0.051 (1.229)	DT 0.001 (1.184)	loss 9.379 (9.379)	prob -0.712 (-0.712)	GS 27.688 (27.688)	mem 44.572
Train: [4][310/750]	BT 0.068 (1.210)	DT 0.007 (1.165)	loss 9.898 (9.898)	prob -1.078 (-1.078)	GS 32.703 (32.703)	mem 44.573
Train: [4][315/750]	BT 0.053 (1.192)	DT 0.018 (1.147)	loss 9.618 (9.618)	prob -0.916 (-0.916)	GS 28.000 (28.000)	mem 44.573
Train: [4][320/750]	BT 0.031 (1.215)	DT 0.001 (1.170)	loss 9.153 (9.153)	prob -0.572 (-0.572)	GS 34.078 (34.078)	mem 44.577
Train: [4][325/750]	BT 0.055 (1.197)	DT 0.008 (1.152)	loss 9.316 (9.316)	prob -0.543 (-0.543)	GS 32.547 (32.547)	mem 44.581
Train: [4][330/750]	BT 0.029 (1.225)	DT 0.001 (1.180)	loss 9.614 (9.614)	prob -1.061 (-1.061)	GS 33.516 (33.516)	mem 44.490
Train: [4][335/750]	BT 0.035 (1.207)	DT 0.001 (1.163)	loss 9.607 (9.607)	prob -0.629 (-0.629)	GS 26.938 (26.938)	mem 44.453
Train: [4][340/750]	BT 10.843 (1.222)	DT 10.780 (1.178)	loss 9.635 (9.635)	prob -0.801 (-0.801)	GS 31.734 (31.734)	mem 44.728
Train: [4][345/750]	BT 0.044 (1.205)	DT 0.002 (1.161)	loss 9.232 (9.232)	prob -0.350 (-0.350)	GS 32.125 (32.125)	mem 44.598
Train: [4][350/750]	BT 0.112 (1.189)	DT 0.002 (1.144)	loss 9.371 (9.371)	prob -0.489 (-0.489)	GS 33.891 (33.891)	mem 44.599
Train: [4][355/750]	BT 0.092 (1.200)	DT 0.002 (1.155)	loss 9.815 (9.815)	prob -0.843 (-0.843)	GS 30.047 (30.047)	mem 44.563
Train: [4][360/750]	BT 0.092 (1.185)	DT 0.012 (1.139)	loss 9.436 (9.436)	prob -0.580 (-0.580)	GS 26.953 (26.953)	mem 44.564
Train: [4][365/750]	BT 0.024 (1.199)	DT 0.001 (1.153)	loss 9.685 (9.685)	prob -0.915 (-0.915)	GS 33.719 (33.719)	mem 44.595
Train: [4][370/750]	BT 0.063 (1.183)	DT 0.018 (1.138)	loss 9.738 (9.738)	prob -0.888 (-0.888)	GS 33.281 (33.281)	mem 44.702
Train: [4][375/750]	BT 0.032 (1.178)	DT 0.001 (1.132)	loss 9.304 (9.304)	prob -0.383 (-0.383)	GS 30.516 (30.516)	mem 44.622
Train: [4][380/750]	BT 0.037 (1.191)	DT 0.001 (1.145)	loss 9.272 (9.272)	prob -0.506 (-0.506)	GS 31.906 (31.906)	mem 44.587
Train: [4][385/750]	BT 0.035 (1.176)	DT 0.003 (1.130)	loss 9.038 (9.038)	prob -0.116 (-0.116)	GS 28.438 (28.438)	mem 44.741
Train: [4][390/750]	BT 0.098 (1.193)	DT 0.013 (1.147)	loss 9.708 (9.708)	prob -0.876 (-0.876)	GS 30.828 (30.828)	mem 44.651
Train: [4][395/750]	BT 0.097 (1.179)	DT 0.011 (1.132)	loss 9.376 (9.376)	prob -0.035 (-0.035)	GS 32.547 (32.547)	mem 44.617
Train: [4][400/750]	BT 5.601 (1.202)	DT 5.564 (1.156)	loss 9.052 (9.052)	prob -0.229 (-0.229)	GS 28.531 (28.531)	mem 44.642
Train: [4][405/750]	BT 0.039 (1.188)	DT 0.003 (1.142)	loss 10.170 (10.170)	prob -1.159 (-1.159)	GS 34.000 (34.000)	mem 44.653
Train: [4][410/750]	BT 6.020 (1.189)	DT 5.956 (1.143)	loss 9.484 (9.484)	prob -0.641 (-0.641)	GS 30.344 (30.344)	mem 44.668
Train: [4][415/750]	BT 0.034 (1.191)	DT 0.001 (1.144)	loss 9.264 (9.264)	prob -0.298 (-0.298)	GS 34.672 (34.672)	mem 44.796
Train: [4][420/750]	BT 0.034 (1.177)	DT 0.002 (1.131)	loss 9.142 (9.142)	prob -0.273 (-0.273)	GS 30.578 (30.578)	mem 44.637
Train: [4][425/750]	BT 0.037 (1.202)	DT 0.008 (1.156)	loss 9.820 (9.820)	prob -0.877 (-0.877)	GS 30.516 (30.516)	mem 44.614
Train: [4][430/750]	BT 0.053 (1.189)	DT 0.010 (1.143)	loss 9.572 (9.572)	prob -0.672 (-0.672)	GS 33.359 (33.359)	mem 44.749
Train: [4][435/750]	BT 0.143 (1.181)	DT 0.002 (1.135)	loss 9.329 (9.329)	prob -0.486 (-0.486)	GS 31.812 (31.812)	mem 44.777
Train: [4][440/750]	BT 0.065 (1.192)	DT 0.007 (1.145)	loss 8.874 (8.874)	prob -0.252 (-0.252)	GS 33.156 (33.156)	mem 44.617
Train: [4][445/750]	BT 0.060 (1.179)	DT 0.010 (1.133)	loss 9.703 (9.703)	prob -0.540 (-0.540)	GS 27.688 (27.688)	mem 44.692
Train: [4][450/750]	BT 0.024 (1.194)	DT 0.001 (1.148)	loss 8.776 (8.776)	prob 0.348 (0.348)	GS 30.109 (30.109)	mem 44.625
Train: [4][455/750]	BT 0.023 (1.181)	DT 0.001 (1.136)	loss 8.930 (8.930)	prob -0.061 (-0.061)	GS 30.406 (30.406)	mem 44.626
Train: [4][460/750]	BT 12.534 (1.197)	DT 12.494 (1.151)	loss 9.863 (9.863)	prob -0.964 (-0.964)	GS 31.688 (31.688)	mem 44.660
Train: [4][465/750]	BT 0.091 (1.185)	DT 0.001 (1.139)	loss 9.518 (9.518)	prob -0.647 (-0.647)	GS 29.906 (29.906)	mem 44.663
Train: [4][470/750]	BT 0.078 (1.173)	DT 0.002 (1.127)	loss 9.671 (9.671)	prob -0.462 (-0.462)	GS 32.391 (32.391)	mem 44.721
Train: [4][475/750]	BT 0.041 (1.185)	DT 0.001 (1.139)	loss 8.936 (8.936)	prob 0.196 (0.196)	GS 30.297 (30.297)	mem 44.638
Train: [4][480/750]	BT 0.032 (1.173)	DT 0.001 (1.127)	loss 9.313 (9.313)	prob -0.400 (-0.400)	GS 29.766 (29.766)	mem 44.588
Train: [4][485/750]	BT 0.061 (1.187)	DT 0.001 (1.142)	loss 9.553 (9.553)	prob -0.336 (-0.336)	GS 33.250 (33.250)	mem 44.676
Train: [4][490/750]	BT 0.032 (1.176)	DT 0.002 (1.130)	loss 9.921 (9.921)	prob -0.612 (-0.612)	GS 33.078 (33.078)	mem 44.677
Train: [4][495/750]	BT 0.043 (1.164)	DT 0.002 (1.119)	loss 9.152 (9.152)	prob 0.088 (0.088)	GS 28.531 (28.531)	mem 44.676
Train: [4][500/750]	BT 0.024 (1.182)	DT 0.001 (1.136)	loss 9.016 (9.016)	prob -0.122 (-0.122)	GS 32.516 (32.516)	mem 44.605
Train: [4][505/750]	BT 0.066 (1.170)	DT 0.026 (1.125)	loss 9.805 (9.805)	prob -0.290 (-0.290)	GS 30.312 (30.312)	mem 44.606
Train: [4][510/750]	BT 0.047 (1.183)	DT 0.006 (1.138)	loss 9.664 (9.664)	prob -0.573 (-0.573)	GS 36.609 (36.609)	mem 44.608
Train: [4][515/750]	BT 0.040 (1.172)	DT 0.002 (1.127)	loss 9.130 (9.130)	prob 0.058 (0.058)	GS 29.609 (29.609)	mem 44.627
Train: [4][520/750]	BT 14.189 (1.189)	DT 14.150 (1.144)	loss 9.325 (9.325)	prob -0.152 (-0.152)	GS 35.266 (35.266)	mem 44.322
Train: [4][525/750]	BT 0.026 (1.178)	DT 0.001 (1.133)	loss 9.415 (9.415)	prob 0.097 (0.097)	GS 31.953 (31.953)	mem 44.256
Train: [4][530/750]	BT 0.028 (1.167)	DT 0.001 (1.122)	loss 9.387 (9.387)	prob -0.152 (-0.152)	GS 34.781 (34.781)	mem 44.258
Train: [4][535/750]	BT 0.038 (1.184)	DT 0.007 (1.139)	loss 9.031 (9.031)	prob 0.167 (0.167)	GS 28.969 (28.969)	mem 44.334
Train: [4][540/750]	BT 0.040 (1.173)	DT 0.001 (1.129)	loss 9.577 (9.577)	prob -0.177 (-0.177)	GS 40.656 (40.656)	mem 44.381
Train: [4][545/750]	BT 0.045 (1.186)	DT 0.013 (1.141)	loss 9.333 (9.333)	prob 0.139 (0.139)	GS 35.094 (35.094)	mem 44.534
Train: [4][550/750]	BT 0.032 (1.175)	DT 0.001 (1.131)	loss 9.416 (9.416)	prob 0.043 (0.043)	GS 31.516 (31.516)	mem 44.435
Train: [4][555/750]	BT 0.031 (1.165)	DT 0.001 (1.121)	loss 9.224 (9.224)	prob 0.198 (0.198)	GS 35.641 (35.641)	mem 44.512
Train: [4][560/750]	BT 0.057 (1.176)	DT 0.006 (1.132)	loss 9.616 (9.616)	prob -0.343 (-0.343)	GS 29.281 (29.281)	mem 44.396
Train: [4][565/750]	BT 0.056 (1.166)	DT 0.002 (1.122)	loss 9.624 (9.624)	prob -0.091 (-0.091)	GS 32.312 (32.312)	mem 44.478
Train: [4][570/750]	BT 0.032 (1.177)	DT 0.002 (1.133)	loss 9.626 (9.626)	prob -0.198 (-0.198)	GS 37.031 (37.031)	mem 44.519
Train: [4][575/750]	BT 0.067 (1.167)	DT 0.010 (1.123)	loss 9.338 (9.338)	prob 0.040 (0.040)	GS 29.766 (29.766)	mem 44.488
Train: [4][580/750]	BT 15.497 (1.184)	DT 15.440 (1.140)	loss 9.404 (9.404)	prob 0.135 (0.135)	GS 34.562 (34.562)	mem 44.472
Train: [4][585/750]	BT 0.040 (1.175)	DT 0.003 (1.130)	loss 9.403 (9.403)	prob 0.095 (0.095)	GS 29.984 (29.984)	mem 44.596
Train: [4][590/750]	BT 0.025 (1.169)	DT 0.001 (1.125)	loss 8.983 (8.983)	prob 0.608 (0.608)	GS 32.766 (32.766)	mem 44.455
Train: [4][595/750]	BT 0.040 (1.174)	DT 0.002 (1.130)	loss 8.701 (8.701)	prob 0.693 (0.693)	GS 32.453 (32.453)	mem 44.596
Train: [4][600/750]	BT 0.112 (1.165)	DT 0.021 (1.121)	loss 9.447 (9.447)	prob 0.121 (0.121)	GS 33.094 (33.094)	mem 44.477
Train: [4][605/750]	BT 0.033 (1.177)	DT 0.002 (1.132)	loss 9.121 (9.121)	prob 0.522 (0.522)	GS 31.953 (31.953)	mem 44.515
Train: [4][610/750]	BT 0.034 (1.167)	DT 0.001 (1.123)	loss 9.370 (9.370)	prob 0.134 (0.134)	GS 36.625 (36.625)	mem 44.515
Train: [4][615/750]	BT 0.072 (1.159)	DT 0.022 (1.115)	loss 9.451 (9.451)	prob 0.144 (0.144)	GS 32.250 (32.250)	mem 44.451
Train: [4][620/750]	BT 0.036 (1.167)	DT 0.003 (1.123)	loss 9.054 (9.054)	prob 0.407 (0.407)	GS 30.125 (30.125)	mem 44.707
Train: [4][625/750]	BT 0.036 (1.159)	DT 0.001 (1.115)	loss 9.168 (9.168)	prob 0.379 (0.379)	GS 31.797 (31.797)	mem 44.450
Train: [4][630/750]	BT 0.087 (1.168)	DT 0.020 (1.124)	loss 9.804 (9.804)	prob -0.345 (-0.345)	GS 37.703 (37.703)	mem 44.459
Train: [4][635/750]	BT 0.073 (1.159)	DT 0.002 (1.115)	loss 9.472 (9.472)	prob 0.039 (0.039)	GS 44.500 (44.500)	mem 44.535
Train: [4][640/750]	BT 12.675 (1.170)	DT 12.637 (1.126)	loss 9.469 (9.469)	prob 0.218 (0.218)	GS 34.703 (34.703)	mem 44.504
Train: [4][645/750]	BT 0.078 (1.165)	DT 0.001 (1.120)	loss 9.182 (9.182)	prob 0.466 (0.466)	GS 34.859 (34.859)	mem 44.446
Train: [4][650/750]	BT 0.040 (1.156)	DT 0.003 (1.112)	loss 9.045 (9.045)	prob 0.741 (0.741)	GS 31.297 (31.297)	mem 44.445
Train: [4][655/750]	BT 0.044 (1.166)	DT 0.013 (1.122)	loss 9.809 (9.809)	prob 0.346 (0.346)	GS 32.312 (32.312)	mem 44.491
Train: [4][660/750]	BT 0.030 (1.158)	DT 0.001 (1.113)	loss 9.278 (9.278)	prob 0.620 (0.620)	GS 31.359 (31.359)	mem 44.494
Train: [4][665/750]	BT 0.045 (1.159)	DT 0.002 (1.115)	loss 9.553 (9.553)	prob 0.469 (0.469)	GS 33.391 (33.391)	mem 44.522
Train: [4][670/750]	BT 1.595 (1.159)	DT 1.545 (1.114)	loss 9.166 (9.166)	prob 0.735 (0.735)	GS 35.312 (35.312)	mem 44.471
Train: [4][675/750]	BT 0.042 (1.150)	DT 0.002 (1.106)	loss 8.998 (8.998)	prob 0.858 (0.858)	GS 26.609 (26.609)	mem 44.541
Train: [4][680/750]	BT 0.030 (1.156)	DT 0.001 (1.111)	loss 9.004 (9.004)	prob 0.949 (0.949)	GS 35.109 (35.109)	mem 44.498
Train: [4][685/750]	BT 0.042 (1.153)	DT 0.002 (1.109)	loss 9.728 (9.728)	prob 0.172 (0.172)	GS 33.297 (33.297)	mem 44.483
Train: [4][690/750]	BT 6.505 (1.165)	DT 6.464 (1.121)	loss 9.559 (9.559)	prob 0.338 (0.338)	GS 32.953 (32.953)	mem 44.480
Train: [4][695/750]	BT 0.102 (1.160)	DT 0.020 (1.115)	loss 9.325 (9.325)	prob 0.286 (0.286)	GS 31.953 (31.953)	mem 44.482
Train: [4][700/750]	BT 8.561 (1.164)	DT 8.506 (1.119)	loss 9.499 (9.499)	prob 0.208 (0.208)	GS 32.688 (32.688)	mem 44.504
Train: [4][705/750]	BT 0.064 (1.158)	DT 0.001 (1.113)	loss 9.448 (9.448)	prob 0.579 (0.579)	GS 29.609 (29.609)	mem 44.544
Train: [4][710/750]	BT 0.071 (1.155)	DT 0.001 (1.110)	loss 9.409 (9.409)	prob 0.265 (0.265)	GS 33.688 (33.688)	mem 44.515
Train: [4][715/750]	BT 0.037 (1.159)	DT 0.001 (1.114)	loss 10.126 (10.126)	prob 0.084 (0.084)	GS 29.781 (29.781)	mem 44.492
Train: [4][720/750]	BT 0.050 (1.156)	DT 0.009 (1.111)	loss 9.336 (9.336)	prob 0.648 (0.648)	GS 37.969 (37.969)	mem 44.374
Train: [4][725/750]	BT 0.030 (1.160)	DT 0.002 (1.115)	loss 9.780 (9.780)	prob 0.286 (0.286)	GS 35.219 (35.219)	mem 44.211
Train: [4][730/750]	BT 3.768 (1.161)	DT 3.736 (1.116)	loss 9.288 (9.288)	prob 0.483 (0.483)	GS 35.203 (35.203)	mem 44.116
Train: [4][735/750]	BT 0.097 (1.153)	DT 0.001 (1.108)	loss 8.965 (8.965)	prob 0.880 (0.880)	GS 31.047 (31.047)	mem 44.199
Train: [4][740/750]	BT 3.666 (1.157)	DT 3.615 (1.112)	loss 9.628 (9.628)	prob 0.514 (0.514)	GS 33.438 (33.438)	mem 21.101
Train: [4][745/750]	BT 0.028 (1.150)	DT 0.001 (1.105)	loss 9.366 (9.366)	prob 0.477 (0.477)	GS 29.812 (29.812)	mem 18.112
Train: [4][750/750]	BT 0.020 (1.142)	DT 0.001 (1.098)	loss 9.237 (9.237)	prob 0.939 (0.939)	GS 30.688 (30.688)	mem 18.111
Train: [4][755/750]	BT 0.026 (1.140)	DT 0.001 (1.095)	loss 8.964 (8.964)	prob 1.116 (1.116)	GS 30.688 (30.688)	mem 12.112
epoch 4, total time 860.58
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [5][1/750]	BT 21.228 (21.228)	DT 21.147 (21.147)	loss 10.089 (10.089)	prob 0.405 (0.405)	GS 28.625 (28.625)	mem 43.038
Train: [5][5/750]	BT 0.106 (5.277)	DT 0.010 (5.217)	loss 9.739 (9.739)	prob 0.440 (0.440)	GS 38.000 (38.000)	mem 43.398
Train: [5][10/750]	BT 0.035 (2.661)	DT 0.002 (2.610)	loss 9.072 (9.072)	prob 0.964 (0.964)	GS 31.484 (31.484)	mem 43.184
Train: [5][15/750]	BT 3.087 (2.478)	DT 3.033 (2.428)	loss 9.234 (9.234)	prob 1.098 (1.098)	GS 31.469 (31.469)	mem 43.209
Train: [5][20/750]	BT 0.071 (2.359)	DT 0.015 (2.306)	loss 9.379 (9.379)	prob 0.603 (0.603)	GS 37.094 (37.094)	mem 43.363
Train: [5][25/750]	BT 0.081 (1.898)	DT 0.005 (1.845)	loss 9.237 (9.237)	prob 0.990 (0.990)	GS 30.562 (30.562)	mem 43.237
Train: [5][30/750]	BT 0.033 (1.954)	DT 0.002 (1.901)	loss 9.108 (9.108)	prob 1.016 (1.016)	GS 29.922 (29.922)	mem 43.375
Train: [5][35/750]	BT 0.051 (1.684)	DT 0.001 (1.630)	loss 9.987 (9.987)	prob 0.588 (0.588)	GS 31.953 (31.953)	mem 43.376
Train: [5][40/750]	BT 15.050 (1.855)	DT 15.016 (1.802)	loss 9.229 (9.229)	prob 1.066 (1.066)	GS 31.859 (31.859)	mem 43.777
Train: [5][45/750]	BT 0.043 (1.653)	DT 0.005 (1.602)	loss 9.128 (9.128)	prob 1.305 (1.305)	GS 31.375 (31.375)	mem 43.778
Train: [5][50/750]	BT 0.026 (1.491)	DT 0.001 (1.442)	loss 9.349 (9.349)	prob 0.944 (0.944)	GS 36.625 (36.625)	mem 43.817
Train: [5][55/750]	BT 0.106 (1.563)	DT 0.003 (1.512)	loss 9.011 (9.011)	prob 1.206 (1.206)	GS 29.391 (29.391)	mem 43.937
Train: [5][60/750]	BT 0.042 (1.437)	DT 0.001 (1.387)	loss 9.099 (9.099)	prob 1.239 (1.239)	GS 35.031 (35.031)	mem 43.938
Train: [5][65/750]	BT 0.046 (1.529)	DT 0.002 (1.478)	loss 9.616 (9.616)	prob 0.905 (0.905)	GS 27.406 (27.406)	mem 43.995
Train: [5][70/750]	BT 0.028 (1.422)	DT 0.001 (1.373)	loss 9.372 (9.372)	prob 0.998 (0.998)	GS 35.203 (35.203)	mem 43.996
Train: [5][75/750]	BT 0.045 (1.343)	DT 0.003 (1.294)	loss 9.566 (9.566)	prob 1.396 (1.396)	GS 31.047 (31.047)	mem 44.106
Train: [5][80/750]	BT 0.027 (1.445)	DT 0.001 (1.397)	loss 9.424 (9.424)	prob 0.750 (0.750)	GS 32.422 (32.422)	mem 43.991
Train: [5][85/750]	BT 0.034 (1.362)	DT 0.001 (1.315)	loss 9.789 (9.789)	prob 0.762 (0.762)	GS 31.766 (31.766)	mem 44.028
Train: [5][90/750]	BT 0.045 (1.428)	DT 0.002 (1.382)	loss 9.681 (9.681)	prob 0.639 (0.639)	GS 35.734 (35.734)	mem 44.046
Train: [5][95/750]	BT 0.035 (1.355)	DT 0.002 (1.309)	loss 9.619 (9.619)	prob 1.082 (1.082)	GS 31.531 (31.531)	mem 44.050
Train: [5][100/750]	BT 10.863 (1.415)	DT 10.834 (1.371)	loss 8.985 (8.985)	prob 1.624 (1.624)	GS 36.094 (36.094)	mem 44.072
Train: [5][105/750]	BT 0.043 (1.350)	DT 0.009 (1.306)	loss 9.081 (9.081)	prob 1.294 (1.294)	GS 27.391 (27.391)	mem 44.070
Train: [5][110/750]	BT 5.339 (1.339)	DT 5.305 (1.295)	loss 9.406 (9.406)	prob 0.853 (0.853)	GS 33.031 (33.031)	mem 44.145
Train: [5][115/750]	BT 0.030 (1.337)	DT 0.001 (1.294)	loss 9.657 (9.657)	prob 0.885 (0.885)	GS 32.453 (32.453)	mem 44.120
Train: [5][120/750]	BT 0.097 (1.284)	DT 0.012 (1.240)	loss 9.228 (9.228)	prob 1.064 (1.064)	GS 35.797 (35.797)	mem 44.088
Train: [5][125/750]	BT 0.034 (1.317)	DT 0.002 (1.274)	loss 9.588 (9.588)	prob 0.958 (0.958)	GS 33.516 (33.516)	mem 44.130
Train: [5][130/750]	BT 0.090 (1.269)	DT 0.003 (1.225)	loss 9.661 (9.661)	prob 0.626 (0.626)	GS 34.062 (34.062)	mem 44.139
Train: [5][135/750]	BT 0.093 (1.292)	DT 0.006 (1.247)	loss 9.116 (9.116)	prob 1.428 (1.428)	GS 27.078 (27.078)	mem 44.216
Train: [5][140/750]	BT 0.030 (1.274)	DT 0.001 (1.231)	loss 9.662 (9.662)	prob 1.031 (1.031)	GS 34.953 (34.953)	mem 44.181
Train: [5][145/750]	BT 0.098 (1.234)	DT 0.008 (1.188)	loss 9.524 (9.524)	prob 1.030 (1.030)	GS 29.078 (29.078)	mem 44.142
Train: [5][150/750]	BT 1.817 (1.280)	DT 1.782 (1.234)	loss 9.040 (9.040)	prob 1.579 (1.579)	GS 38.172 (38.172)	mem 44.261
Train: [5][155/750]	BT 0.048 (1.239)	DT 0.003 (1.194)	loss 9.449 (9.449)	prob 1.084 (1.084)	GS 29.578 (29.578)	mem 44.225
Train: [5][160/750]	BT 6.341 (1.280)	DT 6.297 (1.235)	loss 9.686 (9.686)	prob 0.702 (0.702)	GS 34.578 (34.578)	mem 44.226
Train: [5][165/750]	BT 0.054 (1.262)	DT 0.018 (1.216)	loss 9.266 (9.266)	prob 1.417 (1.417)	GS 32.312 (32.312)	mem 44.349
Train: [5][170/750]	BT 7.783 (1.271)	DT 7.751 (1.226)	loss 10.536 (10.536)	prob 0.398 (0.398)	GS 35.750 (35.750)	mem 44.211
Train: [5][175/750]	BT 0.052 (1.256)	DT 0.014 (1.210)	loss 9.650 (9.650)	prob 1.149 (1.149)	GS 29.359 (29.359)	mem 44.402
Train: [5][180/750]	BT 0.026 (1.222)	DT 0.001 (1.177)	loss 9.114 (9.114)	prob 1.983 (1.983)	GS 34.297 (34.297)	mem 44.239
Train: [5][185/750]	BT 0.032 (1.254)	DT 0.002 (1.209)	loss 9.546 (9.546)	prob 1.412 (1.412)	GS 30.000 (30.000)	mem 44.376
Train: [5][190/750]	BT 0.035 (1.228)	DT 0.001 (1.183)	loss 9.670 (9.670)	prob 1.150 (1.150)	GS 34.453 (34.453)	mem 44.250
Train: [5][195/750]	BT 0.031 (1.263)	DT 0.002 (1.218)	loss 9.068 (9.068)	prob 1.554 (1.554)	GS 33.047 (33.047)	mem 44.281
Train: [5][200/750]	BT 0.031 (1.232)	DT 0.001 (1.188)	loss 10.020 (10.020)	prob 0.889 (0.889)	GS 33.547 (33.547)	mem 44.282
Train: [5][205/750]	BT 0.056 (1.218)	DT 0.001 (1.174)	loss 9.020 (9.020)	prob 1.708 (1.708)	GS 28.125 (28.125)	mem 44.329
Train: [5][210/750]	BT 0.033 (1.234)	DT 0.003 (1.190)	loss 9.226 (9.226)	prob 1.617 (1.617)	GS 29.734 (29.734)	mem 44.250
Train: [5][215/750]	BT 0.033 (1.206)	DT 0.002 (1.162)	loss 9.471 (9.471)	prob 1.067 (1.067)	GS 33.000 (33.000)	mem 44.249
Train: [5][220/750]	BT 0.042 (1.226)	DT 0.001 (1.182)	loss 9.185 (9.185)	prob 1.445 (1.445)	GS 30.828 (30.828)	mem 44.382
Train: [5][225/750]	BT 0.044 (1.200)	DT 0.012 (1.156)	loss 9.677 (9.677)	prob 1.330 (1.330)	GS 30.016 (30.016)	mem 44.619
Train: [5][230/750]	BT 8.836 (1.234)	DT 8.798 (1.190)	loss 9.293 (9.293)	prob 1.391 (1.391)	GS 34.781 (34.781)	mem 44.383
Train: [5][235/750]	BT 0.030 (1.208)	DT 0.001 (1.165)	loss 9.100 (9.100)	prob 1.373 (1.373)	GS 28.484 (28.484)	mem 44.383
Train: [5][240/750]	BT 5.996 (1.209)	DT 5.964 (1.165)	loss 9.227 (9.227)	prob 1.387 (1.387)	GS 31.156 (31.156)	mem 44.419
Train: [5][245/750]	BT 0.031 (1.204)	DT 0.001 (1.160)	loss 9.415 (9.415)	prob 1.243 (1.243)	GS 32.219 (32.219)	mem 44.433
Train: [5][250/750]	BT 0.047 (1.181)	DT 0.002 (1.137)	loss 9.173 (9.173)	prob 1.490 (1.490)	GS 35.141 (35.141)	mem 44.433
Train: [5][255/750]	BT 0.087 (1.218)	DT 0.010 (1.174)	loss 9.298 (9.298)	prob 1.560 (1.560)	GS 30.859 (30.859)	mem 44.247
Train: [5][260/750]	BT 0.031 (1.195)	DT 0.001 (1.151)	loss 9.630 (9.630)	prob 1.779 (1.779)	GS 33.062 (33.062)	mem 44.256
Train: [5][265/750]	BT 0.144 (1.190)	DT 0.003 (1.146)	loss 9.647 (9.647)	prob 1.386 (1.386)	GS 31.312 (31.312)	mem 44.323
Train: [5][270/750]	BT 0.052 (1.198)	DT 0.003 (1.154)	loss 9.654 (9.654)	prob 1.059 (1.059)	GS 33.844 (33.844)	mem 44.368
Train: [5][275/750]	BT 0.117 (1.177)	DT 0.013 (1.133)	loss 9.301 (9.301)	prob 1.437 (1.437)	GS 31.703 (31.703)	mem 44.569
Train: [5][280/750]	BT 0.038 (1.193)	DT 0.002 (1.148)	loss 9.442 (9.442)	prob 1.386 (1.386)	GS 35.891 (35.891)	mem 44.389
Train: [5][285/750]	BT 0.056 (1.175)	DT 0.001 (1.131)	loss 9.005 (9.005)	prob 1.800 (1.800)	GS 37.797 (37.797)	mem 44.507
Train: [5][290/750]	BT 2.653 (1.184)	DT 2.622 (1.139)	loss 9.139 (9.139)	prob 1.655 (1.655)	GS 35.375 (35.375)	mem 44.398
Train: [5][295/750]	BT 0.032 (1.177)	DT 0.007 (1.132)	loss 9.459 (9.459)	prob 1.610 (1.610)	GS 32.250 (32.250)	mem 44.404
Train: [5][300/750]	BT 5.855 (1.177)	DT 5.802 (1.132)	loss 9.431 (9.431)	prob 1.549 (1.549)	GS 34.047 (34.047)	mem 44.529
Train: [5][305/750]	BT 0.035 (1.176)	DT 0.001 (1.131)	loss 9.023 (9.023)	prob 1.986 (1.986)	GS 31.672 (31.672)	mem 44.467
Train: [5][310/750]	BT 0.024 (1.164)	DT 0.001 (1.119)	loss 9.428 (9.428)	prob 1.309 (1.309)	GS 33.375 (33.375)	mem 44.353
Train: [5][315/750]	BT 0.051 (1.180)	DT 0.008 (1.136)	loss 9.305 (9.305)	prob 1.913 (1.913)	GS 39.438 (39.438)	mem 44.369
Train: [5][320/750]	BT 1.079 (1.166)	DT 1.043 (1.121)	loss 9.347 (9.347)	prob 1.673 (1.673)	GS 36.219 (36.219)	mem 44.343
Train: [5][325/750]	BT 0.028 (1.160)	DT 0.002 (1.115)	loss 9.784 (9.784)	prob 1.098 (1.098)	GS 36.172 (36.172)	mem 44.385
Train: [5][330/750]	BT 0.023 (1.169)	DT 0.001 (1.124)	loss 9.626 (9.626)	prob 1.453 (1.453)	GS 33.734 (33.734)	mem 44.370
Train: [5][335/750]	BT 0.032 (1.161)	DT 0.001 (1.116)	loss 9.936 (9.936)	prob 1.407 (1.407)	GS 31.516 (31.516)	mem 44.329
Train: [5][340/750]	BT 2.563 (1.166)	DT 2.512 (1.121)	loss 9.055 (9.055)	prob 2.036 (2.036)	GS 29.188 (29.188)	mem 44.611
Train: [5][345/750]	BT 0.080 (1.167)	DT 0.011 (1.122)	loss 9.248 (9.248)	prob 1.946 (1.946)	GS 33.469 (33.469)	mem 44.341
Train: [5][350/750]	BT 6.958 (1.171)	DT 6.926 (1.126)	loss 9.494 (9.494)	prob 1.382 (1.382)	GS 34.234 (34.234)	mem 44.347
Train: [5][355/750]	BT 0.047 (1.165)	DT 0.014 (1.120)	loss 9.804 (9.804)	prob 1.313 (1.313)	GS 31.781 (31.781)	mem 44.334
Train: [5][360/750]	BT 0.040 (1.163)	DT 0.002 (1.118)	loss 9.367 (9.367)	prob 1.710 (1.710)	GS 31.406 (31.406)	mem 44.417
Train: [5][365/750]	BT 0.031 (1.162)	DT 0.001 (1.117)	loss 9.533 (9.533)	prob 1.640 (1.640)	GS 30.047 (30.047)	mem 44.405
Train: [5][370/750]	BT 0.024 (1.164)	DT 0.001 (1.119)	loss 9.077 (9.077)	prob 1.841 (1.841)	GS 28.656 (28.656)	mem 44.373
Train: [5][375/750]	BT 0.026 (1.175)	DT 0.001 (1.130)	loss 9.858 (9.858)	prob 1.326 (1.326)	GS 47.516 (47.516)	mem 44.314
Train: [5][380/750]	BT 0.983 (1.163)	DT 0.944 (1.118)	loss 8.803 (8.803)	prob 2.047 (2.047)	GS 27.438 (27.438)	mem 44.350
Train: [5][385/750]	BT 0.060 (1.148)	DT 0.001 (1.103)	loss 9.509 (9.509)	prob 1.937 (1.937)	GS 29.688 (29.688)	mem 44.348
Train: [5][390/750]	BT 0.058 (1.162)	DT 0.007 (1.117)	loss 9.155 (9.155)	prob 1.859 (1.859)	GS 32.312 (32.312)	mem 44.412
Train: [5][395/750]	BT 0.066 (1.149)	DT 0.017 (1.103)	loss 9.326 (9.326)	prob 1.568 (1.568)	GS 31.672 (31.672)	mem 44.483
Train: [5][400/750]	BT 0.040 (1.162)	DT 0.006 (1.116)	loss 9.223 (9.223)	prob 1.736 (1.736)	GS 30.438 (30.438)	mem 44.518
Train: [5][405/750]	BT 0.037 (1.158)	DT 0.006 (1.113)	loss 9.260 (9.260)	prob 2.031 (2.031)	GS 28.203 (28.203)	mem 44.426
Train: [5][410/750]	BT 6.222 (1.160)	DT 6.194 (1.115)	loss 8.543 (8.543)	prob 2.260 (2.260)	GS 29.062 (29.062)	mem 44.396
Train: [5][415/750]	BT 0.061 (1.161)	DT 0.005 (1.116)	loss 9.178 (9.178)	prob 1.768 (1.768)	GS 31.875 (31.875)	mem 44.522
Train: [5][420/750]	BT 0.036 (1.148)	DT 0.001 (1.103)	loss 9.906 (9.906)	prob 1.863 (1.863)	GS 34.875 (34.875)	mem 44.545
Train: [5][425/750]	BT 0.118 (1.146)	DT 0.002 (1.101)	loss 9.009 (9.009)	prob 2.134 (2.134)	GS 27.234 (27.234)	mem 44.507
Train: [5][430/750]	BT 0.026 (1.152)	DT 0.001 (1.107)	loss 9.685 (9.685)	prob 1.336 (1.336)	GS 37.578 (37.578)	mem 44.500
Train: [5][435/750]	BT 0.131 (1.149)	DT 0.026 (1.104)	loss 9.231 (9.231)	prob 1.778 (1.778)	GS 32.844 (32.844)	mem 44.486
Train: [5][440/750]	BT 1.272 (1.155)	DT 1.219 (1.110)	loss 8.954 (8.954)	prob 1.926 (1.926)	GS 33.188 (33.188)	mem 44.515
Train: [5][445/750]	BT 0.032 (1.142)	DT 0.002 (1.097)	loss 9.112 (9.112)	prob 1.869 (1.869)	GS 29.797 (29.797)	mem 44.477
Train: [5][450/750]	BT 9.405 (1.157)	DT 9.376 (1.112)	loss 9.836 (9.836)	prob 1.465 (1.465)	GS 32.500 (32.500)	mem 44.403
Train: [5][455/750]	BT 0.056 (1.147)	DT 0.012 (1.102)	loss 10.479 (10.479)	prob 1.173 (1.173)	GS 32.969 (32.969)	mem 44.208
Train: [5][460/750]	BT 0.031 (1.142)	DT 0.002 (1.097)	loss 9.159 (9.159)	prob 2.101 (2.101)	GS 32.984 (32.984)	mem 44.338
Train: [5][465/750]	BT 0.037 (1.146)	DT 0.003 (1.101)	loss 9.327 (9.327)	prob 1.873 (1.873)	GS 31.594 (31.594)	mem 44.436
Train: [5][470/750]	BT 5.200 (1.146)	DT 5.165 (1.101)	loss 9.211 (9.211)	prob 2.071 (2.071)	GS 31.312 (31.312)	mem 44.543
Train: [5][475/750]	BT 0.050 (1.143)	DT 0.003 (1.098)	loss 8.780 (8.780)	prob 2.420 (2.420)	GS 30.844 (30.844)	mem 44.568
Train: [5][480/750]	BT 0.450 (1.144)	DT 0.417 (1.099)	loss 8.800 (8.800)	prob 1.898 (1.898)	GS 33.812 (33.812)	mem 44.512
Train: [5][485/750]	BT 0.062 (1.136)	DT 0.012 (1.091)	loss 9.293 (9.293)	prob 1.941 (1.941)	GS 29.484 (29.484)	mem 44.466
Train: [5][490/750]	BT 0.050 (1.146)	DT 0.011 (1.101)	loss 9.689 (9.689)	prob 1.613 (1.613)	GS 36.953 (36.953)	mem 44.444
Train: [5][495/750]	BT 0.031 (1.140)	DT 0.001 (1.095)	loss 9.000 (9.000)	prob 2.062 (2.062)	GS 31.891 (31.891)	mem 44.378
Train: [5][500/750]	BT 0.245 (1.145)	DT 0.219 (1.100)	loss 9.308 (9.308)	prob 1.651 (1.651)	GS 34.531 (34.531)	mem 44.361
Train: [5][505/750]	BT 0.086 (1.140)	DT 0.007 (1.095)	loss 9.250 (9.250)	prob 2.058 (2.058)	GS 31.500 (31.500)	mem 44.384
Train: [5][510/750]	BT 7.584 (1.147)	DT 7.536 (1.102)	loss 9.082 (9.082)	prob 1.991 (1.991)	GS 33.109 (33.109)	mem 44.444
Train: [5][515/750]	BT 0.032 (1.137)	DT 0.002 (1.092)	loss 9.284 (9.284)	prob 2.237 (2.237)	GS 33.609 (33.609)	mem 44.425
Train: [5][520/750]	BT 0.032 (1.137)	DT 0.003 (1.093)	loss 9.242 (9.242)	prob 2.042 (2.042)	GS 32.453 (32.453)	mem 44.459
Train: [5][525/750]	BT 0.067 (1.138)	DT 0.003 (1.094)	loss 9.292 (9.292)	prob 1.764 (1.764)	GS 32.875 (32.875)	mem 44.532
Train: [5][530/750]	BT 0.026 (1.138)	DT 0.002 (1.093)	loss 8.425 (8.425)	prob 2.729 (2.729)	GS 30.672 (30.672)	mem 44.384
Train: [5][535/750]	BT 0.034 (1.142)	DT 0.001 (1.098)	loss 9.301 (9.301)	prob 2.327 (2.327)	GS 37.250 (37.250)	mem 44.577
Train: [5][540/750]	BT 5.662 (1.142)	DT 5.625 (1.098)	loss 9.122 (9.122)	prob 2.277 (2.277)	GS 31.266 (31.266)	mem 44.468
Train: [5][545/750]	BT 0.065 (1.136)	DT 0.009 (1.091)	loss 8.954 (8.954)	prob 2.058 (2.058)	GS 32.266 (32.266)	mem 44.411
Train: [5][550/750]	BT 0.406 (1.136)	DT 0.374 (1.091)	loss 8.998 (8.998)	prob 2.548 (2.548)	GS 31.688 (31.688)	mem 44.413
Train: [5][555/750]	BT 0.059 (1.141)	DT 0.002 (1.096)	loss 9.109 (9.109)	prob 1.736 (1.736)	GS 31.641 (31.641)	mem 44.415
Train: [5][560/750]	BT 0.033 (1.133)	DT 0.001 (1.088)	loss 8.775 (8.775)	prob 2.367 (2.367)	GS 33.219 (33.219)	mem 44.494
Train: [5][565/750]	BT 0.048 (1.134)	DT 0.003 (1.089)	loss 10.099 (10.099)	prob 1.599 (1.599)	GS 26.641 (26.641)	mem 44.485
Train: [5][570/750]	BT 0.044 (1.135)	DT 0.014 (1.090)	loss 8.533 (8.533)	prob 2.686 (2.686)	GS 33.406 (33.406)	mem 44.520
Train: [5][575/750]	BT 0.057 (1.135)	DT 0.007 (1.090)	loss 9.520 (9.520)	prob 1.652 (1.652)	GS 32.406 (32.406)	mem 44.485
Train: [5][580/750]	BT 0.029 (1.135)	DT 0.001 (1.090)	loss 8.648 (8.648)	prob 2.666 (2.666)	GS 32.203 (32.203)	mem 44.454
Train: [5][585/750]	BT 0.050 (1.136)	DT 0.002 (1.091)	loss 9.225 (9.225)	prob 2.123 (2.123)	GS 30.656 (30.656)	mem 44.264
Train: [5][590/750]	BT 3.298 (1.134)	DT 3.262 (1.090)	loss 8.463 (8.463)	prob 2.997 (2.997)	GS 32.469 (32.469)	mem 44.425
Train: [5][595/750]	BT 0.036 (1.135)	DT 0.007 (1.091)	loss 8.987 (8.987)	prob 2.401 (2.401)	GS 29.359 (29.359)	mem 44.354
Train: [5][600/750]	BT 0.175 (1.127)	DT 0.137 (1.082)	loss 9.183 (9.183)	prob 2.626 (2.626)	GS 30.266 (30.266)	mem 44.361
Train: [5][605/750]	BT 0.054 (1.128)	DT 0.003 (1.084)	loss 9.173 (9.173)	prob 2.246 (2.246)	GS 27.984 (27.984)	mem 44.388
Train: [5][610/750]	BT 3.211 (1.134)	DT 3.150 (1.090)	loss 8.727 (8.727)	prob 2.492 (2.492)	GS 35.719 (35.719)	mem 44.429
Train: [5][615/750]	BT 0.054 (1.136)	DT 0.001 (1.092)	loss 8.797 (8.797)	prob 2.438 (2.438)	GS 30.547 (30.547)	mem 44.345
Train: [5][620/750]	BT 0.062 (1.135)	DT 0.014 (1.091)	loss 9.200 (9.200)	prob 2.173 (2.173)	GS 32.141 (32.141)	mem 44.444
Train: [5][625/750]	BT 0.049 (1.127)	DT 0.002 (1.083)	loss 8.110 (8.110)	prob 3.210 (3.210)	GS 30.688 (30.688)	mem 44.372
Train: [5][630/750]	BT 5.790 (1.136)	DT 5.750 (1.092)	loss 8.794 (8.794)	prob 2.275 (2.275)	GS 33.359 (33.359)	mem 44.417
Train: [5][635/750]	BT 0.118 (1.134)	DT 0.001 (1.090)	loss 9.218 (9.218)	prob 2.172 (2.172)	GS 30.906 (30.906)	mem 44.677
Train: [5][640/750]	BT 0.045 (1.129)	DT 0.012 (1.084)	loss 8.810 (8.810)	prob 2.473 (2.473)	GS 35.828 (35.828)	mem 44.456
Train: [5][645/750]	BT 0.028 (1.134)	DT 0.003 (1.089)	loss 8.842 (8.842)	prob 2.417 (2.417)	GS 29.172 (29.172)	mem 44.389
Train: [5][650/750]	BT 3.412 (1.134)	DT 3.370 (1.090)	loss 9.119 (9.119)	prob 2.166 (2.166)	GS 30.656 (30.656)	mem 44.412
Train: [5][655/750]	BT 0.033 (1.137)	DT 0.003 (1.093)	loss 8.886 (8.886)	prob 2.320 (2.320)	GS 32.547 (32.547)	mem 44.500
Train: [5][660/750]	BT 0.031 (1.133)	DT 0.002 (1.088)	loss 8.933 (8.933)	prob 2.298 (2.298)	GS 31.844 (31.844)	mem 44.450
Train: [5][665/750]	BT 0.029 (1.129)	DT 0.001 (1.085)	loss 8.774 (8.774)	prob 2.342 (2.342)	GS 36.094 (36.094)	mem 44.447
arpack error, retry= 0
arpack error, retry= 0
Train: [5][670/750]	BT 0.298 (1.132)	DT 0.260 (1.088)	loss 9.541 (9.541)	prob 2.193 (2.193)	GS 36.562 (36.562)	mem 44.434
Train: [5][675/750]	BT 0.033 (1.130)	DT 0.002 (1.086)	loss 9.335 (9.335)	prob 2.200 (2.200)	GS 36.312 (36.312)	mem 44.456
Train: [5][680/750]	BT 0.036 (1.140)	DT 0.001 (1.095)	loss 9.181 (9.181)	prob 1.810 (1.810)	GS 35.969 (35.969)	mem 44.470
Train: [5][685/750]	BT 0.031 (1.132)	DT 0.001 (1.088)	loss 8.816 (8.816)	prob 2.609 (2.609)	GS 30.969 (30.969)	mem 44.526
Train: [5][690/750]	BT 12.543 (1.142)	DT 12.492 (1.098)	loss 8.918 (8.918)	prob 2.237 (2.237)	GS 36.188 (36.188)	mem 44.438
Train: [5][695/750]	BT 0.044 (1.134)	DT 0.001 (1.090)	loss 9.268 (9.268)	prob 1.974 (1.974)	GS 29.844 (29.844)	mem 44.570
Train: [5][700/750]	BT 0.031 (1.126)	DT 0.001 (1.082)	loss 9.041 (9.041)	prob 2.453 (2.453)	GS 32.594 (32.594)	mem 44.438
Train: [5][705/750]	BT 0.045 (1.137)	DT 0.005 (1.093)	loss 9.050 (9.050)	prob 2.059 (2.059)	GS 28.391 (28.391)	mem 44.417
Train: [5][710/750]	BT 0.032 (1.129)	DT 0.002 (1.085)	loss 9.539 (9.539)	prob 1.931 (1.931)	GS 35.359 (35.359)	mem 44.419
Train: [5][715/750]	BT 0.043 (1.142)	DT 0.004 (1.098)	loss 8.562 (8.562)	prob 2.718 (2.718)	GS 30.156 (30.156)	mem 44.442
Train: [5][720/750]	BT 0.040 (1.135)	DT 0.001 (1.091)	loss 9.039 (9.039)	prob 2.042 (2.042)	GS 33.766 (33.766)	mem 44.445
Train: [5][725/750]	BT 0.054 (1.127)	DT 0.011 (1.083)	loss 9.000 (9.000)	prob 2.537 (2.537)	GS 32.484 (32.484)	mem 44.447
Train: [5][730/750]	BT 0.032 (1.135)	DT 0.001 (1.091)	loss 8.584 (8.584)	prob 2.702 (2.702)	GS 33.656 (33.656)	mem 44.227
Train: [5][735/750]	BT 0.030 (1.128)	DT 0.001 (1.084)	loss 8.769 (8.769)	prob 2.694 (2.694)	GS 31.594 (31.594)	mem 44.226
Train: [5][740/750]	BT 0.023 (1.132)	DT 0.001 (1.088)	loss 9.101 (9.101)	prob 2.352 (2.352)	GS 36.953 (36.953)	mem 15.026
Train: [5][745/750]	BT 0.032 (1.124)	DT 0.002 (1.081)	loss 9.369 (9.369)	prob 1.794 (1.794)	GS 37.906 (37.906)	mem 15.028
Train: [5][750/750]	BT 1.592 (1.119)	DT 1.565 (1.076)	loss 8.910 (8.910)	prob 1.882 (1.882)	GS 32.562 (32.562)	mem 12.023
Train: [5][755/750]	BT 0.028 (1.112)	DT 0.001 (1.068)	loss 9.928 (9.928)	prob 1.428 (1.428)	GS 33.812 (33.812)	mem 12.025
epoch 5, total time 839.65
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [6][1/750]	BT 23.257 (23.257)	DT 23.185 (23.185)	loss 8.794 (8.794)	prob 2.238 (2.238)	GS 37.172 (37.172)	mem 43.457
Train: [6][5/750]	BT 0.032 (5.108)	DT 0.002 (5.065)	loss 8.417 (8.417)	prob 2.620 (2.620)	GS 27.297 (27.297)	mem 43.606
Train: [6][10/750]	BT 0.049 (2.572)	DT 0.007 (2.534)	loss 8.852 (8.852)	prob 1.858 (1.858)	GS 36.250 (36.250)	mem 43.626
Train: [6][15/750]	BT 0.585 (2.360)	DT 0.536 (2.319)	loss 8.418 (8.418)	prob 2.750 (2.750)	GS 28.812 (28.812)	mem 43.891
Train: [6][20/750]	BT 0.035 (2.075)	DT 0.003 (2.033)	loss 8.545 (8.545)	prob 2.616 (2.616)	GS 35.078 (35.078)	mem 44.151
Train: [6][25/750]	BT 4.329 (1.845)	DT 4.291 (1.799)	loss 8.733 (8.733)	prob 2.589 (2.589)	GS 30.234 (30.234)	mem 43.929
Train: [6][30/750]	BT 5.172 (1.934)	DT 5.123 (1.890)	loss 8.854 (8.854)	prob 2.553 (2.553)	GS 34.531 (34.531)	mem 43.927
Train: [6][35/750]	BT 0.103 (1.667)	DT 0.012 (1.621)	loss 8.791 (8.791)	prob 2.398 (2.398)	GS 31.562 (31.562)	mem 44.106
Train: [6][40/750]	BT 0.033 (1.583)	DT 0.001 (1.536)	loss 8.698 (8.698)	prob 2.727 (2.727)	GS 32.438 (32.438)	mem 43.888
Train: [6][45/750]	BT 0.103 (1.588)	DT 0.009 (1.537)	loss 8.826 (8.826)	prob 2.700 (2.700)	GS 44.922 (44.922)	mem 44.085
Train: [6][50/750]	BT 10.089 (1.636)	DT 10.058 (1.586)	loss 8.321 (8.321)	prob 3.198 (3.198)	GS 36.438 (36.438)	mem 44.004
Train: [6][55/750]	BT 0.026 (1.549)	DT 0.001 (1.499)	loss 8.669 (8.669)	prob 2.948 (2.948)	GS 31.438 (31.438)	mem 43.897
Train: [6][60/750]	BT 0.069 (1.424)	DT 0.018 (1.375)	loss 8.828 (8.828)	prob 2.413 (2.413)	GS 32.531 (32.531)	mem 43.924
Train: [6][65/750]	BT 0.039 (1.435)	DT 0.008 (1.386)	loss 8.791 (8.791)	prob 2.970 (2.970)	GS 32.125 (32.125)	mem 44.064
Train: [6][70/750]	BT 0.078 (1.445)	DT 0.015 (1.395)	loss 9.131 (9.131)	prob 2.450 (2.450)	GS 36.250 (36.250)	mem 44.081
Train: [6][75/750]	BT 0.024 (1.396)	DT 0.001 (1.347)	loss 8.881 (8.881)	prob 1.982 (1.982)	GS 36.625 (36.625)	mem 44.091
Train: [6][80/750]	BT 0.058 (1.429)	DT 0.010 (1.380)	loss 8.411 (8.411)	prob 2.504 (2.504)	GS 34.750 (34.750)	mem 43.990
Train: [6][85/750]	BT 0.033 (1.348)	DT 0.001 (1.299)	loss 8.362 (8.362)	prob 2.596 (2.596)	GS 31.969 (31.969)	mem 43.989
Train: [6][90/750]	BT 6.264 (1.414)	DT 6.230 (1.365)	loss 8.710 (8.710)	prob 2.471 (2.471)	GS 33.406 (33.406)	mem 44.474
Train: [6][95/750]	BT 0.085 (1.342)	DT 0.033 (1.294)	loss 8.575 (8.575)	prob 2.615 (2.615)	GS 31.109 (31.109)	mem 44.141
Train: [6][100/750]	BT 6.821 (1.369)	DT 6.799 (1.321)	loss 8.893 (8.893)	prob 2.945 (2.945)	GS 39.219 (39.219)	mem 44.171
Train: [6][105/750]	BT 0.031 (1.342)	DT 0.001 (1.294)	loss 8.849 (8.849)	prob 2.736 (2.736)	GS 32.281 (32.281)	mem 44.120
Train: [6][110/750]	BT 1.334 (1.294)	DT 1.282 (1.247)	loss 8.490 (8.490)	prob 2.797 (2.797)	GS 34.797 (34.797)	mem 44.117
Train: [6][115/750]	BT 0.037 (1.334)	DT 0.002 (1.286)	loss 8.927 (8.927)	prob 2.300 (2.300)	GS 31.094 (31.094)	mem 44.185
Train: [6][120/750]	BT 0.027 (1.280)	DT 0.001 (1.232)	loss 9.517 (9.517)	prob 2.097 (2.097)	GS 33.422 (33.422)	mem 44.292
Train: [6][125/750]	BT 0.032 (1.302)	DT 0.001 (1.254)	loss 9.485 (9.485)	prob 1.975 (1.975)	GS 32.000 (32.000)	mem 44.301
Train: [6][130/750]	BT 0.032 (1.277)	DT 0.002 (1.230)	loss 9.202 (9.202)	prob 2.447 (2.447)	GS 34.359 (34.359)	mem 44.237
Train: [6][135/750]	BT 0.046 (1.254)	DT 0.015 (1.207)	loss 8.269 (8.269)	prob 3.143 (3.143)	GS 26.953 (26.953)	mem 44.285
Train: [6][140/750]	BT 0.026 (1.288)	DT 0.001 (1.242)	loss 8.364 (8.364)	prob 3.030 (3.030)	GS 33.906 (33.906)	mem 44.200
Train: [6][145/750]	BT 0.032 (1.245)	DT 0.003 (1.199)	loss 8.232 (8.232)	prob 3.354 (3.354)	GS 34.344 (34.344)	mem 44.199
Train: [6][150/750]	BT 1.232 (1.293)	DT 1.172 (1.246)	loss 8.671 (8.671)	prob 2.839 (2.839)	GS 37.516 (37.516)	mem 44.287
Train: [6][155/750]	BT 0.075 (1.253)	DT 0.004 (1.206)	loss 8.355 (8.355)	prob 2.923 (2.923)	GS 42.719 (42.719)	mem 44.438
Train: [6][160/750]	BT 11.681 (1.288)	DT 11.639 (1.241)	loss 8.305 (8.305)	prob 3.273 (3.273)	GS 31.453 (31.453)	mem 44.297
Train: [6][165/750]	BT 0.057 (1.250)	DT 0.008 (1.204)	loss 8.884 (8.884)	prob 2.591 (2.591)	GS 29.641 (29.641)	mem 44.367
Train: [6][170/750]	BT 0.061 (1.216)	DT 0.001 (1.169)	loss 8.452 (8.452)	prob 2.817 (2.817)	GS 37.219 (37.219)	mem 44.496
Train: [6][175/750]	BT 0.030 (1.260)	DT 0.003 (1.213)	loss 8.803 (8.803)	prob 2.884 (2.884)	GS 36.953 (36.953)	mem 44.354
Train: [6][180/750]	BT 0.047 (1.226)	DT 0.010 (1.179)	loss 8.579 (8.579)	prob 2.695 (2.695)	GS 36.828 (36.828)	mem 44.354
Train: [6][185/750]	BT 0.033 (1.252)	DT 0.002 (1.205)	loss 8.415 (8.415)	prob 3.046 (3.046)	GS 29.453 (29.453)	mem 44.392
Train: [6][190/750]	BT 0.031 (1.233)	DT 0.001 (1.186)	loss 8.676 (8.676)	prob 3.066 (3.066)	GS 31.609 (31.609)	mem 44.341
Train: [6][195/750]	BT 0.033 (1.203)	DT 0.002 (1.156)	loss 8.516 (8.516)	prob 2.890 (2.890)	GS 27.953 (27.953)	mem 44.366
Train: [6][200/750]	BT 0.046 (1.235)	DT 0.002 (1.187)	loss 8.442 (8.442)	prob 2.522 (2.522)	GS 32.688 (32.688)	mem 44.366
Train: [6][205/750]	BT 0.025 (1.205)	DT 0.001 (1.159)	loss 9.048 (9.048)	prob 2.692 (2.692)	GS 33.281 (33.281)	mem 44.367
Train: [6][210/750]	BT 0.052 (1.229)	DT 0.001 (1.182)	loss 8.340 (8.340)	prob 2.801 (2.801)	GS 30.672 (30.672)	mem 44.435
Train: [6][215/750]	BT 0.030 (1.202)	DT 0.001 (1.154)	loss 8.758 (8.758)	prob 2.497 (2.497)	GS 32.484 (32.484)	mem 44.497
Train: [6][220/750]	BT 14.320 (1.253)	DT 14.284 (1.205)	loss 8.342 (8.342)	prob 2.966 (2.966)	GS 35.469 (35.469)	mem 44.320
Train: [6][225/750]	BT 0.040 (1.226)	DT 0.002 (1.179)	loss 8.606 (8.606)	prob 2.584 (2.584)	GS 24.203 (24.203)	mem 44.253
Train: [6][230/750]	BT 0.051 (1.201)	DT 0.013 (1.153)	loss 8.313 (8.313)	prob 2.632 (2.632)	GS 36.406 (36.406)	mem 44.355
Train: [6][235/750]	BT 0.030 (1.229)	DT 0.001 (1.182)	loss 8.362 (8.362)	prob 2.917 (2.917)	GS 29.688 (29.688)	mem 44.282
Train: [6][240/750]	BT 0.031 (1.204)	DT 0.001 (1.158)	loss 8.583 (8.583)	prob 2.883 (2.883)	GS 34.172 (34.172)	mem 44.326
Train: [6][245/750]	BT 0.031 (1.235)	DT 0.001 (1.188)	loss 8.181 (8.181)	prob 3.346 (3.346)	GS 27.828 (27.828)	mem 44.311
Train: [6][250/750]	BT 0.090 (1.211)	DT 0.019 (1.165)	loss 8.195 (8.195)	prob 3.094 (3.094)	GS 33.766 (33.766)	mem 44.311
Train: [6][255/750]	BT 0.032 (1.188)	DT 0.001 (1.142)	loss 8.487 (8.487)	prob 2.730 (2.730)	GS 30.562 (30.562)	mem 44.324
Train: [6][260/750]	BT 0.039 (1.222)	DT 0.002 (1.177)	loss 8.531 (8.531)	prob 2.771 (2.771)	GS 34.625 (34.625)	mem 44.366
Train: [6][265/750]	BT 0.044 (1.200)	DT 0.008 (1.154)	loss 8.692 (8.692)	prob 2.376 (2.376)	GS 29.969 (29.969)	mem 44.522
Train: [6][270/750]	BT 0.031 (1.219)	DT 0.001 (1.173)	loss 8.680 (8.680)	prob 2.533 (2.533)	GS 38.906 (38.906)	mem 44.384
Train: [6][275/750]	BT 0.052 (1.197)	DT 0.001 (1.152)	loss 8.613 (8.613)	prob 2.705 (2.705)	GS 31.422 (31.422)	mem 44.385
Train: [6][280/750]	BT 15.849 (1.233)	DT 15.820 (1.188)	loss 8.419 (8.419)	prob 2.667 (2.667)	GS 33.703 (33.703)	mem 44.376
Train: [6][285/750]	BT 0.030 (1.212)	DT 0.001 (1.167)	loss 9.046 (9.046)	prob 2.316 (2.316)	GS 32.094 (32.094)	mem 44.376
Train: [6][290/750]	BT 0.050 (1.192)	DT 0.002 (1.147)	loss 8.762 (8.762)	prob 2.442 (2.442)	GS 34.734 (34.734)	mem 44.420
Train: [6][295/750]	BT 0.033 (1.209)	DT 0.003 (1.164)	loss 8.135 (8.135)	prob 3.008 (3.008)	GS 32.891 (32.891)	mem 44.441
Train: [6][300/750]	BT 0.029 (1.190)	DT 0.002 (1.144)	loss 8.353 (8.353)	prob 3.156 (3.156)	GS 32.609 (32.609)	mem 44.410
Train: [6][305/750]	BT 0.029 (1.213)	DT 0.001 (1.168)	loss 7.956 (7.956)	prob 3.502 (3.502)	GS 30.250 (30.250)	mem 44.431
Train: [6][310/750]	BT 0.023 (1.194)	DT 0.001 (1.149)	loss 8.592 (8.592)	prob 2.692 (2.692)	GS 34.719 (34.719)	mem 44.432
Train: [6][315/750]	BT 0.187 (1.177)	DT 0.005 (1.131)	loss 8.341 (8.341)	prob 2.939 (2.939)	GS 32.375 (32.375)	mem 44.487
Train: [6][320/750]	BT 0.033 (1.206)	DT 0.002 (1.160)	loss 8.335 (8.335)	prob 3.040 (3.040)	GS 40.031 (40.031)	mem 44.473
Train: [6][325/750]	BT 0.025 (1.188)	DT 0.001 (1.143)	loss 8.635 (8.635)	prob 2.520 (2.520)	GS 34.766 (34.766)	mem 44.261
Train: [6][330/750]	BT 0.037 (1.208)	DT 0.008 (1.163)	loss 8.351 (8.351)	prob 2.852 (2.852)	GS 36.609 (36.609)	mem 44.342
Train: [6][335/750]	BT 0.031 (1.191)	DT 0.001 (1.145)	loss 8.252 (8.252)	prob 3.329 (3.329)	GS 30.719 (30.719)	mem 44.360
Train: [6][340/750]	BT 12.646 (1.211)	DT 12.539 (1.165)	loss 8.627 (8.627)	prob 2.772 (2.772)	GS 36.797 (36.797)	mem 44.477
Train: [6][345/750]	BT 0.031 (1.194)	DT 0.001 (1.149)	loss 8.496 (8.496)	prob 2.884 (2.884)	GS 31.969 (31.969)	mem 44.426
Train: [6][350/750]	BT 0.033 (1.177)	DT 0.001 (1.132)	loss 8.051 (8.051)	prob 3.475 (3.475)	GS 36.344 (36.344)	mem 44.426
Train: [6][355/750]	BT 0.046 (1.196)	DT 0.010 (1.151)	loss 8.651 (8.651)	prob 3.043 (3.043)	GS 30.609 (30.609)	mem 44.375
Train: [6][360/750]	BT 0.034 (1.180)	DT 0.001 (1.135)	loss 8.308 (8.308)	prob 3.241 (3.241)	GS 31.422 (31.422)	mem 44.443
Train: [6][365/750]	BT 0.029 (1.201)	DT 0.001 (1.155)	loss 8.732 (8.732)	prob 2.486 (2.486)	GS 32.141 (32.141)	mem 44.375
Train: [6][370/750]	BT 0.070 (1.185)	DT 0.004 (1.140)	loss 8.320 (8.320)	prob 2.615 (2.615)	GS 33.453 (33.453)	mem 44.380
Train: [6][375/750]	BT 0.032 (1.170)	DT 0.002 (1.125)	loss 8.119 (8.119)	prob 3.044 (3.044)	GS 35.406 (35.406)	mem 44.381
Train: [6][380/750]	BT 0.040 (1.188)	DT 0.001 (1.143)	loss 8.304 (8.304)	prob 2.731 (2.731)	GS 32.469 (32.469)	mem 44.460
Train: [6][385/750]	BT 0.039 (1.173)	DT 0.001 (1.128)	loss 8.525 (8.525)	prob 2.888 (2.888)	GS 36.250 (36.250)	mem 44.246
Train: [6][390/750]	BT 0.032 (1.190)	DT 0.002 (1.145)	loss 8.442 (8.442)	prob 2.871 (2.871)	GS 34.000 (34.000)	mem 44.337
Train: [6][395/750]	BT 0.045 (1.175)	DT 0.001 (1.131)	loss 8.720 (8.720)	prob 2.678 (2.678)	GS 40.719 (40.719)	mem 44.366
Train: [6][400/750]	BT 12.459 (1.193)	DT 12.421 (1.148)	loss 8.161 (8.161)	prob 3.330 (3.330)	GS 32.516 (32.516)	mem 44.356
Train: [6][405/750]	BT 0.032 (1.179)	DT 0.001 (1.134)	loss 8.863 (8.863)	prob 3.096 (3.096)	GS 33.266 (33.266)	mem 44.317
Train: [6][410/750]	BT 0.513 (1.166)	DT 0.477 (1.122)	loss 8.101 (8.101)	prob 3.138 (3.138)	GS 33.078 (33.078)	mem 44.450
Train: [6][415/750]	BT 0.024 (1.186)	DT 0.001 (1.142)	loss 8.739 (8.739)	prob 2.572 (2.572)	GS 30.344 (30.344)	mem 44.376
Train: [6][420/750]	BT 0.047 (1.173)	DT 0.002 (1.128)	loss 8.432 (8.432)	prob 3.293 (3.293)	GS 32.984 (32.984)	mem 44.377
Train: [6][425/750]	BT 0.105 (1.181)	DT 0.024 (1.136)	loss 8.405 (8.405)	prob 2.955 (2.955)	GS 31.312 (31.312)	mem 44.412
Train: [6][430/750]	BT 0.033 (1.168)	DT 0.001 (1.123)	loss 7.983 (7.983)	prob 3.529 (3.529)	GS 29.188 (29.188)	mem 44.414
Train: [6][435/750]	BT 0.036 (1.165)	DT 0.005 (1.121)	loss 7.880 (7.880)	prob 3.389 (3.389)	GS 30.141 (30.141)	mem 44.416
Train: [6][440/750]	BT 0.075 (1.168)	DT 0.014 (1.123)	loss 8.062 (8.062)	prob 2.819 (2.819)	GS 34.594 (34.594)	mem 44.879
Train: [6][445/750]	BT 0.056 (1.164)	DT 0.013 (1.119)	loss 8.307 (8.307)	prob 2.819 (2.819)	GS 28.375 (28.375)	mem 44.373
Train: [6][450/750]	BT 1.029 (1.175)	DT 0.967 (1.130)	loss 8.384 (8.384)	prob 3.037 (3.037)	GS 37.703 (37.703)	mem 44.340
Train: [6][455/750]	BT 0.057 (1.169)	DT 0.002 (1.124)	loss 8.454 (8.454)	prob 2.773 (2.773)	GS 32.188 (32.188)	mem 44.369
Train: [6][460/750]	BT 11.744 (1.191)	DT 11.713 (1.146)	loss 8.339 (8.339)	prob 2.791 (2.791)	GS 39.172 (39.172)	mem 44.348
Train: [6][465/750]	BT 0.050 (1.179)	DT 0.010 (1.134)	loss 8.236 (8.236)	prob 3.322 (3.322)	GS 31.859 (31.859)	mem 44.348
Train: [6][470/750]	BT 0.243 (1.167)	DT 0.194 (1.122)	loss 8.213 (8.213)	prob 2.908 (2.908)	GS 30.016 (30.016)	mem 44.359
Train: [6][475/750]	BT 0.039 (1.184)	DT 0.017 (1.140)	loss 8.120 (8.120)	prob 3.346 (3.346)	GS 30.562 (30.562)	mem 44.338
Train: [6][480/750]	BT 0.032 (1.172)	DT 0.003 (1.128)	loss 7.893 (7.893)	prob 3.208 (3.208)	GS 31.422 (31.422)	mem 44.478
Train: [6][485/750]	BT 0.025 (1.185)	DT 0.001 (1.140)	loss 8.782 (8.782)	prob 2.306 (2.306)	GS 47.359 (47.359)	mem 44.355
Train: [6][490/750]	BT 0.047 (1.173)	DT 0.007 (1.128)	loss 7.826 (7.826)	prob 2.974 (2.974)	GS 36.938 (36.938)	mem 44.356
Train: [6][495/750]	BT 0.037 (1.174)	DT 0.002 (1.130)	loss 8.173 (8.173)	prob 2.921 (2.921)	GS 32.609 (32.609)	mem 44.352
Train: [6][500/750]	BT 0.026 (1.181)	DT 0.001 (1.136)	loss 8.166 (8.166)	prob 3.443 (3.443)	GS 40.109 (40.109)	mem 44.366
Train: [6][505/750]	BT 0.034 (1.169)	DT 0.003 (1.125)	loss 8.293 (8.293)	prob 2.786 (2.786)	GS 30.938 (30.938)	mem 44.366
Train: [6][510/750]	BT 0.031 (1.184)	DT 0.001 (1.140)	loss 7.923 (7.923)	prob 3.095 (3.095)	GS 33.453 (33.453)	mem 44.332
Train: [6][515/750]	BT 0.032 (1.173)	DT 0.001 (1.129)	loss 8.536 (8.536)	prob 2.918 (2.918)	GS 31.891 (31.891)	mem 44.333
Train: [6][520/750]	BT 12.030 (1.187)	DT 11.998 (1.143)	loss 8.135 (8.135)	prob 2.610 (2.610)	GS 32.312 (32.312)	mem 44.379
Train: [6][525/750]	BT 0.024 (1.176)	DT 0.001 (1.132)	loss 7.855 (7.855)	prob 2.995 (2.995)	GS 31.969 (31.969)	mem 44.383
Train: [6][530/750]	BT 0.460 (1.166)	DT 0.414 (1.122)	loss 8.091 (8.091)	prob 2.715 (2.715)	GS 32.609 (32.609)	mem 44.320
Train: [6][535/750]	BT 0.026 (1.178)	DT 0.001 (1.134)	loss 7.853 (7.853)	prob 3.248 (3.248)	GS 30.953 (30.953)	mem 44.341
Train: [6][540/750]	BT 0.045 (1.168)	DT 0.005 (1.123)	loss 7.871 (7.871)	prob 3.268 (3.268)	GS 34.594 (34.594)	mem 44.391
Train: [6][545/750]	BT 0.037 (1.183)	DT 0.007 (1.138)	loss 7.693 (7.693)	prob 3.477 (3.477)	GS 28.672 (28.672)	mem 44.259
Train: [6][550/750]	BT 0.048 (1.172)	DT 0.005 (1.128)	loss 8.161 (8.161)	prob 3.260 (3.260)	GS 29.828 (29.828)	mem 44.268
Train: [6][555/750]	BT 0.061 (1.162)	DT 0.004 (1.118)	loss 7.721 (7.721)	prob 3.597 (3.597)	GS 33.125 (33.125)	mem 44.326
Train: [6][560/750]	BT 0.047 (1.180)	DT 0.004 (1.135)	loss 7.952 (7.952)	prob 3.112 (3.112)	GS 39.422 (39.422)	mem 44.295
Train: [6][565/750]	BT 0.048 (1.169)	DT 0.001 (1.125)	loss 7.722 (7.722)	prob 3.407 (3.407)	GS 29.016 (29.016)	mem 44.296
Train: [6][570/750]	BT 0.026 (1.177)	DT 0.001 (1.133)	loss 8.484 (8.484)	prob 2.770 (2.770)	GS 34.609 (34.609)	mem 44.566
Train: [6][575/750]	BT 0.025 (1.167)	DT 0.001 (1.123)	loss 7.891 (7.891)	prob 3.086 (3.086)	GS 32.000 (32.000)	mem 44.481
Train: [6][580/750]	BT 13.176 (1.180)	DT 13.100 (1.136)	loss 7.919 (7.919)	prob 3.040 (3.040)	GS 36.000 (36.000)	mem 44.412
Train: [6][585/750]	BT 0.066 (1.170)	DT 0.016 (1.126)	loss 8.021 (8.021)	prob 2.907 (2.907)	GS 32.906 (32.906)	mem 44.483
Train: [6][590/750]	BT 0.035 (1.161)	DT 0.001 (1.117)	loss 8.162 (8.162)	prob 3.396 (3.396)	GS 34.781 (34.781)	mem 44.353
Train: [6][595/750]	BT 0.030 (1.175)	DT 0.002 (1.131)	loss 7.938 (7.938)	prob 3.325 (3.325)	GS 30.594 (30.594)	mem 44.439
Train: [6][600/750]	BT 0.057 (1.165)	DT 0.003 (1.121)	loss 7.910 (7.910)	prob 3.289 (3.289)	GS 35.719 (35.719)	mem 44.439
Train: [6][605/750]	BT 0.042 (1.179)	DT 0.001 (1.135)	loss 7.895 (7.895)	prob 2.801 (2.801)	GS 32.109 (32.109)	mem 44.407
Train: [6][610/750]	BT 0.085 (1.170)	DT 0.001 (1.125)	loss 7.758 (7.758)	prob 2.893 (2.893)	GS 36.219 (36.219)	mem 44.408
Train: [6][615/750]	BT 0.031 (1.160)	DT 0.001 (1.116)	loss 7.912 (7.912)	prob 3.854 (3.854)	GS 34.078 (34.078)	mem 44.408
Train: [6][620/750]	BT 0.090 (1.174)	DT 0.002 (1.130)	loss 7.600 (7.600)	prob 2.946 (2.946)	GS 33.484 (33.484)	mem 44.446
Train: [6][625/750]	BT 0.044 (1.165)	DT 0.001 (1.121)	loss 8.090 (8.090)	prob 2.593 (2.593)	GS 31.203 (31.203)	mem 44.456
Train: [6][630/750]	BT 0.022 (1.176)	DT 0.001 (1.132)	loss 7.460 (7.460)	prob 3.364 (3.364)	GS 34.828 (34.828)	mem 44.454
Train: [6][635/750]	BT 0.048 (1.167)	DT 0.006 (1.123)	loss 7.962 (7.962)	prob 3.256 (3.256)	GS 30.734 (30.734)	mem 44.455
Train: [6][640/750]	BT 13.945 (1.180)	DT 13.914 (1.136)	loss 7.827 (7.827)	prob 3.177 (3.177)	GS 34.641 (34.641)	mem 44.400
Train: [6][645/750]	BT 0.028 (1.171)	DT 0.001 (1.128)	loss 7.696 (7.696)	prob 3.205 (3.205)	GS 35.062 (35.062)	mem 44.407
Train: [6][650/750]	BT 0.064 (1.163)	DT 0.001 (1.119)	loss 7.868 (7.868)	prob 3.239 (3.239)	GS 34.156 (34.156)	mem 44.427
Train: [6][655/750]	BT 0.111 (1.172)	DT 0.042 (1.128)	loss 7.924 (7.924)	prob 3.138 (3.138)	GS 27.047 (27.047)	mem 44.458
Train: [6][660/750]	BT 0.029 (1.164)	DT 0.001 (1.120)	loss 8.018 (8.018)	prob 2.918 (2.918)	GS 29.688 (29.688)	mem 44.456
Train: [6][665/750]	BT 0.040 (1.177)	DT 0.009 (1.133)	loss 7.797 (7.797)	prob 3.428 (3.428)	GS 29.031 (29.031)	mem 44.437
Train: [6][670/750]	BT 0.024 (1.169)	DT 0.001 (1.125)	loss 7.816 (7.816)	prob 3.126 (3.126)	GS 32.359 (32.359)	mem 44.459
Train: [6][675/750]	BT 0.052 (1.161)	DT 0.012 (1.117)	loss 7.863 (7.863)	prob 2.469 (2.469)	GS 32.859 (32.859)	mem 44.439
Train: [6][680/750]	BT 0.055 (1.169)	DT 0.014 (1.125)	loss 7.688 (7.688)	prob 3.004 (3.004)	GS 34.812 (34.812)	mem 44.460
Train: [6][685/750]	BT 0.067 (1.161)	DT 0.004 (1.117)	loss 7.851 (7.851)	prob 2.708 (2.708)	GS 30.562 (30.562)	mem 44.493
Train: [6][690/750]	BT 0.102 (1.170)	DT 0.017 (1.125)	loss 7.955 (7.955)	prob 2.369 (2.369)	GS 36.828 (36.828)	mem 44.499
Train: [6][695/750]	BT 0.041 (1.162)	DT 0.003 (1.117)	loss 7.978 (7.978)	prob 2.975 (2.975)	GS 34.859 (34.859)	mem 44.612
Train: [6][700/750]	BT 13.721 (1.173)	DT 13.686 (1.129)	loss 7.950 (7.950)	prob 3.040 (3.040)	GS 33.172 (33.172)	mem 44.460
Train: [6][705/750]	BT 0.053 (1.165)	DT 0.002 (1.121)	loss 7.902 (7.902)	prob 2.639 (2.639)	GS 28.438 (28.438)	mem 44.460
Train: [6][710/750]	BT 0.031 (1.157)	DT 0.001 (1.113)	loss 7.534 (7.534)	prob 3.340 (3.340)	GS 33.062 (33.062)	mem 44.461
Train: [6][715/750]	BT 0.031 (1.169)	DT 0.002 (1.125)	loss 7.404 (7.404)	prob 3.210 (3.210)	GS 32.312 (32.312)	mem 44.464
Train: [6][720/750]	BT 0.041 (1.162)	DT 0.003 (1.118)	loss 7.715 (7.715)	prob 2.901 (2.901)	GS 33.000 (33.000)	mem 44.464
Train: [6][725/750]	BT 0.047 (1.173)	DT 0.001 (1.129)	loss 7.705 (7.705)	prob 3.057 (3.057)	GS 30.672 (30.672)	mem 44.243
Train: [6][730/750]	BT 0.033 (1.165)	DT 0.003 (1.121)	loss 7.394 (7.394)	prob 2.938 (2.938)	GS 31.562 (31.562)	mem 44.244
Train: [6][735/750]	BT 0.030 (1.158)	DT 0.001 (1.114)	loss 7.928 (7.928)	prob 3.100 (3.100)	GS 30.516 (30.516)	mem 44.183
Train: [6][740/750]	BT 0.034 (1.157)	DT 0.002 (1.114)	loss 7.534 (7.534)	prob 2.668 (2.668)	GS 29.031 (29.031)	mem 15.800
Train: [6][745/750]	BT 0.033 (1.150)	DT 0.001 (1.106)	loss 7.797 (7.797)	prob 2.627 (2.627)	GS 37.531 (37.531)	mem 15.311
Train: [6][750/750]	BT 0.038 (1.146)	DT 0.001 (1.102)	loss 7.829 (7.829)	prob 2.721 (2.721)	GS 31.469 (31.469)	mem 12.138
Train: [6][755/750]	BT 0.035 (1.138)	DT 0.002 (1.095)	loss 7.697 (7.697)	prob 3.176 (3.176)	GS 32.219 (32.219)	mem 12.139
epoch 6, total time 859.66
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [7][1/750]	BT 22.931 (22.931)	DT 22.869 (22.869)	loss 7.724 (7.724)	prob 3.235 (3.235)	GS 30.188 (30.188)	mem 43.011
Train: [7][5/750]	BT 0.033 (4.694)	DT 0.003 (4.647)	loss 7.999 (7.999)	prob 2.709 (2.709)	GS 36.438 (36.438)	mem 43.043
Train: [7][10/750]	BT 0.032 (2.363)	DT 0.002 (2.325)	loss 7.979 (7.979)	prob 2.832 (2.832)	GS 34.531 (34.531)	mem 43.013
Train: [7][15/750]	BT 0.084 (2.316)	DT 0.005 (2.265)	loss 7.785 (7.785)	prob 3.066 (3.066)	GS 33.125 (33.125)	mem 43.311
Train: [7][20/750]	BT 0.357 (1.941)	DT 0.321 (1.892)	loss 7.777 (7.777)	prob 2.671 (2.671)	GS 30.578 (30.578)	mem 43.548
Train: [7][25/750]	BT 2.584 (1.667)	DT 2.552 (1.617)	loss 7.421 (7.421)	prob 3.244 (3.244)	GS 29.281 (29.281)	mem 43.728
Train: [7][30/750]	BT 5.966 (1.827)	DT 5.919 (1.778)	loss 7.540 (7.540)	prob 3.048 (3.048)	GS 36.500 (36.500)	mem 43.542
Train: [7][35/750]	BT 0.064 (1.573)	DT 0.012 (1.525)	loss 7.495 (7.495)	prob 2.863 (2.863)	GS 28.797 (28.797)	mem 43.501
Train: [7][40/750]	BT 0.032 (1.577)	DT 0.001 (1.530)	loss 7.779 (7.779)	prob 3.064 (3.064)	GS 35.875 (35.875)	mem 43.547
Train: [7][45/750]	BT 0.052 (1.531)	DT 0.004 (1.482)	loss 7.566 (7.566)	prob 3.166 (3.166)	GS 31.141 (31.141)	mem 43.566
Train: [7][50/750]	BT 12.491 (1.633)	DT 12.400 (1.582)	loss 7.614 (7.614)	prob 2.393 (2.393)	GS 32.375 (32.375)	mem 43.866
Train: [7][55/750]	BT 0.055 (1.512)	DT 0.008 (1.462)	loss 7.713 (7.713)	prob 2.913 (2.913)	GS 33.953 (33.953)	mem 43.597
Train: [7][60/750]	BT 0.035 (1.431)	DT 0.001 (1.383)	loss 7.290 (7.290)	prob 2.931 (2.931)	GS 33.031 (33.031)	mem 43.599
Train: [7][65/750]	BT 0.065 (1.446)	DT 0.011 (1.398)	loss 7.919 (7.919)	prob 2.560 (2.560)	GS 31.734 (31.734)	mem 43.755
Train: [7][70/750]	BT 0.049 (1.425)	DT 0.001 (1.379)	loss 7.302 (7.302)	prob 2.445 (2.445)	GS 35.047 (35.047)	mem 43.701
Train: [7][75/750]	BT 0.062 (1.438)	DT 0.018 (1.391)	loss 7.419 (7.419)	prob 2.761 (2.761)	GS 29.141 (29.141)	mem 43.679
Train: [7][80/750]	BT 0.050 (1.428)	DT 0.001 (1.382)	loss 7.466 (7.466)	prob 2.805 (2.805)	GS 32.188 (32.188)	mem 43.681
Train: [7][85/750]	BT 0.037 (1.349)	DT 0.003 (1.301)	loss 7.821 (7.821)	prob 2.954 (2.954)	GS 34.172 (34.172)	mem 43.623
Train: [7][90/750]	BT 3.714 (1.380)	DT 3.641 (1.332)	loss 7.540 (7.540)	prob 2.705 (2.705)	GS 31.375 (31.375)	mem 43.659
Train: [7][95/750]	BT 0.060 (1.311)	DT 0.009 (1.262)	loss 7.666 (7.666)	prob 2.748 (2.748)	GS 35.469 (35.469)	mem 43.661
Train: [7][100/750]	BT 0.038 (1.352)	DT 0.002 (1.303)	loss 7.698 (7.698)	prob 2.687 (2.687)	GS 32.891 (32.891)	mem 43.681
Train: [7][105/750]	BT 0.044 (1.346)	DT 0.001 (1.297)	loss 7.596 (7.596)	prob 2.712 (2.712)	GS 35.891 (35.891)	mem 43.685
Train: [7][110/750]	BT 9.372 (1.373)	DT 9.304 (1.323)	loss 7.676 (7.676)	prob 2.295 (2.295)	GS 35.297 (35.297)	mem 43.635
Train: [7][115/750]	BT 0.040 (1.377)	DT 0.007 (1.328)	loss 7.535 (7.535)	prob 2.452 (2.452)	GS 33.859 (33.859)	mem 43.667
Train: [7][120/750]	BT 0.028 (1.321)	DT 0.001 (1.272)	loss 8.019 (8.019)	prob 2.445 (2.445)	GS 34.250 (34.250)	mem 43.622
Train: [7][125/750]	BT 0.047 (1.317)	DT 0.004 (1.268)	loss 7.494 (7.494)	prob 2.310 (2.310)	GS 29.547 (29.547)	mem 43.646
Train: [7][130/750]	BT 0.101 (1.320)	DT 0.009 (1.271)	loss 7.640 (7.640)	prob 2.636 (2.636)	GS 31.328 (31.328)	mem 43.966
Train: [7][135/750]	BT 0.032 (1.312)	DT 0.002 (1.262)	loss 7.717 (7.717)	prob 2.761 (2.761)	GS 36.438 (36.438)	mem 43.736
Train: [7][140/750]	BT 0.025 (1.308)	DT 0.001 (1.259)	loss 7.513 (7.513)	prob 2.788 (2.788)	GS 32.469 (32.469)	mem 43.669
Train: [7][145/750]	BT 0.085 (1.265)	DT 0.001 (1.215)	loss 7.675 (7.675)	prob 2.448 (2.448)	GS 30.891 (30.891)	mem 43.698
Train: [7][150/750]	BT 9.578 (1.319)	DT 9.530 (1.269)	loss 7.578 (7.578)	prob 3.150 (3.150)	GS 36.328 (36.328)	mem 43.779
Train: [7][155/750]	BT 0.056 (1.278)	DT 0.006 (1.228)	loss 7.508 (7.508)	prob 2.813 (2.813)	GS 30.297 (30.297)	mem 43.759
Train: [7][160/750]	BT 0.068 (1.255)	DT 0.007 (1.205)	loss 7.297 (7.297)	prob 2.816 (2.816)	GS 35.156 (35.156)	mem 43.745
Train: [7][165/750]	BT 0.026 (1.275)	DT 0.001 (1.226)	loss 7.715 (7.715)	prob 1.999 (1.999)	GS 33.203 (33.203)	mem 43.754
Train: [7][170/750]	BT 5.065 (1.268)	DT 5.020 (1.219)	loss 7.677 (7.677)	prob 2.613 (2.613)	GS 32.984 (32.984)	mem 44.065
Train: [7][175/750]	BT 0.066 (1.270)	DT 0.002 (1.221)	loss 7.188 (7.188)	prob 2.998 (2.998)	GS 33.562 (33.562)	mem 43.876
Train: [7][180/750]	BT 0.064 (1.237)	DT 0.003 (1.187)	loss 7.311 (7.311)	prob 2.999 (2.999)	GS 35.469 (35.469)	mem 44.062
Train: [7][185/750]	BT 0.057 (1.242)	DT 0.007 (1.193)	loss 7.381 (7.381)	prob 2.253 (2.253)	GS 32.297 (32.297)	mem 43.790
Train: [7][190/750]	BT 0.034 (1.227)	DT 0.002 (1.178)	loss 7.650 (7.650)	prob 2.528 (2.528)	GS 34.375 (34.375)	mem 43.893
Train: [7][195/750]	BT 0.044 (1.251)	DT 0.001 (1.203)	loss 7.300 (7.300)	prob 2.641 (2.641)	GS 29.797 (29.797)	mem 44.036
Train: [7][200/750]	BT 0.036 (1.233)	DT 0.003 (1.184)	loss 7.200 (7.200)	prob 3.328 (3.328)	GS 33.594 (33.594)	mem 43.963
Train: [7][205/750]	BT 0.036 (1.213)	DT 0.006 (1.165)	loss 7.558 (7.558)	prob 2.049 (2.049)	GS 28.781 (28.781)	mem 44.013
Train: [7][210/750]	BT 0.405 (1.233)	DT 0.360 (1.185)	loss 7.549 (7.549)	prob 2.636 (2.636)	GS 33.438 (33.438)	mem 44.053
Train: [7][215/750]	BT 0.095 (1.206)	DT 0.006 (1.158)	loss 7.506 (7.506)	prob 2.545 (2.545)	GS 31.969 (31.969)	mem 44.064
Train: [7][220/750]	BT 2.759 (1.244)	DT 2.704 (1.196)	loss 7.378 (7.378)	prob 2.513 (2.513)	GS 32.156 (32.156)	mem 44.163
Train: [7][225/750]	BT 0.076 (1.218)	DT 0.037 (1.170)	loss 7.548 (7.548)	prob 2.593 (2.593)	GS 34.109 (34.109)	mem 44.082
Train: [7][230/750]	BT 8.432 (1.229)	DT 8.396 (1.181)	loss 7.287 (7.287)	prob 2.947 (2.947)	GS 33.266 (33.266)	mem 44.244
Train: [7][235/750]	BT 0.034 (1.229)	DT 0.002 (1.181)	loss 7.661 (7.661)	prob 2.569 (2.569)	GS 33.172 (33.172)	mem 44.105
Train: [7][240/750]	BT 0.050 (1.204)	DT 0.001 (1.157)	loss 7.302 (7.302)	prob 2.079 (2.079)	GS 33.766 (33.766)	mem 44.175
Train: [7][245/750]	BT 0.070 (1.233)	DT 0.011 (1.185)	loss 7.614 (7.614)	prob 2.094 (2.094)	GS 35.203 (35.203)	mem 44.181
Train: [7][250/750]	BT 0.079 (1.218)	DT 0.012 (1.171)	loss 7.213 (7.213)	prob 2.599 (2.599)	GS 35.922 (35.922)	mem 44.078
Train: [7][255/750]	BT 0.071 (1.208)	DT 0.009 (1.160)	loss 7.542 (7.542)	prob 2.396 (2.396)	GS 31.172 (31.172)	mem 44.091
Train: [7][260/750]	BT 0.115 (1.219)	DT 0.002 (1.171)	loss 7.235 (7.235)	prob 2.699 (2.699)	GS 36.172 (36.172)	mem 44.192
Train: [7][265/750]	BT 0.081 (1.197)	DT 0.008 (1.149)	loss 7.526 (7.526)	prob 2.068 (2.068)	GS 32.344 (32.344)	mem 44.246
Train: [7][270/750]	BT 0.063 (1.237)	DT 0.010 (1.189)	loss 6.955 (6.955)	prob 2.518 (2.518)	GS 35.016 (35.016)	mem 44.560
Train: [7][275/750]	BT 0.040 (1.216)	DT 0.014 (1.168)	loss 7.427 (7.427)	prob 2.360 (2.360)	GS 27.172 (27.172)	mem 44.399
Train: [7][280/750]	BT 13.739 (1.252)	DT 13.715 (1.203)	loss 7.359 (7.359)	prob 2.380 (2.380)	GS 37.609 (37.609)	mem 44.605
Train: [7][285/750]	BT 0.049 (1.231)	DT 0.011 (1.182)	loss 7.398 (7.398)	prob 2.382 (2.382)	GS 29.969 (29.969)	mem 44.349
Train: [7][290/750]	BT 3.122 (1.221)	DT 3.061 (1.173)	loss 7.570 (7.570)	prob 2.095 (2.095)	GS 37.281 (37.281)	mem 44.427
Train: [7][295/750]	BT 0.041 (1.233)	DT 0.002 (1.185)	loss 7.492 (7.492)	prob 2.203 (2.203)	GS 29.375 (29.375)	mem 44.410
Train: [7][300/750]	BT 0.026 (1.213)	DT 0.001 (1.166)	loss 7.286 (7.286)	prob 2.210 (2.210)	GS 38.516 (38.516)	mem 44.432
Train: [7][305/750]	BT 0.035 (1.241)	DT 0.001 (1.193)	loss 7.303 (7.303)	prob 2.310 (2.310)	GS 31.984 (31.984)	mem 44.446
Train: [7][310/750]	BT 0.025 (1.222)	DT 0.001 (1.174)	loss 7.330 (7.330)	prob 2.535 (2.535)	GS 34.812 (34.812)	mem 44.475
Train: [7][315/750]	BT 0.041 (1.203)	DT 0.002 (1.156)	loss 7.202 (7.202)	prob 2.456 (2.456)	GS 30.641 (30.641)	mem 44.542
Train: [7][320/750]	BT 0.041 (1.225)	DT 0.001 (1.178)	loss 7.001 (7.001)	prob 2.882 (2.882)	GS 29.906 (29.906)	mem 44.442
Train: [7][325/750]	BT 0.032 (1.207)	DT 0.001 (1.160)	loss 7.687 (7.687)	prob 2.542 (2.542)	GS 33.000 (33.000)	mem 44.441
Train: [7][330/750]	BT 0.025 (1.230)	DT 0.002 (1.183)	loss 7.208 (7.208)	prob 2.664 (2.664)	GS 34.938 (34.938)	mem 44.430
Train: [7][335/750]	BT 0.026 (1.212)	DT 0.001 (1.165)	loss 7.254 (7.254)	prob 2.378 (2.378)	GS 32.875 (32.875)	mem 44.432
Train: [7][340/750]	BT 12.550 (1.231)	DT 12.527 (1.185)	loss 7.420 (7.420)	prob 1.982 (1.982)	GS 31.906 (31.906)	mem 44.491
Train: [7][345/750]	BT 0.119 (1.215)	DT 0.003 (1.169)	loss 7.544 (7.544)	prob 1.708 (1.708)	GS 27.281 (27.281)	mem 44.526
Train: [7][350/750]	BT 0.047 (1.199)	DT 0.011 (1.153)	loss 7.319 (7.319)	prob 2.258 (2.258)	GS 31.844 (31.844)	mem 44.579
Train: [7][355/750]	BT 0.031 (1.232)	DT 0.001 (1.186)	loss 7.370 (7.370)	prob 2.172 (2.172)	GS 31.500 (31.500)	mem 44.504
Train: [7][360/750]	BT 0.030 (1.215)	DT 0.001 (1.170)	loss 7.288 (7.288)	prob 2.726 (2.726)	GS 33.859 (33.859)	mem 44.504
Train: [7][365/750]	BT 0.040 (1.213)	DT 0.003 (1.167)	loss 7.146 (7.146)	prob 2.626 (2.626)	GS 27.281 (27.281)	mem 44.513
Train: [7][370/750]	BT 0.030 (1.213)	DT 0.001 (1.167)	loss 7.398 (7.398)	prob 2.322 (2.322)	GS 34.141 (34.141)	mem 44.459
Train: [7][375/750]	BT 0.059 (1.197)	DT 0.003 (1.152)	loss 7.377 (7.377)	prob 2.324 (2.324)	GS 33.344 (33.344)	mem 44.461
Train: [7][380/750]	BT 0.040 (1.215)	DT 0.001 (1.170)	loss 7.054 (7.054)	prob 2.557 (2.557)	GS 33.594 (33.594)	mem 44.446
Train: [7][385/750]	BT 0.037 (1.200)	DT 0.002 (1.155)	loss 7.260 (7.260)	prob 1.995 (1.995)	GS 30.797 (30.797)	mem 44.448
Train: [7][390/750]	BT 4.052 (1.218)	DT 4.012 (1.173)	loss 7.275 (7.275)	prob 2.424 (2.424)	GS 29.938 (29.938)	mem 44.526
Train: [7][395/750]	BT 0.048 (1.204)	DT 0.015 (1.158)	loss 7.102 (7.102)	prob 2.336 (2.336)	GS 31.875 (31.875)	mem 44.527
Train: [7][400/750]	BT 11.218 (1.217)	DT 11.188 (1.172)	loss 7.203 (7.203)	prob 2.165 (2.165)	GS 34.734 (34.734)	mem 44.470
Train: [7][405/750]	BT 0.075 (1.208)	DT 0.014 (1.163)	loss 7.382 (7.382)	prob 1.915 (1.915)	GS 30.109 (30.109)	mem 44.414
Train: [7][410/750]	BT 0.032 (1.194)	DT 0.001 (1.149)	loss 7.223 (7.223)	prob 1.685 (1.685)	GS 35.516 (35.516)	mem 44.414
Train: [7][415/750]	BT 0.029 (1.213)	DT 0.001 (1.168)	loss 7.331 (7.331)	prob 1.629 (1.629)	GS 29.812 (29.812)	mem 44.386
Train: [7][420/750]	BT 0.022 (1.199)	DT 0.001 (1.154)	loss 6.903 (6.903)	prob 2.177 (2.177)	GS 36.266 (36.266)	mem 44.386
Train: [7][425/750]	BT 0.033 (1.199)	DT 0.003 (1.155)	loss 7.363 (7.363)	prob 2.299 (2.299)	GS 36.031 (36.031)	mem 44.480
Train: [7][430/750]	BT 0.098 (1.199)	DT 0.011 (1.154)	loss 7.086 (7.086)	prob 1.896 (1.896)	GS 31.766 (31.766)	mem 44.523
Train: [7][435/750]	BT 0.064 (1.186)	DT 0.009 (1.141)	loss 7.111 (7.111)	prob 2.169 (2.169)	GS 28.906 (28.906)	mem 44.596
Train: [7][440/750]	BT 0.048 (1.203)	DT 0.008 (1.158)	loss 7.214 (7.214)	prob 2.159 (2.159)	GS 35.484 (35.484)	mem 44.395
Train: [7][445/750]	BT 0.071 (1.190)	DT 0.018 (1.145)	loss 7.061 (7.061)	prob 2.257 (2.257)	GS 32.938 (32.938)	mem 44.395
Train: [7][450/750]	BT 3.521 (1.201)	DT 3.489 (1.156)	loss 7.086 (7.086)	prob 1.970 (1.970)	GS 30.250 (30.250)	mem 44.429
Train: [7][455/750]	BT 0.068 (1.189)	DT 0.002 (1.144)	loss 7.253 (7.253)	prob 2.432 (2.432)	GS 37.281 (37.281)	mem 44.429
Train: [7][460/750]	BT 12.217 (1.203)	DT 12.181 (1.158)	loss 7.214 (7.214)	prob 2.055 (2.055)	GS 36.266 (36.266)	mem 44.455
Train: [7][465/750]	BT 0.029 (1.195)	DT 0.001 (1.151)	loss 7.126 (7.126)	prob 2.295 (2.295)	GS 30.500 (30.500)	mem 44.458
Train: [7][470/750]	BT 0.111 (1.184)	DT 0.002 (1.138)	loss 6.921 (6.921)	prob 2.294 (2.294)	GS 31.453 (31.453)	mem 44.440
Train: [7][475/750]	BT 0.024 (1.198)	DT 0.001 (1.153)	loss 6.982 (6.982)	prob 2.355 (2.355)	GS 29.953 (29.953)	mem 44.421
Train: [7][480/750]	BT 0.108 (1.187)	DT 0.004 (1.141)	loss 7.670 (7.670)	prob 1.994 (1.994)	GS 37.766 (37.766)	mem 44.510
Train: [7][485/750]	BT 0.060 (1.204)	DT 0.004 (1.158)	loss 6.890 (6.890)	prob 2.965 (2.965)	GS 33.531 (33.531)	mem 44.347
Train: [7][490/750]	BT 0.049 (1.192)	DT 0.001 (1.147)	loss 7.196 (7.196)	prob 2.210 (2.210)	GS 32.984 (32.984)	mem 44.358
Train: [7][495/750]	BT 0.042 (1.180)	DT 0.001 (1.135)	loss 7.137 (7.137)	prob 2.288 (2.288)	GS 31.375 (31.375)	mem 44.388
Train: [7][500/750]	BT 0.029 (1.193)	DT 0.001 (1.148)	loss 7.109 (7.109)	prob 2.059 (2.059)	GS 37.141 (37.141)	mem 44.392
Train: [7][505/750]	BT 0.043 (1.181)	DT 0.004 (1.136)	loss 7.279 (7.279)	prob 2.194 (2.194)	GS 30.938 (30.938)	mem 44.393
Train: [7][510/750]	BT 0.438 (1.193)	DT 0.413 (1.148)	loss 7.299 (7.299)	prob 1.941 (1.941)	GS 31.047 (31.047)	mem 44.462
Train: [7][515/750]	BT 0.037 (1.184)	DT 0.002 (1.138)	loss 7.095 (7.095)	prob 2.558 (2.558)	GS 28.797 (28.797)	mem 44.406
Train: [7][520/750]	BT 14.350 (1.200)	DT 14.317 (1.155)	loss 7.149 (7.149)	prob 2.178 (2.178)	GS 35.719 (35.719)	mem 44.466
Train: [7][525/750]	BT 0.140 (1.190)	DT 0.007 (1.144)	loss 7.192 (7.192)	prob 2.243 (2.243)	GS 31.344 (31.344)	mem 44.500
Train: [7][530/750]	BT 0.060 (1.179)	DT 0.012 (1.133)	loss 7.143 (7.143)	prob 2.430 (2.430)	GS 30.609 (30.609)	mem 44.502
Train: [7][535/750]	BT 0.026 (1.197)	DT 0.001 (1.152)	loss 7.302 (7.302)	prob 2.243 (2.243)	GS 24.844 (24.844)	mem 44.479
Train: [7][540/750]	BT 0.026 (1.186)	DT 0.001 (1.141)	loss 7.019 (7.019)	prob 2.705 (2.705)	GS 35.172 (35.172)	mem 44.484
Train: [7][545/750]	BT 0.044 (1.199)	DT 0.003 (1.154)	loss 7.221 (7.221)	prob 2.430 (2.430)	GS 32.750 (32.750)	mem 44.524
Train: [7][550/750]	BT 0.044 (1.189)	DT 0.004 (1.144)	loss 7.230 (7.230)	prob 2.098 (2.098)	GS 30.844 (30.844)	mem 44.525
Train: [7][555/750]	BT 0.035 (1.178)	DT 0.001 (1.133)	loss 7.032 (7.032)	prob 2.263 (2.263)	GS 26.406 (26.406)	mem 44.592
Train: [7][560/750]	BT 0.031 (1.189)	DT 0.001 (1.144)	loss 7.122 (7.122)	prob 2.274 (2.274)	GS 34.453 (34.453)	mem 44.542
Train: [7][565/750]	BT 0.071 (1.179)	DT 0.013 (1.134)	loss 6.997 (6.997)	prob 2.161 (2.161)	GS 33.094 (33.094)	mem 44.548
Train: [7][570/750]	BT 0.028 (1.194)	DT 0.001 (1.149)	loss 7.137 (7.137)	prob 2.679 (2.679)	GS 35.969 (35.969)	mem 44.462
Train: [7][575/750]	BT 0.031 (1.184)	DT 0.009 (1.139)	loss 7.137 (7.137)	prob 2.270 (2.270)	GS 33.359 (33.359)	mem 44.462
Train: [7][580/750]	BT 11.293 (1.193)	DT 11.260 (1.149)	loss 7.186 (7.186)	prob 2.433 (2.433)	GS 35.172 (35.172)	mem 44.742
Train: [7][585/750]	BT 0.060 (1.183)	DT 0.004 (1.139)	loss 7.246 (7.246)	prob 2.029 (2.029)	GS 33.875 (33.875)	mem 44.651
Train: [7][590/750]	BT 0.026 (1.175)	DT 0.001 (1.130)	loss 7.053 (7.053)	prob 2.224 (2.224)	GS 34.297 (34.297)	mem 44.557
Train: [7][595/750]	BT 0.109 (1.190)	DT 0.027 (1.145)	loss 7.188 (7.188)	prob 2.627 (2.627)	GS 32.812 (32.812)	mem 44.500
Train: [7][600/750]	BT 0.108 (1.180)	DT 0.058 (1.136)	loss 6.827 (6.827)	prob 2.374 (2.374)	GS 35.438 (35.438)	mem 44.536
Train: [7][605/750]	BT 0.027 (1.192)	DT 0.001 (1.148)	loss 6.622 (6.622)	prob 2.739 (2.739)	GS 36.984 (36.984)	mem 44.348
Train: [7][610/750]	BT 0.033 (1.183)	DT 0.001 (1.138)	loss 6.829 (6.829)	prob 2.506 (2.506)	GS 33.672 (33.672)	mem 44.347
Train: [7][615/750]	BT 0.044 (1.173)	DT 0.011 (1.129)	loss 6.973 (6.973)	prob 2.630 (2.630)	GS 29.578 (29.578)	mem 44.376
Train: [7][620/750]	BT 0.074 (1.185)	DT 0.023 (1.141)	loss 7.120 (7.120)	prob 2.587 (2.587)	GS 32.250 (32.250)	mem 44.541
Train: [7][625/750]	BT 0.087 (1.176)	DT 0.025 (1.132)	loss 7.025 (7.025)	prob 2.553 (2.553)	GS 31.969 (31.969)	mem 44.509
Train: [7][630/750]	BT 0.029 (1.189)	DT 0.001 (1.144)	loss 6.934 (6.934)	prob 2.520 (2.520)	GS 31.391 (31.391)	mem 44.372
Train: [7][635/750]	BT 0.032 (1.180)	DT 0.001 (1.135)	loss 7.078 (7.078)	prob 2.842 (2.842)	GS 31.906 (31.906)	mem 44.477
Train: [7][640/750]	BT 9.594 (1.186)	DT 9.558 (1.142)	loss 7.007 (7.007)	prob 2.767 (2.767)	GS 31.094 (31.094)	mem 44.529
Train: [7][645/750]	BT 0.077 (1.177)	DT 0.006 (1.133)	loss 6.962 (6.962)	prob 2.400 (2.400)	GS 32.812 (32.812)	mem 44.653
Train: [7][650/750]	BT 1.344 (1.170)	DT 1.312 (1.126)	loss 7.104 (7.104)	prob 2.024 (2.024)	GS 25.469 (25.469)	mem 44.580
Train: [7][655/750]	BT 0.033 (1.178)	DT 0.001 (1.133)	loss 7.233 (7.233)	prob 2.738 (2.738)	GS 27.672 (27.672)	mem 44.500
Train: [7][660/750]	BT 0.060 (1.171)	DT 0.002 (1.127)	loss 6.945 (6.945)	prob 2.309 (2.309)	GS 34.297 (34.297)	mem 44.434
Train: [7][665/750]	BT 0.068 (1.180)	DT 0.012 (1.136)	loss 7.002 (7.002)	prob 2.315 (2.315)	GS 31.234 (31.234)	mem 44.408
Train: [7][670/750]	BT 0.067 (1.171)	DT 0.013 (1.127)	loss 7.005 (7.005)	prob 2.593 (2.593)	GS 37.188 (37.188)	mem 44.569
Train: [7][675/750]	BT 0.031 (1.172)	DT 0.001 (1.128)	loss 6.639 (6.639)	prob 2.588 (2.588)	GS 38.266 (38.266)	mem 44.457
Train: [7][680/750]	BT 0.375 (1.170)	DT 0.321 (1.126)	loss 6.961 (6.961)	prob 2.203 (2.203)	GS 35.906 (35.906)	mem 44.479
Train: [7][685/750]	BT 0.086 (1.168)	DT 0.007 (1.123)	loss 7.005 (7.005)	prob 2.383 (2.383)	GS 32.719 (32.719)	mem 44.501
Train: [7][690/750]	BT 0.031 (1.172)	DT 0.001 (1.128)	loss 6.896 (6.896)	prob 2.580 (2.580)	GS 32.656 (32.656)	mem 44.394
Train: [7][695/750]	BT 0.056 (1.164)	DT 0.011 (1.120)	loss 7.029 (7.029)	prob 2.287 (2.287)	GS 30.141 (30.141)	mem 44.394
Train: [7][700/750]	BT 2.770 (1.178)	DT 2.737 (1.134)	loss 7.440 (7.440)	prob 2.076 (2.076)	GS 36.312 (36.312)	mem 44.387
Train: [7][705/750]	BT 0.031 (1.170)	DT 0.001 (1.126)	loss 6.826 (6.826)	prob 2.485 (2.485)	GS 30.516 (30.516)	mem 44.387
Train: [7][710/750]	BT 6.076 (1.172)	DT 6.044 (1.128)	loss 6.751 (6.751)	prob 2.552 (2.552)	GS 32.938 (32.938)	mem 44.453
Train: [7][715/750]	BT 0.024 (1.176)	DT 0.001 (1.132)	loss 6.586 (6.586)	prob 2.355 (2.355)	GS 32.750 (32.750)	mem 44.358
Train: [7][720/750]	BT 0.036 (1.168)	DT 0.002 (1.124)	loss 7.134 (7.134)	prob 2.410 (2.410)	GS 33.547 (33.547)	mem 44.399
Train: [7][725/750]	BT 0.051 (1.176)	DT 0.002 (1.132)	loss 6.795 (6.795)	prob 2.664 (2.664)	GS 36.203 (36.203)	mem 44.333
Train: [7][730/750]	BT 0.025 (1.168)	DT 0.001 (1.124)	loss 7.067 (7.067)	prob 1.989 (1.989)	GS 30.750 (30.750)	mem 44.335
Train: [7][735/750]	BT 0.060 (1.161)	DT 0.003 (1.117)	loss 6.776 (6.776)	prob 2.797 (2.797)	GS 30.266 (30.266)	mem 41.501
Train: [7][740/750]	BT 0.037 (1.165)	DT 0.001 (1.121)	loss 7.151 (7.151)	prob 1.826 (1.826)	GS 27.297 (27.297)	mem 18.245
Train: [7][745/750]	BT 0.031 (1.158)	DT 0.002 (1.114)	loss 6.879 (6.879)	prob 2.178 (2.178)	GS 31.312 (31.312)	mem 16.814
Train: [7][750/750]	BT 0.024 (1.153)	DT 0.001 (1.109)	loss 6.810 (6.810)	prob 2.513 (2.513)	GS 36.125 (36.125)	mem 12.068
Train: [7][755/750]	BT 0.033 (1.146)	DT 0.001 (1.102)	loss 6.694 (6.694)	prob 2.068 (2.068)	GS 32.844 (32.844)	mem 12.067
epoch 7, total time 865.42
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [8][1/750]	BT 19.619 (19.619)	DT 19.545 (19.545)	loss 6.567 (6.567)	prob 2.401 (2.401)	GS 32.719 (32.719)	mem 42.842
Train: [8][5/750]	BT 0.092 (4.475)	DT 0.013 (4.414)	loss 6.643 (6.643)	prob 2.223 (2.223)	GS 30.938 (30.938)	mem 42.963
Train: [8][10/750]	BT 1.152 (2.385)	DT 1.105 (2.325)	loss 6.917 (6.917)	prob 1.813 (1.813)	GS 34.859 (34.859)	mem 43.014
Train: [8][15/750]	BT 0.040 (2.154)	DT 0.001 (2.099)	loss 6.385 (6.385)	prob 2.869 (2.869)	GS 27.672 (27.672)	mem 43.153
Train: [8][20/750]	BT 0.032 (1.879)	DT 0.001 (1.829)	loss 6.845 (6.845)	prob 2.635 (2.635)	GS 34.703 (34.703)	mem 43.273
Train: [8][25/750]	BT 0.515 (1.539)	DT 0.428 (1.488)	loss 6.753 (6.753)	prob 2.747 (2.747)	GS 31.750 (31.750)	mem 43.275
Train: [8][30/750]	BT 2.817 (1.678)	DT 2.770 (1.628)	loss 6.616 (6.616)	prob 2.799 (2.799)	GS 36.109 (36.109)	mem 43.315
Train: [8][35/750]	BT 0.035 (1.592)	DT 0.005 (1.544)	loss 7.011 (7.011)	prob 2.174 (2.174)	GS 29.484 (29.484)	mem 43.320
Train: [8][40/750]	BT 3.787 (1.612)	DT 3.756 (1.564)	loss 7.054 (7.054)	prob 2.405 (2.405)	GS 38.516 (38.516)	mem 43.385
Train: [8][45/750]	BT 0.034 (1.437)	DT 0.003 (1.391)	loss 6.871 (6.871)	prob 2.391 (2.391)	GS 33.922 (33.922)	mem 43.387
Train: [8][50/750]	BT 6.039 (1.472)	DT 6.008 (1.426)	loss 6.825 (6.825)	prob 2.564 (2.564)	GS 32.078 (32.078)	mem 43.500
Train: [8][55/750]	BT 0.033 (1.418)	DT 0.002 (1.372)	loss 6.828 (6.828)	prob 2.247 (2.247)	GS 31.531 (31.531)	mem 42.206
Train: [8][60/750]	BT 0.094 (1.394)	DT 0.002 (1.347)	loss 6.926 (6.926)	prob 2.022 (2.022)	GS 33.828 (33.828)	mem 42.193
Train: [8][65/750]	BT 0.091 (1.397)	DT 0.012 (1.349)	loss 7.149 (7.149)	prob 1.753 (1.753)	GS 34.766 (34.766)	mem 42.388
Train: [8][70/750]	BT 2.832 (1.353)	DT 2.800 (1.305)	loss 6.824 (6.824)	prob 2.256 (2.256)	GS 32.859 (32.859)	mem 42.254
Train: [8][75/750]	BT 0.065 (1.295)	DT 0.010 (1.246)	loss 7.103 (7.103)	prob 1.702 (1.702)	GS 30.688 (30.688)	mem 42.380
Train: [8][80/750]	BT 0.032 (1.314)	DT 0.001 (1.265)	loss 6.995 (6.995)	prob 1.633 (1.633)	GS 35.750 (35.750)	mem 42.279
Train: [8][85/750]	BT 0.033 (1.268)	DT 0.001 (1.220)	loss 6.601 (6.601)	prob 2.276 (2.276)	GS 32.516 (32.516)	mem 42.402
Train: [8][90/750]	BT 0.049 (1.319)	DT 0.002 (1.272)	loss 7.188 (7.188)	prob 1.510 (1.510)	GS 31.844 (31.844)	mem 42.468
Train: [8][95/750]	BT 0.068 (1.265)	DT 0.004 (1.218)	loss 6.815 (6.815)	prob 1.547 (1.547)	GS 27.453 (27.453)	mem 42.373
Train: [8][100/750]	BT 4.537 (1.290)	DT 4.475 (1.241)	loss 6.877 (6.877)	prob 1.501 (1.501)	GS 33.438 (33.438)	mem 42.437
Train: [8][105/750]	BT 0.066 (1.285)	DT 0.001 (1.236)	loss 6.606 (6.606)	prob 1.955 (1.955)	GS 31.188 (31.188)	mem 42.364
Train: [8][110/750]	BT 3.455 (1.260)	DT 3.383 (1.211)	loss 6.883 (6.883)	prob 1.878 (1.878)	GS 37.562 (37.562)	mem 42.447
Train: [8][115/750]	BT 0.039 (1.290)	DT 0.003 (1.240)	loss 6.750 (6.750)	prob 1.799 (1.799)	GS 30.844 (30.844)	mem 42.535
Train: [8][120/750]	BT 0.070 (1.238)	DT 0.003 (1.189)	loss 6.650 (6.650)	prob 1.583 (1.583)	GS 38.906 (38.906)	mem 42.404
Train: [8][125/750]	BT 0.028 (1.254)	DT 0.001 (1.206)	loss 6.929 (6.929)	prob 1.636 (1.636)	GS 33.969 (33.969)	mem 42.386
Train: [8][130/750]	BT 0.120 (1.239)	DT 0.081 (1.191)	loss 7.192 (7.192)	prob 1.360 (1.360)	GS 35.938 (35.938)	mem 42.358
Train: [8][135/750]	BT 0.071 (1.261)	DT 0.003 (1.212)	loss 6.989 (6.989)	prob 1.352 (1.352)	GS 28.828 (28.828)	mem 42.429
Train: [8][140/750]	BT 0.030 (1.251)	DT 0.001 (1.203)	loss 7.070 (7.070)	prob 1.423 (1.423)	GS 30.344 (30.344)	mem 42.470
Train: [8][145/750]	BT 0.036 (1.231)	DT 0.001 (1.184)	loss 6.853 (6.853)	prob 1.381 (1.381)	GS 30.234 (30.234)	mem 42.431
Train: [8][150/750]	BT 3.271 (1.256)	DT 3.217 (1.208)	loss 6.921 (6.921)	prob 1.764 (1.764)	GS 33.828 (33.828)	mem 42.653
Train: [8][155/750]	BT 0.088 (1.266)	DT 0.027 (1.218)	loss 6.861 (6.861)	prob 1.181 (1.181)	GS 30.859 (30.859)	mem 42.697
Train: [8][160/750]	BT 0.032 (1.260)	DT 0.002 (1.213)	loss 7.246 (7.246)	prob 1.309 (1.309)	GS 35.578 (35.578)	mem 42.718
Train: [8][165/750]	BT 0.055 (1.228)	DT 0.002 (1.180)	loss 6.969 (6.969)	prob 1.276 (1.276)	GS 31.688 (31.688)	mem 42.715
Train: [8][170/750]	BT 7.113 (1.274)	DT 7.083 (1.227)	loss 7.129 (7.129)	prob 1.246 (1.246)	GS 33.375 (33.375)	mem 42.704
Train: [8][175/750]	BT 0.034 (1.238)	DT 0.001 (1.192)	loss 7.090 (7.090)	prob 1.425 (1.425)	GS 26.531 (26.531)	mem 42.740
Train: [8][180/750]	BT 0.036 (1.211)	DT 0.002 (1.165)	loss 6.986 (6.986)	prob 1.463 (1.463)	GS 35.672 (35.672)	mem 42.740
Train: [8][185/750]	BT 0.023 (1.222)	DT 0.001 (1.176)	loss 6.693 (6.693)	prob 1.867 (1.867)	GS 29.938 (29.938)	mem 42.714
Train: [8][190/750]	BT 1.215 (1.197)	DT 1.165 (1.151)	loss 6.790 (6.790)	prob 1.887 (1.887)	GS 31.828 (31.828)	mem 42.726
Train: [8][195/750]	BT 0.037 (1.225)	DT 0.001 (1.178)	loss 6.841 (6.841)	prob 1.590 (1.590)	GS 32.781 (32.781)	mem 42.780
Train: [8][200/750]	BT 0.160 (1.196)	DT 0.055 (1.149)	loss 7.577 (7.577)	prob 1.464 (1.464)	GS 34.078 (34.078)	mem 42.782
Train: [8][205/750]	BT 0.064 (1.191)	DT 0.007 (1.145)	loss 7.063 (7.063)	prob 1.252 (1.252)	GS 32.656 (32.656)	mem 42.723
Train: [8][210/750]	BT 0.056 (1.191)	DT 0.009 (1.144)	loss 7.207 (7.207)	prob 2.822 (2.822)	GS 32.516 (32.516)	mem 42.856
Train: [8][215/750]	BT 0.056 (1.193)	DT 0.017 (1.146)	loss 7.105 (7.105)	prob 0.674 (0.674)	GS 30.328 (30.328)	mem 42.846
Train: [8][220/750]	BT 0.061 (1.200)	DT 0.008 (1.153)	loss 6.970 (6.970)	prob 1.621 (1.621)	GS 30.641 (30.641)	mem 42.973
Train: [8][225/750]	BT 0.041 (1.174)	DT 0.002 (1.128)	loss 7.379 (7.379)	prob 0.992 (0.992)	GS 40.172 (40.172)	mem 42.973
Train: [8][230/750]	BT 4.520 (1.201)	DT 4.482 (1.154)	loss 7.361 (7.361)	prob 2.217 (2.217)	GS 31.906 (31.906)	mem 42.994
Train: [8][235/750]	BT 0.054 (1.176)	DT 0.002 (1.130)	loss 7.353 (7.353)	prob 1.432 (1.432)	GS 31.922 (31.922)	mem 42.994
Train: [8][240/750]	BT 0.036 (1.193)	DT 0.002 (1.147)	loss 7.194 (7.194)	prob 2.162 (2.162)	GS 31.172 (31.172)	mem 43.193
Train: [8][245/750]	BT 0.036 (1.183)	DT 0.001 (1.136)	loss 7.176 (7.176)	prob 1.201 (1.201)	GS 32.516 (32.516)	mem 43.095
Train: [8][250/750]	BT 8.017 (1.192)	DT 7.984 (1.146)	loss 6.948 (6.948)	prob 1.965 (1.965)	GS 31.594 (31.594)	mem 43.132
Train: [8][255/750]	BT 0.038 (1.189)	DT 0.002 (1.143)	loss 7.389 (7.389)	prob 1.199 (1.199)	GS 35.797 (35.797)	mem 42.998
Train: [8][260/750]	BT 0.033 (1.167)	DT 0.003 (1.121)	loss 7.189 (7.189)	prob 1.498 (1.498)	GS 37.781 (37.781)	mem 43.036
Train: [8][265/750]	BT 0.052 (1.185)	DT 0.011 (1.139)	loss 7.438 (7.438)	prob 0.709 (0.709)	GS 33.469 (33.469)	mem 43.100
Train: [8][270/750]	BT 0.061 (1.173)	DT 0.009 (1.127)	loss 8.082 (8.082)	prob 1.193 (1.193)	GS 33.453 (33.453)	mem 43.132
Train: [8][275/750]	BT 0.025 (1.187)	DT 0.001 (1.142)	loss 6.867 (6.867)	prob 1.904 (1.904)	GS 31.188 (31.188)	mem 43.217
Train: [8][280/750]	BT 0.054 (1.169)	DT 0.002 (1.124)	loss 7.196 (7.196)	prob 1.957 (1.957)	GS 33.750 (33.750)	mem 43.035
Train: [8][285/750]	BT 0.034 (1.150)	DT 0.001 (1.104)	loss 7.241 (7.241)	prob 1.395 (1.395)	GS 31.203 (31.203)	mem 43.036
Train: [8][290/750]	BT 7.849 (1.194)	DT 7.817 (1.149)	loss 7.913 (7.913)	prob 2.313 (2.313)	GS 32.812 (32.812)	mem 43.059
Train: [8][295/750]	BT 0.023 (1.174)	DT 0.001 (1.130)	loss 7.074 (7.074)	prob 1.874 (1.874)	GS 28.016 (28.016)	mem 43.063
Train: [8][300/750]	BT 0.028 (1.174)	DT 0.001 (1.129)	loss 7.138 (7.138)	prob 2.491 (2.491)	GS 33.531 (33.531)	mem 43.126
Train: [8][305/750]	BT 0.032 (1.178)	DT 0.002 (1.133)	loss 7.102 (7.102)	prob 2.293 (2.293)	GS 32.781 (32.781)	mem 43.093
Train: [8][310/750]	BT 6.297 (1.180)	DT 6.254 (1.135)	loss 7.400 (7.400)	prob 2.119 (2.119)	GS 32.281 (32.281)	mem 43.149
Train: [8][315/750]	BT 0.038 (1.188)	DT 0.001 (1.144)	loss 7.754 (7.754)	prob 0.713 (0.713)	GS 30.703 (30.703)	mem 43.108
Train: [8][320/750]	BT 0.045 (1.171)	DT 0.007 (1.126)	loss 7.251 (7.251)	prob 2.680 (2.680)	GS 34.922 (34.922)	mem 43.110
Train: [8][325/750]	BT 0.031 (1.167)	DT 0.001 (1.122)	loss 7.023 (7.023)	prob 1.704 (1.704)	GS 26.391 (26.391)	mem 42.848
Train: [8][330/750]	BT 0.056 (1.173)	DT 0.011 (1.128)	loss 6.901 (6.901)	prob 3.114 (3.114)	GS 32.375 (32.375)	mem 42.882
Train: [8][335/750]	BT 0.072 (1.168)	DT 0.010 (1.123)	loss 7.426 (7.426)	prob 1.586 (1.586)	GS 27.594 (27.594)	mem 42.820
Train: [8][340/750]	BT 0.042 (1.176)	DT 0.001 (1.131)	loss 7.421 (7.421)	prob 2.916 (2.916)	GS 33.641 (33.641)	mem 42.972
Train: [8][345/750]	BT 0.053 (1.159)	DT 0.010 (1.115)	loss 7.501 (7.501)	prob 2.376 (2.376)	GS 30.172 (30.172)	mem 42.943
Train: [8][350/750]	BT 8.311 (1.180)	DT 8.271 (1.136)	loss 7.420 (7.420)	prob 1.698 (1.698)	GS 33.500 (33.500)	mem 42.857
Train: [8][355/750]	BT 0.038 (1.164)	DT 0.004 (1.120)	loss 7.103 (7.103)	prob 2.383 (2.383)	GS 30.375 (30.375)	mem 42.944
Train: [8][360/750]	BT 0.039 (1.171)	DT 0.010 (1.127)	loss 7.091 (7.091)	prob 2.671 (2.671)	GS 32.766 (32.766)	mem 42.895
Train: [8][365/750]	BT 0.044 (1.164)	DT 0.002 (1.120)	loss 7.101 (7.101)	prob 2.521 (2.521)	GS 28.688 (28.688)	mem 42.897
Train: [8][370/750]	BT 12.831 (1.184)	DT 12.786 (1.139)	loss 7.313 (7.313)	prob 2.028 (2.028)	GS 38.953 (38.953)	mem 42.908
Train: [8][375/750]	BT 0.023 (1.168)	DT 0.001 (1.124)	loss 7.217 (7.217)	prob 1.459 (1.459)	GS 35.547 (35.547)	mem 42.957
Train: [8][380/750]	BT 0.031 (1.154)	DT 0.001 (1.110)	loss 7.583 (7.583)	prob 2.293 (2.293)	GS 34.688 (34.688)	mem 42.910
Train: [8][385/750]	BT 0.029 (1.173)	DT 0.001 (1.130)	loss 7.537 (7.537)	prob 2.111 (2.111)	GS 33.234 (33.234)	mem 42.903
Train: [8][390/750]	BT 0.033 (1.159)	DT 0.001 (1.115)	loss 7.249 (7.249)	prob 2.376 (2.376)	GS 35.125 (35.125)	mem 42.836
Train: [8][395/750]	BT 0.030 (1.176)	DT 0.001 (1.132)	loss 7.326 (7.326)	prob 1.180 (1.180)	GS 29.781 (29.781)	mem 42.957
Train: [8][400/750]	BT 0.023 (1.161)	DT 0.001 (1.118)	loss 7.708 (7.708)	prob 1.935 (1.935)	GS 33.406 (33.406)	mem 42.785
Train: [8][405/750]	BT 0.030 (1.147)	DT 0.001 (1.104)	loss 7.126 (7.126)	prob 2.116 (2.116)	GS 29.750 (29.750)	mem 42.819
Train: [8][410/750]	BT 0.074 (1.167)	DT 0.004 (1.123)	loss 7.303 (7.303)	prob 2.512 (2.512)	GS 35.453 (35.453)	mem 42.730
Train: [8][415/750]	BT 0.046 (1.153)	DT 0.012 (1.110)	loss 7.381 (7.381)	prob 2.132 (2.132)	GS 28.859 (28.859)	mem 42.730
Train: [8][420/750]	BT 0.023 (1.167)	DT 0.001 (1.124)	loss 8.081 (8.081)	prob 2.249 (2.249)	GS 35.781 (35.781)	mem 42.983
Train: [8][425/750]	BT 0.095 (1.154)	DT 0.011 (1.111)	loss 7.966 (7.966)	prob 1.780 (1.780)	GS 31.875 (31.875)	mem 43.181
Train: [8][430/750]	BT 13.611 (1.172)	DT 13.583 (1.129)	loss 7.661 (7.661)	prob 2.409 (2.409)	GS 37.172 (37.172)	mem 42.823
Train: [8][435/750]	BT 0.024 (1.159)	DT 0.001 (1.116)	loss 7.927 (7.927)	prob 1.699 (1.699)	GS 31.938 (31.938)	mem 42.793
Train: [8][440/750]	BT 0.052 (1.147)	DT 0.012 (1.104)	loss 7.318 (7.318)	prob 2.705 (2.705)	GS 34.141 (34.141)	mem 42.814
Train: [8][445/750]	BT 0.032 (1.166)	DT 0.001 (1.124)	loss 8.172 (8.172)	prob 2.092 (2.092)	GS 31.672 (31.672)	mem 42.861
Train: [8][450/750]	BT 0.109 (1.154)	DT 0.012 (1.111)	loss 7.821 (7.821)	prob 2.391 (2.391)	GS 33.406 (33.406)	mem 42.861
Train: [8][455/750]	BT 0.033 (1.169)	DT 0.001 (1.126)	loss 7.477 (7.477)	prob 2.219 (2.219)	GS 29.609 (29.609)	mem 42.880
Train: [8][460/750]	BT 0.028 (1.157)	DT 0.001 (1.114)	loss 8.109 (8.109)	prob 2.340 (2.340)	GS 33.188 (33.188)	mem 42.879
Train: [8][465/750]	BT 0.050 (1.145)	DT 0.009 (1.102)	loss 7.507 (7.507)	prob 1.872 (1.872)	GS 30.188 (30.188)	mem 42.883
Train: [8][470/750]	BT 1.937 (1.165)	DT 1.887 (1.122)	loss 8.121 (8.121)	prob 2.534 (2.534)	GS 32.750 (32.750)	mem 42.925
Train: [8][475/750]	BT 0.035 (1.153)	DT 0.002 (1.110)	loss 7.498 (7.498)	prob 3.087 (3.087)	GS 33.109 (33.109)	mem 42.924
Train: [8][480/750]	BT 0.031 (1.164)	DT 0.001 (1.121)	loss 7.977 (7.977)	prob 2.904 (2.904)	GS 34.484 (34.484)	mem 42.936
Train: [8][485/750]	BT 0.034 (1.158)	DT 0.001 (1.116)	loss 7.155 (7.155)	prob 3.125 (3.125)	GS 30.375 (30.375)	mem 42.940
Train: [8][490/750]	BT 8.055 (1.163)	DT 8.021 (1.121)	loss 7.665 (7.665)	prob 2.978 (2.978)	GS 30.172 (30.172)	mem 42.943
Train: [8][495/750]	BT 0.033 (1.162)	DT 0.002 (1.120)	loss 7.525 (7.525)	prob 2.604 (2.604)	GS 33.031 (33.031)	mem 42.950
Train: [8][500/750]	BT 0.123 (1.152)	DT 0.023 (1.109)	loss 7.791 (7.791)	prob 2.637 (2.637)	GS 32.438 (32.438)	mem 42.957
Train: [8][505/750]	BT 0.089 (1.161)	DT 0.002 (1.118)	loss 8.022 (8.022)	prob 1.981 (1.981)	GS 41.078 (41.078)	mem 42.974
Train: [8][510/750]	BT 0.034 (1.150)	DT 0.001 (1.107)	loss 7.348 (7.348)	prob 3.140 (3.140)	GS 34.156 (34.156)	mem 42.940
Train: [8][515/750]	BT 0.031 (1.159)	DT 0.001 (1.115)	loss 6.911 (6.911)	prob 3.124 (3.124)	GS 32.531 (32.531)	mem 42.910
Train: [8][520/750]	BT 0.036 (1.152)	DT 0.001 (1.109)	loss 6.983 (6.983)	prob 3.260 (3.260)	GS 34.953 (34.953)	mem 42.914
Train: [8][525/750]	BT 0.040 (1.141)	DT 0.001 (1.098)	loss 7.782 (7.782)	prob 1.062 (1.062)	GS 33.156 (33.156)	mem 42.914
Train: [8][530/750]	BT 0.077 (1.154)	DT 0.003 (1.111)	loss 7.574 (7.574)	prob 3.503 (3.503)	GS 30.797 (30.797)	mem 42.934
Train: [8][535/750]	BT 0.048 (1.144)	DT 0.016 (1.101)	loss 7.085 (7.085)	prob 3.103 (3.103)	GS 29.766 (29.766)	mem 42.939
Train: [8][540/750]	BT 0.033 (1.161)	DT 0.003 (1.118)	loss 7.689 (7.689)	prob 2.150 (2.150)	GS 35.172 (35.172)	mem 43.011
Train: [8][545/750]	BT 0.060 (1.151)	DT 0.007 (1.108)	loss 8.030 (8.030)	prob 1.457 (1.457)	GS 31.047 (31.047)	mem 42.946
Train: [8][550/750]	BT 12.826 (1.164)	DT 12.792 (1.121)	loss 6.918 (6.918)	prob 3.264 (3.264)	GS 35.656 (35.656)	mem 42.989
Train: [8][555/750]	BT 0.094 (1.154)	DT 0.012 (1.111)	loss 8.825 (8.825)	prob 0.823 (0.823)	GS 36.391 (36.391)	mem 42.854
Train: [8][560/750]	BT 0.128 (1.144)	DT 0.022 (1.101)	loss 7.239 (7.239)	prob 2.365 (2.365)	GS 32.719 (32.719)	mem 42.920
Train: [8][565/750]	BT 0.027 (1.156)	DT 0.001 (1.113)	loss 7.141 (7.141)	prob 2.249 (2.249)	GS 29.000 (29.000)	mem 42.934
Train: [8][570/750]	BT 0.022 (1.146)	DT 0.001 (1.103)	loss 7.282 (7.282)	prob 3.285 (3.285)	GS 35.781 (35.781)	mem 42.934
Train: [8][575/750]	BT 0.038 (1.155)	DT 0.002 (1.112)	loss 7.134 (7.134)	prob 3.044 (3.044)	GS 29.875 (29.875)	mem 42.999
Train: [8][580/750]	BT 0.025 (1.145)	DT 0.001 (1.103)	loss 6.842 (6.842)	prob 2.650 (2.650)	GS 27.672 (27.672)	mem 43.001
Train: [8][585/750]	BT 0.024 (1.136)	DT 0.001 (1.093)	loss 7.301 (7.301)	prob 2.983 (2.983)	GS 31.797 (31.797)	mem 43.003
Train: [8][590/750]	BT 0.029 (1.151)	DT 0.001 (1.109)	loss 7.370 (7.370)	prob 2.409 (2.409)	GS 36.906 (36.906)	mem 42.897
Train: [8][595/750]	BT 0.032 (1.142)	DT 0.002 (1.099)	loss 7.258 (7.258)	prob 2.026 (2.026)	GS 28.859 (28.859)	mem 42.896
Train: [8][600/750]	BT 0.021 (1.152)	DT 0.001 (1.110)	loss 7.434 (7.434)	prob 2.461 (2.461)	GS 31.438 (31.438)	mem 42.915
Train: [8][605/750]	BT 0.036 (1.143)	DT 0.001 (1.101)	loss 8.488 (8.488)	prob 1.121 (1.121)	GS 44.250 (44.250)	mem 43.240
Train: [8][610/750]	BT 14.656 (1.158)	DT 14.628 (1.116)	loss 7.596 (7.596)	prob 3.164 (3.164)	GS 35.078 (35.078)	mem 42.874
Train: [8][615/750]	BT 0.025 (1.149)	DT 0.001 (1.107)	loss 7.261 (7.261)	prob 2.977 (2.977)	GS 33.078 (33.078)	mem 42.874
Train: [8][620/750]	BT 0.025 (1.140)	DT 0.001 (1.098)	loss 7.608 (7.608)	prob 2.830 (2.830)	GS 35.234 (35.234)	mem 42.911
Train: [8][625/750]	BT 0.042 (1.152)	DT 0.014 (1.110)	loss 8.157 (8.157)	prob 1.985 (1.985)	GS 32.750 (32.750)	mem 42.988
Train: [8][630/750]	BT 0.086 (1.143)	DT 0.002 (1.101)	loss 7.303 (7.303)	prob 3.445 (3.445)	GS 37.250 (37.250)	mem 42.989
Train: [8][635/750]	BT 0.045 (1.153)	DT 0.003 (1.111)	loss 7.531 (7.531)	prob 1.716 (1.716)	GS 32.734 (32.734)	mem 42.994
Train: [8][640/750]	BT 0.088 (1.144)	DT 0.001 (1.102)	loss 7.457 (7.457)	prob 3.182 (3.182)	GS 35.562 (35.562)	mem 43.114
Train: [8][645/750]	BT 0.026 (1.136)	DT 0.001 (1.094)	loss 8.196 (8.196)	prob 1.252 (1.252)	GS 29.906 (29.906)	mem 43.072
Train: [8][650/750]	BT 0.030 (1.147)	DT 0.002 (1.104)	loss 7.837 (7.837)	prob 2.220 (2.220)	GS 33.188 (33.188)	mem 43.016
Train: [8][655/750]	BT 0.033 (1.138)	DT 0.002 (1.096)	loss 7.243 (7.243)	prob 2.843 (2.843)	GS 30.266 (30.266)	mem 43.005
Train: [8][660/750]	BT 0.048 (1.151)	DT 0.006 (1.108)	loss 7.337 (7.337)	prob 3.136 (3.136)	GS 28.344 (28.344)	mem 42.969
Train: [8][665/750]	BT 0.039 (1.143)	DT 0.001 (1.100)	loss 7.248 (7.248)	prob 3.177 (3.177)	GS 30.859 (30.859)	mem 42.971
arpack error, retry= 0
arpack error, retry= 0
Train: [8][670/750]	BT 15.894 (1.158)	DT 15.800 (1.115)	loss 7.559 (7.559)	prob 2.999 (2.999)	GS 31.859 (31.859)	mem 42.805
Train: [8][675/750]	BT 0.033 (1.150)	DT 0.001 (1.107)	loss 8.363 (8.363)	prob 0.822 (0.822)	GS 29.359 (29.359)	mem 42.846
Train: [8][680/750]	BT 0.072 (1.142)	DT 0.012 (1.099)	loss 7.712 (7.712)	prob 2.181 (2.181)	GS 34.453 (34.453)	mem 42.807
Train: [8][685/750]	BT 0.035 (1.152)	DT 0.005 (1.109)	loss 7.626 (7.626)	prob 1.924 (1.924)	GS 32.891 (32.891)	mem 42.947
Train: [8][690/750]	BT 0.033 (1.144)	DT 0.001 (1.101)	loss 7.775 (7.775)	prob 2.543 (2.543)	GS 33.156 (33.156)	mem 42.970
Train: [8][695/750]	BT 0.046 (1.157)	DT 0.011 (1.114)	loss 7.370 (7.370)	prob 2.726 (2.726)	GS 30.812 (30.812)	mem 42.912
Train: [8][700/750]	BT 0.041 (1.149)	DT 0.001 (1.106)	loss 8.373 (8.373)	prob 3.523 (3.523)	GS 35.156 (35.156)	mem 42.912
Train: [8][705/750]	BT 0.047 (1.141)	DT 0.009 (1.098)	loss 7.585 (7.585)	prob 2.866 (2.866)	GS 28.469 (28.469)	mem 42.913
Train: [8][710/750]	BT 0.042 (1.146)	DT 0.003 (1.103)	loss 7.352 (7.352)	prob 3.667 (3.667)	GS 33.297 (33.297)	mem 42.972
Train: [8][715/750]	BT 0.049 (1.139)	DT 0.007 (1.096)	loss 7.384 (7.384)	prob 2.487 (2.487)	GS 30.391 (30.391)	mem 43.080
Train: [8][720/750]	BT 0.033 (1.148)	DT 0.003 (1.105)	loss 7.627 (7.627)	prob 3.366 (3.366)	GS 31.219 (31.219)	mem 42.979
Train: [8][725/750]	BT 0.040 (1.141)	DT 0.001 (1.098)	loss 7.391 (7.391)	prob 2.660 (2.660)	GS 30.953 (30.953)	mem 42.967
Train: [8][730/750]	BT 9.230 (1.146)	DT 9.203 (1.103)	loss 7.842 (7.842)	prob 2.424 (2.424)	GS 36.359 (36.359)	mem 42.597
Train: [8][735/750]	BT 0.030 (1.138)	DT 0.001 (1.096)	loss 7.540 (7.540)	prob 2.129 (2.129)	GS 32.141 (32.141)	mem 40.936
Train: [8][740/750]	BT 0.045 (1.131)	DT 0.001 (1.088)	loss 7.306 (7.306)	prob 4.136 (4.136)	GS 31.703 (31.703)	mem 39.776
Train: [8][745/750]	BT 0.035 (1.132)	DT 0.001 (1.089)	loss 7.448 (7.448)	prob 2.414 (2.414)	GS 29.844 (29.844)	mem 13.670
Train: [8][750/750]	BT 0.027 (1.124)	DT 0.001 (1.082)	loss 7.301 (7.301)	prob 2.806 (2.806)	GS 35.094 (35.094)	mem 13.670
Train: [8][755/750]	BT 0.031 (1.120)	DT 0.002 (1.078)	loss 7.250 (7.250)	prob 2.784 (2.784)	GS 29.000 (29.000)	mem 10.659
epoch 8, total time 845.82
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [9][1/750]	BT 20.278 (20.278)	DT 20.222 (20.222)	loss 7.309 (7.309)	prob 3.293 (3.293)	GS 29.516 (29.516)	mem 41.516
Train: [9][5/750]	BT 0.046 (4.910)	DT 0.003 (4.871)	loss 7.834 (7.834)	prob 1.770 (1.770)	GS 34.469 (34.469)	mem 41.655
Train: [9][10/750]	BT 0.050 (2.769)	DT 0.008 (2.721)	loss 7.640 (7.640)	prob 3.065 (3.065)	GS 33.406 (33.406)	mem 41.666
Train: [9][15/750]	BT 2.515 (2.329)	DT 2.488 (2.283)	loss 8.089 (8.089)	prob 2.089 (2.089)	GS 37.062 (37.062)	mem 41.844
Train: [9][20/750]	BT 3.730 (2.127)	DT 3.679 (2.081)	loss 7.672 (7.672)	prob 1.937 (1.937)	GS 37.500 (37.500)	mem 41.838
Train: [9][25/750]	BT 0.068 (1.717)	DT 0.008 (1.666)	loss 7.641 (7.641)	prob 2.331 (2.331)	GS 29.750 (29.750)	mem 41.846
Train: [9][30/750]	BT 0.587 (1.813)	DT 0.538 (1.763)	loss 7.678 (7.678)	prob 3.071 (3.071)	GS 32.609 (32.609)	mem 41.872
Train: [9][35/750]	BT 0.056 (1.699)	DT 0.009 (1.649)	loss 7.363 (7.363)	prob 2.959 (2.959)	GS 32.125 (32.125)	mem 41.846
Train: [9][40/750]	BT 9.261 (1.722)	DT 9.195 (1.673)	loss 7.883 (7.883)	prob 2.993 (2.993)	GS 32.906 (32.906)	mem 42.178
Train: [9][45/750]	BT 0.068 (1.624)	DT 0.005 (1.576)	loss 7.759 (7.759)	prob 2.357 (2.357)	GS 33.172 (33.172)	mem 42.015
Train: [9][50/750]	BT 0.044 (1.469)	DT 0.005 (1.421)	loss 7.822 (7.822)	prob 3.835 (3.835)	GS 28.703 (28.703)	mem 42.018
Train: [9][55/750]	BT 0.026 (1.552)	DT 0.004 (1.504)	loss 8.130 (8.130)	prob 3.040 (3.040)	GS 38.984 (38.984)	mem 42.061
Train: [9][60/750]	BT 0.062 (1.446)	DT 0.011 (1.399)	loss 7.779 (7.779)	prob 3.162 (3.162)	GS 32.688 (32.688)	mem 41.917
Train: [9][65/750]	BT 0.065 (1.428)	DT 0.005 (1.380)	loss 7.342 (7.342)	prob 3.343 (3.343)	GS 32.344 (32.344)	mem 42.042
Train: [9][70/750]	BT 1.053 (1.447)	DT 1.020 (1.399)	loss 7.849 (7.849)	prob 2.219 (2.219)	GS 33.250 (33.250)	mem 41.963
Train: [9][75/750]	BT 0.031 (1.353)	DT 0.001 (1.306)	loss 7.617 (7.617)	prob 2.616 (2.616)	GS 32.156 (32.156)	mem 41.964
Train: [9][80/750]	BT 0.066 (1.429)	DT 0.009 (1.382)	loss 7.446 (7.446)	prob 2.730 (2.730)	GS 30.906 (30.906)	mem 42.075
Train: [9][85/750]	BT 0.026 (1.348)	DT 0.001 (1.301)	loss 7.438 (7.438)	prob 3.043 (3.043)	GS 31.344 (31.344)	mem 42.034
Train: [9][90/750]	BT 6.854 (1.399)	DT 6.822 (1.351)	loss 7.250 (7.250)	prob 3.112 (3.112)	GS 30.562 (30.562)	mem 42.168
Train: [9][95/750]	BT 0.077 (1.364)	DT 0.005 (1.316)	loss 7.636 (7.636)	prob 2.604 (2.604)	GS 29.688 (29.688)	mem 42.160
Train: [9][100/750]	BT 0.026 (1.297)	DT 0.001 (1.250)	loss 7.462 (7.462)	prob 3.248 (3.248)	GS 30.828 (30.828)	mem 42.104
Train: [9][105/750]	BT 0.034 (1.297)	DT 0.002 (1.250)	loss 7.738 (7.738)	prob 2.786 (2.786)	GS 34.812 (34.812)	mem 42.157
Train: [9][110/750]	BT 0.106 (1.298)	DT 0.016 (1.252)	loss 8.190 (8.190)	prob 1.956 (1.956)	GS 34.609 (34.609)	mem 42.159
Train: [9][115/750]	BT 0.042 (1.313)	DT 0.007 (1.267)	loss 7.973 (7.973)	prob 1.794 (1.794)	GS 27.312 (27.312)	mem 42.363
Train: [9][120/750]	BT 0.041 (1.323)	DT 0.006 (1.277)	loss 8.032 (8.032)	prob 2.682 (2.682)	GS 32.234 (32.234)	mem 42.237
Train: [9][125/750]	BT 0.040 (1.279)	DT 0.005 (1.233)	loss 7.375 (7.375)	prob 2.368 (2.368)	GS 31.969 (31.969)	mem 42.240
Train: [9][130/750]	BT 7.104 (1.315)	DT 7.073 (1.269)	loss 7.858 (7.858)	prob 3.276 (3.276)	GS 37.594 (37.594)	mem 42.351
Train: [9][135/750]	BT 0.055 (1.269)	DT 0.015 (1.222)	loss 7.455 (7.455)	prob 2.308 (2.308)	GS 27.109 (27.109)	mem 42.352
Train: [9][140/750]	BT 0.032 (1.242)	DT 0.002 (1.196)	loss 7.621 (7.621)	prob 2.734 (2.734)	GS 34.125 (34.125)	mem 42.373
Train: [9][145/750]	BT 0.054 (1.276)	DT 0.007 (1.230)	loss 7.200 (7.200)	prob 3.131 (3.131)	GS 28.203 (28.203)	mem 42.423
Train: [9][150/750]	BT 0.078 (1.250)	DT 0.011 (1.203)	loss 7.199 (7.199)	prob 3.263 (3.263)	GS 35.547 (35.547)	mem 42.365
Train: [9][155/750]	BT 0.050 (1.285)	DT 0.005 (1.237)	loss 7.675 (7.675)	prob 2.097 (2.097)	GS 31.891 (31.891)	mem 42.679
Train: [9][160/750]	BT 2.607 (1.262)	DT 2.535 (1.215)	loss 7.428 (7.428)	prob 2.426 (2.426)	GS 34.047 (34.047)	mem 42.624
Train: [9][165/750]	BT 0.032 (1.245)	DT 0.002 (1.198)	loss 7.725 (7.725)	prob 2.273 (2.273)	GS 31.547 (31.547)	mem 42.534
Train: [9][170/750]	BT 0.023 (1.259)	DT 0.001 (1.212)	loss 7.638 (7.638)	prob 2.313 (2.313)	GS 35.000 (35.000)	mem 42.582
Train: [9][175/750]	BT 0.087 (1.238)	DT 0.003 (1.191)	loss 7.755 (7.755)	prob 1.429 (1.429)	GS 35.266 (35.266)	mem 42.727
Train: [9][180/750]	BT 0.059 (1.260)	DT 0.002 (1.213)	loss 7.331 (7.331)	prob 2.958 (2.958)	GS 32.969 (32.969)	mem 42.749
Train: [9][185/750]	BT 0.119 (1.227)	DT 0.018 (1.180)	loss 7.303 (7.303)	prob 2.653 (2.653)	GS 30.359 (30.359)	mem 42.812
Train: [9][190/750]	BT 5.689 (1.256)	DT 5.577 (1.208)	loss 7.293 (7.293)	prob 2.970 (2.970)	GS 35.078 (35.078)	mem 42.663
Train: [9][195/750]	BT 0.031 (1.225)	DT 0.002 (1.177)	loss 7.471 (7.471)	prob 2.609 (2.609)	GS 35.391 (35.391)	mem 42.665
Train: [9][200/750]	BT 0.034 (1.239)	DT 0.003 (1.192)	loss 8.143 (8.143)	prob 2.439 (2.439)	GS 37.375 (37.375)	mem 42.710
Train: [9][205/750]	BT 0.036 (1.234)	DT 0.001 (1.187)	loss 7.899 (7.899)	prob 1.693 (1.693)	GS 32.953 (32.953)	mem 42.756
Train: [9][210/750]	BT 5.734 (1.233)	DT 5.691 (1.185)	loss 7.392 (7.392)	prob 3.161 (3.161)	GS 35.469 (35.469)	mem 42.686
Train: [9][215/750]	BT 0.027 (1.243)	DT 0.002 (1.196)	loss 7.842 (7.842)	prob 1.724 (1.724)	GS 28.359 (28.359)	mem 42.765
Train: [9][220/750]	BT 0.039 (1.215)	DT 0.002 (1.169)	loss 7.501 (7.501)	prob 3.190 (3.190)	GS 29.281 (29.281)	mem 42.767
Train: [9][225/750]	BT 0.033 (1.208)	DT 0.001 (1.161)	loss 7.917 (7.917)	prob 1.925 (1.925)	GS 32.109 (32.109)	mem 42.715
Train: [9][230/750]	BT 0.021 (1.233)	DT 0.001 (1.187)	loss 7.757 (7.757)	prob 3.403 (3.403)	GS 33.078 (33.078)	mem 42.713
Train: [9][235/750]	BT 0.080 (1.208)	DT 0.010 (1.162)	loss 7.059 (7.059)	prob 2.805 (2.805)	GS 30.406 (30.406)	mem 42.713
Train: [9][240/750]	BT 0.028 (1.234)	DT 0.001 (1.187)	loss 7.404 (7.404)	prob 2.638 (2.638)	GS 34.172 (34.172)	mem 42.798
Train: [9][245/750]	BT 0.074 (1.209)	DT 0.003 (1.163)	loss 8.429 (8.429)	prob 1.950 (1.950)	GS 31.438 (31.438)	mem 42.798
Train: [9][250/750]	BT 13.772 (1.242)	DT 13.738 (1.195)	loss 7.692 (7.692)	prob 2.380 (2.380)	GS 34.797 (34.797)	mem 42.734
Train: [9][255/750]	BT 0.032 (1.218)	DT 0.002 (1.172)	loss 7.833 (7.833)	prob 1.611 (1.611)	GS 30.281 (30.281)	mem 42.885
Train: [9][260/750]	BT 0.025 (1.196)	DT 0.001 (1.149)	loss 7.471 (7.471)	prob 2.986 (2.986)	GS 33.422 (33.422)	mem 42.939
Train: [9][265/750]	BT 0.025 (1.221)	DT 0.001 (1.175)	loss 7.458 (7.458)	prob 3.104 (3.104)	GS 35.031 (35.031)	mem 42.870
Train: [9][270/750]	BT 0.083 (1.199)	DT 0.002 (1.153)	loss 8.748 (8.748)	prob 1.807 (1.807)	GS 33.672 (33.672)	mem 42.872
Train: [9][275/750]	BT 0.041 (1.214)	DT 0.004 (1.168)	loss 7.241 (7.241)	prob 2.682 (2.682)	GS 41.469 (41.469)	mem 42.909
Train: [9][280/750]	BT 0.030 (1.193)	DT 0.001 (1.147)	loss 7.745 (7.745)	prob 2.772 (2.772)	GS 33.438 (33.438)	mem 42.850
Train: [9][285/750]	BT 0.100 (1.178)	DT 0.013 (1.132)	loss 7.742 (7.742)	prob 2.418 (2.418)	GS 34.266 (34.266)	mem 42.830
Train: [9][290/750]	BT 0.044 (1.193)	DT 0.015 (1.148)	loss 8.603 (8.603)	prob 2.262 (2.262)	GS 39.422 (39.422)	mem 42.949
Train: [9][295/750]	BT 0.044 (1.181)	DT 0.012 (1.135)	loss 7.411 (7.411)	prob 2.456 (2.456)	GS 33.125 (33.125)	mem 42.995
Train: [9][300/750]	BT 0.039 (1.199)	DT 0.008 (1.153)	loss 7.368 (7.368)	prob 3.984 (3.984)	GS 31.906 (31.906)	mem 42.889
Train: [9][305/750]	BT 0.081 (1.180)	DT 0.008 (1.134)	loss 8.735 (8.735)	prob 1.065 (1.065)	GS 28.375 (28.375)	mem 42.944
Train: [9][310/750]	BT 12.339 (1.205)	DT 12.304 (1.159)	loss 7.978 (7.978)	prob 2.110 (2.110)	GS 35.062 (35.062)	mem 43.061
Train: [9][315/750]	BT 0.090 (1.187)	DT 0.026 (1.141)	loss 7.062 (7.062)	prob 2.973 (2.973)	GS 30.422 (30.422)	mem 42.954
Train: [9][320/750]	BT 0.090 (1.170)	DT 0.002 (1.124)	loss 7.629 (7.629)	prob 2.942 (2.942)	GS 29.141 (29.141)	mem 43.013
Train: [9][325/750]	BT 0.033 (1.190)	DT 0.001 (1.144)	loss 8.706 (8.706)	prob 1.250 (1.250)	GS 34.156 (34.156)	mem 42.959
Train: [9][330/750]	BT 1.157 (1.176)	DT 1.087 (1.130)	loss 7.849 (7.849)	prob 3.110 (3.110)	GS 33.547 (33.547)	mem 42.963
Train: [9][335/750]	BT 0.048 (1.194)	DT 0.003 (1.148)	loss 7.325 (7.325)	prob 2.788 (2.788)	GS 31.016 (31.016)	mem 43.190
Train: [9][340/750]	BT 0.039 (1.177)	DT 0.001 (1.131)	loss 8.298 (8.298)	prob 2.885 (2.885)	GS 36.062 (36.062)	mem 42.978
Train: [9][345/750]	BT 0.075 (1.164)	DT 0.023 (1.119)	loss 7.707 (7.707)	prob 3.099 (3.099)	GS 26.531 (26.531)	mem 42.900
Train: [9][350/750]	BT 0.052 (1.181)	DT 0.001 (1.135)	loss 7.873 (7.873)	prob 3.223 (3.223)	GS 34.078 (34.078)	mem 42.905
Train: [9][355/750]	BT 0.136 (1.165)	DT 0.006 (1.119)	loss 7.877 (7.877)	prob 1.993 (1.993)	GS 37.078 (37.078)	mem 42.905
Train: [9][360/750]	BT 0.083 (1.184)	DT 0.014 (1.137)	loss 7.554 (7.554)	prob 2.151 (2.151)	GS 36.812 (36.812)	mem 43.095
Train: [9][365/750]	BT 0.057 (1.168)	DT 0.001 (1.122)	loss 7.972 (7.972)	prob 2.232 (2.232)	GS 32.359 (32.359)	mem 42.970
Train: [9][370/750]	BT 11.878 (1.185)	DT 11.834 (1.139)	loss 7.498 (7.498)	prob 2.972 (2.972)	GS 32.969 (32.969)	mem 42.990
Train: [9][375/750]	BT 0.036 (1.170)	DT 0.007 (1.124)	loss 7.425 (7.425)	prob 3.128 (3.128)	GS 33.500 (33.500)	mem 42.992
Train: [9][380/750]	BT 0.051 (1.155)	DT 0.007 (1.109)	loss 8.372 (8.372)	prob 2.780 (2.780)	GS 35.375 (35.375)	mem 42.991
Train: [9][385/750]	BT 0.124 (1.175)	DT 0.045 (1.129)	loss 7.901 (7.901)	prob 2.731 (2.731)	GS 30.656 (30.656)	mem 43.363
Train: [9][390/750]	BT 0.046 (1.161)	DT 0.008 (1.115)	loss 7.553 (7.553)	prob 4.022 (4.022)	GS 35.469 (35.469)	mem 43.472
Train: [9][395/750]	BT 0.030 (1.178)	DT 0.001 (1.132)	loss 7.857 (7.857)	prob 2.755 (2.755)	GS 29.188 (29.188)	mem 42.964
Train: [9][400/750]	BT 0.110 (1.164)	DT 0.080 (1.118)	loss 8.008 (8.008)	prob 2.533 (2.533)	GS 31.344 (31.344)	mem 42.964
Train: [9][405/750]	BT 0.038 (1.150)	DT 0.002 (1.104)	loss 8.273 (8.273)	prob 2.016 (2.016)	GS 31.109 (31.109)	mem 42.964
Train: [9][410/750]	BT 0.056 (1.160)	DT 0.012 (1.113)	loss 7.585 (7.585)	prob 3.281 (3.281)	GS 32.844 (32.844)	mem 43.185
Train: [9][415/750]	BT 0.029 (1.158)	DT 0.005 (1.112)	loss 7.943 (7.943)	prob 3.003 (3.003)	GS 31.328 (31.328)	mem 43.027
Train: [9][420/750]	BT 0.024 (1.159)	DT 0.001 (1.112)	loss 8.169 (8.169)	prob 2.855 (2.855)	GS 36.047 (36.047)	mem 42.976
Train: [9][425/750]	BT 0.052 (1.156)	DT 0.002 (1.110)	loss 8.010 (8.010)	prob 2.171 (2.171)	GS 35.250 (35.250)	mem 42.983
Train: [9][430/750]	BT 2.735 (1.155)	DT 2.670 (1.109)	loss 7.096 (7.096)	prob 3.111 (3.111)	GS 34.156 (34.156)	mem 43.038
Train: [9][435/750]	BT 0.052 (1.143)	DT 0.005 (1.096)	loss 7.744 (7.744)	prob 3.572 (3.572)	GS 32.625 (32.625)	mem 43.058
Train: [9][440/750]	BT 0.131 (1.154)	DT 0.003 (1.107)	loss 7.511 (7.511)	prob 3.805 (3.805)	GS 33.297 (33.297)	mem 43.016
Train: [9][445/750]	BT 0.042 (1.148)	DT 0.002 (1.101)	loss 8.008 (8.008)	prob 2.492 (2.492)	GS 31.078 (31.078)	mem 43.105
Train: [9][450/750]	BT 0.060 (1.157)	DT 0.010 (1.110)	loss 7.599 (7.599)	prob 3.041 (3.041)	GS 32.859 (32.859)	mem 42.972
Train: [9][455/750]	BT 0.076 (1.155)	DT 0.018 (1.108)	loss 7.735 (7.735)	prob 2.846 (2.846)	GS 30.625 (30.625)	mem 42.978
Train: [9][460/750]	BT 10.123 (1.165)	DT 10.091 (1.118)	loss 7.461 (7.461)	prob 3.137 (3.137)	GS 32.078 (32.078)	mem 43.063
Train: [9][465/750]	BT 0.095 (1.153)	DT 0.004 (1.106)	loss 7.534 (7.534)	prob 2.702 (2.702)	GS 28.766 (28.766)	mem 43.014
Train: [9][470/750]	BT 0.033 (1.145)	DT 0.001 (1.098)	loss 7.950 (7.950)	prob 3.119 (3.119)	GS 34.188 (34.188)	mem 43.002
Train: [9][475/750]	BT 0.039 (1.154)	DT 0.001 (1.107)	loss 8.078 (8.078)	prob 2.631 (2.631)	GS 27.641 (27.641)	mem 43.003
Train: [9][480/750]	BT 0.037 (1.143)	DT 0.001 (1.096)	loss 7.553 (7.553)	prob 3.337 (3.337)	GS 32.156 (32.156)	mem 43.010
Train: [9][485/750]	BT 0.060 (1.156)	DT 0.003 (1.109)	loss 7.535 (7.535)	prob 2.942 (2.942)	GS 32.891 (32.891)	mem 43.051
Train: [9][490/750]	BT 0.023 (1.151)	DT 0.001 (1.105)	loss 7.784 (7.784)	prob 3.053 (3.053)	GS 32.672 (32.672)	mem 43.060
Train: [9][495/750]	BT 0.042 (1.154)	DT 0.010 (1.107)	loss 8.655 (8.655)	prob 0.881 (0.881)	GS 29.094 (29.094)	mem 43.170
Train: [9][500/750]	BT 0.034 (1.150)	DT 0.002 (1.103)	loss 7.235 (7.235)	prob 3.130 (3.130)	GS 32.797 (32.797)	mem 43.018
Train: [9][505/750]	BT 0.035 (1.142)	DT 0.002 (1.095)	loss 7.610 (7.610)	prob 3.546 (3.546)	GS 32.609 (32.609)	mem 43.077
Train: [9][510/750]	BT 3.940 (1.159)	DT 3.893 (1.112)	loss 7.618 (7.618)	prob 3.477 (3.477)	GS 35.375 (35.375)	mem 43.079
Train: [9][515/750]	BT 0.047 (1.148)	DT 0.002 (1.101)	loss 7.224 (7.224)	prob 2.667 (2.667)	GS 30.688 (30.688)	mem 43.081
Train: [9][520/750]	BT 4.362 (1.150)	DT 4.330 (1.104)	loss 8.305 (8.305)	prob 3.158 (3.158)	GS 33.750 (33.750)	mem 43.215
Train: [9][525/750]	BT 0.028 (1.150)	DT 0.001 (1.104)	loss 7.179 (7.179)	prob 3.429 (3.429)	GS 31.078 (31.078)	mem 43.046
Train: [9][530/750]	BT 1.792 (1.145)	DT 1.752 (1.099)	loss 8.319 (8.319)	prob 3.664 (3.664)	GS 33.609 (33.609)	mem 43.201
Train: [9][535/750]	BT 0.027 (1.155)	DT 0.001 (1.108)	loss 7.725 (7.725)	prob 2.398 (2.398)	GS 28.312 (28.312)	mem 43.036
Train: [9][540/750]	BT 0.055 (1.150)	DT 0.010 (1.104)	loss 7.250 (7.250)	prob 2.920 (2.920)	GS 33.750 (33.750)	mem 43.075
Train: [9][545/750]	BT 0.034 (1.140)	DT 0.003 (1.094)	loss 7.452 (7.452)	prob 2.835 (2.835)	GS 36.234 (36.234)	mem 43.075
Train: [9][550/750]	BT 1.420 (1.152)	DT 1.390 (1.106)	loss 8.094 (8.094)	prob 3.339 (3.339)	GS 34.594 (34.594)	mem 42.990
Train: [9][555/750]	BT 0.032 (1.142)	DT 0.002 (1.096)	loss 7.467 (7.467)	prob 2.758 (2.758)	GS 28.719 (28.719)	mem 42.990
Train: [9][560/750]	BT 0.031 (1.152)	DT 0.001 (1.105)	loss 7.471 (7.471)	prob 3.648 (3.648)	GS 35.734 (35.734)	mem 42.938
Train: [9][565/750]	BT 0.037 (1.142)	DT 0.001 (1.096)	loss 8.130 (8.130)	prob 2.109 (2.109)	GS 32.891 (32.891)	mem 42.996
Train: [9][570/750]	BT 4.393 (1.153)	DT 4.357 (1.107)	loss 7.796 (7.796)	prob 2.675 (2.675)	GS 37.656 (37.656)	mem 43.021
Train: [9][575/750]	BT 0.034 (1.150)	DT 0.002 (1.104)	loss 7.885 (7.885)	prob 1.930 (1.930)	GS 28.922 (28.922)	mem 43.017
Train: [9][580/750]	BT 0.972 (1.142)	DT 0.940 (1.096)	loss 7.694 (7.694)	prob 3.447 (3.447)	GS 31.656 (31.656)	mem 42.978
Train: [9][585/750]	BT 0.037 (1.144)	DT 0.002 (1.098)	loss 8.039 (8.039)	prob 2.106 (2.106)	GS 30.359 (30.359)	mem 42.987
Train: [9][590/750]	BT 0.037 (1.141)	DT 0.012 (1.095)	loss 7.988 (7.988)	prob 2.845 (2.845)	GS 32.328 (32.328)	mem 43.017
Train: [9][595/750]	BT 0.071 (1.148)	DT 0.026 (1.102)	loss 7.894 (7.894)	prob 1.838 (1.838)	GS 31.438 (31.438)	mem 43.023
Train: [9][600/750]	BT 0.041 (1.142)	DT 0.008 (1.096)	loss 7.877 (7.877)	prob 2.921 (2.921)	GS 31.547 (31.547)	mem 43.024
Train: [9][605/750]	BT 0.052 (1.138)	DT 0.001 (1.092)	loss 7.591 (7.591)	prob 2.015 (2.015)	GS 28.734 (28.734)	mem 43.105
Train: [9][610/750]	BT 4.886 (1.146)	DT 4.853 (1.100)	loss 7.469 (7.469)	prob 3.416 (3.416)	GS 34.719 (34.719)	mem 43.090
Train: [9][615/750]	BT 0.077 (1.138)	DT 0.008 (1.091)	loss 8.041 (8.041)	prob 2.348 (2.348)	GS 29.766 (29.766)	mem 43.142
Train: [9][620/750]	BT 0.051 (1.141)	DT 0.002 (1.095)	loss 7.680 (7.680)	prob 2.419 (2.419)	GS 36.656 (36.656)	mem 43.071
Train: [9][625/750]	BT 0.035 (1.140)	DT 0.001 (1.094)	loss 7.636 (7.636)	prob 2.352 (2.352)	GS 27.703 (27.703)	mem 43.067
Train: [9][630/750]	BT 5.861 (1.140)	DT 5.829 (1.094)	loss 7.516 (7.516)	prob 2.508 (2.508)	GS 33.656 (33.656)	mem 43.044
Train: [9][635/750]	BT 0.046 (1.141)	DT 0.005 (1.095)	loss 8.784 (8.784)	prob 1.362 (1.362)	GS 29.484 (29.484)	mem 43.039
Train: [9][640/750]	BT 0.033 (1.132)	DT 0.002 (1.086)	loss 7.763 (7.763)	prob 3.615 (3.615)	GS 30.125 (30.125)	mem 43.039
Train: [9][645/750]	BT 0.031 (1.138)	DT 0.001 (1.092)	loss 7.549 (7.549)	prob 2.332 (2.332)	GS 31.906 (31.906)	mem 42.914
Train: [9][650/750]	BT 0.048 (1.133)	DT 0.005 (1.087)	loss 8.326 (8.326)	prob 3.046 (3.046)	GS 35.375 (35.375)	mem 42.946
Train: [9][655/750]	BT 0.057 (1.140)	DT 0.007 (1.094)	loss 8.201 (8.201)	prob 1.762 (1.762)	GS 28.875 (28.875)	mem 43.064
Train: [9][660/750]	BT 0.039 (1.137)	DT 0.005 (1.092)	loss 8.226 (8.226)	prob 2.405 (2.405)	GS 33.312 (33.312)	mem 43.044
Train: [9][665/750]	BT 0.070 (1.129)	DT 0.016 (1.083)	loss 7.446 (7.446)	prob 2.970 (2.970)	GS 29.656 (29.656)	mem 43.066
arpack error, retry= 0
arpack error, retry= 0
Train: [9][670/750]	BT 7.109 (1.144)	DT 7.042 (1.098)	loss 8.165 (8.165)	prob 2.297 (2.297)	GS 35.891 (35.891)	mem 43.334
Train: [9][675/750]	BT 0.064 (1.135)	DT 0.007 (1.090)	loss 8.050 (8.050)	prob 1.700 (1.700)	GS 29.188 (29.188)	mem 43.043
Train: [9][680/750]	BT 0.190 (1.132)	DT 0.128 (1.087)	loss 8.767 (8.767)	prob 2.572 (2.572)	GS 37.594 (37.594)	mem 43.047
Train: [9][685/750]	BT 0.071 (1.133)	DT 0.001 (1.087)	loss 7.955 (7.955)	prob 1.698 (1.698)	GS 31.172 (31.172)	mem 42.992
Train: [9][690/750]	BT 5.344 (1.133)	DT 5.312 (1.087)	loss 8.418 (8.418)	prob 2.966 (2.966)	GS 38.406 (38.406)	mem 42.983
Train: [9][695/750]	BT 0.100 (1.135)	DT 0.003 (1.090)	loss 8.281 (8.281)	prob 2.220 (2.220)	GS 31.828 (31.828)	mem 42.955
Train: [9][700/750]	BT 2.662 (1.131)	DT 2.608 (1.086)	loss 7.970 (7.970)	prob 2.386 (2.386)	GS 35.891 (35.891)	mem 42.964
Train: [9][705/750]	BT 0.046 (1.127)	DT 0.004 (1.081)	loss 7.476 (7.476)	prob 2.615 (2.615)	GS 30.938 (30.938)	mem 42.971
Train: [9][710/750]	BT 0.046 (1.133)	DT 0.002 (1.087)	loss 7.688 (7.688)	prob 1.828 (1.828)	GS 35.906 (35.906)	mem 43.004
Train: [9][715/750]	BT 0.031 (1.130)	DT 0.001 (1.085)	loss 7.724 (7.724)	prob 1.999 (1.999)	GS 28.594 (28.594)	mem 42.956
Train: [9][720/750]	BT 0.031 (1.136)	DT 0.001 (1.091)	loss 7.630 (7.630)	prob 2.645 (2.645)	GS 33.250 (33.250)	mem 42.933
Train: [9][725/750]	BT 0.043 (1.136)	DT 0.006 (1.091)	loss 8.647 (8.647)	prob 1.232 (1.232)	GS 26.531 (26.531)	mem 42.858
Train: [9][730/750]	BT 4.213 (1.140)	DT 4.180 (1.095)	loss 7.555 (7.555)	prob 2.957 (2.957)	GS 32.609 (32.609)	mem 42.673
Train: [9][735/750]	BT 0.033 (1.133)	DT 0.001 (1.087)	loss 7.575 (7.575)	prob 2.507 (2.507)	GS 31.531 (31.531)	mem 42.673
Train: [9][740/750]	BT 3.532 (1.132)	DT 3.488 (1.086)	loss 7.683 (7.683)	prob 2.507 (2.507)	GS 31.484 (31.484)	mem 19.593
Train: [9][745/750]	BT 0.034 (1.127)	DT 0.006 (1.081)	loss 8.585 (8.585)	prob 1.415 (1.415)	GS 33.750 (33.750)	mem 13.633
Train: [9][750/750]	BT 0.035 (1.119)	DT 0.001 (1.074)	loss 7.997 (7.997)	prob 1.879 (1.879)	GS 34.969 (34.969)	mem 13.672
Train: [9][755/750]	BT 0.035 (1.116)	DT 0.002 (1.071)	loss 8.214 (8.214)	prob 3.105 (3.105)	GS 28.594 (28.594)	mem 10.609
epoch 9, total time 842.73
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [10][1/750]	BT 22.983 (22.983)	DT 22.919 (22.919)	loss 7.813 (7.813)	prob 3.455 (3.455)	GS 33.859 (33.859)	mem 41.680
Train: [10][5/750]	BT 0.048 (5.003)	DT 0.001 (4.953)	loss 8.307 (8.307)	prob 1.956 (1.956)	GS 30.359 (30.359)	mem 41.597
Train: [10][10/750]	BT 0.032 (2.530)	DT 0.001 (2.479)	loss 7.374 (7.374)	prob 3.301 (3.301)	GS 33.906 (33.906)	mem 41.610
Train: [10][15/750]	BT 0.048 (2.463)	DT 0.014 (2.415)	loss 7.391 (7.391)	prob 2.533 (2.533)	GS 29.984 (29.984)	mem 41.797
Train: [10][20/750]	BT 0.061 (2.039)	DT 0.005 (1.989)	loss 7.591 (7.591)	prob 2.726 (2.726)	GS 32.172 (32.172)	mem 41.940
Train: [10][25/750]	BT 3.930 (1.799)	DT 3.899 (1.749)	loss 7.929 (7.929)	prob 1.982 (1.982)	GS 33.922 (33.922)	mem 41.916
Train: [10][30/750]	BT 0.083 (1.840)	DT 0.012 (1.790)	loss 8.265 (8.265)	prob 2.932 (2.932)	GS 35.453 (35.453)	mem 41.998
Train: [10][35/750]	BT 0.072 (1.671)	DT 0.015 (1.619)	loss 8.301 (8.301)	prob 1.502 (1.502)	GS 29.578 (29.578)	mem 41.977
Train: [10][40/750]	BT 0.968 (1.745)	DT 0.919 (1.693)	loss 8.330 (8.330)	prob 2.756 (2.756)	GS 34.547 (34.547)	mem 42.128
Train: [10][45/750]	BT 0.146 (1.560)	DT 0.014 (1.506)	loss 7.531 (7.531)	prob 2.419 (2.419)	GS 23.578 (23.578)	mem 42.009
Train: [10][50/750]	BT 13.395 (1.685)	DT 13.363 (1.631)	loss 7.716 (7.716)	prob 2.892 (2.892)	GS 31.094 (31.094)	mem 42.064
Train: [10][55/750]	BT 0.045 (1.547)	DT 0.001 (1.493)	loss 8.017 (8.017)	prob 1.793 (1.793)	GS 33.391 (33.391)	mem 42.068
Train: [10][60/750]	BT 0.114 (1.444)	DT 0.002 (1.388)	loss 7.702 (7.702)	prob 3.773 (3.773)	GS 28.234 (28.234)	mem 42.071
Train: [10][65/750]	BT 0.050 (1.502)	DT 0.005 (1.446)	loss 7.399 (7.399)	prob 3.368 (3.368)	GS 32.422 (32.422)	mem 42.058
Train: [10][70/750]	BT 0.038 (1.426)	DT 0.001 (1.370)	loss 7.897 (7.897)	prob 3.505 (3.505)	GS 31.297 (31.297)	mem 42.106
Train: [10][75/750]	BT 0.033 (1.488)	DT 0.001 (1.433)	loss 8.461 (8.461)	prob 1.645 (1.645)	GS 32.141 (32.141)	mem 42.408
Train: [10][80/750]	BT 1.303 (1.415)	DT 1.252 (1.359)	loss 8.480 (8.480)	prob 2.306 (2.306)	GS 31.734 (31.734)	mem 42.440
Train: [10][85/750]	BT 0.067 (1.334)	DT 0.013 (1.279)	loss 8.195 (8.195)	prob 2.365 (2.365)	GS 35.484 (35.484)	mem 42.411
Train: [10][90/750]	BT 0.058 (1.373)	DT 0.003 (1.318)	loss 8.838 (8.838)	prob 1.840 (1.840)	GS 30.016 (30.016)	mem 42.529
Train: [10][95/750]	BT 0.031 (1.330)	DT 0.001 (1.277)	loss 7.452 (7.452)	prob 2.166 (2.166)	GS 33.688 (33.688)	mem 42.497
Train: [10][100/750]	BT 1.907 (1.378)	DT 1.875 (1.325)	loss 8.652 (8.652)	prob 2.392 (2.392)	GS 34.109 (34.109)	mem 42.633
Train: [10][105/750]	BT 0.036 (1.336)	DT 0.001 (1.283)	loss 8.360 (8.360)	prob 1.641 (1.641)	GS 29.328 (29.328)	mem 42.584
Train: [10][110/750]	BT 9.940 (1.367)	DT 9.859 (1.315)	loss 8.281 (8.281)	prob 1.899 (1.899)	GS 33.859 (33.859)	mem 42.737
Train: [10][115/750]	BT 0.045 (1.334)	DT 0.002 (1.282)	loss 7.727 (7.727)	prob 2.408 (2.408)	GS 38.172 (38.172)	mem 42.743
Train: [10][120/750]	BT 0.032 (1.293)	DT 0.001 (1.241)	loss 8.804 (8.804)	prob 1.825 (1.825)	GS 31.234 (31.234)	mem 42.679
Train: [10][125/750]	BT 0.064 (1.324)	DT 0.007 (1.272)	loss 7.482 (7.482)	prob 3.581 (3.581)	GS 33.297 (33.297)	mem 42.753
Train: [10][130/750]	BT 0.036 (1.310)	DT 0.001 (1.258)	loss 7.775 (7.775)	prob 3.471 (3.471)	GS 30.688 (30.688)	mem 42.752
Train: [10][135/750]	BT 0.118 (1.296)	DT 0.048 (1.244)	loss 8.079 (8.079)	prob 2.363 (2.363)	GS 31.453 (31.453)	mem 43.166
Train: [10][140/750]	BT 9.842 (1.325)	DT 9.778 (1.274)	loss 8.821 (8.821)	prob 2.985 (2.985)	GS 36.062 (36.062)	mem 42.921
Train: [10][145/750]	BT 0.043 (1.282)	DT 0.002 (1.230)	loss 7.578 (7.578)	prob 2.738 (2.738)	GS 30.641 (30.641)	mem 42.756
Train: [10][150/750]	BT 0.030 (1.266)	DT 0.001 (1.215)	loss 8.704 (8.704)	prob 2.635 (2.635)	GS 33.000 (33.000)	mem 42.782
Train: [10][155/750]	BT 0.051 (1.295)	DT 0.011 (1.244)	loss 8.685 (8.685)	prob 1.802 (1.802)	GS 31.031 (31.031)	mem 42.797
Train: [10][160/750]	BT 0.461 (1.262)	DT 0.417 (1.212)	loss 7.997 (7.997)	prob 2.656 (2.656)	GS 30.047 (30.047)	mem 42.799
Train: [10][165/750]	BT 0.035 (1.301)	DT 0.001 (1.251)	loss 7.734 (7.734)	prob 2.110 (2.110)	GS 33.484 (33.484)	mem 42.828
Train: [10][170/750]	BT 1.109 (1.270)	DT 1.077 (1.220)	loss 7.582 (7.582)	prob 2.686 (2.686)	GS 33.953 (33.953)	mem 42.827
Train: [10][175/750]	BT 0.048 (1.249)	DT 0.001 (1.200)	loss 8.694 (8.694)	prob 1.673 (1.673)	GS 31.453 (31.453)	mem 42.793
Train: [10][180/750]	BT 0.062 (1.261)	DT 0.005 (1.211)	loss 9.169 (9.169)	prob 2.335 (2.335)	GS 38.641 (38.641)	mem 42.775
Train: [10][185/750]	BT 0.065 (1.260)	DT 0.009 (1.211)	loss 8.748 (8.748)	prob 1.530 (1.530)	GS 30.984 (30.984)	mem 42.796
Train: [10][190/750]	BT 0.087 (1.242)	DT 0.007 (1.192)	loss 8.349 (8.349)	prob 1.740 (1.740)	GS 36.531 (36.531)	mem 42.816
Train: [10][195/750]	BT 0.042 (1.229)	DT 0.004 (1.179)	loss 7.642 (7.642)	prob 2.593 (2.593)	GS 34.094 (34.094)	mem 42.855
Train: [10][200/750]	BT 0.056 (1.246)	DT 0.003 (1.196)	loss 8.216 (8.216)	prob 3.247 (3.247)	GS 31.172 (31.172)	mem 42.790
Train: [10][205/750]	BT 0.052 (1.217)	DT 0.012 (1.167)	loss 7.684 (7.684)	prob 3.126 (3.126)	GS 26.234 (26.234)	mem 42.791
Train: [10][210/750]	BT 0.074 (1.247)	DT 0.005 (1.198)	loss 8.300 (8.300)	prob 3.085 (3.085)	GS 31.844 (31.844)	mem 42.789
Train: [10][215/750]	BT 0.035 (1.220)	DT 0.004 (1.170)	loss 8.098 (8.098)	prob 3.123 (3.123)	GS 41.828 (41.828)	mem 42.790
Train: [10][220/750]	BT 8.807 (1.248)	DT 8.776 (1.199)	loss 9.141 (9.141)	prob 2.635 (2.635)	GS 33.391 (33.391)	mem 42.855
Train: [10][225/750]	BT 0.037 (1.221)	DT 0.001 (1.172)	loss 7.774 (7.774)	prob 3.581 (3.581)	GS 29.688 (29.688)	mem 42.940
Train: [10][230/750]	BT 5.777 (1.220)	DT 5.739 (1.172)	loss 8.633 (8.633)	prob 3.008 (3.008)	GS 31.453 (31.453)	mem 42.879
Train: [10][235/750]	BT 0.030 (1.228)	DT 0.001 (1.180)	loss 8.051 (8.051)	prob 2.520 (2.520)	GS 27.375 (27.375)	mem 42.959
Train: [10][240/750]	BT 0.111 (1.204)	DT 0.012 (1.155)	loss 7.914 (7.914)	prob 3.477 (3.477)	GS 31.188 (31.188)	mem 42.911
Train: [10][245/750]	BT 0.085 (1.252)	DT 0.002 (1.203)	loss 9.102 (9.102)	prob 0.996 (0.996)	GS 28.188 (28.188)	mem 42.972
Train: [10][250/750]	BT 0.044 (1.228)	DT 0.011 (1.179)	loss 8.117 (8.117)	prob 3.823 (3.823)	GS 33.562 (33.562)	mem 43.057
Train: [10][255/750]	BT 0.087 (1.205)	DT 0.016 (1.156)	loss 8.640 (8.640)	prob 1.898 (1.898)	GS 29.703 (29.703)	mem 42.942
Train: [10][260/750]	BT 0.123 (1.227)	DT 0.029 (1.178)	loss 8.729 (8.729)	prob 2.922 (2.922)	GS 37.266 (37.266)	mem 42.973
Train: [10][265/750]	BT 0.042 (1.205)	DT 0.003 (1.156)	loss 7.786 (7.786)	prob 2.394 (2.394)	GS 28.641 (28.641)	mem 42.936
Train: [10][270/750]	BT 0.030 (1.228)	DT 0.001 (1.179)	loss 7.782 (7.782)	prob 3.530 (3.530)	GS 28.828 (28.828)	mem 42.848
Train: [10][275/750]	BT 0.034 (1.207)	DT 0.002 (1.158)	loss 7.865 (7.865)	prob 3.040 (3.040)	GS 28.594 (28.594)	mem 42.921
Train: [10][280/750]	BT 11.682 (1.228)	DT 11.645 (1.179)	loss 8.794 (8.794)	prob 3.183 (3.183)	GS 35.375 (35.375)	mem 43.183
Train: [10][285/750]	BT 0.025 (1.207)	DT 0.001 (1.158)	loss 8.148 (8.148)	prob 2.383 (2.383)	GS 31.641 (31.641)	mem 42.986
Train: [10][290/750]	BT 0.068 (1.187)	DT 0.012 (1.138)	loss 7.731 (7.731)	prob 3.818 (3.818)	GS 30.000 (30.000)	mem 42.994
Train: [10][295/750]	BT 0.037 (1.217)	DT 0.008 (1.169)	loss 7.658 (7.658)	prob 3.348 (3.348)	GS 30.094 (30.094)	mem 42.895
Train: [10][300/750]	BT 0.028 (1.198)	DT 0.001 (1.149)	loss 8.584 (8.584)	prob 3.215 (3.215)	GS 34.938 (34.938)	mem 42.898
Train: [10][305/750]	BT 0.025 (1.215)	DT 0.004 (1.167)	loss 8.235 (8.235)	prob 3.404 (3.404)	GS 31.703 (31.703)	mem 42.934
Train: [10][310/750]	BT 0.034 (1.196)	DT 0.001 (1.148)	loss 7.806 (7.806)	prob 3.704 (3.704)	GS 32.766 (32.766)	mem 42.935
Train: [10][315/750]	BT 0.032 (1.178)	DT 0.002 (1.130)	loss 7.760 (7.760)	prob 3.163 (3.163)	GS 30.547 (30.547)	mem 42.935
Train: [10][320/750]	BT 0.024 (1.198)	DT 0.001 (1.151)	loss 8.035 (8.035)	prob 2.836 (2.836)	GS 38.156 (38.156)	mem 43.050
Train: [10][325/750]	BT 0.026 (1.181)	DT 0.001 (1.133)	loss 7.964 (7.964)	prob 2.881 (2.881)	GS 26.016 (26.016)	mem 42.976
Train: [10][330/750]	BT 0.257 (1.194)	DT 0.222 (1.147)	loss 7.785 (7.785)	prob 3.658 (3.658)	GS 33.453 (33.453)	mem 42.924
Train: [10][335/750]	BT 0.078 (1.177)	DT 0.001 (1.130)	loss 7.903 (7.903)	prob 3.202 (3.202)	GS 30.672 (30.672)	mem 42.926
Train: [10][340/750]	BT 13.517 (1.200)	DT 13.477 (1.153)	loss 8.251 (8.251)	prob 2.582 (2.582)	GS 28.953 (28.953)	mem 42.922
Train: [10][345/750]	BT 0.073 (1.184)	DT 0.004 (1.136)	loss 7.812 (7.812)	prob 3.542 (3.542)	GS 29.969 (29.969)	mem 42.929
Train: [10][350/750]	BT 0.038 (1.167)	DT 0.002 (1.120)	loss 8.189 (8.189)	prob 3.603 (3.603)	GS 34.812 (34.812)	mem 42.942
Train: [10][355/750]	BT 0.031 (1.190)	DT 0.001 (1.143)	loss 8.086 (8.086)	prob 2.759 (2.759)	GS 28.516 (28.516)	mem 43.024
Train: [10][360/750]	BT 0.120 (1.174)	DT 0.043 (1.127)	loss 8.142 (8.142)	prob 3.021 (3.021)	GS 32.000 (32.000)	mem 42.998
Train: [10][365/750]	BT 0.047 (1.191)	DT 0.002 (1.144)	loss 7.944 (7.944)	prob 2.905 (2.905)	GS 31.156 (31.156)	mem 42.950
Train: [10][370/750]	BT 0.037 (1.176)	DT 0.001 (1.128)	loss 8.858 (8.858)	prob 3.379 (3.379)	GS 32.109 (32.109)	mem 42.978
Train: [10][375/750]	BT 0.032 (1.161)	DT 0.002 (1.113)	loss 8.148 (8.148)	prob 2.800 (2.800)	GS 33.484 (33.484)	mem 42.985
Train: [10][380/750]	BT 0.037 (1.177)	DT 0.004 (1.130)	loss 7.410 (7.410)	prob 3.565 (3.565)	GS 30.188 (30.188)	mem 43.016
Train: [10][385/750]	BT 0.048 (1.163)	DT 0.002 (1.116)	loss 7.777 (7.777)	prob 2.897 (2.897)	GS 34.578 (34.578)	mem 43.053
Train: [10][390/750]	BT 0.027 (1.183)	DT 0.001 (1.136)	loss 7.775 (7.775)	prob 4.022 (4.022)	GS 31.484 (31.484)	mem 43.005
Train: [10][395/750]	BT 0.040 (1.169)	DT 0.002 (1.122)	loss 8.469 (8.469)	prob 2.132 (2.132)	GS 30.641 (30.641)	mem 43.005
Train: [10][400/750]	BT 13.318 (1.188)	DT 13.286 (1.141)	loss 8.635 (8.635)	prob 3.221 (3.221)	GS 38.125 (38.125)	mem 42.970
Train: [10][405/750]	BT 0.029 (1.174)	DT 0.001 (1.127)	loss 7.880 (7.880)	prob 2.474 (2.474)	GS 29.375 (29.375)	mem 42.971
Train: [10][410/750]	BT 0.030 (1.160)	DT 0.001 (1.113)	loss 8.253 (8.253)	prob 3.682 (3.682)	GS 31.094 (31.094)	mem 42.971
Train: [10][415/750]	BT 0.059 (1.182)	DT 0.007 (1.136)	loss 7.884 (7.884)	prob 3.382 (3.382)	GS 29.391 (29.391)	mem 42.857
Train: [10][420/750]	BT 0.023 (1.169)	DT 0.001 (1.122)	loss 7.656 (7.656)	prob 3.889 (3.889)	GS 31.078 (31.078)	mem 42.860
Train: [10][425/750]	BT 0.034 (1.172)	DT 0.007 (1.125)	loss 7.677 (7.677)	prob 3.753 (3.753)	GS 30.109 (30.109)	mem 42.986
Train: [10][430/750]	BT 0.034 (1.169)	DT 0.004 (1.122)	loss 7.972 (7.972)	prob 2.773 (2.773)	GS 30.219 (30.219)	mem 43.034
Train: [10][435/750]	BT 0.033 (1.156)	DT 0.002 (1.109)	loss 8.074 (8.074)	prob 2.173 (2.173)	GS 35.891 (35.891)	mem 43.036
Train: [10][440/750]	BT 0.065 (1.167)	DT 0.007 (1.121)	loss 8.099 (8.099)	prob 3.019 (3.019)	GS 37.562 (37.562)	mem 42.997
Train: [10][445/750]	BT 0.041 (1.155)	DT 0.001 (1.108)	loss 8.311 (8.311)	prob 1.727 (1.727)	GS 26.500 (26.500)	mem 42.998
Train: [10][450/750]	BT 1.947 (1.168)	DT 1.919 (1.121)	loss 8.342 (8.342)	prob 3.730 (3.730)	GS 30.281 (30.281)	mem 43.017
Train: [10][455/750]	BT 0.038 (1.156)	DT 0.003 (1.109)	loss 8.302 (8.302)	prob 2.821 (2.821)	GS 27.891 (27.891)	mem 43.018
Train: [10][460/750]	BT 10.440 (1.166)	DT 10.391 (1.120)	loss 7.824 (7.824)	prob 4.162 (4.162)	GS 30.922 (30.922)	mem 43.160
Train: [10][465/750]	BT 0.064 (1.156)	DT 0.002 (1.109)	loss 7.827 (7.827)	prob 3.133 (3.133)	GS 30.891 (30.891)	mem 43.168
Train: [10][470/750]	BT 0.032 (1.144)	DT 0.001 (1.098)	loss 7.466 (7.466)	prob 3.951 (3.951)	GS 30.844 (30.844)	mem 43.039
Train: [10][475/750]	BT 0.034 (1.163)	DT 0.003 (1.117)	loss 7.439 (7.439)	prob 3.206 (3.206)	GS 29.250 (29.250)	mem 42.974
Train: [10][480/750]	BT 0.032 (1.151)	DT 0.001 (1.105)	loss 8.318 (8.318)	prob 3.063 (3.063)	GS 31.531 (31.531)	mem 43.014
Train: [10][485/750]	BT 0.032 (1.163)	DT 0.002 (1.118)	loss 7.963 (7.963)	prob 2.381 (2.381)	GS 31.625 (31.625)	mem 42.983
Train: [10][490/750]	BT 0.032 (1.152)	DT 0.002 (1.107)	loss 7.968 (7.968)	prob 3.139 (3.139)	GS 32.250 (32.250)	mem 42.983
Train: [10][495/750]	BT 0.067 (1.141)	DT 0.006 (1.096)	loss 8.890 (8.890)	prob 1.777 (1.777)	GS 32.797 (32.797)	mem 42.982
Train: [10][500/750]	BT 0.035 (1.156)	DT 0.001 (1.111)	loss 8.318 (8.318)	prob 2.968 (2.968)	GS 28.641 (28.641)	mem 43.126
Train: [10][505/750]	BT 0.066 (1.145)	DT 0.005 (1.100)	loss 7.688 (7.688)	prob 2.629 (2.629)	GS 30.828 (30.828)	mem 43.208
Train: [10][510/750]	BT 7.522 (1.161)	DT 7.485 (1.116)	loss 8.669 (8.669)	prob 3.530 (3.530)	GS 32.312 (32.312)	mem 43.173
Train: [10][515/750]	BT 0.049 (1.151)	DT 0.003 (1.105)	loss 7.480 (7.480)	prob 3.704 (3.704)	GS 30.906 (30.906)	mem 43.122
Train: [10][520/750]	BT 4.792 (1.149)	DT 4.717 (1.104)	loss 7.920 (7.920)	prob 3.757 (3.757)	GS 36.016 (36.016)	mem 42.984
Train: [10][525/750]	BT 0.040 (1.153)	DT 0.001 (1.108)	loss 7.930 (7.930)	prob 1.861 (1.861)	GS 31.781 (31.781)	mem 42.987
Train: [10][530/750]	BT 0.031 (1.143)	DT 0.001 (1.097)	loss 8.276 (8.276)	prob 2.549 (2.549)	GS 36.688 (36.688)	mem 43.170
Train: [10][535/750]	BT 0.025 (1.151)	DT 0.001 (1.106)	loss 7.806 (7.806)	prob 2.780 (2.780)	GS 30.938 (30.938)	mem 42.853
Train: [10][540/750]	BT 5.440 (1.151)	DT 5.322 (1.105)	loss 7.846 (7.846)	prob 3.055 (3.055)	GS 32.484 (32.484)	mem 42.887
Train: [10][545/750]	BT 0.032 (1.157)	DT 0.001 (1.111)	loss 7.910 (7.910)	prob 2.945 (2.945)	GS 30.000 (30.000)	mem 42.927
Train: [10][550/750]	BT 0.041 (1.147)	DT 0.005 (1.101)	loss 8.338 (8.338)	prob 2.926 (2.926)	GS 35.734 (35.734)	mem 42.874
Train: [10][555/750]	BT 0.034 (1.140)	DT 0.002 (1.094)	loss 7.436 (7.436)	prob 3.386 (3.386)	GS 32.547 (32.547)	mem 43.020
Train: [10][560/750]	BT 0.031 (1.154)	DT 0.002 (1.108)	loss 7.425 (7.425)	prob 3.121 (3.121)	GS 31.141 (31.141)	mem 42.911
Train: [10][565/750]	BT 0.036 (1.144)	DT 0.002 (1.098)	loss 7.573 (7.573)	prob 2.356 (2.356)	GS 31.078 (31.078)	mem 42.951
Train: [10][570/750]	BT 0.052 (1.154)	DT 0.004 (1.109)	loss 7.866 (7.866)	prob 4.339 (4.339)	GS 28.188 (28.188)	mem 42.968
Train: [10][575/750]	BT 0.127 (1.145)	DT 0.007 (1.099)	loss 7.580 (7.580)	prob 2.491 (2.491)	GS 31.125 (31.125)	mem 42.887
Train: [10][580/750]	BT 7.370 (1.157)	DT 7.340 (1.112)	loss 8.970 (8.970)	prob 1.983 (1.983)	GS 36.422 (36.422)	mem 42.924
Train: [10][585/750]	BT 0.076 (1.148)	DT 0.008 (1.103)	loss 7.396 (7.396)	prob 3.126 (3.126)	GS 29.766 (29.766)	mem 42.959
Train: [10][590/750]	BT 0.033 (1.147)	DT 0.003 (1.102)	loss 7.524 (7.524)	prob 3.833 (3.833)	GS 29.328 (29.328)	mem 42.847
Train: [10][595/750]	BT 0.032 (1.148)	DT 0.001 (1.103)	loss 7.965 (7.965)	prob 2.909 (2.909)	GS 26.625 (26.625)	mem 42.947
Train: [10][600/750]	BT 11.015 (1.157)	DT 10.983 (1.112)	loss 8.195 (8.195)	prob 2.138 (2.138)	GS 34.875 (34.875)	mem 42.963
Train: [10][605/750]	BT 0.024 (1.153)	DT 0.001 (1.108)	loss 7.705 (7.705)	prob 1.788 (1.788)	GS 29.484 (29.484)	mem 42.900
Train: [10][610/750]	BT 0.132 (1.144)	DT 0.008 (1.099)	loss 7.829 (7.829)	prob 2.844 (2.844)	GS 33.203 (33.203)	mem 42.947
Train: [10][615/750]	BT 0.031 (1.157)	DT 0.002 (1.111)	loss 8.335 (8.335)	prob 1.761 (1.761)	GS 33.000 (33.000)	mem 42.860
Train: [10][620/750]	BT 0.048 (1.148)	DT 0.009 (1.103)	loss 7.494 (7.494)	prob 3.284 (3.284)	GS 32.594 (32.594)	mem 42.905
Train: [10][625/750]	BT 0.028 (1.161)	DT 0.006 (1.116)	loss 8.370 (8.370)	prob 1.466 (1.466)	GS 31.188 (31.188)	mem 43.025
Train: [10][630/750]	BT 0.032 (1.154)	DT 0.001 (1.109)	loss 8.392 (8.392)	prob 2.232 (2.232)	GS 29.281 (29.281)	mem 42.996
Train: [10][635/750]	BT 0.053 (1.145)	DT 0.010 (1.100)	loss 8.425 (8.425)	prob 1.334 (1.334)	GS 29.953 (29.953)	mem 42.997
Train: [10][640/750]	BT 2.835 (1.156)	DT 2.804 (1.111)	loss 7.647 (7.647)	prob 2.440 (2.440)	GS 36.625 (36.625)	mem 42.956
Train: [10][645/750]	BT 0.050 (1.147)	DT 0.001 (1.102)	loss 7.726 (7.726)	prob 2.125 (2.125)	GS 33.766 (33.766)	mem 42.980
Train: [10][650/750]	BT 0.036 (1.156)	DT 0.005 (1.111)	loss 8.656 (8.656)	prob 2.281 (2.281)	GS 35.531 (35.531)	mem 43.044
Train: [10][655/750]	BT 0.048 (1.156)	DT 0.003 (1.111)	loss 7.612 (7.612)	prob 4.173 (4.173)	GS 29.281 (29.281)	mem 42.900
arpack error, retry= 0
Train: [10][660/750]	BT 4.645 (1.155)	DT 4.566 (1.110)	loss 7.792 (7.792)	prob 2.669 (2.669)	GS 34.906 (34.906)	mem 43.036
Train: [10][665/750]	BT 0.037 (1.157)	DT 0.006 (1.112)	loss 7.560 (7.560)	prob 2.597 (2.597)	GS 28.875 (28.875)	mem 43.043
Train: [10][670/750]	BT 0.032 (1.149)	DT 0.001 (1.104)	loss 7.993 (7.993)	prob 2.864 (2.864)	GS 36.766 (36.766)	mem 42.908
Train: [10][675/750]	BT 0.033 (1.148)	DT 0.002 (1.103)	loss 8.697 (8.697)	prob 1.252 (1.252)	GS 28.688 (28.688)	mem 43.016
Train: [10][680/750]	BT 0.030 (1.156)	DT 0.001 (1.111)	loss 8.251 (8.251)	prob 3.612 (3.612)	GS 34.016 (34.016)	mem 42.969
Train: [10][685/750]	BT 0.030 (1.157)	DT 0.006 (1.112)	loss 8.274 (8.274)	prob 2.285 (2.285)	GS 31.906 (31.906)	mem 42.977
Train: [10][690/750]	BT 0.037 (1.158)	DT 0.006 (1.113)	loss 8.805 (8.805)	prob 1.666 (1.666)	GS 33.047 (33.047)	mem 42.947
Train: [10][695/750]	BT 0.043 (1.150)	DT 0.004 (1.105)	loss 8.403 (8.403)	prob 1.388 (1.388)	GS 33.109 (33.109)	mem 42.947
Train: [10][700/750]	BT 7.102 (1.157)	DT 7.022 (1.112)	loss 7.547 (7.547)	prob 3.357 (3.357)	GS 32.203 (32.203)	mem 43.189
Train: [10][705/750]	BT 0.034 (1.149)	DT 0.003 (1.104)	loss 7.709 (7.709)	prob 3.113 (3.113)	GS 29.625 (29.625)	mem 43.218
Train: [10][710/750]	BT 0.033 (1.149)	DT 0.003 (1.104)	loss 8.109 (8.109)	prob 2.962 (2.962)	GS 33.609 (33.609)	mem 43.038
Train: [10][715/750]	BT 0.096 (1.152)	DT 0.005 (1.108)	loss 8.467 (8.467)	prob 1.626 (1.626)	GS 33.078 (33.078)	mem 42.974
Train: [10][720/750]	BT 5.266 (1.152)	DT 5.193 (1.107)	loss 8.645 (8.645)	prob 2.635 (2.635)	GS 31.703 (31.703)	mem 43.151
Train: [10][725/750]	BT 0.033 (1.156)	DT 0.002 (1.112)	loss 7.967 (7.967)	prob 2.068 (2.068)	GS 28.859 (28.859)	mem 42.922
Train: [10][730/750]	BT 0.035 (1.149)	DT 0.004 (1.104)	loss 8.288 (8.288)	prob 2.646 (2.646)	GS 31.984 (31.984)	mem 42.881
Train: [10][735/750]	BT 0.051 (1.142)	DT 0.002 (1.098)	loss 8.762 (8.762)	prob 1.165 (1.165)	GS 33.188 (33.188)	mem 42.890
Train: [10][740/750]	BT 0.020 (1.144)	DT 0.001 (1.100)	loss 8.403 (8.403)	prob 3.062 (3.062)	GS 30.984 (30.984)	mem 16.578
Train: [10][745/750]	BT 0.042 (1.137)	DT 0.005 (1.093)	loss 8.425 (8.425)	prob 2.297 (2.297)	GS 38.844 (38.844)	mem 16.581
Train: [10][750/750]	BT 0.020 (1.133)	DT 0.001 (1.088)	loss 8.700 (8.700)	prob 3.734 (3.734)	GS 33.000 (33.000)	mem 13.600
Train: [10][755/750]	BT 0.038 (1.125)	DT 0.002 (1.081)	loss 7.758 (7.758)	prob 3.807 (3.807)	GS 36.000 (36.000)	mem 13.601
epoch 10, total time 851.55
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [11][1/750]	BT 19.422 (19.422)	DT 19.328 (19.328)	loss 8.723 (8.723)	prob 1.229 (1.229)	GS 28.750 (28.750)	mem 41.309
Train: [11][5/750]	BT 0.032 (5.614)	DT 0.001 (5.566)	loss 8.244 (8.244)	prob 1.575 (1.575)	GS 33.844 (33.844)	mem 41.702
Train: [11][10/750]	BT 0.024 (2.825)	DT 0.001 (2.785)	loss 8.047 (8.047)	prob 3.965 (3.965)	GS 33.984 (33.984)	mem 41.705
Train: [11][15/750]	BT 0.251 (1.967)	DT 0.171 (1.926)	loss 8.770 (8.770)	prob 1.368 (1.368)	GS 29.047 (29.047)	mem 41.792
Train: [11][20/750]	BT 0.031 (2.095)	DT 0.001 (2.053)	loss 7.844 (7.844)	prob 3.269 (3.269)	GS 33.922 (33.922)	mem 41.866
Train: [11][25/750]	BT 0.035 (1.686)	DT 0.002 (1.644)	loss 8.567 (8.567)	prob 1.210 (1.210)	GS 30.188 (30.188)	mem 41.869
Train: [11][30/750]	BT 0.036 (1.874)	DT 0.002 (1.832)	loss 8.246 (8.246)	prob 1.789 (1.789)	GS 34.234 (34.234)	mem 42.044
Train: [11][35/750]	BT 0.073 (1.614)	DT 0.005 (1.571)	loss 7.675 (7.675)	prob 2.885 (2.885)	GS 29.391 (29.391)	mem 42.121
Train: [11][40/750]	BT 14.116 (1.775)	DT 14.075 (1.731)	loss 8.729 (8.729)	prob 3.153 (3.153)	GS 34.500 (34.500)	mem 42.855
Train: [11][45/750]	BT 0.038 (1.586)	DT 0.001 (1.539)	loss 7.840 (7.840)	prob 2.350 (2.350)	GS 31.938 (31.938)	mem 42.837
Train: [11][50/750]	BT 0.032 (1.431)	DT 0.002 (1.386)	loss 8.178 (8.178)	prob 2.824 (2.824)	GS 30.484 (30.484)	mem 42.674
Train: [11][55/750]	BT 0.021 (1.528)	DT 0.001 (1.484)	loss 7.664 (7.664)	prob 2.628 (2.628)	GS 31.188 (31.188)	mem 42.672
Train: [11][60/750]	BT 0.075 (1.405)	DT 0.001 (1.361)	loss 8.487 (8.487)	prob 3.063 (3.063)	GS 32.359 (32.359)	mem 42.682
Train: [11][65/750]	BT 0.031 (1.491)	DT 0.001 (1.447)	loss 8.052 (8.052)	prob 2.393 (2.393)	GS 31.672 (31.672)	mem 42.661
Train: [11][70/750]	BT 0.054 (1.389)	DT 0.010 (1.344)	loss 9.180 (9.180)	prob 2.746 (2.746)	GS 30.469 (30.469)	mem 42.662
Train: [11][75/750]	BT 0.033 (1.300)	DT 0.003 (1.255)	loss 8.450 (8.450)	prob 2.154 (2.154)	GS 31.484 (31.484)	mem 42.663
Train: [11][80/750]	BT 0.040 (1.377)	DT 0.002 (1.332)	loss 8.637 (8.637)	prob 2.700 (2.700)	GS 32.078 (32.078)	mem 42.687
Train: [11][85/750]	BT 0.033 (1.299)	DT 0.001 (1.254)	loss 7.914 (7.914)	prob 2.932 (2.932)	GS 31.828 (31.828)	mem 42.688
Train: [11][90/750]	BT 0.034 (1.375)	DT 0.003 (1.330)	loss 8.385 (8.385)	prob 2.091 (2.091)	GS 34.250 (34.250)	mem 42.721
Train: [11][95/750]	BT 0.039 (1.304)	DT 0.001 (1.261)	loss 7.740 (7.740)	prob 2.406 (2.406)	GS 29.094 (29.094)	mem 42.675
Train: [11][100/750]	BT 14.158 (1.384)	DT 14.096 (1.340)	loss 8.210 (8.210)	prob 3.068 (3.068)	GS 34.062 (34.062)	mem 42.760
Train: [11][105/750]	BT 0.070 (1.320)	DT 0.008 (1.276)	loss 7.917 (7.917)	prob 3.352 (3.352)	GS 29.031 (29.031)	mem 42.761
Train: [11][110/750]	BT 0.654 (1.268)	DT 0.615 (1.224)	loss 8.183 (8.183)	prob 3.406 (3.406)	GS 32.938 (32.938)	mem 42.762
Train: [11][115/750]	BT 0.034 (1.308)	DT 0.001 (1.264)	loss 8.028 (8.028)	prob 2.731 (2.731)	GS 30.609 (30.609)	mem 42.779
Train: [11][120/750]	BT 0.169 (1.256)	DT 0.031 (1.212)	loss 8.753 (8.753)	prob 2.134 (2.134)	GS 36.422 (36.422)	mem 42.854
Train: [11][125/750]	BT 0.060 (1.314)	DT 0.001 (1.269)	loss 8.403 (8.403)	prob 1.821 (1.821)	GS 29.641 (29.641)	mem 42.788
Train: [11][130/750]	BT 0.032 (1.265)	DT 0.001 (1.221)	loss 7.935 (7.935)	prob 3.422 (3.422)	GS 34.562 (34.562)	mem 42.771
Train: [11][135/750]	BT 0.033 (1.232)	DT 0.002 (1.188)	loss 8.370 (8.370)	prob 2.732 (2.732)	GS 30.203 (30.203)	mem 42.904
Train: [11][140/750]	BT 0.046 (1.268)	DT 0.003 (1.225)	loss 8.478 (8.478)	prob 3.208 (3.208)	GS 33.406 (33.406)	mem 42.960
Train: [11][145/750]	BT 0.085 (1.247)	DT 0.003 (1.203)	loss 8.487 (8.487)	prob 2.104 (2.104)	GS 31.391 (31.391)	mem 42.957
Train: [11][150/750]	BT 0.024 (1.285)	DT 0.002 (1.241)	loss 8.104 (8.104)	prob 3.599 (3.599)	GS 32.797 (32.797)	mem 42.878
Train: [11][155/750]	BT 0.027 (1.245)	DT 0.001 (1.201)	loss 7.885 (7.885)	prob 3.082 (3.082)	GS 32.172 (32.172)	mem 42.882
Train: [11][160/750]	BT 4.395 (1.273)	DT 4.351 (1.228)	loss 8.107 (8.107)	prob 3.237 (3.237)	GS 33.344 (33.344)	mem 42.818
Train: [11][165/750]	BT 0.033 (1.236)	DT 0.001 (1.191)	loss 8.013 (8.013)	prob 2.430 (2.430)	GS 29.188 (29.188)	mem 42.818
Train: [11][170/750]	BT 3.567 (1.248)	DT 3.520 (1.203)	loss 8.087 (8.087)	prob 3.632 (3.632)	GS 37.078 (37.078)	mem 42.887
Train: [11][175/750]	BT 0.083 (1.247)	DT 0.002 (1.201)	loss 8.117 (8.117)	prob 2.510 (2.510)	GS 33.859 (33.859)	mem 42.879
Train: [11][180/750]	BT 7.105 (1.252)	DT 7.056 (1.207)	loss 7.937 (7.937)	prob 3.282 (3.282)	GS 37.016 (37.016)	mem 42.883
Train: [11][185/750]	BT 0.032 (1.248)	DT 0.001 (1.203)	loss 7.748 (7.748)	prob 3.068 (3.068)	GS 28.812 (28.812)	mem 42.942
Train: [11][190/750]	BT 0.045 (1.216)	DT 0.002 (1.171)	loss 7.938 (7.938)	prob 3.441 (3.441)	GS 31.828 (31.828)	mem 42.942
Train: [11][195/750]	BT 0.049 (1.231)	DT 0.004 (1.186)	loss 9.048 (9.048)	prob 1.948 (1.948)	GS 30.875 (30.875)	mem 42.962
Train: [11][200/750]	BT 0.066 (1.236)	DT 0.012 (1.191)	loss 7.963 (7.963)	prob 4.193 (4.193)	GS 33.438 (33.438)	mem 43.045
Train: [11][205/750]	BT 0.041 (1.229)	DT 0.010 (1.184)	loss 8.497 (8.497)	prob 2.441 (2.441)	GS 32.312 (32.312)	mem 42.900
Train: [11][210/750]	BT 0.029 (1.245)	DT 0.001 (1.201)	loss 8.982 (8.982)	prob 2.665 (2.665)	GS 31.938 (31.938)	mem 42.989
Train: [11][215/750]	BT 0.065 (1.218)	DT 0.026 (1.173)	loss 8.363 (8.363)	prob 2.814 (2.814)	GS 33.641 (33.641)	mem 42.993
Train: [11][220/750]	BT 4.335 (1.255)	DT 4.303 (1.210)	loss 8.080 (8.080)	prob 2.762 (2.762)	GS 33.953 (33.953)	mem 43.142
Train: [11][225/750]	BT 0.058 (1.228)	DT 0.002 (1.184)	loss 7.979 (7.979)	prob 3.090 (3.090)	GS 33.797 (33.797)	mem 43.145
Train: [11][230/750]	BT 7.652 (1.235)	DT 7.600 (1.191)	loss 8.064 (8.064)	prob 3.886 (3.886)	GS 35.156 (35.156)	mem 43.336
Train: [11][235/750]	BT 0.025 (1.241)	DT 0.001 (1.198)	loss 7.888 (7.888)	prob 3.830 (3.830)	GS 32.797 (32.797)	mem 43.371
Train: [11][240/750]	BT 0.099 (1.217)	DT 0.004 (1.173)	loss 8.041 (8.041)	prob 3.231 (3.231)	GS 32.672 (32.672)	mem 43.381
Train: [11][245/750]	BT 0.035 (1.238)	DT 0.003 (1.194)	loss 8.151 (8.151)	prob 2.792 (2.792)	GS 33.906 (33.906)	mem 43.304
Train: [11][250/750]	BT 0.030 (1.214)	DT 0.003 (1.170)	loss 8.160 (8.160)	prob 3.318 (3.318)	GS 32.359 (32.359)	mem 43.259
Train: [11][255/750]	BT 0.057 (1.218)	DT 0.010 (1.174)	loss 7.391 (7.391)	prob 4.133 (4.133)	GS 31.094 (31.094)	mem 43.229
Train: [11][260/750]	BT 0.098 (1.216)	DT 0.038 (1.173)	loss 8.600 (8.600)	prob 3.666 (3.666)	GS 30.938 (30.938)	mem 43.492
Train: [11][265/750]	BT 0.031 (1.194)	DT 0.002 (1.151)	loss 7.729 (7.729)	prob 3.488 (3.488)	GS 31.500 (31.500)	mem 43.248
Train: [11][270/750]	BT 0.028 (1.233)	DT 0.001 (1.189)	loss 8.786 (8.786)	prob 2.305 (2.305)	GS 33.188 (33.188)	mem 43.287
Train: [11][275/750]	BT 0.065 (1.211)	DT 0.001 (1.168)	loss 9.482 (9.482)	prob 1.118 (1.118)	GS 33.469 (33.469)	mem 43.365
Train: [11][280/750]	BT 10.764 (1.236)	DT 10.731 (1.192)	loss 8.120 (8.120)	prob 2.856 (2.856)	GS 35.406 (35.406)	mem 43.335
Train: [11][285/750]	BT 0.052 (1.215)	DT 0.010 (1.171)	loss 8.553 (8.553)	prob 1.959 (1.959)	GS 27.047 (27.047)	mem 43.422
Train: [11][290/750]	BT 1.828 (1.201)	DT 1.795 (1.157)	loss 8.249 (8.249)	prob 2.718 (2.718)	GS 35.438 (35.438)	mem 43.383
Train: [11][295/750]	BT 0.049 (1.220)	DT 0.001 (1.176)	loss 7.758 (7.758)	prob 3.731 (3.731)	GS 33.281 (33.281)	mem 43.276
Train: [11][300/750]	BT 0.033 (1.201)	DT 0.001 (1.157)	loss 8.965 (8.965)	prob 3.079 (3.079)	GS 34.641 (34.641)	mem 43.076
Train: [11][305/750]	BT 0.032 (1.218)	DT 0.001 (1.174)	loss 8.543 (8.543)	prob 2.090 (2.090)	GS 30.391 (30.391)	mem 42.985
Train: [11][310/750]	BT 0.035 (1.199)	DT 0.002 (1.155)	loss 8.132 (8.132)	prob 2.383 (2.383)	GS 36.406 (36.406)	mem 42.985
Train: [11][315/750]	BT 0.069 (1.184)	DT 0.015 (1.141)	loss 7.440 (7.440)	prob 2.710 (2.710)	GS 27.375 (27.375)	mem 43.056
Train: [11][320/750]	BT 0.047 (1.193)	DT 0.006 (1.149)	loss 8.185 (8.185)	prob 3.944 (3.944)	GS 35.531 (35.531)	mem 42.966
Train: [11][325/750]	BT 0.055 (1.176)	DT 0.001 (1.132)	loss 8.212 (8.212)	prob 1.854 (1.854)	GS 32.344 (32.344)	mem 43.008
Train: [11][330/750]	BT 0.065 (1.202)	DT 0.002 (1.158)	loss 7.589 (7.589)	prob 3.649 (3.649)	GS 30.281 (30.281)	mem 43.014
Train: [11][335/750]	BT 0.065 (1.185)	DT 0.005 (1.141)	loss 7.403 (7.403)	prob 3.814 (3.814)	GS 28.391 (28.391)	mem 43.017
Train: [11][340/750]	BT 13.322 (1.209)	DT 13.289 (1.165)	loss 8.182 (8.182)	prob 3.097 (3.097)	GS 35.953 (35.953)	mem 42.977
Train: [11][345/750]	BT 0.061 (1.192)	DT 0.002 (1.148)	loss 8.374 (8.374)	prob 3.294 (3.294)	GS 29.406 (29.406)	mem 42.979
Train: [11][350/750]	BT 0.261 (1.177)	DT 0.211 (1.132)	loss 7.455 (7.455)	prob 3.010 (3.010)	GS 32.797 (32.797)	mem 43.167
Train: [11][355/750]	BT 0.034 (1.194)	DT 0.003 (1.150)	loss 8.150 (8.150)	prob 2.334 (2.334)	GS 29.719 (29.719)	mem 43.057
Train: [11][360/750]	BT 0.032 (1.178)	DT 0.001 (1.134)	loss 8.378 (8.378)	prob 2.679 (2.679)	GS 31.906 (31.906)	mem 42.951
Train: [11][365/750]	BT 0.029 (1.198)	DT 0.001 (1.154)	loss 7.985 (7.985)	prob 2.819 (2.819)	GS 33.016 (33.016)	mem 42.987
Train: [11][370/750]	BT 0.041 (1.182)	DT 0.001 (1.138)	loss 8.072 (8.072)	prob 4.033 (4.033)	GS 31.531 (31.531)	mem 42.987
Train: [11][375/750]	BT 0.032 (1.167)	DT 0.002 (1.123)	loss 8.990 (8.990)	prob 1.891 (1.891)	GS 30.938 (30.938)	mem 42.916
Train: [11][380/750]	BT 0.024 (1.188)	DT 0.001 (1.144)	loss 8.135 (8.135)	prob 1.534 (1.534)	GS 37.469 (37.469)	mem 42.978
Train: [11][385/750]	BT 0.039 (1.173)	DT 0.002 (1.130)	loss 8.097 (8.097)	prob 2.247 (2.247)	GS 29.438 (29.438)	mem 42.916
Train: [11][390/750]	BT 0.032 (1.186)	DT 0.002 (1.142)	loss 8.386 (8.386)	prob 2.600 (2.600)	GS 32.438 (32.438)	mem 42.989
Train: [11][395/750]	BT 0.034 (1.171)	DT 0.002 (1.128)	loss 8.277 (8.277)	prob 1.847 (1.847)	GS 30.266 (30.266)	mem 42.990
Train: [11][400/750]	BT 11.753 (1.192)	DT 11.709 (1.149)	loss 8.149 (8.149)	prob 1.622 (1.622)	GS 34.938 (34.938)	mem 43.013
Train: [11][405/750]	BT 0.050 (1.178)	DT 0.009 (1.134)	loss 7.768 (7.768)	prob 2.209 (2.209)	GS 28.828 (28.828)	mem 43.016
Train: [11][410/750]	BT 1.486 (1.167)	DT 1.452 (1.124)	loss 9.071 (9.071)	prob 2.649 (2.649)	GS 36.047 (36.047)	mem 43.131
Train: [11][415/750]	BT 0.027 (1.179)	DT 0.001 (1.135)	loss 8.186 (8.186)	prob 2.348 (2.348)	GS 32.484 (32.484)	mem 43.034
Train: [11][420/750]	BT 0.087 (1.166)	DT 0.004 (1.122)	loss 8.541 (8.541)	prob 2.800 (2.800)	GS 32.484 (32.484)	mem 43.062
Train: [11][425/750]	BT 0.118 (1.183)	DT 0.016 (1.139)	loss 7.517 (7.517)	prob 2.514 (2.514)	GS 28.781 (28.781)	mem 43.170
Train: [11][430/750]	BT 0.053 (1.170)	DT 0.011 (1.126)	loss 8.212 (8.212)	prob 3.048 (3.048)	GS 36.484 (36.484)	mem 43.055
Train: [11][435/750]	BT 0.044 (1.165)	DT 0.008 (1.121)	loss 7.986 (7.986)	prob 1.978 (1.978)	GS 32.859 (32.859)	mem 43.081
Train: [11][440/750]	BT 0.032 (1.170)	DT 0.006 (1.126)	loss 8.140 (8.140)	prob 2.737 (2.737)	GS 32.266 (32.266)	mem 43.104
Train: [11][445/750]	BT 0.042 (1.157)	DT 0.002 (1.113)	loss 7.938 (7.938)	prob 1.419 (1.419)	GS 36.375 (36.375)	mem 43.196
Train: [11][450/750]	BT 0.032 (1.170)	DT 0.001 (1.127)	loss 8.000 (8.000)	prob 2.675 (2.675)	GS 27.766 (27.766)	mem 43.061
Train: [11][455/750]	BT 0.045 (1.158)	DT 0.011 (1.114)	loss 7.807 (7.807)	prob 3.063 (3.063)	GS 32.922 (32.922)	mem 43.088
Train: [11][460/750]	BT 0.200 (1.172)	DT 0.101 (1.128)	loss 8.107 (8.107)	prob 1.087 (1.087)	GS 35.266 (35.266)	mem 43.035
Train: [11][465/750]	BT 0.029 (1.160)	DT 0.001 (1.116)	loss 7.964 (7.964)	prob 2.169 (2.169)	GS 31.969 (31.969)	mem 43.037
Train: [11][470/750]	BT 6.873 (1.178)	DT 6.791 (1.133)	loss 7.975 (7.975)	prob 2.329 (2.329)	GS 32.297 (32.297)	mem 43.042
Train: [11][475/750]	BT 0.052 (1.167)	DT 0.015 (1.123)	loss 8.177 (8.177)	prob 1.233 (1.233)	GS 34.172 (34.172)	mem 43.141
Train: [11][480/750]	BT 5.192 (1.166)	DT 5.099 (1.122)	loss 8.468 (8.468)	prob 2.347 (2.347)	GS 32.344 (32.344)	mem 43.124
Train: [11][485/750]	BT 0.050 (1.174)	DT 0.005 (1.130)	loss 7.865 (7.865)	prob 1.488 (1.488)	GS 33.469 (33.469)	mem 43.030
Train: [11][490/750]	BT 0.048 (1.162)	DT 0.002 (1.118)	loss 8.500 (8.500)	prob 2.362 (2.362)	GS 31.641 (31.641)	mem 43.031
Train: [11][495/750]	BT 0.101 (1.175)	DT 0.014 (1.130)	loss 8.242 (8.242)	prob 1.748 (1.748)	GS 29.031 (29.031)	mem 43.048
Train: [11][500/750]	BT 0.029 (1.164)	DT 0.007 (1.120)	loss 9.099 (9.099)	prob 2.375 (2.375)	GS 31.125 (31.125)	mem 43.048
Train: [11][505/750]	BT 0.146 (1.157)	DT 0.032 (1.112)	loss 7.821 (7.821)	prob 1.821 (1.821)	GS 32.047 (32.047)	mem 43.047
Train: [11][510/750]	BT 0.067 (1.167)	DT 0.004 (1.122)	loss 7.960 (7.960)	prob 1.622 (1.622)	GS 33.625 (33.625)	mem 43.196
Train: [11][515/750]	BT 0.038 (1.156)	DT 0.010 (1.111)	loss 7.883 (7.883)	prob 2.875 (2.875)	GS 28.250 (28.250)	mem 43.014
Train: [11][520/750]	BT 0.034 (1.171)	DT 0.002 (1.127)	loss 8.514 (8.514)	prob 2.501 (2.501)	GS 32.156 (32.156)	mem 43.145
Train: [11][525/750]	BT 0.031 (1.161)	DT 0.001 (1.116)	loss 7.989 (7.989)	prob 2.550 (2.550)	GS 29.688 (29.688)	mem 43.047
Train: [11][530/750]	BT 12.204 (1.173)	DT 12.156 (1.128)	loss 8.078 (8.078)	prob 2.525 (2.525)	GS 35.984 (35.984)	mem 43.010
Train: [11][535/750]	BT 0.034 (1.163)	DT 0.003 (1.118)	loss 8.379 (8.379)	prob 1.139 (1.139)	GS 29.375 (29.375)	mem 43.047
Train: [11][540/750]	BT 1.944 (1.156)	DT 1.898 (1.111)	loss 8.865 (8.865)	prob 1.956 (1.956)	GS 34.609 (34.609)	mem 42.989
Train: [11][545/750]	BT 0.062 (1.163)	DT 0.003 (1.118)	loss 7.835 (7.835)	prob 2.826 (2.826)	GS 30.812 (30.812)	mem 43.009
Train: [11][550/750]	BT 0.046 (1.153)	DT 0.005 (1.108)	loss 8.697 (8.697)	prob 2.764 (2.764)	GS 31.969 (31.969)	mem 43.145
Train: [11][555/750]	BT 0.052 (1.166)	DT 0.002 (1.121)	loss 7.907 (7.907)	prob 2.392 (2.392)	GS 34.703 (34.703)	mem 43.193
Train: [11][560/750]	BT 0.050 (1.160)	DT 0.015 (1.115)	loss 7.845 (7.845)	prob 2.515 (2.515)	GS 33.734 (33.734)	mem 43.234
Train: [11][565/750]	BT 0.061 (1.154)	DT 0.003 (1.109)	loss 8.160 (8.160)	prob 1.254 (1.254)	GS 31.234 (31.234)	mem 43.015
Train: [11][570/750]	BT 0.054 (1.165)	DT 0.010 (1.120)	loss 8.454 (8.454)	prob 2.227 (2.227)	GS 35.078 (35.078)	mem 43.062
Train: [11][575/750]	BT 0.027 (1.155)	DT 0.001 (1.110)	loss 8.379 (8.379)	prob 1.645 (1.645)	GS 28.016 (28.016)	mem 43.062
Train: [11][580/750]	BT 5.280 (1.167)	DT 5.221 (1.122)	loss 8.297 (8.297)	prob 2.844 (2.844)	GS 32.453 (32.453)	mem 43.017
Train: [11][585/750]	BT 0.038 (1.157)	DT 0.001 (1.113)	loss 8.430 (8.430)	prob 1.402 (1.402)	GS 28.656 (28.656)	mem 43.018
Train: [11][590/750]	BT 3.593 (1.154)	DT 3.483 (1.109)	loss 8.245 (8.245)	prob 2.307 (2.307)	GS 33.875 (33.875)	mem 43.163
Train: [11][595/750]	BT 0.032 (1.160)	DT 0.009 (1.115)	loss 8.247 (8.247)	prob 1.712 (1.712)	GS 31.219 (31.219)	mem 43.027
Train: [11][600/750]	BT 0.155 (1.150)	DT 0.106 (1.106)	loss 9.176 (9.176)	prob 2.498 (2.498)	GS 34.438 (34.438)	mem 43.027
Train: [11][605/750]	BT 0.034 (1.159)	DT 0.006 (1.114)	loss 8.025 (8.025)	prob 2.055 (2.055)	GS 30.312 (30.312)	mem 43.046
Train: [11][610/750]	BT 0.044 (1.150)	DT 0.001 (1.105)	loss 8.713 (8.713)	prob 2.656 (2.656)	GS 35.922 (35.922)	mem 43.046
Train: [11][615/750]	BT 0.034 (1.151)	DT 0.003 (1.106)	loss 7.988 (7.988)	prob 2.343 (2.343)	GS 31.188 (31.188)	mem 43.107
Train: [11][620/750]	BT 0.037 (1.154)	DT 0.006 (1.109)	loss 8.166 (8.166)	prob 3.258 (3.258)	GS 31.922 (31.922)	mem 43.077
Train: [11][625/750]	BT 0.053 (1.151)	DT 0.004 (1.107)	loss 8.401 (8.401)	prob 1.963 (1.963)	GS 33.562 (33.562)	mem 43.057
Train: [11][630/750]	BT 0.054 (1.162)	DT 0.003 (1.117)	loss 7.916 (7.916)	prob 3.054 (3.054)	GS 32.547 (32.547)	mem 43.123
Train: [11][635/750]	BT 0.036 (1.153)	DT 0.002 (1.109)	loss 7.814 (7.814)	prob 3.221 (3.221)	GS 30.656 (30.656)	mem 43.125
Train: [11][640/750]	BT 9.719 (1.164)	DT 9.675 (1.119)	loss 8.269 (8.269)	prob 3.096 (3.096)	GS 32.984 (32.984)	mem 43.118
Train: [11][645/750]	BT 0.035 (1.155)	DT 0.001 (1.111)	loss 8.509 (8.509)	prob 1.793 (1.793)	GS 32.750 (32.750)	mem 43.119
Train: [11][650/750]	BT 0.041 (1.151)	DT 0.010 (1.107)	loss 7.862 (7.862)	prob 3.194 (3.194)	GS 31.734 (31.734)	mem 42.999
Train: [11][655/750]	BT 0.054 (1.152)	DT 0.005 (1.107)	loss 7.988 (7.988)	prob 2.879 (2.879)	GS 31.578 (31.578)	mem 43.206
arpack error, retry= 0
Train: [11][660/750]	BT 7.435 (1.155)	DT 7.399 (1.110)	loss 8.356 (8.356)	prob 2.974 (2.974)	GS 36.562 (36.562)	mem 43.114
Train: [11][665/750]	BT 0.031 (1.152)	DT 0.001 (1.107)	loss 8.741 (8.741)	prob 2.519 (2.519)	GS 30.328 (30.328)	mem 43.118
Train: [11][670/750]	BT 0.027 (1.144)	DT 0.001 (1.099)	loss 8.607 (8.607)	prob 2.864 (2.864)	GS 31.281 (31.281)	mem 43.119
Train: [11][675/750]	BT 0.075 (1.149)	DT 0.014 (1.104)	loss 8.245 (8.245)	prob 2.424 (2.424)	GS 32.234 (32.234)	mem 43.215
Train: [11][680/750]	BT 0.051 (1.144)	DT 0.001 (1.099)	loss 8.599 (8.599)	prob 3.454 (3.454)	GS 33.062 (33.062)	mem 43.239
Train: [11][685/750]	BT 0.043 (1.152)	DT 0.008 (1.107)	loss 8.518 (8.518)	prob 1.714 (1.714)	GS 30.750 (30.750)	mem 43.296
Train: [11][690/750]	BT 0.056 (1.146)	DT 0.004 (1.101)	loss 8.989 (8.989)	prob 2.804 (2.804)	GS 34.500 (34.500)	mem 43.102
Train: [11][695/750]	BT 0.051 (1.138)	DT 0.010 (1.093)	loss 8.384 (8.384)	prob 2.135 (2.135)	GS 34.438 (34.438)	mem 43.103
Train: [11][700/750]	BT 0.033 (1.147)	DT 0.001 (1.103)	loss 8.467 (8.467)	prob 2.459 (2.459)	GS 33.906 (33.906)	mem 43.113
Train: [11][705/750]	BT 0.044 (1.140)	DT 0.017 (1.095)	loss 8.860 (8.860)	prob 1.748 (1.748)	GS 29.797 (29.797)	mem 43.095
Train: [11][710/750]	BT 0.030 (1.148)	DT 0.001 (1.104)	loss 8.281 (8.281)	prob 3.029 (3.029)	GS 36.766 (36.766)	mem 43.060
Train: [11][715/750]	BT 0.064 (1.143)	DT 0.004 (1.098)	loss 7.880 (7.880)	prob 2.700 (2.700)	GS 26.000 (26.000)	mem 43.524
Train: [11][720/750]	BT 10.516 (1.152)	DT 10.466 (1.107)	loss 8.247 (8.247)	prob 3.532 (3.532)	GS 33.641 (33.641)	mem 43.051
Train: [11][725/750]	BT 0.049 (1.144)	DT 0.004 (1.099)	loss 8.208 (8.208)	prob 2.063 (2.063)	GS 34.203 (34.203)	mem 43.051
Train: [11][730/750]	BT 1.767 (1.141)	DT 1.731 (1.097)	loss 8.283 (8.283)	prob 2.745 (2.745)	GS 39.125 (39.125)	mem 43.140
Train: [11][735/750]	BT 0.045 (1.148)	DT 0.002 (1.103)	loss 8.226 (8.226)	prob 2.236 (2.236)	GS 30.641 (30.641)	mem 42.603
Train: [11][740/750]	BT 0.025 (1.140)	DT 0.001 (1.096)	loss 9.002 (9.002)	prob 1.906 (1.906)	GS 32.766 (32.766)	mem 42.601
Train: [11][745/750]	BT 0.031 (1.141)	DT 0.001 (1.096)	loss 7.999 (7.999)	prob 2.032 (2.032)	GS 35.969 (35.969)	mem 10.679
Train: [11][750/750]	BT 0.035 (1.133)	DT 0.001 (1.089)	loss 8.970 (8.970)	prob 3.442 (3.442)	GS 27.875 (27.875)	mem 10.718
Train: [11][755/750]	BT 0.050 (1.126)	DT 0.011 (1.082)	loss 7.768 (7.768)	prob 3.288 (3.288)	GS 37.312 (37.312)	mem 10.693
epoch 11, total time 852.56
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [12][1/750]	BT 23.284 (23.284)	DT 23.190 (23.190)	loss 9.657 (9.657)	prob 2.175 (2.175)	GS 36.938 (36.938)	mem 42.350
Train: [12][5/750]	BT 0.038 (5.153)	DT 0.005 (5.098)	loss 8.850 (8.850)	prob 1.454 (1.454)	GS 29.906 (29.906)	mem 42.383
Train: [12][10/750]	BT 1.551 (2.750)	DT 1.518 (2.703)	loss 8.656 (8.656)	prob 2.753 (2.753)	GS 36.469 (36.469)	mem 42.413
Train: [12][15/750]	BT 0.079 (2.566)	DT 0.007 (2.514)	loss 8.229 (8.229)	prob 2.417 (2.417)	GS 34.484 (34.484)	mem 42.391
Train: [12][20/750]	BT 5.304 (2.234)	DT 5.225 (2.184)	loss 9.106 (9.106)	prob 2.741 (2.741)	GS 32.078 (32.078)	mem 42.468
Train: [12][25/750]	BT 0.032 (1.795)	DT 0.001 (1.747)	loss 7.975 (7.975)	prob 2.687 (2.687)	GS 36.172 (36.172)	mem 42.470
Train: [12][30/750]	BT 0.691 (1.786)	DT 0.604 (1.737)	loss 8.762 (8.762)	prob 1.966 (1.966)	GS 34.516 (34.516)	mem 42.733
Train: [12][35/750]	BT 0.040 (1.739)	DT 0.001 (1.690)	loss 7.661 (7.661)	prob 3.074 (3.074)	GS 32.469 (32.469)	mem 42.489
Train: [12][40/750]	BT 3.059 (1.636)	DT 2.984 (1.586)	loss 8.532 (8.532)	prob 3.840 (3.840)	GS 31.500 (31.500)	mem 42.584
Train: [12][45/750]	BT 0.147 (1.624)	DT 0.022 (1.569)	loss 8.273 (8.273)	prob 2.630 (2.630)	GS 31.922 (31.922)	mem 42.562
Train: [12][50/750]	BT 3.120 (1.529)	DT 3.078 (1.475)	loss 7.964 (7.964)	prob 2.931 (2.931)	GS 34.875 (34.875)	mem 42.573
Train: [12][55/750]	BT 0.032 (1.469)	DT 0.001 (1.416)	loss 8.118 (8.118)	prob 2.653 (2.653)	GS 30.703 (30.703)	mem 42.587
Train: [12][60/750]	BT 0.032 (1.466)	DT 0.001 (1.414)	loss 8.848 (8.848)	prob 2.833 (2.833)	GS 35.438 (35.438)	mem 42.656
Train: [12][65/750]	BT 0.038 (1.413)	DT 0.003 (1.362)	loss 8.456 (8.456)	prob 2.737 (2.737)	GS 32.469 (32.469)	mem 42.674
Train: [12][70/750]	BT 4.639 (1.433)	DT 4.606 (1.383)	loss 8.823 (8.823)	prob 2.847 (2.847)	GS 32.703 (32.703)	mem 42.687
Train: [12][75/750]	BT 0.046 (1.433)	DT 0.001 (1.384)	loss 8.215 (8.215)	prob 2.200 (2.200)	GS 34.188 (34.188)	mem 42.702
Train: [12][80/750]	BT 1.944 (1.372)	DT 1.913 (1.321)	loss 8.852 (8.852)	prob 2.469 (2.469)	GS 32.297 (32.297)	mem 42.662
Train: [12][85/750]	BT 0.034 (1.322)	DT 0.002 (1.273)	loss 7.936 (7.936)	prob 3.107 (3.107)	GS 30.484 (30.484)	mem 42.696
Train: [12][90/750]	BT 0.032 (1.346)	DT 0.002 (1.297)	loss 9.436 (9.436)	prob 2.692 (2.692)	GS 38.016 (38.016)	mem 42.484
Train: [12][95/750]	BT 0.054 (1.319)	DT 0.007 (1.270)	loss 8.162 (8.162)	prob 3.607 (3.607)	GS 34.531 (34.531)	mem 42.628
Train: [12][100/750]	BT 0.029 (1.412)	DT 0.001 (1.362)	loss 9.134 (9.134)	prob 2.528 (2.528)	GS 36.156 (36.156)	mem 42.774
Train: [12][105/750]	BT 0.069 (1.347)	DT 0.006 (1.297)	loss 7.745 (7.745)	prob 3.142 (3.142)	GS 34.609 (34.609)	mem 42.776
Train: [12][110/750]	BT 11.988 (1.396)	DT 11.942 (1.347)	loss 9.033 (9.033)	prob 3.044 (3.044)	GS 36.312 (36.312)	mem 42.801
Train: [12][115/750]	BT 0.031 (1.337)	DT 0.001 (1.288)	loss 8.687 (8.687)	prob 2.235 (2.235)	GS 36.625 (36.625)	mem 42.834
Train: [12][120/750]	BT 0.052 (1.283)	DT 0.001 (1.235)	loss 8.328 (8.328)	prob 4.381 (4.381)	GS 34.078 (34.078)	mem 42.803
Train: [12][125/750]	BT 0.031 (1.350)	DT 0.001 (1.303)	loss 7.925 (7.925)	prob 3.182 (3.182)	GS 29.094 (29.094)	mem 42.830
Train: [12][130/750]	BT 0.032 (1.301)	DT 0.001 (1.253)	loss 8.634 (8.634)	prob 3.608 (3.608)	GS 36.984 (36.984)	mem 42.831
Train: [12][135/750]	BT 0.031 (1.350)	DT 0.002 (1.303)	loss 8.654 (8.654)	prob 2.316 (2.316)	GS 31.328 (31.328)	mem 42.973
Train: [12][140/750]	BT 0.078 (1.304)	DT 0.009 (1.257)	loss 8.298 (8.298)	prob 3.577 (3.577)	GS 35.062 (35.062)	mem 42.907
Train: [12][145/750]	BT 0.047 (1.260)	DT 0.001 (1.214)	loss 8.509 (8.509)	prob 2.315 (2.315)	GS 30.328 (30.328)	mem 42.907
Train: [12][150/750]	BT 0.021 (1.320)	DT 0.001 (1.274)	loss 8.012 (8.012)	prob 3.427 (3.427)	GS 29.234 (29.234)	mem 42.831
Train: [12][155/750]	BT 0.065 (1.279)	DT 0.009 (1.233)	loss 7.609 (7.609)	prob 4.364 (4.364)	GS 30.641 (30.641)	mem 42.832
Train: [12][160/750]	BT 0.022 (1.330)	DT 0.001 (1.285)	loss 8.795 (8.795)	prob 3.502 (3.502)	GS 34.234 (34.234)	mem 42.916
Train: [12][165/750]	BT 0.034 (1.291)	DT 0.001 (1.246)	loss 8.442 (8.442)	prob 2.939 (2.939)	GS 28.578 (28.578)	mem 42.918
Train: [12][170/750]	BT 11.515 (1.322)	DT 11.467 (1.277)	loss 8.044 (8.044)	prob 3.536 (3.536)	GS 32.109 (32.109)	mem 42.889
Train: [12][175/750]	BT 0.031 (1.285)	DT 0.001 (1.241)	loss 8.704 (8.704)	prob 3.016 (3.016)	GS 26.250 (26.250)	mem 42.893
Train: [12][180/750]	BT 0.038 (1.251)	DT 0.001 (1.206)	loss 8.868 (8.868)	prob 2.159 (2.159)	GS 35.953 (35.953)	mem 42.966
Train: [12][185/750]	BT 0.030 (1.296)	DT 0.001 (1.252)	loss 8.055 (8.055)	prob 3.330 (3.330)	GS 30.906 (30.906)	mem 42.881
Train: [12][190/750]	BT 0.044 (1.263)	DT 0.014 (1.219)	loss 8.183 (8.183)	prob 2.684 (2.684)	GS 31.344 (31.344)	mem 42.935
Train: [12][195/750]	BT 0.021 (1.304)	DT 0.001 (1.260)	loss 8.256 (8.256)	prob 2.409 (2.409)	GS 27.359 (27.359)	mem 42.892
Train: [12][200/750]	BT 0.040 (1.272)	DT 0.011 (1.229)	loss 8.988 (8.988)	prob 2.983 (2.983)	GS 38.750 (38.750)	mem 42.893
Train: [12][205/750]	BT 0.064 (1.242)	DT 0.011 (1.199)	loss 8.955 (8.955)	prob 1.858 (1.858)	GS 28.797 (28.797)	mem 42.947
Train: [12][210/750]	BT 0.026 (1.279)	DT 0.001 (1.235)	loss 8.363 (8.363)	prob 3.768 (3.768)	GS 35.250 (35.250)	mem 42.920
Train: [12][215/750]	BT 0.030 (1.250)	DT 0.001 (1.207)	loss 7.893 (7.893)	prob 3.694 (3.694)	GS 30.078 (30.078)	mem 42.950
Train: [12][220/750]	BT 0.023 (1.263)	DT 0.001 (1.221)	loss 8.542 (8.542)	prob 3.798 (3.798)	GS 35.203 (35.203)	mem 42.970
Train: [12][225/750]	BT 0.068 (1.237)	DT 0.024 (1.194)	loss 8.400 (8.400)	prob 2.742 (2.742)	GS 32.203 (32.203)	mem 42.908
Train: [12][230/750]	BT 13.359 (1.268)	DT 13.329 (1.226)	loss 8.939 (8.939)	prob 3.870 (3.870)	GS 33.906 (33.906)	mem 42.941
Train: [12][235/750]	BT 0.028 (1.242)	DT 0.001 (1.200)	loss 7.872 (7.872)	prob 2.957 (2.957)	GS 25.938 (25.938)	mem 42.969
Train: [12][240/750]	BT 0.027 (1.217)	DT 0.001 (1.175)	loss 8.146 (8.146)	prob 4.081 (4.081)	GS 31.625 (31.625)	mem 42.976
Train: [12][245/750]	BT 0.029 (1.256)	DT 0.001 (1.214)	loss 7.918 (7.918)	prob 3.639 (3.639)	GS 33.594 (33.594)	mem 43.004
Train: [12][250/750]	BT 0.073 (1.232)	DT 0.001 (1.190)	loss 8.378 (8.378)	prob 3.112 (3.112)	GS 35.469 (35.469)	mem 42.997
Train: [12][255/750]	BT 0.030 (1.260)	DT 0.001 (1.218)	loss 7.498 (7.498)	prob 4.004 (4.004)	GS 29.875 (29.875)	mem 43.023
Train: [12][260/750]	BT 0.024 (1.236)	DT 0.001 (1.194)	loss 7.686 (7.686)	prob 3.257 (3.257)	GS 32.328 (32.328)	mem 43.024
Train: [12][265/750]	BT 0.025 (1.214)	DT 0.001 (1.172)	loss 7.852 (7.852)	prob 2.706 (2.706)	GS 29.203 (29.203)	mem 43.025
Train: [12][270/750]	BT 0.030 (1.241)	DT 0.005 (1.199)	loss 7.936 (7.936)	prob 3.686 (3.686)	GS 29.297 (29.297)	mem 43.020
Train: [12][275/750]	BT 0.023 (1.219)	DT 0.001 (1.177)	loss 7.752 (7.752)	prob 3.133 (3.133)	GS 31.328 (31.328)	mem 42.979
Train: [12][280/750]	BT 0.034 (1.240)	DT 0.003 (1.198)	loss 8.501 (8.501)	prob 2.876 (2.876)	GS 35.797 (35.797)	mem 43.167
Train: [12][285/750]	BT 0.034 (1.219)	DT 0.002 (1.177)	loss 8.938 (8.938)	prob 1.411 (1.411)	GS 35.375 (35.375)	mem 43.194
Train: [12][290/750]	BT 15.472 (1.252)	DT 15.421 (1.210)	loss 8.131 (8.131)	prob 3.178 (3.178)	GS 36.797 (36.797)	mem 42.995
Train: [12][295/750]	BT 0.041 (1.231)	DT 0.001 (1.190)	loss 7.966 (7.966)	prob 2.787 (2.787)	GS 29.688 (29.688)	mem 42.997
Train: [12][300/750]	BT 0.053 (1.212)	DT 0.009 (1.170)	loss 8.386 (8.386)	prob 2.184 (2.184)	GS 34.562 (34.562)	mem 43.070
Train: [12][305/750]	BT 0.050 (1.229)	DT 0.017 (1.188)	loss 8.762 (8.762)	prob 1.539 (1.539)	GS 39.938 (39.938)	mem 42.957
Train: [12][310/750]	BT 0.063 (1.212)	DT 0.005 (1.170)	loss 8.907 (8.907)	prob 1.887 (1.887)	GS 32.422 (32.422)	mem 43.030
Train: [12][315/750]	BT 0.026 (1.233)	DT 0.001 (1.191)	loss 7.726 (7.726)	prob 1.985 (1.985)	GS 29.109 (29.109)	mem 42.915
Train: [12][320/750]	BT 0.031 (1.214)	DT 0.001 (1.173)	loss 8.839 (8.839)	prob 2.665 (2.665)	GS 34.312 (34.312)	mem 42.915
Train: [12][325/750]	BT 0.025 (1.196)	DT 0.001 (1.155)	loss 8.200 (8.200)	prob 2.416 (2.416)	GS 26.656 (26.656)	mem 42.916
Train: [12][330/750]	BT 0.032 (1.219)	DT 0.001 (1.177)	loss 8.148 (8.148)	prob 1.899 (1.899)	GS 28.891 (28.891)	mem 43.002
Train: [12][335/750]	BT 0.034 (1.201)	DT 0.002 (1.160)	loss 7.709 (7.709)	prob 2.814 (2.814)	GS 27.656 (27.656)	mem 43.042
Train: [12][340/750]	BT 0.029 (1.225)	DT 0.001 (1.183)	loss 8.041 (8.041)	prob 2.935 (2.935)	GS 34.844 (34.844)	mem 43.009
Train: [12][345/750]	BT 0.079 (1.207)	DT 0.010 (1.166)	loss 8.616 (8.616)	prob 2.409 (2.409)	GS 33.500 (33.500)	mem 43.010
Train: [12][350/750]	BT 13.743 (1.230)	DT 13.714 (1.189)	loss 8.814 (8.814)	prob 2.073 (2.073)	GS 34.766 (34.766)	mem 42.960
Train: [12][355/750]	BT 0.025 (1.213)	DT 0.002 (1.172)	loss 7.576 (7.576)	prob 2.568 (2.568)	GS 30.094 (30.094)	mem 42.963
Train: [12][360/750]	BT 0.036 (1.197)	DT 0.005 (1.156)	loss 8.177 (8.177)	prob 2.249 (2.249)	GS 31.984 (31.984)	mem 42.964
Train: [12][365/750]	BT 0.058 (1.214)	DT 0.010 (1.173)	loss 7.814 (7.814)	prob 2.237 (2.237)	GS 32.234 (32.234)	mem 43.020
Train: [12][370/750]	BT 0.051 (1.198)	DT 0.001 (1.157)	loss 7.764 (7.764)	prob 3.255 (3.255)	GS 32.234 (32.234)	mem 43.026
Train: [12][375/750]	BT 0.060 (1.210)	DT 0.009 (1.170)	loss 7.923 (7.923)	prob 3.261 (3.261)	GS 29.797 (29.797)	mem 43.084
Train: [12][380/750]	BT 0.026 (1.195)	DT 0.001 (1.154)	loss 9.188 (9.188)	prob 2.774 (2.774)	GS 32.844 (32.844)	mem 43.001
Train: [12][385/750]	BT 0.053 (1.180)	DT 0.016 (1.139)	loss 7.768 (7.768)	prob 3.029 (3.029)	GS 33.578 (33.578)	mem 43.002
Train: [12][390/750]	BT 0.032 (1.193)	DT 0.001 (1.152)	loss 9.019 (9.019)	prob 1.957 (1.957)	GS 34.812 (34.812)	mem 43.060
Train: [12][395/750]	BT 0.038 (1.179)	DT 0.003 (1.139)	loss 8.322 (8.322)	prob 1.615 (1.615)	GS 29.547 (29.547)	mem 43.183
Train: [12][400/750]	BT 0.985 (1.199)	DT 0.895 (1.158)	loss 8.299 (8.299)	prob 1.803 (1.803)	GS 33.578 (33.578)	mem 43.050
Train: [12][405/750]	BT 0.086 (1.190)	DT 0.007 (1.149)	loss 8.644 (8.644)	prob 0.984 (0.984)	GS 31.891 (31.891)	mem 43.051
Train: [12][410/750]	BT 13.963 (1.210)	DT 13.904 (1.169)	loss 9.460 (9.460)	prob 1.883 (1.883)	GS 36.562 (36.562)	mem 43.111
Train: [12][415/750]	BT 0.032 (1.196)	DT 0.002 (1.155)	loss 8.741 (8.741)	prob 1.986 (1.986)	GS 31.750 (31.750)	mem 43.054
Train: [12][420/750]	BT 0.092 (1.182)	DT 0.001 (1.141)	loss 9.536 (9.536)	prob 1.767 (1.767)	GS 33.250 (33.250)	mem 43.056
Train: [12][425/750]	BT 0.080 (1.199)	DT 0.012 (1.158)	loss 8.523 (8.523)	prob 1.277 (1.277)	GS 32.703 (32.703)	mem 43.141
Train: [12][430/750]	BT 0.050 (1.186)	DT 0.006 (1.144)	loss 8.561 (8.561)	prob 2.956 (2.956)	GS 36.641 (36.641)	mem 43.100
Train: [12][435/750]	BT 0.037 (1.199)	DT 0.001 (1.158)	loss 7.783 (7.783)	prob 3.148 (3.148)	GS 29.484 (29.484)	mem 43.103
Train: [12][440/750]	BT 0.074 (1.186)	DT 0.001 (1.145)	loss 8.569 (8.569)	prob 2.805 (2.805)	GS 36.219 (36.219)	mem 43.025
Train: [12][445/750]	BT 0.026 (1.174)	DT 0.002 (1.132)	loss 9.719 (9.719)	prob -0.076 (-0.076)	GS 31.297 (31.297)	mem 43.061
Train: [12][450/750]	BT 0.038 (1.184)	DT 0.004 (1.142)	loss 8.201 (8.201)	prob 2.514 (2.514)	GS 28.109 (28.109)	mem 43.096
Train: [12][455/750]	BT 0.044 (1.178)	DT 0.002 (1.137)	loss 7.994 (7.994)	prob 2.679 (2.679)	GS 31.594 (31.594)	mem 43.096
Train: [12][460/750]	BT 3.427 (1.188)	DT 3.385 (1.147)	loss 8.751 (8.751)	prob 2.740 (2.740)	GS 31.781 (31.781)	mem 43.112
Train: [12][465/750]	BT 0.031 (1.177)	DT 0.002 (1.136)	loss 8.106 (8.106)	prob 3.756 (3.756)	GS 27.516 (27.516)	mem 43.050
Train: [12][470/750]	BT 7.624 (1.181)	DT 7.582 (1.140)	loss 9.187 (9.187)	prob 2.520 (2.520)	GS 33.547 (33.547)	mem 43.084
Train: [12][475/750]	BT 0.072 (1.182)	DT 0.027 (1.140)	loss 8.104 (8.104)	prob 3.097 (3.097)	GS 36.828 (36.828)	mem 43.087
Train: [12][480/750]	BT 0.032 (1.174)	DT 0.001 (1.133)	loss 9.873 (9.873)	prob 2.151 (2.151)	GS 34.266 (34.266)	mem 43.022
Train: [12][485/750]	BT 0.033 (1.187)	DT 0.001 (1.146)	loss 8.610 (8.610)	prob 1.052 (1.052)	GS 36.375 (36.375)	mem 43.087
Train: [12][490/750]	BT 0.051 (1.176)	DT 0.002 (1.134)	loss 8.097 (8.097)	prob 2.759 (2.759)	GS 36.172 (36.172)	mem 43.088
Train: [12][495/750]	BT 0.043 (1.175)	DT 0.001 (1.134)	loss 8.483 (8.483)	prob 2.684 (2.684)	GS 30.719 (30.719)	mem 43.093
Train: [12][500/750]	BT 0.040 (1.179)	DT 0.001 (1.137)	loss 8.473 (8.473)	prob 2.204 (2.204)	GS 32.891 (32.891)	mem 43.091
Train: [12][505/750]	BT 0.041 (1.167)	DT 0.002 (1.126)	loss 8.494 (8.494)	prob 2.974 (2.974)	GS 29.344 (29.344)	mem 43.095
Train: [12][510/750]	BT 0.032 (1.183)	DT 0.001 (1.142)	loss 9.346 (9.346)	prob 2.435 (2.435)	GS 34.641 (34.641)	mem 43.145
Train: [12][515/750]	BT 0.060 (1.172)	DT 0.018 (1.131)	loss 9.610 (9.610)	prob 1.905 (1.905)	GS 35.219 (35.219)	mem 43.119
Train: [12][520/750]	BT 6.837 (1.185)	DT 6.809 (1.144)	loss 8.274 (8.274)	prob 2.902 (2.902)	GS 34.969 (34.969)	mem 43.147
Train: [12][525/750]	BT 0.058 (1.174)	DT 0.014 (1.133)	loss 8.545 (8.545)	prob 2.448 (2.448)	GS 31.594 (31.594)	mem 43.287
Train: [12][530/750]	BT 5.863 (1.175)	DT 5.832 (1.133)	loss 8.315 (8.315)	prob 3.714 (3.714)	GS 32.875 (32.875)	mem 43.053
Train: [12][535/750]	BT 0.111 (1.172)	DT 0.004 (1.130)	loss 8.732 (8.732)	prob 2.947 (2.947)	GS 30.922 (30.922)	mem 43.118
Train: [12][540/750]	BT 0.030 (1.161)	DT 0.002 (1.120)	loss 7.992 (7.992)	prob 3.085 (3.085)	GS 32.188 (32.188)	mem 43.088
Train: [12][545/750]	BT 0.033 (1.175)	DT 0.002 (1.133)	loss 8.149 (8.149)	prob 2.804 (2.804)	GS 33.766 (33.766)	mem 43.026
Train: [12][550/750]	BT 0.036 (1.164)	DT 0.001 (1.123)	loss 8.150 (8.150)	prob 3.665 (3.665)	GS 30.562 (30.562)	mem 43.346
Train: [12][555/750]	BT 0.033 (1.170)	DT 0.002 (1.129)	loss 7.853 (7.853)	prob 3.016 (3.016)	GS 31.578 (31.578)	mem 43.152
Train: [12][560/750]	BT 0.050 (1.170)	DT 0.001 (1.128)	loss 8.437 (8.437)	prob 2.773 (2.773)	GS 31.781 (31.781)	mem 43.067
Train: [12][565/750]	BT 0.042 (1.160)	DT 0.009 (1.118)	loss 8.506 (8.506)	prob 3.468 (3.468)	GS 33.078 (33.078)	mem 43.292
Train: [12][570/750]	BT 0.028 (1.174)	DT 0.001 (1.133)	loss 8.458 (8.458)	prob 3.601 (3.601)	GS 32.094 (32.094)	mem 43.139
Train: [12][575/750]	BT 0.035 (1.164)	DT 0.002 (1.123)	loss 8.098 (8.098)	prob 3.655 (3.655)	GS 28.812 (28.812)	mem 43.508
Train: [12][580/750]	BT 5.197 (1.177)	DT 5.156 (1.136)	loss 8.582 (8.582)	prob 3.674 (3.674)	GS 30.219 (30.219)	mem 42.872
Train: [12][585/750]	BT 0.070 (1.167)	DT 0.021 (1.126)	loss 8.886 (8.886)	prob 1.727 (1.727)	GS 29.453 (29.453)	mem 42.873
Train: [12][590/750]	BT 7.227 (1.170)	DT 7.195 (1.129)	loss 8.226 (8.226)	prob 3.875 (3.875)	GS 34.219 (34.219)	mem 42.928
Train: [12][595/750]	BT 0.035 (1.173)	DT 0.012 (1.132)	loss 8.191 (8.191)	prob 3.956 (3.956)	GS 33.531 (33.531)	mem 42.916
Train: [12][600/750]	BT 0.032 (1.164)	DT 0.007 (1.123)	loss 8.521 (8.521)	prob 3.603 (3.603)	GS 34.328 (34.328)	mem 42.903
Train: [12][605/750]	BT 0.029 (1.177)	DT 0.001 (1.136)	loss 8.355 (8.355)	prob 2.870 (2.870)	GS 34.250 (34.250)	mem 43.018
Train: [12][610/750]	BT 0.064 (1.168)	DT 0.010 (1.126)	loss 8.379 (8.379)	prob 3.271 (3.271)	GS 34.922 (34.922)	mem 42.968
Train: [12][615/750]	BT 0.031 (1.164)	DT 0.002 (1.122)	loss 8.380 (8.380)	prob 4.248 (4.248)	GS 37.828 (37.828)	mem 42.979
Train: [12][620/750]	BT 0.062 (1.172)	DT 0.003 (1.130)	loss 9.175 (9.175)	prob 2.675 (2.675)	GS 36.781 (36.781)	mem 43.226
Train: [12][625/750]	BT 0.033 (1.163)	DT 0.001 (1.121)	loss 8.281 (8.281)	prob 3.202 (3.202)	GS 32.125 (32.125)	mem 43.004
Train: [12][630/750]	BT 0.045 (1.174)	DT 0.005 (1.132)	loss 8.518 (8.518)	prob 3.387 (3.387)	GS 31.219 (31.219)	mem 43.064
Train: [12][635/750]	BT 0.025 (1.165)	DT 0.001 (1.123)	loss 9.112 (9.112)	prob 1.793 (1.793)	GS 30.422 (30.422)	mem 43.066
Train: [12][640/750]	BT 6.289 (1.176)	DT 6.245 (1.134)	loss 9.085 (9.085)	prob 3.824 (3.824)	GS 34.094 (34.094)	mem 43.065
Train: [12][645/750]	BT 0.029 (1.168)	DT 0.001 (1.127)	loss 8.776 (8.776)	prob 2.417 (2.417)	GS 28.750 (28.750)	mem 43.018
Train: [12][650/750]	BT 9.241 (1.174)	DT 9.204 (1.133)	loss 8.696 (8.696)	prob 3.520 (3.520)	GS 36.000 (36.000)	mem 43.022
Train: [12][655/750]	BT 0.040 (1.165)	DT 0.001 (1.124)	loss 8.034 (8.034)	prob 3.735 (3.735)	GS 30.297 (30.297)	mem 43.024
Train: [12][660/750]	BT 0.036 (1.163)	DT 0.012 (1.121)	loss 8.417 (8.417)	prob 3.768 (3.768)	GS 30.344 (30.344)	mem 43.055
Train: [12][665/750]	BT 0.021 (1.172)	DT 0.001 (1.130)	loss 7.788 (7.788)	prob 3.766 (3.766)	GS 30.375 (30.375)	mem 42.964
Train: [12][670/750]	BT 0.032 (1.166)	DT 0.002 (1.125)	loss 9.074 (9.074)	prob 3.354 (3.354)	GS 31.250 (31.250)	mem 42.925
Train: [12][675/750]	BT 0.031 (1.171)	DT 0.001 (1.130)	loss 7.879 (7.879)	prob 4.287 (4.287)	GS 30.266 (30.266)	mem 43.070
Train: [12][680/750]	BT 4.752 (1.169)	DT 4.719 (1.128)	loss 8.147 (8.147)	prob 4.147 (4.147)	GS 32.500 (32.500)	mem 43.091
Train: [12][685/750]	BT 0.075 (1.161)	DT 0.003 (1.120)	loss 8.045 (8.045)	prob 2.992 (2.992)	GS 27.797 (27.797)	mem 43.111
Train: [12][690/750]	BT 0.033 (1.165)	DT 0.001 (1.124)	loss 8.041 (8.041)	prob 3.247 (3.247)	GS 34.859 (34.859)	mem 43.041
Train: [12][695/750]	BT 0.038 (1.162)	DT 0.002 (1.121)	loss 8.854 (8.854)	prob 3.061 (3.061)	GS 34.312 (34.312)	mem 42.992
Train: [12][700/750]	BT 0.055 (1.164)	DT 0.004 (1.122)	loss 8.193 (8.193)	prob 3.525 (3.525)	GS 35.141 (35.141)	mem 42.977
Train: [12][705/750]	BT 0.190 (1.165)	DT 0.062 (1.123)	loss 8.439 (8.439)	prob 3.185 (3.185)	GS 31.125 (31.125)	mem 43.020
Train: [12][710/750]	BT 8.001 (1.168)	DT 7.972 (1.127)	loss 7.689 (7.689)	prob 4.908 (4.908)	GS 37.156 (37.156)	mem 43.151
Train: [12][715/750]	BT 0.032 (1.160)	DT 0.003 (1.119)	loss 8.381 (8.381)	prob 2.982 (2.982)	GS 31.172 (31.172)	mem 43.052
Train: [12][720/750]	BT 0.112 (1.156)	DT 0.001 (1.114)	loss 8.462 (8.462)	prob 3.870 (3.870)	GS 34.438 (34.438)	mem 43.125
Train: [12][725/750]	BT 0.032 (1.161)	DT 0.002 (1.120)	loss 7.999 (7.999)	prob 3.841 (3.841)	GS 24.891 (24.891)	mem 42.913
Train: [12][730/750]	BT 0.078 (1.161)	DT 0.001 (1.119)	loss 8.673 (8.673)	prob 3.634 (3.634)	GS 34.969 (34.969)	mem 42.717
Train: [12][735/750]	BT 0.033 (1.157)	DT 0.002 (1.116)	loss 8.927 (8.927)	prob 2.286 (2.286)	GS 32.922 (32.922)	mem 39.891
Train: [12][740/750]	BT 2.862 (1.156)	DT 2.804 (1.115)	loss 8.974 (8.974)	prob 2.838 (2.838)	GS 33.766 (33.766)	mem 16.649
Train: [12][745/750]	BT 0.031 (1.149)	DT 0.003 (1.108)	loss 7.857 (7.857)	prob 3.734 (3.734)	GS 33.438 (33.438)	mem 16.649
Train: [12][750/750]	BT 0.028 (1.142)	DT 0.001 (1.100)	loss 8.384 (8.384)	prob 3.867 (3.867)	GS 31.281 (31.281)	mem 16.613
Train: [12][755/750]	BT 0.020 (1.139)	DT 0.001 (1.098)	loss 8.368 (8.368)	prob 2.920 (2.920)	GS 27.250 (27.250)	mem 10.668
epoch 12, total time 860.04
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [13][1/750]	BT 23.336 (23.336)	DT 23.284 (23.284)	loss 8.355 (8.355)	prob 4.011 (4.011)	GS 34.672 (34.672)	mem 41.750
Train: [13][5/750]	BT 0.040 (4.727)	DT 0.002 (4.679)	loss 8.354 (8.354)	prob 3.261 (3.261)	GS 34.438 (34.438)	mem 41.713
Train: [13][10/750]	BT 0.845 (2.481)	DT 0.801 (2.436)	loss 7.587 (7.587)	prob 4.281 (4.281)	GS 34.812 (34.812)	mem 41.668
Train: [13][15/750]	BT 0.047 (2.646)	DT 0.001 (2.601)	loss 8.849 (8.849)	prob 2.214 (2.214)	GS 26.625 (26.625)	mem 41.931
Train: [13][20/750]	BT 0.044 (1.997)	DT 0.013 (1.953)	loss 8.251 (8.251)	prob 3.931 (3.931)	GS 34.625 (34.625)	mem 41.906
Train: [13][25/750]	BT 2.823 (1.721)	DT 2.776 (1.675)	loss 8.205 (8.205)	prob 3.872 (3.872)	GS 31.016 (31.016)	mem 42.028
Train: [13][30/750]	BT 0.051 (1.770)	DT 0.001 (1.725)	loss 8.235 (8.235)	prob 3.835 (3.835)	GS 30.328 (30.328)	mem 42.049
Train: [13][35/750]	BT 0.047 (1.523)	DT 0.006 (1.479)	loss 7.852 (7.852)	prob 3.826 (3.826)	GS 34.016 (34.016)	mem 42.081
Train: [13][40/750]	BT 0.025 (1.684)	DT 0.002 (1.638)	loss 9.336 (9.336)	prob 3.399 (3.399)	GS 35.344 (35.344)	mem 42.046
Train: [13][45/750]	BT 0.030 (1.501)	DT 0.001 (1.456)	loss 7.781 (7.781)	prob 3.839 (3.839)	GS 32.234 (32.234)	mem 42.049
Train: [13][50/750]	BT 12.440 (1.603)	DT 12.382 (1.558)	loss 7.934 (7.934)	prob 4.166 (4.166)	GS 35.000 (35.000)	mem 42.191
Train: [13][55/750]	BT 0.025 (1.462)	DT 0.001 (1.417)	loss 8.139 (8.139)	prob 3.748 (3.748)	GS 31.750 (31.750)	mem 42.122
Train: [13][60/750]	BT 0.096 (1.344)	DT 0.006 (1.299)	loss 8.311 (8.311)	prob 4.123 (4.123)	GS 36.188 (36.188)	mem 42.209
Train: [13][65/750]	BT 0.062 (1.496)	DT 0.015 (1.451)	loss 8.298 (8.298)	prob 3.870 (3.870)	GS 31.188 (31.188)	mem 42.114
Train: [13][70/750]	BT 0.066 (1.393)	DT 0.003 (1.348)	loss 8.399 (8.399)	prob 3.963 (3.963)	GS 35.125 (35.125)	mem 42.114
Train: [13][75/750]	BT 0.020 (1.511)	DT 0.001 (1.468)	loss 8.460 (8.460)	prob 2.813 (2.813)	GS 29.188 (29.188)	mem 42.084
Train: [13][80/750]	BT 0.034 (1.419)	DT 0.002 (1.376)	loss 8.505 (8.505)	prob 4.287 (4.287)	GS 38.125 (38.125)	mem 42.086
Train: [13][85/750]	BT 0.027 (1.337)	DT 0.001 (1.295)	loss 8.326 (8.326)	prob 3.199 (3.199)	GS 34.297 (34.297)	mem 42.086
Train: [13][90/750]	BT 0.028 (1.445)	DT 0.001 (1.404)	loss 8.448 (8.448)	prob 3.318 (3.318)	GS 36.781 (36.781)	mem 42.247
Train: [13][95/750]	BT 0.049 (1.372)	DT 0.003 (1.330)	loss 8.239 (8.239)	prob 2.763 (2.763)	GS 29.172 (29.172)	mem 42.215
Train: [13][100/750]	BT 0.070 (1.432)	DT 0.007 (1.389)	loss 8.859 (8.859)	prob 3.290 (3.290)	GS 33.141 (33.141)	mem 42.228
Train: [13][105/750]	BT 0.026 (1.365)	DT 0.001 (1.323)	loss 7.653 (7.653)	prob 3.089 (3.089)	GS 33.969 (33.969)	mem 42.229
Train: [13][110/750]	BT 10.957 (1.405)	DT 10.914 (1.362)	loss 8.817 (8.817)	prob 2.916 (2.916)	GS 36.703 (36.703)	mem 42.196
Train: [13][115/750]	BT 0.050 (1.346)	DT 0.002 (1.304)	loss 8.171 (8.171)	prob 3.066 (3.066)	GS 35.469 (35.469)	mem 42.197
Train: [13][120/750]	BT 0.103 (1.293)	DT 0.016 (1.250)	loss 8.577 (8.577)	prob 3.825 (3.825)	GS 37.812 (37.812)	mem 42.197
Train: [13][125/750]	BT 0.025 (1.360)	DT 0.001 (1.317)	loss 7.989 (7.989)	prob 4.269 (4.269)	GS 32.328 (32.328)	mem 42.268
Train: [13][130/750]	BT 0.084 (1.310)	DT 0.002 (1.267)	loss 8.437 (8.437)	prob 3.411 (3.411)	GS 33.578 (33.578)	mem 42.307
Train: [13][135/750]	BT 0.039 (1.353)	DT 0.001 (1.310)	loss 8.124 (8.124)	prob 3.566 (3.566)	GS 32.922 (32.922)	mem 42.357
Train: [13][140/750]	BT 0.066 (1.307)	DT 0.013 (1.263)	loss 8.203 (8.203)	prob 3.609 (3.609)	GS 31.250 (31.250)	mem 42.514
Train: [13][145/750]	BT 0.086 (1.264)	DT 0.008 (1.220)	loss 7.905 (7.905)	prob 3.922 (3.922)	GS 32.875 (32.875)	mem 42.327
Train: [13][150/750]	BT 0.033 (1.311)	DT 0.002 (1.267)	loss 8.148 (8.148)	prob 4.309 (4.309)	GS 34.859 (34.859)	mem 42.256
Train: [13][155/750]	BT 0.084 (1.270)	DT 0.002 (1.226)	loss 8.178 (8.178)	prob 3.886 (3.886)	GS 32.359 (32.359)	mem 42.322
Train: [13][160/750]	BT 0.037 (1.301)	DT 0.004 (1.257)	loss 7.781 (7.781)	prob 3.980 (3.980)	GS 33.188 (33.188)	mem 42.417
Train: [13][165/750]	BT 0.073 (1.263)	DT 0.010 (1.219)	loss 8.093 (8.093)	prob 2.935 (2.935)	GS 32.469 (32.469)	mem 42.349
Train: [13][170/750]	BT 12.151 (1.299)	DT 12.069 (1.255)	loss 8.160 (8.160)	prob 4.801 (4.801)	GS 29.281 (29.281)	mem 42.308
Train: [13][175/750]	BT 0.034 (1.263)	DT 0.003 (1.219)	loss 7.952 (7.952)	prob 4.133 (4.133)	GS 32.188 (32.188)	mem 42.309
Train: [13][180/750]	BT 0.044 (1.229)	DT 0.004 (1.185)	loss 8.066 (8.066)	prob 4.716 (4.716)	GS 36.953 (36.953)	mem 42.320
Train: [13][185/750]	BT 0.077 (1.255)	DT 0.004 (1.211)	loss 7.693 (7.693)	prob 4.039 (4.039)	GS 26.109 (26.109)	mem 42.757
Train: [13][190/750]	BT 0.049 (1.224)	DT 0.002 (1.179)	loss 7.802 (7.802)	prob 3.239 (3.239)	GS 35.422 (35.422)	mem 42.675
Train: [13][195/750]	BT 0.023 (1.286)	DT 0.001 (1.242)	loss 8.321 (8.321)	prob 2.185 (2.185)	GS 32.406 (32.406)	mem 42.588
Train: [13][200/750]	BT 0.051 (1.255)	DT 0.002 (1.211)	loss 7.980 (7.980)	prob 3.563 (3.563)	GS 30.422 (30.422)	mem 42.597
Train: [13][205/750]	BT 0.040 (1.226)	DT 0.002 (1.182)	loss 8.138 (8.138)	prob 3.067 (3.067)	GS 30.797 (30.797)	mem 42.598
Train: [13][210/750]	BT 0.034 (1.263)	DT 0.001 (1.219)	loss 7.856 (7.856)	prob 4.019 (4.019)	GS 33.375 (33.375)	mem 42.773
Train: [13][215/750]	BT 0.032 (1.234)	DT 0.002 (1.190)	loss 7.915 (7.915)	prob 3.519 (3.519)	GS 30.703 (30.703)	mem 42.697
Train: [13][220/750]	BT 0.066 (1.274)	DT 0.005 (1.230)	loss 8.258 (8.258)	prob 3.484 (3.484)	GS 39.188 (39.188)	mem 42.642
Train: [13][225/750]	BT 0.025 (1.246)	DT 0.001 (1.202)	loss 8.102 (8.102)	prob 3.178 (3.178)	GS 34.359 (34.359)	mem 42.580
Train: [13][230/750]	BT 11.313 (1.270)	DT 11.282 (1.225)	loss 7.787 (7.787)	prob 3.167 (3.167)	GS 29.406 (29.406)	mem 42.743
Train: [13][235/750]	BT 0.024 (1.243)	DT 0.001 (1.199)	loss 7.948 (7.948)	prob 3.136 (3.136)	GS 33.844 (33.844)	mem 42.744
Train: [13][240/750]	BT 0.100 (1.219)	DT 0.003 (1.175)	loss 7.856 (7.856)	prob 3.565 (3.565)	GS 32.969 (32.969)	mem 42.890
Train: [13][245/750]	BT 0.026 (1.242)	DT 0.001 (1.198)	loss 8.098 (8.098)	prob 2.972 (2.972)	GS 33.969 (33.969)	mem 42.765
Train: [13][250/750]	BT 0.049 (1.219)	DT 0.002 (1.174)	loss 7.928 (7.928)	prob 3.983 (3.983)	GS 34.734 (34.734)	mem 42.734
Train: [13][255/750]	BT 0.061 (1.241)	DT 0.011 (1.196)	loss 7.448 (7.448)	prob 3.316 (3.316)	GS 31.734 (31.734)	mem 42.879
Train: [13][260/750]	BT 0.081 (1.218)	DT 0.002 (1.173)	loss 8.070 (8.070)	prob 3.619 (3.619)	GS 37.469 (37.469)	mem 43.006
Train: [13][265/750]	BT 0.087 (1.196)	DT 0.007 (1.151)	loss 8.035 (8.035)	prob 2.888 (2.888)	GS 27.516 (27.516)	mem 42.915
Train: [13][270/750]	BT 0.048 (1.227)	DT 0.010 (1.182)	loss 8.211 (8.211)	prob 2.802 (2.802)	GS 34.406 (34.406)	mem 42.906
Train: [13][275/750]	BT 0.124 (1.205)	DT 0.025 (1.161)	loss 8.157 (8.157)	prob 2.784 (2.784)	GS 30.734 (30.734)	mem 42.907
Train: [13][280/750]	BT 0.024 (1.219)	DT 0.001 (1.175)	loss 8.416 (8.416)	prob 2.959 (2.959)	GS 33.875 (33.875)	mem 43.084
Train: [13][285/750]	BT 0.025 (1.199)	DT 0.001 (1.154)	loss 7.602 (7.602)	prob 3.610 (3.610)	GS 28.219 (28.219)	mem 42.886
Train: [13][290/750]	BT 12.325 (1.221)	DT 12.280 (1.177)	loss 7.956 (7.956)	prob 3.019 (3.019)	GS 31.328 (31.328)	mem 42.946
Train: [13][295/750]	BT 0.062 (1.201)	DT 0.020 (1.157)	loss 8.873 (8.873)	prob 1.252 (1.252)	GS 28.484 (28.484)	mem 42.948
Train: [13][300/750]	BT 0.068 (1.182)	DT 0.019 (1.138)	loss 8.999 (8.999)	prob 2.693 (2.693)	GS 31.984 (31.984)	mem 42.993
Train: [13][305/750]	BT 0.033 (1.202)	DT 0.002 (1.158)	loss 8.011 (8.011)	prob 2.168 (2.168)	GS 34.547 (34.547)	mem 42.992
Train: [13][310/750]	BT 0.052 (1.184)	DT 0.015 (1.139)	loss 7.750 (7.750)	prob 2.893 (2.893)	GS 34.734 (34.734)	mem 42.993
Train: [13][315/750]	BT 0.051 (1.208)	DT 0.013 (1.163)	loss 7.753 (7.753)	prob 2.495 (2.495)	GS 31.672 (31.672)	mem 43.027
Train: [13][320/750]	BT 1.639 (1.196)	DT 1.606 (1.151)	loss 7.880 (7.880)	prob 2.366 (2.366)	GS 33.328 (33.328)	mem 42.904
Train: [13][325/750]	BT 0.078 (1.178)	DT 0.001 (1.133)	loss 7.826 (7.826)	prob 2.658 (2.658)	GS 34.359 (34.359)	mem 43.129
Train: [13][330/750]	BT 5.135 (1.201)	DT 5.098 (1.156)	loss 8.151 (8.151)	prob 2.708 (2.708)	GS 34.859 (34.859)	mem 43.006
Train: [13][335/750]	BT 0.033 (1.184)	DT 0.002 (1.139)	loss 8.207 (8.207)	prob 2.161 (2.161)	GS 29.297 (29.297)	mem 42.963
Train: [13][340/750]	BT 0.024 (1.189)	DT 0.001 (1.144)	loss 8.007 (8.007)	prob 2.112 (2.112)	GS 32.797 (32.797)	mem 42.978
Train: [13][345/750]	BT 0.071 (1.188)	DT 0.001 (1.143)	loss 8.302 (8.302)	prob 1.361 (1.361)	GS 29.500 (29.500)	mem 42.986
Train: [13][350/750]	BT 9.999 (1.200)	DT 9.941 (1.155)	loss 8.282 (8.282)	prob 2.387 (2.387)	GS 29.969 (29.969)	mem 43.034
Train: [13][355/750]	BT 0.033 (1.186)	DT 0.002 (1.142)	loss 8.139 (8.139)	prob 1.395 (1.395)	GS 31.594 (31.594)	mem 43.005
Train: [13][360/750]	BT 0.052 (1.170)	DT 0.004 (1.126)	loss 9.062 (9.062)	prob 1.788 (1.788)	GS 29.891 (29.891)	mem 43.003
Train: [13][365/750]	BT 0.060 (1.185)	DT 0.008 (1.141)	loss 8.035 (8.035)	prob 2.323 (2.323)	GS 30.219 (30.219)	mem 43.125
Train: [13][370/750]	BT 0.063 (1.174)	DT 0.002 (1.129)	loss 7.596 (7.596)	prob 2.454 (2.454)	GS 35.469 (35.469)	mem 43.000
Train: [13][375/750]	BT 0.042 (1.185)	DT 0.009 (1.140)	loss 7.917 (7.917)	prob 1.331 (1.331)	GS 32.219 (32.219)	mem 43.076
Train: [13][380/750]	BT 0.045 (1.178)	DT 0.002 (1.134)	loss 8.063 (8.063)	prob 2.775 (2.775)	GS 33.250 (33.250)	mem 42.993
Train: [13][385/750]	BT 0.126 (1.163)	DT 0.002 (1.119)	loss 7.973 (7.973)	prob 1.667 (1.667)	GS 30.953 (30.953)	mem 42.993
Train: [13][390/750]	BT 3.903 (1.183)	DT 3.871 (1.139)	loss 9.402 (9.402)	prob 1.068 (1.068)	GS 31.828 (31.828)	mem 43.065
Train: [13][395/750]	BT 0.034 (1.169)	DT 0.003 (1.125)	loss 9.532 (9.532)	prob 0.842 (0.842)	GS 31.344 (31.344)	mem 43.013
Train: [13][400/750]	BT 0.033 (1.173)	DT 0.002 (1.129)	loss 7.904 (7.904)	prob 2.551 (2.551)	GS 30.516 (30.516)	mem 42.987
Train: [13][405/750]	BT 0.084 (1.179)	DT 0.004 (1.134)	loss 7.684 (7.684)	prob 2.731 (2.731)	GS 28.125 (28.125)	mem 43.038
Train: [13][410/750]	BT 2.399 (1.171)	DT 2.358 (1.126)	loss 8.416 (8.416)	prob 1.991 (1.991)	GS 29.828 (29.828)	mem 43.035
Train: [13][415/750]	BT 0.045 (1.178)	DT 0.013 (1.134)	loss 8.407 (8.407)	prob 1.508 (1.508)	GS 36.719 (36.719)	mem 43.010
Train: [13][420/750]	BT 0.029 (1.165)	DT 0.001 (1.120)	loss 8.361 (8.361)	prob 1.795 (1.795)	GS 34.312 (34.312)	mem 43.010
Train: [13][425/750]	BT 0.050 (1.157)	DT 0.005 (1.113)	loss 8.317 (8.317)	prob 1.223 (1.223)	GS 28.500 (28.500)	mem 43.196
Train: [13][430/750]	BT 0.056 (1.171)	DT 0.011 (1.126)	loss 8.604 (8.604)	prob 2.355 (2.355)	GS 34.297 (34.297)	mem 42.952
Train: [13][435/750]	BT 0.051 (1.162)	DT 0.017 (1.118)	loss 8.324 (8.324)	prob 2.387 (2.387)	GS 29.031 (29.031)	mem 42.939
Train: [13][440/750]	BT 0.029 (1.167)	DT 0.001 (1.123)	loss 8.092 (8.092)	prob 2.726 (2.726)	GS 27.969 (27.969)	mem 42.972
Train: [13][445/750]	BT 0.088 (1.155)	DT 0.001 (1.111)	loss 8.444 (8.444)	prob 0.851 (0.851)	GS 32.688 (32.688)	mem 43.094
Train: [13][450/750]	BT 7.359 (1.165)	DT 7.293 (1.121)	loss 8.418 (8.418)	prob 1.863 (1.863)	GS 32.016 (32.016)	mem 43.187
Train: [13][455/750]	BT 0.027 (1.153)	DT 0.001 (1.108)	loss 7.541 (7.541)	prob 2.793 (2.793)	GS 25.828 (25.828)	mem 42.978
Train: [13][460/750]	BT 0.129 (1.154)	DT 0.007 (1.109)	loss 8.164 (8.164)	prob 2.479 (2.479)	GS 34.672 (34.672)	mem 43.054
Train: [13][465/750]	BT 0.031 (1.152)	DT 0.001 (1.107)	loss 8.751 (8.751)	prob 1.601 (1.601)	GS 29.531 (29.531)	mem 42.967
Train: [13][470/750]	BT 8.950 (1.159)	DT 8.866 (1.114)	loss 7.658 (7.658)	prob 3.567 (3.567)	GS 29.266 (29.266)	mem 43.097
Train: [13][475/750]	BT 0.056 (1.156)	DT 0.002 (1.111)	loss 8.095 (8.095)	prob 2.304 (2.304)	GS 30.391 (30.391)	mem 43.004
Train: [13][480/750]	BT 0.030 (1.144)	DT 0.001 (1.099)	loss 8.439 (8.439)	prob 2.822 (2.822)	GS 33.312 (33.312)	mem 43.009
Train: [13][485/750]	BT 0.061 (1.152)	DT 0.014 (1.107)	loss 7.965 (7.965)	prob 1.912 (1.912)	GS 30.484 (30.484)	mem 43.172
Train: [13][490/750]	BT 0.048 (1.147)	DT 0.002 (1.102)	loss 8.269 (8.269)	prob 2.207 (2.207)	GS 35.844 (35.844)	mem 42.949
Train: [13][495/750]	BT 0.035 (1.157)	DT 0.003 (1.112)	loss 8.306 (8.306)	prob 1.200 (1.200)	GS 31.562 (31.562)	mem 43.080
Train: [13][500/750]	BT 0.043 (1.150)	DT 0.001 (1.105)	loss 8.016 (8.016)	prob 3.379 (3.379)	GS 36.047 (36.047)	mem 42.923
Train: [13][505/750]	BT 0.049 (1.139)	DT 0.001 (1.094)	loss 8.374 (8.374)	prob 2.457 (2.457)	GS 31.688 (31.688)	mem 42.916
Train: [13][510/750]	BT 3.579 (1.157)	DT 3.491 (1.112)	loss 8.913 (8.913)	prob 2.442 (2.442)	GS 35.078 (35.078)	mem 43.045
Train: [13][515/750]	BT 0.057 (1.146)	DT 0.010 (1.101)	loss 7.843 (7.843)	prob 2.814 (2.814)	GS 28.969 (28.969)	mem 43.045
Train: [13][520/750]	BT 0.049 (1.153)	DT 0.008 (1.108)	loss 8.744 (8.744)	prob 1.305 (1.305)	GS 38.734 (38.734)	mem 43.126
Train: [13][525/750]	BT 0.027 (1.159)	DT 0.001 (1.114)	loss 7.799 (7.799)	prob 2.817 (2.817)	GS 32.750 (32.750)	mem 42.920
Train: [13][530/750]	BT 5.393 (1.159)	DT 5.360 (1.114)	loss 8.662 (8.662)	prob 3.654 (3.654)	GS 33.828 (33.828)	mem 42.946
Train: [13][535/750]	BT 0.046 (1.163)	DT 0.007 (1.118)	loss 7.824 (7.824)	prob 2.471 (2.471)	GS 33.672 (33.672)	mem 42.925
Train: [13][540/750]	BT 0.030 (1.153)	DT 0.001 (1.108)	loss 9.039 (9.039)	prob 2.470 (2.470)	GS 34.688 (34.688)	mem 42.927
Train: [13][545/750]	BT 0.034 (1.147)	DT 0.003 (1.102)	loss 8.636 (8.636)	prob 2.912 (2.912)	GS 32.453 (32.453)	mem 42.983
Train: [13][550/750]	BT 0.096 (1.155)	DT 0.001 (1.110)	loss 8.273 (8.273)	prob 3.747 (3.747)	GS 32.328 (32.328)	mem 43.012
Train: [13][555/750]	BT 0.033 (1.153)	DT 0.002 (1.108)	loss 8.383 (8.383)	prob 2.117 (2.117)	GS 29.391 (29.391)	mem 42.921
Train: [13][560/750]	BT 0.032 (1.163)	DT 0.003 (1.118)	loss 8.595 (8.595)	prob 2.916 (2.916)	GS 32.484 (32.484)	mem 42.914
Train: [13][565/750]	BT 0.122 (1.154)	DT 0.018 (1.109)	loss 7.600 (7.600)	prob 3.560 (3.560)	GS 29.219 (29.219)	mem 42.913
Train: [13][570/750]	BT 12.895 (1.168)	DT 12.863 (1.123)	loss 8.524 (8.524)	prob 2.182 (2.182)	GS 37.234 (37.234)	mem 43.007
Train: [13][575/750]	BT 0.053 (1.158)	DT 0.002 (1.113)	loss 8.033 (8.033)	prob 2.482 (2.482)	GS 37.141 (37.141)	mem 43.024
Train: [13][580/750]	BT 0.040 (1.150)	DT 0.002 (1.105)	loss 8.702 (8.702)	prob 2.841 (2.841)	GS 35.156 (35.156)	mem 43.052
Train: [13][585/750]	BT 0.025 (1.159)	DT 0.001 (1.114)	loss 8.937 (8.937)	prob 2.013 (2.013)	GS 35.031 (35.031)	mem 42.985
Train: [13][590/750]	BT 2.659 (1.154)	DT 2.625 (1.109)	loss 8.239 (8.239)	prob 3.025 (3.025)	GS 37.000 (37.000)	mem 42.956
Train: [13][595/750]	BT 0.034 (1.161)	DT 0.002 (1.116)	loss 7.859 (7.859)	prob 2.776 (2.776)	GS 27.359 (27.359)	mem 43.031
Train: [13][600/750]	BT 0.032 (1.152)	DT 0.001 (1.107)	loss 8.864 (8.864)	prob 2.704 (2.704)	GS 37.469 (37.469)	mem 43.006
Train: [13][605/750]	BT 0.092 (1.149)	DT 0.024 (1.104)	loss 8.455 (8.455)	prob 2.585 (2.585)	GS 35.609 (35.609)	mem 43.000
Train: [13][610/750]	BT 0.051 (1.156)	DT 0.004 (1.111)	loss 8.321 (8.321)	prob 2.839 (2.839)	GS 34.281 (34.281)	mem 42.955
Train: [13][615/750]	BT 0.066 (1.151)	DT 0.007 (1.106)	loss 7.948 (7.948)	prob 2.469 (2.469)	GS 39.188 (39.188)	mem 43.076
Train: [13][620/750]	BT 7.070 (1.165)	DT 7.039 (1.120)	loss 9.123 (9.123)	prob 2.998 (2.998)	GS 35.109 (35.109)	mem 43.165
Train: [13][625/750]	BT 0.031 (1.156)	DT 0.001 (1.111)	loss 8.769 (8.769)	prob 2.522 (2.522)	GS 33.000 (33.000)	mem 43.167
Train: [13][630/750]	BT 4.404 (1.157)	DT 4.353 (1.112)	loss 8.415 (8.415)	prob 2.659 (2.659)	GS 33.266 (33.266)	mem 43.161
Train: [13][635/750]	BT 0.027 (1.156)	DT 0.001 (1.111)	loss 7.977 (7.977)	prob 3.622 (3.622)	GS 30.812 (30.812)	mem 43.037
Train: [13][640/750]	BT 0.054 (1.158)	DT 0.012 (1.113)	loss 8.497 (8.497)	prob 3.395 (3.395)	GS 30.141 (30.141)	mem 43.007
Train: [13][645/750]	BT 0.043 (1.153)	DT 0.002 (1.108)	loss 8.907 (8.907)	prob 2.615 (2.615)	GS 31.750 (31.750)	mem 43.064
Train: [13][650/750]	BT 10.681 (1.161)	DT 10.613 (1.116)	loss 8.564 (8.564)	prob 3.744 (3.744)	GS 32.203 (32.203)	mem 43.059
Train: [13][655/750]	BT 0.033 (1.153)	DT 0.004 (1.108)	loss 8.183 (8.183)	prob 3.472 (3.472)	GS 28.266 (28.266)	mem 43.063
arpack error, retry= 0
Train: [13][660/750]	BT 0.061 (1.148)	DT 0.013 (1.103)	loss 8.077 (8.077)	prob 3.506 (3.506)	GS 32.844 (32.844)	mem 42.946
Train: [13][665/750]	BT 0.060 (1.157)	DT 0.004 (1.112)	loss 9.155 (9.155)	prob 1.506 (1.506)	GS 32.531 (32.531)	mem 43.025
Train: [13][670/750]	BT 0.054 (1.152)	DT 0.001 (1.107)	loss 8.399 (8.399)	prob 3.176 (3.176)	GS 37.469 (37.469)	mem 42.994
Train: [13][675/750]	BT 0.085 (1.160)	DT 0.006 (1.114)	loss 8.709 (8.709)	prob 2.290 (2.290)	GS 37.875 (37.875)	mem 43.024
Train: [13][680/750]	BT 1.209 (1.153)	DT 1.177 (1.108)	loss 8.471 (8.471)	prob 3.346 (3.346)	GS 35.062 (35.062)	mem 43.033
Train: [13][685/750]	BT 0.045 (1.145)	DT 0.003 (1.100)	loss 9.193 (9.193)	prob 2.336 (2.336)	GS 30.625 (30.625)	mem 43.035
Train: [13][690/750]	BT 0.026 (1.155)	DT 0.001 (1.110)	loss 7.948 (7.948)	prob 2.507 (2.507)	GS 37.734 (37.734)	mem 42.970
Train: [13][695/750]	BT 0.042 (1.149)	DT 0.004 (1.104)	loss 8.642 (8.642)	prob 2.248 (2.248)	GS 34.344 (34.344)	mem 42.954
Train: [13][700/750]	BT 0.066 (1.160)	DT 0.002 (1.114)	loss 8.039 (8.039)	prob 3.098 (3.098)	GS 33.734 (33.734)	mem 43.019
Train: [13][705/750]	BT 0.078 (1.152)	DT 0.011 (1.106)	loss 8.620 (8.620)	prob 2.435 (2.435)	GS 29.594 (29.594)	mem 43.025
Train: [13][710/750]	BT 12.362 (1.161)	DT 12.321 (1.116)	loss 8.136 (8.136)	prob 3.326 (3.326)	GS 32.484 (32.484)	mem 43.241
Train: [13][715/750]	BT 0.057 (1.154)	DT 0.007 (1.108)	loss 8.388 (8.388)	prob 3.230 (3.230)	GS 31.688 (31.688)	mem 43.058
Train: [13][720/750]	BT 0.086 (1.146)	DT 0.005 (1.100)	loss 8.102 (8.102)	prob 3.977 (3.977)	GS 33.922 (33.922)	mem 43.133
Train: [13][725/750]	BT 0.039 (1.158)	DT 0.001 (1.113)	loss 8.847 (8.847)	prob 2.268 (2.268)	GS 29.016 (29.016)	mem 42.976
Train: [13][730/750]	BT 0.037 (1.151)	DT 0.005 (1.105)	loss 8.299 (8.299)	prob 3.775 (3.775)	GS 33.094 (33.094)	mem 42.859
Train: [13][735/750]	BT 0.040 (1.155)	DT 0.005 (1.109)	loss 8.063 (8.063)	prob 3.325 (3.325)	GS 36.062 (36.062)	mem 39.632
Train: [13][740/750]	BT 1.252 (1.149)	DT 1.217 (1.103)	loss 8.488 (8.488)	prob 3.860 (3.860)	GS 32.719 (32.719)	mem 13.734
Train: [13][745/750]	BT 0.029 (1.141)	DT 0.001 (1.096)	loss 8.143 (8.143)	prob 3.038 (3.038)	GS 31.938 (31.938)	mem 13.754
Train: [13][750/750]	BT 0.028 (1.137)	DT 0.001 (1.092)	loss 8.119 (8.119)	prob 3.438 (3.438)	GS 34.750 (34.750)	mem 10.732
Train: [13][755/750]	BT 0.027 (1.130)	DT 0.001 (1.084)	loss 8.227 (8.227)	prob 3.853 (3.853)	GS 30.062 (30.062)	mem 10.692
epoch 13, total time 853.18
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [14][1/750]	BT 21.319 (21.319)	DT 21.243 (21.243)	loss 8.058 (8.058)	prob 4.148 (4.148)	GS 32.344 (32.344)	mem 41.428
Train: [14][5/750]	BT 0.160 (5.371)	DT 0.120 (5.326)	loss 8.398 (8.398)	prob 2.763 (2.763)	GS 38.812 (38.812)	mem 41.720
Train: [14][10/750]	BT 0.073 (2.723)	DT 0.003 (2.668)	loss 8.439 (8.439)	prob 3.307 (3.307)	GS 33.547 (33.547)	mem 41.748
Train: [14][15/750]	BT 4.468 (2.720)	DT 4.435 (2.666)	loss 8.268 (8.268)	prob 2.739 (2.739)	GS 27.688 (27.688)	mem 41.963
Train: [14][20/750]	BT 0.044 (2.054)	DT 0.002 (2.000)	loss 7.732 (7.732)	prob 3.540 (3.540)	GS 33.359 (33.359)	mem 42.002
Train: [14][25/750]	BT 1.321 (1.709)	DT 1.290 (1.653)	loss 7.914 (7.914)	prob 3.225 (3.225)	GS 30.562 (30.562)	mem 42.006
Train: [14][30/750]	BT 1.908 (1.764)	DT 1.873 (1.711)	loss 7.760 (7.760)	prob 3.300 (3.300)	GS 28.484 (28.484)	mem 41.992
Train: [14][35/750]	BT 0.028 (1.517)	DT 0.001 (1.467)	loss 8.165 (8.165)	prob 3.280 (3.280)	GS 31.875 (31.875)	mem 41.988
Train: [14][40/750]	BT 0.307 (1.566)	DT 0.270 (1.519)	loss 8.308 (8.308)	prob 3.433 (3.433)	GS 34.531 (34.531)	mem 42.075
Train: [14][45/750]	BT 0.034 (1.489)	DT 0.002 (1.442)	loss 8.145 (8.145)	prob 3.763 (3.763)	GS 33.828 (33.828)	mem 42.082
Train: [14][50/750]	BT 5.948 (1.467)	DT 5.905 (1.417)	loss 7.925 (7.925)	prob 4.166 (4.166)	GS 30.547 (30.547)	mem 42.065
Train: [14][55/750]	BT 0.121 (1.466)	DT 0.016 (1.416)	loss 7.872 (7.872)	prob 3.636 (3.636)	GS 29.250 (29.250)	mem 42.126
Train: [14][60/750]	BT 0.069 (1.348)	DT 0.012 (1.298)	loss 7.719 (7.719)	prob 4.664 (4.664)	GS 32.750 (32.750)	mem 42.133
Train: [14][65/750]	BT 0.041 (1.446)	DT 0.001 (1.395)	loss 8.429 (8.429)	prob 2.937 (2.937)	GS 30.359 (30.359)	mem 42.221
Train: [14][70/750]	BT 0.902 (1.368)	DT 0.851 (1.317)	loss 9.083 (9.083)	prob 3.632 (3.632)	GS 34.422 (34.422)	mem 42.213
Train: [14][75/750]	BT 0.049 (1.338)	DT 0.005 (1.288)	loss 8.906 (8.906)	prob 2.341 (2.341)	GS 30.516 (30.516)	mem 42.172
Train: [14][80/750]	BT 0.051 (1.339)	DT 0.010 (1.289)	loss 7.993 (7.993)	prob 3.136 (3.136)	GS 34.781 (34.781)	mem 42.189
Train: [14][85/750]	BT 0.042 (1.267)	DT 0.002 (1.217)	loss 8.387 (8.387)	prob 2.690 (2.690)	GS 35.516 (35.516)	mem 42.190
Train: [14][90/750]	BT 1.723 (1.330)	DT 1.676 (1.278)	loss 7.937 (7.937)	prob 4.636 (4.636)	GS 32.719 (32.719)	mem 42.100
Train: [14][95/750]	BT 0.093 (1.290)	DT 0.009 (1.238)	loss 7.931 (7.931)	prob 3.027 (3.027)	GS 28.281 (28.281)	mem 42.330
Train: [14][100/750]	BT 0.068 (1.325)	DT 0.012 (1.273)	loss 8.086 (8.086)	prob 4.156 (4.156)	GS 32.953 (32.953)	mem 42.197
Train: [14][105/750]	BT 0.049 (1.280)	DT 0.001 (1.229)	loss 8.056 (8.056)	prob 3.194 (3.194)	GS 30.719 (30.719)	mem 42.020
Train: [14][110/750]	BT 11.468 (1.327)	DT 11.423 (1.277)	loss 8.320 (8.320)	prob 4.064 (4.064)	GS 39.500 (39.500)	mem 42.310
Train: [14][115/750]	BT 0.044 (1.272)	DT 0.011 (1.222)	loss 8.130 (8.130)	prob 3.222 (3.222)	GS 30.719 (30.719)	mem 42.249
Train: [14][120/750]	BT 0.072 (1.241)	DT 0.015 (1.191)	loss 8.134 (8.134)	prob 3.547 (3.547)	GS 32.812 (32.812)	mem 42.206
Train: [14][125/750]	BT 0.092 (1.287)	DT 0.013 (1.238)	loss 7.910 (7.910)	prob 3.424 (3.424)	GS 35.188 (35.188)	mem 42.198
Train: [14][130/750]	BT 3.543 (1.267)	DT 3.511 (1.217)	loss 8.716 (8.716)	prob 3.674 (3.674)	GS 33.078 (33.078)	mem 42.226
Train: [14][135/750]	BT 0.107 (1.270)	DT 0.005 (1.219)	loss 8.218 (8.218)	prob 3.510 (3.510)	GS 28.953 (28.953)	mem 42.143
Train: [14][140/750]	BT 0.029 (1.251)	DT 0.001 (1.201)	loss 8.201 (8.201)	prob 3.549 (3.549)	GS 37.953 (37.953)	mem 42.223
Train: [14][145/750]	BT 0.082 (1.229)	DT 0.001 (1.179)	loss 8.909 (8.909)	prob 2.346 (2.346)	GS 31.344 (31.344)	mem 42.382
Train: [14][150/750]	BT 3.878 (1.262)	DT 3.853 (1.212)	loss 7.795 (7.795)	prob 3.843 (3.843)	GS 31.625 (31.625)	mem 42.519
Train: [14][155/750]	BT 0.037 (1.231)	DT 0.001 (1.182)	loss 7.733 (7.733)	prob 3.571 (3.571)	GS 30.469 (30.469)	mem 42.604
Train: [14][160/750]	BT 5.122 (1.239)	DT 5.092 (1.190)	loss 8.199 (8.199)	prob 3.303 (3.303)	GS 36.031 (36.031)	mem 42.534
Train: [14][165/750]	BT 0.040 (1.216)	DT 0.004 (1.167)	loss 8.562 (8.562)	prob 2.202 (2.202)	GS 36.172 (36.172)	mem 42.467
Train: [14][170/750]	BT 0.032 (1.223)	DT 0.002 (1.174)	loss 7.679 (7.679)	prob 4.050 (4.050)	GS 30.078 (30.078)	mem 42.484
Train: [14][175/750]	BT 0.032 (1.211)	DT 0.001 (1.163)	loss 7.738 (7.738)	prob 4.330 (4.330)	GS 31.844 (31.844)	mem 42.464
Train: [14][180/750]	BT 0.049 (1.246)	DT 0.009 (1.198)	loss 8.163 (8.163)	prob 3.902 (3.902)	GS 31.984 (31.984)	mem 42.459
Train: [14][185/750]	BT 0.025 (1.214)	DT 0.001 (1.165)	loss 8.321 (8.321)	prob 2.956 (2.956)	GS 30.781 (30.781)	mem 42.459
Train: [14][190/750]	BT 5.876 (1.231)	DT 5.838 (1.183)	loss 7.744 (7.744)	prob 4.430 (4.430)	GS 33.312 (33.312)	mem 42.496
Train: [14][195/750]	BT 0.032 (1.200)	DT 0.002 (1.153)	loss 8.279 (8.279)	prob 2.319 (2.319)	GS 31.422 (31.422)	mem 42.496
Train: [14][200/750]	BT 0.032 (1.204)	DT 0.001 (1.157)	loss 8.016 (8.016)	prob 3.540 (3.540)	GS 34.828 (34.828)	mem 42.749
Train: [14][205/750]	BT 0.032 (1.191)	DT 0.002 (1.144)	loss 7.901 (7.901)	prob 2.851 (2.851)	GS 30.953 (30.953)	mem 42.823
Train: [14][210/750]	BT 10.639 (1.218)	DT 10.606 (1.172)	loss 8.501 (8.501)	prob 3.759 (3.759)	GS 35.219 (35.219)	mem 42.734
Train: [14][215/750]	BT 0.036 (1.192)	DT 0.001 (1.146)	loss 7.634 (7.634)	prob 3.395 (3.395)	GS 33.500 (33.500)	mem 42.700
Train: [14][220/750]	BT 2.238 (1.177)	DT 2.138 (1.130)	loss 9.064 (9.064)	prob 3.358 (3.358)	GS 34.406 (34.406)	mem 42.790
Train: [14][225/750]	BT 0.033 (1.195)	DT 0.002 (1.148)	loss 7.825 (7.825)	prob 2.492 (2.492)	GS 28.609 (28.609)	mem 42.746
Train: [14][230/750]	BT 0.897 (1.173)	DT 0.864 (1.127)	loss 8.244 (8.244)	prob 4.254 (4.254)	GS 32.844 (32.844)	mem 42.829
Train: [14][235/750]	BT 0.050 (1.199)	DT 0.010 (1.152)	loss 8.225 (8.225)	prob 2.890 (2.890)	GS 34.328 (34.328)	mem 42.971
Train: [14][240/750]	BT 0.066 (1.175)	DT 0.001 (1.128)	loss 8.714 (8.714)	prob 2.857 (2.857)	GS 33.734 (33.734)	mem 43.169
Train: [14][245/750]	BT 0.063 (1.175)	DT 0.014 (1.128)	loss 7.802 (7.802)	prob 2.813 (2.813)	GS 31.734 (31.734)	mem 42.919
Train: [14][250/750]	BT 0.057 (1.187)	DT 0.010 (1.140)	loss 8.289 (8.289)	prob 3.010 (3.010)	GS 33.234 (33.234)	mem 42.844
Train: [14][255/750]	BT 0.077 (1.170)	DT 0.003 (1.123)	loss 8.651 (8.651)	prob 2.210 (2.210)	GS 29.141 (29.141)	mem 42.780
Train: [14][260/750]	BT 0.032 (1.185)	DT 0.002 (1.137)	loss 7.991 (7.991)	prob 2.600 (2.600)	GS 33.844 (33.844)	mem 42.903
Train: [14][265/750]	BT 0.071 (1.188)	DT 0.017 (1.141)	loss 7.623 (7.623)	prob 2.166 (2.166)	GS 30.266 (30.266)	mem 42.878
Train: [14][270/750]	BT 5.337 (1.187)	DT 5.272 (1.140)	loss 8.578 (8.578)	prob 2.626 (2.626)	GS 32.422 (32.422)	mem 43.382
Train: [14][275/750]	BT 0.050 (1.166)	DT 0.002 (1.119)	loss 7.953 (7.953)	prob 2.849 (2.849)	GS 32.953 (32.953)	mem 43.384
Train: [14][280/750]	BT 0.033 (1.185)	DT 0.002 (1.138)	loss 7.478 (7.478)	prob 3.909 (3.909)	GS 32.391 (32.391)	mem 43.410
Train: [14][285/750]	BT 0.056 (1.188)	DT 0.025 (1.141)	loss 8.715 (8.715)	prob 1.698 (1.698)	GS 29.844 (29.844)	mem 43.393
Train: [14][290/750]	BT 0.053 (1.190)	DT 0.012 (1.143)	loss 8.449 (8.449)	prob 2.217 (2.217)	GS 35.672 (35.672)	mem 43.421
Train: [14][295/750]	BT 0.031 (1.205)	DT 0.003 (1.158)	loss 7.753 (7.753)	prob 1.569 (1.569)	GS 34.516 (34.516)	mem 43.312
Train: [14][300/750]	BT 0.877 (1.188)	DT 0.826 (1.141)	loss 7.753 (7.753)	prob 2.642 (2.642)	GS 33.328 (33.328)	mem 43.556
Train: [14][305/750]	BT 0.032 (1.169)	DT 0.001 (1.122)	loss 7.934 (7.934)	prob 1.679 (1.679)	GS 35.500 (35.500)	mem 43.354
Train: [14][310/750]	BT 0.037 (1.190)	DT 0.003 (1.144)	loss 8.328 (8.328)	prob 2.143 (2.143)	GS 32.703 (32.703)	mem 43.480
Train: [14][315/750]	BT 0.036 (1.172)	DT 0.001 (1.125)	loss 7.707 (7.707)	prob 3.096 (3.096)	GS 28.953 (28.953)	mem 43.482
Train: [14][320/750]	BT 0.115 (1.201)	DT 0.025 (1.155)	loss 8.065 (8.065)	prob 2.540 (2.540)	GS 32.719 (32.719)	mem 43.437
Train: [14][325/750]	BT 0.061 (1.184)	DT 0.002 (1.137)	loss 8.186 (8.186)	prob 1.931 (1.931)	GS 30.438 (30.438)	mem 43.437
Train: [14][330/750]	BT 10.828 (1.199)	DT 10.797 (1.152)	loss 8.324 (8.324)	prob 2.322 (2.322)	GS 34.672 (34.672)	mem 43.497
Train: [14][335/750]	BT 0.092 (1.182)	DT 0.009 (1.135)	loss 8.007 (8.007)	prob 1.948 (1.948)	GS 35.406 (35.406)	mem 43.513
Train: [14][340/750]	BT 0.103 (1.165)	DT 0.013 (1.119)	loss 8.645 (8.645)	prob 1.556 (1.556)	GS 31.297 (31.297)	mem 43.551
Train: [14][345/750]	BT 0.046 (1.183)	DT 0.001 (1.137)	loss 8.169 (8.169)	prob 2.073 (2.073)	GS 29.094 (29.094)	mem 42.896
Train: [14][350/750]	BT 0.054 (1.168)	DT 0.011 (1.121)	loss 7.478 (7.478)	prob 2.901 (2.901)	GS 27.422 (27.422)	mem 42.898
Train: [14][355/750]	BT 0.031 (1.188)	DT 0.001 (1.141)	loss 8.026 (8.026)	prob 1.385 (1.385)	GS 32.078 (32.078)	mem 42.878
Train: [14][360/750]	BT 0.050 (1.172)	DT 0.004 (1.126)	loss 8.013 (8.013)	prob 2.436 (2.436)	GS 36.688 (36.688)	mem 42.887
Train: [14][365/750]	BT 0.057 (1.157)	DT 0.010 (1.110)	loss 8.504 (8.504)	prob 0.818 (0.818)	GS 33.734 (33.734)	mem 42.979
Train: [14][370/750]	BT 0.033 (1.181)	DT 0.002 (1.135)	loss 8.430 (8.430)	prob 2.427 (2.427)	GS 36.672 (36.672)	mem 42.927
Train: [14][375/750]	BT 0.072 (1.166)	DT 0.028 (1.120)	loss 8.930 (8.930)	prob 1.445 (1.445)	GS 35.469 (35.469)	mem 42.972
Train: [14][380/750]	BT 0.031 (1.194)	DT 0.002 (1.148)	loss 7.944 (7.944)	prob 1.861 (1.861)	GS 38.469 (38.469)	mem 43.013
Train: [14][385/750]	BT 0.029 (1.179)	DT 0.001 (1.133)	loss 7.964 (7.964)	prob 2.534 (2.534)	GS 36.578 (36.578)	mem 43.039
Train: [14][390/750]	BT 14.345 (1.201)	DT 14.314 (1.155)	loss 7.879 (7.879)	prob 2.762 (2.762)	GS 29.938 (29.938)	mem 42.934
Train: [14][395/750]	BT 0.045 (1.186)	DT 0.015 (1.141)	loss 7.799 (7.799)	prob 2.216 (2.216)	GS 35.891 (35.891)	mem 43.048
Train: [14][400/750]	BT 0.030 (1.172)	DT 0.001 (1.127)	loss 8.277 (8.277)	prob 2.883 (2.883)	GS 34.125 (34.125)	mem 42.938
Train: [14][405/750]	BT 0.055 (1.191)	DT 0.002 (1.145)	loss 8.155 (8.155)	prob 1.577 (1.577)	GS 30.406 (30.406)	mem 43.075
Train: [14][410/750]	BT 0.091 (1.177)	DT 0.002 (1.132)	loss 7.721 (7.721)	prob 2.875 (2.875)	GS 33.141 (33.141)	mem 43.102
Train: [14][415/750]	BT 0.032 (1.199)	DT 0.002 (1.153)	loss 8.640 (8.640)	prob 1.116 (1.116)	GS 31.875 (31.875)	mem 43.018
Train: [14][420/750]	BT 0.029 (1.185)	DT 0.001 (1.140)	loss 8.579 (8.579)	prob 1.629 (1.629)	GS 34.609 (34.609)	mem 43.018
Train: [14][425/750]	BT 0.038 (1.171)	DT 0.001 (1.126)	loss 8.982 (8.982)	prob 1.206 (1.206)	GS 32.047 (32.047)	mem 43.020
Train: [14][430/750]	BT 0.041 (1.191)	DT 0.002 (1.146)	loss 8.145 (8.145)	prob 2.540 (2.540)	GS 35.750 (35.750)	mem 42.846
Train: [14][435/750]	BT 0.047 (1.178)	DT 0.006 (1.133)	loss 9.241 (9.241)	prob 1.469 (1.469)	GS 32.359 (32.359)	mem 42.845
Train: [14][440/750]	BT 0.046 (1.195)	DT 0.004 (1.150)	loss 8.416 (8.416)	prob 3.049 (3.049)	GS 32.812 (32.812)	mem 43.051
Train: [14][445/750]	BT 0.026 (1.182)	DT 0.001 (1.138)	loss 8.481 (8.481)	prob 2.215 (2.215)	GS 32.750 (32.750)	mem 43.085
Train: [14][450/750]	BT 12.914 (1.198)	DT 12.876 (1.154)	loss 8.827 (8.827)	prob 2.270 (2.270)	GS 31.469 (31.469)	mem 43.011
Train: [14][455/750]	BT 0.040 (1.185)	DT 0.002 (1.141)	loss 8.397 (8.397)	prob 2.091 (2.091)	GS 30.062 (30.062)	mem 43.105
Train: [14][460/750]	BT 0.075 (1.173)	DT 0.003 (1.129)	loss 8.980 (8.980)	prob 2.785 (2.785)	GS 36.000 (36.000)	mem 43.012
Train: [14][465/750]	BT 0.029 (1.193)	DT 0.001 (1.149)	loss 8.636 (8.636)	prob 1.976 (1.976)	GS 31.797 (31.797)	mem 43.090
Train: [14][470/750]	BT 0.035 (1.181)	DT 0.005 (1.137)	loss 8.041 (8.041)	prob 3.024 (3.024)	GS 33.875 (33.875)	mem 43.090
Train: [14][475/750]	BT 0.027 (1.199)	DT 0.001 (1.155)	loss 8.154 (8.154)	prob 1.971 (1.971)	GS 35.094 (35.094)	mem 42.913
Train: [14][480/750]	BT 0.027 (1.187)	DT 0.001 (1.143)	loss 8.643 (8.643)	prob 3.024 (3.024)	GS 31.375 (31.375)	mem 42.913
Train: [14][485/750]	BT 0.030 (1.175)	DT 0.001 (1.131)	loss 7.932 (7.932)	prob 3.325 (3.325)	GS 28.203 (28.203)	mem 42.973
Train: [14][490/750]	BT 0.084 (1.185)	DT 0.005 (1.141)	loss 8.484 (8.484)	prob 3.072 (3.072)	GS 33.156 (33.156)	mem 43.043
Train: [14][495/750]	BT 0.051 (1.173)	DT 0.012 (1.130)	loss 8.701 (8.701)	prob 1.641 (1.641)	GS 31.984 (31.984)	mem 43.044
Train: [14][500/750]	BT 0.041 (1.188)	DT 0.002 (1.145)	loss 8.661 (8.661)	prob 2.745 (2.745)	GS 35.969 (35.969)	mem 42.993
Train: [14][505/750]	BT 0.029 (1.177)	DT 0.001 (1.133)	loss 7.780 (7.780)	prob 3.788 (3.788)	GS 30.016 (30.016)	mem 42.993
Train: [14][510/750]	BT 13.067 (1.191)	DT 13.028 (1.148)	loss 8.356 (8.356)	prob 2.889 (2.889)	GS 33.344 (33.344)	mem 43.096
Train: [14][515/750]	BT 0.031 (1.180)	DT 0.002 (1.137)	loss 8.234 (8.234)	prob 2.768 (2.768)	GS 36.562 (36.562)	mem 43.049
Train: [14][520/750]	BT 0.035 (1.169)	DT 0.002 (1.126)	loss 8.172 (8.172)	prob 4.149 (4.149)	GS 35.297 (35.297)	mem 43.070
Train: [14][525/750]	BT 0.045 (1.186)	DT 0.001 (1.142)	loss 7.680 (7.680)	prob 3.604 (3.604)	GS 26.438 (26.438)	mem 43.363
Train: [14][530/750]	BT 0.027 (1.175)	DT 0.001 (1.131)	loss 8.199 (8.199)	prob 3.244 (3.244)	GS 34.547 (34.547)	mem 43.373
Train: [14][535/750]	BT 0.030 (1.187)	DT 0.001 (1.143)	loss 8.146 (8.146)	prob 3.122 (3.122)	GS 35.250 (35.250)	mem 43.123
Train: [14][540/750]	BT 0.028 (1.176)	DT 0.001 (1.133)	loss 7.949 (7.949)	prob 3.258 (3.258)	GS 35.141 (35.141)	mem 43.125
Train: [14][545/750]	BT 0.067 (1.166)	DT 0.012 (1.122)	loss 7.997 (7.997)	prob 2.842 (2.842)	GS 31.109 (31.109)	mem 43.125
Train: [14][550/750]	BT 0.050 (1.177)	DT 0.001 (1.134)	loss 8.263 (8.263)	prob 3.562 (3.562)	GS 36.031 (36.031)	mem 43.142
Train: [14][555/750]	BT 0.029 (1.167)	DT 0.007 (1.123)	loss 8.060 (8.060)	prob 3.901 (3.901)	GS 31.625 (31.625)	mem 43.143
Train: [14][560/750]	BT 0.063 (1.176)	DT 0.015 (1.133)	loss 7.687 (7.687)	prob 4.485 (4.485)	GS 31.688 (31.688)	mem 43.211
Train: [14][565/750]	BT 0.035 (1.166)	DT 0.004 (1.123)	loss 8.249 (8.249)	prob 2.138 (2.138)	GS 36.172 (36.172)	mem 43.158
Train: [14][570/750]	BT 12.316 (1.178)	DT 12.283 (1.135)	loss 8.572 (8.572)	prob 3.371 (3.371)	GS 35.656 (35.656)	mem 43.099
Train: [14][575/750]	BT 0.028 (1.168)	DT 0.001 (1.125)	loss 7.930 (7.930)	prob 3.371 (3.371)	GS 25.703 (25.703)	mem 43.140
Train: [14][580/750]	BT 0.139 (1.158)	DT 0.002 (1.115)	loss 8.010 (8.010)	prob 3.556 (3.556)	GS 35.938 (35.938)	mem 43.118
Train: [14][585/750]	BT 0.021 (1.173)	DT 0.001 (1.130)	loss 8.359 (8.359)	prob 2.711 (2.711)	GS 34.750 (34.750)	mem 43.019
Train: [14][590/750]	BT 0.048 (1.163)	DT 0.001 (1.120)	loss 8.761 (8.761)	prob 2.829 (2.829)	GS 37.406 (37.406)	mem 43.018
Train: [14][595/750]	BT 0.039 (1.170)	DT 0.001 (1.127)	loss 8.128 (8.128)	prob 3.802 (3.802)	GS 33.250 (33.250)	mem 43.088
Train: [14][600/750]	BT 0.046 (1.160)	DT 0.001 (1.117)	loss 9.081 (9.081)	prob 3.849 (3.849)	GS 37.203 (37.203)	mem 43.135
Train: [14][605/750]	BT 0.038 (1.151)	DT 0.002 (1.108)	loss 7.815 (7.815)	prob 3.413 (3.413)	GS 27.250 (27.250)	mem 43.129
Train: [14][610/750]	BT 0.035 (1.162)	DT 0.001 (1.119)	loss 8.454 (8.454)	prob 3.978 (3.978)	GS 35.125 (35.125)	mem 43.142
Train: [14][615/750]	BT 0.031 (1.153)	DT 0.001 (1.110)	loss 8.631 (8.631)	prob 2.445 (2.445)	GS 31.734 (31.734)	mem 43.143
Train: [14][620/750]	BT 0.038 (1.162)	DT 0.001 (1.119)	loss 7.797 (7.797)	prob 4.350 (4.350)	GS 34.484 (34.484)	mem 43.132
Train: [14][625/750]	BT 0.034 (1.153)	DT 0.001 (1.110)	loss 8.130 (8.130)	prob 3.699 (3.699)	GS 38.047 (38.047)	mem 43.132
Train: [14][630/750]	BT 12.754 (1.165)	DT 12.722 (1.122)	loss 7.943 (7.943)	prob 4.553 (4.553)	GS 33.656 (33.656)	mem 43.118
Train: [14][635/750]	BT 0.111 (1.156)	DT 0.024 (1.113)	loss 7.885 (7.885)	prob 3.569 (3.569)	GS 29.312 (29.312)	mem 43.139
Train: [14][640/750]	BT 0.028 (1.148)	DT 0.001 (1.104)	loss 8.429 (8.429)	prob 4.111 (4.111)	GS 35.625 (35.625)	mem 43.104
Train: [14][645/750]	BT 0.034 (1.159)	DT 0.001 (1.116)	loss 7.982 (7.982)	prob 4.004 (4.004)	GS 28.938 (28.938)	mem 43.245
Train: [14][650/750]	BT 0.034 (1.151)	DT 0.001 (1.108)	loss 8.166 (8.166)	prob 4.003 (4.003)	GS 31.109 (31.109)	mem 43.118
Train: [14][655/750]	BT 0.045 (1.163)	DT 0.010 (1.120)	loss 8.208 (8.208)	prob 3.293 (3.293)	GS 30.547 (30.547)	mem 42.900
arpack error, retry= 0
Train: [14][660/750]	BT 0.032 (1.156)	DT 0.002 (1.113)	loss 8.400 (8.400)	prob 4.251 (4.251)	GS 33.391 (33.391)	mem 42.933
Train: [14][665/750]	BT 0.059 (1.147)	DT 0.004 (1.104)	loss 7.995 (7.995)	prob 3.522 (3.522)	GS 47.938 (47.938)	mem 42.934
Train: [14][670/750]	BT 4.816 (1.161)	DT 4.782 (1.118)	loss 8.403 (8.403)	prob 3.299 (3.299)	GS 35.203 (35.203)	mem 43.000
Train: [14][675/750]	BT 0.033 (1.153)	DT 0.001 (1.110)	loss 8.581 (8.581)	prob 3.436 (3.436)	GS 30.828 (30.828)	mem 43.001
Train: [14][680/750]	BT 0.037 (1.160)	DT 0.002 (1.117)	loss 7.816 (7.816)	prob 4.329 (4.329)	GS 33.266 (33.266)	mem 43.061
Train: [14][685/750]	BT 0.077 (1.152)	DT 0.013 (1.109)	loss 7.917 (7.917)	prob 3.572 (3.572)	GS 46.828 (46.828)	mem 43.092
Train: [14][690/750]	BT 13.275 (1.164)	DT 13.231 (1.120)	loss 8.054 (8.054)	prob 3.129 (3.129)	GS 38.219 (38.219)	mem 42.987
Train: [14][695/750]	BT 0.024 (1.158)	DT 0.001 (1.114)	loss 8.044 (8.044)	prob 2.984 (2.984)	GS 30.297 (30.297)	mem 42.927
Train: [14][700/750]	BT 0.035 (1.150)	DT 0.002 (1.106)	loss 8.580 (8.580)	prob 3.724 (3.724)	GS 33.531 (33.531)	mem 42.931
Train: [14][705/750]	BT 0.032 (1.159)	DT 0.002 (1.116)	loss 8.450 (8.450)	prob 3.654 (3.654)	GS 42.109 (42.109)	mem 43.051
Train: [14][710/750]	BT 0.111 (1.151)	DT 0.031 (1.108)	loss 8.206 (8.206)	prob 4.093 (4.093)	GS 33.875 (33.875)	mem 43.179
Train: [14][715/750]	BT 0.025 (1.159)	DT 0.003 (1.116)	loss 8.185 (8.185)	prob 3.493 (3.493)	GS 28.016 (28.016)	mem 43.071
Train: [14][720/750]	BT 0.038 (1.154)	DT 0.004 (1.111)	loss 8.864 (8.864)	prob 3.753 (3.753)	GS 34.219 (34.219)	mem 42.951
Train: [14][725/750]	BT 0.050 (1.146)	DT 0.002 (1.103)	loss 8.139 (8.139)	prob 3.842 (3.842)	GS 29.688 (29.688)	mem 42.951
Train: [14][730/750]	BT 0.025 (1.157)	DT 0.001 (1.114)	loss 8.011 (8.011)	prob 3.529 (3.529)	GS 36.797 (36.797)	mem 42.620
Train: [14][735/750]	BT 0.030 (1.149)	DT 0.001 (1.106)	loss 8.204 (8.204)	prob 2.735 (2.735)	GS 34.281 (34.281)	mem 42.621
Train: [14][740/750]	BT 0.028 (1.152)	DT 0.001 (1.109)	loss 8.365 (8.365)	prob 3.498 (3.498)	GS 30.500 (30.500)	mem 10.675
Train: [14][745/750]	BT 0.027 (1.144)	DT 0.001 (1.101)	loss 8.099 (8.099)	prob 3.844 (3.844)	GS 34.062 (34.062)	mem 10.674
Train: [14][750/750]	BT 3.045 (1.141)	DT 3.017 (1.098)	loss 8.575 (8.575)	prob 2.270 (2.270)	GS 36.219 (36.219)	mem 10.639
Train: [14][755/750]	BT 0.045 (1.133)	DT 0.002 (1.091)	loss 8.213 (8.213)	prob 3.148 (3.148)	GS 26.500 (26.500)	mem 10.639
epoch 14, total time 855.89
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [15][1/750]	BT 21.569 (21.569)	DT 21.521 (21.521)	loss 8.475 (8.475)	prob 2.823 (2.823)	GS 34.312 (34.312)	mem 41.576
Train: [15][5/750]	BT 0.130 (4.826)	DT 0.006 (4.744)	loss 8.393 (8.393)	prob 3.055 (3.055)	GS 38.266 (38.266)	mem 41.676
Train: [15][10/750]	BT 0.034 (2.432)	DT 0.002 (2.375)	loss 8.209 (8.209)	prob 4.310 (4.310)	GS 29.969 (29.969)	mem 41.724
Train: [15][15/750]	BT 0.125 (2.346)	DT 0.005 (2.289)	loss 8.372 (8.372)	prob 3.578 (3.578)	GS 35.344 (35.344)	mem 42.100
Train: [15][20/750]	BT 0.033 (2.193)	DT 0.002 (2.140)	loss 8.194 (8.194)	prob 3.924 (3.924)	GS 35.812 (35.812)	mem 41.933
Train: [15][25/750]	BT 0.030 (1.760)	DT 0.001 (1.712)	loss 8.518 (8.518)	prob 2.354 (2.354)	GS 29.875 (29.875)	mem 41.936
Train: [15][30/750]	BT 0.025 (1.978)	DT 0.001 (1.930)	loss 8.393 (8.393)	prob 3.709 (3.709)	GS 37.875 (37.875)	mem 42.089
Train: [15][35/750]	BT 0.068 (1.703)	DT 0.007 (1.655)	loss 8.304 (8.304)	prob 3.224 (3.224)	GS 30.234 (30.234)	mem 42.094
Train: [15][40/750]	BT 7.016 (1.823)	DT 6.972 (1.776)	loss 7.967 (7.967)	prob 4.174 (4.174)	GS 34.516 (34.516)	mem 42.111
Train: [15][45/750]	BT 0.030 (1.623)	DT 0.001 (1.578)	loss 7.896 (7.896)	prob 3.696 (3.696)	GS 32.016 (32.016)	mem 42.068
Train: [15][50/750]	BT 5.676 (1.578)	DT 5.619 (1.533)	loss 8.206 (8.206)	prob 4.319 (4.319)	GS 32.359 (32.359)	mem 42.147
Train: [15][55/750]	BT 0.031 (1.562)	DT 0.001 (1.519)	loss 8.289 (8.289)	prob 3.730 (3.730)	GS 32.391 (32.391)	mem 42.178
Train: [15][60/750]	BT 0.025 (1.437)	DT 0.001 (1.393)	loss 8.131 (8.131)	prob 3.875 (3.875)	GS 32.234 (32.234)	mem 42.125
Train: [15][65/750]	BT 0.092 (1.518)	DT 0.002 (1.474)	loss 8.134 (8.134)	prob 3.234 (3.234)	GS 30.016 (30.016)	mem 42.489
Train: [15][70/750]	BT 0.075 (1.413)	DT 0.003 (1.369)	loss 8.197 (8.197)	prob 3.885 (3.885)	GS 34.016 (34.016)	mem 42.268
Train: [15][75/750]	BT 0.082 (1.468)	DT 0.010 (1.423)	loss 8.186 (8.186)	prob 3.096 (3.096)	GS 35.438 (35.438)	mem 42.223
Train: [15][80/750]	BT 0.031 (1.388)	DT 0.001 (1.343)	loss 8.275 (8.275)	prob 4.040 (4.040)	GS 37.297 (37.297)	mem 42.154
Train: [15][85/750]	BT 0.057 (1.309)	DT 0.012 (1.265)	loss 7.500 (7.500)	prob 3.741 (3.741)	GS 26.203 (26.203)	mem 42.159
Train: [15][90/750]	BT 0.035 (1.404)	DT 0.001 (1.361)	loss 8.149 (8.149)	prob 3.593 (3.593)	GS 30.188 (30.188)	mem 42.440
Train: [15][95/750]	BT 0.052 (1.334)	DT 0.021 (1.290)	loss 8.673 (8.673)	prob 1.769 (1.769)	GS 39.078 (39.078)	mem 42.413
Train: [15][100/750]	BT 0.031 (1.388)	DT 0.001 (1.344)	loss 8.174 (8.174)	prob 3.647 (3.647)	GS 31.203 (31.203)	mem 42.469
Train: [15][105/750]	BT 0.036 (1.325)	DT 0.003 (1.280)	loss 8.938 (8.938)	prob 2.380 (2.380)	GS 33.172 (33.172)	mem 42.469
Train: [15][110/750]	BT 10.710 (1.364)	DT 10.679 (1.319)	loss 7.979 (7.979)	prob 3.768 (3.768)	GS 33.234 (33.234)	mem 42.541
Train: [15][115/750]	BT 0.024 (1.310)	DT 0.001 (1.265)	loss 8.079 (8.079)	prob 2.804 (2.804)	GS 29.500 (29.500)	mem 42.543
Train: [15][120/750]	BT 0.032 (1.266)	DT 0.001 (1.221)	loss 7.900 (7.900)	prob 4.088 (4.088)	GS 34.141 (34.141)	mem 42.532
Train: [15][125/750]	BT 0.042 (1.321)	DT 0.005 (1.277)	loss 8.053 (8.053)	prob 3.558 (3.558)	GS 28.750 (28.750)	mem 42.633
Train: [15][130/750]	BT 0.354 (1.275)	DT 0.300 (1.230)	loss 8.039 (8.039)	prob 3.938 (3.938)	GS 33.109 (33.109)	mem 42.686
Train: [15][135/750]	BT 0.072 (1.308)	DT 0.034 (1.263)	loss 8.273 (8.273)	prob 3.835 (3.835)	GS 32.453 (32.453)	mem 42.786
Train: [15][140/750]	BT 0.028 (1.280)	DT 0.001 (1.236)	loss 8.962 (8.962)	prob 3.623 (3.623)	GS 34.188 (34.188)	mem 42.861
Train: [15][145/750]	BT 0.057 (1.238)	DT 0.009 (1.193)	loss 8.139 (8.139)	prob 3.012 (3.012)	GS 32.594 (32.594)	mem 42.763
Train: [15][150/750]	BT 0.033 (1.284)	DT 0.002 (1.239)	loss 7.978 (7.978)	prob 3.354 (3.354)	GS 32.703 (32.703)	mem 42.873
Train: [15][155/750]	BT 0.030 (1.243)	DT 0.001 (1.199)	loss 7.852 (7.852)	prob 3.469 (3.469)	GS 29.047 (29.047)	mem 42.879
Train: [15][160/750]	BT 2.561 (1.294)	DT 2.524 (1.250)	loss 7.625 (7.625)	prob 3.189 (3.189)	GS 33.297 (33.297)	mem 42.821
Train: [15][165/750]	BT 0.031 (1.255)	DT 0.001 (1.212)	loss 8.290 (8.290)	prob 2.064 (2.064)	GS 31.719 (31.719)	mem 42.821
Train: [15][170/750]	BT 11.715 (1.288)	DT 11.656 (1.245)	loss 8.177 (8.177)	prob 3.501 (3.501)	GS 37.484 (37.484)	mem 42.875
Train: [15][175/750]	BT 0.042 (1.274)	DT 0.005 (1.231)	loss 7.862 (7.862)	prob 2.747 (2.747)	GS 30.047 (30.047)	mem 42.869
Train: [15][180/750]	BT 0.057 (1.240)	DT 0.008 (1.197)	loss 8.135 (8.135)	prob 3.581 (3.581)	GS 34.391 (34.391)	mem 42.771
Train: [15][185/750]	BT 0.039 (1.268)	DT 0.009 (1.225)	loss 7.964 (7.964)	prob 2.735 (2.735)	GS 33.938 (33.938)	mem 42.897
Train: [15][190/750]	BT 0.065 (1.236)	DT 0.033 (1.193)	loss 8.409 (8.409)	prob 3.530 (3.530)	GS 36.781 (36.781)	mem 42.923
Train: [15][195/750]	BT 0.037 (1.276)	DT 0.013 (1.233)	loss 7.971 (7.971)	prob 3.084 (3.084)	GS 28.844 (28.844)	mem 42.868
Train: [15][200/750]	BT 0.099 (1.245)	DT 0.002 (1.202)	loss 8.140 (8.140)	prob 3.801 (3.801)	GS 35.609 (35.609)	mem 42.920
Train: [15][205/750]	BT 0.041 (1.216)	DT 0.002 (1.173)	loss 8.184 (8.184)	prob 1.818 (1.818)	GS 32.297 (32.297)	mem 42.872
Train: [15][210/750]	BT 0.074 (1.258)	DT 0.007 (1.214)	loss 8.222 (8.222)	prob 3.156 (3.156)	GS 35.391 (35.391)	mem 43.029
Train: [15][215/750]	BT 0.032 (1.230)	DT 0.001 (1.186)	loss 7.876 (7.876)	prob 2.326 (2.326)	GS 34.578 (34.578)	mem 42.979
Train: [15][220/750]	BT 0.030 (1.269)	DT 0.001 (1.226)	loss 8.193 (8.193)	prob 2.378 (2.378)	GS 31.203 (31.203)	mem 43.036
Train: [15][225/750]	BT 0.125 (1.242)	DT 0.001 (1.198)	loss 8.532 (8.532)	prob 1.271 (1.271)	GS 32.297 (32.297)	mem 42.958
Train: [15][230/750]	BT 11.947 (1.268)	DT 11.921 (1.224)	loss 7.763 (7.763)	prob 3.288 (3.288)	GS 36.812 (36.812)	mem 43.003
Train: [15][235/750]	BT 0.023 (1.242)	DT 0.001 (1.198)	loss 7.909 (7.909)	prob 2.592 (2.592)	GS 29.125 (29.125)	mem 43.046
Train: [15][240/750]	BT 0.054 (1.217)	DT 0.006 (1.174)	loss 8.431 (8.431)	prob 2.905 (2.905)	GS 29.781 (29.781)	mem 43.210
Train: [15][245/750]	BT 0.031 (1.243)	DT 0.001 (1.199)	loss 7.908 (7.908)	prob 2.927 (2.927)	GS 34.484 (34.484)	mem 43.008
Train: [15][250/750]	BT 0.023 (1.219)	DT 0.001 (1.175)	loss 9.010 (9.010)	prob 1.730 (1.730)	GS 34.688 (34.688)	mem 43.009
Train: [15][255/750]	BT 0.042 (1.243)	DT 0.005 (1.200)	loss 8.043 (8.043)	prob 1.424 (1.424)	GS 32.281 (32.281)	mem 43.045
Train: [15][260/750]	BT 0.032 (1.220)	DT 0.003 (1.177)	loss 8.041 (8.041)	prob 3.065 (3.065)	GS 40.156 (40.156)	mem 43.059
Train: [15][265/750]	BT 0.047 (1.198)	DT 0.002 (1.155)	loss 8.405 (8.405)	prob 1.103 (1.103)	GS 29.578 (29.578)	mem 43.005
Train: [15][270/750]	BT 0.040 (1.228)	DT 0.009 (1.185)	loss 7.977 (7.977)	prob 2.269 (2.269)	GS 31.672 (31.672)	mem 43.081
Train: [15][275/750]	BT 0.025 (1.207)	DT 0.001 (1.164)	loss 8.836 (8.836)	prob 0.523 (0.523)	GS 34.031 (34.031)	mem 43.024
Train: [15][280/750]	BT 0.022 (1.233)	DT 0.001 (1.190)	loss 7.568 (7.568)	prob 2.833 (2.833)	GS 34.469 (34.469)	mem 43.064
Train: [15][285/750]	BT 0.051 (1.212)	DT 0.001 (1.169)	loss 8.215 (8.215)	prob 1.011 (1.011)	GS 30.906 (30.906)	mem 43.078
Train: [15][290/750]	BT 12.894 (1.237)	DT 12.863 (1.194)	loss 8.265 (8.265)	prob 2.092 (2.092)	GS 38.453 (38.453)	mem 43.083
Train: [15][295/750]	BT 0.033 (1.217)	DT 0.002 (1.174)	loss 8.418 (8.418)	prob 1.577 (1.577)	GS 32.656 (32.656)	mem 43.094
Train: [15][300/750]	BT 0.063 (1.197)	DT 0.004 (1.154)	loss 7.673 (7.673)	prob 2.290 (2.290)	GS 36.609 (36.609)	mem 43.251
Train: [15][305/750]	BT 0.030 (1.217)	DT 0.001 (1.174)	loss 7.965 (7.965)	prob 1.765 (1.765)	GS 41.078 (41.078)	mem 42.997
Train: [15][310/750]	BT 0.035 (1.198)	DT 0.003 (1.155)	loss 8.131 (8.131)	prob 1.465 (1.465)	GS 35.016 (35.016)	mem 42.996
Train: [15][315/750]	BT 0.127 (1.219)	DT 0.024 (1.175)	loss 8.450 (8.450)	prob 1.024 (1.024)	GS 30.000 (30.000)	mem 43.068
Train: [15][320/750]	BT 0.039 (1.200)	DT 0.001 (1.157)	loss 8.257 (8.257)	prob 2.462 (2.462)	GS 33.562 (33.562)	mem 43.145
Train: [15][325/750]	BT 0.047 (1.183)	DT 0.002 (1.139)	loss 7.803 (7.803)	prob 2.830 (2.830)	GS 30.250 (30.250)	mem 43.201
Train: [15][330/750]	BT 0.035 (1.203)	DT 0.003 (1.160)	loss 7.972 (7.972)	prob 1.999 (1.999)	GS 34.359 (34.359)	mem 43.335
Train: [15][335/750]	BT 0.032 (1.186)	DT 0.002 (1.142)	loss 7.741 (7.741)	prob 1.496 (1.496)	GS 31.688 (31.688)	mem 43.057
Train: [15][340/750]	BT 0.108 (1.207)	DT 0.028 (1.164)	loss 9.351 (9.351)	prob 1.590 (1.590)	GS 33.031 (33.031)	mem 43.015
Train: [15][345/750]	BT 0.037 (1.190)	DT 0.001 (1.147)	loss 7.926 (7.926)	prob 2.283 (2.283)	GS 33.594 (33.594)	mem 42.977
Train: [15][350/750]	BT 13.053 (1.211)	DT 13.022 (1.168)	loss 7.953 (7.953)	prob 2.902 (2.902)	GS 29.094 (29.094)	mem 43.032
Train: [15][355/750]	BT 0.023 (1.195)	DT 0.002 (1.152)	loss 7.688 (7.688)	prob 2.062 (2.062)	GS 31.828 (31.828)	mem 43.033
Train: [15][360/750]	BT 0.031 (1.179)	DT 0.003 (1.136)	loss 7.655 (7.655)	prob 2.556 (2.556)	GS 35.688 (35.688)	mem 43.036
Train: [15][365/750]	BT 0.023 (1.197)	DT 0.001 (1.154)	loss 8.286 (8.286)	prob 1.554 (1.554)	GS 31.844 (31.844)	mem 42.932
Train: [15][370/750]	BT 0.052 (1.181)	DT 0.021 (1.138)	loss 8.257 (8.257)	prob 1.720 (1.720)	GS 38.141 (38.141)	mem 42.933
Train: [15][375/750]	BT 0.052 (1.198)	DT 0.009 (1.155)	loss 8.195 (8.195)	prob 3.044 (3.044)	GS 32.312 (32.312)	mem 43.045
Train: [15][380/750]	BT 0.060 (1.183)	DT 0.002 (1.140)	loss 8.136 (8.136)	prob 2.529 (2.529)	GS 38.109 (38.109)	mem 43.101
Train: [15][385/750]	BT 0.101 (1.168)	DT 0.012 (1.125)	loss 7.603 (7.603)	prob 2.189 (2.189)	GS 22.562 (22.562)	mem 43.127
Train: [15][390/750]	BT 0.075 (1.186)	DT 0.011 (1.142)	loss 8.591 (8.591)	prob 1.944 (1.944)	GS 37.734 (37.734)	mem 42.919
Train: [15][395/750]	BT 0.039 (1.171)	DT 0.002 (1.128)	loss 8.501 (8.501)	prob 0.990 (0.990)	GS 29.688 (29.688)	mem 42.965
Train: [15][400/750]	BT 0.027 (1.188)	DT 0.001 (1.145)	loss 8.434 (8.434)	prob 2.888 (2.888)	GS 31.500 (31.500)	mem 42.916
Train: [15][405/750]	BT 0.042 (1.174)	DT 0.001 (1.131)	loss 8.435 (8.435)	prob 1.680 (1.680)	GS 29.656 (29.656)	mem 42.979
Train: [15][410/750]	BT 12.988 (1.192)	DT 12.949 (1.149)	loss 8.582 (8.582)	prob 2.795 (2.795)	GS 31.844 (31.844)	mem 42.928
Train: [15][415/750]	BT 0.031 (1.178)	DT 0.002 (1.135)	loss 7.859 (7.859)	prob 2.345 (2.345)	GS 29.172 (29.172)	mem 42.987
Train: [15][420/750]	BT 0.065 (1.165)	DT 0.004 (1.121)	loss 7.764 (7.764)	prob 3.047 (3.047)	GS 31.703 (31.703)	mem 43.138
Train: [15][425/750]	BT 0.033 (1.182)	DT 0.003 (1.139)	loss 8.261 (8.261)	prob 1.924 (1.924)	GS 29.641 (29.641)	mem 43.027
Train: [15][430/750]	BT 0.033 (1.169)	DT 0.002 (1.126)	loss 9.071 (9.071)	prob 1.946 (1.946)	GS 33.172 (33.172)	mem 43.137
Train: [15][435/750]	BT 0.038 (1.188)	DT 0.005 (1.144)	loss 8.434 (8.434)	prob 1.178 (1.178)	GS 29.078 (29.078)	mem 42.772
Train: [15][440/750]	BT 0.024 (1.175)	DT 0.001 (1.131)	loss 8.206 (8.206)	prob 2.337 (2.337)	GS 37.391 (37.391)	mem 42.773
Train: [15][445/750]	BT 0.031 (1.162)	DT 0.001 (1.119)	loss 8.111 (8.111)	prob 2.164 (2.164)	GS 33.000 (33.000)	mem 42.773
Train: [15][450/750]	BT 0.024 (1.181)	DT 0.001 (1.137)	loss 8.814 (8.814)	prob 2.327 (2.327)	GS 29.453 (29.453)	mem 42.991
Train: [15][455/750]	BT 0.046 (1.168)	DT 0.002 (1.125)	loss 8.186 (8.186)	prob 2.326 (2.326)	GS 30.844 (30.844)	mem 42.991
Train: [15][460/750]	BT 0.052 (1.178)	DT 0.012 (1.135)	loss 8.120 (8.120)	prob 2.744 (2.744)	GS 34.688 (34.688)	mem 42.973
Train: [15][465/750]	BT 0.055 (1.166)	DT 0.002 (1.123)	loss 7.917 (7.917)	prob 3.405 (3.405)	GS 26.469 (26.469)	mem 43.197
Train: [15][470/750]	BT 13.740 (1.183)	DT 13.690 (1.140)	loss 8.332 (8.332)	prob 3.536 (3.536)	GS 34.547 (34.547)	mem 43.021
Train: [15][475/750]	BT 0.084 (1.171)	DT 0.001 (1.128)	loss 7.879 (7.879)	prob 2.577 (2.577)	GS 29.984 (29.984)	mem 43.020
Train: [15][480/750]	BT 0.049 (1.160)	DT 0.006 (1.116)	loss 8.236 (8.236)	prob 4.558 (4.558)	GS 33.453 (33.453)	mem 43.020
Train: [15][485/750]	BT 0.104 (1.173)	DT 0.012 (1.130)	loss 8.495 (8.495)	prob 1.902 (1.902)	GS 28.828 (28.828)	mem 43.373
Train: [15][490/750]	BT 0.035 (1.161)	DT 0.003 (1.118)	loss 8.489 (8.489)	prob 1.934 (1.934)	GS 32.469 (32.469)	mem 43.056
Train: [15][495/750]	BT 0.067 (1.180)	DT 0.005 (1.136)	loss 8.000 (8.000)	prob 1.646 (1.646)	GS 33.719 (33.719)	mem 43.124
Train: [15][500/750]	BT 0.026 (1.168)	DT 0.001 (1.125)	loss 8.748 (8.748)	prob 2.926 (2.926)	GS 35.859 (35.859)	mem 43.070
Train: [15][505/750]	BT 0.067 (1.157)	DT 0.001 (1.114)	loss 8.593 (8.593)	prob 2.388 (2.388)	GS 31.766 (31.766)	mem 43.071
Train: [15][510/750]	BT 0.031 (1.172)	DT 0.001 (1.129)	loss 7.892 (7.892)	prob 3.117 (3.117)	GS 36.547 (36.547)	mem 43.025
Train: [15][515/750]	BT 0.035 (1.161)	DT 0.006 (1.118)	loss 8.492 (8.492)	prob 1.788 (1.788)	GS 42.312 (42.312)	mem 43.025
Train: [15][520/750]	BT 0.046 (1.172)	DT 0.014 (1.129)	loss 8.870 (8.870)	prob 2.864 (2.864)	GS 34.188 (34.188)	mem 43.141
Train: [15][525/750]	BT 0.033 (1.162)	DT 0.003 (1.118)	loss 8.383 (8.383)	prob 2.157 (2.157)	GS 32.828 (32.828)	mem 43.108
Train: [15][530/750]	BT 13.005 (1.176)	DT 12.981 (1.132)	loss 8.597 (8.597)	prob 3.102 (3.102)	GS 35.047 (35.047)	mem 43.072
Train: [15][535/750]	BT 0.060 (1.165)	DT 0.002 (1.122)	loss 8.495 (8.495)	prob 2.958 (2.958)	GS 32.156 (32.156)	mem 43.077
Train: [15][540/750]	BT 0.066 (1.155)	DT 0.002 (1.112)	loss 8.487 (8.487)	prob 3.140 (3.140)	GS 35.391 (35.391)	mem 43.078
Train: [15][545/750]	BT 0.073 (1.172)	DT 0.018 (1.128)	loss 8.141 (8.141)	prob 2.411 (2.411)	GS 32.016 (32.016)	mem 43.040
Train: [15][550/750]	BT 0.101 (1.162)	DT 0.002 (1.118)	loss 9.205 (9.205)	prob 2.587 (2.587)	GS 35.453 (35.453)	mem 43.077
Train: [15][555/750]	BT 0.033 (1.172)	DT 0.002 (1.129)	loss 8.051 (8.051)	prob 2.854 (2.854)	GS 33.562 (33.562)	mem 43.091
Train: [15][560/750]	BT 0.054 (1.162)	DT 0.001 (1.119)	loss 7.704 (7.704)	prob 3.424 (3.424)	GS 33.453 (33.453)	mem 43.092
Train: [15][565/750]	BT 0.041 (1.152)	DT 0.003 (1.109)	loss 8.959 (8.959)	prob 1.555 (1.555)	GS 35.250 (35.250)	mem 43.093
Train: [15][570/750]	BT 0.030 (1.164)	DT 0.001 (1.120)	loss 8.165 (8.165)	prob 3.969 (3.969)	GS 29.422 (29.422)	mem 42.929
Train: [15][575/750]	BT 0.062 (1.154)	DT 0.012 (1.111)	loss 8.465 (8.465)	prob 2.985 (2.985)	GS 31.828 (31.828)	mem 42.999
Train: [15][580/750]	BT 0.061 (1.169)	DT 0.002 (1.125)	loss 8.172 (8.172)	prob 3.059 (3.059)	GS 35.875 (35.875)	mem 43.039
Train: [15][585/750]	BT 0.108 (1.159)	DT 0.001 (1.115)	loss 8.243 (8.243)	prob 2.384 (2.384)	GS 31.422 (31.422)	mem 43.155
Train: [15][590/750]	BT 8.838 (1.165)	DT 8.805 (1.121)	loss 7.733 (7.733)	prob 3.963 (3.963)	GS 34.828 (34.828)	mem 43.140
Train: [15][595/750]	BT 0.060 (1.155)	DT 0.002 (1.112)	loss 8.770 (8.770)	prob 2.084 (2.084)	GS 32.672 (32.672)	mem 43.055
Train: [15][600/750]	BT 0.025 (1.153)	DT 0.001 (1.109)	loss 9.294 (9.294)	prob 3.135 (3.135)	GS 31.922 (31.922)	mem 43.058
Train: [15][605/750]	BT 0.034 (1.158)	DT 0.002 (1.115)	loss 8.395 (8.395)	prob 3.049 (3.049)	GS 33.047 (33.047)	mem 43.136
Train: [15][610/750]	BT 5.154 (1.159)	DT 5.096 (1.116)	loss 8.480 (8.480)	prob 3.494 (3.494)	GS 37.562 (37.562)	mem 42.977
Train: [15][615/750]	BT 0.079 (1.160)	DT 0.010 (1.116)	loss 8.803 (8.803)	prob 3.248 (3.248)	GS 34.453 (34.453)	mem 43.146
Train: [15][620/750]	BT 0.046 (1.157)	DT 0.019 (1.113)	loss 8.117 (8.117)	prob 3.504 (3.504)	GS 32.766 (32.766)	mem 43.175
Train: [15][625/750]	BT 0.028 (1.158)	DT 0.001 (1.114)	loss 7.536 (7.536)	prob 4.303 (4.303)	GS 30.703 (30.703)	mem 43.076
Train: [15][630/750]	BT 5.041 (1.165)	DT 4.999 (1.121)	loss 8.695 (8.695)	prob 3.376 (3.376)	GS 36.156 (36.156)	mem 43.011
Train: [15][635/750]	BT 0.039 (1.157)	DT 0.001 (1.113)	loss 7.844 (7.844)	prob 3.636 (3.636)	GS 31.031 (31.031)	mem 43.060
Train: [15][640/750]	BT 0.031 (1.163)	DT 0.001 (1.119)	loss 8.305 (8.305)	prob 3.702 (3.702)	GS 33.547 (33.547)	mem 43.015
Train: [15][645/750]	BT 0.041 (1.162)	DT 0.010 (1.118)	loss 8.000 (8.000)	prob 3.213 (3.213)	GS 30.000 (30.000)	mem 43.114
Train: [15][650/750]	BT 4.348 (1.163)	DT 4.314 (1.119)	loss 7.988 (7.988)	prob 4.025 (4.025)	GS 29.219 (29.219)	mem 43.079
Train: [15][655/750]	BT 0.036 (1.165)	DT 0.002 (1.122)	loss 7.930 (7.930)	prob 3.270 (3.270)	GS 31.406 (31.406)	mem 43.162
arpack error, retry= 0
arpack error, retry= 0
arpack error, retry= 0
Train: [15][660/750]	BT 0.033 (1.162)	DT 0.001 (1.118)	loss 8.032 (8.032)	prob 3.292 (3.292)	GS 31.547 (31.547)	mem 42.935
Train: [15][665/750]	BT 0.132 (1.153)	DT 0.003 (1.110)	loss 7.666 (7.666)	prob 4.043 (4.043)	GS 32.266 (32.266)	mem 43.028
Train: [15][670/750]	BT 6.118 (1.170)	DT 6.088 (1.126)	loss 8.294 (8.294)	prob 4.186 (4.186)	GS 32.766 (32.766)	mem 43.088
Train: [15][675/750]	BT 0.032 (1.161)	DT 0.001 (1.117)	loss 8.078 (8.078)	prob 3.416 (3.416)	GS 28.922 (28.922)	mem 43.089
Train: [15][680/750]	BT 9.265 (1.168)	DT 9.142 (1.124)	loss 8.063 (8.063)	prob 4.335 (4.335)	GS 35.969 (35.969)	mem 43.075
Train: [15][685/750]	BT 0.033 (1.166)	DT 0.003 (1.121)	loss 8.402 (8.402)	prob 2.731 (2.731)	GS 31.422 (31.422)	mem 43.069
Train: [15][690/750]	BT 0.032 (1.157)	DT 0.001 (1.113)	loss 8.139 (8.139)	prob 4.143 (4.143)	GS 30.391 (30.391)	mem 43.011
Train: [15][695/750]	BT 0.074 (1.165)	DT 0.003 (1.120)	loss 7.731 (7.731)	prob 3.833 (3.833)	GS 30.109 (30.109)	mem 43.192
Train: [15][700/750]	BT 0.039 (1.157)	DT 0.007 (1.112)	loss 8.148 (8.148)	prob 4.204 (4.204)	GS 30.812 (30.812)	mem 43.164
Train: [15][705/750]	BT 0.033 (1.161)	DT 0.002 (1.117)	loss 7.701 (7.701)	prob 3.950 (3.950)	GS 30.672 (30.672)	mem 43.053
Train: [15][710/750]	BT 0.024 (1.156)	DT 0.001 (1.112)	loss 8.560 (8.560)	prob 3.001 (3.001)	GS 33.000 (33.000)	mem 43.065
Train: [15][715/750]	BT 0.032 (1.155)	DT 0.002 (1.111)	loss 7.990 (7.990)	prob 3.392 (3.392)	GS 32.469 (32.469)	mem 43.111
Train: [15][720/750]	BT 0.032 (1.159)	DT 0.001 (1.115)	loss 7.964 (7.964)	prob 3.803 (3.803)	GS 38.172 (38.172)	mem 43.147
Train: [15][725/750]	BT 0.053 (1.156)	DT 0.003 (1.112)	loss 7.772 (7.772)	prob 4.333 (4.333)	GS 28.062 (28.062)	mem 43.280
Train: [15][730/750]	BT 0.022 (1.159)	DT 0.001 (1.114)	loss 8.129 (8.129)	prob 4.110 (4.110)	GS 31.141 (31.141)	mem 42.761
Train: [15][735/750]	BT 0.080 (1.155)	DT 0.013 (1.110)	loss 8.358 (8.358)	prob 3.366 (3.366)	GS 29.609 (29.609)	mem 39.952
Train: [15][740/750]	BT 4.920 (1.155)	DT 4.887 (1.111)	loss 8.084 (8.084)	prob 4.306 (4.306)	GS 30.297 (30.297)	mem 16.735
Train: [15][745/750]	BT 0.022 (1.148)	DT 0.001 (1.104)	loss 7.803 (7.803)	prob 4.311 (4.311)	GS 26.562 (26.562)	mem 16.731
Train: [15][750/750]	BT 0.024 (1.141)	DT 0.001 (1.096)	loss 8.088 (8.088)	prob 3.390 (3.390)	GS 32.062 (32.062)	mem 16.732
Train: [15][755/750]	BT 0.020 (1.137)	DT 0.001 (1.093)	loss 8.909 (8.909)	prob 2.755 (2.755)	GS 36.875 (36.875)	mem 12.393
epoch 15, total time 858.55
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [16][1/750]	BT 20.664 (20.664)	DT 20.610 (20.610)	loss 8.011 (8.011)	prob 3.447 (3.447)	GS 34.656 (34.656)	mem 41.618
Train: [16][5/750]	BT 0.062 (4.319)	DT 0.011 (4.273)	loss 7.644 (7.644)	prob 3.983 (3.983)	GS 30.688 (30.688)	mem 41.639
Train: [16][10/750]	BT 0.036 (2.521)	DT 0.001 (2.471)	loss 8.402 (8.402)	prob 3.909 (3.909)	GS 36.141 (36.141)	mem 41.692
Train: [16][15/750]	BT 0.041 (2.441)	DT 0.004 (2.390)	loss 8.327 (8.327)	prob 3.230 (3.230)	GS 32.062 (32.062)	mem 41.883
Train: [16][20/750]	BT 1.273 (1.903)	DT 1.226 (1.855)	loss 8.291 (8.291)	prob 3.562 (3.562)	GS 32.625 (32.625)	mem 41.883
Train: [16][25/750]	BT 1.206 (1.579)	DT 1.177 (1.533)	loss 7.793 (7.793)	prob 3.399 (3.399)	GS 29.438 (29.438)	mem 41.935
Train: [16][30/750]	BT 0.048 (1.738)	DT 0.003 (1.693)	loss 8.499 (8.499)	prob 4.042 (4.042)	GS 30.734 (30.734)	mem 42.071
Train: [16][35/750]	BT 0.084 (1.500)	DT 0.012 (1.453)	loss 8.354 (8.354)	prob 3.340 (3.340)	GS 32.750 (32.750)	mem 42.019
Train: [16][40/750]	BT 0.031 (1.657)	DT 0.001 (1.612)	loss 8.171 (8.171)	prob 4.083 (4.083)	GS 34.688 (34.688)	mem 42.154
Train: [16][45/750]	BT 0.053 (1.517)	DT 0.001 (1.472)	loss 8.365 (8.365)	prob 2.732 (2.732)	GS 32.562 (32.562)	mem 42.408
Train: [16][50/750]	BT 11.882 (1.608)	DT 11.850 (1.562)	loss 7.937 (7.937)	prob 4.231 (4.231)	GS 33.562 (33.562)	mem 42.396
Train: [16][55/750]	BT 0.107 (1.466)	DT 0.023 (1.420)	loss 7.849 (7.849)	prob 3.245 (3.245)	GS 29.641 (29.641)	mem 42.347
Train: [16][60/750]	BT 0.043 (1.423)	DT 0.010 (1.375)	loss 8.097 (8.097)	prob 3.670 (3.670)	GS 32.109 (32.109)	mem 42.373
Train: [16][65/750]	BT 0.032 (1.477)	DT 0.001 (1.429)	loss 8.099 (8.099)	prob 2.779 (2.779)	GS 31.359 (31.359)	mem 42.584
Train: [16][70/750]	BT 0.043 (1.407)	DT 0.001 (1.359)	loss 8.472 (8.472)	prob 3.164 (3.164)	GS 35.547 (35.547)	mem 42.599
Train: [16][75/750]	BT 0.032 (1.427)	DT 0.002 (1.380)	loss 8.169 (8.169)	prob 3.742 (3.742)	GS 31.656 (31.656)	mem 42.680
Train: [16][80/750]	BT 5.393 (1.407)	DT 5.344 (1.360)	loss 8.529 (8.529)	prob 3.218 (3.218)	GS 37.000 (37.000)	mem 42.678
Train: [16][85/750]	BT 0.032 (1.326)	DT 0.001 (1.281)	loss 7.570 (7.570)	prob 4.322 (4.322)	GS 35.922 (35.922)	mem 42.692
Train: [16][90/750]	BT 0.037 (1.351)	DT 0.001 (1.306)	loss 7.728 (7.728)	prob 3.759 (3.759)	GS 29.766 (29.766)	mem 42.719
Train: [16][95/750]	BT 0.067 (1.301)	DT 0.015 (1.255)	loss 7.983 (7.983)	prob 3.073 (3.073)	GS 32.906 (32.906)	mem 42.782
Train: [16][100/750]	BT 0.023 (1.368)	DT 0.001 (1.323)	loss 8.523 (8.523)	prob 3.689 (3.689)	GS 29.828 (29.828)	mem 42.737
Train: [16][105/750]	BT 0.083 (1.332)	DT 0.020 (1.286)	loss 7.789 (7.789)	prob 3.196 (3.196)	GS 32.953 (32.953)	mem 42.841
Train: [16][110/750]	BT 9.606 (1.362)	DT 9.539 (1.314)	loss 8.484 (8.484)	prob 3.904 (3.904)	GS 30.891 (30.891)	mem 42.752
Train: [16][115/750]	BT 0.087 (1.305)	DT 0.009 (1.257)	loss 8.576 (8.576)	prob 2.427 (2.427)	GS 35.094 (35.094)	mem 42.754
Train: [16][120/750]	BT 0.073 (1.263)	DT 0.002 (1.215)	loss 8.673 (8.673)	prob 2.827 (2.827)	GS 36.891 (36.891)	mem 42.760
Train: [16][125/750]	BT 0.035 (1.307)	DT 0.003 (1.260)	loss 8.211 (8.211)	prob 2.712 (2.712)	GS 33.750 (33.750)	mem 42.792
Train: [16][130/750]	BT 0.053 (1.264)	DT 0.014 (1.217)	loss 8.213 (8.213)	prob 3.157 (3.157)	GS 35.391 (35.391)	mem 42.733
Train: [16][135/750]	BT 0.050 (1.304)	DT 0.015 (1.257)	loss 7.741 (7.741)	prob 3.686 (3.686)	GS 21.031 (21.031)	mem 42.803
Train: [16][140/750]	BT 2.695 (1.278)	DT 2.629 (1.231)	loss 8.135 (8.135)	prob 3.440 (3.440)	GS 34.891 (34.891)	mem 42.840
Train: [16][145/750]	BT 0.049 (1.235)	DT 0.002 (1.189)	loss 7.796 (7.796)	prob 3.466 (3.466)	GS 30.953 (30.953)	mem 42.841
Train: [16][150/750]	BT 0.032 (1.252)	DT 0.002 (1.206)	loss 8.025 (8.025)	prob 2.781 (2.781)	GS 30.375 (30.375)	mem 42.780
Train: [16][155/750]	BT 0.091 (1.262)	DT 0.002 (1.215)	loss 7.668 (7.668)	prob 2.648 (2.648)	GS 32.391 (32.391)	mem 42.870
Train: [16][160/750]	BT 0.034 (1.248)	DT 0.001 (1.202)	loss 8.375 (8.375)	prob 3.560 (3.560)	GS 31.891 (31.891)	mem 42.830
Train: [16][165/750]	BT 0.124 (1.248)	DT 0.013 (1.202)	loss 7.890 (7.890)	prob 2.186 (2.186)	GS 30.844 (30.844)	mem 42.878
Train: [16][170/750]	BT 6.264 (1.250)	DT 6.233 (1.204)	loss 8.031 (8.031)	prob 3.252 (3.252)	GS 36.797 (36.797)	mem 42.914
Train: [16][175/750]	BT 0.086 (1.215)	DT 0.032 (1.170)	loss 8.354 (8.354)	prob 2.357 (2.357)	GS 37.078 (37.078)	mem 43.010
Train: [16][180/750]	BT 0.066 (1.235)	DT 0.003 (1.189)	loss 8.437 (8.437)	prob 2.638 (2.638)	GS 37.438 (37.438)	mem 42.890
Train: [16][185/750]	BT 0.045 (1.219)	DT 0.002 (1.173)	loss 8.562 (8.562)	prob 2.243 (2.243)	GS 29.141 (29.141)	mem 42.941
Train: [16][190/750]	BT 0.067 (1.248)	DT 0.002 (1.201)	loss 8.461 (8.461)	prob 2.230 (2.230)	GS 35.078 (35.078)	mem 42.906
Train: [16][195/750]	BT 0.023 (1.217)	DT 0.001 (1.171)	loss 7.572 (7.572)	prob 2.963 (2.963)	GS 30.219 (30.219)	mem 42.873
Train: [16][200/750]	BT 12.700 (1.251)	DT 12.670 (1.205)	loss 8.267 (8.267)	prob 2.530 (2.530)	GS 35.219 (35.219)	mem 42.856
Train: [16][205/750]	BT 0.070 (1.222)	DT 0.003 (1.176)	loss 9.648 (9.648)	prob 0.352 (0.352)	GS 28.891 (28.891)	mem 42.859
Train: [16][210/750]	BT 0.033 (1.202)	DT 0.001 (1.157)	loss 7.787 (7.787)	prob 3.228 (3.228)	GS 30.375 (30.375)	mem 42.933
Train: [16][215/750]	BT 0.054 (1.223)	DT 0.009 (1.177)	loss 8.920 (8.920)	prob 1.342 (1.342)	GS 34.938 (34.938)	mem 43.045
Train: [16][220/750]	BT 0.055 (1.215)	DT 0.015 (1.169)	loss 8.235 (8.235)	prob 1.983 (1.983)	GS 34.922 (34.922)	mem 42.921
Train: [16][225/750]	BT 0.038 (1.234)	DT 0.007 (1.187)	loss 8.142 (8.142)	prob 1.338 (1.338)	GS 29.359 (29.359)	mem 43.023
Train: [16][230/750]	BT 3.863 (1.224)	DT 3.809 (1.178)	loss 9.802 (9.802)	prob 2.079 (2.079)	GS 33.875 (33.875)	mem 42.979
Train: [16][235/750]	BT 0.099 (1.199)	DT 0.010 (1.153)	loss 7.673 (7.673)	prob 2.093 (2.093)	GS 28.922 (28.922)	mem 42.980
Train: [16][240/750]	BT 0.033 (1.216)	DT 0.002 (1.169)	loss 8.659 (8.659)	prob 2.053 (2.053)	GS 31.266 (31.266)	mem 42.994
Train: [16][245/750]	BT 0.063 (1.210)	DT 0.008 (1.164)	loss 8.291 (8.291)	prob 1.947 (1.947)	GS 30.484 (30.484)	mem 42.953
Train: [16][250/750]	BT 0.057 (1.221)	DT 0.025 (1.175)	loss 8.662 (8.662)	prob 2.685 (2.685)	GS 35.359 (35.359)	mem 43.045
Train: [16][255/750]	BT 0.034 (1.206)	DT 0.003 (1.160)	loss 8.041 (8.041)	prob 1.598 (1.598)	GS 31.969 (31.969)	mem 43.051
Train: [16][260/750]	BT 11.294 (1.227)	DT 11.250 (1.181)	loss 8.371 (8.371)	prob 3.297 (3.297)	GS 35.547 (35.547)	mem 42.963
Train: [16][265/750]	BT 0.080 (1.205)	DT 0.006 (1.159)	loss 8.302 (8.302)	prob 1.399 (1.399)	GS 29.125 (29.125)	mem 42.964
Train: [16][270/750]	BT 0.053 (1.194)	DT 0.001 (1.148)	loss 8.448 (8.448)	prob 2.596 (2.596)	GS 36.125 (36.125)	mem 42.948
Train: [16][275/750]	BT 0.028 (1.217)	DT 0.001 (1.171)	loss 7.974 (7.974)	prob 1.960 (1.960)	GS 29.344 (29.344)	mem 42.898
Train: [16][280/750]	BT 0.033 (1.196)	DT 0.001 (1.150)	loss 8.360 (8.360)	prob 1.136 (1.136)	GS 34.203 (34.203)	mem 42.900
Train: [16][285/750]	BT 0.065 (1.220)	DT 0.014 (1.174)	loss 8.140 (8.140)	prob 1.856 (1.856)	GS 33.234 (33.234)	mem 42.854
Train: [16][290/750]	BT 0.069 (1.200)	DT 0.001 (1.154)	loss 8.391 (8.391)	prob 2.038 (2.038)	GS 36.000 (36.000)	mem 42.858
Train: [16][295/750]	BT 0.031 (1.180)	DT 0.001 (1.135)	loss 8.652 (8.652)	prob 0.746 (0.746)	GS 34.094 (34.094)	mem 42.858
Train: [16][300/750]	BT 0.039 (1.203)	DT 0.003 (1.157)	loss 8.521 (8.521)	prob 2.331 (2.331)	GS 36.188 (36.188)	mem 42.963
Train: [16][305/750]	BT 0.026 (1.184)	DT 0.001 (1.138)	loss 8.053 (8.053)	prob 1.246 (1.246)	GS 28.016 (28.016)	mem 42.942
Train: [16][310/750]	BT 0.072 (1.214)	DT 0.003 (1.168)	loss 8.524 (8.524)	prob 1.838 (1.838)	GS 30.766 (30.766)	mem 43.000
Train: [16][315/750]	BT 0.024 (1.196)	DT 0.001 (1.150)	loss 8.057 (8.057)	prob 1.398 (1.398)	GS 33.703 (33.703)	mem 43.002
Train: [16][320/750]	BT 13.835 (1.221)	DT 13.801 (1.175)	loss 8.962 (8.962)	prob 3.197 (3.197)	GS 31.422 (31.422)	mem 43.005
Train: [16][325/750]	BT 0.048 (1.203)	DT 0.002 (1.157)	loss 8.531 (8.531)	prob 1.827 (1.827)	GS 31.422 (31.422)	mem 42.904
Train: [16][330/750]	BT 0.030 (1.185)	DT 0.001 (1.140)	loss 9.212 (9.212)	prob 1.754 (1.754)	GS 34.734 (34.734)	mem 42.982
Train: [16][335/750]	BT 0.028 (1.206)	DT 0.001 (1.160)	loss 8.226 (8.226)	prob 2.062 (2.062)	GS 35.234 (35.234)	mem 42.956
Train: [16][340/750]	BT 0.035 (1.188)	DT 0.011 (1.143)	loss 8.564 (8.564)	prob 1.890 (1.890)	GS 33.750 (33.750)	mem 42.956
Train: [16][345/750]	BT 0.023 (1.209)	DT 0.001 (1.164)	loss 8.256 (8.256)	prob 0.888 (0.888)	GS 27.375 (27.375)	mem 43.002
Train: [16][350/750]	BT 0.048 (1.192)	DT 0.001 (1.147)	loss 8.442 (8.442)	prob 2.960 (2.960)	GS 33.234 (33.234)	mem 43.002
Train: [16][355/750]	BT 0.035 (1.176)	DT 0.001 (1.131)	loss 8.969 (8.969)	prob 1.274 (1.274)	GS 34.281 (34.281)	mem 43.003
Train: [16][360/750]	BT 0.071 (1.199)	DT 0.007 (1.154)	loss 8.576 (8.576)	prob 2.054 (2.054)	GS 35.766 (35.766)	mem 43.041
Train: [16][365/750]	BT 0.030 (1.183)	DT 0.001 (1.138)	loss 7.847 (7.847)	prob 2.907 (2.907)	GS 34.516 (34.516)	mem 43.039
Train: [16][370/750]	BT 0.037 (1.194)	DT 0.001 (1.150)	loss 9.279 (9.279)	prob 0.910 (0.910)	GS 33.047 (33.047)	mem 43.062
Train: [16][375/750]	BT 0.053 (1.179)	DT 0.008 (1.135)	loss 8.246 (8.246)	prob 2.015 (2.015)	GS 33.562 (33.562)	mem 43.062
Train: [16][380/750]	BT 10.278 (1.191)	DT 10.161 (1.146)	loss 7.828 (7.828)	prob 3.324 (3.324)	GS 31.031 (31.031)	mem 43.065
Train: [16][385/750]	BT 0.037 (1.176)	DT 0.002 (1.132)	loss 8.017 (8.017)	prob 2.651 (2.651)	GS 31.938 (31.938)	mem 43.065
Train: [16][390/750]	BT 0.080 (1.162)	DT 0.011 (1.117)	loss 9.149 (9.149)	prob 3.214 (3.214)	GS 29.766 (29.766)	mem 43.066
Train: [16][395/750]	BT 0.029 (1.177)	DT 0.001 (1.133)	loss 8.159 (8.159)	prob 2.582 (2.582)	GS 29.969 (29.969)	mem 43.041
Train: [16][400/750]	BT 0.054 (1.164)	DT 0.007 (1.119)	loss 8.310 (8.310)	prob 1.681 (1.681)	GS 35.609 (35.609)	mem 43.041
Train: [16][405/750]	BT 0.071 (1.184)	DT 0.001 (1.140)	loss 9.049 (9.049)	prob 0.661 (0.661)	GS 33.969 (33.969)	mem 43.027
Train: [16][410/750]	BT 0.101 (1.171)	DT 0.026 (1.126)	loss 8.863 (8.863)	prob 2.742 (2.742)	GS 35.219 (35.219)	mem 43.072
Train: [16][415/750]	BT 0.055 (1.158)	DT 0.010 (1.112)	loss 7.936 (7.936)	prob 2.559 (2.559)	GS 28.156 (28.156)	mem 43.047
Train: [16][420/750]	BT 0.050 (1.177)	DT 0.001 (1.132)	loss 8.920 (8.920)	prob 1.994 (1.994)	GS 34.578 (34.578)	mem 43.094
Train: [16][425/750]	BT 0.026 (1.164)	DT 0.001 (1.119)	loss 9.274 (9.274)	prob 0.725 (0.725)	GS 27.125 (27.125)	mem 42.974
Train: [16][430/750]	BT 0.057 (1.175)	DT 0.003 (1.130)	loss 9.586 (9.586)	prob 1.928 (1.928)	GS 35.672 (35.672)	mem 43.100
Train: [16][435/750]	BT 0.043 (1.162)	DT 0.002 (1.117)	loss 8.392 (8.392)	prob 2.515 (2.515)	GS 31.953 (31.953)	mem 43.078
Train: [16][440/750]	BT 16.594 (1.187)	DT 16.555 (1.142)	loss 8.764 (8.764)	prob 2.367 (2.367)	GS 36.281 (36.281)	mem 43.085
Train: [16][445/750]	BT 0.086 (1.174)	DT 0.005 (1.129)	loss 8.824 (8.824)	prob 2.115 (2.115)	GS 30.266 (30.266)	mem 43.053
Train: [16][450/750]	BT 0.025 (1.162)	DT 0.001 (1.116)	loss 8.331 (8.331)	prob 2.548 (2.548)	GS 33.688 (33.688)	mem 43.056
Train: [16][455/750]	BT 0.044 (1.179)	DT 0.007 (1.134)	loss 8.284 (8.284)	prob 3.663 (3.663)	GS 31.531 (31.531)	mem 43.110
Train: [16][460/750]	BT 0.028 (1.167)	DT 0.001 (1.122)	loss 8.696 (8.696)	prob 1.926 (1.926)	GS 35.812 (35.812)	mem 43.111
Train: [16][465/750]	BT 0.067 (1.188)	DT 0.022 (1.143)	loss 8.839 (8.839)	prob 1.523 (1.523)	GS 29.062 (29.062)	mem 43.047
Train: [16][470/750]	BT 0.053 (1.176)	DT 0.017 (1.131)	loss 8.989 (8.989)	prob 2.594 (2.594)	GS 32.344 (32.344)	mem 42.983
Train: [16][475/750]	BT 0.048 (1.164)	DT 0.003 (1.119)	loss 8.764 (8.764)	prob 2.477 (2.477)	GS 32.031 (32.031)	mem 42.985
Train: [16][480/750]	BT 0.055 (1.174)	DT 0.009 (1.129)	loss 8.246 (8.246)	prob 3.596 (3.596)	GS 33.984 (33.984)	mem 43.001
Train: [16][485/750]	BT 0.028 (1.163)	DT 0.001 (1.118)	loss 8.281 (8.281)	prob 2.309 (2.309)	GS 30.797 (30.797)	mem 43.089
Train: [16][490/750]	BT 0.022 (1.175)	DT 0.001 (1.130)	loss 8.477 (8.477)	prob 3.046 (3.046)	GS 33.938 (33.938)	mem 42.954
Train: [16][495/750]	BT 0.040 (1.164)	DT 0.004 (1.119)	loss 8.964 (8.964)	prob 2.232 (2.232)	GS 34.031 (34.031)	mem 42.954
Train: [16][500/750]	BT 9.147 (1.171)	DT 9.120 (1.126)	loss 7.928 (7.928)	prob 3.864 (3.864)	GS 29.688 (29.688)	mem 43.083
Train: [16][505/750]	BT 0.049 (1.160)	DT 0.009 (1.115)	loss 7.988 (7.988)	prob 3.811 (3.811)	GS 34.641 (34.641)	mem 43.084
Train: [16][510/750]	BT 0.092 (1.149)	DT 0.012 (1.104)	loss 8.384 (8.384)	prob 3.589 (3.589)	GS 32.984 (32.984)	mem 43.149
Train: [16][515/750]	BT 0.064 (1.161)	DT 0.002 (1.116)	loss 8.573 (8.573)	prob 3.153 (3.153)	GS 33.172 (33.172)	mem 43.041
Train: [16][520/750]	BT 0.024 (1.150)	DT 0.001 (1.105)	loss 8.354 (8.354)	prob 3.711 (3.711)	GS 33.766 (33.766)	mem 43.044
Train: [16][525/750]	BT 0.034 (1.169)	DT 0.010 (1.124)	loss 7.899 (7.899)	prob 3.420 (3.420)	GS 32.984 (32.984)	mem 43.085
Train: [16][530/750]	BT 0.028 (1.158)	DT 0.001 (1.114)	loss 9.296 (9.296)	prob 2.787 (2.787)	GS 30.938 (30.938)	mem 43.092
Train: [16][535/750]	BT 0.041 (1.149)	DT 0.009 (1.104)	loss 8.501 (8.501)	prob 2.453 (2.453)	GS 32.547 (32.547)	mem 43.133
Train: [16][540/750]	BT 0.025 (1.159)	DT 0.001 (1.114)	loss 8.054 (8.054)	prob 3.357 (3.357)	GS 30.141 (30.141)	mem 43.151
Train: [16][545/750]	BT 0.052 (1.149)	DT 0.007 (1.104)	loss 8.383 (8.383)	prob 3.098 (3.098)	GS 30.562 (30.562)	mem 43.148
Train: [16][550/750]	BT 0.034 (1.161)	DT 0.003 (1.116)	loss 8.458 (8.458)	prob 4.549 (4.549)	GS 30.656 (30.656)	mem 43.110
Train: [16][555/750]	BT 0.066 (1.151)	DT 0.027 (1.106)	loss 8.222 (8.222)	prob 3.171 (3.171)	GS 29.047 (29.047)	mem 43.214
Train: [16][560/750]	BT 8.726 (1.157)	DT 8.645 (1.112)	loss 8.666 (8.666)	prob 3.609 (3.609)	GS 36.562 (36.562)	mem 43.205
Train: [16][565/750]	BT 0.049 (1.147)	DT 0.010 (1.102)	loss 7.968 (7.968)	prob 3.129 (3.129)	GS 31.688 (31.688)	mem 43.146
Train: [16][570/750]	BT 2.432 (1.142)	DT 2.376 (1.097)	loss 7.692 (7.692)	prob 4.443 (4.443)	GS 28.531 (28.531)	mem 43.091
Train: [16][575/750]	BT 0.048 (1.151)	DT 0.004 (1.105)	loss 8.054 (8.054)	prob 3.425 (3.425)	GS 30.000 (30.000)	mem 43.080
Train: [16][580/750]	BT 0.032 (1.141)	DT 0.001 (1.096)	loss 8.134 (8.134)	prob 4.929 (4.929)	GS 35.312 (35.312)	mem 43.096
Train: [16][585/750]	BT 0.030 (1.154)	DT 0.001 (1.108)	loss 8.871 (8.871)	prob 2.235 (2.235)	GS 32.328 (32.328)	mem 42.975
Train: [16][590/750]	BT 0.088 (1.144)	DT 0.005 (1.099)	loss 8.246 (8.246)	prob 4.197 (4.197)	GS 34.484 (34.484)	mem 43.060
Train: [16][595/750]	BT 0.040 (1.146)	DT 0.001 (1.100)	loss 8.616 (8.616)	prob 2.839 (2.839)	GS 34.359 (34.359)	mem 43.174
Train: [16][600/750]	BT 0.029 (1.152)	DT 0.001 (1.106)	loss 8.016 (8.016)	prob 4.094 (4.094)	GS 32.031 (32.031)	mem 43.153
Train: [16][605/750]	BT 0.061 (1.143)	DT 0.013 (1.098)	loss 8.651 (8.651)	prob 2.897 (2.897)	GS 28.875 (28.875)	mem 43.094
Train: [16][610/750]	BT 0.022 (1.158)	DT 0.001 (1.113)	loss 8.257 (8.257)	prob 3.553 (3.553)	GS 35.156 (35.156)	mem 43.034
Train: [16][615/750]	BT 0.029 (1.149)	DT 0.001 (1.104)	loss 8.311 (8.311)	prob 3.647 (3.647)	GS 30.188 (30.188)	mem 43.047
Train: [16][620/750]	BT 9.546 (1.158)	DT 9.522 (1.113)	loss 7.854 (7.854)	prob 3.800 (3.800)	GS 35.469 (35.469)	mem 43.049
Train: [16][625/750]	BT 0.029 (1.149)	DT 0.001 (1.104)	loss 8.353 (8.353)	prob 2.608 (2.608)	GS 28.797 (28.797)	mem 43.049
Train: [16][630/750]	BT 1.294 (1.142)	DT 1.256 (1.097)	loss 8.272 (8.272)	prob 3.768 (3.768)	GS 29.359 (29.359)	mem 43.207
Train: [16][635/750]	BT 0.034 (1.153)	DT 0.001 (1.108)	loss 8.634 (8.634)	prob 3.199 (3.199)	GS 32.797 (32.797)	mem 43.072
Train: [16][640/750]	BT 0.024 (1.144)	DT 0.001 (1.099)	loss 8.459 (8.459)	prob 4.741 (4.741)	GS 35.938 (35.938)	mem 43.073
Train: [16][645/750]	BT 0.028 (1.154)	DT 0.002 (1.109)	loss 7.966 (7.966)	prob 4.217 (4.217)	GS 31.344 (31.344)	mem 43.112
Train: [16][650/750]	BT 0.031 (1.146)	DT 0.002 (1.101)	loss 8.944 (8.944)	prob 3.661 (3.661)	GS 33.938 (33.938)	mem 43.130
Train: [16][655/750]	BT 0.033 (1.137)	DT 0.001 (1.092)	loss 7.998 (7.998)	prob 3.632 (3.632)	GS 30.859 (30.859)	mem 43.066
arpack error, retry= 0
arpack error, retry= 0
Train: [16][660/750]	BT 0.033 (1.151)	DT 0.002 (1.106)	loss 8.289 (8.289)	prob 3.847 (3.847)	GS 34.219 (34.219)	mem 43.080
Train: [16][665/750]	BT 0.033 (1.143)	DT 0.002 (1.098)	loss 8.101 (8.101)	prob 3.542 (3.542)	GS 27.359 (27.359)	mem 43.026
Train: [16][670/750]	BT 0.032 (1.148)	DT 0.002 (1.104)	loss 8.957 (8.957)	prob 4.315 (4.315)	GS 33.000 (33.000)	mem 43.096
Train: [16][675/750]	BT 0.033 (1.140)	DT 0.002 (1.095)	loss 7.720 (7.720)	prob 4.719 (4.719)	GS 30.469 (30.469)	mem 43.133
Train: [16][680/750]	BT 7.706 (1.150)	DT 7.675 (1.106)	loss 8.247 (8.247)	prob 4.907 (4.907)	GS 34.922 (34.922)	mem 43.227
Train: [16][685/750]	BT 0.068 (1.142)	DT 0.015 (1.098)	loss 8.023 (8.023)	prob 3.465 (3.465)	GS 31.781 (31.781)	mem 43.247
Train: [16][690/750]	BT 8.739 (1.147)	DT 8.708 (1.102)	loss 8.270 (8.270)	prob 4.081 (4.081)	GS 36.422 (36.422)	mem 43.329
Train: [16][695/750]	BT 0.046 (1.143)	DT 0.015 (1.099)	loss 8.044 (8.044)	prob 3.866 (3.866)	GS 26.859 (26.859)	mem 43.117
Train: [16][700/750]	BT 0.039 (1.136)	DT 0.006 (1.091)	loss 8.348 (8.348)	prob 4.428 (4.428)	GS 32.531 (32.531)	mem 43.118
Train: [16][705/750]	BT 0.039 (1.147)	DT 0.002 (1.103)	loss 8.079 (8.079)	prob 4.038 (4.038)	GS 30.922 (30.922)	mem 43.177
Train: [16][710/750]	BT 0.045 (1.140)	DT 0.004 (1.095)	loss 8.307 (8.307)	prob 4.409 (4.409)	GS 34.594 (34.594)	mem 43.115
Train: [16][715/750]	BT 0.047 (1.142)	DT 0.006 (1.097)	loss 8.266 (8.266)	prob 3.233 (3.233)	GS 29.656 (29.656)	mem 43.120
Train: [16][720/750]	BT 0.045 (1.146)	DT 0.002 (1.101)	loss 8.217 (8.217)	prob 4.350 (4.350)	GS 32.250 (32.250)	mem 43.199
Train: [16][725/750]	BT 0.086 (1.139)	DT 0.020 (1.094)	loss 7.915 (7.915)	prob 3.948 (3.948)	GS 32.156 (32.156)	mem 43.150
Train: [16][730/750]	BT 0.046 (1.145)	DT 0.006 (1.100)	loss 7.389 (7.389)	prob 4.076 (4.076)	GS 31.844 (31.844)	mem 42.641
Train: [16][735/750]	BT 0.035 (1.137)	DT 0.007 (1.093)	loss 8.934 (8.934)	prob 2.528 (2.528)	GS 32.266 (32.266)	mem 42.642
Train: [16][740/750]	BT 4.785 (1.138)	DT 4.748 (1.094)	loss 8.269 (8.269)	prob 3.889 (3.889)	GS 32.953 (32.953)	mem 13.685
Train: [16][745/750]	BT 0.034 (1.131)	DT 0.001 (1.086)	loss 7.480 (7.480)	prob 3.774 (3.774)	GS 29.594 (29.594)	mem 13.723
Train: [16][750/750]	BT 0.023 (1.124)	DT 0.001 (1.079)	loss 8.081 (8.081)	prob 4.474 (4.474)	GS 31.281 (31.281)	mem 13.687
Train: [16][755/750]	BT 0.020 (1.119)	DT 0.001 (1.075)	loss 7.302 (7.302)	prob 4.695 (4.695)	GS 28.250 (28.250)	mem 10.677
epoch 16, total time 845.19
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [17][1/750]	BT 25.481 (25.481)	DT 25.411 (25.411)	loss 7.468 (7.468)	prob 3.820 (3.820)	GS 31.547 (31.547)	mem 41.704
Train: [17][5/750]	BT 0.032 (5.121)	DT 0.001 (5.083)	loss 8.326 (8.326)	prob 3.125 (3.125)	GS 31.938 (31.938)	mem 41.706
Train: [17][10/750]	BT 0.088 (2.769)	DT 0.002 (2.717)	loss 7.654 (7.654)	prob 4.409 (4.409)	GS 30.641 (30.641)	mem 41.812
Train: [17][15/750]	BT 0.049 (2.385)	DT 0.014 (2.338)	loss 7.963 (7.963)	prob 3.901 (3.901)	GS 29.906 (29.906)	mem 42.392
Train: [17][20/750]	BT 6.274 (2.180)	DT 6.213 (2.131)	loss 8.062 (8.062)	prob 4.157 (4.157)	GS 35.656 (35.656)	mem 42.500
Train: [17][25/750]	BT 2.509 (1.854)	DT 2.435 (1.802)	loss 7.866 (7.866)	prob 3.996 (3.996)	GS 33.297 (33.297)	mem 42.391
Train: [17][30/750]	BT 0.033 (1.610)	DT 0.001 (1.561)	loss 8.106 (8.106)	prob 4.184 (4.184)	GS 33.094 (33.094)	mem 42.520
Train: [17][35/750]	BT 0.132 (1.672)	DT 0.025 (1.621)	loss 8.076 (8.076)	prob 3.993 (3.993)	GS 34.078 (34.078)	mem 42.520
Train: [17][40/750]	BT 3.914 (1.617)	DT 3.883 (1.566)	loss 7.894 (7.894)	prob 4.756 (4.756)	GS 33.438 (33.438)	mem 42.782
Train: [17][45/750]	BT 0.060 (1.637)	DT 0.010 (1.587)	loss 9.155 (9.155)	prob 2.972 (2.972)	GS 29.016 (29.016)	mem 42.564
Train: [17][50/750]	BT 0.038 (1.477)	DT 0.006 (1.429)	loss 7.997 (7.997)	prob 4.574 (4.574)	GS 33.250 (33.250)	mem 42.570
Train: [17][55/750]	BT 0.087 (1.418)	DT 0.001 (1.370)	loss 7.886 (7.886)	prob 4.478 (4.478)	GS 29.203 (29.203)	mem 42.737
Train: [17][60/750]	BT 0.065 (1.479)	DT 0.001 (1.431)	loss 8.073 (8.073)	prob 3.962 (3.962)	GS 31.062 (31.062)	mem 42.691
Train: [17][65/750]	BT 0.048 (1.369)	DT 0.008 (1.322)	loss 8.088 (8.088)	prob 4.107 (4.107)	GS 30.672 (30.672)	mem 42.692
Train: [17][70/750]	BT 0.048 (1.486)	DT 0.010 (1.439)	loss 8.250 (8.250)	prob 3.923 (3.923)	GS 34.094 (34.094)	mem 42.722
Train: [17][75/750]	BT 0.058 (1.389)	DT 0.008 (1.344)	loss 8.198 (8.198)	prob 3.475 (3.475)	GS 31.406 (31.406)	mem 42.722
Train: [17][80/750]	BT 9.319 (1.467)	DT 9.275 (1.421)	loss 8.254 (8.254)	prob 3.983 (3.983)	GS 38.203 (38.203)	mem 42.758
Train: [17][85/750]	BT 0.033 (1.383)	DT 0.001 (1.337)	loss 8.036 (8.036)	prob 4.606 (4.606)	GS 29.422 (29.422)	mem 42.685
Train: [17][90/750]	BT 0.045 (1.349)	DT 0.002 (1.302)	loss 7.624 (7.624)	prob 4.052 (4.052)	GS 33.984 (33.984)	mem 42.699
Train: [17][95/750]	BT 0.069 (1.376)	DT 0.009 (1.328)	loss 8.112 (8.112)	prob 4.298 (4.298)	GS 31.047 (31.047)	mem 42.991
Train: [17][100/750]	BT 0.050 (1.310)	DT 0.010 (1.262)	loss 8.619 (8.619)	prob 3.653 (3.653)	GS 30.984 (30.984)	mem 42.842
Train: [17][105/750]	BT 0.032 (1.364)	DT 0.007 (1.316)	loss 7.793 (7.793)	prob 3.969 (3.969)	GS 30.969 (30.969)	mem 42.836
Train: [17][110/750]	BT 0.050 (1.304)	DT 0.001 (1.257)	loss 8.017 (8.017)	prob 4.073 (4.073)	GS 36.125 (36.125)	mem 42.860
Train: [17][115/750]	BT 0.028 (1.253)	DT 0.001 (1.206)	loss 8.522 (8.522)	prob 3.613 (3.613)	GS 34.125 (34.125)	mem 42.720
Train: [17][120/750]	BT 0.035 (1.311)	DT 0.003 (1.264)	loss 7.863 (7.863)	prob 4.264 (4.264)	GS 34.422 (34.422)	mem 42.877
Train: [17][125/750]	BT 0.035 (1.260)	DT 0.004 (1.214)	loss 7.611 (7.611)	prob 4.140 (4.140)	GS 31.109 (31.109)	mem 42.878
Train: [17][130/750]	BT 0.026 (1.308)	DT 0.001 (1.262)	loss 7.840 (7.840)	prob 3.936 (3.936)	GS 35.969 (35.969)	mem 42.843
Train: [17][135/750]	BT 0.042 (1.262)	DT 0.001 (1.216)	loss 7.413 (7.413)	prob 4.143 (4.143)	GS 28.438 (28.438)	mem 42.858
Train: [17][140/750]	BT 9.928 (1.303)	DT 9.885 (1.257)	loss 8.399 (8.399)	prob 4.206 (4.206)	GS 35.562 (35.562)	mem 42.935
Train: [17][145/750]	BT 0.062 (1.260)	DT 0.009 (1.214)	loss 8.667 (8.667)	prob 2.949 (2.949)	GS 31.719 (31.719)	mem 42.972
Train: [17][150/750]	BT 0.031 (1.238)	DT 0.001 (1.192)	loss 8.039 (8.039)	prob 4.141 (4.141)	GS 29.922 (29.922)	mem 42.874
Train: [17][155/750]	BT 0.038 (1.267)	DT 0.001 (1.221)	loss 8.503 (8.503)	prob 3.437 (3.437)	GS 33.969 (33.969)	mem 42.866
Train: [17][160/750]	BT 0.042 (1.229)	DT 0.016 (1.183)	loss 7.917 (7.917)	prob 3.058 (3.058)	GS 34.656 (34.656)	mem 42.867
Train: [17][165/750]	BT 0.033 (1.261)	DT 0.002 (1.216)	loss 8.326 (8.326)	prob 3.268 (3.268)	GS 32.781 (32.781)	mem 43.060
Train: [17][170/750]	BT 0.044 (1.225)	DT 0.002 (1.180)	loss 8.181 (8.181)	prob 4.027 (4.027)	GS 32.578 (32.578)	mem 43.181
Train: [17][175/750]	BT 0.060 (1.192)	DT 0.023 (1.147)	loss 7.918 (7.918)	prob 3.162 (3.162)	GS 28.672 (28.672)	mem 42.892
Train: [17][180/750]	BT 0.035 (1.223)	DT 0.001 (1.178)	loss 7.777 (7.777)	prob 3.985 (3.985)	GS 36.188 (36.188)	mem 42.925
Train: [17][185/750]	BT 0.041 (1.193)	DT 0.002 (1.148)	loss 7.690 (7.690)	prob 3.261 (3.261)	GS 31.172 (31.172)	mem 42.925
Train: [17][190/750]	BT 0.022 (1.233)	DT 0.001 (1.188)	loss 8.022 (8.022)	prob 4.143 (4.143)	GS 31.234 (31.234)	mem 42.996
Train: [17][195/750]	BT 0.032 (1.202)	DT 0.001 (1.158)	loss 8.470 (8.470)	prob 2.755 (2.755)	GS 31.578 (31.578)	mem 42.997
Train: [17][200/750]	BT 10.518 (1.231)	DT 10.462 (1.186)	loss 8.169 (8.169)	prob 3.287 (3.287)	GS 37.359 (37.359)	mem 43.023
Train: [17][205/750]	BT 0.037 (1.202)	DT 0.002 (1.157)	loss 8.115 (8.115)	prob 2.499 (2.499)	GS 31.406 (31.406)	mem 43.024
Train: [17][210/750]	BT 0.121 (1.194)	DT 0.002 (1.150)	loss 7.651 (7.651)	prob 3.626 (3.626)	GS 30.688 (30.688)	mem 43.087
Train: [17][215/750]	BT 0.065 (1.205)	DT 0.027 (1.159)	loss 8.085 (8.085)	prob 2.411 (2.411)	GS 33.344 (33.344)	mem 43.045
Train: [17][220/750]	BT 3.516 (1.199)	DT 3.483 (1.154)	loss 8.034 (8.034)	prob 2.334 (2.334)	GS 35.156 (35.156)	mem 42.997
Train: [17][225/750]	BT 0.119 (1.191)	DT 0.003 (1.145)	loss 7.698 (7.698)	prob 3.294 (3.294)	GS 32.062 (32.062)	mem 43.536
Train: [17][230/750]	BT 2.078 (1.175)	DT 2.047 (1.129)	loss 8.535 (8.535)	prob 3.202 (3.202)	GS 28.844 (28.844)	mem 43.077
Train: [17][235/750]	BT 0.063 (1.190)	DT 0.004 (1.144)	loss 7.960 (7.960)	prob 2.378 (2.378)	GS 35.297 (35.297)	mem 42.915
Train: [17][240/750]	BT 0.038 (1.193)	DT 0.001 (1.148)	loss 7.763 (7.763)	prob 2.598 (2.598)	GS 33.516 (33.516)	mem 43.128
Train: [17][245/750]	BT 0.037 (1.196)	DT 0.002 (1.151)	loss 7.979 (7.979)	prob 2.262 (2.262)	GS 31.562 (31.562)	mem 42.974
Train: [17][250/750]	BT 0.034 (1.195)	DT 0.002 (1.150)	loss 8.227 (8.227)	prob 2.544 (2.544)	GS 35.953 (35.953)	mem 42.968
Train: [17][255/750]	BT 0.056 (1.173)	DT 0.010 (1.128)	loss 7.777 (7.777)	prob 2.011 (2.011)	GS 32.422 (32.422)	mem 42.934
Train: [17][260/750]	BT 7.036 (1.200)	DT 6.995 (1.155)	loss 7.971 (7.971)	prob 2.494 (2.494)	GS 31.156 (31.156)	mem 43.145
Train: [17][265/750]	BT 0.027 (1.178)	DT 0.004 (1.133)	loss 7.406 (7.406)	prob 3.515 (3.515)	GS 30.500 (30.500)	mem 43.204
Train: [17][270/750]	BT 0.053 (1.178)	DT 0.005 (1.132)	loss 7.945 (7.945)	prob 2.382 (2.382)	GS 32.297 (32.297)	mem 42.995
Train: [17][275/750]	BT 0.034 (1.178)	DT 0.001 (1.133)	loss 8.223 (8.223)	prob 2.139 (2.139)	GS 29.984 (29.984)	mem 43.132
Train: [17][280/750]	BT 10.937 (1.197)	DT 10.905 (1.151)	loss 8.875 (8.875)	prob 1.896 (1.896)	GS 34.969 (34.969)	mem 42.941
Train: [17][285/750]	BT 0.040 (1.186)	DT 0.002 (1.140)	loss 7.816 (7.816)	prob 2.151 (2.151)	GS 28.625 (28.625)	mem 42.951
Train: [17][290/750]	BT 0.079 (1.166)	DT 0.020 (1.121)	loss 8.098 (8.098)	prob 2.461 (2.461)	GS 33.453 (33.453)	mem 43.047
Train: [17][295/750]	BT 0.086 (1.184)	DT 0.016 (1.138)	loss 7.848 (7.848)	prob 1.401 (1.401)	GS 31.062 (31.062)	mem 43.356
Train: [17][300/750]	BT 0.088 (1.170)	DT 0.015 (1.124)	loss 7.998 (7.998)	prob 1.782 (1.782)	GS 35.688 (35.688)	mem 43.170
Train: [17][305/750]	BT 0.063 (1.186)	DT 0.007 (1.140)	loss 7.630 (7.630)	prob 1.536 (1.536)	GS 28.625 (28.625)	mem 43.093
Train: [17][310/750]	BT 0.036 (1.185)	DT 0.003 (1.139)	loss 8.960 (8.960)	prob 2.146 (2.146)	GS 30.391 (30.391)	mem 43.140
Train: [17][315/750]	BT 0.032 (1.167)	DT 0.001 (1.121)	loss 7.834 (7.834)	prob 1.850 (1.850)	GS 28.484 (28.484)	mem 42.968
Train: [17][320/750]	BT 2.396 (1.188)	DT 2.366 (1.142)	loss 8.262 (8.262)	prob 2.361 (2.361)	GS 31.234 (31.234)	mem 43.064
Train: [17][325/750]	BT 0.040 (1.171)	DT 0.012 (1.125)	loss 8.982 (8.982)	prob 0.837 (0.837)	GS 35.328 (35.328)	mem 43.065
Train: [17][330/750]	BT 0.032 (1.185)	DT 0.001 (1.139)	loss 7.923 (7.923)	prob 2.533 (2.533)	GS 30.875 (30.875)	mem 43.079
Train: [17][335/750]	BT 0.091 (1.170)	DT 0.005 (1.124)	loss 7.781 (7.781)	prob 1.969 (1.969)	GS 38.375 (38.375)	mem 43.118
Train: [17][340/750]	BT 12.323 (1.190)	DT 12.266 (1.144)	loss 7.736 (7.736)	prob 2.328 (2.328)	GS 35.500 (35.500)	mem 43.021
Train: [17][345/750]	BT 0.039 (1.174)	DT 0.004 (1.127)	loss 7.686 (7.686)	prob 1.269 (1.269)	GS 33.953 (33.953)	mem 43.022
Train: [17][350/750]	BT 0.033 (1.158)	DT 0.003 (1.111)	loss 7.951 (7.951)	prob 2.071 (2.071)	GS 31.875 (31.875)	mem 43.029
Train: [17][355/750]	BT 0.055 (1.179)	DT 0.021 (1.133)	loss 8.600 (8.600)	prob 1.033 (1.033)	GS 30.172 (30.172)	mem 43.011
Train: [17][360/750]	BT 0.059 (1.163)	DT 0.012 (1.117)	loss 8.323 (8.323)	prob 1.938 (1.938)	GS 30.484 (30.484)	mem 42.978
Train: [17][365/750]	BT 0.125 (1.181)	DT 0.002 (1.135)	loss 8.270 (8.270)	prob 1.108 (1.108)	GS 29.703 (29.703)	mem 43.200
Train: [17][370/750]	BT 0.044 (1.167)	DT 0.012 (1.120)	loss 7.819 (7.819)	prob 2.542 (2.542)	GS 32.375 (32.375)	mem 43.293
Train: [17][375/750]	BT 0.054 (1.152)	DT 0.005 (1.105)	loss 7.752 (7.752)	prob 1.750 (1.750)	GS 30.969 (30.969)	mem 43.136
Train: [17][380/750]	BT 0.050 (1.170)	DT 0.004 (1.123)	loss 8.328 (8.328)	prob 2.419 (2.419)	GS 32.812 (32.812)	mem 42.999
Train: [17][385/750]	BT 0.031 (1.155)	DT 0.001 (1.109)	loss 8.017 (8.017)	prob 0.842 (0.842)	GS 28.812 (28.812)	mem 43.000
Train: [17][390/750]	BT 0.063 (1.171)	DT 0.012 (1.124)	loss 7.604 (7.604)	prob 1.775 (1.775)	GS 32.984 (32.984)	mem 43.322
Train: [17][395/750]	BT 0.038 (1.157)	DT 0.002 (1.110)	loss 7.859 (7.859)	prob 2.491 (2.491)	GS 30.844 (30.844)	mem 43.334
Train: [17][400/750]	BT 12.919 (1.175)	DT 12.872 (1.129)	loss 8.057 (8.057)	prob 1.737 (1.737)	GS 33.922 (33.922)	mem 42.930
Train: [17][405/750]	BT 0.072 (1.164)	DT 0.002 (1.118)	loss 7.959 (7.959)	prob 1.515 (1.515)	GS 30.641 (30.641)	mem 42.934
Train: [17][410/750]	BT 0.039 (1.150)	DT 0.001 (1.104)	loss 7.772 (7.772)	prob 2.181 (2.181)	GS 35.906 (35.906)	mem 42.936
Train: [17][415/750]	BT 0.072 (1.161)	DT 0.002 (1.115)	loss 8.447 (8.447)	prob 1.497 (1.497)	GS 33.328 (33.328)	mem 43.067
Train: [17][420/750]	BT 0.076 (1.156)	DT 0.007 (1.110)	loss 8.001 (8.001)	prob 2.544 (2.544)	GS 36.203 (36.203)	mem 43.209
Train: [17][425/750]	BT 0.038 (1.159)	DT 0.002 (1.112)	loss 8.662 (8.662)	prob 1.947 (1.947)	GS 31.750 (31.750)	mem 43.229
Train: [17][430/750]	BT 0.096 (1.168)	DT 0.020 (1.121)	loss 7.663 (7.663)	prob 2.379 (2.379)	GS 33.312 (33.312)	mem 43.087
Train: [17][435/750]	BT 0.033 (1.155)	DT 0.002 (1.109)	loss 7.846 (7.846)	prob 1.966 (1.966)	GS 30.297 (30.297)	mem 43.106
Train: [17][440/750]	BT 3.847 (1.164)	DT 3.815 (1.117)	loss 7.777 (7.777)	prob 3.285 (3.285)	GS 29.922 (29.922)	mem 42.990
Train: [17][445/750]	BT 0.032 (1.152)	DT 0.002 (1.105)	loss 8.362 (8.362)	prob 2.305 (2.305)	GS 26.625 (26.625)	mem 42.991
Train: [17][450/750]	BT 0.863 (1.162)	DT 0.825 (1.116)	loss 7.850 (7.850)	prob 2.379 (2.379)	GS 34.344 (34.344)	mem 43.167
Train: [17][455/750]	BT 0.043 (1.154)	DT 0.003 (1.107)	loss 7.800 (7.800)	prob 2.789 (2.789)	GS 33.141 (33.141)	mem 43.006
Train: [17][460/750]	BT 8.577 (1.164)	DT 8.519 (1.117)	loss 7.930 (7.930)	prob 2.734 (2.734)	GS 36.125 (36.125)	mem 43.213
Train: [17][465/750]	BT 0.063 (1.154)	DT 0.002 (1.107)	loss 8.441 (8.441)	prob 1.130 (1.130)	GS 43.688 (43.688)	mem 43.120
Train: [17][470/750]	BT 0.765 (1.146)	DT 0.730 (1.099)	loss 7.885 (7.885)	prob 2.899 (2.899)	GS 33.609 (33.609)	mem 43.050
Train: [17][475/750]	BT 0.035 (1.160)	DT 0.002 (1.113)	loss 8.797 (8.797)	prob 1.437 (1.437)	GS 36.203 (36.203)	mem 43.090
Train: [17][480/750]	BT 0.043 (1.152)	DT 0.010 (1.105)	loss 8.761 (8.761)	prob 2.224 (2.224)	GS 32.906 (32.906)	mem 43.064
Train: [17][485/750]	BT 0.040 (1.155)	DT 0.011 (1.108)	loss 7.959 (7.959)	prob 2.349 (2.349)	GS 34.266 (34.266)	mem 43.128
Train: [17][490/750]	BT 0.032 (1.158)	DT 0.002 (1.111)	loss 8.683 (8.683)	prob 2.737 (2.737)	GS 35.000 (35.000)	mem 43.126
Train: [17][495/750]	BT 0.053 (1.147)	DT 0.006 (1.100)	loss 8.226 (8.226)	prob 2.881 (2.881)	GS 31.297 (31.297)	mem 43.008
Train: [17][500/750]	BT 0.022 (1.166)	DT 0.001 (1.119)	loss 8.492 (8.492)	prob 2.850 (2.850)	GS 29.641 (29.641)	mem 42.971
Train: [17][505/750]	BT 0.052 (1.155)	DT 0.003 (1.108)	loss 8.095 (8.095)	prob 3.523 (3.523)	GS 46.141 (46.141)	mem 43.031
Train: [17][510/750]	BT 11.419 (1.172)	DT 11.377 (1.125)	loss 7.941 (7.941)	prob 2.445 (2.445)	GS 34.984 (34.984)	mem 43.078
Train: [17][515/750]	BT 0.034 (1.161)	DT 0.001 (1.114)	loss 8.517 (8.517)	prob 2.821 (2.821)	GS 38.156 (38.156)	mem 43.114
Train: [17][520/750]	BT 1.084 (1.152)	DT 1.044 (1.106)	loss 8.087 (8.087)	prob 3.526 (3.526)	GS 34.719 (34.719)	mem 43.074
Train: [17][525/750]	BT 0.079 (1.162)	DT 0.002 (1.116)	loss 8.244 (8.244)	prob 2.528 (2.528)	GS 32.844 (32.844)	mem 42.969
Train: [17][530/750]	BT 0.028 (1.152)	DT 0.001 (1.105)	loss 9.006 (9.006)	prob 2.534 (2.534)	GS 36.141 (36.141)	mem 42.971
Train: [17][535/750]	BT 0.053 (1.168)	DT 0.002 (1.122)	loss 8.926 (8.926)	prob 1.831 (1.831)	GS 33.453 (33.453)	mem 43.123
Train: [17][540/750]	BT 0.054 (1.158)	DT 0.006 (1.111)	loss 8.649 (8.649)	prob 2.802 (2.802)	GS 35.312 (35.312)	mem 43.026
Train: [17][545/750]	BT 0.036 (1.148)	DT 0.001 (1.101)	loss 7.933 (7.933)	prob 3.581 (3.581)	GS 33.625 (33.625)	mem 43.038
Train: [17][550/750]	BT 0.032 (1.163)	DT 0.002 (1.116)	loss 8.324 (8.324)	prob 3.082 (3.082)	GS 33.172 (33.172)	mem 43.071
Train: [17][555/750]	BT 0.036 (1.153)	DT 0.001 (1.106)	loss 8.138 (8.138)	prob 3.030 (3.030)	GS 25.062 (25.062)	mem 43.116
Train: [17][560/750]	BT 0.139 (1.165)	DT 0.102 (1.119)	loss 8.651 (8.651)	prob 3.746 (3.746)	GS 37.953 (37.953)	mem 43.018
Train: [17][565/750]	BT 0.039 (1.155)	DT 0.008 (1.109)	loss 8.528 (8.528)	prob 2.485 (2.485)	GS 34.797 (34.797)	mem 43.072
Train: [17][570/750]	BT 13.740 (1.170)	DT 13.709 (1.123)	loss 7.947 (7.947)	prob 3.781 (3.781)	GS 35.328 (35.328)	mem 43.032
Train: [17][575/750]	BT 0.084 (1.162)	DT 0.007 (1.115)	loss 8.588 (8.588)	prob 1.647 (1.647)	GS 34.375 (34.375)	mem 43.009
Train: [17][580/750]	BT 0.040 (1.152)	DT 0.001 (1.105)	loss 7.996 (7.996)	prob 2.971 (2.971)	GS 32.094 (32.094)	mem 42.949
Train: [17][585/750]	BT 0.095 (1.166)	DT 0.001 (1.119)	loss 8.257 (8.257)	prob 2.830 (2.830)	GS 28.328 (28.328)	mem 43.042
Train: [17][590/750]	BT 0.027 (1.156)	DT 0.001 (1.109)	loss 8.204 (8.204)	prob 3.737 (3.737)	GS 36.375 (36.375)	mem 42.999
Train: [17][595/750]	BT 0.042 (1.163)	DT 0.006 (1.116)	loss 7.793 (7.793)	prob 3.704 (3.704)	GS 26.672 (26.672)	mem 43.065
Train: [17][600/750]	BT 0.031 (1.156)	DT 0.001 (1.109)	loss 8.187 (8.187)	prob 3.378 (3.378)	GS 30.922 (30.922)	mem 42.979
Train: [17][605/750]	BT 0.046 (1.147)	DT 0.003 (1.100)	loss 8.123 (8.123)	prob 2.850 (2.850)	GS 29.688 (29.688)	mem 43.036
Train: [17][610/750]	BT 0.034 (1.163)	DT 0.001 (1.116)	loss 8.394 (8.394)	prob 3.569 (3.569)	GS 35.328 (35.328)	mem 43.024
Train: [17][615/750]	BT 0.034 (1.153)	DT 0.001 (1.107)	loss 9.447 (9.447)	prob 1.672 (1.672)	GS 31.438 (31.438)	mem 43.094
Train: [17][620/750]	BT 2.630 (1.162)	DT 2.595 (1.115)	loss 8.713 (8.713)	prob 4.643 (4.643)	GS 29.750 (29.750)	mem 43.081
Train: [17][625/750]	BT 0.091 (1.153)	DT 0.002 (1.106)	loss 8.338 (8.338)	prob 2.958 (2.958)	GS 33.406 (33.406)	mem 43.151
Train: [17][630/750]	BT 9.701 (1.160)	DT 9.666 (1.113)	loss 8.009 (8.009)	prob 3.322 (3.322)	GS 38.562 (38.562)	mem 43.087
Train: [17][635/750]	BT 0.038 (1.153)	DT 0.002 (1.107)	loss 8.176 (8.176)	prob 3.096 (3.096)	GS 32.938 (32.938)	mem 43.253
Train: [17][640/750]	BT 1.825 (1.147)	DT 1.771 (1.101)	loss 8.766 (8.766)	prob 2.632 (2.632)	GS 36.594 (36.594)	mem 43.098
Train: [17][645/750]	BT 0.039 (1.155)	DT 0.001 (1.109)	loss 8.285 (8.285)	prob 2.740 (2.740)	GS 33.766 (33.766)	mem 43.156
Train: [17][650/750]	BT 0.046 (1.147)	DT 0.006 (1.100)	loss 7.743 (7.743)	prob 2.945 (2.945)	GS 36.453 (36.453)	mem 43.058
Train: [17][655/750]	BT 0.094 (1.158)	DT 0.012 (1.112)	loss 8.254 (8.254)	prob 3.006 (3.006)	GS 28.094 (28.094)	mem 43.154
Train: [17][660/750]	BT 0.032 (1.150)	DT 0.002 (1.104)	loss 8.860 (8.860)	prob 3.458 (3.458)	GS 34.609 (34.609)	mem 43.103
Train: [17][665/750]	BT 0.096 (1.142)	DT 0.003 (1.095)	loss 8.256 (8.256)	prob 3.085 (3.085)	GS 30.391 (30.391)	mem 43.103
Train: [17][670/750]	BT 0.033 (1.155)	DT 0.002 (1.108)	loss 8.084 (8.084)	prob 3.749 (3.749)	GS 32.906 (32.906)	mem 43.614
Train: [17][675/750]	BT 0.077 (1.147)	DT 0.013 (1.100)	loss 8.730 (8.730)	prob 1.988 (1.988)	GS 31.719 (31.719)	mem 43.732
Train: [17][680/750]	BT 6.151 (1.158)	DT 6.118 (1.111)	loss 8.365 (8.365)	prob 3.411 (3.411)	GS 36.969 (36.969)	mem 43.584
Train: [17][685/750]	BT 0.048 (1.150)	DT 0.001 (1.103)	loss 8.088 (8.088)	prob 3.879 (3.879)	GS 31.750 (31.750)	mem 43.588
Train: [17][690/750]	BT 6.788 (1.151)	DT 6.744 (1.105)	loss 7.912 (7.912)	prob 3.846 (3.846)	GS 33.094 (33.094)	mem 43.727
Train: [17][695/750]	BT 0.032 (1.150)	DT 0.002 (1.104)	loss 8.606 (8.606)	prob 3.560 (3.560)	GS 27.156 (27.156)	mem 43.624
Train: [17][700/750]	BT 0.034 (1.142)	DT 0.005 (1.096)	loss 8.123 (8.123)	prob 3.942 (3.942)	GS 32.297 (32.297)	mem 43.624
Train: [17][705/750]	BT 0.037 (1.156)	DT 0.002 (1.110)	loss 8.318 (8.318)	prob 3.725 (3.725)	GS 30.484 (30.484)	mem 43.003
Train: [17][710/750]	BT 0.036 (1.148)	DT 0.002 (1.102)	loss 8.488 (8.488)	prob 3.184 (3.184)	GS 34.219 (34.219)	mem 43.034
Train: [17][715/750]	BT 0.032 (1.155)	DT 0.001 (1.109)	loss 7.929 (7.929)	prob 2.747 (2.747)	GS 29.641 (29.641)	mem 43.479
Train: [17][720/750]	BT 0.063 (1.151)	DT 0.014 (1.105)	loss 8.635 (8.635)	prob 3.967 (3.967)	GS 35.656 (35.656)	mem 43.503
Train: [17][725/750]	BT 0.050 (1.143)	DT 0.020 (1.097)	loss 8.226 (8.226)	prob 3.276 (3.276)	GS 31.828 (31.828)	mem 43.579
Train: [17][730/750]	BT 0.032 (1.151)	DT 0.001 (1.105)	loss 8.573 (8.573)	prob 4.309 (4.309)	GS 33.141 (33.141)	mem 44.067
Train: [17][735/750]	BT 0.028 (1.143)	DT 0.001 (1.097)	loss 7.999 (7.999)	prob 3.457 (3.457)	GS 30.156 (30.156)	mem 44.089
Train: [17][740/750]	BT 0.492 (1.148)	DT 0.452 (1.102)	loss 8.162 (8.162)	prob 4.308 (4.308)	GS 32.406 (32.406)	mem 22.159
Train: [17][745/750]	BT 0.037 (1.141)	DT 0.001 (1.095)	loss 8.344 (8.344)	prob 3.233 (3.233)	GS 28.062 (28.062)	mem 22.146
Train: [17][750/750]	BT 2.776 (1.137)	DT 2.743 (1.091)	loss 8.013 (8.013)	prob 3.575 (3.575)	GS 32.875 (32.875)	mem 16.511
Train: [17][755/750]	BT 0.052 (1.130)	DT 0.002 (1.084)	loss 7.806 (7.806)	prob 4.651 (4.651)	GS 29.094 (29.094)	mem 14.189
epoch 17, total time 853.09
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [18][1/750]	BT 18.951 (18.951)	DT 18.905 (18.905)	loss 7.809 (7.809)	prob 3.858 (3.858)	GS 33.188 (33.188)	mem 44.432
Train: [18][5/750]	BT 0.031 (4.551)	DT 0.001 (4.491)	loss 8.160 (8.160)	prob 2.931 (2.931)	GS 29.312 (29.312)	mem 44.878
Train: [18][10/750]	BT 0.032 (3.137)	DT 0.001 (3.084)	loss 7.852 (7.852)	prob 4.416 (4.416)	GS 37.188 (37.188)	mem 43.914
Train: [18][15/750]	BT 0.103 (2.534)	DT 0.003 (2.470)	loss 8.044 (8.044)	prob 3.766 (3.766)	GS 34.172 (34.172)	mem 44.043
Train: [18][20/750]	BT 0.035 (2.230)	DT 0.003 (2.169)	loss 7.859 (7.859)	prob 3.850 (3.850)	GS 33.219 (33.219)	mem 44.326
Train: [18][25/750]	BT 0.058 (1.793)	DT 0.003 (1.736)	loss 7.990 (7.990)	prob 4.323 (4.323)	GS 38.656 (38.656)	mem 44.364
Train: [18][30/750]	BT 4.195 (1.940)	DT 4.068 (1.882)	loss 8.109 (8.109)	prob 3.169 (3.169)	GS 35.250 (35.250)	mem 44.388
Train: [18][35/750]	BT 0.105 (1.675)	DT 0.002 (1.614)	loss 8.334 (8.334)	prob 3.332 (3.332)	GS 30.766 (30.766)	mem 44.272
Train: [18][40/750]	BT 0.033 (1.694)	DT 0.001 (1.636)	loss 7.756 (7.756)	prob 4.054 (4.054)	GS 35.141 (35.141)	mem 44.352
Train: [18][45/750]	BT 0.028 (1.589)	DT 0.004 (1.533)	loss 7.926 (7.926)	prob 3.594 (3.594)	GS 29.922 (29.922)	mem 44.344
Train: [18][50/750]	BT 7.871 (1.593)	DT 7.832 (1.538)	loss 8.089 (8.089)	prob 3.947 (3.947)	GS 36.859 (36.859)	mem 44.369
Train: [18][55/750]	BT 0.052 (1.464)	DT 0.002 (1.411)	loss 8.361 (8.361)	prob 2.948 (2.948)	GS 30.766 (30.766)	mem 44.392
Train: [18][60/750]	BT 0.032 (1.424)	DT 0.002 (1.370)	loss 8.309 (8.309)	prob 4.105 (4.105)	GS 31.812 (31.812)	mem 44.350
Train: [18][65/750]	BT 0.033 (1.441)	DT 0.003 (1.388)	loss 7.532 (7.532)	prob 4.931 (4.931)	GS 31.047 (31.047)	mem 44.604
Train: [18][70/750]	BT 0.037 (1.409)	DT 0.002 (1.357)	loss 8.155 (8.155)	prob 4.174 (4.174)	GS 35.828 (35.828)	mem 44.531
Train: [18][75/750]	BT 0.037 (1.416)	DT 0.005 (1.365)	loss 8.002 (8.002)	prob 3.945 (3.945)	GS 33.719 (33.719)	mem 44.584
Train: [18][80/750]	BT 2.234 (1.376)	DT 2.198 (1.325)	loss 8.070 (8.070)	prob 4.182 (4.182)	GS 32.328 (32.328)	mem 44.724
Train: [18][85/750]	BT 0.144 (1.299)	DT 0.003 (1.247)	loss 8.659 (8.659)	prob 2.881 (2.881)	GS 32.094 (32.094)	mem 44.824
Train: [18][90/750]	BT 3.447 (1.380)	DT 3.414 (1.328)	loss 8.278 (8.278)	prob 3.791 (3.791)	GS 35.625 (35.625)	mem 44.530
Train: [18][95/750]	BT 0.026 (1.310)	DT 0.001 (1.259)	loss 7.902 (7.902)	prob 4.000 (4.000)	GS 34.453 (34.453)	mem 44.498
Train: [18][100/750]	BT 0.033 (1.340)	DT 0.001 (1.289)	loss 7.468 (7.468)	prob 4.666 (4.666)	GS 30.734 (30.734)	mem 44.493
Train: [18][105/750]	BT 0.045 (1.335)	DT 0.003 (1.286)	loss 8.184 (8.184)	prob 3.019 (3.019)	GS 30.609 (30.609)	mem 44.538
Train: [18][110/750]	BT 3.649 (1.311)	DT 3.617 (1.260)	loss 7.840 (7.840)	prob 4.394 (4.394)	GS 33.062 (33.062)	mem 44.586
Train: [18][115/750]	BT 0.105 (1.355)	DT 0.002 (1.305)	loss 8.480 (8.480)	prob 3.058 (3.058)	GS 28.922 (28.922)	mem 44.663
Train: [18][120/750]	BT 0.043 (1.301)	DT 0.003 (1.251)	loss 7.510 (7.510)	prob 4.420 (4.420)	GS 33.016 (33.016)	mem 44.609
Train: [18][125/750]	BT 0.034 (1.269)	DT 0.002 (1.219)	loss 8.508 (8.508)	prob 3.211 (3.211)	GS 30.359 (30.359)	mem 44.690
Train: [18][130/750]	BT 0.024 (1.306)	DT 0.001 (1.257)	loss 7.924 (7.924)	prob 3.800 (3.800)	GS 33.406 (33.406)	mem 44.654
Train: [18][135/750]	BT 0.085 (1.260)	DT 0.016 (1.211)	loss 7.743 (7.743)	prob 3.432 (3.432)	GS 25.688 (25.688)	mem 44.654
Train: [18][140/750]	BT 0.053 (1.323)	DT 0.010 (1.274)	loss 7.780 (7.780)	prob 4.123 (4.123)	GS 36.250 (36.250)	mem 44.695
Train: [18][145/750]	BT 0.054 (1.279)	DT 0.011 (1.231)	loss 7.766 (7.766)	prob 4.413 (4.413)	GS 30.000 (30.000)	mem 44.585
Train: [18][150/750]	BT 11.965 (1.318)	DT 11.921 (1.269)	loss 7.820 (7.820)	prob 4.123 (4.123)	GS 32.328 (32.328)	mem 44.756
Train: [18][155/750]	BT 0.031 (1.276)	DT 0.002 (1.228)	loss 8.089 (8.089)	prob 3.267 (3.267)	GS 31.078 (31.078)	mem 44.724
Train: [18][160/750]	BT 0.037 (1.238)	DT 0.001 (1.190)	loss 7.737 (7.737)	prob 4.137 (4.137)	GS 31.766 (31.766)	mem 44.724
Train: [18][165/750]	BT 0.029 (1.278)	DT 0.001 (1.231)	loss 7.737 (7.737)	prob 4.020 (4.020)	GS 30.766 (30.766)	mem 44.786
Train: [18][170/750]	BT 0.062 (1.242)	DT 0.012 (1.195)	loss 8.049 (8.049)	prob 4.171 (4.171)	GS 34.078 (34.078)	mem 44.843
Train: [18][175/750]	BT 0.053 (1.277)	DT 0.008 (1.230)	loss 7.815 (7.815)	prob 3.505 (3.505)	GS 27.891 (27.891)	mem 42.476
Train: [18][180/750]	BT 0.035 (1.243)	DT 0.010 (1.196)	loss 8.095 (8.095)	prob 4.246 (4.246)	GS 34.922 (34.922)	mem 42.417
Train: [18][185/750]	BT 0.055 (1.211)	DT 0.001 (1.164)	loss 7.819 (7.819)	prob 3.698 (3.698)	GS 31.453 (31.453)	mem 42.421
Train: [18][190/750]	BT 0.033 (1.246)	DT 0.002 (1.199)	loss 7.521 (7.521)	prob 4.304 (4.304)	GS 36.062 (36.062)	mem 42.593
Train: [18][195/750]	BT 0.041 (1.215)	DT 0.002 (1.168)	loss 8.127 (8.127)	prob 2.800 (2.800)	GS 33.750 (33.750)	mem 42.639
Train: [18][200/750]	BT 0.032 (1.246)	DT 0.001 (1.200)	loss 8.159 (8.159)	prob 3.434 (3.434)	GS 39.203 (39.203)	mem 42.591
Train: [18][205/750]	BT 0.061 (1.217)	DT 0.007 (1.171)	loss 8.015 (8.015)	prob 3.393 (3.393)	GS 30.844 (30.844)	mem 42.595
Train: [18][210/750]	BT 14.880 (1.260)	DT 14.811 (1.214)	loss 7.678 (7.678)	prob 4.058 (4.058)	GS 33.234 (33.234)	mem 42.644
Train: [18][215/750]	BT 0.029 (1.231)	DT 0.003 (1.186)	loss 7.759 (7.759)	prob 3.015 (3.015)	GS 30.234 (30.234)	mem 42.653
Train: [18][220/750]	BT 0.025 (1.204)	DT 0.001 (1.159)	loss 7.832 (7.832)	prob 3.378 (3.378)	GS 33.078 (33.078)	mem 42.655
Train: [18][225/750]	BT 0.063 (1.222)	DT 0.005 (1.177)	loss 8.287 (8.287)	prob 3.426 (3.426)	GS 30.000 (30.000)	mem 42.822
Train: [18][230/750]	BT 0.032 (1.196)	DT 0.002 (1.151)	loss 8.252 (8.252)	prob 3.024 (3.024)	GS 35.469 (35.469)	mem 43.016
Train: [18][235/750]	BT 0.060 (1.232)	DT 0.016 (1.187)	loss 7.632 (7.632)	prob 3.357 (3.357)	GS 29.281 (29.281)	mem 42.765
Train: [18][240/750]	BT 0.040 (1.207)	DT 0.005 (1.162)	loss 7.972 (7.972)	prob 3.588 (3.588)	GS 32.641 (32.641)	mem 42.892
Train: [18][245/750]	BT 0.063 (1.183)	DT 0.009 (1.138)	loss 7.783 (7.783)	prob 3.030 (3.030)	GS 33.172 (33.172)	mem 42.868
Train: [18][250/750]	BT 0.040 (1.210)	DT 0.002 (1.165)	loss 7.485 (7.485)	prob 3.999 (3.999)	GS 31.281 (31.281)	mem 42.738
Train: [18][255/750]	BT 0.045 (1.187)	DT 0.001 (1.142)	loss 7.624 (7.624)	prob 3.226 (3.226)	GS 31.203 (31.203)	mem 42.739
Train: [18][260/750]	BT 0.037 (1.223)	DT 0.002 (1.179)	loss 7.838 (7.838)	prob 3.120 (3.120)	GS 33.578 (33.578)	mem 42.747
Train: [18][265/750]	BT 0.032 (1.201)	DT 0.002 (1.157)	loss 7.760 (7.760)	prob 3.085 (3.085)	GS 31.719 (31.719)	mem 42.796
Train: [18][270/750]	BT 11.722 (1.223)	DT 11.676 (1.179)	loss 7.579 (7.579)	prob 3.022 (3.022)	GS 36.656 (36.656)	mem 42.744
Train: [18][275/750]	BT 0.095 (1.201)	DT 0.008 (1.157)	loss 7.997 (7.997)	prob 2.302 (2.302)	GS 26.484 (26.484)	mem 42.779
Train: [18][280/750]	BT 0.064 (1.181)	DT 0.004 (1.137)	loss 7.370 (7.370)	prob 3.692 (3.692)	GS 36.703 (36.703)	mem 42.965
Train: [18][285/750]	BT 0.039 (1.198)	DT 0.002 (1.154)	loss 7.722 (7.722)	prob 2.985 (2.985)	GS 28.359 (28.359)	mem 43.148
Train: [18][290/750]	BT 0.048 (1.179)	DT 0.008 (1.135)	loss 7.875 (7.875)	prob 3.113 (3.113)	GS 30.500 (30.500)	mem 43.071
Train: [18][295/750]	BT 0.023 (1.201)	DT 0.001 (1.157)	loss 8.060 (8.060)	prob 2.498 (2.498)	GS 29.094 (29.094)	mem 42.991
Train: [18][300/750]	BT 0.121 (1.187)	DT 0.033 (1.143)	loss 7.731 (7.731)	prob 3.790 (3.790)	GS 32.297 (32.297)	mem 42.993
Train: [18][305/750]	BT 0.046 (1.169)	DT 0.002 (1.125)	loss 7.665 (7.665)	prob 3.358 (3.358)	GS 35.625 (35.625)	mem 43.000
Train: [18][310/750]	BT 0.039 (1.205)	DT 0.002 (1.160)	loss 8.042 (8.042)	prob 3.329 (3.329)	GS 35.391 (35.391)	mem 42.969
Train: [18][315/750]	BT 0.052 (1.186)	DT 0.004 (1.142)	loss 7.970 (7.970)	prob 2.062 (2.062)	GS 31.062 (31.062)	mem 42.970
Train: [18][320/750]	BT 0.075 (1.200)	DT 0.001 (1.155)	loss 7.561 (7.561)	prob 2.463 (2.463)	GS 33.828 (33.828)	mem 42.949
Train: [18][325/750]	BT 0.052 (1.182)	DT 0.002 (1.137)	loss 7.754 (7.754)	prob 2.220 (2.220)	GS 32.734 (32.734)	mem 42.951
Train: [18][330/750]	BT 14.067 (1.207)	DT 14.016 (1.163)	loss 7.859 (7.859)	prob 2.972 (2.972)	GS 32.484 (32.484)	mem 43.063
Train: [18][335/750]	BT 0.033 (1.190)	DT 0.002 (1.146)	loss 8.096 (8.096)	prob 1.783 (1.783)	GS 33.609 (33.609)	mem 43.192
Train: [18][340/750]	BT 0.031 (1.173)	DT 0.001 (1.129)	loss 7.347 (7.347)	prob 3.270 (3.270)	GS 36.406 (36.406)	mem 42.981
Train: [18][345/750]	BT 0.082 (1.187)	DT 0.012 (1.143)	loss 7.236 (7.236)	prob 2.891 (2.891)	GS 32.953 (32.953)	mem 42.954
Train: [18][350/750]	BT 0.034 (1.171)	DT 0.001 (1.127)	loss 8.056 (8.056)	prob 1.691 (1.691)	GS 35.188 (35.188)	mem 42.965
Train: [18][355/750]	BT 0.079 (1.191)	DT 0.011 (1.146)	loss 7.252 (7.252)	prob 2.220 (2.220)	GS 32.719 (32.719)	mem 43.000
Train: [18][360/750]	BT 0.033 (1.175)	DT 0.001 (1.131)	loss 7.990 (7.990)	prob 2.162 (2.162)	GS 30.219 (30.219)	mem 43.219
Train: [18][365/750]	BT 0.034 (1.160)	DT 0.003 (1.115)	loss 7.655 (7.655)	prob 1.266 (1.266)	GS 31.203 (31.203)	mem 43.022
Train: [18][370/750]	BT 0.031 (1.186)	DT 0.002 (1.141)	loss 7.905 (7.905)	prob 2.251 (2.251)	GS 36.172 (36.172)	mem 43.081
Train: [18][375/750]	BT 0.049 (1.171)	DT 0.004 (1.126)	loss 8.738 (8.738)	prob 0.480 (0.480)	GS 30.766 (30.766)	mem 42.998
Train: [18][380/750]	BT 0.052 (1.189)	DT 0.005 (1.144)	loss 7.623 (7.623)	prob 2.070 (2.070)	GS 38.266 (38.266)	mem 43.023
Train: [18][385/750]	BT 0.052 (1.174)	DT 0.012 (1.130)	loss 7.486 (7.486)	prob 1.318 (1.318)	GS 38.609 (38.609)	mem 43.044
Train: [18][390/750]	BT 12.268 (1.191)	DT 12.243 (1.146)	loss 7.320 (7.320)	prob 2.419 (2.419)	GS 31.000 (31.000)	mem 43.024
Train: [18][395/750]	BT 0.048 (1.176)	DT 0.001 (1.132)	loss 8.010 (8.010)	prob 1.886 (1.886)	GS 31.422 (31.422)	mem 43.025
Train: [18][400/750]	BT 0.047 (1.162)	DT 0.015 (1.118)	loss 8.733 (8.733)	prob 0.648 (0.648)	GS 35.609 (35.609)	mem 43.172
Train: [18][405/750]	BT 0.045 (1.178)	DT 0.009 (1.133)	loss 7.798 (7.798)	prob 0.335 (0.335)	GS 32.297 (32.297)	mem 43.130
Train: [18][410/750]	BT 0.034 (1.164)	DT 0.003 (1.120)	loss 7.849 (7.849)	prob 1.960 (1.960)	GS 31.109 (31.109)	mem 43.046
Train: [18][415/750]	BT 0.032 (1.173)	DT 0.002 (1.129)	loss 7.962 (7.962)	prob 2.147 (2.147)	GS 30.406 (30.406)	mem 42.984
Train: [18][420/750]	BT 0.086 (1.160)	DT 0.009 (1.116)	loss 8.093 (8.093)	prob 2.872 (2.872)	GS 32.953 (32.953)	mem 42.985
Train: [18][425/750]	BT 0.030 (1.147)	DT 0.002 (1.103)	loss 7.959 (7.959)	prob 1.153 (1.153)	GS 36.125 (36.125)	mem 42.984
Train: [18][430/750]	BT 0.057 (1.166)	DT 0.004 (1.122)	loss 8.523 (8.523)	prob 0.874 (0.874)	GS 37.500 (37.500)	mem 43.208
Train: [18][435/750]	BT 0.033 (1.153)	DT 0.003 (1.109)	loss 8.438 (8.438)	prob 0.130 (0.130)	GS 34.266 (34.266)	mem 42.996
Train: [18][440/750]	BT 0.030 (1.173)	DT 0.002 (1.129)	loss 8.472 (8.472)	prob 1.314 (1.314)	GS 33.125 (33.125)	mem 43.018
Train: [18][445/750]	BT 0.066 (1.160)	DT 0.003 (1.116)	loss 7.949 (7.949)	prob 1.943 (1.943)	GS 32.469 (32.469)	mem 43.027
Train: [18][450/750]	BT 11.378 (1.173)	DT 11.333 (1.129)	loss 7.939 (7.939)	prob 2.268 (2.268)	GS 29.250 (29.250)	mem 43.204
Train: [18][455/750]	BT 0.031 (1.161)	DT 0.001 (1.117)	loss 8.095 (8.095)	prob 2.288 (2.288)	GS 30.953 (30.953)	mem 43.042
Train: [18][460/750]	BT 0.058 (1.149)	DT 0.001 (1.105)	loss 7.876 (7.876)	prob 2.795 (2.795)	GS 31.062 (31.062)	mem 43.045
Train: [18][465/750]	BT 0.031 (1.168)	DT 0.001 (1.124)	loss 7.949 (7.949)	prob 1.944 (1.944)	GS 40.219 (40.219)	mem 43.067
Train: [18][470/750]	BT 0.055 (1.156)	DT 0.007 (1.112)	loss 8.648 (8.648)	prob 2.500 (2.500)	GS 34.984 (34.984)	mem 43.071
Train: [18][475/750]	BT 0.048 (1.160)	DT 0.001 (1.116)	loss 7.725 (7.725)	prob 2.253 (2.253)	GS 30.094 (30.094)	mem 43.225
Train: [18][480/750]	BT 0.024 (1.160)	DT 0.001 (1.116)	loss 7.842 (7.842)	prob 1.730 (1.730)	GS 34.359 (34.359)	mem 43.092
Train: [18][485/750]	BT 0.088 (1.149)	DT 0.010 (1.105)	loss 8.549 (8.549)	prob 1.369 (1.369)	GS 37.719 (37.719)	mem 43.075
Train: [18][490/750]	BT 0.043 (1.166)	DT 0.002 (1.122)	loss 7.858 (7.858)	prob 2.661 (2.661)	GS 32.719 (32.719)	mem 43.200
Train: [18][495/750]	BT 0.051 (1.155)	DT 0.012 (1.110)	loss 7.973 (7.973)	prob 1.681 (1.681)	GS 34.266 (34.266)	mem 43.246
Train: [18][500/750]	BT 1.509 (1.166)	DT 1.479 (1.122)	loss 8.362 (8.362)	prob 1.538 (1.538)	GS 30.797 (30.797)	mem 43.002
Train: [18][505/750]	BT 0.046 (1.155)	DT 0.001 (1.111)	loss 8.168 (8.168)	prob 1.863 (1.863)	GS 25.906 (25.906)	mem 43.131
Train: [18][510/750]	BT 12.162 (1.170)	DT 12.135 (1.126)	loss 9.047 (9.047)	prob 2.303 (2.303)	GS 39.766 (39.766)	mem 42.981
Train: [18][515/750]	BT 0.024 (1.160)	DT 0.001 (1.116)	loss 8.399 (8.399)	prob 2.375 (2.375)	GS 34.516 (34.516)	mem 43.009
Train: [18][520/750]	BT 0.025 (1.149)	DT 0.001 (1.105)	loss 8.158 (8.158)	prob 2.867 (2.867)	GS 33.391 (33.391)	mem 42.993
Train: [18][525/750]	BT 0.106 (1.161)	DT 0.004 (1.117)	loss 8.349 (8.349)	prob 1.612 (1.612)	GS 31.625 (31.625)	mem 42.968
Train: [18][530/750]	BT 0.303 (1.150)	DT 0.242 (1.107)	loss 7.416 (7.416)	prob 2.301 (2.301)	GS 33.094 (33.094)	mem 43.162
Train: [18][535/750]	BT 0.074 (1.168)	DT 0.005 (1.124)	loss 9.469 (9.469)	prob 1.493 (1.493)	GS 29.531 (29.531)	mem 43.567
Train: [18][540/750]	BT 0.023 (1.157)	DT 0.001 (1.113)	loss 8.622 (8.622)	prob 2.741 (2.741)	GS 33.281 (33.281)	mem 43.340
Train: [18][545/750]	BT 0.031 (1.150)	DT 0.003 (1.107)	loss 8.326 (8.326)	prob 1.227 (1.227)	GS 31.953 (31.953)	mem 43.050
Train: [18][550/750]	BT 0.087 (1.158)	DT 0.013 (1.115)	loss 8.454 (8.454)	prob 2.206 (2.206)	GS 30.062 (30.062)	mem 43.092
Train: [18][555/750]	BT 0.081 (1.153)	DT 0.002 (1.109)	loss 7.461 (7.461)	prob 4.066 (4.066)	GS 29.797 (29.797)	mem 43.108
Train: [18][560/750]	BT 4.217 (1.164)	DT 4.127 (1.120)	loss 8.151 (8.151)	prob 2.885 (2.885)	GS 30.203 (30.203)	mem 43.293
Train: [18][565/750]	BT 0.106 (1.154)	DT 0.001 (1.110)	loss 8.037 (8.037)	prob 2.238 (2.238)	GS 30.312 (30.312)	mem 43.223
Train: [18][570/750]	BT 11.927 (1.166)	DT 11.875 (1.122)	loss 8.274 (8.274)	prob 2.911 (2.911)	GS 30.703 (30.703)	mem 43.156
Train: [18][575/750]	BT 0.066 (1.158)	DT 0.002 (1.113)	loss 8.007 (8.007)	prob 1.370 (1.370)	GS 31.609 (31.609)	mem 43.234
Train: [18][580/750]	BT 0.585 (1.150)	DT 0.555 (1.105)	loss 8.152 (8.152)	prob 3.148 (3.148)	GS 32.719 (32.719)	mem 43.090
Train: [18][585/750]	BT 0.135 (1.162)	DT 0.017 (1.118)	loss 8.659 (8.659)	prob 2.242 (2.242)	GS 34.969 (34.969)	mem 43.118
Train: [18][590/750]	BT 0.041 (1.153)	DT 0.002 (1.108)	loss 8.206 (8.206)	prob 2.582 (2.582)	GS 33.688 (33.688)	mem 43.120
Train: [18][595/750]	BT 0.034 (1.160)	DT 0.001 (1.115)	loss 7.983 (7.983)	prob 2.878 (2.878)	GS 31.641 (31.641)	mem 43.272
Train: [18][600/750]	BT 0.025 (1.156)	DT 0.001 (1.111)	loss 8.039 (8.039)	prob 3.512 (3.512)	GS 31.438 (31.438)	mem 43.095
Train: [18][605/750]	BT 0.031 (1.146)	DT 0.004 (1.102)	loss 8.071 (8.071)	prob 3.024 (3.024)	GS 35.594 (35.594)	mem 43.096
Train: [18][610/750]	BT 0.022 (1.159)	DT 0.001 (1.115)	loss 8.124 (8.124)	prob 3.064 (3.064)	GS 32.250 (32.250)	mem 43.074
Train: [18][615/750]	BT 0.047 (1.150)	DT 0.002 (1.106)	loss 8.498 (8.498)	prob 2.654 (2.654)	GS 30.359 (30.359)	mem 43.152
Train: [18][620/750]	BT 4.634 (1.161)	DT 4.588 (1.116)	loss 8.171 (8.171)	prob 3.928 (3.928)	GS 36.969 (36.969)	mem 43.059
Train: [18][625/750]	BT 0.089 (1.152)	DT 0.006 (1.107)	loss 8.027 (8.027)	prob 2.719 (2.719)	GS 33.250 (33.250)	mem 43.076
Train: [18][630/750]	BT 7.973 (1.156)	DT 7.932 (1.111)	loss 8.478 (8.478)	prob 3.155 (3.155)	GS 33.891 (33.891)	mem 43.045
Train: [18][635/750]	BT 0.043 (1.156)	DT 0.001 (1.111)	loss 8.567 (8.567)	prob 2.458 (2.458)	GS 33.875 (33.875)	mem 43.018
Train: [18][640/750]	BT 0.043 (1.147)	DT 0.001 (1.103)	loss 7.877 (7.877)	prob 3.728 (3.728)	GS 33.281 (33.281)	mem 42.983
Train: [18][645/750]	BT 0.027 (1.157)	DT 0.001 (1.113)	loss 7.696 (7.696)	prob 3.685 (3.685)	GS 33.188 (33.188)	mem 43.311
Train: [18][650/750]	BT 0.024 (1.149)	DT 0.001 (1.105)	loss 7.813 (7.813)	prob 3.629 (3.629)	GS 32.266 (32.266)	mem 43.082
Train: [18][655/750]	BT 0.170 (1.147)	DT 0.003 (1.102)	loss 8.209 (8.209)	prob 2.304 (2.304)	GS 33.359 (33.359)	mem 43.395
arpack error, retry= 0
Train: [18][660/750]	BT 0.051 (1.149)	DT 0.002 (1.104)	loss 8.583 (8.583)	prob 3.516 (3.516)	GS 34.797 (34.797)	mem 43.096
Train: [18][665/750]	BT 0.043 (1.140)	DT 0.003 (1.096)	loss 8.509 (8.509)	prob 2.490 (2.490)	GS 31.609 (31.609)	mem 43.029
Train: [18][670/750]	BT 0.036 (1.156)	DT 0.002 (1.112)	loss 8.025 (8.025)	prob 4.616 (4.616)	GS 31.562 (31.562)	mem 43.423
Train: [18][675/750]	BT 0.033 (1.148)	DT 0.001 (1.104)	loss 8.985 (8.985)	prob 2.771 (2.771)	GS 31.406 (31.406)	mem 43.009
Train: [18][680/750]	BT 13.651 (1.161)	DT 13.580 (1.117)	loss 7.714 (7.714)	prob 3.269 (3.269)	GS 38.734 (38.734)	mem 43.048
Train: [18][685/750]	BT 0.027 (1.153)	DT 0.001 (1.109)	loss 7.790 (7.790)	prob 2.796 (2.796)	GS 29.828 (29.828)	mem 43.111
Train: [18][690/750]	BT 0.048 (1.145)	DT 0.008 (1.101)	loss 8.222 (8.222)	prob 3.938 (3.938)	GS 33.656 (33.656)	mem 43.051
Train: [18][695/750]	BT 0.033 (1.158)	DT 0.001 (1.114)	loss 8.073 (8.073)	prob 3.233 (3.233)	GS 26.953 (26.953)	mem 43.079
Train: [18][700/750]	BT 0.049 (1.150)	DT 0.008 (1.106)	loss 8.685 (8.685)	prob 3.736 (3.736)	GS 32.156 (32.156)	mem 43.080
Train: [18][705/750]	BT 0.031 (1.160)	DT 0.001 (1.116)	loss 7.892 (7.892)	prob 3.048 (3.048)	GS 33.328 (33.328)	mem 43.182
Train: [18][710/750]	BT 0.040 (1.152)	DT 0.001 (1.108)	loss 8.001 (8.001)	prob 3.818 (3.818)	GS 30.688 (30.688)	mem 43.182
Train: [18][715/750]	BT 0.082 (1.144)	DT 0.015 (1.100)	loss 7.859 (7.859)	prob 3.708 (3.708)	GS 28.094 (28.094)	mem 43.115
Train: [18][720/750]	BT 0.027 (1.149)	DT 0.001 (1.105)	loss 8.457 (8.457)	prob 2.865 (2.865)	GS 30.625 (30.625)	mem 43.172
Train: [18][725/750]	BT 0.104 (1.141)	DT 0.008 (1.097)	loss 7.843 (7.843)	prob 3.632 (3.632)	GS 28.391 (28.391)	mem 43.175
Train: [18][730/750]	BT 0.031 (1.151)	DT 0.001 (1.107)	loss 8.208 (8.208)	prob 4.214 (4.214)	GS 34.172 (34.172)	mem 42.859
Train: [18][735/750]	BT 0.055 (1.143)	DT 0.010 (1.099)	loss 8.216 (8.216)	prob 3.198 (3.198)	GS 29.891 (29.891)	mem 42.920
Train: [18][740/750]	BT 9.879 (1.149)	DT 9.847 (1.105)	loss 8.133 (8.133)	prob 3.715 (3.715)	GS 36.500 (36.500)	mem 13.795
Train: [18][745/750]	BT 0.025 (1.141)	DT 0.001 (1.098)	loss 8.676 (8.676)	prob 3.289 (3.289)	GS 34.125 (34.125)	mem 13.829
Train: [18][750/750]	BT 0.022 (1.134)	DT 0.001 (1.090)	loss 8.207 (8.207)	prob 4.018 (4.018)	GS 32.062 (32.062)	mem 13.759
Train: [18][755/750]	BT 0.021 (1.131)	DT 0.001 (1.087)	loss 8.022 (8.022)	prob 3.874 (3.874)	GS 29.188 (29.188)	mem 10.787
epoch 18, total time 853.95
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [19][1/750]	BT 20.978 (20.978)	DT 20.928 (20.928)	loss 8.336 (8.336)	prob 3.729 (3.729)	GS 29.906 (29.906)	mem 41.700
Train: [19][5/750]	BT 0.087 (4.976)	DT 0.017 (4.927)	loss 7.756 (7.756)	prob 3.772 (3.772)	GS 34.656 (34.656)	mem 41.814
Train: [19][10/750]	BT 0.033 (2.519)	DT 0.001 (2.468)	loss 8.118 (8.118)	prob 4.078 (4.078)	GS 34.016 (34.016)	mem 41.784
Train: [19][15/750]	BT 0.160 (2.759)	DT 0.005 (2.703)	loss 7.945 (7.945)	prob 3.293 (3.293)	GS 33.156 (33.156)	mem 42.591
Train: [19][20/750]	BT 0.051 (2.079)	DT 0.001 (2.028)	loss 7.758 (7.758)	prob 4.237 (4.237)	GS 29.656 (29.656)	mem 42.449
Train: [19][25/750]	BT 0.545 (1.712)	DT 0.511 (1.663)	loss 8.288 (8.288)	prob 3.849 (3.849)	GS 30.984 (30.984)	mem 42.609
Train: [19][30/750]	BT 0.031 (1.921)	DT 0.001 (1.874)	loss 8.129 (8.129)	prob 3.935 (3.935)	GS 32.156 (32.156)	mem 42.368
Train: [19][35/750]	BT 0.038 (1.652)	DT 0.006 (1.606)	loss 7.710 (7.710)	prob 3.909 (3.909)	GS 27.453 (27.453)	mem 42.504
Train: [19][40/750]	BT 0.058 (1.833)	DT 0.008 (1.785)	loss 8.100 (8.100)	prob 3.819 (3.819)	GS 34.219 (34.219)	mem 42.658
Train: [19][45/750]	BT 0.023 (1.633)	DT 0.001 (1.587)	loss 7.856 (7.856)	prob 4.223 (4.223)	GS 30.578 (30.578)	mem 42.532
Train: [19][50/750]	BT 14.751 (1.768)	DT 14.722 (1.723)	loss 8.449 (8.449)	prob 3.699 (3.699)	GS 36.359 (36.359)	mem 42.726
Train: [19][55/750]	BT 0.064 (1.611)	DT 0.002 (1.567)	loss 7.638 (7.638)	prob 4.469 (4.469)	GS 32.344 (32.344)	mem 42.783
Train: [19][60/750]	BT 0.033 (1.480)	DT 0.003 (1.436)	loss 8.141 (8.141)	prob 4.449 (4.449)	GS 33.281 (33.281)	mem 42.601
Train: [19][65/750]	BT 0.071 (1.568)	DT 0.001 (1.525)	loss 7.874 (7.874)	prob 4.109 (4.109)	GS 31.188 (31.188)	mem 42.646
Train: [19][70/750]	BT 0.027 (1.461)	DT 0.001 (1.416)	loss 7.945 (7.945)	prob 4.378 (4.378)	GS 38.859 (38.859)	mem 42.581
Train: [19][75/750]	BT 0.049 (1.524)	DT 0.002 (1.480)	loss 8.016 (8.016)	prob 3.286 (3.286)	GS 31.172 (31.172)	mem 42.647
Train: [19][80/750]	BT 0.066 (1.433)	DT 0.004 (1.388)	loss 7.966 (7.966)	prob 3.724 (3.724)	GS 36.750 (36.750)	mem 42.625
Train: [19][85/750]	BT 0.032 (1.350)	DT 0.001 (1.306)	loss 7.937 (7.937)	prob 4.108 (4.108)	GS 37.484 (37.484)	mem 42.627
Train: [19][90/750]	BT 0.047 (1.401)	DT 0.014 (1.356)	loss 8.108 (8.108)	prob 3.949 (3.949)	GS 32.125 (32.125)	mem 42.681
Train: [19][95/750]	BT 0.042 (1.330)	DT 0.002 (1.285)	loss 8.114 (8.114)	prob 3.190 (3.190)	GS 31.734 (31.734)	mem 42.783
Train: [19][100/750]	BT 0.094 (1.435)	DT 0.005 (1.390)	loss 7.927 (7.927)	prob 3.805 (3.805)	GS 32.422 (32.422)	mem 42.257
Train: [19][105/750]	BT 0.032 (1.369)	DT 0.002 (1.324)	loss 7.949 (7.949)	prob 3.660 (3.660)	GS 32.344 (32.344)	mem 42.258
Train: [19][110/750]	BT 12.188 (1.419)	DT 12.158 (1.375)	loss 7.746 (7.746)	prob 3.560 (3.560)	GS 32.734 (32.734)	mem 42.270
Train: [19][115/750]	BT 0.025 (1.359)	DT 0.001 (1.315)	loss 8.563 (8.563)	prob 3.458 (3.458)	GS 34.859 (34.859)	mem 42.269
Train: [19][120/750]	BT 0.062 (1.304)	DT 0.018 (1.260)	loss 7.897 (7.897)	prob 4.424 (4.424)	GS 36.984 (36.984)	mem 42.269
Train: [19][125/750]	BT 0.030 (1.343)	DT 0.001 (1.299)	loss 7.690 (7.690)	prob 3.604 (3.604)	GS 32.969 (32.969)	mem 42.290
Train: [19][130/750]	BT 0.074 (1.293)	DT 0.001 (1.249)	loss 7.849 (7.849)	prob 4.229 (4.229)	GS 35.203 (35.203)	mem 42.328
Train: [19][135/750]	BT 0.034 (1.333)	DT 0.003 (1.289)	loss 7.914 (7.914)	prob 4.175 (4.175)	GS 29.328 (29.328)	mem 42.314
Train: [19][140/750]	BT 0.036 (1.286)	DT 0.001 (1.243)	loss 7.522 (7.522)	prob 4.657 (4.657)	GS 36.453 (36.453)	mem 42.572
Train: [19][145/750]	BT 0.033 (1.244)	DT 0.003 (1.200)	loss 8.026 (8.026)	prob 3.794 (3.794)	GS 32.922 (32.922)	mem 42.469
Train: [19][150/750]	BT 0.033 (1.278)	DT 0.002 (1.234)	loss 7.968 (7.968)	prob 3.806 (3.806)	GS 36.188 (36.188)	mem 42.565
Train: [19][155/750]	BT 0.157 (1.240)	DT 0.039 (1.195)	loss 7.692 (7.692)	prob 3.662 (3.662)	GS 30.188 (30.188)	mem 42.568
Train: [19][160/750]	BT 0.033 (1.275)	DT 0.002 (1.230)	loss 8.027 (8.027)	prob 4.133 (4.133)	GS 32.031 (32.031)	mem 42.742
Train: [19][165/750]	BT 0.071 (1.238)	DT 0.011 (1.193)	loss 7.654 (7.654)	prob 3.979 (3.979)	GS 30.000 (30.000)	mem 42.883
Train: [19][170/750]	BT 14.822 (1.290)	DT 14.789 (1.245)	loss 8.156 (8.156)	prob 4.634 (4.634)	GS 35.422 (35.422)	mem 42.603
Train: [19][175/750]	BT 0.030 (1.254)	DT 0.001 (1.209)	loss 7.634 (7.634)	prob 4.301 (4.301)	GS 34.062 (34.062)	mem 42.604
Train: [19][180/750]	BT 0.037 (1.221)	DT 0.002 (1.176)	loss 8.419 (8.419)	prob 3.890 (3.890)	GS 33.609 (33.609)	mem 42.605
Train: [19][185/750]	BT 0.023 (1.259)	DT 0.001 (1.215)	loss 7.838 (7.838)	prob 3.293 (3.293)	GS 30.609 (30.609)	mem 42.555
Train: [19][190/750]	BT 0.044 (1.227)	DT 0.005 (1.183)	loss 8.022 (8.022)	prob 4.308 (4.308)	GS 34.453 (34.453)	mem 42.562
Train: [19][195/750]	BT 0.048 (1.259)	DT 0.008 (1.215)	loss 7.189 (7.189)	prob 4.297 (4.297)	GS 33.312 (33.312)	mem 42.625
Train: [19][200/750]	BT 0.027 (1.229)	DT 0.003 (1.185)	loss 8.152 (8.152)	prob 4.258 (4.258)	GS 35.078 (35.078)	mem 42.626
Train: [19][205/750]	BT 0.055 (1.200)	DT 0.003 (1.156)	loss 7.652 (7.652)	prob 4.320 (4.320)	GS 28.656 (28.656)	mem 42.716
Train: [19][210/750]	BT 0.051 (1.223)	DT 0.004 (1.179)	loss 7.376 (7.376)	prob 4.225 (4.225)	GS 33.828 (33.828)	mem 42.909
Train: [19][215/750]	BT 0.047 (1.196)	DT 0.001 (1.152)	loss 7.434 (7.434)	prob 3.843 (3.843)	GS 28.750 (28.750)	mem 42.635
Train: [19][220/750]	BT 0.032 (1.228)	DT 0.002 (1.184)	loss 7.880 (7.880)	prob 3.771 (3.771)	GS 30.828 (30.828)	mem 42.930
Train: [19][225/750]	BT 0.117 (1.203)	DT 0.010 (1.159)	loss 8.003 (8.003)	prob 2.853 (2.853)	GS 33.969 (33.969)	mem 42.888
Train: [19][230/750]	BT 13.194 (1.235)	DT 13.148 (1.191)	loss 8.148 (8.148)	prob 3.669 (3.669)	GS 34.766 (34.766)	mem 42.923
Train: [19][235/750]	BT 0.093 (1.210)	DT 0.003 (1.166)	loss 7.981 (7.981)	prob 3.729 (3.729)	GS 31.781 (31.781)	mem 43.009
Train: [19][240/750]	BT 0.033 (1.186)	DT 0.002 (1.142)	loss 7.605 (7.605)	prob 4.173 (4.173)	GS 35.531 (35.531)	mem 42.957
Train: [19][245/750]	BT 0.053 (1.222)	DT 0.022 (1.177)	loss 7.453 (7.453)	prob 4.012 (4.012)	GS 30.891 (30.891)	mem 42.939
Train: [19][250/750]	BT 0.033 (1.198)	DT 0.001 (1.154)	loss 7.666 (7.666)	prob 3.993 (3.993)	GS 36.562 (36.562)	mem 42.939
Train: [19][255/750]	BT 0.036 (1.229)	DT 0.002 (1.185)	loss 7.853 (7.853)	prob 3.266 (3.266)	GS 31.828 (31.828)	mem 42.948
Train: [19][260/750]	BT 0.042 (1.206)	DT 0.001 (1.162)	loss 7.931 (7.931)	prob 4.310 (4.310)	GS 32.766 (32.766)	mem 42.948
Train: [19][265/750]	BT 0.058 (1.185)	DT 0.011 (1.140)	loss 7.998 (7.998)	prob 3.135 (3.135)	GS 36.203 (36.203)	mem 42.949
Train: [19][270/750]	BT 0.038 (1.211)	DT 0.003 (1.167)	loss 7.504 (7.504)	prob 3.826 (3.826)	GS 34.500 (34.500)	mem 42.960
Train: [19][275/750]	BT 0.026 (1.190)	DT 0.001 (1.146)	loss 8.024 (8.024)	prob 3.006 (3.006)	GS 28.531 (28.531)	mem 42.960
Train: [19][280/750]	BT 0.037 (1.205)	DT 0.002 (1.161)	loss 7.885 (7.885)	prob 4.324 (4.324)	GS 39.078 (39.078)	mem 43.150
Train: [19][285/750]	BT 0.035 (1.184)	DT 0.003 (1.141)	loss 8.911 (8.911)	prob 2.312 (2.312)	GS 33.734 (33.734)	mem 43.143
Train: [19][290/750]	BT 14.902 (1.216)	DT 14.869 (1.172)	loss 7.735 (7.735)	prob 3.201 (3.201)	GS 35.703 (35.703)	mem 42.976
Train: [19][295/750]	BT 0.076 (1.197)	DT 0.007 (1.152)	loss 7.930 (7.930)	prob 3.186 (3.186)	GS 31.172 (31.172)	mem 42.961
Train: [19][300/750]	BT 0.052 (1.177)	DT 0.014 (1.133)	loss 8.140 (8.140)	prob 3.776 (3.776)	GS 39.594 (39.594)	mem 42.961
Train: [19][305/750]	BT 0.031 (1.202)	DT 0.001 (1.158)	loss 7.764 (7.764)	prob 3.138 (3.138)	GS 33.188 (33.188)	mem 43.025
Train: [19][310/750]	BT 0.033 (1.183)	DT 0.001 (1.139)	loss 7.541 (7.541)	prob 4.087 (4.087)	GS 38.797 (38.797)	mem 43.049
Train: [19][315/750]	BT 0.032 (1.204)	DT 0.001 (1.160)	loss 7.819 (7.819)	prob 2.931 (2.931)	GS 29.609 (29.609)	mem 43.002
Train: [19][320/750]	BT 0.036 (1.186)	DT 0.002 (1.142)	loss 8.102 (8.102)	prob 3.795 (3.795)	GS 30.141 (30.141)	mem 43.011
Train: [19][325/750]	BT 0.093 (1.169)	DT 0.008 (1.125)	loss 7.517 (7.517)	prob 3.465 (3.465)	GS 31.891 (31.891)	mem 43.011
Train: [19][330/750]	BT 0.078 (1.190)	DT 0.018 (1.146)	loss 8.237 (8.237)	prob 3.516 (3.516)	GS 31.531 (31.531)	mem 42.980
Train: [19][335/750]	BT 0.031 (1.173)	DT 0.001 (1.129)	loss 7.374 (7.374)	prob 3.392 (3.392)	GS 31.562 (31.562)	mem 42.974
Train: [19][340/750]	BT 0.022 (1.199)	DT 0.001 (1.154)	loss 7.841 (7.841)	prob 3.561 (3.561)	GS 34.688 (34.688)	mem 43.002
Train: [19][345/750]	BT 0.034 (1.182)	DT 0.002 (1.138)	loss 7.475 (7.475)	prob 3.570 (3.570)	GS 30.125 (30.125)	mem 43.004
Train: [19][350/750]	BT 15.105 (1.208)	DT 15.056 (1.164)	loss 7.894 (7.894)	prob 3.537 (3.537)	GS 35.094 (35.094)	mem 43.070
Train: [19][355/750]	BT 0.022 (1.192)	DT 0.001 (1.148)	loss 7.610 (7.610)	prob 2.629 (2.629)	GS 31.703 (31.703)	mem 43.007
Train: [19][360/750]	BT 0.048 (1.176)	DT 0.008 (1.132)	loss 7.411 (7.411)	prob 3.100 (3.100)	GS 35.688 (35.688)	mem 43.008
Train: [19][365/750]	BT 0.053 (1.192)	DT 0.002 (1.149)	loss 7.564 (7.564)	prob 2.274 (2.274)	GS 31.828 (31.828)	mem 43.146
Train: [19][370/750]	BT 0.091 (1.177)	DT 0.003 (1.133)	loss 7.433 (7.433)	prob 2.535 (2.535)	GS 37.344 (37.344)	mem 43.192
Train: [19][375/750]	BT 0.032 (1.202)	DT 0.001 (1.158)	loss 7.457 (7.457)	prob 3.088 (3.088)	GS 31.375 (31.375)	mem 42.907
Train: [19][380/750]	BT 0.034 (1.186)	DT 0.002 (1.143)	loss 7.328 (7.328)	prob 3.036 (3.036)	GS 31.547 (31.547)	mem 42.914
Train: [19][385/750]	BT 0.035 (1.172)	DT 0.002 (1.128)	loss 8.251 (8.251)	prob 1.924 (1.924)	GS 36.891 (36.891)	mem 42.934
Train: [19][390/750]	BT 0.043 (1.188)	DT 0.001 (1.144)	loss 7.465 (7.465)	prob 2.965 (2.965)	GS 33.047 (33.047)	mem 43.088
Train: [19][395/750]	BT 0.033 (1.173)	DT 0.001 (1.130)	loss 7.286 (7.286)	prob 3.028 (3.028)	GS 32.688 (32.688)	mem 42.966
Train: [19][400/750]	BT 0.025 (1.193)	DT 0.001 (1.150)	loss 7.566 (7.566)	prob 2.877 (2.877)	GS 28.484 (28.484)	mem 42.946
Train: [19][405/750]	BT 0.051 (1.179)	DT 0.004 (1.136)	loss 7.462 (7.462)	prob 2.379 (2.379)	GS 30.391 (30.391)	mem 42.975
Train: [19][410/750]	BT 12.994 (1.197)	DT 12.954 (1.153)	loss 7.476 (7.476)	prob 3.079 (3.079)	GS 35.188 (35.188)	mem 43.074
Train: [19][415/750]	BT 0.038 (1.183)	DT 0.014 (1.140)	loss 7.329 (7.329)	prob 2.887 (2.887)	GS 32.500 (32.500)	mem 43.074
Train: [19][420/750]	BT 0.024 (1.170)	DT 0.001 (1.126)	loss 7.600 (7.600)	prob 2.522 (2.522)	GS 36.953 (36.953)	mem 43.074
Train: [19][425/750]	BT 0.034 (1.179)	DT 0.002 (1.136)	loss 7.532 (7.532)	prob 2.187 (2.187)	GS 33.203 (33.203)	mem 43.249
Train: [19][430/750]	BT 0.033 (1.166)	DT 0.003 (1.122)	loss 7.276 (7.276)	prob 3.279 (3.279)	GS 29.812 (29.812)	mem 43.054
Train: [19][435/750]	BT 0.033 (1.185)	DT 0.002 (1.142)	loss 7.447 (7.447)	prob 2.862 (2.862)	GS 28.969 (28.969)	mem 43.008
Train: [19][440/750]	BT 0.037 (1.172)	DT 0.001 (1.129)	loss 7.392 (7.392)	prob 2.749 (2.749)	GS 37.719 (37.719)	mem 43.183
Train: [19][445/750]	BT 0.047 (1.160)	DT 0.015 (1.116)	loss 7.316 (7.316)	prob 2.551 (2.551)	GS 35.375 (35.375)	mem 43.008
Train: [19][450/750]	BT 0.030 (1.179)	DT 0.009 (1.136)	loss 7.184 (7.184)	prob 3.535 (3.535)	GS 35.688 (35.688)	mem 43.117
Train: [19][455/750]	BT 0.060 (1.167)	DT 0.008 (1.123)	loss 7.470 (7.470)	prob 2.263 (2.263)	GS 32.781 (32.781)	mem 43.256
Train: [19][460/750]	BT 0.025 (1.183)	DT 0.005 (1.140)	loss 7.686 (7.686)	prob 2.095 (2.095)	GS 33.500 (33.500)	mem 43.110
Train: [19][465/750]	BT 0.069 (1.171)	DT 0.006 (1.128)	loss 7.423 (7.423)	prob 1.665 (1.665)	GS 33.172 (33.172)	mem 43.110
Train: [19][470/750]	BT 13.507 (1.188)	DT 13.474 (1.144)	loss 7.899 (7.899)	prob 2.354 (2.354)	GS 34.547 (34.547)	mem 43.264
Train: [19][475/750]	BT 0.042 (1.176)	DT 0.001 (1.132)	loss 7.458 (7.458)	prob 2.553 (2.553)	GS 32.297 (32.297)	mem 43.129
Train: [19][480/750]	BT 0.038 (1.164)	DT 0.002 (1.121)	loss 7.905 (7.905)	prob 1.936 (1.936)	GS 34.125 (34.125)	mem 43.129
Train: [19][485/750]	BT 0.056 (1.181)	DT 0.026 (1.138)	loss 8.006 (8.006)	prob 1.465 (1.465)	GS 31.141 (31.141)	mem 42.959
Train: [19][490/750]	BT 0.030 (1.169)	DT 0.001 (1.126)	loss 7.688 (7.688)	prob 1.808 (1.808)	GS 32.953 (32.953)	mem 42.960
Train: [19][495/750]	BT 0.050 (1.182)	DT 0.010 (1.139)	loss 7.843 (7.843)	prob 2.095 (2.095)	GS 29.859 (29.859)	mem 43.058
Train: [19][500/750]	BT 0.053 (1.171)	DT 0.001 (1.128)	loss 8.136 (8.136)	prob 1.766 (1.766)	GS 32.984 (32.984)	mem 43.075
Train: [19][505/750]	BT 0.034 (1.160)	DT 0.001 (1.117)	loss 7.566 (7.566)	prob 2.117 (2.117)	GS 30.984 (30.984)	mem 43.075
Train: [19][510/750]	BT 0.081 (1.174)	DT 0.012 (1.131)	loss 7.435 (7.435)	prob 1.578 (1.578)	GS 38.797 (38.797)	mem 43.053
Train: [19][515/750]	BT 0.042 (1.163)	DT 0.001 (1.120)	loss 7.883 (7.883)	prob 0.707 (0.707)	GS 27.250 (27.250)	mem 42.948
Train: [19][520/750]	BT 0.042 (1.176)	DT 0.002 (1.133)	loss 7.400 (7.400)	prob 3.268 (3.268)	GS 32.484 (32.484)	mem 43.105
Train: [19][525/750]	BT 0.076 (1.165)	DT 0.025 (1.123)	loss 8.748 (8.748)	prob -0.051 (-0.051)	GS 29.859 (29.859)	mem 43.110
Train: [19][530/750]	BT 13.525 (1.180)	DT 13.494 (1.138)	loss 7.774 (7.774)	prob 2.044 (2.044)	GS 35.594 (35.594)	mem 43.032
Train: [19][535/750]	BT 0.090 (1.170)	DT 0.002 (1.127)	loss 7.511 (7.511)	prob 1.902 (1.902)	GS 32.312 (32.312)	mem 43.117
Train: [19][540/750]	BT 0.083 (1.160)	DT 0.014 (1.117)	loss 7.086 (7.086)	prob 2.378 (2.378)	GS 35.266 (35.266)	mem 43.046
Train: [19][545/750]	BT 0.065 (1.167)	DT 0.004 (1.124)	loss 8.811 (8.811)	prob 1.386 (1.386)	GS 33.422 (33.422)	mem 43.144
Train: [19][550/750]	BT 0.037 (1.160)	DT 0.001 (1.117)	loss 7.780 (7.780)	prob 2.482 (2.482)	GS 35.000 (35.000)	mem 43.075
Train: [19][555/750]	BT 0.031 (1.175)	DT 0.001 (1.131)	loss 7.709 (7.709)	prob 1.372 (1.372)	GS 33.797 (33.797)	mem 43.084
Train: [19][560/750]	BT 0.032 (1.165)	DT 0.001 (1.121)	loss 7.942 (7.942)	prob 1.531 (1.531)	GS 29.797 (29.797)	mem 43.095
Train: [19][565/750]	BT 0.039 (1.155)	DT 0.001 (1.111)	loss 7.979 (7.979)	prob 1.746 (1.746)	GS 32.141 (32.141)	mem 43.096
Train: [19][570/750]	BT 0.070 (1.171)	DT 0.003 (1.127)	loss 7.335 (7.335)	prob 2.265 (2.265)	GS 35.516 (35.516)	mem 43.135
Train: [19][575/750]	BT 0.031 (1.161)	DT 0.001 (1.118)	loss 7.597 (7.597)	prob 2.968 (2.968)	GS 32.953 (32.953)	mem 43.137
Train: [19][580/750]	BT 0.044 (1.169)	DT 0.002 (1.126)	loss 8.206 (8.206)	prob 2.652 (2.652)	GS 29.359 (29.359)	mem 43.150
Train: [19][585/750]	BT 0.031 (1.160)	DT 0.002 (1.117)	loss 8.177 (8.177)	prob 1.717 (1.717)	GS 30.062 (30.062)	mem 43.063
Train: [19][590/750]	BT 14.435 (1.175)	DT 14.403 (1.132)	loss 7.308 (7.308)	prob 2.563 (2.563)	GS 36.359 (36.359)	mem 42.938
Train: [19][595/750]	BT 0.039 (1.167)	DT 0.007 (1.124)	loss 7.878 (7.878)	prob 2.381 (2.381)	GS 34.016 (34.016)	mem 43.034
Train: [19][600/750]	BT 0.049 (1.158)	DT 0.005 (1.115)	loss 8.251 (8.251)	prob 2.772 (2.772)	GS 34.312 (34.312)	mem 43.008
Train: [19][605/750]	BT 0.035 (1.170)	DT 0.002 (1.127)	loss 7.568 (7.568)	prob 2.981 (2.981)	GS 34.266 (34.266)	mem 43.059
Train: [19][610/750]	BT 0.050 (1.160)	DT 0.001 (1.117)	loss 8.485 (8.485)	prob 2.595 (2.595)	GS 34.031 (34.031)	mem 43.077
Train: [19][615/750]	BT 0.031 (1.171)	DT 0.001 (1.128)	loss 8.061 (8.061)	prob 2.715 (2.715)	GS 33.391 (33.391)	mem 42.945
Train: [19][620/750]	BT 0.064 (1.162)	DT 0.002 (1.119)	loss 8.252 (8.252)	prob 2.316 (2.316)	GS 34.781 (34.781)	mem 42.989
Train: [19][625/750]	BT 0.033 (1.153)	DT 0.002 (1.110)	loss 8.501 (8.501)	prob 1.785 (1.785)	GS 30.734 (30.734)	mem 42.947
Train: [19][630/750]	BT 0.054 (1.166)	DT 0.001 (1.123)	loss 8.055 (8.055)	prob 2.543 (2.543)	GS 36.891 (36.891)	mem 42.975
Train: [19][635/750]	BT 0.025 (1.157)	DT 0.001 (1.114)	loss 7.979 (7.979)	prob 2.699 (2.699)	GS 28.297 (28.297)	mem 43.003
Train: [19][640/750]	BT 0.026 (1.168)	DT 0.001 (1.125)	loss 7.738 (7.738)	prob 3.781 (3.781)	GS 31.078 (31.078)	mem 42.954
Train: [19][645/750]	BT 0.033 (1.159)	DT 0.001 (1.117)	loss 7.704 (7.704)	prob 3.432 (3.432)	GS 29.000 (29.000)	mem 42.953
Train: [19][650/750]	BT 13.221 (1.171)	DT 13.186 (1.128)	loss 8.435 (8.435)	prob 3.123 (3.123)	GS 36.438 (36.438)	mem 43.136
Train: [19][655/750]	BT 0.034 (1.165)	DT 0.003 (1.122)	loss 7.539 (7.539)	prob 2.568 (2.568)	GS 28.859 (28.859)	mem 43.003
arpack error, retry= 0
Train: [19][660/750]	BT 0.056 (1.156)	DT 0.002 (1.113)	loss 8.002 (8.002)	prob 3.313 (3.313)	GS 32.031 (32.031)	mem 43.004
Train: [19][665/750]	BT 0.112 (1.171)	DT 0.021 (1.128)	loss 7.713 (7.713)	prob 3.253 (3.253)	GS 27.562 (27.562)	mem 43.006
Train: [19][670/750]	BT 0.029 (1.163)	DT 0.001 (1.119)	loss 7.786 (7.786)	prob 2.659 (2.659)	GS 32.328 (32.328)	mem 43.015
Train: [19][675/750]	BT 0.040 (1.174)	DT 0.010 (1.131)	loss 8.327 (8.327)	prob 2.731 (2.731)	GS 26.797 (26.797)	mem 43.071
Train: [19][680/750]	BT 0.030 (1.166)	DT 0.002 (1.123)	loss 9.275 (9.275)	prob 3.170 (3.170)	GS 34.859 (34.859)	mem 43.139
Train: [19][685/750]	BT 0.035 (1.158)	DT 0.001 (1.115)	loss 8.079 (8.079)	prob 2.411 (2.411)	GS 36.766 (36.766)	mem 43.140
Train: [19][690/750]	BT 0.028 (1.168)	DT 0.001 (1.124)	loss 7.993 (7.993)	prob 2.964 (2.964)	GS 35.609 (35.609)	mem 42.982
Train: [19][695/750]	BT 0.083 (1.160)	DT 0.001 (1.116)	loss 8.085 (8.085)	prob 2.820 (2.820)	GS 32.969 (32.969)	mem 43.197
Train: [19][700/750]	BT 2.334 (1.172)	DT 2.281 (1.129)	loss 7.846 (7.846)	prob 2.883 (2.883)	GS 32.797 (32.797)	mem 43.052
Train: [19][705/750]	BT 0.034 (1.164)	DT 0.003 (1.121)	loss 8.355 (8.355)	prob 2.334 (2.334)	GS 30.281 (30.281)	mem 43.136
Train: [19][710/750]	BT 9.781 (1.170)	DT 9.755 (1.126)	loss 8.346 (8.346)	prob 3.552 (3.552)	GS 33.031 (33.031)	mem 43.093
Train: [19][715/750]	BT 0.100 (1.163)	DT 0.012 (1.119)	loss 7.641 (7.641)	prob 3.214 (3.214)	GS 30.469 (30.469)	mem 43.057
Train: [19][720/750]	BT 0.066 (1.155)	DT 0.015 (1.112)	loss 8.624 (8.624)	prob 3.975 (3.975)	GS 31.984 (31.984)	mem 43.062
Train: [19][725/750]	BT 0.070 (1.163)	DT 0.004 (1.119)	loss 8.614 (8.614)	prob 3.096 (3.096)	GS 31.438 (31.438)	mem 42.988
Train: [19][730/750]	BT 0.033 (1.157)	DT 0.001 (1.113)	loss 8.204 (8.204)	prob 3.739 (3.739)	GS 33.484 (33.484)	mem 42.987
Train: [19][735/750]	BT 0.029 (1.163)	DT 0.002 (1.119)	loss 8.170 (8.170)	prob 3.285 (3.285)	GS 31.016 (31.016)	mem 39.707
Train: [19][740/750]	BT 0.030 (1.157)	DT 0.001 (1.113)	loss 7.758 (7.758)	prob 4.432 (4.432)	GS 31.781 (31.781)	mem 19.647
Train: [19][745/750]	BT 0.045 (1.149)	DT 0.010 (1.106)	loss 7.778 (7.778)	prob 3.457 (3.457)	GS 28.625 (28.625)	mem 19.647
Train: [19][750/750]	BT 0.210 (1.146)	DT 0.181 (1.103)	loss 8.518 (8.518)	prob 2.941 (2.941)	GS 35.688 (35.688)	mem 11.297
Train: [19][755/750]	BT 0.035 (1.139)	DT 0.001 (1.095)	loss 8.263 (8.263)	prob 3.288 (3.288)	GS 40.812 (40.812)	mem 10.716
epoch 19, total time 859.87
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [20][1/750]	BT 20.707 (20.707)	DT 20.658 (20.658)	loss 8.358 (8.358)	prob 3.341 (3.341)	GS 30.578 (30.578)	mem 41.664
Train: [20][5/750]	BT 0.047 (4.805)	DT 0.003 (4.758)	loss 7.605 (7.605)	prob 2.958 (2.958)	GS 27.266 (27.266)	mem 41.787
Train: [20][10/750]	BT 0.709 (2.506)	DT 0.673 (2.467)	loss 8.247 (8.247)	prob 3.313 (3.313)	GS 36.234 (36.234)	mem 41.770
Train: [20][15/750]	BT 0.124 (2.478)	DT 0.080 (2.432)	loss 7.818 (7.818)	prob 3.192 (3.192)	GS 32.078 (32.078)	mem 41.923
Train: [20][20/750]	BT 0.093 (2.049)	DT 0.005 (2.001)	loss 7.826 (7.826)	prob 4.280 (4.280)	GS 28.219 (28.219)	mem 42.020
Train: [20][25/750]	BT 0.045 (1.787)	DT 0.008 (1.736)	loss 7.850 (7.850)	prob 3.800 (3.800)	GS 26.188 (26.188)	mem 42.011
Train: [20][30/750]	BT 4.421 (1.890)	DT 4.388 (1.840)	loss 7.867 (7.867)	prob 4.155 (4.155)	GS 35.344 (35.344)	mem 42.199
Train: [20][35/750]	BT 0.036 (1.627)	DT 0.002 (1.579)	loss 7.716 (7.716)	prob 2.681 (2.681)	GS 40.344 (40.344)	mem 42.268
Train: [20][40/750]	BT 5.197 (1.712)	DT 5.164 (1.665)	loss 8.121 (8.121)	prob 3.187 (3.187)	GS 34.312 (34.312)	mem 42.089
Train: [20][45/750]	BT 0.069 (1.625)	DT 0.001 (1.577)	loss 8.388 (8.388)	prob 2.458 (2.458)	GS 28.969 (28.969)	mem 42.114
Train: [20][50/750]	BT 5.668 (1.581)	DT 5.637 (1.533)	loss 7.948 (7.948)	prob 3.835 (3.835)	GS 34.406 (34.406)	mem 42.174
Train: [20][55/750]	BT 0.094 (1.554)	DT 0.012 (1.504)	loss 7.570 (7.570)	prob 3.870 (3.870)	GS 28.375 (28.375)	mem 42.218
Train: [20][60/750]	BT 0.042 (1.434)	DT 0.009 (1.384)	loss 8.360 (8.360)	prob 3.378 (3.378)	GS 31.625 (31.625)	mem 42.183
Train: [20][65/750]	BT 0.049 (1.532)	DT 0.021 (1.482)	loss 7.995 (7.995)	prob 3.325 (3.325)	GS 29.844 (29.844)	mem 42.190
Train: [20][70/750]	BT 0.028 (1.426)	DT 0.003 (1.376)	loss 7.677 (7.677)	prob 4.482 (4.482)	GS 29.516 (29.516)	mem 42.192
Train: [20][75/750]	BT 0.035 (1.451)	DT 0.001 (1.402)	loss 8.113 (8.113)	prob 3.772 (3.772)	GS 34.859 (34.859)	mem 42.193
Train: [20][80/750]	BT 0.115 (1.427)	DT 0.005 (1.378)	loss 7.525 (7.525)	prob 4.477 (4.477)	GS 33.125 (33.125)	mem 42.139
Train: [20][85/750]	BT 0.038 (1.348)	DT 0.002 (1.297)	loss 8.106 (8.106)	prob 2.798 (2.798)	GS 31.422 (31.422)	mem 42.142
Train: [20][90/750]	BT 0.919 (1.412)	DT 0.874 (1.362)	loss 8.368 (8.368)	prob 3.564 (3.564)	GS 32.266 (32.266)	mem 42.191
Train: [20][95/750]	BT 0.037 (1.340)	DT 0.006 (1.291)	loss 8.104 (8.104)	prob 3.261 (3.261)	GS 30.891 (30.891)	mem 42.200
Train: [20][100/750]	BT 3.812 (1.378)	DT 3.765 (1.329)	loss 7.880 (7.880)	prob 4.685 (4.685)	GS 32.672 (32.672)	mem 42.404
Train: [20][105/750]	BT 0.036 (1.337)	DT 0.002 (1.289)	loss 8.695 (8.695)	prob 2.294 (2.294)	GS 36.219 (36.219)	mem 42.481
Train: [20][110/750]	BT 5.911 (1.332)	DT 5.880 (1.285)	loss 7.918 (7.918)	prob 3.169 (3.169)	GS 36.766 (36.766)	mem 42.587
Train: [20][115/750]	BT 0.027 (1.334)	DT 0.001 (1.288)	loss 7.432 (7.432)	prob 4.399 (4.399)	GS 36.422 (36.422)	mem 42.576
Train: [20][120/750]	BT 0.049 (1.281)	DT 0.004 (1.234)	loss 7.879 (7.879)	prob 3.214 (3.214)	GS 36.031 (36.031)	mem 42.577
Train: [20][125/750]	BT 0.032 (1.335)	DT 0.001 (1.288)	loss 7.686 (7.686)	prob 3.890 (3.890)	GS 29.672 (29.672)	mem 42.508
Train: [20][130/750]	BT 1.600 (1.298)	DT 1.560 (1.251)	loss 8.188 (8.188)	prob 4.354 (4.354)	GS 36.172 (36.172)	mem 42.452
Train: [20][135/750]	BT 0.048 (1.305)	DT 0.001 (1.258)	loss 8.139 (8.139)	prob 3.430 (3.430)	GS 33.250 (33.250)	mem 42.535
Train: [20][140/750]	BT 0.028 (1.306)	DT 0.002 (1.260)	loss 8.389 (8.389)	prob 4.525 (4.525)	GS 32.719 (32.719)	mem 42.487
Train: [20][145/750]	BT 0.138 (1.263)	DT 0.003 (1.216)	loss 7.766 (7.766)	prob 3.797 (3.797)	GS 27.359 (27.359)	mem 42.497
Train: [20][150/750]	BT 0.042 (1.297)	DT 0.001 (1.251)	loss 7.855 (7.855)	prob 3.680 (3.680)	GS 33.953 (33.953)	mem 42.650
Train: [20][155/750]	BT 0.048 (1.257)	DT 0.001 (1.211)	loss 7.932 (7.932)	prob 3.291 (3.291)	GS 36.750 (36.750)	mem 42.668
Train: [20][160/750]	BT 5.995 (1.281)	DT 5.954 (1.235)	loss 7.208 (7.208)	prob 4.215 (4.215)	GS 33.266 (33.266)	mem 43.028
Train: [20][165/750]	BT 0.106 (1.244)	DT 0.007 (1.197)	loss 7.741 (7.741)	prob 3.945 (3.945)	GS 32.531 (32.531)	mem 42.845
Train: [20][170/750]	BT 7.673 (1.264)	DT 7.641 (1.217)	loss 7.878 (7.878)	prob 3.732 (3.732)	GS 34.703 (34.703)	mem 42.782
Train: [20][175/750]	BT 0.034 (1.245)	DT 0.001 (1.198)	loss 8.037 (8.037)	prob 3.481 (3.481)	GS 31.031 (31.031)	mem 42.901
Train: [20][180/750]	BT 1.027 (1.218)	DT 0.928 (1.170)	loss 7.945 (7.945)	prob 3.787 (3.787)	GS 33.219 (33.219)	mem 42.834
Train: [20][185/750]	BT 0.096 (1.267)	DT 0.008 (1.219)	loss 7.807 (7.807)	prob 3.374 (3.374)	GS 27.641 (27.641)	mem 42.867
Train: [20][190/750]	BT 0.032 (1.235)	DT 0.001 (1.187)	loss 7.735 (7.735)	prob 4.543 (4.543)	GS 34.422 (34.422)	mem 42.830
Train: [20][195/750]	BT 0.032 (1.248)	DT 0.007 (1.201)	loss 7.732 (7.732)	prob 4.331 (4.331)	GS 33.438 (33.438)	mem 43.242
Train: [20][200/750]	BT 0.042 (1.262)	DT 0.002 (1.215)	loss 7.599 (7.599)	prob 4.334 (4.334)	GS 36.594 (36.594)	mem 42.910
Train: [20][205/750]	BT 0.054 (1.232)	DT 0.004 (1.185)	loss 7.922 (7.922)	prob 2.662 (2.662)	GS 37.438 (37.438)	mem 42.965
Train: [20][210/750]	BT 7.877 (1.291)	DT 7.845 (1.244)	loss 7.570 (7.570)	prob 3.564 (3.564)	GS 39.922 (39.922)	mem 43.003
Train: [20][215/750]	BT 0.035 (1.262)	DT 0.002 (1.215)	loss 7.834 (7.834)	prob 4.036 (4.036)	GS 33.172 (33.172)	mem 42.929
Train: [20][220/750]	BT 0.032 (1.234)	DT 0.001 (1.188)	loss 7.333 (7.333)	prob 4.333 (4.333)	GS 31.797 (31.797)	mem 42.947
Train: [20][225/750]	BT 0.035 (1.283)	DT 0.001 (1.236)	loss 7.582 (7.582)	prob 4.181 (4.181)	GS 33.609 (33.609)	mem 42.887
Train: [20][230/750]	BT 0.047 (1.256)	DT 0.004 (1.209)	loss 7.682 (7.682)	prob 4.033 (4.033)	GS 36.422 (36.422)	mem 42.888
Train: [20][235/750]	BT 0.030 (1.278)	DT 0.001 (1.232)	loss 7.667 (7.667)	prob 3.929 (3.929)	GS 29.344 (29.344)	mem 43.002
Train: [20][240/750]	BT 0.030 (1.252)	DT 0.001 (1.206)	loss 7.551 (7.551)	prob 4.601 (4.601)	GS 33.500 (33.500)	mem 43.002
Train: [20][245/750]	BT 0.068 (1.228)	DT 0.002 (1.182)	loss 8.018 (8.018)	prob 2.971 (2.971)	GS 35.062 (35.062)	mem 43.002
Train: [20][250/750]	BT 0.023 (1.247)	DT 0.001 (1.202)	loss 7.494 (7.494)	prob 4.224 (4.224)	GS 30.562 (30.562)	mem 43.040
Train: [20][255/750]	BT 0.030 (1.224)	DT 0.001 (1.179)	loss 7.458 (7.458)	prob 3.988 (3.988)	GS 31.344 (31.344)	mem 43.040
Train: [20][260/750]	BT 0.032 (1.242)	DT 0.001 (1.197)	loss 7.769 (7.769)	prob 4.269 (4.269)	GS 35.281 (35.281)	mem 43.073
Train: [20][265/750]	BT 0.048 (1.219)	DT 0.008 (1.175)	loss 7.641 (7.641)	prob 4.085 (4.085)	GS 31.547 (31.547)	mem 43.074
Train: [20][270/750]	BT 12.019 (1.242)	DT 11.971 (1.197)	loss 7.869 (7.869)	prob 4.018 (4.018)	GS 33.141 (33.141)	mem 43.116
Train: [20][275/750]	BT 0.054 (1.220)	DT 0.009 (1.176)	loss 7.681 (7.681)	prob 3.770 (3.770)	GS 34.891 (34.891)	mem 43.004
Train: [20][280/750]	BT 0.034 (1.199)	DT 0.002 (1.155)	loss 7.160 (7.160)	prob 4.089 (4.089)	GS 34.078 (34.078)	mem 43.063
Train: [20][285/750]	BT 0.033 (1.225)	DT 0.001 (1.180)	loss 7.678 (7.678)	prob 3.387 (3.387)	GS 32.344 (32.344)	mem 43.082
Train: [20][290/750]	BT 0.033 (1.204)	DT 0.002 (1.160)	loss 7.595 (7.595)	prob 4.200 (4.200)	GS 36.266 (36.266)	mem 43.067
Train: [20][295/750]	BT 0.055 (1.222)	DT 0.012 (1.178)	loss 7.686 (7.686)	prob 3.549 (3.549)	GS 30.609 (30.609)	mem 43.045
Train: [20][300/750]	BT 0.027 (1.202)	DT 0.001 (1.158)	loss 7.578 (7.578)	prob 3.631 (3.631)	GS 33.250 (33.250)	mem 43.142
Train: [20][305/750]	BT 0.102 (1.183)	DT 0.002 (1.139)	loss 7.902 (7.902)	prob 3.430 (3.430)	GS 30.000 (30.000)	mem 43.047
Train: [20][310/750]	BT 0.066 (1.210)	DT 0.002 (1.166)	loss 7.619 (7.619)	prob 4.551 (4.551)	GS 33.656 (33.656)	mem 43.083
Train: [20][315/750]	BT 0.098 (1.192)	DT 0.002 (1.147)	loss 7.716 (7.716)	prob 3.567 (3.567)	GS 28.203 (28.203)	mem 43.096
Train: [20][320/750]	BT 0.034 (1.218)	DT 0.001 (1.174)	loss 7.414 (7.414)	prob 4.318 (4.318)	GS 30.156 (30.156)	mem 43.063
Train: [20][325/750]	BT 0.058 (1.200)	DT 0.003 (1.156)	loss 7.542 (7.542)	prob 3.631 (3.631)	GS 31.531 (31.531)	mem 43.152
Train: [20][330/750]	BT 10.454 (1.214)	DT 10.389 (1.170)	loss 7.382 (7.382)	prob 3.830 (3.830)	GS 33.469 (33.469)	mem 43.038
Train: [20][335/750]	BT 0.029 (1.197)	DT 0.001 (1.153)	loss 7.577 (7.577)	prob 3.104 (3.104)	GS 33.750 (33.750)	mem 43.008
Train: [20][340/750]	BT 0.046 (1.180)	DT 0.004 (1.136)	loss 7.416 (7.416)	prob 3.643 (3.643)	GS 32.641 (32.641)	mem 43.015
Train: [20][345/750]	BT 0.049 (1.207)	DT 0.008 (1.162)	loss 7.383 (7.383)	prob 3.926 (3.926)	GS 30.516 (30.516)	mem 42.930
Train: [20][350/750]	BT 0.024 (1.190)	DT 0.002 (1.145)	loss 7.845 (7.845)	prob 3.546 (3.546)	GS 34.031 (34.031)	mem 42.933
Train: [20][355/750]	BT 0.048 (1.211)	DT 0.003 (1.167)	loss 7.436 (7.436)	prob 4.083 (4.083)	GS 29.594 (29.594)	mem 42.870
Train: [20][360/750]	BT 0.028 (1.195)	DT 0.001 (1.151)	loss 7.222 (7.222)	prob 3.900 (3.900)	GS 30.906 (30.906)	mem 42.871
Train: [20][365/750]	BT 0.045 (1.179)	DT 0.003 (1.135)	loss 7.368 (7.368)	prob 3.959 (3.959)	GS 28.078 (28.078)	mem 42.873
Train: [20][370/750]	BT 0.036 (1.188)	DT 0.003 (1.144)	loss 7.518 (7.518)	prob 4.079 (4.079)	GS 33.344 (33.344)	mem 42.970
Train: [20][375/750]	BT 0.068 (1.173)	DT 0.011 (1.129)	loss 7.407 (7.407)	prob 3.685 (3.685)	GS 30.719 (30.719)	mem 42.977
Train: [20][380/750]	BT 0.024 (1.198)	DT 0.001 (1.154)	loss 7.755 (7.755)	prob 3.961 (3.961)	GS 29.344 (29.344)	mem 43.116
Train: [20][385/750]	BT 0.057 (1.183)	DT 0.001 (1.139)	loss 7.326 (7.326)	prob 3.699 (3.699)	GS 30.703 (30.703)	mem 43.086
Train: [20][390/750]	BT 12.202 (1.200)	DT 12.137 (1.155)	loss 7.449 (7.449)	prob 4.283 (4.283)	GS 34.203 (34.203)	mem 43.342
Train: [20][395/750]	BT 0.075 (1.186)	DT 0.005 (1.141)	loss 7.542 (7.542)	prob 3.425 (3.425)	GS 30.000 (30.000)	mem 43.184
Train: [20][400/750]	BT 0.034 (1.171)	DT 0.001 (1.127)	loss 7.350 (7.350)	prob 4.395 (4.395)	GS 34.438 (34.438)	mem 43.183
Train: [20][405/750]	BT 0.030 (1.188)	DT 0.001 (1.143)	loss 7.387 (7.387)	prob 4.385 (4.385)	GS 31.906 (31.906)	mem 43.023
Train: [20][410/750]	BT 0.050 (1.174)	DT 0.001 (1.129)	loss 7.689 (7.689)	prob 4.303 (4.303)	GS 32.188 (32.188)	mem 43.023
Train: [20][415/750]	BT 0.069 (1.189)	DT 0.012 (1.145)	loss 7.616 (7.616)	prob 3.332 (3.332)	GS 31.406 (31.406)	mem 43.033
Train: [20][420/750]	BT 0.026 (1.175)	DT 0.001 (1.131)	loss 7.326 (7.326)	prob 4.603 (4.603)	GS 30.859 (30.859)	mem 43.034
Train: [20][425/750]	BT 0.035 (1.162)	DT 0.002 (1.118)	loss 7.402 (7.402)	prob 3.185 (3.185)	GS 28.062 (28.062)	mem 43.034
Train: [20][430/750]	BT 0.050 (1.178)	DT 0.001 (1.134)	loss 7.319 (7.319)	prob 4.601 (4.601)	GS 34.406 (34.406)	mem 43.108
Train: [20][435/750]	BT 0.030 (1.165)	DT 0.002 (1.121)	loss 7.543 (7.543)	prob 3.855 (3.855)	GS 39.141 (39.141)	mem 42.996
Train: [20][440/750]	BT 0.060 (1.179)	DT 0.014 (1.136)	loss 7.819 (7.819)	prob 3.355 (3.355)	GS 36.531 (36.531)	mem 43.134
Train: [20][445/750]	BT 0.025 (1.167)	DT 0.003 (1.123)	loss 7.327 (7.327)	prob 3.622 (3.622)	GS 29.047 (29.047)	mem 43.025
Train: [20][450/750]	BT 11.132 (1.179)	DT 11.093 (1.135)	loss 7.508 (7.508)	prob 3.424 (3.424)	GS 33.547 (33.547)	mem 43.106
Train: [20][455/750]	BT 0.038 (1.166)	DT 0.001 (1.123)	loss 7.788 (7.788)	prob 3.280 (3.280)	GS 34.719 (34.719)	mem 43.016
Train: [20][460/750]	BT 0.033 (1.154)	DT 0.002 (1.110)	loss 7.394 (7.394)	prob 4.056 (4.056)	GS 34.578 (34.578)	mem 43.018
Train: [20][465/750]	BT 0.076 (1.167)	DT 0.008 (1.123)	loss 7.351 (7.351)	prob 3.576 (3.576)	GS 28.734 (28.734)	mem 43.115
Train: [20][470/750]	BT 0.057 (1.155)	DT 0.007 (1.111)	loss 7.424 (7.424)	prob 3.949 (3.949)	GS 34.469 (34.469)	mem 43.040
Train: [20][475/750]	BT 0.028 (1.173)	DT 0.001 (1.129)	loss 7.538 (7.538)	prob 3.090 (3.090)	GS 32.562 (32.562)	mem 43.049
Train: [20][480/750]	BT 0.046 (1.162)	DT 0.001 (1.118)	loss 7.422 (7.422)	prob 3.626 (3.626)	GS 35.766 (35.766)	mem 43.086
Train: [20][485/750]	BT 0.032 (1.150)	DT 0.002 (1.106)	loss 7.206 (7.206)	prob 3.645 (3.645)	GS 31.781 (31.781)	mem 43.049
Train: [20][490/750]	BT 0.077 (1.163)	DT 0.005 (1.119)	loss 7.309 (7.309)	prob 3.708 (3.708)	GS 35.219 (35.219)	mem 40.726
Train: [20][495/750]	BT 0.059 (1.152)	DT 0.021 (1.107)	loss 7.445 (7.445)	prob 3.071 (3.071)	GS 31.547 (31.547)	mem 40.916
Train: [20][500/750]	BT 0.049 (1.167)	DT 0.002 (1.123)	loss 7.414 (7.414)	prob 3.838 (3.838)	GS 28.891 (28.891)	mem 40.634
Train: [20][505/750]	BT 0.062 (1.156)	DT 0.011 (1.112)	loss 7.354 (7.354)	prob 3.780 (3.780)	GS 27.328 (27.328)	mem 40.698
Train: [20][510/750]	BT 10.601 (1.166)	DT 10.564 (1.121)	loss 7.652 (7.652)	prob 3.508 (3.508)	GS 28.359 (28.359)	mem 40.586
Train: [20][515/750]	BT 0.032 (1.155)	DT 0.001 (1.111)	loss 7.550 (7.550)	prob 3.117 (3.117)	GS 32.812 (32.812)	mem 40.575
Train: [20][520/750]	BT 0.044 (1.144)	DT 0.003 (1.100)	loss 7.225 (7.225)	prob 4.011 (4.011)	GS 31.703 (31.703)	mem 40.577
Train: [20][525/750]	BT 0.058 (1.163)	DT 0.001 (1.118)	loss 7.109 (7.109)	prob 3.833 (3.833)	GS 28.656 (28.656)	mem 40.471
Train: [20][530/750]	BT 0.120 (1.152)	DT 0.010 (1.108)	loss 7.248 (7.248)	prob 3.957 (3.957)	GS 34.203 (34.203)	mem 40.540
Train: [20][535/750]	BT 0.036 (1.163)	DT 0.001 (1.118)	loss 7.238 (7.238)	prob 3.607 (3.607)	GS 28.844 (28.844)	mem 40.606
Train: [20][540/750]	BT 0.033 (1.153)	DT 0.001 (1.108)	loss 7.200 (7.200)	prob 3.729 (3.729)	GS 33.078 (33.078)	mem 40.563
Train: [20][545/750]	BT 0.040 (1.143)	DT 0.011 (1.098)	loss 7.143 (7.143)	prob 3.330 (3.330)	GS 35.875 (35.875)	mem 40.564
Train: [20][550/750]	BT 0.071 (1.161)	DT 0.010 (1.116)	loss 7.200 (7.200)	prob 2.932 (2.932)	GS 31.891 (31.891)	mem 40.592
Train: [20][555/750]	BT 0.067 (1.151)	DT 0.026 (1.106)	loss 7.545 (7.545)	prob 2.232 (2.232)	GS 33.500 (33.500)	mem 40.592
Train: [20][560/750]	BT 0.072 (1.160)	DT 0.015 (1.116)	loss 7.257 (7.257)	prob 3.219 (3.219)	GS 31.156 (31.156)	mem 40.776
Train: [20][565/750]	BT 0.036 (1.150)	DT 0.001 (1.106)	loss 7.278 (7.278)	prob 3.005 (3.005)	GS 27.250 (27.250)	mem 40.525
Train: [20][570/750]	BT 14.207 (1.166)	DT 14.185 (1.121)	loss 7.241 (7.241)	prob 2.521 (2.521)	GS 38.062 (38.062)	mem 40.462
Train: [20][575/750]	BT 0.032 (1.156)	DT 0.002 (1.112)	loss 7.298 (7.298)	prob 2.433 (2.433)	GS 35.203 (35.203)	mem 40.463
Train: [20][580/750]	BT 0.042 (1.146)	DT 0.002 (1.102)	loss 7.136 (7.136)	prob 2.244 (2.244)	GS 36.344 (36.344)	mem 40.463
Train: [20][585/750]	BT 0.022 (1.161)	DT 0.001 (1.117)	loss 7.336 (7.336)	prob 2.714 (2.714)	GS 31.531 (31.531)	mem 40.588
Train: [20][590/750]	BT 0.039 (1.151)	DT 0.003 (1.108)	loss 7.230 (7.230)	prob 3.249 (3.249)	GS 34.156 (34.156)	mem 40.634
Train: [20][595/750]	BT 0.086 (1.168)	DT 0.008 (1.124)	loss 7.631 (7.631)	prob 2.409 (2.409)	GS 31.156 (31.156)	mem 40.630
Train: [20][600/750]	BT 0.023 (1.158)	DT 0.001 (1.114)	loss 7.211 (7.211)	prob 2.908 (2.908)	GS 32.672 (32.672)	mem 40.555
Train: [20][605/750]	BT 0.041 (1.149)	DT 0.001 (1.105)	loss 7.638 (7.638)	prob 2.149 (2.149)	GS 33.781 (33.781)	mem 40.705
Train: [20][610/750]	BT 0.027 (1.164)	DT 0.001 (1.120)	loss 7.002 (7.002)	prob 2.889 (2.889)	GS 36.062 (36.062)	mem 40.530
Train: [20][615/750]	BT 0.044 (1.155)	DT 0.001 (1.111)	loss 7.153 (7.153)	prob 2.859 (2.859)	GS 36.703 (36.703)	mem 40.531
Train: [20][620/750]	BT 0.028 (1.164)	DT 0.001 (1.120)	loss 7.548 (7.548)	prob 2.562 (2.562)	GS 33.594 (33.594)	mem 40.742
Train: [20][625/750]	BT 0.039 (1.155)	DT 0.004 (1.111)	loss 7.582 (7.582)	prob 1.710 (1.710)	GS 34.672 (34.672)	mem 40.622
Train: [20][630/750]	BT 11.582 (1.165)	DT 11.535 (1.121)	loss 7.382 (7.382)	prob 3.107 (3.107)	GS 31.797 (31.797)	mem 40.639
Train: [20][635/750]	BT 0.032 (1.156)	DT 0.002 (1.112)	loss 7.281 (7.281)	prob 2.790 (2.790)	GS 29.672 (29.672)	mem 40.596
Train: [20][640/750]	BT 0.062 (1.147)	DT 0.012 (1.103)	loss 7.144 (7.144)	prob 2.383 (2.383)	GS 40.000 (40.000)	mem 40.597
Train: [20][645/750]	BT 0.050 (1.158)	DT 0.007 (1.114)	loss 7.037 (7.037)	prob 2.611 (2.611)	GS 34.828 (34.828)	mem 40.871
Train: [20][650/750]	BT 0.038 (1.150)	DT 0.002 (1.106)	loss 7.127 (7.127)	prob 2.723 (2.723)	GS 35.250 (35.250)	mem 40.566
Train: [20][655/750]	BT 0.118 (1.155)	DT 0.002 (1.112)	loss 7.463 (7.463)	prob 2.351 (2.351)	GS 37.500 (37.500)	mem 40.605
Train: [20][660/750]	BT 0.027 (1.154)	DT 0.001 (1.110)	loss 7.072 (7.072)	prob 2.511 (2.511)	GS 33.141 (33.141)	mem 40.552
Train: [20][665/750]	BT 0.025 (1.145)	DT 0.001 (1.102)	loss 7.288 (7.288)	prob 2.502 (2.502)	GS 30.562 (30.562)	mem 40.533
Train: [20][670/750]	BT 6.620 (1.158)	DT 6.573 (1.115)	loss 7.023 (7.023)	prob 3.017 (3.017)	GS 34.812 (34.812)	mem 40.621
Train: [20][675/750]	BT 0.060 (1.150)	DT 0.030 (1.106)	loss 7.388 (7.388)	prob 2.484 (2.484)	GS 37.203 (37.203)	mem 40.623
Train: [20][680/750]	BT 0.027 (1.154)	DT 0.001 (1.111)	loss 7.067 (7.067)	prob 2.575 (2.575)	GS 37.750 (37.750)	mem 40.544
Train: [20][685/750]	BT 0.055 (1.157)	DT 0.004 (1.114)	loss 7.102 (7.102)	prob 2.914 (2.914)	GS 32.734 (32.734)	mem 40.544
Train: [20][690/750]	BT 4.603 (1.156)	DT 4.557 (1.112)	loss 7.068 (7.068)	prob 2.436 (2.436)	GS 35.828 (35.828)	mem 40.693
Train: [20][695/750]	BT 0.033 (1.156)	DT 0.003 (1.113)	loss 7.391 (7.391)	prob 2.461 (2.461)	GS 32.781 (32.781)	mem 40.564
Train: [20][700/750]	BT 1.422 (1.150)	DT 1.350 (1.107)	loss 7.118 (7.118)	prob 2.986 (2.986)	GS 37.656 (37.656)	mem 40.590
Train: [20][705/750]	BT 0.099 (1.147)	DT 0.005 (1.103)	loss 7.250 (7.250)	prob 2.287 (2.287)	GS 30.875 (30.875)	mem 40.633
Train: [20][710/750]	BT 0.055 (1.150)	DT 0.007 (1.106)	loss 7.438 (7.438)	prob 2.875 (2.875)	GS 34.312 (34.312)	mem 40.610
Train: [20][715/750]	BT 0.036 (1.152)	DT 0.006 (1.108)	loss 7.012 (7.012)	prob 2.780 (2.780)	GS 27.766 (27.766)	mem 40.632
Train: [20][720/750]	BT 0.122 (1.154)	DT 0.028 (1.110)	loss 7.161 (7.161)	prob 2.455 (2.455)	GS 30.094 (30.094)	mem 40.621
Train: [20][725/750]	BT 0.047 (1.151)	DT 0.003 (1.107)	loss 7.375 (7.375)	prob 2.444 (2.444)	GS 32.141 (32.141)	mem 40.579
Train: [20][730/750]	BT 4.438 (1.156)	DT 4.406 (1.113)	loss 6.947 (6.947)	prob 3.191 (3.191)	GS 35.438 (35.438)	mem 40.356
Train: [20][735/750]	BT 0.047 (1.149)	DT 0.010 (1.105)	loss 7.138 (7.138)	prob 2.952 (2.952)	GS 29.594 (29.594)	mem 40.358
Train: [20][740/750]	BT 0.023 (1.147)	DT 0.001 (1.103)	loss 6.882 (6.882)	prob 2.966 (2.966)	GS 40.922 (40.922)	mem 20.131
Train: [20][745/750]	BT 0.032 (1.143)	DT 0.002 (1.100)	loss 6.882 (6.882)	prob 3.219 (3.219)	GS 28.812 (28.812)	mem 11.274
Train: [20][750/750]	BT 0.481 (1.136)	DT 0.451 (1.093)	loss 7.031 (7.031)	prob 2.944 (2.944)	GS 28.219 (28.219)	mem 11.251
Train: [20][755/750]	BT 0.029 (1.133)	DT 0.001 (1.089)	loss 7.071 (7.071)	prob 2.214 (2.214)	GS 31.688 (31.688)	mem 8.255
epoch 20, total time 855.51
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [21][1/750]	BT 19.991 (19.991)	DT 19.935 (19.935)	loss 6.944 (6.944)	prob 2.586 (2.586)	GS 31.109 (31.109)	mem 38.788
Train: [21][5/750]	BT 4.795 (5.330)	DT 4.723 (5.273)	loss 7.111 (7.111)	prob 1.773 (1.773)	GS 31.266 (31.266)	mem 38.832
Train: [21][10/750]	BT 0.043 (2.702)	DT 0.001 (2.641)	loss 7.080 (7.080)	prob 3.094 (3.094)	GS 34.391 (34.391)	mem 38.852
Train: [21][15/750]	BT 0.809 (2.002)	DT 0.775 (1.941)	loss 6.995 (6.995)	prob 2.149 (2.149)	GS 29.750 (29.750)	mem 38.927
Train: [21][20/750]	BT 0.056 (1.782)	DT 0.019 (1.727)	loss 6.838 (6.838)	prob 3.058 (3.058)	GS 33.938 (33.938)	mem 38.972
Train: [21][25/750]	BT 0.026 (1.725)	DT 0.001 (1.671)	loss 7.269 (7.269)	prob 2.056 (2.056)	GS 33.312 (33.312)	mem 39.090
Train: [21][30/750]	BT 0.030 (1.577)	DT 0.006 (1.526)	loss 6.921 (6.921)	prob 3.026 (3.026)	GS 35.953 (35.953)	mem 39.060
Train: [21][35/750]	BT 0.032 (1.442)	DT 0.001 (1.393)	loss 7.274 (7.274)	prob 2.554 (2.554)	GS 37.297 (37.297)	mem 39.104
Train: [21][40/750]	BT 6.708 (1.558)	DT 6.657 (1.509)	loss 6.958 (6.958)	prob 3.187 (3.187)	GS 38.406 (38.406)	mem 39.276
Train: [21][45/750]	BT 0.044 (1.399)	DT 0.009 (1.350)	loss 7.084 (7.084)	prob 2.316 (2.316)	GS 27.625 (27.625)	mem 39.145
Train: [21][50/750]	BT 6.365 (1.432)	DT 6.328 (1.384)	loss 6.996 (6.996)	prob 2.718 (2.718)	GS 35.781 (35.781)	mem 39.170
Train: [21][55/750]	BT 0.047 (1.398)	DT 0.001 (1.350)	loss 7.354 (7.354)	prob 2.394 (2.394)	GS 34.297 (34.297)	mem 39.162
Train: [21][60/750]	BT 6.760 (1.401)	DT 6.711 (1.353)	loss 7.201 (7.201)	prob 2.381 (2.381)	GS 32.266 (32.266)	mem 39.224
Train: [21][65/750]	BT 0.122 (1.401)	DT 0.002 (1.352)	loss 7.129 (7.129)	prob 2.300 (2.300)	GS 31.984 (31.984)	mem 39.332
Train: [21][70/750]	BT 0.035 (1.304)	DT 0.002 (1.256)	loss 7.177 (7.177)	prob 2.561 (2.561)	GS 30.672 (30.672)	mem 39.235
Train: [21][75/750]	BT 0.032 (1.377)	DT 0.001 (1.329)	loss 6.956 (6.956)	prob 2.687 (2.687)	GS 29.625 (29.625)	mem 39.319
Train: [21][80/750]	BT 0.054 (1.350)	DT 0.015 (1.302)	loss 7.052 (7.052)	prob 2.675 (2.675)	GS 25.859 (25.859)	mem 39.538
Train: [21][85/750]	BT 0.033 (1.387)	DT 0.001 (1.339)	loss 7.662 (7.662)	prob 1.737 (1.737)	GS 44.438 (44.438)	mem 39.581
Train: [21][90/750]	BT 0.031 (1.377)	DT 0.001 (1.328)	loss 7.223 (7.223)	prob 3.304 (3.304)	GS 36.531 (36.531)	mem 39.634
Train: [21][95/750]	BT 0.048 (1.308)	DT 0.012 (1.259)	loss 7.073 (7.073)	prob 2.499 (2.499)	GS 35.438 (35.438)	mem 39.789
Train: [21][100/750]	BT 2.372 (1.375)	DT 2.321 (1.326)	loss 7.201 (7.201)	prob 2.519 (2.519)	GS 36.188 (36.188)	mem 39.738
Train: [21][105/750]	BT 0.049 (1.313)	DT 0.007 (1.264)	loss 7.252 (7.252)	prob 2.475 (2.475)	GS 35.250 (35.250)	mem 39.700
Train: [21][110/750]	BT 0.117 (1.335)	DT 0.001 (1.285)	loss 7.193 (7.193)	prob 3.234 (3.234)	GS 33.656 (33.656)	mem 39.858
Train: [21][115/750]	BT 0.031 (1.336)	DT 0.001 (1.287)	loss 7.213 (7.213)	prob 2.636 (2.636)	GS 27.656 (27.656)	mem 39.743
Train: [21][120/750]	BT 1.605 (1.295)	DT 1.547 (1.247)	loss 7.051 (7.051)	prob 3.032 (3.032)	GS 35.625 (35.625)	mem 39.761
Train: [21][125/750]	BT 0.097 (1.347)	DT 0.010 (1.298)	loss 7.289 (7.289)	prob 2.504 (2.504)	GS 29.094 (29.094)	mem 39.944
Train: [21][130/750]	BT 0.022 (1.296)	DT 0.001 (1.248)	loss 7.237 (7.237)	prob 2.712 (2.712)	GS 33.828 (33.828)	mem 39.854
Train: [21][135/750]	BT 0.032 (1.297)	DT 0.001 (1.249)	loss 6.990 (6.990)	prob 3.251 (3.251)	GS 31.469 (31.469)	mem 39.880
Train: [21][140/750]	BT 0.032 (1.294)	DT 0.002 (1.247)	loss 7.017 (7.017)	prob 3.413 (3.413)	GS 31.062 (31.062)	mem 39.871
Train: [21][145/750]	BT 0.134 (1.306)	DT 0.043 (1.258)	loss 7.308 (7.308)	prob 2.914 (2.914)	GS 28.750 (28.750)	mem 39.812
Train: [21][150/750]	BT 0.102 (1.273)	DT 0.020 (1.225)	loss 7.052 (7.052)	prob 2.745 (2.745)	GS 30.844 (30.844)	mem 39.754
Train: [21][155/750]	BT 0.052 (1.233)	DT 0.014 (1.186)	loss 7.276 (7.276)	prob 2.641 (2.641)	GS 32.938 (32.938)	mem 39.766
Train: [21][160/750]	BT 2.691 (1.279)	DT 2.652 (1.232)	loss 7.123 (7.123)	prob 2.840 (2.840)	GS 34.031 (34.031)	mem 39.719
Train: [21][165/750]	BT 0.115 (1.242)	DT 0.006 (1.194)	loss 7.058 (7.058)	prob 2.994 (2.994)	GS 32.172 (32.172)	mem 39.740
Train: [21][170/750]	BT 0.094 (1.249)	DT 0.008 (1.202)	loss 7.063 (7.063)	prob 3.192 (3.192)	GS 34.531 (34.531)	mem 39.826
Train: [21][175/750]	BT 0.023 (1.246)	DT 0.001 (1.199)	loss 7.088 (7.088)	prob 2.750 (2.750)	GS 32.766 (32.766)	mem 39.776
Train: [21][180/750]	BT 3.536 (1.232)	DT 3.492 (1.185)	loss 7.040 (7.040)	prob 2.917 (2.917)	GS 33.906 (33.906)	mem 39.799
Train: [21][185/750]	BT 0.043 (1.244)	DT 0.007 (1.196)	loss 7.013 (7.013)	prob 2.425 (2.425)	GS 34.094 (34.094)	mem 39.837
Train: [21][190/750]	BT 0.054 (1.212)	DT 0.002 (1.165)	loss 7.013 (7.013)	prob 2.832 (2.832)	GS 31.047 (31.047)	mem 39.879
Train: [21][195/750]	BT 0.092 (1.216)	DT 0.008 (1.169)	loss 6.984 (6.984)	prob 2.440 (2.440)	GS 34.000 (34.000)	mem 40.024
Train: [21][200/750]	BT 0.044 (1.229)	DT 0.002 (1.181)	loss 7.100 (7.100)	prob 3.222 (3.222)	GS 35.703 (35.703)	mem 39.855
Train: [21][205/750]	BT 0.046 (1.217)	DT 0.002 (1.169)	loss 6.998 (6.998)	prob 2.860 (2.860)	GS 34.609 (34.609)	mem 39.901
Train: [21][210/750]	BT 6.004 (1.239)	DT 5.969 (1.191)	loss 6.972 (6.972)	prob 2.688 (2.688)	GS 33.875 (33.875)	mem 39.971
Train: [21][215/750]	BT 0.057 (1.211)	DT 0.001 (1.163)	loss 7.478 (7.478)	prob 1.695 (1.695)	GS 35.656 (35.656)	mem 39.926
Train: [21][220/750]	BT 4.417 (1.222)	DT 4.356 (1.174)	loss 6.897 (6.897)	prob 3.812 (3.812)	GS 33.312 (33.312)	mem 39.971
Train: [21][225/750]	BT 0.035 (1.203)	DT 0.005 (1.155)	loss 7.016 (7.016)	prob 2.398 (2.398)	GS 31.578 (31.578)	mem 40.008
Train: [21][230/750]	BT 2.659 (1.213)	DT 2.631 (1.166)	loss 7.005 (7.005)	prob 3.535 (3.535)	GS 32.734 (32.734)	mem 39.879
Train: [21][235/750]	BT 0.124 (1.191)	DT 0.026 (1.143)	loss 7.586 (7.586)	prob 2.684 (2.684)	GS 32.562 (32.562)	mem 39.880
Train: [21][240/750]	BT 7.479 (1.198)	DT 7.443 (1.150)	loss 6.966 (6.966)	prob 2.679 (2.679)	GS 36.156 (36.156)	mem 39.965
Train: [21][245/750]	BT 0.092 (1.204)	DT 0.028 (1.156)	loss 7.100 (7.100)	prob 2.648 (2.648)	GS 31.594 (31.594)	mem 40.116
Train: [21][250/750]	BT 0.064 (1.181)	DT 0.012 (1.133)	loss 7.185 (7.185)	prob 2.677 (2.677)	GS 33.594 (33.594)	mem 40.011
Train: [21][255/750]	BT 0.051 (1.200)	DT 0.016 (1.152)	loss 7.037 (7.037)	prob 2.699 (2.699)	GS 33.734 (33.734)	mem 39.890
Train: [21][260/750]	BT 0.040 (1.188)	DT 0.004 (1.140)	loss 6.971 (6.971)	prob 3.421 (3.421)	GS 31.141 (31.141)	mem 39.950
Train: [21][265/750]	BT 0.051 (1.171)	DT 0.008 (1.123)	loss 7.080 (7.080)	prob 2.561 (2.561)	GS 29.422 (29.422)	mem 40.056
Train: [21][270/750]	BT 0.025 (1.188)	DT 0.001 (1.140)	loss 7.165 (7.165)	prob 2.859 (2.859)	GS 37.797 (37.797)	mem 40.052
Train: [21][275/750]	BT 0.034 (1.168)	DT 0.001 (1.120)	loss 7.300 (7.300)	prob 2.657 (2.657)	GS 30.859 (30.859)	mem 39.954
Train: [21][280/750]	BT 0.026 (1.194)	DT 0.001 (1.147)	loss 7.023 (7.023)	prob 3.001 (3.001)	GS 32.266 (32.266)	mem 40.059
Train: [21][285/750]	BT 0.025 (1.174)	DT 0.001 (1.126)	loss 7.191 (7.191)	prob 2.911 (2.911)	GS 35.375 (35.375)	mem 40.001
Train: [21][290/750]	BT 16.181 (1.211)	DT 16.149 (1.163)	loss 7.011 (7.011)	prob 3.347 (3.347)	GS 35.844 (35.844)	mem 39.970
Train: [21][295/750]	BT 0.032 (1.191)	DT 0.001 (1.143)	loss 6.868 (6.868)	prob 3.640 (3.640)	GS 32.688 (32.688)	mem 39.972
Train: [21][300/750]	BT 0.107 (1.172)	DT 0.016 (1.124)	loss 7.101 (7.101)	prob 2.734 (2.734)	GS 37.062 (37.062)	mem 39.973
Train: [21][305/750]	BT 0.032 (1.187)	DT 0.002 (1.139)	loss 7.092 (7.092)	prob 2.993 (2.993)	GS 30.188 (30.188)	mem 40.063
Train: [21][310/750]	BT 0.030 (1.168)	DT 0.001 (1.121)	loss 7.198 (7.198)	prob 3.084 (3.084)	GS 36.281 (36.281)	mem 40.004
Train: [21][315/750]	BT 0.031 (1.197)	DT 0.001 (1.150)	loss 7.322 (7.322)	prob 2.490 (2.490)	GS 31.312 (31.312)	mem 39.905
Train: [21][320/750]	BT 0.049 (1.179)	DT 0.018 (1.132)	loss 7.036 (7.036)	prob 3.344 (3.344)	GS 29.391 (29.391)	mem 39.910
Train: [21][325/750]	BT 0.035 (1.162)	DT 0.011 (1.115)	loss 6.969 (6.969)	prob 3.650 (3.650)	GS 29.156 (29.156)	mem 39.922
Train: [21][330/750]	BT 0.080 (1.183)	DT 0.011 (1.136)	loss 7.345 (7.345)	prob 2.682 (2.682)	GS 30.250 (30.250)	mem 40.057
Train: [21][335/750]	BT 0.053 (1.166)	DT 0.010 (1.119)	loss 7.164 (7.164)	prob 2.940 (2.940)	GS 34.156 (34.156)	mem 40.058
Train: [21][340/750]	BT 0.878 (1.186)	DT 0.847 (1.140)	loss 7.165 (7.165)	prob 2.990 (2.990)	GS 31.359 (31.359)	mem 39.853
Train: [21][345/750]	BT 0.095 (1.170)	DT 0.018 (1.123)	loss 7.258 (7.258)	prob 2.636 (2.636)	GS 28.172 (28.172)	mem 39.897
Train: [21][350/750]	BT 13.504 (1.193)	DT 13.406 (1.146)	loss 7.019 (7.019)	prob 3.045 (3.045)	GS 35.312 (35.312)	mem 39.915
Train: [21][355/750]	BT 0.031 (1.183)	DT 0.001 (1.136)	loss 7.177 (7.177)	prob 3.249 (3.249)	GS 29.125 (29.125)	mem 39.966
Train: [21][360/750]	BT 0.058 (1.167)	DT 0.003 (1.120)	loss 6.908 (6.908)	prob 3.796 (3.796)	GS 27.359 (27.359)	mem 40.065
Train: [21][365/750]	BT 0.031 (1.189)	DT 0.007 (1.142)	loss 7.119 (7.119)	prob 2.339 (2.339)	GS 31.250 (31.250)	mem 39.987
Train: [21][370/750]	BT 0.031 (1.174)	DT 0.001 (1.127)	loss 7.215 (7.215)	prob 2.537 (2.537)	GS 33.078 (33.078)	mem 39.987
Train: [21][375/750]	BT 0.022 (1.187)	DT 0.001 (1.141)	loss 7.141 (7.141)	prob 2.377 (2.377)	GS 29.578 (29.578)	mem 40.036
Train: [21][380/750]	BT 0.100 (1.175)	DT 0.002 (1.129)	loss 7.211 (7.211)	prob 2.003 (2.003)	GS 34.531 (34.531)	mem 40.095
Train: [21][385/750]	BT 0.052 (1.161)	DT 0.015 (1.115)	loss 7.004 (7.004)	prob 2.683 (2.683)	GS 35.531 (35.531)	mem 40.050
Train: [21][390/750]	BT 0.031 (1.177)	DT 0.001 (1.131)	loss 7.282 (7.282)	prob 2.110 (2.110)	GS 32.609 (32.609)	mem 40.067
Train: [21][395/750]	BT 0.032 (1.163)	DT 0.001 (1.117)	loss 7.100 (7.100)	prob 2.625 (2.625)	GS 28.188 (28.188)	mem 40.083
Train: [21][400/750]	BT 5.806 (1.184)	DT 5.774 (1.138)	loss 7.190 (7.190)	prob 2.113 (2.113)	GS 36.281 (36.281)	mem 40.063
Train: [21][405/750]	BT 0.065 (1.170)	DT 0.001 (1.124)	loss 7.365 (7.365)	prob 1.622 (1.622)	GS 29.406 (29.406)	mem 40.064
Train: [21][410/750]	BT 6.482 (1.172)	DT 6.440 (1.126)	loss 7.150 (7.150)	prob 1.771 (1.771)	GS 33.734 (33.734)	mem 40.018
Train: [21][415/750]	BT 0.031 (1.176)	DT 0.001 (1.130)	loss 7.245 (7.245)	prob 2.076 (2.076)	GS 30.500 (30.500)	mem 40.043
Train: [21][420/750]	BT 0.040 (1.162)	DT 0.001 (1.116)	loss 6.864 (6.864)	prob 2.552 (2.552)	GS 31.406 (31.406)	mem 40.117
Train: [21][425/750]	BT 0.088 (1.174)	DT 0.002 (1.128)	loss 6.774 (6.774)	prob 2.956 (2.956)	GS 27.875 (27.875)	mem 40.304
Train: [21][430/750]	BT 0.051 (1.161)	DT 0.002 (1.115)	loss 7.055 (7.055)	prob 2.730 (2.730)	GS 34.953 (34.953)	mem 40.143
Train: [21][435/750]	BT 0.046 (1.168)	DT 0.007 (1.122)	loss 7.066 (7.066)	prob 1.909 (1.909)	GS 26.953 (26.953)	mem 40.139
Train: [21][440/750]	BT 0.032 (1.165)	DT 0.001 (1.119)	loss 6.876 (6.876)	prob 2.653 (2.653)	GS 37.344 (37.344)	mem 40.111
Train: [21][445/750]	BT 0.043 (1.152)	DT 0.001 (1.106)	loss 7.109 (7.109)	prob 1.985 (1.985)	GS 31.484 (31.484)	mem 40.112
Train: [21][450/750]	BT 0.036 (1.169)	DT 0.001 (1.123)	loss 7.259 (7.259)	prob 2.201 (2.201)	GS 34.203 (34.203)	mem 40.034
Train: [21][455/750]	BT 0.048 (1.157)	DT 0.003 (1.111)	loss 7.252 (7.252)	prob 2.042 (2.042)	GS 33.078 (33.078)	mem 40.064
Train: [21][460/750]	BT 0.157 (1.166)	DT 0.122 (1.121)	loss 6.908 (6.908)	prob 2.410 (2.410)	GS 30.844 (30.844)	mem 40.105
Train: [21][465/750]	BT 0.098 (1.154)	DT 0.040 (1.109)	loss 7.236 (7.236)	prob 1.596 (1.596)	GS 30.906 (30.906)	mem 40.155
Train: [21][470/750]	BT 12.178 (1.168)	DT 12.122 (1.123)	loss 7.285 (7.285)	prob 1.436 (1.436)	GS 33.578 (33.578)	mem 40.055
Train: [21][475/750]	BT 0.032 (1.162)	DT 0.001 (1.116)	loss 7.140 (7.140)	prob 1.357 (1.357)	GS 33.172 (33.172)	mem 40.051
Train: [21][480/750]	BT 0.054 (1.150)	DT 0.003 (1.105)	loss 7.291 (7.291)	prob 1.630 (1.630)	GS 31.297 (31.297)	mem 40.085
Train: [21][485/750]	BT 0.050 (1.170)	DT 0.003 (1.124)	loss 6.856 (6.856)	prob 2.132 (2.132)	GS 30.859 (30.859)	mem 40.173
Train: [21][490/750]	BT 0.050 (1.158)	DT 0.010 (1.113)	loss 7.086 (7.086)	prob 1.558 (1.558)	GS 31.297 (31.297)	mem 40.151
Train: [21][495/750]	BT 0.062 (1.155)	DT 0.013 (1.110)	loss 7.141 (7.141)	prob 1.220 (1.220)	GS 30.141 (30.141)	mem 40.553
Train: [21][500/750]	BT 0.070 (1.162)	DT 0.002 (1.117)	loss 7.183 (7.183)	prob 1.775 (1.775)	GS 36.484 (36.484)	mem 40.174
Train: [21][505/750]	BT 0.046 (1.151)	DT 0.003 (1.106)	loss 7.114 (7.114)	prob 1.372 (1.372)	GS 28.797 (28.797)	mem 40.112
Train: [21][510/750]	BT 0.030 (1.167)	DT 0.001 (1.122)	loss 7.437 (7.437)	prob 1.726 (1.726)	GS 34.375 (34.375)	mem 40.161
Train: [21][515/750]	BT 0.054 (1.156)	DT 0.002 (1.111)	loss 7.174 (7.174)	prob 1.149 (1.149)	GS 29.266 (29.266)	mem 40.269
Train: [21][520/750]	BT 7.818 (1.167)	DT 7.757 (1.122)	loss 7.544 (7.544)	prob 1.110 (1.110)	GS 30.016 (30.016)	mem 40.028
Train: [21][525/750]	BT 0.030 (1.157)	DT 0.001 (1.112)	loss 7.074 (7.074)	prob 1.125 (1.125)	GS 31.828 (31.828)	mem 40.028
Train: [21][530/750]	BT 5.162 (1.156)	DT 5.131 (1.111)	loss 7.293 (7.293)	prob 1.363 (1.363)	GS 36.422 (36.422)	mem 40.081
Train: [21][535/750]	BT 0.037 (1.158)	DT 0.001 (1.113)	loss 7.400 (7.400)	prob 1.185 (1.185)	GS 31.250 (31.250)	mem 40.160
Train: [21][540/750]	BT 0.133 (1.148)	DT 0.035 (1.103)	loss 7.428 (7.428)	prob 1.974 (1.974)	GS 34.438 (34.438)	mem 40.162
Train: [21][545/750]	BT 0.043 (1.163)	DT 0.001 (1.118)	loss 7.212 (7.212)	prob 1.912 (1.912)	GS 30.031 (30.031)	mem 40.168
Train: [21][550/750]	BT 0.031 (1.153)	DT 0.001 (1.108)	loss 7.979 (7.979)	prob 1.756 (1.756)	GS 32.141 (32.141)	mem 40.167
Train: [21][555/750]	BT 0.047 (1.148)	DT 0.007 (1.104)	loss 7.624 (7.624)	prob 1.833 (1.833)	GS 29.031 (29.031)	mem 40.239
Train: [21][560/750]	BT 0.048 (1.154)	DT 0.013 (1.109)	loss 7.259 (7.259)	prob 2.238 (2.238)	GS 33.938 (33.938)	mem 40.287
Train: [21][565/750]	BT 0.051 (1.144)	DT 0.009 (1.100)	loss 7.321 (7.321)	prob 1.563 (1.563)	GS 33.109 (33.109)	mem 40.167
Train: [21][570/750]	BT 0.030 (1.157)	DT 0.001 (1.112)	loss 7.535 (7.535)	prob 1.734 (1.734)	GS 34.812 (34.812)	mem 40.159
Train: [21][575/750]	BT 0.054 (1.147)	DT 0.004 (1.102)	loss 7.756 (7.756)	prob 1.586 (1.586)	GS 31.984 (31.984)	mem 40.251
Train: [21][580/750]	BT 4.963 (1.158)	DT 4.933 (1.114)	loss 8.171 (8.171)	prob 2.144 (2.144)	GS 35.516 (35.516)	mem 40.184
Train: [21][585/750]	BT 0.079 (1.149)	DT 0.008 (1.104)	loss 7.982 (7.982)	prob 1.565 (1.565)	GS 37.125 (37.125)	mem 40.227
Train: [21][590/750]	BT 6.745 (1.151)	DT 6.656 (1.106)	loss 7.507 (7.507)	prob 2.783 (2.783)	GS 31.516 (31.516)	mem 40.173
Train: [21][595/750]	BT 0.035 (1.148)	DT 0.002 (1.103)	loss 7.512 (7.512)	prob 2.067 (2.067)	GS 28.703 (28.703)	mem 40.349
Train: [21][600/750]	BT 0.036 (1.139)	DT 0.002 (1.094)	loss 7.772 (7.772)	prob 2.772 (2.772)	GS 27.078 (27.078)	mem 40.510
Train: [21][605/750]	BT 0.049 (1.148)	DT 0.001 (1.104)	loss 7.937 (7.937)	prob 1.984 (1.984)	GS 33.453 (33.453)	mem 40.443
Train: [21][610/750]	BT 0.050 (1.139)	DT 0.006 (1.095)	loss 7.922 (7.922)	prob 1.907 (1.907)	GS 34.703 (34.703)	mem 40.207
Train: [21][615/750]	BT 0.065 (1.148)	DT 0.026 (1.103)	loss 7.628 (7.628)	prob 2.258 (2.258)	GS 36.688 (36.688)	mem 40.175
Train: [21][620/750]	BT 0.054 (1.148)	DT 0.001 (1.103)	loss 7.854 (7.854)	prob 2.711 (2.711)	GS 34.797 (34.797)	mem 40.124
Train: [21][625/750]	BT 0.030 (1.139)	DT 0.001 (1.095)	loss 7.330 (7.330)	prob 2.802 (2.802)	GS 33.734 (33.734)	mem 40.125
Train: [21][630/750]	BT 0.050 (1.150)	DT 0.010 (1.105)	loss 7.507 (7.507)	prob 2.823 (2.823)	GS 33.234 (33.234)	mem 40.027
Train: [21][635/750]	BT 0.068 (1.142)	DT 0.011 (1.097)	loss 7.697 (7.697)	prob 2.765 (2.765)	GS 28.266 (28.266)	mem 40.054
Train: [21][640/750]	BT 2.642 (1.151)	DT 2.615 (1.106)	loss 8.075 (8.075)	prob 2.456 (2.456)	GS 33.266 (33.266)	mem 40.128
Train: [21][645/750]	BT 0.059 (1.142)	DT 0.007 (1.097)	loss 7.455 (7.455)	prob 2.369 (2.369)	GS 30.828 (30.828)	mem 40.267
Train: [21][650/750]	BT 8.988 (1.148)	DT 8.955 (1.103)	loss 7.793 (7.793)	prob 3.636 (3.636)	GS 32.875 (32.875)	mem 40.199
Train: [21][655/750]	BT 0.077 (1.150)	DT 0.009 (1.106)	loss 8.510 (8.510)	prob 1.426 (1.426)	GS 31.812 (31.812)	mem 40.180
Train: [21][660/750]	BT 0.091 (1.142)	DT 0.001 (1.097)	loss 7.771 (7.771)	prob 2.695 (2.695)	GS 34.484 (34.484)	mem 40.219
Train: [21][665/750]	BT 0.042 (1.153)	DT 0.007 (1.108)	loss 8.151 (8.151)	prob 1.645 (1.645)	GS 31.359 (31.359)	mem 40.205
Train: [21][670/750]	BT 0.037 (1.145)	DT 0.001 (1.100)	loss 8.135 (8.135)	prob 2.378 (2.378)	GS 30.156 (30.156)	mem 40.384
Train: [21][675/750]	BT 0.030 (1.142)	DT 0.001 (1.097)	loss 7.537 (7.537)	prob 2.995 (2.995)	GS 27.969 (27.969)	mem 40.207
Train: [21][680/750]	BT 0.023 (1.149)	DT 0.001 (1.104)	loss 8.309 (8.309)	prob 3.146 (3.146)	GS 34.312 (34.312)	mem 40.136
Train: [21][685/750]	BT 0.039 (1.140)	DT 0.001 (1.096)	loss 7.983 (7.983)	prob 2.699 (2.699)	GS 31.750 (31.750)	mem 40.138
Train: [21][690/750]	BT 0.032 (1.149)	DT 0.001 (1.105)	loss 7.828 (7.828)	prob 3.209 (3.209)	GS 37.750 (37.750)	mem 40.189
Train: [21][695/750]	BT 0.027 (1.141)	DT 0.001 (1.097)	loss 7.616 (7.616)	prob 3.364 (3.364)	GS 33.531 (33.531)	mem 40.190
Train: [21][700/750]	BT 8.221 (1.155)	DT 8.177 (1.111)	loss 7.668 (7.668)	prob 3.173 (3.173)	GS 34.969 (34.969)	mem 40.148
Train: [21][705/750]	BT 0.052 (1.148)	DT 0.001 (1.103)	loss 7.927 (7.927)	prob 3.054 (3.054)	GS 29.984 (29.984)	mem 40.161
Train: [21][710/750]	BT 2.976 (1.144)	DT 2.930 (1.099)	loss 7.937 (7.937)	prob 3.194 (3.194)	GS 35.438 (35.438)	mem 40.153
Train: [21][715/750]	BT 0.043 (1.152)	DT 0.005 (1.107)	loss 7.590 (7.590)	prob 3.623 (3.623)	GS 27.156 (27.156)	mem 40.196
Train: [21][720/750]	BT 0.050 (1.144)	DT 0.002 (1.100)	loss 8.164 (8.164)	prob 3.061 (3.061)	GS 36.359 (36.359)	mem 40.196
Train: [21][725/750]	BT 0.085 (1.151)	DT 0.001 (1.106)	loss 8.328 (8.328)	prob 2.953 (2.953)	GS 45.000 (45.000)	mem 39.966
Train: [21][730/750]	BT 0.042 (1.143)	DT 0.004 (1.099)	loss 7.656 (7.656)	prob 3.778 (3.778)	GS 32.984 (32.984)	mem 39.968
Train: [21][735/750]	BT 0.029 (1.136)	DT 0.001 (1.091)	loss 7.731 (7.731)	prob 3.353 (3.353)	GS 34.609 (34.609)	mem 39.968
Train: [21][740/750]	BT 0.038 (1.137)	DT 0.001 (1.093)	loss 7.663 (7.663)	prob 3.514 (3.514)	GS 33.703 (33.703)	mem 10.624
Train: [21][745/750]	BT 0.030 (1.130)	DT 0.001 (1.086)	loss 9.247 (9.247)	prob 2.143 (2.143)	GS 33.062 (33.062)	mem 10.625
Train: [21][750/750]	BT 0.027 (1.127)	DT 0.001 (1.082)	loss 8.557 (8.557)	prob 3.238 (3.238)	GS 35.812 (35.812)	mem 7.710
Train: [21][755/750]	BT 0.026 (1.119)	DT 0.001 (1.075)	loss 7.842 (7.842)	prob 3.030 (3.030)	GS 30.156 (30.156)	mem 7.710
epoch 21, total time 845.30
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [22][1/750]	BT 19.683 (19.683)	DT 19.637 (19.637)	loss 7.412 (7.412)	prob 3.781 (3.781)	GS 32.422 (32.422)	mem 38.648
Train: [22][5/750]	BT 0.266 (4.009)	DT 0.235 (3.975)	loss 7.824 (7.824)	prob 3.609 (3.609)	GS 31.828 (31.828)	mem 38.595
Train: [22][10/750]	BT 0.039 (2.128)	DT 0.008 (2.094)	loss 8.107 (8.107)	prob 3.538 (3.538)	GS 34.594 (34.594)	mem 38.667
Train: [22][15/750]	BT 0.037 (2.014)	DT 0.006 (1.975)	loss 7.758 (7.758)	prob 3.145 (3.145)	GS 29.484 (29.484)	mem 38.916
Train: [22][20/750]	BT 0.032 (1.807)	DT 0.002 (1.762)	loss 8.209 (8.209)	prob 3.274 (3.274)	GS 33.500 (33.500)	mem 38.973
Train: [22][25/750]	BT 0.963 (1.624)	DT 0.904 (1.578)	loss 7.920 (7.920)	prob 2.459 (2.459)	GS 33.969 (33.969)	mem 39.005
Train: [22][30/750]	BT 0.364 (1.605)	DT 0.293 (1.559)	loss 7.320 (7.320)	prob 3.822 (3.822)	GS 31.734 (31.734)	mem 39.033
Train: [22][35/750]	BT 0.046 (1.509)	DT 0.002 (1.464)	loss 8.160 (8.160)	prob 2.605 (2.605)	GS 29.984 (29.984)	mem 39.051
Train: [22][40/750]	BT 8.728 (1.569)	DT 8.688 (1.523)	loss 7.933 (7.933)	prob 3.208 (3.208)	GS 35.406 (35.406)	mem 39.424
Train: [22][45/750]	BT 0.027 (1.498)	DT 0.001 (1.452)	loss 8.349 (8.349)	prob 2.596 (2.596)	GS 27.266 (27.266)	mem 39.507
Train: [22][50/750]	BT 0.054 (1.353)	DT 0.011 (1.307)	loss 7.343 (7.343)	prob 4.466 (4.466)	GS 28.172 (28.172)	mem 39.403
Train: [22][55/750]	BT 0.046 (1.410)	DT 0.016 (1.364)	loss 7.123 (7.123)	prob 4.125 (4.125)	GS 32.344 (32.344)	mem 39.680
Train: [22][60/750]	BT 3.169 (1.352)	DT 3.134 (1.307)	loss 8.019 (8.019)	prob 3.051 (3.051)	GS 35.672 (35.672)	mem 39.874
Train: [22][65/750]	BT 0.065 (1.389)	DT 0.002 (1.343)	loss 8.001 (8.001)	prob 3.315 (3.315)	GS 32.375 (32.375)	mem 39.922
Train: [22][70/750]	BT 0.035 (1.329)	DT 0.001 (1.282)	loss 7.619 (7.619)	prob 3.152 (3.152)	GS 33.828 (33.828)	mem 39.747
Train: [22][75/750]	BT 0.031 (1.242)	DT 0.001 (1.197)	loss 8.189 (8.189)	prob 2.936 (2.936)	GS 30.594 (30.594)	mem 39.749
Train: [22][80/750]	BT 0.032 (1.370)	DT 0.001 (1.325)	loss 7.176 (7.176)	prob 3.960 (3.960)	GS 34.266 (34.266)	mem 39.813
Train: [22][85/750]	BT 0.072 (1.293)	DT 0.019 (1.247)	loss 7.704 (7.704)	prob 3.124 (3.124)	GS 28.672 (28.672)	mem 39.963
Train: [22][90/750]	BT 0.020 (1.363)	DT 0.001 (1.319)	loss 7.932 (7.932)	prob 2.879 (2.879)	GS 38.266 (38.266)	mem 39.763
Train: [22][95/750]	BT 0.054 (1.322)	DT 0.001 (1.278)	loss 7.745 (7.745)	prob 3.484 (3.484)	GS 29.406 (29.406)	mem 39.774
Train: [22][100/750]	BT 9.804 (1.356)	DT 9.752 (1.312)	loss 7.681 (7.681)	prob 3.816 (3.816)	GS 35.531 (35.531)	mem 39.774
Train: [22][105/750]	BT 0.030 (1.331)	DT 0.001 (1.288)	loss 7.699 (7.699)	prob 3.383 (3.383)	GS 33.797 (33.797)	mem 39.824
Train: [22][110/750]	BT 0.050 (1.273)	DT 0.011 (1.230)	loss 8.065 (8.065)	prob 3.063 (3.063)	GS 36.375 (36.375)	mem 39.860
Train: [22][115/750]	BT 0.124 (1.288)	DT 0.001 (1.244)	loss 7.558 (7.558)	prob 3.304 (3.304)	GS 36.734 (36.734)	mem 39.842
Train: [22][120/750]	BT 0.029 (1.296)	DT 0.008 (1.253)	loss 7.521 (7.521)	prob 3.840 (3.840)	GS 32.453 (32.453)	mem 39.886
Train: [22][125/750]	BT 0.032 (1.263)	DT 0.001 (1.220)	loss 7.644 (7.644)	prob 3.280 (3.280)	GS 28.797 (28.797)	mem 39.778
Train: [22][130/750]	BT 0.058 (1.283)	DT 0.002 (1.241)	loss 8.173 (8.173)	prob 4.048 (4.048)	GS 35.734 (35.734)	mem 40.016
Train: [22][135/750]	BT 0.052 (1.237)	DT 0.006 (1.195)	loss 7.554 (7.554)	prob 3.917 (3.917)	GS 30.422 (30.422)	mem 39.884
Train: [22][140/750]	BT 2.741 (1.266)	DT 2.700 (1.223)	loss 7.682 (7.682)	prob 4.069 (4.069)	GS 29.375 (29.375)	mem 39.849
Train: [22][145/750]	BT 0.047 (1.224)	DT 0.003 (1.181)	loss 7.791 (7.791)	prob 3.443 (3.443)	GS 35.297 (35.297)	mem 39.934
Train: [22][150/750]	BT 0.035 (1.260)	DT 0.001 (1.217)	loss 8.005 (8.005)	prob 4.164 (4.164)	GS 32.078 (32.078)	mem 39.925
Train: [22][155/750]	BT 0.064 (1.254)	DT 0.017 (1.211)	loss 8.357 (8.357)	prob 2.155 (2.155)	GS 32.141 (32.141)	mem 39.879
Train: [22][160/750]	BT 8.455 (1.269)	DT 8.410 (1.226)	loss 7.856 (7.856)	prob 3.257 (3.257)	GS 34.922 (34.922)	mem 39.866
Train: [22][165/750]	BT 0.023 (1.252)	DT 0.001 (1.210)	loss 7.582 (7.582)	prob 3.526 (3.526)	GS 32.141 (32.141)	mem 39.859
Train: [22][170/750]	BT 0.034 (1.216)	DT 0.005 (1.174)	loss 8.152 (8.152)	prob 3.016 (3.016)	GS 37.406 (37.406)	mem 39.910
Train: [22][175/750]	BT 0.027 (1.241)	DT 0.001 (1.200)	loss 7.480 (7.480)	prob 3.608 (3.608)	GS 31.969 (31.969)	mem 39.847
Train: [22][180/750]	BT 0.048 (1.219)	DT 0.001 (1.177)	loss 7.482 (7.482)	prob 3.644 (3.644)	GS 32.625 (32.625)	mem 39.891
Train: [22][185/750]	BT 0.043 (1.248)	DT 0.001 (1.207)	loss 7.840 (7.840)	prob 3.403 (3.403)	GS 29.953 (29.953)	mem 39.895
Train: [22][190/750]	BT 0.105 (1.228)	DT 0.002 (1.186)	loss 7.550 (7.550)	prob 3.808 (3.808)	GS 35.156 (35.156)	mem 39.955
Train: [22][195/750]	BT 0.033 (1.198)	DT 0.001 (1.156)	loss 7.903 (7.903)	prob 3.095 (3.095)	GS 29.125 (29.125)	mem 40.049
Train: [22][200/750]	BT 0.035 (1.222)	DT 0.002 (1.179)	loss 7.707 (7.707)	prob 4.311 (4.311)	GS 34.781 (34.781)	mem 40.121
Train: [22][205/750]	BT 0.027 (1.193)	DT 0.001 (1.151)	loss 7.783 (7.783)	prob 3.833 (3.833)	GS 28.766 (28.766)	mem 39.995
Train: [22][210/750]	BT 0.074 (1.236)	DT 0.001 (1.194)	loss 7.520 (7.520)	prob 3.948 (3.948)	GS 36.781 (36.781)	mem 39.993
Train: [22][215/750]	BT 0.025 (1.209)	DT 0.001 (1.167)	loss 7.810 (7.810)	prob 3.590 (3.590)	GS 32.281 (32.281)	mem 39.967
Train: [22][220/750]	BT 14.162 (1.246)	DT 14.079 (1.204)	loss 7.515 (7.515)	prob 4.060 (4.060)	GS 35.922 (35.922)	mem 39.897
Train: [22][225/750]	BT 0.026 (1.220)	DT 0.001 (1.178)	loss 7.656 (7.656)	prob 3.311 (3.311)	GS 36.547 (36.547)	mem 39.946
Train: [22][230/750]	BT 0.095 (1.195)	DT 0.028 (1.152)	loss 7.712 (7.712)	prob 2.883 (2.883)	GS 34.141 (34.141)	mem 39.901
Train: [22][235/750]	BT 0.028 (1.229)	DT 0.001 (1.187)	loss 8.206 (8.206)	prob 2.825 (2.825)	GS 37.094 (37.094)	mem 39.923
Train: [22][240/750]	BT 0.034 (1.204)	DT 0.002 (1.162)	loss 7.722 (7.722)	prob 3.315 (3.315)	GS 36.766 (36.766)	mem 39.960
Train: [22][245/750]	BT 0.101 (1.217)	DT 0.023 (1.175)	loss 7.843 (7.843)	prob 3.095 (3.095)	GS 29.391 (29.391)	mem 40.049
Train: [22][250/750]	BT 0.032 (1.194)	DT 0.001 (1.152)	loss 7.528 (7.528)	prob 4.056 (4.056)	GS 31.953 (31.953)	mem 39.995
Train: [22][255/750]	BT 0.051 (1.171)	DT 0.007 (1.129)	loss 7.498 (7.498)	prob 3.300 (3.300)	GS 34.500 (34.500)	mem 40.066
Train: [22][260/750]	BT 0.034 (1.206)	DT 0.002 (1.164)	loss 7.438 (7.438)	prob 3.795 (3.795)	GS 34.234 (34.234)	mem 40.064
Train: [22][265/750]	BT 0.029 (1.185)	DT 0.001 (1.143)	loss 7.444 (7.444)	prob 3.135 (3.135)	GS 33.625 (33.625)	mem 40.066
Train: [22][270/750]	BT 0.030 (1.218)	DT 0.001 (1.176)	loss 7.297 (7.297)	prob 3.905 (3.905)	GS 33.031 (33.031)	mem 39.915
Train: [22][275/750]	BT 0.051 (1.197)	DT 0.009 (1.155)	loss 7.278 (7.278)	prob 3.844 (3.844)	GS 31.094 (31.094)	mem 39.916
Train: [22][280/750]	BT 13.092 (1.223)	DT 13.054 (1.181)	loss 7.252 (7.252)	prob 3.968 (3.968)	GS 35.141 (35.141)	mem 39.992
Train: [22][285/750]	BT 0.030 (1.202)	DT 0.002 (1.160)	loss 7.373 (7.373)	prob 3.792 (3.792)	GS 36.391 (36.391)	mem 39.992
Train: [22][290/750]	BT 0.048 (1.182)	DT 0.007 (1.140)	loss 7.762 (7.762)	prob 3.561 (3.561)	GS 28.078 (28.078)	mem 39.993
Train: [22][295/750]	BT 0.031 (1.211)	DT 0.002 (1.169)	loss 7.228 (7.228)	prob 3.876 (3.876)	GS 34.578 (34.578)	mem 39.988
Train: [22][300/750]	BT 0.096 (1.191)	DT 0.064 (1.150)	loss 7.792 (7.792)	prob 3.744 (3.744)	GS 34.188 (34.188)	mem 40.002
Train: [22][305/750]	BT 0.031 (1.218)	DT 0.005 (1.176)	loss 7.951 (7.951)	prob 2.702 (2.702)	GS 30.562 (30.562)	mem 40.055
Train: [22][310/750]	BT 0.066 (1.199)	DT 0.013 (1.157)	loss 7.201 (7.201)	prob 3.579 (3.579)	GS 34.594 (34.594)	mem 40.000
Train: [22][315/750]	BT 0.043 (1.181)	DT 0.002 (1.139)	loss 7.856 (7.856)	prob 3.003 (3.003)	GS 31.641 (31.641)	mem 40.006
Train: [22][320/750]	BT 0.028 (1.201)	DT 0.001 (1.159)	loss 7.037 (7.037)	prob 3.275 (3.275)	GS 33.281 (33.281)	mem 40.011
Train: [22][325/750]	BT 0.142 (1.183)	DT 0.006 (1.142)	loss 7.626 (7.626)	prob 3.440 (3.440)	GS 33.484 (33.484)	mem 40.014
Train: [22][330/750]	BT 0.034 (1.199)	DT 0.001 (1.157)	loss 7.505 (7.505)	prob 3.334 (3.334)	GS 34.406 (34.406)	mem 40.071
Train: [22][335/750]	BT 0.068 (1.182)	DT 0.001 (1.140)	loss 7.157 (7.157)	prob 3.357 (3.357)	GS 32.891 (32.891)	mem 40.073
Train: [22][340/750]	BT 13.112 (1.204)	DT 13.080 (1.162)	loss 7.882 (7.882)	prob 2.968 (2.968)	GS 31.359 (31.359)	mem 39.925
Train: [22][345/750]	BT 0.040 (1.187)	DT 0.002 (1.145)	loss 7.566 (7.566)	prob 2.863 (2.863)	GS 30.203 (30.203)	mem 39.902
Train: [22][350/750]	BT 0.042 (1.171)	DT 0.001 (1.129)	loss 7.548 (7.548)	prob 3.396 (3.396)	GS 39.250 (39.250)	mem 39.915
Train: [22][355/750]	BT 0.036 (1.187)	DT 0.002 (1.145)	loss 7.974 (7.974)	prob 2.857 (2.857)	GS 28.203 (28.203)	mem 40.295
Train: [22][360/750]	BT 0.025 (1.171)	DT 0.001 (1.129)	loss 7.722 (7.722)	prob 3.341 (3.341)	GS 34.812 (34.812)	mem 40.095
Train: [22][365/750]	BT 0.112 (1.192)	DT 0.004 (1.149)	loss 7.300 (7.300)	prob 3.407 (3.407)	GS 30.438 (30.438)	mem 40.192
Train: [22][370/750]	BT 0.071 (1.176)	DT 0.007 (1.134)	loss 7.468 (7.468)	prob 2.818 (2.818)	GS 38.109 (38.109)	mem 40.105
Train: [22][375/750]	BT 0.032 (1.161)	DT 0.001 (1.119)	loss 7.380 (7.380)	prob 2.875 (2.875)	GS 35.656 (35.656)	mem 40.104
Train: [22][380/750]	BT 0.032 (1.180)	DT 0.001 (1.138)	loss 7.166 (7.166)	prob 3.265 (3.265)	GS 34.297 (34.297)	mem 40.182
Train: [22][385/750]	BT 0.035 (1.165)	DT 0.002 (1.123)	loss 7.239 (7.239)	prob 3.316 (3.316)	GS 35.094 (35.094)	mem 40.275
Train: [22][390/750]	BT 0.043 (1.185)	DT 0.002 (1.143)	loss 7.325 (7.325)	prob 3.207 (3.207)	GS 35.297 (35.297)	mem 40.071
Train: [22][395/750]	BT 0.025 (1.171)	DT 0.001 (1.129)	loss 7.613 (7.613)	prob 2.806 (2.806)	GS 30.734 (30.734)	mem 40.071
Train: [22][400/750]	BT 11.069 (1.184)	DT 11.048 (1.142)	loss 7.340 (7.340)	prob 3.437 (3.437)	GS 38.359 (38.359)	mem 40.079
Train: [22][405/750]	BT 0.073 (1.170)	DT 0.003 (1.128)	loss 7.449 (7.449)	prob 3.088 (3.088)	GS 29.391 (29.391)	mem 40.082
Train: [22][410/750]	BT 0.086 (1.157)	DT 0.002 (1.114)	loss 7.609 (7.609)	prob 3.454 (3.454)	GS 31.172 (31.172)	mem 40.275
Train: [22][415/750]	BT 0.026 (1.176)	DT 0.001 (1.134)	loss 7.780 (7.780)	prob 2.230 (2.230)	GS 31.797 (31.797)	mem 39.994
Train: [22][420/750]	BT 0.029 (1.162)	DT 0.001 (1.120)	loss 7.163 (7.163)	prob 2.945 (2.945)	GS 35.906 (35.906)	mem 40.021
Train: [22][425/750]	BT 0.025 (1.182)	DT 0.002 (1.140)	loss 7.285 (7.285)	prob 3.013 (3.013)	GS 31.078 (31.078)	mem 40.093
Train: [22][430/750]	BT 0.074 (1.169)	DT 0.002 (1.127)	loss 7.141 (7.141)	prob 3.427 (3.427)	GS 32.453 (32.453)	mem 40.192
Train: [22][435/750]	BT 0.106 (1.157)	DT 0.002 (1.114)	loss 7.563 (7.563)	prob 2.579 (2.579)	GS 33.422 (33.422)	mem 40.139
Train: [22][440/750]	BT 0.031 (1.174)	DT 0.001 (1.131)	loss 7.206 (7.206)	prob 3.077 (3.077)	GS 34.109 (34.109)	mem 39.975
Train: [22][445/750]	BT 0.036 (1.161)	DT 0.003 (1.119)	loss 7.216 (7.216)	prob 3.309 (3.309)	GS 31.203 (31.203)	mem 40.019
Train: [22][450/750]	BT 0.067 (1.177)	DT 0.001 (1.135)	loss 7.184 (7.184)	prob 2.662 (2.662)	GS 30.828 (30.828)	mem 40.143
Train: [22][455/750]	BT 0.034 (1.167)	DT 0.001 (1.124)	loss 7.689 (7.689)	prob 2.937 (2.937)	GS 34.422 (34.422)	mem 40.145
Train: [22][460/750]	BT 13.338 (1.183)	DT 13.296 (1.141)	loss 7.446 (7.446)	prob 3.316 (3.316)	GS 37.453 (37.453)	mem 40.220
Train: [22][465/750]	BT 0.048 (1.171)	DT 0.002 (1.129)	loss 7.265 (7.265)	prob 3.420 (3.420)	GS 32.641 (32.641)	mem 40.405
Train: [22][470/750]	BT 0.038 (1.159)	DT 0.001 (1.117)	loss 7.181 (7.181)	prob 3.619 (3.619)	GS 31.812 (31.812)	mem 40.069
Train: [22][475/750]	BT 0.026 (1.176)	DT 0.001 (1.134)	loss 7.358 (7.358)	prob 2.987 (2.987)	GS 33.484 (33.484)	mem 40.170
Train: [22][480/750]	BT 0.073 (1.165)	DT 0.003 (1.122)	loss 7.115 (7.115)	prob 3.621 (3.621)	GS 35.156 (35.156)	mem 40.171
Train: [22][485/750]	BT 0.032 (1.177)	DT 0.001 (1.135)	loss 7.278 (7.278)	prob 2.847 (2.847)	GS 31.000 (31.000)	mem 40.058
Train: [22][490/750]	BT 0.022 (1.166)	DT 0.001 (1.123)	loss 7.373 (7.373)	prob 3.561 (3.561)	GS 31.781 (31.781)	mem 40.066
Train: [22][495/750]	BT 0.044 (1.155)	DT 0.005 (1.112)	loss 7.177 (7.177)	prob 2.986 (2.986)	GS 30.609 (30.609)	mem 40.076
Train: [22][500/750]	BT 0.031 (1.168)	DT 0.001 (1.126)	loss 7.052 (7.052)	prob 2.970 (2.970)	GS 32.797 (32.797)	mem 40.106
Train: [22][505/750]	BT 0.049 (1.157)	DT 0.008 (1.114)	loss 7.316 (7.316)	prob 2.737 (2.737)	GS 29.297 (29.297)	mem 40.110
Train: [22][510/750]	BT 0.028 (1.173)	DT 0.001 (1.131)	loss 7.112 (7.112)	prob 3.225 (3.225)	GS 33.891 (33.891)	mem 39.998
Train: [22][515/750]	BT 0.095 (1.163)	DT 0.013 (1.120)	loss 7.014 (7.014)	prob 3.392 (3.392)	GS 30.188 (30.188)	mem 40.028
Train: [22][520/750]	BT 13.684 (1.178)	DT 13.655 (1.136)	loss 7.113 (7.113)	prob 3.266 (3.266)	GS 33.359 (33.359)	mem 40.016
Train: [22][525/750]	BT 0.042 (1.168)	DT 0.003 (1.125)	loss 7.072 (7.072)	prob 2.995 (2.995)	GS 34.641 (34.641)	mem 40.018
Train: [22][530/750]	BT 0.037 (1.157)	DT 0.013 (1.114)	loss 7.080 (7.080)	prob 3.404 (3.404)	GS 33.969 (33.969)	mem 40.018
Train: [22][535/750]	BT 0.037 (1.170)	DT 0.001 (1.128)	loss 6.776 (6.776)	prob 3.445 (3.445)	GS 26.750 (26.750)	mem 40.055
Train: [22][540/750]	BT 0.089 (1.160)	DT 0.002 (1.118)	loss 7.378 (7.378)	prob 2.663 (2.663)	GS 36.672 (36.672)	mem 40.024
Train: [22][545/750]	BT 0.026 (1.175)	DT 0.001 (1.132)	loss 7.346 (7.346)	prob 2.553 (2.553)	GS 30.703 (30.703)	mem 39.944
Train: [22][550/750]	BT 0.029 (1.164)	DT 0.001 (1.122)	loss 7.116 (7.116)	prob 3.332 (3.332)	GS 30.125 (30.125)	mem 39.944
Train: [22][555/750]	BT 0.031 (1.154)	DT 0.001 (1.112)	loss 7.295 (7.295)	prob 2.736 (2.736)	GS 29.328 (29.328)	mem 39.969
Train: [22][560/750]	BT 0.109 (1.167)	DT 0.002 (1.125)	loss 7.382 (7.382)	prob 2.904 (2.904)	GS 32.922 (32.922)	mem 40.032
Train: [22][565/750]	BT 0.031 (1.157)	DT 0.002 (1.115)	loss 7.505 (7.505)	prob 2.131 (2.131)	GS 30.453 (30.453)	mem 40.038
Train: [22][570/750]	BT 0.063 (1.167)	DT 0.005 (1.125)	loss 7.383 (7.383)	prob 2.750 (2.750)	GS 34.828 (34.828)	mem 39.985
Train: [22][575/750]	BT 0.055 (1.158)	DT 0.004 (1.116)	loss 7.175 (7.175)	prob 2.823 (2.823)	GS 35.516 (35.516)	mem 40.056
Train: [22][580/750]	BT 12.345 (1.169)	DT 12.314 (1.127)	loss 7.204 (7.204)	prob 3.122 (3.122)	GS 32.594 (32.594)	mem 40.002
Train: [22][585/750]	BT 0.045 (1.160)	DT 0.002 (1.118)	loss 7.044 (7.044)	prob 3.062 (3.062)	GS 33.375 (33.375)	mem 40.009
Train: [22][590/750]	BT 0.145 (1.150)	DT 0.009 (1.108)	loss 6.978 (6.978)	prob 3.565 (3.565)	GS 35.266 (35.266)	mem 40.324
Train: [22][595/750]	BT 0.054 (1.166)	DT 0.011 (1.124)	loss 6.954 (6.954)	prob 3.215 (3.215)	GS 27.297 (27.297)	mem 39.972
Train: [22][600/750]	BT 0.034 (1.157)	DT 0.002 (1.114)	loss 7.288 (7.288)	prob 2.756 (2.756)	GS 27.250 (27.250)	mem 40.060
Train: [22][605/750]	BT 0.023 (1.167)	DT 0.001 (1.125)	loss 7.189 (7.189)	prob 2.854 (2.854)	GS 31.484 (31.484)	mem 39.979
Train: [22][610/750]	BT 0.056 (1.158)	DT 0.014 (1.116)	loss 7.078 (7.078)	prob 3.035 (3.035)	GS 33.281 (33.281)	mem 39.981
Train: [22][615/750]	BT 0.041 (1.149)	DT 0.001 (1.107)	loss 7.029 (7.029)	prob 2.968 (2.968)	GS 32.234 (32.234)	mem 40.013
Train: [22][620/750]	BT 0.043 (1.164)	DT 0.001 (1.121)	loss 7.172 (7.172)	prob 2.805 (2.805)	GS 30.734 (30.734)	mem 39.958
Train: [22][625/750]	BT 0.043 (1.155)	DT 0.008 (1.112)	loss 7.488 (7.488)	prob 2.489 (2.489)	GS 32.266 (32.266)	mem 39.959
Train: [22][630/750]	BT 0.040 (1.167)	DT 0.004 (1.125)	loss 7.054 (7.054)	prob 3.309 (3.309)	GS 34.828 (34.828)	mem 39.902
Train: [22][635/750]	BT 0.061 (1.158)	DT 0.007 (1.116)	loss 7.234 (7.234)	prob 3.118 (3.118)	GS 29.547 (29.547)	mem 39.902
Train: [22][640/750]	BT 12.692 (1.169)	DT 12.663 (1.127)	loss 7.377 (7.377)	prob 2.623 (2.623)	GS 37.656 (37.656)	mem 39.904
Train: [22][645/750]	BT 0.029 (1.161)	DT 0.001 (1.118)	loss 7.144 (7.144)	prob 3.248 (3.248)	GS 26.281 (26.281)	mem 39.905
Train: [22][650/750]	BT 0.023 (1.152)	DT 0.001 (1.110)	loss 7.103 (7.103)	prob 2.544 (2.544)	GS 39.500 (39.500)	mem 39.911
Train: [22][655/750]	BT 0.074 (1.164)	DT 0.023 (1.122)	loss 7.114 (7.114)	prob 2.874 (2.874)	GS 30.344 (30.344)	mem 40.046
Train: [22][660/750]	BT 0.076 (1.155)	DT 0.010 (1.113)	loss 7.231 (7.231)	prob 2.920 (2.920)	GS 35.312 (35.312)	mem 40.047
Train: [22][665/750]	BT 0.070 (1.164)	DT 0.015 (1.122)	loss 7.066 (7.066)	prob 3.308 (3.308)	GS 32.781 (32.781)	mem 40.102
Train: [22][670/750]	BT 0.032 (1.156)	DT 0.001 (1.114)	loss 7.135 (7.135)	prob 2.793 (2.793)	GS 34.453 (34.453)	mem 40.102
Train: [22][675/750]	BT 0.043 (1.147)	DT 0.001 (1.106)	loss 7.039 (7.039)	prob 3.111 (3.111)	GS 33.812 (33.812)	mem 40.141
Train: [22][680/750]	BT 0.080 (1.161)	DT 0.023 (1.119)	loss 6.992 (6.992)	prob 3.511 (3.511)	GS 35.141 (35.141)	mem 40.170
Train: [22][685/750]	BT 0.047 (1.153)	DT 0.002 (1.111)	loss 7.207 (7.207)	prob 2.399 (2.399)	GS 34.625 (34.625)	mem 40.184
Train: [22][690/750]	BT 0.032 (1.161)	DT 0.002 (1.119)	loss 7.004 (7.004)	prob 3.330 (3.330)	GS 32.781 (32.781)	mem 40.344
Train: [22][695/750]	BT 0.058 (1.153)	DT 0.023 (1.111)	loss 7.827 (7.827)	prob 1.932 (1.932)	GS 32.516 (32.516)	mem 40.178
Train: [22][700/750]	BT 13.376 (1.164)	DT 13.330 (1.122)	loss 7.566 (7.566)	prob 2.540 (2.540)	GS 37.906 (37.906)	mem 40.158
Train: [22][705/750]	BT 0.070 (1.156)	DT 0.026 (1.114)	loss 7.193 (7.193)	prob 2.444 (2.444)	GS 35.062 (35.062)	mem 40.159
Train: [22][710/750]	BT 0.037 (1.148)	DT 0.002 (1.106)	loss 7.154 (7.154)	prob 2.741 (2.741)	GS 39.266 (39.266)	mem 40.160
Train: [22][715/750]	BT 0.056 (1.156)	DT 0.011 (1.114)	loss 7.245 (7.245)	prob 2.110 (2.110)	GS 31.562 (31.562)	mem 40.160
Train: [22][720/750]	BT 0.058 (1.148)	DT 0.008 (1.106)	loss 7.000 (7.000)	prob 2.640 (2.640)	GS 35.172 (35.172)	mem 40.159
Train: [22][725/750]	BT 0.046 (1.156)	DT 0.012 (1.114)	loss 7.217 (7.217)	prob 2.349 (2.349)	GS 29.031 (29.031)	mem 39.872
Train: [22][730/750]	BT 0.040 (1.148)	DT 0.001 (1.106)	loss 6.710 (6.710)	prob 3.008 (3.008)	GS 31.891 (31.891)	mem 39.872
Train: [22][735/750]	BT 0.045 (1.141)	DT 0.001 (1.099)	loss 7.045 (7.045)	prob 2.296 (2.296)	GS 29.516 (29.516)	mem 39.951
Train: [22][740/750]	BT 0.028 (1.146)	DT 0.001 (1.104)	loss 6.996 (6.996)	prob 2.488 (2.488)	GS 31.359 (31.359)	mem 13.739
Train: [22][745/750]	BT 0.028 (1.139)	DT 0.001 (1.097)	loss 7.291 (7.291)	prob 1.413 (1.413)	GS 28.500 (28.500)	mem 13.740
Train: [22][750/750]	BT 0.024 (1.136)	DT 0.001 (1.094)	loss 7.286 (7.286)	prob 2.377 (2.377)	GS 35.656 (35.656)	mem 7.757
Train: [22][755/750]	BT 0.033 (1.128)	DT 0.001 (1.087)	loss 6.831 (6.831)	prob 2.764 (2.764)	GS 29.906 (29.906)	mem 7.757
epoch 22, total time 852.18
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [23][1/750]	BT 20.120 (20.120)	DT 20.035 (20.035)	loss 6.878 (6.878)	prob 2.112 (2.112)	GS 29.828 (29.828)	mem 39.290
Train: [23][5/750]	BT 0.049 (5.324)	DT 0.001 (5.268)	loss 7.238 (7.238)	prob 1.935 (1.935)	GS 35.094 (35.094)	mem 39.500
Train: [23][10/750]	BT 3.405 (3.029)	DT 3.367 (2.974)	loss 7.351 (7.351)	prob 2.013 (2.013)	GS 37.016 (37.016)	mem 39.541
Train: [23][15/750]	BT 0.092 (2.637)	DT 0.030 (2.581)	loss 7.000 (7.000)	prob 1.855 (1.855)	GS 28.203 (28.203)	mem 39.625
Train: [23][20/750]	BT 0.031 (2.040)	DT 0.001 (1.989)	loss 7.260 (7.260)	prob 1.941 (1.941)	GS 34.641 (34.641)	mem 39.591
Train: [23][25/750]	BT 0.045 (1.875)	DT 0.006 (1.826)	loss 6.873 (6.873)	prob 2.115 (2.115)	GS 31.266 (31.266)	mem 39.676
Train: [23][30/750]	BT 0.065 (1.850)	DT 0.006 (1.801)	loss 6.950 (6.950)	prob 2.411 (2.411)	GS 32.250 (32.250)	mem 39.791
Train: [23][35/750]	BT 0.035 (1.732)	DT 0.001 (1.685)	loss 7.336 (7.336)	prob 2.447 (2.447)	GS 30.859 (30.859)	mem 39.889
Train: [23][40/750]	BT 0.043 (1.728)	DT 0.013 (1.680)	loss 7.376 (7.376)	prob 2.497 (2.497)	GS 33.953 (33.953)	mem 39.737
Train: [23][45/750]	BT 0.223 (1.546)	DT 0.014 (1.494)	loss 7.194 (7.194)	prob 2.213 (2.213)	GS 33.422 (33.422)	mem 39.871
Train: [23][50/750]	BT 6.949 (1.652)	DT 6.903 (1.599)	loss 7.227 (7.227)	prob 2.101 (2.101)	GS 36.875 (36.875)	mem 39.834
Train: [23][55/750]	BT 0.106 (1.553)	DT 0.002 (1.500)	loss 6.947 (6.947)	prob 2.206 (2.206)	GS 30.094 (30.094)	mem 39.899
Train: [23][60/750]	BT 0.032 (1.462)	DT 0.001 (1.410)	loss 6.975 (6.975)	prob 2.942 (2.942)	GS 33.188 (33.188)	mem 39.892
Train: [23][65/750]	BT 0.023 (1.550)	DT 0.001 (1.500)	loss 7.389 (7.389)	prob 1.928 (1.928)	GS 32.875 (32.875)	mem 39.884
Train: [23][70/750]	BT 1.199 (1.459)	DT 1.146 (1.409)	loss 7.001 (7.001)	prob 2.311 (2.311)	GS 32.016 (32.016)	mem 39.959
Train: [23][75/750]	BT 0.048 (1.429)	DT 0.007 (1.377)	loss 7.189 (7.189)	prob 2.203 (2.203)	GS 28.875 (28.875)	mem 40.065
Train: [23][80/750]	BT 0.029 (1.456)	DT 0.001 (1.405)	loss 7.352 (7.352)	prob 2.573 (2.573)	GS 32.266 (32.266)	mem 40.018
Train: [23][85/750]	BT 0.152 (1.376)	DT 0.044 (1.323)	loss 7.133 (7.133)	prob 2.038 (2.038)	GS 33.875 (33.875)	mem 39.935
Train: [23][90/750]	BT 0.033 (1.400)	DT 0.001 (1.348)	loss 7.019 (7.019)	prob 2.910 (2.910)	GS 32.734 (32.734)	mem 39.964
Train: [23][95/750]	BT 0.048 (1.329)	DT 0.004 (1.277)	loss 7.157 (7.157)	prob 2.320 (2.320)	GS 32.938 (32.938)	mem 40.054
Train: [23][100/750]	BT 0.497 (1.404)	DT 0.463 (1.352)	loss 6.561 (6.561)	prob 2.586 (2.586)	GS 30.469 (30.469)	mem 39.940
Train: [23][105/750]	BT 0.114 (1.340)	DT 0.001 (1.288)	loss 7.270 (7.270)	prob 2.359 (2.359)	GS 29.125 (29.125)	mem 39.940
Train: [23][110/750]	BT 9.873 (1.370)	DT 9.841 (1.319)	loss 6.972 (6.972)	prob 2.211 (2.211)	GS 34.828 (34.828)	mem 39.933
Train: [23][115/750]	BT 0.040 (1.313)	DT 0.010 (1.262)	loss 7.061 (7.061)	prob 2.088 (2.088)	GS 28.125 (28.125)	mem 39.934
Train: [23][120/750]	BT 0.056 (1.259)	DT 0.006 (1.209)	loss 7.089 (7.089)	prob 2.589 (2.589)	GS 36.906 (36.906)	mem 39.934
Train: [23][125/750]	BT 0.057 (1.313)	DT 0.002 (1.263)	loss 7.029 (7.029)	prob 2.487 (2.487)	GS 28.969 (28.969)	mem 40.016
Train: [23][130/750]	BT 0.038 (1.264)	DT 0.002 (1.215)	loss 7.221 (7.221)	prob 2.103 (2.103)	GS 33.875 (33.875)	mem 39.934
Train: [23][135/750]	BT 0.044 (1.331)	DT 0.019 (1.282)	loss 7.106 (7.106)	prob 2.175 (2.175)	GS 29.281 (29.281)	mem 39.954
Train: [23][140/750]	BT 0.031 (1.285)	DT 0.001 (1.236)	loss 6.842 (6.842)	prob 2.734 (2.734)	GS 33.016 (33.016)	mem 40.019
Train: [23][145/750]	BT 0.028 (1.242)	DT 0.001 (1.194)	loss 7.020 (7.020)	prob 2.236 (2.236)	GS 29.828 (29.828)	mem 39.972
Train: [23][150/750]	BT 0.027 (1.286)	DT 0.001 (1.238)	loss 7.197 (7.197)	prob 3.033 (3.033)	GS 30.578 (30.578)	mem 39.949
Train: [23][155/750]	BT 0.044 (1.247)	DT 0.002 (1.199)	loss 7.028 (7.028)	prob 2.591 (2.591)	GS 30.203 (30.203)	mem 40.057
Train: [23][160/750]	BT 0.049 (1.300)	DT 0.004 (1.253)	loss 7.387 (7.387)	prob 2.818 (2.818)	GS 34.516 (34.516)	mem 39.955
Train: [23][165/750]	BT 0.021 (1.262)	DT 0.001 (1.215)	loss 7.087 (7.087)	prob 2.593 (2.593)	GS 29.328 (29.328)	mem 39.955
Train: [23][170/750]	BT 12.571 (1.300)	DT 12.535 (1.253)	loss 6.928 (6.928)	prob 2.433 (2.433)	GS 34.938 (34.938)	mem 39.949
Train: [23][175/750]	BT 0.047 (1.264)	DT 0.010 (1.217)	loss 7.188 (7.188)	prob 2.223 (2.223)	GS 31.844 (31.844)	mem 39.988
Train: [23][180/750]	BT 0.033 (1.230)	DT 0.001 (1.184)	loss 6.889 (6.889)	prob 2.630 (2.630)	GS 32.656 (32.656)	mem 39.957
Train: [23][185/750]	BT 0.031 (1.277)	DT 0.001 (1.231)	loss 7.356 (7.356)	prob 2.129 (2.129)	GS 35.469 (35.469)	mem 40.162
Train: [23][190/750]	BT 0.048 (1.245)	DT 0.001 (1.198)	loss 6.919 (6.919)	prob 2.718 (2.718)	GS 36.375 (36.375)	mem 40.066
Train: [23][195/750]	BT 0.094 (1.274)	DT 0.018 (1.227)	loss 7.075 (7.075)	prob 2.328 (2.328)	GS 33.141 (33.141)	mem 40.407
Train: [23][200/750]	BT 0.033 (1.243)	DT 0.001 (1.196)	loss 6.860 (6.860)	prob 2.728 (2.728)	GS 39.531 (39.531)	mem 40.130
Train: [23][205/750]	BT 0.031 (1.214)	DT 0.001 (1.167)	loss 7.250 (7.250)	prob 2.469 (2.469)	GS 30.062 (30.062)	mem 40.130
Train: [23][210/750]	BT 0.063 (1.233)	DT 0.001 (1.185)	loss 6.906 (6.906)	prob 3.055 (3.055)	GS 31.047 (31.047)	mem 40.197
Train: [23][215/750]	BT 0.046 (1.205)	DT 0.002 (1.158)	loss 7.381 (7.381)	prob 2.173 (2.173)	GS 31.609 (31.609)	mem 40.131
Train: [23][220/750]	BT 0.030 (1.239)	DT 0.001 (1.191)	loss 6.965 (6.965)	prob 2.702 (2.702)	GS 36.516 (36.516)	mem 40.166
Train: [23][225/750]	BT 0.089 (1.212)	DT 0.027 (1.165)	loss 7.137 (7.137)	prob 2.357 (2.357)	GS 27.078 (27.078)	mem 40.496
Train: [23][230/750]	BT 12.421 (1.241)	DT 12.389 (1.194)	loss 6.930 (6.930)	prob 2.594 (2.594)	GS 32.750 (32.750)	mem 40.119
Train: [23][235/750]	BT 0.028 (1.215)	DT 0.001 (1.169)	loss 7.054 (7.054)	prob 2.737 (2.737)	GS 29.234 (29.234)	mem 40.120
Train: [23][240/750]	BT 0.051 (1.192)	DT 0.002 (1.144)	loss 7.248 (7.248)	prob 2.163 (2.163)	GS 36.281 (36.281)	mem 40.175
Train: [23][245/750]	BT 0.032 (1.227)	DT 0.001 (1.180)	loss 6.925 (6.925)	prob 2.500 (2.500)	GS 30.312 (30.312)	mem 40.036
Train: [23][250/750]	BT 0.061 (1.204)	DT 0.002 (1.157)	loss 7.017 (7.017)	prob 1.955 (1.955)	GS 33.094 (33.094)	mem 40.075
Train: [23][255/750]	BT 0.039 (1.232)	DT 0.004 (1.185)	loss 7.027 (7.027)	prob 2.617 (2.617)	GS 31.109 (31.109)	mem 40.053
Train: [23][260/750]	BT 0.055 (1.209)	DT 0.010 (1.163)	loss 6.882 (6.882)	prob 2.794 (2.794)	GS 34.438 (34.438)	mem 40.071
Train: [23][265/750]	BT 0.023 (1.187)	DT 0.001 (1.141)	loss 7.197 (7.197)	prob 2.159 (2.159)	GS 30.797 (30.797)	mem 40.072
Train: [23][270/750]	BT 0.033 (1.216)	DT 0.002 (1.169)	loss 7.035 (7.035)	prob 2.694 (2.694)	GS 32.500 (32.500)	mem 39.995
Train: [23][275/750]	BT 0.069 (1.195)	DT 0.013 (1.148)	loss 7.024 (7.024)	prob 2.269 (2.269)	GS 30.484 (30.484)	mem 40.053
Train: [23][280/750]	BT 0.024 (1.224)	DT 0.001 (1.178)	loss 7.253 (7.253)	prob 1.823 (1.823)	GS 34.969 (34.969)	mem 39.988
Train: [23][285/750]	BT 0.031 (1.203)	DT 0.001 (1.157)	loss 7.069 (7.069)	prob 2.667 (2.667)	GS 28.875 (28.875)	mem 39.993
Train: [23][290/750]	BT 12.380 (1.226)	DT 12.334 (1.180)	loss 7.218 (7.218)	prob 2.777 (2.777)	GS 36.297 (36.297)	mem 40.006
Train: [23][295/750]	BT 0.029 (1.206)	DT 0.001 (1.160)	loss 7.332 (7.332)	prob 2.810 (2.810)	GS 28.859 (28.859)	mem 40.030
Train: [23][300/750]	BT 0.034 (1.186)	DT 0.002 (1.141)	loss 7.054 (7.054)	prob 2.912 (2.912)	GS 33.438 (33.438)	mem 40.072
Train: [23][305/750]	BT 0.025 (1.219)	DT 0.001 (1.174)	loss 6.963 (6.963)	prob 2.713 (2.713)	GS 32.219 (32.219)	mem 39.885
Train: [23][310/750]	BT 0.022 (1.200)	DT 0.001 (1.155)	loss 6.860 (6.860)	prob 3.273 (3.273)	GS 34.000 (34.000)	mem 39.886
Train: [23][315/750]	BT 0.033 (1.224)	DT 0.001 (1.179)	loss 6.925 (6.925)	prob 2.425 (2.425)	GS 30.766 (30.766)	mem 39.968
Train: [23][320/750]	BT 0.042 (1.205)	DT 0.001 (1.160)	loss 6.860 (6.860)	prob 2.717 (2.717)	GS 34.047 (34.047)	mem 39.968
Train: [23][325/750]	BT 0.038 (1.187)	DT 0.014 (1.142)	loss 7.193 (7.193)	prob 2.248 (2.248)	GS 42.422 (42.422)	mem 39.969
Train: [23][330/750]	BT 0.022 (1.205)	DT 0.001 (1.160)	loss 6.908 (6.908)	prob 2.665 (2.665)	GS 31.125 (31.125)	mem 40.004
Train: [23][335/750]	BT 0.053 (1.187)	DT 0.011 (1.143)	loss 6.788 (6.788)	prob 2.953 (2.953)	GS 26.469 (26.469)	mem 40.134
Train: [23][340/750]	BT 0.030 (1.209)	DT 0.002 (1.165)	loss 7.144 (7.144)	prob 2.661 (2.661)	GS 34.016 (34.016)	mem 40.044
Train: [23][345/750]	BT 0.052 (1.193)	DT 0.006 (1.148)	loss 7.091 (7.091)	prob 2.510 (2.510)	GS 29.922 (29.922)	mem 40.045
Train: [23][350/750]	BT 9.382 (1.203)	DT 9.350 (1.158)	loss 6.920 (6.920)	prob 1.065 (1.065)	GS 31.406 (31.406)	mem 39.962
Train: [23][355/750]	BT 0.094 (1.187)	DT 0.001 (1.142)	loss 7.092 (7.092)	prob 1.997 (1.997)	GS 37.047 (37.047)	mem 39.964
Train: [23][360/750]	BT 0.208 (1.171)	DT 0.156 (1.127)	loss 7.109 (7.109)	prob 1.886 (1.886)	GS 33.406 (33.406)	mem 39.963
Train: [23][365/750]	BT 0.047 (1.190)	DT 0.007 (1.145)	loss 6.958 (6.958)	prob 2.961 (2.961)	GS 31.094 (31.094)	mem 40.068
Train: [23][370/750]	BT 0.076 (1.174)	DT 0.019 (1.130)	loss 6.971 (6.971)	prob 2.323 (2.323)	GS 36.109 (36.109)	mem 40.180
Train: [23][375/750]	BT 0.032 (1.188)	DT 0.001 (1.144)	loss 6.937 (6.937)	prob 2.587 (2.587)	GS 32.156 (32.156)	mem 40.086
Train: [23][380/750]	BT 0.047 (1.173)	DT 0.001 (1.129)	loss 7.112 (7.112)	prob 2.123 (2.123)	GS 33.281 (33.281)	mem 40.087
Train: [23][385/750]	BT 0.079 (1.159)	DT 0.002 (1.114)	loss 7.301 (7.301)	prob 2.367 (2.367)	GS 28.734 (28.734)	mem 40.088
Train: [23][390/750]	BT 0.031 (1.177)	DT 0.001 (1.132)	loss 6.962 (6.962)	prob 3.094 (3.094)	GS 32.734 (32.734)	mem 40.080
Train: [23][395/750]	BT 0.093 (1.162)	DT 0.012 (1.118)	loss 7.299 (7.299)	prob 2.328 (2.328)	GS 32.312 (32.312)	mem 40.138
Train: [23][400/750]	BT 0.021 (1.186)	DT 0.001 (1.141)	loss 6.842 (6.842)	prob 2.603 (2.603)	GS 32.219 (32.219)	mem 39.973
Train: [23][405/750]	BT 0.026 (1.172)	DT 0.002 (1.127)	loss 7.274 (7.274)	prob 2.186 (2.186)	GS 34.438 (34.438)	mem 39.975
Train: [23][410/750]	BT 13.674 (1.192)	DT 13.628 (1.147)	loss 6.875 (6.875)	prob 2.293 (2.293)	GS 33.172 (33.172)	mem 40.013
Train: [23][415/750]	BT 0.052 (1.178)	DT 0.012 (1.133)	loss 7.186 (7.186)	prob 2.133 (2.133)	GS 28.438 (28.438)	mem 40.013
Train: [23][420/750]	BT 0.027 (1.164)	DT 0.001 (1.120)	loss 6.987 (6.987)	prob 2.429 (2.429)	GS 34.953 (34.953)	mem 40.012
Train: [23][425/750]	BT 0.028 (1.178)	DT 0.001 (1.134)	loss 6.890 (6.890)	prob 3.237 (3.237)	GS 29.844 (29.844)	mem 40.231
Train: [23][430/750]	BT 0.063 (1.165)	DT 0.001 (1.120)	loss 6.976 (6.976)	prob 3.124 (3.124)	GS 38.172 (38.172)	mem 40.094
Train: [23][435/750]	BT 0.023 (1.182)	DT 0.001 (1.138)	loss 7.046 (7.046)	prob 2.790 (2.790)	GS 33.656 (33.656)	mem 40.023
Train: [23][440/750]	BT 0.045 (1.169)	DT 0.002 (1.125)	loss 6.810 (6.810)	prob 2.530 (2.530)	GS 36.406 (36.406)	mem 40.062
Train: [23][445/750]	BT 0.041 (1.156)	DT 0.001 (1.112)	loss 7.232 (7.232)	prob 2.203 (2.203)	GS 30.969 (30.969)	mem 40.024
Train: [23][450/750]	BT 0.023 (1.168)	DT 0.001 (1.124)	loss 6.814 (6.814)	prob 2.732 (2.732)	GS 32.688 (32.688)	mem 40.088
Train: [23][455/750]	BT 0.031 (1.155)	DT 0.001 (1.111)	loss 6.901 (6.901)	prob 2.627 (2.627)	GS 26.156 (26.156)	mem 40.089
Train: [23][460/750]	BT 0.047 (1.170)	DT 0.002 (1.126)	loss 7.117 (7.117)	prob 2.257 (2.257)	GS 34.781 (34.781)	mem 40.048
Train: [23][465/750]	BT 0.022 (1.158)	DT 0.001 (1.114)	loss 7.154 (7.154)	prob 2.042 (2.042)	GS 31.625 (31.625)	mem 40.048
Train: [23][470/750]	BT 11.720 (1.171)	DT 11.691 (1.127)	loss 6.835 (6.835)	prob 2.743 (2.743)	GS 29.328 (29.328)	mem 40.061
Train: [23][475/750]	BT 0.025 (1.159)	DT 0.001 (1.115)	loss 7.133 (7.133)	prob 2.069 (2.069)	GS 34.016 (34.016)	mem 40.061
Train: [23][480/750]	BT 0.033 (1.147)	DT 0.002 (1.103)	loss 7.035 (7.035)	prob 2.452 (2.452)	GS 31.516 (31.516)	mem 40.085
Train: [23][485/750]	BT 0.031 (1.159)	DT 0.001 (1.116)	loss 7.278 (7.278)	prob 1.522 (1.522)	GS 29.562 (29.562)	mem 40.028
Train: [23][490/750]	BT 0.080 (1.153)	DT 0.011 (1.110)	loss 7.271 (7.271)	prob 2.385 (2.385)	GS 33.547 (33.547)	mem 40.336
Train: [23][495/750]	BT 0.032 (1.160)	DT 0.002 (1.117)	loss 6.877 (6.877)	prob 2.773 (2.773)	GS 29.625 (29.625)	mem 40.072
Train: [23][500/750]	BT 0.028 (1.149)	DT 0.001 (1.106)	loss 7.010 (7.010)	prob 2.467 (2.467)	GS 33.375 (33.375)	mem 40.072
Train: [23][505/750]	BT 0.027 (1.152)	DT 0.001 (1.108)	loss 7.189 (7.189)	prob 2.634 (2.634)	GS 31.797 (31.797)	mem 40.162
Train: [23][510/750]	BT 0.055 (1.150)	DT 0.002 (1.106)	loss 6.900 (6.900)	prob 2.343 (2.343)	GS 35.047 (35.047)	mem 40.234
Train: [23][515/750]	BT 0.037 (1.141)	DT 0.001 (1.097)	loss 6.856 (6.856)	prob 2.289 (2.289)	GS 27.562 (27.562)	mem 40.083
Train: [23][520/750]	BT 0.057 (1.149)	DT 0.003 (1.105)	loss 6.932 (6.932)	prob 1.962 (1.962)	GS 37.531 (37.531)	mem 40.130
Train: [23][525/750]	BT 0.023 (1.138)	DT 0.001 (1.095)	loss 6.824 (6.824)	prob 2.360 (2.360)	GS 31.438 (31.438)	mem 40.130
Train: [23][530/750]	BT 2.577 (1.149)	DT 2.525 (1.105)	loss 6.941 (6.941)	prob 2.859 (2.859)	GS 35.000 (35.000)	mem 40.098
Train: [23][535/750]	BT 0.045 (1.139)	DT 0.005 (1.095)	loss 6.806 (6.806)	prob 2.438 (2.438)	GS 28.547 (28.547)	mem 40.099
Train: [23][540/750]	BT 7.718 (1.145)	DT 7.676 (1.102)	loss 6.990 (6.990)	prob 2.223 (2.223)	GS 32.359 (32.359)	mem 40.169
Train: [23][545/750]	BT 0.050 (1.142)	DT 0.017 (1.099)	loss 7.141 (7.141)	prob 1.967 (1.967)	GS 29.688 (29.688)	mem 40.238
Train: [23][550/750]	BT 0.049 (1.139)	DT 0.001 (1.096)	loss 6.755 (6.755)	prob 2.574 (2.574)	GS 33.562 (33.562)	mem 39.972
Train: [23][555/750]	BT 0.023 (1.152)	DT 0.001 (1.109)	loss 6.928 (6.928)	prob 2.161 (2.161)	GS 27.922 (27.922)	mem 40.071
Train: [23][560/750]	BT 0.028 (1.142)	DT 0.001 (1.099)	loss 6.857 (6.857)	prob 2.507 (2.507)	GS 37.234 (37.234)	mem 40.300
Train: [23][565/750]	BT 0.035 (1.141)	DT 0.002 (1.097)	loss 6.999 (6.999)	prob 2.488 (2.488)	GS 30.953 (30.953)	mem 39.920
Train: [23][570/750]	BT 0.031 (1.143)	DT 0.002 (1.099)	loss 6.859 (6.859)	prob 2.791 (2.791)	GS 35.859 (35.859)	mem 40.055
Train: [23][575/750]	BT 0.073 (1.134)	DT 0.010 (1.090)	loss 6.812 (6.812)	prob 2.029 (2.029)	GS 35.281 (35.281)	mem 40.177
Train: [23][580/750]	BT 0.031 (1.147)	DT 0.001 (1.103)	loss 6.871 (6.871)	prob 2.616 (2.616)	GS 33.672 (33.672)	mem 40.017
Train: [23][585/750]	BT 0.060 (1.137)	DT 0.002 (1.094)	loss 7.017 (7.017)	prob 2.607 (2.607)	GS 29.531 (29.531)	mem 40.018
Train: [23][590/750]	BT 9.857 (1.154)	DT 9.820 (1.111)	loss 6.977 (6.977)	prob 2.190 (2.190)	GS 37.219 (37.219)	mem 40.102
Train: [23][595/750]	BT 0.030 (1.145)	DT 0.001 (1.102)	loss 7.275 (7.275)	prob 2.083 (2.083)	GS 30.203 (30.203)	mem 40.103
Train: [23][600/750]	BT 3.329 (1.142)	DT 3.295 (1.099)	loss 7.063 (7.063)	prob 2.501 (2.501)	GS 32.156 (32.156)	mem 40.369
Train: [23][605/750]	BT 0.057 (1.150)	DT 0.010 (1.107)	loss 6.917 (6.917)	prob 3.134 (3.134)	GS 32.047 (32.047)	mem 40.172
Train: [23][610/750]	BT 0.034 (1.141)	DT 0.001 (1.098)	loss 6.774 (6.774)	prob 3.111 (3.111)	GS 32.922 (32.922)	mem 40.088
Train: [23][615/750]	BT 0.052 (1.156)	DT 0.010 (1.112)	loss 6.857 (6.857)	prob 2.858 (2.858)	GS 31.828 (31.828)	mem 40.020
Train: [23][620/750]	BT 0.053 (1.147)	DT 0.002 (1.103)	loss 7.066 (7.066)	prob 2.802 (2.802)	GS 34.391 (34.391)	mem 40.020
Train: [23][625/750]	BT 0.039 (1.138)	DT 0.001 (1.095)	loss 7.044 (7.044)	prob 3.028 (3.028)	GS 35.562 (35.562)	mem 40.051
Train: [23][630/750]	BT 0.030 (1.147)	DT 0.001 (1.104)	loss 6.963 (6.963)	prob 2.457 (2.457)	GS 33.453 (33.453)	mem 40.117
Train: [23][635/750]	BT 0.037 (1.139)	DT 0.001 (1.095)	loss 6.984 (6.984)	prob 2.287 (2.287)	GS 31.547 (31.547)	mem 40.090
Train: [23][640/750]	BT 0.058 (1.152)	DT 0.025 (1.108)	loss 6.865 (6.865)	prob 2.989 (2.989)	GS 28.672 (28.672)	mem 40.057
Train: [23][645/750]	BT 0.059 (1.143)	DT 0.003 (1.100)	loss 7.248 (7.248)	prob 2.686 (2.686)	GS 29.922 (29.922)	mem 40.008
Train: [23][650/750]	BT 12.501 (1.154)	DT 12.471 (1.111)	loss 7.205 (7.205)	prob 2.172 (2.172)	GS 32.297 (32.297)	mem 40.123
Train: [23][655/750]	BT 0.045 (1.145)	DT 0.005 (1.102)	loss 6.809 (6.809)	prob 3.005 (3.005)	GS 25.672 (25.672)	mem 40.117
arpack error, retry= 0
arpack error, retry= 0
Train: [23][660/750]	BT 0.043 (1.137)	DT 0.011 (1.094)	loss 6.803 (6.803)	prob 2.588 (2.588)	GS 33.219 (33.219)	mem 40.118
Train: [23][665/750]	BT 0.026 (1.152)	DT 0.001 (1.109)	loss 6.738 (6.738)	prob 2.605 (2.605)	GS 29.984 (29.984)	mem 40.009
Train: [23][670/750]	BT 0.039 (1.144)	DT 0.002 (1.100)	loss 6.973 (6.973)	prob 3.096 (3.096)	GS 30.141 (30.141)	mem 40.010
Train: [23][675/750]	BT 0.036 (1.155)	DT 0.001 (1.112)	loss 6.992 (6.992)	prob 3.069 (3.069)	GS 31.656 (31.656)	mem 40.038
Train: [23][680/750]	BT 0.049 (1.147)	DT 0.014 (1.103)	loss 7.064 (7.064)	prob 2.649 (2.649)	GS 29.891 (29.891)	mem 40.221
Train: [23][685/750]	BT 0.051 (1.139)	DT 0.005 (1.095)	loss 7.089 (7.089)	prob 2.337 (2.337)	GS 30.969 (30.969)	mem 40.041
Train: [23][690/750]	BT 0.023 (1.147)	DT 0.001 (1.104)	loss 6.761 (6.761)	prob 2.340 (2.340)	GS 33.062 (33.062)	mem 40.083
Train: [23][695/750]	BT 0.044 (1.139)	DT 0.001 (1.096)	loss 6.687 (6.687)	prob 2.426 (2.426)	GS 32.562 (32.562)	mem 40.203
Train: [23][700/750]	BT 0.037 (1.148)	DT 0.002 (1.105)	loss 7.110 (7.110)	prob 2.359 (2.359)	GS 32.844 (32.844)	mem 40.178
Train: [23][705/750]	BT 0.042 (1.141)	DT 0.001 (1.098)	loss 6.873 (6.873)	prob 2.752 (2.752)	GS 28.859 (28.859)	mem 40.184
Train: [23][710/750]	BT 10.783 (1.148)	DT 10.739 (1.105)	loss 7.072 (7.072)	prob 2.834 (2.834)	GS 34.641 (34.641)	mem 40.134
Train: [23][715/750]	BT 0.035 (1.140)	DT 0.004 (1.097)	loss 7.192 (7.192)	prob 2.382 (2.382)	GS 31.547 (31.547)	mem 40.134
Train: [23][720/750]	BT 0.045 (1.133)	DT 0.002 (1.090)	loss 6.812 (6.812)	prob 2.637 (2.637)	GS 32.938 (32.938)	mem 40.134
Train: [23][725/750]	BT 0.033 (1.142)	DT 0.001 (1.099)	loss 7.086 (7.086)	prob 1.935 (1.935)	GS 42.266 (42.266)	mem 40.176
Train: [23][730/750]	BT 0.032 (1.135)	DT 0.001 (1.092)	loss 6.939 (6.939)	prob 2.537 (2.537)	GS 33.078 (33.078)	mem 40.058
Train: [23][735/750]	BT 0.035 (1.139)	DT 0.002 (1.096)	loss 6.998 (6.998)	prob 2.446 (2.446)	GS 33.578 (33.578)	mem 36.908
Train: [23][740/750]	BT 0.032 (1.132)	DT 0.001 (1.089)	loss 6.968 (6.968)	prob 2.174 (2.174)	GS 31.562 (31.562)	mem 36.908
Train: [23][745/750]	BT 0.031 (1.124)	DT 0.002 (1.081)	loss 7.042 (7.042)	prob 2.315 (2.315)	GS 33.719 (33.719)	mem 36.908
Train: [23][750/750]	BT 0.026 (1.120)	DT 0.001 (1.078)	loss 6.678 (6.678)	prob 2.975 (2.975)	GS 37.500 (37.500)	mem 10.793
Train: [23][755/750]	BT 0.027 (1.113)	DT 0.006 (1.071)	loss 6.687 (6.687)	prob 1.788 (1.788)	GS 26.688 (26.688)	mem 10.794
epoch 23, total time 840.71
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [24][1/750]	BT 19.615 (19.615)	DT 19.536 (19.536)	loss 6.974 (6.974)	prob 2.567 (2.567)	GS 29.672 (29.672)	mem 38.760
Train: [24][5/750]	BT 2.228 (4.987)	DT 2.199 (4.933)	loss 7.002 (7.002)	prob 2.570 (2.570)	GS 34.234 (34.234)	mem 39.021
Train: [24][10/750]	BT 0.883 (2.595)	DT 0.839 (2.551)	loss 6.660 (6.660)	prob 2.867 (2.867)	GS 34.266 (34.266)	mem 39.060
Train: [24][15/750]	BT 0.032 (2.377)	DT 0.001 (2.329)	loss 6.895 (6.895)	prob 3.012 (3.012)	GS 29.562 (29.562)	mem 38.960
Train: [24][20/750]	BT 1.315 (1.861)	DT 1.273 (1.811)	loss 6.824 (6.824)	prob 2.635 (2.635)	GS 32.531 (32.531)	mem 39.058
Train: [24][25/750]	BT 2.632 (1.775)	DT 2.593 (1.727)	loss 6.804 (6.804)	prob 2.973 (2.973)	GS 29.672 (29.672)	mem 39.030
Train: [24][30/750]	BT 0.057 (1.662)	DT 0.007 (1.612)	loss 6.936 (6.936)	prob 2.650 (2.650)	GS 31.219 (31.219)	mem 39.083
Train: [24][35/750]	BT 0.031 (1.517)	DT 0.001 (1.468)	loss 7.007 (7.007)	prob 2.423 (2.423)	GS 30.875 (30.875)	mem 39.068
Train: [24][40/750]	BT 0.145 (1.573)	DT 0.008 (1.522)	loss 6.998 (6.998)	prob 2.511 (2.511)	GS 35.078 (35.078)	mem 39.162
Train: [24][45/750]	BT 0.036 (1.406)	DT 0.002 (1.354)	loss 6.991 (6.991)	prob 2.578 (2.578)	GS 30.609 (30.609)	mem 39.165
Train: [24][50/750]	BT 0.060 (1.504)	DT 0.006 (1.453)	loss 6.867 (6.867)	prob 2.969 (2.969)	GS 36.906 (36.906)	mem 39.157
Train: [24][55/750]	BT 0.046 (1.371)	DT 0.005 (1.321)	loss 6.957 (6.957)	prob 2.718 (2.718)	GS 34.453 (34.453)	mem 39.159
Train: [24][60/750]	BT 7.514 (1.512)	DT 7.448 (1.463)	loss 6.957 (6.957)	prob 2.782 (2.782)	GS 35.547 (35.547)	mem 39.171
Train: [24][65/750]	BT 0.044 (1.400)	DT 0.014 (1.351)	loss 6.891 (6.891)	prob 2.008 (2.008)	GS 26.719 (26.719)	mem 39.173
Train: [24][70/750]	BT 3.727 (1.356)	DT 3.682 (1.308)	loss 7.074 (7.074)	prob 2.495 (2.495)	GS 32.078 (32.078)	mem 39.404
Train: [24][75/750]	BT 0.032 (1.356)	DT 0.002 (1.309)	loss 7.118 (7.118)	prob 2.476 (2.476)	GS 27.547 (27.547)	mem 39.262
Train: [24][80/750]	BT 0.071 (1.280)	DT 0.020 (1.233)	loss 6.805 (6.805)	prob 2.959 (2.959)	GS 35.156 (35.156)	mem 39.204
Train: [24][85/750]	BT 0.113 (1.324)	DT 0.002 (1.277)	loss 7.058 (7.058)	prob 2.502 (2.502)	GS 31.016 (31.016)	mem 39.342
Train: [24][90/750]	BT 0.030 (1.316)	DT 0.002 (1.268)	loss 6.827 (6.827)	prob 2.292 (2.292)	GS 36.609 (36.609)	mem 39.255
Train: [24][95/750]	BT 0.029 (1.249)	DT 0.001 (1.201)	loss 7.005 (7.005)	prob 2.778 (2.778)	GS 30.797 (30.797)	mem 39.309
Train: [24][100/750]	BT 2.827 (1.291)	DT 2.793 (1.243)	loss 6.862 (6.862)	prob 2.424 (2.424)	GS 31.797 (31.797)	mem 39.272
Train: [24][105/750]	BT 0.095 (1.232)	DT 0.009 (1.184)	loss 6.875 (6.875)	prob 2.722 (2.722)	GS 32.203 (32.203)	mem 39.339
Train: [24][110/750]	BT 7.037 (1.270)	DT 7.005 (1.221)	loss 7.322 (7.322)	prob 2.014 (2.014)	GS 35.656 (35.656)	mem 39.339
Train: [24][115/750]	BT 0.053 (1.276)	DT 0.004 (1.227)	loss 6.875 (6.875)	prob 2.985 (2.985)	GS 32.453 (32.453)	mem 39.350
Train: [24][120/750]	BT 0.067 (1.225)	DT 0.001 (1.176)	loss 6.752 (6.752)	prob 3.121 (3.121)	GS 32.297 (32.297)	mem 39.302
Train: [24][125/750]	BT 0.030 (1.278)	DT 0.001 (1.229)	loss 7.128 (7.128)	prob 2.552 (2.552)	GS 28.719 (28.719)	mem 39.332
Train: [24][130/750]	BT 0.025 (1.230)	DT 0.001 (1.182)	loss 7.247 (7.247)	prob 1.929 (1.929)	GS 34.359 (34.359)	mem 39.314
Train: [24][135/750]	BT 0.055 (1.205)	DT 0.002 (1.157)	loss 7.253 (7.253)	prob 2.087 (2.087)	GS 34.156 (34.156)	mem 39.484
Train: [24][140/750]	BT 0.047 (1.254)	DT 0.001 (1.207)	loss 6.817 (6.817)	prob 2.618 (2.618)	GS 34.781 (34.781)	mem 39.425
Train: [24][145/750]	BT 0.156 (1.225)	DT 0.022 (1.176)	loss 6.863 (6.863)	prob 2.740 (2.740)	GS 29.828 (29.828)	mem 39.450
Train: [24][150/750]	BT 0.026 (1.245)	DT 0.001 (1.197)	loss 6.988 (6.988)	prob 2.560 (2.560)	GS 34.625 (34.625)	mem 39.431
Train: [24][155/750]	BT 0.031 (1.207)	DT 0.001 (1.159)	loss 7.021 (7.021)	prob 2.495 (2.495)	GS 31.516 (31.516)	mem 39.531
Train: [24][160/750]	BT 4.911 (1.233)	DT 4.876 (1.185)	loss 6.880 (6.880)	prob 2.739 (2.739)	GS 33.672 (33.672)	mem 39.459
Train: [24][165/750]	BT 0.052 (1.198)	DT 0.001 (1.149)	loss 6.876 (6.876)	prob 2.462 (2.462)	GS 33.094 (33.094)	mem 39.461
Train: [24][170/750]	BT 3.319 (1.218)	DT 3.287 (1.170)	loss 6.938 (6.938)	prob 2.242 (2.242)	GS 36.438 (36.438)	mem 39.626
Train: [24][175/750]	BT 0.029 (1.205)	DT 0.001 (1.157)	loss 7.070 (7.070)	prob 2.779 (2.779)	GS 29.781 (29.781)	mem 39.700
Train: [24][180/750]	BT 6.485 (1.208)	DT 6.435 (1.161)	loss 6.774 (6.774)	prob 2.565 (2.565)	GS 32.219 (32.219)	mem 39.705
Train: [24][185/750]	BT 0.038 (1.205)	DT 0.005 (1.157)	loss 7.109 (7.109)	prob 2.588 (2.588)	GS 28.453 (28.453)	mem 39.685
Train: [24][190/750]	BT 0.032 (1.174)	DT 0.001 (1.127)	loss 7.095 (7.095)	prob 2.526 (2.526)	GS 30.906 (30.906)	mem 39.686
Train: [24][195/750]	BT 0.037 (1.202)	DT 0.001 (1.155)	loss 7.050 (7.050)	prob 2.693 (2.693)	GS 36.391 (36.391)	mem 39.682
Train: [24][200/750]	BT 0.053 (1.191)	DT 0.011 (1.143)	loss 6.743 (6.743)	prob 2.611 (2.611)	GS 36.922 (36.922)	mem 39.683
Train: [24][205/750]	BT 0.153 (1.171)	DT 0.029 (1.123)	loss 6.980 (6.980)	prob 2.676 (2.676)	GS 31.453 (31.453)	mem 39.808
Train: [24][210/750]	BT 0.044 (1.187)	DT 0.013 (1.139)	loss 6.935 (6.935)	prob 2.422 (2.422)	GS 33.188 (33.188)	mem 39.770
Train: [24][215/750]	BT 0.067 (1.161)	DT 0.028 (1.113)	loss 6.887 (6.887)	prob 2.608 (2.608)	GS 32.172 (32.172)	mem 39.691
Train: [24][220/750]	BT 4.056 (1.189)	DT 4.032 (1.141)	loss 7.007 (7.007)	prob 2.678 (2.678)	GS 35.078 (35.078)	mem 39.704
Train: [24][225/750]	BT 0.026 (1.163)	DT 0.001 (1.115)	loss 7.107 (7.107)	prob 2.944 (2.944)	GS 29.281 (29.281)	mem 39.837
Train: [24][230/750]	BT 5.625 (1.175)	DT 5.543 (1.127)	loss 6.888 (6.888)	prob 3.018 (3.018)	GS 35.047 (35.047)	mem 39.686
Train: [24][235/750]	BT 0.044 (1.170)	DT 0.001 (1.122)	loss 6.774 (6.774)	prob 2.718 (2.718)	GS 28.312 (28.312)	mem 39.693
Train: [24][240/750]	BT 3.892 (1.163)	DT 3.834 (1.115)	loss 6.938 (6.938)	prob 2.365 (2.365)	GS 34.203 (34.203)	mem 39.847
Train: [24][245/750]	BT 0.034 (1.176)	DT 0.001 (1.128)	loss 6.905 (6.905)	prob 2.550 (2.550)	GS 30.406 (30.406)	mem 39.998
Train: [24][250/750]	BT 0.062 (1.154)	DT 0.006 (1.106)	loss 7.117 (7.117)	prob 2.190 (2.190)	GS 33.375 (33.375)	mem 39.901
Train: [24][255/750]	BT 0.032 (1.169)	DT 0.001 (1.121)	loss 6.966 (6.966)	prob 2.780 (2.780)	GS 32.094 (32.094)	mem 39.890
Train: [24][260/750]	BT 0.047 (1.153)	DT 0.015 (1.105)	loss 6.623 (6.623)	prob 2.905 (2.905)	GS 33.234 (33.234)	mem 39.984
Train: [24][265/750]	BT 0.028 (1.140)	DT 0.003 (1.093)	loss 6.771 (6.771)	prob 2.813 (2.813)	GS 30.078 (30.078)	mem 39.902
Train: [24][270/750]	BT 0.032 (1.157)	DT 0.002 (1.109)	loss 7.055 (7.055)	prob 1.799 (1.799)	GS 34.344 (34.344)	mem 39.909
Train: [24][275/750]	BT 0.130 (1.137)	DT 0.025 (1.089)	loss 7.071 (7.071)	prob 2.267 (2.267)	GS 29.281 (29.281)	mem 39.909
Train: [24][280/750]	BT 0.869 (1.155)	DT 0.830 (1.107)	loss 6.995 (6.995)	prob 2.743 (2.743)	GS 33.734 (33.734)	mem 39.991
Train: [24][285/750]	BT 0.058 (1.136)	DT 0.001 (1.088)	loss 6.744 (6.744)	prob 2.837 (2.837)	GS 34.969 (34.969)	mem 40.020
Train: [24][290/750]	BT 4.209 (1.160)	DT 4.177 (1.112)	loss 6.768 (6.768)	prob 2.711 (2.711)	GS 37.344 (37.344)	mem 39.940
Train: [24][295/750]	BT 0.045 (1.149)	DT 0.001 (1.101)	loss 7.212 (7.212)	prob 2.010 (2.010)	GS 32.406 (32.406)	mem 40.072
Train: [24][300/750]	BT 5.785 (1.150)	DT 5.742 (1.102)	loss 7.053 (7.053)	prob 2.325 (2.325)	GS 37.516 (37.516)	mem 40.002
Train: [24][305/750]	BT 0.119 (1.156)	DT 0.012 (1.108)	loss 6.999 (6.999)	prob 1.917 (1.917)	GS 34.969 (34.969)	mem 40.125
Train: [24][310/750]	BT 0.036 (1.138)	DT 0.001 (1.090)	loss 6.828 (6.828)	prob 2.765 (2.765)	GS 33.984 (33.984)	mem 40.023
Train: [24][315/750]	BT 0.044 (1.157)	DT 0.012 (1.109)	loss 7.130 (7.130)	prob 2.931 (2.931)	GS 31.109 (31.109)	mem 39.899
Train: [24][320/750]	BT 0.052 (1.157)	DT 0.001 (1.109)	loss 6.841 (6.841)	prob 2.599 (2.599)	GS 33.281 (33.281)	mem 40.040
Train: [24][325/750]	BT 0.046 (1.155)	DT 0.006 (1.107)	loss 6.885 (6.885)	prob 2.779 (2.779)	GS 34.391 (34.391)	mem 40.059
Train: [24][330/750]	BT 0.062 (1.166)	DT 0.006 (1.118)	loss 6.905 (6.905)	prob 2.149 (2.149)	GS 33.234 (33.234)	mem 40.000
Train: [24][335/750]	BT 0.028 (1.149)	DT 0.001 (1.101)	loss 7.054 (7.054)	prob 2.944 (2.944)	GS 30.156 (30.156)	mem 40.000
Train: [24][340/750]	BT 8.459 (1.175)	DT 8.413 (1.128)	loss 6.958 (6.958)	prob 2.566 (2.566)	GS 37.672 (37.672)	mem 39.818
Train: [24][345/750]	BT 0.063 (1.159)	DT 0.016 (1.111)	loss 6.963 (6.963)	prob 2.891 (2.891)	GS 30.203 (30.203)	mem 39.832
Train: [24][350/750]	BT 0.049 (1.154)	DT 0.003 (1.107)	loss 7.196 (7.196)	prob 2.217 (2.217)	GS 33.281 (33.281)	mem 39.926
Train: [24][355/750]	BT 0.026 (1.165)	DT 0.002 (1.117)	loss 6.913 (6.913)	prob 2.613 (2.613)	GS 27.016 (27.016)	mem 39.910
Train: [24][360/750]	BT 2.637 (1.156)	DT 2.606 (1.109)	loss 6.919 (6.919)	prob 2.618 (2.618)	GS 32.516 (32.516)	mem 39.964
Train: [24][365/750]	BT 0.039 (1.163)	DT 0.016 (1.116)	loss 6.987 (6.987)	prob 2.596 (2.596)	GS 28.828 (28.828)	mem 40.088
Train: [24][370/750]	BT 0.058 (1.148)	DT 0.006 (1.101)	loss 6.965 (6.965)	prob 2.600 (2.600)	GS 36.469 (36.469)	mem 40.299
Train: [24][375/750]	BT 0.022 (1.140)	DT 0.001 (1.093)	loss 6.996 (6.996)	prob 2.415 (2.415)	GS 32.109 (32.109)	mem 40.115
Train: [24][380/750]	BT 0.035 (1.153)	DT 0.001 (1.106)	loss 6.987 (6.987)	prob 2.738 (2.738)	GS 34.812 (34.812)	mem 40.113
Train: [24][385/750]	BT 0.085 (1.139)	DT 0.014 (1.092)	loss 6.991 (6.991)	prob 2.622 (2.622)	GS 28.719 (28.719)	mem 40.112
Train: [24][390/750]	BT 0.035 (1.161)	DT 0.001 (1.114)	loss 6.720 (6.720)	prob 3.519 (3.519)	GS 35.984 (35.984)	mem 40.096
Train: [24][395/750]	BT 0.118 (1.147)	DT 0.062 (1.100)	loss 6.924 (6.924)	prob 2.878 (2.878)	GS 35.188 (35.188)	mem 40.083
Train: [24][400/750]	BT 12.240 (1.164)	DT 12.215 (1.117)	loss 6.944 (6.944)	prob 2.560 (2.560)	GS 36.703 (36.703)	mem 40.110
Train: [24][405/750]	BT 0.038 (1.150)	DT 0.001 (1.103)	loss 6.922 (6.922)	prob 1.818 (1.818)	GS 29.812 (29.812)	mem 40.110
Train: [24][410/750]	BT 0.049 (1.137)	DT 0.002 (1.090)	loss 6.802 (6.802)	prob 2.836 (2.836)	GS 36.516 (36.516)	mem 40.110
Train: [24][415/750]	BT 0.050 (1.158)	DT 0.005 (1.111)	loss 6.903 (6.903)	prob 2.256 (2.256)	GS 38.969 (38.969)	mem 40.167
Train: [24][420/750]	BT 0.023 (1.144)	DT 0.001 (1.098)	loss 7.101 (7.101)	prob 2.938 (2.938)	GS 33.016 (33.016)	mem 40.073
Train: [24][425/750]	BT 0.042 (1.162)	DT 0.008 (1.116)	loss 6.966 (6.966)	prob 2.698 (2.698)	GS 32.703 (32.703)	mem 40.136
Train: [24][430/750]	BT 0.032 (1.150)	DT 0.001 (1.103)	loss 6.792 (6.792)	prob 3.007 (3.007)	GS 35.562 (35.562)	mem 40.137
Train: [24][435/750]	BT 0.031 (1.140)	DT 0.002 (1.093)	loss 6.933 (6.933)	prob 2.728 (2.728)	GS 31.688 (31.688)	mem 40.067
Train: [24][440/750]	BT 0.033 (1.150)	DT 0.001 (1.104)	loss 6.985 (6.985)	prob 2.576 (2.576)	GS 36.688 (36.688)	mem 40.103
Train: [24][445/750]	BT 0.079 (1.138)	DT 0.002 (1.091)	loss 6.980 (6.980)	prob 2.164 (2.164)	GS 34.703 (34.703)	mem 40.118
Train: [24][450/750]	BT 0.030 (1.157)	DT 0.001 (1.111)	loss 6.908 (6.908)	prob 3.137 (3.137)	GS 33.703 (33.703)	mem 40.016
Train: [24][455/750]	BT 0.039 (1.145)	DT 0.002 (1.099)	loss 7.055 (7.055)	prob 2.133 (2.133)	GS 31.688 (31.688)	mem 40.017
Train: [24][460/750]	BT 12.564 (1.163)	DT 12.531 (1.116)	loss 7.301 (7.301)	prob 1.681 (1.681)	GS 34.047 (34.047)	mem 40.092
Train: [24][465/750]	BT 0.046 (1.150)	DT 0.008 (1.104)	loss 6.826 (6.826)	prob 2.576 (2.576)	GS 32.391 (32.391)	mem 40.093
Train: [24][470/750]	BT 0.314 (1.140)	DT 0.283 (1.093)	loss 6.776 (6.776)	prob 2.642 (2.642)	GS 36.625 (36.625)	mem 40.116
Train: [24][475/750]	BT 0.033 (1.146)	DT 0.001 (1.099)	loss 7.030 (7.030)	prob 2.396 (2.396)	GS 33.469 (33.469)	mem 40.103
Train: [24][480/750]	BT 0.038 (1.134)	DT 0.002 (1.088)	loss 7.110 (7.110)	prob 2.580 (2.580)	GS 30.297 (30.297)	mem 40.104
Train: [24][485/750]	BT 0.038 (1.144)	DT 0.001 (1.097)	loss 6.821 (6.821)	prob 2.788 (2.788)	GS 31.328 (31.328)	mem 40.174
Train: [24][490/750]	BT 0.080 (1.132)	DT 0.019 (1.086)	loss 6.758 (6.758)	prob 2.307 (2.307)	GS 32.328 (32.328)	mem 40.139
Train: [24][495/750]	BT 0.035 (1.141)	DT 0.006 (1.095)	loss 7.003 (7.003)	prob 2.256 (2.256)	GS 32.312 (32.312)	mem 40.054
Train: [24][500/750]	BT 0.049 (1.136)	DT 0.002 (1.090)	loss 7.042 (7.042)	prob 2.546 (2.546)	GS 38.859 (38.859)	mem 40.102
Train: [24][505/750]	BT 0.066 (1.125)	DT 0.007 (1.079)	loss 7.063 (7.063)	prob 2.440 (2.440)	GS 30.312 (30.312)	mem 39.989
Train: [24][510/750]	BT 0.039 (1.139)	DT 0.001 (1.093)	loss 7.063 (7.063)	prob 2.050 (2.050)	GS 32.812 (32.812)	mem 40.079
Train: [24][515/750]	BT 0.032 (1.129)	DT 0.001 (1.082)	loss 6.985 (6.985)	prob 2.781 (2.781)	GS 30.797 (30.797)	mem 40.078
Train: [24][520/750]	BT 0.156 (1.140)	DT 0.125 (1.094)	loss 7.076 (7.076)	prob 2.175 (2.175)	GS 33.312 (33.312)	mem 40.050
Train: [24][525/750]	BT 0.051 (1.129)	DT 0.002 (1.083)	loss 6.903 (6.903)	prob 2.575 (2.575)	GS 34.234 (34.234)	mem 40.079
Train: [24][530/750]	BT 8.152 (1.146)	DT 8.129 (1.100)	loss 6.741 (6.741)	prob 2.017 (2.017)	GS 34.500 (34.500)	mem 40.131
Train: [24][535/750]	BT 0.032 (1.137)	DT 0.002 (1.091)	loss 6.845 (6.845)	prob 2.797 (2.797)	GS 33.266 (33.266)	mem 40.063
Train: [24][540/750]	BT 7.639 (1.141)	DT 7.570 (1.095)	loss 7.103 (7.103)	prob 2.389 (2.389)	GS 36.562 (36.562)	mem 40.233
Train: [24][545/750]	BT 0.052 (1.141)	DT 0.011 (1.095)	loss 6.692 (6.692)	prob 3.010 (3.010)	GS 32.062 (32.062)	mem 40.110
Train: [24][550/750]	BT 0.041 (1.131)	DT 0.001 (1.085)	loss 6.843 (6.843)	prob 2.795 (2.795)	GS 36.609 (36.609)	mem 40.111
Train: [24][555/750]	BT 0.030 (1.150)	DT 0.001 (1.105)	loss 6.769 (6.769)	prob 2.962 (2.962)	GS 30.453 (30.453)	mem 39.992
Train: [24][560/750]	BT 0.024 (1.140)	DT 0.001 (1.095)	loss 7.000 (7.000)	prob 2.214 (2.214)	GS 34.047 (34.047)	mem 39.993
Train: [24][565/750]	BT 0.039 (1.131)	DT 0.001 (1.085)	loss 7.004 (7.004)	prob 2.777 (2.777)	GS 31.672 (31.672)	mem 39.992
Train: [24][570/750]	BT 0.022 (1.145)	DT 0.001 (1.099)	loss 6.777 (6.777)	prob 2.337 (2.337)	GS 32.875 (32.875)	mem 40.068
Train: [24][575/750]	BT 0.105 (1.135)	DT 0.029 (1.090)	loss 6.754 (6.754)	prob 2.825 (2.825)	GS 35.031 (35.031)	mem 40.069
Train: [24][580/750]	BT 0.027 (1.150)	DT 0.001 (1.104)	loss 6.969 (6.969)	prob 2.060 (2.060)	GS 32.109 (32.109)	mem 40.250
Train: [24][585/750]	BT 0.029 (1.140)	DT 0.005 (1.095)	loss 7.289 (7.289)	prob 1.646 (1.646)	GS 33.234 (33.234)	mem 40.141
Train: [24][590/750]	BT 13.233 (1.153)	DT 13.211 (1.108)	loss 6.962 (6.962)	prob 2.429 (2.429)	GS 32.672 (32.672)	mem 40.318
Train: [24][595/750]	BT 0.051 (1.144)	DT 0.003 (1.099)	loss 6.747 (6.747)	prob 2.606 (2.606)	GS 33.859 (33.859)	mem 40.401
Train: [24][600/750]	BT 0.074 (1.135)	DT 0.004 (1.089)	loss 6.980 (6.980)	prob 2.454 (2.454)	GS 32.188 (32.188)	mem 40.479
Train: [24][605/750]	BT 0.036 (1.149)	DT 0.006 (1.104)	loss 6.758 (6.758)	prob 3.477 (3.477)	GS 33.094 (33.094)	mem 40.566
Train: [24][610/750]	BT 0.042 (1.140)	DT 0.001 (1.095)	loss 6.771 (6.771)	prob 3.098 (3.098)	GS 35.516 (35.516)	mem 40.569
Train: [24][615/750]	BT 0.033 (1.153)	DT 0.001 (1.108)	loss 6.673 (6.673)	prob 2.833 (2.833)	GS 33.156 (33.156)	mem 40.553
Train: [24][620/750]	BT 0.041 (1.144)	DT 0.002 (1.099)	loss 7.026 (7.026)	prob 2.552 (2.552)	GS 31.578 (31.578)	mem 40.580
Train: [24][625/750]	BT 0.061 (1.136)	DT 0.002 (1.090)	loss 7.144 (7.144)	prob 2.337 (2.337)	GS 33.766 (33.766)	mem 40.662
Train: [24][630/750]	BT 0.033 (1.149)	DT 0.001 (1.103)	loss 6.819 (6.819)	prob 2.716 (2.716)	GS 34.484 (34.484)	mem 42.091
Train: [24][635/750]	BT 0.041 (1.140)	DT 0.002 (1.095)	loss 6.874 (6.874)	prob 2.278 (2.278)	GS 28.594 (28.594)	mem 42.108
Train: [24][640/750]	BT 0.039 (1.155)	DT 0.006 (1.110)	loss 6.671 (6.671)	prob 2.324 (2.324)	GS 32.172 (32.172)	mem 42.192
Train: [24][645/750]	BT 0.029 (1.147)	DT 0.001 (1.102)	loss 7.092 (7.092)	prob 2.438 (2.438)	GS 34.078 (34.078)	mem 42.203
Train: [24][650/750]	BT 13.259 (1.159)	DT 13.196 (1.114)	loss 6.822 (6.822)	prob 2.297 (2.297)	GS 32.484 (32.484)	mem 42.829
Train: [24][655/750]	BT 0.031 (1.150)	DT 0.001 (1.105)	loss 6.764 (6.764)	prob 2.674 (2.674)	GS 32.219 (32.219)	mem 42.842
arpack error, retry= 0
arpack error, retry= 0
Train: [24][660/750]	BT 0.040 (1.142)	DT 0.001 (1.097)	loss 6.880 (6.880)	prob 2.900 (2.900)	GS 34.391 (34.391)	mem 42.930
Train: [24][665/750]	BT 0.081 (1.152)	DT 0.027 (1.106)	loss 7.184 (7.184)	prob 1.914 (1.914)	GS 27.766 (27.766)	mem 42.095
Train: [24][670/750]	BT 0.039 (1.143)	DT 0.014 (1.098)	loss 7.022 (7.022)	prob 1.883 (1.883)	GS 32.250 (32.250)	mem 41.949
Train: [24][675/750]	BT 0.042 (1.151)	DT 0.005 (1.106)	loss 6.875 (6.875)	prob 2.696 (2.696)	GS 27.625 (27.625)	mem 42.170
Train: [24][680/750]	BT 0.120 (1.143)	DT 0.003 (1.098)	loss 6.743 (6.743)	prob 2.769 (2.769)	GS 33.766 (33.766)	mem 42.248
Train: [24][685/750]	BT 0.042 (1.135)	DT 0.002 (1.090)	loss 6.941 (6.941)	prob 3.015 (3.015)	GS 29.156 (29.156)	mem 42.172
Train: [24][690/750]	BT 0.033 (1.145)	DT 0.001 (1.100)	loss 6.826 (6.826)	prob 2.770 (2.770)	GS 29.891 (29.891)	mem 42.199
Train: [24][695/750]	BT 0.049 (1.137)	DT 0.003 (1.092)	loss 6.932 (6.932)	prob 2.057 (2.057)	GS 30.781 (30.781)	mem 42.255
Train: [24][700/750]	BT 0.031 (1.145)	DT 0.001 (1.100)	loss 6.778 (6.778)	prob 2.312 (2.312)	GS 32.781 (32.781)	mem 42.138
Train: [24][705/750]	BT 0.044 (1.138)	DT 0.017 (1.092)	loss 6.645 (6.645)	prob 2.946 (2.946)	GS 30.891 (30.891)	mem 42.139
Train: [24][710/750]	BT 11.606 (1.146)	DT 11.562 (1.101)	loss 6.876 (6.876)	prob 2.432 (2.432)	GS 33.891 (33.891)	mem 42.217
Train: [24][715/750]	BT 0.160 (1.139)	DT 0.051 (1.093)	loss 6.786 (6.786)	prob 2.582 (2.582)	GS 32.500 (32.500)	mem 42.335
Train: [24][720/750]	BT 0.038 (1.131)	DT 0.006 (1.086)	loss 7.095 (7.095)	prob 2.326 (2.326)	GS 32.922 (32.922)	mem 42.221
Train: [24][725/750]	BT 0.041 (1.142)	DT 0.008 (1.097)	loss 7.100 (7.100)	prob 2.273 (2.273)	GS 29.266 (29.266)	mem 42.244
Train: [24][730/750]	BT 0.076 (1.135)	DT 0.004 (1.089)	loss 6.729 (6.729)	prob 2.666 (2.666)	GS 30.875 (30.875)	mem 42.245
Train: [24][735/750]	BT 0.035 (1.143)	DT 0.005 (1.097)	loss 7.020 (7.020)	prob 2.580 (2.580)	GS 27.297 (27.297)	mem 38.978
Train: [24][740/750]	BT 0.024 (1.135)	DT 0.001 (1.090)	loss 6.944 (6.944)	prob 2.858 (2.858)	GS 33.672 (33.672)	mem 38.995
Train: [24][745/750]	BT 0.027 (1.128)	DT 0.001 (1.083)	loss 6.757 (6.757)	prob 2.890 (2.890)	GS 36.500 (36.500)	mem 38.996
Train: [24][750/750]	BT 0.020 (1.124)	DT 0.001 (1.079)	loss 7.014 (7.014)	prob 2.731 (2.731)	GS 35.594 (35.594)	mem 9.808
Train: [24][755/750]	BT 0.025 (1.117)	DT 0.001 (1.072)	loss 6.764 (6.764)	prob 3.350 (3.350)	GS 34.312 (34.312)	mem 9.808
epoch 24, total time 843.41
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [25][1/750]	BT 21.164 (21.164)	DT 21.109 (21.109)	loss 6.801 (6.801)	prob 2.585 (2.585)	GS 36.125 (36.125)	mem 40.816
Train: [25][5/750]	BT 0.032 (4.719)	DT 0.001 (4.677)	loss 6.996 (6.996)	prob 2.779 (2.779)	GS 31.312 (31.312)	mem 40.899
Train: [25][10/750]	BT 0.823 (2.731)	DT 0.794 (2.681)	loss 6.642 (6.642)	prob 2.061 (2.061)	GS 32.828 (32.828)	mem 40.900
Train: [25][15/750]	BT 0.073 (2.458)	DT 0.001 (2.401)	loss 7.042 (7.042)	prob 2.307 (2.307)	GS 31.125 (31.125)	mem 41.009
Train: [25][20/750]	BT 0.028 (1.998)	DT 0.001 (1.942)	loss 6.722 (6.722)	prob 2.177 (2.177)	GS 32.500 (32.500)	mem 41.072
Train: [25][25/750]	BT 5.228 (1.842)	DT 5.194 (1.789)	loss 6.769 (6.769)	prob 2.751 (2.751)	GS 32.734 (32.734)	mem 41.213
Train: [25][30/750]	BT 7.298 (1.850)	DT 7.266 (1.797)	loss 6.793 (6.793)	prob 2.467 (2.467)	GS 37.172 (37.172)	mem 40.383
Train: [25][35/750]	BT 0.059 (1.594)	DT 0.014 (1.541)	loss 6.882 (6.882)	prob 2.575 (2.575)	GS 30.031 (30.031)	mem 39.090
Train: [25][40/750]	BT 5.631 (1.611)	DT 5.598 (1.560)	loss 7.017 (7.017)	prob 2.197 (2.197)	GS 34.484 (34.484)	mem 39.211
Train: [25][45/750]	BT 0.026 (1.614)	DT 0.001 (1.565)	loss 6.913 (6.913)	prob 3.025 (3.025)	GS 28.828 (28.828)	mem 39.131
Train: [25][50/750]	BT 0.031 (1.456)	DT 0.001 (1.409)	loss 6.952 (6.952)	prob 2.418 (2.418)	GS 30.375 (30.375)	mem 39.131
Train: [25][55/750]	BT 0.032 (1.555)	DT 0.001 (1.509)	loss 7.013 (7.013)	prob 2.399 (2.399)	GS 31.703 (31.703)	mem 39.239
Train: [25][60/750]	BT 0.048 (1.429)	DT 0.001 (1.383)	loss 6.875 (6.875)	prob 2.049 (2.049)	GS 34.516 (34.516)	mem 39.241
Train: [25][65/750]	BT 0.043 (1.324)	DT 0.001 (1.278)	loss 7.058 (7.058)	prob 2.598 (2.598)	GS 39.250 (39.250)	mem 39.172
Train: [25][70/750]	BT 0.025 (1.406)	DT 0.001 (1.361)	loss 6.848 (6.848)	prob 2.683 (2.683)	GS 32.906 (32.906)	mem 39.226
Train: [25][75/750]	BT 0.028 (1.315)	DT 0.002 (1.270)	loss 7.214 (7.214)	prob 2.364 (2.364)	GS 36.312 (36.312)	mem 39.364
Train: [25][80/750]	BT 0.072 (1.390)	DT 0.001 (1.346)	loss 7.007 (7.007)	prob 2.441 (2.441)	GS 32.109 (32.109)	mem 39.413
Train: [25][85/750]	BT 0.024 (1.311)	DT 0.001 (1.267)	loss 6.752 (6.752)	prob 2.976 (2.976)	GS 31.172 (31.172)	mem 39.267
Train: [25][90/750]	BT 5.709 (1.348)	DT 5.675 (1.304)	loss 6.645 (6.645)	prob 2.793 (2.793)	GS 34.812 (34.812)	mem 39.249
Train: [25][95/750]	BT 0.032 (1.278)	DT 0.001 (1.235)	loss 6.912 (6.912)	prob 2.375 (2.375)	GS 34.641 (34.641)	mem 39.250
Train: [25][100/750]	BT 9.512 (1.311)	DT 9.463 (1.268)	loss 6.625 (6.625)	prob 2.928 (2.928)	GS 33.016 (33.016)	mem 39.272
Train: [25][105/750]	BT 0.048 (1.258)	DT 0.009 (1.215)	loss 6.825 (6.825)	prob 2.812 (2.812)	GS 29.719 (29.719)	mem 39.208
Train: [25][110/750]	BT 0.913 (1.211)	DT 0.863 (1.168)	loss 6.837 (6.837)	prob 3.060 (3.060)	GS 32.562 (32.562)	mem 39.289
Train: [25][115/750]	BT 0.032 (1.265)	DT 0.002 (1.222)	loss 7.004 (7.004)	prob 2.755 (2.755)	GS 32.000 (32.000)	mem 39.442
Train: [25][120/750]	BT 5.762 (1.261)	DT 5.729 (1.219)	loss 6.663 (6.663)	prob 3.070 (3.070)	GS 34.297 (34.297)	mem 39.248
Train: [25][125/750]	BT 0.032 (1.240)	DT 0.002 (1.198)	loss 7.060 (7.060)	prob 2.628 (2.628)	GS 26.297 (26.297)	mem 39.218
Train: [25][130/750]	BT 1.359 (1.204)	DT 1.306 (1.162)	loss 6.646 (6.646)	prob 2.683 (2.683)	GS 32.125 (32.125)	mem 39.249
Train: [25][135/750]	BT 0.054 (1.199)	DT 0.010 (1.157)	loss 6.769 (6.769)	prob 2.584 (2.584)	GS 28.422 (28.422)	mem 39.414
Train: [25][140/750]	BT 0.025 (1.205)	DT 0.001 (1.163)	loss 6.938 (6.938)	prob 2.260 (2.260)	GS 30.688 (30.688)	mem 39.527
Train: [25][145/750]	BT 0.038 (1.203)	DT 0.001 (1.161)	loss 6.758 (6.758)	prob 3.038 (3.038)	GS 32.672 (32.672)	mem 39.578
Train: [25][150/750]	BT 0.032 (1.220)	DT 0.001 (1.178)	loss 6.852 (6.852)	prob 2.723 (2.723)	GS 31.031 (31.031)	mem 39.605
Train: [25][155/750]	BT 0.107 (1.182)	DT 0.011 (1.140)	loss 7.052 (7.052)	prob 2.706 (2.706)	GS 29.625 (29.625)	mem 39.606
Train: [25][160/750]	BT 5.385 (1.226)	DT 5.342 (1.183)	loss 7.184 (7.184)	prob 2.190 (2.190)	GS 33.219 (33.219)	mem 39.618
Train: [25][165/750]	BT 0.142 (1.191)	DT 0.005 (1.148)	loss 6.857 (6.857)	prob 2.806 (2.806)	GS 39.609 (39.609)	mem 39.566
Train: [25][170/750]	BT 0.057 (1.201)	DT 0.010 (1.157)	loss 7.065 (7.065)	prob 2.388 (2.388)	GS 37.250 (37.250)	mem 39.685
Train: [25][175/750]	BT 0.032 (1.208)	DT 0.002 (1.165)	loss 6.751 (6.751)	prob 3.417 (3.417)	GS 34.109 (34.109)	mem 39.632
Train: [25][180/750]	BT 5.372 (1.205)	DT 5.330 (1.162)	loss 6.768 (6.768)	prob 2.829 (2.829)	GS 36.391 (36.391)	mem 39.650
Train: [25][185/750]	BT 0.038 (1.205)	DT 0.001 (1.161)	loss 6.728 (6.728)	prob 2.240 (2.240)	GS 32.531 (32.531)	mem 39.787
Train: [25][190/750]	BT 0.051 (1.174)	DT 0.002 (1.131)	loss 6.925 (6.925)	prob 2.097 (2.097)	GS 36.375 (36.375)	mem 39.909
Train: [25][195/750]	BT 0.110 (1.186)	DT 0.002 (1.142)	loss 7.049 (7.049)	prob 2.396 (2.396)	GS 24.922 (24.922)	mem 40.004
Train: [25][200/750]	BT 0.027 (1.185)	DT 0.001 (1.142)	loss 6.864 (6.864)	prob 2.987 (2.987)	GS 35.078 (35.078)	mem 39.983
Train: [25][205/750]	BT 0.055 (1.182)	DT 0.005 (1.139)	loss 7.148 (7.148)	prob 2.479 (2.479)	GS 34.234 (34.234)	mem 40.059
Train: [25][210/750]	BT 0.031 (1.178)	DT 0.001 (1.134)	loss 7.004 (7.004)	prob 2.337 (2.337)	GS 34.797 (34.797)	mem 40.040
Train: [25][215/750]	BT 0.049 (1.151)	DT 0.008 (1.108)	loss 6.939 (6.939)	prob 2.448 (2.448)	GS 30.109 (30.109)	mem 40.039
Train: [25][220/750]	BT 2.155 (1.180)	DT 2.107 (1.137)	loss 6.778 (6.778)	prob 2.528 (2.528)	GS 30.078 (30.078)	mem 39.951
Train: [25][225/750]	BT 0.024 (1.155)	DT 0.001 (1.112)	loss 6.701 (6.701)	prob 2.804 (2.804)	GS 29.219 (29.219)	mem 39.954
Train: [25][230/750]	BT 0.033 (1.184)	DT 0.003 (1.141)	loss 6.740 (6.740)	prob 2.858 (2.858)	GS 33.266 (33.266)	mem 40.006
Train: [25][235/750]	BT 0.035 (1.163)	DT 0.002 (1.120)	loss 6.836 (6.836)	prob 2.458 (2.458)	GS 32.125 (32.125)	mem 40.156
Train: [25][240/750]	BT 13.246 (1.195)	DT 13.211 (1.152)	loss 6.880 (6.880)	prob 1.833 (1.833)	GS 33.531 (33.531)	mem 40.025
Train: [25][245/750]	BT 0.031 (1.186)	DT 0.001 (1.143)	loss 6.802 (6.802)	prob 2.640 (2.640)	GS 32.562 (32.562)	mem 40.037
Train: [25][250/750]	BT 0.050 (1.163)	DT 0.002 (1.120)	loss 6.811 (6.811)	prob 2.909 (2.909)	GS 32.453 (32.453)	mem 40.038
Train: [25][255/750]	BT 0.065 (1.171)	DT 0.007 (1.128)	loss 6.982 (6.982)	prob 2.717 (2.717)	GS 31.281 (31.281)	mem 39.952
Train: [25][260/750]	BT 0.029 (1.161)	DT 0.001 (1.119)	loss 6.810 (6.810)	prob 2.859 (2.859)	GS 32.516 (32.516)	mem 40.022
Train: [25][265/750]	BT 0.047 (1.174)	DT 0.011 (1.132)	loss 6.937 (6.937)	prob 2.555 (2.555)	GS 33.859 (33.859)	mem 39.984
Train: [25][270/750]	BT 0.059 (1.172)	DT 0.008 (1.129)	loss 6.651 (6.651)	prob 2.740 (2.740)	GS 32.234 (32.234)	mem 39.914
Train: [25][275/750]	BT 0.047 (1.151)	DT 0.006 (1.109)	loss 7.086 (7.086)	prob 2.874 (2.874)	GS 29.578 (29.578)	mem 39.914
Train: [25][280/750]	BT 8.611 (1.178)	DT 8.556 (1.136)	loss 6.922 (6.922)	prob 2.465 (2.465)	GS 34.109 (34.109)	mem 40.063
Train: [25][285/750]	BT 0.071 (1.159)	DT 0.002 (1.116)	loss 6.910 (6.910)	prob 2.582 (2.582)	GS 33.859 (33.859)	mem 40.134
Train: [25][290/750]	BT 0.053 (1.153)	DT 0.001 (1.109)	loss 7.157 (7.157)	prob 2.417 (2.417)	GS 30.250 (30.250)	mem 39.986
Train: [25][295/750]	BT 0.035 (1.168)	DT 0.002 (1.125)	loss 6.942 (6.942)	prob 2.521 (2.521)	GS 30.656 (30.656)	mem 39.959
Train: [25][300/750]	BT 4.137 (1.163)	DT 4.104 (1.120)	loss 6.753 (6.753)	prob 2.492 (2.492)	GS 33.406 (33.406)	mem 40.036
Train: [25][305/750]	BT 0.041 (1.173)	DT 0.002 (1.129)	loss 6.890 (6.890)	prob 2.018 (2.018)	GS 31.391 (31.391)	mem 40.207
Train: [25][310/750]	BT 0.041 (1.155)	DT 0.001 (1.111)	loss 6.731 (6.731)	prob 2.360 (2.360)	GS 35.906 (35.906)	mem 40.519
Train: [25][315/750]	BT 0.049 (1.153)	DT 0.002 (1.110)	loss 6.886 (6.886)	prob 2.458 (2.458)	GS 31.281 (31.281)	mem 40.054
Train: [25][320/750]	BT 0.038 (1.164)	DT 0.002 (1.120)	loss 6.652 (6.652)	prob 2.473 (2.473)	GS 28.438 (28.438)	mem 40.107
Train: [25][325/750]	BT 0.053 (1.162)	DT 0.020 (1.119)	loss 6.668 (6.668)	prob 2.763 (2.763)	GS 33.719 (33.719)	mem 40.412
Train: [25][330/750]	BT 0.056 (1.168)	DT 0.010 (1.124)	loss 6.845 (6.845)	prob 2.032 (2.032)	GS 30.469 (30.469)	mem 40.053
Train: [25][335/750]	BT 0.035 (1.151)	DT 0.003 (1.107)	loss 6.799 (6.799)	prob 2.251 (2.251)	GS 39.625 (39.625)	mem 40.042
Train: [25][340/750]	BT 2.757 (1.168)	DT 2.727 (1.124)	loss 6.905 (6.905)	prob 2.397 (2.397)	GS 36.094 (36.094)	mem 40.076
Train: [25][345/750]	BT 0.030 (1.151)	DT 0.001 (1.108)	loss 6.656 (6.656)	prob 2.237 (2.237)	GS 33.391 (33.391)	mem 40.077
Train: [25][350/750]	BT 0.073 (1.157)	DT 0.001 (1.113)	loss 6.885 (6.885)	prob 2.353 (2.353)	GS 30.719 (30.719)	mem 40.072
Train: [25][355/750]	BT 0.028 (1.167)	DT 0.001 (1.123)	loss 6.680 (6.680)	prob 2.010 (2.010)	GS 33.266 (33.266)	mem 39.991
Train: [25][360/750]	BT 1.684 (1.156)	DT 1.585 (1.112)	loss 7.099 (7.099)	prob 2.013 (2.013)	GS 28.781 (28.781)	mem 39.991
Train: [25][365/750]	BT 0.058 (1.173)	DT 0.005 (1.129)	loss 7.058 (7.058)	prob 2.506 (2.506)	GS 31.750 (31.750)	mem 40.098
Train: [25][370/750]	BT 0.057 (1.157)	DT 0.006 (1.114)	loss 6.832 (6.832)	prob 2.312 (2.312)	GS 31.219 (31.219)	mem 40.236
Train: [25][375/750]	BT 0.045 (1.143)	DT 0.002 (1.100)	loss 6.720 (6.720)	prob 2.848 (2.848)	GS 36.062 (36.062)	mem 40.024
Train: [25][380/750]	BT 0.051 (1.160)	DT 0.007 (1.116)	loss 6.758 (6.758)	prob 2.935 (2.935)	GS 32.656 (32.656)	mem 40.103
Train: [25][385/750]	BT 0.034 (1.145)	DT 0.001 (1.101)	loss 7.178 (7.178)	prob 2.205 (2.205)	GS 35.578 (35.578)	mem 40.109
Train: [25][390/750]	BT 0.090 (1.161)	DT 0.001 (1.117)	loss 6.887 (6.887)	prob 2.763 (2.763)	GS 35.422 (35.422)	mem 40.094
Train: [25][395/750]	BT 0.053 (1.147)	DT 0.006 (1.103)	loss 7.038 (7.038)	prob 2.798 (2.798)	GS 43.406 (43.406)	mem 40.321
Train: [25][400/750]	BT 9.033 (1.162)	DT 9.000 (1.118)	loss 6.676 (6.676)	prob 3.022 (3.022)	GS 35.422 (35.422)	mem 40.307
Train: [25][405/750]	BT 0.037 (1.148)	DT 0.002 (1.104)	loss 6.953 (6.953)	prob 2.713 (2.713)	GS 28.250 (28.250)	mem 40.241
Train: [25][410/750]	BT 0.790 (1.141)	DT 0.762 (1.097)	loss 6.599 (6.599)	prob 3.076 (3.076)	GS 35.219 (35.219)	mem 40.030
Train: [25][415/750]	BT 0.044 (1.157)	DT 0.001 (1.112)	loss 6.897 (6.897)	prob 2.273 (2.273)	GS 30.891 (30.891)	mem 40.284
Train: [25][420/750]	BT 0.032 (1.143)	DT 0.001 (1.099)	loss 7.058 (7.058)	prob 2.017 (2.017)	GS 34.781 (34.781)	mem 40.192
Train: [25][425/750]	BT 0.038 (1.159)	DT 0.001 (1.114)	loss 6.981 (6.981)	prob 2.487 (2.487)	GS 33.219 (33.219)	mem 40.085
Train: [25][430/750]	BT 0.032 (1.146)	DT 0.001 (1.102)	loss 6.712 (6.712)	prob 2.366 (2.366)	GS 37.297 (37.297)	mem 40.085
Train: [25][435/750]	BT 0.029 (1.147)	DT 0.001 (1.104)	loss 6.930 (6.930)	prob 2.562 (2.562)	GS 33.078 (33.078)	mem 40.109
Train: [25][440/750]	BT 0.050 (1.147)	DT 0.002 (1.103)	loss 6.819 (6.819)	prob 1.922 (1.922)	GS 37.188 (37.188)	mem 40.235
Train: [25][445/750]	BT 0.033 (1.153)	DT 0.002 (1.109)	loss 7.078 (7.078)	prob 2.617 (2.617)	GS 32.406 (32.406)	mem 40.276
Train: [25][450/750]	BT 0.079 (1.154)	DT 0.008 (1.110)	loss 6.726 (6.726)	prob 2.643 (2.643)	GS 32.969 (32.969)	mem 40.399
Train: [25][455/750]	BT 0.115 (1.143)	DT 0.008 (1.098)	loss 6.782 (6.782)	prob 2.672 (2.672)	GS 34.078 (34.078)	mem 40.282
Train: [25][460/750]	BT 1.852 (1.155)	DT 1.789 (1.110)	loss 6.722 (6.722)	prob 1.444 (1.444)	GS 29.250 (29.250)	mem 40.261
Train: [25][465/750]	BT 0.030 (1.143)	DT 0.002 (1.098)	loss 7.251 (7.251)	prob 2.371 (2.371)	GS 31.922 (31.922)	mem 40.230
Train: [25][470/750]	BT 0.044 (1.154)	DT 0.001 (1.110)	loss 6.741 (6.741)	prob 3.216 (3.216)	GS 31.281 (31.281)	mem 40.107
Train: [25][475/750]	BT 0.102 (1.145)	DT 0.025 (1.101)	loss 6.955 (6.955)	prob 2.864 (2.864)	GS 28.875 (28.875)	mem 40.047
Train: [25][480/750]	BT 9.085 (1.153)	DT 9.037 (1.108)	loss 7.024 (7.024)	prob 2.868 (2.868)	GS 33.594 (33.594)	mem 40.105
Train: [25][485/750]	BT 0.032 (1.144)	DT 0.001 (1.100)	loss 6.892 (6.892)	prob 2.181 (2.181)	GS 29.250 (29.250)	mem 40.126
Train: [25][490/750]	BT 0.035 (1.133)	DT 0.001 (1.089)	loss 6.817 (6.817)	prob 2.378 (2.378)	GS 34.625 (34.625)	mem 40.055
Train: [25][495/750]	BT 0.040 (1.137)	DT 0.009 (1.093)	loss 6.930 (6.930)	prob 2.452 (2.452)	GS 34.922 (34.922)	mem 40.108
Train: [25][500/750]	BT 0.031 (1.137)	DT 0.001 (1.093)	loss 6.986 (6.986)	prob 2.103 (2.103)	GS 34.484 (34.484)	mem 40.070
Train: [25][505/750]	BT 0.090 (1.141)	DT 0.007 (1.096)	loss 6.914 (6.914)	prob 2.967 (2.967)	GS 26.781 (26.781)	mem 40.135
Train: [25][510/750]	BT 0.080 (1.133)	DT 0.003 (1.089)	loss 6.663 (6.663)	prob 2.578 (2.578)	GS 32.562 (32.562)	mem 40.136
Train: [25][515/750]	BT 0.084 (1.125)	DT 0.013 (1.081)	loss 7.307 (7.307)	prob 2.429 (2.429)	GS 29.672 (29.672)	mem 40.189
Train: [25][520/750]	BT 2.813 (1.139)	DT 2.781 (1.095)	loss 6.711 (6.711)	prob 2.559 (2.559)	GS 34.078 (34.078)	mem 40.113
Train: [25][525/750]	BT 0.050 (1.129)	DT 0.010 (1.084)	loss 6.813 (6.813)	prob 2.393 (2.393)	GS 27.625 (27.625)	mem 40.113
Train: [25][530/750]	BT 5.325 (1.137)	DT 5.277 (1.092)	loss 6.915 (6.915)	prob 2.434 (2.434)	GS 37.281 (37.281)	mem 40.140
Train: [25][535/750]	BT 0.032 (1.136)	DT 0.001 (1.091)	loss 7.004 (7.004)	prob 2.921 (2.921)	GS 32.594 (32.594)	mem 40.167
Train: [25][540/750]	BT 2.373 (1.130)	DT 2.344 (1.086)	loss 6.862 (6.862)	prob 3.175 (3.175)	GS 35.938 (35.938)	mem 40.104
Train: [25][545/750]	BT 0.035 (1.143)	DT 0.004 (1.099)	loss 6.677 (6.677)	prob 2.755 (2.755)	GS 38.562 (38.562)	mem 40.036
Train: [25][550/750]	BT 0.055 (1.133)	DT 0.002 (1.089)	loss 6.898 (6.898)	prob 3.171 (3.171)	GS 31.047 (31.047)	mem 40.037
Train: [25][555/750]	BT 0.040 (1.129)	DT 0.014 (1.085)	loss 6.767 (6.767)	prob 2.434 (2.434)	GS 32.750 (32.750)	mem 40.106
Train: [25][560/750]	BT 0.059 (1.137)	DT 0.001 (1.093)	loss 6.587 (6.587)	prob 2.526 (2.526)	GS 30.922 (30.922)	mem 40.633
Train: [25][565/750]	BT 0.034 (1.128)	DT 0.002 (1.083)	loss 6.935 (6.935)	prob 2.441 (2.441)	GS 30.484 (30.484)	mem 40.641
Train: [25][570/750]	BT 0.059 (1.135)	DT 0.014 (1.091)	loss 6.843 (6.843)	prob 2.352 (2.352)	GS 35.281 (35.281)	mem 40.637
Train: [25][575/750]	BT 0.100 (1.130)	DT 0.039 (1.086)	loss 6.803 (6.803)	prob 2.652 (2.652)	GS 34.359 (34.359)	mem 40.664
Train: [25][580/750]	BT 8.096 (1.137)	DT 8.045 (1.092)	loss 6.806 (6.806)	prob 2.600 (2.600)	GS 33.531 (33.531)	mem 40.684
Train: [25][585/750]	BT 0.036 (1.127)	DT 0.001 (1.083)	loss 6.788 (6.788)	prob 2.409 (2.409)	GS 30.516 (30.516)	mem 40.714
Train: [25][590/750]	BT 0.049 (1.129)	DT 0.001 (1.085)	loss 6.840 (6.840)	prob 2.624 (2.624)	GS 37.641 (37.641)	mem 40.156
Train: [25][595/750]	BT 0.040 (1.128)	DT 0.002 (1.084)	loss 6.966 (6.966)	prob 2.401 (2.401)	GS 29.328 (29.328)	mem 40.162
Train: [25][600/750]	BT 4.508 (1.138)	DT 4.460 (1.094)	loss 7.163 (7.163)	prob 2.167 (2.167)	GS 41.422 (41.422)	mem 40.195
Train: [25][605/750]	BT 0.029 (1.133)	DT 0.001 (1.088)	loss 7.046 (7.046)	prob 2.466 (2.466)	GS 34.094 (34.094)	mem 40.194
Train: [25][610/750]	BT 4.072 (1.130)	DT 4.029 (1.086)	loss 6.719 (6.719)	prob 3.102 (3.102)	GS 34.938 (34.938)	mem 40.123
Train: [25][615/750]	BT 0.032 (1.132)	DT 0.002 (1.088)	loss 6.906 (6.906)	prob 2.721 (2.721)	GS 29.344 (29.344)	mem 40.176
Train: [25][620/750]	BT 0.031 (1.130)	DT 0.001 (1.086)	loss 6.745 (6.745)	prob 2.832 (2.832)	GS 34.406 (34.406)	mem 40.121
Train: [25][625/750]	BT 0.039 (1.132)	DT 0.002 (1.088)	loss 6.941 (6.941)	prob 3.015 (3.015)	GS 29.656 (29.656)	mem 40.306
Train: [25][630/750]	BT 0.081 (1.141)	DT 0.020 (1.097)	loss 6.964 (6.964)	prob 2.357 (2.357)	GS 32.406 (32.406)	mem 40.186
Train: [25][635/750]	BT 0.046 (1.132)	DT 0.009 (1.088)	loss 6.830 (6.830)	prob 2.981 (2.981)	GS 32.797 (32.797)	mem 40.150
Train: [25][640/750]	BT 15.795 (1.149)	DT 15.762 (1.104)	loss 7.000 (7.000)	prob 2.568 (2.568)	GS 33.000 (33.000)	mem 40.132
Train: [25][645/750]	BT 0.021 (1.140)	DT 0.001 (1.096)	loss 7.191 (7.191)	prob 2.437 (2.437)	GS 28.422 (28.422)	mem 40.132
Train: [25][650/750]	BT 0.057 (1.131)	DT 0.002 (1.087)	loss 6.780 (6.780)	prob 2.552 (2.552)	GS 29.406 (29.406)	mem 40.293
Train: [25][655/750]	BT 0.032 (1.139)	DT 0.006 (1.095)	loss 6.757 (6.757)	prob 2.997 (2.997)	GS 33.891 (33.891)	mem 40.199
arpack error, retry= 0
Train: [25][660/750]	BT 0.032 (1.131)	DT 0.002 (1.087)	loss 6.787 (6.787)	prob 3.003 (3.003)	GS 29.766 (29.766)	mem 40.200
Train: [25][665/750]	BT 0.086 (1.141)	DT 0.011 (1.097)	loss 6.955 (6.955)	prob 2.952 (2.952)	GS 32.031 (32.031)	mem 40.143
Train: [25][670/750]	BT 2.757 (1.137)	DT 2.727 (1.093)	loss 6.996 (6.996)	prob 2.611 (2.611)	GS 34.797 (34.797)	mem 40.117
Train: [25][675/750]	BT 0.039 (1.129)	DT 0.007 (1.085)	loss 7.061 (7.061)	prob 2.288 (2.288)	GS 27.812 (27.812)	mem 40.117
Train: [25][680/750]	BT 0.032 (1.136)	DT 0.001 (1.093)	loss 6.638 (6.638)	prob 3.895 (3.895)	GS 35.938 (35.938)	mem 40.235
Train: [25][685/750]	BT 0.057 (1.128)	DT 0.001 (1.085)	loss 6.875 (6.875)	prob 3.220 (3.220)	GS 28.906 (28.906)	mem 40.305
Train: [25][690/750]	BT 0.056 (1.140)	DT 0.010 (1.096)	loss 7.008 (7.008)	prob 2.188 (2.188)	GS 35.547 (35.547)	mem 40.207
Train: [25][695/750]	BT 0.046 (1.132)	DT 0.002 (1.088)	loss 6.918 (6.918)	prob 2.664 (2.664)	GS 28.219 (28.219)	mem 40.208
Train: [25][700/750]	BT 11.783 (1.141)	DT 11.738 (1.097)	loss 6.727 (6.727)	prob 3.099 (3.099)	GS 33.047 (33.047)	mem 40.215
Train: [25][705/750]	BT 0.087 (1.133)	DT 0.004 (1.089)	loss 6.870 (6.870)	prob 2.996 (2.996)	GS 30.906 (30.906)	mem 40.366
Train: [25][710/750]	BT 0.028 (1.126)	DT 0.001 (1.082)	loss 6.866 (6.866)	prob 2.595 (2.595)	GS 30.391 (30.391)	mem 40.218
Train: [25][715/750]	BT 0.029 (1.132)	DT 0.001 (1.088)	loss 6.637 (6.637)	prob 3.104 (3.104)	GS 28.672 (28.672)	mem 40.376
Train: [25][720/750]	BT 0.083 (1.124)	DT 0.007 (1.080)	loss 6.794 (6.794)	prob 3.022 (3.022)	GS 33.391 (33.391)	mem 40.706
Train: [25][725/750]	BT 0.025 (1.136)	DT 0.001 (1.092)	loss 6.732 (6.732)	prob 2.220 (2.220)	GS 32.266 (32.266)	mem 40.064
Train: [25][730/750]	BT 1.450 (1.130)	DT 1.325 (1.086)	loss 7.173 (7.173)	prob 3.066 (3.066)	GS 41.625 (41.625)	mem 40.077
Train: [25][735/750]	BT 0.032 (1.125)	DT 0.001 (1.080)	loss 6.929 (6.929)	prob 2.414 (2.414)	GS 30.031 (30.031)	mem 37.229
Train: [25][740/750]	BT 0.024 (1.129)	DT 0.001 (1.085)	loss 6.860 (6.860)	prob 2.327 (2.327)	GS 33.000 (33.000)	mem 19.613
Train: [25][745/750]	BT 0.040 (1.122)	DT 0.001 (1.078)	loss 6.883 (6.883)	prob 2.846 (2.846)	GS 31.438 (31.438)	mem 18.337
Train: [25][750/750]	BT 0.031 (1.118)	DT 0.001 (1.074)	loss 6.915 (6.915)	prob 2.506 (2.506)	GS 34.219 (34.219)	mem 10.768
Train: [25][755/750]	BT 0.035 (1.112)	DT 0.001 (1.068)	loss 7.051 (7.051)	prob 2.486 (2.486)	GS 30.875 (30.875)	mem 7.789
epoch 25, total time 839.43
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [26][1/750]	BT 20.954 (20.954)	DT 20.889 (20.889)	loss 6.550 (6.550)	prob 3.339 (3.339)	GS 30.234 (30.234)	mem 38.595
Train: [26][5/750]	BT 0.067 (4.241)	DT 0.006 (4.185)	loss 6.731 (6.731)	prob 2.902 (2.902)	GS 31.156 (31.156)	mem 38.600
Train: [26][10/750]	BT 0.485 (2.323)	DT 0.449 (2.269)	loss 6.719 (6.719)	prob 2.734 (2.734)	GS 34.656 (34.656)	mem 38.772
Train: [26][15/750]	BT 0.370 (2.083)	DT 0.274 (2.023)	loss 6.694 (6.694)	prob 3.069 (3.069)	GS 30.422 (30.422)	mem 38.990
Train: [26][20/750]	BT 1.573 (1.794)	DT 1.528 (1.737)	loss 6.836 (6.836)	prob 2.679 (2.679)	GS 34.250 (34.250)	mem 39.061
Train: [26][25/750]	BT 0.857 (1.583)	DT 0.811 (1.529)	loss 6.728 (6.728)	prob 2.503 (2.503)	GS 29.359 (29.359)	mem 39.084
Train: [26][30/750]	BT 0.040 (1.644)	DT 0.001 (1.590)	loss 6.671 (6.671)	prob 2.783 (2.783)	GS 38.234 (38.234)	mem 39.156
Train: [26][35/750]	BT 0.083 (1.529)	DT 0.017 (1.471)	loss 6.817 (6.817)	prob 3.455 (3.455)	GS 27.578 (27.578)	mem 39.116
Train: [26][40/750]	BT 7.778 (1.661)	DT 7.743 (1.606)	loss 6.866 (6.866)	prob 2.894 (2.894)	GS 40.828 (40.828)	mem 39.147
Train: [26][45/750]	BT 0.095 (1.574)	DT 0.002 (1.518)	loss 6.590 (6.590)	prob 2.740 (2.740)	GS 32.484 (32.484)	mem 39.258
Train: [26][50/750]	BT 0.851 (1.438)	DT 0.815 (1.383)	loss 6.947 (6.947)	prob 3.358 (3.358)	GS 34.359 (34.359)	mem 39.109
Train: [26][55/750]	BT 0.032 (1.457)	DT 0.001 (1.401)	loss 7.390 (7.390)	prob 1.824 (1.824)	GS 31.719 (31.719)	mem 39.220
Train: [26][60/750]	BT 0.134 (1.414)	DT 0.006 (1.357)	loss 6.840 (6.840)	prob 2.900 (2.900)	GS 35.047 (35.047)	mem 39.087
Train: [26][65/750]	BT 0.035 (1.466)	DT 0.003 (1.409)	loss 6.922 (6.922)	prob 3.062 (3.062)	GS 34.609 (34.609)	mem 39.231
Train: [26][70/750]	BT 0.082 (1.422)	DT 0.020 (1.366)	loss 6.911 (6.911)	prob 3.101 (3.101)	GS 32.906 (32.906)	mem 39.264
Train: [26][75/750]	BT 0.032 (1.329)	DT 0.001 (1.275)	loss 6.970 (6.970)	prob 2.216 (2.216)	GS 30.422 (30.422)	mem 39.264
Train: [26][80/750]	BT 3.803 (1.422)	DT 3.771 (1.369)	loss 6.802 (6.802)	prob 3.231 (3.231)	GS 34.938 (34.938)	mem 39.287
Train: [26][85/750]	BT 0.055 (1.342)	DT 0.003 (1.289)	loss 6.946 (6.946)	prob 2.794 (2.794)	GS 27.328 (27.328)	mem 39.499
Train: [26][90/750]	BT 0.063 (1.395)	DT 0.011 (1.344)	loss 6.973 (6.973)	prob 2.732 (2.732)	GS 33.062 (33.062)	mem 39.647
Train: [26][95/750]	BT 0.045 (1.340)	DT 0.002 (1.288)	loss 6.952 (6.952)	prob 3.001 (3.001)	GS 33.328 (33.328)	mem 39.557
Train: [26][100/750]	BT 13.267 (1.408)	DT 13.199 (1.356)	loss 6.695 (6.695)	prob 3.448 (3.448)	GS 36.609 (36.609)	mem 39.822
Train: [26][105/750]	BT 0.065 (1.346)	DT 0.015 (1.294)	loss 7.077 (7.077)	prob 2.720 (2.720)	GS 32.172 (32.172)	mem 39.664
Train: [26][110/750]	BT 0.032 (1.303)	DT 0.001 (1.250)	loss 6.941 (6.941)	prob 2.690 (2.690)	GS 33.484 (33.484)	mem 39.552
Train: [26][115/750]	BT 0.052 (1.339)	DT 0.008 (1.287)	loss 7.031 (7.031)	prob 2.786 (2.786)	GS 33.016 (33.016)	mem 39.641
Train: [26][120/750]	BT 0.081 (1.302)	DT 0.007 (1.249)	loss 6.931 (6.931)	prob 1.900 (1.900)	GS 37.188 (37.188)	mem 39.678
Train: [26][125/750]	BT 0.055 (1.321)	DT 0.003 (1.269)	loss 7.056 (7.056)	prob 2.447 (2.447)	GS 32.031 (32.031)	mem 39.772
Train: [26][130/750]	BT 5.559 (1.315)	DT 5.465 (1.262)	loss 6.771 (6.771)	prob 2.333 (2.333)	GS 31.594 (31.594)	mem 39.835
Train: [26][135/750]	BT 0.032 (1.267)	DT 0.001 (1.215)	loss 6.946 (6.946)	prob 2.305 (2.305)	GS 28.125 (28.125)	mem 39.837
Train: [26][140/750]	BT 1.508 (1.288)	DT 1.463 (1.236)	loss 7.114 (7.114)	prob 2.060 (2.060)	GS 38.906 (38.906)	mem 39.888
Train: [26][145/750]	BT 0.031 (1.260)	DT 0.001 (1.209)	loss 7.151 (7.151)	prob 2.669 (2.669)	GS 26.734 (26.734)	mem 39.842
Train: [26][150/750]	BT 0.679 (1.279)	DT 0.652 (1.228)	loss 6.877 (6.877)	prob 3.177 (3.177)	GS 35.266 (35.266)	mem 39.828
Train: [26][155/750]	BT 0.027 (1.277)	DT 0.001 (1.226)	loss 6.915 (6.915)	prob 2.728 (2.728)	GS 30.938 (30.938)	mem 39.816
Train: [26][160/750]	BT 10.717 (1.305)	DT 10.695 (1.255)	loss 6.814 (6.814)	prob 2.911 (2.911)	GS 34.688 (34.688)	mem 39.905
Train: [26][165/750]	BT 0.095 (1.268)	DT 0.025 (1.217)	loss 6.903 (6.903)	prob 2.803 (2.803)	GS 33.734 (33.734)	mem 39.865
Train: [26][170/750]	BT 0.025 (1.244)	DT 0.001 (1.194)	loss 6.894 (6.894)	prob 2.161 (2.161)	GS 36.047 (36.047)	mem 39.891
Train: [26][175/750]	BT 0.076 (1.277)	DT 0.014 (1.227)	loss 6.809 (6.809)	prob 2.935 (2.935)	GS 27.984 (27.984)	mem 39.993
Train: [26][180/750]	BT 0.046 (1.255)	DT 0.006 (1.205)	loss 6.910 (6.910)	prob 2.655 (2.655)	GS 33.531 (33.531)	mem 39.800
Train: [26][185/750]	BT 0.053 (1.265)	DT 0.001 (1.216)	loss 6.908 (6.908)	prob 2.760 (2.760)	GS 31.422 (31.422)	mem 39.788
Train: [26][190/750]	BT 1.259 (1.257)	DT 1.227 (1.208)	loss 6.680 (6.680)	prob 2.362 (2.362)	GS 35.375 (35.375)	mem 39.865
Train: [26][195/750]	BT 0.035 (1.226)	DT 0.004 (1.177)	loss 6.868 (6.868)	prob 2.520 (2.520)	GS 32.938 (32.938)	mem 39.814
Train: [26][200/750]	BT 0.034 (1.245)	DT 0.004 (1.196)	loss 6.959 (6.959)	prob 2.573 (2.573)	GS 34.250 (34.250)	mem 39.909
Train: [26][205/750]	BT 0.039 (1.241)	DT 0.002 (1.192)	loss 6.777 (6.777)	prob 2.981 (2.981)	GS 31.312 (31.312)	mem 40.120
Train: [26][210/750]	BT 2.478 (1.246)	DT 2.414 (1.197)	loss 6.936 (6.936)	prob 2.264 (2.264)	GS 32.000 (32.000)	mem 40.028
Train: [26][215/750]	BT 0.029 (1.239)	DT 0.001 (1.190)	loss 6.792 (6.792)	prob 2.310 (2.310)	GS 33.281 (33.281)	mem 39.964
Train: [26][220/750]	BT 4.838 (1.233)	DT 4.810 (1.185)	loss 6.824 (6.824)	prob 2.269 (2.269)	GS 35.203 (35.203)	mem 40.480
Train: [26][225/750]	BT 0.034 (1.239)	DT 0.002 (1.191)	loss 7.023 (7.023)	prob 1.981 (1.981)	GS 31.281 (31.281)	mem 40.170
Train: [26][230/750]	BT 0.039 (1.218)	DT 0.008 (1.170)	loss 6.719 (6.719)	prob 2.825 (2.825)	GS 33.703 (33.703)	mem 39.969
Train: [26][235/750]	BT 0.110 (1.238)	DT 0.021 (1.190)	loss 6.970 (6.970)	prob 2.061 (2.061)	GS 29.359 (29.359)	mem 39.949
Train: [26][240/750]	BT 0.057 (1.215)	DT 0.001 (1.167)	loss 6.805 (6.805)	prob 2.438 (2.438)	GS 35.172 (35.172)	mem 39.888
Train: [26][245/750]	BT 0.079 (1.219)	DT 0.005 (1.171)	loss 6.795 (6.795)	prob 2.866 (2.866)	GS 32.125 (32.125)	mem 40.067
Train: [26][250/750]	BT 0.742 (1.222)	DT 0.684 (1.174)	loss 6.761 (6.761)	prob 2.484 (2.484)	GS 34.984 (34.984)	mem 40.082
Train: [26][255/750]	BT 0.034 (1.199)	DT 0.002 (1.151)	loss 6.755 (6.755)	prob 2.813 (2.813)	GS 34.547 (34.547)	mem 40.258
Train: [26][260/750]	BT 0.041 (1.228)	DT 0.012 (1.180)	loss 6.656 (6.656)	prob 2.492 (2.492)	GS 33.750 (33.750)	mem 40.118
Train: [26][265/750]	BT 0.061 (1.208)	DT 0.005 (1.160)	loss 6.879 (6.879)	prob 2.605 (2.605)	GS 31.094 (31.094)	mem 40.069
Train: [26][270/750]	BT 1.451 (1.236)	DT 1.415 (1.188)	loss 6.799 (6.799)	prob 2.521 (2.521)	GS 37.688 (37.688)	mem 40.059
Train: [26][275/750]	BT 0.063 (1.215)	DT 0.003 (1.167)	loss 6.712 (6.712)	prob 2.566 (2.566)	GS 35.234 (35.234)	mem 40.061
Train: [26][280/750]	BT 11.893 (1.237)	DT 11.863 (1.189)	loss 6.788 (6.788)	prob 2.946 (2.946)	GS 31.703 (31.703)	mem 40.053
Train: [26][285/750]	BT 0.034 (1.218)	DT 0.001 (1.170)	loss 6.838 (6.838)	prob 3.153 (3.153)	GS 27.047 (27.047)	mem 40.218
Train: [26][290/750]	BT 0.051 (1.197)	DT 0.007 (1.150)	loss 6.718 (6.718)	prob 3.363 (3.363)	GS 35.938 (35.938)	mem 40.093
Train: [26][295/750]	BT 0.082 (1.226)	DT 0.008 (1.178)	loss 7.351 (7.351)	prob 2.306 (2.306)	GS 33.688 (33.688)	mem 40.113
Train: [26][300/750]	BT 0.052 (1.206)	DT 0.011 (1.158)	loss 6.910 (6.910)	prob 2.666 (2.666)	GS 35.375 (35.375)	mem 40.113
Train: [26][305/750]	BT 0.071 (1.231)	DT 0.022 (1.183)	loss 7.016 (7.016)	prob 2.783 (2.783)	GS 30.672 (30.672)	mem 40.055
Train: [26][310/750]	BT 0.032 (1.211)	DT 0.001 (1.164)	loss 6.895 (6.895)	prob 3.176 (3.176)	GS 37.594 (37.594)	mem 40.055
Train: [26][315/750]	BT 0.057 (1.193)	DT 0.018 (1.146)	loss 6.940 (6.940)	prob 3.080 (3.080)	GS 32.203 (32.203)	mem 40.267
Train: [26][320/750]	BT 0.034 (1.212)	DT 0.004 (1.165)	loss 6.961 (6.961)	prob 2.545 (2.545)	GS 28.016 (28.016)	mem 40.094
Train: [26][325/750]	BT 0.092 (1.194)	DT 0.001 (1.147)	loss 7.084 (7.084)	prob 1.535 (1.535)	GS 29.000 (29.000)	mem 40.094
Train: [26][330/750]	BT 0.097 (1.214)	DT 0.058 (1.166)	loss 6.906 (6.906)	prob 2.941 (2.941)	GS 29.812 (29.812)	mem 40.142
Train: [26][335/750]	BT 0.032 (1.196)	DT 0.001 (1.149)	loss 6.782 (6.782)	prob 2.714 (2.714)	GS 30.969 (30.969)	mem 40.065
Train: [26][340/750]	BT 14.320 (1.221)	DT 14.287 (1.174)	loss 6.664 (6.664)	prob 2.831 (2.831)	GS 32.375 (32.375)	mem 40.092
Train: [26][345/750]	BT 0.079 (1.204)	DT 0.024 (1.157)	loss 6.902 (6.902)	prob 2.648 (2.648)	GS 31.438 (31.438)	mem 40.057
Train: [26][350/750]	BT 0.032 (1.188)	DT 0.001 (1.141)	loss 6.667 (6.667)	prob 2.836 (2.836)	GS 29.000 (29.000)	mem 40.059
Train: [26][355/750]	BT 0.026 (1.215)	DT 0.003 (1.169)	loss 7.046 (7.046)	prob 2.716 (2.716)	GS 32.625 (32.625)	mem 40.035
Train: [26][360/750]	BT 0.128 (1.199)	DT 0.008 (1.152)	loss 6.779 (6.779)	prob 2.141 (2.141)	GS 32.516 (32.516)	mem 40.036
Train: [26][365/750]	BT 0.050 (1.201)	DT 0.002 (1.155)	loss 7.055 (7.055)	prob 3.085 (3.085)	GS 31.141 (31.141)	mem 40.185
Train: [26][370/750]	BT 0.045 (1.202)	DT 0.009 (1.155)	loss 6.667 (6.667)	prob 2.970 (2.970)	GS 31.406 (31.406)	mem 40.035
Train: [26][375/750]	BT 0.084 (1.187)	DT 0.008 (1.140)	loss 6.860 (6.860)	prob 2.783 (2.783)	GS 28.531 (28.531)	mem 40.036
Train: [26][380/750]	BT 0.023 (1.201)	DT 0.001 (1.154)	loss 6.729 (6.729)	prob 2.909 (2.909)	GS 35.922 (35.922)	mem 40.059
Train: [26][385/750]	BT 0.023 (1.186)	DT 0.001 (1.139)	loss 6.955 (6.955)	prob 3.019 (3.019)	GS 31.328 (31.328)	mem 40.061
Train: [26][390/750]	BT 0.351 (1.198)	DT 0.297 (1.151)	loss 6.885 (6.885)	prob 2.677 (2.677)	GS 33.953 (33.953)	mem 40.300
Train: [26][395/750]	BT 0.042 (1.184)	DT 0.002 (1.137)	loss 6.837 (6.837)	prob 2.568 (2.568)	GS 27.891 (27.891)	mem 40.341
Train: [26][400/750]	BT 14.074 (1.205)	DT 14.039 (1.158)	loss 6.660 (6.660)	prob 3.888 (3.888)	GS 31.000 (31.000)	mem 40.334
Train: [26][405/750]	BT 0.054 (1.190)	DT 0.014 (1.144)	loss 6.818 (6.818)	prob 2.507 (2.507)	GS 29.156 (29.156)	mem 40.146
Train: [26][410/750]	BT 0.042 (1.176)	DT 0.002 (1.130)	loss 7.050 (7.050)	prob 2.470 (2.470)	GS 32.812 (32.812)	mem 40.073
Train: [26][415/750]	BT 0.095 (1.197)	DT 0.013 (1.151)	loss 6.919 (6.919)	prob 3.142 (3.142)	GS 31.203 (31.203)	mem 40.096
Train: [26][420/750]	BT 0.032 (1.184)	DT 0.001 (1.137)	loss 6.924 (6.924)	prob 1.960 (1.960)	GS 33.016 (33.016)	mem 40.097
Train: [26][425/750]	BT 0.053 (1.204)	DT 0.004 (1.157)	loss 6.749 (6.749)	prob 2.900 (2.900)	GS 30.375 (30.375)	mem 40.232
Train: [26][430/750]	BT 0.029 (1.199)	DT 0.001 (1.152)	loss 6.938 (6.938)	prob 2.669 (2.669)	GS 36.875 (36.875)	mem 40.036
Train: [26][435/750]	BT 0.031 (1.185)	DT 0.001 (1.139)	loss 7.248 (7.248)	prob 2.333 (2.333)	GS 45.219 (45.219)	mem 40.066
Train: [26][440/750]	BT 0.021 (1.205)	DT 0.001 (1.159)	loss 6.767 (6.767)	prob 3.197 (3.197)	GS 30.609 (30.609)	mem 40.007
Train: [26][445/750]	BT 0.034 (1.192)	DT 0.001 (1.146)	loss 7.014 (7.014)	prob 3.189 (3.189)	GS 25.875 (25.875)	mem 40.012
Train: [26][450/750]	BT 9.449 (1.205)	DT 9.359 (1.159)	loss 6.741 (6.741)	prob 3.098 (3.098)	GS 35.578 (35.578)	mem 40.227
Train: [26][455/750]	BT 0.031 (1.192)	DT 0.002 (1.147)	loss 6.908 (6.908)	prob 3.089 (3.089)	GS 29.344 (29.344)	mem 40.132
Train: [26][460/750]	BT 6.391 (1.194)	DT 6.323 (1.148)	loss 6.858 (6.858)	prob 2.557 (2.557)	GS 35.344 (35.344)	mem 40.102
Train: [26][465/750]	BT 0.032 (1.200)	DT 0.001 (1.154)	loss 6.894 (6.894)	prob 3.037 (3.037)	GS 27.828 (27.828)	mem 40.191
Train: [26][470/750]	BT 0.031 (1.187)	DT 0.001 (1.141)	loss 7.219 (7.219)	prob 1.844 (1.844)	GS 32.484 (32.484)	mem 40.164
Train: [26][475/750]	BT 0.042 (1.200)	DT 0.001 (1.154)	loss 6.913 (6.913)	prob 2.878 (2.878)	GS 28.312 (28.312)	mem 40.300
Train: [26][480/750]	BT 0.031 (1.187)	DT 0.001 (1.142)	loss 6.787 (6.787)	prob 3.135 (3.135)	GS 36.453 (36.453)	mem 40.121
Train: [26][485/750]	BT 0.032 (1.181)	DT 0.002 (1.135)	loss 6.891 (6.891)	prob 2.633 (2.633)	GS 32.203 (32.203)	mem 40.160
Train: [26][490/750]	BT 0.026 (1.189)	DT 0.001 (1.143)	loss 6.701 (6.701)	prob 3.680 (3.680)	GS 39.188 (39.188)	mem 39.988
Train: [26][495/750]	BT 0.056 (1.177)	DT 0.005 (1.132)	loss 6.744 (6.744)	prob 2.896 (2.896)	GS 30.078 (30.078)	mem 39.990
Train: [26][500/750]	BT 0.033 (1.192)	DT 0.001 (1.146)	loss 6.778 (6.778)	prob 3.117 (3.117)	GS 34.109 (34.109)	mem 40.213
Train: [26][505/750]	BT 0.033 (1.180)	DT 0.001 (1.135)	loss 6.618 (6.618)	prob 3.063 (3.063)	GS 30.219 (30.219)	mem 40.176
Train: [26][510/750]	BT 14.596 (1.198)	DT 14.541 (1.153)	loss 7.161 (7.161)	prob 2.182 (2.182)	GS 39.938 (39.938)	mem 40.054
Train: [26][515/750]	BT 0.028 (1.187)	DT 0.001 (1.142)	loss 6.903 (6.903)	prob 2.836 (2.836)	GS 30.375 (30.375)	mem 40.055
Train: [26][520/750]	BT 0.030 (1.176)	DT 0.001 (1.131)	loss 6.905 (6.905)	prob 2.123 (2.123)	GS 33.531 (33.531)	mem 40.057
Train: [26][525/750]	BT 0.022 (1.186)	DT 0.001 (1.141)	loss 6.875 (6.875)	prob 3.006 (3.006)	GS 27.609 (27.609)	mem 40.120
Train: [26][530/750]	BT 0.128 (1.176)	DT 0.003 (1.130)	loss 6.956 (6.956)	prob 2.449 (2.449)	GS 34.375 (34.375)	mem 40.268
Train: [26][535/750]	BT 0.023 (1.192)	DT 0.001 (1.147)	loss 6.619 (6.619)	prob 2.696 (2.696)	GS 29.750 (29.750)	mem 40.149
Train: [26][540/750]	BT 0.037 (1.181)	DT 0.002 (1.136)	loss 6.733 (6.733)	prob 2.772 (2.772)	GS 37.781 (37.781)	mem 40.256
Train: [26][545/750]	BT 0.032 (1.170)	DT 0.002 (1.126)	loss 6.616 (6.616)	prob 2.910 (2.910)	GS 31.375 (31.375)	mem 40.149
Train: [26][550/750]	BT 0.051 (1.183)	DT 0.008 (1.138)	loss 6.538 (6.538)	prob 2.347 (2.347)	GS 33.828 (33.828)	mem 40.167
Train: [26][555/750]	BT 0.057 (1.173)	DT 0.002 (1.128)	loss 6.429 (6.429)	prob 3.214 (3.214)	GS 28.812 (28.812)	mem 40.253
Train: [26][560/750]	BT 0.035 (1.188)	DT 0.002 (1.143)	loss 6.479 (6.479)	prob 2.694 (2.694)	GS 36.203 (36.203)	mem 40.205
Train: [26][565/750]	BT 0.033 (1.178)	DT 0.001 (1.133)	loss 6.449 (6.449)	prob 2.421 (2.421)	GS 32.328 (32.328)	mem 40.206
Train: [26][570/750]	BT 13.098 (1.191)	DT 13.067 (1.146)	loss 6.689 (6.689)	prob 2.701 (2.701)	GS 35.297 (35.297)	mem 40.221
Train: [26][575/750]	BT 0.042 (1.180)	DT 0.002 (1.136)	loss 6.525 (6.525)	prob 2.776 (2.776)	GS 26.312 (26.312)	mem 40.222
Train: [26][580/750]	BT 0.032 (1.171)	DT 0.001 (1.126)	loss 6.387 (6.387)	prob 2.906 (2.906)	GS 37.516 (37.516)	mem 40.252
Train: [26][585/750]	BT 0.030 (1.182)	DT 0.001 (1.138)	loss 6.848 (6.848)	prob 2.278 (2.278)	GS 29.969 (29.969)	mem 40.162
Train: [26][590/750]	BT 0.030 (1.173)	DT 0.001 (1.128)	loss 6.570 (6.570)	prob 2.900 (2.900)	GS 35.125 (35.125)	mem 40.161
Train: [26][595/750]	BT 0.046 (1.182)	DT 0.003 (1.138)	loss 6.728 (6.728)	prob 2.435 (2.435)	GS 34.219 (34.219)	mem 40.330
Train: [26][600/750]	BT 0.057 (1.173)	DT 0.003 (1.128)	loss 6.808 (6.808)	prob 2.442 (2.442)	GS 37.797 (37.797)	mem 40.606
Train: [26][605/750]	BT 0.084 (1.163)	DT 0.003 (1.119)	loss 6.733 (6.733)	prob 2.700 (2.700)	GS 30.062 (30.062)	mem 40.370
Train: [26][610/750]	BT 0.041 (1.176)	DT 0.002 (1.132)	loss 6.722 (6.722)	prob 3.608 (3.608)	GS 33.266 (33.266)	mem 40.287
Train: [26][615/750]	BT 0.078 (1.167)	DT 0.001 (1.123)	loss 6.679 (6.679)	prob 2.841 (2.841)	GS 30.891 (30.891)	mem 40.262
Train: [26][620/750]	BT 0.028 (1.178)	DT 0.001 (1.134)	loss 7.100 (7.100)	prob 1.942 (1.942)	GS 27.875 (27.875)	mem 40.162
Train: [26][625/750]	BT 0.046 (1.169)	DT 0.007 (1.124)	loss 7.025 (7.025)	prob 2.388 (2.388)	GS 31.656 (31.656)	mem 40.163
Train: [26][630/750]	BT 14.889 (1.184)	DT 14.863 (1.139)	loss 6.911 (6.911)	prob 3.027 (3.027)	GS 40.031 (40.031)	mem 40.311
Train: [26][635/750]	BT 0.047 (1.175)	DT 0.012 (1.130)	loss 6.878 (6.878)	prob 2.763 (2.763)	GS 36.203 (36.203)	mem 40.151
Train: [26][640/750]	BT 0.041 (1.166)	DT 0.001 (1.121)	loss 7.309 (7.309)	prob 2.023 (2.023)	GS 35.438 (35.438)	mem 40.152
Train: [26][645/750]	BT 0.034 (1.176)	DT 0.001 (1.131)	loss 6.733 (6.733)	prob 2.748 (2.748)	GS 36.078 (36.078)	mem 40.207
Train: [26][650/750]	BT 0.052 (1.167)	DT 0.001 (1.123)	loss 7.428 (7.428)	prob 1.903 (1.903)	GS 35.688 (35.688)	mem 40.207
Train: [26][655/750]	BT 0.049 (1.181)	DT 0.009 (1.136)	loss 7.239 (7.239)	prob 3.015 (3.015)	GS 25.219 (25.219)	mem 40.142
Train: [26][660/750]	BT 0.031 (1.172)	DT 0.001 (1.128)	loss 7.138 (7.138)	prob 2.622 (2.622)	GS 32.609 (32.609)	mem 40.161
Train: [26][665/750]	BT 0.068 (1.164)	DT 0.009 (1.119)	loss 6.852 (6.852)	prob 3.096 (3.096)	GS 28.891 (28.891)	mem 40.161
Train: [26][670/750]	BT 0.039 (1.175)	DT 0.001 (1.130)	loss 7.113 (7.113)	prob 2.619 (2.619)	GS 35.875 (35.875)	mem 40.284
Train: [26][675/750]	BT 0.027 (1.166)	DT 0.001 (1.122)	loss 7.129 (7.129)	prob 2.132 (2.132)	GS 30.750 (30.750)	mem 40.286
Train: [26][680/750]	BT 0.034 (1.180)	DT 0.001 (1.135)	loss 7.705 (7.705)	prob 1.825 (1.825)	GS 35.734 (35.734)	mem 40.177
Train: [26][685/750]	BT 0.031 (1.172)	DT 0.007 (1.127)	loss 6.988 (6.988)	prob 2.957 (2.957)	GS 33.938 (33.938)	mem 40.150
Train: [26][690/750]	BT 13.299 (1.183)	DT 13.270 (1.138)	loss 7.471 (7.471)	prob 2.349 (2.349)	GS 32.703 (32.703)	mem 40.211
Train: [26][695/750]	BT 0.029 (1.174)	DT 0.001 (1.130)	loss 6.897 (6.897)	prob 3.086 (3.086)	GS 31.594 (31.594)	mem 40.210
Train: [26][700/750]	BT 0.062 (1.166)	DT 0.001 (1.122)	loss 7.368 (7.368)	prob 2.721 (2.721)	GS 33.234 (33.234)	mem 40.229
Train: [26][705/750]	BT 0.044 (1.174)	DT 0.002 (1.130)	loss 7.428 (7.428)	prob 2.354 (2.354)	GS 30.016 (30.016)	mem 40.301
Train: [26][710/750]	BT 0.065 (1.166)	DT 0.011 (1.122)	loss 7.201 (7.201)	prob 2.458 (2.458)	GS 32.094 (32.094)	mem 40.247
Train: [26][715/750]	BT 0.030 (1.175)	DT 0.001 (1.131)	loss 7.763 (7.763)	prob 1.410 (1.410)	GS 31.531 (31.531)	mem 40.274
Train: [26][720/750]	BT 0.037 (1.167)	DT 0.001 (1.123)	loss 7.514 (7.514)	prob 2.815 (2.815)	GS 35.203 (35.203)	mem 40.351
Train: [26][725/750]	BT 0.031 (1.160)	DT 0.001 (1.116)	loss 6.870 (6.870)	prob 2.083 (2.083)	GS 30.312 (30.312)	mem 40.261
Train: [26][730/750]	BT 0.029 (1.169)	DT 0.001 (1.125)	loss 7.198 (7.198)	prob 2.454 (2.454)	GS 29.859 (29.859)	mem 39.916
Train: [26][735/750]	BT 0.067 (1.162)	DT 0.001 (1.118)	loss 8.232 (8.232)	prob 1.095 (1.095)	GS 31.297 (31.297)	mem 39.927
Train: [26][740/750]	BT 0.026 (1.163)	DT 0.001 (1.119)	loss 7.530 (7.530)	prob 2.458 (2.458)	GS 32.391 (32.391)	mem 10.718
Train: [26][745/750]	BT 0.039 (1.155)	DT 0.002 (1.112)	loss 6.766 (6.766)	prob 3.183 (3.183)	GS 31.781 (31.781)	mem 10.681
Train: [26][750/750]	BT 1.748 (1.150)	DT 1.712 (1.107)	loss 6.745 (6.745)	prob 3.252 (3.252)	GS 31.156 (31.156)	mem 7.730
Train: [26][755/750]	BT 0.025 (1.143)	DT 0.001 (1.099)	loss 7.043 (7.043)	prob 3.575 (3.575)	GS 32.969 (32.969)	mem 7.730
epoch 26, total time 863.12
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [27][1/750]	BT 20.174 (20.174)	DT 20.126 (20.126)	loss 6.979 (6.979)	prob 2.693 (2.693)	GS 32.484 (32.484)	mem 38.707
Train: [27][5/750]	BT 0.051 (5.155)	DT 0.002 (5.085)	loss 6.958 (6.958)	prob 2.657 (2.657)	GS 31.484 (31.484)	mem 38.882
Train: [27][10/750]	BT 0.035 (2.956)	DT 0.004 (2.900)	loss 7.751 (7.751)	prob 2.157 (2.157)	GS 30.375 (30.375)	mem 38.895
Train: [27][15/750]	BT 0.055 (2.457)	DT 0.007 (2.395)	loss 6.718 (6.718)	prob 3.036 (3.036)	GS 27.188 (27.188)	mem 38.954
Train: [27][20/750]	BT 4.157 (2.162)	DT 4.106 (2.098)	loss 7.560 (7.560)	prob 2.623 (2.623)	GS 33.797 (33.797)	mem 39.007
Train: [27][25/750]	BT 0.076 (1.747)	DT 0.006 (1.679)	loss 7.209 (7.209)	prob 2.329 (2.329)	GS 31.375 (31.375)	mem 39.008
Train: [27][30/750]	BT 1.806 (1.724)	DT 1.772 (1.656)	loss 7.316 (7.316)	prob 2.587 (2.587)	GS 33.125 (33.125)	mem 39.055
Train: [27][35/750]	BT 0.031 (1.573)	DT 0.001 (1.509)	loss 7.217 (7.217)	prob 1.462 (1.462)	GS 30.609 (30.609)	mem 39.069
Train: [27][40/750]	BT 0.033 (1.618)	DT 0.002 (1.557)	loss 7.730 (7.730)	prob 2.843 (2.843)	GS 34.797 (34.797)	mem 39.074
Train: [27][45/750]	BT 0.161 (1.486)	DT 0.018 (1.423)	loss 7.327 (7.327)	prob 2.246 (2.246)	GS 31.516 (31.516)	mem 39.214
Train: [27][50/750]	BT 10.678 (1.555)	DT 10.607 (1.494)	loss 7.153 (7.153)	prob 3.183 (3.183)	GS 31.344 (31.344)	mem 39.363
Train: [27][55/750]	BT 0.035 (1.419)	DT 0.001 (1.358)	loss 7.099 (7.099)	prob 2.819 (2.819)	GS 27.375 (27.375)	mem 39.407
Train: [27][60/750]	BT 0.063 (1.319)	DT 0.014 (1.260)	loss 7.412 (7.412)	prob 2.539 (2.539)	GS 26.000 (26.000)	mem 39.394
Train: [27][65/750]	BT 0.165 (1.418)	DT 0.002 (1.358)	loss 7.503 (7.503)	prob 1.972 (1.972)	GS 33.766 (33.766)	mem 39.890
Train: [27][70/750]	BT 0.034 (1.357)	DT 0.002 (1.298)	loss 7.384 (7.384)	prob 2.837 (2.837)	GS 33.359 (33.359)	mem 39.773
Train: [27][75/750]	BT 0.032 (1.439)	DT 0.001 (1.381)	loss 7.080 (7.080)	prob 2.594 (2.594)	GS 30.203 (30.203)	mem 39.712
Train: [27][80/750]	BT 0.045 (1.352)	DT 0.014 (1.295)	loss 7.465 (7.465)	prob 2.829 (2.829)	GS 34.734 (34.734)	mem 39.753
Train: [27][85/750]	BT 0.031 (1.275)	DT 0.001 (1.219)	loss 7.597 (7.597)	prob 2.083 (2.083)	GS 31.875 (31.875)	mem 39.719
Train: [27][90/750]	BT 0.045 (1.344)	DT 0.010 (1.289)	loss 6.943 (6.943)	prob 2.290 (2.290)	GS 37.953 (37.953)	mem 39.731
Train: [27][95/750]	BT 0.034 (1.281)	DT 0.002 (1.227)	loss 8.453 (8.453)	prob 1.447 (1.447)	GS 33.703 (33.703)	mem 39.736
Train: [27][100/750]	BT 0.031 (1.352)	DT 0.001 (1.298)	loss 7.715 (7.715)	prob 2.966 (2.966)	GS 35.422 (35.422)	mem 39.805
Train: [27][105/750]	BT 0.054 (1.289)	DT 0.010 (1.237)	loss 7.899 (7.899)	prob 1.669 (1.669)	GS 31.766 (31.766)	mem 39.852
Train: [27][110/750]	BT 14.084 (1.361)	DT 14.009 (1.308)	loss 7.461 (7.461)	prob 2.887 (2.887)	GS 35.234 (35.234)	mem 40.012
Train: [27][115/750]	BT 0.034 (1.303)	DT 0.002 (1.251)	loss 7.365 (7.365)	prob 2.303 (2.303)	GS 26.406 (26.406)	mem 40.066
Train: [27][120/750]	BT 0.055 (1.251)	DT 0.004 (1.200)	loss 7.325 (7.325)	prob 2.277 (2.277)	GS 37.578 (37.578)	mem 39.969
Train: [27][125/750]	BT 0.080 (1.312)	DT 0.029 (1.262)	loss 7.181 (7.181)	prob 2.221 (2.221)	GS 30.672 (30.672)	mem 39.806
Train: [27][130/750]	BT 0.032 (1.263)	DT 0.001 (1.213)	loss 7.456 (7.456)	prob 2.877 (2.877)	GS 38.547 (38.547)	mem 39.808
Train: [27][135/750]	BT 0.025 (1.305)	DT 0.001 (1.254)	loss 7.468 (7.468)	prob 2.938 (2.938)	GS 25.406 (25.406)	mem 39.794
Train: [27][140/750]	BT 0.035 (1.259)	DT 0.001 (1.210)	loss 7.431 (7.431)	prob 3.776 (3.776)	GS 27.734 (27.734)	mem 39.798
Train: [27][145/750]	BT 0.053 (1.223)	DT 0.006 (1.174)	loss 7.635 (7.635)	prob 2.135 (2.135)	GS 39.641 (39.641)	mem 39.877
Train: [27][150/750]	BT 0.282 (1.246)	DT 0.234 (1.197)	loss 7.662 (7.662)	prob 2.640 (2.640)	GS 32.734 (32.734)	mem 39.872
Train: [27][155/750]	BT 0.048 (1.208)	DT 0.002 (1.159)	loss 7.105 (7.105)	prob 3.208 (3.208)	GS 31.047 (31.047)	mem 39.895
Train: [27][160/750]	BT 0.031 (1.249)	DT 0.001 (1.201)	loss 7.681 (7.681)	prob 3.184 (3.184)	GS 32.172 (32.172)	mem 39.949
Train: [27][165/750]	BT 0.107 (1.218)	DT 0.003 (1.169)	loss 7.141 (7.141)	prob 3.441 (3.441)	GS 32.297 (32.297)	mem 40.124
Train: [27][170/750]	BT 9.414 (1.254)	DT 9.383 (1.205)	loss 7.624 (7.624)	prob 3.042 (3.042)	GS 34.391 (34.391)	mem 39.860
Train: [27][175/750]	BT 0.034 (1.219)	DT 0.001 (1.171)	loss 7.045 (7.045)	prob 3.000 (3.000)	GS 31.375 (31.375)	mem 39.824
Train: [27][180/750]	BT 0.056 (1.187)	DT 0.019 (1.138)	loss 7.292 (7.292)	prob 3.239 (3.239)	GS 28.516 (28.516)	mem 39.868
Train: [27][185/750]	BT 0.037 (1.222)	DT 0.002 (1.174)	loss 7.198 (7.198)	prob 2.702 (2.702)	GS 30.906 (30.906)	mem 39.956
Train: [27][190/750]	BT 1.198 (1.198)	DT 1.170 (1.149)	loss 7.216 (7.216)	prob 2.945 (2.945)	GS 34.016 (34.016)	mem 39.988
Train: [27][195/750]	BT 0.068 (1.224)	DT 0.012 (1.175)	loss 7.495 (7.495)	prob 2.493 (2.493)	GS 34.422 (34.422)	mem 40.240
Train: [27][200/750]	BT 1.618 (1.219)	DT 1.577 (1.171)	loss 8.053 (8.053)	prob 2.870 (2.870)	GS 36.453 (36.453)	mem 40.254
Train: [27][205/750]	BT 0.024 (1.190)	DT 0.001 (1.143)	loss 7.378 (7.378)	prob 3.110 (3.110)	GS 32.938 (32.938)	mem 40.328
Train: [27][210/750]	BT 1.208 (1.200)	DT 1.157 (1.152)	loss 7.767 (7.767)	prob 3.676 (3.676)	GS 31.344 (31.344)	mem 41.239
Train: [27][215/750]	BT 0.048 (1.196)	DT 0.004 (1.148)	loss 7.216 (7.216)	prob 3.393 (3.393)	GS 32.531 (32.531)	mem 41.905
Train: [27][220/750]	BT 0.033 (1.202)	DT 0.001 (1.154)	loss 7.426 (7.426)	prob 2.981 (2.981)	GS 32.328 (32.328)	mem 42.261
Train: [27][225/750]	BT 0.034 (1.191)	DT 0.002 (1.144)	loss 7.364 (7.364)	prob 2.833 (2.833)	GS 28.750 (28.750)	mem 41.812
Train: [27][230/750]	BT 1.325 (1.202)	DT 1.268 (1.155)	loss 7.224 (7.224)	prob 2.813 (2.813)	GS 34.625 (34.625)	mem 42.169
Train: [27][235/750]	BT 0.087 (1.196)	DT 0.016 (1.149)	loss 8.034 (8.034)	prob 1.871 (1.871)	GS 33.812 (33.812)	mem 42.320
Train: [27][240/750]	BT 0.050 (1.204)	DT 0.006 (1.156)	loss 7.924 (7.924)	prob 3.398 (3.398)	GS 33.547 (33.547)	mem 42.902
Train: [27][245/750]	BT 0.030 (1.196)	DT 0.002 (1.148)	loss 7.144 (7.144)	prob 3.048 (3.048)	GS 29.641 (29.641)	mem 43.152
Train: [27][250/750]	BT 2.293 (1.208)	DT 2.253 (1.160)	loss 7.236 (7.236)	prob 3.323 (3.323)	GS 33.469 (33.469)	mem 41.693
Train: [27][255/750]	BT 0.040 (1.194)	DT 0.007 (1.146)	loss 7.657 (7.657)	prob 2.704 (2.704)	GS 30.203 (30.203)	mem 41.822
Train: [27][260/750]	BT 6.923 (1.198)	DT 6.888 (1.151)	loss 6.983 (6.983)	prob 3.910 (3.910)	GS 32.188 (32.188)	mem 42.164
Train: [27][265/750]	BT 0.044 (1.186)	DT 0.001 (1.138)	loss 7.269 (7.269)	prob 3.282 (3.282)	GS 29.953 (29.953)	mem 41.895
Train: [27][270/750]	BT 0.041 (1.175)	DT 0.001 (1.128)	loss 7.276 (7.276)	prob 3.124 (3.124)	GS 30.141 (30.141)	mem 41.965
Train: [27][275/750]	BT 0.052 (1.194)	DT 0.002 (1.146)	loss 7.528 (7.528)	prob 2.529 (2.529)	GS 29.484 (29.484)	mem 41.977
Train: [27][280/750]	BT 0.032 (1.188)	DT 0.002 (1.140)	loss 7.168 (7.168)	prob 3.012 (3.012)	GS 35.641 (35.641)	mem 41.841
Train: [27][285/750]	BT 0.027 (1.197)	DT 0.001 (1.149)	loss 7.445 (7.445)	prob 2.013 (2.013)	GS 30.344 (30.344)	mem 41.925
Train: [27][290/750]	BT 5.961 (1.200)	DT 5.921 (1.153)	loss 7.343 (7.343)	prob 3.657 (3.657)	GS 37.109 (37.109)	mem 41.932
Train: [27][295/750]	BT 0.051 (1.181)	DT 0.010 (1.133)	loss 7.116 (7.116)	prob 3.377 (3.377)	GS 27.875 (27.875)	mem 41.935
Train: [27][300/750]	BT 0.026 (1.186)	DT 0.001 (1.138)	loss 7.239 (7.239)	prob 3.833 (3.833)	GS 33.375 (33.375)	mem 42.013
Train: [27][305/750]	BT 0.031 (1.195)	DT 0.001 (1.148)	loss 8.009 (8.009)	prob 2.497 (2.497)	GS 29.406 (29.406)	mem 41.960
Train: [27][310/750]	BT 2.922 (1.186)	DT 2.886 (1.138)	loss 7.317 (7.317)	prob 3.701 (3.701)	GS 36.016 (36.016)	mem 41.964
Train: [27][315/750]	BT 0.074 (1.196)	DT 0.004 (1.149)	loss 7.383 (7.383)	prob 3.205 (3.205)	GS 32.281 (32.281)	mem 41.798
Train: [27][320/750]	BT 0.057 (1.179)	DT 0.001 (1.131)	loss 7.229 (7.229)	prob 3.658 (3.658)	GS 29.844 (29.844)	mem 41.800
Train: [27][325/750]	BT 0.035 (1.168)	DT 0.002 (1.120)	loss 7.765 (7.765)	prob 2.316 (2.316)	GS 27.531 (27.531)	mem 42.043
Train: [27][330/750]	BT 0.052 (1.176)	DT 0.006 (1.128)	loss 7.393 (7.393)	prob 3.151 (3.151)	GS 33.531 (33.531)	mem 41.990
Train: [27][335/750]	BT 0.049 (1.175)	DT 0.009 (1.128)	loss 7.619 (7.619)	prob 2.267 (2.267)	GS 30.516 (30.516)	mem 41.772
Train: [27][340/750]	BT 0.030 (1.181)	DT 0.002 (1.134)	loss 7.278 (7.278)	prob 3.082 (3.082)	GS 31.391 (31.391)	mem 41.871
Train: [27][345/750]	BT 0.033 (1.166)	DT 0.002 (1.119)	loss 7.201 (7.201)	prob 3.285 (3.285)	GS 28.844 (28.844)	mem 41.874
Train: [27][350/750]	BT 5.558 (1.178)	DT 5.522 (1.131)	loss 7.222 (7.222)	prob 3.285 (3.285)	GS 30.750 (30.750)	mem 40.081
Train: [27][355/750]	BT 0.037 (1.162)	DT 0.001 (1.115)	loss 7.652 (7.652)	prob 2.641 (2.641)	GS 30.312 (30.312)	mem 40.079
Train: [27][360/750]	BT 0.057 (1.165)	DT 0.009 (1.118)	loss 6.973 (6.973)	prob 3.064 (3.064)	GS 34.297 (34.297)	mem 40.207
Train: [27][365/750]	BT 0.048 (1.172)	DT 0.008 (1.125)	loss 7.423 (7.423)	prob 3.187 (3.187)	GS 31.188 (31.188)	mem 40.076
Train: [27][370/750]	BT 1.589 (1.163)	DT 1.560 (1.116)	loss 7.221 (7.221)	prob 3.471 (3.471)	GS 34.688 (34.688)	mem 40.449
Train: [27][375/750]	BT 0.023 (1.176)	DT 0.001 (1.129)	loss 7.516 (7.516)	prob 2.294 (2.294)	GS 33.297 (33.297)	mem 40.277
Train: [27][380/750]	BT 2.501 (1.168)	DT 2.468 (1.120)	loss 6.953 (6.953)	prob 3.360 (3.360)	GS 34.547 (34.547)	mem 40.296
Train: [27][385/750]	BT 0.038 (1.153)	DT 0.006 (1.106)	loss 7.910 (7.910)	prob 1.900 (1.900)	GS 29.750 (29.750)	mem 40.295
Train: [27][390/750]	BT 0.050 (1.152)	DT 0.010 (1.105)	loss 7.351 (7.351)	prob 3.412 (3.412)	GS 37.250 (37.250)	mem 40.415
Train: [27][395/750]	BT 0.058 (1.157)	DT 0.027 (1.110)	loss 7.082 (7.082)	prob 3.304 (3.304)	GS 33.625 (33.625)	mem 40.460
Train: [27][400/750]	BT 0.033 (1.166)	DT 0.002 (1.119)	loss 7.579 (7.579)	prob 3.334 (3.334)	GS 33.266 (33.266)	mem 40.591
Train: [27][405/750]	BT 0.041 (1.160)	DT 0.002 (1.114)	loss 7.689 (7.689)	prob 2.763 (2.763)	GS 31.578 (31.578)	mem 40.662
Train: [27][410/750]	BT 7.241 (1.174)	DT 7.199 (1.127)	loss 7.537 (7.537)	prob 3.344 (3.344)	GS 34.594 (34.594)	mem 40.629
Train: [27][415/750]	BT 0.031 (1.160)	DT 0.001 (1.113)	loss 7.475 (7.475)	prob 3.044 (3.044)	GS 30.797 (30.797)	mem 40.628
Train: [27][420/750]	BT 0.055 (1.159)	DT 0.021 (1.112)	loss 7.187 (7.187)	prob 3.375 (3.375)	GS 34.578 (34.578)	mem 40.641
Train: [27][425/750]	BT 0.038 (1.173)	DT 0.002 (1.126)	loss 7.611 (7.611)	prob 2.391 (2.391)	GS 29.766 (29.766)	mem 40.638
Train: [27][430/750]	BT 3.169 (1.167)	DT 3.136 (1.120)	loss 7.605 (7.605)	prob 2.736 (2.736)	GS 44.047 (44.047)	mem 40.696
Train: [27][435/750]	BT 0.041 (1.176)	DT 0.005 (1.130)	loss 7.486 (7.486)	prob 2.865 (2.865)	GS 34.516 (34.516)	mem 40.248
Train: [27][440/750]	BT 0.134 (1.164)	DT 0.003 (1.117)	loss 7.550 (7.550)	prob 3.110 (3.110)	GS 35.688 (35.688)	mem 40.301
Train: [27][445/750]	BT 0.034 (1.151)	DT 0.001 (1.105)	loss 8.250 (8.250)	prob 1.518 (1.518)	GS 31.375 (31.375)	mem 40.362
Train: [27][450/750]	BT 0.039 (1.161)	DT 0.001 (1.115)	loss 7.054 (7.054)	prob 3.637 (3.637)	GS 27.391 (27.391)	mem 40.242
Train: [27][455/750]	BT 0.025 (1.151)	DT 0.001 (1.105)	loss 7.249 (7.249)	prob 3.139 (3.139)	GS 27.156 (27.156)	mem 40.214
Train: [27][460/750]	BT 0.033 (1.159)	DT 0.002 (1.113)	loss 7.445 (7.445)	prob 3.565 (3.565)	GS 33.891 (33.891)	mem 40.137
Train: [27][465/750]	BT 0.035 (1.147)	DT 0.002 (1.101)	loss 7.653 (7.653)	prob 2.621 (2.621)	GS 31.359 (31.359)	mem 40.170
Train: [27][470/750]	BT 13.472 (1.168)	DT 13.439 (1.122)	loss 7.574 (7.574)	prob 3.184 (3.184)	GS 34.000 (34.000)	mem 40.163
Train: [27][475/750]	BT 0.031 (1.157)	DT 0.002 (1.110)	loss 7.078 (7.078)	prob 3.048 (3.048)	GS 32.703 (32.703)	mem 40.091
Train: [27][480/750]	BT 0.051 (1.145)	DT 0.011 (1.099)	loss 7.150 (7.150)	prob 3.578 (3.578)	GS 33.719 (33.719)	mem 40.092
Train: [27][485/750]	BT 0.023 (1.162)	DT 0.001 (1.116)	loss 7.096 (7.096)	prob 2.433 (2.433)	GS 28.109 (28.109)	mem 40.171
Train: [27][490/750]	BT 0.031 (1.150)	DT 0.001 (1.105)	loss 7.103 (7.103)	prob 3.486 (3.486)	GS 32.734 (32.734)	mem 40.171
Train: [27][495/750]	BT 0.034 (1.160)	DT 0.002 (1.114)	loss 6.929 (6.929)	prob 2.713 (2.713)	GS 28.875 (28.875)	mem 40.119
Train: [27][500/750]	BT 0.133 (1.149)	DT 0.052 (1.103)	loss 7.424 (7.424)	prob 2.524 (2.524)	GS 37.703 (37.703)	mem 40.150
Train: [27][505/750]	BT 0.074 (1.139)	DT 0.005 (1.093)	loss 7.184 (7.184)	prob 3.169 (3.169)	GS 33.328 (33.328)	mem 40.256
Train: [27][510/750]	BT 0.033 (1.151)	DT 0.002 (1.105)	loss 6.841 (6.841)	prob 2.814 (2.814)	GS 28.781 (28.781)	mem 40.239
Train: [27][515/750]	BT 0.033 (1.141)	DT 0.002 (1.095)	loss 7.228 (7.228)	prob 2.670 (2.670)	GS 31.547 (31.547)	mem 40.282
Train: [27][520/750]	BT 0.038 (1.152)	DT 0.002 (1.106)	loss 7.419 (7.419)	prob 3.071 (3.071)	GS 37.062 (37.062)	mem 41.496
Train: [27][525/750]	BT 0.045 (1.142)	DT 0.006 (1.096)	loss 7.326 (7.326)	prob 2.866 (2.866)	GS 31.578 (31.578)	mem 41.561
Train: [27][530/750]	BT 12.430 (1.155)	DT 12.394 (1.109)	loss 7.035 (7.035)	prob 3.098 (3.098)	GS 29.859 (29.859)	mem 41.842
Train: [27][535/750]	BT 0.057 (1.145)	DT 0.004 (1.098)	loss 7.599 (7.599)	prob 2.717 (2.717)	GS 34.266 (34.266)	mem 41.877
Train: [27][540/750]	BT 0.056 (1.135)	DT 0.020 (1.088)	loss 7.188 (7.188)	prob 3.104 (3.104)	GS 33.578 (33.578)	mem 41.706
Train: [27][545/750]	BT 0.074 (1.146)	DT 0.003 (1.100)	loss 6.929 (6.929)	prob 3.235 (3.235)	GS 31.531 (31.531)	mem 40.317
Train: [27][550/750]	BT 0.034 (1.136)	DT 0.004 (1.090)	loss 6.970 (6.970)	prob 2.703 (2.703)	GS 31.406 (31.406)	mem 40.176
Train: [27][555/750]	BT 0.039 (1.151)	DT 0.003 (1.105)	loss 7.403 (7.403)	prob 2.203 (2.203)	GS 31.406 (31.406)	mem 40.172
Train: [27][560/750]	BT 0.029 (1.142)	DT 0.001 (1.095)	loss 7.354 (7.354)	prob 3.017 (3.017)	GS 31.500 (31.500)	mem 40.173
Train: [27][565/750]	BT 0.031 (1.132)	DT 0.001 (1.086)	loss 6.886 (6.886)	prob 2.476 (2.476)	GS 30.969 (30.969)	mem 40.174
Train: [27][570/750]	BT 0.032 (1.143)	DT 0.001 (1.097)	loss 7.157 (7.157)	prob 2.928 (2.928)	GS 29.500 (29.500)	mem 40.223
Train: [27][575/750]	BT 0.033 (1.140)	DT 0.001 (1.094)	loss 7.315 (7.315)	prob 2.360 (2.360)	GS 33.359 (33.359)	mem 40.246
Train: [27][580/750]	BT 0.062 (1.147)	DT 0.008 (1.101)	loss 6.921 (6.921)	prob 2.743 (2.743)	GS 33.250 (33.250)	mem 40.858
Train: [27][585/750]	BT 0.028 (1.138)	DT 0.001 (1.092)	loss 7.379 (7.379)	prob 2.463 (2.463)	GS 26.969 (26.969)	mem 40.907
Train: [27][590/750]	BT 6.462 (1.149)	DT 6.403 (1.104)	loss 6.884 (6.884)	prob 3.068 (3.068)	GS 31.188 (31.188)	mem 40.820
Train: [27][595/750]	BT 0.047 (1.140)	DT 0.002 (1.094)	loss 7.174 (7.174)	prob 2.822 (2.822)	GS 29.625 (29.625)	mem 40.728
Train: [27][600/750]	BT 0.074 (1.154)	DT 0.011 (1.108)	loss 7.188 (7.188)	prob 3.170 (3.170)	GS 34.906 (34.906)	mem 40.699
Train: [27][605/750]	BT 0.026 (1.145)	DT 0.003 (1.099)	loss 7.070 (7.070)	prob 2.980 (2.980)	GS 27.672 (27.672)	mem 40.698
Train: [27][610/750]	BT 13.415 (1.157)	DT 13.370 (1.112)	loss 7.041 (7.041)	prob 3.183 (3.183)	GS 37.359 (37.359)	mem 40.809
Train: [27][615/750]	BT 0.081 (1.148)	DT 0.008 (1.103)	loss 7.265 (7.265)	prob 2.401 (2.401)	GS 32.281 (32.281)	mem 40.871
Train: [27][620/750]	BT 0.046 (1.139)	DT 0.004 (1.094)	loss 7.385 (7.385)	prob 2.822 (2.822)	GS 35.141 (35.141)	mem 40.771
Train: [27][625/750]	BT 0.020 (1.156)	DT 0.001 (1.111)	loss 7.417 (7.417)	prob 2.345 (2.345)	GS 33.094 (33.094)	mem 40.012
Train: [27][630/750]	BT 0.030 (1.147)	DT 0.001 (1.102)	loss 7.265 (7.265)	prob 3.252 (3.252)	GS 30.562 (30.562)	mem 40.067
Train: [27][635/750]	BT 0.030 (1.158)	DT 0.010 (1.113)	loss 7.426 (7.426)	prob 2.102 (2.102)	GS 35.969 (35.969)	mem 40.028
Train: [27][640/750]	BT 0.023 (1.150)	DT 0.001 (1.105)	loss 6.989 (6.989)	prob 2.996 (2.996)	GS 32.141 (32.141)	mem 40.028
Train: [27][645/750]	BT 0.078 (1.141)	DT 0.010 (1.096)	loss 7.287 (7.287)	prob 2.816 (2.816)	GS 31.969 (31.969)	mem 40.029
Train: [27][650/750]	BT 0.028 (1.154)	DT 0.001 (1.109)	loss 7.241 (7.241)	prob 2.966 (2.966)	GS 29.328 (29.328)	mem 40.060
Train: [27][655/750]	BT 0.062 (1.146)	DT 0.004 (1.101)	loss 6.987 (6.987)	prob 2.476 (2.476)	GS 31.641 (31.641)	mem 40.063
arpack error, retry= 0
Train: [27][660/750]	BT 0.032 (1.158)	DT 0.002 (1.113)	loss 7.142 (7.142)	prob 2.332 (2.332)	GS 30.031 (30.031)	mem 40.137
Train: [27][665/750]	BT 0.027 (1.149)	DT 0.001 (1.105)	loss 6.856 (6.856)	prob 2.841 (2.841)	GS 31.875 (31.875)	mem 40.077
Train: [27][670/750]	BT 11.646 (1.158)	DT 11.614 (1.114)	loss 6.946 (6.946)	prob 3.034 (3.034)	GS 33.359 (33.359)	mem 40.109
Train: [27][675/750]	BT 0.031 (1.150)	DT 0.001 (1.105)	loss 7.424 (7.424)	prob 2.134 (2.134)	GS 32.375 (32.375)	mem 40.108
Train: [27][680/750]	BT 0.030 (1.142)	DT 0.001 (1.097)	loss 7.131 (7.131)	prob 3.052 (3.052)	GS 35.438 (35.438)	mem 40.108
Train: [27][685/750]	BT 0.022 (1.153)	DT 0.001 (1.109)	loss 7.530 (7.530)	prob 2.256 (2.256)	GS 30.531 (30.531)	mem 40.162
Train: [27][690/750]	BT 0.032 (1.145)	DT 0.001 (1.101)	loss 7.178 (7.178)	prob 2.246 (2.246)	GS 31.828 (31.828)	mem 40.162
Train: [27][695/750]	BT 0.034 (1.155)	DT 0.001 (1.111)	loss 7.309 (7.309)	prob 2.473 (2.473)	GS 34.000 (34.000)	mem 40.152
Train: [27][700/750]	BT 0.054 (1.147)	DT 0.011 (1.103)	loss 6.929 (6.929)	prob 2.993 (2.993)	GS 35.703 (35.703)	mem 40.115
Train: [27][705/750]	BT 0.046 (1.139)	DT 0.002 (1.095)	loss 7.341 (7.341)	prob 2.681 (2.681)	GS 36.297 (36.297)	mem 40.108
Train: [27][710/750]	BT 0.062 (1.147)	DT 0.001 (1.103)	loss 7.937 (7.937)	prob 1.934 (1.934)	GS 35.266 (35.266)	mem 40.103
Train: [27][715/750]	BT 0.029 (1.139)	DT 0.001 (1.095)	loss 7.017 (7.017)	prob 2.617 (2.617)	GS 31.891 (31.891)	mem 40.103
Train: [27][720/750]	BT 0.023 (1.147)	DT 0.001 (1.103)	loss 6.899 (6.899)	prob 3.256 (3.256)	GS 31.484 (31.484)	mem 40.118
Train: [27][725/750]	BT 0.033 (1.140)	DT 0.002 (1.096)	loss 7.166 (7.166)	prob 2.320 (2.320)	GS 31.250 (31.250)	mem 40.057
Train: [27][730/750]	BT 10.436 (1.147)	DT 10.392 (1.103)	loss 6.962 (6.962)	prob 2.922 (2.922)	GS 30.625 (30.625)	mem 39.729
Train: [27][735/750]	BT 0.039 (1.140)	DT 0.001 (1.096)	loss 7.014 (7.014)	prob 2.813 (2.813)	GS 36.422 (36.422)	mem 36.901
Train: [27][740/750]	BT 0.038 (1.133)	DT 0.001 (1.089)	loss 6.945 (6.945)	prob 2.349 (2.349)	GS 33.625 (33.625)	mem 36.900
Train: [27][745/750]	BT 0.019 (1.134)	DT 0.001 (1.090)	loss 6.952 (6.952)	prob 2.833 (2.833)	GS 29.094 (29.094)	mem 7.840
Train: [27][750/750]	BT 0.019 (1.127)	DT 0.001 (1.083)	loss 7.170 (7.170)	prob 1.941 (1.941)	GS 39.688 (39.688)	mem 7.824
Train: [27][755/750]	BT 0.040 (1.122)	DT 0.001 (1.079)	loss 7.693 (7.693)	prob 2.004 (2.004)	GS 31.500 (31.500)	mem 7.791
epoch 27, total time 847.66
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [28][1/750]	BT 19.632 (19.632)	DT 19.586 (19.586)	loss 6.955 (6.955)	prob 2.117 (2.117)	GS 30.969 (30.969)	mem 38.696
Train: [28][5/750]	BT 0.127 (4.914)	DT 0.002 (4.856)	loss 6.950 (6.950)	prob 2.809 (2.809)	GS 25.641 (25.641)	mem 39.164
Train: [28][10/750]	BT 0.039 (2.494)	DT 0.002 (2.431)	loss 6.968 (6.968)	prob 2.806 (2.806)	GS 33.250 (33.250)	mem 38.972
Train: [28][15/750]	BT 0.069 (2.844)	DT 0.028 (2.784)	loss 6.977 (6.977)	prob 2.303 (2.303)	GS 29.406 (29.406)	mem 39.637
Train: [28][20/750]	BT 0.023 (2.141)	DT 0.001 (2.089)	loss 7.201 (7.201)	prob 2.422 (2.422)	GS 35.453 (35.453)	mem 39.600
Train: [28][25/750]	BT 0.026 (1.719)	DT 0.001 (1.671)	loss 6.842 (6.842)	prob 2.910 (2.910)	GS 27.453 (27.453)	mem 39.602
Train: [28][30/750]	BT 0.082 (1.956)	DT 0.003 (1.909)	loss 7.099 (7.099)	prob 2.332 (2.332)	GS 33.438 (33.438)	mem 39.807
Train: [28][35/750]	BT 0.091 (1.685)	DT 0.001 (1.637)	loss 7.132 (7.132)	prob 2.381 (2.381)	GS 28.641 (28.641)	mem 39.974
Train: [28][40/750]	BT 0.022 (1.832)	DT 0.001 (1.785)	loss 6.816 (6.816)	prob 2.703 (2.703)	GS 36.703 (36.703)	mem 39.761
Train: [28][45/750]	BT 0.100 (1.633)	DT 0.007 (1.587)	loss 7.022 (7.022)	prob 2.263 (2.263)	GS 34.484 (34.484)	mem 39.761
Train: [28][50/750]	BT 12.267 (1.718)	DT 12.208 (1.673)	loss 7.103 (7.103)	prob 2.477 (2.477)	GS 29.469 (29.469)	mem 39.846
Train: [28][55/750]	BT 0.041 (1.565)	DT 0.001 (1.521)	loss 6.987 (6.987)	prob 2.582 (2.582)	GS 33.328 (33.328)	mem 39.869
Train: [28][60/750]	BT 0.034 (1.439)	DT 0.002 (1.394)	loss 6.988 (6.988)	prob 2.420 (2.420)	GS 34.484 (34.484)	mem 39.820
Train: [28][65/750]	BT 0.035 (1.549)	DT 0.002 (1.505)	loss 6.764 (6.764)	prob 2.640 (2.640)	GS 29.734 (29.734)	mem 39.829
Train: [28][70/750]	BT 0.032 (1.442)	DT 0.001 (1.398)	loss 6.942 (6.942)	prob 2.554 (2.554)	GS 32.000 (32.000)	mem 39.838
Train: [28][75/750]	BT 0.031 (1.536)	DT 0.001 (1.493)	loss 6.869 (6.869)	prob 2.563 (2.563)	GS 31.453 (31.453)	mem 39.885
Train: [28][80/750]	BT 0.026 (1.443)	DT 0.002 (1.400)	loss 6.942 (6.942)	prob 2.224 (2.224)	GS 32.922 (32.922)	mem 39.853
Train: [28][85/750]	BT 0.108 (1.362)	DT 0.021 (1.318)	loss 6.877 (6.877)	prob 2.750 (2.750)	GS 32.891 (32.891)	mem 40.026
Train: [28][90/750]	BT 0.127 (1.437)	DT 0.002 (1.392)	loss 6.879 (6.879)	prob 2.787 (2.787)	GS 33.750 (33.750)	mem 39.849
Train: [28][95/750]	BT 0.065 (1.364)	DT 0.010 (1.319)	loss 6.846 (6.846)	prob 2.650 (2.650)	GS 30.094 (30.094)	mem 39.857
Train: [28][100/750]	BT 0.038 (1.428)	DT 0.001 (1.384)	loss 6.989 (6.989)	prob 2.404 (2.404)	GS 31.203 (31.203)	mem 39.919
Train: [28][105/750]	BT 0.030 (1.362)	DT 0.001 (1.318)	loss 6.847 (6.847)	prob 1.857 (1.857)	GS 26.062 (26.062)	mem 39.922
Train: [28][110/750]	BT 11.714 (1.408)	DT 11.640 (1.364)	loss 6.953 (6.953)	prob 1.905 (1.905)	GS 33.984 (33.984)	mem 40.088
Train: [28][115/750]	BT 0.026 (1.349)	DT 0.001 (1.305)	loss 7.024 (7.024)	prob 2.617 (2.617)	GS 31.250 (31.250)	mem 40.090
Train: [28][120/750]	BT 0.033 (1.295)	DT 0.002 (1.251)	loss 6.901 (6.901)	prob 2.091 (2.091)	GS 28.375 (28.375)	mem 40.090
Train: [28][125/750]	BT 0.042 (1.353)	DT 0.002 (1.309)	loss 7.147 (7.147)	prob 1.719 (1.719)	GS 28.781 (28.781)	mem 40.415
Train: [28][130/750]	BT 0.023 (1.303)	DT 0.001 (1.259)	loss 6.916 (6.916)	prob 2.412 (2.412)	GS 29.781 (29.781)	mem 40.301
Train: [28][135/750]	BT 0.058 (1.349)	DT 0.002 (1.304)	loss 6.994 (6.994)	prob 1.965 (1.965)	GS 34.969 (34.969)	mem 40.483
Train: [28][140/750]	BT 0.031 (1.302)	DT 0.001 (1.258)	loss 7.608 (7.608)	prob 1.618 (1.618)	GS 34.953 (34.953)	mem 40.439
Train: [28][145/750]	BT 0.033 (1.258)	DT 0.002 (1.215)	loss 6.988 (6.988)	prob 2.110 (2.110)	GS 30.141 (30.141)	mem 40.502
Train: [28][150/750]	BT 0.023 (1.300)	DT 0.001 (1.257)	loss 7.320 (7.320)	prob 1.483 (1.483)	GS 30.578 (30.578)	mem 40.533
Train: [28][155/750]	BT 0.079 (1.266)	DT 0.002 (1.222)	loss 7.111 (7.111)	prob 1.984 (1.984)	GS 30.219 (30.219)	mem 40.606
Train: [28][160/750]	BT 0.071 (1.308)	DT 0.028 (1.263)	loss 6.946 (6.946)	prob 1.904 (1.904)	GS 36.188 (36.188)	mem 40.605
Train: [28][165/750]	BT 0.144 (1.270)	DT 0.005 (1.225)	loss 6.722 (6.722)	prob 1.806 (1.806)	GS 30.500 (30.500)	mem 40.661
Train: [28][170/750]	BT 14.748 (1.322)	DT 14.709 (1.276)	loss 6.988 (6.988)	prob 1.793 (1.793)	GS 31.672 (31.672)	mem 40.001
Train: [28][175/750]	BT 0.072 (1.286)	DT 0.001 (1.239)	loss 7.345 (7.345)	prob 1.267 (1.267)	GS 31.031 (31.031)	mem 40.154
Train: [28][180/750]	BT 0.062 (1.252)	DT 0.012 (1.205)	loss 7.490 (7.490)	prob 1.357 (1.357)	GS 33.391 (33.391)	mem 40.050
Train: [28][185/750]	BT 0.029 (1.295)	DT 0.001 (1.249)	loss 6.971 (6.971)	prob 1.466 (1.466)	GS 29.156 (29.156)	mem 40.206
Train: [28][190/750]	BT 0.057 (1.262)	DT 0.006 (1.216)	loss 7.043 (7.043)	prob 1.243 (1.243)	GS 36.125 (36.125)	mem 40.224
Train: [28][195/750]	BT 0.066 (1.278)	DT 0.011 (1.232)	loss 6.917 (6.917)	prob 1.505 (1.505)	GS 30.781 (30.781)	mem 41.867
Train: [28][200/750]	BT 0.036 (1.247)	DT 0.002 (1.201)	loss 7.136 (7.136)	prob 2.024 (2.024)	GS 34.578 (34.578)	mem 42.265
Train: [28][205/750]	BT 0.037 (1.218)	DT 0.003 (1.172)	loss 7.541 (7.541)	prob 0.487 (0.487)	GS 29.078 (29.078)	mem 42.109
Train: [28][210/750]	BT 0.035 (1.263)	DT 0.012 (1.217)	loss 6.958 (6.958)	prob 1.976 (1.976)	GS 33.719 (33.719)	mem 41.799
Train: [28][215/750]	BT 0.044 (1.234)	DT 0.001 (1.189)	loss 7.219 (7.219)	prob 1.753 (1.753)	GS 32.203 (32.203)	mem 41.801
Train: [28][220/750]	BT 0.031 (1.273)	DT 0.001 (1.228)	loss 7.494 (7.494)	prob 1.413 (1.413)	GS 33.797 (33.797)	mem 41.788
Train: [28][225/750]	BT 0.037 (1.246)	DT 0.001 (1.201)	loss 7.259 (7.259)	prob 1.024 (1.024)	GS 28.047 (28.047)	mem 41.790
Train: [28][230/750]	BT 13.682 (1.279)	DT 13.620 (1.234)	loss 8.111 (8.111)	prob 0.901 (0.901)	GS 30.141 (30.141)	mem 41.805
Train: [28][235/750]	BT 0.027 (1.253)	DT 0.001 (1.208)	loss 7.761 (7.761)	prob 1.374 (1.374)	GS 33.719 (33.719)	mem 41.771
Train: [28][240/750]	BT 0.045 (1.228)	DT 0.002 (1.183)	loss 7.654 (7.654)	prob 2.133 (2.133)	GS 36.578 (36.578)	mem 41.761
Train: [28][245/750]	BT 0.028 (1.256)	DT 0.001 (1.211)	loss 7.006 (7.006)	prob 1.928 (1.928)	GS 29.375 (29.375)	mem 40.589
Train: [28][250/750]	BT 0.045 (1.232)	DT 0.003 (1.187)	loss 7.448 (7.448)	prob 2.107 (2.107)	GS 30.438 (30.438)	mem 40.601
Train: [28][255/750]	BT 0.128 (1.252)	DT 0.002 (1.207)	loss 7.163 (7.163)	prob 1.441 (1.441)	GS 32.031 (32.031)	mem 41.656
Train: [28][260/750]	BT 0.085 (1.229)	DT 0.002 (1.184)	loss 7.278 (7.278)	prob 1.582 (1.582)	GS 31.906 (31.906)	mem 41.702
Train: [28][265/750]	BT 0.051 (1.207)	DT 0.012 (1.162)	loss 7.372 (7.372)	prob 1.608 (1.608)	GS 28.641 (28.641)	mem 41.669
Train: [28][270/750]	BT 0.067 (1.230)	DT 0.008 (1.185)	loss 7.552 (7.552)	prob 2.036 (2.036)	GS 38.766 (38.766)	mem 40.028
Train: [28][275/750]	BT 0.055 (1.209)	DT 0.012 (1.164)	loss 7.497 (7.497)	prob 1.902 (1.902)	GS 36.422 (36.422)	mem 40.044
Train: [28][280/750]	BT 0.024 (1.241)	DT 0.001 (1.197)	loss 7.298 (7.298)	prob 2.492 (2.492)	GS 31.406 (31.406)	mem 40.145
Train: [28][285/750]	BT 0.062 (1.221)	DT 0.015 (1.176)	loss 8.442 (8.442)	prob 1.175 (1.175)	GS 38.172 (38.172)	mem 40.146
Train: [28][290/750]	BT 11.964 (1.241)	DT 11.890 (1.197)	loss 7.598 (7.598)	prob 1.955 (1.955)	GS 33.578 (33.578)	mem 40.157
Train: [28][295/750]	BT 0.035 (1.221)	DT 0.010 (1.176)	loss 7.499 (7.499)	prob 2.240 (2.240)	GS 27.000 (27.000)	mem 40.157
Train: [28][300/750]	BT 0.150 (1.201)	DT 0.001 (1.157)	loss 7.594 (7.594)	prob 3.039 (3.039)	GS 33.734 (33.734)	mem 40.227
Train: [28][305/750]	BT 0.032 (1.221)	DT 0.002 (1.177)	loss 7.620 (7.620)	prob 1.939 (1.939)	GS 29.531 (29.531)	mem 40.202
Train: [28][310/750]	BT 0.093 (1.202)	DT 0.025 (1.158)	loss 7.389 (7.389)	prob 2.066 (2.066)	GS 33.391 (33.391)	mem 40.242
Train: [28][315/750]	BT 0.097 (1.218)	DT 0.018 (1.173)	loss 7.891 (7.891)	prob 1.327 (1.327)	GS 30.688 (30.688)	mem 40.230
Train: [28][320/750]	BT 0.033 (1.200)	DT 0.001 (1.155)	loss 7.652 (7.652)	prob 2.868 (2.868)	GS 31.094 (31.094)	mem 40.245
Train: [28][325/750]	BT 0.103 (1.183)	DT 0.008 (1.137)	loss 7.495 (7.495)	prob 2.763 (2.763)	GS 29.172 (29.172)	mem 40.220
Train: [28][330/750]	BT 0.051 (1.206)	DT 0.016 (1.160)	loss 7.630 (7.630)	prob 2.433 (2.433)	GS 34.938 (34.938)	mem 40.206
Train: [28][335/750]	BT 0.038 (1.188)	DT 0.005 (1.143)	loss 7.617 (7.617)	prob 2.732 (2.732)	GS 32.922 (32.922)	mem 40.413
Train: [28][340/750]	BT 1.133 (1.205)	DT 1.099 (1.160)	loss 7.633 (7.633)	prob 3.406 (3.406)	GS 31.875 (31.875)	mem 40.204
Train: [28][345/750]	BT 0.112 (1.188)	DT 0.027 (1.143)	loss 7.285 (7.285)	prob 2.540 (2.540)	GS 29.625 (29.625)	mem 40.150
Train: [28][350/750]	BT 9.874 (1.200)	DT 9.835 (1.155)	loss 7.682 (7.682)	prob 2.811 (2.811)	GS 28.891 (28.891)	mem 40.208
Train: [28][355/750]	BT 0.028 (1.184)	DT 0.001 (1.139)	loss 7.069 (7.069)	prob 3.333 (3.333)	GS 29.875 (29.875)	mem 40.345
Train: [28][360/750]	BT 2.659 (1.176)	DT 2.613 (1.130)	loss 7.750 (7.750)	prob 2.112 (2.112)	GS 32.156 (32.156)	mem 40.268
Train: [28][365/750]	BT 0.029 (1.201)	DT 0.002 (1.156)	loss 8.275 (8.275)	prob 1.208 (1.208)	GS 37.000 (37.000)	mem 40.200
Train: [28][370/750]	BT 0.080 (1.185)	DT 0.012 (1.140)	loss 7.489 (7.489)	prob 2.114 (2.114)	GS 35.641 (35.641)	mem 40.202
Train: [28][375/750]	BT 0.032 (1.204)	DT 0.001 (1.159)	loss 7.853 (7.853)	prob 1.910 (1.910)	GS 29.469 (29.469)	mem 40.151
Train: [28][380/750]	BT 0.020 (1.189)	DT 0.001 (1.144)	loss 7.450 (7.450)	prob 3.305 (3.305)	GS 33.219 (33.219)	mem 40.142
Train: [28][385/750]	BT 0.065 (1.174)	DT 0.011 (1.129)	loss 7.487 (7.487)	prob 2.946 (2.946)	GS 32.859 (32.859)	mem 40.142
Train: [28][390/750]	BT 0.068 (1.187)	DT 0.002 (1.142)	loss 7.573 (7.573)	prob 2.924 (2.924)	GS 35.781 (35.781)	mem 40.155
Train: [28][395/750]	BT 0.045 (1.173)	DT 0.002 (1.128)	loss 7.208 (7.208)	prob 2.795 (2.795)	GS 30.328 (30.328)	mem 40.215
Train: [28][400/750]	BT 0.038 (1.194)	DT 0.002 (1.149)	loss 7.921 (7.921)	prob 3.140 (3.140)	GS 34.344 (34.344)	mem 40.280
Train: [28][405/750]	BT 0.064 (1.180)	DT 0.010 (1.135)	loss 7.777 (7.777)	prob 2.132 (2.132)	GS 36.375 (36.375)	mem 40.336
Train: [28][410/750]	BT 14.743 (1.202)	DT 14.701 (1.157)	loss 7.144 (7.144)	prob 2.792 (2.792)	GS 35.969 (35.969)	mem 40.188
Train: [28][415/750]	BT 0.025 (1.188)	DT 0.001 (1.143)	loss 7.501 (7.501)	prob 3.236 (3.236)	GS 32.250 (32.250)	mem 40.190
Train: [28][420/750]	BT 0.064 (1.175)	DT 0.004 (1.130)	loss 7.863 (7.863)	prob 3.062 (3.062)	GS 38.875 (38.875)	mem 40.190
Train: [28][425/750]	BT 0.031 (1.193)	DT 0.001 (1.148)	loss 7.663 (7.663)	prob 2.954 (2.954)	GS 32.656 (32.656)	mem 40.144
Train: [28][430/750]	BT 0.042 (1.180)	DT 0.002 (1.135)	loss 7.564 (7.564)	prob 3.215 (3.215)	GS 34.406 (34.406)	mem 40.145
Train: [28][435/750]	BT 0.029 (1.197)	DT 0.001 (1.151)	loss 7.458 (7.458)	prob 3.341 (3.341)	GS 33.516 (33.516)	mem 40.132
Train: [28][440/750]	BT 0.054 (1.183)	DT 0.002 (1.138)	loss 8.541 (8.541)	prob 3.031 (3.031)	GS 34.969 (34.969)	mem 40.134
Train: [28][445/750]	BT 0.065 (1.171)	DT 0.007 (1.126)	loss 7.698 (7.698)	prob 2.939 (2.939)	GS 32.234 (32.234)	mem 40.137
Train: [28][450/750]	BT 0.030 (1.188)	DT 0.001 (1.143)	loss 7.523 (7.523)	prob 3.384 (3.384)	GS 37.672 (37.672)	mem 40.188
Train: [28][455/750]	BT 0.031 (1.175)	DT 0.001 (1.130)	loss 7.288 (7.288)	prob 3.816 (3.816)	GS 30.594 (30.594)	mem 40.190
Train: [28][460/750]	BT 0.034 (1.197)	DT 0.002 (1.152)	loss 7.556 (7.556)	prob 2.816 (2.816)	GS 32.281 (32.281)	mem 40.059
Train: [28][465/750]	BT 0.034 (1.184)	DT 0.001 (1.139)	loss 7.500 (7.500)	prob 3.620 (3.620)	GS 27.797 (27.797)	mem 40.060
Train: [28][470/750]	BT 10.998 (1.195)	DT 10.942 (1.151)	loss 8.195 (8.195)	prob 3.929 (3.929)	GS 32.109 (32.109)	mem 40.168
Train: [28][475/750]	BT 0.034 (1.183)	DT 0.001 (1.139)	loss 7.489 (7.489)	prob 3.630 (3.630)	GS 26.547 (26.547)	mem 40.291
Train: [28][480/750]	BT 0.092 (1.172)	DT 0.014 (1.127)	loss 6.901 (6.901)	prob 4.195 (4.195)	GS 33.953 (33.953)	mem 40.114
Train: [28][485/750]	BT 0.020 (1.187)	DT 0.001 (1.142)	loss 7.765 (7.765)	prob 2.852 (2.852)	GS 29.469 (29.469)	mem 40.083
Train: [28][490/750]	BT 0.039 (1.175)	DT 0.002 (1.131)	loss 7.775 (7.775)	prob 3.719 (3.719)	GS 29.844 (29.844)	mem 40.086
Train: [28][495/750]	BT 0.033 (1.189)	DT 0.002 (1.144)	loss 7.552 (7.552)	prob 3.343 (3.343)	GS 32.047 (32.047)	mem 40.179
Train: [28][500/750]	BT 0.041 (1.177)	DT 0.001 (1.133)	loss 7.598 (7.598)	prob 4.104 (4.104)	GS 30.312 (30.312)	mem 40.254
Train: [28][505/750]	BT 0.068 (1.166)	DT 0.003 (1.122)	loss 7.914 (7.914)	prob 2.979 (2.979)	GS 35.406 (35.406)	mem 40.222
Train: [28][510/750]	BT 0.040 (1.182)	DT 0.009 (1.137)	loss 7.368 (7.368)	prob 3.652 (3.652)	GS 33.047 (33.047)	mem 40.219
Train: [28][515/750]	BT 0.021 (1.171)	DT 0.001 (1.126)	loss 7.290 (7.290)	prob 3.947 (3.947)	GS 30.094 (30.094)	mem 40.148
Train: [28][520/750]	BT 0.052 (1.182)	DT 0.002 (1.138)	loss 7.849 (7.849)	prob 3.922 (3.922)	GS 35.672 (35.672)	mem 40.353
Train: [28][525/750]	BT 0.085 (1.172)	DT 0.025 (1.127)	loss 7.486 (7.486)	prob 3.216 (3.216)	GS 28.109 (28.109)	mem 40.268
Train: [28][530/750]	BT 11.425 (1.183)	DT 11.384 (1.138)	loss 7.686 (7.686)	prob 2.651 (2.651)	GS 31.625 (31.625)	mem 40.186
Train: [28][535/750]	BT 0.107 (1.172)	DT 0.005 (1.127)	loss 8.441 (8.441)	prob 3.147 (3.147)	GS 28.141 (28.141)	mem 40.194
Train: [28][540/750]	BT 0.037 (1.162)	DT 0.001 (1.117)	loss 7.241 (7.241)	prob 4.202 (4.202)	GS 33.609 (33.609)	mem 40.212
Train: [28][545/750]	BT 0.053 (1.174)	DT 0.019 (1.129)	loss 7.777 (7.777)	prob 3.031 (3.031)	GS 28.938 (28.938)	mem 40.160
Train: [28][550/750]	BT 0.033 (1.164)	DT 0.001 (1.119)	loss 7.945 (7.945)	prob 3.817 (3.817)	GS 36.797 (36.797)	mem 40.159
Train: [28][555/750]	BT 0.033 (1.179)	DT 0.002 (1.135)	loss 8.048 (8.048)	prob 2.904 (2.904)	GS 32.656 (32.656)	mem 40.160
Train: [28][560/750]	BT 0.048 (1.169)	DT 0.006 (1.125)	loss 7.703 (7.703)	prob 3.256 (3.256)	GS 34.016 (34.016)	mem 40.145
Train: [28][565/750]	BT 0.094 (1.159)	DT 0.016 (1.115)	loss 8.137 (8.137)	prob 2.828 (2.828)	GS 36.281 (36.281)	mem 40.047
Train: [28][570/750]	BT 0.038 (1.167)	DT 0.005 (1.123)	loss 7.373 (7.373)	prob 3.642 (3.642)	GS 35.375 (35.375)	mem 40.159
Train: [28][575/750]	BT 0.026 (1.158)	DT 0.002 (1.113)	loss 7.346 (7.346)	prob 3.107 (3.107)	GS 32.812 (32.812)	mem 40.159
Train: [28][580/750]	BT 0.040 (1.166)	DT 0.008 (1.121)	loss 7.880 (7.880)	prob 3.591 (3.591)	GS 34.500 (34.500)	mem 40.202
Train: [28][585/750]	BT 0.095 (1.157)	DT 0.028 (1.112)	loss 8.062 (8.062)	prob 2.788 (2.788)	GS 34.438 (34.438)	mem 40.111
Train: [28][590/750]	BT 12.145 (1.168)	DT 12.108 (1.123)	loss 7.548 (7.548)	prob 4.306 (4.306)	GS 31.250 (31.250)	mem 40.313
Train: [28][595/750]	BT 0.024 (1.159)	DT 0.001 (1.114)	loss 7.635 (7.635)	prob 3.505 (3.505)	GS 28.984 (28.984)	mem 40.204
Train: [28][600/750]	BT 0.064 (1.149)	DT 0.025 (1.104)	loss 7.495 (7.495)	prob 4.390 (4.390)	GS 32.953 (32.953)	mem 40.203
Train: [28][605/750]	BT 0.036 (1.160)	DT 0.001 (1.115)	loss 7.997 (7.997)	prob 2.967 (2.967)	GS 33.922 (33.922)	mem 40.258
Train: [28][610/750]	BT 0.033 (1.155)	DT 0.001 (1.110)	loss 7.592 (7.592)	prob 3.238 (3.238)	GS 34.250 (34.250)	mem 40.568
Train: [28][615/750]	BT 0.046 (1.162)	DT 0.016 (1.118)	loss 7.355 (7.355)	prob 3.104 (3.104)	GS 31.750 (31.750)	mem 40.432
Train: [28][620/750]	BT 0.060 (1.157)	DT 0.004 (1.113)	loss 7.936 (7.936)	prob 3.471 (3.471)	GS 33.844 (33.844)	mem 40.472
Train: [28][625/750]	BT 0.039 (1.148)	DT 0.002 (1.104)	loss 7.294 (7.294)	prob 3.297 (3.297)	GS 35.781 (35.781)	mem 40.483
Train: [28][630/750]	BT 1.171 (1.158)	DT 1.087 (1.113)	loss 8.090 (8.090)	prob 3.927 (3.927)	GS 34.016 (34.016)	mem 40.752
Train: [28][635/750]	BT 0.033 (1.149)	DT 0.001 (1.104)	loss 7.510 (7.510)	prob 3.943 (3.943)	GS 28.344 (28.344)	mem 40.637
Train: [28][640/750]	BT 0.090 (1.158)	DT 0.043 (1.113)	loss 7.605 (7.605)	prob 3.746 (3.746)	GS 30.438 (30.438)	mem 40.728
Train: [28][645/750]	BT 0.052 (1.151)	DT 0.012 (1.106)	loss 8.050 (8.050)	prob 3.031 (3.031)	GS 32.172 (32.172)	mem 40.680
Train: [28][650/750]	BT 8.758 (1.159)	DT 8.724 (1.114)	loss 7.729 (7.729)	prob 3.638 (3.638)	GS 32.656 (32.656)	mem 40.663
Train: [28][655/750]	BT 0.084 (1.156)	DT 0.005 (1.111)	loss 7.458 (7.458)	prob 3.208 (3.208)	GS 31.609 (31.609)	mem 40.759
Train: [28][660/750]	BT 0.137 (1.148)	DT 0.106 (1.103)	loss 7.755 (7.755)	prob 3.352 (3.352)	GS 37.047 (37.047)	mem 40.658
Train: [28][665/750]	BT 0.044 (1.157)	DT 0.009 (1.112)	loss 7.854 (7.854)	prob 3.019 (3.019)	GS 32.016 (32.016)	mem 40.757
Train: [28][670/750]	BT 0.082 (1.154)	DT 0.012 (1.109)	loss 7.200 (7.200)	prob 4.202 (4.202)	GS 39.500 (39.500)	mem 40.828
Train: [28][675/750]	BT 0.056 (1.157)	DT 0.003 (1.112)	loss 7.386 (7.386)	prob 3.354 (3.354)	GS 28.734 (28.734)	mem 40.551
Train: [28][680/750]	BT 0.032 (1.152)	DT 0.001 (1.107)	loss 7.565 (7.565)	prob 4.356 (4.356)	GS 34.406 (34.406)	mem 40.576
Train: [28][685/750]	BT 0.031 (1.144)	DT 0.001 (1.099)	loss 7.292 (7.292)	prob 3.547 (3.547)	GS 32.047 (32.047)	mem 40.592
Train: [28][690/750]	BT 0.047 (1.158)	DT 0.012 (1.113)	loss 8.113 (8.113)	prob 3.547 (3.547)	GS 35.766 (35.766)	mem 40.156
Train: [28][695/750]	BT 0.085 (1.150)	DT 0.030 (1.105)	loss 8.436 (8.436)	prob 2.201 (2.201)	GS 34.328 (34.328)	mem 40.157
Train: [28][700/750]	BT 5.419 (1.163)	DT 5.387 (1.118)	loss 7.843 (7.843)	prob 3.760 (3.760)	GS 36.625 (36.625)	mem 40.227
Train: [28][705/750]	BT 0.087 (1.155)	DT 0.001 (1.110)	loss 7.509 (7.509)	prob 3.040 (3.040)	GS 32.125 (32.125)	mem 40.254
Train: [28][710/750]	BT 3.115 (1.151)	DT 3.037 (1.106)	loss 7.270 (7.270)	prob 3.907 (3.907)	GS 34.156 (34.156)	mem 40.216
Train: [28][715/750]	BT 0.039 (1.154)	DT 0.002 (1.109)	loss 7.526 (7.526)	prob 3.610 (3.610)	GS 30.578 (30.578)	mem 40.216
Train: [28][720/750]	BT 0.044 (1.146)	DT 0.003 (1.101)	loss 7.572 (7.572)	prob 3.358 (3.358)	GS 35.219 (35.219)	mem 40.225
Train: [28][725/750]	BT 0.075 (1.153)	DT 0.020 (1.108)	loss 7.465 (7.465)	prob 3.627 (3.627)	GS 28.828 (28.828)	mem 40.176
Train: [28][730/750]	BT 0.055 (1.146)	DT 0.016 (1.100)	loss 7.595 (7.595)	prob 3.817 (3.817)	GS 36.500 (36.500)	mem 40.106
Train: [28][735/750]	BT 0.032 (1.148)	DT 0.002 (1.103)	loss 7.192 (7.192)	prob 3.110 (3.110)	GS 28.312 (28.312)	mem 36.913
Train: [28][740/750]	BT 0.072 (1.145)	DT 0.006 (1.100)	loss 7.425 (7.425)	prob 3.550 (3.550)	GS 35.406 (35.406)	mem 31.222
Train: [28][745/750]	BT 0.032 (1.137)	DT 0.001 (1.092)	loss 7.496 (7.496)	prob 4.029 (4.029)	GS 28.344 (28.344)	mem 31.538
Train: [28][750/750]	BT 0.020 (1.134)	DT 0.001 (1.088)	loss 8.208 (8.208)	prob 3.305 (3.305)	GS 35.781 (35.781)	mem 10.841
Train: [28][755/750]	BT 0.028 (1.126)	DT 0.001 (1.081)	loss 6.900 (6.900)	prob 3.531 (3.531)	GS 36.000 (36.000)	mem 10.843
epoch 28, total time 850.76
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [29][1/750]	BT 20.476 (20.476)	DT 20.425 (20.425)	loss 7.793 (7.793)	prob 2.954 (2.954)	GS 28.422 (28.422)	mem 38.441
Train: [29][5/750]	BT 1.618 (4.590)	DT 1.584 (4.552)	loss 7.209 (7.209)	prob 3.287 (3.287)	GS 33.594 (33.594)	mem 38.645
Train: [29][10/750]	BT 0.079 (2.996)	DT 0.014 (2.936)	loss 7.436 (7.436)	prob 3.908 (3.908)	GS 32.891 (32.891)	mem 38.908
Train: [29][15/750]	BT 0.048 (2.420)	DT 0.011 (2.367)	loss 7.387 (7.387)	prob 3.010 (3.010)	GS 28.266 (28.266)	mem 38.908
Train: [29][20/750]	BT 0.026 (2.203)	DT 0.001 (2.154)	loss 7.367 (7.367)	prob 3.275 (3.275)	GS 31.703 (31.703)	mem 38.956
Train: [29][25/750]	BT 2.072 (1.854)	DT 2.024 (1.805)	loss 7.267 (7.267)	prob 3.008 (3.008)	GS 31.594 (31.594)	mem 39.014
Train: [29][30/750]	BT 7.016 (1.943)	DT 6.919 (1.891)	loss 7.220 (7.220)	prob 3.769 (3.769)	GS 34.172 (34.172)	mem 39.153
Train: [29][35/750]	BT 0.097 (1.672)	DT 0.018 (1.622)	loss 7.342 (7.342)	prob 2.880 (2.880)	GS 27.078 (27.078)	mem 39.155
Train: [29][40/750]	BT 0.510 (1.620)	DT 0.469 (1.569)	loss 7.604 (7.604)	prob 3.655 (3.655)	GS 33.469 (33.469)	mem 39.231
Train: [29][45/750]	BT 0.109 (1.584)	DT 0.001 (1.532)	loss 7.399 (7.399)	prob 2.385 (2.385)	GS 28.234 (28.234)	mem 39.190
Train: [29][50/750]	BT 6.550 (1.560)	DT 6.490 (1.509)	loss 7.407 (7.407)	prob 3.120 (3.120)	GS 33.500 (33.500)	mem 39.253
Train: [29][55/750]	BT 0.032 (1.538)	DT 0.002 (1.487)	loss 7.279 (7.279)	prob 2.954 (2.954)	GS 30.094 (30.094)	mem 39.236
Train: [29][60/750]	BT 0.029 (1.413)	DT 0.001 (1.363)	loss 7.238 (7.238)	prob 3.292 (3.292)	GS 32.641 (32.641)	mem 39.280
Train: [29][65/750]	BT 0.033 (1.444)	DT 0.001 (1.395)	loss 7.220 (7.220)	prob 3.402 (3.402)	GS 31.328 (31.328)	mem 39.363
Train: [29][70/750]	BT 0.081 (1.370)	DT 0.006 (1.320)	loss 7.343 (7.343)	prob 3.574 (3.574)	GS 30.344 (30.344)	mem 39.256
Train: [29][75/750]	BT 0.061 (1.366)	DT 0.007 (1.317)	loss 6.930 (6.930)	prob 3.322 (3.322)	GS 32.484 (32.484)	mem 39.321
Train: [29][80/750]	BT 0.042 (1.345)	DT 0.013 (1.296)	loss 7.065 (7.065)	prob 3.097 (3.097)	GS 32.984 (32.984)	mem 39.240
Train: [29][85/750]	BT 0.049 (1.309)	DT 0.007 (1.261)	loss 7.158 (7.158)	prob 2.772 (2.772)	GS 31.406 (31.406)	mem 39.296
Train: [29][90/750]	BT 0.486 (1.329)	DT 0.422 (1.280)	loss 7.048 (7.048)	prob 2.947 (2.947)	GS 32.828 (32.828)	mem 39.348
Train: [29][95/750]	BT 0.049 (1.261)	DT 0.004 (1.213)	loss 7.411 (7.411)	prob 2.675 (2.675)	GS 29.094 (29.094)	mem 39.328
Train: [29][100/750]	BT 1.243 (1.321)	DT 1.212 (1.273)	loss 7.378 (7.378)	prob 3.489 (3.489)	GS 35.656 (35.656)	mem 39.446
Train: [29][105/750]	BT 0.032 (1.280)	DT 0.002 (1.233)	loss 7.640 (7.640)	prob 2.217 (2.217)	GS 31.828 (31.828)	mem 39.280
Train: [29][110/750]	BT 10.894 (1.331)	DT 10.868 (1.283)	loss 6.970 (6.970)	prob 3.465 (3.465)	GS 32.312 (32.312)	mem 39.351
Train: [29][115/750]	BT 0.039 (1.280)	DT 0.002 (1.234)	loss 7.488 (7.488)	prob 3.036 (3.036)	GS 49.922 (49.922)	mem 39.353
Train: [29][120/750]	BT 0.031 (1.239)	DT 0.001 (1.193)	loss 7.313 (7.313)	prob 2.558 (2.558)	GS 31.922 (31.922)	mem 39.358
Train: [29][125/750]	BT 0.043 (1.265)	DT 0.002 (1.219)	loss 7.102 (7.102)	prob 2.906 (2.906)	GS 33.094 (33.094)	mem 39.400
Train: [29][130/750]	BT 2.019 (1.255)	DT 1.884 (1.209)	loss 7.324 (7.324)	prob 3.406 (3.406)	GS 35.703 (35.703)	mem 39.197
Train: [29][135/750]	BT 0.042 (1.288)	DT 0.001 (1.241)	loss 7.853 (7.853)	prob 2.548 (2.548)	GS 33.984 (33.984)	mem 39.420
Train: [29][140/750]	BT 0.056 (1.248)	DT 0.002 (1.201)	loss 7.309 (7.309)	prob 2.524 (2.524)	GS 31.062 (31.062)	mem 39.277
Train: [29][145/750]	BT 0.040 (1.209)	DT 0.002 (1.163)	loss 7.241 (7.241)	prob 2.929 (2.929)	GS 28.734 (28.734)	mem 39.281
Train: [29][150/750]	BT 0.176 (1.255)	DT 0.139 (1.209)	loss 7.307 (7.307)	prob 3.044 (3.044)	GS 35.609 (35.609)	mem 39.266
Train: [29][155/750]	BT 0.035 (1.223)	DT 0.001 (1.176)	loss 7.371 (7.371)	prob 2.780 (2.780)	GS 30.016 (30.016)	mem 39.298
Train: [29][160/750]	BT 2.836 (1.261)	DT 2.806 (1.215)	loss 7.092 (7.092)	prob 3.193 (3.193)	GS 34.953 (34.953)	mem 39.344
Train: [29][165/750]	BT 0.066 (1.244)	DT 0.009 (1.198)	loss 7.309 (7.309)	prob 2.680 (2.680)	GS 32.453 (32.453)	mem 39.486
Train: [29][170/750]	BT 2.649 (1.225)	DT 2.614 (1.179)	loss 6.943 (6.943)	prob 2.966 (2.966)	GS 32.797 (32.797)	mem 39.398
Train: [29][175/750]	BT 0.055 (1.248)	DT 0.002 (1.202)	loss 7.157 (7.157)	prob 2.945 (2.945)	GS 32.062 (32.062)	mem 39.610
Train: [29][180/750]	BT 0.035 (1.215)	DT 0.001 (1.169)	loss 7.107 (7.107)	prob 2.796 (2.796)	GS 34.375 (34.375)	mem 39.438
Train: [29][185/750]	BT 0.044 (1.220)	DT 0.015 (1.175)	loss 7.442 (7.442)	prob 2.325 (2.325)	GS 33.469 (33.469)	mem 39.668
Train: [29][190/750]	BT 2.330 (1.227)	DT 2.295 (1.182)	loss 7.347 (7.347)	prob 2.511 (2.511)	GS 36.641 (36.641)	mem 39.725
Train: [29][195/750]	BT 0.046 (1.211)	DT 0.016 (1.166)	loss 7.180 (7.180)	prob 3.055 (3.055)	GS 28.141 (28.141)	mem 39.657
Train: [29][200/750]	BT 0.057 (1.228)	DT 0.011 (1.183)	loss 7.757 (7.757)	prob 2.540 (2.540)	GS 35.844 (35.844)	mem 39.734
Train: [29][205/750]	BT 0.032 (1.206)	DT 0.001 (1.161)	loss 6.982 (6.982)	prob 3.039 (3.039)	GS 31.859 (31.859)	mem 39.735
Train: [29][210/750]	BT 6.640 (1.240)	DT 6.594 (1.195)	loss 7.257 (7.257)	prob 2.923 (2.923)	GS 33.484 (33.484)	mem 39.700
Train: [29][215/750]	BT 0.068 (1.212)	DT 0.003 (1.167)	loss 7.010 (7.010)	prob 3.097 (3.097)	GS 30.219 (30.219)	mem 39.746
Train: [29][220/750]	BT 4.556 (1.212)	DT 4.524 (1.167)	loss 6.861 (6.861)	prob 3.511 (3.511)	GS 33.828 (33.828)	mem 39.734
Train: [29][225/750]	BT 0.027 (1.238)	DT 0.001 (1.193)	loss 7.158 (7.158)	prob 2.354 (2.354)	GS 30.516 (30.516)	mem 39.626
Train: [29][230/750]	BT 0.105 (1.212)	DT 0.032 (1.168)	loss 7.133 (7.133)	prob 2.872 (2.872)	GS 33.078 (33.078)	mem 39.639
Train: [29][235/750]	BT 0.051 (1.245)	DT 0.005 (1.200)	loss 7.045 (7.045)	prob 2.811 (2.811)	GS 28.906 (28.906)	mem 39.752
Train: [29][240/750]	BT 0.030 (1.220)	DT 0.001 (1.175)	loss 7.185 (7.185)	prob 2.647 (2.647)	GS 34.969 (34.969)	mem 39.753
Train: [29][245/750]	BT 0.053 (1.196)	DT 0.010 (1.152)	loss 6.890 (6.890)	prob 3.107 (3.107)	GS 29.156 (29.156)	mem 39.764
Train: [29][250/750]	BT 0.022 (1.237)	DT 0.001 (1.193)	loss 7.094 (7.094)	prob 2.706 (2.706)	GS 32.266 (32.266)	mem 39.690
Train: [29][255/750]	BT 0.031 (1.213)	DT 0.001 (1.169)	loss 7.061 (7.061)	prob 3.047 (3.047)	GS 32.203 (32.203)	mem 39.692
Train: [29][260/750]	BT 0.031 (1.239)	DT 0.001 (1.196)	loss 7.369 (7.369)	prob 2.742 (2.742)	GS 35.297 (35.297)	mem 39.951
Train: [29][265/750]	BT 0.042 (1.217)	DT 0.002 (1.173)	loss 7.359 (7.359)	prob 2.808 (2.808)	GS 30.547 (30.547)	mem 39.952
Train: [29][270/750]	BT 13.724 (1.246)	DT 13.694 (1.202)	loss 7.031 (7.031)	prob 2.838 (2.838)	GS 33.188 (33.188)	mem 40.190
Train: [29][275/750]	BT 0.032 (1.224)	DT 0.001 (1.180)	loss 7.461 (7.461)	prob 2.056 (2.056)	GS 29.781 (29.781)	mem 40.045
Train: [29][280/750]	BT 0.032 (1.203)	DT 0.002 (1.159)	loss 7.275 (7.275)	prob 2.610 (2.610)	GS 33.422 (33.422)	mem 40.057
Train: [29][285/750]	BT 0.022 (1.230)	DT 0.001 (1.187)	loss 7.210 (7.210)	prob 3.019 (3.019)	GS 33.781 (33.781)	mem 40.050
Train: [29][290/750]	BT 0.075 (1.210)	DT 0.009 (1.167)	loss 7.324 (7.324)	prob 2.267 (2.267)	GS 29.609 (29.609)	mem 40.095
Train: [29][295/750]	BT 0.031 (1.228)	DT 0.001 (1.185)	loss 7.101 (7.101)	prob 2.843 (2.843)	GS 29.719 (29.719)	mem 40.160
Train: [29][300/750]	BT 0.130 (1.209)	DT 0.026 (1.166)	loss 7.111 (7.111)	prob 3.016 (3.016)	GS 39.531 (39.531)	mem 40.118
Train: [29][305/750]	BT 0.024 (1.190)	DT 0.001 (1.147)	loss 7.439 (7.439)	prob 2.311 (2.311)	GS 32.984 (32.984)	mem 40.072
Train: [29][310/750]	BT 1.040 (1.214)	DT 1.007 (1.171)	loss 6.929 (6.929)	prob 2.092 (2.092)	GS 33.438 (33.438)	mem 40.294
Train: [29][315/750]	BT 0.031 (1.196)	DT 0.001 (1.152)	loss 7.204 (7.204)	prob 2.549 (2.549)	GS 29.344 (29.344)	mem 40.103
Train: [29][320/750]	BT 0.035 (1.210)	DT 0.001 (1.166)	loss 7.245 (7.245)	prob 2.810 (2.810)	GS 34.531 (34.531)	mem 40.070
Train: [29][325/750]	BT 0.058 (1.192)	DT 0.008 (1.148)	loss 7.561 (7.561)	prob 2.380 (2.380)	GS 31.094 (31.094)	mem 40.094
Train: [29][330/750]	BT 13.270 (1.215)	DT 13.248 (1.171)	loss 7.108 (7.108)	prob 3.329 (3.329)	GS 32.703 (32.703)	mem 40.128
Train: [29][335/750]	BT 0.047 (1.197)	DT 0.013 (1.154)	loss 7.395 (7.395)	prob 2.323 (2.323)	GS 32.344 (32.344)	mem 40.133
Train: [29][340/750]	BT 0.033 (1.180)	DT 0.001 (1.137)	loss 7.321 (7.321)	prob 2.681 (2.681)	GS 31.219 (31.219)	mem 40.070
Train: [29][345/750]	BT 0.027 (1.200)	DT 0.002 (1.157)	loss 7.363 (7.363)	prob 2.614 (2.614)	GS 27.578 (27.578)	mem 40.095
Train: [29][350/750]	BT 0.038 (1.184)	DT 0.006 (1.140)	loss 7.027 (7.027)	prob 2.956 (2.956)	GS 26.719 (26.719)	mem 40.157
Train: [29][355/750]	BT 0.029 (1.208)	DT 0.002 (1.164)	loss 7.019 (7.019)	prob 2.413 (2.413)	GS 30.500 (30.500)	mem 40.115
Train: [29][360/750]	BT 0.022 (1.191)	DT 0.001 (1.148)	loss 6.982 (6.982)	prob 3.383 (3.383)	GS 32.141 (32.141)	mem 40.115
Train: [29][365/750]	BT 0.032 (1.175)	DT 0.001 (1.132)	loss 7.173 (7.173)	prob 2.251 (2.251)	GS 34.703 (34.703)	mem 40.115
Train: [29][370/750]	BT 0.020 (1.198)	DT 0.001 (1.155)	loss 7.006 (7.006)	prob 2.862 (2.862)	GS 34.000 (34.000)	mem 40.084
Train: [29][375/750]	BT 0.083 (1.183)	DT 0.008 (1.140)	loss 6.886 (6.886)	prob 2.147 (2.147)	GS 26.766 (26.766)	mem 40.094
Train: [29][380/750]	BT 0.043 (1.203)	DT 0.001 (1.160)	loss 6.957 (6.957)	prob 2.274 (2.274)	GS 32.641 (32.641)	mem 40.163
Train: [29][385/750]	BT 0.112 (1.188)	DT 0.002 (1.145)	loss 6.922 (6.922)	prob 2.477 (2.477)	GS 29.281 (29.281)	mem 40.165
Train: [29][390/750]	BT 11.849 (1.204)	DT 11.824 (1.161)	loss 7.290 (7.290)	prob 2.540 (2.540)	GS 31.062 (31.062)	mem 40.328
Train: [29][395/750]	BT 0.046 (1.192)	DT 0.002 (1.149)	loss 7.102 (7.102)	prob 2.473 (2.473)	GS 32.109 (32.109)	mem 40.349
Train: [29][400/750]	BT 0.049 (1.178)	DT 0.002 (1.135)	loss 7.264 (7.264)	prob 2.586 (2.586)	GS 31.234 (31.234)	mem 40.201
Train: [29][405/750]	BT 0.048 (1.191)	DT 0.002 (1.148)	loss 7.066 (7.066)	prob 2.886 (2.886)	GS 31.953 (31.953)	mem 40.134
Train: [29][410/750]	BT 0.048 (1.188)	DT 0.011 (1.145)	loss 7.198 (7.198)	prob 2.904 (2.904)	GS 31.500 (31.500)	mem 40.184
Train: [29][415/750]	BT 0.132 (1.191)	DT 0.014 (1.148)	loss 7.206 (7.206)	prob 2.565 (2.565)	GS 29.797 (29.797)	mem 40.172
Train: [29][420/750]	BT 0.076 (1.188)	DT 0.018 (1.145)	loss 6.988 (6.988)	prob 2.670 (2.670)	GS 35.547 (35.547)	mem 40.149
Train: [29][425/750]	BT 0.080 (1.175)	DT 0.006 (1.132)	loss 7.011 (7.011)	prob 2.535 (2.535)	GS 32.188 (32.188)	mem 40.257
Train: [29][430/750]	BT 3.484 (1.192)	DT 3.452 (1.149)	loss 7.001 (7.001)	prob 2.763 (2.763)	GS 34.250 (34.250)	mem 40.252
Train: [29][435/750]	BT 0.030 (1.179)	DT 0.001 (1.136)	loss 7.430 (7.430)	prob 1.593 (1.593)	GS 29.016 (29.016)	mem 40.121
Train: [29][440/750]	BT 0.086 (1.192)	DT 0.003 (1.149)	loss 7.301 (7.301)	prob 2.666 (2.666)	GS 39.594 (39.594)	mem 40.544
Train: [29][445/750]	BT 0.023 (1.188)	DT 0.001 (1.145)	loss 6.843 (6.843)	prob 2.904 (2.904)	GS 29.688 (29.688)	mem 40.065
Train: [29][450/750]	BT 9.265 (1.196)	DT 9.232 (1.153)	loss 7.148 (7.148)	prob 2.773 (2.773)	GS 32.438 (32.438)	mem 40.066
Train: [29][455/750]	BT 0.043 (1.194)	DT 0.001 (1.151)	loss 6.962 (6.962)	prob 2.393 (2.393)	GS 29.016 (29.016)	mem 40.064
Train: [29][460/750]	BT 0.117 (1.182)	DT 0.004 (1.138)	loss 6.913 (6.913)	prob 2.157 (2.157)	GS 30.328 (30.328)	mem 40.103
Train: [29][465/750]	BT 0.033 (1.182)	DT 0.001 (1.138)	loss 7.466 (7.466)	prob 2.091 (2.091)	GS 31.984 (31.984)	mem 40.081
Train: [29][470/750]	BT 0.028 (1.187)	DT 0.001 (1.143)	loss 7.105 (7.105)	prob 2.160 (2.160)	GS 37.078 (37.078)	mem 40.071
Train: [29][475/750]	BT 0.053 (1.185)	DT 0.003 (1.141)	loss 7.523 (7.523)	prob 2.042 (2.042)	GS 28.375 (28.375)	mem 40.094
Train: [29][480/750]	BT 0.039 (1.186)	DT 0.009 (1.142)	loss 7.048 (7.048)	prob 2.291 (2.291)	GS 31.844 (31.844)	mem 40.176
Train: [29][485/750]	BT 0.045 (1.174)	DT 0.004 (1.131)	loss 7.124 (7.124)	prob 2.621 (2.621)	GS 34.875 (34.875)	mem 40.175
Train: [29][490/750]	BT 0.127 (1.184)	DT 0.085 (1.140)	loss 7.025 (7.025)	prob 2.759 (2.759)	GS 31.172 (31.172)	mem 40.252
Train: [29][495/750]	BT 0.037 (1.172)	DT 0.001 (1.129)	loss 6.980 (6.980)	prob 2.562 (2.562)	GS 31.656 (31.656)	mem 40.169
Train: [29][500/750]	BT 0.030 (1.189)	DT 0.001 (1.145)	loss 7.165 (7.165)	prob 3.108 (3.108)	GS 38.812 (38.812)	mem 40.096
Train: [29][505/750]	BT 0.034 (1.179)	DT 0.002 (1.135)	loss 7.373 (7.373)	prob 2.248 (2.248)	GS 34.547 (34.547)	mem 40.104
Train: [29][510/750]	BT 10.805 (1.189)	DT 10.759 (1.145)	loss 7.207 (7.207)	prob 2.513 (2.513)	GS 34.406 (34.406)	mem 40.056
Train: [29][515/750]	BT 0.079 (1.184)	DT 0.004 (1.140)	loss 7.172 (7.172)	prob 1.747 (1.747)	GS 29.516 (29.516)	mem 40.059
Train: [29][520/750]	BT 0.037 (1.173)	DT 0.002 (1.129)	loss 7.129 (7.129)	prob 2.270 (2.270)	GS 31.453 (31.453)	mem 40.069
Train: [29][525/750]	BT 0.043 (1.176)	DT 0.002 (1.132)	loss 6.946 (6.946)	prob 2.696 (2.696)	GS 32.172 (32.172)	mem 40.056
Train: [29][530/750]	BT 0.048 (1.170)	DT 0.007 (1.127)	loss 7.135 (7.135)	prob 2.468 (2.468)	GS 36.406 (36.406)	mem 40.106
Train: [29][535/750]	BT 0.065 (1.182)	DT 0.010 (1.138)	loss 7.054 (7.054)	prob 2.007 (2.007)	GS 35.359 (35.359)	mem 40.166
Train: [29][540/750]	BT 0.070 (1.182)	DT 0.011 (1.139)	loss 6.810 (6.810)	prob 2.690 (2.690)	GS 39.078 (39.078)	mem 40.106
Train: [29][545/750]	BT 0.031 (1.172)	DT 0.001 (1.128)	loss 7.452 (7.452)	prob 1.459 (1.459)	GS 32.391 (32.391)	mem 40.119
Train: [29][550/750]	BT 6.818 (1.183)	DT 6.768 (1.140)	loss 6.925 (6.925)	prob 2.495 (2.495)	GS 34.984 (34.984)	mem 40.185
Train: [29][555/750]	BT 0.067 (1.173)	DT 0.011 (1.129)	loss 7.362 (7.362)	prob 2.097 (2.097)	GS 31.422 (31.422)	mem 40.348
Train: [29][560/750]	BT 1.884 (1.173)	DT 1.833 (1.130)	loss 7.138 (7.138)	prob 2.536 (2.536)	GS 35.734 (35.734)	mem 39.931
Train: [29][565/750]	BT 0.040 (1.171)	DT 0.002 (1.128)	loss 7.279 (7.279)	prob 1.806 (1.806)	GS 31.516 (31.516)	mem 40.027
Train: [29][570/750]	BT 6.345 (1.173)	DT 6.278 (1.129)	loss 7.076 (7.076)	prob 3.144 (3.144)	GS 38.031 (38.031)	mem 40.059
Train: [29][575/750]	BT 0.042 (1.177)	DT 0.010 (1.133)	loss 7.073 (7.073)	prob 2.777 (2.777)	GS 31.219 (31.219)	mem 40.113
Train: [29][580/750]	BT 0.064 (1.167)	DT 0.003 (1.123)	loss 6.665 (6.665)	prob 2.924 (2.924)	GS 30.625 (30.625)	mem 40.045
Train: [29][585/750]	BT 0.051 (1.173)	DT 0.005 (1.129)	loss 7.121 (7.121)	prob 1.608 (1.608)	GS 33.828 (33.828)	mem 40.071
Train: [29][590/750]	BT 0.030 (1.170)	DT 0.001 (1.127)	loss 7.332 (7.332)	prob 1.813 (1.813)	GS 32.281 (32.281)	mem 40.087
Train: [29][595/750]	BT 0.031 (1.177)	DT 0.001 (1.133)	loss 6.915 (6.915)	prob 2.035 (2.035)	GS 29.531 (29.531)	mem 40.101
Train: [29][600/750]	BT 0.028 (1.174)	DT 0.001 (1.130)	loss 7.240 (7.240)	prob 1.970 (1.970)	GS 30.375 (30.375)	mem 40.125
Train: [29][605/750]	BT 0.051 (1.164)	DT 0.001 (1.121)	loss 7.104 (7.104)	prob 2.677 (2.677)	GS 31.547 (31.547)	mem 40.126
Train: [29][610/750]	BT 2.631 (1.175)	DT 2.585 (1.132)	loss 7.187 (7.187)	prob 1.545 (1.545)	GS 33.219 (33.219)	mem 40.217
Train: [29][615/750]	BT 0.041 (1.166)	DT 0.001 (1.123)	loss 6.936 (6.936)	prob 1.817 (1.817)	GS 35.703 (35.703)	mem 40.048
Train: [29][620/750]	BT 0.068 (1.174)	DT 0.010 (1.130)	loss 7.049 (7.049)	prob 2.595 (2.595)	GS 32.703 (32.703)	mem 40.038
Train: [29][625/750]	BT 0.032 (1.170)	DT 0.001 (1.127)	loss 7.035 (7.035)	prob 1.949 (1.949)	GS 33.438 (33.438)	mem 40.033
Train: [29][630/750]	BT 10.214 (1.177)	DT 10.186 (1.134)	loss 8.418 (8.418)	prob 1.103 (1.103)	GS 33.234 (33.234)	mem 40.058
Train: [29][635/750]	BT 0.039 (1.171)	DT 0.003 (1.127)	loss 7.142 (7.142)	prob 1.960 (1.960)	GS 37.781 (37.781)	mem 40.050
Train: [29][640/750]	BT 0.078 (1.162)	DT 0.021 (1.118)	loss 7.034 (7.034)	prob 1.906 (1.906)	GS 33.344 (33.344)	mem 40.049
Train: [29][645/750]	BT 0.061 (1.168)	DT 0.009 (1.125)	loss 7.336 (7.336)	prob 1.722 (1.722)	GS 38.875 (38.875)	mem 40.055
Train: [29][650/750]	BT 0.091 (1.160)	DT 0.013 (1.116)	loss 7.780 (7.780)	prob 1.647 (1.647)	GS 33.578 (33.578)	mem 40.179
Train: [29][655/750]	BT 0.048 (1.176)	DT 0.001 (1.132)	loss 7.355 (7.355)	prob 1.485 (1.485)	GS 32.172 (32.172)	mem 39.970
Train: [29][660/750]	BT 0.034 (1.168)	DT 0.001 (1.124)	loss 7.401 (7.401)	prob 2.695 (2.695)	GS 31.344 (31.344)	mem 39.972
Train: [29][665/750]	BT 0.032 (1.159)	DT 0.002 (1.115)	loss 7.166 (7.166)	prob 1.646 (1.646)	GS 33.891 (33.891)	mem 39.974
Train: [29][670/750]	BT 0.092 (1.167)	DT 0.007 (1.123)	loss 7.576 (7.576)	prob 1.685 (1.685)	GS 36.484 (36.484)	mem 39.958
Train: [29][675/750]	BT 0.036 (1.159)	DT 0.002 (1.115)	loss 7.681 (7.681)	prob 1.512 (1.512)	GS 31.219 (31.219)	mem 40.162
Train: [29][680/750]	BT 0.042 (1.170)	DT 0.004 (1.126)	loss 8.006 (8.006)	prob 1.777 (1.777)	GS 33.734 (33.734)	mem 40.014
Train: [29][685/750]	BT 0.076 (1.162)	DT 0.007 (1.118)	loss 7.297 (7.297)	prob 2.668 (2.668)	GS 31.453 (31.453)	mem 40.015
Train: [29][690/750]	BT 13.478 (1.175)	DT 13.350 (1.131)	loss 8.814 (8.814)	prob 1.168 (1.168)	GS 32.656 (32.656)	mem 39.991
Train: [29][695/750]	BT 0.051 (1.167)	DT 0.004 (1.122)	loss 6.855 (6.855)	prob 3.345 (3.345)	GS 30.031 (30.031)	mem 39.953
Train: [29][700/750]	BT 0.032 (1.159)	DT 0.002 (1.114)	loss 7.278 (7.278)	prob 2.101 (2.101)	GS 36.000 (36.000)	mem 40.036
Train: [29][705/750]	BT 0.027 (1.170)	DT 0.001 (1.126)	loss 7.346 (7.346)	prob 1.947 (1.947)	GS 32.203 (32.203)	mem 39.846
Train: [29][710/750]	BT 0.021 (1.162)	DT 0.001 (1.118)	loss 7.754 (7.754)	prob 2.780 (2.780)	GS 36.484 (36.484)	mem 39.816
Train: [29][715/750]	BT 0.033 (1.171)	DT 0.002 (1.128)	loss 8.572 (8.572)	prob 1.083 (1.083)	GS 33.625 (33.625)	mem 40.160
Train: [29][720/750]	BT 0.051 (1.164)	DT 0.011 (1.120)	loss 7.750 (7.750)	prob 2.186 (2.186)	GS 33.891 (33.891)	mem 39.936
Train: [29][725/750]	BT 0.043 (1.156)	DT 0.002 (1.112)	loss 7.363 (7.363)	prob 2.683 (2.683)	GS 30.828 (30.828)	mem 40.048
Train: [29][730/750]	BT 0.039 (1.168)	DT 0.009 (1.124)	loss 8.074 (8.074)	prob 2.092 (2.092)	GS 32.672 (32.672)	mem 39.712
Train: [29][735/750]	BT 0.059 (1.160)	DT 0.005 (1.116)	loss 7.299 (7.299)	prob 2.339 (2.339)	GS 30.891 (30.891)	mem 39.714
Train: [29][740/750]	BT 0.037 (1.163)	DT 0.002 (1.119)	loss 7.236 (7.236)	prob 2.798 (2.798)	GS 33.922 (33.922)	mem 7.592
Train: [29][745/750]	BT 0.028 (1.155)	DT 0.001 (1.111)	loss 7.661 (7.661)	prob 1.895 (1.895)	GS 32.156 (32.156)	mem 7.592
Train: [29][750/750]	BT 2.685 (1.151)	DT 2.656 (1.108)	loss 8.681 (8.681)	prob 2.067 (2.067)	GS 37.281 (37.281)	mem 7.606
Train: [29][755/750]	BT 0.032 (1.144)	DT 0.001 (1.100)	loss 8.535 (8.535)	prob 1.250 (1.250)	GS 31.156 (31.156)	mem 7.606
epoch 29, total time 863.81
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [30][1/750]	BT 24.625 (24.625)	DT 24.573 (24.573)	loss 8.013 (8.013)	prob 2.580 (2.580)	GS 31.156 (31.156)	mem 38.593
Train: [30][5/750]	BT 0.052 (4.957)	DT 0.002 (4.916)	loss 8.055 (8.055)	prob 1.572 (1.572)	GS 36.641 (36.641)	mem 38.524
Train: [30][10/750]	BT 0.069 (2.574)	DT 0.001 (2.532)	loss 7.195 (7.195)	prob 3.436 (3.436)	GS 35.703 (35.703)	mem 38.755
Train: [30][15/750]	BT 0.040 (2.395)	DT 0.001 (2.352)	loss 7.783 (7.783)	prob 2.096 (2.096)	GS 28.969 (28.969)	mem 38.841
Train: [30][20/750]	BT 0.023 (2.159)	DT 0.001 (2.116)	loss 7.633 (7.633)	prob 2.311 (2.311)	GS 34.016 (34.016)	mem 38.856
Train: [30][25/750]	BT 0.039 (1.738)	DT 0.008 (1.693)	loss 7.466 (7.466)	prob 2.871 (2.871)	GS 29.203 (29.203)	mem 38.858
Train: [30][30/750]	BT 5.301 (1.859)	DT 5.268 (1.814)	loss 7.230 (7.230)	prob 2.515 (2.515)	GS 31.672 (31.672)	mem 39.023
Train: [30][35/750]	BT 0.028 (1.655)	DT 0.002 (1.611)	loss 8.210 (8.210)	prob 2.579 (2.579)	GS 33.922 (33.922)	mem 39.016
Train: [30][40/750]	BT 0.358 (1.554)	DT 0.304 (1.511)	loss 7.396 (7.396)	prob 3.141 (3.141)	GS 33.766 (33.766)	mem 38.927
Train: [30][45/750]	BT 0.049 (1.577)	DT 0.009 (1.534)	loss 7.806 (7.806)	prob 2.721 (2.721)	GS 29.719 (29.719)	mem 38.889
Train: [30][50/750]	BT 7.738 (1.579)	DT 7.699 (1.535)	loss 8.185 (8.185)	prob 2.914 (2.914)	GS 35.094 (35.094)	mem 38.909
Train: [30][55/750]	BT 0.049 (1.465)	DT 0.002 (1.422)	loss 7.401 (7.401)	prob 3.433 (3.433)	GS 25.938 (25.938)	mem 38.973
Train: [30][60/750]	BT 0.042 (1.388)	DT 0.002 (1.344)	loss 8.292 (8.292)	prob 3.872 (3.872)	GS 36.219 (36.219)	mem 39.037
Train: [30][65/750]	BT 0.022 (1.449)	DT 0.001 (1.406)	loss 8.344 (8.344)	prob 2.877 (2.877)	GS 30.859 (30.859)	mem 38.955
Train: [30][70/750]	BT 0.033 (1.366)	DT 0.001 (1.322)	loss 7.349 (7.349)	prob 3.847 (3.847)	GS 30.969 (30.969)	mem 38.981
Train: [30][75/750]	BT 0.031 (1.424)	DT 0.001 (1.381)	loss 8.103 (8.103)	prob 2.944 (2.944)	GS 35.281 (35.281)	mem 39.015
Train: [30][80/750]	BT 0.033 (1.379)	DT 0.001 (1.337)	loss 7.948 (7.948)	prob 3.637 (3.637)	GS 32.609 (32.609)	mem 39.047
Train: [30][85/750]	BT 0.083 (1.302)	DT 0.008 (1.258)	loss 8.147 (8.147)	prob 3.266 (3.266)	GS 34.703 (34.703)	mem 38.973
Train: [30][90/750]	BT 0.383 (1.376)	DT 0.301 (1.333)	loss 7.663 (7.663)	prob 3.626 (3.626)	GS 38.750 (38.750)	mem 39.136
Train: [30][95/750]	BT 0.034 (1.305)	DT 0.005 (1.263)	loss 7.258 (7.258)	prob 4.336 (4.336)	GS 32.203 (32.203)	mem 39.061
Train: [30][100/750]	BT 0.048 (1.404)	DT 0.005 (1.362)	loss 7.508 (7.508)	prob 3.307 (3.307)	GS 31.281 (31.281)	mem 39.130
Train: [30][105/750]	BT 0.052 (1.340)	DT 0.008 (1.298)	loss 7.913 (7.913)	prob 3.020 (3.020)	GS 30.016 (30.016)	mem 39.130
Train: [30][110/750]	BT 13.346 (1.401)	DT 13.310 (1.360)	loss 8.076 (8.076)	prob 3.966 (3.966)	GS 34.906 (34.906)	mem 39.192
Train: [30][115/750]	BT 0.031 (1.342)	DT 0.002 (1.301)	loss 8.207 (8.207)	prob 3.504 (3.504)	GS 31.250 (31.250)	mem 39.236
Train: [30][120/750]	BT 0.031 (1.287)	DT 0.001 (1.247)	loss 7.755 (7.755)	prob 3.756 (3.756)	GS 39.031 (39.031)	mem 39.194
Train: [30][125/750]	BT 0.067 (1.346)	DT 0.006 (1.305)	loss 8.409 (8.409)	prob 2.997 (2.997)	GS 32.688 (32.688)	mem 39.244
Train: [30][130/750]	BT 0.043 (1.295)	DT 0.002 (1.255)	loss 7.580 (7.580)	prob 3.933 (3.933)	GS 33.359 (33.359)	mem 39.147
Train: [30][135/750]	BT 0.031 (1.356)	DT 0.005 (1.316)	loss 8.004 (8.004)	prob 3.689 (3.689)	GS 30.562 (30.562)	mem 39.416
Train: [30][140/750]	BT 0.048 (1.309)	DT 0.007 (1.269)	loss 7.434 (7.434)	prob 3.996 (3.996)	GS 34.891 (34.891)	mem 39.534
Train: [30][145/750]	BT 0.089 (1.266)	DT 0.010 (1.226)	loss 8.599 (8.599)	prob 1.978 (1.978)	GS 37.531 (37.531)	mem 39.601
Train: [30][150/750]	BT 0.045 (1.324)	DT 0.001 (1.284)	loss 7.647 (7.647)	prob 3.600 (3.600)	GS 36.016 (36.016)	mem 39.423
Train: [30][155/750]	BT 0.030 (1.283)	DT 0.001 (1.243)	loss 8.107 (8.107)	prob 2.753 (2.753)	GS 31.516 (31.516)	mem 39.445
Train: [30][160/750]	BT 0.031 (1.321)	DT 0.001 (1.282)	loss 7.257 (7.257)	prob 4.072 (4.072)	GS 37.062 (37.062)	mem 39.554
Train: [30][165/750]	BT 0.075 (1.283)	DT 0.011 (1.243)	loss 7.853 (7.853)	prob 3.310 (3.310)	GS 36.984 (36.984)	mem 39.554
Train: [30][170/750]	BT 13.926 (1.328)	DT 13.894 (1.288)	loss 7.908 (7.908)	prob 4.290 (4.290)	GS 33.266 (33.266)	mem 39.511
Train: [30][175/750]	BT 0.043 (1.291)	DT 0.001 (1.252)	loss 7.620 (7.620)	prob 3.861 (3.861)	GS 34.609 (34.609)	mem 39.510
Train: [30][180/750]	BT 0.056 (1.256)	DT 0.004 (1.217)	loss 8.030 (8.030)	prob 3.967 (3.967)	GS 33.594 (33.594)	mem 39.511
Train: [30][185/750]	BT 0.046 (1.290)	DT 0.009 (1.250)	loss 7.501 (7.501)	prob 4.330 (4.330)	GS 28.719 (28.719)	mem 39.610
Train: [30][190/750]	BT 0.106 (1.257)	DT 0.002 (1.217)	loss 7.745 (7.745)	prob 4.361 (4.361)	GS 31.656 (31.656)	mem 39.864
Train: [30][195/750]	BT 0.031 (1.294)	DT 0.007 (1.253)	loss 7.823 (7.823)	prob 3.561 (3.561)	GS 30.844 (30.844)	mem 39.741
Train: [30][200/750]	BT 0.033 (1.263)	DT 0.002 (1.222)	loss 7.702 (7.702)	prob 3.864 (3.864)	GS 29.859 (29.859)	mem 39.940
Train: [30][205/750]	BT 0.047 (1.233)	DT 0.010 (1.192)	loss 7.439 (7.439)	prob 3.452 (3.452)	GS 28.047 (28.047)	mem 39.723
Train: [30][210/750]	BT 0.031 (1.257)	DT 0.002 (1.217)	loss 8.414 (8.414)	prob 3.145 (3.145)	GS 28.203 (28.203)	mem 39.846
Train: [30][215/750]	BT 0.024 (1.229)	DT 0.001 (1.189)	loss 7.490 (7.490)	prob 3.920 (3.920)	GS 30.938 (30.938)	mem 39.872
Train: [30][220/750]	BT 0.051 (1.261)	DT 0.012 (1.221)	loss 8.098 (8.098)	prob 3.513 (3.513)	GS 33.953 (33.953)	mem 39.879
Train: [30][225/750]	BT 0.033 (1.234)	DT 0.001 (1.194)	loss 7.837 (7.837)	prob 3.495 (3.495)	GS 29.219 (29.219)	mem 39.897
Train: [30][230/750]	BT 11.633 (1.259)	DT 11.601 (1.218)	loss 7.734 (7.734)	prob 2.927 (2.927)	GS 30.766 (30.766)	mem 39.891
Train: [30][235/750]	BT 0.031 (1.233)	DT 0.001 (1.193)	loss 7.498 (7.498)	prob 3.801 (3.801)	GS 29.547 (29.547)	mem 39.897
Train: [30][240/750]	BT 0.058 (1.208)	DT 0.014 (1.168)	loss 7.448 (7.448)	prob 3.834 (3.834)	GS 32.688 (32.688)	mem 39.897
Train: [30][245/750]	BT 0.052 (1.245)	DT 0.001 (1.205)	loss 8.763 (8.763)	prob 2.158 (2.158)	GS 30.391 (30.391)	mem 39.867
Train: [30][250/750]	BT 0.056 (1.221)	DT 0.013 (1.181)	loss 7.411 (7.411)	prob 4.247 (4.247)	GS 37.047 (37.047)	mem 39.816
Train: [30][255/750]	BT 0.056 (1.243)	DT 0.002 (1.203)	loss 7.618 (7.618)	prob 3.151 (3.151)	GS 29.422 (29.422)	mem 39.960
Train: [30][260/750]	BT 0.029 (1.220)	DT 0.001 (1.180)	loss 7.967 (7.967)	prob 3.809 (3.809)	GS 31.516 (31.516)	mem 39.967
Train: [30][265/750]	BT 0.132 (1.198)	DT 0.050 (1.158)	loss 8.256 (8.256)	prob 2.320 (2.320)	GS 32.078 (32.078)	mem 40.044
Train: [30][270/750]	BT 0.032 (1.233)	DT 0.001 (1.193)	loss 7.922 (7.922)	prob 3.527 (3.527)	GS 37.203 (37.203)	mem 39.938
Train: [30][275/750]	BT 0.043 (1.212)	DT 0.005 (1.171)	loss 7.564 (7.564)	prob 3.440 (3.440)	GS 28.359 (28.359)	mem 39.864
Train: [30][280/750]	BT 0.023 (1.231)	DT 0.001 (1.191)	loss 7.764 (7.764)	prob 3.061 (3.061)	GS 36.125 (36.125)	mem 39.879
Train: [30][285/750]	BT 0.024 (1.210)	DT 0.001 (1.170)	loss 7.280 (7.280)	prob 4.027 (4.027)	GS 24.891 (24.891)	mem 39.899
Train: [30][290/750]	BT 13.649 (1.237)	DT 13.620 (1.197)	loss 7.905 (7.905)	prob 4.100 (4.100)	GS 34.453 (34.453)	mem 39.953
Train: [30][295/750]	BT 0.077 (1.217)	DT 0.013 (1.177)	loss 7.585 (7.585)	prob 3.789 (3.789)	GS 35.719 (35.719)	mem 40.136
Train: [30][300/750]	BT 0.057 (1.198)	DT 0.003 (1.157)	loss 7.581 (7.581)	prob 3.683 (3.683)	GS 32.484 (32.484)	mem 40.002
Train: [30][305/750]	BT 0.033 (1.227)	DT 0.001 (1.187)	loss 7.488 (7.488)	prob 3.741 (3.741)	GS 33.969 (33.969)	mem 39.958
Train: [30][310/750]	BT 0.023 (1.208)	DT 0.001 (1.168)	loss 7.199 (7.199)	prob 3.872 (3.872)	GS 34.812 (34.812)	mem 39.959
Train: [30][315/750]	BT 0.049 (1.223)	DT 0.002 (1.182)	loss 7.401 (7.401)	prob 2.702 (2.702)	GS 32.250 (32.250)	mem 40.040
Train: [30][320/750]	BT 0.077 (1.204)	DT 0.009 (1.164)	loss 7.680 (7.680)	prob 3.694 (3.694)	GS 33.500 (33.500)	mem 40.081
Train: [30][325/750]	BT 0.029 (1.187)	DT 0.001 (1.146)	loss 7.255 (7.255)	prob 3.441 (3.441)	GS 29.969 (29.969)	mem 40.043
Train: [30][330/750]	BT 0.033 (1.201)	DT 0.001 (1.160)	loss 8.531 (8.531)	prob 3.612 (3.612)	GS 35.375 (35.375)	mem 39.989
Train: [30][335/750]	BT 0.066 (1.184)	DT 0.001 (1.143)	loss 7.443 (7.443)	prob 4.168 (4.168)	GS 31.844 (31.844)	mem 40.094
Train: [30][340/750]	BT 0.029 (1.202)	DT 0.001 (1.160)	loss 7.371 (7.371)	prob 4.331 (4.331)	GS 31.656 (31.656)	mem 40.056
Train: [30][345/750]	BT 0.035 (1.185)	DT 0.001 (1.143)	loss 7.550 (7.550)	prob 3.483 (3.483)	GS 30.047 (30.047)	mem 40.134
Train: [30][350/750]	BT 14.495 (1.210)	DT 14.453 (1.168)	loss 7.357 (7.357)	prob 3.960 (3.960)	GS 35.141 (35.141)	mem 40.286
Train: [30][355/750]	BT 0.041 (1.193)	DT 0.001 (1.152)	loss 7.443 (7.443)	prob 3.062 (3.062)	GS 30.031 (30.031)	mem 40.274
Train: [30][360/750]	BT 0.044 (1.184)	DT 0.005 (1.142)	loss 7.451 (7.451)	prob 3.479 (3.479)	GS 34.547 (34.547)	mem 40.071
Train: [30][365/750]	BT 0.024 (1.197)	DT 0.001 (1.156)	loss 7.337 (7.337)	prob 4.077 (4.077)	GS 28.594 (28.594)	mem 40.048
Train: [30][370/750]	BT 0.033 (1.183)	DT 0.001 (1.142)	loss 7.293 (7.293)	prob 3.013 (3.013)	GS 34.703 (34.703)	mem 40.049
Train: [30][375/750]	BT 0.031 (1.199)	DT 0.001 (1.158)	loss 7.480 (7.480)	prob 3.095 (3.095)	GS 33.484 (33.484)	mem 40.039
Train: [30][380/750]	BT 0.723 (1.186)	DT 0.677 (1.145)	loss 7.224 (7.224)	prob 4.149 (4.149)	GS 36.328 (36.328)	mem 40.039
Train: [30][385/750]	BT 0.049 (1.171)	DT 0.001 (1.130)	loss 7.173 (7.173)	prob 4.040 (4.040)	GS 28.234 (28.234)	mem 40.171
Train: [30][390/750]	BT 0.068 (1.184)	DT 0.002 (1.143)	loss 7.403 (7.403)	prob 4.232 (4.232)	GS 33.219 (33.219)	mem 40.109
Train: [30][395/750]	BT 0.065 (1.171)	DT 0.011 (1.130)	loss 7.224 (7.224)	prob 3.777 (3.777)	GS 31.000 (31.000)	mem 39.950
Train: [30][400/750]	BT 0.101 (1.187)	DT 0.001 (1.145)	loss 7.246 (7.246)	prob 3.677 (3.677)	GS 30.750 (30.750)	mem 39.976
Train: [30][405/750]	BT 0.038 (1.173)	DT 0.002 (1.131)	loss 7.668 (7.668)	prob 2.836 (2.836)	GS 30.078 (30.078)	mem 39.976
Train: [30][410/750]	BT 10.810 (1.185)	DT 10.771 (1.144)	loss 7.505 (7.505)	prob 2.821 (2.821)	GS 31.547 (31.547)	mem 39.946
Train: [30][415/750]	BT 0.059 (1.171)	DT 0.002 (1.130)	loss 7.273 (7.273)	prob 2.867 (2.867)	GS 32.312 (32.312)	mem 39.946
Train: [30][420/750]	BT 0.033 (1.159)	DT 0.001 (1.118)	loss 7.190 (7.190)	prob 3.177 (3.177)	GS 32.047 (32.047)	mem 40.180
Train: [30][425/750]	BT 0.032 (1.177)	DT 0.002 (1.136)	loss 7.562 (7.562)	prob 3.240 (3.240)	GS 32.891 (32.891)	mem 39.866
Train: [30][430/750]	BT 0.040 (1.164)	DT 0.002 (1.123)	loss 7.322 (7.322)	prob 3.329 (3.329)	GS 34.812 (34.812)	mem 39.981
Train: [30][435/750]	BT 0.048 (1.180)	DT 0.002 (1.138)	loss 7.280 (7.280)	prob 3.342 (3.342)	GS 28.203 (28.203)	mem 39.836
Train: [30][440/750]	BT 0.051 (1.167)	DT 0.010 (1.125)	loss 7.114 (7.114)	prob 3.467 (3.467)	GS 30.328 (30.328)	mem 39.836
Train: [30][445/750]	BT 0.058 (1.154)	DT 0.002 (1.113)	loss 7.243 (7.243)	prob 3.046 (3.046)	GS 32.219 (32.219)	mem 39.920
Train: [30][450/750]	BT 0.031 (1.168)	DT 0.001 (1.126)	loss 7.057 (7.057)	prob 3.086 (3.086)	GS 33.406 (33.406)	mem 39.837
Train: [30][455/750]	BT 0.032 (1.155)	DT 0.002 (1.114)	loss 7.213 (7.213)	prob 3.729 (3.729)	GS 52.500 (52.500)	mem 39.838
Train: [30][460/750]	BT 0.051 (1.174)	DT 0.001 (1.132)	loss 7.187 (7.187)	prob 3.358 (3.358)	GS 36.219 (36.219)	mem 40.091
Train: [30][465/750]	BT 0.055 (1.162)	DT 0.002 (1.120)	loss 7.558 (7.558)	prob 2.830 (2.830)	GS 33.312 (33.312)	mem 39.890
Train: [30][470/750]	BT 13.692 (1.179)	DT 13.661 (1.137)	loss 7.816 (7.816)	prob 2.796 (2.796)	GS 34.859 (34.859)	mem 40.056
Train: [30][475/750]	BT 0.043 (1.167)	DT 0.001 (1.125)	loss 7.304 (7.304)	prob 2.729 (2.729)	GS 29.422 (29.422)	mem 39.869
Train: [30][480/750]	BT 0.073 (1.155)	DT 0.003 (1.114)	loss 7.213 (7.213)	prob 3.492 (3.492)	GS 34.047 (34.047)	mem 39.903
Train: [30][485/750]	BT 0.036 (1.165)	DT 0.002 (1.124)	loss 7.802 (7.802)	prob 2.541 (2.541)	GS 27.125 (27.125)	mem 39.997
Train: [30][490/750]	BT 0.047 (1.154)	DT 0.007 (1.112)	loss 7.405 (7.405)	prob 2.866 (2.866)	GS 35.531 (35.531)	mem 39.976
Train: [30][495/750]	BT 0.065 (1.169)	DT 0.024 (1.127)	loss 7.634 (7.634)	prob 2.889 (2.889)	GS 38.688 (38.688)	mem 40.053
Train: [30][500/750]	BT 0.030 (1.157)	DT 0.001 (1.116)	loss 7.527 (7.527)	prob 3.209 (3.209)	GS 31.766 (31.766)	mem 39.987
Train: [30][505/750]	BT 0.081 (1.148)	DT 0.014 (1.106)	loss 7.353 (7.353)	prob 2.808 (2.808)	GS 32.641 (32.641)	mem 39.951
Train: [30][510/750]	BT 0.092 (1.163)	DT 0.012 (1.121)	loss 7.163 (7.163)	prob 3.151 (3.151)	GS 32.266 (32.266)	mem 40.200
Train: [30][515/750]	BT 0.026 (1.152)	DT 0.002 (1.110)	loss 7.175 (7.175)	prob 2.814 (2.814)	GS 29.156 (29.156)	mem 39.913
Train: [30][520/750]	BT 0.032 (1.166)	DT 0.001 (1.124)	loss 7.252 (7.252)	prob 2.738 (2.738)	GS 33.672 (33.672)	mem 40.029
Train: [30][525/750]	BT 0.048 (1.155)	DT 0.001 (1.113)	loss 7.338 (7.338)	prob 2.219 (2.219)	GS 29.656 (29.656)	mem 40.029
Train: [30][530/750]	BT 8.174 (1.165)	DT 8.141 (1.123)	loss 7.186 (7.186)	prob 2.907 (2.907)	GS 32.422 (32.422)	mem 40.079
Train: [30][535/750]	BT 0.060 (1.154)	DT 0.012 (1.113)	loss 7.369 (7.369)	prob 2.480 (2.480)	GS 28.594 (28.594)	mem 40.082
Train: [30][540/750]	BT 0.103 (1.145)	DT 0.034 (1.103)	loss 7.202 (7.202)	prob 2.930 (2.930)	GS 30.656 (30.656)	mem 40.002
Train: [30][545/750]	BT 0.032 (1.158)	DT 0.001 (1.116)	loss 7.488 (7.488)	prob 2.343 (2.343)	GS 28.547 (28.547)	mem 40.005
Train: [30][550/750]	BT 0.086 (1.148)	DT 0.008 (1.106)	loss 7.021 (7.021)	prob 2.899 (2.899)	GS 30.578 (30.578)	mem 40.096
Train: [30][555/750]	BT 0.028 (1.160)	DT 0.001 (1.118)	loss 7.151 (7.151)	prob 2.887 (2.887)	GS 33.656 (33.656)	mem 39.936
Train: [30][560/750]	BT 0.024 (1.150)	DT 0.001 (1.108)	loss 7.548 (7.548)	prob 2.978 (2.978)	GS 32.891 (32.891)	mem 39.939
Train: [30][565/750]	BT 0.047 (1.140)	DT 0.004 (1.098)	loss 7.078 (7.078)	prob 2.846 (2.846)	GS 29.031 (29.031)	mem 39.991
Train: [30][570/750]	BT 0.021 (1.152)	DT 0.001 (1.110)	loss 7.067 (7.067)	prob 2.894 (2.894)	GS 36.094 (36.094)	mem 40.003
Train: [30][575/750]	BT 0.036 (1.142)	DT 0.002 (1.100)	loss 6.939 (6.939)	prob 3.287 (3.287)	GS 30.000 (30.000)	mem 40.047
Train: [30][580/750]	BT 0.022 (1.153)	DT 0.001 (1.111)	loss 7.416 (7.416)	prob 3.082 (3.082)	GS 31.688 (31.688)	mem 39.944
Train: [30][585/750]	BT 0.034 (1.143)	DT 0.002 (1.102)	loss 7.260 (7.260)	prob 2.613 (2.613)	GS 30.266 (30.266)	mem 39.941
Train: [30][590/750]	BT 10.181 (1.151)	DT 10.150 (1.110)	loss 7.014 (7.014)	prob 2.826 (2.826)	GS 33.547 (33.547)	mem 40.039
Train: [30][595/750]	BT 0.040 (1.142)	DT 0.001 (1.100)	loss 7.076 (7.076)	prob 2.717 (2.717)	GS 35.516 (35.516)	mem 40.039
Train: [30][600/750]	BT 0.040 (1.139)	DT 0.013 (1.097)	loss 7.043 (7.043)	prob 2.438 (2.438)	GS 29.859 (29.859)	mem 39.975
Train: [30][605/750]	BT 0.050 (1.141)	DT 0.004 (1.099)	loss 7.561 (7.561)	prob 2.974 (2.974)	GS 30.781 (30.781)	mem 40.092
Train: [30][610/750]	BT 0.075 (1.142)	DT 0.001 (1.100)	loss 7.353 (7.353)	prob 2.819 (2.819)	GS 33.531 (33.531)	mem 40.141
Train: [30][615/750]	BT 0.023 (1.141)	DT 0.001 (1.099)	loss 7.062 (7.062)	prob 2.745 (2.745)	GS 30.594 (30.594)	mem 40.007
Train: [30][620/750]	BT 0.077 (1.138)	DT 0.008 (1.096)	loss 7.266 (7.266)	prob 2.774 (2.774)	GS 31.500 (31.500)	mem 40.025
Train: [30][625/750]	BT 0.050 (1.131)	DT 0.005 (1.089)	loss 7.264 (7.264)	prob 2.451 (2.451)	GS 29.406 (29.406)	mem 40.025
Train: [30][630/750]	BT 0.119 (1.136)	DT 0.092 (1.094)	loss 7.113 (7.113)	prob 2.630 (2.630)	GS 34.547 (34.547)	mem 39.992
Train: [30][635/750]	BT 0.023 (1.132)	DT 0.001 (1.090)	loss 7.470 (7.470)	prob 2.345 (2.345)	GS 33.422 (33.422)	mem 40.032
Train: [30][640/750]	BT 0.032 (1.144)	DT 0.002 (1.102)	loss 7.062 (7.062)	prob 2.802 (2.802)	GS 33.500 (33.500)	mem 39.989
Train: [30][645/750]	BT 0.035 (1.136)	DT 0.002 (1.094)	loss 7.117 (7.117)	prob 2.356 (2.356)	GS 35.094 (35.094)	mem 39.992
Train: [30][650/750]	BT 11.824 (1.146)	DT 11.801 (1.104)	loss 7.024 (7.024)	prob 2.731 (2.731)	GS 34.312 (34.312)	mem 40.054
Train: [30][655/750]	BT 0.033 (1.137)	DT 0.002 (1.095)	loss 7.258 (7.258)	prob 2.929 (2.929)	GS 31.266 (31.266)	mem 40.142
arpack error, retry= 0
arpack error, retry= 0
Train: [30][660/750]	BT 1.370 (1.131)	DT 1.314 (1.089)	loss 7.298 (7.298)	prob 2.702 (2.702)	GS 30.625 (30.625)	mem 40.103
Train: [30][665/750]	BT 0.060 (1.140)	DT 0.009 (1.098)	loss 7.504 (7.504)	prob 2.914 (2.914)	GS 30.172 (30.172)	mem 40.061
Train: [30][670/750]	BT 0.046 (1.132)	DT 0.003 (1.090)	loss 7.441 (7.441)	prob 2.901 (2.901)	GS 30.734 (30.734)	mem 40.112
Train: [30][675/750]	BT 0.045 (1.141)	DT 0.008 (1.099)	loss 6.866 (6.866)	prob 3.234 (3.234)	GS 32.047 (32.047)	mem 39.990
Train: [30][680/750]	BT 0.045 (1.133)	DT 0.002 (1.091)	loss 6.997 (6.997)	prob 2.545 (2.545)	GS 34.266 (34.266)	mem 40.006
Train: [30][685/750]	BT 0.034 (1.127)	DT 0.002 (1.085)	loss 7.227 (7.227)	prob 2.417 (2.417)	GS 29.906 (29.906)	mem 40.168
Train: [30][690/750]	BT 0.033 (1.138)	DT 0.001 (1.096)	loss 7.247 (7.247)	prob 2.596 (2.596)	GS 33.188 (33.188)	mem 40.040
Train: [30][695/750]	BT 0.053 (1.130)	DT 0.001 (1.088)	loss 7.267 (7.267)	prob 2.519 (2.519)	GS 28.984 (28.984)	mem 40.040
Train: [30][700/750]	BT 1.493 (1.140)	DT 1.450 (1.098)	loss 7.054 (7.054)	prob 2.706 (2.706)	GS 31.594 (31.594)	mem 39.995
Train: [30][705/750]	BT 0.044 (1.135)	DT 0.005 (1.093)	loss 7.097 (7.097)	prob 2.578 (2.578)	GS 31.891 (31.891)	mem 39.857
Train: [30][710/750]	BT 7.778 (1.138)	DT 7.723 (1.096)	loss 7.032 (7.032)	prob 3.047 (3.047)	GS 37.000 (37.000)	mem 40.041
Train: [30][715/750]	BT 0.089 (1.132)	DT 0.001 (1.090)	loss 7.291 (7.291)	prob 2.092 (2.092)	GS 26.156 (26.156)	mem 40.022
Train: [30][720/750]	BT 0.089 (1.130)	DT 0.007 (1.088)	loss 7.244 (7.244)	prob 3.133 (3.133)	GS 28.953 (28.953)	mem 40.119
Train: [30][725/750]	BT 0.058 (1.133)	DT 0.007 (1.091)	loss 6.966 (6.966)	prob 2.627 (2.627)	GS 28.844 (28.844)	mem 39.971
Train: [30][730/750]	BT 0.032 (1.134)	DT 0.001 (1.092)	loss 7.324 (7.324)	prob 3.040 (3.040)	GS 34.453 (34.453)	mem 39.819
Train: [30][735/750]	BT 0.050 (1.133)	DT 0.009 (1.090)	loss 7.103 (7.103)	prob 2.349 (2.349)	GS 31.172 (31.172)	mem 36.791
Train: [30][740/750]	BT 2.929 (1.132)	DT 2.895 (1.090)	loss 7.070 (7.070)	prob 2.600 (2.600)	GS 33.266 (33.266)	mem 19.548
Train: [30][745/750]	BT 0.088 (1.125)	DT 0.002 (1.082)	loss 7.321 (7.321)	prob 2.862 (2.862)	GS 33.312 (33.312)	mem 19.589
Train: [30][750/750]	BT 0.332 (1.118)	DT 0.312 (1.076)	loss 7.323 (7.323)	prob 3.008 (3.008)	GS 31.344 (31.344)	mem 16.637
Train: [30][755/750]	BT 0.026 (1.116)	DT 0.001 (1.073)	loss 7.306 (7.306)	prob 2.738 (2.738)	GS 26.812 (26.812)	mem 7.658
epoch 30, total time 842.53
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [31][1/750]	BT 23.254 (23.254)	DT 23.190 (23.190)	loss 7.051 (7.051)	prob 2.523 (2.523)	GS 40.578 (40.578)	mem 38.662
Train: [31][5/750]	BT 0.116 (4.704)	DT 0.013 (4.641)	loss 7.001 (7.001)	prob 2.494 (2.494)	GS 28.656 (28.656)	mem 39.002
Train: [31][10/750]	BT 0.033 (2.952)	DT 0.001 (2.898)	loss 7.119 (7.119)	prob 2.913 (2.913)	GS 35.422 (35.422)	mem 38.777
Train: [31][15/750]	BT 0.030 (2.602)	DT 0.001 (2.556)	loss 7.064 (7.064)	prob 2.881 (2.881)	GS 31.578 (31.578)	mem 38.862
Train: [31][20/750]	BT 0.033 (1.966)	DT 0.003 (1.918)	loss 6.829 (6.829)	prob 3.573 (3.573)	GS 32.953 (32.953)	mem 38.779
Train: [31][25/750]	BT 0.050 (1.753)	DT 0.003 (1.697)	loss 7.035 (7.035)	prob 2.986 (2.986)	GS 28.406 (28.406)	mem 39.018
Train: [31][30/750]	BT 0.039 (1.897)	DT 0.006 (1.843)	loss 6.865 (6.865)	prob 2.954 (2.954)	GS 33.344 (33.344)	mem 38.879
Train: [31][35/750]	BT 0.030 (1.735)	DT 0.001 (1.681)	loss 7.319 (7.319)	prob 2.126 (2.126)	GS 35.812 (35.812)	mem 39.086
Train: [31][40/750]	BT 0.101 (1.804)	DT 0.002 (1.750)	loss 6.965 (6.965)	prob 3.257 (3.257)	GS 33.516 (33.516)	mem 39.269
Train: [31][45/750]	BT 0.026 (1.609)	DT 0.001 (1.556)	loss 7.048 (7.048)	prob 2.919 (2.919)	GS 33.484 (33.484)	mem 38.920
Train: [31][50/750]	BT 7.404 (1.660)	DT 7.331 (1.609)	loss 6.995 (6.995)	prob 3.173 (3.173)	GS 32.547 (32.547)	mem 39.034
Train: [31][55/750]	BT 0.033 (1.514)	DT 0.002 (1.463)	loss 7.140 (7.140)	prob 2.634 (2.634)	GS 30.219 (30.219)	mem 39.046
Train: [31][60/750]	BT 0.046 (1.463)	DT 0.001 (1.413)	loss 6.869 (6.869)	prob 2.803 (2.803)	GS 35.891 (35.891)	mem 39.126
Train: [31][65/750]	BT 0.049 (1.482)	DT 0.007 (1.433)	loss 6.939 (6.939)	prob 3.397 (3.397)	GS 31.375 (31.375)	mem 39.191
Train: [31][70/750]	BT 3.394 (1.437)	DT 3.347 (1.388)	loss 6.875 (6.875)	prob 3.158 (3.158)	GS 37.625 (37.625)	mem 39.106
Train: [31][75/750]	BT 0.071 (1.498)	DT 0.009 (1.450)	loss 6.952 (6.952)	prob 3.022 (3.022)	GS 30.188 (30.188)	mem 39.238
Train: [31][80/750]	BT 0.041 (1.407)	DT 0.005 (1.359)	loss 6.704 (6.704)	prob 3.536 (3.536)	GS 27.906 (27.906)	mem 39.245
Train: [31][85/750]	BT 0.032 (1.348)	DT 0.001 (1.301)	loss 7.035 (7.035)	prob 2.566 (2.566)	GS 35.031 (35.031)	mem 39.059
Train: [31][90/750]	BT 0.026 (1.420)	DT 0.001 (1.373)	loss 7.085 (7.085)	prob 3.276 (3.276)	GS 34.219 (34.219)	mem 39.136
Train: [31][95/750]	BT 0.040 (1.360)	DT 0.012 (1.313)	loss 7.069 (7.069)	prob 3.193 (3.193)	GS 32.156 (32.156)	mem 39.159
Train: [31][100/750]	BT 0.027 (1.385)	DT 0.001 (1.339)	loss 7.175 (7.175)	prob 2.853 (2.853)	GS 32.422 (32.422)	mem 39.413
Train: [31][105/750]	BT 0.036 (1.347)	DT 0.001 (1.302)	loss 7.208 (7.208)	prob 2.468 (2.468)	GS 34.469 (34.469)	mem 39.664
Train: [31][110/750]	BT 7.567 (1.365)	DT 7.535 (1.320)	loss 6.906 (6.906)	prob 3.191 (3.191)	GS 37.672 (37.672)	mem 39.517
Train: [31][115/750]	BT 0.036 (1.309)	DT 0.001 (1.263)	loss 7.214 (7.214)	prob 2.559 (2.559)	GS 32.812 (32.812)	mem 39.486
Train: [31][120/750]	BT 0.034 (1.301)	DT 0.001 (1.256)	loss 7.014 (7.014)	prob 3.016 (3.016)	GS 32.312 (32.312)	mem 39.500
Train: [31][125/750]	BT 0.067 (1.325)	DT 0.019 (1.280)	loss 7.134 (7.134)	prob 2.658 (2.658)	GS 31.469 (31.469)	mem 39.410
Train: [31][130/750]	BT 0.038 (1.280)	DT 0.002 (1.235)	loss 7.227 (7.227)	prob 3.118 (3.118)	GS 33.156 (33.156)	mem 39.348
Train: [31][135/750]	BT 0.033 (1.331)	DT 0.001 (1.287)	loss 7.280 (7.280)	prob 2.833 (2.833)	GS 39.250 (39.250)	mem 39.482
Train: [31][140/750]	BT 3.123 (1.307)	DT 3.088 (1.263)	loss 7.248 (7.248)	prob 3.237 (3.237)	GS 38.297 (38.297)	mem 39.589
Train: [31][145/750]	BT 0.075 (1.264)	DT 0.016 (1.220)	loss 7.336 (7.336)	prob 2.486 (2.486)	GS 30.938 (30.938)	mem 39.521
Train: [31][150/750]	BT 0.095 (1.282)	DT 0.005 (1.237)	loss 7.056 (7.056)	prob 2.948 (2.948)	GS 34.859 (34.859)	mem 39.859
Train: [31][155/750]	BT 0.032 (1.284)	DT 0.002 (1.239)	loss 7.192 (7.192)	prob 3.078 (3.078)	GS 35.000 (35.000)	mem 39.771
Train: [31][160/750]	BT 0.020 (1.298)	DT 0.001 (1.254)	loss 7.227 (7.227)	prob 3.013 (3.013)	GS 33.625 (33.625)	mem 39.819
Train: [31][165/750]	BT 0.025 (1.292)	DT 0.001 (1.247)	loss 7.071 (7.071)	prob 3.212 (3.212)	GS 33.688 (33.688)	mem 40.018
Train: [31][170/750]	BT 7.977 (1.302)	DT 7.934 (1.258)	loss 7.124 (7.124)	prob 3.231 (3.231)	GS 35.969 (35.969)	mem 39.912
Train: [31][175/750]	BT 0.034 (1.266)	DT 0.001 (1.222)	loss 7.191 (7.191)	prob 3.229 (3.229)	GS 35.766 (35.766)	mem 39.874
Train: [31][180/750]	BT 0.037 (1.252)	DT 0.001 (1.208)	loss 7.057 (7.057)	prob 2.544 (2.544)	GS 36.484 (36.484)	mem 39.872
Train: [31][185/750]	BT 0.039 (1.266)	DT 0.001 (1.223)	loss 7.177 (7.177)	prob 2.675 (2.675)	GS 28.125 (28.125)	mem 39.821
Train: [31][190/750]	BT 0.033 (1.271)	DT 0.001 (1.227)	loss 7.220 (7.220)	prob 2.885 (2.885)	GS 35.375 (35.375)	mem 39.774
Train: [31][195/750]	BT 0.054 (1.267)	DT 0.008 (1.223)	loss 6.776 (6.776)	prob 3.277 (3.277)	GS 35.562 (35.562)	mem 39.825
Train: [31][200/750]	BT 4.339 (1.258)	DT 4.310 (1.214)	loss 7.011 (7.011)	prob 3.125 (3.125)	GS 31.016 (31.016)	mem 39.786
Train: [31][205/750]	BT 0.041 (1.228)	DT 0.002 (1.185)	loss 6.793 (6.793)	prob 3.062 (3.062)	GS 32.375 (32.375)	mem 39.975
Train: [31][210/750]	BT 0.039 (1.240)	DT 0.002 (1.197)	loss 7.037 (7.037)	prob 3.212 (3.212)	GS 32.984 (32.984)	mem 39.866
Train: [31][215/750]	BT 0.023 (1.229)	DT 0.001 (1.186)	loss 7.101 (7.101)	prob 3.055 (3.055)	GS 31.078 (31.078)	mem 39.801
Train: [31][220/750]	BT 0.033 (1.240)	DT 0.001 (1.197)	loss 7.000 (7.000)	prob 3.121 (3.121)	GS 34.281 (34.281)	mem 39.710
Train: [31][225/750]	BT 0.048 (1.237)	DT 0.016 (1.194)	loss 7.107 (7.107)	prob 2.918 (2.918)	GS 33.078 (33.078)	mem 39.680
Train: [31][230/750]	BT 3.469 (1.226)	DT 3.437 (1.183)	loss 7.126 (7.126)	prob 3.203 (3.203)	GS 38.516 (38.516)	mem 39.701
Train: [31][235/750]	BT 0.032 (1.201)	DT 0.001 (1.158)	loss 6.971 (6.971)	prob 3.055 (3.055)	GS 32.297 (32.297)	mem 39.701
Train: [31][240/750]	BT 0.088 (1.219)	DT 0.001 (1.176)	loss 6.905 (6.905)	prob 2.908 (2.908)	GS 31.609 (31.609)	mem 39.842
Train: [31][245/750]	BT 0.118 (1.201)	DT 0.030 (1.157)	loss 7.041 (7.041)	prob 3.119 (3.119)	GS 34.922 (34.922)	mem 40.007
Train: [31][250/750]	BT 0.048 (1.222)	DT 0.011 (1.178)	loss 6.868 (6.868)	prob 2.797 (2.797)	GS 32.875 (32.875)	mem 39.832
Train: [31][255/750]	BT 0.033 (1.214)	DT 0.002 (1.170)	loss 6.871 (6.871)	prob 3.749 (3.749)	GS 28.781 (28.781)	mem 39.836
Train: [31][260/750]	BT 7.023 (1.218)	DT 6.960 (1.175)	loss 7.124 (7.124)	prob 3.057 (3.057)	GS 30.969 (30.969)	mem 39.851
Train: [31][265/750]	BT 0.121 (1.197)	DT 0.007 (1.153)	loss 7.322 (7.322)	prob 2.618 (2.618)	GS 30.031 (30.031)	mem 39.850
Train: [31][270/750]	BT 0.032 (1.189)	DT 0.001 (1.144)	loss 6.898 (6.898)	prob 3.781 (3.781)	GS 30.844 (30.844)	mem 39.793
Train: [31][275/750]	BT 0.034 (1.197)	DT 0.002 (1.153)	loss 7.076 (7.076)	prob 3.406 (3.406)	GS 29.891 (29.891)	mem 39.909
Train: [31][280/750]	BT 0.031 (1.194)	DT 0.001 (1.150)	loss 6.862 (6.862)	prob 2.789 (2.789)	GS 37.281 (37.281)	mem 39.897
Train: [31][285/750]	BT 0.032 (1.206)	DT 0.001 (1.162)	loss 7.289 (7.289)	prob 3.117 (3.117)	GS 33.812 (33.812)	mem 39.851
Train: [31][290/750]	BT 3.791 (1.199)	DT 3.760 (1.155)	loss 6.940 (6.940)	prob 3.087 (3.087)	GS 33.062 (33.062)	mem 39.859
Train: [31][295/750]	BT 0.035 (1.180)	DT 0.001 (1.136)	loss 7.346 (7.346)	prob 2.987 (2.987)	GS 29.172 (29.172)	mem 39.862
Train: [31][300/750]	BT 0.052 (1.188)	DT 0.012 (1.145)	loss 7.061 (7.061)	prob 2.773 (2.773)	GS 33.812 (33.812)	mem 39.893
Train: [31][305/750]	BT 0.032 (1.184)	DT 0.001 (1.141)	loss 7.190 (7.190)	prob 3.585 (3.585)	GS 29.547 (29.547)	mem 39.880
Train: [31][310/750]	BT 0.030 (1.190)	DT 0.001 (1.147)	loss 7.204 (7.204)	prob 3.800 (3.800)	GS 35.219 (35.219)	mem 39.890
Train: [31][315/750]	BT 0.033 (1.186)	DT 0.001 (1.143)	loss 6.980 (6.980)	prob 3.451 (3.451)	GS 28.422 (28.422)	mem 39.892
Train: [31][320/750]	BT 7.839 (1.193)	DT 7.777 (1.149)	loss 6.922 (6.922)	prob 3.081 (3.081)	GS 32.297 (32.297)	mem 39.939
Train: [31][325/750]	BT 0.055 (1.175)	DT 0.012 (1.132)	loss 7.059 (7.059)	prob 3.377 (3.377)	GS 32.078 (32.078)	mem 39.877
Train: [31][330/750]	BT 0.050 (1.172)	DT 0.003 (1.128)	loss 7.051 (7.051)	prob 3.974 (3.974)	GS 29.625 (29.625)	mem 39.941
Train: [31][335/750]	BT 0.053 (1.175)	DT 0.012 (1.132)	loss 7.066 (7.066)	prob 3.022 (3.022)	GS 37.062 (37.062)	mem 39.882
Train: [31][340/750]	BT 0.028 (1.173)	DT 0.001 (1.130)	loss 7.259 (7.259)	prob 3.566 (3.566)	GS 33.734 (33.734)	mem 39.972
Train: [31][345/750]	BT 0.084 (1.176)	DT 0.001 (1.132)	loss 7.296 (7.296)	prob 3.413 (3.413)	GS 29.656 (29.656)	mem 39.936
Train: [31][350/750]	BT 2.815 (1.168)	DT 2.760 (1.124)	loss 7.132 (7.132)	prob 3.509 (3.509)	GS 30.734 (30.734)	mem 39.963
Train: [31][355/750]	BT 0.044 (1.152)	DT 0.005 (1.108)	loss 7.317 (7.317)	prob 3.564 (3.564)	GS 33.422 (33.422)	mem 39.965
Train: [31][360/750]	BT 0.023 (1.162)	DT 0.001 (1.119)	loss 7.040 (7.040)	prob 3.344 (3.344)	GS 32.781 (32.781)	mem 39.941
Train: [31][365/750]	BT 0.056 (1.156)	DT 0.003 (1.113)	loss 7.189 (7.189)	prob 3.572 (3.572)	GS 30.047 (30.047)	mem 39.952
Train: [31][370/750]	BT 0.029 (1.163)	DT 0.001 (1.120)	loss 6.974 (6.974)	prob 4.013 (4.013)	GS 36.219 (36.219)	mem 39.886
Train: [31][375/750]	BT 0.040 (1.148)	DT 0.001 (1.105)	loss 7.120 (7.120)	prob 3.226 (3.226)	GS 33.750 (33.750)	mem 39.890
Train: [31][380/750]	BT 13.111 (1.168)	DT 13.081 (1.125)	loss 6.992 (6.992)	prob 3.044 (3.044)	GS 31.547 (31.547)	mem 39.892
Train: [31][385/750]	BT 0.057 (1.154)	DT 0.011 (1.111)	loss 7.094 (7.094)	prob 3.013 (3.013)	GS 36.672 (36.672)	mem 39.952
Train: [31][390/750]	BT 0.055 (1.140)	DT 0.001 (1.096)	loss 6.987 (6.987)	prob 3.146 (3.146)	GS 36.328 (36.328)	mem 39.917
Train: [31][395/750]	BT 0.047 (1.159)	DT 0.014 (1.116)	loss 7.083 (7.083)	prob 2.413 (2.413)	GS 30.438 (30.438)	mem 40.181
Train: [31][400/750]	BT 0.050 (1.146)	DT 0.002 (1.102)	loss 7.066 (7.066)	prob 2.781 (2.781)	GS 35.250 (35.250)	mem 40.231
Train: [31][405/750]	BT 0.037 (1.155)	DT 0.002 (1.112)	loss 7.009 (7.009)	prob 2.781 (2.781)	GS 31.062 (31.062)	mem 40.057
Train: [31][410/750]	BT 0.031 (1.154)	DT 0.001 (1.111)	loss 6.872 (6.872)	prob 4.636 (4.636)	GS 35.328 (35.328)	mem 39.965
Train: [31][415/750]	BT 0.055 (1.141)	DT 0.003 (1.098)	loss 7.110 (7.110)	prob 3.477 (3.477)	GS 29.344 (29.344)	mem 40.049
Train: [31][420/750]	BT 0.034 (1.156)	DT 0.001 (1.113)	loss 7.162 (7.162)	prob 2.791 (2.791)	GS 39.109 (39.109)	mem 39.957
Train: [31][425/750]	BT 0.035 (1.143)	DT 0.001 (1.100)	loss 7.050 (7.050)	prob 3.226 (3.226)	GS 28.547 (28.547)	mem 39.960
Train: [31][430/750]	BT 4.202 (1.165)	DT 4.170 (1.122)	loss 7.107 (7.107)	prob 3.633 (3.633)	GS 37.031 (37.031)	mem 39.946
Train: [31][435/750]	BT 0.024 (1.152)	DT 0.001 (1.109)	loss 7.031 (7.031)	prob 3.433 (3.433)	GS 33.312 (33.312)	mem 39.946
Train: [31][440/750]	BT 9.946 (1.162)	DT 9.915 (1.119)	loss 7.172 (7.172)	prob 2.918 (2.918)	GS 38.359 (38.359)	mem 39.921
Train: [31][445/750]	BT 0.049 (1.161)	DT 0.012 (1.117)	loss 7.091 (7.091)	prob 3.368 (3.368)	GS 33.047 (33.047)	mem 39.961
Train: [31][450/750]	BT 0.032 (1.148)	DT 0.001 (1.105)	loss 7.212 (7.212)	prob 3.360 (3.360)	GS 34.234 (34.234)	mem 39.971
Train: [31][455/750]	BT 0.074 (1.166)	DT 0.005 (1.122)	loss 7.153 (7.153)	prob 2.708 (2.708)	GS 29.266 (29.266)	mem 40.150
Train: [31][460/750]	BT 0.071 (1.154)	DT 0.022 (1.110)	loss 7.281 (7.281)	prob 2.313 (2.313)	GS 30.266 (30.266)	mem 40.012
Train: [31][465/750]	BT 0.035 (1.145)	DT 0.001 (1.101)	loss 7.294 (7.294)	prob 2.613 (2.613)	GS 31.078 (31.078)	mem 40.078
Train: [31][470/750]	BT 0.031 (1.157)	DT 0.001 (1.114)	loss 6.910 (6.910)	prob 3.093 (3.093)	GS 34.375 (34.375)	mem 39.980
Train: [31][475/750]	BT 0.032 (1.145)	DT 0.001 (1.102)	loss 6.945 (6.945)	prob 3.326 (3.326)	GS 30.703 (30.703)	mem 39.980
Train: [31][480/750]	BT 0.100 (1.159)	DT 0.021 (1.116)	loss 6.909 (6.909)	prob 3.744 (3.744)	GS 35.656 (35.656)	mem 40.029
Train: [31][485/750]	BT 0.028 (1.147)	DT 0.001 (1.104)	loss 7.019 (7.019)	prob 3.280 (3.280)	GS 29.969 (29.969)	mem 40.029
Train: [31][490/750]	BT 11.563 (1.160)	DT 11.510 (1.117)	loss 7.109 (7.109)	prob 3.038 (3.038)	GS 32.000 (32.000)	mem 39.950
Train: [31][495/750]	BT 0.022 (1.148)	DT 0.001 (1.105)	loss 6.979 (6.979)	prob 3.245 (3.245)	GS 33.500 (33.500)	mem 39.950
Train: [31][500/750]	BT 1.562 (1.140)	DT 1.520 (1.097)	loss 7.240 (7.240)	prob 2.868 (2.868)	GS 38.922 (38.922)	mem 39.919
Train: [31][505/750]	BT 0.030 (1.151)	DT 0.001 (1.108)	loss 7.086 (7.086)	prob 2.463 (2.463)	GS 26.391 (26.391)	mem 39.939
Train: [31][510/750]	BT 0.033 (1.140)	DT 0.001 (1.097)	loss 7.070 (7.070)	prob 3.407 (3.407)	GS 34.672 (34.672)	mem 39.983
Train: [31][515/750]	BT 0.032 (1.151)	DT 0.002 (1.108)	loss 7.057 (7.057)	prob 3.219 (3.219)	GS 30.750 (30.750)	mem 40.011
Train: [31][520/750]	BT 0.065 (1.140)	DT 0.009 (1.097)	loss 7.171 (7.171)	prob 2.729 (2.729)	GS 32.078 (32.078)	mem 40.040
Train: [31][525/750]	BT 0.033 (1.130)	DT 0.002 (1.087)	loss 7.004 (7.004)	prob 2.624 (2.624)	GS 30.734 (30.734)	mem 40.016
Train: [31][530/750]	BT 0.024 (1.149)	DT 0.001 (1.106)	loss 7.269 (7.269)	prob 1.938 (1.938)	GS 35.859 (35.859)	mem 39.996
Train: [31][535/750]	BT 0.032 (1.138)	DT 0.001 (1.095)	loss 7.243 (7.243)	prob 2.329 (2.329)	GS 32.594 (32.594)	mem 39.997
Train: [31][540/750]	BT 0.033 (1.148)	DT 0.001 (1.106)	loss 6.859 (6.859)	prob 2.129 (2.129)	GS 33.672 (33.672)	mem 40.134
Train: [31][545/750]	BT 0.059 (1.138)	DT 0.029 (1.095)	loss 6.976 (6.976)	prob 2.344 (2.344)	GS 24.859 (24.859)	mem 40.038
Train: [31][550/750]	BT 11.577 (1.151)	DT 11.527 (1.108)	loss 7.519 (7.519)	prob 1.819 (1.819)	GS 32.578 (32.578)	mem 39.989
Train: [31][555/750]	BT 0.031 (1.143)	DT 0.002 (1.100)	loss 6.866 (6.866)	prob 2.791 (2.791)	GS 29.062 (29.062)	mem 40.023
Train: [31][560/750]	BT 0.275 (1.134)	DT 0.243 (1.091)	loss 7.033 (7.033)	prob 2.582 (2.582)	GS 31.203 (31.203)	mem 40.047
Train: [31][565/750]	BT 0.093 (1.148)	DT 0.004 (1.104)	loss 7.046 (7.046)	prob 2.370 (2.370)	GS 34.688 (34.688)	mem 40.063
Train: [31][570/750]	BT 0.026 (1.142)	DT 0.001 (1.098)	loss 7.085 (7.085)	prob 2.371 (2.371)	GS 37.188 (37.188)	mem 40.046
Train: [31][575/750]	BT 0.103 (1.150)	DT 0.001 (1.106)	loss 7.057 (7.057)	prob 2.596 (2.596)	GS 32.547 (32.547)	mem 40.077
Train: [31][580/750]	BT 0.057 (1.152)	DT 0.005 (1.108)	loss 7.079 (7.079)	prob 2.583 (2.583)	GS 33.531 (33.531)	mem 39.994
Train: [31][585/750]	BT 0.045 (1.142)	DT 0.013 (1.099)	loss 6.777 (6.777)	prob 3.011 (3.011)	GS 31.125 (31.125)	mem 39.996
Train: [31][590/750]	BT 9.049 (1.154)	DT 9.009 (1.111)	loss 7.156 (7.156)	prob 2.553 (2.553)	GS 36.875 (36.875)	mem 40.136
Train: [31][595/750]	BT 0.145 (1.145)	DT 0.010 (1.101)	loss 7.070 (7.070)	prob 2.302 (2.302)	GS 28.203 (28.203)	mem 40.201
Train: [31][600/750]	BT 0.055 (1.145)	DT 0.004 (1.101)	loss 7.232 (7.232)	prob 2.395 (2.395)	GS 33.859 (33.859)	mem 40.060
Train: [31][605/750]	BT 0.064 (1.148)	DT 0.022 (1.104)	loss 7.402 (7.402)	prob 1.910 (1.910)	GS 31.328 (31.328)	mem 40.083
Train: [31][610/750]	BT 4.211 (1.146)	DT 4.179 (1.102)	loss 6.960 (6.960)	prob 2.476 (2.476)	GS 32.719 (32.719)	mem 40.102
Train: [31][615/750]	BT 0.060 (1.149)	DT 0.003 (1.105)	loss 6.852 (6.852)	prob 2.972 (2.972)	GS 28.281 (28.281)	mem 40.039
Train: [31][620/750]	BT 0.140 (1.140)	DT 0.001 (1.096)	loss 6.949 (6.949)	prob 2.381 (2.381)	GS 36.047 (36.047)	mem 40.074
Train: [31][625/750]	BT 0.159 (1.146)	DT 0.010 (1.102)	loss 7.091 (7.091)	prob 2.289 (2.289)	GS 35.938 (35.938)	mem 40.083
Train: [31][630/750]	BT 0.033 (1.143)	DT 0.002 (1.098)	loss 7.092 (7.092)	prob 2.593 (2.593)	GS 33.469 (33.469)	mem 40.186
Train: [31][635/750]	BT 0.071 (1.137)	DT 0.002 (1.093)	loss 6.920 (6.920)	prob 2.690 (2.690)	GS 32.781 (32.781)	mem 40.071
Train: [31][640/750]	BT 0.041 (1.142)	DT 0.001 (1.098)	loss 6.813 (6.813)	prob 2.556 (2.556)	GS 30.891 (30.891)	mem 40.105
Train: [31][645/750]	BT 0.037 (1.134)	DT 0.001 (1.090)	loss 7.034 (7.034)	prob 2.386 (2.386)	GS 31.609 (31.609)	mem 40.104
Train: [31][650/750]	BT 0.503 (1.144)	DT 0.471 (1.100)	loss 7.026 (7.026)	prob 2.293 (2.293)	GS 31.984 (31.984)	mem 40.106
Train: [31][655/750]	BT 0.031 (1.136)	DT 0.001 (1.092)	loss 7.280 (7.280)	prob 2.385 (2.385)	GS 28.375 (28.375)	mem 40.105
Train: [31][660/750]	BT 12.063 (1.146)	DT 11.966 (1.102)	loss 7.116 (7.116)	prob 2.085 (2.085)	GS 34.547 (34.547)	mem 40.101
Train: [31][665/750]	BT 0.062 (1.141)	DT 0.014 (1.096)	loss 6.996 (6.996)	prob 2.562 (2.562)	GS 30.422 (30.422)	mem 40.129
Train: [31][670/750]	BT 0.083 (1.133)	DT 0.001 (1.088)	loss 6.818 (6.818)	prob 3.357 (3.357)	GS 32.344 (32.344)	mem 40.209
Train: [31][675/750]	BT 0.031 (1.141)	DT 0.001 (1.096)	loss 7.123 (7.123)	prob 2.637 (2.637)	GS 30.781 (30.781)	mem 40.109
Train: [31][680/750]	BT 0.084 (1.133)	DT 0.003 (1.088)	loss 6.965 (6.965)	prob 2.492 (2.492)	GS 35.859 (35.859)	mem 40.109
Train: [31][685/750]	BT 0.033 (1.146)	DT 0.002 (1.102)	loss 7.169 (7.169)	prob 2.493 (2.493)	GS 31.656 (31.656)	mem 39.974
Train: [31][690/750]	BT 0.029 (1.138)	DT 0.001 (1.094)	loss 6.889 (6.889)	prob 2.459 (2.459)	GS 31.281 (31.281)	mem 39.973
Train: [31][695/750]	BT 0.055 (1.132)	DT 0.015 (1.088)	loss 7.205 (7.205)	prob 2.232 (2.232)	GS 31.906 (31.906)	mem 39.947
Train: [31][700/750]	BT 0.041 (1.140)	DT 0.002 (1.096)	loss 6.755 (6.755)	prob 2.988 (2.988)	GS 32.484 (32.484)	mem 40.073
Train: [31][705/750]	BT 0.053 (1.132)	DT 0.012 (1.088)	loss 6.963 (6.963)	prob 2.745 (2.745)	GS 32.469 (32.469)	mem 40.195
Train: [31][710/750]	BT 1.263 (1.144)	DT 1.233 (1.100)	loss 6.720 (6.720)	prob 2.924 (2.924)	GS 32.594 (32.594)	mem 40.038
Train: [31][715/750]	BT 0.080 (1.136)	DT 0.006 (1.092)	loss 7.300 (7.300)	prob 2.262 (2.262)	GS 33.906 (33.906)	mem 40.115
Train: [31][720/750]	BT 7.069 (1.144)	DT 7.037 (1.099)	loss 6.878 (6.878)	prob 2.686 (2.686)	GS 35.547 (35.547)	mem 40.058
Train: [31][725/750]	BT 0.085 (1.136)	DT 0.006 (1.092)	loss 7.185 (7.185)	prob 2.756 (2.756)	GS 27.922 (27.922)	mem 40.194
Train: [31][730/750]	BT 8.591 (1.140)	DT 8.559 (1.096)	loss 7.052 (7.052)	prob 2.450 (2.450)	GS 33.891 (33.891)	mem 39.700
Train: [31][735/750]	BT 0.077 (1.139)	DT 0.011 (1.095)	loss 6.962 (6.962)	prob 2.537 (2.537)	GS 31.406 (31.406)	mem 39.501
Train: [31][740/750]	BT 0.035 (1.132)	DT 0.002 (1.088)	loss 7.202 (7.202)	prob 2.717 (2.717)	GS 33.844 (33.844)	mem 39.543
Train: [31][745/750]	BT 0.028 (1.135)	DT 0.007 (1.091)	loss 6.988 (6.988)	prob 2.713 (2.713)	GS 35.781 (35.781)	mem 10.723
Train: [31][750/750]	BT 0.021 (1.127)	DT 0.001 (1.083)	loss 7.240 (7.240)	prob 2.723 (2.723)	GS 37.031 (37.031)	mem 10.687
Train: [31][755/750]	BT 0.034 (1.120)	DT 0.001 (1.076)	loss 7.225 (7.225)	prob 3.145 (3.145)	GS 26.312 (26.312)	mem 10.687
epoch 31, total time 848.83
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [32][1/750]	BT 22.352 (22.352)	DT 22.271 (22.271)	loss 7.041 (7.041)	prob 2.534 (2.534)	GS 39.156 (39.156)	mem 38.443
Train: [32][5/750]	BT 0.064 (4.945)	DT 0.007 (4.888)	loss 6.799 (6.799)	prob 3.050 (3.050)	GS 32.281 (32.281)	mem 38.573
Train: [32][10/750]	BT 1.990 (2.697)	DT 1.940 (2.641)	loss 6.866 (6.866)	prob 3.013 (3.013)	GS 34.906 (34.906)	mem 38.728
Train: [32][15/750]	BT 0.028 (2.542)	DT 0.001 (2.492)	loss 6.878 (6.878)	prob 2.879 (2.879)	GS 34.125 (34.125)	mem 38.830
Train: [32][20/750]	BT 0.032 (1.983)	DT 0.001 (1.934)	loss 7.146 (7.146)	prob 2.437 (2.437)	GS 33.922 (33.922)	mem 38.894
Train: [32][25/750]	BT 6.594 (1.928)	DT 6.533 (1.880)	loss 6.851 (6.851)	prob 3.209 (3.209)	GS 33.688 (33.688)	mem 38.973
Train: [32][30/750]	BT 0.044 (1.870)	DT 0.005 (1.824)	loss 6.744 (6.744)	prob 3.139 (3.139)	GS 33.297 (33.297)	mem 38.938
Train: [32][35/750]	BT 0.035 (1.611)	DT 0.003 (1.564)	loss 7.066 (7.066)	prob 2.893 (2.893)	GS 31.219 (31.219)	mem 38.897
Train: [32][40/750]	BT 0.032 (1.738)	DT 0.001 (1.691)	loss 6.894 (6.894)	prob 3.100 (3.100)	GS 36.219 (36.219)	mem 39.037
Train: [32][45/750]	BT 0.032 (1.551)	DT 0.002 (1.504)	loss 6.857 (6.857)	prob 3.291 (3.291)	GS 28.688 (28.688)	mem 39.069
Train: [32][50/750]	BT 7.947 (1.593)	DT 7.906 (1.546)	loss 6.930 (6.930)	prob 2.882 (2.882)	GS 30.047 (30.047)	mem 39.128
Train: [32][55/750]	BT 0.051 (1.452)	DT 0.003 (1.405)	loss 7.008 (7.008)	prob 2.807 (2.807)	GS 28.375 (28.375)	mem 39.084
Train: [32][60/750]	BT 0.095 (1.414)	DT 0.002 (1.367)	loss 6.982 (6.982)	prob 3.153 (3.153)	GS 28.844 (28.844)	mem 39.100
Train: [32][65/750]	BT 0.067 (1.403)	DT 0.001 (1.356)	loss 7.188 (7.188)	prob 2.451 (2.451)	GS 37.141 (37.141)	mem 39.004
Train: [32][70/750]	BT 1.245 (1.349)	DT 1.218 (1.301)	loss 6.880 (6.880)	prob 2.701 (2.701)	GS 32.578 (32.578)	mem 39.030
Train: [32][75/750]	BT 0.041 (1.405)	DT 0.001 (1.358)	loss 6.948 (6.948)	prob 2.914 (2.914)	GS 29.312 (29.312)	mem 39.276
Train: [32][80/750]	BT 0.466 (1.345)	DT 0.425 (1.297)	loss 7.180 (7.180)	prob 2.934 (2.934)	GS 36.094 (36.094)	mem 39.453
Train: [32][85/750]	BT 0.105 (1.292)	DT 0.007 (1.244)	loss 7.003 (7.003)	prob 3.042 (3.042)	GS 31.484 (31.484)	mem 39.337
Train: [32][90/750]	BT 3.106 (1.344)	DT 3.081 (1.297)	loss 6.848 (6.848)	prob 2.840 (2.840)	GS 36.703 (36.703)	mem 39.390
Train: [32][95/750]	BT 0.053 (1.276)	DT 0.003 (1.229)	loss 7.228 (7.228)	prob 2.716 (2.716)	GS 36.750 (36.750)	mem 39.571
Train: [32][100/750]	BT 0.720 (1.336)	DT 0.674 (1.288)	loss 7.010 (7.010)	prob 3.087 (3.087)	GS 37.828 (37.828)	mem 39.556
Train: [32][105/750]	BT 0.034 (1.281)	DT 0.002 (1.234)	loss 7.132 (7.132)	prob 3.738 (3.738)	GS 44.188 (44.188)	mem 39.642
Train: [32][110/750]	BT 14.113 (1.352)	DT 14.079 (1.306)	loss 6.788 (6.788)	prob 3.475 (3.475)	GS 35.875 (35.875)	mem 39.612
Train: [32][115/750]	BT 0.043 (1.295)	DT 0.004 (1.249)	loss 7.061 (7.061)	prob 2.898 (2.898)	GS 32.344 (32.344)	mem 39.611
Train: [32][120/750]	BT 0.038 (1.244)	DT 0.001 (1.197)	loss 7.276 (7.276)	prob 2.906 (2.906)	GS 37.703 (37.703)	mem 39.611
Train: [32][125/750]	BT 0.032 (1.276)	DT 0.002 (1.230)	loss 7.272 (7.272)	prob 2.843 (2.843)	GS 28.797 (28.797)	mem 39.746
Train: [32][130/750]	BT 0.031 (1.253)	DT 0.001 (1.208)	loss 7.085 (7.085)	prob 3.175 (3.175)	GS 34.562 (34.562)	mem 39.682
Train: [32][135/750]	BT 0.024 (1.271)	DT 0.001 (1.225)	loss 6.983 (6.983)	prob 2.958 (2.958)	GS 31.375 (31.375)	mem 39.724
Train: [32][140/750]	BT 0.032 (1.260)	DT 0.001 (1.214)	loss 6.800 (6.800)	prob 3.170 (3.170)	GS 34.797 (34.797)	mem 39.725
Train: [32][145/750]	BT 0.041 (1.218)	DT 0.001 (1.172)	loss 7.086 (7.086)	prob 3.323 (3.323)	GS 28.641 (28.641)	mem 39.726
Train: [32][150/750]	BT 1.079 (1.243)	DT 1.038 (1.197)	loss 7.072 (7.072)	prob 3.029 (3.029)	GS 31.219 (31.219)	mem 39.745
Train: [32][155/750]	BT 0.027 (1.205)	DT 0.001 (1.158)	loss 7.215 (7.215)	prob 3.167 (3.167)	GS 28.125 (28.125)	mem 39.782
Train: [32][160/750]	BT 0.039 (1.252)	DT 0.002 (1.205)	loss 7.108 (7.108)	prob 3.185 (3.185)	GS 33.812 (33.812)	mem 39.761
Train: [32][165/750]	BT 0.068 (1.216)	DT 0.015 (1.169)	loss 6.648 (6.648)	prob 3.370 (3.370)	GS 27.828 (27.828)	mem 39.832
Train: [32][170/750]	BT 12.830 (1.257)	DT 12.789 (1.210)	loss 7.085 (7.085)	prob 2.984 (2.984)	GS 35.656 (35.656)	mem 39.780
Train: [32][175/750]	BT 0.044 (1.223)	DT 0.014 (1.176)	loss 7.236 (7.236)	prob 3.272 (3.272)	GS 33.078 (33.078)	mem 39.674
Train: [32][180/750]	BT 0.091 (1.190)	DT 0.017 (1.144)	loss 7.269 (7.269)	prob 2.488 (2.488)	GS 33.203 (33.203)	mem 39.721
Train: [32][185/750]	BT 0.031 (1.223)	DT 0.001 (1.177)	loss 6.906 (6.906)	prob 3.876 (3.876)	GS 34.875 (34.875)	mem 39.687
Train: [32][190/750]	BT 0.067 (1.205)	DT 0.006 (1.158)	loss 6.802 (6.802)	prob 3.402 (3.402)	GS 31.469 (31.469)	mem 39.744
Train: [32][195/750]	BT 0.125 (1.224)	DT 0.050 (1.177)	loss 7.074 (7.074)	prob 3.266 (3.266)	GS 36.953 (36.953)	mem 39.808
Train: [32][200/750]	BT 0.117 (1.200)	DT 0.001 (1.153)	loss 7.059 (7.059)	prob 3.006 (3.006)	GS 33.953 (33.953)	mem 39.866
Train: [32][205/750]	BT 0.115 (1.172)	DT 0.002 (1.125)	loss 6.996 (6.996)	prob 3.154 (3.154)	GS 32.328 (32.328)	mem 39.981
Train: [32][210/750]	BT 4.706 (1.221)	DT 4.674 (1.174)	loss 6.851 (6.851)	prob 2.835 (2.835)	GS 36.688 (36.688)	mem 39.895
Train: [32][215/750]	BT 0.028 (1.194)	DT 0.001 (1.147)	loss 7.135 (7.135)	prob 2.982 (2.982)	GS 29.859 (29.859)	mem 39.802
Train: [32][220/750]	BT 0.047 (1.210)	DT 0.010 (1.163)	loss 6.803 (6.803)	prob 3.205 (3.205)	GS 30.359 (30.359)	mem 39.779
Train: [32][225/750]	BT 0.025 (1.192)	DT 0.001 (1.145)	loss 6.932 (6.932)	prob 2.923 (2.923)	GS 31.719 (31.719)	mem 39.938
Train: [32][230/750]	BT 9.567 (1.208)	DT 9.519 (1.162)	loss 7.152 (7.152)	prob 2.644 (2.644)	GS 30.234 (30.234)	mem 39.903
Train: [32][235/750]	BT 0.053 (1.204)	DT 0.011 (1.158)	loss 7.023 (7.023)	prob 2.608 (2.608)	GS 29.938 (29.938)	mem 39.876
Train: [32][240/750]	BT 0.043 (1.180)	DT 0.002 (1.134)	loss 7.073 (7.073)	prob 2.731 (2.731)	GS 36.422 (36.422)	mem 39.802
Train: [32][245/750]	BT 0.022 (1.203)	DT 0.001 (1.157)	loss 7.212 (7.212)	prob 3.613 (3.613)	GS 34.328 (34.328)	mem 39.973
Train: [32][250/750]	BT 0.029 (1.199)	DT 0.001 (1.153)	loss 6.783 (6.783)	prob 3.894 (3.894)	GS 35.188 (35.188)	mem 39.866
Train: [32][255/750]	BT 0.041 (1.211)	DT 0.007 (1.165)	loss 7.008 (7.008)	prob 2.985 (2.985)	GS 32.469 (32.469)	mem 39.995
Train: [32][260/750]	BT 0.042 (1.194)	DT 0.001 (1.148)	loss 6.969 (6.969)	prob 3.214 (3.214)	GS 34.703 (34.703)	mem 39.989
Train: [32][265/750]	BT 0.060 (1.173)	DT 0.009 (1.127)	loss 7.019 (7.019)	prob 3.243 (3.243)	GS 31.656 (31.656)	mem 39.925
Train: [32][270/750]	BT 4.739 (1.199)	DT 4.704 (1.153)	loss 7.117 (7.117)	prob 2.316 (2.316)	GS 31.141 (31.141)	mem 40.034
Train: [32][275/750]	BT 0.040 (1.178)	DT 0.003 (1.132)	loss 6.964 (6.964)	prob 2.725 (2.725)	GS 32.828 (32.828)	mem 40.005
Train: [32][280/750]	BT 0.033 (1.196)	DT 0.002 (1.150)	loss 7.213 (7.213)	prob 2.988 (2.988)	GS 32.391 (32.391)	mem 40.022
Train: [32][285/750]	BT 0.031 (1.184)	DT 0.001 (1.138)	loss 7.031 (7.031)	prob 2.827 (2.827)	GS 34.031 (34.031)	mem 39.965
Train: [32][290/750]	BT 12.208 (1.206)	DT 12.174 (1.160)	loss 7.064 (7.064)	prob 3.455 (3.455)	GS 37.031 (37.031)	mem 40.302
Train: [32][295/750]	BT 0.038 (1.197)	DT 0.002 (1.151)	loss 7.224 (7.224)	prob 3.189 (3.189)	GS 32.391 (32.391)	mem 39.980
Train: [32][300/750]	BT 0.050 (1.178)	DT 0.009 (1.132)	loss 6.633 (6.633)	prob 4.049 (4.049)	GS 36.781 (36.781)	mem 39.980
Train: [32][305/750]	BT 0.029 (1.191)	DT 0.001 (1.146)	loss 7.151 (7.151)	prob 3.482 (3.482)	GS 31.812 (31.812)	mem 39.892
Train: [32][310/750]	BT 0.035 (1.185)	DT 0.001 (1.140)	loss 6.902 (6.902)	prob 3.136 (3.136)	GS 32.391 (32.391)	mem 39.985
Train: [32][315/750]	BT 0.062 (1.190)	DT 0.008 (1.144)	loss 7.038 (7.038)	prob 2.881 (2.881)	GS 31.719 (31.719)	mem 39.865
Train: [32][320/750]	BT 1.138 (1.188)	DT 1.109 (1.143)	loss 6.895 (6.895)	prob 3.122 (3.122)	GS 33.344 (33.344)	mem 39.851
Train: [32][325/750]	BT 0.052 (1.170)	DT 0.005 (1.125)	loss 7.165 (7.165)	prob 3.048 (3.048)	GS 32.578 (32.578)	mem 39.856
Train: [32][330/750]	BT 4.028 (1.188)	DT 4.002 (1.143)	loss 6.970 (6.970)	prob 3.035 (3.035)	GS 33.141 (33.141)	mem 39.821
Train: [32][335/750]	BT 0.036 (1.171)	DT 0.003 (1.126)	loss 6.975 (6.975)	prob 2.776 (2.776)	GS 28.609 (28.609)	mem 39.896
Train: [32][340/750]	BT 0.041 (1.189)	DT 0.001 (1.144)	loss 6.940 (6.940)	prob 3.439 (3.439)	GS 34.406 (34.406)	mem 39.873
Train: [32][345/750]	BT 0.028 (1.179)	DT 0.001 (1.134)	loss 6.976 (6.976)	prob 3.112 (3.112)	GS 29.000 (29.000)	mem 39.819
Train: [32][350/750]	BT 8.318 (1.187)	DT 8.274 (1.141)	loss 6.686 (6.686)	prob 2.848 (2.848)	GS 32.859 (32.859)	mem 39.955
Train: [32][355/750]	BT 0.052 (1.186)	DT 0.022 (1.141)	loss 7.295 (7.295)	prob 2.639 (2.639)	GS 39.641 (39.641)	mem 39.897
Train: [32][360/750]	BT 0.038 (1.171)	DT 0.001 (1.125)	loss 7.009 (7.009)	prob 3.087 (3.087)	GS 30.922 (30.922)	mem 39.898
Train: [32][365/750]	BT 0.030 (1.179)	DT 0.001 (1.134)	loss 7.121 (7.121)	prob 2.843 (2.843)	GS 46.016 (46.016)	mem 39.935
Train: [32][370/750]	BT 0.070 (1.171)	DT 0.014 (1.126)	loss 6.833 (6.833)	prob 3.036 (3.036)	GS 34.406 (34.406)	mem 40.173
Train: [32][375/750]	BT 0.042 (1.181)	DT 0.003 (1.135)	loss 7.302 (7.302)	prob 2.294 (2.294)	GS 32.641 (32.641)	mem 39.975
Train: [32][380/750]	BT 1.489 (1.171)	DT 1.446 (1.126)	loss 7.075 (7.075)	prob 3.388 (3.388)	GS 30.359 (30.359)	mem 39.974
Train: [32][385/750]	BT 0.112 (1.157)	DT 0.008 (1.111)	loss 7.069 (7.069)	prob 2.975 (2.975)	GS 32.562 (32.562)	mem 40.073
Train: [32][390/750]	BT 0.108 (1.174)	DT 0.005 (1.128)	loss 6.930 (6.930)	prob 3.412 (3.412)	GS 32.109 (32.109)	mem 40.075
Train: [32][395/750]	BT 0.058 (1.165)	DT 0.002 (1.120)	loss 7.146 (7.146)	prob 2.430 (2.430)	GS 27.047 (27.047)	mem 39.961
Train: [32][400/750]	BT 0.042 (1.179)	DT 0.001 (1.133)	loss 7.007 (7.007)	prob 3.302 (3.302)	GS 34.688 (34.688)	mem 40.116
Train: [32][405/750]	BT 0.031 (1.165)	DT 0.002 (1.119)	loss 7.285 (7.285)	prob 2.688 (2.688)	GS 29.062 (29.062)	mem 40.028
Train: [32][410/750]	BT 12.476 (1.181)	DT 12.444 (1.136)	loss 6.949 (6.949)	prob 3.110 (3.110)	GS 35.641 (35.641)	mem 39.949
Train: [32][415/750]	BT 0.065 (1.168)	DT 0.004 (1.122)	loss 7.085 (7.085)	prob 2.814 (2.814)	GS 32.250 (32.250)	mem 39.950
Train: [32][420/750]	BT 0.064 (1.162)	DT 0.022 (1.116)	loss 6.965 (6.965)	prob 3.103 (3.103)	GS 33.422 (33.422)	mem 39.972
Train: [32][425/750]	BT 0.035 (1.167)	DT 0.002 (1.121)	loss 6.868 (6.868)	prob 2.924 (2.924)	GS 33.922 (33.922)	mem 39.991
Train: [32][430/750]	BT 0.029 (1.160)	DT 0.001 (1.115)	loss 6.832 (6.832)	prob 3.151 (3.151)	GS 29.578 (29.578)	mem 40.019
Train: [32][435/750]	BT 0.032 (1.170)	DT 0.001 (1.125)	loss 6.905 (6.905)	prob 2.663 (2.663)	GS 35.375 (35.375)	mem 40.029
Train: [32][440/750]	BT 2.210 (1.162)	DT 2.132 (1.117)	loss 7.071 (7.071)	prob 2.126 (2.126)	GS 32.047 (32.047)	mem 39.968
Train: [32][445/750]	BT 0.104 (1.150)	DT 0.004 (1.104)	loss 7.008 (7.008)	prob 2.960 (2.960)	GS 31.203 (31.203)	mem 39.969
Train: [32][450/750]	BT 0.033 (1.164)	DT 0.001 (1.119)	loss 6.928 (6.928)	prob 2.477 (2.477)	GS 34.172 (34.172)	mem 39.947
Train: [32][455/750]	BT 0.027 (1.152)	DT 0.001 (1.107)	loss 7.021 (7.021)	prob 2.812 (2.812)	GS 31.141 (31.141)	mem 39.871
Train: [32][460/750]	BT 0.031 (1.166)	DT 0.001 (1.120)	loss 6.771 (6.771)	prob 3.351 (3.351)	GS 34.188 (34.188)	mem 40.030
Train: [32][465/750]	BT 0.031 (1.153)	DT 0.001 (1.108)	loss 7.043 (7.043)	prob 2.618 (2.618)	GS 29.859 (29.859)	mem 40.066
Train: [32][470/750]	BT 13.040 (1.175)	DT 13.005 (1.129)	loss 6.811 (6.811)	prob 2.941 (2.941)	GS 34.969 (34.969)	mem 40.001
Train: [32][475/750]	BT 0.049 (1.163)	DT 0.009 (1.118)	loss 6.785 (6.785)	prob 2.213 (2.213)	GS 32.500 (32.500)	mem 40.011
Train: [32][480/750]	BT 0.042 (1.151)	DT 0.001 (1.106)	loss 6.804 (6.804)	prob 2.341 (2.341)	GS 29.938 (29.938)	mem 40.011
Train: [32][485/750]	BT 0.064 (1.165)	DT 0.002 (1.120)	loss 6.861 (6.861)	prob 3.164 (3.164)	GS 35.594 (35.594)	mem 40.060
Train: [32][490/750]	BT 0.519 (1.154)	DT 0.451 (1.109)	loss 6.925 (6.925)	prob 2.545 (2.545)	GS 36.625 (36.625)	mem 40.005
Train: [32][495/750]	BT 0.025 (1.165)	DT 0.001 (1.120)	loss 6.868 (6.868)	prob 2.303 (2.303)	GS 34.250 (34.250)	mem 39.927
Train: [32][500/750]	BT 0.031 (1.154)	DT 0.001 (1.109)	loss 6.799 (6.799)	prob 2.629 (2.629)	GS 34.453 (34.453)	mem 39.927
Train: [32][505/750]	BT 0.084 (1.143)	DT 0.016 (1.098)	loss 6.900 (6.900)	prob 2.298 (2.298)	GS 29.891 (29.891)	mem 39.929
Train: [32][510/750]	BT 0.050 (1.158)	DT 0.008 (1.112)	loss 6.994 (6.994)	prob 2.371 (2.371)	GS 35.109 (35.109)	mem 39.921
Train: [32][515/750]	BT 0.030 (1.150)	DT 0.003 (1.105)	loss 6.855 (6.855)	prob 2.628 (2.628)	GS 36.312 (36.312)	mem 39.926
Train: [32][520/750]	BT 0.031 (1.160)	DT 0.001 (1.114)	loss 6.728 (6.728)	prob 3.146 (3.146)	GS 30.844 (30.844)	mem 40.017
Train: [32][525/750]	BT 0.088 (1.149)	DT 0.001 (1.103)	loss 6.865 (6.865)	prob 2.585 (2.585)	GS 36.109 (36.109)	mem 40.018
Train: [32][530/750]	BT 12.333 (1.162)	DT 12.302 (1.116)	loss 6.769 (6.769)	prob 2.903 (2.903)	GS 34.219 (34.219)	mem 40.062
Train: [32][535/750]	BT 0.065 (1.151)	DT 0.002 (1.106)	loss 7.115 (7.115)	prob 2.632 (2.632)	GS 29.188 (29.188)	mem 40.185
Train: [32][540/750]	BT 0.036 (1.147)	DT 0.004 (1.102)	loss 6.913 (6.913)	prob 3.027 (3.027)	GS 32.891 (32.891)	mem 39.999
Train: [32][545/750]	BT 0.057 (1.157)	DT 0.002 (1.111)	loss 6.888 (6.888)	prob 2.774 (2.774)	GS 28.609 (28.609)	mem 40.119
Train: [32][550/750]	BT 0.031 (1.151)	DT 0.001 (1.106)	loss 6.878 (6.878)	prob 2.484 (2.484)	GS 31.516 (31.516)	mem 40.151
Train: [32][555/750]	BT 0.054 (1.157)	DT 0.004 (1.111)	loss 7.042 (7.042)	prob 2.550 (2.550)	GS 32.250 (32.250)	mem 40.165
Train: [32][560/750]	BT 3.328 (1.153)	DT 3.295 (1.107)	loss 7.155 (7.155)	prob 2.361 (2.361)	GS 34.078 (34.078)	mem 39.923
Train: [32][565/750]	BT 0.076 (1.143)	DT 0.016 (1.097)	loss 6.884 (6.884)	prob 2.315 (2.315)	GS 31.078 (31.078)	mem 39.893
Train: [32][570/750]	BT 0.077 (1.149)	DT 0.009 (1.103)	loss 7.024 (7.024)	prob 2.122 (2.122)	GS 35.219 (35.219)	mem 39.914
Train: [32][575/750]	BT 0.029 (1.148)	DT 0.001 (1.103)	loss 6.763 (6.763)	prob 2.859 (2.859)	GS 28.797 (28.797)	mem 40.034
Train: [32][580/750]	BT 0.022 (1.147)	DT 0.001 (1.102)	loss 6.870 (6.870)	prob 2.620 (2.620)	GS 31.312 (31.312)	mem 40.055
Train: [32][585/750]	BT 0.035 (1.147)	DT 0.002 (1.102)	loss 7.386 (7.386)	prob 2.182 (2.182)	GS 34.062 (34.062)	mem 40.029
Train: [32][590/750]	BT 2.133 (1.147)	DT 2.089 (1.102)	loss 6.948 (6.948)	prob 2.656 (2.656)	GS 36.281 (36.281)	mem 39.930
Train: [32][595/750]	BT 0.031 (1.139)	DT 0.002 (1.094)	loss 7.006 (7.006)	prob 2.420 (2.420)	GS 32.953 (32.953)	mem 39.978
Train: [32][600/750]	BT 0.053 (1.149)	DT 0.001 (1.103)	loss 6.859 (6.859)	prob 2.768 (2.768)	GS 33.406 (33.406)	mem 39.907
Train: [32][605/750]	BT 0.029 (1.140)	DT 0.001 (1.095)	loss 6.865 (6.865)	prob 2.592 (2.592)	GS 32.109 (32.109)	mem 39.969
Train: [32][610/750]	BT 6.155 (1.153)	DT 6.115 (1.108)	loss 7.199 (7.199)	prob 2.058 (2.058)	GS 33.234 (33.234)	mem 40.042
Train: [32][615/750]	BT 0.048 (1.144)	DT 0.011 (1.099)	loss 7.137 (7.137)	prob 2.412 (2.412)	GS 30.328 (30.328)	mem 39.957
Train: [32][620/750]	BT 6.260 (1.148)	DT 6.229 (1.103)	loss 6.935 (6.935)	prob 2.651 (2.651)	GS 33.719 (33.719)	mem 39.996
Train: [32][625/750]	BT 0.046 (1.145)	DT 0.006 (1.100)	loss 7.233 (7.233)	prob 2.558 (2.558)	GS 35.656 (35.656)	mem 39.820
Train: [32][630/750]	BT 4.733 (1.144)	DT 4.698 (1.099)	loss 6.875 (6.875)	prob 2.844 (2.844)	GS 33.375 (33.375)	mem 39.972
Train: [32][635/750]	BT 0.061 (1.143)	DT 0.021 (1.098)	loss 6.751 (6.751)	prob 2.495 (2.495)	GS 30.688 (30.688)	mem 39.940
Train: [32][640/750]	BT 0.102 (1.135)	DT 0.012 (1.090)	loss 6.927 (6.927)	prob 2.451 (2.451)	GS 36.016 (36.016)	mem 39.941
Train: [32][645/750]	BT 0.046 (1.146)	DT 0.005 (1.100)	loss 7.124 (7.124)	prob 2.600 (2.600)	GS 29.781 (29.781)	mem 39.897
Train: [32][650/750]	BT 0.116 (1.137)	DT 0.013 (1.092)	loss 6.952 (6.952)	prob 2.402 (2.402)	GS 28.625 (28.625)	mem 39.935
Train: [32][655/750]	BT 0.037 (1.141)	DT 0.002 (1.096)	loss 6.750 (6.750)	prob 2.503 (2.503)	GS 31.641 (31.641)	mem 39.969
arpack error, retry= 0
Train: [32][660/750]	BT 0.093 (1.140)	DT 0.006 (1.095)	loss 6.936 (6.936)	prob 2.237 (2.237)	GS 34.188 (34.188)	mem 40.154
Train: [32][665/750]	BT 0.063 (1.132)	DT 0.010 (1.087)	loss 6.962 (6.962)	prob 2.662 (2.662)	GS 35.859 (35.859)	mem 39.963
Train: [32][670/750]	BT 0.074 (1.145)	DT 0.002 (1.100)	loss 6.873 (6.873)	prob 2.767 (2.767)	GS 31.859 (31.859)	mem 39.913
Train: [32][675/750]	BT 0.024 (1.137)	DT 0.001 (1.091)	loss 7.022 (7.022)	prob 2.807 (2.807)	GS 33.578 (33.578)	mem 39.938
Train: [32][680/750]	BT 6.317 (1.144)	DT 6.286 (1.098)	loss 7.043 (7.043)	prob 2.463 (2.463)	GS 32.250 (32.250)	mem 39.946
Train: [32][685/750]	BT 0.031 (1.136)	DT 0.001 (1.090)	loss 6.927 (6.927)	prob 2.741 (2.741)	GS 31.375 (31.375)	mem 39.947
Train: [32][690/750]	BT 6.979 (1.138)	DT 6.944 (1.093)	loss 6.689 (6.689)	prob 2.713 (2.713)	GS 33.109 (33.109)	mem 39.943
Train: [32][695/750]	BT 0.027 (1.137)	DT 0.001 (1.092)	loss 6.989 (6.989)	prob 2.690 (2.690)	GS 29.719 (29.719)	mem 39.949
Train: [32][700/750]	BT 0.036 (1.129)	DT 0.001 (1.084)	loss 6.985 (6.985)	prob 2.624 (2.624)	GS 30.312 (30.312)	mem 39.951
Train: [32][705/750]	BT 0.028 (1.134)	DT 0.001 (1.089)	loss 6.968 (6.968)	prob 2.580 (2.580)	GS 29.734 (29.734)	mem 39.955
Train: [32][710/750]	BT 1.270 (1.128)	DT 1.239 (1.083)	loss 6.837 (6.837)	prob 3.269 (3.269)	GS 32.547 (32.547)	mem 39.990
Train: [32][715/750]	BT 0.043 (1.127)	DT 0.003 (1.082)	loss 7.269 (7.269)	prob 2.066 (2.066)	GS 28.406 (28.406)	mem 39.974
Train: [32][720/750]	BT 0.079 (1.130)	DT 0.011 (1.085)	loss 6.873 (6.873)	prob 2.965 (2.965)	GS 29.109 (29.109)	mem 40.052
Train: [32][725/750]	BT 0.086 (1.125)	DT 0.020 (1.079)	loss 6.908 (6.908)	prob 3.127 (3.127)	GS 29.781 (29.781)	mem 40.015
Train: [32][730/750]	BT 0.570 (1.132)	DT 0.526 (1.086)	loss 6.998 (6.998)	prob 2.769 (2.769)	GS 34.719 (34.719)	mem 39.746
Train: [32][735/750]	BT 0.068 (1.125)	DT 0.004 (1.079)	loss 7.268 (7.268)	prob 2.372 (2.372)	GS 29.766 (29.766)	mem 39.665
Train: [32][740/750]	BT 7.792 (1.132)	DT 7.762 (1.086)	loss 6.864 (6.864)	prob 2.945 (2.945)	GS 37.344 (37.344)	mem 13.634
Train: [32][745/750]	BT 0.022 (1.125)	DT 0.001 (1.079)	loss 6.803 (6.803)	prob 2.835 (2.835)	GS 29.375 (29.375)	mem 13.634
Train: [32][750/750]	BT 0.037 (1.117)	DT 0.005 (1.072)	loss 7.089 (7.089)	prob 1.304 (1.304)	GS 33.719 (33.719)	mem 13.598
Train: [32][755/750]	BT 0.036 (1.112)	DT 0.001 (1.067)	loss 7.062 (7.062)	prob 2.988 (2.988)	GS 32.875 (32.875)	mem 7.637
epoch 32, total time 840.18
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [33][1/750]	BT 19.669 (19.669)	DT 19.601 (19.601)	loss 7.197 (7.197)	prob 1.996 (1.996)	GS 29.672 (29.672)	mem 38.949
Train: [33][5/750]	BT 0.041 (4.509)	DT 0.002 (4.451)	loss 6.909 (6.909)	prob 2.615 (2.615)	GS 31.156 (31.156)	mem 38.844
Train: [33][10/750]	BT 0.368 (2.402)	DT 0.330 (2.353)	loss 7.014 (7.014)	prob 2.804 (2.804)	GS 36.812 (36.812)	mem 38.881
Train: [33][15/750]	BT 0.030 (2.232)	DT 0.001 (2.188)	loss 6.588 (6.588)	prob 2.730 (2.730)	GS 32.250 (32.250)	mem 38.894
Train: [33][20/750]	BT 0.139 (1.877)	DT 0.002 (1.827)	loss 6.775 (6.775)	prob 3.031 (3.031)	GS 30.312 (30.312)	mem 38.952
Train: [33][25/750]	BT 4.041 (1.699)	DT 3.976 (1.649)	loss 6.869 (6.869)	prob 3.140 (3.140)	GS 29.141 (29.141)	mem 39.007
Train: [33][30/750]	BT 5.086 (1.743)	DT 5.054 (1.695)	loss 6.788 (6.788)	prob 2.778 (2.778)	GS 34.719 (34.719)	mem 39.022
Train: [33][35/750]	BT 0.043 (1.548)	DT 0.008 (1.500)	loss 6.746 (6.746)	prob 2.983 (2.983)	GS 28.281 (28.281)	mem 39.082
Train: [33][40/750]	BT 0.069 (1.574)	DT 0.008 (1.527)	loss 6.868 (6.868)	prob 2.792 (2.792)	GS 32.766 (32.766)	mem 39.197
Train: [33][45/750]	BT 0.032 (1.404)	DT 0.001 (1.358)	loss 7.157 (7.157)	prob 2.821 (2.821)	GS 33.062 (33.062)	mem 39.217
Train: [33][50/750]	BT 5.879 (1.501)	DT 5.840 (1.456)	loss 6.889 (6.889)	prob 2.446 (2.446)	GS 31.938 (31.938)	mem 39.511
Train: [33][55/750]	BT 0.051 (1.449)	DT 0.012 (1.404)	loss 7.344 (7.344)	prob 1.977 (1.977)	GS 39.406 (39.406)	mem 39.555
Train: [33][60/750]	BT 0.077 (1.336)	DT 0.007 (1.289)	loss 6.809 (6.809)	prob 3.016 (3.016)	GS 33.828 (33.828)	mem 39.600
Train: [33][65/750]	BT 0.021 (1.431)	DT 0.001 (1.384)	loss 7.207 (7.207)	prob 2.558 (2.558)	GS 29.609 (29.609)	mem 39.664
Train: [33][70/750]	BT 0.048 (1.346)	DT 0.009 (1.299)	loss 7.140 (7.140)	prob 2.541 (2.541)	GS 36.469 (36.469)	mem 39.669
Train: [33][75/750]	BT 0.062 (1.423)	DT 0.003 (1.376)	loss 7.318 (7.318)	prob 3.070 (3.070)	GS 32.500 (32.500)	mem 39.670
Train: [33][80/750]	BT 0.031 (1.362)	DT 0.001 (1.316)	loss 6.824 (6.824)	prob 3.310 (3.310)	GS 33.391 (33.391)	mem 39.710
Train: [33][85/750]	BT 0.073 (1.286)	DT 0.002 (1.239)	loss 7.078 (7.078)	prob 2.545 (2.545)	GS 35.219 (35.219)	mem 39.846
Train: [33][90/750]	BT 2.332 (1.355)	DT 2.271 (1.308)	loss 6.783 (6.783)	prob 3.452 (3.452)	GS 31.656 (31.656)	mem 39.691
Train: [33][95/750]	BT 0.061 (1.312)	DT 0.013 (1.266)	loss 6.900 (6.900)	prob 3.189 (3.189)	GS 32.172 (32.172)	mem 39.712
Train: [33][100/750]	BT 0.035 (1.343)	DT 0.001 (1.297)	loss 6.928 (6.928)	prob 2.757 (2.757)	GS 30.875 (30.875)	mem 39.814
Train: [33][105/750]	BT 0.032 (1.286)	DT 0.002 (1.240)	loss 6.943 (6.943)	prob 2.928 (2.928)	GS 34.078 (34.078)	mem 39.729
Train: [33][110/750]	BT 7.840 (1.309)	DT 7.805 (1.264)	loss 6.910 (6.910)	prob 2.807 (2.807)	GS 35.656 (35.656)	mem 39.632
Train: [33][115/750]	BT 0.064 (1.281)	DT 0.007 (1.235)	loss 6.917 (6.917)	prob 2.988 (2.988)	GS 32.125 (32.125)	mem 39.618
Train: [33][120/750]	BT 0.044 (1.234)	DT 0.002 (1.189)	loss 6.930 (6.930)	prob 3.149 (3.149)	GS 39.469 (39.469)	mem 39.624
Train: [33][125/750]	BT 0.070 (1.269)	DT 0.019 (1.223)	loss 6.919 (6.919)	prob 2.830 (2.830)	GS 27.219 (27.219)	mem 39.740
Train: [33][130/750]	BT 4.103 (1.253)	DT 4.068 (1.207)	loss 6.748 (6.748)	prob 2.687 (2.687)	GS 36.609 (36.609)	mem 39.841
Train: [33][135/750]	BT 0.083 (1.283)	DT 0.029 (1.238)	loss 7.204 (7.204)	prob 2.638 (2.638)	GS 33.375 (33.375)	mem 39.724
Train: [33][140/750]	BT 0.080 (1.238)	DT 0.025 (1.194)	loss 6.995 (6.995)	prob 2.650 (2.650)	GS 36.391 (36.391)	mem 39.725
Train: [33][145/750]	BT 0.032 (1.211)	DT 0.001 (1.167)	loss 6.856 (6.856)	prob 2.750 (2.750)	GS 33.656 (33.656)	mem 39.739
Train: [33][150/750]	BT 0.030 (1.256)	DT 0.001 (1.212)	loss 6.905 (6.905)	prob 2.235 (2.235)	GS 30.031 (30.031)	mem 39.686
Train: [33][155/750]	BT 0.119 (1.227)	DT 0.009 (1.183)	loss 7.123 (7.123)	prob 2.624 (2.624)	GS 33.000 (33.000)	mem 39.795
Train: [33][160/750]	BT 0.033 (1.258)	DT 0.002 (1.214)	loss 6.914 (6.914)	prob 2.573 (2.573)	GS 36.859 (36.859)	mem 39.690
Train: [33][165/750]	BT 0.051 (1.221)	DT 0.005 (1.177)	loss 6.825 (6.825)	prob 2.777 (2.777)	GS 29.422 (29.422)	mem 39.691
Train: [33][170/750]	BT 12.583 (1.262)	DT 12.487 (1.217)	loss 6.818 (6.818)	prob 2.488 (2.488)	GS 32.641 (32.641)	mem 39.914
Train: [33][175/750]	BT 0.026 (1.227)	DT 0.001 (1.183)	loss 7.085 (7.085)	prob 2.423 (2.423)	GS 33.250 (33.250)	mem 39.732
Train: [33][180/750]	BT 1.142 (1.200)	DT 1.103 (1.156)	loss 7.203 (7.203)	prob 2.359 (2.359)	GS 34.297 (34.297)	mem 39.727
Train: [33][185/750]	BT 0.046 (1.235)	DT 0.007 (1.191)	loss 7.144 (7.144)	prob 2.278 (2.278)	GS 30.891 (30.891)	mem 39.913
Train: [33][190/750]	BT 0.039 (1.204)	DT 0.003 (1.159)	loss 6.766 (6.766)	prob 3.385 (3.385)	GS 35.375 (35.375)	mem 39.853
Train: [33][195/750]	BT 0.035 (1.241)	DT 0.001 (1.197)	loss 7.068 (7.068)	prob 2.287 (2.287)	GS 32.469 (32.469)	mem 39.870
Train: [33][200/750]	BT 0.048 (1.211)	DT 0.005 (1.167)	loss 6.940 (6.940)	prob 2.730 (2.730)	GS 34.422 (34.422)	mem 39.804
Train: [33][205/750]	BT 0.061 (1.183)	DT 0.011 (1.139)	loss 7.074 (7.074)	prob 2.218 (2.218)	GS 32.938 (32.938)	mem 39.805
Train: [33][210/750]	BT 0.032 (1.209)	DT 0.001 (1.166)	loss 6.942 (6.942)	prob 2.384 (2.384)	GS 35.703 (35.703)	mem 39.930
Train: [33][215/750]	BT 0.038 (1.182)	DT 0.007 (1.139)	loss 6.992 (6.992)	prob 2.995 (2.995)	GS 27.750 (27.750)	mem 39.931
Train: [33][220/750]	BT 0.049 (1.229)	DT 0.001 (1.185)	loss 7.130 (7.130)	prob 2.520 (2.520)	GS 27.875 (27.875)	mem 39.958
Train: [33][225/750]	BT 0.028 (1.202)	DT 0.001 (1.159)	loss 7.059 (7.059)	prob 2.279 (2.279)	GS 26.531 (26.531)	mem 39.983
Train: [33][230/750]	BT 12.735 (1.232)	DT 12.701 (1.189)	loss 6.819 (6.819)	prob 3.117 (3.117)	GS 30.594 (30.594)	mem 40.078
Train: [33][235/750]	BT 0.032 (1.207)	DT 0.001 (1.164)	loss 7.049 (7.049)	prob 2.393 (2.393)	GS 37.734 (37.734)	mem 39.999
Train: [33][240/750]	BT 0.048 (1.182)	DT 0.014 (1.139)	loss 6.932 (6.932)	prob 2.613 (2.613)	GS 30.359 (30.359)	mem 40.069
Train: [33][245/750]	BT 0.069 (1.209)	DT 0.022 (1.165)	loss 6.983 (6.983)	prob 3.217 (3.217)	GS 34.453 (34.453)	mem 40.135
Train: [33][250/750]	BT 0.042 (1.185)	DT 0.001 (1.142)	loss 7.155 (7.155)	prob 2.435 (2.435)	GS 33.984 (33.984)	mem 40.036
Train: [33][255/750]	BT 0.041 (1.208)	DT 0.003 (1.164)	loss 7.084 (7.084)	prob 2.021 (2.021)	GS 31.266 (31.266)	mem 39.938
Train: [33][260/750]	BT 0.032 (1.186)	DT 0.001 (1.142)	loss 6.933 (6.933)	prob 2.560 (2.560)	GS 34.125 (34.125)	mem 40.008
Train: [33][265/750]	BT 0.058 (1.164)	DT 0.007 (1.120)	loss 6.977 (6.977)	prob 2.709 (2.709)	GS 31.062 (31.062)	mem 40.104
Train: [33][270/750]	BT 0.030 (1.186)	DT 0.001 (1.142)	loss 7.052 (7.052)	prob 2.134 (2.134)	GS 35.688 (35.688)	mem 39.894
Train: [33][275/750]	BT 0.035 (1.184)	DT 0.001 (1.140)	loss 6.993 (6.993)	prob 2.578 (2.578)	GS 30.328 (30.328)	mem 39.924
Train: [33][280/750]	BT 0.071 (1.184)	DT 0.010 (1.140)	loss 6.749 (6.749)	prob 2.867 (2.867)	GS 35.625 (35.625)	mem 39.907
Train: [33][285/750]	BT 0.059 (1.186)	DT 0.002 (1.141)	loss 7.087 (7.087)	prob 2.694 (2.694)	GS 32.797 (32.797)	mem 39.900
Train: [33][290/750]	BT 2.796 (1.176)	DT 2.748 (1.131)	loss 7.015 (7.015)	prob 2.492 (2.492)	GS 34.281 (34.281)	mem 39.979
Train: [33][295/750]	BT 0.032 (1.156)	DT 0.002 (1.112)	loss 7.177 (7.177)	prob 2.184 (2.184)	GS 32.172 (32.172)	mem 40.036
Train: [33][300/750]	BT 0.036 (1.185)	DT 0.001 (1.140)	loss 6.803 (6.803)	prob 2.968 (2.968)	GS 33.078 (33.078)	mem 39.953
Train: [33][305/750]	BT 0.070 (1.166)	DT 0.039 (1.122)	loss 7.077 (7.077)	prob 2.598 (2.598)	GS 28.641 (28.641)	mem 39.954
Train: [33][310/750]	BT 0.102 (1.190)	DT 0.035 (1.146)	loss 6.862 (6.862)	prob 2.694 (2.694)	GS 39.234 (39.234)	mem 39.960
Train: [33][315/750]	BT 0.099 (1.172)	DT 0.002 (1.127)	loss 6.984 (6.984)	prob 2.473 (2.473)	GS 36.234 (36.234)	mem 39.994
Train: [33][320/750]	BT 13.665 (1.197)	DT 13.600 (1.152)	loss 7.243 (7.243)	prob 2.273 (2.273)	GS 34.828 (34.828)	mem 39.976
Train: [33][325/750]	BT 0.037 (1.179)	DT 0.007 (1.135)	loss 7.051 (7.051)	prob 2.512 (2.512)	GS 31.266 (31.266)	mem 39.978
Train: [33][330/750]	BT 0.024 (1.162)	DT 0.001 (1.118)	loss 7.160 (7.160)	prob 1.969 (1.969)	GS 30.109 (30.109)	mem 39.978
Train: [33][335/750]	BT 0.023 (1.183)	DT 0.001 (1.139)	loss 6.778 (6.778)	prob 2.358 (2.358)	GS 31.859 (31.859)	mem 39.954
Train: [33][340/750]	BT 0.135 (1.166)	DT 0.001 (1.122)	loss 6.915 (6.915)	prob 2.377 (2.377)	GS 31.469 (31.469)	mem 39.964
Train: [33][345/750]	BT 0.034 (1.192)	DT 0.003 (1.147)	loss 6.954 (6.954)	prob 2.018 (2.018)	GS 30.844 (30.844)	mem 39.989
Train: [33][350/750]	BT 0.049 (1.175)	DT 0.001 (1.131)	loss 6.799 (6.799)	prob 2.104 (2.104)	GS 30.953 (30.953)	mem 40.135
Train: [33][355/750]	BT 0.031 (1.159)	DT 0.001 (1.115)	loss 6.880 (6.880)	prob 1.854 (1.854)	GS 33.156 (33.156)	mem 39.992
Train: [33][360/750]	BT 0.067 (1.177)	DT 0.007 (1.132)	loss 6.929 (6.929)	prob 2.561 (2.561)	GS 36.094 (36.094)	mem 40.076
Train: [33][365/750]	BT 0.028 (1.161)	DT 0.001 (1.117)	loss 6.857 (6.857)	prob 2.479 (2.479)	GS 32.516 (32.516)	mem 39.967
Train: [33][370/750]	BT 0.048 (1.189)	DT 0.009 (1.144)	loss 6.913 (6.913)	prob 2.768 (2.768)	GS 28.609 (28.609)	mem 39.913
Train: [33][375/750]	BT 0.032 (1.173)	DT 0.001 (1.129)	loss 6.751 (6.751)	prob 1.988 (1.988)	GS 29.344 (29.344)	mem 39.914
Train: [33][380/750]	BT 14.319 (1.196)	DT 14.286 (1.152)	loss 6.752 (6.752)	prob 2.650 (2.650)	GS 32.109 (32.109)	mem 40.097
Train: [33][385/750]	BT 0.033 (1.181)	DT 0.001 (1.137)	loss 6.839 (6.839)	prob 2.268 (2.268)	GS 35.875 (35.875)	mem 39.951
Train: [33][390/750]	BT 0.035 (1.166)	DT 0.001 (1.123)	loss 7.016 (7.016)	prob 2.289 (2.289)	GS 29.828 (29.828)	mem 39.951
Train: [33][395/750]	BT 0.056 (1.174)	DT 0.013 (1.131)	loss 6.849 (6.849)	prob 2.183 (2.183)	GS 30.281 (30.281)	mem 40.019
Train: [33][400/750]	BT 0.027 (1.161)	DT 0.001 (1.117)	loss 6.894 (6.894)	prob 2.070 (2.070)	GS 30.594 (30.594)	mem 40.139
Train: [33][405/750]	BT 0.033 (1.184)	DT 0.002 (1.140)	loss 6.915 (6.915)	prob 2.172 (2.172)	GS 31.828 (31.828)	mem 39.831
Train: [33][410/750]	BT 0.050 (1.170)	DT 0.003 (1.126)	loss 6.938 (6.938)	prob 2.259 (2.259)	GS 32.891 (32.891)	mem 39.832
Train: [33][415/750]	BT 0.027 (1.157)	DT 0.001 (1.113)	loss 7.208 (7.208)	prob 1.882 (1.882)	GS 34.406 (34.406)	mem 39.841
Train: [33][420/750]	BT 0.081 (1.169)	DT 0.010 (1.125)	loss 6.753 (6.753)	prob 2.565 (2.565)	GS 34.266 (34.266)	mem 39.943
Train: [33][425/750]	BT 0.057 (1.162)	DT 0.004 (1.118)	loss 6.939 (6.939)	prob 2.754 (2.754)	GS 31.391 (31.391)	mem 39.926
Train: [33][430/750]	BT 0.025 (1.171)	DT 0.001 (1.128)	loss 7.071 (7.071)	prob 2.479 (2.479)	GS 30.438 (30.438)	mem 39.945
Train: [33][435/750]	BT 0.024 (1.171)	DT 0.001 (1.127)	loss 7.078 (7.078)	prob 1.864 (1.864)	GS 33.000 (33.000)	mem 39.934
Train: [33][440/750]	BT 9.783 (1.180)	DT 9.710 (1.136)	loss 6.796 (6.796)	prob 2.572 (2.572)	GS 40.500 (40.500)	mem 40.118
Train: [33][445/750]	BT 0.039 (1.167)	DT 0.002 (1.124)	loss 7.107 (7.107)	prob 2.198 (2.198)	GS 32.141 (32.141)	mem 40.224
Train: [33][450/750]	BT 0.136 (1.156)	DT 0.007 (1.112)	loss 6.837 (6.837)	prob 2.734 (2.734)	GS 32.172 (32.172)	mem 40.078
Train: [33][455/750]	BT 0.050 (1.167)	DT 0.003 (1.123)	loss 6.654 (6.654)	prob 2.981 (2.981)	GS 29.250 (29.250)	mem 39.862
Train: [33][460/750]	BT 0.034 (1.159)	DT 0.002 (1.115)	loss 6.857 (6.857)	prob 2.013 (2.013)	GS 38.578 (38.578)	mem 39.918
Train: [33][465/750]	BT 0.056 (1.177)	DT 0.003 (1.133)	loss 6.726 (6.726)	prob 2.687 (2.687)	GS 33.109 (33.109)	mem 39.964
Train: [33][470/750]	BT 0.032 (1.165)	DT 0.001 (1.121)	loss 6.915 (6.915)	prob 2.401 (2.401)	GS 34.422 (34.422)	mem 39.954
Train: [33][475/750]	BT 0.104 (1.153)	DT 0.026 (1.109)	loss 6.714 (6.714)	prob 2.494 (2.494)	GS 32.594 (32.594)	mem 39.954
Train: [33][480/750]	BT 2.546 (1.169)	DT 2.500 (1.125)	loss 6.659 (6.659)	prob 2.838 (2.838)	GS 35.422 (35.422)	mem 39.934
Train: [33][485/750]	BT 0.074 (1.157)	DT 0.003 (1.113)	loss 6.896 (6.896)	prob 2.091 (2.091)	GS 30.328 (30.328)	mem 39.942
Train: [33][490/750]	BT 0.047 (1.168)	DT 0.010 (1.124)	loss 6.845 (6.845)	prob 2.751 (2.751)	GS 32.328 (32.328)	mem 39.950
Train: [33][495/750]	BT 0.039 (1.157)	DT 0.002 (1.113)	loss 7.074 (7.074)	prob 2.309 (2.309)	GS 32.750 (32.750)	mem 39.994
Train: [33][500/750]	BT 11.231 (1.169)	DT 11.199 (1.125)	loss 6.763 (6.763)	prob 2.763 (2.763)	GS 32.812 (32.812)	mem 39.851
Train: [33][505/750]	BT 0.063 (1.158)	DT 0.001 (1.114)	loss 6.829 (6.829)	prob 2.446 (2.446)	GS 34.250 (34.250)	mem 39.996
Train: [33][510/750]	BT 0.026 (1.149)	DT 0.001 (1.106)	loss 7.012 (7.012)	prob 2.697 (2.697)	GS 33.375 (33.375)	mem 39.922
Train: [33][515/750]	BT 0.037 (1.162)	DT 0.001 (1.119)	loss 6.998 (6.998)	prob 2.478 (2.478)	GS 28.188 (28.188)	mem 39.994
Train: [33][520/750]	BT 0.443 (1.154)	DT 0.387 (1.110)	loss 6.859 (6.859)	prob 2.171 (2.171)	GS 33.641 (33.641)	mem 39.937
Train: [33][525/750]	BT 0.051 (1.167)	DT 0.002 (1.123)	loss 6.864 (6.864)	prob 2.908 (2.908)	GS 27.234 (27.234)	mem 40.073
Train: [33][530/750]	BT 0.100 (1.157)	DT 0.035 (1.113)	loss 6.833 (6.833)	prob 2.725 (2.725)	GS 34.109 (34.109)	mem 40.014
Train: [33][535/750]	BT 0.056 (1.149)	DT 0.028 (1.105)	loss 6.942 (6.942)	prob 2.618 (2.618)	GS 36.438 (36.438)	mem 39.982
Train: [33][540/750]	BT 0.030 (1.158)	DT 0.001 (1.114)	loss 6.755 (6.755)	prob 2.648 (2.648)	GS 30.938 (30.938)	mem 39.980
Train: [33][545/750]	BT 0.074 (1.161)	DT 0.006 (1.117)	loss 6.965 (6.965)	prob 2.989 (2.989)	GS 33.938 (33.938)	mem 39.989
Train: [33][550/750]	BT 0.024 (1.160)	DT 0.001 (1.116)	loss 6.965 (6.965)	prob 2.509 (2.509)	GS 37.234 (37.234)	mem 40.008
Train: [33][555/750]	BT 0.055 (1.150)	DT 0.013 (1.106)	loss 7.122 (7.122)	prob 2.209 (2.209)	GS 33.828 (33.828)	mem 40.166
Train: [33][560/750]	BT 6.793 (1.164)	DT 6.761 (1.120)	loss 6.889 (6.889)	prob 2.447 (2.447)	GS 32.750 (32.750)	mem 40.119
Train: [33][565/750]	BT 0.053 (1.154)	DT 0.014 (1.110)	loss 6.851 (6.851)	prob 2.545 (2.545)	GS 29.266 (29.266)	mem 39.994
Train: [33][570/750]	BT 0.068 (1.156)	DT 0.008 (1.112)	loss 6.696 (6.696)	prob 3.083 (3.083)	GS 33.172 (33.172)	mem 40.093
Train: [33][575/750]	BT 0.031 (1.161)	DT 0.001 (1.117)	loss 7.078 (7.078)	prob 2.398 (2.398)	GS 34.609 (34.609)	mem 40.094
Train: [33][580/750]	BT 1.556 (1.154)	DT 1.512 (1.110)	loss 6.883 (6.883)	prob 2.816 (2.816)	GS 30.125 (30.125)	mem 40.060
Train: [33][585/750]	BT 0.038 (1.164)	DT 0.011 (1.120)	loss 6.948 (6.948)	prob 2.273 (2.273)	GS 37.484 (37.484)	mem 40.014
Train: [33][590/750]	BT 0.081 (1.154)	DT 0.001 (1.110)	loss 6.885 (6.885)	prob 2.346 (2.346)	GS 34.594 (34.594)	mem 40.016
Train: [33][595/750]	BT 0.035 (1.147)	DT 0.001 (1.103)	loss 6.935 (6.935)	prob 2.390 (2.390)	GS 33.375 (33.375)	mem 40.021
Train: [33][600/750]	BT 0.036 (1.158)	DT 0.001 (1.114)	loss 7.131 (7.131)	prob 2.123 (2.123)	GS 30.156 (30.156)	mem 39.986
Train: [33][605/750]	BT 0.050 (1.149)	DT 0.009 (1.105)	loss 6.782 (6.782)	prob 2.742 (2.742)	GS 32.453 (32.453)	mem 39.986
Train: [33][610/750]	BT 0.120 (1.163)	DT 0.021 (1.120)	loss 6.857 (6.857)	prob 3.165 (3.165)	GS 31.578 (31.578)	mem 40.028
Train: [33][615/750]	BT 0.038 (1.155)	DT 0.006 (1.111)	loss 7.043 (7.043)	prob 2.815 (2.815)	GS 33.250 (33.250)	mem 40.032
Train: [33][620/750]	BT 11.931 (1.165)	DT 11.898 (1.121)	loss 6.770 (6.770)	prob 2.914 (2.914)	GS 33.172 (33.172)	mem 39.991
Train: [33][625/750]	BT 0.037 (1.156)	DT 0.014 (1.112)	loss 7.138 (7.138)	prob 2.838 (2.838)	GS 38.266 (38.266)	mem 39.992
Train: [33][630/750]	BT 0.029 (1.147)	DT 0.001 (1.103)	loss 6.989 (6.989)	prob 2.388 (2.388)	GS 35.781 (35.781)	mem 40.010
Train: [33][635/750]	BT 0.031 (1.162)	DT 0.001 (1.118)	loss 6.711 (6.711)	prob 2.839 (2.839)	GS 32.203 (32.203)	mem 39.965
Train: [33][640/750]	BT 0.080 (1.153)	DT 0.003 (1.109)	loss 6.906 (6.906)	prob 2.546 (2.546)	GS 35.203 (35.203)	mem 40.060
Train: [33][645/750]	BT 0.044 (1.160)	DT 0.006 (1.116)	loss 6.898 (6.898)	prob 2.150 (2.150)	GS 28.062 (28.062)	mem 40.125
Train: [33][650/750]	BT 0.131 (1.151)	DT 0.015 (1.108)	loss 6.711 (6.711)	prob 2.429 (2.429)	GS 34.188 (34.188)	mem 40.113
Train: [33][655/750]	BT 0.032 (1.143)	DT 0.001 (1.099)	loss 7.162 (7.162)	prob 2.266 (2.266)	GS 32.719 (32.719)	mem 40.069
Train: [33][660/750]	BT 0.034 (1.155)	DT 0.002 (1.111)	loss 6.765 (6.765)	prob 2.789 (2.789)	GS 33.250 (33.250)	mem 39.992
Train: [33][665/750]	BT 0.039 (1.147)	DT 0.001 (1.103)	loss 7.011 (7.011)	prob 2.591 (2.591)	GS 30.891 (30.891)	mem 40.125
Train: [33][670/750]	BT 0.052 (1.154)	DT 0.003 (1.111)	loss 6.738 (6.738)	prob 2.898 (2.898)	GS 35.734 (35.734)	mem 40.019
Train: [33][675/750]	BT 0.099 (1.154)	DT 0.024 (1.110)	loss 6.808 (6.808)	prob 2.838 (2.838)	GS 32.109 (32.109)	mem 40.000
Train: [33][680/750]	BT 9.273 (1.159)	DT 9.190 (1.116)	loss 6.868 (6.868)	prob 2.470 (2.470)	GS 34.828 (34.828)	mem 40.004
Train: [33][685/750]	BT 0.054 (1.151)	DT 0.001 (1.108)	loss 7.069 (7.069)	prob 2.097 (2.097)	GS 29.016 (29.016)	mem 40.042
Train: [33][690/750]	BT 0.059 (1.148)	DT 0.012 (1.105)	loss 6.926 (6.926)	prob 3.258 (3.258)	GS 34.156 (34.156)	mem 39.995
Train: [33][695/750]	BT 0.034 (1.149)	DT 0.004 (1.105)	loss 6.925 (6.925)	prob 2.708 (2.708)	GS 30.078 (30.078)	mem 40.325
Train: [33][700/750]	BT 0.059 (1.150)	DT 0.012 (1.106)	loss 7.149 (7.149)	prob 1.920 (1.920)	GS 31.766 (31.766)	mem 40.047
Train: [33][705/750]	BT 0.032 (1.155)	DT 0.002 (1.111)	loss 6.932 (6.932)	prob 2.770 (2.770)	GS 29.047 (29.047)	mem 39.994
Train: [33][710/750]	BT 0.744 (1.148)	DT 0.686 (1.104)	loss 6.805 (6.805)	prob 2.930 (2.930)	GS 31.281 (31.281)	mem 39.996
Train: [33][715/750]	BT 0.049 (1.140)	DT 0.004 (1.096)	loss 6.988 (6.988)	prob 2.456 (2.456)	GS 29.750 (29.750)	mem 40.046
Train: [33][720/750]	BT 0.037 (1.148)	DT 0.003 (1.104)	loss 7.147 (7.147)	prob 2.380 (2.380)	GS 33.625 (33.625)	mem 40.003
Train: [33][725/750]	BT 0.032 (1.142)	DT 0.006 (1.098)	loss 6.753 (6.753)	prob 2.976 (2.976)	GS 29.000 (29.000)	mem 40.007
Train: [33][730/750]	BT 0.032 (1.150)	DT 0.001 (1.106)	loss 7.173 (7.173)	prob 2.743 (2.743)	GS 35.688 (35.688)	mem 39.715
Train: [33][735/750]	BT 0.033 (1.142)	DT 0.005 (1.099)	loss 7.051 (7.051)	prob 2.377 (2.377)	GS 34.594 (34.594)	mem 39.716
Train: [33][740/750]	BT 7.897 (1.146)	DT 7.847 (1.102)	loss 6.964 (6.964)	prob 2.398 (2.398)	GS 31.078 (31.078)	mem 10.682
Train: [33][745/750]	BT 0.030 (1.138)	DT 0.001 (1.094)	loss 7.001 (7.001)	prob 2.534 (2.534)	GS 30.594 (30.594)	mem 10.682
Train: [33][750/750]	BT 0.030 (1.131)	DT 0.001 (1.087)	loss 6.615 (6.615)	prob 3.072 (3.072)	GS 36.000 (36.000)	mem 10.646
Train: [33][755/750]	BT 0.035 (1.126)	DT 0.001 (1.083)	loss 6.782 (6.782)	prob 3.155 (3.155)	GS 31.531 (31.531)	mem 7.681
epoch 33, total time 850.39
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [34][1/750]	BT 26.563 (26.563)	DT 26.484 (26.484)	loss 6.979 (6.979)	prob 2.120 (2.120)	GS 33.797 (33.797)	mem 39.203
Train: [34][5/750]	BT 0.041 (5.581)	DT 0.008 (5.528)	loss 6.650 (6.650)	prob 2.428 (2.428)	GS 34.031 (34.031)	mem 39.176
Train: [34][10/750]	BT 0.091 (2.813)	DT 0.023 (2.767)	loss 6.626 (6.626)	prob 2.588 (2.588)	GS 36.953 (36.953)	mem 39.491
Train: [34][15/750]	BT 0.048 (2.613)	DT 0.016 (2.565)	loss 6.700 (6.700)	prob 2.102 (2.102)	GS 31.531 (31.531)	mem 39.480
Train: [34][20/750]	BT 0.087 (2.170)	DT 0.010 (2.121)	loss 6.728 (6.728)	prob 2.551 (2.551)	GS 29.156 (29.156)	mem 39.528
Train: [34][25/750]	BT 1.587 (1.844)	DT 1.465 (1.791)	loss 6.904 (6.904)	prob 2.535 (2.535)	GS 30.672 (30.672)	mem 39.603
Train: [34][30/750]	BT 1.332 (1.877)	DT 1.299 (1.823)	loss 6.588 (6.588)	prob 2.561 (2.561)	GS 37.922 (37.922)	mem 39.509
Train: [34][35/750]	BT 0.065 (1.823)	DT 0.020 (1.770)	loss 6.916 (6.916)	prob 2.196 (2.196)	GS 29.422 (29.422)	mem 39.526
Train: [34][40/750]	BT 0.049 (1.730)	DT 0.001 (1.677)	loss 6.701 (6.701)	prob 2.417 (2.417)	GS 33.250 (33.250)	mem 39.568
Train: [34][45/750]	BT 0.031 (1.546)	DT 0.001 (1.493)	loss 6.974 (6.974)	prob 2.363 (2.363)	GS 32.828 (32.828)	mem 39.568
Train: [34][50/750]	BT 5.058 (1.658)	DT 5.027 (1.607)	loss 6.721 (6.721)	prob 2.897 (2.897)	GS 35.203 (35.203)	mem 39.599
Train: [34][55/750]	BT 0.047 (1.511)	DT 0.014 (1.461)	loss 6.869 (6.869)	prob 2.289 (2.289)	GS 32.297 (32.297)	mem 39.796
Train: [34][60/750]	BT 0.039 (1.518)	DT 0.002 (1.466)	loss 6.902 (6.902)	prob 1.973 (1.973)	GS 31.703 (31.703)	mem 39.671
Train: [34][65/750]	BT 0.034 (1.427)	DT 0.002 (1.376)	loss 6.997 (6.997)	prob 2.468 (2.468)	GS 33.578 (33.578)	mem 39.857
Train: [34][70/750]	BT 7.644 (1.466)	DT 7.612 (1.417)	loss 6.837 (6.837)	prob 2.683 (2.683)	GS 36.891 (36.891)	mem 39.770
Train: [34][75/750]	BT 0.027 (1.451)	DT 0.001 (1.402)	loss 7.055 (7.055)	prob 2.367 (2.367)	GS 38.812 (38.812)	mem 39.798
Train: [34][80/750]	BT 0.078 (1.365)	DT 0.008 (1.315)	loss 6.775 (6.775)	prob 2.072 (2.072)	GS 35.875 (35.875)	mem 39.721
Train: [34][85/750]	BT 0.033 (1.400)	DT 0.002 (1.351)	loss 6.952 (6.952)	prob 2.216 (2.216)	GS 28.297 (28.297)	mem 39.743
Train: [34][90/750]	BT 1.212 (1.361)	DT 1.181 (1.313)	loss 6.685 (6.685)	prob 2.800 (2.800)	GS 32.812 (32.812)	mem 39.752
Train: [34][95/750]	BT 0.049 (1.391)	DT 0.010 (1.344)	loss 6.576 (6.576)	prob 2.762 (2.762)	GS 31.875 (31.875)	mem 39.792
Train: [34][100/750]	BT 0.039 (1.339)	DT 0.001 (1.292)	loss 6.988 (6.988)	prob 2.055 (2.055)	GS 38.391 (38.391)	mem 39.759
Train: [34][105/750]	BT 0.029 (1.282)	DT 0.001 (1.236)	loss 6.810 (6.810)	prob 3.123 (3.123)	GS 33.812 (33.812)	mem 39.716
Train: [34][110/750]	BT 1.031 (1.334)	DT 1.000 (1.288)	loss 6.849 (6.849)	prob 1.599 (1.599)	GS 34.906 (34.906)	mem 39.691
Train: [34][115/750]	BT 0.044 (1.277)	DT 0.002 (1.232)	loss 7.131 (7.131)	prob 2.264 (2.264)	GS 31.641 (31.641)	mem 39.819
Train: [34][120/750]	BT 0.042 (1.379)	DT 0.001 (1.334)	loss 7.091 (7.091)	prob 2.606 (2.606)	GS 32.562 (32.562)	mem 39.917
Train: [34][125/750]	BT 0.032 (1.326)	DT 0.002 (1.281)	loss 6.911 (6.911)	prob 2.520 (2.520)	GS 27.984 (27.984)	mem 39.822
Train: [34][130/750]	BT 14.093 (1.384)	DT 14.061 (1.340)	loss 6.716 (6.716)	prob 2.052 (2.052)	GS 34.750 (34.750)	mem 39.875
Train: [34][135/750]	BT 0.024 (1.335)	DT 0.001 (1.291)	loss 7.002 (7.002)	prob 2.282 (2.282)	GS 29.562 (29.562)	mem 39.806
Train: [34][140/750]	BT 0.067 (1.289)	DT 0.003 (1.245)	loss 7.169 (7.169)	prob 1.947 (1.947)	GS 31.188 (31.188)	mem 39.824
Train: [34][145/750]	BT 0.071 (1.329)	DT 0.010 (1.285)	loss 7.042 (7.042)	prob 2.652 (2.652)	GS 28.594 (28.594)	mem 39.808
Train: [34][150/750]	BT 0.038 (1.286)	DT 0.002 (1.242)	loss 7.101 (7.101)	prob 2.563 (2.563)	GS 35.297 (35.297)	mem 39.807
Train: [34][155/750]	BT 0.063 (1.335)	DT 0.014 (1.291)	loss 6.892 (6.892)	prob 2.685 (2.685)	GS 29.062 (29.062)	mem 39.860
Train: [34][160/750]	BT 0.087 (1.295)	DT 0.001 (1.251)	loss 6.814 (6.814)	prob 2.826 (2.826)	GS 29.703 (29.703)	mem 39.862
Train: [34][165/750]	BT 0.039 (1.257)	DT 0.009 (1.213)	loss 7.003 (7.003)	prob 2.732 (2.732)	GS 30.219 (30.219)	mem 39.849
Train: [34][170/750]	BT 0.030 (1.305)	DT 0.001 (1.261)	loss 6.764 (6.764)	prob 2.754 (2.754)	GS 33.516 (33.516)	mem 39.900
Train: [34][175/750]	BT 0.033 (1.269)	DT 0.001 (1.225)	loss 7.197 (7.197)	prob 2.317 (2.317)	GS 30.688 (30.688)	mem 39.900
Train: [34][180/750]	BT 0.039 (1.314)	DT 0.001 (1.271)	loss 6.934 (6.934)	prob 2.548 (2.548)	GS 33.234 (33.234)	mem 39.871
Train: [34][185/750]	BT 0.038 (1.281)	DT 0.003 (1.237)	loss 6.913 (6.913)	prob 2.723 (2.723)	GS 30.469 (30.469)	mem 39.893
Train: [34][190/750]	BT 14.532 (1.324)	DT 14.472 (1.281)	loss 6.636 (6.636)	prob 2.302 (2.302)	GS 33.641 (33.641)	mem 39.825
Train: [34][195/750]	BT 0.042 (1.292)	DT 0.001 (1.248)	loss 7.077 (7.077)	prob 2.624 (2.624)	GS 29.875 (29.875)	mem 39.825
Train: [34][200/750]	BT 0.054 (1.260)	DT 0.001 (1.217)	loss 6.719 (6.719)	prob 2.931 (2.931)	GS 33.531 (33.531)	mem 39.827
Train: [34][205/750]	BT 0.023 (1.298)	DT 0.001 (1.255)	loss 6.760 (6.760)	prob 2.752 (2.752)	GS 33.109 (33.109)	mem 39.864
Train: [34][210/750]	BT 0.091 (1.268)	DT 0.005 (1.225)	loss 6.770 (6.770)	prob 2.570 (2.570)	GS 29.469 (29.469)	mem 39.896
Train: [34][215/750]	BT 0.067 (1.307)	DT 0.023 (1.264)	loss 6.878 (6.878)	prob 2.521 (2.521)	GS 33.297 (33.297)	mem 39.826
Train: [34][220/750]	BT 0.029 (1.278)	DT 0.001 (1.235)	loss 7.184 (7.184)	prob 2.449 (2.449)	GS 36.312 (36.312)	mem 39.825
Train: [34][225/750]	BT 0.071 (1.251)	DT 0.007 (1.208)	loss 6.800 (6.800)	prob 2.443 (2.443)	GS 32.203 (32.203)	mem 39.825
Train: [34][230/750]	BT 0.118 (1.263)	DT 0.002 (1.220)	loss 6.846 (6.846)	prob 2.639 (2.639)	GS 29.000 (29.000)	mem 39.918
Train: [34][235/750]	BT 0.033 (1.238)	DT 0.002 (1.194)	loss 6.962 (6.962)	prob 2.202 (2.202)	GS 31.984 (31.984)	mem 39.882
Train: [34][240/750]	BT 0.040 (1.263)	DT 0.004 (1.219)	loss 7.015 (7.015)	prob 2.439 (2.439)	GS 33.297 (33.297)	mem 39.949
Train: [34][245/750]	BT 0.091 (1.238)	DT 0.014 (1.194)	loss 6.743 (6.743)	prob 2.904 (2.904)	GS 26.047 (26.047)	mem 39.943
Train: [34][250/750]	BT 11.613 (1.261)	DT 11.535 (1.217)	loss 7.044 (7.044)	prob 1.995 (1.995)	GS 32.594 (32.594)	mem 39.919
Train: [34][255/750]	BT 0.050 (1.237)	DT 0.005 (1.193)	loss 6.743 (6.743)	prob 2.434 (2.434)	GS 36.031 (36.031)	mem 40.000
Train: [34][260/750]	BT 0.039 (1.214)	DT 0.002 (1.170)	loss 6.861 (6.861)	prob 2.706 (2.706)	GS 30.125 (30.125)	mem 39.918
Train: [34][265/750]	BT 0.085 (1.238)	DT 0.008 (1.194)	loss 7.070 (7.070)	prob 1.965 (1.965)	GS 32.578 (32.578)	mem 40.013
Train: [34][270/750]	BT 0.093 (1.216)	DT 0.001 (1.172)	loss 6.913 (6.913)	prob 2.408 (2.408)	GS 36.453 (36.453)	mem 39.960
Train: [34][275/750]	BT 0.031 (1.250)	DT 0.002 (1.206)	loss 6.928 (6.928)	prob 2.143 (2.143)	GS 30.422 (30.422)	mem 39.949
Train: [34][280/750]	BT 0.033 (1.228)	DT 0.001 (1.184)	loss 7.110 (7.110)	prob 2.636 (2.636)	GS 35.844 (35.844)	mem 39.950
Train: [34][285/750]	BT 0.032 (1.208)	DT 0.001 (1.164)	loss 7.014 (7.014)	prob 2.756 (2.756)	GS 29.109 (29.109)	mem 39.951
Train: [34][290/750]	BT 0.032 (1.240)	DT 0.002 (1.197)	loss 7.348 (7.348)	prob 2.017 (2.017)	GS 32.422 (32.422)	mem 39.969
Train: [34][295/750]	BT 0.042 (1.220)	DT 0.001 (1.177)	loss 6.788 (6.788)	prob 2.825 (2.825)	GS 32.953 (32.953)	mem 39.971
Train: [34][300/750]	BT 0.048 (1.240)	DT 0.001 (1.196)	loss 7.154 (7.154)	prob 2.241 (2.241)	GS 35.969 (35.969)	mem 39.990
Train: [34][305/750]	BT 0.052 (1.221)	DT 0.001 (1.177)	loss 6.772 (6.772)	prob 3.279 (3.279)	GS 34.016 (34.016)	mem 39.969
Train: [34][310/750]	BT 13.672 (1.246)	DT 13.627 (1.202)	loss 6.805 (6.805)	prob 2.611 (2.611)	GS 35.641 (35.641)	mem 39.911
Train: [34][315/750]	BT 0.023 (1.226)	DT 0.001 (1.183)	loss 6.898 (6.898)	prob 2.932 (2.932)	GS 31.578 (31.578)	mem 39.913
Train: [34][320/750]	BT 0.059 (1.208)	DT 0.005 (1.164)	loss 6.910 (6.910)	prob 2.520 (2.520)	GS 35.172 (35.172)	mem 39.911
Train: [34][325/750]	BT 0.083 (1.232)	DT 0.012 (1.188)	loss 7.028 (7.028)	prob 2.533 (2.533)	GS 33.375 (33.375)	mem 39.885
Train: [34][330/750]	BT 0.033 (1.214)	DT 0.001 (1.170)	loss 6.891 (6.891)	prob 2.911 (2.911)	GS 35.422 (35.422)	mem 39.917
Train: [34][335/750]	BT 0.044 (1.230)	DT 0.002 (1.186)	loss 6.840 (6.840)	prob 2.464 (2.464)	GS 28.828 (28.828)	mem 39.892
Train: [34][340/750]	BT 0.047 (1.213)	DT 0.021 (1.169)	loss 6.871 (6.871)	prob 2.605 (2.605)	GS 30.484 (30.484)	mem 39.892
Train: [34][345/750]	BT 0.045 (1.196)	DT 0.002 (1.152)	loss 6.729 (6.729)	prob 3.085 (3.085)	GS 30.125 (30.125)	mem 39.893
Train: [34][350/750]	BT 0.033 (1.208)	DT 0.001 (1.164)	loss 6.800 (6.800)	prob 3.098 (3.098)	GS 34.469 (34.469)	mem 39.964
Train: [34][355/750]	BT 0.095 (1.197)	DT 0.002 (1.153)	loss 7.259 (7.259)	prob 2.236 (2.236)	GS 33.469 (33.469)	mem 39.909
Train: [34][360/750]	BT 0.025 (1.214)	DT 0.001 (1.170)	loss 6.945 (6.945)	prob 2.315 (2.315)	GS 33.234 (33.234)	mem 39.841
Train: [34][365/750]	BT 0.030 (1.198)	DT 0.001 (1.154)	loss 6.952 (6.952)	prob 2.533 (2.533)	GS 31.234 (31.234)	mem 39.854
Train: [34][370/750]	BT 11.927 (1.214)	DT 11.890 (1.171)	loss 7.098 (7.098)	prob 2.417 (2.417)	GS 29.016 (29.016)	mem 39.977
Train: [34][375/750]	BT 0.025 (1.199)	DT 0.001 (1.155)	loss 6.859 (6.859)	prob 2.989 (2.989)	GS 33.719 (33.719)	mem 39.946
Train: [34][380/750]	BT 0.031 (1.184)	DT 0.001 (1.141)	loss 6.638 (6.638)	prob 3.202 (3.202)	GS 32.984 (32.984)	mem 39.945
Train: [34][385/750]	BT 0.028 (1.196)	DT 0.001 (1.153)	loss 6.805 (6.805)	prob 2.532 (2.532)	GS 35.891 (35.891)	mem 39.980
Train: [34][390/750]	BT 2.579 (1.190)	DT 2.542 (1.147)	loss 6.710 (6.710)	prob 2.890 (2.890)	GS 35.188 (35.188)	mem 39.987
Train: [34][395/750]	BT 0.044 (1.192)	DT 0.008 (1.149)	loss 6.986 (6.986)	prob 2.368 (2.368)	GS 39.500 (39.500)	mem 39.952
Train: [34][400/750]	BT 2.732 (1.185)	DT 2.692 (1.142)	loss 6.838 (6.838)	prob 2.159 (2.159)	GS 30.516 (30.516)	mem 39.965
Train: [34][405/750]	BT 0.086 (1.182)	DT 0.004 (1.139)	loss 6.647 (6.647)	prob 3.249 (3.249)	GS 32.156 (32.156)	mem 40.021
Train: [34][410/750]	BT 0.065 (1.180)	DT 0.003 (1.137)	loss 6.855 (6.855)	prob 2.380 (2.380)	GS 32.328 (32.328)	mem 40.001
Train: [34][415/750]	BT 0.071 (1.185)	DT 0.021 (1.142)	loss 7.053 (7.053)	prob 3.056 (3.056)	GS 33.000 (33.000)	mem 40.400
Train: [34][420/750]	BT 0.038 (1.188)	DT 0.008 (1.145)	loss 7.087 (7.087)	prob 2.721 (2.721)	GS 33.578 (33.578)	mem 39.979
Train: [34][425/750]	BT 0.134 (1.182)	DT 0.009 (1.139)	loss 6.874 (6.874)	prob 2.954 (2.954)	GS 28.094 (28.094)	mem 40.048
Train: [34][430/750]	BT 10.395 (1.193)	DT 10.299 (1.150)	loss 6.769 (6.769)	prob 3.165 (3.165)	GS 37.438 (37.438)	mem 40.052
Train: [34][435/750]	BT 0.042 (1.185)	DT 0.012 (1.141)	loss 6.887 (6.887)	prob 2.963 (2.963)	GS 34.266 (34.266)	mem 40.035
Train: [34][440/750]	BT 0.081 (1.181)	DT 0.001 (1.137)	loss 6.889 (6.889)	prob 2.803 (2.803)	GS 35.188 (35.188)	mem 40.106
Train: [34][445/750]	BT 0.032 (1.182)	DT 0.001 (1.138)	loss 7.044 (7.044)	prob 2.714 (2.714)	GS 36.578 (36.578)	mem 39.936
Train: [34][450/750]	BT 0.039 (1.180)	DT 0.008 (1.136)	loss 6.745 (6.745)	prob 3.288 (3.288)	GS 35.125 (35.125)	mem 39.921
Train: [34][455/750]	BT 0.033 (1.182)	DT 0.001 (1.139)	loss 6.844 (6.844)	prob 2.973 (2.973)	GS 31.938 (31.938)	mem 39.931
Train: [34][460/750]	BT 0.889 (1.183)	DT 0.837 (1.139)	loss 7.015 (7.015)	prob 2.321 (2.321)	GS 35.406 (35.406)	mem 40.115
Train: [34][465/750]	BT 0.087 (1.171)	DT 0.007 (1.127)	loss 6.964 (6.964)	prob 2.317 (2.317)	GS 23.922 (23.922)	mem 40.070
Train: [34][470/750]	BT 4.841 (1.187)	DT 4.804 (1.143)	loss 6.716 (6.716)	prob 2.977 (2.977)	GS 31.969 (31.969)	mem 39.975
Train: [34][475/750]	BT 0.038 (1.180)	DT 0.008 (1.136)	loss 6.914 (6.914)	prob 3.158 (3.158)	GS 25.188 (25.188)	mem 39.962
Train: [34][480/750]	BT 0.027 (1.179)	DT 0.001 (1.135)	loss 7.050 (7.050)	prob 2.854 (2.854)	GS 33.141 (33.141)	mem 40.024
Train: [34][485/750]	BT 0.035 (1.184)	DT 0.005 (1.140)	loss 7.346 (7.346)	prob 2.465 (2.465)	GS 36.156 (36.156)	mem 40.032
Train: [34][490/750]	BT 4.271 (1.181)	DT 4.240 (1.137)	loss 6.857 (6.857)	prob 3.224 (3.224)	GS 35.484 (35.484)	mem 40.072
Train: [34][495/750]	BT 0.030 (1.180)	DT 0.001 (1.136)	loss 7.037 (7.037)	prob 2.832 (2.832)	GS 28.969 (28.969)	mem 39.983
Train: [34][500/750]	BT 0.070 (1.173)	DT 0.002 (1.129)	loss 6.672 (6.672)	prob 3.174 (3.174)	GS 32.859 (32.859)	mem 40.034
Train: [34][505/750]	BT 0.033 (1.169)	DT 0.002 (1.125)	loss 6.836 (6.836)	prob 2.999 (2.999)	GS 33.297 (33.297)	mem 40.211
Train: [34][510/750]	BT 0.055 (1.175)	DT 0.001 (1.130)	loss 6.754 (6.754)	prob 3.049 (3.049)	GS 27.109 (27.109)	mem 40.058
Train: [34][515/750]	BT 0.031 (1.175)	DT 0.001 (1.130)	loss 6.874 (6.874)	prob 2.795 (2.795)	GS 28.047 (28.047)	mem 40.036
Train: [34][520/750]	BT 0.049 (1.174)	DT 0.002 (1.130)	loss 6.832 (6.832)	prob 2.243 (2.243)	GS 31.375 (31.375)	mem 40.184
Train: [34][525/750]	BT 0.167 (1.172)	DT 0.016 (1.127)	loss 6.714 (6.714)	prob 2.778 (2.778)	GS 29.734 (29.734)	mem 40.061
Train: [34][530/750]	BT 9.891 (1.181)	DT 9.867 (1.137)	loss 6.950 (6.950)	prob 3.612 (3.612)	GS 37.312 (37.312)	mem 40.044
Train: [34][535/750]	BT 0.036 (1.171)	DT 0.005 (1.126)	loss 7.123 (7.123)	prob 2.719 (2.719)	GS 27.312 (27.312)	mem 40.045
Train: [34][540/750]	BT 0.035 (1.162)	DT 0.002 (1.117)	loss 6.831 (6.831)	prob 2.411 (2.411)	GS 31.141 (31.141)	mem 40.068
Train: [34][545/750]	BT 0.033 (1.178)	DT 0.001 (1.134)	loss 7.173 (7.173)	prob 2.846 (2.846)	GS 31.453 (31.453)	mem 40.057
Train: [34][550/750]	BT 0.119 (1.168)	DT 0.056 (1.123)	loss 7.132 (7.132)	prob 3.077 (3.077)	GS 29.375 (29.375)	mem 40.059
Train: [34][555/750]	BT 0.045 (1.188)	DT 0.003 (1.144)	loss 7.108 (7.108)	prob 2.921 (2.921)	GS 33.531 (33.531)	mem 40.000
Train: [34][560/750]	BT 0.053 (1.178)	DT 0.011 (1.134)	loss 6.961 (6.961)	prob 2.777 (2.777)	GS 33.562 (33.562)	mem 40.002
Train: [34][565/750]	BT 0.047 (1.168)	DT 0.003 (1.124)	loss 6.729 (6.729)	prob 3.095 (3.095)	GS 32.453 (32.453)	mem 40.004
Train: [34][570/750]	BT 0.049 (1.176)	DT 0.001 (1.131)	loss 6.859 (6.859)	prob 3.173 (3.173)	GS 34.266 (34.266)	mem 40.168
Train: [34][575/750]	BT 0.047 (1.166)	DT 0.005 (1.122)	loss 7.455 (7.455)	prob 2.018 (2.018)	GS 37.703 (37.703)	mem 39.995
Train: [34][580/750]	BT 0.042 (1.179)	DT 0.001 (1.134)	loss 7.007 (7.007)	prob 3.110 (3.110)	GS 36.500 (36.500)	mem 40.030
Train: [34][585/750]	BT 0.077 (1.169)	DT 0.006 (1.125)	loss 7.005 (7.005)	prob 3.255 (3.255)	GS 29.875 (29.875)	mem 40.033
Train: [34][590/750]	BT 14.458 (1.184)	DT 14.435 (1.140)	loss 7.006 (7.006)	prob 2.847 (2.847)	GS 34.438 (34.438)	mem 40.041
Train: [34][595/750]	BT 0.094 (1.175)	DT 0.029 (1.130)	loss 6.928 (6.928)	prob 3.265 (3.265)	GS 32.344 (32.344)	mem 40.041
Train: [34][600/750]	BT 0.070 (1.165)	DT 0.002 (1.121)	loss 6.844 (6.844)	prob 2.847 (2.847)	GS 31.797 (31.797)	mem 40.077
Train: [34][605/750]	BT 0.032 (1.173)	DT 0.001 (1.129)	loss 6.790 (6.790)	prob 2.850 (2.850)	GS 29.469 (29.469)	mem 40.078
Train: [34][610/750]	BT 0.032 (1.164)	DT 0.001 (1.120)	loss 6.764 (6.764)	prob 3.162 (3.162)	GS 31.516 (31.516)	mem 40.079
Train: [34][615/750]	BT 0.044 (1.175)	DT 0.016 (1.131)	loss 6.989 (6.989)	prob 2.397 (2.397)	GS 30.109 (30.109)	mem 40.090
Train: [34][620/750]	BT 0.110 (1.166)	DT 0.031 (1.122)	loss 6.868 (6.868)	prob 3.389 (3.389)	GS 35.609 (35.609)	mem 40.095
Train: [34][625/750]	BT 0.037 (1.157)	DT 0.006 (1.113)	loss 6.778 (6.778)	prob 3.583 (3.583)	GS 33.719 (33.719)	mem 40.094
Train: [34][630/750]	BT 0.038 (1.168)	DT 0.001 (1.123)	loss 6.997 (6.997)	prob 2.191 (2.191)	GS 39.016 (39.016)	mem 40.171
Train: [34][635/750]	BT 0.064 (1.159)	DT 0.002 (1.115)	loss 7.163 (7.163)	prob 3.018 (3.018)	GS 30.594 (30.594)	mem 40.131
Train: [34][640/750]	BT 0.021 (1.172)	DT 0.001 (1.128)	loss 7.018 (7.018)	prob 2.627 (2.627)	GS 36.797 (36.797)	mem 40.032
Train: [34][645/750]	BT 0.027 (1.163)	DT 0.001 (1.119)	loss 7.001 (7.001)	prob 2.496 (2.496)	GS 30.781 (30.781)	mem 40.048
Train: [34][650/750]	BT 13.484 (1.175)	DT 13.451 (1.131)	loss 6.832 (6.832)	prob 4.057 (4.057)	GS 35.141 (35.141)	mem 39.982
Train: [34][655/750]	BT 0.048 (1.166)	DT 0.001 (1.122)	loss 7.314 (7.314)	prob 1.928 (1.928)	GS 31.938 (31.938)	mem 40.026
Train: [34][660/750]	BT 0.032 (1.158)	DT 0.001 (1.114)	loss 7.083 (7.083)	prob 2.400 (2.400)	GS 34.094 (34.094)	mem 39.982
Train: [34][665/750]	BT 0.033 (1.172)	DT 0.012 (1.129)	loss 6.908 (6.908)	prob 3.524 (3.524)	GS 35.203 (35.203)	mem 39.982
Train: [34][670/750]	BT 0.068 (1.164)	DT 0.009 (1.120)	loss 7.020 (7.020)	prob 2.862 (2.862)	GS 32.625 (32.625)	mem 39.983
Train: [34][675/750]	BT 0.042 (1.174)	DT 0.005 (1.131)	loss 6.913 (6.913)	prob 2.750 (2.750)	GS 29.484 (29.484)	mem 39.974
Train: [34][680/750]	BT 0.030 (1.166)	DT 0.001 (1.122)	loss 6.839 (6.839)	prob 2.661 (2.661)	GS 33.078 (33.078)	mem 39.974
Train: [34][685/750]	BT 0.047 (1.157)	DT 0.007 (1.114)	loss 6.858 (6.858)	prob 2.958 (2.958)	GS 31.453 (31.453)	mem 39.991
Train: [34][690/750]	BT 0.056 (1.167)	DT 0.014 (1.123)	loss 6.913 (6.913)	prob 2.799 (2.799)	GS 34.703 (34.703)	mem 39.992
Train: [34][695/750]	BT 0.060 (1.159)	DT 0.029 (1.115)	loss 7.030 (7.030)	prob 2.386 (2.386)	GS 28.141 (28.141)	mem 39.915
Train: [34][700/750]	BT 0.029 (1.167)	DT 0.001 (1.124)	loss 6.923 (6.923)	prob 2.995 (2.995)	GS 34.047 (34.047)	mem 40.144
Train: [34][705/750]	BT 0.027 (1.159)	DT 0.002 (1.116)	loss 6.926 (6.926)	prob 2.772 (2.772)	GS 29.531 (29.531)	mem 40.291
Train: [34][710/750]	BT 13.241 (1.170)	DT 13.209 (1.127)	loss 6.849 (6.849)	prob 3.094 (3.094)	GS 31.859 (31.859)	mem 39.994
Train: [34][715/750]	BT 0.059 (1.162)	DT 0.008 (1.119)	loss 6.824 (6.824)	prob 3.324 (3.324)	GS 36.141 (36.141)	mem 40.052
Train: [34][720/750]	BT 0.057 (1.155)	DT 0.004 (1.111)	loss 6.781 (6.781)	prob 2.759 (2.759)	GS 30.984 (30.984)	mem 39.998
Train: [34][725/750]	BT 0.059 (1.161)	DT 0.001 (1.117)	loss 7.186 (7.186)	prob 2.467 (2.467)	GS 30.719 (30.719)	mem 39.916
Train: [34][730/750]	BT 0.037 (1.153)	DT 0.001 (1.109)	loss 6.808 (6.808)	prob 3.328 (3.328)	GS 35.438 (35.438)	mem 39.918
Train: [34][735/750]	BT 0.027 (1.158)	DT 0.001 (1.114)	loss 6.855 (6.855)	prob 2.391 (2.391)	GS 29.578 (29.578)	mem 36.599
Train: [34][740/750]	BT 0.029 (1.150)	DT 0.002 (1.106)	loss 7.033 (7.033)	prob 2.205 (2.205)	GS 34.797 (34.797)	mem 36.564
Train: [34][745/750]	BT 0.033 (1.143)	DT 0.001 (1.099)	loss 7.067 (7.067)	prob 2.181 (2.181)	GS 35.094 (35.094)	mem 36.566
Train: [34][750/750]	BT 0.030 (1.137)	DT 0.001 (1.094)	loss 6.854 (6.854)	prob 2.805 (2.805)	GS 31.875 (31.875)	mem 10.583
Train: [34][755/750]	BT 0.041 (1.131)	DT 0.002 (1.087)	loss 6.885 (6.885)	prob 2.711 (2.711)	GS 34.000 (34.000)	mem 7.612
epoch 34, total time 853.95
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [35][1/750]	BT 20.937 (20.937)	DT 20.877 (20.877)	loss 6.733 (6.733)	prob 2.776 (2.776)	GS 34.297 (34.297)	mem 38.560
Train: [35][5/750]	BT 0.031 (5.187)	DT 0.001 (5.139)	loss 6.880 (6.880)	prob 2.273 (2.273)	GS 32.688 (32.688)	mem 38.626
Train: [35][10/750]	BT 0.049 (2.737)	DT 0.001 (2.683)	loss 6.898 (6.898)	prob 2.636 (2.636)	GS 35.891 (35.891)	mem 38.632
Train: [35][15/750]	BT 0.035 (2.670)	DT 0.001 (2.621)	loss 6.939 (6.939)	prob 1.752 (1.752)	GS 29.531 (29.531)	mem 38.879
Train: [35][20/750]	BT 3.964 (2.210)	DT 3.905 (2.162)	loss 6.706 (6.706)	prob 1.942 (1.942)	GS 30.438 (30.438)	mem 39.027
Train: [35][25/750]	BT 0.036 (1.782)	DT 0.002 (1.730)	loss 6.714 (6.714)	prob 2.629 (2.629)	GS 33.516 (33.516)	mem 39.193
Train: [35][30/750]	BT 0.082 (2.052)	DT 0.009 (2.002)	loss 6.979 (6.979)	prob 2.500 (2.500)	GS 30.516 (30.516)	mem 38.992
Train: [35][35/750]	BT 0.052 (1.764)	DT 0.024 (1.717)	loss 6.729 (6.729)	prob 2.667 (2.667)	GS 26.781 (26.781)	mem 38.992
Train: [35][40/750]	BT 4.062 (1.832)	DT 4.030 (1.787)	loss 6.826 (6.826)	prob 2.482 (2.482)	GS 32.328 (32.328)	mem 38.984
Train: [35][45/750]	BT 0.044 (1.634)	DT 0.016 (1.589)	loss 6.752 (6.752)	prob 3.124 (3.124)	GS 31.172 (31.172)	mem 39.061
Train: [35][50/750]	BT 2.932 (1.601)	DT 2.900 (1.555)	loss 6.858 (6.858)	prob 2.460 (2.460)	GS 34.281 (34.281)	mem 39.026
Train: [35][55/750]	BT 0.032 (1.563)	DT 0.001 (1.517)	loss 6.695 (6.695)	prob 2.596 (2.596)	GS 31.875 (31.875)	mem 39.016
Train: [35][60/750]	BT 7.526 (1.561)	DT 7.466 (1.515)	loss 6.758 (6.758)	prob 2.445 (2.445)	GS 36.047 (36.047)	mem 39.078
Train: [35][65/750]	BT 0.024 (1.559)	DT 0.001 (1.515)	loss 7.129 (7.129)	prob 2.565 (2.565)	GS 39.266 (39.266)	mem 38.997
Train: [35][70/750]	BT 0.030 (1.451)	DT 0.001 (1.407)	loss 7.052 (7.052)	prob 2.018 (2.018)	GS 33.266 (33.266)	mem 39.030
Train: [35][75/750]	BT 0.062 (1.414)	DT 0.011 (1.369)	loss 6.625 (6.625)	prob 2.631 (2.631)	GS 28.312 (28.312)	mem 39.111
Train: [35][80/750]	BT 0.024 (1.433)	DT 0.001 (1.389)	loss 6.794 (6.794)	prob 2.534 (2.534)	GS 31.734 (31.734)	mem 39.250
Train: [35][85/750]	BT 0.033 (1.353)	DT 0.002 (1.308)	loss 6.571 (6.571)	prob 2.619 (2.619)	GS 33.297 (33.297)	mem 39.210
Train: [35][90/750]	BT 0.034 (1.408)	DT 0.001 (1.363)	loss 6.594 (6.594)	prob 2.599 (2.599)	GS 33.781 (33.781)	mem 39.062
Train: [35][95/750]	BT 0.045 (1.336)	DT 0.003 (1.291)	loss 6.524 (6.524)	prob 3.375 (3.375)	GS 30.438 (30.438)	mem 39.063
Train: [35][100/750]	BT 8.322 (1.402)	DT 8.291 (1.357)	loss 6.806 (6.806)	prob 2.784 (2.784)	GS 33.438 (33.438)	mem 39.165
Train: [35][105/750]	BT 0.033 (1.337)	DT 0.001 (1.292)	loss 6.606 (6.606)	prob 2.954 (2.954)	GS 31.875 (31.875)	mem 39.166
Train: [35][110/750]	BT 6.285 (1.336)	DT 6.245 (1.292)	loss 6.678 (6.678)	prob 2.703 (2.703)	GS 33.469 (33.469)	mem 39.208
Train: [35][115/750]	BT 0.046 (1.331)	DT 0.016 (1.286)	loss 6.495 (6.495)	prob 3.624 (3.624)	GS 31.797 (31.797)	mem 39.215
Train: [35][120/750]	BT 0.700 (1.282)	DT 0.665 (1.238)	loss 6.760 (6.760)	prob 2.186 (2.186)	GS 36.016 (36.016)	mem 39.342
Train: [35][125/750]	BT 0.052 (1.348)	DT 0.014 (1.304)	loss 6.578 (6.578)	prob 2.655 (2.655)	GS 28.172 (28.172)	mem 39.204
Train: [35][130/750]	BT 0.031 (1.298)	DT 0.001 (1.254)	loss 7.042 (7.042)	prob 2.953 (2.953)	GS 31.766 (31.766)	mem 39.250
Train: [35][135/750]	BT 0.069 (1.268)	DT 0.002 (1.224)	loss 6.672 (6.672)	prob 2.982 (2.982)	GS 36.391 (36.391)	mem 39.214
Train: [35][140/750]	BT 0.033 (1.267)	DT 0.002 (1.224)	loss 6.858 (6.858)	prob 1.748 (1.748)	GS 34.344 (34.344)	mem 39.294
Train: [35][145/750]	BT 0.026 (1.275)	DT 0.001 (1.231)	loss 6.714 (6.714)	prob 2.624 (2.624)	GS 31.016 (31.016)	mem 39.311
Train: [35][150/750]	BT 0.053 (1.278)	DT 0.001 (1.235)	loss 6.941 (6.941)	prob 2.792 (2.792)	GS 35.453 (35.453)	mem 39.327
Train: [35][155/750]	BT 0.033 (1.240)	DT 0.002 (1.195)	loss 6.914 (6.914)	prob 3.433 (3.433)	GS 32.641 (32.641)	mem 39.359
Train: [35][160/750]	BT 0.174 (1.267)	DT 0.143 (1.223)	loss 6.840 (6.840)	prob 2.657 (2.657)	GS 32.219 (32.219)	mem 39.334
Train: [35][165/750]	BT 0.031 (1.230)	DT 0.001 (1.186)	loss 7.263 (7.263)	prob 3.067 (3.067)	GS 32.391 (32.391)	mem 39.333
Train: [35][170/750]	BT 0.036 (1.261)	DT 0.001 (1.216)	loss 6.823 (6.823)	prob 3.360 (3.360)	GS 36.828 (36.828)	mem 39.409
Train: [35][175/750]	BT 0.064 (1.253)	DT 0.015 (1.208)	loss 6.947 (6.947)	prob 3.213 (3.213)	GS 28.906 (28.906)	mem 39.531
Train: [35][180/750]	BT 5.748 (1.252)	DT 5.714 (1.207)	loss 6.812 (6.812)	prob 3.718 (3.718)	GS 33.516 (33.516)	mem 39.493
Train: [35][185/750]	BT 0.062 (1.267)	DT 0.014 (1.222)	loss 6.936 (6.936)	prob 3.690 (3.690)	GS 30.078 (30.078)	mem 39.741
Train: [35][190/750]	BT 0.515 (1.237)	DT 0.484 (1.192)	loss 7.169 (7.169)	prob 3.140 (3.140)	GS 33.891 (33.891)	mem 39.628
Train: [35][195/750]	BT 0.069 (1.250)	DT 0.023 (1.205)	loss 7.226 (7.226)	prob 3.037 (3.037)	GS 27.953 (27.953)	mem 39.507
Train: [35][200/750]	BT 0.056 (1.233)	DT 0.004 (1.188)	loss 7.101 (7.101)	prob 3.050 (3.050)	GS 34.391 (34.391)	mem 39.661
Train: [35][205/750]	BT 0.058 (1.245)	DT 0.005 (1.200)	loss 6.929 (6.929)	prob 3.032 (3.032)	GS 31.250 (31.250)	mem 39.733
Train: [35][210/750]	BT 0.039 (1.242)	DT 0.003 (1.196)	loss 6.796 (6.796)	prob 3.563 (3.563)	GS 34.844 (34.844)	mem 39.592
Train: [35][215/750]	BT 0.037 (1.214)	DT 0.001 (1.169)	loss 6.778 (6.778)	prob 2.911 (2.911)	GS 30.750 (30.750)	mem 39.616
Train: [35][220/750]	BT 3.224 (1.251)	DT 3.192 (1.206)	loss 7.272 (7.272)	prob 2.126 (2.126)	GS 34.703 (34.703)	mem 39.598
Train: [35][225/750]	BT 0.048 (1.224)	DT 0.001 (1.179)	loss 7.106 (7.106)	prob 2.724 (2.724)	GS 33.328 (33.328)	mem 39.635
Train: [35][230/750]	BT 0.033 (1.249)	DT 0.001 (1.204)	loss 6.720 (6.720)	prob 3.398 (3.398)	GS 33.500 (33.500)	mem 39.748
Train: [35][235/750]	BT 0.027 (1.226)	DT 0.001 (1.181)	loss 7.173 (7.173)	prob 2.484 (2.484)	GS 29.219 (29.219)	mem 39.587
Train: [35][240/750]	BT 10.723 (1.246)	DT 10.690 (1.202)	loss 7.063 (7.063)	prob 3.359 (3.359)	GS 34.500 (34.500)	mem 39.653
Train: [35][245/750]	BT 0.049 (1.229)	DT 0.003 (1.185)	loss 6.708 (6.708)	prob 3.323 (3.323)	GS 31.859 (31.859)	mem 39.605
Train: [35][250/750]	BT 0.067 (1.205)	DT 0.002 (1.161)	loss 7.021 (7.021)	prob 2.255 (2.255)	GS 29.750 (29.750)	mem 39.685
Train: [35][255/750]	BT 0.029 (1.223)	DT 0.001 (1.179)	loss 6.934 (6.934)	prob 3.252 (3.252)	GS 28.703 (28.703)	mem 39.726
Train: [35][260/750]	BT 0.056 (1.210)	DT 0.005 (1.166)	loss 7.360 (7.360)	prob 2.487 (2.487)	GS 36.609 (36.609)	mem 39.654
Train: [35][265/750]	BT 0.023 (1.231)	DT 0.001 (1.187)	loss 6.922 (6.922)	prob 3.222 (3.222)	GS 29.688 (29.688)	mem 39.855
Train: [35][270/750]	BT 0.065 (1.212)	DT 0.007 (1.168)	loss 7.270 (7.270)	prob 3.274 (3.274)	GS 31.844 (31.844)	mem 39.929
Train: [35][275/750]	BT 0.038 (1.191)	DT 0.001 (1.147)	loss 6.814 (6.814)	prob 2.934 (2.934)	GS 30.203 (30.203)	mem 39.927
Train: [35][280/750]	BT 0.024 (1.214)	DT 0.001 (1.171)	loss 7.435 (7.435)	prob 2.623 (2.623)	GS 36.500 (36.500)	mem 39.920
Train: [35][285/750]	BT 0.024 (1.194)	DT 0.001 (1.150)	loss 6.852 (6.852)	prob 2.864 (2.864)	GS 29.094 (29.094)	mem 39.922
Train: [35][290/750]	BT 0.030 (1.211)	DT 0.001 (1.168)	loss 7.232 (7.232)	prob 2.741 (2.741)	GS 33.547 (33.547)	mem 39.934
Train: [35][295/750]	BT 0.037 (1.199)	DT 0.001 (1.156)	loss 6.626 (6.626)	prob 2.482 (2.482)	GS 34.141 (34.141)	mem 39.935
Train: [35][300/750]	BT 7.853 (1.214)	DT 7.822 (1.171)	loss 7.246 (7.246)	prob 2.562 (2.562)	GS 33.797 (33.797)	mem 39.937
Train: [35][305/750]	BT 0.132 (1.197)	DT 0.002 (1.154)	loss 7.250 (7.250)	prob 2.419 (2.419)	GS 34.016 (34.016)	mem 40.153
Train: [35][310/750]	BT 0.176 (1.193)	DT 0.022 (1.149)	loss 7.331 (7.331)	prob 2.833 (2.833)	GS 32.844 (32.844)	mem 40.227
Train: [35][315/750]	BT 0.056 (1.205)	DT 0.002 (1.161)	loss 6.940 (6.940)	prob 2.387 (2.387)	GS 33.281 (33.281)	mem 39.972
Train: [35][320/750]	BT 2.588 (1.195)	DT 2.557 (1.151)	loss 7.442 (7.442)	prob 1.419 (1.419)	GS 35.031 (35.031)	mem 39.971
Train: [35][325/750]	BT 0.053 (1.207)	DT 0.002 (1.163)	loss 7.501 (7.501)	prob 2.294 (2.294)	GS 33.297 (33.297)	mem 39.981
Train: [35][330/750]	BT 0.043 (1.193)	DT 0.001 (1.149)	loss 7.516 (7.516)	prob 2.384 (2.384)	GS 30.953 (30.953)	mem 40.005
Train: [35][335/750]	BT 0.031 (1.190)	DT 0.001 (1.147)	loss 7.143 (7.143)	prob 2.429 (2.429)	GS 33.938 (33.938)	mem 39.941
Train: [35][340/750]	BT 0.044 (1.200)	DT 0.009 (1.157)	loss 7.466 (7.466)	prob 2.808 (2.808)	GS 32.344 (32.344)	mem 39.948
Train: [35][345/750]	BT 0.056 (1.184)	DT 0.024 (1.141)	loss 7.358 (7.358)	prob 2.591 (2.591)	GS 31.047 (31.047)	mem 39.922
Train: [35][350/750]	BT 0.084 (1.202)	DT 0.001 (1.158)	loss 7.424 (7.424)	prob 3.099 (3.099)	GS 34.359 (34.359)	mem 40.019
Train: [35][355/750]	BT 0.056 (1.186)	DT 0.001 (1.142)	loss 7.188 (7.188)	prob 2.617 (2.617)	GS 28.922 (28.922)	mem 40.020
Train: [35][360/750]	BT 7.329 (1.207)	DT 7.296 (1.163)	loss 7.287 (7.287)	prob 3.149 (3.149)	GS 36.531 (36.531)	mem 40.015
Train: [35][365/750]	BT 0.023 (1.191)	DT 0.001 (1.147)	loss 7.200 (7.200)	prob 1.873 (1.873)	GS 31.125 (31.125)	mem 40.016
Train: [35][370/750]	BT 2.520 (1.182)	DT 2.484 (1.138)	loss 7.276 (7.276)	prob 2.552 (2.552)	GS 30.547 (30.547)	mem 40.123
Train: [35][375/750]	BT 0.033 (1.195)	DT 0.002 (1.152)	loss 7.138 (7.138)	prob 2.480 (2.480)	GS 27.859 (27.859)	mem 39.995
Train: [35][380/750]	BT 0.035 (1.180)	DT 0.002 (1.137)	loss 7.090 (7.090)	prob 1.459 (1.459)	GS 33.391 (33.391)	mem 39.871
Train: [35][385/750]	BT 0.057 (1.195)	DT 0.024 (1.152)	loss 7.249 (7.249)	prob 2.407 (2.407)	GS 30.094 (30.094)	mem 40.009
Train: [35][390/750]	BT 0.060 (1.181)	DT 0.008 (1.137)	loss 7.754 (7.754)	prob 2.305 (2.305)	GS 30.969 (30.969)	mem 40.011
Train: [35][395/750]	BT 0.083 (1.175)	DT 0.007 (1.132)	loss 7.120 (7.120)	prob 2.208 (2.208)	GS 27.875 (27.875)	mem 40.217
Train: [35][400/750]	BT 0.048 (1.183)	DT 0.007 (1.139)	loss 8.049 (8.049)	prob 2.047 (2.047)	GS 34.719 (34.719)	mem 39.945
Train: [35][405/750]	BT 0.035 (1.169)	DT 0.002 (1.125)	loss 7.425 (7.425)	prob 1.489 (1.489)	GS 35.438 (35.438)	mem 39.908
Train: [35][410/750]	BT 0.032 (1.184)	DT 0.001 (1.141)	loss 7.964 (7.964)	prob 1.886 (1.886)	GS 33.547 (33.547)	mem 39.994
Train: [35][415/750]	BT 0.121 (1.170)	DT 0.008 (1.127)	loss 8.118 (8.118)	prob 0.994 (0.994)	GS 33.391 (33.391)	mem 39.996
Train: [35][420/750]	BT 10.077 (1.192)	DT 10.030 (1.148)	loss 7.816 (7.816)	prob 2.427 (2.427)	GS 36.609 (36.609)	mem 39.752
Train: [35][425/750]	BT 0.043 (1.178)	DT 0.001 (1.135)	loss 7.399 (7.399)	prob 2.570 (2.570)	GS 55.391 (55.391)	mem 39.753
Train: [35][430/750]	BT 7.083 (1.182)	DT 7.028 (1.138)	loss 8.233 (8.233)	prob 1.366 (1.366)	GS 36.172 (36.172)	mem 39.922
Train: [35][435/750]	BT 0.055 (1.181)	DT 0.001 (1.137)	loss 7.377 (7.377)	prob 2.513 (2.513)	GS 32.562 (32.562)	mem 39.958
Train: [35][440/750]	BT 0.100 (1.173)	DT 0.002 (1.128)	loss 7.047 (7.047)	prob 2.040 (2.040)	GS 32.672 (32.672)	mem 39.977
Train: [35][445/750]	BT 0.064 (1.178)	DT 0.003 (1.134)	loss 7.150 (7.150)	prob 2.523 (2.523)	GS 35.078 (35.078)	mem 40.087
Train: [35][450/750]	BT 0.032 (1.170)	DT 0.001 (1.125)	loss 7.228 (7.228)	prob 2.381 (2.381)	GS 31.359 (31.359)	mem 39.973
Train: [35][455/750]	BT 0.037 (1.167)	DT 0.003 (1.123)	loss 8.303 (8.303)	prob 1.082 (1.082)	GS 33.938 (33.938)	mem 39.983
Train: [35][460/750]	BT 2.403 (1.173)	DT 2.372 (1.128)	loss 7.317 (7.317)	prob 2.904 (2.904)	GS 31.547 (31.547)	mem 40.036
Train: [35][465/750]	BT 0.032 (1.161)	DT 0.001 (1.116)	loss 7.560 (7.560)	prob 2.612 (2.612)	GS 32.297 (32.297)	mem 40.035
Train: [35][470/750]	BT 0.065 (1.172)	DT 0.011 (1.128)	loss 7.667 (7.667)	prob 2.271 (2.271)	GS 35.688 (35.688)	mem 40.082
Train: [35][475/750]	BT 0.025 (1.160)	DT 0.001 (1.116)	loss 7.606 (7.606)	prob 2.307 (2.307)	GS 30.266 (30.266)	mem 40.025
Train: [35][480/750]	BT 5.591 (1.174)	DT 5.539 (1.130)	loss 7.334 (7.334)	prob 3.001 (3.001)	GS 34.250 (34.250)	mem 39.858
Train: [35][485/750]	BT 0.032 (1.163)	DT 0.001 (1.118)	loss 7.134 (7.134)	prob 2.516 (2.516)	GS 29.250 (29.250)	mem 39.864
Train: [35][490/750]	BT 2.725 (1.168)	DT 2.686 (1.124)	loss 7.731 (7.731)	prob 3.226 (3.226)	GS 33.578 (33.578)	mem 39.943
Train: [35][495/750]	BT 0.070 (1.167)	DT 0.013 (1.123)	loss 7.553 (7.553)	prob 2.076 (2.076)	GS 32.375 (32.375)	mem 39.924
Train: [35][500/750]	BT 3.635 (1.163)	DT 3.599 (1.119)	loss 7.583 (7.583)	prob 1.931 (1.931)	GS 32.562 (32.562)	mem 39.926
Train: [35][505/750]	BT 0.059 (1.163)	DT 0.007 (1.118)	loss 7.065 (7.065)	prob 3.162 (3.162)	GS 30.828 (30.828)	mem 39.903
Train: [35][510/750]	BT 0.131 (1.153)	DT 0.007 (1.108)	loss 7.764 (7.764)	prob 2.809 (2.809)	GS 34.688 (34.688)	mem 39.870
Train: [35][515/750]	BT 0.032 (1.163)	DT 0.002 (1.119)	loss 7.249 (7.249)	prob 3.153 (3.153)	GS 24.203 (24.203)	mem 39.978
Train: [35][520/750]	BT 0.033 (1.156)	DT 0.001 (1.112)	loss 6.849 (6.849)	prob 3.485 (3.485)	GS 33.859 (33.859)	mem 39.856
Train: [35][525/750]	BT 0.042 (1.154)	DT 0.003 (1.110)	loss 7.661 (7.661)	prob 2.386 (2.386)	GS 32.641 (32.641)	mem 39.905
Train: [35][530/750]	BT 0.024 (1.166)	DT 0.001 (1.122)	loss 7.231 (7.231)	prob 3.230 (3.230)	GS 34.047 (34.047)	mem 39.934
Train: [35][535/750]	BT 0.024 (1.156)	DT 0.001 (1.111)	loss 7.637 (7.637)	prob 1.983 (1.983)	GS 30.953 (30.953)	mem 39.936
Train: [35][540/750]	BT 8.712 (1.170)	DT 8.682 (1.125)	loss 7.640 (7.640)	prob 2.976 (2.976)	GS 38.109 (38.109)	mem 39.875
Train: [35][545/750]	BT 0.032 (1.159)	DT 0.002 (1.115)	loss 7.367 (7.367)	prob 3.309 (3.309)	GS 27.641 (27.641)	mem 39.876
Train: [35][550/750]	BT 0.056 (1.156)	DT 0.006 (1.112)	loss 7.437 (7.437)	prob 3.208 (3.208)	GS 30.906 (30.906)	mem 39.893
Train: [35][555/750]	BT 0.050 (1.157)	DT 0.011 (1.113)	loss 7.369 (7.369)	prob 3.478 (3.478)	GS 30.156 (30.156)	mem 39.930
Train: [35][560/750]	BT 5.499 (1.157)	DT 5.455 (1.113)	loss 7.354 (7.354)	prob 3.413 (3.413)	GS 29.750 (29.750)	mem 39.908
Train: [35][565/750]	BT 0.046 (1.161)	DT 0.002 (1.117)	loss 7.668 (7.668)	prob 2.433 (2.433)	GS 33.641 (33.641)	mem 40.051
Train: [35][570/750]	BT 0.034 (1.152)	DT 0.001 (1.107)	loss 6.915 (6.915)	prob 3.006 (3.006)	GS 30.219 (30.219)	mem 39.985
Train: [35][575/750]	BT 0.074 (1.153)	DT 0.005 (1.109)	loss 7.107 (7.107)	prob 3.382 (3.382)	GS 29.766 (29.766)	mem 39.914
Train: [35][580/750]	BT 0.033 (1.154)	DT 0.002 (1.110)	loss 7.121 (7.121)	prob 3.200 (3.200)	GS 32.281 (32.281)	mem 39.999
Train: [35][585/750]	BT 0.031 (1.157)	DT 0.002 (1.113)	loss 7.770 (7.770)	prob 2.386 (2.386)	GS 36.516 (36.516)	mem 39.955
Train: [35][590/750]	BT 0.024 (1.155)	DT 0.001 (1.110)	loss 7.685 (7.685)	prob 3.133 (3.133)	GS 38.531 (38.531)	mem 39.906
Train: [35][595/750]	BT 0.031 (1.145)	DT 0.001 (1.101)	loss 7.683 (7.683)	prob 2.914 (2.914)	GS 27.781 (27.781)	mem 39.906
Train: [35][600/750]	BT 1.167 (1.158)	DT 1.135 (1.114)	loss 7.674 (7.674)	prob 3.135 (3.135)	GS 33.234 (33.234)	mem 39.964
Train: [35][605/750]	BT 0.032 (1.149)	DT 0.002 (1.105)	loss 7.391 (7.391)	prob 3.299 (3.299)	GS 29.031 (29.031)	mem 39.962
Train: [35][610/750]	BT 0.033 (1.157)	DT 0.001 (1.113)	loss 7.971 (7.971)	prob 2.718 (2.718)	GS 34.172 (34.172)	mem 40.071
Train: [35][615/750]	BT 0.043 (1.155)	DT 0.004 (1.111)	loss 7.263 (7.263)	prob 3.681 (3.681)	GS 31.312 (31.312)	mem 39.858
Train: [35][620/750]	BT 9.160 (1.161)	DT 9.137 (1.117)	loss 7.698 (7.698)	prob 3.430 (3.430)	GS 34.094 (34.094)	mem 39.868
Train: [35][625/750]	BT 0.036 (1.155)	DT 0.001 (1.110)	loss 7.023 (7.023)	prob 3.691 (3.691)	GS 26.109 (26.109)	mem 39.897
Train: [35][630/750]	BT 0.023 (1.147)	DT 0.001 (1.103)	loss 7.551 (7.551)	prob 3.196 (3.196)	GS 36.562 (36.562)	mem 39.951
Train: [35][635/750]	BT 0.031 (1.152)	DT 0.001 (1.108)	loss 7.502 (7.502)	prob 3.333 (3.333)	GS 32.859 (32.859)	mem 39.880
Train: [35][640/750]	BT 3.027 (1.151)	DT 2.980 (1.107)	loss 7.605 (7.605)	prob 3.675 (3.675)	GS 36.953 (36.953)	mem 39.991
Train: [35][645/750]	BT 0.030 (1.159)	DT 0.004 (1.115)	loss 7.590 (7.590)	prob 2.579 (2.579)	GS 30.375 (30.375)	mem 39.961
Train: [35][650/750]	BT 0.045 (1.151)	DT 0.002 (1.106)	loss 7.456 (7.456)	prob 3.182 (3.182)	GS 35.391 (35.391)	mem 40.065
Train: [35][655/750]	BT 0.063 (1.147)	DT 0.011 (1.103)	loss 7.567 (7.567)	prob 3.308 (3.308)	GS 31.469 (31.469)	mem 39.926
arpack error, retry= 0
Train: [35][660/750]	BT 0.041 (1.153)	DT 0.009 (1.109)	loss 7.417 (7.417)	prob 3.205 (3.205)	GS 34.906 (34.906)	mem 39.855
Train: [35][665/750]	BT 0.026 (1.154)	DT 0.001 (1.110)	loss 8.323 (8.323)	prob 1.716 (1.716)	GS 35.703 (35.703)	mem 39.875
Train: [35][670/750]	BT 0.088 (1.154)	DT 0.004 (1.110)	loss 7.355 (7.355)	prob 2.778 (2.778)	GS 32.172 (32.172)	mem 39.988
Train: [35][675/750]	BT 0.023 (1.150)	DT 0.001 (1.106)	loss 7.466 (7.466)	prob 3.046 (3.046)	GS 33.531 (33.531)	mem 39.914
Train: [35][680/750]	BT 6.796 (1.157)	DT 6.768 (1.113)	loss 7.655 (7.655)	prob 3.248 (3.248)	GS 31.078 (31.078)	mem 39.856
Train: [35][685/750]	BT 0.093 (1.151)	DT 0.005 (1.107)	loss 7.354 (7.354)	prob 3.944 (3.944)	GS 29.188 (29.188)	mem 39.901
Train: [35][690/750]	BT 0.035 (1.147)	DT 0.004 (1.103)	loss 7.051 (7.051)	prob 3.925 (3.925)	GS 35.391 (35.391)	mem 39.827
Train: [35][695/750]	BT 0.045 (1.154)	DT 0.002 (1.110)	loss 7.755 (7.755)	prob 2.504 (2.504)	GS 30.984 (30.984)	mem 39.918
Train: [35][700/750]	BT 4.356 (1.152)	DT 4.319 (1.108)	loss 7.497 (7.497)	prob 3.178 (3.178)	GS 36.031 (36.031)	mem 39.990
Train: [35][705/750]	BT 0.032 (1.152)	DT 0.001 (1.108)	loss 7.123 (7.123)	prob 3.056 (3.056)	GS 32.297 (32.297)	mem 39.855
Train: [35][710/750]	BT 0.025 (1.154)	DT 0.001 (1.109)	loss 7.520 (7.520)	prob 3.113 (3.113)	GS 34.391 (34.391)	mem 39.921
Train: [35][715/750]	BT 0.030 (1.146)	DT 0.001 (1.102)	loss 7.368 (7.368)	prob 2.894 (2.894)	GS 27.703 (27.703)	mem 39.922
Train: [35][720/750]	BT 6.809 (1.157)	DT 6.785 (1.113)	loss 7.532 (7.532)	prob 2.953 (2.953)	GS 36.531 (36.531)	mem 39.877
Train: [35][725/750]	BT 0.030 (1.149)	DT 0.002 (1.105)	loss 7.350 (7.350)	prob 3.635 (3.635)	GS 31.125 (31.125)	mem 39.877
Train: [35][730/750]	BT 0.025 (1.153)	DT 0.001 (1.109)	loss 7.636 (7.636)	prob 3.213 (3.213)	GS 34.484 (34.484)	mem 39.631
Train: [35][735/750]	BT 0.030 (1.151)	DT 0.001 (1.107)	loss 7.750 (7.750)	prob 2.832 (2.832)	GS 32.281 (32.281)	mem 39.362
Train: [35][740/750]	BT 1.901 (1.146)	DT 1.869 (1.102)	loss 7.279 (7.279)	prob 4.073 (4.073)	GS 33.188 (33.188)	mem 10.537
Train: [35][745/750]	BT 0.026 (1.142)	DT 0.001 (1.099)	loss 7.910 (7.910)	prob 2.679 (2.679)	GS 32.281 (32.281)	mem 7.624
Train: [35][750/750]	BT 0.026 (1.135)	DT 0.001 (1.092)	loss 6.985 (6.985)	prob 3.958 (3.958)	GS 27.625 (27.625)	mem 7.624
Train: [35][755/750]	BT 0.025 (1.128)	DT 0.001 (1.084)	loss 7.478 (7.478)	prob 3.303 (3.303)	GS 30.125 (30.125)	mem 7.624
epoch 35, total time 853.57
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [36][1/750]	BT 20.063 (20.063)	DT 19.931 (19.931)	loss 7.543 (7.543)	prob 2.342 (2.342)	GS 31.000 (31.000)	mem 38.635
Train: [36][5/750]	BT 0.104 (4.879)	DT 0.037 (4.801)	loss 7.133 (7.133)	prob 3.562 (3.562)	GS 30.609 (30.609)	mem 38.742
Train: [36][10/750]	BT 2.612 (2.990)	DT 2.580 (2.927)	loss 7.291 (7.291)	prob 3.058 (3.058)	GS 37.125 (37.125)	mem 38.634
Train: [36][15/750]	BT 0.074 (2.902)	DT 0.002 (2.844)	loss 7.262 (7.262)	prob 2.889 (2.889)	GS 29.188 (29.188)	mem 38.904
Train: [36][20/750]	BT 0.023 (2.184)	DT 0.001 (2.133)	loss 7.161 (7.161)	prob 3.013 (3.013)	GS 34.984 (34.984)	mem 38.759
Train: [36][25/750]	BT 0.072 (1.765)	DT 0.011 (1.716)	loss 7.171 (7.171)	prob 3.083 (3.083)	GS 31.172 (31.172)	mem 38.775
Train: [36][30/750]	BT 0.032 (1.888)	DT 0.001 (1.840)	loss 7.408 (7.408)	prob 3.268 (3.268)	GS 31.203 (31.203)	mem 39.013
Train: [36][35/750]	BT 0.063 (1.658)	DT 0.007 (1.605)	loss 7.235 (7.235)	prob 3.386 (3.386)	GS 29.875 (29.875)	mem 38.973
Train: [36][40/750]	BT 0.035 (1.767)	DT 0.002 (1.717)	loss 7.089 (7.089)	prob 3.396 (3.396)	GS 28.547 (28.547)	mem 38.948
Train: [36][45/750]	BT 0.072 (1.578)	DT 0.009 (1.527)	loss 7.115 (7.115)	prob 3.164 (3.164)	GS 30.188 (30.188)	mem 38.979
Train: [36][50/750]	BT 14.135 (1.720)	DT 14.102 (1.669)	loss 7.540 (7.540)	prob 2.881 (2.881)	GS 33.469 (33.469)	mem 38.986
Train: [36][55/750]	BT 0.031 (1.568)	DT 0.001 (1.518)	loss 7.639 (7.639)	prob 2.520 (2.520)	GS 31.766 (31.766)	mem 38.987
Train: [36][60/750]	BT 0.049 (1.442)	DT 0.001 (1.392)	loss 7.148 (7.148)	prob 3.769 (3.769)	GS 33.781 (33.781)	mem 38.988
Train: [36][65/750]	BT 0.038 (1.544)	DT 0.001 (1.495)	loss 7.782 (7.782)	prob 1.905 (1.905)	GS 32.359 (32.359)	mem 39.007
Train: [36][70/750]	BT 0.064 (1.437)	DT 0.006 (1.389)	loss 7.227 (7.227)	prob 3.354 (3.354)	GS 30.516 (30.516)	mem 39.070
Train: [36][75/750]	BT 0.024 (1.526)	DT 0.001 (1.477)	loss 7.110 (7.110)	prob 3.122 (3.122)	GS 34.797 (34.797)	mem 39.040
Train: [36][80/750]	BT 0.093 (1.433)	DT 0.002 (1.385)	loss 7.420 (7.420)	prob 2.831 (2.831)	GS 38.812 (38.812)	mem 38.975
Train: [36][85/750]	BT 0.037 (1.351)	DT 0.001 (1.303)	loss 7.571 (7.571)	prob 2.852 (2.852)	GS 32.062 (32.062)	mem 38.975
Train: [36][90/750]	BT 0.033 (1.422)	DT 0.001 (1.375)	loss 7.146 (7.146)	prob 3.064 (3.064)	GS 33.703 (33.703)	mem 39.066
Train: [36][95/750]	BT 0.051 (1.350)	DT 0.013 (1.303)	loss 7.333 (7.333)	prob 2.439 (2.439)	GS 31.812 (31.812)	mem 39.067
Train: [36][100/750]	BT 0.038 (1.432)	DT 0.002 (1.385)	loss 7.440 (7.440)	prob 2.965 (2.965)	GS 36.969 (36.969)	mem 39.142
Train: [36][105/750]	BT 0.032 (1.365)	DT 0.001 (1.320)	loss 7.393 (7.393)	prob 2.328 (2.328)	GS 32.703 (32.703)	mem 39.096
Train: [36][110/750]	BT 11.633 (1.411)	DT 11.601 (1.365)	loss 7.172 (7.172)	prob 3.012 (3.012)	GS 36.641 (36.641)	mem 39.076
Train: [36][115/750]	BT 0.033 (1.352)	DT 0.002 (1.306)	loss 7.609 (7.609)	prob 2.756 (2.756)	GS 35.438 (35.438)	mem 39.015
Train: [36][120/750]	BT 0.129 (1.298)	DT 0.001 (1.252)	loss 7.251 (7.251)	prob 2.845 (2.845)	GS 31.406 (31.406)	mem 39.019
Train: [36][125/750]	BT 0.038 (1.341)	DT 0.001 (1.295)	loss 7.137 (7.137)	prob 2.544 (2.544)	GS 29.625 (29.625)	mem 39.136
Train: [36][130/750]	BT 0.065 (1.291)	DT 0.002 (1.246)	loss 7.424 (7.424)	prob 2.700 (2.700)	GS 35.594 (35.594)	mem 39.137
Train: [36][135/750]	BT 0.047 (1.344)	DT 0.001 (1.299)	loss 7.441 (7.441)	prob 2.353 (2.353)	GS 26.062 (26.062)	mem 39.389
Train: [36][140/750]	BT 0.029 (1.297)	DT 0.001 (1.253)	loss 7.026 (7.026)	prob 2.921 (2.921)	GS 37.297 (37.297)	mem 39.389
Train: [36][145/750]	BT 0.033 (1.254)	DT 0.002 (1.210)	loss 7.471 (7.471)	prob 2.536 (2.536)	GS 30.484 (30.484)	mem 39.390
Train: [36][150/750]	BT 0.041 (1.320)	DT 0.001 (1.276)	loss 7.212 (7.212)	prob 3.459 (3.459)	GS 32.828 (32.828)	mem 39.393
Train: [36][155/750]	BT 0.118 (1.279)	DT 0.001 (1.235)	loss 7.383 (7.383)	prob 2.884 (2.884)	GS 37.719 (37.719)	mem 39.360
Train: [36][160/750]	BT 0.054 (1.318)	DT 0.015 (1.274)	loss 7.040 (7.040)	prob 3.406 (3.406)	GS 31.922 (31.922)	mem 39.525
Train: [36][165/750]	BT 0.070 (1.280)	DT 0.028 (1.235)	loss 7.264 (7.264)	prob 3.004 (3.004)	GS 32.453 (32.453)	mem 39.602
Train: [36][170/750]	BT 13.059 (1.320)	DT 13.001 (1.276)	loss 7.001 (7.001)	prob 2.983 (2.983)	GS 34.125 (34.125)	mem 39.485
Train: [36][175/750]	BT 0.048 (1.284)	DT 0.006 (1.239)	loss 7.080 (7.080)	prob 2.974 (2.974)	GS 36.172 (36.172)	mem 39.510
Train: [36][180/750]	BT 0.065 (1.250)	DT 0.001 (1.205)	loss 7.162 (7.162)	prob 3.066 (3.066)	GS 35.547 (35.547)	mem 39.596
Train: [36][185/750]	BT 0.035 (1.282)	DT 0.001 (1.237)	loss 7.263 (7.263)	prob 3.089 (3.089)	GS 31.094 (31.094)	mem 39.657
Train: [36][190/750]	BT 0.033 (1.249)	DT 0.002 (1.205)	loss 7.000 (7.000)	prob 2.636 (2.636)	GS 33.453 (33.453)	mem 39.569
Train: [36][195/750]	BT 0.048 (1.301)	DT 0.008 (1.257)	loss 7.513 (7.513)	prob 2.841 (2.841)	GS 35.328 (35.328)	mem 39.705
Train: [36][200/750]	BT 0.086 (1.270)	DT 0.001 (1.225)	loss 6.727 (6.727)	prob 2.988 (2.988)	GS 35.125 (35.125)	mem 39.801
Train: [36][205/750]	BT 0.032 (1.240)	DT 0.002 (1.195)	loss 6.947 (6.947)	prob 2.893 (2.893)	GS 31.062 (31.062)	mem 39.708
Train: [36][210/750]	BT 0.033 (1.279)	DT 0.001 (1.235)	loss 6.927 (6.927)	prob 3.332 (3.332)	GS 30.844 (30.844)	mem 39.932
Train: [36][215/750]	BT 0.043 (1.251)	DT 0.017 (1.207)	loss 7.081 (7.081)	prob 3.024 (3.024)	GS 29.078 (29.078)	mem 39.877
Train: [36][220/750]	BT 0.023 (1.291)	DT 0.001 (1.246)	loss 7.046 (7.046)	prob 2.784 (2.784)	GS 33.875 (33.875)	mem 39.784
Train: [36][225/750]	BT 0.055 (1.263)	DT 0.003 (1.219)	loss 7.126 (7.126)	prob 2.872 (2.872)	GS 31.141 (31.141)	mem 39.799
Train: [36][230/750]	BT 11.546 (1.286)	DT 11.430 (1.242)	loss 7.028 (7.028)	prob 3.007 (3.007)	GS 33.719 (33.719)	mem 39.742
Train: [36][235/750]	BT 0.031 (1.260)	DT 0.002 (1.216)	loss 7.301 (7.301)	prob 2.544 (2.544)	GS 34.531 (34.531)	mem 39.715
Train: [36][240/750]	BT 0.030 (1.234)	DT 0.002 (1.190)	loss 6.903 (6.903)	prob 3.475 (3.475)	GS 39.484 (39.484)	mem 39.715
Train: [36][245/750]	BT 0.058 (1.258)	DT 0.026 (1.214)	loss 7.278 (7.278)	prob 2.782 (2.782)	GS 31.281 (31.281)	mem 39.871
Train: [36][250/750]	BT 0.028 (1.234)	DT 0.001 (1.190)	loss 7.313 (7.313)	prob 2.176 (2.176)	GS 35.281 (35.281)	mem 39.855
Train: [36][255/750]	BT 0.062 (1.257)	DT 0.010 (1.213)	loss 7.281 (7.281)	prob 2.478 (2.478)	GS 29.672 (29.672)	mem 39.806
Train: [36][260/750]	BT 0.031 (1.233)	DT 0.001 (1.189)	loss 6.952 (6.952)	prob 3.194 (3.194)	GS 34.656 (34.656)	mem 39.810
Train: [36][265/750]	BT 0.032 (1.210)	DT 0.001 (1.167)	loss 6.963 (6.963)	prob 3.211 (3.211)	GS 30.688 (30.688)	mem 39.810
Train: [36][270/750]	BT 0.073 (1.230)	DT 0.003 (1.186)	loss 6.898 (6.898)	prob 3.259 (3.259)	GS 35.547 (35.547)	mem 39.959
Train: [36][275/750]	BT 0.055 (1.208)	DT 0.005 (1.165)	loss 7.065 (7.065)	prob 2.971 (2.971)	GS 27.641 (27.641)	mem 39.815
Train: [36][280/750]	BT 0.116 (1.229)	DT 0.091 (1.185)	loss 7.243 (7.243)	prob 2.957 (2.957)	GS 34.484 (34.484)	mem 39.839
Train: [36][285/750]	BT 0.063 (1.208)	DT 0.015 (1.165)	loss 6.684 (6.684)	prob 3.215 (3.215)	GS 28.859 (28.859)	mem 39.839
Train: [36][290/750]	BT 11.643 (1.228)	DT 11.608 (1.185)	loss 6.982 (6.982)	prob 2.879 (2.879)	GS 35.609 (35.609)	mem 39.623
Train: [36][295/750]	BT 0.091 (1.208)	DT 0.011 (1.165)	loss 7.118 (7.118)	prob 2.721 (2.721)	GS 27.625 (27.625)	mem 39.631
Train: [36][300/750]	BT 0.080 (1.189)	DT 0.010 (1.146)	loss 6.820 (6.820)	prob 2.543 (2.543)	GS 32.609 (32.609)	mem 39.692
Train: [36][305/750]	BT 0.032 (1.208)	DT 0.001 (1.165)	loss 7.290 (7.290)	prob 2.395 (2.395)	GS 26.344 (26.344)	mem 39.844
Train: [36][310/750]	BT 0.073 (1.190)	DT 0.008 (1.147)	loss 6.809 (6.809)	prob 3.507 (3.507)	GS 35.625 (35.625)	mem 39.844
Train: [36][315/750]	BT 0.033 (1.215)	DT 0.002 (1.172)	loss 7.036 (7.036)	prob 2.931 (2.931)	GS 32.234 (32.234)	mem 39.872
Train: [36][320/750]	BT 0.046 (1.197)	DT 0.001 (1.154)	loss 6.859 (6.859)	prob 2.764 (2.764)	GS 34.000 (34.000)	mem 39.945
Train: [36][325/750]	BT 0.092 (1.179)	DT 0.040 (1.136)	loss 7.127 (7.127)	prob 2.155 (2.155)	GS 27.938 (27.938)	mem 39.985
Train: [36][330/750]	BT 0.054 (1.209)	DT 0.012 (1.166)	loss 6.564 (6.564)	prob 3.251 (3.251)	GS 32.891 (32.891)	mem 39.913
Train: [36][335/750]	BT 0.068 (1.192)	DT 0.009 (1.149)	loss 7.065 (7.065)	prob 2.788 (2.788)	GS 30.625 (30.625)	mem 39.982
Train: [36][340/750]	BT 0.057 (1.206)	DT 0.012 (1.163)	loss 6.875 (6.875)	prob 3.043 (3.043)	GS 27.828 (27.828)	mem 40.186
Train: [36][345/750]	BT 0.028 (1.189)	DT 0.001 (1.146)	loss 7.183 (7.183)	prob 2.874 (2.874)	GS 34.875 (34.875)	mem 39.916
Train: [36][350/750]	BT 14.030 (1.212)	DT 14.001 (1.169)	loss 6.878 (6.878)	prob 3.181 (3.181)	GS 33.688 (33.688)	mem 39.888
Train: [36][355/750]	BT 0.032 (1.196)	DT 0.001 (1.153)	loss 7.069 (7.069)	prob 2.947 (2.947)	GS 23.844 (23.844)	mem 40.095
Train: [36][360/750]	BT 0.072 (1.180)	DT 0.005 (1.137)	loss 6.802 (6.802)	prob 2.752 (2.752)	GS 31.672 (31.672)	mem 39.922
Train: [36][365/750]	BT 0.043 (1.198)	DT 0.005 (1.155)	loss 7.003 (7.003)	prob 2.359 (2.359)	GS 29.453 (29.453)	mem 39.910
Train: [36][370/750]	BT 0.051 (1.183)	DT 0.002 (1.140)	loss 6.863 (6.863)	prob 2.772 (2.772)	GS 34.141 (34.141)	mem 39.829
Train: [36][375/750]	BT 0.036 (1.196)	DT 0.001 (1.152)	loss 7.051 (7.051)	prob 2.582 (2.582)	GS 31.078 (31.078)	mem 39.820
Train: [36][380/750]	BT 0.056 (1.180)	DT 0.022 (1.137)	loss 6.939 (6.939)	prob 3.025 (3.025)	GS 34.875 (34.875)	mem 39.820
Train: [36][385/750]	BT 0.086 (1.166)	DT 0.004 (1.123)	loss 6.753 (6.753)	prob 3.580 (3.580)	GS 28.094 (28.094)	mem 39.827
Train: [36][390/750]	BT 0.088 (1.182)	DT 0.001 (1.139)	loss 6.763 (6.763)	prob 2.665 (2.665)	GS 33.812 (33.812)	mem 40.013
Train: [36][395/750]	BT 0.033 (1.170)	DT 0.001 (1.127)	loss 7.023 (7.023)	prob 2.716 (2.716)	GS 32.078 (32.078)	mem 39.796
Train: [36][400/750]	BT 0.102 (1.190)	DT 0.001 (1.146)	loss 7.321 (7.321)	prob 2.296 (2.296)	GS 35.609 (35.609)	mem 39.957
Train: [36][405/750]	BT 0.029 (1.176)	DT 0.001 (1.133)	loss 7.098 (7.098)	prob 2.618 (2.618)	GS 29.219 (29.219)	mem 39.900
Train: [36][410/750]	BT 13.760 (1.196)	DT 13.729 (1.152)	loss 6.872 (6.872)	prob 3.171 (3.171)	GS 36.359 (36.359)	mem 39.882
Train: [36][415/750]	BT 0.032 (1.182)	DT 0.002 (1.138)	loss 6.901 (6.901)	prob 2.870 (2.870)	GS 27.891 (27.891)	mem 39.899
Train: [36][420/750]	BT 0.032 (1.168)	DT 0.001 (1.125)	loss 6.998 (6.998)	prob 2.643 (2.643)	GS 35.250 (35.250)	mem 39.935
Train: [36][425/750]	BT 0.046 (1.185)	DT 0.005 (1.142)	loss 7.121 (7.121)	prob 2.913 (2.913)	GS 30.906 (30.906)	mem 39.942
Train: [36][430/750]	BT 0.033 (1.177)	DT 0.001 (1.133)	loss 6.935 (6.935)	prob 3.022 (3.022)	GS 36.125 (36.125)	mem 40.035
Train: [36][435/750]	BT 0.053 (1.193)	DT 0.007 (1.150)	loss 6.851 (6.851)	prob 3.032 (3.032)	GS 34.500 (34.500)	mem 39.875
Train: [36][440/750]	BT 0.058 (1.180)	DT 0.002 (1.136)	loss 7.039 (7.039)	prob 3.233 (3.233)	GS 35.875 (35.875)	mem 39.949
Train: [36][445/750]	BT 0.025 (1.167)	DT 0.001 (1.124)	loss 6.948 (6.948)	prob 2.767 (2.767)	GS 34.719 (34.719)	mem 39.882
Train: [36][450/750]	BT 0.034 (1.190)	DT 0.004 (1.146)	loss 6.786 (6.786)	prob 2.818 (2.818)	GS 35.922 (35.922)	mem 39.961
Train: [36][455/750]	BT 0.033 (1.177)	DT 0.002 (1.134)	loss 6.982 (6.982)	prob 2.660 (2.660)	GS 33.312 (33.312)	mem 39.850
Train: [36][460/750]	BT 10.207 (1.197)	DT 10.158 (1.154)	loss 7.009 (7.009)	prob 2.470 (2.470)	GS 33.984 (33.984)	mem 39.871
Train: [36][465/750]	BT 0.053 (1.185)	DT 0.002 (1.142)	loss 7.157 (7.157)	prob 2.558 (2.558)	GS 32.359 (32.359)	mem 39.893
Train: [36][470/750]	BT 5.321 (1.184)	DT 5.282 (1.141)	loss 6.888 (6.888)	prob 2.776 (2.776)	GS 36.625 (36.625)	mem 39.896
Train: [36][475/750]	BT 0.029 (1.186)	DT 0.001 (1.143)	loss 7.205 (7.205)	prob 2.512 (2.512)	GS 31.688 (31.688)	mem 39.772
Train: [36][480/750]	BT 0.054 (1.174)	DT 0.001 (1.131)	loss 6.924 (6.924)	prob 2.576 (2.576)	GS 32.609 (32.609)	mem 39.866
Train: [36][485/750]	BT 0.026 (1.190)	DT 0.001 (1.147)	loss 7.214 (7.214)	prob 2.324 (2.324)	GS 31.000 (31.000)	mem 39.824
Train: [36][490/750]	BT 0.032 (1.178)	DT 0.001 (1.135)	loss 6.806 (6.806)	prob 2.244 (2.244)	GS 35.047 (35.047)	mem 39.825
Train: [36][495/750]	BT 0.064 (1.174)	DT 0.014 (1.132)	loss 7.066 (7.066)	prob 2.319 (2.319)	GS 31.422 (31.422)	mem 39.908
Train: [36][500/750]	BT 0.029 (1.181)	DT 0.001 (1.138)	loss 7.064 (7.064)	prob 2.649 (2.649)	GS 33.641 (33.641)	mem 39.914
Train: [36][505/750]	BT 0.053 (1.170)	DT 0.003 (1.127)	loss 6.682 (6.682)	prob 3.000 (3.000)	GS 32.906 (32.906)	mem 39.915
Train: [36][510/750]	BT 0.044 (1.186)	DT 0.013 (1.143)	loss 6.885 (6.885)	prob 2.459 (2.459)	GS 33.484 (33.484)	mem 39.948
Train: [36][515/750]	BT 0.058 (1.175)	DT 0.002 (1.132)	loss 6.963 (6.963)	prob 2.738 (2.738)	GS 33.156 (33.156)	mem 39.948
Train: [36][520/750]	BT 6.978 (1.185)	DT 6.943 (1.142)	loss 6.909 (6.909)	prob 2.261 (2.261)	GS 33.641 (33.641)	mem 40.032
Train: [36][525/750]	BT 0.038 (1.174)	DT 0.001 (1.131)	loss 6.994 (6.994)	prob 2.534 (2.534)	GS 33.109 (33.109)	mem 39.980
Train: [36][530/750]	BT 6.864 (1.176)	DT 6.804 (1.134)	loss 6.758 (6.758)	prob 2.731 (2.731)	GS 37.812 (37.812)	mem 39.980
Train: [36][535/750]	BT 0.057 (1.179)	DT 0.012 (1.136)	loss 6.868 (6.868)	prob 2.130 (2.130)	GS 33.094 (33.094)	mem 39.882
Train: [36][540/750]	BT 0.070 (1.168)	DT 0.001 (1.125)	loss 6.858 (6.858)	prob 2.274 (2.274)	GS 31.922 (31.922)	mem 39.896
Train: [36][545/750]	BT 0.075 (1.183)	DT 0.001 (1.141)	loss 7.078 (7.078)	prob 1.919 (1.919)	GS 34.250 (34.250)	mem 40.062
Train: [36][550/750]	BT 0.037 (1.173)	DT 0.001 (1.130)	loss 6.973 (6.973)	prob 2.079 (2.079)	GS 33.031 (33.031)	mem 39.911
Train: [36][555/750]	BT 0.060 (1.168)	DT 0.013 (1.125)	loss 6.943 (6.943)	prob 2.472 (2.472)	GS 26.297 (26.297)	mem 39.845
Train: [36][560/750]	BT 0.056 (1.175)	DT 0.007 (1.132)	loss 7.150 (7.150)	prob 2.188 (2.188)	GS 38.344 (38.344)	mem 39.935
Train: [36][565/750]	BT 0.075 (1.165)	DT 0.001 (1.122)	loss 7.045 (7.045)	prob 2.420 (2.420)	GS 31.938 (31.938)	mem 39.937
Train: [36][570/750]	BT 0.033 (1.176)	DT 0.009 (1.134)	loss 6.814 (6.814)	prob 3.084 (3.084)	GS 33.000 (33.000)	mem 39.830
Train: [36][575/750]	BT 0.032 (1.167)	DT 0.002 (1.124)	loss 6.935 (6.935)	prob 2.485 (2.485)	GS 33.719 (33.719)	mem 39.831
Train: [36][580/750]	BT 10.226 (1.176)	DT 10.183 (1.133)	loss 6.847 (6.847)	prob 2.457 (2.457)	GS 30.766 (30.766)	mem 39.840
Train: [36][585/750]	BT 0.030 (1.166)	DT 0.001 (1.123)	loss 7.003 (7.003)	prob 2.410 (2.410)	GS 32.344 (32.344)	mem 39.844
Train: [36][590/750]	BT 0.710 (1.158)	DT 0.679 (1.115)	loss 6.603 (6.603)	prob 2.786 (2.786)	GS 30.812 (30.812)	mem 39.986
Train: [36][595/750]	BT 0.032 (1.168)	DT 0.001 (1.125)	loss 7.038 (7.038)	prob 3.262 (3.262)	GS 29.594 (29.594)	mem 39.886
Train: [36][600/750]	BT 0.045 (1.158)	DT 0.001 (1.116)	loss 6.691 (6.691)	prob 2.321 (2.321)	GS 29.062 (29.062)	mem 39.887
Train: [36][605/750]	BT 0.031 (1.169)	DT 0.001 (1.127)	loss 6.972 (6.972)	prob 2.453 (2.453)	GS 29.000 (29.000)	mem 39.893
Train: [36][610/750]	BT 0.046 (1.160)	DT 0.015 (1.117)	loss 6.873 (6.873)	prob 3.297 (3.297)	GS 35.141 (35.141)	mem 39.895
Train: [36][615/750]	BT 0.041 (1.155)	DT 0.002 (1.113)	loss 7.007 (7.007)	prob 2.571 (2.571)	GS 30.484 (30.484)	mem 39.963
Train: [36][620/750]	BT 0.043 (1.163)	DT 0.010 (1.121)	loss 6.670 (6.670)	prob 2.712 (2.712)	GS 32.641 (32.641)	mem 39.915
Train: [36][625/750]	BT 0.032 (1.154)	DT 0.001 (1.112)	loss 7.117 (7.117)	prob 2.779 (2.779)	GS 28.812 (28.812)	mem 39.916
Train: [36][630/750]	BT 0.034 (1.162)	DT 0.001 (1.119)	loss 6.829 (6.829)	prob 2.592 (2.592)	GS 33.719 (33.719)	mem 39.913
Train: [36][635/750]	BT 0.028 (1.153)	DT 0.001 (1.111)	loss 7.106 (7.106)	prob 2.388 (2.388)	GS 35.719 (35.719)	mem 39.940
Train: [36][640/750]	BT 8.698 (1.166)	DT 8.626 (1.123)	loss 6.888 (6.888)	prob 2.325 (2.325)	GS 30.328 (30.328)	mem 40.209
Train: [36][645/750]	BT 0.130 (1.157)	DT 0.005 (1.114)	loss 6.934 (6.934)	prob 2.569 (2.569)	GS 31.000 (31.000)	mem 40.123
Train: [36][650/750]	BT 1.933 (1.151)	DT 1.890 (1.109)	loss 6.891 (6.891)	prob 2.375 (2.375)	GS 29.500 (29.500)	mem 40.049
Train: [36][655/750]	BT 0.028 (1.167)	DT 0.001 (1.124)	loss 7.031 (7.031)	prob 2.344 (2.344)	GS 31.844 (31.844)	mem 39.750
arpack error, retry= 0
arpack error, retry= 0
Train: [36][660/750]	BT 0.030 (1.159)	DT 0.001 (1.116)	loss 6.648 (6.648)	prob 2.723 (2.723)	GS 34.219 (34.219)	mem 39.752
Train: [36][665/750]	BT 0.028 (1.171)	DT 0.001 (1.129)	loss 6.811 (6.811)	prob 2.697 (2.697)	GS 33.359 (33.359)	mem 39.908
Train: [36][670/750]	BT 0.029 (1.163)	DT 0.001 (1.120)	loss 6.958 (6.958)	prob 2.392 (2.392)	GS 34.125 (34.125)	mem 39.810
Train: [36][675/750]	BT 0.078 (1.154)	DT 0.005 (1.112)	loss 6.807 (6.807)	prob 2.693 (2.693)	GS 31.844 (31.844)	mem 39.812
Train: [36][680/750]	BT 0.032 (1.165)	DT 0.001 (1.123)	loss 6.959 (6.959)	prob 2.889 (2.889)	GS 32.766 (32.766)	mem 40.094
Train: [36][685/750]	BT 0.042 (1.157)	DT 0.003 (1.115)	loss 6.940 (6.940)	prob 2.590 (2.590)	GS 30.516 (30.516)	mem 39.952
Train: [36][690/750]	BT 0.032 (1.166)	DT 0.001 (1.123)	loss 6.886 (6.886)	prob 1.838 (1.838)	GS 31.562 (31.562)	mem 40.025
Train: [36][695/750]	BT 0.032 (1.157)	DT 0.002 (1.115)	loss 7.038 (7.038)	prob 2.731 (2.731)	GS 32.000 (32.000)	mem 40.120
Train: [36][700/750]	BT 13.468 (1.169)	DT 13.439 (1.126)	loss 6.731 (6.731)	prob 2.675 (2.675)	GS 36.203 (36.203)	mem 39.899
Train: [36][705/750]	BT 0.029 (1.161)	DT 0.001 (1.118)	loss 7.108 (7.108)	prob 3.005 (3.005)	GS 33.734 (33.734)	mem 39.901
Train: [36][710/750]	BT 0.031 (1.153)	DT 0.001 (1.110)	loss 6.903 (6.903)	prob 2.798 (2.798)	GS 33.891 (33.891)	mem 39.913
Train: [36][715/750]	BT 0.034 (1.162)	DT 0.001 (1.119)	loss 6.991 (6.991)	prob 2.874 (2.874)	GS 50.016 (50.016)	mem 40.013
Train: [36][720/750]	BT 0.092 (1.154)	DT 0.005 (1.112)	loss 6.994 (6.994)	prob 3.063 (3.063)	GS 33.734 (33.734)	mem 39.972
Train: [36][725/750]	BT 0.026 (1.164)	DT 0.001 (1.122)	loss 6.997 (6.997)	prob 2.750 (2.750)	GS 30.234 (30.234)	mem 39.754
Train: [36][730/750]	BT 0.028 (1.156)	DT 0.001 (1.114)	loss 7.000 (7.000)	prob 2.322 (2.322)	GS 28.406 (28.406)	mem 39.757
Train: [36][735/750]	BT 0.027 (1.149)	DT 0.001 (1.106)	loss 7.241 (7.241)	prob 2.527 (2.527)	GS 39.547 (39.547)	mem 39.810
Train: [36][740/750]	BT 0.035 (1.154)	DT 0.001 (1.112)	loss 6.744 (6.744)	prob 3.517 (3.517)	GS 30.703 (30.703)	mem 10.631
Train: [36][745/750]	BT 0.030 (1.146)	DT 0.001 (1.104)	loss 6.787 (6.787)	prob 3.028 (3.028)	GS 37.000 (37.000)	mem 10.632
Train: [36][750/750]	BT 0.044 (1.142)	DT 0.001 (1.100)	loss 6.669 (6.669)	prob 3.067 (3.067)	GS 34.531 (34.531)	mem 7.620
Train: [36][755/750]	BT 0.040 (1.134)	DT 0.002 (1.092)	loss 6.887 (6.887)	prob 3.088 (3.088)	GS 32.812 (32.812)	mem 7.621
epoch 36, total time 856.60
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [37][1/750]	BT 20.119 (20.119)	DT 19.981 (19.981)	loss 7.195 (7.195)	prob 2.523 (2.523)	GS 28.281 (28.281)	mem 38.400
Train: [37][5/750]	BT 0.065 (4.727)	DT 0.013 (4.670)	loss 6.634 (6.634)	prob 2.290 (2.290)	GS 34.641 (34.641)	mem 38.512
Train: [37][10/750]	BT 0.079 (2.392)	DT 0.009 (2.338)	loss 6.718 (6.718)	prob 2.747 (2.747)	GS 33.453 (33.453)	mem 38.545
Train: [37][15/750]	BT 0.045 (2.379)	DT 0.003 (2.327)	loss 6.647 (6.647)	prob 2.879 (2.879)	GS 31.375 (31.375)	mem 38.744
Train: [37][20/750]	BT 0.063 (1.871)	DT 0.012 (1.815)	loss 7.041 (7.041)	prob 2.014 (2.014)	GS 32.734 (32.734)	mem 38.751
Train: [37][25/750]	BT 0.040 (1.507)	DT 0.008 (1.453)	loss 6.624 (6.624)	prob 2.588 (2.588)	GS 28.422 (28.422)	mem 38.754
Train: [37][30/750]	BT 0.025 (1.699)	DT 0.001 (1.647)	loss 6.641 (6.641)	prob 2.900 (2.900)	GS 31.625 (31.625)	mem 38.831
Train: [37][35/750]	BT 0.053 (1.464)	DT 0.004 (1.412)	loss 6.844 (6.844)	prob 2.908 (2.908)	GS 45.266 (45.266)	mem 38.831
Train: [37][40/750]	BT 0.459 (1.609)	DT 0.421 (1.558)	loss 6.843 (6.843)	prob 2.828 (2.828)	GS 37.109 (37.109)	mem 38.889
Train: [37][45/750]	BT 0.105 (1.472)	DT 0.007 (1.421)	loss 6.844 (6.844)	prob 3.197 (3.197)	GS 28.234 (28.234)	mem 38.908
Train: [37][50/750]	BT 7.961 (1.489)	DT 7.928 (1.438)	loss 7.141 (7.141)	prob 1.367 (1.367)	GS 34.125 (34.125)	mem 38.959
Train: [37][55/750]	BT 0.032 (1.398)	DT 0.001 (1.348)	loss 6.943 (6.943)	prob 2.600 (2.600)	GS 32.047 (32.047)	mem 38.969
Train: [37][60/750]	BT 0.060 (1.365)	DT 0.003 (1.317)	loss 6.777 (6.777)	prob 2.664 (2.664)	GS 34.219 (34.219)	mem 39.002
Train: [37][65/750]	BT 0.034 (1.395)	DT 0.002 (1.346)	loss 6.938 (6.938)	prob 2.199 (2.199)	GS 46.625 (46.625)	mem 39.110
Train: [37][70/750]	BT 0.083 (1.365)	DT 0.019 (1.317)	loss 7.014 (7.014)	prob 3.120 (3.120)	GS 32.078 (32.078)	mem 39.086
Train: [37][75/750]	BT 0.040 (1.373)	DT 0.005 (1.326)	loss 6.991 (6.991)	prob 2.417 (2.417)	GS 32.438 (32.438)	mem 39.215
Train: [37][80/750]	BT 2.389 (1.343)	DT 2.356 (1.295)	loss 6.781 (6.781)	prob 2.776 (2.776)	GS 35.188 (35.188)	mem 39.028
Train: [37][85/750]	BT 0.067 (1.274)	DT 0.001 (1.224)	loss 6.996 (6.996)	prob 2.381 (2.381)	GS 29.453 (29.453)	mem 39.029
Train: [37][90/750]	BT 0.823 (1.296)	DT 0.790 (1.247)	loss 6.859 (6.859)	prob 2.817 (2.817)	GS 34.219 (34.219)	mem 38.995
Train: [37][95/750]	BT 0.067 (1.279)	DT 0.001 (1.229)	loss 6.723 (6.723)	prob 2.962 (2.962)	GS 33.625 (33.625)	mem 39.045
Train: [37][100/750]	BT 4.646 (1.329)	DT 4.611 (1.281)	loss 6.843 (6.843)	prob 2.418 (2.418)	GS 41.516 (41.516)	mem 39.323
Train: [37][105/750]	BT 0.025 (1.271)	DT 0.001 (1.223)	loss 7.057 (7.057)	prob 2.667 (2.667)	GS 33.531 (33.531)	mem 39.259
Train: [37][110/750]	BT 6.655 (1.299)	DT 6.617 (1.252)	loss 6.748 (6.748)	prob 2.914 (2.914)	GS 39.422 (39.422)	mem 39.657
Train: [37][115/750]	BT 0.032 (1.269)	DT 0.002 (1.222)	loss 7.049 (7.049)	prob 2.407 (2.407)	GS 30.234 (30.234)	mem 39.395
Train: [37][120/750]	BT 0.023 (1.250)	DT 0.001 (1.203)	loss 6.826 (6.826)	prob 2.523 (2.523)	GS 39.625 (39.625)	mem 39.400
Train: [37][125/750]	BT 0.044 (1.292)	DT 0.002 (1.245)	loss 6.654 (6.654)	prob 2.731 (2.731)	GS 32.281 (32.281)	mem 39.418
Train: [37][130/750]	BT 0.642 (1.249)	DT 0.607 (1.202)	loss 6.876 (6.876)	prob 1.948 (1.948)	GS 34.000 (34.000)	mem 39.341
Train: [37][135/750]	BT 0.075 (1.217)	DT 0.028 (1.170)	loss 6.902 (6.902)	prob 2.521 (2.521)	GS 29.812 (29.812)	mem 39.452
Train: [37][140/750]	BT 1.821 (1.263)	DT 1.756 (1.215)	loss 6.926 (6.926)	prob 2.864 (2.864)	GS 35.500 (35.500)	mem 39.615
Train: [37][145/750]	BT 0.050 (1.222)	DT 0.005 (1.173)	loss 6.901 (6.901)	prob 2.245 (2.245)	GS 31.250 (31.250)	mem 39.655
Train: [37][150/750]	BT 0.028 (1.266)	DT 0.001 (1.218)	loss 6.746 (6.746)	prob 2.615 (2.615)	GS 33.141 (33.141)	mem 39.659
Train: [37][155/750]	BT 0.040 (1.227)	DT 0.014 (1.179)	loss 6.951 (6.951)	prob 2.439 (2.439)	GS 34.203 (34.203)	mem 39.659
Train: [37][160/750]	BT 11.108 (1.280)	DT 11.075 (1.232)	loss 7.068 (7.068)	prob 1.983 (1.983)	GS 33.734 (33.734)	mem 39.707
Train: [37][165/750]	BT 0.033 (1.242)	DT 0.001 (1.195)	loss 6.918 (6.918)	prob 2.088 (2.088)	GS 28.109 (28.109)	mem 39.745
Train: [37][170/750]	BT 3.037 (1.224)	DT 2.995 (1.177)	loss 6.646 (6.646)	prob 2.805 (2.805)	GS 34.406 (34.406)	mem 39.713
Train: [37][175/750]	BT 0.030 (1.245)	DT 0.002 (1.198)	loss 7.127 (7.127)	prob 2.319 (2.319)	GS 31.141 (31.141)	mem 39.705
Train: [37][180/750]	BT 0.031 (1.211)	DT 0.001 (1.165)	loss 7.070 (7.070)	prob 2.635 (2.635)	GS 33.359 (33.359)	mem 39.707
Train: [37][185/750]	BT 0.033 (1.253)	DT 0.001 (1.208)	loss 6.908 (6.908)	prob 2.556 (2.556)	GS 31.750 (31.750)	mem 39.730
Train: [37][190/750]	BT 0.037 (1.222)	DT 0.006 (1.176)	loss 6.945 (6.945)	prob 2.834 (2.834)	GS 29.594 (29.594)	mem 39.732
Train: [37][195/750]	BT 0.037 (1.192)	DT 0.001 (1.146)	loss 6.889 (6.889)	prob 2.526 (2.526)	GS 32.078 (32.078)	mem 39.734
Train: [37][200/750]	BT 0.036 (1.234)	DT 0.001 (1.189)	loss 6.889 (6.889)	prob 2.934 (2.934)	GS 35.281 (35.281)	mem 39.687
Train: [37][205/750]	BT 0.051 (1.206)	DT 0.001 (1.160)	loss 6.741 (6.741)	prob 2.651 (2.651)	GS 29.828 (29.828)	mem 39.688
Train: [37][210/750]	BT 0.031 (1.252)	DT 0.001 (1.207)	loss 6.837 (6.837)	prob 2.327 (2.327)	GS 35.156 (35.156)	mem 39.679
Train: [37][215/750]	BT 0.034 (1.224)	DT 0.004 (1.179)	loss 6.931 (6.931)	prob 2.779 (2.779)	GS 33.625 (33.625)	mem 39.680
Train: [37][220/750]	BT 11.445 (1.249)	DT 11.414 (1.204)	loss 6.753 (6.753)	prob 2.667 (2.667)	GS 37.000 (37.000)	mem 39.696
Train: [37][225/750]	BT 0.046 (1.222)	DT 0.004 (1.177)	loss 7.071 (7.071)	prob 2.106 (2.106)	GS 30.938 (30.938)	mem 39.697
Train: [37][230/750]	BT 0.046 (1.196)	DT 0.001 (1.152)	loss 6.671 (6.671)	prob 2.521 (2.521)	GS 34.781 (34.781)	mem 39.792
Train: [37][235/750]	BT 0.029 (1.227)	DT 0.001 (1.183)	loss 7.101 (7.101)	prob 2.139 (2.139)	GS 32.328 (32.328)	mem 39.736
Train: [37][240/750]	BT 0.050 (1.202)	DT 0.002 (1.158)	loss 6.797 (6.797)	prob 2.644 (2.644)	GS 33.859 (33.859)	mem 39.994
Train: [37][245/750]	BT 0.035 (1.219)	DT 0.002 (1.175)	loss 6.881 (6.881)	prob 2.354 (2.354)	GS 31.344 (31.344)	mem 39.819
Train: [37][250/750]	BT 0.033 (1.197)	DT 0.001 (1.153)	loss 7.048 (7.048)	prob 2.315 (2.315)	GS 32.359 (32.359)	mem 39.716
Train: [37][255/750]	BT 0.052 (1.174)	DT 0.004 (1.130)	loss 7.032 (7.032)	prob 2.436 (2.436)	GS 38.922 (38.922)	mem 39.814
Train: [37][260/750]	BT 1.730 (1.210)	DT 1.673 (1.165)	loss 6.893 (6.893)	prob 2.480 (2.480)	GS 34.688 (34.688)	mem 39.842
Train: [37][265/750]	BT 0.033 (1.188)	DT 0.009 (1.144)	loss 6.963 (6.963)	prob 2.184 (2.184)	GS 31.484 (31.484)	mem 39.888
Train: [37][270/750]	BT 0.033 (1.218)	DT 0.002 (1.173)	loss 6.722 (6.722)	prob 2.747 (2.747)	GS 34.203 (34.203)	mem 39.839
Train: [37][275/750]	BT 0.036 (1.196)	DT 0.001 (1.152)	loss 6.855 (6.855)	prob 2.681 (2.681)	GS 33.469 (33.469)	mem 39.840
Train: [37][280/750]	BT 11.885 (1.218)	DT 11.838 (1.174)	loss 6.729 (6.729)	prob 2.563 (2.563)	GS 29.703 (29.703)	mem 39.864
Train: [37][285/750]	BT 0.051 (1.198)	DT 0.012 (1.153)	loss 6.659 (6.659)	prob 3.533 (3.533)	GS 29.578 (29.578)	mem 39.865
Train: [37][290/750]	BT 0.032 (1.178)	DT 0.001 (1.134)	loss 7.003 (7.003)	prob 2.626 (2.626)	GS 35.766 (35.766)	mem 39.965
Train: [37][295/750]	BT 0.078 (1.203)	DT 0.004 (1.158)	loss 7.126 (7.126)	prob 2.767 (2.767)	GS 33.141 (33.141)	mem 39.864
Train: [37][300/750]	BT 0.039 (1.183)	DT 0.003 (1.139)	loss 6.746 (6.746)	prob 3.362 (3.362)	GS 33.812 (33.812)	mem 39.867
Train: [37][305/750]	BT 0.030 (1.208)	DT 0.002 (1.164)	loss 7.125 (7.125)	prob 3.015 (3.015)	GS 32.578 (32.578)	mem 39.924
Train: [37][310/750]	BT 0.060 (1.195)	DT 0.001 (1.151)	loss 6.932 (6.932)	prob 2.492 (2.492)	GS 29.484 (29.484)	mem 39.835
Train: [37][315/750]	BT 0.036 (1.176)	DT 0.011 (1.132)	loss 6.982 (6.982)	prob 2.437 (2.437)	GS 30.781 (30.781)	mem 39.849
Train: [37][320/750]	BT 0.059 (1.193)	DT 0.010 (1.149)	loss 6.750 (6.750)	prob 2.309 (2.309)	GS 32.609 (32.609)	mem 39.914
Train: [37][325/750]	BT 0.043 (1.175)	DT 0.003 (1.131)	loss 7.132 (7.132)	prob 2.651 (2.651)	GS 29.797 (29.797)	mem 39.887
Train: [37][330/750]	BT 0.040 (1.192)	DT 0.002 (1.148)	loss 7.128 (7.128)	prob 1.948 (1.948)	GS 34.250 (34.250)	mem 39.905
Train: [37][335/750]	BT 0.034 (1.176)	DT 0.004 (1.133)	loss 6.673 (6.673)	prob 2.648 (2.648)	GS 27.281 (27.281)	mem 39.841
Train: [37][340/750]	BT 12.959 (1.198)	DT 12.910 (1.154)	loss 6.944 (6.944)	prob 1.650 (1.650)	GS 35.656 (35.656)	mem 39.895
Train: [37][345/750]	BT 0.102 (1.189)	DT 0.026 (1.145)	loss 6.767 (6.767)	prob 3.268 (3.268)	GS 35.062 (35.062)	mem 39.877
Train: [37][350/750]	BT 0.024 (1.173)	DT 0.001 (1.129)	loss 6.957 (6.957)	prob 2.556 (2.556)	GS 31.828 (31.828)	mem 39.840
Train: [37][355/750]	BT 0.032 (1.180)	DT 0.005 (1.137)	loss 7.067 (7.067)	prob 1.713 (1.713)	GS 29.594 (29.594)	mem 39.898
Train: [37][360/750]	BT 0.024 (1.169)	DT 0.001 (1.126)	loss 6.895 (6.895)	prob 2.612 (2.612)	GS 29.125 (29.125)	mem 39.840
Train: [37][365/750]	BT 0.041 (1.187)	DT 0.002 (1.144)	loss 6.684 (6.684)	prob 2.626 (2.626)	GS 29.984 (29.984)	mem 39.900
Train: [37][370/750]	BT 0.031 (1.177)	DT 0.001 (1.134)	loss 6.954 (6.954)	prob 1.924 (1.924)	GS 34.156 (34.156)	mem 39.867
Train: [37][375/750]	BT 0.135 (1.162)	DT 0.010 (1.119)	loss 6.761 (6.761)	prob 2.601 (2.601)	GS 30.656 (30.656)	mem 39.871
Train: [37][380/750]	BT 1.996 (1.181)	DT 1.933 (1.137)	loss 6.797 (6.797)	prob 2.864 (2.864)	GS 36.812 (36.812)	mem 39.988
Train: [37][385/750]	BT 0.034 (1.166)	DT 0.001 (1.123)	loss 7.039 (7.039)	prob 2.353 (2.353)	GS 32.062 (32.062)	mem 39.905
Train: [37][390/750]	BT 0.101 (1.180)	DT 0.001 (1.136)	loss 6.817 (6.817)	prob 2.845 (2.845)	GS 35.656 (35.656)	mem 40.214
Train: [37][395/750]	BT 0.029 (1.168)	DT 0.002 (1.124)	loss 6.992 (6.992)	prob 2.206 (2.206)	GS 27.516 (27.516)	mem 39.957
Train: [37][400/750]	BT 11.645 (1.183)	DT 11.596 (1.139)	loss 6.813 (6.813)	prob 2.522 (2.522)	GS 32.062 (32.062)	mem 39.903
Train: [37][405/750]	BT 0.033 (1.169)	DT 0.003 (1.125)	loss 7.036 (7.036)	prob 2.756 (2.756)	GS 33.484 (33.484)	mem 39.904
Train: [37][410/750]	BT 0.050 (1.155)	DT 0.001 (1.112)	loss 6.649 (6.649)	prob 2.908 (2.908)	GS 34.641 (34.641)	mem 39.905
Train: [37][415/750]	BT 0.026 (1.168)	DT 0.001 (1.125)	loss 6.912 (6.912)	prob 2.294 (2.294)	GS 35.266 (35.266)	mem 39.950
Train: [37][420/750]	BT 0.082 (1.159)	DT 0.036 (1.116)	loss 6.964 (6.964)	prob 2.008 (2.008)	GS 35.375 (35.375)	mem 40.039
Train: [37][425/750]	BT 0.067 (1.171)	DT 0.010 (1.127)	loss 6.814 (6.814)	prob 2.886 (2.886)	GS 28.312 (28.312)	mem 39.941
Train: [37][430/750]	BT 0.051 (1.172)	DT 0.003 (1.129)	loss 6.851 (6.851)	prob 2.864 (2.864)	GS 35.250 (35.250)	mem 39.931
Train: [37][435/750]	BT 0.054 (1.159)	DT 0.002 (1.116)	loss 7.134 (7.134)	prob 2.307 (2.307)	GS 31.375 (31.375)	mem 39.932
Train: [37][440/750]	BT 6.873 (1.182)	DT 6.802 (1.139)	loss 6.831 (6.831)	prob 3.347 (3.347)	GS 33.969 (33.969)	mem 39.896
Train: [37][445/750]	BT 0.039 (1.169)	DT 0.002 (1.126)	loss 7.060 (7.060)	prob 2.324 (2.324)	GS 31.547 (31.547)	mem 39.898
Train: [37][450/750]	BT 0.034 (1.169)	DT 0.001 (1.126)	loss 6.569 (6.569)	prob 3.239 (3.239)	GS 36.172 (36.172)	mem 39.851
Train: [37][455/750]	BT 0.048 (1.180)	DT 0.002 (1.137)	loss 6.950 (6.950)	prob 2.335 (2.335)	GS 27.641 (27.641)	mem 39.835
Train: [37][460/750]	BT 2.344 (1.173)	DT 2.312 (1.130)	loss 6.900 (6.900)	prob 2.695 (2.695)	GS 35.734 (35.734)	mem 40.082
Train: [37][465/750]	BT 0.047 (1.184)	DT 0.008 (1.140)	loss 6.966 (6.966)	prob 2.859 (2.859)	GS 32.562 (32.562)	mem 39.826
Train: [37][470/750]	BT 0.046 (1.172)	DT 0.020 (1.128)	loss 6.785 (6.785)	prob 2.905 (2.905)	GS 33.891 (33.891)	mem 39.828
Train: [37][475/750]	BT 0.062 (1.160)	DT 0.001 (1.116)	loss 6.916 (6.916)	prob 2.641 (2.641)	GS 30.875 (30.875)	mem 39.923
Train: [37][480/750]	BT 0.023 (1.174)	DT 0.001 (1.131)	loss 6.973 (6.973)	prob 2.662 (2.662)	GS 35.656 (35.656)	mem 39.860
Train: [37][485/750]	BT 0.032 (1.162)	DT 0.001 (1.119)	loss 6.887 (6.887)	prob 2.870 (2.870)	GS 28.844 (28.844)	mem 40.186
Train: [37][490/750]	BT 0.033 (1.175)	DT 0.002 (1.131)	loss 6.949 (6.949)	prob 3.045 (3.045)	GS 33.656 (33.656)	mem 40.129
Train: [37][495/750]	BT 0.031 (1.163)	DT 0.001 (1.120)	loss 6.814 (6.814)	prob 2.914 (2.914)	GS 32.250 (32.250)	mem 39.969
Train: [37][500/750]	BT 13.360 (1.179)	DT 13.326 (1.135)	loss 6.859 (6.859)	prob 2.801 (2.801)	GS 31.250 (31.250)	mem 39.977
Train: [37][505/750]	BT 0.027 (1.167)	DT 0.001 (1.124)	loss 6.751 (6.751)	prob 2.631 (2.631)	GS 33.891 (33.891)	mem 39.998
Train: [37][510/750]	BT 0.056 (1.156)	DT 0.003 (1.113)	loss 6.767 (6.767)	prob 3.012 (3.012)	GS 33.438 (33.438)	mem 40.099
Train: [37][515/750]	BT 0.052 (1.169)	DT 0.012 (1.126)	loss 6.894 (6.894)	prob 2.172 (2.172)	GS 33.016 (33.016)	mem 40.056
Train: [37][520/750]	BT 0.051 (1.158)	DT 0.001 (1.115)	loss 6.914 (6.914)	prob 2.866 (2.866)	GS 32.062 (32.062)	mem 40.057
Train: [37][525/750]	BT 0.034 (1.173)	DT 0.005 (1.129)	loss 7.028 (7.028)	prob 2.589 (2.589)	GS 29.406 (29.406)	mem 40.025
Train: [37][530/750]	BT 0.041 (1.162)	DT 0.009 (1.119)	loss 6.724 (6.724)	prob 3.284 (3.284)	GS 36.703 (36.703)	mem 40.023
Train: [37][535/750]	BT 0.057 (1.151)	DT 0.001 (1.108)	loss 7.045 (7.045)	prob 2.057 (2.057)	GS 32.109 (32.109)	mem 40.024
Train: [37][540/750]	BT 0.023 (1.173)	DT 0.001 (1.130)	loss 6.922 (6.922)	prob 2.703 (2.703)	GS 30.781 (30.781)	mem 39.944
Train: [37][545/750]	BT 0.049 (1.162)	DT 0.001 (1.119)	loss 7.039 (7.039)	prob 2.783 (2.783)	GS 29.516 (29.516)	mem 39.944
Train: [37][550/750]	BT 0.034 (1.175)	DT 0.005 (1.132)	loss 6.877 (6.877)	prob 3.178 (3.178)	GS 33.953 (33.953)	mem 39.996
Train: [37][555/750]	BT 0.026 (1.165)	DT 0.001 (1.122)	loss 6.880 (6.880)	prob 2.748 (2.748)	GS 30.031 (30.031)	mem 39.995
Train: [37][560/750]	BT 14.311 (1.180)	DT 14.289 (1.138)	loss 6.729 (6.729)	prob 3.066 (3.066)	GS 32.188 (32.188)	mem 39.972
Train: [37][565/750]	BT 0.029 (1.170)	DT 0.001 (1.127)	loss 6.684 (6.684)	prob 2.685 (2.685)	GS 31.125 (31.125)	mem 39.974
Train: [37][570/750]	BT 0.042 (1.160)	DT 0.002 (1.118)	loss 6.888 (6.888)	prob 2.828 (2.828)	GS 34.500 (34.500)	mem 39.974
Train: [37][575/750]	BT 0.034 (1.172)	DT 0.002 (1.129)	loss 6.973 (6.973)	prob 2.700 (2.700)	GS 32.391 (32.391)	mem 39.826
Train: [37][580/750]	BT 0.042 (1.162)	DT 0.001 (1.120)	loss 6.808 (6.808)	prob 3.518 (3.518)	GS 32.391 (32.391)	mem 39.827
Train: [37][585/750]	BT 0.025 (1.176)	DT 0.001 (1.133)	loss 6.824 (6.824)	prob 2.490 (2.490)	GS 31.438 (31.438)	mem 39.766
Train: [37][590/750]	BT 0.124 (1.166)	DT 0.003 (1.124)	loss 6.862 (6.862)	prob 2.256 (2.256)	GS 33.766 (33.766)	mem 39.862
Train: [37][595/750]	BT 0.031 (1.157)	DT 0.001 (1.114)	loss 6.911 (6.911)	prob 2.655 (2.655)	GS 29.703 (29.703)	mem 39.808
Train: [37][600/750]	BT 0.035 (1.170)	DT 0.001 (1.128)	loss 6.872 (6.872)	prob 2.561 (2.561)	GS 37.016 (37.016)	mem 39.808
Train: [37][605/750]	BT 0.029 (1.161)	DT 0.001 (1.118)	loss 6.929 (6.929)	prob 2.363 (2.363)	GS 29.484 (29.484)	mem 39.886
Train: [37][610/750]	BT 0.070 (1.172)	DT 0.012 (1.129)	loss 7.116 (7.116)	prob 2.385 (2.385)	GS 29.484 (29.484)	mem 39.795
Train: [37][615/750]	BT 0.039 (1.162)	DT 0.002 (1.120)	loss 6.680 (6.680)	prob 2.545 (2.545)	GS 32.734 (32.734)	mem 39.795
Train: [37][620/750]	BT 13.592 (1.175)	DT 13.557 (1.133)	loss 6.951 (6.951)	prob 2.053 (2.053)	GS 32.156 (32.156)	mem 39.839
Train: [37][625/750]	BT 0.049 (1.166)	DT 0.002 (1.124)	loss 6.854 (6.854)	prob 2.525 (2.525)	GS 35.188 (35.188)	mem 39.839
Train: [37][630/750]	BT 0.037 (1.158)	DT 0.002 (1.115)	loss 6.777 (6.777)	prob 3.282 (3.282)	GS 30.250 (30.250)	mem 39.841
Train: [37][635/750]	BT 0.034 (1.171)	DT 0.006 (1.129)	loss 7.003 (7.003)	prob 1.796 (1.796)	GS 27.938 (27.938)	mem 39.710
Train: [37][640/750]	BT 0.025 (1.162)	DT 0.001 (1.120)	loss 7.087 (7.087)	prob 1.955 (1.955)	GS 32.984 (32.984)	mem 39.709
Train: [37][645/750]	BT 0.038 (1.173)	DT 0.006 (1.131)	loss 6.948 (6.948)	prob 2.675 (2.675)	GS 32.719 (32.719)	mem 39.760
Train: [37][650/750]	BT 0.066 (1.165)	DT 0.009 (1.122)	loss 6.765 (6.765)	prob 2.267 (2.267)	GS 28.484 (28.484)	mem 39.760
Train: [37][655/750]	BT 0.048 (1.156)	DT 0.007 (1.114)	loss 6.820 (6.820)	prob 2.913 (2.913)	GS 32.719 (32.719)	mem 39.770
Train: [37][660/750]	BT 0.034 (1.165)	DT 0.001 (1.122)	loss 6.787 (6.787)	prob 3.245 (3.245)	GS 29.672 (29.672)	mem 40.028
Train: [37][665/750]	BT 0.048 (1.157)	DT 0.001 (1.114)	loss 6.763 (6.763)	prob 3.445 (3.445)	GS 31.422 (31.422)	mem 39.929
Train: [37][670/750]	BT 0.036 (1.168)	DT 0.001 (1.125)	loss 6.797 (6.797)	prob 2.723 (2.723)	GS 35.969 (35.969)	mem 39.902
Train: [37][675/750]	BT 0.043 (1.160)	DT 0.012 (1.117)	loss 7.078 (7.078)	prob 2.457 (2.457)	GS 27.719 (27.719)	mem 39.909
Train: [37][680/750]	BT 12.343 (1.170)	DT 12.310 (1.127)	loss 6.851 (6.851)	prob 2.834 (2.834)	GS 35.250 (35.250)	mem 39.894
Train: [37][685/750]	BT 0.052 (1.161)	DT 0.006 (1.119)	loss 6.985 (6.985)	prob 2.958 (2.958)	GS 34.844 (34.844)	mem 39.898
Train: [37][690/750]	BT 0.044 (1.153)	DT 0.004 (1.111)	loss 6.693 (6.693)	prob 3.026 (3.026)	GS 36.094 (36.094)	mem 39.898
Train: [37][695/750]	BT 0.051 (1.168)	DT 0.012 (1.125)	loss 7.098 (7.098)	prob 2.833 (2.833)	GS 33.875 (33.875)	mem 39.928
Train: [37][700/750]	BT 0.030 (1.160)	DT 0.001 (1.117)	loss 6.762 (6.762)	prob 2.799 (2.799)	GS 34.000 (34.000)	mem 39.856
Train: [37][705/750]	BT 0.095 (1.171)	DT 0.022 (1.128)	loss 6.975 (6.975)	prob 3.375 (3.375)	GS 30.672 (30.672)	mem 39.896
Train: [37][710/750]	BT 0.037 (1.163)	DT 0.002 (1.121)	loss 6.925 (6.925)	prob 2.650 (2.650)	GS 33.359 (33.359)	mem 39.998
Train: [37][715/750]	BT 0.076 (1.155)	DT 0.001 (1.113)	loss 6.976 (6.976)	prob 3.115 (3.115)	GS 33.719 (33.719)	mem 40.058
Train: [37][720/750]	BT 0.025 (1.166)	DT 0.001 (1.123)	loss 7.101 (7.101)	prob 2.382 (2.382)	GS 31.719 (31.719)	mem 39.972
Train: [37][725/750]	BT 0.052 (1.158)	DT 0.005 (1.116)	loss 7.004 (7.004)	prob 2.928 (2.928)	GS 32.047 (32.047)	mem 39.973
Train: [37][730/750]	BT 0.028 (1.164)	DT 0.001 (1.121)	loss 6.573 (6.573)	prob 2.555 (2.555)	GS 34.250 (34.250)	mem 39.663
Train: [37][735/750]	BT 0.075 (1.156)	DT 0.014 (1.114)	loss 7.069 (7.069)	prob 2.372 (2.372)	GS 29.516 (29.516)	mem 39.602
Train: [37][740/750]	BT 5.765 (1.156)	DT 5.736 (1.114)	loss 6.727 (6.727)	prob 3.558 (3.558)	GS 29.500 (29.500)	mem 7.610
Train: [37][745/750]	BT 0.029 (1.149)	DT 0.001 (1.106)	loss 6.874 (6.874)	prob 2.580 (2.580)	GS 31.719 (31.719)	mem 7.611
Train: [37][750/750]	BT 0.022 (1.141)	DT 0.001 (1.099)	loss 7.205 (7.205)	prob 3.107 (3.107)	GS 37.469 (37.469)	mem 7.649
Train: [37][755/750]	BT 0.025 (1.138)	DT 0.001 (1.096)	loss 6.774 (6.774)	prob 3.567 (3.567)	GS 26.906 (26.906)	mem 7.574
epoch 37, total time 859.12
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [38][1/750]	BT 22.064 (22.064)	DT 21.996 (21.996)	loss 7.164 (7.164)	prob 1.804 (1.804)	GS 33.875 (33.875)	mem 39.027
Train: [38][5/750]	BT 0.031 (5.183)	DT 0.001 (5.142)	loss 6.880 (6.880)	prob 3.554 (3.554)	GS 31.703 (31.703)	mem 38.732
Train: [38][10/750]	BT 0.295 (2.644)	DT 0.251 (2.598)	loss 6.933 (6.933)	prob 2.770 (2.770)	GS 33.312 (33.312)	mem 38.735
Train: [38][15/750]	BT 0.032 (2.818)	DT 0.001 (2.773)	loss 6.889 (6.889)	prob 2.501 (2.501)	GS 31.922 (31.922)	mem 38.909
Train: [38][20/750]	BT 0.096 (2.134)	DT 0.001 (2.081)	loss 6.703 (6.703)	prob 2.979 (2.979)	GS 26.312 (26.312)	mem 38.860
Train: [38][25/750]	BT 1.459 (1.774)	DT 1.353 (1.721)	loss 6.840 (6.840)	prob 3.531 (3.531)	GS 29.969 (29.969)	mem 38.882
Train: [38][30/750]	BT 0.033 (1.960)	DT 0.002 (1.910)	loss 6.958 (6.958)	prob 2.823 (2.823)	GS 34.953 (34.953)	mem 39.038
Train: [38][35/750]	BT 0.034 (1.685)	DT 0.001 (1.637)	loss 6.957 (6.957)	prob 2.607 (2.607)	GS 32.156 (32.156)	mem 38.930
Train: [38][40/750]	BT 0.033 (1.778)	DT 0.001 (1.730)	loss 6.905 (6.905)	prob 3.014 (3.014)	GS 34.375 (34.375)	mem 38.969
Train: [38][45/750]	BT 0.033 (1.584)	DT 0.008 (1.538)	loss 6.917 (6.917)	prob 2.482 (2.482)	GS 28.203 (28.203)	mem 38.969
Train: [38][50/750]	BT 13.260 (1.694)	DT 13.229 (1.650)	loss 7.012 (7.012)	prob 3.265 (3.265)	GS 32.734 (32.734)	mem 39.129
Train: [38][55/750]	BT 0.022 (1.543)	DT 0.001 (1.500)	loss 7.169 (7.169)	prob 2.549 (2.549)	GS 29.688 (29.688)	mem 39.131
Train: [38][60/750]	BT 0.063 (1.419)	DT 0.002 (1.375)	loss 7.049 (7.049)	prob 2.630 (2.630)	GS 30.562 (30.562)	mem 39.366
Train: [38][65/750]	BT 0.059 (1.501)	DT 0.013 (1.457)	loss 7.058 (7.058)	prob 2.568 (2.568)	GS 30.297 (30.297)	mem 39.255
Train: [38][70/750]	BT 0.063 (1.398)	DT 0.003 (1.353)	loss 6.757 (6.757)	prob 3.333 (3.333)	GS 33.953 (33.953)	mem 39.257
Train: [38][75/750]	BT 0.033 (1.458)	DT 0.002 (1.414)	loss 7.556 (7.556)	prob 1.960 (1.960)	GS 35.406 (35.406)	mem 39.393
Train: [38][80/750]	BT 0.034 (1.370)	DT 0.003 (1.326)	loss 6.999 (6.999)	prob 2.547 (2.547)	GS 31.641 (31.641)	mem 39.486
Train: [38][85/750]	BT 0.102 (1.293)	DT 0.008 (1.248)	loss 7.303 (7.303)	prob 2.137 (2.137)	GS 30.469 (30.469)	mem 39.393
Train: [38][90/750]	BT 0.032 (1.369)	DT 0.002 (1.324)	loss 6.916 (6.916)	prob 2.585 (2.585)	GS 32.953 (32.953)	mem 39.626
Train: [38][95/750]	BT 0.059 (1.299)	DT 0.004 (1.254)	loss 6.968 (6.968)	prob 3.146 (3.146)	GS 34.125 (34.125)	mem 39.695
Train: [38][100/750]	BT 0.048 (1.387)	DT 0.008 (1.343)	loss 6.752 (6.752)	prob 2.879 (2.879)	GS 35.469 (35.469)	mem 39.640
Train: [38][105/750]	BT 0.023 (1.323)	DT 0.001 (1.279)	loss 6.947 (6.947)	prob 2.281 (2.281)	GS 29.391 (29.391)	mem 39.640
Train: [38][110/750]	BT 13.887 (1.390)	DT 13.852 (1.347)	loss 6.997 (6.997)	prob 2.911 (2.911)	GS 36.625 (36.625)	mem 39.644
Train: [38][115/750]	BT 0.049 (1.332)	DT 0.001 (1.288)	loss 7.024 (7.024)	prob 2.449 (2.449)	GS 39.797 (39.797)	mem 39.644
Train: [38][120/750]	BT 0.055 (1.278)	DT 0.009 (1.235)	loss 6.847 (6.847)	prob 3.027 (3.027)	GS 28.703 (28.703)	mem 39.646
Train: [38][125/750]	BT 0.028 (1.351)	DT 0.001 (1.309)	loss 7.061 (7.061)	prob 2.614 (2.614)	GS 37.953 (37.953)	mem 39.760
Train: [38][130/750]	BT 0.113 (1.301)	DT 0.048 (1.259)	loss 6.873 (6.873)	prob 2.546 (2.546)	GS 38.328 (38.328)	mem 39.761
Train: [38][135/750]	BT 0.063 (1.359)	DT 0.006 (1.316)	loss 7.100 (7.100)	prob 2.106 (2.106)	GS 32.062 (32.062)	mem 39.784
Train: [38][140/750]	BT 0.043 (1.312)	DT 0.005 (1.269)	loss 6.984 (6.984)	prob 2.447 (2.447)	GS 37.797 (37.797)	mem 39.786
Train: [38][145/750]	BT 0.032 (1.268)	DT 0.002 (1.226)	loss 7.149 (7.149)	prob 2.946 (2.946)	GS 35.547 (35.547)	mem 39.812
Train: [38][150/750]	BT 0.052 (1.308)	DT 0.015 (1.266)	loss 6.847 (6.847)	prob 3.403 (3.403)	GS 33.047 (33.047)	mem 39.800
Train: [38][155/750]	BT 0.037 (1.267)	DT 0.002 (1.226)	loss 7.279 (7.279)	prob 3.179 (3.179)	GS 39.219 (39.219)	mem 39.791
Train: [38][160/750]	BT 0.084 (1.303)	DT 0.004 (1.261)	loss 6.956 (6.956)	prob 2.253 (2.253)	GS 32.781 (32.781)	mem 39.876
Train: [38][165/750]	BT 0.057 (1.265)	DT 0.001 (1.223)	loss 6.885 (6.885)	prob 3.013 (3.013)	GS 29.328 (29.328)	mem 39.814
Train: [38][170/750]	BT 11.993 (1.300)	DT 11.959 (1.258)	loss 6.800 (6.800)	prob 3.022 (3.022)	GS 29.672 (29.672)	mem 39.828
Train: [38][175/750]	BT 0.022 (1.263)	DT 0.001 (1.222)	loss 7.193 (7.193)	prob 2.461 (2.461)	GS 29.031 (29.031)	mem 39.828
Train: [38][180/750]	BT 0.032 (1.230)	DT 0.001 (1.188)	loss 6.967 (6.967)	prob 2.703 (2.703)	GS 31.094 (31.094)	mem 39.859
Train: [38][185/750]	BT 0.055 (1.266)	DT 0.001 (1.224)	loss 7.058 (7.058)	prob 2.654 (2.654)	GS 31.828 (31.828)	mem 39.965
Train: [38][190/750]	BT 0.026 (1.233)	DT 0.001 (1.192)	loss 6.851 (6.851)	prob 2.332 (2.332)	GS 35.938 (35.938)	mem 39.846
Train: [38][195/750]	BT 0.056 (1.260)	DT 0.003 (1.218)	loss 6.843 (6.843)	prob 3.472 (3.472)	GS 36.562 (36.562)	mem 39.815
Train: [38][200/750]	BT 0.050 (1.230)	DT 0.004 (1.188)	loss 6.846 (6.846)	prob 3.288 (3.288)	GS 39.297 (39.297)	mem 39.817
Train: [38][205/750]	BT 0.052 (1.201)	DT 0.001 (1.159)	loss 6.872 (6.872)	prob 2.951 (2.951)	GS 33.562 (33.562)	mem 39.819
Train: [38][210/750]	BT 0.031 (1.241)	DT 0.001 (1.199)	loss 6.937 (6.937)	prob 2.889 (2.889)	GS 34.484 (34.484)	mem 39.890
Train: [38][215/750]	BT 0.043 (1.213)	DT 0.001 (1.172)	loss 6.855 (6.855)	prob 2.768 (2.768)	GS 31.859 (31.859)	mem 40.153
Train: [38][220/750]	BT 0.029 (1.250)	DT 0.001 (1.208)	loss 6.822 (6.822)	prob 2.708 (2.708)	GS 32.969 (32.969)	mem 39.913
Train: [38][225/750]	BT 0.077 (1.224)	DT 0.012 (1.182)	loss 7.011 (7.011)	prob 2.527 (2.527)	GS 25.234 (25.234)	mem 39.913
Train: [38][230/750]	BT 12.641 (1.253)	DT 12.610 (1.211)	loss 6.879 (6.879)	prob 3.011 (3.011)	GS 36.219 (36.219)	mem 39.932
Train: [38][235/750]	BT 0.032 (1.227)	DT 0.001 (1.185)	loss 6.970 (6.970)	prob 2.373 (2.373)	GS 31.516 (31.516)	mem 39.965
Train: [38][240/750]	BT 0.042 (1.202)	DT 0.001 (1.160)	loss 6.701 (6.701)	prob 3.130 (3.130)	GS 34.906 (34.906)	mem 39.935
Train: [38][245/750]	BT 0.043 (1.219)	DT 0.009 (1.178)	loss 7.120 (7.120)	prob 2.892 (2.892)	GS 29.484 (29.484)	mem 39.947
Train: [38][250/750]	BT 0.062 (1.196)	DT 0.001 (1.154)	loss 6.617 (6.617)	prob 2.525 (2.525)	GS 29.906 (29.906)	mem 39.947
Train: [38][255/750]	BT 0.043 (1.226)	DT 0.005 (1.184)	loss 6.771 (6.771)	prob 2.076 (2.076)	GS 28.719 (28.719)	mem 39.963
Train: [38][260/750]	BT 0.035 (1.203)	DT 0.001 (1.161)	loss 7.081 (7.081)	prob 2.201 (2.201)	GS 31.609 (31.609)	mem 40.005
Train: [38][265/750]	BT 0.082 (1.181)	DT 0.005 (1.139)	loss 6.875 (6.875)	prob 2.298 (2.298)	GS 27.531 (27.531)	mem 39.963
Train: [38][270/750]	BT 0.094 (1.210)	DT 0.001 (1.168)	loss 6.790 (6.790)	prob 2.274 (2.274)	GS 31.609 (31.609)	mem 40.038
Train: [38][275/750]	BT 0.057 (1.189)	DT 0.001 (1.147)	loss 6.914 (6.914)	prob 2.558 (2.558)	GS 25.219 (25.219)	mem 39.967
Train: [38][280/750]	BT 0.047 (1.216)	DT 0.007 (1.174)	loss 6.931 (6.931)	prob 2.207 (2.207)	GS 36.031 (36.031)	mem 39.798
Train: [38][285/750]	BT 0.042 (1.196)	DT 0.003 (1.153)	loss 6.687 (6.687)	prob 3.046 (3.046)	GS 30.422 (30.422)	mem 39.797
Train: [38][290/750]	BT 14.370 (1.225)	DT 14.339 (1.183)	loss 7.014 (7.014)	prob 2.678 (2.678)	GS 37.547 (37.547)	mem 39.853
Train: [38][295/750]	BT 0.022 (1.205)	DT 0.001 (1.163)	loss 6.932 (6.932)	prob 1.879 (1.879)	GS 33.016 (33.016)	mem 39.871
Train: [38][300/750]	BT 0.054 (1.185)	DT 0.007 (1.144)	loss 6.836 (6.836)	prob 2.699 (2.699)	GS 29.938 (29.938)	mem 39.871
Train: [38][305/750]	BT 0.028 (1.216)	DT 0.001 (1.174)	loss 6.769 (6.769)	prob 2.489 (2.489)	GS 32.469 (32.469)	mem 39.893
Train: [38][310/750]	BT 0.030 (1.196)	DT 0.001 (1.155)	loss 6.737 (6.737)	prob 3.113 (3.113)	GS 33.016 (33.016)	mem 39.893
Train: [38][315/750]	BT 0.039 (1.221)	DT 0.006 (1.180)	loss 7.105 (7.105)	prob 2.439 (2.439)	GS 35.141 (35.141)	mem 39.888
Train: [38][320/750]	BT 0.029 (1.203)	DT 0.001 (1.162)	loss 6.758 (6.758)	prob 2.879 (2.879)	GS 32.344 (32.344)	mem 39.887
Train: [38][325/750]	BT 0.036 (1.185)	DT 0.008 (1.144)	loss 6.902 (6.902)	prob 1.870 (1.870)	GS 32.359 (32.359)	mem 39.887
Train: [38][330/750]	BT 0.037 (1.201)	DT 0.001 (1.160)	loss 6.843 (6.843)	prob 2.752 (2.752)	GS 31.938 (31.938)	mem 39.866
Train: [38][335/750]	BT 0.032 (1.184)	DT 0.002 (1.143)	loss 6.872 (6.872)	prob 2.342 (2.342)	GS 31.062 (31.062)	mem 39.867
Train: [38][340/750]	BT 0.031 (1.200)	DT 0.001 (1.159)	loss 6.892 (6.892)	prob 2.562 (2.562)	GS 33.688 (33.688)	mem 39.787
Train: [38][345/750]	BT 0.047 (1.183)	DT 0.009 (1.142)	loss 7.051 (7.051)	prob 2.492 (2.492)	GS 33.188 (33.188)	mem 39.788
Train: [38][350/750]	BT 15.292 (1.211)	DT 15.262 (1.170)	loss 6.877 (6.877)	prob 2.915 (2.915)	GS 33.312 (33.312)	mem 39.832
Train: [38][355/750]	BT 0.040 (1.194)	DT 0.001 (1.153)	loss 6.897 (6.897)	prob 2.672 (2.672)	GS 32.703 (32.703)	mem 39.823
Train: [38][360/750]	BT 0.066 (1.178)	DT 0.005 (1.137)	loss 6.727 (6.727)	prob 2.669 (2.669)	GS 33.734 (33.734)	mem 39.889
Train: [38][365/750]	BT 0.027 (1.205)	DT 0.001 (1.165)	loss 6.935 (6.935)	prob 2.314 (2.314)	GS 30.297 (30.297)	mem 39.772
Train: [38][370/750]	BT 0.042 (1.189)	DT 0.001 (1.149)	loss 7.113 (7.113)	prob 2.619 (2.619)	GS 36.281 (36.281)	mem 39.824
Train: [38][375/750]	BT 0.031 (1.208)	DT 0.001 (1.167)	loss 7.034 (7.034)	prob 2.386 (2.386)	GS 31.250 (31.250)	mem 39.768
Train: [38][380/750]	BT 0.030 (1.192)	DT 0.001 (1.152)	loss 6.891 (6.891)	prob 2.213 (2.213)	GS 33.000 (33.000)	mem 39.729
Train: [38][385/750]	BT 0.111 (1.178)	DT 0.012 (1.137)	loss 7.134 (7.134)	prob 2.969 (2.969)	GS 32.484 (32.484)	mem 39.794
Train: [38][390/750]	BT 0.067 (1.193)	DT 0.002 (1.152)	loss 6.828 (6.828)	prob 2.762 (2.762)	GS 31.938 (31.938)	mem 39.821
Train: [38][395/750]	BT 0.034 (1.178)	DT 0.002 (1.137)	loss 7.016 (7.016)	prob 2.149 (2.149)	GS 45.750 (45.750)	mem 39.845
Train: [38][400/750]	BT 0.032 (1.200)	DT 0.001 (1.160)	loss 6.863 (6.863)	prob 2.344 (2.344)	GS 30.062 (30.062)	mem 39.753
Train: [38][405/750]	BT 0.089 (1.186)	DT 0.029 (1.146)	loss 6.734 (6.734)	prob 2.496 (2.496)	GS 31.688 (31.688)	mem 39.753
Train: [38][410/750]	BT 13.664 (1.206)	DT 13.608 (1.165)	loss 6.755 (6.755)	prob 2.780 (2.780)	GS 32.062 (32.062)	mem 39.866
Train: [38][415/750]	BT 0.033 (1.192)	DT 0.002 (1.151)	loss 7.459 (7.459)	prob 2.543 (2.543)	GS 47.266 (47.266)	mem 40.032
Train: [38][420/750]	BT 0.040 (1.178)	DT 0.002 (1.137)	loss 6.846 (6.846)	prob 2.814 (2.814)	GS 35.891 (35.891)	mem 40.096
Train: [38][425/750]	BT 0.047 (1.200)	DT 0.001 (1.159)	loss 6.954 (6.954)	prob 2.780 (2.780)	GS 31.141 (31.141)	mem 39.893
Train: [38][430/750]	BT 0.090 (1.187)	DT 0.039 (1.145)	loss 6.912 (6.912)	prob 2.494 (2.494)	GS 33.266 (33.266)	mem 39.928
Train: [38][435/750]	BT 0.024 (1.209)	DT 0.004 (1.168)	loss 6.939 (6.939)	prob 2.661 (2.661)	GS 27.766 (27.766)	mem 39.907
Train: [38][440/750]	BT 0.068 (1.196)	DT 0.011 (1.155)	loss 6.855 (6.855)	prob 2.797 (2.797)	GS 35.156 (35.156)	mem 39.906
Train: [38][445/750]	BT 0.025 (1.183)	DT 0.001 (1.142)	loss 6.833 (6.833)	prob 2.730 (2.730)	GS 29.000 (29.000)	mem 39.907
Train: [38][450/750]	BT 0.029 (1.192)	DT 0.001 (1.151)	loss 7.130 (7.130)	prob 1.945 (1.945)	GS 35.359 (35.359)	mem 39.936
Train: [38][455/750]	BT 0.028 (1.180)	DT 0.001 (1.138)	loss 6.951 (6.951)	prob 2.631 (2.631)	GS 31.141 (31.141)	mem 39.935
Train: [38][460/750]	BT 0.030 (1.197)	DT 0.001 (1.155)	loss 7.112 (7.112)	prob 2.308 (2.308)	GS 33.344 (33.344)	mem 39.862
Train: [38][465/750]	BT 0.085 (1.185)	DT 0.004 (1.143)	loss 6.868 (6.868)	prob 2.723 (2.723)	GS 32.031 (32.031)	mem 39.798
Train: [38][470/750]	BT 9.731 (1.193)	DT 9.685 (1.151)	loss 6.753 (6.753)	prob 2.706 (2.706)	GS 34.266 (34.266)	mem 39.910
Train: [38][475/750]	BT 0.030 (1.181)	DT 0.001 (1.139)	loss 6.873 (6.873)	prob 2.958 (2.958)	GS 30.406 (30.406)	mem 39.912
Train: [38][480/750]	BT 0.031 (1.169)	DT 0.001 (1.128)	loss 6.974 (6.974)	prob 2.836 (2.836)	GS 32.031 (32.031)	mem 39.912
Train: [38][485/750]	BT 0.057 (1.186)	DT 0.001 (1.144)	loss 6.911 (6.911)	prob 2.354 (2.354)	GS 29.984 (29.984)	mem 40.160
Train: [38][490/750]	BT 0.058 (1.175)	DT 0.025 (1.133)	loss 6.671 (6.671)	prob 3.321 (3.321)	GS 30.984 (30.984)	mem 39.902
Train: [38][495/750]	BT 0.071 (1.187)	DT 0.022 (1.145)	loss 6.907 (6.907)	prob 2.539 (2.539)	GS 32.062 (32.062)	mem 39.950
Train: [38][500/750]	BT 0.073 (1.178)	DT 0.009 (1.136)	loss 6.798 (6.798)	prob 2.790 (2.790)	GS 30.438 (30.438)	mem 39.952
Train: [38][505/750]	BT 0.070 (1.167)	DT 0.002 (1.124)	loss 6.816 (6.816)	prob 2.985 (2.985)	GS 29.344 (29.344)	mem 40.004
Train: [38][510/750]	BT 0.051 (1.178)	DT 0.004 (1.136)	loss 6.867 (6.867)	prob 3.088 (3.088)	GS 32.781 (32.781)	mem 40.060
Train: [38][515/750]	BT 0.050 (1.168)	DT 0.009 (1.125)	loss 6.750 (6.750)	prob 2.631 (2.631)	GS 28.375 (28.375)	mem 39.919
Train: [38][520/750]	BT 2.861 (1.176)	DT 2.826 (1.133)	loss 6.745 (6.745)	prob 2.509 (2.509)	GS 28.719 (28.719)	mem 39.953
Train: [38][525/750]	BT 0.053 (1.165)	DT 0.012 (1.123)	loss 6.865 (6.865)	prob 2.384 (2.384)	GS 35.172 (35.172)	mem 39.954
Train: [38][530/750]	BT 9.920 (1.174)	DT 9.868 (1.132)	loss 6.991 (6.991)	prob 1.662 (1.662)	GS 32.969 (32.969)	mem 40.128
Train: [38][535/750]	BT 0.064 (1.164)	DT 0.013 (1.121)	loss 7.026 (7.026)	prob 2.443 (2.443)	GS 28.281 (28.281)	mem 39.937
Train: [38][540/750]	BT 1.741 (1.163)	DT 1.704 (1.120)	loss 6.725 (6.725)	prob 3.152 (3.152)	GS 29.703 (29.703)	mem 39.915
Train: [38][545/750]	BT 0.040 (1.171)	DT 0.001 (1.128)	loss 6.827 (6.827)	prob 2.414 (2.414)	GS 32.906 (32.906)	mem 39.950
Train: [38][550/750]	BT 4.376 (1.169)	DT 4.329 (1.126)	loss 7.212 (7.212)	prob 1.930 (1.930)	GS 30.719 (30.719)	mem 39.965
Train: [38][555/750]	BT 0.031 (1.173)	DT 0.001 (1.130)	loss 6.791 (6.791)	prob 2.850 (2.850)	GS 31.656 (31.656)	mem 39.972
Train: [38][560/750]	BT 0.094 (1.164)	DT 0.026 (1.120)	loss 6.703 (6.703)	prob 2.961 (2.961)	GS 35.375 (35.375)	mem 40.211
Train: [38][565/750]	BT 0.034 (1.166)	DT 0.002 (1.123)	loss 7.007 (7.007)	prob 2.832 (2.832)	GS 29.812 (29.812)	mem 39.863
Train: [38][570/750]	BT 0.046 (1.169)	DT 0.002 (1.126)	loss 6.778 (6.778)	prob 3.173 (3.173)	GS 33.406 (33.406)	mem 39.890
Train: [38][575/750]	BT 0.032 (1.171)	DT 0.001 (1.127)	loss 6.833 (6.833)	prob 3.161 (3.161)	GS 32.656 (32.656)	mem 39.932
Train: [38][580/750]	BT 0.034 (1.169)	DT 0.001 (1.126)	loss 6.986 (6.986)	prob 2.525 (2.525)	GS 30.078 (30.078)	mem 39.852
Train: [38][585/750]	BT 0.050 (1.160)	DT 0.001 (1.117)	loss 6.892 (6.892)	prob 2.168 (2.168)	GS 28.984 (28.984)	mem 39.852
Train: [38][590/750]	BT 1.661 (1.170)	DT 1.608 (1.127)	loss 6.904 (6.904)	prob 2.414 (2.414)	GS 33.938 (33.938)	mem 39.945
Train: [38][595/750]	BT 0.039 (1.166)	DT 0.002 (1.123)	loss 7.032 (7.032)	prob 2.465 (2.465)	GS 31.094 (31.094)	mem 40.020
Train: [38][600/750]	BT 0.038 (1.171)	DT 0.001 (1.128)	loss 6.787 (6.787)	prob 2.823 (2.823)	GS 31.188 (31.188)	mem 39.907
Train: [38][605/750]	BT 0.036 (1.167)	DT 0.007 (1.124)	loss 6.925 (6.925)	prob 2.024 (2.024)	GS 27.797 (27.797)	mem 39.901
Train: [38][610/750]	BT 7.148 (1.172)	DT 7.110 (1.129)	loss 6.853 (6.853)	prob 2.525 (2.525)	GS 35.594 (35.594)	mem 39.955
Train: [38][615/750]	BT 0.050 (1.171)	DT 0.017 (1.127)	loss 6.874 (6.874)	prob 2.843 (2.843)	GS 31.297 (31.297)	mem 39.923
Train: [38][620/750]	BT 0.944 (1.163)	DT 0.891 (1.120)	loss 6.866 (6.866)	prob 3.068 (3.068)	GS 35.766 (35.766)	mem 39.961
Train: [38][625/750]	BT 0.038 (1.170)	DT 0.002 (1.127)	loss 7.109 (7.109)	prob 2.352 (2.352)	GS 32.062 (32.062)	mem 39.849
Train: [38][630/750]	BT 0.059 (1.168)	DT 0.018 (1.125)	loss 6.957 (6.957)	prob 2.615 (2.615)	GS 33.422 (33.422)	mem 39.828
Train: [38][635/750]	BT 0.071 (1.165)	DT 0.026 (1.121)	loss 7.169 (7.169)	prob 2.246 (2.246)	GS 33.453 (33.453)	mem 39.819
Train: [38][640/750]	BT 1.442 (1.168)	DT 1.401 (1.124)	loss 6.799 (6.799)	prob 2.385 (2.385)	GS 30.922 (30.922)	mem 40.090
Train: [38][645/750]	BT 0.027 (1.164)	DT 0.001 (1.120)	loss 6.762 (6.762)	prob 2.236 (2.236)	GS 32.094 (32.094)	mem 39.925
Train: [38][650/750]	BT 4.765 (1.170)	DT 4.735 (1.127)	loss 6.907 (6.907)	prob 2.322 (2.322)	GS 35.109 (35.109)	mem 39.828
Train: [38][655/750]	BT 0.055 (1.171)	DT 0.013 (1.128)	loss 7.113 (7.113)	prob 2.801 (2.801)	GS 29.516 (29.516)	mem 39.924
Train: [38][660/750]	BT 0.023 (1.162)	DT 0.001 (1.119)	loss 6.868 (6.868)	prob 2.624 (2.624)	GS 32.188 (32.188)	mem 39.925
Train: [38][665/750]	BT 0.082 (1.172)	DT 0.007 (1.129)	loss 6.953 (6.953)	prob 2.716 (2.716)	GS 29.984 (29.984)	mem 40.207
Train: [38][670/750]	BT 2.822 (1.168)	DT 2.750 (1.124)	loss 7.118 (7.118)	prob 2.722 (2.722)	GS 31.609 (31.609)	mem 39.937
Train: [38][675/750]	BT 0.055 (1.169)	DT 0.001 (1.126)	loss 7.005 (7.005)	prob 2.686 (2.686)	GS 48.141 (48.141)	mem 39.912
Train: [38][680/750]	BT 0.044 (1.169)	DT 0.002 (1.126)	loss 6.709 (6.709)	prob 2.627 (2.627)	GS 28.281 (28.281)	mem 39.964
Train: [38][685/750]	BT 0.023 (1.161)	DT 0.001 (1.118)	loss 7.037 (7.037)	prob 2.692 (2.692)	GS 30.828 (30.828)	mem 39.966
Train: [38][690/750]	BT 0.035 (1.173)	DT 0.002 (1.129)	loss 6.823 (6.823)	prob 3.091 (3.091)	GS 30.953 (30.953)	mem 40.039
Train: [38][695/750]	BT 0.032 (1.165)	DT 0.001 (1.121)	loss 6.824 (6.824)	prob 2.938 (2.938)	GS 31.469 (31.469)	mem 39.921
Train: [38][700/750]	BT 2.749 (1.171)	DT 2.704 (1.127)	loss 6.844 (6.844)	prob 2.361 (2.361)	GS 30.078 (30.078)	mem 40.001
Train: [38][705/750]	BT 0.033 (1.165)	DT 0.002 (1.121)	loss 7.057 (7.057)	prob 2.608 (2.608)	GS 46.500 (46.500)	mem 39.967
Train: [38][710/750]	BT 6.369 (1.165)	DT 6.336 (1.123)	loss 6.653 (6.653)	prob 2.809 (2.809)	GS 34.281 (34.281)	mem 40.187
Train: [38][715/750]	BT 0.032 (1.171)	DT 0.001 (1.128)	loss 6.738 (6.738)	prob 2.995 (2.995)	GS 33.859 (33.859)	mem 39.964
Train: [38][720/750]	BT 0.055 (1.163)	DT 0.007 (1.120)	loss 7.063 (7.063)	prob 2.861 (2.861)	GS 29.062 (29.062)	mem 40.110
Train: [38][725/750]	BT 0.044 (1.161)	DT 0.006 (1.118)	loss 6.950 (6.950)	prob 2.523 (2.523)	GS 31.078 (31.078)	mem 40.119
Train: [38][730/750]	BT 0.067 (1.165)	DT 0.002 (1.122)	loss 6.799 (6.799)	prob 2.698 (2.698)	GS 34.375 (34.375)	mem 39.836
Train: [38][735/750]	BT 0.027 (1.158)	DT 0.001 (1.115)	loss 6.768 (6.768)	prob 2.151 (2.151)	GS 27.906 (27.906)	mem 39.737
Train: [38][740/750]	BT 0.031 (1.163)	DT 0.001 (1.120)	loss 6.718 (6.718)	prob 3.311 (3.311)	GS 29.453 (29.453)	mem 10.913
Train: [38][745/750]	BT 0.024 (1.155)	DT 0.001 (1.112)	loss 7.089 (7.089)	prob 2.727 (2.727)	GS 40.062 (40.062)	mem 10.596
Train: [38][750/750]	BT 1.789 (1.150)	DT 1.768 (1.107)	loss 6.658 (6.658)	prob 2.606 (2.606)	GS 30.500 (30.500)	mem 7.623
Train: [38][755/750]	BT 0.040 (1.143)	DT 0.002 (1.100)	loss 6.883 (6.883)	prob 2.935 (2.935)	GS 35.500 (35.500)	mem 7.623
epoch 38, total time 862.98
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [39][1/750]	BT 22.714 (22.714)	DT 22.619 (22.619)	loss 6.671 (6.671)	prob 2.882 (2.882)	GS 35.047 (35.047)	mem 38.726
Train: [39][5/750]	BT 0.054 (4.789)	DT 0.007 (4.734)	loss 7.114 (7.114)	prob 2.575 (2.575)	GS 31.656 (31.656)	mem 38.643
Train: [39][10/750]	BT 0.028 (2.457)	DT 0.001 (2.411)	loss 6.789 (6.789)	prob 3.006 (3.006)	GS 33.094 (33.094)	mem 38.804
Train: [39][15/750]	BT 0.033 (2.714)	DT 0.002 (2.667)	loss 7.031 (7.031)	prob 3.043 (3.043)	GS 44.594 (44.594)	mem 39.134
Train: [39][20/750]	BT 0.033 (2.050)	DT 0.001 (2.003)	loss 6.785 (6.785)	prob 2.830 (2.830)	GS 33.703 (33.703)	mem 39.145
Train: [39][25/750]	BT 2.193 (1.736)	DT 2.123 (1.687)	loss 6.970 (6.970)	prob 2.358 (2.358)	GS 31.250 (31.250)	mem 39.380
Train: [39][30/750]	BT 0.054 (1.871)	DT 0.011 (1.824)	loss 6.694 (6.694)	prob 3.277 (3.277)	GS 34.484 (34.484)	mem 39.560
Train: [39][35/750]	BT 0.038 (1.612)	DT 0.002 (1.564)	loss 7.055 (7.055)	prob 2.803 (2.803)	GS 28.016 (28.016)	mem 39.596
Train: [39][40/750]	BT 0.024 (1.803)	DT 0.001 (1.757)	loss 6.675 (6.675)	prob 2.860 (2.860)	GS 33.453 (33.453)	mem 39.598
Train: [39][45/750]	BT 0.035 (1.607)	DT 0.002 (1.562)	loss 6.918 (6.918)	prob 2.941 (2.941)	GS 33.688 (33.688)	mem 39.674
Train: [39][50/750]	BT 11.249 (1.675)	DT 11.193 (1.630)	loss 6.658 (6.658)	prob 3.471 (3.471)	GS 32.484 (32.484)	mem 39.659
Train: [39][55/750]	BT 0.042 (1.530)	DT 0.002 (1.485)	loss 6.946 (6.946)	prob 1.870 (1.870)	GS 33.000 (33.000)	mem 39.668
Train: [39][60/750]	BT 0.584 (1.416)	DT 0.549 (1.370)	loss 7.044 (7.044)	prob 2.367 (2.367)	GS 34.453 (34.453)	mem 39.655
Train: [39][65/750]	BT 0.047 (1.563)	DT 0.001 (1.518)	loss 6.937 (6.937)	prob 2.741 (2.741)	GS 32.203 (32.203)	mem 39.567
Train: [39][70/750]	BT 0.052 (1.457)	DT 0.002 (1.410)	loss 6.710 (6.710)	prob 2.910 (2.910)	GS 35.328 (35.328)	mem 39.611
Train: [39][75/750]	BT 0.058 (1.529)	DT 0.004 (1.482)	loss 7.029 (7.029)	prob 2.832 (2.832)	GS 28.438 (28.438)	mem 39.583
Train: [39][80/750]	BT 0.028 (1.436)	DT 0.001 (1.390)	loss 7.003 (7.003)	prob 2.756 (2.756)	GS 36.469 (36.469)	mem 39.584
Train: [39][85/750]	BT 0.039 (1.354)	DT 0.007 (1.309)	loss 6.967 (6.967)	prob 2.696 (2.696)	GS 33.781 (33.781)	mem 39.584
Train: [39][90/750]	BT 0.105 (1.444)	DT 0.002 (1.398)	loss 6.777 (6.777)	prob 2.547 (2.547)	GS 31.000 (31.000)	mem 39.696
Train: [39][95/750]	BT 0.030 (1.369)	DT 0.001 (1.324)	loss 6.739 (6.739)	prob 2.713 (2.713)	GS 28.922 (28.922)	mem 39.646
Train: [39][100/750]	BT 0.098 (1.435)	DT 0.001 (1.390)	loss 6.965 (6.965)	prob 2.429 (2.429)	GS 33.281 (33.281)	mem 39.766
Train: [39][105/750]	BT 0.045 (1.369)	DT 0.003 (1.324)	loss 7.183 (7.183)	prob 2.108 (2.108)	GS 31.047 (31.047)	mem 39.674
Train: [39][110/750]	BT 10.872 (1.408)	DT 10.847 (1.363)	loss 6.709 (6.709)	prob 3.077 (3.077)	GS 36.562 (36.562)	mem 39.698
Train: [39][115/750]	BT 0.069 (1.349)	DT 0.011 (1.304)	loss 6.940 (6.940)	prob 2.746 (2.746)	GS 33.828 (33.828)	mem 39.729
Train: [39][120/750]	BT 0.046 (1.307)	DT 0.001 (1.262)	loss 6.896 (6.896)	prob 3.981 (3.981)	GS 33.812 (33.812)	mem 39.718
Train: [39][125/750]	BT 0.069 (1.335)	DT 0.002 (1.290)	loss 6.826 (6.826)	prob 3.463 (3.463)	GS 32.594 (32.594)	mem 39.806
Train: [39][130/750]	BT 5.039 (1.325)	DT 4.992 (1.279)	loss 6.888 (6.888)	prob 3.442 (3.442)	GS 35.844 (35.844)	mem 39.687
Train: [39][135/750]	BT 0.063 (1.324)	DT 0.011 (1.278)	loss 7.325 (7.325)	prob 1.962 (1.962)	GS 30.344 (30.344)	mem 39.717
Train: [39][140/750]	BT 0.040 (1.278)	DT 0.003 (1.232)	loss 6.836 (6.836)	prob 2.503 (2.503)	GS 33.812 (33.812)	mem 39.749
Train: [39][145/750]	BT 0.071 (1.260)	DT 0.005 (1.215)	loss 6.907 (6.907)	prob 2.822 (2.822)	GS 31.219 (31.219)	mem 39.750
Train: [39][150/750]	BT 1.351 (1.272)	DT 1.321 (1.226)	loss 6.935 (6.935)	prob 2.752 (2.752)	GS 34.047 (34.047)	mem 39.775
Train: [39][155/750]	BT 0.049 (1.269)	DT 0.004 (1.224)	loss 6.729 (6.729)	prob 2.972 (2.972)	GS 34.000 (34.000)	mem 39.794
Train: [39][160/750]	BT 0.051 (1.255)	DT 0.012 (1.210)	loss 6.867 (6.867)	prob 3.007 (3.007)	GS 37.984 (37.984)	mem 39.718
Train: [39][165/750]	BT 0.083 (1.235)	DT 0.008 (1.190)	loss 7.231 (7.231)	prob 2.738 (2.738)	GS 36.875 (36.875)	mem 39.749
Train: [39][170/750]	BT 7.064 (1.273)	DT 7.019 (1.228)	loss 6.855 (6.855)	prob 2.759 (2.759)	GS 33.578 (33.578)	mem 39.891
Train: [39][175/750]	BT 0.058 (1.239)	DT 0.004 (1.193)	loss 6.854 (6.854)	prob 3.047 (3.047)	GS 32.625 (32.625)	mem 39.825
Train: [39][180/750]	BT 0.068 (1.239)	DT 0.002 (1.193)	loss 6.992 (6.992)	prob 2.958 (2.958)	GS 31.594 (31.594)	mem 39.725
Train: [39][185/750]	BT 0.035 (1.231)	DT 0.002 (1.185)	loss 6.951 (6.951)	prob 2.415 (2.415)	GS 30.984 (30.984)	mem 39.820
Train: [39][190/750]	BT 7.198 (1.246)	DT 7.150 (1.200)	loss 6.797 (6.797)	prob 2.716 (2.716)	GS 34.312 (34.312)	mem 39.810
Train: [39][195/750]	BT 0.070 (1.236)	DT 0.011 (1.190)	loss 7.047 (7.047)	prob 2.772 (2.772)	GS 25.844 (25.844)	mem 39.999
Train: [39][200/750]	BT 0.030 (1.218)	DT 0.001 (1.173)	loss 6.753 (6.753)	prob 3.060 (3.060)	GS 32.859 (32.859)	mem 39.949
Train: [39][205/750]	BT 0.070 (1.210)	DT 0.005 (1.164)	loss 6.764 (6.764)	prob 2.708 (2.708)	GS 29.484 (29.484)	mem 39.895
Train: [39][210/750]	BT 4.726 (1.214)	DT 4.691 (1.169)	loss 7.077 (7.077)	prob 2.998 (2.998)	GS 32.812 (32.812)	mem 39.907
Train: [39][215/750]	BT 0.084 (1.210)	DT 0.004 (1.164)	loss 6.851 (6.851)	prob 3.106 (3.106)	GS 31.531 (31.531)	mem 40.038
Train: [39][220/750]	BT 0.033 (1.193)	DT 0.001 (1.147)	loss 6.777 (6.777)	prob 2.715 (2.715)	GS 34.891 (34.891)	mem 40.057
Train: [39][225/750]	BT 0.085 (1.180)	DT 0.014 (1.134)	loss 6.979 (6.979)	prob 2.676 (2.676)	GS 32.438 (32.438)	mem 39.947
Train: [39][230/750]	BT 1.769 (1.192)	DT 1.691 (1.146)	loss 6.933 (6.933)	prob 3.305 (3.305)	GS 34.062 (34.062)	mem 39.938
Train: [39][235/750]	BT 0.076 (1.191)	DT 0.032 (1.144)	loss 7.136 (7.136)	prob 2.991 (2.991)	GS 33.375 (33.375)	mem 39.893
Train: [39][240/750]	BT 0.041 (1.196)	DT 0.006 (1.149)	loss 6.926 (6.926)	prob 3.142 (3.142)	GS 29.828 (29.828)	mem 39.851
Train: [39][245/750]	BT 0.064 (1.173)	DT 0.001 (1.126)	loss 6.849 (6.849)	prob 2.654 (2.654)	GS 34.078 (34.078)	mem 39.849
Train: [39][250/750]	BT 9.078 (1.210)	DT 9.043 (1.162)	loss 6.818 (6.818)	prob 2.873 (2.873)	GS 35.828 (35.828)	mem 39.952
Train: [39][255/750]	BT 0.034 (1.187)	DT 0.001 (1.140)	loss 6.810 (6.810)	prob 3.132 (3.132)	GS 30.750 (30.750)	mem 39.960
Train: [39][260/750]	BT 0.032 (1.165)	DT 0.001 (1.118)	loss 6.876 (6.876)	prob 2.889 (2.889)	GS 34.500 (34.500)	mem 39.962
Train: [39][265/750]	BT 0.058 (1.200)	DT 0.002 (1.153)	loss 6.980 (6.980)	prob 3.379 (3.379)	GS 31.453 (31.453)	mem 39.775
Train: [39][270/750]	BT 0.049 (1.178)	DT 0.008 (1.131)	loss 6.989 (6.989)	prob 3.186 (3.186)	GS 34.938 (34.938)	mem 39.776
Train: [39][275/750]	BT 0.034 (1.206)	DT 0.008 (1.159)	loss 6.696 (6.696)	prob 3.341 (3.341)	GS 30.906 (30.906)	mem 39.861
Train: [39][280/750]	BT 0.042 (1.185)	DT 0.003 (1.139)	loss 7.154 (7.154)	prob 3.134 (3.134)	GS 34.469 (34.469)	mem 39.861
Train: [39][285/750]	BT 0.093 (1.165)	DT 0.005 (1.119)	loss 6.944 (6.944)	prob 3.075 (3.075)	GS 33.844 (33.844)	mem 39.862
Train: [39][290/750]	BT 0.049 (1.193)	DT 0.009 (1.146)	loss 7.069 (7.069)	prob 2.470 (2.470)	GS 37.594 (37.594)	mem 39.875
Train: [39][295/750]	BT 0.059 (1.173)	DT 0.018 (1.127)	loss 6.938 (6.938)	prob 3.042 (3.042)	GS 31.141 (31.141)	mem 39.875
Train: [39][300/750]	BT 0.029 (1.191)	DT 0.001 (1.145)	loss 6.941 (6.941)	prob 3.444 (3.444)	GS 34.312 (34.312)	mem 39.936
Train: [39][305/750]	BT 0.040 (1.172)	DT 0.002 (1.126)	loss 6.920 (6.920)	prob 3.090 (3.090)	GS 31.906 (31.906)	mem 40.061
Train: [39][310/750]	BT 12.248 (1.194)	DT 12.212 (1.147)	loss 7.327 (7.327)	prob 2.756 (2.756)	GS 37.281 (37.281)	mem 39.941
Train: [39][315/750]	BT 0.050 (1.177)	DT 0.002 (1.129)	loss 7.178 (7.178)	prob 2.847 (2.847)	GS 31.328 (31.328)	mem 40.054
Train: [39][320/750]	BT 2.358 (1.166)	DT 2.319 (1.119)	loss 6.661 (6.661)	prob 3.144 (3.144)	GS 36.203 (36.203)	mem 40.004
Train: [39][325/750]	BT 0.052 (1.175)	DT 0.008 (1.128)	loss 7.014 (7.014)	prob 2.847 (2.847)	GS 44.172 (44.172)	mem 39.920
Train: [39][330/750]	BT 0.049 (1.166)	DT 0.001 (1.119)	loss 6.906 (6.906)	prob 2.755 (2.755)	GS 32.594 (32.594)	mem 39.938
Train: [39][335/750]	BT 0.028 (1.176)	DT 0.001 (1.129)	loss 6.942 (6.942)	prob 3.042 (3.042)	GS 36.297 (36.297)	mem 39.970
Train: [39][340/750]	BT 0.031 (1.183)	DT 0.001 (1.136)	loss 6.952 (6.952)	prob 2.945 (2.945)	GS 34.234 (34.234)	mem 39.980
Train: [39][345/750]	BT 0.055 (1.167)	DT 0.004 (1.120)	loss 7.093 (7.093)	prob 2.634 (2.634)	GS 30.766 (30.766)	mem 39.963
Train: [39][350/750]	BT 9.135 (1.182)	DT 9.026 (1.135)	loss 6.967 (6.967)	prob 2.427 (2.427)	GS 33.688 (33.688)	mem 40.272
Train: [39][355/750]	BT 0.040 (1.166)	DT 0.010 (1.119)	loss 7.035 (7.035)	prob 2.665 (2.665)	GS 32.562 (32.562)	mem 39.969
Train: [39][360/750]	BT 0.033 (1.162)	DT 0.002 (1.116)	loss 6.785 (6.785)	prob 2.912 (2.912)	GS 34.328 (34.328)	mem 40.044
Train: [39][365/750]	BT 0.031 (1.174)	DT 0.001 (1.127)	loss 7.190 (7.190)	prob 2.001 (2.001)	GS 32.969 (32.969)	mem 39.968
Train: [39][370/750]	BT 9.530 (1.184)	DT 9.498 (1.137)	loss 6.957 (6.957)	prob 3.179 (3.179)	GS 34.703 (34.703)	mem 39.972
Train: [39][375/750]	BT 0.045 (1.175)	DT 0.011 (1.129)	loss 6.876 (6.876)	prob 2.998 (2.998)	GS 35.516 (35.516)	mem 40.003
Train: [39][380/750]	BT 0.039 (1.160)	DT 0.001 (1.114)	loss 7.043 (7.043)	prob 2.021 (2.021)	GS 34.312 (34.312)	mem 40.160
Train: [39][385/750]	BT 0.022 (1.180)	DT 0.001 (1.134)	loss 6.841 (6.841)	prob 3.184 (3.184)	GS 28.594 (28.594)	mem 39.976
Train: [39][390/750]	BT 0.025 (1.166)	DT 0.001 (1.120)	loss 6.918 (6.918)	prob 2.498 (2.498)	GS 30.250 (30.250)	mem 39.978
Train: [39][395/750]	BT 0.024 (1.185)	DT 0.001 (1.139)	loss 6.973 (6.973)	prob 2.759 (2.759)	GS 28.594 (28.594)	mem 39.992
Train: [39][400/750]	BT 0.049 (1.171)	DT 0.002 (1.125)	loss 6.789 (6.789)	prob 3.022 (3.022)	GS 36.281 (36.281)	mem 39.994
Train: [39][405/750]	BT 0.088 (1.157)	DT 0.013 (1.111)	loss 6.979 (6.979)	prob 2.920 (2.920)	GS 31.469 (31.469)	mem 39.996
Train: [39][410/750]	BT 0.251 (1.176)	DT 0.197 (1.129)	loss 6.943 (6.943)	prob 2.406 (2.406)	GS 36.375 (36.375)	mem 39.985
Train: [39][415/750]	BT 0.043 (1.162)	DT 0.003 (1.116)	loss 7.118 (7.118)	prob 1.818 (1.818)	GS 30.703 (30.703)	mem 39.897
Train: [39][420/750]	BT 0.070 (1.181)	DT 0.001 (1.135)	loss 6.860 (6.860)	prob 2.800 (2.800)	GS 30.188 (30.188)	mem 40.009
Train: [39][425/750]	BT 0.103 (1.169)	DT 0.021 (1.122)	loss 6.904 (6.904)	prob 2.388 (2.388)	GS 28.047 (28.047)	mem 39.975
Train: [39][430/750]	BT 16.188 (1.193)	DT 16.155 (1.147)	loss 6.867 (6.867)	prob 2.581 (2.581)	GS 36.266 (36.266)	mem 39.988
Train: [39][435/750]	BT 0.024 (1.180)	DT 0.001 (1.134)	loss 6.934 (6.934)	prob 2.608 (2.608)	GS 31.797 (31.797)	mem 39.989
Train: [39][440/750]	BT 0.064 (1.167)	DT 0.003 (1.121)	loss 6.905 (6.905)	prob 2.760 (2.760)	GS 34.188 (34.188)	mem 39.988
Train: [39][445/750]	BT 0.023 (1.183)	DT 0.001 (1.137)	loss 6.836 (6.836)	prob 2.997 (2.997)	GS 30.516 (30.516)	mem 40.005
Train: [39][450/750]	BT 0.026 (1.170)	DT 0.001 (1.124)	loss 6.935 (6.935)	prob 2.461 (2.461)	GS 31.922 (31.922)	mem 40.053
Train: [39][455/750]	BT 0.049 (1.189)	DT 0.007 (1.143)	loss 6.997 (6.997)	prob 2.804 (2.804)	GS 28.891 (28.891)	mem 39.924
Train: [39][460/750]	BT 0.044 (1.176)	DT 0.009 (1.130)	loss 6.792 (6.792)	prob 2.588 (2.588)	GS 31.109 (31.109)	mem 39.926
Train: [39][465/750]	BT 0.027 (1.164)	DT 0.001 (1.118)	loss 6.767 (6.767)	prob 2.588 (2.588)	GS 32.656 (32.656)	mem 40.038
Train: [39][470/750]	BT 0.029 (1.175)	DT 0.001 (1.129)	loss 7.025 (7.025)	prob 2.145 (2.145)	GS 31.703 (31.703)	mem 40.005
Train: [39][475/750]	BT 0.047 (1.163)	DT 0.002 (1.117)	loss 7.063 (7.063)	prob 2.899 (2.899)	GS 31.469 (31.469)	mem 40.005
Train: [39][480/750]	BT 0.042 (1.176)	DT 0.003 (1.130)	loss 6.792 (6.792)	prob 3.126 (3.126)	GS 31.453 (31.453)	mem 40.138
Train: [39][485/750]	BT 0.033 (1.164)	DT 0.001 (1.119)	loss 6.926 (6.926)	prob 2.739 (2.739)	GS 28.547 (28.547)	mem 40.031
Train: [39][490/750]	BT 11.124 (1.175)	DT 11.092 (1.130)	loss 6.862 (6.862)	prob 2.635 (2.635)	GS 33.297 (33.297)	mem 40.025
Train: [39][495/750]	BT 0.029 (1.164)	DT 0.001 (1.118)	loss 6.823 (6.823)	prob 3.042 (3.042)	GS 32.906 (32.906)	mem 40.027
Train: [39][500/750]	BT 0.029 (1.153)	DT 0.001 (1.107)	loss 6.781 (6.781)	prob 2.363 (2.363)	GS 36.312 (36.312)	mem 40.027
Train: [39][505/750]	BT 0.040 (1.168)	DT 0.012 (1.123)	loss 7.190 (7.190)	prob 2.621 (2.621)	GS 30.406 (30.406)	mem 40.030
Train: [39][510/750]	BT 0.036 (1.157)	DT 0.002 (1.112)	loss 6.915 (6.915)	prob 3.338 (3.338)	GS 30.625 (30.625)	mem 40.030
Train: [39][515/750]	BT 0.034 (1.170)	DT 0.001 (1.125)	loss 6.952 (6.952)	prob 2.317 (2.317)	GS 29.000 (29.000)	mem 40.037
Train: [39][520/750]	BT 0.040 (1.160)	DT 0.002 (1.115)	loss 7.039 (7.039)	prob 2.525 (2.525)	GS 35.656 (35.656)	mem 40.038
Train: [39][525/750]	BT 0.041 (1.149)	DT 0.003 (1.104)	loss 6.946 (6.946)	prob 2.748 (2.748)	GS 34.016 (34.016)	mem 40.038
Train: [39][530/750]	BT 0.691 (1.157)	DT 0.615 (1.112)	loss 6.991 (6.991)	prob 2.500 (2.500)	GS 36.016 (36.016)	mem 40.345
Train: [39][535/750]	BT 0.074 (1.147)	DT 0.009 (1.102)	loss 6.981 (6.981)	prob 2.733 (2.733)	GS 27.938 (27.938)	mem 40.509
Train: [39][540/750]	BT 0.057 (1.159)	DT 0.012 (1.114)	loss 7.007 (7.007)	prob 2.856 (2.856)	GS 29.031 (29.031)	mem 40.118
Train: [39][545/750]	BT 0.071 (1.151)	DT 0.013 (1.105)	loss 6.918 (6.918)	prob 2.898 (2.898)	GS 30.656 (30.656)	mem 40.143
Train: [39][550/750]	BT 15.421 (1.169)	DT 15.369 (1.123)	loss 6.741 (6.741)	prob 2.744 (2.744)	GS 34.156 (34.156)	mem 39.915
Train: [39][555/750]	BT 0.033 (1.159)	DT 0.002 (1.113)	loss 6.760 (6.760)	prob 3.092 (3.092)	GS 38.328 (38.328)	mem 39.917
Train: [39][560/750]	BT 0.067 (1.149)	DT 0.007 (1.103)	loss 6.811 (6.811)	prob 2.901 (2.901)	GS 34.234 (34.234)	mem 39.970
Train: [39][565/750]	BT 0.032 (1.160)	DT 0.001 (1.114)	loss 7.053 (7.053)	prob 2.392 (2.392)	GS 32.062 (32.062)	mem 39.986
Train: [39][570/750]	BT 0.033 (1.150)	DT 0.002 (1.105)	loss 6.755 (6.755)	prob 2.675 (2.675)	GS 34.672 (34.672)	mem 39.988
Train: [39][575/750]	BT 0.045 (1.160)	DT 0.014 (1.115)	loss 6.751 (6.751)	prob 2.953 (2.953)	GS 31.953 (31.953)	mem 39.963
Train: [39][580/750]	BT 0.036 (1.156)	DT 0.003 (1.111)	loss 6.762 (6.762)	prob 2.658 (2.658)	GS 28.016 (28.016)	mem 40.020
Train: [39][585/750]	BT 0.033 (1.147)	DT 0.001 (1.102)	loss 7.353 (7.353)	prob 2.240 (2.240)	GS 30.453 (30.453)	mem 40.120
Train: [39][590/750]	BT 3.598 (1.161)	DT 3.563 (1.116)	loss 6.936 (6.936)	prob 2.239 (2.239)	GS 35.641 (35.641)	mem 40.041
Train: [39][595/750]	BT 0.048 (1.151)	DT 0.008 (1.106)	loss 7.157 (7.157)	prob 2.404 (2.404)	GS 28.922 (28.922)	mem 40.074
Train: [39][600/750]	BT 0.042 (1.152)	DT 0.004 (1.107)	loss 6.747 (6.747)	prob 3.042 (3.042)	GS 37.719 (37.719)	mem 40.074
Train: [39][605/750]	BT 0.042 (1.155)	DT 0.002 (1.110)	loss 6.844 (6.844)	prob 2.694 (2.694)	GS 35.438 (35.438)	mem 40.041
Train: [39][610/750]	BT 1.778 (1.149)	DT 1.749 (1.104)	loss 7.094 (7.094)	prob 2.748 (2.748)	GS 31.328 (31.328)	mem 40.038
Train: [39][615/750]	BT 0.057 (1.161)	DT 0.015 (1.116)	loss 6.823 (6.823)	prob 2.936 (2.936)	GS 31.000 (31.000)	mem 40.041
Train: [39][620/750]	BT 0.056 (1.152)	DT 0.010 (1.107)	loss 6.810 (6.810)	prob 2.373 (2.373)	GS 35.828 (35.828)	mem 39.991
Train: [39][625/750]	BT 0.072 (1.143)	DT 0.003 (1.098)	loss 7.006 (7.006)	prob 2.724 (2.724)	GS 32.781 (32.781)	mem 40.009
Train: [39][630/750]	BT 0.028 (1.155)	DT 0.001 (1.111)	loss 6.715 (6.715)	prob 3.199 (3.199)	GS 33.594 (33.594)	mem 40.081
Train: [39][635/750]	BT 0.034 (1.147)	DT 0.001 (1.102)	loss 6.995 (6.995)	prob 2.555 (2.555)	GS 31.125 (31.125)	mem 40.013
Train: [39][640/750]	BT 0.021 (1.159)	DT 0.001 (1.115)	loss 6.798 (6.798)	prob 3.512 (3.512)	GS 34.469 (34.469)	mem 39.959
Train: [39][645/750]	BT 0.029 (1.151)	DT 0.001 (1.106)	loss 6.918 (6.918)	prob 2.996 (2.996)	GS 29.062 (29.062)	mem 39.997
Train: [39][650/750]	BT 12.754 (1.162)	DT 12.717 (1.117)	loss 6.715 (6.715)	prob 2.860 (2.860)	GS 34.578 (34.578)	mem 39.890
Train: [39][655/750]	BT 0.046 (1.153)	DT 0.005 (1.109)	loss 7.102 (7.102)	prob 1.915 (1.915)	GS 31.000 (31.000)	mem 39.892
arpack error, retry= 0
Train: [39][660/750]	BT 0.091 (1.145)	DT 0.018 (1.100)	loss 6.685 (6.685)	prob 2.495 (2.495)	GS 33.984 (33.984)	mem 39.895
Train: [39][665/750]	BT 0.046 (1.155)	DT 0.001 (1.110)	loss 6.974 (6.974)	prob 3.065 (3.065)	GS 34.312 (34.312)	mem 40.002
Train: [39][670/750]	BT 0.086 (1.146)	DT 0.007 (1.102)	loss 6.840 (6.840)	prob 2.774 (2.774)	GS 33.484 (33.484)	mem 40.001
Train: [39][675/750]	BT 0.025 (1.157)	DT 0.001 (1.113)	loss 7.226 (7.226)	prob 2.758 (2.758)	GS 34.109 (34.109)	mem 40.003
Train: [39][680/750]	BT 0.022 (1.149)	DT 0.001 (1.105)	loss 7.087 (7.087)	prob 2.395 (2.395)	GS 32.578 (32.578)	mem 39.974
Train: [39][685/750]	BT 0.109 (1.141)	DT 0.005 (1.097)	loss 6.832 (6.832)	prob 3.326 (3.326)	GS 34.188 (34.188)	mem 40.020
Train: [39][690/750]	BT 0.021 (1.150)	DT 0.001 (1.106)	loss 6.750 (6.750)	prob 3.184 (3.184)	GS 37.453 (37.453)	mem 39.930
Train: [39][695/750]	BT 0.089 (1.142)	DT 0.027 (1.098)	loss 7.019 (7.019)	prob 2.757 (2.757)	GS 27.516 (27.516)	mem 40.002
Train: [39][700/750]	BT 0.030 (1.152)	DT 0.001 (1.108)	loss 6.835 (6.835)	prob 2.844 (2.844)	GS 36.906 (36.906)	mem 39.977
Train: [39][705/750]	BT 0.045 (1.144)	DT 0.002 (1.100)	loss 6.860 (6.860)	prob 3.494 (3.494)	GS 30.297 (30.297)	mem 39.979
Train: [39][710/750]	BT 12.651 (1.154)	DT 12.610 (1.110)	loss 6.810 (6.810)	prob 3.491 (3.491)	GS 29.938 (29.938)	mem 40.017
Train: [39][715/750]	BT 0.044 (1.146)	DT 0.011 (1.102)	loss 6.886 (6.886)	prob 2.625 (2.625)	GS 34.203 (34.203)	mem 39.970
Train: [39][720/750]	BT 0.049 (1.139)	DT 0.002 (1.095)	loss 7.041 (7.041)	prob 2.871 (2.871)	GS 36.141 (36.141)	mem 39.970
Train: [39][725/750]	BT 0.021 (1.150)	DT 0.001 (1.106)	loss 7.246 (7.246)	prob 2.769 (2.769)	GS 29.625 (29.625)	mem 39.915
Train: [39][730/750]	BT 0.143 (1.143)	DT 0.011 (1.099)	loss 6.685 (6.685)	prob 3.102 (3.102)	GS 32.469 (32.469)	mem 39.915
Train: [39][735/750]	BT 0.032 (1.149)	DT 0.001 (1.105)	loss 7.043 (7.043)	prob 2.982 (2.982)	GS 29.359 (29.359)	mem 36.476
Train: [39][740/750]	BT 0.026 (1.141)	DT 0.001 (1.097)	loss 7.050 (7.050)	prob 2.885 (2.885)	GS 33.266 (33.266)	mem 36.477
Train: [39][745/750]	BT 0.025 (1.134)	DT 0.001 (1.090)	loss 6.992 (6.992)	prob 2.579 (2.579)	GS 39.969 (39.969)	mem 36.476
Train: [39][750/750]	BT 0.038 (1.128)	DT 0.001 (1.085)	loss 6.604 (6.604)	prob 2.879 (2.879)	GS 38.125 (38.125)	mem 7.574
Train: [39][755/750]	BT 0.032 (1.121)	DT 0.001 (1.077)	loss 6.525 (6.525)	prob 2.891 (2.891)	GS 33.719 (33.719)	mem 7.574
epoch 39, total time 846.73
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [40][1/750]	BT 21.194 (21.194)	DT 21.132 (21.132)	loss 6.861 (6.861)	prob 2.957 (2.957)	GS 31.328 (31.328)	mem 38.584
Train: [40][5/750]	BT 0.052 (4.968)	DT 0.002 (4.923)	loss 6.975 (6.975)	prob 3.134 (3.134)	GS 33.344 (33.344)	mem 38.517
Train: [40][10/750]	BT 0.056 (2.510)	DT 0.001 (2.464)	loss 6.825 (6.825)	prob 2.507 (2.507)	GS 35.531 (35.531)	mem 38.567
Train: [40][15/750]	BT 0.043 (2.419)	DT 0.001 (2.376)	loss 6.844 (6.844)	prob 2.421 (2.421)	GS 30.984 (30.984)	mem 38.746
Train: [40][20/750]	BT 0.052 (2.010)	DT 0.002 (1.968)	loss 6.622 (6.622)	prob 2.940 (2.940)	GS 34.281 (34.281)	mem 38.826
Train: [40][25/750]	BT 0.107 (1.623)	DT 0.048 (1.577)	loss 6.870 (6.870)	prob 2.834 (2.834)	GS 30.297 (30.297)	mem 38.778
Train: [40][30/750]	BT 3.036 (1.855)	DT 3.011 (1.811)	loss 6.685 (6.685)	prob 3.459 (3.459)	GS 33.953 (33.953)	mem 38.965
Train: [40][35/750]	BT 0.037 (1.595)	DT 0.001 (1.552)	loss 6.725 (6.725)	prob 3.066 (3.066)	GS 28.250 (28.250)	mem 38.891
Train: [40][40/750]	BT 1.140 (1.647)	DT 1.105 (1.600)	loss 6.706 (6.706)	prob 3.361 (3.361)	GS 36.766 (36.766)	mem 39.041
Train: [40][45/750]	BT 0.071 (1.603)	DT 0.001 (1.557)	loss 6.906 (6.906)	prob 3.059 (3.059)	GS 34.859 (34.859)	mem 38.964
Train: [40][50/750]	BT 7.229 (1.592)	DT 7.198 (1.546)	loss 6.744 (6.744)	prob 2.902 (2.902)	GS 31.969 (31.969)	mem 38.983
Train: [40][55/750]	BT 0.040 (1.467)	DT 0.002 (1.422)	loss 6.974 (6.974)	prob 2.985 (2.985)	GS 26.672 (26.672)	mem 38.985
Train: [40][60/750]	BT 0.032 (1.350)	DT 0.002 (1.304)	loss 6.804 (6.804)	prob 2.390 (2.390)	GS 33.984 (33.984)	mem 38.985
Train: [40][65/750]	BT 0.032 (1.441)	DT 0.002 (1.396)	loss 7.062 (7.062)	prob 2.859 (2.859)	GS 33.312 (33.312)	mem 38.992
Train: [40][70/750]	BT 0.044 (1.379)	DT 0.013 (1.334)	loss 6.834 (6.834)	prob 2.730 (2.730)	GS 35.953 (35.953)	mem 39.017
Train: [40][75/750]	BT 0.023 (1.338)	DT 0.001 (1.294)	loss 6.782 (6.782)	prob 3.133 (3.133)	GS 32.203 (32.203)	mem 39.028
Train: [40][80/750]	BT 0.028 (1.387)	DT 0.001 (1.343)	loss 7.005 (7.005)	prob 2.401 (2.401)	GS 32.734 (32.734)	mem 39.073
Train: [40][85/750]	BT 0.100 (1.310)	DT 0.013 (1.265)	loss 6.848 (6.848)	prob 2.893 (2.893)	GS 28.000 (28.000)	mem 39.026
Train: [40][90/750]	BT 4.792 (1.356)	DT 4.742 (1.311)	loss 6.804 (6.804)	prob 3.138 (3.138)	GS 31.531 (31.531)	mem 39.028
Train: [40][95/750]	BT 0.065 (1.288)	DT 0.009 (1.242)	loss 7.133 (7.133)	prob 2.229 (2.229)	GS 41.422 (41.422)	mem 39.144
Train: [40][100/750]	BT 4.649 (1.289)	DT 4.618 (1.243)	loss 6.784 (6.784)	prob 3.057 (3.057)	GS 30.406 (30.406)	mem 39.080
Train: [40][105/750]	BT 0.067 (1.340)	DT 0.001 (1.295)	loss 7.018 (7.018)	prob 2.859 (2.859)	GS 29.156 (29.156)	mem 39.228
Train: [40][110/750]	BT 0.054 (1.282)	DT 0.017 (1.236)	loss 6.746 (6.746)	prob 3.126 (3.126)	GS 37.578 (37.578)	mem 39.136
Train: [40][115/750]	BT 0.032 (1.334)	DT 0.002 (1.288)	loss 7.126 (7.126)	prob 2.449 (2.449)	GS 39.109 (39.109)	mem 39.145
Train: [40][120/750]	BT 0.022 (1.279)	DT 0.001 (1.235)	loss 6.788 (6.788)	prob 3.063 (3.063)	GS 36.172 (36.172)	mem 39.147
Train: [40][125/750]	BT 0.026 (1.229)	DT 0.001 (1.185)	loss 6.841 (6.841)	prob 2.719 (2.719)	GS 31.891 (31.891)	mem 39.148
Train: [40][130/750]	BT 0.030 (1.303)	DT 0.002 (1.259)	loss 6.995 (6.995)	prob 2.952 (2.952)	GS 31.609 (31.609)	mem 39.197
Train: [40][135/750]	BT 0.042 (1.256)	DT 0.002 (1.212)	loss 6.971 (6.971)	prob 2.216 (2.216)	GS 31.266 (31.266)	mem 39.365
Train: [40][140/750]	BT 0.083 (1.307)	DT 0.016 (1.264)	loss 6.814 (6.814)	prob 2.727 (2.727)	GS 35.500 (35.500)	mem 39.524
Train: [40][145/750]	BT 0.033 (1.265)	DT 0.002 (1.220)	loss 6.979 (6.979)	prob 2.444 (2.444)	GS 35.594 (35.594)	mem 39.177
Train: [40][150/750]	BT 15.085 (1.324)	DT 15.036 (1.280)	loss 6.875 (6.875)	prob 3.054 (3.054)	GS 36.250 (36.250)	mem 39.251
Train: [40][155/750]	BT 0.034 (1.283)	DT 0.002 (1.239)	loss 6.931 (6.931)	prob 2.380 (2.380)	GS 32.391 (32.391)	mem 39.417
Train: [40][160/750]	BT 0.051 (1.244)	DT 0.001 (1.200)	loss 6.790 (6.790)	prob 3.170 (3.170)	GS 31.078 (31.078)	mem 39.410
Train: [40][165/750]	BT 0.030 (1.276)	DT 0.001 (1.233)	loss 6.995 (6.995)	prob 2.893 (2.893)	GS 36.250 (36.250)	mem 39.264
Train: [40][170/750]	BT 0.040 (1.240)	DT 0.002 (1.197)	loss 6.880 (6.880)	prob 3.023 (3.023)	GS 34.344 (34.344)	mem 39.264
Train: [40][175/750]	BT 0.051 (1.301)	DT 0.014 (1.258)	loss 6.996 (6.996)	prob 2.149 (2.149)	GS 29.703 (29.703)	mem 39.253
Train: [40][180/750]	BT 0.047 (1.266)	DT 0.010 (1.223)	loss 6.697 (6.697)	prob 2.475 (2.475)	GS 37.625 (37.625)	mem 39.104
Train: [40][185/750]	BT 0.051 (1.233)	DT 0.001 (1.190)	loss 7.033 (7.033)	prob 2.534 (2.534)	GS 37.359 (37.359)	mem 39.104
Train: [40][190/750]	BT 0.034 (1.266)	DT 0.001 (1.224)	loss 7.042 (7.042)	prob 2.520 (2.520)	GS 32.453 (32.453)	mem 39.309
Train: [40][195/750]	BT 0.040 (1.235)	DT 0.008 (1.193)	loss 7.117 (7.117)	prob 2.857 (2.857)	GS 28.578 (28.578)	mem 39.310
Train: [40][200/750]	BT 0.031 (1.267)	DT 0.003 (1.225)	loss 6.746 (6.746)	prob 2.940 (2.940)	GS 31.375 (31.375)	mem 39.431
Train: [40][205/750]	BT 0.036 (1.236)	DT 0.002 (1.195)	loss 6.680 (6.680)	prob 2.643 (2.643)	GS 32.453 (32.453)	mem 39.445
Train: [40][210/750]	BT 11.632 (1.263)	DT 11.600 (1.222)	loss 6.960 (6.960)	prob 2.389 (2.389)	GS 36.141 (36.141)	mem 39.575
Train: [40][215/750]	BT 0.036 (1.235)	DT 0.004 (1.193)	loss 6.750 (6.750)	prob 3.169 (3.169)	GS 31.359 (31.359)	mem 39.585
Train: [40][220/750]	BT 0.064 (1.208)	DT 0.010 (1.166)	loss 7.038 (7.038)	prob 2.049 (2.049)	GS 30.641 (30.641)	mem 39.586
Train: [40][225/750]	BT 0.055 (1.246)	DT 0.010 (1.204)	loss 6.869 (6.869)	prob 2.993 (2.993)	GS 28.875 (28.875)	mem 39.584
Train: [40][230/750]	BT 0.023 (1.220)	DT 0.001 (1.178)	loss 6.723 (6.723)	prob 2.865 (2.865)	GS 33.594 (33.594)	mem 39.591
Train: [40][235/750]	BT 0.024 (1.252)	DT 0.001 (1.211)	loss 6.689 (6.689)	prob 2.700 (2.700)	GS 29.359 (29.359)	mem 39.647
Train: [40][240/750]	BT 0.024 (1.227)	DT 0.002 (1.186)	loss 6.756 (6.756)	prob 2.478 (2.478)	GS 35.250 (35.250)	mem 39.648
Train: [40][245/750]	BT 0.082 (1.203)	DT 0.003 (1.162)	loss 6.909 (6.909)	prob 2.593 (2.593)	GS 34.922 (34.922)	mem 39.648
Train: [40][250/750]	BT 0.040 (1.215)	DT 0.001 (1.172)	loss 6.879 (6.879)	prob 2.444 (2.444)	GS 30.125 (30.125)	mem 39.596
Train: [40][255/750]	BT 0.032 (1.191)	DT 0.001 (1.149)	loss 6.794 (6.794)	prob 2.411 (2.411)	GS 28.672 (28.672)	mem 39.596
Train: [40][260/750]	BT 0.060 (1.215)	DT 0.002 (1.173)	loss 6.867 (6.867)	prob 2.498 (2.498)	GS 36.000 (36.000)	mem 39.814
Train: [40][265/750]	BT 0.033 (1.193)	DT 0.001 (1.151)	loss 6.748 (6.748)	prob 2.756 (2.756)	GS 37.094 (37.094)	mem 39.654
Train: [40][270/750]	BT 14.466 (1.225)	DT 14.426 (1.183)	loss 6.758 (6.758)	prob 2.673 (2.673)	GS 34.969 (34.969)	mem 39.718
Train: [40][275/750]	BT 0.031 (1.204)	DT 0.001 (1.162)	loss 6.796 (6.796)	prob 2.861 (2.861)	GS 35.344 (35.344)	mem 39.718
Train: [40][280/750]	BT 0.054 (1.183)	DT 0.002 (1.141)	loss 6.806 (6.806)	prob 2.256 (2.256)	GS 35.500 (35.500)	mem 39.718
Train: [40][285/750]	BT 0.042 (1.196)	DT 0.001 (1.154)	loss 6.955 (6.955)	prob 2.821 (2.821)	GS 28.891 (28.891)	mem 39.879
Train: [40][290/750]	BT 0.077 (1.177)	DT 0.009 (1.135)	loss 6.769 (6.769)	prob 2.810 (2.810)	GS 31.062 (31.062)	mem 40.089
Train: [40][295/750]	BT 0.061 (1.218)	DT 0.030 (1.175)	loss 6.814 (6.814)	prob 3.173 (3.173)	GS 30.422 (30.422)	mem 39.863
Train: [40][300/750]	BT 0.030 (1.198)	DT 0.001 (1.156)	loss 6.744 (6.744)	prob 2.913 (2.913)	GS 34.547 (34.547)	mem 39.830
Train: [40][305/750]	BT 0.119 (1.179)	DT 0.003 (1.137)	loss 6.791 (6.791)	prob 2.643 (2.643)	GS 28.016 (28.016)	mem 40.109
Train: [40][310/750]	BT 0.031 (1.204)	DT 0.001 (1.161)	loss 6.725 (6.725)	prob 3.027 (3.027)	GS 34.344 (34.344)	mem 39.906
Train: [40][315/750]	BT 0.045 (1.185)	DT 0.002 (1.143)	loss 6.950 (6.950)	prob 2.713 (2.713)	GS 26.984 (26.984)	mem 40.064
Train: [40][320/750]	BT 0.033 (1.206)	DT 0.001 (1.163)	loss 6.768 (6.768)	prob 2.424 (2.424)	GS 34.641 (34.641)	mem 40.029
Train: [40][325/750]	BT 0.044 (1.193)	DT 0.002 (1.151)	loss 6.677 (6.677)	prob 2.981 (2.981)	GS 31.781 (31.781)	mem 39.893
Train: [40][330/750]	BT 11.496 (1.210)	DT 11.463 (1.168)	loss 7.081 (7.081)	prob 2.424 (2.424)	GS 33.609 (33.609)	mem 39.961
Train: [40][335/750]	BT 0.034 (1.196)	DT 0.003 (1.154)	loss 6.732 (6.732)	prob 2.419 (2.419)	GS 32.188 (32.188)	mem 39.903
Train: [40][340/750]	BT 0.031 (1.182)	DT 0.001 (1.139)	loss 6.703 (6.703)	prob 3.012 (3.012)	GS 34.828 (34.828)	mem 39.913
Train: [40][345/750]	BT 0.060 (1.192)	DT 0.024 (1.150)	loss 6.591 (6.591)	prob 3.174 (3.174)	GS 32.547 (32.547)	mem 39.907
Train: [40][350/750]	BT 0.036 (1.184)	DT 0.001 (1.142)	loss 7.088 (7.088)	prob 2.378 (2.378)	GS 33.953 (33.953)	mem 39.948
Train: [40][355/750]	BT 0.074 (1.202)	DT 0.015 (1.160)	loss 7.045 (7.045)	prob 2.746 (2.746)	GS 24.984 (24.984)	mem 40.039
Train: [40][360/750]	BT 0.464 (1.190)	DT 0.380 (1.148)	loss 6.929 (6.929)	prob 2.772 (2.772)	GS 35.031 (35.031)	mem 39.979
Train: [40][365/750]	BT 0.054 (1.174)	DT 0.004 (1.132)	loss 6.939 (6.939)	prob 2.555 (2.555)	GS 31.391 (31.391)	mem 39.979
Train: [40][370/750]	BT 1.285 (1.185)	DT 1.254 (1.143)	loss 7.088 (7.088)	prob 2.919 (2.919)	GS 30.922 (30.922)	mem 39.986
Train: [40][375/750]	BT 0.122 (1.174)	DT 0.004 (1.131)	loss 6.628 (6.628)	prob 3.406 (3.406)	GS 28.812 (28.812)	mem 39.990
Train: [40][380/750]	BT 0.020 (1.188)	DT 0.001 (1.146)	loss 7.105 (7.105)	prob 2.515 (2.515)	GS 35.672 (35.672)	mem 39.940
Train: [40][385/750]	BT 0.043 (1.178)	DT 0.002 (1.136)	loss 6.843 (6.843)	prob 3.004 (3.004)	GS 30.859 (30.859)	mem 39.988
Train: [40][390/750]	BT 7.533 (1.183)	DT 7.491 (1.140)	loss 6.739 (6.739)	prob 2.791 (2.791)	GS 34.969 (34.969)	mem 40.037
Train: [40][395/750]	BT 0.033 (1.174)	DT 0.001 (1.132)	loss 6.699 (6.699)	prob 2.728 (2.728)	GS 31.203 (31.203)	mem 40.060
Train: [40][400/750]	BT 0.088 (1.169)	DT 0.011 (1.126)	loss 6.772 (6.772)	prob 3.020 (3.020)	GS 30.531 (30.531)	mem 40.269
Train: [40][405/750]	BT 0.045 (1.178)	DT 0.003 (1.136)	loss 6.998 (6.998)	prob 2.795 (2.795)	GS 32.203 (32.203)	mem 40.048
Train: [40][410/750]	BT 0.027 (1.171)	DT 0.001 (1.128)	loss 6.758 (6.758)	prob 2.852 (2.852)	GS 31.391 (31.391)	mem 40.044
Train: [40][415/750]	BT 0.029 (1.184)	DT 0.002 (1.141)	loss 7.050 (7.050)	prob 2.449 (2.449)	GS 29.531 (29.531)	mem 39.988
Train: [40][420/750]	BT 0.032 (1.174)	DT 0.001 (1.131)	loss 7.009 (7.009)	prob 2.429 (2.429)	GS 27.859 (27.859)	mem 39.872
Train: [40][425/750]	BT 0.031 (1.160)	DT 0.003 (1.118)	loss 7.038 (7.038)	prob 2.081 (2.081)	GS 33.266 (33.266)	mem 39.833
Train: [40][430/750]	BT 0.051 (1.172)	DT 0.020 (1.130)	loss 7.145 (7.145)	prob 2.749 (2.749)	GS 31.031 (31.031)	mem 39.919
Train: [40][435/750]	BT 0.050 (1.159)	DT 0.010 (1.117)	loss 6.833 (6.833)	prob 2.292 (2.292)	GS 30.297 (30.297)	mem 39.918
Train: [40][440/750]	BT 0.046 (1.179)	DT 0.006 (1.137)	loss 7.288 (7.288)	prob 3.220 (3.220)	GS 31.984 (31.984)	mem 39.947
Train: [40][445/750]	BT 0.058 (1.175)	DT 0.002 (1.132)	loss 7.173 (7.173)	prob 2.575 (2.575)	GS 31.500 (31.500)	mem 40.021
Train: [40][450/750]	BT 9.102 (1.182)	DT 9.010 (1.140)	loss 7.052 (7.052)	prob 3.070 (3.070)	GS 32.938 (32.938)	mem 40.050
Train: [40][455/750]	BT 0.039 (1.185)	DT 0.001 (1.143)	loss 7.297 (7.297)	prob 2.430 (2.430)	GS 25.172 (25.172)	mem 39.950
Train: [40][460/750]	BT 0.036 (1.173)	DT 0.001 (1.130)	loss 6.754 (6.754)	prob 3.454 (3.454)	GS 33.016 (33.016)	mem 39.941
Train: [40][465/750]	BT 0.040 (1.168)	DT 0.005 (1.125)	loss 6.927 (6.927)	prob 2.433 (2.433)	GS 31.453 (31.453)	mem 40.146
Train: [40][470/750]	BT 0.091 (1.171)	DT 0.010 (1.128)	loss 7.443 (7.443)	prob 2.293 (2.293)	GS 33.953 (33.953)	mem 39.895
Train: [40][475/750]	BT 0.109 (1.174)	DT 0.006 (1.131)	loss 6.865 (6.865)	prob 2.281 (2.281)	GS 29.391 (29.391)	mem 39.833
Train: [40][480/750]	BT 0.033 (1.181)	DT 0.001 (1.138)	loss 7.109 (7.109)	prob 2.527 (2.527)	GS 34.688 (34.688)	mem 39.820
Train: [40][485/750]	BT 0.032 (1.169)	DT 0.002 (1.126)	loss 6.996 (6.996)	prob 2.639 (2.639)	GS 30.375 (30.375)	mem 39.753
Train: [40][490/750]	BT 9.854 (1.187)	DT 9.744 (1.144)	loss 7.493 (7.493)	prob 2.413 (2.413)	GS 34.359 (34.359)	mem 39.876
Train: [40][495/750]	BT 0.029 (1.176)	DT 0.001 (1.132)	loss 7.859 (7.859)	prob 1.678 (1.678)	GS 30.469 (30.469)	mem 39.962
Train: [40][500/750]	BT 0.362 (1.169)	DT 0.206 (1.125)	loss 7.082 (7.082)	prob 2.174 (2.174)	GS 33.453 (33.453)	mem 40.231
Train: [40][505/750]	BT 0.024 (1.183)	DT 0.001 (1.139)	loss 7.060 (7.060)	prob 2.605 (2.605)	GS 31.844 (31.844)	mem 39.866
Train: [40][510/750]	BT 0.046 (1.172)	DT 0.011 (1.128)	loss 7.244 (7.244)	prob 2.803 (2.803)	GS 34.312 (34.312)	mem 39.866
Train: [40][515/750]	BT 0.034 (1.187)	DT 0.002 (1.143)	loss 7.371 (7.371)	prob 2.514 (2.514)	GS 32.781 (32.781)	mem 40.006
Train: [40][520/750]	BT 0.035 (1.176)	DT 0.005 (1.132)	loss 7.375 (7.375)	prob 2.551 (2.551)	GS 31.250 (31.250)	mem 39.871
Train: [40][525/750]	BT 0.028 (1.165)	DT 0.001 (1.122)	loss 7.436 (7.436)	prob 2.283 (2.283)	GS 31.594 (31.594)	mem 39.871
Train: [40][530/750]	BT 0.108 (1.182)	DT 0.012 (1.138)	loss 7.549 (7.549)	prob 2.019 (2.019)	GS 33.906 (33.906)	mem 39.854
Train: [40][535/750]	BT 0.046 (1.171)	DT 0.002 (1.128)	loss 7.148 (7.148)	prob 2.288 (2.288)	GS 29.844 (29.844)	mem 39.797
Train: [40][540/750]	BT 0.054 (1.183)	DT 0.006 (1.140)	loss 7.320 (7.320)	prob 2.053 (2.053)	GS 36.969 (36.969)	mem 39.922
Train: [40][545/750]	BT 0.104 (1.173)	DT 0.007 (1.129)	loss 7.038 (7.038)	prob 2.379 (2.379)	GS 31.625 (31.625)	mem 39.856
Train: [40][550/750]	BT 15.330 (1.190)	DT 15.286 (1.147)	loss 7.256 (7.256)	prob 2.410 (2.410)	GS 34.125 (34.125)	mem 39.903
Train: [40][555/750]	BT 0.066 (1.180)	DT 0.009 (1.137)	loss 7.560 (7.560)	prob 1.120 (1.120)	GS 30.047 (30.047)	mem 39.945
Train: [40][560/750]	BT 0.024 (1.170)	DT 0.001 (1.126)	loss 7.176 (7.176)	prob 2.640 (2.640)	GS 31.172 (31.172)	mem 39.925
Train: [40][565/750]	BT 0.024 (1.188)	DT 0.001 (1.144)	loss 7.145 (7.145)	prob 2.701 (2.701)	GS 30.203 (30.203)	mem 39.910
Train: [40][570/750]	BT 0.050 (1.177)	DT 0.002 (1.134)	loss 7.851 (7.851)	prob 1.523 (1.523)	GS 36.250 (36.250)	mem 39.985
Train: [40][575/750]	BT 0.040 (1.192)	DT 0.001 (1.148)	loss 7.992 (7.992)	prob 1.224 (1.224)	GS 26.156 (26.156)	mem 39.912
Train: [40][580/750]	BT 0.039 (1.182)	DT 0.002 (1.138)	loss 7.370 (7.370)	prob 2.601 (2.601)	GS 32.516 (32.516)	mem 39.912
Train: [40][585/750]	BT 0.046 (1.172)	DT 0.006 (1.129)	loss 7.641 (7.641)	prob 1.861 (1.861)	GS 36.250 (36.250)	mem 39.915
Train: [40][590/750]	BT 0.041 (1.179)	DT 0.001 (1.136)	loss 8.009 (8.009)	prob 2.042 (2.042)	GS 35.516 (35.516)	mem 40.067
Train: [40][595/750]	BT 0.081 (1.170)	DT 0.003 (1.126)	loss 7.294 (7.294)	prob 2.790 (2.790)	GS 31.844 (31.844)	mem 39.998
Train: [40][600/750]	BT 0.034 (1.183)	DT 0.001 (1.139)	loss 7.752 (7.752)	prob 2.122 (2.122)	GS 35.750 (35.750)	mem 39.954
Train: [40][605/750]	BT 0.032 (1.174)	DT 0.001 (1.130)	loss 7.261 (7.261)	prob 2.095 (2.095)	GS 33.938 (33.938)	mem 39.895
Train: [40][610/750]	BT 12.237 (1.184)	DT 12.206 (1.141)	loss 7.542 (7.542)	prob 2.648 (2.648)	GS 36.656 (36.656)	mem 39.999
Train: [40][615/750]	BT 0.082 (1.175)	DT 0.001 (1.132)	loss 7.200 (7.200)	prob 2.288 (2.288)	GS 35.000 (35.000)	mem 40.142
Train: [40][620/750]	BT 0.061 (1.166)	DT 0.008 (1.123)	loss 6.893 (6.893)	prob 2.832 (2.832)	GS 36.047 (36.047)	mem 40.062
Train: [40][625/750]	BT 0.031 (1.176)	DT 0.001 (1.133)	loss 7.679 (7.679)	prob 1.819 (1.819)	GS 31.141 (31.141)	mem 39.897
Train: [40][630/750]	BT 0.028 (1.168)	DT 0.001 (1.124)	loss 7.306 (7.306)	prob 2.645 (2.645)	GS 31.719 (31.719)	mem 39.893
Train: [40][635/750]	BT 0.032 (1.176)	DT 0.001 (1.132)	loss 7.478 (7.478)	prob 2.114 (2.114)	GS 28.188 (28.188)	mem 40.024
Train: [40][640/750]	BT 0.049 (1.167)	DT 0.017 (1.124)	loss 7.511 (7.511)	prob 2.372 (2.372)	GS 35.891 (35.891)	mem 39.968
Train: [40][645/750]	BT 0.079 (1.159)	DT 0.007 (1.115)	loss 7.511 (7.511)	prob 2.356 (2.356)	GS 31.125 (31.125)	mem 39.970
Train: [40][650/750]	BT 0.084 (1.171)	DT 0.005 (1.127)	loss 7.535 (7.535)	prob 2.481 (2.481)	GS 33.688 (33.688)	mem 40.112
Train: [40][655/750]	BT 0.055 (1.162)	DT 0.002 (1.118)	loss 7.281 (7.281)	prob 2.391 (2.391)	GS 34.453 (34.453)	mem 40.399
Train: [40][660/750]	BT 0.039 (1.168)	DT 0.009 (1.124)	loss 7.201 (7.201)	prob 3.028 (3.028)	GS 31.297 (31.297)	mem 40.001
Train: [40][665/750]	BT 0.024 (1.159)	DT 0.001 (1.115)	loss 8.312 (8.312)	prob 1.592 (1.592)	GS 32.172 (32.172)	mem 40.002
Train: [40][670/750]	BT 15.256 (1.174)	DT 15.225 (1.130)	loss 7.371 (7.371)	prob 2.165 (2.165)	GS 35.141 (35.141)	mem 39.916
Train: [40][675/750]	BT 0.031 (1.165)	DT 0.001 (1.121)	loss 7.701 (7.701)	prob 1.611 (1.611)	GS 25.562 (25.562)	mem 39.916
Train: [40][680/750]	BT 0.028 (1.157)	DT 0.001 (1.113)	loss 7.639 (7.639)	prob 2.436 (2.436)	GS 37.344 (37.344)	mem 39.917
Train: [40][685/750]	BT 0.057 (1.172)	DT 0.002 (1.128)	loss 8.242 (8.242)	prob 1.378 (1.378)	GS 47.984 (47.984)	mem 40.002
Train: [40][690/750]	BT 0.030 (1.164)	DT 0.001 (1.120)	loss 7.586 (7.586)	prob 3.319 (3.319)	GS 32.609 (32.609)	mem 40.001
Train: [40][695/750]	BT 0.055 (1.168)	DT 0.009 (1.124)	loss 8.065 (8.065)	prob 2.378 (2.378)	GS 32.281 (32.281)	mem 39.950
Train: [40][700/750]	BT 0.046 (1.164)	DT 0.002 (1.120)	loss 7.217 (7.217)	prob 3.014 (3.014)	GS 32.234 (32.234)	mem 40.017
Train: [40][705/750]	BT 0.027 (1.156)	DT 0.001 (1.112)	loss 7.661 (7.661)	prob 1.678 (1.678)	GS 30.984 (30.984)	mem 39.994
Train: [40][710/750]	BT 0.028 (1.169)	DT 0.002 (1.125)	loss 7.426 (7.426)	prob 2.822 (2.822)	GS 32.953 (32.953)	mem 39.929
Train: [40][715/750]	BT 0.047 (1.162)	DT 0.006 (1.118)	loss 7.614 (7.614)	prob 2.232 (2.232)	GS 29.844 (29.844)	mem 40.025
Train: [40][720/750]	BT 2.614 (1.174)	DT 2.559 (1.130)	loss 7.187 (7.187)	prob 3.266 (3.266)	GS 29.641 (29.641)	mem 39.934
Train: [40][725/750]	BT 0.054 (1.167)	DT 0.001 (1.123)	loss 7.184 (7.184)	prob 3.307 (3.307)	GS 31.094 (31.094)	mem 40.142
Train: [40][730/750]	BT 8.109 (1.170)	DT 8.080 (1.126)	loss 7.793 (7.793)	prob 2.590 (2.590)	GS 31.703 (31.703)	mem 39.537
Train: [40][735/750]	BT 0.031 (1.166)	DT 0.001 (1.121)	loss 7.743 (7.743)	prob 1.523 (1.523)	GS 33.156 (33.156)	mem 39.539
Train: [40][740/750]	BT 0.048 (1.159)	DT 0.008 (1.115)	loss 7.127 (7.127)	prob 2.809 (2.809)	GS 35.312 (35.312)	mem 16.427
Train: [40][745/750]	BT 0.033 (1.160)	DT 0.001 (1.116)	loss 7.444 (7.444)	prob 2.681 (2.681)	GS 29.406 (29.406)	mem 10.599
Train: [40][750/750]	BT 0.026 (1.153)	DT 0.001 (1.109)	loss 7.883 (7.883)	prob 3.114 (3.114)	GS 35.125 (35.125)	mem 10.599
Train: [40][755/750]	BT 0.030 (1.146)	DT 0.001 (1.102)	loss 8.061 (8.061)	prob 2.450 (2.450)	GS 33.125 (33.125)	mem 10.563
epoch 40, total time 866.70
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [41][1/750]	BT 20.790 (20.790)	DT 20.709 (20.709)	loss 7.233 (7.233)	prob 3.903 (3.903)	GS 30.094 (30.094)	mem 38.497
Train: [41][5/750]	BT 0.099 (5.055)	DT 0.029 (4.999)	loss 7.531 (7.531)	prob 2.114 (2.114)	GS 30.234 (30.234)	mem 38.785
Train: [41][10/750]	BT 0.039 (2.549)	DT 0.001 (2.502)	loss 7.472 (7.472)	prob 3.346 (3.346)	GS 35.219 (35.219)	mem 38.648
Train: [41][15/750]	BT 0.037 (2.639)	DT 0.004 (2.590)	loss 7.465 (7.465)	prob 2.649 (2.649)	GS 32.312 (32.312)	mem 38.967
Train: [41][20/750]	BT 0.113 (2.026)	DT 0.054 (1.978)	loss 7.490 (7.490)	prob 2.902 (2.902)	GS 35.516 (35.516)	mem 38.944
Train: [41][25/750]	BT 0.848 (1.663)	DT 0.779 (1.615)	loss 7.601 (7.601)	prob 2.283 (2.283)	GS 26.656 (26.656)	mem 38.839
Train: [41][30/750]	BT 0.039 (1.862)	DT 0.001 (1.816)	loss 7.492 (7.492)	prob 3.711 (3.711)	GS 36.641 (36.641)	mem 38.711
Train: [41][35/750]	BT 0.057 (1.603)	DT 0.009 (1.558)	loss 7.187 (7.187)	prob 4.317 (4.317)	GS 29.609 (29.609)	mem 38.721
Train: [41][40/750]	BT 6.033 (1.766)	DT 5.995 (1.721)	loss 7.548 (7.548)	prob 3.655 (3.655)	GS 35.609 (35.609)	mem 38.790
Train: [41][45/750]	BT 0.109 (1.577)	DT 0.002 (1.530)	loss 7.343 (7.343)	prob 2.784 (2.784)	GS 31.688 (31.688)	mem 38.791
Train: [41][50/750]	BT 5.955 (1.543)	DT 5.914 (1.496)	loss 7.662 (7.662)	prob 3.075 (3.075)	GS 29.500 (29.500)	mem 39.169
Train: [41][55/750]	BT 0.026 (1.525)	DT 0.001 (1.478)	loss 7.232 (7.232)	prob 3.099 (3.099)	GS 26.766 (26.766)	mem 38.951
Train: [41][60/750]	BT 0.060 (1.402)	DT 0.004 (1.355)	loss 7.718 (7.718)	prob 3.052 (3.052)	GS 36.531 (36.531)	mem 39.299
Train: [41][65/750]	BT 0.113 (1.487)	DT 0.002 (1.439)	loss 7.317 (7.317)	prob 2.718 (2.718)	GS 32.266 (32.266)	mem 38.992
Train: [41][70/750]	BT 0.032 (1.384)	DT 0.001 (1.337)	loss 7.091 (7.091)	prob 3.182 (3.182)	GS 32.453 (32.453)	mem 38.995
Train: [41][75/750]	BT 0.037 (1.380)	DT 0.002 (1.332)	loss 7.199 (7.199)	prob 2.816 (2.816)	GS 33.312 (33.312)	mem 39.238
Train: [41][80/750]	BT 0.059 (1.388)	DT 0.002 (1.341)	loss 6.958 (6.958)	prob 3.553 (3.553)	GS 33.531 (33.531)	mem 39.439
Train: [41][85/750]	BT 0.051 (1.310)	DT 0.010 (1.263)	loss 7.457 (7.457)	prob 2.665 (2.665)	GS 31.719 (31.719)	mem 39.071
Train: [41][90/750]	BT 0.035 (1.392)	DT 0.001 (1.345)	loss 7.430 (7.430)	prob 3.113 (3.113)	GS 33.750 (33.750)	mem 39.022
Train: [41][95/750]	BT 0.036 (1.320)	DT 0.001 (1.274)	loss 7.360 (7.360)	prob 2.894 (2.894)	GS 30.656 (30.656)	mem 39.025
Train: [41][100/750]	BT 1.479 (1.356)	DT 1.447 (1.310)	loss 7.527 (7.527)	prob 3.398 (3.398)	GS 29.562 (29.562)	mem 39.068
Train: [41][105/750]	BT 0.098 (1.294)	DT 0.011 (1.248)	loss 7.219 (7.219)	prob 3.113 (3.113)	GS 36.766 (36.766)	mem 39.090
Train: [41][110/750]	BT 13.279 (1.357)	DT 13.245 (1.312)	loss 7.206 (7.206)	prob 3.628 (3.628)	GS 35.453 (35.453)	mem 39.038
Train: [41][115/750]	BT 0.051 (1.300)	DT 0.001 (1.255)	loss 7.359 (7.359)	prob 3.359 (3.359)	GS 31.578 (31.578)	mem 39.040
Train: [41][120/750]	BT 0.034 (1.248)	DT 0.001 (1.203)	loss 7.775 (7.775)	prob 2.857 (2.857)	GS 30.328 (30.328)	mem 39.061
Train: [41][125/750]	BT 0.030 (1.313)	DT 0.001 (1.269)	loss 7.565 (7.565)	prob 2.637 (2.637)	GS 30.266 (30.266)	mem 39.060
Train: [41][130/750]	BT 0.033 (1.264)	DT 0.001 (1.220)	loss 7.937 (7.937)	prob 2.644 (2.644)	GS 40.297 (40.297)	mem 39.066
Train: [41][135/750]	BT 0.045 (1.301)	DT 0.015 (1.257)	loss 7.221 (7.221)	prob 3.054 (3.054)	GS 31.984 (31.984)	mem 39.068
Train: [41][140/750]	BT 0.028 (1.277)	DT 0.001 (1.234)	loss 7.670 (7.670)	prob 3.069 (3.069)	GS 33.094 (33.094)	mem 39.120
Train: [41][145/750]	BT 0.072 (1.235)	DT 0.004 (1.191)	loss 7.882 (7.882)	prob 2.311 (2.311)	GS 32.453 (32.453)	mem 39.122
Train: [41][150/750]	BT 0.082 (1.284)	DT 0.003 (1.240)	loss 7.310 (7.310)	prob 3.220 (3.220)	GS 30.734 (30.734)	mem 39.406
Train: [41][155/750]	BT 0.032 (1.243)	DT 0.001 (1.200)	loss 7.480 (7.480)	prob 2.964 (2.964)	GS 34.562 (34.562)	mem 39.334
Train: [41][160/750]	BT 2.425 (1.272)	DT 2.377 (1.228)	loss 7.091 (7.091)	prob 3.037 (3.037)	GS 29.969 (29.969)	mem 39.539
Train: [41][165/750]	BT 0.056 (1.235)	DT 0.001 (1.191)	loss 7.095 (7.095)	prob 3.780 (3.780)	GS 26.938 (26.938)	mem 39.503
Train: [41][170/750]	BT 10.234 (1.260)	DT 10.197 (1.216)	loss 7.199 (7.199)	prob 3.438 (3.438)	GS 30.594 (30.594)	mem 39.625
Train: [41][175/750]	BT 0.034 (1.250)	DT 0.002 (1.207)	loss 7.660 (7.660)	prob 2.414 (2.414)	GS 30.391 (30.391)	mem 39.507
Train: [41][180/750]	BT 0.053 (1.217)	DT 0.003 (1.173)	loss 7.631 (7.631)	prob 3.458 (3.458)	GS 30.984 (30.984)	mem 39.508
Train: [41][185/750]	BT 0.049 (1.253)	DT 0.003 (1.209)	loss 7.226 (7.226)	prob 3.291 (3.291)	GS 28.609 (28.609)	mem 39.469
Train: [41][190/750]	BT 0.052 (1.221)	DT 0.001 (1.177)	loss 7.271 (7.271)	prob 3.415 (3.415)	GS 32.531 (32.531)	mem 39.507
Train: [41][195/750]	BT 0.034 (1.239)	DT 0.002 (1.195)	loss 7.662 (7.662)	prob 1.938 (1.938)	GS 33.047 (33.047)	mem 40.191
Train: [41][200/750]	BT 0.033 (1.231)	DT 0.002 (1.187)	loss 6.933 (6.933)	prob 2.953 (2.953)	GS 33.250 (33.250)	mem 39.641
Train: [41][205/750]	BT 0.035 (1.202)	DT 0.002 (1.158)	loss 7.482 (7.482)	prob 2.490 (2.490)	GS 23.016 (23.016)	mem 39.967
Train: [41][210/750]	BT 0.030 (1.252)	DT 0.001 (1.208)	loss 7.396 (7.396)	prob 3.411 (3.411)	GS 31.500 (31.500)	mem 39.705
Train: [41][215/750]	BT 0.049 (1.223)	DT 0.001 (1.180)	loss 7.116 (7.116)	prob 3.549 (3.549)	GS 31.734 (31.734)	mem 39.600
Train: [41][220/750]	BT 9.871 (1.256)	DT 9.839 (1.212)	loss 7.097 (7.097)	prob 3.484 (3.484)	GS 33.172 (33.172)	mem 39.623
Train: [41][225/750]	BT 0.055 (1.229)	DT 0.001 (1.185)	loss 7.440 (7.440)	prob 2.648 (2.648)	GS 33.266 (33.266)	mem 39.625
Train: [41][230/750]	BT 3.560 (1.218)	DT 3.527 (1.175)	loss 7.434 (7.434)	prob 3.378 (3.378)	GS 34.750 (34.750)	mem 39.619
Train: [41][235/750]	BT 0.032 (1.236)	DT 0.001 (1.193)	loss 7.105 (7.105)	prob 3.024 (3.024)	GS 30.500 (30.500)	mem 39.903
Train: [41][240/750]	BT 0.028 (1.211)	DT 0.001 (1.168)	loss 7.361 (7.361)	prob 3.115 (3.115)	GS 32.281 (32.281)	mem 39.713
Train: [41][245/750]	BT 0.043 (1.240)	DT 0.007 (1.197)	loss 7.278 (7.278)	prob 2.922 (2.922)	GS 28.297 (28.297)	mem 39.763
Train: [41][250/750]	BT 0.063 (1.216)	DT 0.002 (1.173)	loss 7.006 (7.006)	prob 3.251 (3.251)	GS 29.922 (29.922)	mem 39.764
Train: [41][255/750]	BT 0.049 (1.218)	DT 0.003 (1.175)	loss 7.035 (7.035)	prob 2.893 (2.893)	GS 35.375 (35.375)	mem 39.790
Train: [41][260/750]	BT 0.069 (1.213)	DT 0.037 (1.170)	loss 7.370 (7.370)	prob 3.603 (3.603)	GS 34.375 (34.375)	mem 39.736
Train: [41][265/750]	BT 0.046 (1.191)	DT 0.003 (1.148)	loss 7.460 (7.460)	prob 2.816 (2.816)	GS 29.734 (29.734)	mem 39.722
Train: [41][270/750]	BT 0.050 (1.214)	DT 0.012 (1.171)	loss 6.951 (6.951)	prob 3.679 (3.679)	GS 34.422 (34.422)	mem 39.795
Train: [41][275/750]	BT 0.051 (1.193)	DT 0.010 (1.150)	loss 6.941 (6.941)	prob 2.919 (2.919)	GS 30.781 (30.781)	mem 39.797
Train: [41][280/750]	BT 5.916 (1.220)	DT 5.874 (1.177)	loss 7.215 (7.215)	prob 3.643 (3.643)	GS 35.578 (35.578)	mem 39.817
Train: [41][285/750]	BT 0.030 (1.199)	DT 0.001 (1.156)	loss 6.886 (6.886)	prob 3.501 (3.501)	GS 28.047 (28.047)	mem 39.859
Train: [41][290/750]	BT 3.944 (1.193)	DT 3.898 (1.150)	loss 7.114 (7.114)	prob 3.239 (3.239)	GS 36.047 (36.047)	mem 39.801
Train: [41][295/750]	BT 0.106 (1.204)	DT 0.002 (1.160)	loss 7.490 (7.490)	prob 2.785 (2.785)	GS 34.734 (34.734)	mem 39.772
Train: [41][300/750]	BT 0.054 (1.185)	DT 0.006 (1.141)	loss 7.206 (7.206)	prob 3.431 (3.431)	GS 33.547 (33.547)	mem 39.813
Train: [41][305/750]	BT 0.096 (1.201)	DT 0.008 (1.156)	loss 7.013 (7.013)	prob 3.262 (3.262)	GS 31.062 (31.062)	mem 39.913
Train: [41][310/750]	BT 0.095 (1.182)	DT 0.003 (1.138)	loss 6.994 (6.994)	prob 3.056 (3.056)	GS 38.203 (38.203)	mem 39.830
Train: [41][315/750]	BT 0.036 (1.200)	DT 0.001 (1.155)	loss 6.930 (6.930)	prob 3.214 (3.214)	GS 31.984 (31.984)	mem 39.840
Train: [41][320/750]	BT 0.038 (1.186)	DT 0.002 (1.141)	loss 7.694 (7.694)	prob 3.056 (3.056)	GS 35.281 (35.281)	mem 39.936
Train: [41][325/750]	BT 0.055 (1.168)	DT 0.001 (1.123)	loss 7.245 (7.245)	prob 2.903 (2.903)	GS 28.203 (28.203)	mem 39.828
Train: [41][330/750]	BT 0.043 (1.191)	DT 0.012 (1.146)	loss 7.319 (7.319)	prob 2.798 (2.798)	GS 36.250 (36.250)	mem 39.833
Train: [41][335/750]	BT 0.069 (1.174)	DT 0.001 (1.129)	loss 7.209 (7.209)	prob 3.092 (3.092)	GS 29.562 (29.562)	mem 39.943
Train: [41][340/750]	BT 4.745 (1.190)	DT 4.717 (1.145)	loss 7.154 (7.154)	prob 3.116 (3.116)	GS 35.000 (35.000)	mem 39.900
Train: [41][345/750]	BT 0.035 (1.173)	DT 0.009 (1.129)	loss 7.694 (7.694)	prob 2.380 (2.380)	GS 30.406 (30.406)	mem 39.867
Train: [41][350/750]	BT 9.749 (1.185)	DT 9.698 (1.140)	loss 7.071 (7.071)	prob 3.276 (3.276)	GS 31.328 (31.328)	mem 39.918
Train: [41][355/750]	BT 0.042 (1.178)	DT 0.001 (1.134)	loss 7.474 (7.474)	prob 2.610 (2.610)	GS 28.688 (28.688)	mem 40.212
Train: [41][360/750]	BT 0.036 (1.162)	DT 0.001 (1.118)	loss 6.897 (6.897)	prob 3.389 (3.389)	GS 29.750 (29.750)	mem 40.127
Train: [41][365/750]	BT 0.038 (1.186)	DT 0.008 (1.141)	loss 7.056 (7.056)	prob 3.369 (3.369)	GS 27.953 (27.953)	mem 39.838
Train: [41][370/750]	BT 0.048 (1.170)	DT 0.017 (1.126)	loss 7.446 (7.446)	prob 3.174 (3.174)	GS 31.547 (31.547)	mem 39.839
Train: [41][375/750]	BT 0.034 (1.189)	DT 0.002 (1.145)	loss 7.419 (7.419)	prob 2.652 (2.652)	GS 32.719 (32.719)	mem 39.860
Train: [41][380/750]	BT 0.022 (1.176)	DT 0.001 (1.132)	loss 6.819 (6.819)	prob 3.026 (3.026)	GS 29.078 (29.078)	mem 39.909
Train: [41][385/750]	BT 0.052 (1.161)	DT 0.001 (1.117)	loss 7.411 (7.411)	prob 2.592 (2.592)	GS 28.359 (28.359)	mem 39.865
Train: [41][390/750]	BT 0.147 (1.180)	DT 0.014 (1.136)	loss 7.012 (7.012)	prob 3.232 (3.232)	GS 29.000 (29.000)	mem 39.898
Train: [41][395/750]	BT 0.093 (1.166)	DT 0.012 (1.121)	loss 7.138 (7.138)	prob 3.730 (3.730)	GS 25.578 (25.578)	mem 39.897
Train: [41][400/750]	BT 0.030 (1.185)	DT 0.001 (1.141)	loss 7.252 (7.252)	prob 3.174 (3.174)	GS 31.781 (31.781)	mem 39.966
Train: [41][405/750]	BT 0.029 (1.171)	DT 0.001 (1.127)	loss 6.992 (6.992)	prob 3.081 (3.081)	GS 31.828 (31.828)	mem 39.920
Train: [41][410/750]	BT 10.827 (1.183)	DT 10.791 (1.139)	loss 7.147 (7.147)	prob 2.800 (2.800)	GS 28.141 (28.141)	mem 39.823
Train: [41][415/750]	BT 0.043 (1.174)	DT 0.010 (1.130)	loss 7.356 (7.356)	prob 2.233 (2.233)	GS 35.438 (35.438)	mem 39.852
Train: [41][420/750]	BT 0.027 (1.160)	DT 0.001 (1.117)	loss 7.429 (7.429)	prob 3.274 (3.274)	GS 31.438 (31.438)	mem 39.947
Train: [41][425/750]	BT 0.027 (1.173)	DT 0.001 (1.129)	loss 6.991 (6.991)	prob 2.730 (2.730)	GS 32.094 (32.094)	mem 39.901
Train: [41][430/750]	BT 0.030 (1.160)	DT 0.001 (1.116)	loss 7.022 (7.022)	prob 3.262 (3.262)	GS 34.531 (34.531)	mem 39.902
Train: [41][435/750]	BT 0.032 (1.179)	DT 0.002 (1.136)	loss 7.119 (7.119)	prob 3.134 (3.134)	GS 27.766 (27.766)	mem 39.775
Train: [41][440/750]	BT 0.078 (1.166)	DT 0.001 (1.123)	loss 7.361 (7.361)	prob 2.610 (2.610)	GS 34.969 (34.969)	mem 39.829
Train: [41][445/750]	BT 0.067 (1.154)	DT 0.002 (1.110)	loss 6.861 (6.861)	prob 3.650 (3.650)	GS 32.703 (32.703)	mem 39.978
Train: [41][450/750]	BT 0.052 (1.166)	DT 0.002 (1.122)	loss 7.051 (7.051)	prob 2.456 (2.456)	GS 31.734 (31.734)	mem 39.888
Train: [41][455/750]	BT 0.032 (1.154)	DT 0.001 (1.110)	loss 7.166 (7.166)	prob 2.125 (2.125)	GS 29.031 (29.031)	mem 39.889
Train: [41][460/750]	BT 2.713 (1.169)	DT 2.684 (1.125)	loss 7.233 (7.233)	prob 2.069 (2.069)	GS 34.172 (34.172)	mem 39.801
Train: [41][465/750]	BT 0.031 (1.157)	DT 0.001 (1.113)	loss 6.964 (6.964)	prob 2.731 (2.731)	GS 29.172 (29.172)	mem 39.801
Train: [41][470/750]	BT 5.853 (1.157)	DT 5.737 (1.114)	loss 7.399 (7.399)	prob 3.053 (3.053)	GS 29.891 (29.891)	mem 39.875
Train: [41][475/750]	BT 0.038 (1.163)	DT 0.002 (1.120)	loss 6.936 (6.936)	prob 2.997 (2.997)	GS 32.391 (32.391)	mem 39.896
Train: [41][480/750]	BT 0.051 (1.152)	DT 0.012 (1.108)	loss 7.374 (7.374)	prob 2.334 (2.334)	GS 33.844 (33.844)	mem 39.895
Train: [41][485/750]	BT 0.031 (1.163)	DT 0.001 (1.120)	loss 7.061 (7.061)	prob 2.540 (2.540)	GS 30.109 (30.109)	mem 39.840
Train: [41][490/750]	BT 0.044 (1.152)	DT 0.003 (1.109)	loss 7.141 (7.141)	prob 2.650 (2.650)	GS 33.438 (33.438)	mem 39.920
Train: [41][495/750]	BT 0.048 (1.154)	DT 0.016 (1.110)	loss 7.281 (7.281)	prob 2.117 (2.117)	GS 25.703 (25.703)	mem 39.882
Train: [41][500/750]	BT 0.043 (1.150)	DT 0.002 (1.107)	loss 7.360 (7.360)	prob 2.424 (2.424)	GS 32.969 (32.969)	mem 40.068
Train: [41][505/750]	BT 0.077 (1.144)	DT 0.014 (1.101)	loss 6.999 (6.999)	prob 2.683 (2.683)	GS 32.469 (32.469)	mem 39.777
Train: [41][510/750]	BT 0.060 (1.150)	DT 0.004 (1.106)	loss 6.954 (6.954)	prob 2.335 (2.335)	GS 29.500 (29.500)	mem 39.910
Train: [41][515/750]	BT 0.034 (1.139)	DT 0.002 (1.096)	loss 7.131 (7.131)	prob 2.121 (2.121)	GS 34.406 (34.406)	mem 39.911
Train: [41][520/750]	BT 0.039 (1.151)	DT 0.001 (1.108)	loss 6.954 (6.954)	prob 2.984 (2.984)	GS 31.250 (31.250)	mem 39.932
Train: [41][525/750]	BT 0.031 (1.146)	DT 0.001 (1.103)	loss 7.070 (7.070)	prob 2.632 (2.632)	GS 29.422 (29.422)	mem 39.936
Train: [41][530/750]	BT 13.915 (1.164)	DT 13.884 (1.121)	loss 7.228 (7.228)	prob 2.217 (2.217)	GS 34.203 (34.203)	mem 39.968
Train: [41][535/750]	BT 0.060 (1.154)	DT 0.029 (1.111)	loss 7.087 (7.087)	prob 2.458 (2.458)	GS 30.000 (30.000)	mem 39.928
Train: [41][540/750]	BT 0.023 (1.144)	DT 0.001 (1.100)	loss 7.210 (7.210)	prob 2.093 (2.093)	GS 37.562 (37.562)	mem 39.921
Train: [41][545/750]	BT 0.061 (1.160)	DT 0.004 (1.117)	loss 7.114 (7.114)	prob 2.386 (2.386)	GS 33.094 (33.094)	mem 39.968
Train: [41][550/750]	BT 0.031 (1.150)	DT 0.001 (1.106)	loss 6.912 (6.912)	prob 2.451 (2.451)	GS 34.078 (34.078)	mem 39.892
Train: [41][555/750]	BT 0.054 (1.164)	DT 0.012 (1.121)	loss 7.087 (7.087)	prob 2.761 (2.761)	GS 32.859 (32.859)	mem 39.957
Train: [41][560/750]	BT 0.037 (1.154)	DT 0.002 (1.111)	loss 7.134 (7.134)	prob 2.236 (2.236)	GS 35.266 (35.266)	mem 39.958
Train: [41][565/750]	BT 0.031 (1.144)	DT 0.002 (1.101)	loss 6.753 (6.753)	prob 3.148 (3.148)	GS 31.812 (31.812)	mem 39.957
Train: [41][570/750]	BT 0.031 (1.155)	DT 0.001 (1.112)	loss 7.134 (7.134)	prob 2.065 (2.065)	GS 35.016 (35.016)	mem 39.966
Train: [41][575/750]	BT 0.030 (1.145)	DT 0.001 (1.102)	loss 7.202 (7.202)	prob 1.848 (1.848)	GS 31.719 (31.719)	mem 39.967
Train: [41][580/750]	BT 0.048 (1.160)	DT 0.001 (1.117)	loss 7.102 (7.102)	prob 2.313 (2.313)	GS 31.531 (31.531)	mem 40.072
Train: [41][585/750]	BT 0.075 (1.150)	DT 0.002 (1.108)	loss 7.025 (7.025)	prob 2.492 (2.492)	GS 28.047 (28.047)	mem 40.011
Train: [41][590/750]	BT 11.956 (1.161)	DT 11.898 (1.118)	loss 6.937 (6.937)	prob 3.111 (3.111)	GS 33.688 (33.688)	mem 40.044
Train: [41][595/750]	BT 0.087 (1.152)	DT 0.001 (1.109)	loss 7.052 (7.052)	prob 2.740 (2.740)	GS 34.969 (34.969)	mem 40.022
Train: [41][600/750]	BT 0.034 (1.143)	DT 0.002 (1.100)	loss 7.066 (7.066)	prob 2.436 (2.436)	GS 33.438 (33.438)	mem 40.022
Train: [41][605/750]	BT 0.126 (1.155)	DT 0.001 (1.112)	loss 7.114 (7.114)	prob 2.205 (2.205)	GS 32.938 (32.938)	mem 39.822
Train: [41][610/750]	BT 0.083 (1.146)	DT 0.001 (1.103)	loss 6.983 (6.983)	prob 2.588 (2.588)	GS 34.516 (34.516)	mem 39.823
Train: [41][615/750]	BT 0.032 (1.158)	DT 0.001 (1.115)	loss 6.891 (6.891)	prob 2.205 (2.205)	GS 29.500 (29.500)	mem 39.952
Train: [41][620/750]	BT 0.024 (1.149)	DT 0.001 (1.106)	loss 7.088 (7.088)	prob 2.383 (2.383)	GS 35.891 (35.891)	mem 39.958
Train: [41][625/750]	BT 0.090 (1.140)	DT 0.005 (1.097)	loss 7.079 (7.079)	prob 2.201 (2.201)	GS 32.281 (32.281)	mem 40.029
Train: [41][630/750]	BT 0.033 (1.154)	DT 0.004 (1.111)	loss 7.010 (7.010)	prob 2.638 (2.638)	GS 34.359 (34.359)	mem 40.027
Train: [41][635/750]	BT 0.100 (1.146)	DT 0.025 (1.102)	loss 6.958 (6.958)	prob 2.610 (2.610)	GS 31.172 (31.172)	mem 40.028
Train: [41][640/750]	BT 0.031 (1.158)	DT 0.001 (1.114)	loss 6.711 (6.711)	prob 2.418 (2.418)	GS 34.141 (34.141)	mem 39.975
Train: [41][645/750]	BT 0.030 (1.149)	DT 0.001 (1.106)	loss 7.237 (7.237)	prob 2.506 (2.506)	GS 31.125 (31.125)	mem 39.976
Train: [41][650/750]	BT 11.158 (1.158)	DT 11.099 (1.114)	loss 7.271 (7.271)	prob 2.443 (2.443)	GS 33.688 (33.688)	mem 39.977
Train: [41][655/750]	BT 0.061 (1.149)	DT 0.001 (1.106)	loss 7.447 (7.447)	prob 1.914 (1.914)	GS 32.547 (32.547)	mem 39.985
arpack error, retry= 0
Train: [41][660/750]	BT 0.034 (1.141)	DT 0.001 (1.098)	loss 6.947 (6.947)	prob 2.520 (2.520)	GS 31.547 (31.547)	mem 40.027
Train: [41][665/750]	BT 0.029 (1.151)	DT 0.001 (1.108)	loss 7.168 (7.168)	prob 2.218 (2.218)	GS 31.938 (31.938)	mem 39.950
Train: [41][670/750]	BT 0.042 (1.143)	DT 0.003 (1.100)	loss 6.892 (6.892)	prob 2.839 (2.839)	GS 31.031 (31.031)	mem 39.994
Train: [41][675/750]	BT 0.040 (1.156)	DT 0.004 (1.112)	loss 6.829 (6.829)	prob 2.790 (2.790)	GS 31.609 (31.609)	mem 39.991
Train: [41][680/750]	BT 0.029 (1.147)	DT 0.001 (1.104)	loss 6.663 (6.663)	prob 2.925 (2.925)	GS 33.359 (33.359)	mem 39.959
Train: [41][685/750]	BT 0.044 (1.139)	DT 0.004 (1.096)	loss 7.157 (7.157)	prob 2.469 (2.469)	GS 34.094 (34.094)	mem 40.008
Train: [41][690/750]	BT 0.048 (1.147)	DT 0.001 (1.104)	loss 6.705 (6.705)	prob 2.526 (2.526)	GS 35.375 (35.375)	mem 39.960
Train: [41][695/750]	BT 0.072 (1.139)	DT 0.001 (1.096)	loss 7.105 (7.105)	prob 2.207 (2.207)	GS 32.844 (32.844)	mem 39.962
Train: [41][700/750]	BT 0.087 (1.152)	DT 0.002 (1.109)	loss 6.979 (6.979)	prob 1.978 (1.978)	GS 33.172 (33.172)	mem 40.055
Train: [41][705/750]	BT 0.121 (1.144)	DT 0.003 (1.101)	loss 6.971 (6.971)	prob 2.176 (2.176)	GS 28.406 (28.406)	mem 39.998
Train: [41][710/750]	BT 14.694 (1.157)	DT 14.672 (1.114)	loss 7.119 (7.119)	prob 2.791 (2.791)	GS 33.016 (33.016)	mem 39.932
Train: [41][715/750]	BT 0.028 (1.149)	DT 0.001 (1.106)	loss 6.893 (6.893)	prob 2.148 (2.148)	GS 26.469 (26.469)	mem 39.934
Train: [41][720/750]	BT 0.031 (1.142)	DT 0.002 (1.098)	loss 6.772 (6.772)	prob 1.972 (1.972)	GS 36.234 (36.234)	mem 39.935
Train: [41][725/750]	BT 0.088 (1.153)	DT 0.004 (1.110)	loss 6.860 (6.860)	prob 2.909 (2.909)	GS 30.141 (30.141)	mem 39.874
Train: [41][730/750]	BT 0.076 (1.145)	DT 0.005 (1.102)	loss 6.701 (6.701)	prob 2.407 (2.407)	GS 34.391 (34.391)	mem 39.873
Train: [41][735/750]	BT 0.022 (1.149)	DT 0.001 (1.105)	loss 7.108 (7.108)	prob 2.156 (2.156)	GS 36.469 (36.469)	mem 36.532
Train: [41][740/750]	BT 0.048 (1.142)	DT 0.020 (1.098)	loss 6.692 (6.692)	prob 2.398 (2.398)	GS 33.703 (33.703)	mem 24.415
Train: [41][745/750]	BT 0.032 (1.134)	DT 0.002 (1.091)	loss 7.028 (7.028)	prob 2.233 (2.233)	GS 38.031 (38.031)	mem 14.699
Train: [41][750/750]	BT 0.030 (1.131)	DT 0.001 (1.088)	loss 6.938 (6.938)	prob 2.760 (2.760)	GS 37.000 (37.000)	mem 7.628
Train: [41][755/750]	BT 0.026 (1.124)	DT 0.001 (1.081)	loss 6.891 (6.891)	prob 3.450 (3.450)	GS 32.625 (32.625)	mem 7.629
epoch 41, total time 848.86
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [42][1/750]	BT 19.399 (19.399)	DT 19.346 (19.346)	loss 6.960 (6.960)	prob 2.724 (2.724)	GS 30.438 (30.438)	mem 38.340
Train: [42][5/750]	BT 0.055 (4.780)	DT 0.003 (4.707)	loss 7.160 (7.160)	prob 2.286 (2.286)	GS 33.531 (33.531)	mem 38.548
Train: [42][10/750]	BT 0.037 (2.406)	DT 0.001 (2.355)	loss 6.780 (6.780)	prob 2.924 (2.924)	GS 32.359 (32.359)	mem 38.425
Train: [42][15/750]	BT 0.061 (2.549)	DT 0.010 (2.491)	loss 7.189 (7.189)	prob 1.790 (1.790)	GS 31.297 (31.297)	mem 38.682
Train: [42][20/750]	BT 0.033 (2.042)	DT 0.001 (1.987)	loss 6.875 (6.875)	prob 1.864 (1.864)	GS 31.531 (31.531)	mem 38.717
Train: [42][25/750]	BT 0.031 (1.640)	DT 0.001 (1.590)	loss 6.935 (6.935)	prob 2.442 (2.442)	GS 29.703 (29.703)	mem 38.717
Train: [42][30/750]	BT 0.038 (1.912)	DT 0.002 (1.862)	loss 6.703 (6.703)	prob 2.708 (2.708)	GS 35.062 (35.062)	mem 38.871
Train: [42][35/750]	BT 0.037 (1.647)	DT 0.003 (1.597)	loss 7.011 (7.011)	prob 2.304 (2.304)	GS 29.672 (29.672)	mem 38.805
Train: [42][40/750]	BT 0.029 (1.740)	DT 0.001 (1.692)	loss 6.872 (6.872)	prob 3.166 (3.166)	GS 34.062 (34.062)	mem 38.913
Train: [42][45/750]	BT 0.028 (1.558)	DT 0.003 (1.505)	loss 6.848 (6.848)	prob 2.761 (2.761)	GS 30.891 (30.891)	mem 38.866
Train: [42][50/750]	BT 13.134 (1.668)	DT 13.081 (1.616)	loss 7.027 (7.027)	prob 2.142 (2.142)	GS 38.078 (38.078)	mem 38.909
Train: [42][55/750]	BT 0.073 (1.522)	DT 0.002 (1.470)	loss 7.164 (7.164)	prob 2.386 (2.386)	GS 30.047 (30.047)	mem 38.936
Train: [42][60/750]	BT 0.730 (1.414)	DT 0.647 (1.359)	loss 6.794 (6.794)	prob 2.672 (2.672)	GS 33.578 (33.578)	mem 39.076
Train: [42][65/750]	BT 0.028 (1.523)	DT 0.001 (1.470)	loss 7.378 (7.378)	prob 2.250 (2.250)	GS 44.500 (44.500)	mem 38.911
Train: [42][70/750]	BT 0.023 (1.417)	DT 0.001 (1.365)	loss 7.244 (7.244)	prob 2.974 (2.974)	GS 32.469 (32.469)	mem 38.914
Train: [42][75/750]	BT 0.112 (1.492)	DT 0.039 (1.440)	loss 6.888 (6.888)	prob 2.528 (2.528)	GS 31.234 (31.234)	mem 39.006
Train: [42][80/750]	BT 0.040 (1.443)	DT 0.003 (1.392)	loss 6.841 (6.841)	prob 2.583 (2.583)	GS 34.250 (34.250)	mem 39.045
Train: [42][85/750]	BT 0.031 (1.362)	DT 0.001 (1.310)	loss 7.271 (7.271)	prob 2.213 (2.213)	GS 35.359 (35.359)	mem 38.983
Train: [42][90/750]	BT 6.705 (1.439)	DT 6.609 (1.386)	loss 6.905 (6.905)	prob 1.892 (1.892)	GS 30.875 (30.875)	mem 39.052
Train: [42][95/750]	BT 0.023 (1.365)	DT 0.001 (1.314)	loss 6.802 (6.802)	prob 2.682 (2.682)	GS 27.375 (27.375)	mem 39.054
Train: [42][100/750]	BT 2.557 (1.360)	DT 2.512 (1.310)	loss 6.615 (6.615)	prob 3.290 (3.290)	GS 29.781 (29.781)	mem 39.151
Train: [42][105/750]	BT 0.061 (1.328)	DT 0.012 (1.278)	loss 6.975 (6.975)	prob 2.547 (2.547)	GS 30.297 (30.297)	mem 39.164
Train: [42][110/750]	BT 7.353 (1.337)	DT 7.320 (1.286)	loss 7.082 (7.082)	prob 2.868 (2.868)	GS 32.672 (32.672)	mem 39.152
Train: [42][115/750]	BT 0.063 (1.340)	DT 0.016 (1.290)	loss 6.745 (6.745)	prob 3.011 (3.011)	GS 29.031 (29.031)	mem 39.405
Train: [42][120/750]	BT 0.053 (1.286)	DT 0.010 (1.236)	loss 6.899 (6.899)	prob 2.455 (2.455)	GS 33.359 (33.359)	mem 39.408
Train: [42][125/750]	BT 0.034 (1.335)	DT 0.001 (1.285)	loss 7.249 (7.249)	prob 2.367 (2.367)	GS 32.859 (32.859)	mem 39.428
Train: [42][130/750]	BT 0.035 (1.305)	DT 0.002 (1.255)	loss 6.965 (6.965)	prob 2.368 (2.368)	GS 37.062 (37.062)	mem 39.371
Train: [42][135/750]	BT 0.058 (1.271)	DT 0.009 (1.221)	loss 6.987 (6.987)	prob 2.635 (2.635)	GS 28.500 (28.500)	mem 39.412
Train: [42][140/750]	BT 0.083 (1.313)	DT 0.009 (1.263)	loss 6.812 (6.812)	prob 3.327 (3.327)	GS 29.656 (29.656)	mem 39.310
Train: [42][145/750]	BT 0.052 (1.270)	DT 0.003 (1.220)	loss 7.339 (7.339)	prob 2.526 (2.526)	GS 30.469 (30.469)	mem 39.311
Train: [42][150/750]	BT 0.848 (1.314)	DT 0.814 (1.264)	loss 6.858 (6.858)	prob 2.777 (2.777)	GS 29.516 (29.516)	mem 39.291
Train: [42][155/750]	BT 0.029 (1.273)	DT 0.001 (1.224)	loss 6.874 (6.874)	prob 2.876 (2.876)	GS 30.344 (30.344)	mem 39.292
Train: [42][160/750]	BT 1.054 (1.283)	DT 1.022 (1.233)	loss 6.782 (6.782)	prob 2.961 (2.961)	GS 33.781 (33.781)	mem 39.414
Train: [42][165/750]	BT 0.035 (1.266)	DT 0.001 (1.217)	loss 7.064 (7.064)	prob 2.611 (2.611)	GS 29.859 (29.859)	mem 39.541
Train: [42][170/750]	BT 9.529 (1.285)	DT 9.464 (1.237)	loss 6.783 (6.783)	prob 2.899 (2.899)	GS 34.172 (34.172)	mem 40.175
Train: [42][175/750]	BT 0.031 (1.288)	DT 0.001 (1.239)	loss 6.755 (6.755)	prob 2.875 (2.875)	GS 33.578 (33.578)	mem 39.701
Train: [42][180/750]	BT 0.056 (1.253)	DT 0.001 (1.204)	loss 6.989 (6.989)	prob 3.134 (3.134)	GS 29.969 (29.969)	mem 39.712
Train: [42][185/750]	BT 0.030 (1.251)	DT 0.001 (1.203)	loss 6.983 (6.983)	prob 2.171 (2.171)	GS 31.234 (31.234)	mem 39.707
Train: [42][190/750]	BT 0.066 (1.267)	DT 0.013 (1.219)	loss 6.904 (6.904)	prob 2.805 (2.805)	GS 34.844 (34.844)	mem 39.833
Train: [42][195/750]	BT 0.064 (1.236)	DT 0.004 (1.188)	loss 6.846 (6.846)	prob 3.226 (3.226)	GS 32.859 (32.859)	mem 39.818
Train: [42][200/750]	BT 0.025 (1.276)	DT 0.001 (1.228)	loss 7.048 (7.048)	prob 3.103 (3.103)	GS 34.438 (34.438)	mem 39.682
Train: [42][205/750]	BT 0.026 (1.246)	DT 0.003 (1.198)	loss 7.160 (7.160)	prob 2.844 (2.844)	GS 36.609 (36.609)	mem 39.709
Train: [42][210/750]	BT 11.845 (1.279)	DT 11.775 (1.232)	loss 6.825 (6.825)	prob 3.332 (3.332)	GS 35.219 (35.219)	mem 39.777
Train: [42][215/750]	BT 0.032 (1.251)	DT 0.006 (1.204)	loss 7.036 (7.036)	prob 2.987 (2.987)	GS 35.547 (35.547)	mem 39.780
Train: [42][220/750]	BT 0.147 (1.226)	DT 0.033 (1.178)	loss 6.825 (6.825)	prob 2.949 (2.949)	GS 35.531 (35.531)	mem 39.899
Train: [42][225/750]	BT 0.091 (1.245)	DT 0.003 (1.197)	loss 7.204 (7.204)	prob 2.979 (2.979)	GS 33.312 (33.312)	mem 39.843
Train: [42][230/750]	BT 2.508 (1.230)	DT 2.473 (1.182)	loss 6.910 (6.910)	prob 3.350 (3.350)	GS 34.125 (34.125)	mem 39.812
Train: [42][235/750]	BT 0.033 (1.253)	DT 0.001 (1.205)	loss 7.031 (7.031)	prob 2.539 (2.539)	GS 29.641 (29.641)	mem 39.746
Train: [42][240/750]	BT 0.052 (1.228)	DT 0.002 (1.180)	loss 6.847 (6.847)	prob 2.918 (2.918)	GS 33.031 (33.031)	mem 39.783
Train: [42][245/750]	BT 0.091 (1.221)	DT 0.005 (1.173)	loss 7.021 (7.021)	prob 2.462 (2.462)	GS 47.609 (47.609)	mem 39.779
Train: [42][250/750]	BT 0.032 (1.227)	DT 0.001 (1.180)	loss 7.125 (7.125)	prob 2.658 (2.658)	GS 34.812 (34.812)	mem 39.793
Train: [42][255/750]	BT 0.043 (1.232)	DT 0.001 (1.185)	loss 7.336 (7.336)	prob 2.634 (2.634)	GS 31.297 (31.297)	mem 39.807
Train: [42][260/750]	BT 0.044 (1.240)	DT 0.004 (1.193)	loss 6.916 (6.916)	prob 2.798 (2.798)	GS 33.078 (33.078)	mem 39.808
Train: [42][265/750]	BT 0.030 (1.217)	DT 0.001 (1.170)	loss 7.058 (7.058)	prob 2.289 (2.289)	GS 31.125 (31.125)	mem 39.809
Train: [42][270/750]	BT 7.241 (1.237)	DT 7.204 (1.190)	loss 7.153 (7.153)	prob 2.934 (2.934)	GS 36.141 (36.141)	mem 39.861
Train: [42][275/750]	BT 0.096 (1.215)	DT 0.002 (1.168)	loss 6.880 (6.880)	prob 2.670 (2.670)	GS 29.188 (29.188)	mem 39.983
Train: [42][280/750]	BT 0.050 (1.213)	DT 0.001 (1.166)	loss 6.973 (6.973)	prob 2.606 (2.606)	GS 36.641 (36.641)	mem 39.886
Train: [42][285/750]	BT 0.024 (1.212)	DT 0.001 (1.166)	loss 7.059 (7.059)	prob 2.382 (2.382)	GS 32.422 (32.422)	mem 39.872
Train: [42][290/750]	BT 9.962 (1.227)	DT 9.929 (1.180)	loss 6.911 (6.911)	prob 3.055 (3.055)	GS 33.156 (33.156)	mem 39.912
Train: [42][295/750]	BT 0.035 (1.222)	DT 0.006 (1.176)	loss 6.993 (6.993)	prob 2.657 (2.657)	GS 31.781 (31.781)	mem 39.931
Train: [42][300/750]	BT 0.050 (1.203)	DT 0.006 (1.156)	loss 7.191 (7.191)	prob 2.364 (2.364)	GS 35.172 (35.172)	mem 39.963
Train: [42][305/750]	BT 0.039 (1.209)	DT 0.001 (1.163)	loss 6.787 (6.787)	prob 2.837 (2.837)	GS 27.922 (27.922)	mem 39.919
Train: [42][310/750]	BT 0.039 (1.211)	DT 0.001 (1.164)	loss 6.752 (6.752)	prob 3.409 (3.409)	GS 34.688 (34.688)	mem 40.006
Train: [42][315/750]	BT 0.047 (1.207)	DT 0.007 (1.161)	loss 7.301 (7.301)	prob 2.675 (2.675)	GS 30.188 (30.188)	mem 39.995
Train: [42][320/750]	BT 0.077 (1.207)	DT 0.004 (1.160)	loss 6.995 (6.995)	prob 2.669 (2.669)	GS 32.578 (32.578)	mem 40.043
Train: [42][325/750]	BT 0.032 (1.189)	DT 0.001 (1.143)	loss 7.045 (7.045)	prob 2.862 (2.862)	GS 33.062 (33.062)	mem 39.900
Train: [42][330/750]	BT 3.716 (1.202)	DT 3.684 (1.155)	loss 6.960 (6.960)	prob 3.456 (3.456)	GS 36.281 (36.281)	mem 39.882
Train: [42][335/750]	BT 0.044 (1.185)	DT 0.014 (1.138)	loss 6.975 (6.975)	prob 3.146 (3.146)	GS 32.297 (32.297)	mem 39.883
Train: [42][340/750]	BT 0.078 (1.198)	DT 0.008 (1.151)	loss 6.847 (6.847)	prob 3.417 (3.417)	GS 34.000 (34.000)	mem 39.914
Train: [42][345/750]	BT 0.072 (1.192)	DT 0.001 (1.145)	loss 7.090 (7.090)	prob 2.752 (2.752)	GS 30.516 (30.516)	mem 39.909
Train: [42][350/750]	BT 8.648 (1.200)	DT 8.606 (1.153)	loss 6.999 (6.999)	prob 2.887 (2.887)	GS 33.484 (33.484)	mem 39.989
Train: [42][355/750]	BT 0.035 (1.197)	DT 0.003 (1.150)	loss 6.890 (6.890)	prob 3.380 (3.380)	GS 33.031 (33.031)	mem 39.877
Train: [42][360/750]	BT 1.960 (1.187)	DT 1.896 (1.140)	loss 6.868 (6.868)	prob 2.741 (2.741)	GS 37.438 (37.438)	mem 39.900
Train: [42][365/750]	BT 0.031 (1.180)	DT 0.001 (1.133)	loss 6.892 (6.892)	prob 3.111 (3.111)	GS 27.375 (27.375)	mem 39.837
Train: [42][370/750]	BT 0.022 (1.183)	DT 0.001 (1.136)	loss 7.133 (7.133)	prob 2.520 (2.520)	GS 28.406 (28.406)	mem 39.875
Train: [42][375/750]	BT 0.033 (1.183)	DT 0.002 (1.136)	loss 6.882 (6.882)	prob 2.832 (2.832)	GS 31.578 (31.578)	mem 40.078
Train: [42][380/750]	BT 0.098 (1.184)	DT 0.009 (1.137)	loss 6.894 (6.894)	prob 3.033 (3.033)	GS 35.375 (35.375)	mem 39.992
Train: [42][385/750]	BT 0.044 (1.174)	DT 0.006 (1.127)	loss 7.090 (7.090)	prob 2.684 (2.684)	GS 29.938 (29.938)	mem 39.892
Train: [42][390/750]	BT 1.210 (1.181)	DT 1.150 (1.134)	loss 6.940 (6.940)	prob 3.081 (3.081)	GS 31.391 (31.391)	mem 39.907
Train: [42][395/750]	BT 0.031 (1.177)	DT 0.001 (1.131)	loss 6.947 (6.947)	prob 2.540 (2.540)	GS 31.109 (31.109)	mem 39.966
Train: [42][400/750]	BT 0.022 (1.184)	DT 0.001 (1.137)	loss 6.864 (6.864)	prob 2.055 (2.055)	GS 35.719 (35.719)	mem 39.820
Train: [42][405/750]	BT 0.046 (1.181)	DT 0.007 (1.134)	loss 6.878 (6.878)	prob 3.049 (3.049)	GS 30.062 (30.062)	mem 39.817
Train: [42][410/750]	BT 10.536 (1.192)	DT 10.500 (1.146)	loss 6.828 (6.828)	prob 3.093 (3.093)	GS 32.234 (32.234)	mem 39.908
Train: [42][415/750]	BT 0.056 (1.182)	DT 0.012 (1.135)	loss 7.125 (7.125)	prob 2.638 (2.638)	GS 32.547 (32.547)	mem 39.949
Train: [42][420/750]	BT 0.032 (1.168)	DT 0.001 (1.122)	loss 6.970 (6.970)	prob 2.348 (2.348)	GS 32.812 (32.812)	mem 39.956
Train: [42][425/750]	BT 0.051 (1.174)	DT 0.006 (1.128)	loss 7.137 (7.137)	prob 2.525 (2.525)	GS 31.578 (31.578)	mem 39.944
Train: [42][430/750]	BT 0.032 (1.173)	DT 0.001 (1.126)	loss 6.911 (6.911)	prob 3.195 (3.195)	GS 32.812 (32.812)	mem 39.942
Train: [42][435/750]	BT 0.132 (1.180)	DT 0.032 (1.134)	loss 6.854 (6.854)	prob 3.009 (3.009)	GS 28.609 (28.609)	mem 39.930
Train: [42][440/750]	BT 0.024 (1.179)	DT 0.001 (1.132)	loss 6.928 (6.928)	prob 2.637 (2.637)	GS 34.297 (34.297)	mem 39.850
Train: [42][445/750]	BT 0.103 (1.166)	DT 0.024 (1.120)	loss 7.009 (7.009)	prob 2.923 (2.923)	GS 29.625 (29.625)	mem 39.911
Train: [42][450/750]	BT 9.423 (1.188)	DT 9.375 (1.141)	loss 6.996 (6.996)	prob 2.359 (2.359)	GS 34.391 (34.391)	mem 40.058
Train: [42][455/750]	BT 0.032 (1.175)	DT 0.002 (1.128)	loss 7.118 (7.118)	prob 3.057 (3.057)	GS 30.984 (30.984)	mem 39.942
Train: [42][460/750]	BT 0.048 (1.167)	DT 0.015 (1.120)	loss 6.952 (6.952)	prob 3.006 (3.006)	GS 33.469 (33.469)	mem 39.903
Train: [42][465/750]	BT 0.036 (1.180)	DT 0.002 (1.133)	loss 6.908 (6.908)	prob 3.388 (3.388)	GS 29.844 (29.844)	mem 39.969
Train: [42][470/750]	BT 0.200 (1.168)	DT 0.151 (1.122)	loss 6.790 (6.790)	prob 3.006 (3.006)	GS 33.594 (33.594)	mem 39.902
Train: [42][475/750]	BT 0.055 (1.177)	DT 0.013 (1.131)	loss 6.909 (6.909)	prob 2.206 (2.206)	GS 28.844 (28.844)	mem 39.966
Train: [42][480/750]	BT 0.054 (1.165)	DT 0.023 (1.119)	loss 6.964 (6.964)	prob 2.443 (2.443)	GS 32.062 (32.062)	mem 39.967
Train: [42][485/750]	BT 0.052 (1.159)	DT 0.004 (1.113)	loss 7.017 (7.017)	prob 2.683 (2.683)	GS 31.672 (31.672)	mem 39.969
Train: [42][490/750]	BT 0.053 (1.168)	DT 0.001 (1.122)	loss 7.146 (7.146)	prob 2.462 (2.462)	GS 33.859 (33.859)	mem 40.034
Train: [42][495/750]	BT 0.039 (1.160)	DT 0.008 (1.114)	loss 6.753 (6.753)	prob 2.896 (2.896)	GS 33.688 (33.688)	mem 39.964
Train: [42][500/750]	BT 0.050 (1.173)	DT 0.017 (1.127)	loss 7.058 (7.058)	prob 2.575 (2.575)	GS 31.109 (31.109)	mem 40.418
Train: [42][505/750]	BT 0.038 (1.162)	DT 0.001 (1.116)	loss 6.971 (6.971)	prob 3.331 (3.331)	GS 30.484 (30.484)	mem 40.021
Train: [42][510/750]	BT 11.005 (1.177)	DT 10.972 (1.131)	loss 6.990 (6.990)	prob 2.751 (2.751)	GS 30.312 (30.312)	mem 39.950
Train: [42][515/750]	BT 0.080 (1.166)	DT 0.034 (1.120)	loss 6.858 (6.858)	prob 3.511 (3.511)	GS 33.641 (33.641)	mem 39.950
Train: [42][520/750]	BT 0.032 (1.155)	DT 0.001 (1.109)	loss 6.726 (6.726)	prob 3.178 (3.178)	GS 30.969 (30.969)	mem 39.903
Train: [42][525/750]	BT 0.032 (1.168)	DT 0.002 (1.123)	loss 6.933 (6.933)	prob 2.965 (2.965)	GS 32.734 (32.734)	mem 40.008
Train: [42][530/750]	BT 1.294 (1.160)	DT 1.262 (1.114)	loss 6.908 (6.908)	prob 3.057 (3.057)	GS 36.531 (36.531)	mem 40.012
Train: [42][535/750]	BT 0.025 (1.167)	DT 0.001 (1.122)	loss 7.129 (7.129)	prob 2.242 (2.242)	GS 30.594 (30.594)	mem 39.963
Train: [42][540/750]	BT 0.055 (1.157)	DT 0.009 (1.112)	loss 6.802 (6.802)	prob 3.686 (3.686)	GS 34.234 (34.234)	mem 40.066
Train: [42][545/750]	BT 0.025 (1.157)	DT 0.001 (1.111)	loss 7.034 (7.034)	prob 3.012 (3.012)	GS 30.938 (30.938)	mem 40.037
Train: [42][550/750]	BT 0.062 (1.161)	DT 0.005 (1.116)	loss 6.742 (6.742)	prob 3.646 (3.646)	GS 35.844 (35.844)	mem 39.931
Train: [42][555/750]	BT 0.035 (1.158)	DT 0.001 (1.113)	loss 6.776 (6.776)	prob 3.082 (3.082)	GS 31.547 (31.547)	mem 39.949
Train: [42][560/750]	BT 4.933 (1.166)	DT 4.910 (1.121)	loss 6.934 (6.934)	prob 3.431 (3.431)	GS 35.375 (35.375)	mem 39.875
Train: [42][565/750]	BT 0.122 (1.156)	DT 0.018 (1.111)	loss 7.097 (7.097)	prob 2.630 (2.630)	GS 32.234 (32.234)	mem 40.087
Train: [42][570/750]	BT 4.029 (1.160)	DT 3.971 (1.115)	loss 6.912 (6.912)	prob 3.101 (3.101)	GS 34.922 (34.922)	mem 39.971
Train: [42][575/750]	BT 0.023 (1.156)	DT 0.002 (1.110)	loss 6.919 (6.919)	prob 3.018 (3.018)	GS 36.891 (36.891)	mem 39.916
Train: [42][580/750]	BT 0.033 (1.157)	DT 0.002 (1.111)	loss 6.952 (6.952)	prob 3.315 (3.315)	GS 32.391 (32.391)	mem 40.365
Train: [42][585/750]	BT 0.028 (1.155)	DT 0.001 (1.109)	loss 7.077 (7.077)	prob 3.098 (3.098)	GS 31.953 (31.953)	mem 39.863
Train: [42][590/750]	BT 7.716 (1.159)	DT 7.649 (1.113)	loss 6.878 (6.878)	prob 2.922 (2.922)	GS 30.203 (30.203)	mem 39.912
Train: [42][595/750]	BT 0.113 (1.160)	DT 0.003 (1.114)	loss 7.093 (7.093)	prob 3.036 (3.036)	GS 28.875 (28.875)	mem 40.002
Train: [42][600/750]	BT 0.027 (1.151)	DT 0.001 (1.105)	loss 6.893 (6.893)	prob 2.700 (2.700)	GS 32.625 (32.625)	mem 39.939
Train: [42][605/750]	BT 0.070 (1.149)	DT 0.025 (1.103)	loss 7.094 (7.094)	prob 2.603 (2.603)	GS 29.344 (29.344)	mem 39.928
Train: [42][610/750]	BT 0.091 (1.156)	DT 0.025 (1.110)	loss 6.876 (6.876)	prob 2.737 (2.737)	GS 36.297 (36.297)	mem 39.988
Train: [42][615/750]	BT 0.034 (1.151)	DT 0.002 (1.106)	loss 7.075 (7.075)	prob 2.728 (2.728)	GS 32.250 (32.250)	mem 40.033
Train: [42][620/750]	BT 0.025 (1.156)	DT 0.001 (1.110)	loss 7.061 (7.061)	prob 2.684 (2.684)	GS 36.734 (36.734)	mem 39.954
Train: [42][625/750]	BT 0.103 (1.153)	DT 0.001 (1.107)	loss 6.989 (6.989)	prob 2.789 (2.789)	GS 27.969 (27.969)	mem 39.897
Train: [42][630/750]	BT 4.267 (1.153)	DT 4.243 (1.107)	loss 6.750 (6.750)	prob 3.415 (3.415)	GS 34.266 (34.266)	mem 39.882
Train: [42][635/750]	BT 0.080 (1.144)	DT 0.026 (1.098)	loss 6.998 (6.998)	prob 2.459 (2.459)	GS 28.328 (28.328)	mem 39.883
Train: [42][640/750]	BT 0.037 (1.154)	DT 0.002 (1.108)	loss 6.737 (6.737)	prob 3.158 (3.158)	GS 29.984 (29.984)	mem 39.857
Train: [42][645/750]	BT 0.043 (1.146)	DT 0.001 (1.100)	loss 6.919 (6.919)	prob 3.019 (3.019)	GS 33.969 (33.969)	mem 39.858
Train: [42][650/750]	BT 4.854 (1.155)	DT 4.823 (1.109)	loss 6.770 (6.770)	prob 3.366 (3.366)	GS 33.672 (33.672)	mem 39.884
Train: [42][655/750]	BT 0.081 (1.146)	DT 0.007 (1.100)	loss 6.801 (6.801)	prob 3.412 (3.412)	GS 31.281 (31.281)	mem 39.923
arpack error, retry= 0
arpack error, retry= 0
Train: [42][660/750]	BT 7.329 (1.149)	DT 7.248 (1.103)	loss 6.953 (6.953)	prob 3.429 (3.429)	GS 32.469 (32.469)	mem 39.910
Train: [42][665/750]	BT 0.107 (1.147)	DT 0.002 (1.101)	loss 7.192 (7.192)	prob 3.113 (3.113)	GS 32.438 (32.438)	mem 39.822
Train: [42][670/750]	BT 0.052 (1.141)	DT 0.010 (1.094)	loss 7.022 (7.022)	prob 2.731 (2.731)	GS 35.719 (35.719)	mem 39.832
Train: [42][675/750]	BT 0.030 (1.148)	DT 0.002 (1.102)	loss 6.935 (6.935)	prob 2.608 (2.608)	GS 35.484 (35.484)	mem 39.883
Train: [42][680/750]	BT 0.036 (1.143)	DT 0.004 (1.096)	loss 6.691 (6.691)	prob 3.721 (3.721)	GS 32.812 (32.812)	mem 39.827
Train: [42][685/750]	BT 0.045 (1.145)	DT 0.009 (1.099)	loss 6.891 (6.891)	prob 2.706 (2.706)	GS 31.844 (31.844)	mem 40.230
Train: [42][690/750]	BT 5.290 (1.149)	DT 5.213 (1.103)	loss 6.885 (6.885)	prob 2.846 (2.846)	GS 37.438 (37.438)	mem 39.850
Train: [42][695/750]	BT 0.035 (1.141)	DT 0.003 (1.095)	loss 7.001 (7.001)	prob 2.917 (2.917)	GS 31.953 (31.953)	mem 39.850
Train: [42][700/750]	BT 0.027 (1.142)	DT 0.001 (1.096)	loss 6.876 (6.876)	prob 3.011 (3.011)	GS 32.281 (32.281)	mem 39.869
Train: [42][705/750]	BT 0.047 (1.145)	DT 0.005 (1.099)	loss 6.852 (6.852)	prob 2.277 (2.277)	GS 32.188 (32.188)	mem 40.037
Train: [42][710/750]	BT 2.215 (1.145)	DT 2.170 (1.099)	loss 6.836 (6.836)	prob 2.552 (2.552)	GS 36.047 (36.047)	mem 39.914
Train: [42][715/750]	BT 0.033 (1.150)	DT 0.003 (1.103)	loss 7.020 (7.020)	prob 2.345 (2.345)	GS 28.391 (28.391)	mem 39.912
Train: [42][720/750]	BT 3.837 (1.147)	DT 3.782 (1.101)	loss 6.828 (6.828)	prob 2.709 (2.709)	GS 31.188 (31.188)	mem 39.991
Train: [42][725/750]	BT 0.039 (1.144)	DT 0.001 (1.098)	loss 7.126 (7.126)	prob 2.450 (2.450)	GS 30.859 (30.859)	mem 39.884
Train: [42][730/750]	BT 0.032 (1.144)	DT 0.001 (1.098)	loss 7.147 (7.147)	prob 2.285 (2.285)	GS 33.281 (33.281)	mem 39.690
Train: [42][735/750]	BT 0.021 (1.143)	DT 0.001 (1.097)	loss 6.715 (6.715)	prob 2.927 (2.927)	GS 29.672 (29.672)	mem 36.663
Train: [42][740/750]	BT 0.026 (1.145)	DT 0.001 (1.099)	loss 6.915 (6.915)	prob 1.600 (1.600)	GS 36.719 (36.719)	mem 10.509
Train: [42][745/750]	BT 0.029 (1.139)	DT 0.001 (1.093)	loss 6.839 (6.839)	prob 2.995 (2.995)	GS 32.969 (32.969)	mem 10.541
Train: [42][750/750]	BT 1.287 (1.133)	DT 1.263 (1.087)	loss 6.807 (6.807)	prob 2.331 (2.331)	GS 31.125 (31.125)	mem 10.507
Train: [42][755/750]	BT 0.020 (1.126)	DT 0.001 (1.080)	loss 6.600 (6.600)	prob 3.226 (3.226)	GS 33.406 (33.406)	mem 10.508
epoch 42, total time 851.46
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [43][1/750]	BT 22.041 (22.041)	DT 21.993 (21.993)	loss 6.767 (6.767)	prob 2.800 (2.800)	GS 34.781 (34.781)	mem 38.943
Train: [43][5/750]	BT 0.051 (4.475)	DT 0.019 (4.408)	loss 6.701 (6.701)	prob 3.288 (3.288)	GS 31.578 (31.578)	mem 38.778
Train: [43][10/750]	BT 0.040 (2.596)	DT 0.002 (2.540)	loss 6.684 (6.684)	prob 2.649 (2.649)	GS 35.016 (35.016)	mem 38.636
Train: [43][15/750]	BT 0.032 (2.203)	DT 0.001 (2.154)	loss 6.843 (6.843)	prob 2.646 (2.646)	GS 29.531 (29.531)	mem 38.729
Train: [43][20/750]	BT 7.133 (2.095)	DT 7.087 (2.046)	loss 6.732 (6.732)	prob 2.572 (2.572)	GS 34.250 (34.250)	mem 38.911
Train: [43][25/750]	BT 2.868 (1.796)	DT 2.776 (1.748)	loss 6.581 (6.581)	prob 2.767 (2.767)	GS 34.562 (34.562)	mem 38.977
Train: [43][30/750]	BT 0.032 (1.745)	DT 0.001 (1.700)	loss 6.826 (6.826)	prob 3.328 (3.328)	GS 33.016 (33.016)	mem 38.934
Train: [43][35/750]	BT 0.052 (1.604)	DT 0.001 (1.560)	loss 6.803 (6.803)	prob 2.866 (2.866)	GS 30.891 (30.891)	mem 38.958
Train: [43][40/750]	BT 0.023 (1.659)	DT 0.001 (1.615)	loss 6.859 (6.859)	prob 1.975 (1.975)	GS 31.438 (31.438)	mem 39.163
Train: [43][45/750]	BT 0.029 (1.528)	DT 0.001 (1.484)	loss 7.125 (7.125)	prob 2.302 (2.302)	GS 28.562 (28.562)	mem 38.991
Train: [43][50/750]	BT 9.423 (1.569)	DT 9.385 (1.523)	loss 6.873 (6.873)	prob 2.940 (2.940)	GS 34.938 (34.938)	mem 39.024
Train: [43][55/750]	BT 0.056 (1.431)	DT 0.001 (1.386)	loss 6.979 (6.979)	prob 2.597 (2.597)	GS 30.188 (30.188)	mem 39.119
Train: [43][60/750]	BT 0.109 (1.410)	DT 0.002 (1.365)	loss 6.914 (6.914)	prob 3.114 (3.114)	GS 32.859 (32.859)	mem 39.272
Train: [43][65/750]	BT 0.079 (1.391)	DT 0.005 (1.345)	loss 6.676 (6.676)	prob 2.682 (2.682)	GS 30.875 (30.875)	mem 39.183
Train: [43][70/750]	BT 0.099 (1.353)	DT 0.033 (1.306)	loss 6.792 (6.792)	prob 1.980 (1.980)	GS 33.031 (33.031)	mem 39.169
Train: [43][75/750]	BT 0.026 (1.478)	DT 0.002 (1.432)	loss 6.931 (6.931)	prob 2.425 (2.425)	GS 36.359 (36.359)	mem 39.182
Train: [43][80/750]	BT 0.031 (1.388)	DT 0.001 (1.343)	loss 6.726 (6.726)	prob 2.917 (2.917)	GS 38.156 (38.156)	mem 39.195
Train: [43][85/750]	BT 0.065 (1.310)	DT 0.009 (1.264)	loss 6.789 (6.789)	prob 2.941 (2.941)	GS 32.500 (32.500)	mem 39.230
Train: [43][90/750]	BT 0.033 (1.379)	DT 0.002 (1.335)	loss 7.005 (7.005)	prob 1.907 (1.907)	GS 37.609 (37.609)	mem 39.528
Train: [43][95/750]	BT 0.099 (1.310)	DT 0.005 (1.265)	loss 7.069 (7.069)	prob 2.621 (2.621)	GS 34.969 (34.969)	mem 39.598
Train: [43][100/750]	BT 0.031 (1.363)	DT 0.001 (1.317)	loss 6.662 (6.662)	prob 2.105 (2.105)	GS 33.203 (33.203)	mem 39.426
Train: [43][105/750]	BT 0.033 (1.300)	DT 0.001 (1.255)	loss 6.895 (6.895)	prob 3.036 (3.036)	GS 34.453 (34.453)	mem 39.435
Train: [43][110/750]	BT 13.428 (1.366)	DT 13.377 (1.320)	loss 6.635 (6.635)	prob 3.551 (3.551)	GS 34.875 (34.875)	mem 39.612
Train: [43][115/750]	BT 0.028 (1.308)	DT 0.001 (1.263)	loss 6.771 (6.771)	prob 3.101 (3.101)	GS 30.562 (30.562)	mem 39.456
Train: [43][120/750]	BT 0.027 (1.256)	DT 0.001 (1.210)	loss 6.725 (6.725)	prob 2.676 (2.676)	GS 34.203 (34.203)	mem 39.456
Train: [43][125/750]	BT 0.051 (1.307)	DT 0.001 (1.261)	loss 6.931 (6.931)	prob 2.484 (2.484)	GS 32.875 (32.875)	mem 39.704
Train: [43][130/750]	BT 0.076 (1.259)	DT 0.017 (1.213)	loss 6.832 (6.832)	prob 2.703 (2.703)	GS 34.500 (34.500)	mem 39.678
Train: [43][135/750]	BT 0.035 (1.300)	DT 0.003 (1.254)	loss 6.870 (6.870)	prob 2.058 (2.058)	GS 30.812 (30.812)	mem 39.786
Train: [43][140/750]	BT 0.043 (1.263)	DT 0.001 (1.217)	loss 7.116 (7.116)	prob 2.288 (2.288)	GS 33.094 (33.094)	mem 39.626
Train: [43][145/750]	BT 0.032 (1.220)	DT 0.001 (1.175)	loss 7.199 (7.199)	prob 2.481 (2.481)	GS 43.516 (43.516)	mem 39.632
Train: [43][150/750]	BT 1.810 (1.252)	DT 1.781 (1.207)	loss 6.844 (6.844)	prob 2.581 (2.581)	GS 33.812 (33.812)	mem 39.664
Train: [43][155/750]	BT 0.030 (1.213)	DT 0.001 (1.168)	loss 7.074 (7.074)	prob 2.152 (2.152)	GS 31.516 (31.516)	mem 39.606
Train: [43][160/750]	BT 1.555 (1.260)	DT 1.523 (1.215)	loss 6.861 (6.861)	prob 2.521 (2.521)	GS 36.297 (36.297)	mem 39.591
Train: [43][165/750]	BT 0.053 (1.225)	DT 0.001 (1.181)	loss 6.904 (6.904)	prob 3.029 (3.029)	GS 36.141 (36.141)	mem 39.593
Train: [43][170/750]	BT 6.528 (1.242)	DT 6.496 (1.198)	loss 6.800 (6.800)	prob 2.256 (2.256)	GS 32.109 (32.109)	mem 39.618
Train: [43][175/750]	BT 0.035 (1.236)	DT 0.002 (1.192)	loss 7.113 (7.113)	prob 2.478 (2.478)	GS 36.969 (36.969)	mem 39.654
Train: [43][180/750]	BT 4.046 (1.226)	DT 3.994 (1.181)	loss 7.191 (7.191)	prob 1.528 (1.528)	GS 33.516 (33.516)	mem 39.728
Train: [43][185/750]	BT 0.041 (1.233)	DT 0.002 (1.188)	loss 6.763 (6.763)	prob 3.398 (3.398)	GS 32.781 (32.781)	mem 39.836
Train: [43][190/750]	BT 0.955 (1.212)	DT 0.910 (1.167)	loss 7.062 (7.062)	prob 2.490 (2.490)	GS 35.688 (35.688)	mem 39.727
Train: [43][195/750]	BT 0.122 (1.215)	DT 0.004 (1.170)	loss 6.880 (6.880)	prob 2.573 (2.573)	GS 32.328 (32.328)	mem 39.865
Train: [43][200/750]	BT 0.064 (1.220)	DT 0.001 (1.175)	loss 6.756 (6.756)	prob 2.546 (2.546)	GS 34.375 (34.375)	mem 39.732
Train: [43][205/750]	BT 0.080 (1.207)	DT 0.030 (1.162)	loss 7.053 (7.053)	prob 2.428 (2.428)	GS 31.203 (31.203)	mem 39.774
Train: [43][210/750]	BT 0.045 (1.246)	DT 0.004 (1.201)	loss 6.844 (6.844)	prob 2.110 (2.110)	GS 37.188 (37.188)	mem 39.811
Train: [43][215/750]	BT 0.106 (1.218)	DT 0.021 (1.173)	loss 6.885 (6.885)	prob 2.491 (2.491)	GS 32.594 (32.594)	mem 39.905
Train: [43][220/750]	BT 12.908 (1.250)	DT 12.879 (1.205)	loss 6.938 (6.938)	prob 2.251 (2.251)	GS 33.703 (33.703)	mem 39.763
Train: [43][225/750]	BT 0.029 (1.223)	DT 0.001 (1.178)	loss 6.759 (6.759)	prob 2.215 (2.215)	GS 29.609 (29.609)	mem 39.764
Train: [43][230/750]	BT 0.030 (1.197)	DT 0.001 (1.153)	loss 6.636 (6.636)	prob 2.401 (2.401)	GS 35.578 (35.578)	mem 39.765
Train: [43][235/750]	BT 0.052 (1.222)	DT 0.001 (1.177)	loss 6.947 (6.947)	prob 2.493 (2.493)	GS 29.891 (29.891)	mem 39.850
Train: [43][240/750]	BT 0.023 (1.197)	DT 0.001 (1.153)	loss 6.827 (6.827)	prob 2.429 (2.429)	GS 32.844 (32.844)	mem 39.850
Train: [43][245/750]	BT 0.115 (1.207)	DT 0.016 (1.162)	loss 7.215 (7.215)	prob 2.011 (2.011)	GS 30.750 (30.750)	mem 39.822
Train: [43][250/750]	BT 0.043 (1.187)	DT 0.002 (1.143)	loss 6.864 (6.864)	prob 2.984 (2.984)	GS 30.969 (30.969)	mem 39.902
Train: [43][255/750]	BT 0.145 (1.180)	DT 0.013 (1.135)	loss 6.859 (6.859)	prob 2.308 (2.308)	GS 33.969 (33.969)	mem 39.825
Train: [43][260/750]	BT 1.201 (1.188)	DT 1.175 (1.143)	loss 6.954 (6.954)	prob 2.381 (2.381)	GS 31.328 (31.328)	mem 39.821
Train: [43][265/750]	BT 0.024 (1.175)	DT 0.001 (1.131)	loss 6.946 (6.946)	prob 2.786 (2.786)	GS 32.156 (32.156)	mem 39.885
Train: [43][270/750]	BT 0.038 (1.184)	DT 0.002 (1.140)	loss 6.945 (6.945)	prob 2.375 (2.375)	GS 35.453 (35.453)	mem 39.840
Train: [43][275/750]	BT 0.025 (1.175)	DT 0.001 (1.131)	loss 6.781 (6.781)	prob 2.588 (2.588)	GS 31.250 (31.250)	mem 39.917
Train: [43][280/750]	BT 3.953 (1.183)	DT 3.893 (1.139)	loss 6.791 (6.791)	prob 2.911 (2.911)	GS 31.031 (31.031)	mem 40.062
Train: [43][285/750]	BT 0.093 (1.187)	DT 0.017 (1.143)	loss 6.935 (6.935)	prob 2.756 (2.756)	GS 32.031 (32.031)	mem 39.961
Train: [43][290/750]	BT 0.035 (1.178)	DT 0.001 (1.134)	loss 6.773 (6.773)	prob 2.080 (2.080)	GS 34.969 (34.969)	mem 40.238
Train: [43][295/750]	BT 0.100 (1.181)	DT 0.040 (1.137)	loss 7.385 (7.385)	prob 2.525 (2.525)	GS 35.281 (35.281)	mem 39.917
Train: [43][300/750]	BT 4.775 (1.192)	DT 4.740 (1.147)	loss 6.969 (6.969)	prob 2.774 (2.774)	GS 32.312 (32.312)	mem 39.913
Train: [43][305/750]	BT 0.148 (1.181)	DT 0.006 (1.137)	loss 6.847 (6.847)	prob 2.882 (2.882)	GS 30.578 (30.578)	mem 39.982
Train: [43][310/750]	BT 0.032 (1.190)	DT 0.001 (1.145)	loss 6.819 (6.819)	prob 2.880 (2.880)	GS 33.844 (33.844)	mem 39.858
Train: [43][315/750]	BT 0.073 (1.179)	DT 0.001 (1.134)	loss 6.804 (6.804)	prob 2.993 (2.993)	GS 33.078 (33.078)	mem 40.167
Train: [43][320/750]	BT 0.032 (1.198)	DT 0.001 (1.153)	loss 6.952 (6.952)	prob 2.688 (2.688)	GS 29.281 (29.281)	mem 39.902
Train: [43][325/750]	BT 0.033 (1.182)	DT 0.002 (1.138)	loss 6.652 (6.652)	prob 3.122 (3.122)	GS 31.078 (31.078)	mem 40.127
Train: [43][330/750]	BT 6.754 (1.197)	DT 6.718 (1.153)	loss 6.648 (6.648)	prob 3.249 (3.249)	GS 36.391 (36.391)	mem 39.946
Train: [43][335/750]	BT 0.047 (1.181)	DT 0.001 (1.136)	loss 6.912 (6.912)	prob 2.753 (2.753)	GS 27.109 (27.109)	mem 39.878
Train: [43][340/750]	BT 0.111 (1.173)	DT 0.083 (1.129)	loss 6.810 (6.810)	prob 2.665 (2.665)	GS 34.594 (34.594)	mem 39.774
Train: [43][345/750]	BT 0.056 (1.185)	DT 0.007 (1.141)	loss 6.975 (6.975)	prob 2.148 (2.148)	GS 30.359 (30.359)	mem 39.913
Train: [43][350/750]	BT 0.116 (1.176)	DT 0.016 (1.132)	loss 6.961 (6.961)	prob 3.072 (3.072)	GS 31.844 (31.844)	mem 39.918
Train: [43][355/750]	BT 0.034 (1.194)	DT 0.001 (1.150)	loss 6.931 (6.931)	prob 2.534 (2.534)	GS 28.516 (28.516)	mem 39.977
Train: [43][360/750]	BT 0.031 (1.178)	DT 0.001 (1.134)	loss 6.731 (6.731)	prob 2.063 (2.063)	GS 32.922 (32.922)	mem 39.978
Train: [43][365/750]	BT 0.046 (1.174)	DT 0.014 (1.130)	loss 6.911 (6.911)	prob 3.206 (3.206)	GS 34.281 (34.281)	mem 39.989
Train: [43][370/750]	BT 0.040 (1.191)	DT 0.009 (1.147)	loss 7.061 (7.061)	prob 2.359 (2.359)	GS 32.531 (32.531)	mem 39.868
Train: [43][375/750]	BT 0.024 (1.176)	DT 0.001 (1.132)	loss 6.916 (6.916)	prob 1.867 (1.867)	GS 31.141 (31.141)	mem 39.873
Train: [43][380/750]	BT 0.021 (1.194)	DT 0.001 (1.150)	loss 6.658 (6.658)	prob 2.788 (2.788)	GS 34.125 (34.125)	mem 39.882
Train: [43][385/750]	BT 0.035 (1.180)	DT 0.001 (1.136)	loss 6.965 (6.965)	prob 2.935 (2.935)	GS 29.688 (29.688)	mem 39.883
Train: [43][390/750]	BT 8.186 (1.191)	DT 8.145 (1.147)	loss 6.909 (6.909)	prob 2.459 (2.459)	GS 31.844 (31.844)	mem 39.974
Train: [43][395/750]	BT 0.024 (1.176)	DT 0.001 (1.133)	loss 6.924 (6.924)	prob 1.913 (1.913)	GS 29.141 (29.141)	mem 39.977
Train: [43][400/750]	BT 2.128 (1.168)	DT 2.077 (1.124)	loss 6.783 (6.783)	prob 2.268 (2.268)	GS 29.359 (29.359)	mem 40.083
Train: [43][405/750]	BT 0.031 (1.174)	DT 0.001 (1.131)	loss 6.846 (6.846)	prob 2.313 (2.313)	GS 30.281 (30.281)	mem 40.011
Train: [43][410/750]	BT 0.079 (1.164)	DT 0.031 (1.120)	loss 7.094 (7.094)	prob 2.266 (2.266)	GS 33.688 (33.688)	mem 39.926
Train: [43][415/750]	BT 0.037 (1.177)	DT 0.002 (1.133)	loss 7.126 (7.126)	prob 2.278 (2.278)	GS 29.266 (29.266)	mem 39.953
Train: [43][420/750]	BT 0.033 (1.163)	DT 0.001 (1.120)	loss 6.861 (6.861)	prob 3.113 (3.113)	GS 35.547 (35.547)	mem 39.918
Train: [43][425/750]	BT 0.040 (1.151)	DT 0.008 (1.107)	loss 6.956 (6.956)	prob 2.492 (2.492)	GS 29.328 (29.328)	mem 39.856
Train: [43][430/750]	BT 0.033 (1.170)	DT 0.001 (1.127)	loss 6.983 (6.983)	prob 2.079 (2.079)	GS 36.438 (36.438)	mem 40.265
Train: [43][435/750]	BT 0.030 (1.157)	DT 0.001 (1.114)	loss 7.276 (7.276)	prob 2.240 (2.240)	GS 33.672 (33.672)	mem 39.917
Train: [43][440/750]	BT 0.071 (1.176)	DT 0.002 (1.133)	loss 6.842 (6.842)	prob 2.798 (2.798)	GS 30.312 (30.312)	mem 39.850
Train: [43][445/750]	BT 0.063 (1.163)	DT 0.014 (1.120)	loss 6.773 (6.773)	prob 2.795 (2.795)	GS 23.359 (23.359)	mem 39.852
Train: [43][450/750]	BT 12.385 (1.178)	DT 12.348 (1.135)	loss 6.870 (6.870)	prob 2.741 (2.741)	GS 33.734 (33.734)	mem 39.911
Train: [43][455/750]	BT 0.030 (1.166)	DT 0.001 (1.123)	loss 6.967 (6.967)	prob 2.690 (2.690)	GS 31.812 (31.812)	mem 39.911
Train: [43][460/750]	BT 0.052 (1.153)	DT 0.001 (1.110)	loss 6.805 (6.805)	prob 2.730 (2.730)	GS 33.719 (33.719)	mem 39.968
Train: [43][465/750]	BT 0.031 (1.171)	DT 0.002 (1.128)	loss 6.995 (6.995)	prob 2.335 (2.335)	GS 33.609 (33.609)	mem 39.984
Train: [43][470/750]	BT 0.033 (1.159)	DT 0.001 (1.116)	loss 6.790 (6.790)	prob 2.234 (2.234)	GS 33.859 (33.859)	mem 39.915
Train: [43][475/750]	BT 0.024 (1.171)	DT 0.001 (1.128)	loss 6.913 (6.913)	prob 2.339 (2.339)	GS 31.797 (31.797)	mem 39.940
Train: [43][480/750]	BT 0.040 (1.159)	DT 0.001 (1.117)	loss 7.471 (7.471)	prob 1.755 (1.755)	GS 37.547 (37.547)	mem 39.939
Train: [43][485/750]	BT 0.087 (1.148)	DT 0.007 (1.105)	loss 6.936 (6.936)	prob 2.996 (2.996)	GS 29.734 (29.734)	mem 39.938
Train: [43][490/750]	BT 0.050 (1.161)	DT 0.003 (1.118)	loss 7.189 (7.189)	prob 2.492 (2.492)	GS 31.562 (31.562)	mem 39.943
Train: [43][495/750]	BT 0.096 (1.150)	DT 0.024 (1.107)	loss 6.736 (6.736)	prob 3.227 (3.227)	GS 27.469 (27.469)	mem 39.944
Train: [43][500/750]	BT 0.032 (1.163)	DT 0.001 (1.120)	loss 6.938 (6.938)	prob 2.566 (2.566)	GS 31.406 (31.406)	mem 39.965
Train: [43][505/750]	BT 0.059 (1.152)	DT 0.001 (1.109)	loss 6.710 (6.710)	prob 3.096 (3.096)	GS 33.609 (33.609)	mem 39.965
Train: [43][510/750]	BT 12.631 (1.168)	DT 12.599 (1.125)	loss 6.636 (6.636)	prob 1.973 (1.973)	GS 32.859 (32.859)	mem 39.977
Train: [43][515/750]	BT 0.088 (1.157)	DT 0.001 (1.114)	loss 6.935 (6.935)	prob 2.400 (2.400)	GS 29.125 (29.125)	mem 39.963
Train: [43][520/750]	BT 0.048 (1.147)	DT 0.004 (1.104)	loss 6.834 (6.834)	prob 2.845 (2.845)	GS 32.266 (32.266)	mem 40.084
Train: [43][525/750]	BT 0.065 (1.158)	DT 0.005 (1.115)	loss 6.875 (6.875)	prob 2.933 (2.933)	GS 32.328 (32.328)	mem 39.948
Train: [43][530/750]	BT 0.032 (1.147)	DT 0.001 (1.104)	loss 6.878 (6.878)	prob 2.553 (2.553)	GS 36.500 (36.500)	mem 39.950
Train: [43][535/750]	BT 0.067 (1.161)	DT 0.005 (1.118)	loss 6.954 (6.954)	prob 2.052 (2.052)	GS 30.484 (30.484)	mem 39.893
Train: [43][540/750]	BT 0.091 (1.151)	DT 0.002 (1.107)	loss 6.903 (6.903)	prob 2.517 (2.517)	GS 30.953 (30.953)	mem 39.895
Train: [43][545/750]	BT 0.038 (1.142)	DT 0.007 (1.098)	loss 6.892 (6.892)	prob 2.468 (2.468)	GS 26.531 (26.531)	mem 39.897
Train: [43][550/750]	BT 0.021 (1.157)	DT 0.001 (1.114)	loss 7.041 (7.041)	prob 1.908 (1.908)	GS 33.297 (33.297)	mem 39.928
Train: [43][555/750]	BT 0.078 (1.147)	DT 0.001 (1.104)	loss 6.925 (6.925)	prob 2.473 (2.473)	GS 30.875 (30.875)	mem 39.964
Train: [43][560/750]	BT 0.033 (1.154)	DT 0.001 (1.111)	loss 6.776 (6.776)	prob 2.385 (2.385)	GS 35.312 (35.312)	mem 40.024
Train: [43][565/750]	BT 0.074 (1.145)	DT 0.004 (1.101)	loss 7.030 (7.030)	prob 2.902 (2.902)	GS 31.672 (31.672)	mem 39.896
Train: [43][570/750]	BT 12.868 (1.158)	DT 12.828 (1.114)	loss 6.827 (6.827)	prob 2.359 (2.359)	GS 34.562 (34.562)	mem 39.840
Train: [43][575/750]	BT 0.028 (1.148)	DT 0.001 (1.104)	loss 6.919 (6.919)	prob 2.558 (2.558)	GS 32.297 (32.297)	mem 39.904
Train: [43][580/750]	BT 3.716 (1.145)	DT 3.676 (1.101)	loss 6.728 (6.728)	prob 2.528 (2.528)	GS 36.031 (36.031)	mem 39.918
Train: [43][585/750]	BT 0.030 (1.153)	DT 0.001 (1.110)	loss 6.734 (6.734)	prob 2.477 (2.477)	GS 32.531 (32.531)	mem 39.894
Train: [43][590/750]	BT 0.034 (1.145)	DT 0.011 (1.102)	loss 6.962 (6.962)	prob 2.840 (2.840)	GS 32.641 (32.641)	mem 39.823
Train: [43][595/750]	BT 0.056 (1.152)	DT 0.006 (1.109)	loss 6.756 (6.756)	prob 2.021 (2.021)	GS 30.156 (30.156)	mem 39.894
Train: [43][600/750]	BT 3.110 (1.148)	DT 3.045 (1.105)	loss 7.217 (7.217)	prob 1.983 (1.983)	GS 31.938 (31.938)	mem 39.954
Train: [43][605/750]	BT 0.038 (1.141)	DT 0.002 (1.098)	loss 6.791 (6.791)	prob 1.867 (1.867)	GS 30.250 (30.250)	mem 39.937
Train: [43][610/750]	BT 0.032 (1.150)	DT 0.001 (1.107)	loss 6.883 (6.883)	prob 2.408 (2.408)	GS 36.641 (36.641)	mem 39.959
Train: [43][615/750]	BT 0.034 (1.143)	DT 0.002 (1.099)	loss 7.027 (7.027)	prob 2.112 (2.112)	GS 32.859 (32.859)	mem 40.071
Train: [43][620/750]	BT 0.049 (1.151)	DT 0.001 (1.108)	loss 6.956 (6.956)	prob 2.063 (2.063)	GS 32.469 (32.469)	mem 39.980
Train: [43][625/750]	BT 0.029 (1.143)	DT 0.001 (1.100)	loss 6.826 (6.826)	prob 2.461 (2.461)	GS 31.969 (31.969)	mem 39.930
Train: [43][630/750]	BT 9.223 (1.151)	DT 9.177 (1.108)	loss 6.766 (6.766)	prob 2.503 (2.503)	GS 33.281 (33.281)	mem 39.956
Train: [43][635/750]	BT 0.037 (1.143)	DT 0.002 (1.099)	loss 6.831 (6.831)	prob 2.690 (2.690)	GS 32.406 (32.406)	mem 39.957
Train: [43][640/750]	BT 0.046 (1.140)	DT 0.003 (1.097)	loss 6.816 (6.816)	prob 2.675 (2.675)	GS 34.609 (34.609)	mem 40.118
Train: [43][645/750]	BT 0.038 (1.146)	DT 0.001 (1.103)	loss 6.882 (6.882)	prob 2.867 (2.867)	GS 30.531 (30.531)	mem 40.004
Train: [43][650/750]	BT 0.034 (1.143)	DT 0.002 (1.100)	loss 7.023 (7.023)	prob 2.534 (2.534)	GS 33.453 (33.453)	mem 40.044
Train: [43][655/750]	BT 0.120 (1.146)	DT 0.003 (1.103)	loss 6.635 (6.635)	prob 2.463 (2.463)	GS 28.891 (28.891)	mem 39.982
Train: [43][660/750]	BT 4.736 (1.145)	DT 4.714 (1.102)	loss 6.837 (6.837)	prob 2.173 (2.173)	GS 31.031 (31.031)	mem 40.039
Train: [43][665/750]	BT 0.035 (1.137)	DT 0.001 (1.093)	loss 6.757 (6.757)	prob 2.198 (2.198)	GS 34.609 (34.609)	mem 39.990
Train: [43][670/750]	BT 0.031 (1.143)	DT 0.001 (1.100)	loss 6.972 (6.972)	prob 1.764 (1.764)	GS 30.359 (30.359)	mem 39.942
Train: [43][675/750]	BT 0.034 (1.139)	DT 0.001 (1.095)	loss 7.037 (7.037)	prob 2.279 (2.279)	GS 30.359 (30.359)	mem 40.011
Train: [43][680/750]	BT 0.070 (1.146)	DT 0.008 (1.103)	loss 6.649 (6.649)	prob 3.186 (3.186)	GS 35.562 (35.562)	mem 40.014
Train: [43][685/750]	BT 0.027 (1.142)	DT 0.004 (1.098)	loss 6.670 (6.670)	prob 2.562 (2.562)	GS 31.734 (31.734)	mem 40.016
Train: [43][690/750]	BT 12.286 (1.151)	DT 12.254 (1.108)	loss 6.787 (6.787)	prob 2.667 (2.667)	GS 34.516 (34.516)	mem 40.022
Train: [43][695/750]	BT 0.033 (1.143)	DT 0.001 (1.100)	loss 6.936 (6.936)	prob 2.707 (2.707)	GS 28.844 (28.844)	mem 40.023
Train: [43][700/750]	BT 0.075 (1.136)	DT 0.001 (1.093)	loss 6.798 (6.798)	prob 2.311 (2.311)	GS 32.531 (32.531)	mem 40.061
Train: [43][705/750]	BT 0.041 (1.143)	DT 0.002 (1.100)	loss 7.017 (7.017)	prob 2.260 (2.260)	GS 27.922 (27.922)	mem 40.096
Train: [43][710/750]	BT 0.045 (1.135)	DT 0.004 (1.092)	loss 6.910 (6.910)	prob 2.657 (2.657)	GS 31.312 (31.312)	mem 40.130
Train: [43][715/750]	BT 0.064 (1.142)	DT 0.001 (1.099)	loss 6.713 (6.713)	prob 3.142 (3.142)	GS 34.484 (34.484)	mem 40.039
Train: [43][720/750]	BT 3.979 (1.140)	DT 3.947 (1.097)	loss 6.750 (6.750)	prob 3.028 (3.028)	GS 36.281 (36.281)	mem 40.042
Train: [43][725/750]	BT 0.069 (1.133)	DT 0.008 (1.090)	loss 7.035 (7.035)	prob 2.739 (2.739)	GS 24.250 (24.250)	mem 40.042
Train: [43][730/750]	BT 0.053 (1.137)	DT 0.002 (1.094)	loss 6.942 (6.942)	prob 2.648 (2.648)	GS 35.203 (35.203)	mem 39.890
Train: [43][735/750]	BT 0.032 (1.135)	DT 0.001 (1.091)	loss 6.796 (6.796)	prob 2.301 (2.301)	GS 27.094 (27.094)	mem 39.691
Train: [43][740/750]	BT 0.023 (1.135)	DT 0.001 (1.092)	loss 6.864 (6.864)	prob 2.348 (2.348)	GS 32.578 (32.578)	mem 13.563
Train: [43][745/750]	BT 0.024 (1.132)	DT 0.001 (1.089)	loss 7.046 (7.046)	prob 2.999 (2.999)	GS 32.688 (32.688)	mem 7.619
Train: [43][750/750]	BT 0.031 (1.124)	DT 0.001 (1.082)	loss 7.035 (7.035)	prob 2.471 (2.471)	GS 36.969 (36.969)	mem 7.619
Train: [43][755/750]	BT 0.033 (1.117)	DT 0.001 (1.074)	loss 6.968 (6.968)	prob 2.416 (2.416)	GS 26.938 (26.938)	mem 7.637
epoch 43, total time 845.64
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [44][1/750]	BT 23.161 (23.161)	DT 23.095 (23.095)	loss 6.737 (6.737)	prob 2.262 (2.262)	GS 29.375 (29.375)	mem 38.660
Train: [44][5/750]	BT 0.030 (5.022)	DT 0.001 (4.978)	loss 6.812 (6.812)	prob 2.567 (2.567)	GS 28.188 (28.188)	mem 38.704
Train: [44][10/750]	BT 0.031 (2.638)	DT 0.001 (2.594)	loss 6.811 (6.811)	prob 2.157 (2.157)	GS 33.672 (33.672)	mem 38.722
Train: [44][15/750]	BT 0.030 (2.734)	DT 0.001 (2.693)	loss 6.862 (6.862)	prob 2.451 (2.451)	GS 28.594 (28.594)	mem 38.919
Train: [44][20/750]	BT 0.078 (2.117)	DT 0.001 (2.076)	loss 6.837 (6.837)	prob 2.442 (2.442)	GS 35.172 (35.172)	mem 38.961
Train: [44][25/750]	BT 0.033 (1.703)	DT 0.001 (1.663)	loss 6.711 (6.711)	prob 2.267 (2.267)	GS 28.797 (28.797)	mem 38.991
Train: [44][30/750]	BT 3.790 (1.931)	DT 3.746 (1.889)	loss 6.701 (6.701)	prob 3.181 (3.181)	GS 33.250 (33.250)	mem 39.036
Train: [44][35/750]	BT 0.026 (1.661)	DT 0.002 (1.620)	loss 6.793 (6.793)	prob 2.936 (2.936)	GS 29.859 (29.859)	mem 38.994
Train: [44][40/750]	BT 6.182 (1.837)	DT 6.157 (1.796)	loss 6.700 (6.700)	prob 2.355 (2.355)	GS 36.000 (36.000)	mem 39.085
Train: [44][45/750]	BT 0.046 (1.638)	DT 0.002 (1.598)	loss 7.047 (7.047)	prob 2.680 (2.680)	GS 33.406 (33.406)	mem 39.162
Train: [44][50/750]	BT 10.933 (1.697)	DT 10.901 (1.657)	loss 6.709 (6.709)	prob 2.900 (2.900)	GS 38.266 (38.266)	mem 39.371
Train: [44][55/750]	BT 0.047 (1.594)	DT 0.017 (1.554)	loss 6.854 (6.854)	prob 2.810 (2.810)	GS 33.969 (33.969)	mem 39.310
Train: [44][60/750]	BT 0.049 (1.466)	DT 0.005 (1.425)	loss 6.789 (6.789)	prob 2.512 (2.512)	GS 34.219 (34.219)	mem 39.314
Train: [44][65/750]	BT 0.043 (1.567)	DT 0.003 (1.526)	loss 6.985 (6.985)	prob 2.364 (2.364)	GS 27.641 (27.641)	mem 39.628
Train: [44][70/750]	BT 0.026 (1.480)	DT 0.001 (1.440)	loss 6.607 (6.607)	prob 2.754 (2.754)	GS 34.500 (34.500)	mem 39.595
Train: [44][75/750]	BT 0.042 (1.480)	DT 0.002 (1.440)	loss 7.043 (7.043)	prob 2.146 (2.146)	GS 29.922 (29.922)	mem 39.671
Train: [44][80/750]	BT 0.032 (1.460)	DT 0.001 (1.420)	loss 6.742 (6.742)	prob 2.697 (2.697)	GS 33.266 (33.266)	mem 39.690
Train: [44][85/750]	BT 0.039 (1.376)	DT 0.002 (1.336)	loss 6.891 (6.891)	prob 2.163 (2.163)	GS 36.984 (36.984)	mem 39.692
Train: [44][90/750]	BT 0.204 (1.446)	DT 0.010 (1.405)	loss 6.815 (6.815)	prob 2.485 (2.485)	GS 26.766 (26.766)	mem 39.646
Train: [44][95/750]	BT 0.035 (1.373)	DT 0.002 (1.331)	loss 7.134 (7.134)	prob 2.035 (2.035)	GS 27.141 (27.141)	mem 39.715
Train: [44][100/750]	BT 5.268 (1.447)	DT 5.237 (1.406)	loss 6.683 (6.683)	prob 2.987 (2.987)	GS 36.125 (36.125)	mem 39.685
Train: [44][105/750]	BT 0.081 (1.381)	DT 0.002 (1.339)	loss 6.890 (6.890)	prob 2.522 (2.522)	GS 27.438 (27.438)	mem 39.718
Train: [44][110/750]	BT 7.877 (1.391)	DT 7.823 (1.350)	loss 6.828 (6.828)	prob 2.812 (2.812)	GS 34.734 (34.734)	mem 39.701
Train: [44][115/750]	BT 0.027 (1.365)	DT 0.001 (1.324)	loss 6.877 (6.877)	prob 2.628 (2.628)	GS 34.203 (34.203)	mem 39.713
Train: [44][120/750]	BT 0.037 (1.310)	DT 0.001 (1.269)	loss 6.933 (6.933)	prob 2.310 (2.310)	GS 34.609 (34.609)	mem 39.807
Train: [44][125/750]	BT 0.022 (1.371)	DT 0.001 (1.330)	loss 6.964 (6.964)	prob 2.150 (2.150)	GS 30.500 (30.500)	mem 39.733
Train: [44][130/750]	BT 0.035 (1.320)	DT 0.001 (1.279)	loss 6.690 (6.690)	prob 2.650 (2.650)	GS 29.734 (29.734)	mem 39.734
Train: [44][135/750]	BT 0.084 (1.329)	DT 0.002 (1.288)	loss 6.659 (6.659)	prob 2.814 (2.814)	GS 31.891 (31.891)	mem 39.644
Train: [44][140/750]	BT 0.066 (1.321)	DT 0.001 (1.280)	loss 6.965 (6.965)	prob 2.204 (2.204)	GS 34.109 (34.109)	mem 39.708
Train: [44][145/750]	BT 0.056 (1.278)	DT 0.011 (1.236)	loss 6.725 (6.725)	prob 2.251 (2.251)	GS 30.938 (30.938)	mem 39.662
Train: [44][150/750]	BT 0.087 (1.312)	DT 0.007 (1.269)	loss 6.844 (6.844)	prob 3.168 (3.168)	GS 30.609 (30.609)	mem 39.718
Train: [44][155/750]	BT 0.036 (1.271)	DT 0.003 (1.228)	loss 6.883 (6.883)	prob 2.538 (2.538)	GS 34.438 (34.438)	mem 39.906
Train: [44][160/750]	BT 9.252 (1.314)	DT 9.210 (1.271)	loss 7.194 (7.194)	prob 2.024 (2.024)	GS 31.516 (31.516)	mem 39.726
Train: [44][165/750]	BT 0.058 (1.275)	DT 0.024 (1.232)	loss 7.298 (7.298)	prob 1.665 (1.665)	GS 37.984 (37.984)	mem 39.728
Train: [44][170/750]	BT 2.317 (1.253)	DT 2.280 (1.210)	loss 6.714 (6.714)	prob 2.707 (2.707)	GS 33.438 (33.438)	mem 39.740
Train: [44][175/750]	BT 0.025 (1.260)	DT 0.001 (1.217)	loss 6.740 (6.740)	prob 3.120 (3.120)	GS 31.641 (31.641)	mem 39.758
Train: [44][180/750]	BT 0.072 (1.227)	DT 0.012 (1.183)	loss 6.946 (6.946)	prob 2.663 (2.663)	GS 29.906 (29.906)	mem 39.758
Train: [44][185/750]	BT 0.033 (1.265)	DT 0.002 (1.221)	loss 6.748 (6.748)	prob 2.733 (2.733)	GS 29.859 (29.859)	mem 39.795
Train: [44][190/750]	BT 0.068 (1.233)	DT 0.001 (1.189)	loss 6.676 (6.676)	prob 3.086 (3.086)	GS 31.734 (31.734)	mem 39.757
Train: [44][195/750]	BT 0.069 (1.227)	DT 0.030 (1.183)	loss 6.892 (6.892)	prob 2.676 (2.676)	GS 33.250 (33.250)	mem 39.833
Train: [44][200/750]	BT 0.039 (1.241)	DT 0.002 (1.197)	loss 6.878 (6.878)	prob 2.535 (2.535)	GS 34.188 (34.188)	mem 39.999
Train: [44][205/750]	BT 0.037 (1.212)	DT 0.002 (1.168)	loss 7.071 (7.071)	prob 2.439 (2.439)	GS 31.125 (31.125)	mem 40.052
Train: [44][210/750]	BT 0.026 (1.242)	DT 0.001 (1.197)	loss 6.807 (6.807)	prob 2.920 (2.920)	GS 36.516 (36.516)	mem 39.797
Train: [44][215/750]	BT 0.059 (1.218)	DT 0.018 (1.174)	loss 6.817 (6.817)	prob 3.254 (3.254)	GS 29.938 (29.938)	mem 39.813
Train: [44][220/750]	BT 10.278 (1.248)	DT 10.225 (1.203)	loss 6.905 (6.905)	prob 2.216 (2.216)	GS 36.453 (36.453)	mem 39.854
Train: [44][225/750]	BT 0.031 (1.236)	DT 0.006 (1.192)	loss 6.948 (6.948)	prob 2.690 (2.690)	GS 32.531 (32.531)	mem 39.816
Train: [44][230/750]	BT 3.106 (1.224)	DT 3.074 (1.179)	loss 6.874 (6.874)	prob 2.601 (2.601)	GS 33.297 (33.297)	mem 39.717
Train: [44][235/750]	BT 0.044 (1.218)	DT 0.013 (1.173)	loss 6.879 (6.879)	prob 2.553 (2.553)	GS 29.391 (29.391)	mem 40.059
Train: [44][240/750]	BT 0.032 (1.216)	DT 0.001 (1.171)	loss 6.870 (6.870)	prob 2.048 (2.048)	GS 32.953 (32.953)	mem 39.835
Train: [44][245/750]	BT 0.053 (1.221)	DT 0.001 (1.177)	loss 6.802 (6.802)	prob 2.727 (2.727)	GS 31.547 (31.547)	mem 39.837
Train: [44][250/750]	BT 0.023 (1.216)	DT 0.001 (1.171)	loss 6.740 (6.740)	prob 2.690 (2.690)	GS 32.422 (32.422)	mem 39.908
Train: [44][255/750]	BT 0.093 (1.193)	DT 0.015 (1.149)	loss 6.946 (6.946)	prob 2.689 (2.689)	GS 33.203 (33.203)	mem 39.946
Train: [44][260/750]	BT 2.201 (1.222)	DT 2.160 (1.177)	loss 6.791 (6.791)	prob 2.205 (2.205)	GS 32.875 (32.875)	mem 40.057
Train: [44][265/750]	BT 0.114 (1.200)	DT 0.013 (1.155)	loss 6.783 (6.783)	prob 2.526 (2.526)	GS 27.766 (27.766)	mem 39.854
Train: [44][270/750]	BT 0.054 (1.220)	DT 0.004 (1.174)	loss 7.135 (7.135)	prob 1.854 (1.854)	GS 28.844 (28.844)	mem 39.874
Train: [44][275/750]	BT 0.039 (1.205)	DT 0.001 (1.160)	loss 6.785 (6.785)	prob 1.955 (1.955)	GS 33.766 (33.766)	mem 40.001
Train: [44][280/750]	BT 11.925 (1.226)	DT 11.900 (1.181)	loss 6.836 (6.836)	prob 2.738 (2.738)	GS 33.266 (33.266)	mem 39.809
Train: [44][285/750]	BT 0.025 (1.205)	DT 0.002 (1.161)	loss 6.623 (6.623)	prob 2.621 (2.621)	GS 31.797 (31.797)	mem 39.818
Train: [44][290/750]	BT 0.070 (1.185)	DT 0.038 (1.141)	loss 6.849 (6.849)	prob 2.581 (2.581)	GS 33.406 (33.406)	mem 39.875
Train: [44][295/750]	BT 0.021 (1.214)	DT 0.001 (1.170)	loss 6.881 (6.881)	prob 2.713 (2.713)	GS 29.031 (29.031)	mem 39.869
Train: [44][300/750]	BT 0.032 (1.195)	DT 0.001 (1.151)	loss 6.965 (6.965)	prob 2.204 (2.204)	GS 30.609 (30.609)	mem 39.869
Train: [44][305/750]	BT 0.039 (1.220)	DT 0.001 (1.176)	loss 7.053 (7.053)	prob 2.021 (2.021)	GS 31.938 (31.938)	mem 39.895
Train: [44][310/750]	BT 0.032 (1.201)	DT 0.001 (1.157)	loss 6.643 (6.643)	prob 2.840 (2.840)	GS 35.906 (35.906)	mem 39.897
Train: [44][315/750]	BT 0.036 (1.183)	DT 0.004 (1.139)	loss 6.898 (6.898)	prob 2.591 (2.591)	GS 31.969 (31.969)	mem 39.887
Train: [44][320/750]	BT 0.031 (1.207)	DT 0.001 (1.163)	loss 6.903 (6.903)	prob 2.490 (2.490)	GS 33.938 (33.938)	mem 39.841
Train: [44][325/750]	BT 0.079 (1.189)	DT 0.023 (1.145)	loss 7.012 (7.012)	prob 1.810 (1.810)	GS 35.125 (35.125)	mem 39.899
Train: [44][330/750]	BT 0.030 (1.219)	DT 0.001 (1.176)	loss 6.687 (6.687)	prob 3.110 (3.110)	GS 36.859 (36.859)	mem 39.882
Train: [44][335/750]	BT 0.043 (1.202)	DT 0.005 (1.158)	loss 7.089 (7.089)	prob 2.398 (2.398)	GS 34.031 (34.031)	mem 39.919
Train: [44][340/750]	BT 13.643 (1.225)	DT 13.597 (1.181)	loss 6.864 (6.864)	prob 2.663 (2.663)	GS 34.016 (34.016)	mem 39.812
Train: [44][345/750]	BT 0.035 (1.207)	DT 0.001 (1.164)	loss 6.922 (6.922)	prob 2.228 (2.228)	GS 31.078 (31.078)	mem 39.884
Train: [44][350/750]	BT 0.055 (1.191)	DT 0.002 (1.148)	loss 6.860 (6.860)	prob 1.684 (1.684)	GS 34.797 (34.797)	mem 39.749
Train: [44][355/750]	BT 0.028 (1.211)	DT 0.002 (1.167)	loss 6.715 (6.715)	prob 2.554 (2.554)	GS 28.156 (28.156)	mem 39.861
Train: [44][360/750]	BT 0.034 (1.194)	DT 0.001 (1.151)	loss 6.933 (6.933)	prob 2.141 (2.141)	GS 33.297 (33.297)	mem 39.936
Train: [44][365/750]	BT 0.056 (1.204)	DT 0.008 (1.161)	loss 6.931 (6.931)	prob 2.342 (2.342)	GS 28.938 (28.938)	mem 39.966
Train: [44][370/750]	BT 0.051 (1.189)	DT 0.004 (1.146)	loss 6.740 (6.740)	prob 2.312 (2.312)	GS 38.391 (38.391)	mem 40.035
Train: [44][375/750]	BT 0.078 (1.174)	DT 0.024 (1.131)	loss 7.077 (7.077)	prob 2.389 (2.389)	GS 35.062 (35.062)	mem 40.121
Train: [44][380/750]	BT 0.062 (1.201)	DT 0.001 (1.157)	loss 6.680 (6.680)	prob 2.266 (2.266)	GS 27.734 (27.734)	mem 39.928
Train: [44][385/750]	BT 0.034 (1.185)	DT 0.001 (1.142)	loss 6.928 (6.928)	prob 2.510 (2.510)	GS 26.406 (26.406)	mem 40.012
Train: [44][390/750]	BT 0.086 (1.198)	DT 0.009 (1.155)	loss 6.781 (6.781)	prob 2.760 (2.760)	GS 32.609 (32.609)	mem 39.880
Train: [44][395/750]	BT 0.075 (1.184)	DT 0.007 (1.140)	loss 7.140 (7.140)	prob 1.813 (1.813)	GS 32.984 (32.984)	mem 39.824
Train: [44][400/750]	BT 10.246 (1.195)	DT 10.214 (1.152)	loss 7.026 (7.026)	prob 1.832 (1.832)	GS 33.438 (33.438)	mem 39.870
Train: [44][405/750]	BT 0.033 (1.181)	DT 0.002 (1.137)	loss 6.920 (6.920)	prob 2.419 (2.419)	GS 32.594 (32.594)	mem 39.878
Train: [44][410/750]	BT 0.032 (1.167)	DT 0.002 (1.124)	loss 6.695 (6.695)	prob 2.508 (2.508)	GS 38.062 (38.062)	mem 39.965
Train: [44][415/750]	BT 0.033 (1.183)	DT 0.001 (1.139)	loss 7.029 (7.029)	prob 2.197 (2.197)	GS 31.641 (31.641)	mem 39.895
Train: [44][420/750]	BT 0.347 (1.170)	DT 0.316 (1.126)	loss 7.056 (7.056)	prob 2.428 (2.428)	GS 33.172 (33.172)	mem 39.894
Train: [44][425/750]	BT 0.034 (1.184)	DT 0.002 (1.140)	loss 6.939 (6.939)	prob 2.370 (2.370)	GS 35.375 (35.375)	mem 39.942
Train: [44][430/750]	BT 0.054 (1.171)	DT 0.002 (1.127)	loss 6.909 (6.909)	prob 2.469 (2.469)	GS 32.797 (32.797)	mem 39.944
Train: [44][435/750]	BT 0.056 (1.175)	DT 0.001 (1.131)	loss 7.132 (7.132)	prob 2.357 (2.357)	GS 34.031 (34.031)	mem 39.867
Train: [44][440/750]	BT 0.035 (1.181)	DT 0.010 (1.138)	loss 6.747 (6.747)	prob 3.175 (3.175)	GS 33.625 (33.625)	mem 39.874
Train: [44][445/750]	BT 0.072 (1.169)	DT 0.011 (1.125)	loss 6.780 (6.780)	prob 2.749 (2.749)	GS 28.828 (28.828)	mem 39.984
Train: [44][450/750]	BT 0.024 (1.186)	DT 0.001 (1.142)	loss 7.110 (7.110)	prob 1.967 (1.967)	GS 30.375 (30.375)	mem 39.865
Train: [44][455/750]	BT 0.032 (1.173)	DT 0.001 (1.129)	loss 6.877 (6.877)	prob 2.720 (2.720)	GS 38.719 (38.719)	mem 39.865
Train: [44][460/750]	BT 10.189 (1.183)	DT 10.089 (1.139)	loss 6.831 (6.831)	prob 2.345 (2.345)	GS 31.719 (31.719)	mem 40.124
Train: [44][465/750]	BT 0.046 (1.170)	DT 0.012 (1.127)	loss 6.675 (6.675)	prob 2.514 (2.514)	GS 31.234 (31.234)	mem 40.125
Train: [44][470/750]	BT 8.326 (1.176)	DT 8.294 (1.133)	loss 6.784 (6.784)	prob 2.512 (2.512)	GS 36.188 (36.188)	mem 40.101
Train: [44][475/750]	BT 0.032 (1.173)	DT 0.001 (1.129)	loss 6.894 (6.894)	prob 2.039 (2.039)	GS 33.953 (33.953)	mem 39.939
Train: [44][480/750]	BT 0.039 (1.161)	DT 0.007 (1.118)	loss 6.977 (6.977)	prob 2.311 (2.311)	GS 27.719 (27.719)	mem 39.940
Train: [44][485/750]	BT 0.038 (1.174)	DT 0.007 (1.130)	loss 7.168 (7.168)	prob 2.515 (2.515)	GS 26.422 (26.422)	mem 39.925
Train: [44][490/750]	BT 0.025 (1.162)	DT 0.001 (1.119)	loss 6.840 (6.840)	prob 2.823 (2.823)	GS 37.234 (37.234)	mem 39.976
Train: [44][495/750]	BT 0.046 (1.168)	DT 0.005 (1.124)	loss 6.928 (6.928)	prob 2.312 (2.312)	GS 27.469 (27.469)	mem 39.926
Train: [44][500/750]	BT 0.085 (1.166)	DT 0.007 (1.123)	loss 6.710 (6.710)	prob 2.696 (2.696)	GS 32.047 (32.047)	mem 39.820
Train: [44][505/750]	BT 0.049 (1.155)	DT 0.007 (1.112)	loss 6.872 (6.872)	prob 2.730 (2.730)	GS 28.938 (28.938)	mem 39.822
Train: [44][510/750]	BT 0.141 (1.166)	DT 0.009 (1.123)	loss 6.985 (6.985)	prob 1.849 (1.849)	GS 34.672 (34.672)	mem 39.983
Train: [44][515/750]	BT 0.074 (1.156)	DT 0.014 (1.112)	loss 6.814 (6.814)	prob 3.014 (3.014)	GS 31.000 (31.000)	mem 39.842
Train: [44][520/750]	BT 2.568 (1.171)	DT 2.536 (1.128)	loss 6.984 (6.984)	prob 2.567 (2.567)	GS 35.062 (35.062)	mem 39.942
Train: [44][525/750]	BT 0.032 (1.160)	DT 0.001 (1.117)	loss 7.107 (7.107)	prob 2.727 (2.727)	GS 27.219 (27.219)	mem 39.980
Train: [44][530/750]	BT 7.713 (1.171)	DT 7.670 (1.127)	loss 6.945 (6.945)	prob 2.687 (2.687)	GS 35.641 (35.641)	mem 39.955
Train: [44][535/750]	BT 0.046 (1.166)	DT 0.006 (1.123)	loss 6.795 (6.795)	prob 2.778 (2.778)	GS 29.406 (29.406)	mem 39.967
Train: [44][540/750]	BT 0.974 (1.157)	DT 0.932 (1.114)	loss 6.900 (6.900)	prob 2.486 (2.486)	GS 36.547 (36.547)	mem 39.902
Train: [44][545/750]	BT 0.046 (1.166)	DT 0.004 (1.123)	loss 6.691 (6.691)	prob 2.921 (2.921)	GS 30.000 (30.000)	mem 39.949
Train: [44][550/750]	BT 0.032 (1.156)	DT 0.001 (1.113)	loss 6.951 (6.951)	prob 2.673 (2.673)	GS 35.297 (35.297)	mem 39.950
Train: [44][555/750]	BT 0.044 (1.159)	DT 0.009 (1.115)	loss 6.899 (6.899)	prob 2.539 (2.539)	GS 31.656 (31.656)	mem 39.943
Train: [44][560/750]	BT 0.058 (1.155)	DT 0.007 (1.112)	loss 6.891 (6.891)	prob 2.697 (2.697)	GS 34.969 (34.969)	mem 40.102
Train: [44][565/750]	BT 0.047 (1.149)	DT 0.007 (1.105)	loss 6.960 (6.960)	prob 2.451 (2.451)	GS 29.688 (29.688)	mem 39.892
Train: [44][570/750]	BT 0.049 (1.159)	DT 0.001 (1.116)	loss 6.852 (6.852)	prob 2.494 (2.494)	GS 33.797 (33.797)	mem 39.970
Train: [44][575/750]	BT 0.060 (1.150)	DT 0.006 (1.106)	loss 6.893 (6.893)	prob 2.839 (2.839)	GS 34.719 (34.719)	mem 39.904
Train: [44][580/750]	BT 9.873 (1.164)	DT 9.840 (1.121)	loss 6.719 (6.719)	prob 2.642 (2.642)	GS 34.312 (34.312)	mem 40.027
Train: [44][585/750]	BT 0.040 (1.155)	DT 0.001 (1.111)	loss 6.875 (6.875)	prob 3.154 (3.154)	GS 29.891 (29.891)	mem 39.970
Train: [44][590/750]	BT 2.194 (1.153)	DT 2.158 (1.109)	loss 6.983 (6.983)	prob 2.432 (2.432)	GS 36.016 (36.016)	mem 39.952
Train: [44][595/750]	BT 0.139 (1.153)	DT 0.031 (1.109)	loss 7.351 (7.351)	prob 2.433 (2.433)	GS 26.625 (26.625)	mem 40.530
Train: [44][600/750]	BT 3.464 (1.150)	DT 3.398 (1.106)	loss 6.936 (6.936)	prob 2.909 (2.909)	GS 31.656 (31.656)	mem 40.300
Train: [44][605/750]	BT 0.106 (1.151)	DT 0.025 (1.107)	loss 7.056 (7.056)	prob 2.288 (2.288)	GS 30.703 (30.703)	mem 40.048
Train: [44][610/750]	BT 0.032 (1.142)	DT 0.001 (1.098)	loss 7.132 (7.132)	prob 2.961 (2.961)	GS 36.406 (36.406)	mem 39.927
Train: [44][615/750]	BT 0.043 (1.154)	DT 0.013 (1.110)	loss 6.934 (6.934)	prob 2.771 (2.771)	GS 31.672 (31.672)	mem 39.902
Train: [44][620/750]	BT 0.064 (1.148)	DT 0.012 (1.104)	loss 6.888 (6.888)	prob 2.650 (2.650)	GS 35.188 (35.188)	mem 39.883
Train: [44][625/750]	BT 0.033 (1.146)	DT 0.001 (1.103)	loss 6.837 (6.837)	prob 2.919 (2.919)	GS 32.984 (32.984)	mem 39.882
Train: [44][630/750]	BT 0.058 (1.152)	DT 0.012 (1.108)	loss 6.781 (6.781)	prob 2.595 (2.595)	GS 32.125 (32.125)	mem 39.954
Train: [44][635/750]	BT 0.084 (1.144)	DT 0.013 (1.099)	loss 6.905 (6.905)	prob 3.142 (3.142)	GS 32.344 (32.344)	mem 39.955
Train: [44][640/750]	BT 8.795 (1.159)	DT 8.763 (1.115)	loss 6.769 (6.769)	prob 2.378 (2.378)	GS 38.203 (38.203)	mem 39.895
Train: [44][645/750]	BT 0.050 (1.151)	DT 0.001 (1.106)	loss 6.938 (6.938)	prob 2.940 (2.940)	GS 31.781 (31.781)	mem 39.897
Train: [44][650/750]	BT 2.462 (1.150)	DT 2.426 (1.106)	loss 6.719 (6.719)	prob 2.739 (2.739)	GS 35.047 (35.047)	mem 40.068
Train: [44][655/750]	BT 0.048 (1.155)	DT 0.009 (1.111)	loss 6.995 (6.995)	prob 2.605 (2.605)	GS 27.766 (27.766)	mem 39.928
arpack error, retry= 0
Train: [44][660/750]	BT 3.466 (1.152)	DT 3.418 (1.108)	loss 6.744 (6.744)	prob 2.878 (2.878)	GS 33.250 (33.250)	mem 39.938
Train: [44][665/750]	BT 0.056 (1.159)	DT 0.018 (1.115)	loss 6.865 (6.865)	prob 2.707 (2.707)	GS 28.922 (28.922)	mem 40.217
Train: [44][670/750]	BT 0.034 (1.151)	DT 0.001 (1.107)	loss 7.050 (7.050)	prob 3.066 (3.066)	GS 33.141 (33.141)	mem 39.953
Train: [44][675/750]	BT 0.049 (1.149)	DT 0.003 (1.105)	loss 6.816 (6.816)	prob 3.267 (3.267)	GS 33.500 (33.500)	mem 40.000
Train: [44][680/750]	BT 0.037 (1.154)	DT 0.002 (1.110)	loss 6.840 (6.840)	prob 2.994 (2.994)	GS 32.656 (32.656)	mem 40.442
Train: [44][685/750]	BT 0.026 (1.146)	DT 0.001 (1.102)	loss 6.745 (6.745)	prob 2.536 (2.536)	GS 33.203 (33.203)	mem 40.041
Train: [44][690/750]	BT 0.028 (1.157)	DT 0.001 (1.113)	loss 6.724 (6.724)	prob 2.322 (2.322)	GS 31.328 (31.328)	mem 39.888
Train: [44][695/750]	BT 0.054 (1.149)	DT 0.002 (1.105)	loss 6.958 (6.958)	prob 2.559 (2.559)	GS 32.250 (32.250)	mem 39.928
Train: [44][700/750]	BT 2.433 (1.157)	DT 2.407 (1.113)	loss 6.630 (6.630)	prob 3.088 (3.088)	GS 29.203 (29.203)	mem 39.946
Train: [44][705/750]	BT 0.031 (1.149)	DT 0.001 (1.105)	loss 7.275 (7.275)	prob 2.294 (2.294)	GS 33.875 (33.875)	mem 39.948
Train: [44][710/750]	BT 10.283 (1.156)	DT 10.242 (1.112)	loss 6.773 (6.773)	prob 2.781 (2.781)	GS 34.500 (34.500)	mem 39.988
Train: [44][715/750]	BT 0.031 (1.155)	DT 0.001 (1.111)	loss 6.686 (6.686)	prob 3.147 (3.147)	GS 34.594 (34.594)	mem 39.873
Train: [44][720/750]	BT 0.078 (1.147)	DT 0.001 (1.103)	loss 6.711 (6.711)	prob 3.003 (3.003)	GS 35.656 (35.656)	mem 39.834
Train: [44][725/750]	BT 0.038 (1.158)	DT 0.003 (1.114)	loss 6.984 (6.984)	prob 2.909 (2.909)	GS 29.109 (29.109)	mem 39.785
Train: [44][730/750]	BT 0.053 (1.150)	DT 0.002 (1.106)	loss 6.868 (6.868)	prob 2.556 (2.556)	GS 36.891 (36.891)	mem 39.845
Train: [44][735/750]	BT 0.030 (1.152)	DT 0.005 (1.108)	loss 7.256 (7.256)	prob 2.252 (2.252)	GS 36.562 (36.562)	mem 36.456
Train: [44][740/750]	BT 0.025 (1.147)	DT 0.001 (1.103)	loss 6.698 (6.698)	prob 2.615 (2.615)	GS 32.094 (32.094)	mem 13.521
Train: [44][745/750]	BT 0.024 (1.139)	DT 0.001 (1.095)	loss 6.903 (6.903)	prob 2.540 (2.540)	GS 33.594 (33.594)	mem 13.532
Train: [44][750/750]	BT 0.021 (1.135)	DT 0.001 (1.091)	loss 7.064 (7.064)	prob 2.499 (2.499)	GS 33.969 (33.969)	mem 10.546
Train: [44][755/750]	BT 0.038 (1.128)	DT 0.002 (1.084)	loss 7.035 (7.035)	prob 2.256 (2.256)	GS 27.188 (27.188)	mem 10.546
epoch 44, total time 851.95
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [45][1/750]	BT 22.266 (22.266)	DT 22.178 (22.178)	loss 7.043 (7.043)	prob 2.253 (2.253)	GS 33.812 (33.812)	mem 38.547
Train: [45][5/750]	BT 0.847 (4.707)	DT 0.813 (4.663)	loss 6.841 (6.841)	prob 2.980 (2.980)	GS 31.656 (31.656)	mem 38.665
Train: [45][10/750]	BT 0.025 (3.152)	DT 0.001 (3.109)	loss 6.732 (6.732)	prob 2.623 (2.623)	GS 33.562 (33.562)	mem 39.313
Train: [45][15/750]	BT 0.678 (2.245)	DT 0.627 (2.200)	loss 6.699 (6.699)	prob 2.907 (2.907)	GS 34.234 (34.234)	mem 39.411
Train: [45][20/750]	BT 0.104 (2.334)	DT 0.008 (2.288)	loss 6.725 (6.725)	prob 2.780 (2.780)	GS 35.609 (35.609)	mem 39.465
Train: [45][25/750]	BT 0.031 (1.877)	DT 0.001 (1.831)	loss 6.939 (6.939)	prob 2.680 (2.680)	GS 29.312 (29.312)	mem 39.468
Train: [45][30/750]	BT 5.127 (1.992)	DT 5.095 (1.944)	loss 6.970 (6.970)	prob 2.568 (2.568)	GS 32.500 (32.500)	mem 39.509
Train: [45][35/750]	BT 0.044 (1.714)	DT 0.002 (1.667)	loss 6.900 (6.900)	prob 3.063 (3.063)	GS 24.953 (24.953)	mem 39.510
Train: [45][40/750]	BT 6.961 (1.677)	DT 6.920 (1.632)	loss 7.006 (7.006)	prob 2.012 (2.012)	GS 31.703 (31.703)	mem 39.570
Train: [45][45/750]	BT 0.035 (1.578)	DT 0.002 (1.532)	loss 6.733 (6.733)	prob 2.264 (2.264)	GS 33.109 (33.109)	mem 39.651
Train: [45][50/750]	BT 0.776 (1.441)	DT 0.693 (1.393)	loss 6.577 (6.577)	prob 3.123 (3.123)	GS 34.438 (34.438)	mem 39.617
Train: [45][55/750]	BT 0.027 (1.509)	DT 0.001 (1.462)	loss 6.781 (6.781)	prob 3.154 (3.154)	GS 27.812 (27.812)	mem 39.583
Train: [45][60/750]	BT 0.052 (1.387)	DT 0.001 (1.340)	loss 6.928 (6.928)	prob 2.389 (2.389)	GS 34.031 (34.031)	mem 39.620
Train: [45][65/750]	BT 0.028 (1.482)	DT 0.007 (1.435)	loss 6.897 (6.897)	prob 2.571 (2.571)	GS 28.750 (28.750)	mem 39.612
Train: [45][70/750]	BT 0.051 (1.380)	DT 0.010 (1.333)	loss 6.805 (6.805)	prob 2.844 (2.844)	GS 35.281 (35.281)	mem 39.614
Train: [45][75/750]	BT 0.052 (1.302)	DT 0.002 (1.254)	loss 6.905 (6.905)	prob 2.209 (2.209)	GS 30.188 (30.188)	mem 39.666
Train: [45][80/750]	BT 0.073 (1.358)	DT 0.014 (1.309)	loss 6.652 (6.652)	prob 2.305 (2.305)	GS 33.875 (33.875)	mem 39.636
Train: [45][85/750]	BT 0.071 (1.281)	DT 0.010 (1.233)	loss 6.928 (6.928)	prob 2.730 (2.730)	GS 32.797 (32.797)	mem 39.743
Train: [45][90/750]	BT 7.436 (1.413)	DT 7.400 (1.366)	loss 6.845 (6.845)	prob 2.813 (2.813)	GS 37.016 (37.016)	mem 39.678
Train: [45][95/750]	BT 0.049 (1.341)	DT 0.011 (1.294)	loss 7.071 (7.071)	prob 2.432 (2.432)	GS 30.609 (30.609)	mem 39.665
Train: [45][100/750]	BT 1.496 (1.290)	DT 1.426 (1.244)	loss 6.739 (6.739)	prob 2.786 (2.786)	GS 33.219 (33.219)	mem 39.815
Train: [45][105/750]	BT 0.029 (1.359)	DT 0.001 (1.313)	loss 6.729 (6.729)	prob 2.871 (2.871)	GS 34.422 (34.422)	mem 39.780
Train: [45][110/750]	BT 0.030 (1.298)	DT 0.001 (1.254)	loss 7.008 (7.008)	prob 2.878 (2.878)	GS 35.734 (35.734)	mem 39.781
Train: [45][115/750]	BT 0.030 (1.351)	DT 0.001 (1.307)	loss 6.839 (6.839)	prob 2.770 (2.770)	GS 30.125 (30.125)	mem 39.784
Train: [45][120/750]	BT 0.044 (1.296)	DT 0.001 (1.253)	loss 6.764 (6.764)	prob 2.630 (2.630)	GS 35.812 (35.812)	mem 39.837
Train: [45][125/750]	BT 0.054 (1.247)	DT 0.004 (1.203)	loss 7.140 (7.140)	prob 2.235 (2.235)	GS 31.453 (31.453)	mem 39.795
Train: [45][130/750]	BT 0.033 (1.287)	DT 0.001 (1.244)	loss 6.859 (6.859)	prob 2.031 (2.031)	GS 32.984 (32.984)	mem 39.828
Train: [45][135/750]	BT 0.063 (1.241)	DT 0.014 (1.198)	loss 6.934 (6.934)	prob 2.204 (2.204)	GS 32.203 (32.203)	mem 39.830
Train: [45][140/750]	BT 0.043 (1.286)	DT 0.001 (1.243)	loss 6.765 (6.765)	prob 2.515 (2.515)	GS 32.250 (32.250)	mem 39.848
Train: [45][145/750]	BT 0.054 (1.243)	DT 0.001 (1.200)	loss 6.656 (6.656)	prob 2.581 (2.581)	GS 33.484 (33.484)	mem 39.908
Train: [45][150/750]	BT 12.655 (1.287)	DT 12.625 (1.244)	loss 6.811 (6.811)	prob 2.556 (2.556)	GS 37.578 (37.578)	mem 39.897
Train: [45][155/750]	BT 0.031 (1.248)	DT 0.001 (1.204)	loss 6.770 (6.770)	prob 2.875 (2.875)	GS 33.875 (33.875)	mem 39.965
Train: [45][160/750]	BT 0.077 (1.211)	DT 0.001 (1.167)	loss 6.738 (6.738)	prob 2.522 (2.522)	GS 34.516 (34.516)	mem 39.899
Train: [45][165/750]	BT 0.063 (1.226)	DT 0.016 (1.182)	loss 7.054 (7.054)	prob 2.382 (2.382)	GS 27.641 (27.641)	mem 39.837
Train: [45][170/750]	BT 0.049 (1.195)	DT 0.001 (1.151)	loss 6.823 (6.823)	prob 2.459 (2.459)	GS 32.000 (32.000)	mem 39.857
Train: [45][175/750]	BT 0.039 (1.238)	DT 0.001 (1.194)	loss 6.828 (6.828)	prob 3.114 (3.114)	GS 29.844 (29.844)	mem 39.915
Train: [45][180/750]	BT 0.060 (1.213)	DT 0.001 (1.169)	loss 6.869 (6.869)	prob 2.586 (2.586)	GS 33.250 (33.250)	mem 39.889
Train: [45][185/750]	BT 0.032 (1.182)	DT 0.001 (1.138)	loss 6.999 (6.999)	prob 2.423 (2.423)	GS 31.938 (31.938)	mem 39.889
Train: [45][190/750]	BT 3.832 (1.224)	DT 3.784 (1.180)	loss 7.046 (7.046)	prob 2.391 (2.391)	GS 33.141 (33.141)	mem 39.936
Train: [45][195/750]	BT 0.024 (1.194)	DT 0.001 (1.150)	loss 7.144 (7.144)	prob 2.247 (2.247)	GS 34.938 (34.938)	mem 39.937
Train: [45][200/750]	BT 0.041 (1.213)	DT 0.002 (1.170)	loss 6.891 (6.891)	prob 2.938 (2.938)	GS 34.234 (34.234)	mem 39.969
Train: [45][205/750]	BT 0.030 (1.192)	DT 0.002 (1.148)	loss 6.698 (6.698)	prob 3.098 (3.098)	GS 33.719 (33.719)	mem 39.906
Train: [45][210/750]	BT 11.141 (1.218)	DT 11.098 (1.174)	loss 6.623 (6.623)	prob 2.931 (2.931)	GS 32.547 (32.547)	mem 39.874
Train: [45][215/750]	BT 0.056 (1.219)	DT 0.015 (1.176)	loss 6.961 (6.961)	prob 2.716 (2.716)	GS 36.516 (36.516)	mem 39.819
Train: [45][220/750]	BT 0.029 (1.192)	DT 0.001 (1.149)	loss 6.773 (6.773)	prob 2.386 (2.386)	GS 36.562 (36.562)	mem 39.820
Train: [45][225/750]	BT 0.033 (1.196)	DT 0.001 (1.153)	loss 6.658 (6.658)	prob 3.513 (3.513)	GS 31.891 (31.891)	mem 39.842
Train: [45][230/750]	BT 0.033 (1.190)	DT 0.002 (1.147)	loss 6.792 (6.792)	prob 2.637 (2.637)	GS 34.141 (34.141)	mem 39.885
Train: [45][235/750]	BT 0.090 (1.214)	DT 0.009 (1.171)	loss 6.922 (6.922)	prob 2.315 (2.315)	GS 33.500 (33.500)	mem 39.878
Train: [45][240/750]	BT 0.073 (1.190)	DT 0.016 (1.147)	loss 7.332 (7.332)	prob 2.949 (2.949)	GS 35.328 (35.328)	mem 39.878
Train: [45][245/750]	BT 0.109 (1.167)	DT 0.009 (1.124)	loss 6.719 (6.719)	prob 3.348 (3.348)	GS 34.984 (34.984)	mem 39.877
Train: [45][250/750]	BT 0.068 (1.202)	DT 0.009 (1.158)	loss 6.932 (6.932)	prob 2.818 (2.818)	GS 34.766 (34.766)	mem 39.943
Train: [45][255/750]	BT 0.033 (1.180)	DT 0.001 (1.136)	loss 6.957 (6.957)	prob 2.365 (2.365)	GS 30.578 (30.578)	mem 39.916
Train: [45][260/750]	BT 0.033 (1.212)	DT 0.003 (1.169)	loss 6.800 (6.800)	prob 2.408 (2.408)	GS 36.266 (36.266)	mem 39.863
Train: [45][265/750]	BT 0.042 (1.190)	DT 0.010 (1.147)	loss 6.905 (6.905)	prob 2.784 (2.784)	GS 34.297 (34.297)	mem 39.862
Train: [45][270/750]	BT 10.001 (1.213)	DT 9.956 (1.169)	loss 6.764 (6.764)	prob 3.155 (3.155)	GS 34.969 (34.969)	mem 39.845
Train: [45][275/750]	BT 0.029 (1.192)	DT 0.002 (1.147)	loss 7.099 (7.099)	prob 2.675 (2.675)	GS 44.328 (44.328)	mem 39.844
Train: [45][280/750]	BT 0.052 (1.180)	DT 0.012 (1.136)	loss 6.898 (6.898)	prob 2.441 (2.441)	GS 35.656 (35.656)	mem 39.957
Train: [45][285/750]	BT 0.039 (1.194)	DT 0.006 (1.150)	loss 6.911 (6.911)	prob 2.763 (2.763)	GS 34.344 (34.344)	mem 40.008
Train: [45][290/750]	BT 4.877 (1.191)	DT 4.847 (1.147)	loss 6.775 (6.775)	prob 3.078 (3.078)	GS 33.734 (33.734)	mem 39.983
Train: [45][295/750]	BT 0.031 (1.202)	DT 0.001 (1.159)	loss 6.723 (6.723)	prob 3.700 (3.700)	GS 38.156 (38.156)	mem 40.000
Train: [45][300/750]	BT 0.046 (1.183)	DT 0.011 (1.139)	loss 6.924 (6.924)	prob 2.564 (2.564)	GS 34.812 (34.812)	mem 39.924
Train: [45][305/750]	BT 0.047 (1.182)	DT 0.010 (1.139)	loss 6.783 (6.783)	prob 2.750 (2.750)	GS 27.812 (27.812)	mem 39.858
Train: [45][310/750]	BT 0.029 (1.176)	DT 0.001 (1.132)	loss 6.764 (6.764)	prob 2.662 (2.662)	GS 38.734 (38.734)	mem 39.934
Train: [45][315/750]	BT 0.087 (1.187)	DT 0.002 (1.143)	loss 6.863 (6.863)	prob 2.785 (2.785)	GS 33.266 (33.266)	mem 39.954
Train: [45][320/750]	BT 0.035 (1.180)	DT 0.001 (1.137)	loss 6.776 (6.776)	prob 2.719 (2.719)	GS 32.922 (32.922)	mem 40.102
Train: [45][325/750]	BT 0.031 (1.163)	DT 0.001 (1.120)	loss 6.791 (6.791)	prob 2.934 (2.934)	GS 31.562 (31.562)	mem 39.964
Train: [45][330/750]	BT 1.067 (1.189)	DT 1.032 (1.146)	loss 6.618 (6.618)	prob 3.210 (3.210)	GS 34.672 (34.672)	mem 39.900
Train: [45][335/750]	BT 0.036 (1.172)	DT 0.002 (1.129)	loss 6.897 (6.897)	prob 2.552 (2.552)	GS 29.016 (29.016)	mem 39.900
Train: [45][340/750]	BT 0.042 (1.186)	DT 0.001 (1.142)	loss 6.928 (6.928)	prob 2.346 (2.346)	GS 31.734 (31.734)	mem 39.947
Train: [45][345/750]	BT 0.033 (1.169)	DT 0.001 (1.126)	loss 6.974 (6.974)	prob 2.371 (2.371)	GS 32.656 (32.656)	mem 39.947
Train: [45][350/750]	BT 13.219 (1.191)	DT 13.187 (1.148)	loss 6.826 (6.826)	prob 2.989 (2.989)	GS 33.484 (33.484)	mem 39.966
Train: [45][355/750]	BT 0.136 (1.179)	DT 0.025 (1.136)	loss 6.768 (6.768)	prob 2.792 (2.792)	GS 34.219 (34.219)	mem 40.046
Train: [45][360/750]	BT 0.034 (1.164)	DT 0.001 (1.121)	loss 6.849 (6.849)	prob 2.189 (2.189)	GS 30.625 (30.625)	mem 39.968
Train: [45][365/750]	BT 0.027 (1.180)	DT 0.001 (1.136)	loss 6.788 (6.788)	prob 2.609 (2.609)	GS 34.297 (34.297)	mem 39.986
Train: [45][370/750]	BT 0.026 (1.170)	DT 0.001 (1.126)	loss 6.894 (6.894)	prob 2.454 (2.454)	GS 32.969 (32.969)	mem 39.986
Train: [45][375/750]	BT 0.069 (1.186)	DT 0.007 (1.143)	loss 6.777 (6.777)	prob 2.802 (2.802)	GS 30.422 (30.422)	mem 39.998
Train: [45][380/750]	BT 0.025 (1.171)	DT 0.001 (1.128)	loss 6.717 (6.717)	prob 2.725 (2.725)	GS 32.812 (32.812)	mem 39.998
Train: [45][385/750]	BT 0.033 (1.157)	DT 0.002 (1.113)	loss 6.747 (6.747)	prob 2.349 (2.349)	GS 28.828 (28.828)	mem 39.999
Train: [45][390/750]	BT 0.066 (1.169)	DT 0.011 (1.125)	loss 6.557 (6.557)	prob 2.449 (2.449)	GS 35.797 (35.797)	mem 40.012
Train: [45][395/750]	BT 0.034 (1.155)	DT 0.003 (1.112)	loss 6.616 (6.616)	prob 3.291 (3.291)	GS 33.016 (33.016)	mem 40.013
Train: [45][400/750]	BT 0.039 (1.168)	DT 0.012 (1.125)	loss 7.059 (7.059)	prob 2.784 (2.784)	GS 35.188 (35.188)	mem 40.023
Train: [45][405/750]	BT 0.078 (1.162)	DT 0.009 (1.118)	loss 6.527 (6.527)	prob 2.904 (2.904)	GS 29.438 (29.438)	mem 40.184
Train: [45][410/750]	BT 13.330 (1.180)	DT 13.294 (1.137)	loss 7.089 (7.089)	prob 2.233 (2.233)	GS 35.016 (35.016)	mem 40.039
Train: [45][415/750]	BT 0.025 (1.167)	DT 0.001 (1.123)	loss 6.849 (6.849)	prob 2.345 (2.345)	GS 31.234 (31.234)	mem 40.040
Train: [45][420/750]	BT 0.025 (1.155)	DT 0.001 (1.112)	loss 6.947 (6.947)	prob 2.349 (2.349)	GS 32.500 (32.500)	mem 40.046
Train: [45][425/750]	BT 0.031 (1.169)	DT 0.001 (1.126)	loss 6.876 (6.876)	prob 3.650 (3.650)	GS 28.172 (28.172)	mem 40.165
Train: [45][430/750]	BT 0.035 (1.160)	DT 0.002 (1.116)	loss 6.773 (6.773)	prob 2.897 (2.897)	GS 34.312 (34.312)	mem 40.254
Train: [45][435/750]	BT 0.055 (1.165)	DT 0.002 (1.122)	loss 7.027 (7.027)	prob 2.952 (2.952)	GS 44.719 (44.719)	mem 40.093
Train: [45][440/750]	BT 3.136 (1.160)	DT 3.026 (1.116)	loss 6.712 (6.712)	prob 3.053 (3.053)	GS 31.578 (31.578)	mem 40.074
Train: [45][445/750]	BT 0.096 (1.148)	DT 0.002 (1.104)	loss 6.851 (6.851)	prob 3.076 (3.076)	GS 28.062 (28.062)	mem 40.074
Train: [45][450/750]	BT 0.044 (1.155)	DT 0.001 (1.111)	loss 6.947 (6.947)	prob 3.057 (3.057)	GS 36.172 (36.172)	mem 40.051
Train: [45][455/750]	BT 0.044 (1.151)	DT 0.001 (1.107)	loss 6.787 (6.787)	prob 3.032 (3.032)	GS 30.547 (30.547)	mem 40.067
Train: [45][460/750]	BT 0.032 (1.164)	DT 0.001 (1.120)	loss 7.101 (7.101)	prob 2.078 (2.078)	GS 30.797 (30.797)	mem 39.777
Train: [45][465/750]	BT 0.145 (1.152)	DT 0.060 (1.108)	loss 6.666 (6.666)	prob 3.082 (3.082)	GS 30.469 (30.469)	mem 39.946
Train: [45][470/750]	BT 11.636 (1.165)	DT 11.603 (1.121)	loss 6.739 (6.739)	prob 3.369 (3.369)	GS 33.422 (33.422)	mem 39.849
Train: [45][475/750]	BT 0.041 (1.153)	DT 0.009 (1.109)	loss 6.716 (6.716)	prob 2.921 (2.921)	GS 29.438 (29.438)	mem 39.855
Train: [45][480/750]	BT 0.048 (1.142)	DT 0.001 (1.098)	loss 7.067 (7.067)	prob 2.665 (2.665)	GS 34.547 (34.547)	mem 39.863
Train: [45][485/750]	BT 0.030 (1.157)	DT 0.001 (1.113)	loss 6.654 (6.654)	prob 3.452 (3.452)	GS 32.859 (32.859)	mem 39.843
Train: [45][490/750]	BT 0.031 (1.146)	DT 0.001 (1.102)	loss 6.933 (6.933)	prob 3.469 (3.469)	GS 35.422 (35.422)	mem 39.845
Train: [45][495/750]	BT 0.058 (1.158)	DT 0.001 (1.114)	loss 7.199 (7.199)	prob 2.644 (2.644)	GS 35.719 (35.719)	mem 39.926
Train: [45][500/750]	BT 2.960 (1.153)	DT 2.934 (1.109)	loss 7.032 (7.032)	prob 2.463 (2.463)	GS 35.203 (35.203)	mem 39.902
Train: [45][505/750]	BT 0.067 (1.142)	DT 0.019 (1.098)	loss 7.064 (7.064)	prob 2.293 (2.293)	GS 31.984 (31.984)	mem 39.902
Train: [45][510/750]	BT 0.080 (1.145)	DT 0.002 (1.101)	loss 6.910 (6.910)	prob 3.033 (3.033)	GS 35.734 (35.734)	mem 39.905
Train: [45][515/750]	BT 0.045 (1.142)	DT 0.003 (1.098)	loss 6.859 (6.859)	prob 2.835 (2.835)	GS 28.453 (28.453)	mem 39.928
Train: [45][520/750]	BT 0.032 (1.154)	DT 0.001 (1.109)	loss 6.890 (6.890)	prob 2.925 (2.925)	GS 33.109 (33.109)	mem 40.080
Train: [45][525/750]	BT 0.048 (1.143)	DT 0.001 (1.099)	loss 6.968 (6.968)	prob 3.307 (3.307)	GS 30.578 (30.578)	mem 40.037
Train: [45][530/750]	BT 12.126 (1.155)	DT 12.080 (1.111)	loss 7.200 (7.200)	prob 2.748 (2.748)	GS 33.219 (33.219)	mem 39.894
Train: [45][535/750]	BT 0.028 (1.145)	DT 0.001 (1.101)	loss 6.672 (6.672)	prob 2.784 (2.784)	GS 37.344 (37.344)	mem 39.881
Train: [45][540/750]	BT 1.258 (1.138)	DT 1.202 (1.094)	loss 7.346 (7.346)	prob 2.194 (2.194)	GS 34.641 (34.641)	mem 39.939
Train: [45][545/750]	BT 0.033 (1.150)	DT 0.002 (1.105)	loss 7.159 (7.159)	prob 2.593 (2.593)	GS 40.625 (40.625)	mem 39.876
Train: [45][550/750]	BT 0.038 (1.140)	DT 0.008 (1.095)	loss 7.045 (7.045)	prob 2.471 (2.471)	GS 34.578 (34.578)	mem 39.876
Train: [45][555/750]	BT 0.036 (1.154)	DT 0.001 (1.109)	loss 7.180 (7.180)	prob 2.040 (2.040)	GS 32.938 (32.938)	mem 39.867
Train: [45][560/750]	BT 0.249 (1.145)	DT 0.204 (1.100)	loss 7.330 (7.330)	prob 2.664 (2.664)	GS 32.969 (32.969)	mem 39.868
Train: [45][565/750]	BT 0.026 (1.135)	DT 0.001 (1.090)	loss 7.015 (7.015)	prob 2.526 (2.526)	GS 31.312 (31.312)	mem 39.880
Train: [45][570/750]	BT 0.052 (1.148)	DT 0.011 (1.104)	loss 6.911 (6.911)	prob 2.662 (2.662)	GS 31.078 (31.078)	mem 39.901
Train: [45][575/750]	BT 0.034 (1.139)	DT 0.002 (1.094)	loss 6.862 (6.862)	prob 3.158 (3.158)	GS 30.734 (30.734)	mem 39.963
Train: [45][580/750]	BT 0.036 (1.154)	DT 0.001 (1.109)	loss 6.984 (6.984)	prob 2.865 (2.865)	GS 37.500 (37.500)	mem 40.086
Train: [45][585/750]	BT 0.090 (1.146)	DT 0.022 (1.101)	loss 7.293 (7.293)	prob 2.198 (2.198)	GS 31.516 (31.516)	mem 39.888
Train: [45][590/750]	BT 9.097 (1.152)	DT 9.034 (1.107)	loss 6.926 (6.926)	prob 2.937 (2.937)	GS 31.219 (31.219)	mem 40.012
Train: [45][595/750]	BT 0.027 (1.142)	DT 0.001 (1.098)	loss 7.060 (7.060)	prob 2.440 (2.440)	GS 29.172 (29.172)	mem 39.933
Train: [45][600/750]	BT 0.136 (1.143)	DT 0.010 (1.098)	loss 7.465 (7.465)	prob 2.736 (2.736)	GS 36.156 (36.156)	mem 39.932
Train: [45][605/750]	BT 0.048 (1.150)	DT 0.017 (1.105)	loss 8.128 (8.128)	prob 1.753 (1.753)	GS 37.375 (37.375)	mem 39.965
Train: [45][610/750]	BT 0.032 (1.142)	DT 0.002 (1.097)	loss 7.096 (7.096)	prob 2.487 (2.487)	GS 31.625 (31.625)	mem 40.101
Train: [45][615/750]	BT 0.052 (1.155)	DT 0.003 (1.110)	loss 7.273 (7.273)	prob 2.122 (2.122)	GS 28.156 (28.156)	mem 39.942
Train: [45][620/750]	BT 2.062 (1.149)	DT 2.000 (1.104)	loss 7.629 (7.629)	prob 2.372 (2.372)	GS 32.297 (32.297)	mem 40.024
Train: [45][625/750]	BT 0.051 (1.140)	DT 0.002 (1.096)	loss 7.537 (7.537)	prob 2.062 (2.062)	GS 32.641 (32.641)	mem 39.990
Train: [45][630/750]	BT 0.050 (1.151)	DT 0.004 (1.106)	loss 7.571 (7.571)	prob 2.366 (2.366)	GS 33.016 (33.016)	mem 39.914
Train: [45][635/750]	BT 0.034 (1.142)	DT 0.001 (1.098)	loss 7.612 (7.612)	prob 2.192 (2.192)	GS 31.672 (31.672)	mem 39.914
Train: [45][640/750]	BT 0.045 (1.154)	DT 0.014 (1.110)	loss 7.051 (7.051)	prob 2.990 (2.990)	GS 34.047 (34.047)	mem 39.990
Train: [45][645/750]	BT 0.032 (1.145)	DT 0.001 (1.101)	loss 6.915 (6.915)	prob 2.502 (2.502)	GS 40.172 (40.172)	mem 39.992
Train: [45][650/750]	BT 13.503 (1.158)	DT 13.455 (1.113)	loss 7.483 (7.483)	prob 2.927 (2.927)	GS 33.031 (33.031)	mem 39.941
Train: [45][655/750]	BT 0.031 (1.149)	DT 0.001 (1.105)	loss 7.320 (7.320)	prob 2.190 (2.190)	GS 32.078 (32.078)	mem 39.941
arpack error, retry= 0
Train: [45][660/750]	BT 0.066 (1.141)	DT 0.002 (1.096)	loss 7.440 (7.440)	prob 2.629 (2.629)	GS 29.703 (29.703)	mem 39.942
Train: [45][665/750]	BT 0.070 (1.151)	DT 0.002 (1.107)	loss 7.022 (7.022)	prob 2.782 (2.782)	GS 32.625 (32.625)	mem 39.976
Train: [45][670/750]	BT 0.053 (1.143)	DT 0.002 (1.099)	loss 8.038 (8.038)	prob 2.805 (2.805)	GS 33.266 (33.266)	mem 39.975
Train: [45][675/750]	BT 0.128 (1.152)	DT 0.012 (1.107)	loss 6.834 (6.834)	prob 2.646 (2.646)	GS 31.250 (31.250)	mem 39.974
Train: [45][680/750]	BT 0.032 (1.144)	DT 0.001 (1.099)	loss 7.792 (7.792)	prob 1.605 (1.605)	GS 34.203 (34.203)	mem 40.007
Train: [45][685/750]	BT 0.035 (1.136)	DT 0.008 (1.091)	loss 7.580 (7.580)	prob 2.002 (2.002)	GS 32.672 (32.672)	mem 40.092
Train: [45][690/750]	BT 0.034 (1.144)	DT 0.001 (1.100)	loss 7.122 (7.122)	prob 3.291 (3.291)	GS 31.156 (31.156)	mem 40.038
Train: [45][695/750]	BT 0.029 (1.141)	DT 0.001 (1.096)	loss 7.369 (7.369)	prob 2.593 (2.593)	GS 29.047 (29.047)	mem 40.058
Train: [45][700/750]	BT 0.034 (1.146)	DT 0.001 (1.102)	loss 7.474 (7.474)	prob 2.991 (2.991)	GS 31.031 (31.031)	mem 40.010
Train: [45][705/750]	BT 0.068 (1.148)	DT 0.008 (1.103)	loss 7.872 (7.872)	prob 2.484 (2.484)	GS 32.094 (32.094)	mem 40.077
Train: [45][710/750]	BT 7.067 (1.150)	DT 7.032 (1.106)	loss 7.571 (7.571)	prob 3.330 (3.330)	GS 31.344 (31.344)	mem 40.005
Train: [45][715/750]	BT 0.030 (1.144)	DT 0.002 (1.099)	loss 7.886 (7.886)	prob 2.108 (2.108)	GS 30.250 (30.250)	mem 39.963
Train: [45][720/750]	BT 0.030 (1.146)	DT 0.001 (1.101)	loss 7.162 (7.162)	prob 3.194 (3.194)	GS 32.766 (32.766)	mem 39.880
Train: [45][725/750]	BT 0.036 (1.143)	DT 0.001 (1.099)	loss 7.627 (7.627)	prob 2.409 (2.409)	GS 33.578 (33.578)	mem 39.867
Train: [45][730/750]	BT 0.056 (1.146)	DT 0.005 (1.101)	loss 7.325 (7.325)	prob 2.583 (2.583)	GS 34.953 (34.953)	mem 39.771
Train: [45][735/750]	BT 0.050 (1.141)	DT 0.007 (1.097)	loss 7.277 (7.277)	prob 2.412 (2.412)	GS 32.344 (32.344)	mem 36.782
Train: [45][740/750]	BT 4.364 (1.141)	DT 4.334 (1.097)	loss 7.222 (7.222)	prob 3.122 (3.122)	GS 27.375 (27.375)	mem 16.550
Train: [45][745/750]	BT 0.029 (1.134)	DT 0.001 (1.089)	loss 7.536 (7.536)	prob 1.982 (1.982)	GS 29.375 (29.375)	mem 16.627
Train: [45][750/750]	BT 0.047 (1.126)	DT 0.012 (1.082)	loss 8.292 (8.292)	prob 1.612 (1.612)	GS 35.156 (35.156)	mem 16.749
Train: [45][755/750]	BT 0.025 (1.124)	DT 0.001 (1.079)	loss 7.528 (7.528)	prob 2.874 (2.874)	GS 28.844 (28.844)	mem 7.588
epoch 45, total time 848.54
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [46][1/750]	BT 25.139 (25.139)	DT 25.072 (25.072)	loss 7.797 (7.797)	prob 2.197 (2.197)	GS 36.203 (36.203)	mem 38.694
Train: [46][5/750]	BT 0.024 (5.085)	DT 0.001 (5.044)	loss 7.556 (7.556)	prob 1.887 (1.887)	GS 31.328 (31.328)	mem 38.594
Train: [46][10/750]	BT 0.034 (2.707)	DT 0.001 (2.662)	loss 7.241 (7.241)	prob 2.905 (2.905)	GS 37.484 (37.484)	mem 38.710
Train: [46][15/750]	BT 0.052 (2.429)	DT 0.009 (2.386)	loss 7.245 (7.245)	prob 2.851 (2.851)	GS 26.156 (26.156)	mem 38.918
Train: [46][20/750]	BT 4.820 (2.118)	DT 4.785 (2.077)	loss 7.012 (7.012)	prob 3.291 (3.291)	GS 33.453 (33.453)	mem 38.867
Train: [46][25/750]	BT 4.339 (1.872)	DT 4.311 (1.834)	loss 7.142 (7.142)	prob 3.191 (3.191)	GS 30.547 (30.547)	mem 39.138
Train: [46][30/750]	BT 3.471 (1.772)	DT 3.427 (1.731)	loss 7.495 (7.495)	prob 2.837 (2.837)	GS 34.984 (34.984)	mem 38.875
Train: [46][35/750]	BT 0.075 (1.579)	DT 0.002 (1.533)	loss 7.213 (7.213)	prob 3.567 (3.567)	GS 30.562 (30.562)	mem 38.927
Train: [46][40/750]	BT 5.666 (1.599)	DT 5.620 (1.554)	loss 7.947 (7.947)	prob 3.341 (3.341)	GS 33.422 (33.422)	mem 38.947
Train: [46][45/750]	BT 0.071 (1.471)	DT 0.007 (1.425)	loss 6.830 (6.830)	prob 3.546 (3.546)	GS 31.594 (31.594)	mem 39.090
Train: [46][50/750]	BT 3.708 (1.401)	DT 3.681 (1.356)	loss 7.454 (7.454)	prob 3.170 (3.170)	GS 34.328 (34.328)	mem 39.048
Train: [46][55/750]	BT 0.040 (1.421)	DT 0.001 (1.378)	loss 7.226 (7.226)	prob 2.923 (2.923)	GS 29.516 (29.516)	mem 38.959
Train: [46][60/750]	BT 2.798 (1.353)	DT 2.761 (1.310)	loss 7.318 (7.318)	prob 3.647 (3.647)	GS 33.609 (33.609)	mem 39.015
Train: [46][65/750]	BT 0.034 (1.419)	DT 0.001 (1.376)	loss 7.338 (7.338)	prob 3.120 (3.120)	GS 30.703 (30.703)	mem 39.089
Train: [46][70/750]	BT 0.050 (1.329)	DT 0.010 (1.287)	loss 7.218 (7.218)	prob 3.263 (3.263)	GS 32.000 (32.000)	mem 39.118
Train: [46][75/750]	BT 0.033 (1.297)	DT 0.001 (1.254)	loss 7.584 (7.584)	prob 2.464 (2.464)	GS 34.219 (34.219)	mem 39.096
Train: [46][80/750]	BT 0.030 (1.386)	DT 0.001 (1.343)	loss 7.029 (7.029)	prob 2.990 (2.990)	GS 31.938 (31.938)	mem 39.119
Train: [46][85/750]	BT 0.025 (1.306)	DT 0.001 (1.264)	loss 7.213 (7.213)	prob 2.620 (2.620)	GS 30.703 (30.703)	mem 39.119
Train: [46][90/750]	BT 9.665 (1.388)	DT 9.592 (1.346)	loss 7.255 (7.255)	prob 2.163 (2.163)	GS 33.312 (33.312)	mem 39.102
Train: [46][95/750]	BT 0.067 (1.318)	DT 0.009 (1.275)	loss 7.028 (7.028)	prob 2.821 (2.821)	GS 27.062 (27.062)	mem 39.162
Train: [46][100/750]	BT 4.457 (1.299)	DT 4.410 (1.256)	loss 7.130 (7.130)	prob 3.451 (3.451)	GS 31.156 (31.156)	mem 39.310
Train: [46][105/750]	BT 0.034 (1.337)	DT 0.001 (1.294)	loss 7.755 (7.755)	prob 1.963 (1.963)	GS 39.188 (39.188)	mem 39.154
Train: [46][110/750]	BT 0.034 (1.278)	DT 0.001 (1.236)	loss 7.504 (7.504)	prob 2.353 (2.353)	GS 35.562 (35.562)	mem 39.153
Train: [46][115/750]	BT 0.033 (1.311)	DT 0.002 (1.268)	loss 7.352 (7.352)	prob 3.446 (3.446)	GS 31.734 (31.734)	mem 39.336
Train: [46][120/750]	BT 3.154 (1.297)	DT 3.126 (1.254)	loss 7.650 (7.650)	prob 3.227 (3.227)	GS 33.719 (33.719)	mem 39.156
Train: [46][125/750]	BT 0.037 (1.284)	DT 0.008 (1.240)	loss 7.232 (7.232)	prob 2.978 (2.978)	GS 32.078 (32.078)	mem 39.200
Train: [46][130/750]	BT 2.814 (1.283)	DT 2.785 (1.240)	loss 7.136 (7.136)	prob 2.837 (2.837)	GS 35.609 (35.609)	mem 39.253
Train: [46][135/750]	BT 0.034 (1.253)	DT 0.001 (1.210)	loss 7.430 (7.430)	prob 2.145 (2.145)	GS 33.453 (33.453)	mem 39.216
Train: [46][140/750]	BT 2.655 (1.280)	DT 2.599 (1.236)	loss 7.153 (7.153)	prob 2.909 (2.909)	GS 34.656 (34.656)	mem 39.311
Train: [46][145/750]	BT 0.033 (1.285)	DT 0.002 (1.241)	loss 7.253 (7.253)	prob 2.162 (2.162)	GS 29.031 (29.031)	mem 39.259
Train: [46][150/750]	BT 3.532 (1.266)	DT 3.498 (1.223)	loss 7.354 (7.354)	prob 3.125 (3.125)	GS 35.594 (35.594)	mem 39.272
Train: [46][155/750]	BT 0.043 (1.263)	DT 0.002 (1.220)	loss 7.142 (7.142)	prob 2.938 (2.938)	GS 31.625 (31.625)	mem 39.287
Train: [46][160/750]	BT 0.060 (1.240)	DT 0.006 (1.196)	loss 7.322 (7.322)	prob 2.626 (2.626)	GS 33.719 (33.719)	mem 39.292
Train: [46][165/750]	BT 0.042 (1.271)	DT 0.001 (1.228)	loss 7.848 (7.848)	prob 1.729 (1.729)	GS 27.422 (27.422)	mem 39.294
Train: [46][170/750]	BT 0.038 (1.242)	DT 0.002 (1.199)	loss 7.238 (7.238)	prob 3.056 (3.056)	GS 31.906 (31.906)	mem 39.400
Train: [46][175/750]	BT 0.044 (1.231)	DT 0.002 (1.188)	loss 7.628 (7.628)	prob 2.192 (2.192)	GS 35.297 (35.297)	mem 39.401
Train: [46][180/750]	BT 0.033 (1.248)	DT 0.002 (1.204)	loss 7.071 (7.071)	prob 2.815 (2.815)	GS 36.781 (36.781)	mem 39.324
Train: [46][185/750]	BT 0.071 (1.215)	DT 0.011 (1.172)	loss 7.093 (7.093)	prob 3.130 (3.130)	GS 27.484 (27.484)	mem 39.334
Train: [46][190/750]	BT 3.885 (1.262)	DT 3.800 (1.218)	loss 7.095 (7.095)	prob 3.528 (3.528)	GS 30.078 (30.078)	mem 39.567
Train: [46][195/750]	BT 0.077 (1.238)	DT 0.029 (1.194)	loss 7.436 (7.436)	prob 3.085 (3.085)	GS 34.062 (34.062)	mem 39.586
Train: [46][200/750]	BT 9.304 (1.254)	DT 9.251 (1.211)	loss 7.163 (7.163)	prob 3.466 (3.466)	GS 35.906 (35.906)	mem 39.614
Train: [46][205/750]	BT 0.055 (1.233)	DT 0.010 (1.190)	loss 7.363 (7.363)	prob 2.882 (2.882)	GS 31.781 (31.781)	mem 39.554
Train: [46][210/750]	BT 0.908 (1.210)	DT 0.876 (1.166)	loss 7.411 (7.411)	prob 2.884 (2.884)	GS 32.766 (32.766)	mem 39.535
Train: [46][215/750]	BT 0.066 (1.240)	DT 0.029 (1.195)	loss 7.240 (7.240)	prob 3.833 (3.833)	GS 31.875 (31.875)	mem 39.557
Train: [46][220/750]	BT 0.067 (1.220)	DT 0.013 (1.175)	loss 7.550 (7.550)	prob 3.049 (3.049)	GS 34.453 (34.453)	mem 39.526
Train: [46][225/750]	BT 0.032 (1.247)	DT 0.001 (1.201)	loss 7.691 (7.691)	prob 2.517 (2.517)	GS 31.141 (31.141)	mem 39.538
Train: [46][230/750]	BT 0.043 (1.221)	DT 0.001 (1.175)	loss 7.241 (7.241)	prob 3.029 (3.029)	GS 31.703 (31.703)	mem 39.538
Train: [46][235/750]	BT 0.036 (1.206)	DT 0.002 (1.161)	loss 7.316 (7.316)	prob 3.158 (3.158)	GS 28.438 (28.438)	mem 39.671
Train: [46][240/750]	BT 0.024 (1.222)	DT 0.001 (1.177)	loss 7.589 (7.589)	prob 2.670 (2.670)	GS 31.422 (31.422)	mem 39.618
Train: [46][245/750]	BT 0.027 (1.198)	DT 0.001 (1.153)	loss 7.179 (7.179)	prob 2.261 (2.261)	GS 27.156 (27.156)	mem 39.736
Train: [46][250/750]	BT 0.062 (1.231)	DT 0.004 (1.186)	loss 7.472 (7.472)	prob 2.497 (2.497)	GS 35.625 (35.625)	mem 39.568
Train: [46][255/750]	BT 0.031 (1.208)	DT 0.001 (1.163)	loss 7.259 (7.259)	prob 2.576 (2.576)	GS 31.281 (31.281)	mem 39.571
Train: [46][260/750]	BT 9.752 (1.237)	DT 9.705 (1.192)	loss 7.186 (7.186)	prob 2.686 (2.686)	GS 34.469 (34.469)	mem 39.619
Train: [46][265/750]	BT 0.033 (1.214)	DT 0.002 (1.170)	loss 7.297 (7.297)	prob 3.040 (3.040)	GS 29.406 (29.406)	mem 39.646
Train: [46][270/750]	BT 5.555 (1.213)	DT 5.512 (1.169)	loss 7.209 (7.209)	prob 3.087 (3.087)	GS 32.609 (32.609)	mem 39.695
Train: [46][275/750]	BT 0.029 (1.212)	DT 0.001 (1.167)	loss 7.556 (7.556)	prob 2.722 (2.722)	GS 32.906 (32.906)	mem 39.713
Train: [46][280/750]	BT 0.054 (1.194)	DT 0.002 (1.149)	loss 7.714 (7.714)	prob 2.747 (2.747)	GS 30.672 (30.672)	mem 39.823
Train: [46][285/750]	BT 0.034 (1.216)	DT 0.002 (1.171)	loss 7.166 (7.166)	prob 3.442 (3.442)	GS 29.812 (29.812)	mem 39.756
Train: [46][290/750]	BT 0.093 (1.208)	DT 0.017 (1.163)	loss 7.353 (7.353)	prob 3.239 (3.239)	GS 35.297 (35.297)	mem 39.798
Train: [46][295/750]	BT 0.078 (1.196)	DT 0.005 (1.151)	loss 7.541 (7.541)	prob 2.474 (2.474)	GS 28.828 (28.828)	mem 39.807
Train: [46][300/750]	BT 0.098 (1.209)	DT 0.011 (1.163)	loss 6.938 (6.938)	prob 3.335 (3.335)	GS 31.469 (31.469)	mem 39.759
Train: [46][305/750]	BT 0.036 (1.190)	DT 0.003 (1.144)	loss 7.553 (7.553)	prob 2.664 (2.664)	GS 29.734 (29.734)	mem 39.951
Train: [46][310/750]	BT 0.057 (1.221)	DT 0.005 (1.176)	loss 7.191 (7.191)	prob 3.262 (3.262)	GS 33.484 (33.484)	mem 39.804
Train: [46][315/750]	BT 0.031 (1.202)	DT 0.001 (1.157)	loss 7.305 (7.305)	prob 3.298 (3.298)	GS 30.172 (30.172)	mem 39.804
Train: [46][320/750]	BT 7.366 (1.226)	DT 7.308 (1.180)	loss 7.077 (7.077)	prob 3.250 (3.250)	GS 37.016 (37.016)	mem 39.790
Train: [46][325/750]	BT 0.079 (1.208)	DT 0.015 (1.162)	loss 7.308 (7.308)	prob 2.629 (2.629)	GS 27.031 (27.031)	mem 39.909
Train: [46][330/750]	BT 5.672 (1.207)	DT 5.647 (1.162)	loss 7.007 (7.007)	prob 3.978 (3.978)	GS 31.781 (31.781)	mem 39.780
Train: [46][335/750]	BT 0.066 (1.213)	DT 0.018 (1.168)	loss 7.111 (7.111)	prob 3.892 (3.892)	GS 33.734 (33.734)	mem 39.902
Train: [46][340/750]	BT 0.060 (1.196)	DT 0.008 (1.151)	loss 6.938 (6.938)	prob 3.626 (3.626)	GS 35.062 (35.062)	mem 39.980
Train: [46][345/750]	BT 0.036 (1.218)	DT 0.001 (1.173)	loss 7.011 (7.011)	prob 3.457 (3.457)	GS 32.188 (32.188)	mem 39.905
Train: [46][350/750]	BT 0.049 (1.201)	DT 0.013 (1.156)	loss 7.396 (7.396)	prob 3.111 (3.111)	GS 35.391 (35.391)	mem 39.905
Train: [46][355/750]	BT 0.080 (1.201)	DT 0.021 (1.156)	loss 7.639 (7.639)	prob 2.209 (2.209)	GS 33.469 (33.469)	mem 39.887
Train: [46][360/750]	BT 0.029 (1.202)	DT 0.001 (1.157)	loss 7.074 (7.074)	prob 3.231 (3.231)	GS 32.125 (32.125)	mem 39.939
Train: [46][365/750]	BT 0.042 (1.186)	DT 0.003 (1.141)	loss 7.259 (7.259)	prob 2.818 (2.818)	GS 32.156 (32.156)	mem 39.999
Train: [46][370/750]	BT 0.036 (1.202)	DT 0.002 (1.157)	loss 7.101 (7.101)	prob 2.799 (2.799)	GS 34.156 (34.156)	mem 39.973
Train: [46][375/750]	BT 0.044 (1.187)	DT 0.002 (1.141)	loss 7.442 (7.442)	prob 2.912 (2.912)	GS 29.891 (29.891)	mem 39.912
Train: [46][380/750]	BT 11.467 (1.207)	DT 11.437 (1.162)	loss 7.174 (7.174)	prob 2.963 (2.963)	GS 32.359 (32.359)	mem 39.933
Train: [46][385/750]	BT 0.025 (1.192)	DT 0.001 (1.147)	loss 6.977 (6.977)	prob 3.205 (3.205)	GS 29.281 (29.281)	mem 39.932
Train: [46][390/750]	BT 0.508 (1.178)	DT 0.451 (1.134)	loss 7.058 (7.058)	prob 3.277 (3.277)	GS 31.672 (31.672)	mem 39.909
Train: [46][395/750]	BT 0.073 (1.196)	DT 0.008 (1.151)	loss 7.587 (7.587)	prob 2.570 (2.570)	GS 39.781 (39.781)	mem 39.924
Train: [46][400/750]	BT 0.047 (1.181)	DT 0.002 (1.137)	loss 6.911 (6.911)	prob 3.949 (3.949)	GS 31.250 (31.250)	mem 39.924
Train: [46][405/750]	BT 0.043 (1.198)	DT 0.002 (1.153)	loss 6.997 (6.997)	prob 3.202 (3.202)	GS 31.656 (31.656)	mem 39.925
Train: [46][410/750]	BT 0.082 (1.184)	DT 0.001 (1.139)	loss 7.064 (7.064)	prob 3.523 (3.523)	GS 36.188 (36.188)	mem 39.925
Train: [46][415/750]	BT 0.059 (1.179)	DT 0.008 (1.134)	loss 7.193 (7.193)	prob 2.532 (2.532)	GS 28.969 (28.969)	mem 40.327
Train: [46][420/750]	BT 0.033 (1.185)	DT 0.001 (1.141)	loss 6.993 (6.993)	prob 3.472 (3.472)	GS 32.875 (32.875)	mem 39.943
Train: [46][425/750]	BT 0.058 (1.172)	DT 0.001 (1.127)	loss 7.021 (7.021)	prob 3.441 (3.441)	GS 29.078 (29.078)	mem 40.192
Train: [46][430/750]	BT 3.262 (1.191)	DT 3.238 (1.146)	loss 6.875 (6.875)	prob 3.499 (3.499)	GS 39.312 (39.312)	mem 39.869
Train: [46][435/750]	BT 0.031 (1.177)	DT 0.001 (1.133)	loss 7.332 (7.332)	prob 3.346 (3.346)	GS 27.781 (27.781)	mem 39.871
Train: [46][440/750]	BT 3.256 (1.185)	DT 3.208 (1.140)	loss 7.150 (7.150)	prob 3.414 (3.414)	GS 35.359 (35.359)	mem 39.925
Train: [46][445/750]	BT 0.042 (1.177)	DT 0.005 (1.133)	loss 7.363 (7.363)	prob 2.372 (2.372)	GS 35.203 (35.203)	mem 39.931
Train: [46][450/750]	BT 7.937 (1.182)	DT 7.906 (1.138)	loss 7.146 (7.146)	prob 2.335 (2.335)	GS 36.281 (36.281)	mem 39.979
Train: [46][455/750]	BT 0.022 (1.185)	DT 0.001 (1.141)	loss 7.411 (7.411)	prob 2.131 (2.131)	GS 30.734 (30.734)	mem 39.904
Train: [46][460/750]	BT 0.022 (1.173)	DT 0.001 (1.128)	loss 7.299 (7.299)	prob 2.529 (2.529)	GS 34.891 (34.891)	mem 39.928
Train: [46][465/750]	BT 0.031 (1.180)	DT 0.002 (1.136)	loss 7.217 (7.217)	prob 2.704 (2.704)	GS 28.938 (28.938)	mem 39.911
Train: [46][470/750]	BT 0.054 (1.173)	DT 0.008 (1.128)	loss 6.963 (6.963)	prob 3.100 (3.100)	GS 31.562 (31.562)	mem 39.873
Train: [46][475/750]	BT 0.050 (1.180)	DT 0.004 (1.136)	loss 7.445 (7.445)	prob 2.533 (2.533)	GS 32.516 (32.516)	mem 39.951
Train: [46][480/750]	BT 0.039 (1.172)	DT 0.002 (1.128)	loss 7.052 (7.052)	prob 2.841 (2.841)	GS 33.906 (33.906)	mem 39.892
Train: [46][485/750]	BT 0.084 (1.160)	DT 0.002 (1.116)	loss 7.126 (7.126)	prob 2.892 (2.892)	GS 30.734 (30.734)	mem 39.966
Train: [46][490/750]	BT 1.779 (1.178)	DT 1.748 (1.134)	loss 7.004 (7.004)	prob 3.221 (3.221)	GS 31.344 (31.344)	mem 39.838
Train: [46][495/750]	BT 0.053 (1.166)	DT 0.006 (1.122)	loss 7.165 (7.165)	prob 2.930 (2.930)	GS 35.703 (35.703)	mem 39.912
Train: [46][500/750]	BT 0.032 (1.176)	DT 0.001 (1.132)	loss 7.092 (7.092)	prob 3.180 (3.180)	GS 33.844 (33.844)	mem 39.956
Train: [46][505/750]	BT 0.026 (1.170)	DT 0.001 (1.126)	loss 7.288 (7.288)	prob 2.802 (2.802)	GS 28.172 (28.172)	mem 39.896
Train: [46][510/750]	BT 10.462 (1.180)	DT 10.419 (1.136)	loss 7.340 (7.340)	prob 2.775 (2.775)	GS 37.250 (37.250)	mem 39.950
Train: [46][515/750]	BT 0.027 (1.173)	DT 0.001 (1.129)	loss 7.653 (7.653)	prob 2.016 (2.016)	GS 33.344 (33.344)	mem 39.948
Train: [46][520/750]	BT 0.031 (1.162)	DT 0.002 (1.118)	loss 7.106 (7.106)	prob 2.664 (2.664)	GS 32.703 (32.703)	mem 39.948
Train: [46][525/750]	BT 0.022 (1.171)	DT 0.001 (1.127)	loss 6.989 (6.989)	prob 2.796 (2.796)	GS 29.641 (29.641)	mem 39.963
Train: [46][530/750]	BT 0.061 (1.163)	DT 0.001 (1.119)	loss 6.948 (6.948)	prob 2.607 (2.607)	GS 35.125 (35.125)	mem 39.961
Train: [46][535/750]	BT 0.039 (1.175)	DT 0.001 (1.131)	loss 6.930 (6.930)	prob 2.840 (2.840)	GS 30.609 (30.609)	mem 39.977
Train: [46][540/750]	BT 0.033 (1.165)	DT 0.001 (1.121)	loss 7.207 (7.207)	prob 2.933 (2.933)	GS 28.531 (28.531)	mem 39.975
Train: [46][545/750]	BT 0.096 (1.155)	DT 0.001 (1.111)	loss 7.428 (7.428)	prob 2.203 (2.203)	GS 29.234 (29.234)	mem 40.142
Train: [46][550/750]	BT 1.494 (1.170)	DT 1.426 (1.126)	loss 7.131 (7.131)	prob 2.991 (2.991)	GS 33.250 (33.250)	mem 39.847
Train: [46][555/750]	BT 0.053 (1.159)	DT 0.015 (1.116)	loss 7.358 (7.358)	prob 2.256 (2.256)	GS 39.047 (39.047)	mem 39.848
Train: [46][560/750]	BT 0.034 (1.166)	DT 0.002 (1.123)	loss 7.187 (7.187)	prob 2.755 (2.755)	GS 35.969 (35.969)	mem 40.039
Train: [46][565/750]	BT 0.141 (1.158)	DT 0.004 (1.114)	loss 7.295 (7.295)	prob 2.917 (2.917)	GS 31.234 (31.234)	mem 39.922
Train: [46][570/750]	BT 15.163 (1.175)	DT 15.114 (1.131)	loss 7.125 (7.125)	prob 2.536 (2.536)	GS 32.438 (32.438)	mem 39.948
Train: [46][575/750]	BT 0.030 (1.165)	DT 0.001 (1.122)	loss 7.263 (7.263)	prob 2.918 (2.918)	GS 31.000 (31.000)	mem 39.882
Train: [46][580/750]	BT 0.041 (1.156)	DT 0.002 (1.112)	loss 7.119 (7.119)	prob 2.454 (2.454)	GS 37.078 (37.078)	mem 39.914
Train: [46][585/750]	BT 0.107 (1.164)	DT 0.016 (1.120)	loss 7.386 (7.386)	prob 2.078 (2.078)	GS 33.109 (33.109)	mem 39.965
Train: [46][590/750]	BT 3.167 (1.160)	DT 3.092 (1.116)	loss 7.149 (7.149)	prob 2.745 (2.745)	GS 35.906 (35.906)	mem 39.846
Train: [46][595/750]	BT 0.067 (1.171)	DT 0.016 (1.127)	loss 6.934 (6.934)	prob 3.221 (3.221)	GS 31.688 (31.688)	mem 40.062
Train: [46][600/750]	BT 0.046 (1.161)	DT 0.014 (1.117)	loss 7.160 (7.160)	prob 2.388 (2.388)	GS 33.828 (33.828)	mem 40.004
Train: [46][605/750]	BT 0.053 (1.156)	DT 0.004 (1.112)	loss 6.985 (6.985)	prob 2.308 (2.308)	GS 31.422 (31.422)	mem 40.020
Train: [46][610/750]	BT 0.066 (1.163)	DT 0.003 (1.119)	loss 6.957 (6.957)	prob 2.938 (2.938)	GS 32.531 (32.531)	mem 39.987
Train: [46][615/750]	BT 0.041 (1.157)	DT 0.001 (1.113)	loss 7.079 (7.079)	prob 2.022 (2.022)	GS 34.234 (34.234)	mem 39.929
Train: [46][620/750]	BT 0.077 (1.166)	DT 0.001 (1.122)	loss 7.072 (7.072)	prob 2.683 (2.683)	GS 35.359 (35.359)	mem 40.111
Train: [46][625/750]	BT 0.050 (1.158)	DT 0.007 (1.113)	loss 7.139 (7.139)	prob 2.473 (2.473)	GS 35.469 (35.469)	mem 40.070
Train: [46][630/750]	BT 13.656 (1.173)	DT 13.616 (1.129)	loss 7.344 (7.344)	prob 2.605 (2.605)	GS 37.438 (37.438)	mem 39.982
Train: [46][635/750]	BT 0.042 (1.165)	DT 0.001 (1.120)	loss 7.226 (7.226)	prob 1.876 (1.876)	GS 39.297 (39.297)	mem 39.932
Train: [46][640/750]	BT 0.032 (1.156)	DT 0.001 (1.112)	loss 7.086 (7.086)	prob 2.873 (2.873)	GS 35.500 (35.500)	mem 39.933
Train: [46][645/750]	BT 0.039 (1.167)	DT 0.001 (1.123)	loss 6.961 (6.961)	prob 2.459 (2.459)	GS 35.500 (35.500)	mem 40.157
Train: [46][650/750]	BT 0.052 (1.158)	DT 0.002 (1.114)	loss 7.038 (7.038)	prob 2.078 (2.078)	GS 35.594 (35.594)	mem 39.987
Train: [46][655/750]	BT 0.032 (1.170)	DT 0.001 (1.126)	loss 7.190 (7.190)	prob 2.982 (2.982)	GS 35.047 (35.047)	mem 40.096
Train: [46][660/750]	BT 0.045 (1.162)	DT 0.002 (1.117)	loss 6.985 (6.985)	prob 3.143 (3.143)	GS 31.125 (31.125)	mem 40.409
Train: [46][665/750]	BT 0.137 (1.154)	DT 0.085 (1.109)	loss 7.117 (7.117)	prob 2.801 (2.801)	GS 35.516 (35.516)	mem 40.412
Train: [46][670/750]	BT 0.029 (1.169)	DT 0.001 (1.124)	loss 7.154 (7.154)	prob 2.388 (2.388)	GS 33.203 (33.203)	mem 40.014
Train: [46][675/750]	BT 0.027 (1.160)	DT 0.001 (1.116)	loss 7.050 (7.050)	prob 2.387 (2.387)	GS 29.547 (29.547)	mem 40.014
Train: [46][680/750]	BT 5.072 (1.175)	DT 5.009 (1.130)	loss 6.930 (6.930)	prob 2.235 (2.235)	GS 35.219 (35.219)	mem 39.983
Train: [46][685/750]	BT 0.039 (1.166)	DT 0.012 (1.122)	loss 6.987 (6.987)	prob 3.195 (3.195)	GS 31.328 (31.328)	mem 39.889
Train: [46][690/750]	BT 6.971 (1.168)	DT 6.880 (1.124)	loss 6.893 (6.893)	prob 3.016 (3.016)	GS 31.656 (31.656)	mem 40.002
Train: [46][695/750]	BT 0.053 (1.167)	DT 0.004 (1.123)	loss 7.131 (7.131)	prob 2.994 (2.994)	GS 33.578 (33.578)	mem 40.002
Train: [46][700/750]	BT 0.072 (1.160)	DT 0.019 (1.115)	loss 6.884 (6.884)	prob 3.171 (3.171)	GS 36.219 (36.219)	mem 40.001
Train: [46][705/750]	BT 0.078 (1.167)	DT 0.010 (1.122)	loss 6.926 (6.926)	prob 3.162 (3.162)	GS 28.438 (28.438)	mem 40.249
Train: [46][710/750]	BT 0.035 (1.159)	DT 0.001 (1.114)	loss 7.163 (7.163)	prob 2.265 (2.265)	GS 37.016 (37.016)	mem 40.100
Train: [46][715/750]	BT 0.054 (1.165)	DT 0.007 (1.121)	loss 6.832 (6.832)	prob 3.156 (3.156)	GS 27.531 (27.531)	mem 39.993
Train: [46][720/750]	BT 0.032 (1.162)	DT 0.001 (1.118)	loss 7.141 (7.141)	prob 2.772 (2.772)	GS 32.031 (32.031)	mem 39.969
Train: [46][725/750]	BT 0.050 (1.155)	DT 0.009 (1.110)	loss 7.209 (7.209)	prob 2.309 (2.309)	GS 34.359 (34.359)	mem 39.989
Train: [46][730/750]	BT 0.049 (1.164)	DT 0.019 (1.119)	loss 6.852 (6.852)	prob 2.720 (2.720)	GS 31.234 (31.234)	mem 39.589
Train: [46][735/750]	BT 0.051 (1.156)	DT 0.010 (1.112)	loss 7.096 (7.096)	prob 2.826 (2.826)	GS 33.703 (33.703)	mem 39.589
Train: [46][740/750]	BT 0.022 (1.157)	DT 0.001 (1.113)	loss 7.000 (7.000)	prob 2.631 (2.631)	GS 29.016 (29.016)	mem 13.611
Train: [46][745/750]	BT 0.020 (1.154)	DT 0.001 (1.110)	loss 7.196 (7.196)	prob 1.903 (1.903)	GS 30.000 (30.000)	mem 7.600
Train: [46][750/750]	BT 0.029 (1.146)	DT 0.001 (1.102)	loss 7.166 (7.166)	prob 2.132 (2.132)	GS 31.094 (31.094)	mem 7.613
Train: [46][755/750]	BT 0.022 (1.139)	DT 0.001 (1.095)	loss 6.942 (6.942)	prob 3.026 (3.026)	GS 29.969 (29.969)	mem 7.652
epoch 46, total time 863.72
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [47][1/750]	BT 20.011 (20.011)	DT 19.959 (19.959)	loss 6.853 (6.853)	prob 2.486 (2.486)	GS 30.031 (30.031)	mem 38.519
Train: [47][5/750]	BT 0.996 (4.714)	DT 0.967 (4.670)	loss 7.338 (7.338)	prob 2.535 (2.535)	GS 35.391 (35.391)	mem 38.704
Train: [47][10/750]	BT 0.033 (2.758)	DT 0.001 (2.717)	loss 6.934 (6.934)	prob 2.769 (2.769)	GS 33.453 (33.453)	mem 38.638
Train: [47][15/750]	BT 0.107 (2.492)	DT 0.003 (2.446)	loss 6.959 (6.959)	prob 2.283 (2.283)	GS 30.797 (30.797)	mem 38.885
Train: [47][20/750]	BT 5.553 (2.162)	DT 5.510 (2.111)	loss 6.704 (6.704)	prob 2.852 (2.852)	GS 33.281 (33.281)	mem 38.824
Train: [47][25/750]	BT 0.034 (1.740)	DT 0.002 (1.689)	loss 6.842 (6.842)	prob 2.754 (2.754)	GS 31.000 (31.000)	mem 39.018
Train: [47][30/750]	BT 0.038 (1.713)	DT 0.002 (1.666)	loss 6.949 (6.949)	prob 2.559 (2.559)	GS 33.594 (33.594)	mem 39.023
Train: [47][35/750]	BT 0.051 (1.685)	DT 0.017 (1.637)	loss 7.276 (7.276)	prob 2.442 (2.442)	GS 33.625 (33.625)	mem 38.882
Train: [47][40/750]	BT 0.109 (1.607)	DT 0.004 (1.558)	loss 6.770 (6.770)	prob 2.858 (2.858)	GS 35.391 (35.391)	mem 38.928
Train: [47][45/750]	BT 0.037 (1.524)	DT 0.008 (1.475)	loss 7.006 (7.006)	prob 2.979 (2.979)	GS 26.750 (26.750)	mem 38.858
Train: [47][50/750]	BT 7.010 (1.570)	DT 6.966 (1.521)	loss 7.064 (7.064)	prob 2.463 (2.463)	GS 32.250 (32.250)	mem 38.907
Train: [47][55/750]	BT 0.026 (1.431)	DT 0.001 (1.383)	loss 7.148 (7.148)	prob 2.222 (2.222)	GS 32.125 (32.125)	mem 38.907
Train: [47][60/750]	BT 0.040 (1.389)	DT 0.001 (1.342)	loss 6.909 (6.909)	prob 2.387 (2.387)	GS 33.297 (33.297)	mem 38.965
Train: [47][65/750]	BT 0.062 (1.380)	DT 0.010 (1.333)	loss 7.186 (7.186)	prob 2.372 (2.372)	GS 32.453 (32.453)	mem 38.970
Train: [47][70/750]	BT 0.038 (1.378)	DT 0.002 (1.331)	loss 6.750 (6.750)	prob 2.930 (2.930)	GS 28.078 (28.078)	mem 38.920
Train: [47][75/750]	BT 0.103 (1.414)	DT 0.026 (1.365)	loss 7.254 (7.254)	prob 2.412 (2.412)	GS 39.812 (39.812)	mem 39.154
Train: [47][80/750]	BT 0.765 (1.338)	DT 0.695 (1.289)	loss 6.876 (6.876)	prob 2.905 (2.905)	GS 32.891 (32.891)	mem 39.046
Train: [47][85/750]	BT 0.171 (1.286)	DT 0.022 (1.236)	loss 7.329 (7.329)	prob 1.968 (1.968)	GS 31.422 (31.422)	mem 39.014
Train: [47][90/750]	BT 0.098 (1.322)	DT 0.001 (1.273)	loss 6.874 (6.874)	prob 2.373 (2.373)	GS 31.453 (31.453)	mem 38.992
Train: [47][95/750]	BT 0.034 (1.285)	DT 0.002 (1.236)	loss 7.080 (7.080)	prob 2.329 (2.329)	GS 28.953 (28.953)	mem 38.963
Train: [47][100/750]	BT 0.028 (1.320)	DT 0.002 (1.272)	loss 6.840 (6.840)	prob 2.312 (2.312)	GS 35.906 (35.906)	mem 39.042
Train: [47][105/750]	BT 0.030 (1.269)	DT 0.001 (1.221)	loss 6.686 (6.686)	prob 2.889 (2.889)	GS 26.859 (26.859)	mem 39.043
Train: [47][110/750]	BT 9.732 (1.325)	DT 9.695 (1.277)	loss 6.772 (6.772)	prob 2.446 (2.446)	GS 34.125 (34.125)	mem 39.008
Train: [47][115/750]	BT 0.094 (1.271)	DT 0.002 (1.221)	loss 7.147 (7.147)	prob 2.495 (2.495)	GS 31.484 (31.484)	mem 39.158
Train: [47][120/750]	BT 1.193 (1.229)	DT 1.132 (1.180)	loss 7.061 (7.061)	prob 2.724 (2.724)	GS 31.344 (31.344)	mem 38.992
Train: [47][125/750]	BT 0.032 (1.274)	DT 0.002 (1.225)	loss 7.009 (7.009)	prob 2.301 (2.301)	GS 28.391 (28.391)	mem 39.056
Train: [47][130/750]	BT 0.052 (1.227)	DT 0.013 (1.179)	loss 6.878 (6.878)	prob 2.488 (2.488)	GS 35.016 (35.016)	mem 39.057
Train: [47][135/750]	BT 0.100 (1.265)	DT 0.030 (1.217)	loss 7.036 (7.036)	prob 2.292 (2.292)	GS 31.438 (31.438)	mem 39.108
Train: [47][140/750]	BT 0.049 (1.222)	DT 0.003 (1.174)	loss 7.077 (7.077)	prob 2.761 (2.761)	GS 33.406 (33.406)	mem 39.049
Train: [47][145/750]	BT 0.035 (1.181)	DT 0.002 (1.133)	loss 7.293 (7.293)	prob 2.461 (2.461)	GS 29.531 (29.531)	mem 39.029
Train: [47][150/750]	BT 0.064 (1.221)	DT 0.026 (1.173)	loss 6.894 (6.894)	prob 2.580 (2.580)	GS 33.188 (33.188)	mem 39.107
Train: [47][155/750]	BT 0.154 (1.196)	DT 0.008 (1.148)	loss 6.974 (6.974)	prob 2.663 (2.663)	GS 30.812 (30.812)	mem 39.170
Train: [47][160/750]	BT 0.069 (1.230)	DT 0.023 (1.182)	loss 6.868 (6.868)	prob 2.426 (2.426)	GS 34.672 (34.672)	mem 39.461
Train: [47][165/750]	BT 0.048 (1.207)	DT 0.008 (1.158)	loss 6.892 (6.892)	prob 2.678 (2.678)	GS 32.312 (32.312)	mem 39.331
Train: [47][170/750]	BT 10.778 (1.237)	DT 10.748 (1.188)	loss 6.847 (6.847)	prob 2.836 (2.836)	GS 34.422 (34.422)	mem 39.447
Train: [47][175/750]	BT 0.034 (1.203)	DT 0.003 (1.154)	loss 7.210 (7.210)	prob 2.135 (2.135)	GS 27.406 (27.406)	mem 39.452
Train: [47][180/750]	BT 0.033 (1.181)	DT 0.001 (1.133)	loss 6.664 (6.664)	prob 2.656 (2.656)	GS 35.438 (35.438)	mem 39.451
Train: [47][185/750]	BT 0.027 (1.211)	DT 0.001 (1.163)	loss 6.823 (6.823)	prob 3.065 (3.065)	GS 28.969 (28.969)	mem 39.451
Train: [47][190/750]	BT 3.186 (1.200)	DT 3.153 (1.152)	loss 6.976 (6.976)	prob 2.783 (2.783)	GS 34.656 (34.656)	mem 39.523
Train: [47][195/750]	BT 0.051 (1.212)	DT 0.008 (1.164)	loss 6.924 (6.924)	prob 3.100 (3.100)	GS 32.375 (32.375)	mem 39.408
Train: [47][200/750]	BT 0.086 (1.183)	DT 0.001 (1.135)	loss 6.953 (6.953)	prob 3.246 (3.246)	GS 34.078 (34.078)	mem 39.409
Train: [47][205/750]	BT 0.049 (1.170)	DT 0.002 (1.123)	loss 6.934 (6.934)	prob 2.589 (2.589)	GS 30.750 (30.750)	mem 39.398
Train: [47][210/750]	BT 0.037 (1.188)	DT 0.001 (1.141)	loss 6.766 (6.766)	prob 2.861 (2.861)	GS 32.078 (32.078)	mem 39.442
Train: [47][215/750]	BT 0.054 (1.176)	DT 0.002 (1.128)	loss 7.061 (7.061)	prob 2.458 (2.458)	GS 32.000 (32.000)	mem 39.419
Train: [47][220/750]	BT 0.052 (1.193)	DT 0.011 (1.145)	loss 6.828 (6.828)	prob 3.133 (3.133)	GS 32.922 (32.922)	mem 39.596
Train: [47][225/750]	BT 0.041 (1.171)	DT 0.005 (1.123)	loss 7.351 (7.351)	prob 2.984 (2.984)	GS 36.266 (36.266)	mem 39.455
Train: [47][230/750]	BT 10.015 (1.190)	DT 9.946 (1.142)	loss 6.979 (6.979)	prob 2.796 (2.796)	GS 33.312 (33.312)	mem 39.845
Train: [47][235/750]	BT 0.032 (1.166)	DT 0.001 (1.118)	loss 7.018 (7.018)	prob 2.903 (2.903)	GS 32.484 (32.484)	mem 39.695
Train: [47][240/750]	BT 0.028 (1.178)	DT 0.001 (1.131)	loss 6.872 (6.872)	prob 2.941 (2.941)	GS 35.938 (35.938)	mem 39.693
Train: [47][245/750]	BT 0.034 (1.175)	DT 0.002 (1.127)	loss 7.126 (7.126)	prob 2.996 (2.996)	GS 33.062 (33.062)	mem 39.711
Train: [47][250/750]	BT 0.027 (1.190)	DT 0.001 (1.143)	loss 6.926 (6.926)	prob 3.029 (3.029)	GS 33.859 (33.859)	mem 39.738
Train: [47][255/750]	BT 0.076 (1.168)	DT 0.001 (1.121)	loss 6.822 (6.822)	prob 3.275 (3.275)	GS 29.875 (29.875)	mem 39.738
Train: [47][260/750]	BT 4.999 (1.186)	DT 4.964 (1.139)	loss 7.028 (7.028)	prob 2.816 (2.816)	GS 28.125 (28.125)	mem 39.775
Train: [47][265/750]	BT 0.061 (1.165)	DT 0.023 (1.117)	loss 7.066 (7.066)	prob 2.592 (2.592)	GS 32.125 (32.125)	mem 39.775
Train: [47][270/750]	BT 0.061 (1.156)	DT 0.013 (1.108)	loss 6.877 (6.877)	prob 2.688 (2.688)	GS 36.047 (36.047)	mem 39.780
Train: [47][275/750]	BT 0.043 (1.174)	DT 0.014 (1.127)	loss 6.896 (6.896)	prob 3.085 (3.085)	GS 29.406 (29.406)	mem 39.789
Train: [47][280/750]	BT 0.527 (1.155)	DT 0.482 (1.108)	loss 6.918 (6.918)	prob 3.136 (3.136)	GS 34.844 (34.844)	mem 39.790
Train: [47][285/750]	BT 0.046 (1.191)	DT 0.012 (1.144)	loss 7.317 (7.317)	prob 2.766 (2.766)	GS 29.547 (29.547)	mem 39.758
Train: [47][290/750]	BT 0.031 (1.171)	DT 0.002 (1.124)	loss 6.703 (6.703)	prob 2.339 (2.339)	GS 33.891 (33.891)	mem 39.766
Train: [47][295/750]	BT 0.033 (1.152)	DT 0.003 (1.105)	loss 6.946 (6.946)	prob 2.877 (2.877)	GS 32.156 (32.156)	mem 39.798
Train: [47][300/750]	BT 0.059 (1.174)	DT 0.024 (1.128)	loss 6.940 (6.940)	prob 2.917 (2.917)	GS 37.516 (37.516)	mem 39.809
Train: [47][305/750]	BT 0.056 (1.156)	DT 0.002 (1.109)	loss 7.002 (7.002)	prob 2.587 (2.587)	GS 31.969 (31.969)	mem 39.844
Train: [47][310/750]	BT 0.051 (1.180)	DT 0.001 (1.133)	loss 6.682 (6.682)	prob 3.588 (3.588)	GS 38.422 (38.422)	mem 39.849
Train: [47][315/750]	BT 0.031 (1.162)	DT 0.001 (1.115)	loss 7.122 (7.122)	prob 3.099 (3.099)	GS 30.875 (30.875)	mem 39.850
Train: [47][320/750]	BT 13.750 (1.188)	DT 13.682 (1.141)	loss 6.732 (6.732)	prob 2.824 (2.824)	GS 31.828 (31.828)	mem 39.950
Train: [47][325/750]	BT 0.033 (1.170)	DT 0.001 (1.123)	loss 7.039 (7.039)	prob 2.874 (2.874)	GS 30.359 (30.359)	mem 39.978
Train: [47][330/750]	BT 0.063 (1.154)	DT 0.009 (1.106)	loss 7.071 (7.071)	prob 2.445 (2.445)	GS 36.969 (36.969)	mem 39.885
Train: [47][335/750]	BT 0.045 (1.175)	DT 0.001 (1.128)	loss 6.986 (6.986)	prob 3.249 (3.249)	GS 31.547 (31.547)	mem 39.848
Train: [47][340/750]	BT 0.094 (1.159)	DT 0.002 (1.112)	loss 6.985 (6.985)	prob 3.573 (3.573)	GS 32.672 (32.672)	mem 40.105
Train: [47][345/750]	BT 0.047 (1.178)	DT 0.017 (1.131)	loss 6.978 (6.978)	prob 2.792 (2.792)	GS 28.891 (28.891)	mem 39.940
Train: [47][350/750]	BT 0.032 (1.162)	DT 0.001 (1.115)	loss 6.925 (6.925)	prob 3.269 (3.269)	GS 31.984 (31.984)	mem 39.928
Train: [47][355/750]	BT 0.049 (1.146)	DT 0.011 (1.099)	loss 6.926 (6.926)	prob 2.975 (2.975)	GS 33.688 (33.688)	mem 39.928
Train: [47][360/750]	BT 0.030 (1.166)	DT 0.001 (1.119)	loss 7.147 (7.147)	prob 3.135 (3.135)	GS 32.812 (32.812)	mem 39.887
Train: [47][365/750]	BT 0.030 (1.150)	DT 0.001 (1.103)	loss 7.184 (7.184)	prob 2.848 (2.848)	GS 38.297 (38.297)	mem 39.888
Train: [47][370/750]	BT 0.021 (1.167)	DT 0.001 (1.120)	loss 6.809 (6.809)	prob 2.897 (2.897)	GS 37.219 (37.219)	mem 39.956
Train: [47][375/750]	BT 0.043 (1.154)	DT 0.013 (1.108)	loss 7.131 (7.131)	prob 2.883 (2.883)	GS 31.797 (31.797)	mem 39.889
Train: [47][380/750]	BT 10.457 (1.170)	DT 10.424 (1.124)	loss 6.818 (6.818)	prob 2.852 (2.852)	GS 31.141 (31.141)	mem 39.939
Train: [47][385/750]	BT 0.031 (1.156)	DT 0.001 (1.109)	loss 6.958 (6.958)	prob 3.052 (3.052)	GS 27.828 (27.828)	mem 39.939
Train: [47][390/750]	BT 0.976 (1.150)	DT 0.935 (1.103)	loss 6.874 (6.874)	prob 2.952 (2.952)	GS 32.516 (32.516)	mem 39.916
Train: [47][395/750]	BT 0.043 (1.156)	DT 0.002 (1.110)	loss 6.859 (6.859)	prob 3.246 (3.246)	GS 28.844 (28.844)	mem 39.974
Train: [47][400/750]	BT 0.033 (1.151)	DT 0.002 (1.105)	loss 6.970 (6.970)	prob 3.765 (3.765)	GS 32.344 (32.344)	mem 39.915
Train: [47][405/750]	BT 0.046 (1.154)	DT 0.008 (1.108)	loss 6.969 (6.969)	prob 3.168 (3.168)	GS 27.969 (27.969)	mem 39.887
Train: [47][410/750]	BT 8.629 (1.162)	DT 8.600 (1.116)	loss 6.834 (6.834)	prob 2.973 (2.973)	GS 31.875 (31.875)	mem 39.812
Train: [47][415/750]	BT 0.033 (1.149)	DT 0.002 (1.103)	loss 7.201 (7.201)	prob 2.666 (2.666)	GS 33.625 (33.625)	mem 39.813
Train: [47][420/750]	BT 0.041 (1.140)	DT 0.001 (1.094)	loss 6.684 (6.684)	prob 3.140 (3.140)	GS 35.984 (35.984)	mem 40.011
Train: [47][425/750]	BT 0.050 (1.152)	DT 0.011 (1.106)	loss 6.915 (6.915)	prob 2.773 (2.773)	GS 27.656 (27.656)	mem 40.014
Train: [47][430/750]	BT 0.129 (1.150)	DT 0.007 (1.104)	loss 6.831 (6.831)	prob 2.633 (2.633)	GS 33.312 (33.312)	mem 39.879
Train: [47][435/750]	BT 0.196 (1.144)	DT 0.010 (1.098)	loss 6.682 (6.682)	prob 3.195 (3.195)	GS 41.344 (41.344)	mem 40.229
Train: [47][440/750]	BT 1.694 (1.155)	DT 1.654 (1.108)	loss 6.883 (6.883)	prob 2.499 (2.499)	GS 32.078 (32.078)	mem 39.949
Train: [47][445/750]	BT 0.057 (1.142)	DT 0.028 (1.096)	loss 6.851 (6.851)	prob 3.081 (3.081)	GS 33.125 (33.125)	mem 39.876
Train: [47][450/750]	BT 7.655 (1.156)	DT 7.613 (1.109)	loss 6.709 (6.709)	prob 2.936 (2.936)	GS 34.578 (34.578)	mem 39.982
Train: [47][455/750]	BT 0.033 (1.143)	DT 0.001 (1.097)	loss 6.922 (6.922)	prob 3.180 (3.180)	GS 29.141 (29.141)	mem 40.125
Train: [47][460/750]	BT 1.817 (1.139)	DT 1.770 (1.093)	loss 6.952 (6.952)	prob 2.254 (2.254)	GS 36.188 (36.188)	mem 39.936
Train: [47][465/750]	BT 0.030 (1.147)	DT 0.001 (1.101)	loss 6.827 (6.827)	prob 2.419 (2.419)	GS 31.016 (31.016)	mem 39.837
Train: [47][470/750]	BT 1.463 (1.138)	DT 1.370 (1.092)	loss 6.677 (6.677)	prob 3.114 (3.114)	GS 30.406 (30.406)	mem 39.909
Train: [47][475/750]	BT 0.111 (1.139)	DT 0.012 (1.093)	loss 6.702 (6.702)	prob 2.585 (2.585)	GS 32.828 (32.828)	mem 39.900
Train: [47][480/750]	BT 0.042 (1.139)	DT 0.007 (1.093)	loss 7.034 (7.034)	prob 2.620 (2.620)	GS 34.188 (34.188)	mem 39.950
Train: [47][485/750]	BT 0.070 (1.135)	DT 0.033 (1.089)	loss 7.034 (7.034)	prob 2.364 (2.364)	GS 31.297 (31.297)	mem 39.993
Train: [47][490/750]	BT 0.041 (1.144)	DT 0.001 (1.098)	loss 6.805 (6.805)	prob 2.874 (2.874)	GS 33.156 (33.156)	mem 39.877
Train: [47][495/750]	BT 0.106 (1.135)	DT 0.013 (1.089)	loss 7.217 (7.217)	prob 2.919 (2.919)	GS 31.203 (31.203)	mem 39.889
Train: [47][500/750]	BT 5.985 (1.148)	DT 5.921 (1.102)	loss 6.802 (6.802)	prob 2.894 (2.894)	GS 35.281 (35.281)	mem 39.785
Train: [47][505/750]	BT 0.055 (1.137)	DT 0.003 (1.091)	loss 6.777 (6.777)	prob 2.895 (2.895)	GS 26.766 (26.766)	mem 39.786
Train: [47][510/750]	BT 2.384 (1.134)	DT 2.354 (1.087)	loss 6.964 (6.964)	prob 2.577 (2.577)	GS 28.422 (28.422)	mem 39.831
Train: [47][515/750]	BT 0.050 (1.138)	DT 0.002 (1.092)	loss 6.920 (6.920)	prob 3.140 (3.140)	GS 32.531 (32.531)	mem 40.002
Train: [47][520/750]	BT 5.981 (1.139)	DT 5.949 (1.093)	loss 6.951 (6.951)	prob 2.587 (2.587)	GS 36.266 (36.266)	mem 39.992
Train: [47][525/750]	BT 0.049 (1.143)	DT 0.002 (1.097)	loss 7.016 (7.016)	prob 2.053 (2.053)	GS 32.172 (32.172)	mem 39.965
Train: [47][530/750]	BT 0.043 (1.133)	DT 0.002 (1.087)	loss 6.921 (6.921)	prob 2.172 (2.172)	GS 32.172 (32.172)	mem 40.026
Train: [47][535/750]	BT 0.032 (1.128)	DT 0.002 (1.081)	loss 6.842 (6.842)	prob 2.247 (2.247)	GS 29.672 (29.672)	mem 39.935
Train: [47][540/750]	BT 0.069 (1.132)	DT 0.008 (1.085)	loss 6.633 (6.633)	prob 3.543 (3.543)	GS 34.984 (34.984)	mem 39.996
Train: [47][545/750]	BT 0.056 (1.135)	DT 0.014 (1.089)	loss 7.066 (7.066)	prob 2.013 (2.013)	GS 30.672 (30.672)	mem 39.962
Train: [47][550/750]	BT 0.031 (1.136)	DT 0.001 (1.090)	loss 6.797 (6.797)	prob 2.856 (2.856)	GS 33.578 (33.578)	mem 39.941
Train: [47][555/750]	BT 0.024 (1.126)	DT 0.001 (1.080)	loss 6.724 (6.724)	prob 2.642 (2.642)	GS 29.984 (29.984)	mem 39.942
Train: [47][560/750]	BT 4.973 (1.140)	DT 4.943 (1.094)	loss 6.787 (6.787)	prob 2.738 (2.738)	GS 34.078 (34.078)	mem 39.914
Train: [47][565/750]	BT 0.103 (1.131)	DT 0.021 (1.084)	loss 6.765 (6.765)	prob 2.211 (2.211)	GS 31.500 (31.500)	mem 39.982
Train: [47][570/750]	BT 3.626 (1.140)	DT 3.585 (1.094)	loss 6.845 (6.845)	prob 2.271 (2.271)	GS 32.594 (32.594)	mem 39.964
Train: [47][575/750]	BT 0.022 (1.137)	DT 0.001 (1.091)	loss 6.661 (6.661)	prob 3.384 (3.384)	GS 31.406 (31.406)	mem 39.993
Train: [47][580/750]	BT 2.532 (1.132)	DT 2.491 (1.085)	loss 6.875 (6.875)	prob 2.667 (2.667)	GS 31.703 (31.703)	mem 40.121
Train: [47][585/750]	BT 0.061 (1.142)	DT 0.008 (1.096)	loss 6.964 (6.964)	prob 2.529 (2.529)	GS 30.109 (30.109)	mem 39.854
Train: [47][590/750]	BT 0.058 (1.133)	DT 0.007 (1.087)	loss 6.768 (6.768)	prob 2.770 (2.770)	GS 32.703 (32.703)	mem 39.970
Train: [47][595/750]	BT 0.030 (1.132)	DT 0.001 (1.085)	loss 7.075 (7.075)	prob 1.778 (1.778)	GS 33.125 (33.125)	mem 39.893
Train: [47][600/750]	BT 0.041 (1.138)	DT 0.001 (1.091)	loss 6.751 (6.751)	prob 2.783 (2.783)	GS 32.094 (32.094)	mem 39.884
Train: [47][605/750]	BT 0.031 (1.129)	DT 0.001 (1.082)	loss 6.993 (6.993)	prob 2.156 (2.156)	GS 30.266 (30.266)	mem 39.899
Train: [47][610/750]	BT 0.033 (1.144)	DT 0.002 (1.098)	loss 7.125 (7.125)	prob 2.472 (2.472)	GS 36.922 (36.922)	mem 39.933
Train: [47][615/750]	BT 0.059 (1.135)	DT 0.006 (1.089)	loss 6.933 (6.933)	prob 2.593 (2.593)	GS 24.031 (24.031)	mem 39.935
Train: [47][620/750]	BT 5.792 (1.149)	DT 5.760 (1.102)	loss 6.662 (6.662)	prob 2.932 (2.932)	GS 37.734 (37.734)	mem 39.937
Train: [47][625/750]	BT 0.058 (1.140)	DT 0.002 (1.093)	loss 7.210 (7.210)	prob 2.156 (2.156)	GS 29.484 (29.484)	mem 39.939
Train: [47][630/750]	BT 5.515 (1.140)	DT 5.412 (1.093)	loss 6.927 (6.927)	prob 2.301 (2.301)	GS 33.078 (33.078)	mem 40.104
Train: [47][635/750]	BT 0.034 (1.143)	DT 0.001 (1.096)	loss 7.056 (7.056)	prob 2.513 (2.513)	GS 35.156 (35.156)	mem 40.216
Train: [47][640/750]	BT 0.039 (1.134)	DT 0.003 (1.088)	loss 6.830 (6.830)	prob 2.723 (2.723)	GS 31.625 (31.625)	mem 40.161
Train: [47][645/750]	BT 0.030 (1.145)	DT 0.001 (1.099)	loss 6.903 (6.903)	prob 3.024 (3.024)	GS 30.703 (30.703)	mem 39.905
Train: [47][650/750]	BT 0.039 (1.137)	DT 0.009 (1.090)	loss 6.657 (6.657)	prob 2.579 (2.579)	GS 33.531 (33.531)	mem 39.906
Train: [47][655/750]	BT 0.033 (1.130)	DT 0.002 (1.083)	loss 6.831 (6.831)	prob 2.310 (2.310)	GS 28.516 (28.516)	mem 39.977
Train: [47][660/750]	BT 0.052 (1.138)	DT 0.010 (1.091)	loss 6.559 (6.559)	prob 3.450 (3.450)	GS 33.062 (33.062)	mem 39.950
Train: [47][665/750]	BT 0.063 (1.129)	DT 0.012 (1.083)	loss 6.985 (6.985)	prob 2.441 (2.441)	GS 34.078 (34.078)	mem 39.950
Train: [47][670/750]	BT 0.032 (1.139)	DT 0.001 (1.093)	loss 7.014 (7.014)	prob 2.669 (2.669)	GS 31.016 (31.016)	mem 39.971
Train: [47][675/750]	BT 0.059 (1.131)	DT 0.007 (1.085)	loss 7.163 (7.163)	prob 2.453 (2.453)	GS 32.766 (32.766)	mem 39.989
Train: [47][680/750]	BT 7.235 (1.140)	DT 7.187 (1.094)	loss 7.045 (7.045)	prob 2.769 (2.769)	GS 35.297 (35.297)	mem 39.978
Train: [47][685/750]	BT 0.029 (1.132)	DT 0.003 (1.086)	loss 7.050 (7.050)	prob 2.499 (2.499)	GS 27.875 (27.875)	mem 39.980
Train: [47][690/750]	BT 2.700 (1.128)	DT 2.675 (1.082)	loss 6.650 (6.650)	prob 2.644 (2.644)	GS 33.781 (33.781)	mem 39.980
Train: [47][695/750]	BT 0.031 (1.131)	DT 0.001 (1.085)	loss 7.342 (7.342)	prob 1.926 (1.926)	GS 32.562 (32.562)	mem 39.951
Train: [47][700/750]	BT 0.048 (1.123)	DT 0.001 (1.077)	loss 6.941 (6.941)	prob 2.589 (2.589)	GS 31.531 (31.531)	mem 39.951
Train: [47][705/750]	BT 0.035 (1.132)	DT 0.002 (1.086)	loss 6.641 (6.641)	prob 2.662 (2.662)	GS 26.766 (26.766)	mem 40.205
Train: [47][710/750]	BT 0.046 (1.128)	DT 0.001 (1.082)	loss 6.885 (6.885)	prob 2.071 (2.071)	GS 37.406 (37.406)	mem 39.971
Train: [47][715/750]	BT 0.060 (1.129)	DT 0.002 (1.083)	loss 6.918 (6.918)	prob 2.543 (2.543)	GS 32.500 (32.500)	mem 39.975
Train: [47][720/750]	BT 0.030 (1.132)	DT 0.001 (1.085)	loss 6.952 (6.952)	prob 2.401 (2.401)	GS 32.562 (32.562)	mem 39.992
Train: [47][725/750]	BT 0.023 (1.124)	DT 0.001 (1.078)	loss 6.881 (6.881)	prob 2.423 (2.423)	GS 31.906 (31.906)	mem 39.994
Train: [47][730/750]	BT 0.075 (1.132)	DT 0.022 (1.085)	loss 6.813 (6.813)	prob 2.737 (2.737)	GS 33.562 (33.562)	mem 39.698
Train: [47][735/750]	BT 0.040 (1.124)	DT 0.001 (1.078)	loss 6.726 (6.726)	prob 1.868 (1.868)	GS 29.562 (29.562)	mem 39.697
Train: [47][740/750]	BT 5.311 (1.128)	DT 5.281 (1.083)	loss 6.877 (6.877)	prob 2.710 (2.710)	GS 34.453 (34.453)	mem 10.542
Train: [47][745/750]	BT 0.022 (1.122)	DT 0.001 (1.076)	loss 6.643 (6.643)	prob 2.438 (2.438)	GS 27.656 (27.656)	mem 10.565
Train: [47][750/750]	BT 0.029 (1.114)	DT 0.001 (1.069)	loss 7.010 (7.010)	prob 2.047 (2.047)	GS 29.188 (29.188)	mem 10.565
Train: [47][755/750]	BT 0.027 (1.111)	DT 0.001 (1.065)	loss 6.413 (6.413)	prob 2.261 (2.261)	GS 38.656 (38.656)	mem 7.572
epoch 47, total time 839.02
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [48][1/750]	BT 21.546 (21.546)	DT 21.483 (21.483)	loss 6.994 (6.994)	prob 2.323 (2.323)	GS 31.766 (31.766)	mem 38.575
Train: [48][5/750]	BT 0.063 (4.584)	DT 0.020 (4.534)	loss 6.775 (6.775)	prob 2.415 (2.415)	GS 28.891 (28.891)	mem 38.598
Train: [48][10/750]	BT 5.000 (2.823)	DT 4.962 (2.772)	loss 6.689 (6.689)	prob 3.425 (3.425)	GS 31.547 (31.547)	mem 38.694
Train: [48][15/750]	BT 0.068 (2.361)	DT 0.004 (2.311)	loss 6.633 (6.633)	prob 3.228 (3.228)	GS 25.141 (25.141)	mem 38.832
Train: [48][20/750]	BT 0.036 (1.960)	DT 0.001 (1.911)	loss 6.709 (6.709)	prob 2.554 (2.554)	GS 30.438 (30.438)	mem 38.814
Train: [48][25/750]	BT 0.060 (1.870)	DT 0.004 (1.822)	loss 6.869 (6.869)	prob 2.352 (2.352)	GS 31.516 (31.516)	mem 38.811
Train: [48][30/750]	BT 0.049 (1.776)	DT 0.009 (1.730)	loss 6.818 (6.818)	prob 2.652 (2.652)	GS 33.766 (33.766)	mem 38.842
Train: [48][35/750]	BT 0.123 (1.742)	DT 0.065 (1.696)	loss 6.977 (6.977)	prob 2.398 (2.398)	GS 26.672 (26.672)	mem 38.802
Train: [48][40/750]	BT 8.085 (1.732)	DT 8.032 (1.686)	loss 6.725 (6.725)	prob 2.788 (2.788)	GS 37.344 (37.344)	mem 38.882
Train: [48][45/750]	BT 0.032 (1.543)	DT 0.002 (1.499)	loss 6.942 (6.942)	prob 1.941 (1.941)	GS 30.766 (30.766)	mem 38.883
Train: [48][50/750]	BT 3.806 (1.522)	DT 3.771 (1.476)	loss 6.761 (6.761)	prob 2.536 (2.536)	GS 31.625 (31.625)	mem 38.942
Train: [48][55/750]	BT 0.053 (1.572)	DT 0.002 (1.524)	loss 6.877 (6.877)	prob 2.898 (2.898)	GS 28.859 (28.859)	mem 38.942
Train: [48][60/750]	BT 0.025 (1.446)	DT 0.001 (1.398)	loss 6.853 (6.853)	prob 2.292 (2.292)	GS 35.891 (35.891)	mem 38.903
Train: [48][65/750]	BT 0.030 (1.548)	DT 0.006 (1.499)	loss 6.760 (6.760)	prob 3.270 (3.270)	GS 33.406 (33.406)	mem 39.012
Train: [48][70/750]	BT 0.031 (1.441)	DT 0.001 (1.392)	loss 6.793 (6.793)	prob 2.958 (2.958)	GS 37.234 (37.234)	mem 38.996
Train: [48][75/750]	BT 0.057 (1.392)	DT 0.012 (1.343)	loss 6.790 (6.790)	prob 2.812 (2.812)	GS 30.453 (30.453)	mem 39.018
Train: [48][80/750]	BT 0.023 (1.456)	DT 0.001 (1.407)	loss 6.837 (6.837)	prob 2.735 (2.735)	GS 34.344 (34.344)	mem 38.987
Train: [48][85/750]	BT 0.048 (1.381)	DT 0.016 (1.333)	loss 6.909 (6.909)	prob 2.759 (2.759)	GS 29.344 (29.344)	mem 39.016
Train: [48][90/750]	BT 0.039 (1.403)	DT 0.007 (1.354)	loss 7.099 (7.099)	prob 2.311 (2.311)	GS 29.516 (29.516)	mem 39.026
Train: [48][95/750]	BT 0.031 (1.366)	DT 0.001 (1.318)	loss 7.069 (7.069)	prob 2.508 (2.508)	GS 33.609 (33.609)	mem 39.024
Train: [48][100/750]	BT 6.391 (1.406)	DT 6.307 (1.357)	loss 7.098 (7.098)	prob 1.737 (1.737)	GS 38.125 (38.125)	mem 39.148
Train: [48][105/750]	BT 0.076 (1.346)	DT 0.001 (1.297)	loss 7.446 (7.446)	prob 1.630 (1.630)	GS 32.297 (32.297)	mem 39.170
Train: [48][110/750]	BT 5.085 (1.351)	DT 5.045 (1.301)	loss 6.937 (6.937)	prob 2.363 (2.363)	GS 36.359 (36.359)	mem 39.117
Train: [48][115/750]	BT 0.032 (1.326)	DT 0.001 (1.276)	loss 7.122 (7.122)	prob 2.544 (2.544)	GS 32.406 (32.406)	mem 39.176
Train: [48][120/750]	BT 0.029 (1.318)	DT 0.001 (1.269)	loss 6.617 (6.617)	prob 2.731 (2.731)	GS 38.469 (38.469)	mem 39.420
Train: [48][125/750]	BT 0.168 (1.319)	DT 0.025 (1.270)	loss 6.808 (6.808)	prob 2.691 (2.691)	GS 29.703 (29.703)	mem 39.621
Train: [48][130/750]	BT 2.589 (1.337)	DT 2.557 (1.288)	loss 6.752 (6.752)	prob 2.842 (2.842)	GS 35.781 (35.781)	mem 39.305
Train: [48][135/750]	BT 0.106 (1.290)	DT 0.038 (1.241)	loss 6.943 (6.943)	prob 2.246 (2.246)	GS 32.828 (32.828)	mem 39.242
Train: [48][140/750]	BT 2.481 (1.300)	DT 2.410 (1.251)	loss 6.870 (6.870)	prob 2.322 (2.322)	GS 35.562 (35.562)	mem 39.447
Train: [48][145/750]	BT 0.033 (1.292)	DT 0.001 (1.242)	loss 6.889 (6.889)	prob 2.682 (2.682)	GS 28.719 (28.719)	mem 39.410
Train: [48][150/750]	BT 0.058 (1.290)	DT 0.002 (1.241)	loss 6.821 (6.821)	prob 2.374 (2.374)	GS 35.734 (35.734)	mem 39.397
Train: [48][155/750]	BT 0.025 (1.309)	DT 0.001 (1.259)	loss 6.867 (6.867)	prob 3.095 (3.095)	GS 36.734 (36.734)	mem 39.261
Train: [48][160/750]	BT 3.332 (1.290)	DT 3.300 (1.241)	loss 6.953 (6.953)	prob 2.634 (2.634)	GS 31.312 (31.312)	mem 39.363
Train: [48][165/750]	BT 0.074 (1.259)	DT 0.002 (1.210)	loss 6.855 (6.855)	prob 2.975 (2.975)	GS 29.734 (29.734)	mem 39.417
Train: [48][170/750]	BT 0.091 (1.278)	DT 0.011 (1.228)	loss 7.229 (7.229)	prob 2.569 (2.569)	GS 32.344 (32.344)	mem 39.554
Train: [48][175/750]	BT 0.101 (1.266)	DT 0.026 (1.216)	loss 6.650 (6.650)	prob 2.999 (2.999)	GS 29.547 (29.547)	mem 39.656
Train: [48][180/750]	BT 0.054 (1.278)	DT 0.003 (1.228)	loss 6.670 (6.670)	prob 3.118 (3.118)	GS 30.266 (30.266)	mem 39.854
Train: [48][185/750]	BT 0.076 (1.280)	DT 0.011 (1.231)	loss 6.879 (6.879)	prob 2.094 (2.094)	GS 31.688 (31.688)	mem 39.732
Train: [48][190/750]	BT 4.596 (1.271)	DT 4.568 (1.223)	loss 7.140 (7.140)	prob 2.213 (2.213)	GS 33.922 (33.922)	mem 39.752
Train: [48][195/750]	BT 0.060 (1.240)	DT 0.009 (1.192)	loss 6.924 (6.924)	prob 2.562 (2.562)	GS 36.703 (36.703)	mem 39.753
Train: [48][200/750]	BT 0.641 (1.248)	DT 0.589 (1.199)	loss 6.915 (6.915)	prob 2.382 (2.382)	GS 34.422 (34.422)	mem 39.660
Train: [48][205/750]	BT 0.037 (1.249)	DT 0.001 (1.200)	loss 7.021 (7.021)	prob 2.876 (2.876)	GS 29.484 (29.484)	mem 39.703
Train: [48][210/750]	BT 0.039 (1.241)	DT 0.002 (1.192)	loss 6.848 (6.848)	prob 3.112 (3.112)	GS 29.734 (29.734)	mem 39.881
Train: [48][215/750]	BT 0.055 (1.252)	DT 0.011 (1.203)	loss 6.845 (6.845)	prob 2.461 (2.461)	GS 27.844 (27.844)	mem 39.668
Train: [48][220/750]	BT 2.395 (1.235)	DT 2.345 (1.186)	loss 7.059 (7.059)	prob 2.155 (2.155)	GS 34.094 (34.094)	mem 39.796
Train: [48][225/750]	BT 0.032 (1.213)	DT 0.002 (1.165)	loss 6.740 (6.740)	prob 3.513 (3.513)	GS 23.688 (23.688)	mem 39.730
Train: [48][230/750]	BT 0.035 (1.219)	DT 0.002 (1.170)	loss 7.042 (7.042)	prob 2.366 (2.366)	GS 32.000 (32.000)	mem 39.719
Train: [48][235/750]	BT 0.065 (1.218)	DT 0.015 (1.170)	loss 6.895 (6.895)	prob 3.092 (3.092)	GS 28.047 (28.047)	mem 39.888
Train: [48][240/750]	BT 0.023 (1.229)	DT 0.001 (1.180)	loss 6.867 (6.867)	prob 2.788 (2.788)	GS 36.297 (36.297)	mem 39.794
Train: [48][245/750]	BT 0.038 (1.216)	DT 0.002 (1.168)	loss 6.849 (6.849)	prob 2.782 (2.782)	GS 30.469 (30.469)	mem 39.807
Train: [48][250/750]	BT 7.705 (1.238)	DT 7.673 (1.190)	loss 6.910 (6.910)	prob 3.018 (3.018)	GS 33.703 (33.703)	mem 39.735
Train: [48][255/750]	BT 0.024 (1.215)	DT 0.001 (1.167)	loss 6.876 (6.876)	prob 2.728 (2.728)	GS 34.406 (34.406)	mem 39.758
Train: [48][260/750]	BT 0.956 (1.201)	DT 0.917 (1.153)	loss 6.610 (6.610)	prob 3.060 (3.060)	GS 37.656 (37.656)	mem 39.753
Train: [48][265/750]	BT 0.058 (1.215)	DT 0.012 (1.167)	loss 6.917 (6.917)	prob 2.519 (2.519)	GS 28.984 (28.984)	mem 39.915
Train: [48][270/750]	BT 0.027 (1.205)	DT 0.002 (1.157)	loss 7.203 (7.203)	prob 2.400 (2.400)	GS 35.688 (35.688)	mem 39.787
Train: [48][275/750]	BT 0.077 (1.210)	DT 0.001 (1.162)	loss 6.860 (6.860)	prob 2.720 (2.720)	GS 33.828 (33.828)	mem 39.836
Train: [48][280/750]	BT 3.723 (1.220)	DT 3.695 (1.172)	loss 6.846 (6.846)	prob 3.577 (3.577)	GS 35.828 (35.828)	mem 39.795
Train: [48][285/750]	BT 0.029 (1.211)	DT 0.001 (1.164)	loss 7.036 (7.036)	prob 3.152 (3.152)	GS 35.547 (35.547)	mem 39.769
Train: [48][290/750]	BT 1.548 (1.197)	DT 1.496 (1.149)	loss 6.885 (6.885)	prob 2.281 (2.281)	GS 30.953 (30.953)	mem 39.843
Train: [48][295/750]	BT 0.024 (1.204)	DT 0.001 (1.156)	loss 6.958 (6.958)	prob 2.719 (2.719)	GS 29.469 (29.469)	mem 39.856
Train: [48][300/750]	BT 0.032 (1.192)	DT 0.001 (1.145)	loss 6.953 (6.953)	prob 2.342 (2.342)	GS 31.469 (31.469)	mem 39.826
Train: [48][305/750]	BT 0.036 (1.213)	DT 0.001 (1.165)	loss 6.727 (6.727)	prob 3.279 (3.279)	GS 33.219 (33.219)	mem 40.022
Train: [48][310/750]	BT 0.048 (1.199)	DT 0.016 (1.152)	loss 7.078 (7.078)	prob 2.846 (2.846)	GS 35.938 (35.938)	mem 39.896
Train: [48][315/750]	BT 0.067 (1.183)	DT 0.007 (1.135)	loss 7.159 (7.159)	prob 2.030 (2.030)	GS 35.172 (35.172)	mem 40.029
Train: [48][320/750]	BT 0.033 (1.204)	DT 0.001 (1.157)	loss 6.875 (6.875)	prob 2.735 (2.735)	GS 32.188 (32.188)	mem 39.937
Train: [48][325/750]	BT 0.063 (1.187)	DT 0.002 (1.140)	loss 6.715 (6.715)	prob 3.199 (3.199)	GS 30.156 (30.156)	mem 39.939
Train: [48][330/750]	BT 0.035 (1.213)	DT 0.005 (1.166)	loss 6.856 (6.856)	prob 2.693 (2.693)	GS 30.672 (30.672)	mem 39.997
Train: [48][335/750]	BT 0.041 (1.195)	DT 0.011 (1.148)	loss 6.928 (6.928)	prob 2.660 (2.660)	GS 32.766 (32.766)	mem 39.893
Train: [48][340/750]	BT 11.643 (1.213)	DT 11.601 (1.166)	loss 6.831 (6.831)	prob 2.816 (2.816)	GS 32.078 (32.078)	mem 39.828
Train: [48][345/750]	BT 0.036 (1.195)	DT 0.001 (1.149)	loss 6.834 (6.834)	prob 2.286 (2.286)	GS 36.125 (36.125)	mem 39.830
Train: [48][350/750]	BT 0.078 (1.179)	DT 0.009 (1.132)	loss 6.990 (6.990)	prob 2.942 (2.942)	GS 33.031 (33.031)	mem 39.828
Train: [48][355/750]	BT 0.034 (1.200)	DT 0.001 (1.154)	loss 7.153 (7.153)	prob 2.608 (2.608)	GS 29.797 (29.797)	mem 39.822
Train: [48][360/750]	BT 0.049 (1.184)	DT 0.007 (1.138)	loss 6.816 (6.816)	prob 2.451 (2.451)	GS 33.625 (33.625)	mem 39.860
Train: [48][365/750]	BT 0.022 (1.206)	DT 0.001 (1.160)	loss 7.077 (7.077)	prob 2.676 (2.676)	GS 31.422 (31.422)	mem 39.884
Train: [48][370/750]	BT 0.031 (1.191)	DT 0.001 (1.145)	loss 6.873 (6.873)	prob 2.057 (2.057)	GS 34.516 (34.516)	mem 39.886
Train: [48][375/750]	BT 0.092 (1.176)	DT 0.001 (1.130)	loss 6.933 (6.933)	prob 2.777 (2.777)	GS 43.172 (43.172)	mem 40.021
Train: [48][380/750]	BT 0.032 (1.192)	DT 0.001 (1.146)	loss 6.979 (6.979)	prob 2.506 (2.506)	GS 31.781 (31.781)	mem 39.847
Train: [48][385/750]	BT 0.023 (1.177)	DT 0.001 (1.132)	loss 6.929 (6.929)	prob 2.754 (2.754)	GS 30.891 (30.891)	mem 39.848
Train: [48][390/750]	BT 0.021 (1.202)	DT 0.001 (1.156)	loss 6.872 (6.872)	prob 2.477 (2.477)	GS 33.203 (33.203)	mem 39.801
Train: [48][395/750]	BT 0.096 (1.188)	DT 0.015 (1.142)	loss 6.795 (6.795)	prob 3.094 (3.094)	GS 29.281 (29.281)	mem 39.822
Train: [48][400/750]	BT 12.853 (1.205)	DT 12.821 (1.160)	loss 6.897 (6.897)	prob 2.707 (2.707)	GS 32.859 (32.859)	mem 39.885
Train: [48][405/750]	BT 0.071 (1.191)	DT 0.016 (1.145)	loss 6.829 (6.829)	prob 2.411 (2.411)	GS 33.328 (33.328)	mem 39.886
Train: [48][410/750]	BT 0.041 (1.177)	DT 0.001 (1.132)	loss 6.955 (6.955)	prob 2.499 (2.499)	GS 32.797 (32.797)	mem 39.887
Train: [48][415/750]	BT 0.027 (1.189)	DT 0.001 (1.144)	loss 6.974 (6.974)	prob 2.830 (2.830)	GS 28.938 (28.938)	mem 39.849
Train: [48][420/750]	BT 0.051 (1.175)	DT 0.002 (1.130)	loss 6.904 (6.904)	prob 2.868 (2.868)	GS 36.484 (36.484)	mem 39.991
Train: [48][425/750]	BT 0.043 (1.199)	DT 0.001 (1.154)	loss 7.031 (7.031)	prob 2.257 (2.257)	GS 33.641 (33.641)	mem 39.972
Train: [48][430/750]	BT 0.032 (1.186)	DT 0.001 (1.141)	loss 6.950 (6.950)	prob 2.713 (2.713)	GS 37.609 (37.609)	mem 39.923
Train: [48][435/750]	BT 0.123 (1.173)	DT 0.022 (1.128)	loss 6.969 (6.969)	prob 3.114 (3.114)	GS 32.250 (32.250)	mem 40.108
Train: [48][440/750]	BT 0.029 (1.185)	DT 0.001 (1.140)	loss 6.737 (6.737)	prob 3.276 (3.276)	GS 33.828 (33.828)	mem 39.912
Train: [48][445/750]	BT 0.090 (1.173)	DT 0.014 (1.127)	loss 6.959 (6.959)	prob 2.807 (2.807)	GS 37.312 (37.312)	mem 39.962
Train: [48][450/750]	BT 0.022 (1.193)	DT 0.001 (1.148)	loss 6.926 (6.926)	prob 1.999 (1.999)	GS 33.250 (33.250)	mem 39.856
Train: [48][455/750]	BT 0.043 (1.180)	DT 0.008 (1.135)	loss 7.010 (7.010)	prob 2.760 (2.760)	GS 31.906 (31.906)	mem 39.929
Train: [48][460/750]	BT 12.281 (1.194)	DT 12.252 (1.149)	loss 6.893 (6.893)	prob 3.285 (3.285)	GS 30.844 (30.844)	mem 39.914
Train: [48][465/750]	BT 0.049 (1.182)	DT 0.002 (1.137)	loss 7.089 (7.089)	prob 2.479 (2.479)	GS 32.312 (32.312)	mem 39.915
Train: [48][470/750]	BT 0.055 (1.170)	DT 0.012 (1.125)	loss 7.034 (7.034)	prob 2.406 (2.406)	GS 34.203 (34.203)	mem 39.915
Train: [48][475/750]	BT 0.029 (1.186)	DT 0.001 (1.141)	loss 6.941 (6.941)	prob 2.373 (2.373)	GS 28.766 (28.766)	mem 39.871
Train: [48][480/750]	BT 0.049 (1.174)	DT 0.009 (1.129)	loss 7.053 (7.053)	prob 2.375 (2.375)	GS 30.859 (30.859)	mem 39.871
Train: [48][485/750]	BT 0.139 (1.188)	DT 0.003 (1.143)	loss 6.960 (6.960)	prob 2.536 (2.536)	GS 33.219 (33.219)	mem 39.994
Train: [48][490/750]	BT 0.100 (1.176)	DT 0.029 (1.131)	loss 6.791 (6.791)	prob 2.730 (2.730)	GS 35.047 (35.047)	mem 39.983
Train: [48][495/750]	BT 0.075 (1.165)	DT 0.002 (1.120)	loss 6.889 (6.889)	prob 2.983 (2.983)	GS 33.672 (33.672)	mem 40.021
Train: [48][500/750]	BT 0.021 (1.182)	DT 0.001 (1.138)	loss 6.955 (6.955)	prob 2.122 (2.122)	GS 34.016 (34.016)	mem 39.908
Train: [48][505/750]	BT 0.062 (1.171)	DT 0.022 (1.126)	loss 6.770 (6.770)	prob 3.067 (3.067)	GS 28.844 (28.844)	mem 40.039
Train: [48][510/750]	BT 0.027 (1.184)	DT 0.001 (1.139)	loss 7.049 (7.049)	prob 2.877 (2.877)	GS 33.688 (33.688)	mem 39.980
Train: [48][515/750]	BT 0.034 (1.173)	DT 0.001 (1.128)	loss 7.000 (7.000)	prob 2.724 (2.724)	GS 32.672 (32.672)	mem 39.981
Train: [48][520/750]	BT 14.352 (1.190)	DT 14.323 (1.145)	loss 6.987 (6.987)	prob 2.091 (2.091)	GS 38.953 (38.953)	mem 39.999
Train: [48][525/750]	BT 0.027 (1.179)	DT 0.002 (1.134)	loss 6.886 (6.886)	prob 3.277 (3.277)	GS 35.188 (35.188)	mem 40.001
Train: [48][530/750]	BT 0.046 (1.168)	DT 0.007 (1.124)	loss 6.813 (6.813)	prob 2.850 (2.850)	GS 36.234 (36.234)	mem 40.002
Train: [48][535/750]	BT 0.030 (1.185)	DT 0.001 (1.141)	loss 6.823 (6.823)	prob 2.416 (2.416)	GS 31.672 (31.672)	mem 39.972
Train: [48][540/750]	BT 0.020 (1.174)	DT 0.001 (1.130)	loss 7.077 (7.077)	prob 2.317 (2.317)	GS 31.844 (31.844)	mem 39.974
Train: [48][545/750]	BT 0.049 (1.186)	DT 0.005 (1.142)	loss 6.983 (6.983)	prob 2.607 (2.607)	GS 38.250 (38.250)	mem 40.011
Train: [48][550/750]	BT 0.037 (1.176)	DT 0.001 (1.131)	loss 7.059 (7.059)	prob 2.531 (2.531)	GS 37.328 (37.328)	mem 40.010
Train: [48][555/750]	BT 0.034 (1.165)	DT 0.002 (1.121)	loss 7.183 (7.183)	prob 2.550 (2.550)	GS 32.969 (32.969)	mem 40.087
Train: [48][560/750]	BT 0.021 (1.177)	DT 0.001 (1.133)	loss 6.653 (6.653)	prob 2.803 (2.803)	GS 36.359 (36.359)	mem 39.945
Train: [48][565/750]	BT 0.028 (1.167)	DT 0.001 (1.123)	loss 6.729 (6.729)	prob 2.930 (2.930)	GS 29.188 (29.188)	mem 39.944
Train: [48][570/750]	BT 0.050 (1.177)	DT 0.010 (1.133)	loss 6.763 (6.763)	prob 2.364 (2.364)	GS 31.328 (31.328)	mem 39.977
Train: [48][575/750]	BT 0.031 (1.167)	DT 0.001 (1.123)	loss 6.862 (6.862)	prob 2.618 (2.618)	GS 30.312 (30.312)	mem 39.954
Train: [48][580/750]	BT 11.455 (1.177)	DT 11.352 (1.133)	loss 6.984 (6.984)	prob 2.817 (2.817)	GS 30.531 (30.531)	mem 39.953
Train: [48][585/750]	BT 0.040 (1.168)	DT 0.001 (1.124)	loss 7.279 (7.279)	prob 2.260 (2.260)	GS 34.672 (34.672)	mem 39.973
Train: [48][590/750]	BT 0.062 (1.158)	DT 0.002 (1.114)	loss 6.821 (6.821)	prob 2.773 (2.773)	GS 32.391 (32.391)	mem 39.955
Train: [48][595/750]	BT 0.051 (1.175)	DT 0.011 (1.131)	loss 7.057 (7.057)	prob 2.259 (2.259)	GS 30.719 (30.719)	mem 39.913
Train: [48][600/750]	BT 0.038 (1.165)	DT 0.001 (1.121)	loss 6.828 (6.828)	prob 2.524 (2.524)	GS 30.062 (30.062)	mem 39.915
Train: [48][605/750]	BT 0.029 (1.177)	DT 0.001 (1.133)	loss 6.983 (6.983)	prob 1.990 (1.990)	GS 31.312 (31.312)	mem 39.967
Train: [48][610/750]	BT 0.032 (1.167)	DT 0.002 (1.123)	loss 6.851 (6.851)	prob 2.234 (2.234)	GS 35.672 (35.672)	mem 39.970
Train: [48][615/750]	BT 0.089 (1.158)	DT 0.002 (1.114)	loss 7.096 (7.096)	prob 2.293 (2.293)	GS 31.078 (31.078)	mem 39.972
Train: [48][620/750]	BT 0.035 (1.167)	DT 0.004 (1.123)	loss 7.105 (7.105)	prob 1.915 (1.915)	GS 36.344 (36.344)	mem 39.970
Train: [48][625/750]	BT 0.023 (1.158)	DT 0.001 (1.114)	loss 6.923 (6.923)	prob 2.600 (2.600)	GS 30.656 (30.656)	mem 39.971
Train: [48][630/750]	BT 0.031 (1.175)	DT 0.002 (1.131)	loss 6.781 (6.781)	prob 2.967 (2.967)	GS 31.141 (31.141)	mem 39.952
Train: [48][635/750]	BT 0.030 (1.166)	DT 0.001 (1.123)	loss 7.041 (7.041)	prob 2.406 (2.406)	GS 31.672 (31.672)	mem 39.952
Train: [48][640/750]	BT 13.193 (1.178)	DT 13.147 (1.134)	loss 7.101 (7.101)	prob 2.315 (2.315)	GS 33.141 (33.141)	mem 40.041
Train: [48][645/750]	BT 0.028 (1.169)	DT 0.001 (1.126)	loss 7.188 (7.188)	prob 1.936 (1.936)	GS 28.672 (28.672)	mem 40.007
Train: [48][650/750]	BT 0.112 (1.161)	DT 0.004 (1.117)	loss 6.925 (6.925)	prob 2.454 (2.454)	GS 31.406 (31.406)	mem 40.096
Train: [48][655/750]	BT 0.029 (1.172)	DT 0.004 (1.129)	loss 7.037 (7.037)	prob 2.756 (2.756)	GS 30.875 (30.875)	mem 39.996
Train: [48][660/750]	BT 0.032 (1.164)	DT 0.001 (1.120)	loss 6.881 (6.881)	prob 2.890 (2.890)	GS 35.531 (35.531)	mem 39.995
Train: [48][665/750]	BT 0.035 (1.175)	DT 0.002 (1.132)	loss 6.853 (6.853)	prob 2.931 (2.931)	GS 29.922 (29.922)	mem 39.985
Train: [48][670/750]	BT 0.030 (1.167)	DT 0.001 (1.123)	loss 6.973 (6.973)	prob 2.659 (2.659)	GS 34.625 (34.625)	mem 39.986
Train: [48][675/750]	BT 0.040 (1.158)	DT 0.001 (1.115)	loss 6.956 (6.956)	prob 2.004 (2.004)	GS 31.438 (31.438)	mem 39.986
Train: [48][680/750]	BT 0.032 (1.167)	DT 0.001 (1.124)	loss 6.869 (6.869)	prob 2.571 (2.571)	GS 34.203 (34.203)	mem 40.001
Train: [48][685/750]	BT 0.032 (1.159)	DT 0.001 (1.116)	loss 6.900 (6.900)	prob 2.755 (2.755)	GS 33.797 (33.797)	mem 40.002
Train: [48][690/750]	BT 0.023 (1.172)	DT 0.001 (1.129)	loss 6.623 (6.623)	prob 2.977 (2.977)	GS 32.359 (32.359)	mem 40.037
Train: [48][695/750]	BT 0.038 (1.164)	DT 0.001 (1.121)	loss 7.239 (7.239)	prob 2.273 (2.273)	GS 31.047 (31.047)	mem 40.051
Train: [48][700/750]	BT 9.308 (1.169)	DT 9.254 (1.126)	loss 6.953 (6.953)	prob 2.674 (2.674)	GS 31.141 (31.141)	mem 40.066
Train: [48][705/750]	BT 0.074 (1.161)	DT 0.022 (1.118)	loss 7.150 (7.150)	prob 3.066 (3.066)	GS 38.469 (38.469)	mem 40.134
Train: [48][710/750]	BT 0.062 (1.154)	DT 0.005 (1.110)	loss 7.068 (7.068)	prob 2.416 (2.416)	GS 29.672 (29.672)	mem 40.071
Train: [48][715/750]	BT 0.034 (1.163)	DT 0.001 (1.120)	loss 6.732 (6.732)	prob 2.958 (2.958)	GS 32.844 (32.844)	mem 40.085
Train: [48][720/750]	BT 0.067 (1.155)	DT 0.016 (1.112)	loss 6.836 (6.836)	prob 2.707 (2.707)	GS 32.922 (32.922)	mem 39.996
Train: [48][725/750]	BT 0.070 (1.164)	DT 0.005 (1.120)	loss 7.182 (7.182)	prob 2.104 (2.104)	GS 29.641 (29.641)	mem 39.919
Train: [48][730/750]	BT 0.032 (1.156)	DT 0.001 (1.113)	loss 6.711 (6.711)	prob 2.611 (2.611)	GS 36.484 (36.484)	mem 39.862
Train: [48][735/750]	BT 0.057 (1.149)	DT 0.002 (1.105)	loss 7.042 (7.042)	prob 3.048 (3.048)	GS 31.391 (31.391)	mem 39.871
Train: [48][740/750]	BT 0.056 (1.154)	DT 0.012 (1.110)	loss 6.624 (6.624)	prob 3.403 (3.403)	GS 33.359 (33.359)	mem 20.592
Train: [48][745/750]	BT 0.038 (1.148)	DT 0.006 (1.104)	loss 6.851 (6.851)	prob 2.472 (2.472)	GS 35.656 (35.656)	mem 14.475
Train: [48][750/750]	BT 0.028 (1.142)	DT 0.008 (1.098)	loss 7.059 (7.059)	prob 2.986 (2.986)	GS 33.125 (33.125)	mem 10.595
Train: [48][755/750]	BT 0.035 (1.134)	DT 0.002 (1.091)	loss 7.022 (7.022)	prob 1.982 (1.982)	GS 70.656 (70.656)	mem 10.595
epoch 48, total time 858.04
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [49][1/750]	BT 23.009 (23.009)	DT 22.952 (22.952)	loss 7.028 (7.028)	prob 2.801 (2.801)	GS 31.062 (31.062)	mem 38.640
Train: [49][5/750]	BT 0.128 (5.032)	DT 0.001 (4.954)	loss 6.627 (6.627)	prob 2.885 (2.885)	GS 30.328 (30.328)	mem 38.672
Train: [49][10/750]	BT 0.163 (2.546)	DT 0.024 (2.480)	loss 6.769 (6.769)	prob 2.761 (2.761)	GS 34.516 (34.516)	mem 38.758
Train: [49][15/750]	BT 0.110 (2.456)	DT 0.008 (2.392)	loss 6.831 (6.831)	prob 2.450 (2.450)	GS 33.281 (33.281)	mem 38.919
Train: [49][20/750]	BT 0.052 (1.860)	DT 0.002 (1.797)	loss 6.637 (6.637)	prob 3.072 (3.072)	GS 33.016 (33.016)	mem 38.940
Train: [49][25/750]	BT 2.994 (1.667)	DT 2.952 (1.608)	loss 6.903 (6.903)	prob 2.551 (2.551)	GS 31.312 (31.312)	mem 38.975
Train: [49][30/750]	BT 0.071 (1.712)	DT 0.002 (1.654)	loss 6.672 (6.672)	prob 2.652 (2.652)	GS 34.750 (34.750)	mem 38.926
Train: [49][35/750]	BT 0.037 (1.473)	DT 0.002 (1.418)	loss 6.879 (6.879)	prob 2.600 (2.600)	GS 27.750 (27.750)	mem 38.938
Train: [49][40/750]	BT 0.029 (1.532)	DT 0.001 (1.477)	loss 6.718 (6.718)	prob 2.784 (2.784)	GS 29.562 (29.562)	mem 38.952
Train: [49][45/750]	BT 0.038 (1.470)	DT 0.007 (1.417)	loss 6.680 (6.680)	prob 2.916 (2.916)	GS 24.453 (24.453)	mem 39.061
Train: [49][50/750]	BT 4.988 (1.427)	DT 4.928 (1.374)	loss 6.770 (6.770)	prob 2.294 (2.294)	GS 34.578 (34.578)	mem 39.004
Train: [49][55/750]	BT 0.040 (1.375)	DT 0.010 (1.324)	loss 6.754 (6.754)	prob 2.647 (2.647)	GS 29.094 (29.094)	mem 39.086
Train: [49][60/750]	BT 0.086 (1.291)	DT 0.001 (1.237)	loss 6.691 (6.691)	prob 2.667 (2.667)	GS 32.891 (32.891)	mem 39.138
Train: [49][65/750]	BT 0.073 (1.308)	DT 0.006 (1.254)	loss 6.626 (6.626)	prob 2.481 (2.481)	GS 34.297 (34.297)	mem 39.001
Train: [49][70/750]	BT 0.041 (1.313)	DT 0.001 (1.259)	loss 7.148 (7.148)	prob 1.837 (1.837)	GS 33.469 (33.469)	mem 39.003
Train: [49][75/750]	BT 0.035 (1.274)	DT 0.001 (1.222)	loss 7.024 (7.024)	prob 2.957 (2.957)	GS 26.953 (26.953)	mem 39.028
Train: [49][80/750]	BT 0.042 (1.318)	DT 0.003 (1.265)	loss 6.721 (6.721)	prob 3.270 (3.270)	GS 31.688 (31.688)	mem 39.084
Train: [49][85/750]	BT 0.043 (1.244)	DT 0.002 (1.191)	loss 6.889 (6.889)	prob 2.551 (2.551)	GS 33.078 (33.078)	mem 39.086
Train: [49][90/750]	BT 9.563 (1.329)	DT 9.510 (1.276)	loss 6.995 (6.995)	prob 2.817 (2.817)	GS 32.234 (32.234)	mem 39.413
Train: [49][95/750]	BT 0.072 (1.262)	DT 0.002 (1.209)	loss 6.912 (6.912)	prob 2.637 (2.637)	GS 31.375 (31.375)	mem 39.469
Train: [49][100/750]	BT 2.133 (1.264)	DT 2.072 (1.211)	loss 6.904 (6.904)	prob 2.712 (2.712)	GS 34.703 (34.703)	mem 39.335
Train: [49][105/750]	BT 0.038 (1.284)	DT 0.005 (1.231)	loss 7.005 (7.005)	prob 3.117 (3.117)	GS 32.391 (32.391)	mem 39.329
Train: [49][110/750]	BT 5.492 (1.278)	DT 5.406 (1.225)	loss 7.136 (7.136)	prob 1.946 (1.946)	GS 34.328 (34.328)	mem 39.453
Train: [49][115/750]	BT 0.090 (1.300)	DT 0.005 (1.246)	loss 6.907 (6.907)	prob 2.490 (2.490)	GS 32.078 (32.078)	mem 39.469
Train: [49][120/750]	BT 0.093 (1.248)	DT 0.008 (1.195)	loss 6.732 (6.732)	prob 2.521 (2.521)	GS 35.516 (35.516)	mem 39.557
Train: [49][125/750]	BT 0.025 (1.243)	DT 0.001 (1.190)	loss 7.140 (7.140)	prob 2.875 (2.875)	GS 30.734 (30.734)	mem 39.600
Train: [49][130/750]	BT 0.030 (1.256)	DT 0.001 (1.203)	loss 6.718 (6.718)	prob 2.698 (2.698)	GS 34.000 (34.000)	mem 39.550
Train: [49][135/750]	BT 0.037 (1.248)	DT 0.005 (1.197)	loss 7.263 (7.263)	prob 2.658 (2.658)	GS 29.688 (29.688)	mem 39.687
Train: [49][140/750]	BT 0.097 (1.253)	DT 0.028 (1.200)	loss 6.785 (6.785)	prob 2.607 (2.607)	GS 32.688 (32.688)	mem 39.614
Train: [49][145/750]	BT 0.029 (1.211)	DT 0.001 (1.159)	loss 6.937 (6.937)	prob 2.337 (2.337)	GS 30.719 (30.719)	mem 39.615
Train: [49][150/750]	BT 8.834 (1.275)	DT 8.801 (1.224)	loss 7.192 (7.192)	prob 2.449 (2.449)	GS 39.906 (39.906)	mem 39.687
Train: [49][155/750]	BT 0.041 (1.235)	DT 0.002 (1.184)	loss 6.916 (6.916)	prob 2.029 (2.029)	GS 30.875 (30.875)	mem 39.685
Train: [49][160/750]	BT 0.034 (1.203)	DT 0.002 (1.152)	loss 6.758 (6.758)	prob 3.009 (3.009)	GS 36.562 (36.562)	mem 39.687
Train: [49][165/750]	BT 0.051 (1.244)	DT 0.004 (1.193)	loss 6.898 (6.898)	prob 3.136 (3.136)	GS 31.688 (31.688)	mem 39.591
Train: [49][170/750]	BT 1.404 (1.217)	DT 1.356 (1.166)	loss 6.982 (6.982)	prob 2.565 (2.565)	GS 33.266 (33.266)	mem 39.615
Train: [49][175/750]	BT 0.029 (1.258)	DT 0.002 (1.208)	loss 6.889 (6.889)	prob 2.789 (2.789)	GS 28.844 (28.844)	mem 39.698
Train: [49][180/750]	BT 0.031 (1.224)	DT 0.001 (1.175)	loss 6.865 (6.865)	prob 2.212 (2.212)	GS 34.203 (34.203)	mem 39.703
Train: [49][185/750]	BT 0.024 (1.192)	DT 0.001 (1.143)	loss 6.994 (6.994)	prob 2.775 (2.775)	GS 28.484 (28.484)	mem 39.703
Train: [49][190/750]	BT 0.052 (1.222)	DT 0.007 (1.172)	loss 6.856 (6.856)	prob 2.788 (2.788)	GS 36.094 (36.094)	mem 39.977
Train: [49][195/750]	BT 0.131 (1.193)	DT 0.040 (1.143)	loss 7.132 (7.132)	prob 2.164 (2.164)	GS 36.625 (36.625)	mem 39.833
Train: [49][200/750]	BT 0.041 (1.228)	DT 0.001 (1.179)	loss 7.227 (7.227)	prob 2.037 (2.037)	GS 31.016 (31.016)	mem 39.781
Train: [49][205/750]	BT 0.028 (1.200)	DT 0.001 (1.150)	loss 6.709 (6.709)	prob 2.372 (2.372)	GS 31.906 (31.906)	mem 39.705
Train: [49][210/750]	BT 7.036 (1.224)	DT 7.012 (1.174)	loss 6.746 (6.746)	prob 2.390 (2.390)	GS 31.031 (31.031)	mem 39.763
Train: [49][215/750]	BT 0.043 (1.196)	DT 0.002 (1.147)	loss 7.003 (7.003)	prob 2.880 (2.880)	GS 40.734 (40.734)	mem 39.767
Train: [49][220/750]	BT 3.713 (1.200)	DT 3.673 (1.151)	loss 7.158 (7.158)	prob 2.373 (2.373)	GS 34.422 (34.422)	mem 39.846
Train: [49][225/750]	BT 0.043 (1.207)	DT 0.007 (1.158)	loss 7.112 (7.112)	prob 2.071 (2.071)	GS 31.469 (31.469)	mem 39.799
Train: [49][230/750]	BT 0.525 (1.184)	DT 0.481 (1.135)	loss 6.984 (6.984)	prob 2.840 (2.840)	GS 34.562 (34.562)	mem 39.831
Train: [49][235/750]	BT 0.032 (1.205)	DT 0.001 (1.157)	loss 6.723 (6.723)	prob 2.599 (2.599)	GS 31.250 (31.250)	mem 39.792
Train: [49][240/750]	BT 0.036 (1.181)	DT 0.004 (1.133)	loss 6.839 (6.839)	prob 1.879 (1.879)	GS 38.172 (38.172)	mem 39.793
Train: [49][245/750]	BT 0.088 (1.185)	DT 0.021 (1.137)	loss 7.091 (7.091)	prob 2.545 (2.545)	GS 31.234 (31.234)	mem 40.111
Train: [49][250/750]	BT 0.022 (1.186)	DT 0.001 (1.138)	loss 6.966 (6.966)	prob 2.353 (2.353)	GS 29.266 (29.266)	mem 39.842
Train: [49][255/750]	BT 0.047 (1.175)	DT 0.009 (1.127)	loss 6.893 (6.893)	prob 2.764 (2.764)	GS 33.000 (33.000)	mem 39.952
Train: [49][260/750]	BT 0.025 (1.195)	DT 0.001 (1.147)	loss 6.579 (6.579)	prob 2.841 (2.841)	GS 32.719 (32.719)	mem 39.828
Train: [49][265/750]	BT 0.035 (1.173)	DT 0.005 (1.125)	loss 6.860 (6.860)	prob 2.412 (2.412)	GS 34.453 (34.453)	mem 39.831
Train: [49][270/750]	BT 9.348 (1.204)	DT 9.299 (1.157)	loss 6.779 (6.779)	prob 2.767 (2.767)	GS 30.781 (30.781)	mem 39.822
Train: [49][275/750]	BT 0.042 (1.184)	DT 0.002 (1.136)	loss 6.816 (6.816)	prob 2.583 (2.583)	GS 32.672 (32.672)	mem 39.823
Train: [49][280/750]	BT 3.206 (1.189)	DT 3.174 (1.142)	loss 6.907 (6.907)	prob 3.097 (3.097)	GS 34.391 (34.391)	mem 39.877
Train: [49][285/750]	BT 0.064 (1.180)	DT 0.012 (1.133)	loss 6.882 (6.882)	prob 2.976 (2.976)	GS 30.391 (30.391)	mem 40.055
Train: [49][290/750]	BT 7.334 (1.186)	DT 7.303 (1.138)	loss 6.924 (6.924)	prob 2.607 (2.607)	GS 33.984 (33.984)	mem 39.911
Train: [49][295/750]	BT 0.043 (1.180)	DT 0.005 (1.132)	loss 6.814 (6.814)	prob 2.262 (2.262)	GS 43.938 (43.938)	mem 39.911
Train: [49][300/750]	BT 0.077 (1.161)	DT 0.007 (1.113)	loss 6.717 (6.717)	prob 3.013 (3.013)	GS 30.031 (30.031)	mem 39.937
Train: [49][305/750]	BT 0.036 (1.189)	DT 0.001 (1.142)	loss 6.794 (6.794)	prob 2.276 (2.276)	GS 33.500 (33.500)	mem 39.872
Train: [49][310/750]	BT 0.039 (1.170)	DT 0.001 (1.123)	loss 6.966 (6.966)	prob 2.760 (2.760)	GS 32.453 (32.453)	mem 39.873
Train: [49][315/750]	BT 0.032 (1.162)	DT 0.001 (1.115)	loss 6.894 (6.894)	prob 2.512 (2.512)	GS 30.422 (30.422)	mem 39.907
Train: [49][320/750]	BT 0.031 (1.172)	DT 0.001 (1.125)	loss 6.747 (6.747)	prob 2.733 (2.733)	GS 34.203 (34.203)	mem 39.915
Train: [49][325/750]	BT 0.034 (1.155)	DT 0.003 (1.108)	loss 7.310 (7.310)	prob 1.568 (1.568)	GS 38.188 (38.188)	mem 39.916
Train: [49][330/750]	BT 0.035 (1.171)	DT 0.001 (1.125)	loss 6.847 (6.847)	prob 2.259 (2.259)	GS 36.141 (36.141)	mem 39.857
Train: [49][335/750]	BT 0.031 (1.155)	DT 0.005 (1.108)	loss 7.014 (7.014)	prob 2.097 (2.097)	GS 30.219 (30.219)	mem 39.859
Train: [49][340/750]	BT 1.763 (1.173)	DT 1.731 (1.126)	loss 6.756 (6.756)	prob 1.911 (1.911)	GS 27.172 (27.172)	mem 39.877
Train: [49][345/750]	BT 0.035 (1.156)	DT 0.001 (1.110)	loss 6.895 (6.895)	prob 2.571 (2.571)	GS 30.500 (30.500)	mem 39.878
Train: [49][350/750]	BT 8.576 (1.165)	DT 8.486 (1.118)	loss 7.348 (7.348)	prob 1.391 (1.391)	GS 27.703 (27.703)	mem 39.841
Train: [49][355/750]	BT 0.032 (1.160)	DT 0.002 (1.114)	loss 6.776 (6.776)	prob 2.439 (2.439)	GS 31.438 (31.438)	mem 39.883
Train: [49][360/750]	BT 0.104 (1.145)	DT 0.001 (1.099)	loss 6.772 (6.772)	prob 2.685 (2.685)	GS 33.281 (33.281)	mem 39.798
Train: [49][365/750]	BT 0.044 (1.166)	DT 0.014 (1.120)	loss 6.907 (6.907)	prob 2.202 (2.202)	GS 32.609 (32.609)	mem 39.847
Train: [49][370/750]	BT 0.030 (1.151)	DT 0.001 (1.105)	loss 6.534 (6.534)	prob 2.588 (2.588)	GS 31.672 (31.672)	mem 39.848
Train: [49][375/750]	BT 0.043 (1.160)	DT 0.008 (1.114)	loss 6.697 (6.697)	prob 2.416 (2.416)	GS 33.984 (33.984)	mem 39.900
Train: [49][380/750]	BT 0.058 (1.158)	DT 0.002 (1.112)	loss 6.677 (6.677)	prob 3.133 (3.133)	GS 32.797 (32.797)	mem 40.004
Train: [49][385/750]	BT 0.085 (1.144)	DT 0.011 (1.098)	loss 6.874 (6.874)	prob 1.856 (1.856)	GS 33.062 (33.062)	mem 39.927
Train: [49][390/750]	BT 1.371 (1.161)	DT 1.309 (1.115)	loss 6.928 (6.928)	prob 2.139 (2.139)	GS 37.234 (37.234)	mem 39.849
Train: [49][395/750]	BT 0.051 (1.146)	DT 0.011 (1.101)	loss 7.446 (7.446)	prob 2.937 (2.937)	GS 33.953 (33.953)	mem 39.849
Train: [49][400/750]	BT 1.272 (1.161)	DT 1.241 (1.115)	loss 7.004 (7.004)	prob 2.308 (2.308)	GS 35.922 (35.922)	mem 39.911
Train: [49][405/750]	BT 0.138 (1.149)	DT 0.011 (1.103)	loss 6.786 (6.786)	prob 1.817 (1.817)	GS 25.812 (25.812)	mem 40.108
Train: [49][410/750]	BT 12.965 (1.167)	DT 12.933 (1.121)	loss 6.840 (6.840)	prob 2.124 (2.124)	GS 35.266 (35.266)	mem 39.938
Train: [49][415/750]	BT 0.034 (1.154)	DT 0.001 (1.108)	loss 6.791 (6.791)	prob 2.435 (2.435)	GS 33.453 (33.453)	mem 39.941
Train: [49][420/750]	BT 0.035 (1.141)	DT 0.001 (1.095)	loss 6.810 (6.810)	prob 2.888 (2.888)	GS 31.688 (31.688)	mem 39.943
Train: [49][425/750]	BT 0.027 (1.157)	DT 0.001 (1.112)	loss 6.942 (6.942)	prob 2.369 (2.369)	GS 35.250 (35.250)	mem 39.916
Train: [49][430/750]	BT 0.031 (1.151)	DT 0.001 (1.106)	loss 7.004 (7.004)	prob 2.278 (2.278)	GS 36.328 (36.328)	mem 39.844
Train: [49][435/750]	BT 0.030 (1.163)	DT 0.001 (1.117)	loss 7.048 (7.048)	prob 2.367 (2.367)	GS 29.000 (29.000)	mem 39.935
Train: [49][440/750]	BT 0.072 (1.151)	DT 0.004 (1.106)	loss 6.925 (6.925)	prob 2.326 (2.326)	GS 34.625 (34.625)	mem 40.080
Train: [49][445/750]	BT 0.099 (1.139)	DT 0.002 (1.094)	loss 6.850 (6.850)	prob 2.471 (2.471)	GS 27.469 (27.469)	mem 39.982
Train: [49][450/750]	BT 0.101 (1.161)	DT 0.006 (1.116)	loss 6.900 (6.900)	prob 2.421 (2.421)	GS 32.578 (32.578)	mem 40.044
Train: [49][455/750]	BT 0.050 (1.149)	DT 0.005 (1.104)	loss 6.858 (6.858)	prob 2.166 (2.166)	GS 32.484 (32.484)	mem 39.969
Train: [49][460/750]	BT 3.227 (1.163)	DT 3.169 (1.118)	loss 6.865 (6.865)	prob 1.944 (1.944)	GS 33.516 (33.516)	mem 39.991
Train: [49][465/750]	BT 0.101 (1.151)	DT 0.018 (1.106)	loss 6.754 (6.754)	prob 2.458 (2.458)	GS 30.453 (30.453)	mem 40.031
Train: [49][470/750]	BT 10.166 (1.161)	DT 10.124 (1.115)	loss 7.018 (7.018)	prob 2.563 (2.563)	GS 32.797 (32.797)	mem 39.931
Train: [49][475/750]	BT 0.041 (1.160)	DT 0.008 (1.114)	loss 6.783 (6.783)	prob 3.085 (3.085)	GS 31.266 (31.266)	mem 39.943
Train: [49][480/750]	BT 0.034 (1.148)	DT 0.002 (1.102)	loss 7.031 (7.031)	prob 2.334 (2.334)	GS 33.281 (33.281)	mem 40.088
Train: [49][485/750]	BT 0.037 (1.169)	DT 0.015 (1.123)	loss 7.069 (7.069)	prob 2.905 (2.905)	GS 25.641 (25.641)	mem 39.973
Train: [49][490/750]	BT 0.028 (1.157)	DT 0.001 (1.112)	loss 6.912 (6.912)	prob 2.560 (2.560)	GS 36.031 (36.031)	mem 39.976
Train: [49][495/750]	BT 0.084 (1.151)	DT 0.009 (1.105)	loss 6.744 (6.744)	prob 2.605 (2.605)	GS 32.891 (32.891)	mem 40.018
Train: [49][500/750]	BT 0.038 (1.164)	DT 0.001 (1.119)	loss 6.879 (6.879)	prob 2.490 (2.490)	GS 38.453 (38.453)	mem 39.985
Train: [49][505/750]	BT 0.047 (1.153)	DT 0.002 (1.108)	loss 6.925 (6.925)	prob 2.292 (2.292)	GS 29.750 (29.750)	mem 39.986
Train: [49][510/750]	BT 0.048 (1.166)	DT 0.009 (1.121)	loss 6.900 (6.900)	prob 2.712 (2.712)	GS 35.641 (35.641)	mem 40.058
Train: [49][515/750]	BT 0.037 (1.155)	DT 0.002 (1.110)	loss 6.835 (6.835)	prob 2.569 (2.569)	GS 33.453 (33.453)	mem 40.094
Train: [49][520/750]	BT 15.553 (1.174)	DT 15.521 (1.129)	loss 6.788 (6.788)	prob 2.648 (2.648)	GS 33.406 (33.406)	mem 39.926
Train: [49][525/750]	BT 0.023 (1.163)	DT 0.001 (1.118)	loss 6.859 (6.859)	prob 2.679 (2.679)	GS 30.906 (30.906)	mem 39.926
Train: [49][530/750]	BT 0.031 (1.152)	DT 0.001 (1.108)	loss 6.695 (6.695)	prob 2.950 (2.950)	GS 32.953 (32.953)	mem 39.927
Train: [49][535/750]	BT 0.032 (1.166)	DT 0.001 (1.121)	loss 7.202 (7.202)	prob 2.396 (2.396)	GS 33.688 (33.688)	mem 39.930
Train: [49][540/750]	BT 0.032 (1.155)	DT 0.002 (1.111)	loss 6.990 (6.990)	prob 2.055 (2.055)	GS 34.484 (34.484)	mem 39.930
Train: [49][545/750]	BT 0.030 (1.166)	DT 0.001 (1.121)	loss 6.948 (6.948)	prob 2.752 (2.752)	GS 28.703 (28.703)	mem 40.021
Train: [49][550/750]	BT 0.032 (1.155)	DT 0.002 (1.111)	loss 6.761 (6.761)	prob 2.723 (2.723)	GS 29.531 (29.531)	mem 39.954
Train: [49][555/750]	BT 0.034 (1.145)	DT 0.001 (1.101)	loss 6.907 (6.907)	prob 2.733 (2.733)	GS 32.062 (32.062)	mem 39.956
Train: [49][560/750]	BT 0.035 (1.154)	DT 0.001 (1.110)	loss 6.878 (6.878)	prob 2.602 (2.602)	GS 32.094 (32.094)	mem 40.007
Train: [49][565/750]	BT 0.049 (1.145)	DT 0.002 (1.100)	loss 6.806 (6.806)	prob 2.536 (2.536)	GS 31.172 (31.172)	mem 40.034
Train: [49][570/750]	BT 0.035 (1.160)	DT 0.002 (1.115)	loss 6.774 (6.774)	prob 2.614 (2.614)	GS 34.500 (34.500)	mem 39.971
Train: [49][575/750]	BT 0.037 (1.150)	DT 0.009 (1.106)	loss 6.964 (6.964)	prob 2.524 (2.524)	GS 32.906 (32.906)	mem 39.971
Train: [49][580/750]	BT 13.254 (1.163)	DT 13.212 (1.119)	loss 6.885 (6.885)	prob 2.563 (2.563)	GS 32.641 (32.641)	mem 40.128
Train: [49][585/750]	BT 0.066 (1.154)	DT 0.025 (1.110)	loss 7.051 (7.051)	prob 2.684 (2.684)	GS 28.141 (28.141)	mem 39.950
Train: [49][590/750]	BT 0.040 (1.145)	DT 0.003 (1.100)	loss 6.726 (6.726)	prob 3.237 (3.237)	GS 34.797 (34.797)	mem 39.951
Train: [49][595/750]	BT 0.067 (1.161)	DT 0.017 (1.116)	loss 6.769 (6.769)	prob 2.996 (2.996)	GS 32.688 (32.688)	mem 40.000
Train: [49][600/750]	BT 0.032 (1.151)	DT 0.001 (1.107)	loss 6.857 (6.857)	prob 2.922 (2.922)	GS 33.672 (33.672)	mem 39.999
Train: [49][605/750]	BT 0.025 (1.164)	DT 0.002 (1.120)	loss 6.917 (6.917)	prob 2.363 (2.363)	GS 38.453 (38.453)	mem 39.959
Train: [49][610/750]	BT 0.043 (1.155)	DT 0.011 (1.111)	loss 7.093 (7.093)	prob 2.770 (2.770)	GS 35.625 (35.625)	mem 39.959
Train: [49][615/750]	BT 0.059 (1.146)	DT 0.002 (1.102)	loss 6.980 (6.980)	prob 3.401 (3.401)	GS 29.250 (29.250)	mem 40.011
Train: [49][620/750]	BT 0.046 (1.155)	DT 0.005 (1.111)	loss 6.907 (6.907)	prob 3.249 (3.249)	GS 32.812 (32.812)	mem 40.015
Train: [49][625/750]	BT 0.034 (1.146)	DT 0.002 (1.102)	loss 6.939 (6.939)	prob 2.868 (2.868)	GS 31.297 (31.297)	mem 40.102
Train: [49][630/750]	BT 0.079 (1.160)	DT 0.021 (1.115)	loss 6.866 (6.866)	prob 2.606 (2.606)	GS 32.281 (32.281)	mem 40.002
Train: [49][635/750]	BT 0.024 (1.151)	DT 0.001 (1.107)	loss 6.926 (6.926)	prob 2.847 (2.847)	GS 32.359 (32.359)	mem 40.004
Train: [49][640/750]	BT 11.764 (1.160)	DT 11.732 (1.116)	loss 6.913 (6.913)	prob 3.131 (3.131)	GS 36.031 (36.031)	mem 39.908
Train: [49][645/750]	BT 0.026 (1.152)	DT 0.001 (1.108)	loss 6.772 (6.772)	prob 3.227 (3.227)	GS 32.734 (32.734)	mem 39.907
Train: [49][650/750]	BT 0.060 (1.143)	DT 0.015 (1.099)	loss 6.835 (6.835)	prob 2.936 (2.936)	GS 36.391 (36.391)	mem 40.126
Train: [49][655/750]	BT 0.032 (1.153)	DT 0.001 (1.109)	loss 6.972 (6.972)	prob 2.058 (2.058)	GS 33.641 (33.641)	mem 39.939
arpack error, retry= 0
arpack error, retry= 0
Train: [49][660/750]	BT 0.045 (1.144)	DT 0.004 (1.100)	loss 7.046 (7.046)	prob 2.339 (2.339)	GS 34.219 (34.219)	mem 40.090
Train: [49][665/750]	BT 0.033 (1.155)	DT 0.006 (1.111)	loss 6.954 (6.954)	prob 2.946 (2.946)	GS 31.531 (31.531)	mem 39.916
Train: [49][670/750]	BT 0.050 (1.146)	DT 0.001 (1.102)	loss 6.786 (6.786)	prob 3.014 (3.014)	GS 33.219 (33.219)	mem 39.922
Train: [49][675/750]	BT 0.028 (1.138)	DT 0.001 (1.094)	loss 6.833 (6.833)	prob 2.206 (2.206)	GS 31.219 (31.219)	mem 39.919
Train: [49][680/750]	BT 0.033 (1.149)	DT 0.002 (1.104)	loss 7.029 (7.029)	prob 2.633 (2.633)	GS 40.969 (40.969)	mem 39.952
Train: [49][685/750]	BT 0.030 (1.140)	DT 0.001 (1.096)	loss 6.859 (6.859)	prob 3.011 (3.011)	GS 32.125 (32.125)	mem 39.952
Train: [49][690/750]	BT 0.045 (1.153)	DT 0.001 (1.109)	loss 6.998 (6.998)	prob 2.746 (2.746)	GS 31.766 (31.766)	mem 39.956
Train: [49][695/750]	BT 0.076 (1.146)	DT 0.003 (1.101)	loss 7.002 (7.002)	prob 2.811 (2.811)	GS 31.484 (31.484)	mem 39.899
Train: [49][700/750]	BT 13.465 (1.157)	DT 13.412 (1.113)	loss 6.574 (6.574)	prob 3.500 (3.500)	GS 34.781 (34.781)	mem 39.893
Train: [49][705/750]	BT 0.030 (1.149)	DT 0.001 (1.105)	loss 6.780 (6.780)	prob 3.417 (3.417)	GS 31.703 (31.703)	mem 39.891
Train: [49][710/750]	BT 0.034 (1.141)	DT 0.001 (1.097)	loss 6.837 (6.837)	prob 3.514 (3.514)	GS 36.297 (36.297)	mem 39.932
Train: [49][715/750]	BT 0.027 (1.155)	DT 0.001 (1.111)	loss 7.079 (7.079)	prob 2.893 (2.893)	GS 30.453 (30.453)	mem 39.920
Train: [49][720/750]	BT 0.076 (1.147)	DT 0.003 (1.103)	loss 6.954 (6.954)	prob 2.452 (2.452)	GS 32.078 (32.078)	mem 39.920
Train: [49][725/750]	BT 0.037 (1.154)	DT 0.003 (1.110)	loss 6.729 (6.729)	prob 3.388 (3.388)	GS 30.203 (30.203)	mem 39.768
Train: [49][730/750]	BT 0.029 (1.146)	DT 0.001 (1.102)	loss 6.782 (6.782)	prob 2.896 (2.896)	GS 37.281 (37.281)	mem 39.799
Train: [49][735/750]	BT 0.040 (1.139)	DT 0.006 (1.095)	loss 6.932 (6.932)	prob 2.757 (2.757)	GS 33.547 (33.547)	mem 39.693
Train: [49][740/750]	BT 0.034 (1.143)	DT 0.001 (1.099)	loss 6.909 (6.909)	prob 3.473 (3.473)	GS 30.562 (30.562)	mem 10.525
Train: [49][745/750]	BT 0.029 (1.135)	DT 0.002 (1.092)	loss 6.907 (6.907)	prob 3.204 (3.204)	GS 28.719 (28.719)	mem 10.524
Train: [49][750/750]	BT 0.042 (1.130)	DT 0.002 (1.087)	loss 6.740 (6.740)	prob 3.605 (3.605)	GS 30.844 (30.844)	mem 8.654
Train: [49][755/750]	BT 0.025 (1.123)	DT 0.001 (1.079)	loss 6.889 (6.889)	prob 2.958 (2.958)	GS 44.625 (44.625)	mem 7.521
epoch 49, total time 848.08
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [50][1/750]	BT 23.646 (23.646)	DT 23.599 (23.599)	loss 6.865 (6.865)	prob 3.350 (3.350)	GS 32.578 (32.578)	mem 38.690
Train: [50][5/750]	BT 0.031 (4.764)	DT 0.001 (4.726)	loss 6.919 (6.919)	prob 3.013 (3.013)	GS 28.047 (28.047)	mem 38.605
Train: [50][10/750]	BT 1.324 (2.531)	DT 1.293 (2.494)	loss 6.802 (6.802)	prob 3.301 (3.301)	GS 33.828 (33.828)	mem 38.716
Train: [50][15/750]	BT 0.034 (2.426)	DT 0.001 (2.386)	loss 6.601 (6.601)	prob 3.320 (3.320)	GS 27.906 (27.906)	mem 38.815
Train: [50][20/750]	BT 4.369 (2.053)	DT 4.314 (2.006)	loss 6.886 (6.886)	prob 2.663 (2.663)	GS 32.891 (32.891)	mem 38.820
Train: [50][25/750]	BT 3.330 (1.928)	DT 3.283 (1.881)	loss 6.950 (6.950)	prob 3.274 (3.274)	GS 33.672 (33.672)	mem 38.928
Train: [50][30/750]	BT 0.048 (1.755)	DT 0.002 (1.709)	loss 6.626 (6.626)	prob 4.264 (4.264)	GS 32.391 (32.391)	mem 39.053
Train: [50][35/750]	BT 0.028 (1.814)	DT 0.002 (1.767)	loss 7.039 (7.039)	prob 2.721 (2.721)	GS 27.625 (27.625)	mem 39.062
Train: [50][40/750]	BT 0.820 (1.662)	DT 0.673 (1.613)	loss 6.862 (6.862)	prob 3.046 (3.046)	GS 33.172 (33.172)	mem 39.533
Train: [50][45/750]	BT 0.048 (1.585)	DT 0.002 (1.534)	loss 6.736 (6.736)	prob 3.635 (3.635)	GS 32.391 (32.391)	mem 39.380
Train: [50][50/750]	BT 1.930 (1.615)	DT 1.904 (1.563)	loss 6.950 (6.950)	prob 2.743 (2.743)	GS 32.641 (32.641)	mem 39.583
Train: [50][55/750]	BT 0.047 (1.485)	DT 0.018 (1.434)	loss 7.015 (7.015)	prob 2.936 (2.936)	GS 29.281 (29.281)	mem 39.685
Train: [50][60/750]	BT 0.028 (1.615)	DT 0.001 (1.565)	loss 6.774 (6.774)	prob 3.105 (3.105)	GS 32.625 (32.625)	mem 39.571
Train: [50][65/750]	BT 0.067 (1.495)	DT 0.005 (1.446)	loss 6.681 (6.681)	prob 3.195 (3.195)	GS 30.812 (30.812)	mem 39.572
Train: [50][70/750]	BT 14.679 (1.642)	DT 14.646 (1.593)	loss 6.738 (6.738)	prob 3.395 (3.395)	GS 36.953 (36.953)	mem 39.592
Train: [50][75/750]	BT 0.035 (1.537)	DT 0.001 (1.488)	loss 7.045 (7.045)	prob 2.969 (2.969)	GS 30.156 (30.156)	mem 39.595
Train: [50][80/750]	BT 0.039 (1.443)	DT 0.001 (1.395)	loss 6.914 (6.914)	prob 3.427 (3.427)	GS 35.797 (35.797)	mem 39.596
Train: [50][85/750]	BT 0.062 (1.500)	DT 0.002 (1.452)	loss 6.800 (6.800)	prob 3.689 (3.689)	GS 36.312 (36.312)	mem 39.679
Train: [50][90/750]	BT 0.032 (1.419)	DT 0.001 (1.371)	loss 6.864 (6.864)	prob 3.667 (3.667)	GS 32.328 (32.328)	mem 39.600
Train: [50][95/750]	BT 0.024 (1.500)	DT 0.001 (1.453)	loss 6.944 (6.944)	prob 3.613 (3.613)	GS 28.562 (28.562)	mem 39.649
Train: [50][100/750]	BT 0.029 (1.427)	DT 0.001 (1.381)	loss 6.844 (6.844)	prob 3.155 (3.155)	GS 35.000 (35.000)	mem 39.649
Train: [50][105/750]	BT 0.099 (1.361)	DT 0.006 (1.315)	loss 6.779 (6.779)	prob 3.584 (3.584)	GS 25.531 (25.531)	mem 39.685
Train: [50][110/750]	BT 0.022 (1.430)	DT 0.001 (1.385)	loss 6.949 (6.949)	prob 3.400 (3.400)	GS 34.641 (34.641)	mem 39.716
Train: [50][115/750]	BT 0.031 (1.369)	DT 0.001 (1.325)	loss 6.927 (6.927)	prob 3.110 (3.110)	GS 35.234 (35.234)	mem 39.711
Train: [50][120/750]	BT 0.047 (1.427)	DT 0.008 (1.383)	loss 6.851 (6.851)	prob 3.177 (3.177)	GS 35.891 (35.891)	mem 39.678
Train: [50][125/750]	BT 0.067 (1.372)	DT 0.010 (1.328)	loss 6.911 (6.911)	prob 3.524 (3.524)	GS 31.828 (31.828)	mem 39.745
Train: [50][130/750]	BT 14.398 (1.432)	DT 14.359 (1.387)	loss 6.789 (6.789)	prob 2.726 (2.726)	GS 35.172 (35.172)	mem 39.855
Train: [50][135/750]	BT 0.031 (1.381)	DT 0.001 (1.336)	loss 6.885 (6.885)	prob 3.043 (3.043)	GS 32.109 (32.109)	mem 39.787
Train: [50][140/750]	BT 0.058 (1.333)	DT 0.002 (1.289)	loss 6.794 (6.794)	prob 3.103 (3.103)	GS 36.859 (36.859)	mem 39.862
Train: [50][145/750]	BT 0.047 (1.387)	DT 0.001 (1.342)	loss 7.021 (7.021)	prob 3.154 (3.154)	GS 30.875 (30.875)	mem 39.782
Train: [50][150/750]	BT 0.023 (1.342)	DT 0.001 (1.297)	loss 6.839 (6.839)	prob 3.634 (3.634)	GS 33.906 (33.906)	mem 39.782
Train: [50][155/750]	BT 0.032 (1.373)	DT 0.001 (1.329)	loss 6.818 (6.818)	prob 3.760 (3.760)	GS 32.297 (32.297)	mem 39.803
Train: [50][160/750]	BT 0.054 (1.331)	DT 0.009 (1.287)	loss 7.036 (7.036)	prob 3.083 (3.083)	GS 32.172 (32.172)	mem 39.844
Train: [50][165/750]	BT 0.033 (1.293)	DT 0.005 (1.248)	loss 7.124 (7.124)	prob 3.621 (3.621)	GS 29.297 (29.297)	mem 39.823
Train: [50][170/750]	BT 0.025 (1.350)	DT 0.001 (1.306)	loss 6.931 (6.931)	prob 3.394 (3.394)	GS 30.859 (30.859)	mem 39.861
Train: [50][175/750]	BT 0.081 (1.313)	DT 0.002 (1.269)	loss 7.100 (7.100)	prob 3.220 (3.220)	GS 29.125 (29.125)	mem 39.862
Train: [50][180/750]	BT 0.031 (1.348)	DT 0.001 (1.304)	loss 6.860 (6.860)	prob 3.548 (3.548)	GS 33.922 (33.922)	mem 39.787
Train: [50][185/750]	BT 0.047 (1.313)	DT 0.011 (1.269)	loss 6.756 (6.756)	prob 3.452 (3.452)	GS 29.094 (29.094)	mem 39.840
Train: [50][190/750]	BT 10.771 (1.335)	DT 10.739 (1.292)	loss 6.728 (6.728)	prob 3.570 (3.570)	GS 30.422 (30.422)	mem 39.819
Train: [50][195/750]	BT 0.033 (1.302)	DT 0.001 (1.259)	loss 6.978 (6.978)	prob 3.310 (3.310)	GS 29.500 (29.500)	mem 39.913
Train: [50][200/750]	BT 0.057 (1.270)	DT 0.010 (1.228)	loss 6.917 (6.917)	prob 4.049 (4.049)	GS 34.094 (34.094)	mem 39.824
Train: [50][205/750]	BT 0.027 (1.301)	DT 0.001 (1.259)	loss 7.017 (7.017)	prob 2.852 (2.852)	GS 34.547 (34.547)	mem 39.902
Train: [50][210/750]	BT 0.036 (1.271)	DT 0.002 (1.229)	loss 7.059 (7.059)	prob 3.505 (3.505)	GS 31.281 (31.281)	mem 40.000
Train: [50][215/750]	BT 0.031 (1.285)	DT 0.001 (1.243)	loss 6.833 (6.833)	prob 3.339 (3.339)	GS 33.266 (33.266)	mem 39.923
Train: [50][220/750]	BT 4.882 (1.278)	DT 4.854 (1.236)	loss 7.015 (7.015)	prob 2.884 (2.884)	GS 35.266 (35.266)	mem 39.938
Train: [50][225/750]	BT 0.051 (1.251)	DT 0.014 (1.209)	loss 7.098 (7.098)	prob 2.798 (2.798)	GS 27.375 (27.375)	mem 39.938
Train: [50][230/750]	BT 0.110 (1.266)	DT 0.009 (1.224)	loss 6.813 (6.813)	prob 2.782 (2.782)	GS 34.344 (34.344)	mem 39.913
Train: [50][235/750]	BT 0.051 (1.252)	DT 0.008 (1.209)	loss 6.979 (6.979)	prob 3.055 (3.055)	GS 35.484 (35.484)	mem 39.937
Train: [50][240/750]	BT 0.022 (1.271)	DT 0.001 (1.229)	loss 6.800 (6.800)	prob 3.793 (3.793)	GS 36.578 (36.578)	mem 39.990
Train: [50][245/750]	BT 0.023 (1.254)	DT 0.001 (1.212)	loss 6.897 (6.897)	prob 3.154 (3.154)	GS 33.594 (33.594)	mem 39.971
Train: [50][250/750]	BT 8.602 (1.264)	DT 8.567 (1.223)	loss 6.860 (6.860)	prob 2.755 (2.755)	GS 29.828 (29.828)	mem 39.918
Train: [50][255/750]	BT 0.052 (1.250)	DT 0.001 (1.208)	loss 7.334 (7.334)	prob 2.961 (2.961)	GS 30.766 (30.766)	mem 39.989
Train: [50][260/750]	BT 0.044 (1.228)	DT 0.003 (1.185)	loss 7.126 (7.126)	prob 3.226 (3.226)	GS 32.797 (32.797)	mem 39.892
Train: [50][265/750]	BT 0.035 (1.254)	DT 0.001 (1.211)	loss 7.062 (7.062)	prob 3.151 (3.151)	GS 31.141 (31.141)	mem 39.998
Train: [50][270/750]	BT 0.083 (1.231)	DT 0.002 (1.189)	loss 6.902 (6.902)	prob 3.612 (3.612)	GS 33.297 (33.297)	mem 39.916
Train: [50][275/750]	BT 0.061 (1.247)	DT 0.033 (1.204)	loss 6.929 (6.929)	prob 2.744 (2.744)	GS 31.344 (31.344)	mem 39.873
Train: [50][280/750]	BT 0.037 (1.232)	DT 0.005 (1.190)	loss 7.057 (7.057)	prob 3.547 (3.547)	GS 33.469 (33.469)	mem 39.926
Train: [50][285/750]	BT 0.065 (1.212)	DT 0.011 (1.169)	loss 7.008 (7.008)	prob 3.366 (3.366)	GS 31.125 (31.125)	mem 39.991
Train: [50][290/750]	BT 0.059 (1.241)	DT 0.003 (1.199)	loss 6.912 (6.912)	prob 3.629 (3.629)	GS 35.578 (35.578)	mem 39.949
Train: [50][295/750]	BT 0.110 (1.221)	DT 0.021 (1.179)	loss 7.140 (7.140)	prob 3.294 (3.294)	GS 27.625 (27.625)	mem 39.950
Train: [50][300/750]	BT 2.600 (1.237)	DT 2.559 (1.194)	loss 6.774 (6.774)	prob 3.489 (3.489)	GS 32.703 (32.703)	mem 40.098
Train: [50][305/750]	BT 0.030 (1.217)	DT 0.001 (1.174)	loss 6.962 (6.962)	prob 3.129 (3.129)	GS 31.734 (31.734)	mem 39.977
Train: [50][310/750]	BT 8.994 (1.228)	DT 8.962 (1.185)	loss 6.918 (6.918)	prob 2.494 (2.494)	GS 33.391 (33.391)	mem 40.091
Train: [50][315/750]	BT 0.057 (1.211)	DT 0.006 (1.168)	loss 6.977 (6.977)	prob 3.634 (3.634)	GS 29.953 (29.953)	mem 40.033
Train: [50][320/750]	BT 0.044 (1.193)	DT 0.001 (1.150)	loss 6.846 (6.846)	prob 3.086 (3.086)	GS 35.656 (35.656)	mem 39.982
Train: [50][325/750]	BT 0.033 (1.212)	DT 0.002 (1.169)	loss 7.151 (7.151)	prob 2.545 (2.545)	GS 32.750 (32.750)	mem 40.008
Train: [50][330/750]	BT 0.061 (1.201)	DT 0.004 (1.158)	loss 6.916 (6.916)	prob 3.310 (3.310)	GS 35.422 (35.422)	mem 39.940
Train: [50][335/750]	BT 0.024 (1.210)	DT 0.001 (1.167)	loss 6.826 (6.826)	prob 2.952 (2.952)	GS 31.906 (31.906)	mem 40.033
Train: [50][340/750]	BT 0.072 (1.203)	DT 0.008 (1.160)	loss 6.959 (6.959)	prob 3.428 (3.428)	GS 31.797 (31.797)	mem 39.955
Train: [50][345/750]	BT 0.035 (1.186)	DT 0.001 (1.143)	loss 6.978 (6.978)	prob 3.330 (3.330)	GS 34.172 (34.172)	mem 39.955
Train: [50][350/750]	BT 0.056 (1.208)	DT 0.003 (1.166)	loss 6.909 (6.909)	prob 2.971 (2.971)	GS 35.172 (35.172)	mem 39.854
Train: [50][355/750]	BT 0.061 (1.192)	DT 0.010 (1.149)	loss 7.035 (7.035)	prob 2.879 (2.879)	GS 30.703 (30.703)	mem 39.854
Train: [50][360/750]	BT 1.803 (1.209)	DT 1.781 (1.166)	loss 6.960 (6.960)	prob 3.495 (3.495)	GS 32.938 (32.938)	mem 40.103
Train: [50][365/750]	BT 0.052 (1.193)	DT 0.014 (1.150)	loss 7.009 (7.009)	prob 2.908 (2.908)	GS 32.469 (32.469)	mem 40.072
Train: [50][370/750]	BT 10.190 (1.205)	DT 10.156 (1.162)	loss 7.067 (7.067)	prob 3.020 (3.020)	GS 35.562 (35.562)	mem 40.122
Train: [50][375/750]	BT 0.031 (1.205)	DT 0.001 (1.162)	loss 6.748 (6.748)	prob 3.028 (3.028)	GS 34.922 (34.922)	mem 39.967
Train: [50][380/750]	BT 0.062 (1.189)	DT 0.001 (1.147)	loss 6.866 (6.866)	prob 3.024 (3.024)	GS 31.703 (31.703)	mem 39.969
Train: [50][385/750]	BT 0.033 (1.202)	DT 0.001 (1.160)	loss 6.892 (6.892)	prob 2.787 (2.787)	GS 29.562 (29.562)	mem 39.988
Train: [50][390/750]	BT 0.035 (1.188)	DT 0.002 (1.145)	loss 7.120 (7.120)	prob 2.468 (2.468)	GS 32.406 (32.406)	mem 39.989
Train: [50][395/750]	BT 0.077 (1.187)	DT 0.018 (1.144)	loss 6.799 (6.799)	prob 3.283 (3.283)	GS 34.453 (34.453)	mem 40.301
Train: [50][400/750]	BT 0.035 (1.190)	DT 0.001 (1.147)	loss 6.929 (6.929)	prob 3.084 (3.084)	GS 31.906 (31.906)	mem 39.818
Train: [50][405/750]	BT 0.032 (1.175)	DT 0.001 (1.133)	loss 7.123 (7.123)	prob 2.735 (2.735)	GS 28.062 (28.062)	mem 39.820
Train: [50][410/750]	BT 1.250 (1.189)	DT 1.188 (1.145)	loss 6.827 (6.827)	prob 3.052 (3.052)	GS 37.031 (37.031)	mem 40.349
Train: [50][415/750]	BT 0.068 (1.179)	DT 0.005 (1.135)	loss 6.833 (6.833)	prob 3.211 (3.211)	GS 26.688 (26.688)	mem 39.993
Train: [50][420/750]	BT 1.388 (1.195)	DT 1.340 (1.151)	loss 7.012 (7.012)	prob 2.352 (2.352)	GS 35.953 (35.953)	mem 39.859
Train: [50][425/750]	BT 0.038 (1.181)	DT 0.001 (1.138)	loss 6.966 (6.966)	prob 3.148 (3.148)	GS 28.906 (28.906)	mem 39.796
Train: [50][430/750]	BT 10.019 (1.191)	DT 9.934 (1.148)	loss 6.816 (6.816)	prob 2.941 (2.941)	GS 31.688 (31.688)	mem 39.861
Train: [50][435/750]	BT 0.033 (1.193)	DT 0.001 (1.149)	loss 7.115 (7.115)	prob 2.329 (2.329)	GS 31.766 (31.766)	mem 39.800
Train: [50][440/750]	BT 0.042 (1.180)	DT 0.002 (1.136)	loss 6.874 (6.874)	prob 3.811 (3.811)	GS 32.875 (32.875)	mem 39.899
Train: [50][445/750]	BT 0.030 (1.191)	DT 0.001 (1.148)	loss 6.935 (6.935)	prob 2.323 (2.323)	GS 30.312 (30.312)	mem 39.825
Train: [50][450/750]	BT 0.031 (1.178)	DT 0.001 (1.135)	loss 6.980 (6.980)	prob 2.992 (2.992)	GS 36.734 (36.734)	mem 39.826
Train: [50][455/750]	BT 0.026 (1.179)	DT 0.001 (1.136)	loss 6.801 (6.801)	prob 3.439 (3.439)	GS 35.281 (35.281)	mem 39.891
Train: [50][460/750]	BT 0.029 (1.182)	DT 0.001 (1.138)	loss 6.852 (6.852)	prob 2.400 (2.400)	GS 32.094 (32.094)	mem 39.912
Train: [50][465/750]	BT 0.031 (1.169)	DT 0.001 (1.126)	loss 7.595 (7.595)	prob 2.166 (2.166)	GS 39.359 (39.359)	mem 39.913
Train: [50][470/750]	BT 0.080 (1.185)	DT 0.001 (1.142)	loss 6.935 (6.935)	prob 2.368 (2.368)	GS 31.266 (31.266)	mem 39.960
Train: [50][475/750]	BT 0.030 (1.173)	DT 0.001 (1.130)	loss 6.866 (6.866)	prob 3.408 (3.408)	GS 31.891 (31.891)	mem 39.929
Train: [50][480/750]	BT 3.235 (1.183)	DT 3.187 (1.140)	loss 6.916 (6.916)	prob 2.602 (2.602)	GS 33.391 (33.391)	mem 39.988
Train: [50][485/750]	BT 0.119 (1.176)	DT 0.001 (1.132)	loss 6.876 (6.876)	prob 3.296 (3.296)	GS 28.281 (28.281)	mem 40.096
Train: [50][490/750]	BT 13.322 (1.191)	DT 13.290 (1.148)	loss 6.843 (6.843)	prob 3.072 (3.072)	GS 37.234 (37.234)	mem 39.848
Train: [50][495/750]	BT 0.133 (1.188)	DT 0.010 (1.144)	loss 6.930 (6.930)	prob 3.384 (3.384)	GS 33.375 (33.375)	mem 39.812
Train: [50][500/750]	BT 0.031 (1.176)	DT 0.002 (1.133)	loss 7.055 (7.055)	prob 3.057 (3.057)	GS 31.406 (31.406)	mem 39.813
Train: [50][505/750]	BT 0.051 (1.184)	DT 0.004 (1.141)	loss 6.952 (6.952)	prob 3.393 (3.393)	GS 35.797 (35.797)	mem 39.851
Train: [50][510/750]	BT 0.054 (1.177)	DT 0.003 (1.133)	loss 6.946 (6.946)	prob 3.456 (3.456)	GS 30.828 (30.828)	mem 39.891
Train: [50][515/750]	BT 0.023 (1.189)	DT 0.001 (1.146)	loss 6.963 (6.963)	prob 3.231 (3.231)	GS 29.859 (29.859)	mem 39.897
Train: [50][520/750]	BT 0.054 (1.184)	DT 0.010 (1.140)	loss 6.986 (6.986)	prob 2.936 (2.936)	GS 36.344 (36.344)	mem 39.790
Train: [50][525/750]	BT 0.042 (1.173)	DT 0.012 (1.129)	loss 7.627 (7.627)	prob 2.130 (2.130)	GS 33.062 (33.062)	mem 39.790
Train: [50][530/750]	BT 3.553 (1.185)	DT 3.495 (1.142)	loss 6.813 (6.813)	prob 2.774 (2.774)	GS 32.344 (32.344)	mem 40.006
Train: [50][535/750]	BT 0.031 (1.175)	DT 0.001 (1.131)	loss 7.011 (7.011)	prob 2.428 (2.428)	GS 33.312 (33.312)	mem 39.818
Train: [50][540/750]	BT 0.068 (1.182)	DT 0.020 (1.138)	loss 6.919 (6.919)	prob 2.773 (2.773)	GS 32.797 (32.797)	mem 39.934
Train: [50][545/750]	BT 0.066 (1.175)	DT 0.003 (1.131)	loss 6.870 (6.870)	prob 2.601 (2.601)	GS 25.656 (25.656)	mem 39.909
Train: [50][550/750]	BT 8.457 (1.180)	DT 8.423 (1.136)	loss 6.939 (6.939)	prob 2.258 (2.258)	GS 28.469 (28.469)	mem 39.911
Train: [50][555/750]	BT 0.098 (1.171)	DT 0.005 (1.127)	loss 6.738 (6.738)	prob 2.714 (2.714)	GS 29.406 (29.406)	mem 39.912
Train: [50][560/750]	BT 0.046 (1.162)	DT 0.004 (1.117)	loss 6.728 (6.728)	prob 3.136 (3.136)	GS 32.391 (32.391)	mem 39.955
Train: [50][565/750]	BT 0.024 (1.171)	DT 0.001 (1.127)	loss 6.801 (6.801)	prob 2.559 (2.559)	GS 37.219 (37.219)	mem 39.893
Train: [50][570/750]	BT 0.037 (1.169)	DT 0.003 (1.125)	loss 6.665 (6.665)	prob 2.710 (2.710)	GS 34.234 (34.234)	mem 39.881
Train: [50][575/750]	BT 0.036 (1.180)	DT 0.002 (1.135)	loss 6.785 (6.785)	prob 3.114 (3.114)	GS 33.156 (33.156)	mem 39.923
Train: [50][580/750]	BT 0.032 (1.170)	DT 0.001 (1.126)	loss 6.836 (6.836)	prob 2.543 (2.543)	GS 29.266 (29.266)	mem 39.926
Train: [50][585/750]	BT 0.044 (1.161)	DT 0.001 (1.116)	loss 6.944 (6.944)	prob 2.304 (2.304)	GS 31.500 (31.500)	mem 40.005
Train: [50][590/750]	BT 0.023 (1.175)	DT 0.001 (1.130)	loss 6.973 (6.973)	prob 2.631 (2.631)	GS 37.234 (37.234)	mem 40.005
Train: [50][595/750]	BT 0.036 (1.165)	DT 0.002 (1.121)	loss 6.545 (6.545)	prob 3.418 (3.418)	GS 32.625 (32.625)	mem 40.064
Train: [50][600/750]	BT 0.031 (1.177)	DT 0.001 (1.132)	loss 6.851 (6.851)	prob 2.830 (2.830)	GS 34.719 (34.719)	mem 39.888
Train: [50][605/750]	BT 0.075 (1.168)	DT 0.015 (1.124)	loss 6.773 (6.773)	prob 3.175 (3.175)	GS 30.391 (30.391)	mem 39.943
Train: [50][610/750]	BT 12.094 (1.179)	DT 12.058 (1.134)	loss 6.580 (6.580)	prob 3.222 (3.222)	GS 34.984 (34.984)	mem 39.944
Train: [50][615/750]	BT 0.094 (1.173)	DT 0.005 (1.129)	loss 7.132 (7.132)	prob 2.401 (2.401)	GS 38.219 (38.219)	mem 39.971
Train: [50][620/750]	BT 0.026 (1.164)	DT 0.001 (1.120)	loss 6.928 (6.928)	prob 3.000 (3.000)	GS 32.969 (32.969)	mem 39.973
Train: [50][625/750]	BT 0.057 (1.168)	DT 0.026 (1.124)	loss 6.799 (6.799)	prob 2.569 (2.569)	GS 32.109 (32.109)	mem 40.005
Train: [50][630/750]	BT 0.039 (1.168)	DT 0.001 (1.124)	loss 6.946 (6.946)	prob 2.375 (2.375)	GS 32.469 (32.469)	mem 40.278
Train: [50][635/750]	BT 0.042 (1.168)	DT 0.001 (1.124)	loss 6.789 (6.789)	prob 3.205 (3.205)	GS 35.359 (35.359)	mem 39.973
Train: [50][640/750]	BT 0.027 (1.171)	DT 0.001 (1.127)	loss 6.762 (6.762)	prob 3.104 (3.104)	GS 31.062 (31.062)	mem 40.136
Train: [50][645/750]	BT 0.066 (1.162)	DT 0.010 (1.118)	loss 6.860 (6.860)	prob 2.896 (2.896)	GS 31.203 (31.203)	mem 39.992
Train: [50][650/750]	BT 8.283 (1.174)	DT 8.245 (1.130)	loss 6.817 (6.817)	prob 2.506 (2.506)	GS 35.328 (35.328)	mem 40.233
Train: [50][655/750]	BT 0.076 (1.166)	DT 0.019 (1.122)	loss 6.821 (6.821)	prob 2.892 (2.892)	GS 26.781 (26.781)	mem 40.010
arpack error, retry= 0
Train: [50][660/750]	BT 0.054 (1.168)	DT 0.005 (1.123)	loss 6.872 (6.872)	prob 3.197 (3.197)	GS 30.172 (30.172)	mem 40.006
Train: [50][665/750]	BT 0.058 (1.168)	DT 0.007 (1.124)	loss 7.008 (7.008)	prob 3.021 (3.021)	GS 43.297 (43.297)	mem 40.137
Train: [50][670/750]	BT 10.250 (1.175)	DT 10.219 (1.130)	loss 7.077 (7.077)	prob 2.736 (2.736)	GS 34.922 (34.922)	mem 39.980
Train: [50][675/750]	BT 0.042 (1.170)	DT 0.008 (1.125)	loss 6.768 (6.768)	prob 3.523 (3.523)	GS 31.406 (31.406)	mem 39.981
Train: [50][680/750]	BT 0.072 (1.162)	DT 0.003 (1.117)	loss 7.023 (7.023)	prob 2.981 (2.981)	GS 34.938 (34.938)	mem 39.994
Train: [50][685/750]	BT 0.098 (1.171)	DT 0.002 (1.126)	loss 6.831 (6.831)	prob 3.133 (3.133)	GS 25.016 (25.016)	mem 40.120
Train: [50][690/750]	BT 0.032 (1.165)	DT 0.001 (1.120)	loss 6.882 (6.882)	prob 3.530 (3.530)	GS 31.828 (31.828)	mem 40.074
Train: [50][695/750]	BT 0.038 (1.174)	DT 0.008 (1.129)	loss 6.944 (6.944)	prob 2.653 (2.653)	GS 34.750 (34.750)	mem 39.933
Train: [50][700/750]	BT 0.029 (1.171)	DT 0.001 (1.127)	loss 7.077 (7.077)	prob 2.999 (2.999)	GS 35.641 (35.641)	mem 39.965
Train: [50][705/750]	BT 0.062 (1.164)	DT 0.008 (1.119)	loss 7.114 (7.114)	prob 2.567 (2.567)	GS 31.797 (31.797)	mem 40.050
Train: [50][710/750]	BT 5.798 (1.174)	DT 5.744 (1.129)	loss 6.991 (6.991)	prob 2.960 (2.960)	GS 34.281 (34.281)	mem 39.989
Train: [50][715/750]	BT 0.057 (1.166)	DT 0.009 (1.121)	loss 6.977 (6.977)	prob 2.673 (2.673)	GS 34.141 (34.141)	mem 39.990
Train: [50][720/750]	BT 0.049 (1.166)	DT 0.003 (1.121)	loss 7.328 (7.328)	prob 2.099 (2.099)	GS 33.078 (33.078)	mem 40.006
Train: [50][725/750]	BT 0.047 (1.169)	DT 0.001 (1.124)	loss 6.684 (6.684)	prob 3.146 (3.146)	GS 32.453 (32.453)	mem 39.957
Train: [50][730/750]	BT 4.644 (1.168)	DT 4.621 (1.123)	loss 7.000 (7.000)	prob 3.087 (3.087)	GS 33.516 (33.516)	mem 39.567
Train: [50][735/750]	BT 0.030 (1.165)	DT 0.001 (1.120)	loss 7.037 (7.037)	prob 2.449 (2.449)	GS 32.000 (32.000)	mem 36.545
Train: [50][740/750]	BT 0.038 (1.157)	DT 0.002 (1.112)	loss 6.945 (6.945)	prob 3.216 (3.216)	GS 37.422 (37.422)	mem 36.614
Train: [50][745/750]	BT 0.036 (1.152)	DT 0.001 (1.108)	loss 7.118 (7.118)	prob 2.669 (2.669)	GS 29.406 (29.406)	mem 13.589
Train: [50][750/750]	BT 0.021 (1.145)	DT 0.001 (1.100)	loss 6.736 (6.736)	prob 2.495 (2.495)	GS 35.094 (35.094)	mem 13.553
Train: [50][755/750]	BT 0.043 (1.142)	DT 0.004 (1.097)	loss 6.916 (6.916)	prob 3.100 (3.100)	GS 26.969 (26.969)	mem 10.566
epoch 50, total time 862.39
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [51][1/750]	BT 20.437 (20.437)	DT 20.333 (20.333)	loss 6.587 (6.587)	prob 2.622 (2.622)	GS 36.438 (36.438)	mem 39.195
Train: [51][5/750]	BT 0.030 (5.237)	DT 0.001 (5.194)	loss 6.729 (6.729)	prob 2.364 (2.364)	GS 32.672 (32.672)	mem 39.240
Train: [51][10/750]	BT 0.032 (2.657)	DT 0.001 (2.601)	loss 6.986 (6.986)	prob 3.429 (3.429)	GS 34.500 (34.500)	mem 39.233
Train: [51][15/750]	BT 0.035 (2.897)	DT 0.001 (2.843)	loss 6.764 (6.764)	prob 3.191 (3.191)	GS 26.875 (26.875)	mem 39.410
Train: [51][20/750]	BT 0.036 (2.185)	DT 0.001 (2.133)	loss 7.105 (7.105)	prob 3.304 (3.304)	GS 31.078 (31.078)	mem 39.321
Train: [51][25/750]	BT 0.078 (1.760)	DT 0.009 (1.707)	loss 6.987 (6.987)	prob 2.572 (2.572)	GS 30.094 (30.094)	mem 39.397
Train: [51][30/750]	BT 0.054 (1.890)	DT 0.011 (1.835)	loss 7.085 (7.085)	prob 2.839 (2.839)	GS 30.797 (30.797)	mem 39.477
Train: [51][35/750]	BT 0.040 (1.626)	DT 0.011 (1.574)	loss 6.827 (6.827)	prob 3.291 (3.291)	GS 32.062 (32.062)	mem 39.480
Train: [51][40/750]	BT 0.022 (1.787)	DT 0.001 (1.735)	loss 6.975 (6.975)	prob 3.395 (3.395)	GS 34.672 (34.672)	mem 39.563
Train: [51][45/750]	BT 0.047 (1.594)	DT 0.006 (1.543)	loss 7.082 (7.082)	prob 2.899 (2.899)	GS 31.469 (31.469)	mem 39.565
Train: [51][50/750]	BT 13.437 (1.707)	DT 13.413 (1.657)	loss 7.128 (7.128)	prob 2.717 (2.717)	GS 35.266 (35.266)	mem 39.631
Train: [51][55/750]	BT 0.049 (1.556)	DT 0.001 (1.507)	loss 6.945 (6.945)	prob 3.105 (3.105)	GS 32.625 (32.625)	mem 39.634
Train: [51][60/750]	BT 0.065 (1.431)	DT 0.001 (1.382)	loss 7.287 (7.287)	prob 2.802 (2.802)	GS 36.500 (36.500)	mem 39.669
Train: [51][65/750]	BT 0.030 (1.514)	DT 0.001 (1.466)	loss 6.647 (6.647)	prob 3.194 (3.194)	GS 29.734 (29.734)	mem 39.596
Train: [51][70/750]	BT 0.061 (1.409)	DT 0.001 (1.362)	loss 6.959 (6.959)	prob 2.419 (2.419)	GS 31.234 (31.234)	mem 39.596
Train: [51][75/750]	BT 0.036 (1.493)	DT 0.006 (1.446)	loss 7.125 (7.125)	prob 2.956 (2.956)	GS 35.547 (35.547)	mem 39.700
Train: [51][80/750]	BT 0.032 (1.403)	DT 0.001 (1.355)	loss 6.852 (6.852)	prob 2.916 (2.916)	GS 34.750 (34.750)	mem 39.649
Train: [51][85/750]	BT 0.042 (1.324)	DT 0.001 (1.276)	loss 6.733 (6.733)	prob 3.097 (3.097)	GS 31.422 (31.422)	mem 39.649
Train: [51][90/750]	BT 0.037 (1.390)	DT 0.001 (1.342)	loss 7.487 (7.487)	prob 2.869 (2.869)	GS 31.891 (31.891)	mem 39.650
Train: [51][95/750]	BT 0.033 (1.320)	DT 0.002 (1.271)	loss 7.219 (7.219)	prob 2.483 (2.483)	GS 29.703 (29.703)	mem 39.652
Train: [51][100/750]	BT 0.028 (1.429)	DT 0.001 (1.382)	loss 7.110 (7.110)	prob 2.686 (2.686)	GS 34.125 (34.125)	mem 39.727
Train: [51][105/750]	BT 0.053 (1.364)	DT 0.010 (1.316)	loss 7.028 (7.028)	prob 2.912 (2.912)	GS 31.156 (31.156)	mem 39.726
Train: [51][110/750]	BT 10.010 (1.395)	DT 9.978 (1.347)	loss 6.975 (6.975)	prob 2.362 (2.362)	GS 29.219 (29.219)	mem 39.758
Train: [51][115/750]	BT 0.049 (1.336)	DT 0.009 (1.289)	loss 6.747 (6.747)	prob 2.671 (2.671)	GS 34.094 (34.094)	mem 39.757
Train: [51][120/750]	BT 0.106 (1.283)	DT 0.028 (1.235)	loss 7.189 (7.189)	prob 2.691 (2.691)	GS 35.078 (35.078)	mem 39.757
Train: [51][125/750]	BT 0.038 (1.335)	DT 0.002 (1.288)	loss 7.094 (7.094)	prob 2.277 (2.277)	GS 30.000 (30.000)	mem 39.932
Train: [51][130/750]	BT 0.060 (1.285)	DT 0.002 (1.238)	loss 7.173 (7.173)	prob 2.009 (2.009)	GS 35.219 (35.219)	mem 39.831
Train: [51][135/750]	BT 0.044 (1.342)	DT 0.017 (1.295)	loss 7.293 (7.293)	prob 1.646 (1.646)	GS 32.219 (32.219)	mem 39.830
Train: [51][140/750]	BT 0.048 (1.296)	DT 0.001 (1.249)	loss 7.184 (7.184)	prob 2.929 (2.929)	GS 29.406 (29.406)	mem 39.832
Train: [51][145/750]	BT 0.043 (1.253)	DT 0.014 (1.206)	loss 6.956 (6.956)	prob 2.815 (2.815)	GS 32.328 (32.328)	mem 39.832
Train: [51][150/750]	BT 0.030 (1.296)	DT 0.001 (1.250)	loss 7.948 (7.948)	prob 1.471 (1.471)	GS 30.359 (30.359)	mem 39.804
Train: [51][155/750]	BT 0.034 (1.256)	DT 0.002 (1.210)	loss 7.151 (7.151)	prob 2.053 (2.053)	GS 31.188 (31.188)	mem 39.851
Train: [51][160/750]	BT 0.023 (1.291)	DT 0.001 (1.245)	loss 7.131 (7.131)	prob 2.762 (2.762)	GS 30.672 (30.672)	mem 39.857
Train: [51][165/750]	BT 0.053 (1.254)	DT 0.002 (1.207)	loss 7.216 (7.216)	prob 1.610 (1.610)	GS 28.500 (28.500)	mem 39.927
Train: [51][170/750]	BT 15.534 (1.309)	DT 15.472 (1.263)	loss 7.967 (7.967)	prob 1.895 (1.895)	GS 31.984 (31.984)	mem 39.987
Train: [51][175/750]	BT 0.036 (1.273)	DT 0.001 (1.227)	loss 7.066 (7.066)	prob 2.527 (2.527)	GS 30.609 (30.609)	mem 39.826
Train: [51][180/750]	BT 0.023 (1.239)	DT 0.001 (1.193)	loss 8.290 (8.290)	prob 1.806 (1.806)	GS 33.156 (33.156)	mem 39.834
Train: [51][185/750]	BT 0.043 (1.266)	DT 0.001 (1.220)	loss 7.224 (7.224)	prob 1.097 (1.097)	GS 45.031 (45.031)	mem 39.884
Train: [51][190/750]	BT 0.043 (1.234)	DT 0.001 (1.188)	loss 7.684 (7.684)	prob 2.409 (2.409)	GS 33.953 (33.953)	mem 39.952
Train: [51][195/750]	BT 0.025 (1.278)	DT 0.001 (1.232)	loss 7.624 (7.624)	prob 1.222 (1.222)	GS 29.625 (29.625)	mem 39.945
Train: [51][200/750]	BT 0.033 (1.247)	DT 0.001 (1.201)	loss 7.339 (7.339)	prob 2.210 (2.210)	GS 35.594 (35.594)	mem 39.947
Train: [51][205/750]	BT 0.120 (1.230)	DT 0.001 (1.184)	loss 7.531 (7.531)	prob 1.801 (1.801)	GS 29.469 (29.469)	mem 39.934
Train: [51][210/750]	BT 0.077 (1.250)	DT 0.013 (1.205)	loss 7.113 (7.113)	prob 2.532 (2.532)	GS 31.453 (31.453)	mem 39.926
Train: [51][215/750]	BT 0.026 (1.222)	DT 0.001 (1.177)	loss 7.168 (7.168)	prob 2.106 (2.106)	GS 29.578 (29.578)	mem 39.934
Train: [51][220/750]	BT 0.036 (1.261)	DT 0.002 (1.215)	loss 7.328 (7.328)	prob 2.231 (2.231)	GS 35.312 (35.312)	mem 39.938
Train: [51][225/750]	BT 0.032 (1.234)	DT 0.001 (1.188)	loss 7.175 (7.175)	prob 2.430 (2.430)	GS 33.531 (33.531)	mem 39.809
Train: [51][230/750]	BT 11.897 (1.264)	DT 11.830 (1.218)	loss 7.430 (7.430)	prob 2.224 (2.224)	GS 35.609 (35.609)	mem 40.026
Train: [51][235/750]	BT 0.052 (1.238)	DT 0.006 (1.193)	loss 7.293 (7.293)	prob 2.035 (2.035)	GS 30.219 (30.219)	mem 40.125
Train: [51][240/750]	BT 0.063 (1.215)	DT 0.019 (1.169)	loss 7.294 (7.294)	prob 2.952 (2.952)	GS 35.031 (35.031)	mem 39.835
Train: [51][245/750]	BT 0.061 (1.242)	DT 0.002 (1.196)	loss 6.930 (6.930)	prob 3.721 (3.721)	GS 33.219 (33.219)	mem 39.905
Train: [51][250/750]	BT 0.756 (1.220)	DT 0.654 (1.175)	loss 7.767 (7.767)	prob 1.811 (1.811)	GS 34.875 (34.875)	mem 39.766
Train: [51][255/750]	BT 0.035 (1.238)	DT 0.002 (1.193)	loss 7.122 (7.122)	prob 2.512 (2.512)	GS 30.609 (30.609)	mem 39.970
Train: [51][260/750]	BT 0.027 (1.215)	DT 0.001 (1.170)	loss 7.305 (7.305)	prob 2.878 (2.878)	GS 31.609 (31.609)	mem 39.835
Train: [51][265/750]	BT 0.045 (1.197)	DT 0.013 (1.152)	loss 7.047 (7.047)	prob 2.209 (2.209)	GS 27.344 (27.344)	mem 39.933
Train: [51][270/750]	BT 0.058 (1.213)	DT 0.002 (1.168)	loss 8.225 (8.225)	prob 1.660 (1.660)	GS 32.703 (32.703)	mem 39.967
Train: [51][275/750]	BT 0.033 (1.196)	DT 0.001 (1.151)	loss 7.630 (7.630)	prob 1.975 (1.975)	GS 31.516 (31.516)	mem 39.809
Train: [51][280/750]	BT 0.023 (1.218)	DT 0.001 (1.173)	loss 7.123 (7.123)	prob 2.981 (2.981)	GS 29.891 (29.891)	mem 39.856
Train: [51][285/750]	BT 0.030 (1.198)	DT 0.001 (1.152)	loss 7.505 (7.505)	prob 2.187 (2.187)	GS 33.828 (33.828)	mem 39.855
Train: [51][290/750]	BT 8.705 (1.214)	DT 8.672 (1.169)	loss 7.157 (7.157)	prob 2.504 (2.504)	GS 30.562 (30.562)	mem 39.891
Train: [51][295/750]	BT 0.070 (1.194)	DT 0.002 (1.149)	loss 7.581 (7.581)	prob 1.844 (1.844)	GS 31.453 (31.453)	mem 39.988
Train: [51][300/750]	BT 5.233 (1.199)	DT 5.204 (1.154)	loss 7.934 (7.934)	prob 1.228 (1.228)	GS 37.984 (37.984)	mem 40.020
Train: [51][305/750]	BT 0.060 (1.206)	DT 0.004 (1.161)	loss 7.136 (7.136)	prob 2.316 (2.316)	GS 31.656 (31.656)	mem 39.893
Train: [51][310/750]	BT 0.033 (1.188)	DT 0.001 (1.143)	loss 7.215 (7.215)	prob 2.629 (2.629)	GS 37.219 (37.219)	mem 39.894
Train: [51][315/750]	BT 0.037 (1.210)	DT 0.001 (1.165)	loss 7.100 (7.100)	prob 2.767 (2.767)	GS 30.031 (30.031)	mem 39.895
Train: [51][320/750]	BT 0.069 (1.192)	DT 0.008 (1.147)	loss 7.587 (7.587)	prob 2.220 (2.220)	GS 34.141 (34.141)	mem 39.896
Train: [51][325/750]	BT 0.057 (1.196)	DT 0.010 (1.152)	loss 7.679 (7.679)	prob 1.725 (1.725)	GS 30.984 (30.984)	mem 39.897
Train: [51][330/750]	BT 0.049 (1.199)	DT 0.008 (1.154)	loss 7.253 (7.253)	prob 2.566 (2.566)	GS 31.344 (31.344)	mem 39.841
Train: [51][335/750]	BT 0.059 (1.182)	DT 0.006 (1.137)	loss 7.465 (7.465)	prob 2.371 (2.371)	GS 32.656 (32.656)	mem 39.841
Train: [51][340/750]	BT 0.129 (1.202)	DT 0.001 (1.157)	loss 7.363 (7.363)	prob 2.528 (2.528)	GS 39.797 (39.797)	mem 39.935
Train: [51][345/750]	BT 0.048 (1.185)	DT 0.011 (1.141)	loss 7.137 (7.137)	prob 3.006 (3.006)	GS 32.672 (32.672)	mem 39.913
Train: [51][350/750]	BT 8.427 (1.212)	DT 8.385 (1.167)	loss 7.879 (7.879)	prob 2.658 (2.658)	GS 32.891 (32.891)	mem 40.014
Train: [51][355/750]	BT 0.031 (1.195)	DT 0.001 (1.151)	loss 7.011 (7.011)	prob 2.991 (2.991)	GS 34.141 (34.141)	mem 39.889
Train: [51][360/750]	BT 3.527 (1.189)	DT 3.494 (1.145)	loss 7.087 (7.087)	prob 3.510 (3.510)	GS 32.547 (32.547)	mem 39.868
Train: [51][365/750]	BT 0.043 (1.197)	DT 0.006 (1.152)	loss 7.415 (7.415)	prob 3.016 (3.016)	GS 30.219 (30.219)	mem 39.855
Train: [51][370/750]	BT 0.035 (1.181)	DT 0.001 (1.137)	loss 7.260 (7.260)	prob 2.564 (2.564)	GS 35.719 (35.719)	mem 39.907
Train: [51][375/750]	BT 0.068 (1.204)	DT 0.014 (1.160)	loss 7.549 (7.549)	prob 2.525 (2.525)	GS 31.438 (31.438)	mem 39.804
Train: [51][380/750]	BT 0.049 (1.189)	DT 0.002 (1.144)	loss 7.121 (7.121)	prob 2.752 (2.752)	GS 31.125 (31.125)	mem 39.805
Train: [51][385/750]	BT 0.038 (1.183)	DT 0.005 (1.139)	loss 7.640 (7.640)	prob 1.983 (1.983)	GS 31.016 (31.016)	mem 39.829
Train: [51][390/750]	BT 0.031 (1.187)	DT 0.001 (1.142)	loss 7.780 (7.780)	prob 3.076 (3.076)	GS 33.500 (33.500)	mem 39.856
Train: [51][395/750]	BT 0.045 (1.172)	DT 0.003 (1.128)	loss 7.551 (7.551)	prob 2.568 (2.568)	GS 30.766 (30.766)	mem 39.946
Train: [51][400/750]	BT 0.063 (1.195)	DT 0.013 (1.150)	loss 7.355 (7.355)	prob 3.421 (3.421)	GS 36.406 (36.406)	mem 40.207
Train: [51][405/750]	BT 0.115 (1.181)	DT 0.012 (1.136)	loss 7.358 (7.358)	prob 3.165 (3.165)	GS 29.703 (29.703)	mem 39.942
Train: [51][410/750]	BT 13.367 (1.200)	DT 13.325 (1.155)	loss 7.197 (7.197)	prob 3.126 (3.126)	GS 32.594 (32.594)	mem 39.883
Train: [51][415/750]	BT 0.027 (1.186)	DT 0.001 (1.141)	loss 7.609 (7.609)	prob 2.691 (2.691)	GS 35.484 (35.484)	mem 39.885
Train: [51][420/750]	BT 0.031 (1.172)	DT 0.001 (1.128)	loss 7.506 (7.506)	prob 2.673 (2.673)	GS 34.703 (34.703)	mem 40.015
Train: [51][425/750]	BT 0.050 (1.184)	DT 0.006 (1.139)	loss 7.458 (7.458)	prob 2.493 (2.493)	GS 33.266 (33.266)	mem 39.957
Train: [51][430/750]	BT 0.082 (1.171)	DT 0.002 (1.126)	loss 7.247 (7.247)	prob 2.784 (2.784)	GS 32.297 (32.297)	mem 40.096
Train: [51][435/750]	BT 0.060 (1.185)	DT 0.021 (1.140)	loss 7.705 (7.705)	prob 2.604 (2.604)	GS 32.641 (32.641)	mem 39.886
Train: [51][440/750]	BT 0.030 (1.172)	DT 0.001 (1.127)	loss 7.320 (7.320)	prob 2.540 (2.540)	GS 34.953 (34.953)	mem 39.887
Train: [51][445/750]	BT 0.031 (1.159)	DT 0.001 (1.115)	loss 7.052 (7.052)	prob 3.269 (3.269)	GS 30.391 (30.391)	mem 39.887
Train: [51][450/750]	BT 0.042 (1.174)	DT 0.008 (1.130)	loss 7.357 (7.357)	prob 3.245 (3.245)	GS 34.109 (34.109)	mem 40.050
Train: [51][455/750]	BT 0.026 (1.162)	DT 0.001 (1.118)	loss 7.586 (7.586)	prob 3.191 (3.191)	GS 31.062 (31.062)	mem 39.876
Train: [51][460/750]	BT 0.106 (1.171)	DT 0.041 (1.127)	loss 7.475 (7.475)	prob 3.439 (3.439)	GS 33.328 (33.328)	mem 40.051
Train: [51][465/750]	BT 0.064 (1.165)	DT 0.011 (1.121)	loss 7.703 (7.703)	prob 2.470 (2.470)	GS 31.391 (31.391)	mem 40.023
Train: [51][470/750]	BT 10.523 (1.176)	DT 10.466 (1.131)	loss 7.318 (7.318)	prob 3.094 (3.094)	GS 33.000 (33.000)	mem 39.944
Train: [51][475/750]	BT 0.041 (1.172)	DT 0.010 (1.127)	loss 7.535 (7.535)	prob 2.757 (2.757)	GS 32.766 (32.766)	mem 39.967
Train: [51][480/750]	BT 0.033 (1.160)	DT 0.001 (1.115)	loss 7.168 (7.168)	prob 3.905 (3.905)	GS 31.438 (31.438)	mem 40.034
Train: [51][485/750]	BT 0.030 (1.167)	DT 0.001 (1.123)	loss 7.252 (7.252)	prob 3.216 (3.216)	GS 30.219 (30.219)	mem 40.146
Train: [51][490/750]	BT 0.040 (1.163)	DT 0.002 (1.119)	loss 7.480 (7.480)	prob 3.421 (3.421)	GS 34.312 (34.312)	mem 39.980
Train: [51][495/750]	BT 0.049 (1.171)	DT 0.008 (1.127)	loss 7.273 (7.273)	prob 2.823 (2.823)	GS 32.281 (32.281)	mem 39.978
Train: [51][500/750]	BT 0.124 (1.160)	DT 0.012 (1.116)	loss 7.707 (7.707)	prob 3.123 (3.123)	GS 29.141 (29.141)	mem 39.979
Train: [51][505/750]	BT 0.066 (1.149)	DT 0.003 (1.105)	loss 7.653 (7.653)	prob 2.524 (2.524)	GS 30.547 (30.547)	mem 40.044
Train: [51][510/750]	BT 0.121 (1.163)	DT 0.008 (1.119)	loss 6.955 (6.955)	prob 3.698 (3.698)	GS 31.750 (31.750)	mem 39.968
Train: [51][515/750]	BT 0.142 (1.152)	DT 0.050 (1.108)	loss 7.308 (7.308)	prob 3.288 (3.288)	GS 28.297 (28.297)	mem 39.958
Train: [51][520/750]	BT 0.029 (1.165)	DT 0.001 (1.121)	loss 7.439 (7.439)	prob 3.527 (3.527)	GS 30.312 (30.312)	mem 39.940
Train: [51][525/750]	BT 0.059 (1.154)	DT 0.026 (1.110)	loss 7.411 (7.411)	prob 2.867 (2.867)	GS 31.766 (31.766)	mem 39.906
Train: [51][530/750]	BT 11.350 (1.165)	DT 11.318 (1.121)	loss 7.273 (7.273)	prob 3.614 (3.614)	GS 31.391 (31.391)	mem 39.952
Train: [51][535/750]	BT 0.024 (1.155)	DT 0.001 (1.111)	loss 7.092 (7.092)	prob 3.497 (3.497)	GS 30.453 (30.453)	mem 39.924
Train: [51][540/750]	BT 0.030 (1.144)	DT 0.001 (1.100)	loss 7.292 (7.292)	prob 3.270 (3.270)	GS 34.875 (34.875)	mem 39.924
Train: [51][545/750]	BT 0.072 (1.160)	DT 0.011 (1.116)	loss 7.711 (7.711)	prob 2.448 (2.448)	GS 26.359 (26.359)	mem 39.962
Train: [51][550/750]	BT 0.034 (1.150)	DT 0.002 (1.106)	loss 7.152 (7.152)	prob 3.614 (3.614)	GS 30.766 (30.766)	mem 39.963
Train: [51][555/750]	BT 0.032 (1.163)	DT 0.002 (1.119)	loss 7.559 (7.559)	prob 2.879 (2.879)	GS 29.328 (29.328)	mem 39.927
Train: [51][560/750]	BT 0.061 (1.153)	DT 0.025 (1.109)	loss 7.408 (7.408)	prob 3.396 (3.396)	GS 34.234 (34.234)	mem 39.927
Train: [51][565/750]	BT 0.055 (1.143)	DT 0.001 (1.099)	loss 7.359 (7.359)	prob 2.569 (2.569)	GS 36.156 (36.156)	mem 39.930
Train: [51][570/750]	BT 0.051 (1.152)	DT 0.009 (1.108)	loss 7.678 (7.678)	prob 3.420 (3.420)	GS 33.484 (33.484)	mem 39.949
Train: [51][575/750]	BT 0.037 (1.143)	DT 0.005 (1.099)	loss 7.360 (7.360)	prob 2.637 (2.637)	GS 30.062 (30.062)	mem 40.057
Train: [51][580/750]	BT 0.030 (1.154)	DT 0.001 (1.110)	loss 7.191 (7.191)	prob 3.652 (3.652)	GS 31.859 (31.859)	mem 39.944
Train: [51][585/750]	BT 0.044 (1.144)	DT 0.001 (1.101)	loss 7.215 (7.215)	prob 3.076 (3.076)	GS 31.984 (31.984)	mem 39.886
Train: [51][590/750]	BT 16.003 (1.162)	DT 15.966 (1.118)	loss 6.944 (6.944)	prob 3.232 (3.232)	GS 33.938 (33.938)	mem 39.960
Train: [51][595/750]	BT 0.025 (1.153)	DT 0.001 (1.109)	loss 7.119 (7.119)	prob 3.142 (3.142)	GS 28.656 (28.656)	mem 40.044
Train: [51][600/750]	BT 0.039 (1.143)	DT 0.002 (1.100)	loss 7.189 (7.189)	prob 3.046 (3.046)	GS 37.047 (37.047)	mem 39.981
Train: [51][605/750]	BT 0.030 (1.159)	DT 0.001 (1.115)	loss 7.297 (7.297)	prob 2.612 (2.612)	GS 35.016 (35.016)	mem 39.943
Train: [51][610/750]	BT 0.032 (1.150)	DT 0.001 (1.106)	loss 7.528 (7.528)	prob 2.767 (2.767)	GS 33.547 (33.547)	mem 39.954
Train: [51][615/750]	BT 0.042 (1.166)	DT 0.001 (1.122)	loss 7.246 (7.246)	prob 2.964 (2.964)	GS 32.516 (32.516)	mem 39.984
Train: [51][620/750]	BT 0.044 (1.157)	DT 0.008 (1.113)	loss 7.450 (7.450)	prob 2.766 (2.766)	GS 32.734 (32.734)	mem 39.942
Train: [51][625/750]	BT 0.122 (1.148)	DT 0.018 (1.104)	loss 7.512 (7.512)	prob 2.438 (2.438)	GS 32.391 (32.391)	mem 39.984
Train: [51][630/750]	BT 0.032 (1.160)	DT 0.001 (1.116)	loss 7.261 (7.261)	prob 3.617 (3.617)	GS 31.234 (31.234)	mem 40.009
Train: [51][635/750]	BT 0.054 (1.151)	DT 0.003 (1.108)	loss 7.389 (7.389)	prob 2.686 (2.686)	GS 28.031 (28.031)	mem 40.011
Train: [51][640/750]	BT 0.034 (1.163)	DT 0.001 (1.119)	loss 7.158 (7.158)	prob 2.482 (2.482)	GS 30.156 (30.156)	mem 40.226
Train: [51][645/750]	BT 0.025 (1.154)	DT 0.001 (1.110)	loss 6.885 (6.885)	prob 3.168 (3.168)	GS 28.312 (28.312)	mem 40.226
Train: [51][650/750]	BT 12.150 (1.164)	DT 12.117 (1.120)	loss 7.193 (7.193)	prob 3.073 (3.073)	GS 33.234 (33.234)	mem 40.123
Train: [51][655/750]	BT 0.030 (1.155)	DT 0.002 (1.112)	loss 7.237 (7.237)	prob 3.110 (3.110)	GS 30.266 (30.266)	mem 39.994
arpack error, retry= 0
Train: [51][660/750]	BT 0.032 (1.147)	DT 0.001 (1.104)	loss 7.141 (7.141)	prob 2.863 (2.863)	GS 29.859 (29.859)	mem 40.023
Train: [51][665/750]	BT 0.022 (1.160)	DT 0.001 (1.116)	loss 6.754 (6.754)	prob 3.300 (3.300)	GS 26.844 (26.844)	mem 39.945
Train: [51][670/750]	BT 0.026 (1.151)	DT 0.001 (1.108)	loss 7.504 (7.504)	prob 2.916 (2.916)	GS 35.797 (35.797)	mem 39.945
Train: [51][675/750]	BT 0.060 (1.161)	DT 0.004 (1.118)	loss 7.174 (7.174)	prob 2.928 (2.928)	GS 32.516 (32.516)	mem 40.076
Train: [51][680/750]	BT 0.036 (1.153)	DT 0.001 (1.109)	loss 7.012 (7.012)	prob 2.859 (2.859)	GS 30.750 (30.750)	mem 40.012
Train: [51][685/750]	BT 0.087 (1.145)	DT 0.029 (1.101)	loss 7.182 (7.182)	prob 2.840 (2.840)	GS 34.500 (34.500)	mem 39.990
Train: [51][690/750]	BT 0.063 (1.155)	DT 0.007 (1.112)	loss 7.171 (7.171)	prob 3.534 (3.534)	GS 36.266 (36.266)	mem 40.084
Train: [51][695/750]	BT 0.049 (1.147)	DT 0.005 (1.104)	loss 7.076 (7.076)	prob 2.715 (2.715)	GS 29.391 (29.391)	mem 40.033
Train: [51][700/750]	BT 0.024 (1.157)	DT 0.001 (1.114)	loss 6.762 (6.762)	prob 3.775 (3.775)	GS 34.047 (34.047)	mem 39.943
Train: [51][705/750]	BT 0.036 (1.149)	DT 0.002 (1.106)	loss 6.977 (6.977)	prob 3.320 (3.320)	GS 32.047 (32.047)	mem 40.025
Train: [51][710/750]	BT 14.644 (1.162)	DT 14.610 (1.119)	loss 7.247 (7.247)	prob 2.718 (2.718)	GS 35.062 (35.062)	mem 39.952
Train: [51][715/750]	BT 0.035 (1.154)	DT 0.001 (1.111)	loss 7.255 (7.255)	prob 2.792 (2.792)	GS 33.031 (33.031)	mem 39.953
Train: [51][720/750]	BT 0.057 (1.146)	DT 0.008 (1.103)	loss 7.322 (7.322)	prob 2.764 (2.764)	GS 35.938 (35.938)	mem 39.954
Train: [51][725/750]	BT 0.037 (1.155)	DT 0.002 (1.112)	loss 7.506 (7.506)	prob 2.450 (2.450)	GS 27.516 (27.516)	mem 39.950
Train: [51][730/750]	BT 0.032 (1.148)	DT 0.001 (1.105)	loss 7.329 (7.329)	prob 2.691 (2.691)	GS 33.406 (33.406)	mem 39.953
Train: [51][735/750]	BT 0.036 (1.152)	DT 0.002 (1.109)	loss 7.549 (7.549)	prob 2.641 (2.641)	GS 34.734 (34.734)	mem 36.693
Train: [51][740/750]	BT 0.034 (1.145)	DT 0.001 (1.101)	loss 6.928 (6.928)	prob 3.383 (3.383)	GS 30.359 (30.359)	mem 36.694
Train: [51][745/750]	BT 0.030 (1.137)	DT 0.001 (1.094)	loss 7.020 (7.020)	prob 2.353 (2.353)	GS 36.688 (36.688)	mem 36.660
Train: [51][750/750]	BT 0.025 (1.134)	DT 0.001 (1.091)	loss 7.194 (7.194)	prob 2.670 (2.670)	GS 27.438 (27.438)	mem 7.522
Train: [51][755/750]	BT 0.050 (1.127)	DT 0.002 (1.084)	loss 7.115 (7.115)	prob 1.899 (1.899)	GS 32.969 (32.969)	mem 7.533
epoch 51, total time 851.24
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [52][1/750]	BT 20.642 (20.642)	DT 20.552 (20.552)	loss 7.432 (7.432)	prob 2.378 (2.378)	GS 29.406 (29.406)	mem 38.477
Train: [52][5/750]	BT 0.037 (5.359)	DT 0.001 (5.313)	loss 6.947 (6.947)	prob 2.790 (2.790)	GS 27.578 (27.578)	mem 38.516
Train: [52][10/750]	BT 0.032 (2.704)	DT 0.001 (2.657)	loss 6.816 (6.816)	prob 2.728 (2.728)	GS 34.766 (34.766)	mem 38.524
Train: [52][15/750]	BT 0.063 (2.260)	DT 0.002 (2.213)	loss 6.937 (6.937)	prob 2.836 (2.836)	GS 30.812 (30.812)	mem 38.811
Train: [52][20/750]	BT 0.039 (2.139)	DT 0.002 (2.094)	loss 6.731 (6.731)	prob 3.442 (3.442)	GS 28.219 (28.219)	mem 38.868
Train: [52][25/750]	BT 0.056 (1.723)	DT 0.001 (1.676)	loss 7.220 (7.220)	prob 2.571 (2.571)	GS 30.766 (30.766)	mem 38.961
Train: [52][30/750]	BT 0.032 (1.916)	DT 0.001 (1.866)	loss 6.840 (6.840)	prob 3.164 (3.164)	GS 35.625 (35.625)	mem 39.066
Train: [52][35/750]	BT 0.033 (1.648)	DT 0.001 (1.600)	loss 7.502 (7.502)	prob 2.157 (2.157)	GS 31.844 (31.844)	mem 39.008
Train: [52][40/750]	BT 13.506 (1.814)	DT 13.453 (1.767)	loss 7.106 (7.106)	prob 3.025 (3.025)	GS 36.047 (36.047)	mem 38.884
Train: [52][45/750]	BT 0.030 (1.616)	DT 0.001 (1.571)	loss 7.338 (7.338)	prob 2.308 (2.308)	GS 31.969 (31.969)	mem 38.904
Train: [52][50/750]	BT 3.049 (1.521)	DT 2.985 (1.474)	loss 7.161 (7.161)	prob 2.965 (2.965)	GS 31.250 (31.250)	mem 38.856
Train: [52][55/750]	BT 0.037 (1.561)	DT 0.008 (1.515)	loss 7.097 (7.097)	prob 2.723 (2.723)	GS 31.719 (31.719)	mem 38.946
Train: [52][60/750]	BT 0.036 (1.434)	DT 0.001 (1.389)	loss 6.880 (6.880)	prob 3.246 (3.246)	GS 27.297 (27.297)	mem 39.001
Train: [52][65/750]	BT 0.108 (1.529)	DT 0.011 (1.484)	loss 7.117 (7.117)	prob 2.702 (2.702)	GS 27.766 (27.766)	mem 39.011
Train: [52][70/750]	BT 0.028 (1.424)	DT 0.001 (1.379)	loss 6.878 (6.878)	prob 2.973 (2.973)	GS 31.750 (31.750)	mem 39.049
Train: [52][75/750]	BT 0.093 (1.456)	DT 0.019 (1.411)	loss 7.233 (7.233)	prob 3.109 (3.109)	GS 29.672 (29.672)	mem 38.978
Train: [52][80/750]	BT 0.077 (1.383)	DT 0.002 (1.337)	loss 7.003 (7.003)	prob 3.413 (3.413)	GS 33.359 (33.359)	mem 39.366
Train: [52][85/750]	BT 0.035 (1.304)	DT 0.002 (1.259)	loss 7.125 (7.125)	prob 3.259 (3.259)	GS 33.953 (33.953)	mem 39.215
Train: [52][90/750]	BT 0.026 (1.408)	DT 0.001 (1.363)	loss 7.050 (7.050)	prob 2.620 (2.620)	GS 33.953 (33.953)	mem 39.069
Train: [52][95/750]	BT 0.047 (1.335)	DT 0.008 (1.292)	loss 7.035 (7.035)	prob 2.851 (2.851)	GS 33.422 (33.422)	mem 39.118
Train: [52][100/750]	BT 7.655 (1.423)	DT 7.618 (1.379)	loss 7.654 (7.654)	prob 2.721 (2.721)	GS 41.141 (41.141)	mem 39.182
Train: [52][105/750]	BT 0.029 (1.357)	DT 0.001 (1.313)	loss 7.024 (7.024)	prob 2.966 (2.966)	GS 28.578 (28.578)	mem 39.094
Train: [52][110/750]	BT 2.516 (1.320)	DT 2.477 (1.276)	loss 6.836 (6.836)	prob 2.924 (2.924)	GS 34.016 (34.016)	mem 39.299
Train: [52][115/750]	BT 0.022 (1.363)	DT 0.001 (1.320)	loss 7.214 (7.214)	prob 2.178 (2.178)	GS 32.672 (32.672)	mem 39.162
Train: [52][120/750]	BT 0.025 (1.308)	DT 0.001 (1.265)	loss 6.715 (6.715)	prob 2.986 (2.986)	GS 36.438 (36.438)	mem 39.162
Train: [52][125/750]	BT 0.029 (1.362)	DT 0.002 (1.319)	loss 7.511 (7.511)	prob 2.571 (2.571)	GS 38.625 (38.625)	mem 39.155
Train: [52][130/750]	BT 0.037 (1.311)	DT 0.001 (1.269)	loss 6.994 (6.994)	prob 2.656 (2.656)	GS 36.625 (36.625)	mem 39.189
Train: [52][135/750]	BT 0.054 (1.264)	DT 0.001 (1.222)	loss 7.108 (7.108)	prob 3.272 (3.272)	GS 30.484 (30.484)	mem 39.204
Train: [52][140/750]	BT 0.031 (1.302)	DT 0.001 (1.259)	loss 6.936 (6.936)	prob 3.308 (3.308)	GS 34.594 (34.594)	mem 39.246
Train: [52][145/750]	BT 0.099 (1.259)	DT 0.012 (1.216)	loss 7.115 (7.115)	prob 2.607 (2.607)	GS 31.250 (31.250)	mem 39.278
Train: [52][150/750]	BT 0.026 (1.314)	DT 0.001 (1.271)	loss 6.931 (6.931)	prob 2.457 (2.457)	GS 28.656 (28.656)	mem 39.226
Train: [52][155/750]	BT 0.106 (1.273)	DT 0.028 (1.230)	loss 7.129 (7.129)	prob 2.427 (2.427)	GS 27.703 (27.703)	mem 39.422
Train: [52][160/750]	BT 9.230 (1.311)	DT 9.205 (1.267)	loss 7.044 (7.044)	prob 2.635 (2.635)	GS 33.031 (33.031)	mem 39.380
Train: [52][165/750]	BT 0.048 (1.272)	DT 0.001 (1.229)	loss 7.177 (7.177)	prob 2.634 (2.634)	GS 33.641 (33.641)	mem 39.623
Train: [52][170/750]	BT 9.098 (1.289)	DT 9.048 (1.246)	loss 6.914 (6.914)	prob 2.457 (2.457)	GS 34.422 (34.422)	mem 39.462
Train: [52][175/750]	BT 0.056 (1.264)	DT 0.001 (1.221)	loss 6.916 (6.916)	prob 2.635 (2.635)	GS 27.688 (27.688)	mem 39.439
Train: [52][180/750]	BT 0.052 (1.259)	DT 0.013 (1.215)	loss 7.092 (7.092)	prob 2.450 (2.450)	GS 36.109 (36.109)	mem 39.461
Train: [52][185/750]	BT 0.036 (1.280)	DT 0.007 (1.236)	loss 6.985 (6.985)	prob 2.854 (2.854)	GS 27.469 (27.469)	mem 39.781
Train: [52][190/750]	BT 2.728 (1.262)	DT 2.683 (1.218)	loss 6.872 (6.872)	prob 2.650 (2.650)	GS 33.516 (33.516)	mem 39.673
Train: [52][195/750]	BT 0.108 (1.267)	DT 0.009 (1.223)	loss 7.140 (7.140)	prob 2.732 (2.732)	GS 33.281 (33.281)	mem 39.742
Train: [52][200/750]	BT 0.035 (1.249)	DT 0.001 (1.205)	loss 7.082 (7.082)	prob 2.496 (2.496)	GS 40.031 (40.031)	mem 39.575
Train: [52][205/750]	BT 0.029 (1.239)	DT 0.001 (1.195)	loss 7.066 (7.066)	prob 2.857 (2.857)	GS 33.797 (33.797)	mem 39.576
Train: [52][210/750]	BT 0.094 (1.251)	DT 0.018 (1.207)	loss 7.210 (7.210)	prob 3.151 (3.151)	GS 30.234 (30.234)	mem 39.479
Train: [52][215/750]	BT 0.033 (1.237)	DT 0.002 (1.193)	loss 7.161 (7.161)	prob 2.350 (2.350)	GS 27.969 (27.969)	mem 39.558
Train: [52][220/750]	BT 5.693 (1.254)	DT 5.662 (1.210)	loss 7.009 (7.009)	prob 2.199 (2.199)	GS 34.203 (34.203)	mem 39.585
Train: [52][225/750]	BT 0.033 (1.227)	DT 0.002 (1.183)	loss 7.297 (7.297)	prob 2.658 (2.658)	GS 29.938 (29.938)	mem 39.621
Train: [52][230/750]	BT 7.936 (1.248)	DT 7.906 (1.204)	loss 6.766 (6.766)	prob 3.490 (3.490)	GS 38.125 (38.125)	mem 39.520
Train: [52][235/750]	BT 0.038 (1.231)	DT 0.001 (1.188)	loss 7.206 (7.206)	prob 2.784 (2.784)	GS 33.234 (33.234)	mem 39.486
Train: [52][240/750]	BT 0.037 (1.214)	DT 0.002 (1.171)	loss 6.839 (6.839)	prob 2.866 (2.866)	GS 34.578 (34.578)	mem 39.518
Train: [52][245/750]	BT 0.095 (1.254)	DT 0.002 (1.211)	loss 7.174 (7.174)	prob 2.530 (2.530)	GS 37.656 (37.656)	mem 39.704
Train: [52][250/750]	BT 0.236 (1.231)	DT 0.204 (1.188)	loss 6.843 (6.843)	prob 3.288 (3.288)	GS 34.672 (34.672)	mem 39.744
Train: [52][255/750]	BT 0.050 (1.224)	DT 0.003 (1.180)	loss 7.238 (7.238)	prob 2.204 (2.204)	GS 29.031 (29.031)	mem 39.758
Train: [52][260/750]	BT 0.026 (1.226)	DT 0.001 (1.183)	loss 6.876 (6.876)	prob 2.958 (2.958)	GS 36.078 (36.078)	mem 39.860
Train: [52][265/750]	BT 0.041 (1.207)	DT 0.003 (1.164)	loss 6.896 (6.896)	prob 2.699 (2.699)	GS 31.969 (31.969)	mem 39.872
Train: [52][270/750]	BT 0.049 (1.221)	DT 0.012 (1.177)	loss 7.087 (7.087)	prob 2.635 (2.635)	GS 28.531 (28.531)	mem 40.014
Train: [52][275/750]	BT 0.091 (1.204)	DT 0.004 (1.160)	loss 6.858 (6.858)	prob 2.478 (2.478)	GS 29.203 (29.203)	mem 39.823
Train: [52][280/750]	BT 1.088 (1.223)	DT 1.047 (1.179)	loss 7.001 (7.001)	prob 2.723 (2.723)	GS 36.344 (36.344)	mem 39.824
Train: [52][285/750]	BT 0.060 (1.212)	DT 0.005 (1.168)	loss 6.783 (6.783)	prob 3.337 (3.337)	GS 29.031 (29.031)	mem 39.764
Train: [52][290/750]	BT 6.789 (1.216)	DT 6.746 (1.171)	loss 6.790 (6.790)	prob 2.864 (2.864)	GS 34.766 (34.766)	mem 39.859
Train: [52][295/750]	BT 0.041 (1.201)	DT 0.010 (1.156)	loss 6.948 (6.948)	prob 2.407 (2.407)	GS 30.578 (30.578)	mem 39.885
Train: [52][300/750]	BT 0.032 (1.202)	DT 0.001 (1.158)	loss 6.784 (6.784)	prob 2.977 (2.977)	GS 33.891 (33.891)	mem 39.933
Train: [52][305/750]	BT 0.065 (1.205)	DT 0.009 (1.161)	loss 7.131 (7.131)	prob 2.398 (2.398)	GS 32.016 (32.016)	mem 39.915
Train: [52][310/750]	BT 0.040 (1.206)	DT 0.004 (1.162)	loss 6.799 (6.799)	prob 2.986 (2.986)	GS 32.750 (32.750)	mem 40.156
Train: [52][315/750]	BT 0.108 (1.217)	DT 0.001 (1.173)	loss 6.972 (6.972)	prob 2.441 (2.441)	GS 30.188 (30.188)	mem 39.982
Train: [52][320/750]	BT 4.982 (1.215)	DT 4.956 (1.170)	loss 6.865 (6.865)	prob 3.118 (3.118)	GS 33.734 (33.734)	mem 39.933
Train: [52][325/750]	BT 0.053 (1.197)	DT 0.009 (1.152)	loss 7.284 (7.284)	prob 2.843 (2.843)	GS 33.422 (33.422)	mem 39.933
Train: [52][330/750]	BT 0.042 (1.202)	DT 0.002 (1.157)	loss 6.890 (6.890)	prob 2.641 (2.641)	GS 30.141 (30.141)	mem 39.961
Train: [52][335/750]	BT 0.098 (1.198)	DT 0.001 (1.153)	loss 6.944 (6.944)	prob 2.915 (2.915)	GS 26.484 (26.484)	mem 40.182
Train: [52][340/750]	BT 0.023 (1.215)	DT 0.001 (1.170)	loss 6.867 (6.867)	prob 2.378 (2.378)	GS 37.844 (37.844)	mem 39.949
Train: [52][345/750]	BT 0.031 (1.198)	DT 0.001 (1.153)	loss 7.035 (7.035)	prob 2.861 (2.861)	GS 36.422 (36.422)	mem 39.975
Train: [52][350/750]	BT 12.861 (1.218)	DT 12.828 (1.173)	loss 7.122 (7.122)	prob 2.334 (2.334)	GS 33.359 (33.359)	mem 40.015
Train: [52][355/750]	BT 0.030 (1.202)	DT 0.001 (1.157)	loss 7.114 (7.114)	prob 2.841 (2.841)	GS 27.172 (27.172)	mem 40.017
Train: [52][360/750]	BT 0.050 (1.185)	DT 0.011 (1.141)	loss 6.979 (6.979)	prob 3.031 (3.031)	GS 31.766 (31.766)	mem 40.019
Train: [52][365/750]	BT 0.028 (1.203)	DT 0.001 (1.159)	loss 6.917 (6.917)	prob 2.518 (2.518)	GS 27.312 (27.312)	mem 40.037
Train: [52][370/750]	BT 0.031 (1.187)	DT 0.001 (1.143)	loss 7.097 (7.097)	prob 2.767 (2.767)	GS 32.703 (32.703)	mem 40.037
Train: [52][375/750]	BT 0.030 (1.206)	DT 0.001 (1.161)	loss 7.074 (7.074)	prob 3.001 (3.001)	GS 30.031 (30.031)	mem 40.038
Train: [52][380/750]	BT 0.039 (1.191)	DT 0.003 (1.146)	loss 7.151 (7.151)	prob 2.456 (2.456)	GS 37.094 (37.094)	mem 40.042
Train: [52][385/750]	BT 0.033 (1.176)	DT 0.002 (1.131)	loss 7.267 (7.267)	prob 2.683 (2.683)	GS 31.688 (31.688)	mem 40.044
Train: [52][390/750]	BT 0.031 (1.193)	DT 0.001 (1.149)	loss 7.143 (7.143)	prob 2.754 (2.754)	GS 34.688 (34.688)	mem 39.906
Train: [52][395/750]	BT 0.041 (1.179)	DT 0.017 (1.134)	loss 6.930 (6.930)	prob 2.925 (2.925)	GS 32.266 (32.266)	mem 39.905
Train: [52][400/750]	BT 0.022 (1.192)	DT 0.001 (1.148)	loss 6.787 (6.787)	prob 3.018 (3.018)	GS 35.047 (35.047)	mem 39.952
Train: [52][405/750]	BT 0.034 (1.177)	DT 0.001 (1.134)	loss 6.913 (6.913)	prob 2.633 (2.633)	GS 30.422 (30.422)	mem 39.952
Train: [52][410/750]	BT 13.792 (1.197)	DT 13.744 (1.153)	loss 6.894 (6.894)	prob 2.693 (2.693)	GS 34.109 (34.109)	mem 40.000
Train: [52][415/750]	BT 0.028 (1.183)	DT 0.001 (1.139)	loss 6.849 (6.849)	prob 2.098 (2.098)	GS 28.109 (28.109)	mem 40.000
Train: [52][420/750]	BT 0.062 (1.170)	DT 0.012 (1.126)	loss 6.729 (6.729)	prob 2.570 (2.570)	GS 32.906 (32.906)	mem 40.000
Train: [52][425/750]	BT 0.032 (1.183)	DT 0.002 (1.139)	loss 6.915 (6.915)	prob 2.591 (2.591)	GS 28.828 (28.828)	mem 39.951
Train: [52][430/750]	BT 0.034 (1.170)	DT 0.002 (1.126)	loss 6.845 (6.845)	prob 2.452 (2.452)	GS 37.000 (37.000)	mem 40.037
Train: [52][435/750]	BT 0.025 (1.186)	DT 0.001 (1.142)	loss 7.141 (7.141)	prob 2.582 (2.582)	GS 34.078 (34.078)	mem 40.005
Train: [52][440/750]	BT 0.030 (1.172)	DT 0.001 (1.129)	loss 6.872 (6.872)	prob 1.995 (1.995)	GS 35.109 (35.109)	mem 40.046
Train: [52][445/750]	BT 0.115 (1.160)	DT 0.024 (1.117)	loss 6.885 (6.885)	prob 2.610 (2.610)	GS 34.891 (34.891)	mem 40.009
Train: [52][450/750]	BT 0.105 (1.177)	DT 0.001 (1.134)	loss 6.923 (6.923)	prob 2.416 (2.416)	GS 30.547 (30.547)	mem 40.008
Train: [52][455/750]	BT 0.025 (1.165)	DT 0.001 (1.121)	loss 7.039 (7.039)	prob 2.680 (2.680)	GS 30.453 (30.453)	mem 39.970
Train: [52][460/750]	BT 0.038 (1.182)	DT 0.008 (1.139)	loss 6.798 (6.798)	prob 2.634 (2.634)	GS 30.375 (30.375)	mem 40.101
Train: [52][465/750]	BT 0.031 (1.170)	DT 0.001 (1.127)	loss 7.009 (7.009)	prob 2.052 (2.052)	GS 29.312 (29.312)	mem 39.983
Train: [52][470/750]	BT 13.201 (1.186)	DT 13.152 (1.143)	loss 6.797 (6.797)	prob 1.834 (1.834)	GS 33.359 (33.359)	mem 40.135
Train: [52][475/750]	BT 0.027 (1.174)	DT 0.001 (1.131)	loss 6.972 (6.972)	prob 2.617 (2.617)	GS 30.203 (30.203)	mem 39.982
Train: [52][480/750]	BT 0.026 (1.162)	DT 0.001 (1.119)	loss 6.871 (6.871)	prob 2.379 (2.379)	GS 32.859 (32.859)	mem 39.992
Train: [52][485/750]	BT 0.040 (1.180)	DT 0.003 (1.137)	loss 6.968 (6.968)	prob 2.745 (2.745)	GS 34.391 (34.391)	mem 40.000
Train: [52][490/750]	BT 0.036 (1.169)	DT 0.006 (1.126)	loss 6.809 (6.809)	prob 3.019 (3.019)	GS 36.625 (36.625)	mem 40.000
Train: [52][495/750]	BT 0.031 (1.179)	DT 0.001 (1.136)	loss 6.922 (6.922)	prob 3.126 (3.126)	GS 30.406 (30.406)	mem 39.991
Train: [52][500/750]	BT 0.047 (1.168)	DT 0.017 (1.125)	loss 7.113 (7.113)	prob 1.983 (1.983)	GS 37.797 (37.797)	mem 39.940
Train: [52][505/750]	BT 0.034 (1.156)	DT 0.001 (1.114)	loss 7.145 (7.145)	prob 2.858 (2.858)	GS 29.875 (29.875)	mem 39.940
Train: [52][510/750]	BT 0.046 (1.168)	DT 0.006 (1.125)	loss 7.087 (7.087)	prob 2.418 (2.418)	GS 32.438 (32.438)	mem 39.999
Train: [52][515/750]	BT 0.040 (1.157)	DT 0.001 (1.114)	loss 6.900 (6.900)	prob 2.266 (2.266)	GS 26.375 (26.375)	mem 40.000
Train: [52][520/750]	BT 0.020 (1.172)	DT 0.001 (1.129)	loss 6.810 (6.810)	prob 2.872 (2.872)	GS 33.922 (33.922)	mem 40.037
Train: [52][525/750]	BT 0.089 (1.161)	DT 0.010 (1.119)	loss 7.083 (7.083)	prob 2.779 (2.779)	GS 31.391 (31.391)	mem 40.037
Train: [52][530/750]	BT 12.911 (1.175)	DT 12.878 (1.132)	loss 6.915 (6.915)	prob 2.102 (2.102)	GS 34.234 (34.234)	mem 39.940
Train: [52][535/750]	BT 0.060 (1.165)	DT 0.012 (1.122)	loss 6.778 (6.778)	prob 3.095 (3.095)	GS 29.625 (29.625)	mem 39.883
Train: [52][540/750]	BT 0.033 (1.154)	DT 0.004 (1.112)	loss 6.870 (6.870)	prob 2.495 (2.495)	GS 32.156 (32.156)	mem 39.886
Train: [52][545/750]	BT 0.028 (1.168)	DT 0.001 (1.125)	loss 6.975 (6.975)	prob 2.258 (2.258)	GS 33.266 (33.266)	mem 39.936
Train: [52][550/750]	BT 0.036 (1.158)	DT 0.005 (1.115)	loss 6.856 (6.856)	prob 2.360 (2.360)	GS 33.938 (33.938)	mem 39.936
Train: [52][555/750]	BT 0.054 (1.171)	DT 0.001 (1.128)	loss 6.866 (6.866)	prob 2.919 (2.919)	GS 29.156 (29.156)	mem 40.007
Train: [52][560/750]	BT 0.030 (1.161)	DT 0.001 (1.118)	loss 6.705 (6.705)	prob 2.848 (2.848)	GS 34.484 (34.484)	mem 39.910
Train: [52][565/750]	BT 0.039 (1.151)	DT 0.001 (1.108)	loss 6.611 (6.611)	prob 2.405 (2.405)	GS 32.094 (32.094)	mem 39.923
Train: [52][570/750]	BT 0.063 (1.162)	DT 0.004 (1.120)	loss 6.897 (6.897)	prob 2.532 (2.532)	GS 35.766 (35.766)	mem 39.936
Train: [52][575/750]	BT 0.032 (1.152)	DT 0.002 (1.110)	loss 7.119 (7.119)	prob 1.740 (1.740)	GS 31.297 (31.297)	mem 39.966
Train: [52][580/750]	BT 0.069 (1.167)	DT 0.007 (1.124)	loss 6.605 (6.605)	prob 2.862 (2.862)	GS 35.984 (35.984)	mem 39.970
Train: [52][585/750]	BT 0.034 (1.158)	DT 0.001 (1.115)	loss 6.668 (6.668)	prob 2.609 (2.609)	GS 28.875 (28.875)	mem 39.969
Train: [52][590/750]	BT 13.770 (1.171)	DT 13.738 (1.129)	loss 6.801 (6.801)	prob 2.824 (2.824)	GS 36.422 (36.422)	mem 40.011
Train: [52][595/750]	BT 0.024 (1.162)	DT 0.001 (1.119)	loss 6.895 (6.895)	prob 2.177 (2.177)	GS 30.359 (30.359)	mem 39.935
Train: [52][600/750]	BT 0.038 (1.153)	DT 0.002 (1.110)	loss 6.786 (6.786)	prob 2.412 (2.412)	GS 35.625 (35.625)	mem 39.934
Train: [52][605/750]	BT 0.041 (1.171)	DT 0.003 (1.129)	loss 6.994 (6.994)	prob 2.013 (2.013)	GS 31.953 (31.953)	mem 39.861
Train: [52][610/750]	BT 0.037 (1.162)	DT 0.001 (1.119)	loss 6.894 (6.894)	prob 2.174 (2.174)	GS 37.172 (37.172)	mem 39.861
Train: [52][615/750]	BT 0.033 (1.170)	DT 0.001 (1.128)	loss 6.724 (6.724)	prob 2.946 (2.946)	GS 31.422 (31.422)	mem 39.950
Train: [52][620/750]	BT 0.025 (1.161)	DT 0.001 (1.118)	loss 6.705 (6.705)	prob 3.258 (3.258)	GS 37.359 (37.359)	mem 39.950
Train: [52][625/750]	BT 0.060 (1.152)	DT 0.006 (1.110)	loss 7.393 (7.393)	prob 1.636 (1.636)	GS 34.016 (34.016)	mem 39.950
Train: [52][630/750]	BT 0.032 (1.164)	DT 0.002 (1.122)	loss 7.014 (7.014)	prob 2.713 (2.713)	GS 33.031 (33.031)	mem 40.027
Train: [52][635/750]	BT 0.048 (1.155)	DT 0.001 (1.113)	loss 6.792 (6.792)	prob 2.607 (2.607)	GS 32.984 (32.984)	mem 39.968
Train: [52][640/750]	BT 0.040 (1.166)	DT 0.013 (1.124)	loss 6.869 (6.869)	prob 2.451 (2.451)	GS 34.078 (34.078)	mem 40.151
Train: [52][645/750]	BT 0.053 (1.157)	DT 0.012 (1.115)	loss 6.740 (6.740)	prob 2.810 (2.810)	GS 32.250 (32.250)	mem 40.017
Train: [52][650/750]	BT 12.005 (1.167)	DT 11.973 (1.125)	loss 7.086 (7.086)	prob 2.687 (2.687)	GS 33.016 (33.016)	mem 40.087
Train: [52][655/750]	BT 0.037 (1.158)	DT 0.003 (1.116)	loss 6.929 (6.929)	prob 2.546 (2.546)	GS 36.672 (36.672)	mem 40.038
arpack error, retry= 0
arpack error, retry= 0
arpack error, retry= 0
arpack error, retry= 0
arpack error, retry= 0
Train: [52][660/750]	BT 0.057 (1.150)	DT 0.007 (1.108)	loss 6.817 (6.817)	prob 2.125 (2.125)	GS 30.844 (30.844)	mem 39.972
Train: [52][665/750]	BT 0.038 (1.163)	DT 0.001 (1.121)	loss 6.974 (6.974)	prob 3.168 (3.168)	GS 32.031 (32.031)	mem 39.995
Train: [52][670/750]	BT 0.031 (1.154)	DT 0.001 (1.112)	loss 6.811 (6.811)	prob 2.949 (2.949)	GS 35.953 (35.953)	mem 39.995
Train: [52][675/750]	BT 0.025 (1.166)	DT 0.001 (1.124)	loss 6.859 (6.859)	prob 2.996 (2.996)	GS 30.391 (30.391)	mem 40.007
Train: [52][680/750]	BT 0.053 (1.158)	DT 0.001 (1.116)	loss 6.910 (6.910)	prob 2.139 (2.139)	GS 35.312 (35.312)	mem 40.007
Train: [52][685/750]	BT 0.029 (1.150)	DT 0.001 (1.108)	loss 6.718 (6.718)	prob 2.301 (2.301)	GS 29.406 (29.406)	mem 40.065
Train: [52][690/750]	BT 0.021 (1.157)	DT 0.001 (1.116)	loss 6.939 (6.939)	prob 1.488 (1.488)	GS 31.172 (31.172)	mem 40.023
Train: [52][695/750]	BT 0.032 (1.149)	DT 0.001 (1.108)	loss 7.015 (7.015)	prob 2.469 (2.469)	GS 30.438 (30.438)	mem 40.053
Train: [52][700/750]	BT 0.031 (1.160)	DT 0.001 (1.118)	loss 6.944 (6.944)	prob 2.790 (2.790)	GS 34.359 (34.359)	mem 39.955
Train: [52][705/750]	BT 0.080 (1.152)	DT 0.015 (1.110)	loss 7.131 (7.131)	prob 2.432 (2.432)	GS 31.516 (31.516)	mem 40.135
Train: [52][710/750]	BT 10.035 (1.158)	DT 9.905 (1.116)	loss 6.745 (6.745)	prob 3.499 (3.499)	GS 32.766 (32.766)	mem 40.021
Train: [52][715/750]	BT 0.033 (1.150)	DT 0.001 (1.108)	loss 7.020 (7.020)	prob 2.647 (2.647)	GS 32.109 (32.109)	mem 39.971
Train: [52][720/750]	BT 0.088 (1.143)	DT 0.004 (1.100)	loss 6.785 (6.785)	prob 2.551 (2.551)	GS 34.406 (34.406)	mem 40.003
Train: [52][725/750]	BT 0.066 (1.151)	DT 0.012 (1.109)	loss 6.871 (6.871)	prob 3.165 (3.165)	GS 29.297 (29.297)	mem 39.847
Train: [52][730/750]	BT 1.395 (1.146)	DT 1.368 (1.103)	loss 6.763 (6.763)	prob 2.510 (2.510)	GS 32.438 (32.438)	mem 39.961
Train: [52][735/750]	BT 0.031 (1.148)	DT 0.001 (1.106)	loss 6.917 (6.917)	prob 2.743 (2.743)	GS 28.047 (28.047)	mem 36.691
Train: [52][740/750]	BT 0.265 (1.141)	DT 0.227 (1.099)	loss 6.907 (6.907)	prob 2.310 (2.310)	GS 38.438 (38.438)	mem 35.067
Train: [52][745/750]	BT 0.028 (1.136)	DT 0.001 (1.093)	loss 7.145 (7.145)	prob 1.989 (1.989)	GS 32.094 (32.094)	mem 16.606
Train: [52][750/750]	BT 0.037 (1.133)	DT 0.007 (1.091)	loss 7.055 (7.055)	prob 2.330 (2.330)	GS 36.906 (36.906)	mem 10.516
Train: [52][755/750]	BT 0.024 (1.126)	DT 0.001 (1.084)	loss 6.887 (6.887)	prob 2.441 (2.441)	GS 34.906 (34.906)	mem 7.524
epoch 52, total time 850.64
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [53][1/750]	BT 20.980 (20.980)	DT 20.898 (20.898)	loss 7.196 (7.196)	prob 2.623 (2.623)	GS 29.688 (29.688)	mem 38.688
Train: [53][5/750]	BT 0.049 (5.081)	DT 0.012 (5.033)	loss 6.541 (6.541)	prob 3.509 (3.509)	GS 35.188 (35.188)	mem 38.720
Train: [53][10/750]	BT 0.031 (2.672)	DT 0.001 (2.627)	loss 6.923 (6.923)	prob 3.283 (3.283)	GS 32.250 (32.250)	mem 38.630
Train: [53][15/750]	BT 0.086 (2.439)	DT 0.012 (2.393)	loss 6.962 (6.962)	prob 2.507 (2.507)	GS 31.703 (31.703)	mem 38.735
Train: [53][20/750]	BT 0.040 (2.069)	DT 0.001 (2.026)	loss 6.593 (6.593)	prob 2.357 (2.357)	GS 29.922 (29.922)	mem 38.776
Train: [53][25/750]	BT 2.348 (1.754)	DT 2.317 (1.714)	loss 6.712 (6.712)	prob 2.773 (2.773)	GS 29.344 (29.344)	mem 38.782
Train: [53][30/750]	BT 1.927 (1.731)	DT 1.896 (1.690)	loss 6.839 (6.839)	prob 2.703 (2.703)	GS 29.547 (29.547)	mem 38.830
Train: [53][35/750]	BT 0.031 (1.488)	DT 0.001 (1.448)	loss 6.741 (6.741)	prob 2.710 (2.710)	GS 28.891 (28.891)	mem 38.829
Train: [53][40/750]	BT 0.097 (1.582)	DT 0.031 (1.541)	loss 6.886 (6.886)	prob 2.918 (2.918)	GS 34.734 (34.734)	mem 39.131
Train: [53][45/750]	BT 0.062 (1.499)	DT 0.001 (1.458)	loss 6.898 (6.898)	prob 2.116 (2.116)	GS 27.750 (27.750)	mem 39.011
Train: [53][50/750]	BT 6.747 (1.490)	DT 6.707 (1.447)	loss 6.789 (6.789)	prob 2.292 (2.292)	GS 31.500 (31.500)	mem 39.050
Train: [53][55/750]	BT 0.031 (1.427)	DT 0.001 (1.383)	loss 7.186 (7.186)	prob 2.250 (2.250)	GS 28.047 (28.047)	mem 38.988
Train: [53][60/750]	BT 0.059 (1.339)	DT 0.005 (1.295)	loss 6.948 (6.948)	prob 2.684 (2.684)	GS 35.547 (35.547)	mem 38.985
Train: [53][65/750]	BT 0.040 (1.386)	DT 0.002 (1.342)	loss 6.977 (6.977)	prob 2.309 (2.309)	GS 31.375 (31.375)	mem 39.369
Train: [53][70/750]	BT 11.173 (1.473)	DT 11.136 (1.427)	loss 6.880 (6.880)	prob 2.005 (2.005)	GS 37.219 (37.219)	mem 39.049
Train: [53][75/750]	BT 0.037 (1.378)	DT 0.006 (1.332)	loss 7.144 (7.144)	prob 1.477 (1.477)	GS 32.953 (32.953)	mem 39.077
Train: [53][80/750]	BT 0.024 (1.294)	DT 0.001 (1.249)	loss 6.822 (6.822)	prob 2.846 (2.846)	GS 34.844 (34.844)	mem 39.056
Train: [53][85/750]	BT 0.092 (1.367)	DT 0.013 (1.321)	loss 6.874 (6.874)	prob 3.054 (3.054)	GS 34.672 (34.672)	mem 39.141
Train: [53][90/750]	BT 0.025 (1.293)	DT 0.001 (1.248)	loss 6.850 (6.850)	prob 2.591 (2.591)	GS 34.938 (34.938)	mem 39.143
Train: [53][95/750]	BT 0.032 (1.343)	DT 0.001 (1.298)	loss 6.949 (6.949)	prob 2.741 (2.741)	GS 34.109 (34.109)	mem 39.176
Train: [53][100/750]	BT 6.838 (1.347)	DT 6.799 (1.302)	loss 7.037 (7.037)	prob 2.049 (2.049)	GS 39.984 (39.984)	mem 39.228
Train: [53][105/750]	BT 0.045 (1.286)	DT 0.006 (1.241)	loss 6.911 (6.911)	prob 2.697 (2.697)	GS 26.812 (26.812)	mem 39.195
Train: [53][110/750]	BT 0.034 (1.291)	DT 0.001 (1.245)	loss 7.049 (7.049)	prob 2.832 (2.832)	GS 33.422 (33.422)	mem 39.197
Train: [53][115/750]	BT 0.032 (1.284)	DT 0.001 (1.239)	loss 7.048 (7.048)	prob 2.493 (2.493)	GS 35.047 (35.047)	mem 39.212
Train: [53][120/750]	BT 0.062 (1.295)	DT 0.013 (1.250)	loss 6.881 (6.881)	prob 2.669 (2.669)	GS 31.078 (31.078)	mem 39.168
Train: [53][125/750]	BT 0.040 (1.313)	DT 0.007 (1.269)	loss 6.893 (6.893)	prob 2.176 (2.176)	GS 35.094 (35.094)	mem 39.392
Train: [53][130/750]	BT 6.077 (1.311)	DT 6.043 (1.267)	loss 6.648 (6.648)	prob 2.984 (2.984)	GS 32.250 (32.250)	mem 39.461
Train: [53][135/750]	BT 0.026 (1.264)	DT 0.001 (1.220)	loss 6.749 (6.749)	prob 2.588 (2.588)	GS 28.875 (28.875)	mem 39.517
Train: [53][140/750]	BT 0.032 (1.295)	DT 0.001 (1.251)	loss 7.091 (7.091)	prob 1.560 (1.560)	GS 31.406 (31.406)	mem 39.472
Train: [53][145/750]	BT 0.031 (1.262)	DT 0.001 (1.218)	loss 6.852 (6.852)	prob 2.007 (2.007)	GS 29.656 (29.656)	mem 39.477
Train: [53][150/750]	BT 0.037 (1.309)	DT 0.002 (1.264)	loss 6.847 (6.847)	prob 2.171 (2.171)	GS 34.969 (34.969)	mem 39.503
Train: [53][155/750]	BT 0.048 (1.268)	DT 0.004 (1.224)	loss 7.068 (7.068)	prob 2.380 (2.380)	GS 30.922 (30.922)	mem 39.471
Train: [53][160/750]	BT 15.341 (1.325)	DT 15.313 (1.281)	loss 6.936 (6.936)	prob 2.269 (2.269)	GS 37.672 (37.672)	mem 39.514
Train: [53][165/750]	BT 0.024 (1.286)	DT 0.001 (1.243)	loss 6.842 (6.842)	prob 2.722 (2.722)	GS 31.562 (31.562)	mem 39.513
Train: [53][170/750]	BT 0.049 (1.250)	DT 0.001 (1.206)	loss 7.222 (7.222)	prob 3.081 (3.081)	GS 35.469 (35.469)	mem 39.579
Train: [53][175/750]	BT 0.057 (1.280)	DT 0.006 (1.236)	loss 6.911 (6.911)	prob 3.465 (3.465)	GS 31.297 (31.297)	mem 39.577
Train: [53][180/750]	BT 0.035 (1.245)	DT 0.012 (1.202)	loss 7.294 (7.294)	prob 2.257 (2.257)	GS 33.641 (33.641)	mem 39.577
Train: [53][185/750]	BT 0.051 (1.264)	DT 0.017 (1.219)	loss 7.086 (7.086)	prob 3.164 (3.164)	GS 32.094 (32.094)	mem 39.741
Train: [53][190/750]	BT 0.068 (1.232)	DT 0.029 (1.188)	loss 6.840 (6.840)	prob 2.621 (2.621)	GS 32.469 (32.469)	mem 39.707
Train: [53][195/750]	BT 0.036 (1.201)	DT 0.001 (1.157)	loss 6.825 (6.825)	prob 2.983 (2.983)	GS 32.266 (32.266)	mem 39.768
Train: [53][200/750]	BT 0.057 (1.232)	DT 0.006 (1.188)	loss 7.222 (7.222)	prob 2.251 (2.251)	GS 30.688 (30.688)	mem 39.806
Train: [53][205/750]	BT 0.053 (1.211)	DT 0.011 (1.167)	loss 6.886 (6.886)	prob 3.118 (3.118)	GS 33.422 (33.422)	mem 39.800
Train: [53][210/750]	BT 0.291 (1.234)	DT 0.239 (1.189)	loss 6.951 (6.951)	prob 2.538 (2.538)	GS 35.953 (35.953)	mem 39.843
Train: [53][215/750]	BT 0.041 (1.210)	DT 0.002 (1.165)	loss 6.951 (6.951)	prob 2.736 (2.736)	GS 32.953 (32.953)	mem 39.843
Train: [53][220/750]	BT 10.394 (1.231)	DT 10.357 (1.186)	loss 7.082 (7.082)	prob 2.498 (2.498)	GS 35.203 (35.203)	mem 40.074
Train: [53][225/750]	BT 0.063 (1.204)	DT 0.011 (1.160)	loss 6.899 (6.899)	prob 2.640 (2.640)	GS 31.062 (31.062)	mem 39.787
Train: [53][230/750]	BT 0.076 (1.185)	DT 0.002 (1.140)	loss 7.157 (7.157)	prob 2.195 (2.195)	GS 31.359 (31.359)	mem 39.737
Train: [53][235/750]	BT 0.038 (1.214)	DT 0.001 (1.169)	loss 7.013 (7.013)	prob 2.612 (2.612)	GS 29.484 (29.484)	mem 39.803
Train: [53][240/750]	BT 2.470 (1.200)	DT 2.387 (1.155)	loss 6.627 (6.627)	prob 2.789 (2.789)	GS 36.141 (36.141)	mem 39.956
Train: [53][245/750]	BT 0.032 (1.214)	DT 0.001 (1.169)	loss 6.913 (6.913)	prob 2.763 (2.763)	GS 37.594 (37.594)	mem 39.809
Train: [53][250/750]	BT 1.166 (1.196)	DT 1.134 (1.150)	loss 6.825 (6.825)	prob 3.017 (3.017)	GS 36.766 (36.766)	mem 39.847
Train: [53][255/750]	BT 0.031 (1.191)	DT 0.001 (1.146)	loss 7.168 (7.168)	prob 2.200 (2.200)	GS 34.922 (34.922)	mem 39.905
Train: [53][260/750]	BT 0.041 (1.191)	DT 0.002 (1.146)	loss 6.945 (6.945)	prob 2.443 (2.443)	GS 36.156 (36.156)	mem 39.996
Train: [53][265/750]	BT 0.042 (1.192)	DT 0.013 (1.146)	loss 6.704 (6.704)	prob 2.813 (2.813)	GS 28.094 (28.094)	mem 39.873
Train: [53][270/750]	BT 0.064 (1.212)	DT 0.002 (1.167)	loss 6.755 (6.755)	prob 2.784 (2.784)	GS 32.203 (32.203)	mem 39.827
Train: [53][275/750]	BT 0.049 (1.191)	DT 0.009 (1.146)	loss 6.683 (6.683)	prob 2.887 (2.887)	GS 27.625 (27.625)	mem 39.826
Train: [53][280/750]	BT 12.920 (1.221)	DT 12.875 (1.177)	loss 6.885 (6.885)	prob 2.958 (2.958)	GS 30.109 (30.109)	mem 39.806
Train: [53][285/750]	BT 0.038 (1.201)	DT 0.001 (1.156)	loss 6.894 (6.894)	prob 2.951 (2.951)	GS 27.125 (27.125)	mem 39.806
Train: [53][290/750]	BT 0.067 (1.181)	DT 0.012 (1.136)	loss 6.869 (6.869)	prob 2.307 (2.307)	GS 33.219 (33.219)	mem 39.807
Train: [53][295/750]	BT 0.033 (1.207)	DT 0.001 (1.162)	loss 6.989 (6.989)	prob 1.807 (1.807)	GS 24.125 (24.125)	mem 39.837
Train: [53][300/750]	BT 0.031 (1.188)	DT 0.001 (1.143)	loss 6.970 (6.970)	prob 2.087 (2.087)	GS 34.469 (34.469)	mem 39.837
Train: [53][305/750]	BT 0.044 (1.206)	DT 0.006 (1.161)	loss 6.846 (6.846)	prob 2.810 (2.810)	GS 32.156 (32.156)	mem 40.004
Train: [53][310/750]	BT 0.092 (1.187)	DT 0.012 (1.143)	loss 7.046 (7.046)	prob 2.421 (2.421)	GS 37.219 (37.219)	mem 39.953
Train: [53][315/750]	BT 0.065 (1.169)	DT 0.016 (1.125)	loss 6.737 (6.737)	prob 2.420 (2.420)	GS 33.172 (33.172)	mem 39.953
Train: [53][320/750]	BT 0.025 (1.190)	DT 0.001 (1.146)	loss 6.747 (6.747)	prob 2.751 (2.751)	GS 34.406 (34.406)	mem 39.826
Train: [53][325/750]	BT 0.055 (1.173)	DT 0.012 (1.129)	loss 6.996 (6.996)	prob 2.383 (2.383)	GS 31.766 (31.766)	mem 39.770
Train: [53][330/750]	BT 0.025 (1.185)	DT 0.001 (1.141)	loss 7.207 (7.207)	prob 2.187 (2.187)	GS 31.469 (31.469)	mem 39.874
Train: [53][335/750]	BT 0.123 (1.171)	DT 0.005 (1.126)	loss 6.558 (6.558)	prob 2.803 (2.803)	GS 32.438 (32.438)	mem 39.908
Train: [53][340/750]	BT 2.246 (1.179)	DT 2.200 (1.134)	loss 6.694 (6.694)	prob 2.608 (2.608)	GS 28.594 (28.594)	mem 39.882
Train: [53][345/750]	BT 0.083 (1.163)	DT 0.007 (1.118)	loss 6.849 (6.849)	prob 2.696 (2.696)	GS 31.438 (31.438)	mem 39.882
Train: [53][350/750]	BT 0.073 (1.185)	DT 0.002 (1.139)	loss 6.987 (6.987)	prob 2.326 (2.326)	GS 31.828 (31.828)	mem 39.976
Train: [53][355/750]	BT 0.034 (1.169)	DT 0.002 (1.124)	loss 6.909 (6.909)	prob 2.843 (2.843)	GS 27.312 (27.312)	mem 39.882
Train: [53][360/750]	BT 4.240 (1.183)	DT 4.198 (1.138)	loss 7.471 (7.471)	prob 1.879 (1.879)	GS 32.297 (32.297)	mem 39.883
Train: [53][365/750]	BT 0.199 (1.172)	DT 0.011 (1.127)	loss 7.660 (7.660)	prob 2.283 (2.283)	GS 35.531 (35.531)	mem 39.841
Train: [53][370/750]	BT 1.685 (1.166)	DT 1.628 (1.120)	loss 6.892 (6.892)	prob 2.538 (2.538)	GS 35.000 (35.000)	mem 39.912
Train: [53][375/750]	BT 0.065 (1.173)	DT 0.005 (1.128)	loss 6.866 (6.866)	prob 2.408 (2.408)	GS 33.578 (33.578)	mem 39.920
Train: [53][380/750]	BT 3.338 (1.169)	DT 3.296 (1.123)	loss 6.890 (6.890)	prob 2.964 (2.964)	GS 36.797 (36.797)	mem 39.778
Train: [53][385/750]	BT 0.036 (1.175)	DT 0.001 (1.130)	loss 6.909 (6.909)	prob 2.428 (2.428)	GS 32.875 (32.875)	mem 39.873
Train: [53][390/750]	BT 0.049 (1.167)	DT 0.002 (1.122)	loss 6.783 (6.783)	prob 2.710 (2.710)	GS 31.156 (31.156)	mem 39.860
Train: [53][395/750]	BT 0.028 (1.167)	DT 0.002 (1.121)	loss 6.673 (6.673)	prob 3.130 (3.130)	GS 27.797 (27.797)	mem 39.854
Train: [53][400/750]	BT 4.440 (1.177)	DT 4.408 (1.131)	loss 6.722 (6.722)	prob 2.562 (2.562)	GS 40.359 (40.359)	mem 39.832
Train: [53][405/750]	BT 0.069 (1.163)	DT 0.005 (1.117)	loss 6.904 (6.904)	prob 3.182 (3.182)	GS 27.625 (27.625)	mem 39.832
Train: [53][410/750]	BT 0.046 (1.178)	DT 0.003 (1.132)	loss 7.044 (7.044)	prob 2.456 (2.456)	GS 34.234 (34.234)	mem 39.923
Train: [53][415/750]	BT 0.040 (1.166)	DT 0.003 (1.120)	loss 6.777 (6.777)	prob 2.971 (2.971)	GS 27.938 (27.938)	mem 39.889
Train: [53][420/750]	BT 8.655 (1.177)	DT 8.606 (1.131)	loss 6.797 (6.797)	prob 3.150 (3.150)	GS 33.891 (33.891)	mem 39.916
Train: [53][425/750]	BT 0.064 (1.165)	DT 0.005 (1.118)	loss 6.962 (6.962)	prob 3.037 (3.037)	GS 27.609 (27.609)	mem 39.914
Train: [53][430/750]	BT 0.052 (1.165)	DT 0.004 (1.119)	loss 6.821 (6.821)	prob 2.563 (2.563)	GS 34.328 (34.328)	mem 39.875
Train: [53][435/750]	BT 0.062 (1.164)	DT 0.011 (1.118)	loss 6.727 (6.727)	prob 2.892 (2.892)	GS 30.859 (30.859)	mem 39.796
Train: [53][440/750]	BT 6.414 (1.169)	DT 6.369 (1.123)	loss 7.082 (7.082)	prob 2.592 (2.592)	GS 28.812 (28.812)	mem 39.989
Train: [53][445/750]	BT 0.042 (1.166)	DT 0.002 (1.119)	loss 6.993 (6.993)	prob 3.223 (3.223)	GS 32.578 (32.578)	mem 40.017
Train: [53][450/750]	BT 0.029 (1.168)	DT 0.001 (1.121)	loss 6.912 (6.912)	prob 2.755 (2.755)	GS 32.438 (32.438)	mem 39.922
Train: [53][455/750]	BT 0.047 (1.163)	DT 0.001 (1.116)	loss 7.177 (7.177)	prob 2.761 (2.761)	GS 36.234 (36.234)	mem 39.948
Train: [53][460/750]	BT 4.562 (1.167)	DT 4.411 (1.121)	loss 6.768 (6.768)	prob 2.901 (2.901)	GS 30.656 (30.656)	mem 39.989
Train: [53][465/750]	BT 0.041 (1.170)	DT 0.001 (1.123)	loss 6.989 (6.989)	prob 3.188 (3.188)	GS 33.641 (33.641)	mem 39.885
Train: [53][470/750]	BT 1.502 (1.162)	DT 1.454 (1.115)	loss 6.870 (6.870)	prob 2.922 (2.922)	GS 33.750 (33.750)	mem 40.074
Train: [53][475/750]	BT 0.047 (1.164)	DT 0.004 (1.117)	loss 6.814 (6.814)	prob 2.731 (2.731)	GS 31.359 (31.359)	mem 39.874
Train: [53][480/750]	BT 0.914 (1.158)	DT 0.874 (1.111)	loss 7.119 (7.119)	prob 2.497 (2.497)	GS 34.953 (34.953)	mem 39.904
Train: [53][485/750]	BT 0.039 (1.166)	DT 0.001 (1.119)	loss 7.063 (7.063)	prob 2.581 (2.581)	GS 35.078 (35.078)	mem 39.965
Train: [53][490/750]	BT 0.032 (1.158)	DT 0.008 (1.111)	loss 7.031 (7.031)	prob 2.505 (2.505)	GS 34.625 (34.625)	mem 39.963
Train: [53][495/750]	BT 0.057 (1.167)	DT 0.006 (1.120)	loss 6.934 (6.934)	prob 2.524 (2.524)	GS 31.812 (31.812)	mem 39.946
Train: [53][500/750]	BT 0.034 (1.160)	DT 0.001 (1.113)	loss 6.802 (6.802)	prob 3.593 (3.593)	GS 33.078 (33.078)	mem 39.918
Train: [53][505/750]	BT 0.081 (1.154)	DT 0.008 (1.107)	loss 6.683 (6.683)	prob 3.134 (3.134)	GS 35.297 (35.297)	mem 39.945
Train: [53][510/750]	BT 0.046 (1.164)	DT 0.001 (1.117)	loss 6.710 (6.710)	prob 3.213 (3.213)	GS 33.734 (33.734)	mem 39.970
Train: [53][515/750]	BT 0.079 (1.153)	DT 0.018 (1.106)	loss 6.958 (6.958)	prob 2.601 (2.601)	GS 31.453 (31.453)	mem 39.970
Train: [53][520/750]	BT 1.229 (1.163)	DT 1.154 (1.116)	loss 7.000 (7.000)	prob 2.596 (2.596)	GS 34.953 (34.953)	mem 39.983
Train: [53][525/750]	BT 0.050 (1.154)	DT 0.009 (1.108)	loss 7.232 (7.232)	prob 2.803 (2.803)	GS 33.766 (33.766)	mem 39.950
Train: [53][530/750]	BT 9.716 (1.166)	DT 9.688 (1.119)	loss 6.832 (6.832)	prob 2.593 (2.593)	GS 34.562 (34.562)	mem 40.023
Train: [53][535/750]	BT 0.062 (1.155)	DT 0.003 (1.109)	loss 7.014 (7.014)	prob 2.478 (2.478)	GS 27.844 (27.844)	mem 40.085
Train: [53][540/750]	BT 0.089 (1.153)	DT 0.001 (1.107)	loss 6.892 (6.892)	prob 2.917 (2.917)	GS 30.891 (30.891)	mem 39.987
Train: [53][545/750]	BT 0.032 (1.166)	DT 0.001 (1.120)	loss 6.939 (6.939)	prob 2.308 (2.308)	GS 26.906 (26.906)	mem 40.054
Train: [53][550/750]	BT 0.892 (1.158)	DT 0.860 (1.111)	loss 7.112 (7.112)	prob 2.127 (2.127)	GS 34.625 (34.625)	mem 39.990
Train: [53][555/750]	BT 0.050 (1.168)	DT 0.003 (1.122)	loss 7.122 (7.122)	prob 2.414 (2.414)	GS 33.281 (33.281)	mem 40.106
Train: [53][560/750]	BT 0.043 (1.158)	DT 0.002 (1.112)	loss 6.925 (6.925)	prob 2.539 (2.539)	GS 39.844 (39.844)	mem 40.025
Train: [53][565/750]	BT 0.030 (1.158)	DT 0.001 (1.112)	loss 7.259 (7.259)	prob 2.828 (2.828)	GS 30.984 (30.984)	mem 40.033
Train: [53][570/750]	BT 0.110 (1.162)	DT 0.012 (1.115)	loss 6.874 (6.874)	prob 2.161 (2.161)	GS 32.359 (32.359)	mem 40.037
Train: [53][575/750]	BT 0.052 (1.164)	DT 0.007 (1.117)	loss 7.075 (7.075)	prob 2.566 (2.566)	GS 33.953 (33.953)	mem 39.976
Train: [53][580/750]	BT 0.034 (1.169)	DT 0.002 (1.122)	loss 6.939 (6.939)	prob 2.884 (2.884)	GS 34.438 (34.438)	mem 40.067
Train: [53][585/750]	BT 0.032 (1.159)	DT 0.001 (1.113)	loss 6.931 (6.931)	prob 3.048 (3.048)	GS 34.766 (34.766)	mem 39.992
Train: [53][590/750]	BT 9.255 (1.171)	DT 9.210 (1.124)	loss 6.953 (6.953)	prob 2.822 (2.822)	GS 32.812 (32.812)	mem 40.046
Train: [53][595/750]	BT 0.056 (1.161)	DT 0.005 (1.115)	loss 7.145 (7.145)	prob 2.614 (2.614)	GS 29.391 (29.391)	mem 39.960
Train: [53][600/750]	BT 1.542 (1.157)	DT 1.478 (1.110)	loss 6.723 (6.723)	prob 3.294 (3.294)	GS 30.469 (30.469)	mem 40.013
Train: [53][605/750]	BT 0.028 (1.163)	DT 0.002 (1.117)	loss 7.115 (7.115)	prob 2.434 (2.434)	GS 31.828 (31.828)	mem 40.013
Train: [53][610/750]	BT 0.191 (1.154)	DT 0.149 (1.108)	loss 7.116 (7.116)	prob 3.084 (3.084)	GS 31.672 (31.672)	mem 40.016
Train: [53][615/750]	BT 0.040 (1.162)	DT 0.001 (1.115)	loss 6.902 (6.902)	prob 2.497 (2.497)	GS 29.297 (29.297)	mem 40.078
Train: [53][620/750]	BT 0.035 (1.158)	DT 0.001 (1.111)	loss 7.037 (7.037)	prob 2.566 (2.566)	GS 31.859 (31.859)	mem 39.974
Train: [53][625/750]	BT 0.042 (1.157)	DT 0.005 (1.111)	loss 6.749 (6.749)	prob 2.773 (2.773)	GS 32.000 (32.000)	mem 39.876
Train: [53][630/750]	BT 0.044 (1.158)	DT 0.007 (1.111)	loss 7.158 (7.158)	prob 2.132 (2.132)	GS 33.891 (33.891)	mem 39.948
Train: [53][635/750]	BT 0.042 (1.149)	DT 0.010 (1.103)	loss 7.134 (7.134)	prob 2.455 (2.455)	GS 33.062 (33.062)	mem 39.949
Train: [53][640/750]	BT 1.147 (1.161)	DT 1.099 (1.115)	loss 6.914 (6.914)	prob 2.679 (2.679)	GS 35.891 (35.891)	mem 39.891
Train: [53][645/750]	BT 0.039 (1.152)	DT 0.008 (1.106)	loss 7.040 (7.040)	prob 2.632 (2.632)	GS 32.578 (32.578)	mem 39.891
Train: [53][650/750]	BT 1.881 (1.160)	DT 1.820 (1.114)	loss 6.965 (6.965)	prob 2.811 (2.811)	GS 35.656 (35.656)	mem 39.940
Train: [53][655/750]	BT 0.051 (1.152)	DT 0.006 (1.106)	loss 7.083 (7.083)	prob 3.022 (3.022)	GS 29.125 (29.125)	mem 39.942
arpack error, retry= 0
Train: [53][660/750]	BT 8.756 (1.158)	DT 8.719 (1.112)	loss 7.002 (7.002)	prob 2.478 (2.478)	GS 29.359 (29.359)	mem 39.971
Train: [53][665/750]	BT 0.053 (1.154)	DT 0.004 (1.108)	loss 6.870 (6.870)	prob 3.208 (3.208)	GS 25.703 (25.703)	mem 39.989
Train: [53][670/750]	BT 0.869 (1.147)	DT 0.802 (1.101)	loss 6.578 (6.578)	prob 3.704 (3.704)	GS 35.172 (35.172)	mem 39.906
Train: [53][675/750]	BT 0.031 (1.158)	DT 0.002 (1.111)	loss 6.860 (6.860)	prob 3.099 (3.099)	GS 30.281 (30.281)	mem 39.983
Train: [53][680/750]	BT 0.044 (1.150)	DT 0.012 (1.103)	loss 7.105 (7.105)	prob 2.330 (2.330)	GS 36.578 (36.578)	mem 39.984
Train: [53][685/750]	BT 0.037 (1.155)	DT 0.009 (1.109)	loss 7.126 (7.126)	prob 2.328 (2.328)	GS 28.531 (28.531)	mem 40.012
Train: [53][690/750]	BT 0.099 (1.153)	DT 0.002 (1.107)	loss 6.839 (6.839)	prob 3.199 (3.199)	GS 32.000 (32.000)	mem 40.284
Train: [53][695/750]	BT 0.040 (1.145)	DT 0.001 (1.099)	loss 7.266 (7.266)	prob 2.664 (2.664)	GS 36.094 (36.094)	mem 40.014
Train: [53][700/750]	BT 0.032 (1.156)	DT 0.001 (1.109)	loss 7.062 (7.062)	prob 3.317 (3.317)	GS 36.156 (36.156)	mem 40.002
Train: [53][705/750]	BT 0.049 (1.148)	DT 0.013 (1.101)	loss 6.968 (6.968)	prob 3.199 (3.199)	GS 32.422 (32.422)	mem 40.002
Train: [53][710/750]	BT 1.277 (1.158)	DT 1.224 (1.112)	loss 6.925 (6.925)	prob 2.748 (2.748)	GS 31.812 (31.812)	mem 40.035
Train: [53][715/750]	BT 0.125 (1.151)	DT 0.035 (1.104)	loss 6.953 (6.953)	prob 2.096 (2.096)	GS 30.047 (30.047)	mem 40.036
Train: [53][720/750]	BT 12.084 (1.160)	DT 12.051 (1.114)	loss 7.175 (7.175)	prob 2.004 (2.004)	GS 32.547 (32.547)	mem 39.990
Train: [53][725/750]	BT 0.086 (1.155)	DT 0.009 (1.109)	loss 6.918 (6.918)	prob 2.664 (2.664)	GS 33.812 (33.812)	mem 39.993
Train: [53][730/750]	BT 0.130 (1.148)	DT 0.010 (1.101)	loss 6.930 (6.930)	prob 2.641 (2.641)	GS 31.266 (31.266)	mem 40.150
Train: [53][735/750]	BT 0.031 (1.154)	DT 0.001 (1.108)	loss 6.773 (6.773)	prob 2.948 (2.948)	GS 34.859 (34.859)	mem 37.500
Train: [53][740/750]	BT 0.030 (1.147)	DT 0.001 (1.100)	loss 6.894 (6.894)	prob 2.322 (2.322)	GS 34.953 (34.953)	mem 36.631
Train: [53][745/750]	BT 0.029 (1.146)	DT 0.001 (1.099)	loss 6.762 (6.762)	prob 2.585 (2.585)	GS 28.344 (28.344)	mem 7.670
Train: [53][750/750]	BT 0.033 (1.138)	DT 0.001 (1.092)	loss 6.907 (6.907)	prob 2.854 (2.854)	GS 36.938 (36.938)	mem 7.670
Train: [53][755/750]	BT 0.027 (1.131)	DT 0.001 (1.085)	loss 6.817 (6.817)	prob 2.691 (2.691)	GS 25.656 (25.656)	mem 7.670
epoch 53, total time 856.58
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [54][1/750]	BT 23.746 (23.746)	DT 23.659 (23.659)	loss 6.732 (6.732)	prob 2.583 (2.583)	GS 34.766 (34.766)	mem 38.653
Train: [54][5/750]	BT 0.028 (6.569)	DT 0.001 (6.518)	loss 6.733 (6.733)	prob 2.593 (2.593)	GS 32.031 (32.031)	mem 38.768
Train: [54][10/750]	BT 0.037 (3.309)	DT 0.001 (3.263)	loss 6.668 (6.668)	prob 3.118 (3.118)	GS 36.844 (36.844)	mem 38.829
Train: [54][15/750]	BT 4.639 (2.838)	DT 4.608 (2.793)	loss 6.803 (6.803)	prob 3.178 (3.178)	GS 29.375 (29.375)	mem 38.875
Train: [54][20/750]	BT 0.091 (2.144)	DT 0.010 (2.096)	loss 6.806 (6.806)	prob 3.023 (3.023)	GS 32.375 (32.375)	mem 38.907
Train: [54][25/750]	BT 5.357 (2.045)	DT 5.300 (1.993)	loss 6.915 (6.915)	prob 2.304 (2.304)	GS 30.719 (30.719)	mem 39.001
Train: [54][30/750]	BT 0.043 (1.729)	DT 0.003 (1.677)	loss 6.814 (6.814)	prob 2.581 (2.581)	GS 32.375 (32.375)	mem 38.971
Train: [54][35/750]	BT 0.047 (1.508)	DT 0.011 (1.454)	loss 6.804 (6.804)	prob 2.838 (2.838)	GS 30.547 (30.547)	mem 39.117
Train: [54][40/750]	BT 0.051 (1.665)	DT 0.003 (1.612)	loss 6.692 (6.692)	prob 3.663 (3.663)	GS 35.000 (35.000)	mem 39.105
Train: [54][45/750]	BT 0.032 (1.484)	DT 0.002 (1.433)	loss 6.918 (6.918)	prob 2.669 (2.669)	GS 32.984 (32.984)	mem 39.003
Train: [54][50/750]	BT 0.029 (1.561)	DT 0.001 (1.511)	loss 6.813 (6.813)	prob 2.702 (2.702)	GS 31.891 (31.891)	mem 39.029
Train: [54][55/750]	BT 0.038 (1.442)	DT 0.002 (1.394)	loss 7.193 (7.193)	prob 2.515 (2.515)	GS 29.469 (29.469)	mem 39.042
Train: [54][60/750]	BT 13.274 (1.546)	DT 13.153 (1.497)	loss 7.015 (7.015)	prob 2.964 (2.964)	GS 30.391 (30.391)	mem 39.134
Train: [54][65/750]	BT 0.031 (1.456)	DT 0.001 (1.408)	loss 6.977 (6.977)	prob 2.433 (2.433)	GS 30.344 (30.344)	mem 39.007
Train: [54][70/750]	BT 0.060 (1.355)	DT 0.001 (1.308)	loss 6.895 (6.895)	prob 3.052 (3.052)	GS 34.703 (34.703)	mem 39.007
Train: [54][75/750]	BT 0.030 (1.442)	DT 0.008 (1.395)	loss 6.978 (6.978)	prob 2.839 (2.839)	GS 32.891 (32.891)	mem 39.108
Train: [54][80/750]	BT 0.109 (1.357)	DT 0.012 (1.309)	loss 6.947 (6.947)	prob 2.286 (2.286)	GS 33.703 (33.703)	mem 39.114
Train: [54][85/750]	BT 0.033 (1.402)	DT 0.004 (1.354)	loss 7.187 (7.187)	prob 2.720 (2.720)	GS 33.422 (33.422)	mem 39.054
Train: [54][90/750]	BT 0.046 (1.362)	DT 0.001 (1.316)	loss 6.829 (6.829)	prob 2.652 (2.652)	GS 34.812 (34.812)	mem 38.996
Train: [54][95/750]	BT 0.032 (1.293)	DT 0.001 (1.247)	loss 7.001 (7.001)	prob 2.732 (2.732)	GS 33.781 (33.781)	mem 39.008
Train: [54][100/750]	BT 0.047 (1.344)	DT 0.013 (1.297)	loss 7.027 (7.027)	prob 2.566 (2.566)	GS 33.906 (33.906)	mem 39.264
Train: [54][105/750]	BT 0.028 (1.306)	DT 0.001 (1.259)	loss 7.186 (7.186)	prob 2.547 (2.547)	GS 33.469 (33.469)	mem 39.262
Train: [54][110/750]	BT 2.762 (1.357)	DT 2.733 (1.311)	loss 7.047 (7.047)	prob 3.013 (3.013)	GS 33.844 (33.844)	mem 39.325
Train: [54][115/750]	BT 0.028 (1.299)	DT 0.001 (1.254)	loss 6.821 (6.821)	prob 3.236 (3.236)	GS 28.984 (28.984)	mem 39.301
Train: [54][120/750]	BT 9.722 (1.328)	DT 9.682 (1.282)	loss 6.897 (6.897)	prob 2.772 (2.772)	GS 35.891 (35.891)	mem 39.316
Train: [54][125/750]	BT 0.025 (1.308)	DT 0.001 (1.263)	loss 6.907 (6.907)	prob 2.914 (2.914)	GS 32.203 (32.203)	mem 39.357
Train: [54][130/750]	BT 0.041 (1.260)	DT 0.010 (1.215)	loss 6.807 (6.807)	prob 2.976 (2.976)	GS 33.438 (33.438)	mem 39.516
Train: [54][135/750]	BT 0.045 (1.282)	DT 0.002 (1.238)	loss 6.922 (6.922)	prob 2.315 (2.315)	GS 29.562 (29.562)	mem 39.682
Train: [54][140/750]	BT 0.032 (1.238)	DT 0.002 (1.193)	loss 7.189 (7.189)	prob 2.622 (2.622)	GS 34.188 (34.188)	mem 39.635
Train: [54][145/750]	BT 0.028 (1.257)	DT 0.001 (1.213)	loss 6.891 (6.891)	prob 2.638 (2.638)	GS 29.734 (29.734)	mem 39.750
Train: [54][150/750]	BT 0.037 (1.233)	DT 0.002 (1.189)	loss 6.938 (6.938)	prob 2.711 (2.711)	GS 31.516 (31.516)	mem 39.714
Train: [54][155/750]	BT 0.069 (1.201)	DT 0.004 (1.156)	loss 6.717 (6.717)	prob 3.480 (3.480)	GS 36.609 (36.609)	mem 39.870
Train: [54][160/750]	BT 0.051 (1.245)	DT 0.012 (1.201)	loss 6.689 (6.689)	prob 2.872 (2.872)	GS 33.078 (33.078)	mem 39.792
Train: [54][165/750]	BT 0.033 (1.208)	DT 0.002 (1.164)	loss 7.083 (7.083)	prob 2.105 (2.105)	GS 35.281 (35.281)	mem 39.737
Train: [54][170/750]	BT 6.824 (1.258)	DT 6.741 (1.214)	loss 6.854 (6.854)	prob 3.158 (3.158)	GS 36.047 (36.047)	mem 39.644
Train: [54][175/750]	BT 0.060 (1.223)	DT 0.001 (1.180)	loss 6.712 (6.712)	prob 2.551 (2.551)	GS 27.688 (27.688)	mem 39.664
Train: [54][180/750]	BT 5.023 (1.219)	DT 4.992 (1.175)	loss 6.834 (6.834)	prob 2.885 (2.885)	GS 38.156 (38.156)	mem 39.702
Train: [54][185/750]	BT 0.035 (1.248)	DT 0.001 (1.204)	loss 7.030 (7.030)	prob 3.079 (3.079)	GS 32.859 (32.859)	mem 39.697
Train: [54][190/750]	BT 0.084 (1.217)	DT 0.046 (1.173)	loss 6.959 (6.959)	prob 3.046 (3.046)	GS 34.000 (34.000)	mem 40.007
Train: [54][195/750]	BT 0.045 (1.244)	DT 0.001 (1.200)	loss 6.794 (6.794)	prob 3.169 (3.169)	GS 32.000 (32.000)	mem 39.677
Train: [54][200/750]	BT 0.036 (1.214)	DT 0.002 (1.170)	loss 6.986 (6.986)	prob 2.877 (2.877)	GS 36.172 (36.172)	mem 39.616
Train: [54][205/750]	BT 0.042 (1.193)	DT 0.002 (1.150)	loss 6.804 (6.804)	prob 3.380 (3.380)	GS 32.766 (32.766)	mem 39.790
Train: [54][210/750]	BT 0.028 (1.228)	DT 0.001 (1.185)	loss 6.934 (6.934)	prob 2.893 (2.893)	GS 33.000 (33.000)	mem 39.641
Train: [54][215/750]	BT 0.056 (1.201)	DT 0.001 (1.157)	loss 6.636 (6.636)	prob 3.022 (3.022)	GS 31.734 (31.734)	mem 39.642
Train: [54][220/750]	BT 0.033 (1.221)	DT 0.001 (1.177)	loss 6.987 (6.987)	prob 2.767 (2.767)	GS 35.766 (35.766)	mem 39.867
Train: [54][225/750]	BT 0.028 (1.203)	DT 0.001 (1.159)	loss 7.266 (7.266)	prob 2.715 (2.715)	GS 34.906 (34.906)	mem 39.679
Train: [54][230/750]	BT 9.779 (1.228)	DT 9.738 (1.184)	loss 7.270 (7.270)	prob 2.694 (2.694)	GS 36.609 (36.609)	mem 39.696
Train: [54][235/750]	BT 0.041 (1.204)	DT 0.012 (1.160)	loss 6.863 (6.863)	prob 3.127 (3.127)	GS 33.438 (33.438)	mem 39.704
Train: [54][240/750]	BT 3.887 (1.196)	DT 3.855 (1.152)	loss 6.866 (6.866)	prob 2.817 (2.817)	GS 32.594 (32.594)	mem 39.769
Train: [54][245/750]	BT 0.030 (1.207)	DT 0.002 (1.163)	loss 6.920 (6.920)	prob 2.420 (2.420)	GS 32.344 (32.344)	mem 39.724
Train: [54][250/750]	BT 0.087 (1.183)	DT 0.006 (1.140)	loss 6.896 (6.896)	prob 2.771 (2.771)	GS 37.109 (37.109)	mem 39.763
Train: [54][255/750]	BT 0.031 (1.216)	DT 0.001 (1.172)	loss 7.043 (7.043)	prob 2.391 (2.391)	GS 37.094 (37.094)	mem 39.804
Train: [54][260/750]	BT 0.061 (1.193)	DT 0.001 (1.150)	loss 6.926 (6.926)	prob 3.597 (3.597)	GS 36.062 (36.062)	mem 39.806
Train: [54][265/750]	BT 0.066 (1.183)	DT 0.002 (1.139)	loss 7.124 (7.124)	prob 2.429 (2.429)	GS 33.375 (33.375)	mem 39.908
Train: [54][270/750]	BT 0.118 (1.196)	DT 0.008 (1.152)	loss 7.218 (7.218)	prob 2.609 (2.609)	GS 36.047 (36.047)	mem 40.063
Train: [54][275/750]	BT 0.035 (1.175)	DT 0.001 (1.131)	loss 7.150 (7.150)	prob 2.820 (2.820)	GS 29.688 (29.688)	mem 39.908
Train: [54][280/750]	BT 0.049 (1.207)	DT 0.005 (1.163)	loss 6.801 (6.801)	prob 3.499 (3.499)	GS 36.188 (36.188)	mem 39.784
Train: [54][285/750]	BT 0.053 (1.186)	DT 0.002 (1.142)	loss 6.993 (6.993)	prob 2.968 (2.968)	GS 30.344 (30.344)	mem 39.836
Train: [54][290/750]	BT 13.040 (1.224)	DT 13.005 (1.180)	loss 7.052 (7.052)	prob 2.729 (2.729)	GS 34.484 (34.484)	mem 39.791
Train: [54][295/750]	BT 0.074 (1.204)	DT 0.010 (1.160)	loss 6.980 (6.980)	prob 3.435 (3.435)	GS 30.516 (30.516)	mem 39.956
Train: [54][300/750]	BT 0.523 (1.187)	DT 0.465 (1.142)	loss 7.062 (7.062)	prob 2.699 (2.699)	GS 31.875 (31.875)	mem 39.746
Train: [54][305/750]	BT 0.027 (1.213)	DT 0.001 (1.169)	loss 6.850 (6.850)	prob 3.047 (3.047)	GS 33.875 (33.875)	mem 39.773
Train: [54][310/750]	BT 0.063 (1.194)	DT 0.003 (1.150)	loss 7.187 (7.187)	prob 2.426 (2.426)	GS 35.344 (35.344)	mem 39.832
Train: [54][315/750]	BT 0.031 (1.217)	DT 0.001 (1.173)	loss 6.851 (6.851)	prob 3.236 (3.236)	GS 30.828 (30.828)	mem 39.826
Train: [54][320/750]	BT 0.046 (1.198)	DT 0.005 (1.155)	loss 6.820 (6.820)	prob 4.007 (4.007)	GS 32.750 (32.750)	mem 39.827
Train: [54][325/750]	BT 0.030 (1.180)	DT 0.001 (1.137)	loss 7.109 (7.109)	prob 3.182 (3.182)	GS 29.828 (29.828)	mem 39.879
Train: [54][330/750]	BT 0.036 (1.203)	DT 0.001 (1.160)	loss 6.946 (6.946)	prob 2.374 (2.374)	GS 29.625 (29.625)	mem 39.832
Train: [54][335/750]	BT 0.029 (1.186)	DT 0.001 (1.143)	loss 6.810 (6.810)	prob 3.441 (3.441)	GS 37.188 (37.188)	mem 39.833
Train: [54][340/750]	BT 0.032 (1.204)	DT 0.001 (1.161)	loss 6.904 (6.904)	prob 3.130 (3.130)	GS 31.016 (31.016)	mem 39.812
Train: [54][345/750]	BT 0.026 (1.187)	DT 0.001 (1.145)	loss 7.528 (7.528)	prob 2.334 (2.334)	GS 35.500 (35.500)	mem 39.847
Train: [54][350/750]	BT 15.112 (1.214)	DT 15.082 (1.171)	loss 6.983 (6.983)	prob 2.734 (2.734)	GS 33.281 (33.281)	mem 39.912
Train: [54][355/750]	BT 0.021 (1.197)	DT 0.001 (1.155)	loss 7.307 (7.307)	prob 1.757 (1.757)	GS 24.281 (24.281)	mem 39.913
Train: [54][360/750]	BT 0.113 (1.182)	DT 0.006 (1.139)	loss 6.957 (6.957)	prob 3.176 (3.176)	GS 29.297 (29.297)	mem 39.913
Train: [54][365/750]	BT 0.026 (1.194)	DT 0.001 (1.151)	loss 6.916 (6.916)	prob 2.742 (2.742)	GS 26.391 (26.391)	mem 39.961
Train: [54][370/750]	BT 0.041 (1.178)	DT 0.002 (1.135)	loss 6.737 (6.737)	prob 2.983 (2.983)	GS 33.625 (33.625)	mem 39.974
Train: [54][375/750]	BT 0.027 (1.198)	DT 0.001 (1.155)	loss 7.000 (7.000)	prob 3.707 (3.707)	GS 30.969 (30.969)	mem 39.877
Train: [54][380/750]	BT 0.059 (1.183)	DT 0.003 (1.140)	loss 6.868 (6.868)	prob 3.360 (3.360)	GS 33.969 (33.969)	mem 39.878
Train: [54][385/750]	BT 0.047 (1.168)	DT 0.001 (1.125)	loss 6.975 (6.975)	prob 3.383 (3.383)	GS 30.938 (30.938)	mem 39.877
Train: [54][390/750]	BT 0.029 (1.188)	DT 0.001 (1.145)	loss 6.842 (6.842)	prob 2.774 (2.774)	GS 31.844 (31.844)	mem 39.839
Train: [54][395/750]	BT 0.047 (1.174)	DT 0.009 (1.131)	loss 7.047 (7.047)	prob 2.890 (2.890)	GS 33.109 (33.109)	mem 39.877
Train: [54][400/750]	BT 0.039 (1.187)	DT 0.001 (1.144)	loss 6.909 (6.909)	prob 2.866 (2.866)	GS 29.422 (29.422)	mem 39.896
Train: [54][405/750]	BT 0.068 (1.173)	DT 0.007 (1.130)	loss 6.927 (6.927)	prob 2.816 (2.816)	GS 29.781 (29.781)	mem 39.896
Train: [54][410/750]	BT 13.486 (1.192)	DT 13.443 (1.149)	loss 6.990 (6.990)	prob 2.120 (2.120)	GS 33.734 (33.734)	mem 39.887
Train: [54][415/750]	BT 0.037 (1.178)	DT 0.005 (1.135)	loss 6.899 (6.899)	prob 3.227 (3.227)	GS 30.703 (30.703)	mem 39.888
Train: [54][420/750]	BT 0.061 (1.165)	DT 0.008 (1.122)	loss 7.233 (7.233)	prob 2.389 (2.389)	GS 33.047 (33.047)	mem 39.890
Train: [54][425/750]	BT 0.060 (1.178)	DT 0.010 (1.135)	loss 6.981 (6.981)	prob 3.465 (3.465)	GS 30.844 (30.844)	mem 39.958
Train: [54][430/750]	BT 0.104 (1.165)	DT 0.038 (1.122)	loss 6.847 (6.847)	prob 3.382 (3.382)	GS 37.797 (37.797)	mem 39.958
Train: [54][435/750]	BT 0.023 (1.180)	DT 0.001 (1.137)	loss 7.155 (7.155)	prob 2.576 (2.576)	GS 34.141 (34.141)	mem 39.903
Train: [54][440/750]	BT 0.055 (1.167)	DT 0.002 (1.124)	loss 7.044 (7.044)	prob 2.988 (2.988)	GS 34.609 (34.609)	mem 40.106
Train: [54][445/750]	BT 0.034 (1.156)	DT 0.004 (1.113)	loss 6.855 (6.855)	prob 3.084 (3.084)	GS 27.891 (27.891)	mem 39.928
Train: [54][450/750]	BT 0.031 (1.170)	DT 0.001 (1.126)	loss 6.815 (6.815)	prob 2.573 (2.573)	GS 35.859 (35.859)	mem 39.988
Train: [54][455/750]	BT 0.032 (1.176)	DT 0.002 (1.133)	loss 7.356 (7.356)	prob 2.078 (2.078)	GS 26.953 (26.953)	mem 39.927
Train: [54][460/750]	BT 2.585 (1.175)	DT 2.555 (1.132)	loss 6.825 (6.825)	prob 2.769 (2.769)	GS 29.953 (29.953)	mem 39.934
Train: [54][465/750]	BT 0.066 (1.163)	DT 0.002 (1.120)	loss 6.878 (6.878)	prob 3.189 (3.189)	GS 31.422 (31.422)	mem 39.934
Train: [54][470/750]	BT 4.693 (1.178)	DT 4.603 (1.135)	loss 6.846 (6.846)	prob 3.062 (3.062)	GS 32.922 (32.922)	mem 39.993
Train: [54][475/750]	BT 0.052 (1.166)	DT 0.002 (1.123)	loss 7.089 (7.089)	prob 2.922 (2.922)	GS 29.156 (29.156)	mem 39.936
Train: [54][480/750]	BT 0.082 (1.174)	DT 0.020 (1.130)	loss 6.709 (6.709)	prob 2.827 (2.827)	GS 32.141 (32.141)	mem 39.982
Train: [54][485/750]	BT 0.034 (1.170)	DT 0.001 (1.126)	loss 7.068 (7.068)	prob 2.940 (2.940)	GS 31.562 (31.562)	mem 39.842
Train: [54][490/750]	BT 11.266 (1.181)	DT 11.212 (1.138)	loss 6.969 (6.969)	prob 3.152 (3.152)	GS 33.672 (33.672)	mem 39.950
Train: [54][495/750]	BT 0.031 (1.169)	DT 0.001 (1.126)	loss 6.768 (6.768)	prob 4.110 (4.110)	GS 30.250 (30.250)	mem 39.998
Train: [54][500/750]	BT 0.025 (1.160)	DT 0.001 (1.117)	loss 6.826 (6.826)	prob 3.646 (3.646)	GS 32.203 (32.203)	mem 39.903
Train: [54][505/750]	BT 0.060 (1.176)	DT 0.007 (1.133)	loss 7.260 (7.260)	prob 2.960 (2.960)	GS 33.062 (33.062)	mem 39.939
Train: [54][510/750]	BT 0.049 (1.165)	DT 0.004 (1.122)	loss 6.719 (6.719)	prob 3.279 (3.279)	GS 32.906 (32.906)	mem 40.011
Train: [54][515/750]	BT 0.045 (1.180)	DT 0.005 (1.137)	loss 6.842 (6.842)	prob 3.700 (3.700)	GS 28.375 (28.375)	mem 39.973
Train: [54][520/750]	BT 0.034 (1.169)	DT 0.002 (1.126)	loss 6.900 (6.900)	prob 2.786 (2.786)	GS 35.031 (35.031)	mem 39.973
Train: [54][525/750]	BT 0.033 (1.159)	DT 0.001 (1.116)	loss 7.012 (7.012)	prob 3.124 (3.124)	GS 30.062 (30.062)	mem 39.974
Train: [54][530/750]	BT 0.060 (1.171)	DT 0.003 (1.128)	loss 7.109 (7.109)	prob 1.905 (1.905)	GS 36.453 (36.453)	mem 40.324
Train: [54][535/750]	BT 0.045 (1.160)	DT 0.004 (1.117)	loss 6.921 (6.921)	prob 2.785 (2.785)	GS 31.531 (31.531)	mem 40.019
Train: [54][540/750]	BT 0.049 (1.173)	DT 0.002 (1.130)	loss 7.373 (7.373)	prob 2.609 (2.609)	GS 30.500 (30.500)	mem 40.036
Train: [54][545/750]	BT 0.099 (1.164)	DT 0.016 (1.121)	loss 7.655 (7.655)	prob 2.636 (2.636)	GS 32.359 (32.359)	mem 40.174
Train: [54][550/750]	BT 14.311 (1.180)	DT 14.282 (1.137)	loss 6.896 (6.896)	prob 3.490 (3.490)	GS 36.141 (36.141)	mem 40.030
Train: [54][555/750]	BT 0.056 (1.170)	DT 0.022 (1.126)	loss 7.082 (7.082)	prob 3.156 (3.156)	GS 33.797 (33.797)	mem 40.117
Train: [54][560/750]	BT 0.035 (1.160)	DT 0.001 (1.116)	loss 7.496 (7.496)	prob 2.420 (2.420)	GS 36.047 (36.047)	mem 40.036
Train: [54][565/750]	BT 0.030 (1.175)	DT 0.001 (1.132)	loss 6.905 (6.905)	prob 3.268 (3.268)	GS 28.562 (28.562)	mem 40.015
Train: [54][570/750]	BT 0.060 (1.165)	DT 0.006 (1.122)	loss 6.959 (6.959)	prob 3.168 (3.168)	GS 33.688 (33.688)	mem 40.048
Train: [54][575/750]	BT 0.036 (1.178)	DT 0.007 (1.135)	loss 7.056 (7.056)	prob 2.585 (2.585)	GS 29.062 (29.062)	mem 40.010
Train: [54][580/750]	BT 0.025 (1.168)	DT 0.001 (1.125)	loss 7.090 (7.090)	prob 2.575 (2.575)	GS 35.922 (35.922)	mem 40.012
Train: [54][585/750]	BT 0.065 (1.158)	DT 0.015 (1.115)	loss 7.106 (7.106)	prob 3.396 (3.396)	GS 34.250 (34.250)	mem 40.018
Train: [54][590/750]	BT 0.072 (1.168)	DT 0.007 (1.125)	loss 7.054 (7.054)	prob 3.096 (3.096)	GS 35.156 (35.156)	mem 40.029
Train: [54][595/750]	BT 0.072 (1.159)	DT 0.006 (1.115)	loss 6.861 (6.861)	prob 3.159 (3.159)	GS 33.125 (33.125)	mem 40.012
Train: [54][600/750]	BT 0.069 (1.170)	DT 0.006 (1.126)	loss 7.011 (7.011)	prob 3.046 (3.046)	GS 32.047 (32.047)	mem 40.096
Train: [54][605/750]	BT 0.034 (1.160)	DT 0.002 (1.117)	loss 6.971 (6.971)	prob 2.661 (2.661)	GS 29.516 (29.516)	mem 40.017
Train: [54][610/750]	BT 10.208 (1.174)	DT 10.168 (1.130)	loss 6.944 (6.944)	prob 3.182 (3.182)	GS 34.500 (34.500)	mem 39.985
Train: [54][615/750]	BT 0.079 (1.165)	DT 0.005 (1.122)	loss 7.213 (7.213)	prob 3.291 (3.291)	GS 36.078 (36.078)	mem 40.094
Train: [54][620/750]	BT 0.031 (1.159)	DT 0.002 (1.115)	loss 7.288 (7.288)	prob 3.440 (3.440)	GS 34.078 (34.078)	mem 40.061
Train: [54][625/750]	BT 0.022 (1.168)	DT 0.001 (1.125)	loss 6.740 (6.740)	prob 3.889 (3.889)	GS 37.000 (37.000)	mem 39.961
Train: [54][630/750]	BT 0.028 (1.166)	DT 0.001 (1.123)	loss 7.046 (7.046)	prob 2.595 (2.595)	GS 33.125 (33.125)	mem 39.957
Train: [54][635/750]	BT 0.041 (1.168)	DT 0.001 (1.125)	loss 6.791 (6.791)	prob 3.573 (3.573)	GS 31.469 (31.469)	mem 39.993
Train: [54][640/750]	BT 0.034 (1.166)	DT 0.002 (1.123)	loss 6.869 (6.869)	prob 3.481 (3.481)	GS 32.453 (32.453)	mem 40.073
Train: [54][645/750]	BT 0.061 (1.157)	DT 0.014 (1.114)	loss 6.991 (6.991)	prob 3.041 (3.041)	GS 51.859 (51.859)	mem 40.071
Train: [54][650/750]	BT 3.824 (1.169)	DT 3.764 (1.126)	loss 7.198 (7.198)	prob 2.874 (2.874)	GS 34.000 (34.000)	mem 40.142
Train: [54][655/750]	BT 0.056 (1.160)	DT 0.003 (1.117)	loss 7.093 (7.093)	prob 2.609 (2.609)	GS 27.609 (27.609)	mem 39.968
Train: [54][660/750]	BT 0.061 (1.169)	DT 0.009 (1.126)	loss 6.775 (6.775)	prob 3.025 (3.025)	GS 36.172 (36.172)	mem 39.964
Train: [54][665/750]	BT 0.034 (1.162)	DT 0.002 (1.119)	loss 7.012 (7.012)	prob 3.390 (3.390)	GS 31.375 (31.375)	mem 39.925
Train: [54][670/750]	BT 10.773 (1.174)	DT 10.745 (1.130)	loss 7.064 (7.064)	prob 3.576 (3.576)	GS 34.531 (34.531)	mem 39.879
Train: [54][675/750]	BT 0.023 (1.165)	DT 0.001 (1.122)	loss 7.007 (7.007)	prob 2.866 (2.866)	GS 27.828 (27.828)	mem 39.864
Train: [54][680/750]	BT 0.045 (1.157)	DT 0.001 (1.114)	loss 6.921 (6.921)	prob 3.257 (3.257)	GS 32.984 (32.984)	mem 39.922
Train: [54][685/750]	BT 0.063 (1.167)	DT 0.001 (1.124)	loss 7.078 (7.078)	prob 3.284 (3.284)	GS 26.531 (26.531)	mem 39.929
Train: [54][690/750]	BT 0.033 (1.159)	DT 0.002 (1.115)	loss 6.879 (6.879)	prob 2.481 (2.481)	GS 31.859 (31.859)	mem 39.886
Train: [54][695/750]	BT 0.032 (1.168)	DT 0.001 (1.125)	loss 6.901 (6.901)	prob 2.857 (2.857)	GS 27.875 (27.875)	mem 39.944
Train: [54][700/750]	BT 0.054 (1.160)	DT 0.010 (1.117)	loss 7.036 (7.036)	prob 3.043 (3.043)	GS 30.578 (30.578)	mem 39.951
Train: [54][705/750]	BT 0.061 (1.152)	DT 0.015 (1.109)	loss 6.959 (6.959)	prob 3.317 (3.317)	GS 30.297 (30.297)	mem 39.958
Train: [54][710/750]	BT 0.031 (1.163)	DT 0.001 (1.120)	loss 6.970 (6.970)	prob 3.526 (3.526)	GS 32.578 (32.578)	mem 39.903
Train: [54][715/750]	BT 0.058 (1.155)	DT 0.002 (1.112)	loss 6.941 (6.941)	prob 3.168 (3.168)	GS 32.094 (32.094)	mem 39.938
Train: [54][720/750]	BT 0.058 (1.168)	DT 0.002 (1.125)	loss 6.890 (6.890)	prob 3.775 (3.775)	GS 33.922 (33.922)	mem 40.145
Train: [54][725/750]	BT 0.035 (1.160)	DT 0.002 (1.117)	loss 7.200 (7.200)	prob 2.961 (2.961)	GS 34.875 (34.875)	mem 39.919
Train: [54][730/750]	BT 9.796 (1.166)	DT 9.749 (1.123)	loss 6.887 (6.887)	prob 2.677 (2.677)	GS 30.688 (30.688)	mem 39.454
Train: [54][735/750]	BT 0.031 (1.158)	DT 0.001 (1.115)	loss 6.819 (6.819)	prob 3.225 (3.225)	GS 31.828 (31.828)	mem 39.455
Train: [54][740/750]	BT 0.032 (1.150)	DT 0.002 (1.108)	loss 7.028 (7.028)	prob 2.742 (2.742)	GS 32.812 (32.812)	mem 39.418
Train: [54][745/750]	BT 0.032 (1.151)	DT 0.002 (1.108)	loss 6.984 (6.984)	prob 2.821 (2.821)	GS 35.625 (35.625)	mem 7.576
Train: [54][750/750]	BT 0.022 (1.144)	DT 0.001 (1.101)	loss 7.003 (7.003)	prob 2.885 (2.885)	GS 37.094 (37.094)	mem 7.576
Train: [54][755/750]	BT 0.021 (1.140)	DT 0.001 (1.097)	loss 6.906 (6.906)	prob 2.641 (2.641)	GS 31.125 (31.125)	mem 7.497
epoch 54, total time 860.61
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [55][1/750]	BT 21.035 (21.035)	DT 20.949 (20.949)	loss 6.868 (6.868)	prob 3.224 (3.224)	GS 32.234 (32.234)	mem 38.664
Train: [55][5/750]	BT 0.057 (4.966)	DT 0.007 (4.897)	loss 6.874 (6.874)	prob 3.389 (3.389)	GS 34.984 (34.984)	mem 38.622
Train: [55][10/750]	BT 0.032 (2.665)	DT 0.001 (2.612)	loss 6.789 (6.789)	prob 2.997 (2.997)	GS 33.719 (33.719)	mem 38.684
Train: [55][15/750]	BT 0.039 (2.195)	DT 0.001 (2.148)	loss 6.792 (6.792)	prob 3.276 (3.276)	GS 29.078 (29.078)	mem 38.769
Train: [55][20/750]	BT 0.032 (1.981)	DT 0.001 (1.933)	loss 6.748 (6.748)	prob 2.821 (2.821)	GS 31.000 (31.000)	mem 38.818
Train: [55][25/750]	BT 4.324 (1.766)	DT 4.255 (1.717)	loss 6.912 (6.912)	prob 3.154 (3.154)	GS 30.953 (30.953)	mem 38.813
Train: [55][30/750]	BT 0.025 (1.906)	DT 0.001 (1.862)	loss 6.815 (6.815)	prob 2.973 (2.973)	GS 31.359 (31.359)	mem 38.993
Train: [55][35/750]	BT 0.077 (1.643)	DT 0.016 (1.597)	loss 6.875 (6.875)	prob 3.418 (3.418)	GS 28.719 (28.719)	mem 38.969
Train: [55][40/750]	BT 13.869 (1.817)	DT 13.834 (1.768)	loss 6.648 (6.648)	prob 3.155 (3.155)	GS 31.094 (31.094)	mem 38.879
Train: [55][45/750]	BT 0.022 (1.618)	DT 0.001 (1.572)	loss 7.102 (7.102)	prob 2.582 (2.582)	GS 30.266 (30.266)	mem 38.879
Train: [55][50/750]	BT 0.031 (1.460)	DT 0.002 (1.415)	loss 6.790 (6.790)	prob 2.782 (2.782)	GS 31.484 (31.484)	mem 38.882
Train: [55][55/750]	BT 0.039 (1.538)	DT 0.003 (1.494)	loss 7.064 (7.064)	prob 2.442 (2.442)	GS 31.875 (31.875)	mem 39.131
Train: [55][60/750]	BT 0.034 (1.414)	DT 0.001 (1.370)	loss 6.941 (6.941)	prob 2.732 (2.732)	GS 32.391 (32.391)	mem 39.169
Train: [55][65/750]	BT 0.031 (1.468)	DT 0.002 (1.425)	loss 6.916 (6.916)	prob 2.536 (2.536)	GS 29.906 (29.906)	mem 39.333
Train: [55][70/750]	BT 0.050 (1.366)	DT 0.007 (1.323)	loss 6.815 (6.815)	prob 2.905 (2.905)	GS 28.703 (28.703)	mem 39.498
Train: [55][75/750]	BT 0.032 (1.278)	DT 0.001 (1.236)	loss 6.867 (6.867)	prob 2.509 (2.509)	GS 31.859 (31.859)	mem 39.413
Train: [55][80/750]	BT 1.379 (1.390)	DT 1.342 (1.348)	loss 6.898 (6.898)	prob 2.556 (2.556)	GS 37.531 (37.531)	mem 39.355
Train: [55][85/750]	BT 0.034 (1.310)	DT 0.001 (1.269)	loss 6.919 (6.919)	prob 2.783 (2.783)	GS 30.328 (30.328)	mem 39.355
Train: [55][90/750]	BT 0.030 (1.376)	DT 0.001 (1.334)	loss 7.146 (7.146)	prob 2.246 (2.246)	GS 30.609 (30.609)	mem 39.555
Train: [55][95/750]	BT 0.044 (1.324)	DT 0.002 (1.283)	loss 7.174 (7.174)	prob 2.353 (2.353)	GS 30.359 (30.359)	mem 39.523
Train: [55][100/750]	BT 13.562 (1.395)	DT 13.532 (1.354)	loss 6.843 (6.843)	prob 2.363 (2.363)	GS 37.500 (37.500)	mem 39.490
Train: [55][105/750]	BT 0.048 (1.330)	DT 0.002 (1.290)	loss 6.936 (6.936)	prob 2.744 (2.744)	GS 34.391 (34.391)	mem 39.491
Train: [55][110/750]	BT 0.056 (1.271)	DT 0.001 (1.231)	loss 7.041 (7.041)	prob 2.585 (2.585)	GS 31.750 (31.750)	mem 39.515
Train: [55][115/750]	BT 0.033 (1.321)	DT 0.002 (1.281)	loss 6.989 (6.989)	prob 2.854 (2.854)	GS 33.375 (33.375)	mem 39.587
Train: [55][120/750]	BT 0.040 (1.268)	DT 0.009 (1.228)	loss 6.794 (6.794)	prob 2.826 (2.826)	GS 33.188 (33.188)	mem 39.587
Train: [55][125/750]	BT 0.022 (1.314)	DT 0.001 (1.275)	loss 6.764 (6.764)	prob 2.672 (2.672)	GS 34.125 (34.125)	mem 39.664
Train: [55][130/750]	BT 0.074 (1.267)	DT 0.037 (1.226)	loss 7.097 (7.097)	prob 2.424 (2.424)	GS 30.344 (30.344)	mem 39.666
Train: [55][135/750]	BT 0.029 (1.221)	DT 0.001 (1.181)	loss 6.909 (6.909)	prob 2.404 (2.404)	GS 29.375 (29.375)	mem 39.665
Train: [55][140/750]	BT 0.284 (1.256)	DT 0.220 (1.216)	loss 6.671 (6.671)	prob 2.585 (2.585)	GS 35.156 (35.156)	mem 39.829
Train: [55][145/750]	BT 0.031 (1.215)	DT 0.001 (1.174)	loss 6.958 (6.958)	prob 2.325 (2.325)	GS 31.156 (31.156)	mem 39.684
Train: [55][150/750]	BT 0.031 (1.261)	DT 0.001 (1.220)	loss 6.787 (6.787)	prob 3.106 (3.106)	GS 35.031 (35.031)	mem 39.587
Train: [55][155/750]	BT 0.029 (1.221)	DT 0.002 (1.181)	loss 6.815 (6.815)	prob 1.814 (1.814)	GS 29.922 (29.922)	mem 39.588
Train: [55][160/750]	BT 15.037 (1.279)	DT 15.004 (1.238)	loss 6.803 (6.803)	prob 2.394 (2.394)	GS 32.109 (32.109)	mem 39.673
Train: [55][165/750]	BT 0.045 (1.241)	DT 0.017 (1.201)	loss 7.206 (7.206)	prob 1.975 (1.975)	GS 32.000 (32.000)	mem 39.673
Train: [55][170/750]	BT 0.037 (1.206)	DT 0.004 (1.166)	loss 6.900 (6.900)	prob 2.374 (2.374)	GS 35.109 (35.109)	mem 39.675
Train: [55][175/750]	BT 0.048 (1.239)	DT 0.002 (1.198)	loss 7.209 (7.209)	prob 1.982 (1.982)	GS 35.719 (35.719)	mem 39.736
Train: [55][180/750]	BT 0.045 (1.205)	DT 0.004 (1.165)	loss 6.944 (6.944)	prob 2.581 (2.581)	GS 33.922 (33.922)	mem 39.772
Train: [55][185/750]	BT 0.062 (1.242)	DT 0.001 (1.202)	loss 6.925 (6.925)	prob 2.488 (2.488)	GS 33.078 (33.078)	mem 39.782
Train: [55][190/750]	BT 0.047 (1.211)	DT 0.011 (1.171)	loss 6.892 (6.892)	prob 1.984 (1.984)	GS 36.438 (36.438)	mem 39.689
Train: [55][195/750]	BT 0.029 (1.181)	DT 0.001 (1.141)	loss 6.829 (6.829)	prob 2.509 (2.509)	GS 32.312 (32.312)	mem 39.762
Train: [55][200/750]	BT 0.036 (1.212)	DT 0.008 (1.172)	loss 6.728 (6.728)	prob 2.710 (2.710)	GS 32.406 (32.406)	mem 39.738
Train: [55][205/750]	BT 0.049 (1.183)	DT 0.002 (1.143)	loss 7.061 (7.061)	prob 2.772 (2.772)	GS 33.609 (33.609)	mem 39.737
Train: [55][210/750]	BT 0.031 (1.218)	DT 0.001 (1.179)	loss 6.830 (6.830)	prob 2.437 (2.437)	GS 35.312 (35.312)	mem 39.807
Train: [55][215/750]	BT 0.041 (1.191)	DT 0.015 (1.151)	loss 6.664 (6.664)	prob 3.273 (3.273)	GS 33.938 (33.938)	mem 39.806
Train: [55][220/750]	BT 15.430 (1.235)	DT 15.377 (1.195)	loss 6.817 (6.817)	prob 1.808 (1.808)	GS 35.812 (35.812)	mem 39.875
Train: [55][225/750]	BT 0.043 (1.208)	DT 0.001 (1.169)	loss 6.925 (6.925)	prob 2.147 (2.147)	GS 29.766 (29.766)	mem 39.792
Train: [55][230/750]	BT 0.030 (1.183)	DT 0.001 (1.143)	loss 6.981 (6.981)	prob 2.241 (2.241)	GS 34.281 (34.281)	mem 39.794
Train: [55][235/750]	BT 0.031 (1.203)	DT 0.003 (1.164)	loss 6.899 (6.899)	prob 2.284 (2.284)	GS 26.312 (26.312)	mem 39.743
Train: [55][240/750]	BT 0.034 (1.180)	DT 0.002 (1.140)	loss 6.939 (6.939)	prob 1.722 (1.722)	GS 33.016 (33.016)	mem 39.743
Train: [55][245/750]	BT 0.030 (1.217)	DT 0.001 (1.176)	loss 7.017 (7.017)	prob 2.100 (2.100)	GS 33.531 (33.531)	mem 39.792
Train: [55][250/750]	BT 0.041 (1.193)	DT 0.006 (1.153)	loss 6.838 (6.838)	prob 2.107 (2.107)	GS 33.688 (33.688)	mem 39.792
Train: [55][255/750]	BT 0.035 (1.170)	DT 0.001 (1.130)	loss 6.865 (6.865)	prob 1.897 (1.897)	GS 33.625 (33.625)	mem 39.794
Train: [55][260/750]	BT 0.029 (1.196)	DT 0.001 (1.156)	loss 6.830 (6.830)	prob 1.926 (1.926)	GS 36.344 (36.344)	mem 39.834
Train: [55][265/750]	BT 0.051 (1.174)	DT 0.001 (1.134)	loss 6.942 (6.942)	prob 2.186 (2.186)	GS 31.922 (31.922)	mem 39.959
Train: [55][270/750]	BT 0.041 (1.197)	DT 0.001 (1.158)	loss 6.892 (6.892)	prob 2.090 (2.090)	GS 33.453 (33.453)	mem 39.970
Train: [55][275/750]	BT 0.055 (1.176)	DT 0.001 (1.137)	loss 7.213 (7.213)	prob 2.383 (2.383)	GS 30.562 (30.562)	mem 39.918
Train: [55][280/750]	BT 11.773 (1.198)	DT 11.725 (1.158)	loss 6.946 (6.946)	prob 1.788 (1.788)	GS 31.781 (31.781)	mem 39.923
Train: [55][285/750]	BT 0.058 (1.178)	DT 0.008 (1.138)	loss 7.150 (7.150)	prob 1.881 (1.881)	GS 32.484 (32.484)	mem 39.903
Train: [55][290/750]	BT 0.119 (1.161)	DT 0.012 (1.121)	loss 6.890 (6.890)	prob 1.748 (1.748)	GS 33.156 (33.156)	mem 39.903
Train: [55][295/750]	BT 0.035 (1.183)	DT 0.001 (1.142)	loss 6.779 (6.779)	prob 1.944 (1.944)	GS 32.672 (32.672)	mem 40.045
Train: [55][300/750]	BT 0.025 (1.167)	DT 0.001 (1.126)	loss 7.099 (7.099)	prob 1.902 (1.902)	GS 31.938 (31.938)	mem 39.904
Train: [55][305/750]	BT 0.028 (1.187)	DT 0.001 (1.146)	loss 7.089 (7.089)	prob 2.029 (2.029)	GS 30.156 (30.156)	mem 39.949
Train: [55][310/750]	BT 1.627 (1.174)	DT 1.584 (1.132)	loss 7.210 (7.210)	prob 2.066 (2.066)	GS 31.906 (31.906)	mem 39.963
Train: [55][315/750]	BT 0.070 (1.163)	DT 0.009 (1.122)	loss 7.020 (7.020)	prob 2.725 (2.725)	GS 31.656 (31.656)	mem 39.957
Train: [55][320/750]	BT 0.055 (1.170)	DT 0.008 (1.129)	loss 6.831 (6.831)	prob 2.803 (2.803)	GS 35.453 (35.453)	mem 39.908
Train: [55][325/750]	BT 0.031 (1.161)	DT 0.001 (1.120)	loss 7.225 (7.225)	prob 2.018 (2.018)	GS 28.125 (28.125)	mem 39.918
Train: [55][330/750]	BT 0.083 (1.176)	DT 0.012 (1.134)	loss 6.870 (6.870)	prob 2.185 (2.185)	GS 33.359 (33.359)	mem 39.910
Train: [55][335/750]	BT 0.037 (1.163)	DT 0.002 (1.121)	loss 7.055 (7.055)	prob 2.232 (2.232)	GS 29.188 (29.188)	mem 39.881
Train: [55][340/750]	BT 9.221 (1.184)	DT 9.185 (1.142)	loss 6.954 (6.954)	prob 2.042 (2.042)	GS 30.484 (30.484)	mem 39.845
Train: [55][345/750]	BT 0.073 (1.167)	DT 0.001 (1.125)	loss 7.283 (7.283)	prob 2.098 (2.098)	GS 30.453 (30.453)	mem 39.877
Train: [55][350/750]	BT 5.301 (1.168)	DT 5.269 (1.126)	loss 6.920 (6.920)	prob 2.213 (2.213)	GS 32.094 (32.094)	mem 39.786
Train: [55][355/750]	BT 0.031 (1.172)	DT 0.001 (1.130)	loss 7.030 (7.030)	prob 2.314 (2.314)	GS 33.219 (33.219)	mem 39.697
Train: [55][360/750]	BT 0.031 (1.157)	DT 0.001 (1.115)	loss 7.023 (7.023)	prob 2.236 (2.236)	GS 31.141 (31.141)	mem 39.706
Train: [55][365/750]	BT 0.041 (1.168)	DT 0.001 (1.126)	loss 6.919 (6.919)	prob 2.018 (2.018)	GS 34.562 (34.562)	mem 39.949
Train: [55][370/750]	BT 2.114 (1.159)	DT 2.071 (1.117)	loss 6.812 (6.812)	prob 1.971 (1.971)	GS 31.156 (31.156)	mem 39.832
Train: [55][375/750]	BT 0.035 (1.159)	DT 0.002 (1.117)	loss 6.808 (6.808)	prob 2.336 (2.336)	GS 30.641 (30.641)	mem 39.886
Train: [55][380/750]	BT 0.108 (1.168)	DT 0.015 (1.125)	loss 6.992 (6.992)	prob 1.870 (1.870)	GS 32.266 (32.266)	mem 39.891
Train: [55][385/750]	BT 0.023 (1.153)	DT 0.001 (1.111)	loss 6.925 (6.925)	prob 1.841 (1.841)	GS 27.688 (27.688)	mem 39.893
Train: [55][390/750]	BT 0.025 (1.170)	DT 0.001 (1.128)	loss 6.771 (6.771)	prob 1.890 (1.890)	GS 34.719 (34.719)	mem 39.841
Train: [55][395/750]	BT 0.129 (1.156)	DT 0.010 (1.114)	loss 6.902 (6.902)	prob 2.158 (2.158)	GS 29.516 (29.516)	mem 39.901
Train: [55][400/750]	BT 10.575 (1.180)	DT 10.527 (1.137)	loss 6.974 (6.974)	prob 2.393 (2.393)	GS 32.438 (32.438)	mem 39.834
Train: [55][405/750]	BT 0.031 (1.166)	DT 0.001 (1.123)	loss 6.841 (6.841)	prob 2.064 (2.064)	GS 30.156 (30.156)	mem 39.834
Train: [55][410/750]	BT 2.943 (1.159)	DT 2.894 (1.116)	loss 6.972 (6.972)	prob 2.349 (2.349)	GS 35.344 (35.344)	mem 39.992
Train: [55][415/750]	BT 0.034 (1.162)	DT 0.002 (1.119)	loss 6.891 (6.891)	prob 3.325 (3.325)	GS 37.141 (37.141)	mem 39.839
Train: [55][420/750]	BT 0.031 (1.150)	DT 0.001 (1.107)	loss 7.082 (7.082)	prob 2.560 (2.560)	GS 30.375 (30.375)	mem 39.789
Train: [55][425/750]	BT 0.029 (1.165)	DT 0.001 (1.122)	loss 7.258 (7.258)	prob 2.406 (2.406)	GS 32.516 (32.516)	mem 39.801
Train: [55][430/750]	BT 0.046 (1.156)	DT 0.001 (1.113)	loss 6.911 (6.911)	prob 2.752 (2.752)	GS 30.984 (30.984)	mem 39.782
Train: [55][435/750]	BT 0.065 (1.151)	DT 0.002 (1.108)	loss 6.670 (6.670)	prob 2.810 (2.810)	GS 30.562 (30.562)	mem 39.749
Train: [55][440/750]	BT 0.033 (1.161)	DT 0.001 (1.118)	loss 6.891 (6.891)	prob 2.073 (2.073)	GS 31.828 (31.828)	mem 39.824
Train: [55][445/750]	BT 0.032 (1.148)	DT 0.001 (1.106)	loss 6.644 (6.644)	prob 2.544 (2.544)	GS 28.891 (28.891)	mem 39.850
Train: [55][450/750]	BT 0.107 (1.163)	DT 0.004 (1.120)	loss 6.921 (6.921)	prob 2.701 (2.701)	GS 32.938 (32.938)	mem 39.921
Train: [55][455/750]	BT 0.114 (1.151)	DT 0.015 (1.108)	loss 7.096 (7.096)	prob 1.924 (1.924)	GS 33.891 (33.891)	mem 39.871
Train: [55][460/750]	BT 6.413 (1.163)	DT 6.383 (1.120)	loss 6.785 (6.785)	prob 2.615 (2.615)	GS 35.078 (35.078)	mem 39.803
Train: [55][465/750]	BT 0.026 (1.151)	DT 0.002 (1.108)	loss 7.072 (7.072)	prob 2.472 (2.472)	GS 29.016 (29.016)	mem 39.802
Train: [55][470/750]	BT 4.930 (1.150)	DT 4.895 (1.107)	loss 6.706 (6.706)	prob 2.511 (2.511)	GS 31.938 (31.938)	mem 39.870
Train: [55][475/750]	BT 0.090 (1.156)	DT 0.016 (1.113)	loss 6.874 (6.874)	prob 2.778 (2.778)	GS 31.453 (31.453)	mem 39.887
Train: [55][480/750]	BT 0.053 (1.145)	DT 0.012 (1.102)	loss 6.848 (6.848)	prob 2.798 (2.798)	GS 29.828 (29.828)	mem 39.888
Train: [55][485/750]	BT 0.086 (1.157)	DT 0.008 (1.114)	loss 6.740 (6.740)	prob 2.753 (2.753)	GS 43.969 (43.969)	mem 40.139
Train: [55][490/750]	BT 0.057 (1.146)	DT 0.007 (1.102)	loss 6.967 (6.967)	prob 2.650 (2.650)	GS 32.938 (32.938)	mem 39.906
Train: [55][495/750]	BT 0.057 (1.157)	DT 0.007 (1.114)	loss 7.150 (7.150)	prob 2.377 (2.377)	GS 32.734 (32.734)	mem 40.143
Train: [55][500/750]	BT 0.083 (1.155)	DT 0.001 (1.111)	loss 6.913 (6.913)	prob 2.769 (2.769)	GS 33.812 (33.812)	mem 39.916
Train: [55][505/750]	BT 0.057 (1.144)	DT 0.007 (1.100)	loss 6.747 (6.747)	prob 2.880 (2.880)	GS 26.641 (26.641)	mem 39.917
Train: [55][510/750]	BT 0.045 (1.161)	DT 0.004 (1.117)	loss 7.035 (7.035)	prob 1.896 (1.896)	GS 32.688 (32.688)	mem 39.924
Train: [55][515/750]	BT 0.049 (1.150)	DT 0.008 (1.107)	loss 7.516 (7.516)	prob 2.026 (2.026)	GS 31.719 (31.719)	mem 39.925
Train: [55][520/750]	BT 8.561 (1.164)	DT 8.520 (1.120)	loss 6.936 (6.936)	prob 2.840 (2.840)	GS 32.547 (32.547)	mem 39.866
Train: [55][525/750]	BT 0.028 (1.153)	DT 0.001 (1.109)	loss 7.102 (7.102)	prob 2.518 (2.518)	GS 33.766 (33.766)	mem 39.866
Train: [55][530/750]	BT 4.966 (1.153)	DT 4.922 (1.109)	loss 6.867 (6.867)	prob 1.937 (1.937)	GS 31.531 (31.531)	mem 39.906
Train: [55][535/750]	BT 0.028 (1.157)	DT 0.001 (1.113)	loss 6.943 (6.943)	prob 2.617 (2.617)	GS 31.984 (31.984)	mem 39.854
Train: [55][540/750]	BT 0.033 (1.147)	DT 0.002 (1.103)	loss 6.958 (6.958)	prob 2.217 (2.217)	GS 32.250 (32.250)	mem 39.970
Train: [55][545/750]	BT 0.133 (1.159)	DT 0.008 (1.115)	loss 7.277 (7.277)	prob 1.972 (1.972)	GS 28.484 (28.484)	mem 39.900
Train: [55][550/750]	BT 0.037 (1.149)	DT 0.001 (1.105)	loss 7.027 (7.027)	prob 2.805 (2.805)	GS 34.250 (34.250)	mem 39.860
Train: [55][555/750]	BT 0.040 (1.149)	DT 0.002 (1.105)	loss 6.935 (6.935)	prob 2.547 (2.547)	GS 31.562 (31.562)	mem 39.809
Train: [55][560/750]	BT 0.030 (1.145)	DT 0.001 (1.101)	loss 6.887 (6.887)	prob 2.353 (2.353)	GS 31.219 (31.219)	mem 39.885
Train: [55][565/750]	BT 0.038 (1.135)	DT 0.001 (1.092)	loss 7.065 (7.065)	prob 2.536 (2.536)	GS 33.453 (33.453)	mem 39.901
Train: [55][570/750]	BT 0.034 (1.148)	DT 0.003 (1.105)	loss 6.953 (6.953)	prob 2.348 (2.348)	GS 33.594 (33.594)	mem 39.879
Train: [55][575/750]	BT 0.108 (1.139)	DT 0.004 (1.095)	loss 7.152 (7.152)	prob 2.564 (2.564)	GS 32.250 (32.250)	mem 39.847
Train: [55][580/750]	BT 2.295 (1.152)	DT 2.265 (1.108)	loss 6.824 (6.824)	prob 1.850 (1.850)	GS 34.688 (34.688)	mem 40.065
Train: [55][585/750]	BT 0.046 (1.142)	DT 0.004 (1.099)	loss 6.829 (6.829)	prob 2.427 (2.427)	GS 29.016 (29.016)	mem 39.862
Train: [55][590/750]	BT 14.844 (1.158)	DT 14.816 (1.115)	loss 6.900 (6.900)	prob 2.868 (2.868)	GS 33.766 (33.766)	mem 39.896
Train: [55][595/750]	BT 0.076 (1.149)	DT 0.001 (1.105)	loss 6.861 (6.861)	prob 2.563 (2.563)	GS 30.406 (30.406)	mem 39.905
Train: [55][600/750]	BT 0.032 (1.140)	DT 0.001 (1.096)	loss 7.075 (7.075)	prob 2.764 (2.764)	GS 32.109 (32.109)	mem 39.844
Train: [55][605/750]	BT 0.032 (1.151)	DT 0.002 (1.108)	loss 6.749 (6.749)	prob 2.558 (2.558)	GS 31.750 (31.750)	mem 40.076
Train: [55][610/750]	BT 0.039 (1.142)	DT 0.001 (1.099)	loss 6.866 (6.866)	prob 2.686 (2.686)	GS 34.703 (34.703)	mem 39.944
Train: [55][615/750]	BT 0.046 (1.155)	DT 0.007 (1.112)	loss 6.847 (6.847)	prob 2.815 (2.815)	GS 32.812 (32.812)	mem 39.919
Train: [55][620/750]	BT 0.054 (1.146)	DT 0.016 (1.103)	loss 7.195 (7.195)	prob 1.852 (1.852)	GS 36.984 (36.984)	mem 39.951
Train: [55][625/750]	BT 0.087 (1.137)	DT 0.007 (1.094)	loss 6.857 (6.857)	prob 2.594 (2.594)	GS 34.328 (34.328)	mem 40.116
Train: [55][630/750]	BT 0.050 (1.147)	DT 0.001 (1.104)	loss 6.767 (6.767)	prob 2.630 (2.630)	GS 34.672 (34.672)	mem 40.021
Train: [55][635/750]	BT 0.032 (1.138)	DT 0.001 (1.095)	loss 7.036 (7.036)	prob 2.046 (2.046)	GS 33.297 (33.297)	mem 39.928
Train: [55][640/750]	BT 0.059 (1.152)	DT 0.010 (1.109)	loss 7.012 (7.012)	prob 2.069 (2.069)	GS 34.516 (34.516)	mem 40.322
Train: [55][645/750]	BT 0.029 (1.144)	DT 0.002 (1.101)	loss 7.133 (7.133)	prob 2.628 (2.628)	GS 38.656 (38.656)	mem 40.074
Train: [55][650/750]	BT 12.313 (1.154)	DT 12.290 (1.111)	loss 6.718 (6.718)	prob 2.452 (2.452)	GS 33.656 (33.656)	mem 39.885
Train: [55][655/750]	BT 0.032 (1.146)	DT 0.001 (1.103)	loss 6.836 (6.836)	prob 2.844 (2.844)	GS 34.750 (34.750)	mem 39.885
arpack error, retry= 0
Train: [55][660/750]	BT 0.033 (1.137)	DT 0.002 (1.094)	loss 6.947 (6.947)	prob 2.115 (2.115)	GS 35.078 (35.078)	mem 39.886
Train: [55][665/750]	BT 0.066 (1.149)	DT 0.010 (1.106)	loss 6.588 (6.588)	prob 3.380 (3.380)	GS 33.047 (33.047)	mem 40.022
Train: [55][670/750]	BT 0.070 (1.141)	DT 0.005 (1.098)	loss 6.569 (6.569)	prob 2.877 (2.877)	GS 35.250 (35.250)	mem 39.929
Train: [55][675/750]	BT 0.035 (1.149)	DT 0.002 (1.106)	loss 6.616 (6.616)	prob 2.934 (2.934)	GS 39.500 (39.500)	mem 39.969
Train: [55][680/750]	BT 0.025 (1.141)	DT 0.001 (1.098)	loss 6.744 (6.744)	prob 2.572 (2.572)	GS 37.109 (37.109)	mem 39.968
Train: [55][685/750]	BT 0.031 (1.133)	DT 0.001 (1.090)	loss 7.011 (7.011)	prob 2.467 (2.467)	GS 26.500 (26.500)	mem 40.105
Train: [55][690/750]	BT 0.032 (1.150)	DT 0.002 (1.107)	loss 6.854 (6.854)	prob 3.352 (3.352)	GS 32.641 (32.641)	mem 39.875
Train: [55][695/750]	BT 0.035 (1.142)	DT 0.001 (1.099)	loss 6.538 (6.538)	prob 3.155 (3.155)	GS 31.328 (31.328)	mem 39.951
Train: [55][700/750]	BT 0.057 (1.152)	DT 0.010 (1.109)	loss 6.905 (6.905)	prob 2.956 (2.956)	GS 35.328 (35.328)	mem 39.921
Train: [55][705/750]	BT 0.029 (1.144)	DT 0.001 (1.101)	loss 6.794 (6.794)	prob 2.953 (2.953)	GS 35.594 (35.594)	mem 39.922
Train: [55][710/750]	BT 14.551 (1.157)	DT 14.484 (1.114)	loss 6.925 (6.925)	prob 2.197 (2.197)	GS 35.516 (35.516)	mem 40.082
Train: [55][715/750]	BT 0.063 (1.149)	DT 0.001 (1.106)	loss 6.941 (6.941)	prob 2.559 (2.559)	GS 28.906 (28.906)	mem 39.981
Train: [55][720/750]	BT 0.033 (1.141)	DT 0.002 (1.099)	loss 7.093 (7.093)	prob 2.301 (2.301)	GS 33.219 (33.219)	mem 39.984
Train: [55][725/750]	BT 0.040 (1.149)	DT 0.002 (1.107)	loss 6.577 (6.577)	prob 2.977 (2.977)	GS 29.938 (29.938)	mem 39.914
Train: [55][730/750]	BT 0.072 (1.142)	DT 0.018 (1.099)	loss 6.896 (6.896)	prob 1.990 (1.990)	GS 34.625 (34.625)	mem 39.959
Train: [55][735/750]	BT 0.042 (1.148)	DT 0.002 (1.105)	loss 6.869 (6.869)	prob 2.734 (2.734)	GS 30.484 (30.484)	mem 36.552
Train: [55][740/750]	BT 0.042 (1.141)	DT 0.002 (1.098)	loss 6.720 (6.720)	prob 2.461 (2.461)	GS 33.844 (33.844)	mem 36.553
Train: [55][745/750]	BT 0.026 (1.133)	DT 0.001 (1.090)	loss 6.716 (6.716)	prob 2.927 (2.927)	GS 32.344 (32.344)	mem 36.553
Train: [55][750/750]	BT 0.025 (1.129)	DT 0.001 (1.087)	loss 6.616 (6.616)	prob 2.876 (2.876)	GS 34.031 (34.031)	mem 7.596
Train: [55][755/750]	BT 0.026 (1.122)	DT 0.001 (1.079)	loss 6.709 (6.709)	prob 2.891 (2.891)	GS 28.969 (28.969)	mem 7.596
epoch 55, total time 847.28
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [56][1/750]	BT 19.864 (19.864)	DT 19.808 (19.808)	loss 6.768 (6.768)	prob 2.933 (2.933)	GS 30.531 (30.531)	mem 38.492
Train: [56][5/750]	BT 0.032 (4.460)	DT 0.001 (4.418)	loss 6.660 (6.660)	prob 3.068 (3.068)	GS 29.547 (29.547)	mem 38.445
Train: [56][10/750]	BT 0.046 (2.360)	DT 0.002 (2.311)	loss 6.654 (6.654)	prob 3.100 (3.100)	GS 36.953 (36.953)	mem 38.746
Train: [56][15/750]	BT 2.869 (2.570)	DT 2.837 (2.522)	loss 6.549 (6.549)	prob 3.346 (3.346)	GS 33.375 (33.375)	mem 39.386
Train: [56][20/750]	BT 2.297 (2.048)	DT 2.249 (2.004)	loss 6.913 (6.913)	prob 3.230 (3.230)	GS 33.031 (33.031)	mem 39.462
Train: [56][25/750]	BT 0.587 (1.669)	DT 0.469 (1.622)	loss 6.757 (6.757)	prob 2.995 (2.995)	GS 32.906 (32.906)	mem 39.561
Train: [56][30/750]	BT 0.035 (1.706)	DT 0.002 (1.659)	loss 6.894 (6.894)	prob 2.103 (2.103)	GS 31.203 (31.203)	mem 39.359
Train: [56][35/750]	BT 0.079 (1.641)	DT 0.017 (1.591)	loss 6.769 (6.769)	prob 2.963 (2.963)	GS 32.594 (32.594)	mem 39.499
Train: [56][40/750]	BT 0.092 (1.599)	DT 0.008 (1.544)	loss 6.702 (6.702)	prob 3.366 (3.366)	GS 32.391 (32.391)	mem 39.719
Train: [56][45/750]	BT 0.053 (1.634)	DT 0.016 (1.580)	loss 7.069 (7.069)	prob 2.901 (2.901)	GS 35.141 (35.141)	mem 39.571
Train: [56][50/750]	BT 1.981 (1.514)	DT 1.932 (1.461)	loss 6.740 (6.740)	prob 3.831 (3.831)	GS 33.859 (33.859)	mem 39.484
Train: [56][55/750]	BT 0.034 (1.408)	DT 0.002 (1.354)	loss 7.311 (7.311)	prob 3.007 (3.007)	GS 33.531 (33.531)	mem 39.536
Train: [56][60/750]	BT 0.044 (1.510)	DT 0.007 (1.458)	loss 7.009 (7.009)	prob 2.460 (2.460)	GS 33.812 (33.812)	mem 39.554
Train: [56][65/750]	BT 0.064 (1.428)	DT 0.011 (1.377)	loss 7.163 (7.163)	prob 2.429 (2.429)	GS 29.688 (29.688)	mem 39.627
Train: [56][70/750]	BT 0.105 (1.504)	DT 0.002 (1.453)	loss 6.894 (6.894)	prob 3.035 (3.035)	GS 34.719 (34.719)	mem 39.525
Train: [56][75/750]	BT 0.053 (1.417)	DT 0.002 (1.366)	loss 7.324 (7.324)	prob 2.883 (2.883)	GS 31.812 (31.812)	mem 39.562
Train: [56][80/750]	BT 12.359 (1.486)	DT 12.324 (1.435)	loss 7.146 (7.146)	prob 3.103 (3.103)	GS 34.375 (34.375)	mem 39.645
Train: [56][85/750]	BT 0.028 (1.400)	DT 0.001 (1.351)	loss 7.052 (7.052)	prob 3.218 (3.218)	GS 33.766 (33.766)	mem 39.576
Train: [56][90/750]	BT 0.070 (1.326)	DT 0.023 (1.277)	loss 7.056 (7.056)	prob 2.187 (2.187)	GS 30.328 (30.328)	mem 39.604
Train: [56][95/750]	BT 0.033 (1.393)	DT 0.002 (1.344)	loss 6.761 (6.761)	prob 3.489 (3.489)	GS 29.641 (29.641)	mem 39.705
Train: [56][100/750]	BT 0.062 (1.326)	DT 0.009 (1.277)	loss 6.876 (6.876)	prob 3.479 (3.479)	GS 31.500 (31.500)	mem 39.760
Train: [56][105/750]	BT 0.035 (1.413)	DT 0.003 (1.365)	loss 6.816 (6.816)	prob 3.134 (3.134)	GS 27.359 (27.359)	mem 39.615
Train: [56][110/750]	BT 0.376 (1.353)	DT 0.343 (1.306)	loss 7.144 (7.144)	prob 3.595 (3.595)	GS 36.250 (36.250)	mem 39.591
Train: [56][115/750]	BT 0.032 (1.297)	DT 0.001 (1.249)	loss 6.777 (6.777)	prob 3.277 (3.277)	GS 29.781 (29.781)	mem 39.591
Train: [56][120/750]	BT 0.032 (1.345)	DT 0.001 (1.298)	loss 6.914 (6.914)	prob 2.149 (2.149)	GS 31.875 (31.875)	mem 39.698
Train: [56][125/750]	BT 0.032 (1.298)	DT 0.001 (1.251)	loss 7.028 (7.028)	prob 2.722 (2.722)	GS 32.875 (32.875)	mem 39.727
Train: [56][130/750]	BT 0.024 (1.351)	DT 0.001 (1.305)	loss 6.913 (6.913)	prob 2.962 (2.962)	GS 34.094 (34.094)	mem 39.734
Train: [56][135/750]	BT 0.039 (1.304)	DT 0.001 (1.258)	loss 7.003 (7.003)	prob 2.397 (2.397)	GS 29.469 (29.469)	mem 39.818
Train: [56][140/750]	BT 12.450 (1.347)	DT 12.395 (1.301)	loss 6.990 (6.990)	prob 3.218 (3.218)	GS 32.500 (32.500)	mem 39.845
Train: [56][145/750]	BT 0.042 (1.302)	DT 0.001 (1.256)	loss 6.622 (6.622)	prob 2.808 (2.808)	GS 33.078 (33.078)	mem 39.752
Train: [56][150/750]	BT 0.074 (1.274)	DT 0.005 (1.229)	loss 7.015 (7.015)	prob 2.370 (2.370)	GS 33.734 (33.734)	mem 39.789
Train: [56][155/750]	BT 0.036 (1.311)	DT 0.001 (1.265)	loss 6.816 (6.816)	prob 2.311 (2.311)	GS 31.516 (31.516)	mem 39.827
Train: [56][160/750]	BT 0.034 (1.297)	DT 0.001 (1.252)	loss 6.611 (6.611)	prob 3.331 (3.331)	GS 35.422 (35.422)	mem 39.798
Train: [56][165/750]	BT 0.032 (1.304)	DT 0.001 (1.259)	loss 6.749 (6.749)	prob 2.449 (2.449)	GS 33.109 (33.109)	mem 39.815
Train: [56][170/750]	BT 5.939 (1.302)	DT 5.908 (1.257)	loss 7.079 (7.079)	prob 2.392 (2.392)	GS 34.531 (34.531)	mem 39.769
Train: [56][175/750]	BT 0.051 (1.266)	DT 0.012 (1.221)	loss 6.849 (6.849)	prob 2.532 (2.532)	GS 33.203 (33.203)	mem 39.781
Train: [56][180/750]	BT 0.041 (1.260)	DT 0.012 (1.216)	loss 6.802 (6.802)	prob 2.392 (2.392)	GS 34.875 (34.875)	mem 39.799
Train: [56][185/750]	BT 0.062 (1.256)	DT 0.014 (1.212)	loss 6.963 (6.963)	prob 2.021 (2.021)	GS 31.578 (31.578)	mem 39.836
Train: [56][190/750]	BT 0.062 (1.256)	DT 0.006 (1.212)	loss 7.381 (7.381)	prob 2.136 (2.136)	GS 32.344 (32.344)	mem 40.199
Train: [56][195/750]	BT 0.048 (1.253)	DT 0.008 (1.208)	loss 6.890 (6.890)	prob 1.935 (1.935)	GS 32.969 (32.969)	mem 39.926
Train: [56][200/750]	BT 0.149 (1.258)	DT 0.030 (1.213)	loss 6.816 (6.816)	prob 2.496 (2.496)	GS 33.453 (33.453)	mem 39.761
Train: [56][205/750]	BT 0.029 (1.228)	DT 0.001 (1.183)	loss 6.971 (6.971)	prob 2.017 (2.017)	GS 30.859 (30.859)	mem 39.762
Train: [56][210/750]	BT 7.710 (1.262)	DT 7.651 (1.217)	loss 7.682 (7.682)	prob 1.166 (1.166)	GS 34.281 (34.281)	mem 40.130
Train: [56][215/750]	BT 0.027 (1.242)	DT 0.001 (1.198)	loss 7.076 (7.076)	prob 2.059 (2.059)	GS 31.000 (31.000)	mem 39.915
Train: [56][220/750]	BT 0.032 (1.216)	DT 0.001 (1.171)	loss 7.098 (7.098)	prob 2.190 (2.190)	GS 29.641 (29.641)	mem 39.918
Train: [56][225/750]	BT 0.036 (1.264)	DT 0.001 (1.219)	loss 6.854 (6.854)	prob 1.520 (1.520)	GS 31.516 (31.516)	mem 39.720
Train: [56][230/750]	BT 0.026 (1.237)	DT 0.001 (1.192)	loss 7.077 (7.077)	prob 1.464 (1.464)	GS 32.219 (32.219)	mem 39.718
Train: [56][235/750]	BT 0.039 (1.259)	DT 0.006 (1.215)	loss 7.077 (7.077)	prob 2.050 (2.050)	GS 29.531 (29.531)	mem 40.054
Train: [56][240/750]	BT 0.031 (1.234)	DT 0.001 (1.189)	loss 6.986 (6.986)	prob 1.972 (1.972)	GS 34.359 (34.359)	mem 39.746
Train: [56][245/750]	BT 0.033 (1.209)	DT 0.001 (1.165)	loss 6.750 (6.750)	prob 1.735 (1.735)	GS 32.578 (32.578)	mem 39.808
Train: [56][250/750]	BT 0.033 (1.229)	DT 0.001 (1.185)	loss 7.297 (7.297)	prob 1.430 (1.430)	GS 37.031 (37.031)	mem 39.811
Train: [56][255/750]	BT 0.034 (1.213)	DT 0.001 (1.169)	loss 7.583 (7.583)	prob 1.074 (1.074)	GS 30.391 (30.391)	mem 39.824
Train: [56][260/750]	BT 0.095 (1.231)	DT 0.009 (1.187)	loss 7.217 (7.217)	prob 1.300 (1.300)	GS 35.859 (35.859)	mem 39.839
Train: [56][265/750]	BT 0.037 (1.208)	DT 0.006 (1.164)	loss 6.960 (6.960)	prob 1.489 (1.489)	GS 32.406 (32.406)	mem 39.804
Train: [56][270/750]	BT 15.350 (1.247)	DT 15.299 (1.203)	loss 7.344 (7.344)	prob 1.401 (1.401)	GS 31.266 (31.266)	mem 39.844
Train: [56][275/750]	BT 0.030 (1.225)	DT 0.001 (1.181)	loss 7.202 (7.202)	prob 1.214 (1.214)	GS 28.406 (28.406)	mem 39.846
Train: [56][280/750]	BT 0.033 (1.204)	DT 0.001 (1.160)	loss 7.102 (7.102)	prob 1.581 (1.581)	GS 33.188 (33.188)	mem 39.847
Train: [56][285/750]	BT 0.053 (1.229)	DT 0.001 (1.185)	loss 7.097 (7.097)	prob 1.471 (1.471)	GS 31.594 (31.594)	mem 39.842
Train: [56][290/750]	BT 0.068 (1.209)	DT 0.020 (1.165)	loss 7.176 (7.176)	prob 1.125 (1.125)	GS 39.406 (39.406)	mem 39.843
Train: [56][295/750]	BT 0.038 (1.232)	DT 0.002 (1.188)	loss 6.908 (6.908)	prob 1.653 (1.653)	GS 30.688 (30.688)	mem 39.867
Train: [56][300/750]	BT 0.695 (1.214)	DT 0.641 (1.170)	loss 7.585 (7.585)	prob 1.615 (1.615)	GS 38.375 (38.375)	mem 39.871
Train: [56][305/750]	BT 0.081 (1.198)	DT 0.015 (1.153)	loss 7.216 (7.216)	prob 1.309 (1.309)	GS 30.406 (30.406)	mem 39.855
Train: [56][310/750]	BT 0.032 (1.210)	DT 0.002 (1.165)	loss 7.125 (7.125)	prob 1.974 (1.974)	GS 35.656 (35.656)	mem 39.948
Train: [56][315/750]	BT 0.046 (1.208)	DT 0.015 (1.163)	loss 7.465 (7.465)	prob 1.556 (1.556)	GS 30.328 (30.328)	mem 39.925
Train: [56][320/750]	BT 0.039 (1.220)	DT 0.002 (1.175)	loss 7.855 (7.855)	prob 1.096 (1.096)	GS 36.859 (36.859)	mem 39.896
Train: [56][325/750]	BT 0.067 (1.215)	DT 0.024 (1.170)	loss 7.647 (7.647)	prob 1.189 (1.189)	GS 32.781 (32.781)	mem 39.968
Train: [56][330/750]	BT 7.735 (1.220)	DT 7.703 (1.176)	loss 7.281 (7.281)	prob 1.991 (1.991)	GS 34.281 (34.281)	mem 39.964
Train: [56][335/750]	BT 0.054 (1.203)	DT 0.007 (1.158)	loss 7.420 (7.420)	prob 0.961 (0.961)	GS 32.469 (32.469)	mem 39.862
Train: [56][340/750]	BT 0.115 (1.204)	DT 0.011 (1.159)	loss 7.653 (7.653)	prob 2.155 (2.155)	GS 33.562 (33.562)	mem 39.789
Train: [56][345/750]	BT 0.023 (1.206)	DT 0.001 (1.161)	loss 6.793 (6.793)	prob 2.443 (2.443)	GS 32.062 (32.062)	mem 39.885
Train: [56][350/750]	BT 0.054 (1.206)	DT 0.005 (1.161)	loss 7.468 (7.468)	prob 2.175 (2.175)	GS 30.234 (30.234)	mem 40.111
Train: [56][355/750]	BT 0.044 (1.218)	DT 0.001 (1.172)	loss 7.737 (7.737)	prob 1.218 (1.218)	GS 31.578 (31.578)	mem 39.902
Train: [56][360/750]	BT 1.776 (1.206)	DT 1.745 (1.161)	loss 7.236 (7.236)	prob 1.928 (1.928)	GS 29.391 (29.391)	mem 39.901
Train: [56][365/750]	BT 0.129 (1.191)	DT 0.038 (1.145)	loss 7.493 (7.493)	prob 1.686 (1.686)	GS 34.859 (34.859)	mem 39.901
Train: [56][370/750]	BT 0.041 (1.202)	DT 0.002 (1.156)	loss 7.582 (7.582)	prob 2.663 (2.663)	GS 33.562 (33.562)	mem 39.843
Train: [56][375/750]	BT 0.102 (1.189)	DT 0.012 (1.143)	loss 7.257 (7.257)	prob 2.186 (2.186)	GS 30.078 (30.078)	mem 39.880
Train: [56][380/750]	BT 0.053 (1.203)	DT 0.003 (1.157)	loss 7.196 (7.196)	prob 2.418 (2.418)	GS 33.578 (33.578)	mem 40.047
Train: [56][385/750]	BT 0.038 (1.191)	DT 0.010 (1.145)	loss 7.469 (7.469)	prob 1.665 (1.665)	GS 32.312 (32.312)	mem 39.827
Train: [56][390/750]	BT 12.241 (1.207)	DT 12.194 (1.161)	loss 7.796 (7.796)	prob 2.375 (2.375)	GS 34.156 (34.156)	mem 39.842
Train: [56][395/750]	BT 0.132 (1.193)	DT 0.011 (1.147)	loss 7.100 (7.100)	prob 1.605 (1.605)	GS 29.500 (29.500)	mem 39.843
Train: [56][400/750]	BT 0.037 (1.179)	DT 0.001 (1.132)	loss 7.159 (7.159)	prob 2.370 (2.370)	GS 34.203 (34.203)	mem 39.845
Train: [56][405/750]	BT 0.087 (1.197)	DT 0.001 (1.151)	loss 7.488 (7.488)	prob 1.555 (1.555)	GS 33.391 (33.391)	mem 39.853
Train: [56][410/750]	BT 0.112 (1.183)	DT 0.001 (1.137)	loss 7.420 (7.420)	prob 2.750 (2.750)	GS 30.453 (30.453)	mem 39.901
Train: [56][415/750]	BT 0.035 (1.201)	DT 0.002 (1.155)	loss 7.158 (7.158)	prob 2.403 (2.403)	GS 31.875 (31.875)	mem 39.885
Train: [56][420/750]	BT 0.052 (1.187)	DT 0.012 (1.141)	loss 7.026 (7.026)	prob 3.068 (3.068)	GS 28.859 (28.859)	mem 39.887
Train: [56][425/750]	BT 0.042 (1.174)	DT 0.004 (1.128)	loss 7.034 (7.034)	prob 2.475 (2.475)	GS 30.797 (30.797)	mem 39.957
Train: [56][430/750]	BT 0.053 (1.188)	DT 0.011 (1.142)	loss 7.401 (7.401)	prob 2.168 (2.168)	GS 33.234 (33.234)	mem 40.099
Train: [56][435/750]	BT 0.034 (1.175)	DT 0.002 (1.129)	loss 7.270 (7.270)	prob 2.427 (2.427)	GS 30.078 (30.078)	mem 39.950
Train: [56][440/750]	BT 0.021 (1.191)	DT 0.001 (1.145)	loss 7.534 (7.534)	prob 2.052 (2.052)	GS 37.328 (37.328)	mem 39.884
Train: [56][445/750]	BT 0.052 (1.178)	DT 0.012 (1.132)	loss 7.489 (7.489)	prob 2.882 (2.882)	GS 28.938 (28.938)	mem 39.976
Train: [56][450/750]	BT 10.958 (1.190)	DT 10.927 (1.144)	loss 7.173 (7.173)	prob 3.010 (3.010)	GS 33.922 (33.922)	mem 39.950
Train: [56][455/750]	BT 0.041 (1.179)	DT 0.004 (1.133)	loss 7.347 (7.347)	prob 2.775 (2.775)	GS 32.703 (32.703)	mem 39.892
Train: [56][460/750]	BT 0.032 (1.167)	DT 0.002 (1.121)	loss 7.874 (7.874)	prob 2.249 (2.249)	GS 31.609 (31.609)	mem 39.894
Train: [56][465/750]	BT 0.037 (1.190)	DT 0.005 (1.145)	loss 7.373 (7.373)	prob 2.285 (2.285)	GS 29.328 (29.328)	mem 39.928
Train: [56][470/750]	BT 0.043 (1.178)	DT 0.001 (1.132)	loss 7.502 (7.502)	prob 2.330 (2.330)	GS 33.750 (33.750)	mem 39.934
Train: [56][475/750]	BT 0.078 (1.189)	DT 0.006 (1.143)	loss 7.176 (7.176)	prob 2.655 (2.655)	GS 28.375 (28.375)	mem 39.965
Train: [56][480/750]	BT 0.032 (1.177)	DT 0.001 (1.131)	loss 8.200 (8.200)	prob 2.252 (2.252)	GS 31.016 (31.016)	mem 39.965
Train: [56][485/750]	BT 0.123 (1.166)	DT 0.005 (1.120)	loss 7.557 (7.557)	prob 2.135 (2.135)	GS 29.797 (29.797)	mem 40.098
Train: [56][490/750]	BT 0.028 (1.179)	DT 0.001 (1.133)	loss 7.141 (7.141)	prob 2.493 (2.493)	GS 33.609 (33.609)	mem 39.968
Train: [56][495/750]	BT 0.024 (1.168)	DT 0.001 (1.122)	loss 7.017 (7.017)	prob 2.880 (2.880)	GS 29.812 (29.812)	mem 39.969
Train: [56][500/750]	BT 0.033 (1.180)	DT 0.002 (1.134)	loss 7.351 (7.351)	prob 2.798 (2.798)	GS 36.562 (36.562)	mem 39.919
Train: [56][505/750]	BT 0.031 (1.169)	DT 0.001 (1.123)	loss 7.257 (7.257)	prob 2.602 (2.602)	GS 32.922 (32.922)	mem 39.918
Train: [56][510/750]	BT 11.172 (1.179)	DT 11.126 (1.133)	loss 7.669 (7.669)	prob 2.604 (2.604)	GS 30.328 (30.328)	mem 39.956
Train: [56][515/750]	BT 0.030 (1.168)	DT 0.001 (1.122)	loss 7.327 (7.327)	prob 2.414 (2.414)	GS 31.469 (31.469)	mem 39.958
Train: [56][520/750]	BT 0.031 (1.160)	DT 0.004 (1.114)	loss 7.098 (7.098)	prob 3.173 (3.173)	GS 30.484 (30.484)	mem 39.891
Train: [56][525/750]	BT 0.032 (1.166)	DT 0.001 (1.120)	loss 7.999 (7.999)	prob 2.214 (2.214)	GS 34.531 (34.531)	mem 39.858
Train: [56][530/750]	BT 3.540 (1.163)	DT 3.508 (1.116)	loss 7.207 (7.207)	prob 2.496 (2.496)	GS 30.547 (30.547)	mem 39.908
Train: [56][535/750]	BT 0.151 (1.170)	DT 0.002 (1.124)	loss 7.400 (7.400)	prob 2.705 (2.705)	GS 31.875 (31.875)	mem 39.982
Train: [56][540/750]	BT 0.059 (1.161)	DT 0.012 (1.114)	loss 7.474 (7.474)	prob 2.112 (2.112)	GS 37.359 (37.359)	mem 40.032
Train: [56][545/750]	BT 0.046 (1.159)	DT 0.006 (1.113)	loss 7.276 (7.276)	prob 1.616 (1.616)	GS 33.312 (33.312)	mem 39.937
Train: [56][550/750]	BT 4.873 (1.170)	DT 4.828 (1.124)	loss 7.481 (7.481)	prob 2.867 (2.867)	GS 39.516 (39.516)	mem 40.116
Train: [56][555/750]	BT 0.081 (1.163)	DT 0.008 (1.116)	loss 7.361 (7.361)	prob 2.482 (2.482)	GS 32.391 (32.391)	mem 39.979
Train: [56][560/750]	BT 0.038 (1.163)	DT 0.001 (1.116)	loss 7.448 (7.448)	prob 3.072 (3.072)	GS 35.531 (35.531)	mem 39.983
Train: [56][565/750]	BT 0.036 (1.160)	DT 0.002 (1.113)	loss 7.386 (7.386)	prob 2.480 (2.480)	GS 26.703 (26.703)	mem 40.068
Train: [56][570/750]	BT 8.296 (1.167)	DT 8.200 (1.120)	loss 7.348 (7.348)	prob 3.193 (3.193)	GS 33.078 (33.078)	mem 40.011
Train: [56][575/750]	BT 0.025 (1.164)	DT 0.003 (1.117)	loss 7.588 (7.588)	prob 2.774 (2.774)	GS 29.734 (29.734)	mem 39.958
Train: [56][580/750]	BT 0.098 (1.154)	DT 0.004 (1.107)	loss 7.138 (7.138)	prob 3.562 (3.562)	GS 39.547 (39.547)	mem 40.140
Train: [56][585/750]	BT 0.026 (1.163)	DT 0.001 (1.116)	loss 6.985 (6.985)	prob 2.767 (2.767)	GS 37.125 (37.125)	mem 39.944
Train: [56][590/750]	BT 0.127 (1.158)	DT 0.011 (1.111)	loss 7.231 (7.231)	prob 2.467 (2.467)	GS 36.422 (36.422)	mem 39.944
Train: [56][595/750]	BT 0.039 (1.163)	DT 0.001 (1.116)	loss 7.256 (7.256)	prob 2.998 (2.998)	GS 29.672 (29.672)	mem 39.990
Train: [56][600/750]	BT 1.157 (1.158)	DT 1.123 (1.110)	loss 7.154 (7.154)	prob 3.085 (3.085)	GS 34.719 (34.719)	mem 40.003
Train: [56][605/750]	BT 0.031 (1.148)	DT 0.001 (1.101)	loss 6.823 (6.823)	prob 3.874 (3.874)	GS 29.906 (29.906)	mem 40.003
Train: [56][610/750]	BT 5.216 (1.163)	DT 5.175 (1.116)	loss 7.350 (7.350)	prob 2.830 (2.830)	GS 35.750 (35.750)	mem 39.891
Train: [56][615/750]	BT 0.083 (1.154)	DT 0.025 (1.107)	loss 7.353 (7.353)	prob 2.934 (2.934)	GS 33.234 (33.234)	mem 39.912
Train: [56][620/750]	BT 0.035 (1.152)	DT 0.001 (1.105)	loss 7.277 (7.277)	prob 3.492 (3.492)	GS 29.609 (29.609)	mem 39.954
Train: [56][625/750]	BT 0.038 (1.158)	DT 0.001 (1.111)	loss 7.070 (7.070)	prob 3.042 (3.042)	GS 29.688 (29.688)	mem 39.994
Train: [56][630/750]	BT 4.680 (1.157)	DT 4.628 (1.109)	loss 7.358 (7.358)	prob 3.386 (3.386)	GS 36.438 (36.438)	mem 39.998
Train: [56][635/750]	BT 0.026 (1.163)	DT 0.002 (1.116)	loss 7.286 (7.286)	prob 2.902 (2.902)	GS 29.859 (29.859)	mem 39.967
Train: [56][640/750]	BT 0.045 (1.154)	DT 0.002 (1.107)	loss 7.630 (7.630)	prob 2.552 (2.552)	GS 36.812 (36.812)	mem 40.077
Train: [56][645/750]	BT 0.032 (1.149)	DT 0.002 (1.102)	loss 7.865 (7.865)	prob 2.340 (2.340)	GS 30.875 (30.875)	mem 40.027
Train: [56][650/750]	BT 0.032 (1.159)	DT 0.001 (1.112)	loss 6.972 (6.972)	prob 3.440 (3.440)	GS 33.453 (33.453)	mem 40.035
Train: [56][655/750]	BT 0.054 (1.151)	DT 0.005 (1.104)	loss 7.060 (7.060)	prob 2.887 (2.887)	GS 30.312 (30.312)	mem 39.984
Train: [56][660/750]	BT 0.032 (1.157)	DT 0.001 (1.110)	loss 7.537 (7.537)	prob 3.273 (3.273)	GS 32.062 (32.062)	mem 40.101
Train: [56][665/750]	BT 0.034 (1.149)	DT 0.002 (1.102)	loss 7.449 (7.449)	prob 2.446 (2.446)	GS 33.688 (33.688)	mem 40.013
Train: [56][670/750]	BT 13.196 (1.164)	DT 13.160 (1.117)	loss 6.847 (6.847)	prob 3.506 (3.506)	GS 36.516 (36.516)	mem 39.994
Train: [56][675/750]	BT 0.064 (1.156)	DT 0.002 (1.109)	loss 7.640 (7.640)	prob 2.249 (2.249)	GS 32.906 (32.906)	mem 39.970
Train: [56][680/750]	BT 0.061 (1.149)	DT 0.010 (1.102)	loss 7.363 (7.363)	prob 3.338 (3.338)	GS 33.594 (33.594)	mem 39.971
Train: [56][685/750]	BT 0.035 (1.160)	DT 0.002 (1.112)	loss 7.188 (7.188)	prob 3.267 (3.267)	GS 30.375 (30.375)	mem 39.965
Train: [56][690/750]	BT 0.403 (1.152)	DT 0.372 (1.105)	loss 7.280 (7.280)	prob 3.815 (3.815)	GS 31.828 (31.828)	mem 39.967
Train: [56][695/750]	BT 0.029 (1.164)	DT 0.001 (1.117)	loss 7.551 (7.551)	prob 2.783 (2.783)	GS 31.625 (31.625)	mem 40.013
Train: [56][700/750]	BT 0.106 (1.156)	DT 0.019 (1.109)	loss 7.561 (7.561)	prob 3.510 (3.510)	GS 33.594 (33.594)	mem 40.121
Train: [56][705/750]	BT 0.064 (1.148)	DT 0.021 (1.101)	loss 7.464 (7.464)	prob 2.873 (2.873)	GS 32.766 (32.766)	mem 40.018
Train: [56][710/750]	BT 0.054 (1.160)	DT 0.014 (1.113)	loss 7.021 (7.021)	prob 3.721 (3.721)	GS 32.062 (32.062)	mem 39.976
Train: [56][715/750]	BT 0.062 (1.152)	DT 0.008 (1.105)	loss 7.359 (7.359)	prob 2.897 (2.897)	GS 29.891 (29.891)	mem 40.080
Train: [56][720/750]	BT 0.054 (1.164)	DT 0.010 (1.117)	loss 7.275 (7.275)	prob 3.102 (3.102)	GS 30.109 (30.109)	mem 39.921
Train: [56][725/750]	BT 0.023 (1.156)	DT 0.001 (1.109)	loss 7.099 (7.099)	prob 2.244 (2.244)	GS 30.984 (30.984)	mem 39.922
Train: [56][730/750]	BT 11.733 (1.165)	DT 11.704 (1.118)	loss 6.912 (6.912)	prob 3.500 (3.500)	GS 36.219 (36.219)	mem 39.419
Train: [56][735/750]	BT 0.030 (1.157)	DT 0.001 (1.110)	loss 7.526 (7.526)	prob 3.134 (3.134)	GS 30.047 (30.047)	mem 39.422
Train: [56][740/750]	BT 0.021 (1.149)	DT 0.001 (1.103)	loss 6.932 (6.932)	prob 3.717 (3.717)	GS 35.172 (35.172)	mem 39.430
Train: [56][745/750]	BT 0.021 (1.150)	DT 0.001 (1.103)	loss 6.947 (6.947)	prob 3.716 (3.716)	GS 33.062 (33.062)	mem 7.657
Train: [56][750/750]	BT 0.019 (1.142)	DT 0.001 (1.096)	loss 6.965 (6.965)	prob 3.291 (3.291)	GS 33.031 (33.031)	mem 7.657
Train: [56][755/750]	BT 0.031 (1.138)	DT 0.001 (1.092)	loss 7.461 (7.461)	prob 3.032 (3.032)	GS 33.250 (33.250)	mem 7.656
epoch 56, total time 859.64
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [57][1/750]	BT 20.420 (20.420)	DT 20.365 (20.365)	loss 7.337 (7.337)	prob 3.365 (3.365)	GS 30.000 (30.000)	mem 38.661
Train: [57][5/750]	BT 0.031 (4.551)	DT 0.002 (4.504)	loss 7.448 (7.448)	prob 2.277 (2.277)	GS 29.250 (29.250)	mem 38.597
Train: [57][10/750]	BT 0.033 (2.298)	DT 0.001 (2.254)	loss 6.806 (6.806)	prob 3.715 (3.715)	GS 30.484 (30.484)	mem 38.739
Train: [57][15/750]	BT 0.057 (2.402)	DT 0.009 (2.359)	loss 7.605 (7.605)	prob 2.412 (2.412)	GS 30.016 (30.016)	mem 38.802
Train: [57][20/750]	BT 0.057 (2.105)	DT 0.002 (2.060)	loss 7.058 (7.058)	prob 3.313 (3.313)	GS 32.391 (32.391)	mem 38.798
Train: [57][25/750]	BT 0.097 (1.697)	DT 0.065 (1.651)	loss 7.202 (7.202)	prob 3.026 (3.026)	GS 30.719 (30.719)	mem 38.798
Train: [57][30/750]	BT 0.061 (1.840)	DT 0.007 (1.793)	loss 7.146 (7.146)	prob 3.488 (3.488)	GS 34.703 (34.703)	mem 38.938
Train: [57][35/750]	BT 0.114 (1.586)	DT 0.005 (1.537)	loss 7.105 (7.105)	prob 2.883 (2.883)	GS 28.719 (28.719)	mem 39.135
Train: [57][40/750]	BT 0.042 (1.663)	DT 0.009 (1.612)	loss 6.941 (6.941)	prob 3.601 (3.601)	GS 29.906 (29.906)	mem 38.942
Train: [57][45/750]	BT 0.043 (1.483)	DT 0.001 (1.433)	loss 7.117 (7.117)	prob 2.920 (2.920)	GS 31.953 (31.953)	mem 38.943
Train: [57][50/750]	BT 12.654 (1.594)	DT 12.626 (1.543)	loss 7.232 (7.232)	prob 2.558 (2.558)	GS 37.469 (37.469)	mem 38.912
Train: [57][55/750]	BT 0.032 (1.453)	DT 0.001 (1.403)	loss 7.239 (7.239)	prob 3.099 (3.099)	GS 31.484 (31.484)	mem 38.912
Train: [57][60/750]	BT 0.098 (1.336)	DT 0.002 (1.287)	loss 7.137 (7.137)	prob 3.397 (3.397)	GS 30.234 (30.234)	mem 38.914
Train: [57][65/750]	BT 0.069 (1.480)	DT 0.001 (1.431)	loss 6.945 (6.945)	prob 3.521 (3.521)	GS 27.031 (27.031)	mem 39.003
Train: [57][70/750]	BT 0.053 (1.377)	DT 0.002 (1.329)	loss 7.204 (7.204)	prob 3.110 (3.110)	GS 34.516 (34.516)	mem 39.006
Train: [57][75/750]	BT 0.045 (1.466)	DT 0.003 (1.417)	loss 6.921 (6.921)	prob 3.737 (3.737)	GS 31.531 (31.531)	mem 38.975
Train: [57][80/750]	BT 0.041 (1.378)	DT 0.002 (1.329)	loss 7.021 (7.021)	prob 3.396 (3.396)	GS 29.219 (29.219)	mem 39.016
Train: [57][85/750]	BT 0.047 (1.299)	DT 0.002 (1.251)	loss 7.389 (7.389)	prob 2.677 (2.677)	GS 33.578 (33.578)	mem 38.979
Train: [57][90/750]	BT 0.037 (1.410)	DT 0.001 (1.362)	loss 6.804 (6.804)	prob 3.628 (3.628)	GS 33.062 (33.062)	mem 38.981
Train: [57][95/750]	BT 0.054 (1.338)	DT 0.001 (1.290)	loss 7.340 (7.340)	prob 2.555 (2.555)	GS 34.109 (34.109)	mem 38.982
Train: [57][100/750]	BT 0.033 (1.384)	DT 0.002 (1.337)	loss 7.223 (7.223)	prob 2.961 (2.961)	GS 31.250 (31.250)	mem 39.221
Train: [57][105/750]	BT 0.044 (1.321)	DT 0.013 (1.274)	loss 7.121 (7.121)	prob 3.048 (3.048)	GS 29.797 (29.797)	mem 39.178
Train: [57][110/750]	BT 15.692 (1.404)	DT 15.640 (1.358)	loss 6.972 (6.972)	prob 2.753 (2.753)	GS 34.938 (34.938)	mem 39.102
Train: [57][115/750]	BT 0.044 (1.345)	DT 0.001 (1.299)	loss 7.102 (7.102)	prob 2.839 (2.839)	GS 32.531 (32.531)	mem 39.104
Train: [57][120/750]	BT 0.116 (1.291)	DT 0.050 (1.245)	loss 7.645 (7.645)	prob 2.405 (2.405)	GS 32.047 (32.047)	mem 39.106
Train: [57][125/750]	BT 0.023 (1.334)	DT 0.001 (1.289)	loss 7.088 (7.088)	prob 3.165 (3.165)	GS 26.656 (26.656)	mem 39.104
Train: [57][130/750]	BT 0.042 (1.284)	DT 0.001 (1.239)	loss 7.060 (7.060)	prob 3.457 (3.457)	GS 29.422 (29.422)	mem 39.122
Train: [57][135/750]	BT 0.052 (1.322)	DT 0.004 (1.277)	loss 7.124 (7.124)	prob 2.233 (2.233)	GS 37.203 (37.203)	mem 39.175
Train: [57][140/750]	BT 0.033 (1.276)	DT 0.001 (1.232)	loss 6.918 (6.918)	prob 3.195 (3.195)	GS 31.391 (31.391)	mem 39.303
Train: [57][145/750]	BT 0.035 (1.234)	DT 0.001 (1.190)	loss 7.045 (7.045)	prob 3.032 (3.032)	GS 28.422 (28.422)	mem 39.197
Train: [57][150/750]	BT 0.052 (1.272)	DT 0.006 (1.227)	loss 6.986 (6.986)	prob 2.731 (2.731)	GS 32.406 (32.406)	mem 39.136
Train: [57][155/750]	BT 0.046 (1.233)	DT 0.015 (1.188)	loss 7.019 (7.019)	prob 2.532 (2.532)	GS 29.453 (29.453)	mem 39.138
Train: [57][160/750]	BT 0.096 (1.277)	DT 0.013 (1.232)	loss 7.219 (7.219)	prob 2.468 (2.468)	GS 32.828 (32.828)	mem 39.292
Train: [57][165/750]	BT 0.025 (1.240)	DT 0.001 (1.195)	loss 7.074 (7.074)	prob 2.305 (2.305)	GS 32.188 (32.188)	mem 39.278
Train: [57][170/750]	BT 11.002 (1.269)	DT 10.956 (1.224)	loss 7.080 (7.080)	prob 3.016 (3.016)	GS 27.797 (27.797)	mem 39.269
Train: [57][175/750]	BT 0.080 (1.234)	DT 0.016 (1.189)	loss 7.046 (7.046)	prob 2.941 (2.941)	GS 31.484 (31.484)	mem 39.185
Train: [57][180/750]	BT 0.045 (1.205)	DT 0.015 (1.160)	loss 7.051 (7.051)	prob 2.899 (2.899)	GS 34.906 (34.906)	mem 39.187
Train: [57][185/750]	BT 0.038 (1.238)	DT 0.003 (1.193)	loss 7.272 (7.272)	prob 2.207 (2.207)	GS 33.438 (33.438)	mem 39.173
Train: [57][190/750]	BT 2.017 (1.216)	DT 1.970 (1.172)	loss 7.103 (7.103)	prob 2.619 (2.619)	GS 38.656 (38.656)	mem 39.206
Train: [57][195/750]	BT 0.036 (1.255)	DT 0.002 (1.210)	loss 7.373 (7.373)	prob 2.319 (2.319)	GS 27.906 (27.906)	mem 39.546
Train: [57][200/750]	BT 0.073 (1.224)	DT 0.032 (1.180)	loss 7.357 (7.357)	prob 2.759 (2.759)	GS 33.875 (33.875)	mem 39.516
Train: [57][205/750]	BT 0.030 (1.195)	DT 0.001 (1.152)	loss 7.297 (7.297)	prob 3.135 (3.135)	GS 30.312 (30.312)	mem 39.516
Train: [57][210/750]	BT 0.032 (1.233)	DT 0.001 (1.189)	loss 6.971 (6.971)	prob 3.009 (3.009)	GS 31.641 (31.641)	mem 39.540
Train: [57][215/750]	BT 0.032 (1.205)	DT 0.001 (1.162)	loss 7.076 (7.076)	prob 2.601 (2.601)	GS 29.516 (29.516)	mem 39.588
Train: [57][220/750]	BT 0.031 (1.235)	DT 0.001 (1.192)	loss 6.951 (6.951)	prob 2.567 (2.567)	GS 35.203 (35.203)	mem 39.488
Train: [57][225/750]	BT 0.048 (1.209)	DT 0.001 (1.166)	loss 7.063 (7.063)	prob 2.323 (2.323)	GS 35.922 (35.922)	mem 39.496
Train: [57][230/750]	BT 7.891 (1.231)	DT 7.864 (1.188)	loss 6.949 (6.949)	prob 2.329 (2.329)	GS 30.766 (30.766)	mem 39.510
Train: [57][235/750]	BT 0.046 (1.206)	DT 0.004 (1.163)	loss 7.117 (7.117)	prob 2.361 (2.361)	GS 28.719 (28.719)	mem 39.566
Train: [57][240/750]	BT 0.126 (1.193)	DT 0.038 (1.150)	loss 6.966 (6.966)	prob 2.374 (2.374)	GS 32.031 (32.031)	mem 39.769
Train: [57][245/750]	BT 0.030 (1.221)	DT 0.001 (1.178)	loss 7.007 (7.007)	prob 2.381 (2.381)	GS 32.281 (32.281)	mem 39.564
Train: [57][250/750]	BT 0.032 (1.197)	DT 0.010 (1.155)	loss 6.789 (6.789)	prob 2.429 (2.429)	GS 29.172 (29.172)	mem 39.565
Train: [57][255/750]	BT 0.026 (1.221)	DT 0.001 (1.179)	loss 7.011 (7.011)	prob 2.698 (2.698)	GS 30.906 (30.906)	mem 39.556
Train: [57][260/750]	BT 0.061 (1.199)	DT 0.001 (1.156)	loss 7.023 (7.023)	prob 3.089 (3.089)	GS 33.781 (33.781)	mem 39.633
Train: [57][265/750]	BT 0.096 (1.183)	DT 0.003 (1.140)	loss 7.016 (7.016)	prob 2.658 (2.658)	GS 32.938 (32.938)	mem 39.547
Train: [57][270/750]	BT 0.031 (1.200)	DT 0.001 (1.157)	loss 6.940 (6.940)	prob 2.428 (2.428)	GS 34.062 (34.062)	mem 39.536
Train: [57][275/750]	BT 0.027 (1.191)	DT 0.001 (1.149)	loss 7.195 (7.195)	prob 1.965 (1.965)	GS 28.266 (28.266)	mem 39.564
Train: [57][280/750]	BT 0.034 (1.217)	DT 0.009 (1.175)	loss 6.981 (6.981)	prob 2.616 (2.616)	GS 36.078 (36.078)	mem 39.811
Train: [57][285/750]	BT 0.033 (1.197)	DT 0.002 (1.154)	loss 7.046 (7.046)	prob 2.143 (2.143)	GS 28.891 (28.891)	mem 39.736
Train: [57][290/750]	BT 12.280 (1.219)	DT 12.209 (1.177)	loss 6.966 (6.966)	prob 2.403 (2.403)	GS 34.000 (34.000)	mem 39.748
Train: [57][295/750]	BT 0.033 (1.199)	DT 0.002 (1.157)	loss 7.196 (7.196)	prob 2.447 (2.447)	GS 32.469 (32.469)	mem 39.790
Train: [57][300/750]	BT 0.036 (1.180)	DT 0.001 (1.138)	loss 6.953 (6.953)	prob 2.454 (2.454)	GS 29.562 (29.562)	mem 39.792
Train: [57][305/750]	BT 0.026 (1.199)	DT 0.001 (1.158)	loss 6.954 (6.954)	prob 2.066 (2.066)	GS 31.766 (31.766)	mem 39.826
Train: [57][310/750]	BT 0.030 (1.181)	DT 0.001 (1.139)	loss 6.784 (6.784)	prob 2.871 (2.871)	GS 35.547 (35.547)	mem 39.826
Train: [57][315/750]	BT 0.036 (1.198)	DT 0.002 (1.157)	loss 6.914 (6.914)	prob 2.744 (2.744)	GS 29.984 (29.984)	mem 39.990
Train: [57][320/750]	BT 0.023 (1.180)	DT 0.001 (1.139)	loss 6.919 (6.919)	prob 2.554 (2.554)	GS 32.938 (32.938)	mem 39.872
Train: [57][325/750]	BT 0.066 (1.163)	DT 0.010 (1.121)	loss 7.403 (7.403)	prob 1.854 (1.854)	GS 31.984 (31.984)	mem 39.873
Train: [57][330/750]	BT 0.026 (1.179)	DT 0.001 (1.138)	loss 7.124 (7.124)	prob 2.351 (2.351)	GS 32.078 (32.078)	mem 39.873
Train: [57][335/750]	BT 0.040 (1.163)	DT 0.004 (1.122)	loss 7.093 (7.093)	prob 2.688 (2.688)	GS 31.859 (31.859)	mem 39.890
Train: [57][340/750]	BT 0.031 (1.183)	DT 0.001 (1.142)	loss 6.933 (6.933)	prob 3.009 (3.009)	GS 36.500 (36.500)	mem 39.870
Train: [57][345/750]	BT 0.142 (1.167)	DT 0.018 (1.125)	loss 7.482 (7.482)	prob 2.199 (2.199)	GS 33.547 (33.547)	mem 39.986
Train: [57][350/750]	BT 10.667 (1.183)	DT 10.640 (1.141)	loss 6.768 (6.768)	prob 2.673 (2.673)	GS 31.562 (31.562)	mem 39.868
Train: [57][355/750]	BT 0.030 (1.167)	DT 0.002 (1.125)	loss 6.713 (6.713)	prob 2.664 (2.664)	GS 30.297 (30.297)	mem 39.868
Train: [57][360/750]	BT 0.038 (1.155)	DT 0.001 (1.113)	loss 6.963 (6.963)	prob 2.505 (2.505)	GS 36.312 (36.312)	mem 40.220
Train: [57][365/750]	BT 0.040 (1.169)	DT 0.010 (1.128)	loss 7.068 (7.068)	prob 1.982 (1.982)	GS 31.422 (31.422)	mem 39.911
Train: [57][370/750]	BT 0.304 (1.155)	DT 0.271 (1.114)	loss 6.903 (6.903)	prob 3.111 (3.111)	GS 32.328 (32.328)	mem 39.911
Train: [57][375/750]	BT 0.071 (1.169)	DT 0.007 (1.128)	loss 6.976 (6.976)	prob 2.031 (2.031)	GS 26.516 (26.516)	mem 39.892
Train: [57][380/750]	BT 0.025 (1.154)	DT 0.001 (1.113)	loss 6.917 (6.917)	prob 2.948 (2.948)	GS 33.188 (33.188)	mem 39.895
Train: [57][385/750]	BT 0.123 (1.147)	DT 0.006 (1.106)	loss 6.980 (6.980)	prob 2.274 (2.274)	GS 32.172 (32.172)	mem 39.897
Train: [57][390/750]	BT 0.027 (1.160)	DT 0.001 (1.118)	loss 6.929 (6.929)	prob 2.393 (2.393)	GS 32.203 (32.203)	mem 39.947
Train: [57][395/750]	BT 0.064 (1.150)	DT 0.007 (1.109)	loss 7.097 (7.097)	prob 2.097 (2.097)	GS 31.734 (31.734)	mem 39.970
Train: [57][400/750]	BT 0.043 (1.164)	DT 0.001 (1.122)	loss 7.015 (7.015)	prob 2.396 (2.396)	GS 33.703 (33.703)	mem 40.027
Train: [57][405/750]	BT 0.041 (1.150)	DT 0.011 (1.109)	loss 7.127 (7.127)	prob 2.552 (2.552)	GS 35.078 (35.078)	mem 40.010
Train: [57][410/750]	BT 13.432 (1.170)	DT 13.399 (1.129)	loss 6.887 (6.887)	prob 2.216 (2.216)	GS 37.188 (37.188)	mem 40.004
Train: [57][415/750]	BT 0.056 (1.157)	DT 0.003 (1.116)	loss 6.907 (6.907)	prob 2.280 (2.280)	GS 34.375 (34.375)	mem 40.131
Train: [57][420/750]	BT 0.041 (1.144)	DT 0.005 (1.103)	loss 6.806 (6.806)	prob 2.566 (2.566)	GS 32.906 (32.906)	mem 39.931
Train: [57][425/750]	BT 0.031 (1.162)	DT 0.001 (1.121)	loss 6.867 (6.867)	prob 2.734 (2.734)	GS 32.438 (32.438)	mem 39.908
Train: [57][430/750]	BT 0.028 (1.149)	DT 0.001 (1.108)	loss 6.783 (6.783)	prob 3.056 (3.056)	GS 34.047 (34.047)	mem 39.907
Train: [57][435/750]	BT 0.031 (1.161)	DT 0.002 (1.119)	loss 6.888 (6.888)	prob 2.755 (2.755)	GS 28.297 (28.297)	mem 39.871
Train: [57][440/750]	BT 0.090 (1.148)	DT 0.010 (1.107)	loss 7.198 (7.198)	prob 1.224 (1.224)	GS 34.500 (34.500)	mem 39.872
Train: [57][445/750]	BT 0.040 (1.136)	DT 0.002 (1.094)	loss 6.866 (6.866)	prob 3.132 (3.132)	GS 33.781 (33.781)	mem 39.869
Train: [57][450/750]	BT 0.033 (1.154)	DT 0.002 (1.112)	loss 7.023 (7.023)	prob 2.151 (2.151)	GS 35.828 (35.828)	mem 39.872
Train: [57][455/750]	BT 0.072 (1.142)	DT 0.009 (1.100)	loss 6.944 (6.944)	prob 2.247 (2.247)	GS 31.875 (31.875)	mem 39.931
Train: [57][460/750]	BT 0.045 (1.161)	DT 0.002 (1.119)	loss 6.985 (6.985)	prob 2.163 (2.163)	GS 32.281 (32.281)	mem 39.886
Train: [57][465/750]	BT 0.047 (1.149)	DT 0.008 (1.107)	loss 7.188 (7.188)	prob 2.262 (2.262)	GS 33.266 (33.266)	mem 39.911
Train: [57][470/750]	BT 15.267 (1.169)	DT 15.229 (1.128)	loss 6.698 (6.698)	prob 2.225 (2.225)	GS 34.125 (34.125)	mem 39.869
Train: [57][475/750]	BT 0.035 (1.157)	DT 0.001 (1.116)	loss 6.861 (6.861)	prob 1.938 (1.938)	GS 28.219 (28.219)	mem 39.896
Train: [57][480/750]	BT 0.071 (1.146)	DT 0.002 (1.105)	loss 6.944 (6.944)	prob 1.949 (1.949)	GS 32.234 (32.234)	mem 40.087
Train: [57][485/750]	BT 0.068 (1.157)	DT 0.003 (1.116)	loss 7.022 (7.022)	prob 2.451 (2.451)	GS 36.906 (36.906)	mem 39.983
Train: [57][490/750]	BT 0.060 (1.146)	DT 0.013 (1.105)	loss 6.804 (6.804)	prob 3.007 (3.007)	GS 33.703 (33.703)	mem 39.939
Train: [57][495/750]	BT 0.039 (1.166)	DT 0.001 (1.125)	loss 6.990 (6.990)	prob 2.432 (2.432)	GS 32.703 (32.703)	mem 39.992
Train: [57][500/750]	BT 0.033 (1.155)	DT 0.001 (1.114)	loss 6.961 (6.961)	prob 2.371 (2.371)	GS 32.797 (32.797)	mem 40.062
Train: [57][505/750]	BT 0.041 (1.144)	DT 0.001 (1.103)	loss 7.031 (7.031)	prob 2.228 (2.228)	GS 30.625 (30.625)	mem 39.931
Train: [57][510/750]	BT 0.050 (1.156)	DT 0.004 (1.114)	loss 6.809 (6.809)	prob 2.185 (2.185)	GS 32.141 (32.141)	mem 40.056
Train: [57][515/750]	BT 0.063 (1.145)	DT 0.013 (1.103)	loss 6.860 (6.860)	prob 2.445 (2.445)	GS 31.328 (31.328)	mem 39.996
Train: [57][520/750]	BT 0.040 (1.155)	DT 0.015 (1.113)	loss 6.908 (6.908)	prob 2.488 (2.488)	GS 34.453 (34.453)	mem 39.915
Train: [57][525/750]	BT 0.073 (1.144)	DT 0.010 (1.103)	loss 7.214 (7.214)	prob 2.024 (2.024)	GS 28.391 (28.391)	mem 39.914
Train: [57][530/750]	BT 12.719 (1.158)	DT 12.677 (1.116)	loss 6.912 (6.912)	prob 2.736 (2.736)	GS 36.141 (36.141)	mem 40.085
Train: [57][535/750]	BT 0.034 (1.148)	DT 0.001 (1.106)	loss 7.327 (7.327)	prob 2.135 (2.135)	GS 41.078 (41.078)	mem 39.864
Train: [57][540/750]	BT 0.089 (1.138)	DT 0.006 (1.096)	loss 6.883 (6.883)	prob 2.478 (2.478)	GS 32.766 (32.766)	mem 39.863
Train: [57][545/750]	BT 0.043 (1.151)	DT 0.003 (1.110)	loss 7.142 (7.142)	prob 1.937 (1.937)	GS 33.406 (33.406)	mem 39.860
Train: [57][550/750]	BT 0.076 (1.141)	DT 0.005 (1.100)	loss 6.633 (6.633)	prob 2.697 (2.697)	GS 32.906 (32.906)	mem 39.886
Train: [57][555/750]	BT 0.042 (1.154)	DT 0.003 (1.112)	loss 7.286 (7.286)	prob 2.812 (2.812)	GS 29.078 (29.078)	mem 39.907
Train: [57][560/750]	BT 0.072 (1.144)	DT 0.009 (1.102)	loss 6.760 (6.760)	prob 2.656 (2.656)	GS 34.797 (34.797)	mem 39.956
Train: [57][565/750]	BT 0.039 (1.134)	DT 0.002 (1.092)	loss 6.797 (6.797)	prob 2.489 (2.489)	GS 30.344 (30.344)	mem 39.852
Train: [57][570/750]	BT 0.102 (1.145)	DT 0.014 (1.102)	loss 7.010 (7.010)	prob 2.178 (2.178)	GS 38.859 (38.859)	mem 40.111
Train: [57][575/750]	BT 0.059 (1.135)	DT 0.001 (1.093)	loss 6.863 (6.863)	prob 2.840 (2.840)	GS 35.109 (35.109)	mem 39.946
Train: [57][580/750]	BT 0.081 (1.146)	DT 0.003 (1.103)	loss 7.023 (7.023)	prob 2.073 (2.073)	GS 34.375 (34.375)	mem 40.091
Train: [57][585/750]	BT 0.060 (1.136)	DT 0.030 (1.094)	loss 6.842 (6.842)	prob 2.297 (2.297)	GS 31.625 (31.625)	mem 39.937
Train: [57][590/750]	BT 7.644 (1.151)	DT 7.622 (1.109)	loss 6.831 (6.831)	prob 2.557 (2.557)	GS 36.859 (36.859)	mem 39.796
Train: [57][595/750]	BT 0.037 (1.142)	DT 0.006 (1.100)	loss 7.061 (7.061)	prob 2.652 (2.652)	GS 30.047 (30.047)	mem 39.796
Train: [57][600/750]	BT 2.828 (1.137)	DT 2.799 (1.095)	loss 6.853 (6.853)	prob 2.457 (2.457)	GS 35.906 (35.906)	mem 39.866
Train: [57][605/750]	BT 0.024 (1.145)	DT 0.001 (1.103)	loss 6.861 (6.861)	prob 2.695 (2.695)	GS 32.000 (32.000)	mem 39.806
Train: [57][610/750]	BT 0.031 (1.136)	DT 0.002 (1.094)	loss 6.753 (6.753)	prob 2.917 (2.917)	GS 37.984 (37.984)	mem 39.881
Train: [57][615/750]	BT 0.029 (1.149)	DT 0.001 (1.107)	loss 6.827 (6.827)	prob 2.688 (2.688)	GS 31.906 (31.906)	mem 39.893
Train: [57][620/750]	BT 0.043 (1.140)	DT 0.003 (1.098)	loss 6.989 (6.989)	prob 1.895 (1.895)	GS 33.828 (33.828)	mem 39.894
Train: [57][625/750]	BT 0.064 (1.137)	DT 0.014 (1.095)	loss 6.865 (6.865)	prob 2.774 (2.774)	GS 30.812 (30.812)	mem 39.835
Train: [57][630/750]	BT 0.024 (1.144)	DT 0.001 (1.102)	loss 6.862 (6.862)	prob 3.080 (3.080)	GS 37.594 (37.594)	mem 39.931
Train: [57][635/750]	BT 0.030 (1.136)	DT 0.001 (1.094)	loss 6.748 (6.748)	prob 2.602 (2.602)	GS 29.266 (29.266)	mem 39.932
Train: [57][640/750]	BT 0.064 (1.145)	DT 0.015 (1.103)	loss 6.897 (6.897)	prob 1.764 (1.764)	GS 31.781 (31.781)	mem 39.975
Train: [57][645/750]	BT 0.033 (1.136)	DT 0.001 (1.094)	loss 7.010 (7.010)	prob 2.275 (2.275)	GS 32.438 (32.438)	mem 39.954
Train: [57][650/750]	BT 9.720 (1.144)	DT 9.646 (1.102)	loss 6.975 (6.975)	prob 2.416 (2.416)	GS 32.625 (32.625)	mem 39.887
Train: [57][655/750]	BT 0.026 (1.136)	DT 0.001 (1.093)	loss 6.787 (6.787)	prob 2.684 (2.684)	GS 33.953 (33.953)	mem 39.902
arpack error, retry= 0
Train: [57][660/750]	BT 0.620 (1.128)	DT 0.569 (1.086)	loss 6.837 (6.837)	prob 3.142 (3.142)	GS 33.547 (33.547)	mem 39.914
Train: [57][665/750]	BT 0.050 (1.135)	DT 0.008 (1.092)	loss 7.144 (7.144)	prob 2.397 (2.397)	GS 31.375 (31.375)	mem 39.829
Train: [57][670/750]	BT 0.075 (1.128)	DT 0.002 (1.085)	loss 6.877 (6.877)	prob 2.624 (2.624)	GS 35.984 (35.984)	mem 39.859
Train: [57][675/750]	BT 0.041 (1.140)	DT 0.001 (1.098)	loss 7.329 (7.329)	prob 1.936 (1.936)	GS 33.406 (33.406)	mem 39.833
Train: [57][680/750]	BT 0.032 (1.132)	DT 0.001 (1.090)	loss 6.953 (6.953)	prob 2.735 (2.735)	GS 35.141 (35.141)	mem 39.834
Train: [57][685/750]	BT 0.060 (1.129)	DT 0.010 (1.087)	loss 6.869 (6.869)	prob 2.645 (2.645)	GS 37.125 (37.125)	mem 39.900
Train: [57][690/750]	BT 0.047 (1.136)	DT 0.009 (1.094)	loss 6.808 (6.808)	prob 2.666 (2.666)	GS 35.531 (35.531)	mem 39.912
Train: [57][695/750]	BT 0.047 (1.128)	DT 0.011 (1.086)	loss 6.877 (6.877)	prob 2.558 (2.558)	GS 25.891 (25.891)	mem 39.913
Train: [57][700/750]	BT 0.034 (1.140)	DT 0.001 (1.098)	loss 6.963 (6.963)	prob 2.721 (2.721)	GS 34.828 (34.828)	mem 39.875
Train: [57][705/750]	BT 0.038 (1.133)	DT 0.007 (1.091)	loss 6.911 (6.911)	prob 2.667 (2.667)	GS 33.078 (33.078)	mem 39.899
Train: [57][710/750]	BT 11.441 (1.142)	DT 11.388 (1.100)	loss 6.644 (6.644)	prob 2.900 (2.900)	GS 33.109 (33.109)	mem 40.073
Train: [57][715/750]	BT 0.101 (1.135)	DT 0.007 (1.092)	loss 6.738 (6.738)	prob 2.626 (2.626)	GS 31.781 (31.781)	mem 39.934
Train: [57][720/750]	BT 0.061 (1.127)	DT 0.027 (1.085)	loss 6.920 (6.920)	prob 2.521 (2.521)	GS 33.750 (33.750)	mem 39.871
Train: [57][725/750]	BT 0.031 (1.139)	DT 0.001 (1.097)	loss 7.099 (7.099)	prob 2.335 (2.335)	GS 30.078 (30.078)	mem 39.820
Train: [57][730/750]	BT 0.063 (1.132)	DT 0.026 (1.090)	loss 6.887 (6.887)	prob 2.688 (2.688)	GS 32.953 (32.953)	mem 39.821
Train: [57][735/750]	BT 0.061 (1.137)	DT 0.022 (1.095)	loss 6.824 (6.824)	prob 2.875 (2.875)	GS 36.172 (36.172)	mem 36.548
Train: [57][740/750]	BT 0.046 (1.130)	DT 0.005 (1.087)	loss 6.744 (6.744)	prob 2.433 (2.433)	GS 31.469 (31.469)	mem 36.548
Train: [57][745/750]	BT 0.027 (1.122)	DT 0.001 (1.080)	loss 7.114 (7.114)	prob 2.436 (2.436)	GS 27.844 (27.844)	mem 36.548
Train: [57][750/750]	BT 0.458 (1.120)	DT 0.427 (1.077)	loss 6.846 (6.846)	prob 2.578 (2.578)	GS 35.375 (35.375)	mem 7.516
Train: [57][755/750]	BT 0.026 (1.112)	DT 0.001 (1.070)	loss 6.672 (6.672)	prob 3.255 (3.255)	GS 34.406 (34.406)	mem 7.517
epoch 57, total time 840.06
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [58][1/750]	BT 23.897 (23.897)	DT 23.836 (23.836)	loss 7.026 (7.026)	prob 2.791 (2.791)	GS 30.672 (30.672)	mem 38.702
Train: [58][5/750]	BT 0.045 (5.113)	DT 0.002 (5.060)	loss 6.865 (6.865)	prob 3.150 (3.150)	GS 32.016 (32.016)	mem 38.619
Train: [58][10/750]	BT 0.049 (2.590)	DT 0.010 (2.532)	loss 6.682 (6.682)	prob 2.995 (2.995)	GS 36.891 (36.891)	mem 38.621
Train: [58][15/750]	BT 0.033 (2.524)	DT 0.001 (2.474)	loss 6.849 (6.849)	prob 2.243 (2.243)	GS 28.812 (28.812)	mem 38.801
Train: [58][20/750]	BT 0.047 (2.088)	DT 0.004 (2.039)	loss 6.899 (6.899)	prob 2.542 (2.542)	GS 32.719 (32.719)	mem 38.839
Train: [58][25/750]	BT 10.947 (2.116)	DT 10.915 (2.069)	loss 7.150 (7.150)	prob 1.950 (1.950)	GS 37.547 (37.547)	mem 38.871
Train: [58][30/750]	BT 0.033 (1.837)	DT 0.001 (1.789)	loss 6.906 (6.906)	prob 1.992 (1.992)	GS 30.797 (30.797)	mem 39.056
Train: [58][35/750]	BT 0.024 (1.580)	DT 0.001 (1.534)	loss 7.227 (7.227)	prob 2.000 (2.000)	GS 28.469 (28.469)	mem 38.875
Train: [58][40/750]	BT 8.541 (1.739)	DT 8.493 (1.693)	loss 6.812 (6.812)	prob 2.819 (2.819)	GS 39.656 (39.656)	mem 38.889
Train: [58][45/750]	BT 0.033 (1.549)	DT 0.001 (1.505)	loss 6.809 (6.809)	prob 2.315 (2.315)	GS 30.984 (30.984)	mem 39.015
Train: [58][50/750]	BT 0.695 (1.413)	DT 0.615 (1.368)	loss 6.868 (6.868)	prob 2.235 (2.235)	GS 41.547 (41.547)	mem 38.916
Train: [58][55/750]	BT 0.022 (1.502)	DT 0.001 (1.458)	loss 6.879 (6.879)	prob 2.364 (2.364)	GS 30.844 (30.844)	mem 38.966
Train: [58][60/750]	BT 0.037 (1.380)	DT 0.002 (1.337)	loss 6.801 (6.801)	prob 2.852 (2.852)	GS 32.688 (32.688)	mem 39.005
Train: [58][65/750]	BT 0.044 (1.445)	DT 0.002 (1.402)	loss 7.071 (7.071)	prob 2.709 (2.709)	GS 26.047 (26.047)	mem 38.977
Train: [58][70/750]	BT 0.031 (1.345)	DT 0.001 (1.302)	loss 6.970 (6.970)	prob 2.306 (2.306)	GS 33.375 (33.375)	mem 38.980
Train: [58][75/750]	BT 0.088 (1.304)	DT 0.014 (1.260)	loss 7.016 (7.016)	prob 2.266 (2.266)	GS 30.062 (30.062)	mem 39.308
Train: [58][80/750]	BT 0.061 (1.357)	DT 0.004 (1.313)	loss 6.912 (6.912)	prob 2.577 (2.577)	GS 35.562 (35.562)	mem 39.050
Train: [58][85/750]	BT 0.034 (1.314)	DT 0.002 (1.271)	loss 6.763 (6.763)	prob 2.974 (2.974)	GS 44.469 (44.469)	mem 39.051
Train: [58][90/750]	BT 2.404 (1.342)	DT 2.371 (1.299)	loss 7.211 (7.211)	prob 2.415 (2.415)	GS 37.891 (37.891)	mem 39.214
Train: [58][95/750]	BT 0.128 (1.275)	DT 0.001 (1.231)	loss 6.810 (6.810)	prob 3.092 (3.092)	GS 28.781 (28.781)	mem 39.170
Train: [58][100/750]	BT 8.402 (1.326)	DT 8.371 (1.282)	loss 7.217 (7.217)	prob 2.723 (2.723)	GS 34.422 (34.422)	mem 39.071
Train: [58][105/750]	BT 0.045 (1.265)	DT 0.001 (1.221)	loss 6.785 (6.785)	prob 3.025 (3.025)	GS 30.109 (30.109)	mem 39.115
Train: [58][110/750]	BT 0.032 (1.239)	DT 0.001 (1.195)	loss 6.929 (6.929)	prob 2.762 (2.762)	GS 32.531 (32.531)	mem 39.129
Train: [58][115/750]	BT 0.029 (1.281)	DT 0.001 (1.238)	loss 6.881 (6.881)	prob 2.524 (2.524)	GS 35.125 (35.125)	mem 39.098
Train: [58][120/750]	BT 1.816 (1.244)	DT 1.766 (1.201)	loss 6.883 (6.883)	prob 2.862 (2.862)	GS 35.516 (35.516)	mem 39.153
Train: [58][125/750]	BT 0.024 (1.275)	DT 0.001 (1.232)	loss 7.137 (7.137)	prob 2.232 (2.232)	GS 35.906 (35.906)	mem 39.106
Train: [58][130/750]	BT 0.122 (1.238)	DT 0.007 (1.194)	loss 6.831 (6.831)	prob 2.564 (2.564)	GS 33.422 (33.422)	mem 39.080
Train: [58][135/750]	BT 0.059 (1.217)	DT 0.007 (1.173)	loss 7.086 (7.086)	prob 2.491 (2.491)	GS 33.812 (33.812)	mem 39.156
Train: [58][140/750]	BT 0.026 (1.250)	DT 0.001 (1.206)	loss 6.662 (6.662)	prob 3.048 (3.048)	GS 28.938 (28.938)	mem 39.145
Train: [58][145/750]	BT 0.076 (1.208)	DT 0.024 (1.165)	loss 6.960 (6.960)	prob 2.483 (2.483)	GS 32.594 (32.594)	mem 39.225
Train: [58][150/750]	BT 0.063 (1.253)	DT 0.013 (1.209)	loss 6.924 (6.924)	prob 2.260 (2.260)	GS 34.359 (34.359)	mem 39.241
Train: [58][155/750]	BT 0.076 (1.214)	DT 0.001 (1.170)	loss 7.008 (7.008)	prob 2.638 (2.638)	GS 33.094 (33.094)	mem 39.286
Train: [58][160/750]	BT 8.986 (1.258)	DT 8.938 (1.215)	loss 7.046 (7.046)	prob 2.535 (2.535)	GS 31.891 (31.891)	mem 39.456
Train: [58][165/750]	BT 0.033 (1.221)	DT 0.001 (1.178)	loss 6.784 (6.784)	prob 2.697 (2.697)	GS 28.328 (28.328)	mem 39.806
Train: [58][170/750]	BT 2.791 (1.203)	DT 2.758 (1.160)	loss 6.867 (6.867)	prob 2.866 (2.866)	GS 32.312 (32.312)	mem 39.465
Train: [58][175/750]	BT 0.033 (1.230)	DT 0.001 (1.187)	loss 7.166 (7.166)	prob 2.428 (2.428)	GS 31.203 (31.203)	mem 39.495
Train: [58][180/750]	BT 0.034 (1.197)	DT 0.001 (1.154)	loss 6.937 (6.937)	prob 2.747 (2.747)	GS 32.625 (32.625)	mem 39.505
Train: [58][185/750]	BT 0.041 (1.230)	DT 0.007 (1.186)	loss 6.861 (6.861)	prob 3.352 (3.352)	GS 30.953 (30.953)	mem 39.608
Train: [58][190/750]	BT 0.088 (1.206)	DT 0.008 (1.162)	loss 6.913 (6.913)	prob 2.562 (2.562)	GS 34.375 (34.375)	mem 39.564
Train: [58][195/750]	BT 0.038 (1.192)	DT 0.002 (1.149)	loss 6.993 (6.993)	prob 3.124 (3.124)	GS 28.516 (28.516)	mem 39.540
Train: [58][200/750]	BT 0.037 (1.209)	DT 0.001 (1.165)	loss 7.160 (7.160)	prob 2.532 (2.532)	GS 31.906 (31.906)	mem 39.505
Train: [58][205/750]	BT 0.033 (1.205)	DT 0.002 (1.161)	loss 6.773 (6.773)	prob 3.064 (3.064)	GS 24.828 (24.828)	mem 39.553
Train: [58][210/750]	BT 2.961 (1.207)	DT 2.925 (1.164)	loss 6.830 (6.830)	prob 2.995 (2.995)	GS 36.766 (36.766)	mem 40.214
Train: [58][215/750]	BT 0.031 (1.181)	DT 0.001 (1.137)	loss 7.112 (7.112)	prob 2.418 (2.418)	GS 29.406 (29.406)	mem 40.214
Train: [58][220/750]	BT 3.989 (1.199)	DT 3.957 (1.155)	loss 6.998 (6.998)	prob 2.924 (2.924)	GS 35.578 (35.578)	mem 39.628
Train: [58][225/750]	BT 0.040 (1.190)	DT 0.002 (1.146)	loss 6.818 (6.818)	prob 2.917 (2.917)	GS 30.391 (30.391)	mem 39.709
Train: [58][230/750]	BT 0.040 (1.182)	DT 0.001 (1.137)	loss 6.686 (6.686)	prob 3.593 (3.593)	GS 30.422 (30.422)	mem 39.794
Train: [58][235/750]	BT 0.034 (1.193)	DT 0.002 (1.148)	loss 7.028 (7.028)	prob 2.842 (2.842)	GS 29.953 (29.953)	mem 39.854
Train: [58][240/750]	BT 4.286 (1.186)	DT 4.250 (1.142)	loss 7.040 (7.040)	prob 2.797 (2.797)	GS 33.438 (33.438)	mem 39.837
Train: [58][245/750]	BT 0.037 (1.187)	DT 0.001 (1.143)	loss 7.114 (7.114)	prob 2.765 (2.765)	GS 29.531 (29.531)	mem 39.797
Train: [58][250/750]	BT 0.038 (1.176)	DT 0.003 (1.132)	loss 6.960 (6.960)	prob 2.738 (2.738)	GS 37.500 (37.500)	mem 39.839
Train: [58][255/750]	BT 0.033 (1.172)	DT 0.001 (1.128)	loss 6.621 (6.621)	prob 2.566 (2.566)	GS 29.859 (29.859)	mem 39.808
Train: [58][260/750]	BT 0.022 (1.191)	DT 0.001 (1.147)	loss 7.074 (7.074)	prob 3.040 (3.040)	GS 28.469 (28.469)	mem 39.805
Train: [58][265/750]	BT 0.067 (1.169)	DT 0.017 (1.125)	loss 7.171 (7.171)	prob 2.498 (2.498)	GS 32.094 (32.094)	mem 39.804
Train: [58][270/750]	BT 9.653 (1.199)	DT 9.619 (1.155)	loss 7.078 (7.078)	prob 2.333 (2.333)	GS 32.266 (32.266)	mem 40.140
Train: [58][275/750]	BT 0.035 (1.178)	DT 0.002 (1.134)	loss 7.010 (7.010)	prob 2.322 (2.322)	GS 32.609 (32.609)	mem 40.106
Train: [58][280/750]	BT 0.479 (1.160)	DT 0.425 (1.115)	loss 6.861 (6.861)	prob 2.386 (2.386)	GS 31.516 (31.516)	mem 39.892
Train: [58][285/750]	BT 0.054 (1.182)	DT 0.002 (1.137)	loss 6.807 (6.807)	prob 2.847 (2.847)	GS 33.297 (33.297)	mem 39.891
Train: [58][290/750]	BT 0.040 (1.164)	DT 0.003 (1.120)	loss 6.882 (6.882)	prob 3.040 (3.040)	GS 40.125 (40.125)	mem 39.797
Train: [58][295/750]	BT 0.033 (1.183)	DT 0.002 (1.139)	loss 7.160 (7.160)	prob 2.481 (2.481)	GS 28.328 (28.328)	mem 39.757
Train: [58][300/750]	BT 0.806 (1.166)	DT 0.774 (1.122)	loss 6.883 (6.883)	prob 3.019 (3.019)	GS 32.016 (32.016)	mem 39.764
Train: [58][305/750]	BT 0.057 (1.153)	DT 0.016 (1.109)	loss 7.000 (7.000)	prob 2.499 (2.499)	GS 32.062 (32.062)	mem 39.850
Train: [58][310/750]	BT 0.030 (1.176)	DT 0.001 (1.132)	loss 6.884 (6.884)	prob 2.892 (2.892)	GS 34.219 (34.219)	mem 39.812
Train: [58][315/750]	BT 0.031 (1.161)	DT 0.001 (1.117)	loss 6.980 (6.980)	prob 2.780 (2.780)	GS 34.516 (34.516)	mem 39.706
Train: [58][320/750]	BT 0.039 (1.180)	DT 0.001 (1.136)	loss 6.904 (6.904)	prob 3.109 (3.109)	GS 36.250 (36.250)	mem 39.928
Train: [58][325/750]	BT 0.044 (1.166)	DT 0.002 (1.121)	loss 6.896 (6.896)	prob 3.021 (3.021)	GS 33.812 (33.812)	mem 39.874
Train: [58][330/750]	BT 9.767 (1.178)	DT 9.728 (1.134)	loss 7.217 (7.217)	prob 2.234 (2.234)	GS 33.703 (33.703)	mem 39.846
Train: [58][335/750]	BT 0.035 (1.161)	DT 0.002 (1.117)	loss 6.929 (6.929)	prob 2.983 (2.983)	GS 31.844 (31.844)	mem 39.880
Train: [58][340/750]	BT 1.220 (1.151)	DT 1.163 (1.107)	loss 7.146 (7.146)	prob 2.078 (2.078)	GS 33.719 (33.719)	mem 39.896
Train: [58][345/750]	BT 0.052 (1.169)	DT 0.022 (1.124)	loss 6.816 (6.816)	prob 2.587 (2.587)	GS 29.641 (29.641)	mem 39.900
Train: [58][350/750]	BT 0.050 (1.152)	DT 0.005 (1.108)	loss 6.907 (6.907)	prob 2.649 (2.649)	GS 34.844 (34.844)	mem 39.901
Train: [58][355/750]	BT 0.041 (1.166)	DT 0.002 (1.122)	loss 6.905 (6.905)	prob 2.120 (2.120)	GS 31.109 (31.109)	mem 39.935
Train: [58][360/750]	BT 0.049 (1.151)	DT 0.014 (1.106)	loss 6.901 (6.901)	prob 2.891 (2.891)	GS 31.375 (31.375)	mem 39.936
Train: [58][365/750]	BT 0.034 (1.148)	DT 0.001 (1.103)	loss 6.923 (6.923)	prob 2.664 (2.664)	GS 32.516 (32.516)	mem 39.962
Train: [58][370/750]	BT 0.074 (1.152)	DT 0.008 (1.108)	loss 6.692 (6.692)	prob 2.790 (2.790)	GS 36.875 (36.875)	mem 39.969
Train: [58][375/750]	BT 0.040 (1.138)	DT 0.002 (1.093)	loss 7.173 (7.173)	prob 2.389 (2.389)	GS 26.016 (26.016)	mem 39.968
Train: [58][380/750]	BT 0.067 (1.153)	DT 0.011 (1.108)	loss 6.947 (6.947)	prob 2.569 (2.569)	GS 31.062 (31.062)	mem 39.847
Train: [58][385/750]	BT 0.048 (1.143)	DT 0.017 (1.098)	loss 7.063 (7.063)	prob 2.638 (2.638)	GS 30.203 (30.203)	mem 39.805
Train: [58][390/750]	BT 10.282 (1.155)	DT 10.211 (1.110)	loss 6.907 (6.907)	prob 2.684 (2.684)	GS 30.875 (30.875)	mem 39.863
Train: [58][395/750]	BT 0.061 (1.154)	DT 0.014 (1.110)	loss 7.053 (7.053)	prob 2.805 (2.805)	GS 35.516 (35.516)	mem 39.742
Train: [58][400/750]	BT 0.077 (1.141)	DT 0.010 (1.096)	loss 6.779 (6.779)	prob 3.246 (3.246)	GS 34.141 (34.141)	mem 39.708
Train: [58][405/750]	BT 0.035 (1.144)	DT 0.002 (1.099)	loss 6.922 (6.922)	prob 2.490 (2.490)	GS 30.031 (30.031)	mem 40.009
Train: [58][410/750]	BT 0.032 (1.146)	DT 0.001 (1.101)	loss 6.806 (6.806)	prob 2.609 (2.609)	GS 34.672 (34.672)	mem 39.686
Train: [58][415/750]	BT 0.053 (1.154)	DT 0.009 (1.109)	loss 7.582 (7.582)	prob 2.276 (2.276)	GS 37.156 (37.156)	mem 39.781
Train: [58][420/750]	BT 0.022 (1.144)	DT 0.001 (1.100)	loss 7.083 (7.083)	prob 2.102 (2.102)	GS 34.875 (34.875)	mem 39.784
Train: [58][425/750]	BT 0.049 (1.132)	DT 0.008 (1.087)	loss 7.199 (7.199)	prob 2.580 (2.580)	GS 33.047 (33.047)	mem 39.848
Train: [58][430/750]	BT 2.461 (1.149)	DT 2.428 (1.104)	loss 6.861 (6.861)	prob 3.033 (3.033)	GS 36.312 (36.312)	mem 39.766
Train: [58][435/750]	BT 0.033 (1.146)	DT 0.002 (1.101)	loss 6.987 (6.987)	prob 3.407 (3.407)	GS 29.250 (29.250)	mem 39.773
Train: [58][440/750]	BT 0.076 (1.147)	DT 0.004 (1.102)	loss 6.772 (6.772)	prob 3.240 (3.240)	GS 36.562 (36.562)	mem 39.855
Train: [58][445/750]	BT 0.052 (1.143)	DT 0.002 (1.098)	loss 6.923 (6.923)	prob 2.781 (2.781)	GS 33.016 (33.016)	mem 39.739
Train: [58][450/750]	BT 10.249 (1.154)	DT 10.212 (1.109)	loss 6.841 (6.841)	prob 3.160 (3.160)	GS 38.188 (38.188)	mem 39.874
Train: [58][455/750]	BT 0.035 (1.143)	DT 0.007 (1.098)	loss 7.112 (7.112)	prob 2.260 (2.260)	GS 32.344 (32.344)	mem 39.874
Train: [58][460/750]	BT 3.666 (1.140)	DT 3.605 (1.095)	loss 6.855 (6.855)	prob 2.310 (2.310)	GS 36.422 (36.422)	mem 39.881
Train: [58][465/750]	BT 0.047 (1.141)	DT 0.001 (1.096)	loss 6.750 (6.750)	prob 2.644 (2.644)	GS 26.781 (26.781)	mem 39.774
Train: [58][470/750]	BT 0.031 (1.140)	DT 0.001 (1.095)	loss 7.051 (7.051)	prob 2.502 (2.502)	GS 34.094 (34.094)	mem 39.799
Train: [58][475/750]	BT 0.026 (1.144)	DT 0.001 (1.099)	loss 6.891 (6.891)	prob 3.136 (3.136)	GS 32.891 (32.891)	mem 39.878
Train: [58][480/750]	BT 4.336 (1.141)	DT 4.265 (1.097)	loss 6.733 (6.733)	prob 3.340 (3.340)	GS 33.016 (33.016)	mem 39.810
Train: [58][485/750]	BT 0.102 (1.141)	DT 0.004 (1.096)	loss 7.146 (7.146)	prob 2.409 (2.409)	GS 32.062 (32.062)	mem 39.934
Train: [58][490/750]	BT 3.766 (1.146)	DT 3.705 (1.102)	loss 6.918 (6.918)	prob 3.698 (3.698)	GS 34.984 (34.984)	mem 39.910
Train: [58][495/750]	BT 0.033 (1.135)	DT 0.002 (1.091)	loss 6.885 (6.885)	prob 3.148 (3.148)	GS 29.156 (29.156)	mem 39.816
Train: [58][500/750]	BT 0.101 (1.144)	DT 0.012 (1.099)	loss 6.958 (6.958)	prob 2.436 (2.436)	GS 28.984 (28.984)	mem 39.787
Train: [58][505/750]	BT 0.027 (1.137)	DT 0.001 (1.092)	loss 6.913 (6.913)	prob 2.932 (2.932)	GS 31.000 (31.000)	mem 39.751
Train: [58][510/750]	BT 8.460 (1.146)	DT 8.428 (1.101)	loss 6.953 (6.953)	prob 2.766 (2.766)	GS 33.469 (33.469)	mem 39.874
Train: [58][515/750]	BT 0.052 (1.147)	DT 0.008 (1.102)	loss 7.154 (7.154)	prob 2.367 (2.367)	GS 26.547 (26.547)	mem 39.922
Train: [58][520/750]	BT 0.060 (1.137)	DT 0.008 (1.092)	loss 6.887 (6.887)	prob 2.758 (2.758)	GS 32.656 (32.656)	mem 40.025
Train: [58][525/750]	BT 0.032 (1.137)	DT 0.001 (1.092)	loss 7.121 (7.121)	prob 3.065 (3.065)	GS 29.188 (29.188)	mem 39.898
Train: [58][530/750]	BT 0.061 (1.146)	DT 0.001 (1.101)	loss 6.750 (6.750)	prob 3.645 (3.645)	GS 36.016 (36.016)	mem 39.776
Train: [58][535/750]	BT 0.082 (1.139)	DT 0.018 (1.094)	loss 7.230 (7.230)	prob 2.741 (2.741)	GS 44.891 (44.891)	mem 39.780
Train: [58][540/750]	BT 0.049 (1.146)	DT 0.003 (1.101)	loss 7.474 (7.474)	prob 2.067 (2.067)	GS 37.391 (37.391)	mem 39.866
Train: [58][545/750]	BT 0.024 (1.135)	DT 0.001 (1.091)	loss 6.751 (6.751)	prob 2.821 (2.821)	GS 30.516 (30.516)	mem 39.867
Train: [58][550/750]	BT 5.165 (1.147)	DT 5.105 (1.102)	loss 6.748 (6.748)	prob 3.056 (3.056)	GS 32.141 (32.141)	mem 39.852
Train: [58][555/750]	BT 0.032 (1.141)	DT 0.001 (1.097)	loss 7.008 (7.008)	prob 2.568 (2.568)	GS 31.094 (31.094)	mem 39.896
Train: [58][560/750]	BT 0.404 (1.142)	DT 0.365 (1.098)	loss 6.897 (6.897)	prob 2.858 (2.858)	GS 29.797 (29.797)	mem 39.868
Train: [58][565/750]	BT 0.031 (1.141)	DT 0.001 (1.097)	loss 6.779 (6.779)	prob 2.966 (2.966)	GS 28.969 (28.969)	mem 39.963
Train: [58][570/750]	BT 10.559 (1.150)	DT 10.529 (1.106)	loss 6.820 (6.820)	prob 3.165 (3.165)	GS 34.594 (34.594)	mem 40.009
Train: [58][575/750]	BT 0.049 (1.141)	DT 0.010 (1.096)	loss 6.764 (6.764)	prob 3.231 (3.231)	GS 30.469 (30.469)	mem 40.011
Train: [58][580/750]	BT 0.104 (1.135)	DT 0.003 (1.091)	loss 6.767 (6.767)	prob 2.399 (2.399)	GS 34.719 (34.719)	mem 39.940
Train: [58][585/750]	BT 0.035 (1.144)	DT 0.001 (1.099)	loss 7.658 (7.658)	prob 1.650 (1.650)	GS 29.094 (29.094)	mem 39.951
Train: [58][590/750]	BT 1.737 (1.137)	DT 1.678 (1.093)	loss 6.993 (6.993)	prob 2.605 (2.605)	GS 33.797 (33.797)	mem 40.001
Train: [58][595/750]	BT 0.078 (1.154)	DT 0.009 (1.110)	loss 7.009 (7.009)	prob 2.296 (2.296)	GS 35.109 (35.109)	mem 39.937
Train: [58][600/750]	BT 0.033 (1.145)	DT 0.001 (1.100)	loss 7.006 (7.006)	prob 2.616 (2.616)	GS 35.594 (35.594)	mem 39.982
Train: [58][605/750]	BT 0.107 (1.136)	DT 0.004 (1.091)	loss 7.037 (7.037)	prob 2.085 (2.085)	GS 33.797 (33.797)	mem 39.938
Train: [58][610/750]	BT 0.029 (1.150)	DT 0.001 (1.106)	loss 6.781 (6.781)	prob 3.051 (3.051)	GS 32.812 (32.812)	mem 39.918
Train: [58][615/750]	BT 0.063 (1.141)	DT 0.004 (1.097)	loss 7.488 (7.488)	prob 1.977 (1.977)	GS 28.703 (28.703)	mem 39.917
Train: [58][620/750]	BT 0.038 (1.156)	DT 0.002 (1.112)	loss 6.882 (6.882)	prob 2.936 (2.936)	GS 35.594 (35.594)	mem 39.882
Train: [58][625/750]	BT 0.061 (1.147)	DT 0.004 (1.103)	loss 6.999 (6.999)	prob 2.684 (2.684)	GS 29.375 (29.375)	mem 39.883
Train: [58][630/750]	BT 14.078 (1.161)	DT 14.047 (1.117)	loss 6.884 (6.884)	prob 3.195 (3.195)	GS 31.484 (31.484)	mem 39.968
Train: [58][635/750]	BT 0.034 (1.152)	DT 0.001 (1.108)	loss 7.361 (7.361)	prob 1.987 (1.987)	GS 30.562 (30.562)	mem 40.061
Train: [58][640/750]	BT 0.032 (1.144)	DT 0.003 (1.099)	loss 6.967 (6.967)	prob 2.620 (2.620)	GS 32.078 (32.078)	mem 39.915
Train: [58][645/750]	BT 0.094 (1.152)	DT 0.003 (1.108)	loss 7.105 (7.105)	prob 2.567 (2.567)	GS 27.875 (27.875)	mem 40.035
Train: [58][650/750]	BT 0.071 (1.144)	DT 0.009 (1.099)	loss 6.953 (6.953)	prob 2.852 (2.852)	GS 31.844 (31.844)	mem 39.951
Train: [58][655/750]	BT 0.034 (1.155)	DT 0.002 (1.111)	loss 7.063 (7.063)	prob 2.873 (2.873)	GS 31.672 (31.672)	mem 39.903
Train: [58][660/750]	BT 0.083 (1.147)	DT 0.012 (1.103)	loss 6.879 (6.879)	prob 3.104 (3.104)	GS 32.906 (32.906)	mem 40.043
Train: [58][665/750]	BT 0.080 (1.139)	DT 0.005 (1.094)	loss 7.122 (7.122)	prob 3.140 (3.140)	GS 30.094 (30.094)	mem 40.144
Train: [58][670/750]	BT 0.104 (1.149)	DT 0.001 (1.105)	loss 6.939 (6.939)	prob 2.827 (2.827)	GS 33.234 (33.234)	mem 40.040
Train: [58][675/750]	BT 0.095 (1.141)	DT 0.001 (1.097)	loss 6.842 (6.842)	prob 2.993 (2.993)	GS 27.562 (27.562)	mem 40.072
Train: [58][680/750]	BT 0.022 (1.154)	DT 0.001 (1.109)	loss 6.875 (6.875)	prob 2.713 (2.713)	GS 38.188 (38.188)	mem 39.975
Train: [58][685/750]	BT 0.039 (1.145)	DT 0.001 (1.101)	loss 6.926 (6.926)	prob 2.266 (2.266)	GS 31.156 (31.156)	mem 39.975
Train: [58][690/750]	BT 13.084 (1.156)	DT 13.054 (1.112)	loss 6.811 (6.811)	prob 2.755 (2.755)	GS 35.125 (35.125)	mem 40.039
Train: [58][695/750]	BT 0.030 (1.148)	DT 0.002 (1.104)	loss 6.935 (6.935)	prob 2.987 (2.987)	GS 35.531 (35.531)	mem 40.107
Train: [58][700/750]	BT 0.052 (1.141)	DT 0.002 (1.096)	loss 6.726 (6.726)	prob 2.692 (2.692)	GS 30.719 (30.719)	mem 40.045
Train: [58][705/750]	BT 0.043 (1.153)	DT 0.010 (1.109)	loss 6.919 (6.919)	prob 2.624 (2.624)	GS 32.422 (32.422)	mem 39.896
Train: [58][710/750]	BT 0.046 (1.146)	DT 0.001 (1.101)	loss 6.874 (6.874)	prob 2.290 (2.290)	GS 33.297 (33.297)	mem 39.897
Train: [58][715/750]	BT 0.032 (1.158)	DT 0.001 (1.114)	loss 7.164 (7.164)	prob 1.997 (1.997)	GS 34.953 (34.953)	mem 39.872
Train: [58][720/750]	BT 0.022 (1.150)	DT 0.001 (1.106)	loss 6.931 (6.931)	prob 3.467 (3.467)	GS 30.891 (30.891)	mem 39.873
Train: [58][725/750]	BT 0.030 (1.142)	DT 0.001 (1.098)	loss 6.741 (6.741)	prob 2.842 (2.842)	GS 29.797 (29.797)	mem 39.873
Train: [58][730/750]	BT 0.043 (1.150)	DT 0.011 (1.106)	loss 7.014 (7.014)	prob 2.219 (2.219)	GS 29.375 (29.375)	mem 39.520
Train: [58][735/750]	BT 0.026 (1.142)	DT 0.001 (1.099)	loss 6.991 (6.991)	prob 2.881 (2.881)	GS 26.562 (26.562)	mem 39.520
Train: [58][740/750]	BT 0.029 (1.146)	DT 0.001 (1.103)	loss 6.999 (6.999)	prob 3.062 (3.062)	GS 29.672 (29.672)	mem 7.602
Train: [58][745/750]	BT 0.044 (1.139)	DT 0.011 (1.095)	loss 6.683 (6.683)	prob 2.778 (2.778)	GS 28.844 (28.844)	mem 7.632
Train: [58][750/750]	BT 2.117 (1.134)	DT 2.084 (1.091)	loss 6.597 (6.597)	prob 2.670 (2.670)	GS 34.844 (34.844)	mem 7.623
Train: [58][755/750]	BT 0.030 (1.127)	DT 0.001 (1.083)	loss 7.230 (7.230)	prob 2.053 (2.053)	GS 31.250 (31.250)	mem 7.622
epoch 58, total time 851.00
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [59][1/750]	BT 23.148 (23.148)	DT 23.074 (23.074)	loss 6.775 (6.775)	prob 2.852 (2.852)	GS 32.969 (32.969)	mem 38.579
Train: [59][5/750]	BT 0.063 (4.686)	DT 0.005 (4.623)	loss 6.898 (6.898)	prob 2.517 (2.517)	GS 30.828 (30.828)	mem 38.666
Train: [59][10/750]	BT 0.040 (2.366)	DT 0.004 (2.314)	loss 6.776 (6.776)	prob 2.304 (2.304)	GS 37.344 (37.344)	mem 38.584
Train: [59][15/750]	BT 0.036 (2.357)	DT 0.002 (2.307)	loss 6.805 (6.805)	prob 2.821 (2.821)	GS 27.406 (27.406)	mem 39.063
Train: [59][20/750]	BT 0.038 (2.072)	DT 0.006 (2.025)	loss 7.024 (7.024)	prob 2.863 (2.863)	GS 27.922 (27.922)	mem 38.840
Train: [59][25/750]	BT 0.028 (1.727)	DT 0.001 (1.680)	loss 6.854 (6.854)	prob 2.068 (2.068)	GS 27.281 (27.281)	mem 38.829
Train: [59][30/750]	BT 1.294 (1.873)	DT 1.145 (1.823)	loss 6.745 (6.745)	prob 3.481 (3.481)	GS 39.016 (39.016)	mem 38.867
Train: [59][35/750]	BT 0.037 (1.617)	DT 0.002 (1.566)	loss 6.855 (6.855)	prob 2.760 (2.760)	GS 33.281 (33.281)	mem 38.868
Train: [59][40/750]	BT 3.382 (1.702)	DT 3.349 (1.651)	loss 6.919 (6.919)	prob 3.013 (3.013)	GS 30.031 (30.031)	mem 38.956
Train: [59][45/750]	BT 0.032 (1.571)	DT 0.002 (1.521)	loss 6.815 (6.815)	prob 3.092 (3.092)	GS 34.531 (34.531)	mem 38.983
Train: [59][50/750]	BT 5.382 (1.528)	DT 5.345 (1.478)	loss 7.043 (7.043)	prob 2.930 (2.930)	GS 34.844 (34.844)	mem 39.012
Train: [59][55/750]	BT 0.028 (1.515)	DT 0.002 (1.466)	loss 6.933 (6.933)	prob 2.886 (2.886)	GS 27.781 (27.781)	mem 39.099
Train: [59][60/750]	BT 0.060 (1.435)	DT 0.002 (1.387)	loss 6.622 (6.622)	prob 3.697 (3.697)	GS 36.062 (36.062)	mem 39.235
Train: [59][65/750]	BT 0.069 (1.447)	DT 0.014 (1.398)	loss 7.051 (7.051)	prob 2.765 (2.765)	GS 29.969 (29.969)	mem 39.152
Train: [59][70/750]	BT 0.053 (1.376)	DT 0.023 (1.327)	loss 6.778 (6.778)	prob 3.270 (3.270)	GS 31.766 (31.766)	mem 39.066
Train: [59][75/750]	BT 0.025 (1.451)	DT 0.001 (1.403)	loss 7.092 (7.092)	prob 3.097 (3.097)	GS 28.156 (28.156)	mem 39.082
Train: [59][80/750]	BT 0.049 (1.362)	DT 0.002 (1.316)	loss 6.856 (6.856)	prob 2.934 (2.934)	GS 33.828 (33.828)	mem 39.081
Train: [59][85/750]	BT 0.060 (1.291)	DT 0.003 (1.245)	loss 6.983 (6.983)	prob 3.524 (3.524)	GS 34.219 (34.219)	mem 38.999
Train: [59][90/750]	BT 0.052 (1.350)	DT 0.008 (1.304)	loss 6.941 (6.941)	prob 3.011 (3.011)	GS 33.016 (33.016)	mem 39.164
Train: [59][95/750]	BT 0.044 (1.315)	DT 0.002 (1.269)	loss 7.297 (7.297)	prob 2.518 (2.518)	GS 31.062 (31.062)	mem 39.113
Train: [59][100/750]	BT 0.045 (1.361)	DT 0.002 (1.316)	loss 7.042 (7.042)	prob 2.480 (2.480)	GS 33.047 (33.047)	mem 39.040
Train: [59][105/750]	BT 0.066 (1.299)	DT 0.005 (1.254)	loss 6.907 (6.907)	prob 2.450 (2.450)	GS 27.406 (27.406)	mem 39.162
Train: [59][110/750]	BT 11.449 (1.365)	DT 11.406 (1.320)	loss 6.978 (6.978)	prob 2.702 (2.702)	GS 33.812 (33.812)	mem 39.353
Train: [59][115/750]	BT 0.055 (1.308)	DT 0.003 (1.263)	loss 6.891 (6.891)	prob 2.776 (2.776)	GS 35.266 (35.266)	mem 39.495
Train: [59][120/750]	BT 0.055 (1.273)	DT 0.004 (1.229)	loss 6.931 (6.931)	prob 3.493 (3.493)	GS 35.344 (35.344)	mem 39.340
Train: [59][125/750]	BT 0.035 (1.332)	DT 0.001 (1.287)	loss 6.899 (6.899)	prob 3.031 (3.031)	GS 32.906 (32.906)	mem 39.425
Train: [59][130/750]	BT 0.034 (1.281)	DT 0.004 (1.238)	loss 6.792 (6.792)	prob 3.431 (3.431)	GS 36.609 (36.609)	mem 39.425
Train: [59][135/750]	BT 0.031 (1.323)	DT 0.001 (1.279)	loss 6.811 (6.811)	prob 2.942 (2.942)	GS 31.672 (31.672)	mem 39.390
Train: [59][140/750]	BT 0.043 (1.277)	DT 0.002 (1.234)	loss 6.934 (6.934)	prob 2.673 (2.673)	GS 33.312 (33.312)	mem 39.572
Train: [59][145/750]	BT 0.053 (1.234)	DT 0.001 (1.191)	loss 7.127 (7.127)	prob 2.644 (2.644)	GS 32.672 (32.672)	mem 39.571
Train: [59][150/750]	BT 0.116 (1.275)	DT 0.005 (1.232)	loss 7.015 (7.015)	prob 2.498 (2.498)	GS 32.203 (32.203)	mem 39.468
Train: [59][155/750]	BT 0.031 (1.236)	DT 0.001 (1.192)	loss 7.109 (7.109)	prob 2.764 (2.764)	GS 31.438 (31.438)	mem 39.364
Train: [59][160/750]	BT 0.041 (1.286)	DT 0.015 (1.242)	loss 6.974 (6.974)	prob 2.962 (2.962)	GS 32.188 (32.188)	mem 39.543
Train: [59][165/750]	BT 0.085 (1.249)	DT 0.005 (1.204)	loss 6.826 (6.826)	prob 2.494 (2.494)	GS 27.172 (27.172)	mem 39.724
Train: [59][170/750]	BT 10.106 (1.273)	DT 10.070 (1.229)	loss 7.014 (7.014)	prob 2.431 (2.431)	GS 33.078 (33.078)	mem 39.650
Train: [59][175/750]	BT 0.088 (1.238)	DT 0.008 (1.194)	loss 6.990 (6.990)	prob 2.750 (2.750)	GS 29.266 (29.266)	mem 39.652
Train: [59][180/750]	BT 0.052 (1.228)	DT 0.003 (1.184)	loss 7.075 (7.075)	prob 2.316 (2.316)	GS 31.281 (31.281)	mem 39.702
Train: [59][185/750]	BT 0.033 (1.253)	DT 0.002 (1.209)	loss 6.931 (6.931)	prob 2.474 (2.474)	GS 32.000 (32.000)	mem 39.797
Train: [59][190/750]	BT 2.115 (1.232)	DT 2.082 (1.188)	loss 6.829 (6.829)	prob 2.742 (2.742)	GS 37.266 (37.266)	mem 39.739
Train: [59][195/750]	BT 0.027 (1.282)	DT 0.001 (1.238)	loss 6.930 (6.930)	prob 2.763 (2.763)	GS 29.766 (29.766)	mem 39.794
Train: [59][200/750]	BT 0.045 (1.252)	DT 0.001 (1.207)	loss 6.769 (6.769)	prob 2.195 (2.195)	GS 33.578 (33.578)	mem 39.643
Train: [59][205/750]	BT 0.075 (1.223)	DT 0.011 (1.178)	loss 6.890 (6.890)	prob 2.983 (2.983)	GS 29.703 (29.703)	mem 39.659
Train: [59][210/750]	BT 0.026 (1.259)	DT 0.001 (1.214)	loss 7.088 (7.088)	prob 1.980 (1.980)	GS 34.156 (34.156)	mem 39.745
Train: [59][215/750]	BT 0.022 (1.231)	DT 0.001 (1.186)	loss 7.080 (7.080)	prob 2.178 (2.178)	GS 30.797 (30.797)	mem 39.747
Train: [59][220/750]	BT 0.027 (1.270)	DT 0.001 (1.225)	loss 6.984 (6.984)	prob 2.436 (2.436)	GS 33.125 (33.125)	mem 39.718
Train: [59][225/750]	BT 0.051 (1.242)	DT 0.006 (1.198)	loss 7.132 (7.132)	prob 2.389 (2.389)	GS 48.312 (48.312)	mem 39.745
Train: [59][230/750]	BT 11.973 (1.268)	DT 11.914 (1.224)	loss 6.863 (6.863)	prob 2.901 (2.901)	GS 33.219 (33.219)	mem 40.001
Train: [59][235/750]	BT 0.035 (1.242)	DT 0.006 (1.198)	loss 6.915 (6.915)	prob 2.578 (2.578)	GS 31.297 (31.297)	mem 39.769
Train: [59][240/750]	BT 0.034 (1.217)	DT 0.004 (1.173)	loss 6.856 (6.856)	prob 2.490 (2.490)	GS 35.391 (35.391)	mem 39.769
Train: [59][245/750]	BT 0.028 (1.250)	DT 0.008 (1.206)	loss 6.988 (6.988)	prob 2.313 (2.313)	GS 34.172 (34.172)	mem 39.825
Train: [59][250/750]	BT 0.044 (1.226)	DT 0.004 (1.182)	loss 6.777 (6.777)	prob 2.579 (2.579)	GS 33.703 (33.703)	mem 39.824
Train: [59][255/750]	BT 0.021 (1.258)	DT 0.001 (1.215)	loss 6.990 (6.990)	prob 2.730 (2.730)	GS 31.016 (31.016)	mem 39.737
Train: [59][260/750]	BT 0.043 (1.235)	DT 0.007 (1.192)	loss 6.908 (6.908)	prob 2.463 (2.463)	GS 36.438 (36.438)	mem 39.907
Train: [59][265/750]	BT 0.029 (1.213)	DT 0.001 (1.169)	loss 6.882 (6.882)	prob 2.717 (2.717)	GS 34.141 (34.141)	mem 39.738
Train: [59][270/750]	BT 0.029 (1.239)	DT 0.001 (1.196)	loss 7.081 (7.081)	prob 2.876 (2.876)	GS 34.047 (34.047)	mem 39.777
Train: [59][275/750]	BT 0.032 (1.218)	DT 0.001 (1.175)	loss 6.998 (6.998)	prob 2.475 (2.475)	GS 32.859 (32.859)	mem 39.719
Train: [59][280/750]	BT 0.032 (1.241)	DT 0.002 (1.198)	loss 6.796 (6.796)	prob 2.590 (2.590)	GS 35.094 (35.094)	mem 39.799
Train: [59][285/750]	BT 0.028 (1.220)	DT 0.001 (1.177)	loss 7.073 (7.073)	prob 2.154 (2.154)	GS 29.656 (29.656)	mem 39.799
Train: [59][290/750]	BT 12.358 (1.242)	DT 12.329 (1.200)	loss 6.853 (6.853)	prob 3.456 (3.456)	GS 29.953 (29.953)	mem 39.841
Train: [59][295/750]	BT 0.085 (1.222)	DT 0.021 (1.179)	loss 7.144 (7.144)	prob 2.291 (2.291)	GS 28.922 (28.922)	mem 39.888
Train: [59][300/750]	BT 0.042 (1.203)	DT 0.002 (1.160)	loss 7.035 (7.035)	prob 2.784 (2.784)	GS 35.969 (35.969)	mem 39.844
Train: [59][305/750]	BT 0.047 (1.236)	DT 0.016 (1.194)	loss 7.035 (7.035)	prob 2.757 (2.757)	GS 28.750 (28.750)	mem 39.832
Train: [59][310/750]	BT 0.042 (1.217)	DT 0.001 (1.174)	loss 7.005 (7.005)	prob 2.884 (2.884)	GS 31.797 (31.797)	mem 39.834
Train: [59][315/750]	BT 0.032 (1.238)	DT 0.007 (1.196)	loss 6.880 (6.880)	prob 3.123 (3.123)	GS 27.719 (27.719)	mem 39.814
Train: [59][320/750]	BT 0.045 (1.220)	DT 0.004 (1.177)	loss 7.152 (7.152)	prob 1.620 (1.620)	GS 37.109 (37.109)	mem 40.079
Train: [59][325/750]	BT 0.097 (1.202)	DT 0.001 (1.159)	loss 7.283 (7.283)	prob 2.866 (2.866)	GS 29.188 (29.188)	mem 39.821
Train: [59][330/750]	BT 0.074 (1.218)	DT 0.006 (1.175)	loss 6.811 (6.811)	prob 2.417 (2.417)	GS 36.031 (36.031)	mem 39.871
Train: [59][335/750]	BT 0.096 (1.201)	DT 0.009 (1.158)	loss 6.957 (6.957)	prob 2.829 (2.829)	GS 29.625 (29.625)	mem 39.955
Train: [59][340/750]	BT 0.023 (1.217)	DT 0.001 (1.174)	loss 6.845 (6.845)	prob 2.773 (2.773)	GS 33.250 (33.250)	mem 39.886
Train: [59][345/750]	BT 0.030 (1.200)	DT 0.001 (1.157)	loss 6.910 (6.910)	prob 1.997 (1.997)	GS 29.219 (29.219)	mem 39.887
Train: [59][350/750]	BT 12.722 (1.220)	DT 12.676 (1.177)	loss 7.175 (7.175)	prob 1.828 (1.828)	GS 31.109 (31.109)	mem 39.902
Train: [59][355/750]	BT 0.078 (1.204)	DT 0.023 (1.160)	loss 6.921 (6.921)	prob 2.846 (2.846)	GS 29.531 (29.531)	mem 39.901
Train: [59][360/750]	BT 0.073 (1.188)	DT 0.002 (1.144)	loss 6.992 (6.992)	prob 2.112 (2.112)	GS 32.672 (32.672)	mem 39.901
Train: [59][365/750]	BT 0.026 (1.197)	DT 0.001 (1.154)	loss 6.803 (6.803)	prob 2.563 (2.563)	GS 33.281 (33.281)	mem 39.996
Train: [59][370/750]	BT 0.900 (1.186)	DT 0.865 (1.142)	loss 6.729 (6.729)	prob 2.720 (2.720)	GS 31.938 (31.938)	mem 39.929
Train: [59][375/750]	BT 0.030 (1.198)	DT 0.001 (1.154)	loss 6.919 (6.919)	prob 2.512 (2.512)	GS 31.234 (31.234)	mem 39.968
Train: [59][380/750]	BT 0.032 (1.183)	DT 0.001 (1.139)	loss 6.999 (6.999)	prob 2.289 (2.289)	GS 28.281 (28.281)	mem 40.021
Train: [59][385/750]	BT 0.117 (1.168)	DT 0.002 (1.125)	loss 6.918 (6.918)	prob 2.511 (2.511)	GS 32.609 (32.609)	mem 39.932
Train: [59][390/750]	BT 0.074 (1.192)	DT 0.011 (1.148)	loss 6.934 (6.934)	prob 1.851 (1.851)	GS 29.844 (29.844)	mem 39.895
Train: [59][395/750]	BT 0.047 (1.177)	DT 0.011 (1.134)	loss 7.191 (7.191)	prob 2.279 (2.279)	GS 25.125 (25.125)	mem 39.900
Train: [59][400/750]	BT 1.211 (1.192)	DT 1.188 (1.149)	loss 6.872 (6.872)	prob 3.663 (3.663)	GS 35.031 (35.031)	mem 39.893
Train: [59][405/750]	BT 0.026 (1.178)	DT 0.001 (1.134)	loss 6.951 (6.951)	prob 2.552 (2.552)	GS 38.266 (38.266)	mem 39.936
Train: [59][410/750]	BT 8.298 (1.190)	DT 8.256 (1.146)	loss 7.340 (7.340)	prob 1.707 (1.707)	GS 32.609 (32.609)	mem 39.910
Train: [59][415/750]	BT 0.036 (1.180)	DT 0.002 (1.136)	loss 7.139 (7.139)	prob 2.005 (2.005)	GS 31.656 (31.656)	mem 39.917
Train: [59][420/750]	BT 0.051 (1.180)	DT 0.001 (1.136)	loss 6.981 (6.981)	prob 2.377 (2.377)	GS 37.047 (37.047)	mem 39.983
Train: [59][425/750]	BT 0.030 (1.184)	DT 0.001 (1.140)	loss 7.098 (7.098)	prob 2.255 (2.255)	GS 26.891 (26.891)	mem 39.870
Train: [59][430/750]	BT 3.913 (1.180)	DT 3.833 (1.136)	loss 6.770 (6.770)	prob 2.818 (2.818)	GS 32.891 (32.891)	mem 39.926
Train: [59][435/750]	BT 0.026 (1.180)	DT 0.001 (1.136)	loss 7.285 (7.285)	prob 2.560 (2.560)	GS 29.641 (29.641)	mem 39.801
Train: [59][440/750]	BT 0.040 (1.178)	DT 0.001 (1.134)	loss 6.903 (6.903)	prob 2.543 (2.543)	GS 36.469 (36.469)	mem 39.887
Train: [59][445/750]	BT 0.071 (1.173)	DT 0.014 (1.130)	loss 7.101 (7.101)	prob 2.415 (2.415)	GS 29.984 (29.984)	mem 39.847
Train: [59][450/750]	BT 5.434 (1.183)	DT 5.402 (1.139)	loss 6.818 (6.818)	prob 2.620 (2.620)	GS 36.016 (36.016)	mem 39.900
Train: [59][455/750]	BT 0.046 (1.180)	DT 0.009 (1.136)	loss 7.018 (7.018)	prob 1.907 (1.907)	GS 34.781 (34.781)	mem 39.841
Train: [59][460/750]	BT 2.297 (1.174)	DT 2.266 (1.131)	loss 6.862 (6.862)	prob 2.935 (2.935)	GS 32.688 (32.688)	mem 39.864
Train: [59][465/750]	BT 0.098 (1.172)	DT 0.002 (1.128)	loss 7.034 (7.034)	prob 2.662 (2.662)	GS 27.750 (27.750)	mem 39.977
Train: [59][470/750]	BT 0.034 (1.169)	DT 0.001 (1.125)	loss 6.773 (6.773)	prob 2.379 (2.379)	GS 38.344 (38.344)	mem 39.925
Train: [59][475/750]	BT 0.032 (1.175)	DT 0.002 (1.131)	loss 6.833 (6.833)	prob 2.657 (2.657)	GS 30.797 (30.797)	mem 39.919
Train: [59][480/750]	BT 0.115 (1.166)	DT 0.012 (1.121)	loss 6.742 (6.742)	prob 2.450 (2.450)	GS 29.328 (29.328)	mem 39.993
Train: [59][485/750]	BT 0.032 (1.159)	DT 0.001 (1.115)	loss 6.849 (6.849)	prob 2.226 (2.226)	GS 30.422 (30.422)	mem 39.895
Train: [59][490/750]	BT 4.675 (1.172)	DT 4.632 (1.128)	loss 6.767 (6.767)	prob 2.644 (2.644)	GS 36.953 (36.953)	mem 40.052
Train: [59][495/750]	BT 0.047 (1.161)	DT 0.002 (1.117)	loss 6.709 (6.709)	prob 2.799 (2.799)	GS 34.219 (34.219)	mem 39.957
Train: [59][500/750]	BT 0.072 (1.165)	DT 0.011 (1.121)	loss 6.997 (6.997)	prob 2.572 (2.572)	GS 38.203 (38.203)	mem 40.030
Train: [59][505/750]	BT 0.032 (1.162)	DT 0.002 (1.117)	loss 7.144 (7.144)	prob 2.238 (2.238)	GS 29.641 (29.641)	mem 39.985
Train: [59][510/750]	BT 4.896 (1.166)	DT 4.855 (1.121)	loss 7.032 (7.032)	prob 2.399 (2.399)	GS 32.062 (32.062)	mem 39.992
Train: [59][515/750]	BT 0.032 (1.165)	DT 0.001 (1.120)	loss 6.761 (6.761)	prob 2.361 (2.361)	GS 31.891 (31.891)	mem 40.006
Train: [59][520/750]	BT 0.057 (1.155)	DT 0.015 (1.110)	loss 6.751 (6.751)	prob 2.865 (2.865)	GS 34.719 (34.719)	mem 40.008
Train: [59][525/750]	BT 0.132 (1.162)	DT 0.052 (1.117)	loss 6.980 (6.980)	prob 1.993 (1.993)	GS 34.828 (34.828)	mem 40.012
Train: [59][530/750]	BT 0.045 (1.158)	DT 0.008 (1.113)	loss 6.987 (6.987)	prob 2.795 (2.795)	GS 35.281 (35.281)	mem 40.016
Train: [59][535/750]	BT 0.052 (1.163)	DT 0.002 (1.118)	loss 6.961 (6.961)	prob 2.618 (2.618)	GS 35.859 (35.859)	mem 40.033
Train: [59][540/750]	BT 0.066 (1.163)	DT 0.009 (1.118)	loss 7.067 (7.067)	prob 2.370 (2.370)	GS 32.406 (32.406)	mem 40.071
Train: [59][545/750]	BT 0.055 (1.157)	DT 0.002 (1.111)	loss 6.834 (6.834)	prob 2.471 (2.471)	GS 28.312 (28.312)	mem 40.050
Train: [59][550/750]	BT 7.189 (1.167)	DT 7.118 (1.121)	loss 6.835 (6.835)	prob 2.271 (2.271)	GS 31.156 (31.156)	mem 40.029
Train: [59][555/750]	BT 0.063 (1.156)	DT 0.011 (1.111)	loss 7.088 (7.088)	prob 2.067 (2.067)	GS 33.562 (33.562)	mem 40.001
Train: [59][560/750]	BT 0.029 (1.154)	DT 0.001 (1.109)	loss 6.900 (6.900)	prob 3.001 (3.001)	GS 37.984 (37.984)	mem 40.219
Train: [59][565/750]	BT 0.030 (1.164)	DT 0.001 (1.118)	loss 6.914 (6.914)	prob 2.617 (2.617)	GS 29.344 (29.344)	mem 39.915
Train: [59][570/750]	BT 0.037 (1.154)	DT 0.005 (1.109)	loss 6.725 (6.725)	prob 2.867 (2.867)	GS 35.875 (35.875)	mem 39.932
Train: [59][575/750]	BT 0.034 (1.177)	DT 0.002 (1.132)	loss 6.923 (6.923)	prob 2.700 (2.700)	GS 33.578 (33.578)	mem 39.931
Train: [59][580/750]	BT 0.033 (1.167)	DT 0.001 (1.122)	loss 6.882 (6.882)	prob 2.763 (2.763)	GS 36.078 (36.078)	mem 39.803
Train: [59][585/750]	BT 0.057 (1.158)	DT 0.002 (1.113)	loss 6.863 (6.863)	prob 2.810 (2.810)	GS 31.922 (31.922)	mem 39.805
Train: [59][590/750]	BT 0.061 (1.170)	DT 0.014 (1.125)	loss 6.865 (6.865)	prob 3.058 (3.058)	GS 34.906 (34.906)	mem 39.929
Train: [59][595/750]	BT 0.057 (1.160)	DT 0.005 (1.115)	loss 6.969 (6.969)	prob 2.719 (2.719)	GS 28.781 (28.781)	mem 40.065
Train: [59][600/750]	BT 0.032 (1.169)	DT 0.001 (1.124)	loss 6.777 (6.777)	prob 3.024 (3.024)	GS 34.359 (34.359)	mem 40.070
Train: [59][605/750]	BT 0.034 (1.159)	DT 0.006 (1.115)	loss 6.916 (6.916)	prob 2.363 (2.363)	GS 27.438 (27.438)	mem 39.869
Train: [59][610/750]	BT 11.572 (1.172)	DT 11.537 (1.127)	loss 6.898 (6.898)	prob 2.842 (2.842)	GS 33.094 (33.094)	mem 39.863
Train: [59][615/750]	BT 0.028 (1.163)	DT 0.001 (1.118)	loss 7.018 (7.018)	prob 2.663 (2.663)	GS 28.359 (28.359)	mem 39.871
Train: [59][620/750]	BT 0.448 (1.155)	DT 0.409 (1.110)	loss 6.830 (6.830)	prob 2.606 (2.606)	GS 34.781 (34.781)	mem 39.921
Train: [59][625/750]	BT 0.056 (1.168)	DT 0.001 (1.123)	loss 6.987 (6.987)	prob 2.428 (2.428)	GS 36.688 (36.688)	mem 39.928
Train: [59][630/750]	BT 0.078 (1.160)	DT 0.002 (1.114)	loss 6.658 (6.658)	prob 2.806 (2.806)	GS 32.891 (32.891)	mem 39.929
Train: [59][635/750]	BT 0.056 (1.174)	DT 0.009 (1.129)	loss 7.065 (7.065)	prob 2.600 (2.600)	GS 32.266 (32.266)	mem 39.901
Train: [59][640/750]	BT 0.030 (1.165)	DT 0.001 (1.120)	loss 6.871 (6.871)	prob 3.282 (3.282)	GS 33.328 (33.328)	mem 39.902
Train: [59][645/750]	BT 0.062 (1.157)	DT 0.012 (1.111)	loss 6.829 (6.829)	prob 2.865 (2.865)	GS 25.828 (25.828)	mem 39.934
Train: [59][650/750]	BT 0.057 (1.168)	DT 0.001 (1.123)	loss 7.226 (7.226)	prob 2.814 (2.814)	GS 35.797 (35.797)	mem 40.034
Train: [59][655/750]	BT 0.033 (1.160)	DT 0.002 (1.115)	loss 6.940 (6.940)	prob 2.808 (2.808)	GS 31.844 (31.844)	mem 39.976
arpack error, retry= 0
arpack error, retry= 0
arpack error, retry= 0
Train: [59][660/750]	BT 0.031 (1.171)	DT 0.001 (1.126)	loss 6.838 (6.838)	prob 2.632 (2.632)	GS 31.938 (31.938)	mem 39.891
Train: [59][665/750]	BT 0.034 (1.162)	DT 0.002 (1.117)	loss 6.946 (6.946)	prob 2.775 (2.775)	GS 27.469 (27.469)	mem 39.918
Train: [59][670/750]	BT 13.939 (1.175)	DT 13.900 (1.130)	loss 7.222 (7.222)	prob 1.709 (1.709)	GS 31.406 (31.406)	mem 39.936
Train: [59][675/750]	BT 0.059 (1.166)	DT 0.007 (1.121)	loss 6.943 (6.943)	prob 2.683 (2.683)	GS 27.188 (27.188)	mem 40.086
Train: [59][680/750]	BT 0.026 (1.158)	DT 0.002 (1.113)	loss 7.004 (7.004)	prob 3.019 (3.019)	GS 36.547 (36.547)	mem 39.953
Train: [59][685/750]	BT 0.024 (1.171)	DT 0.001 (1.126)	loss 6.907 (6.907)	prob 2.395 (2.395)	GS 31.266 (31.266)	mem 39.774
Train: [59][690/750]	BT 0.108 (1.163)	DT 0.006 (1.118)	loss 6.760 (6.760)	prob 2.639 (2.639)	GS 34.219 (34.219)	mem 39.810
Train: [59][695/750]	BT 0.042 (1.172)	DT 0.006 (1.127)	loss 6.793 (6.793)	prob 2.642 (2.642)	GS 30.656 (30.656)	mem 39.829
Train: [59][700/750]	BT 0.036 (1.164)	DT 0.002 (1.119)	loss 6.758 (6.758)	prob 2.688 (2.688)	GS 33.016 (33.016)	mem 39.829
Train: [59][705/750]	BT 0.110 (1.156)	DT 0.002 (1.111)	loss 6.859 (6.859)	prob 2.560 (2.560)	GS 31.109 (31.109)	mem 39.896
Train: [59][710/750]	BT 0.032 (1.167)	DT 0.002 (1.122)	loss 7.039 (7.039)	prob 1.984 (1.984)	GS 34.000 (34.000)	mem 39.803
Train: [59][715/750]	BT 0.133 (1.159)	DT 0.021 (1.115)	loss 6.821 (6.821)	prob 2.952 (2.952)	GS 33.781 (33.781)	mem 39.778
Train: [59][720/750]	BT 0.033 (1.169)	DT 0.001 (1.124)	loss 6.942 (6.942)	prob 2.809 (2.809)	GS 31.312 (31.312)	mem 39.788
Train: [59][725/750]	BT 0.033 (1.161)	DT 0.001 (1.117)	loss 6.919 (6.919)	prob 3.162 (3.162)	GS 32.297 (32.297)	mem 39.788
Train: [59][730/750]	BT 9.601 (1.167)	DT 9.572 (1.122)	loss 6.826 (6.826)	prob 2.372 (2.372)	GS 29.672 (29.672)	mem 39.422
Train: [59][735/750]	BT 0.023 (1.159)	DT 0.001 (1.115)	loss 6.893 (6.893)	prob 2.086 (2.086)	GS 29.828 (29.828)	mem 39.446
Train: [59][740/750]	BT 1.491 (1.154)	DT 1.430 (1.109)	loss 6.915 (6.915)	prob 3.223 (3.223)	GS 33.891 (33.891)	mem 19.434
Train: [59][745/750]	BT 0.036 (1.155)	DT 0.001 (1.111)	loss 6.846 (6.846)	prob 2.608 (2.608)	GS 36.500 (36.500)	mem 7.587
Train: [59][750/750]	BT 0.020 (1.148)	DT 0.001 (1.103)	loss 7.011 (7.011)	prob 3.395 (3.395)	GS 29.906 (29.906)	mem 7.588
Train: [59][755/750]	BT 0.028 (1.143)	DT 0.001 (1.099)	loss 6.782 (6.782)	prob 3.250 (3.250)	GS 31.062 (31.062)	mem 7.563
epoch 59, total time 863.37
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [60][1/750]	BT 20.718 (20.718)	DT 20.662 (20.662)	loss 6.865 (6.865)	prob 2.988 (2.988)	GS 32.156 (32.156)	mem 38.277
Train: [60][5/750]	BT 0.067 (5.837)	DT 0.002 (5.783)	loss 6.796 (6.796)	prob 2.900 (2.900)	GS 26.781 (26.781)	mem 38.715
Train: [60][10/750]	BT 0.092 (2.960)	DT 0.003 (2.896)	loss 6.623 (6.623)	prob 2.913 (2.913)	GS 33.953 (33.953)	mem 38.681
Train: [60][15/750]	BT 4.035 (2.730)	DT 4.003 (2.674)	loss 6.788 (6.788)	prob 2.460 (2.460)	GS 32.266 (32.266)	mem 38.782
Train: [60][20/750]	BT 0.051 (2.195)	DT 0.007 (2.142)	loss 6.660 (6.660)	prob 2.683 (2.683)	GS 36.203 (36.203)	mem 38.815
Train: [60][25/750]	BT 1.873 (1.841)	DT 1.806 (1.787)	loss 6.912 (6.912)	prob 2.696 (2.696)	GS 31.234 (31.234)	mem 39.059
Train: [60][30/750]	BT 0.065 (1.875)	DT 0.012 (1.822)	loss 6.751 (6.751)	prob 3.588 (3.588)	GS 28.000 (28.000)	mem 38.934
Train: [60][35/750]	BT 0.111 (1.615)	DT 0.025 (1.563)	loss 7.098 (7.098)	prob 2.883 (2.883)	GS 28.766 (28.766)	mem 39.016
Train: [60][40/750]	BT 2.657 (1.744)	DT 2.616 (1.692)	loss 6.888 (6.888)	prob 2.710 (2.710)	GS 35.406 (35.406)	mem 39.049
Train: [60][45/750]	BT 0.067 (1.558)	DT 0.012 (1.504)	loss 6.875 (6.875)	prob 2.872 (2.872)	GS 31.016 (31.016)	mem 38.927
Train: [60][50/750]	BT 4.005 (1.554)	DT 3.971 (1.502)	loss 6.854 (6.854)	prob 3.115 (3.115)	GS 28.891 (28.891)	mem 38.963
Train: [60][55/750]	BT 0.072 (1.563)	DT 0.016 (1.510)	loss 6.891 (6.891)	prob 2.850 (2.850)	GS 37.422 (37.422)	mem 39.026
Train: [60][60/750]	BT 0.093 (1.437)	DT 0.001 (1.384)	loss 6.913 (6.913)	prob 3.032 (3.032)	GS 33.016 (33.016)	mem 39.133
Train: [60][65/750]	BT 0.030 (1.501)	DT 0.001 (1.448)	loss 6.750 (6.750)	prob 3.242 (3.242)	GS 36.203 (36.203)	mem 38.941
Train: [60][70/750]	BT 0.034 (1.397)	DT 0.001 (1.345)	loss 6.943 (6.943)	prob 2.739 (2.739)	GS 30.891 (30.891)	mem 38.940
Train: [60][75/750]	BT 0.064 (1.388)	DT 0.014 (1.336)	loss 6.970 (6.970)	prob 2.344 (2.344)	GS 32.625 (32.625)	mem 39.043
Train: [60][80/750]	BT 0.031 (1.355)	DT 0.001 (1.303)	loss 6.881 (6.881)	prob 3.206 (3.206)	GS 33.094 (33.094)	mem 39.041
Train: [60][85/750]	BT 0.108 (1.279)	DT 0.012 (1.227)	loss 6.855 (6.855)	prob 3.318 (3.318)	GS 33.047 (33.047)	mem 39.044
Train: [60][90/750]	BT 0.068 (1.349)	DT 0.007 (1.297)	loss 7.261 (7.261)	prob 2.622 (2.622)	GS 33.688 (33.688)	mem 39.438
Train: [60][95/750]	BT 0.038 (1.280)	DT 0.003 (1.228)	loss 6.892 (6.892)	prob 2.673 (2.673)	GS 32.047 (32.047)	mem 39.311
Train: [60][100/750]	BT 3.259 (1.374)	DT 3.220 (1.324)	loss 6.958 (6.958)	prob 2.557 (2.557)	GS 33.938 (33.938)	mem 39.330
Train: [60][105/750]	BT 0.036 (1.318)	DT 0.002 (1.268)	loss 6.963 (6.963)	prob 2.339 (2.339)	GS 35.656 (35.656)	mem 39.328
Train: [60][110/750]	BT 8.816 (1.340)	DT 8.782 (1.290)	loss 6.774 (6.774)	prob 2.884 (2.884)	GS 38.484 (38.484)	mem 39.741
Train: [60][115/750]	BT 0.032 (1.298)	DT 0.001 (1.248)	loss 6.909 (6.909)	prob 2.984 (2.984)	GS 33.953 (33.953)	mem 39.567
Train: [60][120/750]	BT 0.060 (1.246)	DT 0.002 (1.196)	loss 6.931 (6.931)	prob 2.453 (2.453)	GS 35.234 (35.234)	mem 39.607
Train: [60][125/750]	BT 0.044 (1.328)	DT 0.001 (1.278)	loss 6.976 (6.976)	prob 2.784 (2.784)	GS 26.172 (26.172)	mem 39.678
Train: [60][130/750]	BT 0.027 (1.277)	DT 0.001 (1.229)	loss 6.848 (6.848)	prob 3.024 (3.024)	GS 33.906 (33.906)	mem 39.677
Train: [60][135/750]	BT 0.036 (1.308)	DT 0.001 (1.260)	loss 6.985 (6.985)	prob 2.735 (2.735)	GS 29.938 (29.938)	mem 39.627
Train: [60][140/750]	BT 0.033 (1.263)	DT 0.001 (1.215)	loss 7.051 (7.051)	prob 2.191 (2.191)	GS 30.125 (30.125)	mem 39.628
Train: [60][145/750]	BT 0.032 (1.221)	DT 0.001 (1.174)	loss 7.034 (7.034)	prob 3.847 (3.847)	GS 33.984 (33.984)	mem 39.629
Train: [60][150/750]	BT 0.072 (1.269)	DT 0.011 (1.221)	loss 7.135 (7.135)	prob 2.366 (2.366)	GS 31.969 (31.969)	mem 39.656
Train: [60][155/750]	BT 0.040 (1.229)	DT 0.001 (1.182)	loss 6.832 (6.832)	prob 2.688 (2.688)	GS 29.906 (29.906)	mem 39.658
Train: [60][160/750]	BT 0.034 (1.260)	DT 0.002 (1.213)	loss 6.853 (6.853)	prob 2.966 (2.966)	GS 34.500 (34.500)	mem 39.842
Train: [60][165/750]	BT 0.079 (1.224)	DT 0.025 (1.176)	loss 7.252 (7.252)	prob 2.227 (2.227)	GS 32.844 (32.844)	mem 39.697
Train: [60][170/750]	BT 14.128 (1.273)	DT 14.082 (1.225)	loss 6.849 (6.849)	prob 3.017 (3.017)	GS 32.000 (32.000)	mem 39.655
Train: [60][175/750]	BT 0.026 (1.238)	DT 0.001 (1.190)	loss 6.892 (6.892)	prob 2.722 (2.722)	GS 30.969 (30.969)	mem 39.682
Train: [60][180/750]	BT 0.077 (1.205)	DT 0.007 (1.157)	loss 6.822 (6.822)	prob 2.703 (2.703)	GS 34.547 (34.547)	mem 39.680
Train: [60][185/750]	BT 0.031 (1.247)	DT 0.001 (1.199)	loss 6.850 (6.850)	prob 3.267 (3.267)	GS 27.875 (27.875)	mem 39.727
Train: [60][190/750]	BT 0.043 (1.215)	DT 0.004 (1.168)	loss 6.750 (6.750)	prob 2.978 (2.978)	GS 34.781 (34.781)	mem 39.773
Train: [60][195/750]	BT 0.028 (1.254)	DT 0.002 (1.206)	loss 7.022 (7.022)	prob 2.591 (2.591)	GS 29.344 (29.344)	mem 39.814
Train: [60][200/750]	BT 0.070 (1.240)	DT 0.012 (1.193)	loss 6.762 (6.762)	prob 3.440 (3.440)	GS 37.125 (37.125)	mem 39.811
Train: [60][205/750]	BT 0.029 (1.210)	DT 0.001 (1.164)	loss 6.744 (6.744)	prob 3.470 (3.470)	GS 32.406 (32.406)	mem 40.176
Train: [60][210/750]	BT 0.052 (1.240)	DT 0.009 (1.193)	loss 6.868 (6.868)	prob 3.330 (3.330)	GS 32.938 (32.938)	mem 39.764
Train: [60][215/750]	BT 0.031 (1.212)	DT 0.002 (1.166)	loss 6.877 (6.877)	prob 2.763 (2.763)	GS 28.969 (28.969)	mem 39.786
Train: [60][220/750]	BT 2.418 (1.237)	DT 2.389 (1.190)	loss 6.857 (6.857)	prob 3.325 (3.325)	GS 32.094 (32.094)	mem 39.837
Train: [60][225/750]	BT 0.050 (1.210)	DT 0.001 (1.164)	loss 6.832 (6.832)	prob 3.248 (3.248)	GS 35.422 (35.422)	mem 39.838
Train: [60][230/750]	BT 7.255 (1.217)	DT 7.204 (1.170)	loss 6.929 (6.929)	prob 2.660 (2.660)	GS 30.359 (30.359)	mem 39.864
Train: [60][235/750]	BT 0.052 (1.216)	DT 0.002 (1.169)	loss 7.132 (7.132)	prob 2.591 (2.591)	GS 28.875 (28.875)	mem 39.882
Train: [60][240/750]	BT 0.028 (1.191)	DT 0.001 (1.145)	loss 6.797 (6.797)	prob 2.886 (2.886)	GS 30.828 (30.828)	mem 39.884
Train: [60][245/750]	BT 0.032 (1.214)	DT 0.002 (1.167)	loss 6.770 (6.770)	prob 2.647 (2.647)	GS 29.047 (29.047)	mem 39.851
Train: [60][250/750]	BT 0.032 (1.190)	DT 0.001 (1.144)	loss 6.760 (6.760)	prob 2.830 (2.830)	GS 37.125 (37.125)	mem 39.851
Train: [60][255/750]	BT 0.050 (1.201)	DT 0.003 (1.155)	loss 6.890 (6.890)	prob 3.081 (3.081)	GS 36.109 (36.109)	mem 39.915
Train: [60][260/750]	BT 0.032 (1.205)	DT 0.001 (1.159)	loss 6.836 (6.836)	prob 3.382 (3.382)	GS 35.938 (35.938)	mem 39.853
Train: [60][265/750]	BT 0.030 (1.183)	DT 0.001 (1.137)	loss 6.822 (6.822)	prob 2.539 (2.539)	GS 32.562 (32.562)	mem 39.855
Train: [60][270/750]	BT 0.032 (1.205)	DT 0.002 (1.159)	loss 6.936 (6.936)	prob 2.680 (2.680)	GS 32.594 (32.594)	mem 39.928
Train: [60][275/750]	BT 0.029 (1.184)	DT 0.001 (1.138)	loss 6.885 (6.885)	prob 3.207 (3.207)	GS 30.406 (30.406)	mem 39.937
Train: [60][280/750]	BT 6.654 (1.206)	DT 6.629 (1.160)	loss 6.918 (6.918)	prob 2.908 (2.908)	GS 30.031 (30.031)	mem 39.901
Train: [60][285/750]	BT 0.062 (1.187)	DT 0.001 (1.142)	loss 7.237 (7.237)	prob 2.286 (2.286)	GS 31.312 (31.312)	mem 39.904
Train: [60][290/750]	BT 8.210 (1.196)	DT 8.178 (1.150)	loss 7.198 (7.198)	prob 2.423 (2.423)	GS 34.750 (34.750)	mem 39.964
Train: [60][295/750]	BT 0.032 (1.198)	DT 0.001 (1.153)	loss 6.954 (6.954)	prob 2.606 (2.606)	GS 31.562 (31.562)	mem 39.928
Train: [60][300/750]	BT 0.032 (1.179)	DT 0.001 (1.134)	loss 6.944 (6.944)	prob 2.934 (2.934)	GS 32.719 (32.719)	mem 39.929
Train: [60][305/750]	BT 0.043 (1.209)	DT 0.016 (1.164)	loss 6.846 (6.846)	prob 2.574 (2.574)	GS 30.453 (30.453)	mem 39.871
Train: [60][310/750]	BT 0.086 (1.191)	DT 0.001 (1.146)	loss 6.975 (6.975)	prob 3.004 (3.004)	GS 31.797 (31.797)	mem 39.963
Train: [60][315/750]	BT 0.054 (1.182)	DT 0.003 (1.137)	loss 6.867 (6.867)	prob 2.489 (2.489)	GS 31.734 (31.734)	mem 39.873
Train: [60][320/750]	BT 0.031 (1.194)	DT 0.001 (1.149)	loss 6.865 (6.865)	prob 2.769 (2.769)	GS 34.891 (34.891)	mem 39.897
Train: [60][325/750]	BT 0.046 (1.176)	DT 0.001 (1.131)	loss 6.828 (6.828)	prob 2.580 (2.580)	GS 30.156 (30.156)	mem 39.903
Train: [60][330/750]	BT 0.032 (1.194)	DT 0.001 (1.149)	loss 6.891 (6.891)	prob 2.182 (2.182)	GS 36.594 (36.594)	mem 39.921
Train: [60][335/750]	BT 0.043 (1.176)	DT 0.002 (1.132)	loss 7.008 (7.008)	prob 2.384 (2.384)	GS 44.359 (44.359)	mem 39.923
Train: [60][340/750]	BT 15.350 (1.210)	DT 15.317 (1.165)	loss 7.025 (7.025)	prob 2.835 (2.835)	GS 36.516 (36.516)	mem 39.848
Train: [60][345/750]	BT 0.053 (1.193)	DT 0.012 (1.148)	loss 6.771 (6.771)	prob 2.828 (2.828)	GS 29.922 (29.922)	mem 39.860
Train: [60][350/750]	BT 0.047 (1.177)	DT 0.001 (1.132)	loss 6.840 (6.840)	prob 2.110 (2.110)	GS 33.031 (33.031)	mem 39.861
Train: [60][355/750]	BT 0.033 (1.190)	DT 0.001 (1.145)	loss 7.024 (7.024)	prob 2.961 (2.961)	GS 30.859 (30.859)	mem 39.917
Train: [60][360/750]	BT 0.081 (1.174)	DT 0.006 (1.129)	loss 6.748 (6.748)	prob 2.537 (2.537)	GS 31.484 (31.484)	mem 39.936
Train: [60][365/750]	BT 0.055 (1.186)	DT 0.001 (1.141)	loss 6.988 (6.988)	prob 2.373 (2.373)	GS 35.734 (35.734)	mem 39.897
Train: [60][370/750]	BT 0.077 (1.171)	DT 0.001 (1.126)	loss 6.847 (6.847)	prob 2.448 (2.448)	GS 34.266 (34.266)	mem 40.014
Train: [60][375/750]	BT 0.049 (1.156)	DT 0.007 (1.111)	loss 7.243 (7.243)	prob 2.340 (2.340)	GS 28.797 (28.797)	mem 39.905
Train: [60][380/750]	BT 0.025 (1.181)	DT 0.001 (1.136)	loss 7.085 (7.085)	prob 3.022 (3.022)	GS 33.656 (33.656)	mem 39.925
Train: [60][385/750]	BT 0.033 (1.167)	DT 0.002 (1.122)	loss 6.986 (6.986)	prob 2.776 (2.776)	GS 31.094 (31.094)	mem 39.905
Train: [60][390/750]	BT 0.027 (1.185)	DT 0.001 (1.140)	loss 6.831 (6.831)	prob 2.772 (2.772)	GS 35.703 (35.703)	mem 40.113
Train: [60][395/750]	BT 0.058 (1.170)	DT 0.002 (1.125)	loss 7.280 (7.280)	prob 2.660 (2.660)	GS 34.594 (34.594)	mem 39.900
Train: [60][400/750]	BT 14.045 (1.191)	DT 14.013 (1.146)	loss 7.027 (7.027)	prob 2.503 (2.503)	GS 33.188 (33.188)	mem 40.007
Train: [60][405/750]	BT 0.033 (1.177)	DT 0.001 (1.132)	loss 7.047 (7.047)	prob 2.526 (2.526)	GS 34.172 (34.172)	mem 40.008
Train: [60][410/750]	BT 0.031 (1.163)	DT 0.001 (1.119)	loss 7.007 (7.007)	prob 2.330 (2.330)	GS 32.469 (32.469)	mem 40.009
Train: [60][415/750]	BT 0.068 (1.182)	DT 0.022 (1.138)	loss 6.765 (6.765)	prob 3.249 (3.249)	GS 29.062 (29.062)	mem 39.819
Train: [60][420/750]	BT 0.102 (1.169)	DT 0.018 (1.124)	loss 7.307 (7.307)	prob 2.563 (2.563)	GS 35.359 (35.359)	mem 39.822
Train: [60][425/750]	BT 0.088 (1.183)	DT 0.012 (1.138)	loss 7.052 (7.052)	prob 2.815 (2.815)	GS 29.156 (29.156)	mem 39.833
Train: [60][430/750]	BT 0.031 (1.170)	DT 0.001 (1.125)	loss 6.861 (6.861)	prob 2.885 (2.885)	GS 32.625 (32.625)	mem 39.790
Train: [60][435/750]	BT 0.071 (1.158)	DT 0.009 (1.112)	loss 6.770 (6.770)	prob 3.041 (3.041)	GS 30.922 (30.922)	mem 39.818
Train: [60][440/750]	BT 0.073 (1.169)	DT 0.012 (1.124)	loss 6.982 (6.982)	prob 2.841 (2.841)	GS 34.062 (34.062)	mem 39.891
Train: [60][445/750]	BT 0.073 (1.157)	DT 0.005 (1.111)	loss 7.069 (7.069)	prob 2.492 (2.492)	GS 29.250 (29.250)	mem 39.895
Train: [60][450/750]	BT 0.028 (1.173)	DT 0.007 (1.127)	loss 6.733 (6.733)	prob 2.919 (2.919)	GS 37.594 (37.594)	mem 39.877
Train: [60][455/750]	BT 0.050 (1.160)	DT 0.008 (1.115)	loss 6.873 (6.873)	prob 2.866 (2.866)	GS 30.016 (30.016)	mem 39.878
Train: [60][460/750]	BT 11.413 (1.173)	DT 11.376 (1.127)	loss 7.269 (7.269)	prob 2.568 (2.568)	GS 30.172 (30.172)	mem 39.941
Train: [60][465/750]	BT 0.061 (1.165)	DT 0.002 (1.119)	loss 6.817 (6.817)	prob 3.047 (3.047)	GS 26.484 (26.484)	mem 39.891
Train: [60][470/750]	BT 0.036 (1.153)	DT 0.001 (1.108)	loss 7.065 (7.065)	prob 2.540 (2.540)	GS 33.391 (33.391)	mem 39.891
Train: [60][475/750]	BT 0.044 (1.167)	DT 0.002 (1.121)	loss 6.964 (6.964)	prob 2.706 (2.706)	GS 33.422 (33.422)	mem 40.037
Train: [60][480/750]	BT 0.047 (1.165)	DT 0.020 (1.119)	loss 6.831 (6.831)	prob 3.007 (3.007)	GS 34.297 (34.297)	mem 39.882
Train: [60][485/750]	BT 0.043 (1.169)	DT 0.001 (1.124)	loss 6.801 (6.801)	prob 2.745 (2.745)	GS 34.016 (34.016)	mem 39.911
Train: [60][490/750]	BT 7.251 (1.172)	DT 7.179 (1.127)	loss 6.974 (6.974)	prob 2.247 (2.247)	GS 38.125 (38.125)	mem 39.993
Train: [60][495/750]	BT 0.050 (1.161)	DT 0.005 (1.116)	loss 6.868 (6.868)	prob 2.828 (2.828)	GS 28.750 (28.750)	mem 39.870
Train: [60][500/750]	BT 3.059 (1.167)	DT 2.996 (1.121)	loss 7.152 (7.152)	prob 2.070 (2.070)	GS 38.188 (38.188)	mem 39.919
Train: [60][505/750]	BT 0.031 (1.165)	DT 0.002 (1.120)	loss 6.875 (6.875)	prob 2.838 (2.838)	GS 32.609 (32.609)	mem 39.889
Train: [60][510/750]	BT 0.034 (1.169)	DT 0.002 (1.124)	loss 6.924 (6.924)	prob 2.828 (2.828)	GS 34.156 (34.156)	mem 39.919
Train: [60][515/750]	BT 0.033 (1.162)	DT 0.002 (1.117)	loss 6.773 (6.773)	prob 2.616 (2.616)	GS 31.469 (31.469)	mem 39.907
Train: [60][520/750]	BT 11.998 (1.174)	DT 11.965 (1.129)	loss 6.937 (6.937)	prob 2.311 (2.311)	GS 33.828 (33.828)	mem 39.930
Train: [60][525/750]	BT 0.025 (1.166)	DT 0.001 (1.121)	loss 6.943 (6.943)	prob 2.598 (2.598)	GS 32.281 (32.281)	mem 39.961
Train: [60][530/750]	BT 0.059 (1.158)	DT 0.003 (1.113)	loss 6.961 (6.961)	prob 2.305 (2.305)	GS 35.344 (35.344)	mem 39.878
Train: [60][535/750]	BT 0.050 (1.168)	DT 0.002 (1.123)	loss 7.151 (7.151)	prob 1.941 (1.941)	GS 32.797 (32.797)	mem 39.822
Train: [60][540/750]	BT 0.112 (1.161)	DT 0.008 (1.116)	loss 6.806 (6.806)	prob 2.480 (2.480)	GS 32.594 (32.594)	mem 39.866
Train: [60][545/750]	BT 0.024 (1.166)	DT 0.001 (1.122)	loss 7.141 (7.141)	prob 2.446 (2.446)	GS 37.219 (37.219)	mem 39.932
Train: [60][550/750]	BT 5.259 (1.168)	DT 5.234 (1.123)	loss 7.006 (7.006)	prob 2.598 (2.598)	GS 38.250 (38.250)	mem 39.858
Train: [60][555/750]	BT 0.113 (1.158)	DT 0.001 (1.113)	loss 6.878 (6.878)	prob 3.169 (3.169)	GS 32.938 (32.938)	mem 40.023
Train: [60][560/750]	BT 3.627 (1.163)	DT 3.596 (1.118)	loss 6.938 (6.938)	prob 3.174 (3.174)	GS 34.031 (34.031)	mem 39.911
Train: [60][565/750]	BT 0.051 (1.154)	DT 0.002 (1.109)	loss 6.960 (6.960)	prob 2.888 (2.888)	GS 30.703 (30.703)	mem 39.952
Train: [60][570/750]	BT 2.755 (1.164)	DT 2.709 (1.119)	loss 6.857 (6.857)	prob 2.516 (2.516)	GS 37.812 (37.812)	mem 39.936
Train: [60][575/750]	BT 0.036 (1.155)	DT 0.005 (1.111)	loss 6.776 (6.776)	prob 3.527 (3.527)	GS 33.359 (33.359)	mem 39.964
Train: [60][580/750]	BT 9.837 (1.163)	DT 9.794 (1.118)	loss 6.894 (6.894)	prob 2.614 (2.614)	GS 36.531 (36.531)	mem 40.011
Train: [60][585/750]	BT 0.027 (1.155)	DT 0.001 (1.110)	loss 7.058 (7.058)	prob 2.315 (2.315)	GS 28.672 (28.672)	mem 39.857
Train: [60][590/750]	BT 0.024 (1.150)	DT 0.001 (1.105)	loss 7.087 (7.087)	prob 2.942 (2.942)	GS 33.469 (33.469)	mem 39.978
Train: [60][595/750]	BT 0.050 (1.157)	DT 0.018 (1.112)	loss 6.889 (6.889)	prob 3.220 (3.220)	GS 32.578 (32.578)	mem 39.937
Train: [60][600/750]	BT 0.051 (1.151)	DT 0.001 (1.106)	loss 6.953 (6.953)	prob 2.300 (2.300)	GS 31.266 (31.266)	mem 39.939
Train: [60][605/750]	BT 0.034 (1.159)	DT 0.001 (1.114)	loss 7.137 (7.137)	prob 1.909 (1.909)	GS 34.172 (34.172)	mem 39.961
Train: [60][610/750]	BT 0.043 (1.152)	DT 0.002 (1.107)	loss 6.908 (6.908)	prob 2.518 (2.518)	GS 36.297 (36.297)	mem 39.962
Train: [60][615/750]	BT 0.046 (1.143)	DT 0.001 (1.098)	loss 7.145 (7.145)	prob 2.686 (2.686)	GS 50.625 (50.625)	mem 39.963
Train: [60][620/750]	BT 1.654 (1.157)	DT 1.606 (1.112)	loss 7.028 (7.028)	prob 2.504 (2.504)	GS 33.484 (33.484)	mem 39.963
Train: [60][625/750]	BT 0.070 (1.148)	DT 0.003 (1.103)	loss 6.947 (6.947)	prob 2.331 (2.331)	GS 28.828 (28.828)	mem 39.969
Train: [60][630/750]	BT 0.030 (1.154)	DT 0.001 (1.109)	loss 7.186 (7.186)	prob 2.447 (2.447)	GS 33.250 (33.250)	mem 39.933
Train: [60][635/750]	BT 0.031 (1.153)	DT 0.002 (1.108)	loss 6.583 (6.583)	prob 3.104 (3.104)	GS 30.266 (30.266)	mem 39.954
Train: [60][640/750]	BT 6.139 (1.154)	DT 6.099 (1.109)	loss 6.910 (6.910)	prob 2.821 (2.821)	GS 31.812 (31.812)	mem 39.924
Train: [60][645/750]	BT 0.042 (1.158)	DT 0.002 (1.114)	loss 6.716 (6.716)	prob 2.773 (2.773)	GS 39.125 (39.125)	mem 39.893
Train: [60][650/750]	BT 0.048 (1.150)	DT 0.001 (1.105)	loss 6.670 (6.670)	prob 3.409 (3.409)	GS 33.734 (33.734)	mem 39.853
Train: [60][655/750]	BT 0.068 (1.151)	DT 0.026 (1.106)	loss 7.008 (7.008)	prob 2.518 (2.518)	GS 28.453 (28.453)	mem 40.116
Train: [60][660/750]	BT 0.047 (1.153)	DT 0.001 (1.108)	loss 6.827 (6.827)	prob 2.732 (2.732)	GS 35.750 (35.750)	mem 39.915
Train: [60][665/750]	BT 0.036 (1.156)	DT 0.001 (1.111)	loss 6.669 (6.669)	prob 2.849 (2.849)	GS 31.609 (31.609)	mem 39.896
Train: [60][670/750]	BT 0.034 (1.157)	DT 0.002 (1.112)	loss 7.048 (7.048)	prob 2.748 (2.748)	GS 32.672 (32.672)	mem 40.059
Train: [60][675/750]	BT 0.069 (1.148)	DT 0.005 (1.104)	loss 6.778 (6.778)	prob 3.254 (3.254)	GS 29.656 (29.656)	mem 39.910
Train: [60][680/750]	BT 2.642 (1.159)	DT 2.606 (1.114)	loss 6.879 (6.879)	prob 3.440 (3.440)	GS 29.328 (29.328)	mem 39.925
Train: [60][685/750]	BT 0.033 (1.151)	DT 0.001 (1.106)	loss 7.161 (7.161)	prob 3.015 (3.015)	GS 33.250 (33.250)	mem 39.976
Train: [60][690/750]	BT 0.033 (1.157)	DT 0.001 (1.112)	loss 6.998 (6.998)	prob 2.760 (2.760)	GS 29.047 (29.047)	mem 39.996
Train: [60][695/750]	BT 0.032 (1.153)	DT 0.007 (1.108)	loss 7.049 (7.049)	prob 2.563 (2.563)	GS 30.625 (30.625)	mem 39.961
Train: [60][700/750]	BT 12.145 (1.162)	DT 12.070 (1.117)	loss 6.890 (6.890)	prob 3.156 (3.156)	GS 37.219 (37.219)	mem 39.882
Train: [60][705/750]	BT 0.037 (1.156)	DT 0.001 (1.111)	loss 7.186 (7.186)	prob 2.131 (2.131)	GS 38.391 (38.391)	mem 39.805
Train: [60][710/750]	BT 0.053 (1.148)	DT 0.011 (1.103)	loss 7.134 (7.134)	prob 2.125 (2.125)	GS 36.453 (36.453)	mem 39.806
Train: [60][715/750]	BT 0.041 (1.159)	DT 0.005 (1.114)	loss 6.947 (6.947)	prob 2.802 (2.802)	GS 33.516 (33.516)	mem 40.222
Train: [60][720/750]	BT 0.040 (1.151)	DT 0.014 (1.106)	loss 6.849 (6.849)	prob 2.062 (2.062)	GS 33.984 (33.984)	mem 39.955
Train: [60][725/750]	BT 0.034 (1.160)	DT 0.001 (1.115)	loss 6.900 (6.900)	prob 2.894 (2.894)	GS 28.922 (28.922)	mem 39.950
Train: [60][730/750]	BT 0.028 (1.154)	DT 0.001 (1.110)	loss 6.626 (6.626)	prob 3.472 (3.472)	GS 31.328 (31.328)	mem 39.801
Train: [60][735/750]	BT 0.031 (1.147)	DT 0.001 (1.102)	loss 6.981 (6.981)	prob 2.801 (2.801)	GS 29.406 (29.406)	mem 39.801
Train: [60][740/750]	BT 0.020 (1.149)	DT 0.001 (1.105)	loss 6.764 (6.764)	prob 3.232 (3.232)	GS 35.422 (35.422)	mem 13.589
Train: [60][745/750]	BT 0.029 (1.142)	DT 0.001 (1.098)	loss 7.177 (7.177)	prob 2.691 (2.691)	GS 30.156 (30.156)	mem 13.589
Train: [60][750/750]	BT 0.023 (1.138)	DT 0.001 (1.093)	loss 7.021 (7.021)	prob 2.584 (2.584)	GS 32.531 (32.531)	mem 7.528
Train: [60][755/750]	BT 0.019 (1.131)	DT 0.001 (1.086)	loss 6.958 (6.958)	prob 1.582 (1.582)	GS 39.562 (39.562)	mem 7.527
epoch 60, total time 853.79
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [61][1/750]	BT 22.635 (22.635)	DT 22.577 (22.577)	loss 6.725 (6.725)	prob 2.741 (2.741)	GS 30.578 (30.578)	mem 38.826
Train: [61][5/750]	BT 0.050 (4.873)	DT 0.004 (4.804)	loss 6.811 (6.811)	prob 2.542 (2.542)	GS 33.516 (33.516)	mem 38.816
Train: [61][10/750]	BT 0.099 (2.496)	DT 0.008 (2.405)	loss 6.756 (6.756)	prob 3.089 (3.089)	GS 35.484 (35.484)	mem 38.763
Train: [61][15/750]	BT 0.041 (2.658)	DT 0.015 (2.584)	loss 6.499 (6.499)	prob 3.012 (3.012)	GS 29.328 (29.328)	mem 39.026
Train: [61][20/750]	BT 0.032 (2.002)	DT 0.001 (1.939)	loss 6.722 (6.722)	prob 2.849 (2.849)	GS 34.375 (34.375)	mem 39.079
Train: [61][25/750]	BT 1.147 (1.656)	DT 1.108 (1.596)	loss 6.771 (6.771)	prob 2.781 (2.781)	GS 29.797 (29.797)	mem 39.033
Train: [61][30/750]	BT 0.098 (1.759)	DT 0.008 (1.696)	loss 6.783 (6.783)	prob 2.906 (2.906)	GS 32.750 (32.750)	mem 38.901
Train: [61][35/750]	BT 0.040 (1.516)	DT 0.002 (1.454)	loss 6.783 (6.783)	prob 2.670 (2.670)	GS 27.625 (27.625)	mem 38.902
Train: [61][40/750]	BT 0.067 (1.642)	DT 0.002 (1.582)	loss 6.844 (6.844)	prob 2.492 (2.492)	GS 36.812 (36.812)	mem 39.501
Train: [61][45/750]	BT 0.031 (1.467)	DT 0.001 (1.408)	loss 7.031 (7.031)	prob 2.726 (2.726)	GS 27.609 (27.609)	mem 39.210
Train: [61][50/750]	BT 10.518 (1.535)	DT 10.490 (1.477)	loss 6.859 (6.859)	prob 2.470 (2.470)	GS 32.781 (32.781)	mem 39.614
Train: [61][55/750]	BT 0.079 (1.425)	DT 0.004 (1.368)	loss 6.817 (6.817)	prob 2.543 (2.543)	GS 30.078 (30.078)	mem 39.612
Train: [61][60/750]	BT 3.405 (1.370)	DT 3.331 (1.311)	loss 6.968 (6.968)	prob 2.506 (2.506)	GS 34.391 (34.391)	mem 39.693
Train: [61][65/750]	BT 0.075 (1.440)	DT 0.001 (1.382)	loss 6.934 (6.934)	prob 2.952 (2.952)	GS 30.875 (30.875)	mem 39.595
Train: [61][70/750]	BT 0.116 (1.341)	DT 0.016 (1.283)	loss 6.702 (6.702)	prob 3.143 (3.143)	GS 31.562 (31.562)	mem 39.797
Train: [61][75/750]	BT 0.039 (1.465)	DT 0.008 (1.408)	loss 6.934 (6.934)	prob 3.010 (3.010)	GS 35.078 (35.078)	mem 39.629
Train: [61][80/750]	BT 0.037 (1.376)	DT 0.001 (1.320)	loss 6.843 (6.843)	prob 2.703 (2.703)	GS 32.141 (32.141)	mem 39.631
Train: [61][85/750]	BT 0.027 (1.297)	DT 0.001 (1.242)	loss 6.892 (6.892)	prob 2.645 (2.645)	GS 29.219 (29.219)	mem 39.631
Train: [61][90/750]	BT 0.051 (1.369)	DT 0.001 (1.315)	loss 6.907 (6.907)	prob 2.407 (2.407)	GS 35.406 (35.406)	mem 39.652
Train: [61][95/750]	BT 0.085 (1.300)	DT 0.011 (1.246)	loss 6.818 (6.818)	prob 2.402 (2.402)	GS 32.484 (32.484)	mem 39.710
Train: [61][100/750]	BT 0.039 (1.334)	DT 0.002 (1.281)	loss 6.755 (6.755)	prob 3.094 (3.094)	GS 33.953 (33.953)	mem 39.839
Train: [61][105/750]	BT 0.070 (1.275)	DT 0.007 (1.221)	loss 7.123 (7.123)	prob 2.211 (2.211)	GS 35.969 (35.969)	mem 39.699
Train: [61][110/750]	BT 10.327 (1.312)	DT 10.271 (1.259)	loss 6.743 (6.743)	prob 2.892 (2.892)	GS 34.594 (34.594)	mem 39.727
Train: [61][115/750]	BT 0.047 (1.258)	DT 0.001 (1.204)	loss 7.156 (7.156)	prob 2.179 (2.179)	GS 36.047 (36.047)	mem 39.759
Train: [61][120/750]	BT 0.062 (1.235)	DT 0.006 (1.182)	loss 7.004 (7.004)	prob 2.790 (2.790)	GS 33.312 (33.312)	mem 39.735
Train: [61][125/750]	BT 0.024 (1.304)	DT 0.001 (1.252)	loss 6.905 (6.905)	prob 2.687 (2.687)	GS 30.703 (30.703)	mem 39.659
Train: [61][130/750]	BT 0.032 (1.256)	DT 0.001 (1.204)	loss 6.968 (6.968)	prob 2.398 (2.398)	GS 33.375 (33.375)	mem 39.664
Train: [61][135/750]	BT 0.025 (1.306)	DT 0.001 (1.253)	loss 6.633 (6.633)	prob 2.617 (2.617)	GS 28.672 (28.672)	mem 39.727
Train: [61][140/750]	BT 0.068 (1.261)	DT 0.012 (1.209)	loss 6.937 (6.937)	prob 2.721 (2.721)	GS 31.078 (31.078)	mem 39.728
Train: [61][145/750]	BT 0.095 (1.220)	DT 0.003 (1.167)	loss 7.049 (7.049)	prob 2.074 (2.074)	GS 28.578 (28.578)	mem 39.730
Train: [61][150/750]	BT 0.038 (1.242)	DT 0.005 (1.190)	loss 6.843 (6.843)	prob 2.038 (2.038)	GS 29.812 (29.812)	mem 39.884
Train: [61][155/750]	BT 0.097 (1.204)	DT 0.005 (1.152)	loss 6.875 (6.875)	prob 2.613 (2.613)	GS 38.438 (38.438)	mem 39.700
Train: [61][160/750]	BT 0.047 (1.256)	DT 0.017 (1.205)	loss 6.841 (6.841)	prob 1.678 (1.678)	GS 28.719 (28.719)	mem 39.613
Train: [61][165/750]	BT 0.027 (1.220)	DT 0.001 (1.168)	loss 6.716 (6.716)	prob 3.236 (3.236)	GS 29.109 (29.109)	mem 39.659
Train: [61][170/750]	BT 14.274 (1.269)	DT 14.244 (1.218)	loss 6.769 (6.769)	prob 2.909 (2.909)	GS 36.859 (36.859)	mem 39.601
Train: [61][175/750]	BT 0.053 (1.234)	DT 0.002 (1.183)	loss 6.796 (6.796)	prob 2.521 (2.521)	GS 31.859 (31.859)	mem 39.654
Train: [61][180/750]	BT 0.090 (1.201)	DT 0.003 (1.150)	loss 6.879 (6.879)	prob 2.129 (2.129)	GS 33.500 (33.500)	mem 39.604
Train: [61][185/750]	BT 0.026 (1.239)	DT 0.001 (1.188)	loss 6.815 (6.815)	prob 2.386 (2.386)	GS 30.531 (30.531)	mem 39.698
Train: [61][190/750]	BT 0.039 (1.207)	DT 0.001 (1.157)	loss 7.034 (7.034)	prob 1.959 (1.959)	GS 27.984 (27.984)	mem 39.707
Train: [61][195/750]	BT 0.034 (1.243)	DT 0.001 (1.193)	loss 6.977 (6.977)	prob 2.681 (2.681)	GS 32.359 (32.359)	mem 39.837
Train: [61][200/750]	BT 0.055 (1.212)	DT 0.022 (1.163)	loss 6.913 (6.913)	prob 2.334 (2.334)	GS 31.406 (31.406)	mem 39.838
Train: [61][205/750]	BT 0.112 (1.185)	DT 0.026 (1.135)	loss 6.671 (6.671)	prob 2.596 (2.596)	GS 31.875 (31.875)	mem 39.839
Train: [61][210/750]	BT 0.050 (1.225)	DT 0.007 (1.176)	loss 6.763 (6.763)	prob 2.659 (2.659)	GS 30.719 (30.719)	mem 39.820
Train: [61][215/750]	BT 0.048 (1.197)	DT 0.002 (1.148)	loss 6.572 (6.572)	prob 2.467 (2.467)	GS 34.219 (34.219)	mem 39.821
Train: [61][220/750]	BT 0.020 (1.221)	DT 0.001 (1.173)	loss 6.756 (6.756)	prob 2.250 (2.250)	GS 32.828 (32.828)	mem 39.794
Train: [61][225/750]	BT 0.028 (1.195)	DT 0.001 (1.147)	loss 6.735 (6.735)	prob 1.983 (1.983)	GS 32.328 (32.328)	mem 39.793
Train: [61][230/750]	BT 11.511 (1.220)	DT 11.464 (1.172)	loss 6.699 (6.699)	prob 3.583 (3.583)	GS 37.328 (37.328)	mem 39.997
Train: [61][235/750]	BT 0.039 (1.195)	DT 0.009 (1.147)	loss 6.682 (6.682)	prob 3.108 (3.108)	GS 30.656 (30.656)	mem 39.904
Train: [61][240/750]	BT 0.060 (1.171)	DT 0.010 (1.123)	loss 7.046 (7.046)	prob 2.271 (2.271)	GS 29.281 (29.281)	mem 40.027
Train: [61][245/750]	BT 0.035 (1.197)	DT 0.004 (1.150)	loss 6.946 (6.946)	prob 2.406 (2.406)	GS 29.688 (29.688)	mem 39.904
Train: [61][250/750]	BT 0.079 (1.174)	DT 0.003 (1.127)	loss 7.004 (7.004)	prob 2.308 (2.308)	GS 34.391 (34.391)	mem 39.885
Train: [61][255/750]	BT 0.082 (1.202)	DT 0.009 (1.155)	loss 6.798 (6.798)	prob 2.622 (2.622)	GS 32.422 (32.422)	mem 40.024
Train: [61][260/750]	BT 0.038 (1.180)	DT 0.001 (1.133)	loss 6.686 (6.686)	prob 2.435 (2.435)	GS 38.625 (38.625)	mem 39.931
Train: [61][265/750]	BT 0.041 (1.159)	DT 0.001 (1.112)	loss 7.148 (7.148)	prob 2.476 (2.476)	GS 33.125 (33.125)	mem 39.925
Train: [61][270/750]	BT 0.078 (1.179)	DT 0.002 (1.132)	loss 6.818 (6.818)	prob 2.828 (2.828)	GS 33.844 (33.844)	mem 40.007
Train: [61][275/750]	BT 0.051 (1.161)	DT 0.002 (1.114)	loss 6.839 (6.839)	prob 2.574 (2.574)	GS 30.297 (30.297)	mem 39.858
Train: [61][280/750]	BT 0.037 (1.177)	DT 0.001 (1.130)	loss 6.721 (6.721)	prob 2.316 (2.316)	GS 33.172 (33.172)	mem 39.861
Train: [61][285/750]	BT 0.063 (1.157)	DT 0.001 (1.110)	loss 6.957 (6.957)	prob 2.972 (2.972)	GS 29.203 (29.203)	mem 39.862
Train: [61][290/750]	BT 10.490 (1.179)	DT 10.459 (1.132)	loss 6.886 (6.886)	prob 3.291 (3.291)	GS 33.531 (33.531)	mem 39.888
Train: [61][295/750]	BT 0.093 (1.170)	DT 0.008 (1.123)	loss 6.615 (6.615)	prob 3.315 (3.315)	GS 33.625 (33.625)	mem 39.886
Train: [61][300/750]	BT 0.429 (1.152)	DT 0.402 (1.106)	loss 6.865 (6.865)	prob 2.330 (2.330)	GS 34.234 (34.234)	mem 39.821
Train: [61][305/750]	BT 0.024 (1.177)	DT 0.001 (1.131)	loss 6.895 (6.895)	prob 3.164 (3.164)	GS 30.344 (30.344)	mem 39.856
Train: [61][310/750]	BT 0.033 (1.159)	DT 0.001 (1.112)	loss 7.037 (7.037)	prob 2.572 (2.572)	GS 34.469 (34.469)	mem 39.892
Train: [61][315/750]	BT 0.075 (1.160)	DT 0.001 (1.114)	loss 6.751 (6.751)	prob 2.799 (2.799)	GS 33.703 (33.703)	mem 39.822
Train: [61][320/750]	BT 0.029 (1.159)	DT 0.001 (1.113)	loss 7.192 (7.192)	prob 2.710 (2.710)	GS 31.406 (31.406)	mem 39.871
Train: [61][325/750]	BT 0.055 (1.142)	DT 0.010 (1.096)	loss 6.676 (6.676)	prob 2.951 (2.951)	GS 31.109 (31.109)	mem 39.920
Train: [61][330/750]	BT 0.036 (1.169)	DT 0.001 (1.123)	loss 7.229 (7.229)	prob 1.431 (1.431)	GS 30.969 (30.969)	mem 39.921
Train: [61][335/750]	BT 0.057 (1.155)	DT 0.028 (1.109)	loss 6.824 (6.824)	prob 2.474 (2.474)	GS 30.562 (30.562)	mem 40.071
Train: [61][340/750]	BT 8.104 (1.173)	DT 8.072 (1.127)	loss 7.033 (7.033)	prob 2.731 (2.731)	GS 31.406 (31.406)	mem 39.917
Train: [61][345/750]	BT 0.025 (1.157)	DT 0.001 (1.111)	loss 7.011 (7.011)	prob 2.323 (2.323)	GS 30.062 (30.062)	mem 39.877
Train: [61][350/750]	BT 0.031 (1.151)	DT 0.001 (1.105)	loss 6.820 (6.820)	prob 3.059 (3.059)	GS 35.219 (35.219)	mem 39.865
Train: [61][355/750]	BT 0.031 (1.172)	DT 0.001 (1.126)	loss 6.861 (6.861)	prob 2.806 (2.806)	GS 32.250 (32.250)	mem 39.892
Train: [61][360/750]	BT 0.080 (1.157)	DT 0.014 (1.111)	loss 6.837 (6.837)	prob 2.818 (2.818)	GS 35.156 (35.156)	mem 39.893
Train: [61][365/750]	BT 0.054 (1.179)	DT 0.001 (1.133)	loss 6.897 (6.897)	prob 2.910 (2.910)	GS 28.078 (28.078)	mem 39.922
Train: [61][370/750]	BT 0.118 (1.164)	DT 0.001 (1.118)	loss 6.839 (6.839)	prob 2.767 (2.767)	GS 35.016 (35.016)	mem 39.961
Train: [61][375/750]	BT 0.055 (1.161)	DT 0.012 (1.115)	loss 6.967 (6.967)	prob 2.846 (2.846)	GS 30.594 (30.594)	mem 39.943
Train: [61][380/750]	BT 0.030 (1.166)	DT 0.001 (1.120)	loss 7.174 (7.174)	prob 2.747 (2.747)	GS 26.266 (26.266)	mem 39.933
Train: [61][385/750]	BT 0.049 (1.151)	DT 0.002 (1.105)	loss 6.852 (6.852)	prob 3.346 (3.346)	GS 35.359 (35.359)	mem 39.933
Train: [61][390/750]	BT 0.035 (1.166)	DT 0.003 (1.120)	loss 6.936 (6.936)	prob 2.827 (2.827)	GS 34.625 (34.625)	mem 39.995
Train: [61][395/750]	BT 0.046 (1.152)	DT 0.003 (1.106)	loss 6.732 (6.732)	prob 3.047 (3.047)	GS 30.609 (30.609)	mem 39.945
Train: [61][400/750]	BT 5.537 (1.164)	DT 5.431 (1.118)	loss 7.058 (7.058)	prob 2.449 (2.449)	GS 33.453 (33.453)	mem 40.088
Train: [61][405/750]	BT 0.035 (1.151)	DT 0.001 (1.105)	loss 6.820 (6.820)	prob 2.948 (2.948)	GS 34.234 (34.234)	mem 39.945
Train: [61][410/750]	BT 6.304 (1.153)	DT 6.252 (1.107)	loss 6.867 (6.867)	prob 3.254 (3.254)	GS 32.266 (32.266)	mem 39.977
Train: [61][415/750]	BT 0.039 (1.149)	DT 0.001 (1.103)	loss 6.875 (6.875)	prob 2.618 (2.618)	GS 28.422 (28.422)	mem 39.944
Train: [61][420/750]	BT 0.039 (1.139)	DT 0.002 (1.094)	loss 6.803 (6.803)	prob 2.510 (2.510)	GS 32.438 (32.438)	mem 39.945
Train: [61][425/750]	BT 0.025 (1.157)	DT 0.001 (1.111)	loss 6.933 (6.933)	prob 2.539 (2.539)	GS 35.156 (35.156)	mem 39.934
Train: [61][430/750]	BT 1.599 (1.148)	DT 1.552 (1.102)	loss 7.018 (7.018)	prob 2.799 (2.799)	GS 37.578 (37.578)	mem 39.880
Train: [61][435/750]	BT 0.027 (1.138)	DT 0.002 (1.093)	loss 6.941 (6.941)	prob 2.718 (2.718)	GS 31.859 (31.859)	mem 40.065
Train: [61][440/750]	BT 0.032 (1.152)	DT 0.001 (1.106)	loss 6.929 (6.929)	prob 2.948 (2.948)	GS 36.078 (36.078)	mem 39.955
Train: [61][445/750]	BT 0.058 (1.139)	DT 0.010 (1.094)	loss 6.663 (6.663)	prob 2.575 (2.575)	GS 32.891 (32.891)	mem 39.958
Train: [61][450/750]	BT 0.066 (1.165)	DT 0.010 (1.120)	loss 7.022 (7.022)	prob 3.056 (3.056)	GS 37.719 (37.719)	mem 39.941
Train: [61][455/750]	BT 0.034 (1.153)	DT 0.002 (1.107)	loss 6.632 (6.632)	prob 3.647 (3.647)	GS 29.547 (29.547)	mem 39.958
Train: [61][460/750]	BT 12.261 (1.167)	DT 12.204 (1.122)	loss 7.013 (7.013)	prob 3.451 (3.451)	GS 30.266 (30.266)	mem 40.070
Train: [61][465/750]	BT 0.034 (1.155)	DT 0.001 (1.110)	loss 6.813 (6.813)	prob 3.167 (3.167)	GS 33.422 (33.422)	mem 39.951
Train: [61][470/750]	BT 0.147 (1.143)	DT 0.012 (1.098)	loss 7.229 (7.229)	prob 2.476 (2.476)	GS 31.047 (31.047)	mem 40.013
Train: [61][475/750]	BT 0.030 (1.159)	DT 0.001 (1.113)	loss 6.762 (6.762)	prob 3.266 (3.266)	GS 27.141 (27.141)	mem 39.799
Train: [61][480/750]	BT 0.088 (1.147)	DT 0.001 (1.102)	loss 7.124 (7.124)	prob 3.145 (3.145)	GS 31.859 (31.859)	mem 39.901
Train: [61][485/750]	BT 0.077 (1.157)	DT 0.001 (1.112)	loss 6.746 (6.746)	prob 2.849 (2.849)	GS 33.938 (33.938)	mem 40.004
Train: [61][490/750]	BT 0.025 (1.146)	DT 0.001 (1.101)	loss 6.869 (6.869)	prob 2.561 (2.561)	GS 36.812 (36.812)	mem 39.935
Train: [61][495/750]	BT 0.150 (1.135)	DT 0.022 (1.090)	loss 7.084 (7.084)	prob 2.172 (2.172)	GS 31.812 (31.812)	mem 39.942
Train: [61][500/750]	BT 0.057 (1.150)	DT 0.016 (1.105)	loss 6.963 (6.963)	prob 2.840 (2.840)	GS 36.109 (36.109)	mem 39.747
Train: [61][505/750]	BT 0.032 (1.139)	DT 0.002 (1.094)	loss 6.996 (6.996)	prob 2.821 (2.821)	GS 27.938 (27.938)	mem 39.704
Train: [61][510/750]	BT 0.033 (1.151)	DT 0.001 (1.106)	loss 7.175 (7.175)	prob 3.511 (3.511)	GS 31.484 (31.484)	mem 39.883
Train: [61][515/750]	BT 0.025 (1.140)	DT 0.001 (1.095)	loss 6.683 (6.683)	prob 3.023 (3.023)	GS 31.625 (31.625)	mem 39.884
Train: [61][520/750]	BT 13.608 (1.156)	DT 13.575 (1.111)	loss 7.500 (7.500)	prob 2.165 (2.165)	GS 32.000 (32.000)	mem 39.904
Train: [61][525/750]	BT 0.091 (1.145)	DT 0.005 (1.100)	loss 6.913 (6.913)	prob 3.345 (3.345)	GS 33.344 (33.344)	mem 39.843
Train: [61][530/750]	BT 0.053 (1.135)	DT 0.002 (1.090)	loss 7.078 (7.078)	prob 2.617 (2.617)	GS 35.797 (35.797)	mem 39.843
Train: [61][535/750]	BT 0.071 (1.149)	DT 0.029 (1.104)	loss 7.064 (7.064)	prob 2.155 (2.155)	GS 27.422 (27.422)	mem 39.984
Train: [61][540/750]	BT 0.022 (1.139)	DT 0.001 (1.094)	loss 6.865 (6.865)	prob 2.764 (2.764)	GS 34.500 (34.500)	mem 39.926
Train: [61][545/750]	BT 0.028 (1.153)	DT 0.006 (1.108)	loss 7.389 (7.389)	prob 2.238 (2.238)	GS 32.047 (32.047)	mem 39.841
Train: [61][550/750]	BT 0.026 (1.143)	DT 0.001 (1.098)	loss 7.504 (7.504)	prob 1.720 (1.720)	GS 34.938 (34.938)	mem 39.846
Train: [61][555/750]	BT 0.053 (1.138)	DT 0.017 (1.093)	loss 7.104 (7.104)	prob 2.702 (2.702)	GS 36.156 (36.156)	mem 39.784
Train: [61][560/750]	BT 0.030 (1.144)	DT 0.002 (1.099)	loss 7.035 (7.035)	prob 2.627 (2.627)	GS 39.375 (39.375)	mem 40.007
Train: [61][565/750]	BT 0.033 (1.137)	DT 0.002 (1.092)	loss 7.093 (7.093)	prob 2.813 (2.813)	GS 30.703 (30.703)	mem 39.865
Train: [61][570/750]	BT 0.028 (1.147)	DT 0.001 (1.102)	loss 7.209 (7.209)	prob 2.497 (2.497)	GS 33.406 (33.406)	mem 39.869
Train: [61][575/750]	BT 0.082 (1.138)	DT 0.001 (1.093)	loss 7.045 (7.045)	prob 2.596 (2.596)	GS 32.688 (32.688)	mem 39.873
Train: [61][580/750]	BT 8.067 (1.149)	DT 7.983 (1.104)	loss 6.983 (6.983)	prob 3.460 (3.460)	GS 34.188 (34.188)	mem 39.923
Train: [61][585/750]	BT 0.032 (1.140)	DT 0.001 (1.095)	loss 6.742 (6.742)	prob 2.461 (2.461)	GS 34.641 (34.641)	mem 39.878
Train: [61][590/750]	BT 0.049 (1.141)	DT 0.010 (1.096)	loss 7.197 (7.197)	prob 2.888 (2.888)	GS 35.750 (35.750)	mem 39.940
Train: [61][595/750]	BT 0.045 (1.145)	DT 0.001 (1.100)	loss 7.002 (7.002)	prob 2.277 (2.277)	GS 29.594 (29.594)	mem 39.922
Train: [61][600/750]	BT 1.321 (1.138)	DT 1.273 (1.093)	loss 6.950 (6.950)	prob 2.818 (2.818)	GS 28.281 (28.281)	mem 39.977
Train: [61][605/750]	BT 0.039 (1.146)	DT 0.002 (1.101)	loss 6.999 (6.999)	prob 2.522 (2.522)	GS 30.406 (30.406)	mem 40.234
Train: [61][610/750]	BT 0.031 (1.137)	DT 0.001 (1.093)	loss 6.951 (6.951)	prob 2.560 (2.560)	GS 34.875 (34.875)	mem 39.995
Train: [61][615/750]	BT 0.077 (1.139)	DT 0.016 (1.094)	loss 6.864 (6.864)	prob 2.103 (2.103)	GS 29.891 (29.891)	mem 40.006
Train: [61][620/750]	BT 0.029 (1.144)	DT 0.002 (1.099)	loss 7.232 (7.232)	prob 2.018 (2.018)	GS 35.766 (35.766)	mem 39.965
Train: [61][625/750]	BT 0.032 (1.140)	DT 0.002 (1.096)	loss 7.361 (7.361)	prob 1.424 (1.424)	GS 28.266 (28.266)	mem 39.940
Train: [61][630/750]	BT 4.024 (1.145)	DT 3.915 (1.101)	loss 7.487 (7.487)	prob 1.909 (1.909)	GS 32.500 (32.500)	mem 39.976
Train: [61][635/750]	BT 0.033 (1.137)	DT 0.001 (1.092)	loss 7.008 (7.008)	prob 1.962 (1.962)	GS 34.016 (34.016)	mem 39.913
Train: [61][640/750]	BT 0.142 (1.140)	DT 0.107 (1.095)	loss 7.315 (7.315)	prob 1.507 (1.507)	GS 31.891 (31.891)	mem 39.972
Train: [61][645/750]	BT 0.069 (1.135)	DT 0.002 (1.091)	loss 7.359 (7.359)	prob 1.383 (1.383)	GS 31.531 (31.531)	mem 39.972
Train: [61][650/750]	BT 0.037 (1.142)	DT 0.001 (1.098)	loss 7.279 (7.279)	prob 2.287 (2.287)	GS 36.797 (36.797)	mem 39.996
Train: [61][655/750]	BT 0.023 (1.142)	DT 0.001 (1.098)	loss 7.254 (7.254)	prob 1.776 (1.776)	GS 30.125 (30.125)	mem 39.958
arpack error, retry= 0
Train: [61][660/750]	BT 7.414 (1.145)	DT 7.381 (1.100)	loss 7.155 (7.155)	prob 1.530 (1.530)	GS 33.172 (33.172)	mem 39.847
Train: [61][665/750]	BT 0.123 (1.137)	DT 0.026 (1.092)	loss 7.245 (7.245)	prob 2.296 (2.296)	GS 35.438 (35.438)	mem 39.931
Train: [61][670/750]	BT 0.033 (1.139)	DT 0.002 (1.095)	loss 7.125 (7.125)	prob 2.039 (2.039)	GS 34.516 (34.516)	mem 39.952
Train: [61][675/750]	BT 0.044 (1.139)	DT 0.002 (1.095)	loss 7.194 (7.194)	prob 1.762 (1.762)	GS 31.531 (31.531)	mem 40.028
Train: [61][680/750]	BT 0.076 (1.141)	DT 0.001 (1.097)	loss 7.561 (7.561)	prob 1.665 (1.665)	GS 34.172 (34.172)	mem 40.035
Train: [61][685/750]	BT 0.027 (1.141)	DT 0.001 (1.096)	loss 7.057 (7.057)	prob 1.806 (1.806)	GS 32.234 (32.234)	mem 40.043
Train: [61][690/750]	BT 7.426 (1.143)	DT 7.394 (1.099)	loss 7.888 (7.888)	prob 2.018 (2.018)	GS 35.391 (35.391)	mem 40.052
Train: [61][695/750]	BT 0.033 (1.135)	DT 0.002 (1.091)	loss 7.187 (7.187)	prob 1.682 (1.682)	GS 32.188 (32.188)	mem 40.054
Train: [61][700/750]	BT 0.120 (1.131)	DT 0.008 (1.086)	loss 7.274 (7.274)	prob 2.135 (2.135)	GS 35.594 (35.594)	mem 40.175
Train: [61][705/750]	BT 0.023 (1.137)	DT 0.001 (1.093)	loss 7.070 (7.070)	prob 2.136 (2.136)	GS 31.672 (31.672)	mem 40.069
Train: [61][710/750]	BT 0.037 (1.134)	DT 0.002 (1.090)	loss 7.334 (7.334)	prob 2.395 (2.395)	GS 38.203 (38.203)	mem 40.192
Train: [61][715/750]	BT 0.029 (1.140)	DT 0.001 (1.096)	loss 7.361 (7.361)	prob 1.869 (1.869)	GS 32.359 (32.359)	mem 40.045
Train: [61][720/750]	BT 2.316 (1.136)	DT 2.271 (1.092)	loss 7.241 (7.241)	prob 1.974 (1.974)	GS 31.938 (31.938)	mem 40.049
Train: [61][725/750]	BT 0.033 (1.128)	DT 0.002 (1.084)	loss 6.994 (6.994)	prob 1.792 (1.792)	GS 29.500 (29.500)	mem 40.107
Train: [61][730/750]	BT 0.121 (1.130)	DT 0.002 (1.086)	loss 6.842 (6.842)	prob 2.418 (2.418)	GS 35.516 (35.516)	mem 39.885
Train: [61][735/750]	BT 0.032 (1.128)	DT 0.001 (1.084)	loss 7.035 (7.035)	prob 1.773 (1.773)	GS 31.141 (31.141)	mem 39.661
Train: [61][740/750]	BT 0.026 (1.125)	DT 0.001 (1.081)	loss 7.261 (7.261)	prob 2.541 (2.541)	GS 33.953 (33.953)	mem 13.566
Train: [61][745/750]	BT 0.030 (1.122)	DT 0.008 (1.078)	loss 7.101 (7.101)	prob 2.417 (2.417)	GS 34.062 (34.062)	mem 11.227
Train: [61][750/750]	BT 2.082 (1.117)	DT 2.053 (1.073)	loss 7.227 (7.227)	prob 1.379 (1.379)	GS 34.719 (34.719)	mem 10.548
Train: [61][755/750]	BT 0.027 (1.110)	DT 0.001 (1.066)	loss 7.286 (7.286)	prob 2.748 (2.748)	GS 29.500 (29.500)	mem 10.548
epoch 61, total time 839.30
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [62][1/750]	BT 19.436 (19.436)	DT 19.388 (19.388)	loss 7.463 (7.463)	prob 1.888 (1.888)	GS 28.859 (28.859)	mem 39.023
Train: [62][5/750]	BT 0.076 (4.746)	DT 0.009 (4.693)	loss 7.054 (7.054)	prob 2.258 (2.258)	GS 31.750 (31.750)	mem 39.340
Train: [62][10/750]	BT 0.110 (2.422)	DT 0.024 (2.355)	loss 7.069 (7.069)	prob 2.329 (2.329)	GS 33.031 (33.031)	mem 39.503
Train: [62][15/750]	BT 2.412 (2.449)	DT 2.377 (2.391)	loss 6.860 (6.860)	prob 3.119 (3.119)	GS 35.156 (35.156)	mem 39.323
Train: [62][20/750]	BT 0.032 (2.139)	DT 0.001 (2.087)	loss 7.224 (7.224)	prob 2.497 (2.497)	GS 31.125 (31.125)	mem 39.379
Train: [62][25/750]	BT 0.068 (1.728)	DT 0.012 (1.672)	loss 7.202 (7.202)	prob 2.058 (2.058)	GS 32.531 (32.531)	mem 39.355
Train: [62][30/750]	BT 3.225 (1.799)	DT 3.194 (1.745)	loss 7.190 (7.190)	prob 3.681 (3.681)	GS 30.125 (30.125)	mem 39.465
Train: [62][35/750]	BT 0.046 (1.547)	DT 0.001 (1.496)	loss 7.103 (7.103)	prob 2.811 (2.811)	GS 27.078 (27.078)	mem 39.467
Train: [62][40/750]	BT 4.242 (1.581)	DT 4.162 (1.532)	loss 6.924 (6.924)	prob 2.788 (2.788)	GS 32.438 (32.438)	mem 39.759
Train: [62][45/750]	BT 0.031 (1.536)	DT 0.001 (1.488)	loss 7.174 (7.174)	prob 2.205 (2.205)	GS 33.422 (33.422)	mem 39.444
Train: [62][50/750]	BT 1.286 (1.412)	DT 1.243 (1.365)	loss 7.126 (7.126)	prob 2.407 (2.407)	GS 33.453 (33.453)	mem 39.807
Train: [62][55/750]	BT 0.084 (1.501)	DT 0.033 (1.454)	loss 6.980 (6.980)	prob 2.826 (2.826)	GS 29.578 (29.578)	mem 39.536
Train: [62][60/750]	BT 0.032 (1.380)	DT 0.001 (1.334)	loss 7.008 (7.008)	prob 2.914 (2.914)	GS 33.438 (33.438)	mem 39.491
Train: [62][65/750]	BT 0.033 (1.369)	DT 0.002 (1.324)	loss 7.191 (7.191)	prob 2.543 (2.543)	GS 29.672 (29.672)	mem 39.509
Train: [62][70/750]	BT 0.037 (1.376)	DT 0.004 (1.330)	loss 7.204 (7.204)	prob 2.260 (2.260)	GS 36.656 (36.656)	mem 39.488
Train: [62][75/750]	BT 0.045 (1.287)	DT 0.003 (1.242)	loss 7.234 (7.234)	prob 2.017 (2.017)	GS 30.641 (30.641)	mem 39.489
Train: [62][80/750]	BT 0.042 (1.369)	DT 0.011 (1.324)	loss 7.257 (7.257)	prob 2.413 (2.413)	GS 35.172 (35.172)	mem 39.578
Train: [62][85/750]	BT 0.045 (1.291)	DT 0.001 (1.246)	loss 7.118 (7.118)	prob 2.754 (2.754)	GS 28.594 (28.594)	mem 39.579
Train: [62][90/750]	BT 3.013 (1.324)	DT 2.980 (1.280)	loss 7.530 (7.530)	prob 2.509 (2.509)	GS 29.922 (29.922)	mem 39.745
Train: [62][95/750]	BT 0.044 (1.279)	DT 0.004 (1.235)	loss 7.384 (7.384)	prob 2.237 (2.237)	GS 33.312 (33.312)	mem 39.670
Train: [62][100/750]	BT 6.919 (1.292)	DT 6.883 (1.248)	loss 7.119 (7.119)	prob 2.286 (2.286)	GS 32.547 (32.547)	mem 39.514
Train: [62][105/750]	BT 0.084 (1.269)	DT 0.001 (1.226)	loss 7.344 (7.344)	prob 1.943 (1.943)	GS 34.016 (34.016)	mem 39.590
Train: [62][110/750]	BT 5.228 (1.261)	DT 5.191 (1.217)	loss 7.667 (7.667)	prob 2.818 (2.818)	GS 37.031 (37.031)	mem 39.677
Train: [62][115/750]	BT 0.068 (1.266)	DT 0.013 (1.222)	loss 7.305 (7.305)	prob 2.782 (2.782)	GS 33.156 (33.156)	mem 39.672
Train: [62][120/750]	BT 0.040 (1.215)	DT 0.001 (1.171)	loss 7.281 (7.281)	prob 2.615 (2.615)	GS 31.281 (31.281)	mem 39.636
Train: [62][125/750]	BT 0.074 (1.251)	DT 0.002 (1.207)	loss 7.337 (7.337)	prob 2.190 (2.190)	GS 36.047 (36.047)	mem 39.752
Train: [62][130/750]	BT 0.629 (1.225)	DT 0.596 (1.182)	loss 7.182 (7.182)	prob 2.467 (2.467)	GS 37.875 (37.875)	mem 39.651
Train: [62][135/750]	BT 0.121 (1.199)	DT 0.017 (1.154)	loss 7.035 (7.035)	prob 3.286 (3.286)	GS 30.844 (30.844)	mem 39.801
Train: [62][140/750]	BT 0.031 (1.229)	DT 0.001 (1.185)	loss 7.337 (7.337)	prob 2.625 (2.625)	GS 34.625 (34.625)	mem 39.732
Train: [62][145/750]	BT 0.026 (1.196)	DT 0.001 (1.152)	loss 7.244 (7.244)	prob 2.084 (2.084)	GS 32.828 (32.828)	mem 39.736
Train: [62][150/750]	BT 4.876 (1.231)	DT 4.763 (1.186)	loss 7.345 (7.345)	prob 3.053 (3.053)	GS 34.328 (34.328)	mem 39.765
Train: [62][155/750]	BT 0.024 (1.193)	DT 0.001 (1.149)	loss 7.416 (7.416)	prob 2.681 (2.681)	GS 31.250 (31.250)	mem 39.692
Train: [62][160/750]	BT 11.739 (1.231)	DT 11.708 (1.186)	loss 7.158 (7.158)	prob 2.882 (2.882)	GS 37.438 (37.438)	mem 39.694
Train: [62][165/750]	BT 0.079 (1.210)	DT 0.003 (1.165)	loss 7.208 (7.208)	prob 2.557 (2.557)	GS 26.656 (26.656)	mem 39.750
Train: [62][170/750]	BT 0.063 (1.176)	DT 0.013 (1.131)	loss 7.565 (7.565)	prob 2.719 (2.719)	GS 32.078 (32.078)	mem 39.750
Train: [62][175/750]	BT 0.048 (1.220)	DT 0.010 (1.174)	loss 7.244 (7.244)	prob 2.691 (2.691)	GS 33.375 (33.375)	mem 39.792
Train: [62][180/750]	BT 0.024 (1.187)	DT 0.001 (1.142)	loss 7.275 (7.275)	prob 3.138 (3.138)	GS 30.297 (30.297)	mem 39.793
Train: [62][185/750]	BT 0.091 (1.182)	DT 0.020 (1.137)	loss 7.235 (7.235)	prob 2.866 (2.866)	GS 27.453 (27.453)	mem 39.729
Train: [62][190/750]	BT 0.043 (1.195)	DT 0.009 (1.150)	loss 7.329 (7.329)	prob 2.416 (2.416)	GS 33.109 (33.109)	mem 40.036
Train: [62][195/750]	BT 0.088 (1.167)	DT 0.002 (1.122)	loss 7.077 (7.077)	prob 2.369 (2.369)	GS 30.812 (30.812)	mem 39.791
Train: [62][200/750]	BT 0.032 (1.210)	DT 0.001 (1.164)	loss 7.022 (7.022)	prob 2.300 (2.300)	GS 35.469 (35.469)	mem 39.817
Train: [62][205/750]	BT 0.035 (1.181)	DT 0.001 (1.136)	loss 7.415 (7.415)	prob 3.057 (3.057)	GS 25.875 (25.875)	mem 39.824
Train: [62][210/750]	BT 10.739 (1.212)	DT 10.701 (1.166)	loss 7.259 (7.259)	prob 2.879 (2.879)	GS 32.016 (32.016)	mem 39.996
Train: [62][215/750]	BT 0.052 (1.185)	DT 0.002 (1.139)	loss 7.340 (7.340)	prob 2.928 (2.928)	GS 31.141 (31.141)	mem 39.841
Train: [62][220/750]	BT 2.581 (1.179)	DT 2.501 (1.132)	loss 7.252 (7.252)	prob 3.242 (3.242)	GS 32.578 (32.578)	mem 39.825
Train: [62][225/750]	BT 0.061 (1.188)	DT 0.011 (1.142)	loss 7.377 (7.377)	prob 2.385 (2.385)	GS 29.984 (29.984)	mem 39.859
Train: [62][230/750]	BT 0.090 (1.164)	DT 0.011 (1.118)	loss 7.007 (7.007)	prob 3.327 (3.327)	GS 33.859 (33.859)	mem 39.905
Train: [62][235/750]	BT 0.033 (1.189)	DT 0.001 (1.143)	loss 7.815 (7.815)	prob 2.205 (2.205)	GS 32.312 (32.312)	mem 39.864
Train: [62][240/750]	BT 0.061 (1.165)	DT 0.015 (1.119)	loss 7.696 (7.696)	prob 2.448 (2.448)	GS 34.625 (34.625)	mem 39.890
Train: [62][245/750]	BT 0.052 (1.159)	DT 0.002 (1.113)	loss 7.501 (7.501)	prob 2.531 (2.531)	GS 33.719 (33.719)	mem 39.738
Train: [62][250/750]	BT 0.031 (1.172)	DT 0.001 (1.126)	loss 7.049 (7.049)	prob 3.595 (3.595)	GS 34.250 (34.250)	mem 39.781
Train: [62][255/750]	BT 0.032 (1.152)	DT 0.002 (1.106)	loss 7.238 (7.238)	prob 2.934 (2.934)	GS 31.281 (31.281)	mem 39.781
Train: [62][260/750]	BT 0.028 (1.180)	DT 0.002 (1.135)	loss 7.278 (7.278)	prob 2.291 (2.291)	GS 36.828 (36.828)	mem 39.884
Train: [62][265/750]	BT 0.035 (1.159)	DT 0.001 (1.113)	loss 7.233 (7.233)	prob 2.789 (2.789)	GS 28.297 (28.297)	mem 39.815
Train: [62][270/750]	BT 6.910 (1.178)	DT 6.879 (1.133)	loss 7.101 (7.101)	prob 3.052 (3.052)	GS 33.250 (33.250)	mem 39.783
Train: [62][275/750]	BT 0.097 (1.158)	DT 0.008 (1.112)	loss 7.615 (7.615)	prob 2.543 (2.543)	GS 34.562 (34.562)	mem 39.784
Train: [62][280/750]	BT 2.398 (1.147)	DT 2.348 (1.101)	loss 7.417 (7.417)	prob 3.337 (3.337)	GS 33.234 (33.234)	mem 39.945
Train: [62][285/750]	BT 0.045 (1.173)	DT 0.010 (1.128)	loss 7.084 (7.084)	prob 3.663 (3.663)	GS 27.484 (27.484)	mem 39.846
Train: [62][290/750]	BT 0.031 (1.154)	DT 0.001 (1.108)	loss 7.365 (7.365)	prob 3.084 (3.084)	GS 37.188 (37.188)	mem 39.893
Train: [62][295/750]	BT 0.035 (1.184)	DT 0.004 (1.138)	loss 7.038 (7.038)	prob 2.707 (2.707)	GS 31.328 (31.328)	mem 39.976
Train: [62][300/750]	BT 0.054 (1.165)	DT 0.027 (1.119)	loss 7.248 (7.248)	prob 3.310 (3.310)	GS 36.234 (36.234)	mem 39.836
Train: [62][305/750]	BT 0.051 (1.148)	DT 0.002 (1.103)	loss 7.583 (7.583)	prob 2.589 (2.589)	GS 32.391 (32.391)	mem 39.836
Train: [62][310/750]	BT 0.074 (1.162)	DT 0.006 (1.116)	loss 7.193 (7.193)	prob 2.605 (2.605)	GS 34.438 (34.438)	mem 39.814
Train: [62][315/750]	BT 0.088 (1.152)	DT 0.011 (1.106)	loss 7.808 (7.808)	prob 2.545 (2.545)	GS 32.422 (32.422)	mem 39.816
Train: [62][320/750]	BT 0.035 (1.159)	DT 0.003 (1.113)	loss 7.276 (7.276)	prob 3.434 (3.434)	GS 34.766 (34.766)	mem 39.842
Train: [62][325/750]	BT 0.031 (1.142)	DT 0.001 (1.096)	loss 7.221 (7.221)	prob 3.148 (3.148)	GS 33.812 (33.812)	mem 39.817
Train: [62][330/750]	BT 5.554 (1.164)	DT 5.505 (1.118)	loss 6.930 (6.930)	prob 3.736 (3.736)	GS 30.828 (30.828)	mem 39.884
Train: [62][335/750]	BT 0.038 (1.147)	DT 0.002 (1.102)	loss 7.683 (7.683)	prob 2.308 (2.308)	GS 31.641 (31.641)	mem 39.941
Train: [62][340/750]	BT 1.184 (1.147)	DT 1.121 (1.101)	loss 6.848 (6.848)	prob 3.188 (3.188)	GS 29.781 (29.781)	mem 39.900
Train: [62][345/750]	BT 0.056 (1.154)	DT 0.013 (1.109)	loss 7.289 (7.289)	prob 2.611 (2.611)	GS 30.391 (30.391)	mem 39.769
Train: [62][350/750]	BT 1.541 (1.143)	DT 1.474 (1.097)	loss 7.131 (7.131)	prob 3.238 (3.238)	GS 29.906 (29.906)	mem 39.771
Train: [62][355/750]	BT 0.054 (1.152)	DT 0.015 (1.107)	loss 7.638 (7.638)	prob 2.840 (2.840)	GS 33.375 (33.375)	mem 40.046
Train: [62][360/750]	BT 0.032 (1.137)	DT 0.001 (1.091)	loss 7.233 (7.233)	prob 2.707 (2.707)	GS 34.641 (34.641)	mem 39.848
Train: [62][365/750]	BT 0.082 (1.146)	DT 0.011 (1.100)	loss 7.082 (7.082)	prob 2.581 (2.581)	GS 27.156 (27.156)	mem 39.806
Train: [62][370/750]	BT 0.047 (1.150)	DT 0.001 (1.104)	loss 7.128 (7.128)	prob 2.628 (2.628)	GS 37.141 (37.141)	mem 39.863
Train: [62][375/750]	BT 0.054 (1.135)	DT 0.002 (1.089)	loss 7.124 (7.124)	prob 2.728 (2.728)	GS 34.141 (34.141)	mem 39.862
Train: [62][380/750]	BT 0.053 (1.148)	DT 0.005 (1.103)	loss 7.275 (7.275)	prob 3.020 (3.020)	GS 31.594 (31.594)	mem 39.879
Train: [62][385/750]	BT 0.050 (1.134)	DT 0.005 (1.088)	loss 7.004 (7.004)	prob 3.193 (3.193)	GS 26.250 (26.250)	mem 39.881
Train: [62][390/750]	BT 8.996 (1.152)	DT 8.951 (1.107)	loss 7.021 (7.021)	prob 2.589 (2.589)	GS 32.406 (32.406)	mem 40.080
Train: [62][395/750]	BT 0.027 (1.138)	DT 0.001 (1.093)	loss 7.202 (7.202)	prob 2.480 (2.480)	GS 31.391 (31.391)	mem 40.061
Train: [62][400/750]	BT 1.130 (1.127)	DT 1.079 (1.082)	loss 7.218 (7.218)	prob 1.761 (1.761)	GS 31.328 (31.328)	mem 39.998
Train: [62][405/750]	BT 0.036 (1.143)	DT 0.002 (1.097)	loss 7.228 (7.228)	prob 2.408 (2.408)	GS 30.234 (30.234)	mem 39.937
Train: [62][410/750]	BT 0.063 (1.130)	DT 0.014 (1.084)	loss 6.916 (6.916)	prob 3.236 (3.236)	GS 34.109 (34.109)	mem 39.992
Train: [62][415/750]	BT 0.055 (1.151)	DT 0.002 (1.106)	loss 7.420 (7.420)	prob 2.790 (2.790)	GS 32.688 (32.688)	mem 40.012
Train: [62][420/750]	BT 0.033 (1.138)	DT 0.001 (1.093)	loss 7.341 (7.341)	prob 2.591 (2.591)	GS 35.719 (35.719)	mem 39.942
Train: [62][425/750]	BT 0.033 (1.125)	DT 0.001 (1.080)	loss 7.211 (7.211)	prob 3.156 (3.156)	GS 31.172 (31.172)	mem 39.942
Train: [62][430/750]	BT 0.023 (1.146)	DT 0.001 (1.101)	loss 7.304 (7.304)	prob 2.740 (2.740)	GS 33.016 (33.016)	mem 39.842
Train: [62][435/750]	BT 0.043 (1.133)	DT 0.012 (1.088)	loss 7.133 (7.133)	prob 3.007 (3.007)	GS 32.359 (32.359)	mem 39.843
Train: [62][440/750]	BT 0.035 (1.140)	DT 0.002 (1.095)	loss 7.221 (7.221)	prob 2.567 (2.567)	GS 36.359 (36.359)	mem 39.897
Train: [62][445/750]	BT 0.056 (1.128)	DT 0.006 (1.083)	loss 7.321 (7.321)	prob 3.086 (3.086)	GS 28.359 (28.359)	mem 39.898
Train: [62][450/750]	BT 8.951 (1.141)	DT 8.871 (1.095)	loss 7.050 (7.050)	prob 2.959 (2.959)	GS 35.078 (35.078)	mem 39.950
Train: [62][455/750]	BT 0.037 (1.129)	DT 0.004 (1.084)	loss 7.369 (7.369)	prob 2.276 (2.276)	GS 26.672 (26.672)	mem 39.951
Train: [62][460/750]	BT 2.187 (1.127)	DT 2.148 (1.082)	loss 7.255 (7.255)	prob 2.493 (2.493)	GS 33.609 (33.609)	mem 40.105
Train: [62][465/750]	BT 0.021 (1.137)	DT 0.001 (1.092)	loss 7.466 (7.466)	prob 2.702 (2.702)	GS 29.062 (29.062)	mem 39.938
Train: [62][470/750]	BT 2.313 (1.130)	DT 2.248 (1.085)	loss 7.315 (7.315)	prob 2.663 (2.663)	GS 32.734 (32.734)	mem 39.869
Train: [62][475/750]	BT 0.029 (1.140)	DT 0.001 (1.095)	loss 7.100 (7.100)	prob 2.916 (2.916)	GS 28.797 (28.797)	mem 39.891
Train: [62][480/750]	BT 0.058 (1.128)	DT 0.002 (1.084)	loss 7.010 (7.010)	prob 2.984 (2.984)	GS 36.828 (36.828)	mem 40.016
Train: [62][485/750]	BT 0.052 (1.119)	DT 0.005 (1.074)	loss 7.801 (7.801)	prob 1.781 (1.781)	GS 31.000 (31.000)	mem 39.894
Train: [62][490/750]	BT 0.032 (1.129)	DT 0.001 (1.084)	loss 7.059 (7.059)	prob 2.923 (2.923)	GS 33.156 (33.156)	mem 39.896
Train: [62][495/750]	BT 0.032 (1.121)	DT 0.001 (1.076)	loss 7.223 (7.223)	prob 2.801 (2.801)	GS 30.062 (30.062)	mem 39.896
Train: [62][500/750]	BT 0.036 (1.128)	DT 0.001 (1.084)	loss 6.902 (6.902)	prob 3.184 (3.184)	GS 33.453 (33.453)	mem 39.908
Train: [62][505/750]	BT 0.027 (1.118)	DT 0.001 (1.073)	loss 6.791 (6.791)	prob 3.196 (3.196)	GS 32.406 (32.406)	mem 39.909
Train: [62][510/750]	BT 6.014 (1.129)	DT 5.977 (1.084)	loss 6.915 (6.915)	prob 2.642 (2.642)	GS 29.906 (29.906)	mem 40.077
Train: [62][515/750]	BT 0.032 (1.120)	DT 0.001 (1.075)	loss 6.768 (6.768)	prob 2.379 (2.379)	GS 32.766 (32.766)	mem 39.944
Train: [62][520/750]	BT 3.041 (1.123)	DT 3.007 (1.078)	loss 6.787 (6.787)	prob 2.615 (2.615)	GS 37.031 (37.031)	mem 39.968
Train: [62][525/750]	BT 0.049 (1.120)	DT 0.002 (1.075)	loss 7.288 (7.288)	prob 2.674 (2.674)	GS 33.734 (33.734)	mem 39.875
Train: [62][530/750]	BT 0.936 (1.123)	DT 0.845 (1.078)	loss 6.952 (6.952)	prob 3.384 (3.384)	GS 34.844 (34.844)	mem 40.018
Train: [62][535/750]	BT 0.066 (1.122)	DT 0.012 (1.077)	loss 6.924 (6.924)	prob 2.727 (2.727)	GS 29.984 (29.984)	mem 39.879
Train: [62][540/750]	BT 0.031 (1.128)	DT 0.001 (1.083)	loss 6.930 (6.930)	prob 2.325 (2.325)	GS 32.969 (32.969)	mem 39.953
Train: [62][545/750]	BT 0.034 (1.126)	DT 0.001 (1.081)	loss 6.854 (6.854)	prob 2.546 (2.546)	GS 29.297 (29.297)	mem 39.908
Train: [62][550/750]	BT 9.650 (1.134)	DT 9.563 (1.089)	loss 7.037 (7.037)	prob 3.015 (3.015)	GS 33.438 (33.438)	mem 39.958
Train: [62][555/750]	BT 0.046 (1.129)	DT 0.002 (1.084)	loss 7.066 (7.066)	prob 3.054 (3.054)	GS 44.484 (44.484)	mem 40.076
Train: [62][560/750]	BT 0.055 (1.121)	DT 0.014 (1.076)	loss 6.972 (6.972)	prob 2.797 (2.797)	GS 36.531 (36.531)	mem 39.959
Train: [62][565/750]	BT 0.092 (1.123)	DT 0.040 (1.078)	loss 6.936 (6.936)	prob 2.345 (2.345)	GS 30.109 (30.109)	mem 39.966
Train: [62][570/750]	BT 0.031 (1.125)	DT 0.001 (1.080)	loss 6.758 (6.758)	prob 3.033 (3.033)	GS 32.156 (32.156)	mem 40.013
Train: [62][575/750]	BT 0.034 (1.133)	DT 0.002 (1.087)	loss 7.140 (7.140)	prob 2.161 (2.161)	GS 30.172 (30.172)	mem 39.948
Train: [62][580/750]	BT 0.484 (1.126)	DT 0.422 (1.081)	loss 7.004 (7.004)	prob 2.947 (2.947)	GS 37.656 (37.656)	mem 39.973
Train: [62][585/750]	BT 0.079 (1.121)	DT 0.006 (1.076)	loss 7.009 (7.009)	prob 2.107 (2.107)	GS 27.344 (27.344)	mem 39.786
Train: [62][590/750]	BT 3.094 (1.132)	DT 3.030 (1.087)	loss 7.210 (7.210)	prob 2.581 (2.581)	GS 34.859 (34.859)	mem 39.753
Train: [62][595/750]	BT 0.035 (1.123)	DT 0.002 (1.078)	loss 7.091 (7.091)	prob 2.431 (2.431)	GS 31.641 (31.641)	mem 39.781
Train: [62][600/750]	BT 0.027 (1.131)	DT 0.001 (1.086)	loss 6.698 (6.698)	prob 3.320 (3.320)	GS 31.938 (31.938)	mem 39.857
Train: [62][605/750]	BT 0.044 (1.128)	DT 0.003 (1.083)	loss 7.143 (7.143)	prob 2.346 (2.346)	GS 32.312 (32.312)	mem 39.860
Train: [62][610/750]	BT 8.318 (1.132)	DT 8.289 (1.088)	loss 7.136 (7.136)	prob 2.821 (2.821)	GS 32.328 (32.328)	mem 39.890
Train: [62][615/750]	BT 0.071 (1.134)	DT 0.015 (1.089)	loss 6.953 (6.953)	prob 2.597 (2.597)	GS 31.766 (31.766)	mem 39.861
Train: [62][620/750]	BT 0.035 (1.125)	DT 0.001 (1.080)	loss 6.763 (6.763)	prob 2.079 (2.079)	GS 32.984 (32.984)	mem 39.890
Train: [62][625/750]	BT 0.050 (1.130)	DT 0.001 (1.085)	loss 7.279 (7.279)	prob 2.623 (2.623)	GS 31.359 (31.359)	mem 39.834
Train: [62][630/750]	BT 0.031 (1.126)	DT 0.001 (1.081)	loss 6.887 (6.887)	prob 3.008 (3.008)	GS 32.812 (32.812)	mem 39.872
Train: [62][635/750]	BT 0.038 (1.137)	DT 0.001 (1.092)	loss 7.332 (7.332)	prob 2.425 (2.425)	GS 34.109 (34.109)	mem 39.917
Train: [62][640/750]	BT 0.065 (1.130)	DT 0.016 (1.086)	loss 6.896 (6.896)	prob 2.765 (2.765)	GS 31.953 (31.953)	mem 39.953
Train: [62][645/750]	BT 0.034 (1.122)	DT 0.003 (1.077)	loss 7.288 (7.288)	prob 2.570 (2.570)	GS 30.016 (30.016)	mem 39.883
Train: [62][650/750]	BT 2.716 (1.137)	DT 2.679 (1.092)	loss 7.148 (7.148)	prob 2.991 (2.991)	GS 36.266 (36.266)	mem 39.924
Train: [62][655/750]	BT 0.072 (1.129)	DT 0.006 (1.084)	loss 7.086 (7.086)	prob 2.660 (2.660)	GS 32.344 (32.344)	mem 39.925
arpack error, retry= 0
Train: [62][660/750]	BT 0.043 (1.129)	DT 0.015 (1.085)	loss 6.961 (6.961)	prob 2.922 (2.922)	GS 36.188 (36.188)	mem 39.935
Train: [62][665/750]	BT 0.084 (1.128)	DT 0.003 (1.083)	loss 7.076 (7.076)	prob 2.610 (2.610)	GS 35.344 (35.344)	mem 40.012
Train: [62][670/750]	BT 9.983 (1.134)	DT 9.947 (1.090)	loss 7.148 (7.148)	prob 2.600 (2.600)	GS 32.297 (32.297)	mem 39.960
Train: [62][675/750]	BT 0.035 (1.127)	DT 0.003 (1.083)	loss 6.777 (6.777)	prob 2.967 (2.967)	GS 29.656 (29.656)	mem 40.008
Train: [62][680/750]	BT 0.048 (1.120)	DT 0.002 (1.075)	loss 6.883 (6.883)	prob 3.054 (3.054)	GS 35.625 (35.625)	mem 39.941
Train: [62][685/750]	BT 0.049 (1.130)	DT 0.008 (1.085)	loss 6.718 (6.718)	prob 2.825 (2.825)	GS 28.281 (28.281)	mem 39.863
Train: [62][690/750]	BT 0.088 (1.122)	DT 0.004 (1.077)	loss 6.951 (6.951)	prob 3.058 (3.058)	GS 31.688 (31.688)	mem 39.980
Train: [62][695/750]	BT 0.086 (1.131)	DT 0.010 (1.086)	loss 7.042 (7.042)	prob 2.174 (2.174)	GS 31.281 (31.281)	mem 39.994
Train: [62][700/750]	BT 0.058 (1.125)	DT 0.001 (1.080)	loss 6.971 (6.971)	prob 2.081 (2.081)	GS 34.938 (34.938)	mem 39.947
Train: [62][705/750]	BT 0.038 (1.117)	DT 0.003 (1.072)	loss 7.193 (7.193)	prob 2.142 (2.142)	GS 37.234 (37.234)	mem 39.872
Train: [62][710/750]	BT 1.442 (1.128)	DT 1.387 (1.084)	loss 6.908 (6.908)	prob 2.484 (2.484)	GS 34.672 (34.672)	mem 40.027
Train: [62][715/750]	BT 0.039 (1.121)	DT 0.012 (1.076)	loss 7.050 (7.050)	prob 2.440 (2.440)	GS 31.031 (31.031)	mem 39.904
Train: [62][720/750]	BT 0.126 (1.126)	DT 0.040 (1.081)	loss 6.946 (6.946)	prob 2.460 (2.460)	GS 36.938 (36.938)	mem 40.076
Train: [62][725/750]	BT 0.046 (1.120)	DT 0.003 (1.075)	loss 6.933 (6.933)	prob 2.369 (2.369)	GS 31.750 (31.750)	mem 39.958
Train: [62][730/750]	BT 10.095 (1.126)	DT 10.070 (1.082)	loss 6.807 (6.807)	prob 2.282 (2.282)	GS 31.391 (31.391)	mem 39.405
Train: [62][735/750]	BT 0.039 (1.121)	DT 0.014 (1.076)	loss 6.902 (6.902)	prob 3.093 (3.093)	GS 33.391 (33.391)	mem 36.434
Train: [62][740/750]	BT 0.107 (1.114)	DT 0.062 (1.069)	loss 7.349 (7.349)	prob 2.823 (2.823)	GS 31.734 (31.734)	mem 36.349
Train: [62][745/750]	BT 0.026 (1.115)	DT 0.001 (1.070)	loss 6.910 (6.910)	prob 3.011 (3.011)	GS 27.031 (27.031)	mem 7.622
Train: [62][750/750]	BT 0.028 (1.107)	DT 0.001 (1.063)	loss 7.027 (7.027)	prob 2.359 (2.359)	GS 34.312 (34.312)	mem 7.623
Train: [62][755/750]	BT 0.028 (1.104)	DT 0.001 (1.060)	loss 7.506 (7.506)	prob 1.974 (1.974)	GS 37.031 (37.031)	mem 7.587
epoch 62, total time 834.00
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [63][1/750]	BT 23.431 (23.431)	DT 23.367 (23.367)	loss 7.104 (7.104)	prob 2.069 (2.069)	GS 35.062 (35.062)	mem 38.682
Train: [63][5/750]	BT 0.064 (5.236)	DT 0.024 (5.176)	loss 6.550 (6.550)	prob 3.028 (3.028)	GS 31.859 (31.859)	mem 38.751
Train: [63][10/750]	BT 0.044 (2.644)	DT 0.002 (2.589)	loss 6.898 (6.898)	prob 2.665 (2.665)	GS 37.922 (37.922)	mem 38.751
Train: [63][15/750]	BT 0.034 (2.484)	DT 0.003 (2.432)	loss 7.121 (7.121)	prob 2.435 (2.435)	GS 29.609 (29.609)	mem 38.862
Train: [63][20/750]	BT 0.119 (2.041)	DT 0.002 (1.989)	loss 6.848 (6.848)	prob 2.969 (2.969)	GS 29.844 (29.844)	mem 39.058
Train: [63][25/750]	BT 1.557 (1.740)	DT 1.484 (1.683)	loss 6.708 (6.708)	prob 3.238 (3.238)	GS 26.516 (26.516)	mem 39.007
Train: [63][30/750]	BT 2.770 (1.808)	DT 2.738 (1.753)	loss 6.716 (6.716)	prob 3.179 (3.179)	GS 36.438 (36.438)	mem 38.993
Train: [63][35/750]	BT 0.032 (1.555)	DT 0.001 (1.503)	loss 7.219 (7.219)	prob 2.252 (2.252)	GS 31.641 (31.641)	mem 38.943
Train: [63][40/750]	BT 6.452 (1.696)	DT 6.420 (1.645)	loss 6.562 (6.562)	prob 2.993 (2.993)	GS 35.547 (35.547)	mem 39.080
Train: [63][45/750]	BT 0.026 (1.512)	DT 0.001 (1.462)	loss 7.061 (7.061)	prob 2.200 (2.200)	GS 33.938 (33.938)	mem 38.996
Train: [63][50/750]	BT 1.867 (1.464)	DT 1.790 (1.413)	loss 6.935 (6.935)	prob 2.707 (2.707)	GS 33.125 (33.125)	mem 39.036
Train: [63][55/750]	BT 0.056 (1.500)	DT 0.007 (1.449)	loss 7.198 (7.198)	prob 2.312 (2.312)	GS 33.672 (33.672)	mem 39.099
Train: [63][60/750]	BT 0.034 (1.387)	DT 0.001 (1.336)	loss 6.960 (6.960)	prob 2.765 (2.765)	GS 30.438 (30.438)	mem 39.079
Train: [63][65/750]	BT 0.034 (1.464)	DT 0.003 (1.414)	loss 6.804 (6.804)	prob 3.455 (3.455)	GS 33.562 (33.562)	mem 39.043
Train: [63][70/750]	BT 0.032 (1.362)	DT 0.004 (1.313)	loss 6.841 (6.841)	prob 2.528 (2.528)	GS 31.453 (31.453)	mem 39.044
Train: [63][75/750]	BT 0.045 (1.389)	DT 0.002 (1.341)	loss 6.963 (6.963)	prob 2.573 (2.573)	GS 31.438 (31.438)	mem 39.131
Train: [63][80/750]	BT 0.052 (1.365)	DT 0.011 (1.318)	loss 6.953 (6.953)	prob 2.316 (2.316)	GS 31.734 (31.734)	mem 39.155
Train: [63][85/750]	BT 0.082 (1.288)	DT 0.012 (1.241)	loss 6.978 (6.978)	prob 2.319 (2.319)	GS 28.281 (28.281)	mem 39.134
Train: [63][90/750]	BT 0.033 (1.378)	DT 0.001 (1.331)	loss 7.011 (7.011)	prob 2.548 (2.548)	GS 32.359 (32.359)	mem 39.064
Train: [63][95/750]	BT 0.087 (1.307)	DT 0.002 (1.261)	loss 7.422 (7.422)	prob 1.970 (1.970)	GS 34.797 (34.797)	mem 39.064
Train: [63][100/750]	BT 4.971 (1.366)	DT 4.937 (1.319)	loss 6.699 (6.699)	prob 2.855 (2.855)	GS 33.234 (33.234)	mem 39.183
Train: [63][105/750]	BT 0.032 (1.302)	DT 0.001 (1.256)	loss 7.109 (7.109)	prob 2.846 (2.846)	GS 26.953 (26.953)	mem 39.045
Train: [63][110/750]	BT 8.204 (1.320)	DT 8.133 (1.273)	loss 7.077 (7.077)	prob 2.098 (2.098)	GS 34.859 (34.859)	mem 39.340
Train: [63][115/750]	BT 0.077 (1.298)	DT 0.004 (1.250)	loss 6.897 (6.897)	prob 2.831 (2.831)	GS 31.328 (31.328)	mem 39.286
Train: [63][120/750]	BT 0.037 (1.245)	DT 0.001 (1.198)	loss 6.946 (6.946)	prob 2.288 (2.288)	GS 35.344 (35.344)	mem 39.191
Train: [63][125/750]	BT 0.087 (1.306)	DT 0.007 (1.259)	loss 7.104 (7.104)	prob 2.046 (2.046)	GS 25.875 (25.875)	mem 39.201
Train: [63][130/750]	BT 0.034 (1.257)	DT 0.002 (1.211)	loss 6.852 (6.852)	prob 2.769 (2.769)	GS 33.688 (33.688)	mem 39.244
Train: [63][135/750]	BT 0.038 (1.258)	DT 0.004 (1.210)	loss 7.075 (7.075)	prob 2.198 (2.198)	GS 31.188 (31.188)	mem 39.215
Train: [63][140/750]	BT 0.055 (1.288)	DT 0.005 (1.240)	loss 6.794 (6.794)	prob 2.669 (2.669)	GS 35.469 (35.469)	mem 39.327
Train: [63][145/750]	BT 0.035 (1.245)	DT 0.001 (1.198)	loss 7.086 (7.086)	prob 2.112 (2.112)	GS 31.703 (31.703)	mem 39.213
Train: [63][150/750]	BT 0.038 (1.299)	DT 0.005 (1.251)	loss 6.617 (6.617)	prob 2.389 (2.389)	GS 36.812 (36.812)	mem 39.226
Train: [63][155/750]	BT 0.033 (1.258)	DT 0.001 (1.211)	loss 6.993 (6.993)	prob 2.195 (2.195)	GS 31.969 (31.969)	mem 39.271
Train: [63][160/750]	BT 3.561 (1.280)	DT 3.519 (1.233)	loss 7.053 (7.053)	prob 2.640 (2.640)	GS 32.938 (32.938)	mem 39.307
Train: [63][165/750]	BT 0.036 (1.243)	DT 0.002 (1.196)	loss 6.986 (6.986)	prob 3.305 (3.305)	GS 31.922 (31.922)	mem 39.340
Train: [63][170/750]	BT 8.976 (1.262)	DT 8.950 (1.214)	loss 6.855 (6.855)	prob 3.334 (3.334)	GS 32.953 (32.953)	mem 39.541
Train: [63][175/750]	BT 0.107 (1.231)	DT 0.036 (1.183)	loss 7.614 (7.614)	prob 1.801 (1.801)	GS 31.953 (31.953)	mem 39.293
Train: [63][180/750]	BT 0.038 (1.199)	DT 0.001 (1.150)	loss 6.830 (6.830)	prob 2.526 (2.526)	GS 36.391 (36.391)	mem 39.297
Train: [63][185/750]	BT 0.027 (1.253)	DT 0.001 (1.206)	loss 7.166 (7.166)	prob 2.093 (2.093)	GS 31.719 (31.719)	mem 39.443
Train: [63][190/750]	BT 0.036 (1.221)	DT 0.010 (1.174)	loss 7.162 (7.162)	prob 2.659 (2.659)	GS 35.281 (35.281)	mem 39.383
Train: [63][195/750]	BT 0.061 (1.230)	DT 0.007 (1.183)	loss 6.840 (6.840)	prob 2.794 (2.794)	GS 33.984 (33.984)	mem 39.634
Train: [63][200/750]	BT 0.031 (1.219)	DT 0.001 (1.173)	loss 6.866 (6.866)	prob 2.718 (2.718)	GS 32.375 (32.375)	mem 39.568
Train: [63][205/750]	BT 0.035 (1.191)	DT 0.004 (1.144)	loss 7.071 (7.071)	prob 2.520 (2.520)	GS 32.109 (32.109)	mem 39.577
Train: [63][210/750]	BT 0.031 (1.238)	DT 0.001 (1.192)	loss 6.960 (6.960)	prob 3.324 (3.324)	GS 32.500 (32.500)	mem 39.560
Train: [63][215/750]	BT 0.113 (1.211)	DT 0.003 (1.164)	loss 7.308 (7.308)	prob 2.722 (2.722)	GS 32.500 (32.500)	mem 39.561
Train: [63][220/750]	BT 12.920 (1.252)	DT 12.884 (1.206)	loss 6.963 (6.963)	prob 2.783 (2.783)	GS 38.422 (38.422)	mem 39.540
Train: [63][225/750]	BT 0.035 (1.225)	DT 0.002 (1.179)	loss 6.833 (6.833)	prob 2.779 (2.779)	GS 30.094 (30.094)	mem 39.565
Train: [63][230/750]	BT 0.931 (1.203)	DT 0.884 (1.157)	loss 6.918 (6.918)	prob 2.775 (2.775)	GS 33.406 (33.406)	mem 39.497
Train: [63][235/750]	BT 0.047 (1.240)	DT 0.007 (1.195)	loss 6.864 (6.864)	prob 2.813 (2.813)	GS 30.828 (30.828)	mem 39.578
Train: [63][240/750]	BT 0.031 (1.215)	DT 0.001 (1.170)	loss 7.179 (7.179)	prob 2.464 (2.464)	GS 36.188 (36.188)	mem 39.578
Train: [63][245/750]	BT 0.027 (1.252)	DT 0.001 (1.206)	loss 7.156 (7.156)	prob 2.710 (2.710)	GS 33.375 (33.375)	mem 39.627
Train: [63][250/750]	BT 0.029 (1.228)	DT 0.001 (1.182)	loss 6.726 (6.726)	prob 2.792 (2.792)	GS 33.469 (33.469)	mem 39.628
Train: [63][255/750]	BT 0.034 (1.204)	DT 0.002 (1.159)	loss 7.384 (7.384)	prob 2.484 (2.484)	GS 47.875 (47.875)	mem 39.630
Train: [63][260/750]	BT 0.027 (1.230)	DT 0.001 (1.185)	loss 6.711 (6.711)	prob 2.825 (2.825)	GS 37.172 (37.172)	mem 39.637
Train: [63][265/750]	BT 0.035 (1.207)	DT 0.002 (1.162)	loss 7.218 (7.218)	prob 3.055 (3.055)	GS 33.641 (33.641)	mem 39.668
Train: [63][270/750]	BT 0.051 (1.231)	DT 0.008 (1.185)	loss 6.785 (6.785)	prob 2.588 (2.588)	GS 33.297 (33.297)	mem 39.632
Train: [63][275/750]	BT 0.056 (1.209)	DT 0.004 (1.164)	loss 6.952 (6.952)	prob 2.761 (2.761)	GS 29.531 (29.531)	mem 39.681
Train: [63][280/750]	BT 11.945 (1.231)	DT 11.886 (1.185)	loss 6.861 (6.861)	prob 3.580 (3.580)	GS 33.531 (33.531)	mem 39.849
Train: [63][285/750]	BT 0.097 (1.210)	DT 0.029 (1.165)	loss 7.413 (7.413)	prob 2.393 (2.393)	GS 29.547 (29.547)	mem 39.955
Train: [63][290/750]	BT 1.285 (1.194)	DT 1.251 (1.149)	loss 6.815 (6.815)	prob 2.565 (2.565)	GS 31.266 (31.266)	mem 40.238
Train: [63][295/750]	BT 0.030 (1.217)	DT 0.001 (1.172)	loss 6.981 (6.981)	prob 3.385 (3.385)	GS 27.859 (27.859)	mem 40.015
Train: [63][300/750]	BT 0.040 (1.198)	DT 0.013 (1.153)	loss 7.062 (7.062)	prob 2.714 (2.714)	GS 34.125 (34.125)	mem 39.931
Train: [63][305/750]	BT 0.038 (1.219)	DT 0.001 (1.174)	loss 7.067 (7.067)	prob 2.785 (2.785)	GS 28.562 (28.562)	mem 39.841
Train: [63][310/750]	BT 0.086 (1.201)	DT 0.003 (1.155)	loss 6.877 (6.877)	prob 3.112 (3.112)	GS 31.875 (31.875)	mem 39.843
Train: [63][315/750]	BT 0.054 (1.195)	DT 0.028 (1.150)	loss 7.025 (7.025)	prob 2.573 (2.573)	GS 31.359 (31.359)	mem 39.743
Train: [63][320/750]	BT 0.036 (1.203)	DT 0.001 (1.158)	loss 7.157 (7.157)	prob 2.102 (2.102)	GS 32.719 (32.719)	mem 39.989
Train: [63][325/750]	BT 0.055 (1.186)	DT 0.002 (1.140)	loss 7.083 (7.083)	prob 3.461 (3.461)	GS 29.656 (29.656)	mem 39.937
Train: [63][330/750]	BT 0.032 (1.204)	DT 0.002 (1.159)	loss 7.028 (7.028)	prob 2.599 (2.599)	GS 32.547 (32.547)	mem 39.875
Train: [63][335/750]	BT 0.031 (1.188)	DT 0.002 (1.143)	loss 7.117 (7.117)	prob 2.672 (2.672)	GS 34.484 (34.484)	mem 39.919
Train: [63][340/750]	BT 10.204 (1.211)	DT 10.181 (1.166)	loss 6.773 (6.773)	prob 2.676 (2.676)	GS 34.656 (34.656)	mem 39.832
Train: [63][345/750]	BT 0.032 (1.194)	DT 0.001 (1.150)	loss 7.053 (7.053)	prob 2.589 (2.589)	GS 31.641 (31.641)	mem 39.831
Train: [63][350/750]	BT 4.452 (1.191)	DT 4.398 (1.146)	loss 6.876 (6.876)	prob 2.268 (2.268)	GS 31.719 (31.719)	mem 39.875
Train: [63][355/750]	BT 0.047 (1.200)	DT 0.001 (1.156)	loss 7.060 (7.060)	prob 3.253 (3.253)	GS 28.703 (28.703)	mem 39.865
Train: [63][360/750]	BT 0.032 (1.185)	DT 0.001 (1.140)	loss 7.063 (7.063)	prob 2.764 (2.764)	GS 31.859 (31.859)	mem 39.746
Train: [63][365/750]	BT 0.040 (1.204)	DT 0.009 (1.160)	loss 7.132 (7.132)	prob 2.917 (2.917)	GS 29.344 (29.344)	mem 39.815
Train: [63][370/750]	BT 0.032 (1.189)	DT 0.001 (1.145)	loss 7.188 (7.188)	prob 2.040 (2.040)	GS 33.266 (33.266)	mem 39.847
Train: [63][375/750]	BT 0.030 (1.175)	DT 0.001 (1.130)	loss 6.980 (6.980)	prob 2.770 (2.770)	GS 33.984 (33.984)	mem 39.842
Train: [63][380/750]	BT 0.078 (1.191)	DT 0.001 (1.146)	loss 6.907 (6.907)	prob 2.510 (2.510)	GS 35.000 (35.000)	mem 39.895
Train: [63][385/750]	BT 0.051 (1.176)	DT 0.005 (1.131)	loss 7.165 (7.165)	prob 2.341 (2.341)	GS 29.609 (29.609)	mem 39.895
Train: [63][390/750]	BT 0.028 (1.198)	DT 0.001 (1.154)	loss 6.911 (6.911)	prob 3.173 (3.173)	GS 31.266 (31.266)	mem 39.863
Train: [63][395/750]	BT 0.055 (1.183)	DT 0.002 (1.139)	loss 6.921 (6.921)	prob 2.502 (2.502)	GS 33.984 (33.984)	mem 39.797
Train: [63][400/750]	BT 11.824 (1.200)	DT 11.794 (1.155)	loss 6.956 (6.956)	prob 2.622 (2.622)	GS 30.500 (30.500)	mem 39.858
Train: [63][405/750]	BT 0.050 (1.186)	DT 0.008 (1.141)	loss 7.254 (7.254)	prob 2.808 (2.808)	GS 26.281 (26.281)	mem 39.860
Train: [63][410/750]	BT 1.027 (1.183)	DT 0.948 (1.139)	loss 6.807 (6.807)	prob 2.623 (2.623)	GS 33.125 (33.125)	mem 39.868
Train: [63][415/750]	BT 0.047 (1.181)	DT 0.009 (1.137)	loss 7.024 (7.024)	prob 2.840 (2.840)	GS 30.641 (30.641)	mem 39.893
Train: [63][420/750]	BT 6.766 (1.190)	DT 6.677 (1.146)	loss 6.901 (6.901)	prob 2.975 (2.975)	GS 35.516 (35.516)	mem 39.818
Train: [63][425/750]	BT 0.026 (1.185)	DT 0.001 (1.141)	loss 7.013 (7.013)	prob 2.931 (2.931)	GS 28.328 (28.328)	mem 39.789
Train: [63][430/750]	BT 0.069 (1.183)	DT 0.001 (1.139)	loss 6.931 (6.931)	prob 2.822 (2.822)	GS 31.875 (31.875)	mem 39.860
Train: [63][435/750]	BT 0.047 (1.185)	DT 0.002 (1.141)	loss 6.852 (6.852)	prob 2.923 (2.923)	GS 33.812 (33.812)	mem 39.844
Train: [63][440/750]	BT 6.509 (1.195)	DT 6.456 (1.151)	loss 7.287 (7.287)	prob 2.420 (2.420)	GS 47.250 (47.250)	mem 39.930
Train: [63][445/750]	BT 0.054 (1.192)	DT 0.001 (1.148)	loss 7.086 (7.086)	prob 2.197 (2.197)	GS 31.234 (31.234)	mem 40.012
Train: [63][450/750]	BT 0.033 (1.184)	DT 0.002 (1.139)	loss 7.041 (7.041)	prob 2.750 (2.750)	GS 35.203 (35.203)	mem 39.826
Train: [63][455/750]	BT 0.080 (1.182)	DT 0.008 (1.138)	loss 6.964 (6.964)	prob 2.863 (2.863)	GS 34.312 (34.312)	mem 39.859
Train: [63][460/750]	BT 3.263 (1.186)	DT 3.167 (1.142)	loss 6.956 (6.956)	prob 2.895 (2.895)	GS 35.547 (35.547)	mem 39.859
Train: [63][465/750]	BT 0.032 (1.185)	DT 0.001 (1.140)	loss 6.890 (6.890)	prob 3.042 (3.042)	GS 33.812 (33.812)	mem 39.941
Train: [63][470/750]	BT 0.073 (1.184)	DT 0.015 (1.140)	loss 6.796 (6.796)	prob 2.903 (2.903)	GS 33.875 (33.875)	mem 39.861
Train: [63][475/750]	BT 0.056 (1.181)	DT 0.001 (1.137)	loss 7.110 (7.110)	prob 2.474 (2.474)	GS 30.766 (30.766)	mem 39.906
Train: [63][480/750]	BT 4.740 (1.181)	DT 4.692 (1.137)	loss 6.773 (6.773)	prob 2.932 (2.932)	GS 34.516 (34.516)	mem 39.925
Train: [63][485/750]	BT 0.126 (1.182)	DT 0.043 (1.137)	loss 7.001 (7.001)	prob 2.369 (2.369)	GS 28.797 (28.797)	mem 40.031
Train: [63][490/750]	BT 0.025 (1.171)	DT 0.001 (1.127)	loss 6.874 (6.874)	prob 3.009 (3.009)	GS 32.125 (32.125)	mem 39.924
Train: [63][495/750]	BT 0.043 (1.173)	DT 0.001 (1.129)	loss 7.041 (7.041)	prob 2.518 (2.518)	GS 44.969 (44.969)	mem 39.881
Train: [63][500/750]	BT 0.054 (1.173)	DT 0.001 (1.128)	loss 6.727 (6.727)	prob 3.338 (3.338)	GS 37.359 (37.359)	mem 39.984
Train: [63][505/750]	BT 0.078 (1.173)	DT 0.008 (1.128)	loss 7.094 (7.094)	prob 2.510 (2.510)	GS 30.062 (30.062)	mem 40.555
Train: [63][510/750]	BT 0.033 (1.175)	DT 0.002 (1.130)	loss 6.908 (6.908)	prob 3.462 (3.462)	GS 30.406 (30.406)	mem 40.000
Train: [63][515/750]	BT 0.104 (1.168)	DT 0.002 (1.123)	loss 6.941 (6.941)	prob 2.339 (2.339)	GS 28.859 (28.859)	mem 39.908
Train: [63][520/750]	BT 1.339 (1.171)	DT 1.304 (1.126)	loss 6.922 (6.922)	prob 2.772 (2.772)	GS 36.484 (36.484)	mem 39.930
Train: [63][525/750]	BT 0.052 (1.178)	DT 0.004 (1.133)	loss 7.038 (7.038)	prob 2.747 (2.747)	GS 33.984 (33.984)	mem 40.004
Train: [63][530/750]	BT 0.024 (1.174)	DT 0.001 (1.129)	loss 6.797 (6.797)	prob 2.772 (2.772)	GS 35.109 (35.109)	mem 39.945
Train: [63][535/750]	BT 0.027 (1.163)	DT 0.001 (1.119)	loss 6.934 (6.934)	prob 2.161 (2.161)	GS 33.891 (33.891)	mem 40.142
Train: [63][540/750]	BT 2.870 (1.174)	DT 2.837 (1.129)	loss 7.018 (7.018)	prob 2.833 (2.833)	GS 34.812 (34.812)	mem 40.028
Train: [63][545/750]	BT 0.032 (1.169)	DT 0.001 (1.124)	loss 7.035 (7.035)	prob 2.908 (2.908)	GS 35.609 (35.609)	mem 39.919
Train: [63][550/750]	BT 0.052 (1.169)	DT 0.005 (1.125)	loss 6.882 (6.882)	prob 2.595 (2.595)	GS 37.234 (37.234)	mem 40.117
Train: [63][555/750]	BT 0.024 (1.167)	DT 0.001 (1.123)	loss 6.966 (6.966)	prob 2.843 (2.843)	GS 32.906 (32.906)	mem 39.948
Train: [63][560/750]	BT 6.862 (1.169)	DT 6.803 (1.125)	loss 6.809 (6.809)	prob 2.790 (2.790)	GS 32.203 (32.203)	mem 39.946
Train: [63][565/750]	BT 0.032 (1.169)	DT 0.002 (1.126)	loss 7.195 (7.195)	prob 3.286 (3.286)	GS 35.672 (35.672)	mem 39.894
Train: [63][570/750]	BT 0.030 (1.159)	DT 0.001 (1.116)	loss 6.812 (6.812)	prob 3.265 (3.265)	GS 31.266 (31.266)	mem 39.895
Train: [63][575/750]	BT 0.050 (1.170)	DT 0.008 (1.126)	loss 6.877 (6.877)	prob 3.242 (3.242)	GS 31.844 (31.844)	mem 39.956
Train: [63][580/750]	BT 0.051 (1.167)	DT 0.013 (1.123)	loss 6.741 (6.741)	prob 2.995 (2.995)	GS 28.484 (28.484)	mem 39.897
Train: [63][585/750]	BT 0.075 (1.167)	DT 0.002 (1.123)	loss 6.996 (6.996)	prob 2.548 (2.548)	GS 34.906 (34.906)	mem 39.894
Train: [63][590/750]	BT 0.030 (1.174)	DT 0.001 (1.131)	loss 7.013 (7.013)	prob 2.689 (2.689)	GS 32.422 (32.422)	mem 39.939
Train: [63][595/750]	BT 0.077 (1.165)	DT 0.019 (1.122)	loss 7.759 (7.759)	prob 2.567 (2.567)	GS 43.406 (43.406)	mem 39.940
Train: [63][600/750]	BT 3.238 (1.178)	DT 3.196 (1.134)	loss 7.091 (7.091)	prob 2.941 (2.941)	GS 33.359 (33.359)	mem 40.044
Train: [63][605/750]	BT 0.030 (1.169)	DT 0.001 (1.125)	loss 7.045 (7.045)	prob 2.572 (2.572)	GS 30.500 (30.500)	mem 39.928
Train: [63][610/750]	BT 0.083 (1.173)	DT 0.004 (1.129)	loss 7.115 (7.115)	prob 2.496 (2.496)	GS 38.328 (38.328)	mem 39.909
Train: [63][615/750]	BT 0.043 (1.174)	DT 0.002 (1.130)	loss 7.186 (7.186)	prob 2.510 (2.510)	GS 33.703 (33.703)	mem 39.968
Train: [63][620/750]	BT 2.448 (1.169)	DT 2.399 (1.125)	loss 6.912 (6.912)	prob 3.414 (3.414)	GS 32.797 (32.797)	mem 39.968
Train: [63][625/750]	BT 0.032 (1.175)	DT 0.002 (1.131)	loss 6.912 (6.912)	prob 3.044 (3.044)	GS 32.109 (32.109)	mem 39.908
Train: [63][630/750]	BT 0.038 (1.166)	DT 0.001 (1.122)	loss 6.778 (6.778)	prob 3.337 (3.337)	GS 32.391 (32.391)	mem 39.927
Train: [63][635/750]	BT 0.029 (1.162)	DT 0.001 (1.119)	loss 7.024 (7.024)	prob 2.933 (2.933)	GS 28.000 (28.000)	mem 39.940
Train: [63][640/750]	BT 0.034 (1.168)	DT 0.002 (1.125)	loss 6.753 (6.753)	prob 2.972 (2.972)	GS 32.609 (32.609)	mem 39.860
Train: [63][645/750]	BT 0.032 (1.161)	DT 0.001 (1.118)	loss 6.868 (6.868)	prob 2.806 (2.806)	GS 28.969 (28.969)	mem 39.905
Train: [63][650/750]	BT 0.051 (1.170)	DT 0.012 (1.127)	loss 6.803 (6.803)	prob 3.027 (3.027)	GS 33.422 (33.422)	mem 39.737
Train: [63][655/750]	BT 0.030 (1.162)	DT 0.001 (1.118)	loss 7.029 (7.029)	prob 2.540 (2.540)	GS 27.562 (27.562)	mem 39.781
Train: [63][660/750]	BT 12.705 (1.172)	DT 12.675 (1.129)	loss 6.773 (6.773)	prob 3.409 (3.409)	GS 34.828 (34.828)	mem 39.945
Train: [63][665/750]	BT 0.039 (1.164)	DT 0.007 (1.121)	loss 6.875 (6.875)	prob 3.022 (3.022)	GS 32.500 (32.500)	mem 40.025
Train: [63][670/750]	BT 0.039 (1.156)	DT 0.008 (1.113)	loss 6.677 (6.677)	prob 2.901 (2.901)	GS 28.812 (28.812)	mem 39.945
Train: [63][675/750]	BT 0.035 (1.163)	DT 0.004 (1.120)	loss 7.221 (7.221)	prob 2.834 (2.834)	GS 31.078 (31.078)	mem 39.933
Train: [63][680/750]	BT 0.038 (1.156)	DT 0.005 (1.113)	loss 7.121 (7.121)	prob 2.977 (2.977)	GS 33.328 (33.328)	mem 40.009
Train: [63][685/750]	BT 0.056 (1.170)	DT 0.007 (1.127)	loss 6.883 (6.883)	prob 3.491 (3.491)	GS 31.953 (31.953)	mem 39.980
Train: [63][690/750]	BT 0.041 (1.162)	DT 0.010 (1.118)	loss 6.794 (6.794)	prob 3.188 (3.188)	GS 34.844 (34.844)	mem 39.902
Train: [63][695/750]	BT 0.063 (1.154)	DT 0.010 (1.111)	loss 7.013 (7.013)	prob 3.257 (3.257)	GS 30.000 (30.000)	mem 39.935
Train: [63][700/750]	BT 0.056 (1.163)	DT 0.006 (1.120)	loss 6.857 (6.857)	prob 3.197 (3.197)	GS 31.844 (31.844)	mem 40.205
Train: [63][705/750]	BT 0.035 (1.159)	DT 0.002 (1.116)	loss 6.957 (6.957)	prob 3.312 (3.312)	GS 31.406 (31.406)	mem 40.012
Train: [63][710/750]	BT 0.038 (1.161)	DT 0.002 (1.117)	loss 6.850 (6.850)	prob 2.701 (2.701)	GS 35.328 (35.328)	mem 40.031
Train: [63][715/750]	BT 0.098 (1.163)	DT 0.002 (1.120)	loss 6.992 (6.992)	prob 3.373 (3.373)	GS 28.859 (28.859)	mem 40.022
Train: [63][720/750]	BT 8.463 (1.167)	DT 8.425 (1.124)	loss 6.903 (6.903)	prob 3.110 (3.110)	GS 38.391 (38.391)	mem 39.972
Train: [63][725/750]	BT 0.082 (1.159)	DT 0.029 (1.116)	loss 6.851 (6.851)	prob 3.269 (3.269)	GS 25.297 (25.297)	mem 39.979
Train: [63][730/750]	BT 0.027 (1.154)	DT 0.001 (1.111)	loss 7.251 (7.251)	prob 2.695 (2.695)	GS 37.016 (37.016)	mem 39.959
Train: [63][735/750]	BT 0.044 (1.158)	DT 0.009 (1.114)	loss 6.784 (6.784)	prob 3.153 (3.153)	GS 31.750 (31.750)	mem 39.612
Train: [63][740/750]	BT 0.024 (1.152)	DT 0.001 (1.109)	loss 6.754 (6.754)	prob 3.646 (3.646)	GS 31.562 (31.562)	mem 16.714
Train: [63][745/750]	BT 0.036 (1.150)	DT 0.013 (1.107)	loss 7.119 (7.119)	prob 2.351 (2.351)	GS 28.656 (28.656)	mem 7.660
Train: [63][750/750]	BT 0.051 (1.143)	DT 0.011 (1.100)	loss 6.865 (6.865)	prob 2.966 (2.966)	GS 35.875 (35.875)	mem 7.660
Train: [63][755/750]	BT 0.040 (1.136)	DT 0.001 (1.093)	loss 6.939 (6.939)	prob 2.884 (2.884)	GS 32.406 (32.406)	mem 7.661
epoch 63, total time 859.78
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [64][1/750]	BT 23.550 (23.550)	DT 23.509 (23.509)	loss 7.012 (7.012)	prob 3.312 (3.312)	GS 31.484 (31.484)	mem 38.491
Train: [64][5/750]	BT 0.084 (4.791)	DT 0.002 (4.741)	loss 6.748 (6.748)	prob 3.469 (3.469)	GS 34.734 (34.734)	mem 38.502
Train: [64][10/750]	BT 0.055 (3.096)	DT 0.014 (3.047)	loss 6.843 (6.843)	prob 3.102 (3.102)	GS 34.828 (34.828)	mem 38.746
Train: [64][15/750]	BT 0.050 (2.646)	DT 0.007 (2.598)	loss 7.012 (7.012)	prob 2.423 (2.423)	GS 29.359 (29.359)	mem 38.833
Train: [64][20/750]	BT 0.034 (2.432)	DT 0.001 (2.381)	loss 6.800 (6.800)	prob 2.796 (2.796)	GS 31.219 (31.219)	mem 38.974
Train: [64][25/750]	BT 0.026 (1.956)	DT 0.001 (1.906)	loss 6.836 (6.836)	prob 3.609 (3.609)	GS 34.406 (34.406)	mem 38.926
Train: [64][30/750]	BT 0.036 (1.883)	DT 0.001 (1.832)	loss 7.064 (7.064)	prob 2.414 (2.414)	GS 38.016 (38.016)	mem 39.024
Train: [64][35/750]	BT 0.061 (1.685)	DT 0.001 (1.635)	loss 7.041 (7.041)	prob 3.051 (3.051)	GS 37.688 (37.688)	mem 38.976
Train: [64][40/750]	BT 0.044 (1.766)	DT 0.003 (1.715)	loss 6.856 (6.856)	prob 2.953 (2.953)	GS 32.672 (32.672)	mem 38.990
Train: [64][45/750]	BT 0.027 (1.642)	DT 0.001 (1.592)	loss 7.051 (7.051)	prob 2.827 (2.827)	GS 28.578 (28.578)	mem 39.007
Train: [64][50/750]	BT 11.816 (1.720)	DT 11.769 (1.668)	loss 7.031 (7.031)	prob 2.817 (2.817)	GS 35.797 (35.797)	mem 39.037
Train: [64][55/750]	BT 0.052 (1.568)	DT 0.003 (1.517)	loss 6.866 (6.866)	prob 2.813 (2.813)	GS 32.156 (32.156)	mem 39.043
Train: [64][60/750]	BT 0.029 (1.447)	DT 0.001 (1.397)	loss 6.849 (6.849)	prob 2.885 (2.885)	GS 30.797 (30.797)	mem 39.047
Train: [64][65/750]	BT 0.031 (1.490)	DT 0.001 (1.441)	loss 6.828 (6.828)	prob 3.709 (3.709)	GS 35.047 (35.047)	mem 39.095
Train: [64][70/750]	BT 0.035 (1.446)	DT 0.005 (1.398)	loss 6.800 (6.800)	prob 2.740 (2.740)	GS 30.359 (30.359)	mem 39.074
Train: [64][75/750]	BT 0.069 (1.457)	DT 0.004 (1.408)	loss 7.023 (7.023)	prob 2.975 (2.975)	GS 31.719 (31.719)	mem 39.009
Train: [64][80/750]	BT 3.508 (1.418)	DT 3.474 (1.368)	loss 7.036 (7.036)	prob 2.345 (2.345)	GS 29.578 (29.578)	mem 39.020
Train: [64][85/750]	BT 0.031 (1.336)	DT 0.001 (1.288)	loss 7.076 (7.076)	prob 2.410 (2.410)	GS 28.422 (28.422)	mem 39.019
Train: [64][90/750]	BT 4.581 (1.404)	DT 4.538 (1.357)	loss 6.822 (6.822)	prob 3.089 (3.089)	GS 35.000 (35.000)	mem 39.268
Train: [64][95/750]	BT 0.067 (1.342)	DT 0.015 (1.294)	loss 6.983 (6.983)	prob 3.132 (3.132)	GS 32.688 (32.688)	mem 39.099
Train: [64][100/750]	BT 0.032 (1.362)	DT 0.001 (1.315)	loss 6.853 (6.853)	prob 2.223 (2.223)	GS 36.219 (36.219)	mem 39.145
Train: [64][105/750]	BT 0.083 (1.350)	DT 0.002 (1.303)	loss 6.781 (6.781)	prob 2.557 (2.557)	GS 39.453 (39.453)	mem 39.083
Train: [64][110/750]	BT 3.387 (1.321)	DT 3.354 (1.274)	loss 6.900 (6.900)	prob 2.968 (2.968)	GS 34.750 (34.750)	mem 39.221
Train: [64][115/750]	BT 0.023 (1.332)	DT 0.002 (1.285)	loss 6.854 (6.854)	prob 2.922 (2.922)	GS 28.531 (28.531)	mem 39.129
Train: [64][120/750]	BT 0.049 (1.278)	DT 0.012 (1.232)	loss 6.795 (6.795)	prob 2.809 (2.809)	GS 33.969 (33.969)	mem 39.130
Train: [64][125/750]	BT 0.088 (1.256)	DT 0.004 (1.209)	loss 7.209 (7.209)	prob 2.848 (2.848)	GS 26.844 (26.844)	mem 39.147
Train: [64][130/750]	BT 0.025 (1.297)	DT 0.001 (1.250)	loss 7.026 (7.026)	prob 3.003 (3.003)	GS 33.547 (33.547)	mem 39.114
Train: [64][135/750]	BT 0.060 (1.252)	DT 0.004 (1.206)	loss 7.439 (7.439)	prob 2.455 (2.455)	GS 28.312 (28.312)	mem 39.136
Train: [64][140/750]	BT 0.063 (1.321)	DT 0.001 (1.274)	loss 6.828 (6.828)	prob 3.413 (3.413)	GS 37.188 (37.188)	mem 39.127
Train: [64][145/750]	BT 0.036 (1.277)	DT 0.007 (1.231)	loss 6.928 (6.928)	prob 2.901 (2.901)	GS 30.656 (30.656)	mem 39.128
Train: [64][150/750]	BT 13.916 (1.329)	DT 13.885 (1.283)	loss 6.734 (6.734)	prob 2.605 (2.605)	GS 34.688 (34.688)	mem 39.391
Train: [64][155/750]	BT 0.049 (1.288)	DT 0.007 (1.242)	loss 6.945 (6.945)	prob 2.983 (2.983)	GS 31.266 (31.266)	mem 39.391
Train: [64][160/750]	BT 0.046 (1.249)	DT 0.001 (1.203)	loss 7.061 (7.061)	prob 3.242 (3.242)	GS 33.703 (33.703)	mem 39.392
Train: [64][165/750]	BT 0.039 (1.278)	DT 0.001 (1.233)	loss 6.890 (6.890)	prob 2.951 (2.951)	GS 28.797 (28.797)	mem 39.456
Train: [64][170/750]	BT 3.153 (1.260)	DT 3.110 (1.215)	loss 6.958 (6.958)	prob 3.171 (3.171)	GS 38.047 (38.047)	mem 39.461
Train: [64][175/750]	BT 0.022 (1.282)	DT 0.001 (1.238)	loss 6.988 (6.988)	prob 3.665 (3.665)	GS 35.406 (35.406)	mem 39.478
Train: [64][180/750]	BT 0.059 (1.248)	DT 0.001 (1.204)	loss 6.996 (6.996)	prob 2.599 (2.599)	GS 30.703 (30.703)	mem 39.477
Train: [64][185/750]	BT 0.033 (1.234)	DT 0.001 (1.190)	loss 6.996 (6.996)	prob 2.910 (2.910)	GS 30.766 (30.766)	mem 39.529
Train: [64][190/750]	BT 0.063 (1.239)	DT 0.013 (1.194)	loss 6.957 (6.957)	prob 2.534 (2.534)	GS 31.203 (31.203)	mem 39.485
Train: [64][195/750]	BT 0.032 (1.244)	DT 0.001 (1.200)	loss 7.203 (7.203)	prob 2.742 (2.742)	GS 34.812 (34.812)	mem 39.484
Train: [64][200/750]	BT 0.112 (1.240)	DT 0.007 (1.195)	loss 7.066 (7.066)	prob 3.628 (3.628)	GS 35.656 (35.656)	mem 39.548
Train: [64][205/750]	BT 0.035 (1.211)	DT 0.002 (1.166)	loss 6.945 (6.945)	prob 2.688 (2.688)	GS 31.297 (31.297)	mem 39.486
Train: [64][210/750]	BT 3.077 (1.234)	DT 3.047 (1.189)	loss 6.837 (6.837)	prob 3.573 (3.573)	GS 36.203 (36.203)	mem 39.577
Train: [64][215/750]	BT 0.041 (1.214)	DT 0.001 (1.169)	loss 6.976 (6.976)	prob 2.921 (2.921)	GS 30.953 (30.953)	mem 39.637
Train: [64][220/750]	BT 0.027 (1.225)	DT 0.001 (1.180)	loss 6.788 (6.788)	prob 3.341 (3.341)	GS 32.719 (32.719)	mem 39.766
Train: [64][225/750]	BT 0.033 (1.225)	DT 0.002 (1.180)	loss 7.051 (7.051)	prob 2.716 (2.716)	GS 31.844 (31.844)	mem 39.739
Train: [64][230/750]	BT 8.638 (1.237)	DT 8.597 (1.192)	loss 6.918 (6.918)	prob 3.132 (3.132)	GS 34.719 (34.719)	mem 39.759
Train: [64][235/750]	BT 0.112 (1.229)	DT 0.012 (1.184)	loss 6.867 (6.867)	prob 2.720 (2.720)	GS 31.375 (31.375)	mem 40.288
Train: [64][240/750]	BT 0.067 (1.204)	DT 0.011 (1.159)	loss 6.674 (6.674)	prob 3.597 (3.597)	GS 31.547 (31.547)	mem 39.873
Train: [64][245/750]	BT 0.067 (1.222)	DT 0.010 (1.177)	loss 6.986 (6.986)	prob 3.279 (3.279)	GS 31.656 (31.656)	mem 39.831
Train: [64][250/750]	BT 0.031 (1.206)	DT 0.001 (1.161)	loss 6.886 (6.886)	prob 2.917 (2.917)	GS 30.859 (30.859)	mem 39.778
Train: [64][255/750]	BT 0.022 (1.227)	DT 0.001 (1.183)	loss 7.054 (7.054)	prob 2.736 (2.736)	GS 29.656 (29.656)	mem 39.855
Train: [64][260/750]	BT 0.034 (1.208)	DT 0.003 (1.163)	loss 7.069 (7.069)	prob 2.985 (2.985)	GS 31.641 (31.641)	mem 39.814
Train: [64][265/750]	BT 0.044 (1.186)	DT 0.001 (1.141)	loss 6.911 (6.911)	prob 3.214 (3.214)	GS 40.359 (40.359)	mem 39.813
Train: [64][270/750]	BT 3.616 (1.215)	DT 3.576 (1.171)	loss 6.947 (6.947)	prob 3.868 (3.868)	GS 35.094 (35.094)	mem 39.843
Train: [64][275/750]	BT 0.042 (1.193)	DT 0.001 (1.149)	loss 6.976 (6.976)	prob 2.830 (2.830)	GS 32.516 (32.516)	mem 39.860
Train: [64][280/750]	BT 0.156 (1.216)	DT 0.009 (1.171)	loss 6.939 (6.939)	prob 3.448 (3.448)	GS 36.188 (36.188)	mem 39.937
Train: [64][285/750]	BT 0.037 (1.209)	DT 0.001 (1.165)	loss 7.019 (7.019)	prob 3.098 (3.098)	GS 34.484 (34.484)	mem 39.853
Train: [64][290/750]	BT 8.694 (1.220)	DT 8.662 (1.175)	loss 7.029 (7.029)	prob 2.479 (2.479)	GS 38.062 (38.062)	mem 39.856
Train: [64][295/750]	BT 0.045 (1.206)	DT 0.008 (1.161)	loss 7.104 (7.104)	prob 2.443 (2.443)	GS 26.375 (26.375)	mem 39.858
Train: [64][300/750]	BT 0.024 (1.187)	DT 0.001 (1.142)	loss 7.050 (7.050)	prob 3.125 (3.125)	GS 33.781 (33.781)	mem 39.861
Train: [64][305/750]	BT 0.046 (1.197)	DT 0.010 (1.152)	loss 6.992 (6.992)	prob 2.866 (2.866)	GS 31.203 (31.203)	mem 39.876
Train: [64][310/750]	BT 0.030 (1.193)	DT 0.001 (1.148)	loss 7.012 (7.012)	prob 2.299 (2.299)	GS 37.672 (37.672)	mem 39.954
Train: [64][315/750]	BT 0.038 (1.203)	DT 0.004 (1.158)	loss 7.031 (7.031)	prob 3.288 (3.288)	GS 31.203 (31.203)	mem 39.941
Train: [64][320/750]	BT 0.030 (1.200)	DT 0.001 (1.155)	loss 6.845 (6.845)	prob 3.608 (3.608)	GS 29.391 (29.391)	mem 39.875
Train: [64][325/750]	BT 0.041 (1.182)	DT 0.007 (1.138)	loss 7.177 (7.177)	prob 2.411 (2.411)	GS 28.906 (28.906)	mem 39.850
Train: [64][330/750]	BT 7.797 (1.202)	DT 7.762 (1.157)	loss 6.947 (6.947)	prob 2.686 (2.686)	GS 30.219 (30.219)	mem 39.933
Train: [64][335/750]	BT 0.032 (1.184)	DT 0.001 (1.140)	loss 6.854 (6.854)	prob 3.063 (3.063)	GS 32.875 (32.875)	mem 39.995
Train: [64][340/750]	BT 0.025 (1.179)	DT 0.001 (1.134)	loss 7.050 (7.050)	prob 2.498 (2.498)	GS 32.547 (32.547)	mem 39.942
Train: [64][345/750]	BT 0.083 (1.190)	DT 0.029 (1.145)	loss 7.221 (7.221)	prob 2.539 (2.539)	GS 28.484 (28.484)	mem 39.926
Train: [64][350/750]	BT 0.077 (1.175)	DT 0.013 (1.129)	loss 7.015 (7.015)	prob 3.060 (3.060)	GS 28.703 (28.703)	mem 39.953
Train: [64][355/750]	BT 0.046 (1.197)	DT 0.001 (1.151)	loss 6.949 (6.949)	prob 3.461 (3.461)	GS 30.859 (30.859)	mem 39.920
Train: [64][360/750]	BT 0.028 (1.180)	DT 0.001 (1.135)	loss 6.845 (6.845)	prob 2.346 (2.346)	GS 32.953 (32.953)	mem 39.921
Train: [64][365/750]	BT 0.037 (1.165)	DT 0.002 (1.119)	loss 6.906 (6.906)	prob 3.457 (3.457)	GS 44.547 (44.547)	mem 39.927
Train: [64][370/750]	BT 0.048 (1.179)	DT 0.003 (1.134)	loss 6.812 (6.812)	prob 3.010 (3.010)	GS 33.109 (33.109)	mem 40.200
Train: [64][375/750]	BT 0.071 (1.172)	DT 0.026 (1.127)	loss 7.120 (7.120)	prob 2.423 (2.423)	GS 31.391 (31.391)	mem 39.952
Train: [64][380/750]	BT 0.075 (1.175)	DT 0.023 (1.130)	loss 7.023 (7.023)	prob 2.930 (2.930)	GS 32.484 (32.484)	mem 39.866
Train: [64][385/750]	BT 0.033 (1.160)	DT 0.001 (1.115)	loss 6.893 (6.893)	prob 2.593 (2.593)	GS 27.125 (27.125)	mem 39.936
Train: [64][390/750]	BT 2.563 (1.179)	DT 2.530 (1.134)	loss 7.045 (7.045)	prob 2.219 (2.219)	GS 34.438 (34.438)	mem 39.929
Train: [64][395/750]	BT 0.024 (1.165)	DT 0.001 (1.120)	loss 7.062 (7.062)	prob 2.674 (2.674)	GS 34.391 (34.391)	mem 39.861
Train: [64][400/750]	BT 0.038 (1.176)	DT 0.002 (1.132)	loss 6.900 (6.900)	prob 2.899 (2.899)	GS 31.578 (31.578)	mem 39.975
Train: [64][405/750]	BT 0.034 (1.167)	DT 0.004 (1.122)	loss 6.874 (6.874)	prob 2.654 (2.654)	GS 29.297 (29.297)	mem 39.846
Train: [64][410/750]	BT 10.660 (1.179)	DT 10.609 (1.134)	loss 7.166 (7.166)	prob 2.214 (2.214)	GS 32.781 (32.781)	mem 39.814
Train: [64][415/750]	BT 0.029 (1.180)	DT 0.001 (1.135)	loss 7.015 (7.015)	prob 3.403 (3.403)	GS 32.594 (32.594)	mem 39.875
Train: [64][420/750]	BT 0.061 (1.167)	DT 0.010 (1.122)	loss 7.172 (7.172)	prob 2.315 (2.315)	GS 38.156 (38.156)	mem 39.960
Train: [64][425/750]	BT 0.062 (1.163)	DT 0.002 (1.117)	loss 7.088 (7.088)	prob 2.901 (2.901)	GS 33.641 (33.641)	mem 39.936
Train: [64][430/750]	BT 0.025 (1.174)	DT 0.001 (1.129)	loss 6.925 (6.925)	prob 2.528 (2.528)	GS 35.250 (35.250)	mem 39.851
Train: [64][435/750]	BT 0.049 (1.165)	DT 0.004 (1.120)	loss 7.221 (7.221)	prob 2.558 (2.558)	GS 36.203 (36.203)	mem 39.874
Train: [64][440/750]	BT 0.050 (1.181)	DT 0.001 (1.135)	loss 6.942 (6.942)	prob 1.824 (1.824)	GS 32.297 (32.297)	mem 39.927
Train: [64][445/750]	BT 0.056 (1.168)	DT 0.002 (1.123)	loss 6.974 (6.974)	prob 3.012 (3.012)	GS 29.672 (29.672)	mem 39.928
Train: [64][450/750]	BT 12.980 (1.186)	DT 12.953 (1.141)	loss 6.718 (6.718)	prob 2.880 (2.880)	GS 34.469 (34.469)	mem 39.939
Train: [64][455/750]	BT 0.024 (1.173)	DT 0.001 (1.128)	loss 6.919 (6.919)	prob 3.284 (3.284)	GS 28.172 (28.172)	mem 39.965
Train: [64][460/750]	BT 0.032 (1.164)	DT 0.001 (1.120)	loss 6.916 (6.916)	prob 2.960 (2.960)	GS 33.922 (33.922)	mem 39.891
Train: [64][465/750]	BT 0.063 (1.183)	DT 0.012 (1.139)	loss 7.185 (7.185)	prob 2.440 (2.440)	GS 38.938 (38.938)	mem 39.899
Train: [64][470/750]	BT 0.051 (1.171)	DT 0.011 (1.127)	loss 6.897 (6.897)	prob 2.968 (2.968)	GS 34.062 (34.062)	mem 39.900
Train: [64][475/750]	BT 0.032 (1.184)	DT 0.001 (1.140)	loss 6.974 (6.974)	prob 2.112 (2.112)	GS 33.297 (33.297)	mem 39.972
Train: [64][480/750]	BT 0.089 (1.172)	DT 0.003 (1.128)	loss 6.787 (6.787)	prob 2.850 (2.850)	GS 29.500 (29.500)	mem 40.054
Train: [64][485/750]	BT 0.035 (1.161)	DT 0.002 (1.116)	loss 6.932 (6.932)	prob 3.093 (3.093)	GS 32.875 (32.875)	mem 39.989
Train: [64][490/750]	BT 0.061 (1.175)	DT 0.011 (1.131)	loss 7.044 (7.044)	prob 2.554 (2.554)	GS 34.141 (34.141)	mem 39.987
Train: [64][495/750]	BT 0.048 (1.163)	DT 0.001 (1.119)	loss 6.898 (6.898)	prob 3.116 (3.116)	GS 29.688 (29.688)	mem 39.925
Train: [64][500/750]	BT 0.032 (1.179)	DT 0.001 (1.135)	loss 7.114 (7.114)	prob 2.451 (2.451)	GS 34.359 (34.359)	mem 39.876
Train: [64][505/750]	BT 0.036 (1.167)	DT 0.001 (1.123)	loss 6.988 (6.988)	prob 2.433 (2.433)	GS 35.094 (35.094)	mem 39.880
Train: [64][510/750]	BT 13.029 (1.182)	DT 13.000 (1.138)	loss 6.975 (6.975)	prob 2.764 (2.764)	GS 34.922 (34.922)	mem 40.298
Train: [64][515/750]	BT 0.031 (1.171)	DT 0.001 (1.127)	loss 7.030 (7.030)	prob 2.440 (2.440)	GS 27.188 (27.188)	mem 39.976
Train: [64][520/750]	BT 0.050 (1.160)	DT 0.011 (1.116)	loss 7.116 (7.116)	prob 2.659 (2.659)	GS 30.172 (30.172)	mem 39.975
Train: [64][525/750]	BT 0.042 (1.170)	DT 0.004 (1.126)	loss 6.813 (6.813)	prob 2.886 (2.886)	GS 31.500 (31.500)	mem 40.014
Train: [64][530/750]	BT 0.442 (1.160)	DT 0.356 (1.116)	loss 6.862 (6.862)	prob 2.422 (2.422)	GS 29.250 (29.250)	mem 40.017
Train: [64][535/750]	BT 0.046 (1.176)	DT 0.015 (1.132)	loss 6.954 (6.954)	prob 2.781 (2.781)	GS 31.078 (31.078)	mem 40.034
Train: [64][540/750]	BT 0.030 (1.165)	DT 0.001 (1.122)	loss 6.971 (6.971)	prob 2.796 (2.796)	GS 33.078 (33.078)	mem 40.035
Train: [64][545/750]	BT 0.035 (1.155)	DT 0.001 (1.111)	loss 6.768 (6.768)	prob 3.200 (3.200)	GS 31.297 (31.297)	mem 40.035
Train: [64][550/750]	BT 0.046 (1.161)	DT 0.001 (1.117)	loss 6.798 (6.798)	prob 3.006 (3.006)	GS 34.078 (34.078)	mem 39.998
Train: [64][555/750]	BT 0.069 (1.151)	DT 0.012 (1.107)	loss 6.893 (6.893)	prob 2.752 (2.752)	GS 29.188 (29.188)	mem 39.997
Train: [64][560/750]	BT 0.049 (1.162)	DT 0.001 (1.118)	loss 6.982 (6.982)	prob 2.314 (2.314)	GS 35.844 (35.844)	mem 40.059
Train: [64][565/750]	BT 0.027 (1.152)	DT 0.001 (1.108)	loss 7.250 (7.250)	prob 2.287 (2.287)	GS 32.938 (32.938)	mem 40.031
Train: [64][570/750]	BT 11.100 (1.162)	DT 11.068 (1.118)	loss 6.881 (6.881)	prob 2.542 (2.542)	GS 35.172 (35.172)	mem 39.966
Train: [64][575/750]	BT 0.036 (1.152)	DT 0.007 (1.108)	loss 6.820 (6.820)	prob 3.139 (3.139)	GS 33.047 (33.047)	mem 40.052
Train: [64][580/750]	BT 0.080 (1.154)	DT 0.012 (1.111)	loss 6.904 (6.904)	prob 2.950 (2.950)	GS 36.109 (36.109)	mem 40.049
Train: [64][585/750]	BT 0.035 (1.154)	DT 0.001 (1.110)	loss 7.279 (7.279)	prob 2.173 (2.173)	GS 32.234 (32.234)	mem 39.884
Train: [64][590/750]	BT 7.794 (1.158)	DT 7.762 (1.114)	loss 6.977 (6.977)	prob 2.474 (2.474)	GS 32.906 (32.906)	mem 39.917
Train: [64][595/750]	BT 0.069 (1.149)	DT 0.008 (1.105)	loss 6.944 (6.944)	prob 2.158 (2.158)	GS 29.578 (29.578)	mem 40.139
Train: [64][600/750]	BT 0.028 (1.146)	DT 0.001 (1.102)	loss 6.743 (6.743)	prob 2.340 (2.340)	GS 30.125 (30.125)	mem 40.035
Train: [64][605/750]	BT 0.037 (1.161)	DT 0.002 (1.117)	loss 7.102 (7.102)	prob 2.382 (2.382)	GS 30.203 (30.203)	mem 40.081
Train: [64][610/750]	BT 0.049 (1.152)	DT 0.004 (1.108)	loss 6.797 (6.797)	prob 2.288 (2.288)	GS 34.641 (34.641)	mem 40.172
Train: [64][615/750]	BT 0.061 (1.166)	DT 0.001 (1.122)	loss 7.031 (7.031)	prob 2.347 (2.347)	GS 31.797 (31.797)	mem 40.038
Train: [64][620/750]	BT 0.030 (1.156)	DT 0.001 (1.113)	loss 7.083 (7.083)	prob 2.392 (2.392)	GS 35.875 (35.875)	mem 39.988
Train: [64][625/750]	BT 0.050 (1.148)	DT 0.003 (1.104)	loss 7.070 (7.070)	prob 2.706 (2.706)	GS 33.953 (33.953)	mem 39.988
Train: [64][630/750]	BT 0.054 (1.158)	DT 0.009 (1.114)	loss 6.750 (6.750)	prob 2.542 (2.542)	GS 35.109 (35.109)	mem 40.123
Train: [64][635/750]	BT 0.058 (1.149)	DT 0.005 (1.105)	loss 7.020 (7.020)	prob 2.537 (2.537)	GS 30.172 (30.172)	mem 40.013
Train: [64][640/750]	BT 0.021 (1.158)	DT 0.001 (1.114)	loss 6.878 (6.878)	prob 2.715 (2.715)	GS 37.219 (37.219)	mem 39.991
Train: [64][645/750]	BT 0.066 (1.149)	DT 0.005 (1.105)	loss 6.942 (6.942)	prob 2.032 (2.032)	GS 30.859 (30.859)	mem 40.003
Train: [64][650/750]	BT 11.533 (1.158)	DT 11.503 (1.114)	loss 6.808 (6.808)	prob 1.891 (1.891)	GS 29.531 (29.531)	mem 40.007
Train: [64][655/750]	BT 0.022 (1.150)	DT 0.001 (1.106)	loss 7.543 (7.543)	prob 1.920 (1.920)	GS 25.797 (25.797)	mem 40.007
Train: [64][660/750]	BT 0.048 (1.141)	DT 0.001 (1.098)	loss 6.750 (6.750)	prob 2.896 (2.896)	GS 32.875 (32.875)	mem 40.055
Train: [64][665/750]	BT 0.077 (1.153)	DT 0.019 (1.109)	loss 6.896 (6.896)	prob 2.391 (2.391)	GS 29.141 (29.141)	mem 39.886
Train: [64][670/750]	BT 0.032 (1.145)	DT 0.001 (1.101)	loss 6.709 (6.709)	prob 2.876 (2.876)	GS 32.594 (32.594)	mem 39.886
Train: [64][675/750]	BT 0.069 (1.156)	DT 0.001 (1.112)	loss 6.855 (6.855)	prob 2.959 (2.959)	GS 32.891 (32.891)	mem 39.945
Train: [64][680/750]	BT 0.037 (1.147)	DT 0.008 (1.104)	loss 6.845 (6.845)	prob 2.712 (2.712)	GS 32.703 (32.703)	mem 39.953
Train: [64][685/750]	BT 0.103 (1.139)	DT 0.022 (1.096)	loss 7.067 (7.067)	prob 2.647 (2.647)	GS 32.359 (32.359)	mem 40.114
Train: [64][690/750]	BT 0.026 (1.148)	DT 0.001 (1.104)	loss 7.165 (7.165)	prob 2.193 (2.193)	GS 33.812 (33.812)	mem 39.954
Train: [64][695/750]	BT 0.030 (1.140)	DT 0.001 (1.096)	loss 6.770 (6.770)	prob 2.798 (2.798)	GS 31.219 (31.219)	mem 39.953
Train: [64][700/750]	BT 0.031 (1.150)	DT 0.001 (1.106)	loss 7.011 (7.011)	prob 2.332 (2.332)	GS 33.406 (33.406)	mem 39.948
Train: [64][705/750]	BT 0.030 (1.142)	DT 0.001 (1.098)	loss 7.040 (7.040)	prob 1.912 (1.912)	GS 27.531 (27.531)	mem 40.092
Train: [64][710/750]	BT 13.844 (1.154)	DT 13.795 (1.110)	loss 7.280 (7.280)	prob 2.474 (2.474)	GS 34.844 (34.844)	mem 39.932
Train: [64][715/750]	BT 0.070 (1.146)	DT 0.017 (1.102)	loss 6.960 (6.960)	prob 1.840 (1.840)	GS 27.938 (27.938)	mem 39.933
Train: [64][720/750]	BT 0.044 (1.138)	DT 0.002 (1.095)	loss 6.890 (6.890)	prob 2.373 (2.373)	GS 36.922 (36.922)	mem 39.935
Train: [64][725/750]	BT 0.035 (1.148)	DT 0.001 (1.105)	loss 6.987 (6.987)	prob 2.360 (2.360)	GS 28.266 (28.266)	mem 39.791
Train: [64][730/750]	BT 0.064 (1.141)	DT 0.016 (1.097)	loss 6.761 (6.761)	prob 2.343 (2.343)	GS 33.609 (33.609)	mem 39.743
Train: [64][735/750]	BT 0.032 (1.144)	DT 0.001 (1.101)	loss 6.881 (6.881)	prob 2.436 (2.436)	GS 29.156 (29.156)	mem 36.376
Train: [64][740/750]	BT 0.029 (1.137)	DT 0.005 (1.093)	loss 6.986 (6.986)	prob 2.915 (2.915)	GS 37.297 (37.297)	mem 36.377
Train: [64][745/750]	BT 0.019 (1.129)	DT 0.001 (1.086)	loss 7.024 (7.024)	prob 2.441 (2.441)	GS 31.938 (31.938)	mem 36.378
Train: [64][750/750]	BT 0.030 (1.124)	DT 0.001 (1.081)	loss 6.871 (6.871)	prob 2.707 (2.707)	GS 42.375 (42.375)	mem 7.568
Train: [64][755/750]	BT 0.043 (1.117)	DT 0.001 (1.074)	loss 7.149 (7.149)	prob 2.233 (2.233)	GS 30.438 (30.438)	mem 7.569
epoch 64, total time 843.70
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [65][1/750]	BT 23.257 (23.257)	DT 23.196 (23.196)	loss 6.822 (6.822)	prob 2.663 (2.663)	GS 32.406 (32.406)	mem 38.634
Train: [65][5/750]	BT 0.043 (4.789)	DT 0.004 (4.738)	loss 6.937 (6.937)	prob 2.404 (2.404)	GS 29.828 (29.828)	mem 38.691
Train: [65][10/750]	BT 0.083 (2.431)	DT 0.007 (2.372)	loss 7.086 (7.086)	prob 2.434 (2.434)	GS 32.109 (32.109)	mem 38.644
Train: [65][15/750]	BT 0.050 (2.584)	DT 0.001 (2.530)	loss 7.001 (7.001)	prob 2.556 (2.556)	GS 29.391 (29.391)	mem 38.913
Train: [65][20/750]	BT 0.086 (1.949)	DT 0.002 (1.898)	loss 6.711 (6.711)	prob 2.224 (2.224)	GS 35.188 (35.188)	mem 38.828
Train: [65][25/750]	BT 3.589 (1.763)	DT 3.548 (1.715)	loss 6.739 (6.739)	prob 2.474 (2.474)	GS 30.125 (30.125)	mem 38.927
Train: [65][30/750]	BT 0.032 (1.773)	DT 0.001 (1.726)	loss 6.987 (6.987)	prob 2.172 (2.172)	GS 28.266 (28.266)	mem 38.871
Train: [65][35/750]	BT 0.045 (1.616)	DT 0.014 (1.571)	loss 7.179 (7.179)	prob 2.233 (2.233)	GS 30.938 (30.938)	mem 38.895
Train: [65][40/750]	BT 0.032 (1.671)	DT 0.001 (1.627)	loss 6.763 (6.763)	prob 2.835 (2.835)	GS 35.953 (35.953)	mem 38.944
Train: [65][45/750]	BT 0.067 (1.491)	DT 0.017 (1.447)	loss 7.069 (7.069)	prob 2.228 (2.228)	GS 32.453 (32.453)	mem 38.944
Train: [65][50/750]	BT 14.563 (1.653)	DT 14.523 (1.609)	loss 7.080 (7.080)	prob 1.938 (1.938)	GS 34.594 (34.594)	mem 39.006
Train: [65][55/750]	BT 0.032 (1.506)	DT 0.001 (1.463)	loss 6.925 (6.925)	prob 2.480 (2.480)	GS 35.438 (35.438)	mem 39.032
Train: [65][60/750]	BT 0.077 (1.385)	DT 0.006 (1.342)	loss 6.830 (6.830)	prob 2.280 (2.280)	GS 33.031 (33.031)	mem 39.132
Train: [65][65/750]	BT 0.043 (1.472)	DT 0.002 (1.429)	loss 7.020 (7.020)	prob 2.300 (2.300)	GS 31.938 (31.938)	mem 39.055
Train: [65][70/750]	BT 0.029 (1.372)	DT 0.003 (1.328)	loss 6.806 (6.806)	prob 1.879 (1.879)	GS 33.203 (33.203)	mem 39.056
Train: [65][75/750]	BT 0.056 (1.482)	DT 0.013 (1.439)	loss 7.011 (7.011)	prob 2.241 (2.241)	GS 32.766 (32.766)	mem 39.064
Train: [65][80/750]	BT 0.041 (1.392)	DT 0.007 (1.349)	loss 7.015 (7.015)	prob 2.329 (2.329)	GS 35.250 (35.250)	mem 39.064
Train: [65][85/750]	BT 0.042 (1.313)	DT 0.001 (1.270)	loss 6.954 (6.954)	prob 2.029 (2.029)	GS 32.953 (32.953)	mem 39.067
Train: [65][90/750]	BT 0.034 (1.366)	DT 0.001 (1.322)	loss 7.011 (7.011)	prob 2.476 (2.476)	GS 35.328 (35.328)	mem 39.150
Train: [65][95/750]	BT 0.027 (1.297)	DT 0.001 (1.253)	loss 6.745 (6.745)	prob 2.484 (2.484)	GS 28.906 (28.906)	mem 39.150
Train: [65][100/750]	BT 0.031 (1.386)	DT 0.003 (1.341)	loss 6.779 (6.779)	prob 2.516 (2.516)	GS 30.141 (30.141)	mem 39.125
Train: [65][105/750]	BT 0.033 (1.321)	DT 0.001 (1.278)	loss 7.014 (7.014)	prob 2.423 (2.423)	GS 34.141 (34.141)	mem 39.173
Train: [65][110/750]	BT 14.516 (1.395)	DT 14.483 (1.351)	loss 6.921 (6.921)	prob 2.707 (2.707)	GS 38.312 (38.312)	mem 39.348
Train: [65][115/750]	BT 0.030 (1.336)	DT 0.001 (1.293)	loss 6.980 (6.980)	prob 2.062 (2.062)	GS 36.281 (36.281)	mem 39.348
Train: [65][120/750]	BT 0.032 (1.282)	DT 0.001 (1.239)	loss 6.905 (6.905)	prob 1.797 (1.797)	GS 36.234 (36.234)	mem 39.349
Train: [65][125/750]	BT 0.035 (1.329)	DT 0.001 (1.286)	loss 7.034 (7.034)	prob 1.987 (1.987)	GS 33.391 (33.391)	mem 39.366
Train: [65][130/750]	BT 0.038 (1.279)	DT 0.005 (1.237)	loss 6.889 (6.889)	prob 2.626 (2.626)	GS 37.234 (37.234)	mem 39.365
Train: [65][135/750]	BT 0.044 (1.325)	DT 0.005 (1.282)	loss 6.778 (6.778)	prob 2.354 (2.354)	GS 28.859 (28.859)	mem 39.413
Train: [65][140/750]	BT 0.034 (1.279)	DT 0.001 (1.236)	loss 6.979 (6.979)	prob 2.109 (2.109)	GS 31.688 (31.688)	mem 39.420
Train: [65][145/750]	BT 0.031 (1.236)	DT 0.001 (1.194)	loss 7.070 (7.070)	prob 2.506 (2.506)	GS 29.719 (29.719)	mem 39.418
Train: [65][150/750]	BT 0.035 (1.299)	DT 0.001 (1.257)	loss 6.919 (6.919)	prob 2.465 (2.465)	GS 31.906 (31.906)	mem 39.470
Train: [65][155/750]	BT 0.082 (1.258)	DT 0.016 (1.216)	loss 6.985 (6.985)	prob 2.280 (2.280)	GS 33.141 (33.141)	mem 39.470
Train: [65][160/750]	BT 0.102 (1.290)	DT 0.004 (1.247)	loss 6.973 (6.973)	prob 2.296 (2.296)	GS 27.688 (27.688)	mem 39.635
Train: [65][165/750]	BT 0.052 (1.253)	DT 0.005 (1.209)	loss 6.889 (6.889)	prob 2.258 (2.258)	GS 32.500 (32.500)	mem 39.684
Train: [65][170/750]	BT 13.065 (1.295)	DT 13.038 (1.251)	loss 6.776 (6.776)	prob 2.652 (2.652)	GS 31.125 (31.125)	mem 39.663
Train: [65][175/750]	BT 0.031 (1.266)	DT 0.001 (1.223)	loss 7.229 (7.229)	prob 2.237 (2.237)	GS 46.531 (46.531)	mem 39.660
Train: [65][180/750]	BT 0.023 (1.232)	DT 0.001 (1.189)	loss 6.953 (6.953)	prob 2.992 (2.992)	GS 33.922 (33.922)	mem 39.662
Train: [65][185/750]	BT 0.059 (1.264)	DT 0.002 (1.221)	loss 7.257 (7.257)	prob 1.209 (1.209)	GS 30.734 (30.734)	mem 39.800
Train: [65][190/750]	BT 0.028 (1.232)	DT 0.001 (1.189)	loss 6.863 (6.863)	prob 2.715 (2.715)	GS 34.656 (34.656)	mem 39.760
Train: [65][195/750]	BT 0.036 (1.281)	DT 0.005 (1.238)	loss 6.753 (6.753)	prob 3.191 (3.191)	GS 33.094 (33.094)	mem 39.729
Train: [65][200/750]	BT 0.025 (1.250)	DT 0.001 (1.207)	loss 7.082 (7.082)	prob 2.753 (2.753)	GS 35.125 (35.125)	mem 39.794
Train: [65][205/750]	BT 0.058 (1.221)	DT 0.001 (1.178)	loss 7.014 (7.014)	prob 3.068 (3.068)	GS 32.594 (32.594)	mem 39.851
Train: [65][210/750]	BT 0.066 (1.246)	DT 0.010 (1.203)	loss 6.832 (6.832)	prob 2.830 (2.830)	GS 37.078 (37.078)	mem 39.737
Train: [65][215/750]	BT 0.058 (1.218)	DT 0.012 (1.175)	loss 7.008 (7.008)	prob 2.058 (2.058)	GS 36.109 (36.109)	mem 39.737
Train: [65][220/750]	BT 0.033 (1.257)	DT 0.001 (1.215)	loss 6.798 (6.798)	prob 2.570 (2.570)	GS 32.016 (32.016)	mem 39.780
Train: [65][225/750]	BT 0.058 (1.230)	DT 0.002 (1.188)	loss 7.011 (7.011)	prob 1.661 (1.661)	GS 30.578 (30.578)	mem 39.937
Train: [65][230/750]	BT 13.387 (1.263)	DT 13.293 (1.220)	loss 6.809 (6.809)	prob 2.574 (2.574)	GS 33.547 (33.547)	mem 39.873
Train: [65][235/750]	BT 0.033 (1.237)	DT 0.004 (1.194)	loss 6.877 (6.877)	prob 2.808 (2.808)	GS 28.875 (28.875)	mem 39.824
Train: [65][240/750]	BT 0.106 (1.212)	DT 0.047 (1.169)	loss 6.793 (6.793)	prob 3.090 (3.090)	GS 33.953 (33.953)	mem 39.826
Train: [65][245/750]	BT 0.030 (1.243)	DT 0.001 (1.200)	loss 6.768 (6.768)	prob 3.075 (3.075)	GS 32.734 (32.734)	mem 39.864
Train: [65][250/750]	BT 0.028 (1.218)	DT 0.001 (1.176)	loss 6.666 (6.666)	prob 3.021 (3.021)	GS 33.469 (33.469)	mem 39.864
Train: [65][255/750]	BT 0.054 (1.238)	DT 0.002 (1.196)	loss 7.120 (7.120)	prob 2.265 (2.265)	GS 31.188 (31.188)	mem 39.893
Train: [65][260/750]	BT 0.028 (1.215)	DT 0.001 (1.173)	loss 6.824 (6.824)	prob 2.728 (2.728)	GS 32.156 (32.156)	mem 39.931
Train: [65][265/750]	BT 0.033 (1.193)	DT 0.002 (1.151)	loss 6.844 (6.844)	prob 2.579 (2.579)	GS 32.969 (32.969)	mem 40.000
Train: [65][270/750]	BT 0.031 (1.220)	DT 0.001 (1.178)	loss 7.211 (7.211)	prob 1.899 (1.899)	GS 35.750 (35.750)	mem 39.849
Train: [65][275/750]	BT 0.046 (1.199)	DT 0.003 (1.157)	loss 7.136 (7.136)	prob 2.426 (2.426)	GS 36.234 (36.234)	mem 39.857
Train: [65][280/750]	BT 0.099 (1.222)	DT 0.021 (1.180)	loss 6.987 (6.987)	prob 1.867 (1.867)	GS 33.125 (33.125)	mem 40.016
Train: [65][285/750]	BT 0.042 (1.202)	DT 0.012 (1.159)	loss 7.031 (7.031)	prob 2.544 (2.544)	GS 33.109 (33.109)	mem 39.944
Train: [65][290/750]	BT 11.654 (1.222)	DT 11.621 (1.179)	loss 7.019 (7.019)	prob 2.739 (2.739)	GS 33.219 (33.219)	mem 39.908
Train: [65][295/750]	BT 0.033 (1.202)	DT 0.001 (1.159)	loss 6.837 (6.837)	prob 2.315 (2.315)	GS 35.906 (35.906)	mem 39.907
Train: [65][300/750]	BT 0.096 (1.183)	DT 0.032 (1.140)	loss 6.821 (6.821)	prob 2.770 (2.770)	GS 33.922 (33.922)	mem 39.907
Train: [65][305/750]	BT 0.032 (1.209)	DT 0.002 (1.167)	loss 6.868 (6.868)	prob 2.099 (2.099)	GS 27.875 (27.875)	mem 39.946
Train: [65][310/750]	BT 0.097 (1.191)	DT 0.003 (1.148)	loss 6.835 (6.835)	prob 3.018 (3.018)	GS 32.734 (32.734)	mem 39.946
Train: [65][315/750]	BT 0.024 (1.205)	DT 0.001 (1.163)	loss 6.972 (6.972)	prob 2.053 (2.053)	GS 27.016 (27.016)	mem 39.926
Train: [65][320/750]	BT 0.087 (1.187)	DT 0.001 (1.145)	loss 6.844 (6.844)	prob 2.605 (2.605)	GS 32.031 (32.031)	mem 40.027
Train: [65][325/750]	BT 0.040 (1.170)	DT 0.001 (1.127)	loss 7.045 (7.045)	prob 2.504 (2.504)	GS 30.109 (30.109)	mem 39.933
Train: [65][330/750]	BT 0.031 (1.195)	DT 0.001 (1.153)	loss 7.058 (7.058)	prob 2.048 (2.048)	GS 33.125 (33.125)	mem 39.867
Train: [65][335/750]	BT 0.035 (1.178)	DT 0.001 (1.135)	loss 7.180 (7.180)	prob 2.412 (2.412)	GS 31.000 (31.000)	mem 39.865
Train: [65][340/750]	BT 0.032 (1.193)	DT 0.001 (1.150)	loss 7.055 (7.055)	prob 2.196 (2.196)	GS 30.156 (30.156)	mem 39.917
Train: [65][345/750]	BT 0.031 (1.176)	DT 0.001 (1.134)	loss 6.697 (6.697)	prob 1.981 (1.981)	GS 33.453 (33.453)	mem 39.933
Train: [65][350/750]	BT 13.161 (1.197)	DT 13.048 (1.155)	loss 6.822 (6.822)	prob 3.219 (3.219)	GS 32.078 (32.078)	mem 40.355
Train: [65][355/750]	BT 0.027 (1.181)	DT 0.002 (1.139)	loss 6.678 (6.678)	prob 2.764 (2.764)	GS 31.438 (31.438)	mem 40.271
Train: [65][360/750]	BT 0.050 (1.165)	DT 0.003 (1.123)	loss 7.001 (7.001)	prob 2.286 (2.286)	GS 36.297 (36.297)	mem 39.922
Train: [65][365/750]	BT 0.028 (1.191)	DT 0.001 (1.149)	loss 6.583 (6.583)	prob 2.668 (2.668)	GS 28.188 (28.188)	mem 39.995
Train: [65][370/750]	BT 0.042 (1.176)	DT 0.002 (1.133)	loss 6.901 (6.901)	prob 2.712 (2.712)	GS 36.172 (36.172)	mem 39.995
Train: [65][375/750]	BT 0.032 (1.194)	DT 0.002 (1.152)	loss 6.777 (6.777)	prob 2.799 (2.799)	GS 28.562 (28.562)	mem 40.018
Train: [65][380/750]	BT 0.039 (1.179)	DT 0.009 (1.137)	loss 6.740 (6.740)	prob 2.587 (2.587)	GS 28.891 (28.891)	mem 39.965
Train: [65][385/750]	BT 0.050 (1.164)	DT 0.001 (1.122)	loss 6.892 (6.892)	prob 3.110 (3.110)	GS 31.906 (31.906)	mem 39.965
Train: [65][390/750]	BT 0.058 (1.184)	DT 0.011 (1.142)	loss 6.827 (6.827)	prob 3.410 (3.410)	GS 31.219 (31.219)	mem 39.980
Train: [65][395/750]	BT 0.027 (1.169)	DT 0.001 (1.127)	loss 6.826 (6.826)	prob 3.137 (3.137)	GS 33.359 (33.359)	mem 39.981
Train: [65][400/750]	BT 0.020 (1.184)	DT 0.001 (1.142)	loss 6.837 (6.837)	prob 2.803 (2.803)	GS 31.703 (31.703)	mem 39.946
Train: [65][405/750]	BT 0.056 (1.170)	DT 0.010 (1.128)	loss 7.003 (7.003)	prob 2.227 (2.227)	GS 26.828 (26.828)	mem 39.946
Train: [65][410/750]	BT 16.336 (1.196)	DT 16.304 (1.154)	loss 6.683 (6.683)	prob 3.368 (3.368)	GS 35.438 (35.438)	mem 39.815
Train: [65][415/750]	BT 0.025 (1.182)	DT 0.001 (1.140)	loss 7.041 (7.041)	prob 2.245 (2.245)	GS 29.328 (29.328)	mem 39.816
Train: [65][420/750]	BT 0.032 (1.169)	DT 0.001 (1.127)	loss 6.675 (6.675)	prob 2.992 (2.992)	GS 33.188 (33.188)	mem 39.817
Train: [65][425/750]	BT 0.090 (1.189)	DT 0.030 (1.147)	loss 6.887 (6.887)	prob 3.008 (3.008)	GS 34.438 (34.438)	mem 39.853
Train: [65][430/750]	BT 0.027 (1.175)	DT 0.001 (1.133)	loss 6.747 (6.747)	prob 3.484 (3.484)	GS 34.625 (34.625)	mem 39.854
Train: [65][435/750]	BT 0.029 (1.191)	DT 0.001 (1.149)	loss 7.096 (7.096)	prob 2.683 (2.683)	GS 25.531 (25.531)	mem 39.897
Train: [65][440/750]	BT 0.112 (1.178)	DT 0.001 (1.136)	loss 6.687 (6.687)	prob 2.706 (2.706)	GS 38.609 (38.609)	mem 39.908
Train: [65][445/750]	BT 0.050 (1.165)	DT 0.001 (1.123)	loss 7.047 (7.047)	prob 2.533 (2.533)	GS 31.234 (31.234)	mem 40.062
Train: [65][450/750]	BT 0.030 (1.182)	DT 0.001 (1.141)	loss 6.969 (6.969)	prob 1.973 (1.973)	GS 33.125 (33.125)	mem 39.947
Train: [65][455/750]	BT 0.060 (1.170)	DT 0.001 (1.128)	loss 7.058 (7.058)	prob 2.848 (2.848)	GS 33.375 (33.375)	mem 39.947
Train: [65][460/750]	BT 0.020 (1.185)	DT 0.001 (1.144)	loss 6.795 (6.795)	prob 2.858 (2.858)	GS 34.547 (34.547)	mem 39.724
Train: [65][465/750]	BT 0.022 (1.173)	DT 0.001 (1.132)	loss 6.969 (6.969)	prob 3.207 (3.207)	GS 31.250 (31.250)	mem 39.663
Train: [65][470/750]	BT 9.333 (1.181)	DT 9.300 (1.139)	loss 6.828 (6.828)	prob 2.920 (2.920)	GS 30.906 (30.906)	mem 39.792
Train: [65][475/750]	BT 0.051 (1.169)	DT 0.003 (1.128)	loss 6.918 (6.918)	prob 2.829 (2.829)	GS 30.531 (30.531)	mem 39.897
Train: [65][480/750]	BT 0.044 (1.158)	DT 0.003 (1.116)	loss 6.729 (6.729)	prob 2.897 (2.897)	GS 33.484 (33.484)	mem 39.808
Train: [65][485/750]	BT 0.024 (1.175)	DT 0.001 (1.134)	loss 6.790 (6.790)	prob 3.239 (3.239)	GS 31.172 (31.172)	mem 39.833
Train: [65][490/750]	BT 0.068 (1.164)	DT 0.025 (1.122)	loss 6.727 (6.727)	prob 2.500 (2.500)	GS 34.266 (34.266)	mem 39.862
Train: [65][495/750]	BT 0.036 (1.175)	DT 0.001 (1.134)	loss 6.846 (6.846)	prob 2.735 (2.735)	GS 27.375 (27.375)	mem 39.930
Train: [65][500/750]	BT 0.079 (1.164)	DT 0.013 (1.122)	loss 6.926 (6.926)	prob 3.163 (3.163)	GS 32.297 (32.297)	mem 39.826
Train: [65][505/750]	BT 0.145 (1.153)	DT 0.005 (1.111)	loss 6.829 (6.829)	prob 2.943 (2.943)	GS 32.156 (32.156)	mem 39.831
Train: [65][510/750]	BT 0.032 (1.169)	DT 0.001 (1.127)	loss 7.134 (7.134)	prob 2.314 (2.314)	GS 36.094 (36.094)	mem 39.895
Train: [65][515/750]	BT 0.033 (1.158)	DT 0.002 (1.116)	loss 6.926 (6.926)	prob 2.752 (2.752)	GS 33.797 (33.797)	mem 39.990
Train: [65][520/750]	BT 0.042 (1.176)	DT 0.001 (1.134)	loss 7.057 (7.057)	prob 2.169 (2.169)	GS 36.234 (36.234)	mem 40.023
Train: [65][525/750]	BT 0.033 (1.165)	DT 0.001 (1.123)	loss 6.985 (6.985)	prob 2.712 (2.712)	GS 32.672 (32.672)	mem 39.939
Train: [65][530/750]	BT 13.831 (1.180)	DT 13.802 (1.139)	loss 7.050 (7.050)	prob 2.388 (2.388)	GS 39.312 (39.312)	mem 39.971
Train: [65][535/750]	BT 0.030 (1.170)	DT 0.001 (1.128)	loss 6.777 (6.777)	prob 3.522 (3.522)	GS 32.750 (32.750)	mem 39.971
Train: [65][540/750]	BT 0.103 (1.159)	DT 0.030 (1.118)	loss 6.944 (6.944)	prob 2.738 (2.738)	GS 36.984 (36.984)	mem 39.973
Train: [65][545/750]	BT 0.031 (1.172)	DT 0.002 (1.130)	loss 7.244 (7.244)	prob 2.719 (2.719)	GS 27.297 (27.297)	mem 39.994
Train: [65][550/750]	BT 0.046 (1.162)	DT 0.009 (1.120)	loss 6.914 (6.914)	prob 3.192 (3.192)	GS 36.281 (36.281)	mem 39.994
Train: [65][555/750]	BT 0.045 (1.174)	DT 0.006 (1.132)	loss 7.048 (7.048)	prob 2.580 (2.580)	GS 31.766 (31.766)	mem 40.018
Train: [65][560/750]	BT 0.053 (1.164)	DT 0.016 (1.122)	loss 7.064 (7.064)	prob 2.312 (2.312)	GS 32.953 (32.953)	mem 39.993
Train: [65][565/750]	BT 0.036 (1.154)	DT 0.002 (1.112)	loss 7.089 (7.089)	prob 2.767 (2.767)	GS 30.000 (30.000)	mem 40.027
Train: [65][570/750]	BT 0.023 (1.168)	DT 0.001 (1.126)	loss 6.694 (6.694)	prob 3.850 (3.850)	GS 32.578 (32.578)	mem 39.993
Train: [65][575/750]	BT 0.027 (1.158)	DT 0.001 (1.117)	loss 6.786 (6.786)	prob 3.216 (3.216)	GS 29.203 (29.203)	mem 39.994
Train: [65][580/750]	BT 0.065 (1.171)	DT 0.027 (1.130)	loss 6.996 (6.996)	prob 2.902 (2.902)	GS 35.297 (35.297)	mem 40.003
Train: [65][585/750]	BT 0.056 (1.162)	DT 0.011 (1.120)	loss 7.321 (7.321)	prob 2.705 (2.705)	GS 40.500 (40.500)	mem 40.060
Train: [65][590/750]	BT 14.043 (1.176)	DT 13.998 (1.134)	loss 6.899 (6.899)	prob 2.687 (2.687)	GS 37.172 (37.172)	mem 40.005
Train: [65][595/750]	BT 0.046 (1.166)	DT 0.011 (1.125)	loss 7.049 (7.049)	prob 2.767 (2.767)	GS 31.016 (31.016)	mem 40.005
Train: [65][600/750]	BT 0.022 (1.157)	DT 0.001 (1.116)	loss 6.934 (6.934)	prob 2.873 (2.873)	GS 31.016 (31.016)	mem 40.005
Train: [65][605/750]	BT 0.048 (1.169)	DT 0.012 (1.128)	loss 7.047 (7.047)	prob 3.191 (3.191)	GS 30.359 (30.359)	mem 40.006
Train: [65][610/750]	BT 0.030 (1.160)	DT 0.001 (1.118)	loss 7.072 (7.072)	prob 3.201 (3.201)	GS 38.375 (38.375)	mem 40.007
Train: [65][615/750]	BT 0.053 (1.169)	DT 0.002 (1.128)	loss 6.798 (6.798)	prob 2.285 (2.285)	GS 33.516 (33.516)	mem 40.043
Train: [65][620/750]	BT 0.033 (1.160)	DT 0.001 (1.119)	loss 6.835 (6.835)	prob 3.514 (3.514)	GS 34.375 (34.375)	mem 40.099
Train: [65][625/750]	BT 0.064 (1.151)	DT 0.013 (1.110)	loss 7.277 (7.277)	prob 2.462 (2.462)	GS 31.453 (31.453)	mem 40.012
Train: [65][630/750]	BT 0.036 (1.162)	DT 0.001 (1.121)	loss 6.894 (6.894)	prob 2.572 (2.572)	GS 37.484 (37.484)	mem 39.957
Train: [65][635/750]	BT 0.115 (1.154)	DT 0.017 (1.112)	loss 6.931 (6.931)	prob 2.962 (2.962)	GS 31.406 (31.406)	mem 39.958
Train: [65][640/750]	BT 0.038 (1.166)	DT 0.001 (1.124)	loss 6.992 (6.992)	prob 2.434 (2.434)	GS 33.766 (33.766)	mem 39.979
Train: [65][645/750]	BT 0.060 (1.157)	DT 0.007 (1.116)	loss 6.817 (6.817)	prob 2.733 (2.733)	GS 29.672 (29.672)	mem 39.949
Train: [65][650/750]	BT 12.097 (1.168)	DT 12.065 (1.126)	loss 6.930 (6.930)	prob 3.271 (3.271)	GS 33.047 (33.047)	mem 39.964
Train: [65][655/750]	BT 0.033 (1.159)	DT 0.002 (1.117)	loss 7.083 (7.083)	prob 2.601 (2.601)	GS 30.828 (30.828)	mem 39.966
Train: [65][660/750]	BT 0.036 (1.151)	DT 0.004 (1.109)	loss 6.888 (6.888)	prob 3.141 (3.141)	GS 33.422 (33.422)	mem 40.004
Train: [65][665/750]	BT 0.051 (1.161)	DT 0.010 (1.119)	loss 7.143 (7.143)	prob 2.395 (2.395)	GS 33.703 (33.703)	mem 40.032
Train: [65][670/750]	BT 0.030 (1.153)	DT 0.002 (1.111)	loss 6.986 (6.986)	prob 2.811 (2.811)	GS 33.734 (33.734)	mem 40.031
Train: [65][675/750]	BT 0.046 (1.164)	DT 0.006 (1.122)	loss 6.852 (6.852)	prob 3.016 (3.016)	GS 35.359 (35.359)	mem 40.070
Train: [65][680/750]	BT 0.036 (1.156)	DT 0.005 (1.114)	loss 6.922 (6.922)	prob 2.602 (2.602)	GS 35.328 (35.328)	mem 40.037
Train: [65][685/750]	BT 0.081 (1.148)	DT 0.027 (1.106)	loss 7.231 (7.231)	prob 2.627 (2.627)	GS 32.562 (32.562)	mem 39.980
Train: [65][690/750]	BT 0.033 (1.158)	DT 0.002 (1.116)	loss 6.830 (6.830)	prob 2.996 (2.996)	GS 32.438 (32.438)	mem 40.108
Train: [65][695/750]	BT 0.047 (1.150)	DT 0.005 (1.108)	loss 6.844 (6.844)	prob 2.908 (2.908)	GS 32.453 (32.453)	mem 39.988
Train: [65][700/750]	BT 0.053 (1.162)	DT 0.016 (1.119)	loss 6.905 (6.905)	prob 2.757 (2.757)	GS 34.281 (34.281)	mem 39.963
Train: [65][705/750]	BT 0.040 (1.154)	DT 0.003 (1.112)	loss 7.016 (7.016)	prob 1.903 (1.903)	GS 28.812 (28.812)	mem 39.965
Train: [65][710/750]	BT 14.847 (1.167)	DT 14.791 (1.125)	loss 6.811 (6.811)	prob 3.297 (3.297)	GS 34.234 (34.234)	mem 39.905
Train: [65][715/750]	BT 0.028 (1.159)	DT 0.001 (1.117)	loss 6.766 (6.766)	prob 3.083 (3.083)	GS 37.141 (37.141)	mem 39.906
Train: [65][720/750]	BT 0.051 (1.151)	DT 0.005 (1.109)	loss 7.191 (7.191)	prob 2.285 (2.285)	GS 32.047 (32.047)	mem 39.907
Train: [65][725/750]	BT 0.027 (1.161)	DT 0.001 (1.119)	loss 6.991 (6.991)	prob 2.555 (2.555)	GS 30.016 (30.016)	mem 39.861
Train: [65][730/750]	BT 0.025 (1.153)	DT 0.001 (1.112)	loss 6.834 (6.834)	prob 2.855 (2.855)	GS 33.641 (33.641)	mem 39.861
Train: [65][735/750]	BT 0.037 (1.157)	DT 0.001 (1.115)	loss 6.893 (6.893)	prob 2.933 (2.933)	GS 35.156 (35.156)	mem 36.553
Train: [65][740/750]	BT 0.029 (1.149)	DT 0.005 (1.107)	loss 6.802 (6.802)	prob 3.050 (3.050)	GS 34.219 (34.219)	mem 36.485
Train: [65][745/750]	BT 0.031 (1.142)	DT 0.002 (1.100)	loss 6.909 (6.909)	prob 2.459 (2.459)	GS 35.469 (35.469)	mem 36.488
Train: [65][750/750]	BT 0.026 (1.138)	DT 0.001 (1.096)	loss 7.218 (7.218)	prob 2.002 (2.002)	GS 28.312 (28.312)	mem 7.608
Train: [65][755/750]	BT 0.026 (1.130)	DT 0.001 (1.089)	loss 7.289 (7.289)	prob 2.244 (2.244)	GS 38.188 (38.188)	mem 7.607
epoch 65, total time 853.54
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [66][1/750]	BT 20.015 (20.015)	DT 19.965 (19.965)	loss 6.851 (6.851)	prob 2.262 (2.262)	GS 29.641 (29.641)	mem 38.406
Train: [66][5/750]	BT 0.069 (4.614)	DT 0.012 (4.547)	loss 6.782 (6.782)	prob 2.327 (2.327)	GS 32.875 (32.875)	mem 38.550
Train: [66][10/750]	BT 0.134 (2.632)	DT 0.001 (2.560)	loss 6.873 (6.873)	prob 1.965 (1.965)	GS 35.078 (35.078)	mem 38.492
Train: [66][15/750]	BT 0.033 (2.487)	DT 0.001 (2.428)	loss 6.842 (6.842)	prob 2.849 (2.849)	GS 24.938 (24.938)	mem 38.786
Train: [66][20/750]	BT 0.037 (1.891)	DT 0.002 (1.839)	loss 6.897 (6.897)	prob 2.486 (2.486)	GS 36.344 (36.344)	mem 38.952
Train: [66][25/750]	BT 2.660 (1.628)	DT 2.557 (1.574)	loss 6.949 (6.949)	prob 2.233 (2.233)	GS 33.547 (33.547)	mem 39.018
Train: [66][30/750]	BT 0.078 (1.686)	DT 0.003 (1.632)	loss 6.668 (6.668)	prob 2.408 (2.408)	GS 33.703 (33.703)	mem 38.926
Train: [66][35/750]	BT 0.043 (1.531)	DT 0.002 (1.479)	loss 6.948 (6.948)	prob 3.150 (3.150)	GS 32.500 (32.500)	mem 38.889
Train: [66][40/750]	BT 1.934 (1.575)	DT 1.874 (1.522)	loss 6.841 (6.841)	prob 3.000 (3.000)	GS 36.000 (36.000)	mem 38.961
Train: [66][45/750]	BT 0.077 (1.415)	DT 0.017 (1.362)	loss 6.771 (6.771)	prob 2.901 (2.901)	GS 27.641 (27.641)	mem 38.961
Train: [66][50/750]	BT 9.987 (1.495)	DT 9.955 (1.444)	loss 6.911 (6.911)	prob 3.389 (3.389)	GS 33.750 (33.750)	mem 38.992
Train: [66][55/750]	BT 0.045 (1.363)	DT 0.001 (1.313)	loss 6.826 (6.826)	prob 2.761 (2.761)	GS 27.688 (27.688)	mem 38.958
Train: [66][60/750]	BT 0.054 (1.304)	DT 0.002 (1.252)	loss 6.904 (6.904)	prob 2.284 (2.284)	GS 33.062 (33.062)	mem 38.970
Train: [66][65/750]	BT 0.033 (1.384)	DT 0.008 (1.332)	loss 7.001 (7.001)	prob 2.514 (2.514)	GS 29.828 (29.828)	mem 39.305
Train: [66][70/750]	BT 3.887 (1.344)	DT 3.855 (1.292)	loss 6.990 (6.990)	prob 3.018 (3.018)	GS 34.422 (34.422)	mem 39.396
Train: [66][75/750]	BT 0.027 (1.366)	DT 0.001 (1.314)	loss 6.809 (6.809)	prob 2.879 (2.879)	GS 29.906 (29.906)	mem 39.450
Train: [66][80/750]	BT 0.729 (1.292)	DT 0.654 (1.241)	loss 7.142 (7.142)	prob 2.687 (2.687)	GS 35.266 (35.266)	mem 39.498
Train: [66][85/750]	BT 0.047 (1.287)	DT 0.001 (1.236)	loss 6.893 (6.893)	prob 2.927 (2.927)	GS 32.734 (32.734)	mem 39.705
Train: [66][90/750]	BT 1.103 (1.325)	DT 1.075 (1.275)	loss 6.905 (6.905)	prob 3.348 (3.348)	GS 35.625 (35.625)	mem 39.624
Train: [66][95/750]	BT 0.027 (1.269)	DT 0.001 (1.220)	loss 6.933 (6.933)	prob 2.630 (2.630)	GS 33.438 (33.438)	mem 39.627
Train: [66][100/750]	BT 0.032 (1.303)	DT 0.001 (1.254)	loss 6.786 (6.786)	prob 2.930 (2.930)	GS 33.062 (33.062)	mem 39.659
Train: [66][105/750]	BT 0.030 (1.281)	DT 0.002 (1.232)	loss 7.041 (7.041)	prob 2.928 (2.928)	GS 34.016 (34.016)	mem 39.626
Train: [66][110/750]	BT 8.064 (1.300)	DT 8.012 (1.251)	loss 6.715 (6.715)	prob 3.409 (3.409)	GS 37.234 (37.234)	mem 39.702
Train: [66][115/750]	BT 0.040 (1.287)	DT 0.003 (1.239)	loss 6.767 (6.767)	prob 2.829 (2.829)	GS 30.781 (30.781)	mem 39.626
Train: [66][120/750]	BT 0.042 (1.235)	DT 0.001 (1.187)	loss 7.261 (7.261)	prob 2.263 (2.263)	GS 33.672 (33.672)	mem 39.626
Train: [66][125/750]	BT 0.049 (1.250)	DT 0.001 (1.203)	loss 6.781 (6.781)	prob 3.226 (3.226)	GS 30.719 (30.719)	mem 39.643
Train: [66][130/750]	BT 0.068 (1.239)	DT 0.019 (1.192)	loss 6.764 (6.764)	prob 2.919 (2.919)	GS 34.969 (34.969)	mem 39.734
Train: [66][135/750]	BT 0.052 (1.219)	DT 0.001 (1.172)	loss 6.755 (6.755)	prob 2.752 (2.752)	GS 31.297 (31.297)	mem 39.637
Train: [66][140/750]	BT 0.056 (1.238)	DT 0.001 (1.191)	loss 6.813 (6.813)	prob 2.500 (2.500)	GS 33.359 (33.359)	mem 39.606
Train: [66][145/750]	BT 0.065 (1.197)	DT 0.012 (1.150)	loss 6.669 (6.669)	prob 2.827 (2.827)	GS 28.953 (28.953)	mem 39.641
Train: [66][150/750]	BT 2.589 (1.252)	DT 2.549 (1.205)	loss 6.759 (6.759)	prob 2.386 (2.386)	GS 37.312 (37.312)	mem 39.706
Train: [66][155/750]	BT 0.052 (1.213)	DT 0.001 (1.166)	loss 6.660 (6.660)	prob 2.904 (2.904)	GS 30.141 (30.141)	mem 39.657
Train: [66][160/750]	BT 9.264 (1.239)	DT 9.220 (1.193)	loss 6.645 (6.645)	prob 2.755 (2.755)	GS 31.250 (31.250)	mem 39.728
Train: [66][165/750]	BT 0.050 (1.217)	DT 0.001 (1.171)	loss 6.864 (6.864)	prob 3.118 (3.118)	GS 29.594 (29.594)	mem 39.735
Train: [66][170/750]	BT 0.464 (1.185)	DT 0.429 (1.139)	loss 6.818 (6.818)	prob 2.615 (2.615)	GS 34.656 (34.656)	mem 39.673
Train: [66][175/750]	BT 0.043 (1.231)	DT 0.002 (1.185)	loss 6.617 (6.617)	prob 2.788 (2.788)	GS 28.391 (28.391)	mem 39.792
Train: [66][180/750]	BT 0.048 (1.198)	DT 0.006 (1.152)	loss 6.822 (6.822)	prob 1.944 (1.944)	GS 36.750 (36.750)	mem 39.795
Train: [66][185/750]	BT 0.111 (1.199)	DT 0.018 (1.152)	loss 6.688 (6.688)	prob 3.143 (3.143)	GS 33.234 (33.234)	mem 39.924
Train: [66][190/750]	BT 0.058 (1.213)	DT 0.008 (1.166)	loss 6.810 (6.810)	prob 2.286 (2.286)	GS 32.891 (32.891)	mem 39.771
Train: [66][195/750]	BT 0.046 (1.199)	DT 0.015 (1.152)	loss 7.201 (7.201)	prob 1.981 (1.981)	GS 29.000 (29.000)	mem 39.736
Train: [66][200/750]	BT 0.023 (1.225)	DT 0.001 (1.179)	loss 6.882 (6.882)	prob 2.984 (2.984)	GS 33.938 (33.938)	mem 39.722
Train: [66][205/750]	BT 0.052 (1.196)	DT 0.011 (1.150)	loss 7.077 (7.077)	prob 2.347 (2.347)	GS 26.953 (26.953)	mem 39.803
Train: [66][210/750]	BT 8.389 (1.228)	DT 8.348 (1.183)	loss 6.933 (6.933)	prob 2.648 (2.648)	GS 32.516 (32.516)	mem 39.909
Train: [66][215/750]	BT 0.034 (1.201)	DT 0.001 (1.155)	loss 7.234 (7.234)	prob 2.689 (2.689)	GS 31.250 (31.250)	mem 39.824
Train: [66][220/750]	BT 0.089 (1.197)	DT 0.013 (1.151)	loss 6.727 (6.727)	prob 3.100 (3.100)	GS 34.234 (34.234)	mem 40.177
Train: [66][225/750]	BT 0.033 (1.205)	DT 0.002 (1.159)	loss 6.838 (6.838)	prob 3.478 (3.478)	GS 31.375 (31.375)	mem 39.765
Train: [66][230/750]	BT 4.189 (1.198)	DT 4.157 (1.152)	loss 6.833 (6.833)	prob 3.032 (3.032)	GS 31.234 (31.234)	mem 39.787
Train: [66][235/750]	BT 0.045 (1.196)	DT 0.007 (1.151)	loss 6.726 (6.726)	prob 2.940 (2.940)	GS 29.172 (29.172)	mem 39.832
Train: [66][240/750]	BT 0.039 (1.172)	DT 0.002 (1.127)	loss 6.826 (6.826)	prob 3.420 (3.420)	GS 35.875 (35.875)	mem 39.831
Train: [66][245/750]	BT 0.065 (1.185)	DT 0.002 (1.140)	loss 6.892 (6.892)	prob 2.914 (2.914)	GS 27.000 (27.000)	mem 39.896
Train: [66][250/750]	BT 0.029 (1.175)	DT 0.001 (1.130)	loss 6.877 (6.877)	prob 2.700 (2.700)	GS 32.000 (32.000)	mem 39.832
Train: [66][255/750]	BT 0.034 (1.177)	DT 0.002 (1.131)	loss 6.855 (6.855)	prob 2.808 (2.808)	GS 33.812 (33.812)	mem 39.988
Train: [66][260/750]	BT 0.037 (1.180)	DT 0.002 (1.135)	loss 6.999 (6.999)	prob 3.153 (3.153)	GS 36.516 (36.516)	mem 39.923
Train: [66][265/750]	BT 0.033 (1.159)	DT 0.002 (1.113)	loss 7.224 (7.224)	prob 3.080 (3.080)	GS 28.312 (28.312)	mem 39.856
Train: [66][270/750]	BT 10.270 (1.191)	DT 10.209 (1.145)	loss 6.928 (6.928)	prob 2.921 (2.921)	GS 35.766 (35.766)	mem 39.905
Train: [66][275/750]	BT 0.068 (1.170)	DT 0.002 (1.124)	loss 7.108 (7.108)	prob 2.650 (2.650)	GS 34.250 (34.250)	mem 39.904
Train: [66][280/750]	BT 0.053 (1.154)	DT 0.001 (1.109)	loss 6.788 (6.788)	prob 2.051 (2.051)	GS 31.922 (31.922)	mem 39.926
Train: [66][285/750]	BT 0.028 (1.173)	DT 0.001 (1.128)	loss 6.974 (6.974)	prob 2.977 (2.977)	GS 30.625 (30.625)	mem 39.798
Train: [66][290/750]	BT 3.292 (1.164)	DT 3.253 (1.119)	loss 7.251 (7.251)	prob 1.852 (1.852)	GS 31.984 (31.984)	mem 39.790
Train: [66][295/750]	BT 0.034 (1.179)	DT 0.006 (1.134)	loss 7.082 (7.082)	prob 3.326 (3.326)	GS 30.719 (30.719)	mem 39.851
Train: [66][300/750]	BT 0.035 (1.160)	DT 0.002 (1.115)	loss 6.946 (6.946)	prob 3.247 (3.247)	GS 33.906 (33.906)	mem 40.071
Train: [66][305/750]	BT 0.144 (1.154)	DT 0.004 (1.109)	loss 6.848 (6.848)	prob 2.850 (2.850)	GS 32.859 (32.859)	mem 39.931
Train: [66][310/750]	BT 0.044 (1.170)	DT 0.002 (1.125)	loss 7.106 (7.106)	prob 2.350 (2.350)	GS 34.750 (34.750)	mem 39.869
Train: [66][315/750]	BT 0.024 (1.152)	DT 0.001 (1.107)	loss 6.995 (6.995)	prob 2.693 (2.693)	GS 27.750 (27.750)	mem 39.796
Train: [66][320/750]	BT 0.030 (1.178)	DT 0.002 (1.134)	loss 6.849 (6.849)	prob 3.449 (3.449)	GS 28.016 (28.016)	mem 39.743
Train: [66][325/750]	BT 0.041 (1.161)	DT 0.010 (1.116)	loss 6.987 (6.987)	prob 3.023 (3.023)	GS 35.156 (35.156)	mem 39.985
Train: [66][330/750]	BT 14.896 (1.189)	DT 14.862 (1.144)	loss 7.198 (7.198)	prob 2.500 (2.500)	GS 34.578 (34.578)	mem 39.761
Train: [66][335/750]	BT 0.032 (1.172)	DT 0.001 (1.127)	loss 7.132 (7.132)	prob 3.466 (3.466)	GS 36.094 (36.094)	mem 39.762
Train: [66][340/750]	BT 0.079 (1.155)	DT 0.004 (1.111)	loss 7.060 (7.060)	prob 2.875 (2.875)	GS 29.875 (29.875)	mem 39.784
Train: [66][345/750]	BT 0.040 (1.180)	DT 0.011 (1.136)	loss 6.970 (6.970)	prob 3.333 (3.333)	GS 31.094 (31.094)	mem 39.739
Train: [66][350/750]	BT 0.033 (1.164)	DT 0.002 (1.119)	loss 6.931 (6.931)	prob 2.860 (2.860)	GS 28.469 (28.469)	mem 39.764
Train: [66][355/750]	BT 0.029 (1.178)	DT 0.001 (1.134)	loss 7.475 (7.475)	prob 2.300 (2.300)	GS 37.719 (37.719)	mem 39.884
Train: [66][360/750]	BT 0.035 (1.162)	DT 0.001 (1.118)	loss 7.233 (7.233)	prob 2.233 (2.233)	GS 32.469 (32.469)	mem 39.873
Train: [66][365/750]	BT 0.044 (1.147)	DT 0.002 (1.103)	loss 6.943 (6.943)	prob 3.212 (3.212)	GS 32.844 (32.844)	mem 39.872
Train: [66][370/750]	BT 0.032 (1.171)	DT 0.001 (1.127)	loss 6.851 (6.851)	prob 3.127 (3.127)	GS 32.547 (32.547)	mem 39.814
Train: [66][375/750]	BT 0.029 (1.156)	DT 0.001 (1.112)	loss 7.027 (7.027)	prob 2.645 (2.645)	GS 45.047 (45.047)	mem 39.814
Train: [66][380/750]	BT 0.048 (1.171)	DT 0.010 (1.127)	loss 6.905 (6.905)	prob 2.857 (2.857)	GS 34.125 (34.125)	mem 39.918
Train: [66][385/750]	BT 0.025 (1.156)	DT 0.001 (1.113)	loss 7.162 (7.162)	prob 2.417 (2.417)	GS 29.828 (29.828)	mem 39.919
Train: [66][390/750]	BT 11.324 (1.171)	DT 11.253 (1.127)	loss 7.018 (7.018)	prob 2.616 (2.616)	GS 33.312 (33.312)	mem 39.947
Train: [66][395/750]	BT 0.026 (1.157)	DT 0.001 (1.113)	loss 7.117 (7.117)	prob 2.296 (2.296)	GS 31.922 (31.922)	mem 39.953
Train: [66][400/750]	BT 0.034 (1.143)	DT 0.001 (1.099)	loss 6.874 (6.874)	prob 3.458 (3.458)	GS 31.281 (31.281)	mem 39.955
Train: [66][405/750]	BT 0.032 (1.159)	DT 0.002 (1.115)	loss 6.773 (6.773)	prob 2.700 (2.700)	GS 25.562 (25.562)	mem 39.874
Train: [66][410/750]	BT 0.036 (1.145)	DT 0.002 (1.102)	loss 6.972 (6.972)	prob 2.603 (2.603)	GS 28.750 (28.750)	mem 40.068
Train: [66][415/750]	BT 0.029 (1.160)	DT 0.001 (1.117)	loss 7.221 (7.221)	prob 2.981 (2.981)	GS 37.188 (37.188)	mem 39.934
Train: [66][420/750]	BT 0.022 (1.147)	DT 0.001 (1.104)	loss 7.007 (7.007)	prob 2.796 (2.796)	GS 32.984 (32.984)	mem 39.934
Train: [66][425/750]	BT 0.048 (1.134)	DT 0.002 (1.091)	loss 6.802 (6.802)	prob 2.997 (2.997)	GS 31.109 (31.109)	mem 39.934
Train: [66][430/750]	BT 0.023 (1.144)	DT 0.001 (1.100)	loss 6.969 (6.969)	prob 2.600 (2.600)	GS 35.250 (35.250)	mem 39.964
Train: [66][435/750]	BT 0.033 (1.131)	DT 0.004 (1.088)	loss 6.873 (6.873)	prob 2.329 (2.329)	GS 31.125 (31.125)	mem 39.958
Train: [66][440/750]	BT 0.048 (1.145)	DT 0.001 (1.102)	loss 7.000 (7.000)	prob 2.599 (2.599)	GS 31.141 (31.141)	mem 39.959
Train: [66][445/750]	BT 0.033 (1.133)	DT 0.001 (1.089)	loss 7.332 (7.332)	prob 2.504 (2.504)	GS 29.891 (29.891)	mem 40.003
Train: [66][450/750]	BT 10.972 (1.145)	DT 10.944 (1.102)	loss 7.046 (7.046)	prob 2.315 (2.315)	GS 35.547 (35.547)	mem 39.909
Train: [66][455/750]	BT 0.034 (1.133)	DT 0.001 (1.090)	loss 7.021 (7.021)	prob 2.752 (2.752)	GS 26.344 (26.344)	mem 39.986
Train: [66][460/750]	BT 0.048 (1.121)	DT 0.015 (1.078)	loss 7.308 (7.308)	prob 2.757 (2.757)	GS 34.328 (34.328)	mem 39.912
Train: [66][465/750]	BT 0.063 (1.139)	DT 0.006 (1.096)	loss 7.012 (7.012)	prob 3.038 (3.038)	GS 29.375 (29.375)	mem 39.984
Train: [66][470/750]	BT 0.035 (1.127)	DT 0.001 (1.084)	loss 6.816 (6.816)	prob 2.520 (2.520)	GS 31.766 (31.766)	mem 39.985
Train: [66][475/750]	BT 0.043 (1.140)	DT 0.002 (1.097)	loss 6.771 (6.771)	prob 2.352 (2.352)	GS 30.969 (30.969)	mem 39.983
Train: [66][480/750]	BT 0.040 (1.131)	DT 0.015 (1.088)	loss 6.902 (6.902)	prob 2.431 (2.431)	GS 31.281 (31.281)	mem 39.940
Train: [66][485/750]	BT 0.039 (1.120)	DT 0.002 (1.077)	loss 7.166 (7.166)	prob 2.366 (2.366)	GS 35.469 (35.469)	mem 39.960
Train: [66][490/750]	BT 0.249 (1.132)	DT 0.148 (1.088)	loss 6.954 (6.954)	prob 3.129 (3.129)	GS 33.844 (33.844)	mem 39.979
Train: [66][495/750]	BT 0.060 (1.121)	DT 0.004 (1.078)	loss 7.009 (7.009)	prob 2.074 (2.074)	GS 25.156 (25.156)	mem 40.018
Train: [66][500/750]	BT 6.710 (1.141)	DT 6.668 (1.097)	loss 6.978 (6.978)	prob 2.884 (2.884)	GS 38.141 (38.141)	mem 39.970
Train: [66][505/750]	BT 0.058 (1.130)	DT 0.008 (1.086)	loss 6.837 (6.837)	prob 1.987 (1.987)	GS 30.188 (30.188)	mem 40.101
Train: [66][510/750]	BT 2.236 (1.129)	DT 2.204 (1.086)	loss 6.831 (6.831)	prob 2.360 (2.360)	GS 31.469 (31.469)	mem 39.934
Train: [66][515/750]	BT 0.065 (1.134)	DT 0.001 (1.090)	loss 6.846 (6.846)	prob 2.816 (2.816)	GS 33.875 (33.875)	mem 39.951
Train: [66][520/750]	BT 2.233 (1.127)	DT 2.192 (1.084)	loss 6.781 (6.781)	prob 3.051 (3.051)	GS 33.984 (33.984)	mem 40.022
Train: [66][525/750]	BT 0.040 (1.140)	DT 0.002 (1.096)	loss 6.997 (6.997)	prob 2.935 (2.935)	GS 27.688 (27.688)	mem 39.938
Train: [66][530/750]	BT 0.050 (1.130)	DT 0.014 (1.086)	loss 6.856 (6.856)	prob 3.518 (3.518)	GS 33.453 (33.453)	mem 39.866
Train: [66][535/750]	BT 0.063 (1.131)	DT 0.004 (1.087)	loss 6.819 (6.819)	prob 2.762 (2.762)	GS 31.562 (31.562)	mem 39.942
Train: [66][540/750]	BT 0.032 (1.134)	DT 0.001 (1.091)	loss 6.921 (6.921)	prob 2.734 (2.734)	GS 35.156 (35.156)	mem 40.028
Train: [66][545/750]	BT 0.044 (1.124)	DT 0.003 (1.081)	loss 6.847 (6.847)	prob 2.556 (2.556)	GS 30.047 (30.047)	mem 39.971
Train: [66][550/750]	BT 0.056 (1.134)	DT 0.025 (1.091)	loss 6.921 (6.921)	prob 2.120 (2.120)	GS 32.078 (32.078)	mem 39.972
Train: [66][555/750]	BT 0.047 (1.125)	DT 0.012 (1.081)	loss 6.739 (6.739)	prob 2.672 (2.672)	GS 30.156 (30.156)	mem 39.973
Train: [66][560/750]	BT 9.191 (1.140)	DT 9.158 (1.097)	loss 6.933 (6.933)	prob 2.498 (2.498)	GS 33.797 (33.797)	mem 39.959
Train: [66][565/750]	BT 0.073 (1.130)	DT 0.007 (1.087)	loss 6.785 (6.785)	prob 2.244 (2.244)	GS 30.312 (30.312)	mem 39.961
Train: [66][570/750]	BT 1.043 (1.123)	DT 1.019 (1.079)	loss 6.642 (6.642)	prob 1.646 (1.646)	GS 35.266 (35.266)	mem 40.143
Train: [66][575/750]	BT 0.038 (1.138)	DT 0.001 (1.095)	loss 6.888 (6.888)	prob 2.504 (2.504)	GS 33.031 (33.031)	mem 39.994
Train: [66][580/750]	BT 0.033 (1.128)	DT 0.002 (1.085)	loss 6.996 (6.996)	prob 1.928 (1.928)	GS 34.391 (34.391)	mem 40.057
Train: [66][585/750]	BT 0.034 (1.140)	DT 0.007 (1.097)	loss 7.097 (7.097)	prob 1.654 (1.654)	GS 29.391 (29.391)	mem 40.012
Train: [66][590/750]	BT 0.040 (1.131)	DT 0.002 (1.088)	loss 6.864 (6.864)	prob 2.245 (2.245)	GS 35.250 (35.250)	mem 40.012
Train: [66][595/750]	BT 0.037 (1.122)	DT 0.001 (1.079)	loss 6.662 (6.662)	prob 2.584 (2.584)	GS 33.516 (33.516)	mem 40.011
Train: [66][600/750]	BT 0.067 (1.131)	DT 0.012 (1.088)	loss 6.650 (6.650)	prob 2.487 (2.487)	GS 33.094 (33.094)	mem 40.013
Train: [66][605/750]	BT 0.061 (1.123)	DT 0.002 (1.079)	loss 6.750 (6.750)	prob 1.978 (1.978)	GS 30.156 (30.156)	mem 40.015
Train: [66][610/750]	BT 0.035 (1.131)	DT 0.001 (1.088)	loss 7.060 (7.060)	prob 2.804 (2.804)	GS 36.297 (36.297)	mem 39.993
Train: [66][615/750]	BT 0.040 (1.122)	DT 0.002 (1.079)	loss 7.255 (7.255)	prob 1.821 (1.821)	GS 32.188 (32.188)	mem 40.008
Train: [66][620/750]	BT 13.812 (1.136)	DT 13.781 (1.092)	loss 7.041 (7.041)	prob 2.920 (2.920)	GS 34.453 (34.453)	mem 39.958
Train: [66][625/750]	BT 0.090 (1.127)	DT 0.001 (1.084)	loss 6.726 (6.726)	prob 2.821 (2.821)	GS 30.656 (30.656)	mem 40.101
Train: [66][630/750]	BT 0.062 (1.118)	DT 0.003 (1.075)	loss 6.951 (6.951)	prob 2.397 (2.397)	GS 31.969 (31.969)	mem 40.022
Train: [66][635/750]	BT 0.033 (1.130)	DT 0.001 (1.086)	loss 6.770 (6.770)	prob 1.854 (1.854)	GS 33.750 (33.750)	mem 39.995
Train: [66][640/750]	BT 0.040 (1.121)	DT 0.001 (1.078)	loss 7.108 (7.108)	prob 2.814 (2.814)	GS 31.250 (31.250)	mem 39.996
Train: [66][645/750]	BT 0.043 (1.133)	DT 0.009 (1.090)	loss 7.551 (7.551)	prob 2.276 (2.276)	GS 41.703 (41.703)	mem 40.025
Train: [66][650/750]	BT 0.085 (1.125)	DT 0.015 (1.082)	loss 6.974 (6.974)	prob 2.152 (2.152)	GS 38.188 (38.188)	mem 40.089
Train: [66][655/750]	BT 0.116 (1.117)	DT 0.007 (1.074)	loss 7.540 (7.540)	prob 1.484 (1.484)	GS 29.250 (29.250)	mem 40.023
Train: [66][660/750]	BT 0.034 (1.128)	DT 0.002 (1.085)	loss 6.715 (6.715)	prob 2.277 (2.277)	GS 33.078 (33.078)	mem 40.049
Train: [66][665/750]	BT 0.038 (1.120)	DT 0.001 (1.077)	loss 6.992 (6.992)	prob 2.671 (2.671)	GS 34.000 (34.000)	mem 40.106
Train: [66][670/750]	BT 6.577 (1.133)	DT 6.534 (1.090)	loss 7.239 (7.239)	prob 2.465 (2.465)	GS 32.641 (32.641)	mem 40.314
Train: [66][675/750]	BT 0.048 (1.125)	DT 0.012 (1.082)	loss 6.997 (6.997)	prob 1.957 (1.957)	GS 30.969 (30.969)	mem 40.005
Train: [66][680/750]	BT 3.680 (1.123)	DT 3.611 (1.079)	loss 7.101 (7.101)	prob 2.176 (2.176)	GS 32.391 (32.391)	mem 40.164
Train: [66][685/750]	BT 0.026 (1.125)	DT 0.001 (1.081)	loss 7.028 (7.028)	prob 1.599 (1.599)	GS 32.125 (32.125)	mem 40.067
Train: [66][690/750]	BT 0.187 (1.118)	DT 0.022 (1.074)	loss 7.163 (7.163)	prob 1.534 (1.534)	GS 35.094 (35.094)	mem 40.050
Train: [66][695/750]	BT 0.087 (1.128)	DT 0.002 (1.084)	loss 7.031 (7.031)	prob 1.583 (1.583)	GS 33.391 (33.391)	mem 40.213
Train: [66][700/750]	BT 0.032 (1.120)	DT 0.001 (1.076)	loss 7.064 (7.064)	prob 2.251 (2.251)	GS 33.953 (33.953)	mem 40.062
Train: [66][705/750]	BT 0.035 (1.117)	DT 0.001 (1.073)	loss 6.999 (6.999)	prob 2.011 (2.011)	GS 30.625 (30.625)	mem 40.029
Train: [66][710/750]	BT 0.091 (1.121)	DT 0.008 (1.077)	loss 7.085 (7.085)	prob 1.716 (1.716)	GS 35.547 (35.547)	mem 40.061
Train: [66][715/750]	BT 0.032 (1.117)	DT 0.001 (1.072)	loss 6.952 (6.952)	prob 2.119 (2.119)	GS 28.953 (28.953)	mem 40.064
Train: [66][720/750]	BT 0.045 (1.122)	DT 0.001 (1.078)	loss 7.540 (7.540)	prob 2.075 (2.075)	GS 34.094 (34.094)	mem 40.059
Train: [66][725/750]	BT 0.101 (1.115)	DT 0.006 (1.071)	loss 7.211 (7.211)	prob 1.536 (1.536)	GS 25.641 (25.641)	mem 40.203
Train: [66][730/750]	BT 4.843 (1.122)	DT 4.796 (1.078)	loss 7.295 (7.295)	prob 2.310 (2.310)	GS 32.375 (32.375)	mem 39.831
Train: [66][735/750]	BT 0.027 (1.115)	DT 0.001 (1.071)	loss 7.016 (7.016)	prob 2.148 (2.148)	GS 28.094 (28.094)	mem 39.601
Train: [66][740/750]	BT 0.022 (1.116)	DT 0.001 (1.072)	loss 7.176 (7.176)	prob 2.503 (2.503)	GS 34.422 (34.422)	mem 16.609
Train: [66][745/750]	BT 0.031 (1.116)	DT 0.001 (1.072)	loss 7.574 (7.574)	prob 2.141 (2.141)	GS 34.719 (34.719)	mem 7.662
Train: [66][750/750]	BT 0.033 (1.109)	DT 0.002 (1.065)	loss 6.877 (6.877)	prob 3.120 (3.120)	GS 35.625 (35.625)	mem 7.664
Train: [66][755/750]	BT 0.032 (1.105)	DT 0.001 (1.061)	loss 7.142 (7.142)	prob 2.053 (2.053)	GS 27.188 (27.188)	mem 7.635
epoch 66, total time 834.65
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [67][1/750]	BT 25.310 (25.310)	DT 25.252 (25.252)	loss 7.298 (7.298)	prob 2.037 (2.037)	GS 35.359 (35.359)	mem 38.598
Train: [67][5/750]	BT 0.032 (5.103)	DT 0.001 (5.052)	loss 7.063 (7.063)	prob 2.555 (2.555)	GS 31.891 (31.891)	mem 38.649
Train: [67][10/750]	BT 0.033 (2.577)	DT 0.001 (2.527)	loss 6.747 (6.747)	prob 2.493 (2.493)	GS 31.531 (31.531)	mem 38.617
Train: [67][15/750]	BT 0.034 (2.313)	DT 0.002 (2.262)	loss 6.944 (6.944)	prob 2.190 (2.190)	GS 28.750 (28.750)	mem 38.910
Train: [67][20/750]	BT 1.618 (1.829)	DT 1.579 (1.778)	loss 7.752 (7.752)	prob 2.022 (2.022)	GS 34.641 (34.641)	mem 38.912
Train: [67][25/750]	BT 4.919 (1.775)	DT 4.878 (1.724)	loss 7.657 (7.657)	prob 1.667 (1.667)	GS 32.203 (32.203)	mem 39.110
Train: [67][30/750]	BT 0.074 (1.680)	DT 0.002 (1.629)	loss 7.529 (7.529)	prob 1.753 (1.753)	GS 33.859 (33.859)	mem 39.413
Train: [67][35/750]	BT 0.081 (1.622)	DT 0.022 (1.572)	loss 6.755 (6.755)	prob 2.378 (2.378)	GS 32.516 (32.516)	mem 39.508
Train: [67][40/750]	BT 0.039 (1.581)	DT 0.002 (1.532)	loss 6.925 (6.925)	prob 2.920 (2.920)	GS 36.219 (36.219)	mem 39.698
Train: [67][45/750]	BT 0.035 (1.465)	DT 0.001 (1.417)	loss 7.447 (7.447)	prob 1.577 (1.577)	GS 35.609 (35.609)	mem 39.387
Train: [67][50/750]	BT 8.022 (1.504)	DT 7.950 (1.456)	loss 7.395 (7.395)	prob 2.915 (2.915)	GS 35.125 (35.125)	mem 39.677
Train: [67][55/750]	BT 0.128 (1.376)	DT 0.009 (1.327)	loss 7.357 (7.357)	prob 2.541 (2.541)	GS 30.750 (30.750)	mem 39.578
Train: [67][60/750]	BT 0.039 (1.312)	DT 0.002 (1.264)	loss 7.475 (7.475)	prob 2.309 (2.309)	GS 32.562 (32.562)	mem 39.455
Train: [67][65/750]	BT 0.032 (1.382)	DT 0.002 (1.335)	loss 7.251 (7.251)	prob 2.230 (2.230)	GS 30.266 (30.266)	mem 39.521
Train: [67][70/750]	BT 0.038 (1.288)	DT 0.007 (1.240)	loss 6.785 (6.785)	prob 2.714 (2.714)	GS 32.609 (32.609)	mem 39.521
Train: [67][75/750]	BT 0.043 (1.336)	DT 0.012 (1.289)	loss 7.322 (7.322)	prob 1.951 (1.951)	GS 36.359 (36.359)	mem 39.590
Train: [67][80/750]	BT 0.025 (1.315)	DT 0.001 (1.268)	loss 6.892 (6.892)	prob 3.923 (3.923)	GS 35.094 (35.094)	mem 39.530
Train: [67][85/750]	BT 0.065 (1.241)	DT 0.005 (1.194)	loss 7.470 (7.470)	prob 1.901 (1.901)	GS 28.516 (28.516)	mem 39.600
Train: [67][90/750]	BT 0.023 (1.303)	DT 0.001 (1.256)	loss 7.087 (7.087)	prob 3.467 (3.467)	GS 33.203 (33.203)	mem 39.584
Train: [67][95/750]	BT 0.037 (1.237)	DT 0.006 (1.191)	loss 7.192 (7.192)	prob 2.928 (2.928)	GS 29.016 (29.016)	mem 39.588
Train: [67][100/750]	BT 6.336 (1.320)	DT 6.302 (1.273)	loss 7.142 (7.142)	prob 2.964 (2.964)	GS 35.328 (35.328)	mem 39.605
Train: [67][105/750]	BT 0.085 (1.259)	DT 0.002 (1.213)	loss 7.243 (7.243)	prob 1.871 (1.871)	GS 34.000 (34.000)	mem 39.605
Train: [67][110/750]	BT 0.034 (1.264)	DT 0.002 (1.218)	loss 7.498 (7.498)	prob 2.456 (2.456)	GS 30.906 (30.906)	mem 39.614
Train: [67][115/750]	BT 0.099 (1.282)	DT 0.003 (1.236)	loss 7.030 (7.030)	prob 2.842 (2.842)	GS 32.844 (32.844)	mem 39.633
Train: [67][120/750]	BT 5.758 (1.278)	DT 5.703 (1.232)	loss 7.198 (7.198)	prob 3.353 (3.353)	GS 29.859 (29.859)	mem 39.659
Train: [67][125/750]	BT 0.038 (1.288)	DT 0.005 (1.241)	loss 7.057 (7.057)	prob 3.075 (3.075)	GS 33.203 (33.203)	mem 39.656
Train: [67][130/750]	BT 0.032 (1.240)	DT 0.001 (1.194)	loss 7.520 (7.520)	prob 2.564 (2.564)	GS 31.750 (31.750)	mem 39.659
Train: [67][135/750]	BT 0.033 (1.230)	DT 0.001 (1.183)	loss 7.356 (7.356)	prob 2.208 (2.208)	GS 44.250 (44.250)	mem 39.699
Train: [67][140/750]	BT 0.031 (1.227)	DT 0.001 (1.181)	loss 7.144 (7.144)	prob 3.113 (3.113)	GS 32.688 (32.688)	mem 39.778
Train: [67][145/750]	BT 0.104 (1.237)	DT 0.019 (1.190)	loss 7.236 (7.236)	prob 1.974 (1.974)	GS 26.750 (26.750)	mem 39.945
Train: [67][150/750]	BT 0.073 (1.241)	DT 0.005 (1.195)	loss 7.422 (7.422)	prob 2.838 (2.838)	GS 31.875 (31.875)	mem 39.929
Train: [67][155/750]	BT 0.031 (1.203)	DT 0.001 (1.156)	loss 7.165 (7.165)	prob 3.546 (3.546)	GS 31.906 (31.906)	mem 39.707
Train: [67][160/750]	BT 2.707 (1.242)	DT 2.672 (1.196)	loss 7.420 (7.420)	prob 2.566 (2.566)	GS 34.984 (34.984)	mem 39.722
Train: [67][165/750]	BT 0.050 (1.206)	DT 0.003 (1.160)	loss 7.324 (7.324)	prob 2.582 (2.582)	GS 32.672 (32.672)	mem 39.827
Train: [67][170/750]	BT 0.030 (1.234)	DT 0.001 (1.188)	loss 6.967 (6.967)	prob 3.189 (3.189)	GS 34.250 (34.250)	mem 39.733
Train: [67][175/750]	BT 0.033 (1.200)	DT 0.002 (1.154)	loss 7.774 (7.774)	prob 2.400 (2.400)	GS 33.422 (33.422)	mem 39.736
Train: [67][180/750]	BT 11.924 (1.233)	DT 11.892 (1.188)	loss 7.145 (7.145)	prob 2.806 (2.806)	GS 32.172 (32.172)	mem 39.747
Train: [67][185/750]	BT 0.049 (1.201)	DT 0.009 (1.156)	loss 7.299 (7.299)	prob 2.684 (2.684)	GS 29.781 (29.781)	mem 39.793
Train: [67][190/750]	BT 0.035 (1.173)	DT 0.002 (1.128)	loss 7.375 (7.375)	prob 2.755 (2.755)	GS 32.922 (32.922)	mem 39.886
Train: [67][195/750]	BT 0.051 (1.203)	DT 0.016 (1.158)	loss 7.001 (7.001)	prob 2.436 (2.436)	GS 28.516 (28.516)	mem 39.790
Train: [67][200/750]	BT 0.026 (1.179)	DT 0.001 (1.134)	loss 7.327 (7.327)	prob 3.004 (3.004)	GS 33.672 (33.672)	mem 39.790
Train: [67][205/750]	BT 0.056 (1.212)	DT 0.002 (1.167)	loss 7.190 (7.190)	prob 2.915 (2.915)	GS 28.031 (28.031)	mem 39.760
Train: [67][210/750]	BT 0.024 (1.185)	DT 0.001 (1.139)	loss 7.151 (7.151)	prob 3.024 (3.024)	GS 35.172 (35.172)	mem 39.878
Train: [67][215/750]	BT 0.044 (1.158)	DT 0.001 (1.113)	loss 7.390 (7.390)	prob 2.623 (2.623)	GS 32.062 (32.062)	mem 39.803
Train: [67][220/750]	BT 0.065 (1.182)	DT 0.008 (1.137)	loss 7.245 (7.245)	prob 2.881 (2.881)	GS 35.266 (35.266)	mem 39.881
Train: [67][225/750]	BT 0.069 (1.161)	DT 0.007 (1.115)	loss 7.291 (7.291)	prob 2.846 (2.846)	GS 26.953 (26.953)	mem 39.805
Train: [67][230/750]	BT 0.034 (1.190)	DT 0.001 (1.144)	loss 7.322 (7.322)	prob 2.760 (2.760)	GS 31.672 (31.672)	mem 39.904
Train: [67][235/750]	BT 0.029 (1.166)	DT 0.001 (1.120)	loss 7.098 (7.098)	prob 2.967 (2.967)	GS 30.781 (30.781)	mem 39.967
Train: [67][240/750]	BT 11.821 (1.192)	DT 11.791 (1.146)	loss 6.919 (6.919)	prob 3.207 (3.207)	GS 28.453 (28.453)	mem 39.874
Train: [67][245/750]	BT 0.031 (1.185)	DT 0.001 (1.139)	loss 7.042 (7.042)	prob 3.356 (3.356)	GS 29.906 (29.906)	mem 39.925
Train: [67][250/750]	BT 0.066 (1.162)	DT 0.003 (1.116)	loss 7.079 (7.079)	prob 3.078 (3.078)	GS 34.156 (34.156)	mem 39.895
Train: [67][255/750]	BT 0.030 (1.204)	DT 0.001 (1.158)	loss 7.484 (7.484)	prob 2.478 (2.478)	GS 30.609 (30.609)	mem 39.825
Train: [67][260/750]	BT 0.031 (1.182)	DT 0.001 (1.136)	loss 7.048 (7.048)	prob 3.155 (3.155)	GS 31.922 (31.922)	mem 39.826
Train: [67][265/750]	BT 0.047 (1.160)	DT 0.005 (1.114)	loss 7.620 (7.620)	prob 2.763 (2.763)	GS 32.500 (32.500)	mem 39.829
Train: [67][270/750]	BT 0.080 (1.176)	DT 0.012 (1.130)	loss 7.083 (7.083)	prob 3.699 (3.699)	GS 28.656 (28.656)	mem 39.871
Train: [67][275/750]	BT 0.050 (1.156)	DT 0.009 (1.109)	loss 7.545 (7.545)	prob 2.785 (2.785)	GS 34.375 (34.375)	mem 39.868
Train: [67][280/750]	BT 0.032 (1.179)	DT 0.001 (1.132)	loss 6.852 (6.852)	prob 3.289 (3.289)	GS 36.203 (36.203)	mem 39.910
Train: [67][285/750]	BT 0.089 (1.159)	DT 0.005 (1.112)	loss 7.336 (7.336)	prob 1.988 (1.988)	GS 28.953 (28.953)	mem 40.000
Train: [67][290/750]	BT 9.033 (1.192)	DT 9.001 (1.145)	loss 6.726 (6.726)	prob 3.273 (3.273)	GS 37.562 (37.562)	mem 39.955
Train: [67][295/750]	BT 0.038 (1.172)	DT 0.001 (1.126)	loss 7.272 (7.272)	prob 2.936 (2.936)	GS 32.891 (32.891)	mem 39.958
Train: [67][300/750]	BT 3.135 (1.164)	DT 3.056 (1.117)	loss 7.079 (7.079)	prob 3.028 (3.028)	GS 38.016 (38.016)	mem 39.919
Train: [67][305/750]	BT 0.029 (1.181)	DT 0.002 (1.134)	loss 7.155 (7.155)	prob 2.637 (2.637)	GS 31.641 (31.641)	mem 39.996
Train: [67][310/750]	BT 0.034 (1.163)	DT 0.001 (1.116)	loss 7.281 (7.281)	prob 2.582 (2.582)	GS 32.922 (32.922)	mem 39.939
Train: [67][315/750]	BT 0.066 (1.180)	DT 0.010 (1.133)	loss 7.284 (7.284)	prob 2.235 (2.235)	GS 34.500 (34.500)	mem 39.876
Train: [67][320/750]	BT 0.033 (1.162)	DT 0.002 (1.116)	loss 7.351 (7.351)	prob 2.838 (2.838)	GS 35.922 (35.922)	mem 39.912
Train: [67][325/750]	BT 0.064 (1.173)	DT 0.021 (1.126)	loss 7.406 (7.406)	prob 2.126 (2.126)	GS 31.344 (31.344)	mem 39.924
Train: [67][330/750]	BT 0.033 (1.168)	DT 0.002 (1.121)	loss 7.227 (7.227)	prob 2.735 (2.735)	GS 36.062 (36.062)	mem 40.162
Train: [67][335/750]	BT 0.032 (1.151)	DT 0.002 (1.104)	loss 7.522 (7.522)	prob 2.892 (2.892)	GS 33.453 (33.453)	mem 39.904
Train: [67][340/750]	BT 0.026 (1.177)	DT 0.001 (1.131)	loss 7.074 (7.074)	prob 3.060 (3.060)	GS 32.062 (32.062)	mem 39.932
Train: [67][345/750]	BT 0.091 (1.161)	DT 0.002 (1.114)	loss 7.485 (7.485)	prob 1.953 (1.953)	GS 32.812 (32.812)	mem 39.984
Train: [67][350/750]	BT 8.534 (1.184)	DT 8.499 (1.138)	loss 7.112 (7.112)	prob 2.691 (2.691)	GS 31.953 (31.953)	mem 39.935
Train: [67][355/750]	BT 0.048 (1.168)	DT 0.005 (1.122)	loss 7.349 (7.349)	prob 2.227 (2.227)	GS 24.297 (24.297)	mem 39.935
Train: [67][360/750]	BT 1.582 (1.157)	DT 1.529 (1.110)	loss 6.908 (6.908)	prob 2.297 (2.297)	GS 32.156 (32.156)	mem 39.944
Train: [67][365/750]	BT 0.035 (1.172)	DT 0.002 (1.126)	loss 6.998 (6.998)	prob 2.830 (2.830)	GS 31.609 (31.609)	mem 39.890
Train: [67][370/750]	BT 0.090 (1.157)	DT 0.015 (1.111)	loss 6.738 (6.738)	prob 3.475 (3.475)	GS 32.875 (32.875)	mem 39.919
Train: [67][375/750]	BT 0.057 (1.180)	DT 0.004 (1.134)	loss 7.681 (7.681)	prob 1.861 (1.861)	GS 33.703 (33.703)	mem 39.911
Train: [67][380/750]	BT 0.091 (1.165)	DT 0.021 (1.119)	loss 6.972 (6.972)	prob 3.233 (3.233)	GS 35.656 (35.656)	mem 39.980
Train: [67][385/750]	BT 0.034 (1.178)	DT 0.002 (1.132)	loss 7.540 (7.540)	prob 2.273 (2.273)	GS 31.531 (31.531)	mem 39.937
Train: [67][390/750]	BT 3.582 (1.175)	DT 3.547 (1.129)	loss 6.873 (6.873)	prob 3.369 (3.369)	GS 37.609 (37.609)	mem 40.042
Train: [67][395/750]	BT 0.118 (1.161)	DT 0.031 (1.115)	loss 7.267 (7.267)	prob 2.300 (2.300)	GS 31.016 (31.016)	mem 39.980
Train: [67][400/750]	BT 0.032 (1.168)	DT 0.001 (1.122)	loss 7.383 (7.383)	prob 2.301 (2.301)	GS 34.016 (34.016)	mem 39.861
Train: [67][405/750]	BT 0.086 (1.164)	DT 0.013 (1.118)	loss 7.353 (7.353)	prob 1.665 (1.665)	GS 31.734 (31.734)	mem 40.113
Train: [67][410/750]	BT 0.033 (1.175)	DT 0.001 (1.129)	loss 7.180 (7.180)	prob 2.268 (2.268)	GS 34.406 (34.406)	mem 39.959
Train: [67][415/750]	BT 0.066 (1.173)	DT 0.006 (1.126)	loss 7.267 (7.267)	prob 2.613 (2.613)	GS 30.438 (30.438)	mem 39.976
Train: [67][420/750]	BT 7.402 (1.177)	DT 7.341 (1.131)	loss 7.164 (7.164)	prob 2.557 (2.557)	GS 31.219 (31.219)	mem 40.014
Train: [67][425/750]	BT 0.031 (1.165)	DT 0.001 (1.119)	loss 7.103 (7.103)	prob 2.197 (2.197)	GS 35.922 (35.922)	mem 39.951
Train: [67][430/750]	BT 0.034 (1.167)	DT 0.001 (1.121)	loss 7.007 (7.007)	prob 3.479 (3.479)	GS 39.219 (39.219)	mem 40.017
Train: [67][435/750]	BT 0.037 (1.168)	DT 0.002 (1.122)	loss 7.391 (7.391)	prob 2.777 (2.777)	GS 29.875 (29.875)	mem 40.008
Train: [67][440/750]	BT 0.042 (1.174)	DT 0.015 (1.128)	loss 7.058 (7.058)	prob 2.805 (2.805)	GS 34.344 (34.344)	mem 40.094
Train: [67][445/750]	BT 0.084 (1.181)	DT 0.001 (1.135)	loss 7.420 (7.420)	prob 2.923 (2.923)	GS 26.812 (26.812)	mem 40.067
Train: [67][450/750]	BT 4.108 (1.178)	DT 4.050 (1.132)	loss 7.188 (7.188)	prob 2.682 (2.682)	GS 33.781 (33.781)	mem 39.950
Train: [67][455/750]	BT 0.075 (1.165)	DT 0.008 (1.119)	loss 6.943 (6.943)	prob 3.297 (3.297)	GS 31.984 (31.984)	mem 39.949
Train: [67][460/750]	BT 0.046 (1.174)	DT 0.013 (1.128)	loss 7.029 (7.029)	prob 2.983 (2.983)	GS 33.000 (33.000)	mem 39.966
Train: [67][465/750]	BT 0.032 (1.172)	DT 0.002 (1.126)	loss 7.295 (7.295)	prob 2.233 (2.233)	GS 32.750 (32.750)	mem 39.891
Train: [67][470/750]	BT 0.032 (1.171)	DT 0.001 (1.124)	loss 7.293 (7.293)	prob 2.754 (2.754)	GS 30.672 (30.672)	mem 40.129
Train: [67][475/750]	BT 0.046 (1.176)	DT 0.007 (1.130)	loss 7.248 (7.248)	prob 2.834 (2.834)	GS 35.328 (35.328)	mem 40.066
Train: [67][480/750]	BT 4.078 (1.173)	DT 4.050 (1.127)	loss 7.136 (7.136)	prob 2.913 (2.913)	GS 30.672 (30.672)	mem 39.914
Train: [67][485/750]	BT 0.050 (1.162)	DT 0.005 (1.115)	loss 7.314 (7.314)	prob 2.818 (2.818)	GS 27.484 (27.484)	mem 39.962
Train: [67][490/750]	BT 0.058 (1.167)	DT 0.002 (1.120)	loss 7.304 (7.304)	prob 2.715 (2.715)	GS 34.500 (34.500)	mem 40.002
Train: [67][495/750]	BT 0.029 (1.175)	DT 0.001 (1.128)	loss 7.220 (7.220)	prob 2.382 (2.382)	GS 42.750 (42.750)	mem 39.939
Train: [67][500/750]	BT 0.514 (1.165)	DT 0.482 (1.118)	loss 6.814 (6.814)	prob 3.243 (3.243)	GS 33.984 (33.984)	mem 39.908
Train: [67][505/750]	BT 0.022 (1.177)	DT 0.001 (1.131)	loss 7.084 (7.084)	prob 2.550 (2.550)	GS 30.312 (30.312)	mem 39.992
Train: [67][510/750]	BT 2.097 (1.170)	DT 2.066 (1.124)	loss 6.735 (6.735)	prob 2.648 (2.648)	GS 33.750 (33.750)	mem 39.831
Train: [67][515/750]	BT 0.039 (1.159)	DT 0.001 (1.113)	loss 7.112 (7.112)	prob 2.315 (2.315)	GS 32.672 (32.672)	mem 39.832
Train: [67][520/750]	BT 0.031 (1.167)	DT 0.001 (1.121)	loss 6.707 (6.707)	prob 3.183 (3.183)	GS 33.703 (33.703)	mem 39.960
Train: [67][525/750]	BT 0.066 (1.166)	DT 0.007 (1.120)	loss 7.092 (7.092)	prob 2.298 (2.298)	GS 31.922 (31.922)	mem 40.099
Train: [67][530/750]	BT 0.025 (1.168)	DT 0.001 (1.122)	loss 7.312 (7.312)	prob 2.377 (2.377)	GS 35.562 (35.562)	mem 39.943
Train: [67][535/750]	BT 0.043 (1.174)	DT 0.002 (1.127)	loss 7.379 (7.379)	prob 1.913 (1.913)	GS 32.094 (32.094)	mem 39.951
Train: [67][540/750]	BT 2.018 (1.167)	DT 1.937 (1.120)	loss 6.909 (6.909)	prob 2.844 (2.844)	GS 29.172 (29.172)	mem 40.089
Train: [67][545/750]	BT 0.028 (1.158)	DT 0.001 (1.111)	loss 7.142 (7.142)	prob 2.940 (2.940)	GS 31.812 (31.812)	mem 40.000
Train: [67][550/750]	BT 0.028 (1.166)	DT 0.001 (1.120)	loss 7.121 (7.121)	prob 2.500 (2.500)	GS 29.953 (29.953)	mem 40.030
Train: [67][555/750]	BT 0.031 (1.159)	DT 0.001 (1.112)	loss 6.969 (6.969)	prob 3.511 (3.511)	GS 30.938 (30.938)	mem 40.036
Train: [67][560/750]	BT 0.034 (1.171)	DT 0.002 (1.125)	loss 7.086 (7.086)	prob 3.283 (3.283)	GS 29.750 (29.750)	mem 40.224
Train: [67][565/750]	BT 0.078 (1.161)	DT 0.009 (1.115)	loss 7.012 (7.012)	prob 3.125 (3.125)	GS 31.188 (31.188)	mem 40.043
Train: [67][570/750]	BT 13.085 (1.174)	DT 13.050 (1.129)	loss 6.836 (6.836)	prob 2.751 (2.751)	GS 36.125 (36.125)	mem 40.018
Train: [67][575/750]	BT 0.056 (1.165)	DT 0.014 (1.119)	loss 7.250 (7.250)	prob 2.508 (2.508)	GS 31.531 (31.531)	mem 40.056
Train: [67][580/750]	BT 0.041 (1.155)	DT 0.004 (1.109)	loss 7.313 (7.313)	prob 2.189 (2.189)	GS 34.391 (34.391)	mem 39.968
Train: [67][585/750]	BT 0.028 (1.171)	DT 0.001 (1.126)	loss 7.282 (7.282)	prob 2.544 (2.544)	GS 29.516 (29.516)	mem 39.988
Train: [67][590/750]	BT 0.029 (1.162)	DT 0.001 (1.116)	loss 6.736 (6.736)	prob 2.603 (2.603)	GS 29.672 (29.672)	mem 39.988
Train: [67][595/750]	BT 0.051 (1.170)	DT 0.021 (1.124)	loss 7.226 (7.226)	prob 2.548 (2.548)	GS 31.453 (31.453)	mem 40.041
Train: [67][600/750]	BT 0.032 (1.161)	DT 0.002 (1.115)	loss 7.101 (7.101)	prob 2.596 (2.596)	GS 37.719 (37.719)	mem 40.115
Train: [67][605/750]	BT 0.067 (1.151)	DT 0.001 (1.106)	loss 7.226 (7.226)	prob 3.179 (3.179)	GS 31.000 (31.000)	mem 40.014
Train: [67][610/750]	BT 0.044 (1.166)	DT 0.001 (1.121)	loss 6.949 (6.949)	prob 2.403 (2.403)	GS 32.484 (32.484)	mem 39.900
Train: [67][615/750]	BT 0.053 (1.157)	DT 0.007 (1.111)	loss 7.278 (7.278)	prob 2.342 (2.342)	GS 34.344 (34.344)	mem 39.902
Train: [67][620/750]	BT 0.098 (1.167)	DT 0.015 (1.122)	loss 6.907 (6.907)	prob 3.051 (3.051)	GS 32.312 (32.312)	mem 39.964
Train: [67][625/750]	BT 0.030 (1.158)	DT 0.001 (1.113)	loss 6.828 (6.828)	prob 2.417 (2.417)	GS 33.719 (33.719)	mem 39.964
Train: [67][630/750]	BT 13.782 (1.171)	DT 13.746 (1.126)	loss 6.748 (6.748)	prob 3.008 (3.008)	GS 32.875 (32.875)	mem 40.002
Train: [67][635/750]	BT 0.031 (1.162)	DT 0.001 (1.117)	loss 6.889 (6.889)	prob 3.063 (3.063)	GS 29.281 (29.281)	mem 39.923
Train: [67][640/750]	BT 0.044 (1.154)	DT 0.001 (1.108)	loss 6.987 (6.987)	prob 2.704 (2.704)	GS 35.656 (35.656)	mem 39.923
Train: [67][645/750]	BT 0.043 (1.165)	DT 0.001 (1.120)	loss 7.219 (7.219)	prob 2.983 (2.983)	GS 31.328 (31.328)	mem 39.932
Train: [67][650/750]	BT 0.072 (1.157)	DT 0.013 (1.111)	loss 6.968 (6.968)	prob 2.664 (2.664)	GS 36.484 (36.484)	mem 39.932
Train: [67][655/750]	BT 0.049 (1.169)	DT 0.021 (1.123)	loss 7.167 (7.167)	prob 2.224 (2.224)	GS 33.141 (33.141)	mem 39.875
Train: [67][660/750]	BT 0.032 (1.160)	DT 0.002 (1.114)	loss 6.989 (6.989)	prob 3.189 (3.189)	GS 35.172 (35.172)	mem 39.875
Train: [67][665/750]	BT 0.060 (1.151)	DT 0.002 (1.106)	loss 7.347 (7.347)	prob 2.339 (2.339)	GS 34.906 (34.906)	mem 39.927
Train: [67][670/750]	BT 0.056 (1.161)	DT 0.009 (1.116)	loss 6.866 (6.866)	prob 3.327 (3.327)	GS 36.953 (36.953)	mem 39.933
Train: [67][675/750]	BT 0.033 (1.153)	DT 0.002 (1.108)	loss 6.965 (6.965)	prob 2.458 (2.458)	GS 31.578 (31.578)	mem 40.024
Train: [67][680/750]	BT 0.041 (1.164)	DT 0.011 (1.119)	loss 7.059 (7.059)	prob 2.860 (2.860)	GS 34.953 (34.953)	mem 39.907
Train: [67][685/750]	BT 0.030 (1.155)	DT 0.001 (1.111)	loss 7.039 (7.039)	prob 2.370 (2.370)	GS 33.359 (33.359)	mem 39.907
Train: [67][690/750]	BT 12.445 (1.166)	DT 12.413 (1.121)	loss 7.330 (7.330)	prob 2.167 (2.167)	GS 36.172 (36.172)	mem 39.964
Train: [67][695/750]	BT 0.030 (1.157)	DT 0.001 (1.112)	loss 6.879 (6.879)	prob 2.517 (2.517)	GS 24.891 (24.891)	mem 39.964
Train: [67][700/750]	BT 0.033 (1.149)	DT 0.001 (1.105)	loss 6.780 (6.780)	prob 2.941 (2.941)	GS 32.828 (32.828)	mem 39.964
Train: [67][705/750]	BT 0.028 (1.157)	DT 0.001 (1.112)	loss 7.207 (7.207)	prob 2.539 (2.539)	GS 31.469 (31.469)	mem 39.988
Train: [67][710/750]	BT 0.045 (1.152)	DT 0.001 (1.107)	loss 6.936 (6.936)	prob 2.631 (2.631)	GS 28.438 (28.438)	mem 40.036
Train: [67][715/750]	BT 0.033 (1.160)	DT 0.001 (1.115)	loss 7.143 (7.143)	prob 2.471 (2.471)	GS 31.875 (31.875)	mem 40.014
Train: [67][720/750]	BT 1.973 (1.154)	DT 1.929 (1.110)	loss 6.982 (6.982)	prob 2.702 (2.702)	GS 32.188 (32.188)	mem 39.980
Train: [67][725/750]	BT 0.043 (1.147)	DT 0.002 (1.102)	loss 7.287 (7.287)	prob 2.408 (2.408)	GS 31.078 (31.078)	mem 39.948
Train: [67][730/750]	BT 0.024 (1.151)	DT 0.001 (1.106)	loss 7.116 (7.116)	prob 2.144 (2.144)	GS 32.891 (32.891)	mem 39.754
Train: [67][735/750]	BT 0.076 (1.147)	DT 0.001 (1.103)	loss 7.037 (7.037)	prob 2.559 (2.559)	GS 28.312 (28.312)	mem 39.576
Train: [67][740/750]	BT 0.024 (1.149)	DT 0.001 (1.105)	loss 6.827 (6.827)	prob 3.052 (3.052)	GS 34.781 (34.781)	mem 10.524
Train: [67][745/750]	BT 0.028 (1.143)	DT 0.001 (1.098)	loss 7.444 (7.444)	prob 1.820 (1.820)	GS 30.500 (30.500)	mem 10.506
Train: [67][750/750]	BT 2.410 (1.138)	DT 2.377 (1.094)	loss 6.939 (6.939)	prob 3.150 (3.150)	GS 32.781 (32.781)	mem 8.623
Train: [67][755/750]	BT 0.027 (1.131)	DT 0.001 (1.087)	loss 7.317 (7.317)	prob 2.289 (2.289)	GS 27.562 (27.562)	mem 7.573
epoch 67, total time 854.23
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [68][1/750]	BT 22.034 (22.034)	DT 21.982 (21.982)	loss 7.082 (7.082)	prob 2.726 (2.726)	GS 32.188 (32.188)	mem 38.866
Train: [68][5/750]	BT 0.036 (4.992)	DT 0.004 (4.936)	loss 7.084 (7.084)	prob 2.394 (2.394)	GS 27.797 (27.797)	mem 38.834
Train: [68][10/750]	BT 0.146 (2.525)	DT 0.008 (2.469)	loss 6.672 (6.672)	prob 3.546 (3.546)	GS 32.828 (32.828)	mem 39.134
Train: [68][15/750]	BT 0.161 (2.566)	DT 0.003 (2.504)	loss 6.732 (6.732)	prob 3.132 (3.132)	GS 33.828 (33.828)	mem 38.807
Train: [68][20/750]	BT 0.033 (1.968)	DT 0.001 (1.911)	loss 6.803 (6.803)	prob 3.064 (3.064)	GS 35.438 (35.438)	mem 38.806
Train: [68][25/750]	BT 1.047 (1.626)	DT 0.935 (1.569)	loss 6.903 (6.903)	prob 2.721 (2.721)	GS 25.484 (25.484)	mem 38.808
Train: [68][30/750]	BT 0.075 (1.786)	DT 0.001 (1.732)	loss 6.986 (6.986)	prob 2.680 (2.680)	GS 30.953 (30.953)	mem 38.884
Train: [68][35/750]	BT 0.033 (1.541)	DT 0.002 (1.485)	loss 6.779 (6.779)	prob 2.813 (2.813)	GS 29.953 (29.953)	mem 38.936
Train: [68][40/750]	BT 0.983 (1.678)	DT 0.947 (1.624)	loss 6.785 (6.785)	prob 2.975 (2.975)	GS 33.703 (33.703)	mem 38.957
Train: [68][45/750]	BT 0.063 (1.497)	DT 0.012 (1.445)	loss 7.323 (7.323)	prob 2.522 (2.522)	GS 28.062 (28.062)	mem 39.068
Train: [68][50/750]	BT 10.486 (1.561)	DT 10.453 (1.510)	loss 6.947 (6.947)	prob 2.774 (2.774)	GS 34.922 (34.922)	mem 38.972
Train: [68][55/750]	BT 0.039 (1.422)	DT 0.001 (1.373)	loss 6.953 (6.953)	prob 2.786 (2.786)	GS 30.188 (30.188)	mem 38.973
Train: [68][60/750]	BT 0.040 (1.308)	DT 0.001 (1.259)	loss 6.938 (6.938)	prob 2.219 (2.219)	GS 34.828 (34.828)	mem 39.033
Train: [68][65/750]	BT 0.034 (1.431)	DT 0.007 (1.382)	loss 7.342 (7.342)	prob 2.338 (2.338)	GS 26.453 (26.453)	mem 39.047
Train: [68][70/750]	BT 0.051 (1.332)	DT 0.009 (1.283)	loss 6.996 (6.996)	prob 3.139 (3.139)	GS 31.406 (31.406)	mem 39.047
Train: [68][75/750]	BT 0.053 (1.420)	DT 0.009 (1.372)	loss 6.934 (6.934)	prob 2.489 (2.489)	GS 28.188 (28.188)	mem 39.040
Train: [68][80/750]	BT 0.031 (1.335)	DT 0.007 (1.287)	loss 6.961 (6.961)	prob 3.148 (3.148)	GS 32.516 (32.516)	mem 39.041
Train: [68][85/750]	BT 0.074 (1.261)	DT 0.016 (1.212)	loss 6.694 (6.694)	prob 3.098 (3.098)	GS 29.125 (29.125)	mem 39.043
Train: [68][90/750]	BT 0.056 (1.308)	DT 0.001 (1.259)	loss 7.064 (7.064)	prob 2.026 (2.026)	GS 33.750 (33.750)	mem 39.033
Train: [68][95/750]	BT 0.045 (1.293)	DT 0.008 (1.245)	loss 7.210 (7.210)	prob 2.194 (2.194)	GS 33.359 (33.359)	mem 39.087
Train: [68][100/750]	BT 0.050 (1.383)	DT 0.009 (1.335)	loss 6.676 (6.676)	prob 3.515 (3.515)	GS 30.438 (30.438)	mem 39.222
Train: [68][105/750]	BT 0.063 (1.320)	DT 0.002 (1.272)	loss 7.184 (7.184)	prob 2.823 (2.823)	GS 27.828 (27.828)	mem 39.152
Train: [68][110/750]	BT 13.866 (1.388)	DT 13.833 (1.340)	loss 6.897 (6.897)	prob 2.753 (2.753)	GS 37.656 (37.656)	mem 39.218
Train: [68][115/750]	BT 0.045 (1.330)	DT 0.003 (1.282)	loss 6.958 (6.958)	prob 3.219 (3.219)	GS 34.734 (34.734)	mem 39.307
Train: [68][120/750]	BT 0.031 (1.276)	DT 0.001 (1.229)	loss 6.786 (6.786)	prob 3.414 (3.414)	GS 35.953 (35.953)	mem 39.220
Train: [68][125/750]	BT 0.024 (1.330)	DT 0.001 (1.283)	loss 6.885 (6.885)	prob 2.948 (2.948)	GS 33.578 (33.578)	mem 39.229
Train: [68][130/750]	BT 0.059 (1.281)	DT 0.007 (1.234)	loss 6.881 (6.881)	prob 2.529 (2.529)	GS 33.297 (33.297)	mem 39.360
Train: [68][135/750]	BT 0.025 (1.337)	DT 0.001 (1.290)	loss 7.092 (7.092)	prob 3.370 (3.370)	GS 29.438 (29.438)	mem 39.234
Train: [68][140/750]	BT 0.033 (1.291)	DT 0.002 (1.245)	loss 7.052 (7.052)	prob 2.232 (2.232)	GS 32.516 (32.516)	mem 39.237
Train: [68][145/750]	BT 0.056 (1.248)	DT 0.005 (1.202)	loss 7.068 (7.068)	prob 2.859 (2.859)	GS 28.297 (28.297)	mem 39.500
Train: [68][150/750]	BT 0.032 (1.291)	DT 0.001 (1.245)	loss 6.852 (6.852)	prob 3.154 (3.154)	GS 35.891 (35.891)	mem 39.226
Train: [68][155/750]	BT 0.046 (1.251)	DT 0.004 (1.205)	loss 7.346 (7.346)	prob 3.279 (3.279)	GS 29.422 (29.422)	mem 39.235
Train: [68][160/750]	BT 0.027 (1.283)	DT 0.001 (1.237)	loss 6.813 (6.813)	prob 2.993 (2.993)	GS 32.844 (32.844)	mem 39.296
Train: [68][165/750]	BT 0.035 (1.245)	DT 0.010 (1.199)	loss 6.898 (6.898)	prob 3.046 (3.046)	GS 27.375 (27.375)	mem 39.571
Train: [68][170/750]	BT 11.939 (1.280)	DT 11.907 (1.234)	loss 6.940 (6.940)	prob 3.161 (3.161)	GS 36.953 (36.953)	mem 39.316
Train: [68][175/750]	BT 0.022 (1.244)	DT 0.001 (1.199)	loss 6.976 (6.976)	prob 3.097 (3.097)	GS 32.359 (32.359)	mem 39.256
Train: [68][180/750]	BT 0.035 (1.211)	DT 0.002 (1.166)	loss 6.765 (6.765)	prob 2.753 (2.753)	GS 32.734 (32.734)	mem 39.258
Train: [68][185/750]	BT 0.040 (1.252)	DT 0.002 (1.208)	loss 6.830 (6.830)	prob 2.553 (2.553)	GS 30.984 (30.984)	mem 39.390
Train: [68][190/750]	BT 0.030 (1.221)	DT 0.006 (1.176)	loss 6.955 (6.955)	prob 2.490 (2.490)	GS 34.172 (34.172)	mem 39.216
Train: [68][195/750]	BT 0.047 (1.263)	DT 0.001 (1.219)	loss 6.916 (6.916)	prob 2.389 (2.389)	GS 35.375 (35.375)	mem 39.426
Train: [68][200/750]	BT 0.062 (1.233)	DT 0.002 (1.189)	loss 7.239 (7.239)	prob 3.116 (3.116)	GS 34.578 (34.578)	mem 39.387
Train: [68][205/750]	BT 0.058 (1.204)	DT 0.003 (1.160)	loss 6.750 (6.750)	prob 2.962 (2.962)	GS 31.203 (31.203)	mem 39.389
Train: [68][210/750]	BT 0.047 (1.233)	DT 0.001 (1.189)	loss 7.172 (7.172)	prob 3.425 (3.425)	GS 32.078 (32.078)	mem 39.621
Train: [68][215/750]	BT 0.038 (1.206)	DT 0.001 (1.161)	loss 6.845 (6.845)	prob 2.694 (2.694)	GS 28.859 (28.859)	mem 39.575
Train: [68][220/750]	BT 0.027 (1.235)	DT 0.001 (1.191)	loss 7.001 (7.001)	prob 2.984 (2.984)	GS 32.375 (32.375)	mem 39.881
Train: [68][225/750]	BT 0.108 (1.209)	DT 0.002 (1.165)	loss 6.869 (6.869)	prob 3.003 (3.003)	GS 32.625 (32.625)	mem 40.016
Train: [68][230/750]	BT 11.908 (1.236)	DT 11.865 (1.192)	loss 6.930 (6.930)	prob 2.939 (2.939)	GS 34.203 (34.203)	mem 39.577
Train: [68][235/750]	BT 0.029 (1.211)	DT 0.001 (1.167)	loss 6.994 (6.994)	prob 2.634 (2.634)	GS 29.047 (29.047)	mem 39.678
Train: [68][240/750]	BT 0.061 (1.195)	DT 0.004 (1.150)	loss 6.930 (6.930)	prob 2.090 (2.090)	GS 31.625 (31.625)	mem 39.538
Train: [68][245/750]	BT 0.032 (1.217)	DT 0.002 (1.172)	loss 7.092 (7.092)	prob 2.840 (2.840)	GS 41.547 (41.547)	mem 39.773
Train: [68][250/750]	BT 4.432 (1.211)	DT 4.388 (1.167)	loss 6.825 (6.825)	prob 2.748 (2.748)	GS 34.016 (34.016)	mem 39.632
Train: [68][255/750]	BT 0.052 (1.219)	DT 0.005 (1.175)	loss 7.065 (7.065)	prob 2.162 (2.162)	GS 36.391 (36.391)	mem 39.757
Train: [68][260/750]	BT 1.322 (1.202)	DT 1.268 (1.157)	loss 6.821 (6.821)	prob 3.220 (3.220)	GS 33.141 (33.141)	mem 39.669
Train: [68][265/750]	BT 0.033 (1.198)	DT 0.001 (1.153)	loss 7.095 (7.095)	prob 2.859 (2.859)	GS 32.469 (32.469)	mem 39.662
Train: [68][270/750]	BT 0.032 (1.192)	DT 0.001 (1.147)	loss 6.738 (6.738)	prob 2.479 (2.479)	GS 35.844 (35.844)	mem 39.673
Train: [68][275/750]	BT 0.072 (1.199)	DT 0.019 (1.154)	loss 7.021 (7.021)	prob 2.947 (2.947)	GS 32.656 (32.656)	mem 39.693
Train: [68][280/750]	BT 0.032 (1.197)	DT 0.001 (1.152)	loss 6.887 (6.887)	prob 2.632 (2.632)	GS 33.469 (33.469)	mem 39.658
Train: [68][285/750]	BT 0.032 (1.207)	DT 0.001 (1.162)	loss 6.871 (6.871)	prob 2.859 (2.859)	GS 33.156 (33.156)	mem 39.766
Train: [68][290/750]	BT 4.689 (1.204)	DT 4.646 (1.158)	loss 7.097 (7.097)	prob 3.197 (3.197)	GS 34.266 (34.266)	mem 39.786
Train: [68][295/750]	BT 0.053 (1.185)	DT 0.002 (1.139)	loss 6.809 (6.809)	prob 3.418 (3.418)	GS 30.297 (30.297)	mem 39.689
Train: [68][300/750]	BT 0.076 (1.190)	DT 0.007 (1.144)	loss 6.808 (6.808)	prob 2.771 (2.771)	GS 35.562 (35.562)	mem 39.683
Train: [68][305/750]	BT 0.082 (1.193)	DT 0.007 (1.147)	loss 6.790 (6.790)	prob 3.235 (3.235)	GS 34.609 (34.609)	mem 40.154
Train: [68][310/750]	BT 0.032 (1.194)	DT 0.001 (1.147)	loss 6.814 (6.814)	prob 2.228 (2.228)	GS 34.062 (34.062)	mem 39.788
Train: [68][315/750]	BT 0.041 (1.187)	DT 0.010 (1.140)	loss 7.072 (7.072)	prob 2.991 (2.991)	GS 31.156 (31.156)	mem 39.851
Train: [68][320/750]	BT 7.484 (1.192)	DT 7.422 (1.146)	loss 6.875 (6.875)	prob 3.303 (3.303)	GS 32.312 (32.312)	mem 39.941
Train: [68][325/750]	BT 0.028 (1.175)	DT 0.001 (1.128)	loss 6.792 (6.792)	prob 2.696 (2.696)	GS 31.562 (31.562)	mem 39.841
Train: [68][330/750]	BT 0.025 (1.170)	DT 0.001 (1.123)	loss 6.961 (6.961)	prob 2.624 (2.624)	GS 31.188 (31.188)	mem 39.847
Train: [68][335/750]	BT 0.107 (1.182)	DT 0.042 (1.135)	loss 6.739 (6.739)	prob 2.610 (2.610)	GS 33.797 (33.797)	mem 39.769
Train: [68][340/750]	BT 0.050 (1.180)	DT 0.007 (1.134)	loss 6.969 (6.969)	prob 2.590 (2.590)	GS 34.141 (34.141)	mem 39.860
Train: [68][345/750]	BT 0.042 (1.177)	DT 0.002 (1.131)	loss 6.779 (6.779)	prob 2.764 (2.764)	GS 30.172 (30.172)	mem 39.926
Train: [68][350/750]	BT 6.446 (1.182)	DT 6.312 (1.136)	loss 6.948 (6.948)	prob 2.438 (2.438)	GS 35.000 (35.000)	mem 40.030
Train: [68][355/750]	BT 0.085 (1.166)	DT 0.010 (1.120)	loss 7.000 (7.000)	prob 2.835 (2.835)	GS 30.500 (30.500)	mem 39.926
Train: [68][360/750]	BT 0.066 (1.171)	DT 0.002 (1.125)	loss 7.116 (7.116)	prob 1.980 (1.980)	GS 35.172 (35.172)	mem 39.963
Train: [68][365/750]	BT 0.063 (1.178)	DT 0.018 (1.132)	loss 7.010 (7.010)	prob 2.871 (2.871)	GS 30.625 (30.625)	mem 39.873
Train: [68][370/750]	BT 3.402 (1.172)	DT 3.365 (1.126)	loss 6.848 (6.848)	prob 3.249 (3.249)	GS 29.438 (29.438)	mem 40.111
Train: [68][375/750]	BT 0.050 (1.180)	DT 0.001 (1.134)	loss 6.812 (6.812)	prob 2.579 (2.579)	GS 31.000 (31.000)	mem 39.952
Train: [68][380/750]	BT 0.043 (1.165)	DT 0.002 (1.119)	loss 6.818 (6.818)	prob 2.731 (2.731)	GS 30.172 (30.172)	mem 39.986
Train: [68][385/750]	BT 0.051 (1.168)	DT 0.001 (1.122)	loss 6.960 (6.960)	prob 2.675 (2.675)	GS 31.484 (31.484)	mem 39.924
Train: [68][390/750]	BT 0.028 (1.171)	DT 0.001 (1.125)	loss 6.957 (6.957)	prob 2.335 (2.335)	GS 29.391 (29.391)	mem 39.931
Train: [68][395/750]	BT 0.031 (1.165)	DT 0.001 (1.118)	loss 6.897 (6.897)	prob 2.679 (2.679)	GS 31.969 (31.969)	mem 39.936
Train: [68][400/750]	BT 0.021 (1.177)	DT 0.001 (1.131)	loss 7.042 (7.042)	prob 3.096 (3.096)	GS 33.078 (33.078)	mem 39.826
Train: [68][405/750]	BT 0.040 (1.163)	DT 0.003 (1.117)	loss 7.097 (7.097)	prob 2.210 (2.210)	GS 25.812 (25.812)	mem 39.834
Train: [68][410/750]	BT 12.014 (1.178)	DT 11.927 (1.132)	loss 6.759 (6.759)	prob 3.416 (3.416)	GS 28.406 (28.406)	mem 39.913
Train: [68][415/750]	BT 0.040 (1.165)	DT 0.011 (1.119)	loss 6.943 (6.943)	prob 2.877 (2.877)	GS 32.094 (32.094)	mem 39.913
Train: [68][420/750]	BT 0.075 (1.151)	DT 0.011 (1.105)	loss 6.846 (6.846)	prob 2.936 (2.936)	GS 30.922 (30.922)	mem 39.916
Train: [68][425/750]	BT 0.028 (1.169)	DT 0.001 (1.123)	loss 7.099 (7.099)	prob 3.069 (3.069)	GS 32.406 (32.406)	mem 39.918
Train: [68][430/750]	BT 0.027 (1.156)	DT 0.001 (1.110)	loss 6.811 (6.811)	prob 2.915 (2.915)	GS 31.547 (31.547)	mem 39.934
Train: [68][435/750]	BT 0.081 (1.177)	DT 0.010 (1.131)	loss 7.172 (7.172)	prob 3.112 (3.112)	GS 37.812 (37.812)	mem 39.962
Train: [68][440/750]	BT 0.082 (1.164)	DT 0.002 (1.118)	loss 6.958 (6.958)	prob 3.508 (3.508)	GS 33.875 (33.875)	mem 39.963
Train: [68][445/750]	BT 0.038 (1.151)	DT 0.002 (1.105)	loss 7.080 (7.080)	prob 3.086 (3.086)	GS 30.453 (30.453)	mem 39.964
Train: [68][450/750]	BT 0.074 (1.166)	DT 0.013 (1.120)	loss 6.978 (6.978)	prob 3.560 (3.560)	GS 39.328 (39.328)	mem 39.988
Train: [68][455/750]	BT 0.101 (1.154)	DT 0.022 (1.107)	loss 7.450 (7.450)	prob 2.277 (2.277)	GS 29.000 (29.000)	mem 39.982
Train: [68][460/750]	BT 0.022 (1.168)	DT 0.001 (1.122)	loss 7.024 (7.024)	prob 2.794 (2.794)	GS 35.516 (35.516)	mem 39.987
Train: [68][465/750]	BT 0.033 (1.156)	DT 0.001 (1.109)	loss 7.354 (7.354)	prob 2.247 (2.247)	GS 35.203 (35.203)	mem 39.990
Train: [68][470/750]	BT 14.821 (1.175)	DT 14.784 (1.129)	loss 6.955 (6.955)	prob 2.854 (2.854)	GS 35.391 (35.391)	mem 40.126
Train: [68][475/750]	BT 0.082 (1.163)	DT 0.005 (1.117)	loss 6.968 (6.968)	prob 2.838 (2.838)	GS 27.219 (27.219)	mem 39.995
Train: [68][480/750]	BT 0.036 (1.152)	DT 0.001 (1.106)	loss 7.009 (7.009)	prob 2.887 (2.887)	GS 32.797 (32.797)	mem 40.072
Train: [68][485/750]	BT 0.032 (1.163)	DT 0.002 (1.117)	loss 6.912 (6.912)	prob 2.902 (2.902)	GS 33.000 (33.000)	mem 40.165
Train: [68][490/750]	BT 0.179 (1.152)	DT 0.013 (1.106)	loss 6.922 (6.922)	prob 2.952 (2.952)	GS 35.781 (35.781)	mem 40.079
Train: [68][495/750]	BT 0.032 (1.162)	DT 0.003 (1.116)	loss 7.150 (7.150)	prob 2.348 (2.348)	GS 33.578 (33.578)	mem 39.890
Train: [68][500/750]	BT 0.022 (1.152)	DT 0.001 (1.106)	loss 6.848 (6.848)	prob 2.501 (2.501)	GS 33.609 (33.609)	mem 39.898
Train: [68][505/750]	BT 0.028 (1.141)	DT 0.001 (1.095)	loss 7.130 (7.130)	prob 2.306 (2.306)	GS 32.859 (32.859)	mem 39.980
Train: [68][510/750]	BT 0.292 (1.159)	DT 0.261 (1.113)	loss 6.814 (6.814)	prob 2.827 (2.827)	GS 32.562 (32.562)	mem 39.896
Train: [68][515/750]	BT 0.025 (1.148)	DT 0.001 (1.103)	loss 6.969 (6.969)	prob 2.630 (2.630)	GS 34.469 (34.469)	mem 39.912
Train: [68][520/750]	BT 0.070 (1.158)	DT 0.011 (1.112)	loss 6.808 (6.808)	prob 3.352 (3.352)	GS 31.656 (31.656)	mem 39.971
Train: [68][525/750]	BT 0.123 (1.150)	DT 0.035 (1.104)	loss 7.010 (7.010)	prob 3.010 (3.010)	GS 28.953 (28.953)	mem 39.972
Train: [68][530/750]	BT 11.317 (1.161)	DT 11.272 (1.115)	loss 6.992 (6.992)	prob 2.967 (2.967)	GS 31.234 (31.234)	mem 39.882
Train: [68][535/750]	BT 0.049 (1.153)	DT 0.012 (1.107)	loss 7.169 (7.169)	prob 2.510 (2.510)	GS 30.656 (30.656)	mem 39.826
Train: [68][540/750]	BT 0.037 (1.143)	DT 0.003 (1.097)	loss 7.001 (7.001)	prob 3.383 (3.383)	GS 36.891 (36.891)	mem 39.936
Train: [68][545/750]	BT 0.036 (1.148)	DT 0.002 (1.102)	loss 6.997 (6.997)	prob 3.088 (3.088)	GS 30.406 (30.406)	mem 39.909
Train: [68][550/750]	BT 0.119 (1.141)	DT 0.001 (1.095)	loss 7.075 (7.075)	prob 3.048 (3.048)	GS 33.438 (33.438)	mem 39.968
Train: [68][555/750]	BT 0.030 (1.154)	DT 0.001 (1.108)	loss 7.292 (7.292)	prob 3.204 (3.204)	GS 29.781 (29.781)	mem 39.964
Train: [68][560/750]	BT 0.039 (1.144)	DT 0.003 (1.098)	loss 6.906 (6.906)	prob 2.899 (2.899)	GS 33.312 (33.312)	mem 40.068
Train: [68][565/750]	BT 0.029 (1.135)	DT 0.001 (1.088)	loss 7.229 (7.229)	prob 3.015 (3.015)	GS 30.156 (30.156)	mem 40.022
Train: [68][570/750]	BT 0.030 (1.150)	DT 0.001 (1.104)	loss 6.843 (6.843)	prob 3.433 (3.433)	GS 34.000 (34.000)	mem 39.989
Train: [68][575/750]	BT 0.063 (1.140)	DT 0.001 (1.094)	loss 7.076 (7.076)	prob 3.005 (3.005)	GS 31.172 (31.172)	mem 39.989
Train: [68][580/750]	BT 0.046 (1.153)	DT 0.012 (1.107)	loss 7.277 (7.277)	prob 2.270 (2.270)	GS 33.828 (33.828)	mem 39.998
Train: [68][585/750]	BT 0.042 (1.144)	DT 0.001 (1.098)	loss 6.930 (6.930)	prob 2.458 (2.458)	GS 29.312 (29.312)	mem 40.000
Train: [68][590/750]	BT 10.806 (1.153)	DT 10.772 (1.107)	loss 7.023 (7.023)	prob 3.264 (3.264)	GS 32.781 (32.781)	mem 39.966
Train: [68][595/750]	BT 0.032 (1.143)	DT 0.002 (1.098)	loss 6.954 (6.954)	prob 2.941 (2.941)	GS 32.219 (32.219)	mem 39.966
Train: [68][600/750]	BT 0.032 (1.134)	DT 0.002 (1.088)	loss 6.922 (6.922)	prob 3.031 (3.031)	GS 33.891 (33.891)	mem 39.967
Train: [68][605/750]	BT 0.042 (1.144)	DT 0.010 (1.098)	loss 6.989 (6.989)	prob 2.803 (2.803)	GS 31.359 (31.359)	mem 40.025
Train: [68][610/750]	BT 0.022 (1.135)	DT 0.001 (1.089)	loss 7.092 (7.092)	prob 3.107 (3.107)	GS 31.969 (31.969)	mem 40.027
Train: [68][615/750]	BT 0.054 (1.150)	DT 0.010 (1.105)	loss 7.011 (7.011)	prob 2.765 (2.765)	GS 30.031 (30.031)	mem 40.029
Train: [68][620/750]	BT 0.033 (1.141)	DT 0.001 (1.096)	loss 7.120 (7.120)	prob 3.152 (3.152)	GS 32.766 (32.766)	mem 40.074
Train: [68][625/750]	BT 0.046 (1.132)	DT 0.003 (1.087)	loss 7.101 (7.101)	prob 2.541 (2.541)	GS 28.203 (28.203)	mem 40.030
Train: [68][630/750]	BT 0.052 (1.144)	DT 0.004 (1.099)	loss 6.859 (6.859)	prob 3.274 (3.274)	GS 30.938 (30.938)	mem 40.189
Train: [68][635/750]	BT 0.063 (1.136)	DT 0.023 (1.090)	loss 7.313 (7.313)	prob 2.867 (2.867)	GS 29.609 (29.609)	mem 40.026
Train: [68][640/750]	BT 0.023 (1.149)	DT 0.001 (1.104)	loss 6.779 (6.779)	prob 3.374 (3.374)	GS 32.172 (32.172)	mem 39.987
Train: [68][645/750]	BT 0.030 (1.140)	DT 0.001 (1.095)	loss 6.940 (6.940)	prob 2.889 (2.889)	GS 30.469 (30.469)	mem 39.988
Train: [68][650/750]	BT 13.138 (1.152)	DT 13.108 (1.107)	loss 6.795 (6.795)	prob 2.711 (2.711)	GS 34.734 (34.734)	mem 39.985
Train: [68][655/750]	BT 0.026 (1.144)	DT 0.001 (1.099)	loss 7.080 (7.080)	prob 2.151 (2.151)	GS 30.375 (30.375)	mem 39.987
arpack error, retry= 0
arpack error, retry= 0
Train: [68][660/750]	BT 0.048 (1.135)	DT 0.008 (1.090)	loss 6.700 (6.700)	prob 3.061 (3.061)	GS 31.562 (31.562)	mem 40.017
Train: [68][665/750]	BT 0.036 (1.148)	DT 0.012 (1.103)	loss 7.157 (7.157)	prob 1.851 (1.851)	GS 28.516 (28.516)	mem 39.953
Train: [68][670/750]	BT 0.132 (1.140)	DT 0.008 (1.095)	loss 7.007 (7.007)	prob 3.040 (3.040)	GS 32.281 (32.281)	mem 39.951
Train: [68][675/750]	BT 0.074 (1.151)	DT 0.012 (1.106)	loss 7.858 (7.858)	prob 1.515 (1.515)	GS 33.922 (33.922)	mem 40.163
Train: [68][680/750]	BT 0.070 (1.143)	DT 0.011 (1.098)	loss 7.019 (7.019)	prob 2.543 (2.543)	GS 36.469 (36.469)	mem 39.967
Train: [68][685/750]	BT 0.033 (1.135)	DT 0.002 (1.090)	loss 6.815 (6.815)	prob 2.921 (2.921)	GS 30.438 (30.438)	mem 39.967
Train: [68][690/750]	BT 0.031 (1.146)	DT 0.001 (1.101)	loss 6.867 (6.867)	prob 2.041 (2.041)	GS 29.875 (29.875)	mem 39.946
Train: [68][695/750]	BT 0.024 (1.138)	DT 0.001 (1.093)	loss 6.709 (6.709)	prob 2.888 (2.888)	GS 30.438 (30.438)	mem 39.947
Train: [68][700/750]	BT 0.032 (1.150)	DT 0.001 (1.106)	loss 6.832 (6.832)	prob 2.966 (2.966)	GS 32.172 (32.172)	mem 39.960
Train: [68][705/750]	BT 0.033 (1.142)	DT 0.001 (1.098)	loss 7.144 (7.144)	prob 2.262 (2.262)	GS 31.359 (31.359)	mem 40.068
Train: [68][710/750]	BT 12.511 (1.152)	DT 12.453 (1.108)	loss 6.906 (6.906)	prob 2.654 (2.654)	GS 33.906 (33.906)	mem 40.220
Train: [68][715/750]	BT 0.022 (1.144)	DT 0.001 (1.100)	loss 7.209 (7.209)	prob 2.667 (2.667)	GS 27.938 (27.938)	mem 40.019
Train: [68][720/750]	BT 0.051 (1.137)	DT 0.014 (1.092)	loss 7.104 (7.104)	prob 2.033 (2.033)	GS 32.156 (32.156)	mem 40.019
Train: [68][725/750]	BT 0.022 (1.146)	DT 0.001 (1.102)	loss 6.877 (6.877)	prob 3.043 (3.043)	GS 31.703 (31.703)	mem 39.850
Train: [68][730/750]	BT 0.092 (1.139)	DT 0.001 (1.094)	loss 6.945 (6.945)	prob 2.639 (2.639)	GS 35.266 (35.266)	mem 39.851
Train: [68][735/750]	BT 0.030 (1.144)	DT 0.001 (1.100)	loss 6.743 (6.743)	prob 3.102 (3.102)	GS 37.141 (37.141)	mem 36.455
Train: [68][740/750]	BT 0.025 (1.137)	DT 0.001 (1.092)	loss 7.119 (7.119)	prob 2.392 (2.392)	GS 31.484 (31.484)	mem 36.454
Train: [68][745/750]	BT 0.020 (1.129)	DT 0.001 (1.085)	loss 6.611 (6.611)	prob 2.525 (2.525)	GS 31.469 (31.469)	mem 36.454
Train: [68][750/750]	BT 0.024 (1.124)	DT 0.001 (1.080)	loss 7.030 (7.030)	prob 3.208 (3.208)	GS 35.219 (35.219)	mem 7.647
Train: [68][755/750]	BT 0.028 (1.117)	DT 0.001 (1.073)	loss 7.251 (7.251)	prob 3.213 (3.213)	GS 25.688 (25.688)	mem 7.647
epoch 68, total time 843.69
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [69][1/750]	BT 22.309 (22.309)	DT 22.191 (22.191)	loss 6.898 (6.898)	prob 3.542 (3.542)	GS 34.250 (34.250)	mem 38.469
Train: [69][5/750]	BT 0.135 (5.302)	DT 0.001 (5.234)	loss 6.749 (6.749)	prob 3.304 (3.304)	GS 35.609 (35.609)	mem 38.597
Train: [69][10/750]	BT 0.062 (2.747)	DT 0.004 (2.686)	loss 6.838 (6.838)	prob 2.982 (2.982)	GS 36.109 (36.109)	mem 38.577
Train: [69][15/750]	BT 0.096 (2.961)	DT 0.026 (2.900)	loss 7.049 (7.049)	prob 3.091 (3.091)	GS 31.625 (31.625)	mem 38.862
Train: [69][20/750]	BT 0.033 (2.229)	DT 0.001 (2.176)	loss 6.908 (6.908)	prob 2.637 (2.637)	GS 32.078 (32.078)	mem 38.865
Train: [69][25/750]	BT 1.268 (1.843)	DT 1.236 (1.792)	loss 7.130 (7.130)	prob 2.574 (2.574)	GS 34.078 (34.078)	mem 38.976
Train: [69][30/750]	BT 0.030 (1.984)	DT 0.001 (1.934)	loss 6.871 (6.871)	prob 3.060 (3.060)	GS 29.500 (29.500)	mem 38.888
Train: [69][35/750]	BT 0.032 (1.705)	DT 0.001 (1.658)	loss 6.734 (6.734)	prob 2.386 (2.386)	GS 34.188 (34.188)	mem 38.890
Train: [69][40/750]	BT 0.072 (1.812)	DT 0.001 (1.766)	loss 6.905 (6.905)	prob 2.639 (2.639)	GS 33.250 (33.250)	mem 38.938
Train: [69][45/750]	BT 0.031 (1.617)	DT 0.001 (1.570)	loss 6.865 (6.865)	prob 2.728 (2.728)	GS 31.469 (31.469)	mem 38.940
Train: [69][50/750]	BT 11.931 (1.696)	DT 11.908 (1.651)	loss 6.962 (6.962)	prob 3.173 (3.173)	GS 33.531 (33.531)	mem 38.998
Train: [69][55/750]	BT 0.031 (1.545)	DT 0.001 (1.501)	loss 6.821 (6.821)	prob 3.029 (3.029)	GS 27.906 (27.906)	mem 39.000
Train: [69][60/750]	BT 0.031 (1.420)	DT 0.001 (1.377)	loss 7.117 (7.117)	prob 3.159 (3.159)	GS 31.422 (31.422)	mem 38.937
Train: [69][65/750]	BT 0.096 (1.513)	DT 0.008 (1.470)	loss 6.798 (6.798)	prob 2.982 (2.982)	GS 29.766 (29.766)	mem 38.985
Train: [69][70/750]	BT 0.023 (1.409)	DT 0.001 (1.365)	loss 6.772 (6.772)	prob 3.062 (3.062)	GS 39.547 (39.547)	mem 38.987
Train: [69][75/750]	BT 0.048 (1.477)	DT 0.007 (1.434)	loss 6.869 (6.869)	prob 2.729 (2.729)	GS 31.438 (31.438)	mem 38.995
Train: [69][80/750]	BT 0.072 (1.387)	DT 0.012 (1.344)	loss 7.061 (7.061)	prob 2.837 (2.837)	GS 35.984 (35.984)	mem 39.164
Train: [69][85/750]	BT 0.031 (1.308)	DT 0.002 (1.266)	loss 6.991 (6.991)	prob 2.570 (2.570)	GS 31.078 (31.078)	mem 39.001
Train: [69][90/750]	BT 0.026 (1.390)	DT 0.001 (1.348)	loss 6.935 (6.935)	prob 2.717 (2.717)	GS 31.984 (31.984)	mem 38.994
Train: [69][95/750]	BT 0.048 (1.319)	DT 0.005 (1.277)	loss 7.031 (7.031)	prob 2.149 (2.149)	GS 31.953 (31.953)	mem 39.017
Train: [69][100/750]	BT 0.040 (1.376)	DT 0.002 (1.334)	loss 6.884 (6.884)	prob 3.344 (3.344)	GS 32.188 (32.188)	mem 39.094
Train: [69][105/750]	BT 0.038 (1.313)	DT 0.002 (1.271)	loss 6.868 (6.868)	prob 2.677 (2.677)	GS 33.234 (33.234)	mem 39.093
Train: [69][110/750]	BT 13.302 (1.376)	DT 13.256 (1.334)	loss 7.044 (7.044)	prob 3.085 (3.085)	GS 33.547 (33.547)	mem 39.108
Train: [69][115/750]	BT 0.031 (1.317)	DT 0.001 (1.276)	loss 7.165 (7.165)	prob 2.613 (2.613)	GS 34.375 (34.375)	mem 39.109
Train: [69][120/750]	BT 0.053 (1.264)	DT 0.002 (1.223)	loss 7.201 (7.201)	prob 2.444 (2.444)	GS 38.156 (38.156)	mem 39.109
Train: [69][125/750]	BT 0.027 (1.304)	DT 0.001 (1.263)	loss 7.119 (7.119)	prob 2.775 (2.775)	GS 39.953 (39.953)	mem 39.125
Train: [69][130/750]	BT 0.110 (1.257)	DT 0.010 (1.214)	loss 7.127 (7.127)	prob 3.003 (3.003)	GS 31.516 (31.516)	mem 39.127
Train: [69][135/750]	BT 0.116 (1.298)	DT 0.001 (1.256)	loss 6.839 (6.839)	prob 2.814 (2.814)	GS 29.938 (29.938)	mem 39.305
Train: [69][140/750]	BT 0.067 (1.254)	DT 0.002 (1.211)	loss 6.893 (6.893)	prob 2.978 (2.978)	GS 34.500 (34.500)	mem 39.180
Train: [69][145/750]	BT 0.051 (1.213)	DT 0.001 (1.170)	loss 7.348 (7.348)	prob 2.443 (2.443)	GS 28.922 (28.922)	mem 39.166
Train: [69][150/750]	BT 0.037 (1.255)	DT 0.001 (1.212)	loss 6.815 (6.815)	prob 3.442 (3.442)	GS 35.734 (35.734)	mem 39.175
Train: [69][155/750]	BT 0.151 (1.217)	DT 0.017 (1.173)	loss 7.084 (7.084)	prob 2.525 (2.525)	GS 31.281 (31.281)	mem 39.175
Train: [69][160/750]	BT 0.060 (1.259)	DT 0.001 (1.215)	loss 6.910 (6.910)	prob 3.043 (3.043)	GS 37.188 (37.188)	mem 39.164
Train: [69][165/750]	BT 0.031 (1.222)	DT 0.002 (1.178)	loss 7.079 (7.079)	prob 2.122 (2.122)	GS 30.797 (30.797)	mem 39.202
Train: [69][170/750]	BT 14.521 (1.273)	DT 14.489 (1.229)	loss 6.694 (6.694)	prob 4.273 (4.273)	GS 38.891 (38.891)	mem 39.469
Train: [69][175/750]	BT 0.071 (1.238)	DT 0.002 (1.194)	loss 6.890 (6.890)	prob 3.158 (3.158)	GS 35.203 (35.203)	mem 39.469
Train: [69][180/750]	BT 0.060 (1.206)	DT 0.006 (1.161)	loss 6.769 (6.769)	prob 3.029 (3.029)	GS 34.891 (34.891)	mem 39.514
Train: [69][185/750]	BT 0.034 (1.244)	DT 0.001 (1.199)	loss 6.891 (6.891)	prob 2.881 (2.881)	GS 31.578 (31.578)	mem 39.499
Train: [69][190/750]	BT 0.031 (1.212)	DT 0.001 (1.168)	loss 7.124 (7.124)	prob 1.359 (1.359)	GS 33.594 (33.594)	mem 39.499
Train: [69][195/750]	BT 0.031 (1.247)	DT 0.001 (1.203)	loss 7.094 (7.094)	prob 2.996 (2.996)	GS 34.984 (34.984)	mem 39.447
Train: [69][200/750]	BT 0.030 (1.217)	DT 0.001 (1.173)	loss 7.072 (7.072)	prob 2.808 (2.808)	GS 32.656 (32.656)	mem 39.448
Train: [69][205/750]	BT 0.035 (1.189)	DT 0.005 (1.145)	loss 6.907 (6.907)	prob 2.813 (2.813)	GS 31.047 (31.047)	mem 39.448
Train: [69][210/750]	BT 0.028 (1.231)	DT 0.001 (1.187)	loss 6.844 (6.844)	prob 2.920 (2.920)	GS 30.438 (30.438)	mem 39.372
Train: [69][215/750]	BT 0.067 (1.203)	DT 0.001 (1.160)	loss 6.874 (6.874)	prob 3.164 (3.164)	GS 33.812 (33.812)	mem 39.376
Train: [69][220/750]	BT 0.031 (1.240)	DT 0.001 (1.196)	loss 6.722 (6.722)	prob 3.267 (3.267)	GS 33.172 (33.172)	mem 39.418
Train: [69][225/750]	BT 0.102 (1.213)	DT 0.013 (1.170)	loss 6.934 (6.934)	prob 3.163 (3.163)	GS 38.625 (38.625)	mem 39.400
Train: [69][230/750]	BT 12.327 (1.241)	DT 12.303 (1.198)	loss 7.017 (7.017)	prob 2.769 (2.769)	GS 36.109 (36.109)	mem 39.621
Train: [69][235/750]	BT 0.024 (1.215)	DT 0.001 (1.172)	loss 6.917 (6.917)	prob 2.603 (2.603)	GS 29.984 (29.984)	mem 39.626
Train: [69][240/750]	BT 0.033 (1.191)	DT 0.001 (1.148)	loss 7.024 (7.024)	prob 2.578 (2.578)	GS 32.828 (32.828)	mem 39.655
Train: [69][245/750]	BT 0.028 (1.205)	DT 0.001 (1.163)	loss 7.120 (7.120)	prob 2.301 (2.301)	GS 28.734 (28.734)	mem 39.783
Train: [69][250/750]	BT 0.037 (1.182)	DT 0.002 (1.139)	loss 6.696 (6.696)	prob 3.333 (3.333)	GS 33.688 (33.688)	mem 39.876
Train: [69][255/750]	BT 0.037 (1.209)	DT 0.002 (1.166)	loss 7.074 (7.074)	prob 2.382 (2.382)	GS 30.328 (30.328)	mem 39.825
Train: [69][260/750]	BT 0.021 (1.186)	DT 0.001 (1.144)	loss 6.997 (6.997)	prob 2.483 (2.483)	GS 35.453 (35.453)	mem 39.797
Train: [69][265/750]	BT 0.076 (1.165)	DT 0.004 (1.122)	loss 6.721 (6.721)	prob 2.798 (2.798)	GS 28.266 (28.266)	mem 39.798
Train: [69][270/750]	BT 0.046 (1.192)	DT 0.005 (1.149)	loss 6.876 (6.876)	prob 3.164 (3.164)	GS 35.828 (35.828)	mem 39.791
Train: [69][275/750]	BT 0.073 (1.171)	DT 0.010 (1.129)	loss 6.843 (6.843)	prob 2.573 (2.573)	GS 32.250 (32.250)	mem 39.813
Train: [69][280/750]	BT 0.031 (1.195)	DT 0.001 (1.152)	loss 6.911 (6.911)	prob 2.375 (2.375)	GS 34.578 (34.578)	mem 39.698
Train: [69][285/750]	BT 0.045 (1.175)	DT 0.007 (1.132)	loss 7.038 (7.038)	prob 2.446 (2.446)	GS 33.406 (33.406)	mem 39.743
Train: [69][290/750]	BT 13.622 (1.202)	DT 13.594 (1.160)	loss 6.952 (6.952)	prob 2.450 (2.450)	GS 33.375 (33.375)	mem 39.802
Train: [69][295/750]	BT 0.030 (1.183)	DT 0.001 (1.140)	loss 7.110 (7.110)	prob 2.606 (2.606)	GS 27.156 (27.156)	mem 39.802
Train: [69][300/750]	BT 0.033 (1.163)	DT 0.002 (1.121)	loss 6.842 (6.842)	prob 3.008 (3.008)	GS 40.156 (40.156)	mem 39.803
Train: [69][305/750]	BT 0.028 (1.192)	DT 0.001 (1.150)	loss 6.873 (6.873)	prob 2.927 (2.927)	GS 30.031 (30.031)	mem 39.786
Train: [69][310/750]	BT 0.107 (1.173)	DT 0.006 (1.131)	loss 6.860 (6.860)	prob 2.798 (2.798)	GS 37.125 (37.125)	mem 39.787
Train: [69][315/750]	BT 0.029 (1.193)	DT 0.001 (1.151)	loss 6.940 (6.940)	prob 2.851 (2.851)	GS 34.125 (34.125)	mem 39.996
Train: [69][320/750]	BT 0.092 (1.176)	DT 0.001 (1.133)	loss 7.006 (7.006)	prob 2.435 (2.435)	GS 36.812 (36.812)	mem 40.035
Train: [69][325/750]	BT 0.046 (1.158)	DT 0.001 (1.116)	loss 7.059 (7.059)	prob 2.459 (2.459)	GS 30.047 (30.047)	mem 39.870
Train: [69][330/750]	BT 0.056 (1.174)	DT 0.004 (1.131)	loss 6.820 (6.820)	prob 2.530 (2.530)	GS 31.375 (31.375)	mem 39.978
Train: [69][335/750]	BT 0.054 (1.157)	DT 0.002 (1.114)	loss 7.245 (7.245)	prob 2.198 (2.198)	GS 31.156 (31.156)	mem 39.976
Train: [69][340/750]	BT 0.102 (1.175)	DT 0.004 (1.133)	loss 6.982 (6.982)	prob 2.638 (2.638)	GS 36.469 (36.469)	mem 39.904
Train: [69][345/750]	BT 0.034 (1.159)	DT 0.001 (1.116)	loss 6.835 (6.835)	prob 2.984 (2.984)	GS 36.797 (36.797)	mem 39.906
Train: [69][350/750]	BT 11.782 (1.177)	DT 11.746 (1.134)	loss 6.713 (6.713)	prob 3.154 (3.154)	GS 32.531 (32.531)	mem 39.909
Train: [69][355/750]	BT 0.147 (1.161)	DT 0.001 (1.118)	loss 7.078 (7.078)	prob 2.720 (2.720)	GS 38.203 (38.203)	mem 39.954
Train: [69][360/750]	BT 0.050 (1.145)	DT 0.002 (1.103)	loss 6.916 (6.916)	prob 3.345 (3.345)	GS 34.672 (34.672)	mem 40.285
Train: [69][365/750]	BT 0.027 (1.168)	DT 0.001 (1.125)	loss 7.011 (7.011)	prob 3.391 (3.391)	GS 30.750 (30.750)	mem 39.914
Train: [69][370/750]	BT 0.041 (1.153)	DT 0.001 (1.110)	loss 7.197 (7.197)	prob 2.262 (2.262)	GS 30.828 (30.828)	mem 39.914
Train: [69][375/750]	BT 0.060 (1.168)	DT 0.008 (1.126)	loss 7.173 (7.173)	prob 2.629 (2.629)	GS 32.797 (32.797)	mem 39.925
Train: [69][380/750]	BT 0.022 (1.154)	DT 0.001 (1.111)	loss 6.929 (6.929)	prob 3.039 (3.039)	GS 33.156 (33.156)	mem 39.937
Train: [69][385/750]	BT 0.038 (1.139)	DT 0.001 (1.096)	loss 6.987 (6.987)	prob 2.849 (2.849)	GS 38.234 (38.234)	mem 40.330
Train: [69][390/750]	BT 0.049 (1.158)	DT 0.001 (1.115)	loss 6.902 (6.902)	prob 2.926 (2.926)	GS 29.859 (29.859)	mem 39.945
Train: [69][395/750]	BT 0.048 (1.144)	DT 0.001 (1.101)	loss 6.901 (6.901)	prob 2.947 (2.947)	GS 33.016 (33.016)	mem 39.948
Train: [69][400/750]	BT 0.034 (1.153)	DT 0.002 (1.110)	loss 6.705 (6.705)	prob 3.415 (3.415)	GS 36.000 (36.000)	mem 39.924
Train: [69][405/750]	BT 0.033 (1.139)	DT 0.001 (1.097)	loss 6.815 (6.815)	prob 3.132 (3.132)	GS 32.812 (32.812)	mem 39.863
Train: [69][410/750]	BT 12.005 (1.155)	DT 11.958 (1.112)	loss 6.811 (6.811)	prob 3.091 (3.091)	GS 31.078 (31.078)	mem 39.716
Train: [69][415/750]	BT 0.173 (1.142)	DT 0.024 (1.099)	loss 7.030 (7.030)	prob 2.462 (2.462)	GS 32.953 (32.953)	mem 39.810
Train: [69][420/750]	BT 0.048 (1.129)	DT 0.001 (1.086)	loss 7.002 (7.002)	prob 2.878 (2.878)	GS 39.859 (39.859)	mem 39.724
Train: [69][425/750]	BT 0.026 (1.151)	DT 0.001 (1.108)	loss 7.246 (7.246)	prob 2.832 (2.832)	GS 47.797 (47.797)	mem 39.791
Train: [69][430/750]	BT 0.037 (1.138)	DT 0.002 (1.095)	loss 7.051 (7.051)	prob 2.272 (2.272)	GS 35.469 (35.469)	mem 39.791
Train: [69][435/750]	BT 0.033 (1.151)	DT 0.002 (1.108)	loss 7.029 (7.029)	prob 3.036 (3.036)	GS 32.469 (32.469)	mem 39.801
Train: [69][440/750]	BT 0.028 (1.139)	DT 0.001 (1.096)	loss 6.910 (6.910)	prob 2.904 (2.904)	GS 31.062 (31.062)	mem 39.820
Train: [69][445/750]	BT 0.063 (1.126)	DT 0.005 (1.084)	loss 7.355 (7.355)	prob 2.041 (2.041)	GS 30.453 (30.453)	mem 39.801
Train: [69][450/750]	BT 1.338 (1.141)	DT 1.295 (1.098)	loss 6.821 (6.821)	prob 3.098 (3.098)	GS 31.766 (31.766)	mem 39.889
Train: [69][455/750]	BT 0.032 (1.128)	DT 0.001 (1.086)	loss 7.064 (7.064)	prob 2.095 (2.095)	GS 27.469 (27.469)	mem 39.805
Train: [69][460/750]	BT 0.031 (1.146)	DT 0.001 (1.104)	loss 6.681 (6.681)	prob 2.091 (2.091)	GS 33.250 (33.250)	mem 39.815
Train: [69][465/750]	BT 0.063 (1.137)	DT 0.013 (1.094)	loss 7.007 (7.007)	prob 2.739 (2.739)	GS 29.250 (29.250)	mem 39.870
Train: [69][470/750]	BT 11.529 (1.150)	DT 11.500 (1.107)	loss 6.910 (6.910)	prob 2.116 (2.116)	GS 30.797 (30.797)	mem 39.894
Train: [69][475/750]	BT 0.056 (1.141)	DT 0.001 (1.098)	loss 6.951 (6.951)	prob 2.712 (2.712)	GS 33.391 (33.391)	mem 39.752
Train: [69][480/750]	BT 0.070 (1.130)	DT 0.021 (1.087)	loss 6.995 (6.995)	prob 2.550 (2.550)	GS 33.703 (33.703)	mem 39.832
Train: [69][485/750]	BT 0.028 (1.149)	DT 0.001 (1.106)	loss 7.209 (7.209)	prob 2.509 (2.509)	GS 34.281 (34.281)	mem 39.909
Train: [69][490/750]	BT 0.102 (1.138)	DT 0.024 (1.095)	loss 6.800 (6.800)	prob 2.804 (2.804)	GS 37.281 (37.281)	mem 40.070
Train: [69][495/750]	BT 0.042 (1.153)	DT 0.009 (1.110)	loss 7.318 (7.318)	prob 1.925 (1.925)	GS 27.219 (27.219)	mem 39.761
Train: [69][500/750]	BT 0.049 (1.142)	DT 0.006 (1.099)	loss 6.883 (6.883)	prob 2.428 (2.428)	GS 35.922 (35.922)	mem 39.800
Train: [69][505/750]	BT 0.033 (1.131)	DT 0.001 (1.088)	loss 7.044 (7.044)	prob 3.095 (3.095)	GS 31.062 (31.062)	mem 39.800
Train: [69][510/750]	BT 0.042 (1.143)	DT 0.002 (1.100)	loss 6.840 (6.840)	prob 2.933 (2.933)	GS 29.578 (29.578)	mem 39.846
Train: [69][515/750]	BT 0.089 (1.133)	DT 0.018 (1.090)	loss 6.907 (6.907)	prob 3.058 (3.058)	GS 30.188 (30.188)	mem 39.846
Train: [69][520/750]	BT 0.058 (1.142)	DT 0.008 (1.099)	loss 6.854 (6.854)	prob 2.564 (2.564)	GS 32.031 (32.031)	mem 39.980
Train: [69][525/750]	BT 0.061 (1.132)	DT 0.009 (1.088)	loss 7.089 (7.089)	prob 2.685 (2.685)	GS 28.656 (28.656)	mem 39.898
Train: [69][530/750]	BT 9.820 (1.147)	DT 9.767 (1.103)	loss 6.962 (6.962)	prob 2.727 (2.727)	GS 37.969 (37.969)	mem 39.892
Train: [69][535/750]	BT 0.048 (1.137)	DT 0.001 (1.093)	loss 7.082 (7.082)	prob 3.334 (3.334)	GS 33.547 (33.547)	mem 39.791
Train: [69][540/750]	BT 0.065 (1.136)	DT 0.008 (1.092)	loss 6.839 (6.839)	prob 3.108 (3.108)	GS 32.391 (32.391)	mem 39.863
Train: [69][545/750]	BT 0.031 (1.142)	DT 0.001 (1.099)	loss 7.336 (7.336)	prob 2.888 (2.888)	GS 30.047 (30.047)	mem 39.837
Train: [69][550/750]	BT 1.567 (1.136)	DT 1.535 (1.092)	loss 7.026 (7.026)	prob 2.607 (2.607)	GS 35.000 (35.000)	mem 39.876
Train: [69][555/750]	BT 0.034 (1.148)	DT 0.002 (1.105)	loss 7.099 (7.099)	prob 2.759 (2.759)	GS 30.672 (30.672)	mem 39.925
Train: [69][560/750]	BT 0.114 (1.139)	DT 0.009 (1.095)	loss 7.154 (7.154)	prob 2.019 (2.019)	GS 32.812 (32.812)	mem 39.948
Train: [69][565/750]	BT 0.144 (1.130)	DT 0.002 (1.086)	loss 7.146 (7.146)	prob 2.872 (2.872)	GS 36.719 (36.719)	mem 39.929
Train: [69][570/750]	BT 0.031 (1.146)	DT 0.001 (1.102)	loss 7.271 (7.271)	prob 1.969 (1.969)	GS 39.016 (39.016)	mem 39.818
Train: [69][575/750]	BT 0.030 (1.136)	DT 0.001 (1.092)	loss 7.051 (7.051)	prob 2.954 (2.954)	GS 34.812 (34.812)	mem 39.818
Train: [69][580/750]	BT 0.030 (1.151)	DT 0.001 (1.107)	loss 6.915 (6.915)	prob 2.927 (2.927)	GS 32.562 (32.562)	mem 39.794
Train: [69][585/750]	BT 0.026 (1.142)	DT 0.002 (1.098)	loss 7.016 (7.016)	prob 2.487 (2.487)	GS 31.719 (31.719)	mem 39.811
Train: [69][590/750]	BT 8.922 (1.147)	DT 8.857 (1.104)	loss 7.021 (7.021)	prob 3.005 (3.005)	GS 32.516 (32.516)	mem 39.952
Train: [69][595/750]	BT 0.031 (1.138)	DT 0.003 (1.094)	loss 6.893 (6.893)	prob 2.978 (2.978)	GS 30.672 (30.672)	mem 39.973
Train: [69][600/750]	BT 0.033 (1.129)	DT 0.002 (1.085)	loss 7.013 (7.013)	prob 2.543 (2.543)	GS 33.047 (33.047)	mem 39.951
Train: [69][605/750]	BT 0.025 (1.142)	DT 0.001 (1.098)	loss 6.899 (6.899)	prob 2.790 (2.790)	GS 30.828 (30.828)	mem 39.955
Train: [69][610/750]	BT 0.207 (1.133)	DT 0.173 (1.089)	loss 6.942 (6.942)	prob 2.777 (2.777)	GS 35.000 (35.000)	mem 39.888
Train: [69][615/750]	BT 0.032 (1.145)	DT 0.001 (1.102)	loss 7.257 (7.257)	prob 1.866 (1.866)	GS 31.203 (31.203)	mem 39.922
Train: [69][620/750]	BT 0.128 (1.136)	DT 0.002 (1.093)	loss 6.755 (6.755)	prob 2.538 (2.538)	GS 29.203 (29.203)	mem 39.981
Train: [69][625/750]	BT 0.025 (1.128)	DT 0.001 (1.085)	loss 7.044 (7.044)	prob 2.274 (2.274)	GS 35.938 (35.938)	mem 39.969
Train: [69][630/750]	BT 0.078 (1.139)	DT 0.007 (1.096)	loss 6.860 (6.860)	prob 2.959 (2.959)	GS 31.672 (31.672)	mem 39.927
Train: [69][635/750]	BT 0.029 (1.130)	DT 0.001 (1.087)	loss 7.133 (7.133)	prob 2.317 (2.317)	GS 24.125 (24.125)	mem 39.927
Train: [69][640/750]	BT 0.022 (1.137)	DT 0.001 (1.094)	loss 6.933 (6.933)	prob 2.469 (2.469)	GS 37.891 (37.891)	mem 39.897
Train: [69][645/750]	BT 0.058 (1.129)	DT 0.003 (1.086)	loss 6.863 (6.863)	prob 2.170 (2.170)	GS 26.625 (26.625)	mem 40.045
Train: [69][650/750]	BT 14.325 (1.143)	DT 14.288 (1.099)	loss 6.789 (6.789)	prob 2.695 (2.695)	GS 32.484 (32.484)	mem 39.786
Train: [69][655/750]	BT 0.058 (1.134)	DT 0.007 (1.091)	loss 7.050 (7.050)	prob 3.152 (3.152)	GS 28.203 (28.203)	mem 39.786
arpack error, retry= 0
Train: [69][660/750]	BT 0.042 (1.126)	DT 0.001 (1.083)	loss 7.076 (7.076)	prob 2.317 (2.317)	GS 30.719 (30.719)	mem 40.000
Train: [69][665/750]	BT 0.031 (1.139)	DT 0.001 (1.095)	loss 6.902 (6.902)	prob 2.969 (2.969)	GS 32.750 (32.750)	mem 39.783
Train: [69][670/750]	BT 0.038 (1.130)	DT 0.016 (1.087)	loss 7.061 (7.061)	prob 1.864 (1.864)	GS 32.297 (32.297)	mem 39.783
Train: [69][675/750]	BT 0.031 (1.140)	DT 0.001 (1.097)	loss 6.751 (6.751)	prob 2.686 (2.686)	GS 33.188 (33.188)	mem 39.872
Train: [69][680/750]	BT 0.023 (1.132)	DT 0.001 (1.089)	loss 7.040 (7.040)	prob 1.961 (1.961)	GS 35.312 (35.312)	mem 39.874
Train: [69][685/750]	BT 0.057 (1.124)	DT 0.007 (1.081)	loss 6.883 (6.883)	prob 2.238 (2.238)	GS 30.438 (30.438)	mem 39.813
Train: [69][690/750]	BT 0.065 (1.137)	DT 0.009 (1.094)	loss 6.952 (6.952)	prob 2.732 (2.732)	GS 33.469 (33.469)	mem 39.883
Train: [69][695/750]	BT 0.084 (1.129)	DT 0.007 (1.086)	loss 6.943 (6.943)	prob 3.006 (3.006)	GS 30.734 (30.734)	mem 39.882
Train: [69][700/750]	BT 0.033 (1.136)	DT 0.002 (1.093)	loss 6.776 (6.776)	prob 2.916 (2.916)	GS 32.156 (32.156)	mem 39.825
Train: [69][705/750]	BT 0.034 (1.129)	DT 0.002 (1.086)	loss 6.825 (6.825)	prob 3.123 (3.123)	GS 30.078 (30.078)	mem 39.865
Train: [69][710/750]	BT 12.531 (1.139)	DT 12.499 (1.095)	loss 6.858 (6.858)	prob 2.369 (2.369)	GS 29.125 (29.125)	mem 39.822
Train: [69][715/750]	BT 0.047 (1.131)	DT 0.001 (1.088)	loss 6.708 (6.708)	prob 2.793 (2.793)	GS 31.031 (31.031)	mem 39.863
Train: [69][720/750]	BT 0.101 (1.123)	DT 0.007 (1.080)	loss 6.920 (6.920)	prob 2.754 (2.754)	GS 32.938 (32.938)	mem 39.823
Train: [69][725/750]	BT 0.087 (1.132)	DT 0.031 (1.088)	loss 7.019 (7.019)	prob 1.923 (1.923)	GS 43.359 (43.359)	mem 39.735
Train: [69][730/750]	BT 0.056 (1.124)	DT 0.001 (1.081)	loss 6.934 (6.934)	prob 2.125 (2.125)	GS 32.766 (32.766)	mem 39.784
Train: [69][735/750]	BT 0.031 (1.131)	DT 0.002 (1.087)	loss 6.913 (6.913)	prob 2.158 (2.158)	GS 32.969 (32.969)	mem 36.517
Train: [69][740/750]	BT 0.033 (1.123)	DT 0.002 (1.080)	loss 6.971 (6.971)	prob 2.622 (2.622)	GS 32.438 (32.438)	mem 36.481
Train: [69][745/750]	BT 0.047 (1.116)	DT 0.002 (1.073)	loss 7.017 (7.017)	prob 3.003 (3.003)	GS 36.125 (36.125)	mem 36.580
Train: [69][750/750]	BT 0.037 (1.112)	DT 0.010 (1.069)	loss 6.811 (6.811)	prob 2.688 (2.688)	GS 33.312 (33.312)	mem 10.526
Train: [69][755/750]	BT 0.031 (1.105)	DT 0.001 (1.062)	loss 7.038 (7.038)	prob 2.592 (2.592)	GS 42.031 (42.031)	mem 8.579
epoch 69, total time 834.31
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [70][1/750]	BT 21.990 (21.990)	DT 21.930 (21.930)	loss 6.888 (6.888)	prob 3.022 (3.022)	GS 31.375 (31.375)	mem 38.588
Train: [70][5/750]	BT 0.048 (4.554)	DT 0.012 (4.513)	loss 6.742 (6.742)	prob 3.037 (3.037)	GS 30.984 (30.984)	mem 38.711
Train: [70][10/750]	BT 0.657 (2.751)	DT 0.625 (2.704)	loss 6.846 (6.846)	prob 2.492 (2.492)	GS 36.125 (36.125)	mem 38.667
Train: [70][15/750]	BT 0.109 (2.284)	DT 0.039 (2.240)	loss 7.157 (7.157)	prob 1.939 (1.939)	GS 29.797 (29.797)	mem 38.763
Train: [70][20/750]	BT 0.032 (2.046)	DT 0.001 (1.999)	loss 6.760 (6.760)	prob 2.991 (2.991)	GS 32.000 (32.000)	mem 38.800
Train: [70][25/750]	BT 1.831 (1.715)	DT 1.794 (1.671)	loss 6.834 (6.834)	prob 2.396 (2.396)	GS 33.562 (33.562)	mem 38.931
Train: [70][30/750]	BT 6.188 (1.819)	DT 6.154 (1.775)	loss 6.839 (6.839)	prob 2.397 (2.397)	GS 33.750 (33.750)	mem 38.980
Train: [70][35/750]	BT 0.060 (1.642)	DT 0.017 (1.598)	loss 6.802 (6.802)	prob 2.805 (2.805)	GS 30.438 (30.438)	mem 38.963
Train: [70][40/750]	BT 0.031 (1.529)	DT 0.001 (1.486)	loss 6.826 (6.826)	prob 3.300 (3.300)	GS 34.672 (34.672)	mem 39.018
Train: [70][45/750]	BT 0.055 (1.570)	DT 0.012 (1.525)	loss 6.939 (6.939)	prob 3.038 (3.038)	GS 32.016 (32.016)	mem 39.058
Train: [70][50/750]	BT 0.059 (1.421)	DT 0.015 (1.374)	loss 6.776 (6.776)	prob 2.728 (2.728)	GS 30.688 (30.688)	mem 38.998
Train: [70][55/750]	BT 0.028 (1.497)	DT 0.001 (1.452)	loss 6.681 (6.681)	prob 2.799 (2.799)	GS 29.297 (29.297)	mem 39.027
Train: [70][60/750]	BT 0.091 (1.376)	DT 0.001 (1.331)	loss 6.995 (6.995)	prob 2.534 (2.534)	GS 33.844 (33.844)	mem 39.028
Train: [70][65/750]	BT 0.078 (1.335)	DT 0.014 (1.288)	loss 7.133 (7.133)	prob 2.200 (2.200)	GS 29.344 (29.344)	mem 39.042
Train: [70][70/750]	BT 0.022 (1.406)	DT 0.001 (1.358)	loss 6.768 (6.768)	prob 2.850 (2.850)	GS 33.812 (33.812)	mem 39.054
Train: [70][75/750]	BT 0.067 (1.315)	DT 0.010 (1.268)	loss 6.931 (6.931)	prob 3.409 (3.409)	GS 28.781 (28.781)	mem 39.055
Train: [70][80/750]	BT 0.063 (1.349)	DT 0.002 (1.302)	loss 6.915 (6.915)	prob 2.472 (2.472)	GS 36.609 (36.609)	mem 39.108
Train: [70][85/750]	BT 0.063 (1.284)	DT 0.015 (1.236)	loss 7.117 (7.117)	prob 2.711 (2.711)	GS 28.969 (28.969)	mem 39.200
Train: [70][90/750]	BT 13.568 (1.397)	DT 13.515 (1.349)	loss 7.080 (7.080)	prob 1.973 (1.973)	GS 36.172 (36.172)	mem 39.227
Train: [70][95/750]	BT 0.032 (1.325)	DT 0.001 (1.278)	loss 7.022 (7.022)	prob 2.438 (2.438)	GS 31.266 (31.266)	mem 39.091
Train: [70][100/750]	BT 0.428 (1.278)	DT 0.380 (1.230)	loss 6.818 (6.818)	prob 2.414 (2.414)	GS 32.297 (32.297)	mem 39.127
Train: [70][105/750]	BT 0.036 (1.308)	DT 0.001 (1.260)	loss 7.306 (7.306)	prob 2.423 (2.423)	GS 37.250 (37.250)	mem 39.223
Train: [70][110/750]	BT 3.173 (1.279)	DT 3.141 (1.232)	loss 7.053 (7.053)	prob 2.456 (2.456)	GS 34.719 (34.719)	mem 39.176
Train: [70][115/750]	BT 0.050 (1.299)	DT 0.010 (1.252)	loss 7.007 (7.007)	prob 2.768 (2.768)	GS 33.828 (33.828)	mem 39.151
Train: [70][120/750]	BT 0.026 (1.255)	DT 0.001 (1.208)	loss 7.058 (7.058)	prob 2.451 (2.451)	GS 36.781 (36.781)	mem 39.254
Train: [70][125/750]	BT 0.033 (1.254)	DT 0.002 (1.209)	loss 7.004 (7.004)	prob 2.595 (2.595)	GS 29.438 (29.438)	mem 39.473
Train: [70][130/750]	BT 2.938 (1.278)	DT 2.906 (1.232)	loss 6.981 (6.981)	prob 2.314 (2.314)	GS 39.828 (39.828)	mem 39.513
Train: [70][135/750]	BT 0.072 (1.238)	DT 0.006 (1.192)	loss 7.097 (7.097)	prob 2.706 (2.706)	GS 26.844 (26.844)	mem 39.518
Train: [70][140/750]	BT 0.040 (1.251)	DT 0.002 (1.204)	loss 6.989 (6.989)	prob 2.592 (2.592)	GS 34.453 (34.453)	mem 39.662
Train: [70][145/750]	BT 0.035 (1.242)	DT 0.002 (1.195)	loss 7.215 (7.215)	prob 2.366 (2.366)	GS 32.250 (32.250)	mem 39.627
Train: [70][150/750]	BT 0.031 (1.252)	DT 0.001 (1.206)	loss 7.195 (7.195)	prob 2.695 (2.695)	GS 31.609 (31.609)	mem 39.580
Train: [70][155/750]	BT 0.046 (1.279)	DT 0.004 (1.233)	loss 7.156 (7.156)	prob 2.756 (2.756)	GS 32.812 (32.812)	mem 39.526
Train: [70][160/750]	BT 0.616 (1.244)	DT 0.524 (1.198)	loss 7.013 (7.013)	prob 2.753 (2.753)	GS 36.984 (36.984)	mem 39.526
Train: [70][165/750]	BT 0.096 (1.222)	DT 0.014 (1.175)	loss 7.020 (7.020)	prob 2.511 (2.511)	GS 31.781 (31.781)	mem 39.685
Train: [70][170/750]	BT 0.075 (1.241)	DT 0.001 (1.195)	loss 6.878 (6.878)	prob 2.946 (2.946)	GS 32.281 (32.281)	mem 39.730
Train: [70][175/750]	BT 0.080 (1.218)	DT 0.018 (1.170)	loss 7.015 (7.015)	prob 2.541 (2.541)	GS 30.641 (30.641)	mem 39.809
Train: [70][180/750]	BT 0.028 (1.252)	DT 0.001 (1.205)	loss 7.016 (7.016)	prob 3.105 (3.105)	GS 38.984 (38.984)	mem 39.771
Train: [70][185/750]	BT 0.034 (1.219)	DT 0.002 (1.172)	loss 7.178 (7.178)	prob 2.381 (2.381)	GS 30.625 (30.625)	mem 39.878
Train: [70][190/750]	BT 11.094 (1.257)	DT 11.046 (1.211)	loss 7.179 (7.179)	prob 3.568 (3.568)	GS 37.141 (37.141)	mem 39.774
Train: [70][195/750]	BT 0.031 (1.226)	DT 0.001 (1.180)	loss 7.268 (7.268)	prob 2.647 (2.647)	GS 32.250 (32.250)	mem 39.776
Train: [70][200/750]	BT 0.055 (1.197)	DT 0.003 (1.150)	loss 6.845 (6.845)	prob 2.292 (2.292)	GS 30.656 (30.656)	mem 39.777
Train: [70][205/750]	BT 0.107 (1.223)	DT 0.001 (1.177)	loss 6.849 (6.849)	prob 2.690 (2.690)	GS 30.672 (30.672)	mem 39.789
Train: [70][210/750]	BT 0.049 (1.195)	DT 0.001 (1.149)	loss 6.983 (6.983)	prob 2.964 (2.964)	GS 28.875 (28.875)	mem 39.862
Train: [70][215/750]	BT 0.049 (1.240)	DT 0.006 (1.194)	loss 7.055 (7.055)	prob 3.012 (3.012)	GS 32.047 (32.047)	mem 39.851
Train: [70][220/750]	BT 0.090 (1.213)	DT 0.001 (1.167)	loss 7.037 (7.037)	prob 2.760 (2.760)	GS 36.719 (36.719)	mem 39.851
Train: [70][225/750]	BT 0.035 (1.187)	DT 0.001 (1.142)	loss 6.916 (6.916)	prob 3.464 (3.464)	GS 28.156 (28.156)	mem 39.852
Train: [70][230/750]	BT 0.027 (1.232)	DT 0.001 (1.187)	loss 7.080 (7.080)	prob 2.695 (2.695)	GS 30.859 (30.859)	mem 39.859
Train: [70][235/750]	BT 0.025 (1.207)	DT 0.001 (1.162)	loss 7.017 (7.017)	prob 2.700 (2.700)	GS 33.234 (33.234)	mem 39.859
Train: [70][240/750]	BT 0.040 (1.233)	DT 0.011 (1.188)	loss 6.775 (6.775)	prob 3.408 (3.408)	GS 34.234 (34.234)	mem 39.902
Train: [70][245/750]	BT 0.030 (1.208)	DT 0.002 (1.164)	loss 6.918 (6.918)	prob 2.833 (2.833)	GS 31.172 (31.172)	mem 39.889
Train: [70][250/750]	BT 9.768 (1.224)	DT 9.705 (1.179)	loss 6.790 (6.790)	prob 3.100 (3.100)	GS 31.359 (31.359)	mem 39.898
Train: [70][255/750]	BT 0.025 (1.201)	DT 0.001 (1.156)	loss 6.811 (6.811)	prob 2.987 (2.987)	GS 30.812 (30.812)	mem 39.900
Train: [70][260/750]	BT 0.100 (1.179)	DT 0.002 (1.134)	loss 6.979 (6.979)	prob 2.671 (2.671)	GS 32.922 (32.922)	mem 39.974
Train: [70][265/750]	BT 0.033 (1.206)	DT 0.002 (1.161)	loss 6.894 (6.894)	prob 3.340 (3.340)	GS 40.203 (40.203)	mem 39.823
Train: [70][270/750]	BT 0.035 (1.184)	DT 0.004 (1.140)	loss 7.019 (7.019)	prob 3.178 (3.178)	GS 33.828 (33.828)	mem 39.823
Train: [70][275/750]	BT 0.028 (1.215)	DT 0.002 (1.171)	loss 7.218 (7.218)	prob 2.627 (2.627)	GS 34.891 (34.891)	mem 39.880
Train: [70][280/750]	BT 0.041 (1.194)	DT 0.001 (1.150)	loss 6.924 (6.924)	prob 2.803 (2.803)	GS 30.172 (30.172)	mem 39.881
Train: [70][285/750]	BT 0.080 (1.174)	DT 0.011 (1.130)	loss 7.151 (7.151)	prob 2.455 (2.455)	GS 33.203 (33.203)	mem 39.882
Train: [70][290/750]	BT 0.033 (1.203)	DT 0.001 (1.160)	loss 6.762 (6.762)	prob 3.025 (3.025)	GS 34.094 (34.094)	mem 39.986
Train: [70][295/750]	BT 0.048 (1.184)	DT 0.002 (1.140)	loss 6.816 (6.816)	prob 3.645 (3.645)	GS 33.266 (33.266)	mem 40.064
Train: [70][300/750]	BT 0.028 (1.210)	DT 0.001 (1.166)	loss 6.856 (6.856)	prob 3.225 (3.225)	GS 35.906 (35.906)	mem 39.985
Train: [70][305/750]	BT 0.072 (1.191)	DT 0.002 (1.147)	loss 6.859 (6.859)	prob 3.054 (3.054)	GS 33.562 (33.562)	mem 40.039
Train: [70][310/750]	BT 12.884 (1.213)	DT 12.855 (1.170)	loss 7.011 (7.011)	prob 2.687 (2.687)	GS 34.359 (34.359)	mem 39.982
Train: [70][315/750]	BT 0.056 (1.195)	DT 0.001 (1.151)	loss 7.346 (7.346)	prob 2.398 (2.398)	GS 31.750 (31.750)	mem 40.044
Train: [70][320/750]	BT 0.049 (1.177)	DT 0.007 (1.134)	loss 7.004 (7.004)	prob 2.996 (2.996)	GS 33.656 (33.656)	mem 39.984
Train: [70][325/750]	BT 0.032 (1.201)	DT 0.001 (1.157)	loss 7.047 (7.047)	prob 2.629 (2.629)	GS 33.422 (33.422)	mem 40.159
Train: [70][330/750]	BT 0.029 (1.183)	DT 0.002 (1.140)	loss 6.873 (6.873)	prob 2.831 (2.831)	GS 37.953 (37.953)	mem 40.025
Train: [70][335/750]	BT 0.030 (1.199)	DT 0.001 (1.155)	loss 6.942 (6.942)	prob 2.907 (2.907)	GS 34.812 (34.812)	mem 39.974
Train: [70][340/750]	BT 0.031 (1.182)	DT 0.001 (1.138)	loss 6.860 (6.860)	prob 3.160 (3.160)	GS 34.609 (34.609)	mem 39.975
Train: [70][345/750]	BT 0.039 (1.165)	DT 0.002 (1.122)	loss 6.874 (6.874)	prob 3.325 (3.325)	GS 33.656 (33.656)	mem 39.975
Train: [70][350/750]	BT 0.057 (1.184)	DT 0.009 (1.141)	loss 6.909 (6.909)	prob 2.437 (2.437)	GS 34.625 (34.625)	mem 39.915
Train: [70][355/750]	BT 0.031 (1.168)	DT 0.001 (1.125)	loss 7.134 (7.134)	prob 2.277 (2.277)	GS 30.500 (30.500)	mem 39.916
Train: [70][360/750]	BT 0.026 (1.183)	DT 0.001 (1.140)	loss 6.788 (6.788)	prob 3.179 (3.179)	GS 33.781 (33.781)	mem 39.923
Train: [70][365/750]	BT 0.054 (1.168)	DT 0.013 (1.125)	loss 6.947 (6.947)	prob 2.951 (2.951)	GS 32.938 (32.938)	mem 39.974
Train: [70][370/750]	BT 11.230 (1.183)	DT 11.182 (1.140)	loss 6.721 (6.721)	prob 2.694 (2.694)	GS 32.047 (32.047)	mem 39.897
Train: [70][375/750]	BT 0.038 (1.173)	DT 0.002 (1.130)	loss 7.126 (7.126)	prob 2.361 (2.361)	GS 32.031 (32.031)	mem 39.937
Train: [70][380/750]	BT 0.092 (1.158)	DT 0.010 (1.115)	loss 6.915 (6.915)	prob 2.818 (2.818)	GS 38.203 (38.203)	mem 39.978
Train: [70][385/750]	BT 0.064 (1.177)	DT 0.005 (1.134)	loss 6.869 (6.869)	prob 3.154 (3.154)	GS 31.047 (31.047)	mem 39.962
Train: [70][390/750]	BT 0.069 (1.163)	DT 0.001 (1.120)	loss 7.035 (7.035)	prob 2.692 (2.692)	GS 36.234 (36.234)	mem 39.948
Train: [70][395/750]	BT 0.082 (1.169)	DT 0.002 (1.125)	loss 6.997 (6.997)	prob 2.455 (2.455)	GS 29.281 (29.281)	mem 40.129
Train: [70][400/750]	BT 0.034 (1.163)	DT 0.001 (1.119)	loss 6.955 (6.955)	prob 2.654 (2.654)	GS 29.953 (29.953)	mem 40.012
Train: [70][405/750]	BT 0.088 (1.149)	DT 0.004 (1.105)	loss 6.667 (6.667)	prob 3.388 (3.388)	GS 31.453 (31.453)	mem 40.097
Train: [70][410/750]	BT 0.032 (1.161)	DT 0.001 (1.117)	loss 6.925 (6.925)	prob 2.801 (2.801)	GS 31.828 (31.828)	mem 39.941
Train: [70][415/750]	BT 0.030 (1.147)	DT 0.001 (1.104)	loss 6.965 (6.965)	prob 2.675 (2.675)	GS 26.266 (26.266)	mem 39.942
Train: [70][420/750]	BT 0.063 (1.164)	DT 0.004 (1.120)	loss 6.893 (6.893)	prob 2.322 (2.322)	GS 28.094 (28.094)	mem 39.780
Train: [70][425/750]	BT 0.036 (1.151)	DT 0.002 (1.107)	loss 6.758 (6.758)	prob 2.732 (2.732)	GS 24.203 (24.203)	mem 39.781
Train: [70][430/750]	BT 12.969 (1.168)	DT 12.939 (1.124)	loss 6.963 (6.963)	prob 3.076 (3.076)	GS 36.469 (36.469)	mem 39.856
Train: [70][435/750]	BT 0.035 (1.155)	DT 0.002 (1.112)	loss 6.997 (6.997)	prob 2.894 (2.894)	GS 32.172 (32.172)	mem 39.877
Train: [70][440/750]	BT 0.041 (1.144)	DT 0.002 (1.100)	loss 7.051 (7.051)	prob 1.987 (1.987)	GS 33.328 (33.328)	mem 40.076
Train: [70][445/750]	BT 0.037 (1.156)	DT 0.001 (1.112)	loss 7.145 (7.145)	prob 2.407 (2.407)	GS 31.656 (31.656)	mem 39.861
Train: [70][450/750]	BT 0.027 (1.151)	DT 0.005 (1.108)	loss 6.791 (6.791)	prob 2.639 (2.639)	GS 32.766 (32.766)	mem 39.823
Train: [70][455/750]	BT 0.030 (1.160)	DT 0.002 (1.117)	loss 6.954 (6.954)	prob 2.515 (2.515)	GS 33.438 (33.438)	mem 39.887
Train: [70][460/750]	BT 0.032 (1.155)	DT 0.002 (1.111)	loss 6.941 (6.941)	prob 2.462 (2.462)	GS 31.781 (31.781)	mem 39.980
Train: [70][465/750]	BT 0.056 (1.143)	DT 0.012 (1.100)	loss 7.234 (7.234)	prob 2.745 (2.745)	GS 34.812 (34.812)	mem 39.941
Train: [70][470/750]	BT 0.644 (1.152)	DT 0.615 (1.109)	loss 6.882 (6.882)	prob 2.908 (2.908)	GS 30.812 (30.812)	mem 39.936
Train: [70][475/750]	BT 0.038 (1.142)	DT 0.001 (1.099)	loss 6.851 (6.851)	prob 2.780 (2.780)	GS 31.266 (31.266)	mem 39.940
Train: [70][480/750]	BT 0.062 (1.156)	DT 0.017 (1.113)	loss 6.923 (6.923)	prob 3.263 (3.263)	GS 32.875 (32.875)	mem 39.939
Train: [70][485/750]	BT 0.050 (1.148)	DT 0.002 (1.104)	loss 6.816 (6.816)	prob 3.248 (3.248)	GS 29.062 (29.062)	mem 39.903
Train: [70][490/750]	BT 14.953 (1.167)	DT 14.924 (1.123)	loss 6.683 (6.683)	prob 2.920 (2.920)	GS 37.891 (37.891)	mem 39.854
Train: [70][495/750]	BT 0.070 (1.156)	DT 0.003 (1.112)	loss 7.154 (7.154)	prob 2.595 (2.595)	GS 26.797 (26.797)	mem 39.855
Train: [70][500/750]	BT 0.063 (1.145)	DT 0.015 (1.101)	loss 6.862 (6.862)	prob 2.553 (2.553)	GS 34.219 (34.219)	mem 39.870
Train: [70][505/750]	BT 0.054 (1.161)	DT 0.012 (1.118)	loss 6.692 (6.692)	prob 3.178 (3.178)	GS 35.281 (35.281)	mem 39.882
Train: [70][510/750]	BT 0.024 (1.150)	DT 0.001 (1.107)	loss 6.775 (6.775)	prob 3.107 (3.107)	GS 32.656 (32.656)	mem 39.894
Train: [70][515/750]	BT 0.085 (1.161)	DT 0.006 (1.118)	loss 6.985 (6.985)	prob 2.878 (2.878)	GS 31.969 (31.969)	mem 39.904
Train: [70][520/750]	BT 3.974 (1.158)	DT 3.842 (1.114)	loss 6.840 (6.840)	prob 2.711 (2.711)	GS 34.062 (34.062)	mem 39.956
Train: [70][525/750]	BT 0.039 (1.148)	DT 0.002 (1.104)	loss 7.065 (7.065)	prob 2.052 (2.052)	GS 30.375 (30.375)	mem 39.873
Train: [70][530/750]	BT 0.059 (1.159)	DT 0.013 (1.116)	loss 6.905 (6.905)	prob 2.674 (2.674)	GS 33.109 (33.109)	mem 39.946
Train: [70][535/750]	BT 0.037 (1.152)	DT 0.004 (1.108)	loss 6.926 (6.926)	prob 3.075 (3.075)	GS 28.875 (28.875)	mem 39.998
Train: [70][540/750]	BT 0.050 (1.164)	DT 0.012 (1.120)	loss 6.970 (6.970)	prob 3.056 (3.056)	GS 34.953 (34.953)	mem 39.936
Train: [70][545/750]	BT 0.039 (1.154)	DT 0.001 (1.110)	loss 6.857 (6.857)	prob 2.432 (2.432)	GS 34.078 (34.078)	mem 39.983
Train: [70][550/750]	BT 14.097 (1.169)	DT 14.066 (1.126)	loss 7.146 (7.146)	prob 1.771 (1.771)	GS 32.156 (32.156)	mem 39.786
Train: [70][555/750]	BT 0.095 (1.159)	DT 0.001 (1.115)	loss 7.049 (7.049)	prob 3.246 (3.246)	GS 26.922 (26.922)	mem 39.805
Train: [70][560/750]	BT 0.142 (1.149)	DT 0.034 (1.106)	loss 6.892 (6.892)	prob 2.401 (2.401)	GS 35.031 (35.031)	mem 40.042
Train: [70][565/750]	BT 0.038 (1.159)	DT 0.001 (1.115)	loss 6.984 (6.984)	prob 2.321 (2.321)	GS 33.641 (33.641)	mem 40.117
Train: [70][570/750]	BT 0.050 (1.153)	DT 0.001 (1.109)	loss 7.014 (7.014)	prob 2.971 (2.971)	GS 33.422 (33.422)	mem 39.925
Train: [70][575/750]	BT 0.047 (1.162)	DT 0.008 (1.117)	loss 6.867 (6.867)	prob 2.327 (2.327)	GS 29.297 (29.297)	mem 39.971
Train: [70][580/750]	BT 2.791 (1.157)	DT 2.752 (1.113)	loss 6.901 (6.901)	prob 2.485 (2.485)	GS 35.344 (35.344)	mem 39.894
Train: [70][585/750]	BT 0.054 (1.147)	DT 0.005 (1.103)	loss 7.002 (7.002)	prob 2.381 (2.381)	GS 32.281 (32.281)	mem 39.934
Train: [70][590/750]	BT 0.026 (1.154)	DT 0.001 (1.110)	loss 6.761 (6.761)	prob 2.652 (2.652)	GS 31.406 (31.406)	mem 39.952
Train: [70][595/750]	BT 0.039 (1.149)	DT 0.001 (1.105)	loss 6.765 (6.765)	prob 2.466 (2.466)	GS 30.312 (30.312)	mem 40.004
Train: [70][600/750]	BT 0.034 (1.150)	DT 0.002 (1.107)	loss 6.930 (6.930)	prob 2.304 (2.304)	GS 33.391 (33.391)	mem 39.964
Train: [70][605/750]	BT 0.052 (1.152)	DT 0.015 (1.108)	loss 6.781 (6.781)	prob 2.549 (2.549)	GS 28.281 (28.281)	mem 39.968
Train: [70][610/750]	BT 5.900 (1.152)	DT 5.867 (1.108)	loss 6.980 (6.980)	prob 2.660 (2.660)	GS 33.734 (33.734)	mem 39.920
Train: [70][615/750]	BT 0.044 (1.143)	DT 0.011 (1.099)	loss 7.184 (7.184)	prob 2.231 (2.231)	GS 33.266 (33.266)	mem 39.956
Train: [70][620/750]	BT 0.032 (1.141)	DT 0.001 (1.097)	loss 6.931 (6.931)	prob 2.777 (2.777)	GS 32.297 (32.297)	mem 39.991
Train: [70][625/750]	BT 0.033 (1.146)	DT 0.002 (1.103)	loss 6.829 (6.829)	prob 2.115 (2.115)	GS 29.906 (29.906)	mem 39.886
Train: [70][630/750]	BT 0.064 (1.143)	DT 0.009 (1.099)	loss 7.199 (7.199)	prob 1.595 (1.595)	GS 34.500 (34.500)	mem 40.181
Train: [70][635/750]	BT 0.032 (1.147)	DT 0.001 (1.104)	loss 7.011 (7.011)	prob 1.917 (1.917)	GS 33.016 (33.016)	mem 39.964
Train: [70][640/750]	BT 4.723 (1.147)	DT 4.692 (1.103)	loss 7.033 (7.033)	prob 1.710 (1.710)	GS 33.969 (33.969)	mem 39.916
Train: [70][645/750]	BT 0.027 (1.138)	DT 0.001 (1.095)	loss 6.858 (6.858)	prob 2.478 (2.478)	GS 29.906 (29.906)	mem 39.968
Train: [70][650/750]	BT 0.033 (1.141)	DT 0.001 (1.097)	loss 7.033 (7.033)	prob 1.776 (1.776)	GS 33.234 (33.234)	mem 39.975
Train: [70][655/750]	BT 0.025 (1.144)	DT 0.001 (1.100)	loss 6.881 (6.881)	prob 1.636 (1.636)	GS 30.719 (30.719)	mem 39.942
Train: [70][660/750]	BT 2.368 (1.149)	DT 2.307 (1.106)	loss 7.031 (7.031)	prob 1.528 (1.528)	GS 35.984 (35.984)	mem 40.012
Train: [70][665/750]	BT 0.062 (1.143)	DT 0.007 (1.099)	loss 6.943 (6.943)	prob 2.156 (2.156)	GS 30.312 (30.312)	mem 40.044
Train: [70][670/750]	BT 6.831 (1.145)	DT 6.798 (1.101)	loss 7.042 (7.042)	prob 1.898 (1.898)	GS 36.859 (36.859)	mem 39.963
Train: [70][675/750]	BT 0.038 (1.143)	DT 0.003 (1.100)	loss 6.764 (6.764)	prob 2.758 (2.758)	GS 34.078 (34.078)	mem 39.973
Train: [70][680/750]	BT 0.097 (1.139)	DT 0.001 (1.096)	loss 6.716 (6.716)	prob 1.956 (1.956)	GS 32.266 (32.266)	mem 40.008
Train: [70][685/750]	BT 0.042 (1.146)	DT 0.008 (1.102)	loss 7.147 (7.147)	prob 1.644 (1.644)	GS 31.359 (31.359)	mem 40.241
Train: [70][690/750]	BT 0.061 (1.144)	DT 0.012 (1.100)	loss 6.752 (6.752)	prob 2.065 (2.065)	GS 33.500 (33.500)	mem 39.999
Train: [70][695/750]	BT 0.042 (1.140)	DT 0.005 (1.097)	loss 6.846 (6.846)	prob 2.120 (2.120)	GS 33.922 (33.922)	mem 40.049
Train: [70][700/750]	BT 3.094 (1.145)	DT 3.031 (1.101)	loss 6.777 (6.777)	prob 1.693 (1.693)	GS 32.734 (32.734)	mem 39.994
Train: [70][705/750]	BT 0.046 (1.137)	DT 0.013 (1.093)	loss 6.856 (6.856)	prob 2.252 (2.252)	GS 35.422 (35.422)	mem 39.994
Train: [70][710/750]	BT 0.024 (1.145)	DT 0.001 (1.102)	loss 7.137 (7.137)	prob 2.355 (2.355)	GS 33.203 (33.203)	mem 39.939
Train: [70][715/750]	BT 0.071 (1.144)	DT 0.016 (1.101)	loss 7.012 (7.012)	prob 2.697 (2.697)	GS 33.641 (33.641)	mem 40.054
Train: [70][720/750]	BT 4.315 (1.145)	DT 4.254 (1.101)	loss 6.999 (6.999)	prob 1.981 (1.981)	GS 31.328 (31.328)	mem 39.991
Train: [70][725/750]	BT 0.059 (1.145)	DT 0.006 (1.101)	loss 6.929 (6.929)	prob 2.177 (2.177)	GS 31.297 (31.297)	mem 39.828
Train: [70][730/750]	BT 4.367 (1.143)	DT 4.335 (1.100)	loss 6.718 (6.718)	prob 2.124 (2.124)	GS 37.688 (37.688)	mem 39.717
Train: [70][735/750]	BT 0.028 (1.136)	DT 0.001 (1.092)	loss 7.011 (7.011)	prob 2.898 (2.898)	GS 32.344 (32.344)	mem 39.714
Train: [70][740/750]	BT 0.032 (1.136)	DT 0.001 (1.092)	loss 6.932 (6.932)	prob 2.229 (2.229)	GS 34.531 (34.531)	mem 13.687
Train: [70][745/750]	BT 0.023 (1.133)	DT 0.001 (1.090)	loss 6.967 (6.967)	prob 2.201 (2.201)	GS 31.750 (31.750)	mem 10.606
Train: [70][750/750]	BT 0.027 (1.126)	DT 0.001 (1.082)	loss 6.968 (6.968)	prob 2.372 (2.372)	GS 29.938 (29.938)	mem 10.606
Train: [70][755/750]	BT 0.030 (1.120)	DT 0.001 (1.076)	loss 6.884 (6.884)	prob 1.993 (1.993)	GS 23.625 (23.625)	mem 10.571
epoch 70, total time 847.49
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [71][1/750]	BT 19.722 (19.722)	DT 19.673 (19.673)	loss 6.895 (6.895)	prob 2.484 (2.484)	GS 27.562 (27.562)	mem 38.561
Train: [71][5/750]	BT 0.034 (4.800)	DT 0.002 (4.735)	loss 6.753 (6.753)	prob 2.164 (2.164)	GS 29.641 (29.641)	mem 38.687
Train: [71][10/750]	BT 4.481 (2.977)	DT 4.417 (2.919)	loss 7.041 (7.041)	prob 1.972 (1.972)	GS 36.359 (36.359)	mem 38.755
Train: [71][15/750]	BT 0.033 (2.879)	DT 0.002 (2.822)	loss 6.847 (6.847)	prob 2.577 (2.577)	GS 27.734 (27.734)	mem 38.958
Train: [71][20/750]	BT 0.119 (2.181)	DT 0.025 (2.126)	loss 6.744 (6.744)	prob 1.992 (1.992)	GS 31.516 (31.516)	mem 38.906
Train: [71][25/750]	BT 0.040 (1.871)	DT 0.001 (1.819)	loss 6.972 (6.972)	prob 2.275 (2.275)	GS 32.562 (32.562)	mem 38.926
Train: [71][30/750]	BT 0.383 (1.867)	DT 0.334 (1.811)	loss 6.775 (6.775)	prob 2.402 (2.402)	GS 30.156 (30.156)	mem 39.028
Train: [71][35/750]	BT 0.092 (1.670)	DT 0.002 (1.611)	loss 6.845 (6.845)	prob 2.128 (2.128)	GS 29.672 (29.672)	mem 39.052
Train: [71][40/750]	BT 0.060 (1.765)	DT 0.016 (1.709)	loss 6.587 (6.587)	prob 2.164 (2.164)	GS 34.312 (34.312)	mem 39.060
Train: [71][45/750]	BT 0.060 (1.584)	DT 0.002 (1.530)	loss 6.929 (6.929)	prob 1.886 (1.886)	GS 29.984 (29.984)	mem 39.079
Train: [71][50/750]	BT 11.603 (1.677)	DT 11.574 (1.624)	loss 6.831 (6.831)	prob 2.145 (2.145)	GS 33.891 (33.891)	mem 39.055
Train: [71][55/750]	BT 0.033 (1.530)	DT 0.001 (1.477)	loss 7.019 (7.019)	prob 2.201 (2.201)	GS 44.078 (44.078)	mem 39.055
Train: [71][60/750]	BT 0.033 (1.421)	DT 0.001 (1.369)	loss 6.800 (6.800)	prob 2.496 (2.496)	GS 32.031 (32.031)	mem 39.094
Train: [71][65/750]	BT 0.029 (1.470)	DT 0.001 (1.420)	loss 6.913 (6.913)	prob 2.213 (2.213)	GS 33.891 (33.891)	mem 39.077
Train: [71][70/750]	BT 2.208 (1.399)	DT 2.167 (1.349)	loss 7.008 (7.008)	prob 2.377 (2.377)	GS 32.516 (32.516)	mem 39.183
Train: [71][75/750]	BT 0.026 (1.470)	DT 0.001 (1.421)	loss 6.983 (6.983)	prob 2.688 (2.688)	GS 31.781 (31.781)	mem 39.409
Train: [71][80/750]	BT 0.045 (1.381)	DT 0.004 (1.332)	loss 6.989 (6.989)	prob 2.538 (2.538)	GS 36.984 (36.984)	mem 39.372
Train: [71][85/750]	BT 0.027 (1.324)	DT 0.001 (1.275)	loss 7.213 (7.213)	prob 2.327 (2.327)	GS 34.359 (34.359)	mem 39.390
Train: [71][90/750]	BT 0.026 (1.441)	DT 0.002 (1.393)	loss 6.727 (6.727)	prob 2.937 (2.937)	GS 33.656 (33.656)	mem 39.388
Train: [71][95/750]	BT 0.026 (1.367)	DT 0.001 (1.319)	loss 7.030 (7.030)	prob 2.042 (2.042)	GS 27.891 (27.891)	mem 39.390
Train: [71][100/750]	BT 0.031 (1.428)	DT 0.001 (1.381)	loss 7.158 (7.158)	prob 2.134 (2.134)	GS 30.297 (30.297)	mem 39.508
Train: [71][105/750]	BT 0.173 (1.363)	DT 0.040 (1.315)	loss 7.022 (7.022)	prob 2.427 (2.427)	GS 32.234 (32.234)	mem 39.626
Train: [71][110/750]	BT 13.313 (1.423)	DT 13.272 (1.376)	loss 7.150 (7.150)	prob 2.155 (2.155)	GS 33.500 (33.500)	mem 39.618
Train: [71][115/750]	BT 0.068 (1.363)	DT 0.002 (1.317)	loss 6.975 (6.975)	prob 2.584 (2.584)	GS 33.094 (33.094)	mem 39.617
Train: [71][120/750]	BT 0.032 (1.308)	DT 0.001 (1.262)	loss 6.781 (6.781)	prob 2.308 (2.308)	GS 32.172 (32.172)	mem 39.638
Train: [71][125/750]	BT 0.035 (1.336)	DT 0.002 (1.291)	loss 6.895 (6.895)	prob 2.107 (2.107)	GS 29.203 (29.203)	mem 39.727
Train: [71][130/750]	BT 0.033 (1.287)	DT 0.001 (1.241)	loss 7.179 (7.179)	prob 2.332 (2.332)	GS 35.375 (35.375)	mem 39.727
Train: [71][135/750]	BT 0.028 (1.331)	DT 0.004 (1.286)	loss 6.925 (6.925)	prob 2.043 (2.043)	GS 25.422 (25.422)	mem 39.578
Train: [71][140/750]	BT 0.041 (1.286)	DT 0.018 (1.240)	loss 7.171 (7.171)	prob 2.167 (2.167)	GS 32.406 (32.406)	mem 39.636
Train: [71][145/750]	BT 0.081 (1.244)	DT 0.004 (1.197)	loss 6.844 (6.844)	prob 2.702 (2.702)	GS 30.047 (30.047)	mem 39.580
Train: [71][150/750]	BT 0.047 (1.303)	DT 0.001 (1.257)	loss 6.788 (6.788)	prob 3.328 (3.328)	GS 34.078 (34.078)	mem 39.565
Train: [71][155/750]	BT 0.032 (1.262)	DT 0.001 (1.216)	loss 6.736 (6.736)	prob 2.987 (2.987)	GS 31.984 (31.984)	mem 39.566
Train: [71][160/750]	BT 0.027 (1.303)	DT 0.001 (1.257)	loss 6.799 (6.799)	prob 2.522 (2.522)	GS 35.562 (35.562)	mem 39.599
Train: [71][165/750]	BT 0.069 (1.265)	DT 0.011 (1.219)	loss 6.830 (6.830)	prob 2.456 (2.456)	GS 30.844 (30.844)	mem 39.629
Train: [71][170/750]	BT 14.578 (1.315)	DT 14.548 (1.269)	loss 7.041 (7.041)	prob 2.661 (2.661)	GS 34.766 (34.766)	mem 39.636
Train: [71][175/750]	BT 0.043 (1.280)	DT 0.004 (1.233)	loss 6.798 (6.798)	prob 2.531 (2.531)	GS 30.078 (30.078)	mem 39.729
Train: [71][180/750]	BT 0.057 (1.246)	DT 0.004 (1.199)	loss 6.716 (6.716)	prob 2.978 (2.978)	GS 34.297 (34.297)	mem 39.914
Train: [71][185/750]	BT 0.117 (1.287)	DT 0.050 (1.241)	loss 6.966 (6.966)	prob 1.858 (1.858)	GS 36.656 (36.656)	mem 39.618
Train: [71][190/750]	BT 0.025 (1.255)	DT 0.001 (1.208)	loss 6.811 (6.811)	prob 2.747 (2.747)	GS 33.375 (33.375)	mem 39.657
Train: [71][195/750]	BT 0.042 (1.303)	DT 0.007 (1.256)	loss 7.081 (7.081)	prob 3.002 (3.002)	GS 34.391 (34.391)	mem 39.677
Train: [71][200/750]	BT 0.031 (1.271)	DT 0.001 (1.225)	loss 6.819 (6.819)	prob 2.965 (2.965)	GS 39.344 (39.344)	mem 39.677
Train: [71][205/750]	BT 0.062 (1.241)	DT 0.003 (1.195)	loss 6.553 (6.553)	prob 2.924 (2.924)	GS 33.234 (33.234)	mem 39.711
Train: [71][210/750]	BT 0.046 (1.274)	DT 0.004 (1.229)	loss 6.693 (6.693)	prob 2.538 (2.538)	GS 34.625 (34.625)	mem 39.785
Train: [71][215/750]	BT 0.024 (1.246)	DT 0.001 (1.200)	loss 7.076 (7.076)	prob 2.522 (2.522)	GS 33.859 (33.859)	mem 39.811
Train: [71][220/750]	BT 0.028 (1.270)	DT 0.001 (1.225)	loss 6.885 (6.885)	prob 2.974 (2.974)	GS 33.328 (33.328)	mem 39.708
Train: [71][225/750]	BT 0.030 (1.243)	DT 0.001 (1.198)	loss 6.823 (6.823)	prob 2.926 (2.926)	GS 28.719 (28.719)	mem 39.715
Train: [71][230/750]	BT 13.659 (1.276)	DT 13.628 (1.231)	loss 6.932 (6.932)	prob 2.457 (2.457)	GS 36.094 (36.094)	mem 39.810
Train: [71][235/750]	BT 0.133 (1.250)	DT 0.077 (1.206)	loss 6.919 (6.919)	prob 2.795 (2.795)	GS 32.766 (32.766)	mem 39.810
Train: [71][240/750]	BT 0.039 (1.225)	DT 0.001 (1.181)	loss 6.885 (6.885)	prob 1.812 (1.812)	GS 31.703 (31.703)	mem 39.811
Train: [71][245/750]	BT 0.030 (1.252)	DT 0.001 (1.208)	loss 6.718 (6.718)	prob 2.644 (2.644)	GS 34.234 (34.234)	mem 39.782
Train: [71][250/750]	BT 0.027 (1.227)	DT 0.001 (1.184)	loss 6.897 (6.897)	prob 2.393 (2.393)	GS 36.469 (36.469)	mem 39.785
Train: [71][255/750]	BT 0.031 (1.258)	DT 0.001 (1.215)	loss 7.007 (7.007)	prob 1.918 (1.918)	GS 32.875 (32.875)	mem 39.862
Train: [71][260/750]	BT 0.022 (1.235)	DT 0.001 (1.191)	loss 6.840 (6.840)	prob 2.322 (2.322)	GS 32.938 (32.938)	mem 39.863
Train: [71][265/750]	BT 0.116 (1.213)	DT 0.006 (1.169)	loss 6.567 (6.567)	prob 3.613 (3.613)	GS 24.922 (24.922)	mem 39.864
Train: [71][270/750]	BT 0.044 (1.239)	DT 0.002 (1.195)	loss 6.590 (6.590)	prob 3.042 (3.042)	GS 33.266 (33.266)	mem 39.890
Train: [71][275/750]	BT 0.030 (1.217)	DT 0.001 (1.174)	loss 6.980 (6.980)	prob 2.596 (2.596)	GS 34.078 (34.078)	mem 39.890
Train: [71][280/750]	BT 0.034 (1.247)	DT 0.001 (1.204)	loss 6.877 (6.877)	prob 2.768 (2.768)	GS 33.609 (33.609)	mem 39.855
Train: [71][285/750]	BT 0.051 (1.226)	DT 0.002 (1.183)	loss 6.823 (6.823)	prob 2.341 (2.341)	GS 26.859 (26.859)	mem 39.856
Train: [71][290/750]	BT 13.570 (1.252)	DT 13.541 (1.209)	loss 7.010 (7.010)	prob 2.827 (2.827)	GS 37.500 (37.500)	mem 39.840
Train: [71][295/750]	BT 0.044 (1.232)	DT 0.002 (1.189)	loss 6.717 (6.717)	prob 3.046 (3.046)	GS 30.031 (30.031)	mem 39.946
Train: [71][300/750]	BT 0.032 (1.212)	DT 0.001 (1.169)	loss 7.102 (7.102)	prob 2.207 (2.207)	GS 34.516 (34.516)	mem 39.847
Train: [71][305/750]	BT 0.022 (1.228)	DT 0.001 (1.185)	loss 6.949 (6.949)	prob 2.691 (2.691)	GS 28.359 (28.359)	mem 39.895
Train: [71][310/750]	BT 0.043 (1.208)	DT 0.002 (1.166)	loss 7.146 (7.146)	prob 2.261 (2.261)	GS 31.391 (31.391)	mem 39.896
Train: [71][315/750]	BT 0.038 (1.226)	DT 0.008 (1.183)	loss 6.864 (6.864)	prob 2.564 (2.564)	GS 29.656 (29.656)	mem 39.891
Train: [71][320/750]	BT 0.053 (1.208)	DT 0.013 (1.165)	loss 6.620 (6.620)	prob 2.709 (2.709)	GS 32.531 (32.531)	mem 39.886
Train: [71][325/750]	BT 0.065 (1.190)	DT 0.015 (1.147)	loss 6.812 (6.812)	prob 3.220 (3.220)	GS 32.000 (32.000)	mem 39.883
Train: [71][330/750]	BT 0.020 (1.217)	DT 0.001 (1.174)	loss 7.005 (7.005)	prob 2.950 (2.950)	GS 34.781 (34.781)	mem 39.895
Train: [71][335/750]	BT 0.077 (1.199)	DT 0.022 (1.157)	loss 6.579 (6.579)	prob 2.467 (2.467)	GS 31.000 (31.000)	mem 39.895
Train: [71][340/750]	BT 0.023 (1.218)	DT 0.001 (1.175)	loss 6.987 (6.987)	prob 2.642 (2.642)	GS 31.109 (31.109)	mem 39.758
Train: [71][345/750]	BT 0.038 (1.201)	DT 0.001 (1.158)	loss 6.597 (6.597)	prob 2.889 (2.889)	GS 33.594 (33.594)	mem 39.809
Train: [71][350/750]	BT 9.431 (1.212)	DT 9.400 (1.168)	loss 6.745 (6.745)	prob 3.288 (3.288)	GS 29.078 (29.078)	mem 40.112
Train: [71][355/750]	BT 0.075 (1.195)	DT 0.002 (1.152)	loss 6.652 (6.652)	prob 3.037 (3.037)	GS 31.656 (31.656)	mem 39.851
Train: [71][360/750]	BT 0.099 (1.180)	DT 0.003 (1.136)	loss 6.673 (6.673)	prob 2.837 (2.837)	GS 33.766 (33.766)	mem 39.853
Train: [71][365/750]	BT 0.059 (1.200)	DT 0.004 (1.156)	loss 6.686 (6.686)	prob 2.704 (2.704)	GS 31.891 (31.891)	mem 40.024
Train: [71][370/750]	BT 0.066 (1.184)	DT 0.001 (1.140)	loss 7.091 (7.091)	prob 2.896 (2.896)	GS 36.438 (36.438)	mem 39.906
Train: [71][375/750]	BT 0.065 (1.199)	DT 0.010 (1.155)	loss 6.877 (6.877)	prob 2.981 (2.981)	GS 35.672 (35.672)	mem 40.006
Train: [71][380/750]	BT 0.070 (1.184)	DT 0.003 (1.140)	loss 6.954 (6.954)	prob 2.891 (2.891)	GS 32.969 (32.969)	mem 39.984
Train: [71][385/750]	BT 0.061 (1.169)	DT 0.003 (1.125)	loss 6.993 (6.993)	prob 3.013 (3.013)	GS 26.188 (26.188)	mem 39.942
Train: [71][390/750]	BT 0.032 (1.186)	DT 0.001 (1.142)	loss 7.062 (7.062)	prob 2.606 (2.606)	GS 37.750 (37.750)	mem 39.851
Train: [71][395/750]	BT 0.049 (1.172)	DT 0.002 (1.128)	loss 7.058 (7.058)	prob 2.806 (2.806)	GS 29.266 (29.266)	mem 39.853
Train: [71][400/750]	BT 0.031 (1.187)	DT 0.001 (1.143)	loss 6.933 (6.933)	prob 2.788 (2.788)	GS 30.875 (30.875)	mem 39.920
Train: [71][405/750]	BT 0.031 (1.173)	DT 0.001 (1.129)	loss 6.859 (6.859)	prob 2.469 (2.469)	GS 31.344 (31.344)	mem 39.920
Train: [71][410/750]	BT 11.764 (1.188)	DT 11.733 (1.144)	loss 6.815 (6.815)	prob 3.553 (3.553)	GS 33.891 (33.891)	mem 39.932
Train: [71][415/750]	BT 0.023 (1.174)	DT 0.001 (1.130)	loss 7.055 (7.055)	prob 3.032 (3.032)	GS 29.266 (29.266)	mem 39.932
Train: [71][420/750]	BT 0.045 (1.162)	DT 0.001 (1.118)	loss 6.970 (6.970)	prob 2.664 (2.664)	GS 31.750 (31.750)	mem 39.941
Train: [71][425/750]	BT 0.033 (1.183)	DT 0.001 (1.139)	loss 7.060 (7.060)	prob 2.619 (2.619)	GS 28.922 (28.922)	mem 39.963
Train: [71][430/750]	BT 0.064 (1.170)	DT 0.007 (1.126)	loss 6.991 (6.991)	prob 2.799 (2.799)	GS 38.031 (38.031)	mem 39.770
Train: [71][435/750]	BT 0.080 (1.181)	DT 0.004 (1.137)	loss 7.110 (7.110)	prob 2.621 (2.621)	GS 29.656 (29.656)	mem 39.867
Train: [71][440/750]	BT 0.042 (1.175)	DT 0.001 (1.131)	loss 7.059 (7.059)	prob 2.686 (2.686)	GS 36.188 (36.188)	mem 39.932
Train: [71][445/750]	BT 0.046 (1.163)	DT 0.001 (1.119)	loss 7.145 (7.145)	prob 2.252 (2.252)	GS 31.109 (31.109)	mem 39.883
Train: [71][450/750]	BT 1.458 (1.185)	DT 1.428 (1.141)	loss 7.191 (7.191)	prob 2.859 (2.859)	GS 35.734 (35.734)	mem 39.808
Train: [71][455/750]	BT 0.043 (1.172)	DT 0.002 (1.128)	loss 6.805 (6.805)	prob 2.990 (2.990)	GS 31.578 (31.578)	mem 39.815
Train: [71][460/750]	BT 0.032 (1.185)	DT 0.002 (1.141)	loss 7.174 (7.174)	prob 2.435 (2.435)	GS 34.328 (34.328)	mem 39.819
Train: [71][465/750]	BT 0.060 (1.173)	DT 0.002 (1.129)	loss 7.143 (7.143)	prob 2.441 (2.441)	GS 30.984 (30.984)	mem 39.818
Train: [71][470/750]	BT 12.451 (1.187)	DT 12.427 (1.143)	loss 6.967 (6.967)	prob 2.790 (2.790)	GS 34.797 (34.797)	mem 39.915
Train: [71][475/750]	BT 0.032 (1.176)	DT 0.010 (1.132)	loss 7.098 (7.098)	prob 3.175 (3.175)	GS 34.406 (34.406)	mem 39.920
Train: [71][480/750]	BT 0.062 (1.164)	DT 0.011 (1.121)	loss 6.827 (6.827)	prob 3.053 (3.053)	GS 36.188 (36.188)	mem 40.009
Train: [71][485/750]	BT 0.036 (1.180)	DT 0.005 (1.136)	loss 7.062 (7.062)	prob 3.145 (3.145)	GS 30.266 (30.266)	mem 40.006
Train: [71][490/750]	BT 0.047 (1.168)	DT 0.004 (1.124)	loss 6.971 (6.971)	prob 2.209 (2.209)	GS 34.516 (34.516)	mem 40.008
Train: [71][495/750]	BT 0.024 (1.181)	DT 0.001 (1.137)	loss 7.011 (7.011)	prob 2.429 (2.429)	GS 28.250 (28.250)	mem 40.009
Train: [71][500/750]	BT 0.030 (1.170)	DT 0.001 (1.126)	loss 6.960 (6.960)	prob 2.817 (2.817)	GS 33.375 (33.375)	mem 40.010
Train: [71][505/750]	BT 0.077 (1.159)	DT 0.018 (1.115)	loss 7.133 (7.133)	prob 2.551 (2.551)	GS 32.672 (32.672)	mem 40.010
Train: [71][510/750]	BT 0.038 (1.174)	DT 0.002 (1.130)	loss 7.207 (7.207)	prob 3.147 (3.147)	GS 29.984 (29.984)	mem 39.897
Train: [71][515/750]	BT 0.078 (1.164)	DT 0.017 (1.120)	loss 6.820 (6.820)	prob 2.912 (2.912)	GS 28.047 (28.047)	mem 39.899
Train: [71][520/750]	BT 0.032 (1.175)	DT 0.001 (1.131)	loss 6.887 (6.887)	prob 2.620 (2.620)	GS 32.516 (32.516)	mem 39.925
Train: [71][525/750]	BT 0.024 (1.164)	DT 0.001 (1.120)	loss 6.875 (6.875)	prob 2.925 (2.925)	GS 33.031 (33.031)	mem 39.926
Train: [71][530/750]	BT 10.752 (1.174)	DT 10.708 (1.130)	loss 6.784 (6.784)	prob 2.398 (2.398)	GS 33.203 (33.203)	mem 40.036
Train: [71][535/750]	BT 0.118 (1.163)	DT 0.002 (1.119)	loss 6.902 (6.902)	prob 2.725 (2.725)	GS 32.578 (32.578)	mem 40.125
Train: [71][540/750]	BT 0.038 (1.153)	DT 0.002 (1.109)	loss 6.947 (6.947)	prob 2.358 (2.358)	GS 32.734 (32.734)	mem 39.977
Train: [71][545/750]	BT 0.092 (1.161)	DT 0.013 (1.117)	loss 7.228 (7.228)	prob 1.931 (1.931)	GS 26.781 (26.781)	mem 39.927
Train: [71][550/750]	BT 0.039 (1.151)	DT 0.009 (1.107)	loss 6.831 (6.831)	prob 2.216 (2.216)	GS 34.250 (34.250)	mem 39.929
Train: [71][555/750]	BT 0.038 (1.166)	DT 0.001 (1.121)	loss 6.656 (6.656)	prob 2.532 (2.532)	GS 31.766 (31.766)	mem 40.106
Train: [71][560/750]	BT 0.031 (1.156)	DT 0.001 (1.111)	loss 6.770 (6.770)	prob 2.566 (2.566)	GS 34.578 (34.578)	mem 39.980
Train: [71][565/750]	BT 0.077 (1.146)	DT 0.005 (1.102)	loss 6.903 (6.903)	prob 2.566 (2.566)	GS 27.625 (27.625)	mem 39.981
Train: [71][570/750]	BT 0.033 (1.162)	DT 0.003 (1.118)	loss 6.781 (6.781)	prob 2.869 (2.869)	GS 40.453 (40.453)	mem 40.018
Train: [71][575/750]	BT 0.085 (1.152)	DT 0.001 (1.108)	loss 6.836 (6.836)	prob 2.276 (2.276)	GS 31.859 (31.859)	mem 40.018
Train: [71][580/750]	BT 0.026 (1.162)	DT 0.001 (1.118)	loss 6.841 (6.841)	prob 1.940 (1.940)	GS 28.312 (28.312)	mem 39.993
Train: [71][585/750]	BT 0.046 (1.152)	DT 0.003 (1.108)	loss 6.830 (6.830)	prob 1.769 (1.769)	GS 31.812 (31.812)	mem 39.917
Train: [71][590/750]	BT 14.319 (1.167)	DT 14.285 (1.123)	loss 6.846 (6.846)	prob 2.401 (2.401)	GS 36.141 (36.141)	mem 39.951
Train: [71][595/750]	BT 0.027 (1.158)	DT 0.001 (1.114)	loss 6.867 (6.867)	prob 2.366 (2.366)	GS 36.688 (36.688)	mem 39.954
Train: [71][600/750]	BT 0.101 (1.148)	DT 0.001 (1.104)	loss 6.996 (6.996)	prob 2.277 (2.277)	GS 34.609 (34.609)	mem 39.995
Train: [71][605/750]	BT 0.031 (1.161)	DT 0.001 (1.117)	loss 6.754 (6.754)	prob 2.615 (2.615)	GS 31.344 (31.344)	mem 39.890
Train: [71][610/750]	BT 0.051 (1.152)	DT 0.001 (1.108)	loss 6.818 (6.818)	prob 2.970 (2.970)	GS 35.594 (35.594)	mem 39.890
Train: [71][615/750]	BT 0.055 (1.159)	DT 0.009 (1.115)	loss 6.959 (6.959)	prob 2.190 (2.190)	GS 34.328 (34.328)	mem 39.978
Train: [71][620/750]	BT 0.036 (1.150)	DT 0.001 (1.106)	loss 6.963 (6.963)	prob 2.286 (2.286)	GS 29.156 (29.156)	mem 39.987
Train: [71][625/750]	BT 0.033 (1.141)	DT 0.002 (1.098)	loss 6.933 (6.933)	prob 2.198 (2.198)	GS 30.578 (30.578)	mem 39.988
Train: [71][630/750]	BT 0.025 (1.155)	DT 0.001 (1.111)	loss 6.955 (6.955)	prob 2.102 (2.102)	GS 35.969 (35.969)	mem 39.966
Train: [71][635/750]	BT 0.084 (1.146)	DT 0.003 (1.103)	loss 6.885 (6.885)	prob 1.976 (1.976)	GS 32.812 (32.812)	mem 39.967
Train: [71][640/750]	BT 0.052 (1.157)	DT 0.011 (1.114)	loss 7.042 (7.042)	prob 2.017 (2.017)	GS 30.062 (30.062)	mem 39.934
Train: [71][645/750]	BT 0.032 (1.149)	DT 0.001 (1.105)	loss 6.718 (6.718)	prob 1.894 (1.894)	GS 28.812 (28.812)	mem 39.964
Train: [71][650/750]	BT 12.309 (1.159)	DT 12.285 (1.116)	loss 6.919 (6.919)	prob 2.182 (2.182)	GS 30.047 (30.047)	mem 39.946
Train: [71][655/750]	BT 0.025 (1.150)	DT 0.001 (1.107)	loss 7.133 (7.133)	prob 1.898 (1.898)	GS 30.062 (30.062)	mem 39.948
arpack error, retry= 0
Train: [71][660/750]	BT 2.403 (1.146)	DT 2.318 (1.102)	loss 6.946 (6.946)	prob 1.722 (1.722)	GS 30.328 (30.328)	mem 39.918
Train: [71][665/750]	BT 0.033 (1.150)	DT 0.001 (1.106)	loss 7.146 (7.146)	prob 2.069 (2.069)	GS 34.141 (34.141)	mem 39.970
Train: [71][670/750]	BT 1.000 (1.143)	DT 0.952 (1.099)	loss 6.783 (6.783)	prob 2.329 (2.329)	GS 34.969 (34.969)	mem 39.933
Train: [71][675/750]	BT 0.023 (1.153)	DT 0.001 (1.110)	loss 6.886 (6.886)	prob 2.571 (2.571)	GS 30.484 (30.484)	mem 39.966
Train: [71][680/750]	BT 0.108 (1.145)	DT 0.028 (1.102)	loss 6.614 (6.614)	prob 2.463 (2.463)	GS 33.266 (33.266)	mem 39.967
Train: [71][685/750]	BT 0.086 (1.138)	DT 0.013 (1.095)	loss 7.025 (7.025)	prob 1.668 (1.668)	GS 31.156 (31.156)	mem 39.986
Train: [71][690/750]	BT 0.032 (1.150)	DT 0.001 (1.107)	loss 6.580 (6.580)	prob 2.077 (2.077)	GS 35.359 (35.359)	mem 39.914
Train: [71][695/750]	BT 0.042 (1.142)	DT 0.001 (1.099)	loss 7.179 (7.179)	prob 2.025 (2.025)	GS 35.500 (35.500)	mem 39.970
Train: [71][700/750]	BT 0.030 (1.151)	DT 0.001 (1.107)	loss 6.956 (6.956)	prob 1.626 (1.626)	GS 35.125 (35.125)	mem 39.918
Train: [71][705/750]	BT 0.035 (1.143)	DT 0.001 (1.099)	loss 7.092 (7.092)	prob 2.002 (2.002)	GS 33.438 (33.438)	mem 39.919
Train: [71][710/750]	BT 10.773 (1.153)	DT 10.717 (1.110)	loss 6.680 (6.680)	prob 2.422 (2.422)	GS 32.844 (32.844)	mem 39.947
Train: [71][715/750]	BT 0.040 (1.148)	DT 0.002 (1.105)	loss 6.913 (6.913)	prob 2.748 (2.748)	GS 32.281 (32.281)	mem 40.001
Train: [71][720/750]	BT 0.100 (1.140)	DT 0.010 (1.097)	loss 7.107 (7.107)	prob 1.804 (1.804)	GS 31.203 (31.203)	mem 39.898
Train: [71][725/750]	BT 0.052 (1.152)	DT 0.024 (1.109)	loss 7.319 (7.319)	prob 1.412 (1.412)	GS 32.750 (32.750)	mem 39.866
Train: [71][730/750]	BT 2.034 (1.147)	DT 1.983 (1.104)	loss 6.894 (6.894)	prob 1.801 (1.801)	GS 34.234 (34.234)	mem 39.958
Train: [71][735/750]	BT 0.035 (1.146)	DT 0.004 (1.103)	loss 6.898 (6.898)	prob 2.801 (2.801)	GS 33.906 (33.906)	mem 36.671
Train: [71][740/750]	BT 0.022 (1.145)	DT 0.001 (1.102)	loss 6.957 (6.957)	prob 2.781 (2.781)	GS 34.609 (34.609)	mem 13.511
Train: [71][745/750]	BT 0.028 (1.138)	DT 0.001 (1.095)	loss 7.160 (7.160)	prob 2.778 (2.778)	GS 38.844 (38.844)	mem 13.537
Train: [71][750/750]	BT 0.033 (1.133)	DT 0.001 (1.090)	loss 7.022 (7.022)	prob 2.427 (2.427)	GS 33.156 (33.156)	mem 10.536
Train: [71][755/750]	BT 0.029 (1.129)	DT 0.001 (1.087)	loss 6.589 (6.589)	prob 2.672 (2.672)	GS 29.688 (29.688)	mem 7.574
epoch 71, total time 852.98
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [72][1/750]	BT 26.770 (26.770)	DT 26.665 (26.665)	loss 7.393 (7.393)	prob 1.511 (1.511)	GS 37.688 (37.688)	mem 38.649
Train: [72][5/750]	BT 0.032 (5.414)	DT 0.001 (5.362)	loss 7.054 (7.054)	prob 1.955 (1.955)	GS 30.641 (30.641)	mem 38.466
Train: [72][10/750]	BT 0.034 (2.754)	DT 0.001 (2.709)	loss 6.822 (6.822)	prob 2.553 (2.553)	GS 44.516 (44.516)	mem 38.406
Train: [72][15/750]	BT 0.121 (2.820)	DT 0.036 (2.774)	loss 6.820 (6.820)	prob 2.661 (2.661)	GS 29.562 (29.562)	mem 38.783
Train: [72][20/750]	BT 0.074 (2.299)	DT 0.012 (2.255)	loss 7.009 (7.009)	prob 2.037 (2.037)	GS 33.266 (33.266)	mem 38.773
Train: [72][25/750]	BT 0.756 (1.883)	DT 0.707 (1.833)	loss 6.886 (6.886)	prob 2.618 (2.618)	GS 33.406 (33.406)	mem 38.809
Train: [72][30/750]	BT 0.083 (1.894)	DT 0.001 (1.841)	loss 6.907 (6.907)	prob 2.417 (2.417)	GS 35.281 (35.281)	mem 38.864
Train: [72][35/750]	BT 0.055 (1.635)	DT 0.003 (1.579)	loss 7.041 (7.041)	prob 2.691 (2.691)	GS 32.562 (32.562)	mem 38.866
Train: [72][40/750]	BT 4.301 (1.833)	DT 4.265 (1.778)	loss 6.984 (6.984)	prob 2.082 (2.082)	GS 34.656 (34.656)	mem 39.242
Train: [72][45/750]	BT 0.037 (1.634)	DT 0.001 (1.581)	loss 7.379 (7.379)	prob 2.433 (2.433)	GS 29.766 (29.766)	mem 39.295
Train: [72][50/750]	BT 6.697 (1.670)	DT 6.650 (1.616)	loss 6.749 (6.749)	prob 2.514 (2.514)	GS 34.672 (34.672)	mem 39.416
Train: [72][55/750]	BT 0.045 (1.619)	DT 0.005 (1.566)	loss 6.974 (6.974)	prob 2.689 (2.689)	GS 27.562 (27.562)	mem 39.592
Train: [72][60/750]	BT 0.027 (1.489)	DT 0.001 (1.435)	loss 7.007 (7.007)	prob 2.443 (2.443)	GS 29.781 (29.781)	mem 39.444
Train: [72][65/750]	BT 0.059 (1.597)	DT 0.001 (1.544)	loss 6.966 (6.966)	prob 2.466 (2.466)	GS 33.812 (33.812)	mem 39.505
Train: [72][70/750]	BT 0.032 (1.485)	DT 0.001 (1.434)	loss 7.026 (7.026)	prob 2.293 (2.293)	GS 30.797 (30.797)	mem 39.468
Train: [72][75/750]	BT 0.032 (1.400)	DT 0.001 (1.350)	loss 6.838 (6.838)	prob 2.929 (2.929)	GS 32.812 (32.812)	mem 39.531
Train: [72][80/750]	BT 0.027 (1.448)	DT 0.001 (1.399)	loss 6.883 (6.883)	prob 2.620 (2.620)	GS 32.859 (32.859)	mem 39.652
Train: [72][85/750]	BT 0.033 (1.364)	DT 0.001 (1.316)	loss 6.850 (6.850)	prob 2.768 (2.768)	GS 29.500 (29.500)	mem 39.716
Train: [72][90/750]	BT 2.259 (1.451)	DT 2.230 (1.404)	loss 6.642 (6.642)	prob 3.300 (3.300)	GS 32.172 (32.172)	mem 39.540
Train: [72][95/750]	BT 0.037 (1.378)	DT 0.003 (1.330)	loss 6.719 (6.719)	prob 2.879 (2.879)	GS 33.016 (33.016)	mem 39.576
Train: [72][100/750]	BT 5.931 (1.402)	DT 5.890 (1.356)	loss 7.147 (7.147)	prob 2.119 (2.119)	GS 36.062 (36.062)	mem 39.633
Train: [72][105/750]	BT 0.037 (1.361)	DT 0.005 (1.315)	loss 7.055 (7.055)	prob 3.015 (3.015)	GS 30.953 (30.953)	mem 39.632
Train: [72][110/750]	BT 2.968 (1.333)	DT 2.866 (1.287)	loss 6.808 (6.808)	prob 3.123 (3.123)	GS 36.078 (36.078)	mem 39.576
Train: [72][115/750]	BT 0.044 (1.354)	DT 0.002 (1.309)	loss 6.822 (6.822)	prob 1.901 (1.901)	GS 36.250 (36.250)	mem 39.773
Train: [72][120/750]	BT 0.080 (1.301)	DT 0.050 (1.255)	loss 7.056 (7.056)	prob 2.643 (2.643)	GS 34.969 (34.969)	mem 39.650
Train: [72][125/750]	BT 0.056 (1.343)	DT 0.010 (1.297)	loss 6.790 (6.790)	prob 3.131 (3.131)	GS 31.344 (31.344)	mem 39.683
Train: [72][130/750]	BT 0.038 (1.293)	DT 0.005 (1.247)	loss 6.828 (6.828)	prob 2.671 (2.671)	GS 28.109 (28.109)	mem 39.893
Train: [72][135/750]	BT 0.031 (1.266)	DT 0.001 (1.220)	loss 7.212 (7.212)	prob 2.174 (2.174)	GS 32.953 (32.953)	mem 39.689
Train: [72][140/750]	BT 0.023 (1.287)	DT 0.001 (1.242)	loss 7.133 (7.133)	prob 1.940 (1.940)	GS 30.109 (30.109)	mem 39.696
Train: [72][145/750]	BT 0.047 (1.244)	DT 0.002 (1.199)	loss 6.731 (6.731)	prob 2.608 (2.608)	GS 31.266 (31.266)	mem 39.697
Train: [72][150/750]	BT 0.068 (1.283)	DT 0.036 (1.237)	loss 6.928 (6.928)	prob 2.624 (2.624)	GS 33.703 (33.703)	mem 39.706
Train: [72][155/750]	BT 0.043 (1.242)	DT 0.012 (1.198)	loss 6.601 (6.601)	prob 2.524 (2.524)	GS 30.953 (30.953)	mem 39.935
Train: [72][160/750]	BT 2.799 (1.293)	DT 2.767 (1.249)	loss 6.704 (6.704)	prob 3.026 (3.026)	GS 33.688 (33.688)	mem 39.616
Train: [72][165/750]	BT 0.031 (1.255)	DT 0.001 (1.211)	loss 7.012 (7.012)	prob 2.478 (2.478)	GS 32.297 (32.297)	mem 39.617
Train: [72][170/750]	BT 8.725 (1.280)	DT 8.663 (1.236)	loss 6.727 (6.727)	prob 2.183 (2.183)	GS 34.547 (34.547)	mem 39.723
Train: [72][175/750]	BT 0.093 (1.245)	DT 0.001 (1.201)	loss 6.768 (6.768)	prob 2.679 (2.679)	GS 27.359 (27.359)	mem 39.715
Train: [72][180/750]	BT 5.529 (1.243)	DT 5.488 (1.198)	loss 6.661 (6.661)	prob 2.345 (2.345)	GS 30.812 (30.812)	mem 39.722
Train: [72][185/750]	BT 0.048 (1.253)	DT 0.007 (1.208)	loss 6.832 (6.832)	prob 2.585 (2.585)	GS 29.094 (29.094)	mem 39.675
Train: [72][190/750]	BT 0.028 (1.221)	DT 0.001 (1.176)	loss 6.710 (6.710)	prob 2.971 (2.971)	GS 36.344 (36.344)	mem 39.680
Train: [72][195/750]	BT 0.045 (1.263)	DT 0.008 (1.218)	loss 7.097 (7.097)	prob 2.639 (2.639)	GS 32.406 (32.406)	mem 39.712
Train: [72][200/750]	BT 0.092 (1.233)	DT 0.026 (1.188)	loss 6.868 (6.868)	prob 2.545 (2.545)	GS 32.344 (32.344)	mem 39.711
Train: [72][205/750]	BT 0.116 (1.204)	DT 0.010 (1.159)	loss 6.747 (6.747)	prob 2.451 (2.451)	GS 29.125 (29.125)	mem 39.713
Train: [72][210/750]	BT 0.041 (1.225)	DT 0.005 (1.179)	loss 6.942 (6.942)	prob 2.020 (2.020)	GS 37.406 (37.406)	mem 39.825
Train: [72][215/750]	BT 0.042 (1.197)	DT 0.002 (1.152)	loss 6.988 (6.988)	prob 2.208 (2.208)	GS 31.859 (31.859)	mem 39.954
Train: [72][220/750]	BT 0.022 (1.222)	DT 0.001 (1.177)	loss 7.005 (7.005)	prob 1.867 (1.867)	GS 34.594 (34.594)	mem 39.852
Train: [72][225/750]	BT 0.039 (1.196)	DT 0.002 (1.151)	loss 6.863 (6.863)	prob 1.807 (1.807)	GS 30.422 (30.422)	mem 39.854
Train: [72][230/750]	BT 9.801 (1.213)	DT 9.754 (1.168)	loss 6.875 (6.875)	prob 2.550 (2.550)	GS 32.109 (32.109)	mem 39.879
Train: [72][235/750]	BT 0.046 (1.188)	DT 0.001 (1.143)	loss 6.877 (6.877)	prob 2.225 (2.225)	GS 29.406 (29.406)	mem 40.060
Train: [72][240/750]	BT 1.475 (1.171)	DT 1.389 (1.126)	loss 6.595 (6.595)	prob 2.655 (2.655)	GS 31.062 (31.062)	mem 40.006
Train: [72][245/750]	BT 0.034 (1.191)	DT 0.006 (1.146)	loss 6.870 (6.870)	prob 2.522 (2.522)	GS 28.438 (28.438)	mem 40.013
Train: [72][250/750]	BT 0.075 (1.168)	DT 0.035 (1.123)	loss 6.895 (6.895)	prob 2.590 (2.590)	GS 37.578 (37.578)	mem 39.883
Train: [72][255/750]	BT 0.091 (1.191)	DT 0.001 (1.146)	loss 7.136 (7.136)	prob 2.151 (2.151)	GS 47.875 (47.875)	mem 39.959
Train: [72][260/750]	BT 0.079 (1.170)	DT 0.002 (1.124)	loss 6.861 (6.861)	prob 2.774 (2.774)	GS 35.203 (35.203)	mem 40.238
Train: [72][265/750]	BT 0.047 (1.201)	DT 0.009 (1.155)	loss 7.141 (7.141)	prob 2.238 (2.238)	GS 39.266 (39.266)	mem 39.820
Train: [72][270/750]	BT 0.037 (1.180)	DT 0.001 (1.134)	loss 6.948 (6.948)	prob 2.708 (2.708)	GS 35.281 (35.281)	mem 39.773
Train: [72][275/750]	BT 0.040 (1.198)	DT 0.002 (1.152)	loss 6.867 (6.867)	prob 2.471 (2.471)	GS 33.344 (33.344)	mem 39.900
Train: [72][280/750]	BT 0.027 (1.197)	DT 0.001 (1.151)	loss 6.702 (6.702)	prob 3.124 (3.124)	GS 34.797 (34.797)	mem 39.806
Train: [72][285/750]	BT 0.066 (1.176)	DT 0.002 (1.130)	loss 6.916 (6.916)	prob 2.191 (2.191)	GS 31.641 (31.641)	mem 39.817
Train: [72][290/750]	BT 0.035 (1.202)	DT 0.003 (1.156)	loss 6.949 (6.949)	prob 3.016 (3.016)	GS 35.328 (35.328)	mem 39.822
Train: [72][295/750]	BT 0.035 (1.183)	DT 0.001 (1.137)	loss 7.043 (7.043)	prob 2.906 (2.906)	GS 34.438 (34.438)	mem 39.823
Train: [72][300/750]	BT 11.024 (1.209)	DT 10.992 (1.163)	loss 6.889 (6.889)	prob 2.384 (2.384)	GS 35.625 (35.625)	mem 39.838
Train: [72][305/750]	BT 0.029 (1.190)	DT 0.001 (1.144)	loss 6.946 (6.946)	prob 2.285 (2.285)	GS 29.250 (29.250)	mem 39.795
Train: [72][310/750]	BT 3.355 (1.183)	DT 3.258 (1.136)	loss 6.789 (6.789)	prob 2.604 (2.604)	GS 33.188 (33.188)	mem 39.858
Train: [72][315/750]	BT 0.023 (1.200)	DT 0.002 (1.153)	loss 6.860 (6.860)	prob 2.670 (2.670)	GS 28.000 (28.000)	mem 39.932
Train: [72][320/750]	BT 0.079 (1.182)	DT 0.011 (1.135)	loss 6.632 (6.632)	prob 2.610 (2.610)	GS 31.719 (31.719)	mem 39.872
Train: [72][325/750]	BT 0.031 (1.200)	DT 0.001 (1.153)	loss 6.971 (6.971)	prob 2.909 (2.909)	GS 31.281 (31.281)	mem 39.869
Train: [72][330/750]	BT 0.045 (1.182)	DT 0.006 (1.136)	loss 7.156 (7.156)	prob 2.697 (2.697)	GS 36.656 (36.656)	mem 39.868
Train: [72][335/750]	BT 0.030 (1.165)	DT 0.001 (1.119)	loss 7.040 (7.040)	prob 2.662 (2.662)	GS 30.516 (30.516)	mem 39.869
Train: [72][340/750]	BT 0.032 (1.183)	DT 0.002 (1.137)	loss 6.564 (6.564)	prob 3.010 (3.010)	GS 29.922 (29.922)	mem 40.181
Train: [72][345/750]	BT 0.039 (1.166)	DT 0.001 (1.120)	loss 7.021 (7.021)	prob 2.725 (2.725)	GS 27.500 (27.500)	mem 40.193
Train: [72][350/750]	BT 0.029 (1.188)	DT 0.001 (1.142)	loss 6.903 (6.903)	prob 2.362 (2.362)	GS 30.781 (30.781)	mem 39.809
Train: [72][355/750]	BT 0.056 (1.172)	DT 0.009 (1.126)	loss 6.922 (6.922)	prob 2.086 (2.086)	GS 26.453 (26.453)	mem 39.811
Train: [72][360/750]	BT 11.895 (1.190)	DT 11.802 (1.144)	loss 6.940 (6.940)	prob 2.913 (2.913)	GS 31.312 (31.312)	mem 40.148
Train: [72][365/750]	BT 0.056 (1.174)	DT 0.010 (1.128)	loss 6.852 (6.852)	prob 2.708 (2.708)	GS 32.297 (32.297)	mem 40.230
Train: [72][370/750]	BT 0.742 (1.161)	DT 0.696 (1.115)	loss 6.992 (6.992)	prob 2.449 (2.449)	GS 31.891 (31.891)	mem 39.741
Train: [72][375/750]	BT 0.070 (1.173)	DT 0.015 (1.128)	loss 7.167 (7.167)	prob 1.861 (1.861)	GS 29.188 (29.188)	mem 39.859
Train: [72][380/750]	BT 0.648 (1.160)	DT 0.581 (1.115)	loss 6.700 (6.700)	prob 2.792 (2.792)	GS 34.000 (34.000)	mem 39.862
Train: [72][385/750]	BT 0.057 (1.173)	DT 0.006 (1.128)	loss 6.897 (6.897)	prob 2.688 (2.688)	GS 30.062 (30.062)	mem 39.955
Train: [72][390/750]	BT 0.029 (1.159)	DT 0.001 (1.113)	loss 6.833 (6.833)	prob 2.554 (2.554)	GS 34.328 (34.328)	mem 39.930
Train: [72][395/750]	BT 0.036 (1.166)	DT 0.002 (1.120)	loss 6.761 (6.761)	prob 2.861 (2.861)	GS 29.281 (29.281)	mem 39.911
Train: [72][400/750]	BT 0.040 (1.165)	DT 0.002 (1.120)	loss 6.853 (6.853)	prob 2.200 (2.200)	GS 35.094 (35.094)	mem 40.058
Train: [72][405/750]	BT 0.033 (1.158)	DT 0.002 (1.113)	loss 7.017 (7.017)	prob 2.307 (2.307)	GS 46.391 (46.391)	mem 40.062
Train: [72][410/750]	BT 0.038 (1.166)	DT 0.002 (1.120)	loss 6.836 (6.836)	prob 2.661 (2.661)	GS 33.656 (33.656)	mem 39.968
Train: [72][415/750]	BT 0.032 (1.152)	DT 0.002 (1.107)	loss 6.914 (6.914)	prob 3.022 (3.022)	GS 28.469 (28.469)	mem 39.907
Train: [72][420/750]	BT 0.028 (1.170)	DT 0.001 (1.125)	loss 6.931 (6.931)	prob 3.144 (3.144)	GS 34.016 (34.016)	mem 39.805
Train: [72][425/750]	BT 0.059 (1.157)	DT 0.007 (1.111)	loss 7.457 (7.457)	prob 1.635 (1.635)	GS 30.438 (30.438)	mem 39.806
Train: [72][430/750]	BT 12.265 (1.173)	DT 12.216 (1.127)	loss 6.805 (6.805)	prob 2.339 (2.339)	GS 32.500 (32.500)	mem 39.927
Train: [72][435/750]	BT 0.022 (1.160)	DT 0.001 (1.114)	loss 7.039 (7.039)	prob 2.910 (2.910)	GS 28.062 (28.062)	mem 39.997
Train: [72][440/750]	BT 3.910 (1.156)	DT 3.868 (1.110)	loss 6.909 (6.909)	prob 2.634 (2.634)	GS 37.672 (37.672)	mem 39.966
Train: [72][445/750]	BT 0.038 (1.170)	DT 0.002 (1.124)	loss 6.991 (6.991)	prob 2.074 (2.074)	GS 31.734 (31.734)	mem 40.091
Train: [72][450/750]	BT 0.079 (1.157)	DT 0.026 (1.111)	loss 6.830 (6.830)	prob 2.535 (2.535)	GS 36.703 (36.703)	mem 39.844
Train: [72][455/750]	BT 0.035 (1.165)	DT 0.007 (1.119)	loss 7.039 (7.039)	prob 2.655 (2.655)	GS 33.797 (33.797)	mem 39.897
Train: [72][460/750]	BT 0.051 (1.157)	DT 0.007 (1.111)	loss 7.138 (7.138)	prob 2.350 (2.350)	GS 32.125 (32.125)	mem 39.900
Train: [72][465/750]	BT 0.048 (1.145)	DT 0.016 (1.099)	loss 6.961 (6.961)	prob 2.684 (2.684)	GS 32.203 (32.203)	mem 39.901
Train: [72][470/750]	BT 0.025 (1.161)	DT 0.001 (1.115)	loss 7.054 (7.054)	prob 2.091 (2.091)	GS 31.875 (31.875)	mem 39.924
Train: [72][475/750]	BT 0.033 (1.149)	DT 0.003 (1.104)	loss 7.149 (7.149)	prob 2.096 (2.096)	GS 29.109 (29.109)	mem 39.926
Train: [72][480/750]	BT 3.127 (1.164)	DT 3.094 (1.119)	loss 7.042 (7.042)	prob 2.008 (2.008)	GS 28.953 (28.953)	mem 39.879
Train: [72][485/750]	BT 0.093 (1.153)	DT 0.002 (1.107)	loss 6.612 (6.612)	prob 3.262 (3.262)	GS 32.188 (32.188)	mem 39.881
Train: [72][490/750]	BT 7.315 (1.159)	DT 7.240 (1.113)	loss 7.140 (7.140)	prob 2.308 (2.308)	GS 31.594 (31.594)	mem 39.866
Train: [72][495/750]	BT 0.026 (1.155)	DT 0.001 (1.110)	loss 7.166 (7.166)	prob 1.841 (1.841)	GS 31.172 (31.172)	mem 39.929
Train: [72][500/750]	BT 5.110 (1.155)	DT 5.045 (1.109)	loss 6.868 (6.868)	prob 1.219 (1.219)	GS 38.094 (38.094)	mem 39.785
Train: [72][505/750]	BT 0.041 (1.157)	DT 0.002 (1.111)	loss 7.377 (7.377)	prob 2.012 (2.012)	GS 32.578 (32.578)	mem 39.867
Train: [72][510/750]	BT 0.134 (1.146)	DT 0.006 (1.100)	loss 7.039 (7.039)	prob 1.788 (1.788)	GS 36.766 (36.766)	mem 39.767
Train: [72][515/750]	BT 0.044 (1.160)	DT 0.001 (1.114)	loss 7.281 (7.281)	prob 1.746 (1.746)	GS 40.641 (40.641)	mem 39.940
Train: [72][520/750]	BT 0.031 (1.149)	DT 0.001 (1.104)	loss 6.969 (6.969)	prob 2.391 (2.391)	GS 32.828 (32.828)	mem 39.896
Train: [72][525/750]	BT 0.062 (1.142)	DT 0.004 (1.096)	loss 7.312 (7.312)	prob 1.701 (1.701)	GS 33.422 (33.422)	mem 39.901
Train: [72][530/750]	BT 0.043 (1.155)	DT 0.001 (1.109)	loss 6.629 (6.629)	prob 2.458 (2.458)	GS 34.922 (34.922)	mem 39.835
Train: [72][535/750]	BT 0.093 (1.144)	DT 0.036 (1.099)	loss 7.074 (7.074)	prob 2.431 (2.431)	GS 32.531 (32.531)	mem 39.839
Train: [72][540/750]	BT 2.351 (1.158)	DT 2.301 (1.113)	loss 7.028 (7.028)	prob 1.667 (1.667)	GS 33.609 (33.609)	mem 39.899
Train: [72][545/750]	BT 0.058 (1.148)	DT 0.028 (1.103)	loss 7.230 (7.230)	prob 1.971 (1.971)	GS 32.531 (32.531)	mem 39.848
Train: [72][550/750]	BT 9.433 (1.158)	DT 9.401 (1.112)	loss 7.121 (7.121)	prob 2.384 (2.384)	GS 35.172 (35.172)	mem 39.894
Train: [72][555/750]	BT 0.027 (1.160)	DT 0.001 (1.114)	loss 7.135 (7.135)	prob 2.146 (2.146)	GS 33.094 (33.094)	mem 39.859
Train: [72][560/750]	BT 0.069 (1.150)	DT 0.014 (1.104)	loss 7.393 (7.393)	prob 2.034 (2.034)	GS 35.406 (35.406)	mem 39.861
Train: [72][565/750]	BT 0.028 (1.162)	DT 0.002 (1.116)	loss 7.440 (7.440)	prob 2.105 (2.105)	GS 28.719 (28.719)	mem 39.863
Train: [72][570/750]	BT 0.031 (1.152)	DT 0.001 (1.106)	loss 6.906 (6.906)	prob 3.035 (3.035)	GS 31.469 (31.469)	mem 39.904
Train: [72][575/750]	BT 0.088 (1.157)	DT 0.029 (1.111)	loss 7.084 (7.084)	prob 2.370 (2.370)	GS 32.156 (32.156)	mem 39.865
Train: [72][580/750]	BT 0.066 (1.156)	DT 0.001 (1.111)	loss 7.550 (7.550)	prob 2.327 (2.327)	GS 31.609 (31.609)	mem 39.832
Train: [72][585/750]	BT 0.030 (1.147)	DT 0.001 (1.101)	loss 7.287 (7.287)	prob 2.430 (2.430)	GS 31.078 (31.078)	mem 39.833
Train: [72][590/750]	BT 0.075 (1.159)	DT 0.007 (1.114)	loss 6.997 (6.997)	prob 2.465 (2.465)	GS 34.625 (34.625)	mem 40.184
Train: [72][595/750]	BT 0.044 (1.150)	DT 0.003 (1.104)	loss 7.043 (7.043)	prob 2.707 (2.707)	GS 38.781 (38.781)	mem 39.936
Train: [72][600/750]	BT 6.107 (1.157)	DT 6.055 (1.112)	loss 6.783 (6.783)	prob 3.087 (3.087)	GS 35.594 (35.594)	mem 39.872
Train: [72][605/750]	BT 0.047 (1.148)	DT 0.005 (1.103)	loss 7.134 (7.134)	prob 2.322 (2.322)	GS 36.672 (36.672)	mem 39.874
Train: [72][610/750]	BT 8.786 (1.153)	DT 8.751 (1.108)	loss 6.997 (6.997)	prob 2.963 (2.963)	GS 36.484 (36.484)	mem 39.871
Train: [72][615/750]	BT 0.031 (1.151)	DT 0.001 (1.105)	loss 7.322 (7.322)	prob 2.296 (2.296)	GS 27.844 (27.844)	mem 39.858
Train: [72][620/750]	BT 0.054 (1.142)	DT 0.015 (1.096)	loss 7.170 (7.170)	prob 2.779 (2.779)	GS 27.922 (27.922)	mem 39.885
Train: [72][625/750]	BT 0.042 (1.151)	DT 0.001 (1.106)	loss 7.287 (7.287)	prob 2.288 (2.288)	GS 30.484 (30.484)	mem 39.914
Train: [72][630/750]	BT 0.044 (1.143)	DT 0.003 (1.097)	loss 7.002 (7.002)	prob 2.406 (2.406)	GS 35.422 (35.422)	mem 39.914
Train: [72][635/750]	BT 0.068 (1.149)	DT 0.007 (1.104)	loss 7.416 (7.416)	prob 1.895 (1.895)	GS 38.438 (38.438)	mem 39.945
Train: [72][640/750]	BT 0.030 (1.151)	DT 0.001 (1.105)	loss 6.899 (6.899)	prob 3.305 (3.305)	GS 34.109 (34.109)	mem 40.014
Train: [72][645/750]	BT 0.072 (1.147)	DT 0.003 (1.101)	loss 7.064 (7.064)	prob 2.485 (2.485)	GS 33.562 (33.562)	mem 39.934
Train: [72][650/750]	BT 0.025 (1.150)	DT 0.001 (1.105)	loss 7.230 (7.230)	prob 2.368 (2.368)	GS 34.719 (34.719)	mem 40.058
Train: [72][655/750]	BT 0.033 (1.142)	DT 0.001 (1.096)	loss 7.651 (7.651)	prob 1.402 (1.402)	GS 47.312 (47.312)	mem 39.997
Train: [72][660/750]	BT 0.034 (1.153)	DT 0.001 (1.107)	loss 7.289 (7.289)	prob 2.632 (2.632)	GS 36.047 (36.047)	mem 40.064
Train: [72][665/750]	BT 0.028 (1.144)	DT 0.001 (1.099)	loss 6.916 (6.916)	prob 2.664 (2.664)	GS 25.359 (25.359)	mem 39.942
Train: [72][670/750]	BT 10.359 (1.154)	DT 10.322 (1.108)	loss 6.945 (6.945)	prob 2.939 (2.939)	GS 32.500 (32.500)	mem 39.959
Train: [72][675/750]	BT 0.026 (1.147)	DT 0.001 (1.102)	loss 6.931 (6.931)	prob 3.107 (3.107)	GS 32.328 (32.328)	mem 39.960
Train: [72][680/750]	BT 4.735 (1.146)	DT 4.663 (1.101)	loss 7.653 (7.653)	prob 1.745 (1.745)	GS 36.828 (36.828)	mem 40.181
Train: [72][685/750]	BT 0.058 (1.150)	DT 0.010 (1.105)	loss 7.198 (7.198)	prob 2.140 (2.140)	GS 32.312 (32.312)	mem 40.002
Train: [72][690/750]	BT 0.032 (1.142)	DT 0.002 (1.097)	loss 6.975 (6.975)	prob 2.448 (2.448)	GS 32.484 (32.484)	mem 39.944
Train: [72][695/750]	BT 0.129 (1.142)	DT 0.003 (1.096)	loss 7.011 (7.011)	prob 3.462 (3.462)	GS 30.719 (30.719)	mem 40.052
Train: [72][700/750]	BT 0.033 (1.142)	DT 0.001 (1.097)	loss 7.220 (7.220)	prob 2.061 (2.061)	GS 31.469 (31.469)	mem 39.874
Train: [72][705/750]	BT 0.043 (1.145)	DT 0.014 (1.100)	loss 7.444 (7.444)	prob 2.997 (2.997)	GS 40.828 (40.828)	mem 39.945
Train: [72][710/750]	BT 0.057 (1.146)	DT 0.004 (1.100)	loss 7.403 (7.403)	prob 2.755 (2.755)	GS 37.406 (37.406)	mem 39.947
Train: [72][715/750]	BT 0.065 (1.138)	DT 0.021 (1.092)	loss 7.133 (7.133)	prob 2.590 (2.590)	GS 31.641 (31.641)	mem 40.068
Train: [72][720/750]	BT 1.465 (1.143)	DT 1.410 (1.097)	loss 6.773 (6.773)	prob 2.450 (2.450)	GS 29.719 (29.719)	mem 39.956
Train: [72][725/750]	BT 0.058 (1.136)	DT 0.004 (1.090)	loss 7.155 (7.155)	prob 3.045 (3.045)	GS 32.312 (32.312)	mem 39.956
Train: [72][730/750]	BT 3.672 (1.144)	DT 3.623 (1.099)	loss 7.236 (7.236)	prob 2.732 (2.732)	GS 34.469 (34.469)	mem 39.586
Train: [72][735/750]	BT 0.024 (1.138)	DT 0.001 (1.093)	loss 7.349 (7.349)	prob 2.287 (2.287)	GS 30.203 (30.203)	mem 39.543
Train: [72][740/750]	BT 4.720 (1.137)	DT 4.690 (1.092)	loss 7.114 (7.114)	prob 3.217 (3.217)	GS 35.531 (35.531)	mem 13.569
Train: [72][745/750]	BT 0.019 (1.132)	DT 0.001 (1.087)	loss 7.140 (7.140)	prob 2.868 (2.868)	GS 27.344 (27.344)	mem 13.577
Train: [72][750/750]	BT 0.045 (1.125)	DT 0.004 (1.080)	loss 7.816 (7.816)	prob 2.356 (2.356)	GS 35.250 (35.250)	mem 13.578
Train: [72][755/750]	BT 0.027 (1.123)	DT 0.001 (1.077)	loss 8.162 (8.162)	prob 1.214 (1.214)	GS 29.188 (29.188)	mem 7.591
epoch 72, total time 847.72
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [73][1/750]	BT 20.698 (20.698)	DT 20.644 (20.644)	loss 7.242 (7.242)	prob 2.421 (2.421)	GS 35.672 (35.672)	mem 38.709
Train: [73][5/750]	BT 2.926 (5.253)	DT 2.895 (5.213)	loss 7.241 (7.241)	prob 2.780 (2.780)	GS 33.828 (33.828)	mem 39.253
Train: [73][10/750]	BT 0.115 (2.690)	DT 0.010 (2.634)	loss 7.341 (7.341)	prob 2.630 (2.630)	GS 32.891 (32.891)	mem 39.258
Train: [73][15/750]	BT 0.104 (2.504)	DT 0.045 (2.446)	loss 6.808 (6.808)	prob 3.300 (3.300)	GS 30.578 (30.578)	mem 39.541
Train: [73][20/750]	BT 6.344 (2.208)	DT 6.308 (2.151)	loss 7.550 (7.550)	prob 2.818 (2.818)	GS 33.453 (33.453)	mem 39.491
Train: [73][25/750]	BT 0.027 (1.776)	DT 0.001 (1.722)	loss 7.010 (7.010)	prob 3.193 (3.193)	GS 28.953 (28.953)	mem 39.494
Train: [73][30/750]	BT 1.965 (1.696)	DT 1.882 (1.642)	loss 6.992 (6.992)	prob 2.943 (2.943)	GS 31.250 (31.250)	mem 39.597
Train: [73][35/750]	BT 0.058 (1.732)	DT 0.012 (1.675)	loss 6.906 (6.906)	prob 2.961 (2.961)	GS 30.891 (30.891)	mem 39.697
Train: [73][40/750]	BT 0.042 (1.645)	DT 0.001 (1.590)	loss 7.302 (7.302)	prob 3.091 (3.091)	GS 32.703 (32.703)	mem 39.501
Train: [73][45/750]	BT 0.052 (1.696)	DT 0.029 (1.644)	loss 7.050 (7.050)	prob 2.861 (2.861)	GS 31.438 (31.438)	mem 39.522
Train: [73][50/750]	BT 1.896 (1.571)	DT 1.862 (1.517)	loss 7.138 (7.138)	prob 2.587 (2.587)	GS 36.719 (36.719)	mem 39.607
Train: [73][55/750]	BT 0.043 (1.432)	DT 0.001 (1.380)	loss 7.225 (7.225)	prob 2.698 (2.698)	GS 29.156 (29.156)	mem 39.577
Train: [73][60/750]	BT 0.031 (1.481)	DT 0.001 (1.430)	loss 7.609 (7.609)	prob 3.338 (3.338)	GS 36.359 (36.359)	mem 39.631
Train: [73][65/750]	BT 0.033 (1.381)	DT 0.002 (1.331)	loss 6.927 (6.927)	prob 2.590 (2.590)	GS 32.578 (32.578)	mem 39.698
Train: [73][70/750]	BT 0.029 (1.531)	DT 0.001 (1.480)	loss 6.716 (6.716)	prob 3.367 (3.367)	GS 30.844 (30.844)	mem 39.661
Train: [73][75/750]	BT 0.032 (1.432)	DT 0.001 (1.382)	loss 7.034 (7.034)	prob 2.536 (2.536)	GS 29.344 (29.344)	mem 39.662
Train: [73][80/750]	BT 11.255 (1.485)	DT 11.217 (1.436)	loss 7.065 (7.065)	prob 3.376 (3.376)	GS 33.516 (33.516)	mem 39.628
Train: [73][85/750]	BT 0.029 (1.400)	DT 0.003 (1.352)	loss 7.505 (7.505)	prob 2.410 (2.410)	GS 34.750 (34.750)	mem 39.629
Train: [73][90/750]	BT 0.051 (1.326)	DT 0.001 (1.277)	loss 7.187 (7.187)	prob 3.064 (3.064)	GS 34.438 (34.438)	mem 39.690
Train: [73][95/750]	BT 0.031 (1.383)	DT 0.001 (1.334)	loss 7.100 (7.100)	prob 2.881 (2.881)	GS 32.172 (32.172)	mem 39.734
Train: [73][100/750]	BT 0.024 (1.315)	DT 0.001 (1.268)	loss 6.811 (6.811)	prob 2.809 (2.809)	GS 34.094 (34.094)	mem 39.735
Train: [73][105/750]	BT 0.032 (1.386)	DT 0.001 (1.339)	loss 7.112 (7.112)	prob 2.957 (2.957)	GS 29.203 (29.203)	mem 39.579
Train: [73][110/750]	BT 0.026 (1.325)	DT 0.001 (1.278)	loss 6.801 (6.801)	prob 3.230 (3.230)	GS 35.969 (35.969)	mem 39.588
Train: [73][115/750]	BT 0.032 (1.269)	DT 0.001 (1.223)	loss 7.405 (7.405)	prob 2.710 (2.710)	GS 32.312 (32.312)	mem 39.589
Train: [73][120/750]	BT 0.041 (1.318)	DT 0.002 (1.271)	loss 7.217 (7.217)	prob 3.086 (3.086)	GS 31.391 (31.391)	mem 40.002
Train: [73][125/750]	BT 0.033 (1.267)	DT 0.001 (1.221)	loss 7.046 (7.046)	prob 2.224 (2.224)	GS 31.281 (31.281)	mem 39.649
Train: [73][130/750]	BT 0.091 (1.312)	DT 0.011 (1.266)	loss 6.856 (6.856)	prob 2.702 (2.702)	GS 34.875 (34.875)	mem 39.734
Train: [73][135/750]	BT 0.039 (1.265)	DT 0.005 (1.219)	loss 7.010 (7.010)	prob 3.229 (3.229)	GS 33.859 (33.859)	mem 39.736
Train: [73][140/750]	BT 8.582 (1.310)	DT 8.522 (1.264)	loss 6.993 (6.993)	prob 2.607 (2.607)	GS 33.484 (33.484)	mem 39.744
Train: [73][145/750]	BT 0.054 (1.267)	DT 0.027 (1.221)	loss 7.234 (7.234)	prob 2.577 (2.577)	GS 28.922 (28.922)	mem 39.745
Train: [73][150/750]	BT 3.657 (1.250)	DT 3.624 (1.204)	loss 7.546 (7.546)	prob 2.781 (2.781)	GS 29.750 (29.750)	mem 39.768
Train: [73][155/750]	BT 0.102 (1.261)	DT 0.002 (1.214)	loss 7.174 (7.174)	prob 3.544 (3.544)	GS 31.234 (31.234)	mem 39.756
Train: [73][160/750]	BT 0.031 (1.223)	DT 0.001 (1.177)	loss 7.050 (7.050)	prob 2.590 (2.590)	GS 36.625 (36.625)	mem 39.757
Train: [73][165/750]	BT 0.059 (1.258)	DT 0.017 (1.212)	loss 7.104 (7.104)	prob 2.442 (2.442)	GS 32.781 (32.781)	mem 39.723
Train: [73][170/750]	BT 0.025 (1.227)	DT 0.001 (1.181)	loss 7.087 (7.087)	prob 2.865 (2.865)	GS 34.031 (34.031)	mem 39.735
Train: [73][175/750]	BT 0.028 (1.216)	DT 0.001 (1.170)	loss 7.364 (7.364)	prob 2.569 (2.569)	GS 30.312 (30.312)	mem 39.779
Train: [73][180/750]	BT 1.918 (1.235)	DT 1.862 (1.189)	loss 7.199 (7.199)	prob 3.240 (3.240)	GS 35.469 (35.469)	mem 39.714
Train: [73][185/750]	BT 0.052 (1.202)	DT 0.011 (1.157)	loss 7.276 (7.276)	prob 2.682 (2.682)	GS 28.859 (28.859)	mem 39.719
Train: [73][190/750]	BT 0.144 (1.226)	DT 0.010 (1.180)	loss 7.159 (7.159)	prob 3.225 (3.225)	GS 33.641 (33.641)	mem 39.861
Train: [73][195/750]	BT 0.070 (1.198)	DT 0.007 (1.152)	loss 6.975 (6.975)	prob 2.730 (2.730)	GS 32.156 (32.156)	mem 39.869
Train: [73][200/750]	BT 9.871 (1.222)	DT 9.847 (1.176)	loss 7.121 (7.121)	prob 2.520 (2.520)	GS 34.219 (34.219)	mem 39.922
Train: [73][205/750]	BT 0.046 (1.218)	DT 0.015 (1.172)	loss 6.992 (6.992)	prob 2.950 (2.950)	GS 28.766 (28.766)	mem 39.906
Train: [73][210/750]	BT 0.038 (1.190)	DT 0.008 (1.144)	loss 7.242 (7.242)	prob 3.297 (3.297)	GS 32.625 (32.625)	mem 39.885
Train: [73][215/750]	BT 0.052 (1.218)	DT 0.010 (1.172)	loss 7.533 (7.533)	prob 2.352 (2.352)	GS 32.062 (32.062)	mem 39.775
Train: [73][220/750]	BT 0.109 (1.192)	DT 0.004 (1.145)	loss 7.237 (7.237)	prob 2.982 (2.982)	GS 37.062 (37.062)	mem 39.775
Train: [73][225/750]	BT 0.033 (1.186)	DT 0.002 (1.140)	loss 7.157 (7.157)	prob 2.670 (2.670)	GS 31.375 (31.375)	mem 39.871
Train: [73][230/750]	BT 0.075 (1.209)	DT 0.034 (1.164)	loss 7.399 (7.399)	prob 2.624 (2.624)	GS 26.297 (26.297)	mem 39.680
Train: [73][235/750]	BT 0.052 (1.185)	DT 0.010 (1.139)	loss 7.151 (7.151)	prob 2.489 (2.489)	GS 33.531 (33.531)	mem 39.680
Train: [73][240/750]	BT 0.031 (1.220)	DT 0.001 (1.174)	loss 7.127 (7.127)	prob 2.638 (2.638)	GS 32.578 (32.578)	mem 39.726
Train: [73][245/750]	BT 0.033 (1.196)	DT 0.001 (1.151)	loss 7.089 (7.089)	prob 2.842 (2.842)	GS 31.516 (31.516)	mem 39.839
Train: [73][250/750]	BT 11.763 (1.223)	DT 11.727 (1.177)	loss 7.330 (7.330)	prob 2.773 (2.773)	GS 34.156 (34.156)	mem 39.833
Train: [73][255/750]	BT 0.049 (1.200)	DT 0.002 (1.154)	loss 7.243 (7.243)	prob 2.894 (2.894)	GS 33.531 (33.531)	mem 39.891
Train: [73][260/750]	BT 5.155 (1.197)	DT 5.123 (1.152)	loss 7.404 (7.404)	prob 2.897 (2.897)	GS 37.938 (37.938)	mem 39.774
Train: [73][265/750]	BT 0.035 (1.213)	DT 0.001 (1.168)	loss 7.077 (7.077)	prob 3.155 (3.155)	GS 28.281 (28.281)	mem 39.879
Train: [73][270/750]	BT 0.032 (1.191)	DT 0.001 (1.146)	loss 6.989 (6.989)	prob 2.803 (2.803)	GS 34.391 (34.391)	mem 39.850
Train: [73][275/750]	BT 0.045 (1.216)	DT 0.005 (1.171)	loss 7.255 (7.255)	prob 2.985 (2.985)	GS 33.250 (33.250)	mem 39.948
Train: [73][280/750]	BT 0.035 (1.195)	DT 0.001 (1.151)	loss 7.036 (7.036)	prob 3.688 (3.688)	GS 37.344 (37.344)	mem 39.865
Train: [73][285/750]	BT 0.033 (1.180)	DT 0.002 (1.136)	loss 7.522 (7.522)	prob 2.309 (2.309)	GS 30.328 (30.328)	mem 39.801
Train: [73][290/750]	BT 0.034 (1.196)	DT 0.001 (1.152)	loss 6.990 (6.990)	prob 3.857 (3.857)	GS 35.500 (35.500)	mem 39.953
Train: [73][295/750]	BT 0.046 (1.177)	DT 0.002 (1.133)	loss 7.407 (7.407)	prob 2.539 (2.539)	GS 37.922 (37.922)	mem 40.024
Train: [73][300/750]	BT 0.036 (1.197)	DT 0.001 (1.153)	loss 7.214 (7.214)	prob 2.466 (2.466)	GS 33.875 (33.875)	mem 39.872
Train: [73][305/750]	BT 0.031 (1.178)	DT 0.001 (1.134)	loss 7.429 (7.429)	prob 2.499 (2.499)	GS 31.531 (31.531)	mem 39.872
Train: [73][310/750]	BT 17.062 (1.214)	DT 17.022 (1.170)	loss 6.960 (6.960)	prob 3.039 (3.039)	GS 36.812 (36.812)	mem 39.875
Train: [73][315/750]	BT 0.024 (1.195)	DT 0.001 (1.152)	loss 7.689 (7.689)	prob 2.799 (2.799)	GS 32.531 (32.531)	mem 39.865
Train: [73][320/750]	BT 0.024 (1.177)	DT 0.001 (1.134)	loss 7.239 (7.239)	prob 3.481 (3.481)	GS 34.375 (34.375)	mem 39.888
Train: [73][325/750]	BT 0.033 (1.199)	DT 0.001 (1.155)	loss 6.882 (6.882)	prob 3.007 (3.007)	GS 31.219 (31.219)	mem 39.850
Train: [73][330/750]	BT 0.148 (1.182)	DT 0.004 (1.138)	loss 7.331 (7.331)	prob 2.757 (2.757)	GS 35.125 (35.125)	mem 39.971
Train: [73][335/750]	BT 0.030 (1.208)	DT 0.001 (1.164)	loss 7.665 (7.665)	prob 2.070 (2.070)	GS 33.797 (33.797)	mem 39.880
Train: [73][340/750]	BT 0.056 (1.191)	DT 0.007 (1.147)	loss 7.163 (7.163)	prob 2.867 (2.867)	GS 32.406 (32.406)	mem 40.035
Train: [73][345/750]	BT 0.045 (1.174)	DT 0.003 (1.130)	loss 7.067 (7.067)	prob 2.731 (2.731)	GS 28.641 (28.641)	mem 39.887
Train: [73][350/750]	BT 0.047 (1.188)	DT 0.002 (1.143)	loss 7.271 (7.271)	prob 2.563 (2.563)	GS 31.531 (31.531)	mem 39.895
Train: [73][355/750]	BT 0.029 (1.172)	DT 0.001 (1.127)	loss 7.087 (7.087)	prob 2.406 (2.406)	GS 27.672 (27.672)	mem 39.896
Train: [73][360/750]	BT 0.022 (1.199)	DT 0.001 (1.155)	loss 7.377 (7.377)	prob 2.975 (2.975)	GS 32.828 (32.828)	mem 39.858
Train: [73][365/750]	BT 0.046 (1.183)	DT 0.001 (1.139)	loss 7.238 (7.238)	prob 2.977 (2.977)	GS 33.438 (33.438)	mem 39.801
Train: [73][370/750]	BT 11.383 (1.199)	DT 11.318 (1.154)	loss 7.373 (7.373)	prob 3.205 (3.205)	GS 34.625 (34.625)	mem 39.984
Train: [73][375/750]	BT 0.038 (1.183)	DT 0.006 (1.139)	loss 7.362 (7.362)	prob 2.699 (2.699)	GS 34.062 (34.062)	mem 39.821
Train: [73][380/750]	BT 0.050 (1.168)	DT 0.008 (1.124)	loss 7.127 (7.127)	prob 2.631 (2.631)	GS 34.828 (34.828)	mem 39.821
Train: [73][385/750]	BT 0.023 (1.186)	DT 0.001 (1.142)	loss 6.847 (6.847)	prob 2.791 (2.791)	GS 31.938 (31.938)	mem 39.808
Train: [73][390/750]	BT 0.085 (1.172)	DT 0.018 (1.128)	loss 7.230 (7.230)	prob 3.028 (3.028)	GS 36.578 (36.578)	mem 39.810
Train: [73][395/750]	BT 0.034 (1.193)	DT 0.002 (1.149)	loss 7.283 (7.283)	prob 3.139 (3.139)	GS 30.766 (30.766)	mem 39.840
Train: [73][400/750]	BT 0.032 (1.178)	DT 0.001 (1.134)	loss 7.020 (7.020)	prob 3.551 (3.551)	GS 34.766 (34.766)	mem 39.841
Train: [73][405/750]	BT 0.055 (1.164)	DT 0.018 (1.120)	loss 7.143 (7.143)	prob 2.828 (2.828)	GS 28.172 (28.172)	mem 39.842
Train: [73][410/750]	BT 0.038 (1.188)	DT 0.001 (1.144)	loss 7.007 (7.007)	prob 2.768 (2.768)	GS 34.000 (34.000)	mem 40.071
Train: [73][415/750]	BT 0.032 (1.174)	DT 0.001 (1.130)	loss 7.157 (7.157)	prob 2.487 (2.487)	GS 33.297 (33.297)	mem 39.849
Train: [73][420/750]	BT 0.056 (1.186)	DT 0.012 (1.142)	loss 7.037 (7.037)	prob 3.174 (3.174)	GS 33.516 (33.516)	mem 39.861
Train: [73][425/750]	BT 0.042 (1.172)	DT 0.002 (1.128)	loss 7.207 (7.207)	prob 2.440 (2.440)	GS 43.891 (43.891)	mem 39.966
Train: [73][430/750]	BT 11.505 (1.186)	DT 11.445 (1.142)	loss 7.069 (7.069)	prob 2.778 (2.778)	GS 35.984 (35.984)	mem 40.057
Train: [73][435/750]	BT 0.032 (1.173)	DT 0.001 (1.129)	loss 7.381 (7.381)	prob 2.320 (2.320)	GS 32.859 (32.859)	mem 39.908
Train: [73][440/750]	BT 0.032 (1.160)	DT 0.001 (1.116)	loss 7.176 (7.176)	prob 2.765 (2.765)	GS 32.609 (32.609)	mem 39.855
Train: [73][445/750]	BT 0.054 (1.177)	DT 0.006 (1.133)	loss 6.915 (6.915)	prob 2.636 (2.636)	GS 31.703 (31.703)	mem 39.840
Train: [73][450/750]	BT 0.025 (1.166)	DT 0.001 (1.122)	loss 7.358 (7.358)	prob 3.227 (3.227)	GS 33.297 (33.297)	mem 39.844
Train: [73][455/750]	BT 0.029 (1.183)	DT 0.001 (1.139)	loss 7.124 (7.124)	prob 2.605 (2.605)	GS 31.219 (31.219)	mem 39.746
Train: [73][460/750]	BT 0.027 (1.170)	DT 0.001 (1.127)	loss 7.094 (7.094)	prob 2.901 (2.901)	GS 32.781 (32.781)	mem 39.747
Train: [73][465/750]	BT 0.025 (1.158)	DT 0.001 (1.115)	loss 7.486 (7.486)	prob 2.240 (2.240)	GS 32.125 (32.125)	mem 39.749
Train: [73][470/750]	BT 0.036 (1.171)	DT 0.002 (1.128)	loss 6.990 (6.990)	prob 2.965 (2.965)	GS 34.672 (34.672)	mem 39.865
Train: [73][475/750]	BT 0.057 (1.159)	DT 0.003 (1.116)	loss 7.764 (7.764)	prob 2.104 (2.104)	GS 33.250 (33.250)	mem 39.764
Train: [73][480/750]	BT 0.025 (1.176)	DT 0.001 (1.132)	loss 6.943 (6.943)	prob 2.978 (2.978)	GS 32.750 (32.750)	mem 39.842
Train: [73][485/750]	BT 0.064 (1.164)	DT 0.009 (1.121)	loss 7.261 (7.261)	prob 2.225 (2.225)	GS 27.609 (27.609)	mem 39.844
Train: [73][490/750]	BT 11.945 (1.177)	DT 11.892 (1.134)	loss 7.173 (7.173)	prob 2.889 (2.889)	GS 32.109 (32.109)	mem 39.845
Train: [73][495/750]	BT 0.065 (1.166)	DT 0.026 (1.122)	loss 6.885 (6.885)	prob 2.560 (2.560)	GS 31.016 (31.016)	mem 39.851
Train: [73][500/750]	BT 0.035 (1.154)	DT 0.001 (1.111)	loss 7.077 (7.077)	prob 2.965 (2.965)	GS 33.750 (33.750)	mem 39.886
Train: [73][505/750]	BT 0.032 (1.165)	DT 0.001 (1.121)	loss 7.323 (7.323)	prob 2.575 (2.575)	GS 31.719 (31.719)	mem 39.842
Train: [73][510/750]	BT 0.048 (1.156)	DT 0.014 (1.113)	loss 7.033 (7.033)	prob 2.979 (2.979)	GS 34.359 (34.359)	mem 39.866
Train: [73][515/750]	BT 0.127 (1.162)	DT 0.002 (1.119)	loss 7.384 (7.384)	prob 2.734 (2.734)	GS 30.797 (30.797)	mem 40.037
Train: [73][520/750]	BT 0.209 (1.157)	DT 0.174 (1.114)	loss 7.278 (7.278)	prob 2.794 (2.794)	GS 34.766 (34.766)	mem 39.873
Train: [73][525/750]	BT 0.043 (1.146)	DT 0.004 (1.103)	loss 7.530 (7.530)	prob 2.515 (2.515)	GS 31.719 (31.719)	mem 39.903
Train: [73][530/750]	BT 0.036 (1.156)	DT 0.002 (1.113)	loss 7.297 (7.297)	prob 2.564 (2.564)	GS 35.469 (35.469)	mem 40.005
Train: [73][535/750]	BT 0.031 (1.146)	DT 0.001 (1.103)	loss 7.336 (7.336)	prob 2.265 (2.265)	GS 32.219 (32.219)	mem 39.928
Train: [73][540/750]	BT 0.315 (1.158)	DT 0.271 (1.114)	loss 7.239 (7.239)	prob 2.669 (2.669)	GS 35.812 (35.812)	mem 39.675
Train: [73][545/750]	BT 0.044 (1.148)	DT 0.006 (1.104)	loss 7.309 (7.309)	prob 2.385 (2.385)	GS 36.750 (36.750)	mem 39.701
Train: [73][550/750]	BT 13.122 (1.161)	DT 13.042 (1.118)	loss 7.328 (7.328)	prob 2.582 (2.582)	GS 36.312 (36.312)	mem 40.152
Train: [73][555/750]	BT 0.026 (1.151)	DT 0.001 (1.108)	loss 6.837 (6.837)	prob 2.732 (2.732)	GS 30.906 (30.906)	mem 39.909
Train: [73][560/750]	BT 0.052 (1.142)	DT 0.001 (1.098)	loss 7.383 (7.383)	prob 2.382 (2.382)	GS 32.203 (32.203)	mem 39.924
Train: [73][565/750]	BT 0.042 (1.157)	DT 0.012 (1.114)	loss 7.001 (7.001)	prob 2.159 (2.159)	GS 31.766 (31.766)	mem 39.910
Train: [73][570/750]	BT 0.031 (1.147)	DT 0.001 (1.104)	loss 7.223 (7.223)	prob 2.607 (2.607)	GS 38.891 (38.891)	mem 39.912
Train: [73][575/750]	BT 0.029 (1.156)	DT 0.002 (1.113)	loss 6.870 (6.870)	prob 2.528 (2.528)	GS 29.562 (29.562)	mem 39.870
Train: [73][580/750]	BT 0.042 (1.152)	DT 0.012 (1.108)	loss 7.047 (7.047)	prob 2.906 (2.906)	GS 35.703 (35.703)	mem 39.830
Train: [73][585/750]	BT 0.052 (1.142)	DT 0.013 (1.099)	loss 7.492 (7.492)	prob 1.937 (1.937)	GS 30.109 (30.109)	mem 39.876
Train: [73][590/750]	BT 0.078 (1.157)	DT 0.002 (1.113)	loss 7.333 (7.333)	prob 2.376 (2.376)	GS 32.844 (32.844)	mem 40.061
Train: [73][595/750]	BT 0.048 (1.147)	DT 0.001 (1.104)	loss 6.903 (6.903)	prob 1.932 (1.932)	GS 33.656 (33.656)	mem 39.859
Train: [73][600/750]	BT 7.892 (1.160)	DT 7.869 (1.117)	loss 7.089 (7.089)	prob 2.595 (2.595)	GS 36.844 (36.844)	mem 39.877
Train: [73][605/750]	BT 0.045 (1.151)	DT 0.002 (1.108)	loss 7.328 (7.328)	prob 1.827 (1.827)	GS 35.797 (35.797)	mem 39.804
Train: [73][610/750]	BT 7.567 (1.154)	DT 7.536 (1.111)	loss 7.095 (7.095)	prob 2.158 (2.158)	GS 34.844 (34.844)	mem 39.836
Train: [73][615/750]	BT 0.056 (1.156)	DT 0.019 (1.113)	loss 7.268 (7.268)	prob 2.092 (2.092)	GS 34.672 (34.672)	mem 40.001
Train: [73][620/750]	BT 0.104 (1.147)	DT 0.009 (1.104)	loss 7.263 (7.263)	prob 2.433 (2.433)	GS 29.953 (29.953)	mem 39.953
Train: [73][625/750]	BT 0.032 (1.159)	DT 0.001 (1.115)	loss 7.580 (7.580)	prob 1.717 (1.717)	GS 34.625 (34.625)	mem 40.000
Train: [73][630/750]	BT 0.031 (1.150)	DT 0.001 (1.106)	loss 7.441 (7.441)	prob 2.372 (2.372)	GS 32.391 (32.391)	mem 40.000
Train: [73][635/750]	BT 0.088 (1.147)	DT 0.001 (1.104)	loss 7.023 (7.023)	prob 1.997 (1.997)	GS 27.031 (27.031)	mem 40.012
Train: [73][640/750]	BT 5.127 (1.157)	DT 5.096 (1.114)	loss 7.238 (7.238)	prob 2.446 (2.446)	GS 35.109 (35.109)	mem 39.973
Train: [73][645/750]	BT 0.035 (1.148)	DT 0.002 (1.105)	loss 7.156 (7.156)	prob 1.894 (1.894)	GS 31.844 (31.844)	mem 40.184
Train: [73][650/750]	BT 0.045 (1.154)	DT 0.005 (1.111)	loss 7.178 (7.178)	prob 2.621 (2.621)	GS 34.422 (34.422)	mem 40.245
Train: [73][655/750]	BT 0.036 (1.148)	DT 0.007 (1.105)	loss 7.093 (7.093)	prob 2.603 (2.603)	GS 26.516 (26.516)	mem 40.010
arpack error, retry= 0
Train: [73][660/750]	BT 7.241 (1.151)	DT 7.204 (1.108)	loss 6.969 (6.969)	prob 2.496 (2.496)	GS 33.906 (33.906)	mem 40.032
Train: [73][665/750]	BT 0.036 (1.153)	DT 0.002 (1.109)	loss 7.144 (7.144)	prob 2.168 (2.168)	GS 32.125 (32.125)	mem 39.992
Train: [73][670/750]	BT 0.079 (1.144)	DT 0.001 (1.101)	loss 7.245 (7.245)	prob 2.692 (2.692)	GS 33.172 (33.172)	mem 40.014
Train: [73][675/750]	BT 0.078 (1.146)	DT 0.002 (1.102)	loss 7.322 (7.322)	prob 2.304 (2.304)	GS 31.906 (31.906)	mem 39.883
Train: [73][680/750]	BT 0.034 (1.145)	DT 0.008 (1.102)	loss 7.780 (7.780)	prob 2.567 (2.567)	GS 35.484 (35.484)	mem 39.826
Train: [73][685/750]	BT 0.053 (1.145)	DT 0.008 (1.102)	loss 7.117 (7.117)	prob 2.334 (2.334)	GS 35.828 (35.828)	mem 40.008
Train: [73][690/750]	BT 0.040 (1.149)	DT 0.004 (1.105)	loss 6.961 (6.961)	prob 3.095 (3.095)	GS 27.812 (27.812)	mem 39.936
Train: [73][695/750]	BT 0.115 (1.141)	DT 0.058 (1.097)	loss 7.178 (7.178)	prob 2.813 (2.813)	GS 32.000 (32.000)	mem 40.002
Train: [73][700/750]	BT 8.543 (1.153)	DT 8.491 (1.109)	loss 7.149 (7.149)	prob 2.960 (2.960)	GS 33.875 (33.875)	mem 40.031
Train: [73][705/750]	BT 0.035 (1.145)	DT 0.002 (1.102)	loss 7.044 (7.044)	prob 2.929 (2.929)	GS 30.094 (30.094)	mem 39.887
Train: [73][710/750]	BT 0.049 (1.142)	DT 0.017 (1.099)	loss 7.617 (7.617)	prob 2.799 (2.799)	GS 33.156 (33.156)	mem 39.986
Train: [73][715/750]	BT 0.038 (1.148)	DT 0.002 (1.104)	loss 7.083 (7.083)	prob 2.336 (2.336)	GS 29.016 (29.016)	mem 39.936
Train: [73][720/750]	BT 0.461 (1.141)	DT 0.428 (1.097)	loss 7.120 (7.120)	prob 2.558 (2.558)	GS 33.203 (33.203)	mem 40.004
Train: [73][725/750]	BT 0.045 (1.152)	DT 0.009 (1.108)	loss 7.745 (7.745)	prob 2.024 (2.024)	GS 29.703 (29.703)	mem 39.805
Train: [73][730/750]	BT 0.040 (1.144)	DT 0.001 (1.100)	loss 7.127 (7.127)	prob 2.652 (2.652)	GS 31.969 (31.969)	mem 39.807
Train: [73][735/750]	BT 0.055 (1.137)	DT 0.002 (1.094)	loss 7.123 (7.123)	prob 2.431 (2.431)	GS 31.641 (31.641)	mem 39.737
Train: [73][740/750]	BT 0.025 (1.140)	DT 0.001 (1.096)	loss 7.228 (7.228)	prob 2.722 (2.722)	GS 30.344 (30.344)	mem 13.547
Train: [73][745/750]	BT 0.039 (1.133)	DT 0.001 (1.089)	loss 6.948 (6.948)	prob 3.145 (3.145)	GS 37.062 (37.062)	mem 13.623
Train: [73][750/750]	BT 0.029 (1.128)	DT 0.001 (1.084)	loss 7.385 (7.385)	prob 2.970 (2.970)	GS 31.250 (31.250)	mem 10.590
Train: [73][755/750]	BT 0.031 (1.121)	DT 0.002 (1.077)	loss 7.774 (7.774)	prob 1.744 (1.744)	GS 33.875 (33.875)	mem 10.590
epoch 73, total time 847.22
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [74][1/750]	BT 28.706 (28.706)	DT 28.626 (28.626)	loss 7.121 (7.121)	prob 1.899 (1.899)	GS 40.000 (40.000)	mem 38.660
Train: [74][5/750]	BT 0.056 (5.800)	DT 0.003 (5.734)	loss 6.894 (6.894)	prob 2.741 (2.741)	GS 33.297 (33.297)	mem 38.662
Train: [74][10/750]	BT 0.047 (2.936)	DT 0.007 (2.869)	loss 6.800 (6.800)	prob 3.122 (3.122)	GS 32.188 (32.188)	mem 38.665
Train: [74][15/750]	BT 0.045 (2.608)	DT 0.001 (2.550)	loss 7.099 (7.099)	prob 2.681 (2.681)	GS 29.016 (29.016)	mem 38.914
Train: [74][20/750]	BT 1.866 (2.064)	DT 1.818 (2.005)	loss 6.998 (6.998)	prob 3.369 (3.369)	GS 35.609 (35.609)	mem 38.797
Train: [74][25/750]	BT 7.161 (1.944)	DT 7.117 (1.889)	loss 7.427 (7.427)	prob 2.744 (2.744)	GS 32.562 (32.562)	mem 38.900
Train: [74][30/750]	BT 3.227 (1.805)	DT 3.188 (1.753)	loss 7.200 (7.200)	prob 2.992 (2.992)	GS 35.625 (35.625)	mem 38.804
Train: [74][35/750]	BT 0.094 (1.598)	DT 0.010 (1.541)	loss 7.460 (7.460)	prob 2.153 (2.153)	GS 40.125 (40.125)	mem 38.843
Train: [74][40/750]	BT 2.471 (1.609)	DT 2.416 (1.554)	loss 7.597 (7.597)	prob 2.524 (2.524)	GS 37.453 (37.453)	mem 39.020
Train: [74][45/750]	BT 0.058 (1.597)	DT 0.004 (1.542)	loss 7.663 (7.663)	prob 2.302 (2.302)	GS 33.375 (33.375)	mem 38.952
Train: [74][50/750]	BT 3.636 (1.515)	DT 3.604 (1.460)	loss 7.260 (7.260)	prob 3.232 (3.232)	GS 33.641 (33.641)	mem 38.921
Train: [74][55/750]	BT 0.036 (1.464)	DT 0.002 (1.410)	loss 7.134 (7.134)	prob 3.215 (3.215)	GS 33.203 (33.203)	mem 38.960
Train: [74][60/750]	BT 0.032 (1.394)	DT 0.001 (1.342)	loss 6.950 (6.950)	prob 3.347 (3.347)	GS 35.156 (35.156)	mem 38.955
Train: [74][65/750]	BT 0.023 (1.406)	DT 0.001 (1.355)	loss 7.766 (7.766)	prob 2.331 (2.331)	GS 33.203 (33.203)	mem 38.928
Train: [74][70/750]	BT 0.025 (1.327)	DT 0.002 (1.278)	loss 6.960 (6.960)	prob 2.943 (2.943)	GS 30.328 (30.328)	mem 39.003
Train: [74][75/750]	BT 0.033 (1.388)	DT 0.001 (1.339)	loss 7.406 (7.406)	prob 2.879 (2.879)	GS 33.188 (33.188)	mem 39.053
Train: [74][80/750]	BT 3.757 (1.373)	DT 3.718 (1.325)	loss 7.175 (7.175)	prob 3.914 (3.914)	GS 36.406 (36.406)	mem 38.996
Train: [74][85/750]	BT 0.073 (1.295)	DT 0.001 (1.247)	loss 7.271 (7.271)	prob 2.939 (2.939)	GS 44.359 (44.359)	mem 39.067
Train: [74][90/750]	BT 0.048 (1.329)	DT 0.006 (1.282)	loss 6.917 (6.917)	prob 3.120 (3.120)	GS 35.578 (35.578)	mem 39.034
Train: [74][95/750]	BT 0.093 (1.278)	DT 0.010 (1.230)	loss 7.830 (7.830)	prob 2.674 (2.674)	GS 31.594 (31.594)	mem 39.105
Train: [74][100/750]	BT 0.040 (1.347)	DT 0.002 (1.298)	loss 7.320 (7.320)	prob 3.466 (3.466)	GS 35.047 (35.047)	mem 39.263
Train: [74][105/750]	BT 0.041 (1.294)	DT 0.010 (1.246)	loss 7.283 (7.283)	prob 2.848 (2.848)	GS 34.844 (34.844)	mem 39.187
Train: [74][110/750]	BT 10.776 (1.335)	DT 10.731 (1.287)	loss 7.031 (7.031)	prob 2.883 (2.883)	GS 33.016 (33.016)	mem 39.203
Train: [74][115/750]	BT 0.046 (1.279)	DT 0.009 (1.231)	loss 7.095 (7.095)	prob 3.148 (3.148)	GS 26.984 (26.984)	mem 39.099
Train: [74][120/750]	BT 0.079 (1.229)	DT 0.011 (1.180)	loss 7.205 (7.205)	prob 2.935 (2.935)	GS 35.234 (35.234)	mem 39.189
Train: [74][125/750]	BT 0.034 (1.297)	DT 0.002 (1.248)	loss 7.294 (7.294)	prob 2.758 (2.758)	GS 31.641 (31.641)	mem 39.126
Train: [74][130/750]	BT 0.033 (1.248)	DT 0.002 (1.200)	loss 7.291 (7.291)	prob 3.260 (3.260)	GS 34.203 (34.203)	mem 39.160
Train: [74][135/750]	BT 0.047 (1.310)	DT 0.002 (1.262)	loss 7.367 (7.367)	prob 3.292 (3.292)	GS 31.375 (31.375)	mem 39.328
Train: [74][140/750]	BT 0.133 (1.268)	DT 0.013 (1.217)	loss 6.997 (6.997)	prob 3.747 (3.747)	GS 32.422 (32.422)	mem 39.193
Train: [74][145/750]	BT 0.070 (1.227)	DT 0.013 (1.176)	loss 7.033 (7.033)	prob 3.224 (3.224)	GS 27.000 (27.000)	mem 39.278
Train: [74][150/750]	BT 0.032 (1.296)	DT 0.001 (1.245)	loss 7.215 (7.215)	prob 3.325 (3.325)	GS 35.797 (35.797)	mem 39.224
Train: [74][155/750]	BT 0.030 (1.256)	DT 0.001 (1.205)	loss 7.283 (7.283)	prob 3.019 (3.019)	GS 31.984 (31.984)	mem 39.224
Train: [74][160/750]	BT 0.035 (1.288)	DT 0.002 (1.238)	loss 7.244 (7.244)	prob 3.422 (3.422)	GS 32.578 (32.578)	mem 39.265
Train: [74][165/750]	BT 0.048 (1.250)	DT 0.007 (1.201)	loss 7.009 (7.009)	prob 3.503 (3.503)	GS 29.312 (29.312)	mem 39.266
Train: [74][170/750]	BT 11.221 (1.282)	DT 11.174 (1.232)	loss 7.260 (7.260)	prob 3.329 (3.329)	GS 38.312 (38.312)	mem 39.256
Train: [74][175/750]	BT 0.030 (1.246)	DT 0.001 (1.196)	loss 7.148 (7.148)	prob 3.212 (3.212)	GS 29.000 (29.000)	mem 39.256
Train: [74][180/750]	BT 0.025 (1.212)	DT 0.001 (1.163)	loss 7.380 (7.380)	prob 3.731 (3.731)	GS 30.469 (30.469)	mem 39.257
Train: [74][185/750]	BT 0.030 (1.254)	DT 0.001 (1.205)	loss 7.119 (7.119)	prob 3.149 (3.149)	GS 34.344 (34.344)	mem 39.510
Train: [74][190/750]	BT 0.048 (1.222)	DT 0.002 (1.173)	loss 7.276 (7.276)	prob 3.250 (3.250)	GS 39.031 (39.031)	mem 39.577
Train: [74][195/750]	BT 0.026 (1.263)	DT 0.001 (1.214)	loss 7.394 (7.394)	prob 2.829 (2.829)	GS 35.812 (35.812)	mem 39.327
Train: [74][200/750]	BT 0.034 (1.232)	DT 0.001 (1.184)	loss 7.581 (7.581)	prob 3.238 (3.238)	GS 37.484 (37.484)	mem 39.368
Train: [74][205/750]	BT 0.060 (1.210)	DT 0.003 (1.162)	loss 7.234 (7.234)	prob 3.065 (3.065)	GS 32.906 (32.906)	mem 39.327
Train: [74][210/750]	BT 0.036 (1.235)	DT 0.002 (1.188)	loss 7.194 (7.194)	prob 3.593 (3.593)	GS 32.203 (32.203)	mem 39.671
Train: [74][215/750]	BT 0.035 (1.207)	DT 0.002 (1.160)	loss 7.278 (7.278)	prob 3.460 (3.460)	GS 29.281 (29.281)	mem 39.667
Train: [74][220/750]	BT 0.066 (1.247)	DT 0.005 (1.199)	loss 7.370 (7.370)	prob 3.195 (3.195)	GS 34.875 (34.875)	mem 39.561
Train: [74][225/750]	BT 0.068 (1.220)	DT 0.001 (1.172)	loss 6.889 (6.889)	prob 3.513 (3.513)	GS 30.984 (30.984)	mem 39.562
Train: [74][230/750]	BT 13.976 (1.256)	DT 13.937 (1.208)	loss 7.169 (7.169)	prob 2.945 (2.945)	GS 28.469 (28.469)	mem 39.483
Train: [74][235/750]	BT 0.032 (1.230)	DT 0.007 (1.182)	loss 7.391 (7.391)	prob 2.958 (2.958)	GS 30.812 (30.812)	mem 39.483
Train: [74][240/750]	BT 0.054 (1.206)	DT 0.008 (1.158)	loss 7.233 (7.233)	prob 2.489 (2.489)	GS 30.312 (30.312)	mem 39.542
Train: [74][245/750]	BT 0.080 (1.224)	DT 0.015 (1.176)	loss 7.326 (7.326)	prob 2.777 (2.777)	GS 36.781 (36.781)	mem 39.582
Train: [74][250/750]	BT 0.053 (1.201)	DT 0.002 (1.152)	loss 7.175 (7.175)	prob 3.278 (3.278)	GS 35.672 (35.672)	mem 39.550
Train: [74][255/750]	BT 0.150 (1.222)	DT 0.006 (1.173)	loss 7.042 (7.042)	prob 3.588 (3.588)	GS 27.891 (27.891)	mem 39.776
Train: [74][260/750]	BT 0.033 (1.199)	DT 0.002 (1.151)	loss 7.577 (7.577)	prob 3.018 (3.018)	GS 32.953 (32.953)	mem 39.829
Train: [74][265/750]	BT 0.047 (1.186)	DT 0.002 (1.138)	loss 7.438 (7.438)	prob 2.952 (2.952)	GS 33.500 (33.500)	mem 39.912
Train: [74][270/750]	BT 0.060 (1.197)	DT 0.010 (1.149)	loss 7.176 (7.176)	prob 3.248 (3.248)	GS 32.828 (32.828)	mem 39.802
Train: [74][275/750]	BT 0.028 (1.181)	DT 0.001 (1.133)	loss 7.167 (7.167)	prob 2.657 (2.657)	GS 31.750 (31.750)	mem 39.831
Train: [74][280/750]	BT 0.042 (1.199)	DT 0.011 (1.151)	loss 6.953 (6.953)	prob 3.594 (3.594)	GS 33.984 (33.984)	mem 39.885
Train: [74][285/750]	BT 0.041 (1.179)	DT 0.002 (1.131)	loss 7.149 (7.149)	prob 3.123 (3.123)	GS 27.656 (27.656)	mem 40.007
Train: [74][290/750]	BT 4.109 (1.213)	DT 4.047 (1.165)	loss 7.605 (7.605)	prob 2.304 (2.304)	GS 35.031 (35.031)	mem 39.842
Train: [74][295/750]	BT 0.064 (1.193)	DT 0.022 (1.145)	loss 7.626 (7.626)	prob 2.604 (2.604)	GS 31.469 (31.469)	mem 39.842
Train: [74][300/750]	BT 6.323 (1.195)	DT 6.283 (1.147)	loss 6.970 (6.970)	prob 3.133 (3.133)	GS 33.297 (33.297)	mem 40.032
Train: [74][305/750]	BT 0.024 (1.198)	DT 0.001 (1.151)	loss 7.377 (7.377)	prob 2.927 (2.927)	GS 33.094 (33.094)	mem 40.035
Train: [74][310/750]	BT 0.027 (1.180)	DT 0.002 (1.133)	loss 7.259 (7.259)	prob 3.759 (3.759)	GS 34.203 (34.203)	mem 39.917
Train: [74][315/750]	BT 0.037 (1.202)	DT 0.006 (1.155)	loss 7.036 (7.036)	prob 3.131 (3.131)	GS 34.266 (34.266)	mem 39.938
Train: [74][320/750]	BT 0.048 (1.184)	DT 0.003 (1.137)	loss 6.998 (6.998)	prob 3.185 (3.185)	GS 38.547 (38.547)	mem 40.077
Train: [74][325/750]	BT 0.071 (1.171)	DT 0.003 (1.124)	loss 7.134 (7.134)	prob 3.443 (3.443)	GS 29.453 (29.453)	mem 39.935
Train: [74][330/750]	BT 0.104 (1.191)	DT 0.001 (1.144)	loss 7.042 (7.042)	prob 3.325 (3.325)	GS 32.531 (32.531)	mem 39.956
Train: [74][335/750]	BT 0.052 (1.174)	DT 0.018 (1.127)	loss 6.927 (6.927)	prob 3.144 (3.144)	GS 30.438 (30.438)	mem 39.896
Train: [74][340/750]	BT 0.106 (1.198)	DT 0.003 (1.151)	loss 6.821 (6.821)	prob 3.136 (3.136)	GS 29.781 (29.781)	mem 40.204
Train: [74][345/750]	BT 0.037 (1.181)	DT 0.001 (1.134)	loss 7.647 (7.647)	prob 2.163 (2.163)	GS 30.703 (30.703)	mem 39.972
Train: [74][350/750]	BT 8.321 (1.200)	DT 8.280 (1.153)	loss 7.182 (7.182)	prob 2.967 (2.967)	GS 32.391 (32.391)	mem 39.994
Train: [74][355/750]	BT 0.030 (1.184)	DT 0.001 (1.137)	loss 7.278 (7.278)	prob 2.414 (2.414)	GS 29.844 (29.844)	mem 39.995
Train: [74][360/750]	BT 5.944 (1.184)	DT 5.894 (1.138)	loss 7.260 (7.260)	prob 3.424 (3.424)	GS 33.984 (33.984)	mem 40.002
Train: [74][365/750]	BT 0.030 (1.184)	DT 0.001 (1.137)	loss 7.014 (7.014)	prob 3.511 (3.511)	GS 32.500 (32.500)	mem 40.071
Train: [74][370/750]	BT 0.023 (1.168)	DT 0.001 (1.122)	loss 6.965 (6.965)	prob 3.509 (3.509)	GS 31.047 (31.047)	mem 39.986
Train: [74][375/750]	BT 0.092 (1.187)	DT 0.010 (1.141)	loss 7.264 (7.264)	prob 3.087 (3.087)	GS 30.609 (30.609)	mem 39.985
Train: [74][380/750]	BT 0.031 (1.172)	DT 0.001 (1.126)	loss 7.022 (7.022)	prob 3.294 (3.294)	GS 31.328 (31.328)	mem 39.987
Train: [74][385/750]	BT 0.034 (1.168)	DT 0.002 (1.122)	loss 7.019 (7.019)	prob 3.502 (3.502)	GS 30.766 (30.766)	mem 39.954
Train: [74][390/750]	BT 0.024 (1.175)	DT 0.001 (1.129)	loss 7.023 (7.023)	prob 3.367 (3.367)	GS 29.906 (29.906)	mem 40.027
Train: [74][395/750]	BT 0.029 (1.160)	DT 0.001 (1.114)	loss 7.314 (7.314)	prob 2.503 (2.503)	GS 29.016 (29.016)	mem 40.037
Train: [74][400/750]	BT 0.023 (1.174)	DT 0.001 (1.128)	loss 7.048 (7.048)	prob 2.692 (2.692)	GS 34.328 (34.328)	mem 39.971
Train: [74][405/750]	BT 0.050 (1.160)	DT 0.009 (1.114)	loss 7.608 (7.608)	prob 2.068 (2.068)	GS 27.766 (27.766)	mem 39.972
Train: [74][410/750]	BT 13.991 (1.181)	DT 13.946 (1.135)	loss 6.913 (6.913)	prob 2.985 (2.985)	GS 31.234 (31.234)	mem 39.965
Train: [74][415/750]	BT 0.037 (1.167)	DT 0.001 (1.121)	loss 7.077 (7.077)	prob 2.518 (2.518)	GS 31.875 (31.875)	mem 39.965
Train: [74][420/750]	BT 0.163 (1.154)	DT 0.013 (1.108)	loss 6.899 (6.899)	prob 2.914 (2.914)	GS 32.344 (32.344)	mem 40.084
Train: [74][425/750]	BT 0.037 (1.171)	DT 0.001 (1.125)	loss 7.091 (7.091)	prob 2.751 (2.751)	GS 30.516 (30.516)	mem 40.066
Train: [74][430/750]	BT 0.057 (1.159)	DT 0.002 (1.112)	loss 7.193 (7.193)	prob 2.806 (2.806)	GS 36.109 (36.109)	mem 39.994
Train: [74][435/750]	BT 0.060 (1.176)	DT 0.003 (1.130)	loss 7.215 (7.215)	prob 2.658 (2.658)	GS 32.953 (32.953)	mem 39.943
Train: [74][440/750]	BT 0.032 (1.163)	DT 0.001 (1.117)	loss 7.287 (7.287)	prob 3.216 (3.216)	GS 33.312 (33.312)	mem 39.944
Train: [74][445/750]	BT 0.033 (1.150)	DT 0.001 (1.104)	loss 7.147 (7.147)	prob 3.132 (3.132)	GS 36.453 (36.453)	mem 39.943
Train: [74][450/750]	BT 0.030 (1.169)	DT 0.001 (1.123)	loss 7.376 (7.376)	prob 3.125 (3.125)	GS 35.266 (35.266)	mem 40.000
Train: [74][455/750]	BT 0.088 (1.157)	DT 0.010 (1.111)	loss 6.976 (6.976)	prob 2.497 (2.497)	GS 30.406 (30.406)	mem 40.005
Train: [74][460/750]	BT 0.026 (1.172)	DT 0.001 (1.127)	loss 7.008 (7.008)	prob 3.312 (3.312)	GS 31.109 (31.109)	mem 39.966
Train: [74][465/750]	BT 0.030 (1.160)	DT 0.001 (1.115)	loss 7.252 (7.252)	prob 2.971 (2.971)	GS 31.484 (31.484)	mem 39.966
Train: [74][470/750]	BT 12.792 (1.175)	DT 12.763 (1.130)	loss 7.133 (7.133)	prob 2.748 (2.748)	GS 33.812 (33.812)	mem 39.971
Train: [74][475/750]	BT 0.038 (1.163)	DT 0.001 (1.118)	loss 6.913 (6.913)	prob 2.846 (2.846)	GS 31.703 (31.703)	mem 39.909
Train: [74][480/750]	BT 0.034 (1.152)	DT 0.002 (1.107)	loss 7.127 (7.127)	prob 2.974 (2.974)	GS 31.375 (31.375)	mem 39.937
Train: [74][485/750]	BT 0.066 (1.166)	DT 0.011 (1.121)	loss 6.970 (6.970)	prob 2.837 (2.837)	GS 32.000 (32.000)	mem 40.391
Train: [74][490/750]	BT 0.088 (1.155)	DT 0.034 (1.110)	loss 6.976 (6.976)	prob 2.620 (2.620)	GS 35.344 (35.344)	mem 39.969
Train: [74][495/750]	BT 0.024 (1.173)	DT 0.001 (1.128)	loss 7.297 (7.297)	prob 2.822 (2.822)	GS 28.734 (28.734)	mem 39.905
Train: [74][500/750]	BT 0.029 (1.161)	DT 0.001 (1.116)	loss 6.920 (6.920)	prob 2.657 (2.657)	GS 35.125 (35.125)	mem 39.906
Train: [74][505/750]	BT 0.049 (1.150)	DT 0.003 (1.105)	loss 7.362 (7.362)	prob 2.526 (2.526)	GS 33.766 (33.766)	mem 39.907
Train: [74][510/750]	BT 0.022 (1.168)	DT 0.001 (1.123)	loss 6.988 (6.988)	prob 2.248 (2.248)	GS 34.516 (34.516)	mem 39.961
Train: [74][515/750]	BT 0.035 (1.157)	DT 0.001 (1.112)	loss 7.216 (7.216)	prob 2.531 (2.531)	GS 30.078 (30.078)	mem 39.961
Train: [74][520/750]	BT 0.023 (1.172)	DT 0.001 (1.127)	loss 7.078 (7.078)	prob 3.008 (3.008)	GS 33.625 (33.625)	mem 39.922
Train: [74][525/750]	BT 0.030 (1.161)	DT 0.001 (1.116)	loss 7.189 (7.189)	prob 2.433 (2.433)	GS 34.797 (34.797)	mem 39.922
Train: [74][530/750]	BT 13.532 (1.176)	DT 13.491 (1.131)	loss 6.962 (6.962)	prob 2.931 (2.931)	GS 35.250 (35.250)	mem 40.198
Train: [74][535/750]	BT 0.026 (1.165)	DT 0.001 (1.121)	loss 7.045 (7.045)	prob 2.910 (2.910)	GS 30.156 (30.156)	mem 40.081
Train: [74][540/750]	BT 0.049 (1.155)	DT 0.005 (1.110)	loss 7.294 (7.294)	prob 2.642 (2.642)	GS 33.812 (33.812)	mem 40.081
Train: [74][545/750]	BT 0.044 (1.166)	DT 0.001 (1.121)	loss 7.350 (7.350)	prob 2.032 (2.032)	GS 32.062 (32.062)	mem 39.987
Train: [74][550/750]	BT 0.036 (1.155)	DT 0.001 (1.111)	loss 7.341 (7.341)	prob 2.481 (2.481)	GS 31.391 (31.391)	mem 40.125
Train: [74][555/750]	BT 0.068 (1.170)	DT 0.010 (1.126)	loss 6.902 (6.902)	prob 2.732 (2.732)	GS 31.656 (31.656)	mem 40.107
Train: [74][560/750]	BT 0.035 (1.160)	DT 0.005 (1.116)	loss 6.918 (6.918)	prob 2.875 (2.875)	GS 34.156 (34.156)	mem 39.987
Train: [74][565/750]	BT 0.103 (1.150)	DT 0.006 (1.106)	loss 7.139 (7.139)	prob 2.922 (2.922)	GS 32.859 (32.859)	mem 39.988
Train: [74][570/750]	BT 0.114 (1.163)	DT 0.010 (1.118)	loss 7.009 (7.009)	prob 2.809 (2.809)	GS 34.141 (34.141)	mem 39.949
Train: [74][575/750]	BT 0.040 (1.153)	DT 0.001 (1.109)	loss 7.009 (7.009)	prob 2.802 (2.802)	GS 35.906 (35.906)	mem 39.949
Train: [74][580/750]	BT 0.024 (1.165)	DT 0.001 (1.121)	loss 7.174 (7.174)	prob 2.573 (2.573)	GS 35.531 (35.531)	mem 39.890
Train: [74][585/750]	BT 0.053 (1.156)	DT 0.002 (1.111)	loss 7.123 (7.123)	prob 2.527 (2.527)	GS 26.281 (26.281)	mem 39.890
Train: [74][590/750]	BT 14.420 (1.171)	DT 14.380 (1.126)	loss 7.121 (7.121)	prob 2.510 (2.510)	GS 35.359 (35.359)	mem 39.796
Train: [74][595/750]	BT 0.083 (1.161)	DT 0.010 (1.117)	loss 6.801 (6.801)	prob 2.816 (2.816)	GS 31.031 (31.031)	mem 39.796
Train: [74][600/750]	BT 0.047 (1.152)	DT 0.001 (1.108)	loss 7.130 (7.130)	prob 2.080 (2.080)	GS 34.203 (34.203)	mem 39.855
Train: [74][605/750]	BT 0.030 (1.164)	DT 0.001 (1.120)	loss 7.044 (7.044)	prob 2.496 (2.496)	GS 33.219 (33.219)	mem 39.977
Train: [74][610/750]	BT 0.025 (1.155)	DT 0.001 (1.111)	loss 6.808 (6.808)	prob 2.590 (2.590)	GS 38.953 (38.953)	mem 39.878
Train: [74][615/750]	BT 0.030 (1.166)	DT 0.001 (1.122)	loss 7.200 (7.200)	prob 2.044 (2.044)	GS 28.594 (28.594)	mem 39.836
Train: [74][620/750]	BT 0.050 (1.157)	DT 0.011 (1.113)	loss 7.072 (7.072)	prob 2.516 (2.516)	GS 33.484 (33.484)	mem 39.838
Train: [74][625/750]	BT 0.031 (1.148)	DT 0.002 (1.104)	loss 7.177 (7.177)	prob 2.084 (2.084)	GS 25.844 (25.844)	mem 39.840
Train: [74][630/750]	BT 0.029 (1.159)	DT 0.001 (1.115)	loss 7.284 (7.284)	prob 1.688 (1.688)	GS 32.188 (32.188)	mem 39.729
Train: [74][635/750]	BT 0.072 (1.150)	DT 0.022 (1.107)	loss 7.224 (7.224)	prob 2.482 (2.482)	GS 27.000 (27.000)	mem 39.805
Train: [74][640/750]	BT 0.031 (1.161)	DT 0.001 (1.117)	loss 6.962 (6.962)	prob 2.452 (2.452)	GS 30.984 (30.984)	mem 39.908
Train: [74][645/750]	BT 0.079 (1.152)	DT 0.025 (1.108)	loss 7.163 (7.163)	prob 2.161 (2.161)	GS 28.688 (28.688)	mem 39.911
Train: [74][650/750]	BT 12.155 (1.162)	DT 12.108 (1.119)	loss 7.032 (7.032)	prob 2.429 (2.429)	GS 35.500 (35.500)	mem 39.880
Train: [74][655/750]	BT 0.039 (1.154)	DT 0.001 (1.110)	loss 7.421 (7.421)	prob 1.935 (1.935)	GS 31.875 (31.875)	mem 39.894
arpack error, retry= 0
Train: [74][660/750]	BT 0.052 (1.146)	DT 0.002 (1.102)	loss 7.366 (7.366)	prob 2.444 (2.444)	GS 32.250 (32.250)	mem 39.882
Train: [74][665/750]	BT 0.033 (1.157)	DT 0.002 (1.113)	loss 6.772 (6.772)	prob 2.162 (2.162)	GS 32.922 (32.922)	mem 39.930
Train: [74][670/750]	BT 0.030 (1.149)	DT 0.001 (1.105)	loss 7.105 (7.105)	prob 2.568 (2.568)	GS 28.844 (28.844)	mem 39.889
Train: [74][675/750]	BT 0.031 (1.162)	DT 0.001 (1.118)	loss 7.187 (7.187)	prob 2.189 (2.189)	GS 30.141 (30.141)	mem 39.965
Train: [74][680/750]	BT 0.048 (1.153)	DT 0.001 (1.110)	loss 7.035 (7.035)	prob 2.097 (2.097)	GS 34.531 (34.531)	mem 39.967
Train: [74][685/750]	BT 0.037 (1.145)	DT 0.002 (1.102)	loss 8.345 (8.345)	prob 0.809 (0.809)	GS 37.469 (37.469)	mem 39.968
Train: [74][690/750]	BT 0.081 (1.155)	DT 0.002 (1.111)	loss 7.336 (7.336)	prob 1.977 (1.977)	GS 35.828 (35.828)	mem 40.072
Train: [74][695/750]	BT 0.057 (1.147)	DT 0.006 (1.103)	loss 7.161 (7.161)	prob 2.207 (2.207)	GS 31.469 (31.469)	mem 40.008
Train: [74][700/750]	BT 0.035 (1.162)	DT 0.001 (1.119)	loss 7.614 (7.614)	prob 1.957 (1.957)	GS 32.781 (32.781)	mem 39.839
Train: [74][705/750]	BT 0.087 (1.154)	DT 0.004 (1.111)	loss 7.099 (7.099)	prob 2.082 (2.082)	GS 29.141 (29.141)	mem 39.847
Train: [74][710/750]	BT 12.427 (1.164)	DT 12.389 (1.120)	loss 7.237 (7.237)	prob 2.074 (2.074)	GS 33.188 (33.188)	mem 39.972
Train: [74][715/750]	BT 0.023 (1.156)	DT 0.001 (1.113)	loss 7.654 (7.654)	prob 1.510 (1.510)	GS 35.672 (35.672)	mem 39.973
Train: [74][720/750]	BT 0.036 (1.148)	DT 0.001 (1.105)	loss 7.125 (7.125)	prob 1.589 (1.589)	GS 34.859 (34.859)	mem 39.896
Train: [74][725/750]	BT 0.028 (1.157)	DT 0.001 (1.114)	loss 6.833 (6.833)	prob 2.109 (2.109)	GS 32.656 (32.656)	mem 39.896
Train: [74][730/750]	BT 0.024 (1.150)	DT 0.001 (1.107)	loss 7.114 (7.114)	prob 2.049 (2.049)	GS 36.984 (36.984)	mem 39.897
Train: [74][735/750]	BT 0.029 (1.153)	DT 0.001 (1.110)	loss 7.187 (7.187)	prob 2.217 (2.217)	GS 30.922 (30.922)	mem 36.544
Train: [74][740/750]	BT 0.026 (1.146)	DT 0.001 (1.103)	loss 7.167 (7.167)	prob 2.208 (2.208)	GS 29.922 (29.922)	mem 36.545
Train: [74][745/750]	BT 0.031 (1.138)	DT 0.001 (1.095)	loss 7.279 (7.279)	prob 2.048 (2.048)	GS 31.188 (31.188)	mem 36.546
Train: [74][750/750]	BT 0.033 (1.134)	DT 0.001 (1.091)	loss 6.875 (6.875)	prob 1.903 (1.903)	GS 31.969 (31.969)	mem 7.583
Train: [74][755/750]	BT 0.029 (1.127)	DT 0.001 (1.084)	loss 7.246 (7.246)	prob 1.441 (1.441)	GS 36.125 (36.125)	mem 7.583
epoch 74, total time 850.87
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [75][1/750]	BT 19.815 (19.815)	DT 19.748 (19.748)	loss 7.218 (7.218)	prob 1.647 (1.647)	GS 29.625 (29.625)	mem 38.580
Train: [75][5/750]	BT 0.048 (4.941)	DT 0.002 (4.892)	loss 6.998 (6.998)	prob 1.626 (1.626)	GS 27.969 (27.969)	mem 38.633
Train: [75][10/750]	BT 0.044 (2.939)	DT 0.012 (2.883)	loss 7.315 (7.315)	prob 1.855 (1.855)	GS 33.547 (33.547)	mem 38.716
Train: [75][15/750]	BT 0.046 (2.316)	DT 0.007 (2.265)	loss 7.272 (7.272)	prob 2.456 (2.456)	GS 33.406 (33.406)	mem 38.744
Train: [75][20/750]	BT 5.856 (2.102)	DT 5.798 (2.054)	loss 7.140 (7.140)	prob 1.852 (1.852)	GS 33.469 (33.469)	mem 38.820
Train: [75][25/750]	BT 0.088 (1.691)	DT 0.016 (1.645)	loss 7.601 (7.601)	prob 1.513 (1.513)	GS 37.016 (37.016)	mem 38.823
Train: [75][30/750]	BT 0.051 (1.754)	DT 0.003 (1.709)	loss 7.787 (7.787)	prob 1.450 (1.450)	GS 27.094 (27.094)	mem 38.910
Train: [75][35/750]	BT 0.141 (1.523)	DT 0.001 (1.473)	loss 6.944 (6.944)	prob 2.520 (2.520)	GS 32.297 (32.297)	mem 38.992
Train: [75][40/750]	BT 0.058 (1.609)	DT 0.012 (1.560)	loss 7.976 (7.976)	prob 1.858 (1.858)	GS 35.859 (35.859)	mem 38.890
Train: [75][45/750]	BT 0.085 (1.486)	DT 0.004 (1.438)	loss 7.163 (7.163)	prob 2.130 (2.130)	GS 33.453 (33.453)	mem 38.898
Train: [75][50/750]	BT 13.467 (1.611)	DT 13.423 (1.563)	loss 7.359 (7.359)	prob 2.738 (2.738)	GS 34.188 (34.188)	mem 38.997
Train: [75][55/750]	BT 0.055 (1.468)	DT 0.010 (1.421)	loss 7.886 (7.886)	prob 1.742 (1.742)	GS 31.516 (31.516)	mem 38.999
Train: [75][60/750]	BT 4.156 (1.420)	DT 4.125 (1.372)	loss 7.614 (7.614)	prob 2.155 (2.155)	GS 34.203 (34.203)	mem 38.964
Train: [75][65/750]	BT 0.032 (1.455)	DT 0.001 (1.407)	loss 7.820 (7.820)	prob 1.964 (1.964)	GS 40.141 (40.141)	mem 39.031
Train: [75][70/750]	BT 0.084 (1.356)	DT 0.010 (1.306)	loss 6.968 (6.968)	prob 3.041 (3.041)	GS 35.922 (35.922)	mem 39.032
Train: [75][75/750]	BT 0.053 (1.445)	DT 0.004 (1.395)	loss 7.485 (7.485)	prob 2.698 (2.698)	GS 33.141 (33.141)	mem 39.071
Train: [75][80/750]	BT 0.033 (1.356)	DT 0.002 (1.308)	loss 7.237 (7.237)	prob 2.702 (2.702)	GS 33.641 (33.641)	mem 39.073
Train: [75][85/750]	BT 0.031 (1.308)	DT 0.001 (1.259)	loss 7.400 (7.400)	prob 2.554 (2.554)	GS 30.922 (30.922)	mem 39.014
Train: [75][90/750]	BT 0.035 (1.345)	DT 0.002 (1.297)	loss 7.748 (7.748)	prob 2.145 (2.145)	GS 35.156 (35.156)	mem 39.328
Train: [75][95/750]	BT 0.034 (1.276)	DT 0.001 (1.229)	loss 7.413 (7.413)	prob 2.780 (2.780)	GS 28.219 (28.219)	mem 39.108
Train: [75][100/750]	BT 0.054 (1.357)	DT 0.017 (1.310)	loss 7.446 (7.446)	prob 2.629 (2.629)	GS 36.219 (36.219)	mem 39.058
Train: [75][105/750]	BT 0.037 (1.294)	DT 0.001 (1.248)	loss 7.408 (7.408)	prob 2.588 (2.588)	GS 30.688 (30.688)	mem 39.087
Train: [75][110/750]	BT 4.179 (1.345)	DT 4.145 (1.299)	loss 7.124 (7.124)	prob 2.576 (2.576)	GS 32.453 (32.453)	mem 39.015
Train: [75][115/750]	BT 0.031 (1.300)	DT 0.001 (1.254)	loss 7.102 (7.102)	prob 2.735 (2.735)	GS 31.359 (31.359)	mem 39.092
Train: [75][120/750]	BT 10.065 (1.331)	DT 10.031 (1.286)	loss 7.437 (7.437)	prob 3.062 (3.062)	GS 36.469 (36.469)	mem 39.126
Train: [75][125/750]	BT 0.031 (1.290)	DT 0.001 (1.245)	loss 7.079 (7.079)	prob 2.998 (2.998)	GS 33.297 (33.297)	mem 39.137
Train: [75][130/750]	BT 0.093 (1.243)	DT 0.012 (1.197)	loss 7.348 (7.348)	prob 3.007 (3.007)	GS 31.766 (31.766)	mem 39.131
Train: [75][135/750]	BT 0.078 (1.285)	DT 0.012 (1.239)	loss 7.156 (7.156)	prob 2.631 (2.631)	GS 32.859 (32.859)	mem 39.509
Train: [75][140/750]	BT 0.027 (1.241)	DT 0.001 (1.195)	loss 7.034 (7.034)	prob 2.881 (2.881)	GS 31.172 (31.172)	mem 39.649
Train: [75][145/750]	BT 0.032 (1.284)	DT 0.002 (1.238)	loss 7.499 (7.499)	prob 2.867 (2.867)	GS 31.281 (31.281)	mem 39.482
Train: [75][150/750]	BT 0.071 (1.250)	DT 0.010 (1.204)	loss 7.255 (7.255)	prob 2.370 (2.370)	GS 32.797 (32.797)	mem 39.541
Train: [75][155/750]	BT 0.042 (1.211)	DT 0.001 (1.166)	loss 7.177 (7.177)	prob 2.491 (2.491)	GS 31.734 (31.734)	mem 39.477
Train: [75][160/750]	BT 0.066 (1.248)	DT 0.035 (1.202)	loss 7.678 (7.678)	prob 2.129 (2.129)	GS 33.328 (33.328)	mem 39.481
Train: [75][165/750]	BT 0.056 (1.211)	DT 0.008 (1.165)	loss 7.403 (7.403)	prob 2.341 (2.341)	GS 26.922 (26.922)	mem 39.481
Train: [75][170/750]	BT 0.035 (1.256)	DT 0.002 (1.210)	loss 7.469 (7.469)	prob 2.516 (2.516)	GS 31.562 (31.562)	mem 39.567
Train: [75][175/750]	BT 0.062 (1.222)	DT 0.019 (1.176)	loss 6.970 (6.970)	prob 3.069 (3.069)	GS 29.750 (29.750)	mem 39.717
Train: [75][180/750]	BT 11.205 (1.251)	DT 11.163 (1.206)	loss 7.361 (7.361)	prob 2.834 (2.834)	GS 30.156 (30.156)	mem 39.751
Train: [75][185/750]	BT 0.032 (1.219)	DT 0.001 (1.173)	loss 7.464 (7.464)	prob 2.659 (2.659)	GS 30.141 (30.141)	mem 39.573
Train: [75][190/750]	BT 0.050 (1.204)	DT 0.002 (1.159)	loss 7.162 (7.162)	prob 2.761 (2.761)	GS 32.797 (32.797)	mem 39.514
Train: [75][195/750]	BT 0.033 (1.219)	DT 0.001 (1.174)	loss 7.160 (7.160)	prob 2.313 (2.313)	GS 30.516 (30.516)	mem 39.724
Train: [75][200/750]	BT 0.068 (1.196)	DT 0.001 (1.150)	loss 7.115 (7.115)	prob 3.250 (3.250)	GS 34.109 (34.109)	mem 39.821
Train: [75][205/750]	BT 0.033 (1.229)	DT 0.001 (1.183)	loss 7.487 (7.487)	prob 2.592 (2.592)	GS 30.875 (30.875)	mem 39.944
Train: [75][210/750]	BT 0.094 (1.201)	DT 0.001 (1.155)	loss 7.653 (7.653)	prob 3.037 (3.037)	GS 35.688 (35.688)	mem 39.746
Train: [75][215/750]	BT 0.032 (1.174)	DT 0.001 (1.128)	loss 7.218 (7.218)	prob 3.516 (3.516)	GS 27.562 (27.562)	mem 39.746
Train: [75][220/750]	BT 0.058 (1.219)	DT 0.004 (1.173)	loss 7.229 (7.229)	prob 2.567 (2.567)	GS 32.781 (32.781)	mem 39.943
Train: [75][225/750]	BT 0.027 (1.193)	DT 0.001 (1.147)	loss 7.607 (7.607)	prob 1.959 (1.959)	GS 29.672 (29.672)	mem 39.815
Train: [75][230/750]	BT 0.092 (1.216)	DT 0.061 (1.170)	loss 7.420 (7.420)	prob 2.078 (2.078)	GS 35.562 (35.562)	mem 39.796
Train: [75][235/750]	BT 0.057 (1.191)	DT 0.025 (1.145)	loss 7.189 (7.189)	prob 2.660 (2.660)	GS 33.516 (33.516)	mem 39.798
Train: [75][240/750]	BT 12.929 (1.220)	DT 12.897 (1.175)	loss 7.249 (7.249)	prob 3.704 (3.704)	GS 33.719 (33.719)	mem 39.719
Train: [75][245/750]	BT 0.031 (1.196)	DT 0.001 (1.151)	loss 7.243 (7.243)	prob 2.547 (2.547)	GS 35.188 (35.188)	mem 39.720
Train: [75][250/750]	BT 0.064 (1.173)	DT 0.010 (1.128)	loss 7.165 (7.165)	prob 3.366 (3.366)	GS 34.547 (34.547)	mem 39.747
Train: [75][255/750]	BT 0.066 (1.201)	DT 0.004 (1.156)	loss 7.474 (7.474)	prob 2.055 (2.055)	GS 28.656 (28.656)	mem 39.880
Train: [75][260/750]	BT 0.183 (1.180)	DT 0.057 (1.134)	loss 6.818 (6.818)	prob 3.829 (3.829)	GS 31.266 (31.266)	mem 39.897
Train: [75][265/750]	BT 0.092 (1.206)	DT 0.002 (1.161)	loss 7.041 (7.041)	prob 2.789 (2.789)	GS 31.375 (31.375)	mem 39.800
Train: [75][270/750]	BT 0.034 (1.185)	DT 0.001 (1.140)	loss 7.037 (7.037)	prob 3.386 (3.386)	GS 31.344 (31.344)	mem 39.799
Train: [75][275/750]	BT 0.032 (1.164)	DT 0.002 (1.119)	loss 7.460 (7.460)	prob 2.338 (2.338)	GS 32.125 (32.125)	mem 39.801
Train: [75][280/750]	BT 0.024 (1.197)	DT 0.001 (1.153)	loss 7.172 (7.172)	prob 3.585 (3.585)	GS 31.062 (31.062)	mem 39.643
Train: [75][285/750]	BT 0.104 (1.177)	DT 0.001 (1.132)	loss 7.379 (7.379)	prob 2.743 (2.743)	GS 26.719 (26.719)	mem 39.645
Train: [75][290/750]	BT 0.027 (1.197)	DT 0.001 (1.152)	loss 7.483 (7.483)	prob 3.337 (3.337)	GS 37.891 (37.891)	mem 39.821
Train: [75][295/750]	BT 0.035 (1.177)	DT 0.007 (1.133)	loss 7.366 (7.366)	prob 2.860 (2.860)	GS 28.125 (28.125)	mem 39.938
Train: [75][300/750]	BT 11.090 (1.195)	DT 11.060 (1.151)	loss 7.347 (7.347)	prob 3.041 (3.041)	GS 33.266 (33.266)	mem 39.829
Train: [75][305/750]	BT 0.063 (1.177)	DT 0.001 (1.132)	loss 7.123 (7.123)	prob 2.998 (2.998)	GS 30.625 (30.625)	mem 39.851
Train: [75][310/750]	BT 0.095 (1.158)	DT 0.013 (1.114)	loss 7.107 (7.107)	prob 3.054 (3.054)	GS 31.672 (31.672)	mem 39.870
Train: [75][315/750]	BT 0.031 (1.186)	DT 0.001 (1.141)	loss 7.349 (7.349)	prob 2.754 (2.754)	GS 29.656 (29.656)	mem 39.831
Train: [75][320/750]	BT 0.066 (1.168)	DT 0.002 (1.124)	loss 7.120 (7.120)	prob 2.898 (2.898)	GS 36.125 (36.125)	mem 39.831
Train: [75][325/750]	BT 0.098 (1.190)	DT 0.029 (1.145)	loss 7.242 (7.242)	prob 3.095 (3.095)	GS 31.219 (31.219)	mem 39.977
Train: [75][330/750]	BT 0.095 (1.173)	DT 0.001 (1.128)	loss 7.502 (7.502)	prob 2.798 (2.798)	GS 32.812 (32.812)	mem 39.834
Train: [75][335/750]	BT 0.051 (1.156)	DT 0.002 (1.111)	loss 7.258 (7.258)	prob 3.130 (3.130)	GS 29.031 (29.031)	mem 39.832
Train: [75][340/750]	BT 0.050 (1.176)	DT 0.005 (1.132)	loss 7.708 (7.708)	prob 2.545 (2.545)	GS 31.891 (31.891)	mem 40.016
Train: [75][345/750]	BT 0.063 (1.160)	DT 0.006 (1.115)	loss 7.728 (7.728)	prob 2.188 (2.188)	GS 27.969 (27.969)	mem 39.995
Train: [75][350/750]	BT 0.031 (1.184)	DT 0.001 (1.140)	loss 7.165 (7.165)	prob 1.991 (1.991)	GS 32.266 (32.266)	mem 39.854
Train: [75][355/750]	BT 0.030 (1.168)	DT 0.001 (1.124)	loss 7.402 (7.402)	prob 2.373 (2.373)	GS 30.734 (30.734)	mem 39.857
Train: [75][360/750]	BT 12.812 (1.188)	DT 12.779 (1.144)	loss 7.126 (7.126)	prob 3.439 (3.439)	GS 28.531 (28.531)	mem 39.857
Train: [75][365/750]	BT 0.042 (1.173)	DT 0.004 (1.128)	loss 7.600 (7.600)	prob 3.154 (3.154)	GS 27.875 (27.875)	mem 39.768
Train: [75][370/750]	BT 0.032 (1.158)	DT 0.001 (1.113)	loss 7.237 (7.237)	prob 3.404 (3.404)	GS 36.531 (36.531)	mem 39.768
Train: [75][375/750]	BT 0.059 (1.172)	DT 0.002 (1.128)	loss 7.679 (7.679)	prob 2.525 (2.525)	GS 33.594 (33.594)	mem 39.848
Train: [75][380/750]	BT 0.051 (1.158)	DT 0.006 (1.113)	loss 7.384 (7.384)	prob 3.234 (3.234)	GS 30.938 (30.938)	mem 39.864
Train: [75][385/750]	BT 0.030 (1.173)	DT 0.001 (1.128)	loss 7.101 (7.101)	prob 2.645 (2.645)	GS 32.531 (32.531)	mem 39.733
Train: [75][390/750]	BT 0.080 (1.159)	DT 0.012 (1.113)	loss 7.296 (7.296)	prob 3.661 (3.661)	GS 31.922 (31.922)	mem 39.733
Train: [75][395/750]	BT 0.080 (1.145)	DT 0.006 (1.099)	loss 7.165 (7.165)	prob 2.807 (2.807)	GS 30.031 (30.031)	mem 39.766
Train: [75][400/750]	BT 0.070 (1.169)	DT 0.008 (1.124)	loss 7.146 (7.146)	prob 3.144 (3.144)	GS 31.000 (31.000)	mem 39.850
Train: [75][405/750]	BT 0.036 (1.155)	DT 0.001 (1.110)	loss 7.674 (7.674)	prob 2.095 (2.095)	GS 34.156 (34.156)	mem 39.815
Train: [75][410/750]	BT 0.036 (1.170)	DT 0.002 (1.125)	loss 7.332 (7.332)	prob 2.814 (2.814)	GS 34.484 (34.484)	mem 39.880
Train: [75][415/750]	BT 0.047 (1.157)	DT 0.015 (1.112)	loss 7.261 (7.261)	prob 2.794 (2.794)	GS 34.031 (34.031)	mem 39.820
Train: [75][420/750]	BT 14.387 (1.178)	DT 14.352 (1.133)	loss 7.334 (7.334)	prob 2.732 (2.732)	GS 35.828 (35.828)	mem 39.863
Train: [75][425/750]	BT 0.099 (1.165)	DT 0.002 (1.120)	loss 7.518 (7.518)	prob 2.330 (2.330)	GS 30.984 (30.984)	mem 39.864
Train: [75][430/750]	BT 0.995 (1.154)	DT 0.963 (1.109)	loss 7.010 (7.010)	prob 3.459 (3.459)	GS 37.281 (37.281)	mem 39.792
Train: [75][435/750]	BT 0.032 (1.171)	DT 0.001 (1.126)	loss 7.124 (7.124)	prob 2.946 (2.946)	GS 30.875 (30.875)	mem 39.812
Train: [75][440/750]	BT 0.032 (1.158)	DT 0.001 (1.113)	loss 7.288 (7.288)	prob 2.951 (2.951)	GS 32.734 (32.734)	mem 39.812
Train: [75][445/750]	BT 0.032 (1.179)	DT 0.002 (1.135)	loss 7.623 (7.623)	prob 1.811 (1.811)	GS 32.984 (32.984)	mem 39.780
Train: [75][450/750]	BT 0.035 (1.167)	DT 0.001 (1.122)	loss 7.522 (7.522)	prob 3.215 (3.215)	GS 36.109 (36.109)	mem 39.781
Train: [75][455/750]	BT 0.025 (1.154)	DT 0.001 (1.110)	loss 6.872 (6.872)	prob 3.624 (3.624)	GS 28.500 (28.500)	mem 39.783
Train: [75][460/750]	BT 0.055 (1.172)	DT 0.003 (1.127)	loss 6.874 (6.874)	prob 3.330 (3.330)	GS 29.312 (29.312)	mem 39.883
Train: [75][465/750]	BT 0.096 (1.160)	DT 0.002 (1.115)	loss 7.323 (7.323)	prob 3.290 (3.290)	GS 32.594 (32.594)	mem 39.884
Train: [75][470/750]	BT 0.024 (1.173)	DT 0.001 (1.128)	loss 7.232 (7.232)	prob 3.551 (3.551)	GS 35.875 (35.875)	mem 39.930
Train: [75][475/750]	BT 0.046 (1.161)	DT 0.004 (1.116)	loss 7.262 (7.262)	prob 2.165 (2.165)	GS 29.406 (29.406)	mem 39.931
Train: [75][480/750]	BT 10.083 (1.176)	DT 10.027 (1.131)	loss 7.093 (7.093)	prob 3.442 (3.442)	GS 34.234 (34.234)	mem 39.911
Train: [75][485/750]	BT 0.034 (1.164)	DT 0.001 (1.120)	loss 7.090 (7.090)	prob 2.913 (2.913)	GS 30.141 (30.141)	mem 39.959
Train: [75][490/750]	BT 3.185 (1.159)	DT 3.144 (1.115)	loss 7.119 (7.119)	prob 3.271 (3.271)	GS 35.609 (35.609)	mem 39.982
Train: [75][495/750]	BT 0.034 (1.170)	DT 0.001 (1.125)	loss 7.127 (7.127)	prob 3.133 (3.133)	GS 32.141 (32.141)	mem 39.758
Train: [75][500/750]	BT 0.047 (1.159)	DT 0.008 (1.114)	loss 7.436 (7.436)	prob 2.654 (2.654)	GS 33.875 (33.875)	mem 39.759
Train: [75][505/750]	BT 0.077 (1.172)	DT 0.022 (1.127)	loss 7.372 (7.372)	prob 3.331 (3.331)	GS 31.922 (31.922)	mem 39.839
Train: [75][510/750]	BT 0.032 (1.160)	DT 0.001 (1.116)	loss 7.084 (7.084)	prob 3.144 (3.144)	GS 32.234 (32.234)	mem 39.839
Train: [75][515/750]	BT 0.039 (1.152)	DT 0.009 (1.108)	loss 7.296 (7.296)	prob 3.038 (3.038)	GS 31.625 (31.625)	mem 39.835
Train: [75][520/750]	BT 0.031 (1.161)	DT 0.005 (1.117)	loss 7.129 (7.129)	prob 3.732 (3.732)	GS 35.625 (35.625)	mem 39.833
Train: [75][525/750]	BT 0.041 (1.151)	DT 0.002 (1.107)	loss 7.129 (7.129)	prob 3.253 (3.253)	GS 27.125 (27.125)	mem 39.927
Train: [75][530/750]	BT 0.028 (1.170)	DT 0.001 (1.126)	loss 7.029 (7.029)	prob 2.911 (2.911)	GS 32.844 (32.844)	mem 39.960
Train: [75][535/750]	BT 0.058 (1.163)	DT 0.005 (1.119)	loss 7.585 (7.585)	prob 2.423 (2.423)	GS 49.062 (49.062)	mem 39.806
Train: [75][540/750]	BT 13.072 (1.177)	DT 13.032 (1.133)	loss 7.076 (7.076)	prob 2.951 (2.951)	GS 36.312 (36.312)	mem 39.772
Train: [75][545/750]	BT 0.029 (1.166)	DT 0.001 (1.123)	loss 7.387 (7.387)	prob 2.495 (2.495)	GS 33.422 (33.422)	mem 39.774
Train: [75][550/750]	BT 0.030 (1.156)	DT 0.001 (1.113)	loss 7.074 (7.074)	prob 3.676 (3.676)	GS 33.875 (33.875)	mem 39.785
Train: [75][555/750]	BT 0.047 (1.170)	DT 0.003 (1.126)	loss 7.076 (7.076)	prob 3.707 (3.707)	GS 32.672 (32.672)	mem 39.886
Train: [75][560/750]	BT 0.039 (1.160)	DT 0.009 (1.117)	loss 7.323 (7.323)	prob 3.151 (3.151)	GS 32.547 (32.547)	mem 39.815
Train: [75][565/750]	BT 0.057 (1.167)	DT 0.023 (1.124)	loss 6.810 (6.810)	prob 3.152 (3.152)	GS 27.750 (27.750)	mem 39.994
Train: [75][570/750]	BT 0.032 (1.162)	DT 0.001 (1.118)	loss 6.954 (6.954)	prob 2.830 (2.830)	GS 36.094 (36.094)	mem 39.961
Train: [75][575/750]	BT 0.047 (1.155)	DT 0.008 (1.111)	loss 7.082 (7.082)	prob 2.857 (2.857)	GS 32.859 (32.859)	mem 39.971
Train: [75][580/750]	BT 3.158 (1.168)	DT 3.124 (1.125)	loss 7.112 (7.112)	prob 3.152 (3.152)	GS 35.891 (35.891)	mem 39.929
Train: [75][585/750]	BT 0.047 (1.159)	DT 0.015 (1.115)	loss 7.549 (7.549)	prob 2.623 (2.623)	GS 30.328 (30.328)	mem 39.879
Train: [75][590/750]	BT 0.037 (1.166)	DT 0.001 (1.122)	loss 6.887 (6.887)	prob 3.194 (3.194)	GS 32.109 (32.109)	mem 39.874
Train: [75][595/750]	BT 0.036 (1.157)	DT 0.002 (1.114)	loss 6.962 (6.962)	prob 3.470 (3.470)	GS 32.109 (32.109)	mem 39.844
Train: [75][600/750]	BT 9.715 (1.164)	DT 9.665 (1.121)	loss 6.767 (6.767)	prob 3.549 (3.549)	GS 34.922 (34.922)	mem 39.931
Train: [75][605/750]	BT 0.046 (1.157)	DT 0.001 (1.114)	loss 7.313 (7.313)	prob 2.219 (2.219)	GS 29.141 (29.141)	mem 39.826
Train: [75][610/750]	BT 0.038 (1.148)	DT 0.004 (1.104)	loss 7.056 (7.056)	prob 3.382 (3.382)	GS 34.297 (34.297)	mem 39.827
Train: [75][615/750]	BT 0.031 (1.158)	DT 0.001 (1.114)	loss 6.806 (6.806)	prob 3.450 (3.450)	GS 31.828 (31.828)	mem 39.907
Train: [75][620/750]	BT 0.063 (1.152)	DT 0.009 (1.108)	loss 7.001 (7.001)	prob 2.919 (2.919)	GS 29.719 (29.719)	mem 39.944
Train: [75][625/750]	BT 0.031 (1.161)	DT 0.001 (1.118)	loss 7.360 (7.360)	prob 3.054 (3.054)	GS 33.594 (33.594)	mem 39.913
Train: [75][630/750]	BT 0.032 (1.157)	DT 0.001 (1.114)	loss 7.105 (7.105)	prob 3.346 (3.346)	GS 33.000 (33.000)	mem 39.860
Train: [75][635/750]	BT 0.044 (1.151)	DT 0.010 (1.108)	loss 7.140 (7.140)	prob 2.470 (2.470)	GS 30.578 (30.578)	mem 39.874
Train: [75][640/750]	BT 5.504 (1.162)	DT 5.472 (1.119)	loss 7.037 (7.037)	prob 3.142 (3.142)	GS 32.891 (32.891)	mem 39.918
Train: [75][645/750]	BT 0.032 (1.153)	DT 0.002 (1.110)	loss 7.016 (7.016)	prob 3.112 (3.112)	GS 31.672 (31.672)	mem 39.952
Train: [75][650/750]	BT 0.040 (1.155)	DT 0.002 (1.112)	loss 7.208 (7.208)	prob 3.696 (3.696)	GS 34.984 (34.984)	mem 39.912
Train: [75][655/750]	BT 0.044 (1.154)	DT 0.014 (1.111)	loss 7.381 (7.381)	prob 2.555 (2.555)	GS 38.188 (38.188)	mem 39.838
Train: [75][660/750]	BT 10.396 (1.161)	DT 10.365 (1.118)	loss 7.184 (7.184)	prob 3.367 (3.367)	GS 33.031 (33.031)	mem 39.832
Train: [75][665/750]	BT 0.033 (1.157)	DT 0.001 (1.114)	loss 7.007 (7.007)	prob 3.065 (3.065)	GS 31.469 (31.469)	mem 39.862
Train: [75][670/750]	BT 2.212 (1.152)	DT 2.180 (1.109)	loss 7.136 (7.136)	prob 3.243 (3.243)	GS 38.016 (38.016)	mem 39.746
Train: [75][675/750]	BT 0.049 (1.154)	DT 0.005 (1.111)	loss 7.245 (7.245)	prob 2.433 (2.433)	GS 29.062 (29.062)	mem 39.889
Train: [75][680/750]	BT 0.061 (1.154)	DT 0.002 (1.111)	loss 6.783 (6.783)	prob 3.509 (3.509)	GS 32.219 (32.219)	mem 39.979
Train: [75][685/750]	BT 0.055 (1.154)	DT 0.007 (1.111)	loss 7.435 (7.435)	prob 2.838 (2.838)	GS 29.688 (29.688)	mem 39.930
Train: [75][690/750]	BT 0.062 (1.154)	DT 0.006 (1.111)	loss 6.950 (6.950)	prob 3.030 (3.030)	GS 37.375 (37.375)	mem 39.931
Train: [75][695/750]	BT 0.033 (1.156)	DT 0.002 (1.113)	loss 7.300 (7.300)	prob 2.727 (2.727)	GS 27.594 (27.594)	mem 39.874
Train: [75][700/750]	BT 4.908 (1.156)	DT 4.875 (1.113)	loss 6.905 (6.905)	prob 3.366 (3.366)	GS 34.391 (34.391)	mem 39.925
Train: [75][705/750]	BT 0.034 (1.148)	DT 0.002 (1.105)	loss 7.255 (7.255)	prob 2.926 (2.926)	GS 28.250 (28.250)	mem 39.882
Train: [75][710/750]	BT 0.034 (1.154)	DT 0.001 (1.111)	loss 7.163 (7.163)	prob 2.618 (2.618)	GS 35.328 (35.328)	mem 39.854
Train: [75][715/750]	BT 0.031 (1.151)	DT 0.001 (1.108)	loss 6.853 (6.853)	prob 3.599 (3.599)	GS 30.484 (30.484)	mem 39.926
Train: [75][720/750]	BT 4.512 (1.156)	DT 4.369 (1.113)	loss 7.051 (7.051)	prob 3.007 (3.007)	GS 31.969 (31.969)	mem 39.998
Train: [75][725/750]	BT 0.061 (1.152)	DT 0.004 (1.109)	loss 6.959 (6.959)	prob 3.398 (3.398)	GS 31.516 (31.516)	mem 39.976
Train: [75][730/750]	BT 3.618 (1.150)	DT 3.572 (1.107)	loss 6.916 (6.916)	prob 3.266 (3.266)	GS 34.438 (34.438)	mem 39.898
Train: [75][735/750]	BT 0.038 (1.147)	DT 0.001 (1.104)	loss 7.200 (7.200)	prob 2.844 (2.844)	GS 32.062 (32.062)	mem 39.440
Train: [75][740/750]	BT 0.031 (1.140)	DT 0.002 (1.097)	loss 7.314 (7.314)	prob 2.810 (2.810)	GS 31.391 (31.391)	mem 30.532
Train: [75][745/750]	BT 0.028 (1.139)	DT 0.001 (1.096)	loss 6.886 (6.886)	prob 3.209 (3.209)	GS 32.844 (32.844)	mem 10.647
Train: [75][750/750]	BT 0.020 (1.132)	DT 0.001 (1.089)	loss 7.108 (7.108)	prob 3.114 (3.114)	GS 30.031 (30.031)	mem 10.621
Train: [75][755/750]	BT 0.029 (1.128)	DT 0.001 (1.085)	loss 7.068 (7.068)	prob 2.652 (2.652)	GS 26.062 (26.062)	mem 10.588
epoch 75, total time 852.48
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [76][1/750]	BT 18.825 (18.825)	DT 18.743 (18.743)	loss 7.103 (7.103)	prob 2.575 (2.575)	GS 29.047 (29.047)	mem 38.483
Train: [76][5/750]	BT 0.036 (5.754)	DT 0.004 (5.696)	loss 6.987 (6.987)	prob 2.438 (2.438)	GS 28.734 (28.734)	mem 38.652
Train: [76][10/750]	BT 0.069 (3.300)	DT 0.028 (3.245)	loss 7.082 (7.082)	prob 2.886 (2.886)	GS 34.203 (34.203)	mem 38.708
Train: [76][15/750]	BT 4.529 (3.015)	DT 4.497 (2.959)	loss 6.855 (6.855)	prob 2.702 (2.702)	GS 50.172 (50.172)	mem 38.866
Train: [76][20/750]	BT 0.026 (2.272)	DT 0.001 (2.220)	loss 6.929 (6.929)	prob 2.274 (2.274)	GS 33.781 (33.781)	mem 38.864
Train: [76][25/750]	BT 0.038 (1.829)	DT 0.009 (1.776)	loss 7.111 (7.111)	prob 2.550 (2.550)	GS 34.000 (34.000)	mem 38.865
Train: [76][30/750]	BT 0.051 (1.878)	DT 0.012 (1.826)	loss 6.986 (6.986)	prob 3.278 (3.278)	GS 31.781 (31.781)	mem 38.925
Train: [76][35/750]	BT 0.032 (1.616)	DT 0.001 (1.565)	loss 6.899 (6.899)	prob 2.607 (2.607)	GS 29.281 (29.281)	mem 38.925
Train: [76][40/750]	BT 0.063 (1.794)	DT 0.029 (1.743)	loss 7.021 (7.021)	prob 2.531 (2.531)	GS 36.172 (36.172)	mem 39.009
Train: [76][45/750]	BT 0.053 (1.601)	DT 0.016 (1.551)	loss 7.078 (7.078)	prob 2.057 (2.057)	GS 27.594 (27.594)	mem 39.009
Train: [76][50/750]	BT 11.714 (1.678)	DT 11.683 (1.630)	loss 6.974 (6.974)	prob 2.807 (2.807)	GS 36.328 (36.328)	mem 38.958
Train: [76][55/750]	BT 0.031 (1.528)	DT 0.001 (1.482)	loss 7.098 (7.098)	prob 2.191 (2.191)	GS 31.141 (31.141)	mem 38.957
Train: [76][60/750]	BT 0.059 (1.405)	DT 0.001 (1.358)	loss 7.088 (7.088)	prob 3.029 (3.029)	GS 31.984 (31.984)	mem 39.016
Train: [76][65/750]	BT 0.030 (1.515)	DT 0.001 (1.470)	loss 7.180 (7.180)	prob 2.518 (2.518)	GS 32.938 (32.938)	mem 38.916
Train: [76][70/750]	BT 0.039 (1.411)	DT 0.003 (1.365)	loss 6.835 (6.835)	prob 2.775 (2.775)	GS 31.484 (31.484)	mem 38.918
Train: [76][75/750]	BT 0.119 (1.480)	DT 0.013 (1.435)	loss 6.890 (6.890)	prob 3.081 (3.081)	GS 35.984 (35.984)	mem 39.089
Train: [76][80/750]	BT 0.031 (1.390)	DT 0.001 (1.345)	loss 7.136 (7.136)	prob 2.401 (2.401)	GS 33.266 (33.266)	mem 39.035
Train: [76][85/750]	BT 0.025 (1.318)	DT 0.001 (1.273)	loss 7.086 (7.086)	prob 2.546 (2.546)	GS 31.219 (31.219)	mem 39.060
Train: [76][90/750]	BT 0.051 (1.373)	DT 0.014 (1.329)	loss 6.805 (6.805)	prob 2.714 (2.714)	GS 31.234 (31.234)	mem 39.195
Train: [76][95/750]	BT 0.138 (1.304)	DT 0.014 (1.259)	loss 7.040 (7.040)	prob 2.753 (2.753)	GS 31.156 (31.156)	mem 39.252
Train: [76][100/750]	BT 0.039 (1.365)	DT 0.002 (1.321)	loss 6.861 (6.861)	prob 2.849 (2.849)	GS 35.266 (35.266)	mem 39.416
Train: [76][105/750]	BT 0.050 (1.303)	DT 0.017 (1.258)	loss 6.999 (6.999)	prob 2.331 (2.331)	GS 31.484 (31.484)	mem 39.499
Train: [76][110/750]	BT 12.388 (1.373)	DT 12.363 (1.329)	loss 7.070 (7.070)	prob 2.655 (2.655)	GS 35.750 (35.750)	mem 39.342
Train: [76][115/750]	BT 0.032 (1.315)	DT 0.001 (1.272)	loss 6.978 (6.978)	prob 2.836 (2.836)	GS 35.141 (35.141)	mem 39.387
Train: [76][120/750]	BT 0.041 (1.263)	DT 0.005 (1.219)	loss 7.057 (7.057)	prob 2.626 (2.626)	GS 31.219 (31.219)	mem 39.387
Train: [76][125/750]	BT 0.051 (1.317)	DT 0.002 (1.274)	loss 6.860 (6.860)	prob 3.048 (3.048)	GS 30.578 (30.578)	mem 39.488
Train: [76][130/750]	BT 0.072 (1.269)	DT 0.006 (1.225)	loss 7.122 (7.122)	prob 2.798 (2.798)	GS 35.047 (35.047)	mem 39.302
Train: [76][135/750]	BT 0.024 (1.319)	DT 0.001 (1.275)	loss 7.025 (7.025)	prob 3.054 (3.054)	GS 28.594 (28.594)	mem 39.904
Train: [76][140/750]	BT 0.041 (1.273)	DT 0.001 (1.229)	loss 7.059 (7.059)	prob 3.276 (3.276)	GS 31.766 (31.766)	mem 39.771
Train: [76][145/750]	BT 0.030 (1.230)	DT 0.001 (1.187)	loss 7.011 (7.011)	prob 2.893 (2.893)	GS 30.406 (30.406)	mem 39.688
Train: [76][150/750]	BT 0.081 (1.263)	DT 0.004 (1.219)	loss 7.095 (7.095)	prob 2.785 (2.785)	GS 33.953 (33.953)	mem 39.774
Train: [76][155/750]	BT 0.063 (1.224)	DT 0.001 (1.180)	loss 7.221 (7.221)	prob 2.594 (2.594)	GS 32.641 (32.641)	mem 39.701
Train: [76][160/750]	BT 0.024 (1.270)	DT 0.001 (1.227)	loss 6.874 (6.874)	prob 2.855 (2.855)	GS 35.812 (35.812)	mem 39.719
Train: [76][165/750]	BT 0.088 (1.233)	DT 0.018 (1.190)	loss 7.283 (7.283)	prob 2.157 (2.157)	GS 29.531 (29.531)	mem 39.708
Train: [76][170/750]	BT 11.180 (1.265)	DT 11.148 (1.221)	loss 7.149 (7.149)	prob 2.646 (2.646)	GS 34.422 (34.422)	mem 39.713
Train: [76][175/750]	BT 0.022 (1.229)	DT 0.001 (1.187)	loss 7.292 (7.292)	prob 2.366 (2.366)	GS 30.359 (30.359)	mem 39.713
Train: [76][180/750]	BT 0.033 (1.197)	DT 0.001 (1.154)	loss 7.278 (7.278)	prob 1.951 (1.951)	GS 34.484 (34.484)	mem 39.713
Train: [76][185/750]	BT 0.066 (1.235)	DT 0.002 (1.192)	loss 7.082 (7.082)	prob 2.701 (2.701)	GS 34.906 (34.906)	mem 39.789
Train: [76][190/750]	BT 0.032 (1.203)	DT 0.002 (1.160)	loss 7.126 (7.126)	prob 2.570 (2.570)	GS 32.453 (32.453)	mem 39.736
Train: [76][195/750]	BT 0.036 (1.249)	DT 0.001 (1.207)	loss 7.279 (7.279)	prob 2.675 (2.675)	GS 30.062 (30.062)	mem 39.817
Train: [76][200/750]	BT 0.030 (1.219)	DT 0.001 (1.177)	loss 7.017 (7.017)	prob 2.945 (2.945)	GS 37.484 (37.484)	mem 39.752
Train: [76][205/750]	BT 0.060 (1.190)	DT 0.002 (1.148)	loss 7.092 (7.092)	prob 2.892 (2.892)	GS 31.734 (31.734)	mem 39.717
Train: [76][210/750]	BT 0.048 (1.222)	DT 0.003 (1.180)	loss 7.097 (7.097)	prob 2.838 (2.838)	GS 31.266 (31.266)	mem 40.073
Train: [76][215/750]	BT 0.031 (1.194)	DT 0.001 (1.152)	loss 6.814 (6.814)	prob 2.969 (2.969)	GS 28.484 (28.484)	mem 39.732
Train: [76][220/750]	BT 0.029 (1.216)	DT 0.001 (1.174)	loss 7.118 (7.118)	prob 3.508 (3.508)	GS 36.938 (36.938)	mem 39.811
Train: [76][225/750]	BT 0.058 (1.190)	DT 0.003 (1.148)	loss 6.916 (6.916)	prob 3.225 (3.225)	GS 29.375 (29.375)	mem 39.856
Train: [76][230/750]	BT 12.245 (1.218)	DT 12.216 (1.176)	loss 6.955 (6.955)	prob 2.863 (2.863)	GS 34.297 (34.297)	mem 39.777
Train: [76][235/750]	BT 0.031 (1.194)	DT 0.001 (1.151)	loss 6.948 (6.948)	prob 3.141 (3.141)	GS 29.484 (29.484)	mem 39.778
Train: [76][240/750]	BT 2.011 (1.178)	DT 1.978 (1.136)	loss 7.220 (7.220)	prob 2.550 (2.550)	GS 31.781 (31.781)	mem 39.792
Train: [76][245/750]	BT 0.056 (1.184)	DT 0.001 (1.141)	loss 7.088 (7.088)	prob 2.690 (2.690)	GS 35.875 (35.875)	mem 39.838
Train: [76][250/750]	BT 0.064 (1.161)	DT 0.014 (1.118)	loss 7.398 (7.398)	prob 2.596 (2.596)	GS 33.422 (33.422)	mem 39.808
Train: [76][255/750]	BT 0.037 (1.198)	DT 0.001 (1.155)	loss 7.146 (7.146)	prob 2.374 (2.374)	GS 30.391 (30.391)	mem 39.784
Train: [76][260/750]	BT 0.033 (1.176)	DT 0.006 (1.133)	loss 6.957 (6.957)	prob 3.113 (3.113)	GS 35.000 (35.000)	mem 39.706
Train: [76][265/750]	BT 0.036 (1.177)	DT 0.001 (1.135)	loss 7.097 (7.097)	prob 2.270 (2.270)	GS 36.641 (36.641)	mem 39.740
Train: [76][270/750]	BT 0.032 (1.201)	DT 0.002 (1.158)	loss 7.004 (7.004)	prob 2.246 (2.246)	GS 35.875 (35.875)	mem 39.835
Train: [76][275/750]	BT 0.026 (1.180)	DT 0.001 (1.137)	loss 7.377 (7.377)	prob 2.671 (2.671)	GS 30.719 (30.719)	mem 39.836
Train: [76][280/750]	BT 0.025 (1.209)	DT 0.001 (1.167)	loss 6.888 (6.888)	prob 3.523 (3.523)	GS 35.031 (35.031)	mem 39.857
Train: [76][285/750]	BT 0.035 (1.189)	DT 0.001 (1.146)	loss 7.271 (7.271)	prob 2.469 (2.469)	GS 39.578 (39.578)	mem 39.857
Train: [76][290/750]	BT 11.509 (1.208)	DT 11.478 (1.166)	loss 6.805 (6.805)	prob 3.089 (3.089)	GS 34.234 (34.234)	mem 39.933
Train: [76][295/750]	BT 0.023 (1.189)	DT 0.001 (1.147)	loss 7.044 (7.044)	prob 2.248 (2.248)	GS 31.641 (31.641)	mem 39.908
Train: [76][300/750]	BT 2.780 (1.179)	DT 2.754 (1.137)	loss 6.835 (6.835)	prob 3.302 (3.302)	GS 34.641 (34.641)	mem 39.912
Train: [76][305/750]	BT 0.048 (1.185)	DT 0.017 (1.143)	loss 7.192 (7.192)	prob 2.964 (2.964)	GS 28.266 (28.266)	mem 39.922
Train: [76][310/750]	BT 0.037 (1.167)	DT 0.001 (1.125)	loss 6.956 (6.956)	prob 2.599 (2.599)	GS 37.422 (37.422)	mem 40.012
Train: [76][315/750]	BT 0.042 (1.191)	DT 0.006 (1.149)	loss 7.280 (7.280)	prob 3.327 (3.327)	GS 34.250 (34.250)	mem 39.897
Train: [76][320/750]	BT 0.080 (1.174)	DT 0.001 (1.132)	loss 7.057 (7.057)	prob 2.762 (2.762)	GS 28.766 (28.766)	mem 39.985
Train: [76][325/750]	BT 0.076 (1.168)	DT 0.001 (1.125)	loss 7.131 (7.131)	prob 3.243 (3.243)	GS 35.875 (35.875)	mem 39.825
Train: [76][330/750]	BT 0.031 (1.182)	DT 0.001 (1.140)	loss 7.209 (7.209)	prob 2.523 (2.523)	GS 32.141 (32.141)	mem 39.863
Train: [76][335/750]	BT 0.063 (1.165)	DT 0.006 (1.123)	loss 7.286 (7.286)	prob 2.747 (2.747)	GS 31.500 (31.500)	mem 39.863
Train: [76][340/750]	BT 0.031 (1.189)	DT 0.002 (1.147)	loss 7.015 (7.015)	prob 2.270 (2.270)	GS 33.109 (33.109)	mem 39.874
Train: [76][345/750]	BT 0.102 (1.172)	DT 0.011 (1.130)	loss 6.981 (6.981)	prob 2.779 (2.779)	GS 32.172 (32.172)	mem 39.874
Train: [76][350/750]	BT 13.003 (1.193)	DT 12.969 (1.151)	loss 7.109 (7.109)	prob 2.994 (2.994)	GS 35.203 (35.203)	mem 39.931
Train: [76][355/750]	BT 0.032 (1.177)	DT 0.001 (1.135)	loss 7.110 (7.110)	prob 2.416 (2.416)	GS 29.219 (29.219)	mem 39.984
Train: [76][360/750]	BT 0.110 (1.162)	DT 0.001 (1.119)	loss 7.023 (7.023)	prob 3.358 (3.358)	GS 30.688 (30.688)	mem 39.901
Train: [76][365/750]	BT 0.035 (1.190)	DT 0.001 (1.147)	loss 7.165 (7.165)	prob 2.729 (2.729)	GS 31.062 (31.062)	mem 39.858
Train: [76][370/750]	BT 0.033 (1.174)	DT 0.001 (1.132)	loss 6.888 (6.888)	prob 2.556 (2.556)	GS 33.047 (33.047)	mem 39.789
Train: [76][375/750]	BT 0.030 (1.191)	DT 0.001 (1.149)	loss 7.138 (7.138)	prob 2.703 (2.703)	GS 29.844 (29.844)	mem 39.856
Train: [76][380/750]	BT 0.045 (1.176)	DT 0.002 (1.134)	loss 6.921 (6.921)	prob 2.498 (2.498)	GS 36.031 (36.031)	mem 39.930
Train: [76][385/750]	BT 0.042 (1.161)	DT 0.012 (1.119)	loss 7.056 (7.056)	prob 3.122 (3.122)	GS 36.719 (36.719)	mem 39.859
Train: [76][390/750]	BT 0.021 (1.177)	DT 0.001 (1.135)	loss 7.118 (7.118)	prob 3.098 (3.098)	GS 33.375 (33.375)	mem 39.911
Train: [76][395/750]	BT 0.078 (1.163)	DT 0.008 (1.121)	loss 7.167 (7.167)	prob 3.246 (3.246)	GS 30.266 (30.266)	mem 39.912
Train: [76][400/750]	BT 0.074 (1.178)	DT 0.006 (1.136)	loss 7.057 (7.057)	prob 3.143 (3.143)	GS 32.766 (32.766)	mem 40.250
Train: [76][405/750]	BT 0.043 (1.164)	DT 0.001 (1.122)	loss 7.423 (7.423)	prob 2.388 (2.388)	GS 31.453 (31.453)	mem 39.907
Train: [76][410/750]	BT 9.199 (1.173)	DT 9.168 (1.130)	loss 7.105 (7.105)	prob 3.341 (3.341)	GS 30.578 (30.578)	mem 39.881
Train: [76][415/750]	BT 0.107 (1.159)	DT 0.004 (1.117)	loss 6.993 (6.993)	prob 2.952 (2.952)	GS 26.312 (26.312)	mem 39.889
Train: [76][420/750]	BT 0.215 (1.146)	DT 0.180 (1.104)	loss 7.003 (7.003)	prob 2.032 (2.032)	GS 33.969 (33.969)	mem 39.835
Train: [76][425/750]	BT 0.048 (1.160)	DT 0.007 (1.118)	loss 6.993 (6.993)	prob 3.147 (3.147)	GS 33.484 (33.484)	mem 39.861
Train: [76][430/750]	BT 0.032 (1.147)	DT 0.001 (1.105)	loss 7.335 (7.335)	prob 2.551 (2.551)	GS 35.531 (35.531)	mem 39.898
Train: [76][435/750]	BT 0.031 (1.161)	DT 0.002 (1.119)	loss 7.026 (7.026)	prob 3.131 (3.131)	GS 28.250 (28.250)	mem 39.956
Train: [76][440/750]	BT 0.031 (1.148)	DT 0.002 (1.106)	loss 6.951 (6.951)	prob 2.791 (2.791)	GS 32.688 (32.688)	mem 39.958
Train: [76][445/750]	BT 0.049 (1.152)	DT 0.002 (1.110)	loss 7.249 (7.249)	prob 2.679 (2.679)	GS 31.016 (31.016)	mem 39.972
Train: [76][450/750]	BT 0.032 (1.146)	DT 0.002 (1.104)	loss 7.139 (7.139)	prob 3.198 (3.198)	GS 31.156 (31.156)	mem 39.910
Train: [76][455/750]	BT 0.051 (1.137)	DT 0.013 (1.095)	loss 7.067 (7.067)	prob 3.133 (3.133)	GS 32.094 (32.094)	mem 39.949
Train: [76][460/750]	BT 2.719 (1.152)	DT 2.680 (1.110)	loss 7.021 (7.021)	prob 2.685 (2.685)	GS 37.891 (37.891)	mem 40.003
Train: [76][465/750]	BT 0.064 (1.140)	DT 0.026 (1.098)	loss 6.936 (6.936)	prob 2.694 (2.694)	GS 32.547 (32.547)	mem 39.968
Train: [76][470/750]	BT 0.050 (1.150)	DT 0.003 (1.107)	loss 6.983 (6.983)	prob 2.839 (2.839)	GS 31.250 (31.250)	mem 39.916
Train: [76][475/750]	BT 0.031 (1.149)	DT 0.001 (1.107)	loss 7.103 (7.103)	prob 2.971 (2.971)	GS 31.734 (31.734)	mem 39.933
Train: [76][480/750]	BT 6.552 (1.152)	DT 6.522 (1.109)	loss 6.929 (6.929)	prob 2.753 (2.753)	GS 34.438 (34.438)	mem 39.926
Train: [76][485/750]	BT 0.059 (1.152)	DT 0.015 (1.110)	loss 7.073 (7.073)	prob 2.920 (2.920)	GS 34.047 (34.047)	mem 39.949
Train: [76][490/750]	BT 0.130 (1.141)	DT 0.012 (1.098)	loss 6.878 (6.878)	prob 2.892 (2.892)	GS 35.969 (35.969)	mem 40.231
Train: [76][495/750]	BT 0.050 (1.145)	DT 0.011 (1.103)	loss 6.993 (6.993)	prob 2.785 (2.785)	GS 30.344 (30.344)	mem 40.018
Train: [76][500/750]	BT 0.058 (1.141)	DT 0.005 (1.098)	loss 7.344 (7.344)	prob 2.375 (2.375)	GS 33.594 (33.594)	mem 40.088
Train: [76][505/750]	BT 0.046 (1.148)	DT 0.003 (1.105)	loss 7.139 (7.139)	prob 2.794 (2.794)	GS 32.016 (32.016)	mem 39.878
Train: [76][510/750]	BT 0.032 (1.146)	DT 0.002 (1.103)	loss 7.294 (7.294)	prob 2.766 (2.766)	GS 32.578 (32.578)	mem 39.942
Train: [76][515/750]	BT 0.085 (1.136)	DT 0.007 (1.093)	loss 7.134 (7.134)	prob 3.561 (3.561)	GS 33.250 (33.250)	mem 39.928
Train: [76][520/750]	BT 3.439 (1.153)	DT 3.377 (1.111)	loss 6.973 (6.973)	prob 2.801 (2.801)	GS 35.750 (35.750)	mem 40.017
Train: [76][525/750]	BT 0.032 (1.143)	DT 0.001 (1.100)	loss 7.178 (7.178)	prob 2.689 (2.689)	GS 31.844 (31.844)	mem 39.964
Train: [76][530/750]	BT 4.122 (1.156)	DT 4.093 (1.113)	loss 7.266 (7.266)	prob 2.596 (2.596)	GS 34.406 (34.406)	mem 40.047
Train: [76][535/750]	BT 0.075 (1.153)	DT 0.004 (1.110)	loss 6.856 (6.856)	prob 3.600 (3.600)	GS 32.188 (32.188)	mem 40.051
Train: [76][540/750]	BT 0.679 (1.144)	DT 0.640 (1.101)	loss 6.958 (6.958)	prob 3.070 (3.070)	GS 35.266 (35.266)	mem 40.051
Train: [76][545/750]	BT 0.072 (1.151)	DT 0.020 (1.108)	loss 7.127 (7.127)	prob 2.581 (2.581)	GS 30.531 (30.531)	mem 40.044
Train: [76][550/750]	BT 0.133 (1.142)	DT 0.006 (1.098)	loss 7.119 (7.119)	prob 3.164 (3.164)	GS 33.641 (33.641)	mem 40.312
Train: [76][555/750]	BT 0.105 (1.146)	DT 0.002 (1.103)	loss 6.980 (6.980)	prob 3.098 (3.098)	GS 32.250 (32.250)	mem 40.110
Train: [76][560/750]	BT 0.116 (1.144)	DT 0.013 (1.100)	loss 6.881 (6.881)	prob 3.495 (3.495)	GS 33.891 (33.891)	mem 40.020
Train: [76][565/750]	BT 0.077 (1.140)	DT 0.002 (1.097)	loss 7.175 (7.175)	prob 2.357 (2.357)	GS 29.969 (29.969)	mem 40.036
Train: [76][570/750]	BT 0.057 (1.145)	DT 0.006 (1.101)	loss 7.077 (7.077)	prob 2.591 (2.591)	GS 36.344 (36.344)	mem 39.993
Train: [76][575/750]	BT 0.034 (1.136)	DT 0.002 (1.092)	loss 7.090 (7.090)	prob 2.727 (2.727)	GS 30.516 (30.516)	mem 39.961
Train: [76][580/750]	BT 7.220 (1.147)	DT 7.179 (1.103)	loss 7.014 (7.014)	prob 2.904 (2.904)	GS 33.203 (33.203)	mem 40.406
Train: [76][585/750]	BT 0.041 (1.137)	DT 0.002 (1.094)	loss 7.226 (7.226)	prob 2.693 (2.693)	GS 31.172 (31.172)	mem 40.030
Train: [76][590/750]	BT 4.023 (1.140)	DT 3.939 (1.096)	loss 6.860 (6.860)	prob 2.683 (2.683)	GS 34.156 (34.156)	mem 40.054
Train: [76][595/750]	BT 0.038 (1.141)	DT 0.002 (1.097)	loss 7.125 (7.125)	prob 2.877 (2.877)	GS 35.562 (35.562)	mem 40.891
Train: [76][600/750]	BT 3.470 (1.138)	DT 3.426 (1.094)	loss 6.995 (6.995)	prob 3.160 (3.160)	GS 37.188 (37.188)	mem 40.006
Train: [76][605/750]	BT 0.067 (1.144)	DT 0.009 (1.100)	loss 7.406 (7.406)	prob 2.329 (2.329)	GS 46.016 (46.016)	mem 39.983
Train: [76][610/750]	BT 0.032 (1.135)	DT 0.001 (1.091)	loss 6.933 (6.933)	prob 3.891 (3.891)	GS 33.000 (33.000)	mem 39.939
Train: [76][615/750]	BT 0.031 (1.145)	DT 0.001 (1.101)	loss 7.067 (7.067)	prob 2.721 (2.721)	GS 32.469 (32.469)	mem 39.994
Train: [76][620/750]	BT 0.032 (1.136)	DT 0.001 (1.092)	loss 7.002 (7.002)	prob 3.075 (3.075)	GS 37.250 (37.250)	mem 39.996
Train: [76][625/750]	BT 0.096 (1.132)	DT 0.002 (1.088)	loss 7.091 (7.091)	prob 2.454 (2.454)	GS 31.734 (31.734)	mem 39.983
Train: [76][630/750]	BT 0.055 (1.133)	DT 0.001 (1.089)	loss 6.995 (6.995)	prob 2.405 (2.405)	GS 31.531 (31.531)	mem 40.076
Train: [76][635/750]	BT 0.035 (1.126)	DT 0.002 (1.083)	loss 7.000 (7.000)	prob 2.328 (2.328)	GS 30.531 (30.531)	mem 40.046
Train: [76][640/750]	BT 0.034 (1.135)	DT 0.001 (1.091)	loss 6.895 (6.895)	prob 2.375 (2.375)	GS 33.453 (33.453)	mem 39.956
Train: [76][645/750]	BT 0.054 (1.126)	DT 0.016 (1.083)	loss 7.030 (7.030)	prob 3.116 (3.116)	GS 28.281 (28.281)	mem 39.996
Train: [76][650/750]	BT 4.899 (1.135)	DT 4.843 (1.091)	loss 7.002 (7.002)	prob 2.003 (2.003)	GS 32.250 (32.250)	mem 40.049
Train: [76][655/750]	BT 0.030 (1.130)	DT 0.001 (1.086)	loss 7.123 (7.123)	prob 2.751 (2.751)	GS 27.828 (27.828)	mem 39.885
arpack error, retry= 0
Train: [76][660/750]	BT 9.427 (1.136)	DT 9.341 (1.092)	loss 6.816 (6.816)	prob 3.124 (3.124)	GS 35.109 (35.109)	mem 39.950
Train: [76][665/750]	BT 0.034 (1.137)	DT 0.002 (1.093)	loss 6.836 (6.836)	prob 3.030 (3.030)	GS 29.625 (29.625)	mem 40.022
Train: [76][670/750]	BT 0.049 (1.129)	DT 0.002 (1.085)	loss 6.988 (6.988)	prob 3.121 (3.121)	GS 30.438 (30.438)	mem 39.865
Train: [76][675/750]	BT 0.031 (1.144)	DT 0.001 (1.100)	loss 7.059 (7.059)	prob 2.511 (2.511)	GS 31.469 (31.469)	mem 39.914
Train: [76][680/750]	BT 0.032 (1.136)	DT 0.001 (1.092)	loss 7.128 (7.128)	prob 2.509 (2.509)	GS 31.484 (31.484)	mem 39.915
Train: [76][685/750]	BT 0.142 (1.133)	DT 0.026 (1.089)	loss 6.847 (6.847)	prob 2.773 (2.773)	GS 30.703 (30.703)	mem 39.875
Train: [76][690/750]	BT 0.032 (1.138)	DT 0.001 (1.094)	loss 7.133 (7.133)	prob 2.309 (2.309)	GS 32.562 (32.562)	mem 39.919
Train: [76][695/750]	BT 0.133 (1.130)	DT 0.005 (1.086)	loss 7.014 (7.014)	prob 2.256 (2.256)	GS 31.688 (31.688)	mem 40.099
Train: [76][700/750]	BT 0.048 (1.140)	DT 0.005 (1.096)	loss 6.951 (6.951)	prob 3.432 (3.432)	GS 30.406 (30.406)	mem 39.844
Train: [76][705/750]	BT 0.077 (1.133)	DT 0.005 (1.088)	loss 6.998 (6.998)	prob 3.526 (3.526)	GS 31.109 (31.109)	mem 39.910
Train: [76][710/750]	BT 6.730 (1.140)	DT 6.699 (1.095)	loss 6.969 (6.969)	prob 2.649 (2.649)	GS 32.297 (32.297)	mem 39.813
Train: [76][715/750]	BT 0.037 (1.134)	DT 0.002 (1.089)	loss 6.933 (6.933)	prob 3.055 (3.055)	GS 30.312 (30.312)	mem 39.813
Train: [76][720/750]	BT 4.261 (1.132)	DT 4.228 (1.088)	loss 7.015 (7.015)	prob 2.974 (2.974)	GS 34.938 (34.938)	mem 39.928
Train: [76][725/750]	BT 0.046 (1.136)	DT 0.008 (1.091)	loss 6.876 (6.876)	prob 3.145 (3.145)	GS 31.484 (31.484)	mem 39.890
Train: [76][730/750]	BT 0.035 (1.128)	DT 0.002 (1.084)	loss 7.040 (7.040)	prob 2.997 (2.997)	GS 30.797 (30.797)	mem 39.959
Train: [76][735/750]	BT 0.055 (1.135)	DT 0.003 (1.091)	loss 7.052 (7.052)	prob 2.935 (2.935)	GS 28.844 (28.844)	mem 36.650
Train: [76][740/750]	BT 0.023 (1.129)	DT 0.001 (1.084)	loss 6.959 (6.959)	prob 2.727 (2.727)	GS 35.484 (35.484)	mem 13.540
Train: [76][745/750]	BT 0.056 (1.124)	DT 0.010 (1.079)	loss 6.910 (6.910)	prob 3.405 (3.405)	GS 26.375 (26.375)	mem 13.538
Train: [76][750/750]	BT 0.020 (1.118)	DT 0.001 (1.074)	loss 7.146 (7.146)	prob 2.694 (2.694)	GS 27.562 (27.562)	mem 10.534
Train: [76][755/750]	BT 0.026 (1.111)	DT 0.001 (1.067)	loss 6.962 (6.962)	prob 2.678 (2.678)	GS 56.719 (56.719)	mem 10.534
epoch 76, total time 839.71
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [77][1/750]	BT 31.319 (31.319)	DT 31.222 (31.222)	loss 6.871 (6.871)	prob 2.137 (2.137)	GS 48.031 (48.031)	mem 39.023
Train: [77][5/750]	BT 0.037 (6.302)	DT 0.003 (6.248)	loss 6.868 (6.868)	prob 3.132 (3.132)	GS 30.750 (30.750)	mem 38.756
Train: [77][10/750]	BT 0.043 (3.177)	DT 0.004 (3.126)	loss 6.809 (6.809)	prob 3.226 (3.226)	GS 34.469 (34.469)	mem 38.809
Train: [77][15/750]	BT 0.071 (2.778)	DT 0.006 (2.721)	loss 6.916 (6.916)	prob 3.365 (3.365)	GS 26.078 (26.078)	mem 39.053
Train: [77][20/750]	BT 0.080 (2.101)	DT 0.013 (2.043)	loss 6.947 (6.947)	prob 3.742 (3.742)	GS 35.703 (35.703)	mem 38.812
Train: [77][25/750]	BT 10.044 (2.096)	DT 9.952 (2.033)	loss 6.893 (6.893)	prob 3.530 (3.530)	GS 29.062 (29.062)	mem 38.908
Train: [77][30/750]	BT 0.029 (1.916)	DT 0.006 (1.855)	loss 6.936 (6.936)	prob 2.762 (2.762)	GS 37.984 (37.984)	mem 38.960
Train: [77][35/750]	BT 0.063 (1.712)	DT 0.016 (1.655)	loss 7.076 (7.076)	prob 3.093 (3.093)	GS 29.250 (29.250)	mem 38.968
Train: [77][40/750]	BT 7.169 (1.791)	DT 7.127 (1.734)	loss 7.015 (7.015)	prob 3.117 (3.117)	GS 36.406 (36.406)	mem 39.078
Train: [77][45/750]	BT 0.075 (1.666)	DT 0.029 (1.610)	loss 7.199 (7.199)	prob 2.724 (2.724)	GS 29.438 (29.438)	mem 38.917
Train: [77][50/750]	BT 0.042 (1.517)	DT 0.002 (1.462)	loss 7.150 (7.150)	prob 2.975 (2.975)	GS 30.375 (30.375)	mem 39.200
Train: [77][55/750]	BT 0.035 (1.588)	DT 0.005 (1.535)	loss 6.904 (6.904)	prob 2.914 (2.914)	GS 30.953 (30.953)	mem 39.243
Train: [77][60/750]	BT 0.100 (1.462)	DT 0.002 (1.408)	loss 6.855 (6.855)	prob 2.752 (2.752)	GS 32.641 (32.641)	mem 39.286
Train: [77][65/750]	BT 0.089 (1.522)	DT 0.002 (1.468)	loss 7.096 (7.096)	prob 2.336 (2.336)	GS 30.438 (30.438)	mem 39.532
Train: [77][70/750]	BT 0.026 (1.469)	DT 0.001 (1.417)	loss 7.081 (7.081)	prob 2.992 (2.992)	GS 30.797 (30.797)	mem 39.357
Train: [77][75/750]	BT 0.048 (1.376)	DT 0.010 (1.323)	loss 6.894 (6.894)	prob 2.761 (2.761)	GS 36.359 (36.359)	mem 39.359
Train: [77][80/750]	BT 0.041 (1.475)	DT 0.001 (1.423)	loss 6.892 (6.892)	prob 2.971 (2.971)	GS 31.734 (31.734)	mem 39.732
Train: [77][85/750]	BT 0.024 (1.392)	DT 0.001 (1.339)	loss 6.862 (6.862)	prob 3.045 (3.045)	GS 32.125 (32.125)	mem 39.566
Train: [77][90/750]	BT 3.732 (1.451)	DT 3.698 (1.398)	loss 6.914 (6.914)	prob 3.375 (3.375)	GS 35.234 (35.234)	mem 39.642
Train: [77][95/750]	BT 0.043 (1.377)	DT 0.003 (1.325)	loss 6.906 (6.906)	prob 3.154 (3.154)	GS 33.875 (33.875)	mem 39.644
Train: [77][100/750]	BT 7.807 (1.394)	DT 7.733 (1.342)	loss 7.001 (7.001)	prob 3.455 (3.455)	GS 35.125 (35.125)	mem 39.688
Train: [77][105/750]	BT 0.031 (1.380)	DT 0.002 (1.328)	loss 6.845 (6.845)	prob 3.210 (3.210)	GS 36.062 (36.062)	mem 39.743
Train: [77][110/750]	BT 0.065 (1.320)	DT 0.026 (1.268)	loss 7.171 (7.171)	prob 3.274 (3.274)	GS 30.094 (30.094)	mem 39.706
Train: [77][115/750]	BT 0.026 (1.347)	DT 0.001 (1.295)	loss 6.952 (6.952)	prob 2.722 (2.722)	GS 31.703 (31.703)	mem 39.787
Train: [77][120/750]	BT 0.023 (1.339)	DT 0.001 (1.287)	loss 6.978 (6.978)	prob 3.563 (3.563)	GS 34.188 (34.188)	mem 39.643
Train: [77][125/750]	BT 0.091 (1.301)	DT 0.004 (1.249)	loss 6.853 (6.853)	prob 3.540 (3.540)	GS 32.375 (32.375)	mem 39.810
Train: [77][130/750]	BT 0.035 (1.324)	DT 0.002 (1.272)	loss 7.104 (7.104)	prob 3.244 (3.244)	GS 33.344 (33.344)	mem 39.994
Train: [77][135/750]	BT 0.077 (1.286)	DT 0.008 (1.233)	loss 6.967 (6.967)	prob 3.276 (3.276)	GS 29.047 (29.047)	mem 39.818
Train: [77][140/750]	BT 8.183 (1.322)	DT 8.074 (1.268)	loss 7.197 (7.197)	prob 2.721 (2.721)	GS 34.172 (34.172)	mem 39.722
Train: [77][145/750]	BT 0.035 (1.278)	DT 0.002 (1.225)	loss 6.786 (6.786)	prob 2.838 (2.838)	GS 32.203 (32.203)	mem 39.724
Train: [77][150/750]	BT 1.245 (1.281)	DT 1.207 (1.228)	loss 7.110 (7.110)	prob 2.941 (2.941)	GS 36.016 (36.016)	mem 39.737
Train: [77][155/750]	BT 0.032 (1.260)	DT 0.002 (1.208)	loss 6.949 (6.949)	prob 3.399 (3.399)	GS 31.469 (31.469)	mem 39.814
Train: [77][160/750]	BT 4.393 (1.277)	DT 4.352 (1.225)	loss 6.789 (6.789)	prob 3.473 (3.473)	GS 33.094 (33.094)	mem 39.735
Train: [77][165/750]	BT 0.023 (1.285)	DT 0.001 (1.234)	loss 7.298 (7.298)	prob 2.999 (2.999)	GS 35.375 (35.375)	mem 39.778
Train: [77][170/750]	BT 0.024 (1.248)	DT 0.001 (1.197)	loss 7.155 (7.155)	prob 3.338 (3.338)	GS 32.297 (32.297)	mem 39.776
Train: [77][175/750]	BT 0.066 (1.240)	DT 0.008 (1.189)	loss 6.890 (6.890)	prob 2.872 (2.872)	GS 33.359 (33.359)	mem 39.781
Train: [77][180/750]	BT 0.033 (1.255)	DT 0.002 (1.204)	loss 7.173 (7.173)	prob 2.609 (2.609)	GS 38.172 (38.172)	mem 39.744
Train: [77][185/750]	BT 0.032 (1.241)	DT 0.002 (1.191)	loss 7.069 (7.069)	prob 2.991 (2.991)	GS 30.703 (30.703)	mem 39.804
Train: [77][190/750]	BT 0.100 (1.239)	DT 0.009 (1.189)	loss 6.954 (6.954)	prob 3.518 (3.518)	GS 35.359 (35.359)	mem 39.830
Train: [77][195/750]	BT 0.031 (1.208)	DT 0.001 (1.159)	loss 7.097 (7.097)	prob 3.199 (3.199)	GS 29.922 (29.922)	mem 39.789
Train: [77][200/750]	BT 4.539 (1.237)	DT 4.462 (1.188)	loss 7.108 (7.108)	prob 3.004 (3.004)	GS 31.875 (31.875)	mem 39.944
Train: [77][205/750]	BT 0.059 (1.209)	DT 0.027 (1.159)	loss 7.318 (7.318)	prob 2.468 (2.468)	GS 28.906 (28.906)	mem 39.824
Train: [77][210/750]	BT 0.279 (1.214)	DT 0.211 (1.164)	loss 6.957 (6.957)	prob 2.974 (2.974)	GS 35.000 (35.000)	mem 39.838
Train: [77][215/750]	BT 0.025 (1.213)	DT 0.001 (1.163)	loss 7.217 (7.217)	prob 2.737 (2.737)	GS 33.562 (33.562)	mem 39.835
Train: [77][220/750]	BT 4.587 (1.214)	DT 4.532 (1.165)	loss 7.112 (7.112)	prob 2.131 (2.131)	GS 37.516 (37.516)	mem 39.848
Train: [77][225/750]	BT 0.093 (1.232)	DT 0.002 (1.182)	loss 7.050 (7.050)	prob 3.069 (3.069)	GS 32.828 (32.828)	mem 39.811
Train: [77][230/750]	BT 0.036 (1.207)	DT 0.002 (1.157)	loss 7.000 (7.000)	prob 3.317 (3.317)	GS 29.359 (29.359)	mem 39.810
Train: [77][235/750]	BT 0.045 (1.193)	DT 0.001 (1.143)	loss 7.146 (7.146)	prob 2.560 (2.560)	GS 42.438 (42.438)	mem 39.843
Train: [77][240/750]	BT 0.025 (1.217)	DT 0.001 (1.168)	loss 6.934 (6.934)	prob 2.989 (2.989)	GS 34.922 (34.922)	mem 39.772
Train: [77][245/750]	BT 0.043 (1.199)	DT 0.003 (1.150)	loss 7.117 (7.117)	prob 2.635 (2.635)	GS 32.469 (32.469)	mem 39.889
Train: [77][250/750]	BT 0.058 (1.227)	DT 0.001 (1.178)	loss 7.006 (7.006)	prob 3.003 (3.003)	GS 36.359 (36.359)	mem 40.131
Train: [77][255/750]	BT 0.065 (1.204)	DT 0.001 (1.155)	loss 6.875 (6.875)	prob 2.837 (2.837)	GS 29.406 (29.406)	mem 39.865
Train: [77][260/750]	BT 12.600 (1.233)	DT 12.570 (1.184)	loss 7.155 (7.155)	prob 2.618 (2.618)	GS 33.609 (33.609)	mem 39.944
Train: [77][265/750]	BT 0.078 (1.211)	DT 0.006 (1.162)	loss 6.971 (6.971)	prob 2.703 (2.703)	GS 32.828 (32.828)	mem 39.945
Train: [77][270/750]	BT 0.033 (1.189)	DT 0.003 (1.141)	loss 7.411 (7.411)	prob 2.602 (2.602)	GS 33.344 (33.344)	mem 39.947
Train: [77][275/750]	BT 0.029 (1.208)	DT 0.001 (1.160)	loss 6.929 (6.929)	prob 3.864 (3.864)	GS 33.219 (33.219)	mem 39.916
Train: [77][280/750]	BT 0.092 (1.196)	DT 0.004 (1.148)	loss 6.759 (6.759)	prob 3.146 (3.146)	GS 36.266 (36.266)	mem 39.969
Train: [77][285/750]	BT 0.031 (1.212)	DT 0.001 (1.164)	loss 6.983 (6.983)	prob 3.475 (3.475)	GS 33.375 (33.375)	mem 39.902
Train: [77][290/750]	BT 1.329 (1.196)	DT 1.265 (1.148)	loss 7.231 (7.231)	prob 3.382 (3.382)	GS 32.219 (32.219)	mem 39.840
Train: [77][295/750]	BT 0.093 (1.177)	DT 0.002 (1.129)	loss 6.958 (6.958)	prob 3.322 (3.322)	GS 31.906 (31.906)	mem 39.848
Train: [77][300/750]	BT 0.035 (1.198)	DT 0.002 (1.150)	loss 7.107 (7.107)	prob 3.546 (3.546)	GS 33.656 (33.656)	mem 39.780
Train: [77][305/750]	BT 0.033 (1.180)	DT 0.002 (1.132)	loss 7.239 (7.239)	prob 3.002 (3.002)	GS 30.766 (30.766)	mem 39.716
Train: [77][310/750]	BT 6.631 (1.214)	DT 6.580 (1.167)	loss 6.970 (6.970)	prob 3.339 (3.339)	GS 37.484 (37.484)	mem 39.861
Train: [77][315/750]	BT 0.061 (1.196)	DT 0.002 (1.148)	loss 6.991 (6.991)	prob 2.982 (2.982)	GS 28.891 (28.891)	mem 39.861
Train: [77][320/750]	BT 5.606 (1.195)	DT 5.545 (1.148)	loss 7.032 (7.032)	prob 3.341 (3.341)	GS 34.469 (34.469)	mem 39.955
Train: [77][325/750]	BT 0.037 (1.196)	DT 0.001 (1.149)	loss 6.914 (6.914)	prob 3.223 (3.223)	GS 30.484 (30.484)	mem 39.872
Train: [77][330/750]	BT 0.054 (1.179)	DT 0.004 (1.132)	loss 6.915 (6.915)	prob 3.201 (3.201)	GS 33.625 (33.625)	mem 39.874
Train: [77][335/750]	BT 0.031 (1.197)	DT 0.001 (1.150)	loss 6.986 (6.986)	prob 2.783 (2.783)	GS 34.734 (34.734)	mem 39.791
Train: [77][340/750]	BT 0.066 (1.187)	DT 0.034 (1.140)	loss 7.140 (7.140)	prob 3.355 (3.355)	GS 40.125 (40.125)	mem 39.733
Train: [77][345/750]	BT 0.107 (1.186)	DT 0.016 (1.139)	loss 7.058 (7.058)	prob 3.212 (3.212)	GS 32.891 (32.891)	mem 39.885
Train: [77][350/750]	BT 2.281 (1.195)	DT 2.256 (1.148)	loss 7.114 (7.114)	prob 2.632 (2.632)	GS 33.594 (33.594)	mem 39.855
Train: [77][355/750]	BT 0.045 (1.179)	DT 0.002 (1.132)	loss 7.063 (7.063)	prob 2.997 (2.997)	GS 29.281 (29.281)	mem 39.857
Train: [77][360/750]	BT 0.050 (1.188)	DT 0.002 (1.140)	loss 6.880 (6.880)	prob 3.257 (3.257)	GS 32.609 (32.609)	mem 39.971
Train: [77][365/750]	BT 0.042 (1.183)	DT 0.012 (1.136)	loss 7.030 (7.030)	prob 2.890 (2.890)	GS 30.656 (30.656)	mem 39.963
Train: [77][370/750]	BT 8.930 (1.191)	DT 8.896 (1.144)	loss 6.938 (6.938)	prob 2.800 (2.800)	GS 32.656 (32.656)	mem 39.936
Train: [77][375/750]	BT 0.053 (1.190)	DT 0.013 (1.143)	loss 7.048 (7.048)	prob 2.402 (2.402)	GS 28.797 (28.797)	mem 39.885
Train: [77][380/750]	BT 0.325 (1.176)	DT 0.248 (1.129)	loss 6.996 (6.996)	prob 2.605 (2.605)	GS 33.109 (33.109)	mem 39.864
Train: [77][385/750]	BT 0.034 (1.171)	DT 0.002 (1.124)	loss 7.256 (7.256)	prob 2.383 (2.383)	GS 28.719 (28.719)	mem 40.130
Train: [77][390/750]	BT 0.027 (1.180)	DT 0.001 (1.133)	loss 7.049 (7.049)	prob 2.841 (2.841)	GS 31.625 (31.625)	mem 39.903
Train: [77][395/750]	BT 0.048 (1.167)	DT 0.009 (1.120)	loss 7.009 (7.009)	prob 2.786 (2.786)	GS 31.297 (31.297)	mem 39.911
Train: [77][400/750]	BT 0.034 (1.187)	DT 0.002 (1.140)	loss 7.122 (7.122)	prob 3.095 (3.095)	GS 34.047 (34.047)	mem 40.044
Train: [77][405/750]	BT 0.044 (1.176)	DT 0.007 (1.129)	loss 7.012 (7.012)	prob 2.441 (2.441)	GS 32.750 (32.750)	mem 39.870
Train: [77][410/750]	BT 10.705 (1.188)	DT 10.669 (1.141)	loss 7.190 (7.190)	prob 2.117 (2.117)	GS 34.328 (34.328)	mem 40.008
Train: [77][415/750]	BT 0.028 (1.175)	DT 0.001 (1.128)	loss 6.839 (6.839)	prob 2.952 (2.952)	GS 29.766 (29.766)	mem 39.961
Train: [77][420/750]	BT 0.031 (1.171)	DT 0.001 (1.125)	loss 6.826 (6.826)	prob 2.916 (2.916)	GS 32.906 (32.906)	mem 39.727
Train: [77][425/750]	BT 0.049 (1.185)	DT 0.009 (1.139)	loss 7.283 (7.283)	prob 2.553 (2.553)	GS 25.859 (25.859)	mem 39.901
Train: [77][430/750]	BT 2.104 (1.181)	DT 2.071 (1.134)	loss 7.212 (7.212)	prob 3.027 (3.027)	GS 33.109 (33.109)	mem 39.938
Train: [77][435/750]	BT 0.046 (1.182)	DT 0.005 (1.136)	loss 7.103 (7.103)	prob 2.960 (2.960)	GS 34.328 (34.328)	mem 39.933
Train: [77][440/750]	BT 3.547 (1.183)	DT 3.512 (1.137)	loss 7.147 (7.147)	prob 2.353 (2.353)	GS 34.797 (34.797)	mem 39.885
Train: [77][445/750]	BT 0.065 (1.171)	DT 0.005 (1.124)	loss 7.438 (7.438)	prob 2.166 (2.166)	GS 36.609 (36.609)	mem 39.893
Train: [77][450/750]	BT 0.039 (1.178)	DT 0.002 (1.132)	loss 6.880 (6.880)	prob 2.879 (2.879)	GS 34.016 (34.016)	mem 40.353
Train: [77][455/750]	BT 0.032 (1.175)	DT 0.001 (1.128)	loss 7.037 (7.037)	prob 2.902 (2.902)	GS 29.203 (29.203)	mem 39.949
Train: [77][460/750]	BT 2.648 (1.182)	DT 2.607 (1.136)	loss 7.113 (7.113)	prob 2.201 (2.201)	GS 32.125 (32.125)	mem 39.858
Train: [77][465/750]	BT 0.046 (1.187)	DT 0.002 (1.141)	loss 7.165 (7.165)	prob 3.010 (3.010)	GS 37.500 (37.500)	mem 39.952
Train: [77][470/750]	BT 3.100 (1.181)	DT 3.033 (1.135)	loss 6.951 (6.951)	prob 2.670 (2.670)	GS 31.109 (31.109)	mem 39.738
Train: [77][475/750]	BT 0.064 (1.171)	DT 0.004 (1.124)	loss 6.968 (6.968)	prob 2.923 (2.923)	GS 32.922 (32.922)	mem 39.711
Train: [77][480/750]	BT 0.037 (1.174)	DT 0.004 (1.128)	loss 6.903 (6.903)	prob 2.840 (2.840)	GS 28.375 (28.375)	mem 39.828
Train: [77][485/750]	BT 0.055 (1.182)	DT 0.013 (1.136)	loss 7.118 (7.118)	prob 2.563 (2.563)	GS 32.344 (32.344)	mem 39.784
Train: [77][490/750]	BT 0.056 (1.177)	DT 0.005 (1.130)	loss 7.185 (7.185)	prob 2.415 (2.415)	GS 35.641 (35.641)	mem 39.864
Train: [77][495/750]	BT 0.032 (1.180)	DT 0.002 (1.134)	loss 7.112 (7.112)	prob 2.706 (2.706)	GS 30.766 (30.766)	mem 39.833
Train: [77][500/750]	BT 3.159 (1.185)	DT 3.098 (1.139)	loss 7.047 (7.047)	prob 3.051 (3.051)	GS 35.750 (35.750)	mem 39.846
Train: [77][505/750]	BT 0.032 (1.174)	DT 0.001 (1.128)	loss 6.813 (6.813)	prob 3.466 (3.466)	GS 28.984 (28.984)	mem 39.815
Train: [77][510/750]	BT 0.031 (1.176)	DT 0.001 (1.130)	loss 7.082 (7.082)	prob 2.848 (2.848)	GS 31.766 (31.766)	mem 39.860
Train: [77][515/750]	BT 0.031 (1.186)	DT 0.001 (1.140)	loss 6.992 (6.992)	prob 3.006 (3.006)	GS 27.656 (27.656)	mem 39.933
Train: [77][520/750]	BT 1.111 (1.178)	DT 1.066 (1.132)	loss 7.103 (7.103)	prob 3.183 (3.183)	GS 33.016 (33.016)	mem 39.918
Train: [77][525/750]	BT 0.065 (1.189)	DT 0.002 (1.142)	loss 7.144 (7.144)	prob 3.032 (3.032)	GS 35.781 (35.781)	mem 39.945
Train: [77][530/750]	BT 1.785 (1.181)	DT 1.752 (1.135)	loss 7.020 (7.020)	prob 3.087 (3.087)	GS 37.000 (37.000)	mem 39.834
Train: [77][535/750]	BT 0.057 (1.170)	DT 0.004 (1.124)	loss 7.079 (7.079)	prob 2.691 (2.691)	GS 25.078 (25.078)	mem 39.871
Train: [77][540/750]	BT 0.092 (1.178)	DT 0.007 (1.132)	loss 7.000 (7.000)	prob 3.156 (3.156)	GS 29.969 (29.969)	mem 39.940
Train: [77][545/750]	BT 0.063 (1.180)	DT 0.012 (1.134)	loss 6.958 (6.958)	prob 2.902 (2.902)	GS 28.859 (28.859)	mem 39.817
Train: [77][550/750]	BT 0.024 (1.179)	DT 0.001 (1.133)	loss 6.949 (6.949)	prob 2.854 (2.854)	GS 34.453 (34.453)	mem 39.903
Train: [77][555/750]	BT 0.026 (1.186)	DT 0.001 (1.140)	loss 7.028 (7.028)	prob 2.324 (2.324)	GS 33.297 (33.297)	mem 39.793
Train: [77][560/750]	BT 0.911 (1.178)	DT 0.880 (1.132)	loss 6.809 (6.809)	prob 2.915 (2.915)	GS 33.781 (33.781)	mem 39.786
Train: [77][565/750]	BT 0.086 (1.167)	DT 0.005 (1.122)	loss 6.967 (6.967)	prob 2.741 (2.741)	GS 35.469 (35.469)	mem 39.824
Train: [77][570/750]	BT 0.047 (1.179)	DT 0.001 (1.133)	loss 7.085 (7.085)	prob 2.450 (2.450)	GS 35.281 (35.281)	mem 39.848
Train: [77][575/750]	BT 0.084 (1.170)	DT 0.001 (1.124)	loss 6.991 (6.991)	prob 2.967 (2.967)	GS 29.609 (29.609)	mem 39.902
Train: [77][580/750]	BT 0.021 (1.183)	DT 0.001 (1.137)	loss 6.845 (6.845)	prob 3.389 (3.389)	GS 35.219 (35.219)	mem 39.907
Train: [77][585/750]	BT 0.049 (1.174)	DT 0.002 (1.128)	loss 7.223 (7.223)	prob 2.947 (2.947)	GS 29.922 (29.922)	mem 39.908
Train: [77][590/750]	BT 13.999 (1.188)	DT 13.913 (1.142)	loss 6.735 (6.735)	prob 2.966 (2.966)	GS 31.375 (31.375)	mem 39.914
Train: [77][595/750]	BT 0.043 (1.178)	DT 0.001 (1.133)	loss 7.065 (7.065)	prob 2.545 (2.545)	GS 33.344 (33.344)	mem 39.914
Train: [77][600/750]	BT 0.066 (1.173)	DT 0.001 (1.127)	loss 7.024 (7.024)	prob 2.757 (2.757)	GS 34.062 (34.062)	mem 40.003
Train: [77][605/750]	BT 0.035 (1.180)	DT 0.001 (1.134)	loss 6.870 (6.870)	prob 2.982 (2.982)	GS 33.297 (33.297)	mem 39.959
Train: [77][610/750]	BT 0.085 (1.178)	DT 0.002 (1.132)	loss 6.931 (6.931)	prob 3.317 (3.317)	GS 34.844 (34.844)	mem 39.685
Train: [77][615/750]	BT 0.027 (1.180)	DT 0.001 (1.135)	loss 7.011 (7.011)	prob 3.243 (3.243)	GS 32.953 (32.953)	mem 40.012
Train: [77][620/750]	BT 1.212 (1.179)	DT 1.179 (1.133)	loss 6.957 (6.957)	prob 2.852 (2.852)	GS 30.766 (30.766)	mem 39.876
Train: [77][625/750]	BT 0.033 (1.170)	DT 0.002 (1.124)	loss 6.943 (6.943)	prob 3.147 (3.147)	GS 35.766 (35.766)	mem 39.953
Train: [77][630/750]	BT 0.036 (1.180)	DT 0.001 (1.135)	loss 7.021 (7.021)	prob 2.644 (2.644)	GS 30.812 (30.812)	mem 39.960
Train: [77][635/750]	BT 0.033 (1.180)	DT 0.009 (1.134)	loss 6.789 (6.789)	prob 2.957 (2.957)	GS 24.516 (24.516)	mem 39.855
Train: [77][640/750]	BT 9.592 (1.186)	DT 9.519 (1.140)	loss 6.865 (6.865)	prob 2.960 (2.960)	GS 32.219 (32.219)	mem 39.984
Train: [77][645/750]	BT 0.028 (1.182)	DT 0.001 (1.137)	loss 6.873 (6.873)	prob 3.044 (3.044)	GS 29.812 (29.812)	mem 39.926
Train: [77][650/750]	BT 0.027 (1.174)	DT 0.001 (1.128)	loss 7.019 (7.019)	prob 1.997 (1.997)	GS 34.109 (34.109)	mem 39.849
Train: [77][655/750]	BT 0.117 (1.174)	DT 0.028 (1.129)	loss 7.001 (7.001)	prob 3.162 (3.162)	GS 32.297 (32.297)	mem 39.976
arpack error, retry= 0
Train: [77][660/750]	BT 0.061 (1.170)	DT 0.026 (1.125)	loss 6.967 (6.967)	prob 2.731 (2.731)	GS 33.078 (33.078)	mem 39.971
Train: [77][665/750]	BT 0.034 (1.175)	DT 0.002 (1.130)	loss 7.347 (7.347)	prob 2.070 (2.070)	GS 35.703 (35.703)	mem 40.188
Train: [77][670/750]	BT 0.026 (1.173)	DT 0.001 (1.128)	loss 7.011 (7.011)	prob 2.736 (2.736)	GS 34.031 (34.031)	mem 39.946
Train: [77][675/750]	BT 0.032 (1.172)	DT 0.002 (1.127)	loss 6.918 (6.918)	prob 2.897 (2.897)	GS 27.719 (27.719)	mem 39.861
Train: [77][680/750]	BT 2.551 (1.172)	DT 2.516 (1.127)	loss 6.929 (6.929)	prob 3.193 (3.193)	GS 35.672 (35.672)	mem 40.170
Train: [77][685/750]	BT 0.039 (1.164)	DT 0.001 (1.119)	loss 7.089 (7.089)	prob 2.499 (2.499)	GS 33.297 (33.297)	mem 39.889
Train: [77][690/750]	BT 0.092 (1.171)	DT 0.022 (1.126)	loss 6.872 (6.872)	prob 2.841 (2.841)	GS 34.672 (34.672)	mem 39.941
Train: [77][695/750]	BT 0.052 (1.165)	DT 0.012 (1.120)	loss 6.879 (6.879)	prob 3.065 (3.065)	GS 30.625 (30.625)	mem 40.095
Train: [77][700/750]	BT 8.032 (1.176)	DT 7.970 (1.131)	loss 6.984 (6.984)	prob 2.626 (2.626)	GS 35.094 (35.094)	mem 39.973
Train: [77][705/750]	BT 0.096 (1.169)	DT 0.023 (1.123)	loss 6.937 (6.937)	prob 3.114 (3.114)	GS 29.344 (29.344)	mem 40.048
Train: [77][710/750]	BT 2.044 (1.164)	DT 1.976 (1.118)	loss 6.979 (6.979)	prob 3.075 (3.075)	GS 30.812 (30.812)	mem 39.965
Train: [77][715/750]	BT 0.031 (1.171)	DT 0.001 (1.126)	loss 6.949 (6.949)	prob 3.088 (3.088)	GS 32.812 (32.812)	mem 39.857
Train: [77][720/750]	BT 0.029 (1.166)	DT 0.004 (1.120)	loss 6.998 (6.998)	prob 2.903 (2.903)	GS 35.906 (35.906)	mem 39.884
Train: [77][725/750]	BT 0.027 (1.170)	DT 0.001 (1.125)	loss 7.105 (7.105)	prob 3.157 (3.157)	GS 28.797 (28.797)	mem 39.768
Train: [77][730/750]	BT 0.036 (1.163)	DT 0.002 (1.118)	loss 7.078 (7.078)	prob 2.117 (2.117)	GS 33.719 (33.719)	mem 39.780
Train: [77][735/750]	BT 0.046 (1.162)	DT 0.002 (1.116)	loss 7.008 (7.008)	prob 2.870 (2.870)	GS 32.641 (32.641)	mem 36.802
Train: [77][740/750]	BT 0.030 (1.161)	DT 0.001 (1.116)	loss 6.834 (6.834)	prob 2.902 (2.902)	GS 34.812 (34.812)	mem 16.479
Train: [77][745/750]	BT 0.077 (1.154)	DT 0.013 (1.108)	loss 7.706 (7.706)	prob 2.268 (2.268)	GS 33.125 (33.125)	mem 16.481
Train: [77][750/750]	BT 0.045 (1.150)	DT 0.002 (1.105)	loss 7.161 (7.161)	prob 2.639 (2.639)	GS 33.125 (33.125)	mem 10.555
Train: [77][755/750]	BT 0.018 (1.143)	DT 0.001 (1.098)	loss 6.972 (6.972)	prob 2.113 (2.113)	GS 33.656 (33.656)	mem 7.584
epoch 77, total time 863.08
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [78][1/750]	BT 21.160 (21.160)	DT 21.110 (21.110)	loss 7.257 (7.257)	prob 2.834 (2.834)	GS 28.891 (28.891)	mem 38.519
Train: [78][5/750]	BT 0.141 (4.472)	DT 0.097 (4.417)	loss 6.726 (6.726)	prob 3.230 (3.230)	GS 29.172 (29.172)	mem 38.557
Train: [78][10/750]	BT 0.056 (2.499)	DT 0.003 (2.441)	loss 6.727 (6.727)	prob 3.448 (3.448)	GS 31.844 (31.844)	mem 38.651
Train: [78][15/750]	BT 0.052 (2.475)	DT 0.009 (2.411)	loss 6.974 (6.974)	prob 2.737 (2.737)	GS 35.406 (35.406)	mem 38.803
Train: [78][20/750]	BT 0.083 (1.871)	DT 0.005 (1.810)	loss 6.704 (6.704)	prob 3.536 (3.536)	GS 32.984 (32.984)	mem 38.638
Train: [78][25/750]	BT 6.792 (1.773)	DT 6.754 (1.718)	loss 6.759 (6.759)	prob 3.009 (3.009)	GS 33.250 (33.250)	mem 38.959
Train: [78][30/750]	BT 0.047 (1.701)	DT 0.001 (1.649)	loss 6.970 (6.970)	prob 3.268 (3.268)	GS 34.172 (34.172)	mem 39.112
Train: [78][35/750]	BT 0.036 (1.479)	DT 0.003 (1.426)	loss 6.967 (6.967)	prob 3.465 (3.465)	GS 31.219 (31.219)	mem 39.270
Train: [78][40/750]	BT 0.048 (1.686)	DT 0.002 (1.634)	loss 6.799 (6.799)	prob 3.263 (3.263)	GS 37.156 (37.156)	mem 39.577
Train: [78][45/750]	BT 0.028 (1.506)	DT 0.001 (1.453)	loss 6.823 (6.823)	prob 3.179 (3.179)	GS 28.516 (28.516)	mem 39.518
Train: [78][50/750]	BT 10.481 (1.571)	DT 10.444 (1.518)	loss 6.983 (6.983)	prob 2.791 (2.791)	GS 31.953 (31.953)	mem 39.554
Train: [78][55/750]	BT 0.051 (1.434)	DT 0.002 (1.380)	loss 7.525 (7.525)	prob 1.547 (1.547)	GS 34.516 (34.516)	mem 39.610
Train: [78][60/750]	BT 0.044 (1.352)	DT 0.002 (1.299)	loss 7.109 (7.109)	prob 3.068 (3.068)	GS 35.500 (35.500)	mem 39.583
Train: [78][65/750]	BT 0.039 (1.462)	DT 0.002 (1.410)	loss 7.053 (7.053)	prob 2.504 (2.504)	GS 30.000 (30.000)	mem 39.614
Train: [78][70/750]	BT 1.578 (1.382)	DT 1.497 (1.331)	loss 6.777 (6.777)	prob 3.830 (3.830)	GS 35.953 (35.953)	mem 39.613
Train: [78][75/750]	BT 0.035 (1.433)	DT 0.002 (1.383)	loss 6.882 (6.882)	prob 3.357 (3.357)	GS 29.984 (29.984)	mem 39.654
Train: [78][80/750]	BT 0.089 (1.356)	DT 0.004 (1.305)	loss 7.207 (7.207)	prob 2.957 (2.957)	GS 30.047 (30.047)	mem 39.670
Train: [78][85/750]	BT 0.078 (1.313)	DT 0.011 (1.263)	loss 7.079 (7.079)	prob 3.040 (3.040)	GS 31.016 (31.016)	mem 39.676
Train: [78][90/750]	BT 0.026 (1.372)	DT 0.001 (1.323)	loss 7.122 (7.122)	prob 3.407 (3.407)	GS 31.953 (31.953)	mem 39.698
Train: [78][95/750]	BT 0.161 (1.304)	DT 0.023 (1.254)	loss 7.012 (7.012)	prob 3.524 (3.524)	GS 31.891 (31.891)	mem 39.731
Train: [78][100/750]	BT 0.032 (1.396)	DT 0.001 (1.347)	loss 7.051 (7.051)	prob 2.947 (2.947)	GS 36.484 (36.484)	mem 39.663
Train: [78][105/750]	BT 0.042 (1.331)	DT 0.001 (1.283)	loss 6.882 (6.882)	prob 2.888 (2.888)	GS 27.625 (27.625)	mem 39.663
Train: [78][110/750]	BT 13.863 (1.399)	DT 13.833 (1.351)	loss 6.924 (6.924)	prob 2.906 (2.906)	GS 41.703 (41.703)	mem 39.761
Train: [78][115/750]	BT 0.036 (1.340)	DT 0.001 (1.292)	loss 7.113 (7.113)	prob 3.033 (3.033)	GS 34.094 (34.094)	mem 39.725
Train: [78][120/750]	BT 0.039 (1.286)	DT 0.001 (1.239)	loss 7.162 (7.162)	prob 2.469 (2.469)	GS 35.062 (35.062)	mem 39.725
Train: [78][125/750]	BT 0.025 (1.351)	DT 0.001 (1.304)	loss 7.124 (7.124)	prob 3.247 (3.247)	GS 30.125 (30.125)	mem 39.755
Train: [78][130/750]	BT 0.030 (1.300)	DT 0.001 (1.254)	loss 7.067 (7.067)	prob 2.977 (2.977)	GS 35.984 (35.984)	mem 39.756
Train: [78][135/750]	BT 0.039 (1.336)	DT 0.006 (1.290)	loss 7.146 (7.146)	prob 2.470 (2.470)	GS 29.516 (29.516)	mem 39.732
Train: [78][140/750]	BT 0.048 (1.289)	DT 0.005 (1.244)	loss 6.967 (6.967)	prob 3.305 (3.305)	GS 28.797 (28.797)	mem 39.761
Train: [78][145/750]	BT 0.088 (1.248)	DT 0.006 (1.201)	loss 7.047 (7.047)	prob 2.390 (2.390)	GS 30.828 (30.828)	mem 39.779
Train: [78][150/750]	BT 0.063 (1.298)	DT 0.029 (1.252)	loss 7.024 (7.024)	prob 2.319 (2.319)	GS 32.125 (32.125)	mem 39.840
Train: [78][155/750]	BT 0.052 (1.258)	DT 0.001 (1.212)	loss 6.898 (6.898)	prob 2.589 (2.589)	GS 33.734 (33.734)	mem 40.222
Train: [78][160/750]	BT 0.033 (1.277)	DT 0.002 (1.231)	loss 6.849 (6.849)	prob 2.115 (2.115)	GS 31.875 (31.875)	mem 39.825
Train: [78][165/750]	BT 0.034 (1.239)	DT 0.002 (1.193)	loss 6.868 (6.868)	prob 3.206 (3.206)	GS 31.453 (31.453)	mem 39.825
Train: [78][170/750]	BT 13.892 (1.286)	DT 13.860 (1.240)	loss 7.030 (7.030)	prob 2.831 (2.831)	GS 32.375 (32.375)	mem 39.899
Train: [78][175/750]	BT 0.085 (1.250)	DT 0.001 (1.205)	loss 7.025 (7.025)	prob 3.065 (3.065)	GS 30.234 (30.234)	mem 40.102
Train: [78][180/750]	BT 0.061 (1.217)	DT 0.002 (1.171)	loss 7.028 (7.028)	prob 1.716 (1.716)	GS 32.766 (32.766)	mem 40.210
Train: [78][185/750]	BT 0.055 (1.247)	DT 0.016 (1.201)	loss 6.842 (6.842)	prob 3.211 (3.211)	GS 33.062 (33.062)	mem 39.921
Train: [78][190/750]	BT 0.061 (1.225)	DT 0.004 (1.179)	loss 7.064 (7.064)	prob 3.154 (3.154)	GS 34.344 (34.344)	mem 40.206
Train: [78][195/750]	BT 0.025 (1.268)	DT 0.002 (1.221)	loss 7.011 (7.011)	prob 2.899 (2.899)	GS 35.344 (35.344)	mem 39.917
Train: [78][200/750]	BT 0.045 (1.237)	DT 0.019 (1.191)	loss 6.985 (6.985)	prob 3.134 (3.134)	GS 35.859 (35.859)	mem 39.839
Train: [78][205/750]	BT 0.067 (1.212)	DT 0.017 (1.165)	loss 6.795 (6.795)	prob 3.012 (3.012)	GS 34.641 (34.641)	mem 39.877
Train: [78][210/750]	BT 0.042 (1.254)	DT 0.012 (1.208)	loss 7.098 (7.098)	prob 2.312 (2.312)	GS 32.453 (32.453)	mem 39.998
Train: [78][215/750]	BT 0.042 (1.226)	DT 0.001 (1.180)	loss 7.241 (7.241)	prob 2.310 (2.310)	GS 30.062 (30.062)	mem 40.148
Train: [78][220/750]	BT 0.048 (1.255)	DT 0.002 (1.209)	loss 7.209 (7.209)	prob 2.661 (2.661)	GS 33.906 (33.906)	mem 40.069
Train: [78][225/750]	BT 0.028 (1.232)	DT 0.006 (1.187)	loss 6.951 (6.951)	prob 3.076 (3.076)	GS 29.719 (29.719)	mem 39.861
Train: [78][230/750]	BT 13.269 (1.264)	DT 13.182 (1.218)	loss 7.066 (7.066)	prob 2.701 (2.701)	GS 32.312 (32.312)	mem 39.849
Train: [78][235/750]	BT 0.041 (1.238)	DT 0.002 (1.193)	loss 7.124 (7.124)	prob 2.517 (2.517)	GS 30.781 (30.781)	mem 39.871
Train: [78][240/750]	BT 0.033 (1.213)	DT 0.001 (1.168)	loss 6.830 (6.830)	prob 2.927 (2.927)	GS 33.719 (33.719)	mem 39.947
Train: [78][245/750]	BT 0.031 (1.247)	DT 0.001 (1.202)	loss 7.362 (7.362)	prob 2.417 (2.417)	GS 28.828 (28.828)	mem 39.849
Train: [78][250/750]	BT 0.051 (1.223)	DT 0.004 (1.178)	loss 6.903 (6.903)	prob 2.596 (2.596)	GS 32.750 (32.750)	mem 39.850
Train: [78][255/750]	BT 0.048 (1.247)	DT 0.005 (1.201)	loss 6.947 (6.947)	prob 2.585 (2.585)	GS 28.438 (28.438)	mem 39.761
Train: [78][260/750]	BT 0.048 (1.223)	DT 0.011 (1.178)	loss 6.905 (6.905)	prob 2.629 (2.629)	GS 35.938 (35.938)	mem 39.649
Train: [78][265/750]	BT 0.034 (1.201)	DT 0.001 (1.156)	loss 7.267 (7.267)	prob 2.838 (2.838)	GS 32.984 (32.984)	mem 39.649
Train: [78][270/750]	BT 0.083 (1.225)	DT 0.003 (1.180)	loss 7.179 (7.179)	prob 2.983 (2.983)	GS 29.953 (29.953)	mem 39.801
Train: [78][275/750]	BT 0.060 (1.204)	DT 0.003 (1.158)	loss 6.742 (6.742)	prob 3.274 (3.274)	GS 34.016 (34.016)	mem 39.953
Train: [78][280/750]	BT 0.028 (1.232)	DT 0.001 (1.186)	loss 6.651 (6.651)	prob 3.713 (3.713)	GS 36.859 (36.859)	mem 39.764
Train: [78][285/750]	BT 0.031 (1.211)	DT 0.001 (1.166)	loss 6.873 (6.873)	prob 2.636 (2.636)	GS 31.891 (31.891)	mem 39.784
Train: [78][290/750]	BT 12.644 (1.234)	DT 12.607 (1.189)	loss 6.857 (6.857)	prob 2.526 (2.526)	GS 35.359 (35.359)	mem 39.831
Train: [78][295/750]	BT 0.047 (1.214)	DT 0.001 (1.169)	loss 6.857 (6.857)	prob 2.807 (2.807)	GS 31.156 (31.156)	mem 39.779
Train: [78][300/750]	BT 0.044 (1.197)	DT 0.001 (1.152)	loss 7.158 (7.158)	prob 2.698 (2.698)	GS 36.000 (36.000)	mem 39.758
Train: [78][305/750]	BT 0.056 (1.211)	DT 0.004 (1.166)	loss 6.745 (6.745)	prob 3.392 (3.392)	GS 32.406 (32.406)	mem 39.869
Train: [78][310/750]	BT 1.627 (1.197)	DT 1.581 (1.152)	loss 6.821 (6.821)	prob 2.499 (2.499)	GS 31.812 (31.812)	mem 39.664
Train: [78][315/750]	BT 0.035 (1.217)	DT 0.005 (1.172)	loss 6.865 (6.865)	prob 2.847 (2.847)	GS 29.422 (29.422)	mem 39.755
Train: [78][320/750]	BT 0.038 (1.199)	DT 0.001 (1.154)	loss 7.095 (7.095)	prob 2.420 (2.420)	GS 28.016 (28.016)	mem 39.756
Train: [78][325/750]	BT 0.050 (1.185)	DT 0.001 (1.140)	loss 7.252 (7.252)	prob 2.799 (2.799)	GS 30.156 (30.156)	mem 39.831
Train: [78][330/750]	BT 0.047 (1.201)	DT 0.002 (1.157)	loss 7.040 (7.040)	prob 2.896 (2.896)	GS 32.844 (32.844)	mem 39.839
Train: [78][335/750]	BT 0.040 (1.185)	DT 0.001 (1.140)	loss 7.013 (7.013)	prob 3.014 (3.014)	GS 34.688 (34.688)	mem 39.839
Train: [78][340/750]	BT 0.022 (1.204)	DT 0.001 (1.160)	loss 7.112 (7.112)	prob 2.544 (2.544)	GS 29.078 (29.078)	mem 39.879
Train: [78][345/750]	BT 0.028 (1.187)	DT 0.001 (1.143)	loss 7.148 (7.148)	prob 3.257 (3.257)	GS 25.391 (25.391)	mem 39.879
Train: [78][350/750]	BT 10.282 (1.200)	DT 10.258 (1.156)	loss 6.888 (6.888)	prob 3.109 (3.109)	GS 32.109 (32.109)	mem 39.883
Train: [78][355/750]	BT 0.031 (1.184)	DT 0.001 (1.140)	loss 7.118 (7.118)	prob 2.790 (2.790)	GS 32.422 (32.422)	mem 39.984
Train: [78][360/750]	BT 0.056 (1.179)	DT 0.002 (1.135)	loss 6.766 (6.766)	prob 3.191 (3.191)	GS 32.750 (32.750)	mem 39.900
Train: [78][365/750]	BT 0.104 (1.189)	DT 0.035 (1.144)	loss 7.084 (7.084)	prob 3.214 (3.214)	GS 30.453 (30.453)	mem 39.893
Train: [78][370/750]	BT 2.633 (1.183)	DT 2.557 (1.138)	loss 6.979 (6.979)	prob 2.807 (2.807)	GS 32.984 (32.984)	mem 39.854
Train: [78][375/750]	BT 0.047 (1.179)	DT 0.015 (1.134)	loss 6.914 (6.914)	prob 2.863 (2.863)	GS 30.859 (30.859)	mem 39.907
Train: [78][380/750]	BT 0.111 (1.182)	DT 0.043 (1.137)	loss 6.842 (6.842)	prob 2.757 (2.757)	GS 32.219 (32.219)	mem 40.007
Train: [78][385/750]	BT 0.032 (1.174)	DT 0.001 (1.129)	loss 6.924 (6.924)	prob 2.453 (2.453)	GS 33.047 (33.047)	mem 39.919
Train: [78][390/750]	BT 0.034 (1.186)	DT 0.002 (1.142)	loss 6.821 (6.821)	prob 1.817 (1.817)	GS 30.828 (30.828)	mem 39.905
Train: [78][395/750]	BT 0.071 (1.173)	DT 0.006 (1.129)	loss 7.268 (7.268)	prob 1.831 (1.831)	GS 27.031 (27.031)	mem 40.072
Train: [78][400/750]	BT 6.210 (1.194)	DT 6.164 (1.149)	loss 7.017 (7.017)	prob 2.562 (2.562)	GS 34.578 (34.578)	mem 39.907
Train: [78][405/750]	BT 0.082 (1.180)	DT 0.003 (1.135)	loss 7.239 (7.239)	prob 2.558 (2.558)	GS 28.438 (28.438)	mem 39.942
Train: [78][410/750]	BT 7.260 (1.184)	DT 7.230 (1.139)	loss 7.009 (7.009)	prob 2.357 (2.357)	GS 38.141 (38.141)	mem 39.870
Train: [78][415/750]	BT 0.098 (1.176)	DT 0.001 (1.131)	loss 7.046 (7.046)	prob 2.494 (2.494)	GS 28.656 (28.656)	mem 39.955
Train: [78][420/750]	BT 0.088 (1.165)	DT 0.012 (1.120)	loss 7.050 (7.050)	prob 2.384 (2.384)	GS 33.547 (33.547)	mem 39.946
Train: [78][425/750]	BT 0.036 (1.178)	DT 0.001 (1.133)	loss 6.973 (6.973)	prob 2.210 (2.210)	GS 29.859 (29.859)	mem 39.907
Train: [78][430/750]	BT 1.027 (1.167)	DT 1.003 (1.122)	loss 6.832 (6.832)	prob 1.938 (1.938)	GS 32.156 (32.156)	mem 39.910
Train: [78][435/750]	BT 0.043 (1.184)	DT 0.003 (1.140)	loss 7.048 (7.048)	prob 2.322 (2.322)	GS 37.453 (37.453)	mem 39.919
Train: [78][440/750]	BT 0.032 (1.171)	DT 0.001 (1.127)	loss 6.659 (6.659)	prob 3.162 (3.162)	GS 34.656 (34.656)	mem 39.884
Train: [78][445/750]	BT 0.027 (1.159)	DT 0.001 (1.114)	loss 7.151 (7.151)	prob 2.314 (2.314)	GS 29.875 (29.875)	mem 39.884
Train: [78][450/750]	BT 0.031 (1.176)	DT 0.001 (1.132)	loss 7.030 (7.030)	prob 2.374 (2.374)	GS 32.391 (32.391)	mem 39.934
Train: [78][455/750]	BT 0.061 (1.164)	DT 0.021 (1.119)	loss 7.065 (7.065)	prob 2.246 (2.246)	GS 27.125 (27.125)	mem 39.925
Train: [78][460/750]	BT 0.094 (1.182)	DT 0.009 (1.138)	loss 6.778 (6.778)	prob 2.698 (2.698)	GS 34.016 (34.016)	mem 39.895
Train: [78][465/750]	BT 0.062 (1.170)	DT 0.008 (1.126)	loss 7.088 (7.088)	prob 2.166 (2.166)	GS 26.953 (26.953)	mem 39.895
Train: [78][470/750]	BT 10.878 (1.181)	DT 10.849 (1.137)	loss 6.652 (6.652)	prob 2.711 (2.711)	GS 30.797 (30.797)	mem 39.918
Train: [78][475/750]	BT 0.032 (1.170)	DT 0.002 (1.126)	loss 7.084 (7.084)	prob 2.288 (2.288)	GS 32.000 (32.000)	mem 39.973
Train: [78][480/750]	BT 0.040 (1.159)	DT 0.001 (1.114)	loss 6.956 (6.956)	prob 2.055 (2.055)	GS 33.234 (33.234)	mem 39.918
Train: [78][485/750]	BT 0.026 (1.176)	DT 0.001 (1.132)	loss 7.549 (7.549)	prob 1.880 (1.880)	GS 32.797 (32.797)	mem 39.859
Train: [78][490/750]	BT 0.034 (1.165)	DT 0.004 (1.120)	loss 7.007 (7.007)	prob 2.637 (2.637)	GS 30.453 (30.453)	mem 39.921
Train: [78][495/750]	BT 0.027 (1.171)	DT 0.002 (1.127)	loss 6.690 (6.690)	prob 2.812 (2.812)	GS 38.359 (38.359)	mem 39.916
Train: [78][500/750]	BT 0.060 (1.166)	DT 0.014 (1.122)	loss 7.092 (7.092)	prob 2.378 (2.378)	GS 32.609 (32.609)	mem 39.976
Train: [78][505/750]	BT 0.119 (1.159)	DT 0.028 (1.115)	loss 6.875 (6.875)	prob 2.682 (2.682)	GS 29.531 (29.531)	mem 39.945
Train: [78][510/750]	BT 0.064 (1.168)	DT 0.010 (1.123)	loss 6.877 (6.877)	prob 2.431 (2.431)	GS 30.797 (30.797)	mem 39.963
Train: [78][515/750]	BT 0.050 (1.158)	DT 0.008 (1.114)	loss 7.223 (7.223)	prob 2.293 (2.293)	GS 33.703 (33.703)	mem 39.891
Train: [78][520/750]	BT 5.483 (1.171)	DT 5.451 (1.127)	loss 6.929 (6.929)	prob 2.879 (2.879)	GS 33.469 (33.469)	mem 39.905
Train: [78][525/750]	BT 0.081 (1.166)	DT 0.034 (1.122)	loss 7.207 (7.207)	prob 2.775 (2.775)	GS 28.781 (28.781)	mem 39.909
Train: [78][530/750]	BT 3.441 (1.162)	DT 3.326 (1.118)	loss 6.929 (6.929)	prob 2.387 (2.387)	GS 35.938 (35.938)	mem 39.835
Train: [78][535/750]	BT 0.037 (1.166)	DT 0.002 (1.122)	loss 6.872 (6.872)	prob 2.745 (2.745)	GS 28.672 (28.672)	mem 40.229
Train: [78][540/750]	BT 0.026 (1.159)	DT 0.001 (1.115)	loss 6.913 (6.913)	prob 2.501 (2.501)	GS 34.109 (34.109)	mem 39.910
Train: [78][545/750]	BT 0.037 (1.163)	DT 0.001 (1.119)	loss 7.186 (7.186)	prob 2.081 (2.081)	GS 33.250 (33.250)	mem 39.828
Train: [78][550/750]	BT 0.022 (1.164)	DT 0.001 (1.120)	loss 6.967 (6.967)	prob 2.867 (2.867)	GS 34.172 (34.172)	mem 39.809
Train: [78][555/750]	BT 0.042 (1.154)	DT 0.003 (1.110)	loss 7.053 (7.053)	prob 2.788 (2.788)	GS 37.766 (37.766)	mem 39.919
Train: [78][560/750]	BT 1.127 (1.169)	DT 1.063 (1.125)	loss 7.298 (7.298)	prob 2.425 (2.425)	GS 34.547 (34.547)	mem 39.775
Train: [78][565/750]	BT 0.084 (1.159)	DT 0.001 (1.115)	loss 7.217 (7.217)	prob 2.767 (2.767)	GS 34.531 (34.531)	mem 39.927
Train: [78][570/750]	BT 0.024 (1.180)	DT 0.001 (1.135)	loss 6.931 (6.931)	prob 3.171 (3.171)	GS 34.016 (34.016)	mem 39.869
Train: [78][575/750]	BT 0.029 (1.170)	DT 0.001 (1.126)	loss 7.116 (7.116)	prob 3.032 (3.032)	GS 28.922 (28.922)	mem 39.869
Train: [78][580/750]	BT 10.742 (1.179)	DT 10.707 (1.134)	loss 6.968 (6.968)	prob 2.900 (2.900)	GS 30.594 (30.594)	mem 39.956
Train: [78][585/750]	BT 0.111 (1.169)	DT 0.001 (1.125)	loss 7.141 (7.141)	prob 2.696 (2.696)	GS 33.906 (33.906)	mem 39.957
Train: [78][590/750]	BT 0.057 (1.160)	DT 0.002 (1.115)	loss 6.868 (6.868)	prob 2.714 (2.714)	GS 33.703 (33.703)	mem 39.908
Train: [78][595/750]	BT 0.024 (1.170)	DT 0.001 (1.126)	loss 6.901 (6.901)	prob 2.390 (2.390)	GS 33.281 (33.281)	mem 40.036
Train: [78][600/750]	BT 0.047 (1.163)	DT 0.004 (1.119)	loss 6.890 (6.890)	prob 2.580 (2.580)	GS 34.641 (34.641)	mem 39.935
Train: [78][605/750]	BT 0.038 (1.175)	DT 0.003 (1.131)	loss 6.934 (6.934)	prob 3.230 (3.230)	GS 33.438 (33.438)	mem 39.919
Train: [78][610/750]	BT 0.029 (1.165)	DT 0.001 (1.121)	loss 7.012 (7.012)	prob 2.519 (2.519)	GS 35.188 (35.188)	mem 39.920
Train: [78][615/750]	BT 0.034 (1.156)	DT 0.002 (1.112)	loss 6.988 (6.988)	prob 2.450 (2.450)	GS 33.656 (33.656)	mem 39.964
Train: [78][620/750]	BT 2.796 (1.164)	DT 2.731 (1.120)	loss 7.032 (7.032)	prob 2.988 (2.988)	GS 32.578 (32.578)	mem 39.884
Train: [78][625/750]	BT 0.046 (1.155)	DT 0.014 (1.111)	loss 6.911 (6.911)	prob 3.044 (3.044)	GS 31.984 (31.984)	mem 39.892
Train: [78][630/750]	BT 0.045 (1.160)	DT 0.005 (1.116)	loss 7.128 (7.128)	prob 2.009 (2.009)	GS 34.281 (34.281)	mem 39.959
Train: [78][635/750]	BT 0.033 (1.165)	DT 0.002 (1.121)	loss 7.120 (7.120)	prob 2.724 (2.724)	GS 33.344 (33.344)	mem 39.988
Train: [78][640/750]	BT 2.517 (1.160)	DT 2.485 (1.116)	loss 6.799 (6.799)	prob 2.603 (2.603)	GS 32.891 (32.891)	mem 39.885
Train: [78][645/750]	BT 0.029 (1.168)	DT 0.001 (1.124)	loss 6.707 (6.707)	prob 2.841 (2.841)	GS 33.328 (33.328)	mem 39.988
Train: [78][650/750]	BT 0.031 (1.159)	DT 0.001 (1.115)	loss 6.866 (6.866)	prob 2.481 (2.481)	GS 33.094 (33.094)	mem 39.988
Train: [78][655/750]	BT 0.035 (1.152)	DT 0.011 (1.108)	loss 7.086 (7.086)	prob 1.857 (1.857)	GS 34.188 (34.188)	mem 40.010
arpack error, retry= 0
Train: [78][660/750]	BT 0.066 (1.162)	DT 0.017 (1.118)	loss 6.879 (6.879)	prob 2.424 (2.424)	GS 32.156 (32.156)	mem 40.033
Train: [78][665/750]	BT 0.055 (1.153)	DT 0.003 (1.109)	loss 7.141 (7.141)	prob 1.805 (1.805)	GS 44.859 (44.859)	mem 40.034
Train: [78][670/750]	BT 0.044 (1.165)	DT 0.002 (1.121)	loss 6.875 (6.875)	prob 3.041 (3.041)	GS 30.703 (30.703)	mem 40.031
Train: [78][675/750]	BT 0.033 (1.157)	DT 0.001 (1.113)	loss 7.102 (7.102)	prob 2.544 (2.544)	GS 36.078 (36.078)	mem 39.968
Train: [78][680/750]	BT 14.057 (1.169)	DT 14.014 (1.126)	loss 6.812 (6.812)	prob 3.284 (3.284)	GS 36.953 (36.953)	mem 40.019
Train: [78][685/750]	BT 0.032 (1.161)	DT 0.002 (1.117)	loss 6.954 (6.954)	prob 2.635 (2.635)	GS 31.797 (31.797)	mem 40.021
Train: [78][690/750]	BT 0.037 (1.153)	DT 0.008 (1.109)	loss 6.878 (6.878)	prob 2.365 (2.365)	GS 33.609 (33.609)	mem 40.057
Train: [78][695/750]	BT 0.023 (1.168)	DT 0.001 (1.124)	loss 6.800 (6.800)	prob 2.767 (2.767)	GS 32.594 (32.594)	mem 40.006
Train: [78][700/750]	BT 0.049 (1.160)	DT 0.003 (1.116)	loss 6.821 (6.821)	prob 2.463 (2.463)	GS 33.531 (33.531)	mem 40.198
Train: [78][705/750]	BT 0.026 (1.172)	DT 0.001 (1.128)	loss 6.995 (6.995)	prob 2.333 (2.333)	GS 34.516 (34.516)	mem 39.949
Train: [78][710/750]	BT 0.041 (1.164)	DT 0.006 (1.120)	loss 7.043 (7.043)	prob 2.703 (2.703)	GS 35.219 (35.219)	mem 39.949
Train: [78][715/750]	BT 0.036 (1.156)	DT 0.001 (1.112)	loss 7.227 (7.227)	prob 2.915 (2.915)	GS 28.953 (28.953)	mem 40.016
Train: [78][720/750]	BT 0.032 (1.170)	DT 0.001 (1.126)	loss 6.887 (6.887)	prob 2.973 (2.973)	GS 30.516 (30.516)	mem 40.110
Train: [78][725/750]	BT 0.030 (1.162)	DT 0.001 (1.118)	loss 7.038 (7.038)	prob 2.272 (2.272)	GS 28.141 (28.141)	mem 39.950
Train: [78][730/750]	BT 0.025 (1.167)	DT 0.001 (1.123)	loss 7.031 (7.031)	prob 1.911 (1.911)	GS 31.344 (31.344)	mem 39.593
Train: [78][735/750]	BT 0.032 (1.159)	DT 0.002 (1.115)	loss 7.374 (7.374)	prob 1.924 (1.924)	GS 38.516 (38.516)	mem 39.606
Train: [78][740/750]	BT 6.558 (1.160)	DT 6.529 (1.117)	loss 6.983 (6.983)	prob 2.776 (2.776)	GS 32.984 (32.984)	mem 7.658
Train: [78][745/750]	BT 0.033 (1.152)	DT 0.002 (1.109)	loss 7.029 (7.029)	prob 2.908 (2.908)	GS 27.500 (27.500)	mem 7.658
Train: [78][750/750]	BT 0.036 (1.145)	DT 0.001 (1.102)	loss 6.865 (6.865)	prob 2.898 (2.898)	GS 34.875 (34.875)	mem 7.709
Train: [78][755/750]	BT 0.020 (1.142)	DT 0.001 (1.099)	loss 6.974 (6.974)	prob 2.910 (2.910)	GS 29.906 (29.906)	mem 7.629
epoch 78, total time 862.17
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [79][1/750]	BT 26.381 (26.381)	DT 26.295 (26.295)	loss 6.905 (6.905)	prob 2.532 (2.532)	GS 31.078 (31.078)	mem 38.569
Train: [79][5/750]	BT 0.107 (5.333)	DT 0.002 (5.262)	loss 6.772 (6.772)	prob 2.544 (2.544)	GS 33.125 (33.125)	mem 38.768
Train: [79][10/750]	BT 0.029 (2.686)	DT 0.001 (2.633)	loss 6.733 (6.733)	prob 2.844 (2.844)	GS 34.219 (34.219)	mem 38.769
Train: [79][15/750]	BT 0.043 (2.502)	DT 0.015 (2.455)	loss 6.585 (6.585)	prob 2.218 (2.218)	GS 29.688 (29.688)	mem 38.817
Train: [79][20/750]	BT 0.025 (2.046)	DT 0.001 (1.998)	loss 6.625 (6.625)	prob 2.846 (2.846)	GS 36.016 (36.016)	mem 38.888
Train: [79][25/750]	BT 10.072 (2.053)	DT 9.992 (2.000)	loss 6.814 (6.814)	prob 1.984 (1.984)	GS 30.422 (30.422)	mem 39.085
Train: [79][30/750]	BT 4.558 (1.868)	DT 4.517 (1.817)	loss 6.807 (6.807)	prob 3.177 (3.177)	GS 30.672 (30.672)	mem 38.926
Train: [79][35/750]	BT 0.043 (1.607)	DT 0.002 (1.558)	loss 7.087 (7.087)	prob 2.785 (2.785)	GS 33.266 (33.266)	mem 38.907
Train: [79][40/750]	BT 0.028 (1.806)	DT 0.001 (1.756)	loss 6.883 (6.883)	prob 2.063 (2.063)	GS 33.734 (33.734)	mem 38.987
Train: [79][45/750]	BT 0.024 (1.621)	DT 0.001 (1.573)	loss 6.940 (6.940)	prob 3.199 (3.199)	GS 46.406 (46.406)	mem 38.989
Train: [79][50/750]	BT 0.026 (1.620)	DT 0.001 (1.571)	loss 6.910 (6.910)	prob 2.017 (2.017)	GS 35.516 (35.516)	mem 38.998
Train: [79][55/750]	BT 0.059 (1.627)	DT 0.013 (1.578)	loss 6.890 (6.890)	prob 2.645 (2.645)	GS 31.750 (31.750)	mem 39.037
Train: [79][60/750]	BT 0.044 (1.494)	DT 0.010 (1.447)	loss 6.848 (6.848)	prob 3.512 (3.512)	GS 33.250 (33.250)	mem 39.037
Train: [79][65/750]	BT 0.031 (1.383)	DT 0.001 (1.336)	loss 7.382 (7.382)	prob 2.211 (2.211)	GS 31.734 (31.734)	mem 39.060
Train: [79][70/750]	BT 0.060 (1.478)	DT 0.003 (1.429)	loss 6.790 (6.790)	prob 2.417 (2.417)	GS 33.234 (33.234)	mem 39.128
Train: [79][75/750]	BT 0.031 (1.406)	DT 0.002 (1.358)	loss 7.077 (7.077)	prob 2.128 (2.128)	GS 33.906 (33.906)	mem 39.094
Train: [79][80/750]	BT 0.055 (1.435)	DT 0.015 (1.387)	loss 6.986 (6.986)	prob 2.536 (2.536)	GS 32.859 (32.859)	mem 39.015
Train: [79][85/750]	BT 0.025 (1.354)	DT 0.001 (1.306)	loss 6.881 (6.881)	prob 2.367 (2.367)	GS 33.094 (33.094)	mem 39.014
Train: [79][90/750]	BT 8.144 (1.406)	DT 8.115 (1.358)	loss 7.250 (7.250)	prob 2.281 (2.281)	GS 32.125 (32.125)	mem 39.115
Train: [79][95/750]	BT 0.032 (1.336)	DT 0.001 (1.288)	loss 6.960 (6.960)	prob 2.987 (2.987)	GS 38.500 (38.500)	mem 39.116
Train: [79][100/750]	BT 0.111 (1.321)	DT 0.016 (1.272)	loss 6.961 (6.961)	prob 2.605 (2.605)	GS 33.781 (33.781)	mem 39.049
Train: [79][105/750]	BT 0.075 (1.327)	DT 0.002 (1.278)	loss 7.087 (7.087)	prob 3.213 (3.213)	GS 27.719 (27.719)	mem 39.062
Train: [79][110/750]	BT 9.225 (1.353)	DT 9.186 (1.304)	loss 7.065 (7.065)	prob 2.593 (2.593)	GS 35.375 (35.375)	mem 39.243
Train: [79][115/750]	BT 0.031 (1.322)	DT 0.006 (1.274)	loss 7.052 (7.052)	prob 2.915 (2.915)	GS 28.656 (28.656)	mem 39.029
Train: [79][120/750]	BT 0.048 (1.268)	DT 0.015 (1.221)	loss 6.792 (6.792)	prob 2.867 (2.867)	GS 31.594 (31.594)	mem 39.031
Train: [79][125/750]	BT 0.029 (1.300)	DT 0.001 (1.253)	loss 7.046 (7.046)	prob 2.456 (2.456)	GS 31.453 (31.453)	mem 39.172
Train: [79][130/750]	BT 0.033 (1.270)	DT 0.001 (1.223)	loss 6.754 (6.754)	prob 2.113 (2.113)	GS 33.375 (33.375)	mem 38.980
Train: [79][135/750]	BT 0.078 (1.308)	DT 0.002 (1.262)	loss 6.887 (6.887)	prob 3.387 (3.387)	GS 33.609 (33.609)	mem 39.130
Train: [79][140/750]	BT 0.032 (1.270)	DT 0.001 (1.224)	loss 6.923 (6.923)	prob 2.737 (2.737)	GS 30.688 (30.688)	mem 39.064
Train: [79][145/750]	BT 0.133 (1.229)	DT 0.029 (1.182)	loss 6.888 (6.888)	prob 2.697 (2.697)	GS 35.266 (35.266)	mem 39.092
Train: [79][150/750]	BT 1.648 (1.259)	DT 1.616 (1.213)	loss 7.099 (7.099)	prob 2.412 (2.412)	GS 35.344 (35.344)	mem 39.189
Train: [79][155/750]	BT 0.043 (1.249)	DT 0.002 (1.203)	loss 6.988 (6.988)	prob 2.916 (2.916)	GS 33.000 (33.000)	mem 39.171
Train: [79][160/750]	BT 0.049 (1.246)	DT 0.013 (1.200)	loss 6.870 (6.870)	prob 2.557 (2.557)	GS 30.000 (30.000)	mem 39.167
Train: [79][165/750]	BT 0.032 (1.237)	DT 0.002 (1.191)	loss 7.165 (7.165)	prob 2.542 (2.542)	GS 27.984 (27.984)	mem 39.214
Train: [79][170/750]	BT 4.391 (1.234)	DT 4.320 (1.188)	loss 7.027 (7.027)	prob 2.463 (2.463)	GS 34.438 (34.438)	mem 39.257
Train: [79][175/750]	BT 0.030 (1.256)	DT 0.002 (1.210)	loss 6.896 (6.896)	prob 3.044 (3.044)	GS 34.516 (34.516)	mem 39.249
Train: [79][180/750]	BT 0.082 (1.222)	DT 0.003 (1.177)	loss 6.688 (6.688)	prob 3.351 (3.351)	GS 33.125 (33.125)	mem 39.290
Train: [79][185/750]	BT 0.027 (1.232)	DT 0.001 (1.186)	loss 6.978 (6.978)	prob 2.746 (2.746)	GS 29.234 (29.234)	mem 39.302
Train: [79][190/750]	BT 0.032 (1.243)	DT 0.001 (1.197)	loss 6.895 (6.895)	prob 2.953 (2.953)	GS 32.297 (32.297)	mem 39.310
Train: [79][195/750]	BT 0.040 (1.227)	DT 0.009 (1.181)	loss 6.958 (6.958)	prob 3.212 (3.212)	GS 32.922 (32.922)	mem 39.314
Train: [79][200/750]	BT 0.043 (1.236)	DT 0.004 (1.190)	loss 6.993 (6.993)	prob 2.870 (2.870)	GS 33.422 (33.422)	mem 39.360
Train: [79][205/750]	BT 0.061 (1.209)	DT 0.009 (1.163)	loss 6.922 (6.922)	prob 2.755 (2.755)	GS 38.141 (38.141)	mem 39.325
Train: [79][210/750]	BT 10.816 (1.250)	DT 10.752 (1.204)	loss 6.927 (6.927)	prob 2.328 (2.328)	GS 33.703 (33.703)	mem 39.610
Train: [79][215/750]	BT 0.044 (1.222)	DT 0.004 (1.176)	loss 7.035 (7.035)	prob 2.441 (2.441)	GS 32.562 (32.562)	mem 39.473
Train: [79][220/750]	BT 0.034 (1.195)	DT 0.008 (1.150)	loss 7.196 (7.196)	prob 2.615 (2.615)	GS 35.312 (35.312)	mem 39.487
Train: [79][225/750]	BT 0.031 (1.234)	DT 0.001 (1.188)	loss 6.978 (6.978)	prob 2.657 (2.657)	GS 32.875 (32.875)	mem 39.581
Train: [79][230/750]	BT 0.031 (1.208)	DT 0.003 (1.162)	loss 6.927 (6.927)	prob 2.251 (2.251)	GS 29.984 (29.984)	mem 39.582
Train: [79][235/750]	BT 0.095 (1.240)	DT 0.007 (1.194)	loss 6.970 (6.970)	prob 2.631 (2.631)	GS 31.250 (31.250)	mem 39.571
Train: [79][240/750]	BT 0.026 (1.215)	DT 0.001 (1.170)	loss 6.676 (6.676)	prob 3.006 (3.006)	GS 33.078 (33.078)	mem 39.559
Train: [79][245/750]	BT 0.032 (1.192)	DT 0.001 (1.146)	loss 7.055 (7.055)	prob 2.256 (2.256)	GS 32.141 (32.141)	mem 39.543
Train: [79][250/750]	BT 0.044 (1.227)	DT 0.013 (1.182)	loss 6.900 (6.900)	prob 3.478 (3.478)	GS 38.359 (38.359)	mem 39.502
Train: [79][255/750]	BT 0.060 (1.204)	DT 0.016 (1.159)	loss 6.932 (6.932)	prob 2.843 (2.843)	GS 31.969 (31.969)	mem 39.503
Train: [79][260/750]	BT 0.028 (1.224)	DT 0.001 (1.179)	loss 7.076 (7.076)	prob 2.669 (2.669)	GS 35.281 (35.281)	mem 39.637
Train: [79][265/750]	BT 0.033 (1.201)	DT 0.002 (1.156)	loss 6.777 (6.777)	prob 2.807 (2.807)	GS 33.922 (33.922)	mem 39.598
Train: [79][270/750]	BT 12.569 (1.227)	DT 12.537 (1.182)	loss 6.861 (6.861)	prob 2.603 (2.603)	GS 34.844 (34.844)	mem 39.564
Train: [79][275/750]	BT 0.023 (1.205)	DT 0.001 (1.160)	loss 6.974 (6.974)	prob 3.161 (3.161)	GS 36.344 (36.344)	mem 39.566
Train: [79][280/750]	BT 0.044 (1.185)	DT 0.012 (1.140)	loss 7.033 (7.033)	prob 2.766 (2.766)	GS 32.688 (32.688)	mem 39.568
Train: [79][285/750]	BT 0.031 (1.203)	DT 0.002 (1.158)	loss 7.010 (7.010)	prob 2.610 (2.610)	GS 29.391 (29.391)	mem 39.742
Train: [79][290/750]	BT 0.063 (1.183)	DT 0.010 (1.138)	loss 6.707 (6.707)	prob 3.016 (3.016)	GS 36.406 (36.406)	mem 39.642
Train: [79][295/750]	BT 0.033 (1.207)	DT 0.002 (1.162)	loss 6.971 (6.971)	prob 2.283 (2.283)	GS 32.500 (32.500)	mem 39.681
Train: [79][300/750]	BT 0.060 (1.189)	DT 0.005 (1.143)	loss 6.973 (6.973)	prob 3.209 (3.209)	GS 35.266 (35.266)	mem 39.683
Train: [79][305/750]	BT 0.112 (1.189)	DT 0.030 (1.143)	loss 6.997 (6.997)	prob 3.040 (3.040)	GS 28.969 (28.969)	mem 39.773
Train: [79][310/750]	BT 0.083 (1.198)	DT 0.002 (1.152)	loss 6.975 (6.975)	prob 3.283 (3.283)	GS 31.156 (31.156)	mem 39.866
Train: [79][315/750]	BT 0.057 (1.180)	DT 0.012 (1.134)	loss 7.031 (7.031)	prob 2.867 (2.867)	GS 30.609 (30.609)	mem 39.842
Train: [79][320/750]	BT 0.071 (1.202)	DT 0.001 (1.156)	loss 6.893 (6.893)	prob 3.081 (3.081)	GS 38.656 (38.656)	mem 39.851
Train: [79][325/750]	BT 0.033 (1.185)	DT 0.001 (1.139)	loss 7.044 (7.044)	prob 2.544 (2.544)	GS 39.531 (39.531)	mem 39.879
Train: [79][330/750]	BT 10.290 (1.206)	DT 10.226 (1.160)	loss 7.056 (7.056)	prob 2.369 (2.369)	GS 30.844 (30.844)	mem 39.911
Train: [79][335/750]	BT 0.028 (1.188)	DT 0.001 (1.143)	loss 7.017 (7.017)	prob 2.145 (2.145)	GS 34.891 (34.891)	mem 39.911
Train: [79][340/750]	BT 0.037 (1.171)	DT 0.008 (1.126)	loss 6.771 (6.771)	prob 2.844 (2.844)	GS 28.828 (28.828)	mem 39.913
Train: [79][345/750]	BT 0.049 (1.186)	DT 0.001 (1.141)	loss 6.926 (6.926)	prob 3.281 (3.281)	GS 27.359 (27.359)	mem 39.899
Train: [79][350/750]	BT 0.039 (1.170)	DT 0.001 (1.125)	loss 7.110 (7.110)	prob 2.387 (2.387)	GS 33.625 (33.625)	mem 39.900
Train: [79][355/750]	BT 0.061 (1.193)	DT 0.001 (1.147)	loss 7.211 (7.211)	prob 2.528 (2.528)	GS 30.281 (30.281)	mem 39.899
Train: [79][360/750]	BT 0.033 (1.177)	DT 0.001 (1.132)	loss 6.814 (6.814)	prob 3.233 (3.233)	GS 29.219 (29.219)	mem 39.869
Train: [79][365/750]	BT 0.052 (1.162)	DT 0.012 (1.116)	loss 7.213 (7.213)	prob 2.337 (2.337)	GS 32.156 (32.156)	mem 39.868
Train: [79][370/750]	BT 0.026 (1.179)	DT 0.001 (1.133)	loss 6.705 (6.705)	prob 3.013 (3.013)	GS 30.375 (30.375)	mem 39.855
Train: [79][375/750]	BT 0.138 (1.164)	DT 0.004 (1.118)	loss 6.946 (6.946)	prob 2.807 (2.807)	GS 33.250 (33.250)	mem 39.875
Train: [79][380/750]	BT 0.034 (1.188)	DT 0.001 (1.143)	loss 6.899 (6.899)	prob 2.447 (2.447)	GS 34.188 (34.188)	mem 40.083
Train: [79][385/750]	BT 0.086 (1.173)	DT 0.019 (1.128)	loss 7.002 (7.002)	prob 2.546 (2.546)	GS 28.594 (28.594)	mem 39.935
Train: [79][390/750]	BT 10.202 (1.185)	DT 10.171 (1.140)	loss 6.847 (6.847)	prob 2.876 (2.876)	GS 28.297 (28.297)	mem 40.099
Train: [79][395/750]	BT 0.036 (1.170)	DT 0.002 (1.125)	loss 6.847 (6.847)	prob 2.943 (2.943)	GS 31.891 (31.891)	mem 40.300
Train: [79][400/750]	BT 0.032 (1.156)	DT 0.001 (1.111)	loss 6.631 (6.631)	prob 3.658 (3.658)	GS 29.500 (29.500)	mem 40.300
Train: [79][405/750]	BT 0.040 (1.176)	DT 0.008 (1.131)	loss 6.870 (6.870)	prob 3.347 (3.347)	GS 30.109 (30.109)	mem 39.948
Train: [79][410/750]	BT 0.096 (1.163)	DT 0.015 (1.118)	loss 6.841 (6.841)	prob 2.708 (2.708)	GS 35.234 (35.234)	mem 39.948
Train: [79][415/750]	BT 0.037 (1.181)	DT 0.001 (1.136)	loss 7.168 (7.168)	prob 2.310 (2.310)	GS 30.766 (30.766)	mem 39.996
Train: [79][420/750]	BT 0.045 (1.167)	DT 0.001 (1.123)	loss 6.847 (6.847)	prob 2.382 (2.382)	GS 34.875 (34.875)	mem 39.931
Train: [79][425/750]	BT 0.059 (1.154)	DT 0.006 (1.110)	loss 7.000 (7.000)	prob 2.227 (2.227)	GS 32.656 (32.656)	mem 40.016
Train: [79][430/750]	BT 4.496 (1.178)	DT 4.467 (1.134)	loss 6.819 (6.819)	prob 3.108 (3.108)	GS 37.516 (37.516)	mem 40.013
Train: [79][435/750]	BT 0.032 (1.165)	DT 0.001 (1.121)	loss 7.060 (7.060)	prob 2.470 (2.470)	GS 31.484 (31.484)	mem 40.008
Train: [79][440/750]	BT 0.135 (1.165)	DT 0.010 (1.121)	loss 6.810 (6.810)	prob 2.714 (2.714)	GS 35.266 (35.266)	mem 39.961
Train: [79][445/750]	BT 0.138 (1.170)	DT 0.002 (1.125)	loss 7.005 (7.005)	prob 2.176 (2.176)	GS 32.562 (32.562)	mem 39.935
Train: [79][450/750]	BT 3.726 (1.166)	DT 3.689 (1.121)	loss 6.677 (6.677)	prob 3.585 (3.585)	GS 35.734 (35.734)	mem 39.942
Train: [79][455/750]	BT 0.110 (1.173)	DT 0.008 (1.129)	loss 7.094 (7.094)	prob 2.485 (2.485)	GS 33.047 (33.047)	mem 40.122
Train: [79][460/750]	BT 0.036 (1.161)	DT 0.002 (1.116)	loss 7.260 (7.260)	prob 2.501 (2.501)	GS 39.625 (39.625)	mem 39.953
Train: [79][465/750]	BT 0.056 (1.160)	DT 0.003 (1.115)	loss 7.177 (7.177)	prob 2.588 (2.588)	GS 31.938 (31.938)	mem 40.110
Train: [79][470/750]	BT 0.047 (1.171)	DT 0.001 (1.126)	loss 6.656 (6.656)	prob 3.139 (3.139)	GS 31.219 (31.219)	mem 39.956
Train: [79][475/750]	BT 0.032 (1.159)	DT 0.001 (1.114)	loss 7.046 (7.046)	prob 2.820 (2.820)	GS 31.234 (31.234)	mem 39.957
Train: [79][480/750]	BT 0.027 (1.175)	DT 0.001 (1.130)	loss 6.981 (6.981)	prob 2.475 (2.475)	GS 32.719 (32.719)	mem 39.931
Train: [79][485/750]	BT 0.027 (1.163)	DT 0.001 (1.119)	loss 7.180 (7.180)	prob 2.518 (2.518)	GS 27.562 (27.562)	mem 39.935
Train: [79][490/750]	BT 6.175 (1.174)	DT 6.143 (1.129)	loss 6.796 (6.796)	prob 2.942 (2.942)	GS 32.578 (32.578)	mem 39.999
Train: [79][495/750]	BT 0.030 (1.162)	DT 0.001 (1.118)	loss 6.859 (6.859)	prob 3.034 (3.034)	GS 30.141 (30.141)	mem 40.048
Train: [79][500/750]	BT 4.798 (1.168)	DT 4.767 (1.123)	loss 6.903 (6.903)	prob 2.681 (2.681)	GS 35.859 (35.859)	mem 39.855
Train: [79][505/750]	BT 0.070 (1.166)	DT 0.005 (1.121)	loss 6.861 (6.861)	prob 2.869 (2.869)	GS 32.562 (32.562)	mem 40.024
Train: [79][510/750]	BT 0.059 (1.162)	DT 0.012 (1.117)	loss 6.911 (6.911)	prob 2.149 (2.149)	GS 30.953 (30.953)	mem 39.919
Train: [79][515/750]	BT 0.052 (1.168)	DT 0.002 (1.123)	loss 6.984 (6.984)	prob 2.986 (2.986)	GS 34.531 (34.531)	mem 40.006
Train: [79][520/750]	BT 3.967 (1.165)	DT 3.854 (1.120)	loss 7.061 (7.061)	prob 2.084 (2.084)	GS 35.406 (35.406)	mem 39.951
Train: [79][525/750]	BT 0.032 (1.156)	DT 0.001 (1.110)	loss 6.963 (6.963)	prob 2.687 (2.687)	GS 32.594 (32.594)	mem 39.909
Train: [79][530/750]	BT 0.031 (1.166)	DT 0.001 (1.121)	loss 6.939 (6.939)	prob 2.696 (2.696)	GS 34.891 (34.891)	mem 39.852
Train: [79][535/750]	BT 0.060 (1.156)	DT 0.015 (1.111)	loss 7.242 (7.242)	prob 2.246 (2.246)	GS 36.219 (36.219)	mem 39.899
Train: [79][540/750]	BT 0.072 (1.173)	DT 0.007 (1.128)	loss 6.895 (6.895)	prob 3.179 (3.179)	GS 31.125 (31.125)	mem 40.055
Train: [79][545/750]	BT 0.050 (1.163)	DT 0.007 (1.118)	loss 6.890 (6.890)	prob 2.940 (2.940)	GS 29.156 (29.156)	mem 39.938
Train: [79][550/750]	BT 12.209 (1.175)	DT 12.177 (1.130)	loss 6.921 (6.921)	prob 2.283 (2.283)	GS 33.250 (33.250)	mem 40.029
Train: [79][555/750]	BT 0.059 (1.165)	DT 0.018 (1.120)	loss 6.942 (6.942)	prob 3.556 (3.556)	GS 36.688 (36.688)	mem 39.968
Train: [79][560/750]	BT 0.041 (1.155)	DT 0.001 (1.110)	loss 6.978 (6.978)	prob 2.953 (2.953)	GS 33.375 (33.375)	mem 40.022
Train: [79][565/750]	BT 0.036 (1.166)	DT 0.001 (1.121)	loss 7.222 (7.222)	prob 2.428 (2.428)	GS 31.078 (31.078)	mem 39.990
Train: [79][570/750]	BT 0.041 (1.156)	DT 0.002 (1.111)	loss 7.024 (7.024)	prob 2.151 (2.151)	GS 36.469 (36.469)	mem 39.963
Train: [79][575/750]	BT 0.025 (1.168)	DT 0.001 (1.123)	loss 7.247 (7.247)	prob 2.402 (2.402)	GS 31.844 (31.844)	mem 40.002
Train: [79][580/750]	BT 0.034 (1.158)	DT 0.001 (1.113)	loss 6.959 (6.959)	prob 2.894 (2.894)	GS 33.578 (33.578)	mem 39.892
Train: [79][585/750]	BT 0.031 (1.148)	DT 0.001 (1.103)	loss 6.765 (6.765)	prob 2.617 (2.617)	GS 29.859 (29.859)	mem 39.892
Train: [79][590/750]	BT 0.075 (1.161)	DT 0.007 (1.116)	loss 7.101 (7.101)	prob 3.377 (3.377)	GS 35.406 (35.406)	mem 40.454
Train: [79][595/750]	BT 0.052 (1.153)	DT 0.005 (1.108)	loss 6.930 (6.930)	prob 2.651 (2.651)	GS 36.031 (36.031)	mem 39.921
Train: [79][600/750]	BT 0.025 (1.165)	DT 0.001 (1.121)	loss 6.974 (6.974)	prob 3.236 (3.236)	GS 29.516 (29.516)	mem 40.047
Train: [79][605/750]	BT 0.041 (1.156)	DT 0.002 (1.112)	loss 6.867 (6.867)	prob 3.076 (3.076)	GS 33.078 (33.078)	mem 40.130
Train: [79][610/750]	BT 15.597 (1.173)	DT 15.554 (1.128)	loss 7.095 (7.095)	prob 2.437 (2.437)	GS 39.875 (39.875)	mem 39.998
Train: [79][615/750]	BT 0.062 (1.163)	DT 0.001 (1.119)	loss 7.178 (7.178)	prob 2.006 (2.006)	GS 32.078 (32.078)	mem 40.091
Train: [79][620/750]	BT 0.031 (1.154)	DT 0.002 (1.110)	loss 7.039 (7.039)	prob 2.908 (2.908)	GS 35.359 (35.359)	mem 40.001
Train: [79][625/750]	BT 0.025 (1.165)	DT 0.003 (1.120)	loss 6.903 (6.903)	prob 2.717 (2.717)	GS 32.938 (32.938)	mem 39.930
Train: [79][630/750]	BT 0.026 (1.155)	DT 0.001 (1.111)	loss 6.911 (6.911)	prob 2.762 (2.762)	GS 32.359 (32.359)	mem 39.932
Train: [79][635/750]	BT 0.022 (1.166)	DT 0.001 (1.122)	loss 6.866 (6.866)	prob 2.543 (2.543)	GS 33.047 (33.047)	mem 39.951
Train: [79][640/750]	BT 0.058 (1.158)	DT 0.007 (1.113)	loss 6.931 (6.931)	prob 2.671 (2.671)	GS 35.141 (35.141)	mem 39.829
Train: [79][645/750]	BT 0.116 (1.149)	DT 0.032 (1.105)	loss 6.919 (6.919)	prob 3.030 (3.030)	GS 27.078 (27.078)	mem 39.906
Train: [79][650/750]	BT 0.028 (1.160)	DT 0.001 (1.116)	loss 7.268 (7.268)	prob 2.552 (2.552)	GS 33.422 (33.422)	mem 39.907
Train: [79][655/750]	BT 0.072 (1.152)	DT 0.001 (1.108)	loss 7.094 (7.094)	prob 2.893 (2.893)	GS 30.281 (30.281)	mem 39.907
Train: [79][660/750]	BT 0.038 (1.164)	DT 0.001 (1.120)	loss 6.888 (6.888)	prob 2.545 (2.545)	GS 33.156 (33.156)	mem 39.915
Train: [79][665/750]	BT 0.107 (1.156)	DT 0.005 (1.112)	loss 6.720 (6.720)	prob 3.017 (3.017)	GS 27.797 (27.797)	mem 39.915
Train: [79][670/750]	BT 11.620 (1.165)	DT 11.552 (1.121)	loss 7.238 (7.238)	prob 2.826 (2.826)	GS 31.703 (31.703)	mem 40.167
Train: [79][675/750]	BT 0.040 (1.157)	DT 0.005 (1.112)	loss 7.234 (7.234)	prob 2.614 (2.614)	GS 29.438 (29.438)	mem 40.170
Train: [79][680/750]	BT 0.060 (1.149)	DT 0.015 (1.104)	loss 7.080 (7.080)	prob 2.049 (2.049)	GS 31.531 (31.531)	mem 39.865
Train: [79][685/750]	BT 0.032 (1.157)	DT 0.001 (1.113)	loss 6.871 (6.871)	prob 3.044 (3.044)	GS 31.719 (31.719)	mem 39.821
Train: [79][690/750]	BT 0.037 (1.149)	DT 0.001 (1.105)	loss 6.881 (6.881)	prob 2.373 (2.373)	GS 39.406 (39.406)	mem 39.872
Train: [79][695/750]	BT 0.033 (1.162)	DT 0.002 (1.117)	loss 6.732 (6.732)	prob 3.152 (3.152)	GS 33.922 (33.922)	mem 39.960
Train: [79][700/750]	BT 0.075 (1.156)	DT 0.001 (1.111)	loss 6.788 (6.788)	prob 2.897 (2.897)	GS 35.406 (35.406)	mem 39.820
Train: [79][705/750]	BT 0.128 (1.148)	DT 0.038 (1.104)	loss 7.110 (7.110)	prob 2.488 (2.488)	GS 28.766 (28.766)	mem 39.927
Train: [79][710/750]	BT 0.060 (1.160)	DT 0.007 (1.115)	loss 7.004 (7.004)	prob 2.866 (2.866)	GS 35.797 (35.797)	mem 39.854
Train: [79][715/750]	BT 0.044 (1.152)	DT 0.014 (1.108)	loss 6.999 (6.999)	prob 2.878 (2.878)	GS 30.953 (30.953)	mem 39.854
Train: [79][720/750]	BT 2.202 (1.161)	DT 2.155 (1.116)	loss 7.051 (7.051)	prob 1.995 (1.995)	GS 35.078 (35.078)	mem 40.085
Train: [79][725/750]	BT 0.078 (1.153)	DT 0.002 (1.109)	loss 6.974 (6.974)	prob 2.558 (2.558)	GS 30.844 (30.844)	mem 39.990
Train: [79][730/750]	BT 8.460 (1.158)	DT 8.420 (1.114)	loss 6.903 (6.903)	prob 2.401 (2.401)	GS 31.203 (31.203)	mem 39.516
Train: [79][735/750]	BT 0.032 (1.152)	DT 0.001 (1.108)	loss 6.844 (6.844)	prob 2.612 (2.612)	GS 33.578 (33.578)	mem 39.356
Train: [79][740/750]	BT 0.023 (1.146)	DT 0.001 (1.102)	loss 6.891 (6.891)	prob 2.941 (2.941)	GS 32.328 (32.328)	mem 16.452
Train: [79][745/750]	BT 0.029 (1.145)	DT 0.001 (1.101)	loss 6.768 (6.768)	prob 3.142 (3.142)	GS 31.062 (31.062)	mem 10.456
Train: [79][750/750]	BT 0.033 (1.138)	DT 0.001 (1.094)	loss 6.969 (6.969)	prob 3.497 (3.497)	GS 31.969 (31.969)	mem 10.472
Train: [79][755/750]	BT 0.027 (1.135)	DT 0.001 (1.091)	loss 7.062 (7.062)	prob 2.900 (2.900)	GS 25.812 (25.812)	mem 7.560
epoch 79, total time 857.27
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [80][1/750]	BT 21.149 (21.149)	DT 21.100 (21.100)	loss 6.834 (6.834)	prob 3.091 (3.091)	GS 32.734 (32.734)	mem 38.519
Train: [80][5/750]	BT 0.097 (4.806)	DT 0.022 (4.762)	loss 6.775 (6.775)	prob 2.938 (2.938)	GS 33.250 (33.250)	mem 38.696
Train: [80][10/750]	BT 2.631 (2.723)	DT 2.595 (2.676)	loss 6.872 (6.872)	prob 2.280 (2.280)	GS 36.938 (36.938)	mem 38.750
Train: [80][15/750]	BT 0.091 (2.285)	DT 0.002 (2.233)	loss 6.814 (6.814)	prob 2.746 (2.746)	GS 36.844 (36.844)	mem 38.847
Train: [80][20/750]	BT 0.054 (2.018)	DT 0.002 (1.965)	loss 6.772 (6.772)	prob 2.640 (2.640)	GS 33.125 (33.125)	mem 38.930
Train: [80][25/750]	BT 2.476 (1.723)	DT 2.437 (1.671)	loss 6.922 (6.922)	prob 2.575 (2.575)	GS 36.359 (36.359)	mem 39.062
Train: [80][30/750]	BT 0.053 (1.766)	DT 0.005 (1.716)	loss 7.004 (7.004)	prob 3.187 (3.187)	GS 33.422 (33.422)	mem 39.015
Train: [80][35/750]	BT 0.058 (1.552)	DT 0.004 (1.503)	loss 6.996 (6.996)	prob 2.466 (2.466)	GS 31.109 (31.109)	mem 38.909
Train: [80][40/750]	BT 5.599 (1.668)	DT 5.548 (1.619)	loss 6.826 (6.826)	prob 3.200 (3.200)	GS 34.266 (34.266)	mem 39.104
Train: [80][45/750]	BT 0.067 (1.489)	DT 0.002 (1.440)	loss 6.732 (6.732)	prob 2.890 (2.890)	GS 31.594 (31.594)	mem 38.978
Train: [80][50/750]	BT 8.511 (1.515)	DT 8.479 (1.466)	loss 6.969 (6.969)	prob 2.674 (2.674)	GS 33.750 (33.750)	mem 39.085
Train: [80][55/750]	BT 0.036 (1.418)	DT 0.001 (1.370)	loss 6.924 (6.924)	prob 2.565 (2.565)	GS 30.719 (30.719)	mem 39.085
Train: [80][60/750]	BT 0.098 (1.327)	DT 0.029 (1.279)	loss 6.800 (6.800)	prob 2.257 (2.257)	GS 30.875 (30.875)	mem 39.399
Train: [80][65/750]	BT 0.039 (1.428)	DT 0.001 (1.381)	loss 7.070 (7.070)	prob 2.268 (2.268)	GS 27.875 (27.875)	mem 39.047
Train: [80][70/750]	BT 2.449 (1.364)	DT 2.392 (1.317)	loss 6.946 (6.946)	prob 2.225 (2.225)	GS 38.250 (38.250)	mem 39.154
Train: [80][75/750]	BT 0.037 (1.350)	DT 0.001 (1.302)	loss 6.942 (6.942)	prob 2.551 (2.551)	GS 30.688 (30.688)	mem 39.111
Train: [80][80/750]	BT 0.034 (1.320)	DT 0.001 (1.273)	loss 6.769 (6.769)	prob 2.570 (2.570)	GS 33.641 (33.641)	mem 39.131
Train: [80][85/750]	BT 0.043 (1.295)	DT 0.005 (1.248)	loss 6.798 (6.798)	prob 3.222 (3.222)	GS 32.078 (32.078)	mem 39.212
Train: [80][90/750]	BT 1.322 (1.311)	DT 1.257 (1.264)	loss 6.919 (6.919)	prob 2.266 (2.266)	GS 32.953 (32.953)	mem 39.135
Train: [80][95/750]	BT 0.037 (1.297)	DT 0.004 (1.251)	loss 6.848 (6.848)	prob 2.927 (2.927)	GS 32.281 (32.281)	mem 39.113
Train: [80][100/750]	BT 0.062 (1.270)	DT 0.003 (1.222)	loss 6.783 (6.783)	prob 3.059 (3.059)	GS 32.562 (32.562)	mem 39.156
Train: [80][105/750]	BT 0.065 (1.247)	DT 0.016 (1.200)	loss 6.799 (6.799)	prob 2.425 (2.425)	GS 33.141 (33.141)	mem 39.251
Train: [80][110/750]	BT 1.928 (1.284)	DT 1.895 (1.237)	loss 6.982 (6.982)	prob 2.115 (2.115)	GS 35.953 (35.953)	mem 39.461
Train: [80][115/750]	BT 0.078 (1.259)	DT 0.006 (1.211)	loss 6.955 (6.955)	prob 2.483 (2.483)	GS 31.344 (31.344)	mem 39.291
Train: [80][120/750]	BT 0.140 (1.269)	DT 0.022 (1.220)	loss 7.104 (7.104)	prob 2.059 (2.059)	GS 41.984 (41.984)	mem 39.146
Train: [80][125/750]	BT 0.073 (1.259)	DT 0.002 (1.210)	loss 6.876 (6.876)	prob 2.740 (2.740)	GS 33.953 (33.953)	mem 39.395
Train: [80][130/750]	BT 8.675 (1.279)	DT 8.650 (1.230)	loss 7.078 (7.078)	prob 2.731 (2.731)	GS 36.078 (36.078)	mem 39.236
Train: [80][135/750]	BT 0.060 (1.233)	DT 0.003 (1.185)	loss 6.818 (6.818)	prob 2.558 (2.558)	GS 31.266 (31.266)	mem 39.206
Train: [80][140/750]	BT 0.052 (1.221)	DT 0.014 (1.173)	loss 6.730 (6.730)	prob 2.389 (2.389)	GS 29.391 (29.391)	mem 39.214
Train: [80][145/750]	BT 0.039 (1.242)	DT 0.001 (1.194)	loss 7.026 (7.026)	prob 2.195 (2.195)	GS 31.016 (31.016)	mem 39.258
Train: [80][150/750]	BT 2.876 (1.236)	DT 2.841 (1.189)	loss 7.023 (7.023)	prob 2.011 (2.011)	GS 34.844 (34.844)	mem 39.225
Train: [80][155/750]	BT 0.032 (1.244)	DT 0.001 (1.197)	loss 6.909 (6.909)	prob 2.763 (2.763)	GS 28.703 (28.703)	mem 39.169
Train: [80][160/750]	BT 1.984 (1.219)	DT 1.939 (1.171)	loss 6.718 (6.718)	prob 3.469 (3.469)	GS 38.188 (38.188)	mem 39.254
Train: [80][165/750]	BT 0.038 (1.224)	DT 0.005 (1.176)	loss 6.771 (6.771)	prob 2.313 (2.313)	GS 28.797 (28.797)	mem 39.471
Train: [80][170/750]	BT 0.043 (1.222)	DT 0.001 (1.174)	loss 6.791 (6.791)	prob 3.076 (3.076)	GS 30.609 (30.609)	mem 39.521
Train: [80][175/750]	BT 0.033 (1.226)	DT 0.001 (1.178)	loss 7.086 (7.086)	prob 2.533 (2.533)	GS 28.984 (28.984)	mem 39.540
Train: [80][180/750]	BT 0.041 (1.238)	DT 0.001 (1.190)	loss 6.969 (6.969)	prob 2.531 (2.531)	GS 36.500 (36.500)	mem 39.579
Train: [80][185/750]	BT 0.072 (1.207)	DT 0.004 (1.159)	loss 6.988 (6.988)	prob 2.302 (2.302)	GS 34.266 (34.266)	mem 39.578
Train: [80][190/750]	BT 10.451 (1.240)	DT 10.415 (1.192)	loss 6.885 (6.885)	prob 2.449 (2.449)	GS 31.094 (31.094)	mem 39.694
Train: [80][195/750]	BT 0.049 (1.209)	DT 0.009 (1.162)	loss 6.848 (6.848)	prob 1.928 (1.928)	GS 34.828 (34.828)	mem 39.600
Train: [80][200/750]	BT 0.026 (1.197)	DT 0.001 (1.150)	loss 6.835 (6.835)	prob 2.506 (2.506)	GS 31.578 (31.578)	mem 39.607
Train: [80][205/750]	BT 0.038 (1.205)	DT 0.002 (1.157)	loss 6.865 (6.865)	prob 2.838 (2.838)	GS 30.406 (30.406)	mem 39.729
Train: [80][210/750]	BT 6.678 (1.209)	DT 6.576 (1.162)	loss 7.437 (7.437)	prob 1.621 (1.621)	GS 31.172 (31.172)	mem 39.670
Train: [80][215/750]	BT 0.032 (1.208)	DT 0.006 (1.161)	loss 6.890 (6.890)	prob 3.032 (3.032)	GS 32.109 (32.109)	mem 39.620
Train: [80][220/750]	BT 0.066 (1.182)	DT 0.006 (1.135)	loss 6.909 (6.909)	prob 1.858 (1.858)	GS 35.688 (35.688)	mem 39.919
Train: [80][225/750]	BT 0.043 (1.192)	DT 0.008 (1.144)	loss 7.096 (7.096)	prob 2.472 (2.472)	GS 30.875 (30.875)	mem 39.622
Train: [80][230/750]	BT 0.031 (1.190)	DT 0.001 (1.144)	loss 6.757 (6.757)	prob 2.690 (2.690)	GS 35.844 (35.844)	mem 39.638
Train: [80][235/750]	BT 0.062 (1.210)	DT 0.027 (1.163)	loss 7.016 (7.016)	prob 2.824 (2.824)	GS 26.812 (26.812)	mem 39.644
Train: [80][240/750]	BT 0.033 (1.189)	DT 0.001 (1.143)	loss 6.841 (6.841)	prob 2.612 (2.612)	GS 34.562 (34.562)	mem 39.694
Train: [80][245/750]	BT 0.041 (1.169)	DT 0.001 (1.123)	loss 6.934 (6.934)	prob 2.766 (2.766)	GS 33.891 (33.891)	mem 39.696
Train: [80][250/750]	BT 5.363 (1.199)	DT 5.319 (1.153)	loss 6.810 (6.810)	prob 2.351 (2.351)	GS 34.734 (34.734)	mem 39.817
Train: [80][255/750]	BT 0.044 (1.176)	DT 0.001 (1.130)	loss 7.310 (7.310)	prob 2.755 (2.755)	GS 34.375 (34.375)	mem 39.819
Train: [80][260/750]	BT 0.033 (1.183)	DT 0.001 (1.137)	loss 6.825 (6.825)	prob 2.711 (2.711)	GS 32.469 (32.469)	mem 39.892
Train: [80][265/750]	BT 0.033 (1.188)	DT 0.001 (1.142)	loss 7.070 (7.070)	prob 2.245 (2.245)	GS 33.828 (33.828)	mem 39.980
Train: [80][270/750]	BT 3.033 (1.179)	DT 2.996 (1.132)	loss 6.839 (6.839)	prob 3.118 (3.118)	GS 34.344 (34.344)	mem 39.912
Train: [80][275/750]	BT 0.031 (1.196)	DT 0.001 (1.150)	loss 6.966 (6.966)	prob 2.362 (2.362)	GS 29.703 (29.703)	mem 39.866
Train: [80][280/750]	BT 0.090 (1.176)	DT 0.021 (1.130)	loss 6.692 (6.692)	prob 2.671 (2.671)	GS 33.141 (33.141)	mem 39.971
Train: [80][285/750]	BT 0.035 (1.156)	DT 0.001 (1.110)	loss 6.889 (6.889)	prob 2.347 (2.347)	GS 32.969 (32.969)	mem 39.822
Train: [80][290/750]	BT 0.053 (1.179)	DT 0.012 (1.133)	loss 6.967 (6.967)	prob 2.505 (2.505)	GS 30.906 (30.906)	mem 39.953
Train: [80][295/750]	BT 0.038 (1.159)	DT 0.001 (1.114)	loss 6.850 (6.850)	prob 2.625 (2.625)	GS 31.859 (31.859)	mem 39.838
Train: [80][300/750]	BT 0.032 (1.196)	DT 0.001 (1.151)	loss 6.909 (6.909)	prob 2.815 (2.815)	GS 32.359 (32.359)	mem 39.854
Train: [80][305/750]	BT 0.044 (1.177)	DT 0.001 (1.132)	loss 6.868 (6.868)	prob 2.502 (2.502)	GS 29.125 (29.125)	mem 39.819
Train: [80][310/750]	BT 13.584 (1.202)	DT 13.536 (1.157)	loss 6.783 (6.783)	prob 2.528 (2.528)	GS 34.641 (34.641)	mem 39.920
Train: [80][315/750]	BT 0.084 (1.184)	DT 0.015 (1.139)	loss 6.875 (6.875)	prob 2.632 (2.632)	GS 29.750 (29.750)	mem 40.015
Train: [80][320/750]	BT 0.042 (1.166)	DT 0.001 (1.121)	loss 6.880 (6.880)	prob 3.228 (3.228)	GS 34.453 (34.453)	mem 39.922
Train: [80][325/750]	BT 0.041 (1.191)	DT 0.018 (1.146)	loss 6.674 (6.674)	prob 2.669 (2.669)	GS 29.578 (29.578)	mem 40.166
Train: [80][330/750]	BT 0.072 (1.174)	DT 0.002 (1.129)	loss 6.738 (6.738)	prob 2.822 (2.822)	GS 33.547 (33.547)	mem 39.924
Train: [80][335/750]	BT 0.033 (1.196)	DT 0.001 (1.151)	loss 7.014 (7.014)	prob 2.707 (2.707)	GS 34.031 (34.031)	mem 39.964
Train: [80][340/750]	BT 0.030 (1.179)	DT 0.001 (1.134)	loss 6.820 (6.820)	prob 2.318 (2.318)	GS 29.781 (29.781)	mem 39.965
Train: [80][345/750]	BT 0.067 (1.163)	DT 0.033 (1.118)	loss 6.901 (6.901)	prob 2.229 (2.229)	GS 33.531 (33.531)	mem 39.965
Train: [80][350/750]	BT 0.049 (1.187)	DT 0.014 (1.142)	loss 6.679 (6.679)	prob 2.732 (2.732)	GS 33.984 (33.984)	mem 39.987
Train: [80][355/750]	BT 0.056 (1.171)	DT 0.013 (1.126)	loss 7.023 (7.023)	prob 2.311 (2.311)	GS 27.281 (27.281)	mem 40.031
Train: [80][360/750]	BT 0.032 (1.186)	DT 0.001 (1.141)	loss 7.095 (7.095)	prob 1.961 (1.961)	GS 33.391 (33.391)	mem 40.006
Train: [80][365/750]	BT 0.059 (1.170)	DT 0.002 (1.125)	loss 6.979 (6.979)	prob 2.292 (2.292)	GS 31.500 (31.500)	mem 40.009
Train: [80][370/750]	BT 9.081 (1.179)	DT 9.040 (1.135)	loss 6.792 (6.792)	prob 2.527 (2.527)	GS 32.172 (32.172)	mem 39.980
Train: [80][375/750]	BT 0.139 (1.164)	DT 0.002 (1.119)	loss 7.108 (7.108)	prob 2.207 (2.207)	GS 28.641 (28.641)	mem 39.981
Train: [80][380/750]	BT 0.064 (1.150)	DT 0.004 (1.105)	loss 6.744 (6.744)	prob 2.376 (2.376)	GS 34.125 (34.125)	mem 39.982
Train: [80][385/750]	BT 0.030 (1.168)	DT 0.001 (1.124)	loss 7.070 (7.070)	prob 1.915 (1.915)	GS 31.500 (31.500)	mem 39.869
Train: [80][390/750]	BT 0.045 (1.154)	DT 0.001 (1.109)	loss 6.764 (6.764)	prob 1.740 (1.740)	GS 32.594 (32.594)	mem 39.882
Train: [80][395/750]	BT 0.052 (1.168)	DT 0.010 (1.123)	loss 7.182 (7.182)	prob 1.878 (1.878)	GS 29.641 (29.641)	mem 39.953
Train: [80][400/750]	BT 0.033 (1.154)	DT 0.002 (1.109)	loss 6.911 (6.911)	prob 2.479 (2.479)	GS 30.172 (30.172)	mem 39.953
Train: [80][405/750]	BT 0.084 (1.140)	DT 0.009 (1.096)	loss 6.941 (6.941)	prob 2.073 (2.073)	GS 28.734 (28.734)	mem 39.976
Train: [80][410/750]	BT 0.059 (1.161)	DT 0.003 (1.116)	loss 6.890 (6.890)	prob 2.096 (2.096)	GS 32.344 (32.344)	mem 39.844
Train: [80][415/750]	BT 0.035 (1.147)	DT 0.002 (1.103)	loss 6.992 (6.992)	prob 2.955 (2.955)	GS 29.172 (29.172)	mem 40.053
Train: [80][420/750]	BT 0.032 (1.166)	DT 0.001 (1.121)	loss 6.744 (6.744)	prob 2.456 (2.456)	GS 36.469 (36.469)	mem 40.068
Train: [80][425/750]	BT 0.050 (1.152)	DT 0.001 (1.108)	loss 7.009 (7.009)	prob 1.494 (1.494)	GS 46.984 (46.984)	mem 39.922
Train: [80][430/750]	BT 14.318 (1.173)	DT 14.293 (1.128)	loss 6.943 (6.943)	prob 2.182 (2.182)	GS 33.578 (33.578)	mem 39.912
Train: [80][435/750]	BT 0.035 (1.160)	DT 0.002 (1.115)	loss 6.903 (6.903)	prob 3.140 (3.140)	GS 33.500 (33.500)	mem 39.989
Train: [80][440/750]	BT 0.087 (1.147)	DT 0.002 (1.103)	loss 6.912 (6.912)	prob 3.170 (3.170)	GS 37.422 (37.422)	mem 39.961
Train: [80][445/750]	BT 0.038 (1.161)	DT 0.001 (1.117)	loss 7.211 (7.211)	prob 2.220 (2.220)	GS 28.156 (28.156)	mem 39.921
Train: [80][450/750]	BT 0.047 (1.149)	DT 0.004 (1.104)	loss 6.737 (6.737)	prob 2.866 (2.866)	GS 35.234 (35.234)	mem 39.881
Train: [80][455/750]	BT 0.028 (1.163)	DT 0.001 (1.118)	loss 6.708 (6.708)	prob 3.291 (3.291)	GS 30.812 (30.812)	mem 39.839
Train: [80][460/750]	BT 0.022 (1.151)	DT 0.001 (1.106)	loss 7.063 (7.063)	prob 2.723 (2.723)	GS 30.109 (30.109)	mem 39.849
Train: [80][465/750]	BT 0.059 (1.139)	DT 0.004 (1.094)	loss 7.014 (7.014)	prob 1.935 (1.935)	GS 30.156 (30.156)	mem 39.840
Train: [80][470/750]	BT 0.047 (1.156)	DT 0.005 (1.111)	loss 6.774 (6.774)	prob 2.591 (2.591)	GS 34.203 (34.203)	mem 39.920
Train: [80][475/750]	BT 0.080 (1.144)	DT 0.002 (1.100)	loss 6.838 (6.838)	prob 2.314 (2.314)	GS 31.578 (31.578)	mem 39.961
Train: [80][480/750]	BT 0.036 (1.156)	DT 0.001 (1.111)	loss 6.862 (6.862)	prob 2.044 (2.044)	GS 34.719 (34.719)	mem 39.872
Train: [80][485/750]	BT 0.065 (1.144)	DT 0.027 (1.100)	loss 6.800 (6.800)	prob 3.107 (3.107)	GS 32.266 (32.266)	mem 39.891
Train: [80][490/750]	BT 10.811 (1.155)	DT 10.779 (1.111)	loss 7.007 (7.007)	prob 2.593 (2.593)	GS 35.125 (35.125)	mem 39.886
Train: [80][495/750]	BT 0.045 (1.150)	DT 0.006 (1.106)	loss 7.022 (7.022)	prob 2.372 (2.372)	GS 30.812 (30.812)	mem 39.903
Train: [80][500/750]	BT 0.135 (1.139)	DT 0.005 (1.095)	loss 6.620 (6.620)	prob 2.318 (2.318)	GS 34.094 (34.094)	mem 39.904
Train: [80][505/750]	BT 0.035 (1.143)	DT 0.002 (1.099)	loss 6.685 (6.685)	prob 2.705 (2.705)	GS 28.812 (28.812)	mem 39.910
Train: [80][510/750]	BT 0.095 (1.140)	DT 0.001 (1.096)	loss 6.940 (6.940)	prob 2.445 (2.445)	GS 34.172 (34.172)	mem 39.907
Train: [80][515/750]	BT 0.034 (1.141)	DT 0.001 (1.097)	loss 7.038 (7.038)	prob 2.389 (2.389)	GS 25.266 (25.266)	mem 39.971
Train: [80][520/750]	BT 0.041 (1.141)	DT 0.001 (1.096)	loss 7.029 (7.029)	prob 2.244 (2.244)	GS 31.156 (31.156)	mem 39.980
Train: [80][525/750]	BT 0.035 (1.130)	DT 0.002 (1.086)	loss 6.840 (6.840)	prob 2.647 (2.647)	GS 29.656 (29.656)	mem 39.939
Train: [80][530/750]	BT 0.029 (1.147)	DT 0.001 (1.103)	loss 6.768 (6.768)	prob 2.269 (2.269)	GS 31.141 (31.141)	mem 39.947
Train: [80][535/750]	BT 0.082 (1.137)	DT 0.008 (1.093)	loss 6.530 (6.530)	prob 2.395 (2.395)	GS 38.078 (38.078)	mem 39.942
Train: [80][540/750]	BT 5.904 (1.151)	DT 5.873 (1.107)	loss 6.776 (6.776)	prob 2.603 (2.603)	GS 34.703 (34.703)	mem 40.031
Train: [80][545/750]	BT 0.032 (1.141)	DT 0.001 (1.097)	loss 6.885 (6.885)	prob 2.639 (2.639)	GS 36.969 (36.969)	mem 39.976
Train: [80][550/750]	BT 4.515 (1.139)	DT 4.468 (1.095)	loss 6.970 (6.970)	prob 2.220 (2.220)	GS 35.391 (35.391)	mem 40.004
Train: [80][555/750]	BT 0.032 (1.138)	DT 0.002 (1.093)	loss 6.777 (6.777)	prob 2.856 (2.856)	GS 34.062 (34.062)	mem 40.104
Train: [80][560/750]	BT 0.032 (1.128)	DT 0.001 (1.083)	loss 6.993 (6.993)	prob 2.316 (2.316)	GS 31.594 (31.594)	mem 40.034
Train: [80][565/750]	BT 0.028 (1.139)	DT 0.001 (1.095)	loss 6.926 (6.926)	prob 2.798 (2.798)	GS 28.125 (28.125)	mem 39.975
Train: [80][570/750]	BT 0.072 (1.130)	DT 0.009 (1.086)	loss 6.791 (6.791)	prob 2.603 (2.603)	GS 34.516 (34.516)	mem 39.950
Train: [80][575/750]	BT 0.059 (1.140)	DT 0.017 (1.096)	loss 6.929 (6.929)	prob 2.534 (2.534)	GS 28.766 (28.766)	mem 39.951
Train: [80][580/750]	BT 0.038 (1.131)	DT 0.005 (1.087)	loss 7.066 (7.066)	prob 2.646 (2.646)	GS 35.172 (35.172)	mem 39.953
Train: [80][585/750]	BT 0.058 (1.122)	DT 0.002 (1.077)	loss 6.922 (6.922)	prob 2.745 (2.745)	GS 32.953 (32.953)	mem 39.953
Train: [80][590/750]	BT 0.024 (1.138)	DT 0.001 (1.093)	loss 6.760 (6.760)	prob 2.584 (2.584)	GS 33.484 (33.484)	mem 39.966
Train: [80][595/750]	BT 0.030 (1.128)	DT 0.001 (1.084)	loss 6.893 (6.893)	prob 2.392 (2.392)	GS 32.516 (32.516)	mem 40.003
Train: [80][600/750]	BT 0.104 (1.139)	DT 0.075 (1.095)	loss 6.933 (6.933)	prob 2.919 (2.919)	GS 34.031 (34.031)	mem 39.964
Train: [80][605/750]	BT 0.048 (1.130)	DT 0.011 (1.086)	loss 6.856 (6.856)	prob 2.834 (2.834)	GS 30.312 (30.312)	mem 39.966
Train: [80][610/750]	BT 14.541 (1.145)	DT 14.509 (1.101)	loss 6.880 (6.880)	prob 2.818 (2.818)	GS 33.812 (33.812)	mem 39.952
Train: [80][615/750]	BT 0.121 (1.136)	DT 0.016 (1.092)	loss 6.975 (6.975)	prob 2.209 (2.209)	GS 33.359 (33.359)	mem 39.991
Train: [80][620/750]	BT 0.068 (1.127)	DT 0.002 (1.083)	loss 7.048 (7.048)	prob 1.977 (1.977)	GS 34.328 (34.328)	mem 39.952
Train: [80][625/750]	BT 0.028 (1.143)	DT 0.001 (1.099)	loss 6.858 (6.858)	prob 3.445 (3.445)	GS 28.766 (28.766)	mem 40.027
Train: [80][630/750]	BT 0.048 (1.134)	DT 0.016 (1.090)	loss 6.867 (6.867)	prob 2.554 (2.554)	GS 35.625 (35.625)	mem 40.026
Train: [80][635/750]	BT 0.031 (1.141)	DT 0.001 (1.097)	loss 7.059 (7.059)	prob 1.919 (1.919)	GS 32.516 (32.516)	mem 40.009
Train: [80][640/750]	BT 0.041 (1.132)	DT 0.010 (1.089)	loss 7.129 (7.129)	prob 2.302 (2.302)	GS 31.812 (31.812)	mem 40.010
Train: [80][645/750]	BT 0.046 (1.124)	DT 0.002 (1.080)	loss 7.129 (7.129)	prob 2.493 (2.493)	GS 28.281 (28.281)	mem 40.109
Train: [80][650/750]	BT 0.037 (1.133)	DT 0.002 (1.090)	loss 6.885 (6.885)	prob 2.391 (2.391)	GS 34.516 (34.516)	mem 39.964
Train: [80][655/750]	BT 0.047 (1.125)	DT 0.001 (1.082)	loss 6.834 (6.834)	prob 2.330 (2.330)	GS 33.312 (33.312)	mem 40.006
arpack error, retry= 0
Train: [80][660/750]	BT 0.050 (1.138)	DT 0.012 (1.094)	loss 6.953 (6.953)	prob 2.106 (2.106)	GS 31.016 (31.016)	mem 39.908
Train: [80][665/750]	BT 0.022 (1.130)	DT 0.001 (1.086)	loss 7.016 (7.016)	prob 2.808 (2.808)	GS 32.812 (32.812)	mem 39.909
Train: [80][670/750]	BT 12.623 (1.140)	DT 12.572 (1.097)	loss 6.899 (6.899)	prob 2.657 (2.657)	GS 34.500 (34.500)	mem 39.957
Train: [80][675/750]	BT 0.033 (1.132)	DT 0.002 (1.089)	loss 7.023 (7.023)	prob 2.429 (2.429)	GS 33.250 (33.250)	mem 39.957
Train: [80][680/750]	BT 0.060 (1.124)	DT 0.006 (1.081)	loss 6.858 (6.858)	prob 2.865 (2.865)	GS 35.203 (35.203)	mem 39.957
Train: [80][685/750]	BT 0.025 (1.138)	DT 0.002 (1.094)	loss 7.000 (7.000)	prob 2.270 (2.270)	GS 27.938 (27.938)	mem 39.939
Train: [80][690/750]	BT 0.046 (1.130)	DT 0.001 (1.086)	loss 7.005 (7.005)	prob 1.950 (1.950)	GS 36.453 (36.453)	mem 39.975
Train: [80][695/750]	BT 0.025 (1.142)	DT 0.001 (1.099)	loss 7.198 (7.198)	prob 2.101 (2.101)	GS 32.078 (32.078)	mem 39.906
Train: [80][700/750]	BT 0.020 (1.134)	DT 0.001 (1.091)	loss 6.891 (6.891)	prob 2.094 (2.094)	GS 32.594 (32.594)	mem 39.907
Train: [80][705/750]	BT 0.111 (1.127)	DT 0.014 (1.083)	loss 6.678 (6.678)	prob 2.627 (2.627)	GS 26.609 (26.609)	mem 40.101
Train: [80][710/750]	BT 0.035 (1.136)	DT 0.004 (1.093)	loss 7.003 (7.003)	prob 2.708 (2.708)	GS 35.172 (35.172)	mem 40.009
Train: [80][715/750]	BT 0.068 (1.129)	DT 0.002 (1.086)	loss 6.971 (6.971)	prob 2.487 (2.487)	GS 36.172 (36.172)	mem 39.946
Train: [80][720/750]	BT 0.128 (1.137)	DT 0.097 (1.094)	loss 6.931 (6.931)	prob 2.776 (2.776)	GS 32.891 (32.891)	mem 39.952
Train: [80][725/750]	BT 0.030 (1.129)	DT 0.001 (1.086)	loss 7.167 (7.167)	prob 2.463 (2.463)	GS 29.812 (29.812)	mem 39.976
Train: [80][730/750]	BT 11.250 (1.137)	DT 11.213 (1.094)	loss 6.779 (6.779)	prob 2.729 (2.729)	GS 36.922 (36.922)	mem 39.494
Train: [80][735/750]	BT 0.061 (1.133)	DT 0.005 (1.090)	loss 7.003 (7.003)	prob 2.389 (2.389)	GS 32.266 (32.266)	mem 39.484
Train: [80][740/750]	BT 0.049 (1.126)	DT 0.007 (1.083)	loss 7.032 (7.032)	prob 2.949 (2.949)	GS 33.812 (33.812)	mem 39.420
Train: [80][745/750]	BT 0.032 (1.126)	DT 0.001 (1.083)	loss 7.065 (7.065)	prob 1.744 (1.744)	GS 36.875 (36.875)	mem 10.621
Train: [80][750/750]	BT 0.027 (1.119)	DT 0.001 (1.076)	loss 6.567 (6.567)	prob 2.991 (2.991)	GS 37.062 (37.062)	mem 10.620
Train: [80][755/750]	BT 0.033 (1.114)	DT 0.001 (1.071)	loss 6.733 (6.733)	prob 2.281 (2.281)	GS 30.719 (30.719)	mem 10.592
epoch 80, total time 842.30
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [81][1/750]	BT 25.877 (25.877)	DT 25.772 (25.772)	loss 6.925 (6.925)	prob 2.447 (2.447)	GS 37.031 (37.031)	mem 38.630
Train: [81][5/750]	BT 0.076 (5.207)	DT 0.002 (5.155)	loss 6.700 (6.700)	prob 2.241 (2.241)	GS 29.844 (29.844)	mem 38.634
Train: [81][10/750]	BT 0.046 (2.710)	DT 0.002 (2.665)	loss 6.569 (6.569)	prob 2.529 (2.529)	GS 32.938 (32.938)	mem 38.692
Train: [81][15/750]	BT 0.044 (2.379)	DT 0.004 (2.335)	loss 6.635 (6.635)	prob 2.798 (2.798)	GS 32.312 (32.312)	mem 38.734
Train: [81][20/750]	BT 0.050 (1.900)	DT 0.002 (1.850)	loss 6.727 (6.727)	prob 1.949 (1.949)	GS 35.062 (35.062)	mem 38.746
Train: [81][25/750]	BT 1.374 (1.771)	DT 1.264 (1.719)	loss 6.772 (6.772)	prob 2.485 (2.485)	GS 30.625 (30.625)	mem 38.871
Train: [81][30/750]	BT 3.970 (1.762)	DT 3.939 (1.710)	loss 6.708 (6.708)	prob 2.533 (2.533)	GS 32.531 (32.531)	mem 38.907
Train: [81][35/750]	BT 0.051 (1.556)	DT 0.003 (1.505)	loss 6.844 (6.844)	prob 2.382 (2.382)	GS 30.703 (30.703)	mem 38.951
Train: [81][40/750]	BT 0.038 (1.599)	DT 0.001 (1.547)	loss 6.679 (6.679)	prob 3.240 (3.240)	GS 36.859 (36.859)	mem 38.879
Train: [81][45/750]	BT 0.037 (1.514)	DT 0.001 (1.463)	loss 6.954 (6.954)	prob 2.516 (2.516)	GS 35.016 (35.016)	mem 39.115
Train: [81][50/750]	BT 8.835 (1.577)	DT 8.730 (1.525)	loss 6.991 (6.991)	prob 2.914 (2.914)	GS 33.297 (33.297)	mem 38.915
Train: [81][55/750]	BT 0.043 (1.496)	DT 0.007 (1.444)	loss 6.986 (6.986)	prob 2.258 (2.258)	GS 31.750 (31.750)	mem 38.898
Train: [81][60/750]	BT 0.185 (1.379)	DT 0.143 (1.327)	loss 6.899 (6.899)	prob 2.630 (2.630)	GS 32.312 (32.312)	mem 38.911
Train: [81][65/750]	BT 0.030 (1.393)	DT 0.001 (1.343)	loss 6.937 (6.937)	prob 2.343 (2.343)	GS 31.703 (31.703)	mem 39.053
Train: [81][70/750]	BT 0.043 (1.400)	DT 0.002 (1.350)	loss 6.619 (6.619)	prob 3.323 (3.323)	GS 37.438 (37.438)	mem 39.042
Train: [81][75/750]	BT 0.045 (1.359)	DT 0.007 (1.309)	loss 7.072 (7.072)	prob 2.006 (2.006)	GS 30.078 (30.078)	mem 39.051
Train: [81][80/750]	BT 0.035 (1.377)	DT 0.007 (1.327)	loss 6.738 (6.738)	prob 2.600 (2.600)	GS 37.500 (37.500)	mem 39.084
Train: [81][85/750]	BT 0.031 (1.299)	DT 0.001 (1.250)	loss 6.913 (6.913)	prob 2.932 (2.932)	GS 34.484 (34.484)	mem 39.084
Train: [81][90/750]	BT 7.245 (1.361)	DT 7.202 (1.312)	loss 6.912 (6.912)	prob 2.081 (2.081)	GS 34.422 (34.422)	mem 39.206
Train: [81][95/750]	BT 0.061 (1.293)	DT 0.002 (1.244)	loss 6.549 (6.549)	prob 2.496 (2.496)	GS 33.109 (33.109)	mem 39.094
Train: [81][100/750]	BT 0.056 (1.285)	DT 0.010 (1.236)	loss 6.653 (6.653)	prob 2.788 (2.788)	GS 33.891 (33.891)	mem 39.230
Train: [81][105/750]	BT 0.048 (1.326)	DT 0.015 (1.278)	loss 7.241 (7.241)	prob 2.258 (2.258)	GS 32.750 (32.750)	mem 39.009
Train: [81][110/750]	BT 2.695 (1.293)	DT 2.652 (1.244)	loss 7.004 (7.004)	prob 2.058 (2.058)	GS 33.844 (33.844)	mem 39.151
Train: [81][115/750]	BT 0.041 (1.353)	DT 0.001 (1.304)	loss 6.978 (6.978)	prob 3.152 (3.152)	GS 28.531 (28.531)	mem 39.131
Train: [81][120/750]	BT 0.027 (1.298)	DT 0.001 (1.250)	loss 6.892 (6.892)	prob 2.389 (2.389)	GS 33.547 (33.547)	mem 39.132
Train: [81][125/750]	BT 0.033 (1.248)	DT 0.002 (1.200)	loss 6.711 (6.711)	prob 2.893 (2.893)	GS 39.297 (39.297)	mem 39.134
Train: [81][130/750]	BT 0.081 (1.290)	DT 0.001 (1.242)	loss 6.974 (6.974)	prob 2.687 (2.687)	GS 33.656 (33.656)	mem 39.391
Train: [81][135/750]	BT 0.057 (1.257)	DT 0.015 (1.210)	loss 7.004 (7.004)	prob 2.151 (2.151)	GS 30.594 (30.594)	mem 39.323
Train: [81][140/750]	BT 0.033 (1.272)	DT 0.002 (1.224)	loss 6.895 (6.895)	prob 2.079 (2.079)	GS 36.469 (36.469)	mem 39.509
Train: [81][145/750]	BT 0.029 (1.229)	DT 0.001 (1.182)	loss 6.851 (6.851)	prob 2.410 (2.410)	GS 31.266 (31.266)	mem 39.509
Train: [81][150/750]	BT 6.891 (1.272)	DT 6.814 (1.225)	loss 6.855 (6.855)	prob 2.589 (2.589)	GS 31.203 (31.203)	mem 39.433
Train: [81][155/750]	BT 0.066 (1.234)	DT 0.002 (1.185)	loss 6.930 (6.930)	prob 2.571 (2.571)	GS 34.219 (34.219)	mem 39.426
Train: [81][160/750]	BT 0.033 (1.231)	DT 0.001 (1.183)	loss 6.968 (6.968)	prob 2.602 (2.602)	GS 33.766 (33.766)	mem 39.488
Train: [81][165/750]	BT 0.052 (1.244)	DT 0.001 (1.196)	loss 7.490 (7.490)	prob 2.208 (2.208)	GS 39.375 (39.375)	mem 39.517
Train: [81][170/750]	BT 8.455 (1.259)	DT 8.408 (1.210)	loss 7.110 (7.110)	prob 2.636 (2.636)	GS 35.578 (35.578)	mem 39.593
Train: [81][175/750]	BT 0.051 (1.267)	DT 0.010 (1.218)	loss 7.110 (7.110)	prob 2.140 (2.140)	GS 28.828 (28.828)	mem 39.509
Train: [81][180/750]	BT 0.047 (1.233)	DT 0.010 (1.184)	loss 6.842 (6.842)	prob 3.009 (3.009)	GS 35.781 (35.781)	mem 39.510
Train: [81][185/750]	BT 0.046 (1.237)	DT 0.002 (1.188)	loss 7.075 (7.075)	prob 2.410 (2.410)	GS 38.656 (38.656)	mem 39.566
Train: [81][190/750]	BT 0.033 (1.235)	DT 0.001 (1.186)	loss 6.899 (6.899)	prob 1.951 (1.951)	GS 35.203 (35.203)	mem 39.621
Train: [81][195/750]	BT 0.047 (1.255)	DT 0.002 (1.207)	loss 6.985 (6.985)	prob 2.219 (2.219)	GS 34.344 (34.344)	mem 39.594
Train: [81][200/750]	BT 0.049 (1.237)	DT 0.003 (1.188)	loss 6.775 (6.775)	prob 3.231 (3.231)	GS 34.500 (34.500)	mem 39.914
Train: [81][205/750]	BT 0.048 (1.208)	DT 0.007 (1.159)	loss 6.816 (6.816)	prob 3.077 (3.077)	GS 27.344 (27.344)	mem 39.915
Train: [81][210/750]	BT 1.932 (1.245)	DT 1.854 (1.196)	loss 6.965 (6.965)	prob 2.262 (2.262)	GS 34.328 (34.328)	mem 39.749
Train: [81][215/750]	BT 0.032 (1.217)	DT 0.002 (1.168)	loss 7.032 (7.032)	prob 2.659 (2.659)	GS 33.094 (33.094)	mem 39.683
Train: [81][220/750]	BT 0.064 (1.244)	DT 0.002 (1.195)	loss 6.772 (6.772)	prob 2.754 (2.754)	GS 35.766 (35.766)	mem 39.731
Train: [81][225/750]	BT 0.045 (1.220)	DT 0.003 (1.171)	loss 6.998 (6.998)	prob 2.232 (2.232)	GS 31.297 (31.297)	mem 39.668
Train: [81][230/750]	BT 16.995 (1.268)	DT 16.955 (1.220)	loss 6.981 (6.981)	prob 2.438 (2.438)	GS 38.453 (38.453)	mem 39.945
Train: [81][235/750]	BT 0.035 (1.242)	DT 0.003 (1.194)	loss 6.986 (6.986)	prob 2.586 (2.586)	GS 30.562 (30.562)	mem 39.796
Train: [81][240/750]	BT 0.035 (1.218)	DT 0.001 (1.169)	loss 7.132 (7.132)	prob 2.121 (2.121)	GS 32.750 (32.750)	mem 39.885
Train: [81][245/750]	BT 0.027 (1.235)	DT 0.004 (1.187)	loss 6.953 (6.953)	prob 2.686 (2.686)	GS 35.109 (35.109)	mem 39.883
Train: [81][250/750]	BT 0.027 (1.212)	DT 0.001 (1.163)	loss 7.081 (7.081)	prob 2.076 (2.076)	GS 37.844 (37.844)	mem 39.887
Train: [81][255/750]	BT 0.028 (1.245)	DT 0.003 (1.196)	loss 6.680 (6.680)	prob 2.784 (2.784)	GS 30.297 (30.297)	mem 39.805
Train: [81][260/750]	BT 0.031 (1.222)	DT 0.001 (1.173)	loss 6.766 (6.766)	prob 2.534 (2.534)	GS 33.719 (33.719)	mem 39.812
Train: [81][265/750]	BT 0.036 (1.200)	DT 0.003 (1.151)	loss 7.138 (7.138)	prob 2.824 (2.824)	GS 36.500 (36.500)	mem 39.923
Train: [81][270/750]	BT 0.032 (1.222)	DT 0.002 (1.174)	loss 7.118 (7.118)	prob 2.606 (2.606)	GS 34.438 (34.438)	mem 39.854
Train: [81][275/750]	BT 0.046 (1.201)	DT 0.002 (1.153)	loss 7.025 (7.025)	prob 2.470 (2.470)	GS 32.266 (32.266)	mem 39.857
Train: [81][280/750]	BT 0.038 (1.220)	DT 0.004 (1.172)	loss 7.060 (7.060)	prob 2.704 (2.704)	GS 36.469 (36.469)	mem 39.837
Train: [81][285/750]	BT 0.096 (1.199)	DT 0.020 (1.151)	loss 6.995 (6.995)	prob 2.850 (2.850)	GS 30.469 (30.469)	mem 39.984
Train: [81][290/750]	BT 12.175 (1.221)	DT 12.132 (1.173)	loss 6.996 (6.996)	prob 2.378 (2.378)	GS 32.531 (32.531)	mem 39.846
Train: [81][295/750]	BT 0.056 (1.207)	DT 0.009 (1.159)	loss 6.829 (6.829)	prob 2.240 (2.240)	GS 28.453 (28.453)	mem 40.123
Train: [81][300/750]	BT 0.050 (1.188)	DT 0.001 (1.140)	loss 6.912 (6.912)	prob 2.560 (2.560)	GS 31.875 (31.875)	mem 39.805
Train: [81][305/750]	BT 0.053 (1.204)	DT 0.012 (1.156)	loss 6.996 (6.996)	prob 2.321 (2.321)	GS 29.453 (29.453)	mem 39.823
Train: [81][310/750]	BT 0.046 (1.199)	DT 0.007 (1.151)	loss 6.708 (6.708)	prob 2.346 (2.346)	GS 32.312 (32.312)	mem 39.785
Train: [81][315/750]	BT 0.069 (1.201)	DT 0.018 (1.153)	loss 6.832 (6.832)	prob 2.425 (2.425)	GS 30.781 (30.781)	mem 40.025
Train: [81][320/750]	BT 0.036 (1.208)	DT 0.004 (1.161)	loss 6.624 (6.624)	prob 2.916 (2.916)	GS 33.906 (33.906)	mem 39.932
Train: [81][325/750]	BT 0.090 (1.191)	DT 0.010 (1.143)	loss 7.018 (7.018)	prob 1.920 (1.920)	GS 29.578 (29.578)	mem 39.945
Train: [81][330/750]	BT 3.550 (1.202)	DT 3.505 (1.154)	loss 6.744 (6.744)	prob 2.645 (2.645)	GS 37.906 (37.906)	mem 39.843
Train: [81][335/750]	BT 0.038 (1.185)	DT 0.001 (1.137)	loss 7.034 (7.034)	prob 2.229 (2.229)	GS 31.312 (31.312)	mem 39.842
Train: [81][340/750]	BT 2.568 (1.197)	DT 2.514 (1.149)	loss 6.748 (6.748)	prob 2.840 (2.840)	GS 33.688 (33.688)	mem 39.993
Train: [81][345/750]	BT 0.027 (1.196)	DT 0.001 (1.148)	loss 6.797 (6.797)	prob 2.897 (2.897)	GS 32.328 (32.328)	mem 39.893
Train: [81][350/750]	BT 1.088 (1.183)	DT 1.034 (1.135)	loss 6.934 (6.934)	prob 2.041 (2.041)	GS 30.359 (30.359)	mem 39.884
Train: [81][355/750]	BT 0.024 (1.197)	DT 0.002 (1.149)	loss 6.868 (6.868)	prob 2.592 (2.592)	GS 32.344 (32.344)	mem 39.820
Train: [81][360/750]	BT 0.049 (1.181)	DT 0.002 (1.133)	loss 6.770 (6.770)	prob 3.024 (3.024)	GS 32.250 (32.250)	mem 39.857
Train: [81][365/750]	BT 0.089 (1.182)	DT 0.013 (1.135)	loss 6.875 (6.875)	prob 2.601 (2.601)	GS 34.609 (34.609)	mem 40.159
Train: [81][370/750]	BT 0.070 (1.188)	DT 0.020 (1.141)	loss 6.718 (6.718)	prob 2.722 (2.722)	GS 34.375 (34.375)	mem 39.966
Train: [81][375/750]	BT 0.039 (1.173)	DT 0.009 (1.126)	loss 7.231 (7.231)	prob 2.430 (2.430)	GS 33.297 (33.297)	mem 39.852
Train: [81][380/750]	BT 0.038 (1.188)	DT 0.002 (1.141)	loss 6.807 (6.807)	prob 2.490 (2.490)	GS 32.062 (32.062)	mem 39.998
Train: [81][385/750]	BT 0.064 (1.173)	DT 0.001 (1.126)	loss 7.056 (7.056)	prob 2.922 (2.922)	GS 29.578 (29.578)	mem 39.882
Train: [81][390/750]	BT 10.162 (1.195)	DT 10.112 (1.148)	loss 6.960 (6.960)	prob 2.195 (2.195)	GS 33.641 (33.641)	mem 39.840
Train: [81][395/750]	BT 0.028 (1.180)	DT 0.001 (1.133)	loss 6.930 (6.930)	prob 2.227 (2.227)	GS 29.469 (29.469)	mem 39.755
Train: [81][400/750]	BT 4.315 (1.177)	DT 4.190 (1.130)	loss 6.735 (6.735)	prob 2.087 (2.087)	GS 36.703 (36.703)	mem 39.929
Train: [81][405/750]	BT 0.040 (1.183)	DT 0.001 (1.135)	loss 7.043 (7.043)	prob 3.038 (3.038)	GS 29.375 (29.375)	mem 39.909
Train: [81][410/750]	BT 0.031 (1.169)	DT 0.001 (1.122)	loss 6.989 (6.989)	prob 2.510 (2.510)	GS 33.734 (33.734)	mem 39.908
Train: [81][415/750]	BT 0.044 (1.187)	DT 0.006 (1.140)	loss 6.876 (6.876)	prob 2.776 (2.776)	GS 39.844 (39.844)	mem 39.918
Train: [81][420/750]	BT 0.029 (1.174)	DT 0.001 (1.126)	loss 6.858 (6.858)	prob 2.842 (2.842)	GS 32.719 (32.719)	mem 39.947
Train: [81][425/750]	BT 0.062 (1.165)	DT 0.006 (1.118)	loss 6.958 (6.958)	prob 2.471 (2.471)	GS 29.516 (29.516)	mem 39.927
Train: [81][430/750]	BT 0.031 (1.179)	DT 0.001 (1.131)	loss 7.053 (7.053)	prob 2.489 (2.489)	GS 37.641 (37.641)	mem 39.825
Train: [81][435/750]	BT 0.061 (1.165)	DT 0.007 (1.118)	loss 6.712 (6.712)	prob 2.639 (2.639)	GS 29.375 (29.375)	mem 39.825
Train: [81][440/750]	BT 0.038 (1.183)	DT 0.009 (1.136)	loss 7.051 (7.051)	prob 2.201 (2.201)	GS 34.438 (34.438)	mem 39.921
Train: [81][445/750]	BT 0.048 (1.170)	DT 0.004 (1.123)	loss 6.844 (6.844)	prob 2.451 (2.451)	GS 32.781 (32.781)	mem 39.807
Train: [81][450/750]	BT 11.720 (1.184)	DT 11.668 (1.137)	loss 6.734 (6.734)	prob 2.726 (2.726)	GS 34.219 (34.219)	mem 39.829
Train: [81][455/750]	BT 0.043 (1.171)	DT 0.005 (1.125)	loss 6.947 (6.947)	prob 1.739 (1.739)	GS 33.562 (33.562)	mem 39.841
Train: [81][460/750]	BT 0.059 (1.159)	DT 0.005 (1.112)	loss 6.810 (6.810)	prob 2.507 (2.507)	GS 28.516 (28.516)	mem 39.842
Train: [81][465/750]	BT 0.023 (1.175)	DT 0.001 (1.128)	loss 6.729 (6.729)	prob 2.305 (2.305)	GS 29.469 (29.469)	mem 39.891
Train: [81][470/750]	BT 0.028 (1.162)	DT 0.001 (1.116)	loss 6.861 (6.861)	prob 1.884 (1.884)	GS 34.609 (34.609)	mem 39.916
Train: [81][475/750]	BT 0.034 (1.177)	DT 0.001 (1.130)	loss 6.969 (6.969)	prob 2.428 (2.428)	GS 27.672 (27.672)	mem 39.910
Train: [81][480/750]	BT 0.032 (1.165)	DT 0.001 (1.118)	loss 6.735 (6.735)	prob 3.079 (3.079)	GS 30.562 (30.562)	mem 39.910
Train: [81][485/750]	BT 0.039 (1.153)	DT 0.002 (1.107)	loss 6.782 (6.782)	prob 2.710 (2.710)	GS 32.391 (32.391)	mem 39.911
Train: [81][490/750]	BT 0.029 (1.163)	DT 0.001 (1.117)	loss 6.821 (6.821)	prob 2.433 (2.433)	GS 35.078 (35.078)	mem 39.935
Train: [81][495/750]	BT 0.052 (1.152)	DT 0.011 (1.106)	loss 7.033 (7.033)	prob 2.424 (2.424)	GS 29.688 (29.688)	mem 39.998
Train: [81][500/750]	BT 0.040 (1.166)	DT 0.001 (1.120)	loss 6.874 (6.874)	prob 2.646 (2.646)	GS 34.000 (34.000)	mem 40.000
Train: [81][505/750]	BT 0.041 (1.155)	DT 0.010 (1.109)	loss 6.894 (6.894)	prob 2.431 (2.431)	GS 28.438 (28.438)	mem 39.973
Train: [81][510/750]	BT 13.027 (1.169)	DT 12.978 (1.123)	loss 6.866 (6.866)	prob 2.494 (2.494)	GS 34.750 (34.750)	mem 39.988
Train: [81][515/750]	BT 0.041 (1.159)	DT 0.006 (1.113)	loss 6.802 (6.802)	prob 3.097 (3.097)	GS 27.703 (27.703)	mem 39.967
Train: [81][520/750]	BT 0.034 (1.148)	DT 0.002 (1.102)	loss 6.916 (6.916)	prob 2.669 (2.669)	GS 34.625 (34.625)	mem 40.034
Train: [81][525/750]	BT 0.023 (1.162)	DT 0.001 (1.116)	loss 7.209 (7.209)	prob 2.768 (2.768)	GS 31.000 (31.000)	mem 39.923
Train: [81][530/750]	BT 0.024 (1.151)	DT 0.001 (1.106)	loss 6.807 (6.807)	prob 2.426 (2.426)	GS 32.156 (32.156)	mem 39.922
Train: [81][535/750]	BT 0.030 (1.165)	DT 0.001 (1.119)	loss 7.394 (7.394)	prob 2.194 (2.194)	GS 28.297 (28.297)	mem 39.966
Train: [81][540/750]	BT 0.027 (1.155)	DT 0.001 (1.109)	loss 6.938 (6.938)	prob 2.027 (2.027)	GS 33.719 (33.719)	mem 39.979
Train: [81][545/750]	BT 0.033 (1.144)	DT 0.002 (1.099)	loss 6.925 (6.925)	prob 2.829 (2.829)	GS 37.656 (37.656)	mem 39.965
Train: [81][550/750]	BT 0.035 (1.158)	DT 0.013 (1.112)	loss 6.811 (6.811)	prob 3.025 (3.025)	GS 33.938 (33.938)	mem 39.859
Train: [81][555/750]	BT 0.065 (1.148)	DT 0.012 (1.102)	loss 6.966 (6.966)	prob 2.655 (2.655)	GS 31.359 (31.359)	mem 39.860
Train: [81][560/750]	BT 0.024 (1.165)	DT 0.001 (1.119)	loss 7.080 (7.080)	prob 2.484 (2.484)	GS 30.203 (30.203)	mem 39.876
Train: [81][565/750]	BT 0.028 (1.155)	DT 0.001 (1.109)	loss 6.872 (6.872)	prob 2.243 (2.243)	GS 33.359 (33.359)	mem 39.876
Train: [81][570/750]	BT 14.470 (1.170)	DT 14.422 (1.125)	loss 6.809 (6.809)	prob 2.713 (2.713)	GS 36.188 (36.188)	mem 39.931
Train: [81][575/750]	BT 0.046 (1.160)	DT 0.007 (1.115)	loss 7.205 (7.205)	prob 2.966 (2.966)	GS 31.938 (31.938)	mem 39.932
Train: [81][580/750]	BT 0.071 (1.151)	DT 0.011 (1.106)	loss 6.928 (6.928)	prob 2.262 (2.262)	GS 33.203 (33.203)	mem 39.930
Train: [81][585/750]	BT 0.056 (1.163)	DT 0.009 (1.118)	loss 6.982 (6.982)	prob 2.994 (2.994)	GS 32.875 (32.875)	mem 39.868
Train: [81][590/750]	BT 0.061 (1.154)	DT 0.003 (1.109)	loss 6.976 (6.976)	prob 2.227 (2.227)	GS 35.078 (35.078)	mem 39.950
Train: [81][595/750]	BT 0.022 (1.165)	DT 0.001 (1.121)	loss 7.159 (7.159)	prob 2.095 (2.095)	GS 29.312 (29.312)	mem 39.940
Train: [81][600/750]	BT 0.041 (1.156)	DT 0.011 (1.111)	loss 6.790 (6.790)	prob 2.840 (2.840)	GS 34.906 (34.906)	mem 39.941
Train: [81][605/750]	BT 0.032 (1.147)	DT 0.002 (1.102)	loss 6.838 (6.838)	prob 3.128 (3.128)	GS 30.969 (30.969)	mem 39.984
Train: [81][610/750]	BT 0.043 (1.159)	DT 0.002 (1.115)	loss 6.669 (6.669)	prob 2.771 (2.771)	GS 36.375 (36.375)	mem 39.873
Train: [81][615/750]	BT 0.047 (1.150)	DT 0.006 (1.106)	loss 7.340 (7.340)	prob 1.975 (1.975)	GS 35.953 (35.953)	mem 39.872
Train: [81][620/750]	BT 0.025 (1.158)	DT 0.001 (1.114)	loss 7.067 (7.067)	prob 2.153 (2.153)	GS 30.156 (30.156)	mem 39.954
Train: [81][625/750]	BT 0.034 (1.149)	DT 0.002 (1.105)	loss 6.762 (6.762)	prob 2.816 (2.816)	GS 38.062 (38.062)	mem 39.954
Train: [81][630/750]	BT 15.263 (1.165)	DT 15.217 (1.120)	loss 6.783 (6.783)	prob 2.574 (2.574)	GS 33.344 (33.344)	mem 39.903
Train: [81][635/750]	BT 0.026 (1.156)	DT 0.001 (1.111)	loss 6.772 (6.772)	prob 3.244 (3.244)	GS 28.094 (28.094)	mem 39.905
Train: [81][640/750]	BT 0.057 (1.147)	DT 0.011 (1.103)	loss 6.965 (6.965)	prob 2.806 (2.806)	GS 36.969 (36.969)	mem 39.905
Train: [81][645/750]	BT 0.068 (1.155)	DT 0.011 (1.111)	loss 6.563 (6.563)	prob 2.915 (2.915)	GS 29.938 (29.938)	mem 39.824
Train: [81][650/750]	BT 0.031 (1.147)	DT 0.001 (1.102)	loss 6.983 (6.983)	prob 2.571 (2.571)	GS 31.297 (31.297)	mem 39.824
Train: [81][655/750]	BT 0.031 (1.153)	DT 0.001 (1.109)	loss 6.943 (6.943)	prob 2.437 (2.437)	GS 33.109 (33.109)	mem 39.912
arpack error, retry= 0
Train: [81][660/750]	BT 0.022 (1.145)	DT 0.001 (1.100)	loss 6.875 (6.875)	prob 3.054 (3.054)	GS 28.578 (28.578)	mem 39.853
Train: [81][665/750]	BT 0.072 (1.136)	DT 0.001 (1.092)	loss 6.924 (6.924)	prob 1.927 (1.927)	GS 29.594 (29.594)	mem 39.886
Train: [81][670/750]	BT 0.159 (1.147)	DT 0.007 (1.103)	loss 6.862 (6.862)	prob 2.762 (2.762)	GS 35.609 (35.609)	mem 40.038
Train: [81][675/750]	BT 0.029 (1.139)	DT 0.001 (1.094)	loss 7.271 (7.271)	prob 2.369 (2.369)	GS 32.094 (32.094)	mem 39.990
Train: [81][680/750]	BT 0.030 (1.151)	DT 0.001 (1.106)	loss 7.030 (7.030)	prob 2.768 (2.768)	GS 34.250 (34.250)	mem 39.823
Train: [81][685/750]	BT 0.025 (1.143)	DT 0.001 (1.098)	loss 6.835 (6.835)	prob 2.703 (2.703)	GS 30.156 (30.156)	mem 40.054
Train: [81][690/750]	BT 12.162 (1.152)	DT 12.130 (1.108)	loss 6.908 (6.908)	prob 2.312 (2.312)	GS 31.828 (31.828)	mem 39.908
Train: [81][695/750]	BT 0.034 (1.144)	DT 0.003 (1.100)	loss 6.945 (6.945)	prob 2.760 (2.760)	GS 27.188 (27.188)	mem 39.908
Train: [81][700/750]	BT 0.068 (1.136)	DT 0.013 (1.092)	loss 6.979 (6.979)	prob 2.619 (2.619)	GS 31.094 (31.094)	mem 39.918
Train: [81][705/750]	BT 0.050 (1.142)	DT 0.012 (1.098)	loss 7.074 (7.074)	prob 2.629 (2.629)	GS 32.109 (32.109)	mem 39.875
Train: [81][710/750]	BT 0.072 (1.136)	DT 0.002 (1.091)	loss 6.892 (6.892)	prob 2.380 (2.380)	GS 32.703 (32.703)	mem 39.921
Train: [81][715/750]	BT 0.032 (1.143)	DT 0.001 (1.098)	loss 6.931 (6.931)	prob 2.363 (2.363)	GS 30.172 (30.172)	mem 39.919
Train: [81][720/750]	BT 0.110 (1.135)	DT 0.024 (1.091)	loss 7.025 (7.025)	prob 2.073 (2.073)	GS 32.328 (32.328)	mem 39.848
Train: [81][725/750]	BT 0.057 (1.132)	DT 0.011 (1.087)	loss 6.677 (6.677)	prob 2.101 (2.101)	GS 30.078 (30.078)	mem 39.871
Train: [81][730/750]	BT 0.049 (1.141)	DT 0.002 (1.096)	loss 6.768 (6.768)	prob 2.678 (2.678)	GS 32.594 (32.594)	mem 39.592
Train: [81][735/750]	BT 0.049 (1.135)	DT 0.009 (1.090)	loss 6.874 (6.874)	prob 2.338 (2.338)	GS 25.375 (25.375)	mem 36.734
Train: [81][740/750]	BT 0.047 (1.137)	DT 0.006 (1.093)	loss 6.750 (6.750)	prob 2.008 (2.008)	GS 30.328 (30.328)	mem 13.573
Train: [81][745/750]	BT 0.039 (1.131)	DT 0.005 (1.086)	loss 7.097 (7.097)	prob 2.186 (2.186)	GS 30.875 (30.875)	mem 11.053
Train: [81][750/750]	BT 2.003 (1.126)	DT 1.981 (1.081)	loss 6.603 (6.603)	prob 2.897 (2.897)	GS 37.531 (37.531)	mem 10.521
Train: [81][755/750]	BT 0.024 (1.119)	DT 0.001 (1.074)	loss 6.775 (6.775)	prob 2.227 (2.227)	GS 32.219 (32.219)	mem 10.521
epoch 81, total time 845.25
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [82][1/750]	BT 31.685 (31.685)	DT 31.548 (31.548)	loss 7.020 (7.020)	prob 2.750 (2.750)	GS 44.828 (44.828)	mem 38.765
Train: [82][5/750]	BT 0.119 (6.385)	DT 0.002 (6.312)	loss 6.905 (6.905)	prob 3.208 (3.208)	GS 32.438 (32.438)	mem 38.886
Train: [82][10/750]	BT 0.032 (3.210)	DT 0.001 (3.157)	loss 6.878 (6.878)	prob 2.314 (2.314)	GS 32.344 (32.344)	mem 38.732
Train: [82][15/750]	BT 0.066 (2.809)	DT 0.002 (2.758)	loss 6.482 (6.482)	prob 2.684 (2.684)	GS 27.703 (27.703)	mem 38.930
Train: [82][20/750]	BT 0.039 (2.124)	DT 0.001 (2.071)	loss 6.753 (6.753)	prob 2.672 (2.672)	GS 31.219 (31.219)	mem 38.861
Train: [82][25/750]	BT 8.239 (2.042)	DT 8.149 (1.983)	loss 6.794 (6.794)	prob 2.854 (2.854)	GS 36.094 (36.094)	mem 39.017
Train: [82][30/750]	BT 0.055 (1.958)	DT 0.007 (1.901)	loss 6.858 (6.858)	prob 1.997 (1.997)	GS 32.141 (32.141)	mem 38.953
Train: [82][35/750]	BT 0.057 (1.686)	DT 0.012 (1.631)	loss 6.899 (6.899)	prob 2.683 (2.683)	GS 30.438 (30.438)	mem 38.999
Train: [82][40/750]	BT 6.329 (1.864)	DT 6.297 (1.809)	loss 6.866 (6.866)	prob 2.558 (2.558)	GS 33.078 (33.078)	mem 39.040
Train: [82][45/750]	BT 0.138 (1.663)	DT 0.009 (1.609)	loss 6.844 (6.844)	prob 2.648 (2.648)	GS 34.156 (34.156)	mem 39.041
Train: [82][50/750]	BT 8.591 (1.720)	DT 8.546 (1.667)	loss 6.995 (6.995)	prob 2.141 (2.141)	GS 35.422 (35.422)	mem 39.052
Train: [82][55/750]	BT 0.054 (1.659)	DT 0.009 (1.607)	loss 6.714 (6.714)	prob 2.661 (2.661)	GS 32.531 (32.531)	mem 39.133
Train: [82][60/750]	BT 0.074 (1.524)	DT 0.013 (1.474)	loss 7.026 (7.026)	prob 2.044 (2.044)	GS 30.625 (30.625)	mem 39.106
Train: [82][65/750]	BT 0.065 (1.587)	DT 0.026 (1.536)	loss 6.649 (6.649)	prob 2.839 (2.839)	GS 34.156 (34.156)	mem 39.216
Train: [82][70/750]	BT 0.090 (1.477)	DT 0.025 (1.427)	loss nan (nan)	prob nan (nan)	GS 30.797 (30.797)	mem 39.148
Train: [82][75/750]	BT 0.030 (1.495)	DT 0.001 (1.444)	loss nan (nan)	prob nan (nan)	GS 31.266 (31.266)	mem 39.075
Train: [82][80/750]	BT 0.027 (1.452)	DT 0.001 (1.401)	loss nan (nan)	prob nan (nan)	GS 30.859 (30.859)	mem 39.383
Train: [82][85/750]	BT 0.129 (1.373)	DT 0.011 (1.319)	loss nan (nan)	prob nan (nan)	GS 33.062 (33.062)	mem 39.105
Train: [82][90/750]	BT 0.062 (1.449)	DT 0.006 (1.396)	loss nan (nan)	prob nan (nan)	GS 39.984 (39.984)	mem 39.304
Train: [82][95/750]	BT 0.033 (1.376)	DT 0.002 (1.323)	loss nan (nan)	prob nan (nan)	GS 30.297 (30.297)	mem 39.311
Train: [82][100/750]	BT 5.432 (1.431)	DT 5.400 (1.379)	loss nan (nan)	prob nan (nan)	GS 34.641 (34.641)	mem 39.441
Train: [82][105/750]	BT 0.050 (1.367)	DT 0.008 (1.314)	loss nan (nan)	prob nan (nan)	GS 29.625 (29.625)	mem 39.442
Train: [82][110/750]	BT 10.783 (1.404)	DT 10.734 (1.352)	loss nan (nan)	prob nan (nan)	GS 37.859 (37.859)	mem 39.433
Train: [82][115/750]	BT 0.038 (1.345)	DT 0.009 (1.294)	loss nan (nan)	prob nan (nan)	GS 29.438 (29.438)	mem 39.364
Train: [82][120/750]	BT 0.048 (1.292)	DT 0.007 (1.240)	loss nan (nan)	prob nan (nan)	GS 35.125 (35.125)	mem 39.364
Train: [82][125/750]	BT 0.057 (1.339)	DT 0.007 (1.288)	loss nan (nan)	prob nan (nan)	GS 27.250 (27.250)	mem 39.533
Train: [82][130/750]	BT 0.077 (1.304)	DT 0.010 (1.253)	loss nan (nan)	prob nan (nan)	GS 32.625 (32.625)	mem 39.629
Train: [82][135/750]	BT 0.049 (1.315)	DT 0.006 (1.264)	loss nan (nan)	prob nan (nan)	GS 34.016 (34.016)	mem 39.656
Train: [82][140/750]	BT 0.121 (1.306)	DT 0.010 (1.254)	loss nan (nan)	prob nan (nan)	GS 33.656 (33.656)	mem 39.759
Train: [82][145/750]	BT 0.032 (1.285)	DT 0.002 (1.234)	loss nan (nan)	prob nan (nan)	GS 25.734 (25.734)	mem 39.669
Train: [82][150/750]	BT 0.046 (1.321)	DT 0.006 (1.270)	loss nan (nan)	prob nan (nan)	GS 30.891 (30.891)	mem 39.703
Train: [82][155/750]	BT 0.064 (1.280)	DT 0.001 (1.230)	loss nan (nan)	prob nan (nan)	GS 28.156 (28.156)	mem 39.707
Train: [82][160/750]	BT 5.916 (1.331)	DT 5.886 (1.281)	loss nan (nan)	prob nan (nan)	GS 35.391 (35.391)	mem 39.763
Train: [82][165/750]	BT 0.029 (1.292)	DT 0.001 (1.242)	loss nan (nan)	prob nan (nan)	GS 32.062 (32.062)	mem 39.764
Train: [82][170/750]	BT 3.222 (1.283)	DT 3.174 (1.234)	loss nan (nan)	prob nan (nan)	GS 31.156 (31.156)	mem 39.995
Train: [82][175/750]	BT 0.028 (1.283)	DT 0.001 (1.234)	loss nan (nan)	prob nan (nan)	GS 28.172 (28.172)	mem 39.795
Train: [82][180/750]	BT 6.091 (1.282)	DT 6.052 (1.233)	loss nan (nan)	prob nan (nan)	GS 33.281 (33.281)	mem 39.783
Train: [82][185/750]	BT 0.034 (1.279)	DT 0.002 (1.230)	loss nan (nan)	prob nan (nan)	GS 30.344 (30.344)	mem 39.787
Train: [82][190/750]	BT 0.031 (1.246)	DT 0.001 (1.197)	loss nan (nan)	prob nan (nan)	GS 34.047 (34.047)	mem 39.776
Train: [82][195/750]	BT 0.032 (1.263)	DT 0.002 (1.214)	loss nan (nan)	prob nan (nan)	GS 32.641 (32.641)	mem 39.740
Train: [82][200/750]	BT 0.063 (1.255)	DT 0.011 (1.206)	loss nan (nan)	prob nan (nan)	GS 37.891 (37.891)	mem 40.071
Train: [82][205/750]	BT 0.031 (1.259)	DT 0.001 (1.210)	loss nan (nan)	prob nan (nan)	GS 32.797 (32.797)	mem 39.789
Train: [82][210/750]	BT 0.031 (1.258)	DT 0.001 (1.209)	loss nan (nan)	prob nan (nan)	GS 33.547 (33.547)	mem 39.851
Train: [82][215/750]	BT 0.083 (1.230)	DT 0.001 (1.181)	loss nan (nan)	prob nan (nan)	GS 38.281 (38.281)	mem 39.851
Train: [82][220/750]	BT 4.711 (1.251)	DT 4.639 (1.203)	loss nan (nan)	prob nan (nan)	GS 31.672 (31.672)	mem 39.916
Train: [82][225/750]	BT 0.034 (1.224)	DT 0.002 (1.176)	loss nan (nan)	prob nan (nan)	GS 29.828 (29.828)	mem 39.979
Train: [82][230/750]	BT 0.035 (1.242)	DT 0.002 (1.194)	loss nan (nan)	prob nan (nan)	GS 33.734 (33.734)	mem 40.021
Train: [82][235/750]	BT 0.060 (1.235)	DT 0.017 (1.187)	loss nan (nan)	prob nan (nan)	GS 32.812 (32.812)	mem 39.845
Train: [82][240/750]	BT 7.603 (1.241)	DT 7.503 (1.194)	loss nan (nan)	prob nan (nan)	GS 34.984 (34.984)	mem 40.018
Train: [82][245/750]	BT 0.035 (1.230)	DT 0.001 (1.182)	loss nan (nan)	prob nan (nan)	GS 26.047 (26.047)	mem 39.867
Train: [82][250/750]	BT 0.033 (1.206)	DT 0.001 (1.159)	loss nan (nan)	prob nan (nan)	GS 33.125 (33.125)	mem 39.981
Train: [82][255/750]	BT 0.044 (1.229)	DT 0.004 (1.182)	loss nan (nan)	prob nan (nan)	GS 33.375 (33.375)	mem 40.089
Train: [82][260/750]	BT 0.079 (1.211)	DT 0.001 (1.164)	loss nan (nan)	prob nan (nan)	GS 35.797 (35.797)	mem 39.902
Train: [82][265/750]	BT 0.100 (1.227)	DT 0.020 (1.180)	loss nan (nan)	prob nan (nan)	GS 29.312 (29.312)	mem 39.930
Train: [82][270/750]	BT 0.038 (1.223)	DT 0.002 (1.175)	loss nan (nan)	prob nan (nan)	GS 36.406 (36.406)	mem 39.973
Train: [82][275/750]	BT 0.025 (1.201)	DT 0.001 (1.154)	loss nan (nan)	prob nan (nan)	GS 29.547 (29.547)	mem 39.838
Train: [82][280/750]	BT 2.436 (1.219)	DT 2.336 (1.172)	loss nan (nan)	prob nan (nan)	GS 34.656 (34.656)	mem 39.904
Train: [82][285/750]	BT 0.034 (1.199)	DT 0.010 (1.152)	loss nan (nan)	prob nan (nan)	GS 30.656 (30.656)	mem 39.906
Train: [82][290/750]	BT 0.025 (1.214)	DT 0.001 (1.167)	loss nan (nan)	prob nan (nan)	GS 36.375 (36.375)	mem 40.133
Train: [82][295/750]	BT 0.029 (1.206)	DT 0.001 (1.159)	loss nan (nan)	prob nan (nan)	GS 33.594 (33.594)	mem 39.986
Train: [82][300/750]	BT 10.535 (1.222)	DT 10.507 (1.175)	loss nan (nan)	prob nan (nan)	GS 30.625 (30.625)	mem 39.904
Train: [82][305/750]	BT 0.050 (1.209)	DT 0.009 (1.162)	loss nan (nan)	prob nan (nan)	GS 34.750 (34.750)	mem 40.017
Train: [82][310/750]	BT 0.048 (1.191)	DT 0.002 (1.144)	loss nan (nan)	prob nan (nan)	GS 36.219 (36.219)	mem 40.042
Train: [82][315/750]	BT 0.041 (1.203)	DT 0.002 (1.156)	loss nan (nan)	prob nan (nan)	GS 29.719 (29.719)	mem 39.915
Train: [82][320/750]	BT 0.038 (1.193)	DT 0.002 (1.146)	loss nan (nan)	prob nan (nan)	GS 35.891 (35.891)	mem 39.945
Train: [82][325/750]	BT 0.032 (1.209)	DT 0.001 (1.163)	loss nan (nan)	prob nan (nan)	GS 30.141 (30.141)	mem 39.921
Train: [82][330/750]	BT 0.033 (1.194)	DT 0.001 (1.148)	loss nan (nan)	prob nan (nan)	GS 33.625 (33.625)	mem 39.925
Train: [82][335/750]	BT 0.032 (1.177)	DT 0.002 (1.131)	loss nan (nan)	prob nan (nan)	GS 31.141 (31.141)	mem 39.925
Train: [82][340/750]	BT 0.090 (1.196)	DT 0.009 (1.150)	loss nan (nan)	prob nan (nan)	GS 33.984 (33.984)	mem 39.897
Train: [82][345/750]	BT 0.055 (1.180)	DT 0.002 (1.134)	loss nan (nan)	prob nan (nan)	GS 32.172 (32.172)	mem 39.897
Train: [82][350/750]	BT 0.834 (1.194)	DT 0.787 (1.148)	loss nan (nan)	prob nan (nan)	GS 35.844 (35.844)	mem 39.939
Train: [82][355/750]	BT 0.098 (1.178)	DT 0.011 (1.132)	loss nan (nan)	prob nan (nan)	GS 29.031 (29.031)	mem 39.896
Train: [82][360/750]	BT 12.733 (1.197)	DT 12.671 (1.151)	loss nan (nan)	prob nan (nan)	GS 33.125 (33.125)	mem 39.872
Train: [82][365/750]	BT 0.066 (1.188)	DT 0.010 (1.142)	loss nan (nan)	prob nan (nan)	GS 34.500 (34.500)	mem 39.911
Train: [82][370/750]	BT 0.029 (1.173)	DT 0.001 (1.127)	loss nan (nan)	prob nan (nan)	GS 34.047 (34.047)	mem 39.969
Train: [82][375/750]	BT 0.033 (1.196)	DT 0.001 (1.150)	loss nan (nan)	prob nan (nan)	GS 38.031 (38.031)	mem 39.950
Train: [82][380/750]	BT 0.038 (1.181)	DT 0.002 (1.135)	loss nan (nan)	prob nan (nan)	GS 39.391 (39.391)	mem 39.948
Train: [82][385/750]	BT 0.050 (1.191)	DT 0.004 (1.145)	loss nan (nan)	prob nan (nan)	GS 32.969 (32.969)	mem 39.980
Train: [82][390/750]	BT 0.062 (1.187)	DT 0.001 (1.141)	loss nan (nan)	prob nan (nan)	GS 28.531 (28.531)	mem 39.975
Train: [82][395/750]	BT 0.048 (1.173)	DT 0.001 (1.127)	loss nan (nan)	prob nan (nan)	GS 25.484 (25.484)	mem 39.975
Train: [82][400/750]	BT 2.181 (1.191)	DT 2.132 (1.145)	loss nan (nan)	prob nan (nan)	GS 34.578 (34.578)	mem 39.930
Train: [82][405/750]	BT 0.108 (1.178)	DT 0.034 (1.131)	loss nan (nan)	prob nan (nan)	GS 30.453 (30.453)	mem 39.933
Train: [82][410/750]	BT 0.041 (1.188)	DT 0.009 (1.142)	loss nan (nan)	prob nan (nan)	GS 36.734 (36.734)	mem 39.958
Train: [82][415/750]	BT 0.040 (1.176)	DT 0.001 (1.130)	loss nan (nan)	prob nan (nan)	GS 31.219 (31.219)	mem 40.098
Train: [82][420/750]	BT 13.966 (1.195)	DT 13.932 (1.149)	loss nan (nan)	prob nan (nan)	GS 35.578 (35.578)	mem 39.977
Train: [82][425/750]	BT 0.030 (1.182)	DT 0.001 (1.136)	loss nan (nan)	prob nan (nan)	GS 33.266 (33.266)	mem 39.978
Train: [82][430/750]	BT 0.030 (1.169)	DT 0.001 (1.123)	loss nan (nan)	prob nan (nan)	GS 32.469 (32.469)	mem 39.983
Train: [82][435/750]	BT 0.105 (1.183)	DT 0.008 (1.137)	loss nan (nan)	prob nan (nan)	GS 32.703 (32.703)	mem 39.930
Train: [82][440/750]	BT 0.050 (1.170)	DT 0.006 (1.124)	loss nan (nan)	prob nan (nan)	GS 32.312 (32.312)	mem 39.876
Train: [82][445/750]	BT 0.042 (1.190)	DT 0.002 (1.144)	loss nan (nan)	prob nan (nan)	GS 29.000 (29.000)	mem 40.013
Train: [82][450/750]	BT 0.029 (1.177)	DT 0.001 (1.131)	loss nan (nan)	prob nan (nan)	GS 35.875 (35.875)	mem 39.995
Train: [82][455/750]	BT 0.036 (1.165)	DT 0.002 (1.119)	loss nan (nan)	prob nan (nan)	GS 33.781 (33.781)	mem 40.000
Train: [82][460/750]	BT 0.048 (1.179)	DT 0.007 (1.133)	loss nan (nan)	prob nan (nan)	GS 32.781 (32.781)	mem 39.867
Train: [82][465/750]	BT 0.047 (1.167)	DT 0.001 (1.120)	loss nan (nan)	prob nan (nan)	GS 30.781 (30.781)	mem 39.891
Train: [82][470/750]	BT 0.030 (1.178)	DT 0.001 (1.132)	loss nan (nan)	prob nan (nan)	GS 32.438 (32.438)	mem 39.836
Train: [82][475/750]	BT 0.059 (1.171)	DT 0.008 (1.125)	loss nan (nan)	prob nan (nan)	GS 31.688 (31.688)	mem 39.957
Train: [82][480/750]	BT 12.955 (1.187)	DT 12.913 (1.141)	loss nan (nan)	prob nan (nan)	GS 37.844 (37.844)	mem 39.894
Train: [82][485/750]	BT 0.036 (1.179)	DT 0.001 (1.133)	loss nan (nan)	prob nan (nan)	GS 46.406 (46.406)	mem 39.830
Train: [82][490/750]	BT 0.054 (1.168)	DT 0.010 (1.122)	loss nan (nan)	prob nan (nan)	GS 37.594 (37.594)	mem 39.830
Train: [82][495/750]	BT 0.034 (1.179)	DT 0.001 (1.133)	loss nan (nan)	prob nan (nan)	GS 29.625 (29.625)	mem 39.887
Train: [82][500/750]	BT 0.032 (1.171)	DT 0.002 (1.125)	loss nan (nan)	prob nan (nan)	GS 30.094 (30.094)	mem 39.903
Train: [82][505/750]	BT 0.101 (1.182)	DT 0.024 (1.136)	loss nan (nan)	prob nan (nan)	GS 29.906 (29.906)	mem 40.000
Train: [82][510/750]	BT 0.063 (1.174)	DT 0.001 (1.128)	loss nan (nan)	prob nan (nan)	GS 30.531 (30.531)	mem 40.005
Train: [82][515/750]	BT 0.139 (1.163)	DT 0.068 (1.117)	loss nan (nan)	prob nan (nan)	GS 35.078 (35.078)	mem 39.936
Train: [82][520/750]	BT 5.676 (1.182)	DT 5.614 (1.136)	loss nan (nan)	prob nan (nan)	GS 39.031 (39.031)	mem 39.977
Train: [82][525/750]	BT 0.030 (1.171)	DT 0.002 (1.125)	loss nan (nan)	prob nan (nan)	GS 30.922 (30.922)	mem 39.906
Train: [82][530/750]	BT 0.030 (1.172)	DT 0.003 (1.126)	loss nan (nan)	prob nan (nan)	GS 31.297 (31.297)	mem 39.876
Train: [82][535/750]	BT 0.038 (1.178)	DT 0.001 (1.132)	loss nan (nan)	prob nan (nan)	GS 31.203 (31.203)	mem 39.848
Train: [82][540/750]	BT 2.188 (1.171)	DT 2.148 (1.126)	loss nan (nan)	prob nan (nan)	GS 32.922 (32.922)	mem 39.842
Train: [82][545/750]	BT 0.120 (1.179)	DT 0.073 (1.133)	loss nan (nan)	prob nan (nan)	GS 35.625 (35.625)	mem 39.973
Train: [82][550/750]	BT 0.035 (1.168)	DT 0.003 (1.123)	loss nan (nan)	prob nan (nan)	GS 33.469 (33.469)	mem 39.899
Train: [82][555/750]	BT 0.068 (1.166)	DT 0.021 (1.120)	loss nan (nan)	prob nan (nan)	GS 31.359 (31.359)	mem 39.800
Train: [82][560/750]	BT 0.035 (1.166)	DT 0.002 (1.120)	loss nan (nan)	prob nan (nan)	GS 33.906 (33.906)	mem 40.038
Train: [82][565/750]	BT 0.037 (1.167)	DT 0.002 (1.121)	loss nan (nan)	prob nan (nan)	GS 29.438 (29.438)	mem 39.804
Train: [82][570/750]	BT 2.934 (1.169)	DT 2.903 (1.123)	loss nan (nan)	prob nan (nan)	GS 36.438 (36.438)	mem 39.944
Train: [82][575/750]	BT 0.034 (1.159)	DT 0.002 (1.113)	loss nan (nan)	prob nan (nan)	GS 28.406 (28.406)	mem 40.014
Train: [82][580/750]	BT 2.074 (1.162)	DT 2.042 (1.116)	loss nan (nan)	prob nan (nan)	GS 32.344 (32.344)	mem 39.849
Train: [82][585/750]	BT 0.033 (1.154)	DT 0.001 (1.108)	loss nan (nan)	prob nan (nan)	GS 35.422 (35.422)	mem 39.858
Train: [82][590/750]	BT 3.037 (1.164)	DT 2.982 (1.118)	loss nan (nan)	prob nan (nan)	GS 36.219 (36.219)	mem 39.889
Train: [82][595/750]	BT 0.036 (1.156)	DT 0.002 (1.110)	loss nan (nan)	prob nan (nan)	GS 29.172 (29.172)	mem 39.889
Train: [82][600/750]	BT 11.053 (1.165)	DT 11.023 (1.120)	loss nan (nan)	prob nan (nan)	GS 35.438 (35.438)	mem 39.821
Train: [82][605/750]	BT 0.033 (1.156)	DT 0.002 (1.111)	loss nan (nan)	prob nan (nan)	GS 31.031 (31.031)	mem 39.824
Train: [82][610/750]	BT 0.068 (1.156)	DT 0.002 (1.111)	loss nan (nan)	prob nan (nan)	GS 36.516 (36.516)	mem 40.174
Train: [82][615/750]	BT 0.043 (1.164)	DT 0.005 (1.118)	loss nan (nan)	prob nan (nan)	GS 31.641 (31.641)	mem 39.931
Train: [82][620/750]	BT 0.031 (1.155)	DT 0.001 (1.109)	loss nan (nan)	prob nan (nan)	GS 32.859 (32.859)	mem 39.930
Train: [82][625/750]	BT 0.061 (1.168)	DT 0.004 (1.122)	loss nan (nan)	prob nan (nan)	GS 35.438 (35.438)	mem 39.770
Train: [82][630/750]	BT 0.031 (1.160)	DT 0.001 (1.114)	loss nan (nan)	prob nan (nan)	GS 31.906 (31.906)	mem 39.785
Train: [82][635/750]	BT 0.051 (1.151)	DT 0.001 (1.105)	loss nan (nan)	prob nan (nan)	GS 30.375 (30.375)	mem 39.847
Train: [82][640/750]	BT 0.026 (1.162)	DT 0.001 (1.116)	loss nan (nan)	prob nan (nan)	GS 37.547 (37.547)	mem 39.890
Train: [82][645/750]	BT 0.033 (1.154)	DT 0.002 (1.108)	loss nan (nan)	prob nan (nan)	GS 31.188 (31.188)	mem 39.838
Train: [82][650/750]	BT 0.020 (1.168)	DT 0.001 (1.122)	loss nan (nan)	prob nan (nan)	GS 33.875 (33.875)	mem 39.956
Train: [82][655/750]	BT 0.086 (1.160)	DT 0.014 (1.113)	loss nan (nan)	prob nan (nan)	GS 29.203 (29.203)	mem 39.945
Train: [82][660/750]	BT 10.714 (1.167)	DT 10.622 (1.121)	loss nan (nan)	prob nan (nan)	GS 32.844 (32.844)	mem 40.022
Train: [82][665/750]	BT 0.141 (1.159)	DT 0.012 (1.113)	loss nan (nan)	prob nan (nan)	GS 30.422 (30.422)	mem 39.928
Train: [82][670/750]	BT 0.110 (1.157)	DT 0.005 (1.110)	loss nan (nan)	prob nan (nan)	GS 34.188 (34.188)	mem 39.896
Train: [82][675/750]	BT 0.048 (1.162)	DT 0.003 (1.115)	loss nan (nan)	prob nan (nan)	GS 36.922 (36.922)	mem 39.928
Train: [82][680/750]	BT 0.162 (1.154)	DT 0.024 (1.107)	loss nan (nan)	prob nan (nan)	GS 30.188 (30.188)	mem 39.981
Train: [82][685/750]	BT 0.040 (1.162)	DT 0.007 (1.116)	loss nan (nan)	prob nan (nan)	GS 31.609 (31.609)	mem 39.946
Train: [82][690/750]	BT 0.051 (1.156)	DT 0.002 (1.109)	loss nan (nan)	prob nan (nan)	GS 31.000 (31.000)	mem 40.014
Train: [82][695/750]	BT 0.033 (1.152)	DT 0.001 (1.105)	loss nan (nan)	prob nan (nan)	GS 28.953 (28.953)	mem 39.917
Train: [82][700/750]	BT 0.024 (1.159)	DT 0.002 (1.113)	loss nan (nan)	prob nan (nan)	GS 30.516 (30.516)	mem 39.765
arpack error, retry= 0
arpack error, retry= 0
arpack error, retry= 0
arpack error, retry= 0
Train: [82][705/750]	BT 0.034 (1.153)	DT 0.004 (1.106)	loss nan (nan)	prob nan (nan)	GS 29.984 (29.984)	mem 39.804
Train: [82][710/750]	BT 2.876 (1.165)	DT 2.843 (1.119)	loss nan (nan)	prob nan (nan)	GS 33.812 (33.812)	mem 39.755
Train: [82][715/750]	BT 0.026 (1.157)	DT 0.001 (1.111)	loss nan (nan)	prob nan (nan)	GS 26.969 (26.969)	mem 39.757
Train: [82][720/750]	BT 8.252 (1.161)	DT 8.205 (1.115)	loss nan (nan)	prob nan (nan)	GS 33.656 (33.656)	mem 39.978
Train: [82][725/750]	BT 0.045 (1.161)	DT 0.002 (1.115)	loss nan (nan)	prob nan (nan)	GS 32.188 (32.188)	mem 39.876
Train: [82][730/750]	BT 0.043 (1.153)	DT 0.002 (1.107)	loss nan (nan)	prob nan (nan)	GS 33.844 (33.844)	mem 40.329
Train: [82][735/750]	BT 0.032 (1.156)	DT 0.001 (1.110)	loss nan (nan)	prob nan (nan)	GS 31.984 (31.984)	mem 36.426
Train: [82][740/750]	BT 0.026 (1.149)	DT 0.001 (1.103)	loss nan (nan)	prob nan (nan)	GS 31.203 (31.203)	mem 36.455
Train: [82][745/750]	BT 0.030 (1.147)	DT 0.001 (1.101)	loss nan (nan)	prob nan (nan)	GS 35.312 (35.312)	mem 7.560
Train: [82][750/750]	BT 0.029 (1.140)	DT 0.001 (1.094)	loss nan (nan)	prob nan (nan)	GS 35.938 (35.938)	mem 7.561
Train: [82][755/750]	BT 0.029 (1.132)	DT 0.001 (1.087)	loss nan (nan)	prob nan (nan)	GS 30.219 (30.219)	mem 7.561
epoch 82, total time 856.70
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [83][1/750]	BT 21.875 (21.875)	DT 21.777 (21.777)	loss nan (nan)	prob nan (nan)	GS 36.859 (36.859)	mem 38.500
Train: [83][5/750]	BT 0.041 (4.990)	DT 0.001 (4.940)	loss nan (nan)	prob nan (nan)	GS 30.672 (30.672)	mem 38.647
Train: [83][10/750]	BT 0.035 (2.794)	DT 0.001 (2.753)	loss nan (nan)	prob nan (nan)	GS 35.672 (35.672)	mem 38.719
Train: [83][15/750]	BT 0.033 (2.492)	DT 0.001 (2.454)	loss nan (nan)	prob nan (nan)	GS 26.266 (26.266)	mem 38.930
Train: [83][20/750]	BT 5.441 (2.160)	DT 5.395 (2.113)	loss nan (nan)	prob nan (nan)	GS 30.250 (30.250)	mem 38.929
Train: [83][25/750]	BT 0.030 (1.736)	DT 0.006 (1.691)	loss nan (nan)	prob nan (nan)	GS 33.219 (33.219)	mem 38.840
Train: [83][30/750]	BT 0.045 (1.798)	DT 0.013 (1.753)	loss nan (nan)	prob nan (nan)	GS 33.562 (33.562)	mem 38.864
Train: [83][35/750]	BT 0.040 (1.556)	DT 0.001 (1.512)	loss nan (nan)	prob nan (nan)	GS 31.094 (31.094)	mem 38.914
Train: [83][40/750]	BT 3.186 (1.726)	DT 3.084 (1.679)	loss nan (nan)	prob nan (nan)	GS 32.594 (32.594)	mem 39.082
Train: [83][45/750]	BT 0.040 (1.538)	DT 0.002 (1.493)	loss nan (nan)	prob nan (nan)	GS 28.906 (28.906)	mem 38.960
Train: [83][50/750]	BT 10.527 (1.649)	DT 10.470 (1.602)	loss nan (nan)	prob nan (nan)	GS 35.406 (35.406)	mem 39.285
Train: [83][55/750]	BT 0.053 (1.503)	DT 0.002 (1.457)	loss nan (nan)	prob nan (nan)	GS 30.031 (30.031)	mem 39.338
Train: [83][60/750]	BT 3.949 (1.447)	DT 3.871 (1.400)	loss nan (nan)	prob nan (nan)	GS 35.109 (35.109)	mem 39.288
Train: [83][65/750]	BT 0.057 (1.478)	DT 0.009 (1.431)	loss nan (nan)	prob nan (nan)	GS 31.125 (31.125)	mem 39.430
Train: [83][70/750]	BT 0.028 (1.396)	DT 0.002 (1.349)	loss nan (nan)	prob nan (nan)	GS 37.984 (37.984)	mem 39.432
Train: [83][75/750]	BT 0.034 (1.426)	DT 0.003 (1.380)	loss nan (nan)	prob nan (nan)	GS 32.141 (32.141)	mem 39.546
Train: [83][80/750]	BT 5.593 (1.408)	DT 5.505 (1.363)	loss nan (nan)	prob nan (nan)	GS 35.484 (35.484)	mem 39.812
Train: [83][85/750]	BT 0.038 (1.328)	DT 0.001 (1.283)	loss nan (nan)	prob nan (nan)	GS 32.922 (32.922)	mem 39.611
Train: [83][90/750]	BT 0.053 (1.342)	DT 0.002 (1.297)	loss nan (nan)	prob nan (nan)	GS 33.578 (33.578)	mem 39.774
Train: [83][95/750]	BT 0.028 (1.319)	DT 0.001 (1.273)	loss nan (nan)	prob nan (nan)	GS 33.703 (33.703)	mem 39.680
Train: [83][100/750]	BT 3.672 (1.341)	DT 3.612 (1.295)	loss nan (nan)	prob nan (nan)	GS 32.234 (32.234)	mem 39.722
Train: [83][105/750]	BT 0.036 (1.337)	DT 0.002 (1.291)	loss nan (nan)	prob nan (nan)	GS 31.094 (31.094)	mem 39.737
Train: [83][110/750]	BT 1.472 (1.316)	DT 1.449 (1.270)	loss nan (nan)	prob nan (nan)	GS 34.281 (34.281)	mem 39.743
Train: [83][115/750]	BT 0.027 (1.293)	DT 0.001 (1.248)	loss nan (nan)	prob nan (nan)	GS 29.125 (29.125)	mem 39.695
Train: [83][120/750]	BT 0.081 (1.293)	DT 0.018 (1.246)	loss nan (nan)	prob nan (nan)	GS 30.094 (30.094)	mem 39.730
Train: [83][125/750]	BT 0.049 (1.292)	DT 0.006 (1.246)	loss nan (nan)	prob nan (nan)	GS 29.719 (29.719)	mem 39.775
Train: [83][130/750]	BT 0.032 (1.298)	DT 0.001 (1.253)	loss nan (nan)	prob nan (nan)	GS 34.969 (34.969)	mem 39.738
Train: [83][135/750]	BT 0.036 (1.251)	DT 0.001 (1.207)	loss nan (nan)	prob nan (nan)	GS 33.156 (33.156)	mem 39.740
Train: [83][140/750]	BT 2.234 (1.279)	DT 2.190 (1.234)	loss nan (nan)	prob nan (nan)	GS 35.359 (35.359)	mem 39.806
Train: [83][145/750]	BT 0.078 (1.256)	DT 0.007 (1.210)	loss nan (nan)	prob nan (nan)	GS 35.688 (35.688)	mem 40.061
Train: [83][150/750]	BT 0.068 (1.254)	DT 0.001 (1.209)	loss nan (nan)	prob nan (nan)	GS 34.484 (34.484)	mem 39.734
Train: [83][155/750]	BT 0.086 (1.250)	DT 0.001 (1.204)	loss nan (nan)	prob nan (nan)	GS 29.266 (29.266)	mem 39.667
Train: [83][160/750]	BT 3.914 (1.243)	DT 3.857 (1.197)	loss nan (nan)	prob nan (nan)	GS 33.219 (33.219)	mem 39.699
Train: [83][165/750]	BT 0.054 (1.240)	DT 0.002 (1.194)	loss nan (nan)	prob nan (nan)	GS 31.703 (31.703)	mem 39.796
Train: [83][170/750]	BT 4.335 (1.235)	DT 4.303 (1.189)	loss nan (nan)	prob nan (nan)	GS 29.969 (29.969)	mem 39.877
Train: [83][175/750]	BT 0.034 (1.223)	DT 0.003 (1.177)	loss nan (nan)	prob nan (nan)	GS 32.672 (32.672)	mem 39.947
Train: [83][180/750]	BT 0.678 (1.210)	DT 0.616 (1.164)	loss nan (nan)	prob nan (nan)	GS 35.312 (35.312)	mem 40.420
Train: [83][185/750]	BT 0.046 (1.222)	DT 0.003 (1.175)	loss nan (nan)	prob nan (nan)	GS 30.172 (30.172)	mem 39.986
Train: [83][190/750]	BT 2.862 (1.224)	DT 2.822 (1.177)	loss nan (nan)	prob nan (nan)	GS 34.297 (34.297)	mem 39.861
Train: [83][195/750]	BT 0.108 (1.205)	DT 0.014 (1.159)	loss nan (nan)	prob nan (nan)	GS 32.766 (32.766)	mem 39.907
Train: [83][200/750]	BT 6.497 (1.221)	DT 6.460 (1.174)	loss nan (nan)	prob nan (nan)	GS 34.562 (34.562)	mem 39.839
Train: [83][205/750]	BT 0.028 (1.204)	DT 0.001 (1.158)	loss nan (nan)	prob nan (nan)	GS 29.781 (29.781)	mem 39.857
Train: [83][210/750]	BT 0.040 (1.190)	DT 0.002 (1.144)	loss nan (nan)	prob nan (nan)	GS 36.016 (36.016)	mem 39.999
Train: [83][215/750]	BT 0.032 (1.216)	DT 0.001 (1.170)	loss nan (nan)	prob nan (nan)	GS 32.750 (32.750)	mem 39.916
Train: [83][220/750]	BT 0.062 (1.189)	DT 0.009 (1.144)	loss nan (nan)	prob nan (nan)	GS 34.234 (34.234)	mem 39.917
Train: [83][225/750]	BT 0.100 (1.193)	DT 0.010 (1.146)	loss nan (nan)	prob nan (nan)	GS 42.688 (42.688)	mem 39.938
Train: [83][230/750]	BT 0.081 (1.206)	DT 0.001 (1.159)	loss nan (nan)	prob nan (nan)	GS 32.734 (32.734)	mem 39.837
Train: [83][235/750]	BT 0.042 (1.182)	DT 0.012 (1.135)	loss nan (nan)	prob nan (nan)	GS 39.656 (39.656)	mem 39.837
Train: [83][240/750]	BT 0.098 (1.208)	DT 0.020 (1.161)	loss nan (nan)	prob nan (nan)	GS 32.375 (32.375)	mem 39.873
Train: [83][245/750]	BT 0.059 (1.185)	DT 0.004 (1.138)	loss nan (nan)	prob nan (nan)	GS 30.156 (30.156)	mem 39.901
Train: [83][250/750]	BT 9.640 (1.215)	DT 9.609 (1.167)	loss nan (nan)	prob nan (nan)	GS 35.594 (35.594)	mem 40.073
Train: [83][255/750]	BT 0.083 (1.192)	DT 0.026 (1.145)	loss nan (nan)	prob nan (nan)	GS 28.984 (28.984)	mem 39.911
Train: [83][260/750]	BT 0.076 (1.171)	DT 0.026 (1.123)	loss nan (nan)	prob nan (nan)	GS 33.141 (33.141)	mem 39.913
Train: [83][265/750]	BT 0.030 (1.204)	DT 0.001 (1.156)	loss nan (nan)	prob nan (nan)	GS 36.609 (36.609)	mem 39.787
Train: [83][270/750]	BT 0.049 (1.182)	DT 0.002 (1.135)	loss nan (nan)	prob nan (nan)	GS 32.469 (32.469)	mem 39.788
Train: [83][275/750]	BT 0.050 (1.203)	DT 0.011 (1.156)	loss nan (nan)	prob nan (nan)	GS 31.625 (31.625)	mem 39.857
Train: [83][280/750]	BT 0.075 (1.183)	DT 0.012 (1.135)	loss nan (nan)	prob nan (nan)	GS 32.250 (32.250)	mem 39.931
Train: [83][285/750]	BT 0.025 (1.163)	DT 0.001 (1.116)	loss nan (nan)	prob nan (nan)	GS 35.469 (35.469)	mem 39.800
Train: [83][290/750]	BT 0.032 (1.184)	DT 0.001 (1.137)	loss nan (nan)	prob nan (nan)	GS 35.203 (35.203)	mem 39.912
Train: [83][295/750]	BT 0.031 (1.165)	DT 0.001 (1.118)	loss nan (nan)	prob nan (nan)	GS 31.938 (31.938)	mem 39.847
Train: [83][300/750]	BT 0.032 (1.179)	DT 0.002 (1.133)	loss nan (nan)	prob nan (nan)	GS 31.969 (31.969)	mem 39.855
Train: [83][305/750]	BT 0.041 (1.173)	DT 0.006 (1.126)	loss nan (nan)	prob nan (nan)	GS 31.297 (31.297)	mem 39.794
Train: [83][310/750]	BT 6.618 (1.179)	DT 6.585 (1.132)	loss nan (nan)	prob nan (nan)	GS 29.234 (29.234)	mem 39.859
Train: [83][315/750]	BT 0.056 (1.161)	DT 0.002 (1.114)	loss nan (nan)	prob nan (nan)	GS 28.750 (28.750)	mem 39.903
Train: [83][320/750]	BT 0.156 (1.161)	DT 0.090 (1.114)	loss nan (nan)	prob nan (nan)	GS 31.266 (31.266)	mem 39.874
Train: [83][325/750]	BT 0.034 (1.171)	DT 0.002 (1.124)	loss nan (nan)	prob nan (nan)	GS 28.438 (28.438)	mem 39.875
Train: [83][330/750]	BT 0.058 (1.170)	DT 0.021 (1.123)	loss nan (nan)	prob nan (nan)	GS 36.844 (36.844)	mem 39.779
Train: [83][335/750]	BT 0.030 (1.183)	DT 0.001 (1.136)	loss nan (nan)	prob nan (nan)	GS 34.094 (34.094)	mem 39.834
Train: [83][340/750]	BT 2.931 (1.175)	DT 2.849 (1.128)	loss nan (nan)	prob nan (nan)	GS 33.938 (33.938)	mem 39.787
Train: [83][345/750]	BT 0.046 (1.158)	DT 0.001 (1.112)	loss nan (nan)	prob nan (nan)	GS 34.281 (34.281)	mem 39.788
Train: [83][350/750]	BT 0.030 (1.167)	DT 0.001 (1.121)	loss nan (nan)	prob nan (nan)	GS 35.297 (35.297)	mem 39.854
Train: [83][355/750]	BT 0.127 (1.166)	DT 0.035 (1.119)	loss nan (nan)	prob nan (nan)	GS 30.422 (30.422)	mem 39.903
Train: [83][360/750]	BT 0.052 (1.177)	DT 0.004 (1.131)	loss nan (nan)	prob nan (nan)	GS 33.812 (33.812)	mem 39.857
Train: [83][365/750]	BT 0.032 (1.168)	DT 0.001 (1.122)	loss nan (nan)	prob nan (nan)	GS 31.047 (31.047)	mem 39.831
Train: [83][370/750]	BT 7.330 (1.176)	DT 7.299 (1.130)	loss nan (nan)	prob nan (nan)	GS 30.484 (30.484)	mem 39.850
Train: [83][375/750]	BT 0.030 (1.161)	DT 0.001 (1.115)	loss nan (nan)	prob nan (nan)	GS 31.641 (31.641)	mem 39.851
Train: [83][380/750]	BT 0.059 (1.160)	DT 0.006 (1.114)	loss nan (nan)	prob nan (nan)	GS 30.000 (30.000)	mem 39.870
Train: [83][385/750]	BT 0.033 (1.159)	DT 0.002 (1.113)	loss nan (nan)	prob nan (nan)	GS 31.453 (31.453)	mem 39.931
Train: [83][390/750]	BT 0.043 (1.165)	DT 0.005 (1.119)	loss nan (nan)	prob nan (nan)	GS 31.750 (31.750)	mem 39.840
Train: [83][395/750]	BT 0.032 (1.160)	DT 0.001 (1.114)	loss nan (nan)	prob nan (nan)	GS 35.953 (35.953)	mem 39.865
Train: [83][400/750]	BT 9.229 (1.169)	DT 9.198 (1.123)	loss nan (nan)	prob nan (nan)	GS 34.875 (34.875)	mem 39.953
Train: [83][405/750]	BT 0.065 (1.155)	DT 0.010 (1.109)	loss nan (nan)	prob nan (nan)	GS 30.219 (30.219)	mem 40.047
Train: [83][410/750]	BT 0.042 (1.158)	DT 0.005 (1.112)	loss nan (nan)	prob nan (nan)	GS 30.188 (30.188)	mem 39.875
Train: [83][415/750]	BT 0.030 (1.157)	DT 0.001 (1.111)	loss nan (nan)	prob nan (nan)	GS 27.250 (27.250)	mem 39.984
Train: [83][420/750]	BT 0.062 (1.172)	DT 0.006 (1.126)	loss nan (nan)	prob nan (nan)	GS 37.141 (37.141)	mem 40.028
Train: [83][425/750]	BT 0.033 (1.158)	DT 0.002 (1.112)	loss nan (nan)	prob nan (nan)	GS 32.031 (32.031)	mem 39.940
Train: [83][430/750]	BT 10.390 (1.175)	DT 10.360 (1.129)	loss nan (nan)	prob nan (nan)	GS 36.547 (36.547)	mem 39.874
Train: [83][435/750]	BT 0.031 (1.162)	DT 0.002 (1.116)	loss nan (nan)	prob nan (nan)	GS 26.891 (26.891)	mem 39.904
Train: [83][440/750]	BT 1.635 (1.153)	DT 1.603 (1.107)	loss nan (nan)	prob nan (nan)	GS 36.781 (36.781)	mem 39.908
Train: [83][445/750]	BT 0.030 (1.164)	DT 0.001 (1.119)	loss nan (nan)	prob nan (nan)	GS 30.406 (30.406)	mem 39.890
Train: [83][450/750]	BT 0.114 (1.151)	DT 0.010 (1.106)	loss nan (nan)	prob nan (nan)	GS 35.578 (35.578)	mem 39.927
Train: [83][455/750]	BT 0.041 (1.166)	DT 0.002 (1.121)	loss nan (nan)	prob nan (nan)	GS 36.062 (36.062)	mem 39.993
Train: [83][460/750]	BT 0.033 (1.154)	DT 0.001 (1.109)	loss nan (nan)	prob nan (nan)	GS 34.016 (34.016)	mem 39.994
Train: [83][465/750]	BT 0.031 (1.150)	DT 0.001 (1.105)	loss nan (nan)	prob nan (nan)	GS 30.500 (30.500)	mem 39.993
Train: [83][470/750]	BT 0.032 (1.157)	DT 0.001 (1.112)	loss nan (nan)	prob nan (nan)	GS 34.266 (34.266)	mem 40.015
Train: [83][475/750]	BT 0.036 (1.146)	DT 0.001 (1.101)	loss nan (nan)	prob nan (nan)	GS 34.750 (34.750)	mem 40.015
Train: [83][480/750]	BT 0.039 (1.158)	DT 0.002 (1.113)	loss nan (nan)	prob nan (nan)	GS 35.078 (35.078)	mem 40.039
Train: [83][485/750]	BT 0.093 (1.151)	DT 0.012 (1.106)	loss nan (nan)	prob nan (nan)	GS 32.438 (32.438)	mem 40.108
Train: [83][490/750]	BT 10.458 (1.167)	DT 10.417 (1.122)	loss nan (nan)	prob nan (nan)	GS 34.297 (34.297)	mem 39.971
Train: [83][495/750]	BT 0.047 (1.156)	DT 0.009 (1.111)	loss nan (nan)	prob nan (nan)	GS 28.531 (28.531)	mem 39.970
Train: [83][500/750]	BT 0.606 (1.146)	DT 0.498 (1.101)	loss nan (nan)	prob nan (nan)	GS 34.500 (34.500)	mem 39.971
Train: [83][505/750]	BT 0.028 (1.162)	DT 0.001 (1.117)	loss nan (nan)	prob nan (nan)	GS 30.656 (30.656)	mem 39.981
Train: [83][510/750]	BT 0.037 (1.151)	DT 0.005 (1.106)	loss nan (nan)	prob nan (nan)	GS 32.219 (32.219)	mem 40.006
Train: [83][515/750]	BT 0.031 (1.163)	DT 0.006 (1.118)	loss nan (nan)	prob nan (nan)	GS 27.141 (27.141)	mem 39.986
Train: [83][520/750]	BT 0.027 (1.152)	DT 0.001 (1.107)	loss nan (nan)	prob nan (nan)	GS 35.625 (35.625)	mem 39.986
Train: [83][525/750]	BT 0.064 (1.142)	DT 0.016 (1.097)	loss nan (nan)	prob nan (nan)	GS 29.328 (29.328)	mem 40.153
Train: [83][530/750]	BT 0.059 (1.151)	DT 0.001 (1.106)	loss nan (nan)	prob nan (nan)	GS 33.297 (33.297)	mem 39.960
Train: [83][535/750]	BT 0.028 (1.141)	DT 0.001 (1.096)	loss nan (nan)	prob nan (nan)	GS 33.078 (33.078)	mem 40.024
Train: [83][540/750]	BT 0.031 (1.155)	DT 0.001 (1.110)	loss nan (nan)	prob nan (nan)	GS 32.969 (32.969)	mem 39.935
Train: [83][545/750]	BT 0.041 (1.145)	DT 0.011 (1.100)	loss nan (nan)	prob nan (nan)	GS 29.719 (29.719)	mem 39.937
Train: [83][550/750]	BT 11.278 (1.162)	DT 11.244 (1.117)	loss nan (nan)	prob nan (nan)	GS 35.203 (35.203)	mem 39.954
Train: [83][555/750]	BT 0.023 (1.152)	DT 0.001 (1.107)	loss nan (nan)	prob nan (nan)	GS 27.609 (27.609)	mem 39.954
Train: [83][560/750]	BT 1.190 (1.144)	DT 1.148 (1.099)	loss nan (nan)	prob nan (nan)	GS 34.375 (34.375)	mem 40.046
Train: [83][565/750]	BT 0.105 (1.151)	DT 0.038 (1.106)	loss nan (nan)	prob nan (nan)	GS 31.344 (31.344)	mem 40.101
Train: [83][570/750]	BT 0.034 (1.141)	DT 0.001 (1.096)	loss nan (nan)	prob nan (nan)	GS 35.719 (35.719)	mem 39.997
Train: [83][575/750]	BT 0.055 (1.153)	DT 0.003 (1.109)	loss nan (nan)	prob nan (nan)	GS 25.828 (25.828)	mem 39.977
Train: [83][580/750]	BT 0.032 (1.144)	DT 0.001 (1.099)	loss nan (nan)	prob nan (nan)	GS 33.031 (33.031)	mem 40.036
Train: [83][585/750]	BT 0.037 (1.141)	DT 0.002 (1.097)	loss nan (nan)	prob nan (nan)	GS 33.203 (33.203)	mem 39.925
Train: [83][590/750]	BT 0.062 (1.148)	DT 0.022 (1.103)	loss nan (nan)	prob nan (nan)	GS 36.031 (36.031)	mem 40.022
Train: [83][595/750]	BT 0.051 (1.138)	DT 0.012 (1.094)	loss nan (nan)	prob nan (nan)	GS 34.047 (34.047)	mem 39.934
Train: [83][600/750]	BT 0.023 (1.155)	DT 0.001 (1.111)	loss nan (nan)	prob nan (nan)	GS 35.047 (35.047)	mem 39.875
Train: [83][605/750]	BT 0.047 (1.146)	DT 0.001 (1.102)	loss nan (nan)	prob nan (nan)	GS 31.125 (31.125)	mem 39.876
Train: [83][610/750]	BT 12.353 (1.157)	DT 12.317 (1.113)	loss nan (nan)	prob nan (nan)	GS 33.000 (33.000)	mem 40.012
Train: [83][615/750]	BT 0.046 (1.148)	DT 0.014 (1.104)	loss nan (nan)	prob nan (nan)	GS 32.531 (32.531)	mem 39.942
Train: [83][620/750]	BT 4.419 (1.146)	DT 4.385 (1.102)	loss nan (nan)	prob nan (nan)	GS 34.547 (34.547)	mem 39.920
Train: [83][625/750]	BT 0.028 (1.150)	DT 0.001 (1.106)	loss nan (nan)	prob nan (nan)	GS 32.797 (32.797)	mem 39.921
Train: [83][630/750]	BT 0.054 (1.141)	DT 0.001 (1.097)	loss nan (nan)	prob nan (nan)	GS 31.328 (31.328)	mem 39.949
Train: [83][635/750]	BT 0.032 (1.154)	DT 0.001 (1.109)	loss nan (nan)	prob nan (nan)	GS 32.828 (32.828)	mem 40.018
Train: [83][640/750]	BT 0.032 (1.145)	DT 0.001 (1.101)	loss nan (nan)	prob nan (nan)	GS 29.969 (29.969)	mem 39.987
Train: [83][645/750]	BT 0.055 (1.144)	DT 0.005 (1.100)	loss nan (nan)	prob nan (nan)	GS 28.375 (28.375)	mem 40.038
Train: [83][650/750]	BT 0.059 (1.144)	DT 0.013 (1.099)	loss nan (nan)	prob nan (nan)	GS 32.219 (32.219)	mem 40.012
Train: [83][655/750]	BT 0.042 (1.135)	DT 0.001 (1.091)	loss nan (nan)	prob nan (nan)	GS 31.203 (31.203)	mem 40.012
Train: [83][660/750]	BT 0.052 (1.147)	DT 0.006 (1.103)	loss nan (nan)	prob nan (nan)	GS 32.766 (32.766)	mem 39.977
Train: [83][665/750]	BT 0.057 (1.139)	DT 0.004 (1.095)	loss nan (nan)	prob nan (nan)	GS 31.984 (31.984)	mem 39.978
Train: [83][670/750]	BT 5.713 (1.156)	DT 5.680 (1.112)	loss nan (nan)	prob nan (nan)	GS 33.625 (33.625)	mem 40.156
Train: [83][675/750]	BT 0.053 (1.147)	DT 0.001 (1.103)	loss nan (nan)	prob nan (nan)	GS 29.453 (29.453)	mem 39.941
Train: [83][680/750]	BT 3.425 (1.144)	DT 3.338 (1.100)	loss nan (nan)	prob nan (nan)	GS 31.047 (31.047)	mem 39.919
Train: [83][685/750]	BT 0.022 (1.152)	DT 0.001 (1.108)	loss nan (nan)	prob nan (nan)	GS 29.406 (29.406)	mem 40.004
Train: [83][690/750]	BT 0.045 (1.144)	DT 0.001 (1.100)	loss nan (nan)	prob nan (nan)	GS 31.594 (31.594)	mem 40.003
Train: [83][695/750]	BT 0.044 (1.152)	DT 0.004 (1.108)	loss nan (nan)	prob nan (nan)	GS 33.219 (33.219)	mem 40.088
Train: [83][700/750]	BT 0.035 (1.144)	DT 0.003 (1.100)	loss nan (nan)	prob nan (nan)	GS 35.734 (35.734)	mem 40.303
Train: [83][705/750]	BT 0.047 (1.148)	DT 0.002 (1.104)	loss nan (nan)	prob nan (nan)	GS 37.812 (37.812)	mem 40.217
arpack error, retry= 0
Train: [83][710/750]	BT 0.031 (1.144)	DT 0.001 (1.100)	loss nan (nan)	prob nan (nan)	GS 31.609 (31.609)	mem 40.005
Train: [83][715/750]	BT 0.044 (1.136)	DT 0.002 (1.092)	loss nan (nan)	prob nan (nan)	GS 29.422 (29.422)	mem 40.043
Train: [83][720/750]	BT 0.052 (1.149)	DT 0.001 (1.106)	loss nan (nan)	prob nan (nan)	GS 33.047 (33.047)	mem 39.981
Train: [83][725/750]	BT 0.031 (1.142)	DT 0.001 (1.098)	loss nan (nan)	prob nan (nan)	GS 29.734 (29.734)	mem 39.968
Train: [83][730/750]	BT 4.192 (1.148)	DT 4.148 (1.104)	loss nan (nan)	prob nan (nan)	GS 34.188 (34.188)	mem 39.491
Train: [83][735/750]	BT 0.051 (1.140)	DT 0.001 (1.097)	loss nan (nan)	prob nan (nan)	GS 33.094 (33.094)	mem 39.494
Train: [83][740/750]	BT 3.556 (1.138)	DT 3.519 (1.094)	loss nan (nan)	prob nan (nan)	GS 30.578 (30.578)	mem 13.639
Train: [83][745/750]	BT 0.039 (1.133)	DT 0.009 (1.090)	loss nan (nan)	prob nan (nan)	GS 29.812 (29.812)	mem 10.664
Train: [83][750/750]	BT 0.030 (1.126)	DT 0.001 (1.082)	loss nan (nan)	prob nan (nan)	GS 34.094 (34.094)	mem 10.654
Train: [83][755/750]	BT 0.030 (1.123)	DT 0.001 (1.079)	loss nan (nan)	prob nan (nan)	GS 27.188 (27.188)	mem 7.638
epoch 83, total time 847.86
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [84][1/750]	BT 21.556 (21.556)	DT 21.459 (21.459)	loss nan (nan)	prob nan (nan)	GS 33.531 (33.531)	mem 38.746
Train: [84][5/750]	BT 6.189 (5.837)	DT 6.131 (5.764)	loss nan (nan)	prob nan (nan)	GS 33.094 (33.094)	mem 38.840
Train: [84][10/750]	BT 0.040 (2.951)	DT 0.006 (2.886)	loss nan (nan)	prob nan (nan)	GS 36.891 (36.891)	mem 38.776
Train: [84][15/750]	BT 1.038 (2.222)	DT 1.014 (2.166)	loss nan (nan)	prob nan (nan)	GS 27.734 (27.734)	mem 38.855
Train: [84][20/750]	BT 0.105 (2.013)	DT 0.002 (1.959)	loss nan (nan)	prob nan (nan)	GS 32.812 (32.812)	mem 38.991
Train: [84][25/750]	BT 3.787 (1.772)	DT 3.741 (1.718)	loss nan (nan)	prob nan (nan)	GS 30.375 (30.375)	mem 38.816
Train: [84][30/750]	BT 0.064 (1.692)	DT 0.007 (1.640)	loss nan (nan)	prob nan (nan)	GS 33.078 (33.078)	mem 39.142
Train: [84][35/750]	BT 0.063 (1.571)	DT 0.008 (1.520)	loss nan (nan)	prob nan (nan)	GS 27.906 (27.906)	mem 39.319
Train: [84][40/750]	BT 6.627 (1.656)	DT 6.589 (1.605)	loss nan (nan)	prob nan (nan)	GS 35.266 (35.266)	mem 40.206
Train: [84][45/750]	BT 0.049 (1.537)	DT 0.001 (1.484)	loss nan (nan)	prob nan (nan)	GS 33.578 (33.578)	mem 40.188
Train: [84][50/750]	BT 1.413 (1.428)	DT 1.377 (1.374)	loss nan (nan)	prob nan (nan)	GS 35.156 (35.156)	mem 39.995
Train: [84][55/750]	BT 0.037 (1.415)	DT 0.002 (1.363)	loss nan (nan)	prob nan (nan)	GS 30.344 (30.344)	mem 40.022
Train: [84][60/750]	BT 0.030 (1.377)	DT 0.001 (1.326)	loss nan (nan)	prob nan (nan)	GS 33.016 (33.016)	mem 40.015
Train: [84][65/750]	BT 0.034 (1.429)	DT 0.001 (1.378)	loss nan (nan)	prob nan (nan)	GS 35.625 (35.625)	mem 40.220
Train: [84][70/750]	BT 4.448 (1.426)	DT 4.402 (1.375)	loss nan (nan)	prob nan (nan)	GS 36.312 (36.312)	mem 40.847
Train: [84][75/750]	BT 0.034 (1.334)	DT 0.002 (1.284)	loss nan (nan)	prob nan (nan)	GS 34.172 (34.172)	mem 40.699
Train: [84][80/750]	BT 0.048 (1.358)	DT 0.001 (1.307)	loss nan (nan)	prob nan (nan)	GS 31.172 (31.172)	mem 41.678
Train: [84][85/750]	BT 0.026 (1.348)	DT 0.001 (1.297)	loss nan (nan)	prob nan (nan)	GS 36.156 (36.156)	mem 42.037
Train: [84][90/750]	BT 5.020 (1.378)	DT 4.986 (1.328)	loss nan (nan)	prob nan (nan)	GS 34.297 (34.297)	mem 42.017
Train: [84][95/750]	BT 0.077 (1.311)	DT 0.001 (1.261)	loss nan (nan)	prob nan (nan)	GS 30.547 (30.547)	mem 42.113
Train: [84][100/750]	BT 6.312 (1.311)	DT 6.276 (1.261)	loss nan (nan)	prob nan (nan)	GS 33.844 (33.844)	mem 42.415
Train: [84][105/750]	BT 0.067 (1.341)	DT 0.012 (1.291)	loss nan (nan)	prob nan (nan)	GS 31.531 (31.531)	mem 42.705
Train: [84][110/750]	BT 0.056 (1.282)	DT 0.001 (1.232)	loss nan (nan)	prob nan (nan)	GS 34.828 (34.828)	mem 42.725
Train: [84][115/750]	BT 0.096 (1.345)	DT 0.015 (1.293)	loss nan (nan)	prob nan (nan)	GS 30.578 (30.578)	mem 41.775
Train: [84][120/750]	BT 0.038 (1.290)	DT 0.001 (1.239)	loss nan (nan)	prob nan (nan)	GS 28.875 (28.875)	mem 41.777
Train: [84][125/750]	BT 0.050 (1.257)	DT 0.005 (1.206)	loss nan (nan)	prob nan (nan)	GS 33.547 (33.547)	mem 41.921
Train: [84][130/750]	BT 0.043 (1.287)	DT 0.002 (1.235)	loss nan (nan)	prob nan (nan)	GS 34.672 (34.672)	mem 41.853
Train: [84][135/750]	BT 0.051 (1.254)	DT 0.008 (1.203)	loss nan (nan)	prob nan (nan)	GS 25.281 (25.281)	mem 41.801
Train: [84][140/750]	BT 0.736 (1.285)	DT 0.708 (1.234)	loss nan (nan)	prob nan (nan)	GS 33.141 (33.141)	mem 41.984
Train: [84][145/750]	BT 0.050 (1.242)	DT 0.007 (1.192)	loss nan (nan)	prob nan (nan)	GS 30.984 (30.984)	mem 41.988
Train: [84][150/750]	BT 9.799 (1.277)	DT 9.746 (1.227)	loss nan (nan)	prob nan (nan)	GS 33.891 (33.891)	mem 42.194
Train: [84][155/750]	BT 0.039 (1.254)	DT 0.010 (1.204)	loss nan (nan)	prob nan (nan)	GS 28.406 (28.406)	mem 41.918
Train: [84][160/750]	BT 0.145 (1.217)	DT 0.114 (1.167)	loss nan (nan)	prob nan (nan)	GS 31.688 (31.688)	mem 41.920
Train: [84][165/750]	BT 0.042 (1.258)	DT 0.002 (1.208)	loss nan (nan)	prob nan (nan)	GS 32.156 (32.156)	mem 41.980
Train: [84][170/750]	BT 0.056 (1.222)	DT 0.002 (1.172)	loss nan (nan)	prob nan (nan)	GS 34.297 (34.297)	mem 41.986
Train: [84][175/750]	BT 0.105 (1.256)	DT 0.023 (1.206)	loss nan (nan)	prob nan (nan)	GS 31.078 (31.078)	mem 42.102
Train: [84][180/750]	BT 0.062 (1.224)	DT 0.012 (1.174)	loss nan (nan)	prob nan (nan)	GS 31.938 (31.938)	mem 42.108
Train: [84][185/750]	BT 0.035 (1.209)	DT 0.001 (1.159)	loss nan (nan)	prob nan (nan)	GS 32.797 (32.797)	mem 42.126
Train: [84][190/750]	BT 0.031 (1.234)	DT 0.001 (1.185)	loss nan (nan)	prob nan (nan)	GS 32.016 (32.016)	mem 41.950
Train: [84][195/750]	BT 0.052 (1.215)	DT 0.016 (1.166)	loss nan (nan)	prob nan (nan)	GS 34.172 (34.172)	mem 42.170
Train: [84][200/750]	BT 0.031 (1.236)	DT 0.001 (1.187)	loss nan (nan)	prob nan (nan)	GS 33.484 (33.484)	mem 41.966
Train: [84][205/750]	BT 0.042 (1.206)	DT 0.002 (1.158)	loss nan (nan)	prob nan (nan)	GS 34.031 (34.031)	mem 41.967
Train: [84][210/750]	BT 10.636 (1.247)	DT 10.566 (1.198)	loss nan (nan)	prob nan (nan)	GS 33.953 (33.953)	mem 42.018
Train: [84][215/750]	BT 0.052 (1.219)	DT 0.012 (1.170)	loss nan (nan)	prob nan (nan)	GS 32.125 (32.125)	mem 42.019
Train: [84][220/750]	BT 1.280 (1.201)	DT 1.248 (1.152)	loss nan (nan)	prob nan (nan)	GS 34.781 (34.781)	mem 42.061
Train: [84][225/750]	BT 0.052 (1.212)	DT 0.001 (1.163)	loss nan (nan)	prob nan (nan)	GS 27.250 (27.250)	mem 42.008
Train: [84][230/750]	BT 5.509 (1.211)	DT 5.485 (1.161)	loss nan (nan)	prob nan (nan)	GS 38.781 (38.781)	mem 42.028
Train: [84][235/750]	BT 0.032 (1.207)	DT 0.001 (1.158)	loss nan (nan)	prob nan (nan)	GS 30.891 (30.891)	mem 41.994
Train: [84][240/750]	BT 0.068 (1.191)	DT 0.011 (1.142)	loss nan (nan)	prob nan (nan)	GS 34.391 (34.391)	mem 42.040
Train: [84][245/750]	BT 0.050 (1.205)	DT 0.016 (1.156)	loss nan (nan)	prob nan (nan)	GS 31.453 (31.453)	mem 42.627
Train: [84][250/750]	BT 2.594 (1.196)	DT 2.511 (1.147)	loss nan (nan)	prob nan (nan)	GS 38.875 (38.875)	mem 42.037
Train: [84][255/750]	BT 0.032 (1.188)	DT 0.001 (1.139)	loss nan (nan)	prob nan (nan)	GS 31.922 (31.922)	mem 41.941
Train: [84][260/750]	BT 0.034 (1.199)	DT 0.001 (1.150)	loss nan (nan)	prob nan (nan)	GS 26.234 (26.234)	mem 42.019
Train: [84][265/750]	BT 0.175 (1.198)	DT 0.014 (1.149)	loss nan (nan)	prob nan (nan)	GS 33.516 (33.516)	mem 42.025
Train: [84][270/750]	BT 5.753 (1.205)	DT 5.722 (1.157)	loss nan (nan)	prob nan (nan)	GS 33.547 (33.547)	mem 42.068
Train: [84][275/750]	BT 0.031 (1.198)	DT 0.001 (1.150)	loss nan (nan)	prob nan (nan)	GS 33.828 (33.828)	mem 41.992
Train: [84][280/750]	BT 2.685 (1.187)	DT 2.645 (1.139)	loss nan (nan)	prob nan (nan)	GS 32.125 (32.125)	mem 42.007
Train: [84][285/750]	BT 0.032 (1.182)	DT 0.002 (1.133)	loss nan (nan)	prob nan (nan)	GS 27.094 (27.094)	mem 42.053
Train: [84][290/750]	BT 0.032 (1.201)	DT 0.001 (1.152)	loss nan (nan)	prob nan (nan)	GS 36.156 (36.156)	mem 41.922
Train: [84][295/750]	BT 0.035 (1.181)	DT 0.002 (1.133)	loss nan (nan)	prob nan (nan)	GS 38.203 (38.203)	mem 41.924
Train: [84][300/750]	BT 0.037 (1.195)	DT 0.002 (1.147)	loss nan (nan)	prob nan (nan)	GS 35.844 (35.844)	mem 42.414
Train: [84][305/750]	BT 0.064 (1.189)	DT 0.015 (1.141)	loss nan (nan)	prob nan (nan)	GS 30.344 (30.344)	mem 42.042
Train: [84][310/750]	BT 11.872 (1.209)	DT 11.815 (1.161)	loss nan (nan)	prob nan (nan)	GS 37.172 (37.172)	mem 42.013
Train: [84][315/750]	BT 0.027 (1.191)	DT 0.001 (1.143)	loss nan (nan)	prob nan (nan)	GS 30.391 (30.391)	mem 42.012
Train: [84][320/750]	BT 0.088 (1.173)	DT 0.005 (1.125)	loss nan (nan)	prob nan (nan)	GS 35.172 (35.172)	mem 42.012
Train: [84][325/750]	BT 0.052 (1.202)	DT 0.010 (1.154)	loss nan (nan)	prob nan (nan)	GS 31.453 (31.453)	mem 42.101
Train: [84][330/750]	BT 0.034 (1.184)	DT 0.001 (1.137)	loss nan (nan)	prob nan (nan)	GS 33.703 (33.703)	mem 42.087
Train: [84][335/750]	BT 0.028 (1.196)	DT 0.001 (1.148)	loss nan (nan)	prob nan (nan)	GS 28.594 (28.594)	mem 42.116
Train: [84][340/750]	BT 0.031 (1.179)	DT 0.001 (1.131)	loss nan (nan)	prob nan (nan)	GS 33.641 (33.641)	mem 42.051
Train: [84][345/750]	BT 0.028 (1.162)	DT 0.001 (1.115)	loss nan (nan)	prob nan (nan)	GS 28.078 (28.078)	mem 42.053
Train: [84][350/750]	BT 0.126 (1.183)	DT 0.023 (1.136)	loss nan (nan)	prob nan (nan)	GS 29.281 (29.281)	mem 42.026
Train: [84][355/750]	BT 0.056 (1.167)	DT 0.013 (1.120)	loss nan (nan)	prob nan (nan)	GS 32.172 (32.172)	mem 42.027
Train: [84][360/750]	BT 0.031 (1.188)	DT 0.002 (1.141)	loss nan (nan)	prob nan (nan)	GS 32.469 (32.469)	mem 42.013
Train: [84][365/750]	BT 0.025 (1.172)	DT 0.001 (1.126)	loss nan (nan)	prob nan (nan)	GS 26.500 (26.500)	mem 41.990
Train: [84][370/750]	BT 11.701 (1.189)	DT 11.655 (1.142)	loss nan (nan)	prob nan (nan)	GS 33.453 (33.453)	mem 41.969
Train: [84][375/750]	BT 0.030 (1.173)	DT 0.001 (1.127)	loss nan (nan)	prob nan (nan)	GS 33.891 (33.891)	mem 41.970
Train: [84][380/750]	BT 0.080 (1.158)	DT 0.002 (1.112)	loss nan (nan)	prob nan (nan)	GS 35.922 (35.922)	mem 41.972
Train: [84][385/750]	BT 0.028 (1.174)	DT 0.001 (1.128)	loss nan (nan)	prob nan (nan)	GS 30.391 (30.391)	mem 42.076
Train: [84][390/750]	BT 0.021 (1.160)	DT 0.001 (1.114)	loss nan (nan)	prob nan (nan)	GS 34.125 (34.125)	mem 42.017
Train: [84][395/750]	BT 0.031 (1.178)	DT 0.001 (1.132)	loss nan (nan)	prob nan (nan)	GS 27.672 (27.672)	mem 41.861
Train: [84][400/750]	BT 0.049 (1.164)	DT 0.010 (1.118)	loss nan (nan)	prob nan (nan)	GS 37.328 (37.328)	mem 41.865
Train: [84][405/750]	BT 0.029 (1.150)	DT 0.001 (1.104)	loss nan (nan)	prob nan (nan)	GS 26.953 (26.953)	mem 41.887
Train: [84][410/750]	BT 0.050 (1.173)	DT 0.001 (1.127)	loss nan (nan)	prob nan (nan)	GS 35.688 (35.688)	mem 42.116
Train: [84][415/750]	BT 0.028 (1.159)	DT 0.001 (1.114)	loss nan (nan)	prob nan (nan)	GS 32.188 (32.188)	mem 42.115
Train: [84][420/750]	BT 0.052 (1.176)	DT 0.001 (1.130)	loss nan (nan)	prob nan (nan)	GS 32.156 (32.156)	mem 40.228
Train: [84][425/750]	BT 0.038 (1.162)	DT 0.002 (1.117)	loss nan (nan)	prob nan (nan)	GS 30.891 (30.891)	mem 39.963
Train: [84][430/750]	BT 13.054 (1.180)	DT 13.029 (1.134)	loss nan (nan)	prob nan (nan)	GS 34.375 (34.375)	mem 40.104
Train: [84][435/750]	BT 0.045 (1.166)	DT 0.006 (1.121)	loss nan (nan)	prob nan (nan)	GS 30.953 (30.953)	mem 40.143
Train: [84][440/750]	BT 0.031 (1.154)	DT 0.001 (1.108)	loss nan (nan)	prob nan (nan)	GS 35.328 (35.328)	mem 40.069
Train: [84][445/750]	BT 0.034 (1.176)	DT 0.002 (1.131)	loss nan (nan)	prob nan (nan)	GS 35.391 (35.391)	mem 40.091
Train: [84][450/750]	BT 0.069 (1.164)	DT 0.001 (1.118)	loss nan (nan)	prob nan (nan)	GS 34.641 (34.641)	mem 40.095
Train: [84][455/750]	BT 0.050 (1.174)	DT 0.005 (1.128)	loss nan (nan)	prob nan (nan)	GS 30.953 (30.953)	mem 40.391
Train: [84][460/750]	BT 0.036 (1.162)	DT 0.001 (1.116)	loss nan (nan)	prob nan (nan)	GS 34.234 (34.234)	mem 40.101
Train: [84][465/750]	BT 0.052 (1.150)	DT 0.008 (1.104)	loss nan (nan)	prob nan (nan)	GS 33.203 (33.203)	mem 40.173
Train: [84][470/750]	BT 0.075 (1.158)	DT 0.016 (1.112)	loss nan (nan)	prob nan (nan)	GS 31.641 (31.641)	mem 40.123
Train: [84][475/750]	BT 0.070 (1.146)	DT 0.021 (1.101)	loss nan (nan)	prob nan (nan)	GS 28.203 (28.203)	mem 40.057
Train: [84][480/750]	BT 0.042 (1.164)	DT 0.001 (1.118)	loss nan (nan)	prob nan (nan)	GS 31.875 (31.875)	mem 40.083
Train: [84][485/750]	BT 0.024 (1.152)	DT 0.001 (1.107)	loss nan (nan)	prob nan (nan)	GS 30.344 (30.344)	mem 40.052
Train: [84][490/750]	BT 13.712 (1.169)	DT 13.680 (1.124)	loss nan (nan)	prob nan (nan)	GS 34.562 (34.562)	mem 40.055
Train: [84][495/750]	BT 0.115 (1.158)	DT 0.005 (1.112)	loss nan (nan)	prob nan (nan)	GS 33.062 (33.062)	mem 40.122
Train: [84][500/750]	BT 0.048 (1.147)	DT 0.015 (1.101)	loss nan (nan)	prob nan (nan)	GS 40.266 (40.266)	mem 40.056
Train: [84][505/750]	BT 0.037 (1.162)	DT 0.001 (1.116)	loss nan (nan)	prob nan (nan)	GS 33.250 (33.250)	mem 40.032
Train: [84][510/750]	BT 0.033 (1.151)	DT 0.001 (1.105)	loss nan (nan)	prob nan (nan)	GS 36.938 (36.938)	mem 40.032
Train: [84][515/750]	BT 0.036 (1.160)	DT 0.005 (1.115)	loss nan (nan)	prob nan (nan)	GS 29.938 (29.938)	mem 40.050
Train: [84][520/750]	BT 0.072 (1.150)	DT 0.001 (1.104)	loss nan (nan)	prob nan (nan)	GS 29.188 (29.188)	mem 40.050
Train: [84][525/750]	BT 0.043 (1.139)	DT 0.004 (1.094)	loss nan (nan)	prob nan (nan)	GS 28.500 (28.500)	mem 40.050
Train: [84][530/750]	BT 0.036 (1.154)	DT 0.001 (1.109)	loss nan (nan)	prob nan (nan)	GS 33.391 (33.391)	mem 40.045
Train: [84][535/750]	BT 0.047 (1.144)	DT 0.002 (1.099)	loss nan (nan)	prob nan (nan)	GS 33.234 (33.234)	mem 40.107
Train: [84][540/750]	BT 0.078 (1.164)	DT 0.010 (1.118)	loss nan (nan)	prob nan (nan)	GS 33.766 (33.766)	mem 40.009
Train: [84][545/750]	BT 0.073 (1.153)	DT 0.002 (1.108)	loss nan (nan)	prob nan (nan)	GS 30.500 (30.500)	mem 40.027
Train: [84][550/750]	BT 10.824 (1.163)	DT 10.800 (1.118)	loss nan (nan)	prob nan (nan)	GS 30.062 (30.062)	mem 40.041
Train: [84][555/750]	BT 0.133 (1.153)	DT 0.001 (1.108)	loss nan (nan)	prob nan (nan)	GS 32.484 (32.484)	mem 40.040
Train: [84][560/750]	BT 0.050 (1.143)	DT 0.001 (1.098)	loss nan (nan)	prob nan (nan)	GS 37.812 (37.812)	mem 40.040
Train: [84][565/750]	BT 0.036 (1.153)	DT 0.004 (1.108)	loss nan (nan)	prob nan (nan)	GS 29.438 (29.438)	mem 40.156
Train: [84][570/750]	BT 0.035 (1.144)	DT 0.002 (1.098)	loss nan (nan)	prob nan (nan)	GS 30.875 (30.875)	mem 40.129
Train: [84][575/750]	BT 0.045 (1.154)	DT 0.011 (1.108)	loss nan (nan)	prob nan (nan)	GS 33.453 (33.453)	mem 40.071
Train: [84][580/750]	BT 0.028 (1.149)	DT 0.001 (1.104)	loss nan (nan)	prob nan (nan)	GS 29.781 (29.781)	mem 40.068
Train: [84][585/750]	BT 0.033 (1.140)	DT 0.002 (1.094)	loss nan (nan)	prob nan (nan)	GS 34.312 (34.312)	mem 40.258
Train: [84][590/750]	BT 0.038 (1.149)	DT 0.001 (1.104)	loss nan (nan)	prob nan (nan)	GS 31.250 (31.250)	mem 39.956
Train: [84][595/750]	BT 0.032 (1.140)	DT 0.002 (1.094)	loss nan (nan)	prob nan (nan)	GS 31.625 (31.625)	mem 39.965
Train: [84][600/750]	BT 0.077 (1.152)	DT 0.020 (1.107)	loss nan (nan)	prob nan (nan)	GS 36.469 (36.469)	mem 39.994
Train: [84][605/750]	BT 0.077 (1.146)	DT 0.001 (1.100)	loss nan (nan)	prob nan (nan)	GS 28.406 (28.406)	mem 40.087
Train: [84][610/750]	BT 7.809 (1.152)	DT 7.779 (1.106)	loss nan (nan)	prob nan (nan)	GS 32.906 (32.906)	mem 40.103
Train: [84][615/750]	BT 0.042 (1.147)	DT 0.002 (1.101)	loss nan (nan)	prob nan (nan)	GS 31.188 (31.188)	mem 40.163
Train: [84][620/750]	BT 0.041 (1.138)	DT 0.010 (1.092)	loss nan (nan)	prob nan (nan)	GS 34.734 (34.734)	mem 40.032
Train: [84][625/750]	BT 0.090 (1.149)	DT 0.014 (1.103)	loss nan (nan)	prob nan (nan)	GS 28.281 (28.281)	mem 40.068
Train: [84][630/750]	BT 0.037 (1.140)	DT 0.004 (1.095)	loss nan (nan)	prob nan (nan)	GS 29.578 (29.578)	mem 40.158
Train: [84][635/750]	BT 0.036 (1.144)	DT 0.002 (1.099)	loss nan (nan)	prob nan (nan)	GS 33.828 (33.828)	mem 40.059
Train: [84][640/750]	BT 0.088 (1.143)	DT 0.015 (1.098)	loss nan (nan)	prob nan (nan)	GS 31.375 (31.375)	mem 39.940
Train: [84][645/750]	BT 0.037 (1.138)	DT 0.004 (1.092)	loss nan (nan)	prob nan (nan)	GS 29.844 (29.844)	mem 39.981
Train: [84][650/750]	BT 0.090 (1.147)	DT 0.010 (1.101)	loss nan (nan)	prob nan (nan)	GS 34.734 (34.734)	mem 40.054
Train: [84][655/750]	BT 0.050 (1.138)	DT 0.012 (1.093)	loss nan (nan)	prob nan (nan)	GS 32.438 (32.438)	mem 40.018
Train: [84][660/750]	BT 3.212 (1.149)	DT 3.177 (1.103)	loss nan (nan)	prob nan (nan)	GS 34.484 (34.484)	mem 40.068
Train: [84][665/750]	BT 0.070 (1.141)	DT 0.016 (1.096)	loss nan (nan)	prob nan (nan)	GS 29.766 (29.766)	mem 40.025
Train: [84][670/750]	BT 12.644 (1.153)	DT 12.612 (1.107)	loss nan (nan)	prob nan (nan)	GS 34.438 (34.438)	mem 40.043
Train: [84][675/750]	BT 0.068 (1.146)	DT 0.001 (1.100)	loss nan (nan)	prob nan (nan)	GS 32.156 (32.156)	mem 40.021
Train: [84][680/750]	BT 0.084 (1.138)	DT 0.005 (1.092)	loss nan (nan)	prob nan (nan)	GS 31.562 (31.562)	mem 40.024
Train: [84][685/750]	BT 0.037 (1.149)	DT 0.001 (1.103)	loss nan (nan)	prob nan (nan)	GS 34.656 (34.656)	mem 39.987
Train: [84][690/750]	BT 0.054 (1.141)	DT 0.014 (1.095)	loss nan (nan)	prob nan (nan)	GS 32.234 (32.234)	mem 39.981
Train: [84][695/750]	BT 0.052 (1.146)	DT 0.017 (1.100)	loss nan (nan)	prob nan (nan)	GS 31.469 (31.469)	mem 40.118
Train: [84][700/750]	BT 0.032 (1.145)	DT 0.001 (1.099)	loss nan (nan)	prob nan (nan)	GS 36.078 (36.078)	mem 39.983
Train: [84][705/750]	BT 0.039 (1.137)	DT 0.003 (1.092)	loss nan (nan)	prob nan (nan)	GS 28.953 (28.953)	mem 39.984
arpack error, retry= 0
Train: [84][710/750]	BT 2.429 (1.147)	DT 2.394 (1.101)	loss nan (nan)	prob nan (nan)	GS 33.062 (33.062)	mem 40.132
Train: [84][715/750]	BT 0.038 (1.139)	DT 0.003 (1.093)	loss nan (nan)	prob nan (nan)	GS 31.922 (31.922)	mem 40.063
Train: [84][720/750]	BT 7.661 (1.149)	DT 7.629 (1.103)	loss nan (nan)	prob nan (nan)	GS 35.359 (35.359)	mem 40.003
Train: [84][725/750]	BT 0.041 (1.142)	DT 0.004 (1.097)	loss nan (nan)	prob nan (nan)	GS 31.875 (31.875)	mem 39.951
Train: [84][730/750]	BT 7.712 (1.146)	DT 7.682 (1.100)	loss nan (nan)	prob nan (nan)	GS 32.703 (32.703)	mem 39.531
Train: [84][735/750]	BT 0.023 (1.145)	DT 0.003 (1.099)	loss nan (nan)	prob nan (nan)	GS 28.312 (28.312)	mem 39.409
Train: [84][740/750]	BT 0.031 (1.138)	DT 0.001 (1.092)	loss nan (nan)	prob nan (nan)	GS 32.531 (32.531)	mem 39.411
Train: [84][745/750]	BT 0.042 (1.138)	DT 0.005 (1.093)	loss nan (nan)	prob nan (nan)	GS 33.719 (33.719)	mem 10.612
Train: [84][750/750]	BT 0.028 (1.131)	DT 0.001 (1.085)	loss nan (nan)	prob nan (nan)	GS 36.531 (36.531)	mem 10.612
Train: [84][755/750]	BT 0.032 (1.125)	DT 0.001 (1.079)	loss nan (nan)	prob nan (nan)	GS 33.375 (33.375)	mem 10.514
epoch 84, total time 850.30
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [85][1/750]	BT 20.382 (20.382)	DT 20.306 (20.306)	loss nan (nan)	prob nan (nan)	GS 30.281 (30.281)	mem 39.034
Train: [85][5/750]	BT 0.039 (4.735)	DT 0.007 (4.693)	loss nan (nan)	prob nan (nan)	GS 28.938 (28.938)	mem 39.165
Train: [85][10/750]	BT 0.029 (2.407)	DT 0.001 (2.370)	loss nan (nan)	prob nan (nan)	GS 35.406 (35.406)	mem 39.085
Train: [85][15/750]	BT 0.041 (2.581)	DT 0.005 (2.539)	loss nan (nan)	prob nan (nan)	GS 33.156 (33.156)	mem 39.561
Train: [85][20/750]	BT 0.128 (1.949)	DT 0.008 (1.905)	loss nan (nan)	prob nan (nan)	GS 29.406 (29.406)	mem 39.400
Train: [85][25/750]	BT 0.040 (1.571)	DT 0.008 (1.525)	loss nan (nan)	prob nan (nan)	GS 29.812 (29.812)	mem 39.432
Train: [85][30/750]	BT 0.057 (1.783)	DT 0.002 (1.738)	loss nan (nan)	prob nan (nan)	GS 31.344 (31.344)	mem 39.437
Train: [85][35/750]	BT 0.071 (1.537)	DT 0.006 (1.490)	loss nan (nan)	prob nan (nan)	GS 33.328 (33.328)	mem 39.441
Train: [85][40/750]	BT 2.211 (1.724)	DT 2.168 (1.678)	loss nan (nan)	prob nan (nan)	GS 35.953 (35.953)	mem 39.550
Train: [85][45/750]	BT 0.029 (1.536)	DT 0.001 (1.492)	loss nan (nan)	prob nan (nan)	GS 27.391 (27.391)	mem 39.550
Train: [85][50/750]	BT 9.465 (1.577)	DT 9.426 (1.532)	loss nan (nan)	prob nan (nan)	GS 32.750 (32.750)	mem 39.628
Train: [85][55/750]	BT 0.039 (1.471)	DT 0.001 (1.425)	loss nan (nan)	prob nan (nan)	GS 33.594 (33.594)	mem 39.566
Train: [85][60/750]	BT 0.055 (1.352)	DT 0.001 (1.307)	loss nan (nan)	prob nan (nan)	GS 31.859 (31.859)	mem 39.568
Train: [85][65/750]	BT 0.030 (1.457)	DT 0.001 (1.411)	loss nan (nan)	prob nan (nan)	GS 30.625 (30.625)	mem 39.649
Train: [85][70/750]	BT 0.030 (1.357)	DT 0.003 (1.311)	loss nan (nan)	prob nan (nan)	GS 30.500 (30.500)	mem 39.733
Train: [85][75/750]	BT 0.028 (1.411)	DT 0.001 (1.366)	loss nan (nan)	prob nan (nan)	GS 30.578 (30.578)	mem 39.617
Train: [85][80/750]	BT 0.049 (1.343)	DT 0.001 (1.298)	loss nan (nan)	prob nan (nan)	GS 32.625 (32.625)	mem 39.620
Train: [85][85/750]	BT 0.032 (1.267)	DT 0.002 (1.222)	loss nan (nan)	prob nan (nan)	GS 33.281 (33.281)	mem 39.620
Train: [85][90/750]	BT 0.020 (1.372)	DT 0.001 (1.327)	loss nan (nan)	prob nan (nan)	GS 36.031 (36.031)	mem 39.660
Train: [85][95/750]	BT 0.068 (1.302)	DT 0.018 (1.257)	loss nan (nan)	prob nan (nan)	GS 32.812 (32.812)	mem 39.858
Train: [85][100/750]	BT 0.250 (1.356)	DT 0.221 (1.311)	loss nan (nan)	prob nan (nan)	GS 35.172 (35.172)	mem 39.785
Train: [85][105/750]	BT 0.033 (1.293)	DT 0.002 (1.249)	loss nan (nan)	prob nan (nan)	GS 28.250 (28.250)	mem 39.805
Train: [85][110/750]	BT 10.367 (1.330)	DT 10.323 (1.286)	loss nan (nan)	prob nan (nan)	GS 32.016 (32.016)	mem 39.769
Train: [85][115/750]	BT 0.034 (1.288)	DT 0.002 (1.244)	loss nan (nan)	prob nan (nan)	GS 33.938 (33.938)	mem 39.870
Train: [85][120/750]	BT 0.049 (1.237)	DT 0.010 (1.193)	loss nan (nan)	prob nan (nan)	GS 38.906 (38.906)	mem 39.748
Train: [85][125/750]	BT 0.029 (1.301)	DT 0.001 (1.256)	loss nan (nan)	prob nan (nan)	GS 29.859 (29.859)	mem 39.685
Train: [85][130/750]	BT 0.030 (1.252)	DT 0.001 (1.208)	loss nan (nan)	prob nan (nan)	GS 33.422 (33.422)	mem 39.689
Train: [85][135/750]	BT 0.029 (1.310)	DT 0.001 (1.267)	loss nan (nan)	prob nan (nan)	GS 30.922 (30.922)	mem 39.726
Train: [85][140/750]	BT 0.027 (1.265)	DT 0.001 (1.222)	loss nan (nan)	prob nan (nan)	GS 32.500 (32.500)	mem 39.732
Train: [85][145/750]	BT 0.047 (1.223)	DT 0.006 (1.180)	loss nan (nan)	prob nan (nan)	GS 33.812 (33.812)	mem 39.738
Train: [85][150/750]	BT 0.048 (1.278)	DT 0.011 (1.235)	loss nan (nan)	prob nan (nan)	GS 34.109 (34.109)	mem 39.791
Train: [85][155/750]	BT 0.041 (1.238)	DT 0.001 (1.195)	loss nan (nan)	prob nan (nan)	GS 29.109 (29.109)	mem 39.803
Train: [85][160/750]	BT 0.029 (1.284)	DT 0.001 (1.242)	loss nan (nan)	prob nan (nan)	GS 32.875 (32.875)	mem 39.761
Train: [85][165/750]	BT 0.026 (1.246)	DT 0.005 (1.204)	loss nan (nan)	prob nan (nan)	GS 33.438 (33.438)	mem 39.765
Train: [85][170/750]	BT 8.955 (1.264)	DT 8.892 (1.221)	loss nan (nan)	prob nan (nan)	GS 36.578 (36.578)	mem 39.869
Train: [85][175/750]	BT 0.028 (1.229)	DT 0.001 (1.187)	loss nan (nan)	prob nan (nan)	GS 28.109 (28.109)	mem 39.879
Train: [85][180/750]	BT 0.079 (1.196)	DT 0.001 (1.154)	loss nan (nan)	prob nan (nan)	GS 37.391 (37.391)	mem 39.979
Train: [85][185/750]	BT 0.030 (1.236)	DT 0.001 (1.193)	loss nan (nan)	prob nan (nan)	GS 33.781 (33.781)	mem 39.847
Train: [85][190/750]	BT 0.059 (1.211)	DT 0.002 (1.168)	loss nan (nan)	prob nan (nan)	GS 30.969 (30.969)	mem 39.881
Train: [85][195/750]	BT 0.034 (1.236)	DT 0.002 (1.193)	loss nan (nan)	prob nan (nan)	GS 29.000 (29.000)	mem 39.956
Train: [85][200/750]	BT 0.056 (1.211)	DT 0.002 (1.168)	loss nan (nan)	prob nan (nan)	GS 33.062 (33.062)	mem 39.940
Train: [85][205/750]	BT 0.028 (1.182)	DT 0.001 (1.140)	loss nan (nan)	prob nan (nan)	GS 27.688 (27.688)	mem 39.977
Train: [85][210/750]	BT 0.049 (1.215)	DT 0.012 (1.173)	loss nan (nan)	prob nan (nan)	GS 31.484 (31.484)	mem 40.727
Train: [85][215/750]	BT 0.031 (1.188)	DT 0.001 (1.146)	loss nan (nan)	prob nan (nan)	GS 30.531 (30.531)	mem 40.782
Train: [85][220/750]	BT 2.363 (1.223)	DT 2.318 (1.182)	loss nan (nan)	prob nan (nan)	GS 33.969 (33.969)	mem 41.596
Train: [85][225/750]	BT 0.063 (1.199)	DT 0.012 (1.156)	loss nan (nan)	prob nan (nan)	GS 34.719 (34.719)	mem 41.530
Train: [85][230/750]	BT 12.502 (1.228)	DT 12.447 (1.185)	loss nan (nan)	prob nan (nan)	GS 36.969 (36.969)	mem 39.962
Train: [85][235/750]	BT 0.032 (1.209)	DT 0.002 (1.167)	loss nan (nan)	prob nan (nan)	GS 30.391 (30.391)	mem 40.003
Train: [85][240/750]	BT 0.075 (1.185)	DT 0.013 (1.142)	loss nan (nan)	prob nan (nan)	GS 34.750 (34.750)	mem 39.938
Train: [85][245/750]	BT 0.085 (1.219)	DT 0.005 (1.177)	loss nan (nan)	prob nan (nan)	GS 31.984 (31.984)	mem 39.720
Train: [85][250/750]	BT 0.038 (1.196)	DT 0.001 (1.153)	loss nan (nan)	prob nan (nan)	GS 36.219 (36.219)	mem 39.685
Train: [85][255/750]	BT 0.034 (1.215)	DT 0.002 (1.172)	loss nan (nan)	prob nan (nan)	GS 27.812 (27.812)	mem 39.941
Train: [85][260/750]	BT 0.055 (1.197)	DT 0.009 (1.154)	loss nan (nan)	prob nan (nan)	GS 35.281 (35.281)	mem 39.963
Train: [85][265/750]	BT 0.040 (1.175)	DT 0.001 (1.132)	loss nan (nan)	prob nan (nan)	GS 31.125 (31.125)	mem 39.906
Train: [85][270/750]	BT 0.033 (1.207)	DT 0.001 (1.165)	loss nan (nan)	prob nan (nan)	GS 31.531 (31.531)	mem 39.890
Train: [85][275/750]	BT 0.098 (1.186)	DT 0.012 (1.144)	loss nan (nan)	prob nan (nan)	GS 26.938 (26.938)	mem 39.913
Train: [85][280/750]	BT 0.034 (1.215)	DT 0.001 (1.172)	loss nan (nan)	prob nan (nan)	GS 38.891 (38.891)	mem 39.898
Train: [85][285/750]	BT 0.032 (1.194)	DT 0.001 (1.152)	loss nan (nan)	prob nan (nan)	GS 33.266 (33.266)	mem 39.896
Train: [85][290/750]	BT 12.024 (1.216)	DT 11.982 (1.173)	loss nan (nan)	prob nan (nan)	GS 30.844 (30.844)	mem 39.960
Train: [85][295/750]	BT 0.040 (1.196)	DT 0.002 (1.153)	loss nan (nan)	prob nan (nan)	GS 32.484 (32.484)	mem 39.961
Train: [85][300/750]	BT 0.051 (1.177)	DT 0.009 (1.134)	loss nan (nan)	prob nan (nan)	GS 30.375 (30.375)	mem 39.962
Train: [85][305/750]	BT 0.065 (1.199)	DT 0.014 (1.157)	loss nan (nan)	prob nan (nan)	GS 30.344 (30.344)	mem 39.937
Train: [85][310/750]	BT 0.066 (1.181)	DT 0.015 (1.138)	loss nan (nan)	prob nan (nan)	GS 34.203 (34.203)	mem 39.937
Train: [85][315/750]	BT 0.031 (1.204)	DT 0.001 (1.162)	loss nan (nan)	prob nan (nan)	GS 35.797 (35.797)	mem 40.024
Train: [85][320/750]	BT 0.075 (1.186)	DT 0.001 (1.144)	loss nan (nan)	prob nan (nan)	GS 37.031 (37.031)	mem 40.032
Train: [85][325/750]	BT 0.059 (1.169)	DT 0.012 (1.126)	loss nan (nan)	prob nan (nan)	GS 33.562 (33.562)	mem 40.067
Train: [85][330/750]	BT 0.024 (1.199)	DT 0.001 (1.156)	loss nan (nan)	prob nan (nan)	GS 31.531 (31.531)	mem 40.290
Train: [85][335/750]	BT 0.062 (1.181)	DT 0.018 (1.139)	loss nan (nan)	prob nan (nan)	GS 31.047 (31.047)	mem 40.298
Train: [85][340/750]	BT 0.034 (1.196)	DT 0.002 (1.153)	loss nan (nan)	prob nan (nan)	GS 36.156 (36.156)	mem 40.420
Train: [85][345/750]	BT 0.032 (1.179)	DT 0.001 (1.136)	loss nan (nan)	prob nan (nan)	GS 25.828 (25.828)	mem 40.421
Train: [85][350/750]	BT 10.896 (1.194)	DT 10.846 (1.151)	loss nan (nan)	prob nan (nan)	GS 30.625 (30.625)	mem 40.551
Train: [85][355/750]	BT 0.029 (1.177)	DT 0.001 (1.135)	loss nan (nan)	prob nan (nan)	GS 27.500 (27.500)	mem 40.475
Train: [85][360/750]	BT 0.103 (1.162)	DT 0.010 (1.119)	loss nan (nan)	prob nan (nan)	GS 31.891 (31.891)	mem 40.474
Train: [85][365/750]	BT 0.025 (1.186)	DT 0.001 (1.144)	loss nan (nan)	prob nan (nan)	GS 32.672 (32.672)	mem 40.436
Train: [85][370/750]	BT 0.045 (1.170)	DT 0.001 (1.128)	loss nan (nan)	prob nan (nan)	GS 29.469 (29.469)	mem 40.437
Train: [85][375/750]	BT 0.020 (1.187)	DT 0.001 (1.145)	loss nan (nan)	prob nan (nan)	GS 29.578 (29.578)	mem 40.420
Train: [85][380/750]	BT 0.067 (1.172)	DT 0.013 (1.130)	loss nan (nan)	prob nan (nan)	GS 33.953 (33.953)	mem 40.474
Train: [85][385/750]	BT 0.024 (1.158)	DT 0.001 (1.116)	loss nan (nan)	prob nan (nan)	GS 27.422 (27.422)	mem 40.422
Train: [85][390/750]	BT 0.028 (1.179)	DT 0.001 (1.137)	loss nan (nan)	prob nan (nan)	GS 34.469 (34.469)	mem 40.180
Train: [85][395/750]	BT 0.034 (1.164)	DT 0.001 (1.123)	loss nan (nan)	prob nan (nan)	GS 28.641 (28.641)	mem 40.198
Train: [85][400/750]	BT 0.025 (1.182)	DT 0.001 (1.140)	loss nan (nan)	prob nan (nan)	GS 36.641 (36.641)	mem 40.001
Train: [85][405/750]	BT 0.098 (1.168)	DT 0.017 (1.126)	loss nan (nan)	prob nan (nan)	GS 29.734 (29.734)	mem 40.000
Train: [85][410/750]	BT 11.593 (1.183)	DT 11.560 (1.141)	loss nan (nan)	prob nan (nan)	GS 35.078 (35.078)	mem 39.869
Train: [85][415/750]	BT 0.078 (1.169)	DT 0.011 (1.127)	loss nan (nan)	prob nan (nan)	GS 30.141 (30.141)	mem 39.960
Train: [85][420/750]	BT 0.032 (1.156)	DT 0.001 (1.114)	loss nan (nan)	prob nan (nan)	GS 35.297 (35.297)	mem 39.872
Train: [85][425/750]	BT 0.044 (1.173)	DT 0.006 (1.131)	loss nan (nan)	prob nan (nan)	GS 32.172 (32.172)	mem 39.967
Train: [85][430/750]	BT 0.061 (1.160)	DT 0.020 (1.118)	loss nan (nan)	prob nan (nan)	GS 32.938 (32.938)	mem 39.969
Train: [85][435/750]	BT 0.062 (1.181)	DT 0.010 (1.140)	loss nan (nan)	prob nan (nan)	GS 32.078 (32.078)	mem 40.128
Train: [85][440/750]	BT 0.030 (1.169)	DT 0.001 (1.127)	loss nan (nan)	prob nan (nan)	GS 36.484 (36.484)	mem 39.907
Train: [85][445/750]	BT 0.071 (1.156)	DT 0.010 (1.114)	loss nan (nan)	prob nan (nan)	GS 34.828 (34.828)	mem 39.952
Train: [85][450/750]	BT 0.039 (1.176)	DT 0.002 (1.134)	loss nan (nan)	prob nan (nan)	GS 30.984 (30.984)	mem 39.743
Train: [85][455/750]	BT 0.044 (1.163)	DT 0.002 (1.122)	loss nan (nan)	prob nan (nan)	GS 33.547 (33.547)	mem 39.876
Train: [85][460/750]	BT 2.617 (1.175)	DT 2.549 (1.133)	loss nan (nan)	prob nan (nan)	GS 36.734 (36.734)	mem 39.875
Train: [85][465/750]	BT 0.033 (1.163)	DT 0.001 (1.121)	loss nan (nan)	prob nan (nan)	GS 30.969 (30.969)	mem 39.875
Train: [85][470/750]	BT 11.365 (1.175)	DT 11.331 (1.133)	loss nan (nan)	prob nan (nan)	GS 35.672 (35.672)	mem 39.905
Train: [85][475/750]	BT 0.026 (1.165)	DT 0.002 (1.123)	loss nan (nan)	prob nan (nan)	GS 28.516 (28.516)	mem 39.943
Train: [85][480/750]	BT 0.047 (1.153)	DT 0.002 (1.111)	loss nan (nan)	prob nan (nan)	GS 30.438 (30.438)	mem 39.955
Train: [85][485/750]	BT 0.096 (1.172)	DT 0.029 (1.130)	loss nan (nan)	prob nan (nan)	GS 31.391 (31.391)	mem 39.873
Train: [85][490/750]	BT 0.091 (1.161)	DT 0.023 (1.119)	loss nan (nan)	prob nan (nan)	GS 33.250 (33.250)	mem 39.874
Train: [85][495/750]	BT 0.057 (1.171)	DT 0.002 (1.129)	loss nan (nan)	prob nan (nan)	GS 30.203 (30.203)	mem 39.887
Train: [85][500/750]	BT 0.033 (1.164)	DT 0.001 (1.121)	loss nan (nan)	prob nan (nan)	GS 38.344 (38.344)	mem 39.898
Train: [85][505/750]	BT 0.043 (1.153)	DT 0.009 (1.110)	loss nan (nan)	prob nan (nan)	GS 33.281 (33.281)	mem 39.898
Train: [85][510/750]	BT 0.098 (1.168)	DT 0.005 (1.125)	loss nan (nan)	prob nan (nan)	GS 30.500 (30.500)	mem 39.932
Train: [85][515/750]	BT 0.031 (1.157)	DT 0.001 (1.114)	loss nan (nan)	prob nan (nan)	GS 31.500 (31.500)	mem 39.967
Train: [85][520/750]	BT 5.690 (1.170)	DT 5.661 (1.127)	loss nan (nan)	prob nan (nan)	GS 33.359 (33.359)	mem 39.972
Train: [85][525/750]	BT 0.033 (1.159)	DT 0.001 (1.117)	loss nan (nan)	prob nan (nan)	GS 33.156 (33.156)	mem 39.973
Train: [85][530/750]	BT 9.332 (1.167)	DT 9.274 (1.124)	loss nan (nan)	prob nan (nan)	GS 35.625 (35.625)	mem 39.992
Train: [85][535/750]	BT 0.055 (1.161)	DT 0.002 (1.118)	loss nan (nan)	prob nan (nan)	GS 31.438 (31.438)	mem 39.996
Train: [85][540/750]	BT 0.044 (1.150)	DT 0.003 (1.107)	loss nan (nan)	prob nan (nan)	GS 35.109 (35.109)	mem 39.996
Train: [85][545/750]	BT 0.085 (1.160)	DT 0.014 (1.117)	loss nan (nan)	prob nan (nan)	GS 29.516 (29.516)	mem 40.075
Train: [85][550/750]	BT 0.106 (1.150)	DT 0.032 (1.107)	loss nan (nan)	prob nan (nan)	GS 32.047 (32.047)	mem 39.955
Train: [85][555/750]	BT 0.108 (1.154)	DT 0.003 (1.111)	loss nan (nan)	prob nan (nan)	GS 33.812 (33.812)	mem 39.966
Train: [85][560/750]	BT 0.050 (1.156)	DT 0.001 (1.113)	loss nan (nan)	prob nan (nan)	GS 32.047 (32.047)	mem 40.007
Train: [85][565/750]	BT 0.032 (1.146)	DT 0.001 (1.103)	loss nan (nan)	prob nan (nan)	GS 31.000 (31.000)	mem 40.006
Train: [85][570/750]	BT 0.037 (1.158)	DT 0.001 (1.115)	loss nan (nan)	prob nan (nan)	GS 35.172 (35.172)	mem 39.934
Train: [85][575/750]	BT 0.032 (1.148)	DT 0.001 (1.105)	loss nan (nan)	prob nan (nan)	GS 41.484 (41.484)	mem 39.936
Train: [85][580/750]	BT 3.235 (1.159)	DT 3.156 (1.116)	loss nan (nan)	prob nan (nan)	GS 34.203 (34.203)	mem 39.970
Train: [85][585/750]	BT 0.033 (1.149)	DT 0.002 (1.106)	loss nan (nan)	prob nan (nan)	GS 32.891 (32.891)	mem 39.971
Train: [85][590/750]	BT 9.472 (1.156)	DT 9.412 (1.113)	loss nan (nan)	prob nan (nan)	GS 33.266 (33.266)	mem 40.034
Train: [85][595/750]	BT 0.131 (1.149)	DT 0.088 (1.106)	loss nan (nan)	prob nan (nan)	GS 30.922 (30.922)	mem 40.319
Train: [85][600/750]	BT 0.049 (1.140)	DT 0.001 (1.097)	loss nan (nan)	prob nan (nan)	GS 34.188 (34.188)	mem 40.111
Train: [85][605/750]	BT 0.090 (1.153)	DT 0.018 (1.109)	loss nan (nan)	prob nan (nan)	GS 34.734 (34.734)	mem 39.953
Train: [85][610/750]	BT 0.030 (1.144)	DT 0.003 (1.100)	loss nan (nan)	prob nan (nan)	GS 31.125 (31.125)	mem 39.955
Train: [85][615/750]	BT 0.025 (1.154)	DT 0.001 (1.111)	loss nan (nan)	prob nan (nan)	GS 35.406 (35.406)	mem 40.042
Train: [85][620/750]	BT 0.026 (1.145)	DT 0.001 (1.102)	loss nan (nan)	prob nan (nan)	GS 34.031 (34.031)	mem 40.025
Train: [85][625/750]	BT 0.089 (1.136)	DT 0.032 (1.093)	loss nan (nan)	prob nan (nan)	GS 34.281 (34.281)	mem 40.026
Train: [85][630/750]	BT 0.032 (1.146)	DT 0.001 (1.103)	loss nan (nan)	prob nan (nan)	GS 36.641 (36.641)	mem 39.980
Train: [85][635/750]	BT 0.047 (1.137)	DT 0.001 (1.094)	loss nan (nan)	prob nan (nan)	GS 33.797 (33.797)	mem 39.981
Train: [85][640/750]	BT 1.488 (1.148)	DT 1.442 (1.104)	loss nan (nan)	prob nan (nan)	GS 31.891 (31.891)	mem 40.032
Train: [85][645/750]	BT 0.032 (1.139)	DT 0.009 (1.096)	loss nan (nan)	prob nan (nan)	GS 31.688 (31.688)	mem 40.014
Train: [85][650/750]	BT 11.647 (1.148)	DT 11.623 (1.105)	loss nan (nan)	prob nan (nan)	GS 33.312 (33.312)	mem 39.997
Train: [85][655/750]	BT 0.035 (1.141)	DT 0.001 (1.098)	loss nan (nan)	prob nan (nan)	GS 30.422 (30.422)	mem 40.104
Train: [85][660/750]	BT 0.045 (1.136)	DT 0.004 (1.093)	loss nan (nan)	prob nan (nan)	GS 33.266 (33.266)	mem 40.001
Train: [85][665/750]	BT 0.028 (1.148)	DT 0.001 (1.104)	loss nan (nan)	prob nan (nan)	GS 33.734 (33.734)	mem 39.987
Train: [85][670/750]	BT 0.042 (1.139)	DT 0.003 (1.096)	loss nan (nan)	prob nan (nan)	GS 34.828 (34.828)	mem 39.987
Train: [85][675/750]	BT 0.028 (1.151)	DT 0.001 (1.108)	loss nan (nan)	prob nan (nan)	GS 31.047 (31.047)	mem 40.047
Train: [85][680/750]	BT 1.277 (1.144)	DT 1.228 (1.101)	loss nan (nan)	prob nan (nan)	GS 36.438 (36.438)	mem 40.109
Train: [85][685/750]	BT 0.023 (1.136)	DT 0.001 (1.093)	loss nan (nan)	prob nan (nan)	GS 31.016 (31.016)	mem 40.013
Train: [85][690/750]	BT 0.032 (1.146)	DT 0.002 (1.103)	loss nan (nan)	prob nan (nan)	GS 37.875 (37.875)	mem 40.028
Train: [85][695/750]	BT 0.088 (1.142)	DT 0.009 (1.099)	loss nan (nan)	prob nan (nan)	GS 32.734 (32.734)	mem 39.997
Train: [85][700/750]	BT 3.303 (1.151)	DT 3.273 (1.108)	loss nan (nan)	prob nan (nan)	GS 36.484 (36.484)	mem 40.189
Train: [85][705/750]	BT 0.035 (1.143)	DT 0.002 (1.100)	loss nan (nan)	prob nan (nan)	GS 31.781 (31.781)	mem 40.123
arpack error, retry= 0
arpack error, retry= 0
arpack error, retry= 0
Train: [85][710/750]	BT 7.469 (1.146)	DT 7.412 (1.103)	loss nan (nan)	prob nan (nan)	GS 29.828 (29.828)	mem 40.011
Train: [85][715/750]	BT 0.082 (1.145)	DT 0.002 (1.101)	loss nan (nan)	prob nan (nan)	GS 32.766 (32.766)	mem 40.054
Train: [85][720/750]	BT 0.121 (1.137)	DT 0.012 (1.094)	loss nan (nan)	prob nan (nan)	GS 35.531 (35.531)	mem 40.058
Train: [85][725/750]	BT 0.064 (1.146)	DT 0.003 (1.102)	loss nan (nan)	prob nan (nan)	GS 30.312 (30.312)	mem 40.192
Train: [85][730/750]	BT 0.079 (1.138)	DT 0.001 (1.095)	loss nan (nan)	prob nan (nan)	GS 35.156 (35.156)	mem 39.933
Train: [85][735/750]	BT 0.027 (1.147)	DT 0.002 (1.103)	loss nan (nan)	prob nan (nan)	GS 31.312 (31.312)	mem 36.667
Train: [85][740/750]	BT 0.031 (1.139)	DT 0.001 (1.096)	loss nan (nan)	prob nan (nan)	GS 34.594 (34.594)	mem 36.670
Train: [85][745/750]	BT 0.029 (1.132)	DT 0.001 (1.089)	loss nan (nan)	prob nan (nan)	GS 30.312 (30.312)	mem 36.672
Train: [85][750/750]	BT 0.028 (1.128)	DT 0.001 (1.085)	loss nan (nan)	prob nan (nan)	GS 36.312 (36.312)	mem 7.660
Train: [85][755/750]	BT 0.026 (1.121)	DT 0.001 (1.078)	loss nan (nan)	prob nan (nan)	GS 33.562 (33.562)	mem 7.660
epoch 85, total time 846.51
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [86][1/750]	BT 19.151 (19.151)	DT 19.088 (19.088)	loss nan (nan)	prob nan (nan)	GS 35.109 (35.109)	mem 38.638
Train: [86][5/750]	BT 0.055 (4.239)	DT 0.016 (4.181)	loss nan (nan)	prob nan (nan)	GS 33.125 (33.125)	mem 38.627
Train: [86][10/750]	BT 0.044 (2.253)	DT 0.002 (2.200)	loss nan (nan)	prob nan (nan)	GS 34.594 (34.594)	mem 38.671
Train: [86][15/750]	BT 0.070 (2.357)	DT 0.004 (2.307)	loss nan (nan)	prob nan (nan)	GS 30.422 (30.422)	mem 38.838
Train: [86][20/750]	BT 0.041 (1.820)	DT 0.003 (1.771)	loss nan (nan)	prob nan (nan)	GS 36.969 (36.969)	mem 38.979
Train: [86][25/750]	BT 0.071 (1.750)	DT 0.024 (1.700)	loss nan (nan)	prob nan (nan)	GS 32.141 (32.141)	mem 38.955
Train: [86][30/750]	BT 0.062 (1.702)	DT 0.012 (1.654)	loss nan (nan)	prob nan (nan)	GS 34.000 (34.000)	mem 38.982
Train: [86][35/750]	BT 0.101 (1.472)	DT 0.002 (1.419)	loss nan (nan)	prob nan (nan)	GS 29.016 (29.016)	mem 38.985
Train: [86][40/750]	BT 0.044 (1.630)	DT 0.001 (1.578)	loss nan (nan)	prob nan (nan)	GS 31.719 (31.719)	mem 39.012
Train: [86][45/750]	BT 0.040 (1.458)	DT 0.001 (1.403)	loss nan (nan)	prob nan (nan)	GS 29.562 (29.562)	mem 39.019
Train: [86][50/750]	BT 4.689 (1.562)	DT 4.656 (1.507)	loss nan (nan)	prob nan (nan)	GS 33.953 (33.953)	mem 39.041
Train: [86][55/750]	BT 0.045 (1.423)	DT 0.002 (1.370)	loss nan (nan)	prob nan (nan)	GS 31.422 (31.422)	mem 39.040
Train: [86][60/750]	BT 8.585 (1.451)	DT 8.544 (1.399)	loss nan (nan)	prob nan (nan)	GS 31.578 (31.578)	mem 39.121
Train: [86][65/750]	BT 0.044 (1.412)	DT 0.003 (1.361)	loss nan (nan)	prob nan (nan)	GS 33.312 (33.312)	mem 39.143
Train: [86][70/750]	BT 0.263 (1.320)	DT 0.013 (1.264)	loss nan (nan)	prob nan (nan)	GS 33.469 (33.469)	mem 39.150
Train: [86][75/750]	BT 0.115 (1.428)	DT 0.022 (1.371)	loss nan (nan)	prob nan (nan)	GS 32.422 (32.422)	mem 39.222
Train: [86][80/750]	BT 0.058 (1.345)	DT 0.014 (1.289)	loss nan (nan)	prob nan (nan)	GS 34.188 (34.188)	mem 39.139
Train: [86][85/750]	BT 0.099 (1.362)	DT 0.001 (1.307)	loss nan (nan)	prob nan (nan)	GS 32.234 (32.234)	mem 39.262
Train: [86][90/750]	BT 0.027 (1.359)	DT 0.001 (1.305)	loss nan (nan)	prob nan (nan)	GS 30.750 (30.750)	mem 39.151
Train: [86][95/750]	BT 0.029 (1.291)	DT 0.002 (1.237)	loss nan (nan)	prob nan (nan)	GS 30.188 (30.188)	mem 39.119
Train: [86][100/750]	BT 7.637 (1.367)	DT 7.586 (1.313)	loss nan (nan)	prob nan (nan)	GS 32.266 (32.266)	mem 39.192
Train: [86][105/750]	BT 0.029 (1.304)	DT 0.001 (1.251)	loss nan (nan)	prob nan (nan)	GS 34.078 (34.078)	mem 39.192
Train: [86][110/750]	BT 0.296 (1.285)	DT 0.251 (1.233)	loss nan (nan)	prob nan (nan)	GS 32.703 (32.703)	mem 39.144
Train: [86][115/750]	BT 0.037 (1.313)	DT 0.002 (1.261)	loss nan (nan)	prob nan (nan)	GS 33.891 (33.891)	mem 39.227
Train: [86][120/750]	BT 0.955 (1.268)	DT 0.923 (1.216)	loss nan (nan)	prob nan (nan)	GS 35.625 (35.625)	mem 39.289
Train: [86][125/750]	BT 0.035 (1.315)	DT 0.002 (1.264)	loss nan (nan)	prob nan (nan)	GS 26.547 (26.547)	mem 39.483
Train: [86][130/750]	BT 0.065 (1.267)	DT 0.004 (1.215)	loss nan (nan)	prob nan (nan)	GS 35.312 (35.312)	mem 39.523
Train: [86][135/750]	BT 0.032 (1.263)	DT 0.001 (1.211)	loss nan (nan)	prob nan (nan)	GS 28.078 (28.078)	mem 39.211
Train: [86][140/750]	BT 0.033 (1.243)	DT 0.001 (1.192)	loss nan (nan)	prob nan (nan)	GS 33.078 (33.078)	mem 39.339
Train: [86][145/750]	BT 0.033 (1.262)	DT 0.002 (1.211)	loss nan (nan)	prob nan (nan)	GS 27.344 (27.344)	mem 39.319
Train: [86][150/750]	BT 0.032 (1.257)	DT 0.001 (1.206)	loss nan (nan)	prob nan (nan)	GS 27.781 (27.781)	mem 39.372
Train: [86][155/750]	BT 0.144 (1.219)	DT 0.017 (1.168)	loss nan (nan)	prob nan (nan)	GS 24.266 (24.266)	mem 39.323
Train: [86][160/750]	BT 7.817 (1.274)	DT 7.784 (1.223)	loss nan (nan)	prob nan (nan)	GS 33.828 (33.828)	mem 39.470
Train: [86][165/750]	BT 0.089 (1.238)	DT 0.005 (1.186)	loss nan (nan)	prob nan (nan)	GS 31.500 (31.500)	mem 39.373
Train: [86][170/750]	BT 4.567 (1.235)	DT 4.521 (1.183)	loss nan (nan)	prob nan (nan)	GS 37.203 (37.203)	mem 39.399
Train: [86][175/750]	BT 0.045 (1.252)	DT 0.002 (1.201)	loss nan (nan)	prob nan (nan)	GS 34.438 (34.438)	mem 39.615
Train: [86][180/750]	BT 0.411 (1.221)	DT 0.380 (1.170)	loss nan (nan)	prob nan (nan)	GS 34.844 (34.844)	mem 39.498
Train: [86][185/750]	BT 0.049 (1.271)	DT 0.009 (1.220)	loss nan (nan)	prob nan (nan)	GS 28.812 (28.812)	mem 39.496
Train: [86][190/750]	BT 0.052 (1.238)	DT 0.011 (1.188)	loss nan (nan)	prob nan (nan)	GS 34.312 (34.312)	mem 39.518
Train: [86][195/750]	BT 0.032 (1.208)	DT 0.001 (1.158)	loss nan (nan)	prob nan (nan)	GS 28.922 (28.922)	mem 39.507
Train: [86][200/750]	BT 0.023 (1.247)	DT 0.001 (1.197)	loss nan (nan)	prob nan (nan)	GS 34.078 (34.078)	mem 39.519
Train: [86][205/750]	BT 0.045 (1.217)	DT 0.002 (1.168)	loss nan (nan)	prob nan (nan)	GS 35.047 (35.047)	mem 39.519
Train: [86][210/750]	BT 0.062 (1.258)	DT 0.003 (1.210)	loss nan (nan)	prob nan (nan)	GS 33.156 (33.156)	mem 39.809
Train: [86][215/750]	BT 0.029 (1.230)	DT 0.001 (1.182)	loss nan (nan)	prob nan (nan)	GS 30.359 (30.359)	mem 39.621
Train: [86][220/750]	BT 10.825 (1.253)	DT 10.793 (1.205)	loss nan (nan)	prob nan (nan)	GS 33.688 (33.688)	mem 39.578
Train: [86][225/750]	BT 0.052 (1.226)	DT 0.004 (1.178)	loss nan (nan)	prob nan (nan)	GS 33.016 (33.016)	mem 39.710
Train: [86][230/750]	BT 3.116 (1.214)	DT 3.071 (1.166)	loss nan (nan)	prob nan (nan)	GS 36.719 (36.719)	mem 39.724
Train: [86][235/750]	BT 0.035 (1.229)	DT 0.001 (1.181)	loss nan (nan)	prob nan (nan)	GS 31.641 (31.641)	mem 39.704
Train: [86][240/750]	BT 1.470 (1.210)	DT 1.438 (1.162)	loss nan (nan)	prob nan (nan)	GS 31.625 (31.625)	mem 39.718
Train: [86][245/750]	BT 0.036 (1.244)	DT 0.001 (1.196)	loss nan (nan)	prob nan (nan)	GS 33.000 (33.000)	mem 39.759
Train: [86][250/750]	BT 0.031 (1.221)	DT 0.001 (1.173)	loss nan (nan)	prob nan (nan)	GS 33.375 (33.375)	mem 39.759
Train: [86][255/750]	BT 0.031 (1.206)	DT 0.001 (1.158)	loss nan (nan)	prob nan (nan)	GS 28.484 (28.484)	mem 39.841
Train: [86][260/750]	BT 0.090 (1.216)	DT 0.002 (1.169)	loss nan (nan)	prob nan (nan)	GS 33.250 (33.250)	mem 39.927
Train: [86][265/750]	BT 0.058 (1.194)	DT 0.002 (1.147)	loss nan (nan)	prob nan (nan)	GS 31.062 (31.062)	mem 39.836
Train: [86][270/750]	BT 0.026 (1.227)	DT 0.001 (1.179)	loss nan (nan)	prob nan (nan)	GS 37.703 (37.703)	mem 39.985
Train: [86][275/750]	BT 0.034 (1.206)	DT 0.002 (1.158)	loss nan (nan)	prob nan (nan)	GS 28.859 (28.859)	mem 39.957
Train: [86][280/750]	BT 9.148 (1.232)	DT 9.115 (1.185)	loss nan (nan)	prob nan (nan)	GS 32.094 (32.094)	mem 39.898
Train: [86][285/750]	BT 0.094 (1.212)	DT 0.022 (1.164)	loss nan (nan)	prob nan (nan)	GS 31.500 (31.500)	mem 39.891
Train: [86][290/750]	BT 4.311 (1.206)	DT 4.276 (1.159)	loss nan (nan)	prob nan (nan)	GS 34.016 (34.016)	mem 39.900
Train: [86][295/750]	BT 0.024 (1.222)	DT 0.001 (1.174)	loss nan (nan)	prob nan (nan)	GS 32.734 (32.734)	mem 39.845
Train: [86][300/750]	BT 0.052 (1.202)	DT 0.004 (1.155)	loss nan (nan)	prob nan (nan)	GS 34.469 (34.469)	mem 39.855
Train: [86][305/750]	BT 0.046 (1.221)	DT 0.015 (1.173)	loss nan (nan)	prob nan (nan)	GS 33.578 (33.578)	mem 39.817
Train: [86][310/750]	BT 0.036 (1.202)	DT 0.001 (1.155)	loss nan (nan)	prob nan (nan)	GS 33.031 (33.031)	mem 39.816
Train: [86][315/750]	BT 0.059 (1.184)	DT 0.003 (1.136)	loss nan (nan)	prob nan (nan)	GS 28.250 (28.250)	mem 39.848
Train: [86][320/750]	BT 0.023 (1.215)	DT 0.001 (1.168)	loss nan (nan)	prob nan (nan)	GS 36.812 (36.812)	mem 39.862
Train: [86][325/750]	BT 0.058 (1.198)	DT 0.010 (1.150)	loss nan (nan)	prob nan (nan)	GS 28.438 (28.438)	mem 39.920
Train: [86][330/750]	BT 0.074 (1.214)	DT 0.001 (1.166)	loss nan (nan)	prob nan (nan)	GS 33.953 (33.953)	mem 39.979
Train: [86][335/750]	BT 0.027 (1.196)	DT 0.001 (1.149)	loss nan (nan)	prob nan (nan)	GS 35.719 (35.719)	mem 39.948
Train: [86][340/750]	BT 12.661 (1.216)	DT 12.630 (1.169)	loss nan (nan)	prob nan (nan)	GS 33.375 (33.375)	mem 40.035
Train: [86][345/750]	BT 0.032 (1.199)	DT 0.001 (1.152)	loss nan (nan)	prob nan (nan)	GS 31.859 (31.859)	mem 39.930
Train: [86][350/750]	BT 0.065 (1.183)	DT 0.008 (1.136)	loss nan (nan)	prob nan (nan)	GS 32.656 (32.656)	mem 39.932
Train: [86][355/750]	BT 0.027 (1.204)	DT 0.001 (1.157)	loss nan (nan)	prob nan (nan)	GS 30.953 (30.953)	mem 40.002
Train: [86][360/750]	BT 0.070 (1.188)	DT 0.001 (1.141)	loss nan (nan)	prob nan (nan)	GS 31.391 (31.391)	mem 40.003
Train: [86][365/750]	BT 0.038 (1.209)	DT 0.001 (1.163)	loss nan (nan)	prob nan (nan)	GS 30.812 (30.812)	mem 40.018
Train: [86][370/750]	BT 0.035 (1.193)	DT 0.001 (1.147)	loss nan (nan)	prob nan (nan)	GS 28.516 (28.516)	mem 40.018
Train: [86][375/750]	BT 0.033 (1.178)	DT 0.002 (1.132)	loss nan (nan)	prob nan (nan)	GS 32.312 (32.312)	mem 39.951
Train: [86][380/750]	BT 0.029 (1.195)	DT 0.001 (1.149)	loss nan (nan)	prob nan (nan)	GS 33.250 (33.250)	mem 40.027
Train: [86][385/750]	BT 0.053 (1.180)	DT 0.001 (1.134)	loss nan (nan)	prob nan (nan)	GS 32.594 (32.594)	mem 40.044
Train: [86][390/750]	BT 0.061 (1.197)	DT 0.008 (1.151)	loss nan (nan)	prob nan (nan)	GS 31.078 (31.078)	mem 40.058
Train: [86][395/750]	BT 0.038 (1.182)	DT 0.008 (1.137)	loss nan (nan)	prob nan (nan)	GS 35.234 (35.234)	mem 40.058
Train: [86][400/750]	BT 11.519 (1.197)	DT 11.478 (1.151)	loss nan (nan)	prob nan (nan)	GS 33.500 (33.500)	mem 40.010
Train: [86][405/750]	BT 0.090 (1.183)	DT 0.021 (1.137)	loss nan (nan)	prob nan (nan)	GS 30.891 (30.891)	mem 40.011
Train: [86][410/750]	BT 0.082 (1.169)	DT 0.006 (1.124)	loss nan (nan)	prob nan (nan)	GS 32.641 (32.641)	mem 40.154
Train: [86][415/750]	BT 0.072 (1.185)	DT 0.010 (1.139)	loss nan (nan)	prob nan (nan)	GS 30.406 (30.406)	mem 40.059
Train: [86][420/750]	BT 0.046 (1.171)	DT 0.001 (1.125)	loss nan (nan)	prob nan (nan)	GS 37.500 (37.500)	mem 39.941
Train: [86][425/750]	BT 0.079 (1.189)	DT 0.008 (1.144)	loss nan (nan)	prob nan (nan)	GS 33.844 (33.844)	mem 40.105
Train: [86][430/750]	BT 0.025 (1.176)	DT 0.001 (1.131)	loss nan (nan)	prob nan (nan)	GS 31.562 (31.562)	mem 39.990
Train: [86][435/750]	BT 0.026 (1.163)	DT 0.002 (1.118)	loss nan (nan)	prob nan (nan)	GS 33.625 (33.625)	mem 39.974
Train: [86][440/750]	BT 0.033 (1.181)	DT 0.001 (1.136)	loss nan (nan)	prob nan (nan)	GS 38.797 (38.797)	mem 39.955
Train: [86][445/750]	BT 0.066 (1.169)	DT 0.013 (1.123)	loss nan (nan)	prob nan (nan)	GS 33.719 (33.719)	mem 39.915
Train: [86][450/750]	BT 0.049 (1.179)	DT 0.005 (1.134)	loss nan (nan)	prob nan (nan)	GS 31.953 (31.953)	mem 39.963
Train: [86][455/750]	BT 0.096 (1.167)	DT 0.015 (1.122)	loss nan (nan)	prob nan (nan)	GS 30.828 (30.828)	mem 40.100
Train: [86][460/750]	BT 14.204 (1.186)	DT 14.149 (1.140)	loss nan (nan)	prob nan (nan)	GS 33.172 (33.172)	mem 39.917
Train: [86][465/750]	BT 0.025 (1.173)	DT 0.001 (1.128)	loss nan (nan)	prob nan (nan)	GS 33.078 (33.078)	mem 39.917
Train: [86][470/750]	BT 0.070 (1.161)	DT 0.010 (1.116)	loss nan (nan)	prob nan (nan)	GS 32.891 (32.891)	mem 39.989
Train: [86][475/750]	BT 0.060 (1.168)	DT 0.004 (1.122)	loss nan (nan)	prob nan (nan)	GS 32.234 (32.234)	mem 39.981
Train: [86][480/750]	BT 0.054 (1.156)	DT 0.006 (1.111)	loss nan (nan)	prob nan (nan)	GS 33.531 (33.531)	mem 39.982
Train: [86][485/750]	BT 0.037 (1.169)	DT 0.001 (1.125)	loss nan (nan)	prob nan (nan)	GS 30.094 (30.094)	mem 40.023
Train: [86][490/750]	BT 0.033 (1.158)	DT 0.002 (1.113)	loss nan (nan)	prob nan (nan)	GS 33.719 (33.719)	mem 40.132
Train: [86][495/750]	BT 0.033 (1.151)	DT 0.001 (1.106)	loss nan (nan)	prob nan (nan)	GS 32.266 (32.266)	mem 40.046
Train: [86][500/750]	BT 0.146 (1.163)	DT 0.006 (1.118)	loss nan (nan)	prob nan (nan)	GS 32.312 (32.312)	mem 39.989
Train: [86][505/750]	BT 0.047 (1.155)	DT 0.004 (1.110)	loss nan (nan)	prob nan (nan)	GS 33.125 (33.125)	mem 39.933
Train: [86][510/750]	BT 0.037 (1.167)	DT 0.001 (1.122)	loss nan (nan)	prob nan (nan)	GS 36.641 (36.641)	mem 39.951
Train: [86][515/750]	BT 0.087 (1.156)	DT 0.009 (1.111)	loss nan (nan)	prob nan (nan)	GS 28.328 (28.328)	mem 39.874
Train: [86][520/750]	BT 10.170 (1.165)	DT 10.136 (1.120)	loss nan (nan)	prob nan (nan)	GS 32.219 (32.219)	mem 39.940
Train: [86][525/750]	BT 0.027 (1.154)	DT 0.001 (1.109)	loss nan (nan)	prob nan (nan)	GS 34.484 (34.484)	mem 39.940
Train: [86][530/750]	BT 0.034 (1.144)	DT 0.002 (1.099)	loss nan (nan)	prob nan (nan)	GS 33.125 (33.125)	mem 39.939
Train: [86][535/750]	BT 0.062 (1.155)	DT 0.006 (1.110)	loss nan (nan)	prob nan (nan)	GS 32.016 (32.016)	mem 39.979
Train: [86][540/750]	BT 0.402 (1.145)	DT 0.373 (1.101)	loss nan (nan)	prob nan (nan)	GS 32.953 (32.953)	mem 39.978
Train: [86][545/750]	BT 0.074 (1.158)	DT 0.009 (1.114)	loss nan (nan)	prob nan (nan)	GS 28.797 (28.797)	mem 39.907
Train: [86][550/750]	BT 0.053 (1.148)	DT 0.002 (1.103)	loss nan (nan)	prob nan (nan)	GS 36.844 (36.844)	mem 39.914
Train: [86][555/750]	BT 0.025 (1.138)	DT 0.002 (1.094)	loss nan (nan)	prob nan (nan)	GS 31.609 (31.609)	mem 39.882
Train: [86][560/750]	BT 0.104 (1.150)	DT 0.023 (1.105)	loss nan (nan)	prob nan (nan)	GS 31.312 (31.312)	mem 40.061
Train: [86][565/750]	BT 0.155 (1.142)	DT 0.012 (1.097)	loss nan (nan)	prob nan (nan)	GS 33.578 (33.578)	mem 39.937
Train: [86][570/750]	BT 0.035 (1.148)	DT 0.010 (1.103)	loss nan (nan)	prob nan (nan)	GS 36.062 (36.062)	mem 39.910
Train: [86][575/750]	BT 0.060 (1.143)	DT 0.001 (1.098)	loss nan (nan)	prob nan (nan)	GS 26.906 (26.906)	mem 40.101
Train: [86][580/750]	BT 6.151 (1.149)	DT 6.105 (1.104)	loss nan (nan)	prob nan (nan)	GS 36.281 (36.281)	mem 40.043
Train: [86][585/750]	BT 0.070 (1.146)	DT 0.006 (1.101)	loss nan (nan)	prob nan (nan)	GS 31.672 (31.672)	mem 40.045
Train: [86][590/750]	BT 0.070 (1.142)	DT 0.001 (1.097)	loss nan (nan)	prob nan (nan)	GS 30.203 (30.203)	mem 40.230
Train: [86][595/750]	BT 0.078 (1.145)	DT 0.010 (1.100)	loss nan (nan)	prob nan (nan)	GS 35.719 (35.719)	mem 40.081
Train: [86][600/750]	BT 2.857 (1.142)	DT 2.824 (1.097)	loss nan (nan)	prob nan (nan)	GS 33.984 (33.984)	mem 40.050
Train: [86][605/750]	BT 0.055 (1.140)	DT 0.006 (1.095)	loss nan (nan)	prob nan (nan)	GS 37.062 (37.062)	mem 40.120
Train: [86][610/750]	BT 0.030 (1.142)	DT 0.001 (1.097)	loss nan (nan)	prob nan (nan)	GS 31.688 (31.688)	mem 40.103
Train: [86][615/750]	BT 0.067 (1.137)	DT 0.009 (1.092)	loss nan (nan)	prob nan (nan)	GS 33.094 (33.094)	mem 40.152
Train: [86][620/750]	BT 3.837 (1.146)	DT 3.803 (1.101)	loss nan (nan)	prob nan (nan)	GS 29.812 (29.812)	mem 40.160
Train: [86][625/750]	BT 0.039 (1.140)	DT 0.002 (1.095)	loss nan (nan)	prob nan (nan)	GS 34.266 (34.266)	mem 40.382
Train: [86][630/750]	BT 6.404 (1.143)	DT 6.350 (1.098)	loss nan (nan)	prob nan (nan)	GS 32.906 (32.906)	mem 40.236
Train: [86][635/750]	BT 0.046 (1.137)	DT 0.007 (1.092)	loss nan (nan)	prob nan (nan)	GS 27.859 (27.859)	mem 40.375
Train: [86][640/750]	BT 4.502 (1.141)	DT 4.469 (1.096)	loss nan (nan)	prob nan (nan)	GS 32.500 (32.500)	mem 40.117
Train: [86][645/750]	BT 0.057 (1.142)	DT 0.007 (1.097)	loss nan (nan)	prob nan (nan)	GS 29.094 (29.094)	mem 40.121
Train: [86][650/750]	BT 0.047 (1.137)	DT 0.001 (1.092)	loss nan (nan)	prob nan (nan)	GS 29.297 (29.297)	mem 40.140
Train: [86][655/750]	BT 0.037 (1.147)	DT 0.012 (1.102)	loss nan (nan)	prob nan (nan)	GS 31.422 (31.422)	mem 40.134
Train: [86][660/750]	BT 0.911 (1.140)	DT 0.880 (1.095)	loss nan (nan)	prob nan (nan)	GS 35.625 (35.625)	mem 40.047
Train: [86][665/750]	BT 0.043 (1.144)	DT 0.009 (1.099)	loss nan (nan)	prob nan (nan)	GS 30.922 (30.922)	mem 40.181
Train: [86][670/750]	BT 0.026 (1.139)	DT 0.001 (1.094)	loss nan (nan)	prob nan (nan)	GS 35.531 (35.531)	mem 40.259
Train: [86][675/750]	BT 0.033 (1.139)	DT 0.002 (1.095)	loss nan (nan)	prob nan (nan)	GS 32.281 (32.281)	mem 40.001
Train: [86][680/750]	BT 1.404 (1.140)	DT 1.377 (1.096)	loss nan (nan)	prob nan (nan)	GS 33.891 (33.891)	mem 40.034
Train: [86][685/750]	BT 0.116 (1.140)	DT 0.028 (1.095)	loss nan (nan)	prob nan (nan)	GS 33.188 (33.188)	mem 40.136
Train: [86][690/750]	BT 0.049 (1.145)	DT 0.006 (1.100)	loss nan (nan)	prob nan (nan)	GS 29.281 (29.281)	mem 40.028
Train: [86][695/750]	BT 0.076 (1.137)	DT 0.010 (1.092)	loss nan (nan)	prob nan (nan)	GS 31.812 (31.812)	mem 40.028
Train: [86][700/750]	BT 9.354 (1.149)	DT 9.307 (1.104)	loss nan (nan)	prob nan (nan)	GS 40.312 (40.312)	mem 40.049
Train: [86][705/750]	BT 0.031 (1.141)	DT 0.001 (1.096)	loss nan (nan)	prob nan (nan)	GS 34.031 (34.031)	mem 40.033
arpack error, retry= 0
arpack error, retry= 0
Train: [86][710/750]	BT 0.080 (1.138)	DT 0.007 (1.093)	loss nan (nan)	prob nan (nan)	GS 35.547 (35.547)	mem 40.131
Train: [86][715/750]	BT 0.030 (1.147)	DT 0.001 (1.102)	loss nan (nan)	prob nan (nan)	GS 30.625 (30.625)	mem 40.083
Train: [86][720/750]	BT 2.005 (1.142)	DT 1.973 (1.097)	loss nan (nan)	prob nan (nan)	GS 37.078 (37.078)	mem 39.989
Train: [86][725/750]	BT 0.035 (1.149)	DT 0.001 (1.104)	loss nan (nan)	prob nan (nan)	GS 29.250 (29.250)	mem 39.949
Train: [86][730/750]	BT 0.034 (1.141)	DT 0.002 (1.096)	loss nan (nan)	prob nan (nan)	GS 31.703 (31.703)	mem 40.069
Train: [86][735/750]	BT 0.045 (1.136)	DT 0.004 (1.092)	loss nan (nan)	prob nan (nan)	GS 30.844 (30.844)	mem 39.946
Train: [86][740/750]	BT 0.033 (1.135)	DT 0.001 (1.091)	loss nan (nan)	prob nan (nan)	GS 37.734 (37.734)	mem 25.259
Train: [86][745/750]	BT 0.038 (1.134)	DT 0.002 (1.089)	loss nan (nan)	prob nan (nan)	GS 26.906 (26.906)	mem 10.710
Train: [86][750/750]	BT 0.029 (1.126)	DT 0.001 (1.081)	loss nan (nan)	prob nan (nan)	GS 30.719 (30.719)	mem 10.674
Train: [86][755/750]	BT 0.023 (1.119)	DT 0.001 (1.074)	loss nan (nan)	prob nan (nan)	GS 30.719 (30.719)	mem 10.674
epoch 86, total time 847.59
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [87][1/750]	BT 19.991 (19.991)	DT 19.926 (19.926)	loss nan (nan)	prob nan (nan)	GS 31.078 (31.078)	mem 38.611
Train: [87][5/750]	BT 0.042 (5.209)	DT 0.002 (5.151)	loss nan (nan)	prob nan (nan)	GS 32.688 (32.688)	mem 38.713
Train: [87][10/750]	BT 0.068 (2.642)	DT 0.013 (2.579)	loss nan (nan)	prob nan (nan)	GS 32.812 (32.812)	mem 38.681
Train: [87][15/750]	BT 0.350 (2.025)	DT 0.304 (1.967)	loss nan (nan)	prob nan (nan)	GS 25.734 (25.734)	mem 38.726
Train: [87][20/750]	BT 0.034 (2.049)	DT 0.001 (1.998)	loss nan (nan)	prob nan (nan)	GS 32.953 (32.953)	mem 38.956
Train: [87][25/750]	BT 0.033 (1.646)	DT 0.001 (1.599)	loss nan (nan)	prob nan (nan)	GS 33.516 (33.516)	mem 38.934
Train: [87][30/750]	BT 0.058 (1.747)	DT 0.009 (1.700)	loss nan (nan)	prob nan (nan)	GS 33.641 (33.641)	mem 38.977
Train: [87][35/750]	BT 0.050 (1.503)	DT 0.009 (1.458)	loss nan (nan)	prob nan (nan)	GS 33.609 (33.609)	mem 38.984
Train: [87][40/750]	BT 5.761 (1.697)	DT 5.726 (1.648)	loss nan (nan)	prob nan (nan)	GS 37.422 (37.422)	mem 38.984
Train: [87][45/750]	BT 0.044 (1.513)	DT 0.009 (1.466)	loss nan (nan)	prob nan (nan)	GS 28.672 (28.672)	mem 38.985
Train: [87][50/750]	BT 6.648 (1.499)	DT 6.597 (1.452)	loss nan (nan)	prob nan (nan)	GS 34.047 (34.047)	mem 39.052
Train: [87][55/750]	BT 0.032 (1.475)	DT 0.001 (1.428)	loss nan (nan)	prob nan (nan)	GS 32.062 (32.062)	mem 39.035
Train: [87][60/750]	BT 0.058 (1.396)	DT 0.026 (1.350)	loss nan (nan)	prob nan (nan)	GS 37.125 (37.125)	mem 39.034
Train: [87][65/750]	BT 0.091 (1.418)	DT 0.020 (1.372)	loss nan (nan)	prob nan (nan)	GS 31.359 (31.359)	mem 39.101
Train: [87][70/750]	BT 3.056 (1.366)	DT 3.024 (1.318)	loss nan (nan)	prob nan (nan)	GS 28.266 (28.266)	mem 39.073
Train: [87][75/750]	BT 0.028 (1.422)	DT 0.001 (1.375)	loss nan (nan)	prob nan (nan)	GS 33.859 (33.859)	mem 39.112
Train: [87][80/750]	BT 0.069 (1.337)	DT 0.002 (1.290)	loss nan (nan)	prob nan (nan)	GS 34.766 (34.766)	mem 39.193
Train: [87][85/750]	BT 0.081 (1.266)	DT 0.010 (1.218)	loss nan (nan)	prob nan (nan)	GS 30.641 (30.641)	mem 39.088
Train: [87][90/750]	BT 0.041 (1.353)	DT 0.011 (1.305)	loss nan (nan)	prob nan (nan)	GS 30.344 (30.344)	mem 39.077
Train: [87][95/750]	BT 0.088 (1.284)	DT 0.013 (1.237)	loss nan (nan)	prob nan (nan)	GS 36.906 (36.906)	mem 39.123
Train: [87][100/750]	BT 1.254 (1.336)	DT 1.153 (1.288)	loss nan (nan)	prob nan (nan)	GS 33.250 (33.250)	mem 39.172
Train: [87][105/750]	BT 0.038 (1.275)	DT 0.012 (1.227)	loss nan (nan)	prob nan (nan)	GS 33.469 (33.469)	mem 39.172
Train: [87][110/750]	BT 11.411 (1.322)	DT 11.380 (1.275)	loss nan (nan)	prob nan (nan)	GS 35.641 (35.641)	mem 39.097
Train: [87][115/750]	BT 0.041 (1.280)	DT 0.001 (1.233)	loss nan (nan)	prob nan (nan)	GS 36.344 (36.344)	mem 39.124
Train: [87][120/750]	BT 0.036 (1.236)	DT 0.001 (1.189)	loss nan (nan)	prob nan (nan)	GS 32.750 (32.750)	mem 39.149
Train: [87][125/750]	BT 0.116 (1.286)	DT 0.013 (1.238)	loss nan (nan)	prob nan (nan)	GS 33.484 (33.484)	mem 39.231
Train: [87][130/750]	BT 0.033 (1.238)	DT 0.001 (1.190)	loss nan (nan)	prob nan (nan)	GS 34.953 (34.953)	mem 39.232
Train: [87][135/750]	BT 0.034 (1.245)	DT 0.002 (1.197)	loss nan (nan)	prob nan (nan)	GS 34.578 (34.578)	mem 39.398
Train: [87][140/750]	BT 0.029 (1.237)	DT 0.001 (1.189)	loss nan (nan)	prob nan (nan)	GS 35.641 (35.641)	mem 39.413
Train: [87][145/750]	BT 0.126 (1.198)	DT 0.012 (1.149)	loss nan (nan)	prob nan (nan)	GS 28.859 (28.859)	mem 39.414
Train: [87][150/750]	BT 0.030 (1.241)	DT 0.001 (1.191)	loss nan (nan)	prob nan (nan)	GS 36.078 (36.078)	mem 39.418
Train: [87][155/750]	BT 0.046 (1.203)	DT 0.001 (1.153)	loss nan (nan)	prob nan (nan)	GS 28.969 (28.969)	mem 39.421
Train: [87][160/750]	BT 3.664 (1.241)	DT 3.611 (1.192)	loss nan (nan)	prob nan (nan)	GS 32.562 (32.562)	mem 39.646
Train: [87][165/750]	BT 0.046 (1.205)	DT 0.006 (1.156)	loss nan (nan)	prob nan (nan)	GS 32.656 (32.656)	mem 39.537
Train: [87][170/750]	BT 8.267 (1.224)	DT 8.236 (1.175)	loss nan (nan)	prob nan (nan)	GS 36.625 (36.625)	mem 39.481
Train: [87][175/750]	BT 0.070 (1.193)	DT 0.001 (1.144)	loss nan (nan)	prob nan (nan)	GS 28.703 (28.703)	mem 39.486
Train: [87][180/750]	BT 0.034 (1.190)	DT 0.003 (1.141)	loss nan (nan)	prob nan (nan)	GS 33.969 (33.969)	mem 39.538
Train: [87][185/750]	BT 0.048 (1.197)	DT 0.002 (1.148)	loss nan (nan)	prob nan (nan)	GS 32.578 (32.578)	mem 39.489
Train: [87][190/750]	BT 2.016 (1.196)	DT 1.968 (1.147)	loss nan (nan)	prob nan (nan)	GS 29.578 (29.578)	mem 39.792
Train: [87][195/750]	BT 0.044 (1.175)	DT 0.001 (1.126)	loss nan (nan)	prob nan (nan)	GS 29.844 (29.844)	mem 39.950
Train: [87][200/750]	BT 3.395 (1.205)	DT 3.324 (1.156)	loss nan (nan)	prob nan (nan)	GS 36.109 (36.109)	mem 39.823
Train: [87][205/750]	BT 0.076 (1.186)	DT 0.025 (1.136)	loss nan (nan)	prob nan (nan)	GS 33.719 (33.719)	mem 39.774
Train: [87][210/750]	BT 0.073 (1.173)	DT 0.017 (1.124)	loss nan (nan)	prob nan (nan)	GS 32.734 (32.734)	mem 39.784
Train: [87][215/750]	BT 0.033 (1.209)	DT 0.001 (1.160)	loss nan (nan)	prob nan (nan)	GS 33.391 (33.391)	mem 39.762
Train: [87][220/750]	BT 1.631 (1.190)	DT 1.589 (1.141)	loss nan (nan)	prob nan (nan)	GS 29.609 (29.609)	mem 39.823
Train: [87][225/750]	BT 0.033 (1.195)	DT 0.002 (1.146)	loss nan (nan)	prob nan (nan)	GS 32.594 (32.594)	mem 39.887
Train: [87][230/750]	BT 0.044 (1.197)	DT 0.001 (1.148)	loss nan (nan)	prob nan (nan)	GS 33.500 (33.500)	mem 39.783
Train: [87][235/750]	BT 0.093 (1.172)	DT 0.005 (1.124)	loss nan (nan)	prob nan (nan)	GS 27.281 (27.281)	mem 39.784
Train: [87][240/750]	BT 0.032 (1.201)	DT 0.001 (1.153)	loss nan (nan)	prob nan (nan)	GS 35.797 (35.797)	mem 39.771
Train: [87][245/750]	BT 0.043 (1.177)	DT 0.002 (1.129)	loss nan (nan)	prob nan (nan)	GS 30.016 (30.016)	mem 39.711
Train: [87][250/750]	BT 7.601 (1.200)	DT 7.563 (1.152)	loss nan (nan)	prob nan (nan)	GS 36.156 (36.156)	mem 39.878
Train: [87][255/750]	BT 0.040 (1.178)	DT 0.001 (1.130)	loss nan (nan)	prob nan (nan)	GS 30.234 (30.234)	mem 39.880
Train: [87][260/750]	BT 6.649 (1.182)	DT 6.615 (1.134)	loss nan (nan)	prob nan (nan)	GS 32.266 (32.266)	mem 39.930
Train: [87][265/750]	BT 0.032 (1.177)	DT 0.009 (1.129)	loss nan (nan)	prob nan (nan)	GS 32.062 (32.062)	mem 39.721
Train: [87][270/750]	BT 0.049 (1.156)	DT 0.001 (1.108)	loss nan (nan)	prob nan (nan)	GS 30.969 (30.969)	mem 39.734
Train: [87][275/750]	BT 0.031 (1.179)	DT 0.001 (1.131)	loss nan (nan)	prob nan (nan)	GS 27.734 (27.734)	mem 39.797
Train: [87][280/750]	BT 0.134 (1.159)	DT 0.006 (1.111)	loss nan (nan)	prob nan (nan)	GS 31.328 (31.328)	mem 39.858
Train: [87][285/750]	BT 0.130 (1.164)	DT 0.016 (1.115)	loss nan (nan)	prob nan (nan)	GS 30.094 (30.094)	mem 40.239
Train: [87][290/750]	BT 0.048 (1.167)	DT 0.007 (1.119)	loss nan (nan)	prob nan (nan)	GS 36.219 (36.219)	mem 39.760
Train: [87][295/750]	BT 0.044 (1.148)	DT 0.005 (1.100)	loss nan (nan)	prob nan (nan)	GS 32.219 (32.219)	mem 39.774
Train: [87][300/750]	BT 0.057 (1.171)	DT 0.009 (1.122)	loss nan (nan)	prob nan (nan)	GS 32.422 (32.422)	mem 39.886
Train: [87][305/750]	BT 0.049 (1.153)	DT 0.014 (1.104)	loss nan (nan)	prob nan (nan)	GS 32.266 (32.266)	mem 39.887
Train: [87][310/750]	BT 11.115 (1.172)	DT 11.084 (1.124)	loss nan (nan)	prob nan (nan)	GS 34.094 (34.094)	mem 39.932
Train: [87][315/750]	BT 0.028 (1.154)	DT 0.001 (1.106)	loss nan (nan)	prob nan (nan)	GS 28.016 (28.016)	mem 39.974
Train: [87][320/750]	BT 2.265 (1.144)	DT 2.231 (1.096)	loss nan (nan)	prob nan (nan)	GS 34.172 (34.172)	mem 39.941
Train: [87][325/750]	BT 0.033 (1.162)	DT 0.001 (1.114)	loss nan (nan)	prob nan (nan)	GS 28.484 (28.484)	mem 39.959
Train: [87][330/750]	BT 0.030 (1.145)	DT 0.001 (1.097)	loss nan (nan)	prob nan (nan)	GS 36.000 (36.000)	mem 39.960
Train: [87][335/750]	BT 0.052 (1.167)	DT 0.010 (1.119)	loss nan (nan)	prob nan (nan)	GS 34.188 (34.188)	mem 39.912
Train: [87][340/750]	BT 0.071 (1.150)	DT 0.014 (1.103)	loss nan (nan)	prob nan (nan)	GS 28.578 (28.578)	mem 40.027
Train: [87][345/750]	BT 0.063 (1.134)	DT 0.002 (1.087)	loss nan (nan)	prob nan (nan)	GS 32.984 (32.984)	mem 39.929
Train: [87][350/750]	BT 0.032 (1.153)	DT 0.001 (1.106)	loss nan (nan)	prob nan (nan)	GS 34.922 (34.922)	mem 39.923
Train: [87][355/750]	BT 0.040 (1.137)	DT 0.001 (1.090)	loss nan (nan)	prob nan (nan)	GS 28.406 (28.406)	mem 39.923
Train: [87][360/750]	BT 4.834 (1.162)	DT 4.791 (1.115)	loss nan (nan)	prob nan (nan)	GS 31.969 (31.969)	mem 39.796
Train: [87][365/750]	BT 0.076 (1.147)	DT 0.001 (1.100)	loss nan (nan)	prob nan (nan)	GS 33.203 (33.203)	mem 39.902
Train: [87][370/750]	BT 8.175 (1.154)	DT 8.143 (1.107)	loss nan (nan)	prob nan (nan)	GS 33.188 (33.188)	mem 39.823
Train: [87][375/750]	BT 0.041 (1.150)	DT 0.005 (1.103)	loss nan (nan)	prob nan (nan)	GS 32.500 (32.500)	mem 39.936
Train: [87][380/750]	BT 0.030 (1.135)	DT 0.001 (1.089)	loss nan (nan)	prob nan (nan)	GS 39.547 (39.547)	mem 39.941
Train: [87][385/750]	BT 0.025 (1.156)	DT 0.001 (1.109)	loss nan (nan)	prob nan (nan)	GS 30.578 (30.578)	mem 39.895
Train: [87][390/750]	BT 0.031 (1.142)	DT 0.001 (1.095)	loss nan (nan)	prob nan (nan)	GS 30.453 (30.453)	mem 39.895
Train: [87][395/750]	BT 0.060 (1.140)	DT 0.010 (1.093)	loss nan (nan)	prob nan (nan)	GS 28.469 (28.469)	mem 39.935
Train: [87][400/750]	BT 0.058 (1.147)	DT 0.004 (1.100)	loss nan (nan)	prob nan (nan)	GS 33.969 (33.969)	mem 40.296
Train: [87][405/750]	BT 0.040 (1.133)	DT 0.002 (1.087)	loss nan (nan)	prob nan (nan)	GS 27.969 (27.969)	mem 40.343
Train: [87][410/750]	BT 0.057 (1.147)	DT 0.012 (1.101)	loss nan (nan)	prob nan (nan)	GS 33.922 (33.922)	mem 39.963
Train: [87][415/750]	BT 0.035 (1.134)	DT 0.001 (1.088)	loss nan (nan)	prob nan (nan)	GS 36.594 (36.594)	mem 40.025
Train: [87][420/750]	BT 0.937 (1.159)	DT 0.911 (1.112)	loss nan (nan)	prob nan (nan)	GS 35.359 (35.359)	mem 40.053
Train: [87][425/750]	BT 0.044 (1.146)	DT 0.002 (1.099)	loss nan (nan)	prob nan (nan)	GS 29.406 (29.406)	mem 40.130
Train: [87][430/750]	BT 10.164 (1.156)	DT 10.126 (1.110)	loss nan (nan)	prob nan (nan)	GS 34.453 (34.453)	mem 40.041
Train: [87][435/750]	BT 0.026 (1.158)	DT 0.001 (1.112)	loss nan (nan)	prob nan (nan)	GS 31.641 (31.641)	mem 39.966
Train: [87][440/750]	BT 0.022 (1.145)	DT 0.001 (1.099)	loss nan (nan)	prob nan (nan)	GS 30.469 (30.469)	mem 40.011
Train: [87][445/750]	BT 0.033 (1.161)	DT 0.001 (1.116)	loss nan (nan)	prob nan (nan)	GS 29.156 (29.156)	mem 40.008
Train: [87][450/750]	BT 0.033 (1.149)	DT 0.001 (1.103)	loss nan (nan)	prob nan (nan)	GS 35.859 (35.859)	mem 39.947
Train: [87][455/750]	BT 0.060 (1.151)	DT 0.004 (1.105)	loss nan (nan)	prob nan (nan)	GS 31.031 (31.031)	mem 40.035
Train: [87][460/750]	BT 0.039 (1.152)	DT 0.001 (1.106)	loss nan (nan)	prob nan (nan)	GS 34.828 (34.828)	mem 39.954
Train: [87][465/750]	BT 0.047 (1.140)	DT 0.001 (1.095)	loss nan (nan)	prob nan (nan)	GS 27.578 (27.578)	mem 40.044
Train: [87][470/750]	BT 0.033 (1.154)	DT 0.002 (1.108)	loss nan (nan)	prob nan (nan)	GS 34.375 (34.375)	mem 39.923
Train: [87][475/750]	BT 0.037 (1.142)	DT 0.002 (1.096)	loss nan (nan)	prob nan (nan)	GS 29.484 (29.484)	mem 39.995
Train: [87][480/750]	BT 9.708 (1.157)	DT 9.603 (1.111)	loss nan (nan)	prob nan (nan)	GS 33.266 (33.266)	mem 39.965
Train: [87][485/750]	BT 0.034 (1.146)	DT 0.002 (1.100)	loss nan (nan)	prob nan (nan)	GS 28.047 (28.047)	mem 40.017
Train: [87][490/750]	BT 0.921 (1.136)	DT 0.836 (1.090)	loss nan (nan)	prob nan (nan)	GS 34.156 (34.156)	mem 40.151
Train: [87][495/750]	BT 0.029 (1.147)	DT 0.001 (1.101)	loss nan (nan)	prob nan (nan)	GS 34.844 (34.844)	mem 39.886
Train: [87][500/750]	BT 0.189 (1.137)	DT 0.153 (1.091)	loss nan (nan)	prob nan (nan)	GS 36.500 (36.500)	mem 39.828
Train: [87][505/750]	BT 0.036 (1.152)	DT 0.004 (1.106)	loss nan (nan)	prob nan (nan)	GS 31.469 (31.469)	mem 40.007
Train: [87][510/750]	BT 0.088 (1.141)	DT 0.001 (1.096)	loss nan (nan)	prob nan (nan)	GS 33.516 (33.516)	mem 40.094
Train: [87][515/750]	BT 0.049 (1.134)	DT 0.009 (1.088)	loss nan (nan)	prob nan (nan)	GS 28.016 (28.016)	mem 39.889
Train: [87][520/750]	BT 0.031 (1.143)	DT 0.001 (1.097)	loss nan (nan)	prob nan (nan)	GS 32.906 (32.906)	mem 39.910
Train: [87][525/750]	BT 0.036 (1.132)	DT 0.001 (1.087)	loss nan (nan)	prob nan (nan)	GS 31.156 (31.156)	mem 40.006
Train: [87][530/750]	BT 0.035 (1.145)	DT 0.001 (1.100)	loss nan (nan)	prob nan (nan)	GS 37.953 (37.953)	mem 39.867
Train: [87][535/750]	BT 0.060 (1.135)	DT 0.007 (1.089)	loss nan (nan)	prob nan (nan)	GS 31.906 (31.906)	mem 39.984
Train: [87][540/750]	BT 11.202 (1.147)	DT 11.156 (1.101)	loss nan (nan)	prob nan (nan)	GS 33.062 (33.062)	mem 39.990
Train: [87][545/750]	BT 0.031 (1.136)	DT 0.001 (1.091)	loss nan (nan)	prob nan (nan)	GS 31.750 (31.750)	mem 39.995
Train: [87][550/750]	BT 0.061 (1.127)	DT 0.008 (1.081)	loss nan (nan)	prob nan (nan)	GS 31.688 (31.688)	mem 40.049
Train: [87][555/750]	BT 0.028 (1.144)	DT 0.001 (1.099)	loss nan (nan)	prob nan (nan)	GS 29.172 (29.172)	mem 40.019
Train: [87][560/750]	BT 0.029 (1.135)	DT 0.001 (1.089)	loss nan (nan)	prob nan (nan)	GS 35.391 (35.391)	mem 40.046
Train: [87][565/750]	BT 0.061 (1.146)	DT 0.004 (1.100)	loss nan (nan)	prob nan (nan)	GS 33.719 (33.719)	mem 40.168
Train: [87][570/750]	BT 0.034 (1.136)	DT 0.002 (1.090)	loss nan (nan)	prob nan (nan)	GS 36.453 (36.453)	mem 40.101
Train: [87][575/750]	BT 0.033 (1.127)	DT 0.002 (1.081)	loss nan (nan)	prob nan (nan)	GS 27.406 (27.406)	mem 40.133
Train: [87][580/750]	BT 0.024 (1.139)	DT 0.001 (1.093)	loss nan (nan)	prob nan (nan)	GS 33.828 (33.828)	mem 40.108
Train: [87][585/750]	BT 0.031 (1.129)	DT 0.001 (1.084)	loss nan (nan)	prob nan (nan)	GS 28.531 (28.531)	mem 40.110
Train: [87][590/750]	BT 0.040 (1.143)	DT 0.001 (1.098)	loss nan (nan)	prob nan (nan)	GS 37.438 (37.438)	mem 39.982
Train: [87][595/750]	BT 0.026 (1.134)	DT 0.001 (1.088)	loss nan (nan)	prob nan (nan)	GS 31.859 (31.859)	mem 40.162
Train: [87][600/750]	BT 14.268 (1.148)	DT 14.235 (1.103)	loss nan (nan)	prob nan (nan)	GS 35.125 (35.125)	mem 39.942
Train: [87][605/750]	BT 0.056 (1.139)	DT 0.003 (1.094)	loss nan (nan)	prob nan (nan)	GS 33.062 (33.062)	mem 39.946
Train: [87][610/750]	BT 0.034 (1.130)	DT 0.001 (1.085)	loss nan (nan)	prob nan (nan)	GS 33.688 (33.688)	mem 40.014
Train: [87][615/750]	BT 0.043 (1.140)	DT 0.003 (1.094)	loss nan (nan)	prob nan (nan)	GS 29.172 (29.172)	mem 40.141
Train: [87][620/750]	BT 0.032 (1.131)	DT 0.001 (1.085)	loss nan (nan)	prob nan (nan)	GS 32.906 (32.906)	mem 40.007
Train: [87][625/750]	BT 0.068 (1.145)	DT 0.014 (1.099)	loss nan (nan)	prob nan (nan)	GS 25.938 (25.938)	mem 40.082
Train: [87][630/750]	BT 0.025 (1.136)	DT 0.001 (1.091)	loss nan (nan)	prob nan (nan)	GS 34.656 (34.656)	mem 40.005
Train: [87][635/750]	BT 0.032 (1.127)	DT 0.002 (1.082)	loss nan (nan)	prob nan (nan)	GS 33.531 (33.531)	mem 40.005
Train: [87][640/750]	BT 0.028 (1.140)	DT 0.001 (1.094)	loss nan (nan)	prob nan (nan)	GS 35.703 (35.703)	mem 39.938
Train: [87][645/750]	BT 0.032 (1.131)	DT 0.001 (1.086)	loss nan (nan)	prob nan (nan)	GS 29.016 (29.016)	mem 39.939
Train: [87][650/750]	BT 0.061 (1.144)	DT 0.004 (1.099)	loss nan (nan)	prob nan (nan)	GS 36.500 (36.500)	mem 39.930
Train: [87][655/750]	BT 0.042 (1.136)	DT 0.001 (1.090)	loss nan (nan)	prob nan (nan)	GS 28.500 (28.500)	mem 39.963
Train: [87][660/750]	BT 12.132 (1.146)	DT 12.079 (1.101)	loss nan (nan)	prob nan (nan)	GS 37.000 (37.000)	mem 40.012
Train: [87][665/750]	BT 0.043 (1.138)	DT 0.001 (1.092)	loss nan (nan)	prob nan (nan)	GS 34.562 (34.562)	mem 40.014
Train: [87][670/750]	BT 3.607 (1.135)	DT 3.575 (1.090)	loss nan (nan)	prob nan (nan)	GS 33.688 (33.688)	mem 40.074
Train: [87][675/750]	BT 0.123 (1.140)	DT 0.008 (1.094)	loss nan (nan)	prob nan (nan)	GS 35.547 (35.547)	mem 39.907
Train: [87][680/750]	BT 3.397 (1.137)	DT 3.359 (1.091)	loss nan (nan)	prob nan (nan)	GS 32.734 (32.734)	mem 39.993
Train: [87][685/750]	BT 0.047 (1.143)	DT 0.009 (1.098)	loss nan (nan)	prob nan (nan)	GS 28.562 (28.562)	mem 39.957
Train: [87][690/750]	BT 0.076 (1.136)	DT 0.008 (1.090)	loss nan (nan)	prob nan (nan)	GS 34.359 (34.359)	mem 40.122
Train: [87][695/750]	BT 0.036 (1.141)	DT 0.002 (1.095)	loss nan (nan)	prob nan (nan)	GS 32.656 (32.656)	mem 39.952
Train: [87][700/750]	BT 0.030 (1.137)	DT 0.001 (1.091)	loss nan (nan)	prob nan (nan)	GS 32.469 (32.469)	mem 39.937
Train: [87][705/750]	BT 0.088 (1.137)	DT 0.006 (1.091)	loss nan (nan)	prob nan (nan)	GS 29.875 (29.875)	mem 40.043
Train: [87][710/750]	BT 0.054 (1.140)	DT 0.018 (1.094)	loss nan (nan)	prob nan (nan)	GS 31.484 (31.484)	mem 40.449
Train: [87][715/750]	BT 0.033 (1.135)	DT 0.002 (1.089)	loss nan (nan)	prob nan (nan)	GS 32.391 (32.391)	mem 39.920
Train: [87][720/750]	BT 0.265 (1.139)	DT 0.213 (1.093)	loss nan (nan)	prob nan (nan)	GS 32.672 (32.672)	mem 40.065
Train: [87][725/750]	BT 0.072 (1.132)	DT 0.016 (1.086)	loss nan (nan)	prob nan (nan)	GS 30.234 (30.234)	mem 40.063
Train: [87][730/750]	BT 2.101 (1.139)	DT 2.069 (1.093)	loss nan (nan)	prob nan (nan)	GS 32.812 (32.812)	mem 39.682
Train: [87][735/750]	BT 0.086 (1.134)	DT 0.010 (1.088)	loss nan (nan)	prob nan (nan)	GS 33.172 (33.172)	mem 39.681
Train: [87][740/750]	BT 0.341 (1.132)	DT 0.309 (1.086)	loss nan (nan)	prob nan (nan)	GS 33.719 (33.719)	mem 22.875
Train: [87][745/750]	BT 0.044 (1.129)	DT 0.007 (1.083)	loss nan (nan)	prob nan (nan)	GS 28.500 (28.500)	mem 13.625
Train: [87][750/750]	BT 0.029 (1.122)	DT 0.001 (1.076)	loss nan (nan)	prob nan (nan)	GS 35.156 (35.156)	mem 13.625
Train: [87][755/750]	BT 0.025 (1.117)	DT 0.001 (1.071)	loss nan (nan)	prob nan (nan)	GS 36.312 (36.312)	mem 10.613
epoch 87, total time 844.10
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [88][1/750]	BT 22.160 (22.160)	DT 22.082 (22.082)	loss nan (nan)	prob nan (nan)	GS 32.000 (32.000)	mem 38.505
Train: [88][5/750]	BT 0.047 (5.403)	DT 0.010 (5.339)	loss nan (nan)	prob nan (nan)	GS 34.516 (34.516)	mem 38.745
Train: [88][10/750]	BT 0.044 (2.735)	DT 0.005 (2.673)	loss nan (nan)	prob nan (nan)	GS 32.500 (32.500)	mem 38.844
Train: [88][15/750]	BT 0.102 (2.386)	DT 0.006 (2.323)	loss nan (nan)	prob nan (nan)	GS 29.625 (29.625)	mem 39.086
Train: [88][20/750]	BT 0.683 (2.083)	DT 0.625 (2.023)	loss nan (nan)	prob nan (nan)	GS 31.359 (31.359)	mem 38.780
Train: [88][25/750]	BT 2.143 (1.762)	DT 2.111 (1.704)	loss nan (nan)	prob nan (nan)	GS 27.688 (27.688)	mem 38.990
Train: [88][30/750]	BT 0.126 (1.864)	DT 0.001 (1.802)	loss nan (nan)	prob nan (nan)	GS 31.719 (31.719)	mem 38.976
Train: [88][35/750]	BT 0.040 (1.606)	DT 0.002 (1.545)	loss nan (nan)	prob nan (nan)	GS 30.562 (30.562)	mem 38.984
Train: [88][40/750]	BT 11.231 (1.743)	DT 11.177 (1.683)	loss nan (nan)	prob nan (nan)	GS 35.234 (35.234)	mem 38.833
Train: [88][45/750]	BT 0.033 (1.554)	DT 0.001 (1.496)	loss nan (nan)	prob nan (nan)	GS 30.516 (30.516)	mem 38.837
Train: [88][50/750]	BT 0.039 (1.404)	DT 0.002 (1.348)	loss nan (nan)	prob nan (nan)	GS 36.516 (36.516)	mem 38.836
Train: [88][55/750]	BT 0.036 (1.502)	DT 0.001 (1.448)	loss nan (nan)	prob nan (nan)	GS 32.531 (32.531)	mem 39.032
Train: [88][60/750]	BT 0.045 (1.383)	DT 0.001 (1.330)	loss nan (nan)	prob nan (nan)	GS 30.031 (30.031)	mem 39.258
Train: [88][65/750]	BT 0.030 (1.439)	DT 0.001 (1.386)	loss nan (nan)	prob nan (nan)	GS 30.547 (30.547)	mem 39.017
Train: [88][70/750]	BT 0.029 (1.359)	DT 0.001 (1.308)	loss nan (nan)	prob nan (nan)	GS 33.281 (33.281)	mem 39.069
Train: [88][75/750]	BT 0.069 (1.296)	DT 0.006 (1.244)	loss nan (nan)	prob nan (nan)	GS 33.578 (33.578)	mem 39.078
Train: [88][80/750]	BT 0.635 (1.336)	DT 0.595 (1.286)	loss nan (nan)	prob nan (nan)	GS 31.266 (31.266)	mem 39.033
Train: [88][85/750]	BT 0.085 (1.327)	DT 0.002 (1.276)	loss nan (nan)	prob nan (nan)	GS 26.438 (26.438)	mem 39.122
Train: [88][90/750]	BT 0.038 (1.310)	DT 0.002 (1.259)	loss nan (nan)	prob nan (nan)	GS 34.625 (34.625)	mem 39.454
Train: [88][95/750]	BT 0.072 (1.304)	DT 0.001 (1.254)	loss nan (nan)	prob nan (nan)	GS 35.625 (35.625)	mem 39.142
Train: [88][100/750]	BT 8.739 (1.333)	DT 8.696 (1.282)	loss nan (nan)	prob nan (nan)	GS 35.781 (35.781)	mem 39.370
Train: [88][105/750]	BT 0.084 (1.282)	DT 0.010 (1.231)	loss nan (nan)	prob nan (nan)	GS 33.984 (33.984)	mem 39.507
Train: [88][110/750]	BT 0.102 (1.261)	DT 0.011 (1.209)	loss nan (nan)	prob nan (nan)	GS 38.422 (38.422)	mem 39.380
Train: [88][115/750]	BT 0.042 (1.299)	DT 0.004 (1.248)	loss nan (nan)	prob nan (nan)	GS 34.531 (34.531)	mem 39.422
Train: [88][120/750]	BT 4.232 (1.282)	DT 4.141 (1.230)	loss nan (nan)	prob nan (nan)	GS 33.719 (33.719)	mem 39.479
Train: [88][125/750]	BT 0.032 (1.296)	DT 0.001 (1.245)	loss nan (nan)	prob nan (nan)	GS 34.078 (34.078)	mem 39.416
Train: [88][130/750]	BT 0.034 (1.247)	DT 0.001 (1.197)	loss nan (nan)	prob nan (nan)	GS 30.578 (30.578)	mem 39.460
Train: [88][135/750]	BT 0.075 (1.246)	DT 0.026 (1.197)	loss nan (nan)	prob nan (nan)	GS 30.172 (30.172)	mem 39.564
Train: [88][140/750]	BT 0.086 (1.244)	DT 0.003 (1.194)	loss nan (nan)	prob nan (nan)	GS 32.234 (32.234)	mem 39.663
Train: [88][145/750]	BT 0.094 (1.243)	DT 0.003 (1.193)	loss nan (nan)	prob nan (nan)	GS 31.281 (31.281)	mem 39.636
Train: [88][150/750]	BT 0.051 (1.242)	DT 0.021 (1.193)	loss nan (nan)	prob nan (nan)	GS 36.172 (36.172)	mem 39.795
Train: [88][155/750]	BT 0.065 (1.205)	DT 0.008 (1.155)	loss nan (nan)	prob nan (nan)	GS 27.422 (27.422)	mem 39.757
Train: [88][160/750]	BT 3.086 (1.241)	DT 3.055 (1.190)	loss nan (nan)	prob nan (nan)	GS 32.312 (32.312)	mem 39.723
Train: [88][165/750]	BT 0.032 (1.204)	DT 0.001 (1.154)	loss nan (nan)	prob nan (nan)	GS 30.328 (30.328)	mem 39.733
Train: [88][170/750]	BT 0.040 (1.209)	DT 0.009 (1.159)	loss nan (nan)	prob nan (nan)	GS 33.312 (33.312)	mem 39.774
Train: [88][175/750]	BT 0.036 (1.206)	DT 0.001 (1.157)	loss nan (nan)	prob nan (nan)	GS 33.891 (33.891)	mem 39.814
Train: [88][180/750]	BT 11.467 (1.238)	DT 11.421 (1.188)	loss nan (nan)	prob nan (nan)	GS 36.859 (36.859)	mem 39.949
Train: [88][185/750]	BT 0.075 (1.209)	DT 0.016 (1.159)	loss nan (nan)	prob nan (nan)	GS 27.812 (27.812)	mem 39.819
Train: [88][190/750]	BT 0.044 (1.179)	DT 0.002 (1.128)	loss nan (nan)	prob nan (nan)	GS 35.328 (35.328)	mem 39.820
Train: [88][195/750]	BT 0.033 (1.223)	DT 0.001 (1.173)	loss nan (nan)	prob nan (nan)	GS 28.266 (28.266)	mem 39.772
Train: [88][200/750]	BT 0.060 (1.214)	DT 0.028 (1.164)	loss nan (nan)	prob nan (nan)	GS 34.781 (34.781)	mem 39.852
Train: [88][205/750]	BT 0.106 (1.213)	DT 0.013 (1.163)	loss nan (nan)	prob nan (nan)	GS 45.000 (45.000)	mem 39.969
Train: [88][210/750]	BT 0.033 (1.217)	DT 0.001 (1.166)	loss nan (nan)	prob nan (nan)	GS 35.422 (35.422)	mem 39.784
Train: [88][215/750]	BT 0.037 (1.190)	DT 0.001 (1.139)	loss nan (nan)	prob nan (nan)	GS 30.062 (30.062)	mem 39.786
Train: [88][220/750]	BT 9.397 (1.237)	DT 9.364 (1.187)	loss nan (nan)	prob nan (nan)	GS 35.219 (35.219)	mem 39.820
Train: [88][225/750]	BT 0.035 (1.211)	DT 0.002 (1.161)	loss nan (nan)	prob nan (nan)	GS 29.344 (29.344)	mem 39.970
Train: [88][230/750]	BT 2.230 (1.203)	DT 2.188 (1.153)	loss nan (nan)	prob nan (nan)	GS 33.859 (33.859)	mem 39.822
Train: [88][235/750]	BT 0.034 (1.206)	DT 0.001 (1.156)	loss nan (nan)	prob nan (nan)	GS 28.594 (28.594)	mem 39.890
Train: [88][240/750]	BT 5.131 (1.203)	DT 5.012 (1.153)	loss nan (nan)	prob nan (nan)	GS 32.891 (32.891)	mem 39.875
Train: [88][245/750]	BT 0.127 (1.203)	DT 0.005 (1.153)	loss nan (nan)	prob nan (nan)	GS 29.672 (29.672)	mem 39.927
Train: [88][250/750]	BT 0.047 (1.180)	DT 0.001 (1.130)	loss nan (nan)	prob nan (nan)	GS 30.359 (30.359)	mem 39.836
Train: [88][255/750]	BT 0.079 (1.178)	DT 0.006 (1.128)	loss nan (nan)	prob nan (nan)	GS 29.297 (29.297)	mem 40.105
Train: [88][260/750]	BT 0.033 (1.189)	DT 0.001 (1.139)	loss nan (nan)	prob nan (nan)	GS 34.391 (34.391)	mem 39.881
Train: [88][265/750]	BT 0.059 (1.168)	DT 0.001 (1.118)	loss nan (nan)	prob nan (nan)	GS 37.594 (37.594)	mem 39.882
Train: [88][270/750]	BT 0.035 (1.200)	DT 0.002 (1.151)	loss nan (nan)	prob nan (nan)	GS 30.016 (30.016)	mem 39.842
Train: [88][275/750]	BT 0.050 (1.179)	DT 0.004 (1.130)	loss nan (nan)	prob nan (nan)	GS 29.734 (29.734)	mem 39.851
Train: [88][280/750]	BT 7.116 (1.201)	DT 7.078 (1.152)	loss nan (nan)	prob nan (nan)	GS 34.562 (34.562)	mem 40.030
Train: [88][285/750]	BT 0.056 (1.181)	DT 0.008 (1.132)	loss nan (nan)	prob nan (nan)	GS 34.094 (34.094)	mem 39.888
Train: [88][290/750]	BT 3.819 (1.174)	DT 3.774 (1.125)	loss nan (nan)	prob nan (nan)	GS 35.000 (35.000)	mem 39.955
Train: [88][295/750]	BT 0.056 (1.189)	DT 0.006 (1.141)	loss nan (nan)	prob nan (nan)	GS 31.516 (31.516)	mem 40.071
Train: [88][300/750]	BT 0.491 (1.172)	DT 0.449 (1.123)	loss nan (nan)	prob nan (nan)	GS 33.953 (33.953)	mem 39.982
Train: [88][305/750]	BT 0.041 (1.196)	DT 0.007 (1.147)	loss nan (nan)	prob nan (nan)	GS 33.875 (33.875)	mem 39.979
Train: [88][310/750]	BT 0.055 (1.177)	DT 0.002 (1.128)	loss nan (nan)	prob nan (nan)	GS 32.438 (32.438)	mem 39.956
Train: [88][315/750]	BT 0.069 (1.163)	DT 0.021 (1.114)	loss nan (nan)	prob nan (nan)	GS 31.281 (31.281)	mem 40.033
Train: [88][320/750]	BT 0.037 (1.181)	DT 0.003 (1.133)	loss nan (nan)	prob nan (nan)	GS 30.422 (30.422)	mem 39.938
Train: [88][325/750]	BT 0.025 (1.164)	DT 0.001 (1.116)	loss nan (nan)	prob nan (nan)	GS 31.906 (31.906)	mem 39.939
Train: [88][330/750]	BT 0.040 (1.186)	DT 0.010 (1.138)	loss nan (nan)	prob nan (nan)	GS 34.047 (34.047)	mem 39.873
Train: [88][335/750]	BT 0.025 (1.169)	DT 0.001 (1.121)	loss nan (nan)	prob nan (nan)	GS 34.016 (34.016)	mem 39.873
Train: [88][340/750]	BT 12.980 (1.192)	DT 12.943 (1.144)	loss nan (nan)	prob nan (nan)	GS 34.781 (34.781)	mem 39.846
Train: [88][345/750]	BT 0.024 (1.175)	DT 0.001 (1.127)	loss nan (nan)	prob nan (nan)	GS 27.625 (27.625)	mem 39.870
Train: [88][350/750]	BT 0.081 (1.159)	DT 0.004 (1.111)	loss nan (nan)	prob nan (nan)	GS 33.125 (33.125)	mem 39.866
Train: [88][355/750]	BT 0.096 (1.173)	DT 0.040 (1.126)	loss nan (nan)	prob nan (nan)	GS 31.453 (31.453)	mem 39.989
Train: [88][360/750]	BT 0.030 (1.158)	DT 0.001 (1.110)	loss nan (nan)	prob nan (nan)	GS 38.219 (38.219)	mem 39.990
Train: [88][365/750]	BT 0.038 (1.176)	DT 0.006 (1.129)	loss nan (nan)	prob nan (nan)	GS 34.812 (34.812)	mem 40.026
Train: [88][370/750]	BT 0.030 (1.161)	DT 0.001 (1.113)	loss nan (nan)	prob nan (nan)	GS 32.969 (32.969)	mem 40.058
Train: [88][375/750]	BT 0.039 (1.147)	DT 0.009 (1.100)	loss nan (nan)	prob nan (nan)	GS 29.516 (29.516)	mem 39.803
Train: [88][380/750]	BT 0.031 (1.160)	DT 0.002 (1.113)	loss nan (nan)	prob nan (nan)	GS 36.891 (36.891)	mem 39.880
Train: [88][385/750]	BT 0.033 (1.145)	DT 0.002 (1.098)	loss nan (nan)	prob nan (nan)	GS 30.578 (30.578)	mem 39.818
Train: [88][390/750]	BT 0.024 (1.166)	DT 0.001 (1.119)	loss nan (nan)	prob nan (nan)	GS 30.859 (30.859)	mem 39.828
Train: [88][395/750]	BT 0.034 (1.152)	DT 0.002 (1.105)	loss nan (nan)	prob nan (nan)	GS 27.359 (27.359)	mem 39.831
Train: [88][400/750]	BT 14.493 (1.174)	DT 14.449 (1.127)	loss nan (nan)	prob nan (nan)	GS 34.484 (34.484)	mem 39.974
Train: [88][405/750]	BT 0.035 (1.160)	DT 0.002 (1.113)	loss nan (nan)	prob nan (nan)	GS 33.203 (33.203)	mem 39.937
Train: [88][410/750]	BT 0.078 (1.147)	DT 0.019 (1.100)	loss nan (nan)	prob nan (nan)	GS 36.859 (36.859)	mem 39.953
Train: [88][415/750]	BT 0.050 (1.161)	DT 0.010 (1.114)	loss nan (nan)	prob nan (nan)	GS 27.859 (27.859)	mem 39.979
Train: [88][420/750]	BT 0.056 (1.147)	DT 0.007 (1.101)	loss nan (nan)	prob nan (nan)	GS 34.203 (34.203)	mem 39.978
Train: [88][425/750]	BT 0.104 (1.166)	DT 0.001 (1.119)	loss nan (nan)	prob nan (nan)	GS 29.828 (29.828)	mem 40.168
Train: [88][430/750]	BT 0.031 (1.152)	DT 0.001 (1.106)	loss nan (nan)	prob nan (nan)	GS 31.844 (31.844)	mem 40.168
Train: [88][435/750]	BT 0.052 (1.150)	DT 0.022 (1.104)	loss nan (nan)	prob nan (nan)	GS 35.672 (35.672)	mem 39.930
Train: [88][440/750]	BT 0.039 (1.155)	DT 0.005 (1.109)	loss nan (nan)	prob nan (nan)	GS 36.625 (36.625)	mem 40.108
Train: [88][445/750]	BT 0.025 (1.143)	DT 0.001 (1.097)	loss nan (nan)	prob nan (nan)	GS 30.078 (30.078)	mem 39.924
Train: [88][450/750]	BT 0.030 (1.165)	DT 0.001 (1.119)	loss nan (nan)	prob nan (nan)	GS 31.734 (31.734)	mem 39.982
Train: [88][455/750]	BT 0.031 (1.153)	DT 0.001 (1.107)	loss nan (nan)	prob nan (nan)	GS 29.203 (29.203)	mem 39.986
Train: [88][460/750]	BT 12.565 (1.170)	DT 12.534 (1.123)	loss nan (nan)	prob nan (nan)	GS 38.797 (38.797)	mem 39.954
Train: [88][465/750]	BT 0.039 (1.158)	DT 0.001 (1.111)	loss nan (nan)	prob nan (nan)	GS 33.719 (33.719)	mem 39.926
Train: [88][470/750]	BT 0.024 (1.146)	DT 0.001 (1.100)	loss nan (nan)	prob nan (nan)	GS 30.922 (30.922)	mem 39.927
Train: [88][475/750]	BT 0.052 (1.161)	DT 0.014 (1.115)	loss nan (nan)	prob nan (nan)	GS 34.922 (34.922)	mem 39.939
Train: [88][480/750]	BT 0.031 (1.149)	DT 0.001 (1.103)	loss nan (nan)	prob nan (nan)	GS 31.156 (31.156)	mem 39.938
Train: [88][485/750]	BT 0.028 (1.169)	DT 0.001 (1.123)	loss nan (nan)	prob nan (nan)	GS 29.891 (29.891)	mem 39.961
Train: [88][490/750]	BT 0.050 (1.157)	DT 0.005 (1.112)	loss nan (nan)	prob nan (nan)	GS 33.344 (33.344)	mem 39.962
Train: [88][495/750]	BT 0.031 (1.146)	DT 0.002 (1.101)	loss nan (nan)	prob nan (nan)	GS 33.828 (33.828)	mem 39.963
Train: [88][500/750]	BT 0.036 (1.158)	DT 0.001 (1.113)	loss nan (nan)	prob nan (nan)	GS 35.109 (35.109)	mem 40.116
Train: [88][505/750]	BT 0.062 (1.147)	DT 0.006 (1.102)	loss nan (nan)	prob nan (nan)	GS 26.625 (26.625)	mem 40.015
Train: [88][510/750]	BT 0.028 (1.163)	DT 0.001 (1.118)	loss nan (nan)	prob nan (nan)	GS 29.016 (29.016)	mem 40.050
Train: [88][515/750]	BT 0.027 (1.153)	DT 0.001 (1.107)	loss nan (nan)	prob nan (nan)	GS 29.312 (29.312)	mem 40.051
Train: [88][520/750]	BT 10.298 (1.162)	DT 10.261 (1.116)	loss nan (nan)	prob nan (nan)	GS 31.391 (31.391)	mem 40.124
Train: [88][525/750]	BT 0.110 (1.151)	DT 0.020 (1.106)	loss nan (nan)	prob nan (nan)	GS 28.141 (28.141)	mem 40.065
Train: [88][530/750]	BT 0.052 (1.141)	DT 0.009 (1.095)	loss nan (nan)	prob nan (nan)	GS 34.359 (34.359)	mem 40.068
Train: [88][535/750]	BT 0.061 (1.152)	DT 0.018 (1.107)	loss nan (nan)	prob nan (nan)	GS 31.656 (31.656)	mem 40.060
Train: [88][540/750]	BT 0.032 (1.142)	DT 0.002 (1.097)	loss nan (nan)	prob nan (nan)	GS 34.547 (34.547)	mem 40.165
Train: [88][545/750]	BT 0.035 (1.155)	DT 0.002 (1.110)	loss nan (nan)	prob nan (nan)	GS 31.422 (31.422)	mem 40.519
Train: [88][550/750]	BT 0.065 (1.145)	DT 0.009 (1.100)	loss nan (nan)	prob nan (nan)	GS 31.844 (31.844)	mem 40.653
Train: [88][555/750]	BT 0.058 (1.140)	DT 0.009 (1.095)	loss nan (nan)	prob nan (nan)	GS 31.109 (31.109)	mem 40.705
Train: [88][560/750]	BT 0.040 (1.148)	DT 0.001 (1.103)	loss nan (nan)	prob nan (nan)	GS 36.281 (36.281)	mem 40.504
Train: [88][565/750]	BT 0.070 (1.138)	DT 0.012 (1.093)	loss nan (nan)	prob nan (nan)	GS 30.625 (30.625)	mem 40.528
Train: [88][570/750]	BT 0.042 (1.151)	DT 0.001 (1.106)	loss nan (nan)	prob nan (nan)	GS 36.188 (36.188)	mem 41.221
Train: [88][575/750]	BT 0.030 (1.142)	DT 0.001 (1.097)	loss nan (nan)	prob nan (nan)	GS 36.609 (36.609)	mem 41.276
Train: [88][580/750]	BT 11.515 (1.158)	DT 11.484 (1.113)	loss nan (nan)	prob nan (nan)	GS 33.438 (33.438)	mem 42.639
Train: [88][585/750]	BT 0.035 (1.148)	DT 0.004 (1.103)	loss nan (nan)	prob nan (nan)	GS 32.547 (32.547)	mem 42.443
Train: [88][590/750]	BT 4.348 (1.146)	DT 4.293 (1.101)	loss nan (nan)	prob nan (nan)	GS 35.875 (35.875)	mem 42.296
Train: [88][595/750]	BT 0.036 (1.154)	DT 0.001 (1.110)	loss nan (nan)	prob nan (nan)	GS 32.062 (32.062)	mem 42.846
Train: [88][600/750]	BT 0.033 (1.145)	DT 0.002 (1.101)	loss nan (nan)	prob nan (nan)	GS 32.406 (32.406)	mem 42.830
Train: [88][605/750]	BT 0.036 (1.161)	DT 0.002 (1.117)	loss nan (nan)	prob nan (nan)	GS 33.047 (33.047)	mem 41.794
Train: [88][610/750]	BT 0.030 (1.152)	DT 0.001 (1.108)	loss nan (nan)	prob nan (nan)	GS 35.250 (35.250)	mem 41.795
Train: [88][615/750]	BT 0.027 (1.143)	DT 0.001 (1.099)	loss nan (nan)	prob nan (nan)	GS 40.297 (40.297)	mem 41.797
Train: [88][620/750]	BT 0.047 (1.155)	DT 0.009 (1.111)	loss nan (nan)	prob nan (nan)	GS 37.391 (37.391)	mem 42.082
Train: [88][625/750]	BT 0.030 (1.146)	DT 0.001 (1.102)	loss nan (nan)	prob nan (nan)	GS 30.000 (30.000)	mem 42.085
Train: [88][630/750]	BT 0.020 (1.159)	DT 0.001 (1.115)	loss nan (nan)	prob nan (nan)	GS 32.953 (32.953)	mem 42.146
Train: [88][635/750]	BT 0.030 (1.150)	DT 0.002 (1.106)	loss nan (nan)	prob nan (nan)	GS 26.766 (26.766)	mem 42.146
Train: [88][640/750]	BT 10.555 (1.158)	DT 10.524 (1.114)	loss nan (nan)	prob nan (nan)	GS 31.500 (31.500)	mem 42.212
Train: [88][645/750]	BT 0.023 (1.149)	DT 0.001 (1.105)	loss nan (nan)	prob nan (nan)	GS 30.203 (30.203)	mem 42.223
Train: [88][650/750]	BT 0.052 (1.141)	DT 0.009 (1.097)	loss nan (nan)	prob nan (nan)	GS 35.391 (35.391)	mem 42.233
Train: [88][655/750]	BT 0.029 (1.149)	DT 0.001 (1.106)	loss nan (nan)	prob nan (nan)	GS 29.625 (29.625)	mem 42.149
Train: [88][660/750]	BT 0.029 (1.141)	DT 0.002 (1.097)	loss nan (nan)	prob nan (nan)	GS 32.828 (32.828)	mem 42.151
Train: [88][665/750]	BT 0.103 (1.154)	DT 0.004 (1.110)	loss nan (nan)	prob nan (nan)	GS 34.734 (34.734)	mem 42.339
Train: [88][670/750]	BT 0.038 (1.145)	DT 0.002 (1.101)	loss nan (nan)	prob nan (nan)	GS 31.188 (31.188)	mem 42.245
Train: [88][675/750]	BT 0.023 (1.138)	DT 0.001 (1.094)	loss nan (nan)	prob nan (nan)	GS 31.141 (31.141)	mem 42.178
Train: [88][680/750]	BT 0.073 (1.150)	DT 0.026 (1.107)	loss nan (nan)	prob nan (nan)	GS 37.766 (37.766)	mem 42.160
Train: [88][685/750]	BT 0.068 (1.142)	DT 0.013 (1.099)	loss nan (nan)	prob nan (nan)	GS 28.094 (28.094)	mem 42.353
Train: [88][690/750]	BT 0.079 (1.150)	DT 0.014 (1.107)	loss nan (nan)	prob nan (nan)	GS 34.328 (34.328)	mem 42.266
Train: [88][695/750]	BT 0.051 (1.143)	DT 0.006 (1.099)	loss nan (nan)	prob nan (nan)	GS 34.859 (34.859)	mem 42.407
Train: [88][700/750]	BT 7.156 (1.147)	DT 7.102 (1.103)	loss nan (nan)	prob nan (nan)	GS 29.172 (29.172)	mem 42.274
Train: [88][705/750]	BT 0.028 (1.144)	DT 0.004 (1.100)	loss nan (nan)	prob nan (nan)	GS 30.812 (30.812)	mem 42.271
arpack error, retry= 0
Train: [88][710/750]	BT 2.949 (1.140)	DT 2.895 (1.096)	loss nan (nan)	prob nan (nan)	GS 33.797 (33.797)	mem 42.233
Train: [88][715/750]	BT 0.024 (1.144)	DT 0.001 (1.100)	loss nan (nan)	prob nan (nan)	GS 31.422 (31.422)	mem 42.378
Train: [88][720/750]	BT 0.059 (1.136)	DT 0.001 (1.093)	loss nan (nan)	prob nan (nan)	GS 34.859 (34.859)	mem 42.348
Train: [88][725/750]	BT 0.098 (1.145)	DT 0.012 (1.102)	loss nan (nan)	prob nan (nan)	GS 30.219 (30.219)	mem 42.387
Train: [88][730/750]	BT 0.076 (1.138)	DT 0.001 (1.094)	loss nan (nan)	prob nan (nan)	GS 35.844 (35.844)	mem 42.233
Train: [88][735/750]	BT 0.032 (1.135)	DT 0.002 (1.091)	loss nan (nan)	prob nan (nan)	GS 31.641 (31.641)	mem 39.539
Train: [88][740/750]	BT 0.032 (1.139)	DT 0.001 (1.095)	loss nan (nan)	prob nan (nan)	GS 32.703 (32.703)	mem 23.294
Train: [88][745/750]	BT 0.055 (1.131)	DT 0.002 (1.087)	loss nan (nan)	prob nan (nan)	GS 27.812 (27.812)	mem 21.940
Train: [88][750/750]	BT 0.028 (1.130)	DT 0.001 (1.086)	loss nan (nan)	prob nan (nan)	GS 34.562 (34.562)	mem 9.990
Train: [88][755/750]	BT 0.028 (1.122)	DT 0.001 (1.079)	loss nan (nan)	prob nan (nan)	GS 29.562 (29.562)	mem 9.995
epoch 88, total time 847.70
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [89][1/750]	BT 23.596 (23.596)	DT 23.537 (23.537)	loss nan (nan)	prob nan (nan)	GS 26.625 (26.625)	mem 41.127
Train: [89][5/750]	BT 0.048 (5.703)	DT 0.012 (5.649)	loss nan (nan)	prob nan (nan)	GS 29.078 (29.078)	mem 41.083
Train: [89][10/750]	BT 0.033 (2.870)	DT 0.001 (2.825)	loss nan (nan)	prob nan (nan)	GS 32.812 (32.812)	mem 41.089
Train: [89][15/750]	BT 0.035 (2.964)	DT 0.001 (2.922)	loss nan (nan)	prob nan (nan)	GS 29.016 (29.016)	mem 41.093
Train: [89][20/750]	BT 0.044 (2.232)	DT 0.003 (2.193)	loss nan (nan)	prob nan (nan)	GS 32.812 (32.812)	mem 41.039
Train: [89][25/750]	BT 0.049 (1.795)	DT 0.002 (1.755)	loss nan (nan)	prob nan (nan)	GS 33.188 (33.188)	mem 41.041
Train: [89][30/750]	BT 0.051 (1.906)	DT 0.010 (1.866)	loss nan (nan)	prob nan (nan)	GS 29.328 (29.328)	mem 41.095
Train: [89][35/750]	BT 0.044 (1.679)	DT 0.008 (1.638)	loss nan (nan)	prob nan (nan)	GS 30.828 (30.828)	mem 41.325
Train: [89][40/750]	BT 0.035 (1.785)	DT 0.001 (1.744)	loss nan (nan)	prob nan (nan)	GS 35.359 (35.359)	mem 41.157
Train: [89][45/750]	BT 0.031 (1.621)	DT 0.005 (1.577)	loss nan (nan)	prob nan (nan)	GS 28.375 (28.375)	mem 41.198
Train: [89][50/750]	BT 12.377 (1.711)	DT 12.348 (1.667)	loss nan (nan)	prob nan (nan)	GS 33.359 (33.359)	mem 41.300
Train: [89][55/750]	BT 0.051 (1.559)	DT 0.001 (1.515)	loss nan (nan)	prob nan (nan)	GS 34.469 (34.469)	mem 41.303
Train: [89][60/750]	BT 0.031 (1.460)	DT 0.001 (1.416)	loss nan (nan)	prob nan (nan)	GS 29.562 (29.562)	mem 41.367
Train: [89][65/750]	BT 0.062 (1.544)	DT 0.009 (1.501)	loss nan (nan)	prob nan (nan)	GS 35.109 (35.109)	mem 41.636
Train: [89][70/750]	BT 0.070 (1.465)	DT 0.025 (1.421)	loss nan (nan)	prob nan (nan)	GS 37.422 (37.422)	mem 41.630
Train: [89][75/750]	BT 0.058 (1.508)	DT 0.019 (1.464)	loss nan (nan)	prob nan (nan)	GS 31.297 (31.297)	mem 41.645
Train: [89][80/750]	BT 2.816 (1.453)	DT 2.775 (1.407)	loss nan (nan)	prob nan (nan)	GS 35.250 (35.250)	mem 41.792
Train: [89][85/750]	BT 0.040 (1.370)	DT 0.002 (1.325)	loss nan (nan)	prob nan (nan)	GS 33.703 (33.703)	mem 41.789
Train: [89][90/750]	BT 0.026 (1.391)	DT 0.001 (1.347)	loss nan (nan)	prob nan (nan)	GS 33.578 (33.578)	mem 41.918
Train: [89][95/750]	BT 0.034 (1.326)	DT 0.002 (1.280)	loss nan (nan)	prob nan (nan)	GS 29.953 (29.953)	mem 42.006
Train: [89][100/750]	BT 0.030 (1.389)	DT 0.001 (1.343)	loss nan (nan)	prob nan (nan)	GS 31.156 (31.156)	mem 41.942
Train: [89][105/750]	BT 0.044 (1.358)	DT 0.005 (1.313)	loss nan (nan)	prob nan (nan)	GS 33.703 (33.703)	mem 41.966
Train: [89][110/750]	BT 7.096 (1.363)	DT 6.996 (1.317)	loss nan (nan)	prob nan (nan)	GS 34.844 (34.844)	mem 42.397
Train: [89][115/750]	BT 0.031 (1.306)	DT 0.001 (1.260)	loss nan (nan)	prob nan (nan)	GS 29.766 (29.766)	mem 41.906
Train: [89][120/750]	BT 0.026 (1.316)	DT 0.001 (1.271)	loss nan (nan)	prob nan (nan)	GS 31.547 (31.547)	mem 41.954
Train: [89][125/750]	BT 0.080 (1.308)	DT 0.010 (1.263)	loss nan (nan)	prob nan (nan)	GS 30.578 (30.578)	mem 41.939
Train: [89][130/750]	BT 0.049 (1.297)	DT 0.003 (1.252)	loss nan (nan)	prob nan (nan)	GS 31.609 (31.609)	mem 42.010
Train: [89][135/750]	BT 0.077 (1.316)	DT 0.018 (1.271)	loss nan (nan)	prob nan (nan)	GS 31.250 (31.250)	mem 41.907
Train: [89][140/750]	BT 4.552 (1.303)	DT 4.502 (1.258)	loss nan (nan)	prob nan (nan)	GS 37.516 (37.516)	mem 41.869
Train: [89][145/750]	BT 0.055 (1.259)	DT 0.002 (1.215)	loss nan (nan)	prob nan (nan)	GS 28.531 (28.531)	mem 41.916
Train: [89][150/750]	BT 0.030 (1.276)	DT 0.002 (1.232)	loss nan (nan)	prob nan (nan)	GS 32.656 (32.656)	mem 41.811
Train: [89][155/750]	BT 0.031 (1.244)	DT 0.001 (1.200)	loss nan (nan)	prob nan (nan)	GS 27.500 (27.500)	mem 41.839
Train: [89][160/750]	BT 0.030 (1.278)	DT 0.002 (1.234)	loss nan (nan)	prob nan (nan)	GS 34.828 (34.828)	mem 41.841
Train: [89][165/750]	BT 0.031 (1.244)	DT 0.001 (1.201)	loss nan (nan)	prob nan (nan)	GS 31.891 (31.891)	mem 41.864
Train: [89][170/750]	BT 9.913 (1.267)	DT 9.869 (1.224)	loss nan (nan)	prob nan (nan)	GS 31.000 (31.000)	mem 41.961
Train: [89][175/750]	BT 0.145 (1.254)	DT 0.047 (1.210)	loss nan (nan)	prob nan (nan)	GS 31.859 (31.859)	mem 42.137
Train: [89][180/750]	BT 0.041 (1.223)	DT 0.002 (1.179)	loss nan (nan)	prob nan (nan)	GS 34.469 (34.469)	mem 42.024
Train: [89][185/750]	BT 0.029 (1.260)	DT 0.005 (1.216)	loss nan (nan)	prob nan (nan)	GS 32.078 (32.078)	mem 42.167
Train: [89][190/750]	BT 0.035 (1.228)	DT 0.001 (1.184)	loss nan (nan)	prob nan (nan)	GS 37.891 (37.891)	mem 41.892
Train: [89][195/750]	BT 0.094 (1.237)	DT 0.006 (1.194)	loss nan (nan)	prob nan (nan)	GS 34.234 (34.234)	mem 41.922
Train: [89][200/750]	BT 0.042 (1.226)	DT 0.007 (1.182)	loss nan (nan)	prob nan (nan)	GS 37.484 (37.484)	mem 41.995
Train: [89][205/750]	BT 0.100 (1.198)	DT 0.006 (1.154)	loss nan (nan)	prob nan (nan)	GS 33.031 (33.031)	mem 42.044
Train: [89][210/750]	BT 0.033 (1.242)	DT 0.002 (1.198)	loss nan (nan)	prob nan (nan)	GS 32.703 (32.703)	mem 42.029
Train: [89][215/750]	BT 0.038 (1.221)	DT 0.006 (1.177)	loss nan (nan)	prob nan (nan)	GS 26.859 (26.859)	mem 42.032
Train: [89][220/750]	BT 7.561 (1.246)	DT 7.471 (1.202)	loss nan (nan)	prob nan (nan)	GS 34.641 (34.641)	mem 41.999
Train: [89][225/750]	BT 0.031 (1.220)	DT 0.001 (1.175)	loss nan (nan)	prob nan (nan)	GS 30.844 (30.844)	mem 41.998
Train: [89][230/750]	BT 4.772 (1.216)	DT 4.732 (1.170)	loss nan (nan)	prob nan (nan)	GS 30.953 (30.953)	mem 42.120
Train: [89][235/750]	BT 0.081 (1.229)	DT 0.007 (1.183)	loss nan (nan)	prob nan (nan)	GS 26.234 (26.234)	mem 42.227
Train: [89][240/750]	BT 0.080 (1.204)	DT 0.013 (1.159)	loss nan (nan)	prob nan (nan)	GS 31.359 (31.359)	mem 42.063
Train: [89][245/750]	BT 0.057 (1.232)	DT 0.004 (1.186)	loss nan (nan)	prob nan (nan)	GS 34.828 (34.828)	mem 42.031
Train: [89][250/750]	BT 0.052 (1.208)	DT 0.001 (1.163)	loss nan (nan)	prob nan (nan)	GS 31.953 (31.953)	mem 42.031
Train: [89][255/750]	BT 0.102 (1.215)	DT 0.010 (1.169)	loss nan (nan)	prob nan (nan)	GS 30.312 (30.312)	mem 42.081
Train: [89][260/750]	BT 0.145 (1.211)	DT 0.102 (1.165)	loss nan (nan)	prob nan (nan)	GS 36.062 (36.062)	mem 42.125
Train: [89][265/750]	BT 0.034 (1.189)	DT 0.002 (1.143)	loss nan (nan)	prob nan (nan)	GS 33.875 (33.875)	mem 42.126
Train: [89][270/750]	BT 0.026 (1.210)	DT 0.001 (1.164)	loss nan (nan)	prob nan (nan)	GS 32.453 (32.453)	mem 42.262
Train: [89][275/750]	BT 0.039 (1.194)	DT 0.001 (1.149)	loss nan (nan)	prob nan (nan)	GS 37.906 (37.906)	mem 42.178
Train: [89][280/750]	BT 3.222 (1.220)	DT 3.191 (1.174)	loss nan (nan)	prob nan (nan)	GS 34.266 (34.266)	mem 42.128
Train: [89][285/750]	BT 0.032 (1.215)	DT 0.002 (1.170)	loss nan (nan)	prob nan (nan)	GS 31.453 (31.453)	mem 42.129
Train: [89][290/750]	BT 3.309 (1.206)	DT 3.277 (1.161)	loss nan (nan)	prob nan (nan)	GS 30.859 (30.859)	mem 42.131
Train: [89][295/750]	BT 0.033 (1.199)	DT 0.002 (1.154)	loss nan (nan)	prob nan (nan)	GS 30.000 (30.000)	mem 42.133
Train: [89][300/750]	BT 0.044 (1.208)	DT 0.002 (1.163)	loss nan (nan)	prob nan (nan)	GS 31.578 (31.578)	mem 42.155
Train: [89][305/750]	BT 0.063 (1.200)	DT 0.011 (1.155)	loss nan (nan)	prob nan (nan)	GS 29.438 (29.438)	mem 42.092
Train: [89][310/750]	BT 0.022 (1.211)	DT 0.001 (1.165)	loss nan (nan)	prob nan (nan)	GS 35.312 (35.312)	mem 42.130
Train: [89][315/750]	BT 0.038 (1.197)	DT 0.001 (1.152)	loss nan (nan)	prob nan (nan)	GS 28.250 (28.250)	mem 42.149
Train: [89][320/750]	BT 8.490 (1.221)	DT 8.428 (1.176)	loss nan (nan)	prob nan (nan)	GS 35.344 (35.344)	mem 42.199
Train: [89][325/750]	BT 0.030 (1.203)	DT 0.001 (1.158)	loss nan (nan)	prob nan (nan)	GS 31.531 (31.531)	mem 42.127
Train: [89][330/750]	BT 0.088 (1.202)	DT 0.005 (1.157)	loss nan (nan)	prob nan (nan)	GS 35.859 (35.859)	mem 42.200
Train: [89][335/750]	BT 0.031 (1.205)	DT 0.001 (1.160)	loss nan (nan)	prob nan (nan)	GS 30.484 (30.484)	mem 42.154
Train: [89][340/750]	BT 9.842 (1.216)	DT 9.794 (1.172)	loss nan (nan)	prob nan (nan)	GS 34.578 (34.578)	mem 42.170
Train: [89][345/750]	BT 0.045 (1.207)	DT 0.004 (1.162)	loss nan (nan)	prob nan (nan)	GS 30.203 (30.203)	mem 42.140
Train: [89][350/750]	BT 1.269 (1.194)	DT 1.227 (1.149)	loss nan (nan)	prob nan (nan)	GS 33.328 (33.328)	mem 42.166
Train: [89][355/750]	BT 0.021 (1.209)	DT 0.001 (1.164)	loss nan (nan)	prob nan (nan)	GS 31.516 (31.516)	mem 42.115
Train: [89][360/750]	BT 0.072 (1.198)	DT 0.001 (1.153)	loss nan (nan)	prob nan (nan)	GS 33.297 (33.297)	mem 42.082
Train: [89][365/750]	BT 0.036 (1.212)	DT 0.002 (1.167)	loss nan (nan)	prob nan (nan)	GS 34.438 (34.438)	mem 42.252
Train: [89][370/750]	BT 0.031 (1.201)	DT 0.002 (1.156)	loss nan (nan)	prob nan (nan)	GS 33.359 (33.359)	mem 42.117
Train: [89][375/750]	BT 0.112 (1.188)	DT 0.012 (1.143)	loss nan (nan)	prob nan (nan)	GS 33.547 (33.547)	mem 42.249
Train: [89][380/750]	BT 5.156 (1.205)	DT 5.096 (1.160)	loss nan (nan)	prob nan (nan)	GS 31.547 (31.547)	mem 42.169
Train: [89][385/750]	BT 0.053 (1.190)	DT 0.019 (1.145)	loss nan (nan)	prob nan (nan)	GS 26.672 (26.672)	mem 42.227
Train: [89][390/750]	BT 0.051 (1.207)	DT 0.010 (1.162)	loss nan (nan)	prob nan (nan)	GS 34.812 (34.812)	mem 42.222
Train: [89][395/750]	BT 0.047 (1.193)	DT 0.001 (1.148)	loss nan (nan)	prob nan (nan)	GS 33.062 (33.062)	mem 42.019
Train: [89][400/750]	BT 9.730 (1.203)	DT 9.686 (1.158)	loss nan (nan)	prob nan (nan)	GS 30.250 (30.250)	mem 42.160
Train: [89][405/750]	BT 0.037 (1.199)	DT 0.001 (1.154)	loss nan (nan)	prob nan (nan)	GS 30.969 (30.969)	mem 42.129
Train: [89][410/750]	BT 0.048 (1.185)	DT 0.003 (1.140)	loss nan (nan)	prob nan (nan)	GS 29.203 (29.203)	mem 42.292
Train: [89][415/750]	BT 0.032 (1.192)	DT 0.002 (1.148)	loss nan (nan)	prob nan (nan)	GS 31.031 (31.031)	mem 42.137
Train: [89][420/750]	BT 0.095 (1.183)	DT 0.001 (1.138)	loss nan (nan)	prob nan (nan)	GS 30.984 (30.984)	mem 42.069
Train: [89][425/750]	BT 0.116 (1.187)	DT 0.002 (1.142)	loss nan (nan)	prob nan (nan)	GS 35.484 (35.484)	mem 42.163
Train: [89][430/750]	BT 0.038 (1.187)	DT 0.010 (1.142)	loss nan (nan)	prob nan (nan)	GS 35.312 (35.312)	mem 42.168
Train: [89][435/750]	BT 0.048 (1.174)	DT 0.002 (1.129)	loss nan (nan)	prob nan (nan)	GS 27.906 (27.906)	mem 42.205
Train: [89][440/750]	BT 1.470 (1.194)	DT 1.427 (1.149)	loss nan (nan)	prob nan (nan)	GS 38.531 (38.531)	mem 42.181
Train: [89][445/750]	BT 0.047 (1.181)	DT 0.007 (1.136)	loss nan (nan)	prob nan (nan)	GS 34.469 (34.469)	mem 42.102
Train: [89][450/750]	BT 7.164 (1.194)	DT 7.129 (1.149)	loss nan (nan)	prob nan (nan)	GS 32.688 (32.688)	mem 42.295
Train: [89][455/750]	BT 0.032 (1.182)	DT 0.001 (1.138)	loss nan (nan)	prob nan (nan)	GS 34.484 (34.484)	mem 42.214
Train: [89][460/750]	BT 3.690 (1.178)	DT 3.641 (1.133)	loss nan (nan)	prob nan (nan)	GS 35.594 (35.594)	mem 42.219
Train: [89][465/750]	BT 0.031 (1.189)	DT 0.002 (1.145)	loss nan (nan)	prob nan (nan)	GS 24.312 (24.312)	mem 42.336
Train: [89][470/750]	BT 0.046 (1.177)	DT 0.009 (1.133)	loss nan (nan)	prob nan (nan)	GS 34.344 (34.344)	mem 42.187
Train: [89][475/750]	BT 0.031 (1.181)	DT 0.001 (1.137)	loss nan (nan)	prob nan (nan)	GS 31.469 (31.469)	mem 42.190
Train: [89][480/750]	BT 0.035 (1.172)	DT 0.001 (1.128)	loss nan (nan)	prob nan (nan)	GS 33.328 (33.328)	mem 42.226
Train: [89][485/750]	BT 0.050 (1.168)	DT 0.010 (1.124)	loss nan (nan)	prob nan (nan)	GS 31.719 (31.719)	mem 42.317
Train: [89][490/750]	BT 0.040 (1.185)	DT 0.015 (1.141)	loss nan (nan)	prob nan (nan)	GS 34.750 (34.750)	mem 42.112
Train: [89][495/750]	BT 0.032 (1.174)	DT 0.001 (1.130)	loss nan (nan)	prob nan (nan)	GS 37.047 (37.047)	mem 42.050
Train: [89][500/750]	BT 0.024 (1.187)	DT 0.001 (1.143)	loss nan (nan)	prob nan (nan)	GS 31.891 (31.891)	mem 42.105
Train: [89][505/750]	BT 0.027 (1.176)	DT 0.003 (1.132)	loss nan (nan)	prob nan (nan)	GS 28.672 (28.672)	mem 42.105
Train: [89][510/750]	BT 13.264 (1.190)	DT 13.227 (1.146)	loss nan (nan)	prob nan (nan)	GS 35.875 (35.875)	mem 42.346
Train: [89][515/750]	BT 0.023 (1.179)	DT 0.001 (1.135)	loss nan (nan)	prob nan (nan)	GS 27.984 (27.984)	mem 42.214
Train: [89][520/750]	BT 0.036 (1.168)	DT 0.002 (1.124)	loss nan (nan)	prob nan (nan)	GS 33.781 (33.781)	mem 42.214
Train: [89][525/750]	BT 0.049 (1.179)	DT 0.017 (1.135)	loss nan (nan)	prob nan (nan)	GS 27.812 (27.812)	mem 42.248
Train: [89][530/750]	BT 0.032 (1.168)	DT 0.001 (1.125)	loss nan (nan)	prob nan (nan)	GS 31.438 (31.438)	mem 42.248
Train: [89][535/750]	BT 0.030 (1.179)	DT 0.001 (1.135)	loss nan (nan)	prob nan (nan)	GS 34.031 (34.031)	mem 42.264
Train: [89][540/750]	BT 0.035 (1.168)	DT 0.001 (1.125)	loss nan (nan)	prob nan (nan)	GS 37.125 (37.125)	mem 42.264
Train: [89][545/750]	BT 0.058 (1.159)	DT 0.022 (1.116)	loss nan (nan)	prob nan (nan)	GS 30.781 (30.781)	mem 42.307
Train: [89][550/750]	BT 0.024 (1.177)	DT 0.001 (1.134)	loss nan (nan)	prob nan (nan)	GS 34.719 (34.719)	mem 42.273
Train: [89][555/750]	BT 0.026 (1.167)	DT 0.003 (1.123)	loss nan (nan)	prob nan (nan)	GS 29.109 (29.109)	mem 42.273
Train: [89][560/750]	BT 0.032 (1.179)	DT 0.001 (1.136)	loss nan (nan)	prob nan (nan)	GS 34.453 (34.453)	mem 42.282
Train: [89][565/750]	BT 0.040 (1.169)	DT 0.004 (1.126)	loss nan (nan)	prob nan (nan)	GS 43.062 (43.062)	mem 42.338
Train: [89][570/750]	BT 11.568 (1.180)	DT 11.535 (1.136)	loss nan (nan)	prob nan (nan)	GS 31.172 (31.172)	mem 42.335
Train: [89][575/750]	BT 0.107 (1.170)	DT 0.026 (1.126)	loss nan (nan)	prob nan (nan)	GS 26.297 (26.297)	mem 42.332
Train: [89][580/750]	BT 1.151 (1.162)	DT 1.119 (1.119)	loss nan (nan)	prob nan (nan)	GS 34.750 (34.750)	mem 42.275
Train: [89][585/750]	BT 0.034 (1.178)	DT 0.002 (1.135)	loss nan (nan)	prob nan (nan)	GS 30.031 (30.031)	mem 42.363
Train: [89][590/750]	BT 0.067 (1.169)	DT 0.003 (1.125)	loss nan (nan)	prob nan (nan)	GS 31.891 (31.891)	mem 42.257
Train: [89][595/750]	BT 0.047 (1.173)	DT 0.008 (1.130)	loss nan (nan)	prob nan (nan)	GS 32.250 (32.250)	mem 42.315
Train: [89][600/750]	BT 0.106 (1.171)	DT 0.003 (1.127)	loss nan (nan)	prob nan (nan)	GS 33.328 (33.328)	mem 42.272
Train: [89][605/750]	BT 0.024 (1.162)	DT 0.001 (1.118)	loss nan (nan)	prob nan (nan)	GS 29.000 (29.000)	mem 42.201
Train: [89][610/750]	BT 0.049 (1.168)	DT 0.001 (1.125)	loss nan (nan)	prob nan (nan)	GS 35.188 (35.188)	mem 42.367
Train: [89][615/750]	BT 0.104 (1.159)	DT 0.018 (1.116)	loss nan (nan)	prob nan (nan)	GS 30.797 (30.797)	mem 42.323
Train: [89][620/750]	BT 2.909 (1.175)	DT 2.876 (1.131)	loss nan (nan)	prob nan (nan)	GS 34.391 (34.391)	mem 42.280
Train: [89][625/750]	BT 0.064 (1.166)	DT 0.011 (1.122)	loss nan (nan)	prob nan (nan)	GS 31.641 (31.641)	mem 42.280
Train: [89][630/750]	BT 10.626 (1.175)	DT 10.578 (1.131)	loss nan (nan)	prob nan (nan)	GS 34.641 (34.641)	mem 42.263
Train: [89][635/750]	BT 0.067 (1.172)	DT 0.013 (1.128)	loss nan (nan)	prob nan (nan)	GS 42.203 (42.203)	mem 42.222
Train: [89][640/750]	BT 0.043 (1.163)	DT 0.001 (1.120)	loss nan (nan)	prob nan (nan)	GS 33.094 (33.094)	mem 42.223
Train: [89][645/750]	BT 0.033 (1.178)	DT 0.002 (1.135)	loss nan (nan)	prob nan (nan)	GS 32.922 (32.922)	mem 42.103
Train: [89][650/750]	BT 0.051 (1.169)	DT 0.001 (1.126)	loss nan (nan)	prob nan (nan)	GS 35.312 (35.312)	mem 42.104
Train: [89][655/750]	BT 0.112 (1.162)	DT 0.013 (1.119)	loss nan (nan)	prob nan (nan)	GS 30.562 (30.562)	mem 42.130
Train: [89][660/750]	BT 0.042 (1.168)	DT 0.005 (1.124)	loss nan (nan)	prob nan (nan)	GS 34.266 (34.266)	mem 42.166
Train: [89][665/750]	BT 0.029 (1.165)	DT 0.005 (1.121)	loss nan (nan)	prob nan (nan)	GS 31.219 (31.219)	mem 42.107
Train: [89][670/750]	BT 0.052 (1.171)	DT 0.005 (1.128)	loss nan (nan)	prob nan (nan)	GS 34.312 (34.312)	mem 42.196
Train: [89][675/750]	BT 0.082 (1.163)	DT 0.023 (1.120)	loss nan (nan)	prob nan (nan)	GS 31.516 (31.516)	mem 42.179
Train: [89][680/750]	BT 11.117 (1.175)	DT 11.075 (1.131)	loss nan (nan)	prob nan (nan)	GS 31.500 (31.500)	mem 42.440
Train: [89][685/750]	BT 0.064 (1.167)	DT 0.001 (1.123)	loss nan (nan)	prob nan (nan)	GS 28.500 (28.500)	mem 42.335
Train: [89][690/750]	BT 2.195 (1.165)	DT 2.156 (1.121)	loss nan (nan)	prob nan (nan)	GS 35.547 (35.547)	mem 42.094
Train: [89][695/750]	BT 0.031 (1.173)	DT 0.002 (1.129)	loss nan (nan)	prob nan (nan)	GS 34.125 (34.125)	mem 42.274
Train: [89][700/750]	BT 0.049 (1.165)	DT 0.009 (1.121)	loss nan (nan)	prob nan (nan)	GS 30.109 (30.109)	mem 42.238
Train: [89][705/750]	BT 0.030 (1.175)	DT 0.001 (1.131)	loss nan (nan)	prob nan (nan)	GS 30.703 (30.703)	mem 42.181
arpack error, retry= 0
Train: [89][710/750]	BT 0.045 (1.167)	DT 0.002 (1.123)	loss nan (nan)	prob nan (nan)	GS 34.344 (34.344)	mem 42.182
Train: [89][715/750]	BT 0.028 (1.159)	DT 0.001 (1.115)	loss nan (nan)	prob nan (nan)	GS 33.844 (33.844)	mem 42.184
Train: [89][720/750]	BT 0.031 (1.168)	DT 0.001 (1.125)	loss nan (nan)	prob nan (nan)	GS 33.516 (33.516)	mem 42.170
Train: [89][725/750]	BT 0.067 (1.161)	DT 0.012 (1.117)	loss nan (nan)	prob nan (nan)	GS 30.266 (30.266)	mem 42.183
Train: [89][730/750]	BT 0.039 (1.169)	DT 0.001 (1.126)	loss nan (nan)	prob nan (nan)	GS 36.188 (36.188)	mem 41.751
Train: [89][735/750]	BT 0.030 (1.161)	DT 0.002 (1.118)	loss nan (nan)	prob nan (nan)	GS 28.812 (28.812)	mem 41.751
Train: [89][740/750]	BT 6.038 (1.166)	DT 5.993 (1.122)	loss nan (nan)	prob nan (nan)	GS 39.391 (39.391)	mem 9.815
Train: [89][745/750]	BT 0.031 (1.158)	DT 0.002 (1.115)	loss nan (nan)	prob nan (nan)	GS 29.594 (29.594)	mem 9.816
Train: [89][750/750]	BT 0.029 (1.151)	DT 0.001 (1.107)	loss nan (nan)	prob nan (nan)	GS 33.750 (33.750)	mem 9.816
Train: [89][755/750]	BT 0.025 (1.146)	DT 0.001 (1.103)	loss nan (nan)	prob nan (nan)	GS 31.250 (31.250)	mem 9.781
epoch 89, total time 865.61
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [90][1/750]	BT 20.889 (20.889)	DT 20.836 (20.836)	loss nan (nan)	prob nan (nan)	GS 26.328 (26.328)	mem 40.624
Train: [90][5/750]	BT 0.129 (5.837)	DT 0.070 (5.788)	loss nan (nan)	prob nan (nan)	GS 35.078 (35.078)	mem 40.983
Train: [90][10/750]	BT 0.031 (2.946)	DT 0.001 (2.896)	loss nan (nan)	prob nan (nan)	GS 28.266 (28.266)	mem 40.781
Train: [90][15/750]	BT 0.032 (2.887)	DT 0.002 (2.842)	loss nan (nan)	prob nan (nan)	GS 30.984 (30.984)	mem 41.243
Train: [90][20/750]	BT 0.029 (2.174)	DT 0.001 (2.132)	loss nan (nan)	prob nan (nan)	GS 33.359 (33.359)	mem 41.082
Train: [90][25/750]	BT 0.775 (1.778)	DT 0.743 (1.736)	loss nan (nan)	prob nan (nan)	GS 29.828 (29.828)	mem 41.154
Train: [90][30/750]	BT 0.056 (1.883)	DT 0.003 (1.839)	loss nan (nan)	prob nan (nan)	GS 34.844 (34.844)	mem 41.651
Train: [90][35/750]	BT 0.031 (1.623)	DT 0.001 (1.577)	loss nan (nan)	prob nan (nan)	GS 29.109 (29.109)	mem 41.686
Train: [90][40/750]	BT 1.934 (1.812)	DT 1.887 (1.768)	loss nan (nan)	prob nan (nan)	GS 35.812 (35.812)	mem 41.751
Train: [90][45/750]	BT 0.056 (1.615)	DT 0.001 (1.571)	loss nan (nan)	prob nan (nan)	GS 30.562 (30.562)	mem 41.753
Train: [90][50/750]	BT 9.561 (1.648)	DT 9.517 (1.605)	loss nan (nan)	prob nan (nan)	GS 32.688 (32.688)	mem 41.684
Train: [90][55/750]	BT 0.045 (1.523)	DT 0.001 (1.480)	loss nan (nan)	prob nan (nan)	GS 30.984 (30.984)	mem 41.843
Train: [90][60/750]	BT 0.031 (1.402)	DT 0.001 (1.357)	loss nan (nan)	prob nan (nan)	GS 32.578 (32.578)	mem 41.729
Train: [90][65/750]	BT 0.064 (1.480)	DT 0.003 (1.435)	loss nan (nan)	prob nan (nan)	GS 28.422 (28.422)	mem 41.906
Train: [90][70/750]	BT 0.058 (1.377)	DT 0.002 (1.332)	loss nan (nan)	prob nan (nan)	GS 34.781 (34.781)	mem 41.775
Train: [90][75/750]	BT 0.035 (1.459)	DT 0.002 (1.414)	loss nan (nan)	prob nan (nan)	GS 32.469 (32.469)	mem 42.104
Train: [90][80/750]	BT 0.069 (1.371)	DT 0.008 (1.326)	loss nan (nan)	prob nan (nan)	GS 34.000 (34.000)	mem 42.063
Train: [90][85/750]	BT 0.026 (1.343)	DT 0.001 (1.299)	loss nan (nan)	prob nan (nan)	GS 34.750 (34.750)	mem 41.939
Train: [90][90/750]	BT 0.032 (1.370)	DT 0.001 (1.327)	loss nan (nan)	prob nan (nan)	GS 33.000 (33.000)	mem 42.376
Train: [90][95/750]	BT 0.081 (1.319)	DT 0.018 (1.274)	loss nan (nan)	prob nan (nan)	GS 31.953 (31.953)	mem 41.829
Train: [90][100/750]	BT 0.033 (1.368)	DT 0.001 (1.323)	loss nan (nan)	prob nan (nan)	GS 30.609 (30.609)	mem 41.889
Train: [90][105/750]	BT 0.066 (1.305)	DT 0.001 (1.260)	loss nan (nan)	prob nan (nan)	GS 31.891 (31.891)	mem 41.890
Train: [90][110/750]	BT 11.348 (1.372)	DT 11.309 (1.328)	loss nan (nan)	prob nan (nan)	GS 31.562 (31.562)	mem 41.930
Train: [90][115/750]	BT 0.038 (1.315)	DT 0.002 (1.270)	loss nan (nan)	prob nan (nan)	GS 35.078 (35.078)	mem 42.033
Train: [90][120/750]	BT 0.076 (1.262)	DT 0.011 (1.218)	loss nan (nan)	prob nan (nan)	GS 35.328 (35.328)	mem 41.933
Train: [90][125/750]	BT 0.026 (1.327)	DT 0.001 (1.284)	loss nan (nan)	prob nan (nan)	GS 32.453 (32.453)	mem 41.903
Train: [90][130/750]	BT 0.236 (1.279)	DT 0.200 (1.236)	loss nan (nan)	prob nan (nan)	GS 31.969 (31.969)	mem 41.895
Train: [90][135/750]	BT 0.030 (1.324)	DT 0.001 (1.280)	loss nan (nan)	prob nan (nan)	GS 33.453 (33.453)	mem 41.976
Train: [90][140/750]	BT 0.024 (1.278)	DT 0.001 (1.235)	loss nan (nan)	prob nan (nan)	GS 32.906 (32.906)	mem 41.976
Train: [90][145/750]	BT 0.024 (1.252)	DT 0.001 (1.209)	loss nan (nan)	prob nan (nan)	GS 31.281 (31.281)	mem 41.980
Train: [90][150/750]	BT 0.089 (1.278)	DT 0.011 (1.235)	loss nan (nan)	prob nan (nan)	GS 32.578 (32.578)	mem 42.003
Train: [90][155/750]	BT 0.055 (1.262)	DT 0.010 (1.219)	loss nan (nan)	prob nan (nan)	GS 26.875 (26.875)	mem 42.010
Train: [90][160/750]	BT 0.026 (1.285)	DT 0.001 (1.242)	loss nan (nan)	prob nan (nan)	GS 29.922 (29.922)	mem 42.023
Train: [90][165/750]	BT 0.132 (1.248)	DT 0.011 (1.205)	loss nan (nan)	prob nan (nan)	GS 30.688 (30.688)	mem 42.022
Train: [90][170/750]	BT 10.483 (1.289)	DT 10.437 (1.246)	loss nan (nan)	prob nan (nan)	GS 34.547 (34.547)	mem 42.068
Train: [90][175/750]	BT 0.032 (1.254)	DT 0.001 (1.211)	loss nan (nan)	prob nan (nan)	GS 31.125 (31.125)	mem 42.105
Train: [90][180/750]	BT 0.039 (1.240)	DT 0.016 (1.197)	loss nan (nan)	prob nan (nan)	GS 34.609 (34.609)	mem 42.017
Train: [90][185/750]	BT 0.044 (1.263)	DT 0.004 (1.219)	loss nan (nan)	prob nan (nan)	GS 29.828 (29.828)	mem 42.430
Train: [90][190/750]	BT 2.239 (1.242)	DT 2.192 (1.199)	loss nan (nan)	prob nan (nan)	GS 35.438 (35.438)	mem 42.079
Train: [90][195/750]	BT 0.027 (1.278)	DT 0.001 (1.235)	loss nan (nan)	prob nan (nan)	GS 28.797 (28.797)	mem 42.070
Train: [90][200/750]	BT 0.050 (1.247)	DT 0.001 (1.204)	loss nan (nan)	prob nan (nan)	GS 37.000 (37.000)	mem 42.069
Train: [90][205/750]	BT 0.056 (1.218)	DT 0.004 (1.175)	loss nan (nan)	prob nan (nan)	GS 29.141 (29.141)	mem 42.176
Train: [90][210/750]	BT 0.039 (1.247)	DT 0.003 (1.205)	loss nan (nan)	prob nan (nan)	GS 38.438 (38.438)	mem 42.189
Train: [90][215/750]	BT 0.079 (1.243)	DT 0.008 (1.200)	loss nan (nan)	prob nan (nan)	GS 29.062 (29.062)	mem 42.119
Train: [90][220/750]	BT 0.047 (1.246)	DT 0.001 (1.203)	loss nan (nan)	prob nan (nan)	GS 35.547 (35.547)	mem 42.064
Train: [90][225/750]	BT 0.039 (1.219)	DT 0.005 (1.176)	loss nan (nan)	prob nan (nan)	GS 29.828 (29.828)	mem 42.065
Train: [90][230/750]	BT 8.130 (1.244)	DT 8.098 (1.201)	loss nan (nan)	prob nan (nan)	GS 35.250 (35.250)	mem 42.208
Train: [90][235/750]	BT 0.033 (1.219)	DT 0.002 (1.176)	loss nan (nan)	prob nan (nan)	GS 30.500 (30.500)	mem 42.073
Train: [90][240/750]	BT 0.027 (1.229)	DT 0.001 (1.186)	loss nan (nan)	prob nan (nan)	GS 36.156 (36.156)	mem 42.024
Train: [90][245/750]	BT 0.025 (1.213)	DT 0.001 (1.170)	loss nan (nan)	prob nan (nan)	GS 31.344 (31.344)	mem 42.018
Train: [90][250/750]	BT 12.841 (1.241)	DT 12.812 (1.198)	loss nan (nan)	prob nan (nan)	GS 34.141 (34.141)	mem 42.065
Train: [90][255/750]	BT 0.079 (1.219)	DT 0.001 (1.176)	loss nan (nan)	prob nan (nan)	GS 27.844 (27.844)	mem 42.068
Train: [90][260/750]	BT 0.075 (1.197)	DT 0.015 (1.153)	loss nan (nan)	prob nan (nan)	GS 30.547 (30.547)	mem 42.151
Train: [90][265/750]	BT 0.025 (1.221)	DT 0.001 (1.177)	loss nan (nan)	prob nan (nan)	GS 32.812 (32.812)	mem 42.118
Train: [90][270/750]	BT 0.022 (1.200)	DT 0.001 (1.157)	loss nan (nan)	prob nan (nan)	GS 34.625 (34.625)	mem 42.066
Train: [90][275/750]	BT 0.060 (1.220)	DT 0.001 (1.177)	loss nan (nan)	prob nan (nan)	GS 32.297 (32.297)	mem 42.119
Train: [90][280/750]	BT 0.031 (1.204)	DT 0.001 (1.161)	loss nan (nan)	prob nan (nan)	GS 37.938 (37.938)	mem 42.061
Train: [90][285/750]	BT 0.064 (1.184)	DT 0.017 (1.141)	loss nan (nan)	prob nan (nan)	GS 33.297 (33.297)	mem 42.065
Train: [90][290/750]	BT 4.690 (1.217)	DT 4.658 (1.173)	loss nan (nan)	prob nan (nan)	GS 36.250 (36.250)	mem 42.180
Train: [90][295/750]	BT 0.029 (1.204)	DT 0.001 (1.160)	loss nan (nan)	prob nan (nan)	GS 31.172 (31.172)	mem 42.023
Train: [90][300/750]	BT 0.054 (1.200)	DT 0.004 (1.156)	loss nan (nan)	prob nan (nan)	GS 37.578 (37.578)	mem 42.133
Train: [90][305/750]	BT 0.033 (1.214)	DT 0.002 (1.170)	loss nan (nan)	prob nan (nan)	GS 33.906 (33.906)	mem 42.152
Train: [90][310/750]	BT 0.055 (1.196)	DT 0.012 (1.151)	loss nan (nan)	prob nan (nan)	GS 30.359 (30.359)	mem 42.242
Train: [90][315/750]	BT 0.052 (1.201)	DT 0.003 (1.156)	loss nan (nan)	prob nan (nan)	GS 28.516 (28.516)	mem 42.179
Train: [90][320/750]	BT 0.127 (1.207)	DT 0.038 (1.162)	loss nan (nan)	prob nan (nan)	GS 34.531 (34.531)	mem 42.237
Train: [90][325/750]	BT 0.037 (1.189)	DT 0.005 (1.144)	loss nan (nan)	prob nan (nan)	GS 28.234 (28.234)	mem 42.382
Train: [90][330/750]	BT 0.036 (1.215)	DT 0.001 (1.170)	loss nan (nan)	prob nan (nan)	GS 34.406 (34.406)	mem 42.175
Train: [90][335/750]	BT 0.048 (1.197)	DT 0.015 (1.153)	loss nan (nan)	prob nan (nan)	GS 28.172 (28.172)	mem 42.102
Train: [90][340/750]	BT 1.808 (1.212)	DT 1.767 (1.168)	loss nan (nan)	prob nan (nan)	GS 29.984 (29.984)	mem 42.186
Train: [90][345/750]	BT 0.028 (1.195)	DT 0.002 (1.151)	loss nan (nan)	prob nan (nan)	GS 28.797 (28.797)	mem 42.233
Train: [90][350/750]	BT 10.039 (1.211)	DT 9.995 (1.167)	loss nan (nan)	prob nan (nan)	GS 32.422 (32.422)	mem 42.098
Train: [90][355/750]	BT 0.032 (1.199)	DT 0.001 (1.155)	loss nan (nan)	prob nan (nan)	GS 32.750 (32.750)	mem 42.133
Train: [90][360/750]	BT 1.493 (1.187)	DT 1.452 (1.143)	loss nan (nan)	prob nan (nan)	GS 31.141 (31.141)	mem 42.141
Train: [90][365/750]	BT 0.024 (1.193)	DT 0.001 (1.149)	loss nan (nan)	prob nan (nan)	GS 32.828 (32.828)	mem 42.165
Train: [90][370/750]	BT 2.105 (1.183)	DT 1.997 (1.139)	loss nan (nan)	prob nan (nan)	GS 36.203 (36.203)	mem 42.163
Train: [90][375/750]	BT 0.062 (1.195)	DT 0.002 (1.151)	loss nan (nan)	prob nan (nan)	GS 30.812 (30.812)	mem 42.175
Train: [90][380/750]	BT 0.032 (1.180)	DT 0.001 (1.136)	loss nan (nan)	prob nan (nan)	GS 35.141 (35.141)	mem 42.179
Train: [90][385/750]	BT 0.093 (1.172)	DT 0.017 (1.128)	loss nan (nan)	prob nan (nan)	GS 29.703 (29.703)	mem 42.180
Train: [90][390/750]	BT 0.037 (1.179)	DT 0.001 (1.135)	loss nan (nan)	prob nan (nan)	GS 34.719 (34.719)	mem 42.262
Train: [90][395/750]	BT 0.033 (1.174)	DT 0.002 (1.131)	loss nan (nan)	prob nan (nan)	GS 27.250 (27.250)	mem 42.336
Train: [90][400/750]	BT 0.032 (1.190)	DT 0.001 (1.147)	loss nan (nan)	prob nan (nan)	GS 35.906 (35.906)	mem 42.188
Train: [90][405/750]	BT 0.043 (1.177)	DT 0.002 (1.133)	loss nan (nan)	prob nan (nan)	GS 30.453 (30.453)	mem 42.235
Train: [90][410/750]	BT 11.701 (1.191)	DT 11.663 (1.147)	loss nan (nan)	prob nan (nan)	GS 32.422 (32.422)	mem 42.084
Train: [90][415/750]	BT 0.102 (1.178)	DT 0.018 (1.134)	loss nan (nan)	prob nan (nan)	GS 32.422 (32.422)	mem 42.087
Train: [90][420/750]	BT 0.031 (1.164)	DT 0.001 (1.120)	loss nan (nan)	prob nan (nan)	GS 32.766 (32.766)	mem 42.088
Train: [90][425/750]	BT 0.054 (1.180)	DT 0.002 (1.136)	loss nan (nan)	prob nan (nan)	GS 28.719 (28.719)	mem 42.106
Train: [90][430/750]	BT 0.029 (1.167)	DT 0.001 (1.123)	loss nan (nan)	prob nan (nan)	GS 33.031 (33.031)	mem 42.186
Train: [90][435/750]	BT 0.036 (1.179)	DT 0.001 (1.135)	loss nan (nan)	prob nan (nan)	GS 30.484 (30.484)	mem 42.229
Train: [90][440/750]	BT 0.070 (1.166)	DT 0.006 (1.122)	loss nan (nan)	prob nan (nan)	GS 34.031 (34.031)	mem 42.229
Train: [90][445/750]	BT 0.033 (1.157)	DT 0.002 (1.113)	loss nan (nan)	prob nan (nan)	GS 31.359 (31.359)	mem 42.243
Train: [90][450/750]	BT 0.026 (1.174)	DT 0.001 (1.130)	loss nan (nan)	prob nan (nan)	GS 32.188 (32.188)	mem 42.338
Train: [90][455/750]	BT 0.071 (1.162)	DT 0.012 (1.118)	loss nan (nan)	prob nan (nan)	GS 31.781 (31.781)	mem 42.202
Train: [90][460/750]	BT 0.045 (1.177)	DT 0.010 (1.132)	loss nan (nan)	prob nan (nan)	GS 31.906 (31.906)	mem 42.143
Train: [90][465/750]	BT 0.048 (1.164)	DT 0.003 (1.120)	loss nan (nan)	prob nan (nan)	GS 31.109 (31.109)	mem 42.148
Train: [90][470/750]	BT 11.709 (1.179)	DT 11.676 (1.135)	loss nan (nan)	prob nan (nan)	GS 34.922 (34.922)	mem 42.145
Train: [90][475/750]	BT 0.050 (1.167)	DT 0.001 (1.123)	loss nan (nan)	prob nan (nan)	GS 27.562 (27.562)	mem 42.094
Train: [90][480/750]	BT 2.887 (1.161)	DT 2.855 (1.117)	loss nan (nan)	prob nan (nan)	GS 33.797 (33.797)	mem 42.056
Train: [90][485/750]	BT 0.050 (1.167)	DT 0.001 (1.123)	loss nan (nan)	prob nan (nan)	GS 28.094 (28.094)	mem 42.156
Train: [90][490/750]	BT 0.053 (1.156)	DT 0.002 (1.111)	loss nan (nan)	prob nan (nan)	GS 27.641 (27.641)	mem 42.288
Train: [90][495/750]	BT 0.074 (1.169)	DT 0.001 (1.124)	loss nan (nan)	prob nan (nan)	GS 32.062 (32.062)	mem 42.307
Train: [90][500/750]	BT 0.071 (1.157)	DT 0.001 (1.113)	loss nan (nan)	prob nan (nan)	GS 42.719 (42.719)	mem 42.301
Train: [90][505/750]	BT 0.054 (1.150)	DT 0.002 (1.105)	loss nan (nan)	prob nan (nan)	GS 29.766 (29.766)	mem 42.245
Train: [90][510/750]	BT 0.046 (1.160)	DT 0.005 (1.115)	loss nan (nan)	prob nan (nan)	GS 33.031 (33.031)	mem 41.968
Train: [90][515/750]	BT 0.139 (1.149)	DT 0.008 (1.104)	loss nan (nan)	prob nan (nan)	GS 28.984 (28.984)	mem 42.061
Train: [90][520/750]	BT 0.055 (1.169)	DT 0.001 (1.124)	loss nan (nan)	prob nan (nan)	GS 35.844 (35.844)	mem 42.077
Train: [90][525/750]	BT 0.032 (1.158)	DT 0.001 (1.113)	loss nan (nan)	prob nan (nan)	GS 40.250 (40.250)	mem 42.047
Train: [90][530/750]	BT 14.971 (1.176)	DT 14.940 (1.131)	loss nan (nan)	prob nan (nan)	GS 34.688 (34.688)	mem 42.020
Train: [90][535/750]	BT 0.099 (1.166)	DT 0.023 (1.121)	loss nan (nan)	prob nan (nan)	GS 31.062 (31.062)	mem 42.021
Train: [90][540/750]	BT 0.086 (1.155)	DT 0.033 (1.110)	loss nan (nan)	prob nan (nan)	GS 37.234 (37.234)	mem 42.035
Train: [90][545/750]	BT 0.037 (1.158)	DT 0.001 (1.113)	loss nan (nan)	prob nan (nan)	GS 30.656 (30.656)	mem 42.323
Train: [90][550/750]	BT 0.052 (1.148)	DT 0.014 (1.103)	loss nan (nan)	prob nan (nan)	GS 32.578 (32.578)	mem 42.128
Train: [90][555/750]	BT 0.065 (1.163)	DT 0.005 (1.119)	loss nan (nan)	prob nan (nan)	GS 29.859 (29.859)	mem 42.117
Train: [90][560/750]	BT 0.033 (1.153)	DT 0.001 (1.109)	loss nan (nan)	prob nan (nan)	GS 34.766 (34.766)	mem 42.135
Train: [90][565/750]	BT 0.041 (1.148)	DT 0.009 (1.104)	loss nan (nan)	prob nan (nan)	GS 31.484 (31.484)	mem 42.263
Train: [90][570/750]	BT 0.041 (1.156)	DT 0.002 (1.111)	loss nan (nan)	prob nan (nan)	GS 30.344 (30.344)	mem 42.259
Train: [90][575/750]	BT 0.077 (1.146)	DT 0.005 (1.102)	loss nan (nan)	prob nan (nan)	GS 25.641 (25.641)	mem 42.176
Train: [90][580/750]	BT 0.028 (1.160)	DT 0.001 (1.116)	loss nan (nan)	prob nan (nan)	GS 36.078 (36.078)	mem 42.155
Train: [90][585/750]	BT 0.030 (1.151)	DT 0.001 (1.106)	loss nan (nan)	prob nan (nan)	GS 28.688 (28.688)	mem 42.155
Train: [90][590/750]	BT 12.563 (1.162)	DT 12.536 (1.118)	loss nan (nan)	prob nan (nan)	GS 30.344 (30.344)	mem 42.116
Train: [90][595/750]	BT 0.030 (1.153)	DT 0.001 (1.109)	loss nan (nan)	prob nan (nan)	GS 31.125 (31.125)	mem 42.118
Train: [90][600/750]	BT 0.041 (1.144)	DT 0.010 (1.100)	loss nan (nan)	prob nan (nan)	GS 31.875 (31.875)	mem 42.139
Train: [90][605/750]	BT 0.100 (1.156)	DT 0.011 (1.112)	loss nan (nan)	prob nan (nan)	GS 35.844 (35.844)	mem 42.015
Train: [90][610/750]	BT 0.037 (1.147)	DT 0.004 (1.103)	loss nan (nan)	prob nan (nan)	GS 33.172 (33.172)	mem 41.957
Train: [90][615/750]	BT 0.027 (1.158)	DT 0.002 (1.113)	loss nan (nan)	prob nan (nan)	GS 32.141 (32.141)	mem 42.209
Train: [90][620/750]	BT 2.548 (1.153)	DT 2.509 (1.109)	loss nan (nan)	prob nan (nan)	GS 32.938 (32.938)	mem 42.278
Train: [90][625/750]	BT 0.030 (1.144)	DT 0.001 (1.100)	loss nan (nan)	prob nan (nan)	GS 47.297 (47.297)	mem 42.102
Train: [90][630/750]	BT 0.030 (1.155)	DT 0.001 (1.111)	loss nan (nan)	prob nan (nan)	GS 35.875 (35.875)	mem 42.083
Train: [90][635/750]	BT 0.067 (1.146)	DT 0.018 (1.102)	loss nan (nan)	prob nan (nan)	GS 31.031 (31.031)	mem 42.054
Train: [90][640/750]	BT 0.027 (1.161)	DT 0.001 (1.116)	loss nan (nan)	prob nan (nan)	GS 36.281 (36.281)	mem 42.108
Train: [90][645/750]	BT 0.036 (1.152)	DT 0.002 (1.108)	loss nan (nan)	prob nan (nan)	GS 39.875 (39.875)	mem 42.110
Train: [90][650/750]	BT 11.008 (1.160)	DT 10.946 (1.116)	loss nan (nan)	prob nan (nan)	GS 31.109 (31.109)	mem 42.207
Train: [90][655/750]	BT 0.030 (1.152)	DT 0.001 (1.108)	loss nan (nan)	prob nan (nan)	GS 27.094 (27.094)	mem 42.208
Train: [90][660/750]	BT 0.032 (1.144)	DT 0.001 (1.099)	loss nan (nan)	prob nan (nan)	GS 31.453 (31.453)	mem 42.209
Train: [90][665/750]	BT 0.063 (1.153)	DT 0.013 (1.109)	loss nan (nan)	prob nan (nan)	GS 31.297 (31.297)	mem 42.306
Train: [90][670/750]	BT 0.044 (1.145)	DT 0.001 (1.101)	loss nan (nan)	prob nan (nan)	GS 34.641 (34.641)	mem 42.233
Train: [90][675/750]	BT 0.039 (1.156)	DT 0.001 (1.112)	loss nan (nan)	prob nan (nan)	GS 32.000 (32.000)	mem 42.216
Train: [90][680/750]	BT 0.026 (1.148)	DT 0.001 (1.103)	loss nan (nan)	prob nan (nan)	GS 36.016 (36.016)	mem 42.211
Train: [90][685/750]	BT 0.063 (1.140)	DT 0.002 (1.095)	loss nan (nan)	prob nan (nan)	GS 29.188 (29.188)	mem 42.213
Train: [90][690/750]	BT 0.031 (1.147)	DT 0.001 (1.103)	loss nan (nan)	prob nan (nan)	GS 34.812 (34.812)	mem 42.167
Train: [90][695/750]	BT 0.036 (1.139)	DT 0.005 (1.095)	loss nan (nan)	prob nan (nan)	GS 35.000 (35.000)	mem 42.169
Train: [90][700/750]	BT 0.041 (1.148)	DT 0.002 (1.104)	loss nan (nan)	prob nan (nan)	GS 33.703 (33.703)	mem 42.209
Train: [90][705/750]	BT 0.045 (1.141)	DT 0.005 (1.098)	loss nan (nan)	prob nan (nan)	GS 29.781 (29.781)	mem 42.142
arpack error, retry= 0
Train: [90][710/750]	BT 11.840 (1.151)	DT 11.807 (1.107)	loss nan (nan)	prob nan (nan)	GS 36.109 (36.109)	mem 42.292
Train: [90][715/750]	BT 0.026 (1.143)	DT 0.001 (1.099)	loss nan (nan)	prob nan (nan)	GS 32.594 (32.594)	mem 42.218
Train: [90][720/750]	BT 2.608 (1.139)	DT 2.563 (1.095)	loss nan (nan)	prob nan (nan)	GS 36.500 (36.500)	mem 42.253
Train: [90][725/750]	BT 0.043 (1.151)	DT 0.002 (1.107)	loss nan (nan)	prob nan (nan)	GS 28.641 (28.641)	mem 42.157
Train: [90][730/750]	BT 0.103 (1.144)	DT 0.022 (1.100)	loss nan (nan)	prob nan (nan)	GS 32.156 (32.156)	mem 42.117
Train: [90][735/750]	BT 0.039 (1.149)	DT 0.005 (1.105)	loss nan (nan)	prob nan (nan)	GS 33.031 (33.031)	mem 38.670
Train: [90][740/750]	BT 0.028 (1.142)	DT 0.001 (1.098)	loss nan (nan)	prob nan (nan)	GS 31.828 (31.828)	mem 38.672
Train: [90][745/750]	BT 0.033 (1.134)	DT 0.001 (1.090)	loss nan (nan)	prob nan (nan)	GS 34.969 (34.969)	mem 38.671
Train: [90][750/750]	BT 0.022 (1.129)	DT 0.001 (1.086)	loss nan (nan)	prob nan (nan)	GS 29.469 (29.469)	mem 9.819
Train: [90][755/750]	BT 0.031 (1.122)	DT 0.002 (1.078)	loss nan (nan)	prob nan (nan)	GS 35.719 (35.719)	mem 9.819
epoch 90, total time 847.31
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [91][1/750]	BT 21.465 (21.465)	DT 21.364 (21.364)	loss nan (nan)	prob nan (nan)	GS 32.438 (32.438)	mem 40.747
Train: [91][5/750]	BT 0.060 (5.108)	DT 0.002 (5.044)	loss nan (nan)	prob nan (nan)	GS 36.141 (36.141)	mem 40.898
Train: [91][10/750]	BT 0.090 (2.585)	DT 0.011 (2.524)	loss nan (nan)	prob nan (nan)	GS 34.438 (34.438)	mem 40.897
Train: [91][15/750]	BT 0.034 (2.373)	DT 0.002 (2.318)	loss nan (nan)	prob nan (nan)	GS 29.859 (29.859)	mem 40.974
Train: [91][20/750]	BT 0.025 (2.045)	DT 0.001 (1.996)	loss nan (nan)	prob nan (nan)	GS 34.594 (34.594)	mem 41.203
Train: [91][25/750]	BT 0.055 (1.649)	DT 0.021 (1.599)	loss nan (nan)	prob nan (nan)	GS 31.438 (31.438)	mem 41.273
Train: [91][30/750]	BT 0.051 (1.876)	DT 0.001 (1.824)	loss nan (nan)	prob nan (nan)	GS 30.656 (30.656)	mem 41.374
Train: [91][35/750]	BT 0.033 (1.613)	DT 0.002 (1.564)	loss nan (nan)	prob nan (nan)	GS 32.016 (32.016)	mem 41.206
Train: [91][40/750]	BT 5.633 (1.739)	DT 5.601 (1.690)	loss nan (nan)	prob nan (nan)	GS 36.125 (36.125)	mem 41.206
Train: [91][45/750]	BT 0.021 (1.550)	DT 0.001 (1.503)	loss nan (nan)	prob nan (nan)	GS 35.391 (35.391)	mem 41.163
Train: [91][50/750]	BT 4.987 (1.499)	DT 4.958 (1.452)	loss nan (nan)	prob nan (nan)	GS 33.516 (33.516)	mem 41.207
Train: [91][55/750]	BT 0.027 (1.488)	DT 0.001 (1.442)	loss nan (nan)	prob nan (nan)	GS 31.234 (31.234)	mem 41.249
Train: [91][60/750]	BT 0.023 (1.366)	DT 0.001 (1.322)	loss nan (nan)	prob nan (nan)	GS 32.266 (32.266)	mem 41.249
Train: [91][65/750]	BT 0.034 (1.517)	DT 0.002 (1.473)	loss nan (nan)	prob nan (nan)	GS 31.062 (31.062)	mem 41.363
Train: [91][70/750]	BT 0.057 (1.412)	DT 0.001 (1.368)	loss nan (nan)	prob nan (nan)	GS 32.297 (32.297)	mem 41.292
Train: [91][75/750]	BT 0.049 (1.321)	DT 0.006 (1.277)	loss nan (nan)	prob nan (nan)	GS 30.516 (30.516)	mem 41.298
Train: [91][80/750]	BT 0.087 (1.403)	DT 0.014 (1.358)	loss nan (nan)	prob nan (nan)	GS 36.922 (36.922)	mem 41.296
Train: [91][85/750]	BT 0.033 (1.324)	DT 0.001 (1.279)	loss nan (nan)	prob nan (nan)	GS 29.469 (29.469)	mem 41.327
Train: [91][90/750]	BT 0.057 (1.410)	DT 0.005 (1.364)	loss nan (nan)	prob nan (nan)	GS 34.469 (34.469)	mem 41.378
Train: [91][95/750]	BT 0.076 (1.339)	DT 0.015 (1.293)	loss nan (nan)	prob nan (nan)	GS 32.672 (32.672)	mem 41.313
Train: [91][100/750]	BT 12.691 (1.403)	DT 12.659 (1.356)	loss nan (nan)	prob nan (nan)	GS 36.812 (36.812)	mem 41.388
Train: [91][105/750]	BT 0.065 (1.339)	DT 0.012 (1.292)	loss nan (nan)	prob nan (nan)	GS 28.578 (28.578)	mem 41.654
Train: [91][110/750]	BT 0.987 (1.288)	DT 0.937 (1.242)	loss nan (nan)	prob nan (nan)	GS 31.484 (31.484)	mem 41.294
Train: [91][115/750]	BT 0.039 (1.330)	DT 0.009 (1.284)	loss nan (nan)	prob nan (nan)	GS 31.594 (31.594)	mem 41.374
Train: [91][120/750]	BT 0.048 (1.282)	DT 0.006 (1.237)	loss nan (nan)	prob nan (nan)	GS 34.438 (34.438)	mem 41.377
Train: [91][125/750]	BT 0.078 (1.310)	DT 0.017 (1.265)	loss nan (nan)	prob nan (nan)	GS 27.891 (27.891)	mem 41.479
Train: [91][130/750]	BT 0.034 (1.279)	DT 0.001 (1.234)	loss nan (nan)	prob nan (nan)	GS 37.016 (37.016)	mem 41.487
Train: [91][135/750]	BT 0.075 (1.234)	DT 0.011 (1.188)	loss nan (nan)	prob nan (nan)	GS 32.688 (32.688)	mem 41.865
Train: [91][140/750]	BT 4.843 (1.313)	DT 4.768 (1.267)	loss nan (nan)	prob nan (nan)	GS 36.781 (36.781)	mem 41.408
Train: [91][145/750]	BT 0.117 (1.270)	DT 0.002 (1.223)	loss nan (nan)	prob nan (nan)	GS 33.344 (33.344)	mem 41.501
Train: [91][150/750]	BT 0.026 (1.289)	DT 0.001 (1.243)	loss nan (nan)	prob nan (nan)	GS 31.766 (31.766)	mem 41.539
Train: [91][155/750]	BT 0.056 (1.289)	DT 0.009 (1.243)	loss nan (nan)	prob nan (nan)	GS 30.375 (30.375)	mem 41.564
Train: [91][160/750]	BT 6.915 (1.293)	DT 6.887 (1.248)	loss nan (nan)	prob nan (nan)	GS 28.031 (28.031)	mem 41.533
Train: [91][165/750]	BT 0.035 (1.301)	DT 0.002 (1.256)	loss nan (nan)	prob nan (nan)	GS 25.906 (25.906)	mem 41.568
Train: [91][170/750]	BT 0.068 (1.264)	DT 0.013 (1.219)	loss nan (nan)	prob nan (nan)	GS 34.984 (34.984)	mem 41.572
Train: [91][175/750]	BT 0.045 (1.266)	DT 0.001 (1.221)	loss nan (nan)	prob nan (nan)	GS 36.266 (36.266)	mem 41.637
Train: [91][180/750]	BT 0.034 (1.266)	DT 0.001 (1.221)	loss nan (nan)	prob nan (nan)	GS 35.469 (35.469)	mem 41.704
Train: [91][185/750]	BT 0.086 (1.260)	DT 0.048 (1.216)	loss nan (nan)	prob nan (nan)	GS 30.891 (30.891)	mem 41.737
Train: [91][190/750]	BT 0.037 (1.275)	DT 0.007 (1.230)	loss nan (nan)	prob nan (nan)	GS 33.750 (33.750)	mem 41.654
Train: [91][195/750]	BT 0.031 (1.243)	DT 0.007 (1.199)	loss nan (nan)	prob nan (nan)	GS 29.875 (29.875)	mem 41.656
Train: [91][200/750]	BT 5.056 (1.266)	DT 5.015 (1.222)	loss nan (nan)	prob nan (nan)	GS 30.453 (30.453)	mem 41.888
Train: [91][205/750]	BT 0.060 (1.236)	DT 0.002 (1.192)	loss nan (nan)	prob nan (nan)	GS 31.984 (31.984)	mem 42.136
Train: [91][210/750]	BT 0.063 (1.238)	DT 0.003 (1.193)	loss nan (nan)	prob nan (nan)	GS 33.094 (33.094)	mem 41.885
Train: [91][215/750]	BT 0.053 (1.250)	DT 0.015 (1.206)	loss nan (nan)	prob nan (nan)	GS 28.953 (28.953)	mem 41.826
Train: [91][220/750]	BT 0.477 (1.225)	DT 0.451 (1.181)	loss nan (nan)	prob nan (nan)	GS 31.359 (31.359)	mem 41.833
Train: [91][225/750]	BT 0.049 (1.259)	DT 0.001 (1.215)	loss nan (nan)	prob nan (nan)	GS 28.156 (28.156)	mem 41.803
Train: [91][230/750]	BT 0.052 (1.232)	DT 0.009 (1.188)	loss nan (nan)	prob nan (nan)	GS 32.828 (32.828)	mem 41.832
Train: [91][235/750]	BT 0.081 (1.218)	DT 0.005 (1.174)	loss nan (nan)	prob nan (nan)	GS 29.172 (29.172)	mem 41.892
Train: [91][240/750]	BT 0.028 (1.236)	DT 0.001 (1.192)	loss nan (nan)	prob nan (nan)	GS 30.281 (30.281)	mem 42.027
Train: [91][245/750]	BT 0.068 (1.212)	DT 0.015 (1.168)	loss nan (nan)	prob nan (nan)	GS 32.562 (32.562)	mem 42.213
Train: [91][250/750]	BT 0.030 (1.240)	DT 0.001 (1.197)	loss nan (nan)	prob nan (nan)	GS 31.828 (31.828)	mem 41.925
Train: [91][255/750]	BT 0.037 (1.217)	DT 0.001 (1.173)	loss nan (nan)	prob nan (nan)	GS 28.859 (28.859)	mem 41.925
Train: [91][260/750]	BT 10.964 (1.238)	DT 10.908 (1.194)	loss nan (nan)	prob nan (nan)	GS 36.953 (36.953)	mem 42.095
Train: [91][265/750]	BT 0.052 (1.215)	DT 0.011 (1.172)	loss nan (nan)	prob nan (nan)	GS 36.453 (36.453)	mem 41.916
Train: [91][270/750]	BT 0.897 (1.208)	DT 0.857 (1.165)	loss nan (nan)	prob nan (nan)	GS 34.734 (34.734)	mem 41.920
Train: [91][275/750]	BT 0.053 (1.215)	DT 0.001 (1.172)	loss nan (nan)	prob nan (nan)	GS 31.641 (31.641)	mem 41.865
Train: [91][280/750]	BT 0.059 (1.194)	DT 0.029 (1.151)	loss nan (nan)	prob nan (nan)	GS 32.766 (32.766)	mem 41.864
Train: [91][285/750]	BT 0.021 (1.221)	DT 0.001 (1.178)	loss nan (nan)	prob nan (nan)	GS 28.672 (28.672)	mem 41.928
Train: [91][290/750]	BT 0.031 (1.200)	DT 0.002 (1.157)	loss nan (nan)	prob nan (nan)	GS 37.781 (37.781)	mem 41.928
Train: [91][295/750]	BT 0.027 (1.199)	DT 0.001 (1.156)	loss nan (nan)	prob nan (nan)	GS 29.531 (29.531)	mem 42.141
Train: [91][300/750]	BT 0.031 (1.198)	DT 0.001 (1.156)	loss nan (nan)	prob nan (nan)	GS 34.641 (34.641)	mem 42.082
Train: [91][305/750]	BT 0.071 (1.197)	DT 0.018 (1.154)	loss nan (nan)	prob nan (nan)	GS 32.344 (32.344)	mem 42.116
Train: [91][310/750]	BT 0.040 (1.209)	DT 0.009 (1.166)	loss nan (nan)	prob nan (nan)	GS 38.625 (38.625)	mem 42.070
Train: [91][315/750]	BT 0.043 (1.191)	DT 0.001 (1.147)	loss nan (nan)	prob nan (nan)	GS 30.812 (30.812)	mem 42.070
Train: [91][320/750]	BT 2.597 (1.204)	DT 2.547 (1.161)	loss nan (nan)	prob nan (nan)	GS 32.750 (32.750)	mem 42.163
Train: [91][325/750]	BT 0.031 (1.187)	DT 0.002 (1.143)	loss nan (nan)	prob nan (nan)	GS 33.984 (33.984)	mem 42.123
Train: [91][330/750]	BT 1.906 (1.188)	DT 1.867 (1.144)	loss nan (nan)	prob nan (nan)	GS 31.641 (31.641)	mem 42.214
Train: [91][335/750]	BT 0.035 (1.188)	DT 0.002 (1.144)	loss nan (nan)	prob nan (nan)	GS 29.906 (29.906)	mem 42.075
Train: [91][340/750]	BT 8.969 (1.198)	DT 8.909 (1.154)	loss nan (nan)	prob nan (nan)	GS 31.312 (31.312)	mem 42.043
Train: [91][345/750]	BT 0.070 (1.193)	DT 0.008 (1.149)	loss nan (nan)	prob nan (nan)	GS 30.234 (30.234)	mem 42.143
Train: [91][350/750]	BT 0.034 (1.177)	DT 0.005 (1.133)	loss nan (nan)	prob nan (nan)	GS 31.953 (31.953)	mem 42.091
Train: [91][355/750]	BT 0.030 (1.176)	DT 0.001 (1.132)	loss nan (nan)	prob nan (nan)	GS 31.250 (31.250)	mem 42.117
Train: [91][360/750]	BT 0.048 (1.182)	DT 0.001 (1.138)	loss nan (nan)	prob nan (nan)	GS 32.797 (32.797)	mem 42.329
Train: [91][365/750]	BT 0.035 (1.186)	DT 0.001 (1.142)	loss nan (nan)	prob nan (nan)	GS 29.219 (29.219)	mem 42.175
Train: [91][370/750]	BT 0.036 (1.175)	DT 0.002 (1.131)	loss nan (nan)	prob nan (nan)	GS 35.812 (35.812)	mem 42.117
Train: [91][375/750]	BT 0.043 (1.161)	DT 0.005 (1.116)	loss nan (nan)	prob nan (nan)	GS 26.422 (26.422)	mem 42.142
Train: [91][380/750]	BT 0.425 (1.180)	DT 0.393 (1.136)	loss nan (nan)	prob nan (nan)	GS 35.266 (35.266)	mem 42.102
Train: [91][385/750]	BT 0.052 (1.166)	DT 0.003 (1.121)	loss nan (nan)	prob nan (nan)	GS 30.203 (30.203)	mem 42.237
Train: [91][390/750]	BT 0.032 (1.183)	DT 0.001 (1.139)	loss nan (nan)	prob nan (nan)	GS 33.703 (33.703)	mem 42.066
Train: [91][395/750]	BT 0.033 (1.170)	DT 0.001 (1.126)	loss nan (nan)	prob nan (nan)	GS 30.141 (30.141)	mem 42.133
Train: [91][400/750]	BT 12.301 (1.186)	DT 12.264 (1.142)	loss nan (nan)	prob nan (nan)	GS 35.031 (35.031)	mem 42.260
Train: [91][405/750]	BT 0.058 (1.179)	DT 0.001 (1.135)	loss nan (nan)	prob nan (nan)	GS 35.172 (35.172)	mem 42.184
Train: [91][410/750]	BT 0.028 (1.165)	DT 0.001 (1.121)	loss nan (nan)	prob nan (nan)	GS 29.781 (29.781)	mem 42.190
Train: [91][415/750]	BT 0.044 (1.171)	DT 0.005 (1.127)	loss nan (nan)	prob nan (nan)	GS 28.250 (28.250)	mem 42.131
Train: [91][420/750]	BT 0.025 (1.171)	DT 0.001 (1.128)	loss nan (nan)	prob nan (nan)	GS 31.828 (31.828)	mem 42.061
Train: [91][425/750]	BT 0.068 (1.180)	DT 0.010 (1.136)	loss nan (nan)	prob nan (nan)	GS 31.859 (31.859)	mem 42.065
Train: [91][430/750]	BT 0.032 (1.178)	DT 0.001 (1.134)	loss nan (nan)	prob nan (nan)	GS 32.453 (32.453)	mem 41.961
Train: [91][435/750]	BT 0.041 (1.165)	DT 0.001 (1.121)	loss nan (nan)	prob nan (nan)	GS 33.750 (33.750)	mem 41.972
Train: [91][440/750]	BT 0.029 (1.178)	DT 0.001 (1.134)	loss nan (nan)	prob nan (nan)	GS 31.281 (31.281)	mem 42.413
Train: [91][445/750]	BT 0.028 (1.165)	DT 0.001 (1.122)	loss nan (nan)	prob nan (nan)	GS 32.688 (32.688)	mem 42.133
Train: [91][450/750]	BT 0.044 (1.181)	DT 0.003 (1.137)	loss nan (nan)	prob nan (nan)	GS 33.656 (33.656)	mem 42.142
Train: [91][455/750]	BT 0.036 (1.168)	DT 0.002 (1.125)	loss nan (nan)	prob nan (nan)	GS 27.531 (27.531)	mem 42.261
Train: [91][460/750]	BT 11.618 (1.181)	DT 11.582 (1.138)	loss nan (nan)	prob nan (nan)	GS 32.094 (32.094)	mem 42.122
Train: [91][465/750]	BT 0.022 (1.173)	DT 0.001 (1.130)	loss nan (nan)	prob nan (nan)	GS 49.812 (49.812)	mem 42.124
Train: [91][470/750]	BT 0.059 (1.161)	DT 0.006 (1.118)	loss nan (nan)	prob nan (nan)	GS 33.078 (33.078)	mem 42.153
Train: [91][475/750]	BT 0.028 (1.168)	DT 0.001 (1.125)	loss nan (nan)	prob nan (nan)	GS 31.516 (31.516)	mem 42.204
Train: [91][480/750]	BT 0.031 (1.166)	DT 0.001 (1.123)	loss nan (nan)	prob nan (nan)	GS 32.172 (32.172)	mem 42.153
Train: [91][485/750]	BT 0.042 (1.169)	DT 0.002 (1.126)	loss nan (nan)	prob nan (nan)	GS 32.469 (32.469)	mem 42.240
Train: [91][490/750]	BT 0.023 (1.175)	DT 0.001 (1.132)	loss nan (nan)	prob nan (nan)	GS 32.625 (32.625)	mem 42.220
Train: [91][495/750]	BT 0.056 (1.164)	DT 0.005 (1.121)	loss nan (nan)	prob nan (nan)	GS 27.797 (27.797)	mem 42.220
Train: [91][500/750]	BT 8.458 (1.174)	DT 8.417 (1.131)	loss nan (nan)	prob nan (nan)	GS 32.891 (32.891)	mem 42.201
Train: [91][505/750]	BT 0.032 (1.163)	DT 0.002 (1.120)	loss nan (nan)	prob nan (nan)	GS 34.688 (34.688)	mem 42.203
Train: [91][510/750]	BT 0.031 (1.159)	DT 0.001 (1.115)	loss nan (nan)	prob nan (nan)	GS 34.234 (34.234)	mem 42.161
Train: [91][515/750]	BT 0.058 (1.166)	DT 0.017 (1.123)	loss nan (nan)	prob nan (nan)	GS 28.797 (28.797)	mem 42.326
Train: [91][520/750]	BT 2.955 (1.161)	DT 2.907 (1.118)	loss nan (nan)	prob nan (nan)	GS 32.031 (32.031)	mem 42.265
Train: [91][525/750]	BT 0.035 (1.171)	DT 0.002 (1.127)	loss nan (nan)	prob nan (nan)	GS 33.531 (33.531)	mem 42.187
Train: [91][530/750]	BT 0.029 (1.160)	DT 0.001 (1.117)	loss nan (nan)	prob nan (nan)	GS 33.297 (33.297)	mem 42.188
Train: [91][535/750]	BT 0.049 (1.161)	DT 0.012 (1.118)	loss nan (nan)	prob nan (nan)	GS 29.500 (29.500)	mem 42.185
Train: [91][540/750]	BT 0.033 (1.155)	DT 0.001 (1.111)	loss nan (nan)	prob nan (nan)	GS 40.250 (40.250)	mem 42.203
Train: [91][545/750]	BT 0.031 (1.166)	DT 0.002 (1.122)	loss nan (nan)	prob nan (nan)	GS 28.328 (28.328)	mem 42.225
Train: [91][550/750]	BT 0.035 (1.156)	DT 0.001 (1.112)	loss nan (nan)	prob nan (nan)	GS 32.422 (32.422)	mem 42.226
Train: [91][555/750]	BT 0.160 (1.146)	DT 0.010 (1.102)	loss nan (nan)	prob nan (nan)	GS 34.484 (34.484)	mem 42.227
Train: [91][560/750]	BT 0.921 (1.158)	DT 0.886 (1.115)	loss nan (nan)	prob nan (nan)	GS 34.625 (34.625)	mem 42.201
Train: [91][565/750]	BT 0.032 (1.149)	DT 0.001 (1.105)	loss nan (nan)	prob nan (nan)	GS 32.984 (32.984)	mem 42.201
Train: [91][570/750]	BT 0.028 (1.157)	DT 0.001 (1.113)	loss nan (nan)	prob nan (nan)	GS 36.453 (36.453)	mem 42.252
Train: [91][575/750]	BT 0.025 (1.148)	DT 0.001 (1.104)	loss nan (nan)	prob nan (nan)	GS 31.875 (31.875)	mem 42.192
Train: [91][580/750]	BT 13.268 (1.161)	DT 13.237 (1.118)	loss nan (nan)	prob nan (nan)	GS 35.078 (35.078)	mem 42.235
Train: [91][585/750]	BT 0.033 (1.157)	DT 0.002 (1.114)	loss nan (nan)	prob nan (nan)	GS 29.297 (29.297)	mem 42.289
Train: [91][590/750]	BT 0.039 (1.148)	DT 0.003 (1.104)	loss nan (nan)	prob nan (nan)	GS 33.234 (33.234)	mem 42.346
Train: [91][595/750]	BT 0.038 (1.152)	DT 0.002 (1.108)	loss nan (nan)	prob nan (nan)	GS 30.078 (30.078)	mem 42.495
Train: [91][600/750]	BT 0.048 (1.150)	DT 0.001 (1.106)	loss nan (nan)	prob nan (nan)	GS 33.234 (33.234)	mem 42.270
Train: [91][605/750]	BT 0.041 (1.154)	DT 0.006 (1.111)	loss nan (nan)	prob nan (nan)	GS 29.312 (29.312)	mem 42.205
Train: [91][610/750]	BT 0.047 (1.154)	DT 0.005 (1.111)	loss nan (nan)	prob nan (nan)	GS 30.094 (30.094)	mem 42.270
Train: [91][615/750]	BT 0.082 (1.145)	DT 0.034 (1.102)	loss nan (nan)	prob nan (nan)	GS 35.062 (35.062)	mem 42.228
Train: [91][620/750]	BT 4.058 (1.157)	DT 4.008 (1.114)	loss nan (nan)	prob nan (nan)	GS 39.328 (39.328)	mem 42.262
Train: [91][625/750]	BT 0.096 (1.148)	DT 0.010 (1.105)	loss nan (nan)	prob nan (nan)	GS 31.828 (31.828)	mem 42.447
Train: [91][630/750]	BT 0.150 (1.151)	DT 0.007 (1.108)	loss nan (nan)	prob nan (nan)	GS 34.188 (34.188)	mem 42.449
Train: [91][635/750]	BT 0.037 (1.158)	DT 0.002 (1.114)	loss nan (nan)	prob nan (nan)	GS 34.312 (34.312)	mem 42.304
Train: [91][640/750]	BT 3.956 (1.155)	DT 3.905 (1.112)	loss nan (nan)	prob nan (nan)	GS 36.812 (36.812)	mem 42.310
Train: [91][645/750]	BT 0.030 (1.162)	DT 0.001 (1.119)	loss nan (nan)	prob nan (nan)	GS 31.641 (31.641)	mem 42.368
Train: [91][650/750]	BT 0.058 (1.154)	DT 0.002 (1.110)	loss nan (nan)	prob nan (nan)	GS 31.609 (31.609)	mem 42.324
Train: [91][655/750]	BT 0.040 (1.148)	DT 0.001 (1.104)	loss nan (nan)	prob nan (nan)	GS 32.484 (32.484)	mem 42.265
Train: [91][660/750]	BT 0.044 (1.157)	DT 0.001 (1.113)	loss nan (nan)	prob nan (nan)	GS 35.312 (35.312)	mem 42.439
Train: [91][665/750]	BT 0.067 (1.149)	DT 0.011 (1.106)	loss nan (nan)	prob nan (nan)	GS 32.031 (32.031)	mem 42.245
Train: [91][670/750]	BT 0.025 (1.155)	DT 0.001 (1.111)	loss nan (nan)	prob nan (nan)	GS 31.422 (31.422)	mem 42.294
Train: [91][675/750]	BT 0.032 (1.147)	DT 0.001 (1.103)	loss nan (nan)	prob nan (nan)	GS 29.516 (29.516)	mem 42.297
Train: [91][680/750]	BT 7.769 (1.157)	DT 7.738 (1.113)	loss nan (nan)	prob nan (nan)	GS 33.234 (33.234)	mem 42.275
Train: [91][685/750]	BT 0.082 (1.149)	DT 0.008 (1.105)	loss nan (nan)	prob nan (nan)	GS 27.844 (27.844)	mem 42.275
Train: [91][690/750]	BT 2.503 (1.148)	DT 2.452 (1.104)	loss nan (nan)	prob nan (nan)	GS 32.844 (32.844)	mem 42.353
Train: [91][695/750]	BT 0.038 (1.147)	DT 0.007 (1.104)	loss nan (nan)	prob nan (nan)	GS 28.484 (28.484)	mem 42.444
Train: [91][700/750]	BT 5.435 (1.147)	DT 5.307 (1.103)	loss nan (nan)	prob nan (nan)	GS 35.406 (35.406)	mem 42.290
Train: [91][705/750]	BT 0.032 (1.152)	DT 0.001 (1.108)	loss nan (nan)	prob nan (nan)	GS 32.438 (32.438)	mem 42.266
Train: [91][710/750]	BT 0.031 (1.144)	DT 0.002 (1.100)	loss nan (nan)	prob nan (nan)	GS 29.828 (29.828)	mem 42.349
Train: [91][715/750]	BT 0.069 (1.141)	DT 0.002 (1.098)	loss nan (nan)	prob nan (nan)	GS 32.047 (32.047)	mem 42.324
Train: [91][720/750]	BT 0.049 (1.146)	DT 0.003 (1.102)	loss nan (nan)	prob nan (nan)	GS 34.859 (34.859)	mem 42.501
Train: [91][725/750]	BT 0.053 (1.140)	DT 0.004 (1.096)	loss nan (nan)	prob nan (nan)	GS 34.094 (34.094)	mem 42.258
Train: [91][730/750]	BT 0.037 (1.146)	DT 0.001 (1.103)	loss nan (nan)	prob nan (nan)	GS 36.828 (36.828)	mem 41.968
Train: [91][735/750]	BT 0.053 (1.139)	DT 0.013 (1.095)	loss nan (nan)	prob nan (nan)	GS 30.547 (30.547)	mem 41.970
Train: [91][740/750]	BT 2.697 (1.141)	DT 2.662 (1.098)	loss nan (nan)	prob nan (nan)	GS 35.797 (35.797)	mem 12.900
Train: [91][745/750]	BT 0.026 (1.134)	DT 0.001 (1.090)	loss nan (nan)	prob nan (nan)	GS 27.094 (27.094)	mem 12.865
Train: [91][750/750]	BT 0.032 (1.126)	DT 0.005 (1.083)	loss nan (nan)	prob nan (nan)	GS 29.906 (29.906)	mem 12.865
Train: [91][755/750]	BT 0.021 (1.122)	DT 0.001 (1.078)	loss nan (nan)	prob nan (nan)	GS 30.188 (30.188)	mem 9.876
epoch 91, total time 847.11
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [92][1/750]	BT 22.486 (22.486)	DT 22.372 (22.372)	loss nan (nan)	prob nan (nan)	GS 29.500 (29.500)	mem 40.884
Train: [92][5/750]	BT 0.046 (6.305)	DT 0.015 (6.244)	loss nan (nan)	prob nan (nan)	GS 30.656 (30.656)	mem 41.009
Train: [92][10/750]	BT 0.115 (3.176)	DT 0.008 (3.123)	loss nan (nan)	prob nan (nan)	GS 36.000 (36.000)	mem 41.085
Train: [92][15/750]	BT 0.039 (2.397)	DT 0.002 (2.349)	loss nan (nan)	prob nan (nan)	GS 27.719 (27.719)	mem 41.054
Train: [92][20/750]	BT 0.033 (2.114)	DT 0.001 (2.066)	loss nan (nan)	prob nan (nan)	GS 31.188 (31.188)	mem 41.140
Train: [92][25/750]	BT 1.674 (1.769)	DT 1.614 (1.719)	loss nan (nan)	prob nan (nan)	GS 35.891 (35.891)	mem 41.247
Train: [92][30/750]	BT 0.025 (1.884)	DT 0.001 (1.836)	loss nan (nan)	prob nan (nan)	GS 33.766 (33.766)	mem 41.088
Train: [92][35/750]	BT 0.053 (1.623)	DT 0.009 (1.574)	loss nan (nan)	prob nan (nan)	GS 30.125 (30.125)	mem 41.093
Train: [92][40/750]	BT 6.796 (1.707)	DT 6.747 (1.658)	loss nan (nan)	prob nan (nan)	GS 32.562 (32.562)	mem 41.260
Train: [92][45/750]	BT 0.031 (1.522)	DT 0.001 (1.475)	loss nan (nan)	prob nan (nan)	GS 33.297 (33.297)	mem 41.196
Train: [92][50/750]	BT 8.675 (1.546)	DT 8.620 (1.500)	loss nan (nan)	prob nan (nan)	GS 31.734 (31.734)	mem 41.263
Train: [92][55/750]	BT 0.036 (1.451)	DT 0.002 (1.406)	loss nan (nan)	prob nan (nan)	GS 31.844 (31.844)	mem 41.240
Train: [92][60/750]	BT 0.032 (1.374)	DT 0.001 (1.330)	loss nan (nan)	prob nan (nan)	GS 33.328 (33.328)	mem 41.273
Train: [92][65/750]	BT 0.050 (1.450)	DT 0.002 (1.406)	loss nan (nan)	prob nan (nan)	GS 30.172 (30.172)	mem 41.458
Train: [92][70/750]	BT 1.191 (1.367)	DT 1.157 (1.323)	loss nan (nan)	prob nan (nan)	GS 32.984 (32.984)	mem 41.300
Train: [92][75/750]	BT 0.046 (1.421)	DT 0.018 (1.377)	loss nan (nan)	prob nan (nan)	GS 32.938 (32.938)	mem 41.310
Train: [92][80/750]	BT 0.038 (1.370)	DT 0.001 (1.327)	loss nan (nan)	prob nan (nan)	GS 36.234 (36.234)	mem 41.324
Train: [92][85/750]	BT 0.040 (1.292)	DT 0.001 (1.249)	loss nan (nan)	prob nan (nan)	GS 41.719 (41.719)	mem 41.320
Train: [92][90/750]	BT 3.716 (1.403)	DT 3.679 (1.361)	loss nan (nan)	prob nan (nan)	GS 40.875 (40.875)	mem 41.410
Train: [92][95/750]	BT 0.033 (1.332)	DT 0.001 (1.290)	loss nan (nan)	prob nan (nan)	GS 33.000 (33.000)	mem 41.317
Train: [92][100/750]	BT 0.427 (1.317)	DT 0.396 (1.275)	loss nan (nan)	prob nan (nan)	GS 33.312 (33.312)	mem 41.344
Train: [92][105/750]	BT 0.042 (1.295)	DT 0.001 (1.252)	loss nan (nan)	prob nan (nan)	GS 30.297 (30.297)	mem 41.354
Train: [92][110/750]	BT 11.103 (1.339)	DT 11.070 (1.296)	loss nan (nan)	prob nan (nan)	GS 38.016 (38.016)	mem 41.388
Train: [92][115/750]	BT 0.034 (1.324)	DT 0.001 (1.280)	loss nan (nan)	prob nan (nan)	GS 31.391 (31.391)	mem 41.398
Train: [92][120/750]	BT 0.066 (1.272)	DT 0.015 (1.227)	loss nan (nan)	prob nan (nan)	GS 41.344 (41.344)	mem 41.495
Train: [92][125/750]	BT 0.038 (1.294)	DT 0.001 (1.249)	loss nan (nan)	prob nan (nan)	GS 31.719 (31.719)	mem 41.370
Train: [92][130/750]	BT 0.046 (1.269)	DT 0.002 (1.224)	loss nan (nan)	prob nan (nan)	GS 33.391 (33.391)	mem 41.405
Train: [92][135/750]	BT 0.056 (1.248)	DT 0.015 (1.202)	loss nan (nan)	prob nan (nan)	GS 30.984 (30.984)	mem 41.411
Train: [92][140/750]	BT 0.030 (1.268)	DT 0.001 (1.222)	loss nan (nan)	prob nan (nan)	GS 35.000 (35.000)	mem 41.390
Train: [92][145/750]	BT 0.045 (1.225)	DT 0.002 (1.180)	loss nan (nan)	prob nan (nan)	GS 30.531 (30.531)	mem 41.405
Train: [92][150/750]	BT 4.052 (1.261)	DT 4.010 (1.216)	loss nan (nan)	prob nan (nan)	GS 37.281 (37.281)	mem 41.413
Train: [92][155/750]	BT 0.066 (1.221)	DT 0.007 (1.177)	loss nan (nan)	prob nan (nan)	GS 33.172 (33.172)	mem 41.430
Train: [92][160/750]	BT 0.042 (1.233)	DT 0.001 (1.189)	loss nan (nan)	prob nan (nan)	GS 34.875 (34.875)	mem 41.484
Train: [92][165/750]	BT 0.105 (1.230)	DT 0.002 (1.185)	loss nan (nan)	prob nan (nan)	GS 27.938 (27.938)	mem 41.529
Train: [92][170/750]	BT 6.107 (1.232)	DT 6.033 (1.186)	loss nan (nan)	prob nan (nan)	GS 30.531 (30.531)	mem 41.711
Train: [92][175/750]	BT 0.077 (1.228)	DT 0.005 (1.182)	loss nan (nan)	prob nan (nan)	GS 33.438 (33.438)	mem 41.762
Train: [92][180/750]	BT 0.042 (1.195)	DT 0.001 (1.150)	loss nan (nan)	prob nan (nan)	GS 30.078 (30.078)	mem 41.705
Train: [92][185/750]	BT 0.101 (1.215)	DT 0.006 (1.169)	loss nan (nan)	prob nan (nan)	GS 31.781 (31.781)	mem 41.744
Train: [92][190/750]	BT 0.047 (1.200)	DT 0.001 (1.155)	loss nan (nan)	prob nan (nan)	GS 31.281 (31.281)	mem 41.684
Train: [92][195/750]	BT 0.035 (1.222)	DT 0.001 (1.176)	loss nan (nan)	prob nan (nan)	GS 29.328 (29.328)	mem 41.891
Train: [92][200/750]	BT 0.027 (1.211)	DT 0.001 (1.165)	loss nan (nan)	prob nan (nan)	GS 31.906 (31.906)	mem 41.726
Train: [92][205/750]	BT 0.038 (1.183)	DT 0.001 (1.137)	loss nan (nan)	prob nan (nan)	GS 30.984 (30.984)	mem 41.791
Train: [92][210/750]	BT 3.042 (1.215)	DT 3.004 (1.170)	loss nan (nan)	prob nan (nan)	GS 33.531 (33.531)	mem 41.992
Train: [92][215/750]	BT 0.057 (1.189)	DT 0.009 (1.143)	loss nan (nan)	prob nan (nan)	GS 29.062 (29.062)	mem 41.929
Train: [92][220/750]	BT 0.136 (1.200)	DT 0.040 (1.154)	loss nan (nan)	prob nan (nan)	GS 35.594 (35.594)	mem 41.846
Train: [92][225/750]	BT 0.031 (1.175)	DT 0.001 (1.129)	loss nan (nan)	prob nan (nan)	GS 32.469 (32.469)	mem 41.888
Train: [92][230/750]	BT 12.189 (1.204)	DT 12.148 (1.158)	loss nan (nan)	prob nan (nan)	GS 29.203 (29.203)	mem 41.964
Train: [92][235/750]	BT 0.050 (1.193)	DT 0.012 (1.147)	loss nan (nan)	prob nan (nan)	GS 29.516 (29.516)	mem 41.932
Train: [92][240/750]	BT 0.041 (1.169)	DT 0.003 (1.123)	loss nan (nan)	prob nan (nan)	GS 30.969 (30.969)	mem 41.933
Train: [92][245/750]	BT 0.068 (1.193)	DT 0.002 (1.146)	loss nan (nan)	prob nan (nan)	GS 35.062 (35.062)	mem 42.032
Train: [92][250/750]	BT 0.068 (1.170)	DT 0.008 (1.123)	loss nan (nan)	prob nan (nan)	GS 35.625 (35.625)	mem 42.070
Train: [92][255/750]	BT 0.036 (1.189)	DT 0.001 (1.143)	loss nan (nan)	prob nan (nan)	GS 28.062 (28.062)	mem 42.090
Train: [92][260/750]	BT 0.215 (1.179)	DT 0.006 (1.132)	loss nan (nan)	prob nan (nan)	GS 34.812 (34.812)	mem 42.498
Train: [92][265/750]	BT 0.133 (1.158)	DT 0.020 (1.111)	loss nan (nan)	prob nan (nan)	GS 35.641 (35.641)	mem 42.539
Train: [92][270/750]	BT 2.888 (1.190)	DT 2.855 (1.142)	loss nan (nan)	prob nan (nan)	GS 33.750 (33.750)	mem 42.092
Train: [92][275/750]	BT 0.034 (1.169)	DT 0.001 (1.122)	loss nan (nan)	prob nan (nan)	GS 31.422 (31.422)	mem 42.197
Train: [92][280/750]	BT 3.812 (1.183)	DT 3.781 (1.136)	loss nan (nan)	prob nan (nan)	GS 36.516 (36.516)	mem 42.131
Train: [92][285/750]	BT 0.039 (1.167)	DT 0.012 (1.120)	loss nan (nan)	prob nan (nan)	GS 31.562 (31.562)	mem 42.112
Train: [92][290/750]	BT 7.839 (1.175)	DT 7.814 (1.128)	loss nan (nan)	prob nan (nan)	GS 35.797 (35.797)	mem 42.047
Train: [92][295/750]	BT 0.037 (1.179)	DT 0.002 (1.133)	loss nan (nan)	prob nan (nan)	GS 29.188 (29.188)	mem 42.038
Train: [92][300/750]	BT 0.031 (1.161)	DT 0.001 (1.114)	loss nan (nan)	prob nan (nan)	GS 34.969 (34.969)	mem 42.037
Train: [92][305/750]	BT 0.073 (1.181)	DT 0.021 (1.134)	loss nan (nan)	prob nan (nan)	GS 32.516 (32.516)	mem 41.949
Train: [92][310/750]	BT 0.096 (1.180)	DT 0.019 (1.133)	loss nan (nan)	prob nan (nan)	GS 36.625 (36.625)	mem 42.044
Train: [92][315/750]	BT 0.124 (1.180)	DT 0.037 (1.132)	loss nan (nan)	prob nan (nan)	GS 28.625 (28.625)	mem 42.094
Train: [92][320/750]	BT 0.047 (1.186)	DT 0.015 (1.138)	loss nan (nan)	prob nan (nan)	GS 31.844 (31.844)	mem 42.186
Train: [92][325/750]	BT 0.034 (1.169)	DT 0.005 (1.121)	loss nan (nan)	prob nan (nan)	GS 32.641 (32.641)	mem 42.014
Train: [92][330/750]	BT 3.705 (1.196)	DT 3.671 (1.148)	loss nan (nan)	prob nan (nan)	GS 32.312 (32.312)	mem 42.173
Train: [92][335/750]	BT 0.043 (1.179)	DT 0.001 (1.131)	loss nan (nan)	prob nan (nan)	GS 36.531 (36.531)	mem 42.174
Train: [92][340/750]	BT 3.862 (1.178)	DT 3.798 (1.130)	loss nan (nan)	prob nan (nan)	GS 32.625 (32.625)	mem 42.112
Train: [92][345/750]	BT 0.032 (1.183)	DT 0.001 (1.135)	loss nan (nan)	prob nan (nan)	GS 31.391 (31.391)	mem 42.405
Train: [92][350/750]	BT 2.489 (1.174)	DT 2.412 (1.126)	loss nan (nan)	prob nan (nan)	GS 27.531 (27.531)	mem 42.152
Train: [92][355/750]	BT 0.049 (1.181)	DT 0.013 (1.133)	loss nan (nan)	prob nan (nan)	GS 34.172 (34.172)	mem 42.133
Train: [92][360/750]	BT 0.023 (1.165)	DT 0.001 (1.117)	loss nan (nan)	prob nan (nan)	GS 35.016 (35.016)	mem 42.136
Train: [92][365/750]	BT 0.048 (1.178)	DT 0.009 (1.131)	loss nan (nan)	prob nan (nan)	GS 36.781 (36.781)	mem 42.179
Train: [92][370/750]	BT 0.035 (1.163)	DT 0.004 (1.116)	loss nan (nan)	prob nan (nan)	GS 37.938 (37.938)	mem 42.114
Train: [92][375/750]	BT 0.022 (1.185)	DT 0.001 (1.137)	loss nan (nan)	prob nan (nan)	GS 31.234 (31.234)	mem 42.135
Train: [92][380/750]	BT 0.024 (1.169)	DT 0.001 (1.122)	loss nan (nan)	prob nan (nan)	GS 37.281 (37.281)	mem 42.135
Train: [92][385/750]	BT 0.057 (1.155)	DT 0.001 (1.108)	loss nan (nan)	prob nan (nan)	GS 46.750 (46.750)	mem 42.144
Train: [92][390/750]	BT 0.024 (1.176)	DT 0.001 (1.129)	loss nan (nan)	prob nan (nan)	GS 33.484 (33.484)	mem 42.093
Train: [92][395/750]	BT 0.098 (1.162)	DT 0.009 (1.115)	loss nan (nan)	prob nan (nan)	GS 33.703 (33.703)	mem 42.095
Train: [92][400/750]	BT 0.089 (1.177)	DT 0.003 (1.130)	loss nan (nan)	prob nan (nan)	GS 37.078 (37.078)	mem 42.093
Train: [92][405/750]	BT 0.032 (1.163)	DT 0.001 (1.116)	loss nan (nan)	prob nan (nan)	GS 30.016 (30.016)	mem 42.104
Train: [92][410/750]	BT 12.155 (1.180)	DT 12.122 (1.132)	loss nan (nan)	prob nan (nan)	GS 35.875 (35.875)	mem 42.217
Train: [92][415/750]	BT 0.031 (1.166)	DT 0.001 (1.119)	loss nan (nan)	prob nan (nan)	GS 35.750 (35.750)	mem 42.114
Train: [92][420/750]	BT 0.044 (1.153)	DT 0.001 (1.106)	loss nan (nan)	prob nan (nan)	GS 30.828 (30.828)	mem 42.116
Train: [92][425/750]	BT 0.043 (1.171)	DT 0.002 (1.124)	loss nan (nan)	prob nan (nan)	GS 30.141 (30.141)	mem 42.174
Train: [92][430/750]	BT 0.037 (1.158)	DT 0.001 (1.111)	loss nan (nan)	prob nan (nan)	GS 31.047 (31.047)	mem 42.124
Train: [92][435/750]	BT 0.063 (1.170)	DT 0.012 (1.123)	loss nan (nan)	prob nan (nan)	GS 34.344 (34.344)	mem 42.210
Train: [92][440/750]	BT 0.031 (1.159)	DT 0.001 (1.112)	loss nan (nan)	prob nan (nan)	GS 35.906 (35.906)	mem 42.274
Train: [92][445/750]	BT 0.092 (1.148)	DT 0.012 (1.101)	loss nan (nan)	prob nan (nan)	GS 38.422 (38.422)	mem 42.219
Train: [92][450/750]	BT 0.250 (1.163)	DT 0.219 (1.116)	loss nan (nan)	prob nan (nan)	GS 28.781 (28.781)	mem 42.194
Train: [92][455/750]	BT 0.082 (1.151)	DT 0.010 (1.104)	loss nan (nan)	prob nan (nan)	GS 30.828 (30.828)	mem 42.218
Train: [92][460/750]	BT 0.032 (1.159)	DT 0.001 (1.112)	loss nan (nan)	prob nan (nan)	GS 29.078 (29.078)	mem 42.134
Train: [92][465/750]	BT 0.030 (1.154)	DT 0.001 (1.108)	loss nan (nan)	prob nan (nan)	GS 28.578 (28.578)	mem 42.204
Train: [92][470/750]	BT 10.094 (1.164)	DT 10.044 (1.117)	loss nan (nan)	prob nan (nan)	GS 36.266 (36.266)	mem 42.153
Train: [92][475/750]	BT 0.043 (1.155)	DT 0.001 (1.108)	loss nan (nan)	prob nan (nan)	GS 34.750 (34.750)	mem 42.114
Train: [92][480/750]	BT 0.035 (1.143)	DT 0.002 (1.097)	loss nan (nan)	prob nan (nan)	GS 30.781 (30.781)	mem 42.115
Train: [92][485/750]	BT 0.036 (1.153)	DT 0.001 (1.106)	loss nan (nan)	prob nan (nan)	GS 34.062 (34.062)	mem 42.250
Train: [92][490/750]	BT 0.036 (1.145)	DT 0.005 (1.099)	loss nan (nan)	prob nan (nan)	GS 31.078 (31.078)	mem 42.128
Train: [92][495/750]	BT 0.033 (1.159)	DT 0.002 (1.112)	loss nan (nan)	prob nan (nan)	GS 25.641 (25.641)	mem 42.157
Train: [92][500/750]	BT 0.051 (1.148)	DT 0.002 (1.101)	loss nan (nan)	prob nan (nan)	GS 30.859 (30.859)	mem 42.158
Train: [92][505/750]	BT 0.027 (1.137)	DT 0.002 (1.090)	loss nan (nan)	prob nan (nan)	GS 32.812 (32.812)	mem 42.158
Train: [92][510/750]	BT 0.058 (1.151)	DT 0.004 (1.104)	loss nan (nan)	prob nan (nan)	GS 34.141 (34.141)	mem 42.195
Train: [92][515/750]	BT 0.096 (1.140)	DT 0.011 (1.093)	loss nan (nan)	prob nan (nan)	GS 32.422 (32.422)	mem 42.116
Train: [92][520/750]	BT 0.037 (1.165)	DT 0.004 (1.118)	loss nan (nan)	prob nan (nan)	GS 36.062 (36.062)	mem 42.020
Train: [92][525/750]	BT 0.055 (1.154)	DT 0.002 (1.107)	loss nan (nan)	prob nan (nan)	GS 33.812 (33.812)	mem 42.020
Train: [92][530/750]	BT 11.871 (1.166)	DT 11.846 (1.119)	loss nan (nan)	prob nan (nan)	GS 35.312 (35.312)	mem 42.179
Train: [92][535/750]	BT 0.051 (1.155)	DT 0.012 (1.109)	loss nan (nan)	prob nan (nan)	GS 36.781 (36.781)	mem 42.253
Train: [92][540/750]	BT 1.681 (1.148)	DT 1.631 (1.101)	loss nan (nan)	prob nan (nan)	GS 31.094 (31.094)	mem 42.171
Train: [92][545/750]	BT 0.028 (1.159)	DT 0.001 (1.113)	loss nan (nan)	prob nan (nan)	GS 33.062 (33.062)	mem 42.186
Train: [92][550/750]	BT 0.046 (1.149)	DT 0.006 (1.103)	loss nan (nan)	prob nan (nan)	GS 32.922 (32.922)	mem 42.186
Train: [92][555/750]	BT 0.074 (1.158)	DT 0.002 (1.112)	loss nan (nan)	prob nan (nan)	GS 34.672 (34.672)	mem 42.192
Train: [92][560/750]	BT 0.053 (1.149)	DT 0.011 (1.102)	loss nan (nan)	prob nan (nan)	GS 36.672 (36.672)	mem 42.154
Train: [92][565/750]	BT 0.121 (1.142)	DT 0.018 (1.095)	loss nan (nan)	prob nan (nan)	GS 28.500 (28.500)	mem 42.184
Train: [92][570/750]	BT 0.056 (1.152)	DT 0.009 (1.105)	loss nan (nan)	prob nan (nan)	GS 38.578 (38.578)	mem 42.103
Train: [92][575/750]	BT 0.054 (1.142)	DT 0.001 (1.096)	loss nan (nan)	prob nan (nan)	GS 30.250 (30.250)	mem 42.104
Train: [92][580/750]	BT 0.040 (1.152)	DT 0.012 (1.106)	loss nan (nan)	prob nan (nan)	GS 31.797 (31.797)	mem 42.249
Train: [92][585/750]	BT 0.042 (1.148)	DT 0.002 (1.101)	loss nan (nan)	prob nan (nan)	GS 35.625 (35.625)	mem 42.189
Train: [92][590/750]	BT 8.512 (1.154)	DT 8.478 (1.108)	loss nan (nan)	prob nan (nan)	GS 36.344 (36.344)	mem 42.319
Train: [92][595/750]	BT 0.065 (1.146)	DT 0.004 (1.100)	loss nan (nan)	prob nan (nan)	GS 32.375 (32.375)	mem 42.301
Train: [92][600/750]	BT 0.047 (1.144)	DT 0.010 (1.098)	loss nan (nan)	prob nan (nan)	GS 33.547 (33.547)	mem 42.147
Train: [92][605/750]	BT 0.044 (1.153)	DT 0.010 (1.107)	loss nan (nan)	prob nan (nan)	GS 29.594 (29.594)	mem 42.224
Train: [92][610/750]	BT 0.032 (1.153)	DT 0.002 (1.107)	loss nan (nan)	prob nan (nan)	GS 33.922 (33.922)	mem 42.146
Train: [92][615/750]	BT 0.057 (1.154)	DT 0.004 (1.108)	loss nan (nan)	prob nan (nan)	GS 29.859 (29.859)	mem 42.038
Train: [92][620/750]	BT 3.056 (1.152)	DT 3.004 (1.106)	loss nan (nan)	prob nan (nan)	GS 33.766 (33.766)	mem 42.279
Train: [92][625/750]	BT 0.059 (1.144)	DT 0.016 (1.098)	loss nan (nan)	prob nan (nan)	GS 25.359 (25.359)	mem 42.056
Train: [92][630/750]	BT 0.472 (1.150)	DT 0.440 (1.104)	loss nan (nan)	prob nan (nan)	GS 30.062 (30.062)	mem 42.119
Train: [92][635/750]	BT 0.037 (1.147)	DT 0.002 (1.101)	loss nan (nan)	prob nan (nan)	GS 26.969 (26.969)	mem 42.149
Train: [92][640/750]	BT 0.037 (1.154)	DT 0.003 (1.109)	loss nan (nan)	prob nan (nan)	GS 33.359 (33.359)	mem 42.167
Train: [92][645/750]	BT 0.036 (1.146)	DT 0.001 (1.100)	loss nan (nan)	prob nan (nan)	GS 33.094 (33.094)	mem 42.204
Train: [92][650/750]	BT 10.972 (1.156)	DT 10.923 (1.110)	loss nan (nan)	prob nan (nan)	GS 33.109 (33.109)	mem 42.169
Train: [92][655/750]	BT 0.031 (1.147)	DT 0.001 (1.101)	loss nan (nan)	prob nan (nan)	GS 32.156 (32.156)	mem 42.169
Train: [92][660/750]	BT 2.390 (1.145)	DT 2.350 (1.099)	loss nan (nan)	prob nan (nan)	GS 32.641 (32.641)	mem 42.309
Train: [92][665/750]	BT 0.073 (1.149)	DT 0.004 (1.103)	loss nan (nan)	prob nan (nan)	GS 26.719 (26.719)	mem 42.061
Train: [92][670/750]	BT 0.053 (1.143)	DT 0.012 (1.098)	loss nan (nan)	prob nan (nan)	GS 32.328 (32.328)	mem 42.073
Train: [92][675/750]	BT 0.049 (1.155)	DT 0.003 (1.110)	loss nan (nan)	prob nan (nan)	GS 31.797 (31.797)	mem 42.159
Train: [92][680/750]	BT 0.044 (1.147)	DT 0.005 (1.101)	loss nan (nan)	prob nan (nan)	GS 33.984 (33.984)	mem 42.128
Train: [92][685/750]	BT 0.073 (1.143)	DT 0.010 (1.097)	loss nan (nan)	prob nan (nan)	GS 28.344 (28.344)	mem 42.370
Train: [92][690/750]	BT 0.022 (1.151)	DT 0.001 (1.105)	loss nan (nan)	prob nan (nan)	GS 31.812 (31.812)	mem 42.146
Train: [92][695/750]	BT 0.049 (1.143)	DT 0.005 (1.097)	loss nan (nan)	prob nan (nan)	GS 29.344 (29.344)	mem 42.223
Train: [92][700/750]	BT 0.075 (1.154)	DT 0.005 (1.108)	loss nan (nan)	prob nan (nan)	GS 35.953 (35.953)	mem 42.032
Train: [92][705/750]	BT 0.036 (1.146)	DT 0.002 (1.100)	loss nan (nan)	prob nan (nan)	GS 30.156 (30.156)	mem 42.033
Train: [92][710/750]	BT 12.243 (1.156)	DT 12.205 (1.110)	loss nan (nan)	prob nan (nan)	GS 34.969 (34.969)	mem 42.124
Train: [92][715/750]	BT 0.069 (1.148)	DT 0.011 (1.102)	loss nan (nan)	prob nan (nan)	GS 28.953 (28.953)	mem 42.146
Train: [92][720/750]	BT 0.044 (1.140)	DT 0.012 (1.094)	loss nan (nan)	prob nan (nan)	GS 35.578 (35.578)	mem 42.146
Train: [92][725/750]	BT 0.053 (1.148)	DT 0.011 (1.102)	loss nan (nan)	prob nan (nan)	GS 36.453 (36.453)	mem 42.057
Train: [92][730/750]	BT 0.126 (1.141)	DT 0.095 (1.095)	loss nan (nan)	prob nan (nan)	GS 34.047 (34.047)	mem 42.058
Train: [92][735/750]	BT 0.039 (1.144)	DT 0.001 (1.098)	loss nan (nan)	prob nan (nan)	GS 32.859 (32.859)	mem 38.814
Train: [92][740/750]	BT 0.533 (1.137)	DT 0.469 (1.091)	loss nan (nan)	prob nan (nan)	GS 35.312 (35.312)	mem 20.650
Train: [92][745/750]	BT 0.028 (1.133)	DT 0.005 (1.087)	loss nan (nan)	prob nan (nan)	GS 31.969 (31.969)	mem 18.715
Train: [92][750/750]	BT 0.032 (1.126)	DT 0.001 (1.080)	loss nan (nan)	prob nan (nan)	GS 35.344 (35.344)	mem 18.766
Train: [92][755/750]	BT 0.042 (1.121)	DT 0.001 (1.076)	loss nan (nan)	prob nan (nan)	GS 33.938 (33.938)	mem 12.797
epoch 92, total time 848.55
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [93][1/750]	BT 21.246 (21.246)	DT 21.166 (21.166)	loss nan (nan)	prob nan (nan)	GS 29.969 (29.969)	mem 40.803
Train: [93][5/750]	BT 0.266 (4.533)	DT 0.224 (4.483)	loss nan (nan)	prob nan (nan)	GS 32.031 (32.031)	mem 41.168
Train: [93][10/750]	BT 0.043 (2.648)	DT 0.001 (2.605)	loss nan (nan)	prob nan (nan)	GS 30.141 (30.141)	mem 40.860
Train: [93][15/750]	BT 0.146 (2.309)	DT 0.020 (2.261)	loss nan (nan)	prob nan (nan)	GS 30.391 (30.391)	mem 40.995
Train: [93][20/750]	BT 0.038 (2.031)	DT 0.013 (1.983)	loss nan (nan)	prob nan (nan)	GS 34.281 (34.281)	mem 41.104
Train: [93][25/750]	BT 0.145 (1.641)	DT 0.042 (1.589)	loss nan (nan)	prob nan (nan)	GS 30.594 (30.594)	mem 41.249
Train: [93][30/750]	BT 5.046 (1.821)	DT 5.008 (1.771)	loss nan (nan)	prob nan (nan)	GS 36.062 (36.062)	mem 41.279
Train: [93][35/750]	BT 0.035 (1.568)	DT 0.001 (1.518)	loss nan (nan)	prob nan (nan)	GS 29.500 (29.500)	mem 41.385
Train: [93][40/750]	BT 0.046 (1.638)	DT 0.004 (1.590)	loss nan (nan)	prob nan (nan)	GS 33.594 (33.594)	mem 41.220
Train: [93][45/750]	BT 0.081 (1.497)	DT 0.003 (1.448)	loss nan (nan)	prob nan (nan)	GS 29.797 (29.797)	mem 41.286
Train: [93][50/750]	BT 8.555 (1.521)	DT 8.521 (1.474)	loss nan (nan)	prob nan (nan)	GS 34.891 (34.891)	mem 41.212
Train: [93][55/750]	BT 0.026 (1.450)	DT 0.001 (1.405)	loss nan (nan)	prob nan (nan)	GS 25.906 (25.906)	mem 41.323
Train: [93][60/750]	BT 0.024 (1.335)	DT 0.001 (1.288)	loss nan (nan)	prob nan (nan)	GS 31.891 (31.891)	mem 41.227
Train: [93][65/750]	BT 0.076 (1.428)	DT 0.002 (1.381)	loss nan (nan)	prob nan (nan)	GS 31.922 (31.922)	mem 41.335
Train: [93][70/750]	BT 0.032 (1.329)	DT 0.001 (1.282)	loss nan (nan)	prob nan (nan)	GS 36.750 (36.750)	mem 41.326
Train: [93][75/750]	BT 0.036 (1.344)	DT 0.003 (1.296)	loss nan (nan)	prob nan (nan)	GS 30.141 (30.141)	mem 41.283
Train: [93][80/750]	BT 0.034 (1.359)	DT 0.002 (1.311)	loss nan (nan)	prob nan (nan)	GS 34.219 (34.219)	mem 41.345
Train: [93][85/750]	BT 0.058 (1.281)	DT 0.002 (1.234)	loss nan (nan)	prob nan (nan)	GS 33.891 (33.891)	mem 41.293
Train: [93][90/750]	BT 0.031 (1.384)	DT 0.001 (1.337)	loss nan (nan)	prob nan (nan)	GS 37.578 (37.578)	mem 41.305
Train: [93][95/750]	BT 0.030 (1.313)	DT 0.002 (1.267)	loss nan (nan)	prob nan (nan)	GS 34.641 (34.641)	mem 41.308
Train: [93][100/750]	BT 12.000 (1.380)	DT 11.968 (1.334)	loss nan (nan)	prob nan (nan)	GS 33.234 (33.234)	mem 41.361
Train: [93][105/750]	BT 0.059 (1.316)	DT 0.001 (1.271)	loss nan (nan)	prob nan (nan)	GS 28.625 (28.625)	mem 41.324
Train: [93][110/750]	BT 0.063 (1.259)	DT 0.007 (1.213)	loss nan (nan)	prob nan (nan)	GS 32.250 (32.250)	mem 41.329
Train: [93][115/750]	BT 0.042 (1.324)	DT 0.002 (1.278)	loss nan (nan)	prob nan (nan)	GS 31.328 (31.328)	mem 41.481
Train: [93][120/750]	BT 4.238 (1.306)	DT 4.188 (1.260)	loss nan (nan)	prob nan (nan)	GS 34.953 (34.953)	mem 41.446
Train: [93][125/750]	BT 0.053 (1.306)	DT 0.007 (1.260)	loss nan (nan)	prob nan (nan)	GS 27.344 (27.344)	mem 41.646
Train: [93][130/750]	BT 0.032 (1.267)	DT 0.001 (1.221)	loss nan (nan)	prob nan (nan)	GS 33.906 (33.906)	mem 41.671
Train: [93][135/750]	BT 0.038 (1.250)	DT 0.001 (1.204)	loss nan (nan)	prob nan (nan)	GS 29.328 (29.328)	mem 41.694
Train: [93][140/750]	BT 0.021 (1.290)	DT 0.001 (1.245)	loss nan (nan)	prob nan (nan)	GS 31.484 (31.484)	mem 41.596
Train: [93][145/750]	BT 0.096 (1.276)	DT 0.015 (1.230)	loss nan (nan)	prob nan (nan)	GS 30.906 (30.906)	mem 41.639
Train: [93][150/750]	BT 4.182 (1.298)	DT 4.149 (1.252)	loss nan (nan)	prob nan (nan)	GS 31.375 (31.375)	mem 41.679
Train: [93][155/750]	BT 0.041 (1.257)	DT 0.010 (1.212)	loss nan (nan)	prob nan (nan)	GS 31.188 (31.188)	mem 41.720
Train: [93][160/750]	BT 6.747 (1.265)	DT 6.711 (1.219)	loss nan (nan)	prob nan (nan)	GS 35.203 (35.203)	mem 41.707
Train: [93][165/750]	BT 0.023 (1.253)	DT 0.001 (1.208)	loss nan (nan)	prob nan (nan)	GS 28.438 (28.438)	mem 41.764
Train: [93][170/750]	BT 0.053 (1.222)	DT 0.003 (1.176)	loss nan (nan)	prob nan (nan)	GS 39.484 (39.484)	mem 41.910
Train: [93][175/750]	BT 0.112 (1.267)	DT 0.005 (1.222)	loss nan (nan)	prob nan (nan)	GS 33.406 (33.406)	mem 41.825
Train: [93][180/750]	BT 0.059 (1.233)	DT 0.015 (1.188)	loss nan (nan)	prob nan (nan)	GS 34.484 (34.484)	mem 41.845
Train: [93][185/750]	BT 0.074 (1.228)	DT 0.009 (1.183)	loss nan (nan)	prob nan (nan)	GS 29.656 (29.656)	mem 41.984
Train: [93][190/750]	BT 0.025 (1.244)	DT 0.001 (1.200)	loss nan (nan)	prob nan (nan)	GS 34.031 (34.031)	mem 41.970
Train: [93][195/750]	BT 0.025 (1.213)	DT 0.001 (1.169)	loss nan (nan)	prob nan (nan)	GS 32.391 (32.391)	mem 41.970
Train: [93][200/750]	BT 0.055 (1.256)	DT 0.001 (1.212)	loss nan (nan)	prob nan (nan)	GS 33.375 (33.375)	mem 42.014
Train: [93][205/750]	BT 0.030 (1.227)	DT 0.001 (1.183)	loss nan (nan)	prob nan (nan)	GS 31.531 (31.531)	mem 41.894
Train: [93][210/750]	BT 11.718 (1.255)	DT 11.688 (1.211)	loss nan (nan)	prob nan (nan)	GS 35.125 (35.125)	mem 41.977
Train: [93][215/750]	BT 0.043 (1.226)	DT 0.002 (1.183)	loss nan (nan)	prob nan (nan)	GS 28.469 (28.469)	mem 41.913
Train: [93][220/750]	BT 0.100 (1.200)	DT 0.025 (1.156)	loss nan (nan)	prob nan (nan)	GS 33.516 (33.516)	mem 41.915
Train: [93][225/750]	BT 0.032 (1.232)	DT 0.001 (1.188)	loss nan (nan)	prob nan (nan)	GS 28.375 (28.375)	mem 41.952
Train: [93][230/750]	BT 0.059 (1.206)	DT 0.003 (1.163)	loss nan (nan)	prob nan (nan)	GS 33.641 (33.641)	mem 41.952
Train: [93][235/750]	BT 0.041 (1.235)	DT 0.001 (1.191)	loss nan (nan)	prob nan (nan)	GS 28.656 (28.656)	mem 41.823
Train: [93][240/750]	BT 0.062 (1.211)	DT 0.005 (1.167)	loss nan (nan)	prob nan (nan)	GS 35.203 (35.203)	mem 41.853
Train: [93][245/750]	BT 0.038 (1.187)	DT 0.003 (1.143)	loss nan (nan)	prob nan (nan)	GS 29.438 (29.438)	mem 41.883
Train: [93][250/750]	BT 0.034 (1.219)	DT 0.001 (1.175)	loss nan (nan)	prob nan (nan)	GS 35.812 (35.812)	mem 41.970
Train: [93][255/750]	BT 0.068 (1.197)	DT 0.012 (1.152)	loss nan (nan)	prob nan (nan)	GS 31.859 (31.859)	mem 41.973
Train: [93][260/750]	BT 0.032 (1.220)	DT 0.001 (1.175)	loss nan (nan)	prob nan (nan)	GS 35.766 (35.766)	mem 42.068
Train: [93][265/750]	BT 0.060 (1.198)	DT 0.001 (1.153)	loss nan (nan)	prob nan (nan)	GS 36.812 (36.812)	mem 42.068
Train: [93][270/750]	BT 15.342 (1.233)	DT 15.300 (1.189)	loss nan (nan)	prob nan (nan)	GS 36.250 (36.250)	mem 42.053
Train: [93][275/750]	BT 0.060 (1.211)	DT 0.001 (1.167)	loss nan (nan)	prob nan (nan)	GS 31.344 (31.344)	mem 42.054
Train: [93][280/750]	BT 0.045 (1.191)	DT 0.004 (1.147)	loss nan (nan)	prob nan (nan)	GS 34.078 (34.078)	mem 42.134
Train: [93][285/750]	BT 0.047 (1.218)	DT 0.002 (1.174)	loss nan (nan)	prob nan (nan)	GS 31.828 (31.828)	mem 42.146
Train: [93][290/750]	BT 0.031 (1.198)	DT 0.001 (1.154)	loss nan (nan)	prob nan (nan)	GS 34.250 (34.250)	mem 42.063
Train: [93][295/750]	BT 0.045 (1.221)	DT 0.010 (1.177)	loss nan (nan)	prob nan (nan)	GS 33.156 (33.156)	mem 42.199
Train: [93][300/750]	BT 0.042 (1.201)	DT 0.002 (1.157)	loss nan (nan)	prob nan (nan)	GS 33.734 (33.734)	mem 42.134
Train: [93][305/750]	BT 0.117 (1.183)	DT 0.003 (1.138)	loss nan (nan)	prob nan (nan)	GS 28.969 (28.969)	mem 42.435
Train: [93][310/750]	BT 0.028 (1.210)	DT 0.001 (1.166)	loss nan (nan)	prob nan (nan)	GS 39.344 (39.344)	mem 42.145
Train: [93][315/750]	BT 0.031 (1.191)	DT 0.001 (1.147)	loss nan (nan)	prob nan (nan)	GS 31.734 (31.734)	mem 42.145
Train: [93][320/750]	BT 0.059 (1.220)	DT 0.007 (1.176)	loss nan (nan)	prob nan (nan)	GS 34.516 (34.516)	mem 42.340
Train: [93][325/750]	BT 0.057 (1.202)	DT 0.008 (1.158)	loss nan (nan)	prob nan (nan)	GS 47.266 (47.266)	mem 42.225
Train: [93][330/750]	BT 11.406 (1.219)	DT 11.358 (1.175)	loss nan (nan)	prob nan (nan)	GS 34.141 (34.141)	mem 42.233
Train: [93][335/750]	BT 0.028 (1.202)	DT 0.001 (1.158)	loss nan (nan)	prob nan (nan)	GS 28.578 (28.578)	mem 42.217
Train: [93][340/750]	BT 0.029 (1.187)	DT 0.001 (1.143)	loss nan (nan)	prob nan (nan)	GS 35.312 (35.312)	mem 42.217
Train: [93][345/750]	BT 0.033 (1.206)	DT 0.001 (1.163)	loss nan (nan)	prob nan (nan)	GS 30.125 (30.125)	mem 42.191
Train: [93][350/750]	BT 0.037 (1.192)	DT 0.001 (1.149)	loss nan (nan)	prob nan (nan)	GS 32.578 (32.578)	mem 42.187
Train: [93][355/750]	BT 0.061 (1.208)	DT 0.027 (1.164)	loss nan (nan)	prob nan (nan)	GS 30.422 (30.422)	mem 42.184
Train: [93][360/750]	BT 2.760 (1.199)	DT 2.723 (1.155)	loss nan (nan)	prob nan (nan)	GS 33.391 (33.391)	mem 42.355
Train: [93][365/750]	BT 0.069 (1.183)	DT 0.011 (1.140)	loss nan (nan)	prob nan (nan)	GS 35.766 (35.766)	mem 42.226
Train: [93][370/750]	BT 0.088 (1.191)	DT 0.001 (1.147)	loss nan (nan)	prob nan (nan)	GS 33.906 (33.906)	mem 42.375
Train: [93][375/750]	BT 0.024 (1.189)	DT 0.001 (1.145)	loss nan (nan)	prob nan (nan)	GS 35.359 (35.359)	mem 42.172
Train: [93][380/750]	BT 0.037 (1.187)	DT 0.001 (1.143)	loss nan (nan)	prob nan (nan)	GS 34.625 (34.625)	mem 42.146
Train: [93][385/750]	BT 0.088 (1.185)	DT 0.014 (1.141)	loss nan (nan)	prob nan (nan)	GS 32.844 (32.844)	mem 42.574
Train: [93][390/750]	BT 7.289 (1.189)	DT 7.239 (1.145)	loss nan (nan)	prob nan (nan)	GS 34.312 (34.312)	mem 42.157
Train: [93][395/750]	BT 0.090 (1.174)	DT 0.002 (1.130)	loss nan (nan)	prob nan (nan)	GS 37.156 (37.156)	mem 42.286
Train: [93][400/750]	BT 0.064 (1.167)	DT 0.005 (1.123)	loss nan (nan)	prob nan (nan)	GS 33.375 (33.375)	mem 42.214
Train: [93][405/750]	BT 0.030 (1.178)	DT 0.001 (1.133)	loss nan (nan)	prob nan (nan)	GS 28.484 (28.484)	mem 42.069
Train: [93][410/750]	BT 0.031 (1.174)	DT 0.001 (1.130)	loss nan (nan)	prob nan (nan)	GS 30.672 (30.672)	mem 42.077
Train: [93][415/750]	BT 0.069 (1.179)	DT 0.014 (1.135)	loss nan (nan)	prob nan (nan)	GS 30.734 (30.734)	mem 42.270
Train: [93][420/750]	BT 5.067 (1.178)	DT 5.036 (1.134)	loss nan (nan)	prob nan (nan)	GS 34.203 (34.203)	mem 42.098
Train: [93][425/750]	BT 0.032 (1.164)	DT 0.002 (1.121)	loss nan (nan)	prob nan (nan)	GS 33.750 (33.750)	mem 42.101
Train: [93][430/750]	BT 0.062 (1.170)	DT 0.004 (1.125)	loss nan (nan)	prob nan (nan)	GS 33.203 (33.203)	mem 42.119
Train: [93][435/750]	BT 0.034 (1.168)	DT 0.002 (1.124)	loss nan (nan)	prob nan (nan)	GS 29.797 (29.797)	mem 42.009
Train: [93][440/750]	BT 0.022 (1.175)	DT 0.001 (1.131)	loss nan (nan)	prob nan (nan)	GS 31.234 (31.234)	mem 42.089
Train: [93][445/750]	BT 0.036 (1.170)	DT 0.004 (1.126)	loss nan (nan)	prob nan (nan)	GS 29.672 (29.672)	mem 42.085
Train: [93][450/750]	BT 8.330 (1.176)	DT 8.308 (1.132)	loss nan (nan)	prob nan (nan)	GS 33.078 (33.078)	mem 42.083
Train: [93][455/750]	BT 0.043 (1.164)	DT 0.002 (1.120)	loss nan (nan)	prob nan (nan)	GS 31.328 (31.328)	mem 42.150
Train: [93][460/750]	BT 0.044 (1.161)	DT 0.001 (1.117)	loss nan (nan)	prob nan (nan)	GS 35.594 (35.594)	mem 42.374
Train: [93][465/750]	BT 0.026 (1.173)	DT 0.001 (1.129)	loss nan (nan)	prob nan (nan)	GS 29.391 (29.391)	mem 42.209
Train: [93][470/750]	BT 0.032 (1.162)	DT 0.001 (1.118)	loss nan (nan)	prob nan (nan)	GS 34.578 (34.578)	mem 42.024
Train: [93][475/750]	BT 0.086 (1.178)	DT 0.001 (1.133)	loss nan (nan)	prob nan (nan)	GS 28.453 (28.453)	mem 42.220
Train: [93][480/750]	BT 1.428 (1.169)	DT 1.377 (1.124)	loss nan (nan)	prob nan (nan)	GS 35.219 (35.219)	mem 42.136
Train: [93][485/750]	BT 0.074 (1.157)	DT 0.036 (1.113)	loss nan (nan)	prob nan (nan)	GS 31.719 (31.719)	mem 42.135
Train: [93][490/750]	BT 0.024 (1.172)	DT 0.001 (1.128)	loss nan (nan)	prob nan (nan)	GS 33.484 (33.484)	mem 42.153
Train: [93][495/750]	BT 0.032 (1.162)	DT 0.002 (1.117)	loss nan (nan)	prob nan (nan)	GS 30.438 (30.438)	mem 42.295
Train: [93][500/750]	BT 0.047 (1.172)	DT 0.008 (1.128)	loss nan (nan)	prob nan (nan)	GS 34.891 (34.891)	mem 42.263
Train: [93][505/750]	BT 0.040 (1.168)	DT 0.017 (1.124)	loss nan (nan)	prob nan (nan)	GS 31.156 (31.156)	mem 42.125
Train: [93][510/750]	BT 8.736 (1.174)	DT 8.691 (1.130)	loss nan (nan)	prob nan (nan)	GS 30.219 (30.219)	mem 42.137
Train: [93][515/750]	BT 0.049 (1.163)	DT 0.001 (1.119)	loss nan (nan)	prob nan (nan)	GS 32.141 (32.141)	mem 42.139
Train: [93][520/750]	BT 0.069 (1.160)	DT 0.001 (1.116)	loss nan (nan)	prob nan (nan)	GS 34.625 (34.625)	mem 42.130
Train: [93][525/750]	BT 0.043 (1.172)	DT 0.002 (1.129)	loss nan (nan)	prob nan (nan)	GS 32.094 (32.094)	mem 42.438
Train: [93][530/750]	BT 0.027 (1.162)	DT 0.001 (1.118)	loss nan (nan)	prob nan (nan)	GS 33.375 (33.375)	mem 42.155
Train: [93][535/750]	BT 0.024 (1.175)	DT 0.001 (1.131)	loss nan (nan)	prob nan (nan)	GS 28.953 (28.953)	mem 42.146
Train: [93][540/750]	BT 0.033 (1.164)	DT 0.002 (1.120)	loss nan (nan)	prob nan (nan)	GS 31.297 (31.297)	mem 42.147
Train: [93][545/750]	BT 0.052 (1.154)	DT 0.009 (1.110)	loss nan (nan)	prob nan (nan)	GS 33.172 (33.172)	mem 42.147
Train: [93][550/750]	BT 0.038 (1.164)	DT 0.006 (1.120)	loss nan (nan)	prob nan (nan)	GS 34.578 (34.578)	mem 42.248
Train: [93][555/750]	BT 0.050 (1.154)	DT 0.010 (1.110)	loss nan (nan)	prob nan (nan)	GS 28.094 (28.094)	mem 42.161
Train: [93][560/750]	BT 0.033 (1.163)	DT 0.001 (1.120)	loss nan (nan)	prob nan (nan)	GS 31.297 (31.297)	mem 42.233
Train: [93][565/750]	BT 0.031 (1.157)	DT 0.002 (1.114)	loss nan (nan)	prob nan (nan)	GS 31.859 (31.859)	mem 42.184
Train: [93][570/750]	BT 13.939 (1.172)	DT 13.866 (1.128)	loss nan (nan)	prob nan (nan)	GS 34.734 (34.734)	mem 42.159
Train: [93][575/750]	BT 0.034 (1.162)	DT 0.001 (1.119)	loss nan (nan)	prob nan (nan)	GS 30.500 (30.500)	mem 42.161
Train: [93][580/750]	BT 0.034 (1.158)	DT 0.001 (1.115)	loss nan (nan)	prob nan (nan)	GS 34.109 (34.109)	mem 42.059
Train: [93][585/750]	BT 0.106 (1.159)	DT 0.001 (1.115)	loss nan (nan)	prob nan (nan)	GS 33.859 (33.859)	mem 42.137
Train: [93][590/750]	BT 0.035 (1.164)	DT 0.002 (1.120)	loss nan (nan)	prob nan (nan)	GS 35.531 (35.531)	mem 42.272
Train: [93][595/750]	BT 0.068 (1.162)	DT 0.006 (1.118)	loss nan (nan)	prob nan (nan)	GS 33.359 (33.359)	mem 42.104
Train: [93][600/750]	BT 12.267 (1.173)	DT 12.214 (1.129)	loss nan (nan)	prob nan (nan)	GS 37.578 (37.578)	mem 42.026
Train: [93][605/750]	BT 0.034 (1.163)	DT 0.001 (1.120)	loss nan (nan)	prob nan (nan)	GS 32.000 (32.000)	mem 42.027
Train: [93][610/750]	BT 0.084 (1.157)	DT 0.002 (1.114)	loss nan (nan)	prob nan (nan)	GS 35.219 (35.219)	mem 42.060
Train: [93][615/750]	BT 0.087 (1.164)	DT 0.016 (1.121)	loss nan (nan)	prob nan (nan)	GS 31.469 (31.469)	mem 42.227
Train: [93][620/750]	BT 0.032 (1.160)	DT 0.001 (1.117)	loss nan (nan)	prob nan (nan)	GS 35.938 (35.938)	mem 42.105
Train: [93][625/750]	BT 0.032 (1.170)	DT 0.001 (1.126)	loss nan (nan)	prob nan (nan)	GS 30.297 (30.297)	mem 42.136
Train: [93][630/750]	BT 0.033 (1.161)	DT 0.002 (1.117)	loss nan (nan)	prob nan (nan)	GS 32.344 (32.344)	mem 42.170
Train: [93][635/750]	BT 0.037 (1.152)	DT 0.002 (1.109)	loss nan (nan)	prob nan (nan)	GS 28.750 (28.750)	mem 42.155
Train: [93][640/750]	BT 0.036 (1.164)	DT 0.009 (1.121)	loss nan (nan)	prob nan (nan)	GS 37.578 (37.578)	mem 42.064
Train: [93][645/750]	BT 0.045 (1.155)	DT 0.010 (1.112)	loss nan (nan)	prob nan (nan)	GS 29.969 (29.969)	mem 42.067
Train: [93][650/750]	BT 0.026 (1.170)	DT 0.001 (1.127)	loss nan (nan)	prob nan (nan)	GS 34.297 (34.297)	mem 42.099
Train: [93][655/750]	BT 0.057 (1.161)	DT 0.001 (1.118)	loss nan (nan)	prob nan (nan)	GS 29.062 (29.062)	mem 42.127
Train: [93][660/750]	BT 11.626 (1.170)	DT 11.598 (1.127)	loss nan (nan)	prob nan (nan)	GS 33.719 (33.719)	mem 42.188
Train: [93][665/750]	BT 0.030 (1.162)	DT 0.001 (1.119)	loss nan (nan)	prob nan (nan)	GS 35.359 (35.359)	mem 42.128
Train: [93][670/750]	BT 0.037 (1.156)	DT 0.002 (1.113)	loss nan (nan)	prob nan (nan)	GS 34.359 (34.359)	mem 42.135
Train: [93][675/750]	BT 0.023 (1.165)	DT 0.001 (1.122)	loss nan (nan)	prob nan (nan)	GS 30.734 (30.734)	mem 42.155
Train: [93][680/750]	BT 0.033 (1.161)	DT 0.002 (1.119)	loss nan (nan)	prob nan (nan)	GS 34.844 (34.844)	mem 42.157
Train: [93][685/750]	BT 0.048 (1.168)	DT 0.009 (1.125)	loss nan (nan)	prob nan (nan)	GS 34.250 (34.250)	mem 42.255
Train: [93][690/750]	BT 2.958 (1.164)	DT 2.918 (1.121)	loss nan (nan)	prob nan (nan)	GS 31.984 (31.984)	mem 42.167
Train: [93][695/750]	BT 0.033 (1.156)	DT 0.002 (1.113)	loss nan (nan)	prob nan (nan)	GS 25.547 (25.547)	mem 42.278
Train: [93][700/750]	BT 0.031 (1.163)	DT 0.001 (1.120)	loss nan (nan)	prob nan (nan)	GS 33.031 (33.031)	mem 42.095
Train: [93][705/750]	BT 0.059 (1.155)	DT 0.022 (1.112)	loss nan (nan)	prob nan (nan)	GS 30.391 (30.391)	mem 42.212
Train: [93][710/750]	BT 0.030 (1.166)	DT 0.001 (1.123)	loss nan (nan)	prob nan (nan)	GS 35.484 (35.484)	mem 42.012
Train: [93][715/750]	BT 0.118 (1.161)	DT 0.007 (1.118)	loss nan (nan)	prob nan (nan)	GS 32.703 (32.703)	mem 42.466
Train: [93][720/750]	BT 9.440 (1.166)	DT 9.409 (1.123)	loss nan (nan)	prob nan (nan)	GS 31.969 (31.969)	mem 42.191
Train: [93][725/750]	BT 0.023 (1.158)	DT 0.001 (1.115)	loss nan (nan)	prob nan (nan)	GS 31.031 (31.031)	mem 42.210
Train: [93][730/750]	BT 0.033 (1.151)	DT 0.001 (1.108)	loss nan (nan)	prob nan (nan)	GS 34.516 (34.516)	mem 42.233
Train: [93][735/750]	BT 0.022 (1.160)	DT 0.001 (1.118)	loss nan (nan)	prob nan (nan)	GS 25.984 (25.984)	mem 41.620
Train: [93][740/750]	BT 0.033 (1.153)	DT 0.002 (1.110)	loss nan (nan)	prob nan (nan)	GS 32.625 (32.625)	mem 41.585
Train: [93][745/750]	BT 0.031 (1.153)	DT 0.005 (1.110)	loss nan (nan)	prob nan (nan)	GS 35.688 (35.688)	mem 9.905
Train: [93][750/750]	BT 0.022 (1.145)	DT 0.001 (1.103)	loss nan (nan)	prob nan (nan)	GS 34.125 (34.125)	mem 9.905
Train: [93][755/750]	BT 0.027 (1.138)	DT 0.001 (1.095)	loss nan (nan)	prob nan (nan)	GS 30.656 (30.656)	mem 9.904
epoch 93, total time 861.89
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [94][1/750]	BT 20.345 (20.345)	DT 20.152 (20.152)	loss nan (nan)	prob nan (nan)	GS 29.531 (29.531)	mem 40.883
Train: [94][5/750]	BT 1.098 (4.830)	DT 1.066 (4.755)	loss nan (nan)	prob nan (nan)	GS 30.703 (30.703)	mem 40.871
Train: [94][10/750]	BT 0.083 (2.446)	DT 0.003 (2.381)	loss nan (nan)	prob nan (nan)	GS 32.141 (32.141)	mem 40.997
Train: [94][15/750]	BT 0.071 (2.626)	DT 0.002 (2.566)	loss nan (nan)	prob nan (nan)	GS 33.188 (33.188)	mem 41.039
Train: [94][20/750]	BT 0.125 (2.080)	DT 0.012 (2.019)	loss nan (nan)	prob nan (nan)	GS 31.219 (31.219)	mem 41.272
Train: [94][25/750]	BT 0.055 (1.677)	DT 0.014 (1.616)	loss nan (nan)	prob nan (nan)	GS 30.234 (30.234)	mem 41.209
Train: [94][30/750]	BT 0.087 (1.801)	DT 0.007 (1.741)	loss nan (nan)	prob nan (nan)	GS 32.188 (32.188)	mem 41.196
Train: [94][35/750]	BT 0.036 (1.553)	DT 0.002 (1.494)	loss nan (nan)	prob nan (nan)	GS 30.766 (30.766)	mem 41.086
Train: [94][40/750]	BT 0.099 (1.633)	DT 0.022 (1.577)	loss nan (nan)	prob nan (nan)	GS 30.672 (30.672)	mem 41.287
Train: [94][45/750]	BT 0.047 (1.457)	DT 0.002 (1.402)	loss nan (nan)	prob nan (nan)	GS 32.297 (32.297)	mem 41.262
Train: [94][50/750]	BT 12.982 (1.600)	DT 12.948 (1.547)	loss nan (nan)	prob nan (nan)	GS 33.016 (33.016)	mem 41.277
Train: [94][55/750]	BT 0.046 (1.459)	DT 0.002 (1.406)	loss nan (nan)	prob nan (nan)	GS 29.453 (29.453)	mem 41.358
Train: [94][60/750]	BT 0.398 (1.378)	DT 0.340 (1.325)	loss nan (nan)	prob nan (nan)	GS 31.531 (31.531)	mem 41.250
Train: [94][65/750]	BT 0.037 (1.423)	DT 0.006 (1.372)	loss nan (nan)	prob nan (nan)	GS 27.703 (27.703)	mem 41.349
Train: [94][70/750]	BT 0.044 (1.357)	DT 0.004 (1.305)	loss nan (nan)	prob nan (nan)	GS 34.891 (34.891)	mem 41.276
Train: [94][75/750]	BT 0.026 (1.447)	DT 0.002 (1.396)	loss nan (nan)	prob nan (nan)	GS 31.562 (31.562)	mem 41.415
Train: [94][80/750]	BT 0.036 (1.359)	DT 0.001 (1.310)	loss nan (nan)	prob nan (nan)	GS 31.516 (31.516)	mem 41.450
Train: [94][85/750]	BT 0.027 (1.282)	DT 0.001 (1.233)	loss nan (nan)	prob nan (nan)	GS 28.375 (28.375)	mem 41.451
Train: [94][90/750]	BT 0.059 (1.367)	DT 0.008 (1.317)	loss nan (nan)	prob nan (nan)	GS 38.078 (38.078)	mem 41.477
Train: [94][95/750]	BT 0.112 (1.323)	DT 0.026 (1.273)	loss nan (nan)	prob nan (nan)	GS 29.234 (29.234)	mem 41.495
Train: [94][100/750]	BT 0.031 (1.373)	DT 0.003 (1.324)	loss nan (nan)	prob nan (nan)	GS 33.328 (33.328)	mem 41.524
Train: [94][105/750]	BT 0.064 (1.345)	DT 0.008 (1.295)	loss nan (nan)	prob nan (nan)	GS 34.094 (34.094)	mem 41.622
Train: [94][110/750]	BT 5.344 (1.334)	DT 5.296 (1.285)	loss nan (nan)	prob nan (nan)	GS 36.516 (36.516)	mem 41.686
Train: [94][115/750]	BT 0.033 (1.278)	DT 0.001 (1.230)	loss nan (nan)	prob nan (nan)	GS 35.766 (35.766)	mem 41.692
Train: [94][120/750]	BT 0.033 (1.271)	DT 0.001 (1.223)	loss nan (nan)	prob nan (nan)	GS 37.219 (37.219)	mem 41.758
Train: [94][125/750]	BT 0.032 (1.262)	DT 0.002 (1.214)	loss nan (nan)	prob nan (nan)	GS 28.625 (28.625)	mem 41.805
Train: [94][130/750]	BT 0.043 (1.276)	DT 0.009 (1.228)	loss nan (nan)	prob nan (nan)	GS 34.453 (34.453)	mem 41.758
Train: [94][135/750]	BT 0.054 (1.267)	DT 0.006 (1.219)	loss nan (nan)	prob nan (nan)	GS 33.625 (33.625)	mem 41.835
Train: [94][140/750]	BT 9.681 (1.293)	DT 9.649 (1.244)	loss nan (nan)	prob nan (nan)	GS 29.812 (29.812)	mem 41.868
Train: [94][145/750]	BT 0.032 (1.250)	DT 0.001 (1.201)	loss nan (nan)	prob nan (nan)	GS 33.109 (33.109)	mem 42.053
Train: [94][150/750]	BT 0.046 (1.233)	DT 0.003 (1.185)	loss nan (nan)	prob nan (nan)	GS 30.500 (30.500)	mem 41.843
Train: [94][155/750]	BT 0.065 (1.236)	DT 0.013 (1.188)	loss nan (nan)	prob nan (nan)	GS 31.203 (31.203)	mem 42.083
Train: [94][160/750]	BT 0.054 (1.222)	DT 0.001 (1.175)	loss nan (nan)	prob nan (nan)	GS 32.016 (32.016)	mem 41.954
Train: [94][165/750]	BT 0.032 (1.239)	DT 0.001 (1.192)	loss nan (nan)	prob nan (nan)	GS 29.266 (29.266)	mem 41.769
Train: [94][170/750]	BT 1.836 (1.214)	DT 1.782 (1.167)	loss nan (nan)	prob nan (nan)	GS 31.750 (31.750)	mem 41.900
Train: [94][175/750]	BT 0.101 (1.181)	DT 0.017 (1.134)	loss nan (nan)	prob nan (nan)	GS 30.875 (30.875)	mem 41.759
Train: [94][180/750]	BT 0.116 (1.197)	DT 0.039 (1.150)	loss nan (nan)	prob nan (nan)	GS 35.031 (35.031)	mem 41.981
Train: [94][185/750]	BT 0.093 (1.177)	DT 0.008 (1.129)	loss nan (nan)	prob nan (nan)	GS 30.266 (30.266)	mem 41.935
Train: [94][190/750]	BT 0.033 (1.203)	DT 0.002 (1.156)	loss nan (nan)	prob nan (nan)	GS 36.094 (36.094)	mem 41.889
Train: [94][195/750]	BT 0.047 (1.194)	DT 0.008 (1.147)	loss nan (nan)	prob nan (nan)	GS 33.516 (33.516)	mem 41.920
Train: [94][200/750]	BT 11.170 (1.221)	DT 11.138 (1.174)	loss nan (nan)	prob nan (nan)	GS 39.094 (39.094)	mem 41.941
Train: [94][205/750]	BT 0.085 (1.193)	DT 0.017 (1.146)	loss nan (nan)	prob nan (nan)	GS 33.812 (33.812)	mem 41.977
Train: [94][210/750]	BT 0.162 (1.166)	DT 0.023 (1.118)	loss nan (nan)	prob nan (nan)	GS 34.203 (34.203)	mem 42.010
Train: [94][215/750]	BT 0.052 (1.203)	DT 0.012 (1.155)	loss nan (nan)	prob nan (nan)	GS 40.062 (40.062)	mem 41.972
Train: [94][220/750]	BT 0.078 (1.176)	DT 0.007 (1.129)	loss nan (nan)	prob nan (nan)	GS 35.750 (35.750)	mem 42.032
Train: [94][225/750]	BT 0.031 (1.211)	DT 0.001 (1.164)	loss nan (nan)	prob nan (nan)	GS 31.547 (31.547)	mem 42.030
Train: [94][230/750]	BT 0.231 (1.186)	DT 0.174 (1.139)	loss nan (nan)	prob nan (nan)	GS 33.547 (33.547)	mem 42.072
Train: [94][235/750]	BT 0.073 (1.162)	DT 0.004 (1.115)	loss nan (nan)	prob nan (nan)	GS 28.359 (28.359)	mem 42.033
Train: [94][240/750]	BT 0.033 (1.182)	DT 0.001 (1.135)	loss nan (nan)	prob nan (nan)	GS 36.078 (36.078)	mem 42.068
Train: [94][245/750]	BT 0.050 (1.177)	DT 0.005 (1.130)	loss nan (nan)	prob nan (nan)	GS 34.234 (34.234)	mem 42.059
Train: [94][250/750]	BT 0.053 (1.189)	DT 0.011 (1.142)	loss nan (nan)	prob nan (nan)	GS 29.359 (29.359)	mem 42.135
Train: [94][255/750]	BT 0.062 (1.169)	DT 0.012 (1.122)	loss nan (nan)	prob nan (nan)	GS 32.281 (32.281)	mem 42.087
Train: [94][260/750]	BT 10.148 (1.186)	DT 10.053 (1.139)	loss nan (nan)	prob nan (nan)	GS 31.750 (31.750)	mem 42.441
Train: [94][265/750]	BT 0.035 (1.165)	DT 0.002 (1.118)	loss nan (nan)	prob nan (nan)	GS 35.984 (35.984)	mem 42.444
Train: [94][270/750]	BT 0.052 (1.170)	DT 0.004 (1.124)	loss nan (nan)	prob nan (nan)	GS 32.906 (32.906)	mem 42.090
Train: [94][275/750]	BT 0.053 (1.174)	DT 0.003 (1.127)	loss nan (nan)	prob nan (nan)	GS 29.281 (29.281)	mem 42.207
Train: [94][280/750]	BT 0.070 (1.166)	DT 0.011 (1.119)	loss nan (nan)	prob nan (nan)	GS 35.078 (35.078)	mem 42.105
Train: [94][285/750]	BT 0.025 (1.176)	DT 0.001 (1.129)	loss nan (nan)	prob nan (nan)	GS 31.688 (31.688)	mem 42.102
Train: [94][290/750]	BT 0.131 (1.157)	DT 0.100 (1.110)	loss nan (nan)	prob nan (nan)	GS 33.578 (33.578)	mem 42.123
Train: [94][295/750]	BT 0.086 (1.139)	DT 0.003 (1.092)	loss nan (nan)	prob nan (nan)	GS 30.062 (30.062)	mem 42.232
Train: [94][300/750]	BT 0.032 (1.161)	DT 0.001 (1.114)	loss nan (nan)	prob nan (nan)	GS 33.922 (33.922)	mem 42.207
Train: [94][305/750]	BT 0.111 (1.145)	DT 0.019 (1.098)	loss nan (nan)	prob nan (nan)	GS 30.500 (30.500)	mem 42.161
Train: [94][310/750]	BT 0.031 (1.177)	DT 0.001 (1.130)	loss nan (nan)	prob nan (nan)	GS 32.047 (32.047)	mem 42.039
Train: [94][315/750]	BT 0.067 (1.160)	DT 0.002 (1.112)	loss nan (nan)	prob nan (nan)	GS 30.391 (30.391)	mem 42.041
Train: [94][320/750]	BT 12.348 (1.181)	DT 12.320 (1.133)	loss nan (nan)	prob nan (nan)	GS 34.281 (34.281)	mem 41.953
Train: [94][325/750]	BT 0.097 (1.163)	DT 0.003 (1.116)	loss nan (nan)	prob nan (nan)	GS 32.109 (32.109)	mem 42.053
Train: [94][330/750]	BT 0.048 (1.147)	DT 0.006 (1.099)	loss nan (nan)	prob nan (nan)	GS 32.094 (32.094)	mem 42.007
Train: [94][335/750]	BT 0.051 (1.168)	DT 0.002 (1.120)	loss nan (nan)	prob nan (nan)	GS 28.781 (28.781)	mem 42.161
Train: [94][340/750]	BT 0.052 (1.151)	DT 0.015 (1.104)	loss nan (nan)	prob nan (nan)	GS 33.297 (33.297)	mem 42.065
Train: [94][345/750]	BT 0.071 (1.169)	DT 0.010 (1.121)	loss nan (nan)	prob nan (nan)	GS 33.656 (33.656)	mem 42.103
Train: [94][350/750]	BT 0.597 (1.155)	DT 0.538 (1.107)	loss nan (nan)	prob nan (nan)	GS 29.922 (29.922)	mem 42.103
Train: [94][355/750]	BT 0.058 (1.139)	DT 0.007 (1.091)	loss nan (nan)	prob nan (nan)	GS 34.906 (34.906)	mem 42.105
Train: [94][360/750]	BT 0.060 (1.156)	DT 0.003 (1.108)	loss nan (nan)	prob nan (nan)	GS 35.750 (35.750)	mem 42.095
Train: [94][365/750]	BT 0.054 (1.143)	DT 0.009 (1.095)	loss nan (nan)	prob nan (nan)	GS 43.766 (43.766)	mem 42.084
Train: [94][370/750]	BT 0.036 (1.157)	DT 0.001 (1.109)	loss nan (nan)	prob nan (nan)	GS 33.359 (33.359)	mem 42.130
Train: [94][375/750]	BT 0.049 (1.148)	DT 0.001 (1.101)	loss nan (nan)	prob nan (nan)	GS 29.469 (29.469)	mem 42.141
Train: [94][380/750]	BT 10.777 (1.162)	DT 10.724 (1.114)	loss nan (nan)	prob nan (nan)	GS 33.391 (33.391)	mem 42.125
Train: [94][385/750]	BT 0.049 (1.147)	DT 0.001 (1.100)	loss nan (nan)	prob nan (nan)	GS 27.125 (27.125)	mem 42.127
Train: [94][390/750]	BT 1.528 (1.141)	DT 1.483 (1.093)	loss nan (nan)	prob nan (nan)	GS 34.906 (34.906)	mem 42.113
Train: [94][395/750]	BT 0.033 (1.150)	DT 0.002 (1.102)	loss nan (nan)	prob nan (nan)	GS 29.203 (29.203)	mem 42.148
Train: [94][400/750]	BT 0.032 (1.146)	DT 0.001 (1.099)	loss nan (nan)	prob nan (nan)	GS 34.703 (34.703)	mem 42.156
Train: [94][405/750]	BT 0.035 (1.150)	DT 0.001 (1.102)	loss nan (nan)	prob nan (nan)	GS 33.844 (33.844)	mem 42.180
Train: [94][410/750]	BT 6.209 (1.152)	DT 6.167 (1.104)	loss nan (nan)	prob nan (nan)	GS 32.266 (32.266)	mem 42.210
Train: [94][415/750]	BT 0.033 (1.139)	DT 0.001 (1.091)	loss nan (nan)	prob nan (nan)	GS 31.750 (31.750)	mem 42.129
Train: [94][420/750]	BT 0.064 (1.142)	DT 0.006 (1.095)	loss nan (nan)	prob nan (nan)	GS 35.109 (35.109)	mem 42.175
Train: [94][425/750]	BT 0.087 (1.142)	DT 0.003 (1.094)	loss nan (nan)	prob nan (nan)	GS 31.031 (31.031)	mem 42.213
Train: [94][430/750]	BT 2.342 (1.143)	DT 2.302 (1.095)	loss nan (nan)	prob nan (nan)	GS 33.641 (33.641)	mem 42.328
Train: [94][435/750]	BT 0.029 (1.155)	DT 0.001 (1.108)	loss nan (nan)	prob nan (nan)	GS 27.625 (27.625)	mem 42.111
Train: [94][440/750]	BT 0.738 (1.144)	DT 0.698 (1.097)	loss nan (nan)	prob nan (nan)	GS 38.594 (38.594)	mem 42.117
Train: [94][445/750]	BT 0.044 (1.135)	DT 0.003 (1.087)	loss nan (nan)	prob nan (nan)	GS 31.500 (31.500)	mem 42.156
Train: [94][450/750]	BT 0.031 (1.147)	DT 0.001 (1.100)	loss nan (nan)	prob nan (nan)	GS 36.438 (36.438)	mem 42.101
Train: [94][455/750]	BT 0.041 (1.141)	DT 0.013 (1.094)	loss nan (nan)	prob nan (nan)	GS 50.969 (50.969)	mem 42.103
Train: [94][460/750]	BT 0.030 (1.151)	DT 0.001 (1.104)	loss nan (nan)	prob nan (nan)	GS 33.375 (33.375)	mem 42.130
Train: [94][465/750]	BT 0.050 (1.145)	DT 0.014 (1.098)	loss nan (nan)	prob nan (nan)	GS 28.953 (28.953)	mem 42.074
Train: [94][470/750]	BT 10.435 (1.156)	DT 10.401 (1.109)	loss nan (nan)	prob nan (nan)	GS 36.625 (36.625)	mem 42.105
Train: [94][475/750]	BT 0.050 (1.144)	DT 0.006 (1.097)	loss nan (nan)	prob nan (nan)	GS 28.531 (28.531)	mem 42.105
Train: [94][480/750]	BT 0.102 (1.140)	DT 0.008 (1.093)	loss nan (nan)	prob nan (nan)	GS 34.781 (34.781)	mem 42.110
Train: [94][485/750]	BT 0.035 (1.153)	DT 0.001 (1.106)	loss nan (nan)	prob nan (nan)	GS 34.953 (34.953)	mem 42.085
Train: [94][490/750]	BT 0.057 (1.148)	DT 0.004 (1.101)	loss nan (nan)	prob nan (nan)	GS 33.797 (33.797)	mem 42.370
Train: [94][495/750]	BT 0.031 (1.163)	DT 0.001 (1.116)	loss nan (nan)	prob nan (nan)	GS 30.031 (30.031)	mem 42.152
Train: [94][500/750]	BT 0.694 (1.155)	DT 0.668 (1.108)	loss nan (nan)	prob nan (nan)	GS 36.266 (36.266)	mem 42.116
Train: [94][505/750]	BT 0.033 (1.144)	DT 0.001 (1.097)	loss nan (nan)	prob nan (nan)	GS 30.891 (30.891)	mem 42.118
Train: [94][510/750]	BT 0.032 (1.156)	DT 0.002 (1.109)	loss nan (nan)	prob nan (nan)	GS 29.109 (29.109)	mem 42.137
Train: [94][515/750]	BT 0.053 (1.145)	DT 0.002 (1.099)	loss nan (nan)	prob nan (nan)	GS 30.219 (30.219)	mem 42.071
Train: [94][520/750]	BT 0.027 (1.158)	DT 0.001 (1.111)	loss nan (nan)	prob nan (nan)	GS 34.625 (34.625)	mem 42.224
Train: [94][525/750]	BT 0.055 (1.147)	DT 0.010 (1.100)	loss nan (nan)	prob nan (nan)	GS 31.812 (31.812)	mem 42.225
Train: [94][530/750]	BT 15.110 (1.165)	DT 15.076 (1.119)	loss nan (nan)	prob nan (nan)	GS 33.609 (33.609)	mem 42.161
Train: [94][535/750]	BT 0.027 (1.155)	DT 0.001 (1.108)	loss nan (nan)	prob nan (nan)	GS 29.672 (29.672)	mem 42.251
Train: [94][540/750]	BT 0.042 (1.145)	DT 0.001 (1.098)	loss nan (nan)	prob nan (nan)	GS 35.516 (35.516)	mem 42.161
Train: [94][545/750]	BT 0.047 (1.157)	DT 0.014 (1.110)	loss nan (nan)	prob nan (nan)	GS 34.344 (34.344)	mem 42.198
Train: [94][550/750]	BT 0.148 (1.150)	DT 0.011 (1.103)	loss nan (nan)	prob nan (nan)	GS 32.094 (32.094)	mem 42.074
Train: [94][555/750]	BT 0.049 (1.166)	DT 0.001 (1.119)	loss nan (nan)	prob nan (nan)	GS 40.781 (40.781)	mem 42.058
Train: [94][560/750]	BT 0.024 (1.156)	DT 0.001 (1.109)	loss nan (nan)	prob nan (nan)	GS 33.344 (33.344)	mem 42.059
Train: [94][565/750]	BT 0.046 (1.146)	DT 0.003 (1.100)	loss nan (nan)	prob nan (nan)	GS 33.406 (33.406)	mem 42.059
Train: [94][570/750]	BT 0.035 (1.159)	DT 0.001 (1.113)	loss nan (nan)	prob nan (nan)	GS 32.766 (32.766)	mem 42.047
Train: [94][575/750]	BT 0.061 (1.150)	DT 0.002 (1.103)	loss nan (nan)	prob nan (nan)	GS 45.516 (45.516)	mem 42.047
Train: [94][580/750]	BT 0.026 (1.163)	DT 0.001 (1.117)	loss nan (nan)	prob nan (nan)	GS 33.953 (33.953)	mem 42.080
Train: [94][585/750]	BT 0.107 (1.154)	DT 0.059 (1.108)	loss nan (nan)	prob nan (nan)	GS 30.656 (30.656)	mem 42.090
Train: [94][590/750]	BT 12.639 (1.166)	DT 12.604 (1.120)	loss nan (nan)	prob nan (nan)	GS 34.359 (34.359)	mem 42.073
Train: [94][595/750]	BT 0.060 (1.157)	DT 0.011 (1.110)	loss nan (nan)	prob nan (nan)	GS 30.188 (30.188)	mem 42.076
Train: [94][600/750]	BT 0.125 (1.148)	DT 0.008 (1.101)	loss nan (nan)	prob nan (nan)	GS 33.188 (33.188)	mem 42.138
Train: [94][605/750]	BT 0.028 (1.162)	DT 0.002 (1.116)	loss nan (nan)	prob nan (nan)	GS 30.641 (30.641)	mem 42.079
Train: [94][610/750]	BT 0.023 (1.153)	DT 0.001 (1.107)	loss nan (nan)	prob nan (nan)	GS 33.984 (33.984)	mem 42.070
Train: [94][615/750]	BT 0.032 (1.165)	DT 0.001 (1.119)	loss nan (nan)	prob nan (nan)	GS 33.797 (33.797)	mem 42.132
Train: [94][620/750]	BT 0.033 (1.156)	DT 0.002 (1.110)	loss nan (nan)	prob nan (nan)	GS 36.609 (36.609)	mem 42.133
Train: [94][625/750]	BT 0.068 (1.148)	DT 0.026 (1.102)	loss nan (nan)	prob nan (nan)	GS 29.531 (29.531)	mem 42.217
Train: [94][630/750]	BT 0.047 (1.158)	DT 0.003 (1.111)	loss nan (nan)	prob nan (nan)	GS 32.500 (32.500)	mem 42.113
Train: [94][635/750]	BT 0.063 (1.149)	DT 0.015 (1.103)	loss nan (nan)	prob nan (nan)	GS 34.766 (34.766)	mem 42.256
Train: [94][640/750]	BT 0.056 (1.163)	DT 0.001 (1.117)	loss nan (nan)	prob nan (nan)	GS 34.922 (34.922)	mem 42.122
Train: [94][645/750]	BT 0.079 (1.154)	DT 0.016 (1.108)	loss nan (nan)	prob nan (nan)	GS 33.984 (33.984)	mem 42.229
Train: [94][650/750]	BT 11.524 (1.163)	DT 11.442 (1.117)	loss nan (nan)	prob nan (nan)	GS 36.672 (36.672)	mem 42.242
Train: [94][655/750]	BT 0.033 (1.155)	DT 0.001 (1.109)	loss nan (nan)	prob nan (nan)	GS 31.750 (31.750)	mem 42.094
Train: [94][660/750]	BT 0.080 (1.146)	DT 0.005 (1.100)	loss nan (nan)	prob nan (nan)	GS 32.656 (32.656)	mem 42.094
Train: [94][665/750]	BT 0.040 (1.159)	DT 0.003 (1.113)	loss nan (nan)	prob nan (nan)	GS 33.531 (33.531)	mem 42.213
Train: [94][670/750]	BT 0.032 (1.151)	DT 0.001 (1.105)	loss nan (nan)	prob nan (nan)	GS 32.781 (32.781)	mem 42.194
Train: [94][675/750]	BT 0.035 (1.159)	DT 0.002 (1.113)	loss nan (nan)	prob nan (nan)	GS 32.766 (32.766)	mem 42.207
Train: [94][680/750]	BT 0.057 (1.151)	DT 0.002 (1.105)	loss nan (nan)	prob nan (nan)	GS 34.391 (34.391)	mem 42.209
Train: [94][685/750]	BT 0.031 (1.147)	DT 0.002 (1.100)	loss nan (nan)	prob nan (nan)	GS 26.984 (26.984)	mem 42.212
Train: [94][690/750]	BT 2.012 (1.152)	DT 1.985 (1.106)	loss nan (nan)	prob nan (nan)	GS 34.031 (34.031)	mem 42.229
Train: [94][695/750]	BT 0.039 (1.149)	DT 0.002 (1.103)	loss nan (nan)	prob nan (nan)	GS 31.969 (31.969)	mem 42.578
Train: [94][700/750]	BT 0.045 (1.154)	DT 0.012 (1.108)	loss nan (nan)	prob nan (nan)	GS 34.203 (34.203)	mem 42.209
Train: [94][705/750]	BT 0.032 (1.149)	DT 0.001 (1.103)	loss nan (nan)	prob nan (nan)	GS 32.906 (32.906)	mem 42.147
Train: [94][710/750]	BT 9.640 (1.155)	DT 9.565 (1.108)	loss nan (nan)	prob nan (nan)	GS 33.281 (33.281)	mem 42.236
Train: [94][715/750]	BT 0.035 (1.149)	DT 0.006 (1.102)	loss nan (nan)	prob nan (nan)	GS 31.688 (31.688)	mem 42.237
Train: [94][720/750]	BT 0.080 (1.148)	DT 0.014 (1.101)	loss nan (nan)	prob nan (nan)	GS 36.281 (36.281)	mem 42.263
Train: [94][725/750]	BT 0.057 (1.146)	DT 0.017 (1.099)	loss nan (nan)	prob nan (nan)	GS 30.266 (30.266)	mem 42.316
Train: [94][730/750]	BT 10.213 (1.154)	DT 10.179 (1.108)	loss nan (nan)	prob nan (nan)	GS 33.812 (33.812)	mem 41.835
Train: [94][735/750]	BT 0.034 (1.147)	DT 0.002 (1.100)	loss nan (nan)	prob nan (nan)	GS 31.094 (31.094)	mem 41.836
Train: [94][740/750]	BT 0.040 (1.142)	DT 0.001 (1.096)	loss nan (nan)	prob nan (nan)	GS 36.672 (36.672)	mem 27.527
Train: [94][745/750]	BT 0.029 (1.142)	DT 0.001 (1.095)	loss nan (nan)	prob nan (nan)	GS 28.906 (28.906)	mem 9.784
Train: [94][750/750]	BT 0.029 (1.134)	DT 0.001 (1.088)	loss nan (nan)	prob nan (nan)	GS 39.094 (39.094)	mem 9.784
Train: [94][755/750]	BT 0.028 (1.132)	DT 0.001 (1.086)	loss nan (nan)	prob nan (nan)	GS 32.875 (32.875)	mem 9.741
epoch 94, total time 854.79
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [95][1/750]	BT 24.227 (24.227)	DT 24.154 (24.154)	loss nan (nan)	prob nan (nan)	GS 33.469 (33.469)	mem 40.890
Train: [95][5/750]	BT 0.062 (5.109)	DT 0.002 (5.060)	loss nan (nan)	prob nan (nan)	GS 33.891 (33.891)	mem 40.783
Train: [95][10/750]	BT 0.037 (2.897)	DT 0.002 (2.853)	loss nan (nan)	prob nan (nan)	GS 31.484 (31.484)	mem 40.696
Train: [95][15/750]	BT 0.047 (2.665)	DT 0.001 (2.619)	loss nan (nan)	prob nan (nan)	GS 33.594 (33.594)	mem 40.868
Train: [95][20/750]	BT 0.035 (2.185)	DT 0.002 (2.140)	loss nan (nan)	prob nan (nan)	GS 33.719 (33.719)	mem 40.845
Train: [95][25/750]	BT 0.047 (1.757)	DT 0.001 (1.713)	loss nan (nan)	prob nan (nan)	GS 29.844 (29.844)	mem 40.858
Train: [95][30/750]	BT 5.590 (1.893)	DT 5.556 (1.846)	loss nan (nan)	prob nan (nan)	GS 33.438 (33.438)	mem 41.093
Train: [95][35/750]	BT 0.099 (1.636)	DT 0.022 (1.584)	loss nan (nan)	prob nan (nan)	GS 29.625 (29.625)	mem 41.095
Train: [95][40/750]	BT 3.910 (1.681)	DT 3.841 (1.626)	loss nan (nan)	prob nan (nan)	GS 32.562 (32.562)	mem 41.221
Train: [95][45/750]	BT 0.028 (1.598)	DT 0.001 (1.544)	loss nan (nan)	prob nan (nan)	GS 29.969 (29.969)	mem 41.476
Train: [95][50/750]	BT 4.949 (1.553)	DT 4.909 (1.498)	loss nan (nan)	prob nan (nan)	GS 34.953 (34.953)	mem 41.610
Train: [95][55/750]	BT 0.056 (1.537)	DT 0.008 (1.480)	loss nan (nan)	prob nan (nan)	GS 32.859 (32.859)	mem 41.731
Train: [95][60/750]	BT 0.024 (1.432)	DT 0.001 (1.376)	loss nan (nan)	prob nan (nan)	GS 33.281 (33.281)	mem 41.735
Train: [95][65/750]	BT 0.042 (1.458)	DT 0.011 (1.404)	loss nan (nan)	prob nan (nan)	GS 28.594 (28.594)	mem 41.786
Train: [95][70/750]	BT 3.451 (1.439)	DT 3.388 (1.386)	loss nan (nan)	prob nan (nan)	GS 36.438 (36.438)	mem 41.884
Train: [95][75/750]	BT 0.028 (1.345)	DT 0.001 (1.294)	loss nan (nan)	prob nan (nan)	GS 28.766 (28.766)	mem 41.800
Train: [95][80/750]	BT 1.985 (1.388)	DT 1.953 (1.336)	loss nan (nan)	prob nan (nan)	GS 33.625 (33.625)	mem 41.821
Train: [95][85/750]	BT 0.026 (1.358)	DT 0.001 (1.306)	loss nan (nan)	prob nan (nan)	GS 35.391 (35.391)	mem 41.844
Train: [95][90/750]	BT 2.483 (1.370)	DT 2.411 (1.317)	loss nan (nan)	prob nan (nan)	GS 32.625 (32.625)	mem 41.780
Train: [95][95/750]	BT 0.036 (1.362)	DT 0.002 (1.310)	loss nan (nan)	prob nan (nan)	GS 29.688 (29.688)	mem 42.134
Train: [95][100/750]	BT 3.611 (1.331)	DT 3.577 (1.281)	loss nan (nan)	prob nan (nan)	GS 36.328 (36.328)	mem 41.852
Train: [95][105/750]	BT 0.089 (1.328)	DT 0.019 (1.276)	loss nan (nan)	prob nan (nan)	GS 32.625 (32.625)	mem 41.827
Train: [95][110/750]	BT 0.030 (1.293)	DT 0.001 (1.243)	loss nan (nan)	prob nan (nan)	GS 37.125 (37.125)	mem 41.883
Train: [95][115/750]	BT 0.090 (1.298)	DT 0.012 (1.247)	loss nan (nan)	prob nan (nan)	GS 34.344 (34.344)	mem 41.892
Train: [95][120/750]	BT 0.037 (1.293)	DT 0.002 (1.242)	loss nan (nan)	prob nan (nan)	GS 35.438 (35.438)	mem 42.325
Train: [95][125/750]	BT 0.057 (1.286)	DT 0.029 (1.235)	loss nan (nan)	prob nan (nan)	GS 31.109 (31.109)	mem 41.922
Train: [95][130/750]	BT 2.816 (1.285)	DT 2.773 (1.234)	loss nan (nan)	prob nan (nan)	GS 32.891 (32.891)	mem 41.943
Train: [95][135/750]	BT 0.067 (1.240)	DT 0.001 (1.189)	loss nan (nan)	prob nan (nan)	GS 30.344 (30.344)	mem 41.978
Train: [95][140/750]	BT 0.928 (1.267)	DT 0.876 (1.216)	loss nan (nan)	prob nan (nan)	GS 35.500 (35.500)	mem 42.016
Train: [95][145/750]	BT 0.133 (1.234)	DT 0.002 (1.183)	loss nan (nan)	prob nan (nan)	GS 35.734 (35.734)	mem 42.148
Train: [95][150/750]	BT 0.055 (1.267)	DT 0.022 (1.216)	loss nan (nan)	prob nan (nan)	GS 32.391 (32.391)	mem 41.806
Train: [95][155/750]	BT 0.032 (1.263)	DT 0.001 (1.212)	loss nan (nan)	prob nan (nan)	GS 31.688 (31.688)	mem 41.832
Train: [95][160/750]	BT 9.248 (1.282)	DT 9.218 (1.232)	loss nan (nan)	prob nan (nan)	GS 35.234 (35.234)	mem 41.921
Train: [95][165/750]	BT 0.050 (1.263)	DT 0.001 (1.213)	loss nan (nan)	prob nan (nan)	GS 30.625 (30.625)	mem 41.907
Train: [95][170/750]	BT 0.144 (1.232)	DT 0.093 (1.183)	loss nan (nan)	prob nan (nan)	GS 31.875 (31.875)	mem 42.169
Train: [95][175/750]	BT 0.064 (1.241)	DT 0.012 (1.190)	loss nan (nan)	prob nan (nan)	GS 33.594 (33.594)	mem 42.044
Train: [95][180/750]	BT 0.034 (1.235)	DT 0.002 (1.185)	loss nan (nan)	prob nan (nan)	GS 38.297 (38.297)	mem 42.130
Train: [95][185/750]	BT 0.060 (1.241)	DT 0.004 (1.192)	loss nan (nan)	prob nan (nan)	GS 27.250 (27.250)	mem 42.013
Train: [95][190/750]	BT 3.019 (1.236)	DT 2.987 (1.187)	loss nan (nan)	prob nan (nan)	GS 34.625 (34.625)	mem 42.060
Train: [95][195/750]	BT 0.076 (1.227)	DT 0.008 (1.177)	loss nan (nan)	prob nan (nan)	GS 35.359 (35.359)	mem 42.067
Train: [95][200/750]	BT 3.863 (1.227)	DT 3.820 (1.177)	loss nan (nan)	prob nan (nan)	GS 30.797 (30.797)	mem 42.075
Train: [95][205/750]	BT 0.105 (1.244)	DT 0.050 (1.194)	loss nan (nan)	prob nan (nan)	GS 34.578 (34.578)	mem 42.030
Train: [95][210/750]	BT 0.040 (1.216)	DT 0.004 (1.165)	loss nan (nan)	prob nan (nan)	GS 29.922 (29.922)	mem 42.107
Train: [95][215/750]	BT 0.027 (1.213)	DT 0.001 (1.163)	loss nan (nan)	prob nan (nan)	GS 35.344 (35.344)	mem 42.041
Train: [95][220/750]	BT 0.274 (1.221)	DT 0.230 (1.171)	loss nan (nan)	prob nan (nan)	GS 36.859 (36.859)	mem 42.079
Train: [95][225/750]	BT 0.065 (1.195)	DT 0.002 (1.145)	loss nan (nan)	prob nan (nan)	GS 32.172 (32.172)	mem 42.079
Train: [95][230/750]	BT 0.043 (1.219)	DT 0.001 (1.169)	loss nan (nan)	prob nan (nan)	GS 34.328 (34.328)	mem 42.008
Train: [95][235/750]	BT 0.059 (1.207)	DT 0.006 (1.157)	loss nan (nan)	prob nan (nan)	GS 34.047 (34.047)	mem 42.191
Train: [95][240/750]	BT 4.426 (1.220)	DT 4.371 (1.170)	loss nan (nan)	prob nan (nan)	GS 30.391 (30.391)	mem 42.133
Train: [95][245/750]	BT 0.032 (1.217)	DT 0.005 (1.167)	loss nan (nan)	prob nan (nan)	GS 30.359 (30.359)	mem 42.079
Train: [95][250/750]	BT 1.533 (1.199)	DT 1.494 (1.150)	loss nan (nan)	prob nan (nan)	GS 31.797 (31.797)	mem 42.123
Train: [95][255/750]	BT 0.032 (1.207)	DT 0.002 (1.157)	loss nan (nan)	prob nan (nan)	GS 33.297 (33.297)	mem 42.115
Train: [95][260/750]	BT 0.023 (1.199)	DT 0.001 (1.150)	loss nan (nan)	prob nan (nan)	GS 33.812 (33.812)	mem 42.067
Train: [95][265/750]	BT 0.052 (1.208)	DT 0.002 (1.159)	loss nan (nan)	prob nan (nan)	GS 32.594 (32.594)	mem 42.049
Train: [95][270/750]	BT 0.045 (1.193)	DT 0.001 (1.144)	loss nan (nan)	prob nan (nan)	GS 29.312 (29.312)	mem 42.051
Train: [95][275/750]	BT 0.028 (1.213)	DT 0.002 (1.164)	loss nan (nan)	prob nan (nan)	GS 29.750 (29.750)	mem 42.132
Train: [95][280/750]	BT 3.312 (1.204)	DT 3.281 (1.155)	loss nan (nan)	prob nan (nan)	GS 35.672 (35.672)	mem 42.170
Train: [95][285/750]	BT 0.031 (1.184)	DT 0.001 (1.135)	loss nan (nan)	prob nan (nan)	GS 30.766 (30.766)	mem 42.123
Train: [95][290/750]	BT 0.030 (1.199)	DT 0.001 (1.151)	loss nan (nan)	prob nan (nan)	GS 36.281 (36.281)	mem 42.078
Train: [95][295/750]	BT 0.031 (1.188)	DT 0.002 (1.140)	loss nan (nan)	prob nan (nan)	GS 31.484 (31.484)	mem 42.154
Train: [95][300/750]	BT 0.029 (1.196)	DT 0.005 (1.148)	loss nan (nan)	prob nan (nan)	GS 31.500 (31.500)	mem 42.174
Train: [95][305/750]	BT 0.029 (1.196)	DT 0.001 (1.149)	loss nan (nan)	prob nan (nan)	GS 34.500 (34.500)	mem 42.291
Train: [95][310/750]	BT 5.189 (1.194)	DT 5.157 (1.147)	loss nan (nan)	prob nan (nan)	GS 34.484 (34.484)	mem 42.242
Train: [95][315/750]	BT 0.033 (1.178)	DT 0.002 (1.131)	loss nan (nan)	prob nan (nan)	GS 28.578 (28.578)	mem 42.121
Train: [95][320/750]	BT 0.046 (1.175)	DT 0.005 (1.127)	loss nan (nan)	prob nan (nan)	GS 33.938 (33.938)	mem 42.195
Train: [95][325/750]	BT 0.041 (1.196)	DT 0.001 (1.149)	loss nan (nan)	prob nan (nan)	GS 30.328 (30.328)	mem 42.076
Train: [95][330/750]	BT 0.041 (1.178)	DT 0.001 (1.131)	loss nan (nan)	prob nan (nan)	GS 34.859 (34.859)	mem 42.075
Train: [95][335/750]	BT 0.058 (1.198)	DT 0.007 (1.151)	loss nan (nan)	prob nan (nan)	GS 33.062 (33.062)	mem 42.168
Train: [95][340/750]	BT 0.054 (1.190)	DT 0.002 (1.143)	loss nan (nan)	prob nan (nan)	GS 29.625 (29.625)	mem 42.145
Train: [95][345/750]	BT 0.094 (1.174)	DT 0.031 (1.127)	loss nan (nan)	prob nan (nan)	GS 27.656 (27.656)	mem 42.328
Train: [95][350/750]	BT 0.052 (1.191)	DT 0.005 (1.144)	loss nan (nan)	prob nan (nan)	GS 32.781 (32.781)	mem 42.181
Train: [95][355/750]	BT 0.073 (1.175)	DT 0.001 (1.128)	loss nan (nan)	prob nan (nan)	GS 28.641 (28.641)	mem 42.181
Train: [95][360/750]	BT 0.808 (1.193)	DT 0.778 (1.146)	loss nan (nan)	prob nan (nan)	GS 32.359 (32.359)	mem 42.165
Train: [95][365/750]	BT 0.113 (1.179)	DT 0.001 (1.132)	loss nan (nan)	prob nan (nan)	GS 26.766 (26.766)	mem 42.176
Train: [95][370/750]	BT 12.580 (1.197)	DT 12.548 (1.150)	loss nan (nan)	prob nan (nan)	GS 35.188 (35.188)	mem 42.081
Train: [95][375/750]	BT 0.028 (1.182)	DT 0.001 (1.135)	loss nan (nan)	prob nan (nan)	GS 31.547 (31.547)	mem 42.080
Train: [95][380/750]	BT 0.062 (1.171)	DT 0.003 (1.123)	loss nan (nan)	prob nan (nan)	GS 35.406 (35.406)	mem 42.139
Train: [95][385/750]	BT 0.040 (1.189)	DT 0.003 (1.141)	loss nan (nan)	prob nan (nan)	GS 27.219 (27.219)	mem 42.105
Train: [95][390/750]	BT 0.076 (1.174)	DT 0.001 (1.127)	loss nan (nan)	prob nan (nan)	GS 32.062 (32.062)	mem 42.178
Train: [95][395/750]	BT 0.039 (1.186)	DT 0.002 (1.139)	loss nan (nan)	prob nan (nan)	GS 33.562 (33.562)	mem 42.199
Train: [95][400/750]	BT 1.246 (1.179)	DT 1.127 (1.132)	loss nan (nan)	prob nan (nan)	GS 33.250 (33.250)	mem 42.124
Train: [95][405/750]	BT 0.032 (1.165)	DT 0.001 (1.118)	loss nan (nan)	prob nan (nan)	GS 30.484 (30.484)	mem 42.126
Train: [95][410/750]	BT 0.031 (1.179)	DT 0.001 (1.132)	loss nan (nan)	prob nan (nan)	GS 32.250 (32.250)	mem 42.171
Train: [95][415/750]	BT 0.034 (1.177)	DT 0.002 (1.130)	loss nan (nan)	prob nan (nan)	GS 28.453 (28.453)	mem 42.190
Train: [95][420/750]	BT 10.084 (1.187)	DT 10.008 (1.140)	loss nan (nan)	prob nan (nan)	GS 37.391 (37.391)	mem 42.185
Train: [95][425/750]	BT 0.034 (1.178)	DT 0.004 (1.131)	loss nan (nan)	prob nan (nan)	GS 34.969 (34.969)	mem 42.182
Train: [95][430/750]	BT 0.033 (1.165)	DT 0.001 (1.118)	loss nan (nan)	prob nan (nan)	GS 37.281 (37.281)	mem 42.182
Train: [95][435/750]	BT 0.032 (1.177)	DT 0.001 (1.131)	loss nan (nan)	prob nan (nan)	GS 29.594 (29.594)	mem 42.171
Train: [95][440/750]	BT 0.031 (1.171)	DT 0.001 (1.125)	loss nan (nan)	prob nan (nan)	GS 29.328 (29.328)	mem 42.171
Train: [95][445/750]	BT 0.051 (1.183)	DT 0.028 (1.136)	loss nan (nan)	prob nan (nan)	GS 33.547 (33.547)	mem 42.230
Train: [95][450/750]	BT 0.051 (1.170)	DT 0.014 (1.124)	loss nan (nan)	prob nan (nan)	GS 29.906 (29.906)	mem 42.230
Train: [95][455/750]	BT 0.039 (1.158)	DT 0.001 (1.112)	loss nan (nan)	prob nan (nan)	GS 29.125 (29.125)	mem 42.231
Train: [95][460/750]	BT 1.140 (1.172)	DT 1.074 (1.125)	loss nan (nan)	prob nan (nan)	GS 33.391 (33.391)	mem 42.216
Train: [95][465/750]	BT 0.029 (1.159)	DT 0.001 (1.113)	loss nan (nan)	prob nan (nan)	GS 31.984 (31.984)	mem 42.134
Train: [95][470/750]	BT 0.064 (1.173)	DT 0.004 (1.127)	loss nan (nan)	prob nan (nan)	GS 33.094 (33.094)	mem 42.205
Train: [95][475/750]	BT 0.036 (1.161)	DT 0.002 (1.115)	loss nan (nan)	prob nan (nan)	GS 31.469 (31.469)	mem 42.230
Train: [95][480/750]	BT 14.169 (1.179)	DT 14.119 (1.133)	loss nan (nan)	prob nan (nan)	GS 38.000 (38.000)	mem 42.431
Train: [95][485/750]	BT 0.030 (1.167)	DT 0.002 (1.121)	loss nan (nan)	prob nan (nan)	GS 29.062 (29.062)	mem 42.168
Train: [95][490/750]	BT 0.107 (1.156)	DT 0.013 (1.110)	loss nan (nan)	prob nan (nan)	GS 31.734 (31.734)	mem 42.230
Train: [95][495/750]	BT 0.044 (1.167)	DT 0.001 (1.121)	loss nan (nan)	prob nan (nan)	GS 32.016 (32.016)	mem 41.860
Train: [95][500/750]	BT 0.030 (1.156)	DT 0.001 (1.109)	loss nan (nan)	prob nan (nan)	GS 29.656 (29.656)	mem 41.863
Train: [95][505/750]	BT 0.052 (1.170)	DT 0.009 (1.124)	loss nan (nan)	prob nan (nan)	GS 28.328 (28.328)	mem 42.033
Train: [95][510/750]	BT 0.035 (1.159)	DT 0.003 (1.113)	loss nan (nan)	prob nan (nan)	GS 28.484 (28.484)	mem 42.146
Train: [95][515/750]	BT 0.030 (1.148)	DT 0.002 (1.102)	loss nan (nan)	prob nan (nan)	GS 28.438 (28.438)	mem 42.042
Train: [95][520/750]	BT 0.082 (1.163)	DT 0.001 (1.117)	loss nan (nan)	prob nan (nan)	GS 33.953 (33.953)	mem 42.139
Train: [95][525/750]	BT 0.050 (1.152)	DT 0.012 (1.106)	loss nan (nan)	prob nan (nan)	GS 33.391 (33.391)	mem 42.102
Train: [95][530/750]	BT 0.029 (1.169)	DT 0.001 (1.123)	loss nan (nan)	prob nan (nan)	GS 34.328 (34.328)	mem 42.005
Train: [95][535/750]	BT 0.027 (1.158)	DT 0.001 (1.112)	loss nan (nan)	prob nan (nan)	GS 28.469 (28.469)	mem 42.005
Train: [95][540/750]	BT 11.366 (1.169)	DT 11.322 (1.123)	loss nan (nan)	prob nan (nan)	GS 33.547 (33.547)	mem 42.171
Train: [95][545/750]	BT 0.053 (1.159)	DT 0.001 (1.113)	loss nan (nan)	prob nan (nan)	GS 27.109 (27.109)	mem 42.041
Train: [95][550/750]	BT 0.062 (1.149)	DT 0.015 (1.103)	loss nan (nan)	prob nan (nan)	GS 37.109 (37.109)	mem 42.044
Train: [95][555/750]	BT 0.027 (1.165)	DT 0.001 (1.120)	loss nan (nan)	prob nan (nan)	GS 29.266 (29.266)	mem 42.006
Train: [95][560/750]	BT 0.024 (1.155)	DT 0.002 (1.110)	loss nan (nan)	prob nan (nan)	GS 33.906 (33.906)	mem 42.007
Train: [95][565/750]	BT 0.043 (1.170)	DT 0.003 (1.124)	loss nan (nan)	prob nan (nan)	GS 29.875 (29.875)	mem 42.018
Train: [95][570/750]	BT 0.032 (1.160)	DT 0.002 (1.114)	loss nan (nan)	prob nan (nan)	GS 30.875 (30.875)	mem 42.019
Train: [95][575/750]	BT 0.042 (1.150)	DT 0.002 (1.105)	loss nan (nan)	prob nan (nan)	GS 28.766 (28.766)	mem 42.049
Train: [95][580/750]	BT 0.111 (1.158)	DT 0.024 (1.112)	loss nan (nan)	prob nan (nan)	GS 33.516 (33.516)	mem 42.100
Train: [95][585/750]	BT 0.167 (1.149)	DT 0.033 (1.103)	loss nan (nan)	prob nan (nan)	GS 28.438 (28.438)	mem 42.178
Train: [95][590/750]	BT 0.029 (1.163)	DT 0.001 (1.118)	loss nan (nan)	prob nan (nan)	GS 29.375 (29.375)	mem 42.130
Train: [95][595/750]	BT 0.032 (1.154)	DT 0.001 (1.108)	loss nan (nan)	prob nan (nan)	GS 31.938 (31.938)	mem 42.130
Train: [95][600/750]	BT 15.851 (1.171)	DT 15.812 (1.125)	loss nan (nan)	prob nan (nan)	GS 35.281 (35.281)	mem 42.094
Train: [95][605/750]	BT 0.035 (1.162)	DT 0.001 (1.116)	loss nan (nan)	prob nan (nan)	GS 30.406 (30.406)	mem 42.158
Train: [95][610/750]	BT 0.029 (1.153)	DT 0.003 (1.107)	loss nan (nan)	prob nan (nan)	GS 32.438 (32.438)	mem 42.103
Train: [95][615/750]	BT 0.034 (1.165)	DT 0.001 (1.119)	loss nan (nan)	prob nan (nan)	GS 27.578 (27.578)	mem 42.183
Train: [95][620/750]	BT 0.035 (1.156)	DT 0.001 (1.110)	loss nan (nan)	prob nan (nan)	GS 35.156 (35.156)	mem 42.182
Train: [95][625/750]	BT 0.031 (1.169)	DT 0.001 (1.124)	loss nan (nan)	prob nan (nan)	GS 29.984 (29.984)	mem 42.217
Train: [95][630/750]	BT 0.028 (1.160)	DT 0.001 (1.115)	loss nan (nan)	prob nan (nan)	GS 34.328 (34.328)	mem 42.161
Train: [95][635/750]	BT 0.053 (1.151)	DT 0.011 (1.106)	loss nan (nan)	prob nan (nan)	GS 28.453 (28.453)	mem 42.162
Train: [95][640/750]	BT 0.080 (1.165)	DT 0.001 (1.120)	loss nan (nan)	prob nan (nan)	GS 36.516 (36.516)	mem 42.082
Train: [95][645/750]	BT 0.053 (1.157)	DT 0.002 (1.111)	loss nan (nan)	prob nan (nan)	GS 41.125 (41.125)	mem 42.082
Train: [95][650/750]	BT 0.028 (1.168)	DT 0.001 (1.123)	loss nan (nan)	prob nan (nan)	GS 32.625 (32.625)	mem 42.290
Train: [95][655/750]	BT 0.033 (1.159)	DT 0.001 (1.114)	loss nan (nan)	prob nan (nan)	GS 31.203 (31.203)	mem 42.225
Train: [95][660/750]	BT 15.182 (1.174)	DT 15.148 (1.128)	loss nan (nan)	prob nan (nan)	GS 36.438 (36.438)	mem 42.093
Train: [95][665/750]	BT 0.029 (1.165)	DT 0.001 (1.120)	loss nan (nan)	prob nan (nan)	GS 29.828 (29.828)	mem 42.096
Train: [95][670/750]	BT 0.028 (1.156)	DT 0.001 (1.112)	loss nan (nan)	prob nan (nan)	GS 36.719 (36.719)	mem 42.096
Train: [95][675/750]	BT 0.026 (1.165)	DT 0.001 (1.120)	loss nan (nan)	prob nan (nan)	GS 30.172 (30.172)	mem 42.227
Train: [95][680/750]	BT 0.051 (1.157)	DT 0.006 (1.112)	loss nan (nan)	prob nan (nan)	GS 33.281 (33.281)	mem 42.271
Train: [95][685/750]	BT 0.028 (1.169)	DT 0.001 (1.124)	loss nan (nan)	prob nan (nan)	GS 31.500 (31.500)	mem 42.223
Train: [95][690/750]	BT 0.076 (1.161)	DT 0.029 (1.116)	loss nan (nan)	prob nan (nan)	GS 33.266 (33.266)	mem 42.320
Train: [95][695/750]	BT 0.139 (1.153)	DT 0.010 (1.108)	loss nan (nan)	prob nan (nan)	GS 28.641 (28.641)	mem 42.194
Train: [95][700/750]	BT 0.055 (1.162)	DT 0.010 (1.118)	loss nan (nan)	prob nan (nan)	GS 34.219 (34.219)	mem 42.238
Train: [95][705/750]	BT 0.034 (1.154)	DT 0.001 (1.110)	loss nan (nan)	prob nan (nan)	GS 32.281 (32.281)	mem 42.245
arpack error, retry= 0
Train: [95][710/750]	BT 0.054 (1.163)	DT 0.007 (1.119)	loss nan (nan)	prob nan (nan)	GS 31.172 (31.172)	mem 42.214
Train: [95][715/750]	BT 0.059 (1.156)	DT 0.003 (1.111)	loss nan (nan)	prob nan (nan)	GS 30.531 (30.531)	mem 42.402
Train: [95][720/750]	BT 12.115 (1.165)	DT 12.083 (1.120)	loss nan (nan)	prob nan (nan)	GS 34.766 (34.766)	mem 42.233
Train: [95][725/750]	BT 0.035 (1.157)	DT 0.001 (1.112)	loss nan (nan)	prob nan (nan)	GS 30.562 (30.562)	mem 42.267
Train: [95][730/750]	BT 0.114 (1.149)	DT 0.005 (1.105)	loss nan (nan)	prob nan (nan)	GS 37.000 (37.000)	mem 42.234
Train: [95][735/750]	BT 0.056 (1.156)	DT 0.001 (1.111)	loss nan (nan)	prob nan (nan)	GS 28.078 (28.078)	mem 41.620
Train: [95][740/750]	BT 0.036 (1.148)	DT 0.002 (1.104)	loss nan (nan)	prob nan (nan)	GS 32.562 (32.562)	mem 41.620
Train: [95][745/750]	BT 0.029 (1.147)	DT 0.001 (1.103)	loss nan (nan)	prob nan (nan)	GS 30.094 (30.094)	mem 9.805
Train: [95][750/750]	BT 0.030 (1.140)	DT 0.001 (1.095)	loss nan (nan)	prob nan (nan)	GS 35.438 (35.438)	mem 9.805
Train: [95][755/750]	BT 0.046 (1.132)	DT 0.001 (1.088)	loss nan (nan)	prob nan (nan)	GS 34.156 (34.156)	mem 9.807
epoch 95, total time 857.57
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [96][1/750]	BT 23.568 (23.568)	DT 23.451 (23.451)	loss nan (nan)	prob nan (nan)	GS 34.906 (34.906)	mem 40.794
Train: [96][5/750]	BT 0.038 (4.830)	DT 0.002 (4.780)	loss nan (nan)	prob nan (nan)	GS 32.406 (32.406)	mem 40.848
Train: [96][10/750]	BT 0.138 (2.456)	DT 0.006 (2.394)	loss nan (nan)	prob nan (nan)	GS 35.469 (35.469)	mem 40.948
Train: [96][15/750]	BT 0.038 (2.649)	DT 0.007 (2.592)	loss nan (nan)	prob nan (nan)	GS 35.422 (35.422)	mem 41.603
Train: [96][20/750]	BT 0.152 (2.009)	DT 0.121 (1.951)	loss nan (nan)	prob nan (nan)	GS 35.406 (35.406)	mem 41.603
Train: [96][25/750]	BT 5.642 (1.841)	DT 5.607 (1.786)	loss nan (nan)	prob nan (nan)	GS 30.844 (30.844)	mem 41.637
Train: [96][30/750]	BT 0.066 (1.741)	DT 0.008 (1.687)	loss nan (nan)	prob nan (nan)	GS 33.234 (33.234)	mem 41.621
Train: [96][35/750]	BT 0.031 (1.499)	DT 0.001 (1.447)	loss nan (nan)	prob nan (nan)	GS 31.609 (31.609)	mem 41.622
Train: [96][40/750]	BT 0.267 (1.620)	DT 0.232 (1.571)	loss nan (nan)	prob nan (nan)	GS 34.578 (34.578)	mem 42.044
Train: [96][45/750]	BT 0.059 (1.565)	DT 0.024 (1.516)	loss nan (nan)	prob nan (nan)	GS 34.859 (34.859)	mem 41.781
Train: [96][50/750]	BT 4.819 (1.509)	DT 4.789 (1.461)	loss nan (nan)	prob nan (nan)	GS 31.188 (31.188)	mem 41.860
Train: [96][55/750]	BT 0.059 (1.393)	DT 0.016 (1.346)	loss nan (nan)	prob nan (nan)	GS 28.281 (28.281)	mem 41.967
Train: [96][60/750]	BT 0.062 (1.373)	DT 0.011 (1.326)	loss nan (nan)	prob nan (nan)	GS 29.922 (29.922)	mem 41.924
Train: [96][65/750]	BT 0.039 (1.346)	DT 0.002 (1.299)	loss nan (nan)	prob nan (nan)	GS 29.578 (29.578)	mem 42.056
Train: [96][70/750]	BT 0.044 (1.388)	DT 0.004 (1.340)	loss nan (nan)	prob nan (nan)	GS 34.812 (34.812)	mem 41.914
Train: [96][75/750]	BT 0.031 (1.303)	DT 0.001 (1.255)	loss nan (nan)	prob nan (nan)	GS 31.484 (31.484)	mem 41.843
Train: [96][80/750]	BT 11.774 (1.415)	DT 11.744 (1.367)	loss nan (nan)	prob nan (nan)	GS 32.781 (32.781)	mem 41.869
Train: [96][85/750]	BT 0.032 (1.333)	DT 0.001 (1.287)	loss nan (nan)	prob nan (nan)	GS 28.859 (28.859)	mem 41.869
Train: [96][90/750]	BT 1.806 (1.282)	DT 1.740 (1.236)	loss nan (nan)	prob nan (nan)	GS 34.906 (34.906)	mem 41.877
Train: [96][95/750]	BT 0.036 (1.293)	DT 0.005 (1.246)	loss nan (nan)	prob nan (nan)	GS 33.219 (33.219)	mem 42.071
Train: [96][100/750]	BT 0.064 (1.255)	DT 0.012 (1.209)	loss nan (nan)	prob nan (nan)	GS 33.984 (33.984)	mem 42.040
Train: [96][105/750]	BT 0.070 (1.304)	DT 0.002 (1.257)	loss nan (nan)	prob nan (nan)	GS 30.734 (30.734)	mem 42.054
Train: [96][110/750]	BT 2.488 (1.269)	DT 2.447 (1.222)	loss nan (nan)	prob nan (nan)	GS 35.797 (35.797)	mem 41.988
Train: [96][115/750]	BT 0.060 (1.284)	DT 0.008 (1.237)	loss nan (nan)	prob nan (nan)	GS 35.906 (35.906)	mem 42.074
Train: [96][120/750]	BT 0.056 (1.278)	DT 0.006 (1.231)	loss nan (nan)	prob nan (nan)	GS 30.531 (30.531)	mem 42.016
Train: [96][125/750]	BT 0.052 (1.235)	DT 0.002 (1.187)	loss nan (nan)	prob nan (nan)	GS 30.391 (30.391)	mem 41.948
Train: [96][130/750]	BT 0.038 (1.277)	DT 0.006 (1.229)	loss nan (nan)	prob nan (nan)	GS 35.812 (35.812)	mem 42.162
Train: [96][135/750]	BT 0.094 (1.251)	DT 0.025 (1.203)	loss nan (nan)	prob nan (nan)	GS 29.812 (29.812)	mem 42.074
Train: [96][140/750]	BT 8.605 (1.275)	DT 8.572 (1.228)	loss nan (nan)	prob nan (nan)	GS 31.141 (31.141)	mem 42.064
Train: [96][145/750]	BT 0.031 (1.233)	DT 0.001 (1.186)	loss nan (nan)	prob nan (nan)	GS 34.109 (34.109)	mem 42.067
Train: [96][150/750]	BT 3.825 (1.226)	DT 3.756 (1.179)	loss nan (nan)	prob nan (nan)	GS 36.438 (36.438)	mem 42.127
Train: [96][155/750]	BT 0.030 (1.228)	DT 0.001 (1.181)	loss nan (nan)	prob nan (nan)	GS 30.250 (30.250)	mem 42.112
Train: [96][160/750]	BT 0.075 (1.217)	DT 0.001 (1.170)	loss nan (nan)	prob nan (nan)	GS 34.297 (34.297)	mem 42.199
Train: [96][165/750]	BT 0.044 (1.235)	DT 0.001 (1.188)	loss nan (nan)	prob nan (nan)	GS 32.547 (32.547)	mem 42.148
Train: [96][170/750]	BT 2.372 (1.217)	DT 2.340 (1.170)	loss nan (nan)	prob nan (nan)	GS 34.016 (34.016)	mem 42.288
Train: [96][175/750]	BT 0.032 (1.212)	DT 0.001 (1.165)	loss nan (nan)	prob nan (nan)	GS 28.312 (28.312)	mem 42.244
Train: [96][180/750]	BT 0.024 (1.214)	DT 0.001 (1.167)	loss nan (nan)	prob nan (nan)	GS 34.047 (34.047)	mem 42.119
Train: [96][185/750]	BT 0.119 (1.194)	DT 0.002 (1.147)	loss nan (nan)	prob nan (nan)	GS 30.453 (30.453)	mem 42.121
Train: [96][190/750]	BT 0.033 (1.215)	DT 0.001 (1.168)	loss nan (nan)	prob nan (nan)	GS 30.750 (30.750)	mem 42.146
Train: [96][195/750]	BT 0.169 (1.202)	DT 0.011 (1.155)	loss nan (nan)	prob nan (nan)	GS 32.203 (32.203)	mem 42.119
Train: [96][200/750]	BT 7.552 (1.218)	DT 7.449 (1.170)	loss nan (nan)	prob nan (nan)	GS 36.172 (36.172)	mem 42.120
Train: [96][205/750]	BT 0.053 (1.211)	DT 0.007 (1.163)	loss nan (nan)	prob nan (nan)	GS 32.938 (32.938)	mem 42.248
Train: [96][210/750]	BT 1.399 (1.190)	DT 1.358 (1.142)	loss nan (nan)	prob nan (nan)	GS 35.344 (35.344)	mem 42.247
Train: [96][215/750]	BT 0.106 (1.193)	DT 0.001 (1.145)	loss nan (nan)	prob nan (nan)	GS 29.953 (29.953)	mem 42.249
Train: [96][220/750]	BT 0.042 (1.183)	DT 0.001 (1.135)	loss nan (nan)	prob nan (nan)	GS 31.266 (31.266)	mem 42.195
Train: [96][225/750]	BT 0.037 (1.182)	DT 0.005 (1.133)	loss nan (nan)	prob nan (nan)	GS 31.953 (31.953)	mem 42.150
Train: [96][230/750]	BT 1.175 (1.187)	DT 1.144 (1.139)	loss nan (nan)	prob nan (nan)	GS 34.281 (34.281)	mem 42.252
Train: [96][235/750]	BT 0.063 (1.163)	DT 0.011 (1.115)	loss nan (nan)	prob nan (nan)	GS 31.875 (31.875)	mem 42.218
Train: [96][240/750]	BT 0.038 (1.186)	DT 0.002 (1.138)	loss nan (nan)	prob nan (nan)	GS 35.828 (35.828)	mem 41.943
Train: [96][245/750]	BT 0.055 (1.179)	DT 0.005 (1.131)	loss nan (nan)	prob nan (nan)	GS 30.516 (30.516)	mem 42.154
Train: [96][250/750]	BT 6.001 (1.190)	DT 5.966 (1.142)	loss nan (nan)	prob nan (nan)	GS 34.734 (34.734)	mem 41.890
Train: [96][255/750]	BT 0.040 (1.175)	DT 0.002 (1.127)	loss nan (nan)	prob nan (nan)	GS 35.281 (35.281)	mem 42.047
Train: [96][260/750]	BT 6.506 (1.179)	DT 6.390 (1.130)	loss nan (nan)	prob nan (nan)	GS 32.688 (32.688)	mem 42.001
Train: [96][265/750]	BT 0.033 (1.181)	DT 0.001 (1.133)	loss nan (nan)	prob nan (nan)	GS 30.344 (30.344)	mem 42.080
Train: [96][270/750]	BT 0.067 (1.161)	DT 0.012 (1.112)	loss nan (nan)	prob nan (nan)	GS 30.266 (30.266)	mem 42.030
Train: [96][275/750]	BT 0.057 (1.171)	DT 0.002 (1.122)	loss nan (nan)	prob nan (nan)	GS 32.656 (32.656)	mem 41.993
Train: [96][280/750]	BT 0.081 (1.171)	DT 0.029 (1.122)	loss nan (nan)	prob nan (nan)	GS 32.141 (32.141)	mem 41.962
Train: [96][285/750]	BT 0.033 (1.167)	DT 0.001 (1.119)	loss nan (nan)	prob nan (nan)	GS 28.562 (28.562)	mem 42.058
Train: [96][290/750]	BT 0.074 (1.182)	DT 0.025 (1.133)	loss nan (nan)	prob nan (nan)	GS 34.172 (34.172)	mem 42.088
Train: [96][295/750]	BT 0.044 (1.163)	DT 0.008 (1.114)	loss nan (nan)	prob nan (nan)	GS 33.547 (33.547)	mem 42.177
Train: [96][300/750]	BT 11.890 (1.193)	DT 11.851 (1.144)	loss nan (nan)	prob nan (nan)	GS 31.938 (31.938)	mem 42.023
Train: [96][305/750]	BT 0.023 (1.174)	DT 0.001 (1.126)	loss nan (nan)	prob nan (nan)	GS 27.906 (27.906)	mem 42.025
Train: [96][310/750]	BT 1.323 (1.160)	DT 1.281 (1.112)	loss nan (nan)	prob nan (nan)	GS 36.297 (36.297)	mem 42.018
Train: [96][315/750]	BT 0.054 (1.184)	DT 0.011 (1.136)	loss nan (nan)	prob nan (nan)	GS 31.672 (31.672)	mem 42.305
Train: [96][320/750]	BT 0.049 (1.166)	DT 0.007 (1.118)	loss nan (nan)	prob nan (nan)	GS 31.828 (31.828)	mem 42.238
Train: [96][325/750]	BT 0.027 (1.185)	DT 0.001 (1.137)	loss nan (nan)	prob nan (nan)	GS 34.062 (34.062)	mem 42.178
Train: [96][330/750]	BT 0.143 (1.168)	DT 0.020 (1.120)	loss nan (nan)	prob nan (nan)	GS 31.859 (31.859)	mem 42.107
Train: [96][335/750]	BT 0.127 (1.158)	DT 0.024 (1.109)	loss nan (nan)	prob nan (nan)	GS 32.109 (32.109)	mem 42.004
Train: [96][340/750]	BT 0.106 (1.173)	DT 0.011 (1.124)	loss nan (nan)	prob nan (nan)	GS 28.578 (28.578)	mem 42.110
Train: [96][345/750]	BT 0.051 (1.157)	DT 0.001 (1.108)	loss nan (nan)	prob nan (nan)	GS 28.828 (28.828)	mem 42.109
Train: [96][350/750]	BT 0.032 (1.178)	DT 0.001 (1.130)	loss nan (nan)	prob nan (nan)	GS 30.625 (30.625)	mem 42.133
Train: [96][355/750]	BT 0.066 (1.162)	DT 0.021 (1.114)	loss nan (nan)	prob nan (nan)	GS 31.203 (31.203)	mem 42.133
Train: [96][360/750]	BT 8.085 (1.180)	DT 8.058 (1.131)	loss nan (nan)	prob nan (nan)	GS 32.781 (32.781)	mem 42.101
Train: [96][365/750]	BT 0.038 (1.164)	DT 0.012 (1.116)	loss nan (nan)	prob nan (nan)	GS 30.797 (30.797)	mem 42.125
Train: [96][370/750]	BT 0.031 (1.160)	DT 0.001 (1.112)	loss nan (nan)	prob nan (nan)	GS 32.234 (32.234)	mem 42.118
Train: [96][375/750]	BT 0.044 (1.167)	DT 0.010 (1.119)	loss nan (nan)	prob nan (nan)	GS 33.078 (33.078)	mem 42.156
Train: [96][380/750]	BT 2.534 (1.159)	DT 2.462 (1.110)	loss nan (nan)	prob nan (nan)	GS 36.312 (36.312)	mem 42.093
Train: [96][385/750]	BT 0.026 (1.171)	DT 0.001 (1.123)	loss nan (nan)	prob nan (nan)	GS 28.812 (28.812)	mem 42.156
Train: [96][390/750]	BT 0.037 (1.157)	DT 0.001 (1.109)	loss nan (nan)	prob nan (nan)	GS 34.938 (34.938)	mem 42.156
Train: [96][395/750]	BT 0.037 (1.159)	DT 0.001 (1.110)	loss nan (nan)	prob nan (nan)	GS 31.578 (31.578)	mem 42.160
Train: [96][400/750]	BT 0.025 (1.157)	DT 0.001 (1.109)	loss nan (nan)	prob nan (nan)	GS 35.812 (35.812)	mem 42.163
Train: [96][405/750]	BT 0.055 (1.143)	DT 0.001 (1.095)	loss nan (nan)	prob nan (nan)	GS 31.578 (31.578)	mem 42.243
Train: [96][410/750]	BT 0.029 (1.165)	DT 0.001 (1.117)	loss nan (nan)	prob nan (nan)	GS 33.984 (33.984)	mem 42.198
Train: [96][415/750]	BT 0.034 (1.151)	DT 0.002 (1.103)	loss nan (nan)	prob nan (nan)	GS 31.562 (31.562)	mem 42.199
Train: [96][420/750]	BT 0.057 (1.157)	DT 0.002 (1.110)	loss nan (nan)	prob nan (nan)	GS 27.438 (27.438)	mem 42.106
Train: [96][425/750]	BT 0.038 (1.144)	DT 0.001 (1.097)	loss nan (nan)	prob nan (nan)	GS 27.438 (27.438)	mem 42.171
Train: [96][430/750]	BT 11.068 (1.158)	DT 11.035 (1.111)	loss nan (nan)	prob nan (nan)	GS 35.453 (35.453)	mem 42.392
Train: [96][435/750]	BT 0.117 (1.150)	DT 0.004 (1.103)	loss nan (nan)	prob nan (nan)	GS 27.672 (27.672)	mem 42.221
Train: [96][440/750]	BT 2.463 (1.143)	DT 2.432 (1.096)	loss nan (nan)	prob nan (nan)	GS 34.922 (34.922)	mem 42.580
Train: [96][445/750]	BT 0.048 (1.162)	DT 0.001 (1.114)	loss nan (nan)	prob nan (nan)	GS 26.438 (26.438)	mem 42.128
Train: [96][450/750]	BT 0.030 (1.150)	DT 0.004 (1.102)	loss nan (nan)	prob nan (nan)	GS 37.594 (37.594)	mem 42.129
Train: [96][455/750]	BT 0.055 (1.165)	DT 0.001 (1.117)	loss nan (nan)	prob nan (nan)	GS 33.203 (33.203)	mem 42.120
Train: [96][460/750]	BT 0.043 (1.162)	DT 0.001 (1.115)	loss nan (nan)	prob nan (nan)	GS 34.266 (34.266)	mem 42.110
Train: [96][465/750]	BT 0.032 (1.150)	DT 0.002 (1.103)	loss nan (nan)	prob nan (nan)	GS 33.359 (33.359)	mem 42.116
Train: [96][470/750]	BT 0.032 (1.164)	DT 0.001 (1.117)	loss nan (nan)	prob nan (nan)	GS 37.359 (37.359)	mem 42.148
Train: [96][475/750]	BT 0.049 (1.152)	DT 0.001 (1.105)	loss nan (nan)	prob nan (nan)	GS 33.562 (33.562)	mem 42.148
Train: [96][480/750]	BT 8.185 (1.166)	DT 8.085 (1.119)	loss nan (nan)	prob nan (nan)	GS 31.719 (31.719)	mem 42.180
Train: [96][485/750]	BT 0.032 (1.154)	DT 0.001 (1.107)	loss nan (nan)	prob nan (nan)	GS 28.844 (28.844)	mem 42.180
Train: [96][490/750]	BT 6.859 (1.157)	DT 6.805 (1.110)	loss nan (nan)	prob nan (nan)	GS 37.453 (37.453)	mem 42.181
Train: [96][495/750]	BT 0.035 (1.156)	DT 0.001 (1.108)	loss nan (nan)	prob nan (nan)	GS 27.594 (27.594)	mem 42.151
Train: [96][500/750]	BT 0.047 (1.144)	DT 0.001 (1.097)	loss nan (nan)	prob nan (nan)	GS 36.359 (36.359)	mem 42.153
Train: [96][505/750]	BT 0.031 (1.155)	DT 0.003 (1.108)	loss nan (nan)	prob nan (nan)	GS 26.156 (26.156)	mem 42.109
Train: [96][510/750]	BT 0.064 (1.144)	DT 0.005 (1.097)	loss nan (nan)	prob nan (nan)	GS 34.875 (34.875)	mem 42.154
Train: [96][515/750]	BT 0.035 (1.159)	DT 0.001 (1.112)	loss nan (nan)	prob nan (nan)	GS 32.312 (32.312)	mem 42.196
Train: [96][520/750]	BT 0.060 (1.148)	DT 0.003 (1.101)	loss nan (nan)	prob nan (nan)	GS 37.078 (37.078)	mem 42.196
Train: [96][525/750]	BT 0.113 (1.142)	DT 0.044 (1.095)	loss nan (nan)	prob nan (nan)	GS 26.016 (26.016)	mem 42.197
Train: [96][530/750]	BT 0.053 (1.152)	DT 0.013 (1.105)	loss nan (nan)	prob nan (nan)	GS 39.203 (39.203)	mem 42.202
Train: [96][535/750]	BT 0.044 (1.142)	DT 0.005 (1.095)	loss nan (nan)	prob nan (nan)	GS 32.547 (32.547)	mem 42.203
Train: [96][540/750]	BT 3.116 (1.159)	DT 3.084 (1.112)	loss nan (nan)	prob nan (nan)	GS 37.500 (37.500)	mem 42.174
Train: [96][545/750]	BT 0.040 (1.148)	DT 0.014 (1.102)	loss nan (nan)	prob nan (nan)	GS 35.328 (35.328)	mem 42.204
Train: [96][550/750]	BT 5.460 (1.156)	DT 5.393 (1.110)	loss nan (nan)	prob nan (nan)	GS 34.828 (34.828)	mem 42.129
Train: [96][555/750]	BT 0.082 (1.153)	DT 0.022 (1.106)	loss nan (nan)	prob nan (nan)	GS 38.422 (38.422)	mem 42.182
Train: [96][560/750]	BT 7.279 (1.156)	DT 7.230 (1.109)	loss nan (nan)	prob nan (nan)	GS 36.359 (36.359)	mem 42.201
Train: [96][565/750]	BT 0.026 (1.156)	DT 0.003 (1.110)	loss nan (nan)	prob nan (nan)	GS 26.250 (26.250)	mem 42.189
Train: [96][570/750]	BT 0.092 (1.147)	DT 0.013 (1.100)	loss nan (nan)	prob nan (nan)	GS 33.516 (33.516)	mem 42.289
Train: [96][575/750]	BT 0.057 (1.149)	DT 0.005 (1.103)	loss nan (nan)	prob nan (nan)	GS 29.000 (29.000)	mem 42.149
Train: [96][580/750]	BT 0.024 (1.146)	DT 0.001 (1.099)	loss nan (nan)	prob nan (nan)	GS 34.797 (34.797)	mem 42.145
Train: [96][585/750]	BT 0.047 (1.146)	DT 0.007 (1.100)	loss nan (nan)	prob nan (nan)	GS 32.547 (32.547)	mem 42.176
Train: [96][590/750]	BT 0.035 (1.152)	DT 0.002 (1.105)	loss nan (nan)	prob nan (nan)	GS 34.078 (34.078)	mem 42.413
Train: [96][595/750]	BT 0.091 (1.143)	DT 0.004 (1.096)	loss nan (nan)	prob nan (nan)	GS 32.406 (32.406)	mem 42.541
Train: [96][600/750]	BT 2.060 (1.155)	DT 2.029 (1.109)	loss nan (nan)	prob nan (nan)	GS 30.516 (30.516)	mem 42.213
Train: [96][605/750]	BT 0.039 (1.146)	DT 0.001 (1.099)	loss nan (nan)	prob nan (nan)	GS 32.219 (32.219)	mem 42.231
Train: [96][610/750]	BT 8.212 (1.154)	DT 8.144 (1.108)	loss nan (nan)	prob nan (nan)	GS 33.484 (33.484)	mem 42.216
Train: [96][615/750]	BT 0.037 (1.146)	DT 0.005 (1.100)	loss nan (nan)	prob nan (nan)	GS 32.516 (32.516)	mem 42.218
Train: [96][620/750]	BT 3.110 (1.142)	DT 3.078 (1.096)	loss nan (nan)	prob nan (nan)	GS 31.625 (31.625)	mem 42.139
Train: [96][625/750]	BT 0.032 (1.147)	DT 0.001 (1.101)	loss nan (nan)	prob nan (nan)	GS 33.469 (33.469)	mem 42.197
Train: [96][630/750]	BT 0.030 (1.139)	DT 0.002 (1.092)	loss nan (nan)	prob nan (nan)	GS 28.797 (28.797)	mem 42.198
Train: [96][635/750]	BT 0.033 (1.148)	DT 0.001 (1.101)	loss nan (nan)	prob nan (nan)	GS 33.016 (33.016)	mem 42.328
Train: [96][640/750]	BT 0.040 (1.143)	DT 0.001 (1.096)	loss nan (nan)	prob nan (nan)	GS 34.797 (34.797)	mem 42.238
Train: [96][645/750]	BT 0.044 (1.134)	DT 0.002 (1.088)	loss nan (nan)	prob nan (nan)	GS 29.922 (29.922)	mem 42.237
Train: [96][650/750]	BT 0.079 (1.149)	DT 0.012 (1.102)	loss nan (nan)	prob nan (nan)	GS 33.047 (33.047)	mem 42.242
Train: [96][655/750]	BT 0.024 (1.140)	DT 0.001 (1.093)	loss nan (nan)	prob nan (nan)	GS 32.156 (32.156)	mem 42.242
Train: [96][660/750]	BT 4.396 (1.151)	DT 4.290 (1.104)	loss nan (nan)	prob nan (nan)	GS 35.344 (35.344)	mem 42.516
Train: [96][665/750]	BT 0.057 (1.142)	DT 0.011 (1.096)	loss nan (nan)	prob nan (nan)	GS 38.125 (38.125)	mem 42.420
Train: [96][670/750]	BT 10.075 (1.149)	DT 10.022 (1.103)	loss nan (nan)	prob nan (nan)	GS 30.859 (30.859)	mem 42.348
Train: [96][675/750]	BT 0.040 (1.148)	DT 0.012 (1.102)	loss nan (nan)	prob nan (nan)	GS 30.750 (30.750)	mem 42.232
Train: [96][680/750]	BT 0.068 (1.140)	DT 0.006 (1.094)	loss nan (nan)	prob nan (nan)	GS 37.531 (37.531)	mem 42.466
Train: [96][685/750]	BT 0.033 (1.150)	DT 0.001 (1.103)	loss nan (nan)	prob nan (nan)	GS 32.016 (32.016)	mem 42.200
Train: [96][690/750]	BT 0.031 (1.142)	DT 0.001 (1.095)	loss nan (nan)	prob nan (nan)	GS 35.125 (35.125)	mem 42.200
Train: [96][695/750]	BT 0.039 (1.143)	DT 0.004 (1.097)	loss nan (nan)	prob nan (nan)	GS 31.062 (31.062)	mem 42.200
Train: [96][700/750]	BT 0.071 (1.147)	DT 0.003 (1.101)	loss nan (nan)	prob nan (nan)	GS 35.469 (35.469)	mem 42.215
Train: [96][705/750]	BT 0.067 (1.139)	DT 0.036 (1.093)	loss nan (nan)	prob nan (nan)	GS 33.641 (33.641)	mem 42.181
Train: [96][710/750]	BT 0.031 (1.148)	DT 0.001 (1.102)	loss nan (nan)	prob nan (nan)	GS 32.047 (32.047)	mem 42.270
Train: [96][715/750]	BT 0.042 (1.141)	DT 0.001 (1.094)	loss nan (nan)	prob nan (nan)	GS 33.844 (33.844)	mem 42.201
Train: [96][720/750]	BT 8.696 (1.150)	DT 8.664 (1.103)	loss nan (nan)	prob nan (nan)	GS 34.219 (34.219)	mem 42.256
Train: [96][725/750]	BT 0.052 (1.142)	DT 0.002 (1.096)	loss nan (nan)	prob nan (nan)	GS 28.844 (28.844)	mem 42.254
Train: [96][730/750]	BT 7.805 (1.145)	DT 7.762 (1.099)	loss nan (nan)	prob nan (nan)	GS 36.172 (36.172)	mem 41.767
Train: [96][735/750]	BT 0.031 (1.140)	DT 0.001 (1.093)	loss nan (nan)	prob nan (nan)	GS 31.188 (31.188)	mem 41.805
Train: [96][740/750]	BT 0.834 (1.135)	DT 0.790 (1.088)	loss nan (nan)	prob nan (nan)	GS 31.141 (31.141)	mem 18.786
Train: [96][745/750]	BT 0.027 (1.134)	DT 0.001 (1.088)	loss nan (nan)	prob nan (nan)	GS 34.656 (34.656)	mem 12.871
Train: [96][750/750]	BT 0.028 (1.126)	DT 0.001 (1.080)	loss nan (nan)	prob nan (nan)	GS 32.438 (32.438)	mem 12.871
Train: [96][755/750]	BT 0.028 (1.122)	DT 0.001 (1.076)	loss nan (nan)	prob nan (nan)	GS 23.906 (23.906)	mem 12.783
epoch 96, total time 848.65
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [97][1/750]	BT 27.173 (27.173)	DT 27.064 (27.064)	loss nan (nan)	prob nan (nan)	GS 38.828 (38.828)	mem 40.876
Train: [97][5/750]	BT 0.038 (5.472)	DT 0.001 (5.415)	loss nan (nan)	prob nan (nan)	GS 33.531 (33.531)	mem 40.863
Train: [97][10/750]	BT 0.063 (2.767)	DT 0.002 (2.711)	loss nan (nan)	prob nan (nan)	GS 32.656 (32.656)	mem 40.871
Train: [97][15/750]	BT 0.044 (2.531)	DT 0.002 (2.478)	loss nan (nan)	prob nan (nan)	GS 26.047 (26.047)	mem 41.239
Train: [97][20/750]	BT 0.387 (1.930)	DT 0.356 (1.878)	loss nan (nan)	prob nan (nan)	GS 34.344 (34.344)	mem 40.973
Train: [97][25/750]	BT 12.156 (2.037)	DT 12.123 (1.989)	loss nan (nan)	prob nan (nan)	GS 30.031 (30.031)	mem 41.286
Train: [97][30/750]	BT 0.044 (1.769)	DT 0.002 (1.720)	loss nan (nan)	prob nan (nan)	GS 31.250 (31.250)	mem 41.095
Train: [97][35/750]	BT 0.032 (1.524)	DT 0.001 (1.475)	loss nan (nan)	prob nan (nan)	GS 29.438 (29.438)	mem 41.098
Train: [97][40/750]	BT 0.044 (1.777)	DT 0.011 (1.727)	loss nan (nan)	prob nan (nan)	GS 29.812 (29.812)	mem 41.190
Train: [97][45/750]	BT 0.134 (1.589)	DT 0.010 (1.536)	loss nan (nan)	prob nan (nan)	GS 39.531 (39.531)	mem 41.307
Train: [97][50/750]	BT 11.760 (1.717)	DT 11.685 (1.663)	loss nan (nan)	prob nan (nan)	GS 35.781 (35.781)	mem 41.363
Train: [97][55/750]	BT 0.095 (1.566)	DT 0.002 (1.513)	loss nan (nan)	prob nan (nan)	GS 31.422 (31.422)	mem 41.128
Train: [97][60/750]	BT 0.082 (1.440)	DT 0.001 (1.387)	loss nan (nan)	prob nan (nan)	GS 32.594 (32.594)	mem 41.140
Train: [97][65/750]	BT 0.031 (1.545)	DT 0.002 (1.493)	loss nan (nan)	prob nan (nan)	GS 34.344 (34.344)	mem 41.326
Train: [97][70/750]	BT 0.065 (1.530)	DT 0.009 (1.478)	loss nan (nan)	prob nan (nan)	GS 29.719 (29.719)	mem 41.174
Train: [97][75/750]	BT 0.059 (1.453)	DT 0.013 (1.402)	loss nan (nan)	prob nan (nan)	GS 33.969 (33.969)	mem 41.337
Train: [97][80/750]	BT 0.050 (1.455)	DT 0.007 (1.405)	loss nan (nan)	prob nan (nan)	GS 34.062 (34.062)	mem 41.281
Train: [97][85/750]	BT 0.097 (1.373)	DT 0.007 (1.323)	loss nan (nan)	prob nan (nan)	GS 30.453 (30.453)	mem 41.368
Train: [97][90/750]	BT 11.929 (1.481)	DT 11.898 (1.431)	loss nan (nan)	prob nan (nan)	GS 38.031 (38.031)	mem 41.230
Train: [97][95/750]	BT 0.031 (1.405)	DT 0.001 (1.356)	loss nan (nan)	prob nan (nan)	GS 36.594 (36.594)	mem 41.416
Train: [97][100/750]	BT 0.028 (1.337)	DT 0.001 (1.288)	loss nan (nan)	prob nan (nan)	GS 34.391 (34.391)	mem 41.217
Train: [97][105/750]	BT 0.033 (1.384)	DT 0.001 (1.335)	loss nan (nan)	prob nan (nan)	GS 29.047 (29.047)	mem 41.310
Train: [97][110/750]	BT 1.977 (1.340)	DT 1.936 (1.292)	loss nan (nan)	prob nan (nan)	GS 34.875 (34.875)	mem 41.309
Train: [97][115/750]	BT 0.062 (1.356)	DT 0.007 (1.307)	loss nan (nan)	prob nan (nan)	GS 38.094 (38.094)	mem 41.328
Train: [97][120/750]	BT 0.078 (1.301)	DT 0.001 (1.253)	loss nan (nan)	prob nan (nan)	GS 34.391 (34.391)	mem 41.339
Train: [97][125/750]	BT 0.032 (1.303)	DT 0.001 (1.256)	loss nan (nan)	prob nan (nan)	GS 37.469 (37.469)	mem 41.390
Train: [97][130/750]	BT 0.051 (1.320)	DT 0.006 (1.272)	loss nan (nan)	prob nan (nan)	GS 33.125 (33.125)	mem 41.367
Train: [97][135/750]	BT 0.052 (1.285)	DT 0.002 (1.238)	loss nan (nan)	prob nan (nan)	GS 31.172 (31.172)	mem 41.411
Train: [97][140/750]	BT 7.177 (1.329)	DT 7.148 (1.282)	loss nan (nan)	prob nan (nan)	GS 36.609 (36.609)	mem 41.396
Train: [97][145/750]	BT 0.028 (1.285)	DT 0.002 (1.238)	loss nan (nan)	prob nan (nan)	GS 31.047 (31.047)	mem 41.395
Train: [97][150/750]	BT 5.880 (1.282)	DT 5.806 (1.236)	loss nan (nan)	prob nan (nan)	GS 31.641 (31.641)	mem 41.347
Train: [97][155/750]	BT 0.045 (1.298)	DT 0.001 (1.251)	loss nan (nan)	prob nan (nan)	GS 33.766 (33.766)	mem 41.462
Train: [97][160/750]	BT 0.078 (1.259)	DT 0.010 (1.212)	loss nan (nan)	prob nan (nan)	GS 33.781 (33.781)	mem 41.473
Train: [97][165/750]	BT 0.024 (1.300)	DT 0.001 (1.253)	loss nan (nan)	prob nan (nan)	GS 33.719 (33.719)	mem 41.575
Train: [97][170/750]	BT 0.027 (1.263)	DT 0.001 (1.216)	loss nan (nan)	prob nan (nan)	GS 34.844 (34.844)	mem 41.515
Train: [97][175/750]	BT 0.032 (1.246)	DT 0.001 (1.199)	loss nan (nan)	prob nan (nan)	GS 32.109 (32.109)	mem 41.453
Train: [97][180/750]	BT 0.044 (1.259)	DT 0.002 (1.212)	loss nan (nan)	prob nan (nan)	GS 34.531 (34.531)	mem 41.543
Train: [97][185/750]	BT 0.053 (1.241)	DT 0.001 (1.194)	loss nan (nan)	prob nan (nan)	GS 31.219 (31.219)	mem 41.693
Train: [97][190/750]	BT 0.031 (1.258)	DT 0.001 (1.211)	loss nan (nan)	prob nan (nan)	GS 35.953 (35.953)	mem 41.853
Train: [97][195/750]	BT 0.072 (1.242)	DT 0.001 (1.195)	loss nan (nan)	prob nan (nan)	GS 31.781 (31.781)	mem 41.545
Train: [97][200/750]	BT 6.056 (1.281)	DT 6.025 (1.234)	loss nan (nan)	prob nan (nan)	GS 34.516 (34.516)	mem 41.792
Train: [97][205/750]	BT 0.040 (1.250)	DT 0.009 (1.204)	loss nan (nan)	prob nan (nan)	GS 29.781 (29.781)	mem 41.792
Train: [97][210/750]	BT 8.940 (1.264)	DT 8.899 (1.218)	loss nan (nan)	prob nan (nan)	GS 33.625 (33.625)	mem 41.819
Train: [97][215/750]	BT 0.020 (1.253)	DT 0.001 (1.207)	loss nan (nan)	prob nan (nan)	GS 26.141 (26.141)	mem 41.827
Train: [97][220/750]	BT 0.038 (1.233)	DT 0.001 (1.187)	loss nan (nan)	prob nan (nan)	GS 35.062 (35.062)	mem 41.837
Train: [97][225/750]	BT 0.035 (1.250)	DT 0.004 (1.204)	loss nan (nan)	prob nan (nan)	GS 30.984 (30.984)	mem 41.807
Train: [97][230/750]	BT 4.488 (1.243)	DT 4.457 (1.198)	loss nan (nan)	prob nan (nan)	GS 30.969 (30.969)	mem 41.812
Train: [97][235/750]	BT 0.041 (1.260)	DT 0.002 (1.215)	loss nan (nan)	prob nan (nan)	GS 29.375 (29.375)	mem 41.879
Train: [97][240/750]	BT 0.033 (1.235)	DT 0.002 (1.190)	loss nan (nan)	prob nan (nan)	GS 31.312 (31.312)	mem 41.809
Train: [97][245/750]	BT 0.035 (1.224)	DT 0.002 (1.179)	loss nan (nan)	prob nan (nan)	GS 33.859 (33.859)	mem 41.877
Train: [97][250/750]	BT 0.044 (1.245)	DT 0.001 (1.200)	loss nan (nan)	prob nan (nan)	GS 31.188 (31.188)	mem 41.944
Train: [97][255/750]	BT 0.029 (1.224)	DT 0.001 (1.179)	loss nan (nan)	prob nan (nan)	GS 30.594 (30.594)	mem 41.792
Train: [97][260/750]	BT 6.874 (1.246)	DT 6.844 (1.201)	loss nan (nan)	prob nan (nan)	GS 31.172 (31.172)	mem 41.869
Train: [97][265/750]	BT 0.047 (1.223)	DT 0.004 (1.179)	loss nan (nan)	prob nan (nan)	GS 41.656 (41.656)	mem 41.857
Train: [97][270/750]	BT 1.175 (1.208)	DT 1.129 (1.164)	loss nan (nan)	prob nan (nan)	GS 29.109 (29.109)	mem 42.081
Train: [97][275/750]	BT 0.073 (1.225)	DT 0.001 (1.181)	loss nan (nan)	prob nan (nan)	GS 30.766 (30.766)	mem 41.880
Train: [97][280/750]	BT 0.033 (1.211)	DT 0.002 (1.166)	loss nan (nan)	prob nan (nan)	GS 33.688 (33.688)	mem 41.935
Train: [97][285/750]	BT 0.085 (1.236)	DT 0.002 (1.192)	loss nan (nan)	prob nan (nan)	GS 27.906 (27.906)	mem 42.286
Train: [97][290/750]	BT 0.096 (1.216)	DT 0.008 (1.171)	loss nan (nan)	prob nan (nan)	GS 34.453 (34.453)	mem 42.146
Train: [97][295/750]	BT 0.070 (1.199)	DT 0.004 (1.154)	loss nan (nan)	prob nan (nan)	GS 30.141 (30.141)	mem 42.090
Train: [97][300/750]	BT 0.036 (1.231)	DT 0.002 (1.187)	loss nan (nan)	prob nan (nan)	GS 35.688 (35.688)	mem 42.091
Train: [97][305/750]	BT 0.046 (1.211)	DT 0.009 (1.167)	loss nan (nan)	prob nan (nan)	GS 31.750 (31.750)	mem 42.091
Train: [97][310/750]	BT 0.024 (1.237)	DT 0.003 (1.193)	loss nan (nan)	prob nan (nan)	GS 32.875 (32.875)	mem 42.008
Train: [97][315/750]	BT 0.051 (1.218)	DT 0.010 (1.174)	loss nan (nan)	prob nan (nan)	GS 31.578 (31.578)	mem 42.009
Train: [97][320/750]	BT 12.805 (1.240)	DT 12.758 (1.196)	loss nan (nan)	prob nan (nan)	GS 34.344 (34.344)	mem 42.144
Train: [97][325/750]	BT 0.050 (1.222)	DT 0.002 (1.178)	loss nan (nan)	prob nan (nan)	GS 28.266 (28.266)	mem 42.144
Train: [97][330/750]	BT 0.040 (1.204)	DT 0.011 (1.160)	loss nan (nan)	prob nan (nan)	GS 30.875 (30.875)	mem 42.145
Train: [97][335/750]	BT 0.049 (1.224)	DT 0.003 (1.181)	loss nan (nan)	prob nan (nan)	GS 30.188 (30.188)	mem 42.171
Train: [97][340/750]	BT 0.038 (1.207)	DT 0.002 (1.163)	loss nan (nan)	prob nan (nan)	GS 32.203 (32.203)	mem 42.171
Train: [97][345/750]	BT 0.058 (1.220)	DT 0.008 (1.176)	loss nan (nan)	prob nan (nan)	GS 27.000 (27.000)	mem 42.229
Train: [97][350/750]	BT 0.059 (1.203)	DT 0.008 (1.159)	loss nan (nan)	prob nan (nan)	GS 35.312 (35.312)	mem 42.188
Train: [97][355/750]	BT 0.064 (1.187)	DT 0.012 (1.143)	loss nan (nan)	prob nan (nan)	GS 36.891 (36.891)	mem 42.252
Train: [97][360/750]	BT 0.048 (1.202)	DT 0.013 (1.158)	loss nan (nan)	prob nan (nan)	GS 34.422 (34.422)	mem 42.165
Train: [97][365/750]	BT 0.122 (1.186)	DT 0.023 (1.142)	loss nan (nan)	prob nan (nan)	GS 29.328 (29.328)	mem 42.142
Train: [97][370/750]	BT 0.081 (1.202)	DT 0.001 (1.158)	loss nan (nan)	prob nan (nan)	GS 32.922 (32.922)	mem 42.179
Train: [97][375/750]	BT 0.123 (1.193)	DT 0.047 (1.149)	loss nan (nan)	prob nan (nan)	GS 30.078 (30.078)	mem 42.144
Train: [97][380/750]	BT 8.664 (1.201)	DT 8.605 (1.157)	loss nan (nan)	prob nan (nan)	GS 32.906 (32.906)	mem 42.203
Train: [97][385/750]	BT 0.028 (1.186)	DT 0.001 (1.142)	loss nan (nan)	prob nan (nan)	GS 31.734 (31.734)	mem 42.204
Train: [97][390/750]	BT 0.082 (1.187)	DT 0.002 (1.143)	loss nan (nan)	prob nan (nan)	GS 33.719 (33.719)	mem 42.209
Train: [97][395/750]	BT 0.034 (1.178)	DT 0.002 (1.134)	loss nan (nan)	prob nan (nan)	GS 32.062 (32.062)	mem 42.279
Train: [97][400/750]	BT 0.030 (1.192)	DT 0.002 (1.148)	loss nan (nan)	prob nan (nan)	GS 33.828 (33.828)	mem 42.192
Train: [97][405/750]	BT 0.041 (1.182)	DT 0.009 (1.138)	loss nan (nan)	prob nan (nan)	GS 34.438 (34.438)	mem 42.240
Train: [97][410/750]	BT 10.444 (1.194)	DT 10.405 (1.149)	loss nan (nan)	prob nan (nan)	GS 31.516 (31.516)	mem 42.212
Train: [97][415/750]	BT 0.032 (1.180)	DT 0.002 (1.136)	loss nan (nan)	prob nan (nan)	GS 33.812 (33.812)	mem 42.212
Train: [97][420/750]	BT 0.036 (1.166)	DT 0.002 (1.122)	loss nan (nan)	prob nan (nan)	GS 28.469 (28.469)	mem 42.252
Train: [97][425/750]	BT 0.023 (1.180)	DT 0.001 (1.136)	loss nan (nan)	prob nan (nan)	GS 29.125 (29.125)	mem 42.258
Train: [97][430/750]	BT 0.043 (1.167)	DT 0.001 (1.123)	loss nan (nan)	prob nan (nan)	GS 35.250 (35.250)	mem 42.258
Train: [97][435/750]	BT 0.064 (1.180)	DT 0.026 (1.137)	loss nan (nan)	prob nan (nan)	GS 27.281 (27.281)	mem 42.237
Train: [97][440/750]	BT 2.076 (1.172)	DT 2.003 (1.128)	loss nan (nan)	prob nan (nan)	GS 36.703 (36.703)	mem 42.335
Train: [97][445/750]	BT 0.033 (1.160)	DT 0.001 (1.116)	loss nan (nan)	prob nan (nan)	GS 31.062 (31.062)	mem 42.176
Train: [97][450/750]	BT 0.040 (1.168)	DT 0.010 (1.123)	loss nan (nan)	prob nan (nan)	GS 32.672 (32.672)	mem 42.245
Train: [97][455/750]	BT 0.032 (1.163)	DT 0.001 (1.119)	loss nan (nan)	prob nan (nan)	GS 32.047 (32.047)	mem 42.243
Train: [97][460/750]	BT 0.036 (1.169)	DT 0.004 (1.125)	loss nan (nan)	prob nan (nan)	GS 29.531 (29.531)	mem 42.314
Train: [97][465/750]	BT 0.075 (1.171)	DT 0.023 (1.127)	loss nan (nan)	prob nan (nan)	GS 28.312 (28.312)	mem 42.322
Train: [97][470/750]	BT 7.010 (1.174)	DT 6.888 (1.129)	loss nan (nan)	prob nan (nan)	GS 32.594 (32.594)	mem 42.346
Train: [97][475/750]	BT 0.037 (1.162)	DT 0.001 (1.118)	loss nan (nan)	prob nan (nan)	GS 33.562 (33.562)	mem 42.559
Train: [97][480/750]	BT 2.379 (1.162)	DT 2.347 (1.117)	loss nan (nan)	prob nan (nan)	GS 34.562 (34.562)	mem 42.187
Train: [97][485/750]	BT 0.035 (1.174)	DT 0.001 (1.129)	loss nan (nan)	prob nan (nan)	GS 29.125 (29.125)	mem 42.138
Train: [97][490/750]	BT 1.982 (1.166)	DT 1.951 (1.122)	loss nan (nan)	prob nan (nan)	GS 35.266 (35.266)	mem 42.181
Train: [97][495/750]	BT 0.025 (1.178)	DT 0.001 (1.133)	loss nan (nan)	prob nan (nan)	GS 30.266 (30.266)	mem 42.244
Train: [97][500/750]	BT 0.041 (1.166)	DT 0.001 (1.122)	loss nan (nan)	prob nan (nan)	GS 36.188 (36.188)	mem 42.245
Train: [97][505/750]	BT 0.061 (1.164)	DT 0.010 (1.120)	loss nan (nan)	prob nan (nan)	GS 34.875 (34.875)	mem 42.365
Train: [97][510/750]	BT 0.035 (1.172)	DT 0.002 (1.128)	loss nan (nan)	prob nan (nan)	GS 32.984 (32.984)	mem 42.170
Train: [97][515/750]	BT 0.065 (1.161)	DT 0.008 (1.117)	loss nan (nan)	prob nan (nan)	GS 31.000 (31.000)	mem 42.170
Train: [97][520/750]	BT 0.031 (1.171)	DT 0.001 (1.127)	loss nan (nan)	prob nan (nan)	GS 36.188 (36.188)	mem 42.241
Train: [97][525/750]	BT 0.042 (1.160)	DT 0.002 (1.116)	loss nan (nan)	prob nan (nan)	GS 29.594 (29.594)	mem 42.242
Train: [97][530/750]	BT 14.277 (1.180)	DT 14.245 (1.135)	loss nan (nan)	prob nan (nan)	GS 36.250 (36.250)	mem 42.157
Train: [97][535/750]	BT 0.100 (1.169)	DT 0.032 (1.125)	loss nan (nan)	prob nan (nan)	GS 29.750 (29.750)	mem 42.217
Train: [97][540/750]	BT 0.038 (1.159)	DT 0.002 (1.114)	loss nan (nan)	prob nan (nan)	GS 36.109 (36.109)	mem 42.180
Train: [97][545/750]	BT 0.024 (1.172)	DT 0.001 (1.128)	loss nan (nan)	prob nan (nan)	GS 31.828 (31.828)	mem 42.055
Train: [97][550/750]	BT 0.031 (1.162)	DT 0.001 (1.117)	loss nan (nan)	prob nan (nan)	GS 36.438 (36.438)	mem 42.061
Train: [97][555/750]	BT 0.051 (1.172)	DT 0.012 (1.128)	loss nan (nan)	prob nan (nan)	GS 32.500 (32.500)	mem 42.019
Train: [97][560/750]	BT 0.031 (1.162)	DT 0.001 (1.118)	loss nan (nan)	prob nan (nan)	GS 30.891 (30.891)	mem 42.043
Train: [97][565/750]	BT 0.029 (1.152)	DT 0.001 (1.108)	loss nan (nan)	prob nan (nan)	GS 29.656 (29.656)	mem 42.043
Train: [97][570/750]	BT 0.670 (1.161)	DT 0.638 (1.117)	loss nan (nan)	prob nan (nan)	GS 32.391 (32.391)	mem 42.055
Train: [97][575/750]	BT 0.047 (1.151)	DT 0.001 (1.108)	loss nan (nan)	prob nan (nan)	GS 33.562 (33.562)	mem 42.055
Train: [97][580/750]	BT 0.021 (1.163)	DT 0.001 (1.119)	loss nan (nan)	prob nan (nan)	GS 41.078 (41.078)	mem 42.161
Train: [97][585/750]	BT 0.120 (1.157)	DT 0.023 (1.113)	loss nan (nan)	prob nan (nan)	GS 28.609 (28.609)	mem 42.039
Train: [97][590/750]	BT 7.871 (1.161)	DT 7.815 (1.117)	loss nan (nan)	prob nan (nan)	GS 33.984 (33.984)	mem 42.229
Train: [97][595/750]	BT 0.035 (1.165)	DT 0.001 (1.121)	loss nan (nan)	prob nan (nan)	GS 34.797 (34.797)	mem 42.102
Train: [97][600/750]	BT 0.030 (1.156)	DT 0.001 (1.112)	loss nan (nan)	prob nan (nan)	GS 31.688 (31.688)	mem 42.102
Train: [97][605/750]	BT 0.025 (1.153)	DT 0.002 (1.110)	loss nan (nan)	prob nan (nan)	GS 33.938 (33.938)	mem 42.109
Train: [97][610/750]	BT 0.035 (1.161)	DT 0.001 (1.117)	loss nan (nan)	prob nan (nan)	GS 34.016 (34.016)	mem 42.152
Train: [97][615/750]	BT 0.056 (1.154)	DT 0.014 (1.110)	loss nan (nan)	prob nan (nan)	GS 36.438 (36.438)	mem 42.297
Train: [97][620/750]	BT 0.029 (1.163)	DT 0.001 (1.119)	loss nan (nan)	prob nan (nan)	GS 39.266 (39.266)	mem 42.212
Train: [97][625/750]	BT 0.062 (1.154)	DT 0.011 (1.110)	loss nan (nan)	prob nan (nan)	GS 33.516 (33.516)	mem 42.212
Train: [97][630/750]	BT 6.032 (1.160)	DT 5.994 (1.117)	loss nan (nan)	prob nan (nan)	GS 33.969 (33.969)	mem 42.115
Train: [97][635/750]	BT 0.032 (1.152)	DT 0.001 (1.108)	loss nan (nan)	prob nan (nan)	GS 27.281 (27.281)	mem 42.116
Train: [97][640/750]	BT 0.032 (1.156)	DT 0.001 (1.113)	loss nan (nan)	prob nan (nan)	GS 43.094 (43.094)	mem 42.094
Train: [97][645/750]	BT 0.030 (1.153)	DT 0.001 (1.109)	loss nan (nan)	prob nan (nan)	GS 26.094 (26.094)	mem 42.170
Train: [97][650/750]	BT 12.514 (1.163)	DT 12.459 (1.120)	loss nan (nan)	prob nan (nan)	GS 29.859 (29.859)	mem 41.992
Train: [97][655/750]	BT 0.022 (1.155)	DT 0.001 (1.111)	loss nan (nan)	prob nan (nan)	GS 29.062 (29.062)	mem 42.025
Train: [97][660/750]	BT 1.846 (1.149)	DT 1.796 (1.105)	loss nan (nan)	prob nan (nan)	GS 35.266 (35.266)	mem 42.114
Train: [97][665/750]	BT 0.023 (1.158)	DT 0.001 (1.115)	loss nan (nan)	prob nan (nan)	GS 28.984 (28.984)	mem 42.189
Train: [97][670/750]	BT 0.034 (1.150)	DT 0.002 (1.106)	loss nan (nan)	prob nan (nan)	GS 31.859 (31.859)	mem 42.248
Train: [97][675/750]	BT 0.027 (1.161)	DT 0.001 (1.117)	loss nan (nan)	prob nan (nan)	GS 30.156 (30.156)	mem 42.191
Train: [97][680/750]	BT 0.033 (1.152)	DT 0.002 (1.109)	loss nan (nan)	prob nan (nan)	GS 35.516 (35.516)	mem 42.160
Train: [97][685/750]	BT 0.037 (1.144)	DT 0.001 (1.101)	loss nan (nan)	prob nan (nan)	GS 32.234 (32.234)	mem 42.172
Train: [97][690/750]	BT 1.585 (1.158)	DT 1.553 (1.114)	loss nan (nan)	prob nan (nan)	GS 37.203 (37.203)	mem 42.124
Train: [97][695/750]	BT 0.029 (1.150)	DT 0.001 (1.106)	loss nan (nan)	prob nan (nan)	GS 30.266 (30.266)	mem 42.130
Train: [97][700/750]	BT 0.067 (1.154)	DT 0.017 (1.110)	loss nan (nan)	prob nan (nan)	GS 36.375 (36.375)	mem 42.296
Train: [97][705/750]	BT 0.034 (1.151)	DT 0.001 (1.107)	loss nan (nan)	prob nan (nan)	GS 28.234 (28.234)	mem 42.221
arpack error, retry= 0
arpack error, retry= 0
Train: [97][710/750]	BT 13.685 (1.163)	DT 13.655 (1.119)	loss nan (nan)	prob nan (nan)	GS 37.609 (37.609)	mem 42.096
Train: [97][715/750]	BT 0.050 (1.155)	DT 0.010 (1.111)	loss nan (nan)	prob nan (nan)	GS 32.844 (32.844)	mem 42.111
Train: [97][720/750]	BT 0.036 (1.147)	DT 0.001 (1.103)	loss nan (nan)	prob nan (nan)	GS 33.188 (33.188)	mem 42.244
Train: [97][725/750]	BT 0.033 (1.154)	DT 0.002 (1.110)	loss nan (nan)	prob nan (nan)	GS 30.469 (30.469)	mem 42.149
Train: [97][730/750]	BT 0.034 (1.152)	DT 0.001 (1.109)	loss nan (nan)	prob nan (nan)	GS 31.188 (31.188)	mem 42.167
Train: [97][735/750]	BT 0.065 (1.151)	DT 0.008 (1.108)	loss nan (nan)	prob nan (nan)	GS 32.141 (32.141)	mem 38.914
Train: [97][740/750]	BT 0.021 (1.147)	DT 0.001 (1.104)	loss nan (nan)	prob nan (nan)	GS 35.406 (35.406)	mem 10.022
Train: [97][745/750]	BT 0.029 (1.140)	DT 0.001 (1.097)	loss nan (nan)	prob nan (nan)	GS 25.531 (25.531)	mem 9.859
Train: [97][750/750]	BT 2.297 (1.135)	DT 2.264 (1.092)	loss nan (nan)	prob nan (nan)	GS 39.750 (39.750)	mem 9.821
Train: [97][755/750]	BT 0.025 (1.128)	DT 0.001 (1.085)	loss nan (nan)	prob nan (nan)	GS 29.438 (29.438)	mem 9.822
epoch 97, total time 851.89
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [98][1/750]	BT 21.033 (21.033)	DT 20.972 (20.972)	loss nan (nan)	prob nan (nan)	GS 32.516 (32.516)	mem 41.013
Train: [98][5/750]	BT 0.071 (4.822)	DT 0.001 (4.774)	loss nan (nan)	prob nan (nan)	GS 34.453 (34.453)	mem 40.995
Train: [98][10/750]	BT 1.114 (2.737)	DT 1.084 (2.690)	loss nan (nan)	prob nan (nan)	GS 33.219 (33.219)	mem 41.000
Train: [98][15/750]	BT 0.024 (2.219)	DT 0.001 (2.170)	loss nan (nan)	prob nan (nan)	GS 29.344 (29.344)	mem 41.030
Train: [98][20/750]	BT 0.052 (1.938)	DT 0.005 (1.892)	loss nan (nan)	prob nan (nan)	GS 29.391 (29.391)	mem 41.157
Train: [98][25/750]	BT 4.499 (1.790)	DT 4.468 (1.742)	loss nan (nan)	prob nan (nan)	GS 30.516 (30.516)	mem 41.123
Train: [98][30/750]	BT 2.200 (1.712)	DT 2.162 (1.663)	loss nan (nan)	prob nan (nan)	GS 33.031 (33.031)	mem 41.121
Train: [98][35/750]	BT 0.044 (1.560)	DT 0.001 (1.512)	loss nan (nan)	prob nan (nan)	GS 30.688 (30.688)	mem 41.166
Train: [98][40/750]	BT 5.428 (1.642)	DT 5.394 (1.594)	loss nan (nan)	prob nan (nan)	GS 34.891 (34.891)	mem 41.144
Train: [98][45/750]	BT 0.041 (1.578)	DT 0.008 (1.529)	loss nan (nan)	prob nan (nan)	GS 30.703 (30.703)	mem 41.114
Train: [98][50/750]	BT 6.606 (1.556)	DT 6.546 (1.508)	loss nan (nan)	prob nan (nan)	GS 36.688 (36.688)	mem 41.165
Train: [98][55/750]	BT 0.095 (1.500)	DT 0.027 (1.451)	loss nan (nan)	prob nan (nan)	GS 32.766 (32.766)	mem 41.145
Train: [98][60/750]	BT 0.125 (1.383)	DT 0.009 (1.331)	loss nan (nan)	prob nan (nan)	GS 33.984 (33.984)	mem 41.161
Train: [98][65/750]	BT 0.033 (1.403)	DT 0.001 (1.352)	loss nan (nan)	prob nan (nan)	GS 33.125 (33.125)	mem 41.230
Train: [98][70/750]	BT 0.052 (1.396)	DT 0.014 (1.345)	loss nan (nan)	prob nan (nan)	GS 35.406 (35.406)	mem 41.241
Train: [98][75/750]	BT 0.033 (1.368)	DT 0.003 (1.317)	loss nan (nan)	prob nan (nan)	GS 33.016 (33.016)	mem 41.408
Train: [98][80/750]	BT 0.028 (1.413)	DT 0.001 (1.363)	loss nan (nan)	prob nan (nan)	GS 36.094 (36.094)	mem 41.276
Train: [98][85/750]	BT 0.055 (1.333)	DT 0.001 (1.283)	loss nan (nan)	prob nan (nan)	GS 29.406 (29.406)	mem 41.276
Train: [98][90/750]	BT 10.617 (1.412)	DT 10.586 (1.363)	loss nan (nan)	prob nan (nan)	GS 34.328 (34.328)	mem 41.294
Train: [98][95/750]	BT 0.031 (1.340)	DT 0.001 (1.291)	loss nan (nan)	prob nan (nan)	GS 29.844 (29.844)	mem 41.294
Train: [98][100/750]	BT 0.056 (1.331)	DT 0.022 (1.283)	loss nan (nan)	prob nan (nan)	GS 35.562 (35.562)	mem 41.214
Train: [98][105/750]	BT 0.049 (1.368)	DT 0.003 (1.320)	loss nan (nan)	prob nan (nan)	GS 36.656 (36.656)	mem 41.307
Train: [98][110/750]	BT 0.330 (1.310)	DT 0.298 (1.263)	loss nan (nan)	prob nan (nan)	GS 32.594 (32.594)	mem 41.355
Train: [98][115/750]	BT 0.053 (1.346)	DT 0.005 (1.298)	loss nan (nan)	prob nan (nan)	GS 31.750 (31.750)	mem 41.348
Train: [98][120/750]	BT 0.040 (1.292)	DT 0.001 (1.244)	loss nan (nan)	prob nan (nan)	GS 36.859 (36.859)	mem 41.527
Train: [98][125/750]	BT 0.045 (1.243)	DT 0.004 (1.195)	loss nan (nan)	prob nan (nan)	GS 30.859 (30.859)	mem 41.352
Train: [98][130/750]	BT 0.032 (1.315)	DT 0.001 (1.267)	loss nan (nan)	prob nan (nan)	GS 34.031 (34.031)	mem 41.441
Train: [98][135/750]	BT 0.025 (1.267)	DT 0.001 (1.220)	loss nan (nan)	prob nan (nan)	GS 35.359 (35.359)	mem 41.534
Train: [98][140/750]	BT 0.030 (1.324)	DT 0.001 (1.278)	loss nan (nan)	prob nan (nan)	GS 32.578 (32.578)	mem 41.411
Train: [98][145/750]	BT 0.036 (1.280)	DT 0.002 (1.234)	loss nan (nan)	prob nan (nan)	GS 31.328 (31.328)	mem 41.449
Train: [98][150/750]	BT 13.077 (1.326)	DT 13.047 (1.280)	loss nan (nan)	prob nan (nan)	GS 31.984 (31.984)	mem 41.661
Train: [98][155/750]	BT 0.083 (1.285)	DT 0.035 (1.239)	loss nan (nan)	prob nan (nan)	GS 36.828 (36.828)	mem 41.634
Train: [98][160/750]	BT 0.053 (1.246)	DT 0.001 (1.200)	loss nan (nan)	prob nan (nan)	GS 31.688 (31.688)	mem 41.634
Train: [98][165/750]	BT 0.038 (1.301)	DT 0.001 (1.256)	loss nan (nan)	prob nan (nan)	GS 31.094 (31.094)	mem 41.633
Train: [98][170/750]	BT 0.046 (1.264)	DT 0.002 (1.219)	loss nan (nan)	prob nan (nan)	GS 34.312 (34.312)	mem 41.633
Train: [98][175/750]	BT 0.080 (1.285)	DT 0.015 (1.240)	loss nan (nan)	prob nan (nan)	GS 30.469 (30.469)	mem 41.777
Train: [98][180/750]	BT 0.033 (1.251)	DT 0.001 (1.206)	loss nan (nan)	prob nan (nan)	GS 32.641 (32.641)	mem 41.803
Train: [98][185/750]	BT 0.034 (1.218)	DT 0.002 (1.173)	loss nan (nan)	prob nan (nan)	GS 31.875 (31.875)	mem 41.772
Train: [98][190/750]	BT 0.112 (1.266)	DT 0.008 (1.220)	loss nan (nan)	prob nan (nan)	GS 34.391 (34.391)	mem 41.728
Train: [98][195/750]	BT 0.032 (1.234)	DT 0.002 (1.189)	loss nan (nan)	prob nan (nan)	GS 30.953 (30.953)	mem 41.730
Train: [98][200/750]	BT 0.029 (1.253)	DT 0.001 (1.208)	loss nan (nan)	prob nan (nan)	GS 35.000 (35.000)	mem 41.717
Train: [98][205/750]	BT 0.063 (1.224)	DT 0.017 (1.179)	loss nan (nan)	prob nan (nan)	GS 33.406 (33.406)	mem 41.864
Train: [98][210/750]	BT 14.723 (1.267)	DT 14.689 (1.221)	loss nan (nan)	prob nan (nan)	GS 36.391 (36.391)	mem 41.847
Train: [98][215/750]	BT 0.033 (1.238)	DT 0.001 (1.193)	loss nan (nan)	prob nan (nan)	GS 32.844 (32.844)	mem 41.849
Train: [98][220/750]	BT 0.069 (1.211)	DT 0.012 (1.166)	loss nan (nan)	prob nan (nan)	GS 37.141 (37.141)	mem 41.900
Train: [98][225/750]	BT 0.030 (1.234)	DT 0.001 (1.188)	loss nan (nan)	prob nan (nan)	GS 31.047 (31.047)	mem 41.941
Train: [98][230/750]	BT 0.073 (1.208)	DT 0.014 (1.162)	loss nan (nan)	prob nan (nan)	GS 35.484 (35.484)	mem 41.880
Train: [98][235/750]	BT 0.031 (1.237)	DT 0.005 (1.190)	loss nan (nan)	prob nan (nan)	GS 27.312 (27.312)	mem 42.074
Train: [98][240/750]	BT 0.027 (1.211)	DT 0.001 (1.166)	loss nan (nan)	prob nan (nan)	GS 35.484 (35.484)	mem 42.232
Train: [98][245/750]	BT 0.032 (1.188)	DT 0.001 (1.142)	loss nan (nan)	prob nan (nan)	GS 26.234 (26.234)	mem 42.015
Train: [98][250/750]	BT 0.067 (1.222)	DT 0.005 (1.176)	loss nan (nan)	prob nan (nan)	GS 33.766 (33.766)	mem 42.121
Train: [98][255/750]	BT 0.060 (1.199)	DT 0.012 (1.153)	loss nan (nan)	prob nan (nan)	GS 34.703 (34.703)	mem 41.997
Train: [98][260/750]	BT 0.034 (1.222)	DT 0.001 (1.177)	loss nan (nan)	prob nan (nan)	GS 34.359 (34.359)	mem 42.158
Train: [98][265/750]	BT 0.039 (1.200)	DT 0.002 (1.155)	loss nan (nan)	prob nan (nan)	GS 32.453 (32.453)	mem 42.030
Train: [98][270/750]	BT 12.236 (1.224)	DT 12.204 (1.179)	loss nan (nan)	prob nan (nan)	GS 30.469 (30.469)	mem 42.135
Train: [98][275/750]	BT 0.094 (1.202)	DT 0.002 (1.157)	loss nan (nan)	prob nan (nan)	GS 28.984 (28.984)	mem 42.226
Train: [98][280/750]	BT 0.046 (1.182)	DT 0.015 (1.137)	loss nan (nan)	prob nan (nan)	GS 35.938 (35.938)	mem 42.381
Train: [98][285/750]	BT 0.030 (1.206)	DT 0.001 (1.160)	loss nan (nan)	prob nan (nan)	GS 31.391 (31.391)	mem 42.056
Train: [98][290/750]	BT 0.032 (1.186)	DT 0.001 (1.140)	loss nan (nan)	prob nan (nan)	GS 36.781 (36.781)	mem 42.056
Train: [98][295/750]	BT 0.046 (1.207)	DT 0.010 (1.162)	loss nan (nan)	prob nan (nan)	GS 35.047 (35.047)	mem 42.123
Train: [98][300/750]	BT 0.030 (1.187)	DT 0.001 (1.143)	loss nan (nan)	prob nan (nan)	GS 33.828 (33.828)	mem 42.124
Train: [98][305/750]	BT 0.126 (1.169)	DT 0.026 (1.124)	loss nan (nan)	prob nan (nan)	GS 33.797 (33.797)	mem 42.136
Train: [98][310/750]	BT 0.023 (1.199)	DT 0.001 (1.154)	loss nan (nan)	prob nan (nan)	GS 35.594 (35.594)	mem 42.089
Train: [98][315/750]	BT 0.048 (1.181)	DT 0.010 (1.136)	loss nan (nan)	prob nan (nan)	GS 29.516 (29.516)	mem 42.091
Train: [98][320/750]	BT 0.030 (1.207)	DT 0.001 (1.163)	loss nan (nan)	prob nan (nan)	GS 34.516 (34.516)	mem 42.095
Train: [98][325/750]	BT 0.050 (1.190)	DT 0.010 (1.145)	loss nan (nan)	prob nan (nan)	GS 30.312 (30.312)	mem 42.095
Train: [98][330/750]	BT 11.985 (1.208)	DT 11.888 (1.164)	loss nan (nan)	prob nan (nan)	GS 32.688 (32.688)	mem 42.142
Train: [98][335/750]	BT 0.039 (1.191)	DT 0.001 (1.147)	loss nan (nan)	prob nan (nan)	GS 34.562 (34.562)	mem 42.176
Train: [98][340/750]	BT 0.056 (1.174)	DT 0.001 (1.130)	loss nan (nan)	prob nan (nan)	GS 32.656 (32.656)	mem 42.144
Train: [98][345/750]	BT 0.032 (1.200)	DT 0.003 (1.156)	loss nan (nan)	prob nan (nan)	GS 32.781 (32.781)	mem 42.173
Train: [98][350/750]	BT 0.030 (1.184)	DT 0.001 (1.140)	loss nan (nan)	prob nan (nan)	GS 28.500 (28.500)	mem 42.173
Train: [98][355/750]	BT 0.032 (1.197)	DT 0.002 (1.153)	loss nan (nan)	prob nan (nan)	GS 40.906 (40.906)	mem 42.187
Train: [98][360/750]	BT 0.027 (1.181)	DT 0.001 (1.137)	loss nan (nan)	prob nan (nan)	GS 35.531 (35.531)	mem 42.189
Train: [98][365/750]	BT 0.033 (1.166)	DT 0.002 (1.122)	loss nan (nan)	prob nan (nan)	GS 36.359 (36.359)	mem 42.396
Train: [98][370/750]	BT 0.028 (1.185)	DT 0.001 (1.142)	loss nan (nan)	prob nan (nan)	GS 36.984 (36.984)	mem 42.127
Train: [98][375/750]	BT 0.037 (1.170)	DT 0.005 (1.126)	loss nan (nan)	prob nan (nan)	GS 30.016 (30.016)	mem 42.066
Train: [98][380/750]	BT 0.031 (1.196)	DT 0.001 (1.152)	loss nan (nan)	prob nan (nan)	GS 30.594 (30.594)	mem 42.168
Train: [98][385/750]	BT 0.051 (1.181)	DT 0.001 (1.137)	loss nan (nan)	prob nan (nan)	GS 30.891 (30.891)	mem 42.023
Train: [98][390/750]	BT 12.878 (1.199)	DT 12.846 (1.156)	loss nan (nan)	prob nan (nan)	GS 32.703 (32.703)	mem 42.142
Train: [98][395/750]	BT 0.128 (1.185)	DT 0.009 (1.141)	loss nan (nan)	prob nan (nan)	GS 31.219 (31.219)	mem 42.039
Train: [98][400/750]	BT 0.032 (1.171)	DT 0.001 (1.127)	loss nan (nan)	prob nan (nan)	GS 35.188 (35.188)	mem 42.072
Train: [98][405/750]	BT 0.048 (1.189)	DT 0.009 (1.145)	loss nan (nan)	prob nan (nan)	GS 38.500 (38.500)	mem 42.042
Train: [98][410/750]	BT 0.044 (1.175)	DT 0.003 (1.131)	loss nan (nan)	prob nan (nan)	GS 36.156 (36.156)	mem 42.041
Train: [98][415/750]	BT 0.047 (1.194)	DT 0.016 (1.150)	loss nan (nan)	prob nan (nan)	GS 34.984 (34.984)	mem 42.156
Train: [98][420/750]	BT 0.075 (1.180)	DT 0.004 (1.136)	loss nan (nan)	prob nan (nan)	GS 34.578 (34.578)	mem 42.099
Train: [98][425/750]	BT 0.030 (1.167)	DT 0.001 (1.123)	loss nan (nan)	prob nan (nan)	GS 37.594 (37.594)	mem 42.102
Train: [98][430/750]	BT 0.050 (1.181)	DT 0.009 (1.138)	loss nan (nan)	prob nan (nan)	GS 32.609 (32.609)	mem 42.116
Train: [98][435/750]	BT 0.039 (1.168)	DT 0.001 (1.125)	loss nan (nan)	prob nan (nan)	GS 26.609 (26.609)	mem 42.116
Train: [98][440/750]	BT 0.031 (1.180)	DT 0.001 (1.136)	loss nan (nan)	prob nan (nan)	GS 34.812 (34.812)	mem 42.137
Train: [98][445/750]	BT 0.029 (1.167)	DT 0.001 (1.124)	loss nan (nan)	prob nan (nan)	GS 26.688 (26.688)	mem 42.137
Train: [98][450/750]	BT 15.383 (1.189)	DT 15.328 (1.145)	loss nan (nan)	prob nan (nan)	GS 34.047 (34.047)	mem 42.161
Train: [98][455/750]	BT 0.048 (1.176)	DT 0.010 (1.133)	loss nan (nan)	prob nan (nan)	GS 32.969 (32.969)	mem 42.159
Train: [98][460/750]	BT 0.028 (1.164)	DT 0.001 (1.120)	loss nan (nan)	prob nan (nan)	GS 34.953 (34.953)	mem 42.159
Train: [98][465/750]	BT 0.032 (1.180)	DT 0.001 (1.137)	loss nan (nan)	prob nan (nan)	GS 25.094 (25.094)	mem 42.104
Train: [98][470/750]	BT 0.027 (1.168)	DT 0.001 (1.125)	loss nan (nan)	prob nan (nan)	GS 26.844 (26.844)	mem 42.105
Train: [98][475/750]	BT 0.038 (1.176)	DT 0.002 (1.133)	loss nan (nan)	prob nan (nan)	GS 32.219 (32.219)	mem 42.259
Train: [98][480/750]	BT 0.044 (1.164)	DT 0.002 (1.121)	loss nan (nan)	prob nan (nan)	GS 34.812 (34.812)	mem 42.259
Train: [98][485/750]	BT 0.065 (1.153)	DT 0.001 (1.110)	loss nan (nan)	prob nan (nan)	GS 31.562 (31.562)	mem 42.180
Train: [98][490/750]	BT 0.031 (1.168)	DT 0.001 (1.125)	loss nan (nan)	prob nan (nan)	GS 36.797 (36.797)	mem 42.180
Train: [98][495/750]	BT 0.033 (1.157)	DT 0.002 (1.114)	loss nan (nan)	prob nan (nan)	GS 30.938 (30.938)	mem 42.237
Train: [98][500/750]	BT 0.037 (1.175)	DT 0.001 (1.132)	loss nan (nan)	prob nan (nan)	GS 37.859 (37.859)	mem 42.126
Train: [98][505/750]	BT 0.021 (1.164)	DT 0.001 (1.121)	loss nan (nan)	prob nan (nan)	GS 28.203 (28.203)	mem 42.126
Train: [98][510/750]	BT 14.750 (1.182)	DT 14.720 (1.139)	loss nan (nan)	prob nan (nan)	GS 34.500 (34.500)	mem 42.058
Train: [98][515/750]	BT 0.046 (1.171)	DT 0.005 (1.128)	loss nan (nan)	prob nan (nan)	GS 31.375 (31.375)	mem 42.058
Train: [98][520/750]	BT 0.031 (1.160)	DT 0.001 (1.117)	loss nan (nan)	prob nan (nan)	GS 37.109 (37.109)	mem 42.059
Train: [98][525/750]	BT 0.033 (1.172)	DT 0.002 (1.129)	loss nan (nan)	prob nan (nan)	GS 39.266 (39.266)	mem 42.173
Train: [98][530/750]	BT 0.032 (1.162)	DT 0.002 (1.119)	loss nan (nan)	prob nan (nan)	GS 35.266 (35.266)	mem 42.174
Train: [98][535/750]	BT 0.029 (1.175)	DT 0.001 (1.132)	loss nan (nan)	prob nan (nan)	GS 30.578 (30.578)	mem 42.324
Train: [98][540/750]	BT 0.033 (1.164)	DT 0.002 (1.121)	loss nan (nan)	prob nan (nan)	GS 32.375 (32.375)	mem 42.299
Train: [98][545/750]	BT 0.074 (1.154)	DT 0.007 (1.111)	loss nan (nan)	prob nan (nan)	GS 28.172 (28.172)	mem 42.261
Train: [98][550/750]	BT 0.027 (1.171)	DT 0.001 (1.128)	loss nan (nan)	prob nan (nan)	GS 34.359 (34.359)	mem 42.186
Train: [98][555/750]	BT 0.031 (1.161)	DT 0.002 (1.118)	loss nan (nan)	prob nan (nan)	GS 29.766 (29.766)	mem 42.185
Train: [98][560/750]	BT 0.040 (1.170)	DT 0.002 (1.128)	loss nan (nan)	prob nan (nan)	GS 30.812 (30.812)	mem 42.186
Train: [98][565/750]	BT 0.081 (1.160)	DT 0.003 (1.118)	loss nan (nan)	prob nan (nan)	GS 31.766 (31.766)	mem 42.360
Train: [98][570/750]	BT 12.149 (1.172)	DT 12.121 (1.129)	loss nan (nan)	prob nan (nan)	GS 34.016 (34.016)	mem 42.189
Train: [98][575/750]	BT 0.030 (1.162)	DT 0.002 (1.119)	loss nan (nan)	prob nan (nan)	GS 30.125 (30.125)	mem 42.190
Train: [98][580/750]	BT 0.061 (1.152)	DT 0.007 (1.110)	loss nan (nan)	prob nan (nan)	GS 37.922 (37.922)	mem 42.229
Train: [98][585/750]	BT 0.024 (1.163)	DT 0.001 (1.121)	loss nan (nan)	prob nan (nan)	GS 32.594 (32.594)	mem 42.392
Train: [98][590/750]	BT 0.036 (1.154)	DT 0.001 (1.112)	loss nan (nan)	prob nan (nan)	GS 35.703 (35.703)	mem 42.425
Train: [98][595/750]	BT 0.032 (1.166)	DT 0.001 (1.124)	loss nan (nan)	prob nan (nan)	GS 27.812 (27.812)	mem 42.041
Train: [98][600/750]	BT 0.059 (1.157)	DT 0.002 (1.114)	loss nan (nan)	prob nan (nan)	GS 31.984 (31.984)	mem 42.084
Train: [98][605/750]	BT 0.025 (1.147)	DT 0.001 (1.105)	loss nan (nan)	prob nan (nan)	GS 32.016 (32.016)	mem 42.044
Train: [98][610/750]	BT 0.027 (1.163)	DT 0.001 (1.121)	loss nan (nan)	prob nan (nan)	GS 38.469 (38.469)	mem 42.099
Train: [98][615/750]	BT 0.037 (1.154)	DT 0.003 (1.112)	loss nan (nan)	prob nan (nan)	GS 28.391 (28.391)	mem 42.096
Train: [98][620/750]	BT 0.034 (1.163)	DT 0.001 (1.121)	loss nan (nan)	prob nan (nan)	GS 34.250 (34.250)	mem 42.297
Train: [98][625/750]	BT 0.103 (1.155)	DT 0.020 (1.113)	loss nan (nan)	prob nan (nan)	GS 33.500 (33.500)	mem 42.167
Train: [98][630/750]	BT 12.206 (1.165)	DT 12.173 (1.123)	loss nan (nan)	prob nan (nan)	GS 32.219 (32.219)	mem 42.147
Train: [98][635/750]	BT 0.088 (1.157)	DT 0.012 (1.114)	loss nan (nan)	prob nan (nan)	GS 33.203 (33.203)	mem 42.211
Train: [98][640/750]	BT 0.045 (1.148)	DT 0.002 (1.106)	loss nan (nan)	prob nan (nan)	GS 34.172 (34.172)	mem 42.143
Train: [98][645/750]	BT 0.021 (1.157)	DT 0.001 (1.115)	loss nan (nan)	prob nan (nan)	GS 36.781 (36.781)	mem 42.125
Train: [98][650/750]	BT 0.033 (1.148)	DT 0.002 (1.106)	loss nan (nan)	prob nan (nan)	GS 35.234 (35.234)	mem 42.125
Train: [98][655/750]	BT 0.033 (1.159)	DT 0.001 (1.117)	loss nan (nan)	prob nan (nan)	GS 26.156 (26.156)	mem 42.270
Train: [98][660/750]	BT 0.052 (1.151)	DT 0.001 (1.108)	loss nan (nan)	prob nan (nan)	GS 32.828 (32.828)	mem 42.166
Train: [98][665/750]	BT 0.062 (1.143)	DT 0.009 (1.100)	loss nan (nan)	prob nan (nan)	GS 31.438 (31.438)	mem 42.263
Train: [98][670/750]	BT 0.076 (1.153)	DT 0.001 (1.110)	loss nan (nan)	prob nan (nan)	GS 34.125 (34.125)	mem 42.161
Train: [98][675/750]	BT 0.107 (1.145)	DT 0.020 (1.102)	loss nan (nan)	prob nan (nan)	GS 26.297 (26.297)	mem 42.163
Train: [98][680/750]	BT 4.257 (1.160)	DT 4.226 (1.117)	loss nan (nan)	prob nan (nan)	GS 34.219 (34.219)	mem 42.221
Train: [98][685/750]	BT 0.086 (1.152)	DT 0.002 (1.109)	loss nan (nan)	prob nan (nan)	GS 31.125 (31.125)	mem 42.220
Train: [98][690/750]	BT 4.491 (1.150)	DT 4.459 (1.107)	loss nan (nan)	prob nan (nan)	GS 33.391 (33.391)	mem 42.227
Train: [98][695/750]	BT 0.062 (1.154)	DT 0.009 (1.111)	loss nan (nan)	prob nan (nan)	GS 33.703 (33.703)	mem 42.279
Train: [98][700/750]	BT 0.042 (1.146)	DT 0.002 (1.103)	loss nan (nan)	prob nan (nan)	GS 32.984 (32.984)	mem 42.343
Train: [98][705/750]	BT 0.035 (1.157)	DT 0.001 (1.114)	loss nan (nan)	prob nan (nan)	GS 28.359 (28.359)	mem 42.403
arpack error, retry= 0
arpack error, retry= 0
Train: [98][710/750]	BT 0.115 (1.150)	DT 0.008 (1.107)	loss nan (nan)	prob nan (nan)	GS 34.062 (34.062)	mem 42.216
Train: [98][715/750]	BT 0.032 (1.142)	DT 0.001 (1.099)	loss nan (nan)	prob nan (nan)	GS 29.469 (29.469)	mem 42.176
Train: [98][720/750]	BT 0.033 (1.152)	DT 0.001 (1.109)	loss nan (nan)	prob nan (nan)	GS 31.766 (31.766)	mem 42.246
Train: [98][725/750]	BT 0.042 (1.148)	DT 0.003 (1.105)	loss nan (nan)	prob nan (nan)	GS 30.453 (30.453)	mem 42.223
Train: [98][730/750]	BT 0.023 (1.152)	DT 0.001 (1.109)	loss nan (nan)	prob nan (nan)	GS 41.703 (41.703)	mem 41.841
Train: [98][735/750]	BT 0.071 (1.148)	DT 0.008 (1.106)	loss nan (nan)	prob nan (nan)	GS 30.062 (30.062)	mem 39.417
Train: [98][740/750]	BT 6.863 (1.150)	DT 6.832 (1.107)	loss nan (nan)	prob nan (nan)	GS 33.656 (33.656)	mem 15.848
Train: [98][745/750]	BT 0.032 (1.143)	DT 0.002 (1.100)	loss nan (nan)	prob nan (nan)	GS 27.781 (27.781)	mem 15.848
Train: [98][750/750]	BT 0.033 (1.135)	DT 0.002 (1.093)	loss nan (nan)	prob nan (nan)	GS 33.125 (33.125)	mem 15.847
Train: [98][755/750]	BT 0.024 (1.132)	DT 0.001 (1.089)	loss nan (nan)	prob nan (nan)	GS 31.656 (31.656)	mem 9.798
epoch 98, total time 854.54
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.local/lib/python3.9/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [99][1/750]	BT 20.694 (20.694)	DT 20.649 (20.649)	loss nan (nan)	prob nan (nan)	GS 32.312 (32.312)	mem 40.669
Train: [99][5/750]	BT 0.034 (4.486)	DT 0.002 (4.451)	loss nan (nan)	prob nan (nan)	GS 32.656 (32.656)	mem 40.745
Train: [99][10/750]	BT 0.032 (2.383)	DT 0.001 (2.347)	loss nan (nan)	prob nan (nan)	GS 35.391 (35.391)	mem 40.749
Train: [99][15/750]	BT 0.120 (2.095)	DT 0.020 (2.049)	loss nan (nan)	prob nan (nan)	GS 30.031 (30.031)	mem 40.984
Train: [99][20/750]	BT 2.057 (1.938)	DT 2.022 (1.892)	loss nan (nan)	prob nan (nan)	GS 32.797 (32.797)	mem 41.047
Train: [99][25/750]	BT 0.208 (1.576)	DT 0.111 (1.530)	loss nan (nan)	prob nan (nan)	GS 28.609 (28.609)	mem 41.136
Train: [99][30/750]	BT 0.049 (1.774)	DT 0.009 (1.728)	loss nan (nan)	prob nan (nan)	GS 30.828 (30.828)	mem 41.234
Train: [99][35/750]	BT 0.032 (1.527)	DT 0.001 (1.482)	loss nan (nan)	prob nan (nan)	GS 29.125 (29.125)	mem 41.244
Train: [99][40/750]	BT 3.225 (1.680)	DT 3.168 (1.634)	loss nan (nan)	prob nan (nan)	GS 33.484 (33.484)	mem 41.336
Train: [99][45/750]	BT 0.115 (1.500)	DT 0.055 (1.454)	loss nan (nan)	prob nan (nan)	GS 30.703 (30.703)	mem 41.419
Train: [99][50/750]	BT 9.479 (1.564)	DT 9.378 (1.517)	loss nan (nan)	prob nan (nan)	GS 31.922 (31.922)	mem 41.347
Train: [99][55/750]	BT 0.034 (1.481)	DT 0.001 (1.434)	loss nan (nan)	prob nan (nan)	GS 29.938 (29.938)	mem 41.354
Train: [99][60/750]	BT 0.041 (1.360)	DT 0.001 (1.315)	loss nan (nan)	prob nan (nan)	GS 32.844 (32.844)	mem 41.443
Train: [99][65/750]	BT 0.035 (1.436)	DT 0.001 (1.390)	loss nan (nan)	prob nan (nan)	GS 39.062 (39.062)	mem 41.310
Train: [99][70/750]	BT 0.078 (1.345)	DT 0.003 (1.298)	loss nan (nan)	prob nan (nan)	GS 34.047 (34.047)	mem 41.276
Train: [99][75/750]	BT 0.097 (1.375)	DT 0.002 (1.328)	loss nan (nan)	prob nan (nan)	GS 29.531 (29.531)	mem 41.650
Train: [99][80/750]	BT 1.634 (1.348)	DT 1.584 (1.302)	loss nan (nan)	prob nan (nan)	GS 36.359 (36.359)	mem 41.365
Train: [99][85/750]	BT 0.031 (1.271)	DT 0.002 (1.225)	loss nan (nan)	prob nan (nan)	GS 31.062 (31.062)	mem 41.302
Train: [99][90/750]	BT 0.048 (1.337)	DT 0.004 (1.290)	loss nan (nan)	prob nan (nan)	GS 36.875 (36.875)	mem 41.344
Train: [99][95/750]	BT 0.032 (1.322)	DT 0.002 (1.276)	loss nan (nan)	prob nan (nan)	GS 31.625 (31.625)	mem 41.424
Train: [99][100/750]	BT 8.431 (1.342)	DT 8.382 (1.296)	loss nan (nan)	prob nan (nan)	GS 33.828 (33.828)	mem 41.420
Train: [99][105/750]	BT 0.057 (1.317)	DT 0.025 (1.271)	loss nan (nan)	prob nan (nan)	GS 32.594 (32.594)	mem 41.364
Train: [99][110/750]	BT 1.072 (1.269)	DT 1.038 (1.223)	loss nan (nan)	prob nan (nan)	GS 30.828 (30.828)	mem 41.453
Train: [99][115/750]	BT 0.165 (1.336)	DT 0.010 (1.288)	loss nan (nan)	prob nan (nan)	GS 31.562 (31.562)	mem 41.577
Train: [99][120/750]	BT 0.025 (1.282)	DT 0.001 (1.234)	loss nan (nan)	prob nan (nan)	GS 36.469 (36.469)	mem 41.578
Train: [99][125/750]	BT 0.078 (1.340)	DT 0.023 (1.292)	loss nan (nan)	prob nan (nan)	GS 34.719 (34.719)	mem 41.776
Train: [99][130/750]	BT 0.071 (1.290)	DT 0.001 (1.243)	loss nan (nan)	prob nan (nan)	GS 37.359 (37.359)	mem 41.660
Train: [99][135/750]	BT 0.071 (1.246)	DT 0.012 (1.197)	loss nan (nan)	prob nan (nan)	GS 30.625 (30.625)	mem 41.667
Train: [99][140/750]	BT 0.038 (1.287)	DT 0.012 (1.239)	loss nan (nan)	prob nan (nan)	GS 31.594 (31.594)	mem 41.632
Train: [99][145/750]	BT 0.091 (1.245)	DT 0.011 (1.197)	loss nan (nan)	prob nan (nan)	GS 32.188 (32.188)	mem 41.633
Train: [99][150/750]	BT 0.037 (1.289)	DT 0.009 (1.241)	loss nan (nan)	prob nan (nan)	GS 32.781 (32.781)	mem 41.648
Train: [99][155/750]	BT 0.030 (1.248)	DT 0.001 (1.201)	loss nan (nan)	prob nan (nan)	GS 27.047 (27.047)	mem 41.648
Train: [99][160/750]	BT 8.748 (1.272)	DT 8.715 (1.225)	loss nan (nan)	prob nan (nan)	GS 31.203 (31.203)	mem 41.899
Train: [99][165/750]	BT 0.032 (1.235)	DT 0.001 (1.188)	loss nan (nan)	prob nan (nan)	GS 32.203 (32.203)	mem 41.826
Train: [99][170/750]	BT 5.155 (1.230)	DT 5.083 (1.183)	loss nan (nan)	prob nan (nan)	GS 31.000 (31.000)	mem 41.934
Train: [99][175/750]	BT 0.033 (1.238)	DT 0.002 (1.191)	loss nan (nan)	prob nan (nan)	GS 39.547 (39.547)	mem 41.925
Train: [99][180/750]	BT 0.069 (1.205)	DT 0.002 (1.158)	loss nan (nan)	prob nan (nan)	GS 36.297 (36.297)	mem 41.927
Train: [99][185/750]	BT 0.023 (1.253)	DT 0.001 (1.206)	loss nan (nan)	prob nan (nan)	GS 30.984 (30.984)	mem 41.975
Train: [99][190/750]	BT 0.034 (1.221)	DT 0.001 (1.175)	loss nan (nan)	prob nan (nan)	GS 30.875 (30.875)	mem 42.010
Train: [99][195/750]	BT 0.038 (1.210)	DT 0.001 (1.164)	loss nan (nan)	prob nan (nan)	GS 34.219 (34.219)	mem 42.168
Train: [99][200/750]	BT 0.050 (1.232)	DT 0.010 (1.186)	loss nan (nan)	prob nan (nan)	GS 31.688 (31.688)	mem 42.021
Train: [99][205/750]	BT 0.031 (1.203)	DT 0.001 (1.157)	loss nan (nan)	prob nan (nan)	GS 29.766 (29.766)	mem 42.022
Train: [99][210/750]	BT 3.758 (1.231)	DT 3.725 (1.185)	loss nan (nan)	prob nan (nan)	GS 33.844 (33.844)	mem 41.982
Train: [99][215/750]	BT 0.048 (1.203)	DT 0.005 (1.157)	loss nan (nan)	prob nan (nan)	GS 44.016 (44.016)	mem 41.944
Train: [99][220/750]	BT 11.572 (1.234)	DT 11.532 (1.189)	loss nan (nan)	prob nan (nan)	GS 35.094 (35.094)	mem 41.916
Train: [99][225/750]	BT 0.076 (1.213)	DT 0.001 (1.168)	loss nan (nan)	prob nan (nan)	GS 29.250 (29.250)	mem 41.944
Train: [99][230/750]	BT 3.642 (1.204)	DT 3.560 (1.158)	loss nan (nan)	prob nan (nan)	GS 34.406 (34.406)	mem 42.259
Train: [99][235/750]	BT 0.067 (1.222)	DT 0.004 (1.176)	loss nan (nan)	prob nan (nan)	GS 26.625 (26.625)	mem 42.136
Train: [99][240/750]	BT 0.029 (1.197)	DT 0.001 (1.152)	loss nan (nan)	prob nan (nan)	GS 29.375 (29.375)	mem 42.035
Train: [99][245/750]	BT 0.077 (1.196)	DT 0.004 (1.150)	loss nan (nan)	prob nan (nan)	GS 33.438 (33.438)	mem 42.116
Train: [99][250/750]	BT 0.056 (1.195)	DT 0.004 (1.149)	loss nan (nan)	prob nan (nan)	GS 31.578 (31.578)	mem 42.019
Train: [99][255/750]	BT 0.067 (1.174)	DT 0.005 (1.128)	loss nan (nan)	prob nan (nan)	GS 33.062 (33.062)	mem 42.111
Train: [99][260/750]	BT 0.061 (1.200)	DT 0.003 (1.153)	loss nan (nan)	prob nan (nan)	GS 41.125 (41.125)	mem 42.009
Train: [99][265/750]	BT 0.041 (1.178)	DT 0.001 (1.132)	loss nan (nan)	prob nan (nan)	GS 30.625 (30.625)	mem 42.010
Train: [99][270/750]	BT 5.937 (1.203)	DT 5.903 (1.157)	loss nan (nan)	prob nan (nan)	GS 33.203 (33.203)	mem 42.084
Train: [99][275/750]	BT 0.023 (1.182)	DT 0.001 (1.136)	loss nan (nan)	prob nan (nan)	GS 31.750 (31.750)	mem 42.085
Train: [99][280/750]	BT 8.971 (1.193)	DT 8.939 (1.148)	loss nan (nan)	prob nan (nan)	GS 34.219 (34.219)	mem 42.121
Train: [99][285/750]	BT 0.026 (1.188)	DT 0.001 (1.143)	loss nan (nan)	prob nan (nan)	GS 29.422 (29.422)	mem 42.082
Train: [99][290/750]	BT 0.031 (1.168)	DT 0.001 (1.123)	loss nan (nan)	prob nan (nan)	GS 34.781 (34.781)	mem 42.083
Train: [99][295/750]	BT 0.037 (1.189)	DT 0.002 (1.143)	loss nan (nan)	prob nan (nan)	GS 33.297 (33.297)	mem 42.169
Train: [99][300/750]	BT 0.032 (1.169)	DT 0.001 (1.124)	loss nan (nan)	prob nan (nan)	GS 33.594 (33.594)	mem 42.051
Train: [99][305/750]	BT 0.035 (1.185)	DT 0.001 (1.140)	loss nan (nan)	prob nan (nan)	GS 27.844 (27.844)	mem 42.084
Train: [99][310/750]	BT 0.033 (1.174)	DT 0.010 (1.130)	loss nan (nan)	prob nan (nan)	GS 39.422 (39.422)	mem 42.099
Train: [99][315/750]	BT 0.105 (1.157)	DT 0.022 (1.112)	loss nan (nan)	prob nan (nan)	GS 37.406 (37.406)	mem 42.221
Train: [99][320/750]	BT 0.046 (1.183)	DT 0.004 (1.138)	loss nan (nan)	prob nan (nan)	GS 34.938 (34.938)	mem 42.109
Train: [99][325/750]	BT 0.048 (1.165)	DT 0.009 (1.120)	loss nan (nan)	prob nan (nan)	GS 25.297 (25.297)	mem 42.109
Train: [99][330/750]	BT 7.364 (1.183)	DT 7.278 (1.138)	loss nan (nan)	prob nan (nan)	GS 34.141 (34.141)	mem 42.195
Train: [99][335/750]	BT 0.033 (1.166)	DT 0.001 (1.121)	loss nan (nan)	prob nan (nan)	GS 31.266 (31.266)	mem 42.284
Train: [99][340/750]	BT 7.386 (1.171)	DT 7.354 (1.126)	loss nan (nan)	prob nan (nan)	GS 32.406 (32.406)	mem 42.138
Train: [99][345/750]	BT 0.022 (1.175)	DT 0.001 (1.130)	loss nan (nan)	prob nan (nan)	GS 28.625 (28.625)	mem 42.167
Train: [99][350/750]	BT 0.041 (1.159)	DT 0.001 (1.114)	loss nan (nan)	prob nan (nan)	GS 31.438 (31.438)	mem 42.160
Train: [99][355/750]	BT 0.088 (1.184)	DT 0.022 (1.139)	loss nan (nan)	prob nan (nan)	GS 31.266 (31.266)	mem 42.306
Train: [99][360/750]	BT 0.030 (1.168)	DT 0.001 (1.123)	loss nan (nan)	prob nan (nan)	GS 33.406 (33.406)	mem 42.175
Train: [99][365/750]	BT 0.028 (1.153)	DT 0.001 (1.108)	loss nan (nan)	prob nan (nan)	GS 28.625 (28.625)	mem 42.175
Train: [99][370/750]	BT 0.035 (1.170)	DT 0.001 (1.125)	loss nan (nan)	prob nan (nan)	GS 30.125 (30.125)	mem 42.337
Train: [99][375/750]	BT 0.057 (1.156)	DT 0.012 (1.111)	loss nan (nan)	prob nan (nan)	GS 26.469 (26.469)	mem 42.184
Train: [99][380/750]	BT 0.048 (1.171)	DT 0.009 (1.127)	loss nan (nan)	prob nan (nan)	GS 36.516 (36.516)	mem 42.133
Train: [99][385/750]	BT 0.038 (1.157)	DT 0.001 (1.112)	loss nan (nan)	prob nan (nan)	GS 27.328 (27.328)	mem 42.132
Train: [99][390/750]	BT 12.929 (1.175)	DT 12.874 (1.131)	loss nan (nan)	prob nan (nan)	GS 31.516 (31.516)	mem 42.243
Train: [99][395/750]	BT 0.031 (1.161)	DT 0.001 (1.117)	loss nan (nan)	prob nan (nan)	GS 33.188 (33.188)	mem 42.198
Train: [99][400/750]	BT 0.082 (1.147)	DT 0.019 (1.103)	loss nan (nan)	prob nan (nan)	GS 34.109 (34.109)	mem 42.266
Train: [99][405/750]	BT 0.066 (1.158)	DT 0.004 (1.113)	loss nan (nan)	prob nan (nan)	GS 30.422 (30.422)	mem 42.202
Train: [99][410/750]	BT 0.052 (1.144)	DT 0.010 (1.100)	loss nan (nan)	prob nan (nan)	GS 35.781 (35.781)	mem 42.099
Train: [99][415/750]	BT 0.104 (1.152)	DT 0.013 (1.107)	loss nan (nan)	prob nan (nan)	GS 28.031 (28.031)	mem 42.138
Train: [99][420/750]	BT 0.032 (1.139)	DT 0.001 (1.094)	loss nan (nan)	prob nan (nan)	GS 31.812 (31.812)	mem 42.138
Train: [99][425/750]	BT 0.129 (1.131)	DT 0.058 (1.086)	loss nan (nan)	prob nan (nan)	GS 35.547 (35.547)	mem 42.072
Train: [99][430/750]	BT 0.099 (1.137)	DT 0.003 (1.092)	loss nan (nan)	prob nan (nan)	GS 35.531 (35.531)	mem 42.119
Train: [99][435/750]	BT 0.078 (1.124)	DT 0.003 (1.079)	loss nan (nan)	prob nan (nan)	GS 36.531 (36.531)	mem 42.121
Train: [99][440/750]	BT 0.047 (1.142)	DT 0.013 (1.097)	loss nan (nan)	prob nan (nan)	GS 30.766 (30.766)	mem 42.085
Train: [99][445/750]	BT 0.051 (1.130)	DT 0.012 (1.085)	loss nan (nan)	prob nan (nan)	GS 28.578 (28.578)	mem 42.034
Train: [99][450/750]	BT 6.972 (1.143)	DT 6.938 (1.099)	loss nan (nan)	prob nan (nan)	GS 30.234 (30.234)	mem 42.108
Train: [99][455/750]	BT 0.079 (1.132)	DT 0.004 (1.087)	loss nan (nan)	prob nan (nan)	GS 29.078 (29.078)	mem 42.110
Train: [99][460/750]	BT 6.494 (1.134)	DT 6.467 (1.089)	loss nan (nan)	prob nan (nan)	GS 37.359 (37.359)	mem 42.143
Train: [99][465/750]	BT 0.035 (1.128)	DT 0.002 (1.083)	loss nan (nan)	prob nan (nan)	GS 28.891 (28.891)	mem 42.290
Train: [99][470/750]	BT 0.044 (1.116)	DT 0.004 (1.071)	loss nan (nan)	prob nan (nan)	GS 36.500 (36.500)	mem 42.226
Train: [99][475/750]	BT 0.043 (1.136)	DT 0.001 (1.091)	loss nan (nan)	prob nan (nan)	GS 31.125 (31.125)	mem 42.269
Train: [99][480/750]	BT 0.033 (1.125)	DT 0.001 (1.079)	loss nan (nan)	prob nan (nan)	GS 35.828 (35.828)	mem 42.235
Train: [99][485/750]	BT 0.112 (1.126)	DT 0.033 (1.081)	loss nan (nan)	prob nan (nan)	GS 33.062 (33.062)	mem 42.199
Train: [99][490/750]	BT 0.057 (1.126)	DT 0.003 (1.080)	loss nan (nan)	prob nan (nan)	GS 28.594 (28.594)	mem 42.288
Train: [99][495/750]	BT 0.052 (1.115)	DT 0.002 (1.069)	loss nan (nan)	prob nan (nan)	GS 30.594 (30.594)	mem 42.193
Train: [99][500/750]	BT 0.034 (1.132)	DT 0.002 (1.087)	loss nan (nan)	prob nan (nan)	GS 32.031 (32.031)	mem 42.341
Train: [99][505/750]	BT 0.044 (1.122)	DT 0.010 (1.076)	loss nan (nan)	prob nan (nan)	GS 30.172 (30.172)	mem 42.237
Train: [99][510/750]	BT 1.135 (1.131)	DT 1.077 (1.085)	loss nan (nan)	prob nan (nan)	GS 29.672 (29.672)	mem 42.199
Train: [99][515/750]	BT 0.029 (1.120)	DT 0.001 (1.075)	loss nan (nan)	prob nan (nan)	GS 37.234 (37.234)	mem 42.197
Train: [99][520/750]	BT 10.953 (1.131)	DT 10.921 (1.086)	loss nan (nan)	prob nan (nan)	GS 32.156 (32.156)	mem 42.274
Train: [99][525/750]	BT 0.029 (1.126)	DT 0.002 (1.081)	loss nan (nan)	prob nan (nan)	GS 29.031 (29.031)	mem 42.269
Train: [99][530/750]	BT 0.043 (1.118)	DT 0.001 (1.072)	loss nan (nan)	prob nan (nan)	GS 31.141 (31.141)	mem 42.271
Train: [99][535/750]	BT 0.062 (1.130)	DT 0.010 (1.085)	loss nan (nan)	prob nan (nan)	GS 27.609 (27.609)	mem 42.454
Train: [99][540/750]	BT 0.033 (1.127)	DT 0.002 (1.082)	loss nan (nan)	prob nan (nan)	GS 36.938 (36.938)	mem 42.303
Train: [99][545/750]	BT 0.060 (1.120)	DT 0.002 (1.075)	loss nan (nan)	prob nan (nan)	GS 33.156 (33.156)	mem 42.283
Train: [99][550/750]	BT 7.555 (1.133)	DT 7.526 (1.088)	loss nan (nan)	prob nan (nan)	GS 29.938 (29.938)	mem 42.247
Train: [99][555/750]	BT 0.026 (1.123)	DT 0.002 (1.078)	loss nan (nan)	prob nan (nan)	GS 31.969 (31.969)	mem 42.258
Train: [99][560/750]	BT 0.062 (1.114)	DT 0.025 (1.069)	loss nan (nan)	prob nan (nan)	GS 32.891 (32.891)	mem 42.259
Train: [99][565/750]	BT 0.037 (1.124)	DT 0.001 (1.079)	loss nan (nan)	prob nan (nan)	GS 32.234 (32.234)	mem 42.191
Train: [99][570/750]	BT 2.616 (1.119)	DT 2.587 (1.075)	loss nan (nan)	prob nan (nan)	GS 35.078 (35.078)	mem 42.199
Train: [99][575/750]	BT 0.031 (1.129)	DT 0.001 (1.084)	loss nan (nan)	prob nan (nan)	GS 31.750 (31.750)	mem 42.218
Train: [99][580/750]	BT 0.033 (1.119)	DT 0.001 (1.075)	loss nan (nan)	prob nan (nan)	GS 31.172 (31.172)	mem 42.178
Train: [99][585/750]	BT 0.025 (1.118)	DT 0.001 (1.073)	loss nan (nan)	prob nan (nan)	GS 30.156 (30.156)	mem 42.155
Train: [99][590/750]	BT 0.048 (1.122)	DT 0.013 (1.077)	loss nan (nan)	prob nan (nan)	GS 31.547 (31.547)	mem 42.217
Train: [99][595/750]	BT 0.038 (1.122)	DT 0.002 (1.077)	loss nan (nan)	prob nan (nan)	GS 29.547 (29.547)	mem 42.205
Train: [99][600/750]	BT 0.035 (1.126)	DT 0.005 (1.081)	loss nan (nan)	prob nan (nan)	GS 31.953 (31.953)	mem 42.218
Train: [99][605/750]	BT 0.038 (1.117)	DT 0.002 (1.073)	loss nan (nan)	prob nan (nan)	GS 31.203 (31.203)	mem 42.218
Train: [99][610/750]	BT 4.130 (1.128)	DT 4.098 (1.084)	loss nan (nan)	prob nan (nan)	GS 35.062 (35.062)	mem 42.273
Train: [99][615/750]	BT 0.072 (1.120)	DT 0.001 (1.075)	loss nan (nan)	prob nan (nan)	GS 35.641 (35.641)	mem 42.313
Train: [99][620/750]	BT 0.024 (1.126)	DT 0.001 (1.082)	loss nan (nan)	prob nan (nan)	GS 30.516 (30.516)	mem 42.292
Train: [99][625/750]	BT 0.032 (1.126)	DT 0.002 (1.082)	loss nan (nan)	prob nan (nan)	GS 31.156 (31.156)	mem 42.264
Train: [99][630/750]	BT 7.773 (1.130)	DT 7.729 (1.085)	loss nan (nan)	prob nan (nan)	GS 33.859 (33.859)	mem 42.068
Train: [99][635/750]	BT 0.073 (1.122)	DT 0.001 (1.077)	loss nan (nan)	prob nan (nan)	GS 30.141 (30.141)	mem 42.047
Train: [99][640/750]	BT 0.039 (1.118)	DT 0.002 (1.073)	loss nan (nan)	prob nan (nan)	GS 32.562 (32.562)	mem 42.135
Train: [99][645/750]	BT 0.038 (1.127)	DT 0.002 (1.082)	loss nan (nan)	prob nan (nan)	GS 31.328 (31.328)	mem 42.127
Train: [99][650/750]	BT 0.036 (1.121)	DT 0.002 (1.076)	loss nan (nan)	prob nan (nan)	GS 31.859 (31.859)	mem 42.465
Train: [99][655/750]	BT 0.033 (1.124)	DT 0.002 (1.080)	loss nan (nan)	prob nan (nan)	GS 44.703 (44.703)	mem 42.210
Train: [99][660/750]	BT 0.038 (1.123)	DT 0.015 (1.078)	loss nan (nan)	prob nan (nan)	GS 32.078 (32.078)	mem 42.163
Train: [99][665/750]	BT 0.032 (1.115)	DT 0.002 (1.070)	loss nan (nan)	prob nan (nan)	GS 29.859 (29.859)	mem 42.196
Train: [99][670/750]	BT 0.925 (1.122)	DT 0.894 (1.078)	loss nan (nan)	prob nan (nan)	GS 33.969 (33.969)	mem 42.188
Train: [99][675/750]	BT 0.060 (1.114)	DT 0.004 (1.070)	loss nan (nan)	prob nan (nan)	GS 33.594 (33.594)	mem 42.223
Train: [99][680/750]	BT 0.065 (1.123)	DT 0.005 (1.079)	loss nan (nan)	prob nan (nan)	GS 36.047 (36.047)	mem 42.341
Train: [99][685/750]	BT 0.098 (1.119)	DT 0.045 (1.074)	loss nan (nan)	prob nan (nan)	GS 31.859 (31.859)	mem 42.184
Train: [99][690/750]	BT 9.375 (1.125)	DT 9.348 (1.080)	loss nan (nan)	prob nan (nan)	GS 32.047 (32.047)	mem 42.190
Train: [99][695/750]	BT 0.041 (1.125)	DT 0.002 (1.080)	loss nan (nan)	prob nan (nan)	GS 36.578 (36.578)	mem 42.265
Train: [99][700/750]	BT 0.036 (1.118)	DT 0.002 (1.073)	loss nan (nan)	prob nan (nan)	GS 38.188 (38.188)	mem 42.422
Train: [99][705/750]	BT 0.051 (1.118)	DT 0.002 (1.073)	loss nan (nan)	prob nan (nan)	GS 33.406 (33.406)	mem 42.179
arpack error, retry= 0
arpack error, retry= 0
Train: [99][710/750]	BT 0.047 (1.120)	DT 0.005 (1.075)	loss nan (nan)	prob nan (nan)	GS 31.641 (31.641)	mem 42.169
Train: [99][715/750]	BT 0.026 (1.120)	DT 0.001 (1.075)	loss nan (nan)	prob nan (nan)	GS 36.375 (36.375)	mem 42.221
Train: [99][720/750]	BT 0.033 (1.119)	DT 0.002 (1.074)	loss nan (nan)	prob nan (nan)	GS 34.203 (34.203)	mem 42.160
Train: [99][725/750]	BT 0.059 (1.111)	DT 0.009 (1.066)	loss nan (nan)	prob nan (nan)	GS 31.172 (31.172)	mem 42.190
Train: [99][730/750]	BT 1.178 (1.118)	DT 1.135 (1.074)	loss nan (nan)	prob nan (nan)	GS 36.391 (36.391)	mem 41.814
Train: [99][735/750]	BT 0.031 (1.111)	DT 0.002 (1.066)	loss nan (nan)	prob nan (nan)	GS 31.844 (31.844)	mem 41.817
Train: [99][740/750]	BT 0.021 (1.112)	DT 0.001 (1.067)	loss nan (nan)	prob nan (nan)	GS 31.094 (31.094)	mem 15.752
Train: [99][745/750]	BT 0.021 (1.109)	DT 0.001 (1.064)	loss nan (nan)	prob nan (nan)	GS 34.344 (34.344)	mem 12.740
Train: [99][750/750]	BT 0.025 (1.102)	DT 0.001 (1.057)	loss nan (nan)	prob nan (nan)	GS 28.562 (28.562)	mem 12.740
Train: [99][755/750]	BT 0.020 (1.099)	DT 0.001 (1.054)	loss nan (nan)	prob nan (nan)	GS 29.719 (29.719)	mem 9.791
epoch 99, total time 829.76
==> Saving...
==> Saving...
