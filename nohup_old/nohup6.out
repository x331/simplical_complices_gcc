Graph(num_nodes=20, num_edges=292,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)})
cuda:1
Namespace(alpha=0.999, aug='1st', batch_size=32, beta1=0.9, beta2=0.999, clip_norm=1.0, cv=False, cvrun=-1, dataset='dgl', degree_embedding_size=16, epochs=100, exp='Pretrain', finetune=False, fold_idx=0, freq_embedding_size=16, gpu=0, hidden_size=64, learning_rate=0.005, load_path=None, lr_decay_epochs=[120, 160, 200], lr_decay_rate=0.0, max_degree=512, max_edge_freq=16, max_node_freq=16, moco=True, model='gin', model_folder='saved/Pretrain_moco_True_dgl_gin_layer_5_lr_0.005_decay_1e-05_bsz_32_hid_64_samples_2000_nce_t_0.07_nce_k_16384_rw_hops_256_restart_prob_0.8_aug_1st_ft_False_deg_16_pos_32_momentum_0.999', model_name='Pretrain_moco_True_dgl_gin_layer_5_lr_0.005_decay_1e-05_bsz_32_hid_64_samples_2000_nce_t_0.07_nce_k_16384_rw_hops_256_restart_prob_0.8_aug_1st_ft_False_deg_16_pos_32_momentum_0.999', model_path='saved', momentum=0.9, nce_k=16384, nce_t=0.07, norm=True, num_copies=12, num_layer=5, num_samples=2000, num_workers=24, optimizer='adam', positional_embedding_size=32, print_freq=10, readout='avg', restart_prob=0.8, resume='', rw_hops=256, save_freq=1, seed=0, set2set_iter=6, set2set_lstm_layer=3, subgraph_size=128, tb_folder='tensorboard/Pretrain_moco_True_dgl_gin_layer_5_lr_0.005_decay_1e-05_bsz_32_hid_64_samples_2000_nce_t_0.07_nce_k_16384_rw_hops_256_restart_prob_0.8_aug_1st_ft_False_deg_16_pos_32_momentum_0.999', tb_freq=50, tb_path='tensorboard', weight_decay=1e-05)
Pretrain_moco_True_dgl_gin_layer_5_lr_0.005_decay_1e-05_bsz_32_hid_64_samples_2000_nce_t_0.07_nce_k_16384_rw_hops_256_restart_prob_0.8_aug_1st_ft_False_deg_16_pos_32_momentum_0.999
Use GPU: 0 for training
setting random seeds
before construct dataset 5.254283905029297
load graph done
before construct dataloader 5.254283905029297
before training 5.254283905029297
using queue shape: (16384,64)
==> training...
moco1
moco2
moco3
moco4
Train: [0][1/1500]	BT 20.379 (20.379)	DT 19.080 (19.080)	loss 5.540 (5.540)	prob 5.742 (5.742)	GS 33.891 (33.891)	mem 74.267
Train: [0][10/1500]	BT 0.059 (2.785)	DT 0.000 (2.603)	loss 9.620 (9.793)	prob 0.086 (0.172)	GS 34.375 (32.109)	mem 74.510
Train: [0][20/1500]	BT 0.039 (1.498)	DT 0.001 (1.388)	loss 9.511 (9.673)	prob 0.203 (0.158)	GS 33.438 (33.070)	mem 74.700
Train: [0][30/1500]	BT 1.750 (1.070)	DT 1.704 (0.983)	loss 9.442 (9.600)	prob 0.284 (0.192)	GS 34.250 (33.011)	mem 74.955
Train: [0][40/1500]	BT 0.037 (1.006)	DT 0.000 (0.931)	loss 9.384 (9.546)	prob 0.363 (0.235)	GS 31.031 (32.834)	mem 75.741
Train: [0][50/1500]	BT 0.036 (0.813)	DT 0.001 (0.745)	loss 9.312 (9.497)	prob 0.464 (0.280)	GS 34.078 (32.906)	mem 75.751
Train: [0][60/1500]	BT 0.040 (0.777)	DT 0.000 (0.714)	loss 9.193 (9.249)	prob 0.612 (0.541)	GS 32.188 (32.134)	mem 75.811
Train: [0][70/1500]	BT 0.039 (0.671)	DT 0.001 (0.612)	loss 9.173 (9.219)	prob 0.686 (0.592)	GS 35.047 (32.306)	mem 75.815
Train: [0][80/1500]	BT 0.040 (0.606)	DT 0.001 (0.549)	loss 9.152 (9.211)	prob 0.707 (0.618)	GS 34.781 (33.183)	mem 75.844
Train: [0][90/1500]	BT 0.061 (0.580)	DT 0.003 (0.524)	loss 9.089 (9.194)	prob 0.848 (0.652)	GS 31.672 (33.172)	mem 75.931
Train: [0][100/1500]	BT 0.038 (0.579)	DT 0.001 (0.524)	loss 9.123 (9.180)	prob 0.822 (0.686)	GS 33.031 (33.193)	mem 76.000
Train: [0][110/1500]	BT 0.042 (0.530)	DT 0.001 (0.476)	loss 9.088 (9.117)	prob 0.945 (0.882)	GS 31.516 (31.766)	mem 76.009
Train: [0][120/1500]	BT 0.052 (0.491)	DT 0.001 (0.437)	loss 9.155 (9.121)	prob 0.916 (0.892)	GS 31.422 (31.714)	mem 76.018
Train: [0][130/1500]	BT 0.069 (0.506)	DT 0.004 (0.452)	loss 9.146 (9.115)	prob 0.949 (0.922)	GS 31.391 (31.560)	mem 76.289
Train: [0][140/1500]	BT 0.061 (0.473)	DT 0.017 (0.420)	loss 9.235 (9.121)	prob 0.875 (0.936)	GS 33.906 (32.098)	mem 76.315
Train: [0][150/1500]	BT 0.039 (0.478)	DT 0.000 (0.425)	loss 9.064 (9.128)	prob 1.091 (0.947)	GS 34.312 (32.178)	mem 77.933
Train: [0][160/1500]	BT 0.037 (0.463)	DT 0.000 (0.411)	loss 9.226 (9.185)	prob 0.972 (1.009)	GS 34.172 (33.055)	mem 79.083
Train: [0][170/1500]	BT 0.045 (0.439)	DT 0.010 (0.387)	loss 9.171 (9.173)	prob 1.076 (1.042)	GS 35.109 (32.859)	mem 79.257
Train: [0][180/1500]	BT 0.038 (0.441)	DT 0.001 (0.390)	loss 9.165 (9.178)	prob 1.129 (1.054)	GS 39.234 (32.729)	mem 76.468
Train: [0][190/1500]	BT 0.039 (0.420)	DT 0.001 (0.370)	loss 9.318 (9.191)	prob 1.026 (1.060)	GS 35.203 (32.608)	mem 76.483
Train: [0][200/1500]	BT 0.039 (0.407)	DT 0.001 (0.358)	loss 9.217 (9.195)	prob 1.126 (1.074)	GS 36.375 (32.591)	mem 76.551
Train: [0][210/1500]	BT 0.038 (0.396)	DT 0.001 (0.347)	loss 9.332 (9.208)	prob 1.051 (1.189)	GS 29.719 (32.673)	mem 76.611
Train: [0][220/1500]	BT 0.056 (0.388)	DT 0.000 (0.340)	loss 9.349 (9.257)	prob 0.975 (1.122)	GS 33.828 (33.248)	mem 76.652
Train: [0][230/1500]	BT 0.037 (0.380)	DT 0.000 (0.332)	loss 9.298 (9.255)	prob 1.084 (1.132)	GS 28.875 (33.031)	mem 76.680
Train: [0][240/1500]	BT 0.037 (0.370)	DT 0.000 (0.322)	loss 9.240 (9.267)	prob 1.139 (1.128)	GS 34.594 (33.010)	mem 76.706
Train: [0][250/1500]	BT 0.038 (0.368)	DT 0.001 (0.320)	loss 9.319 (9.282)	prob 1.093 (1.120)	GS 34.594 (32.978)	mem 76.778
Train: [0][260/1500]	BT 0.040 (0.357)	DT 0.000 (0.310)	loss 9.344 (9.353)	prob 1.099 (1.075)	GS 29.156 (32.413)	mem 76.802
Train: [0][270/1500]	BT 0.037 (0.359)	DT 0.000 (0.312)	loss 9.365 (9.368)	prob 1.140 (1.085)	GS 36.000 (32.429)	mem 76.889
Train: [0][280/1500]	BT 0.037 (0.350)	DT 0.000 (0.303)	loss 9.567 (9.390)	prob 0.929 (1.079)	GS 34.094 (31.860)	mem 76.907
Train: [0][290/1500]	BT 0.039 (0.343)	DT 0.001 (0.297)	loss 9.538 (9.397)	prob 0.947 (1.072)	GS 30.344 (32.005)	mem 76.932
Train: [0][300/1500]	BT 0.040 (0.339)	DT 0.001 (0.293)	loss 9.602 (9.408)	prob 0.946 (1.073)	GS 36.141 (32.255)	mem 76.061
Train: [0][310/1500]	BT 0.069 (0.338)	DT 0.017 (0.292)	loss 9.533 (9.456)	prob 0.983 (1.088)	GS 34.312 (33.297)	mem 75.871
Train: [0][320/1500]	BT 0.034 (0.332)	DT 0.001 (0.285)	loss 9.763 (9.487)	prob 0.779 (1.045)	GS 35.828 (32.637)	mem 75.881
Train: [0][330/1500]	BT 0.037 (0.346)	DT 0.001 (0.300)	loss 9.538 (9.503)	prob 0.892 (1.009)	GS 31.375 (32.803)	mem 75.974
Train: [0][340/1500]	BT 0.038 (0.337)	DT 0.001 (0.291)	loss 9.567 (9.513)	prob 1.009 (0.997)	GS 33.703 (32.753)	mem 75.999
Train: [0][350/1500]	BT 0.039 (0.339)	DT 0.001 (0.293)	loss 9.649 (9.519)	prob 0.977 (0.998)	GS 37.281 (32.842)	mem 76.464
Train: [0][360/1500]	BT 0.039 (0.330)	DT 0.001 (0.285)	loss 9.552 (9.572)	prob 0.944 (0.953)	GS 34.328 (33.734)	mem 76.493
Train: [0][370/1500]	BT 0.039 (0.330)	DT 0.000 (0.285)	loss 9.720 (9.587)	prob 0.871 (0.927)	GS 35.234 (32.812)	mem 76.636
Train: [0][380/1500]	BT 0.044 (0.327)	DT 0.008 (0.282)	loss 9.733 (9.597)	prob 0.723 (0.913)	GS 35.562 (33.048)	mem 77.051
Train: [0][390/1500]	BT 0.043 (0.319)	DT 0.001 (0.275)	loss 9.746 (9.607)	prob 0.907 (0.897)	GS 36.000 (32.827)	mem 77.135
Train: [0][400/1500]	BT 0.041 (0.331)	DT 0.001 (0.286)	loss 9.865 (9.623)	prob 0.600 (0.885)	GS 36.781 (32.867)	mem 78.074
Train: [0][410/1500]	BT 0.038 (0.324)	DT 0.000 (0.279)	loss 9.638 (9.670)	prob 0.847 (0.820)	GS 32.734 (34.003)	mem 78.053
Train: [0][420/1500]	BT 0.083 (0.343)	DT 0.009 (0.298)	loss 9.630 (9.696)	prob 0.818 (0.758)	GS 29.938 (34.187)	mem 77.870
Train: [0][430/1500]	BT 0.039 (0.341)	DT 0.001 (0.296)	loss 9.633 (9.690)	prob 0.800 (0.748)	GS 32.594 (33.932)	mem 77.907
Train: [0][440/1500]	BT 0.038 (0.334)	DT 0.001 (0.289)	loss 9.651 (9.701)	prob 0.788 (0.735)	GS 30.359 (33.662)	mem 77.921
Train: [0][450/1500]	BT 0.029 (0.343)	DT 0.000 (0.298)	loss 9.711 (9.709)	prob 0.688 (0.729)	GS 33.203 (34.016)	mem 78.109
Train: [0][460/1500]	BT 0.029 (0.336)	DT 0.001 (0.292)	loss 9.885 (9.781)	prob 0.393 (0.580)	GS 34.781 (32.020)	mem 78.096
Train: [0][470/1500]	BT 0.038 (0.338)	DT 0.000 (0.293)	loss 9.903 (9.777)	prob 0.334 (0.584)	GS 32.016 (32.632)	mem 78.200
Train: [0][480/1500]	BT 0.039 (0.332)	DT 0.000 (0.287)	loss 10.019 (9.788)	prob 0.224 (0.532)	GS 35.453 (32.476)	mem 78.212
Train: [0][490/1500]	BT 0.038 (0.326)	DT 0.001 (0.281)	loss 10.157 (9.801)	prob 0.144 (0.478)	GS 34.875 (32.462)	mem 78.217
Train: [0][500/1500]	BT 0.039 (0.328)	DT 0.001 (0.284)	loss 9.926 (9.794)	prob 0.216 (0.468)	GS 30.156 (32.312)	mem 77.303
Train: [0][510/1500]	BT 0.040 (0.322)	DT 0.001 (0.278)	loss 10.129 (9.842)	prob -0.041 (0.231)	GS 34.406 (31.941)	mem 77.304
Train: [0][520/1500]	BT 0.039 (0.322)	DT 0.001 (0.278)	loss 9.913 (9.850)	prob -0.157 (0.089)	GS 33.203 (32.267)	mem 77.322
Train: [0][530/1500]	BT 0.039 (0.317)	DT 0.001 (0.273)	loss 9.839 (9.834)	prob 0.053 (0.037)	GS 35.094 (32.322)	mem 77.328
Train: [0][540/1500]	BT 0.041 (0.316)	DT 0.001 (0.273)	loss 9.642 (9.821)	prob 0.362 (0.020)	GS 35.500 (32.143)	mem 77.379
Train: [0][550/1500]	BT 0.040 (0.316)	DT 0.000 (0.272)	loss 9.863 (9.832)	prob 0.000 (0.034)	GS 32.312 (32.084)	mem 77.455
Train: [0][560/1500]	BT 0.041 (0.311)	DT 0.001 (0.268)	loss 9.803 (9.860)	prob 0.078 (0.044)	GS 33.719 (32.820)	mem 77.468
Train: [0][570/1500]	BT 0.361 (0.309)	DT 0.321 (0.265)	loss 9.861 (9.877)	prob 0.167 (0.081)	GS 36.391 (33.723)	mem 77.536
Train: [0][580/1500]	BT 0.033 (0.313)	DT 0.001 (0.269)	loss 9.818 (9.853)	prob 0.166 (0.120)	GS 34.297 (33.566)	mem 77.712
Train: [0][590/1500]	BT 0.034 (0.308)	DT 0.001 (0.265)	loss 10.037 (9.866)	prob -0.171 (0.066)	GS 37.297 (33.663)	mem 77.721
Train: [0][600/1500]	BT 0.031 (0.320)	DT 0.000 (0.277)	loss 9.531 (9.861)	prob 0.171 (0.024)	GS 37.422 (33.605)	mem 77.822
Train: [0][610/1500]	BT 0.037 (0.321)	DT 0.001 (0.278)	loss 9.668 (9.915)	prob 0.328 (-0.013)	GS 34.172 (33.909)	mem 77.932
Train: [0][620/1500]	BT 0.040 (0.316)	DT 0.001 (0.274)	loss 10.108 (9.901)	prob -0.216 (-0.031)	GS 34.391 (33.246)	mem 77.939
Train: [0][630/1500]	BT 0.038 (0.317)	DT 0.000 (0.274)	loss 9.857 (9.896)	prob -0.068 (-0.008)	GS 33.812 (33.205)	mem 77.999
Train: [0][640/1500]	BT 0.063 (0.313)	DT 0.003 (0.270)	loss 9.890 (9.900)	prob -0.095 (0.014)	GS 35.078 (33.082)	mem 78.008
Train: [0][650/1500]	BT 0.093 (0.319)	DT 0.010 (0.275)	loss 9.737 (9.895)	prob 0.187 (0.020)	GS 34.328 (33.178)	mem 78.142
Train: [0][660/1500]	BT 0.060 (0.315)	DT 0.003 (0.271)	loss 9.947 (9.888)	prob 0.167 (0.187)	GS 33.922 (31.059)	mem 78.160
Train: [0][670/1500]	BT 0.048 (0.314)	DT 0.000 (0.270)	loss 9.699 (9.894)	prob 0.481 (0.172)	GS 35.734 (31.887)	mem 78.218
Train: [0][680/1500]	BT 0.040 (0.316)	DT 0.001 (0.272)	loss 9.922 (9.897)	prob -0.019 (0.158)	GS 28.047 (32.443)	mem 79.471
Train: [0][690/1500]	BT 0.040 (0.312)	DT 0.001 (0.269)	loss 9.996 (9.898)	prob -0.088 (0.135)	GS 30.828 (32.150)	mem 79.758
Train: [0][700/1500]	BT 0.040 (0.312)	DT 0.001 (0.269)	loss 10.121 (9.902)	prob -0.170 (0.106)	GS 31.203 (32.090)	mem 81.388
Train: [0][710/1500]	BT 0.059 (0.309)	DT 0.000 (0.265)	loss 9.921 (9.958)	prob 0.162 (0.060)	GS 32.688 (33.431)	mem 81.405
Train: [0][720/1500]	BT 0.072 (0.310)	DT 0.005 (0.266)	loss 10.143 (9.981)	prob 0.100 (0.057)	GS 37.422 (32.550)	mem 78.497
Train: [0][730/1500]	BT 0.027 (0.318)	DT 0.000 (0.274)	loss 10.134 (9.962)	prob 0.133 (0.113)	GS 32.953 (32.722)	mem 77.585
Train: [0][740/1500]	BT 0.039 (0.314)	DT 0.001 (0.270)	loss 9.842 (9.958)	prob 0.333 (0.127)	GS 32.078 (32.732)	mem 77.607
Train: [0][750/1500]	BT 0.047 (0.318)	DT 0.013 (0.275)	loss 10.128 (9.963)	prob -0.121 (0.135)	GS 35.078 (32.755)	mem 77.784
Train: [0][760/1500]	BT 0.068 (0.314)	DT 0.004 (0.271)	loss 9.787 (9.954)	prob 0.149 (-0.012)	GS 31.219 (31.916)	mem 77.792
Train: [0][770/1500]	BT 0.065 (0.311)	DT 0.013 (0.268)	loss 10.019 (9.949)	prob 0.004 (0.075)	GS 28.750 (31.910)	mem 77.798
Train: [0][780/1500]	BT 0.047 (0.327)	DT 0.001 (0.283)	loss 10.148 (9.946)	prob 0.206 (0.145)	GS 31.438 (32.691)	mem 77.995
Train: [0][790/1500]	BT 0.038 (0.323)	DT 0.000 (0.280)	loss 9.946 (9.950)	prob 0.433 (0.188)	GS 32.047 (33.172)	mem 78.005
Train: [0][800/1500]	BT 0.038 (0.320)	DT 0.000 (0.276)	loss 10.158 (9.963)	prob -0.102 (0.160)	GS 33.375 (33.022)	mem 78.016
Train: [0][810/1500]	BT 0.037 (0.322)	DT 0.001 (0.279)	loss 10.011 (9.956)	prob 0.195 (0.257)	GS 32.172 (30.977)	mem 78.158
Train: [0][820/1500]	BT 0.040 (0.318)	DT 0.001 (0.275)	loss 10.278 (9.957)	prob -0.150 (0.204)	GS 30.125 (30.955)	mem 78.153
Train: [0][830/1500]	BT 0.024 (0.321)	DT 0.000 (0.278)	loss 10.148 (9.962)	prob -0.125 (0.148)	GS 35.469 (31.392)	mem 77.906
Train: [0][840/1500]	BT 0.027 (0.318)	DT 0.000 (0.275)	loss 10.100 (9.969)	prob 0.048 (0.154)	GS 32.984 (31.412)	mem 77.914
Train: [0][850/1500]	BT 0.037 (0.319)	DT 0.001 (0.276)	loss 9.786 (9.958)	prob 0.478 (0.185)	GS 28.953 (31.820)	mem 77.937
Train: [0][860/1500]	BT 0.027 (0.315)	DT 0.000 (0.273)	loss 10.270 (10.042)	prob 0.148 (0.212)	GS 34.594 (35.602)	mem 77.950
Train: [0][870/1500]	BT 0.038 (0.312)	DT 0.001 (0.270)	loss 10.154 (10.041)	prob 0.231 (0.281)	GS 35.688 (34.228)	mem 77.961
Train: [0][880/1500]	BT 0.037 (0.314)	DT 0.000 (0.271)	loss 9.964 (10.021)	prob 0.315 (0.344)	GS 30.672 (33.603)	mem 78.106
Train: [0][890/1500]	BT 0.039 (0.310)	DT 0.001 (0.268)	loss 9.920 (10.007)	prob 0.149 (0.313)	GS 30.031 (33.395)	mem 78.122
Train: [0][900/1500]	BT 0.035 (0.312)	DT 0.000 (0.270)	loss 10.527 (10.021)	prob -0.582 (0.261)	GS 31.516 (32.900)	mem 77.256
Train: [0][910/1500]	BT 0.032 (0.309)	DT 0.001 (0.267)	loss 10.040 (10.071)	prob -0.149 (-0.165)	GS 36.516 (31.366)	mem 77.268
Train: [0][920/1500]	BT 0.032 (0.306)	DT 0.000 (0.264)	loss 10.390 (10.052)	prob -0.394 (-0.095)	GS 32.172 (31.423)	mem 77.272
Train: [0][930/1500]	BT 0.037 (0.313)	DT 0.001 (0.271)	loss 9.685 (10.036)	prob 0.431 (-0.031)	GS 35.438 (32.305)	mem 77.362
Train: [0][940/1500]	BT 0.038 (0.310)	DT 0.001 (0.268)	loss 10.235 (10.029)	prob 0.205 (0.030)	GS 32.703 (32.279)	mem 77.372
Train: [0][950/1500]	BT 0.031 (0.312)	DT 0.000 (0.270)	loss 9.959 (10.038)	prob -0.081 (0.023)	GS 30.266 (32.031)	mem 77.499
Train: [0][960/1500]	BT 0.031 (0.309)	DT 0.001 (0.267)	loss 9.869 (10.045)	prob 0.183 (-0.169)	GS 32.047 (33.419)	mem 77.504
Train: [0][970/1500]	BT 0.029 (0.312)	DT 0.000 (0.271)	loss 10.151 (10.068)	prob 0.224 (-0.011)	GS 37.062 (33.235)	mem 77.665
Train: [0][980/1500]	BT 0.040 (0.309)	DT 0.001 (0.268)	loss 10.020 (10.066)	prob 0.155 (0.092)	GS 30.047 (33.346)	mem 77.632
Train: [0][990/1500]	BT 0.039 (0.306)	DT 0.001 (0.265)	loss 10.061 (10.080)	prob -0.183 (0.117)	GS 33.266 (33.730)	mem 77.646
Train: [0][1000/1500]	BT 0.032 (0.308)	DT 0.000 (0.267)	loss 9.897 (10.057)	prob 0.657 (0.203)	GS 32.500 (33.678)	mem 77.874
Train: [0][1010/1500]	BT 0.037 (0.306)	DT 0.001 (0.265)	loss 9.685 (10.057)	prob 0.185 (0.241)	GS 32.016 (32.688)	mem 77.886
Train: [0][1020/1500]	BT 0.068 (0.308)	DT 0.004 (0.267)	loss 10.593 (10.104)	prob -0.310 (0.146)	GS 34.594 (31.915)	mem 77.954
Train: [0][1030/1500]	BT 0.034 (0.306)	DT 0.000 (0.265)	loss 10.474 (10.061)	prob -0.154 (0.183)	GS 33.109 (31.859)	mem 77.985
Train: [0][1040/1500]	BT 0.039 (0.304)	DT 0.001 (0.263)	loss 10.236 (10.085)	prob 0.134 (0.207)	GS 32.172 (32.044)	mem 77.997
Train: [0][1050/1500]	BT 0.061 (0.308)	DT 0.006 (0.267)	loss 10.217 (10.097)	prob -0.334 (0.195)	GS 35.656 (32.280)	mem 78.123
Train: [0][1060/1500]	BT 0.033 (0.306)	DT 0.000 (0.265)	loss 10.503 (10.101)	prob -0.209 (0.109)	GS 38.312 (33.670)	mem 78.127
Train: [0][1070/1500]	BT 0.031 (0.312)	DT 0.000 (0.271)	loss 10.061 (10.087)	prob -0.198 (0.039)	GS 35.984 (33.913)	mem 78.351
Train: [0][1080/1500]	BT 0.030 (0.309)	DT 0.000 (0.268)	loss 10.170 (10.108)	prob 0.001 (0.086)	GS 34.406 (33.322)	mem 78.374
Train: [0][1090/1500]	BT 0.028 (0.317)	DT 0.000 (0.276)	loss 10.203 (10.094)	prob 0.135 (0.128)	GS 31.328 (32.715)	mem 77.584
Train: [0][1100/1500]	BT 0.032 (0.315)	DT 0.000 (0.274)	loss 10.249 (10.089)	prob -0.122 (0.120)	GS 32.438 (32.455)	mem 77.591
Train: [0][1110/1500]	BT 0.038 (0.312)	DT 0.001 (0.272)	loss 10.105 (10.082)	prob 0.181 (0.289)	GS 31.750 (33.600)	mem 77.597
Train: [0][1120/1500]	BT 0.042 (0.314)	DT 0.001 (0.273)	loss 9.961 (10.101)	prob 0.370 (0.221)	GS 34.344 (33.043)	mem 77.644
Train: [0][1130/1500]	BT 0.039 (0.311)	DT 0.001 (0.271)	loss 10.551 (10.135)	prob -0.539 (0.219)	GS 32.375 (33.032)	mem 77.656
Train: [0][1140/1500]	BT 0.029 (0.314)	DT 0.000 (0.273)	loss 10.148 (10.131)	prob 0.156 (0.203)	GS 37.062 (32.906)	mem 77.942
Train: [0][1150/1500]	BT 0.024 (0.311)	DT 0.000 (0.271)	loss 10.125 (10.142)	prob 0.315 (0.165)	GS 36.969 (32.824)	mem 77.962
Train: [0][1160/1500]	BT 0.038 (0.311)	DT 0.001 (0.271)	loss 9.785 (10.203)	prob 0.495 (0.046)	GS 28.516 (32.445)	mem 78.078
Train: [0][1170/1500]	BT 0.038 (0.309)	DT 0.001 (0.269)	loss 10.523 (10.201)	prob -0.000 (0.112)	GS 37.625 (32.398)	mem 78.091
Train: [0][1180/1500]	BT 0.050 (0.307)	DT 0.014 (0.266)	loss 10.154 (10.193)	prob 0.067 (0.113)	GS 36.031 (32.576)	mem 78.102
Train: [0][1190/1500]	BT 0.037 (0.308)	DT 0.001 (0.268)	loss 10.244 (10.189)	prob -0.103 (0.141)	GS 33.797 (32.468)	mem 78.243
Train: [0][1200/1500]	BT 0.038 (0.306)	DT 0.001 (0.266)	loss 10.179 (10.187)	prob 0.811 (0.194)	GS 31.781 (32.593)	mem 78.255
Train: [0][1210/1500]	BT 0.038 (0.306)	DT 0.001 (0.266)	loss 10.031 (10.215)	prob 0.618 (0.629)	GS 31.797 (32.987)	mem 78.338
Train: [0][1220/1500]	BT 0.039 (0.304)	DT 0.001 (0.264)	loss 9.903 (10.203)	prob 1.119 (0.627)	GS 34.266 (33.577)	mem 78.360
Train: [0][1230/1500]	BT 0.038 (0.302)	DT 0.001 (0.261)	loss 10.034 (10.224)	prob -0.014 (0.560)	GS 32.938 (33.200)	mem 78.386
Train: [0][1240/1500]	BT 0.064 (0.306)	DT 0.000 (0.265)	loss 10.227 (10.226)	prob 0.037 (0.453)	GS 34.109 (33.163)	mem 78.555
Train: [0][1250/1500]	BT 0.039 (0.304)	DT 0.001 (0.264)	loss 10.245 (10.214)	prob 0.454 (0.409)	GS 31.734 (33.492)	mem 78.601
Train: [0][1260/1500]	BT 0.049 (0.307)	DT 0.001 (0.266)	loss 10.101 (10.196)	prob 0.514 (0.338)	GS 33.453 (32.650)	mem 78.716
Train: [0][1270/1500]	BT 0.039 (0.305)	DT 0.001 (0.264)	loss 10.161 (10.140)	prob 0.233 (0.318)	GS 28.766 (32.587)	mem 78.126
Train: [0][1280/1500]	BT 12.221 (0.320)	DT 12.177 (0.279)	loss 10.618 (10.204)	prob -0.122 (0.277)	GS 36.969 (32.651)	mem 77.596
Train: [0][1290/1500]	BT 0.032 (0.318)	DT 0.000 (0.277)	loss 10.263 (10.223)	prob 0.455 (0.296)	GS 36.344 (32.749)	mem 77.614
Train: [0][1300/1500]	BT 0.038 (0.315)	DT 0.001 (0.275)	loss 10.267 (10.221)	prob -0.107 (0.286)	GS 34.172 (32.800)	mem 77.635
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [0][1310/1500]	BT 0.028 (0.319)	DT 0.000 (0.279)	loss 10.383 (10.205)	prob 0.127 (0.057)	GS 37.000 (32.431)	mem 76.711
Train: [0][1320/1500]	BT 0.032 (0.317)	DT 0.000 (0.276)	loss 10.339 (10.238)	prob 0.218 (0.052)	GS 34.391 (32.354)	mem 76.723
Train: [0][1330/1500]	BT 0.028 (0.317)	DT 0.000 (0.277)	loss 10.953 (10.302)	prob -0.249 (0.142)	GS 30.359 (32.497)	mem 76.836
Train: [0][1340/1500]	BT 0.039 (0.315)	DT 0.001 (0.275)	loss 10.373 (10.333)	prob 0.342 (0.188)	GS 36.688 (32.987)	mem 76.848
Train: [0][1350/1500]	BT 0.039 (0.313)	DT 0.001 (0.273)	loss 10.755 (10.316)	prob -0.118 (0.234)	GS 35.781 (32.695)	mem 76.869
Train: [0][1360/1500]	BT 0.038 (0.315)	DT 0.001 (0.275)	loss 9.999 (10.310)	prob 0.597 (0.327)	GS 35.234 (32.837)	mem 77.034
Train: [0][1370/1500]	BT 0.038 (0.313)	DT 0.001 (0.273)	loss 10.260 (10.336)	prob 0.418 (0.273)	GS 36.453 (33.230)	mem 77.046
Train: [0][1380/1500]	BT 0.070 (0.314)	DT 0.009 (0.274)	loss 10.533 (10.363)	prob -0.037 (0.223)	GS 35.000 (33.352)	mem 77.141
Train: [0][1390/1500]	BT 0.063 (0.312)	DT 0.001 (0.272)	loss 9.903 (10.337)	prob 0.666 (0.302)	GS 38.906 (33.238)	mem 77.158
Train: [0][1400/1500]	BT 0.035 (0.318)	DT 0.000 (0.278)	loss 10.305 (10.323)	prob 0.128 (0.377)	GS 35.578 (33.425)	mem 77.341
Train: [0][1410/1500]	BT 0.038 (0.316)	DT 0.001 (0.276)	loss 10.285 (10.337)	prob -0.371 (0.130)	GS 33.438 (33.013)	mem 77.350
Train: [0][1420/1500]	BT 0.038 (0.316)	DT 0.000 (0.276)	loss 10.183 (10.389)	prob 0.181 (0.050)	GS 34.594 (32.997)	mem 77.424
Train: [0][1430/1500]	BT 0.034 (0.314)	DT 0.001 (0.274)	loss 10.095 (10.312)	prob 0.767 (0.280)	GS 30.719 (33.290)	mem 77.437
Train: [0][1440/1500]	BT 0.047 (0.312)	DT 0.001 (0.272)	loss 10.131 (10.311)	prob 0.708 (0.355)	GS 33.219 (33.325)	mem 77.443
Train: [0][1450/1500]	BT 0.039 (0.316)	DT 0.001 (0.275)	loss 10.803 (10.344)	prob -0.375 (0.363)	GS 34.750 (32.906)	mem 76.621
Train: [0][1460/1500]	BT 0.036 (0.318)	DT 0.001 (0.278)	loss 10.205 (10.216)	prob 0.003 (0.218)	GS 31.078 (32.802)	mem 76.398
Train: [0][1470/1500]	BT 0.036 (0.316)	DT 0.001 (0.276)	loss 10.446 (10.257)	prob -0.032 (0.337)	GS 34.297 (32.290)	mem 76.406
Train: [0][1480/1500]	BT 0.039 (0.316)	DT 0.001 (0.276)	loss 9.771 (10.248)	prob 0.765 (0.415)	GS 32.609 (31.930)	mem 11.849
Train: [0][1490/1500]	BT 0.027 (0.314)	DT 0.000 (0.274)	loss 10.105 (10.284)	prob 0.975 (0.370)	GS 30.781 (32.198)	mem 11.864
Train: [0][1500/1500]	BT 0.023 (0.312)	DT 0.000 (0.272)	loss 10.523 (10.313)	prob 0.927 (0.404)	GS 33.531 (32.251)	mem 11.876
Train: [0][1510/1500]	BT 0.023 (0.311)	DT 0.000 (0.271)	loss 10.152 (10.447)	prob 1.272 (0.813)	GS 38.844 (32.728)	mem 11.845
epoch 0, total time 469.15
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [1][1/1500]	BT 18.588 (18.588)	DT 18.532 (18.532)	loss 10.390 (10.390)	prob 0.930 (0.930)	GS 32.734 (32.734)	mem 75.506
Train: [1][10/1500]	BT 0.038 (2.760)	DT 0.001 (2.709)	loss 10.243 (10.527)	prob 1.150 (1.066)	GS 35.297 (34.729)	mem 75.952
Train: [1][20/1500]	BT 0.040 (1.399)	DT 0.001 (1.355)	loss 10.796 (10.471)	prob 0.773 (0.923)	GS 32.750 (34.245)	mem 75.954
Train: [1][30/1500]	BT 0.037 (1.097)	DT 0.001 (1.055)	loss 10.484 (10.435)	prob -0.164 (0.803)	GS 31.656 (33.825)	mem 75.938
Train: [1][40/1500]	BT 0.033 (0.832)	DT 0.001 (0.791)	loss 10.163 (10.392)	prob 0.761 (0.675)	GS 33.875 (33.064)	mem 75.942
Train: [1][50/1500]	BT 0.039 (0.702)	DT 0.001 (0.663)	loss 10.339 (10.385)	prob 0.897 (0.668)	GS 34.281 (32.800)	mem 75.951
Train: [1][60/1500]	BT 0.038 (0.630)	DT 0.001 (0.591)	loss 10.007 (10.406)	prob 1.205 (0.684)	GS 32.062 (32.039)	mem 76.026
Train: [1][70/1500]	BT 0.040 (0.546)	DT 0.001 (0.507)	loss 10.334 (10.515)	prob 0.435 (0.578)	GS 34.594 (32.492)	mem 76.028
Train: [1][80/1500]	BT 0.040 (0.540)	DT 0.001 (0.501)	loss 10.460 (10.473)	prob 0.210 (0.543)	GS 37.562 (33.071)	mem 76.014
Train: [1][90/1500]	BT 0.040 (0.484)	DT 0.001 (0.445)	loss 10.804 (10.481)	prob 0.172 (0.530)	GS 32.188 (32.958)	mem 76.162
Train: [1][100/1500]	BT 0.082 (0.467)	DT 0.012 (0.428)	loss 10.748 (10.479)	prob 0.293 (0.556)	GS 37.094 (32.759)	mem 76.663
Train: [1][110/1500]	BT 0.039 (0.462)	DT 0.001 (0.422)	loss 10.022 (10.457)	prob 1.553 (0.995)	GS 35.406 (31.113)	mem 76.828
Train: [1][120/1500]	BT 0.040 (0.426)	DT 0.001 (0.387)	loss 10.150 (10.493)	prob 1.368 (0.698)	GS 32.203 (31.845)	mem 76.838
Train: [1][130/1500]	BT 0.034 (0.435)	DT 0.000 (0.396)	loss 10.697 (10.531)	prob 0.588 (0.685)	GS 31.906 (31.597)	mem 77.051
Train: [1][140/1500]	BT 0.033 (0.406)	DT 0.000 (0.367)	loss 10.620 (10.534)	prob 0.246 (0.677)	GS 32.062 (31.784)	mem 77.052
Train: [1][150/1500]	BT 0.029 (0.442)	DT 0.000 (0.404)	loss 10.394 (10.527)	prob 0.918 (0.647)	GS 30.312 (32.042)	mem 77.058
Train: [1][160/1500]	BT 0.035 (0.416)	DT 0.001 (0.379)	loss 10.841 (10.521)	prob 0.480 (0.404)	GS 30.188 (32.208)	mem 77.059
Train: [1][170/1500]	BT 0.038 (0.394)	DT 0.001 (0.356)	loss 10.974 (10.548)	prob 0.015 (0.542)	GS 34.531 (32.924)	mem 77.060
Train: [1][180/1500]	BT 0.039 (0.390)	DT 0.001 (0.353)	loss 10.919 (10.524)	prob 0.918 (0.635)	GS 35.250 (32.758)	mem 77.109
Train: [1][190/1500]	BT 0.098 (0.373)	DT 0.006 (0.335)	loss 9.991 (10.531)	prob 0.983 (0.720)	GS 36.031 (33.488)	mem 77.120
Train: [1][200/1500]	BT 0.066 (0.409)	DT 0.017 (0.368)	loss 10.476 (10.505)	prob 0.712 (0.723)	GS 32.625 (33.397)	mem 77.128
Train: [1][210/1500]	BT 0.048 (0.422)	DT 0.006 (0.381)	loss 10.868 (10.673)	prob 0.891 (0.669)	GS 35.562 (34.008)	mem 77.108
Train: [1][220/1500]	BT 0.028 (0.404)	DT 0.000 (0.364)	loss 10.700 (10.596)	prob 0.444 (0.830)	GS 35.562 (33.868)	mem 77.109
Train: [1][230/1500]	BT 0.029 (0.388)	DT 0.000 (0.348)	loss 10.532 (10.558)	prob 0.133 (0.785)	GS 36.328 (33.531)	mem 77.109
Train: [1][240/1500]	BT 0.040 (0.386)	DT 0.001 (0.346)	loss 9.840 (10.554)	prob 1.638 (0.764)	GS 36.031 (33.675)	mem 77.112
Train: [1][250/1500]	BT 0.038 (0.374)	DT 0.001 (0.334)	loss 10.816 (10.548)	prob 0.478 (0.756)	GS 33.828 (33.576)	mem 76.638
Train: [1][260/1500]	BT 0.038 (0.370)	DT 0.001 (0.330)	loss 11.066 (10.704)	prob 0.512 (1.070)	GS 31.609 (33.055)	mem 76.631
Train: [1][270/1500]	BT 0.037 (0.361)	DT 0.000 (0.321)	loss 10.051 (10.623)	prob 0.360 (0.678)	GS 34.766 (32.829)	mem 76.643
Train: [1][280/1500]	BT 0.032 (0.349)	DT 0.000 (0.310)	loss 10.689 (10.631)	prob 0.107 (0.595)	GS 34.547 (32.549)	mem 76.643
Train: [1][290/1500]	BT 0.037 (0.351)	DT 0.001 (0.312)	loss 10.707 (10.625)	prob 0.363 (0.569)	GS 32.547 (32.589)	mem 76.196
Train: [1][300/1500]	BT 0.057 (0.347)	DT 0.013 (0.308)	loss 11.315 (10.628)	prob -0.716 (0.508)	GS 35.469 (32.730)	mem 76.205
Train: [1][310/1500]	BT 0.038 (0.350)	DT 0.001 (0.311)	loss 10.447 (10.494)	prob 0.502 (0.367)	GS 34.375 (32.991)	mem 76.210
Train: [1][320/1500]	BT 0.038 (0.344)	DT 0.000 (0.305)	loss 10.878 (10.616)	prob 0.378 (0.395)	GS 31.828 (32.760)	mem 76.067
Train: [1][330/1500]	BT 0.546 (0.346)	DT 0.510 (0.307)	loss 10.051 (10.585)	prob 0.779 (0.386)	GS 30.656 (32.423)	mem 75.977
Train: [1][340/1500]	BT 0.030 (0.337)	DT 0.000 (0.298)	loss 10.553 (10.604)	prob 0.240 (0.234)	GS 35.375 (32.576)	mem 75.978
Train: [1][350/1500]	BT 0.038 (0.328)	DT 0.001 (0.289)	loss 10.384 (10.611)	prob -0.071 (0.205)	GS 31.000 (32.350)	mem 75.979
Train: [1][360/1500]	BT 0.040 (0.331)	DT 0.001 (0.292)	loss 10.519 (10.425)	prob 0.950 (0.613)	GS 31.188 (31.825)	mem 75.973
Train: [1][370/1500]	BT 0.037 (0.323)	DT 0.000 (0.284)	loss 10.402 (10.398)	prob 0.067 (0.553)	GS 35.625 (31.945)	mem 75.973
Train: [1][380/1500]	BT 0.030 (0.331)	DT 0.001 (0.292)	loss 10.372 (10.431)	prob 0.471 (0.371)	GS 33.984 (32.107)	mem 75.976
Train: [1][390/1500]	BT 0.083 (0.324)	DT 0.022 (0.286)	loss 10.569 (10.462)	prob -0.095 (0.348)	GS 33.969 (32.355)	mem 75.958
Train: [1][400/1500]	BT 0.038 (0.317)	DT 0.001 (0.278)	loss 10.803 (10.499)	prob 0.336 (0.325)	GS 33.516 (32.629)	mem 75.959
Train: [1][410/1500]	BT 0.031 (0.326)	DT 0.000 (0.288)	loss 10.827 (10.482)	prob 0.159 (0.405)	GS 32.141 (33.831)	mem 75.956
Train: [1][420/1500]	BT 0.062 (0.320)	DT 0.011 (0.281)	loss 10.484 (10.566)	prob 0.734 (0.371)	GS 32.125 (32.907)	mem 75.955
Train: [1][430/1500]	BT 0.027 (0.353)	DT 0.000 (0.314)	loss 10.095 (10.612)	prob 1.360 (0.492)	GS 33.953 (32.878)	mem 75.968
Train: [1][440/1500]	BT 0.030 (0.345)	DT 0.000 (0.307)	loss 10.507 (10.578)	prob 1.030 (0.559)	GS 40.312 (33.138)	mem 75.969
Train: [1][450/1500]	BT 0.033 (0.339)	DT 0.000 (0.300)	loss 11.024 (10.580)	prob 0.778 (0.653)	GS 33.016 (32.793)	mem 75.968
Train: [1][460/1500]	BT 0.038 (0.338)	DT 0.001 (0.299)	loss 10.610 (10.498)	prob 1.078 (1.203)	GS 36.453 (32.858)	mem 75.978
Train: [1][470/1500]	BT 0.041 (0.331)	DT 0.001 (0.293)	loss 11.332 (10.646)	prob -0.334 (1.001)	GS 33.078 (32.130)	mem 75.977
Train: [1][480/1500]	BT 0.037 (0.337)	DT 0.000 (0.298)	loss 11.094 (10.635)	prob -0.021 (0.777)	GS 34.750 (32.301)	mem 76.030
Train: [1][490/1500]	BT 0.049 (0.331)	DT 0.000 (0.292)	loss 10.916 (10.612)	prob 0.408 (0.838)	GS 32.453 (32.323)	mem 76.030
Train: [1][500/1500]	BT 7.903 (0.341)	DT 7.850 (0.302)	loss 10.095 (10.596)	prob 0.750 (0.845)	GS 32.375 (32.326)	mem 76.077
Train: [1][510/1500]	BT 0.029 (0.346)	DT 0.000 (0.307)	loss 10.199 (10.550)	prob 1.386 (0.971)	GS 30.062 (34.730)	mem 76.183
Train: [1][520/1500]	BT 0.033 (0.340)	DT 0.000 (0.301)	loss 10.757 (10.537)	prob 0.241 (0.676)	GS 32.000 (33.505)	mem 76.183
Train: [1][530/1500]	BT 0.048 (0.342)	DT 0.001 (0.304)	loss 10.749 (10.582)	prob -0.183 (0.457)	GS 31.797 (33.419)	mem 76.185
Train: [1][540/1500]	BT 0.053 (0.337)	DT 0.006 (0.298)	loss 11.226 (10.619)	prob -0.304 (0.393)	GS 36.188 (33.767)	mem 76.186
Train: [1][550/1500]	BT 0.060 (0.332)	DT 0.001 (0.293)	loss 10.886 (10.602)	prob 0.393 (0.419)	GS 30.641 (33.497)	mem 76.185
Train: [1][560/1500]	BT 0.039 (0.337)	DT 0.001 (0.298)	loss 10.791 (10.842)	prob 0.179 (0.220)	GS 30.078 (32.892)	mem 76.188
Train: [1][570/1500]	BT 0.039 (0.332)	DT 0.001 (0.293)	loss 10.827 (10.695)	prob -0.041 (0.403)	GS 33.828 (33.163)	mem 76.188
Train: [1][580/1500]	BT 0.058 (0.330)	DT 0.001 (0.291)	loss 10.334 (10.716)	prob 0.824 (0.376)	GS 33.234 (33.222)	mem 76.187
Train: [1][590/1500]	BT 0.045 (0.330)	DT 0.000 (0.291)	loss 10.439 (10.683)	prob 0.328 (0.385)	GS 33.594 (32.916)	mem 76.189
Train: [1][600/1500]	BT 0.031 (0.325)	DT 0.000 (0.286)	loss 10.873 (10.703)	prob 0.415 (0.335)	GS 36.656 (32.720)	mem 76.188
Train: [1][610/1500]	BT 0.036 (0.328)	DT 0.001 (0.289)	loss 10.014 (10.464)	prob 1.015 (0.799)	GS 31.188 (32.316)	mem 76.203
Train: [1][620/1500]	BT 0.036 (0.323)	DT 0.000 (0.284)	loss 10.367 (10.548)	prob 0.137 (0.598)	GS 32.469 (32.284)	mem 76.203
Train: [1][630/1500]	BT 0.037 (0.325)	DT 0.000 (0.286)	loss 11.333 (10.569)	prob -0.651 (0.519)	GS 39.625 (32.381)	mem 76.208
Train: [1][640/1500]	BT 0.038 (0.321)	DT 0.001 (0.282)	loss 10.234 (10.528)	prob 0.452 (0.526)	GS 31.594 (31.936)	mem 76.209
Train: [1][650/1500]	BT 0.064 (0.324)	DT 0.010 (0.285)	loss 10.490 (10.540)	prob 0.240 (0.453)	GS 32.312 (31.885)	mem 76.211
Train: [1][660/1500]	BT 0.037 (0.320)	DT 0.001 (0.281)	loss 10.564 (10.496)	prob 0.476 (0.876)	GS 32.000 (33.373)	mem 76.213
Train: [1][670/1500]	BT 0.037 (0.316)	DT 0.001 (0.277)	loss 10.802 (10.523)	prob 0.442 (0.811)	GS 32.203 (32.389)	mem 76.214
Train: [1][680/1500]	BT 0.038 (0.320)	DT 0.001 (0.281)	loss 10.276 (10.495)	prob 0.297 (0.915)	GS 32.828 (32.288)	mem 76.264
Train: [1][690/1500]	BT 0.038 (0.316)	DT 0.001 (0.277)	loss 10.517 (10.558)	prob 0.352 (0.794)	GS 31.125 (32.323)	mem 76.266
Train: [1][700/1500]	BT 0.040 (0.319)	DT 0.001 (0.280)	loss 10.643 (10.565)	prob -0.042 (0.682)	GS 33.922 (32.295)	mem 76.321
Train: [1][710/1500]	BT 0.037 (0.315)	DT 0.000 (0.276)	loss 10.063 (10.427)	prob 0.234 (0.098)	GS 34.031 (33.006)	mem 76.322
Train: [1][720/1500]	BT 0.029 (0.311)	DT 0.000 (0.272)	loss 10.240 (10.497)	prob 0.738 (0.208)	GS 35.078 (32.398)	mem 76.330
Train: [1][730/1500]	BT 0.034 (0.316)	DT 0.000 (0.277)	loss 10.149 (10.435)	prob 0.986 (0.458)	GS 34.000 (32.836)	mem 76.430
Train: [1][740/1500]	BT 0.037 (0.312)	DT 0.000 (0.273)	loss 10.430 (10.450)	prob 0.488 (0.468)	GS 38.625 (32.781)	mem 76.433
Train: [1][750/1500]	BT 0.036 (0.314)	DT 0.000 (0.275)	loss 10.386 (10.453)	prob 0.370 (0.494)	GS 32.938 (32.815)	mem 76.509
Train: [1][760/1500]	BT 0.024 (0.310)	DT 0.000 (0.271)	loss 10.464 (10.627)	prob 0.565 (0.444)	GS 31.031 (32.987)	mem 76.510
Train: [1][770/1500]	BT 0.047 (0.312)	DT 0.000 (0.273)	loss 10.643 (10.566)	prob -0.060 (0.541)	GS 35.234 (32.589)	mem 76.519
Train: [1][780/1500]	BT 0.055 (0.308)	DT 0.000 (0.269)	loss 10.057 (10.575)	prob 1.364 (0.503)	GS 29.328 (32.692)	mem 76.522
Train: [1][790/1500]	BT 0.063 (0.306)	DT 0.011 (0.267)	loss 10.673 (10.561)	prob 0.936 (0.577)	GS 29.375 (32.434)	mem 76.549
Train: [1][800/1500]	BT 0.045 (0.314)	DT 0.001 (0.275)	loss 10.354 (10.567)	prob 0.221 (0.625)	GS 31.734 (32.320)	mem 76.666
Train: [1][810/1500]	BT 0.073 (0.310)	DT 0.024 (0.272)	loss 10.479 (10.566)	prob 0.756 (0.795)	GS 37.375 (32.773)	mem 76.666
Train: [1][820/1500]	BT 0.038 (0.312)	DT 0.000 (0.273)	loss 10.742 (10.482)	prob 0.500 (0.840)	GS 32.766 (32.284)	mem 76.667
Train: [1][830/1500]	BT 0.029 (0.309)	DT 0.000 (0.270)	loss 10.586 (10.499)	prob 0.488 (0.795)	GS 37.188 (32.899)	mem 76.667
Train: [1][840/1500]	BT 0.041 (0.306)	DT 0.001 (0.267)	loss 11.228 (10.560)	prob -0.081 (0.643)	GS 38.125 (32.973)	mem 76.666
Train: [1][850/1500]	BT 0.036 (0.309)	DT 0.001 (0.270)	loss 10.314 (10.578)	prob 1.265 (0.657)	GS 29.266 (32.815)	mem 76.127
Train: [1][860/1500]	BT 0.037 (0.306)	DT 0.001 (0.267)	loss 10.452 (10.698)	prob 0.662 (0.458)	GS 33.891 (33.300)	mem 76.127
Train: [1][870/1500]	BT 0.821 (0.307)	DT 0.776 (0.268)	loss 10.775 (10.700)	prob 0.679 (0.528)	GS 34.109 (33.298)	mem 76.124
Train: [1][880/1500]	BT 0.038 (0.304)	DT 0.001 (0.265)	loss 10.336 (10.595)	prob 0.900 (0.762)	GS 35.062 (33.108)	mem 76.125
Train: [1][890/1500]	BT 0.078 (0.307)	DT 0.009 (0.268)	loss 10.943 (10.579)	prob -0.058 (0.621)	GS 32.844 (32.895)	mem 76.129
Train: [1][900/1500]	BT 0.030 (0.307)	DT 0.000 (0.269)	loss 11.099 (10.600)	prob -0.062 (0.576)	GS 35.500 (32.977)	mem 76.127
Train: [1][910/1500]	BT 0.037 (0.304)	DT 0.000 (0.266)	loss 10.089 (10.483)	prob 1.592 (0.707)	GS 32.219 (33.525)	mem 76.127
Train: [1][920/1500]	BT 0.037 (0.305)	DT 0.001 (0.266)	loss 10.440 (10.535)	prob 0.909 (0.794)	GS 33.422 (33.032)	mem 76.126
Train: [1][930/1500]	BT 0.069 (0.302)	DT 0.004 (0.263)	loss 10.323 (10.537)	prob 0.862 (0.891)	GS 33.641 (33.003)	mem 76.126
Train: [1][940/1500]	BT 0.039 (0.303)	DT 0.001 (0.265)	loss 9.825 (10.513)	prob 1.510 (0.857)	GS 31.828 (32.696)	mem 76.161
Train: [1][950/1500]	BT 0.040 (0.301)	DT 0.001 (0.262)	loss 10.942 (10.545)	prob 1.005 (0.879)	GS 33.547 (32.865)	mem 76.161
Train: [1][960/1500]	BT 0.039 (0.298)	DT 0.001 (0.259)	loss 11.233 (10.542)	prob 0.039 (0.919)	GS 37.094 (31.688)	mem 76.161
Train: [1][970/1500]	BT 0.038 (0.300)	DT 0.001 (0.261)	loss 10.614 (10.541)	prob 0.108 (0.762)	GS 35.188 (32.796)	mem 76.164
Train: [1][980/1500]	BT 0.040 (0.297)	DT 0.001 (0.259)	loss 10.413 (10.532)	prob -0.004 (0.599)	GS 36.688 (33.011)	mem 76.163
Train: [1][990/1500]	BT 0.039 (0.298)	DT 0.001 (0.260)	loss 10.246 (10.536)	prob 0.216 (0.468)	GS 31.344 (33.052)	mem 76.124
Train: [1][1000/1500]	BT 0.039 (0.296)	DT 0.001 (0.257)	loss 10.800 (10.569)	prob -0.921 (0.252)	GS 33.141 (32.906)	mem 76.124
Train: [1][1010/1500]	BT 0.039 (0.294)	DT 0.001 (0.255)	loss 10.825 (10.534)	prob 0.336 (-0.147)	GS 33.078 (33.631)	mem 76.122
Train: [1][1020/1500]	BT 0.041 (0.294)	DT 0.001 (0.255)	loss 10.503 (10.545)	prob 0.189 (-0.085)	GS 36.406 (31.951)	mem 76.162
Train: [1][1030/1500]	BT 0.040 (0.291)	DT 0.001 (0.253)	loss 10.499 (10.519)	prob 0.564 (0.033)	GS 29.281 (31.999)	mem 76.183
Train: [1][1040/1500]	BT 0.031 (0.300)	DT 0.001 (0.262)	loss 10.575 (10.523)	prob 0.372 (0.153)	GS 32.500 (32.470)	mem 76.359
Train: [1][1050/1500]	BT 0.039 (0.298)	DT 0.001 (0.259)	loss 10.711 (10.539)	prob 0.264 (0.242)	GS 27.828 (32.650)	mem 76.371
Train: [1][1060/1500]	BT 0.028 (0.299)	DT 0.000 (0.261)	loss 10.474 (10.507)	prob 0.556 (0.542)	GS 33.031 (32.306)	mem 76.375
Train: [1][1070/1500]	BT 0.039 (0.297)	DT 0.001 (0.258)	loss 10.795 (10.558)	prob 0.515 (0.574)	GS 29.984 (32.402)	mem 76.388
Train: [1][1080/1500]	BT 0.036 (0.294)	DT 0.001 (0.256)	loss 10.581 (10.581)	prob 0.647 (0.571)	GS 34.406 (32.443)	mem 76.400
Train: [1][1090/1500]	BT 0.030 (0.295)	DT 0.000 (0.257)	loss 10.597 (10.537)	prob 0.851 (0.684)	GS 29.609 (32.333)	mem 76.391
Train: [1][1100/1500]	BT 0.039 (0.293)	DT 0.001 (0.254)	loss 10.357 (10.564)	prob 0.209 (0.616)	GS 27.469 (32.151)	mem 76.401
Train: [1][1110/1500]	BT 0.039 (0.294)	DT 0.001 (0.255)	loss 10.359 (10.443)	prob 0.706 (0.457)	GS 34.625 (32.163)	mem 76.352
Train: [1][1120/1500]	BT 0.039 (0.291)	DT 0.000 (0.253)	loss 11.011 (10.496)	prob 0.004 (0.456)	GS 35.188 (32.700)	mem 76.357
Train: [1][1130/1500]	BT 0.040 (0.292)	DT 0.001 (0.253)	loss 10.935 (10.487)	prob 0.191 (0.497)	GS 32.781 (32.629)	mem 76.354
Train: [1][1140/1500]	BT 0.040 (0.291)	DT 0.001 (0.252)	loss 10.321 (10.532)	prob 1.248 (0.530)	GS 32.625 (32.440)	mem 76.409
Train: [1][1150/1500]	BT 0.043 (0.288)	DT 0.001 (0.250)	loss 10.411 (10.502)	prob 0.936 (0.616)	GS 36.031 (32.276)	mem 76.430
Train: [1][1160/1500]	BT 0.038 (0.290)	DT 0.000 (0.251)	loss 10.317 (10.305)	prob 0.539 (0.592)	GS 37.141 (33.119)	mem 76.554
Train: [1][1170/1500]	BT 0.039 (0.288)	DT 0.001 (0.249)	loss 10.688 (10.448)	prob 0.440 (0.464)	GS 30.375 (32.385)	mem 76.567
Train: [1][1180/1500]	BT 0.038 (0.289)	DT 0.001 (0.250)	loss 10.499 (10.471)	prob 0.532 (0.457)	GS 35.875 (32.163)	mem 76.665
Train: [1][1190/1500]	BT 0.027 (0.287)	DT 0.000 (0.249)	loss 10.340 (10.437)	prob 0.333 (0.498)	GS 34.047 (32.396)	mem 76.694
Train: [1][1200/1500]	BT 0.039 (0.285)	DT 0.001 (0.247)	loss 10.844 (10.467)	prob 0.313 (0.519)	GS 35.031 (32.721)	mem 76.705
Train: [1][1210/1500]	BT 0.039 (0.287)	DT 0.001 (0.248)	loss 10.129 (10.636)	prob 0.734 (0.370)	GS 34.703 (33.587)	mem 76.825
Train: [1][1220/1500]	BT 0.039 (0.285)	DT 0.001 (0.246)	loss 10.467 (10.602)	prob 0.464 (0.423)	GS 33.188 (33.377)	mem 76.850
Train: [1][1230/1500]	BT 0.038 (0.286)	DT 0.000 (0.247)	loss 10.561 (10.527)	prob 0.476 (0.542)	GS 37.469 (32.938)	mem 76.880
Train: [1][1240/1500]	BT 0.037 (0.284)	DT 0.000 (0.245)	loss 10.737 (10.471)	prob 0.031 (0.587)	GS 35.031 (32.730)	mem 76.896
Train: [1][1250/1500]	BT 0.072 (0.286)	DT 0.001 (0.248)	loss 10.093 (10.467)	prob 0.578 (0.481)	GS 31.562 (32.705)	mem 76.971
Train: [1][1260/1500]	BT 0.029 (0.288)	DT 0.000 (0.250)	loss 9.950 (10.485)	prob 0.398 (-0.029)	GS 33.672 (34.516)	mem 77.072
Train: [1][1270/1500]	BT 0.037 (0.286)	DT 0.000 (0.248)	loss 10.437 (10.466)	prob -0.164 (-0.217)	GS 34.047 (33.881)	mem 77.085
Train: [1][1280/1500]	BT 0.650 (0.285)	DT 0.612 (0.246)	loss 10.466 (10.476)	prob -0.588 (-0.304)	GS 33.047 (33.416)	mem 77.121
Train: [1][1290/1500]	BT 0.038 (0.285)	DT 0.001 (0.246)	loss 10.408 (10.492)	prob 0.068 (-0.262)	GS 33.500 (33.318)	mem 77.212
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [1][1300/1500]	BT 0.030 (0.289)	DT 0.000 (0.250)	loss 10.107 (10.445)	prob 0.318 (-0.182)	GS 33.719 (33.382)	mem 77.482
Train: [1][1310/1500]	BT 0.050 (0.287)	DT 0.001 (0.248)	loss 10.793 (10.591)	prob -0.265 (-0.095)	GS 34.828 (31.836)	mem 77.533
Train: [1][1320/1500]	BT 0.043 (0.285)	DT 0.001 (0.246)	loss 10.066 (10.495)	prob 0.433 (0.079)	GS 36.469 (31.966)	mem 77.563
Train: [1][1330/1500]	BT 0.065 (0.287)	DT 0.001 (0.248)	loss 10.711 (10.473)	prob -0.120 (0.148)	GS 31.109 (32.054)	mem 79.358
Train: [1][1340/1500]	BT 0.040 (0.285)	DT 0.001 (0.246)	loss 10.389 (10.478)	prob -0.143 (0.154)	GS 30.719 (32.074)	mem 79.291
Train: [1][1350/1500]	BT 0.039 (0.285)	DT 0.001 (0.247)	loss 10.212 (10.471)	prob 0.704 (0.104)	GS 32.469 (32.047)	mem 76.471
Train: [1][1360/1500]	BT 0.041 (0.284)	DT 0.001 (0.245)	loss 10.659 (10.365)	prob -0.227 (0.008)	GS 37.109 (33.547)	mem 76.477
Train: [1][1370/1500]	BT 0.039 (0.285)	DT 0.001 (0.247)	loss 10.735 (10.388)	prob 0.277 (0.239)	GS 33.688 (32.569)	mem 76.592
Train: [1][1380/1500]	BT 0.040 (0.283)	DT 0.001 (0.245)	loss 10.088 (10.410)	prob 0.598 (0.270)	GS 34.062 (32.892)	mem 76.601
Train: [1][1390/1500]	BT 0.040 (0.282)	DT 0.001 (0.243)	loss 10.533 (10.422)	prob 0.491 (0.279)	GS 32.438 (32.494)	mem 76.608
Train: [1][1400/1500]	BT 0.031 (0.286)	DT 0.000 (0.248)	loss 10.918 (10.428)	prob 0.194 (0.312)	GS 35.938 (32.375)	mem 76.722
Train: [1][1410/1500]	BT 0.031 (0.284)	DT 0.000 (0.246)	loss 10.167 (10.493)	prob 0.175 (-0.003)	GS 30.781 (31.087)	mem 76.730
Train: [1][1420/1500]	BT 0.032 (0.287)	DT 0.000 (0.248)	loss 10.340 (10.424)	prob -0.425 (-0.067)	GS 35.984 (31.880)	mem 76.808
Train: [1][1430/1500]	BT 0.040 (0.285)	DT 0.001 (0.246)	loss 10.346 (10.397)	prob -0.122 (-0.085)	GS 33.281 (32.087)	mem 76.819
Train: [1][1440/1500]	BT 0.030 (0.286)	DT 0.000 (0.247)	loss 9.880 (10.397)	prob 0.161 (-0.115)	GS 30.875 (31.993)	mem 76.901
Train: [1][1450/1500]	BT 0.039 (0.285)	DT 0.001 (0.246)	loss 10.344 (10.403)	prob 0.140 (-0.185)	GS 32.500 (32.001)	mem 76.931
Train: [1][1460/1500]	BT 0.039 (0.283)	DT 0.001 (0.245)	loss 10.187 (10.389)	prob 0.095 (-0.275)	GS 31.969 (31.978)	mem 76.944
Train: [1][1470/1500]	BT 0.028 (0.284)	DT 0.000 (0.245)	loss 10.200 (10.344)	prob -0.901 (-0.518)	GS 31.453 (32.170)	mem 76.259
Train: [1][1480/1500]	BT 0.032 (0.282)	DT 0.001 (0.244)	loss 10.181 (10.394)	prob -0.813 (-0.740)	GS 31.906 (32.040)	mem 47.460
Train: [1][1490/1500]	BT 0.030 (0.283)	DT 0.000 (0.244)	loss 10.062 (10.446)	prob -0.546 (-0.785)	GS 30.312 (32.389)	mem 13.052
Train: [1][1500/1500]	BT 0.024 (0.281)	DT 0.000 (0.243)	loss 10.829 (10.484)	prob -1.006 (-0.799)	GS 28.781 (32.267)	mem 12.210
Train: [1][1510/1500]	BT 0.026 (0.279)	DT 0.000 (0.241)	loss 10.728 (10.737)	prob 0.449 (0.171)	GS 35.594 (33.344)	mem 12.227
epoch 1, total time 422.93
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [2][1/1500]	BT 17.701 (17.701)	DT 17.643 (17.643)	loss 10.394 (10.394)	prob 1.006 (1.006)	GS 30.203 (30.203)	mem 74.957
Train: [2][10/1500]	BT 0.035 (2.635)	DT 0.000 (2.586)	loss 10.181 (10.272)	prob 0.318 (0.571)	GS 34.922 (32.872)	mem 75.295
Train: [2][20/1500]	BT 0.028 (1.721)	DT 0.000 (1.676)	loss 9.941 (10.220)	prob 0.361 (0.420)	GS 32.328 (33.409)	mem 75.543
Train: [2][30/1500]	BT 0.038 (1.205)	DT 0.000 (1.164)	loss 11.037 (10.186)	prob -1.195 (0.241)	GS 36.203 (33.713)	mem 75.607
Train: [2][40/1500]	BT 0.037 (0.913)	DT 0.000 (0.873)	loss 9.581 (10.193)	prob -0.011 (0.065)	GS 31.969 (33.272)	mem 75.620
Train: [2][50/1500]	BT 0.039 (0.769)	DT 0.001 (0.729)	loss 10.321 (10.180)	prob -1.021 (-0.095)	GS 34.219 (32.877)	mem 75.674
Train: [2][60/1500]	BT 0.039 (0.684)	DT 0.001 (0.644)	loss 9.761 (10.109)	prob 0.025 (-0.711)	GS 30.781 (31.308)	mem 75.752
Train: [2][70/1500]	BT 0.053 (0.619)	DT 0.001 (0.579)	loss 10.175 (10.184)	prob -0.050 (-0.638)	GS 30.828 (31.423)	mem 76.659
Train: [2][80/1500]	BT 0.043 (0.599)	DT 0.001 (0.559)	loss 10.588 (10.130)	prob -0.774 (-0.470)	GS 31.719 (31.327)	mem 78.490
Train: [2][90/1500]	BT 0.042 (0.553)	DT 0.001 (0.512)	loss 10.476 (10.127)	prob -0.645 (-0.447)	GS 34.281 (31.727)	mem 80.185
Train: [2][100/1500]	BT 0.042 (0.536)	DT 0.001 (0.496)	loss 10.867 (10.106)	prob -0.884 (-0.431)	GS 32.750 (31.916)	mem 91.044
Train: [2][110/1500]	BT 0.042 (0.491)	DT 0.001 (0.451)	loss 9.914 (10.194)	prob -0.381 (-0.522)	GS 30.156 (33.355)	mem 89.955
Train: [2][120/1500]	BT 0.039 (0.465)	DT 0.001 (0.425)	loss 9.873 (10.166)	prob 0.024 (-0.545)	GS 33.766 (33.143)	mem 76.320
Train: [2][130/1500]	BT 0.041 (0.453)	DT 0.001 (0.412)	loss 9.441 (10.143)	prob 0.012 (-0.568)	GS 33.797 (32.680)	mem 77.902
Train: [2][140/1500]	BT 0.040 (0.440)	DT 0.001 (0.399)	loss 9.803 (10.124)	prob 0.091 (-0.534)	GS 35.141 (32.588)	mem 79.262
Train: [2][150/1500]	BT 0.039 (0.419)	DT 0.001 (0.378)	loss 10.258 (10.094)	prob -0.952 (-0.522)	GS 29.781 (32.770)	mem 77.212
Train: [2][160/1500]	BT 0.038 (0.395)	DT 0.001 (0.355)	loss 10.333 (10.082)	prob -0.692 (-0.562)	GS 35.250 (32.362)	mem 76.331
Train: [2][170/1500]	BT 0.049 (0.394)	DT 0.003 (0.354)	loss 9.840 (10.033)	prob -0.179 (-0.551)	GS 31.797 (32.166)	mem 75.365
Train: [2][180/1500]	BT 0.047 (0.391)	DT 0.001 (0.349)	loss 9.698 (10.051)	prob -0.872 (-0.561)	GS 33.172 (32.242)	mem 75.358
Train: [2][190/1500]	BT 0.043 (0.399)	DT 0.011 (0.357)	loss 9.685 (10.040)	prob -0.489 (-0.640)	GS 31.734 (31.983)	mem 75.783
Train: [2][200/1500]	BT 0.039 (0.412)	DT 0.001 (0.370)	loss 9.693 (10.030)	prob -0.172 (-0.633)	GS 38.359 (32.467)	mem 76.565
Train: [2][210/1500]	BT 0.038 (0.395)	DT 0.001 (0.353)	loss 9.989 (10.016)	prob -0.498 (-0.857)	GS 35.562 (33.908)	mem 76.589
Train: [2][220/1500]	BT 0.039 (0.383)	DT 0.001 (0.341)	loss 9.971 (10.020)	prob -0.548 (-0.824)	GS 36.766 (33.167)	mem 76.647
Train: [2][230/1500]	BT 0.038 (0.380)	DT 0.001 (0.339)	loss 9.384 (9.965)	prob -0.420 (-0.843)	GS 35.500 (33.033)	mem 76.741
Train: [2][240/1500]	BT 0.038 (0.368)	DT 0.001 (0.327)	loss 9.042 (9.983)	prob 0.258 (-0.830)	GS 33.484 (33.016)	mem 76.757
Train: [2][250/1500]	BT 0.062 (0.372)	DT 0.006 (0.330)	loss 10.650 (9.984)	prob -1.113 (-0.798)	GS 37.391 (33.008)	mem 76.835
Train: [2][260/1500]	BT 0.062 (0.360)	DT 0.011 (0.318)	loss 10.154 (9.935)	prob -0.722 (-0.411)	GS 31.359 (31.236)	mem 76.844
Train: [2][270/1500]	BT 0.088 (0.379)	DT 0.009 (0.337)	loss 10.064 (9.878)	prob -0.475 (-0.308)	GS 31.312 (31.323)	mem 76.950
Train: [2][280/1500]	BT 0.030 (0.395)	DT 0.000 (0.353)	loss 9.860 (9.852)	prob -0.281 (-0.328)	GS 36.641 (31.548)	mem 76.993
Train: [2][290/1500]	BT 0.036 (0.383)	DT 0.001 (0.341)	loss 9.693 (9.862)	prob -0.561 (-0.384)	GS 31.828 (31.752)	mem 77.003
Train: [2][300/1500]	BT 0.039 (0.380)	DT 0.001 (0.339)	loss 10.179 (9.892)	prob -1.054 (-0.482)	GS 31.969 (32.054)	mem 77.096
Train: [2][310/1500]	BT 0.039 (0.369)	DT 0.001 (0.328)	loss 9.935 (9.674)	prob -0.838 (-0.492)	GS 31.906 (32.536)	mem 77.111
Train: [2][320/1500]	BT 0.041 (0.369)	DT 0.001 (0.328)	loss 10.088 (9.787)	prob -1.117 (-0.722)	GS 34.328 (32.847)	mem 77.198
Train: [2][330/1500]	BT 0.040 (0.359)	DT 0.001 (0.318)	loss 9.217 (9.834)	prob -0.643 (-0.832)	GS 28.750 (32.991)	mem 77.212
Train: [2][340/1500]	BT 0.039 (0.350)	DT 0.001 (0.309)	loss 9.436 (9.823)	prob -0.175 (-0.821)	GS 29.234 (32.664)	mem 77.214
Train: [2][350/1500]	BT 0.040 (0.354)	DT 0.009 (0.313)	loss 9.880 (9.824)	prob -0.742 (-0.807)	GS 36.438 (32.600)	mem 77.353
Train: [2][360/1500]	BT 0.032 (0.346)	DT 0.000 (0.305)	loss 10.158 (9.702)	prob -1.060 (-0.738)	GS 30.328 (33.481)	mem 77.364
Train: [2][370/1500]	BT 0.039 (0.351)	DT 0.001 (0.310)	loss 9.402 (9.747)	prob -0.449 (-0.797)	GS 31.984 (33.151)	mem 76.340
Train: [2][380/1500]	BT 0.039 (0.343)	DT 0.001 (0.302)	loss 9.757 (9.802)	prob -0.877 (-0.803)	GS 36.641 (33.364)	mem 76.343
Train: [2][390/1500]	BT 0.040 (0.342)	DT 0.001 (0.301)	loss 9.849 (9.810)	prob -0.495 (-0.838)	GS 33.031 (33.449)	mem 76.403
Train: [2][400/1500]	BT 0.040 (0.335)	DT 0.001 (0.294)	loss 9.935 (9.811)	prob -0.582 (-0.802)	GS 36.797 (33.304)	mem 76.423
Train: [2][410/1500]	BT 0.040 (0.330)	DT 0.001 (0.290)	loss 10.266 (9.822)	prob -1.083 (-0.489)	GS 33.062 (33.184)	mem 76.478
Train: [2][420/1500]	BT 0.064 (0.352)	DT 0.004 (0.311)	loss 9.834 (9.743)	prob -0.718 (-0.511)	GS 34.562 (32.893)	mem 76.733
Train: [2][430/1500]	BT 0.067 (0.346)	DT 0.017 (0.304)	loss 9.769 (9.745)	prob -0.676 (-0.497)	GS 30.750 (32.745)	mem 76.762
Train: [2][440/1500]	BT 0.033 (0.369)	DT 0.000 (0.327)	loss 9.328 (9.744)	prob -0.019 (-0.483)	GS 37.438 (32.939)	mem 79.723
Train: [2][450/1500]	BT 0.031 (0.382)	DT 0.000 (0.341)	loss 10.233 (9.737)	prob -1.027 (-0.533)	GS 33.781 (33.190)	mem 77.089
Train: [2][460/1500]	BT 0.042 (0.374)	DT 0.004 (0.334)	loss 9.909 (9.830)	prob -0.619 (-0.599)	GS 37.031 (33.814)	mem 77.100
Train: [2][470/1500]	BT 0.040 (0.378)	DT 0.010 (0.338)	loss 9.425 (9.765)	prob -0.384 (-0.572)	GS 28.109 (32.648)	mem 77.212
Train: [2][480/1500]	BT 0.060 (0.371)	DT 0.002 (0.331)	loss 9.717 (9.755)	prob -0.034 (-0.507)	GS 36.922 (32.696)	mem 77.219
Train: [2][490/1500]	BT 0.072 (0.365)	DT 0.001 (0.324)	loss 10.181 (9.780)	prob -0.788 (-0.533)	GS 33.969 (32.674)	mem 77.229
Train: [2][500/1500]	BT 0.133 (0.381)	DT 0.020 (0.339)	loss 9.764 (9.782)	prob -0.900 (-0.565)	GS 31.641 (32.815)	mem 77.323
Train: [2][510/1500]	BT 0.023 (0.408)	DT 0.000 (0.366)	loss 9.488 (9.751)	prob -0.317 (-0.573)	GS 34.453 (33.087)	mem 76.497
Train: [2][520/1500]	BT 0.041 (0.400)	DT 0.001 (0.359)	loss 9.132 (9.742)	prob -0.183 (-0.621)	GS 31.500 (33.648)	mem 76.508
Train: [2][530/1500]	BT 0.065 (0.406)	DT 0.002 (0.364)	loss 9.563 (9.704)	prob 0.017 (-0.576)	GS 35.875 (33.238)	mem 76.593
Train: [2][540/1500]	BT 0.099 (0.399)	DT 0.025 (0.357)	loss 10.104 (9.724)	prob -0.644 (-0.547)	GS 33.766 (33.196)	mem 76.602
Train: [2][550/1500]	BT 0.102 (0.397)	DT 0.011 (0.355)	loss 9.400 (9.714)	prob -0.104 (-0.536)	GS 31.609 (33.114)	mem 76.620
Train: [2][560/1500]	BT 0.030 (0.397)	DT 0.001 (0.355)	loss 9.401 (9.716)	prob -0.242 (-0.552)	GS 36.422 (32.161)	mem 76.718
Train: [2][570/1500]	BT 0.039 (0.391)	DT 0.001 (0.348)	loss 9.564 (9.744)	prob -0.496 (-0.663)	GS 30.781 (33.345)	mem 76.726
Train: [2][580/1500]	BT 0.039 (0.390)	DT 0.001 (0.348)	loss 9.660 (9.748)	prob -0.271 (-0.642)	GS 30.703 (32.979)	mem 76.792
Train: [2][590/1500]	BT 0.040 (0.384)	DT 0.001 (0.342)	loss 10.067 (9.748)	prob -0.694 (-0.579)	GS 35.516 (33.147)	mem 76.799
Train: [2][600/1500]	BT 0.065 (0.386)	DT 0.003 (0.344)	loss 10.090 (9.744)	prob -0.660 (-0.563)	GS 34.406 (32.851)	mem 76.912
Train: [2][610/1500]	BT 0.031 (0.381)	DT 0.000 (0.338)	loss 9.479 (9.832)	prob 0.128 (-0.386)	GS 37.641 (33.392)	mem 76.918
Train: [2][620/1500]	BT 0.036 (0.375)	DT 0.001 (0.333)	loss 9.801 (9.836)	prob -0.512 (-0.441)	GS 37.078 (33.505)	mem 76.922
Train: [2][630/1500]	BT 0.034 (0.384)	DT 0.000 (0.342)	loss 9.840 (9.821)	prob -0.201 (-0.474)	GS 36.047 (33.341)	mem 77.030
Train: [2][640/1500]	BT 0.040 (0.385)	DT 0.001 (0.343)	loss 9.962 (9.806)	prob -0.612 (-0.473)	GS 30.375 (33.378)	mem 77.137
Train: [2][650/1500]	BT 0.053 (0.381)	DT 0.000 (0.339)	loss 10.239 (9.800)	prob -0.726 (-0.462)	GS 36.250 (33.030)	mem 77.142
Train: [2][660/1500]	BT 0.075 (0.383)	DT 0.013 (0.341)	loss 10.170 (9.832)	prob -0.325 (-0.241)	GS 34.672 (32.097)	mem 77.217
Train: [2][670/1500]	BT 0.062 (0.378)	DT 0.015 (0.336)	loss 9.467 (9.784)	prob 0.033 (-0.304)	GS 33.078 (32.542)	mem 77.226
Train: [2][680/1500]	BT 0.038 (0.378)	DT 0.001 (0.336)	loss 10.388 (9.806)	prob -0.699 (-0.336)	GS 32.453 (32.346)	mem 77.255
Train: [2][690/1500]	BT 0.038 (0.375)	DT 0.001 (0.333)	loss 9.379 (9.776)	prob 0.242 (-0.269)	GS 35.078 (32.138)	mem 77.244
Train: [2][700/1500]	BT 0.038 (0.372)	DT 0.001 (0.330)	loss 9.516 (9.767)	prob 0.126 (-0.238)	GS 30.828 (32.363)	mem 77.273
Train: [2][710/1500]	BT 0.038 (0.370)	DT 0.001 (0.328)	loss 9.425 (9.548)	prob 0.281 (0.111)	GS 34.109 (31.464)	mem 77.320
Train: [2][720/1500]	BT 0.867 (0.369)	DT 0.829 (0.327)	loss 9.868 (9.774)	prob 0.031 (-0.074)	GS 33.688 (31.250)	mem 76.386
Train: [2][730/1500]	BT 0.039 (0.365)	DT 0.001 (0.323)	loss 9.840 (9.767)	prob -0.117 (-0.077)	GS 34.109 (31.653)	mem 76.392
Train: [2][740/1500]	BT 0.069 (0.368)	DT 0.010 (0.326)	loss 10.056 (9.794)	prob -0.166 (-0.114)	GS 37.875 (32.105)	mem 76.343
Train: [2][750/1500]	BT 0.089 (0.364)	DT 0.012 (0.322)	loss 10.085 (9.796)	prob -0.384 (-0.157)	GS 33.734 (32.157)	mem 76.358
Train: [2][760/1500]	BT 0.030 (0.372)	DT 0.000 (0.330)	loss 10.017 (9.682)	prob 0.097 (0.068)	GS 34.141 (32.600)	mem 76.535
Train: [2][770/1500]	BT 0.028 (0.368)	DT 0.000 (0.326)	loss 10.219 (9.789)	prob 0.101 (0.057)	GS 35.906 (32.681)	mem 76.542
Train: [2][780/1500]	BT 0.038 (0.367)	DT 0.001 (0.326)	loss 10.244 (9.812)	prob -0.447 (-0.001)	GS 34.031 (32.868)	mem 76.625
Train: [2][790/1500]	BT 0.037 (0.363)	DT 0.000 (0.321)	loss 9.805 (9.791)	prob -0.244 (-0.037)	GS 29.422 (32.733)	mem 76.632
Train: [2][800/1500]	BT 0.038 (0.359)	DT 0.000 (0.317)	loss 10.066 (9.793)	prob -0.194 (-0.010)	GS 33.828 (32.477)	mem 76.638
Train: [2][810/1500]	BT 0.038 (0.360)	DT 0.000 (0.318)	loss 9.689 (9.777)	prob 0.298 (0.055)	GS 35.594 (32.362)	mem 76.732
Train: [2][820/1500]	BT 0.051 (0.356)	DT 0.000 (0.314)	loss 9.946 (9.749)	prob 0.161 (0.113)	GS 35.469 (32.469)	mem 76.737
Train: [2][830/1500]	BT 0.038 (0.361)	DT 0.001 (0.319)	loss 10.469 (9.797)	prob -0.270 (0.088)	GS 35.797 (32.449)	mem 76.846
Train: [2][840/1500]	BT 0.039 (0.358)	DT 0.001 (0.316)	loss 10.737 (9.825)	prob -0.443 (0.042)	GS 33.734 (32.649)	mem 76.877
Train: [2][850/1500]	BT 0.062 (0.357)	DT 0.013 (0.315)	loss 9.793 (9.822)	prob -0.051 (0.065)	GS 35.797 (32.965)	mem 76.935
Train: [2][860/1500]	BT 0.070 (0.359)	DT 0.001 (0.317)	loss 9.895 (9.935)	prob 0.323 (0.239)	GS 30.297 (33.005)	mem 78.747
Train: [2][870/1500]	BT 0.042 (0.355)	DT 0.001 (0.313)	loss 10.034 (9.845)	prob 0.142 (0.283)	GS 34.062 (33.130)	mem 78.927
Train: [2][880/1500]	BT 0.044 (0.358)	DT 0.001 (0.316)	loss 9.970 (9.813)	prob 0.280 (0.321)	GS 32.203 (32.942)	mem 85.494
Train: [2][890/1500]	BT 0.045 (0.354)	DT 0.001 (0.312)	loss 9.961 (9.806)	prob 0.383 (0.344)	GS 29.562 (32.721)	mem 87.509
Train: [2][900/1500]	BT 0.044 (0.353)	DT 0.001 (0.311)	loss 9.451 (9.793)	prob 0.376 (0.339)	GS 33.859 (32.759)	mem 95.354
Train: [2][910/1500]	BT 0.046 (0.355)	DT 0.001 (0.313)	loss 9.843 (9.861)	prob 0.266 (0.050)	GS 32.484 (32.625)	mem 105.682
Train: [2][920/1500]	BT 0.046 (0.352)	DT 0.001 (0.310)	loss 9.687 (9.841)	prob 0.541 (0.150)	GS 33.344 (31.970)	mem 109.575
Train: [2][930/1500]	BT 0.052 (0.355)	DT 0.001 (0.313)	loss 10.038 (9.832)	prob 0.148 (0.175)	GS 33.406 (32.209)	mem 112.927
Train: [2][940/1500]	BT 0.037 (0.352)	DT 0.001 (0.310)	loss 9.598 (9.834)	prob 0.713 (0.204)	GS 35.891 (32.354)	mem 112.942
Train: [2][950/1500]	BT 0.058 (0.351)	DT 0.001 (0.309)	loss 9.763 (9.852)	prob 0.627 (0.242)	GS 32.469 (32.055)	mem 112.940
Train: [2][960/1500]	BT 0.046 (0.352)	DT 0.001 (0.309)	loss 10.437 (9.948)	prob -0.184 (0.204)	GS 36.016 (33.581)	mem 113.009
Train: [2][970/1500]	BT 0.040 (0.350)	DT 0.001 (0.307)	loss 9.970 (9.904)	prob -0.050 (0.253)	GS 31.359 (33.019)	mem 113.037
Train: [2][980/1500]	BT 0.043 (0.352)	DT 0.001 (0.310)	loss 9.995 (9.883)	prob 0.908 (0.336)	GS 35.125 (33.045)	mem 113.080
Train: [2][990/1500]	BT 0.044 (0.349)	DT 0.001 (0.307)	loss 9.485 (9.888)	prob 0.568 (0.369)	GS 31.891 (33.093)	mem 113.092
Train: [2][1000/1500]	BT 0.042 (0.351)	DT 0.001 (0.309)	loss 9.609 (9.897)	prob 0.788 (0.373)	GS 37.891 (33.257)	mem 76.596
Train: [2][1010/1500]	BT 0.040 (0.348)	DT 0.001 (0.306)	loss 10.213 (9.800)	prob 0.195 (0.370)	GS 32.656 (33.991)	mem 76.605
Train: [2][1020/1500]	BT 0.039 (0.346)	DT 0.001 (0.304)	loss 9.784 (9.869)	prob 0.540 (0.418)	GS 31.891 (33.386)	mem 76.629
Train: [2][1030/1500]	BT 0.038 (0.346)	DT 0.001 (0.304)	loss 10.342 (9.882)	prob 0.162 (0.432)	GS 33.875 (32.582)	mem 76.700
Train: [2][1040/1500]	BT 0.038 (0.343)	DT 0.001 (0.301)	loss 10.172 (9.871)	prob 0.358 (0.477)	GS 31.516 (32.470)	mem 76.712
Train: [2][1050/1500]	BT 0.029 (0.346)	DT 0.000 (0.304)	loss 10.101 (9.886)	prob 0.490 (0.438)	GS 38.047 (32.879)	mem 77.350
Train: [2][1060/1500]	BT 0.040 (0.343)	DT 0.001 (0.301)	loss 10.246 (9.926)	prob 0.199 (0.246)	GS 36.781 (34.494)	mem 77.538
Train: [2][1070/1500]	BT 0.044 (0.342)	DT 0.001 (0.300)	loss 9.560 (9.892)	prob 0.856 (0.340)	GS 37.281 (33.782)	mem 78.693
Train: [2][1080/1500]	BT 0.031 (0.347)	DT 0.000 (0.305)	loss 9.656 (9.922)	prob 0.404 (0.363)	GS 32.281 (33.767)	mem 77.069
Train: [2][1090/1500]	BT 0.025 (0.344)	DT 0.000 (0.302)	loss 9.831 (9.910)	prob 0.284 (0.348)	GS 37.750 (33.535)	mem 77.078
Train: [2][1100/1500]	BT 0.034 (0.342)	DT 0.001 (0.300)	loss 9.572 (9.871)	prob 0.745 (0.411)	GS 31.359 (33.308)	mem 77.102
Train: [2][1110/1500]	BT 0.038 (0.341)	DT 0.000 (0.300)	loss 10.076 (9.824)	prob 0.248 (0.546)	GS 36.297 (32.895)	mem 77.204
Train: [2][1120/1500]	BT 0.038 (0.341)	DT 0.001 (0.299)	loss 10.629 (9.817)	prob 0.024 (0.618)	GS 37.984 (33.046)	mem 77.273
Train: [2][1130/1500]	BT 0.028 (0.340)	DT 0.000 (0.298)	loss 9.736 (9.873)	prob 0.598 (0.583)	GS 35.453 (32.901)	mem 77.313
Train: [2][1140/1500]	BT 0.040 (0.338)	DT 0.001 (0.296)	loss 9.935 (9.857)	prob 0.797 (0.644)	GS 37.688 (32.896)	mem 77.337
Train: [2][1150/1500]	BT 0.038 (0.339)	DT 0.001 (0.297)	loss 10.495 (9.845)	prob 0.334 (0.682)	GS 37.203 (32.602)	mem 76.518
Train: [2][1160/1500]	BT 0.039 (0.336)	DT 0.001 (0.295)	loss 10.330 (9.910)	prob 0.404 (0.671)	GS 34.703 (32.800)	mem 76.523
Train: [2][1170/1500]	BT 0.039 (0.335)	DT 0.001 (0.294)	loss 9.960 (9.820)	prob 0.815 (0.792)	GS 32.844 (32.329)	mem 76.518
Train: [2][1180/1500]	BT 0.061 (0.336)	DT 0.000 (0.295)	loss 9.905 (9.807)	prob 0.847 (0.791)	GS 35.219 (32.285)	mem 76.551
Train: [2][1190/1500]	BT 0.028 (0.352)	DT 0.001 (0.310)	loss 9.843 (9.814)	prob 1.229 (0.794)	GS 32.906 (32.621)	mem 94.406
Train: [2][1200/1500]	BT 0.098 (0.349)	DT 0.010 (0.308)	loss 9.421 (9.821)	prob 1.199 (0.774)	GS 28.500 (32.688)	mem 94.850
Train: [2][1210/1500]	BT 0.046 (0.351)	DT 0.001 (0.309)	loss 10.117 (9.685)	prob 0.773 (0.936)	GS 35.312 (32.273)	mem 109.843
Train: [2][1220/1500]	BT 0.046 (0.348)	DT 0.001 (0.307)	loss 9.989 (9.786)	prob 0.666 (0.766)	GS 33.578 (33.630)	mem 111.993
Train: [2][1230/1500]	BT 0.041 (0.346)	DT 0.001 (0.304)	loss 10.286 (9.866)	prob 0.446 (0.630)	GS 39.125 (34.082)	mem 113.471
Train: [2][1240/1500]	BT 0.047 (0.347)	DT 0.001 (0.306)	loss 9.562 (9.819)	prob 1.082 (0.696)	GS 33.125 (33.536)	mem 113.596
Train: [2][1250/1500]	BT 0.042 (0.345)	DT 0.000 (0.303)	loss 9.862 (9.815)	prob 1.287 (0.775)	GS 31.250 (33.236)	mem 113.605
Train: [2][1260/1500]	BT 0.076 (0.349)	DT 0.002 (0.307)	loss 9.575 (9.798)	prob 1.425 (1.166)	GS 36.578 (32.420)	mem 113.722
Train: [2][1270/1500]	BT 0.060 (0.347)	DT 0.003 (0.305)	loss 9.723 (9.849)	prob 0.956 (1.114)	GS 30.500 (32.496)	mem 113.733
Train: [2][1280/1500]	BT 0.071 (0.344)	DT 0.011 (0.302)	loss 9.886 (9.798)	prob 0.958 (1.144)	GS 34.969 (32.179)	mem 113.745
Train: [2][1290/1500]	BT 0.062 (0.351)	DT 0.008 (0.308)	loss 10.341 (9.785)	prob 0.930 (1.191)	GS 34.312 (32.374)	mem 113.882
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [2][1300/1500]	BT 0.060 (0.348)	DT 0.001 (0.306)	loss 9.959 (9.776)	prob 0.986 (1.188)	GS 30.703 (32.263)	mem 113.887
Train: [2][1310/1500]	BT 0.030 (0.362)	DT 0.000 (0.319)	loss 9.432 (9.687)	prob 1.554 (1.340)	GS 33.094 (32.833)	mem 79.418
Train: [2][1320/1500]	BT 0.029 (0.359)	DT 0.000 (0.317)	loss 9.370 (9.737)	prob 1.318 (1.200)	GS 32.438 (32.601)	mem 79.422
Train: [2][1330/1500]	BT 3.223 (0.359)	DT 3.187 (0.317)	loss 9.683 (9.743)	prob 1.211 (1.136)	GS 35.922 (32.770)	mem 76.563
Train: [2][1340/1500]	BT 0.039 (0.357)	DT 0.001 (0.315)	loss 9.290 (9.743)	prob 1.641 (1.175)	GS 31.625 (32.448)	mem 76.568
Train: [2][1350/1500]	BT 0.057 (0.354)	DT 0.011 (0.312)	loss 9.067 (9.718)	prob 1.815 (1.198)	GS 31.734 (32.872)	mem 76.571
Train: [2][1360/1500]	BT 0.037 (0.358)	DT 0.001 (0.316)	loss 9.977 (9.807)	prob 0.821 (1.148)	GS 35.484 (32.459)	mem 76.641
Train: [2][1370/1500]	BT 0.039 (0.356)	DT 0.001 (0.314)	loss 9.601 (9.769)	prob 1.347 (1.270)	GS 30.625 (32.169)	mem 76.647
Train: [2][1380/1500]	BT 0.066 (0.359)	DT 0.006 (0.317)	loss 9.511 (9.707)	prob 1.508 (1.291)	GS 33.109 (32.210)	mem 76.789
Train: [2][1390/1500]	BT 0.031 (0.357)	DT 0.001 (0.315)	loss 9.624 (9.705)	prob 1.127 (1.267)	GS 32.344 (31.730)	mem 76.797
Train: [2][1400/1500]	BT 0.040 (0.357)	DT 0.006 (0.315)	loss 9.690 (9.697)	prob 1.463 (1.266)	GS 34.891 (32.002)	mem 76.833
Train: [2][1410/1500]	BT 0.030 (0.357)	DT 0.001 (0.315)	loss 9.274 (9.639)	prob 1.604 (1.403)	GS 31.594 (33.775)	mem 76.820
Train: [2][1420/1500]	BT 0.039 (0.355)	DT 0.001 (0.313)	loss 9.922 (9.649)	prob 1.340 (1.370)	GS 33.328 (33.902)	mem 76.837
Train: [2][1430/1500]	BT 0.041 (0.357)	DT 0.009 (0.315)	loss 9.610 (9.639)	prob 1.348 (1.397)	GS 37.359 (33.898)	mem 76.958
Train: [2][1440/1500]	BT 0.089 (0.354)	DT 0.009 (0.312)	loss 9.910 (9.660)	prob 1.072 (1.400)	GS 34.750 (33.745)	mem 76.963
Train: [2][1450/1500]	BT 0.035 (0.358)	DT 0.001 (0.315)	loss 9.597 (9.664)	prob 1.603 (1.399)	GS 34.125 (33.261)	mem 76.777
Train: [2][1460/1500]	BT 0.026 (0.357)	DT 0.000 (0.315)	loss 9.918 (9.611)	prob 1.280 (1.451)	GS 34.375 (33.819)	mem 76.550
Train: [2][1470/1500]	BT 0.023 (0.355)	DT 0.000 (0.313)	loss 9.148 (9.608)	prob 2.065 (1.572)	GS 32.750 (32.615)	mem 76.558
Train: [2][1480/1500]	BT 0.025 (0.354)	DT 0.001 (0.312)	loss 9.794 (9.568)	prob 1.167 (1.567)	GS 35.672 (32.538)	mem 12.284
Train: [2][1490/1500]	BT 0.027 (0.352)	DT 0.000 (0.310)	loss 10.430 (9.577)	prob 0.829 (1.530)	GS 37.031 (32.404)	mem 12.296
Train: [2][1500/1500]	BT 0.026 (0.350)	DT 0.000 (0.308)	loss 10.062 (9.586)	prob 1.638 (1.529)	GS 31.625 (32.372)	mem 12.306
Train: [2][1510/1500]	BT 0.036 (0.348)	DT 0.000 (0.307)	loss 9.886 (9.707)	prob 1.408 (1.721)	GS 34.031 (32.044)	mem 12.282
epoch 2, total time 526.11
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [3][1/1500]	BT 19.602 (19.602)	DT 19.546 (19.546)	loss 10.048 (10.048)	prob 1.576 (1.576)	GS 31.922 (31.922)	mem 75.089
Train: [3][10/1500]	BT 0.039 (2.673)	DT 0.000 (2.633)	loss 9.425 (9.715)	prob 1.121 (1.243)	GS 34.125 (34.812)	mem 75.520
Train: [3][20/1500]	BT 0.041 (1.583)	DT 0.001 (1.546)	loss 9.942 (9.653)	prob 0.929 (1.298)	GS 35.344 (34.252)	mem 75.652
Train: [3][30/1500]	BT 0.041 (1.082)	DT 0.001 (1.044)	loss 9.245 (9.575)	prob 2.465 (1.437)	GS 32.062 (33.563)	mem 75.680
Train: [3][40/1500]	BT 0.041 (0.929)	DT 0.001 (0.891)	loss 9.851 (9.560)	prob 1.115 (1.547)	GS 30.219 (33.064)	mem 75.852
Train: [3][50/1500]	BT 0.040 (0.751)	DT 0.001 (0.713)	loss 9.172 (9.534)	prob 1.771 (1.595)	GS 29.953 (32.904)	mem 75.859
Train: [3][60/1500]	BT 0.039 (0.686)	DT 0.001 (0.648)	loss 10.050 (9.613)	prob 1.340 (1.519)	GS 34.312 (32.464)	mem 75.931
Train: [3][70/1500]	BT 0.039 (0.593)	DT 0.000 (0.555)	loss 9.495 (9.459)	prob 1.990 (1.680)	GS 30.641 (31.719)	mem 75.943
Train: [3][80/1500]	BT 0.040 (0.524)	DT 0.001 (0.486)	loss 9.234 (9.465)	prob 1.573 (1.668)	GS 32.000 (32.030)	mem 75.952
Train: [3][90/1500]	BT 0.040 (0.501)	DT 0.001 (0.462)	loss 9.989 (9.488)	prob 1.200 (1.650)	GS 37.875 (32.215)	mem 76.017
Train: [3][100/1500]	BT 0.374 (0.466)	DT 0.334 (0.428)	loss 9.457 (9.480)	prob 1.916 (1.695)	GS 29.688 (32.077)	mem 76.063
Train: [3][110/1500]	BT 0.039 (0.510)	DT 0.000 (0.471)	loss 9.505 (9.552)	prob 2.085 (1.829)	GS 34.578 (33.053)	mem 76.250
Train: [3][120/1500]	BT 0.039 (0.470)	DT 0.001 (0.432)	loss 9.262 (9.487)	prob 2.028 (1.885)	GS 36.641 (33.087)	mem 76.259
Train: [3][130/1500]	BT 0.027 (0.471)	DT 0.000 (0.434)	loss 9.733 (9.503)	prob 1.503 (1.737)	GS 32.578 (33.251)	mem 75.345
Train: [3][140/1500]	BT 0.033 (0.440)	DT 0.000 (0.403)	loss 9.815 (9.513)	prob 2.052 (1.735)	GS 33.391 (33.116)	mem 75.349
Train: [3][150/1500]	BT 0.038 (0.413)	DT 0.001 (0.376)	loss 9.682 (9.490)	prob 1.766 (1.765)	GS 33.938 (32.982)	mem 75.357
Train: [3][160/1500]	BT 0.038 (0.413)	DT 0.001 (0.376)	loss 9.658 (9.491)	prob 1.244 (1.613)	GS 39.719 (33.188)	mem 75.442
Train: [3][170/1500]	BT 0.038 (0.391)	DT 0.001 (0.354)	loss 9.425 (9.368)	prob 1.993 (1.806)	GS 33.016 (32.405)	mem 75.456
Train: [3][180/1500]	BT 0.038 (0.396)	DT 0.001 (0.358)	loss 9.932 (9.379)	prob 1.597 (1.876)	GS 36.094 (32.421)	mem 75.616
Train: [3][190/1500]	BT 0.038 (0.377)	DT 0.001 (0.339)	loss 9.869 (9.375)	prob 1.247 (1.866)	GS 34.234 (32.646)	mem 75.632
Train: [3][200/1500]	BT 0.037 (0.375)	DT 0.000 (0.338)	loss 9.644 (9.343)	prob 2.114 (1.920)	GS 30.109 (32.208)	mem 75.621
Train: [3][210/1500]	BT 0.037 (0.359)	DT 0.000 (0.322)	loss 9.242 (9.478)	prob 1.905 (2.019)	GS 36.281 (33.511)	mem 75.634
Train: [3][220/1500]	BT 0.038 (0.344)	DT 0.000 (0.307)	loss 9.348 (9.418)	prob 2.240 (1.912)	GS 34.969 (33.299)	mem 75.646
Train: [3][230/1500]	BT 0.071 (0.356)	DT 0.000 (0.318)	loss 9.842 (9.475)	prob 1.756 (1.887)	GS 31.438 (33.092)	mem 75.776
Train: [3][240/1500]	BT 0.037 (0.344)	DT 0.001 (0.305)	loss 9.280 (9.431)	prob 2.382 (1.957)	GS 30.688 (32.877)	mem 75.782
Train: [3][250/1500]	BT 0.030 (0.359)	DT 0.000 (0.320)	loss 9.196 (9.403)	prob 2.080 (1.968)	GS 34.484 (32.942)	mem 76.291
Train: [3][260/1500]	BT 0.028 (0.367)	DT 0.000 (0.328)	loss 9.450 (9.325)	prob 2.163 (2.103)	GS 30.172 (32.891)	mem 76.694
Train: [3][270/1500]	BT 0.039 (0.355)	DT 0.001 (0.316)	loss 9.719 (9.380)	prob 1.569 (2.011)	GS 35.297 (32.575)	mem 76.756
Train: [3][280/1500]	BT 0.038 (0.363)	DT 0.000 (0.325)	loss 9.903 (9.385)	prob 1.398 (2.049)	GS 38.750 (32.548)	mem 77.253
Train: [3][290/1500]	BT 0.038 (0.352)	DT 0.001 (0.314)	loss 9.308 (9.372)	prob 2.091 (2.017)	GS 29.859 (32.660)	mem 77.266
Train: [3][300/1500]	BT 0.053 (0.346)	DT 0.006 (0.307)	loss 9.588 (9.348)	prob 1.751 (2.046)	GS 34.750 (32.795)	mem 77.301
Train: [3][310/1500]	BT 0.068 (0.349)	DT 0.004 (0.310)	loss 9.188 (9.294)	prob 2.159 (1.973)	GS 31.984 (32.933)	mem 77.356
Train: [3][320/1500]	BT 0.039 (0.344)	DT 0.001 (0.305)	loss 9.596 (9.281)	prob 1.536 (2.030)	GS 34.734 (32.623)	mem 76.375
Train: [3][330/1500]	BT 0.063 (0.342)	DT 0.007 (0.303)	loss 9.202 (9.244)	prob 2.280 (2.124)	GS 34.875 (32.244)	mem 76.398
Train: [3][340/1500]	BT 0.068 (0.334)	DT 0.011 (0.294)	loss 9.150 (9.223)	prob 2.300 (2.176)	GS 32.750 (32.075)	mem 76.404
Train: [3][350/1500]	BT 0.062 (0.341)	DT 0.002 (0.300)	loss 8.824 (9.201)	prob 2.697 (2.190)	GS 33.656 (31.849)	mem 76.423
Train: [3][360/1500]	BT 0.067 (0.345)	DT 0.010 (0.304)	loss 9.273 (9.296)	prob 1.895 (1.934)	GS 35.391 (33.223)	mem 76.480
Train: [3][370/1500]	BT 0.040 (0.346)	DT 0.001 (0.305)	loss 9.375 (9.319)	prob 1.819 (1.911)	GS 35.266 (33.254)	mem 76.511
Train: [3][380/1500]	BT 0.025 (0.343)	DT 0.000 (0.302)	loss 9.096 (9.287)	prob 2.186 (1.955)	GS 31.578 (33.211)	mem 76.566
Train: [3][390/1500]	BT 0.026 (0.335)	DT 0.000 (0.295)	loss 9.367 (9.247)	prob 2.120 (2.050)	GS 34.594 (33.171)	mem 76.571
Train: [3][400/1500]	BT 0.039 (0.337)	DT 0.001 (0.297)	loss 9.080 (9.230)	prob 2.145 (2.040)	GS 37.438 (33.319)	mem 76.665
Train: [3][410/1500]	BT 0.038 (0.330)	DT 0.000 (0.290)	loss 9.285 (9.123)	prob 1.602 (2.305)	GS 31.641 (31.681)	mem 76.674
Train: [3][420/1500]	BT 0.054 (0.336)	DT 0.001 (0.295)	loss 9.160 (9.074)	prob 2.274 (2.283)	GS 32.297 (32.095)	mem 76.787
Train: [3][430/1500]	BT 0.058 (0.334)	DT 0.002 (0.294)	loss 9.226 (9.112)	prob 2.136 (2.287)	GS 34.391 (32.094)	mem 76.836
Train: [3][440/1500]	BT 0.070 (0.335)	DT 0.015 (0.294)	loss 9.521 (9.092)	prob 2.054 (2.312)	GS 33.297 (31.995)	mem 76.870
Train: [3][450/1500]	BT 0.064 (0.334)	DT 0.002 (0.292)	loss 8.791 (9.092)	prob 2.717 (2.323)	GS 37.656 (32.253)	mem 76.919
Train: [3][460/1500]	BT 0.030 (0.362)	DT 0.000 (0.320)	loss 9.297 (9.238)	prob 2.137 (2.167)	GS 33.141 (33.341)	mem 77.231
Train: [3][470/1500]	BT 0.034 (0.355)	DT 0.001 (0.314)	loss 9.159 (9.138)	prob 2.897 (2.425)	GS 36.016 (32.566)	mem 77.243
Train: [3][480/1500]	BT 0.029 (0.355)	DT 0.000 (0.314)	loss 9.398 (9.056)	prob 2.608 (2.509)	GS 35.859 (32.357)	mem 77.316
Train: [3][490/1500]	BT 0.039 (0.349)	DT 0.001 (0.308)	loss 8.668 (9.048)	prob 2.743 (2.455)	GS 33.500 (32.519)	mem 77.329
Train: [3][500/1500]	BT 0.039 (0.342)	DT 0.001 (0.301)	loss 9.141 (9.045)	prob 2.233 (2.433)	GS 34.672 (32.463)	mem 77.338
Train: [3][510/1500]	BT 0.041 (0.351)	DT 0.001 (0.310)	loss 9.072 (9.056)	prob 2.320 (2.648)	GS 34.625 (32.638)	mem 76.452
Train: [3][520/1500]	BT 0.040 (0.345)	DT 0.001 (0.304)	loss 9.069 (9.042)	prob 2.456 (2.519)	GS 34.031 (33.005)	mem 76.452
Train: [3][530/1500]	BT 0.041 (0.344)	DT 0.001 (0.304)	loss 9.257 (9.008)	prob 2.297 (2.537)	GS 31.797 (32.695)	mem 76.505
Train: [3][540/1500]	BT 0.041 (0.339)	DT 0.001 (0.298)	loss 8.831 (9.016)	prob 2.740 (2.496)	GS 34.453 (32.754)	mem 76.514
Train: [3][550/1500]	BT 0.038 (0.335)	DT 0.001 (0.294)	loss 9.289 (9.048)	prob 2.107 (2.442)	GS 36.641 (32.774)	mem 76.539
Train: [3][560/1500]	BT 0.038 (0.334)	DT 0.001 (0.293)	loss 9.547 (8.984)	prob 2.131 (2.467)	GS 32.891 (32.519)	mem 76.572
Train: [3][570/1500]	BT 0.038 (0.333)	DT 0.001 (0.292)	loss 8.983 (8.976)	prob 2.465 (2.438)	GS 33.156 (32.883)	mem 76.602
Train: [3][580/1500]	BT 0.030 (0.345)	DT 0.000 (0.305)	loss 8.938 (8.947)	prob 2.224 (2.435)	GS 35.047 (33.015)	mem 76.838
Train: [3][590/1500]	BT 0.037 (0.340)	DT 0.000 (0.300)	loss 9.617 (8.951)	prob 1.933 (2.395)	GS 33.016 (33.138)	mem 76.853
Train: [3][600/1500]	BT 2.742 (0.339)	DT 2.704 (0.299)	loss 8.819 (8.934)	prob 2.386 (2.408)	GS 31.656 (32.932)	mem 76.917
Train: [3][610/1500]	BT 0.039 (0.334)	DT 0.001 (0.294)	loss 8.999 (8.869)	prob 2.451 (2.465)	GS 31.531 (32.450)	mem 76.925
Train: [3][620/1500]	BT 0.037 (0.330)	DT 0.001 (0.289)	loss 8.828 (8.878)	prob 2.947 (2.511)	GS 29.453 (32.454)	mem 76.891
Train: [3][630/1500]	BT 0.039 (0.331)	DT 0.000 (0.291)	loss 8.946 (8.903)	prob 2.263 (2.505)	GS 33.312 (32.532)	mem 76.982
Train: [3][640/1500]	BT 0.037 (0.327)	DT 0.001 (0.286)	loss 8.745 (8.890)	prob 3.182 (2.540)	GS 29.359 (32.364)	mem 76.991
Train: [3][650/1500]	BT 0.058 (0.327)	DT 0.011 (0.287)	loss 8.704 (8.879)	prob 3.116 (2.620)	GS 32.000 (32.334)	mem 77.053
Train: [3][660/1500]	BT 0.060 (0.333)	DT 0.016 (0.293)	loss 9.020 (8.758)	prob 2.450 (2.876)	GS 33.609 (33.278)	mem 77.149
Train: [3][670/1500]	BT 0.032 (0.329)	DT 0.000 (0.289)	loss 8.741 (8.734)	prob 2.682 (2.866)	GS 30.578 (32.702)	mem 77.155
Train: [3][680/1500]	BT 0.038 (0.331)	DT 0.000 (0.291)	loss 8.645 (8.769)	prob 2.921 (2.775)	GS 29.047 (32.424)	mem 77.220
Train: [3][690/1500]	BT 0.070 (0.327)	DT 0.009 (0.286)	loss 8.483 (8.765)	prob 2.992 (2.761)	GS 32.266 (32.193)	mem 77.227
Train: [3][700/1500]	BT 0.048 (0.327)	DT 0.000 (0.286)	loss 8.826 (8.745)	prob 3.079 (2.778)	GS 31.219 (32.078)	mem 77.275
Train: [3][710/1500]	BT 0.030 (0.327)	DT 0.000 (0.287)	loss 9.020 (8.813)	prob 2.467 (2.645)	GS 36.422 (31.789)	mem 77.334
Train: [3][720/1500]	BT 0.039 (0.327)	DT 0.001 (0.287)	loss 9.007 (8.800)	prob 2.431 (2.580)	GS 36.750 (32.782)	mem 77.449
Train: [3][730/1500]	BT 0.038 (0.326)	DT 0.001 (0.286)	loss 8.859 (8.785)	prob 2.985 (2.623)	GS 33.844 (32.419)	mem 76.462
Train: [3][740/1500]	BT 0.039 (0.324)	DT 0.001 (0.283)	loss 8.736 (8.763)	prob 2.612 (2.636)	GS 33.281 (32.404)	mem 76.459
Train: [3][750/1500]	BT 0.040 (0.321)	DT 0.001 (0.280)	loss 9.133 (8.781)	prob 2.080 (2.581)	GS 34.641 (32.728)	mem 76.468
Train: [3][760/1500]	BT 0.030 (0.328)	DT 0.000 (0.288)	loss 8.767 (8.634)	prob 2.543 (2.702)	GS 29.266 (33.763)	mem 76.580
Train: [3][770/1500]	BT 0.031 (0.324)	DT 0.000 (0.284)	loss 9.019 (8.648)	prob 2.656 (2.796)	GS 34.297 (32.673)	mem 76.593
Train: [3][780/1500]	BT 0.037 (0.320)	DT 0.000 (0.280)	loss 8.748 (8.638)	prob 3.192 (2.839)	GS 32.469 (32.445)	mem 76.604
Train: [3][790/1500]	BT 0.035 (0.321)	DT 0.001 (0.281)	loss 8.711 (8.670)	prob 2.562 (2.795)	GS 34.188 (32.643)	mem 76.747
Train: [3][800/1500]	BT 0.038 (0.317)	DT 0.001 (0.277)	loss 9.266 (8.689)	prob 2.490 (2.747)	GS 31.625 (32.658)	mem 76.766
Train: [3][810/1500]	BT 0.038 (0.320)	DT 0.001 (0.281)	loss 8.637 (8.557)	prob 3.295 (3.063)	GS 34.031 (31.181)	mem 76.857
Train: [3][820/1500]	BT 0.038 (0.317)	DT 0.001 (0.277)	loss 8.761 (8.560)	prob 2.638 (3.104)	GS 35.328 (31.430)	mem 76.869
Train: [3][830/1500]	BT 0.038 (0.314)	DT 0.001 (0.274)	loss 8.763 (8.584)	prob 2.735 (3.003)	GS 31.562 (31.656)	mem 76.882
Train: [3][840/1500]	BT 0.038 (0.316)	DT 0.000 (0.277)	loss 9.232 (8.594)	prob 2.623 (2.978)	GS 32.469 (31.774)	mem 77.068
Train: [3][850/1500]	BT 0.025 (0.313)	DT 0.000 (0.273)	loss 8.751 (8.608)	prob 3.283 (2.953)	GS 36.031 (32.026)	mem 77.098
Train: [3][860/1500]	BT 0.039 (0.315)	DT 0.001 (0.275)	loss 8.557 (8.599)	prob 3.710 (3.148)	GS 31.078 (31.478)	mem 77.197
Train: [3][870/1500]	BT 0.035 (0.311)	DT 0.001 (0.272)	loss 8.948 (8.579)	prob 2.256 (3.072)	GS 37.047 (32.201)	mem 77.205
Train: [3][880/1500]	BT 0.028 (0.315)	DT 0.001 (0.275)	loss 8.888 (8.599)	prob 2.162 (2.847)	GS 35.531 (32.865)	mem 77.373
Train: [3][890/1500]	BT 0.029 (0.312)	DT 0.000 (0.272)	loss 8.374 (8.575)	prob 3.517 (2.847)	GS 34.359 (32.897)	mem 77.387
Train: [3][900/1500]	BT 0.027 (0.308)	DT 0.000 (0.269)	loss 8.723 (8.562)	prob 2.635 (2.891)	GS 32.094 (32.673)	mem 77.397
Train: [3][910/1500]	BT 0.037 (0.310)	DT 0.001 (0.271)	loss 8.453 (8.476)	prob 2.868 (2.886)	GS 28.125 (32.567)	mem 77.230
Train: [3][920/1500]	BT 0.039 (0.307)	DT 0.001 (0.268)	loss 8.816 (8.508)	prob 2.385 (2.877)	GS 35.312 (33.380)	mem 76.545
Train: [3][930/1500]	BT 0.043 (0.310)	DT 0.001 (0.271)	loss 8.327 (8.460)	prob 3.331 (2.950)	GS 32.625 (32.655)	mem 76.575
Train: [3][940/1500]	BT 0.042 (0.307)	DT 0.001 (0.268)	loss 8.640 (8.483)	prob 3.123 (2.993)	GS 34.141 (32.465)	mem 76.579
Train: [3][950/1500]	BT 0.030 (0.304)	DT 0.000 (0.265)	loss 8.661 (8.480)	prob 3.099 (2.982)	GS 32.391 (32.597)	mem 76.584
Train: [3][960/1500]	BT 0.032 (0.306)	DT 0.001 (0.267)	loss 8.317 (8.410)	prob 2.788 (3.008)	GS 30.250 (32.683)	mem 76.622
Train: [3][970/1500]	BT 0.054 (0.303)	DT 0.006 (0.264)	loss 8.657 (8.425)	prob 2.530 (2.952)	GS 36.203 (33.193)	mem 76.623
Train: [3][980/1500]	BT 0.071 (0.305)	DT 0.011 (0.266)	loss 8.569 (8.423)	prob 3.017 (2.922)	GS 35.547 (33.156)	mem 76.632
Train: [3][990/1500]	BT 0.040 (0.303)	DT 0.001 (0.264)	loss 8.505 (8.417)	prob 3.333 (2.959)	GS 28.844 (33.025)	mem 76.636
Train: [3][1000/1500]	BT 0.062 (0.307)	DT 0.017 (0.267)	loss 8.497 (8.421)	prob 2.629 (2.965)	GS 36.734 (33.005)	mem 76.741
Train: [3][1010/1500]	BT 0.040 (0.307)	DT 0.001 (0.268)	loss 8.488 (8.359)	prob 2.800 (3.056)	GS 33.156 (33.312)	mem 76.833
Train: [3][1020/1500]	BT 0.030 (0.304)	DT 0.000 (0.265)	loss 8.996 (8.336)	prob 2.717 (3.176)	GS 35.047 (32.063)	mem 76.845
Train: [3][1030/1500]	BT 0.041 (0.305)	DT 0.001 (0.266)	loss 7.927 (8.319)	prob 3.168 (3.171)	GS 27.078 (31.776)	mem 76.907
Train: [3][1040/1500]	BT 0.037 (0.302)	DT 0.001 (0.263)	loss 8.515 (8.350)	prob 2.875 (3.172)	GS 36.156 (31.938)	mem 76.914
Train: [3][1050/1500]	BT 0.039 (0.303)	DT 0.001 (0.263)	loss 8.296 (8.339)	prob 2.600 (3.127)	GS 33.141 (32.085)	mem 76.988
Train: [3][1060/1500]	BT 0.041 (0.301)	DT 0.001 (0.262)	loss 8.090 (8.248)	prob 2.952 (2.972)	GS 36.125 (33.011)	mem 77.019
Train: [3][1070/1500]	BT 0.039 (0.299)	DT 0.001 (0.260)	loss 8.235 (8.242)	prob 3.530 (2.980)	GS 31.703 (32.330)	mem 77.027
Train: [3][1080/1500]	BT 0.040 (0.301)	DT 0.001 (0.262)	loss 8.221 (8.290)	prob 3.010 (2.988)	GS 30.141 (32.535)	mem 77.127
Train: [3][1090/1500]	BT 0.038 (0.299)	DT 0.001 (0.259)	loss 8.103 (8.233)	prob 3.486 (3.060)	GS 34.000 (32.436)	mem 77.125
Train: [3][1100/1500]	BT 0.039 (0.299)	DT 0.001 (0.260)	loss 8.371 (8.237)	prob 2.767 (3.034)	GS 32.109 (32.473)	mem 77.223
Train: [3][1110/1500]	BT 0.048 (0.302)	DT 0.006 (0.263)	loss 8.586 (8.421)	prob 2.378 (3.047)	GS 33.000 (34.189)	mem 77.336
Train: [3][1120/1500]	BT 0.038 (0.300)	DT 0.001 (0.261)	loss 8.282 (8.346)	prob 2.836 (2.956)	GS 33.250 (33.934)	mem 77.342
Train: [3][1130/1500]	BT 0.077 (0.298)	DT 0.001 (0.259)	loss 8.170 (8.289)	prob 2.699 (3.053)	GS 30.375 (33.535)	mem 77.357
Train: [3][1140/1500]	BT 0.065 (0.300)	DT 0.011 (0.260)	loss 8.268 (8.246)	prob 3.416 (3.128)	GS 37.594 (33.171)	mem 77.422
Train: [3][1150/1500]	BT 0.033 (0.307)	DT 0.000 (0.267)	loss 8.988 (8.253)	prob 1.669 (3.023)	GS 42.172 (33.826)	mem 76.485
Train: [3][1160/1500]	BT 0.027 (0.304)	DT 0.000 (0.265)	loss 8.439 (8.178)	prob 2.621 (2.667)	GS 35.906 (33.583)	mem 76.493
Train: [3][1170/1500]	BT 0.039 (0.305)	DT 0.001 (0.266)	loss 8.029 (8.128)	prob 3.171 (2.945)	GS 31.797 (32.674)	mem 76.563
Train: [3][1180/1500]	BT 0.027 (0.303)	DT 0.000 (0.264)	loss 7.640 (8.139)	prob 3.913 (2.906)	GS 32.453 (33.073)	mem 76.569
Train: [3][1190/1500]	BT 0.038 (0.301)	DT 0.001 (0.262)	loss 8.146 (8.131)	prob 2.888 (2.975)	GS 33.938 (33.050)	mem 76.575
Train: [3][1200/1500]	BT 0.037 (0.302)	DT 0.001 (0.263)	loss 8.156 (8.136)	prob 3.360 (2.981)	GS 34.906 (33.037)	mem 76.705
Train: [3][1210/1500]	BT 0.038 (0.300)	DT 0.001 (0.261)	loss 8.007 (8.193)	prob 3.137 (2.804)	GS 35.281 (34.052)	mem 76.718
Train: [3][1220/1500]	BT 0.047 (0.302)	DT 0.000 (0.263)	loss 8.407 (8.166)	prob 2.641 (2.866)	GS 36.453 (33.862)	mem 76.822
Train: [3][1230/1500]	BT 0.040 (0.300)	DT 0.001 (0.261)	loss 8.627 (8.145)	prob 2.564 (2.924)	GS 36.125 (33.760)	mem 76.831
Train: [3][1240/1500]	BT 0.050 (0.305)	DT 0.007 (0.266)	loss 8.237 (8.141)	prob 2.939 (2.956)	GS 36.016 (33.548)	mem 76.943
Train: [3][1250/1500]	BT 0.031 (0.303)	DT 0.000 (0.264)	loss 8.058 (8.126)	prob 3.409 (2.884)	GS 34.266 (33.520)	mem 76.948
Train: [3][1260/1500]	BT 0.038 (0.302)	DT 0.001 (0.263)	loss 8.418 (8.104)	prob 2.763 (2.968)	GS 36.094 (33.441)	mem 77.010
Train: [3][1270/1500]	BT 0.029 (0.303)	DT 0.000 (0.264)	loss 7.843 (8.026)	prob 2.799 (3.122)	GS 32.719 (32.691)	mem 77.079
Train: [3][1280/1500]	BT 0.029 (0.301)	DT 0.000 (0.262)	loss 7.896 (8.030)	prob 2.933 (3.116)	GS 35.594 (33.064)	mem 77.095
Train: [3][1290/1500]	BT 0.028 (0.303)	DT 0.001 (0.264)	loss 7.822 (8.033)	prob 2.981 (3.097)	GS 32.531 (33.223)	mem 77.232
Train: [3][1300/1500]	BT 0.061 (0.301)	DT 0.002 (0.262)	loss 8.098 (8.019)	prob 3.140 (3.124)	GS 34.516 (32.966)	mem 77.242
Train: [3][1310/1500]	BT 0.035 (0.299)	DT 0.001 (0.260)	loss 7.955 (7.944)	prob 3.202 (3.171)	GS 34.141 (31.931)	mem 77.252
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [3][1320/1500]	BT 0.038 (0.304)	DT 0.001 (0.265)	loss 8.017 (7.939)	prob 3.333 (3.301)	GS 34.094 (31.946)	mem 77.385
Train: [3][1330/1500]	BT 0.039 (0.304)	DT 0.001 (0.265)	loss 7.998 (7.958)	prob 2.647 (3.225)	GS 33.141 (32.384)	mem 76.463
Train: [3][1340/1500]	BT 0.029 (0.304)	DT 0.000 (0.265)	loss 7.990 (7.973)	prob 3.297 (3.194)	GS 31.719 (32.223)	mem 76.498
Train: [3][1350/1500]	BT 0.031 (0.305)	DT 0.000 (0.266)	loss 7.878 (7.963)	prob 3.098 (3.190)	GS 37.625 (32.959)	mem 76.563
Train: [3][1360/1500]	BT 0.039 (0.303)	DT 0.001 (0.264)	loss 8.184 (8.007)	prob 3.303 (2.903)	GS 33.688 (32.802)	mem 76.573
Train: [3][1370/1500]	BT 0.040 (0.303)	DT 0.001 (0.264)	loss 7.910 (7.986)	prob 3.269 (2.884)	GS 30.109 (33.173)	mem 76.599
Train: [3][1380/1500]	BT 0.040 (0.301)	DT 0.001 (0.263)	loss 7.942 (7.988)	prob 3.269 (2.989)	GS 31.734 (32.832)	mem 76.605
Train: [3][1390/1500]	BT 0.040 (0.301)	DT 0.004 (0.262)	loss 8.286 (7.983)	prob 3.413 (2.976)	GS 34.594 (33.000)	mem 76.683
Train: [3][1400/1500]	BT 0.064 (0.300)	DT 0.000 (0.261)	loss 8.354 (7.966)	prob 3.091 (2.971)	GS 31.781 (33.048)	mem 76.701
Train: [3][1410/1500]	BT 0.038 (0.302)	DT 0.000 (0.263)	loss 8.181 (7.902)	prob 2.744 (3.157)	GS 36.484 (32.325)	mem 76.804
Train: [3][1420/1500]	BT 0.072 (0.301)	DT 0.001 (0.262)	loss 8.194 (7.931)	prob 2.657 (3.087)	GS 38.703 (32.436)	mem 76.790
Train: [3][1430/1500]	BT 0.039 (0.300)	DT 0.001 (0.260)	loss 8.063 (7.879)	prob 3.561 (3.191)	GS 31.594 (31.989)	mem 76.805
Train: [3][1440/1500]	BT 0.035 (0.300)	DT 0.001 (0.261)	loss 7.761 (7.864)	prob 3.103 (3.205)	GS 29.266 (31.865)	mem 76.873
Train: [3][1450/1500]	BT 0.051 (0.304)	DT 0.001 (0.265)	loss 8.099 (7.879)	prob 2.935 (3.240)	GS 34.375 (32.148)	mem 76.989
Train: [3][1460/1500]	BT 0.036 (0.302)	DT 0.001 (0.263)	loss 7.712 (7.729)	prob 3.155 (3.343)	GS 34.344 (31.272)	mem 77.025
Train: [3][1470/1500]	BT 0.036 (0.305)	DT 0.001 (0.265)	loss 8.346 (7.790)	prob 2.624 (3.244)	GS 33.156 (31.768)	mem 63.159
Train: [3][1480/1500]	BT 0.024 (0.304)	DT 0.000 (0.264)	loss 8.167 (7.808)	prob 3.110 (3.134)	GS 34.125 (32.505)	mem 25.228
Train: [3][1490/1500]	BT 0.023 (0.302)	DT 0.000 (0.262)	loss 7.508 (7.807)	prob 3.695 (3.126)	GS 30.625 (32.637)	mem 25.247
Train: [3][1500/1500]	BT 0.033 (0.300)	DT 0.000 (0.261)	loss 7.732 (7.808)	prob 3.277 (3.149)	GS 35.812 (32.618)	mem 17.769
Train: [3][1510/1500]	BT 0.030 (0.299)	DT 0.001 (0.260)	loss 7.486 (7.636)	prob 3.850 (3.240)	GS 37.312 (32.391)	mem 14.949
epoch 3, total time 451.21
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [4][1/1500]	BT 18.491 (18.491)	DT 18.433 (18.433)	loss 7.832 (7.832)	prob 2.864 (2.864)	GS 36.547 (36.547)	mem 74.551
Train: [4][10/1500]	BT 0.032 (2.776)	DT 0.000 (2.740)	loss 7.558 (7.639)	prob 3.330 (2.942)	GS 35.438 (33.859)	mem 75.271
Train: [4][20/1500]	BT 0.025 (1.401)	DT 0.000 (1.370)	loss 7.791 (7.627)	prob 3.059 (3.075)	GS 35.609 (33.095)	mem 75.282
Train: [4][30/1500]	BT 0.039 (1.098)	DT 0.000 (1.064)	loss 7.540 (7.628)	prob 3.094 (3.063)	GS 36.672 (33.039)	mem 75.447
Train: [4][40/1500]	BT 0.038 (0.833)	DT 0.000 (0.798)	loss 7.607 (7.598)	prob 3.683 (3.148)	GS 33.844 (32.653)	mem 75.452
Train: [4][50/1500]	BT 7.684 (0.828)	DT 7.630 (0.791)	loss 7.775 (7.620)	prob 2.681 (3.095)	GS 35.250 (32.686)	mem 75.533
Train: [4][60/1500]	BT 0.092 (0.798)	DT 0.019 (0.759)	loss 7.787 (7.666)	prob 3.264 (3.004)	GS 41.172 (33.347)	mem 75.695
Train: [4][70/1500]	BT 0.094 (0.693)	DT 0.002 (0.652)	loss 7.760 (7.627)	prob 3.188 (3.140)	GS 33.125 (32.881)	mem 75.722
Train: [4][80/1500]	BT 0.028 (0.850)	DT 0.000 (0.810)	loss 7.851 (7.672)	prob 2.663 (3.032)	GS 31.781 (32.870)	mem 75.997
Train: [4][90/1500]	BT 0.031 (0.759)	DT 0.000 (0.720)	loss 7.388 (7.647)	prob 3.434 (3.087)	GS 31.812 (32.575)	mem 76.007
Train: [4][100/1500]	BT 0.040 (0.713)	DT 0.001 (0.674)	loss 7.782 (7.642)	prob 3.528 (3.132)	GS 34.484 (32.422)	mem 76.111
Train: [4][110/1500]	BT 0.067 (0.652)	DT 0.003 (0.613)	loss 7.543 (7.673)	prob 3.700 (3.257)	GS 36.266 (33.695)	mem 76.121
Train: [4][120/1500]	BT 0.038 (0.655)	DT 0.000 (0.616)	loss 7.991 (7.689)	prob 2.885 (3.213)	GS 38.422 (33.509)	mem 75.298
Train: [4][130/1500]	BT 0.038 (0.608)	DT 0.001 (0.568)	loss 8.316 (7.672)	prob 2.551 (3.152)	GS 32.969 (33.498)	mem 75.299
Train: [4][140/1500]	BT 0.038 (0.567)	DT 0.001 (0.528)	loss 7.850 (7.658)	prob 3.026 (3.126)	GS 34.578 (33.183)	mem 75.299
Train: [4][150/1500]	BT 0.039 (0.559)	DT 0.001 (0.521)	loss 7.603 (7.637)	prob 2.626 (3.101)	GS 36.828 (33.127)	mem 75.335
Train: [4][160/1500]	BT 0.061 (0.527)	DT 0.017 (0.488)	loss 7.613 (7.615)	prob 3.020 (2.644)	GS 35.406 (33.973)	mem 75.345
Train: [4][170/1500]	BT 0.086 (0.529)	DT 0.024 (0.490)	loss 7.652 (7.587)	prob 3.043 (2.764)	GS 33.359 (33.622)	mem 75.419
Train: [4][180/1500]	BT 0.054 (0.502)	DT 0.011 (0.463)	loss 7.688 (7.571)	prob 3.093 (2.932)	GS 34.703 (33.061)	mem 75.422
Train: [4][190/1500]	BT 0.038 (0.505)	DT 0.001 (0.467)	loss 7.460 (7.578)	prob 2.894 (2.947)	GS 33.969 (33.445)	mem 75.510
Train: [4][200/1500]	BT 0.038 (0.482)	DT 0.001 (0.443)	loss 7.684 (7.571)	prob 2.944 (2.986)	GS 33.750 (33.423)	mem 75.521
Train: [4][210/1500]	BT 0.038 (0.481)	DT 0.001 (0.442)	loss 7.644 (7.519)	prob 3.121 (3.278)	GS 36.141 (33.125)	mem 75.678
Train: [4][220/1500]	BT 0.029 (0.462)	DT 0.000 (0.423)	loss 7.854 (7.486)	prob 2.948 (3.121)	GS 34.156 (33.920)	mem 75.700
Train: [4][230/1500]	BT 0.038 (0.443)	DT 0.000 (0.405)	loss 7.244 (7.488)	prob 3.703 (3.143)	GS 31.797 (33.343)	mem 75.713
Train: [4][240/1500]	BT 0.038 (0.445)	DT 0.001 (0.406)	loss 7.409 (7.526)	prob 3.393 (3.063)	GS 32.422 (33.559)	mem 75.811
Train: [4][250/1500]	BT 0.055 (0.432)	DT 0.001 (0.393)	loss 7.433 (7.514)	prob 3.384 (3.053)	GS 32.781 (33.654)	mem 75.826
Train: [4][260/1500]	BT 0.048 (0.433)	DT 0.003 (0.394)	loss 7.777 (7.511)	prob 2.998 (3.240)	GS 35.500 (32.761)	mem 75.931
Train: [4][270/1500]	BT 0.039 (0.425)	DT 0.001 (0.385)	loss 7.479 (7.516)	prob 3.535 (3.292)	GS 35.172 (32.754)	mem 75.982
Train: [4][280/1500]	BT 0.031 (0.422)	DT 0.000 (0.383)	loss 7.794 (7.508)	prob 2.787 (3.234)	GS 33.766 (32.810)	mem 76.082
Train: [4][290/1500]	BT 0.053 (0.409)	DT 0.001 (0.369)	loss 7.254 (7.502)	prob 3.228 (3.179)	GS 30.906 (32.728)	mem 76.139
Train: [4][300/1500]	BT 0.024 (0.436)	DT 0.000 (0.397)	loss 7.443 (7.490)	prob 3.291 (3.188)	GS 31.875 (33.272)	mem 76.493
Train: [4][310/1500]	BT 0.039 (0.423)	DT 0.001 (0.384)	loss 7.318 (7.364)	prob 3.197 (3.138)	GS 33.438 (32.422)	mem 76.606
Train: [4][320/1500]	BT 0.040 (0.421)	DT 0.001 (0.382)	loss 7.144 (7.390)	prob 3.296 (3.255)	GS 34.719 (32.422)	mem 76.134
Train: [4][330/1500]	BT 0.067 (0.410)	DT 0.009 (0.371)	loss 7.587 (7.386)	prob 3.009 (3.225)	GS 36.859 (32.523)	mem 76.282
Train: [4][340/1500]	BT 0.067 (0.400)	DT 0.015 (0.360)	loss 7.414 (7.392)	prob 2.971 (3.205)	GS 33.203 (32.502)	mem 76.330
Train: [4][350/1500]	BT 0.054 (0.405)	DT 0.006 (0.364)	loss 7.522 (7.393)	prob 2.611 (3.181)	GS 34.516 (32.369)	mem 76.560
Train: [4][360/1500]	BT 0.045 (0.396)	DT 0.012 (0.356)	loss 7.410 (7.332)	prob 3.063 (3.108)	GS 28.344 (31.728)	mem 76.568
Train: [4][370/1500]	BT 0.030 (0.416)	DT 0.000 (0.375)	loss 7.230 (7.344)	prob 2.620 (3.043)	GS 33.953 (33.470)	mem 76.716
Train: [4][380/1500]	BT 0.040 (0.406)	DT 0.001 (0.365)	loss 7.545 (7.375)	prob 2.947 (2.985)	GS 30.094 (32.990)	mem 76.724
Train: [4][390/1500]	BT 0.033 (0.413)	DT 0.002 (0.373)	loss 7.103 (7.367)	prob 3.502 (3.075)	GS 32.875 (32.756)	mem 76.871
Train: [4][400/1500]	BT 0.031 (0.404)	DT 0.000 (0.364)	loss 7.329 (7.366)	prob 2.752 (3.030)	GS 31.875 (32.944)	mem 76.877
Train: [4][410/1500]	BT 0.057 (0.395)	DT 0.000 (0.355)	loss 7.276 (7.317)	prob 2.784 (2.820)	GS 36.312 (32.933)	mem 76.886
Train: [4][420/1500]	BT 0.030 (0.429)	DT 0.000 (0.389)	loss 7.541 (7.336)	prob 2.655 (2.955)	GS 39.109 (33.141)	mem 77.241
Train: [4][430/1500]	BT 0.034 (0.420)	DT 0.000 (0.380)	loss 7.454 (7.325)	prob 3.050 (3.042)	GS 33.312 (32.651)	mem 77.251
Train: [4][440/1500]	BT 0.090 (0.421)	DT 0.005 (0.382)	loss 7.174 (7.317)	prob 2.915 (3.044)	GS 36.203 (32.550)	mem 77.420
Train: [4][450/1500]	BT 0.033 (0.413)	DT 0.000 (0.373)	loss 7.466 (7.319)	prob 3.005 (3.023)	GS 35.328 (32.554)	mem 77.433
Train: [4][460/1500]	BT 4.817 (0.416)	DT 4.748 (0.375)	loss 7.473 (7.333)	prob 2.783 (2.959)	GS 32.672 (32.072)	mem 77.480
Train: [4][470/1500]	BT 0.036 (0.409)	DT 0.000 (0.368)	loss 7.502 (7.307)	prob 3.001 (3.068)	GS 29.688 (31.958)	mem 77.492
Train: [4][480/1500]	BT 0.031 (0.416)	DT 0.000 (0.375)	loss 7.376 (7.315)	prob 3.199 (2.996)	GS 28.922 (32.532)	mem 76.593
Train: [4][490/1500]	BT 0.027 (0.408)	DT 0.000 (0.367)	loss 7.326 (7.290)	prob 2.793 (3.010)	GS 35.922 (32.405)	mem 76.599
Train: [4][500/1500]	BT 0.072 (0.408)	DT 0.004 (0.367)	loss 7.001 (7.267)	prob 3.621 (3.050)	GS 32.453 (32.161)	mem 76.628
Train: [4][510/1500]	BT 0.076 (0.401)	DT 0.011 (0.360)	loss 7.302 (7.275)	prob 2.782 (2.962)	GS 32.094 (31.677)	mem 76.632
Train: [4][520/1500]	BT 0.075 (0.395)	DT 0.001 (0.353)	loss 7.171 (7.256)	prob 3.397 (2.892)	GS 33.906 (31.956)	mem 76.635
Train: [4][530/1500]	BT 0.038 (0.400)	DT 0.001 (0.358)	loss 7.258 (7.240)	prob 3.552 (2.875)	GS 29.312 (32.255)	mem 76.749
Train: [4][540/1500]	BT 0.060 (0.394)	DT 0.001 (0.352)	loss 7.157 (7.249)	prob 2.572 (2.806)	GS 35.469 (32.487)	mem 76.758
Train: [4][550/1500]	BT 0.039 (0.392)	DT 0.001 (0.349)	loss 7.136 (7.252)	prob 3.823 (2.795)	GS 35.109 (32.628)	mem 76.817
Train: [4][560/1500]	BT 0.038 (0.391)	DT 0.001 (0.348)	loss 7.712 (7.244)	prob 2.210 (2.591)	GS 34.484 (33.170)	mem 76.905
Train: [4][570/1500]	BT 0.038 (0.384)	DT 0.001 (0.342)	loss 7.301 (7.232)	prob 2.526 (2.561)	GS 36.609 (33.813)	mem 76.909
Train: [4][580/1500]	BT 0.066 (0.388)	DT 0.016 (0.346)	loss 6.982 (7.217)	prob 2.752 (2.598)	GS 32.453 (33.060)	mem 76.999
Train: [4][590/1500]	BT 0.039 (0.386)	DT 0.001 (0.344)	loss 7.286 (7.224)	prob 3.125 (2.669)	GS 31.500 (32.913)	mem 77.045
Train: [4][600/1500]	BT 0.028 (0.383)	DT 0.000 (0.341)	loss 7.385 (7.227)	prob 2.387 (2.667)	GS 35.094 (33.119)	mem 76.973
Train: [4][610/1500]	BT 0.038 (0.379)	DT 0.001 (0.337)	loss 6.906 (7.136)	prob 3.000 (2.598)	GS 29.703 (32.336)	mem 77.019
Train: [4][620/1500]	BT 0.039 (0.376)	DT 0.001 (0.334)	loss 7.120 (7.150)	prob 3.159 (2.682)	GS 33.516 (32.646)	mem 77.087
Train: [4][630/1500]	BT 0.040 (0.374)	DT 0.001 (0.332)	loss 7.390 (7.162)	prob 2.554 (2.636)	GS 33.797 (32.861)	mem 77.188
Train: [4][640/1500]	BT 0.039 (0.372)	DT 0.001 (0.330)	loss 7.173 (7.149)	prob 2.962 (2.674)	GS 33.625 (32.858)	mem 77.283
Train: [4][650/1500]	BT 0.037 (0.371)	DT 0.000 (0.329)	loss 7.257 (7.148)	prob 2.308 (2.649)	GS 38.312 (32.866)	mem 77.346
Train: [4][660/1500]	BT 0.037 (0.366)	DT 0.000 (0.324)	loss 7.079 (7.102)	prob 2.240 (2.361)	GS 33.469 (32.173)	mem 77.351
Train: [4][670/1500]	BT 0.771 (0.363)	DT 0.733 (0.322)	loss 7.304 (7.119)	prob 2.127 (2.403)	GS 37.859 (33.483)	mem 77.402
Train: [4][680/1500]	BT 0.073 (0.365)	DT 0.006 (0.323)	loss 7.109 (7.113)	prob 3.021 (2.556)	GS 28.219 (32.831)	mem 76.542
Train: [4][690/1500]	BT 0.063 (0.361)	DT 0.014 (0.319)	loss 7.289 (7.112)	prob 2.447 (2.584)	GS 31.047 (32.847)	mem 76.551
Train: [4][700/1500]	BT 0.030 (0.369)	DT 0.000 (0.327)	loss 7.246 (7.111)	prob 2.523 (2.612)	GS 35.484 (32.852)	mem 76.628
Train: [4][710/1500]	BT 0.039 (0.365)	DT 0.001 (0.323)	loss 7.133 (7.042)	prob 3.168 (2.717)	GS 33.250 (31.511)	mem 76.610
Train: [4][720/1500]	BT 0.039 (0.364)	DT 0.001 (0.322)	loss 6.777 (7.058)	prob 3.101 (2.603)	GS 30.641 (31.971)	mem 76.660
Train: [4][730/1500]	BT 0.040 (0.360)	DT 0.001 (0.318)	loss 7.067 (7.050)	prob 2.453 (2.623)	GS 36.094 (32.526)	mem 76.665
Train: [4][740/1500]	BT 0.039 (0.355)	DT 0.001 (0.313)	loss 7.486 (7.044)	prob 2.546 (2.633)	GS 33.984 (32.162)	mem 76.673
Train: [4][750/1500]	BT 0.039 (0.356)	DT 0.001 (0.314)	loss 7.113 (7.032)	prob 2.525 (2.631)	GS 31.688 (32.193)	mem 76.730
Train: [4][760/1500]	BT 0.039 (0.351)	DT 0.001 (0.309)	loss 7.182 (7.056)	prob 1.788 (2.337)	GS 32.141 (32.841)	mem 76.743
Train: [4][770/1500]	BT 0.039 (0.352)	DT 0.001 (0.311)	loss 7.170 (7.047)	prob 2.860 (2.504)	GS 33.078 (32.262)	mem 76.848
Train: [4][780/1500]	BT 0.042 (0.349)	DT 0.001 (0.307)	loss 7.241 (7.052)	prob 2.284 (2.559)	GS 33.484 (32.163)	mem 76.859
Train: [4][790/1500]	BT 0.076 (0.345)	DT 0.015 (0.303)	loss 6.874 (7.053)	prob 2.471 (2.523)	GS 32.703 (32.209)	mem 76.867
Train: [4][800/1500]	BT 0.032 (0.364)	DT 0.001 (0.322)	loss 6.952 (7.038)	prob 2.831 (2.524)	GS 34.688 (32.164)	mem 77.093
Train: [4][810/1500]	BT 0.049 (0.360)	DT 0.001 (0.318)	loss 7.185 (7.028)	prob 2.446 (2.338)	GS 31.297 (33.802)	mem 77.107
Train: [4][820/1500]	BT 0.035 (0.356)	DT 0.000 (0.314)	loss 6.970 (7.027)	prob 2.560 (2.336)	GS 31.031 (33.060)	mem 77.116
Train: [4][830/1500]	BT 0.040 (0.361)	DT 0.001 (0.319)	loss 6.883 (7.021)	prob 2.926 (2.421)	GS 30.016 (32.559)	mem 77.226
Train: [4][840/1500]	BT 0.041 (0.357)	DT 0.001 (0.315)	loss 6.970 (7.002)	prob 2.873 (2.430)	GS 36.438 (32.421)	mem 77.240
Train: [4][850/1500]	BT 0.061 (0.361)	DT 0.004 (0.319)	loss 6.867 (6.988)	prob 2.306 (2.415)	GS 37.078 (32.902)	mem 77.443
Train: [4][860/1500]	BT 0.062 (0.357)	DT 0.009 (0.315)	loss 6.837 (6.895)	prob 2.237 (2.332)	GS 36.766 (33.153)	mem 77.455
Train: [4][870/1500]	BT 0.082 (0.354)	DT 0.001 (0.311)	loss 6.838 (6.929)	prob 2.647 (2.357)	GS 33.750 (32.705)	mem 77.466
Train: [4][880/1500]	BT 0.033 (0.359)	DT 0.000 (0.316)	loss 6.910 (6.923)	prob 2.809 (2.386)	GS 35.125 (33.281)	mem 76.631
Train: [4][890/1500]	BT 0.041 (0.355)	DT 0.001 (0.313)	loss 6.940 (6.926)	prob 1.125 (2.364)	GS 35.359 (33.634)	mem 76.634
Train: [4][900/1500]	BT 0.031 (0.357)	DT 0.001 (0.314)	loss 6.850 (6.931)	prob 2.604 (2.363)	GS 33.625 (33.526)	mem 76.718
Train: [4][910/1500]	BT 0.040 (0.353)	DT 0.001 (0.311)	loss 6.955 (6.867)	prob 3.446 (2.615)	GS 34.953 (33.903)	mem 76.724
Train: [4][920/1500]	BT 0.031 (0.354)	DT 0.000 (0.311)	loss 6.961 (6.896)	prob 2.347 (2.554)	GS 37.516 (33.053)	mem 76.775
Train: [4][930/1500]	BT 0.040 (0.350)	DT 0.000 (0.308)	loss 7.024 (6.884)	prob 2.640 (2.511)	GS 35.641 (33.345)	mem 76.778
Train: [4][940/1500]	BT 0.038 (0.347)	DT 0.001 (0.305)	loss 6.850 (6.885)	prob 2.315 (2.495)	GS 32.750 (32.875)	mem 76.782
Train: [4][950/1500]	BT 0.030 (0.350)	DT 0.000 (0.308)	loss 6.838 (6.888)	prob 2.636 (2.440)	GS 34.453 (32.693)	mem 76.917
Train: [4][960/1500]	BT 0.029 (0.346)	DT 0.000 (0.304)	loss 6.975 (6.928)	prob 2.385 (2.557)	GS 34.453 (32.564)	mem 76.928
Train: [4][970/1500]	BT 0.059 (0.348)	DT 0.014 (0.306)	loss 6.791 (6.878)	prob 2.520 (2.386)	GS 31.141 (32.070)	mem 77.048
Train: [4][980/1500]	BT 0.033 (0.345)	DT 0.001 (0.303)	loss 6.883 (6.871)	prob 1.867 (2.277)	GS 33.844 (32.319)	mem 77.055
Train: [4][990/1500]	BT 0.079 (0.342)	DT 0.022 (0.300)	loss 6.945 (6.865)	prob 1.917 (2.204)	GS 34.516 (32.269)	mem 77.064
Train: [4][1000/1500]	BT 0.060 (0.347)	DT 0.016 (0.305)	loss 7.013 (6.868)	prob 2.375 (2.164)	GS 37.797 (32.375)	mem 77.163
Train: [4][1010/1500]	BT 0.025 (0.356)	DT 0.000 (0.314)	loss 6.759 (6.800)	prob 1.588 (2.213)	GS 36.359 (33.461)	mem 77.262
Train: [4][1020/1500]	BT 0.030 (0.353)	DT 0.000 (0.311)	loss 6.892 (6.816)	prob 2.739 (2.305)	GS 31.219 (32.153)	mem 77.273
Train: [4][1030/1500]	BT 0.037 (0.349)	DT 0.000 (0.308)	loss 6.616 (6.806)	prob 2.175 (2.288)	GS 30.641 (31.870)	mem 77.284
Train: [4][1040/1500]	BT 0.031 (0.349)	DT 0.001 (0.308)	loss 7.005 (6.812)	prob 2.378 (2.214)	GS 33.812 (32.283)	mem 77.383
Train: [4][1050/1500]	BT 0.038 (0.347)	DT 0.001 (0.305)	loss 6.851 (6.821)	prob 2.577 (2.253)	GS 34.281 (32.256)	mem 77.391
Train: [4][1060/1500]	BT 0.060 (0.350)	DT 0.003 (0.309)	loss 6.893 (6.851)	prob 2.302 (2.088)	GS 29.578 (31.741)	mem 77.457
Train: [4][1070/1500]	BT 0.064 (0.348)	DT 0.003 (0.306)	loss 6.818 (6.829)	prob 2.291 (2.036)	GS 32.875 (31.853)	mem 77.466
Train: [4][1080/1500]	BT 0.058 (0.345)	DT 0.011 (0.303)	loss 6.760 (6.814)	prob 2.160 (2.024)	GS 31.641 (32.001)	mem 77.474
Train: [4][1090/1500]	BT 0.030 (0.357)	DT 0.000 (0.315)	loss 6.821 (6.802)	prob 1.565 (2.055)	GS 29.438 (32.070)	mem 76.611
Train: [4][1100/1500]	BT 0.036 (0.354)	DT 0.000 (0.312)	loss 6.945 (6.796)	prob 1.888 (2.065)	GS 33.625 (32.042)	mem 76.616
Train: [4][1110/1500]	BT 0.060 (0.356)	DT 0.011 (0.314)	loss 7.000 (6.800)	prob 1.686 (2.108)	GS 35.969 (32.966)	mem 76.671
Train: [4][1120/1500]	BT 0.060 (0.353)	DT 0.011 (0.311)	loss 6.824 (6.776)	prob 1.806 (2.073)	GS 33.219 (32.580)	mem 76.680
Train: [4][1130/1500]	BT 0.067 (0.355)	DT 0.016 (0.313)	loss 6.765 (6.775)	prob 2.342 (2.035)	GS 35.156 (33.291)	mem 76.740
Train: [4][1140/1500]	BT 0.042 (0.354)	DT 0.001 (0.313)	loss 6.649 (6.769)	prob 2.545 (2.058)	GS 30.172 (33.135)	mem 76.818
Train: [4][1150/1500]	BT 0.042 (0.352)	DT 0.001 (0.310)	loss 6.665 (6.759)	prob 2.359 (2.093)	GS 32.188 (33.007)	mem 76.834
Train: [4][1160/1500]	BT 0.030 (0.356)	DT 0.000 (0.314)	loss 6.785 (6.721)	prob 2.799 (2.324)	GS 33.938 (32.567)	mem 77.077
Train: [4][1170/1500]	BT 0.026 (0.353)	DT 0.000 (0.311)	loss 6.783 (6.718)	prob 2.716 (2.337)	GS 38.500 (33.455)	mem 77.091
Train: [4][1180/1500]	BT 0.039 (0.353)	DT 0.000 (0.312)	loss 6.771 (6.730)	prob 1.964 (2.285)	GS 31.172 (33.108)	mem 77.240
Train: [4][1190/1500]	BT 0.038 (0.350)	DT 0.001 (0.309)	loss 6.825 (6.722)	prob 2.043 (2.214)	GS 33.922 (33.159)	mem 77.249
Train: [4][1200/1500]	BT 0.042 (0.348)	DT 0.001 (0.306)	loss 6.841 (6.716)	prob 1.885 (2.187)	GS 33.734 (33.124)	mem 77.263
Train: [4][1210/1500]	BT 0.039 (0.351)	DT 0.000 (0.309)	loss 6.941 (6.715)	prob 1.955 (2.092)	GS 41.109 (34.620)	mem 77.416
Train: [4][1220/1500]	BT 0.039 (0.348)	DT 0.001 (0.307)	loss 6.539 (6.692)	prob 2.759 (2.286)	GS 35.797 (34.440)	mem 77.432
Train: [4][1230/1500]	BT 0.060 (0.352)	DT 0.005 (0.310)	loss 6.575 (6.676)	prob 2.071 (2.297)	GS 36.188 (34.290)	mem 77.644
Train: [4][1240/1500]	BT 0.049 (0.350)	DT 0.001 (0.308)	loss 6.492 (6.659)	prob 2.247 (2.303)	GS 34.703 (33.618)	mem 77.670
Train: [4][1250/1500]	BT 0.060 (0.347)	DT 0.002 (0.306)	loss 6.651 (6.652)	prob 3.036 (2.356)	GS 30.078 (33.114)	mem 77.687
Train: [4][1260/1500]	BT 0.032 (0.360)	DT 0.001 (0.318)	loss 6.502 (6.653)	prob 2.554 (2.277)	GS 34.531 (32.083)	mem 76.899
Train: [4][1270/1500]	BT 0.030 (0.357)	DT 0.000 (0.315)	loss 6.688 (6.652)	prob 2.258 (2.354)	GS 35.859 (31.989)	mem 76.904
Train: [4][1280/1500]	BT 0.037 (0.355)	DT 0.001 (0.313)	loss 6.642 (6.660)	prob 2.243 (2.273)	GS 35.453 (32.328)	mem 76.908
Train: [4][1290/1500]	BT 0.039 (0.354)	DT 0.001 (0.312)	loss 6.536 (6.637)	prob 2.547 (2.279)	GS 34.156 (32.306)	mem 76.944
Train: [4][1300/1500]	BT 0.033 (0.352)	DT 0.000 (0.310)	loss 6.594 (6.634)	prob 2.401 (2.289)	GS 37.078 (32.314)	mem 76.923
Train: [4][1310/1500]	BT 0.066 (0.353)	DT 0.005 (0.311)	loss 6.466 (6.560)	prob 2.351 (2.389)	GS 31.062 (31.741)	mem 76.972
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [4][1320/1500]	BT 0.079 (0.351)	DT 0.010 (0.309)	loss 6.567 (6.567)	prob 2.308 (2.317)	GS 32.562 (31.514)	mem 76.962
Train: [4][1330/1500]	BT 0.034 (0.351)	DT 0.001 (0.309)	loss 6.575 (6.567)	prob 2.413 (2.354)	GS 31.375 (32.296)	mem 77.014
Train: [4][1340/1500]	BT 0.027 (0.365)	DT 0.000 (0.322)	loss 6.556 (6.566)	prob 2.485 (2.330)	GS 34.922 (32.450)	mem 77.473
Train: [4][1350/1500]	BT 0.030 (0.362)	DT 0.000 (0.320)	loss 6.523 (6.565)	prob 2.428 (2.309)	GS 37.109 (32.544)	mem 77.487
Train: [4][1360/1500]	BT 0.037 (0.360)	DT 0.001 (0.317)	loss 6.681 (6.621)	prob 2.556 (2.419)	GS 28.781 (32.269)	mem 77.497
Train: [4][1370/1500]	BT 0.033 (0.361)	DT 0.000 (0.318)	loss 6.671 (6.605)	prob 2.200 (2.394)	GS 33.953 (32.747)	mem 77.643
Train: [4][1380/1500]	BT 0.040 (0.358)	DT 0.001 (0.316)	loss 6.446 (6.597)	prob 2.354 (2.230)	GS 35.078 (32.978)	mem 77.658
Train: [4][1390/1500]	BT 0.032 (0.360)	DT 0.000 (0.318)	loss 6.497 (6.593)	prob 2.443 (2.253)	GS 34.531 (32.630)	mem 77.759
Train: [4][1400/1500]	BT 0.039 (0.358)	DT 0.001 (0.316)	loss 6.455 (6.573)	prob 2.371 (2.275)	GS 33.188 (32.605)	mem 77.773
Train: [4][1410/1500]	BT 0.056 (0.359)	DT 0.013 (0.317)	loss 6.458 (6.560)	prob 2.056 (1.976)	GS 33.781 (32.009)	mem 77.862
Train: [4][1420/1500]	BT 0.054 (0.357)	DT 0.006 (0.315)	loss 6.562 (6.565)	prob 1.605 (2.034)	GS 35.375 (33.155)	mem 77.875
Train: [4][1430/1500]	BT 0.047 (0.358)	DT 0.000 (0.316)	loss 6.420 (6.553)	prob 2.412 (2.039)	GS 32.781 (33.357)	mem 77.979
Train: [4][1440/1500]	BT 0.039 (0.356)	DT 0.001 (0.315)	loss 6.456 (6.546)	prob 1.753 (2.097)	GS 29.469 (32.903)	mem 77.081
Train: [4][1450/1500]	BT 0.040 (0.357)	DT 0.000 (0.315)	loss 6.619 (6.542)	prob 2.066 (2.201)	GS 32.297 (32.684)	mem 76.471
Train: [4][1460/1500]	BT 0.041 (0.355)	DT 0.001 (0.313)	loss 6.622 (6.552)	prob 2.194 (2.111)	GS 29.094 (31.741)	mem 76.502
Train: [4][1470/1500]	BT 0.041 (0.353)	DT 0.001 (0.311)	loss 6.567 (6.542)	prob 2.041 (2.156)	GS 32.828 (31.644)	mem 76.441
Train: [4][1480/1500]	BT 0.023 (0.354)	DT 0.000 (0.312)	loss 6.695 (6.547)	prob 2.046 (2.164)	GS 33.891 (32.060)	mem 17.230
Train: [4][1490/1500]	BT 0.020 (0.351)	DT 0.000 (0.310)	loss 6.390 (6.550)	prob 2.158 (2.170)	GS 34.469 (31.812)	mem 17.233
Train: [4][1500/1500]	BT 0.034 (0.350)	DT 0.000 (0.308)	loss 6.907 (6.546)	prob 1.198 (2.188)	GS 33.688 (31.692)	mem 11.640
Train: [4][1510/1500]	BT 0.028 (0.348)	DT 0.000 (0.306)	loss 6.233 (6.314)	prob 2.518 (2.262)	GS 33.938 (30.497)	mem 11.661
epoch 4, total time 525.18
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [5][1/1500]	BT 21.233 (21.233)	DT 21.178 (21.178)	loss 6.130 (6.130)	prob 2.439 (2.439)	GS 30.172 (30.172)	mem 75.826
Train: [5][10/1500]	BT 0.060 (2.257)	DT 0.018 (2.217)	loss 6.459 (6.331)	prob 2.327 (2.515)	GS 33.344 (31.851)	mem 75.890
Train: [5][20/1500]	BT 0.039 (1.171)	DT 0.001 (1.131)	loss 6.473 (6.368)	prob 2.265 (2.412)	GS 32.125 (31.581)	mem 75.954
Train: [5][30/1500]	BT 0.030 (0.893)	DT 0.000 (0.854)	loss 6.876 (6.432)	prob 1.450 (2.314)	GS 33.469 (31.287)	mem 76.074
Train: [5][40/1500]	BT 0.039 (0.717)	DT 0.001 (0.680)	loss 6.429 (6.457)	prob 1.961 (2.289)	GS 32.625 (31.374)	mem 76.126
Train: [5][50/1500]	BT 0.032 (0.666)	DT 0.000 (0.628)	loss 6.626 (6.487)	prob 2.076 (2.184)	GS 29.578 (31.423)	mem 76.187
Train: [5][60/1500]	BT 0.059 (0.569)	DT 0.004 (0.531)	loss 6.640 (6.622)	prob 1.953 (2.173)	GS 35.812 (33.566)	mem 76.205
Train: [5][70/1500]	BT 0.067 (0.532)	DT 0.009 (0.491)	loss 6.784 (6.689)	prob 2.035 (1.951)	GS 33.453 (32.750)	mem 76.248
Train: [5][80/1500]	BT 0.030 (0.643)	DT 0.000 (0.603)	loss 6.533 (6.716)	prob 2.794 (1.951)	GS 34.406 (33.148)	mem 75.331
Train: [5][90/1500]	BT 0.024 (0.575)	DT 0.000 (0.536)	loss 6.718 (6.682)	prob 2.612 (2.121)	GS 32.734 (33.228)	mem 75.339
Train: [5][100/1500]	BT 0.038 (0.548)	DT 0.001 (0.510)	loss 6.602 (6.668)	prob 2.326 (2.158)	GS 37.141 (33.166)	mem 75.402
Train: [5][110/1500]	BT 0.038 (0.503)	DT 0.001 (0.464)	loss 6.498 (6.612)	prob 2.953 (2.427)	GS 32.328 (32.452)	mem 75.411
Train: [5][120/1500]	BT 0.039 (0.464)	DT 0.001 (0.426)	loss 6.665 (6.590)	prob 2.072 (2.272)	GS 33.219 (31.869)	mem 75.417
Train: [5][130/1500]	BT 0.039 (0.469)	DT 0.001 (0.431)	loss 6.552 (6.596)	prob 1.939 (2.220)	GS 31.984 (32.274)	mem 75.544
Train: [5][140/1500]	BT 0.034 (0.438)	DT 0.000 (0.400)	loss 6.547 (6.592)	prob 2.832 (2.125)	GS 34.984 (32.225)	mem 75.422
Train: [5][150/1500]	BT 0.038 (0.427)	DT 0.001 (0.389)	loss 6.454 (6.592)	prob 2.156 (2.105)	GS 29.531 (32.259)	mem 75.535
Train: [5][160/1500]	BT 0.028 (0.428)	DT 0.000 (0.390)	loss 6.876 (6.632)	prob 1.059 (2.028)	GS 32.469 (33.828)	mem 75.633
Train: [5][170/1500]	BT 0.038 (0.406)	DT 0.001 (0.369)	loss 7.052 (6.615)	prob 1.814 (2.006)	GS 33.172 (33.236)	mem 75.655
Train: [5][180/1500]	BT 0.030 (0.430)	DT 0.000 (0.392)	loss 6.467 (6.613)	prob 1.945 (2.145)	GS 33.578 (32.984)	mem 75.885
Train: [5][190/1500]	BT 0.028 (0.409)	DT 0.000 (0.372)	loss 6.751 (6.608)	prob 3.141 (2.269)	GS 34.969 (32.801)	mem 75.899
Train: [5][200/1500]	BT 0.031 (0.390)	DT 0.000 (0.353)	loss 6.597 (6.612)	prob 2.337 (2.261)	GS 35.719 (32.715)	mem 75.907
Train: [5][210/1500]	BT 0.039 (0.391)	DT 0.001 (0.354)	loss 6.706 (6.739)	prob 1.809 (2.039)	GS 38.156 (32.336)	mem 76.056
Train: [5][220/1500]	BT 0.039 (0.375)	DT 0.001 (0.338)	loss 6.708 (6.747)	prob 2.240 (2.230)	GS 32.234 (32.576)	mem 76.078
Train: [5][230/1500]	BT 0.028 (0.380)	DT 0.000 (0.343)	loss 6.635 (6.713)	prob 1.438 (2.271)	GS 31.375 (32.698)	mem 76.121
Train: [5][240/1500]	BT 0.039 (0.366)	DT 0.001 (0.329)	loss 6.751 (6.739)	prob 2.109 (2.257)	GS 32.031 (32.556)	mem 76.132
Train: [5][250/1500]	BT 0.038 (0.369)	DT 0.001 (0.332)	loss 6.775 (6.746)	prob 1.974 (2.203)	GS 30.406 (32.428)	mem 75.441
Train: [5][260/1500]	BT 0.036 (0.356)	DT 0.001 (0.319)	loss 6.753 (6.793)	prob 2.300 (2.452)	GS 36.438 (32.317)	mem 75.496
Train: [5][270/1500]	BT 0.040 (0.344)	DT 0.001 (0.307)	loss 6.960 (6.799)	prob 2.531 (2.314)	GS 36.016 (32.779)	mem 75.501
Train: [5][280/1500]	BT 0.037 (0.351)	DT 0.001 (0.314)	loss 6.937 (6.794)	prob 2.449 (2.372)	GS 32.422 (32.371)	mem 76.458
Train: [5][290/1500]	BT 0.042 (0.340)	DT 0.001 (0.303)	loss 7.241 (6.802)	prob 1.795 (2.328)	GS 35.109 (32.321)	mem 76.514
Train: [5][300/1500]	BT 0.031 (0.360)	DT 0.000 (0.323)	loss 7.208 (6.827)	prob 2.245 (2.361)	GS 33.469 (32.377)	mem 76.628
Train: [5][310/1500]	BT 0.034 (0.349)	DT 0.001 (0.312)	loss 7.140 (6.941)	prob 1.702 (2.231)	GS 36.781 (31.922)	mem 76.639
Train: [5][320/1500]	BT 0.040 (0.341)	DT 0.001 (0.304)	loss 6.854 (6.878)	prob 2.432 (2.159)	GS 36.750 (31.383)	mem 76.664
Train: [5][330/1500]	BT 0.030 (0.348)	DT 0.000 (0.311)	loss 6.878 (6.850)	prob 3.178 (2.282)	GS 35.031 (31.912)	mem 76.870
Train: [5][340/1500]	BT 0.038 (0.339)	DT 0.000 (0.302)	loss 6.903 (6.862)	prob 2.287 (2.378)	GS 34.062 (31.682)	mem 76.879
Train: [5][350/1500]	BT 0.051 (0.339)	DT 0.001 (0.302)	loss 7.275 (6.865)	prob 2.450 (2.475)	GS 38.016 (32.104)	mem 76.967
Train: [5][360/1500]	BT 0.033 (0.332)	DT 0.000 (0.294)	loss 6.810 (6.995)	prob 2.074 (2.436)	GS 32.016 (31.753)	mem 76.973
Train: [5][370/1500]	BT 0.031 (0.340)	DT 0.000 (0.303)	loss 6.838 (6.953)	prob 1.783 (2.229)	GS 32.688 (31.917)	mem 77.127
Train: [5][380/1500]	BT 0.027 (0.332)	DT 0.001 (0.295)	loss 7.334 (6.926)	prob 2.328 (2.346)	GS 32.344 (32.433)	mem 77.093
Train: [5][390/1500]	BT 0.039 (0.325)	DT 0.001 (0.287)	loss 7.385 (6.933)	prob 2.110 (2.376)	GS 35.875 (32.719)	mem 77.103
Train: [5][400/1500]	BT 0.035 (0.329)	DT 0.001 (0.291)	loss 6.869 (6.937)	prob 2.363 (2.361)	GS 34.797 (33.014)	mem 77.217
Train: [5][410/1500]	BT 0.037 (0.321)	DT 0.000 (0.284)	loss 7.130 (6.977)	prob 3.353 (2.775)	GS 35.234 (32.702)	mem 77.226
Train: [5][420/1500]	BT 0.038 (0.323)	DT 0.000 (0.285)	loss 7.525 (7.064)	prob 1.615 (2.610)	GS 36.031 (32.485)	mem 77.325
Train: [5][430/1500]	BT 0.039 (0.316)	DT 0.001 (0.279)	loss 7.079 (7.018)	prob 2.116 (2.532)	GS 34.391 (32.354)	mem 77.335
Train: [5][440/1500]	BT 0.039 (0.310)	DT 0.001 (0.272)	loss 7.473 (6.988)	prob 2.358 (2.446)	GS 38.078 (32.357)	mem 76.423
Train: [5][450/1500]	BT 0.038 (0.310)	DT 0.001 (0.273)	loss 6.606 (6.958)	prob 2.580 (2.518)	GS 30.281 (32.359)	mem 76.447
Train: [5][460/1500]	BT 0.038 (0.304)	DT 0.001 (0.267)	loss 7.266 (6.955)	prob 1.851 (2.547)	GS 34.781 (31.730)	mem 76.452
Train: [5][470/1500]	BT 0.125 (0.313)	DT 0.021 (0.275)	loss 7.023 (6.963)	prob 3.339 (2.411)	GS 37.109 (31.548)	mem 76.504
Train: [5][480/1500]	BT 0.080 (0.330)	DT 0.013 (0.291)	loss 7.178 (6.983)	prob 1.422 (2.411)	GS 34.297 (32.762)	mem 76.565
Train: [5][490/1500]	BT 0.027 (0.351)	DT 0.000 (0.312)	loss 6.942 (7.013)	prob 2.017 (2.363)	GS 31.250 (32.934)	mem 76.772
Train: [5][500/1500]	BT 0.023 (0.345)	DT 0.000 (0.306)	loss 7.579 (7.043)	prob 2.198 (2.289)	GS 36.688 (33.280)	mem 76.786
Train: [5][510/1500]	BT 0.025 (0.338)	DT 0.000 (0.300)	loss 6.980 (6.996)	prob 1.960 (2.183)	GS 34.750 (33.219)	mem 76.793
Train: [5][520/1500]	BT 0.040 (0.342)	DT 0.001 (0.304)	loss 7.001 (6.966)	prob 2.811 (2.214)	GS 34.359 (33.185)	mem 76.898
Train: [5][530/1500]	BT 0.040 (0.336)	DT 0.001 (0.298)	loss 7.250 (6.976)	prob 1.926 (2.271)	GS 35.203 (33.057)	mem 76.923
Train: [5][540/1500]	BT 0.038 (0.338)	DT 0.001 (0.299)	loss 7.263 (7.000)	prob 1.876 (2.154)	GS 34.891 (33.356)	mem 77.007
Train: [5][550/1500]	BT 0.038 (0.332)	DT 0.001 (0.294)	loss 7.032 (7.018)	prob 2.077 (2.074)	GS 34.531 (33.360)	mem 77.020
Train: [5][560/1500]	BT 0.041 (0.333)	DT 0.000 (0.295)	loss 7.090 (7.048)	prob 2.522 (2.300)	GS 31.562 (31.803)	mem 77.125
Train: [5][570/1500]	BT 0.038 (0.328)	DT 0.000 (0.289)	loss 7.443 (7.099)	prob 2.133 (2.348)	GS 36.266 (32.014)	mem 77.134
Train: [5][580/1500]	BT 0.039 (0.323)	DT 0.000 (0.284)	loss 7.225 (7.087)	prob 2.507 (2.341)	GS 32.562 (32.049)	mem 77.140
Train: [5][590/1500]	BT 0.030 (0.348)	DT 0.000 (0.310)	loss 7.265 (7.112)	prob 1.414 (2.238)	GS 31.688 (32.741)	mem 76.576
Train: [5][600/1500]	BT 0.060 (0.343)	DT 0.016 (0.304)	loss 7.080 (7.138)	prob 2.438 (2.225)	GS 31.656 (32.827)	mem 76.593
Train: [5][610/1500]	BT 0.082 (0.347)	DT 0.010 (0.308)	loss 7.214 (7.087)	prob 2.694 (2.415)	GS 38.109 (33.317)	mem 76.680
Train: [5][620/1500]	BT 0.072 (0.342)	DT 0.012 (0.303)	loss 7.006 (7.092)	prob 2.407 (2.272)	GS 34.875 (33.429)	mem 76.647
Train: [5][630/1500]	BT 0.029 (0.356)	DT 0.000 (0.317)	loss 6.975 (7.098)	prob 1.897 (2.283)	GS 29.094 (33.192)	mem 76.734
Train: [5][640/1500]	BT 0.030 (0.351)	DT 0.000 (0.312)	loss 7.014 (7.081)	prob 1.461 (2.297)	GS 36.125 (33.072)	mem 76.742
Train: [5][650/1500]	BT 0.036 (0.346)	DT 0.000 (0.307)	loss 7.035 (7.079)	prob 2.099 (2.332)	GS 37.172 (33.047)	mem 76.747
Train: [5][660/1500]	BT 0.033 (0.346)	DT 0.000 (0.307)	loss 7.530 (7.268)	prob 2.275 (2.254)	GS 33.375 (33.350)	mem 76.779
Train: [5][670/1500]	BT 0.038 (0.341)	DT 0.001 (0.302)	loss 7.663 (7.407)	prob 2.659 (2.258)	GS 29.328 (32.748)	mem 76.784
Train: [5][680/1500]	BT 0.068 (0.344)	DT 0.011 (0.305)	loss 7.169 (7.329)	prob 2.904 (2.366)	GS 30.094 (32.204)	mem 76.898
Train: [5][690/1500]	BT 0.111 (0.340)	DT 0.026 (0.301)	loss 7.242 (7.289)	prob 2.556 (2.490)	GS 35.062 (32.110)	mem 76.905
Train: [5][700/1500]	BT 0.046 (0.352)	DT 0.005 (0.313)	loss 7.113 (7.277)	prob 3.070 (2.478)	GS 34.391 (32.118)	mem 77.067
Train: [5][710/1500]	BT 0.040 (0.348)	DT 0.000 (0.309)	loss 7.552 (7.337)	prob 3.101 (2.731)	GS 34.656 (31.856)	mem 77.080
Train: [5][720/1500]	BT 0.038 (0.344)	DT 0.001 (0.305)	loss 7.128 (7.235)	prob 3.156 (2.756)	GS 32.984 (32.220)	mem 77.112
Train: [5][730/1500]	BT 0.030 (0.345)	DT 0.001 (0.306)	loss 7.448 (7.256)	prob 2.824 (2.725)	GS 32.344 (32.782)	mem 77.221
Train: [5][740/1500]	BT 0.060 (0.341)	DT 0.001 (0.301)	loss 7.254 (7.261)	prob 3.922 (2.797)	GS 30.812 (32.647)	mem 77.228
Train: [5][750/1500]	BT 0.040 (0.341)	DT 0.001 (0.301)	loss 7.371 (7.260)	prob 2.469 (2.794)	GS 33.125 (32.864)	mem 77.284
Train: [5][760/1500]	BT 0.042 (0.339)	DT 0.001 (0.300)	loss 7.333 (7.376)	prob 3.502 (3.346)	GS 32.156 (31.789)	mem 77.325
Train: [5][770/1500]	BT 0.040 (0.335)	DT 0.001 (0.296)	loss 7.677 (7.265)	prob 2.348 (3.230)	GS 34.766 (32.373)	mem 77.332
Train: [5][780/1500]	BT 0.040 (0.335)	DT 0.001 (0.295)	loss 7.310 (7.272)	prob 2.746 (3.038)	GS 39.062 (32.618)	mem 77.386
Train: [5][790/1500]	BT 0.034 (0.333)	DT 0.000 (0.293)	loss 7.753 (7.253)	prob 2.722 (2.943)	GS 31.000 (32.457)	mem 77.426
Train: [5][800/1500]	BT 0.056 (0.347)	DT 0.001 (0.307)	loss 7.561 (7.239)	prob 3.549 (2.997)	GS 33.578 (32.918)	mem 76.596
Train: [5][810/1500]	BT 0.060 (0.343)	DT 0.016 (0.304)	loss 7.710 (7.262)	prob 3.025 (3.072)	GS 29.891 (32.556)	mem 76.601
Train: [5][820/1500]	BT 0.054 (0.340)	DT 0.003 (0.300)	loss 7.756 (7.284)	prob 3.004 (3.288)	GS 31.250 (32.003)	mem 76.610
Train: [5][830/1500]	BT 0.045 (0.351)	DT 0.001 (0.311)	loss 7.006 (7.296)	prob 3.956 (3.350)	GS 36.484 (32.206)	mem 76.698
Train: [5][840/1500]	BT 0.038 (0.347)	DT 0.001 (0.307)	loss 7.774 (7.303)	prob 3.457 (3.405)	GS 34.422 (32.075)	mem 76.705
Train: [5][850/1500]	BT 0.036 (0.352)	DT 0.000 (0.312)	loss 7.018 (7.263)	prob 3.762 (3.483)	GS 34.344 (32.505)	mem 76.814
Train: [5][860/1500]	BT 0.071 (0.348)	DT 0.019 (0.308)	loss 7.397 (7.370)	prob 3.154 (3.289)	GS 36.141 (34.475)	mem 76.822
Train: [5][870/1500]	BT 0.030 (0.344)	DT 0.001 (0.305)	loss 7.414 (7.380)	prob 3.091 (3.299)	GS 35.672 (33.650)	mem 76.828
Train: [5][880/1500]	BT 0.039 (0.346)	DT 0.001 (0.306)	loss 7.170 (7.269)	prob 3.323 (3.559)	GS 30.766 (33.150)	mem 76.948
Train: [5][890/1500]	BT 0.040 (0.342)	DT 0.001 (0.303)	loss 6.931 (7.234)	prob 4.651 (3.613)	GS 31.172 (33.059)	mem 76.959
Train: [5][900/1500]	BT 0.038 (0.344)	DT 0.001 (0.304)	loss 7.124 (7.254)	prob 4.518 (3.676)	GS 32.359 (33.034)	mem 77.113
Train: [5][910/1500]	BT 0.038 (0.340)	DT 0.001 (0.301)	loss 7.549 (7.251)	prob 3.642 (3.381)	GS 38.625 (33.744)	mem 77.124
Train: [5][920/1500]	BT 0.042 (0.341)	DT 0.001 (0.301)	loss 7.161 (7.191)	prob 3.493 (3.634)	GS 33.422 (32.863)	mem 78.489
Train: [5][930/1500]	BT 0.042 (0.338)	DT 0.001 (0.298)	loss 6.961 (7.155)	prob 3.812 (3.678)	GS 34.125 (32.656)	mem 78.662
Train: [5][940/1500]	BT 0.044 (0.335)	DT 0.001 (0.295)	loss 7.074 (7.146)	prob 4.494 (3.716)	GS 35.359 (32.287)	mem 78.857
Train: [5][950/1500]	BT 0.040 (0.337)	DT 0.001 (0.297)	loss 7.015 (7.142)	prob 3.700 (3.717)	GS 29.984 (32.304)	mem 81.696
Train: [5][960/1500]	BT 0.043 (0.334)	DT 0.001 (0.294)	loss 7.040 (7.225)	prob 3.858 (3.468)	GS 31.172 (33.330)	mem 82.001
Train: [5][970/1500]	BT 0.110 (0.341)	DT 0.012 (0.301)	loss 7.387 (7.220)	prob 3.133 (3.369)	GS 36.703 (33.433)	mem 93.410
Train: [5][980/1500]	BT 0.088 (0.338)	DT 0.004 (0.298)	loss 7.210 (7.204)	prob 3.271 (3.374)	GS 33.078 (33.272)	mem 93.605
Train: [5][990/1500]	BT 0.054 (0.340)	DT 0.015 (0.299)	loss 7.088 (7.230)	prob 3.999 (3.348)	GS 33.469 (33.489)	mem 96.828
Train: [5][1000/1500]	BT 0.036 (0.343)	DT 0.000 (0.303)	loss 7.625 (7.242)	prob 2.866 (3.313)	GS 37.391 (33.900)	mem 113.116
Train: [5][1010/1500]	BT 0.044 (0.340)	DT 0.001 (0.300)	loss 7.272 (7.375)	prob 4.138 (3.429)	GS 34.391 (33.763)	mem 113.122
Train: [5][1020/1500]	BT 0.055 (0.342)	DT 0.003 (0.302)	loss 7.037 (7.257)	prob 3.955 (3.550)	GS 33.000 (32.802)	mem 113.184
Train: [5][1030/1500]	BT 0.045 (0.339)	DT 0.001 (0.299)	loss 7.407 (7.253)	prob 3.466 (3.471)	GS 29.250 (32.422)	mem 113.189
Train: [5][1040/1500]	BT 0.072 (0.339)	DT 0.009 (0.299)	loss 7.206 (7.206)	prob 3.215 (3.505)	GS 34.406 (32.398)	mem 113.188
Train: [5][1050/1500]	BT 0.067 (0.340)	DT 0.003 (0.299)	loss 7.282 (7.179)	prob 3.404 (3.472)	GS 36.750 (32.236)	mem 113.846
Train: [5][1060/1500]	BT 0.065 (0.337)	DT 0.000 (0.296)	loss 7.133 (7.197)	prob 3.575 (3.461)	GS 37.750 (31.667)	mem 113.849
Train: [5][1070/1500]	BT 0.033 (0.346)	DT 0.000 (0.305)	loss 7.866 (7.191)	prob 2.201 (3.196)	GS 34.406 (32.654)	mem 76.734
Train: [5][1080/1500]	BT 0.037 (0.343)	DT 0.001 (0.302)	loss 6.683 (7.162)	prob 3.459 (3.164)	GS 32.719 (32.487)	mem 76.744
Train: [5][1090/1500]	BT 0.038 (0.343)	DT 0.001 (0.302)	loss 6.961 (7.167)	prob 3.967 (3.167)	GS 33.969 (32.408)	mem 76.799
Train: [5][1100/1500]	BT 0.038 (0.340)	DT 0.001 (0.299)	loss 7.198 (7.178)	prob 2.784 (3.123)	GS 32.953 (32.507)	mem 76.808
Train: [5][1110/1500]	BT 0.038 (0.337)	DT 0.001 (0.297)	loss 7.818 (7.119)	prob 2.204 (2.979)	GS 39.375 (33.402)	mem 76.816
Train: [5][1120/1500]	BT 0.028 (0.339)	DT 0.000 (0.298)	loss 7.430 (7.173)	prob 3.166 (3.016)	GS 34.047 (32.737)	mem 76.886
Train: [5][1130/1500]	BT 0.039 (0.336)	DT 0.001 (0.295)	loss 7.272 (7.203)	prob 2.409 (2.901)	GS 35.344 (33.366)	mem 76.892
Train: [5][1140/1500]	BT 0.038 (0.337)	DT 0.001 (0.296)	loss 7.026 (7.221)	prob 3.793 (2.957)	GS 28.438 (32.861)	mem 76.981
Train: [5][1150/1500]	BT 0.038 (0.334)	DT 0.001 (0.294)	loss 6.859 (7.213)	prob 3.911 (3.001)	GS 31.203 (32.683)	mem 76.993
Train: [5][1160/1500]	BT 0.039 (0.335)	DT 0.001 (0.294)	loss 7.404 (7.300)	prob 3.332 (3.200)	GS 35.250 (32.072)	mem 77.021
Train: [5][1170/1500]	BT 0.033 (0.335)	DT 0.000 (0.294)	loss 7.108 (7.262)	prob 2.799 (2.992)	GS 31.297 (32.169)	mem 77.103
Train: [5][1180/1500]	BT 0.029 (0.332)	DT 0.000 (0.291)	loss 7.646 (7.264)	prob 2.781 (2.927)	GS 36.844 (32.557)	mem 77.117
Train: [5][1190/1500]	BT 0.037 (0.333)	DT 0.001 (0.293)	loss 7.076 (7.242)	prob 2.846 (2.917)	GS 36.984 (32.743)	mem 77.275
Train: [5][1200/1500]	BT 0.038 (0.331)	DT 0.001 (0.291)	loss 7.383 (7.289)	prob 3.305 (2.876)	GS 34.562 (32.666)	mem 77.286
Train: [5][1210/1500]	BT 0.038 (0.328)	DT 0.000 (0.288)	loss 7.653 (7.464)	prob 3.006 (2.547)	GS 32.078 (33.241)	mem 77.296
Train: [5][1220/1500]	BT 0.040 (0.330)	DT 0.001 (0.289)	loss 7.588 (7.413)	prob 2.029 (2.717)	GS 37.125 (33.241)	mem 76.462
Train: [5][1230/1500]	BT 0.082 (0.328)	DT 0.001 (0.287)	loss 7.805 (7.431)	prob 2.939 (2.702)	GS 33.594 (33.493)	mem 76.461
Train: [5][1240/1500]	BT 0.028 (0.331)	DT 0.000 (0.291)	loss 7.885 (7.454)	prob 3.109 (2.740)	GS 33.312 (33.309)	mem 76.514
Train: [5][1250/1500]	BT 0.038 (0.329)	DT 0.000 (0.289)	loss 7.914 (7.430)	prob 2.803 (2.784)	GS 33.812 (33.298)	mem 76.526
Train: [5][1260/1500]	BT 0.026 (0.330)	DT 0.000 (0.290)	loss 7.527 (7.554)	prob 3.340 (3.244)	GS 31.391 (32.483)	mem 76.597
Train: [5][1270/1500]	BT 0.039 (0.328)	DT 0.001 (0.287)	loss 7.601 (7.564)	prob 3.091 (3.110)	GS 32.812 (32.292)	mem 76.603
Train: [5][1280/1500]	BT 0.039 (0.326)	DT 0.001 (0.285)	loss 7.698 (7.531)	prob 2.343 (2.944)	GS 36.859 (32.728)	mem 76.611
Train: [5][1290/1500]	BT 0.052 (0.327)	DT 0.013 (0.287)	loss 7.807 (7.504)	prob 2.283 (2.941)	GS 34.328 (32.744)	mem 76.638
Train: [5][1300/1500]	BT 0.037 (0.325)	DT 0.001 (0.284)	loss 7.800 (7.502)	prob 3.255 (2.980)	GS 35.219 (32.611)	mem 76.642
Train: [5][1310/1500]	BT 0.036 (0.325)	DT 0.001 (0.285)	loss 7.808 (7.389)	prob 3.447 (3.583)	GS 36.234 (32.361)	mem 76.681
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [5][1320/1500]	BT 0.030 (0.323)	DT 0.001 (0.283)	loss 7.364 (7.489)	prob 3.802 (3.459)	GS 32.500 (31.952)	mem 76.687
Train: [5][1330/1500]	BT 0.030 (0.321)	DT 0.001 (0.281)	loss 7.183 (7.451)	prob 3.323 (3.341)	GS 32.375 (32.368)	mem 76.723
Train: [5][1340/1500]	BT 0.030 (0.327)	DT 0.001 (0.287)	loss 7.764 (7.449)	prob 2.856 (3.255)	GS 33.906 (32.855)	mem 76.874
Train: [5][1350/1500]	BT 0.040 (0.325)	DT 0.001 (0.285)	loss 7.227 (7.445)	prob 2.810 (3.218)	GS 32.797 (32.867)	mem 76.890
Train: [5][1360/1500]	BT 0.040 (0.323)	DT 0.001 (0.283)	loss 7.721 (7.498)	prob 3.450 (2.978)	GS 33.438 (31.663)	mem 76.906
Train: [5][1370/1500]	BT 0.067 (0.323)	DT 0.011 (0.283)	loss 7.704 (7.490)	prob 2.487 (2.952)	GS 30.547 (31.598)	mem 76.986
Train: [5][1380/1500]	BT 0.032 (0.323)	DT 0.000 (0.282)	loss 7.762 (7.499)	prob 3.911 (3.009)	GS 33.188 (32.096)	mem 77.026
Train: [5][1390/1500]	BT 0.065 (0.324)	DT 0.001 (0.284)	loss 7.237 (7.494)	prob 3.233 (3.006)	GS 30.078 (32.274)	mem 77.117
Train: [5][1400/1500]	BT 0.102 (0.323)	DT 0.015 (0.282)	loss 7.362 (7.476)	prob 3.273 (3.060)	GS 30.906 (32.385)	mem 77.123
Train: [5][1410/1500]	BT 0.039 (0.324)	DT 0.001 (0.283)	loss 7.668 (7.574)	prob 3.129 (2.984)	GS 35.531 (33.834)	mem 77.181
Train: [5][1420/1500]	BT 0.029 (0.323)	DT 0.000 (0.282)	loss 7.538 (7.428)	prob 3.275 (3.000)	GS 36.656 (33.074)	mem 77.205
Train: [5][1430/1500]	BT 0.039 (0.322)	DT 0.001 (0.281)	loss 7.255 (7.460)	prob 3.299 (3.027)	GS 31.672 (32.915)	mem 77.263
Train: [5][1440/1500]	BT 0.040 (0.321)	DT 0.001 (0.280)	loss 7.623 (7.459)	prob 3.188 (3.095)	GS 31.297 (32.703)	mem 77.271
Train: [5][1450/1500]	BT 0.043 (0.320)	DT 0.001 (0.280)	loss 7.693 (7.470)	prob 3.506 (3.092)	GS 35.297 (32.767)	mem 77.329
Train: [5][1460/1500]	BT 0.036 (0.320)	DT 0.001 (0.280)	loss 7.418 (7.389)	prob 3.388 (2.773)	GS 32.422 (31.764)	mem 76.080
Train: [5][1470/1500]	BT 0.038 (0.318)	DT 0.000 (0.278)	loss 8.436 (7.477)	prob 2.275 (2.907)	GS 35.875 (31.903)	mem 76.037
Train: [5][1480/1500]	BT 0.030 (0.318)	DT 0.000 (0.278)	loss 7.491 (7.504)	prob 3.237 (2.905)	GS 31.156 (32.222)	mem 31.763
Train: [5][1490/1500]	BT 0.028 (0.316)	DT 0.000 (0.276)	loss 7.243 (7.508)	prob 3.302 (2.988)	GS 34.531 (32.310)	mem 22.767
Train: [5][1500/1500]	BT 0.039 (0.315)	DT 0.000 (0.274)	loss 7.187 (7.521)	prob 3.326 (2.955)	GS 28.469 (32.588)	mem 22.701
Train: [5][1510/1500]	BT 0.037 (0.313)	DT 0.001 (0.273)	loss 7.813 (7.510)	prob 2.889 (3.051)	GS 36.406 (34.438)	mem 11.414
epoch 5, total time 473.38
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [6][1/1500]	BT 25.160 (25.160)	DT 25.107 (25.107)	loss 7.272 (7.272)	prob 2.952 (2.952)	GS 30.953 (30.953)	mem 75.587
Train: [6][10/1500]	BT 0.072 (2.600)	DT 0.000 (2.562)	loss 7.209 (7.220)	prob 3.049 (3.026)	GS 33.469 (32.408)	mem 75.613
Train: [6][20/1500]	BT 0.054 (1.400)	DT 0.011 (1.355)	loss 6.954 (7.354)	prob 3.932 (3.044)	GS 30.594 (32.448)	mem 75.646
Train: [6][30/1500]	BT 0.037 (1.158)	DT 0.000 (1.116)	loss 7.769 (7.387)	prob 3.445 (3.189)	GS 30.984 (31.999)	mem 75.766
Train: [6][40/1500]	BT 0.030 (0.888)	DT 0.000 (0.848)	loss 7.167 (7.388)	prob 3.185 (3.179)	GS 33.734 (31.994)	mem 75.776
Train: [6][50/1500]	BT 0.031 (0.768)	DT 0.001 (0.728)	loss 7.536 (7.426)	prob 2.813 (3.154)	GS 37.219 (32.301)	mem 75.956
Train: [6][60/1500]	BT 0.762 (0.687)	DT 0.712 (0.647)	loss 8.048 (7.502)	prob 3.491 (3.323)	GS 29.906 (30.991)	mem 76.084
Train: [6][70/1500]	BT 0.059 (0.597)	DT 0.011 (0.556)	loss 7.406 (7.401)	prob 3.671 (3.436)	GS 32.094 (30.829)	mem 76.096
Train: [6][80/1500]	BT 0.038 (0.586)	DT 0.001 (0.546)	loss 7.181 (7.381)	prob 3.133 (3.312)	GS 37.938 (31.227)	mem 75.280
Train: [6][90/1500]	BT 0.038 (0.525)	DT 0.001 (0.485)	loss 7.677 (7.423)	prob 3.026 (3.220)	GS 34.469 (31.677)	mem 75.280
Train: [6][100/1500]	BT 0.226 (0.519)	DT 0.189 (0.479)	loss 7.998 (7.453)	prob 2.465 (3.188)	GS 28.828 (31.931)	mem 75.330
Train: [6][110/1500]	BT 0.028 (0.483)	DT 0.000 (0.444)	loss 7.802 (7.573)	prob 2.913 (2.834)	GS 33.703 (31.820)	mem 75.351
Train: [6][120/1500]	BT 0.052 (0.445)	DT 0.013 (0.407)	loss 7.492 (7.531)	prob 3.423 (2.930)	GS 33.750 (32.152)	mem 75.356
Train: [6][130/1500]	BT 0.040 (0.458)	DT 0.001 (0.420)	loss 7.891 (7.522)	prob 3.187 (2.968)	GS 35.906 (32.492)	mem 75.454
Train: [6][140/1500]	BT 0.042 (0.428)	DT 0.001 (0.390)	loss 7.271 (7.467)	prob 3.048 (3.038)	GS 33.500 (32.855)	mem 75.440
Train: [6][150/1500]	BT 0.037 (0.433)	DT 0.000 (0.394)	loss 8.280 (7.509)	prob 2.415 (2.907)	GS 39.828 (32.962)	mem 75.561
Train: [6][160/1500]	BT 0.028 (0.408)	DT 0.000 (0.370)	loss 7.048 (7.312)	prob 3.130 (2.781)	GS 34.266 (32.689)	mem 75.574
Train: [6][170/1500]	BT 0.025 (0.385)	DT 0.000 (0.348)	loss 7.220 (7.399)	prob 3.181 (2.854)	GS 33.547 (32.544)	mem 75.581
Train: [6][180/1500]	BT 0.039 (0.383)	DT 0.001 (0.345)	loss 7.685 (7.422)	prob 2.226 (2.784)	GS 36.750 (33.131)	mem 75.699
Train: [6][190/1500]	BT 0.038 (0.364)	DT 0.001 (0.327)	loss 7.254 (7.390)	prob 3.318 (2.771)	GS 31.281 (33.085)	mem 75.712
Train: [6][200/1500]	BT 0.046 (0.372)	DT 0.006 (0.334)	loss 8.161 (7.416)	prob 3.174 (2.734)	GS 34.750 (33.293)	mem 75.838
Train: [6][210/1500]	BT 0.030 (0.355)	DT 0.000 (0.318)	loss 7.377 (7.384)	prob 3.598 (3.277)	GS 36.516 (32.269)	mem 75.848
Train: [6][220/1500]	BT 0.040 (0.363)	DT 0.001 (0.326)	loss 7.680 (7.475)	prob 3.253 (3.062)	GS 34.031 (32.807)	mem 75.914
Train: [6][230/1500]	BT 0.038 (0.349)	DT 0.001 (0.312)	loss 7.786 (7.491)	prob 3.423 (3.015)	GS 35.234 (32.740)	mem 75.923
Train: [6][240/1500]	BT 0.039 (0.345)	DT 0.001 (0.307)	loss 7.809 (7.514)	prob 2.972 (2.889)	GS 34.609 (33.281)	mem 75.998
Train: [6][250/1500]	BT 0.039 (0.343)	DT 0.000 (0.306)	loss 7.621 (7.527)	prob 3.814 (2.896)	GS 35.969 (33.214)	mem 76.006
Train: [6][260/1500]	BT 0.041 (0.342)	DT 0.001 (0.305)	loss 8.201 (7.403)	prob 2.893 (3.309)	GS 34.047 (33.947)	mem 76.100
Train: [6][270/1500]	BT 0.063 (0.339)	DT 0.011 (0.301)	loss 8.484 (7.552)	prob 2.674 (2.929)	GS 30.031 (33.484)	mem 76.148
Train: [6][280/1500]	BT 0.040 (0.329)	DT 0.001 (0.291)	loss 7.928 (7.538)	prob 2.174 (2.902)	GS 32.375 (33.144)	mem 76.162
Train: [6][290/1500]	BT 0.039 (0.327)	DT 0.001 (0.290)	loss 7.274 (7.557)	prob 2.695 (2.834)	GS 33.203 (33.085)	mem 76.210
Train: [6][300/1500]	BT 0.039 (0.327)	DT 0.001 (0.289)	loss 7.672 (7.551)	prob 2.447 (2.779)	GS 31.406 (33.032)	mem 75.380
Train: [6][310/1500]	BT 0.040 (0.318)	DT 0.001 (0.280)	loss 7.451 (7.516)	prob 2.652 (2.832)	GS 31.109 (33.272)	mem 75.379
Train: [6][320/1500]	BT 0.040 (0.323)	DT 0.001 (0.285)	loss 8.131 (7.669)	prob 2.638 (2.828)	GS 36.844 (32.707)	mem 75.480
Train: [6][330/1500]	BT 0.041 (0.315)	DT 0.001 (0.277)	loss 7.873 (7.659)	prob 3.029 (2.768)	GS 31.109 (32.544)	mem 75.560
Train: [6][340/1500]	BT 8.674 (0.333)	DT 8.642 (0.295)	loss 7.966 (7.700)	prob 2.981 (2.781)	GS 38.031 (32.618)	mem 76.547
Train: [6][350/1500]	BT 0.052 (0.325)	DT 0.001 (0.286)	loss 8.051 (7.701)	prob 2.706 (2.786)	GS 32.469 (32.568)	mem 76.600
Train: [6][360/1500]	BT 0.053 (0.322)	DT 0.006 (0.283)	loss 7.770 (7.655)	prob 2.076 (2.895)	GS 32.484 (32.594)	mem 76.667
Train: [6][370/1500]	BT 0.076 (0.337)	DT 0.005 (0.298)	loss 7.822 (7.555)	prob 3.411 (3.136)	GS 33.109 (32.891)	mem 76.726
Train: [6][380/1500]	BT 0.026 (0.330)	DT 0.000 (0.291)	loss 7.703 (7.588)	prob 3.711 (3.201)	GS 29.438 (32.068)	mem 76.743
Train: [6][390/1500]	BT 0.041 (0.333)	DT 0.001 (0.293)	loss 7.375 (7.589)	prob 3.097 (3.152)	GS 35.969 (32.248)	mem 76.837
Train: [6][400/1500]	BT 0.040 (0.326)	DT 0.001 (0.286)	loss 8.087 (7.644)	prob 2.215 (2.932)	GS 30.578 (32.911)	mem 76.847
Train: [6][410/1500]	BT 0.040 (0.325)	DT 0.001 (0.286)	loss 8.279 (7.760)	prob 2.816 (2.528)	GS 35.422 (32.800)	mem 76.936
Train: [6][420/1500]	BT 0.040 (0.318)	DT 0.001 (0.279)	loss 8.666 (7.836)	prob 2.708 (2.850)	GS 34.531 (32.277)	mem 76.962
Train: [6][430/1500]	BT 0.040 (0.314)	DT 0.001 (0.274)	loss 8.585 (7.904)	prob 2.906 (2.797)	GS 33.250 (32.209)	mem 77.025
Train: [6][440/1500]	BT 0.038 (0.315)	DT 0.000 (0.275)	loss 7.249 (7.826)	prob 3.130 (2.967)	GS 32.906 (32.100)	mem 77.099
Train: [6][450/1500]	BT 0.038 (0.309)	DT 0.000 (0.269)	loss 7.809 (7.798)	prob 2.672 (2.865)	GS 35.156 (32.442)	mem 77.105
Train: [6][460/1500]	BT 0.029 (0.323)	DT 0.000 (0.283)	loss 7.562 (7.994)	prob 4.013 (2.778)	GS 31.594 (33.098)	mem 77.247
Train: [6][470/1500]	BT 0.030 (0.317)	DT 0.000 (0.277)	loss 8.492 (7.826)	prob 3.728 (3.265)	GS 34.844 (32.279)	mem 77.258
Train: [6][480/1500]	BT 0.039 (0.314)	DT 0.001 (0.275)	loss 7.596 (7.764)	prob 4.315 (3.340)	GS 34.422 (31.858)	mem 77.301
Train: [6][490/1500]	BT 0.040 (0.311)	DT 0.001 (0.272)	loss 8.329 (7.819)	prob 2.895 (3.176)	GS 33.891 (32.261)	mem 77.331
Train: [6][500/1500]	BT 0.098 (0.327)	DT 0.018 (0.287)	loss 8.032 (7.797)	prob 3.435 (3.211)	GS 35.359 (32.185)	mem 77.607
Train: [6][510/1500]	BT 0.074 (0.326)	DT 0.004 (0.285)	loss 7.756 (7.821)	prob 2.917 (3.318)	GS 31.844 (32.900)	mem 77.662
Train: [6][520/1500]	BT 0.138 (0.340)	DT 0.011 (0.299)	loss 8.057 (7.838)	prob 3.815 (3.190)	GS 30.672 (32.829)	mem 78.644
Train: [6][530/1500]	BT 0.031 (0.366)	DT 0.001 (0.324)	loss 7.947 (7.803)	prob 2.930 (3.110)	GS 34.219 (33.074)	mem 76.664
Train: [6][540/1500]	BT 0.038 (0.359)	DT 0.001 (0.318)	loss 8.521 (7.786)	prob 3.121 (3.232)	GS 34.656 (32.651)	mem 76.670
Train: [6][550/1500]	BT 0.040 (0.358)	DT 0.001 (0.317)	loss 7.782 (7.823)	prob 3.952 (3.205)	GS 31.531 (32.783)	mem 76.701
Train: [6][560/1500]	BT 0.039 (0.353)	DT 0.001 (0.312)	loss 9.112 (7.759)	prob 3.065 (3.036)	GS 34.625 (34.309)	mem 76.702
Train: [6][570/1500]	BT 0.064 (0.355)	DT 0.014 (0.314)	loss 8.766 (7.843)	prob 2.835 (2.886)	GS 34.000 (33.956)	mem 76.751
Train: [6][580/1500]	BT 0.051 (0.350)	DT 0.001 (0.309)	loss 7.958 (7.817)	prob 3.087 (3.008)	GS 35.609 (33.763)	mem 76.759
Train: [6][590/1500]	BT 0.039 (0.345)	DT 0.001 (0.304)	loss 7.918 (7.808)	prob 4.321 (3.082)	GS 29.281 (33.264)	mem 76.768
Train: [6][600/1500]	BT 0.308 (0.346)	DT 0.268 (0.305)	loss 8.093 (7.858)	prob 3.293 (3.094)	GS 38.219 (33.435)	mem 76.830
Train: [6][610/1500]	BT 0.039 (0.344)	DT 0.001 (0.303)	loss 7.849 (7.757)	prob 3.991 (3.488)	GS 34.172 (32.530)	mem 76.911
Train: [6][620/1500]	BT 0.397 (0.343)	DT 0.346 (0.302)	loss 7.736 (7.740)	prob 3.642 (3.519)	GS 35.281 (32.770)	mem 76.942
Train: [6][630/1500]	BT 0.038 (0.350)	DT 0.000 (0.309)	loss 7.924 (7.835)	prob 3.322 (3.310)	GS 31.297 (33.101)	mem 77.075
Train: [6][640/1500]	BT 0.038 (0.346)	DT 0.001 (0.304)	loss 7.775 (7.788)	prob 3.464 (3.345)	GS 31.109 (33.012)	mem 77.055
Train: [6][650/1500]	BT 0.054 (0.342)	DT 0.011 (0.301)	loss 8.460 (7.807)	prob 3.918 (3.362)	GS 34.828 (33.078)	mem 76.575
Train: [6][660/1500]	BT 0.063 (0.347)	DT 0.002 (0.306)	loss 8.479 (7.785)	prob 3.739 (3.660)	GS 33.703 (31.739)	mem 76.491
Train: [6][670/1500]	BT 0.038 (0.343)	DT 0.001 (0.302)	loss 8.025 (7.762)	prob 3.582 (3.594)	GS 30.344 (32.212)	mem 76.503
Train: [6][680/1500]	BT 0.027 (0.344)	DT 0.000 (0.302)	loss 7.937 (7.763)	prob 3.476 (3.522)	GS 34.109 (32.658)	mem 76.548
Train: [6][690/1500]	BT 0.047 (0.340)	DT 0.002 (0.298)	loss 7.666 (7.735)	prob 3.932 (3.500)	GS 27.797 (32.265)	mem 76.553
Train: [6][700/1500]	BT 0.060 (0.343)	DT 0.002 (0.301)	loss 7.573 (7.681)	prob 4.666 (3.592)	GS 34.766 (32.147)	mem 76.611
Train: [6][710/1500]	BT 0.066 (0.339)	DT 0.002 (0.297)	loss 7.759 (7.815)	prob 3.942 (2.975)	GS 31.875 (32.825)	mem 76.617
Train: [6][720/1500]	BT 0.029 (0.353)	DT 0.000 (0.311)	loss 7.989 (7.696)	prob 4.448 (3.391)	GS 31.500 (32.418)	mem 76.830
Train: [6][730/1500]	BT 0.034 (0.348)	DT 0.000 (0.307)	loss 8.318 (7.710)	prob 4.022 (3.559)	GS 36.438 (32.465)	mem 76.840
Train: [6][740/1500]	BT 0.038 (0.349)	DT 0.001 (0.307)	loss 7.460 (7.678)	prob 3.865 (3.547)	GS 33.984 (32.429)	mem 76.925
Train: [6][750/1500]	BT 0.040 (0.344)	DT 0.001 (0.303)	loss 7.823 (7.660)	prob 3.118 (3.530)	GS 36.062 (32.531)	mem 76.937
Train: [6][760/1500]	BT 0.039 (0.340)	DT 0.001 (0.299)	loss 7.878 (7.674)	prob 3.550 (3.288)	GS 31.859 (31.964)	mem 76.946
Train: [6][770/1500]	BT 0.043 (0.343)	DT 0.001 (0.302)	loss 8.594 (7.721)	prob 3.972 (3.468)	GS 32.750 (31.523)	mem 77.070
Train: [6][780/1500]	BT 0.043 (0.339)	DT 0.001 (0.298)	loss 7.377 (7.686)	prob 3.379 (3.631)	GS 34.359 (31.326)	mem 77.084
Train: [6][790/1500]	BT 0.039 (0.340)	DT 0.000 (0.299)	loss 7.569 (7.689)	prob 4.474 (3.706)	GS 29.875 (31.139)	mem 77.154
Train: [6][800/1500]	BT 0.040 (0.337)	DT 0.001 (0.296)	loss 8.380 (7.716)	prob 3.695 (3.660)	GS 32.844 (31.349)	mem 77.167
Train: [6][810/1500]	BT 0.039 (0.336)	DT 0.000 (0.295)	loss 8.095 (7.837)	prob 3.989 (3.437)	GS 31.750 (31.913)	mem 77.245
Train: [6][820/1500]	BT 0.039 (0.333)	DT 0.001 (0.292)	loss 7.374 (7.712)	prob 3.613 (3.437)	GS 31.484 (32.740)	mem 77.254
Train: [6][830/1500]	BT 0.039 (0.329)	DT 0.001 (0.288)	loss 7.443 (7.666)	prob 4.045 (3.553)	GS 33.062 (32.388)	mem 77.261
Train: [6][840/1500]	BT 0.064 (0.333)	DT 0.007 (0.292)	loss 7.459 (7.674)	prob 3.241 (3.517)	GS 38.297 (32.638)	mem 77.363
Train: [6][850/1500]	BT 0.031 (0.337)	DT 0.000 (0.296)	loss 7.832 (7.681)	prob 3.854 (3.478)	GS 33.266 (32.955)	mem 76.553
Train: [6][860/1500]	BT 0.039 (0.333)	DT 0.001 (0.292)	loss 7.605 (7.666)	prob 3.399 (3.186)	GS 35.141 (34.422)	mem 76.535
Train: [6][870/1500]	BT 0.075 (0.337)	DT 0.006 (0.296)	loss 8.553 (7.768)	prob 2.389 (3.159)	GS 32.969 (33.735)	mem 76.594
Train: [6][880/1500]	BT 0.061 (0.334)	DT 0.006 (0.293)	loss 7.316 (7.770)	prob 2.815 (3.163)	GS 33.562 (33.647)	mem 76.593
Train: [6][890/1500]	BT 0.038 (0.338)	DT 0.003 (0.297)	loss 7.941 (7.751)	prob 3.565 (3.158)	GS 35.031 (33.600)	mem 76.673
Train: [6][900/1500]	BT 0.037 (0.335)	DT 0.000 (0.293)	loss 7.626 (7.766)	prob 3.590 (3.136)	GS 35.766 (33.488)	mem 76.678
Train: [6][910/1500]	BT 0.063 (0.331)	DT 0.011 (0.290)	loss 7.877 (7.809)	prob 3.406 (3.205)	GS 31.188 (32.444)	mem 76.683
Train: [6][920/1500]	BT 0.037 (0.333)	DT 0.000 (0.291)	loss 8.535 (7.831)	prob 3.614 (3.143)	GS 35.797 (32.304)	mem 76.731
Train: [6][930/1500]	BT 0.038 (0.329)	DT 0.001 (0.288)	loss 8.064 (7.811)	prob 3.480 (3.071)	GS 35.266 (32.506)	mem 76.737
Train: [6][940/1500]	BT 0.031 (0.330)	DT 0.001 (0.289)	loss 7.552 (7.801)	prob 4.231 (3.131)	GS 34.844 (32.259)	mem 76.801
Train: [6][950/1500]	BT 0.033 (0.326)	DT 0.001 (0.286)	loss 7.836 (7.814)	prob 2.783 (3.034)	GS 31.828 (32.624)	mem 76.809
Train: [6][960/1500]	BT 0.038 (0.323)	DT 0.000 (0.283)	loss 8.631 (8.002)	prob 2.908 (2.806)	GS 34.859 (31.708)	mem 76.816
Train: [6][970/1500]	BT 0.038 (0.323)	DT 0.001 (0.283)	loss 8.127 (7.969)	prob 2.823 (2.843)	GS 31.750 (32.270)	mem 76.877
Train: [6][980/1500]	BT 0.039 (0.321)	DT 0.001 (0.280)	loss 8.298 (7.859)	prob 3.514 (3.066)	GS 31.281 (32.169)	mem 76.893
Train: [6][990/1500]	BT 0.038 (0.323)	DT 0.001 (0.282)	loss 7.680 (7.827)	prob 3.148 (3.034)	GS 29.781 (32.394)	mem 76.959
Train: [6][1000/1500]	BT 0.038 (0.322)	DT 0.001 (0.281)	loss 8.117 (7.873)	prob 2.731 (2.948)	GS 31.047 (32.400)	mem 76.979
Train: [6][1010/1500]	BT 0.039 (0.320)	DT 0.001 (0.279)	loss 8.112 (8.027)	prob 3.429 (2.822)	GS 34.500 (31.472)	mem 76.997
Train: [6][1020/1500]	BT 0.048 (0.324)	DT 0.000 (0.283)	loss 8.372 (8.001)	prob 2.650 (2.836)	GS 32.328 (32.077)	mem 78.985
Train: [6][1030/1500]	BT 0.040 (0.323)	DT 0.001 (0.282)	loss 7.294 (7.979)	prob 3.521 (2.907)	GS 32.125 (32.187)	mem 79.732
Train: [6][1040/1500]	BT 0.046 (0.320)	DT 0.001 (0.280)	loss 8.496 (8.010)	prob 3.403 (2.887)	GS 36.062 (32.093)	mem 80.793
Train: [6][1050/1500]	BT 0.068 (0.322)	DT 0.006 (0.281)	loss 8.023 (7.981)	prob 3.778 (3.002)	GS 33.297 (32.052)	mem 77.310
Train: [6][1060/1500]	BT 0.038 (0.319)	DT 0.001 (0.278)	loss 8.286 (7.991)	prob 3.595 (3.150)	GS 31.422 (32.362)	mem 77.322
Train: [6][1070/1500]	BT 0.058 (0.322)	DT 0.011 (0.281)	loss 7.944 (7.987)	prob 2.534 (2.877)	GS 34.125 (32.612)	mem 77.419
Train: [6][1080/1500]	BT 0.038 (0.319)	DT 0.001 (0.279)	loss 8.332 (8.037)	prob 3.624 (2.761)	GS 34.203 (32.642)	mem 77.428
Train: [6][1090/1500]	BT 0.039 (0.321)	DT 0.001 (0.280)	loss 8.010 (7.988)	prob 3.016 (2.897)	GS 36.875 (32.431)	mem 76.554
Train: [6][1100/1500]	BT 0.038 (0.319)	DT 0.001 (0.278)	loss 8.400 (8.011)	prob 2.915 (2.883)	GS 34.469 (32.350)	mem 76.554
Train: [6][1110/1500]	BT 0.039 (0.316)	DT 0.001 (0.276)	loss 7.638 (8.044)	prob 3.827 (3.123)	GS 35.906 (33.150)	mem 76.559
Train: [6][1120/1500]	BT 0.058 (0.319)	DT 0.011 (0.278)	loss 7.772 (7.961)	prob 3.837 (3.115)	GS 33.906 (33.299)	mem 76.602
Train: [6][1130/1500]	BT 0.072 (0.316)	DT 0.016 (0.275)	loss 8.362 (8.019)	prob 3.826 (3.131)	GS 34.312 (33.330)	mem 76.606
Train: [6][1140/1500]	BT 0.038 (0.320)	DT 0.001 (0.279)	loss 7.948 (8.007)	prob 2.911 (3.146)	GS 37.125 (33.346)	mem 76.679
Train: [6][1150/1500]	BT 0.038 (0.318)	DT 0.001 (0.277)	loss 7.831 (8.010)	prob 3.191 (3.141)	GS 34.672 (33.423)	mem 76.698
Train: [6][1160/1500]	BT 0.039 (0.316)	DT 0.001 (0.275)	loss 8.025 (8.105)	prob 4.446 (3.210)	GS 34.266 (31.495)	mem 76.704
Train: [6][1170/1500]	BT 0.038 (0.317)	DT 0.001 (0.276)	loss 7.893 (8.081)	prob 3.278 (3.236)	GS 32.906 (32.177)	mem 76.802
Train: [6][1180/1500]	BT 0.038 (0.315)	DT 0.001 (0.274)	loss 8.458 (8.039)	prob 3.996 (3.317)	GS 32.688 (31.812)	mem 76.814
Train: [6][1190/1500]	BT 0.054 (0.313)	DT 0.013 (0.272)	loss 8.034 (7.977)	prob 3.932 (3.341)	GS 31.969 (32.145)	mem 76.848
Train: [6][1200/1500]	BT 0.037 (0.315)	DT 0.001 (0.274)	loss 8.268 (7.996)	prob 2.994 (3.298)	GS 32.750 (32.503)	mem 76.928
Train: [6][1210/1500]	BT 0.038 (0.313)	DT 0.001 (0.272)	loss 8.170 (8.102)	prob 3.510 (2.996)	GS 35.844 (33.386)	mem 76.934
Train: [6][1220/1500]	BT 0.038 (0.313)	DT 0.001 (0.272)	loss 7.697 (8.078)	prob 3.578 (3.068)	GS 38.047 (33.338)	mem 76.994
Train: [6][1230/1500]	BT 0.039 (0.311)	DT 0.001 (0.271)	loss 9.114 (8.068)	prob 2.652 (3.106)	GS 36.297 (32.789)	mem 77.019
Train: [6][1240/1500]	BT 0.039 (0.312)	DT 0.000 (0.271)	loss 7.919 (8.024)	prob 2.809 (3.122)	GS 33.562 (32.596)	mem 77.150
Train: [6][1250/1500]	BT 0.040 (0.310)	DT 0.001 (0.269)	loss 7.504 (7.992)	prob 4.260 (3.129)	GS 30.812 (32.581)	mem 77.163
Train: [6][1260/1500]	BT 0.039 (0.308)	DT 0.001 (0.267)	loss 8.280 (8.035)	prob 3.201 (3.370)	GS 31.375 (32.116)	mem 77.194
Train: [6][1270/1500]	BT 0.040 (0.308)	DT 0.001 (0.268)	loss 7.520 (7.856)	prob 4.021 (3.521)	GS 32.906 (31.999)	mem 77.270
Train: [6][1280/1500]	BT 0.040 (0.308)	DT 0.001 (0.268)	loss 8.290 (7.908)	prob 3.733 (3.486)	GS 33.453 (32.315)	mem 77.333
Train: [6][1290/1500]	BT 0.040 (0.307)	DT 0.001 (0.266)	loss 7.729 (7.854)	prob 4.336 (3.515)	GS 33.938 (32.318)	mem 77.352
Train: [6][1300/1500]	BT 0.040 (0.305)	DT 0.001 (0.264)	loss 7.762 (7.837)	prob 3.712 (3.489)	GS 32.469 (32.440)	mem 77.359
Train: [6][1310/1500]	BT 0.039 (0.305)	DT 0.001 (0.265)	loss 8.024 (7.994)	prob 4.666 (3.773)	GS 31.469 (30.611)	mem 77.434
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [6][1320/1500]	BT 0.040 (0.303)	DT 0.001 (0.263)	loss 8.273 (7.975)	prob 3.659 (3.559)	GS 35.906 (31.152)	mem 77.442
Train: [6][1330/1500]	BT 0.039 (0.305)	DT 0.001 (0.264)	loss 8.506 (7.952)	prob 3.641 (3.569)	GS 38.656 (31.646)	mem 76.655
Train: [6][1340/1500]	BT 0.039 (0.303)	DT 0.001 (0.262)	loss 7.642 (7.946)	prob 4.597 (3.546)	GS 33.312 (31.677)	mem 76.655
Train: [6][1350/1500]	BT 0.040 (0.304)	DT 0.001 (0.263)	loss 8.051 (7.929)	prob 2.883 (3.492)	GS 36.266 (31.889)	mem 76.654
Train: [6][1360/1500]	BT 0.032 (0.302)	DT 0.001 (0.261)	loss 8.001 (7.919)	prob 3.850 (3.368)	GS 30.016 (32.002)	mem 76.658
Train: [6][1370/1500]	BT 0.029 (0.300)	DT 0.000 (0.259)	loss 7.925 (7.845)	prob 3.890 (3.297)	GS 35.188 (32.754)	mem 76.660
Train: [6][1380/1500]	BT 0.040 (0.303)	DT 0.001 (0.262)	loss 7.771 (7.858)	prob 3.956 (3.196)	GS 26.500 (32.536)	mem 76.714
Train: [6][1390/1500]	BT 0.039 (0.301)	DT 0.001 (0.260)	loss 7.451 (7.829)	prob 2.966 (3.224)	GS 34.797 (33.004)	mem 76.719
Train: [6][1400/1500]	BT 0.032 (0.301)	DT 0.000 (0.261)	loss 7.782 (7.842)	prob 4.133 (3.212)	GS 29.812 (32.749)	mem 76.753
Train: [6][1410/1500]	BT 0.031 (0.299)	DT 0.000 (0.259)	loss 8.559 (8.026)	prob 2.720 (3.415)	GS 37.828 (32.598)	mem 76.763
Train: [6][1420/1500]	BT 0.040 (0.297)	DT 0.001 (0.257)	loss 7.766 (7.930)	prob 4.152 (3.406)	GS 30.234 (32.467)	mem 76.769
Train: [6][1430/1500]	BT 0.039 (0.298)	DT 0.001 (0.258)	loss 7.358 (7.857)	prob 4.663 (3.560)	GS 31.781 (32.321)	mem 76.806
Train: [6][1440/1500]	BT 0.040 (0.297)	DT 0.001 (0.256)	loss 7.711 (7.846)	prob 3.840 (3.571)	GS 36.922 (32.487)	mem 76.806
Train: [6][1450/1500]	BT 0.038 (0.298)	DT 0.001 (0.258)	loss 7.579 (7.856)	prob 3.396 (3.426)	GS 33.469 (32.477)	mem 76.727
Train: [6][1460/1500]	BT 0.032 (0.296)	DT 0.001 (0.256)	loss 8.377 (7.618)	prob 4.050 (3.558)	GS 28.984 (31.372)	mem 76.736
Train: [6][1470/1500]	BT 0.040 (0.296)	DT 0.001 (0.255)	loss 7.971 (7.662)	prob 2.993 (3.381)	GS 33.156 (32.691)	mem 67.600
Train: [6][1480/1500]	BT 0.019 (0.296)	DT 0.000 (0.255)	loss 8.186 (7.756)	prob 3.260 (3.382)	GS 39.172 (32.953)	mem 14.873
Train: [6][1490/1500]	BT 0.031 (0.294)	DT 0.000 (0.254)	loss 8.059 (7.814)	prob 3.271 (3.395)	GS 39.031 (32.995)	mem 14.882
Train: [6][1500/1500]	BT 0.036 (0.292)	DT 0.000 (0.252)	loss 7.194 (7.811)	prob 3.406 (3.436)	GS 33.812 (32.810)	mem 12.058
Train: [6][1510/1500]	BT 0.028 (0.291)	DT 0.000 (0.251)	loss 7.935 (7.796)	prob 3.991 (3.168)	GS 36.156 (33.763)	mem 12.072
epoch 6, total time 439.31
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [7][1/1500]	BT 18.463 (18.463)	DT 18.413 (18.413)	loss 7.585 (7.585)	prob 3.436 (3.436)	GS 34.062 (34.062)	mem 75.156
Train: [7][10/1500]	BT 0.037 (2.296)	DT 0.001 (2.258)	loss 7.208 (7.428)	prob 3.545 (3.511)	GS 31.656 (33.472)	mem 75.341
Train: [7][20/1500]	BT 0.038 (1.168)	DT 0.001 (1.130)	loss 7.457 (7.576)	prob 4.732 (3.525)	GS 29.359 (32.356)	mem 75.348
Train: [7][30/1500]	BT 0.039 (0.908)	DT 0.000 (0.870)	loss 8.517 (7.570)	prob 3.005 (3.527)	GS 30.547 (32.204)	mem 75.430
Train: [7][40/1500]	BT 0.030 (0.885)	DT 0.000 (0.848)	loss 8.686 (7.613)	prob 2.553 (3.463)	GS 34.141 (32.817)	mem 75.618
Train: [7][50/1500]	BT 0.040 (0.715)	DT 0.001 (0.678)	loss 8.261 (7.624)	prob 4.372 (3.517)	GS 30.641 (32.320)	mem 75.641
Train: [7][60/1500]	BT 0.039 (0.645)	DT 0.001 (0.608)	loss 7.334 (7.708)	prob 4.172 (3.731)	GS 33.609 (32.309)	mem 75.667
Train: [7][70/1500]	BT 0.039 (0.567)	DT 0.001 (0.529)	loss 8.112 (7.923)	prob 3.305 (3.334)	GS 34.719 (32.291)	mem 75.700
Train: [7][80/1500]	BT 0.039 (0.501)	DT 0.000 (0.463)	loss 8.215 (7.895)	prob 3.651 (3.231)	GS 31.094 (32.205)	mem 75.711
Train: [7][90/1500]	BT 0.040 (0.498)	DT 0.001 (0.460)	loss 7.685 (7.856)	prob 3.795 (3.281)	GS 34.578 (32.240)	mem 76.027
Train: [7][100/1500]	BT 0.040 (0.452)	DT 0.000 (0.414)	loss 7.708 (7.823)	prob 4.816 (3.310)	GS 32.891 (32.237)	mem 76.112
Train: [7][110/1500]	BT 0.031 (0.441)	DT 0.000 (0.403)	loss 8.733 (7.892)	prob 2.366 (3.421)	GS 38.328 (31.562)	mem 77.817
Train: [7][120/1500]	BT 0.031 (0.407)	DT 0.000 (0.370)	loss 7.830 (7.823)	prob 3.589 (3.108)	GS 37.297 (31.984)	mem 77.913
Train: [7][130/1500]	BT 0.046 (0.436)	DT 0.014 (0.398)	loss 7.885 (7.845)	prob 4.172 (2.969)	GS 30.734 (32.069)	mem 76.052
Train: [7][140/1500]	BT 0.031 (0.473)	DT 0.001 (0.436)	loss 7.596 (7.880)	prob 2.848 (2.906)	GS 32.469 (32.841)	mem 76.307
Train: [7][150/1500]	BT 0.035 (0.444)	DT 0.000 (0.407)	loss 9.031 (7.900)	prob 1.475 (2.847)	GS 33.500 (32.803)	mem 76.318
Train: [7][160/1500]	BT 0.036 (0.436)	DT 0.000 (0.399)	loss 8.412 (7.884)	prob 2.382 (2.375)	GS 34.141 (32.655)	mem 75.436
Train: [7][170/1500]	BT 0.038 (0.412)	DT 0.000 (0.376)	loss 8.325 (7.886)	prob 2.607 (2.486)	GS 34.891 (32.719)	mem 75.438
Train: [7][180/1500]	BT 0.047 (0.415)	DT 0.007 (0.379)	loss 8.484 (7.964)	prob 2.685 (2.423)	GS 36.281 (32.664)	mem 75.488
Train: [7][190/1500]	BT 0.062 (0.411)	DT 0.011 (0.374)	loss 8.032 (7.992)	prob 2.461 (2.478)	GS 35.344 (32.932)	mem 75.508
Train: [7][200/1500]	BT 0.038 (0.393)	DT 0.001 (0.356)	loss 8.870 (8.017)	prob 2.250 (2.445)	GS 37.156 (32.912)	mem 75.515
Train: [7][210/1500]	BT 0.031 (0.399)	DT 0.000 (0.362)	loss 7.639 (7.877)	prob 2.042 (2.612)	GS 38.516 (32.489)	mem 75.566
Train: [7][220/1500]	BT 0.060 (0.383)	DT 0.001 (0.346)	loss 8.159 (7.907)	prob 2.679 (2.462)	GS 35.438 (32.241)	mem 75.573
Train: [7][230/1500]	BT 0.038 (0.386)	DT 0.001 (0.348)	loss 8.268 (7.949)	prob 3.287 (2.405)	GS 30.547 (32.206)	mem 75.576
Train: [7][240/1500]	BT 0.037 (0.381)	DT 0.001 (0.343)	loss 8.332 (7.955)	prob 2.260 (2.456)	GS 32.234 (32.318)	mem 75.643
Train: [7][250/1500]	BT 0.038 (0.367)	DT 0.001 (0.329)	loss 7.888 (7.960)	prob 2.255 (2.415)	GS 34.812 (32.567)	mem 75.655
Train: [7][260/1500]	BT 0.035 (0.371)	DT 0.000 (0.333)	loss 8.725 (8.103)	prob 3.478 (2.852)	GS 36.797 (32.656)	mem 75.817
Train: [7][270/1500]	BT 0.039 (0.359)	DT 0.001 (0.321)	loss 8.058 (7.986)	prob 2.591 (2.752)	GS 32.438 (33.166)	mem 75.831
Train: [7][280/1500]	BT 0.030 (0.376)	DT 0.000 (0.338)	loss 7.658 (7.987)	prob 4.251 (2.800)	GS 34.719 (32.831)	mem 76.017
Train: [7][290/1500]	BT 0.034 (0.364)	DT 0.000 (0.326)	loss 9.004 (8.000)	prob 3.198 (2.835)	GS 35.766 (32.823)	mem 76.034
Train: [7][300/1500]	BT 0.033 (0.363)	DT 0.000 (0.325)	loss 8.654 (8.001)	prob 3.240 (2.870)	GS 32.312 (32.651)	mem 76.121
Train: [7][310/1500]	BT 0.041 (0.352)	DT 0.001 (0.315)	loss 7.952 (8.235)	prob 3.141 (2.914)	GS 32.188 (34.333)	mem 76.128
Train: [7][320/1500]	BT 0.038 (0.342)	DT 0.001 (0.305)	loss 7.463 (8.030)	prob 3.460 (3.215)	GS 34.891 (33.505)	mem 76.135
Train: [7][330/1500]	BT 0.039 (0.353)	DT 0.001 (0.316)	loss 8.721 (8.088)	prob 3.399 (3.097)	GS 32.984 (33.097)	mem 76.273
Train: [7][340/1500]	BT 0.040 (0.344)	DT 0.001 (0.307)	loss 8.668 (8.102)	prob 2.858 (3.043)	GS 31.000 (32.871)	mem 76.286
Train: [7][350/1500]	BT 0.035 (0.343)	DT 0.001 (0.307)	loss 7.940 (8.129)	prob 3.712 (3.076)	GS 34.453 (32.933)	mem 75.470
Train: [7][360/1500]	BT 0.034 (0.335)	DT 0.001 (0.298)	loss 8.557 (8.326)	prob 2.486 (2.676)	GS 37.797 (34.491)	mem 75.470
Train: [7][370/1500]	BT 0.034 (0.327)	DT 0.001 (0.290)	loss 8.406 (8.284)	prob 3.011 (2.731)	GS 34.047 (33.937)	mem 75.470
Train: [7][380/1500]	BT 0.039 (0.330)	DT 0.001 (0.293)	loss 7.762 (8.264)	prob 3.696 (2.854)	GS 36.578 (33.503)	mem 75.502
Train: [7][390/1500]	BT 0.060 (0.323)	DT 0.002 (0.286)	loss 8.316 (8.229)	prob 3.692 (3.048)	GS 35.656 (33.108)	mem 75.513
Train: [7][400/1500]	BT 0.073 (0.330)	DT 0.017 (0.293)	loss 8.413 (8.214)	prob 3.080 (3.073)	GS 33.938 (33.149)	mem 75.554
Train: [7][410/1500]	BT 0.063 (0.324)	DT 0.015 (0.286)	loss 8.504 (8.013)	prob 4.059 (3.228)	GS 35.500 (32.806)	mem 75.559
Train: [7][420/1500]	BT 0.038 (0.327)	DT 0.001 (0.289)	loss 9.037 (8.122)	prob 3.602 (3.125)	GS 34.641 (32.940)	mem 75.609
Train: [7][430/1500]	BT 0.037 (0.321)	DT 0.001 (0.283)	loss 8.326 (8.113)	prob 4.277 (3.284)	GS 31.406 (32.777)	mem 75.614
Train: [7][440/1500]	BT 0.038 (0.318)	DT 0.001 (0.280)	loss 8.009 (8.080)	prob 4.098 (3.423)	GS 30.688 (32.748)	mem 75.634
Train: [7][450/1500]	BT 0.027 (0.318)	DT 0.000 (0.280)	loss 7.934 (8.086)	prob 3.706 (3.400)	GS 34.859 (32.822)	mem 75.686
Train: [7][460/1500]	BT 0.041 (0.312)	DT 0.001 (0.274)	loss 8.189 (8.085)	prob 3.614 (3.643)	GS 36.891 (31.641)	mem 75.697
Train: [7][470/1500]	BT 0.035 (0.321)	DT 0.001 (0.283)	loss 8.329 (8.088)	prob 3.146 (3.718)	GS 33.359 (31.714)	mem 75.790
Train: [7][480/1500]	BT 0.050 (0.319)	DT 0.001 (0.282)	loss 7.635 (8.126)	prob 3.644 (3.652)	GS 29.750 (31.857)	mem 75.891
Train: [7][490/1500]	BT 1.762 (0.318)	DT 1.725 (0.279)	loss 8.558 (8.132)	prob 4.048 (3.734)	GS 34.906 (31.989)	mem 75.965
Train: [7][500/1500]	BT 0.030 (0.319)	DT 0.000 (0.281)	loss 8.946 (8.127)	prob 3.628 (3.665)	GS 34.672 (32.131)	mem 76.631
Train: [7][510/1500]	BT 0.042 (0.313)	DT 0.000 (0.275)	loss 7.968 (8.069)	prob 4.103 (3.772)	GS 33.625 (32.986)	mem 76.688
Train: [7][520/1500]	BT 0.040 (0.314)	DT 0.001 (0.276)	loss 8.215 (8.118)	prob 4.164 (3.520)	GS 33.484 (33.868)	mem 77.186
Train: [7][530/1500]	BT 0.033 (0.308)	DT 0.001 (0.270)	loss 8.346 (8.121)	prob 3.835 (3.499)	GS 34.797 (33.583)	mem 77.198
Train: [7][540/1500]	BT 0.067 (0.308)	DT 0.011 (0.270)	loss 8.531 (8.129)	prob 3.612 (3.589)	GS 37.188 (33.098)	mem 77.349
Train: [7][550/1500]	BT 0.072 (0.314)	DT 0.003 (0.276)	loss 8.083 (8.090)	prob 4.884 (3.642)	GS 31.484 (33.067)	mem 77.531
Train: [7][560/1500]	BT 0.036 (0.309)	DT 0.000 (0.271)	loss 8.259 (8.110)	prob 3.980 (3.696)	GS 36.609 (33.400)	mem 77.536
Train: [7][570/1500]	BT 0.072 (0.318)	DT 0.004 (0.279)	loss 8.501 (8.070)	prob 4.206 (3.601)	GS 36.719 (32.494)	mem 76.683
Train: [7][580/1500]	BT 0.039 (0.313)	DT 0.001 (0.275)	loss 8.110 (8.073)	prob 4.559 (3.575)	GS 31.016 (32.322)	mem 76.682
Train: [7][590/1500]	BT 0.032 (0.326)	DT 0.001 (0.288)	loss 8.133 (8.045)	prob 3.055 (3.578)	GS 33.984 (32.816)	mem 76.748
Train: [7][600/1500]	BT 0.038 (0.324)	DT 0.001 (0.285)	loss 8.267 (8.030)	prob 3.884 (3.519)	GS 34.922 (32.952)	mem 76.780
Train: [7][610/1500]	BT 0.052 (0.324)	DT 0.010 (0.285)	loss 7.832 (7.893)	prob 3.861 (3.273)	GS 34.719 (32.434)	mem 76.821
Train: [7][620/1500]	BT 0.058 (0.319)	DT 0.011 (0.280)	loss 7.620 (7.886)	prob 3.613 (3.267)	GS 32.422 (32.518)	mem 76.824
Train: [7][630/1500]	BT 0.037 (0.320)	DT 0.002 (0.281)	loss 7.891 (7.877)	prob 3.706 (3.344)	GS 32.359 (32.466)	mem 76.876
Train: [7][640/1500]	BT 0.040 (0.324)	DT 0.001 (0.285)	loss 8.196 (7.921)	prob 3.062 (3.307)	GS 30.672 (32.058)	mem 76.948
Train: [7][650/1500]	BT 0.040 (0.320)	DT 0.001 (0.282)	loss 7.902 (7.949)	prob 4.571 (3.235)	GS 28.250 (32.351)	mem 76.994
Train: [7][660/1500]	BT 0.043 (0.322)	DT 0.001 (0.284)	loss 7.677 (7.906)	prob 3.254 (3.468)	GS 31.609 (32.383)	mem 77.062
Train: [7][670/1500]	BT 0.043 (0.318)	DT 0.001 (0.279)	loss 8.478 (7.860)	prob 2.961 (3.281)	GS 35.797 (33.334)	mem 77.073
Train: [7][680/1500]	BT 0.040 (0.318)	DT 0.001 (0.279)	loss 7.833 (7.831)	prob 3.943 (3.214)	GS 30.375 (32.842)	mem 77.186
Train: [7][690/1500]	BT 0.039 (0.314)	DT 0.001 (0.275)	loss 8.009 (7.883)	prob 3.369 (3.198)	GS 30.188 (32.662)	mem 77.192
Train: [7][700/1500]	BT 0.056 (0.313)	DT 0.002 (0.274)	loss 7.763 (7.842)	prob 3.464 (3.311)	GS 32.422 (32.251)	mem 77.231
Train: [7][710/1500]	BT 0.027 (0.321)	DT 0.000 (0.282)	loss 7.815 (7.662)	prob 2.891 (3.077)	GS 34.406 (32.855)	mem 76.941
Train: [7][720/1500]	BT 0.029 (0.319)	DT 0.000 (0.280)	loss 7.623 (7.670)	prob 3.419 (3.091)	GS 31.547 (32.161)	mem 77.184
Train: [7][730/1500]	BT 0.041 (0.318)	DT 0.001 (0.279)	loss 7.888 (7.709)	prob 3.584 (2.943)	GS 34.406 (32.177)	mem 77.183
Train: [7][740/1500]	BT 0.041 (0.318)	DT 0.001 (0.279)	loss 7.913 (7.708)	prob 2.905 (2.848)	GS 34.406 (32.177)	mem 77.759
Train: [7][750/1500]	BT 0.043 (0.314)	DT 0.001 (0.275)	loss 8.259 (7.781)	prob 2.968 (2.788)	GS 31.188 (32.523)	mem 77.797
Train: [7][760/1500]	BT 0.041 (0.314)	DT 0.001 (0.275)	loss 8.011 (7.987)	prob 3.069 (2.412)	GS 34.281 (33.231)	mem 78.818
Train: [7][770/1500]	BT 0.064 (0.316)	DT 0.006 (0.277)	loss 9.270 (8.025)	prob 2.819 (2.362)	GS 33.453 (32.641)	mem 78.533
Train: [7][780/1500]	BT 0.062 (0.319)	DT 0.012 (0.280)	loss 9.088 (8.048)	prob 1.948 (2.437)	GS 31.797 (32.339)	mem 79.679
Train: [7][790/1500]	BT 0.032 (0.334)	DT 0.000 (0.295)	loss 7.744 (8.046)	prob 3.724 (2.501)	GS 35.047 (33.091)	mem 98.253
Train: [7][800/1500]	BT 0.044 (0.330)	DT 0.001 (0.291)	loss 8.245 (8.055)	prob 3.409 (2.545)	GS 39.188 (33.079)	mem 100.364
Train: [7][810/1500]	BT 0.048 (0.327)	DT 0.001 (0.288)	loss 8.540 (8.006)	prob 3.652 (3.074)	GS 33.703 (31.748)	mem 102.126
Train: [7][820/1500]	BT 0.042 (0.329)	DT 0.001 (0.290)	loss 8.064 (8.022)	prob 2.905 (2.862)	GS 32.891 (32.026)	mem 103.865
Train: [7][830/1500]	BT 0.110 (0.326)	DT 0.025 (0.287)	loss 7.932 (8.050)	prob 2.582 (2.808)	GS 34.078 (32.319)	mem 80.014
Train: [7][840/1500]	BT 0.028 (0.329)	DT 0.000 (0.290)	loss 8.724 (8.080)	prob 2.798 (2.764)	GS 35.266 (32.492)	mem 78.693
Train: [7][850/1500]	BT 0.027 (0.326)	DT 0.000 (0.286)	loss 8.592 (8.087)	prob 2.744 (2.827)	GS 34.188 (32.545)	mem 78.701
Train: [7][860/1500]	BT 0.031 (0.328)	DT 0.000 (0.288)	loss 8.364 (8.058)	prob 3.438 (3.000)	GS 36.422 (32.692)	mem 78.815
Train: [7][870/1500]	BT 0.033 (0.324)	DT 0.000 (0.285)	loss 8.980 (8.104)	prob 3.331 (3.307)	GS 31.641 (32.211)	mem 78.823
Train: [7][880/1500]	BT 0.040 (0.321)	DT 0.001 (0.282)	loss 8.346 (8.099)	prob 4.077 (3.311)	GS 33.469 (32.348)	mem 78.829
Train: [7][890/1500]	BT 0.052 (0.321)	DT 0.013 (0.282)	loss 9.310 (8.068)	prob 3.183 (3.340)	GS 37.750 (32.445)	mem 78.891
Train: [7][900/1500]	BT 0.056 (0.318)	DT 0.010 (0.279)	loss 8.004 (8.094)	prob 4.274 (3.256)	GS 30.953 (32.611)	mem 78.901
Train: [7][910/1500]	BT 0.040 (0.323)	DT 0.001 (0.283)	loss 7.873 (7.949)	prob 2.807 (2.843)	GS 37.094 (33.294)	mem 78.029
Train: [7][920/1500]	BT 0.039 (0.319)	DT 0.001 (0.280)	loss 8.646 (8.073)	prob 2.821 (2.957)	GS 30.094 (33.048)	mem 78.033
Train: [7][930/1500]	BT 0.039 (0.323)	DT 0.001 (0.283)	loss 8.897 (8.129)	prob 4.092 (3.162)	GS 33.281 (33.091)	mem 78.184
Train: [7][940/1500]	BT 0.042 (0.321)	DT 0.001 (0.282)	loss 8.153 (8.115)	prob 3.863 (3.191)	GS 32.188 (32.798)	mem 78.606
Train: [7][950/1500]	BT 0.040 (0.321)	DT 0.001 (0.281)	loss 8.071 (8.111)	prob 2.188 (3.060)	GS 31.734 (33.006)	mem 80.043
Train: [7][960/1500]	BT 0.062 (0.319)	DT 0.012 (0.279)	loss 9.102 (8.356)	prob 3.852 (3.285)	GS 32.656 (32.138)	mem 81.043
Train: [7][970/1500]	BT 0.062 (0.325)	DT 0.011 (0.285)	loss 7.728 (8.075)	prob 4.264 (3.421)	GS 33.844 (32.411)	mem 78.170
Train: [7][980/1500]	BT 0.072 (0.322)	DT 0.001 (0.282)	loss 7.908 (8.167)	prob 4.002 (3.446)	GS 37.375 (32.480)	mem 78.173
Train: [7][990/1500]	BT 0.087 (0.321)	DT 0.002 (0.280)	loss 8.128 (8.185)	prob 3.721 (3.415)	GS 34.719 (32.735)	mem 78.179
Train: [7][1000/1500]	BT 0.037 (0.327)	DT 0.001 (0.286)	loss 8.338 (8.199)	prob 3.311 (3.391)	GS 33.281 (32.776)	mem 78.351
Train: [7][1010/1500]	BT 0.041 (0.324)	DT 0.001 (0.284)	loss 8.353 (8.117)	prob 4.151 (3.273)	GS 33.109 (32.714)	mem 78.328
Train: [7][1020/1500]	BT 0.037 (0.324)	DT 0.001 (0.283)	loss 8.714 (8.175)	prob 3.436 (3.522)	GS 32.469 (31.852)	mem 78.351
Train: [7][1030/1500]	BT 0.025 (0.321)	DT 0.000 (0.281)	loss 8.147 (8.110)	prob 3.234 (3.599)	GS 31.484 (31.749)	mem 78.388
Train: [7][1040/1500]	BT 0.064 (0.321)	DT 0.001 (0.281)	loss 7.867 (8.086)	prob 4.300 (3.633)	GS 31.781 (31.512)	mem 78.902
Train: [7][1050/1500]	BT 0.067 (0.322)	DT 0.016 (0.282)	loss 8.342 (8.083)	prob 4.323 (3.561)	GS 29.047 (31.518)	mem 80.155
Train: [7][1060/1500]	BT 0.065 (0.320)	DT 0.006 (0.279)	loss 8.702 (7.965)	prob 3.908 (3.878)	GS 37.328 (32.061)	mem 80.218
Train: [7][1070/1500]	BT 0.030 (0.326)	DT 0.000 (0.285)	loss 7.870 (7.887)	prob 3.908 (3.711)	GS 35.312 (32.505)	mem 78.669
Train: [7][1080/1500]	BT 0.038 (0.323)	DT 0.001 (0.283)	loss 7.875 (7.871)	prob 3.863 (3.605)	GS 34.812 (32.843)	mem 78.682
Train: [7][1090/1500]	BT 0.040 (0.323)	DT 0.001 (0.283)	loss 8.246 (7.895)	prob 3.077 (3.523)	GS 32.922 (32.469)	mem 78.752
Train: [7][1100/1500]	BT 0.039 (0.321)	DT 0.001 (0.280)	loss 8.287 (7.913)	prob 3.775 (3.499)	GS 29.969 (32.389)	mem 78.764
Train: [7][1110/1500]	BT 0.039 (0.323)	DT 0.001 (0.283)	loss 8.077 (8.015)	prob 4.277 (3.466)	GS 31.125 (32.420)	mem 77.888
Train: [7][1120/1500]	BT 0.039 (0.321)	DT 0.001 (0.281)	loss 8.174 (8.029)	prob 3.992 (3.496)	GS 34.953 (33.412)	mem 77.890
Train: [7][1130/1500]	BT 0.039 (0.319)	DT 0.001 (0.278)	loss 8.346 (8.022)	prob 3.515 (3.329)	GS 34.750 (33.364)	mem 77.877
Train: [7][1140/1500]	BT 0.069 (0.323)	DT 0.001 (0.282)	loss 7.772 (8.001)	prob 3.128 (3.264)	GS 30.781 (33.309)	mem 77.953
Train: [7][1150/1500]	BT 0.080 (0.321)	DT 0.006 (0.280)	loss 8.139 (8.002)	prob 3.494 (3.223)	GS 36.062 (33.058)	mem 77.958
Train: [7][1160/1500]	BT 0.039 (0.322)	DT 0.001 (0.282)	loss 9.024 (8.096)	prob 3.422 (3.306)	GS 33.391 (32.378)	mem 78.013
Train: [7][1170/1500]	BT 0.039 (0.320)	DT 0.001 (0.279)	loss 8.121 (7.978)	prob 3.880 (3.358)	GS 34.203 (32.433)	mem 78.016
Train: [7][1180/1500]	BT 0.039 (0.318)	DT 0.001 (0.277)	loss 7.422 (7.923)	prob 3.797 (3.250)	GS 35.438 (33.111)	mem 78.020
Train: [7][1190/1500]	BT 0.042 (0.320)	DT 0.001 (0.279)	loss 8.372 (7.937)	prob 2.988 (3.206)	GS 34.781 (33.257)	mem 78.142
Train: [7][1200/1500]	BT 0.040 (0.317)	DT 0.001 (0.277)	loss 7.801 (7.939)	prob 3.225 (3.279)	GS 36.719 (33.005)	mem 78.160
Train: [7][1210/1500]	BT 0.032 (0.318)	DT 0.000 (0.278)	loss 7.889 (8.051)	prob 3.649 (3.037)	GS 32.328 (33.866)	mem 78.271
Train: [7][1220/1500]	BT 0.031 (0.316)	DT 0.000 (0.276)	loss 8.638 (7.991)	prob 4.086 (3.132)	GS 37.156 (33.354)	mem 78.287
Train: [7][1230/1500]	BT 0.052 (0.320)	DT 0.012 (0.280)	loss 7.919 (7.947)	prob 3.149 (3.131)	GS 38.734 (33.411)	mem 78.412
Train: [7][1240/1500]	BT 0.035 (0.318)	DT 0.000 (0.278)	loss 8.021 (7.998)	prob 3.084 (2.981)	GS 32.359 (33.193)	mem 78.419
Train: [7][1250/1500]	BT 0.067 (0.323)	DT 0.014 (0.282)	loss 7.184 (7.960)	prob 3.969 (3.041)	GS 33.438 (33.403)	mem 78.554
Train: [7][1260/1500]	BT 0.068 (0.323)	DT 0.000 (0.282)	loss 8.323 (8.185)	prob 3.432 (3.265)	GS 39.500 (31.956)	mem 78.626
Train: [7][1270/1500]	BT 0.039 (0.342)	DT 0.001 (0.301)	loss 7.488 (7.956)	prob 3.663 (3.311)	GS 29.547 (31.950)	mem 83.235
Train: [7][1280/1500]	BT 0.071 (0.339)	DT 0.001 (0.298)	loss 8.650 (7.968)	prob 2.305 (3.207)	GS 37.031 (32.059)	mem 83.697
Train: [7][1290/1500]	BT 0.106 (0.337)	DT 0.005 (0.296)	loss 8.517 (7.943)	prob 3.087 (3.162)	GS 33.438 (32.317)	mem 84.989
Train: [7][1300/1500]	BT 0.130 (0.342)	DT 0.008 (0.301)	loss 7.348 (7.940)	prob 3.557 (3.196)	GS 32.922 (32.316)	mem 94.062
Train: [7][1310/1500]	BT 0.032 (0.357)	DT 0.000 (0.315)	loss 7.911 (7.958)	prob 3.018 (3.100)	GS 35.875 (31.691)	mem 114.768
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [7][1320/1500]	BT 0.039 (0.355)	DT 0.000 (0.313)	loss 8.995 (8.067)	prob 2.117 (2.940)	GS 34.141 (31.618)	mem 114.773
Train: [7][1330/1500]	BT 0.074 (0.358)	DT 0.003 (0.316)	loss 7.715 (7.989)	prob 3.716 (3.065)	GS 34.984 (31.982)	mem 114.857
Train: [7][1340/1500]	BT 0.053 (0.356)	DT 0.001 (0.314)	loss 8.946 (8.029)	prob 2.273 (3.087)	GS 34.344 (32.181)	mem 114.873
Train: [7][1350/1500]	BT 0.054 (0.354)	DT 0.001 (0.312)	loss 7.673 (8.022)	prob 3.827 (3.079)	GS 34.109 (32.241)	mem 114.888
Train: [7][1360/1500]	BT 0.068 (0.357)	DT 0.016 (0.315)	loss 8.061 (8.336)	prob 3.200 (2.747)	GS 30.422 (32.195)	mem 114.990
Train: [7][1370/1500]	BT 0.057 (0.355)	DT 0.001 (0.313)	loss 8.598 (8.272)	prob 3.512 (2.950)	GS 32.188 (33.074)	mem 114.960
Train: [7][1380/1500]	BT 0.063 (0.359)	DT 0.002 (0.316)	loss 8.193 (8.174)	prob 3.924 (3.043)	GS 31.469 (32.566)	mem 78.465
Train: [7][1390/1500]	BT 0.092 (0.357)	DT 0.003 (0.314)	loss 8.329 (8.132)	prob 3.586 (3.086)	GS 33.406 (32.848)	mem 78.477
Train: [7][1400/1500]	BT 12.318 (0.363)	DT 12.242 (0.320)	loss 8.645 (8.125)	prob 3.743 (3.100)	GS 34.312 (32.904)	mem 78.572
Train: [7][1410/1500]	BT 0.041 (0.369)	DT 0.001 (0.326)	loss 8.711 (8.370)	prob 2.769 (2.693)	GS 36.234 (32.656)	mem 78.714
Train: [7][1420/1500]	BT 0.040 (0.367)	DT 0.001 (0.324)	loss 8.683 (8.268)	prob 3.412 (2.743)	GS 32.828 (32.914)	mem 78.727
Train: [7][1430/1500]	BT 0.033 (0.366)	DT 0.000 (0.324)	loss 7.637 (8.218)	prob 3.605 (2.900)	GS 31.906 (32.874)	mem 78.838
Train: [7][1440/1500]	BT 0.038 (0.364)	DT 0.001 (0.321)	loss 8.735 (8.262)	prob 3.709 (2.977)	GS 31.031 (33.036)	mem 78.845
Train: [7][1450/1500]	BT 0.038 (0.362)	DT 0.001 (0.319)	loss 8.705 (8.252)	prob 3.026 (3.043)	GS 32.938 (32.989)	mem 78.851
Train: [7][1460/1500]	BT 0.035 (0.363)	DT 0.001 (0.321)	loss 8.846 (8.321)	prob 3.730 (3.441)	GS 35.906 (32.856)	mem 75.738
Train: [7][1470/1500]	BT 0.039 (0.361)	DT 0.001 (0.319)	loss 8.733 (8.247)	prob 3.331 (3.460)	GS 35.141 (32.528)	mem 75.694
Train: [7][1480/1500]	BT 0.030 (0.361)	DT 0.000 (0.318)	loss 8.299 (8.247)	prob 3.307 (3.449)	GS 32.188 (32.070)	mem 19.794
Train: [7][1490/1500]	BT 0.027 (0.359)	DT 0.000 (0.316)	loss 7.610 (8.238)	prob 3.851 (3.476)	GS 35.781 (32.189)	mem 19.810
Train: [7][1500/1500]	BT 0.040 (0.357)	DT 0.000 (0.315)	loss 8.396 (8.245)	prob 4.245 (3.448)	GS 32.031 (32.229)	mem 11.323
Train: [7][1510/1500]	BT 0.020 (0.355)	DT 0.000 (0.312)	loss 8.124 (7.964)	prob 3.284 (3.881)	GS 32.469 (31.828)	mem 11.332
epoch 7, total time 535.86
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [8][1/1500]	BT 21.804 (21.804)	DT 21.705 (21.705)	loss 7.519 (7.519)	prob 4.374 (4.374)	GS 30.656 (30.656)	mem 75.309
Train: [8][10/1500]	BT 0.039 (2.822)	DT 0.001 (2.767)	loss 8.233 (8.068)	prob 3.248 (3.241)	GS 36.922 (33.609)	mem 75.544
Train: [8][20/1500]	BT 0.038 (1.430)	DT 0.001 (1.384)	loss 8.314 (8.006)	prob 3.235 (3.201)	GS 34.109 (33.424)	mem 75.556
Train: [8][30/1500]	BT 0.038 (0.988)	DT 0.000 (0.944)	loss 8.195 (8.044)	prob 3.786 (3.176)	GS 29.344 (32.753)	mem 75.600
Train: [8][40/1500]	BT 0.040 (0.803)	DT 0.001 (0.760)	loss 8.757 (8.069)	prob 4.312 (3.265)	GS 31.672 (32.748)	mem 75.672
Train: [8][50/1500]	BT 0.038 (0.674)	DT 0.000 (0.633)	loss 9.028 (8.079)	prob 3.463 (3.364)	GS 34.359 (32.729)	mem 75.726
Train: [8][60/1500]	BT 0.039 (0.605)	DT 0.001 (0.563)	loss 8.358 (7.978)	prob 3.770 (3.637)	GS 35.938 (31.823)	mem 75.867
Train: [8][70/1500]	BT 0.039 (0.550)	DT 0.001 (0.509)	loss 7.966 (8.025)	prob 4.539 (3.538)	GS 32.484 (31.992)	mem 75.910
Train: [8][80/1500]	BT 0.039 (0.497)	DT 0.001 (0.456)	loss 8.113 (8.151)	prob 4.570 (3.533)	GS 35.062 (32.406)	mem 75.943
Train: [8][90/1500]	BT 0.037 (0.488)	DT 0.001 (0.447)	loss 8.242 (8.153)	prob 4.843 (3.518)	GS 30.875 (32.587)	mem 75.054
Train: [8][100/1500]	BT 0.037 (0.455)	DT 0.001 (0.415)	loss 8.351 (8.135)	prob 3.569 (3.495)	GS 34.562 (32.482)	mem 75.073
Train: [8][110/1500]	BT 0.038 (0.441)	DT 0.001 (0.401)	loss 8.365 (8.344)	prob 3.570 (3.331)	GS 34.125 (31.780)	mem 75.131
Train: [8][120/1500]	BT 0.038 (0.408)	DT 0.001 (0.368)	loss 8.483 (8.268)	prob 3.463 (3.341)	GS 34.266 (32.271)	mem 75.134
Train: [8][130/1500]	BT 0.058 (0.384)	DT 0.021 (0.345)	loss 8.155 (8.173)	prob 4.398 (3.387)	GS 30.828 (31.993)	mem 75.144
Train: [8][140/1500]	BT 0.039 (0.396)	DT 0.001 (0.357)	loss 8.009 (8.217)	prob 4.358 (3.296)	GS 33.000 (32.255)	mem 75.211
Train: [8][150/1500]	BT 0.038 (0.372)	DT 0.001 (0.333)	loss 7.900 (8.191)	prob 3.418 (3.342)	GS 27.469 (32.219)	mem 75.218
Train: [8][160/1500]	BT 0.027 (0.401)	DT 0.000 (0.362)	loss 8.082 (8.219)	prob 2.691 (3.242)	GS 35.484 (32.509)	mem 75.454
Train: [8][170/1500]	BT 0.023 (0.379)	DT 0.000 (0.341)	loss 8.248 (8.178)	prob 4.302 (3.250)	GS 32.703 (32.570)	mem 75.463
Train: [8][180/1500]	BT 0.034 (0.360)	DT 0.001 (0.322)	loss 7.803 (8.120)	prob 3.935 (3.265)	GS 37.172 (32.929)	mem 75.472
Train: [8][190/1500]	BT 0.024 (0.366)	DT 0.000 (0.329)	loss 7.848 (8.125)	prob 3.429 (3.194)	GS 34.219 (32.969)	mem 75.669
Train: [8][200/1500]	BT 0.033 (0.349)	DT 0.000 (0.313)	loss 8.110 (8.130)	prob 3.179 (3.112)	GS 34.250 (32.846)	mem 75.680
Train: [8][210/1500]	BT 0.041 (0.349)	DT 0.001 (0.312)	loss 8.503 (8.166)	prob 3.592 (2.894)	GS 34.031 (32.908)	mem 75.775
Train: [8][220/1500]	BT 0.040 (0.335)	DT 0.001 (0.298)	loss 7.771 (8.117)	prob 3.217 (3.000)	GS 35.078 (33.152)	mem 75.784
Train: [8][230/1500]	BT 0.041 (0.338)	DT 0.001 (0.301)	loss 8.432 (8.067)	prob 3.044 (3.105)	GS 34.703 (32.951)	mem 76.841
Train: [8][240/1500]	BT 0.042 (0.325)	DT 0.001 (0.288)	loss 7.952 (8.051)	prob 3.593 (3.109)	GS 33.625 (33.098)	mem 77.070
Train: [8][250/1500]	BT 0.035 (0.314)	DT 0.000 (0.277)	loss 8.660 (8.090)	prob 3.768 (2.973)	GS 31.125 (33.088)	mem 77.295
Train: [8][260/1500]	BT 0.064 (0.335)	DT 0.012 (0.298)	loss 8.550 (8.082)	prob 2.339 (2.797)	GS 32.750 (33.258)	mem 78.696
Train: [8][270/1500]	BT 0.048 (0.358)	DT 0.001 (0.320)	loss 7.613 (7.959)	prob 2.658 (2.652)	GS 29.844 (33.142)	mem 94.858
Train: [8][280/1500]	BT 0.042 (0.347)	DT 0.001 (0.308)	loss 7.897 (7.969)	prob 3.539 (2.732)	GS 33.453 (33.025)	mem 96.883
Train: [8][290/1500]	BT 0.048 (0.353)	DT 0.002 (0.315)	loss 8.351 (7.992)	prob 2.699 (2.608)	GS 30.844 (32.707)	mem 111.810
Train: [8][300/1500]	BT 0.052 (0.343)	DT 0.005 (0.304)	loss 8.020 (7.963)	prob 2.168 (2.539)	GS 29.375 (32.403)	mem 111.811
Train: [8][310/1500]	BT 0.045 (0.333)	DT 0.001 (0.294)	loss 8.569 (8.110)	prob 1.931 (2.154)	GS 32.812 (31.986)	mem 111.815
Train: [8][320/1500]	BT 0.044 (0.341)	DT 0.001 (0.302)	loss 8.466 (8.030)	prob 2.677 (2.350)	GS 38.594 (32.297)	mem 111.900
Train: [8][330/1500]	BT 0.056 (0.332)	DT 0.001 (0.293)	loss 7.630 (7.976)	prob 2.348 (2.246)	GS 31.812 (32.147)	mem 111.868
Train: [8][340/1500]	BT 0.086 (0.355)	DT 0.004 (0.315)	loss 8.270 (7.938)	prob 2.828 (2.314)	GS 31.562 (32.201)	mem 112.125
Train: [8][350/1500]	BT 0.031 (0.378)	DT 0.000 (0.337)	loss 8.908 (7.914)	prob 2.893 (2.297)	GS 35.516 (32.412)	mem 115.051
Train: [8][360/1500]	BT 0.037 (0.368)	DT 0.001 (0.328)	loss 8.440 (8.100)	prob 2.387 (1.960)	GS 36.891 (33.298)	mem 113.383
Train: [8][370/1500]	BT 0.040 (0.359)	DT 0.001 (0.319)	loss 8.570 (8.120)	prob 2.516 (2.153)	GS 32.422 (32.597)	mem 111.613
Train: [8][380/1500]	BT 0.028 (0.367)	DT 0.000 (0.327)	loss 7.736 (8.077)	prob 3.265 (2.244)	GS 31.547 (32.422)	mem 114.373
Train: [8][390/1500]	BT 0.059 (0.359)	DT 0.004 (0.319)	loss 7.256 (8.033)	prob 2.422 (2.248)	GS 33.438 (32.571)	mem 114.355
Train: [8][400/1500]	BT 0.097 (0.366)	DT 0.016 (0.325)	loss 7.914 (8.047)	prob 2.519 (2.260)	GS 33.078 (32.523)	mem 114.485
Train: [8][410/1500]	BT 0.073 (0.359)	DT 0.001 (0.317)	loss 8.431 (8.122)	prob 2.998 (2.084)	GS 33.828 (33.039)	mem 114.497
Train: [8][420/1500]	BT 0.042 (0.366)	DT 0.001 (0.324)	loss 7.932 (8.115)	prob 3.275 (2.197)	GS 36.172 (33.366)	mem 114.593
Train: [8][430/1500]	BT 0.037 (0.358)	DT 0.000 (0.316)	loss 8.277 (8.182)	prob 2.825 (2.168)	GS 31.641 (33.370)	mem 114.608
Train: [8][440/1500]	BT 0.040 (0.356)	DT 0.001 (0.314)	loss 8.697 (8.168)	prob 2.244 (2.355)	GS 34.172 (33.350)	mem 114.692
Train: [8][450/1500]	BT 0.047 (0.355)	DT 0.001 (0.313)	loss 8.025 (8.197)	prob 3.591 (2.423)	GS 36.016 (33.265)	mem 115.356
Train: [8][460/1500]	BT 0.073 (0.349)	DT 0.001 (0.306)	loss 8.902 (8.082)	prob 2.929 (3.077)	GS 35.359 (32.538)	mem 115.285
Train: [8][470/1500]	BT 0.039 (0.351)	DT 0.001 (0.308)	loss 8.493 (8.172)	prob 3.288 (3.063)	GS 35.609 (32.649)	mem 114.531
Train: [8][480/1500]	BT 0.039 (0.345)	DT 0.001 (0.302)	loss 8.311 (8.176)	prob 3.380 (3.118)	GS 34.859 (32.635)	mem 114.537
Train: [8][490/1500]	BT 0.049 (0.344)	DT 0.001 (0.302)	loss 9.241 (8.199)	prob 2.345 (3.060)	GS 35.203 (32.725)	mem 75.587
Train: [8][500/1500]	BT 0.068 (0.356)	DT 0.001 (0.314)	loss 8.000 (8.166)	prob 3.459 (3.066)	GS 35.172 (32.758)	mem 76.101
Train: [8][510/1500]	BT 0.039 (0.351)	DT 0.001 (0.309)	loss 8.893 (8.144)	prob 3.146 (3.240)	GS 34.062 (33.627)	mem 76.139
Train: [8][520/1500]	BT 0.040 (0.351)	DT 0.001 (0.308)	loss 8.689 (8.244)	prob 3.249 (3.220)	GS 35.656 (33.938)	mem 76.426
Train: [8][530/1500]	BT 0.039 (0.347)	DT 0.001 (0.304)	loss 7.649 (8.221)	prob 3.920 (3.132)	GS 36.266 (33.594)	mem 76.440
Train: [8][540/1500]	BT 0.039 (0.346)	DT 0.001 (0.303)	loss 7.999 (8.198)	prob 3.960 (3.210)	GS 30.812 (33.011)	mem 76.476
Train: [8][550/1500]	BT 0.040 (0.344)	DT 0.001 (0.301)	loss 7.847 (8.186)	prob 4.187 (3.253)	GS 33.188 (32.944)	mem 76.495
Train: [8][560/1500]	BT 0.039 (0.342)	DT 0.000 (0.300)	loss 8.696 (8.267)	prob 3.286 (3.478)	GS 33.875 (31.261)	mem 76.538
Train: [8][570/1500]	BT 0.041 (0.338)	DT 0.001 (0.295)	loss 8.547 (8.284)	prob 3.360 (3.341)	GS 37.922 (32.395)	mem 76.590
Train: [8][580/1500]	BT 0.042 (0.333)	DT 0.001 (0.291)	loss 8.389 (8.242)	prob 3.272 (3.469)	GS 34.297 (32.196)	mem 76.621
Train: [8][590/1500]	BT 0.038 (0.335)	DT 0.001 (0.292)	loss 8.321 (8.204)	prob 3.893 (3.553)	GS 32.141 (32.307)	mem 76.726
Train: [8][600/1500]	BT 0.039 (0.331)	DT 0.001 (0.288)	loss 7.848 (8.181)	prob 4.509 (3.563)	GS 28.578 (32.305)	mem 76.741
Train: [8][610/1500]	BT 0.038 (0.332)	DT 0.000 (0.289)	loss 8.790 (8.285)	prob 3.903 (3.724)	GS 32.609 (31.456)	mem 76.720
Train: [8][620/1500]	BT 0.058 (0.327)	DT 0.015 (0.285)	loss 7.938 (8.254)	prob 3.206 (3.687)	GS 32.812 (31.529)	mem 76.735
Train: [8][630/1500]	BT 0.087 (0.338)	DT 0.001 (0.295)	loss 8.175 (8.165)	prob 3.663 (3.769)	GS 35.281 (32.087)	mem 76.845
Train: [8][640/1500]	BT 0.094 (0.334)	DT 0.009 (0.290)	loss 8.196 (8.168)	prob 4.524 (3.677)	GS 32.719 (32.153)	mem 76.852
Train: [8][650/1500]	BT 0.033 (0.378)	DT 0.001 (0.334)	loss 8.955 (8.161)	prob 2.919 (3.600)	GS 38.172 (32.509)	mem 77.229
Train: [8][660/1500]	BT 0.035 (0.373)	DT 0.001 (0.329)	loss 8.543 (8.103)	prob 2.850 (3.271)	GS 34.219 (32.950)	mem 77.261
Train: [8][670/1500]	BT 0.033 (0.368)	DT 0.001 (0.324)	loss 7.739 (8.120)	prob 3.925 (3.416)	GS 30.984 (32.826)	mem 76.493
Train: [8][680/1500]	BT 0.040 (0.368)	DT 0.001 (0.324)	loss 7.494 (8.152)	prob 3.975 (3.503)	GS 33.891 (32.660)	mem 76.356
Train: [8][690/1500]	BT 0.051 (0.364)	DT 0.001 (0.320)	loss 7.990 (8.118)	prob 3.912 (3.556)	GS 33.172 (32.485)	mem 76.373
Train: [8][700/1500]	BT 0.040 (0.365)	DT 0.001 (0.321)	loss 7.706 (8.065)	prob 3.806 (3.574)	GS 31.281 (32.455)	mem 76.411
Train: [8][710/1500]	BT 0.040 (0.360)	DT 0.001 (0.317)	loss 7.550 (8.179)	prob 3.874 (3.561)	GS 34.406 (31.877)	mem 76.418
Train: [8][720/1500]	BT 1.799 (0.360)	DT 1.760 (0.317)	loss 7.942 (8.143)	prob 4.143 (3.418)	GS 31.906 (31.864)	mem 76.458
Train: [8][730/1500]	BT 0.040 (0.356)	DT 0.001 (0.312)	loss 8.063 (8.104)	prob 2.782 (3.426)	GS 34.656 (32.201)	mem 76.456
Train: [8][740/1500]	BT 0.040 (0.356)	DT 0.001 (0.313)	loss 8.131 (8.083)	prob 3.832 (3.367)	GS 36.984 (32.383)	mem 76.481
Train: [8][750/1500]	BT 0.079 (0.353)	DT 0.001 (0.310)	loss 9.019 (8.076)	prob 2.511 (3.393)	GS 32.812 (32.218)	mem 76.497
Train: [8][760/1500]	BT 0.039 (0.354)	DT 0.001 (0.311)	loss 8.426 (8.083)	prob 2.843 (3.956)	GS 33.078 (31.102)	mem 76.550
Train: [8][770/1500]	BT 0.050 (0.357)	DT 0.009 (0.313)	loss 8.182 (8.114)	prob 3.926 (3.562)	GS 32.359 (32.643)	mem 76.605
Train: [8][780/1500]	BT 0.047 (0.353)	DT 0.001 (0.309)	loss 7.898 (8.126)	prob 3.639 (3.417)	GS 34.938 (32.445)	mem 76.613
Train: [8][790/1500]	BT 0.040 (0.355)	DT 0.001 (0.312)	loss 7.911 (8.069)	prob 2.787 (3.343)	GS 31.109 (32.252)	mem 76.754
Train: [8][800/1500]	BT 0.042 (0.352)	DT 0.001 (0.309)	loss 8.559 (8.079)	prob 3.317 (3.239)	GS 35.750 (32.304)	mem 77.444
Train: [8][810/1500]	BT 0.042 (0.354)	DT 0.001 (0.310)	loss 8.470 (8.009)	prob 3.074 (3.046)	GS 33.547 (31.980)	mem 79.191
Train: [8][820/1500]	BT 0.045 (0.351)	DT 0.001 (0.308)	loss 7.982 (8.080)	prob 2.982 (2.968)	GS 36.781 (32.316)	mem 79.888
Train: [8][830/1500]	BT 0.034 (0.347)	DT 0.001 (0.304)	loss 7.604 (8.010)	prob 3.747 (2.945)	GS 31.562 (32.512)	mem 81.333
Train: [8][840/1500]	BT 2.637 (0.352)	DT 2.590 (0.309)	loss 9.081 (8.035)	prob 0.982 (2.868)	GS 33.859 (32.413)	mem 93.143
Train: [8][850/1500]	BT 0.049 (0.359)	DT 0.001 (0.316)	loss 8.403 (8.055)	prob 3.394 (2.876)	GS 33.047 (32.608)	mem 108.035
Train: [8][860/1500]	BT 0.046 (0.356)	DT 0.001 (0.312)	loss 8.439 (7.973)	prob 2.870 (3.190)	GS 35.188 (31.903)	mem 110.410
Train: [8][870/1500]	BT 0.046 (0.352)	DT 0.001 (0.309)	loss 8.510 (8.024)	prob 2.665 (2.795)	GS 36.156 (32.817)	mem 112.893
Train: [8][880/1500]	BT 0.044 (0.355)	DT 0.001 (0.312)	loss 8.065 (7.996)	prob 3.007 (2.903)	GS 29.188 (32.704)	mem 113.834
Train: [8][890/1500]	BT 0.045 (0.352)	DT 0.001 (0.308)	loss 7.762 (7.996)	prob 3.260 (2.900)	GS 29.734 (32.765)	mem 113.839
Train: [8][900/1500]	BT 0.093 (0.359)	DT 0.004 (0.315)	loss 8.635 (8.084)	prob 2.456 (2.820)	GS 34.625 (32.791)	mem 112.983
Train: [8][910/1500]	BT 0.118 (0.356)	DT 0.029 (0.312)	loss 8.268 (8.085)	prob 3.910 (2.407)	GS 31.891 (32.712)	mem 112.986
Train: [8][920/1500]	BT 0.113 (0.353)	DT 0.010 (0.309)	loss 8.063 (8.077)	prob 2.448 (2.675)	GS 34.391 (32.573)	mem 112.993
Train: [8][930/1500]	BT 0.040 (0.355)	DT 0.001 (0.311)	loss 8.229 (8.127)	prob 3.770 (2.648)	GS 35.484 (32.488)	mem 84.050
Train: [8][940/1500]	BT 0.040 (0.352)	DT 0.001 (0.308)	loss 8.084 (8.109)	prob 3.322 (2.701)	GS 31.922 (32.714)	mem 83.998
Train: [8][950/1500]	BT 0.051 (0.357)	DT 0.001 (0.313)	loss 8.845 (8.140)	prob 2.951 (2.762)	GS 35.516 (32.577)	mem 76.443
Train: [8][960/1500]	BT 0.067 (0.355)	DT 0.006 (0.310)	loss 7.901 (8.233)	prob 3.968 (3.066)	GS 33.125 (32.241)	mem 76.447
Train: [8][970/1500]	BT 0.072 (0.358)	DT 0.006 (0.314)	loss 8.624 (8.169)	prob 3.617 (3.148)	GS 33.188 (32.688)	mem 76.513
Train: [8][980/1500]	BT 0.035 (0.355)	DT 0.000 (0.311)	loss 9.300 (8.226)	prob 2.552 (3.227)	GS 33.562 (32.499)	mem 76.520
Train: [8][990/1500]	BT 0.031 (0.358)	DT 0.001 (0.314)	loss 8.808 (8.230)	prob 3.837 (3.176)	GS 35.078 (32.430)	mem 76.759
Train: [8][1000/1500]	BT 0.036 (0.356)	DT 0.000 (0.311)	loss 7.974 (8.184)	prob 4.121 (3.201)	GS 39.469 (32.395)	mem 76.853
Train: [8][1010/1500]	BT 0.134 (0.353)	DT 0.013 (0.308)	loss 7.763 (8.416)	prob 2.604 (2.750)	GS 34.016 (33.288)	mem 76.882
Train: [8][1020/1500]	BT 0.031 (0.358)	DT 0.000 (0.314)	loss 8.187 (8.388)	prob 3.968 (2.852)	GS 34.984 (32.870)	mem 79.687
Train: [8][1030/1500]	BT 0.029 (0.355)	DT 0.000 (0.311)	loss 8.525 (8.339)	prob 4.274 (2.955)	GS 31.031 (32.884)	mem 76.855
Train: [8][1040/1500]	BT 0.037 (0.354)	DT 0.001 (0.310)	loss 7.770 (8.284)	prob 3.465 (3.028)	GS 32.375 (32.743)	mem 76.897
Train: [8][1050/1500]	BT 0.038 (0.352)	DT 0.001 (0.308)	loss 9.350 (8.311)	prob 2.463 (3.067)	GS 33.750 (32.529)	mem 76.891
Train: [8][1060/1500]	BT 0.076 (0.352)	DT 0.010 (0.308)	loss 8.394 (8.190)	prob 3.572 (3.115)	GS 32.641 (31.677)	mem 76.993
Train: [8][1070/1500]	BT 0.071 (0.353)	DT 0.011 (0.309)	loss 8.036 (8.072)	prob 2.867 (3.211)	GS 34.156 (32.134)	mem 77.023
Train: [8][1080/1500]	BT 0.075 (0.350)	DT 0.011 (0.306)	loss 8.092 (8.125)	prob 4.316 (3.357)	GS 33.359 (31.916)	mem 77.028
Train: [8][1090/1500]	BT 0.049 (0.354)	DT 0.006 (0.310)	loss 8.422 (8.125)	prob 4.046 (3.362)	GS 33.094 (32.246)	mem 77.129
Train: [8][1100/1500]	BT 0.037 (0.351)	DT 0.000 (0.307)	loss 8.377 (8.127)	prob 4.145 (3.336)	GS 30.016 (32.196)	mem 77.134
Train: [8][1110/1500]	BT 0.034 (0.361)	DT 0.000 (0.317)	loss 8.496 (8.049)	prob 3.664 (3.741)	GS 33.000 (32.469)	mem 76.483
Train: [8][1120/1500]	BT 0.027 (0.358)	DT 0.000 (0.314)	loss 7.704 (8.001)	prob 3.797 (3.525)	GS 31.109 (32.809)	mem 76.504
Train: [8][1130/1500]	BT 0.049 (0.361)	DT 0.008 (0.317)	loss 7.969 (7.993)	prob 3.859 (3.506)	GS 32.297 (32.524)	mem 76.595
Train: [8][1140/1500]	BT 0.068 (0.358)	DT 0.004 (0.314)	loss 8.323 (8.057)	prob 3.051 (3.396)	GS 35.203 (32.593)	mem 76.600
Train: [8][1150/1500]	BT 0.068 (0.356)	DT 0.005 (0.312)	loss 7.972 (8.104)	prob 4.103 (3.285)	GS 32.344 (32.659)	mem 76.605
Train: [8][1160/1500]	BT 0.022 (0.359)	DT 0.000 (0.315)	loss 8.322 (7.997)	prob 3.577 (3.699)	GS 37.391 (32.261)	mem 76.641
Train: [8][1170/1500]	BT 0.026 (0.357)	DT 0.000 (0.314)	loss 8.609 (8.066)	prob 3.346 (3.284)	GS 38.125 (33.469)	mem 76.724
Train: [8][1180/1500]	BT 0.038 (0.355)	DT 0.001 (0.312)	loss 8.255 (8.045)	prob 3.605 (3.339)	GS 33.734 (32.807)	mem 76.759
Train: [8][1190/1500]	BT 0.040 (0.356)	DT 0.001 (0.313)	loss 8.291 (8.083)	prob 4.158 (3.341)	GS 31.938 (32.744)	mem 76.911
Train: [8][1200/1500]	BT 0.041 (0.354)	DT 0.001 (0.310)	loss 8.927 (8.095)	prob 3.316 (3.332)	GS 42.109 (32.707)	mem 76.884
Train: [8][1210/1500]	BT 0.031 (0.354)	DT 0.001 (0.310)	loss 8.119 (7.944)	prob 3.610 (3.118)	GS 39.234 (33.672)	mem 77.003
Train: [8][1220/1500]	BT 0.042 (0.351)	DT 0.001 (0.308)	loss 7.705 (8.035)	prob 3.665 (3.129)	GS 34.219 (33.205)	mem 77.017
Train: [8][1230/1500]	BT 0.039 (0.349)	DT 0.001 (0.305)	loss 8.545 (8.075)	prob 3.689 (3.004)	GS 35.016 (33.401)	mem 77.005
Train: [8][1240/1500]	BT 0.070 (0.351)	DT 0.017 (0.308)	loss 8.512 (8.107)	prob 3.242 (2.969)	GS 34.000 (33.256)	mem 77.086
Train: [8][1250/1500]	BT 0.102 (0.349)	DT 0.027 (0.306)	loss 7.750 (8.085)	prob 3.180 (2.967)	GS 32.859 (33.145)	mem 77.100
Train: [8][1260/1500]	BT 0.038 (0.350)	DT 0.001 (0.306)	loss 8.053 (8.140)	prob 2.760 (2.760)	GS 34.172 (33.341)	mem 77.211
Train: [8][1270/1500]	BT 0.038 (0.348)	DT 0.001 (0.304)	loss 7.846 (8.092)	prob 3.262 (2.859)	GS 36.781 (33.356)	mem 77.223
Train: [8][1280/1500]	BT 0.039 (0.348)	DT 0.001 (0.304)	loss 8.341 (8.093)	prob 2.939 (2.977)	GS 31.188 (33.048)	mem 76.418
Train: [8][1290/1500]	BT 0.039 (0.346)	DT 0.001 (0.302)	loss 8.318 (8.111)	prob 2.262 (2.978)	GS 37.531 (33.117)	mem 76.421
Train: [8][1300/1500]	BT 0.039 (0.346)	DT 0.001 (0.302)	loss 8.227 (8.114)	prob 3.215 (3.008)	GS 32.281 (32.954)	mem 76.439
Train: [8][1310/1500]	BT 0.039 (0.344)	DT 0.001 (0.300)	loss 8.077 (8.061)	prob 2.913 (2.796)	GS 35.656 (33.820)	mem 76.453
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [8][1320/1500]	BT 0.039 (0.342)	DT 0.001 (0.298)	loss 8.455 (8.144)	prob 2.512 (2.895)	GS 29.719 (33.323)	mem 76.464
Train: [8][1330/1500]	BT 0.036 (0.343)	DT 0.001 (0.299)	loss 8.202 (8.188)	prob 3.591 (2.786)	GS 35.891 (33.453)	mem 76.523
Train: [8][1340/1500]	BT 0.034 (0.340)	DT 0.001 (0.297)	loss 8.890 (8.222)	prob 2.842 (2.752)	GS 33.188 (33.202)	mem 76.530
Train: [8][1350/1500]	BT 0.048 (0.340)	DT 0.001 (0.296)	loss 8.632 (8.196)	prob 3.638 (2.823)	GS 34.469 (33.036)	mem 76.606
Train: [8][1360/1500]	BT 0.033 (0.345)	DT 0.001 (0.302)	loss 7.782 (7.969)	prob 3.611 (3.033)	GS 30.859 (33.845)	mem 76.707
Train: [8][1370/1500]	BT 0.041 (0.343)	DT 0.001 (0.299)	loss 7.456 (8.087)	prob 4.607 (3.107)	GS 38.109 (33.628)	mem 76.721
Train: [8][1380/1500]	BT 0.040 (0.343)	DT 0.001 (0.299)	loss 7.864 (8.130)	prob 3.658 (3.006)	GS 34.406 (33.622)	mem 76.790
Train: [8][1390/1500]	BT 0.040 (0.341)	DT 0.001 (0.297)	loss 8.355 (8.108)	prob 2.280 (2.930)	GS 30.812 (33.553)	mem 76.804
Train: [8][1400/1500]	BT 0.041 (0.339)	DT 0.001 (0.296)	loss 8.184 (8.089)	prob 2.974 (2.903)	GS 29.891 (33.227)	mem 76.858
Train: [8][1410/1500]	BT 0.052 (0.341)	DT 0.011 (0.298)	loss 8.062 (7.879)	prob 3.402 (3.056)	GS 34.438 (32.981)	mem 76.937
Train: [8][1420/1500]	BT 0.073 (0.340)	DT 0.011 (0.296)	loss 8.439 (8.054)	prob 2.903 (2.828)	GS 32.562 (32.812)	mem 76.969
Train: [8][1430/1500]	BT 0.039 (0.340)	DT 0.001 (0.297)	loss 8.872 (8.027)	prob 2.598 (2.835)	GS 33.719 (32.945)	mem 77.082
Train: [8][1440/1500]	BT 0.030 (0.338)	DT 0.000 (0.295)	loss 7.696 (8.014)	prob 3.563 (2.820)	GS 36.844 (33.236)	mem 77.089
Train: [8][1450/1500]	BT 0.039 (0.339)	DT 0.001 (0.296)	loss 8.691 (8.052)	prob 2.396 (2.723)	GS 31.031 (33.421)	mem 77.122
Train: [8][1460/1500]	BT 0.062 (0.338)	DT 0.011 (0.295)	loss 8.661 (8.194)	prob 3.284 (3.053)	GS 31.328 (31.312)	mem 77.066
Train: [8][1470/1500]	BT 0.065 (0.336)	DT 0.014 (0.293)	loss 8.017 (8.168)	prob 3.479 (3.075)	GS 35.531 (31.634)	mem 77.074
Train: [8][1480/1500]	BT 0.022 (0.342)	DT 0.000 (0.299)	loss 7.731 (8.204)	prob 2.744 (2.865)	GS 36.203 (31.799)	mem 11.477
Train: [8][1490/1500]	BT 0.027 (0.340)	DT 0.000 (0.297)	loss 7.589 (8.216)	prob 3.974 (2.805)	GS 28.438 (32.086)	mem 11.482
Train: [8][1500/1500]	BT 0.027 (0.338)	DT 0.000 (0.295)	loss 9.095 (8.244)	prob 3.315 (2.788)	GS 36.531 (32.302)	mem 11.487
Train: [8][1510/1500]	BT 0.034 (0.337)	DT 0.001 (0.293)	loss 9.017 (8.299)	prob 2.482 (2.641)	GS 34.188 (35.344)	mem 11.442
epoch 8, total time 508.52
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [9][1/1500]	BT 23.506 (23.506)	DT 23.454 (23.454)	loss 7.264 (7.264)	prob 4.286 (4.286)	GS 31.484 (31.484)	mem 75.737
Train: [9][10/1500]	BT 0.039 (2.451)	DT 0.001 (2.410)	loss 7.698 (7.896)	prob 3.948 (2.965)	GS 35.172 (33.005)	mem 75.774
Train: [9][20/1500]	BT 0.039 (1.245)	DT 0.001 (1.205)	loss 8.773 (8.019)	prob 3.748 (3.004)	GS 34.016 (32.844)	mem 75.786
Train: [9][30/1500]	BT 0.040 (0.979)	DT 0.000 (0.940)	loss 8.302 (7.983)	prob 3.605 (3.051)	GS 35.469 (33.070)	mem 75.896
Train: [9][40/1500]	BT 0.042 (0.744)	DT 0.001 (0.705)	loss 8.163 (7.989)	prob 3.756 (3.052)	GS 30.750 (32.556)	mem 75.905
Train: [9][50/1500]	BT 0.048 (0.677)	DT 0.000 (0.637)	loss 8.401 (8.034)	prob 4.121 (3.095)	GS 37.656 (32.342)	mem 75.981
Train: [9][60/1500]	BT 0.028 (0.603)	DT 0.000 (0.564)	loss 8.268 (8.117)	prob 4.180 (3.224)	GS 33.984 (31.519)	mem 76.069
Train: [9][70/1500]	BT 0.038 (0.529)	DT 0.001 (0.490)	loss 8.850 (8.108)	prob 3.481 (3.171)	GS 35.188 (31.805)	mem 76.085
Train: [9][80/1500]	BT 0.028 (0.516)	DT 0.000 (0.478)	loss 8.076 (8.152)	prob 2.729 (3.182)	GS 36.969 (31.907)	mem 76.212
Train: [9][90/1500]	BT 0.038 (0.470)	DT 0.000 (0.432)	loss 8.137 (8.168)	prob 4.442 (3.291)	GS 34.906 (31.596)	mem 76.247
Train: [9][100/1500]	BT 0.037 (0.447)	DT 0.001 (0.410)	loss 8.295 (8.201)	prob 4.030 (3.311)	GS 29.906 (31.367)	mem 75.405
Train: [9][110/1500]	BT 0.248 (0.428)	DT 0.221 (0.391)	loss 8.382 (8.055)	prob 3.716 (3.110)	GS 34.031 (32.959)	mem 75.327
Train: [9][120/1500]	BT 0.029 (0.395)	DT 0.001 (0.358)	loss 8.272 (8.164)	prob 4.042 (3.098)	GS 32.406 (32.765)	mem 75.331
Train: [9][130/1500]	BT 0.028 (0.425)	DT 0.000 (0.389)	loss 8.610 (8.125)	prob 3.442 (3.280)	GS 30.625 (32.804)	mem 75.382
Train: [9][140/1500]	BT 0.027 (0.396)	DT 0.000 (0.361)	loss 8.679 (8.148)	prob 4.189 (3.289)	GS 35.625 (33.017)	mem 75.388
Train: [9][150/1500]	BT 0.040 (0.396)	DT 0.001 (0.361)	loss 8.738 (8.176)	prob 3.651 (3.254)	GS 32.969 (32.921)	mem 75.369
Train: [9][160/1500]	BT 0.038 (0.374)	DT 0.001 (0.338)	loss 7.871 (8.090)	prob 3.430 (3.498)	GS 35.828 (34.892)	mem 75.375
Train: [9][170/1500]	BT 0.041 (0.370)	DT 0.001 (0.334)	loss 8.075 (8.079)	prob 4.121 (3.501)	GS 32.359 (33.663)	mem 75.423
Train: [9][180/1500]	BT 0.049 (0.357)	DT 0.003 (0.320)	loss 7.894 (8.118)	prob 3.398 (3.325)	GS 31.359 (33.385)	mem 75.443
Train: [9][190/1500]	BT 0.055 (0.342)	DT 0.004 (0.304)	loss 8.217 (8.168)	prob 4.103 (3.313)	GS 35.984 (33.373)	mem 75.447
Train: [9][200/1500]	BT 0.068 (0.354)	DT 0.011 (0.315)	loss 8.554 (8.191)	prob 4.082 (3.221)	GS 32.641 (33.285)	mem 75.544
Train: [9][210/1500]	BT 0.059 (0.340)	DT 0.011 (0.301)	loss 8.342 (8.318)	prob 4.250 (3.279)	GS 35.000 (33.508)	mem 75.550
Train: [9][220/1500]	BT 0.080 (0.358)	DT 0.016 (0.318)	loss 7.985 (8.312)	prob 3.445 (3.289)	GS 33.281 (34.096)	mem 75.608
Train: [9][230/1500]	BT 0.031 (0.370)	DT 0.000 (0.330)	loss 8.551 (8.278)	prob 3.613 (3.268)	GS 33.781 (34.024)	mem 75.714
Train: [9][240/1500]	BT 0.084 (0.429)	DT 0.015 (0.389)	loss 8.934 (8.283)	prob 3.715 (3.231)	GS 32.953 (34.126)	mem 77.268
Train: [9][250/1500]	BT 0.058 (0.415)	DT 0.019 (0.373)	loss 8.327 (8.257)	prob 3.286 (3.315)	GS 34.984 (33.655)	mem 77.516
Train: [9][260/1500]	BT 0.026 (0.428)	DT 0.000 (0.387)	loss 8.354 (8.290)	prob 2.907 (3.239)	GS 33.922 (32.811)	mem 76.100
Train: [9][270/1500]	BT 0.034 (0.414)	DT 0.001 (0.373)	loss 8.115 (8.288)	prob 4.064 (3.212)	GS 33.391 (32.458)	mem 76.112
Train: [9][280/1500]	BT 0.044 (0.419)	DT 0.016 (0.379)	loss 7.947 (8.181)	prob 2.374 (3.161)	GS 34.375 (32.242)	mem 75.355
Train: [9][290/1500]	BT 0.027 (0.406)	DT 0.000 (0.366)	loss 8.479 (8.174)	prob 2.733 (3.161)	GS 34.453 (32.295)	mem 75.336
Train: [9][300/1500]	BT 0.034 (0.393)	DT 0.000 (0.354)	loss 8.081 (8.159)	prob 3.704 (3.213)	GS 32.047 (32.170)	mem 75.342
Train: [9][310/1500]	BT 0.029 (0.401)	DT 0.001 (0.361)	loss 7.731 (8.334)	prob 3.309 (2.613)	GS 34.312 (32.120)	mem 75.414
Train: [9][320/1500]	BT 0.030 (0.389)	DT 0.000 (0.350)	loss 7.736 (8.336)	prob 3.602 (2.647)	GS 33.875 (32.472)	mem 75.419
Train: [9][330/1500]	BT 0.038 (0.390)	DT 0.001 (0.351)	loss 8.543 (8.277)	prob 2.254 (2.602)	GS 34.266 (32.669)	mem 75.455
Train: [9][340/1500]	BT 0.029 (0.380)	DT 0.000 (0.341)	loss 8.095 (8.232)	prob 3.495 (2.727)	GS 30.266 (32.546)	mem 75.458
Train: [9][350/1500]	BT 0.030 (0.370)	DT 0.000 (0.331)	loss 9.270 (8.271)	prob 3.095 (2.719)	GS 34.016 (32.323)	mem 75.460
Train: [9][360/1500]	BT 0.039 (0.369)	DT 0.001 (0.330)	loss 8.548 (8.298)	prob 2.162 (2.483)	GS 27.828 (30.998)	mem 75.497
Train: [9][370/1500]	BT 0.039 (0.360)	DT 0.000 (0.322)	loss 8.243 (8.252)	prob 3.008 (2.434)	GS 34.141 (32.276)	mem 75.508
Train: [9][380/1500]	BT 0.041 (0.360)	DT 0.001 (0.321)	loss 7.918 (8.203)	prob 1.436 (2.274)	GS 35.391 (32.748)	mem 75.745
Train: [9][390/1500]	BT 0.030 (0.356)	DT 0.001 (0.318)	loss 8.602 (8.247)	prob 2.152 (2.242)	GS 35.391 (33.058)	mem 77.152
Train: [9][400/1500]	BT 0.041 (0.354)	DT 0.001 (0.316)	loss 8.691 (8.284)	prob 2.483 (2.205)	GS 31.688 (32.953)	mem 77.921
Train: [9][410/1500]	BT 1.784 (0.355)	DT 1.744 (0.316)	loss 9.738 (8.209)	prob 2.575 (2.571)	GS 32.094 (31.023)	mem 75.693
Train: [9][420/1500]	BT 0.038 (0.347)	DT 0.000 (0.308)	loss 9.323 (8.159)	prob 2.165 (2.645)	GS 37.625 (31.859)	mem 75.706
Train: [9][430/1500]	BT 0.032 (0.347)	DT 0.001 (0.309)	loss 7.768 (8.148)	prob 3.212 (2.520)	GS 30.516 (32.333)	mem 75.750
Train: [9][440/1500]	BT 0.038 (0.344)	DT 0.000 (0.306)	loss 8.116 (8.142)	prob 3.224 (2.560)	GS 29.719 (31.902)	mem 75.816
Train: [9][450/1500]	BT 0.059 (0.355)	DT 0.016 (0.317)	loss 8.173 (8.148)	prob 2.116 (2.468)	GS 33.000 (32.336)	mem 76.065
Train: [9][460/1500]	BT 0.084 (0.351)	DT 0.016 (0.312)	loss 7.965 (8.443)	prob 3.416 (2.135)	GS 36.438 (33.098)	mem 76.080
Train: [9][470/1500]	BT 0.029 (0.366)	DT 0.000 (0.327)	loss 8.338 (8.424)	prob 2.544 (2.110)	GS 34.484 (32.338)	mem 76.758
Train: [9][480/1500]	BT 0.036 (0.359)	DT 0.001 (0.320)	loss 7.749 (8.366)	prob 2.743 (2.144)	GS 29.062 (31.814)	mem 76.775
Train: [9][490/1500]	BT 0.077 (0.362)	DT 0.005 (0.323)	loss 8.547 (8.346)	prob 2.028 (2.147)	GS 36.734 (32.412)	mem 77.224
Train: [9][500/1500]	BT 0.072 (0.356)	DT 0.004 (0.317)	loss 8.707 (8.312)	prob 3.639 (2.293)	GS 31.750 (32.297)	mem 76.327
Train: [9][510/1500]	BT 0.043 (0.364)	DT 0.000 (0.324)	loss 8.876 (8.358)	prob 3.600 (2.770)	GS 33.297 (32.987)	mem 76.549
Train: [9][520/1500]	BT 0.041 (0.358)	DT 0.000 (0.318)	loss 9.661 (8.475)	prob 2.121 (2.608)	GS 35.797 (33.733)	mem 76.558
Train: [9][530/1500]	BT 0.027 (0.351)	DT 0.000 (0.312)	loss 8.560 (8.375)	prob 3.113 (2.671)	GS 32.297 (33.172)	mem 76.565
Train: [9][540/1500]	BT 0.038 (0.353)	DT 0.001 (0.313)	loss 8.313 (8.349)	prob 2.778 (2.643)	GS 32.828 (33.210)	mem 76.609
Train: [9][550/1500]	BT 0.037 (0.347)	DT 0.001 (0.308)	loss 7.926 (8.338)	prob 4.211 (2.658)	GS 35.156 (33.110)	mem 76.614
Train: [9][560/1500]	BT 0.060 (0.354)	DT 0.003 (0.314)	loss 8.272 (8.456)	prob 3.257 (2.571)	GS 30.109 (33.987)	mem 76.708
Train: [9][570/1500]	BT 0.064 (0.349)	DT 0.003 (0.309)	loss 9.125 (8.425)	prob 3.343 (2.601)	GS 38.781 (33.338)	mem 76.718
Train: [9][580/1500]	BT 0.049 (0.344)	DT 0.002 (0.303)	loss 8.959 (8.365)	prob 3.683 (2.743)	GS 34.125 (33.138)	mem 76.686
Train: [9][590/1500]	BT 0.071 (0.355)	DT 0.016 (0.314)	loss 8.384 (8.341)	prob 3.561 (2.746)	GS 34.984 (32.992)	mem 76.823
Train: [9][600/1500]	BT 0.031 (0.361)	DT 0.000 (0.321)	loss 9.947 (8.379)	prob 2.986 (2.742)	GS 33.453 (33.126)	mem 76.970
Train: [9][610/1500]	BT 0.036 (0.356)	DT 0.000 (0.315)	loss 8.752 (8.439)	prob 3.709 (3.421)	GS 39.406 (32.822)	mem 76.980
Train: [9][620/1500]	BT 0.040 (0.356)	DT 0.001 (0.316)	loss 8.249 (8.284)	prob 3.030 (3.228)	GS 34.484 (32.658)	mem 77.085
Train: [9][630/1500]	BT 0.040 (0.351)	DT 0.001 (0.311)	loss 9.686 (8.379)	prob 2.779 (3.110)	GS 31.344 (32.622)	mem 77.108
Train: [9][640/1500]	BT 0.039 (0.351)	DT 0.000 (0.311)	loss 8.640 (8.382)	prob 3.030 (3.150)	GS 34.812 (32.657)	mem 77.233
Train: [9][650/1500]	BT 0.040 (0.346)	DT 0.001 (0.306)	loss 8.139 (8.365)	prob 4.128 (3.169)	GS 36.781 (32.462)	mem 77.248
Train: [9][660/1500]	BT 0.029 (0.342)	DT 0.000 (0.302)	loss 7.953 (8.146)	prob 3.892 (3.242)	GS 34.469 (33.270)	mem 77.227
Train: [9][670/1500]	BT 0.042 (0.342)	DT 0.001 (0.302)	loss 8.011 (8.209)	prob 3.948 (3.263)	GS 30.141 (32.857)	mem 78.635
Train: [9][680/1500]	BT 1.272 (0.340)	DT 1.230 (0.300)	loss 8.056 (8.213)	prob 4.646 (3.277)	GS 34.781 (32.602)	mem 79.335
Train: [9][690/1500]	BT 0.103 (0.348)	DT 0.002 (0.307)	loss 8.863 (8.248)	prob 3.856 (3.312)	GS 31.781 (32.451)	mem 80.123
Train: [9][700/1500]	BT 0.053 (0.352)	DT 0.002 (0.311)	loss 8.973 (8.282)	prob 3.069 (3.344)	GS 31.031 (32.452)	mem 82.742
Train: [9][710/1500]	BT 0.080 (0.350)	DT 0.011 (0.308)	loss 8.280 (8.570)	prob 3.159 (3.332)	GS 35.828 (32.997)	mem 85.013
Train: [9][720/1500]	BT 0.885 (0.355)	DT 0.856 (0.313)	loss 8.397 (8.531)	prob 4.267 (3.237)	GS 33.438 (32.643)	mem 109.052
Train: [9][730/1500]	BT 0.045 (0.350)	DT 0.001 (0.309)	loss 8.637 (8.477)	prob 2.571 (3.249)	GS 36.844 (32.705)	mem 111.287
Train: [9][740/1500]	BT 0.047 (0.349)	DT 0.001 (0.308)	loss 8.737 (8.482)	prob 3.382 (3.189)	GS 35.125 (32.932)	mem 113.333
Train: [9][750/1500]	BT 0.136 (0.351)	DT 0.021 (0.310)	loss 8.204 (8.424)	prob 3.936 (3.227)	GS 34.922 (32.895)	mem 113.354
Train: [9][760/1500]	BT 0.044 (0.353)	DT 0.001 (0.311)	loss 8.194 (8.348)	prob 3.264 (3.285)	GS 33.266 (32.045)	mem 113.353
Train: [9][770/1500]	BT 0.093 (0.353)	DT 0.010 (0.310)	loss 7.971 (8.319)	prob 4.021 (3.239)	GS 34.844 (32.803)	mem 113.382
Train: [9][780/1500]	BT 0.041 (0.349)	DT 0.000 (0.306)	loss 9.204 (8.395)	prob 2.775 (3.189)	GS 33.969 (32.774)	mem 113.388
Train: [9][790/1500]	BT 0.068 (0.353)	DT 0.005 (0.310)	loss 7.951 (8.360)	prob 3.654 (3.308)	GS 31.609 (32.368)	mem 76.820
Train: [9][800/1500]	BT 0.073 (0.350)	DT 0.006 (0.306)	loss 8.317 (8.383)	prob 3.721 (3.343)	GS 33.016 (32.240)	mem 76.834
Train: [9][810/1500]	BT 0.034 (0.356)	DT 0.001 (0.313)	loss 8.424 (8.429)	prob 4.119 (3.518)	GS 35.031 (31.780)	mem 76.921
Train: [9][820/1500]	BT 0.048 (0.381)	DT 0.001 (0.337)	loss 8.461 (8.337)	prob 2.623 (3.319)	GS 34.734 (32.400)	mem 77.455
Train: [9][830/1500]	BT 0.026 (0.376)	DT 0.000 (0.333)	loss 8.663 (8.327)	prob 2.987 (3.318)	GS 32.734 (32.082)	mem 77.466
Train: [9][840/1500]	BT 0.033 (0.378)	DT 0.001 (0.335)	loss 8.240 (8.314)	prob 4.350 (3.437)	GS 29.516 (31.766)	mem 77.620
Train: [9][850/1500]	BT 0.026 (0.374)	DT 0.000 (0.331)	loss 7.992 (8.323)	prob 3.245 (3.308)	GS 34.531 (32.669)	mem 77.629
Train: [9][860/1500]	BT 0.040 (0.370)	DT 0.001 (0.327)	loss 8.005 (8.114)	prob 3.877 (3.272)	GS 31.906 (32.358)	mem 77.637
Train: [9][870/1500]	BT 0.040 (0.369)	DT 0.001 (0.327)	loss 8.718 (8.250)	prob 3.044 (3.227)	GS 36.984 (33.032)	mem 76.860
Train: [9][880/1500]	BT 0.040 (0.366)	DT 0.001 (0.323)	loss 7.540 (8.252)	prob 3.846 (3.093)	GS 33.859 (33.093)	mem 76.880
Train: [9][890/1500]	BT 0.064 (0.369)	DT 0.001 (0.327)	loss 8.639 (8.269)	prob 3.449 (3.020)	GS 32.609 (32.945)	mem 76.958
Train: [9][900/1500]	BT 0.100 (0.366)	DT 0.001 (0.323)	loss 8.625 (8.247)	prob 3.044 (3.089)	GS 34.766 (32.825)	mem 76.968
Train: [9][910/1500]	BT 1.216 (0.366)	DT 1.177 (0.323)	loss 8.169 (8.266)	prob 3.068 (2.708)	GS 32.234 (34.364)	mem 76.995
Train: [9][920/1500]	BT 0.039 (0.363)	DT 0.001 (0.320)	loss 8.172 (8.271)	prob 4.139 (2.869)	GS 35.078 (33.051)	mem 77.000
Train: [9][930/1500]	BT 0.104 (0.365)	DT 0.008 (0.322)	loss 8.394 (8.292)	prob 3.429 (2.781)	GS 34.219 (33.352)	mem 77.070
Train: [9][940/1500]	BT 0.041 (0.369)	DT 0.001 (0.326)	loss 8.021 (8.273)	prob 3.015 (2.820)	GS 34.641 (32.971)	mem 78.049
Train: [9][950/1500]	BT 0.042 (0.367)	DT 0.001 (0.324)	loss 7.896 (8.217)	prob 2.714 (2.837)	GS 30.438 (32.827)	mem 78.848
Train: [9][960/1500]	BT 4.535 (0.369)	DT 4.477 (0.326)	loss 8.327 (8.005)	prob 3.611 (3.183)	GS 32.281 (31.245)	mem 79.875
Train: [9][970/1500]	BT 0.042 (0.379)	DT 0.001 (0.335)	loss 8.296 (8.039)	prob 3.062 (3.011)	GS 36.281 (32.350)	mem 96.311
Train: [9][980/1500]	BT 0.046 (0.375)	DT 0.001 (0.332)	loss 7.839 (8.050)	prob 1.693 (2.780)	GS 30.109 (32.294)	mem 98.980
Train: [9][990/1500]	BT 0.086 (0.378)	DT 0.001 (0.335)	loss 8.677 (8.092)	prob 2.480 (2.621)	GS 32.938 (32.833)	mem 114.094
Train: [9][1000/1500]	BT 0.070 (0.375)	DT 0.010 (0.331)	loss 8.062 (8.146)	prob 3.366 (2.490)	GS 29.391 (32.857)	mem 114.111
Train: [9][1010/1500]	BT 0.064 (0.372)	DT 0.016 (0.328)	loss 8.234 (7.990)	prob 1.990 (2.106)	GS 32.109 (33.377)	mem 114.122
Train: [9][1020/1500]	BT 0.031 (0.377)	DT 0.000 (0.334)	loss 8.142 (8.087)	prob 4.025 (2.357)	GS 30.625 (32.309)	mem 77.661
Train: [9][1030/1500]	BT 0.036 (0.376)	DT 0.001 (0.332)	loss 8.775 (8.124)	prob 2.950 (2.358)	GS 31.156 (32.341)	mem 77.692
Train: [9][1040/1500]	BT 0.061 (0.376)	DT 0.004 (0.332)	loss 8.618 (8.189)	prob 2.327 (2.350)	GS 34.547 (32.392)	mem 77.973
Train: [9][1050/1500]	BT 0.081 (0.377)	DT 0.001 (0.333)	loss 7.682 (8.176)	prob 2.904 (2.347)	GS 33.062 (32.439)	mem 79.313
Train: [9][1060/1500]	BT 0.090 (0.374)	DT 0.015 (0.330)	loss 8.372 (8.139)	prob 2.982 (2.270)	GS 33.266 (32.400)	mem 79.418
Train: [9][1070/1500]	BT 0.040 (0.374)	DT 0.001 (0.330)	loss 7.587 (8.168)	prob 1.784 (2.067)	GS 32.453 (33.073)	mem 76.721
Train: [9][1080/1500]	BT 0.042 (0.372)	DT 0.001 (0.328)	loss 8.573 (8.207)	prob 2.613 (2.136)	GS 32.531 (32.746)	mem 76.719
Train: [9][1090/1500]	BT 0.071 (0.372)	DT 0.000 (0.329)	loss 8.857 (8.240)	prob 3.132 (2.125)	GS 33.797 (32.461)	mem 76.777
Train: [9][1100/1500]	BT 0.072 (0.369)	DT 0.006 (0.326)	loss 8.560 (8.247)	prob 3.555 (2.217)	GS 36.516 (32.224)	mem 76.779
Train: [9][1110/1500]	BT 0.039 (0.373)	DT 0.001 (0.329)	loss 9.169 (8.391)	prob 1.659 (2.141)	GS 36.328 (33.330)	mem 76.832
Train: [9][1120/1500]	BT 0.037 (0.370)	DT 0.001 (0.326)	loss 7.864 (8.203)	prob 3.543 (2.360)	GS 31.094 (32.546)	mem 76.836
Train: [9][1130/1500]	BT 0.041 (0.368)	DT 0.001 (0.324)	loss 7.703 (8.206)	prob 3.876 (2.694)	GS 30.375 (32.328)	mem 76.859
Train: [9][1140/1500]	BT 0.031 (0.368)	DT 0.000 (0.324)	loss 8.622 (8.268)	prob 2.009 (2.502)	GS 34.109 (32.672)	mem 76.931
Train: [9][1150/1500]	BT 0.042 (0.365)	DT 0.001 (0.321)	loss 7.896 (8.321)	prob 4.258 (2.499)	GS 29.875 (32.587)	mem 76.938
Train: [9][1160/1500]	BT 0.035 (0.366)	DT 0.001 (0.322)	loss 8.297 (8.367)	prob 3.093 (2.833)	GS 32.953 (33.145)	mem 77.037
Train: [9][1170/1500]	BT 0.034 (0.363)	DT 0.000 (0.320)	loss 9.445 (8.324)	prob 3.348 (2.873)	GS 36.984 (32.663)	mem 77.045
Train: [9][1180/1500]	BT 0.040 (0.367)	DT 0.001 (0.323)	loss 7.926 (8.260)	prob 3.647 (3.041)	GS 33.234 (33.105)	mem 77.211
Train: [9][1190/1500]	BT 0.040 (0.364)	DT 0.001 (0.321)	loss 8.345 (8.305)	prob 3.260 (2.988)	GS 33.375 (32.791)	mem 77.222
Train: [9][1200/1500]	BT 0.040 (0.365)	DT 0.001 (0.321)	loss 8.198 (8.312)	prob 2.247 (2.918)	GS 31.297 (33.274)	mem 77.287
Train: [9][1210/1500]	BT 0.040 (0.363)	DT 0.001 (0.319)	loss 9.049 (8.510)	prob 3.100 (2.418)	GS 30.938 (33.250)	mem 77.340
Train: [9][1220/1500]	BT 0.114 (0.362)	DT 0.003 (0.319)	loss 8.089 (8.373)	prob 3.629 (2.653)	GS 33.938 (33.351)	mem 77.521
Train: [9][1230/1500]	BT 0.044 (0.363)	DT 0.002 (0.319)	loss 8.554 (8.302)	prob 3.868 (2.957)	GS 32.859 (32.760)	mem 77.556
Train: [9][1240/1500]	BT 0.061 (0.360)	DT 0.004 (0.317)	loss 8.262 (8.313)	prob 4.613 (2.980)	GS 30.984 (32.716)	mem 77.570
Train: [9][1250/1500]	BT 0.052 (0.360)	DT 0.015 (0.317)	loss 8.727 (8.343)	prob 1.621 (3.012)	GS 39.250 (32.759)	mem 78.177
Train: [9][1260/1500]	BT 0.055 (0.362)	DT 0.006 (0.319)	loss 8.953 (8.515)	prob 3.223 (3.164)	GS 33.812 (32.216)	mem 79.708
Train: [9][1270/1500]	BT 0.027 (0.373)	DT 0.000 (0.329)	loss 9.170 (8.398)	prob 2.559 (3.243)	GS 34.859 (32.173)	mem 76.829
Train: [9][1280/1500]	BT 0.031 (0.370)	DT 0.000 (0.327)	loss 8.615 (8.420)	prob 3.302 (3.160)	GS 36.891 (32.567)	mem 76.836
Train: [9][1290/1500]	BT 0.028 (0.371)	DT 0.001 (0.328)	loss 8.712 (8.462)	prob 3.656 (3.142)	GS 35.359 (32.395)	mem 76.906
Train: [9][1300/1500]	BT 0.030 (0.368)	DT 0.000 (0.325)	loss 8.146 (8.438)	prob 3.730 (3.182)	GS 35.953 (32.454)	mem 76.909
Train: [9][1310/1500]	BT 6.110 (0.371)	DT 6.078 (0.327)	loss 7.780 (8.193)	prob 4.580 (3.378)	GS 32.312 (32.703)	mem 76.988
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [9][1320/1500]	BT 0.022 (0.372)	DT 0.000 (0.328)	loss 8.815 (8.373)	prob 3.246 (3.341)	GS 35.938 (34.119)	mem 77.123
Train: [9][1330/1500]	BT 0.036 (0.369)	DT 0.001 (0.326)	loss 7.979 (8.287)	prob 4.317 (3.386)	GS 32.156 (33.193)	mem 77.133
Train: [9][1340/1500]	BT 0.039 (0.370)	DT 0.001 (0.327)	loss 9.176 (8.342)	prob 3.911 (3.371)	GS 32.672 (33.029)	mem 77.156
Train: [9][1350/1500]	BT 0.039 (0.367)	DT 0.001 (0.324)	loss 8.891 (8.383)	prob 3.282 (3.396)	GS 38.484 (32.992)	mem 77.188
Train: [9][1360/1500]	BT 0.049 (0.368)	DT 0.014 (0.325)	loss 8.576 (8.374)	prob 3.939 (3.270)	GS 32.312 (31.823)	mem 77.264
Train: [9][1370/1500]	BT 0.056 (0.366)	DT 0.006 (0.323)	loss 8.984 (8.366)	prob 3.687 (3.287)	GS 34.812 (32.195)	mem 77.270
Train: [9][1380/1500]	BT 0.089 (0.367)	DT 0.014 (0.323)	loss 9.095 (8.383)	prob 2.854 (3.210)	GS 32.391 (32.872)	mem 77.472
Train: [9][1390/1500]	BT 0.028 (0.370)	DT 0.000 (0.327)	loss 8.716 (8.416)	prob 3.579 (3.163)	GS 33.953 (33.230)	mem 79.417
Train: [9][1400/1500]	BT 0.039 (0.368)	DT 0.001 (0.325)	loss 8.033 (8.413)	prob 4.395 (3.238)	GS 33.922 (32.824)	mem 79.747
Train: [9][1410/1500]	BT 0.098 (0.368)	DT 0.030 (0.325)	loss 7.943 (8.291)	prob 4.149 (3.653)	GS 31.141 (32.756)	mem 77.521
Train: [9][1420/1500]	BT 0.030 (0.366)	DT 0.001 (0.323)	loss 7.970 (8.290)	prob 4.349 (3.407)	GS 34.719 (33.069)	mem 77.501
Train: [9][1430/1500]	BT 0.029 (0.364)	DT 0.000 (0.321)	loss 8.492 (8.241)	prob 4.424 (3.615)	GS 31.422 (32.413)	mem 77.519
Train: [9][1440/1500]	BT 0.035 (0.364)	DT 0.001 (0.321)	loss 9.253 (8.273)	prob 3.579 (3.592)	GS 33.812 (32.581)	mem 76.778
Train: [9][1450/1500]	BT 0.040 (0.363)	DT 0.001 (0.320)	loss 8.191 (8.233)	prob 4.436 (3.624)	GS 31.844 (32.593)	mem 76.811
Train: [9][1460/1500]	BT 0.079 (0.363)	DT 0.020 (0.320)	loss 8.369 (8.329)	prob 3.418 (3.393)	GS 34.156 (32.587)	mem 76.250
Train: [9][1470/1500]	BT 0.052 (0.363)	DT 0.009 (0.319)	loss 7.852 (8.149)	prob 3.632 (3.541)	GS 31.312 (32.070)	mem 42.969
Train: [9][1480/1500]	BT 11.003 (0.370)	DT 10.954 (0.327)	loss 8.270 (8.170)	prob 4.168 (3.503)	GS 36.750 (31.965)	mem 17.212
Train: [9][1490/1500]	BT 0.033 (0.368)	DT 0.001 (0.325)	loss 8.389 (8.174)	prob 3.989 (3.471)	GS 30.875 (31.774)	mem 19.170
Train: [9][1500/1500]	BT 0.038 (0.366)	DT 0.001 (0.323)	loss 7.663 (8.159)	prob 4.051 (3.434)	GS 35.750 (32.005)	mem 21.887
Train: [9][1510/1500]	BT 0.059 (0.364)	DT 0.002 (0.321)	loss 7.831 (8.024)	prob 3.563 (3.320)	GS 34.500 (33.403)	mem 27.056
epoch 9, total time 549.91
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [10][1/1500]	BT 24.762 (24.762)	DT 24.697 (24.697)	loss 7.512 (7.512)	prob 3.062 (3.062)	GS 27.812 (27.812)	mem 114.683
Train: [10][10/1500]	BT 0.043 (2.965)	DT 0.001 (2.910)	loss 8.288 (8.104)	prob 4.488 (3.397)	GS 29.734 (32.448)	mem 114.857
Train: [10][20/1500]	BT 0.058 (1.507)	DT 0.001 (1.457)	loss 8.185 (8.024)	prob 3.830 (3.413)	GS 33.672 (32.253)	mem 114.873
Train: [10][30/1500]	BT 0.040 (1.139)	DT 0.001 (1.090)	loss 8.113 (8.018)	prob 3.491 (3.314)	GS 35.000 (32.766)	mem 76.027
Train: [10][40/1500]	BT 0.040 (0.865)	DT 0.001 (0.818)	loss 7.857 (8.013)	prob 2.798 (3.287)	GS 37.172 (32.672)	mem 76.040
Train: [10][50/1500]	BT 0.244 (0.773)	DT 0.201 (0.728)	loss 8.066 (8.026)	prob 4.417 (3.289)	GS 33.703 (32.696)	mem 75.217
Train: [10][60/1500]	BT 0.070 (0.704)	DT 0.025 (0.657)	loss 8.379 (8.018)	prob 3.994 (3.530)	GS 31.859 (31.887)	mem 75.241
Train: [10][70/1500]	BT 0.775 (0.624)	DT 0.736 (0.577)	loss 8.543 (8.050)	prob 3.653 (3.434)	GS 37.531 (32.068)	mem 75.272
Train: [10][80/1500]	BT 0.037 (0.600)	DT 0.001 (0.554)	loss 8.692 (8.082)	prob 3.438 (3.477)	GS 37.422 (32.156)	mem 75.356
Train: [10][90/1500]	BT 0.037 (0.538)	DT 0.001 (0.493)	loss 8.310 (8.015)	prob 4.456 (3.601)	GS 34.656 (32.098)	mem 75.363
Train: [10][100/1500]	BT 0.064 (0.522)	DT 0.003 (0.478)	loss 8.003 (8.008)	prob 4.265 (3.564)	GS 28.203 (31.877)	mem 75.396
Train: [10][110/1500]	BT 0.038 (0.603)	DT 0.000 (0.560)	loss 8.203 (7.938)	prob 3.591 (3.663)	GS 31.797 (31.583)	mem 75.639
Train: [10][120/1500]	BT 0.036 (0.555)	DT 0.000 (0.513)	loss 9.282 (8.022)	prob 2.748 (3.278)	GS 36.812 (31.862)	mem 75.650
Train: [10][130/1500]	BT 0.040 (0.536)	DT 0.001 (0.495)	loss 7.678 (8.022)	prob 2.868 (3.141)	GS 38.422 (32.137)	mem 75.749
Train: [10][140/1500]	BT 0.034 (0.501)	DT 0.001 (0.459)	loss 8.367 (8.030)	prob 3.493 (3.091)	GS 31.453 (32.317)	mem 75.762
Train: [10][150/1500]	BT 0.075 (0.510)	DT 0.003 (0.468)	loss 8.563 (8.030)	prob 3.448 (3.115)	GS 34.500 (32.421)	mem 75.826
Train: [10][160/1500]	BT 0.055 (0.482)	DT 0.003 (0.439)	loss 8.285 (8.114)	prob 3.825 (2.705)	GS 35.328 (32.712)	mem 75.834
Train: [10][170/1500]	BT 0.056 (0.499)	DT 0.001 (0.457)	loss 8.031 (8.027)	prob 3.608 (2.872)	GS 29.703 (32.240)	mem 75.947
Train: [10][180/1500]	BT 0.038 (0.474)	DT 0.001 (0.431)	loss 8.708 (8.001)	prob 2.210 (2.920)	GS 35.375 (32.606)	mem 75.959
Train: [10][190/1500]	BT 0.038 (0.489)	DT 0.000 (0.446)	loss 9.064 (7.996)	prob 2.014 (2.784)	GS 33.188 (32.831)	mem 76.073
Train: [10][200/1500]	BT 0.072 (0.467)	DT 0.003 (0.423)	loss 7.789 (8.014)	prob 3.130 (2.726)	GS 33.719 (32.758)	mem 76.081
Train: [10][210/1500]	BT 0.035 (0.447)	DT 0.000 (0.403)	loss 7.739 (8.074)	prob 2.941 (2.427)	GS 36.562 (33.584)	mem 76.087
Train: [10][220/1500]	BT 0.031 (0.459)	DT 0.001 (0.416)	loss 8.082 (8.064)	prob 3.432 (2.533)	GS 34.797 (33.839)	mem 76.173
Train: [10][230/1500]	BT 0.037 (0.451)	DT 0.001 (0.408)	loss 8.259 (8.164)	prob 3.758 (2.560)	GS 34.281 (33.619)	mem 75.306
Train: [10][240/1500]	BT 0.036 (0.439)	DT 0.000 (0.396)	loss 8.219 (8.152)	prob 3.305 (2.602)	GS 39.094 (33.440)	mem 75.324
Train: [10][250/1500]	BT 0.039 (0.438)	DT 0.001 (0.396)	loss 7.914 (8.163)	prob 3.987 (2.591)	GS 34.781 (33.327)	mem 75.358
Train: [10][260/1500]	BT 0.039 (0.423)	DT 0.001 (0.381)	loss 8.415 (8.231)	prob 3.289 (2.539)	GS 33.375 (33.391)	mem 75.368
Train: [10][270/1500]	BT 0.038 (0.419)	DT 0.001 (0.377)	loss 7.997 (8.356)	prob 3.933 (2.512)	GS 35.578 (32.874)	mem 75.398
Train: [10][280/1500]	BT 1.247 (0.410)	DT 1.193 (0.368)	loss 8.736 (8.363)	prob 3.761 (2.427)	GS 34.766 (32.756)	mem 75.410
Train: [10][290/1500]	BT 0.037 (0.416)	DT 0.000 (0.373)	loss 8.168 (8.364)	prob 2.899 (2.629)	GS 36.062 (32.820)	mem 75.454
Train: [10][300/1500]	BT 0.033 (0.409)	DT 0.000 (0.366)	loss 8.292 (8.318)	prob 3.121 (2.690)	GS 30.422 (32.524)	mem 75.447
Train: [10][310/1500]	BT 0.028 (0.452)	DT 0.000 (0.409)	loss 7.714 (8.375)	prob 3.258 (3.033)	GS 31.297 (32.573)	mem 75.665
Train: [10][320/1500]	BT 0.027 (0.438)	DT 0.000 (0.396)	loss 8.681 (8.419)	prob 3.327 (3.082)	GS 33.688 (32.224)	mem 75.677
Train: [10][330/1500]	BT 0.032 (0.439)	DT 0.001 (0.397)	loss 9.503 (8.459)	prob 2.535 (2.927)	GS 38.844 (32.686)	mem 75.764
Train: [10][340/1500]	BT 0.050 (0.428)	DT 0.005 (0.386)	loss 8.944 (8.397)	prob 3.776 (3.023)	GS 32.562 (32.385)	mem 75.776
Train: [10][350/1500]	BT 0.054 (0.417)	DT 0.005 (0.375)	loss 8.747 (8.366)	prob 2.817 (3.007)	GS 34.812 (32.543)	mem 75.787
Train: [10][360/1500]	BT 0.026 (0.419)	DT 0.000 (0.377)	loss 7.920 (8.407)	prob 3.923 (2.874)	GS 33.375 (32.708)	mem 75.951
Train: [10][370/1500]	BT 0.037 (0.409)	DT 0.001 (0.367)	loss 8.464 (8.395)	prob 3.122 (2.824)	GS 33.859 (33.718)	mem 75.962
Train: [10][380/1500]	BT 0.071 (0.407)	DT 0.013 (0.365)	loss 8.382 (8.390)	prob 4.682 (2.965)	GS 31.172 (33.314)	mem 76.062
Train: [10][390/1500]	BT 0.034 (0.397)	DT 0.001 (0.355)	loss 8.566 (8.388)	prob 3.637 (3.042)	GS 39.578 (33.279)	mem 76.068
Train: [10][400/1500]	BT 0.032 (0.388)	DT 0.001 (0.346)	loss 8.659 (8.407)	prob 3.161 (3.062)	GS 35.844 (33.183)	mem 76.073
Train: [10][410/1500]	BT 0.040 (0.391)	DT 0.001 (0.349)	loss 8.345 (8.407)	prob 2.823 (2.992)	GS 35.141 (35.069)	mem 75.282
Train: [10][420/1500]	BT 0.039 (0.382)	DT 0.001 (0.341)	loss 8.165 (8.395)	prob 4.287 (3.156)	GS 32.031 (33.153)	mem 75.293
Train: [10][430/1500]	BT 0.038 (0.385)	DT 0.001 (0.343)	loss 8.900 (8.430)	prob 3.725 (3.233)	GS 33.625 (32.784)	mem 75.320
Train: [10][440/1500]	BT 0.029 (0.377)	DT 0.000 (0.335)	loss 8.819 (8.368)	prob 3.217 (3.383)	GS 38.281 (32.645)	mem 75.326
Train: [10][450/1500]	BT 0.062 (0.385)	DT 0.001 (0.344)	loss 9.124 (8.395)	prob 3.339 (3.351)	GS 37.125 (32.828)	mem 75.395
Train: [10][460/1500]	BT 0.066 (0.378)	DT 0.014 (0.337)	loss 8.372 (8.391)	prob 4.416 (3.401)	GS 35.531 (32.275)	mem 75.397
Train: [10][470/1500]	BT 2.215 (0.376)	DT 2.179 (0.334)	loss 8.270 (8.425)	prob 3.428 (3.275)	GS 39.234 (33.037)	mem 75.430
Train: [10][480/1500]	BT 0.031 (0.378)	DT 0.000 (0.337)	loss 9.632 (8.425)	prob 4.112 (3.408)	GS 30.109 (32.537)	mem 75.546
Train: [10][490/1500]	BT 0.052 (0.372)	DT 0.011 (0.330)	loss 8.275 (8.391)	prob 4.937 (3.583)	GS 28.422 (32.139)	mem 75.550
Train: [10][500/1500]	BT 0.031 (0.373)	DT 0.000 (0.331)	loss 8.679 (8.435)	prob 3.268 (3.517)	GS 32.172 (32.256)	mem 76.035
Train: [10][510/1500]	BT 0.088 (0.366)	DT 0.007 (0.325)	loss 8.791 (8.401)	prob 3.427 (3.286)	GS 39.438 (33.827)	mem 76.052
Train: [10][520/1500]	BT 0.039 (0.369)	DT 0.001 (0.326)	loss 8.892 (8.503)	prob 4.329 (3.176)	GS 36.406 (33.968)	mem 76.433
Train: [10][530/1500]	BT 0.237 (0.363)	DT 0.199 (0.321)	loss 8.154 (8.439)	prob 4.549 (3.216)	GS 30.141 (33.639)	mem 76.548
Train: [10][540/1500]	BT 0.040 (0.357)	DT 0.001 (0.315)	loss 8.683 (8.466)	prob 4.165 (3.330)	GS 34.391 (33.377)	mem 76.556
Train: [10][550/1500]	BT 0.039 (0.358)	DT 0.001 (0.316)	loss 9.334 (8.431)	prob 4.131 (3.397)	GS 37.359 (33.222)	mem 76.954
Train: [10][560/1500]	BT 0.064 (0.355)	DT 0.003 (0.313)	loss 8.065 (8.375)	prob 4.138 (3.670)	GS 33.703 (32.061)	mem 77.013
Train: [10][570/1500]	BT 0.031 (0.368)	DT 0.001 (0.326)	loss 8.371 (8.380)	prob 4.498 (3.690)	GS 30.938 (32.046)	mem 77.156
Train: [10][580/1500]	BT 0.040 (0.363)	DT 0.001 (0.320)	loss 8.824 (8.482)	prob 4.015 (3.569)	GS 32.406 (32.428)	mem 77.170
Train: [10][590/1500]	BT 0.041 (0.357)	DT 0.001 (0.315)	loss 7.750 (8.431)	prob 3.924 (3.584)	GS 32.562 (32.800)	mem 77.161
Train: [10][600/1500]	BT 0.040 (0.359)	DT 0.001 (0.316)	loss 8.032 (8.367)	prob 3.260 (3.527)	GS 35.359 (33.114)	mem 77.296
Train: [10][610/1500]	BT 0.040 (0.353)	DT 0.001 (0.311)	loss 8.197 (8.318)	prob 3.783 (3.103)	GS 37.984 (34.120)	mem 77.307
Train: [10][620/1500]	BT 0.039 (0.356)	DT 0.001 (0.313)	loss 7.782 (8.256)	prob 3.867 (3.174)	GS 35.125 (33.592)	mem 76.533
Train: [10][630/1500]	BT 0.039 (0.350)	DT 0.001 (0.308)	loss 9.191 (8.237)	prob 3.705 (3.310)	GS 32.453 (33.009)	mem 76.538
Train: [10][640/1500]	BT 0.032 (0.346)	DT 0.001 (0.304)	loss 8.468 (8.239)	prob 3.049 (3.344)	GS 37.562 (32.972)	mem 76.544
Train: [10][650/1500]	BT 0.032 (0.348)	DT 0.000 (0.306)	loss 8.781 (8.232)	prob 4.108 (3.434)	GS 34.797 (32.633)	mem 76.606
Train: [10][660/1500]	BT 0.026 (0.343)	DT 0.000 (0.301)	loss 8.477 (8.219)	prob 3.864 (3.377)	GS 27.344 (31.708)	mem 76.613
Train: [10][670/1500]	BT 0.028 (0.350)	DT 0.000 (0.309)	loss 8.290 (8.259)	prob 3.988 (3.327)	GS 34.469 (32.111)	mem 76.644
Train: [10][680/1500]	BT 0.040 (0.346)	DT 0.001 (0.304)	loss 8.372 (8.259)	prob 3.478 (3.226)	GS 34.453 (32.452)	mem 76.649
Train: [10][690/1500]	BT 0.038 (0.348)	DT 0.001 (0.307)	loss 8.599 (8.265)	prob 2.589 (3.270)	GS 33.266 (32.359)	mem 76.677
Train: [10][700/1500]	BT 0.030 (0.344)	DT 0.001 (0.303)	loss 8.060 (8.291)	prob 3.832 (3.228)	GS 39.922 (32.741)	mem 76.685
Train: [10][710/1500]	BT 0.040 (0.340)	DT 0.001 (0.298)	loss 8.076 (8.336)	prob 3.941 (2.793)	GS 31.297 (32.078)	mem 76.689
Train: [10][720/1500]	BT 0.026 (0.340)	DT 0.000 (0.299)	loss 7.875 (8.273)	prob 4.480 (3.141)	GS 32.156 (31.547)	mem 76.719
Train: [10][730/1500]	BT 0.026 (0.335)	DT 0.000 (0.295)	loss 8.346 (8.320)	prob 3.718 (3.105)	GS 33.797 (31.938)	mem 76.722
Train: [10][740/1500]	BT 0.038 (0.336)	DT 0.001 (0.295)	loss 8.973 (8.359)	prob 2.933 (3.063)	GS 31.141 (31.748)	mem 76.796
Train: [10][750/1500]	BT 0.035 (0.333)	DT 0.001 (0.292)	loss 7.886 (8.291)	prob 3.033 (2.998)	GS 31.047 (31.924)	mem 76.822
Train: [10][760/1500]	BT 0.064 (0.329)	DT 0.005 (0.288)	loss 7.946 (8.252)	prob 2.748 (2.524)	GS 36.391 (32.975)	mem 76.830
Train: [10][770/1500]	BT 0.038 (0.330)	DT 0.001 (0.290)	loss 8.391 (8.153)	prob 3.080 (2.499)	GS 31.188 (32.092)	mem 76.946
Train: [10][780/1500]	BT 0.034 (0.328)	DT 0.001 (0.287)	loss 8.278 (8.090)	prob 2.902 (2.507)	GS 33.266 (32.389)	mem 76.965
Train: [10][790/1500]	BT 0.036 (0.334)	DT 0.000 (0.293)	loss 8.328 (8.128)	prob 2.835 (2.406)	GS 30.844 (32.485)	mem 77.091
Train: [10][800/1500]	BT 0.031 (0.331)	DT 0.000 (0.290)	loss 8.124 (8.134)	prob 3.438 (2.334)	GS 32.781 (32.543)	mem 77.104
Train: [10][810/1500]	BT 0.052 (0.337)	DT 0.004 (0.296)	loss 9.464 (8.281)	prob 1.235 (1.926)	GS 37.609 (34.725)	mem 77.203
Train: [10][820/1500]	BT 0.038 (0.333)	DT 0.002 (0.292)	loss 8.501 (8.205)	prob 1.221 (1.813)	GS 38.719 (33.620)	mem 77.213
Train: [10][830/1500]	BT 0.037 (0.330)	DT 0.001 (0.289)	loss 8.347 (8.213)	prob 2.245 (1.890)	GS 33.516 (33.187)	mem 77.219
Train: [10][840/1500]	BT 0.027 (0.334)	DT 0.000 (0.293)	loss 8.996 (8.249)	prob 2.237 (1.857)	GS 34.688 (32.650)	mem 77.285
Train: [10][850/1500]	BT 0.040 (0.330)	DT 0.001 (0.289)	loss 8.397 (8.301)	prob 2.296 (1.738)	GS 35.641 (32.916)	mem 77.290
Train: [10][860/1500]	BT 0.055 (0.334)	DT 0.001 (0.293)	loss 8.746 (8.434)	prob 1.373 (1.388)	GS 36.812 (34.242)	mem 76.468
Train: [10][870/1500]	BT 0.055 (0.330)	DT 0.001 (0.290)	loss 8.283 (8.407)	prob 1.241 (1.352)	GS 36.469 (34.036)	mem 76.471
Train: [10][880/1500]	BT 0.110 (0.334)	DT 0.032 (0.293)	loss 9.373 (8.418)	prob 1.793 (1.398)	GS 38.328 (34.011)	mem 76.536
Train: [10][890/1500]	BT 0.027 (0.349)	DT 0.000 (0.308)	loss 8.677 (8.440)	prob 1.718 (1.409)	GS 30.859 (34.104)	mem 76.708
Train: [10][900/1500]	BT 0.036 (0.346)	DT 0.001 (0.305)	loss 8.780 (8.436)	prob 2.620 (1.531)	GS 33.297 (33.591)	mem 76.720
Train: [10][910/1500]	BT 0.040 (0.345)	DT 0.001 (0.305)	loss 8.160 (8.353)	prob 3.232 (1.820)	GS 32.891 (32.272)	mem 76.782
Train: [10][920/1500]	BT 0.041 (0.342)	DT 0.001 (0.301)	loss 9.418 (8.398)	prob 1.500 (1.698)	GS 30.719 (32.143)	mem 76.798
Train: [10][930/1500]	BT 0.042 (0.339)	DT 0.001 (0.298)	loss 8.410 (8.384)	prob 3.401 (1.843)	GS 31.422 (32.268)	mem 76.812
Train: [10][940/1500]	BT 0.040 (0.339)	DT 0.001 (0.298)	loss 7.938 (8.295)	prob 2.478 (1.965)	GS 31.328 (32.153)	mem 76.895
Train: [10][950/1500]	BT 0.040 (0.336)	DT 0.001 (0.295)	loss 7.808 (8.258)	prob 4.171 (2.132)	GS 34.594 (32.056)	mem 76.901
Train: [10][960/1500]	BT 0.040 (0.338)	DT 0.001 (0.298)	loss 9.117 (8.206)	prob 2.886 (2.606)	GS 32.484 (30.677)	mem 77.005
Train: [10][970/1500]	BT 0.039 (0.335)	DT 0.000 (0.295)	loss 8.622 (8.230)	prob 2.677 (2.401)	GS 34.656 (32.114)	mem 77.011
Train: [10][980/1500]	BT 5.150 (0.337)	DT 5.111 (0.297)	loss 8.318 (8.324)	prob 2.516 (2.297)	GS 37.266 (32.514)	mem 77.104
Train: [10][990/1500]	BT 0.039 (0.335)	DT 0.001 (0.295)	loss 8.066 (8.306)	prob 3.343 (2.302)	GS 35.031 (32.584)	mem 77.143
Train: [10][1000/1500]	BT 0.040 (0.332)	DT 0.001 (0.292)	loss 9.238 (8.330)	prob 2.293 (2.260)	GS 36.188 (32.752)	mem 77.154
Train: [10][1010/1500]	BT 0.039 (0.332)	DT 0.001 (0.292)	loss 7.957 (8.333)	prob 2.857 (2.447)	GS 29.641 (33.492)	mem 77.221
Train: [10][1020/1500]	BT 0.040 (0.330)	DT 0.001 (0.289)	loss 8.716 (8.379)	prob 3.099 (2.473)	GS 30.594 (32.829)	mem 77.229
Train: [10][1030/1500]	BT 0.040 (0.330)	DT 0.001 (0.290)	loss 8.958 (8.374)	prob 3.284 (2.749)	GS 30.281 (32.304)	mem 77.277
Train: [10][1040/1500]	BT 0.030 (0.328)	DT 0.001 (0.288)	loss 8.512 (8.418)	prob 3.169 (2.738)	GS 40.094 (32.259)	mem 77.342
Train: [10][1050/1500]	BT 0.041 (0.326)	DT 0.001 (0.285)	loss 7.780 (8.365)	prob 4.620 (2.809)	GS 34.250 (32.299)	mem 77.354
Train: [10][1060/1500]	BT 0.037 (0.328)	DT 0.001 (0.287)	loss 8.341 (8.244)	prob 4.075 (3.450)	GS 28.156 (30.427)	mem 76.490
Train: [10][1070/1500]	BT 0.038 (0.325)	DT 0.001 (0.285)	loss 7.547 (8.249)	prob 4.133 (3.421)	GS 32.578 (31.146)	mem 76.497
Train: [10][1080/1500]	BT 0.062 (0.325)	DT 0.014 (0.285)	loss 8.638 (8.239)	prob 3.681 (3.322)	GS 34.766 (32.123)	mem 76.532
Train: [10][1090/1500]	BT 0.031 (0.328)	DT 0.000 (0.287)	loss 8.149 (8.238)	prob 3.288 (3.200)	GS 30.984 (32.207)	mem 76.579
Train: [10][1100/1500]	BT 1.207 (0.326)	DT 1.159 (0.286)	loss 8.429 (8.276)	prob 3.858 (3.197)	GS 34.875 (32.387)	mem 76.588
Train: [10][1110/1500]	BT 0.038 (0.326)	DT 0.001 (0.286)	loss 8.276 (8.348)	prob 4.520 (3.553)	GS 31.625 (32.202)	mem 76.615
Train: [10][1120/1500]	BT 0.038 (0.324)	DT 0.001 (0.283)	loss 7.976 (8.325)	prob 4.270 (3.489)	GS 35.625 (32.898)	mem 76.618
Train: [10][1130/1500]	BT 0.405 (0.324)	DT 0.355 (0.283)	loss 7.720 (8.325)	prob 4.522 (3.534)	GS 33.578 (32.938)	mem 76.652
Train: [10][1140/1500]	BT 0.061 (0.322)	DT 0.011 (0.282)	loss 8.117 (8.338)	prob 4.867 (3.581)	GS 31.266 (32.830)	mem 76.657
Train: [10][1150/1500]	BT 0.022 (0.331)	DT 0.000 (0.290)	loss 8.606 (8.312)	prob 4.088 (3.621)	GS 28.906 (32.816)	mem 76.819
Train: [10][1160/1500]	BT 0.028 (0.328)	DT 0.001 (0.288)	loss 8.045 (8.243)	prob 4.665 (3.486)	GS 35.219 (33.772)	mem 76.829
Train: [10][1170/1500]	BT 0.035 (0.330)	DT 0.000 (0.290)	loss 8.663 (8.349)	prob 3.684 (3.522)	GS 30.453 (33.643)	mem 76.999
Train: [10][1180/1500]	BT 0.031 (0.328)	DT 0.000 (0.287)	loss 8.836 (8.334)	prob 4.049 (3.676)	GS 33.031 (33.139)	mem 77.008
Train: [10][1190/1500]	BT 0.040 (0.325)	DT 0.001 (0.285)	loss 9.057 (8.359)	prob 4.522 (3.678)	GS 36.375 (33.146)	mem 77.018
Train: [10][1200/1500]	BT 0.034 (0.326)	DT 0.001 (0.286)	loss 8.386 (8.340)	prob 3.391 (3.796)	GS 36.000 (32.938)	mem 77.123
Train: [10][1210/1500]	BT 0.038 (0.324)	DT 0.001 (0.284)	loss 8.262 (8.302)	prob 4.732 (3.954)	GS 32.531 (33.491)	mem 77.137
Train: [10][1220/1500]	BT 0.041 (0.327)	DT 0.001 (0.287)	loss 8.628 (8.262)	prob 4.489 (4.111)	GS 32.578 (32.605)	mem 77.313
Train: [10][1230/1500]	BT 0.040 (0.325)	DT 0.001 (0.284)	loss 8.378 (8.213)	prob 4.587 (4.141)	GS 35.047 (32.568)	mem 77.289
Train: [10][1240/1500]	BT 0.042 (0.322)	DT 0.001 (0.282)	loss 8.768 (8.218)	prob 4.481 (4.183)	GS 35.781 (33.109)	mem 77.296
Train: [10][1250/1500]	BT 0.023 (0.326)	DT 0.000 (0.286)	loss 8.261 (8.182)	prob 4.938 (4.295)	GS 42.312 (33.291)	mem 79.438
Train: [10][1260/1500]	BT 0.024 (0.324)	DT 0.000 (0.284)	loss 8.550 (8.192)	prob 4.857 (4.767)	GS 37.844 (32.972)	mem 79.441
Train: [10][1270/1500]	BT 0.029 (0.325)	DT 0.000 (0.285)	loss 7.993 (8.147)	prob 3.935 (4.581)	GS 35.391 (33.034)	mem 76.594
Train: [10][1280/1500]	BT 0.039 (0.322)	DT 0.001 (0.283)	loss 7.949 (8.142)	prob 4.994 (4.512)	GS 30.484 (32.885)	mem 76.600
Train: [10][1290/1500]	BT 0.042 (0.324)	DT 0.001 (0.284)	loss 8.258 (8.159)	prob 3.833 (4.540)	GS 34.125 (32.696)	mem 76.647
Train: [10][1300/1500]	BT 0.039 (0.321)	DT 0.001 (0.282)	loss 8.831 (8.157)	prob 4.361 (4.506)	GS 35.156 (32.667)	mem 76.655
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [10][1310/1500]	BT 0.039 (0.319)	DT 0.001 (0.279)	loss 8.204 (8.187)	prob 4.948 (4.378)	GS 35.750 (32.608)	mem 76.667
Train: [10][1320/1500]	BT 0.030 (0.320)	DT 0.000 (0.281)	loss 8.476 (8.045)	prob 4.482 (4.554)	GS 38.859 (32.796)	mem 76.766
Train: [10][1330/1500]	BT 0.098 (0.318)	DT 0.000 (0.279)	loss 8.191 (8.052)	prob 5.106 (4.577)	GS 34.562 (32.633)	mem 76.778
Train: [10][1340/1500]	BT 0.038 (0.320)	DT 0.001 (0.280)	loss 8.323 (8.058)	prob 4.994 (4.624)	GS 32.328 (32.671)	mem 76.858
Train: [10][1350/1500]	BT 0.052 (0.318)	DT 0.014 (0.278)	loss 7.872 (8.054)	prob 5.279 (4.605)	GS 32.953 (32.515)	mem 76.866
Train: [10][1360/1500]	BT 0.035 (0.316)	DT 0.000 (0.276)	loss 8.245 (7.979)	prob 4.692 (5.024)	GS 31.438 (31.102)	mem 76.875
Train: [10][1370/1500]	BT 0.061 (0.323)	DT 0.011 (0.283)	loss 8.072 (8.046)	prob 4.710 (4.683)	GS 32.469 (32.824)	mem 77.031
Train: [10][1380/1500]	BT 0.071 (0.321)	DT 0.011 (0.281)	loss 8.122 (8.022)	prob 5.130 (4.690)	GS 30.188 (32.761)	mem 77.036
Train: [10][1390/1500]	BT 0.039 (0.324)	DT 0.001 (0.284)	loss 7.554 (7.957)	prob 4.800 (4.738)	GS 31.609 (32.941)	mem 77.123
Train: [10][1400/1500]	BT 0.031 (0.324)	DT 0.000 (0.284)	loss 8.279 (7.949)	prob 4.533 (4.726)	GS 33.375 (33.092)	mem 77.224
Train: [10][1410/1500]	BT 0.040 (0.322)	DT 0.000 (0.282)	loss 8.028 (7.937)	prob 5.428 (5.082)	GS 33.594 (32.273)	mem 77.237
Train: [10][1420/1500]	BT 0.039 (0.322)	DT 0.001 (0.282)	loss 7.693 (7.951)	prob 5.894 (5.031)	GS 34.703 (32.468)	mem 77.299
Train: [10][1430/1500]	BT 0.038 (0.320)	DT 0.001 (0.280)	loss 7.945 (7.918)	prob 4.604 (4.917)	GS 31.281 (32.574)	mem 77.307
Train: [10][1440/1500]	BT 0.075 (0.319)	DT 0.016 (0.279)	loss 7.175 (7.858)	prob 5.724 (4.927)	GS 37.922 (32.761)	mem 77.333
Train: [10][1450/1500]	BT 0.040 (0.320)	DT 0.001 (0.281)	loss 7.699 (7.824)	prob 5.008 (4.890)	GS 35.578 (32.667)	mem 76.585
Train: [10][1460/1500]	BT 0.035 (0.323)	DT 0.001 (0.283)	loss 8.431 (7.844)	prob 4.944 (4.780)	GS 31.609 (34.084)	mem 75.768
Train: [10][1470/1500]	BT 0.030 (0.321)	DT 0.001 (0.281)	loss 8.002 (7.827)	prob 4.436 (4.645)	GS 33.797 (34.008)	mem 75.778
Train: [10][1480/1500]	BT 0.031 (0.319)	DT 0.000 (0.279)	loss 7.538 (7.810)	prob 5.349 (4.885)	GS 34.438 (33.114)	mem 75.758
Train: [10][1490/1500]	BT 0.031 (0.319)	DT 0.001 (0.279)	loss 7.840 (7.775)	prob 4.337 (4.873)	GS 37.781 (33.079)	mem 11.663
Train: [10][1500/1500]	BT 0.027 (0.317)	DT 0.000 (0.277)	loss 7.142 (7.748)	prob 5.258 (4.846)	GS 33.062 (32.890)	mem 11.669
Train: [10][1510/1500]	BT 0.033 (0.315)	DT 0.000 (0.276)	loss 7.710 (7.545)	prob 5.347 (4.567)	GS 37.781 (33.869)	mem 11.616
epoch 10, total time 476.12
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [11][1/1500]	BT 18.415 (18.415)	DT 18.357 (18.357)	loss 7.243 (7.243)	prob 5.001 (5.001)	GS 31.922 (31.922)	mem 75.507
Train: [11][10/1500]	BT 0.062 (2.386)	DT 0.002 (2.342)	loss 7.230 (7.359)	prob 4.432 (4.957)	GS 34.828 (32.660)	mem 75.866
Train: [11][20/1500]	BT 0.064 (1.242)	DT 0.003 (1.200)	loss 7.603 (7.451)	prob 4.890 (4.824)	GS 35.609 (33.947)	mem 75.926
Train: [11][30/1500]	BT 0.039 (0.960)	DT 0.001 (0.919)	loss 7.380 (7.442)	prob 5.413 (4.927)	GS 35.266 (33.213)	mem 76.096
Train: [11][40/1500]	BT 0.035 (0.769)	DT 0.000 (0.724)	loss 7.646 (7.444)	prob 5.853 (5.041)	GS 31.547 (32.459)	mem 76.122
Train: [11][50/1500]	BT 0.039 (0.625)	DT 0.000 (0.580)	loss 7.248 (7.458)	prob 5.225 (5.039)	GS 34.375 (32.481)	mem 76.136
Train: [11][60/1500]	BT 0.036 (0.625)	DT 0.001 (0.578)	loss 7.416 (7.580)	prob 4.779 (4.830)	GS 30.062 (31.903)	mem 75.637
Train: [11][70/1500]	BT 0.029 (0.650)	DT 0.000 (0.604)	loss 7.477 (7.550)	prob 5.507 (4.935)	GS 33.562 (33.089)	mem 78.341
Train: [11][80/1500]	BT 0.040 (0.573)	DT 0.001 (0.528)	loss 7.433 (7.581)	prob 5.484 (4.807)	GS 37.703 (32.902)	mem 75.453
Train: [11][90/1500]	BT 0.041 (0.558)	DT 0.001 (0.514)	loss 7.962 (7.590)	prob 4.464 (4.759)	GS 35.828 (32.905)	mem 75.501
Train: [11][100/1500]	BT 0.041 (0.506)	DT 0.001 (0.462)	loss 7.398 (7.604)	prob 4.886 (4.724)	GS 34.578 (32.748)	mem 75.508
Train: [11][110/1500]	BT 0.040 (0.463)	DT 0.001 (0.420)	loss 8.044 (7.675)	prob 4.399 (4.539)	GS 33.219 (33.503)	mem 75.510
Train: [11][120/1500]	BT 0.037 (0.461)	DT 0.001 (0.419)	loss 8.600 (7.667)	prob 4.756 (4.424)	GS 32.422 (32.813)	mem 75.556
Train: [11][130/1500]	BT 0.038 (0.429)	DT 0.001 (0.387)	loss 7.775 (7.702)	prob 3.836 (4.246)	GS 35.562 (32.911)	mem 75.566
Train: [11][140/1500]	BT 0.039 (0.423)	DT 0.001 (0.381)	loss 8.114 (7.688)	prob 3.084 (4.100)	GS 33.578 (32.735)	mem 75.605
Train: [11][150/1500]	BT 0.039 (0.398)	DT 0.001 (0.356)	loss 7.709 (7.692)	prob 3.711 (3.974)	GS 30.703 (32.662)	mem 75.617
Train: [11][160/1500]	BT 0.067 (0.394)	DT 0.017 (0.352)	loss 7.686 (7.712)	prob 3.444 (3.691)	GS 32.984 (32.188)	mem 75.656
Train: [11][170/1500]	BT 0.035 (0.395)	DT 0.001 (0.353)	loss 8.026 (7.759)	prob 2.943 (3.175)	GS 30.031 (32.036)	mem 75.688
Train: [11][180/1500]	BT 0.038 (0.396)	DT 0.000 (0.354)	loss 7.360 (7.813)	prob 3.656 (3.026)	GS 35.828 (32.082)	mem 75.763
Train: [11][190/1500]	BT 0.038 (0.387)	DT 0.000 (0.345)	loss 7.873 (7.810)	prob 2.273 (2.845)	GS 35.266 (32.482)	mem 75.835
Train: [11][200/1500]	BT 0.038 (0.379)	DT 0.001 (0.337)	loss 8.423 (7.833)	prob 1.615 (2.659)	GS 37.250 (32.824)	mem 75.935
Train: [11][210/1500]	BT 0.037 (0.376)	DT 0.000 (0.334)	loss 7.399 (7.880)	prob 2.529 (1.979)	GS 35.422 (33.316)	mem 75.877
Train: [11][220/1500]	BT 0.038 (0.362)	DT 0.000 (0.321)	loss 8.310 (7.884)	prob 2.842 (1.911)	GS 33.672 (32.705)	mem 75.892
Train: [11][230/1500]	BT 0.037 (0.349)	DT 0.001 (0.308)	loss 8.393 (7.880)	prob 1.517 (1.874)	GS 34.828 (32.714)	mem 75.902
Train: [11][240/1500]	BT 0.040 (0.348)	DT 0.001 (0.306)	loss 7.895 (7.883)	prob 1.458 (1.836)	GS 35.938 (32.987)	mem 75.959
Train: [11][250/1500]	BT 0.040 (0.348)	DT 0.001 (0.307)	loss 7.897 (7.896)	prob 2.470 (1.789)	GS 36.453 (33.076)	mem 76.036
Train: [11][260/1500]	BT 0.084 (0.337)	DT 0.004 (0.295)	loss 8.297 (7.941)	prob 1.337 (1.841)	GS 31.281 (31.469)	mem 76.049
Train: [11][270/1500]	BT 0.040 (0.337)	DT 0.004 (0.295)	loss 7.537 (7.980)	prob 1.976 (1.766)	GS 30.578 (31.692)	mem 76.136
Train: [11][280/1500]	BT 0.067 (0.343)	DT 0.016 (0.301)	loss 7.832 (7.965)	prob 2.191 (1.866)	GS 35.844 (32.117)	mem 76.220
Train: [11][290/1500]	BT 0.057 (0.349)	DT 0.013 (0.307)	loss 8.039 (8.029)	prob 1.643 (1.729)	GS 31.969 (32.328)	mem 75.393
Train: [11][300/1500]	BT 0.030 (0.355)	DT 0.000 (0.312)	loss 8.087 (8.044)	prob 1.986 (1.780)	GS 35.141 (32.485)	mem 75.422
Train: [11][310/1500]	BT 0.038 (0.354)	DT 0.001 (0.312)	loss 7.784 (8.236)	prob 2.081 (1.624)	GS 36.516 (34.372)	mem 75.462
Train: [11][320/1500]	BT 0.030 (0.345)	DT 0.000 (0.303)	loss 7.603 (8.090)	prob 2.170 (1.650)	GS 34.875 (33.367)	mem 75.468
Train: [11][330/1500]	BT 0.039 (0.340)	DT 0.001 (0.298)	loss 8.175 (8.081)	prob 2.590 (1.769)	GS 35.000 (33.154)	mem 75.485
Train: [11][340/1500]	BT 0.036 (0.341)	DT 0.001 (0.299)	loss 7.841 (8.119)	prob 1.868 (1.751)	GS 34.672 (33.453)	mem 75.508
Train: [11][350/1500]	BT 0.066 (0.333)	DT 0.006 (0.291)	loss 8.867 (8.132)	prob 2.976 (1.881)	GS 33.125 (33.246)	mem 75.483
Train: [11][360/1500]	BT 0.041 (0.342)	DT 0.001 (0.300)	loss 8.883 (8.396)	prob 1.705 (2.236)	GS 35.750 (33.264)	mem 75.557
Train: [11][370/1500]	BT 0.040 (0.338)	DT 0.001 (0.296)	loss 9.024 (8.376)	prob 2.571 (2.212)	GS 32.688 (33.482)	mem 75.558
Train: [11][380/1500]	BT 0.039 (0.336)	DT 0.001 (0.293)	loss 8.528 (8.342)	prob 2.324 (2.155)	GS 32.094 (33.182)	mem 75.585
Train: [11][390/1500]	BT 0.034 (0.334)	DT 0.001 (0.292)	loss 7.591 (8.280)	prob 2.678 (2.211)	GS 32.625 (32.881)	mem 75.612
Train: [11][400/1500]	BT 0.065 (0.327)	DT 0.014 (0.285)	loss 7.873 (8.249)	prob 2.343 (2.173)	GS 32.969 (33.240)	mem 75.619
Train: [11][410/1500]	BT 0.064 (0.326)	DT 0.006 (0.284)	loss 9.243 (8.365)	prob 2.263 (2.253)	GS 35.172 (33.822)	mem 75.658
Train: [11][420/1500]	BT 0.039 (0.333)	DT 0.001 (0.291)	loss 7.720 (8.257)	prob 3.252 (2.322)	GS 30.391 (33.141)	mem 75.753
Train: [11][430/1500]	BT 0.049 (0.328)	DT 0.003 (0.286)	loss 8.744 (8.280)	prob 2.227 (2.352)	GS 32.156 (32.857)	mem 75.775
Train: [11][440/1500]	BT 0.039 (0.331)	DT 0.001 (0.289)	loss 8.393 (8.235)	prob 3.614 (2.440)	GS 36.266 (32.909)	mem 75.855
Train: [11][450/1500]	BT 0.037 (0.324)	DT 0.001 (0.282)	loss 8.385 (8.230)	prob 1.462 (2.487)	GS 37.547 (33.088)	mem 75.881
Train: [11][460/1500]	BT 0.043 (0.325)	DT 0.001 (0.283)	loss 8.504 (8.225)	prob 3.067 (2.523)	GS 31.328 (31.413)	mem 75.983
Train: [11][470/1500]	BT 0.042 (0.319)	DT 0.001 (0.277)	loss 8.553 (8.363)	prob 2.775 (2.581)	GS 35.781 (32.523)	mem 75.990
Train: [11][480/1500]	BT 0.031 (0.339)	DT 0.000 (0.297)	loss 8.065 (8.328)	prob 2.770 (2.729)	GS 30.438 (32.374)	mem 77.319
Train: [11][490/1500]	BT 0.058 (0.333)	DT 0.011 (0.291)	loss 8.816 (8.325)	prob 2.758 (2.685)	GS 33.531 (32.397)	mem 77.375
Train: [11][500/1500]	BT 0.035 (0.327)	DT 0.000 (0.286)	loss 8.106 (8.270)	prob 3.982 (2.736)	GS 33.500 (32.480)	mem 77.403
Train: [11][510/1500]	BT 0.031 (0.355)	DT 0.000 (0.313)	loss 8.215 (8.270)	prob 4.217 (2.872)	GS 34.844 (32.809)	mem 75.524
Train: [11][520/1500]	BT 0.029 (0.348)	DT 0.000 (0.307)	loss 8.496 (8.206)	prob 3.104 (3.023)	GS 36.422 (32.906)	mem 75.530
Train: [11][530/1500]	BT 0.031 (0.351)	DT 0.000 (0.310)	loss 8.166 (8.219)	prob 3.697 (3.029)	GS 34.062 (32.709)	mem 75.651
Train: [11][540/1500]	BT 0.035 (0.346)	DT 0.000 (0.304)	loss 8.863 (8.252)	prob 3.484 (2.964)	GS 30.625 (32.680)	mem 75.653
Train: [11][550/1500]	BT 0.031 (0.340)	DT 0.001 (0.299)	loss 7.891 (8.218)	prob 3.433 (2.993)	GS 35.984 (32.525)	mem 75.657
Train: [11][560/1500]	BT 0.030 (0.349)	DT 0.000 (0.308)	loss 8.913 (8.367)	prob 2.834 (2.695)	GS 37.328 (34.844)	mem 76.264
Train: [11][570/1500]	BT 0.026 (0.343)	DT 0.000 (0.302)	loss 8.097 (8.265)	prob 3.559 (2.787)	GS 34.094 (33.591)	mem 76.322
Train: [11][580/1500]	BT 0.043 (0.342)	DT 0.006 (0.302)	loss 7.656 (8.194)	prob 3.736 (2.945)	GS 34.969 (33.162)	mem 76.882
Train: [11][590/1500]	BT 0.038 (0.339)	DT 0.001 (0.298)	loss 8.254 (8.199)	prob 2.551 (2.889)	GS 31.047 (33.193)	mem 76.896
Train: [11][600/1500]	BT 3.111 (0.339)	DT 3.074 (0.298)	loss 7.882 (8.184)	prob 3.062 (2.857)	GS 34.281 (33.274)	mem 77.045
Train: [11][610/1500]	BT 0.038 (0.334)	DT 0.001 (0.294)	loss 8.252 (8.073)	prob 3.472 (3.444)	GS 34.422 (32.455)	mem 77.054
Train: [11][620/1500]	BT 0.038 (0.329)	DT 0.001 (0.289)	loss 8.544 (8.117)	prob 3.022 (3.147)	GS 34.641 (33.253)	mem 77.061
Train: [11][630/1500]	BT 0.038 (0.331)	DT 0.000 (0.290)	loss 8.104 (8.105)	prob 3.279 (3.105)	GS 34.312 (32.906)	mem 77.138
Train: [11][640/1500]	BT 0.041 (0.327)	DT 0.001 (0.287)	loss 7.673 (8.078)	prob 4.281 (3.094)	GS 31.312 (32.577)	mem 77.167
Train: [11][650/1500]	BT 0.040 (0.326)	DT 0.001 (0.286)	loss 8.260 (8.101)	prob 3.537 (3.101)	GS 37.719 (32.571)	mem 77.251
Train: [11][660/1500]	BT 0.038 (0.324)	DT 0.001 (0.283)	loss 8.288 (8.013)	prob 3.577 (3.329)	GS 33.125 (31.602)	mem 77.293
Train: [11][670/1500]	BT 0.039 (0.320)	DT 0.001 (0.279)	loss 8.180 (8.078)	prob 3.271 (3.374)	GS 33.828 (30.989)	mem 77.300
Train: [11][680/1500]	BT 0.041 (0.326)	DT 0.001 (0.286)	loss 8.020 (8.065)	prob 3.172 (3.257)	GS 33.031 (31.183)	mem 77.449
Train: [11][690/1500]	BT 0.038 (0.322)	DT 0.001 (0.281)	loss 8.161 (8.045)	prob 3.685 (3.222)	GS 36.438 (31.896)	mem 77.458
Train: [11][700/1500]	BT 0.039 (0.322)	DT 0.001 (0.282)	loss 8.532 (8.054)	prob 3.446 (3.230)	GS 31.250 (31.892)	mem 76.648
Train: [11][710/1500]	BT 0.031 (0.321)	DT 0.000 (0.281)	loss 8.093 (7.950)	prob 3.256 (3.148)	GS 31.875 (32.186)	mem 76.679
Train: [11][720/1500]	BT 4.963 (0.324)	DT 4.920 (0.284)	loss 8.536 (7.948)	prob 3.107 (3.203)	GS 31.453 (31.745)	mem 76.718
Train: [11][730/1500]	BT 0.031 (0.325)	DT 0.000 (0.284)	loss 8.209 (7.935)	prob 4.284 (3.302)	GS 30.531 (31.910)	mem 76.742
Train: [11][740/1500]	BT 0.031 (0.333)	DT 0.000 (0.293)	loss 8.190 (7.978)	prob 3.381 (3.211)	GS 31.453 (32.298)	mem 76.815
Train: [11][750/1500]	BT 0.037 (0.329)	DT 0.001 (0.289)	loss 7.709 (7.964)	prob 4.456 (3.254)	GS 31.375 (31.984)	mem 76.825
Train: [11][760/1500]	BT 0.035 (0.330)	DT 0.001 (0.290)	loss 8.007 (7.757)	prob 2.703 (3.158)	GS 35.000 (33.241)	mem 76.925
Train: [11][770/1500]	BT 0.038 (0.327)	DT 0.001 (0.286)	loss 8.317 (7.816)	prob 2.664 (2.954)	GS 36.141 (33.132)	mem 76.936
Train: [11][780/1500]	BT 0.039 (0.323)	DT 0.001 (0.283)	loss 7.858 (7.770)	prob 3.950 (3.106)	GS 32.453 (32.645)	mem 76.943
Train: [11][790/1500]	BT 0.040 (0.328)	DT 0.002 (0.288)	loss 7.188 (7.771)	prob 3.673 (3.120)	GS 30.828 (32.365)	mem 77.085
Train: [11][800/1500]	BT 0.041 (0.325)	DT 0.001 (0.285)	loss 7.983 (7.848)	prob 3.732 (3.081)	GS 34.688 (32.382)	mem 77.097
Train: [11][810/1500]	BT 0.037 (0.326)	DT 0.001 (0.286)	loss 8.186 (7.930)	prob 3.459 (3.089)	GS 27.719 (32.128)	mem 77.224
Train: [11][820/1500]	BT 0.038 (0.323)	DT 0.001 (0.283)	loss 7.553 (7.948)	prob 3.037 (2.901)	GS 31.203 (33.017)	mem 77.226
Train: [11][830/1500]	BT 0.039 (0.319)	DT 0.001 (0.279)	loss 8.008 (7.904)	prob 3.257 (2.941)	GS 39.672 (32.859)	mem 77.238
Train: [11][840/1500]	BT 0.060 (0.322)	DT 0.016 (0.282)	loss 7.722 (7.890)	prob 3.548 (2.894)	GS 33.234 (32.963)	mem 77.373
Train: [11][850/1500]	BT 0.027 (0.323)	DT 0.000 (0.283)	loss 8.101 (7.879)	prob 2.919 (2.883)	GS 34.203 (33.203)	mem 77.471
Train: [11][860/1500]	BT 0.030 (0.320)	DT 0.001 (0.280)	loss 7.475 (7.742)	prob 3.133 (3.216)	GS 29.516 (31.845)	mem 77.481
Train: [11][870/1500]	BT 0.042 (0.321)	DT 0.001 (0.281)	loss 7.702 (7.780)	prob 2.954 (2.966)	GS 35.453 (32.737)	mem 76.680
Train: [11][880/1500]	BT 0.040 (0.318)	DT 0.001 (0.279)	loss 7.810 (7.803)	prob 3.481 (2.890)	GS 35.703 (33.025)	mem 76.687
Train: [11][890/1500]	BT 0.030 (0.320)	DT 0.000 (0.281)	loss 7.698 (7.788)	prob 3.060 (2.879)	GS 33.500 (32.754)	mem 76.741
Train: [11][900/1500]	BT 0.037 (0.317)	DT 0.001 (0.278)	loss 7.636 (7.777)	prob 3.621 (2.900)	GS 34.375 (32.593)	mem 76.746
Train: [11][910/1500]	BT 0.034 (0.314)	DT 0.001 (0.275)	loss 8.198 (7.772)	prob 3.273 (3.087)	GS 27.219 (31.466)	mem 76.754
Train: [11][920/1500]	BT 0.067 (0.319)	DT 0.009 (0.279)	loss 7.685 (7.657)	prob 3.449 (3.209)	GS 33.453 (31.317)	mem 76.815
Train: [11][930/1500]	BT 0.066 (0.317)	DT 0.006 (0.277)	loss 7.711 (7.653)	prob 3.410 (3.160)	GS 34.938 (31.746)	mem 76.824
Train: [11][940/1500]	BT 0.029 (0.321)	DT 0.000 (0.281)	loss 8.111 (7.672)	prob 2.697 (2.919)	GS 33.656 (31.764)	mem 76.935
Train: [11][950/1500]	BT 0.025 (0.318)	DT 0.000 (0.278)	loss 7.442 (7.650)	prob 3.758 (2.899)	GS 34.203 (31.891)	mem 76.946
Train: [11][960/1500]	BT 0.040 (0.315)	DT 0.001 (0.275)	loss 7.528 (7.692)	prob 3.125 (2.309)	GS 34.391 (33.073)	mem 76.954
Train: [11][970/1500]	BT 0.039 (0.318)	DT 0.001 (0.279)	loss 7.777 (7.625)	prob 2.730 (2.387)	GS 36.094 (32.825)	mem 77.062
Train: [11][980/1500]	BT 0.041 (0.316)	DT 0.001 (0.276)	loss 8.175 (7.668)	prob 1.865 (2.294)	GS 31.859 (32.786)	mem 77.067
Train: [11][990/1500]	BT 0.029 (0.318)	DT 0.000 (0.278)	loss 7.464 (7.687)	prob 2.118 (2.209)	GS 29.109 (32.914)	mem 77.192
Train: [11][1000/1500]	BT 0.042 (0.315)	DT 0.001 (0.275)	loss 7.804 (7.681)	prob 2.124 (2.133)	GS 36.641 (33.076)	mem 77.203
Train: [11][1010/1500]	BT 0.030 (0.315)	DT 0.000 (0.276)	loss 7.344 (7.580)	prob 1.603 (2.074)	GS 30.531 (33.797)	mem 77.281
Train: [11][1020/1500]	BT 0.039 (0.312)	DT 0.001 (0.273)	loss 8.483 (7.722)	prob 1.679 (1.975)	GS 32.109 (32.711)	mem 77.288
Train: [11][1030/1500]	BT 0.040 (0.310)	DT 0.001 (0.270)	loss 7.471 (7.687)	prob 1.565 (1.892)	GS 30.141 (32.476)	mem 77.296
Train: [11][1040/1500]	BT 0.041 (0.311)	DT 0.001 (0.272)	loss 8.055 (7.697)	prob 1.055 (1.890)	GS 39.062 (32.459)	mem 77.386
Train: [11][1050/1500]	BT 0.042 (0.309)	DT 0.001 (0.269)	loss 8.249 (7.737)	prob 1.604 (1.835)	GS 30.953 (32.329)	mem 77.396
Train: [11][1060/1500]	BT 0.039 (0.311)	DT 0.001 (0.271)	loss 7.860 (7.822)	prob 1.819 (1.732)	GS 36.219 (33.164)	mem 77.147
Train: [11][1070/1500]	BT 0.030 (0.308)	DT 0.000 (0.269)	loss 7.320 (7.835)	prob 3.184 (1.726)	GS 30.344 (32.686)	mem 76.687
Train: [11][1080/1500]	BT 0.040 (0.306)	DT 0.001 (0.266)	loss 8.454 (7.887)	prob 2.146 (1.877)	GS 35.469 (32.404)	mem 76.685
Train: [11][1090/1500]	BT 0.033 (0.311)	DT 0.000 (0.272)	loss 8.047 (7.917)	prob 3.097 (1.899)	GS 35.594 (32.531)	mem 76.725
Train: [11][1100/1500]	BT 0.040 (0.309)	DT 0.001 (0.269)	loss 7.748 (7.935)	prob 1.913 (1.935)	GS 32.719 (32.233)	mem 76.735
Train: [11][1110/1500]	BT 0.076 (0.310)	DT 0.011 (0.270)	loss 8.229 (8.082)	prob 1.648 (1.884)	GS 32.250 (32.772)	mem 76.787
Train: [11][1120/1500]	BT 0.039 (0.308)	DT 0.001 (0.268)	loss 8.453 (8.032)	prob 2.878 (2.192)	GS 38.969 (32.632)	mem 76.789
Train: [11][1130/1500]	BT 0.039 (0.305)	DT 0.001 (0.266)	loss 7.622 (7.965)	prob 3.021 (2.375)	GS 33.672 (32.375)	mem 76.795
Train: [11][1140/1500]	BT 0.037 (0.306)	DT 0.001 (0.267)	loss 7.719 (7.943)	prob 3.425 (2.495)	GS 38.422 (32.200)	mem 76.838
Train: [11][1150/1500]	BT 0.038 (0.304)	DT 0.001 (0.265)	loss 8.126 (7.958)	prob 2.716 (2.478)	GS 34.719 (32.501)	mem 76.843
Train: [11][1160/1500]	BT 0.035 (0.306)	DT 0.001 (0.266)	loss 7.707 (8.196)	prob 3.383 (2.748)	GS 37.312 (33.712)	mem 76.895
Train: [11][1170/1500]	BT 0.036 (0.303)	DT 0.001 (0.264)	loss 8.252 (8.108)	prob 3.756 (2.797)	GS 34.703 (33.333)	mem 76.902
Train: [11][1180/1500]	BT 0.038 (0.301)	DT 0.001 (0.262)	loss 8.036 (8.093)	prob 3.758 (2.837)	GS 32.484 (32.785)	mem 76.906
Train: [11][1190/1500]	BT 0.037 (0.303)	DT 0.001 (0.264)	loss 7.907 (8.047)	prob 3.596 (2.930)	GS 36.281 (32.886)	mem 76.961
Train: [11][1200/1500]	BT 0.053 (0.301)	DT 0.002 (0.262)	loss 7.795 (8.016)	prob 4.506 (2.998)	GS 35.281 (32.726)	mem 76.992
Train: [11][1210/1500]	BT 0.032 (0.303)	DT 0.001 (0.264)	loss 7.641 (7.944)	prob 3.577 (3.241)	GS 35.906 (33.663)	mem 77.055
Train: [11][1220/1500]	BT 0.024 (0.301)	DT 0.000 (0.262)	loss 7.884 (7.979)	prob 3.080 (3.230)	GS 35.344 (33.446)	mem 77.064
Train: [11][1230/1500]	BT 0.047 (0.306)	DT 0.006 (0.267)	loss 8.316 (8.032)	prob 4.978 (3.300)	GS 29.938 (33.399)	mem 77.098
Train: [11][1240/1500]	BT 0.058 (0.304)	DT 0.011 (0.264)	loss 8.199 (8.006)	prob 3.535 (3.441)	GS 33.188 (33.333)	mem 77.106
Train: [11][1250/1500]	BT 0.029 (0.310)	DT 0.000 (0.271)	loss 8.166 (8.009)	prob 3.791 (3.457)	GS 33.047 (33.118)	mem 77.247
Train: [11][1260/1500]	BT 0.026 (0.308)	DT 0.000 (0.269)	loss 8.509 (8.144)	prob 4.514 (3.873)	GS 34.797 (33.917)	mem 77.261
Train: [11][1270/1500]	BT 0.038 (0.306)	DT 0.001 (0.267)	loss 8.130 (8.096)	prob 4.210 (3.950)	GS 33.641 (33.549)	mem 77.273
Train: [11][1280/1500]	BT 0.039 (0.308)	DT 0.000 (0.269)	loss 8.597 (8.096)	prob 3.173 (4.002)	GS 38.250 (33.229)	mem 77.387
Train: [11][1290/1500]	BT 0.039 (0.306)	DT 0.001 (0.267)	loss 8.323 (8.065)	prob 4.451 (4.088)	GS 34.359 (33.302)	mem 77.395
Train: [11][1300/1500]	BT 0.027 (0.308)	DT 0.000 (0.269)	loss 8.478 (8.051)	prob 4.002 (4.120)	GS 34.812 (33.057)	mem 76.579
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [11][1310/1500]	BT 0.027 (0.306)	DT 0.000 (0.267)	loss 8.046 (7.880)	prob 5.510 (4.468)	GS 30.203 (31.100)	mem 76.583
Train: [11][1320/1500]	BT 0.040 (0.306)	DT 0.001 (0.267)	loss 7.653 (7.866)	prob 4.666 (4.515)	GS 33.266 (31.826)	mem 76.613
Train: [11][1330/1500]	BT 0.040 (0.304)	DT 0.001 (0.265)	loss 7.638 (7.993)	prob 4.475 (4.345)	GS 33.188 (32.271)	mem 76.614
Train: [11][1340/1500]	BT 0.036 (0.303)	DT 0.001 (0.264)	loss 7.894 (8.024)	prob 4.177 (4.318)	GS 29.516 (32.574)	mem 76.626
Train: [11][1350/1500]	BT 0.041 (0.306)	DT 0.000 (0.267)	loss 7.841 (7.982)	prob 4.918 (4.436)	GS 32.812 (32.611)	mem 76.682
Train: [11][1360/1500]	BT 0.022 (0.320)	DT 0.000 (0.281)	loss 8.542 (8.005)	prob 4.885 (4.516)	GS 34.016 (33.500)	mem 76.878
Train: [11][1370/1500]	BT 0.026 (0.318)	DT 0.000 (0.279)	loss 7.638 (7.994)	prob 5.098 (4.549)	GS 36.750 (33.413)	mem 76.891
Train: [11][1380/1500]	BT 0.037 (0.318)	DT 0.001 (0.279)	loss 7.973 (7.998)	prob 4.646 (4.543)	GS 36.672 (33.830)	mem 76.986
Train: [11][1390/1500]	BT 0.036 (0.316)	DT 0.001 (0.277)	loss 7.623 (7.982)	prob 4.965 (4.570)	GS 29.219 (33.704)	mem 76.996
Train: [11][1400/1500]	BT 0.030 (0.314)	DT 0.000 (0.275)	loss 7.364 (7.978)	prob 4.822 (4.660)	GS 33.594 (33.490)	mem 77.001
Train: [11][1410/1500]	BT 0.031 (0.319)	DT 0.001 (0.280)	loss 8.253 (8.020)	prob 5.136 (4.831)	GS 33.031 (32.767)	mem 77.156
Train: [11][1420/1500]	BT 0.039 (0.317)	DT 0.001 (0.278)	loss 7.983 (7.978)	prob 5.026 (4.965)	GS 35.734 (32.712)	mem 77.168
Train: [11][1430/1500]	BT 0.038 (0.317)	DT 0.001 (0.278)	loss 8.071 (7.973)	prob 4.602 (4.879)	GS 35.047 (33.192)	mem 77.299
Train: [11][1440/1500]	BT 0.039 (0.315)	DT 0.001 (0.276)	loss 8.094 (7.943)	prob 5.649 (4.867)	GS 39.203 (33.340)	mem 77.282
Train: [11][1450/1500]	BT 0.038 (0.316)	DT 0.001 (0.277)	loss 8.161 (7.957)	prob 5.671 (4.933)	GS 36.438 (33.253)	mem 77.205
Train: [11][1460/1500]	BT 0.038 (0.315)	DT 0.001 (0.277)	loss 7.750 (7.732)	prob 5.507 (5.563)	GS 34.062 (31.575)	mem 76.983
Train: [11][1470/1500]	BT 0.039 (0.314)	DT 0.001 (0.275)	loss 7.581 (7.772)	prob 5.795 (5.374)	GS 33.359 (31.169)	mem 76.991
Train: [11][1480/1500]	BT 0.032 (0.314)	DT 0.001 (0.275)	loss 7.993 (7.801)	prob 5.095 (5.231)	GS 33.609 (31.997)	mem 24.239
Train: [11][1490/1500]	BT 0.020 (0.312)	DT 0.000 (0.273)	loss 7.654 (7.767)	prob 5.668 (5.216)	GS 37.031 (32.049)	mem 22.674
Train: [11][1500/1500]	BT 0.034 (0.310)	DT 0.001 (0.271)	loss 7.438 (7.761)	prob 5.473 (5.187)	GS 34.844 (32.098)	mem 17.060
Train: [11][1510/1500]	BT 0.034 (0.308)	DT 0.000 (0.270)	loss 7.646 (7.636)	prob 4.302 (4.802)	GS 32.219 (32.122)	mem 11.490
epoch 11, total time 466.01
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [12][1/1500]	BT 23.338 (23.338)	DT 23.260 (23.260)	loss 7.430 (7.430)	prob 5.677 (5.677)	GS 27.547 (27.547)	mem 75.453
Train: [12][10/1500]	BT 0.038 (2.458)	DT 0.000 (2.415)	loss 7.154 (7.518)	prob 5.579 (4.993)	GS 34.703 (33.576)	mem 75.510
Train: [12][20/1500]	BT 0.038 (1.248)	DT 0.000 (1.208)	loss 7.828 (7.577)	prob 5.428 (5.051)	GS 32.312 (33.003)	mem 75.537
Train: [12][30/1500]	BT 0.029 (0.984)	DT 0.000 (0.946)	loss 7.237 (7.560)	prob 5.873 (5.186)	GS 32.625 (33.058)	mem 75.710
Train: [12][40/1500]	BT 0.039 (0.758)	DT 0.001 (0.720)	loss 8.623 (7.597)	prob 4.998 (5.143)	GS 34.281 (33.032)	mem 75.741
Train: [12][50/1500]	BT 0.057 (0.710)	DT 0.007 (0.672)	loss 7.878 (7.619)	prob 5.114 (5.131)	GS 32.719 (32.905)	mem 75.817
Train: [12][60/1500]	BT 0.039 (0.687)	DT 0.001 (0.649)	loss 7.290 (7.596)	prob 5.494 (5.003)	GS 31.266 (32.194)	mem 75.942
Train: [12][70/1500]	BT 0.040 (0.595)	DT 0.001 (0.557)	loss 7.659 (7.646)	prob 5.610 (5.077)	GS 32.969 (32.133)	mem 75.951
Train: [12][80/1500]	BT 0.030 (0.761)	DT 0.000 (0.722)	loss 7.647 (7.666)	prob 5.667 (5.058)	GS 35.422 (32.477)	mem 75.304
Train: [12][90/1500]	BT 0.027 (0.679)	DT 0.000 (0.642)	loss 7.801 (7.647)	prob 5.257 (5.038)	GS 30.938 (32.621)	mem 75.311
Train: [12][100/1500]	BT 0.036 (0.615)	DT 0.000 (0.578)	loss 7.594 (7.647)	prob 5.449 (5.024)	GS 34.594 (32.352)	mem 75.304
Train: [12][110/1500]	BT 0.038 (0.587)	DT 0.001 (0.549)	loss 7.517 (7.537)	prob 4.848 (4.862)	GS 34.516 (33.131)	mem 75.372
Train: [12][120/1500]	BT 0.039 (0.541)	DT 0.000 (0.504)	loss 7.640 (7.561)	prob 4.892 (4.860)	GS 35.875 (33.701)	mem 75.382
Train: [12][130/1500]	BT 0.037 (0.546)	DT 0.001 (0.508)	loss 7.328 (7.539)	prob 5.276 (4.798)	GS 37.250 (33.947)	mem 75.418
Train: [12][140/1500]	BT 0.038 (0.510)	DT 0.001 (0.472)	loss 7.401 (7.518)	prob 5.247 (4.836)	GS 33.688 (33.539)	mem 75.424
Train: [12][150/1500]	BT 0.038 (0.478)	DT 0.001 (0.441)	loss 7.566 (7.506)	prob 5.411 (4.828)	GS 35.688 (33.495)	mem 75.430
Train: [12][160/1500]	BT 0.028 (0.481)	DT 0.000 (0.444)	loss 7.442 (7.493)	prob 5.128 (5.012)	GS 36.422 (32.487)	mem 75.504
Train: [12][170/1500]	BT 0.029 (0.454)	DT 0.000 (0.417)	loss 7.437 (7.449)	prob 4.765 (4.719)	GS 36.172 (33.205)	mem 75.508
Train: [12][180/1500]	BT 0.030 (0.490)	DT 0.000 (0.453)	loss 7.343 (7.448)	prob 4.545 (4.681)	GS 33.984 (33.435)	mem 75.677
Train: [12][190/1500]	BT 0.037 (0.466)	DT 0.001 (0.429)	loss 7.253 (7.437)	prob 4.655 (4.645)	GS 35.203 (33.507)	mem 75.693
Train: [12][200/1500]	BT 0.038 (0.453)	DT 0.001 (0.416)	loss 7.225 (7.406)	prob 4.723 (4.676)	GS 35.297 (33.345)	mem 75.737
Train: [12][210/1500]	BT 0.032 (0.450)	DT 0.000 (0.413)	loss 7.368 (7.361)	prob 4.738 (4.497)	GS 36.500 (33.263)	mem 75.815
Train: [12][220/1500]	BT 0.045 (0.431)	DT 0.002 (0.394)	loss 7.431 (7.367)	prob 4.577 (4.572)	GS 35.922 (32.860)	mem 75.826
Train: [12][230/1500]	BT 0.035 (0.440)	DT 0.000 (0.402)	loss 7.214 (7.370)	prob 5.166 (4.476)	GS 30.578 (32.747)	mem 75.919
Train: [12][240/1500]	BT 0.067 (0.424)	DT 0.005 (0.386)	loss 7.437 (7.380)	prob 5.087 (4.437)	GS 33.688 (33.057)	mem 75.926
Train: [12][250/1500]	BT 0.039 (0.427)	DT 0.001 (0.389)	loss 7.017 (7.374)	prob 4.862 (4.443)	GS 37.203 (33.087)	mem 76.021
Train: [12][260/1500]	BT 0.039 (0.412)	DT 0.001 (0.374)	loss 7.266 (7.384)	prob 4.294 (4.232)	GS 32.453 (34.033)	mem 76.043
Train: [12][270/1500]	BT 0.037 (0.414)	DT 0.001 (0.376)	loss 7.488 (7.369)	prob 4.259 (4.147)	GS 33.344 (33.027)	mem 76.171
Train: [12][280/1500]	BT 0.038 (0.401)	DT 0.001 (0.363)	loss 7.516 (7.348)	prob 4.671 (4.199)	GS 36.531 (32.249)	mem 76.186
Train: [12][290/1500]	BT 0.039 (0.388)	DT 0.001 (0.350)	loss 7.435 (7.339)	prob 3.980 (4.147)	GS 35.109 (32.362)	mem 76.200
Train: [12][300/1500]	BT 0.037 (0.394)	DT 0.001 (0.356)	loss 7.796 (7.331)	prob 3.140 (4.066)	GS 33.656 (32.313)	mem 75.380
Train: [12][310/1500]	BT 0.039 (0.383)	DT 0.000 (0.345)	loss 7.029 (7.274)	prob 4.615 (3.913)	GS 34.484 (31.834)	mem 75.384
Train: [12][320/1500]	BT 0.039 (0.379)	DT 0.001 (0.341)	loss 7.157 (7.253)	prob 3.990 (3.966)	GS 32.188 (32.125)	mem 75.426
Train: [12][330/1500]	BT 0.066 (0.381)	DT 0.009 (0.342)	loss 7.504 (7.292)	prob 3.521 (3.782)	GS 34.406 (32.628)	mem 75.465
Train: [12][340/1500]	BT 0.356 (0.372)	DT 0.300 (0.333)	loss 7.000 (7.281)	prob 3.677 (3.766)	GS 30.312 (32.241)	mem 75.468
Train: [12][350/1500]	BT 0.061 (0.373)	DT 0.013 (0.334)	loss 7.266 (7.298)	prob 3.388 (3.661)	GS 40.125 (32.620)	mem 75.502
Train: [12][360/1500]	BT 0.065 (0.377)	DT 0.002 (0.337)	loss 7.433 (7.263)	prob 3.186 (3.550)	GS 34.828 (33.773)	mem 75.548
Train: [12][370/1500]	BT 0.031 (0.401)	DT 0.000 (0.361)	loss 7.581 (7.279)	prob 3.835 (3.367)	GS 29.422 (33.394)	mem 75.662
Train: [12][380/1500]	BT 0.027 (0.392)	DT 0.000 (0.352)	loss 7.177 (7.271)	prob 3.653 (3.411)	GS 32.422 (32.735)	mem 75.673
Train: [12][390/1500]	BT 0.028 (0.393)	DT 0.001 (0.353)	loss 7.204 (7.266)	prob 3.828 (3.363)	GS 37.188 (32.911)	mem 75.763
Train: [12][400/1500]	BT 0.030 (0.384)	DT 0.000 (0.344)	loss 7.121 (7.268)	prob 2.969 (3.249)	GS 35.438 (33.064)	mem 75.774
Train: [12][410/1500]	BT 0.039 (0.375)	DT 0.001 (0.336)	loss 7.416 (7.230)	prob 3.099 (3.122)	GS 33.875 (33.948)	mem 75.785
Train: [12][420/1500]	BT 0.033 (0.378)	DT 0.000 (0.338)	loss 7.212 (7.244)	prob 3.155 (3.175)	GS 33.438 (33.663)	mem 75.920
Train: [12][430/1500]	BT 0.054 (0.370)	DT 0.002 (0.331)	loss 6.847 (7.236)	prob 3.635 (3.085)	GS 29.844 (33.143)	mem 75.931
Train: [12][440/1500]	BT 0.036 (0.374)	DT 0.000 (0.335)	loss 7.301 (7.254)	prob 2.769 (2.984)	GS 33.969 (32.917)	mem 75.987
Train: [12][450/1500]	BT 0.038 (0.368)	DT 0.001 (0.327)	loss 7.288 (7.243)	prob 2.837 (2.961)	GS 33.625 (33.006)	mem 76.001
Train: [12][460/1500]	BT 0.028 (0.381)	DT 0.000 (0.341)	loss 7.104 (7.186)	prob 3.701 (3.045)	GS 33.109 (34.178)	mem 76.154
Train: [12][470/1500]	BT 0.038 (0.374)	DT 0.000 (0.334)	loss 7.291 (7.244)	prob 3.336 (2.796)	GS 29.062 (32.802)	mem 76.163
Train: [12][480/1500]	BT 0.030 (0.386)	DT 0.001 (0.346)	loss 7.366 (7.250)	prob 2.772 (2.735)	GS 34.094 (32.968)	mem 75.386
Train: [12][490/1500]	BT 0.031 (0.378)	DT 0.000 (0.339)	loss 7.413 (7.249)	prob 2.847 (2.838)	GS 34.750 (33.056)	mem 75.392
Train: [12][500/1500]	BT 0.028 (0.372)	DT 0.000 (0.332)	loss 7.182 (7.233)	prob 2.583 (2.821)	GS 32.469 (32.829)	mem 75.397
Train: [12][510/1500]	BT 0.040 (0.372)	DT 0.001 (0.332)	loss 7.179 (7.200)	prob 2.497 (2.279)	GS 33.656 (32.516)	mem 75.428
Train: [12][520/1500]	BT 0.040 (0.365)	DT 0.001 (0.325)	loss 7.172 (7.164)	prob 2.924 (2.444)	GS 33.031 (32.784)	mem 75.430
Train: [12][530/1500]	BT 0.061 (0.368)	DT 0.007 (0.328)	loss 7.299 (7.177)	prob 2.709 (2.541)	GS 31.859 (33.396)	mem 75.468
Train: [12][540/1500]	BT 0.030 (0.367)	DT 0.001 (0.327)	loss 7.238 (7.183)	prob 2.225 (2.477)	GS 35.188 (33.546)	mem 75.492
Train: [12][550/1500]	BT 0.040 (0.361)	DT 0.001 (0.321)	loss 7.197 (7.184)	prob 2.439 (2.441)	GS 34.234 (33.358)	mem 75.499
Train: [12][560/1500]	BT 0.039 (0.365)	DT 0.001 (0.325)	loss 7.184 (7.140)	prob 2.152 (2.228)	GS 36.500 (34.077)	mem 75.559
Train: [12][570/1500]	BT 0.039 (0.360)	DT 0.001 (0.320)	loss 7.113 (7.145)	prob 3.027 (2.255)	GS 36.188 (34.101)	mem 75.565
Train: [12][580/1500]	BT 0.026 (0.363)	DT 0.000 (0.323)	loss 7.114 (7.160)	prob 2.313 (2.248)	GS 37.344 (33.601)	mem 75.693
Train: [12][590/1500]	BT 0.037 (0.357)	DT 0.000 (0.317)	loss 7.522 (7.141)	prob 1.817 (2.165)	GS 34.734 (33.202)	mem 75.706
Train: [12][600/1500]	BT 0.038 (0.354)	DT 0.000 (0.314)	loss 7.174 (7.143)	prob 1.900 (2.078)	GS 33.938 (32.945)	mem 75.754
Train: [12][610/1500]	BT 0.031 (0.355)	DT 0.000 (0.315)	loss 7.270 (7.124)	prob 2.093 (1.755)	GS 34.250 (32.413)	mem 75.927
Train: [12][620/1500]	BT 0.040 (0.349)	DT 0.001 (0.310)	loss 7.478 (7.195)	prob 1.318 (1.623)	GS 34.359 (32.660)	mem 75.941
Train: [12][630/1500]	BT 0.031 (0.353)	DT 0.000 (0.314)	loss 7.069 (7.157)	prob 1.610 (1.482)	GS 35.000 (32.153)	mem 76.159
Train: [12][640/1500]	BT 0.045 (0.348)	DT 0.000 (0.309)	loss 7.349 (7.178)	prob 1.285 (1.377)	GS 32.141 (31.990)	mem 76.166
Train: [12][650/1500]	BT 0.030 (0.354)	DT 0.000 (0.314)	loss 6.903 (7.209)	prob 1.184 (1.262)	GS 35.359 (32.122)	mem 76.862
Train: [12][660/1500]	BT 0.030 (0.349)	DT 0.000 (0.310)	loss 7.956 (7.570)	prob 0.855 (0.644)	GS 30.812 (31.702)	mem 76.870
Train: [12][670/1500]	BT 0.038 (0.344)	DT 0.001 (0.305)	loss 7.526 (7.504)	prob 0.548 (0.443)	GS 30.016 (31.888)	mem 76.882
Train: [12][680/1500]	BT 0.028 (0.350)	DT 0.000 (0.311)	loss 7.637 (7.526)	prob 1.399 (0.537)	GS 33.203 (32.096)	mem 76.581
Train: [12][690/1500]	BT 0.028 (0.345)	DT 0.000 (0.306)	loss 7.132 (7.512)	prob 1.120 (0.564)	GS 31.609 (32.293)	mem 76.612
Train: [12][700/1500]	BT 0.032 (0.351)	DT 0.000 (0.312)	loss 8.303 (7.538)	prob 0.848 (0.616)	GS 34.500 (32.269)	mem 78.444
Train: [12][710/1500]	BT 0.026 (0.349)	DT 0.000 (0.311)	loss 8.465 (7.550)	prob 1.712 (1.166)	GS 32.078 (32.309)	mem 76.697
Train: [12][720/1500]	BT 0.037 (0.345)	DT 0.001 (0.306)	loss 8.226 (7.627)	prob 0.442 (0.946)	GS 31.719 (32.006)	mem 76.613
Train: [12][730/1500]	BT 0.055 (0.344)	DT 0.016 (0.306)	loss 7.690 (7.627)	prob 1.843 (1.077)	GS 33.438 (32.129)	mem 76.667
Train: [12][740/1500]	BT 0.069 (0.341)	DT 0.011 (0.302)	loss 7.687 (7.670)	prob 1.651 (1.130)	GS 31.531 (32.436)	mem 76.676
Train: [12][750/1500]	BT 0.043 (0.352)	DT 0.011 (0.313)	loss 7.769 (7.727)	prob 1.464 (1.189)	GS 35.281 (32.355)	mem 76.715
Train: [12][760/1500]	BT 0.029 (0.358)	DT 0.000 (0.319)	loss 8.228 (7.882)	prob 1.748 (0.976)	GS 33.547 (32.189)	mem 76.778
Train: [12][770/1500]	BT 0.039 (0.353)	DT 0.000 (0.315)	loss 8.089 (7.937)	prob 2.696 (1.255)	GS 35.562 (32.998)	mem 76.793
Train: [12][780/1500]	BT 0.039 (0.349)	DT 0.001 (0.310)	loss 8.005 (7.862)	prob 2.784 (1.389)	GS 32.641 (32.438)	mem 76.807
Train: [12][790/1500]	BT 0.061 (0.349)	DT 0.004 (0.311)	loss 8.386 (7.879)	prob 2.470 (1.405)	GS 31.453 (32.401)	mem 76.864
Train: [12][800/1500]	BT 0.039 (0.347)	DT 0.001 (0.308)	loss 8.647 (7.871)	prob 2.999 (1.610)	GS 30.719 (32.205)	mem 76.911
Train: [12][810/1500]	BT 0.039 (0.346)	DT 0.001 (0.307)	loss 7.952 (7.956)	prob 1.881 (1.788)	GS 38.250 (33.194)	mem 76.968
Train: [12][820/1500]	BT 0.039 (0.342)	DT 0.001 (0.303)	loss 7.967 (7.875)	prob 2.612 (1.979)	GS 34.891 (32.572)	mem 76.980
Train: [12][830/1500]	BT 0.040 (0.342)	DT 0.001 (0.303)	loss 8.090 (7.838)	prob 2.756 (2.153)	GS 32.281 (31.844)	mem 77.054
Train: [12][840/1500]	BT 0.073 (0.340)	DT 0.017 (0.301)	loss 8.195 (7.813)	prob 2.139 (2.209)	GS 33.625 (31.839)	mem 77.079
Train: [12][850/1500]	BT 0.072 (0.338)	DT 0.017 (0.299)	loss 7.430 (7.818)	prob 1.299 (2.108)	GS 34.766 (32.121)	mem 77.097
Train: [12][860/1500]	BT 0.028 (0.352)	DT 0.000 (0.313)	loss 7.681 (7.900)	prob 3.017 (2.074)	GS 28.656 (32.706)	mem 76.465
Train: [12][870/1500]	BT 0.032 (0.348)	DT 0.000 (0.309)	loss 7.561 (7.828)	prob 3.083 (2.061)	GS 30.344 (33.116)	mem 76.466
Train: [12][880/1500]	BT 0.033 (0.344)	DT 0.001 (0.305)	loss 7.386 (7.730)	prob 2.808 (2.127)	GS 30.312 (32.356)	mem 76.464
Train: [12][890/1500]	BT 0.028 (0.346)	DT 0.000 (0.307)	loss 8.042 (7.792)	prob 2.230 (2.115)	GS 34.047 (32.684)	mem 76.516
Train: [12][900/1500]	BT 0.038 (0.343)	DT 0.001 (0.304)	loss 7.938 (7.784)	prob 2.987 (2.201)	GS 28.969 (32.403)	mem 76.522
Train: [12][910/1500]	BT 0.021 (0.344)	DT 0.000 (0.306)	loss 8.552 (7.893)	prob 2.841 (2.376)	GS 37.062 (32.555)	mem 76.577
Train: [12][920/1500]	BT 0.032 (0.341)	DT 0.000 (0.302)	loss 7.673 (7.799)	prob 3.143 (2.577)	GS 34.156 (31.952)	mem 76.582
Train: [12][930/1500]	BT 0.083 (0.342)	DT 0.015 (0.304)	loss 7.591 (7.764)	prob 2.357 (2.588)	GS 32.875 (32.023)	mem 76.627
Train: [12][940/1500]	BT 0.058 (0.339)	DT 0.001 (0.301)	loss 7.709 (7.784)	prob 2.604 (2.469)	GS 33.734 (32.121)	mem 76.632
Train: [12][950/1500]	BT 0.039 (0.336)	DT 0.001 (0.297)	loss 8.841 (7.816)	prob 2.432 (2.476)	GS 34.781 (32.119)	mem 76.635
Train: [12][960/1500]	BT 0.037 (0.338)	DT 0.001 (0.299)	loss 8.372 (7.832)	prob 2.773 (2.651)	GS 34.812 (31.952)	mem 76.711
Train: [12][970/1500]	BT 0.038 (0.335)	DT 0.001 (0.296)	loss 7.748 (7.845)	prob 2.600 (2.474)	GS 33.422 (32.362)	mem 76.716
Train: [12][980/1500]	BT 0.035 (0.338)	DT 0.000 (0.300)	loss 7.302 (7.828)	prob 3.323 (2.479)	GS 32.719 (32.486)	mem 76.830
Train: [12][990/1500]	BT 0.040 (0.335)	DT 0.001 (0.297)	loss 8.380 (7.851)	prob 2.851 (2.437)	GS 33.172 (32.621)	mem 76.863
Train: [12][1000/1500]	BT 0.042 (0.332)	DT 0.000 (0.294)	loss 7.993 (7.844)	prob 3.570 (2.474)	GS 38.828 (32.745)	mem 76.921
Train: [12][1010/1500]	BT 0.036 (0.335)	DT 0.000 (0.297)	loss 7.921 (7.847)	prob 3.336 (2.439)	GS 30.578 (32.100)	mem 78.735
Train: [12][1020/1500]	BT 0.051 (0.333)	DT 0.000 (0.294)	loss 7.617 (7.785)	prob 3.244 (2.799)	GS 31.797 (31.360)	mem 78.832
Train: [12][1030/1500]	BT 0.036 (0.338)	DT 0.000 (0.299)	loss 7.804 (7.778)	prob 3.857 (2.828)	GS 33.453 (31.459)	mem 77.060
Train: [12][1040/1500]	BT 0.047 (0.335)	DT 0.001 (0.296)	loss 7.833 (7.766)	prob 3.690 (2.912)	GS 35.234 (31.694)	mem 77.069
Train: [12][1050/1500]	BT 0.056 (0.340)	DT 0.005 (0.301)	loss 8.072 (7.779)	prob 3.384 (2.876)	GS 28.469 (31.926)	mem 77.197
Train: [12][1060/1500]	BT 0.029 (0.341)	DT 0.000 (0.302)	loss 8.438 (7.680)	prob 2.240 (2.646)	GS 34.984 (33.114)	mem 77.239
Train: [12][1070/1500]	BT 0.032 (0.338)	DT 0.000 (0.299)	loss 7.600 (7.648)	prob 2.798 (2.567)	GS 36.422 (32.751)	mem 77.248
Train: [12][1080/1500]	BT 0.040 (0.338)	DT 0.001 (0.300)	loss 7.648 (7.638)	prob 2.383 (2.448)	GS 34.000 (32.950)	mem 77.316
Train: [12][1090/1500]	BT 0.038 (0.336)	DT 0.001 (0.297)	loss 8.023 (7.613)	prob 3.906 (2.570)	GS 33.859 (32.719)	mem 77.323
Train: [12][1100/1500]	BT 0.037 (0.336)	DT 0.000 (0.297)	loss 7.932 (7.624)	prob 3.086 (2.631)	GS 33.422 (32.349)	mem 76.505
Train: [12][1110/1500]	BT 0.040 (0.333)	DT 0.001 (0.295)	loss 7.360 (7.493)	prob 3.754 (2.895)	GS 30.500 (32.372)	mem 76.505
Train: [12][1120/1500]	BT 0.052 (0.331)	DT 0.008 (0.292)	loss 7.594 (7.532)	prob 3.553 (2.980)	GS 36.234 (31.905)	mem 76.505
Train: [12][1130/1500]	BT 0.039 (0.333)	DT 0.001 (0.294)	loss 7.724 (7.535)	prob 3.116 (2.945)	GS 33.234 (32.172)	mem 76.512
Train: [12][1140/1500]	BT 0.039 (0.330)	DT 0.001 (0.291)	loss 7.307 (7.529)	prob 2.693 (2.873)	GS 30.656 (32.436)	mem 76.520
Train: [12][1150/1500]	BT 0.029 (0.335)	DT 0.000 (0.296)	loss 7.120 (7.544)	prob 3.318 (2.849)	GS 35.422 (32.669)	mem 76.647
Train: [12][1160/1500]	BT 0.026 (0.332)	DT 0.000 (0.294)	loss 7.790 (7.474)	prob 3.485 (3.182)	GS 35.641 (31.800)	mem 76.654
Train: [12][1170/1500]	BT 0.105 (0.331)	DT 0.006 (0.292)	loss 7.462 (7.498)	prob 2.580 (2.910)	GS 30.922 (32.344)	mem 76.670
Train: [12][1180/1500]	BT 0.052 (0.334)	DT 0.011 (0.295)	loss 7.363 (7.514)	prob 2.787 (2.868)	GS 32.453 (32.606)	mem 76.735
Train: [12][1190/1500]	BT 0.030 (0.341)	DT 0.000 (0.302)	loss 7.577 (7.504)	prob 3.332 (2.864)	GS 32.297 (32.774)	mem 76.958
Train: [12][1200/1500]	BT 0.031 (0.338)	DT 0.000 (0.299)	loss 7.550 (7.491)	prob 2.840 (2.840)	GS 35.156 (32.997)	mem 76.968
Train: [12][1210/1500]	BT 0.037 (0.336)	DT 0.001 (0.297)	loss 7.418 (7.420)	prob 2.679 (2.976)	GS 36.391 (32.891)	mem 76.980
Train: [12][1220/1500]	BT 0.038 (0.337)	DT 0.001 (0.298)	loss 7.395 (7.469)	prob 3.585 (2.891)	GS 34.156 (33.382)	mem 77.076
Train: [12][1230/1500]	BT 0.039 (0.334)	DT 0.001 (0.295)	loss 7.738 (7.445)	prob 2.511 (2.844)	GS 34.672 (33.171)	mem 77.088
Train: [12][1240/1500]	BT 0.067 (0.335)	DT 0.011 (0.296)	loss 7.394 (7.417)	prob 3.198 (2.891)	GS 33.500 (33.048)	mem 77.136
Train: [12][1250/1500]	BT 0.060 (0.333)	DT 0.003 (0.294)	loss 7.207 (7.410)	prob 3.373 (2.881)	GS 32.062 (32.821)	mem 77.143
Train: [12][1260/1500]	BT 0.030 (0.337)	DT 0.000 (0.298)	loss 7.592 (7.417)	prob 3.129 (2.841)	GS 35.297 (33.747)	mem 77.306
Train: [12][1270/1500]	BT 0.039 (0.334)	DT 0.001 (0.295)	loss 7.172 (7.395)	prob 2.895 (2.777)	GS 33.359 (33.188)	mem 77.318
Train: [12][1280/1500]	BT 0.124 (0.340)	DT 0.037 (0.301)	loss 7.244 (7.352)	prob 2.992 (2.838)	GS 34.078 (32.781)	mem 76.545
Train: [12][1290/1500]	BT 0.055 (0.339)	DT 0.015 (0.300)	loss 7.663 (7.346)	prob 2.901 (2.809)	GS 33.891 (32.521)	mem 76.554
Train: [12][1300/1500]	BT 0.029 (0.337)	DT 0.000 (0.298)	loss 7.260 (7.333)	prob 3.288 (2.902)	GS 36.766 (32.677)	mem 76.559
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [12][1310/1500]	BT 0.038 (0.339)	DT 0.001 (0.300)	loss 7.477 (7.395)	prob 3.033 (2.692)	GS 31.703 (33.905)	mem 76.617
Train: [12][1320/1500]	BT 0.038 (0.337)	DT 0.001 (0.298)	loss 7.395 (7.337)	prob 3.245 (2.833)	GS 36.469 (32.923)	mem 76.622
Train: [12][1330/1500]	BT 0.038 (0.335)	DT 0.001 (0.296)	loss 7.223 (7.286)	prob 3.556 (2.983)	GS 35.062 (32.464)	mem 76.646
Train: [12][1340/1500]	BT 0.039 (0.335)	DT 0.001 (0.296)	loss 7.374 (7.313)	prob 2.916 (2.915)	GS 34.047 (32.786)	mem 76.709
Train: [12][1350/1500]	BT 0.048 (0.333)	DT 0.000 (0.294)	loss 7.799 (7.305)	prob 3.191 (3.002)	GS 33.672 (32.745)	mem 76.719
Train: [12][1360/1500]	BT 0.072 (0.336)	DT 0.006 (0.297)	loss 7.389 (7.268)	prob 2.792 (2.996)	GS 33.656 (34.236)	mem 76.449
Train: [12][1370/1500]	BT 0.068 (0.334)	DT 0.005 (0.295)	loss 7.423 (7.243)	prob 3.563 (3.037)	GS 32.438 (34.017)	mem 76.453
Train: [12][1380/1500]	BT 0.030 (0.352)	DT 0.000 (0.312)	loss 7.224 (7.243)	prob 3.089 (3.158)	GS 31.375 (33.154)	mem 76.624
Train: [12][1390/1500]	BT 0.026 (0.349)	DT 0.000 (0.310)	loss 7.316 (7.233)	prob 2.948 (3.182)	GS 37.109 (33.143)	mem 76.634
Train: [12][1400/1500]	BT 0.031 (0.350)	DT 0.000 (0.311)	loss 7.368 (7.258)	prob 2.767 (3.141)	GS 32.750 (33.026)	mem 76.738
Train: [12][1410/1500]	BT 0.032 (0.348)	DT 0.000 (0.309)	loss 7.221 (7.250)	prob 3.754 (3.257)	GS 31.766 (31.930)	mem 76.749
Train: [12][1420/1500]	BT 0.039 (0.346)	DT 0.001 (0.307)	loss 7.322 (7.284)	prob 3.077 (3.019)	GS 36.703 (32.764)	mem 76.761
Train: [12][1430/1500]	BT 0.030 (0.347)	DT 0.000 (0.308)	loss 6.940 (7.251)	prob 3.575 (3.033)	GS 36.781 (32.886)	mem 76.900
Train: [12][1440/1500]	BT 0.032 (0.345)	DT 0.001 (0.306)	loss 6.987 (7.222)	prob 3.862 (3.146)	GS 31.781 (32.507)	mem 76.910
Train: [12][1450/1500]	BT 0.030 (0.346)	DT 0.000 (0.307)	loss 7.167 (7.210)	prob 2.921 (3.142)	GS 32.719 (32.390)	mem 76.693
Train: [12][1460/1500]	BT 0.035 (0.344)	DT 0.001 (0.305)	loss 7.110 (7.201)	prob 2.946 (2.829)	GS 32.625 (32.658)	mem 76.702
Train: [12][1470/1500]	BT 0.052 (0.342)	DT 0.009 (0.303)	loss 7.067 (7.265)	prob 3.766 (2.930)	GS 34.047 (32.576)	mem 76.708
Train: [12][1480/1500]	BT 0.028 (0.341)	DT 0.000 (0.302)	loss 7.098 (7.240)	prob 2.920 (2.971)	GS 35.922 (32.560)	mem 20.521
Train: [12][1490/1500]	BT 0.030 (0.339)	DT 0.001 (0.300)	loss 7.249 (7.231)	prob 2.985 (2.966)	GS 36.094 (32.459)	mem 17.728
Train: [12][1500/1500]	BT 0.032 (0.338)	DT 0.000 (0.299)	loss 7.054 (7.217)	prob 2.452 (2.973)	GS 32.531 (32.266)	mem 14.885
Train: [12][1510/1500]	BT 0.030 (0.336)	DT 0.000 (0.297)	loss 6.882 (7.060)	prob 3.066 (2.773)	GS 29.031 (32.800)	mem 14.610
epoch 12, total time 507.25
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [13][1/1500]	BT 18.371 (18.371)	DT 18.313 (18.313)	loss 6.740 (6.740)	prob 3.672 (3.672)	GS 28.656 (28.656)	mem 74.900
Train: [13][10/1500]	BT 0.042 (2.479)	DT 0.001 (2.437)	loss 6.990 (6.952)	prob 2.837 (3.080)	GS 34.031 (31.509)	mem 75.297
Train: [13][20/1500]	BT 0.040 (1.261)	DT 0.001 (1.220)	loss 7.834 (6.970)	prob 3.246 (3.138)	GS 35.812 (32.576)	mem 75.305
Train: [13][30/1500]	BT 1.165 (0.975)	DT 1.128 (0.935)	loss 7.120 (7.003)	prob 3.585 (3.118)	GS 36.859 (32.705)	mem 75.399
Train: [13][40/1500]	BT 0.098 (0.769)	DT 0.016 (0.723)	loss 6.731 (6.999)	prob 3.576 (3.165)	GS 35.078 (32.556)	mem 75.433
Train: [13][50/1500]	BT 0.928 (0.678)	DT 0.890 (0.630)	loss 7.210 (7.025)	prob 3.455 (3.195)	GS 31.516 (32.204)	mem 75.505
Train: [13][60/1500]	BT 0.038 (0.621)	DT 0.001 (0.576)	loss 6.982 (7.100)	prob 3.948 (3.346)	GS 29.078 (32.203)	mem 75.597
Train: [13][70/1500]	BT 0.039 (0.538)	DT 0.001 (0.494)	loss 7.358 (7.111)	prob 2.820 (3.288)	GS 36.172 (32.293)	mem 75.610
Train: [13][80/1500]	BT 0.063 (0.527)	DT 0.003 (0.483)	loss 6.899 (7.075)	prob 3.017 (3.235)	GS 35.047 (32.483)	mem 75.697
Train: [13][90/1500]	BT 0.031 (0.491)	DT 0.000 (0.447)	loss 7.014 (7.097)	prob 3.639 (3.159)	GS 32.359 (32.206)	mem 75.722
Train: [13][100/1500]	BT 0.049 (0.450)	DT 0.003 (0.407)	loss 7.251 (7.094)	prob 3.001 (3.126)	GS 34.203 (32.018)	mem 75.732
Train: [13][110/1500]	BT 0.037 (0.461)	DT 0.000 (0.418)	loss 7.295 (7.086)	prob 3.193 (3.309)	GS 33.500 (30.828)	mem 75.753
Train: [13][120/1500]	BT 0.038 (0.428)	DT 0.000 (0.386)	loss 6.937 (7.052)	prob 2.483 (3.036)	GS 34.172 (31.791)	mem 75.786
Train: [13][130/1500]	BT 1.828 (0.420)	DT 1.759 (0.378)	loss 7.418 (7.063)	prob 2.840 (2.920)	GS 31.516 (31.617)	mem 75.851
Train: [13][140/1500]	BT 0.075 (0.448)	DT 0.013 (0.405)	loss 7.305 (7.087)	prob 2.913 (2.897)	GS 35.188 (32.326)	mem 75.947
Train: [13][150/1500]	BT 0.073 (0.423)	DT 0.011 (0.378)	loss 7.169 (7.092)	prob 3.270 (2.937)	GS 34.375 (32.393)	mem 75.954
Train: [13][160/1500]	BT 2.034 (0.435)	DT 1.981 (0.390)	loss 7.334 (7.074)	prob 3.067 (3.119)	GS 32.625 (33.292)	mem 76.110
Train: [13][170/1500]	BT 0.059 (0.413)	DT 0.012 (0.367)	loss 7.067 (7.094)	prob 3.302 (3.120)	GS 32.953 (32.925)	mem 76.092
Train: [13][180/1500]	BT 0.039 (0.428)	DT 0.000 (0.382)	loss 6.991 (7.095)	prob 3.183 (3.098)	GS 32.469 (33.006)	mem 76.199
Train: [13][190/1500]	BT 0.039 (0.412)	DT 0.001 (0.367)	loss 7.178 (7.086)	prob 3.088 (3.046)	GS 35.578 (32.584)	mem 76.023
Train: [13][200/1500]	BT 0.038 (0.399)	DT 0.001 (0.354)	loss 6.957 (7.078)	prob 3.319 (3.017)	GS 33.594 (32.531)	mem 75.304
Train: [13][210/1500]	BT 0.046 (0.405)	DT 0.004 (0.361)	loss 6.948 (7.047)	prob 3.713 (3.007)	GS 28.812 (33.580)	mem 75.300
Train: [13][220/1500]	BT 0.039 (0.395)	DT 0.001 (0.350)	loss 7.193 (7.057)	prob 2.627 (3.054)	GS 33.266 (33.167)	mem 75.311
Train: [13][230/1500]	BT 0.042 (0.401)	DT 0.001 (0.357)	loss 7.259 (7.081)	prob 2.652 (2.926)	GS 36.594 (33.868)	mem 75.377
Train: [13][240/1500]	BT 0.039 (0.386)	DT 0.001 (0.342)	loss 6.907 (7.073)	prob 3.226 (3.045)	GS 34.578 (33.561)	mem 75.381
Train: [13][250/1500]	BT 0.032 (0.392)	DT 0.001 (0.348)	loss 6.927 (7.061)	prob 2.768 (3.048)	GS 33.766 (33.464)	mem 75.445
Train: [13][260/1500]	BT 0.040 (0.378)	DT 0.001 (0.334)	loss 6.896 (7.039)	prob 3.104 (2.998)	GS 37.797 (34.281)	mem 75.453
Train: [13][270/1500]	BT 0.039 (0.376)	DT 0.001 (0.332)	loss 7.288 (7.054)	prob 3.142 (2.968)	GS 27.922 (33.839)	mem 75.530
Train: [13][280/1500]	BT 0.039 (0.367)	DT 0.001 (0.324)	loss 7.046 (7.028)	prob 2.721 (3.005)	GS 29.891 (33.114)	mem 75.556
Train: [13][290/1500]	BT 0.040 (0.356)	DT 0.001 (0.312)	loss 7.043 (7.034)	prob 2.834 (2.978)	GS 32.891 (32.765)	mem 75.564
Train: [13][300/1500]	BT 0.039 (0.365)	DT 0.000 (0.321)	loss 6.995 (7.030)	prob 2.155 (2.921)	GS 32.828 (32.708)	mem 75.683
Train: [13][310/1500]	BT 0.040 (0.354)	DT 0.001 (0.311)	loss 6.720 (6.968)	prob 2.624 (2.451)	GS 33.812 (32.867)	mem 75.696
Train: [13][320/1500]	BT 0.041 (0.351)	DT 0.001 (0.307)	loss 7.366 (6.982)	prob 2.992 (2.611)	GS 34.547 (32.453)	mem 75.741
Train: [13][330/1500]	BT 0.039 (0.346)	DT 0.001 (0.302)	loss 6.903 (6.971)	prob 2.967 (2.618)	GS 37.781 (32.452)	mem 75.803
Train: [13][340/1500]	BT 0.048 (0.363)	DT 0.008 (0.320)	loss 6.965 (6.974)	prob 2.404 (2.594)	GS 32.531 (32.156)	mem 75.948
Train: [13][350/1500]	BT 0.031 (0.354)	DT 0.000 (0.311)	loss 6.689 (6.961)	prob 2.966 (2.565)	GS 33.438 (32.494)	mem 75.958
Train: [13][360/1500]	BT 0.048 (0.355)	DT 0.002 (0.312)	loss 6.834 (6.879)	prob 3.128 (2.673)	GS 33.938 (34.316)	mem 76.057
Train: [13][370/1500]	BT 0.032 (0.350)	DT 0.000 (0.307)	loss 6.809 (6.859)	prob 3.160 (2.624)	GS 32.875 (33.936)	mem 76.074
Train: [13][380/1500]	BT 0.038 (0.354)	DT 0.001 (0.311)	loss 6.710 (6.844)	prob 3.708 (2.764)	GS 28.969 (33.388)	mem 76.184
Train: [13][390/1500]	BT 0.037 (0.347)	DT 0.001 (0.305)	loss 6.725 (6.822)	prob 3.277 (2.815)	GS 30.969 (33.179)	mem 76.214
Train: [13][400/1500]	BT 0.038 (0.346)	DT 0.001 (0.303)	loss 6.828 (6.827)	prob 2.721 (2.953)	GS 34.406 (32.946)	mem 75.340
Train: [13][410/1500]	BT 0.038 (0.338)	DT 0.001 (0.296)	loss 6.873 (6.856)	prob 3.167 (3.316)	GS 34.094 (34.736)	mem 75.340
Train: [13][420/1500]	BT 0.038 (0.332)	DT 0.001 (0.290)	loss 7.445 (6.942)	prob 2.770 (3.146)	GS 32.438 (33.209)	mem 75.343
Train: [13][430/1500]	BT 0.039 (0.334)	DT 0.001 (0.292)	loss 7.523 (6.992)	prob 2.655 (3.100)	GS 33.531 (32.915)	mem 75.427
Train: [13][440/1500]	BT 0.025 (0.329)	DT 0.000 (0.287)	loss 7.191 (7.011)	prob 3.310 (3.055)	GS 29.875 (32.932)	mem 75.415
Train: [13][450/1500]	BT 0.038 (0.332)	DT 0.001 (0.291)	loss 7.507 (7.060)	prob 3.000 (3.048)	GS 34.438 (32.939)	mem 75.477
Train: [13][460/1500]	BT 0.039 (0.326)	DT 0.001 (0.285)	loss 7.771 (7.342)	prob 3.259 (3.000)	GS 36.094 (33.055)	mem 75.483
Train: [13][470/1500]	BT 0.098 (0.323)	DT 0.013 (0.281)	loss 6.757 (7.316)	prob 3.031 (2.987)	GS 36.234 (33.438)	mem 75.504
Train: [13][480/1500]	BT 0.031 (0.332)	DT 0.000 (0.290)	loss 8.016 (7.373)	prob 3.566 (2.876)	GS 35.359 (33.051)	mem 75.552
Train: [13][490/1500]	BT 0.038 (0.338)	DT 0.001 (0.296)	loss 7.754 (7.417)	prob 3.758 (2.914)	GS 34.281 (32.939)	mem 75.658
Train: [13][500/1500]	BT 0.035 (0.334)	DT 0.000 (0.293)	loss 7.216 (7.464)	prob 3.659 (2.979)	GS 30.953 (33.047)	mem 75.704
Train: [13][510/1500]	BT 0.058 (0.329)	DT 0.014 (0.287)	loss 7.835 (7.582)	prob 3.873 (3.353)	GS 34.562 (32.227)	mem 75.682
Train: [13][520/1500]	BT 0.028 (0.351)	DT 0.000 (0.309)	loss 7.419 (7.597)	prob 3.566 (3.128)	GS 33.578 (33.534)	mem 75.932
Train: [13][530/1500]	BT 0.037 (0.345)	DT 0.000 (0.303)	loss 7.982 (7.675)	prob 4.255 (3.284)	GS 31.031 (33.043)	mem 75.941
Train: [13][540/1500]	BT 0.031 (0.352)	DT 0.000 (0.311)	loss 8.294 (7.707)	prob 3.810 (3.275)	GS 31.188 (32.921)	mem 76.049
Train: [13][550/1500]	BT 0.031 (0.346)	DT 0.000 (0.305)	loss 7.758 (7.725)	prob 2.982 (3.286)	GS 34.359 (33.155)	mem 76.054
Train: [13][560/1500]	BT 0.076 (0.349)	DT 0.022 (0.308)	loss 8.280 (7.938)	prob 3.669 (3.048)	GS 34.312 (33.459)	mem 76.127
Train: [13][570/1500]	BT 0.031 (0.368)	DT 0.001 (0.327)	loss 8.276 (7.937)	prob 3.260 (3.232)	GS 32.312 (32.977)	mem 75.397
Train: [13][580/1500]	BT 0.031 (0.363)	DT 0.000 (0.321)	loss 8.093 (7.887)	prob 3.377 (3.248)	GS 36.828 (33.497)	mem 75.403
Train: [13][590/1500]	BT 0.038 (0.357)	DT 0.001 (0.316)	loss 7.837 (7.876)	prob 4.226 (3.337)	GS 33.750 (33.123)	mem 75.360
Train: [13][600/1500]	BT 0.029 (0.358)	DT 0.000 (0.317)	loss 7.490 (7.826)	prob 4.396 (3.450)	GS 34.625 (32.865)	mem 75.391
Train: [13][610/1500]	BT 0.035 (0.353)	DT 0.001 (0.312)	loss 7.639 (7.751)	prob 3.964 (3.717)	GS 30.656 (33.548)	mem 75.410
Train: [13][620/1500]	BT 0.029 (0.353)	DT 0.000 (0.312)	loss 8.297 (7.761)	prob 3.490 (3.798)	GS 31.812 (32.670)	mem 75.464
Train: [13][630/1500]	BT 0.041 (0.347)	DT 0.001 (0.307)	loss 7.549 (7.725)	prob 3.723 (3.798)	GS 33.719 (32.839)	mem 75.467
Train: [13][640/1500]	BT 0.038 (0.343)	DT 0.001 (0.302)	loss 8.015 (7.723)	prob 4.089 (3.786)	GS 36.375 (32.687)	mem 75.460
Train: [13][650/1500]	BT 0.038 (0.344)	DT 0.001 (0.304)	loss 7.768 (7.712)	prob 3.681 (3.818)	GS 30.969 (32.381)	mem 75.677
Train: [13][660/1500]	BT 0.038 (0.340)	DT 0.001 (0.299)	loss 7.847 (7.705)	prob 5.296 (4.157)	GS 32.219 (31.525)	mem 75.679
Train: [13][670/1500]	BT 0.039 (0.342)	DT 0.001 (0.302)	loss 7.677 (7.701)	prob 3.615 (4.042)	GS 29.828 (31.734)	mem 76.127
Train: [13][680/1500]	BT 0.039 (0.338)	DT 0.001 (0.297)	loss 7.431 (7.679)	prob 4.458 (3.887)	GS 33.062 (31.639)	mem 76.231
Train: [13][690/1500]	BT 0.039 (0.341)	DT 0.000 (0.300)	loss 7.552 (7.692)	prob 3.688 (3.854)	GS 33.656 (31.660)	mem 76.728
Train: [13][700/1500]	BT 0.029 (0.336)	DT 0.000 (0.296)	loss 7.931 (7.706)	prob 3.898 (3.800)	GS 36.047 (31.658)	mem 76.788
Train: [13][710/1500]	BT 0.038 (0.332)	DT 0.001 (0.292)	loss 7.856 (7.524)	prob 4.207 (3.595)	GS 31.047 (31.575)	mem 76.801
Train: [13][720/1500]	BT 0.030 (0.333)	DT 0.000 (0.293)	loss 7.869 (7.614)	prob 4.698 (3.771)	GS 27.812 (31.192)	mem 76.967
Train: [13][730/1500]	BT 0.030 (0.328)	DT 0.000 (0.289)	loss 7.360 (7.584)	prob 4.538 (3.895)	GS 31.938 (30.884)	mem 76.976
Train: [13][740/1500]	BT 0.039 (0.331)	DT 0.001 (0.291)	loss 7.299 (7.557)	prob 4.413 (3.892)	GS 30.812 (30.934)	mem 77.117
Train: [13][750/1500]	BT 0.040 (0.327)	DT 0.001 (0.288)	loss 7.935 (7.575)	prob 3.642 (3.853)	GS 31.203 (31.339)	mem 77.129
Train: [13][760/1500]	BT 0.039 (0.324)	DT 0.001 (0.284)	loss 7.541 (7.673)	prob 3.926 (3.382)	GS 33.719 (32.737)	mem 77.135
Train: [13][770/1500]	BT 0.040 (0.325)	DT 0.001 (0.286)	loss 7.476 (7.620)	prob 4.351 (3.601)	GS 33.547 (31.881)	mem 77.258
Train: [13][780/1500]	BT 0.040 (0.322)	DT 0.001 (0.282)	loss 7.246 (7.515)	prob 3.366 (3.604)	GS 31.438 (31.514)	mem 77.269
Train: [13][790/1500]	BT 0.039 (0.322)	DT 0.001 (0.282)	loss 7.546 (7.498)	prob 3.123 (3.537)	GS 35.453 (31.715)	mem 77.379
Train: [13][800/1500]	BT 0.040 (0.319)	DT 0.001 (0.279)	loss 7.276 (7.492)	prob 4.120 (3.507)	GS 33.109 (31.613)	mem 77.390
Train: [13][810/1500]	BT 0.052 (0.322)	DT 0.011 (0.282)	loss 7.761 (7.456)	prob 3.878 (3.204)	GS 34.141 (32.531)	mem 77.476
Train: [13][820/1500]	BT 0.036 (0.319)	DT 0.000 (0.279)	loss 7.052 (7.401)	prob 4.026 (3.364)	GS 37.094 (32.499)	mem 77.492
Train: [13][830/1500]	BT 0.045 (0.315)	DT 0.000 (0.276)	loss 7.295 (7.384)	prob 3.471 (3.378)	GS 34.734 (32.135)	mem 77.497
Train: [13][840/1500]	BT 0.039 (0.320)	DT 0.001 (0.281)	loss 7.343 (7.392)	prob 3.395 (3.306)	GS 34.234 (32.035)	mem 76.597
Train: [13][850/1500]	BT 0.031 (0.330)	DT 0.000 (0.290)	loss 7.447 (7.394)	prob 3.840 (3.341)	GS 31.641 (32.346)	mem 76.707
Train: [13][860/1500]	BT 0.029 (0.326)	DT 0.000 (0.287)	loss 6.805 (7.317)	prob 3.296 (3.498)	GS 31.234 (32.200)	mem 76.712
Train: [13][870/1500]	BT 0.027 (0.328)	DT 0.000 (0.288)	loss 7.539 (7.412)	prob 3.076 (3.207)	GS 35.531 (33.391)	mem 76.822
Train: [13][880/1500]	BT 0.029 (0.325)	DT 0.000 (0.285)	loss 7.547 (7.418)	prob 3.288 (3.159)	GS 36.281 (33.383)	mem 76.838
Train: [13][890/1500]	BT 0.040 (0.321)	DT 0.001 (0.282)	loss 7.406 (7.417)	prob 2.228 (3.052)	GS 37.891 (33.817)	mem 76.854
Train: [13][900/1500]	BT 0.040 (0.321)	DT 0.001 (0.282)	loss 7.257 (7.401)	prob 3.758 (3.078)	GS 35.109 (33.530)	mem 76.957
Train: [13][910/1500]	BT 0.040 (0.318)	DT 0.001 (0.279)	loss 7.823 (7.345)	prob 2.767 (2.846)	GS 34.484 (32.530)	mem 76.971
Train: [13][920/1500]	BT 0.040 (0.318)	DT 0.001 (0.279)	loss 7.312 (7.348)	prob 4.018 (3.000)	GS 30.484 (32.817)	mem 77.062
Train: [13][930/1500]	BT 0.040 (0.315)	DT 0.001 (0.276)	loss 7.580 (7.310)	prob 3.266 (3.178)	GS 31.891 (32.815)	mem 77.072
Train: [13][940/1500]	BT 0.041 (0.313)	DT 0.001 (0.273)	loss 7.406 (7.318)	prob 3.545 (3.247)	GS 29.391 (32.545)	mem 77.081
Train: [13][950/1500]	BT 0.039 (0.313)	DT 0.001 (0.273)	loss 7.809 (7.331)	prob 2.946 (3.190)	GS 38.531 (32.547)	mem 77.102
Train: [13][960/1500]	BT 0.650 (0.311)	DT 0.612 (0.271)	loss 7.753 (7.337)	prob 2.937 (2.865)	GS 34.734 (32.570)	mem 77.141
Train: [13][970/1500]	BT 0.061 (0.313)	DT 0.002 (0.274)	loss 7.468 (7.294)	prob 3.585 (3.175)	GS 31.984 (32.524)	mem 77.180
Train: [13][980/1500]	BT 0.038 (0.318)	DT 0.001 (0.279)	loss 7.097 (7.296)	prob 3.441 (3.127)	GS 35.312 (32.758)	mem 77.322
Train: [13][990/1500]	BT 0.039 (0.316)	DT 0.001 (0.276)	loss 7.066 (7.287)	prob 3.052 (3.172)	GS 32.406 (32.402)	mem 77.329
Train: [13][1000/1500]	BT 0.039 (0.313)	DT 0.001 (0.274)	loss 6.970 (7.294)	prob 3.531 (3.139)	GS 32.422 (32.321)	mem 77.343
Train: [13][1010/1500]	BT 0.028 (0.315)	DT 0.000 (0.275)	loss 7.255 (7.306)	prob 2.609 (3.049)	GS 31.141 (32.938)	mem 77.366
Train: [13][1020/1500]	BT 0.040 (0.312)	DT 0.000 (0.272)	loss 7.434 (7.325)	prob 3.786 (3.068)	GS 33.078 (32.457)	mem 77.377
Train: [13][1030/1500]	BT 0.027 (0.315)	DT 0.000 (0.276)	loss 7.838 (7.335)	prob 3.001 (3.123)	GS 34.781 (32.705)	mem 76.557
Train: [13][1040/1500]	BT 0.025 (0.312)	DT 0.000 (0.273)	loss 7.434 (7.311)	prob 3.040 (3.121)	GS 36.062 (32.529)	mem 76.568
Train: [13][1050/1500]	BT 0.048 (0.315)	DT 0.007 (0.276)	loss 7.378 (7.316)	prob 2.808 (3.140)	GS 33.594 (32.485)	mem 76.599
Train: [13][1060/1500]	BT 0.043 (0.313)	DT 0.001 (0.273)	loss 7.420 (7.205)	prob 2.718 (2.888)	GS 36.781 (31.944)	mem 76.603
Train: [13][1070/1500]	BT 0.052 (0.310)	DT 0.001 (0.271)	loss 7.303 (7.211)	prob 3.153 (2.953)	GS 35.031 (32.086)	mem 76.608
Train: [13][1080/1500]	BT 0.055 (0.313)	DT 0.007 (0.274)	loss 7.208 (7.235)	prob 2.765 (2.836)	GS 32.375 (32.620)	mem 76.662
Train: [13][1090/1500]	BT 0.063 (0.311)	DT 0.003 (0.271)	loss 7.128 (7.211)	prob 3.390 (2.860)	GS 34.281 (32.405)	mem 76.666
Train: [13][1100/1500]	BT 0.038 (0.314)	DT 0.001 (0.273)	loss 7.245 (7.206)	prob 3.001 (2.851)	GS 34.266 (32.398)	mem 76.749
Train: [13][1110/1500]	BT 0.039 (0.311)	DT 0.001 (0.271)	loss 7.052 (7.198)	prob 2.687 (2.930)	GS 32.375 (33.827)	mem 76.757
Train: [13][1120/1500]	BT 0.039 (0.309)	DT 0.001 (0.269)	loss 7.122 (7.221)	prob 2.522 (2.934)	GS 32.828 (33.543)	mem 76.780
Train: [13][1130/1500]	BT 0.068 (0.311)	DT 0.016 (0.270)	loss 7.093 (7.221)	prob 2.762 (2.806)	GS 32.141 (33.233)	mem 76.908
Train: [13][1140/1500]	BT 0.056 (0.318)	DT 0.001 (0.277)	loss 7.290 (7.209)	prob 2.667 (2.802)	GS 33.578 (33.629)	mem 77.064
Train: [13][1150/1500]	BT 0.059 (0.316)	DT 0.016 (0.275)	loss 7.232 (7.185)	prob 2.553 (2.867)	GS 33.578 (33.276)	mem 77.093
Train: [13][1160/1500]	BT 0.059 (0.313)	DT 0.011 (0.273)	loss 7.023 (7.125)	prob 2.921 (2.941)	GS 32.734 (31.080)	mem 77.126
Train: [13][1170/1500]	BT 0.052 (0.318)	DT 0.003 (0.278)	loss 7.209 (7.097)	prob 3.445 (2.955)	GS 34.422 (31.906)	mem 78.352
Train: [13][1180/1500]	BT 12.298 (0.327)	DT 12.254 (0.286)	loss 7.242 (7.120)	prob 2.756 (2.935)	GS 38.203 (32.388)	mem 77.398
Train: [13][1190/1500]	BT 0.031 (0.324)	DT 0.001 (0.283)	loss 7.280 (7.135)	prob 2.785 (2.918)	GS 33.609 (32.304)	mem 77.414
Train: [13][1200/1500]	BT 0.038 (0.322)	DT 0.001 (0.281)	loss 7.090 (7.125)	prob 2.851 (2.854)	GS 31.703 (32.407)	mem 77.430
Train: [13][1210/1500]	BT 0.039 (0.323)	DT 0.001 (0.282)	loss 6.921 (7.115)	prob 3.321 (2.951)	GS 35.406 (34.220)	mem 76.548
Train: [13][1220/1500]	BT 0.040 (0.320)	DT 0.001 (0.280)	loss 7.987 (7.198)	prob 1.977 (2.762)	GS 37.969 (33.798)	mem 76.552
Train: [13][1230/1500]	BT 0.039 (0.321)	DT 0.001 (0.280)	loss 7.278 (7.155)	prob 2.888 (2.788)	GS 36.453 (33.700)	mem 76.585
Train: [13][1240/1500]	BT 0.039 (0.318)	DT 0.001 (0.278)	loss 7.243 (7.135)	prob 2.653 (2.808)	GS 35.406 (33.402)	mem 76.589
Train: [13][1250/1500]	BT 0.040 (0.316)	DT 0.001 (0.276)	loss 7.222 (7.135)	prob 2.366 (2.791)	GS 33.656 (33.539)	mem 76.592
Train: [13][1260/1500]	BT 0.040 (0.316)	DT 0.001 (0.276)	loss 7.194 (7.182)	prob 3.284 (2.827)	GS 33.844 (32.575)	mem 76.640
Train: [13][1270/1500]	BT 0.042 (0.314)	DT 0.001 (0.273)	loss 6.913 (7.160)	prob 3.822 (3.006)	GS 31.281 (32.612)	mem 76.646
Train: [13][1280/1500]	BT 0.038 (0.316)	DT 0.000 (0.276)	loss 7.327 (7.116)	prob 2.480 (2.984)	GS 32.500 (32.409)	mem 76.693
Train: [13][1290/1500]	BT 0.032 (0.322)	DT 0.000 (0.281)	loss 7.348 (7.107)	prob 2.789 (2.910)	GS 36.750 (32.995)	mem 76.827
Train: [13][1300/1500]	BT 0.040 (0.320)	DT 0.001 (0.279)	loss 7.204 (7.097)	prob 3.108 (2.924)	GS 34.969 (32.945)	mem 76.840
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [13][1310/1500]	BT 0.029 (0.319)	DT 0.000 (0.278)	loss 7.114 (7.048)	prob 3.032 (3.013)	GS 33.000 (32.263)	mem 76.911
Train: [13][1320/1500]	BT 0.038 (0.319)	DT 0.001 (0.278)	loss 7.004 (7.054)	prob 3.024 (2.886)	GS 28.391 (32.623)	mem 77.032
Train: [13][1330/1500]	BT 0.038 (0.317)	DT 0.001 (0.276)	loss 7.016 (7.041)	prob 2.899 (2.949)	GS 33.406 (32.298)	mem 77.046
Train: [13][1340/1500]	BT 0.040 (0.318)	DT 0.001 (0.277)	loss 7.039 (7.046)	prob 3.137 (2.989)	GS 34.500 (32.380)	mem 77.203
Train: [13][1350/1500]	BT 0.041 (0.316)	DT 0.001 (0.275)	loss 7.344 (7.050)	prob 2.329 (2.939)	GS 34.500 (32.259)	mem 77.220
Train: [13][1360/1500]	BT 0.038 (0.314)	DT 0.001 (0.274)	loss 7.051 (6.989)	prob 2.907 (2.867)	GS 34.234 (32.983)	mem 77.257
Train: [13][1370/1500]	BT 0.037 (0.315)	DT 0.001 (0.274)	loss 7.010 (7.012)	prob 3.165 (3.016)	GS 33.766 (32.995)	mem 77.376
Train: [13][1380/1500]	BT 0.038 (0.313)	DT 0.000 (0.273)	loss 6.930 (7.022)	prob 2.932 (2.977)	GS 33.672 (32.962)	mem 77.416
Train: [13][1390/1500]	BT 0.039 (0.313)	DT 0.001 (0.273)	loss 7.084 (7.006)	prob 3.351 (3.030)	GS 32.938 (32.639)	mem 77.628
Train: [13][1400/1500]	BT 0.039 (0.311)	DT 0.001 (0.271)	loss 7.198 (7.023)	prob 3.024 (3.015)	GS 38.156 (32.715)	mem 77.661
Train: [13][1410/1500]	BT 0.060 (0.313)	DT 0.011 (0.272)	loss 7.040 (6.968)	prob 3.280 (3.037)	GS 31.359 (30.498)	mem 78.555
Train: [13][1420/1500]	BT 0.029 (0.312)	DT 0.000 (0.272)	loss 6.758 (6.980)	prob 3.562 (3.142)	GS 33.438 (32.081)	mem 79.543
Train: [13][1430/1500]	BT 0.038 (0.312)	DT 0.001 (0.272)	loss 6.774 (7.018)	prob 3.401 (3.098)	GS 29.078 (32.642)	mem 76.603
Train: [13][1440/1500]	BT 0.028 (0.311)	DT 0.001 (0.271)	loss 7.019 (7.025)	prob 3.235 (3.166)	GS 30.344 (32.205)	mem 76.638
Train: [13][1450/1500]	BT 0.039 (0.309)	DT 0.001 (0.269)	loss 7.234 (7.020)	prob 3.385 (3.156)	GS 33.047 (32.224)	mem 76.651
Train: [13][1460/1500]	BT 0.031 (0.311)	DT 0.001 (0.271)	loss 7.119 (7.025)	prob 3.067 (3.291)	GS 36.766 (33.680)	mem 76.053
Train: [13][1470/1500]	BT 0.029 (0.309)	DT 0.001 (0.269)	loss 7.266 (7.026)	prob 2.426 (3.247)	GS 33.469 (33.171)	mem 76.059
Train: [13][1480/1500]	BT 0.033 (0.310)	DT 0.000 (0.270)	loss 6.942 (7.023)	prob 3.544 (3.399)	GS 38.672 (33.855)	mem 11.710
Train: [13][1490/1500]	BT 0.027 (0.309)	DT 0.000 (0.269)	loss 7.025 (7.036)	prob 3.802 (3.480)	GS 30.688 (33.651)	mem 11.722
Train: [13][1500/1500]	BT 0.025 (0.307)	DT 0.000 (0.267)	loss 6.757 (7.022)	prob 3.658 (3.465)	GS 38.875 (33.369)	mem 11.690
Train: [13][1510/1500]	BT 0.026 (0.305)	DT 0.000 (0.266)	loss 6.809 (6.785)	prob 3.180 (3.160)	GS 30.844 (31.984)	mem 11.702
epoch 13, total time 461.28
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [14][1/1500]	BT 24.812 (24.812)	DT 24.756 (24.756)	loss 6.861 (6.861)	prob 3.708 (3.708)	GS 27.938 (27.938)	mem 83.171
Train: [14][10/1500]	BT 0.045 (2.523)	DT 0.001 (2.477)	loss 6.657 (6.760)	prob 3.297 (3.380)	GS 33.750 (32.688)	mem 85.069
Train: [14][20/1500]	BT 0.047 (1.287)	DT 0.001 (1.239)	loss 6.672 (6.770)	prob 4.250 (3.608)	GS 34.188 (32.850)	mem 87.293
Train: [14][30/1500]	BT 0.040 (1.064)	DT 0.001 (1.017)	loss 6.827 (6.813)	prob 3.723 (3.585)	GS 33.375 (32.954)	mem 106.571
Train: [14][40/1500]	BT 0.043 (0.808)	DT 0.001 (0.763)	loss 6.882 (6.829)	prob 3.373 (3.601)	GS 28.281 (32.490)	mem 108.266
Train: [14][50/1500]	BT 0.044 (0.780)	DT 0.001 (0.735)	loss 6.922 (6.848)	prob 3.581 (3.562)	GS 36.625 (32.798)	mem 114.515
Train: [14][60/1500]	BT 0.039 (0.672)	DT 0.000 (0.626)	loss 7.148 (7.021)	prob 4.049 (3.852)	GS 33.656 (33.781)	mem 114.561
Train: [14][70/1500]	BT 0.043 (0.589)	DT 0.001 (0.542)	loss 6.942 (6.977)	prob 4.089 (3.782)	GS 32.672 (32.620)	mem 114.623
Train: [14][80/1500]	BT 0.047 (0.581)	DT 0.001 (0.534)	loss 7.042 (6.986)	prob 3.203 (3.638)	GS 35.344 (32.539)	mem 116.428
Train: [14][90/1500]	BT 0.389 (0.527)	DT 0.355 (0.479)	loss 7.016 (6.981)	prob 3.093 (3.546)	GS 35.875 (32.721)	mem 116.848
Train: [14][100/1500]	BT 0.038 (0.527)	DT 0.001 (0.479)	loss 6.800 (6.969)	prob 3.491 (3.460)	GS 33.984 (32.836)	mem 114.330
Train: [14][110/1500]	BT 0.038 (0.482)	DT 0.001 (0.436)	loss 7.033 (6.961)	prob 3.901 (3.368)	GS 34.875 (33.050)	mem 114.334
Train: [14][120/1500]	BT 0.039 (0.446)	DT 0.001 (0.400)	loss 6.823 (6.912)	prob 3.916 (3.355)	GS 30.375 (32.452)	mem 114.336
Train: [14][130/1500]	BT 0.040 (0.448)	DT 0.001 (0.403)	loss 6.716 (6.890)	prob 3.708 (3.339)	GS 37.188 (32.372)	mem 77.985
Train: [14][140/1500]	BT 0.039 (0.419)	DT 0.001 (0.374)	loss 6.780 (6.859)	prob 3.706 (3.376)	GS 37.844 (32.413)	mem 77.981
Train: [14][150/1500]	BT 10.000 (0.503)	DT 9.958 (0.458)	loss 6.911 (6.847)	prob 3.185 (3.381)	GS 41.547 (32.566)	mem 78.300
Train: [14][160/1500]	BT 0.031 (0.473)	DT 0.000 (0.429)	loss 6.957 (6.819)	prob 3.377 (3.342)	GS 30.734 (31.762)	mem 78.339
Train: [14][170/1500]	BT 0.036 (0.447)	DT 0.001 (0.404)	loss 6.736 (6.829)	prob 2.523 (3.358)	GS 32.656 (32.315)	mem 78.351
Train: [14][180/1500]	BT 0.041 (0.439)	DT 0.001 (0.396)	loss 6.963 (6.839)	prob 3.720 (3.317)	GS 34.156 (32.368)	mem 78.371
Train: [14][190/1500]	BT 0.033 (0.418)	DT 0.001 (0.376)	loss 7.136 (6.843)	prob 2.588 (3.258)	GS 33.156 (32.643)	mem 78.380
Train: [14][200/1500]	BT 0.053 (0.463)	DT 0.006 (0.421)	loss 6.683 (6.837)	prob 4.191 (3.323)	GS 34.156 (32.721)	mem 78.639
Train: [14][210/1500]	BT 0.070 (0.456)	DT 0.003 (0.413)	loss 6.890 (6.825)	prob 3.661 (3.422)	GS 32.078 (34.266)	mem 78.653
Train: [14][220/1500]	BT 0.056 (0.459)	DT 0.002 (0.415)	loss 6.843 (6.818)	prob 3.492 (3.491)	GS 32.406 (34.780)	mem 78.739
Train: [14][230/1500]	BT 0.030 (0.486)	DT 0.000 (0.443)	loss 6.672 (6.827)	prob 3.450 (3.433)	GS 34.109 (34.462)	mem 77.933
Train: [14][240/1500]	BT 0.037 (0.467)	DT 0.001 (0.425)	loss 6.718 (6.829)	prob 3.776 (3.406)	GS 37.562 (34.279)	mem 77.940
Train: [14][250/1500]	BT 0.064 (0.464)	DT 0.002 (0.421)	loss 6.787 (6.839)	prob 3.802 (3.362)	GS 32.406 (33.898)	mem 77.975
Train: [14][260/1500]	BT 0.061 (0.448)	DT 0.001 (0.405)	loss 6.841 (6.849)	prob 3.433 (3.227)	GS 34.203 (30.730)	mem 77.978
Train: [14][270/1500]	BT 0.061 (0.434)	DT 0.004 (0.390)	loss 7.043 (6.851)	prob 2.951 (3.167)	GS 29.000 (31.332)	mem 77.981
Train: [14][280/1500]	BT 0.084 (0.475)	DT 0.003 (0.431)	loss 6.619 (6.844)	prob 3.512 (3.060)	GS 38.891 (32.242)	mem 79.209
Train: [14][290/1500]	BT 0.031 (0.540)	DT 0.000 (0.494)	loss 6.831 (6.835)	prob 3.020 (3.074)	GS 30.703 (32.341)	mem 91.195
Train: [14][300/1500]	BT 0.041 (0.523)	DT 0.001 (0.478)	loss 6.702 (6.833)	prob 3.057 (3.039)	GS 33.438 (32.416)	mem 93.074
Train: [14][310/1500]	BT 0.151 (0.509)	DT 0.026 (0.463)	loss 6.744 (6.775)	prob 3.017 (2.993)	GS 31.203 (32.783)	mem 93.558
Train: [14][320/1500]	BT 0.077 (0.513)	DT 0.012 (0.467)	loss 6.515 (6.786)	prob 3.778 (3.013)	GS 34.875 (32.457)	mem 115.002
Train: [14][330/1500]	BT 0.050 (0.499)	DT 0.001 (0.453)	loss 6.854 (6.810)	prob 3.222 (2.984)	GS 31.453 (32.664)	mem 115.023
Train: [14][340/1500]	BT 0.040 (0.512)	DT 0.001 (0.466)	loss 7.009 (6.822)	prob 2.794 (2.976)	GS 31.516 (32.847)	mem 115.146
Train: [14][350/1500]	BT 0.042 (0.499)	DT 0.001 (0.453)	loss 6.831 (6.818)	prob 3.375 (3.008)	GS 34.641 (33.255)	mem 115.162
Train: [14][360/1500]	BT 0.044 (0.487)	DT 0.001 (0.441)	loss 6.700 (6.890)	prob 3.078 (3.102)	GS 34.516 (32.717)	mem 115.133
Train: [14][370/1500]	BT 0.048 (0.489)	DT 0.001 (0.443)	loss 6.893 (6.908)	prob 2.253 (2.863)	GS 32.797 (32.744)	mem 115.156
Train: [14][380/1500]	BT 0.054 (0.477)	DT 0.001 (0.431)	loss 6.805 (6.920)	prob 2.980 (2.883)	GS 33.922 (32.397)	mem 115.165
Train: [14][390/1500]	BT 0.062 (0.488)	DT 0.002 (0.442)	loss 6.716 (6.910)	prob 3.144 (2.884)	GS 35.453 (32.395)	mem 115.271
Train: [14][400/1500]	BT 0.037 (0.497)	DT 0.001 (0.450)	loss 6.898 (6.892)	prob 3.557 (2.913)	GS 35.125 (33.218)	mem 116.066
Train: [14][410/1500]	BT 0.044 (0.486)	DT 0.001 (0.440)	loss 6.880 (6.907)	prob 2.519 (2.857)	GS 31.281 (31.534)	mem 116.325
Train: [14][420/1500]	BT 0.046 (0.487)	DT 0.001 (0.441)	loss 6.813 (6.862)	prob 2.995 (2.882)	GS 32.703 (32.021)	mem 116.394
Train: [14][430/1500]	BT 0.043 (0.477)	DT 0.001 (0.431)	loss 6.852 (6.880)	prob 2.933 (2.842)	GS 30.500 (32.265)	mem 116.401
Train: [14][440/1500]	BT 0.042 (0.467)	DT 0.001 (0.421)	loss 6.970 (6.881)	prob 1.992 (2.800)	GS 32.000 (32.296)	mem 116.412
Train: [14][450/1500]	BT 0.030 (0.471)	DT 0.000 (0.425)	loss 6.922 (6.886)	prob 2.825 (2.780)	GS 31.328 (32.349)	mem 77.932
Train: [14][460/1500]	BT 0.039 (0.462)	DT 0.001 (0.416)	loss 6.800 (6.812)	prob 2.153 (2.638)	GS 32.922 (32.155)	mem 77.938
Train: [14][470/1500]	BT 0.046 (0.459)	DT 0.000 (0.414)	loss 6.770 (6.803)	prob 3.624 (2.795)	GS 35.297 (32.134)	mem 77.992
Train: [14][480/1500]	BT 0.036 (0.451)	DT 0.001 (0.405)	loss 6.876 (6.780)	prob 2.514 (2.795)	GS 36.609 (32.351)	mem 77.996
Train: [14][490/1500]	BT 0.064 (0.456)	DT 0.011 (0.411)	loss 6.625 (6.787)	prob 2.698 (2.828)	GS 33.297 (32.448)	mem 78.096
Train: [14][500/1500]	BT 0.038 (0.448)	DT 0.001 (0.403)	loss 6.828 (6.789)	prob 3.111 (2.786)	GS 37.172 (32.268)	mem 78.104
Train: [14][510/1500]	BT 0.040 (0.440)	DT 0.001 (0.395)	loss 6.566 (6.751)	prob 2.463 (2.991)	GS 34.797 (33.034)	mem 78.123
Train: [14][520/1500]	BT 0.040 (0.439)	DT 0.001 (0.395)	loss 6.726 (6.754)	prob 2.193 (2.735)	GS 30.391 (32.562)	mem 78.476
Train: [14][530/1500]	BT 0.045 (0.433)	DT 0.001 (0.388)	loss 6.650 (6.773)	prob 2.659 (2.649)	GS 33.906 (32.666)	mem 79.049
Train: [14][540/1500]	BT 0.056 (0.445)	DT 0.006 (0.400)	loss 6.725 (6.780)	prob 2.622 (2.626)	GS 36.641 (33.195)	mem 82.831
Train: [14][550/1500]	BT 0.041 (0.437)	DT 0.001 (0.393)	loss 6.821 (6.785)	prob 2.327 (2.626)	GS 35.500 (32.961)	mem 83.661
Train: [14][560/1500]	BT 0.043 (0.430)	DT 0.001 (0.386)	loss 6.849 (6.887)	prob 2.621 (2.271)	GS 33.406 (32.652)	mem 85.373
Train: [14][570/1500]	BT 0.048 (0.433)	DT 0.001 (0.389)	loss 6.803 (6.845)	prob 2.448 (2.257)	GS 33.281 (32.695)	mem 106.253
Train: [14][580/1500]	BT 0.052 (0.427)	DT 0.013 (0.382)	loss 6.960 (6.847)	prob 2.305 (2.387)	GS 39.531 (32.948)	mem 107.397
Train: [14][590/1500]	BT 0.037 (0.440)	DT 0.001 (0.396)	loss 6.684 (6.823)	prob 2.478 (2.419)	GS 35.188 (33.330)	mem 115.242
Train: [14][600/1500]	BT 0.045 (0.434)	DT 0.001 (0.389)	loss 6.830 (6.813)	prob 2.394 (2.406)	GS 31.188 (33.138)	mem 115.254
Train: [14][610/1500]	BT 0.061 (0.433)	DT 0.003 (0.388)	loss 6.793 (6.790)	prob 1.930 (2.296)	GS 30.062 (32.936)	mem 115.343
Train: [14][620/1500]	BT 0.075 (0.432)	DT 0.015 (0.387)	loss 6.986 (6.846)	prob 1.876 (2.258)	GS 32.297 (33.000)	mem 115.369
Train: [14][630/1500]	BT 0.052 (0.426)	DT 0.009 (0.381)	loss 6.994 (6.847)	prob 2.067 (2.392)	GS 36.188 (33.407)	mem 115.384
Train: [14][640/1500]	BT 0.039 (0.430)	DT 0.001 (0.385)	loss 6.753 (6.832)	prob 2.944 (2.429)	GS 32.453 (32.968)	mem 114.479
Train: [14][650/1500]	BT 0.040 (0.424)	DT 0.001 (0.379)	loss 6.772 (6.819)	prob 2.655 (2.475)	GS 32.047 (32.938)	mem 114.480
Train: [14][660/1500]	BT 0.082 (0.428)	DT 0.011 (0.382)	loss 6.905 (6.724)	prob 1.976 (2.498)	GS 29.391 (31.203)	mem 114.642
Train: [14][670/1500]	BT 0.100 (0.423)	DT 0.001 (0.377)	loss 6.767 (6.759)	prob 2.372 (2.449)	GS 38.438 (32.220)	mem 115.149
Train: [14][680/1500]	BT 0.101 (0.418)	DT 0.001 (0.371)	loss 6.734 (6.758)	prob 1.817 (2.425)	GS 33.781 (32.248)	mem 115.160
Train: [14][690/1500]	BT 0.026 (0.425)	DT 0.000 (0.378)	loss 6.745 (6.767)	prob 2.408 (2.350)	GS 34.047 (32.552)	mem 78.902
Train: [14][700/1500]	BT 0.029 (0.420)	DT 0.000 (0.373)	loss 6.669 (6.774)	prob 3.191 (2.392)	GS 30.688 (32.370)	mem 79.057
Train: [14][710/1500]	BT 0.040 (0.416)	DT 0.001 (0.370)	loss 6.706 (6.680)	prob 2.772 (2.646)	GS 32.344 (31.517)	mem 79.946
Train: [14][720/1500]	BT 0.039 (0.416)	DT 0.001 (0.370)	loss 6.878 (6.731)	prob 1.169 (2.464)	GS 30.938 (30.753)	mem 78.093
Train: [14][730/1500]	BT 0.039 (0.411)	DT 0.001 (0.365)	loss 6.790 (6.740)	prob 2.649 (2.411)	GS 33.734 (30.963)	mem 78.120
Train: [14][740/1500]	BT 0.038 (0.413)	DT 0.001 (0.367)	loss 6.639 (6.739)	prob 2.290 (2.454)	GS 36.562 (31.452)	mem 78.208
Train: [14][750/1500]	BT 0.030 (0.408)	DT 0.000 (0.362)	loss 6.855 (6.739)	prob 2.246 (2.483)	GS 35.219 (31.773)	mem 78.214
Train: [14][760/1500]	BT 0.038 (0.405)	DT 0.001 (0.359)	loss 6.809 (6.800)	prob 2.856 (2.205)	GS 32.062 (32.114)	mem 76.947
Train: [14][770/1500]	BT 0.038 (0.403)	DT 0.001 (0.358)	loss 6.767 (6.764)	prob 2.428 (2.379)	GS 30.203 (32.284)	mem 76.814
Train: [14][780/1500]	BT 0.038 (0.401)	DT 0.001 (0.355)	loss 6.828 (6.753)	prob 1.960 (2.347)	GS 34.453 (32.173)	mem 76.893
Train: [14][790/1500]	BT 0.038 (0.401)	DT 0.001 (0.355)	loss 6.779 (6.756)	prob 2.393 (2.331)	GS 31.844 (31.918)	mem 78.856
Train: [14][800/1500]	BT 0.042 (0.396)	DT 0.001 (0.351)	loss 7.088 (6.765)	prob 1.713 (2.334)	GS 35.750 (31.943)	mem 79.034
Train: [14][810/1500]	BT 0.078 (0.400)	DT 0.005 (0.355)	loss 6.612 (6.773)	prob 2.587 (2.305)	GS 35.266 (31.995)	mem 83.395
Train: [14][820/1500]	BT 0.045 (0.396)	DT 0.001 (0.351)	loss 7.041 (6.796)	prob 1.910 (2.110)	GS 32.625 (32.010)	mem 84.805
Train: [14][830/1500]	BT 0.066 (0.403)	DT 0.016 (0.357)	loss 6.680 (6.762)	prob 2.498 (2.127)	GS 33.297 (32.248)	mem 98.082
Train: [14][840/1500]	BT 0.065 (0.399)	DT 0.013 (0.353)	loss 6.804 (6.763)	prob 2.479 (2.158)	GS 27.859 (32.085)	mem 98.791
Train: [14][850/1500]	BT 0.055 (0.395)	DT 0.006 (0.349)	loss 6.884 (6.771)	prob 1.507 (2.107)	GS 33.438 (32.116)	mem 99.414
Train: [14][860/1500]	BT 0.063 (0.399)	DT 0.013 (0.353)	loss 6.700 (6.791)	prob 1.941 (1.868)	GS 36.844 (33.417)	mem 116.255
Train: [14][870/1500]	BT 0.063 (0.400)	DT 0.014 (0.354)	loss 6.872 (6.765)	prob 2.538 (2.049)	GS 33.109 (33.245)	mem 112.976
Train: [14][880/1500]	BT 0.023 (0.402)	DT 0.000 (0.356)	loss 6.582 (6.737)	prob 2.822 (2.244)	GS 31.984 (33.267)	mem 76.422
Train: [14][890/1500]	BT 0.039 (0.397)	DT 0.001 (0.352)	loss 6.625 (6.725)	prob 2.449 (2.245)	GS 39.562 (33.666)	mem 76.424
Train: [14][900/1500]	BT 0.069 (0.398)	DT 0.014 (0.353)	loss 6.946 (6.723)	prob 1.418 (2.266)	GS 31.547 (33.435)	mem 76.453
Train: [14][910/1500]	BT 0.038 (0.395)	DT 0.000 (0.349)	loss 6.673 (6.721)	prob 1.212 (1.921)	GS 35.109 (32.847)	mem 76.458
Train: [14][920/1500]	BT 0.053 (0.395)	DT 0.001 (0.349)	loss 6.444 (6.665)	prob 2.502 (1.938)	GS 38.438 (32.502)	mem 76.485
Train: [14][930/1500]	BT 0.072 (0.397)	DT 0.001 (0.350)	loss 6.541 (6.638)	prob 2.115 (1.945)	GS 28.266 (32.334)	mem 76.514
Train: [14][940/1500]	BT 0.028 (0.409)	DT 0.000 (0.362)	loss 6.617 (6.628)	prob 2.200 (2.063)	GS 34.344 (32.131)	mem 76.677
Train: [14][950/1500]	BT 0.037 (0.405)	DT 0.000 (0.359)	loss 6.631 (6.641)	prob 2.427 (2.073)	GS 27.500 (32.010)	mem 76.690
Train: [14][960/1500]	BT 0.038 (0.405)	DT 0.001 (0.359)	loss 6.838 (6.732)	prob 2.517 (2.010)	GS 33.656 (33.375)	mem 76.821
Train: [14][970/1500]	BT 0.039 (0.401)	DT 0.001 (0.355)	loss 7.064 (6.768)	prob 2.352 (2.240)	GS 37.188 (33.862)	mem 76.830
Train: [14][980/1500]	BT 0.039 (0.398)	DT 0.001 (0.352)	loss 6.657 (6.748)	prob 2.864 (2.279)	GS 34.859 (33.377)	mem 76.841
Train: [14][990/1500]	BT 0.054 (0.401)	DT 0.001 (0.356)	loss 6.847 (6.789)	prob 2.552 (2.397)	GS 32.453 (33.664)	mem 76.906
Train: [14][1000/1500]	BT 0.097 (0.398)	DT 0.017 (0.352)	loss 6.818 (6.809)	prob 3.322 (2.457)	GS 32.891 (33.586)	mem 76.924
Train: [14][1010/1500]	BT 0.033 (0.402)	DT 0.001 (0.356)	loss 7.193 (6.810)	prob 1.917 (2.638)	GS 33.828 (33.625)	mem 77.051
Train: [14][1020/1500]	BT 0.037 (0.403)	DT 0.000 (0.357)	loss 6.922 (6.866)	prob 3.599 (2.628)	GS 34.438 (33.070)	mem 77.158
Train: [14][1030/1500]	BT 0.072 (0.400)	DT 0.004 (0.354)	loss 7.407 (6.936)	prob 2.324 (2.558)	GS 31.219 (32.434)	mem 77.169
Train: [14][1040/1500]	BT 0.031 (0.410)	DT 0.000 (0.365)	loss 7.713 (6.970)	prob 3.247 (2.621)	GS 33.781 (32.597)	mem 76.461
Train: [14][1050/1500]	BT 0.037 (0.407)	DT 0.001 (0.361)	loss 7.776 (7.012)	prob 3.081 (2.695)	GS 35.219 (32.895)	mem 76.462
Train: [14][1060/1500]	BT 0.040 (0.407)	DT 0.001 (0.362)	loss 7.093 (7.058)	prob 2.788 (3.117)	GS 36.359 (32.888)	mem 76.516
Train: [14][1070/1500]	BT 0.040 (0.404)	DT 0.001 (0.358)	loss 7.214 (7.154)	prob 3.315 (2.893)	GS 34.000 (32.327)	mem 76.529
Train: [14][1080/1500]	BT 0.040 (0.401)	DT 0.001 (0.355)	loss 6.803 (7.116)	prob 2.929 (2.974)	GS 31.484 (32.046)	mem 76.540
Train: [14][1090/1500]	BT 0.037 (0.400)	DT 0.001 (0.355)	loss 7.188 (7.154)	prob 3.133 (2.970)	GS 32.016 (32.343)	mem 76.564
Train: [14][1100/1500]	BT 0.038 (0.397)	DT 0.001 (0.352)	loss 7.077 (7.159)	prob 2.983 (2.989)	GS 33.750 (32.229)	mem 76.568
Train: [14][1110/1500]	BT 0.037 (0.398)	DT 0.001 (0.352)	loss 7.755 (7.346)	prob 3.092 (2.864)	GS 35.844 (31.483)	mem 76.633
Train: [14][1120/1500]	BT 0.038 (0.394)	DT 0.001 (0.349)	loss 7.234 (7.294)	prob 2.584 (2.943)	GS 32.891 (32.243)	mem 76.636
Train: [14][1130/1500]	BT 0.047 (0.394)	DT 0.000 (0.349)	loss 7.766 (7.291)	prob 2.860 (3.012)	GS 33.609 (32.001)	mem 76.724
Train: [14][1140/1500]	BT 0.063 (0.391)	DT 0.004 (0.346)	loss 7.074 (7.283)	prob 3.260 (2.940)	GS 32.922 (32.461)	mem 76.730
Train: [14][1150/1500]	BT 0.041 (0.388)	DT 0.001 (0.343)	loss 7.767 (7.308)	prob 2.613 (2.853)	GS 29.250 (32.640)	mem 76.737
Train: [14][1160/1500]	BT 0.038 (0.391)	DT 0.001 (0.346)	loss 7.346 (7.363)	prob 2.933 (3.004)	GS 33.500 (31.670)	mem 76.874
Train: [14][1170/1500]	BT 0.054 (0.388)	DT 0.002 (0.343)	loss 7.330 (7.337)	prob 2.174 (3.004)	GS 30.359 (32.156)	mem 76.896
Train: [14][1180/1500]	BT 0.038 (0.388)	DT 0.001 (0.343)	loss 7.884 (7.384)	prob 2.969 (3.018)	GS 35.688 (32.491)	mem 76.963
Train: [14][1190/1500]	BT 0.038 (0.385)	DT 0.001 (0.340)	loss 7.212 (7.379)	prob 3.167 (3.021)	GS 32.609 (32.352)	mem 76.976
Train: [14][1200/1500]	BT 0.038 (0.383)	DT 0.001 (0.338)	loss 7.502 (7.376)	prob 2.581 (2.975)	GS 34.062 (32.450)	mem 77.024
Train: [14][1210/1500]	BT 0.038 (0.382)	DT 0.001 (0.337)	loss 7.064 (7.327)	prob 2.931 (2.932)	GS 32.484 (33.305)	mem 77.070
Train: [14][1220/1500]	BT 0.039 (0.382)	DT 0.001 (0.337)	loss 7.741 (7.392)	prob 2.780 (2.789)	GS 32.422 (33.151)	mem 77.164
Train: [14][1230/1500]	BT 0.050 (0.379)	DT 0.011 (0.334)	loss 7.435 (7.380)	prob 2.996 (2.817)	GS 36.844 (33.033)	mem 77.218
Train: [14][1240/1500]	BT 6.990 (0.382)	DT 6.952 (0.337)	loss 7.568 (7.385)	prob 2.987 (2.878)	GS 32.969 (32.919)	mem 79.901
Train: [14][1250/1500]	BT 0.047 (0.380)	DT 0.001 (0.335)	loss 7.667 (7.390)	prob 2.850 (2.794)	GS 35.922 (33.041)	mem 80.905
Train: [14][1260/1500]	BT 0.053 (0.377)	DT 0.001 (0.333)	loss 7.079 (7.495)	prob 3.519 (2.820)	GS 36.203 (32.575)	mem 81.773
Train: [14][1270/1500]	BT 0.058 (0.381)	DT 0.001 (0.336)	loss 7.603 (7.409)	prob 1.763 (2.694)	GS 32.531 (32.718)	mem 88.573
Train: [14][1280/1500]	BT 0.071 (0.380)	DT 0.006 (0.335)	loss 8.336 (7.445)	prob 1.654 (2.666)	GS 38.109 (32.815)	mem 92.625
Train: [14][1290/1500]	BT 0.045 (0.380)	DT 0.001 (0.335)	loss 7.265 (7.433)	prob 3.159 (2.651)	GS 34.016 (32.768)	mem 100.308
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [14][1300/1500]	BT 0.094 (0.380)	DT 0.001 (0.335)	loss 7.613 (7.417)	prob 2.428 (2.701)	GS 33.000 (32.566)	mem 113.070
Train: [14][1310/1500]	BT 0.103 (0.382)	DT 0.002 (0.336)	loss 7.687 (7.381)	prob 3.019 (2.789)	GS 33.391 (30.589)	mem 113.120
Train: [14][1320/1500]	BT 0.083 (0.380)	DT 0.003 (0.334)	loss 7.185 (7.381)	prob 3.291 (2.835)	GS 35.406 (31.720)	mem 113.124
Train: [14][1330/1500]	BT 0.075 (0.380)	DT 0.001 (0.334)	loss 7.558 (7.404)	prob 2.718 (2.825)	GS 37.203 (32.465)	mem 113.145
Train: [14][1340/1500]	BT 0.054 (0.383)	DT 0.001 (0.337)	loss 7.302 (7.425)	prob 2.365 (2.684)	GS 31.156 (32.702)	mem 113.313
Train: [14][1350/1500]	BT 0.061 (0.381)	DT 0.001 (0.335)	loss 7.463 (7.430)	prob 2.363 (2.594)	GS 35.359 (32.809)	mem 113.433
Train: [14][1360/1500]	BT 0.043 (0.382)	DT 0.001 (0.336)	loss 7.844 (7.468)	prob 2.342 (2.460)	GS 34.578 (31.725)	mem 115.238
Train: [14][1370/1500]	BT 0.051 (0.380)	DT 0.001 (0.334)	loss 7.144 (7.435)	prob 3.242 (2.587)	GS 36.828 (32.332)	mem 116.197
Train: [14][1380/1500]	BT 0.058 (0.382)	DT 0.006 (0.336)	loss 7.303 (7.414)	prob 2.448 (2.597)	GS 33.750 (32.374)	mem 111.873
Train: [14][1390/1500]	BT 0.036 (0.391)	DT 0.001 (0.345)	loss 7.381 (7.423)	prob 2.068 (2.464)	GS 32.250 (32.548)	mem 79.697
Train: [14][1400/1500]	BT 0.036 (0.389)	DT 0.001 (0.343)	loss 7.696 (7.434)	prob 2.785 (2.412)	GS 35.344 (32.527)	mem 81.214
Train: [14][1410/1500]	BT 0.044 (0.386)	DT 0.001 (0.340)	loss 7.295 (7.436)	prob 2.090 (2.154)	GS 33.172 (32.803)	mem 81.230
Train: [14][1420/1500]	BT 0.068 (0.388)	DT 0.008 (0.342)	loss 7.152 (7.446)	prob 2.360 (2.225)	GS 32.594 (33.045)	mem 103.031
Train: [14][1430/1500]	BT 0.064 (0.386)	DT 0.014 (0.340)	loss 7.435 (7.433)	prob 2.630 (2.137)	GS 34.469 (32.767)	mem 103.774
Train: [14][1440/1500]	BT 0.084 (0.390)	DT 0.002 (0.344)	loss 7.309 (7.432)	prob 2.436 (2.090)	GS 35.172 (33.058)	mem 113.854
Train: [14][1450/1500]	BT 0.093 (0.388)	DT 0.009 (0.342)	loss 7.609 (7.431)	prob 2.454 (2.020)	GS 31.453 (32.851)	mem 113.861
Train: [14][1460/1500]	BT 0.094 (0.386)	DT 0.012 (0.340)	loss 7.548 (7.438)	prob 1.568 (1.850)	GS 36.344 (33.347)	mem 113.868
Train: [14][1470/1500]	BT 0.036 (0.390)	DT 0.001 (0.343)	loss 7.555 (7.388)	prob 2.452 (1.902)	GS 34.281 (32.441)	mem 113.039
Train: [14][1480/1500]	BT 0.032 (0.388)	DT 0.001 (0.342)	loss 7.076 (7.413)	prob 2.388 (1.977)	GS 34.781 (32.643)	mem 59.290
Train: [14][1490/1500]	BT 0.030 (0.387)	DT 0.000 (0.341)	loss 7.283 (7.441)	prob 2.240 (1.890)	GS 32.688 (32.274)	mem 47.984
Train: [14][1500/1500]	BT 0.028 (0.385)	DT 0.000 (0.339)	loss 8.407 (7.458)	prob 2.324 (1.912)	GS 36.750 (32.449)	mem 47.990
Train: [14][1510/1500]	BT 0.028 (0.383)	DT 0.000 (0.337)	loss 7.816 (7.169)	prob 2.890 (2.570)	GS 36.062 (30.616)	mem 47.924
epoch 14, total time 578.46
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [15][1/1500]	BT 22.221 (22.221)	DT 22.162 (22.162)	loss 7.073 (7.073)	prob 2.996 (2.996)	GS 28.703 (28.703)	mem 75.365
Train: [15][10/1500]	BT 0.039 (2.511)	DT 0.000 (2.471)	loss 7.436 (7.142)	prob 3.019 (2.726)	GS 33.016 (30.332)	mem 75.515
Train: [15][20/1500]	BT 0.039 (1.275)	DT 0.001 (1.236)	loss 6.909 (7.209)	prob 2.299 (2.525)	GS 31.125 (31.396)	mem 75.529
Train: [15][30/1500]	BT 0.057 (1.027)	DT 0.001 (0.988)	loss 7.600 (7.319)	prob 3.015 (2.336)	GS 31.531 (31.597)	mem 75.810
Train: [15][40/1500]	BT 0.094 (0.820)	DT 0.004 (0.776)	loss 7.603 (7.361)	prob 2.806 (2.254)	GS 35.188 (32.060)	mem 76.004
Train: [15][50/1500]	BT 0.030 (1.048)	DT 0.000 (1.005)	loss 7.618 (7.407)	prob 2.299 (2.292)	GS 31.656 (32.362)	mem 76.270
Train: [15][60/1500]	BT 0.027 (0.878)	DT 0.000 (0.838)	loss 7.714 (7.394)	prob 3.208 (2.600)	GS 34.203 (31.639)	mem 76.272
Train: [15][70/1500]	BT 0.039 (0.821)	DT 0.001 (0.781)	loss 7.684 (7.399)	prob 3.649 (2.777)	GS 31.656 (31.073)	mem 76.421
Train: [15][80/1500]	BT 0.039 (0.722)	DT 0.001 (0.684)	loss 7.155 (7.393)	prob 3.530 (2.904)	GS 29.859 (30.832)	mem 76.426
Train: [15][90/1500]	BT 5.188 (0.704)	DT 5.141 (0.665)	loss 7.867 (7.425)	prob 2.634 (2.770)	GS 30.688 (31.552)	mem 76.489
Train: [15][100/1500]	BT 0.058 (0.637)	DT 0.014 (0.599)	loss 7.302 (7.430)	prob 2.753 (2.667)	GS 32.719 (31.684)	mem 76.491
Train: [15][110/1500]	BT 0.034 (0.583)	DT 0.000 (0.544)	loss 7.855 (7.378)	prob 2.888 (2.639)	GS 28.641 (31.325)	mem 76.495
Train: [15][120/1500]	BT 0.039 (0.608)	DT 0.001 (0.569)	loss 7.841 (7.432)	prob 3.098 (2.746)	GS 34.016 (32.416)	mem 76.595
Train: [15][130/1500]	BT 0.044 (0.599)	DT 0.005 (0.559)	loss 7.968 (7.512)	prob 2.306 (2.652)	GS 39.719 (33.285)	mem 76.610
Train: [15][140/1500]	BT 0.030 (0.574)	DT 0.000 (0.534)	loss 7.414 (7.545)	prob 2.065 (2.515)	GS 30.422 (33.204)	mem 76.688
Train: [15][150/1500]	BT 0.040 (0.538)	DT 0.001 (0.498)	loss 6.988 (7.522)	prob 3.571 (2.607)	GS 33.891 (33.027)	mem 76.698
Train: [15][160/1500]	BT 0.070 (0.535)	DT 0.002 (0.496)	loss 7.927 (7.747)	prob 2.772 (2.735)	GS 34.141 (30.886)	mem 76.967
Train: [15][170/1500]	BT 0.037 (0.507)	DT 0.001 (0.467)	loss 7.205 (7.654)	prob 2.876 (2.509)	GS 31.922 (32.012)	mem 76.984
Train: [15][180/1500]	BT 0.041 (0.511)	DT 0.001 (0.470)	loss 7.700 (7.588)	prob 2.982 (2.552)	GS 34.453 (32.507)	mem 79.625
Train: [15][190/1500]	BT 0.040 (0.486)	DT 0.001 (0.445)	loss 7.791 (7.610)	prob 3.218 (2.436)	GS 33.969 (32.521)	mem 79.864
Train: [15][200/1500]	BT 0.041 (0.464)	DT 0.001 (0.423)	loss 7.595 (7.589)	prob 2.309 (2.480)	GS 32.000 (32.843)	mem 79.808
Train: [15][210/1500]	BT 0.029 (0.476)	DT 0.000 (0.436)	loss 7.701 (7.678)	prob 2.569 (2.178)	GS 33.719 (32.797)	mem 77.006
Train: [15][220/1500]	BT 0.040 (0.456)	DT 0.001 (0.416)	loss 7.664 (7.640)	prob 2.370 (2.368)	GS 34.109 (33.612)	mem 77.014
Train: [15][230/1500]	BT 0.056 (0.455)	DT 0.001 (0.414)	loss 7.263 (7.604)	prob 2.579 (2.326)	GS 37.125 (33.579)	mem 77.117
Train: [15][240/1500]	BT 0.039 (0.438)	DT 0.001 (0.397)	loss 7.770 (7.604)	prob 2.249 (2.306)	GS 33.984 (33.220)	mem 77.133
Train: [15][250/1500]	BT 0.039 (0.434)	DT 0.001 (0.394)	loss 7.960 (7.640)	prob 2.911 (2.317)	GS 37.844 (32.719)	mem 77.230
Train: [15][260/1500]	BT 0.045 (0.423)	DT 0.001 (0.383)	loss 8.011 (7.820)	prob 2.367 (2.232)	GS 33.672 (33.086)	mem 77.243
Train: [15][270/1500]	BT 0.042 (0.409)	DT 0.001 (0.369)	loss 8.518 (7.719)	prob 1.965 (2.154)	GS 33.094 (33.373)	mem 77.250
Train: [15][280/1500]	BT 0.091 (0.420)	DT 0.011 (0.379)	loss 8.061 (7.715)	prob 3.567 (2.262)	GS 32.250 (32.712)	mem 77.344
Train: [15][290/1500]	BT 0.031 (0.422)	DT 0.000 (0.381)	loss 7.169 (7.677)	prob 2.762 (2.233)	GS 31.969 (32.923)	mem 76.456
Train: [15][300/1500]	BT 0.039 (0.409)	DT 0.001 (0.369)	loss 8.022 (7.734)	prob 2.734 (2.220)	GS 35.703 (32.681)	mem 76.463
Train: [15][310/1500]	BT 0.039 (0.409)	DT 0.001 (0.369)	loss 8.293 (7.748)	prob 1.410 (2.314)	GS 38.906 (32.130)	mem 76.504
Train: [15][320/1500]	BT 0.039 (0.398)	DT 0.001 (0.358)	loss 8.036 (7.667)	prob 3.200 (2.526)	GS 34.859 (31.935)	mem 76.511
Train: [15][330/1500]	BT 0.030 (0.429)	DT 0.000 (0.389)	loss 8.409 (7.737)	prob 2.870 (2.522)	GS 31.047 (32.301)	mem 76.572
Train: [15][340/1500]	BT 0.033 (0.417)	DT 0.000 (0.377)	loss 8.042 (7.749)	prob 3.311 (2.534)	GS 32.984 (32.221)	mem 76.580
Train: [15][350/1500]	BT 0.037 (0.406)	DT 0.001 (0.366)	loss 7.666 (7.799)	prob 3.063 (2.469)	GS 31.047 (32.248)	mem 76.626
Train: [15][360/1500]	BT 0.063 (0.407)	DT 0.011 (0.367)	loss 7.729 (8.038)	prob 2.580 (2.309)	GS 33.719 (32.734)	mem 77.368
Train: [15][370/1500]	BT 0.066 (0.397)	DT 0.017 (0.357)	loss 7.951 (7.871)	prob 3.248 (2.547)	GS 35.578 (33.396)	mem 77.615
Train: [15][380/1500]	BT 0.029 (0.409)	DT 0.000 (0.369)	loss 7.926 (7.879)	prob 2.174 (2.593)	GS 31.344 (33.135)	mem 76.811
Train: [15][390/1500]	BT 0.027 (0.399)	DT 0.000 (0.359)	loss 7.351 (7.859)	prob 3.000 (2.582)	GS 34.469 (33.025)	mem 76.822
Train: [15][400/1500]	BT 0.039 (0.390)	DT 0.001 (0.351)	loss 7.503 (7.856)	prob 3.998 (2.596)	GS 32.812 (33.134)	mem 76.839
Train: [15][410/1500]	BT 0.047 (0.396)	DT 0.001 (0.356)	loss 8.078 (7.769)	prob 1.822 (2.833)	GS 31.594 (33.598)	mem 76.949
Train: [15][420/1500]	BT 0.065 (0.388)	DT 0.006 (0.348)	loss 8.157 (7.768)	prob 2.338 (2.812)	GS 33.766 (32.681)	mem 76.960
Train: [15][430/1500]	BT 0.030 (0.403)	DT 0.000 (0.363)	loss 8.186 (7.811)	prob 2.631 (2.675)	GS 33.844 (32.889)	mem 77.116
Train: [15][440/1500]	BT 0.037 (0.394)	DT 0.000 (0.354)	loss 8.081 (7.805)	prob 3.840 (2.730)	GS 31.406 (32.861)	mem 77.128
Train: [15][450/1500]	BT 0.091 (0.399)	DT 0.008 (0.359)	loss 8.909 (7.820)	prob 1.644 (2.760)	GS 36.281 (32.995)	mem 77.211
Train: [15][460/1500]	BT 0.089 (0.392)	DT 0.007 (0.351)	loss 8.079 (7.893)	prob 2.478 (2.649)	GS 28.203 (32.584)	mem 77.217
Train: [15][470/1500]	BT 0.101 (0.386)	DT 0.013 (0.344)	loss 8.140 (7.940)	prob 2.043 (2.468)	GS 35.969 (33.312)	mem 77.227
Train: [15][480/1500]	BT 0.092 (0.406)	DT 0.005 (0.363)	loss 7.790 (7.877)	prob 3.637 (2.616)	GS 27.984 (32.665)	mem 77.336
Train: [15][490/1500]	BT 0.028 (0.442)	DT 0.000 (0.399)	loss 8.021 (7.970)	prob 3.050 (2.580)	GS 36.141 (33.302)	mem 76.586
Train: [15][500/1500]	BT 0.063 (0.434)	DT 0.014 (0.391)	loss 8.033 (7.974)	prob 3.421 (2.572)	GS 30.016 (33.204)	mem 76.592
Train: [15][510/1500]	BT 0.031 (0.441)	DT 0.001 (0.398)	loss 7.564 (8.039)	prob 3.675 (2.684)	GS 37.266 (33.983)	mem 76.508
Train: [15][520/1500]	BT 0.031 (0.433)	DT 0.000 (0.390)	loss 7.689 (7.912)	prob 3.679 (2.923)	GS 32.734 (32.559)	mem 76.508
Train: [15][530/1500]	BT 0.032 (0.439)	DT 0.000 (0.396)	loss 8.959 (7.929)	prob 3.223 (2.965)	GS 35.156 (33.336)	mem 76.576
Train: [15][540/1500]	BT 0.026 (0.432)	DT 0.000 (0.389)	loss 7.553 (7.888)	prob 3.467 (2.994)	GS 31.125 (32.909)	mem 76.606
Train: [15][550/1500]	BT 0.039 (0.425)	DT 0.001 (0.382)	loss 8.300 (7.920)	prob 3.008 (2.882)	GS 32.438 (33.077)	mem 76.615
Train: [15][560/1500]	BT 0.042 (0.424)	DT 0.001 (0.382)	loss 8.239 (7.881)	prob 3.161 (2.581)	GS 35.359 (32.761)	mem 76.725
Train: [15][570/1500]	BT 0.041 (0.418)	DT 0.001 (0.375)	loss 7.720 (7.763)	prob 3.314 (2.669)	GS 38.203 (33.276)	mem 76.741
Train: [15][580/1500]	BT 0.036 (0.426)	DT 0.000 (0.383)	loss 8.538 (7.863)	prob 2.889 (2.690)	GS 34.719 (32.800)	mem 76.838
Train: [15][590/1500]	BT 0.037 (0.419)	DT 0.000 (0.377)	loss 7.891 (7.907)	prob 3.858 (2.744)	GS 29.609 (33.031)	mem 76.854
Train: [15][600/1500]	BT 0.038 (0.418)	DT 0.001 (0.375)	loss 8.019 (7.868)	prob 3.867 (2.835)	GS 36.641 (32.741)	mem 76.920
Train: [15][610/1500]	BT 0.038 (0.413)	DT 0.001 (0.371)	loss 8.397 (8.176)	prob 2.836 (2.703)	GS 34.281 (32.719)	mem 76.965
Train: [15][620/1500]	BT 0.039 (0.407)	DT 0.001 (0.365)	loss 8.795 (8.151)	prob 1.857 (2.636)	GS 35.578 (33.280)	mem 76.977
Train: [15][630/1500]	BT 0.046 (0.407)	DT 0.001 (0.365)	loss 7.230 (8.051)	prob 3.117 (2.754)	GS 31.859 (32.952)	mem 77.042
Train: [15][640/1500]	BT 0.038 (0.403)	DT 0.001 (0.361)	loss 8.158 (8.037)	prob 2.753 (2.697)	GS 30.828 (33.079)	mem 77.078
Train: [15][650/1500]	BT 0.039 (0.408)	DT 0.000 (0.366)	loss 8.819 (8.063)	prob 2.747 (2.664)	GS 35.281 (33.338)	mem 77.142
Train: [15][660/1500]	BT 0.060 (0.406)	DT 0.011 (0.364)	loss 8.921 (8.001)	prob 2.605 (2.708)	GS 38.797 (32.911)	mem 77.190
Train: [15][670/1500]	BT 0.041 (0.403)	DT 0.001 (0.360)	loss 8.742 (8.031)	prob 2.811 (2.674)	GS 35.656 (33.194)	mem 77.237
Train: [15][680/1500]	BT 0.040 (0.400)	DT 0.001 (0.358)	loss 8.105 (8.026)	prob 2.895 (2.690)	GS 31.031 (32.758)	mem 76.365
Train: [15][690/1500]	BT 0.039 (0.397)	DT 0.001 (0.355)	loss 8.161 (8.092)	prob 3.158 (2.708)	GS 30.594 (32.350)	mem 76.364
Train: [15][700/1500]	BT 0.040 (0.395)	DT 0.001 (0.353)	loss 8.029 (8.064)	prob 2.462 (2.784)	GS 32.688 (32.296)	mem 76.581
Train: [15][710/1500]	BT 0.076 (0.393)	DT 0.011 (0.351)	loss 7.628 (7.928)	prob 3.869 (2.688)	GS 29.734 (32.486)	mem 77.233
Train: [15][720/1500]	BT 0.088 (0.396)	DT 0.019 (0.353)	loss 7.585 (7.893)	prob 3.805 (3.009)	GS 30.859 (32.117)	mem 78.388
Train: [15][730/1500]	BT 0.033 (0.397)	DT 0.000 (0.354)	loss 8.655 (7.975)	prob 2.970 (2.748)	GS 33.969 (32.445)	mem 79.478
Train: [15][740/1500]	BT 0.035 (0.412)	DT 0.001 (0.369)	loss 8.621 (7.982)	prob 2.608 (2.712)	GS 35.672 (32.651)	mem 77.242
Train: [15][750/1500]	BT 0.033 (0.407)	DT 0.000 (0.364)	loss 7.765 (7.956)	prob 2.507 (2.703)	GS 37.281 (32.639)	mem 77.548
Train: [15][760/1500]	BT 0.040 (0.403)	DT 0.001 (0.360)	loss 8.310 (8.202)	prob 3.187 (2.485)	GS 35.031 (33.247)	mem 77.722
Train: [15][770/1500]	BT 0.046 (0.405)	DT 0.003 (0.362)	loss 8.731 (8.125)	prob 2.993 (2.656)	GS 34.328 (32.691)	mem 79.495
Train: [15][780/1500]	BT 0.043 (0.400)	DT 0.001 (0.357)	loss 7.885 (8.064)	prob 4.018 (2.783)	GS 34.766 (32.805)	mem 79.500
Train: [15][790/1500]	BT 0.045 (0.402)	DT 0.001 (0.359)	loss 7.718 (8.053)	prob 3.771 (2.842)	GS 36.125 (32.552)	mem 95.261
Train: [15][800/1500]	BT 0.043 (0.397)	DT 0.001 (0.355)	loss 8.406 (8.101)	prob 3.265 (2.777)	GS 32.453 (32.555)	mem 97.406
Train: [15][810/1500]	BT 0.047 (0.393)	DT 0.001 (0.350)	loss 7.526 (7.839)	prob 2.163 (2.891)	GS 35.703 (33.089)	mem 99.163
Train: [15][820/1500]	BT 0.084 (0.398)	DT 0.028 (0.355)	loss 8.057 (8.011)	prob 2.183 (2.579)	GS 29.531 (32.614)	mem 113.643
Train: [15][830/1500]	BT 0.052 (0.394)	DT 0.001 (0.350)	loss 8.113 (7.981)	prob 3.332 (2.669)	GS 30.094 (32.833)	mem 113.653
Train: [15][840/1500]	BT 0.037 (0.401)	DT 0.000 (0.357)	loss 8.202 (8.018)	prob 3.160 (2.643)	GS 32.625 (32.653)	mem 77.186
Train: [15][850/1500]	BT 0.032 (0.396)	DT 0.000 (0.353)	loss 8.418 (8.053)	prob 3.207 (2.670)	GS 38.672 (32.796)	mem 77.190
Train: [15][860/1500]	BT 0.035 (0.412)	DT 0.001 (0.369)	loss 8.241 (8.038)	prob 3.295 (2.839)	GS 32.906 (32.783)	mem 76.446
Train: [15][870/1500]	BT 0.038 (0.407)	DT 0.001 (0.364)	loss 8.732 (8.097)	prob 1.892 (2.920)	GS 37.656 (32.957)	mem 76.453
Train: [15][880/1500]	BT 0.028 (0.410)	DT 0.000 (0.367)	loss 8.882 (8.131)	prob 1.901 (2.794)	GS 37.781 (33.041)	mem 76.561
Train: [15][890/1500]	BT 0.030 (0.406)	DT 0.000 (0.363)	loss 8.655 (8.139)	prob 3.636 (2.868)	GS 33.906 (33.018)	mem 76.568
Train: [15][900/1500]	BT 0.031 (0.402)	DT 0.001 (0.359)	loss 8.772 (8.156)	prob 3.073 (2.908)	GS 34.203 (32.623)	mem 76.578
Train: [15][910/1500]	BT 0.063 (0.404)	DT 0.013 (0.361)	loss 8.322 (8.193)	prob 4.137 (3.032)	GS 31.828 (32.097)	mem 76.638
Train: [15][920/1500]	BT 0.036 (0.400)	DT 0.000 (0.357)	loss 8.307 (8.107)	prob 4.125 (3.139)	GS 30.812 (31.692)	mem 76.641
Train: [15][930/1500]	BT 0.040 (0.404)	DT 0.001 (0.361)	loss 8.541 (8.101)	prob 3.594 (3.037)	GS 30.641 (31.867)	mem 78.178
Train: [15][940/1500]	BT 0.042 (0.400)	DT 0.001 (0.357)	loss 7.615 (8.082)	prob 3.868 (3.080)	GS 32.672 (31.823)	mem 78.382
Train: [15][950/1500]	BT 0.044 (0.404)	DT 0.001 (0.361)	loss 8.453 (8.085)	prob 3.114 (3.023)	GS 32.766 (32.159)	mem 80.985
Train: [15][960/1500]	BT 0.042 (0.400)	DT 0.001 (0.357)	loss 8.379 (8.236)	prob 3.376 (2.881)	GS 30.984 (31.669)	mem 80.986
Train: [15][970/1500]	BT 0.040 (0.397)	DT 0.001 (0.353)	loss 8.147 (8.082)	prob 3.613 (2.967)	GS 34.766 (32.435)	mem 81.812
Train: [15][980/1500]	BT 0.046 (0.398)	DT 0.001 (0.355)	loss 8.394 (8.129)	prob 3.027 (2.880)	GS 36.062 (32.418)	mem 103.435
Train: [15][990/1500]	BT 0.044 (0.395)	DT 0.001 (0.352)	loss 8.015 (8.114)	prob 4.133 (2.945)	GS 33.828 (32.383)	mem 105.522
Train: [15][1000/1500]	BT 0.032 (0.405)	DT 0.000 (0.362)	loss 8.408 (8.107)	prob 3.260 (2.932)	GS 30.891 (32.493)	mem 113.702
Train: [15][1010/1500]	BT 0.042 (0.401)	DT 0.001 (0.358)	loss 8.180 (8.150)	prob 3.325 (3.022)	GS 30.734 (31.758)	mem 113.713
Train: [15][1020/1500]	BT 0.042 (0.398)	DT 0.001 (0.355)	loss 8.356 (8.139)	prob 2.524 (2.965)	GS 33.734 (31.040)	mem 113.724
Train: [15][1030/1500]	BT 0.030 (0.402)	DT 0.000 (0.359)	loss 8.222 (8.157)	prob 2.806 (2.797)	GS 34.016 (31.629)	mem 85.146
Train: [15][1040/1500]	BT 0.034 (0.399)	DT 0.000 (0.356)	loss 7.861 (8.127)	prob 3.863 (2.824)	GS 32.312 (31.755)	mem 84.910
Train: [15][1050/1500]	BT 0.031 (0.403)	DT 0.000 (0.360)	loss 8.210 (8.111)	prob 3.598 (2.819)	GS 31.422 (31.965)	mem 76.434
Train: [15][1060/1500]	BT 0.030 (0.401)	DT 0.000 (0.359)	loss 8.368 (8.077)	prob 4.412 (3.133)	GS 33.500 (33.014)	mem 76.457
Train: [15][1070/1500]	BT 0.035 (0.400)	DT 0.001 (0.357)	loss 8.922 (8.155)	prob 3.052 (3.114)	GS 30.953 (32.617)	mem 76.494
Train: [15][1080/1500]	BT 0.031 (0.400)	DT 0.000 (0.357)	loss 7.760 (8.091)	prob 3.353 (3.042)	GS 31.406 (32.455)	mem 76.535
Train: [15][1090/1500]	BT 0.033 (0.396)	DT 0.001 (0.354)	loss 8.143 (8.149)	prob 4.520 (3.024)	GS 31.375 (32.389)	mem 76.540
Train: [15][1100/1500]	BT 0.037 (0.394)	DT 0.001 (0.351)	loss 8.502 (8.165)	prob 3.080 (3.077)	GS 34.984 (32.398)	mem 76.544
Train: [15][1110/1500]	BT 0.040 (0.395)	DT 0.001 (0.352)	loss 8.732 (8.394)	prob 2.869 (2.648)	GS 31.859 (34.083)	mem 76.569
Train: [15][1120/1500]	BT 0.039 (0.392)	DT 0.001 (0.350)	loss 7.980 (8.248)	prob 2.323 (2.600)	GS 34.000 (33.777)	mem 76.585
Train: [15][1130/1500]	BT 0.090 (0.393)	DT 0.035 (0.350)	loss 8.405 (8.236)	prob 4.384 (2.839)	GS 32.500 (32.982)	mem 76.674
Train: [15][1140/1500]	BT 0.053 (0.390)	DT 0.014 (0.347)	loss 8.704 (8.227)	prob 3.473 (2.921)	GS 31.734 (32.588)	mem 76.682
Train: [15][1150/1500]	BT 0.031 (0.390)	DT 0.000 (0.347)	loss 8.305 (8.202)	prob 3.575 (2.898)	GS 33.344 (32.536)	mem 76.781
Train: [15][1160/1500]	BT 0.039 (0.387)	DT 0.001 (0.344)	loss 8.389 (8.112)	prob 2.506 (2.733)	GS 33.297 (32.478)	mem 76.792
Train: [15][1170/1500]	BT 0.038 (0.384)	DT 0.001 (0.341)	loss 8.524 (8.175)	prob 2.594 (2.749)	GS 36.484 (32.980)	mem 76.799
Train: [15][1180/1500]	BT 0.081 (0.386)	DT 0.005 (0.344)	loss 7.957 (8.183)	prob 4.012 (2.818)	GS 31.500 (32.746)	mem 76.921
Train: [15][1190/1500]	BT 0.059 (0.384)	DT 0.002 (0.341)	loss 7.980 (8.166)	prob 3.254 (2.862)	GS 34.328 (32.782)	mem 76.959
Train: [15][1200/1500]	BT 0.032 (0.398)	DT 0.001 (0.355)	loss 7.868 (8.138)	prob 3.853 (2.887)	GS 33.562 (32.963)	mem 84.355
Train: [15][1210/1500]	BT 0.042 (0.395)	DT 0.001 (0.352)	loss 8.515 (8.184)	prob 1.923 (2.748)	GS 37.469 (33.520)	mem 86.316
Train: [15][1220/1500]	BT 0.056 (0.396)	DT 0.001 (0.354)	loss 8.224 (8.124)	prob 3.309 (2.947)	GS 36.078 (33.559)	mem 108.765
Train: [15][1230/1500]	BT 0.060 (0.393)	DT 0.015 (0.351)	loss 9.491 (8.178)	prob 2.686 (2.924)	GS 37.234 (33.519)	mem 109.397
Train: [15][1240/1500]	BT 0.048 (0.391)	DT 0.001 (0.348)	loss 8.800 (8.182)	prob 3.001 (3.000)	GS 39.500 (33.308)	mem 109.876
Train: [15][1250/1500]	BT 0.046 (0.394)	DT 0.014 (0.351)	loss 7.912 (8.194)	prob 2.689 (2.925)	GS 33.688 (33.538)	mem 113.107
Train: [15][1260/1500]	BT 0.101 (0.392)	DT 0.006 (0.349)	loss 8.054 (8.209)	prob 2.986 (2.830)	GS 33.312 (33.353)	mem 113.107
Train: [15][1270/1500]	BT 0.057 (0.396)	DT 0.001 (0.353)	loss 8.184 (8.247)	prob 3.900 (3.099)	GS 33.219 (32.632)	mem 113.137
Train: [15][1280/1500]	BT 0.080 (0.394)	DT 0.007 (0.350)	loss 7.887 (8.279)	prob 2.710 (3.068)	GS 30.328 (32.449)	mem 113.142
Train: [15][1290/1500]	BT 0.039 (0.400)	DT 0.000 (0.356)	loss 9.061 (8.284)	prob 2.449 (2.978)	GS 38.406 (33.025)	mem 113.234
Train: [15][1300/1500]	BT 0.041 (0.397)	DT 0.001 (0.353)	loss 7.765 (8.296)	prob 3.908 (2.928)	GS 30.031 (32.628)	mem 113.246
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [15][1310/1500]	BT 0.041 (0.398)	DT 0.001 (0.355)	loss 8.253 (8.090)	prob 4.288 (3.415)	GS 34.359 (32.289)	mem 112.769
Train: [15][1320/1500]	BT 0.045 (0.395)	DT 0.001 (0.352)	loss 7.781 (8.124)	prob 3.581 (3.340)	GS 32.859 (31.420)	mem 113.684
Train: [15][1330/1500]	BT 0.092 (0.396)	DT 0.023 (0.352)	loss 7.635 (8.101)	prob 3.416 (3.296)	GS 33.266 (31.592)	mem 76.736
Train: [15][1340/1500]	BT 0.094 (0.394)	DT 0.001 (0.350)	loss 7.576 (8.022)	prob 3.859 (3.284)	GS 28.062 (31.530)	mem 76.740
Train: [15][1350/1500]	BT 0.095 (0.391)	DT 0.000 (0.347)	loss 8.248 (8.061)	prob 4.191 (3.266)	GS 34.609 (31.662)	mem 76.746
Train: [15][1360/1500]	BT 0.038 (0.393)	DT 0.001 (0.349)	loss 8.106 (8.158)	prob 2.707 (2.653)	GS 34.312 (33.205)	mem 76.840
Train: [15][1370/1500]	BT 0.038 (0.391)	DT 0.001 (0.347)	loss 8.501 (8.210)	prob 3.410 (2.687)	GS 33.703 (32.373)	mem 76.853
Train: [15][1380/1500]	BT 0.067 (0.393)	DT 0.005 (0.349)	loss 8.877 (8.267)	prob 2.372 (2.638)	GS 32.234 (32.711)	mem 76.917
Train: [15][1390/1500]	BT 0.028 (0.395)	DT 0.000 (0.351)	loss 8.169 (8.267)	prob 2.829 (2.552)	GS 32.531 (33.321)	mem 77.080
Train: [15][1400/1500]	BT 0.027 (0.393)	DT 0.000 (0.349)	loss 8.566 (8.291)	prob 3.442 (2.626)	GS 37.062 (33.264)	mem 77.092
Train: [15][1410/1500]	BT 0.040 (0.390)	DT 0.001 (0.346)	loss 8.349 (8.226)	prob 3.416 (2.602)	GS 29.672 (32.377)	mem 77.092
Train: [15][1420/1500]	BT 0.029 (0.390)	DT 0.000 (0.347)	loss 8.549 (8.264)	prob 2.716 (2.407)	GS 38.297 (33.503)	mem 77.229
Train: [15][1430/1500]	BT 0.045 (0.388)	DT 0.001 (0.344)	loss 8.175 (8.256)	prob 3.617 (2.498)	GS 34.844 (33.272)	mem 77.237
Train: [15][1440/1500]	BT 0.040 (0.387)	DT 0.001 (0.344)	loss 8.711 (8.323)	prob 2.031 (2.525)	GS 36.562 (33.077)	mem 77.318
Train: [15][1450/1500]	BT 0.040 (0.385)	DT 0.001 (0.341)	loss 8.361 (8.283)	prob 2.847 (2.517)	GS 36.188 (32.970)	mem 77.324
Train: [15][1460/1500]	BT 0.038 (0.385)	DT 0.001 (0.341)	loss 8.165 (8.110)	prob 3.081 (2.860)	GS 31.656 (32.483)	mem 77.029
Train: [15][1470/1500]	BT 0.039 (0.382)	DT 0.001 (0.339)	loss 8.765 (8.259)	prob 3.229 (2.840)	GS 32.328 (32.548)	mem 77.036
Train: [15][1480/1500]	BT 0.031 (0.380)	DT 0.000 (0.337)	loss 8.068 (8.278)	prob 4.106 (2.748)	GS 32.328 (32.273)	mem 76.755
Train: [15][1490/1500]	BT 0.027 (0.379)	DT 0.000 (0.336)	loss 8.360 (8.299)	prob 2.710 (2.762)	GS 30.719 (32.125)	mem 17.128
Train: [15][1500/1500]	BT 0.031 (0.377)	DT 0.000 (0.334)	loss 8.264 (8.296)	prob 3.773 (2.813)	GS 35.500 (32.236)	mem 17.072
Train: [15][1510/1500]	BT 0.027 (0.375)	DT 0.000 (0.332)	loss 7.801 (8.169)	prob 4.018 (3.231)	GS 36.750 (32.369)	mem 11.470
epoch 15, total time 566.89
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [16][1/1500]	BT 18.182 (18.182)	DT 18.124 (18.124)	loss 8.439 (8.439)	prob 2.309 (2.309)	GS 36.547 (36.547)	mem 75.556
Train: [16][10/1500]	BT 0.041 (2.370)	DT 0.001 (2.330)	loss 8.189 (8.062)	prob 3.224 (3.079)	GS 28.859 (31.464)	mem 76.821
Train: [16][20/1500]	BT 0.068 (1.214)	DT 0.009 (1.167)	loss 8.070 (8.073)	prob 3.949 (2.979)	GS 33.203 (32.555)	mem 76.837
Train: [16][30/1500]	BT 0.059 (1.076)	DT 0.015 (1.027)	loss 7.834 (8.082)	prob 3.129 (2.932)	GS 35.156 (32.693)	mem 77.014
Train: [16][40/1500]	BT 0.040 (1.134)	DT 0.000 (1.088)	loss 8.367 (8.074)	prob 4.282 (3.000)	GS 31.766 (32.616)	mem 77.310
Train: [16][50/1500]	BT 0.027 (0.914)	DT 0.000 (0.871)	loss 8.053 (8.122)	prob 4.271 (3.022)	GS 30.281 (32.452)	mem 77.317
Train: [16][60/1500]	BT 4.301 (0.839)	DT 4.262 (0.797)	loss 7.961 (8.169)	prob 3.582 (2.847)	GS 33.500 (32.069)	mem 76.551
Train: [16][70/1500]	BT 0.026 (0.723)	DT 0.000 (0.683)	loss 8.037 (8.020)	prob 3.457 (3.131)	GS 34.703 (31.498)	mem 76.551
Train: [16][80/1500]	BT 0.040 (0.637)	DT 0.001 (0.598)	loss 8.125 (8.059)	prob 2.927 (3.060)	GS 34.016 (32.058)	mem 76.552
Train: [16][90/1500]	BT 0.045 (0.640)	DT 0.001 (0.600)	loss 8.784 (8.097)	prob 3.045 (2.988)	GS 32.562 (32.514)	mem 76.593
Train: [16][100/1500]	BT 0.031 (0.582)	DT 0.000 (0.541)	loss 8.608 (8.128)	prob 2.916 (2.961)	GS 32.031 (32.549)	mem 76.594
Train: [16][110/1500]	BT 0.041 (0.575)	DT 0.001 (0.535)	loss 9.163 (8.156)	prob 2.170 (2.899)	GS 36.344 (34.420)	mem 76.649
Train: [16][120/1500]	BT 0.042 (0.531)	DT 0.001 (0.490)	loss 8.275 (8.321)	prob 3.388 (2.917)	GS 32.625 (33.102)	mem 76.666
Train: [16][130/1500]	BT 0.028 (0.539)	DT 0.000 (0.499)	loss 8.513 (8.287)	prob 3.986 (2.977)	GS 35.281 (32.929)	mem 76.736
Train: [16][140/1500]	BT 0.030 (0.503)	DT 0.000 (0.463)	loss 8.629 (8.284)	prob 3.095 (2.975)	GS 36.062 (32.745)	mem 76.746
Train: [16][150/1500]	BT 0.041 (0.472)	DT 0.001 (0.433)	loss 8.358 (8.255)	prob 3.145 (2.964)	GS 38.938 (32.720)	mem 76.758
Train: [16][160/1500]	BT 0.028 (0.471)	DT 0.000 (0.433)	loss 8.117 (8.436)	prob 3.470 (2.740)	GS 34.844 (33.263)	mem 76.817
Train: [16][170/1500]	BT 0.039 (0.445)	DT 0.000 (0.407)	loss 7.928 (8.266)	prob 2.728 (2.789)	GS 31.812 (33.074)	mem 76.831
Train: [16][180/1500]	BT 0.037 (0.444)	DT 0.001 (0.405)	loss 7.861 (8.233)	prob 3.895 (2.804)	GS 35.156 (33.084)	mem 76.946
Train: [16][190/1500]	BT 0.052 (0.422)	DT 0.001 (0.384)	loss 8.651 (8.279)	prob 3.160 (2.774)	GS 33.672 (33.035)	mem 76.961
Train: [16][200/1500]	BT 0.029 (0.424)	DT 0.000 (0.386)	loss 7.999 (8.288)	prob 3.461 (2.722)	GS 36.031 (33.250)	mem 77.083
Train: [16][210/1500]	BT 0.038 (0.406)	DT 0.000 (0.368)	loss 8.289 (8.490)	prob 3.608 (2.777)	GS 34.922 (33.061)	mem 76.955
Train: [16][220/1500]	BT 0.041 (0.389)	DT 0.001 (0.351)	loss 8.293 (8.351)	prob 3.062 (2.609)	GS 35.031 (33.817)	mem 76.975
Train: [16][230/1500]	BT 0.038 (0.386)	DT 0.001 (0.348)	loss 8.449 (8.343)	prob 3.757 (2.686)	GS 34.922 (33.676)	mem 77.029
Train: [16][240/1500]	BT 0.038 (0.372)	DT 0.001 (0.334)	loss 8.792 (8.347)	prob 3.237 (2.700)	GS 35.344 (33.508)	mem 77.035
Train: [16][250/1500]	BT 0.037 (0.371)	DT 0.000 (0.333)	loss 8.807 (8.378)	prob 2.994 (2.676)	GS 34.703 (33.424)	mem 77.136
Train: [16][260/1500]	BT 0.032 (0.358)	DT 0.000 (0.320)	loss 8.552 (8.318)	prob 3.375 (2.550)	GS 34.906 (33.159)	mem 77.147
Train: [16][270/1500]	BT 0.034 (0.409)	DT 0.000 (0.371)	loss 7.910 (8.283)	prob 4.275 (2.732)	GS 28.906 (32.650)	mem 77.359
Train: [16][280/1500]	BT 0.031 (0.396)	DT 0.000 (0.358)	loss 8.530 (8.306)	prob 2.574 (2.608)	GS 33.406 (32.754)	mem 77.371
Train: [16][290/1500]	BT 0.037 (0.383)	DT 0.001 (0.346)	loss 8.631 (8.337)	prob 2.636 (2.586)	GS 35.828 (32.851)	mem 77.379
Train: [16][300/1500]	BT 0.038 (0.386)	DT 0.001 (0.348)	loss 8.827 (8.372)	prob 2.687 (2.509)	GS 32.016 (32.961)	mem 76.518
Train: [16][310/1500]	BT 0.039 (0.375)	DT 0.001 (0.337)	loss 8.171 (8.375)	prob 2.594 (2.555)	GS 34.906 (32.911)	mem 76.525
Train: [16][320/1500]	BT 0.042 (0.381)	DT 0.001 (0.343)	loss 7.809 (8.346)	prob 1.416 (2.382)	GS 32.422 (32.891)	mem 77.630
Train: [16][330/1500]	BT 0.043 (0.371)	DT 0.001 (0.333)	loss 9.954 (8.429)	prob 1.769 (2.364)	GS 33.922 (32.869)	mem 77.898
Train: [16][340/1500]	BT 5.447 (0.377)	DT 5.405 (0.339)	loss 8.942 (8.431)	prob 3.177 (2.455)	GS 35.844 (32.895)	mem 80.846
Train: [16][350/1500]	BT 0.045 (0.367)	DT 0.001 (0.329)	loss 8.289 (8.385)	prob 3.405 (2.539)	GS 36.859 (32.996)	mem 81.235
Train: [16][360/1500]	BT 0.047 (0.358)	DT 0.001 (0.320)	loss 9.757 (8.478)	prob 2.432 (2.304)	GS 32.906 (31.539)	mem 81.802
Train: [16][370/1500]	BT 0.045 (0.365)	DT 0.001 (0.327)	loss 8.710 (8.529)	prob 2.793 (2.442)	GS 35.500 (32.030)	mem 102.444
Train: [16][380/1500]	BT 0.045 (0.356)	DT 0.001 (0.318)	loss 8.645 (8.476)	prob 3.648 (2.576)	GS 34.156 (32.005)	mem 104.763
Train: [16][390/1500]	BT 0.037 (0.370)	DT 0.001 (0.331)	loss 9.082 (8.478)	prob 2.762 (2.515)	GS 34.812 (32.428)	mem 113.379
Train: [16][400/1500]	BT 0.087 (0.363)	DT 0.005 (0.323)	loss 8.385 (8.488)	prob 3.089 (2.579)	GS 34.094 (32.546)	mem 113.400
Train: [16][410/1500]	BT 0.035 (0.374)	DT 0.001 (0.335)	loss 8.794 (8.453)	prob 2.855 (2.896)	GS 32.938 (33.388)	mem 113.585
Train: [16][420/1500]	BT 0.038 (0.366)	DT 0.001 (0.327)	loss 8.401 (8.422)	prob 3.246 (2.857)	GS 34.062 (32.836)	mem 111.827
Train: [16][430/1500]	BT 0.039 (0.372)	DT 0.001 (0.332)	loss 8.091 (8.452)	prob 3.576 (2.812)	GS 33.344 (32.480)	mem 77.090
Train: [16][440/1500]	BT 0.040 (0.364)	DT 0.001 (0.324)	loss 9.690 (8.471)	prob 2.612 (2.881)	GS 42.672 (32.684)	mem 77.101
Train: [16][450/1500]	BT 0.039 (0.357)	DT 0.001 (0.317)	loss 8.851 (8.477)	prob 2.645 (2.829)	GS 33.328 (32.850)	mem 77.111
Train: [16][460/1500]	BT 0.351 (0.357)	DT 0.281 (0.317)	loss 8.491 (8.302)	prob 3.922 (3.404)	GS 31.672 (31.050)	mem 77.188
Train: [16][470/1500]	BT 0.066 (0.351)	DT 0.011 (0.311)	loss 8.428 (8.342)	prob 3.097 (3.359)	GS 31.312 (30.972)	mem 77.197
Train: [16][480/1500]	BT 0.090 (0.358)	DT 0.011 (0.317)	loss 7.739 (8.400)	prob 3.291 (3.250)	GS 33.703 (31.548)	mem 77.276
Train: [16][490/1500]	BT 0.039 (0.367)	DT 0.001 (0.326)	loss 8.894 (8.493)	prob 2.195 (3.011)	GS 35.781 (32.226)	mem 77.394
Train: [16][500/1500]	BT 0.041 (0.361)	DT 0.001 (0.320)	loss 9.263 (8.501)	prob 3.224 (2.958)	GS 34.516 (32.589)	mem 77.407
Train: [16][510/1500]	BT 0.077 (0.355)	DT 0.001 (0.314)	loss 8.840 (8.524)	prob 3.323 (2.762)	GS 35.516 (32.772)	mem 77.438
Train: [16][520/1500]	BT 0.036 (0.360)	DT 0.001 (0.318)	loss 9.088 (8.610)	prob 2.394 (2.577)	GS 31.344 (33.325)	mem 76.556
Train: [16][530/1500]	BT 0.032 (0.354)	DT 0.001 (0.313)	loss 8.381 (8.562)	prob 2.845 (2.741)	GS 31.500 (33.509)	mem 76.560
Train: [16][540/1500]	BT 0.036 (0.356)	DT 0.001 (0.315)	loss 8.363 (8.508)	prob 2.431 (2.816)	GS 33.875 (33.610)	mem 76.619
Train: [16][550/1500]	BT 0.038 (0.351)	DT 0.001 (0.310)	loss 9.394 (8.528)	prob 3.434 (2.837)	GS 32.875 (33.618)	mem 76.626
Train: [16][560/1500]	BT 0.038 (0.349)	DT 0.001 (0.308)	loss 8.072 (8.474)	prob 3.815 (3.007)	GS 30.625 (33.348)	mem 76.662
Train: [16][570/1500]	BT 0.038 (0.347)	DT 0.001 (0.306)	loss 8.881 (8.495)	prob 3.892 (3.281)	GS 30.594 (31.835)	mem 76.696
Train: [16][580/1500]	BT 0.038 (0.345)	DT 0.001 (0.304)	loss 8.532 (8.564)	prob 3.887 (3.228)	GS 34.047 (32.165)	mem 76.717
Train: [16][590/1500]	BT 0.030 (0.342)	DT 0.000 (0.301)	loss 8.191 (8.496)	prob 3.709 (3.127)	GS 33.062 (32.675)	mem 76.751
Train: [16][600/1500]	BT 0.075 (0.341)	DT 0.013 (0.300)	loss 9.249 (8.523)	prob 3.112 (3.195)	GS 37.547 (32.527)	mem 76.754
Train: [16][610/1500]	BT 0.051 (0.345)	DT 0.001 (0.304)	loss 8.403 (8.338)	prob 3.684 (3.383)	GS 32.156 (32.945)	mem 76.790
Train: [16][620/1500]	BT 0.028 (0.359)	DT 0.000 (0.318)	loss 9.106 (8.567)	prob 2.624 (3.175)	GS 33.281 (33.828)	mem 77.016
Train: [16][630/1500]	BT 0.027 (0.354)	DT 0.000 (0.313)	loss 8.706 (8.505)	prob 3.415 (3.265)	GS 32.266 (33.438)	mem 77.027
Train: [16][640/1500]	BT 0.038 (0.349)	DT 0.000 (0.308)	loss 8.826 (8.566)	prob 4.261 (3.258)	GS 34.672 (33.105)	mem 77.037
Train: [16][650/1500]	BT 0.038 (0.349)	DT 0.001 (0.308)	loss 9.317 (8.573)	prob 3.212 (3.269)	GS 35.156 (33.126)	mem 77.137
Train: [16][660/1500]	BT 0.038 (0.344)	DT 0.001 (0.303)	loss 8.066 (8.289)	prob 4.104 (3.542)	GS 34.531 (32.811)	mem 77.144
Train: [16][670/1500]	BT 0.029 (0.346)	DT 0.000 (0.305)	loss 8.594 (8.476)	prob 4.528 (3.410)	GS 32.547 (32.391)	mem 77.267
Train: [16][680/1500]	BT 0.041 (0.341)	DT 0.000 (0.301)	loss 8.450 (8.407)	prob 4.296 (3.455)	GS 33.875 (32.226)	mem 77.280
Train: [16][690/1500]	BT 0.028 (0.342)	DT 0.000 (0.301)	loss 8.576 (8.458)	prob 4.575 (3.389)	GS 28.219 (32.437)	mem 77.382
Train: [16][700/1500]	BT 0.039 (0.338)	DT 0.001 (0.297)	loss 8.480 (8.435)	prob 3.424 (3.425)	GS 32.047 (32.467)	mem 77.395
Train: [16][710/1500]	BT 0.038 (0.334)	DT 0.001 (0.293)	loss 8.671 (8.535)	prob 3.648 (3.261)	GS 31.688 (31.850)	mem 77.409
Train: [16][720/1500]	BT 0.038 (0.335)	DT 0.000 (0.294)	loss 8.265 (8.469)	prob 4.126 (3.214)	GS 31.547 (32.157)	mem 76.556
Train: [16][730/1500]	BT 0.039 (0.334)	DT 0.001 (0.294)	loss 8.407 (8.422)	prob 3.690 (3.249)	GS 36.953 (32.227)	mem 76.564
Train: [16][740/1500]	BT 0.041 (0.336)	DT 0.001 (0.295)	loss 7.783 (8.355)	prob 4.340 (3.266)	GS 33.891 (32.341)	mem 76.593
Train: [16][750/1500]	BT 0.041 (0.332)	DT 0.001 (0.292)	loss 8.322 (8.392)	prob 4.043 (3.269)	GS 34.656 (32.327)	mem 76.599
Train: [16][760/1500]	BT 0.039 (0.333)	DT 0.001 (0.293)	loss 8.178 (8.442)	prob 4.327 (3.152)	GS 29.922 (32.128)	mem 76.702
Train: [16][770/1500]	BT 0.040 (0.330)	DT 0.001 (0.289)	loss 9.788 (8.495)	prob 3.161 (3.185)	GS 35.000 (32.139)	mem 76.715
Train: [16][780/1500]	BT 0.064 (0.342)	DT 0.003 (0.301)	loss 8.296 (8.467)	prob 3.351 (3.199)	GS 32.953 (32.457)	mem 76.755
Train: [16][790/1500]	BT 0.034 (0.338)	DT 0.000 (0.297)	loss 8.802 (8.525)	prob 3.288 (3.131)	GS 34.312 (32.406)	mem 76.760
Train: [16][800/1500]	BT 0.072 (0.343)	DT 0.006 (0.302)	loss 8.178 (8.488)	prob 3.518 (3.163)	GS 31.234 (32.258)	mem 76.805
Train: [16][810/1500]	BT 0.036 (0.339)	DT 0.001 (0.298)	loss 8.265 (8.399)	prob 3.869 (2.990)	GS 29.562 (31.488)	mem 76.811
Train: [16][820/1500]	BT 0.030 (0.351)	DT 0.000 (0.310)	loss 8.668 (8.470)	prob 2.925 (2.943)	GS 27.609 (32.148)	mem 77.102
Train: [16][830/1500]	BT 0.036 (0.347)	DT 0.000 (0.307)	loss 9.693 (8.494)	prob 2.266 (2.941)	GS 32.703 (32.236)	mem 77.117
Train: [16][840/1500]	BT 0.033 (0.349)	DT 0.001 (0.308)	loss 9.810 (8.456)	prob 2.814 (2.962)	GS 33.734 (32.096)	mem 77.268
Train: [16][850/1500]	BT 0.041 (0.345)	DT 0.001 (0.305)	loss 9.283 (8.439)	prob 2.934 (2.981)	GS 35.688 (32.314)	mem 77.282
Train: [16][860/1500]	BT 0.038 (0.342)	DT 0.001 (0.301)	loss 9.172 (8.330)	prob 3.264 (3.054)	GS 35.688 (31.625)	mem 77.291
Train: [16][870/1500]	BT 0.064 (0.346)	DT 0.014 (0.306)	loss 9.643 (8.448)	prob 2.639 (2.759)	GS 39.266 (32.546)	mem 77.404
Train: [16][880/1500]	BT 0.032 (0.343)	DT 0.000 (0.302)	loss 8.920 (8.422)	prob 2.296 (2.753)	GS 34.125 (32.882)	mem 77.410
Train: [16][890/1500]	BT 0.039 (0.348)	DT 0.001 (0.307)	loss 9.246 (8.415)	prob 2.321 (2.805)	GS 36.453 (33.116)	mem 76.629
Train: [16][900/1500]	BT 0.039 (0.344)	DT 0.001 (0.304)	loss 8.019 (8.419)	prob 3.112 (2.676)	GS 35.766 (33.221)	mem 76.598
Train: [16][910/1500]	BT 0.037 (0.345)	DT 0.000 (0.305)	loss 8.553 (8.352)	prob 2.248 (2.701)	GS 32.312 (33.047)	mem 76.661
Train: [16][920/1500]	BT 0.039 (0.342)	DT 0.001 (0.301)	loss 9.493 (8.382)	prob 2.968 (2.554)	GS 32.438 (32.466)	mem 76.664
Train: [16][930/1500]	BT 0.040 (0.339)	DT 0.001 (0.298)	loss 8.345 (8.334)	prob 3.547 (2.793)	GS 33.484 (32.065)	mem 76.669
Train: [16][940/1500]	BT 0.038 (0.339)	DT 0.001 (0.299)	loss 8.694 (8.378)	prob 3.733 (2.818)	GS 32.969 (31.869)	mem 76.702
Train: [16][950/1500]	BT 0.033 (0.336)	DT 0.001 (0.295)	loss 8.195 (8.391)	prob 3.669 (2.805)	GS 36.125 (31.989)	mem 76.707
Train: [16][960/1500]	BT 1.675 (0.338)	DT 1.637 (0.298)	loss 8.710 (8.238)	prob 2.194 (2.727)	GS 31.344 (31.973)	mem 76.769
Train: [16][970/1500]	BT 0.040 (0.335)	DT 0.001 (0.295)	loss 9.061 (8.303)	prob 3.657 (2.728)	GS 30.453 (32.798)	mem 76.774
Train: [16][980/1500]	BT 0.041 (0.335)	DT 0.001 (0.294)	loss 8.301 (8.328)	prob 2.238 (2.764)	GS 33.812 (33.004)	mem 76.809
Train: [16][990/1500]	BT 0.041 (0.333)	DT 0.001 (0.293)	loss 8.993 (8.349)	prob 2.148 (2.678)	GS 33.500 (33.134)	mem 76.852
Train: [16][1000/1500]	BT 0.040 (0.330)	DT 0.001 (0.290)	loss 8.181 (8.374)	prob 3.804 (2.635)	GS 36.844 (33.200)	mem 76.865
Train: [16][1010/1500]	BT 0.039 (0.332)	DT 0.001 (0.292)	loss 8.702 (8.391)	prob 3.555 (2.724)	GS 37.703 (32.819)	mem 77.001
Train: [16][1020/1500]	BT 0.040 (0.329)	DT 0.001 (0.289)	loss 8.812 (8.441)	prob 2.495 (2.874)	GS 34.078 (32.165)	mem 77.013
Train: [16][1030/1500]	BT 0.031 (0.328)	DT 0.001 (0.288)	loss 8.025 (8.381)	prob 3.249 (3.029)	GS 34.422 (31.782)	mem 77.079
Train: [16][1040/1500]	BT 0.039 (0.328)	DT 0.001 (0.288)	loss 9.383 (8.394)	prob 2.555 (2.988)	GS 35.078 (31.905)	mem 77.192
Train: [16][1050/1500]	BT 0.031 (0.326)	DT 0.001 (0.285)	loss 9.050 (8.478)	prob 3.464 (2.941)	GS 34.891 (31.929)	mem 77.205
Train: [16][1060/1500]	BT 0.058 (0.326)	DT 0.001 (0.285)	loss 8.262 (8.318)	prob 3.341 (3.272)	GS 34.094 (31.550)	mem 77.290
Train: [16][1070/1500]	BT 0.073 (0.323)	DT 0.008 (0.282)	loss 8.315 (8.411)	prob 3.735 (3.118)	GS 33.031 (31.848)	mem 77.296
Train: [16][1080/1500]	BT 0.034 (0.331)	DT 0.000 (0.291)	loss 8.524 (8.437)	prob 4.914 (3.209)	GS 31.578 (32.308)	mem 77.513
Train: [16][1090/1500]	BT 0.028 (0.328)	DT 0.000 (0.288)	loss 8.859 (8.442)	prob 3.284 (3.174)	GS 32.578 (32.465)	mem 77.462
Train: [16][1100/1500]	BT 0.040 (0.328)	DT 0.001 (0.288)	loss 8.461 (8.460)	prob 3.976 (3.178)	GS 33.062 (32.572)	mem 76.615
Train: [16][1110/1500]	BT 0.040 (0.326)	DT 0.001 (0.285)	loss 8.809 (8.389)	prob 2.743 (2.995)	GS 32.609 (33.334)	mem 76.617
Train: [16][1120/1500]	BT 0.040 (0.323)	DT 0.001 (0.283)	loss 8.287 (8.350)	prob 2.688 (3.083)	GS 37.188 (32.760)	mem 76.619
Train: [16][1130/1500]	BT 0.039 (0.324)	DT 0.001 (0.283)	loss 9.806 (8.431)	prob 2.664 (3.041)	GS 34.516 (32.969)	mem 76.678
Train: [16][1140/1500]	BT 0.038 (0.321)	DT 0.001 (0.281)	loss 8.906 (8.468)	prob 3.729 (3.061)	GS 31.766 (32.637)	mem 76.681
Train: [16][1150/1500]	BT 0.100 (0.325)	DT 0.027 (0.285)	loss 8.036 (8.476)	prob 4.548 (3.101)	GS 34.547 (32.720)	mem 76.747
Train: [16][1160/1500]	BT 0.031 (0.323)	DT 0.001 (0.282)	loss 8.911 (8.394)	prob 3.762 (3.136)	GS 35.938 (33.922)	mem 76.752
Train: [16][1170/1500]	BT 0.080 (0.325)	DT 0.024 (0.285)	loss 8.665 (8.589)	prob 3.193 (3.129)	GS 36.344 (34.125)	mem 76.846
Train: [16][1180/1500]	BT 0.038 (0.323)	DT 0.001 (0.283)	loss 8.152 (8.506)	prob 3.783 (3.211)	GS 32.391 (33.454)	mem 76.850
Train: [16][1190/1500]	BT 0.028 (0.321)	DT 0.000 (0.280)	loss 8.390 (8.454)	prob 4.915 (3.313)	GS 29.328 (33.241)	mem 76.859
Train: [16][1200/1500]	BT 0.034 (0.321)	DT 0.000 (0.281)	loss 8.302 (8.452)	prob 3.142 (3.317)	GS 34.625 (33.333)	mem 76.836
Train: [16][1210/1500]	BT 0.028 (0.319)	DT 0.000 (0.279)	loss 7.954 (8.364)	prob 3.680 (3.362)	GS 30.719 (31.820)	mem 76.850
Train: [16][1220/1500]	BT 0.028 (0.320)	DT 0.000 (0.280)	loss 8.339 (8.393)	prob 2.701 (3.473)	GS 31.781 (32.545)	mem 76.980
Train: [16][1230/1500]	BT 0.038 (0.317)	DT 0.001 (0.277)	loss 9.236 (8.437)	prob 2.823 (3.318)	GS 38.328 (32.730)	mem 76.994
Train: [16][1240/1500]	BT 0.039 (0.315)	DT 0.001 (0.275)	loss 7.658 (8.401)	prob 4.776 (3.343)	GS 31.953 (32.614)	mem 77.006
Train: [16][1250/1500]	BT 0.066 (0.318)	DT 0.011 (0.277)	loss 8.304 (8.412)	prob 3.772 (3.412)	GS 33.141 (32.619)	mem 77.103
Train: [16][1260/1500]	BT 0.041 (0.318)	DT 0.001 (0.277)	loss 8.266 (8.412)	prob 4.056 (3.388)	GS 29.719 (32.730)	mem 77.113
Train: [16][1270/1500]	BT 0.039 (0.317)	DT 0.001 (0.277)	loss 8.262 (8.506)	prob 4.568 (3.362)	GS 29.922 (32.519)	mem 77.134
Train: [16][1280/1500]	BT 0.038 (0.317)	DT 0.001 (0.277)	loss 8.533 (8.504)	prob 3.964 (3.465)	GS 35.984 (32.541)	mem 77.222
Train: [16][1290/1500]	BT 0.039 (0.316)	DT 0.001 (0.276)	loss 9.347 (8.547)	prob 3.032 (3.398)	GS 36.141 (32.861)	mem 77.266
Train: [16][1300/1500]	BT 0.030 (0.315)	DT 0.000 (0.275)	loss 7.645 (8.518)	prob 4.680 (3.412)	GS 29.297 (32.652)	mem 77.297
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [16][1310/1500]	BT 0.030 (0.312)	DT 0.000 (0.272)	loss 8.157 (8.406)	prob 3.959 (3.544)	GS 32.125 (31.431)	mem 77.303
Train: [16][1320/1500]	BT 0.040 (0.313)	DT 0.001 (0.273)	loss 8.945 (8.444)	prob 3.585 (3.293)	GS 34.125 (31.946)	mem 77.380
Train: [16][1330/1500]	BT 0.030 (0.312)	DT 0.000 (0.272)	loss 8.770 (8.461)	prob 3.173 (3.338)	GS 34.250 (32.192)	mem 77.407
Train: [16][1340/1500]	BT 0.039 (0.312)	DT 0.001 (0.272)	loss 9.726 (8.466)	prob 3.642 (3.395)	GS 34.344 (32.208)	mem 76.555
Train: [16][1350/1500]	BT 0.054 (0.312)	DT 0.001 (0.272)	loss 8.617 (8.467)	prob 3.067 (3.279)	GS 32.969 (32.481)	mem 76.531
Train: [16][1360/1500]	BT 0.061 (0.310)	DT 0.001 (0.270)	loss 8.269 (8.154)	prob 3.264 (3.419)	GS 32.875 (31.758)	mem 76.539
Train: [16][1370/1500]	BT 0.028 (0.324)	DT 0.000 (0.284)	loss 8.447 (8.297)	prob 3.513 (3.171)	GS 31.406 (32.150)	mem 76.704
Train: [16][1380/1500]	BT 0.033 (0.322)	DT 0.000 (0.282)	loss 8.644 (8.280)	prob 3.625 (3.164)	GS 37.266 (32.537)	mem 76.710
Train: [16][1390/1500]	BT 7.524 (0.326)	DT 7.481 (0.286)	loss 8.866 (8.298)	prob 2.520 (3.049)	GS 35.047 (32.732)	mem 76.771
Train: [16][1400/1500]	BT 0.030 (0.323)	DT 0.001 (0.284)	loss 8.745 (8.309)	prob 3.626 (3.021)	GS 35.188 (32.598)	mem 76.780
Train: [16][1410/1500]	BT 0.027 (0.321)	DT 0.000 (0.282)	loss 7.952 (8.462)	prob 3.756 (3.096)	GS 28.375 (30.459)	mem 76.786
Train: [16][1420/1500]	BT 0.039 (0.323)	DT 0.001 (0.283)	loss 8.701 (8.305)	prob 2.853 (2.941)	GS 33.281 (32.094)	mem 76.920
Train: [16][1430/1500]	BT 0.075 (0.321)	DT 0.006 (0.281)	loss 7.712 (8.315)	prob 3.588 (2.830)	GS 32.547 (32.455)	mem 76.934
Train: [16][1440/1500]	BT 0.031 (0.326)	DT 0.000 (0.286)	loss 8.058 (8.344)	prob 2.055 (2.690)	GS 39.859 (32.953)	mem 77.006
Train: [16][1450/1500]	BT 0.032 (0.325)	DT 0.000 (0.285)	loss 9.267 (8.387)	prob 2.316 (2.594)	GS 34.141 (33.304)	mem 77.059
Train: [16][1460/1500]	BT 0.039 (0.323)	DT 0.001 (0.283)	loss 8.475 (8.445)	prob 2.334 (2.061)	GS 30.812 (32.281)	mem 77.031
Train: [16][1470/1500]	BT 0.028 (0.322)	DT 0.000 (0.282)	loss 8.489 (8.355)	prob 3.400 (2.260)	GS 34.547 (32.288)	mem 76.570
Train: [16][1480/1500]	BT 0.024 (0.321)	DT 0.000 (0.281)	loss 8.370 (8.324)	prob 2.802 (2.269)	GS 33.078 (32.203)	mem 23.402
Train: [16][1490/1500]	BT 0.028 (0.320)	DT 0.000 (0.280)	loss 8.063 (8.372)	prob 2.993 (2.296)	GS 35.500 (32.023)	mem 17.765
Train: [16][1500/1500]	BT 0.032 (0.318)	DT 0.000 (0.278)	loss 8.866 (8.360)	prob 2.142 (2.378)	GS 35.594 (32.147)	mem 17.743
Train: [16][1510/1500]	BT 0.770 (0.317)	DT 0.730 (0.277)	loss 8.765 (8.140)	prob 0.850 (2.338)	GS 38.250 (34.653)	mem 12.199
epoch 16, total time 478.45
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [17][1/1500]	BT 24.147 (24.147)	DT 24.087 (24.087)	loss 7.947 (7.947)	prob 1.893 (1.893)	GS 35.031 (35.031)	mem 75.872
Train: [17][10/1500]	BT 0.037 (2.449)	DT 0.001 (2.411)	loss 8.969 (8.003)	prob 2.716 (2.035)	GS 34.000 (33.153)	mem 75.946
Train: [17][20/1500]	BT 0.034 (1.241)	DT 0.000 (1.206)	loss 7.865 (8.041)	prob 3.259 (2.436)	GS 36.484 (32.491)	mem 76.033
Train: [17][30/1500]	BT 0.060 (0.966)	DT 0.010 (0.926)	loss 9.155 (8.040)	prob 2.633 (2.612)	GS 35.375 (32.420)	mem 76.507
Train: [17][40/1500]	BT 0.037 (0.824)	DT 0.000 (0.786)	loss 8.202 (8.068)	prob 2.338 (2.677)	GS 34.953 (32.455)	mem 76.681
Train: [17][50/1500]	BT 0.038 (0.674)	DT 0.000 (0.636)	loss 8.027 (8.068)	prob 3.542 (2.705)	GS 33.516 (32.238)	mem 76.709
Train: [17][60/1500]	BT 0.038 (0.613)	DT 0.001 (0.575)	loss 8.301 (8.120)	prob 2.926 (2.692)	GS 32.547 (32.080)	mem 76.782
Train: [17][70/1500]	BT 0.038 (0.530)	DT 0.001 (0.493)	loss 7.787 (8.156)	prob 4.008 (2.816)	GS 33.141 (32.256)	mem 76.795
Train: [17][80/1500]	BT 0.039 (0.537)	DT 0.001 (0.500)	loss 7.929 (8.199)	prob 3.334 (2.813)	GS 34.203 (32.109)	mem 76.963
Train: [17][90/1500]	BT 0.039 (0.482)	DT 0.001 (0.444)	loss 7.960 (8.264)	prob 3.419 (2.811)	GS 30.203 (32.351)	mem 76.974
Train: [17][100/1500]	BT 0.042 (0.439)	DT 0.001 (0.400)	loss 8.479 (8.265)	prob 2.996 (2.871)	GS 33.188 (32.448)	mem 76.984
Train: [17][110/1500]	BT 0.025 (0.462)	DT 0.000 (0.424)	loss 8.009 (8.142)	prob 3.893 (3.294)	GS 32.609 (31.962)	mem 77.131
Train: [17][120/1500]	BT 0.025 (0.426)	DT 0.000 (0.389)	loss 8.533 (8.131)	prob 2.721 (3.090)	GS 34.531 (32.341)	mem 77.139
Train: [17][130/1500]	BT 0.039 (0.421)	DT 0.001 (0.384)	loss 9.004 (8.187)	prob 2.286 (2.988)	GS 36.734 (32.538)	mem 77.228
Train: [17][140/1500]	BT 0.038 (0.393)	DT 0.001 (0.357)	loss 8.568 (8.254)	prob 2.476 (2.981)	GS 33.141 (32.568)	mem 77.235
Train: [17][150/1500]	BT 0.030 (0.372)	DT 0.000 (0.335)	loss 8.202 (8.247)	prob 3.843 (3.034)	GS 29.125 (32.542)	mem 77.250
Train: [17][160/1500]	BT 0.043 (0.367)	DT 0.001 (0.330)	loss 8.445 (8.434)	prob 2.489 (3.122)	GS 35.609 (33.373)	mem 77.341
Train: [17][170/1500]	BT 0.032 (0.360)	DT 0.000 (0.324)	loss 8.171 (8.343)	prob 3.707 (2.975)	GS 36.094 (33.342)	mem 76.485
Train: [17][180/1500]	BT 0.035 (0.436)	DT 0.001 (0.400)	loss 8.017 (8.337)	prob 3.437 (3.101)	GS 32.062 (33.528)	mem 76.654
Train: [17][190/1500]	BT 0.040 (0.415)	DT 0.000 (0.379)	loss 7.950 (8.300)	prob 3.630 (3.123)	GS 37.359 (33.329)	mem 76.663
Train: [17][200/1500]	BT 0.028 (0.415)	DT 0.000 (0.378)	loss 8.352 (8.314)	prob 4.018 (3.086)	GS 37.609 (33.274)	mem 76.737
Train: [17][210/1500]	BT 0.034 (0.396)	DT 0.001 (0.360)	loss 8.185 (8.267)	prob 3.627 (3.402)	GS 27.219 (32.828)	mem 76.743
Train: [17][220/1500]	BT 0.035 (0.380)	DT 0.000 (0.344)	loss 9.014 (8.295)	prob 3.120 (3.321)	GS 31.125 (32.967)	mem 76.749
Train: [17][230/1500]	BT 0.026 (0.385)	DT 0.000 (0.349)	loss 8.933 (8.257)	prob 2.735 (3.353)	GS 38.891 (33.161)	mem 76.915
Train: [17][240/1500]	BT 0.040 (0.370)	DT 0.000 (0.335)	loss 8.512 (8.244)	prob 3.069 (3.245)	GS 38.016 (33.173)	mem 76.931
Train: [17][250/1500]	BT 0.032 (0.376)	DT 0.000 (0.341)	loss 8.631 (8.264)	prob 3.724 (3.168)	GS 29.500 (33.002)	mem 77.090
Train: [17][260/1500]	BT 0.031 (0.363)	DT 0.000 (0.328)	loss 8.672 (8.273)	prob 3.296 (3.299)	GS 37.062 (33.481)	mem 77.096
Train: [17][270/1500]	BT 0.040 (0.351)	DT 0.001 (0.315)	loss 7.971 (8.295)	prob 3.299 (3.268)	GS 34.453 (32.600)	mem 77.105
Train: [17][280/1500]	BT 0.037 (0.355)	DT 0.000 (0.319)	loss 8.464 (8.301)	prob 3.451 (3.234)	GS 33.312 (32.206)	mem 77.202
Train: [17][290/1500]	BT 0.040 (0.344)	DT 0.001 (0.308)	loss 8.603 (8.291)	prob 2.432 (3.137)	GS 33.422 (32.705)	mem 77.213
Train: [17][300/1500]	BT 0.047 (0.349)	DT 0.012 (0.313)	loss 8.304 (8.272)	prob 2.238 (3.155)	GS 32.609 (32.477)	mem 77.354
Train: [17][310/1500]	BT 0.039 (0.339)	DT 0.001 (0.303)	loss 7.881 (8.315)	prob 3.800 (3.029)	GS 32.188 (33.475)	mem 77.368
Train: [17][320/1500]	BT 0.035 (0.342)	DT 0.001 (0.306)	loss 8.515 (8.347)	prob 3.861 (3.130)	GS 30.391 (32.681)	mem 77.443
Train: [17][330/1500]	BT 0.086 (0.334)	DT 0.009 (0.297)	loss 8.720 (8.316)	prob 3.154 (3.190)	GS 39.094 (32.621)	mem 77.454
Train: [17][340/1500]	BT 0.032 (0.326)	DT 0.001 (0.288)	loss 8.634 (8.338)	prob 2.782 (3.000)	GS 34.062 (32.977)	mem 76.553
Train: [17][350/1500]	BT 0.039 (0.335)	DT 0.001 (0.297)	loss 8.469 (8.369)	prob 2.523 (2.933)	GS 33.844 (32.961)	mem 76.534
Train: [17][360/1500]	BT 0.039 (0.327)	DT 0.001 (0.289)	loss 8.121 (8.351)	prob 4.313 (3.344)	GS 33.922 (32.747)	mem 76.538
Train: [17][370/1500]	BT 0.039 (0.328)	DT 0.001 (0.290)	loss 8.945 (8.239)	prob 3.073 (3.285)	GS 33.422 (32.413)	mem 76.585
Train: [17][380/1500]	BT 0.085 (0.326)	DT 0.026 (0.288)	loss 8.407 (8.268)	prob 2.868 (3.284)	GS 31.219 (32.149)	mem 76.602
Train: [17][390/1500]	BT 0.056 (0.337)	DT 0.006 (0.299)	loss 8.461 (8.294)	prob 3.883 (3.162)	GS 36.188 (32.491)	mem 76.646
Train: [17][400/1500]	BT 0.035 (0.330)	DT 0.000 (0.291)	loss 8.954 (8.281)	prob 2.627 (3.071)	GS 33.672 (32.739)	mem 76.650
Train: [17][410/1500]	BT 0.041 (0.333)	DT 0.001 (0.295)	loss 8.539 (8.629)	prob 3.191 (2.626)	GS 34.672 (34.617)	mem 76.683
Train: [17][420/1500]	BT 0.041 (0.328)	DT 0.001 (0.289)	loss 8.778 (8.457)	prob 3.489 (2.854)	GS 33.266 (33.122)	mem 76.712
Train: [17][430/1500]	BT 0.114 (0.339)	DT 0.037 (0.300)	loss 8.454 (8.436)	prob 1.716 (2.812)	GS 33.250 (33.155)	mem 76.792
Train: [17][440/1500]	BT 0.058 (0.348)	DT 0.011 (0.309)	loss 8.844 (8.381)	prob 3.167 (2.971)	GS 37.875 (33.248)	mem 76.864
Train: [17][450/1500]	BT 13.030 (0.370)	DT 12.994 (0.331)	loss 8.803 (8.354)	prob 2.848 (2.893)	GS 42.094 (33.340)	mem 77.049
Train: [17][460/1500]	BT 0.031 (0.363)	DT 0.000 (0.324)	loss 8.664 (8.300)	prob 2.317 (2.760)	GS 32.641 (32.900)	mem 77.063
Train: [17][470/1500]	BT 0.038 (0.356)	DT 0.001 (0.317)	loss 9.080 (8.360)	prob 2.983 (2.881)	GS 32.266 (32.495)	mem 77.073
Train: [17][480/1500]	BT 0.028 (0.359)	DT 0.000 (0.319)	loss 9.136 (8.324)	prob 3.243 (3.079)	GS 30.734 (32.047)	mem 77.191
Train: [17][490/1500]	BT 0.030 (0.352)	DT 0.000 (0.313)	loss 8.394 (8.312)	prob 4.205 (3.037)	GS 31.156 (32.099)	mem 77.210
Train: [17][500/1500]	BT 0.031 (0.355)	DT 0.000 (0.316)	loss 9.240 (8.315)	prob 2.949 (3.026)	GS 35.328 (32.065)	mem 77.317
Train: [17][510/1500]	BT 0.029 (0.349)	DT 0.000 (0.310)	loss 8.478 (8.416)	prob 3.669 (2.993)	GS 36.766 (31.567)	mem 77.327
Train: [17][520/1500]	BT 0.038 (0.343)	DT 0.001 (0.304)	loss 8.792 (8.414)	prob 3.227 (2.855)	GS 31.812 (32.315)	mem 77.338
Train: [17][530/1500]	BT 0.028 (0.345)	DT 0.000 (0.307)	loss 8.191 (8.384)	prob 3.603 (2.932)	GS 34.672 (32.646)	mem 76.756
Train: [17][540/1500]	BT 0.037 (0.339)	DT 0.001 (0.301)	loss 7.850 (8.405)	prob 3.928 (2.906)	GS 35.219 (32.551)	mem 76.576
Train: [17][550/1500]	BT 0.065 (0.343)	DT 0.001 (0.304)	loss 8.857 (8.426)	prob 2.815 (2.893)	GS 37.266 (32.431)	mem 76.634
Train: [17][560/1500]	BT 0.071 (0.338)	DT 0.001 (0.299)	loss 8.258 (8.137)	prob 3.611 (3.179)	GS 34.469 (32.388)	mem 76.636
Train: [17][570/1500]	BT 4.102 (0.340)	DT 4.062 (0.301)	loss 8.348 (8.178)	prob 2.883 (2.916)	GS 33.281 (32.984)	mem 76.707
Train: [17][580/1500]	BT 0.029 (0.345)	DT 0.000 (0.306)	loss 8.189 (8.257)	prob 2.655 (2.857)	GS 31.250 (33.339)	mem 76.759
Train: [17][590/1500]	BT 0.037 (0.340)	DT 0.000 (0.301)	loss 9.038 (8.280)	prob 2.184 (2.852)	GS 33.812 (33.732)	mem 76.765
Train: [17][600/1500]	BT 0.028 (0.336)	DT 0.000 (0.297)	loss 9.930 (8.350)	prob 2.170 (2.755)	GS 32.266 (33.588)	mem 76.642
Train: [17][610/1500]	BT 0.064 (0.338)	DT 0.004 (0.299)	loss 9.156 (8.547)	prob 2.597 (2.972)	GS 39.000 (34.234)	mem 76.685
Train: [17][620/1500]	BT 0.060 (0.336)	DT 0.005 (0.297)	loss 8.387 (8.493)	prob 3.154 (2.807)	GS 30.969 (32.970)	mem 76.704
Train: [17][630/1500]	BT 0.061 (0.338)	DT 0.002 (0.299)	loss 8.268 (8.365)	prob 3.272 (2.876)	GS 34.547 (32.783)	mem 76.762
Train: [17][640/1500]	BT 0.038 (0.351)	DT 0.000 (0.311)	loss 8.621 (8.382)	prob 3.570 (2.847)	GS 35.078 (33.204)	mem 76.915
Train: [17][650/1500]	BT 0.037 (0.351)	DT 0.000 (0.311)	loss 9.296 (8.401)	prob 3.211 (2.738)	GS 29.000 (33.236)	mem 76.918
Train: [17][660/1500]	BT 0.072 (0.347)	DT 0.016 (0.306)	loss 9.195 (8.565)	prob 3.284 (3.085)	GS 31.750 (31.384)	mem 76.925
Train: [17][670/1500]	BT 0.064 (0.350)	DT 0.000 (0.309)	loss 9.757 (8.509)	prob 2.500 (2.948)	GS 35.672 (32.345)	mem 77.006
Train: [17][680/1500]	BT 0.027 (0.363)	DT 0.000 (0.322)	loss 7.957 (8.412)	prob 3.953 (2.967)	GS 33.109 (32.337)	mem 77.280
Train: [17][690/1500]	BT 0.031 (0.358)	DT 0.000 (0.318)	loss 8.152 (8.391)	prob 3.046 (2.895)	GS 35.453 (32.351)	mem 77.290
Train: [17][700/1500]	BT 0.025 (0.354)	DT 0.000 (0.313)	loss 8.700 (8.381)	prob 3.616 (2.846)	GS 35.047 (32.277)	mem 77.299
Train: [17][710/1500]	BT 0.036 (0.355)	DT 0.000 (0.315)	loss 8.980 (8.593)	prob 2.949 (2.778)	GS 30.281 (31.869)	mem 76.475
Train: [17][720/1500]	BT 0.033 (0.351)	DT 0.000 (0.311)	loss 9.559 (8.498)	prob 2.424 (2.770)	GS 34.578 (31.264)	mem 76.478
Train: [17][730/1500]	BT 0.032 (0.353)	DT 0.000 (0.312)	loss 7.903 (8.438)	prob 3.552 (2.671)	GS 32.219 (31.889)	mem 76.503
Train: [17][740/1500]	BT 0.053 (0.348)	DT 0.001 (0.308)	loss 9.937 (8.401)	prob 1.838 (2.686)	GS 43.469 (32.050)	mem 76.507
Train: [17][750/1500]	BT 0.028 (0.350)	DT 0.000 (0.310)	loss 8.579 (8.374)	prob 3.230 (2.616)	GS 31.781 (32.073)	mem 76.550
Train: [17][760/1500]	BT 0.037 (0.346)	DT 0.001 (0.306)	loss 8.223 (8.489)	prob 2.632 (2.147)	GS 29.141 (33.300)	mem 76.558
Train: [17][770/1500]	BT 0.039 (0.342)	DT 0.001 (0.302)	loss 8.554 (8.462)	prob 2.600 (2.149)	GS 28.516 (32.959)	mem 76.562
Train: [17][780/1500]	BT 0.030 (0.349)	DT 0.000 (0.309)	loss 9.367 (8.450)	prob 2.441 (2.281)	GS 34.266 (32.746)	mem 76.654
Train: [17][790/1500]	BT 0.042 (0.345)	DT 0.001 (0.305)	loss 8.784 (8.478)	prob 2.385 (2.224)	GS 34.578 (32.806)	mem 76.658
Train: [17][800/1500]	BT 0.030 (0.344)	DT 0.000 (0.305)	loss 9.059 (8.447)	prob 2.975 (2.228)	GS 37.234 (32.912)	mem 76.741
Train: [17][810/1500]	BT 0.040 (0.340)	DT 0.001 (0.301)	loss 8.745 (8.121)	prob 2.217 (2.819)	GS 34.312 (31.358)	mem 76.757
Train: [17][820/1500]	BT 0.039 (0.337)	DT 0.001 (0.297)	loss 7.810 (8.208)	prob 2.990 (2.738)	GS 31.391 (31.631)	mem 76.792
Train: [17][830/1500]	BT 0.028 (0.339)	DT 0.000 (0.299)	loss 8.149 (8.255)	prob 2.251 (2.649)	GS 34.750 (31.986)	mem 76.923
Train: [17][840/1500]	BT 0.038 (0.335)	DT 0.000 (0.296)	loss 8.663 (8.264)	prob 1.929 (2.568)	GS 29.766 (31.580)	mem 76.936
Train: [17][850/1500]	BT 0.040 (0.339)	DT 0.009 (0.299)	loss 8.955 (8.259)	prob 1.703 (2.528)	GS 33.750 (31.694)	mem 77.069
Train: [17][860/1500]	BT 0.069 (0.335)	DT 0.005 (0.296)	loss 9.000 (8.604)	prob 2.627 (1.848)	GS 33.859 (32.823)	mem 77.075
Train: [17][870/1500]	BT 0.076 (0.339)	DT 0.001 (0.299)	loss 8.641 (8.487)	prob 2.937 (1.980)	GS 33.766 (33.364)	mem 77.186
Train: [17][880/1500]	BT 0.062 (0.336)	DT 0.001 (0.296)	loss 9.018 (8.450)	prob 1.682 (2.033)	GS 37.062 (33.704)	mem 77.199
Train: [17][890/1500]	BT 5.171 (0.338)	DT 5.118 (0.298)	loss 8.833 (8.442)	prob 2.487 (2.063)	GS 38.656 (33.968)	mem 77.287
Train: [17][900/1500]	BT 0.057 (0.336)	DT 0.006 (0.296)	loss 8.227 (8.424)	prob 3.524 (2.078)	GS 32.156 (33.746)	mem 77.320
Train: [17][910/1500]	BT 0.066 (0.333)	DT 0.013 (0.293)	loss 9.061 (8.347)	prob 2.822 (2.820)	GS 30.516 (32.056)	mem 77.330
Train: [17][920/1500]	BT 0.037 (0.336)	DT 0.000 (0.296)	loss 8.484 (8.366)	prob 4.029 (2.778)	GS 33.109 (31.658)	mem 77.424
Train: [17][930/1500]	BT 0.038 (0.332)	DT 0.000 (0.293)	loss 8.460 (8.420)	prob 2.759 (2.657)	GS 40.125 (32.241)	mem 77.432
Train: [17][940/1500]	BT 0.028 (0.332)	DT 0.000 (0.293)	loss 9.326 (8.434)	prob 2.703 (2.609)	GS 32.969 (32.245)	mem 76.544
Train: [17][950/1500]	BT 0.038 (0.331)	DT 0.001 (0.291)	loss 7.937 (8.385)	prob 4.114 (2.597)	GS 34.531 (32.380)	mem 76.568
Train: [17][960/1500]	BT 0.057 (0.328)	DT 0.004 (0.288)	loss 8.250 (8.510)	prob 3.365 (2.781)	GS 36.438 (34.239)	mem 76.576
Train: [17][970/1500]	BT 0.028 (0.332)	DT 0.000 (0.292)	loss 8.625 (8.435)	prob 2.500 (2.739)	GS 34.578 (34.134)	mem 76.656
Train: [17][980/1500]	BT 0.029 (0.329)	DT 0.000 (0.289)	loss 8.320 (8.381)	prob 3.273 (2.814)	GS 34.203 (33.586)	mem 76.659
Train: [17][990/1500]	BT 0.028 (0.331)	DT 0.000 (0.292)	loss 8.415 (8.339)	prob 2.874 (2.904)	GS 35.891 (33.250)	mem 76.694
Train: [17][1000/1500]	BT 0.028 (0.328)	DT 0.000 (0.289)	loss 8.594 (8.288)	prob 3.514 (2.904)	GS 35.297 (33.344)	mem 76.699
Train: [17][1010/1500]	BT 0.048 (0.325)	DT 0.000 (0.286)	loss 8.894 (8.230)	prob 2.464 (3.025)	GS 32.734 (32.617)	mem 76.703
Train: [17][1020/1500]	BT 0.059 (0.326)	DT 0.016 (0.286)	loss 8.450 (8.231)	prob 4.268 (3.206)	GS 34.531 (31.864)	mem 76.738
Train: [17][1030/1500]	BT 0.029 (0.323)	DT 0.000 (0.283)	loss 9.318 (8.269)	prob 3.283 (3.259)	GS 32.688 (32.005)	mem 76.746
Train: [17][1040/1500]	BT 0.038 (0.323)	DT 0.001 (0.283)	loss 8.919 (8.333)	prob 3.289 (3.235)	GS 32.234 (32.520)	mem 76.809
Train: [17][1050/1500]	BT 0.038 (0.321)	DT 0.001 (0.281)	loss 8.060 (8.281)	prob 4.019 (3.230)	GS 33.172 (32.552)	mem 76.828
Train: [17][1060/1500]	BT 0.038 (0.319)	DT 0.001 (0.279)	loss 7.605 (8.148)	prob 4.230 (3.036)	GS 32.594 (33.916)	mem 76.868
Train: [17][1070/1500]	BT 0.039 (0.320)	DT 0.001 (0.281)	loss 7.953 (8.064)	prob 3.386 (3.314)	GS 35.328 (32.862)	mem 77.017
Train: [17][1080/1500]	BT 0.040 (0.318)	DT 0.001 (0.278)	loss 8.478 (8.165)	prob 2.912 (3.233)	GS 34.953 (33.051)	mem 77.034
Train: [17][1090/1500]	BT 0.090 (0.321)	DT 0.003 (0.281)	loss 7.658 (8.161)	prob 5.014 (3.319)	GS 28.422 (32.619)	mem 77.169
Train: [17][1100/1500]	BT 0.050 (0.318)	DT 0.000 (0.278)	loss 8.046 (8.135)	prob 4.180 (3.460)	GS 34.312 (32.389)	mem 77.177
Train: [17][1110/1500]	BT 0.022 (0.325)	DT 0.000 (0.285)	loss 8.547 (8.302)	prob 3.367 (3.365)	GS 33.391 (33.119)	mem 77.359
Train: [17][1120/1500]	BT 0.036 (0.322)	DT 0.000 (0.282)	loss 8.226 (8.302)	prob 3.549 (3.289)	GS 32.234 (33.688)	mem 77.371
Train: [17][1130/1500]	BT 0.032 (0.323)	DT 0.001 (0.283)	loss 8.739 (8.241)	prob 4.107 (3.497)	GS 34.109 (33.798)	mem 76.559
Train: [17][1140/1500]	BT 0.039 (0.321)	DT 0.001 (0.281)	loss 8.672 (8.267)	prob 4.443 (3.510)	GS 32.375 (33.286)	mem 76.564
Train: [17][1150/1500]	BT 0.038 (0.326)	DT 0.000 (0.286)	loss 8.839 (8.273)	prob 3.861 (3.578)	GS 31.281 (33.086)	mem 76.624
Train: [17][1160/1500]	BT 0.037 (0.323)	DT 0.001 (0.284)	loss 8.097 (8.199)	prob 3.643 (3.833)	GS 32.938 (32.286)	mem 76.632
Train: [17][1170/1500]	BT 0.067 (0.321)	DT 0.005 (0.281)	loss 9.151 (8.241)	prob 3.307 (3.719)	GS 35.531 (32.543)	mem 76.639
Train: [17][1180/1500]	BT 0.039 (0.322)	DT 0.001 (0.282)	loss 7.898 (8.274)	prob 4.873 (3.697)	GS 36.203 (32.923)	mem 76.714
Train: [17][1190/1500]	BT 0.039 (0.320)	DT 0.001 (0.280)	loss 7.702 (8.261)	prob 3.784 (3.636)	GS 32.328 (33.180)	mem 76.721
Train: [17][1200/1500]	BT 0.062 (0.321)	DT 0.001 (0.281)	loss 7.960 (8.202)	prob 4.209 (3.670)	GS 33.453 (33.376)	mem 76.771
Train: [17][1210/1500]	BT 0.057 (0.319)	DT 0.006 (0.279)	loss 8.230 (8.257)	prob 4.533 (3.424)	GS 34.781 (34.892)	mem 76.776
Train: [17][1220/1500]	BT 0.068 (0.317)	DT 0.006 (0.277)	loss 8.669 (8.197)	prob 4.120 (3.742)	GS 35.047 (33.797)	mem 76.781
Train: [17][1230/1500]	BT 0.027 (0.323)	DT 0.000 (0.283)	loss 8.462 (8.187)	prob 3.571 (3.916)	GS 34.672 (33.862)	mem 76.897
Train: [17][1240/1500]	BT 0.040 (0.321)	DT 0.001 (0.281)	loss 8.363 (8.206)	prob 4.151 (3.885)	GS 35.578 (33.545)	mem 76.912
Train: [17][1250/1500]	BT 0.083 (0.324)	DT 0.014 (0.283)	loss 8.962 (8.266)	prob 3.067 (3.787)	GS 35.984 (33.626)	mem 77.021
Train: [17][1260/1500]	BT 0.057 (0.322)	DT 0.006 (0.281)	loss 7.787 (8.212)	prob 3.883 (4.143)	GS 33.719 (33.461)	mem 77.033
Train: [17][1270/1500]	BT 0.086 (0.322)	DT 0.017 (0.281)	loss 8.194 (8.209)	prob 3.784 (3.961)	GS 32.844 (33.396)	mem 77.104
Train: [17][1280/1500]	BT 0.066 (0.322)	DT 0.005 (0.281)	loss 8.683 (8.191)	prob 3.710 (3.824)	GS 36.484 (33.290)	mem 77.152
Train: [17][1290/1500]	BT 0.024 (0.336)	DT 0.000 (0.295)	loss 8.342 (8.205)	prob 3.848 (3.731)	GS 31.172 (33.112)	mem 76.563
Train: [17][1300/1500]	BT 0.031 (0.334)	DT 0.001 (0.293)	loss 8.356 (8.218)	prob 3.647 (3.651)	GS 36.234 (32.932)	mem 76.564
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [17][1310/1500]	BT 3.015 (0.333)	DT 2.976 (0.293)	loss 9.098 (8.312)	prob 2.894 (3.202)	GS 33.328 (32.616)	mem 76.590
Train: [17][1320/1500]	BT 0.040 (0.331)	DT 0.001 (0.291)	loss 8.178 (8.382)	prob 3.705 (3.007)	GS 33.656 (32.884)	mem 76.595
Train: [17][1330/1500]	BT 0.041 (0.329)	DT 0.001 (0.289)	loss 8.949 (8.353)	prob 3.331 (3.063)	GS 37.391 (32.768)	mem 76.601
Train: [17][1340/1500]	BT 0.040 (0.331)	DT 0.001 (0.291)	loss 8.073 (8.282)	prob 2.669 (3.044)	GS 33.844 (33.070)	mem 76.639
Train: [17][1350/1500]	BT 0.040 (0.329)	DT 0.001 (0.289)	loss 7.759 (8.255)	prob 3.063 (3.077)	GS 32.266 (32.782)	mem 76.644
Train: [17][1360/1500]	BT 0.030 (0.329)	DT 0.000 (0.289)	loss 8.121 (8.133)	prob 3.116 (3.344)	GS 38.828 (33.245)	mem 76.680
Train: [17][1370/1500]	BT 0.040 (0.327)	DT 0.001 (0.287)	loss 8.591 (8.115)	prob 3.763 (3.125)	GS 34.219 (32.976)	mem 76.686
Train: [17][1380/1500]	BT 0.040 (0.325)	DT 0.001 (0.285)	loss 8.238 (8.185)	prob 3.523 (2.952)	GS 29.531 (32.520)	mem 76.692
Train: [17][1390/1500]	BT 0.041 (0.327)	DT 0.001 (0.286)	loss 8.357 (8.192)	prob 3.328 (2.889)	GS 33.734 (32.192)	mem 76.770
Train: [17][1400/1500]	BT 0.040 (0.324)	DT 0.001 (0.284)	loss 7.834 (8.195)	prob 2.798 (2.885)	GS 34.328 (32.012)	mem 76.755
Train: [17][1410/1500]	BT 0.065 (0.325)	DT 0.015 (0.285)	loss 7.811 (8.081)	prob 3.090 (2.545)	GS 34.969 (32.555)	mem 76.798
Train: [17][1420/1500]	BT 0.060 (0.323)	DT 0.012 (0.283)	loss 8.691 (8.111)	prob 2.466 (2.577)	GS 34.375 (32.166)	mem 76.805
Train: [17][1430/1500]	BT 0.031 (0.332)	DT 0.001 (0.292)	loss 8.245 (8.082)	prob 3.069 (2.683)	GS 33.453 (32.681)	mem 76.952
Train: [17][1440/1500]	BT 0.030 (0.334)	DT 0.000 (0.293)	loss 8.554 (8.148)	prob 2.530 (2.588)	GS 32.969 (32.701)	mem 77.079
Train: [17][1450/1500]	BT 0.040 (0.332)	DT 0.001 (0.291)	loss 9.546 (8.199)	prob 2.184 (2.537)	GS 32.672 (32.757)	mem 77.090
Train: [17][1460/1500]	BT 0.104 (0.334)	DT 0.009 (0.293)	loss 8.605 (8.513)	prob 2.143 (2.381)	GS 33.922 (32.950)	mem 76.195
Train: [17][1470/1500]	BT 0.050 (0.332)	DT 0.014 (0.292)	loss 7.943 (8.335)	prob 2.846 (2.532)	GS 32.172 (32.523)	mem 76.201
Train: [17][1480/1500]	BT 0.037 (0.330)	DT 0.000 (0.290)	loss 8.414 (8.424)	prob 3.329 (2.445)	GS 32.812 (32.689)	mem 76.208
Train: [17][1490/1500]	BT 0.027 (0.330)	DT 0.001 (0.290)	loss 7.602 (8.394)	prob 3.853 (2.514)	GS 31.719 (32.668)	mem 12.291
Train: [17][1500/1500]	BT 0.025 (0.328)	DT 0.000 (0.288)	loss 8.477 (8.404)	prob 3.907 (2.559)	GS 31.938 (32.855)	mem 12.299
Train: [17][1510/1500]	BT 0.025 (0.327)	DT 0.000 (0.286)	loss 8.512 (8.409)	prob 3.529 (3.104)	GS 31.875 (32.300)	mem 12.269
epoch 17, total time 493.47
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [18][1/1500]	BT 21.530 (21.530)	DT 21.477 (21.477)	loss 8.329 (8.329)	prob 1.748 (1.748)	GS 33.750 (33.750)	mem 76.497
Train: [18][10/1500]	BT 0.040 (2.330)	DT 0.001 (2.290)	loss 7.605 (8.103)	prob 4.501 (3.316)	GS 33.812 (32.035)	mem 76.539
Train: [18][20/1500]	BT 0.037 (1.185)	DT 0.000 (1.146)	loss 8.460 (8.207)	prob 3.134 (3.148)	GS 34.000 (32.803)	mem 76.547
Train: [18][30/1500]	BT 0.038 (0.891)	DT 0.000 (0.853)	loss 9.253 (8.200)	prob 2.411 (3.216)	GS 34.234 (32.517)	mem 76.622
Train: [18][40/1500]	BT 0.060 (0.764)	DT 0.001 (0.722)	loss 8.166 (8.171)	prob 3.943 (3.320)	GS 34.328 (32.192)	mem 76.700
Train: [18][50/1500]	BT 0.083 (0.689)	DT 0.009 (0.644)	loss 8.181 (8.175)	prob 3.949 (3.367)	GS 30.109 (32.035)	mem 76.752
Train: [18][60/1500]	BT 0.081 (0.641)	DT 0.018 (0.593)	loss 8.809 (8.412)	prob 2.902 (2.998)	GS 32.781 (32.641)	mem 76.787
Train: [18][70/1500]	BT 0.041 (0.598)	DT 0.001 (0.551)	loss 8.357 (8.273)	prob 4.198 (3.130)	GS 33.031 (33.073)	mem 76.880
Train: [18][80/1500]	BT 0.039 (0.560)	DT 0.000 (0.514)	loss 8.305 (8.262)	prob 4.745 (3.266)	GS 38.141 (32.455)	mem 76.950
Train: [18][90/1500]	BT 0.039 (0.509)	DT 0.000 (0.463)	loss 8.801 (8.245)	prob 4.007 (3.331)	GS 34.562 (32.565)	mem 76.973
Train: [18][100/1500]	BT 0.039 (0.467)	DT 0.001 (0.423)	loss 7.857 (8.240)	prob 4.297 (3.356)	GS 34.156 (32.789)	mem 76.990
Train: [18][110/1500]	BT 0.039 (0.464)	DT 0.001 (0.420)	loss 8.839 (8.522)	prob 3.882 (3.773)	GS 33.750 (30.777)	mem 77.086
Train: [18][120/1500]	BT 0.039 (0.429)	DT 0.001 (0.385)	loss 8.289 (8.415)	prob 5.158 (3.833)	GS 30.453 (31.466)	mem 77.093
Train: [18][130/1500]	BT 0.039 (0.433)	DT 0.001 (0.389)	loss 9.300 (8.341)	prob 3.095 (3.766)	GS 36.922 (32.133)	mem 77.201
Train: [18][140/1500]	BT 0.039 (0.404)	DT 0.001 (0.362)	loss 8.570 (8.297)	prob 3.386 (3.744)	GS 37.469 (32.359)	mem 77.214
Train: [18][150/1500]	BT 0.040 (0.383)	DT 0.001 (0.340)	loss 8.397 (8.279)	prob 4.013 (3.742)	GS 33.094 (32.167)	mem 77.240
Train: [18][160/1500]	BT 0.031 (0.387)	DT 0.000 (0.345)	loss 8.457 (8.434)	prob 3.260 (3.326)	GS 36.531 (33.794)	mem 77.376
Train: [18][170/1500]	BT 0.035 (0.366)	DT 0.001 (0.325)	loss 8.475 (8.322)	prob 3.770 (3.636)	GS 37.875 (33.270)	mem 77.390
Train: [18][180/1500]	BT 0.065 (0.379)	DT 0.015 (0.338)	loss 8.365 (8.335)	prob 4.308 (3.711)	GS 35.453 (33.404)	mem 76.510
Train: [18][190/1500]	BT 0.040 (0.361)	DT 0.001 (0.320)	loss 8.777 (8.286)	prob 3.857 (3.717)	GS 30.078 (33.179)	mem 76.518
Train: [18][200/1500]	BT 0.034 (0.367)	DT 0.000 (0.326)	loss 7.812 (8.259)	prob 4.271 (3.721)	GS 32.188 (33.253)	mem 76.606
Train: [18][210/1500]	BT 0.036 (0.351)	DT 0.001 (0.310)	loss 8.385 (8.308)	prob 3.272 (3.769)	GS 31.375 (33.436)	mem 76.611
Train: [18][220/1500]	BT 0.038 (0.336)	DT 0.001 (0.296)	loss 8.278 (8.297)	prob 4.083 (3.955)	GS 31.219 (33.067)	mem 76.618
Train: [18][230/1500]	BT 0.061 (0.346)	DT 0.011 (0.305)	loss 8.448 (8.262)	prob 4.445 (3.923)	GS 32.953 (33.087)	mem 76.705
Train: [18][240/1500]	BT 0.035 (0.333)	DT 0.001 (0.292)	loss 7.698 (8.213)	prob 3.583 (3.856)	GS 36.531 (33.188)	mem 76.708
Train: [18][250/1500]	BT 0.056 (0.347)	DT 0.002 (0.307)	loss 8.257 (8.173)	prob 4.236 (3.881)	GS 36.109 (33.137)	mem 76.791
Train: [18][260/1500]	BT 0.081 (0.336)	DT 0.009 (0.295)	loss 8.262 (8.218)	prob 4.512 (3.555)	GS 32.094 (33.859)	mem 76.800
Train: [18][270/1500]	BT 0.088 (0.326)	DT 0.008 (0.284)	loss 7.974 (8.083)	prob 3.948 (3.861)	GS 34.969 (33.603)	mem 76.809
Train: [18][280/1500]	BT 0.021 (0.378)	DT 0.000 (0.336)	loss 8.323 (8.088)	prob 3.717 (3.907)	GS 32.766 (33.355)	mem 77.069
Train: [18][290/1500]	BT 0.029 (0.366)	DT 0.000 (0.325)	loss 9.288 (8.113)	prob 3.489 (3.926)	GS 34.375 (33.430)	mem 77.081
Train: [18][300/1500]	BT 0.036 (0.367)	DT 0.001 (0.326)	loss 8.433 (8.114)	prob 3.884 (3.838)	GS 34.781 (33.215)	mem 77.162
Train: [18][310/1500]	BT 0.037 (0.357)	DT 0.000 (0.315)	loss 8.232 (7.981)	prob 4.006 (4.101)	GS 32.938 (31.773)	mem 77.171
Train: [18][320/1500]	BT 0.071 (0.349)	DT 0.001 (0.308)	loss 8.529 (8.003)	prob 3.682 (4.042)	GS 32.734 (32.302)	mem 77.193
Train: [18][330/1500]	BT 0.030 (0.362)	DT 0.000 (0.321)	loss 8.376 (8.004)	prob 4.505 (3.983)	GS 33.844 (32.752)	mem 77.379
Train: [18][340/1500]	BT 0.028 (0.352)	DT 0.000 (0.311)	loss 8.100 (8.021)	prob 3.668 (3.889)	GS 30.250 (32.674)	mem 77.393
Train: [18][350/1500]	BT 0.038 (0.354)	DT 0.001 (0.314)	loss 8.026 (8.028)	prob 3.224 (3.874)	GS 35.750 (32.877)	mem 76.588
Train: [18][360/1500]	BT 0.037 (0.345)	DT 0.000 (0.305)	loss 8.020 (8.021)	prob 3.306 (3.326)	GS 36.656 (33.823)	mem 76.590
Train: [18][370/1500]	BT 0.036 (0.351)	DT 0.000 (0.311)	loss 7.848 (8.026)	prob 4.491 (3.474)	GS 33.547 (33.212)	mem 76.643
Train: [18][380/1500]	BT 0.060 (0.344)	DT 0.013 (0.303)	loss 7.880 (7.995)	prob 4.540 (3.602)	GS 31.219 (33.064)	mem 76.651
Train: [18][390/1500]	BT 0.036 (0.336)	DT 0.001 (0.296)	loss 8.690 (7.989)	prob 4.001 (3.686)	GS 34.641 (32.902)	mem 76.657
Train: [18][400/1500]	BT 0.036 (0.342)	DT 0.001 (0.301)	loss 8.257 (7.971)	prob 2.976 (3.648)	GS 36.188 (32.811)	mem 76.700
Train: [18][410/1500]	BT 0.038 (0.335)	DT 0.001 (0.295)	loss 7.447 (7.968)	prob 3.865 (3.407)	GS 33.312 (32.533)	mem 76.704
Train: [18][420/1500]	BT 0.039 (0.336)	DT 0.001 (0.296)	loss 8.509 (7.955)	prob 3.948 (3.547)	GS 34.062 (32.628)	mem 76.744
Train: [18][430/1500]	BT 0.039 (0.329)	DT 0.001 (0.289)	loss 8.252 (7.882)	prob 4.301 (3.633)	GS 36.625 (32.504)	mem 76.748
Train: [18][440/1500]	BT 0.038 (0.325)	DT 0.001 (0.284)	loss 7.452 (7.869)	prob 3.271 (3.531)	GS 31.609 (32.539)	mem 76.759
Train: [18][450/1500]	BT 0.039 (0.326)	DT 0.000 (0.286)	loss 7.590 (7.849)	prob 3.201 (3.511)	GS 34.062 (32.580)	mem 76.806
Train: [18][460/1500]	BT 0.039 (0.323)	DT 0.001 (0.283)	loss 7.666 (7.891)	prob 3.544 (3.241)	GS 31.375 (32.005)	mem 76.838
Train: [18][470/1500]	BT 0.034 (0.320)	DT 0.001 (0.280)	loss 8.071 (7.839)	prob 3.015 (3.168)	GS 32.250 (32.562)	mem 76.878
Train: [18][480/1500]	BT 0.029 (0.324)	DT 0.000 (0.284)	loss 7.740 (7.859)	prob 3.727 (3.209)	GS 36.234 (32.426)	mem 76.955
Train: [18][490/1500]	BT 0.056 (0.318)	DT 0.000 (0.278)	loss 7.803 (7.857)	prob 3.764 (3.179)	GS 32.391 (32.645)	mem 76.966
Train: [18][500/1500]	BT 0.029 (0.327)	DT 0.001 (0.287)	loss 8.215 (7.852)	prob 1.715 (3.068)	GS 33.594 (33.054)	mem 77.113
Train: [18][510/1500]	BT 0.033 (0.321)	DT 0.001 (0.282)	loss 8.508 (7.995)	prob 2.557 (2.732)	GS 30.625 (33.003)	mem 77.122
Train: [18][520/1500]	BT 0.038 (0.329)	DT 0.000 (0.289)	loss 7.759 (7.944)	prob 3.373 (2.644)	GS 36.391 (32.962)	mem 77.265
Train: [18][530/1500]	BT 0.071 (0.324)	DT 0.001 (0.284)	loss 8.208 (7.982)	prob 2.816 (2.611)	GS 34.031 (33.063)	mem 77.273
Train: [18][540/1500]	BT 0.040 (0.328)	DT 0.000 (0.289)	loss 8.094 (7.972)	prob 2.512 (2.580)	GS 35.016 (33.389)	mem 77.352
Train: [18][550/1500]	BT 0.028 (0.323)	DT 0.000 (0.283)	loss 8.874 (7.972)	prob 2.204 (2.572)	GS 33.203 (33.398)	mem 77.363
Train: [18][560/1500]	BT 0.038 (0.318)	DT 0.001 (0.278)	loss 8.106 (7.962)	prob 3.039 (2.378)	GS 30.578 (33.695)	mem 77.376
Train: [18][570/1500]	BT 0.030 (0.321)	DT 0.000 (0.281)	loss 8.304 (7.980)	prob 2.663 (2.497)	GS 35.453 (33.141)	mem 77.508
Train: [18][580/1500]	BT 0.039 (0.316)	DT 0.001 (0.276)	loss 7.848 (7.977)	prob 2.892 (2.435)	GS 39.453 (33.507)	mem 77.516
Train: [18][590/1500]	BT 0.055 (0.326)	DT 0.006 (0.286)	loss 7.457 (7.941)	prob 3.211 (2.441)	GS 36.859 (33.429)	mem 76.685
Train: [18][600/1500]	BT 0.039 (0.322)	DT 0.001 (0.282)	loss 8.080 (7.977)	prob 2.374 (2.318)	GS 35.578 (33.828)	mem 76.699
Train: [18][610/1500]	BT 0.040 (0.318)	DT 0.001 (0.279)	loss 8.082 (8.015)	prob 3.128 (2.365)	GS 31.422 (32.356)	mem 76.719
Train: [18][620/1500]	BT 0.029 (0.320)	DT 0.000 (0.280)	loss 7.646 (7.926)	prob 3.196 (2.379)	GS 33.328 (32.354)	mem 76.752
Train: [18][630/1500]	BT 0.040 (0.315)	DT 0.001 (0.276)	loss 8.473 (7.911)	prob 4.079 (2.496)	GS 34.266 (32.133)	mem 76.756
Train: [18][640/1500]	BT 0.039 (0.314)	DT 0.001 (0.274)	loss 8.121 (7.939)	prob 2.172 (2.608)	GS 32.641 (31.870)	mem 76.790
Train: [18][650/1500]	BT 0.039 (0.311)	DT 0.001 (0.272)	loss 7.849 (7.976)	prob 3.022 (2.614)	GS 36.281 (31.839)	mem 76.815
Train: [18][660/1500]	BT 0.039 (0.308)	DT 0.001 (0.269)	loss 8.952 (8.143)	prob 3.035 (2.794)	GS 32.422 (31.847)	mem 76.826
Train: [18][670/1500]	BT 0.029 (0.316)	DT 0.000 (0.277)	loss 8.361 (8.123)	prob 3.413 (2.839)	GS 36.828 (32.516)	mem 76.894
Train: [18][680/1500]	BT 0.034 (0.312)	DT 0.001 (0.273)	loss 8.004 (8.130)	prob 3.161 (2.706)	GS 32.609 (32.461)	mem 76.897
Train: [18][690/1500]	BT 0.040 (0.309)	DT 0.001 (0.270)	loss 8.655 (8.172)	prob 2.713 (2.615)	GS 34.625 (31.940)	mem 76.917
Train: [18][700/1500]	BT 0.039 (0.312)	DT 0.001 (0.273)	loss 8.801 (8.194)	prob 3.133 (2.590)	GS 30.547 (31.874)	mem 77.014
Train: [18][710/1500]	BT 0.040 (0.308)	DT 0.001 (0.269)	loss 7.764 (8.221)	prob 4.397 (2.732)	GS 31.875 (31.295)	mem 77.031
Train: [18][720/1500]	BT 0.041 (0.311)	DT 0.001 (0.272)	loss 8.025 (8.191)	prob 3.561 (2.598)	GS 32.109 (31.511)	mem 77.203
Train: [18][730/1500]	BT 0.030 (0.307)	DT 0.000 (0.268)	loss 7.866 (8.125)	prob 3.949 (2.738)	GS 32.531 (32.149)	mem 77.215
Train: [18][740/1500]	BT 0.069 (0.310)	DT 0.001 (0.270)	loss 8.652 (8.111)	prob 2.371 (2.750)	GS 38.062 (32.273)	mem 77.311
Train: [18][750/1500]	BT 0.068 (0.306)	DT 0.013 (0.267)	loss 8.646 (8.112)	prob 3.326 (2.807)	GS 33.734 (32.072)	mem 77.316
Train: [18][760/1500]	BT 0.053 (0.303)	DT 0.014 (0.263)	loss 8.987 (8.433)	prob 2.322 (2.268)	GS 33.266 (32.138)	mem 77.323
Train: [18][770/1500]	BT 0.081 (0.305)	DT 0.001 (0.266)	loss 8.615 (8.283)	prob 2.840 (2.633)	GS 35.641 (33.155)	mem 77.416
Train: [18][780/1500]	BT 0.063 (0.302)	DT 0.003 (0.262)	loss 8.507 (8.259)	prob 2.548 (2.608)	GS 33.891 (33.090)	mem 77.471
Train: [18][790/1500]	BT 0.052 (0.304)	DT 0.005 (0.264)	loss 8.698 (8.215)	prob 2.832 (2.657)	GS 32.672 (32.583)	mem 77.439
Train: [18][800/1500]	BT 0.043 (0.306)	DT 0.001 (0.266)	loss 8.028 (8.168)	prob 3.273 (2.732)	GS 34.438 (32.503)	mem 77.522
Train: [18][810/1500]	BT 0.040 (0.308)	DT 0.001 (0.267)	loss 7.983 (8.267)	prob 4.364 (2.890)	GS 30.125 (30.939)	mem 76.662
Train: [18][820/1500]	BT 0.039 (0.305)	DT 0.001 (0.265)	loss 8.275 (8.160)	prob 2.751 (3.072)	GS 31.531 (31.572)	mem 76.662
Train: [18][830/1500]	BT 0.060 (0.305)	DT 0.003 (0.265)	loss 8.473 (8.121)	prob 2.368 (2.986)	GS 38.125 (32.147)	mem 76.680
Train: [18][840/1500]	BT 0.105 (0.307)	DT 0.010 (0.266)	loss 8.834 (8.151)	prob 2.883 (2.845)	GS 34.703 (32.248)	mem 76.704
Train: [18][850/1500]	BT 0.038 (0.311)	DT 0.001 (0.270)	loss 8.368 (8.149)	prob 2.749 (2.848)	GS 35.562 (32.988)	mem 76.743
Train: [18][860/1500]	BT 0.038 (0.309)	DT 0.001 (0.268)	loss 7.860 (8.048)	prob 3.585 (3.120)	GS 32.266 (31.948)	mem 76.754
Train: [18][870/1500]	BT 0.038 (0.310)	DT 0.001 (0.269)	loss 8.277 (8.096)	prob 2.721 (3.062)	GS 35.141 (32.898)	mem 76.801
Train: [18][880/1500]	BT 0.038 (0.307)	DT 0.001 (0.266)	loss 7.965 (8.068)	prob 3.259 (3.052)	GS 29.312 (32.786)	mem 76.805
Train: [18][890/1500]	BT 0.050 (0.310)	DT 0.012 (0.270)	loss 9.154 (8.143)	prob 2.563 (2.984)	GS 34.703 (33.037)	mem 76.876
Train: [18][900/1500]	BT 0.118 (0.308)	DT 0.004 (0.267)	loss 8.123 (8.106)	prob 3.823 (3.033)	GS 37.219 (33.157)	mem 76.883
Train: [18][910/1500]	BT 0.072 (0.305)	DT 0.006 (0.264)	loss 8.484 (8.175)	prob 3.540 (3.280)	GS 37.125 (32.247)	mem 76.893
Train: [18][920/1500]	BT 0.029 (0.312)	DT 0.000 (0.270)	loss 8.544 (8.136)	prob 3.001 (3.326)	GS 38.609 (32.497)	mem 77.072
Train: [18][930/1500]	BT 0.029 (0.309)	DT 0.000 (0.267)	loss 8.288 (8.098)	prob 3.068 (3.311)	GS 36.297 (32.159)	mem 77.084
Train: [18][940/1500]	BT 0.026 (0.314)	DT 0.000 (0.273)	loss 7.947 (8.056)	prob 3.502 (3.287)	GS 33.328 (32.654)	mem 77.104
Train: [18][950/1500]	BT 0.037 (0.311)	DT 0.001 (0.270)	loss 8.361 (8.065)	prob 3.762 (3.246)	GS 33.359 (32.783)	mem 77.115
Train: [18][960/1500]	BT 0.039 (0.308)	DT 0.001 (0.267)	loss 8.141 (7.964)	prob 2.599 (3.331)	GS 32.797 (32.136)	mem 77.129
Train: [18][970/1500]	BT 0.034 (0.312)	DT 0.001 (0.271)	loss 7.726 (8.014)	prob 3.224 (3.072)	GS 37.875 (33.102)	mem 77.296
Train: [18][980/1500]	BT 0.075 (0.310)	DT 0.005 (0.269)	loss 8.376 (7.991)	prob 4.105 (3.063)	GS 31.750 (32.709)	mem 77.315
Train: [18][990/1500]	BT 0.030 (0.312)	DT 0.000 (0.271)	loss 7.846 (7.931)	prob 3.825 (3.091)	GS 32.422 (32.696)	mem 77.389
Train: [18][1000/1500]	BT 0.037 (0.309)	DT 0.000 (0.268)	loss 8.477 (7.930)	prob 3.573 (3.188)	GS 39.828 (32.741)	mem 77.399
Train: [18][1010/1500]	BT 0.039 (0.306)	DT 0.001 (0.265)	loss 7.409 (7.727)	prob 3.916 (3.205)	GS 30.953 (31.909)	mem 77.412
Train: [18][1020/1500]	BT 0.033 (0.309)	DT 0.000 (0.268)	loss 8.234 (7.867)	prob 2.883 (3.367)	GS 28.797 (31.670)	mem 76.610
Train: [18][1030/1500]	BT 0.039 (0.306)	DT 0.001 (0.266)	loss 7.887 (7.955)	prob 4.191 (3.203)	GS 29.203 (31.568)	mem 76.611
Train: [18][1040/1500]	BT 0.039 (0.307)	DT 0.001 (0.266)	loss 7.710 (7.936)	prob 2.922 (3.213)	GS 34.203 (31.628)	mem 76.615
Train: [18][1050/1500]	BT 0.033 (0.304)	DT 0.001 (0.263)	loss 7.652 (7.925)	prob 2.443 (3.042)	GS 32.328 (32.082)	mem 76.619
Train: [18][1060/1500]	BT 0.053 (0.308)	DT 0.006 (0.267)	loss 7.571 (7.994)	prob 3.085 (2.414)	GS 31.719 (33.259)	mem 76.679
Train: [18][1070/1500]	BT 0.055 (0.308)	DT 0.004 (0.267)	loss 7.581 (7.963)	prob 3.840 (2.610)	GS 32.031 (31.966)	mem 76.684
Train: [18][1080/1500]	BT 0.021 (0.316)	DT 0.000 (0.275)	loss 8.423 (7.940)	prob 2.514 (2.668)	GS 35.609 (32.516)	mem 76.792
Train: [18][1090/1500]	BT 0.030 (0.314)	DT 0.000 (0.273)	loss 7.895 (7.937)	prob 2.913 (2.647)	GS 36.578 (32.643)	mem 76.798
Train: [18][1100/1500]	BT 0.038 (0.311)	DT 0.001 (0.270)	loss 8.682 (7.937)	prob 3.458 (2.643)	GS 36.000 (32.582)	mem 76.805
Train: [18][1110/1500]	BT 0.031 (0.314)	DT 0.001 (0.273)	loss 8.074 (8.034)	prob 3.309 (2.609)	GS 34.891 (32.872)	mem 76.874
Train: [18][1120/1500]	BT 0.031 (0.311)	DT 0.000 (0.271)	loss 8.441 (7.910)	prob 2.773 (2.490)	GS 34.031 (32.790)	mem 76.878
Train: [18][1130/1500]	BT 0.040 (0.317)	DT 0.001 (0.277)	loss 7.817 (7.958)	prob 2.666 (2.534)	GS 34.453 (32.980)	mem 77.033
Train: [18][1140/1500]	BT 0.072 (0.315)	DT 0.004 (0.274)	loss 8.135 (7.965)	prob 3.099 (2.557)	GS 33.609 (32.622)	mem 77.046
Train: [18][1150/1500]	BT 2.285 (0.316)	DT 2.246 (0.276)	loss 8.778 (7.955)	prob 3.040 (2.575)	GS 36.000 (32.957)	mem 77.105
Train: [18][1160/1500]	BT 0.040 (0.314)	DT 0.001 (0.273)	loss 7.722 (8.017)	prob 2.704 (2.346)	GS 30.812 (31.853)	mem 77.118
Train: [18][1170/1500]	BT 0.042 (0.312)	DT 0.001 (0.271)	loss 8.282 (8.014)	prob 2.829 (2.286)	GS 33.594 (32.318)	mem 77.134
Train: [18][1180/1500]	BT 0.076 (0.314)	DT 0.005 (0.274)	loss 8.764 (8.070)	prob 2.533 (2.404)	GS 34.656 (32.427)	mem 77.208
Train: [18][1190/1500]	BT 0.072 (0.312)	DT 0.005 (0.272)	loss 8.391 (8.096)	prob 2.766 (2.438)	GS 37.312 (32.556)	mem 77.216
Train: [18][1200/1500]	BT 0.039 (0.313)	DT 0.001 (0.272)	loss 8.574 (8.105)	prob 3.400 (2.374)	GS 32.828 (32.794)	mem 77.280
Train: [18][1210/1500]	BT 0.039 (0.310)	DT 0.001 (0.270)	loss 8.003 (8.039)	prob 3.460 (2.537)	GS 31.406 (32.489)	mem 77.288
Train: [18][1220/1500]	BT 0.041 (0.309)	DT 0.001 (0.268)	loss 8.452 (8.141)	prob 1.994 (2.319)	GS 34.516 (33.245)	mem 77.311
Train: [18][1230/1500]	BT 0.037 (0.310)	DT 0.000 (0.269)	loss 7.605 (8.124)	prob 3.056 (2.235)	GS 35.297 (33.520)	mem 77.403
Train: [18][1240/1500]	BT 0.034 (0.308)	DT 0.000 (0.267)	loss 8.440 (8.111)	prob 3.115 (2.365)	GS 34.891 (33.523)	mem 77.432
Train: [18][1250/1500]	BT 0.038 (0.310)	DT 0.001 (0.270)	loss 9.686 (8.182)	prob 2.085 (2.386)	GS 33.234 (33.241)	mem 76.588
Train: [18][1260/1500]	BT 0.038 (0.308)	DT 0.000 (0.267)	loss 8.649 (8.114)	prob 2.333 (2.516)	GS 33.922 (32.456)	mem 76.588
Train: [18][1270/1500]	BT 0.038 (0.308)	DT 0.001 (0.268)	loss 9.080 (8.256)	prob 3.074 (2.653)	GS 34.828 (31.868)	mem 76.632
Train: [18][1280/1500]	BT 0.041 (0.306)	DT 0.001 (0.266)	loss 9.376 (8.246)	prob 2.227 (2.713)	GS 36.328 (32.216)	mem 76.638
Train: [18][1290/1500]	BT 0.037 (0.310)	DT 0.000 (0.269)	loss 8.888 (8.259)	prob 3.454 (2.765)	GS 37.391 (32.215)	mem 76.698
Train: [18][1300/1500]	BT 0.068 (0.311)	DT 0.014 (0.271)	loss 8.439 (8.222)	prob 4.047 (2.857)	GS 33.375 (32.110)	mem 76.740
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [18][1310/1500]	BT 0.078 (0.309)	DT 0.013 (0.269)	loss 8.339 (8.270)	prob 3.002 (2.826)	GS 32.438 (32.336)	mem 76.742
Train: [18][1320/1500]	BT 6.381 (0.318)	DT 6.336 (0.277)	loss 8.510 (8.269)	prob 3.012 (2.868)	GS 35.969 (32.651)	mem 76.931
Train: [18][1330/1500]	BT 0.030 (0.316)	DT 0.000 (0.275)	loss 7.949 (8.225)	prob 3.324 (2.912)	GS 35.047 (32.621)	mem 76.944
Train: [18][1340/1500]	BT 0.028 (0.314)	DT 0.001 (0.273)	loss 8.593 (8.279)	prob 2.805 (2.943)	GS 34.734 (32.527)	mem 76.954
Train: [18][1350/1500]	BT 0.039 (0.315)	DT 0.000 (0.274)	loss 7.845 (8.232)	prob 4.416 (2.927)	GS 38.031 (32.663)	mem 77.092
Train: [18][1360/1500]	BT 0.033 (0.313)	DT 0.000 (0.272)	loss 8.785 (8.236)	prob 2.873 (3.219)	GS 34.469 (32.606)	mem 77.100
Train: [18][1370/1500]	BT 0.036 (0.314)	DT 0.000 (0.274)	loss 8.590 (8.177)	prob 3.550 (3.139)	GS 30.188 (32.606)	mem 77.247
Train: [18][1380/1500]	BT 0.037 (0.312)	DT 0.001 (0.272)	loss 8.436 (8.216)	prob 3.086 (3.146)	GS 31.844 (32.363)	mem 77.261
Train: [18][1390/1500]	BT 0.038 (0.310)	DT 0.000 (0.270)	loss 8.686 (8.241)	prob 4.355 (3.168)	GS 32.188 (32.462)	mem 77.266
Train: [18][1400/1500]	BT 0.028 (0.312)	DT 0.000 (0.271)	loss 9.363 (8.262)	prob 3.335 (3.148)	GS 32.672 (32.626)	mem 77.383
Train: [18][1410/1500]	BT 0.032 (0.310)	DT 0.000 (0.269)	loss 7.966 (7.989)	prob 4.562 (3.575)	GS 35.188 (31.683)	mem 77.395
Train: [18][1420/1500]	BT 0.028 (0.313)	DT 0.000 (0.273)	loss 8.751 (8.147)	prob 3.352 (3.327)	GS 36.094 (32.298)	mem 77.499
Train: [18][1430/1500]	BT 0.038 (0.311)	DT 0.001 (0.271)	loss 8.212 (8.159)	prob 3.287 (3.329)	GS 34.953 (32.693)	mem 77.510
Train: [18][1440/1500]	BT 4.484 (0.313)	DT 4.446 (0.273)	loss 8.431 (8.158)	prob 3.322 (3.239)	GS 34.734 (32.940)	mem 76.665
Train: [18][1450/1500]	BT 0.037 (0.311)	DT 0.001 (0.271)	loss 8.362 (8.157)	prob 2.924 (3.265)	GS 37.797 (32.851)	mem 76.670
Train: [18][1460/1500]	BT 0.038 (0.309)	DT 0.001 (0.269)	loss 8.959 (8.329)	prob 3.149 (3.213)	GS 31.938 (30.953)	mem 76.676
Train: [18][1470/1500]	BT 0.026 (0.309)	DT 0.000 (0.269)	loss 7.998 (8.203)	prob 4.592 (3.473)	GS 32.734 (31.401)	mem 75.125
Train: [18][1480/1500]	BT 0.029 (0.307)	DT 0.000 (0.267)	loss 8.381 (8.164)	prob 4.519 (3.603)	GS 30.359 (31.566)	mem 75.129
Train: [18][1490/1500]	BT 0.033 (0.307)	DT 0.000 (0.267)	loss 8.157 (8.190)	prob 3.682 (3.437)	GS 30.719 (31.990)	mem 11.694
Train: [18][1500/1500]	BT 0.027 (0.305)	DT 0.000 (0.265)	loss 8.054 (8.196)	prob 3.796 (3.413)	GS 32.062 (32.050)	mem 11.703
Train: [18][1510/1500]	BT 0.032 (0.303)	DT 0.001 (0.264)	loss 7.871 (8.077)	prob 3.176 (3.576)	GS 34.438 (32.953)	mem 11.714
epoch 18, total time 459.26
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [19][1/1500]	BT 21.660 (21.660)	DT 21.607 (21.607)	loss 8.235 (8.235)	prob 2.308 (2.308)	GS 29.266 (29.266)	mem 75.710
Train: [19][10/1500]	BT 0.043 (2.270)	DT 0.011 (2.235)	loss 7.708 (8.005)	prob 3.551 (3.308)	GS 33.969 (32.901)	mem 75.773
Train: [19][20/1500]	BT 0.032 (1.293)	DT 0.000 (1.262)	loss 7.670 (8.068)	prob 4.241 (3.071)	GS 29.922 (33.535)	mem 76.053
Train: [19][30/1500]	BT 0.038 (0.916)	DT 0.001 (0.882)	loss 7.875 (8.071)	prob 2.938 (3.188)	GS 33.641 (33.533)	mem 76.374
Train: [19][40/1500]	BT 0.030 (1.082)	DT 0.000 (1.046)	loss 8.413 (8.028)	prob 3.344 (3.231)	GS 32.766 (33.300)	mem 76.441
Train: [19][50/1500]	BT 0.031 (0.872)	DT 0.000 (0.837)	loss 8.096 (8.060)	prob 3.724 (3.192)	GS 35.609 (33.318)	mem 76.445
Train: [19][60/1500]	BT 0.039 (0.733)	DT 0.001 (0.698)	loss 8.327 (8.050)	prob 4.226 (3.134)	GS 34.578 (34.000)	mem 76.471
Train: [19][70/1500]	BT 0.029 (0.692)	DT 0.000 (0.658)	loss 8.105 (8.015)	prob 4.027 (3.385)	GS 35.422 (33.045)	mem 76.556
Train: [19][80/1500]	BT 0.039 (0.610)	DT 0.001 (0.575)	loss 8.173 (8.021)	prob 4.287 (3.425)	GS 31.453 (33.193)	mem 76.561
Train: [19][90/1500]	BT 0.040 (0.579)	DT 0.001 (0.544)	loss 8.017 (8.013)	prob 3.541 (3.545)	GS 31.547 (32.532)	mem 76.616
Train: [19][100/1500]	BT 0.030 (0.525)	DT 0.001 (0.490)	loss 8.005 (8.041)	prob 3.837 (3.511)	GS 33.609 (32.604)	mem 76.595
Train: [19][110/1500]	BT 0.039 (0.506)	DT 0.001 (0.471)	loss 7.909 (7.987)	prob 4.233 (3.747)	GS 32.328 (32.069)	mem 76.624
Train: [19][120/1500]	BT 0.040 (0.467)	DT 0.001 (0.431)	loss 9.302 (7.990)	prob 3.693 (3.571)	GS 35.984 (32.079)	mem 76.625
Train: [19][130/1500]	BT 0.040 (0.434)	DT 0.001 (0.398)	loss 8.921 (8.063)	prob 3.313 (3.589)	GS 36.125 (32.262)	mem 76.630
Train: [19][140/1500]	BT 0.054 (0.436)	DT 0.011 (0.400)	loss 8.510 (8.037)	prob 3.357 (3.543)	GS 30.719 (32.259)	mem 76.681
Train: [19][150/1500]	BT 0.028 (0.492)	DT 0.001 (0.455)	loss 7.702 (7.976)	prob 2.888 (3.495)	GS 32.438 (32.737)	mem 76.844
Train: [19][160/1500]	BT 0.029 (0.463)	DT 0.000 (0.426)	loss 7.670 (7.838)	prob 2.880 (3.210)	GS 30.938 (31.881)	mem 76.857
Train: [19][170/1500]	BT 0.041 (0.438)	DT 0.001 (0.401)	loss 8.393 (7.906)	prob 3.104 (3.211)	GS 30.500 (32.754)	mem 76.868
Train: [19][180/1500]	BT 0.033 (0.439)	DT 0.000 (0.401)	loss 8.665 (7.968)	prob 2.870 (3.181)	GS 36.922 (32.555)	mem 76.989
Train: [19][190/1500]	BT 0.067 (0.418)	DT 0.005 (0.380)	loss 8.490 (7.992)	prob 3.117 (3.164)	GS 33.594 (32.487)	mem 76.997
Train: [19][200/1500]	BT 0.051 (0.446)	DT 0.001 (0.407)	loss 8.541 (8.018)	prob 2.890 (3.048)	GS 38.031 (32.774)	mem 77.116
Train: [19][210/1500]	BT 0.061 (0.427)	DT 0.011 (0.388)	loss 8.120 (7.797)	prob 4.398 (3.257)	GS 34.359 (33.472)	mem 77.120
Train: [19][220/1500]	BT 0.030 (0.433)	DT 0.000 (0.394)	loss 8.469 (7.899)	prob 2.541 (3.104)	GS 37.125 (34.312)	mem 77.291
Train: [19][230/1500]	BT 0.033 (0.416)	DT 0.000 (0.377)	loss 8.228 (7.923)	prob 2.157 (2.889)	GS 36.812 (33.757)	mem 77.307
Train: [19][240/1500]	BT 0.041 (0.400)	DT 0.001 (0.361)	loss 7.838 (7.907)	prob 3.992 (2.949)	GS 31.781 (33.098)	mem 77.294
Train: [19][250/1500]	BT 0.038 (0.407)	DT 0.001 (0.369)	loss 7.938 (7.921)	prob 2.679 (2.907)	GS 30.484 (32.929)	mem 77.371
Train: [19][260/1500]	BT 0.037 (0.394)	DT 0.000 (0.355)	loss 7.749 (7.850)	prob 2.472 (2.746)	GS 38.766 (33.227)	mem 77.378
Train: [19][270/1500]	BT 0.037 (0.403)	DT 0.001 (0.364)	loss 8.448 (7.939)	prob 1.407 (2.314)	GS 33.594 (33.743)	mem 76.571
Train: [19][280/1500]	BT 0.039 (0.390)	DT 0.001 (0.351)	loss 7.996 (7.917)	prob 2.982 (2.443)	GS 32.891 (32.992)	mem 76.569
Train: [19][290/1500]	BT 0.040 (0.396)	DT 0.001 (0.357)	loss 7.815 (7.905)	prob 3.393 (2.543)	GS 34.094 (32.891)	mem 76.472
Train: [19][300/1500]	BT 0.038 (0.384)	DT 0.001 (0.345)	loss 8.193 (7.888)	prob 2.786 (2.625)	GS 32.781 (32.600)	mem 76.486
Train: [19][310/1500]	BT 0.041 (0.373)	DT 0.001 (0.334)	loss 8.356 (7.837)	prob 2.463 (2.797)	GS 32.188 (32.827)	mem 76.491
Train: [19][320/1500]	BT 0.055 (0.379)	DT 0.006 (0.339)	loss 7.845 (7.940)	prob 3.136 (2.801)	GS 34.109 (32.712)	mem 76.527
Train: [19][330/1500]	BT 0.035 (0.369)	DT 0.001 (0.329)	loss 9.155 (7.952)	prob 2.930 (2.877)	GS 33.250 (32.575)	mem 76.531
Train: [19][340/1500]	BT 0.037 (0.375)	DT 0.001 (0.335)	loss 7.957 (7.912)	prob 2.865 (2.886)	GS 33.047 (32.973)	mem 76.583
Train: [19][350/1500]	BT 0.038 (0.366)	DT 0.001 (0.326)	loss 7.967 (7.916)	prob 3.212 (2.836)	GS 35.375 (32.895)	mem 76.595
Train: [19][360/1500]	BT 0.039 (0.357)	DT 0.001 (0.317)	loss 8.608 (7.943)	prob 2.521 (2.607)	GS 30.109 (31.953)	mem 76.603
Train: [19][370/1500]	BT 0.038 (0.356)	DT 0.001 (0.316)	loss 7.473 (7.947)	prob 4.043 (2.812)	GS 34.438 (31.839)	mem 76.619
Train: [19][380/1500]	BT 0.068 (0.348)	DT 0.014 (0.308)	loss 8.912 (8.012)	prob 2.614 (2.740)	GS 35.984 (31.723)	mem 76.626
Train: [19][390/1500]	BT 0.026 (0.363)	DT 0.000 (0.323)	loss 8.508 (8.068)	prob 3.020 (2.783)	GS 34.078 (32.089)	mem 76.716
Train: [19][400/1500]	BT 0.040 (0.354)	DT 0.001 (0.315)	loss 9.019 (8.093)	prob 2.430 (2.712)	GS 37.766 (32.691)	mem 76.734
Train: [19][410/1500]	BT 0.039 (0.347)	DT 0.001 (0.307)	loss 8.091 (8.139)	prob 4.326 (2.838)	GS 29.719 (33.509)	mem 76.750
Train: [19][420/1500]	BT 0.037 (0.348)	DT 0.001 (0.309)	loss 7.980 (8.178)	prob 4.259 (3.068)	GS 31.875 (32.413)	mem 76.806
Train: [19][430/1500]	BT 0.046 (0.341)	DT 0.001 (0.301)	loss 7.556 (8.103)	prob 4.586 (3.217)	GS 29.812 (32.132)	mem 76.813
Train: [19][440/1500]	BT 0.042 (0.346)	DT 0.001 (0.307)	loss 8.567 (8.129)	prob 3.064 (3.099)	GS 34.203 (32.211)	mem 76.905
Train: [19][450/1500]	BT 0.030 (0.339)	DT 0.000 (0.300)	loss 8.495 (8.148)	prob 3.545 (3.048)	GS 37.172 (32.431)	mem 76.916
Train: [19][460/1500]	BT 0.037 (0.344)	DT 0.001 (0.304)	loss 8.248 (8.137)	prob 3.065 (3.295)	GS 37.281 (32.989)	mem 77.054
Train: [19][470/1500]	BT 0.040 (0.337)	DT 0.001 (0.298)	loss 7.559 (8.082)	prob 4.172 (3.069)	GS 29.953 (33.625)	mem 77.065
Train: [19][480/1500]	BT 0.040 (0.331)	DT 0.001 (0.292)	loss 9.230 (8.181)	prob 3.669 (3.237)	GS 32.484 (32.913)	mem 77.079
Train: [19][490/1500]	BT 0.028 (0.354)	DT 0.000 (0.314)	loss 8.164 (8.214)	prob 4.537 (3.269)	GS 26.312 (32.711)	mem 77.200
Train: [19][500/1500]	BT 0.043 (0.348)	DT 0.001 (0.308)	loss 8.689 (8.215)	prob 3.888 (3.375)	GS 34.562 (32.626)	mem 77.216
Train: [19][510/1500]	BT 5.641 (0.353)	DT 5.590 (0.314)	loss 8.237 (8.189)	prob 4.110 (3.210)	GS 39.297 (35.298)	mem 77.326
Train: [19][520/1500]	BT 0.063 (0.350)	DT 0.001 (0.310)	loss 8.830 (8.207)	prob 2.669 (3.353)	GS 38.719 (33.084)	mem 77.312
Train: [19][530/1500]	BT 0.058 (0.344)	DT 0.001 (0.304)	loss 8.472 (8.214)	prob 4.269 (3.460)	GS 34.422 (32.765)	mem 77.315
Train: [19][540/1500]	BT 0.058 (0.358)	DT 0.014 (0.318)	loss 9.180 (8.254)	prob 3.298 (3.397)	GS 36.969 (33.155)	mem 76.514
Train: [19][550/1500]	BT 0.081 (0.367)	DT 0.011 (0.326)	loss 8.393 (8.225)	prob 3.458 (3.408)	GS 36.719 (33.398)	mem 76.509
Train: [19][560/1500]	BT 0.032 (0.377)	DT 0.001 (0.337)	loss 8.376 (8.242)	prob 2.843 (3.054)	GS 35.703 (35.947)	mem 76.550
Train: [19][570/1500]	BT 0.026 (0.371)	DT 0.000 (0.331)	loss 8.392 (8.248)	prob 3.868 (3.202)	GS 32.703 (34.484)	mem 76.553
Train: [19][580/1500]	BT 0.030 (0.365)	DT 0.001 (0.325)	loss 8.386 (8.251)	prob 3.873 (3.318)	GS 32.031 (33.795)	mem 76.557
Train: [19][590/1500]	BT 0.038 (0.367)	DT 0.001 (0.327)	loss 9.224 (8.239)	prob 3.457 (3.449)	GS 34.000 (33.311)	mem 76.621
Train: [19][600/1500]	BT 0.039 (0.362)	DT 0.001 (0.321)	loss 8.110 (8.228)	prob 3.993 (3.545)	GS 35.328 (32.992)	mem 76.625
Train: [19][610/1500]	BT 0.031 (0.368)	DT 0.001 (0.328)	loss 8.610 (8.160)	prob 3.435 (3.525)	GS 32.359 (31.914)	mem 76.685
Train: [19][620/1500]	BT 0.084 (0.363)	DT 0.000 (0.322)	loss 9.343 (8.269)	prob 3.996 (3.451)	GS 34.188 (32.173)	mem 76.688
Train: [19][630/1500]	BT 0.067 (0.358)	DT 0.012 (0.318)	loss 8.767 (8.233)	prob 3.559 (3.606)	GS 35.922 (32.316)	mem 76.692
Train: [19][640/1500]	BT 0.038 (0.362)	DT 0.001 (0.321)	loss 8.417 (8.167)	prob 4.059 (3.615)	GS 35.797 (32.375)	mem 76.780
Train: [19][650/1500]	BT 0.029 (0.357)	DT 0.001 (0.316)	loss 8.270 (8.132)	prob 3.972 (3.674)	GS 30.078 (32.058)	mem 76.791
Train: [19][660/1500]	BT 0.032 (0.359)	DT 0.000 (0.319)	loss 8.187 (8.284)	prob 3.896 (3.487)	GS 30.172 (31.770)	mem 76.896
Train: [19][670/1500]	BT 0.091 (0.355)	DT 0.004 (0.314)	loss 8.398 (8.193)	prob 3.562 (3.621)	GS 31.391 (31.179)	mem 76.904
Train: [19][680/1500]	BT 0.053 (0.356)	DT 0.007 (0.315)	loss 8.231 (8.179)	prob 4.443 (3.664)	GS 33.234 (31.103)	mem 76.987
Train: [19][690/1500]	BT 0.064 (0.360)	DT 0.011 (0.319)	loss 8.543 (8.149)	prob 3.741 (3.656)	GS 32.734 (31.036)	mem 77.033
Train: [19][700/1500]	BT 0.066 (0.355)	DT 0.023 (0.314)	loss 7.786 (8.167)	prob 3.283 (3.567)	GS 31.047 (31.437)	mem 77.039
Train: [19][710/1500]	BT 0.031 (0.365)	DT 0.000 (0.324)	loss 8.235 (8.046)	prob 3.385 (3.450)	GS 35.234 (33.758)	mem 77.152
Train: [19][720/1500]	BT 0.024 (0.360)	DT 0.000 (0.319)	loss 8.054 (8.072)	prob 3.578 (3.380)	GS 35.344 (32.919)	mem 77.161
Train: [19][730/1500]	BT 0.023 (0.366)	DT 0.000 (0.326)	loss 8.971 (8.087)	prob 2.853 (3.145)	GS 33.594 (33.685)	mem 76.595
Train: [19][740/1500]	BT 0.024 (0.362)	DT 0.000 (0.321)	loss 7.980 (8.084)	prob 3.507 (3.123)	GS 33.266 (33.797)	mem 76.531
Train: [19][750/1500]	BT 0.029 (0.366)	DT 0.001 (0.325)	loss 7.790 (8.059)	prob 2.841 (3.148)	GS 33.344 (33.523)	mem 76.549
Train: [19][760/1500]	BT 0.029 (0.361)	DT 0.000 (0.321)	loss 8.643 (8.125)	prob 3.756 (3.109)	GS 34.047 (31.819)	mem 76.553
Train: [19][770/1500]	BT 0.037 (0.357)	DT 0.001 (0.317)	loss 8.588 (8.139)	prob 3.344 (3.091)	GS 35.250 (32.350)	mem 76.559
Train: [19][780/1500]	BT 0.037 (0.359)	DT 0.001 (0.319)	loss 7.892 (8.125)	prob 3.121 (3.034)	GS 32.891 (32.249)	mem 76.627
Train: [19][790/1500]	BT 0.067 (0.355)	DT 0.013 (0.315)	loss 8.493 (8.096)	prob 3.419 (3.063)	GS 33.406 (32.110)	mem 76.636
Train: [19][800/1500]	BT 0.071 (0.360)	DT 0.003 (0.319)	loss 8.094 (8.088)	prob 3.185 (3.016)	GS 30.453 (31.986)	mem 76.663
Train: [19][810/1500]	BT 0.073 (0.356)	DT 0.013 (0.315)	loss 8.088 (8.153)	prob 2.319 (2.750)	GS 32.000 (31.819)	mem 76.668
Train: [19][820/1500]	BT 0.039 (0.358)	DT 0.001 (0.317)	loss 7.893 (8.147)	prob 2.710 (2.582)	GS 30.719 (32.443)	mem 76.705
Train: [19][830/1500]	BT 0.031 (0.357)	DT 0.000 (0.317)	loss 8.359 (8.122)	prob 3.480 (2.569)	GS 33.531 (32.534)	mem 76.763
Train: [19][840/1500]	BT 0.038 (0.354)	DT 0.001 (0.313)	loss 8.183 (8.155)	prob 2.673 (2.516)	GS 36.047 (32.644)	mem 76.777
Train: [19][850/1500]	BT 0.039 (0.357)	DT 0.001 (0.316)	loss 8.950 (8.187)	prob 1.804 (2.377)	GS 37.562 (32.809)	mem 76.948
Train: [19][860/1500]	BT 0.039 (0.353)	DT 0.001 (0.312)	loss 8.184 (8.225)	prob 1.929 (1.987)	GS 33.562 (33.741)	mem 76.963
Train: [19][870/1500]	BT 0.031 (0.357)	DT 0.000 (0.316)	loss 9.179 (8.211)	prob 2.256 (2.086)	GS 38.375 (33.497)	mem 77.065
Train: [19][880/1500]	BT 0.033 (0.353)	DT 0.001 (0.312)	loss 8.656 (8.144)	prob 3.317 (2.328)	GS 32.344 (33.094)	mem 77.075
Train: [19][890/1500]	BT 0.038 (0.349)	DT 0.001 (0.309)	loss 8.591 (8.082)	prob 1.479 (2.369)	GS 38.672 (33.134)	mem 77.090
Train: [19][900/1500]	BT 0.028 (0.355)	DT 0.000 (0.314)	loss 8.657 (8.148)	prob 2.253 (2.252)	GS 32.453 (33.388)	mem 77.280
Train: [19][910/1500]	BT 0.036 (0.351)	DT 0.000 (0.311)	loss 8.523 (8.128)	prob 2.388 (2.233)	GS 34.312 (32.487)	mem 77.292
Train: [19][920/1500]	BT 0.038 (0.352)	DT 0.001 (0.312)	loss 8.016 (8.155)	prob 2.673 (2.321)	GS 33.984 (32.566)	mem 77.436
Train: [19][930/1500]	BT 0.037 (0.349)	DT 0.001 (0.308)	loss 8.841 (8.185)	prob 2.696 (2.253)	GS 33.266 (32.523)	mem 77.451
Train: [19][940/1500]	BT 0.039 (0.346)	DT 0.001 (0.305)	loss 8.607 (8.215)	prob 2.851 (2.236)	GS 36.250 (32.527)	mem 77.430
Train: [19][950/1500]	BT 0.039 (0.345)	DT 0.001 (0.305)	loss 8.233 (8.237)	prob 2.365 (2.182)	GS 30.250 (32.586)	mem 76.557
Train: [19][960/1500]	BT 0.040 (0.342)	DT 0.001 (0.302)	loss 9.042 (8.501)	prob 2.136 (2.333)	GS 34.469 (32.180)	mem 76.560
Train: [19][970/1500]	BT 0.038 (0.344)	DT 0.001 (0.304)	loss 8.743 (8.371)	prob 2.718 (2.293)	GS 33.844 (32.577)	mem 76.592
Train: [19][980/1500]	BT 0.038 (0.341)	DT 0.001 (0.301)	loss 8.836 (8.286)	prob 2.427 (2.468)	GS 36.547 (32.418)	mem 76.597
Train: [19][990/1500]	BT 0.039 (0.343)	DT 0.001 (0.303)	loss 8.238 (8.265)	prob 2.423 (2.513)	GS 30.875 (32.194)	mem 76.687
Train: [19][1000/1500]	BT 0.040 (0.340)	DT 0.001 (0.300)	loss 8.205 (8.214)	prob 3.488 (2.514)	GS 35.281 (32.395)	mem 76.690
Train: [19][1010/1500]	BT 0.061 (0.337)	DT 0.011 (0.297)	loss 8.912 (8.409)	prob 2.514 (2.363)	GS 35.203 (33.358)	mem 76.694
Train: [19][1020/1500]	BT 0.034 (0.341)	DT 0.001 (0.301)	loss 8.366 (8.328)	prob 3.074 (2.613)	GS 31.016 (32.727)	mem 76.752
Train: [19][1030/1500]	BT 0.060 (0.338)	DT 0.016 (0.298)	loss 8.447 (8.337)	prob 3.777 (2.523)	GS 27.688 (32.303)	mem 76.755
Train: [19][1040/1500]	BT 0.060 (0.343)	DT 0.003 (0.303)	loss 8.174 (8.341)	prob 3.239 (2.493)	GS 33.156 (32.264)	mem 76.798
Train: [19][1050/1500]	BT 0.062 (0.341)	DT 0.012 (0.300)	loss 7.802 (8.351)	prob 3.344 (2.556)	GS 29.172 (32.261)	mem 76.800
Train: [19][1060/1500]	BT 0.060 (0.350)	DT 0.001 (0.309)	loss 8.612 (8.271)	prob 3.617 (2.928)	GS 33.578 (31.750)	mem 76.916
Train: [19][1070/1500]	BT 0.030 (0.357)	DT 0.000 (0.316)	loss 8.340 (8.302)	prob 2.078 (2.806)	GS 31.203 (32.395)	mem 77.157
Train: [19][1080/1500]	BT 0.028 (0.354)	DT 0.000 (0.313)	loss 8.283 (8.254)	prob 3.143 (2.950)	GS 33.703 (32.374)	mem 77.167
Train: [19][1090/1500]	BT 0.041 (0.353)	DT 0.001 (0.313)	loss 8.017 (8.232)	prob 2.917 (2.898)	GS 34.781 (32.730)	mem 77.265
Train: [19][1100/1500]	BT 0.040 (0.351)	DT 0.001 (0.310)	loss 8.599 (8.242)	prob 3.278 (2.866)	GS 32.719 (32.656)	mem 77.275
Train: [19][1110/1500]	BT 3.075 (0.351)	DT 3.038 (0.310)	loss 8.111 (8.045)	prob 4.086 (3.288)	GS 32.484 (31.805)	mem 77.333
Train: [19][1120/1500]	BT 0.040 (0.348)	DT 0.001 (0.307)	loss 8.528 (8.013)	prob 3.101 (3.337)	GS 32.359 (32.071)	mem 77.340
Train: [19][1130/1500]	BT 0.040 (0.345)	DT 0.001 (0.305)	loss 9.137 (8.099)	prob 2.987 (3.299)	GS 35.875 (32.199)	mem 77.350
Train: [19][1140/1500]	BT 0.040 (0.345)	DT 0.001 (0.305)	loss 8.350 (8.100)	prob 3.156 (3.202)	GS 34.953 (32.527)	mem 77.413
Train: [19][1150/1500]	BT 0.060 (0.344)	DT 0.003 (0.303)	loss 8.366 (8.129)	prob 3.371 (3.119)	GS 33.234 (32.541)	mem 77.445
Train: [19][1160/1500]	BT 0.031 (0.345)	DT 0.000 (0.305)	loss 8.324 (8.255)	prob 4.146 (3.558)	GS 33.844 (32.855)	mem 76.612
Train: [19][1170/1500]	BT 0.039 (0.347)	DT 0.001 (0.307)	loss 8.256 (8.200)	prob 2.841 (3.269)	GS 35.625 (33.432)	mem 76.615
Train: [19][1180/1500]	BT 0.030 (0.345)	DT 0.000 (0.305)	loss 9.068 (8.224)	prob 3.192 (3.162)	GS 39.391 (33.982)	mem 76.629
Train: [19][1190/1500]	BT 0.039 (0.344)	DT 0.001 (0.304)	loss 9.046 (8.242)	prob 3.700 (3.124)	GS 34.906 (33.944)	mem 76.650
Train: [19][1200/1500]	BT 0.026 (0.344)	DT 0.000 (0.304)	loss 8.031 (8.204)	prob 4.436 (3.223)	GS 30.812 (33.806)	mem 76.677
Train: [19][1210/1500]	BT 0.040 (0.342)	DT 0.001 (0.301)	loss 7.837 (7.985)	prob 3.867 (3.819)	GS 36.484 (32.484)	mem 76.684
Train: [19][1220/1500]	BT 0.035 (0.341)	DT 0.001 (0.300)	loss 8.268 (8.067)	prob 3.461 (3.637)	GS 38.531 (32.899)	mem 76.711
Train: [19][1230/1500]	BT 0.039 (0.342)	DT 0.001 (0.301)	loss 8.233 (8.107)	prob 3.954 (3.636)	GS 33.328 (32.958)	mem 76.717
Train: [19][1240/1500]	BT 0.040 (0.341)	DT 0.001 (0.301)	loss 8.410 (8.157)	prob 3.862 (3.481)	GS 35.719 (33.218)	mem 76.746
Train: [19][1250/1500]	BT 0.039 (0.340)	DT 0.001 (0.300)	loss 8.533 (8.145)	prob 4.496 (3.504)	GS 34.562 (32.989)	mem 76.764
Train: [19][1260/1500]	BT 0.039 (0.340)	DT 0.001 (0.299)	loss 8.264 (7.875)	prob 3.853 (3.931)	GS 28.875 (31.208)	mem 76.837
Train: [19][1270/1500]	BT 0.039 (0.337)	DT 0.001 (0.297)	loss 8.740 (8.097)	prob 2.858 (3.600)	GS 32.453 (31.936)	mem 76.850
Train: [19][1280/1500]	BT 0.027 (0.338)	DT 0.000 (0.298)	loss 8.726 (8.125)	prob 3.526 (3.636)	GS 34.703 (32.821)	mem 76.981
Train: [19][1290/1500]	BT 0.030 (0.336)	DT 0.001 (0.296)	loss 8.081 (8.068)	prob 4.387 (3.622)	GS 35.359 (32.850)	mem 76.996
Train: [19][1300/1500]	BT 0.037 (0.336)	DT 0.001 (0.296)	loss 8.229 (8.077)	prob 4.497 (3.685)	GS 28.594 (32.599)	mem 77.075
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [19][1310/1500]	BT 0.038 (0.334)	DT 0.001 (0.293)	loss 7.986 (8.024)	prob 3.909 (4.126)	GS 35.047 (31.789)	mem 77.078
Train: [19][1320/1500]	BT 0.038 (0.333)	DT 0.000 (0.293)	loss 7.842 (8.019)	prob 4.420 (4.117)	GS 31.141 (32.121)	mem 77.051
Train: [19][1330/1500]	BT 0.038 (0.331)	DT 0.001 (0.291)	loss 8.226 (8.058)	prob 3.456 (4.040)	GS 31.688 (32.081)	mem 77.060
Train: [19][1340/1500]	BT 0.039 (0.329)	DT 0.001 (0.289)	loss 8.321 (8.073)	prob 3.937 (3.893)	GS 35.031 (32.248)	mem 77.073
Train: [19][1350/1500]	BT 0.026 (0.335)	DT 0.000 (0.295)	loss 8.182 (8.054)	prob 4.611 (3.877)	GS 34.125 (32.445)	mem 77.222
Train: [19][1360/1500]	BT 0.030 (0.333)	DT 0.000 (0.293)	loss 8.787 (8.061)	prob 3.600 (3.797)	GS 37.391 (34.908)	mem 77.230
Train: [19][1370/1500]	BT 0.038 (0.331)	DT 0.001 (0.291)	loss 8.292 (7.994)	prob 3.773 (3.761)	GS 34.453 (34.407)	mem 77.255
Train: [19][1380/1500]	BT 0.038 (0.332)	DT 0.001 (0.292)	loss 8.204 (8.005)	prob 4.045 (3.797)	GS 36.547 (33.645)	mem 77.362
Train: [19][1390/1500]	BT 0.039 (0.329)	DT 0.001 (0.290)	loss 8.976 (8.068)	prob 3.710 (3.766)	GS 32.859 (33.268)	mem 77.374
Train: [19][1400/1500]	BT 0.038 (0.330)	DT 0.001 (0.291)	loss 8.005 (8.063)	prob 4.289 (3.763)	GS 34.062 (33.060)	mem 76.574
Train: [19][1410/1500]	BT 0.029 (0.328)	DT 0.000 (0.288)	loss 9.156 (8.211)	prob 3.432 (3.483)	GS 34.109 (32.639)	mem 76.575
Train: [19][1420/1500]	BT 0.039 (0.328)	DT 0.001 (0.288)	loss 8.912 (8.113)	prob 3.792 (3.700)	GS 35.688 (32.395)	mem 76.593
Train: [19][1430/1500]	BT 0.042 (0.328)	DT 0.001 (0.288)	loss 8.171 (7.993)	prob 4.139 (3.657)	GS 32.531 (32.592)	mem 76.638
Train: [19][1440/1500]	BT 0.039 (0.326)	DT 0.001 (0.286)	loss 7.827 (7.959)	prob 4.672 (3.705)	GS 31.531 (32.358)	mem 76.646
Train: [19][1450/1500]	BT 0.068 (0.328)	DT 0.001 (0.288)	loss 8.019 (7.961)	prob 3.028 (3.719)	GS 34.953 (32.493)	mem 76.618
Train: [19][1460/1500]	BT 0.040 (0.327)	DT 0.001 (0.287)	loss 7.790 (7.729)	prob 4.195 (3.848)	GS 35.188 (33.220)	mem 76.604
Train: [19][1470/1500]	BT 0.039 (0.325)	DT 0.001 (0.285)	loss 9.338 (7.831)	prob 1.936 (3.500)	GS 30.906 (33.504)	mem 76.427
Train: [19][1480/1500]	BT 0.052 (0.324)	DT 0.011 (0.284)	loss 8.361 (7.903)	prob 3.453 (3.444)	GS 33.891 (32.770)	mem 50.967
Train: [19][1490/1500]	BT 0.036 (0.323)	DT 0.000 (0.284)	loss 8.014 (7.890)	prob 3.026 (3.339)	GS 36.188 (32.769)	mem 11.712
Train: [19][1500/1500]	BT 0.025 (0.322)	DT 0.000 (0.282)	loss 7.897 (7.896)	prob 2.813 (3.313)	GS 27.438 (32.767)	mem 11.718
Train: [19][1510/1500]	BT 0.029 (0.320)	DT 0.000 (0.280)	loss 7.233 (7.890)	prob 3.479 (3.092)	GS 36.625 (36.178)	mem 11.662
epoch 19, total time 483.52
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [20][1/1500]	BT 24.507 (24.507)	DT 24.425 (24.425)	loss 7.477 (7.477)	prob 3.168 (3.168)	GS 34.953 (34.953)	mem 75.855
Train: [20][10/1500]	BT 0.048 (2.757)	DT 0.002 (2.711)	loss 8.123 (7.976)	prob 3.639 (3.122)	GS 32.047 (32.783)	mem 75.929
Train: [20][20/1500]	BT 0.029 (1.740)	DT 0.001 (1.693)	loss 7.606 (7.902)	prob 3.277 (3.185)	GS 35.109 (34.039)	mem 76.512
Train: [20][30/1500]	BT 0.040 (1.172)	DT 0.001 (1.129)	loss 8.219 (7.834)	prob 3.246 (3.191)	GS 31.328 (33.450)	mem 76.578
Train: [20][40/1500]	BT 0.049 (0.889)	DT 0.010 (0.847)	loss 7.773 (7.818)	prob 3.622 (3.212)	GS 34.203 (33.284)	mem 76.612
Train: [20][50/1500]	BT 0.038 (0.775)	DT 0.000 (0.734)	loss 8.376 (7.876)	prob 3.702 (3.203)	GS 35.547 (32.998)	mem 77.191
Train: [20][60/1500]	BT 0.063 (0.655)	DT 0.006 (0.613)	loss 7.844 (7.975)	prob 3.577 (3.655)	GS 32.453 (31.445)	mem 77.196
Train: [20][70/1500]	BT 0.031 (0.638)	DT 0.000 (0.596)	loss 8.138 (8.004)	prob 3.702 (3.501)	GS 32.547 (31.836)	mem 77.242
Train: [20][80/1500]	BT 0.027 (0.590)	DT 0.000 (0.550)	loss 7.557 (7.975)	prob 4.424 (3.598)	GS 33.922 (31.734)	mem 77.252
Train: [20][90/1500]	BT 0.038 (0.532)	DT 0.000 (0.492)	loss 8.148 (7.963)	prob 4.470 (3.558)	GS 36.297 (31.864)	mem 77.255
Train: [20][100/1500]	BT 0.042 (0.529)	DT 0.011 (0.490)	loss 8.529 (7.949)	prob 3.795 (3.605)	GS 34.547 (31.989)	mem 77.259
Train: [20][110/1500]	BT 0.059 (0.489)	DT 0.005 (0.448)	loss 8.061 (8.084)	prob 3.335 (3.507)	GS 35.391 (32.031)	mem 77.262
Train: [20][120/1500]	BT 0.037 (0.483)	DT 0.001 (0.442)	loss 9.382 (8.102)	prob 2.192 (3.407)	GS 32.984 (32.485)	mem 77.265
Train: [20][130/1500]	BT 0.027 (0.458)	DT 0.000 (0.417)	loss 7.993 (8.070)	prob 3.761 (3.416)	GS 29.047 (31.950)	mem 77.265
Train: [20][140/1500]	BT 0.034 (0.451)	DT 0.001 (0.411)	loss 7.954 (8.026)	prob 3.124 (3.361)	GS 35.047 (32.383)	mem 77.273
Train: [20][150/1500]	BT 0.028 (0.425)	DT 0.000 (0.385)	loss 9.161 (8.067)	prob 3.302 (3.234)	GS 34.672 (32.587)	mem 77.276
Train: [20][160/1500]	BT 0.272 (0.402)	DT 0.235 (0.363)	loss 7.534 (7.962)	prob 4.597 (3.287)	GS 32.188 (31.269)	mem 77.277
Train: [20][170/1500]	BT 0.038 (0.413)	DT 0.001 (0.374)	loss 7.913 (8.102)	prob 2.629 (3.122)	GS 37.047 (31.866)	mem 77.283
Train: [20][180/1500]	BT 0.034 (0.392)	DT 0.001 (0.353)	loss 8.364 (8.093)	prob 2.322 (2.910)	GS 37.578 (32.569)	mem 77.284
Train: [20][190/1500]	BT 0.037 (0.386)	DT 0.000 (0.347)	loss 8.044 (8.063)	prob 4.421 (2.872)	GS 34.406 (32.496)	mem 77.286
Train: [20][200/1500]	BT 0.037 (0.383)	DT 0.001 (0.345)	loss 7.726 (8.056)	prob 3.731 (2.862)	GS 31.906 (32.678)	mem 77.287
Train: [20][210/1500]	BT 0.038 (0.368)	DT 0.001 (0.330)	loss 8.303 (8.065)	prob 2.719 (2.483)	GS 33.859 (32.766)	mem 77.287
Train: [20][220/1500]	BT 0.037 (0.372)	DT 0.001 (0.334)	loss 7.983 (8.137)	prob 3.573 (2.513)	GS 32.891 (32.730)	mem 77.107
Train: [20][230/1500]	BT 0.037 (0.361)	DT 0.000 (0.323)	loss 7.847 (8.109)	prob 3.554 (2.686)	GS 33.516 (33.010)	mem 76.182
Train: [20][240/1500]	BT 0.037 (0.355)	DT 0.001 (0.317)	loss 8.295 (8.150)	prob 1.697 (2.585)	GS 37.578 (33.378)	mem 76.181
Train: [20][250/1500]	BT 0.038 (0.343)	DT 0.001 (0.305)	loss 9.085 (8.163)	prob 2.850 (2.631)	GS 33.281 (33.322)	mem 76.181
Train: [20][260/1500]	BT 0.037 (0.335)	DT 0.001 (0.297)	loss 8.054 (8.232)	prob 3.488 (2.910)	GS 33.328 (32.894)	mem 76.182
Train: [20][270/1500]	BT 0.551 (0.334)	DT 0.514 (0.296)	loss 8.401 (8.273)	prob 3.316 (2.445)	GS 31.281 (33.059)	mem 76.186
Train: [20][280/1500]	BT 0.039 (0.330)	DT 0.000 (0.292)	loss 8.764 (8.279)	prob 3.585 (2.503)	GS 33.766 (32.471)	mem 76.187
Train: [20][290/1500]	BT 0.037 (0.322)	DT 0.001 (0.284)	loss 8.293 (8.234)	prob 3.011 (2.626)	GS 33.078 (32.148)	mem 76.187
Train: [20][300/1500]	BT 0.038 (0.317)	DT 0.001 (0.279)	loss 8.551 (8.210)	prob 2.294 (2.644)	GS 35.109 (32.090)	mem 76.188
Train: [20][310/1500]	BT 0.035 (0.318)	DT 0.001 (0.279)	loss 8.404 (8.258)	prob 2.707 (1.955)	GS 31.297 (32.253)	mem 76.193
Train: [20][320/1500]	BT 0.037 (0.323)	DT 0.001 (0.285)	loss 9.525 (8.290)	prob 2.802 (2.458)	GS 34.344 (32.370)	mem 76.197
Train: [20][330/1500]	BT 0.037 (0.315)	DT 0.000 (0.276)	loss 9.035 (8.282)	prob 2.241 (2.565)	GS 35.453 (32.092)	mem 76.197
Train: [20][340/1500]	BT 1.176 (0.310)	DT 1.138 (0.272)	loss 8.177 (8.286)	prob 3.262 (2.543)	GS 31.000 (31.976)	mem 76.209
Train: [20][350/1500]	BT 0.038 (0.309)	DT 0.001 (0.271)	loss 8.548 (8.291)	prob 3.086 (2.533)	GS 32.891 (32.084)	mem 76.216
Train: [20][360/1500]	BT 0.038 (0.305)	DT 0.001 (0.267)	loss 8.828 (8.229)	prob 3.019 (2.987)	GS 35.188 (33.258)	mem 76.210
Train: [20][370/1500]	BT 0.037 (0.308)	DT 0.001 (0.270)	loss 8.410 (8.264)	prob 2.678 (2.707)	GS 33.281 (33.118)	mem 76.220
Train: [20][380/1500]	BT 0.039 (0.303)	DT 0.001 (0.264)	loss 7.947 (8.295)	prob 3.311 (2.565)	GS 30.453 (32.720)	mem 76.246
Train: [20][390/1500]	BT 0.051 (0.310)	DT 0.007 (0.272)	loss 8.727 (8.311)	prob 2.168 (2.483)	GS 35.203 (33.005)	mem 76.252
Train: [20][400/1500]	BT 0.029 (0.317)	DT 0.000 (0.279)	loss 8.700 (8.271)	prob 2.227 (2.471)	GS 37.281 (33.446)	mem 76.251
Train: [20][410/1500]	BT 0.039 (0.310)	DT 0.001 (0.272)	loss 8.183 (7.961)	prob 2.249 (2.661)	GS 35.797 (34.533)	mem 76.252
Train: [20][420/1500]	BT 0.029 (0.312)	DT 0.000 (0.274)	loss 8.536 (8.061)	prob 2.688 (2.627)	GS 30.203 (33.414)	mem 76.252
Train: [20][430/1500]	BT 0.028 (0.305)	DT 0.000 (0.268)	loss 8.407 (8.100)	prob 3.989 (2.786)	GS 34.750 (33.313)	mem 76.253
Train: [20][440/1500]	BT 0.031 (0.309)	DT 0.000 (0.271)	loss 8.454 (8.131)	prob 3.411 (2.796)	GS 33.859 (33.003)	mem 76.254
Train: [20][450/1500]	BT 0.028 (0.303)	DT 0.000 (0.265)	loss 8.524 (8.146)	prob 2.401 (2.836)	GS 34.250 (32.979)	mem 76.255
Train: [20][460/1500]	BT 0.050 (0.297)	DT 0.011 (0.260)	loss 8.579 (8.247)	prob 3.010 (2.824)	GS 33.531 (32.120)	mem 76.255
Train: [20][470/1500]	BT 0.036 (0.298)	DT 0.001 (0.261)	loss 7.872 (8.206)	prob 3.658 (2.887)	GS 30.594 (31.707)	mem 76.253
Train: [20][480/1500]	BT 0.039 (0.293)	DT 0.001 (0.255)	loss 8.367 (8.226)	prob 2.582 (2.886)	GS 38.906 (32.032)	mem 76.254
Train: [20][490/1500]	BT 0.063 (0.293)	DT 0.008 (0.255)	loss 8.607 (8.247)	prob 2.209 (2.759)	GS 34.938 (32.462)	mem 76.253
Train: [20][500/1500]	BT 0.066 (0.295)	DT 0.001 (0.257)	loss 8.409 (8.223)	prob 2.272 (2.772)	GS 34.422 (32.613)	mem 76.252
Train: [20][510/1500]	BT 0.039 (0.290)	DT 0.001 (0.252)	loss 7.973 (8.139)	prob 3.081 (2.759)	GS 32.094 (32.041)	mem 76.252
Train: [20][520/1500]	BT 0.040 (0.289)	DT 0.001 (0.252)	loss 7.730 (8.220)	prob 3.111 (2.811)	GS 32.547 (32.091)	mem 76.253
Train: [20][530/1500]	BT 0.040 (0.286)	DT 0.001 (0.248)	loss 8.003 (8.175)	prob 4.036 (2.848)	GS 34.578 (32.473)	mem 76.253
Train: [20][540/1500]	BT 0.040 (0.285)	DT 0.001 (0.247)	loss 8.557 (8.153)	prob 3.126 (2.952)	GS 34.359 (32.538)	mem 76.252
Train: [20][550/1500]	BT 0.029 (0.287)	DT 0.001 (0.249)	loss 8.657 (8.134)	prob 2.509 (2.999)	GS 36.375 (32.338)	mem 76.255
Train: [20][560/1500]	BT 0.040 (0.283)	DT 0.001 (0.245)	loss 8.620 (7.873)	prob 3.468 (3.011)	GS 34.516 (32.398)	mem 76.257
Train: [20][570/1500]	BT 0.039 (0.283)	DT 0.001 (0.245)	loss 8.093 (8.032)	prob 3.488 (3.044)	GS 33.219 (32.436)	mem 76.260
Train: [20][580/1500]	BT 0.039 (0.279)	DT 0.001 (0.241)	loss 7.968 (8.073)	prob 2.020 (2.822)	GS 29.562 (32.860)	mem 76.259
Train: [20][590/1500]	BT 0.744 (0.279)	DT 0.705 (0.242)	loss 8.488 (8.051)	prob 2.995 (2.858)	GS 35.734 (32.819)	mem 76.261
Train: [20][600/1500]	BT 0.039 (0.278)	DT 0.001 (0.240)	loss 8.569 (8.069)	prob 2.233 (2.878)	GS 35.094 (32.699)	mem 76.262
Train: [20][610/1500]	BT 0.036 (0.279)	DT 0.001 (0.241)	loss 9.123 (8.308)	prob 2.745 (3.467)	GS 36.172 (31.620)	mem 76.262
Train: [20][620/1500]	BT 0.040 (0.277)	DT 0.000 (0.240)	loss 8.549 (8.323)	prob 3.524 (3.210)	GS 34.125 (32.317)	mem 76.268
Train: [20][630/1500]	BT 0.038 (0.276)	DT 0.001 (0.238)	loss 7.877 (8.240)	prob 2.914 (3.039)	GS 33.328 (32.578)	mem 76.279
Train: [20][640/1500]	BT 0.038 (0.273)	DT 0.001 (0.235)	loss 8.707 (8.256)	prob 2.977 (2.942)	GS 36.109 (32.619)	mem 76.279
Train: [20][650/1500]	BT 0.037 (0.272)	DT 0.001 (0.235)	loss 8.108 (8.222)	prob 3.708 (2.944)	GS 32.938 (32.500)	mem 76.273
Train: [20][660/1500]	BT 0.027 (0.269)	DT 0.000 (0.231)	loss 7.918 (8.058)	prob 3.704 (2.787)	GS 32.047 (32.369)	mem 76.274
Train: [20][670/1500]	BT 0.037 (0.271)	DT 0.001 (0.234)	loss 8.082 (8.045)	prob 3.831 (2.955)	GS 34.125 (32.670)	mem 76.176
Train: [20][680/1500]	BT 0.068 (0.270)	DT 0.032 (0.232)	loss 8.373 (8.063)	prob 3.204 (2.875)	GS 39.203 (32.734)	mem 76.176
Train: [20][690/1500]	BT 0.038 (0.267)	DT 0.001 (0.229)	loss 7.992 (8.012)	prob 2.569 (3.001)	GS 32.562 (32.412)	mem 76.176
Train: [20][700/1500]	BT 0.037 (0.267)	DT 0.001 (0.230)	loss 8.013 (8.040)	prob 2.714 (2.918)	GS 29.609 (32.274)	mem 76.176
Train: [20][710/1500]	BT 0.038 (0.267)	DT 0.000 (0.229)	loss 8.845 (8.121)	prob 3.267 (3.066)	GS 37.078 (31.455)	mem 76.146
Train: [20][720/1500]	BT 0.037 (0.266)	DT 0.000 (0.229)	loss 8.714 (8.073)	prob 3.414 (3.090)	GS 32.484 (31.669)	mem 76.147
Train: [20][730/1500]	BT 0.037 (0.264)	DT 0.001 (0.227)	loss 7.776 (8.052)	prob 3.999 (3.057)	GS 33.516 (31.649)	mem 76.148
Train: [20][740/1500]	BT 0.038 (0.264)	DT 0.000 (0.226)	loss 8.611 (8.103)	prob 2.872 (3.071)	GS 33.109 (31.995)	mem 76.150
Train: [20][750/1500]	BT 0.030 (0.272)	DT 0.000 (0.235)	loss 7.896 (8.068)	prob 3.999 (3.126)	GS 34.016 (32.304)	mem 76.169
Train: [20][760/1500]	BT 0.028 (0.269)	DT 0.000 (0.232)	loss 7.718 (8.068)	prob 2.098 (2.540)	GS 33.797 (33.600)	mem 76.169
Train: [20][770/1500]	BT 0.035 (0.272)	DT 0.000 (0.235)	loss 7.872 (8.041)	prob 2.782 (2.702)	GS 32.734 (33.134)	mem 76.155
Train: [20][780/1500]	BT 0.041 (0.269)	DT 0.001 (0.232)	loss 7.810 (7.979)	prob 3.775 (2.836)	GS 35.500 (32.829)	mem 76.159
Train: [20][790/1500]	BT 0.039 (0.266)	DT 0.001 (0.229)	loss 8.547 (8.016)	prob 3.613 (2.856)	GS 36.922 (32.729)	mem 76.158
Train: [20][800/1500]	BT 0.031 (0.269)	DT 0.000 (0.231)	loss 8.221 (8.045)	prob 3.092 (2.796)	GS 34.109 (32.819)	mem 76.157
Train: [20][810/1500]	BT 0.056 (0.266)	DT 0.001 (0.229)	loss 9.109 (8.139)	prob 3.118 (2.786)	GS 32.344 (33.061)	mem 76.157
Train: [20][820/1500]	BT 0.024 (0.273)	DT 0.000 (0.236)	loss 7.577 (8.085)	prob 2.912 (2.830)	GS 35.141 (33.767)	mem 76.158
Train: [20][830/1500]	BT 0.026 (0.271)	DT 0.000 (0.233)	loss 8.161 (8.041)	prob 3.324 (2.925)	GS 33.125 (33.567)	mem 76.158
Train: [20][840/1500]	BT 0.030 (0.268)	DT 0.001 (0.231)	loss 7.751 (8.003)	prob 2.714 (2.962)	GS 33.500 (33.016)	mem 76.157
Train: [20][850/1500]	BT 0.039 (0.268)	DT 0.001 (0.231)	loss 8.027 (8.034)	prob 4.235 (3.039)	GS 33.953 (33.002)	mem 76.159
Train: [20][860/1500]	BT 0.039 (0.266)	DT 0.001 (0.229)	loss 8.332 (8.166)	prob 4.013 (2.951)	GS 27.797 (32.564)	mem 76.159
Train: [20][870/1500]	BT 0.054 (0.269)	DT 0.000 (0.232)	loss 7.497 (8.122)	prob 3.229 (2.989)	GS 36.375 (32.961)	mem 76.159
Train: [20][880/1500]	BT 0.033 (0.277)	DT 0.000 (0.239)	loss 8.251 (8.071)	prob 3.188 (2.977)	GS 31.359 (33.426)	mem 76.157
Train: [20][890/1500]	BT 0.040 (0.285)	DT 0.000 (0.248)	loss 8.249 (8.048)	prob 2.114 (2.923)	GS 34.953 (33.706)	mem 76.156
Train: [20][900/1500]	BT 0.031 (0.283)	DT 0.000 (0.245)	loss 8.416 (8.055)	prob 2.804 (2.932)	GS 38.266 (33.858)	mem 76.156
Train: [20][910/1500]	BT 0.025 (0.280)	DT 0.000 (0.243)	loss 8.653 (8.112)	prob 2.540 (2.967)	GS 39.781 (32.305)	mem 76.157
Train: [20][920/1500]	BT 0.031 (0.282)	DT 0.000 (0.245)	loss 7.741 (8.037)	prob 2.209 (2.942)	GS 35.266 (32.076)	mem 76.157
Train: [20][930/1500]	BT 0.038 (0.280)	DT 0.001 (0.243)	loss 8.346 (8.075)	prob 1.895 (2.839)	GS 33.562 (32.429)	mem 76.158
Train: [20][940/1500]	BT 0.040 (0.280)	DT 0.001 (0.243)	loss 8.589 (8.132)	prob 3.059 (2.733)	GS 34.125 (32.566)	mem 76.175
Train: [20][950/1500]	BT 0.040 (0.278)	DT 0.001 (0.241)	loss 8.760 (8.145)	prob 2.677 (2.744)	GS 32.156 (32.863)	mem 76.174
Train: [20][960/1500]	BT 0.037 (0.275)	DT 0.001 (0.238)	loss 9.100 (8.250)	prob 2.308 (3.006)	GS 32.969 (31.073)	mem 76.175
Train: [20][970/1500]	BT 0.037 (0.277)	DT 0.001 (0.240)	loss 7.639 (8.095)	prob 2.889 (2.966)	GS 34.109 (32.077)	mem 76.178
Train: [20][980/1500]	BT 0.026 (0.275)	DT 0.000 (0.238)	loss 8.274 (8.064)	prob 2.748 (2.959)	GS 33.359 (31.941)	mem 76.179
Train: [20][990/1500]	BT 0.066 (0.281)	DT 0.016 (0.244)	loss 8.261 (8.073)	prob 2.048 (2.823)	GS 31.891 (32.089)	mem 76.181
Train: [20][1000/1500]	BT 0.052 (0.278)	DT 0.003 (0.241)	loss 8.033 (8.089)	prob 3.356 (2.842)	GS 33.562 (32.243)	mem 76.180
Train: [20][1010/1500]	BT 0.033 (0.280)	DT 0.001 (0.243)	loss 8.046 (8.177)	prob 2.844 (2.794)	GS 33.859 (34.995)	mem 76.183
Train: [20][1020/1500]	BT 0.037 (0.277)	DT 0.001 (0.240)	loss 8.379 (8.155)	prob 3.379 (2.875)	GS 30.375 (33.051)	mem 76.185
Train: [20][1030/1500]	BT 0.068 (0.278)	DT 0.005 (0.241)	loss 7.963 (8.111)	prob 3.390 (2.888)	GS 35.469 (32.785)	mem 76.187
Train: [20][1040/1500]	BT 0.067 (0.277)	DT 0.011 (0.240)	loss 8.116 (8.112)	prob 2.801 (2.835)	GS 32.547 (32.558)	mem 76.187
Train: [20][1050/1500]	BT 0.037 (0.281)	DT 0.001 (0.244)	loss 8.206 (8.154)	prob 3.138 (2.790)	GS 33.062 (32.684)	mem 76.185
Train: [20][1060/1500]	BT 0.031 (0.279)	DT 0.001 (0.241)	loss 7.849 (8.066)	prob 2.733 (2.774)	GS 28.297 (31.273)	mem 76.186
Train: [20][1070/1500]	BT 0.027 (0.281)	DT 0.000 (0.244)	loss 8.738 (8.057)	prob 2.158 (2.916)	GS 37.250 (31.834)	mem 76.190
Train: [20][1080/1500]	BT 0.036 (0.279)	DT 0.001 (0.241)	loss 8.364 (8.090)	prob 3.411 (2.912)	GS 31.078 (31.747)	mem 76.191
Train: [20][1090/1500]	BT 0.037 (0.276)	DT 0.001 (0.239)	loss 8.390 (8.082)	prob 3.330 (2.977)	GS 35.375 (31.981)	mem 76.192
Train: [20][1100/1500]	BT 0.038 (0.277)	DT 0.001 (0.239)	loss 8.429 (8.144)	prob 2.691 (2.924)	GS 33.953 (31.998)	mem 76.194
Train: [20][1110/1500]	BT 0.037 (0.275)	DT 0.001 (0.238)	loss 8.096 (8.282)	prob 3.790 (3.183)	GS 35.234 (32.714)	mem 76.193
Train: [20][1120/1500]	BT 0.036 (0.278)	DT 0.001 (0.241)	loss 8.051 (8.228)	prob 3.582 (3.116)	GS 40.281 (32.742)	mem 76.194
Train: [20][1130/1500]	BT 0.038 (0.276)	DT 0.001 (0.239)	loss 8.350 (8.184)	prob 3.298 (3.071)	GS 35.047 (32.662)	mem 76.194
Train: [20][1140/1500]	BT 0.038 (0.274)	DT 0.001 (0.237)	loss 8.093 (8.173)	prob 3.145 (3.134)	GS 31.812 (32.418)	mem 76.195
Train: [20][1150/1500]	BT 0.037 (0.275)	DT 0.001 (0.238)	loss 8.433 (8.196)	prob 3.340 (3.119)	GS 34.719 (32.481)	mem 76.197
Train: [20][1160/1500]	BT 0.037 (0.274)	DT 0.001 (0.237)	loss 8.693 (8.205)	prob 4.099 (3.383)	GS 31.188 (31.305)	mem 76.197
Train: [20][1170/1500]	BT 0.037 (0.273)	DT 0.001 (0.236)	loss 7.849 (8.157)	prob 4.295 (3.279)	GS 32.516 (31.429)	mem 76.198
Train: [20][1180/1500]	BT 0.037 (0.272)	DT 0.001 (0.234)	loss 8.481 (8.185)	prob 3.679 (3.244)	GS 35.797 (31.984)	mem 76.198
Train: [20][1190/1500]	BT 0.037 (0.272)	DT 0.001 (0.235)	loss 8.012 (8.198)	prob 4.099 (3.219)	GS 35.203 (32.205)	mem 76.200
Train: [20][1200/1500]	BT 0.053 (0.271)	DT 0.006 (0.234)	loss 8.401 (8.204)	prob 3.057 (3.238)	GS 32.484 (32.248)	mem 76.201
Train: [20][1210/1500]	BT 0.058 (0.269)	DT 0.011 (0.232)	loss 8.673 (8.178)	prob 3.685 (3.120)	GS 36.547 (33.170)	mem 76.201
Train: [20][1220/1500]	BT 0.067 (0.272)	DT 0.002 (0.235)	loss 7.669 (8.130)	prob 3.732 (3.206)	GS 33.375 (32.799)	mem 76.201
Train: [20][1230/1500]	BT 0.060 (0.271)	DT 0.016 (0.234)	loss 8.492 (8.133)	prob 3.533 (3.353)	GS 37.734 (32.702)	mem 76.201
Train: [20][1240/1500]	BT 0.029 (0.280)	DT 0.000 (0.242)	loss 8.215 (8.157)	prob 4.092 (3.363)	GS 34.484 (33.052)	mem 76.196
Train: [20][1250/1500]	BT 0.026 (0.278)	DT 0.000 (0.240)	loss 8.893 (8.183)	prob 3.268 (3.422)	GS 32.328 (32.877)	mem 76.196
Train: [20][1260/1500]	BT 0.039 (0.279)	DT 0.001 (0.242)	loss 8.554 (8.235)	prob 4.040 (3.846)	GS 30.906 (31.716)	mem 76.199
Train: [20][1270/1500]	BT 0.025 (0.277)	DT 0.000 (0.240)	loss 8.646 (8.165)	prob 3.685 (3.861)	GS 32.500 (31.989)	mem 76.199
Train: [20][1280/1500]	BT 0.038 (0.275)	DT 0.001 (0.238)	loss 8.431 (8.158)	prob 3.472 (3.712)	GS 34.500 (32.331)	mem 76.200
Train: [20][1290/1500]	BT 0.032 (0.275)	DT 0.001 (0.238)	loss 8.493 (8.181)	prob 3.069 (3.530)	GS 36.125 (32.656)	mem 76.204
Train: [20][1300/1500]	BT 0.033 (0.274)	DT 0.000 (0.237)	loss 8.786 (8.195)	prob 4.212 (3.503)	GS 30.953 (32.492)	mem 76.219
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [20][1310/1500]	BT 0.047 (0.274)	DT 0.000 (0.237)	loss 9.551 (8.189)	prob 3.452 (3.563)	GS 28.734 (30.767)	mem 76.231
Train: [20][1320/1500]	BT 0.051 (0.273)	DT 0.005 (0.235)	loss 8.487 (8.191)	prob 4.031 (3.657)	GS 35.625 (31.051)	mem 76.232
Train: [20][1330/1500]	BT 0.027 (0.276)	DT 0.000 (0.239)	loss 9.379 (8.276)	prob 3.475 (3.494)	GS 33.453 (31.915)	mem 76.232
Train: [20][1340/1500]	BT 0.031 (0.274)	DT 0.000 (0.237)	loss 8.052 (8.218)	prob 3.756 (3.500)	GS 33.203 (31.930)	mem 76.233
Train: [20][1350/1500]	BT 0.029 (0.278)	DT 0.001 (0.241)	loss 7.731 (8.247)	prob 4.193 (3.510)	GS 30.578 (32.032)	mem 76.235
Train: [20][1360/1500]	BT 0.039 (0.276)	DT 0.001 (0.239)	loss 8.333 (8.110)	prob 3.052 (3.285)	GS 35.969 (32.370)	mem 76.235
Train: [20][1370/1500]	BT 0.039 (0.274)	DT 0.001 (0.237)	loss 8.293 (8.157)	prob 3.897 (3.168)	GS 34.594 (32.624)	mem 76.234
Train: [20][1380/1500]	BT 0.038 (0.276)	DT 0.001 (0.238)	loss 7.802 (8.163)	prob 3.850 (3.287)	GS 32.500 (32.557)	mem 76.241
Train: [20][1390/1500]	BT 0.029 (0.274)	DT 0.001 (0.237)	loss 7.520 (8.176)	prob 5.132 (3.367)	GS 33.000 (32.546)	mem 76.242
Train: [20][1400/1500]	BT 0.038 (0.275)	DT 0.001 (0.238)	loss 8.324 (8.165)	prob 3.708 (3.461)	GS 35.359 (32.987)	mem 76.242
Train: [20][1410/1500]	BT 0.025 (0.273)	DT 0.000 (0.236)	loss 8.272 (8.160)	prob 3.568 (3.699)	GS 36.703 (31.717)	mem 76.243
Train: [20][1420/1500]	BT 0.034 (0.276)	DT 0.002 (0.239)	loss 8.677 (8.157)	prob 3.764 (3.495)	GS 31.547 (32.047)	mem 76.232
Train: [20][1430/1500]	BT 0.030 (0.274)	DT 0.000 (0.237)	loss 8.426 (8.151)	prob 3.739 (3.407)	GS 34.875 (32.499)	mem 76.232
Train: [20][1440/1500]	BT 0.053 (0.273)	DT 0.006 (0.236)	loss 8.485 (8.171)	prob 3.320 (3.342)	GS 34.938 (32.802)	mem 76.231
Train: [20][1450/1500]	BT 0.038 (0.275)	DT 0.001 (0.238)	loss 8.310 (8.252)	prob 3.710 (3.214)	GS 33.812 (32.940)	mem 76.122
Train: [20][1460/1500]	BT 0.030 (0.275)	DT 0.000 (0.238)	loss 8.752 (8.145)	prob 3.455 (3.657)	GS 32.531 (31.553)	mem 75.867
Train: [20][1470/1500]	BT 0.026 (0.274)	DT 0.000 (0.237)	loss 8.372 (8.103)	prob 3.412 (3.348)	GS 36.281 (32.078)	mem 36.669
Train: [20][1480/1500]	BT 1.559 (0.273)	DT 1.520 (0.236)	loss 8.313 (8.153)	prob 3.587 (3.234)	GS 34.234 (32.203)	mem 11.235
Train: [20][1490/1500]	BT 0.025 (0.271)	DT 0.000 (0.235)	loss 8.404 (8.114)	prob 2.845 (3.223)	GS 37.594 (32.268)	mem 11.235
Train: [20][1500/1500]	BT 0.025 (0.270)	DT 0.000 (0.233)	loss 9.342 (8.113)	prob 1.734 (3.181)	GS 34.719 (32.500)	mem 11.234
Train: [20][1510/1500]	BT 0.026 (0.269)	DT 0.000 (0.232)	loss 8.191 (8.160)	prob 3.063 (3.555)	GS 35.531 (31.613)	mem 11.199
epoch 20, total time 405.93
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [21][1/1500]	BT 18.373 (18.373)	DT 18.317 (18.317)	loss 7.458 (7.458)	prob 2.668 (2.668)	GS 28.812 (28.812)	mem 74.493
Train: [21][10/1500]	BT 0.048 (2.329)	DT 0.002 (2.291)	loss 7.984 (7.889)	prob 3.165 (3.082)	GS 37.844 (32.998)	mem 74.896
Train: [21][20/1500]	BT 0.048 (1.185)	DT 0.000 (1.147)	loss 8.947 (8.020)	prob 2.355 (2.805)	GS 39.047 (33.686)	mem 74.898
Train: [21][30/1500]	BT 0.038 (0.965)	DT 0.000 (0.926)	loss 8.068 (8.037)	prob 3.473 (2.859)	GS 31.078 (33.321)	mem 74.987
Train: [21][40/1500]	BT 0.037 (0.748)	DT 0.001 (0.710)	loss 8.290 (8.033)	prob 3.899 (2.936)	GS 30.766 (33.264)	mem 74.988
Train: [21][50/1500]	BT 0.342 (0.624)	DT 0.304 (0.586)	loss 8.246 (8.044)	prob 3.172 (2.993)	GS 37.484 (33.156)	mem 74.995
Train: [21][60/1500]	BT 0.037 (0.577)	DT 0.000 (0.539)	loss 8.551 (8.080)	prob 3.443 (3.609)	GS 33.875 (31.200)	mem 74.899
Train: [21][70/1500]	BT 0.037 (0.500)	DT 0.001 (0.462)	loss 8.339 (8.038)	prob 3.365 (3.530)	GS 34.484 (31.677)	mem 74.906
Train: [21][80/1500]	BT 0.027 (0.500)	DT 0.000 (0.462)	loss 8.050 (8.005)	prob 2.367 (3.369)	GS 36.047 (32.216)	mem 74.923
Train: [21][90/1500]	BT 0.027 (0.448)	DT 0.000 (0.411)	loss 8.234 (7.987)	prob 3.704 (3.356)	GS 32.562 (32.164)	mem 74.924
Train: [21][100/1500]	BT 0.079 (0.408)	DT 0.020 (0.371)	loss 8.880 (7.985)	prob 3.086 (3.334)	GS 32.531 (32.037)	mem 74.928
Train: [21][110/1500]	BT 0.037 (0.418)	DT 0.001 (0.382)	loss 8.209 (8.057)	prob 3.622 (3.316)	GS 33.219 (32.500)	mem 74.930
Train: [21][120/1500]	BT 0.038 (0.390)	DT 0.001 (0.354)	loss 8.331 (8.070)	prob 2.635 (3.115)	GS 30.703 (32.700)	mem 74.930
Train: [21][130/1500]	BT 0.037 (0.402)	DT 0.001 (0.364)	loss 7.905 (8.008)	prob 3.638 (3.050)	GS 30.734 (33.020)	mem 75.182
Train: [21][140/1500]	BT 0.036 (0.383)	DT 0.001 (0.346)	loss 7.931 (8.016)	prob 3.337 (3.071)	GS 34.531 (32.882)	mem 75.643
Train: [21][150/1500]	BT 0.038 (0.360)	DT 0.001 (0.323)	loss 7.871 (8.028)	prob 4.380 (3.128)	GS 29.906 (32.459)	mem 75.888
Train: [21][160/1500]	BT 0.039 (0.360)	DT 0.001 (0.323)	loss 8.134 (7.876)	prob 2.378 (3.223)	GS 35.312 (33.587)	mem 76.038
Train: [21][170/1500]	BT 0.039 (0.349)	DT 0.001 (0.312)	loss 8.555 (8.071)	prob 2.756 (2.942)	GS 38.219 (33.855)	mem 76.135
Train: [21][180/1500]	BT 0.040 (0.340)	DT 0.001 (0.303)	loss 7.641 (8.014)	prob 3.246 (2.790)	GS 32.750 (33.389)	mem 76.137
Train: [21][190/1500]	BT 0.067 (0.339)	DT 0.011 (0.302)	loss 9.605 (8.092)	prob 2.095 (2.795)	GS 35.750 (33.239)	mem 76.140
Train: [21][200/1500]	BT 0.038 (0.331)	DT 0.000 (0.292)	loss 8.640 (8.061)	prob 2.901 (2.846)	GS 35.609 (33.046)	mem 76.127
Train: [21][210/1500]	BT 0.038 (0.342)	DT 0.001 (0.303)	loss 8.633 (8.089)	prob 3.138 (2.743)	GS 36.016 (32.297)	mem 76.128
Train: [21][220/1500]	BT 0.039 (0.328)	DT 0.001 (0.290)	loss 7.897 (8.030)	prob 3.005 (2.578)	GS 30.078 (32.041)	mem 76.128
Train: [21][230/1500]	BT 0.039 (0.316)	DT 0.001 (0.278)	loss 8.939 (8.145)	prob 2.130 (2.410)	GS 33.906 (33.059)	mem 76.131
Train: [21][240/1500]	BT 0.042 (0.316)	DT 0.001 (0.277)	loss 8.949 (8.111)	prob 2.272 (2.427)	GS 35.781 (33.011)	mem 76.133
Train: [21][250/1500]	BT 0.079 (0.312)	DT 0.011 (0.273)	loss 8.757 (8.135)	prob 3.307 (2.465)	GS 34.672 (33.127)	mem 76.135
Train: [21][260/1500]	BT 0.086 (0.312)	DT 0.016 (0.272)	loss 8.005 (8.043)	prob 3.191 (2.531)	GS 33.812 (32.727)	mem 76.135
Train: [21][270/1500]	BT 0.039 (0.312)	DT 0.001 (0.272)	loss 8.182 (8.017)	prob 2.310 (2.620)	GS 33.297 (32.536)	mem 76.137
Train: [21][280/1500]	BT 0.040 (0.304)	DT 0.001 (0.264)	loss 8.654 (8.148)	prob 2.549 (2.404)	GS 38.375 (32.745)	mem 76.138
Train: [21][290/1500]	BT 0.040 (0.299)	DT 0.001 (0.259)	loss 8.003 (8.131)	prob 3.566 (2.385)	GS 31.578 (32.421)	mem 76.140
Train: [21][300/1500]	BT 0.037 (0.302)	DT 0.001 (0.263)	loss 8.739 (8.206)	prob 3.127 (2.424)	GS 34.344 (32.437)	mem 76.160
Train: [21][310/1500]	BT 0.068 (0.294)	DT 0.032 (0.254)	loss 7.990 (8.225)	prob 3.058 (2.595)	GS 30.406 (32.116)	mem 76.160
Train: [21][320/1500]	BT 0.027 (0.299)	DT 0.000 (0.260)	loss 8.889 (8.253)	prob 1.560 (2.450)	GS 34.547 (31.915)	mem 76.165
Train: [21][330/1500]	BT 0.033 (0.291)	DT 0.001 (0.252)	loss 8.465 (8.280)	prob 2.162 (2.453)	GS 32.500 (32.071)	mem 76.165
Train: [21][340/1500]	BT 0.037 (0.294)	DT 0.001 (0.255)	loss 8.127 (8.274)	prob 2.506 (2.379)	GS 33.391 (32.411)	mem 76.170
Train: [21][350/1500]	BT 0.037 (0.287)	DT 0.001 (0.248)	loss 8.234 (8.283)	prob 2.882 (2.392)	GS 31.281 (32.237)	mem 76.169
Train: [21][360/1500]	BT 0.037 (0.280)	DT 0.001 (0.241)	loss 8.534 (8.633)	prob 3.151 (2.520)	GS 30.359 (32.233)	mem 76.170
Train: [21][370/1500]	BT 0.030 (0.286)	DT 0.000 (0.248)	loss 7.958 (8.554)	prob 3.798 (2.651)	GS 28.047 (32.085)	mem 76.176
Train: [21][380/1500]	BT 0.024 (0.280)	DT 0.000 (0.241)	loss 8.438 (8.497)	prob 3.057 (2.756)	GS 34.547 (32.389)	mem 76.178
Train: [21][390/1500]	BT 0.045 (0.285)	DT 0.000 (0.246)	loss 8.238 (8.447)	prob 3.395 (2.809)	GS 30.938 (32.173)	mem 76.183
Train: [21][400/1500]	BT 0.037 (0.279)	DT 0.000 (0.240)	loss 8.865 (8.506)	prob 3.292 (2.739)	GS 35.891 (32.318)	mem 76.183
Train: [21][410/1500]	BT 0.036 (0.276)	DT 0.001 (0.237)	loss 8.454 (8.348)	prob 2.414 (2.406)	GS 34.859 (33.856)	mem 76.183
Train: [21][420/1500]	BT 0.038 (0.280)	DT 0.000 (0.241)	loss 9.275 (8.405)	prob 3.094 (2.565)	GS 32.266 (33.275)	mem 76.183
Train: [21][430/1500]	BT 0.037 (0.274)	DT 0.001 (0.235)	loss 8.691 (8.430)	prob 2.914 (2.644)	GS 34.891 (33.397)	mem 76.184
Train: [21][440/1500]	BT 0.038 (0.275)	DT 0.001 (0.236)	loss 7.917 (8.402)	prob 3.648 (2.763)	GS 34.234 (33.203)	mem 76.184
Train: [21][450/1500]	BT 0.037 (0.270)	DT 0.001 (0.231)	loss 9.110 (8.426)	prob 2.490 (2.748)	GS 32.703 (32.921)	mem 76.184
Train: [21][460/1500]	BT 0.083 (0.282)	DT 0.003 (0.243)	loss 8.390 (8.229)	prob 4.168 (3.010)	GS 28.703 (31.481)	mem 76.185
Train: [21][470/1500]	BT 0.100 (0.278)	DT 0.010 (0.238)	loss 8.298 (8.285)	prob 3.846 (3.217)	GS 29.781 (30.764)	mem 76.185
Train: [21][480/1500]	BT 0.043 (0.328)	DT 0.002 (0.288)	loss 8.627 (8.319)	prob 3.367 (3.103)	GS 30.906 (30.853)	mem 76.185
Train: [21][490/1500]	BT 0.038 (0.332)	DT 0.000 (0.292)	loss 7.903 (8.327)	prob 3.780 (3.046)	GS 32.391 (31.704)	mem 76.190
Train: [21][500/1500]	BT 0.030 (0.326)	DT 0.000 (0.286)	loss 9.219 (8.374)	prob 2.640 (2.938)	GS 35.531 (31.799)	mem 76.192
Train: [21][510/1500]	BT 0.036 (0.320)	DT 0.000 (0.280)	loss 8.369 (8.218)	prob 3.688 (3.038)	GS 31.922 (30.766)	mem 76.193
Train: [21][520/1500]	BT 0.037 (0.320)	DT 0.001 (0.280)	loss 8.301 (8.246)	prob 3.434 (3.189)	GS 36.422 (31.691)	mem 76.195
Train: [21][530/1500]	BT 0.063 (0.315)	DT 0.013 (0.275)	loss 8.784 (8.308)	prob 2.591 (3.097)	GS 32.703 (31.965)	mem 76.195
Train: [21][540/1500]	BT 0.072 (0.321)	DT 0.016 (0.281)	loss 8.249 (8.279)	prob 3.582 (3.064)	GS 33.672 (31.955)	mem 76.197
Train: [21][550/1500]	BT 0.031 (0.316)	DT 0.001 (0.276)	loss 7.931 (8.231)	prob 3.612 (3.021)	GS 33.234 (32.273)	mem 76.197
Train: [21][560/1500]	BT 0.027 (0.320)	DT 0.000 (0.280)	loss 8.369 (8.252)	prob 3.692 (3.173)	GS 33.078 (33.205)	mem 76.199
Train: [21][570/1500]	BT 0.037 (0.315)	DT 0.000 (0.275)	loss 8.215 (8.176)	prob 3.337 (3.070)	GS 33.750 (33.430)	mem 76.200
Train: [21][580/1500]	BT 0.075 (0.322)	DT 0.011 (0.282)	loss 9.001 (8.167)	prob 3.042 (3.128)	GS 34.547 (33.423)	mem 76.201
Train: [21][590/1500]	BT 0.058 (0.318)	DT 0.011 (0.277)	loss 8.663 (8.148)	prob 2.932 (3.173)	GS 33.766 (33.110)	mem 76.202
Train: [21][600/1500]	BT 0.032 (0.313)	DT 0.000 (0.273)	loss 8.452 (8.137)	prob 3.755 (3.151)	GS 31.125 (33.052)	mem 76.202
Train: [21][610/1500]	BT 0.033 (0.321)	DT 0.000 (0.281)	loss 8.629 (8.240)	prob 3.104 (3.136)	GS 38.000 (33.983)	mem 76.202
Train: [21][620/1500]	BT 0.037 (0.317)	DT 0.001 (0.277)	loss 7.653 (8.201)	prob 4.476 (3.321)	GS 31.531 (33.781)	mem 76.202
Train: [21][630/1500]	BT 0.064 (0.320)	DT 0.004 (0.280)	loss 8.197 (8.201)	prob 4.164 (3.305)	GS 29.469 (33.406)	mem 76.235
Train: [21][640/1500]	BT 0.059 (0.316)	DT 0.001 (0.276)	loss 7.998 (8.230)	prob 3.532 (3.182)	GS 35.484 (33.014)	mem 76.235
Train: [21][650/1500]	BT 0.072 (0.312)	DT 0.006 (0.272)	loss 8.133 (8.185)	prob 2.775 (3.232)	GS 37.094 (32.793)	mem 76.237
Train: [21][660/1500]	BT 0.033 (0.317)	DT 0.001 (0.276)	loss 7.941 (8.217)	prob 4.422 (3.567)	GS 31.391 (32.536)	mem 76.235
Train: [21][670/1500]	BT 0.072 (0.315)	DT 0.002 (0.274)	loss 8.899 (8.256)	prob 2.545 (3.244)	GS 33.453 (32.721)	mem 76.235
Train: [21][680/1500]	BT 0.043 (0.333)	DT 0.001 (0.292)	loss 8.080 (8.200)	prob 3.729 (3.235)	GS 33.469 (32.967)	mem 76.237
Train: [21][690/1500]	BT 0.039 (0.329)	DT 0.001 (0.288)	loss 8.530 (8.141)	prob 3.710 (3.228)	GS 33.891 (32.843)	mem 76.238
Train: [21][700/1500]	BT 0.029 (0.330)	DT 0.000 (0.290)	loss 8.039 (8.143)	prob 3.418 (3.238)	GS 32.469 (32.721)	mem 76.239
Train: [21][710/1500]	BT 0.039 (0.326)	DT 0.001 (0.286)	loss 8.144 (8.013)	prob 4.530 (3.502)	GS 30.812 (32.025)	mem 76.241
Train: [21][720/1500]	BT 0.038 (0.327)	DT 0.000 (0.286)	loss 8.225 (7.986)	prob 3.999 (3.498)	GS 34.984 (32.063)	mem 76.240
Train: [21][730/1500]	BT 0.042 (0.323)	DT 0.001 (0.283)	loss 7.696 (7.972)	prob 3.893 (3.431)	GS 32.156 (32.311)	mem 76.241
Train: [21][740/1500]	BT 0.039 (0.319)	DT 0.001 (0.279)	loss 8.277 (7.998)	prob 3.968 (3.446)	GS 31.391 (32.406)	mem 76.241
Train: [21][750/1500]	BT 0.067 (0.320)	DT 0.009 (0.279)	loss 7.914 (7.997)	prob 3.670 (3.409)	GS 29.484 (32.479)	mem 76.240
Train: [21][760/1500]	BT 0.054 (0.317)	DT 0.006 (0.276)	loss 7.840 (7.928)	prob 3.811 (3.470)	GS 33.750 (33.217)	mem 76.239
Train: [21][770/1500]	BT 0.039 (0.318)	DT 0.001 (0.277)	loss 8.427 (8.047)	prob 3.929 (3.223)	GS 32.891 (32.873)	mem 76.241
Train: [21][780/1500]	BT 0.039 (0.314)	DT 0.001 (0.274)	loss 7.618 (8.017)	prob 4.459 (3.318)	GS 32.453 (32.603)	mem 76.240
Train: [21][790/1500]	BT 0.040 (0.312)	DT 0.001 (0.272)	loss 7.833 (7.983)	prob 3.815 (3.394)	GS 34.453 (32.263)	mem 76.240
Train: [21][800/1500]	BT 0.112 (0.317)	DT 0.018 (0.276)	loss 7.942 (7.998)	prob 4.131 (3.322)	GS 33.719 (32.462)	mem 76.239
Train: [21][810/1500]	BT 2.308 (0.317)	DT 2.275 (0.276)	loss 8.209 (7.866)	prob 3.647 (3.652)	GS 35.719 (30.727)	mem 76.239
Train: [21][820/1500]	BT 0.031 (0.327)	DT 0.000 (0.286)	loss 8.131 (7.987)	prob 4.148 (3.571)	GS 30.969 (32.082)	mem 76.255
Train: [21][830/1500]	BT 0.081 (0.324)	DT 0.011 (0.283)	loss 7.660 (7.925)	prob 3.544 (3.489)	GS 32.469 (32.220)	mem 76.257
Train: [21][840/1500]	BT 0.058 (0.324)	DT 0.011 (0.283)	loss 7.686 (7.942)	prob 3.234 (3.408)	GS 31.016 (32.311)	mem 76.247
Train: [21][850/1500]	BT 0.030 (0.335)	DT 0.000 (0.293)	loss 8.114 (7.919)	prob 3.471 (3.355)	GS 35.391 (32.687)	mem 76.245
Train: [21][860/1500]	BT 0.028 (0.331)	DT 0.000 (0.290)	loss 7.923 (7.979)	prob 2.589 (3.145)	GS 33.469 (33.273)	mem 76.244
Train: [21][870/1500]	BT 4.208 (0.332)	DT 4.176 (0.291)	loss 7.993 (7.925)	prob 4.314 (3.200)	GS 30.375 (33.288)	mem 76.247
Train: [21][880/1500]	BT 0.064 (0.329)	DT 0.004 (0.288)	loss 7.771 (7.958)	prob 3.762 (3.217)	GS 31.844 (33.029)	mem 76.247
Train: [21][890/1500]	BT 0.038 (0.326)	DT 0.001 (0.285)	loss 8.526 (7.963)	prob 2.915 (3.207)	GS 35.688 (33.557)	mem 76.249
Train: [21][900/1500]	BT 0.029 (0.336)	DT 0.000 (0.295)	loss 8.087 (7.932)	prob 3.236 (3.199)	GS 35.094 (33.827)	mem 76.257
Train: [21][910/1500]	BT 0.027 (0.332)	DT 0.000 (0.291)	loss 7.340 (7.785)	prob 3.289 (3.309)	GS 33.406 (31.359)	mem 76.258
Train: [21][920/1500]	BT 0.026 (0.334)	DT 0.000 (0.293)	loss 7.473 (7.842)	prob 3.800 (3.060)	GS 30.578 (31.569)	mem 76.251
Train: [21][930/1500]	BT 0.038 (0.330)	DT 0.001 (0.289)	loss 7.502 (7.842)	prob 2.850 (2.983)	GS 31.281 (32.144)	mem 76.251
Train: [21][940/1500]	BT 0.094 (0.327)	DT 0.025 (0.286)	loss 8.615 (7.889)	prob 2.607 (2.988)	GS 38.531 (32.466)	mem 76.249
Train: [21][950/1500]	BT 0.024 (0.329)	DT 0.000 (0.288)	loss 8.153 (7.911)	prob 3.147 (2.882)	GS 32.141 (32.478)	mem 76.253
Train: [21][960/1500]	BT 0.037 (0.326)	DT 0.001 (0.285)	loss 8.113 (8.073)	prob 3.165 (2.801)	GS 33.141 (31.111)	mem 76.254
Train: [21][970/1500]	BT 0.038 (0.325)	DT 0.001 (0.285)	loss 8.565 (8.094)	prob 2.225 (2.746)	GS 33.828 (31.910)	mem 76.266
Train: [21][980/1500]	BT 0.038 (0.323)	DT 0.001 (0.282)	loss 8.217 (8.094)	prob 1.720 (2.645)	GS 33.656 (32.558)	mem 76.266
Train: [21][990/1500]	BT 0.037 (0.325)	DT 0.000 (0.285)	loss 8.190 (8.098)	prob 4.091 (2.663)	GS 35.719 (32.320)	mem 76.264
Train: [21][1000/1500]	BT 0.037 (0.323)	DT 0.001 (0.282)	loss 8.016 (8.164)	prob 2.191 (2.660)	GS 35.547 (32.758)	mem 76.264
Train: [21][1010/1500]	BT 0.037 (0.320)	DT 0.001 (0.280)	loss 8.249 (8.131)	prob 2.647 (2.553)	GS 32.031 (32.478)	mem 76.284
Train: [21][1020/1500]	BT 0.027 (0.322)	DT 0.000 (0.281)	loss 8.705 (8.246)	prob 2.153 (2.597)	GS 32.828 (32.057)	mem 76.166
Train: [21][1030/1500]	BT 0.029 (0.319)	DT 0.000 (0.279)	loss 8.623 (8.288)	prob 2.628 (2.484)	GS 35.344 (32.189)	mem 76.168
Train: [21][1040/1500]	BT 0.038 (0.319)	DT 0.001 (0.279)	loss 8.132 (8.238)	prob 2.752 (2.480)	GS 33.312 (32.441)	mem 76.169
Train: [21][1050/1500]	BT 0.038 (0.316)	DT 0.001 (0.276)	loss 8.869 (8.259)	prob 2.296 (2.415)	GS 36.672 (32.662)	mem 76.170
Train: [21][1060/1500]	BT 0.038 (0.313)	DT 0.001 (0.273)	loss 8.712 (8.456)	prob 3.373 (2.994)	GS 37.781 (33.366)	mem 76.169
Train: [21][1070/1500]	BT 0.069 (0.315)	DT 0.011 (0.275)	loss 8.567 (8.341)	prob 3.344 (3.101)	GS 32.047 (32.548)	mem 76.171
Train: [21][1080/1500]	BT 0.029 (0.327)	DT 0.000 (0.287)	loss 8.159 (8.331)	prob 3.809 (3.070)	GS 36.609 (32.564)	mem 76.189
Train: [21][1090/1500]	BT 0.029 (0.325)	DT 0.000 (0.285)	loss 8.636 (8.306)	prob 3.010 (3.070)	GS 31.172 (32.343)	mem 76.191
Train: [21][1100/1500]	BT 0.046 (0.325)	DT 0.006 (0.285)	loss 8.504 (8.302)	prob 3.582 (3.042)	GS 36.188 (32.370)	mem 76.179
Train: [21][1110/1500]	BT 0.031 (0.323)	DT 0.000 (0.283)	loss 8.014 (8.066)	prob 2.845 (3.449)	GS 32.672 (31.230)	mem 76.180
Train: [21][1120/1500]	BT 0.060 (0.320)	DT 0.002 (0.280)	loss 7.786 (8.151)	prob 4.099 (3.377)	GS 34.641 (32.087)	mem 76.179
Train: [21][1130/1500]	BT 0.066 (0.325)	DT 0.015 (0.285)	loss 7.812 (8.235)	prob 3.253 (3.210)	GS 39.453 (32.777)	mem 76.178
Train: [21][1140/1500]	BT 0.082 (0.323)	DT 0.014 (0.283)	loss 8.430 (8.232)	prob 3.613 (3.196)	GS 34.453 (32.795)	mem 76.178
Train: [21][1150/1500]	BT 0.027 (0.325)	DT 0.001 (0.284)	loss 8.225 (8.245)	prob 2.520 (3.141)	GS 36.266 (33.010)	mem 76.178
Train: [21][1160/1500]	BT 0.038 (0.322)	DT 0.001 (0.282)	loss 8.096 (8.250)	prob 3.240 (2.958)	GS 30.031 (32.241)	mem 76.178
Train: [21][1170/1500]	BT 0.039 (0.320)	DT 0.001 (0.280)	loss 9.658 (8.458)	prob 2.947 (2.939)	GS 35.875 (33.194)	mem 76.178
Train: [21][1180/1500]	BT 0.031 (0.324)	DT 0.000 (0.283)	loss 8.211 (8.381)	prob 3.954 (3.053)	GS 28.625 (33.163)	mem 76.177
Train: [21][1190/1500]	BT 0.039 (0.321)	DT 0.001 (0.281)	loss 8.420 (8.371)	prob 3.252 (3.078)	GS 32.078 (33.183)	mem 76.178
Train: [21][1200/1500]	BT 0.028 (0.322)	DT 0.000 (0.282)	loss 9.133 (8.360)	prob 3.639 (3.137)	GS 34.203 (33.153)	mem 76.180
Train: [21][1210/1500]	BT 0.039 (0.319)	DT 0.001 (0.279)	loss 8.323 (8.116)	prob 3.379 (3.492)	GS 35.906 (33.853)	mem 76.181
Train: [21][1220/1500]	BT 0.039 (0.317)	DT 0.001 (0.277)	loss 8.231 (8.204)	prob 3.436 (3.500)	GS 33.297 (32.997)	mem 76.182
Train: [21][1230/1500]	BT 0.040 (0.317)	DT 0.001 (0.277)	loss 8.826 (8.217)	prob 3.725 (3.433)	GS 37.719 (32.998)	mem 76.184
Train: [21][1240/1500]	BT 0.039 (0.315)	DT 0.001 (0.275)	loss 8.349 (8.247)	prob 3.561 (3.455)	GS 36.062 (33.032)	mem 76.184
Train: [21][1250/1500]	BT 0.048 (0.316)	DT 0.001 (0.276)	loss 8.149 (8.209)	prob 2.899 (3.514)	GS 37.922 (32.945)	mem 76.182
Train: [21][1260/1500]	BT 0.034 (0.323)	DT 0.001 (0.283)	loss 8.308 (8.333)	prob 4.117 (3.340)	GS 31.812 (32.655)	mem 76.184
Train: [21][1270/1500]	BT 0.025 (0.321)	DT 0.000 (0.281)	loss 8.890 (8.291)	prob 3.046 (3.450)	GS 35.562 (32.629)	mem 76.185
Train: [21][1280/1500]	BT 0.049 (0.322)	DT 0.006 (0.282)	loss 8.960 (8.330)	prob 3.849 (3.384)	GS 32.375 (32.692)	mem 76.197
Train: [21][1290/1500]	BT 0.044 (0.320)	DT 0.001 (0.280)	loss 8.108 (8.327)	prob 3.738 (3.371)	GS 34.344 (32.753)	mem 76.199
Train: [21][1300/1500]	BT 0.069 (0.318)	DT 0.004 (0.278)	loss 9.155 (8.303)	prob 3.545 (3.452)	GS 32.266 (32.802)	mem 76.200
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [21][1310/1500]	BT 0.052 (0.321)	DT 0.004 (0.281)	loss 8.372 (8.264)	prob 4.542 (3.839)	GS 31.547 (31.719)	mem 76.197
Train: [21][1320/1500]	BT 0.060 (0.319)	DT 0.002 (0.279)	loss 8.235 (8.225)	prob 3.584 (3.788)	GS 38.922 (32.303)	mem 76.196
Train: [21][1330/1500]	BT 0.051 (0.321)	DT 0.008 (0.281)	loss 7.991 (8.194)	prob 4.679 (3.718)	GS 31.281 (32.556)	mem 76.197
Train: [21][1340/1500]	BT 0.063 (0.319)	DT 0.007 (0.279)	loss 7.865 (8.200)	prob 4.440 (3.774)	GS 32.188 (32.470)	mem 76.197
Train: [21][1350/1500]	BT 0.031 (0.320)	DT 0.000 (0.280)	loss 8.651 (8.182)	prob 3.076 (3.690)	GS 35.609 (32.715)	mem 76.199
Train: [21][1360/1500]	BT 0.037 (0.318)	DT 0.001 (0.278)	loss 7.946 (8.103)	prob 3.817 (3.546)	GS 32.594 (33.278)	mem 76.199
Train: [21][1370/1500]	BT 0.038 (0.316)	DT 0.001 (0.276)	loss 8.244 (8.164)	prob 3.816 (3.646)	GS 32.812 (33.365)	mem 76.200
Train: [21][1380/1500]	BT 0.037 (0.317)	DT 0.001 (0.277)	loss 8.729 (8.154)	prob 4.015 (3.738)	GS 36.062 (32.876)	mem 76.202
Train: [21][1390/1500]	BT 0.037 (0.315)	DT 0.001 (0.275)	loss 8.156 (8.105)	prob 3.783 (3.870)	GS 33.156 (32.680)	mem 76.202
Train: [21][1400/1500]	BT 0.037 (0.318)	DT 0.001 (0.277)	loss 8.388 (8.130)	prob 3.094 (3.770)	GS 33.297 (32.883)	mem 76.202
Train: [21][1410/1500]	BT 0.035 (0.316)	DT 0.001 (0.275)	loss 8.558 (8.425)	prob 4.491 (3.692)	GS 35.094 (32.148)	mem 76.202
Train: [21][1420/1500]	BT 0.056 (0.315)	DT 0.013 (0.275)	loss 8.741 (8.326)	prob 2.960 (3.544)	GS 33.172 (33.083)	mem 76.204
Train: [21][1430/1500]	BT 0.031 (0.319)	DT 0.000 (0.279)	loss 7.980 (8.236)	prob 3.724 (3.572)	GS 29.375 (33.171)	mem 76.206
Train: [21][1440/1500]	BT 0.024 (0.317)	DT 0.000 (0.277)	loss 7.597 (8.195)	prob 3.957 (3.621)	GS 33.078 (33.278)	mem 76.207
Train: [21][1450/1500]	BT 0.037 (0.315)	DT 0.001 (0.275)	loss 8.605 (8.173)	prob 3.988 (3.702)	GS 28.422 (32.845)	mem 76.210
Train: [21][1460/1500]	BT 0.028 (0.315)	DT 0.000 (0.275)	loss 8.119 (7.897)	prob 4.007 (3.804)	GS 35.656 (32.263)	mem 75.484
Train: [21][1470/1500]	BT 0.022 (0.313)	DT 0.000 (0.274)	loss 8.189 (7.971)	prob 3.391 (3.631)	GS 33.016 (33.005)	mem 75.484
Train: [21][1480/1500]	BT 0.024 (0.315)	DT 0.000 (0.275)	loss 7.948 (7.982)	prob 4.767 (3.653)	GS 32.141 (32.372)	mem 11.159
Train: [21][1490/1500]	BT 0.026 (0.313)	DT 0.000 (0.274)	loss 7.647 (7.991)	prob 4.584 (3.778)	GS 37.312 (32.038)	mem 11.160
Train: [21][1500/1500]	BT 0.026 (0.311)	DT 0.000 (0.272)	loss 8.695 (8.017)	prob 3.601 (3.800)	GS 32.875 (32.096)	mem 11.160
Train: [21][1510/1500]	BT 0.025 (0.310)	DT 0.000 (0.271)	loss 8.961 (7.968)	prob 2.445 (3.558)	GS 30.906 (30.828)	mem 11.086
epoch 21, total time 468.48
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [22][1/1500]	BT 17.974 (17.974)	DT 17.927 (17.927)	loss 7.192 (7.192)	prob 3.798 (3.798)	GS 30.875 (30.875)	mem 74.605
Train: [22][10/1500]	BT 0.040 (2.326)	DT 0.002 (2.288)	loss 7.845 (7.585)	prob 3.996 (3.953)	GS 33.562 (31.832)	mem 74.940
Train: [22][20/1500]	BT 0.037 (1.344)	DT 0.000 (1.306)	loss 7.877 (7.671)	prob 3.870 (3.764)	GS 36.656 (32.565)	mem 74.978
Train: [22][30/1500]	BT 0.064 (0.930)	DT 0.003 (0.889)	loss 8.046 (7.686)	prob 3.787 (3.705)	GS 36.781 (32.581)	mem 74.996
Train: [22][40/1500]	BT 0.028 (0.909)	DT 0.000 (0.867)	loss 7.491 (7.684)	prob 3.338 (3.657)	GS 35.625 (32.937)	mem 75.020
Train: [22][50/1500]	BT 0.028 (0.733)	DT 0.000 (0.694)	loss 7.923 (7.698)	prob 3.820 (3.646)	GS 34.125 (32.935)	mem 75.019
Train: [22][60/1500]	BT 0.037 (0.669)	DT 0.000 (0.628)	loss 7.689 (7.754)	prob 4.272 (3.671)	GS 34.047 (33.939)	mem 75.032
Train: [22][70/1500]	BT 0.037 (0.596)	DT 0.001 (0.556)	loss 7.698 (7.685)	prob 4.055 (3.700)	GS 33.297 (33.572)	mem 75.031
Train: [22][80/1500]	BT 0.030 (0.597)	DT 0.000 (0.557)	loss 7.854 (7.774)	prob 3.776 (3.622)	GS 33.156 (33.321)	mem 75.040
Train: [22][90/1500]	BT 0.027 (0.534)	DT 0.000 (0.496)	loss 7.573 (7.761)	prob 3.543 (3.658)	GS 32.719 (33.131)	mem 75.040
Train: [22][100/1500]	BT 0.037 (0.484)	DT 0.001 (0.446)	loss 7.385 (7.726)	prob 4.019 (3.683)	GS 35.750 (32.957)	mem 75.041
Train: [22][110/1500]	BT 0.031 (0.490)	DT 0.000 (0.452)	loss 7.308 (7.618)	prob 3.389 (3.725)	GS 31.734 (32.273)	mem 75.061
Train: [22][120/1500]	BT 0.052 (0.453)	DT 0.011 (0.414)	loss 7.524 (7.630)	prob 3.950 (3.710)	GS 31.172 (33.039)	mem 75.061
Train: [22][130/1500]	BT 0.030 (0.462)	DT 0.000 (0.424)	loss 7.354 (7.589)	prob 3.844 (3.701)	GS 37.312 (33.190)	mem 75.102
Train: [22][140/1500]	BT 0.028 (0.431)	DT 0.000 (0.394)	loss 8.063 (7.591)	prob 3.809 (3.612)	GS 30.719 (33.076)	mem 75.151
Train: [22][150/1500]	BT 0.039 (0.405)	DT 0.001 (0.367)	loss 7.543 (7.619)	prob 4.753 (3.628)	GS 32.672 (33.140)	mem 75.250
Train: [22][160/1500]	BT 0.039 (0.404)	DT 0.001 (0.366)	loss 7.942 (7.652)	prob 3.220 (3.434)	GS 35.125 (32.444)	mem 75.832
Train: [22][170/1500]	BT 0.039 (0.382)	DT 0.001 (0.345)	loss 8.178 (7.770)	prob 3.256 (3.019)	GS 34.688 (33.077)	mem 75.940
Train: [22][180/1500]	BT 0.029 (0.387)	DT 0.000 (0.350)	loss 7.972 (7.761)	prob 2.760 (3.009)	GS 34.547 (32.608)	mem 76.237
Train: [22][190/1500]	BT 0.039 (0.369)	DT 0.001 (0.331)	loss 8.442 (7.814)	prob 2.988 (2.961)	GS 33.250 (32.263)	mem 76.237
Train: [22][200/1500]	BT 0.087 (0.368)	DT 0.003 (0.331)	loss 7.582 (7.823)	prob 3.170 (2.933)	GS 36.750 (32.627)	mem 76.287
Train: [22][210/1500]	BT 0.068 (0.354)	DT 0.001 (0.315)	loss 8.207 (8.170)	prob 2.662 (2.086)	GS 32.109 (33.822)	mem 76.288
Train: [22][220/1500]	BT 0.064 (0.348)	DT 0.003 (0.308)	loss 8.393 (8.113)	prob 3.806 (2.314)	GS 34.734 (33.427)	mem 76.289
Train: [22][230/1500]	BT 0.030 (0.379)	DT 0.000 (0.338)	loss 7.645 (8.052)	prob 2.791 (2.532)	GS 33.062 (33.909)	mem 76.293
Train: [22][240/1500]	BT 0.038 (0.364)	DT 0.000 (0.324)	loss 8.199 (8.055)	prob 1.454 (2.481)	GS 37.469 (33.804)	mem 76.294
Train: [22][250/1500]	BT 0.039 (0.362)	DT 0.001 (0.323)	loss 8.620 (8.017)	prob 1.817 (2.495)	GS 39.562 (33.566)	mem 76.298
Train: [22][260/1500]	BT 0.038 (0.350)	DT 0.001 (0.311)	loss 8.970 (8.053)	prob 3.409 (2.913)	GS 32.438 (32.477)	mem 76.298
Train: [22][270/1500]	BT 0.039 (0.338)	DT 0.001 (0.299)	loss 8.703 (8.125)	prob 3.034 (2.919)	GS 35.109 (32.244)	mem 76.298
Train: [22][280/1500]	BT 0.030 (0.348)	DT 0.000 (0.309)	loss 8.244 (8.118)	prob 2.246 (2.699)	GS 31.656 (32.491)	mem 76.301
Train: [22][290/1500]	BT 0.039 (0.337)	DT 0.001 (0.298)	loss 8.833 (8.143)	prob 2.177 (2.608)	GS 32.719 (32.280)	mem 76.301
Train: [22][300/1500]	BT 0.063 (0.346)	DT 0.009 (0.306)	loss 8.731 (8.163)	prob 3.338 (2.585)	GS 32.984 (32.232)	mem 76.300
Train: [22][310/1500]	BT 0.035 (0.336)	DT 0.000 (0.296)	loss 8.236 (8.100)	prob 3.584 (3.026)	GS 32.312 (31.892)	mem 76.300
Train: [22][320/1500]	BT 0.064 (0.327)	DT 0.010 (0.287)	loss 8.397 (8.116)	prob 2.502 (2.740)	GS 32.844 (32.116)	mem 76.302
Train: [22][330/1500]	BT 0.031 (0.342)	DT 0.000 (0.303)	loss 7.846 (8.102)	prob 2.404 (2.571)	GS 32.500 (32.981)	mem 76.305
Train: [22][340/1500]	BT 0.027 (0.333)	DT 0.000 (0.294)	loss 7.977 (8.104)	prob 2.219 (2.556)	GS 28.719 (32.832)	mem 76.307
Train: [22][350/1500]	BT 0.030 (0.337)	DT 0.000 (0.298)	loss 7.974 (8.130)	prob 3.412 (2.568)	GS 37.328 (32.785)	mem 76.301
Train: [22][360/1500]	BT 0.038 (0.328)	DT 0.000 (0.290)	loss 8.456 (8.025)	prob 2.758 (3.031)	GS 35.391 (32.814)	mem 76.301
Train: [22][370/1500]	BT 0.065 (0.334)	DT 0.000 (0.295)	loss 8.445 (8.077)	prob 3.787 (2.916)	GS 30.594 (32.655)	mem 76.308
Train: [22][380/1500]	BT 0.048 (0.327)	DT 0.001 (0.288)	loss 7.823 (8.134)	prob 3.148 (2.980)	GS 34.797 (32.623)	mem 76.308
Train: [22][390/1500]	BT 0.054 (0.320)	DT 0.003 (0.281)	loss 8.335 (8.125)	prob 2.745 (2.821)	GS 34.625 (32.641)	mem 76.308
Train: [22][400/1500]	BT 0.031 (0.331)	DT 0.000 (0.292)	loss 7.782 (8.121)	prob 4.138 (2.842)	GS 29.234 (32.554)	mem 76.308
Train: [22][410/1500]	BT 0.067 (0.325)	DT 0.010 (0.285)	loss 8.471 (8.246)	prob 2.546 (2.421)	GS 33.156 (33.272)	mem 76.309
Train: [22][420/1500]	BT 0.026 (0.349)	DT 0.000 (0.310)	loss 7.923 (8.171)	prob 1.674 (2.568)	GS 32.453 (32.704)	mem 76.319
Train: [22][430/1500]	BT 0.026 (0.342)	DT 0.000 (0.303)	loss 8.814 (8.193)	prob 2.907 (2.578)	GS 30.438 (32.577)	mem 76.321
Train: [22][440/1500]	BT 0.038 (0.346)	DT 0.001 (0.307)	loss 8.302 (8.125)	prob 2.903 (2.687)	GS 38.547 (32.586)	mem 76.343
Train: [22][450/1500]	BT 0.027 (0.339)	DT 0.000 (0.300)	loss 8.300 (8.083)	prob 2.956 (2.713)	GS 34.062 (32.478)	mem 76.343
Train: [22][460/1500]	BT 0.038 (0.333)	DT 0.000 (0.294)	loss 8.328 (8.072)	prob 2.901 (3.333)	GS 30.734 (29.962)	mem 76.344
Train: [22][470/1500]	BT 0.036 (0.335)	DT 0.000 (0.296)	loss 8.614 (8.162)	prob 3.288 (3.281)	GS 35.984 (31.152)	mem 76.226
Train: [22][480/1500]	BT 0.054 (0.329)	DT 0.000 (0.290)	loss 7.374 (8.083)	prob 3.589 (3.155)	GS 27.391 (30.825)	mem 76.226
Train: [22][490/1500]	BT 0.028 (0.335)	DT 0.000 (0.297)	loss 7.902 (8.147)	prob 2.834 (3.065)	GS 36.719 (31.361)	mem 76.226
Train: [22][500/1500]	BT 0.037 (0.330)	DT 0.001 (0.291)	loss 8.553 (8.125)	prob 3.595 (3.099)	GS 32.438 (31.418)	mem 76.227
Train: [22][510/1500]	BT 0.043 (0.329)	DT 0.000 (0.291)	loss 8.130 (8.140)	prob 3.234 (3.125)	GS 34.562 (32.289)	mem 76.225
Train: [22][520/1500]	BT 0.032 (0.324)	DT 0.000 (0.285)	loss 7.701 (8.179)	prob 3.403 (3.081)	GS 31.375 (31.991)	mem 76.226
Train: [22][530/1500]	BT 0.060 (0.319)	DT 0.016 (0.280)	loss 8.125 (8.175)	prob 4.111 (3.068)	GS 28.188 (32.145)	mem 76.226
Train: [22][540/1500]	BT 0.060 (0.332)	DT 0.001 (0.293)	loss 8.830 (8.162)	prob 2.899 (3.089)	GS 34.156 (32.329)	mem 76.227
Train: [22][550/1500]	BT 0.048 (0.327)	DT 0.001 (0.288)	loss 7.973 (8.204)	prob 3.023 (2.977)	GS 34.953 (32.536)	mem 76.227
Train: [22][560/1500]	BT 0.026 (0.357)	DT 0.000 (0.318)	loss 8.254 (8.013)	prob 3.011 (3.044)	GS 34.484 (33.189)	mem 76.234
Train: [22][570/1500]	BT 0.027 (0.351)	DT 0.000 (0.312)	loss 8.561 (8.066)	prob 3.570 (3.047)	GS 33.891 (33.112)	mem 76.237
Train: [22][580/1500]	BT 0.049 (0.355)	DT 0.008 (0.316)	loss 8.308 (8.059)	prob 3.163 (3.046)	GS 34.719 (32.926)	mem 76.239
Train: [22][590/1500]	BT 0.035 (0.350)	DT 0.001 (0.311)	loss 7.816 (8.067)	prob 4.417 (3.079)	GS 35.031 (32.788)	mem 76.240
Train: [22][600/1500]	BT 0.038 (0.344)	DT 0.001 (0.305)	loss 7.646 (8.065)	prob 4.408 (3.093)	GS 32.297 (32.675)	mem 76.241
Train: [22][610/1500]	BT 0.031 (0.347)	DT 0.000 (0.309)	loss 8.757 (7.986)	prob 2.949 (3.191)	GS 34.984 (32.962)	mem 76.241
Train: [22][620/1500]	BT 0.037 (0.342)	DT 0.001 (0.304)	loss 8.103 (7.988)	prob 3.657 (3.230)	GS 32.453 (32.595)	mem 76.242
Train: [22][630/1500]	BT 0.082 (0.343)	DT 0.013 (0.305)	loss 7.519 (7.953)	prob 3.729 (3.308)	GS 27.891 (32.383)	mem 76.244
Train: [22][640/1500]	BT 0.038 (0.339)	DT 0.000 (0.300)	loss 8.092 (7.961)	prob 3.910 (3.364)	GS 36.906 (32.002)	mem 76.245
Train: [22][650/1500]	BT 0.023 (0.344)	DT 0.000 (0.305)	loss 8.135 (7.971)	prob 3.192 (3.300)	GS 32.203 (31.957)	mem 76.241
Train: [22][660/1500]	BT 0.026 (0.339)	DT 0.000 (0.300)	loss 7.540 (8.009)	prob 3.538 (3.185)	GS 32.203 (31.575)	mem 76.241
Train: [22][670/1500]	BT 0.039 (0.335)	DT 0.001 (0.296)	loss 8.057 (8.074)	prob 3.271 (2.932)	GS 33.531 (33.396)	mem 76.242
Train: [22][680/1500]	BT 0.039 (0.334)	DT 0.001 (0.296)	loss 8.602 (8.060)	prob 3.305 (2.973)	GS 37.312 (32.889)	mem 76.243
Train: [22][690/1500]	BT 0.029 (0.330)	DT 0.000 (0.291)	loss 8.371 (8.007)	prob 3.937 (3.014)	GS 34.656 (32.744)	mem 76.244
Train: [22][700/1500]	BT 0.072 (0.336)	DT 0.003 (0.297)	loss 7.813 (7.971)	prob 3.912 (3.141)	GS 33.078 (32.183)	mem 76.246
Train: [22][710/1500]	BT 0.072 (0.332)	DT 0.016 (0.293)	loss 8.525 (7.977)	prob 3.610 (3.305)	GS 35.531 (31.328)	mem 76.246
Train: [22][720/1500]	BT 0.040 (0.330)	DT 0.001 (0.291)	loss 7.891 (7.917)	prob 3.543 (3.332)	GS 30.688 (31.642)	mem 76.248
Train: [22][730/1500]	BT 0.028 (0.343)	DT 0.000 (0.304)	loss 7.553 (7.859)	prob 3.408 (3.228)	GS 36.047 (31.530)	mem 76.260
Train: [22][740/1500]	BT 0.033 (0.338)	DT 0.000 (0.300)	loss 8.371 (7.890)	prob 3.172 (3.032)	GS 36.688 (32.148)	mem 76.261
Train: [22][750/1500]	BT 0.029 (0.340)	DT 0.000 (0.301)	loss 8.745 (7.912)	prob 3.720 (2.957)	GS 33.328 (31.969)	mem 76.268
Train: [22][760/1500]	BT 0.024 (0.336)	DT 0.000 (0.297)	loss 8.390 (7.848)	prob 3.374 (3.283)	GS 37.266 (33.672)	mem 76.267
Train: [22][770/1500]	BT 0.039 (0.335)	DT 0.001 (0.297)	loss 7.896 (7.800)	prob 2.664 (2.928)	GS 30.578 (33.492)	mem 76.270
Train: [22][780/1500]	BT 0.038 (0.331)	DT 0.001 (0.293)	loss 7.503 (7.828)	prob 3.189 (2.947)	GS 33.859 (33.244)	mem 76.271
Train: [22][790/1500]	BT 0.037 (0.328)	DT 0.001 (0.289)	loss 8.408 (7.791)	prob 3.393 (3.021)	GS 32.266 (32.691)	mem 76.271
Train: [22][800/1500]	BT 0.055 (0.332)	DT 0.001 (0.294)	loss 8.021 (7.823)	prob 2.948 (2.998)	GS 35.172 (32.611)	mem 76.272
Train: [22][810/1500]	BT 0.080 (0.329)	DT 0.002 (0.290)	loss 7.930 (7.827)	prob 2.773 (2.846)	GS 35.453 (33.289)	mem 76.271
Train: [22][820/1500]	BT 0.027 (0.340)	DT 0.000 (0.301)	loss 8.321 (7.967)	prob 3.300 (2.603)	GS 33.891 (33.004)	mem 76.271
Train: [22][830/1500]	BT 0.025 (0.336)	DT 0.000 (0.298)	loss 8.041 (7.904)	prob 2.228 (2.603)	GS 33.109 (33.319)	mem 76.272
Train: [22][840/1500]	BT 0.055 (0.343)	DT 0.002 (0.304)	loss 7.596 (7.884)	prob 3.885 (2.619)	GS 33.328 (32.957)	mem 76.272
Train: [22][850/1500]	BT 0.064 (0.339)	DT 0.016 (0.301)	loss 7.241 (7.824)	prob 3.181 (2.673)	GS 29.984 (32.562)	mem 76.274
Train: [22][860/1500]	BT 0.036 (0.336)	DT 0.001 (0.297)	loss 8.259 (7.893)	prob 1.925 (2.110)	GS 36.453 (36.909)	mem 76.273
Train: [22][870/1500]	BT 0.037 (0.338)	DT 0.001 (0.299)	loss 8.522 (7.856)	prob 2.264 (2.018)	GS 37.641 (34.574)	mem 76.275
Train: [22][880/1500]	BT 0.037 (0.335)	DT 0.001 (0.296)	loss 7.724 (7.852)	prob 2.336 (2.206)	GS 38.266 (34.989)	mem 76.275
Train: [22][890/1500]	BT 0.041 (0.339)	DT 0.000 (0.300)	loss 8.829 (7.844)	prob 2.356 (2.289)	GS 38.625 (34.793)	mem 76.279
Train: [22][900/1500]	BT 0.028 (0.335)	DT 0.000 (0.297)	loss 7.387 (7.811)	prob 2.412 (2.311)	GS 33.672 (34.411)	mem 76.279
Train: [22][910/1500]	BT 0.033 (0.332)	DT 0.001 (0.293)	loss 8.552 (7.907)	prob 1.662 (1.852)	GS 36.734 (33.928)	mem 76.279
Train: [22][920/1500]	BT 0.040 (0.333)	DT 0.004 (0.295)	loss 8.177 (7.907)	prob 3.085 (2.123)	GS 34.859 (33.118)	mem 76.280
Train: [22][930/1500]	BT 0.044 (0.330)	DT 0.004 (0.291)	loss 7.583 (7.843)	prob 1.511 (2.184)	GS 32.922 (33.220)	mem 76.279
Train: [22][940/1500]	BT 0.027 (0.332)	DT 0.000 (0.294)	loss 8.037 (7.853)	prob 1.582 (2.160)	GS 33.328 (33.224)	mem 76.282
Train: [22][950/1500]	BT 0.032 (0.329)	DT 0.000 (0.291)	loss 7.846 (7.882)	prob 1.670 (2.057)	GS 33.562 (33.328)	mem 76.282
Train: [22][960/1500]	BT 0.028 (0.331)	DT 0.000 (0.293)	loss 8.350 (7.838)	prob 2.343 (2.270)	GS 33.766 (32.052)	mem 76.284
Train: [22][970/1500]	BT 0.037 (0.328)	DT 0.000 (0.290)	loss 8.359 (7.843)	prob 2.939 (2.309)	GS 31.531 (31.634)	mem 76.285
Train: [22][980/1500]	BT 0.038 (0.327)	DT 0.001 (0.289)	loss 8.244 (7.844)	prob 1.761 (2.341)	GS 35.359 (32.135)	mem 76.285
Train: [22][990/1500]	BT 0.037 (0.326)	DT 0.001 (0.287)	loss 8.456 (7.889)	prob 3.030 (2.274)	GS 33.281 (32.050)	mem 76.286
Train: [22][1000/1500]	BT 0.037 (0.326)	DT 0.001 (0.288)	loss 8.207 (7.914)	prob 2.591 (2.274)	GS 33.719 (32.403)	mem 76.287
Train: [22][1010/1500]	BT 0.038 (0.324)	DT 0.001 (0.285)	loss 7.929 (8.066)	prob 2.855 (2.220)	GS 31.547 (32.142)	mem 76.287
Train: [22][1020/1500]	BT 0.037 (0.323)	DT 0.001 (0.285)	loss 7.958 (8.126)	prob 2.977 (2.402)	GS 30.047 (31.131)	mem 76.287
Train: [22][1030/1500]	BT 0.038 (0.320)	DT 0.001 (0.282)	loss 8.498 (8.256)	prob 2.627 (2.297)	GS 33.891 (31.723)	mem 76.288
Train: [22][1040/1500]	BT 0.038 (0.319)	DT 0.001 (0.281)	loss 8.637 (8.203)	prob 2.155 (2.407)	GS 36.188 (31.942)	mem 76.289
Train: [22][1050/1500]	BT 0.029 (0.321)	DT 0.000 (0.283)	loss 8.178 (8.196)	prob 3.206 (2.415)	GS 31.875 (32.279)	mem 76.291
Train: [22][1060/1500]	BT 0.035 (0.319)	DT 0.000 (0.281)	loss 8.235 (8.232)	prob 3.298 (2.729)	GS 33.906 (32.969)	mem 76.292
Train: [22][1070/1500]	BT 0.040 (0.322)	DT 0.001 (0.284)	loss 8.479 (8.197)	prob 3.379 (2.850)	GS 35.344 (32.348)	mem 76.294
Train: [22][1080/1500]	BT 0.040 (0.320)	DT 0.004 (0.281)	loss 8.699 (8.189)	prob 2.945 (2.822)	GS 36.250 (32.347)	mem 76.294
Train: [22][1090/1500]	BT 0.074 (0.320)	DT 0.003 (0.282)	loss 8.283 (8.197)	prob 2.548 (2.895)	GS 34.672 (32.594)	mem 76.293
Train: [22][1100/1500]	BT 0.073 (0.321)	DT 0.006 (0.282)	loss 8.590 (8.211)	prob 2.479 (2.826)	GS 33.516 (32.705)	mem 76.294
Train: [22][1110/1500]	BT 0.075 (0.321)	DT 0.011 (0.283)	loss 8.368 (8.290)	prob 4.162 (2.773)	GS 33.641 (31.117)	mem 76.294
Train: [22][1120/1500]	BT 0.028 (0.328)	DT 0.000 (0.289)	loss 8.395 (8.220)	prob 3.635 (2.869)	GS 35.047 (32.460)	mem 76.296
Train: [22][1130/1500]	BT 0.027 (0.325)	DT 0.000 (0.287)	loss 8.458 (8.211)	prob 2.730 (2.970)	GS 35.391 (32.482)	mem 76.296
Train: [22][1140/1500]	BT 0.037 (0.325)	DT 0.001 (0.287)	loss 9.118 (8.306)	prob 3.390 (2.958)	GS 35.312 (32.506)	mem 76.329
Train: [22][1150/1500]	BT 0.039 (0.323)	DT 0.001 (0.284)	loss 8.347 (8.302)	prob 2.786 (2.959)	GS 38.469 (32.804)	mem 76.330
Train: [22][1160/1500]	BT 0.027 (0.320)	DT 0.000 (0.282)	loss 8.656 (8.267)	prob 2.602 (3.211)	GS 35.750 (32.913)	mem 76.331
Train: [22][1170/1500]	BT 0.026 (0.322)	DT 0.000 (0.284)	loss 7.935 (8.223)	prob 4.008 (3.329)	GS 32.000 (32.668)	mem 76.332
Train: [22][1180/1500]	BT 0.029 (0.320)	DT 0.000 (0.281)	loss 8.373 (8.195)	prob 3.254 (3.361)	GS 36.656 (32.987)	mem 76.332
Train: [22][1190/1500]	BT 0.039 (0.322)	DT 0.001 (0.284)	loss 8.334 (8.225)	prob 3.758 (3.305)	GS 31.484 (32.796)	mem 76.329
Train: [22][1200/1500]	BT 0.038 (0.319)	DT 0.001 (0.281)	loss 9.303 (8.267)	prob 3.316 (3.303)	GS 34.078 (32.874)	mem 76.330
Train: [22][1210/1500]	BT 5.394 (0.321)	DT 5.355 (0.283)	loss 8.231 (8.241)	prob 5.056 (3.695)	GS 34.594 (32.942)	mem 76.329
Train: [22][1220/1500]	BT 0.031 (0.319)	DT 0.000 (0.281)	loss 8.370 (8.138)	prob 3.948 (3.677)	GS 36.516 (32.827)	mem 76.332
Train: [22][1230/1500]	BT 0.039 (0.317)	DT 0.001 (0.279)	loss 8.205 (8.133)	prob 3.343 (3.650)	GS 33.969 (32.931)	mem 76.332
Train: [22][1240/1500]	BT 0.038 (0.318)	DT 0.001 (0.281)	loss 8.337 (8.159)	prob 4.087 (3.621)	GS 36.656 (33.048)	mem 76.332
Train: [22][1250/1500]	BT 0.039 (0.316)	DT 0.001 (0.278)	loss 8.319 (8.132)	prob 3.690 (3.653)	GS 35.234 (32.851)	mem 76.332
Train: [22][1260/1500]	BT 0.065 (0.319)	DT 0.010 (0.281)	loss 7.380 (8.178)	prob 3.933 (3.746)	GS 31.031 (32.089)	mem 76.332
Train: [22][1270/1500]	BT 0.063 (0.317)	DT 0.003 (0.278)	loss 7.903 (8.126)	prob 4.608 (3.831)	GS 33.531 (32.031)	mem 76.333
Train: [22][1280/1500]	BT 0.048 (0.315)	DT 0.000 (0.276)	loss 8.173 (8.130)	prob 4.281 (3.872)	GS 32.219 (32.357)	mem 76.333
Train: [22][1290/1500]	BT 0.075 (0.319)	DT 0.012 (0.281)	loss 8.485 (8.135)	prob 3.368 (3.810)	GS 30.781 (32.591)	mem 76.334
Train: [22][1300/1500]	BT 0.071 (0.317)	DT 0.003 (0.279)	loss 8.720 (8.156)	prob 4.338 (3.836)	GS 29.797 (32.554)	mem 76.332
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [22][1310/1500]	BT 0.038 (0.318)	DT 0.000 (0.280)	loss 8.181 (8.052)	prob 5.425 (3.883)	GS 34.750 (32.664)	mem 76.332
Train: [22][1320/1500]	BT 0.039 (0.316)	DT 0.001 (0.278)	loss 8.083 (8.109)	prob 4.515 (4.070)	GS 29.969 (31.677)	mem 76.333
Train: [22][1330/1500]	BT 4.445 (0.317)	DT 4.412 (0.279)	loss 8.021 (8.162)	prob 5.170 (4.120)	GS 32.391 (32.366)	mem 76.333
Train: [22][1340/1500]	BT 0.039 (0.315)	DT 0.000 (0.277)	loss 8.289 (8.214)	prob 4.610 (4.079)	GS 33.578 (32.435)	mem 76.334
Train: [22][1350/1500]	BT 0.039 (0.313)	DT 0.001 (0.275)	loss 8.508 (8.217)	prob 3.942 (4.055)	GS 30.812 (32.525)	mem 76.334
Train: [22][1360/1500]	BT 0.053 (0.317)	DT 0.006 (0.278)	loss 8.462 (7.989)	prob 3.843 (4.150)	GS 36.609 (31.945)	mem 76.333
Train: [22][1370/1500]	BT 0.038 (0.316)	DT 0.001 (0.277)	loss 8.464 (8.067)	prob 3.703 (3.956)	GS 38.625 (32.887)	mem 76.333
Train: [22][1380/1500]	BT 0.059 (0.316)	DT 0.004 (0.277)	loss 7.732 (8.039)	prob 4.241 (3.982)	GS 32.203 (32.641)	mem 76.335
Train: [22][1390/1500]	BT 0.038 (0.315)	DT 0.001 (0.276)	loss 7.763 (8.081)	prob 4.625 (3.995)	GS 28.875 (32.591)	mem 76.337
Train: [22][1400/1500]	BT 0.039 (0.313)	DT 0.001 (0.274)	loss 7.928 (8.109)	prob 4.906 (4.027)	GS 30.125 (32.525)	mem 76.334
Train: [22][1410/1500]	BT 0.061 (0.312)	DT 0.014 (0.273)	loss 7.714 (8.053)	prob 4.848 (4.223)	GS 34.844 (32.589)	mem 76.336
Train: [22][1420/1500]	BT 0.035 (0.312)	DT 0.000 (0.273)	loss 7.939 (8.072)	prob 4.784 (4.111)	GS 36.719 (32.823)	mem 76.337
Train: [22][1430/1500]	BT 0.065 (0.313)	DT 0.004 (0.274)	loss 8.127 (8.025)	prob 5.248 (4.218)	GS 33.750 (32.787)	mem 76.337
Train: [22][1440/1500]	BT 0.036 (0.313)	DT 0.001 (0.274)	loss 7.622 (8.029)	prob 4.968 (4.230)	GS 33.484 (32.854)	mem 76.337
Train: [22][1450/1500]	BT 0.029 (0.311)	DT 0.000 (0.272)	loss 7.979 (8.025)	prob 4.655 (4.208)	GS 28.938 (32.475)	mem 76.337
Train: [22][1460/1500]	BT 0.036 (0.311)	DT 0.001 (0.272)	loss 7.715 (7.783)	prob 4.268 (4.072)	GS 36.078 (33.464)	mem 75.944
Train: [22][1470/1500]	BT 0.027 (0.310)	DT 0.000 (0.271)	loss 7.554 (7.792)	prob 3.758 (4.042)	GS 34.250 (32.811)	mem 75.871
Train: [22][1480/1500]	BT 0.029 (0.308)	DT 0.000 (0.269)	loss 7.985 (7.864)	prob 4.038 (3.832)	GS 34.703 (32.658)	mem 42.388
Train: [22][1490/1500]	BT 0.026 (0.308)	DT 0.000 (0.269)	loss 8.196 (7.929)	prob 3.526 (3.831)	GS 33.594 (32.750)	mem 19.550
Train: [22][1500/1500]	BT 0.033 (0.306)	DT 0.000 (0.267)	loss 7.839 (7.949)	prob 4.139 (3.800)	GS 37.438 (32.812)	mem 19.513
Train: [22][1510/1500]	BT 0.029 (0.304)	DT 0.000 (0.266)	loss 7.627 (8.001)	prob 4.403 (3.829)	GS 29.500 (31.447)	mem 11.166
epoch 22, total time 459.90
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [23][1/1500]	BT 17.875 (17.875)	DT 17.825 (17.825)	loss 7.543 (7.543)	prob 4.251 (4.251)	GS 31.516 (31.516)	mem 74.786
Train: [23][10/1500]	BT 0.038 (2.224)	DT 0.000 (2.186)	loss 7.382 (7.595)	prob 3.996 (3.861)	GS 35.719 (33.253)	mem 74.943
Train: [23][20/1500]	BT 0.038 (1.133)	DT 0.000 (1.093)	loss 8.123 (7.738)	prob 3.845 (3.707)	GS 34.141 (33.076)	mem 74.944
Train: [23][30/1500]	BT 0.027 (0.934)	DT 0.000 (0.896)	loss 7.993 (7.768)	prob 3.442 (3.672)	GS 34.438 (33.519)	mem 74.984
Train: [23][40/1500]	BT 0.037 (0.708)	DT 0.000 (0.672)	loss 8.807 (7.783)	prob 3.233 (3.737)	GS 34.781 (33.012)	mem 74.984
Train: [23][50/1500]	BT 0.029 (0.573)	DT 0.000 (0.538)	loss 7.546 (7.792)	prob 4.060 (3.766)	GS 30.828 (32.731)	mem 74.986
Train: [23][60/1500]	BT 0.033 (0.576)	DT 0.000 (0.542)	loss 8.010 (7.816)	prob 3.227 (3.314)	GS 37.734 (33.839)	mem 75.006
Train: [23][70/1500]	BT 0.039 (0.500)	DT 0.000 (0.465)	loss 7.525 (7.820)	prob 4.070 (3.416)	GS 32.625 (33.104)	mem 75.008
Train: [23][80/1500]	BT 0.083 (0.514)	DT 0.014 (0.478)	loss 9.006 (7.797)	prob 3.667 (3.546)	GS 34.500 (32.872)	mem 75.014
Train: [23][90/1500]	BT 0.081 (0.465)	DT 0.013 (0.426)	loss 8.342 (7.807)	prob 4.563 (3.580)	GS 31.703 (32.705)	mem 75.012
Train: [23][100/1500]	BT 0.039 (0.462)	DT 0.001 (0.422)	loss 8.229 (7.830)	prob 3.996 (3.602)	GS 33.938 (32.886)	mem 75.020
Train: [23][110/1500]	BT 0.031 (0.453)	DT 0.000 (0.413)	loss 7.528 (7.777)	prob 3.852 (3.243)	GS 31.734 (32.464)	mem 75.074
Train: [23][120/1500]	BT 0.039 (0.418)	DT 0.001 (0.379)	loss 7.792 (7.709)	prob 4.479 (3.539)	GS 33.500 (31.788)	mem 75.080
Train: [23][130/1500]	BT 0.038 (0.420)	DT 0.001 (0.381)	loss 7.244 (7.745)	prob 3.643 (3.308)	GS 38.297 (32.694)	mem 76.017
Train: [23][140/1500]	BT 0.039 (0.393)	DT 0.001 (0.354)	loss 7.759 (7.719)	prob 3.377 (3.142)	GS 31.922 (32.764)	mem 76.067
Train: [23][150/1500]	BT 0.028 (0.401)	DT 0.000 (0.362)	loss 7.783 (7.763)	prob 3.126 (3.046)	GS 36.125 (32.779)	mem 76.186
Train: [23][160/1500]	BT 0.027 (0.378)	DT 0.000 (0.340)	loss 8.162 (7.968)	prob 2.857 (2.622)	GS 34.922 (32.364)	mem 76.235
Train: [23][170/1500]	BT 0.037 (0.358)	DT 0.000 (0.320)	loss 8.063 (7.866)	prob 2.875 (2.891)	GS 35.250 (32.016)	mem 76.237
Train: [23][180/1500]	BT 0.027 (0.361)	DT 0.000 (0.324)	loss 7.889 (7.845)	prob 2.975 (2.815)	GS 33.312 (32.127)	mem 76.243
Train: [23][190/1500]	BT 0.040 (0.344)	DT 0.001 (0.307)	loss 7.643 (7.797)	prob 3.209 (2.756)	GS 36.938 (32.612)	mem 76.244
Train: [23][200/1500]	BT 0.038 (0.343)	DT 0.001 (0.306)	loss 8.134 (7.846)	prob 3.091 (2.735)	GS 36.531 (32.580)	mem 76.248
Train: [23][210/1500]	BT 0.038 (0.329)	DT 0.001 (0.291)	loss 8.667 (7.847)	prob 1.551 (2.810)	GS 35.500 (32.566)	mem 76.248
Train: [23][220/1500]	BT 0.037 (0.315)	DT 0.001 (0.278)	loss 7.990 (7.965)	prob 2.306 (2.740)	GS 38.688 (32.734)	mem 76.247
Train: [23][230/1500]	BT 0.034 (0.336)	DT 0.000 (0.298)	loss 7.857 (7.984)	prob 3.701 (2.703)	GS 33.719 (32.836)	mem 76.251
Train: [23][240/1500]	BT 0.033 (0.323)	DT 0.000 (0.286)	loss 8.118 (7.953)	prob 2.836 (2.781)	GS 33.531 (32.957)	mem 76.251
Train: [23][250/1500]	BT 0.037 (0.336)	DT 0.001 (0.298)	loss 8.099 (7.987)	prob 3.505 (2.710)	GS 37.156 (33.282)	mem 76.253
Train: [23][260/1500]	BT 0.037 (0.325)	DT 0.000 (0.287)	loss 8.107 (8.131)	prob 2.726 (2.435)	GS 35.156 (33.342)	mem 76.253
Train: [23][270/1500]	BT 0.026 (0.341)	DT 0.000 (0.304)	loss 8.194 (8.082)	prob 3.174 (2.583)	GS 30.750 (33.163)	mem 76.258
Train: [23][280/1500]	BT 0.027 (0.330)	DT 0.000 (0.293)	loss 8.663 (8.083)	prob 2.590 (2.681)	GS 36.938 (32.806)	mem 76.258
Train: [23][290/1500]	BT 0.047 (0.320)	DT 0.002 (0.283)	loss 7.754 (8.116)	prob 2.947 (2.718)	GS 30.438 (32.569)	mem 76.259
Train: [23][300/1500]	BT 0.034 (0.323)	DT 0.000 (0.286)	loss 8.634 (8.112)	prob 3.109 (2.770)	GS 35.500 (32.583)	mem 76.263
Train: [23][310/1500]	BT 0.049 (0.327)	DT 0.008 (0.289)	loss 8.207 (8.049)	prob 3.452 (3.088)	GS 32.016 (32.902)	mem 76.263
Train: [23][320/1500]	BT 0.064 (0.319)	DT 0.004 (0.281)	loss 8.166 (8.166)	prob 3.673 (2.946)	GS 35.625 (32.738)	mem 76.264
Train: [23][330/1500]	BT 0.037 (0.322)	DT 0.001 (0.283)	loss 7.934 (8.132)	prob 4.039 (3.016)	GS 33.750 (32.459)	mem 76.268
Train: [23][340/1500]	BT 0.037 (0.314)	DT 0.001 (0.275)	loss 8.246 (8.174)	prob 3.599 (3.139)	GS 33.531 (32.429)	mem 76.268
Train: [23][350/1500]	BT 0.038 (0.307)	DT 0.001 (0.269)	loss 8.044 (8.165)	prob 3.131 (3.150)	GS 34.172 (32.476)	mem 76.269
Train: [23][360/1500]	BT 0.038 (0.306)	DT 0.000 (0.267)	loss 8.500 (8.066)	prob 3.212 (3.170)	GS 33.469 (31.930)	mem 76.270
Train: [23][370/1500]	BT 0.038 (0.304)	DT 0.001 (0.266)	loss 8.231 (8.098)	prob 3.182 (3.138)	GS 32.062 (32.430)	mem 76.272
Train: [23][380/1500]	BT 0.037 (0.299)	DT 0.001 (0.260)	loss 8.087 (8.065)	prob 3.478 (3.099)	GS 32.125 (32.559)	mem 76.273
Train: [23][390/1500]	BT 0.028 (0.300)	DT 0.000 (0.261)	loss 8.211 (8.070)	prob 3.611 (3.143)	GS 35.484 (32.488)	mem 76.275
Train: [23][400/1500]	BT 0.059 (0.293)	DT 0.021 (0.255)	loss 8.235 (8.044)	prob 3.105 (3.160)	GS 34.531 (32.512)	mem 76.276
Train: [23][410/1500]	BT 0.068 (0.293)	DT 0.001 (0.254)	loss 8.386 (7.934)	prob 3.875 (3.279)	GS 32.641 (33.416)	mem 76.279
Train: [23][420/1500]	BT 0.477 (0.290)	DT 0.439 (0.251)	loss 8.029 (7.970)	prob 4.357 (3.522)	GS 32.438 (32.087)	mem 76.280
Train: [23][430/1500]	BT 0.039 (0.291)	DT 0.000 (0.252)	loss 7.586 (7.977)	prob 3.876 (3.485)	GS 32.078 (32.165)	mem 76.282
Train: [23][440/1500]	BT 0.037 (0.286)	DT 0.001 (0.247)	loss 7.812 (8.050)	prob 4.243 (3.406)	GS 33.516 (32.469)	mem 76.284
Train: [23][450/1500]	BT 1.301 (0.292)	DT 1.251 (0.253)	loss 7.666 (8.067)	prob 4.693 (3.396)	GS 33.469 (32.688)	mem 76.285
Train: [23][460/1500]	BT 0.070 (0.289)	DT 0.015 (0.249)	loss 8.410 (8.094)	prob 4.203 (3.424)	GS 34.219 (33.120)	mem 76.283
Train: [23][470/1500]	BT 0.027 (0.321)	DT 0.000 (0.282)	loss 7.767 (8.038)	prob 3.414 (3.543)	GS 36.516 (32.666)	mem 76.281
Train: [23][480/1500]	BT 0.035 (0.315)	DT 0.000 (0.276)	loss 8.320 (7.999)	prob 3.801 (3.498)	GS 33.625 (33.013)	mem 76.282
Train: [23][490/1500]	BT 0.035 (0.309)	DT 0.000 (0.270)	loss 8.137 (8.021)	prob 3.971 (3.564)	GS 32.844 (32.636)	mem 76.283
Train: [23][500/1500]	BT 0.028 (0.312)	DT 0.000 (0.273)	loss 8.500 (8.030)	prob 3.714 (3.580)	GS 33.766 (32.586)	mem 76.317
Train: [23][510/1500]	BT 0.031 (0.307)	DT 0.000 (0.268)	loss 7.808 (7.933)	prob 4.758 (3.728)	GS 34.703 (32.116)	mem 76.318
Train: [23][520/1500]	BT 0.031 (0.310)	DT 0.000 (0.272)	loss 8.612 (8.013)	prob 3.164 (3.609)	GS 40.469 (32.917)	mem 76.319
Train: [23][530/1500]	BT 0.028 (0.305)	DT 0.000 (0.266)	loss 8.037 (7.964)	prob 4.010 (3.449)	GS 31.047 (33.350)	mem 76.319
Train: [23][540/1500]	BT 0.026 (0.300)	DT 0.000 (0.262)	loss 7.954 (7.963)	prob 4.302 (3.413)	GS 29.812 (33.283)	mem 76.320
Train: [23][550/1500]	BT 0.039 (0.300)	DT 0.001 (0.262)	loss 8.086 (7.964)	prob 3.653 (3.491)	GS 31.438 (33.017)	mem 76.322
Train: [23][560/1500]	BT 0.029 (0.295)	DT 0.000 (0.257)	loss 8.304 (7.984)	prob 3.912 (3.399)	GS 33.703 (32.655)	mem 76.322
Train: [23][570/1500]	BT 0.037 (0.296)	DT 0.001 (0.258)	loss 8.286 (7.918)	prob 3.621 (3.571)	GS 35.422 (33.230)	mem 76.325
Train: [23][580/1500]	BT 0.038 (0.292)	DT 0.001 (0.254)	loss 8.099 (7.886)	prob 3.823 (3.578)	GS 34.969 (32.968)	mem 76.325
Train: [23][590/1500]	BT 0.039 (0.293)	DT 0.001 (0.255)	loss 8.145 (7.843)	prob 2.884 (3.522)	GS 36.484 (33.000)	mem 76.324
Train: [23][600/1500]	BT 0.757 (0.290)	DT 0.719 (0.252)	loss 8.221 (7.864)	prob 3.744 (3.483)	GS 35.156 (32.986)	mem 76.324
Train: [23][610/1500]	BT 0.039 (0.286)	DT 0.001 (0.248)	loss 7.988 (8.045)	prob 3.851 (3.532)	GS 35.656 (32.378)	mem 76.324
Train: [23][620/1500]	BT 0.034 (0.287)	DT 0.001 (0.249)	loss 7.964 (7.981)	prob 3.461 (3.543)	GS 35.578 (32.430)	mem 76.325
Train: [23][630/1500]	BT 0.039 (0.286)	DT 0.001 (0.248)	loss 8.276 (7.950)	prob 3.236 (3.328)	GS 31.062 (32.554)	mem 76.325
Train: [23][640/1500]	BT 0.039 (0.285)	DT 0.001 (0.247)	loss 7.552 (7.922)	prob 4.329 (3.462)	GS 32.422 (32.346)	mem 76.325
Train: [23][650/1500]	BT 0.039 (0.286)	DT 0.001 (0.248)	loss 7.626 (7.904)	prob 3.555 (3.509)	GS 33.312 (32.197)	mem 76.327
Train: [23][660/1500]	BT 0.039 (0.282)	DT 0.001 (0.244)	loss 8.026 (7.674)	prob 3.218 (3.421)	GS 32.609 (31.066)	mem 76.327
Train: [23][670/1500]	BT 0.040 (0.286)	DT 0.001 (0.248)	loss 7.776 (7.684)	prob 3.991 (3.562)	GS 33.578 (31.395)	mem 76.328
Train: [23][680/1500]	BT 0.039 (0.283)	DT 0.001 (0.245)	loss 7.942 (7.727)	prob 2.751 (3.376)	GS 32.312 (31.936)	mem 76.328
Train: [23][690/1500]	BT 0.062 (0.286)	DT 0.008 (0.248)	loss 8.006 (7.731)	prob 2.031 (3.269)	GS 33.984 (32.200)	mem 76.328
Train: [23][700/1500]	BT 0.031 (0.284)	DT 0.000 (0.246)	loss 7.564 (7.724)	prob 4.076 (3.296)	GS 32.859 (32.119)	mem 76.330
Train: [23][710/1500]	BT 0.031 (0.293)	DT 0.000 (0.255)	loss 8.146 (7.731)	prob 2.634 (3.373)	GS 31.203 (32.084)	mem 76.331
Train: [23][720/1500]	BT 0.023 (0.289)	DT 0.000 (0.251)	loss 8.252 (7.693)	prob 2.835 (3.320)	GS 37.625 (31.986)	mem 76.330
Train: [23][730/1500]	BT 0.029 (0.286)	DT 0.001 (0.248)	loss 7.373 (7.628)	prob 3.529 (3.323)	GS 34.219 (31.955)	mem 76.330
Train: [23][740/1500]	BT 0.027 (0.290)	DT 0.000 (0.253)	loss 7.370 (7.615)	prob 3.716 (3.321)	GS 32.609 (31.976)	mem 76.328
Train: [23][750/1500]	BT 0.046 (0.287)	DT 0.001 (0.249)	loss 7.398 (7.607)	prob 3.565 (3.335)	GS 36.156 (31.905)	mem 76.328
Train: [23][760/1500]	BT 0.056 (0.290)	DT 0.001 (0.253)	loss 8.638 (7.562)	prob 2.404 (2.937)	GS 39.156 (33.112)	mem 76.331
Train: [23][770/1500]	BT 0.067 (0.290)	DT 0.011 (0.252)	loss 8.125 (7.586)	prob 2.418 (2.675)	GS 34.312 (33.995)	mem 76.332
Train: [23][780/1500]	BT 0.072 (0.287)	DT 0.011 (0.249)	loss 8.675 (7.625)	prob 2.034 (2.622)	GS 33.109 (33.512)	mem 76.333
Train: [23][790/1500]	BT 0.025 (0.291)	DT 0.000 (0.253)	loss 8.074 (7.628)	prob 2.898 (2.649)	GS 38.844 (33.843)	mem 76.354
Train: [23][800/1500]	BT 0.038 (0.287)	DT 0.001 (0.250)	loss 7.892 (7.642)	prob 3.100 (2.681)	GS 36.031 (33.684)	mem 76.355
Train: [23][810/1500]	BT 0.031 (0.290)	DT 0.000 (0.252)	loss 7.803 (7.598)	prob 3.193 (3.023)	GS 31.516 (31.980)	mem 76.295
Train: [23][820/1500]	BT 0.031 (0.287)	DT 0.000 (0.249)	loss 7.761 (7.544)	prob 2.883 (2.930)	GS 39.375 (32.320)	mem 76.296
Train: [23][830/1500]	BT 0.048 (0.284)	DT 0.006 (0.247)	loss 7.857 (7.566)	prob 3.493 (2.962)	GS 29.203 (32.145)	mem 76.236
Train: [23][840/1500]	BT 0.027 (0.288)	DT 0.000 (0.250)	loss 7.463 (7.561)	prob 2.829 (2.908)	GS 33.766 (32.265)	mem 76.254
Train: [23][850/1500]	BT 0.037 (0.285)	DT 0.001 (0.247)	loss 7.500 (7.557)	prob 3.156 (2.786)	GS 38.219 (32.708)	mem 76.257
Train: [23][860/1500]	BT 0.042 (0.287)	DT 0.001 (0.250)	loss 7.398 (7.540)	prob 3.143 (2.875)	GS 31.766 (33.103)	mem 76.255
Train: [23][870/1500]	BT 0.028 (0.294)	DT 0.000 (0.256)	loss 7.428 (7.554)	prob 3.094 (2.715)	GS 31.578 (33.654)	mem 76.255
Train: [23][880/1500]	BT 0.030 (0.291)	DT 0.000 (0.253)	loss 8.220 (7.539)	prob 2.331 (2.730)	GS 36.172 (33.426)	mem 76.261
Train: [23][890/1500]	BT 0.036 (0.288)	DT 0.001 (0.250)	loss 7.687 (7.517)	prob 3.141 (2.715)	GS 32.828 (33.037)	mem 76.274
Train: [23][900/1500]	BT 0.029 (0.289)	DT 0.000 (0.252)	loss 7.487 (7.560)	prob 2.352 (2.634)	GS 34.422 (32.843)	mem 76.277
Train: [23][910/1500]	BT 0.029 (0.287)	DT 0.000 (0.249)	loss 7.614 (7.629)	prob 2.144 (2.014)	GS 33.469 (33.142)	mem 76.279
Train: [23][920/1500]	BT 0.042 (0.287)	DT 0.001 (0.250)	loss 8.456 (7.637)	prob 1.580 (2.051)	GS 40.141 (33.116)	mem 76.278
Train: [23][930/1500]	BT 0.029 (0.285)	DT 0.000 (0.247)	loss 8.340 (7.683)	prob 2.697 (2.132)	GS 37.156 (32.496)	mem 76.279
Train: [23][940/1500]	BT 0.044 (0.287)	DT 0.005 (0.249)	loss 7.777 (7.667)	prob 1.227 (2.082)	GS 35.484 (32.558)	mem 76.280
Train: [23][950/1500]	BT 0.038 (0.287)	DT 0.000 (0.249)	loss 7.896 (7.692)	prob 2.674 (1.989)	GS 30.125 (32.348)	mem 76.265
Train: [23][960/1500]	BT 0.038 (0.284)	DT 0.001 (0.247)	loss 7.899 (7.729)	prob 2.705 (2.088)	GS 35.016 (32.334)	mem 76.266
Train: [23][970/1500]	BT 0.049 (0.293)	DT 0.000 (0.255)	loss 7.833 (7.731)	prob 2.605 (2.054)	GS 35.453 (32.427)	mem 76.267
Train: [23][980/1500]	BT 0.044 (0.290)	DT 0.001 (0.253)	loss 8.037 (7.738)	prob 1.699 (2.028)	GS 36.688 (32.461)	mem 76.266
Train: [23][990/1500]	BT 0.031 (0.300)	DT 0.000 (0.263)	loss 8.272 (7.763)	prob 2.343 (2.038)	GS 33.062 (32.564)	mem 76.267
Train: [23][1000/1500]	BT 0.031 (0.298)	DT 0.000 (0.260)	loss 7.853 (7.797)	prob 2.048 (2.053)	GS 32.625 (32.637)	mem 76.267
Train: [23][1010/1500]	BT 0.038 (0.295)	DT 0.001 (0.258)	loss 7.859 (8.033)	prob 1.236 (2.073)	GS 33.453 (33.136)	mem 76.268
Train: [23][1020/1500]	BT 0.039 (0.295)	DT 0.001 (0.258)	loss 8.815 (8.012)	prob 2.442 (2.044)	GS 29.797 (32.475)	mem 76.267
Train: [23][1030/1500]	BT 0.039 (0.293)	DT 0.001 (0.255)	loss 8.202 (8.000)	prob 2.831 (2.237)	GS 35.172 (32.135)	mem 76.267
Train: [23][1040/1500]	BT 0.082 (0.294)	DT 0.014 (0.256)	loss 8.015 (7.947)	prob 2.831 (2.296)	GS 31.922 (32.129)	mem 76.268
Train: [23][1050/1500]	BT 0.033 (0.291)	DT 0.000 (0.254)	loss 8.178 (7.967)	prob 3.418 (2.367)	GS 29.547 (32.106)	mem 76.267
Train: [23][1060/1500]	BT 0.039 (0.295)	DT 0.001 (0.257)	loss 7.970 (7.851)	prob 3.004 (2.649)	GS 30.844 (33.803)	mem 76.267
Train: [23][1070/1500]	BT 0.031 (0.293)	DT 0.001 (0.255)	loss 7.593 (7.857)	prob 2.932 (2.828)	GS 32.844 (32.574)	mem 76.267
Train: [23][1080/1500]	BT 0.039 (0.290)	DT 0.001 (0.253)	loss 8.640 (7.940)	prob 2.564 (2.736)	GS 33.672 (32.843)	mem 76.268
Train: [23][1090/1500]	BT 0.037 (0.291)	DT 0.001 (0.253)	loss 8.691 (7.991)	prob 2.432 (2.771)	GS 36.141 (32.668)	mem 76.277
Train: [23][1100/1500]	BT 0.037 (0.289)	DT 0.001 (0.252)	loss 7.733 (7.993)	prob 3.339 (2.799)	GS 31.828 (32.577)	mem 76.281
Train: [23][1110/1500]	BT 0.065 (0.291)	DT 0.012 (0.253)	loss 7.917 (7.888)	prob 3.893 (3.267)	GS 32.875 (32.025)	mem 76.283
Train: [23][1120/1500]	BT 0.068 (0.293)	DT 0.003 (0.255)	loss 8.067 (7.925)	prob 4.367 (3.264)	GS 38.062 (31.986)	mem 76.285
Train: [23][1130/1500]	BT 0.038 (0.291)	DT 0.000 (0.253)	loss 7.835 (7.912)	prob 4.232 (3.411)	GS 34.609 (31.988)	mem 76.286
Train: [23][1140/1500]	BT 0.028 (0.291)	DT 0.000 (0.253)	loss 8.652 (7.959)	prob 3.567 (3.375)	GS 37.156 (32.177)	mem 76.288
Train: [23][1150/1500]	BT 0.037 (0.290)	DT 0.001 (0.252)	loss 8.403 (7.985)	prob 2.678 (3.361)	GS 36.297 (32.519)	mem 76.291
Train: [23][1160/1500]	BT 0.064 (0.289)	DT 0.004 (0.251)	loss 8.537 (8.065)	prob 3.901 (3.292)	GS 35.266 (33.716)	mem 76.291
Train: [23][1170/1500]	BT 0.033 (0.290)	DT 0.000 (0.252)	loss 8.492 (8.144)	prob 3.624 (3.249)	GS 33.484 (33.499)	mem 76.294
Train: [23][1180/1500]	BT 0.037 (0.290)	DT 0.000 (0.252)	loss 7.816 (8.125)	prob 4.302 (3.452)	GS 33.797 (32.919)	mem 76.294
Train: [23][1190/1500]	BT 0.038 (0.288)	DT 0.001 (0.250)	loss 9.185 (8.120)	prob 3.246 (3.531)	GS 31.141 (32.884)	mem 76.294
Train: [23][1200/1500]	BT 0.037 (0.287)	DT 0.001 (0.249)	loss 7.803 (8.092)	prob 4.341 (3.676)	GS 31.703 (32.684)	mem 76.294
Train: [23][1210/1500]	BT 0.040 (0.288)	DT 0.000 (0.250)	loss 8.392 (7.952)	prob 3.684 (3.758)	GS 41.000 (33.359)	mem 76.301
Train: [23][1220/1500]	BT 0.061 (0.286)	DT 0.001 (0.248)	loss 7.908 (7.956)	prob 4.174 (3.724)	GS 33.844 (32.946)	mem 76.301
Train: [23][1230/1500]	BT 0.038 (0.286)	DT 0.001 (0.248)	loss 8.625 (7.998)	prob 3.982 (3.756)	GS 40.438 (32.810)	mem 76.300
Train: [23][1240/1500]	BT 1.556 (0.288)	DT 1.519 (0.250)	loss 8.078 (8.001)	prob 4.131 (3.749)	GS 40.500 (33.066)	mem 76.302
Train: [23][1250/1500]	BT 0.038 (0.286)	DT 0.000 (0.248)	loss 8.395 (8.019)	prob 3.462 (3.667)	GS 38.328 (33.403)	mem 76.303
Train: [23][1260/1500]	BT 0.037 (0.285)	DT 0.000 (0.247)	loss 8.454 (8.188)	prob 3.786 (3.754)	GS 33.766 (33.038)	mem 76.304
Train: [23][1270/1500]	BT 0.027 (0.286)	DT 0.000 (0.248)	loss 8.625 (8.025)	prob 3.898 (3.928)	GS 35.281 (32.788)	mem 76.307
Train: [23][1280/1500]	BT 0.037 (0.285)	DT 0.000 (0.247)	loss 8.168 (8.012)	prob 4.448 (3.950)	GS 31.500 (32.627)	mem 76.309
Train: [23][1290/1500]	BT 0.039 (0.286)	DT 0.001 (0.248)	loss 8.301 (8.031)	prob 3.886 (3.930)	GS 35.453 (32.866)	mem 76.311
Train: [23][1300/1500]	BT 0.033 (0.284)	DT 0.000 (0.246)	loss 8.158 (8.004)	prob 4.721 (3.991)	GS 34.766 (32.466)	mem 76.311
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [23][1310/1500]	BT 0.038 (0.282)	DT 0.001 (0.244)	loss 7.581 (7.893)	prob 4.696 (4.316)	GS 33.469 (31.750)	mem 76.309
Train: [23][1320/1500]	BT 0.037 (0.282)	DT 0.001 (0.244)	loss 7.225 (7.903)	prob 5.279 (4.268)	GS 33.844 (32.055)	mem 76.308
Train: [23][1330/1500]	BT 0.054 (0.282)	DT 0.016 (0.244)	loss 7.771 (7.848)	prob 4.868 (4.341)	GS 32.562 (31.982)	mem 76.308
Train: [23][1340/1500]	BT 0.031 (0.284)	DT 0.000 (0.246)	loss 8.038 (7.871)	prob 4.813 (4.337)	GS 32.250 (31.954)	mem 76.311
Train: [23][1350/1500]	BT 0.037 (0.286)	DT 0.000 (0.248)	loss 8.104 (7.870)	prob 3.571 (4.282)	GS 33.562 (32.461)	mem 76.312
Train: [23][1360/1500]	BT 0.040 (0.286)	DT 0.001 (0.248)	loss 7.543 (7.844)	prob 4.654 (3.891)	GS 33.141 (35.130)	mem 76.313
Train: [23][1370/1500]	BT 0.036 (0.285)	DT 0.000 (0.247)	loss 7.628 (7.793)	prob 5.221 (4.134)	GS 33.500 (33.365)	mem 76.313
Train: [23][1380/1500]	BT 0.036 (0.287)	DT 0.001 (0.249)	loss 7.495 (7.765)	prob 4.580 (4.131)	GS 35.781 (33.255)	mem 76.314
Train: [23][1390/1500]	BT 0.038 (0.285)	DT 0.001 (0.247)	loss 7.676 (7.765)	prob 4.625 (4.212)	GS 31.812 (32.921)	mem 76.314
Train: [23][1400/1500]	BT 0.038 (0.283)	DT 0.001 (0.245)	loss 7.965 (7.774)	prob 4.336 (4.216)	GS 31.844 (32.872)	mem 76.314
Train: [23][1410/1500]	BT 0.038 (0.284)	DT 0.001 (0.246)	loss 7.872 (7.778)	prob 5.088 (4.503)	GS 32.750 (31.762)	mem 76.344
Train: [23][1420/1500]	BT 0.038 (0.283)	DT 0.001 (0.245)	loss 8.021 (7.694)	prob 4.301 (4.607)	GS 39.359 (32.455)	mem 76.345
Train: [23][1430/1500]	BT 0.060 (0.287)	DT 0.002 (0.249)	loss 7.900 (7.690)	prob 4.702 (4.494)	GS 36.438 (32.409)	mem 76.346
Train: [23][1440/1500]	BT 0.083 (0.286)	DT 0.008 (0.247)	loss 7.831 (7.685)	prob 4.886 (4.498)	GS 34.406 (32.467)	mem 76.346
Train: [23][1450/1500]	BT 0.068 (0.291)	DT 0.005 (0.253)	loss 7.743 (7.668)	prob 5.020 (4.538)	GS 34.625 (32.239)	mem 76.198
Train: [23][1460/1500]	BT 0.029 (0.300)	DT 0.000 (0.262)	loss 7.922 (7.571)	prob 4.140 (4.476)	GS 38.828 (33.641)	mem 75.471
Train: [23][1470/1500]	BT 0.029 (0.299)	DT 0.000 (0.260)	loss 7.845 (7.625)	prob 4.851 (4.288)	GS 32.234 (33.571)	mem 75.471
Train: [23][1480/1500]	BT 0.026 (0.299)	DT 0.000 (0.261)	loss 7.293 (7.583)	prob 4.323 (4.301)	GS 34.594 (33.554)	mem 11.201
Train: [23][1490/1500]	BT 0.025 (0.297)	DT 0.000 (0.259)	loss 7.601 (7.594)	prob 4.042 (4.262)	GS 36.062 (33.371)	mem 11.201
Train: [23][1500/1500]	BT 0.025 (0.295)	DT 0.000 (0.257)	loss 7.354 (7.568)	prob 4.739 (4.289)	GS 28.344 (33.359)	mem 11.201
Train: [23][1510/1500]	BT 0.037 (0.294)	DT 0.000 (0.256)	loss 7.747 (7.521)	prob 4.508 (4.181)	GS 31.594 (34.397)	mem 11.128
epoch 23, total time 444.14
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [24][1/1500]	BT 18.128 (18.128)	DT 18.076 (18.076)	loss 7.318 (7.318)	prob 4.085 (4.085)	GS 37.594 (37.594)	mem 74.584
Train: [24][10/1500]	BT 0.036 (2.329)	DT 0.001 (2.295)	loss 7.729 (7.410)	prob 3.790 (4.248)	GS 30.938 (33.918)	mem 75.004
Train: [24][20/1500]	BT 0.035 (1.182)	DT 0.001 (1.148)	loss 7.283 (7.381)	prob 4.917 (4.355)	GS 33.984 (33.682)	mem 75.005
Train: [24][30/1500]	BT 0.026 (0.963)	DT 0.000 (0.929)	loss 7.422 (7.387)	prob 5.098 (4.499)	GS 36.859 (33.485)	mem 75.056
Train: [24][40/1500]	BT 0.028 (0.730)	DT 0.000 (0.697)	loss 7.580 (7.375)	prob 5.202 (4.570)	GS 32.109 (32.912)	mem 75.058
Train: [24][50/1500]	BT 0.039 (0.591)	DT 0.001 (0.558)	loss 7.627 (7.410)	prob 4.845 (4.612)	GS 31.031 (32.371)	mem 75.059
Train: [24][60/1500]	BT 0.039 (0.549)	DT 0.001 (0.514)	loss 7.489 (7.491)	prob 4.585 (4.454)	GS 30.516 (31.853)	mem 75.065
Train: [24][70/1500]	BT 0.039 (0.476)	DT 0.001 (0.441)	loss 7.542 (7.509)	prob 4.994 (4.446)	GS 32.812 (32.298)	mem 75.066
Train: [24][80/1500]	BT 0.039 (0.457)	DT 0.001 (0.421)	loss 7.741 (7.497)	prob 4.100 (4.446)	GS 33.469 (32.368)	mem 75.086
Train: [24][90/1500]	BT 0.037 (0.433)	DT 0.001 (0.397)	loss 7.229 (7.490)	prob 4.581 (4.440)	GS 32.938 (32.278)	mem 75.088
Train: [24][100/1500]	BT 0.037 (0.417)	DT 0.000 (0.380)	loss 7.479 (7.497)	prob 4.318 (4.444)	GS 33.703 (32.315)	mem 75.095
Train: [24][110/1500]	BT 0.036 (0.382)	DT 0.000 (0.346)	loss 7.502 (7.585)	prob 4.240 (4.222)	GS 38.500 (31.806)	mem 75.097
Train: [24][120/1500]	BT 0.036 (0.358)	DT 0.000 (0.322)	loss 7.625 (7.578)	prob 4.584 (4.278)	GS 31.500 (31.980)	mem 75.100
Train: [24][130/1500]	BT 0.024 (0.424)	DT 0.000 (0.388)	loss 7.684 (7.522)	prob 3.997 (4.217)	GS 33.469 (32.849)	mem 75.007
Train: [24][140/1500]	BT 0.026 (0.396)	DT 0.000 (0.360)	loss 7.634 (7.525)	prob 4.213 (4.159)	GS 33.516 (32.628)	mem 75.016
Train: [24][150/1500]	BT 0.037 (0.390)	DT 0.001 (0.355)	loss 7.370 (7.521)	prob 4.312 (4.101)	GS 34.641 (32.668)	mem 75.019
Train: [24][160/1500]	BT 0.037 (0.368)	DT 0.000 (0.332)	loss 7.606 (7.483)	prob 3.459 (3.761)	GS 35.375 (33.303)	mem 75.020
Train: [24][170/1500]	BT 0.037 (0.348)	DT 0.000 (0.313)	loss 7.387 (7.468)	prob 3.972 (3.657)	GS 33.734 (33.048)	mem 75.020
Train: [24][180/1500]	BT 0.038 (0.346)	DT 0.001 (0.310)	loss 7.321 (7.471)	prob 4.296 (3.710)	GS 33.938 (33.024)	mem 75.118
Train: [24][190/1500]	BT 0.037 (0.330)	DT 0.001 (0.294)	loss 7.094 (7.473)	prob 3.882 (3.712)	GS 32.312 (32.791)	mem 75.168
Train: [24][200/1500]	BT 0.037 (0.334)	DT 0.000 (0.299)	loss 7.092 (7.462)	prob 3.773 (3.620)	GS 35.141 (32.720)	mem 75.856
Train: [24][210/1500]	BT 0.038 (0.320)	DT 0.001 (0.284)	loss 7.832 (7.529)	prob 2.990 (2.924)	GS 36.719 (32.750)	mem 76.002
Train: [24][220/1500]	BT 0.037 (0.309)	DT 0.000 (0.274)	loss 7.472 (7.564)	prob 2.186 (2.733)	GS 36.375 (33.311)	mem 76.074
Train: [24][230/1500]	BT 0.031 (0.316)	DT 0.000 (0.280)	loss 8.552 (7.586)	prob 2.526 (2.626)	GS 35.109 (33.238)	mem 76.212
Train: [24][240/1500]	BT 0.072 (0.305)	DT 0.039 (0.269)	loss 7.931 (7.562)	prob 2.412 (2.598)	GS 34.953 (33.313)	mem 76.212
Train: [24][250/1500]	BT 0.027 (0.322)	DT 0.000 (0.286)	loss 7.404 (7.534)	prob 3.113 (2.654)	GS 35.250 (33.084)	mem 76.235
Train: [24][260/1500]	BT 0.037 (0.310)	DT 0.000 (0.275)	loss 7.985 (7.613)	prob 2.466 (2.343)	GS 30.203 (32.302)	mem 76.237
Train: [24][270/1500]	BT 0.038 (0.306)	DT 0.001 (0.270)	loss 7.576 (7.488)	prob 2.683 (2.393)	GS 33.906 (32.759)	mem 76.240
Train: [24][280/1500]	BT 0.038 (0.303)	DT 0.000 (0.267)	loss 7.668 (7.478)	prob 2.306 (2.334)	GS 33.578 (32.935)	mem 76.242
Train: [24][290/1500]	BT 0.038 (0.294)	DT 0.001 (0.258)	loss 7.401 (7.499)	prob 2.211 (2.280)	GS 32.172 (32.609)	mem 76.242
Train: [24][300/1500]	BT 0.084 (0.307)	DT 0.015 (0.271)	loss 7.788 (7.584)	prob 2.505 (2.182)	GS 35.922 (32.770)	mem 76.232
Train: [24][310/1500]	BT 0.077 (0.299)	DT 0.017 (0.262)	loss 7.966 (7.684)	prob 2.014 (2.061)	GS 32.438 (31.772)	mem 76.232
Train: [24][320/1500]	BT 2.875 (0.312)	DT 2.830 (0.275)	loss 7.687 (7.622)	prob 1.726 (2.105)	GS 32.984 (32.574)	mem 76.231
Train: [24][330/1500]	BT 0.041 (0.304)	DT 0.007 (0.266)	loss 8.646 (7.765)	prob 1.115 (1.988)	GS 39.578 (32.462)	mem 76.233
Train: [24][340/1500]	BT 0.036 (0.298)	DT 0.001 (0.261)	loss 8.921 (7.759)	prob 1.442 (1.894)	GS 32.391 (32.674)	mem 76.234
Train: [24][350/1500]	BT 0.033 (0.305)	DT 0.001 (0.267)	loss 7.858 (7.800)	prob 2.356 (1.861)	GS 30.609 (32.744)	mem 76.236
Train: [24][360/1500]	BT 0.038 (0.298)	DT 0.001 (0.260)	loss 8.354 (7.895)	prob 1.281 (2.097)	GS 37.531 (33.278)	mem 76.236
Train: [24][370/1500]	BT 0.039 (0.300)	DT 0.001 (0.262)	loss 7.751 (8.001)	prob 2.425 (1.790)	GS 30.594 (32.531)	mem 76.237
Train: [24][380/1500]	BT 0.038 (0.293)	DT 0.001 (0.256)	loss 8.289 (7.927)	prob 1.187 (1.864)	GS 32.484 (33.244)	mem 76.237
Train: [24][390/1500]	BT 0.953 (0.293)	DT 0.914 (0.255)	loss 8.291 (7.912)	prob 1.971 (1.919)	GS 35.078 (33.303)	mem 76.239
Train: [24][400/1500]	BT 0.039 (0.291)	DT 0.001 (0.254)	loss 8.146 (7.948)	prob 2.347 (1.975)	GS 35.406 (33.358)	mem 76.240
Train: [24][410/1500]	BT 0.039 (0.286)	DT 0.001 (0.248)	loss 7.785 (8.092)	prob 2.484 (2.328)	GS 31.188 (32.145)	mem 76.240
Train: [24][420/1500]	BT 0.031 (0.307)	DT 0.001 (0.269)	loss 7.869 (8.014)	prob 2.215 (2.336)	GS 33.141 (32.362)	mem 76.258
Train: [24][430/1500]	BT 0.030 (0.300)	DT 0.000 (0.263)	loss 7.655 (8.014)	prob 2.911 (2.324)	GS 30.578 (31.920)	mem 76.258
Train: [24][440/1500]	BT 0.036 (0.294)	DT 0.001 (0.257)	loss 8.217 (8.027)	prob 3.144 (2.295)	GS 37.688 (32.393)	mem 76.259
Train: [24][450/1500]	BT 0.030 (0.297)	DT 0.000 (0.260)	loss 7.918 (8.054)	prob 2.962 (2.257)	GS 33.672 (32.351)	mem 76.265
Train: [24][460/1500]	BT 0.031 (0.291)	DT 0.000 (0.254)	loss 8.226 (7.975)	prob 2.518 (2.702)	GS 34.844 (33.152)	mem 76.264
Train: [24][470/1500]	BT 0.031 (0.296)	DT 0.000 (0.259)	loss 8.145 (8.045)	prob 2.366 (2.445)	GS 34.953 (33.165)	mem 76.269
Train: [24][480/1500]	BT 0.034 (0.291)	DT 0.001 (0.254)	loss 7.914 (8.087)	prob 3.047 (2.519)	GS 31.656 (32.655)	mem 76.269
Train: [24][490/1500]	BT 0.033 (0.285)	DT 0.001 (0.249)	loss 8.603 (8.074)	prob 2.738 (2.646)	GS 35.703 (32.582)	mem 76.271
Train: [24][500/1500]	BT 0.025 (0.288)	DT 0.000 (0.252)	loss 7.973 (8.069)	prob 3.217 (2.713)	GS 33.703 (32.430)	mem 76.273
Train: [24][510/1500]	BT 0.027 (0.283)	DT 0.000 (0.247)	loss 7.946 (8.038)	prob 2.411 (2.916)	GS 30.812 (32.720)	mem 76.272
Train: [24][520/1500]	BT 0.025 (0.290)	DT 0.000 (0.253)	loss 7.822 (7.977)	prob 2.628 (2.988)	GS 36.016 (32.594)	mem 76.276
Train: [24][530/1500]	BT 0.028 (0.285)	DT 0.000 (0.249)	loss 8.053 (7.964)	prob 3.683 (3.048)	GS 36.188 (32.556)	mem 76.277
Train: [24][540/1500]	BT 0.040 (0.285)	DT 0.000 (0.249)	loss 8.120 (7.949)	prob 2.771 (3.006)	GS 35.922 (32.679)	mem 76.281
Train: [24][550/1500]	BT 0.034 (0.281)	DT 0.000 (0.245)	loss 8.413 (7.965)	prob 2.897 (2.958)	GS 35.297 (32.704)	mem 76.281
Train: [24][560/1500]	BT 0.034 (0.277)	DT 0.001 (0.241)	loss 7.491 (8.067)	prob 2.857 (2.935)	GS 33.062 (33.214)	mem 76.282
Train: [24][570/1500]	BT 0.038 (0.281)	DT 0.000 (0.245)	loss 8.632 (8.021)	prob 3.043 (3.050)	GS 37.109 (33.318)	mem 76.284
Train: [24][580/1500]	BT 0.028 (0.277)	DT 0.000 (0.241)	loss 8.285 (7.985)	prob 3.122 (2.970)	GS 36.422 (33.481)	mem 76.286
Train: [24][590/1500]	BT 0.066 (0.282)	DT 0.016 (0.246)	loss 8.348 (7.948)	prob 4.007 (2.975)	GS 33.094 (33.109)	mem 76.287
Train: [24][600/1500]	BT 0.033 (0.278)	DT 0.000 (0.242)	loss 8.139 (7.950)	prob 3.743 (3.035)	GS 33.766 (33.032)	mem 76.286
Train: [24][610/1500]	BT 0.026 (0.293)	DT 0.000 (0.257)	loss 7.726 (7.876)	prob 4.242 (3.321)	GS 33.656 (32.520)	mem 76.284
Train: [24][620/1500]	BT 0.034 (0.289)	DT 0.000 (0.253)	loss 7.796 (7.926)	prob 1.929 (3.206)	GS 33.141 (32.895)	mem 76.284
Train: [24][630/1500]	BT 0.027 (0.289)	DT 0.001 (0.253)	loss 8.230 (7.950)	prob 3.637 (3.134)	GS 32.734 (32.461)	mem 76.284
Train: [24][640/1500]	BT 0.030 (0.285)	DT 0.000 (0.249)	loss 8.348 (7.918)	prob 3.612 (3.257)	GS 35.141 (32.100)	mem 76.286
Train: [24][650/1500]	BT 0.025 (0.281)	DT 0.000 (0.245)	loss 7.895 (7.890)	prob 3.519 (3.178)	GS 34.531 (32.070)	mem 76.287
Train: [24][660/1500]	BT 0.051 (0.284)	DT 0.005 (0.248)	loss 7.464 (7.744)	prob 3.682 (2.894)	GS 35.125 (32.903)	mem 76.288
Train: [24][670/1500]	BT 0.038 (0.281)	DT 0.000 (0.245)	loss 7.934 (7.795)	prob 3.838 (3.000)	GS 35.328 (32.393)	mem 76.288
Train: [24][680/1500]	BT 0.058 (0.283)	DT 0.006 (0.247)	loss 7.914 (7.784)	prob 3.408 (3.126)	GS 32.109 (32.194)	mem 76.289
Train: [24][690/1500]	BT 0.052 (0.280)	DT 0.001 (0.244)	loss 7.307 (7.771)	prob 3.432 (3.110)	GS 36.703 (32.331)	mem 76.289
Train: [24][700/1500]	BT 0.057 (0.277)	DT 0.013 (0.241)	loss 7.505 (7.725)	prob 3.999 (3.140)	GS 27.781 (32.112)	mem 76.289
Train: [24][710/1500]	BT 0.038 (0.282)	DT 0.001 (0.246)	loss 7.749 (7.799)	prob 3.928 (3.529)	GS 33.797 (31.702)	mem 76.289
Train: [24][720/1500]	BT 0.038 (0.279)	DT 0.000 (0.242)	loss 7.885 (7.803)	prob 3.629 (3.476)	GS 33.969 (32.227)	mem 76.290
Train: [24][730/1500]	BT 0.037 (0.280)	DT 0.001 (0.244)	loss 7.598 (7.747)	prob 3.374 (3.498)	GS 32.141 (32.047)	mem 76.290
Train: [24][740/1500]	BT 0.038 (0.277)	DT 0.001 (0.240)	loss 7.577 (7.766)	prob 3.469 (3.396)	GS 32.500 (32.221)	mem 76.290
Train: [24][750/1500]	BT 0.038 (0.278)	DT 0.000 (0.242)	loss 8.170 (7.755)	prob 3.850 (3.366)	GS 33.312 (32.176)	mem 76.292
Train: [24][760/1500]	BT 0.038 (0.276)	DT 0.001 (0.239)	loss 7.606 (7.705)	prob 4.588 (3.702)	GS 33.484 (32.864)	mem 76.293
Train: [24][770/1500]	BT 0.037 (0.273)	DT 0.001 (0.236)	loss 7.430 (7.702)	prob 3.994 (3.586)	GS 34.062 (32.512)	mem 76.293
Train: [24][780/1500]	BT 0.031 (0.279)	DT 0.000 (0.243)	loss 8.139 (7.756)	prob 3.384 (3.531)	GS 35.734 (32.469)	mem 76.296
Train: [24][790/1500]	BT 0.038 (0.279)	DT 0.001 (0.242)	loss 7.554 (7.737)	prob 3.420 (3.451)	GS 31.469 (32.800)	mem 76.297
Train: [24][800/1500]	BT 0.039 (0.280)	DT 0.000 (0.244)	loss 7.807 (7.717)	prob 4.322 (3.482)	GS 35.344 (32.707)	mem 76.326
Train: [24][810/1500]	BT 0.039 (0.277)	DT 0.001 (0.241)	loss 7.679 (7.712)	prob 3.375 (3.449)	GS 32.625 (32.345)	mem 76.327
Train: [24][820/1500]	BT 0.040 (0.276)	DT 0.001 (0.239)	loss 7.740 (7.654)	prob 3.600 (3.482)	GS 36.312 (31.976)	mem 76.327
Train: [24][830/1500]	BT 0.039 (0.275)	DT 0.001 (0.239)	loss 7.719 (7.618)	prob 4.205 (3.485)	GS 38.016 (32.203)	mem 76.327
Train: [24][840/1500]	BT 0.039 (0.276)	DT 0.001 (0.239)	loss 8.063 (7.632)	prob 3.238 (3.413)	GS 33.031 (32.285)	mem 76.327
Train: [24][850/1500]	BT 0.039 (0.274)	DT 0.001 (0.237)	loss 7.583 (7.623)	prob 3.590 (3.447)	GS 32.703 (32.481)	mem 76.327
Train: [24][860/1500]	BT 2.320 (0.274)	DT 2.281 (0.237)	loss 7.783 (7.570)	prob 2.717 (3.349)	GS 35.344 (32.398)	mem 76.326
Train: [24][870/1500]	BT 0.027 (0.283)	DT 0.000 (0.246)	loss 7.858 (7.526)	prob 2.710 (3.485)	GS 35.750 (33.226)	mem 76.324
Train: [24][880/1500]	BT 0.031 (0.281)	DT 0.000 (0.243)	loss 8.115 (7.579)	prob 2.356 (3.430)	GS 38.047 (33.688)	mem 76.326
Train: [24][890/1500]	BT 0.037 (0.278)	DT 0.001 (0.241)	loss 7.591 (7.571)	prob 3.584 (3.411)	GS 30.047 (33.783)	mem 76.327
Train: [24][900/1500]	BT 0.040 (0.279)	DT 0.001 (0.242)	loss 7.703 (7.593)	prob 3.652 (3.445)	GS 35.688 (33.394)	mem 76.329
Train: [24][910/1500]	BT 0.030 (0.276)	DT 0.000 (0.239)	loss 7.258 (7.429)	prob 3.760 (3.738)	GS 33.953 (31.470)	mem 76.330
Train: [24][920/1500]	BT 0.066 (0.281)	DT 0.016 (0.244)	loss 7.316 (7.476)	prob 3.896 (3.573)	GS 34.016 (32.019)	mem 76.331
Train: [24][930/1500]	BT 0.031 (0.284)	DT 0.000 (0.246)	loss 7.275 (7.447)	prob 3.674 (3.489)	GS 37.328 (32.815)	mem 76.333
Train: [24][940/1500]	BT 0.039 (0.281)	DT 0.001 (0.244)	loss 7.477 (7.426)	prob 3.079 (3.495)	GS 32.625 (32.554)	mem 76.334
Train: [24][950/1500]	BT 0.038 (0.282)	DT 0.001 (0.245)	loss 7.216 (7.443)	prob 3.016 (3.465)	GS 29.078 (32.696)	mem 76.335
Train: [24][960/1500]	BT 0.039 (0.279)	DT 0.001 (0.242)	loss 7.487 (7.332)	prob 3.662 (3.615)	GS 31.109 (33.141)	mem 76.335
Train: [24][970/1500]	BT 0.036 (0.278)	DT 0.001 (0.241)	loss 8.153 (7.406)	prob 2.991 (3.539)	GS 35.547 (33.309)	mem 76.335
Train: [24][980/1500]	BT 0.039 (0.277)	DT 0.001 (0.240)	loss 7.316 (7.419)	prob 3.019 (3.446)	GS 32.875 (33.212)	mem 76.335
Train: [24][990/1500]	BT 0.048 (0.278)	DT 0.006 (0.241)	loss 7.217 (7.375)	prob 3.177 (3.423)	GS 34.766 (32.989)	mem 76.336
Train: [24][1000/1500]	BT 0.062 (0.277)	DT 0.003 (0.240)	loss 7.658 (7.391)	prob 3.285 (3.361)	GS 35.078 (33.038)	mem 76.337
Train: [24][1010/1500]	BT 0.037 (0.276)	DT 0.001 (0.239)	loss 7.110 (7.259)	prob 3.754 (3.326)	GS 30.391 (33.634)	mem 76.336
Train: [24][1020/1500]	BT 0.038 (0.275)	DT 0.001 (0.238)	loss 7.497 (7.265)	prob 3.778 (3.420)	GS 34.812 (32.660)	mem 76.335
Train: [24][1030/1500]	BT 0.066 (0.281)	DT 0.013 (0.244)	loss 7.242 (7.271)	prob 3.598 (3.338)	GS 32.984 (32.809)	mem 76.331
Train: [24][1040/1500]	BT 0.040 (0.279)	DT 0.000 (0.242)	loss 7.232 (7.268)	prob 3.175 (3.243)	GS 28.938 (32.886)	mem 76.334
Train: [24][1050/1500]	BT 0.033 (0.286)	DT 0.000 (0.249)	loss 7.326 (7.273)	prob 3.213 (3.244)	GS 31.516 (32.953)	mem 76.335
Train: [24][1060/1500]	BT 0.076 (0.284)	DT 0.010 (0.246)	loss 7.256 (7.219)	prob 3.520 (3.278)	GS 31.844 (32.808)	mem 76.335
Train: [24][1070/1500]	BT 0.038 (0.299)	DT 0.000 (0.262)	loss 7.374 (7.180)	prob 3.617 (3.412)	GS 32.891 (32.777)	mem 76.345
Train: [24][1080/1500]	BT 0.035 (0.297)	DT 0.001 (0.259)	loss 7.289 (7.147)	prob 3.260 (3.386)	GS 36.125 (32.512)	mem 76.347
Train: [24][1090/1500]	BT 0.026 (0.298)	DT 0.000 (0.261)	loss 7.204 (7.160)	prob 3.401 (3.328)	GS 30.484 (32.284)	mem 76.356
Train: [24][1100/1500]	BT 0.038 (0.296)	DT 0.001 (0.258)	loss 6.935 (7.162)	prob 4.101 (3.367)	GS 34.156 (32.443)	mem 76.338
Train: [24][1110/1500]	BT 0.037 (0.296)	DT 0.000 (0.259)	loss 7.251 (7.128)	prob 2.777 (3.379)	GS 36.172 (32.016)	mem 76.259
Train: [24][1120/1500]	BT 0.037 (0.294)	DT 0.000 (0.256)	loss 7.156 (7.109)	prob 3.735 (3.275)	GS 34.359 (32.782)	mem 76.259
Train: [24][1130/1500]	BT 0.037 (0.292)	DT 0.001 (0.254)	loss 7.179 (7.127)	prob 3.399 (3.148)	GS 34.062 (33.020)	mem 76.258
Train: [24][1140/1500]	BT 0.037 (0.292)	DT 0.001 (0.254)	loss 7.597 (7.146)	prob 2.977 (3.068)	GS 35.375 (33.026)	mem 76.258
Train: [24][1150/1500]	BT 0.037 (0.289)	DT 0.000 (0.252)	loss 7.278 (7.167)	prob 4.072 (3.059)	GS 32.453 (32.906)	mem 76.258
Train: [24][1160/1500]	BT 0.050 (0.290)	DT 0.011 (0.253)	loss 7.144 (7.265)	prob 3.449 (3.271)	GS 31.125 (31.775)	mem 76.259
Train: [24][1170/1500]	BT 0.052 (0.289)	DT 0.007 (0.252)	loss 7.341 (7.294)	prob 2.437 (2.968)	GS 32.828 (32.145)	mem 76.260
Train: [24][1180/1500]	BT 0.067 (0.287)	DT 0.011 (0.250)	loss 7.544 (7.273)	prob 3.531 (2.891)	GS 31.734 (32.595)	mem 76.259
Train: [24][1190/1500]	BT 0.052 (0.299)	DT 0.001 (0.261)	loss 7.410 (7.304)	prob 2.757 (2.783)	GS 34.734 (33.103)	mem 76.259
Train: [24][1200/1500]	BT 0.034 (0.298)	DT 0.001 (0.260)	loss 7.487 (7.329)	prob 3.284 (2.810)	GS 32.078 (32.845)	mem 76.260
Train: [24][1210/1500]	BT 0.031 (0.295)	DT 0.000 (0.258)	loss 7.493 (7.378)	prob 3.128 (2.614)	GS 32.969 (32.906)	mem 76.261
Train: [24][1220/1500]	BT 0.024 (0.297)	DT 0.000 (0.259)	loss 7.421 (7.428)	prob 2.534 (2.493)	GS 34.078 (33.338)	mem 76.267
Train: [24][1230/1500]	BT 0.030 (0.294)	DT 0.000 (0.257)	loss 7.755 (7.428)	prob 2.688 (2.374)	GS 34.016 (33.356)	mem 76.265
Train: [24][1240/1500]	BT 0.040 (0.297)	DT 0.001 (0.259)	loss 7.899 (7.460)	prob 2.677 (2.411)	GS 38.453 (33.516)	mem 76.265
Train: [24][1250/1500]	BT 0.038 (0.295)	DT 0.001 (0.257)	loss 7.752 (7.514)	prob 2.384 (2.372)	GS 36.609 (33.561)	mem 76.264
Train: [24][1260/1500]	BT 0.039 (0.293)	DT 0.001 (0.255)	loss 7.797 (7.545)	prob 2.516 (2.309)	GS 35.672 (32.408)	mem 76.265
Train: [24][1270/1500]	BT 0.078 (0.294)	DT 0.002 (0.257)	loss 8.154 (7.591)	prob 2.468 (2.234)	GS 33.188 (33.263)	mem 76.266
Train: [24][1280/1500]	BT 0.042 (0.293)	DT 0.000 (0.255)	loss 8.605 (7.652)	prob 2.384 (2.232)	GS 36.359 (33.220)	mem 76.267
Train: [24][1290/1500]	BT 0.022 (0.296)	DT 0.000 (0.259)	loss 7.564 (7.648)	prob 3.441 (2.270)	GS 35.656 (33.125)	mem 76.267
Train: [24][1300/1500]	BT 0.026 (0.294)	DT 0.000 (0.257)	loss 8.060 (7.684)	prob 3.342 (2.366)	GS 31.844 (32.990)	mem 76.268
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [24][1310/1500]	BT 0.039 (0.295)	DT 0.001 (0.257)	loss 7.816 (7.759)	prob 2.748 (2.636)	GS 34.438 (32.200)	mem 76.269
Train: [24][1320/1500]	BT 0.029 (0.294)	DT 0.000 (0.256)	loss 7.360 (7.750)	prob 3.577 (2.737)	GS 31.016 (32.002)	mem 76.268
Train: [24][1330/1500]	BT 0.040 (0.292)	DT 0.001 (0.254)	loss 7.739 (7.742)	prob 3.372 (2.698)	GS 36.172 (32.525)	mem 76.270
Train: [24][1340/1500]	BT 0.030 (0.297)	DT 0.000 (0.259)	loss 7.718 (7.782)	prob 3.347 (2.633)	GS 32.516 (32.888)	mem 76.270
Train: [24][1350/1500]	BT 0.027 (0.295)	DT 0.000 (0.257)	loss 7.839 (7.795)	prob 3.277 (2.634)	GS 35.703 (32.945)	mem 76.270
Train: [24][1360/1500]	BT 0.027 (0.296)	DT 0.000 (0.258)	loss 7.859 (7.883)	prob 2.785 (2.803)	GS 37.156 (31.992)	mem 76.288
Train: [24][1370/1500]	BT 0.037 (0.294)	DT 0.000 (0.256)	loss 7.729 (7.812)	prob 4.213 (3.075)	GS 32.484 (32.520)	mem 76.288
Train: [24][1380/1500]	BT 0.037 (0.292)	DT 0.000 (0.254)	loss 7.761 (7.762)	prob 2.912 (3.060)	GS 31.141 (32.610)	mem 76.289
Train: [24][1390/1500]	BT 0.037 (0.292)	DT 0.000 (0.255)	loss 8.236 (7.788)	prob 3.021 (3.124)	GS 34.469 (32.198)	mem 76.292
Train: [24][1400/1500]	BT 0.037 (0.290)	DT 0.001 (0.253)	loss 8.228 (7.796)	prob 2.912 (3.104)	GS 35.172 (32.231)	mem 76.293
Train: [24][1410/1500]	BT 0.037 (0.290)	DT 0.000 (0.253)	loss 7.952 (7.777)	prob 3.409 (3.013)	GS 33.750 (32.577)	mem 76.297
Train: [24][1420/1500]	BT 0.037 (0.289)	DT 0.000 (0.251)	loss 8.220 (7.836)	prob 3.195 (3.129)	GS 35.438 (33.045)	mem 76.296
Train: [24][1430/1500]	BT 0.095 (0.289)	DT 0.059 (0.252)	loss 9.053 (7.856)	prob 2.782 (3.030)	GS 36.547 (32.763)	mem 76.299
Train: [24][1440/1500]	BT 0.036 (0.288)	DT 0.000 (0.250)	loss 7.823 (7.855)	prob 3.828 (3.121)	GS 30.328 (32.874)	mem 76.298
Train: [24][1450/1500]	BT 0.036 (0.287)	DT 0.001 (0.250)	loss 8.599 (7.871)	prob 3.739 (3.220)	GS 35.266 (32.782)	mem 76.299
Train: [24][1460/1500]	BT 0.026 (0.289)	DT 0.000 (0.252)	loss 7.990 (7.841)	prob 2.408 (3.276)	GS 32.609 (33.409)	mem 75.644
Train: [24][1470/1500]	BT 0.024 (0.287)	DT 0.000 (0.250)	loss 8.833 (7.901)	prob 3.221 (3.380)	GS 37.109 (32.645)	mem 75.642
Train: [24][1480/1500]	BT 0.034 (0.288)	DT 0.000 (0.251)	loss 7.703 (7.833)	prob 3.966 (3.444)	GS 33.656 (32.743)	mem 11.159
Train: [24][1490/1500]	BT 0.024 (0.287)	DT 0.000 (0.249)	loss 7.618 (7.818)	prob 4.311 (3.476)	GS 34.781 (32.706)	mem 11.159
Train: [24][1500/1500]	BT 0.026 (0.285)	DT 0.000 (0.248)	loss 8.141 (7.812)	prob 2.808 (3.482)	GS 34.438 (32.786)	mem 11.159
Train: [24][1510/1500]	BT 0.032 (0.284)	DT 0.000 (0.247)	loss 8.379 (8.091)	prob 3.226 (3.072)	GS 29.812 (33.134)	mem 11.085
epoch 24, total time 428.60
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [25][1/1500]	BT 17.832 (17.832)	DT 17.775 (17.775)	loss 7.479 (7.479)	prob 4.324 (4.324)	GS 34.000 (34.000)	mem 74.262
Train: [25][10/1500]	BT 0.034 (2.334)	DT 0.000 (2.295)	loss 7.431 (7.481)	prob 3.860 (3.518)	GS 31.750 (31.707)	mem 74.846
Train: [25][20/1500]	BT 0.033 (1.185)	DT 0.000 (1.149)	loss 7.379 (7.516)	prob 3.769 (3.385)	GS 39.719 (33.413)	mem 74.846
Train: [25][30/1500]	BT 0.080 (1.085)	DT 0.001 (1.042)	loss 7.502 (7.582)	prob 4.810 (3.446)	GS 31.094 (32.853)	mem 74.922
Train: [25][40/1500]	BT 0.030 (0.881)	DT 0.000 (0.843)	loss 7.585 (7.576)	prob 4.658 (3.590)	GS 34.234 (32.889)	mem 74.930
Train: [25][50/1500]	BT 0.028 (0.712)	DT 0.000 (0.674)	loss 8.442 (7.586)	prob 3.785 (3.694)	GS 35.562 (32.734)	mem 74.931
Train: [25][60/1500]	BT 0.034 (0.647)	DT 0.000 (0.610)	loss 7.421 (7.867)	prob 4.807 (3.412)	GS 34.578 (33.092)	mem 74.942
Train: [25][70/1500]	BT 0.032 (0.560)	DT 0.000 (0.523)	loss 7.558 (7.728)	prob 5.016 (3.804)	GS 33.469 (32.536)	mem 74.943
Train: [25][80/1500]	BT 0.080 (0.615)	DT 0.005 (0.577)	loss 7.447 (7.717)	prob 4.104 (3.857)	GS 32.078 (32.276)	mem 74.958
Train: [25][90/1500]	BT 0.058 (0.555)	DT 0.004 (0.514)	loss 7.253 (7.714)	prob 3.992 (3.707)	GS 33.781 (32.676)	mem 74.958
Train: [25][100/1500]	BT 0.034 (0.651)	DT 0.001 (0.610)	loss 7.550 (7.712)	prob 4.700 (3.672)	GS 36.844 (32.875)	mem 74.963
Train: [25][110/1500]	BT 0.038 (0.595)	DT 0.000 (0.555)	loss 7.893 (7.577)	prob 4.271 (4.013)	GS 36.859 (32.403)	mem 74.964
Train: [25][120/1500]	BT 0.042 (0.582)	DT 0.001 (0.542)	loss 7.871 (7.625)	prob 3.834 (3.865)	GS 35.562 (32.748)	mem 74.971
Train: [25][130/1500]	BT 0.062 (0.540)	DT 0.003 (0.501)	loss 7.442 (7.630)	prob 4.572 (3.770)	GS 33.312 (32.840)	mem 74.969
Train: [25][140/1500]	BT 0.054 (0.506)	DT 0.002 (0.465)	loss 7.651 (7.646)	prob 3.303 (3.693)	GS 29.844 (32.914)	mem 74.969
Train: [25][150/1500]	BT 0.055 (0.535)	DT 0.012 (0.493)	loss 7.781 (7.647)	prob 4.319 (3.640)	GS 30.938 (32.825)	mem 74.982
Train: [25][160/1500]	BT 0.061 (0.531)	DT 0.002 (0.489)	loss 7.828 (7.673)	prob 3.627 (3.685)	GS 39.609 (34.766)	mem 74.983
Train: [25][170/1500]	BT 0.033 (0.524)	DT 0.000 (0.482)	loss 7.680 (7.647)	prob 3.433 (3.531)	GS 35.109 (34.187)	mem 74.984
Train: [25][180/1500]	BT 0.023 (0.537)	DT 0.000 (0.496)	loss 7.337 (7.608)	prob 3.934 (3.642)	GS 36.969 (33.705)	mem 74.988
Train: [25][190/1500]	BT 0.035 (0.510)	DT 0.000 (0.470)	loss 7.804 (7.588)	prob 2.833 (3.565)	GS 37.859 (33.697)	mem 74.990
Train: [25][200/1500]	BT 0.038 (0.500)	DT 0.001 (0.460)	loss 7.927 (7.574)	prob 4.039 (3.490)	GS 34.938 (33.549)	mem 74.993
Train: [25][210/1500]	BT 0.029 (0.478)	DT 0.000 (0.438)	loss 7.793 (7.696)	prob 3.219 (3.565)	GS 32.094 (34.237)	mem 74.992
Train: [25][220/1500]	BT 4.806 (0.479)	DT 4.752 (0.440)	loss 7.734 (7.665)	prob 4.205 (3.714)	GS 33.078 (33.670)	mem 75.022
Train: [25][230/1500]	BT 0.039 (0.460)	DT 0.001 (0.421)	loss 8.787 (7.651)	prob 2.709 (3.673)	GS 37.359 (33.605)	mem 75.023
Train: [25][240/1500]	BT 0.039 (0.443)	DT 0.001 (0.403)	loss 7.413 (7.605)	prob 4.140 (3.629)	GS 34.609 (33.289)	mem 75.023
Train: [25][250/1500]	BT 0.037 (0.442)	DT 0.001 (0.403)	loss 7.750 (7.623)	prob 3.914 (3.575)	GS 39.141 (33.138)	mem 75.271
Train: [25][260/1500]	BT 0.040 (0.427)	DT 0.001 (0.387)	loss 7.233 (7.534)	prob 3.904 (3.753)	GS 36.266 (32.370)	mem 75.319
Train: [25][270/1500]	BT 0.059 (0.438)	DT 0.006 (0.399)	loss 7.772 (7.579)	prob 2.906 (3.629)	GS 37.672 (33.032)	mem 76.102
Train: [25][280/1500]	BT 0.035 (0.424)	DT 0.000 (0.385)	loss 7.926 (7.519)	prob 2.518 (3.447)	GS 33.906 (33.015)	mem 76.151
Train: [25][290/1500]	BT 0.031 (0.412)	DT 0.000 (0.372)	loss 7.311 (7.476)	prob 3.619 (3.348)	GS 34.234 (32.814)	mem 76.153
Train: [25][300/1500]	BT 0.028 (0.451)	DT 0.000 (0.412)	loss 7.231 (7.468)	prob 4.062 (3.316)	GS 35.547 (32.926)	mem 76.203
Train: [25][310/1500]	BT 0.037 (0.438)	DT 0.001 (0.399)	loss 7.793 (7.563)	prob 3.042 (3.264)	GS 32.203 (33.641)	mem 76.206
Train: [25][320/1500]	BT 0.054 (0.434)	DT 0.006 (0.395)	loss 7.358 (7.496)	prob 2.924 (3.399)	GS 35.453 (33.139)	mem 76.211
Train: [25][330/1500]	BT 0.030 (0.422)	DT 0.000 (0.383)	loss 7.995 (7.482)	prob 2.787 (3.343)	GS 32.156 (33.187)	mem 76.212
Train: [25][340/1500]	BT 0.030 (0.411)	DT 0.001 (0.372)	loss 7.505 (7.474)	prob 2.647 (3.291)	GS 36.141 (33.225)	mem 76.212
Train: [25][350/1500]	BT 0.032 (0.409)	DT 0.001 (0.370)	loss 7.575 (7.490)	prob 3.272 (3.234)	GS 32.031 (32.999)	mem 76.216
Train: [25][360/1500]	BT 0.038 (0.415)	DT 0.001 (0.376)	loss 7.057 (7.449)	prob 3.724 (3.184)	GS 25.453 (32.994)	mem 76.214
Train: [25][370/1500]	BT 0.065 (0.407)	DT 0.001 (0.368)	loss 7.684 (7.474)	prob 2.634 (3.257)	GS 32.719 (33.085)	mem 76.213
Train: [25][380/1500]	BT 0.037 (0.412)	DT 0.000 (0.374)	loss 7.471 (7.460)	prob 3.084 (3.215)	GS 35.844 (32.866)	mem 76.217
Train: [25][390/1500]	BT 0.045 (0.407)	DT 0.002 (0.368)	loss 6.960 (7.423)	prob 2.348 (3.098)	GS 31.672 (32.915)	mem 76.217
Train: [25][400/1500]	BT 0.029 (0.417)	DT 0.000 (0.379)	loss 7.410 (7.419)	prob 3.175 (3.076)	GS 36.953 (33.119)	mem 76.217
Train: [25][410/1500]	BT 0.027 (0.408)	DT 0.000 (0.369)	loss 7.264 (7.384)	prob 3.550 (3.376)	GS 30.359 (30.489)	mem 76.217
Train: [25][420/1500]	BT 0.039 (0.406)	DT 0.001 (0.367)	loss 7.432 (7.419)	prob 4.112 (3.157)	GS 32.875 (31.528)	mem 76.219
Train: [25][430/1500]	BT 0.031 (0.397)	DT 0.001 (0.359)	loss 7.682 (7.403)	prob 3.251 (3.144)	GS 34.109 (31.941)	mem 76.220
Train: [25][440/1500]	BT 0.039 (0.389)	DT 0.001 (0.351)	loss 7.880 (7.393)	prob 1.518 (2.960)	GS 29.250 (32.028)	mem 76.221
Train: [25][450/1500]	BT 0.038 (0.387)	DT 0.001 (0.349)	loss 7.104 (7.369)	prob 3.325 (2.869)	GS 31.062 (32.165)	mem 76.222
Train: [25][460/1500]	BT 0.031 (0.386)	DT 0.000 (0.348)	loss 7.280 (7.417)	prob 2.461 (2.389)	GS 36.500 (33.247)	mem 76.221
Train: [25][470/1500]	BT 0.033 (0.384)	DT 0.000 (0.346)	loss 7.500 (7.369)	prob 2.296 (2.320)	GS 30.750 (33.069)	mem 76.224
Train: [25][480/1500]	BT 0.029 (0.399)	DT 0.000 (0.361)	loss 7.847 (7.375)	prob 2.458 (2.336)	GS 33.141 (33.081)	mem 76.222
Train: [25][490/1500]	BT 0.025 (0.391)	DT 0.000 (0.353)	loss 7.265 (7.379)	prob 2.356 (2.371)	GS 36.234 (33.033)	mem 76.224
Train: [25][500/1500]	BT 0.027 (0.389)	DT 0.000 (0.352)	loss 7.708 (7.393)	prob 1.894 (2.374)	GS 33.125 (32.773)	mem 76.246
Train: [25][510/1500]	BT 0.038 (0.382)	DT 0.001 (0.345)	loss 7.884 (7.554)	prob 1.661 (2.230)	GS 34.562 (33.402)	mem 76.247
Train: [25][520/1500]	BT 6.905 (0.389)	DT 6.869 (0.351)	loss 7.580 (7.520)	prob 2.513 (2.232)	GS 34.062 (32.780)	mem 76.244
Train: [25][530/1500]	BT 0.037 (0.384)	DT 0.001 (0.346)	loss 7.901 (7.519)	prob 2.739 (2.189)	GS 35.625 (33.070)	mem 76.244
Train: [25][540/1500]	BT 0.038 (0.377)	DT 0.001 (0.340)	loss 7.475 (7.490)	prob 2.302 (2.286)	GS 33.312 (32.526)	mem 76.244
Train: [25][550/1500]	BT 0.037 (0.377)	DT 0.001 (0.339)	loss 7.607 (7.503)	prob 2.473 (2.283)	GS 32.891 (32.562)	mem 76.145
Train: [25][560/1500]	BT 0.037 (0.371)	DT 0.001 (0.333)	loss 8.235 (7.616)	prob 2.277 (2.199)	GS 36.641 (34.109)	mem 76.145
Train: [25][570/1500]	BT 0.036 (0.372)	DT 0.001 (0.334)	loss 7.612 (7.605)	prob 2.568 (2.194)	GS 36.906 (33.669)	mem 76.144
Train: [25][580/1500]	BT 0.036 (0.366)	DT 0.001 (0.328)	loss 8.203 (7.643)	prob 2.849 (2.148)	GS 35.484 (33.567)	mem 76.144
Train: [25][590/1500]	BT 0.037 (0.360)	DT 0.000 (0.323)	loss 7.916 (7.604)	prob 1.959 (2.308)	GS 38.172 (33.532)	mem 76.144
Train: [25][600/1500]	BT 0.054 (0.361)	DT 0.008 (0.324)	loss 7.952 (7.645)	prob 3.261 (2.396)	GS 28.703 (33.258)	mem 76.146
Train: [25][610/1500]	BT 0.054 (0.356)	DT 0.001 (0.318)	loss 7.751 (7.708)	prob 3.168 (3.077)	GS 35.172 (32.664)	mem 76.147
Train: [25][620/1500]	BT 0.037 (0.362)	DT 0.001 (0.324)	loss 7.573 (7.683)	prob 3.171 (2.975)	GS 35.859 (32.904)	mem 76.147
Train: [25][630/1500]	BT 0.037 (0.357)	DT 0.001 (0.319)	loss 7.813 (7.698)	prob 3.199 (2.787)	GS 35.625 (33.479)	mem 76.147
Train: [25][640/1500]	BT 3.562 (0.357)	DT 3.513 (0.319)	loss 8.034 (7.707)	prob 3.652 (2.898)	GS 30.094 (33.059)	mem 76.165
Train: [25][650/1500]	BT 0.027 (0.371)	DT 0.000 (0.333)	loss 7.139 (7.721)	prob 3.672 (2.984)	GS 36.156 (32.988)	mem 76.157
Train: [25][660/1500]	BT 0.029 (0.366)	DT 0.000 (0.328)	loss 7.833 (7.793)	prob 3.260 (3.206)	GS 32.625 (31.752)	mem 76.156
Train: [25][670/1500]	BT 0.025 (0.361)	DT 0.000 (0.323)	loss 7.855 (7.763)	prob 4.052 (3.356)	GS 35.016 (31.745)	mem 76.157
Train: [25][680/1500]	BT 0.028 (0.362)	DT 0.000 (0.325)	loss 8.540 (7.786)	prob 2.350 (3.293)	GS 32.578 (32.349)	mem 76.160
Train: [25][690/1500]	BT 0.039 (0.357)	DT 0.001 (0.320)	loss 8.181 (7.815)	prob 2.938 (3.295)	GS 37.609 (32.683)	mem 76.159
Train: [25][700/1500]	BT 0.038 (0.361)	DT 0.001 (0.324)	loss 8.294 (7.805)	prob 4.354 (3.381)	GS 32.703 (32.420)	mem 76.162
Train: [25][710/1500]	BT 0.039 (0.357)	DT 0.001 (0.319)	loss 8.260 (7.939)	prob 2.607 (3.229)	GS 33.281 (33.186)	mem 76.162
Train: [25][720/1500]	BT 0.026 (0.359)	DT 0.001 (0.322)	loss 7.423 (7.874)	prob 4.451 (3.504)	GS 26.828 (32.073)	mem 76.159
Train: [25][730/1500]	BT 0.030 (0.355)	DT 0.000 (0.317)	loss 7.705 (7.884)	prob 3.681 (3.569)	GS 29.500 (32.302)	mem 76.160
Train: [25][740/1500]	BT 0.026 (0.350)	DT 0.000 (0.313)	loss 7.302 (7.905)	prob 3.462 (3.573)	GS 37.141 (32.646)	mem 76.161
Train: [25][750/1500]	BT 0.030 (0.353)	DT 0.000 (0.316)	loss 8.909 (7.930)	prob 3.901 (3.543)	GS 32.734 (32.380)	mem 76.162
Train: [25][760/1500]	BT 0.028 (0.349)	DT 0.000 (0.312)	loss 8.308 (7.871)	prob 3.736 (3.998)	GS 30.656 (31.445)	mem 76.161
Train: [25][770/1500]	BT 0.037 (0.348)	DT 0.001 (0.311)	loss 8.311 (7.916)	prob 4.252 (4.126)	GS 38.000 (32.229)	mem 76.176
Train: [25][780/1500]	BT 0.037 (0.344)	DT 0.000 (0.307)	loss 7.377 (7.888)	prob 3.970 (3.980)	GS 34.172 (31.993)	mem 76.179
Train: [25][790/1500]	BT 0.036 (0.341)	DT 0.000 (0.304)	loss 8.155 (7.907)	prob 4.162 (3.895)	GS 31.156 (31.991)	mem 76.179
Train: [25][800/1500]	BT 0.032 (0.345)	DT 0.000 (0.308)	loss 8.760 (7.899)	prob 3.093 (3.902)	GS 34.422 (32.154)	mem 76.181
Train: [25][810/1500]	BT 0.037 (0.341)	DT 0.000 (0.305)	loss 7.345 (7.835)	prob 4.830 (3.909)	GS 29.734 (31.400)	mem 76.182
Train: [25][820/1500]	BT 0.034 (0.343)	DT 0.000 (0.306)	loss 8.607 (7.970)	prob 3.936 (3.965)	GS 32.359 (32.048)	mem 76.184
Train: [25][830/1500]	BT 0.085 (0.340)	DT 0.011 (0.303)	loss 8.093 (7.974)	prob 4.758 (3.989)	GS 32.328 (32.048)	mem 76.183
Train: [25][840/1500]	BT 0.059 (0.352)	DT 0.005 (0.314)	loss 7.889 (7.965)	prob 4.809 (4.069)	GS 36.859 (32.161)	mem 76.184
Train: [25][850/1500]	BT 0.093 (0.348)	DT 0.009 (0.310)	loss 7.482 (7.921)	prob 4.538 (4.097)	GS 36.641 (32.375)	mem 76.185
Train: [25][860/1500]	BT 0.027 (0.371)	DT 0.000 (0.333)	loss 8.105 (7.784)	prob 4.540 (3.898)	GS 31.734 (32.627)	mem 76.188
Train: [25][870/1500]	BT 0.031 (0.367)	DT 0.000 (0.329)	loss 7.846 (7.786)	prob 4.543 (3.761)	GS 32.844 (32.888)	mem 76.188
Train: [25][880/1500]	BT 4.312 (0.368)	DT 4.271 (0.330)	loss 7.773 (7.796)	prob 3.797 (3.747)	GS 32.859 (33.331)	mem 76.189
Train: [25][890/1500]	BT 0.062 (0.365)	DT 0.002 (0.326)	loss 8.151 (7.803)	prob 4.389 (3.815)	GS 36.688 (33.344)	mem 76.191
Train: [25][900/1500]	BT 0.062 (0.361)	DT 0.013 (0.323)	loss 7.877 (7.810)	prob 4.361 (3.826)	GS 32.094 (33.431)	mem 76.190
Train: [25][910/1500]	BT 0.056 (0.363)	DT 0.011 (0.325)	loss 8.353 (7.965)	prob 3.677 (4.098)	GS 37.469 (33.667)	mem 76.194
Train: [25][920/1500]	BT 0.068 (0.360)	DT 0.010 (0.321)	loss 8.009 (7.865)	prob 4.390 (4.078)	GS 33.531 (33.167)	mem 76.195
Train: [25][930/1500]	BT 0.039 (0.362)	DT 0.001 (0.324)	loss 7.712 (7.796)	prob 4.398 (4.060)	GS 31.281 (33.463)	mem 76.196
Train: [25][940/1500]	BT 0.036 (0.359)	DT 0.000 (0.320)	loss 7.727 (7.778)	prob 4.198 (4.034)	GS 34.609 (33.396)	mem 76.196
Train: [25][950/1500]	BT 0.038 (0.356)	DT 0.001 (0.317)	loss 7.676 (7.758)	prob 3.633 (4.050)	GS 32.875 (33.054)	mem 76.196
Train: [25][960/1500]	BT 0.072 (0.359)	DT 0.009 (0.320)	loss 7.964 (7.726)	prob 4.316 (4.310)	GS 33.875 (32.275)	mem 76.195
Train: [25][970/1500]	BT 0.075 (0.356)	DT 0.014 (0.317)	loss 7.335 (7.719)	prob 4.223 (3.922)	GS 30.281 (32.899)	mem 76.195
Train: [25][980/1500]	BT 0.037 (0.357)	DT 0.001 (0.318)	loss 7.889 (7.728)	prob 3.475 (3.839)	GS 31.359 (33.127)	mem 76.196
Train: [25][990/1500]	BT 0.027 (0.355)	DT 0.000 (0.316)	loss 7.621 (7.696)	prob 4.838 (3.830)	GS 34.859 (32.961)	mem 76.196
Train: [25][1000/1500]	BT 1.905 (0.356)	DT 1.857 (0.317)	loss 7.642 (7.680)	prob 4.495 (3.884)	GS 32.750 (32.822)	mem 76.196
Train: [25][1010/1500]	BT 0.057 (0.356)	DT 0.007 (0.317)	loss 7.785 (7.631)	prob 3.281 (3.887)	GS 28.562 (32.041)	mem 76.199
Train: [25][1020/1500]	BT 0.032 (0.361)	DT 0.000 (0.322)	loss 7.734 (7.604)	prob 3.653 (3.970)	GS 33.922 (32.987)	mem 76.197
Train: [25][1030/1500]	BT 0.080 (0.358)	DT 0.007 (0.319)	loss 7.359 (7.539)	prob 5.153 (4.060)	GS 34.719 (32.391)	mem 76.198
Train: [25][1040/1500]	BT 0.062 (0.355)	DT 0.003 (0.316)	loss 7.766 (7.543)	prob 3.855 (4.017)	GS 33.016 (32.666)	mem 76.197
Train: [25][1050/1500]	BT 0.058 (0.358)	DT 0.000 (0.318)	loss 7.148 (7.523)	prob 4.332 (3.998)	GS 32.188 (32.555)	mem 76.201
Train: [25][1060/1500]	BT 0.038 (0.355)	DT 0.004 (0.316)	loss 7.367 (7.531)	prob 4.596 (3.940)	GS 30.484 (31.955)	mem 76.201
Train: [25][1070/1500]	BT 0.084 (0.362)	DT 0.004 (0.322)	loss 7.410 (7.503)	prob 3.597 (3.939)	GS 36.547 (32.191)	mem 76.201
Train: [25][1080/1500]	BT 0.029 (0.365)	DT 0.000 (0.325)	loss 8.113 (7.500)	prob 4.275 (3.848)	GS 39.969 (33.022)	mem 76.204
Train: [25][1090/1500]	BT 0.032 (0.362)	DT 0.001 (0.322)	loss 7.260 (7.513)	prob 5.133 (3.939)	GS 33.750 (32.886)	mem 76.204
Train: [25][1100/1500]	BT 0.060 (0.363)	DT 0.011 (0.324)	loss 7.373 (7.496)	prob 4.484 (3.974)	GS 31.859 (32.555)	mem 76.206
Train: [25][1110/1500]	BT 0.078 (0.360)	DT 0.003 (0.321)	loss 7.578 (7.539)	prob 4.661 (4.021)	GS 34.234 (32.575)	mem 76.206
Train: [25][1120/1500]	BT 0.059 (0.358)	DT 0.013 (0.318)	loss 7.409 (7.513)	prob 3.151 (3.862)	GS 34.938 (33.346)	mem 76.204
Train: [25][1130/1500]	BT 0.056 (0.361)	DT 0.006 (0.321)	loss 7.667 (7.503)	prob 4.238 (3.768)	GS 39.172 (33.696)	mem 76.204
Train: [25][1140/1500]	BT 0.035 (0.360)	DT 0.000 (0.320)	loss 7.556 (7.475)	prob 3.623 (3.775)	GS 33.719 (33.396)	mem 76.204
Train: [25][1150/1500]	BT 0.059 (0.362)	DT 0.002 (0.322)	loss 7.698 (7.489)	prob 3.826 (3.767)	GS 34.000 (33.282)	mem 76.203
Train: [25][1160/1500]	BT 0.060 (0.360)	DT 0.001 (0.319)	loss 7.323 (7.326)	prob 3.640 (3.794)	GS 32.000 (32.166)	mem 76.202
Train: [25][1170/1500]	BT 0.030 (0.366)	DT 0.000 (0.326)	loss 7.792 (7.340)	prob 3.634 (3.583)	GS 30.828 (32.395)	mem 76.203
Train: [25][1180/1500]	BT 0.028 (0.367)	DT 0.000 (0.327)	loss 7.151 (7.342)	prob 3.514 (3.579)	GS 36.297 (33.086)	mem 76.206
Train: [25][1190/1500]	BT 0.110 (0.365)	DT 0.028 (0.324)	loss 7.449 (7.358)	prob 3.385 (3.546)	GS 35.844 (33.059)	mem 76.206
Train: [25][1200/1500]	BT 0.026 (0.368)	DT 0.000 (0.328)	loss 7.207 (7.356)	prob 4.078 (3.457)	GS 33.250 (33.189)	mem 76.209
Train: [25][1210/1500]	BT 0.037 (0.365)	DT 0.001 (0.325)	loss 7.434 (7.462)	prob 3.572 (3.122)	GS 32.906 (32.927)	mem 76.210
Train: [25][1220/1500]	BT 0.038 (0.364)	DT 0.000 (0.324)	loss 7.560 (7.424)	prob 3.347 (3.139)	GS 34.141 (33.471)	mem 76.210
Train: [25][1230/1500]	BT 0.038 (0.362)	DT 0.001 (0.322)	loss 7.654 (7.426)	prob 3.731 (3.143)	GS 32.078 (33.166)	mem 76.210
Train: [25][1240/1500]	BT 0.038 (0.360)	DT 0.001 (0.319)	loss 7.319 (7.436)	prob 3.953 (3.131)	GS 32.891 (32.992)	mem 76.210
Train: [25][1250/1500]	BT 0.042 (0.361)	DT 0.000 (0.321)	loss 7.523 (7.423)	prob 3.805 (3.138)	GS 30.172 (32.868)	mem 76.211
Train: [25][1260/1500]	BT 0.076 (0.358)	DT 0.012 (0.318)	loss 7.555 (7.513)	prob 2.928 (2.931)	GS 33.672 (32.438)	mem 76.212
Train: [25][1270/1500]	BT 0.033 (0.363)	DT 0.000 (0.322)	loss 7.597 (7.449)	prob 3.258 (2.784)	GS 36.938 (33.306)	mem 76.210
Train: [25][1280/1500]	BT 0.042 (0.366)	DT 0.001 (0.326)	loss 7.602 (7.475)	prob 2.654 (2.753)	GS 30.875 (32.921)	mem 76.214
Train: [25][1290/1500]	BT 0.034 (0.364)	DT 0.000 (0.323)	loss 7.094 (7.468)	prob 3.656 (2.789)	GS 34.156 (32.462)	mem 76.241
Train: [25][1300/1500]	BT 0.039 (0.363)	DT 0.001 (0.323)	loss 8.582 (7.525)	prob 2.329 (2.734)	GS 31.250 (32.986)	mem 76.245
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [25][1310/1500]	BT 0.039 (0.361)	DT 0.001 (0.321)	loss 7.949 (7.559)	prob 2.960 (2.747)	GS 29.109 (31.288)	mem 76.244
Train: [25][1320/1500]	BT 0.062 (0.358)	DT 0.003 (0.318)	loss 7.616 (7.686)	prob 2.142 (2.431)	GS 31.922 (32.071)	mem 76.244
Train: [25][1330/1500]	BT 0.080 (0.367)	DT 0.008 (0.326)	loss 7.259 (7.637)	prob 2.850 (2.476)	GS 31.109 (31.628)	mem 76.243
Train: [25][1340/1500]	BT 0.097 (0.364)	DT 0.022 (0.324)	loss 7.731 (7.630)	prob 1.786 (2.459)	GS 31.797 (31.785)	mem 76.244
Train: [25][1350/1500]	BT 0.029 (0.375)	DT 0.000 (0.335)	loss 7.650 (7.654)	prob 1.826 (2.342)	GS 37.156 (32.075)	mem 76.246
Train: [25][1360/1500]	BT 0.028 (0.373)	DT 0.000 (0.333)	loss 7.744 (7.817)	prob 2.360 (1.530)	GS 32.031 (34.244)	mem 76.248
Train: [25][1370/1500]	BT 0.038 (0.373)	DT 0.001 (0.333)	loss 8.333 (7.772)	prob 1.909 (1.838)	GS 32.625 (33.420)	mem 76.248
Train: [25][1380/1500]	BT 0.040 (0.371)	DT 0.001 (0.330)	loss 8.087 (7.771)	prob 3.033 (2.021)	GS 32.406 (32.583)	mem 76.247
Train: [25][1390/1500]	BT 3.164 (0.371)	DT 3.126 (0.330)	loss 8.243 (7.760)	prob 2.023 (2.094)	GS 31.875 (32.561)	mem 76.247
Train: [25][1400/1500]	BT 0.051 (0.368)	DT 0.013 (0.328)	loss 7.380 (7.741)	prob 2.312 (2.132)	GS 35.359 (32.554)	mem 76.249
Train: [25][1410/1500]	BT 0.064 (0.366)	DT 0.008 (0.326)	loss 8.315 (7.968)	prob 1.913 (1.999)	GS 33.656 (33.019)	mem 76.250
Train: [25][1420/1500]	BT 0.039 (0.366)	DT 0.001 (0.325)	loss 8.279 (7.981)	prob 2.383 (2.029)	GS 36.047 (33.461)	mem 76.249
Train: [25][1430/1500]	BT 0.026 (0.365)	DT 0.000 (0.324)	loss 7.961 (7.955)	prob 2.290 (2.058)	GS 35.047 (33.303)	mem 76.247
Train: [25][1440/1500]	BT 0.033 (0.364)	DT 0.000 (0.324)	loss 8.848 (7.960)	prob 1.818 (2.060)	GS 32.875 (33.202)	mem 76.248
Train: [25][1450/1500]	BT 0.034 (0.362)	DT 0.000 (0.322)	loss 8.646 (8.010)	prob 1.778 (2.084)	GS 35.344 (32.960)	mem 76.248
Train: [25][1460/1500]	BT 0.086 (0.362)	DT 0.009 (0.322)	loss 8.144 (7.923)	prob 3.267 (2.542)	GS 33.719 (31.334)	mem 76.174
Train: [25][1470/1500]	BT 0.028 (0.371)	DT 0.000 (0.331)	loss 7.997 (7.872)	prob 2.654 (2.549)	GS 30.062 (31.742)	mem 75.221
Train: [25][1480/1500]	BT 0.027 (0.369)	DT 0.000 (0.329)	loss 7.829 (7.868)	prob 3.854 (2.713)	GS 34.281 (31.972)	mem 75.146
Train: [25][1490/1500]	BT 0.027 (0.368)	DT 0.000 (0.328)	loss 8.314 (7.959)	prob 3.291 (2.644)	GS 32.969 (32.291)	mem 11.207
Train: [25][1500/1500]	BT 0.025 (0.366)	DT 0.000 (0.326)	loss 7.815 (7.963)	prob 2.917 (2.636)	GS 36.250 (32.422)	mem 11.207
Train: [25][1510/1500]	BT 0.028 (0.364)	DT 0.000 (0.324)	loss 7.543 (8.016)	prob 3.021 (2.935)	GS 32.094 (32.141)	mem 11.132
epoch 25, total time 550.49
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [26][1/1500]	BT 26.190 (26.190)	DT 26.139 (26.139)	loss 7.321 (7.321)	prob 3.409 (3.409)	GS 31.438 (31.438)	mem 74.994
Train: [26][10/1500]	BT 0.041 (2.655)	DT 0.001 (2.615)	loss 7.604 (7.687)	prob 3.691 (2.823)	GS 29.328 (32.844)	mem 75.006
Train: [26][20/1500]	BT 0.027 (1.342)	DT 0.000 (1.308)	loss 8.078 (7.648)	prob 2.795 (3.000)	GS 32.922 (33.039)	mem 75.007
Train: [26][30/1500]	BT 0.027 (1.046)	DT 0.000 (1.012)	loss 7.639 (7.734)	prob 3.406 (2.948)	GS 29.203 (33.254)	mem 75.053
Train: [26][40/1500]	BT 0.037 (0.793)	DT 0.000 (0.759)	loss 7.977 (7.743)	prob 3.596 (3.038)	GS 31.859 (33.028)	mem 75.052
Train: [26][50/1500]	BT 0.037 (0.707)	DT 0.000 (0.673)	loss 7.561 (7.734)	prob 3.921 (3.054)	GS 28.469 (32.539)	mem 75.068
Train: [26][60/1500]	BT 0.027 (0.609)	DT 0.000 (0.575)	loss 8.274 (7.797)	prob 2.764 (3.271)	GS 36.547 (32.830)	mem 75.082
Train: [26][70/1500]	BT 0.037 (0.526)	DT 0.000 (0.493)	loss 7.838 (7.823)	prob 3.658 (3.262)	GS 33.766 (32.107)	mem 75.083
Train: [26][80/1500]	BT 0.038 (0.502)	DT 0.001 (0.469)	loss 7.824 (7.844)	prob 4.121 (3.379)	GS 33.250 (31.565)	mem 75.097
Train: [26][90/1500]	BT 0.037 (0.451)	DT 0.001 (0.417)	loss 8.113 (7.856)	prob 3.701 (3.415)	GS 29.156 (31.514)	mem 75.097
Train: [26][100/1500]	BT 0.067 (0.488)	DT 0.011 (0.454)	loss 8.434 (7.877)	prob 3.530 (3.369)	GS 33.781 (31.593)	mem 75.103
Train: [26][110/1500]	BT 0.048 (0.493)	DT 0.014 (0.458)	loss 7.957 (8.016)	prob 3.444 (3.374)	GS 28.766 (33.672)	mem 74.984
Train: [26][120/1500]	BT 0.038 (0.458)	DT 0.001 (0.423)	loss 7.961 (7.943)	prob 2.849 (3.170)	GS 30.672 (33.846)	mem 75.006
Train: [26][130/1500]	BT 0.054 (0.444)	DT 0.001 (0.408)	loss 8.297 (7.972)	prob 3.013 (3.132)	GS 32.375 (33.650)	mem 75.018
Train: [26][140/1500]	BT 0.039 (0.436)	DT 0.000 (0.400)	loss 8.009 (7.924)	prob 2.821 (3.152)	GS 33.203 (33.354)	mem 75.026
Train: [26][150/1500]	BT 0.038 (0.418)	DT 0.001 (0.382)	loss 7.872 (7.953)	prob 3.477 (3.132)	GS 34.406 (33.236)	mem 75.028
Train: [26][160/1500]	BT 0.068 (0.415)	DT 0.008 (0.378)	loss 7.895 (7.932)	prob 3.721 (3.422)	GS 31.609 (32.223)	mem 75.030
Train: [26][170/1500]	BT 0.036 (0.406)	DT 0.001 (0.369)	loss 7.778 (7.858)	prob 3.720 (3.551)	GS 34.297 (32.414)	mem 75.034
Train: [26][180/1500]	BT 0.037 (0.385)	DT 0.001 (0.348)	loss 8.574 (7.904)	prob 3.009 (3.507)	GS 34.906 (32.899)	mem 75.035
Train: [26][190/1500]	BT 0.028 (0.375)	DT 0.000 (0.338)	loss 8.674 (7.911)	prob 3.775 (3.493)	GS 31.875 (32.259)	mem 75.038
Train: [26][200/1500]	BT 0.038 (0.364)	DT 0.001 (0.327)	loss 8.251 (7.881)	prob 3.625 (3.529)	GS 35.344 (32.193)	mem 75.059
Train: [26][210/1500]	BT 0.038 (0.356)	DT 0.001 (0.320)	loss 7.763 (7.838)	prob 3.774 (3.561)	GS 33.500 (32.808)	mem 75.060
Train: [26][220/1500]	BT 0.038 (0.357)	DT 0.000 (0.320)	loss 8.250 (7.838)	prob 4.043 (3.503)	GS 38.438 (32.878)	mem 75.063
Train: [26][230/1500]	BT 0.039 (0.349)	DT 0.000 (0.313)	loss 7.993 (7.793)	prob 4.138 (3.440)	GS 39.469 (33.447)	mem 75.067
Train: [26][240/1500]	BT 0.038 (0.337)	DT 0.001 (0.301)	loss 7.742 (7.795)	prob 3.380 (3.427)	GS 35.469 (33.436)	mem 75.068
Train: [26][250/1500]	BT 0.038 (0.343)	DT 0.000 (0.306)	loss 8.416 (7.800)	prob 3.627 (3.470)	GS 33.141 (33.014)	mem 75.058
Train: [26][260/1500]	BT 0.035 (0.338)	DT 0.001 (0.301)	loss 8.846 (7.844)	prob 2.619 (3.229)	GS 34.922 (34.112)	mem 75.058
Train: [26][270/1500]	BT 0.029 (0.358)	DT 0.000 (0.322)	loss 8.022 (7.799)	prob 2.701 (3.194)	GS 38.984 (34.810)	mem 75.406
Train: [26][280/1500]	BT 0.039 (0.347)	DT 0.001 (0.310)	loss 7.359 (7.741)	prob 4.122 (3.408)	GS 31.750 (33.885)	mem 75.455
Train: [26][290/1500]	BT 0.034 (0.350)	DT 0.000 (0.314)	loss 7.827 (7.742)	prob 3.972 (3.486)	GS 29.516 (33.320)	mem 76.041
Train: [26][300/1500]	BT 0.093 (0.340)	DT 0.012 (0.304)	loss 8.203 (7.737)	prob 3.475 (3.513)	GS 33.969 (33.238)	mem 76.042
Train: [26][310/1500]	BT 0.056 (0.332)	DT 0.002 (0.294)	loss 7.441 (7.674)	prob 3.925 (3.754)	GS 33.078 (31.778)	mem 76.090
Train: [26][320/1500]	BT 0.028 (0.340)	DT 0.000 (0.303)	loss 8.009 (7.652)	prob 4.073 (3.807)	GS 35.281 (32.046)	mem 76.190
Train: [26][330/1500]	BT 0.032 (0.331)	DT 0.000 (0.294)	loss 7.910 (7.663)	prob 3.558 (3.836)	GS 34.891 (31.956)	mem 76.199
Train: [26][340/1500]	BT 0.031 (0.344)	DT 0.000 (0.307)	loss 7.654 (7.689)	prob 3.786 (3.591)	GS 32.250 (32.554)	mem 76.255
Train: [26][350/1500]	BT 0.029 (0.344)	DT 0.000 (0.306)	loss 7.458 (7.686)	prob 3.428 (3.512)	GS 33.484 (32.972)	mem 76.257
Train: [26][360/1500]	BT 0.031 (0.335)	DT 0.000 (0.298)	loss 8.003 (7.719)	prob 3.044 (3.121)	GS 34.156 (32.664)	mem 76.261
Train: [26][370/1500]	BT 0.037 (0.331)	DT 0.001 (0.294)	loss 7.398 (7.655)	prob 3.692 (3.173)	GS 31.812 (32.380)	mem 76.263
Train: [26][380/1500]	BT 0.060 (0.330)	DT 0.002 (0.292)	loss 7.689 (7.620)	prob 3.005 (3.307)	GS 33.234 (32.301)	mem 76.264
Train: [26][390/1500]	BT 0.037 (0.338)	DT 0.000 (0.301)	loss 8.350 (7.632)	prob 3.061 (3.253)	GS 34.766 (32.459)	mem 76.261
Train: [26][400/1500]	BT 0.037 (0.331)	DT 0.000 (0.293)	loss 7.623 (7.634)	prob 3.905 (3.269)	GS 34.406 (32.549)	mem 76.261
Train: [26][410/1500]	BT 0.038 (0.330)	DT 0.001 (0.292)	loss 7.799 (7.746)	prob 3.483 (3.170)	GS 34.938 (34.452)	mem 76.264
Train: [26][420/1500]	BT 0.036 (0.327)	DT 0.000 (0.289)	loss 7.657 (7.625)	prob 3.557 (3.334)	GS 30.656 (33.043)	mem 76.264
Train: [26][430/1500]	BT 0.035 (0.331)	DT 0.000 (0.293)	loss 8.067 (7.613)	prob 3.711 (3.386)	GS 37.094 (33.107)	mem 76.270
Train: [26][440/1500]	BT 0.038 (0.324)	DT 0.001 (0.287)	loss 7.237 (7.578)	prob 3.041 (3.335)	GS 33.109 (32.861)	mem 76.272
Train: [26][450/1500]	BT 0.038 (0.319)	DT 0.001 (0.281)	loss 7.607 (7.572)	prob 3.030 (3.280)	GS 35.203 (32.828)	mem 76.271
Train: [26][460/1500]	BT 0.037 (0.321)	DT 0.001 (0.283)	loss 7.551 (7.572)	prob 3.207 (3.015)	GS 35.906 (34.783)	mem 76.275
Train: [26][470/1500]	BT 0.038 (0.315)	DT 0.001 (0.277)	loss 7.481 (7.495)	prob 3.872 (2.965)	GS 33.938 (34.087)	mem 76.275
Train: [26][480/1500]	BT 0.032 (0.316)	DT 0.000 (0.278)	loss 7.929 (7.527)	prob 3.167 (3.128)	GS 34.531 (33.599)	mem 76.280
Train: [26][490/1500]	BT 0.025 (0.310)	DT 0.000 (0.273)	loss 7.715 (7.554)	prob 3.329 (3.133)	GS 36.453 (33.626)	mem 76.280
Train: [26][500/1500]	BT 0.042 (0.333)	DT 0.001 (0.296)	loss 7.490 (7.544)	prob 3.165 (3.124)	GS 35.922 (33.763)	mem 76.282
Train: [26][510/1500]	BT 0.030 (0.327)	DT 0.000 (0.290)	loss 7.507 (7.566)	prob 3.673 (3.021)	GS 33.531 (32.875)	mem 76.283
Train: [26][520/1500]	BT 0.026 (0.322)	DT 0.000 (0.285)	loss 7.245 (7.430)	prob 3.238 (3.177)	GS 30.547 (33.420)	mem 76.284
Train: [26][530/1500]	BT 0.065 (0.328)	DT 0.001 (0.291)	loss 7.084 (7.390)	prob 3.526 (3.164)	GS 35.250 (33.411)	mem 76.285
Train: [26][540/1500]	BT 0.065 (0.323)	DT 0.002 (0.286)	loss 7.297 (7.434)	prob 2.843 (3.056)	GS 30.516 (33.286)	mem 76.285
Train: [26][550/1500]	BT 0.035 (0.329)	DT 0.000 (0.291)	loss 7.584 (7.418)	prob 2.340 (2.951)	GS 31.328 (33.467)	mem 76.284
Train: [26][560/1500]	BT 0.036 (0.324)	DT 0.000 (0.286)	loss 7.124 (7.318)	prob 3.223 (2.978)	GS 33.047 (33.531)	mem 76.285
Train: [26][570/1500]	BT 0.028 (0.354)	DT 0.001 (0.316)	loss 7.398 (7.370)	prob 2.827 (2.901)	GS 36.938 (33.826)	mem 76.284
Train: [26][580/1500]	BT 0.030 (0.348)	DT 0.000 (0.310)	loss 7.401 (7.372)	prob 2.752 (2.738)	GS 36.641 (34.058)	mem 76.285
Train: [26][590/1500]	BT 0.036 (0.343)	DT 0.000 (0.305)	loss 7.670 (7.366)	prob 2.944 (2.766)	GS 32.703 (34.109)	mem 76.285
Train: [26][600/1500]	BT 0.027 (0.344)	DT 0.000 (0.307)	loss 7.461 (7.388)	prob 2.770 (2.741)	GS 35.484 (34.053)	mem 76.287
Train: [26][610/1500]	BT 0.038 (0.339)	DT 0.001 (0.302)	loss 7.682 (7.409)	prob 1.886 (2.248)	GS 35.688 (34.438)	mem 76.288
Train: [26][620/1500]	BT 0.026 (0.341)	DT 0.000 (0.303)	loss 7.665 (7.462)	prob 3.291 (2.365)	GS 30.609 (33.773)	mem 76.291
Train: [26][630/1500]	BT 0.031 (0.336)	DT 0.000 (0.299)	loss 7.384 (7.487)	prob 2.772 (2.411)	GS 33.688 (33.366)	mem 76.292
Train: [26][640/1500]	BT 0.038 (0.336)	DT 0.000 (0.298)	loss 7.328 (7.497)	prob 3.385 (2.465)	GS 30.438 (33.041)	mem 76.293
Train: [26][650/1500]	BT 0.033 (0.331)	DT 0.001 (0.294)	loss 7.275 (7.501)	prob 2.376 (2.437)	GS 33.625 (33.114)	mem 76.293
Train: [26][660/1500]	BT 0.038 (0.326)	DT 0.001 (0.289)	loss 7.785 (7.560)	prob 1.706 (2.573)	GS 34.312 (32.244)	mem 76.295
Train: [26][670/1500]	BT 0.027 (0.345)	DT 0.000 (0.308)	loss 7.452 (7.670)	prob 2.709 (2.257)	GS 35.562 (34.411)	mem 76.290
Train: [26][680/1500]	BT 0.023 (0.340)	DT 0.000 (0.304)	loss 7.357 (7.581)	prob 2.967 (2.352)	GS 30.422 (33.330)	mem 76.291
Train: [26][690/1500]	BT 0.028 (0.342)	DT 0.000 (0.305)	loss 8.059 (7.604)	prob 2.272 (2.408)	GS 34.344 (33.095)	mem 76.323
Train: [26][700/1500]	BT 0.040 (0.338)	DT 0.001 (0.301)	loss 7.538 (7.620)	prob 3.010 (2.459)	GS 34.641 (32.869)	mem 76.325
Train: [26][710/1500]	BT 0.040 (0.333)	DT 0.001 (0.297)	loss 7.342 (7.661)	prob 3.285 (2.903)	GS 30.984 (30.436)	mem 76.326
Train: [26][720/1500]	BT 0.030 (0.336)	DT 0.000 (0.299)	loss 8.196 (7.758)	prob 2.667 (2.798)	GS 32.641 (31.414)	mem 76.324
Train: [26][730/1500]	BT 0.035 (0.332)	DT 0.001 (0.295)	loss 8.359 (7.791)	prob 3.055 (2.747)	GS 32.281 (31.988)	mem 76.324
Train: [26][740/1500]	BT 0.025 (0.331)	DT 0.000 (0.295)	loss 8.384 (7.830)	prob 2.501 (2.636)	GS 36.766 (32.112)	mem 76.326
Train: [26][750/1500]	BT 0.028 (0.327)	DT 0.000 (0.291)	loss 8.001 (7.838)	prob 3.656 (2.664)	GS 30.719 (32.139)	mem 76.326
Train: [26][760/1500]	BT 0.049 (0.330)	DT 0.001 (0.294)	loss 8.558 (7.807)	prob 2.112 (3.256)	GS 31.625 (31.492)	mem 76.326
Train: [26][770/1500]	BT 0.046 (0.326)	DT 0.000 (0.290)	loss 8.024 (7.898)	prob 3.407 (3.199)	GS 30.734 (31.249)	mem 76.327
Train: [26][780/1500]	BT 0.038 (0.323)	DT 0.000 (0.286)	loss 7.988 (7.906)	prob 3.465 (3.317)	GS 35.297 (31.565)	mem 76.326
Train: [26][790/1500]	BT 0.039 (0.327)	DT 0.001 (0.290)	loss 8.198 (7.960)	prob 3.536 (3.174)	GS 30.234 (31.823)	mem 76.326
Train: [26][800/1500]	BT 0.039 (0.326)	DT 0.000 (0.289)	loss 8.982 (8.000)	prob 3.455 (3.178)	GS 33.750 (31.973)	mem 76.328
Train: [26][810/1500]	BT 0.039 (0.324)	DT 0.001 (0.287)	loss 8.155 (8.118)	prob 3.514 (3.155)	GS 32.125 (31.558)	mem 76.328
Train: [26][820/1500]	BT 0.040 (0.324)	DT 0.001 (0.287)	loss 7.583 (8.054)	prob 4.048 (3.309)	GS 33.594 (31.875)	mem 76.329
Train: [26][830/1500]	BT 0.039 (0.320)	DT 0.001 (0.284)	loss 8.419 (8.048)	prob 4.532 (3.418)	GS 32.734 (31.850)	mem 76.329
Train: [26][840/1500]	BT 0.039 (0.318)	DT 0.001 (0.281)	loss 8.706 (8.037)	prob 4.127 (3.509)	GS 32.641 (31.823)	mem 76.329
Train: [26][850/1500]	BT 0.029 (0.324)	DT 0.000 (0.287)	loss 8.150 (7.970)	prob 3.772 (3.565)	GS 37.828 (32.258)	mem 76.330
Train: [26][860/1500]	BT 0.039 (0.320)	DT 0.001 (0.284)	loss 8.388 (7.838)	prob 3.490 (3.472)	GS 37.203 (33.288)	mem 76.331
Train: [26][870/1500]	BT 0.038 (0.321)	DT 0.000 (0.284)	loss 8.256 (7.902)	prob 3.680 (3.624)	GS 35.062 (33.509)	mem 76.333
Train: [26][880/1500]	BT 0.039 (0.318)	DT 0.001 (0.281)	loss 8.065 (7.911)	prob 4.235 (3.524)	GS 35.266 (33.634)	mem 76.334
Train: [26][890/1500]	BT 0.039 (0.315)	DT 0.001 (0.278)	loss 8.113 (7.947)	prob 4.720 (3.628)	GS 30.828 (33.282)	mem 76.334
Train: [26][900/1500]	BT 0.029 (0.317)	DT 0.000 (0.280)	loss 7.727 (7.958)	prob 4.091 (3.674)	GS 34.047 (33.207)	mem 76.334
Train: [26][910/1500]	BT 0.025 (0.314)	DT 0.000 (0.277)	loss 7.926 (7.880)	prob 4.243 (4.196)	GS 35.906 (32.450)	mem 76.337
Train: [26][920/1500]	BT 0.039 (0.316)	DT 0.004 (0.280)	loss 7.895 (7.903)	prob 4.100 (4.012)	GS 36.734 (33.114)	mem 76.343
Train: [26][930/1500]	BT 0.072 (0.314)	DT 0.005 (0.277)	loss 8.240 (7.937)	prob 4.650 (3.983)	GS 33.141 (32.701)	mem 76.341
Train: [26][940/1500]	BT 0.057 (0.320)	DT 0.007 (0.283)	loss 8.453 (7.951)	prob 4.693 (4.091)	GS 35.047 (32.924)	mem 76.339
Train: [26][950/1500]	BT 0.032 (0.321)	DT 0.000 (0.283)	loss 7.960 (7.943)	prob 3.486 (4.083)	GS 34.594 (33.047)	mem 76.349
Train: [26][960/1500]	BT 0.037 (0.317)	DT 0.000 (0.280)	loss 8.815 (8.001)	prob 4.422 (4.030)	GS 33.156 (31.189)	mem 76.350
Train: [26][970/1500]	BT 0.038 (0.315)	DT 0.001 (0.278)	loss 7.681 (7.898)	prob 4.532 (4.231)	GS 37.531 (31.910)	mem 76.349
Train: [26][980/1500]	BT 0.038 (0.315)	DT 0.001 (0.278)	loss 7.741 (7.944)	prob 3.916 (4.026)	GS 34.391 (32.411)	mem 76.351
Train: [26][990/1500]	BT 0.038 (0.315)	DT 0.001 (0.278)	loss 8.051 (7.899)	prob 4.839 (3.982)	GS 30.422 (32.196)	mem 76.249
Train: [26][1000/1500]	BT 0.064 (0.312)	DT 0.016 (0.275)	loss 8.271 (7.910)	prob 3.820 (4.035)	GS 35.406 (32.498)	mem 76.249
Train: [26][1010/1500]	BT 0.058 (0.310)	DT 0.011 (0.273)	loss 7.877 (7.878)	prob 3.745 (3.860)	GS 34.422 (34.434)	mem 76.248
Train: [26][1020/1500]	BT 0.037 (0.314)	DT 0.000 (0.277)	loss 7.437 (7.804)	prob 4.136 (3.812)	GS 31.703 (33.270)	mem 76.250
Train: [26][1030/1500]	BT 0.037 (0.312)	DT 0.001 (0.275)	loss 7.846 (7.832)	prob 4.299 (3.811)	GS 33.031 (32.754)	mem 76.250
Train: [26][1040/1500]	BT 0.037 (0.312)	DT 0.001 (0.275)	loss 7.855 (7.806)	prob 4.841 (3.902)	GS 31.766 (32.384)	mem 76.252
Train: [26][1050/1500]	BT 0.038 (0.310)	DT 0.001 (0.272)	loss 7.856 (7.820)	prob 3.573 (3.888)	GS 35.062 (32.447)	mem 76.252
Train: [26][1060/1500]	BT 0.044 (0.310)	DT 0.000 (0.272)	loss 8.092 (7.798)	prob 5.108 (4.091)	GS 30.062 (32.839)	mem 76.254
Train: [26][1070/1500]	BT 0.038 (0.310)	DT 0.001 (0.273)	loss 7.605 (7.832)	prob 3.895 (4.053)	GS 34.531 (32.925)	mem 76.274
Train: [26][1080/1500]	BT 0.038 (0.308)	DT 0.001 (0.270)	loss 7.731 (7.795)	prob 3.670 (4.137)	GS 31.109 (32.706)	mem 76.274
Train: [26][1090/1500]	BT 0.038 (0.306)	DT 0.001 (0.268)	loss 7.619 (7.803)	prob 3.826 (4.164)	GS 35.359 (32.220)	mem 76.275
Train: [26][1100/1500]	BT 0.029 (0.308)	DT 0.000 (0.270)	loss 7.940 (7.768)	prob 4.190 (4.137)	GS 33.297 (32.355)	mem 76.280
Train: [26][1110/1500]	BT 0.038 (0.305)	DT 0.001 (0.268)	loss 7.964 (7.796)	prob 4.771 (3.948)	GS 33.359 (31.634)	mem 76.280
Train: [26][1120/1500]	BT 0.038 (0.305)	DT 0.001 (0.268)	loss 7.665 (7.787)	prob 4.302 (3.966)	GS 36.547 (32.491)	mem 76.268
Train: [26][1130/1500]	BT 0.053 (0.303)	DT 0.002 (0.266)	loss 7.433 (7.723)	prob 4.936 (3.921)	GS 33.281 (32.434)	mem 76.267
Train: [26][1140/1500]	BT 0.039 (0.301)	DT 0.001 (0.264)	loss 7.882 (7.735)	prob 4.417 (3.952)	GS 35.328 (32.237)	mem 76.267
Train: [26][1150/1500]	BT 0.029 (0.301)	DT 0.000 (0.264)	loss 7.609 (7.721)	prob 4.456 (4.011)	GS 38.016 (32.028)	mem 76.268
Train: [26][1160/1500]	BT 0.039 (0.299)	DT 0.001 (0.262)	loss 7.735 (7.538)	prob 3.742 (3.919)	GS 35.844 (33.589)	mem 76.269
Train: [26][1170/1500]	BT 0.035 (0.303)	DT 0.001 (0.266)	loss 7.406 (7.514)	prob 4.006 (3.940)	GS 36.000 (34.048)	mem 76.267
Train: [26][1180/1500]	BT 0.036 (0.301)	DT 0.001 (0.264)	loss 8.176 (7.589)	prob 4.260 (3.836)	GS 35.234 (33.813)	mem 76.267
Train: [26][1190/1500]	BT 0.033 (0.303)	DT 0.000 (0.266)	loss 7.774 (7.589)	prob 3.949 (3.829)	GS 31.578 (33.712)	mem 76.269
Train: [26][1200/1500]	BT 0.036 (0.301)	DT 0.001 (0.263)	loss 7.831 (7.568)	prob 4.009 (3.912)	GS 31.891 (33.472)	mem 76.270
Train: [26][1210/1500]	BT 0.062 (0.299)	DT 0.023 (0.261)	loss 7.657 (7.532)	prob 3.679 (3.932)	GS 33.312 (33.836)	mem 76.271
Train: [26][1220/1500]	BT 0.028 (0.300)	DT 0.000 (0.263)	loss 7.318 (7.571)	prob 3.195 (3.632)	GS 36.891 (33.852)	mem 76.282
Train: [26][1230/1500]	BT 0.037 (0.298)	DT 0.000 (0.260)	loss 7.897 (7.524)	prob 4.106 (3.661)	GS 36.844 (33.968)	mem 76.283
Train: [26][1240/1500]	BT 0.037 (0.299)	DT 0.001 (0.262)	loss 7.240 (7.484)	prob 4.902 (3.799)	GS 33.609 (33.542)	mem 76.289
Train: [26][1250/1500]	BT 0.037 (0.297)	DT 0.001 (0.260)	loss 7.234 (7.458)	prob 4.072 (3.828)	GS 32.984 (33.375)	mem 76.289
Train: [26][1260/1500]	BT 0.030 (0.298)	DT 0.000 (0.261)	loss 7.264 (7.452)	prob 4.408 (4.274)	GS 32.781 (32.777)	mem 76.292
Train: [26][1270/1500]	BT 0.026 (0.296)	DT 0.000 (0.259)	loss 7.616 (7.422)	prob 4.188 (4.084)	GS 36.141 (32.222)	mem 76.294
Train: [26][1280/1500]	BT 0.037 (0.294)	DT 0.001 (0.257)	loss 7.206 (7.420)	prob 4.421 (3.998)	GS 34.188 (32.381)	mem 76.294
Train: [26][1290/1500]	BT 0.048 (0.294)	DT 0.012 (0.257)	loss 7.480 (7.412)	prob 3.419 (3.991)	GS 37.672 (32.305)	mem 76.295
Train: [26][1300/1500]	BT 0.037 (0.292)	DT 0.001 (0.255)	loss 7.137 (7.384)	prob 4.629 (3.948)	GS 33.906 (32.299)	mem 76.297
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [26][1310/1500]	BT 0.069 (0.295)	DT 0.016 (0.258)	loss 7.003 (7.359)	prob 3.561 (3.936)	GS 33.812 (32.186)	mem 76.295
Train: [26][1320/1500]	BT 0.033 (0.296)	DT 0.000 (0.258)	loss 7.310 (7.438)	prob 3.098 (3.579)	GS 34.891 (33.465)	mem 76.295
Train: [26][1330/1500]	BT 0.038 (0.294)	DT 0.001 (0.256)	loss 7.602 (7.424)	prob 4.313 (3.595)	GS 31.766 (33.163)	mem 76.296
Train: [26][1340/1500]	BT 0.036 (0.296)	DT 0.000 (0.259)	loss 7.689 (7.433)	prob 4.406 (3.699)	GS 32.438 (32.770)	mem 76.296
Train: [26][1350/1500]	BT 0.036 (0.294)	DT 0.000 (0.257)	loss 7.207 (7.412)	prob 4.418 (3.751)	GS 33.312 (32.524)	mem 76.296
Train: [26][1360/1500]	BT 0.037 (0.292)	DT 0.001 (0.255)	loss 7.275 (7.370)	prob 3.983 (3.771)	GS 33.734 (31.587)	mem 76.296
Train: [26][1370/1500]	BT 0.032 (0.294)	DT 0.000 (0.257)	loss 7.158 (7.329)	prob 2.938 (3.722)	GS 33.328 (32.434)	mem 76.302
Train: [26][1380/1500]	BT 0.048 (0.292)	DT 0.000 (0.255)	loss 7.430 (7.318)	prob 3.770 (3.647)	GS 33.172 (32.499)	mem 76.302
Train: [26][1390/1500]	BT 0.030 (0.297)	DT 0.000 (0.259)	loss 7.245 (7.329)	prob 3.388 (3.675)	GS 35.062 (32.525)	mem 76.305
Train: [26][1400/1500]	BT 0.042 (0.295)	DT 0.001 (0.258)	loss 7.559 (7.330)	prob 3.432 (3.652)	GS 31.391 (32.574)	mem 76.305
Train: [26][1410/1500]	BT 0.027 (0.301)	DT 0.000 (0.264)	loss 7.024 (7.414)	prob 3.765 (3.238)	GS 39.156 (35.048)	mem 76.306
Train: [26][1420/1500]	BT 0.023 (0.299)	DT 0.000 (0.262)	loss 7.184 (7.319)	prob 3.574 (3.435)	GS 33.625 (33.894)	mem 76.307
Train: [26][1430/1500]	BT 0.069 (0.302)	DT 0.020 (0.265)	loss 7.592 (7.329)	prob 3.466 (3.474)	GS 28.859 (33.418)	mem 76.308
Train: [26][1440/1500]	BT 0.083 (0.300)	DT 0.008 (0.263)	loss 7.167 (7.303)	prob 3.753 (3.464)	GS 40.328 (33.405)	mem 76.308
Train: [26][1450/1500]	BT 0.080 (0.299)	DT 0.009 (0.261)	loss 7.235 (7.291)	prob 4.256 (3.433)	GS 32.266 (33.320)	mem 76.307
Train: [26][1460/1500]	BT 0.027 (0.309)	DT 0.000 (0.271)	loss 7.250 (7.194)	prob 3.623 (3.354)	GS 33.016 (33.311)	mem 75.429
Train: [26][1470/1500]	BT 0.029 (0.307)	DT 0.000 (0.269)	loss 7.122 (7.179)	prob 3.529 (3.356)	GS 35.828 (33.074)	mem 75.355
Train: [26][1480/1500]	BT 0.026 (0.308)	DT 0.000 (0.270)	loss 7.387 (7.193)	prob 3.358 (3.407)	GS 29.984 (32.440)	mem 11.209
Train: [26][1490/1500]	BT 0.024 (0.306)	DT 0.000 (0.269)	loss 7.215 (7.165)	prob 2.888 (3.397)	GS 35.438 (32.523)	mem 11.209
Train: [26][1500/1500]	BT 0.025 (0.304)	DT 0.000 (0.267)	loss 6.971 (7.172)	prob 4.147 (3.373)	GS 39.719 (32.698)	mem 11.209
Train: [26][1510/1500]	BT 0.034 (0.303)	DT 0.001 (0.266)	loss 6.715 (7.034)	prob 2.916 (3.183)	GS 35.125 (34.353)	mem 11.138
epoch 26, total time 457.35
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [27][1/1500]	BT 18.790 (18.790)	DT 18.740 (18.740)	loss 6.869 (6.869)	prob 3.101 (3.101)	GS 32.094 (32.094)	mem 74.699
Train: [27][10/1500]	BT 0.037 (2.323)	DT 0.001 (2.285)	loss 6.947 (6.983)	prob 3.566 (3.605)	GS 34.078 (33.887)	mem 74.837
Train: [27][20/1500]	BT 0.038 (1.182)	DT 0.001 (1.145)	loss 6.978 (7.002)	prob 3.571 (3.454)	GS 32.766 (33.235)	mem 74.866
Train: [27][30/1500]	BT 0.515 (0.939)	DT 0.478 (0.902)	loss 7.140 (7.067)	prob 3.791 (3.493)	GS 29.297 (32.436)	mem 74.903
Train: [27][40/1500]	BT 0.038 (0.714)	DT 0.001 (0.676)	loss 7.223 (7.091)	prob 3.163 (3.455)	GS 31.969 (31.873)	mem 74.931
Train: [27][50/1500]	BT 1.239 (0.607)	DT 1.201 (0.570)	loss 6.965 (7.094)	prob 3.194 (3.413)	GS 34.625 (32.186)	mem 74.933
Train: [27][60/1500]	BT 0.038 (0.556)	DT 0.001 (0.519)	loss 6.988 (7.155)	prob 3.278 (3.307)	GS 31.938 (30.775)	mem 74.936
Train: [27][70/1500]	BT 0.039 (0.499)	DT 0.001 (0.462)	loss 7.097 (7.121)	prob 3.908 (3.288)	GS 33.406 (31.957)	mem 74.945
Train: [27][80/1500]	BT 0.033 (0.471)	DT 0.000 (0.433)	loss 7.069 (7.111)	prob 3.839 (3.253)	GS 36.109 (31.643)	mem 74.950
Train: [27][90/1500]	BT 0.077 (0.462)	DT 0.018 (0.424)	loss 7.351 (7.115)	prob 3.016 (3.196)	GS 33.031 (31.805)	mem 74.952
Train: [27][100/1500]	BT 0.030 (0.435)	DT 0.000 (0.397)	loss 7.200 (7.114)	prob 2.355 (3.197)	GS 32.859 (31.826)	mem 74.956
Train: [27][110/1500]	BT 0.038 (0.434)	DT 0.001 (0.396)	loss 6.988 (7.046)	prob 3.024 (3.058)	GS 32.500 (32.292)	mem 74.958
Train: [27][120/1500]	BT 0.055 (0.406)	DT 0.009 (0.368)	loss 7.236 (7.055)	prob 2.608 (2.941)	GS 32.844 (32.055)	mem 74.958
Train: [27][130/1500]	BT 0.091 (0.398)	DT 0.022 (0.358)	loss 7.275 (7.070)	prob 2.969 (2.912)	GS 31.875 (31.426)	mem 74.960
Train: [27][140/1500]	BT 0.045 (0.439)	DT 0.001 (0.398)	loss 7.082 (7.057)	prob 2.744 (2.859)	GS 28.953 (31.691)	mem 74.977
Train: [27][150/1500]	BT 0.038 (0.412)	DT 0.001 (0.372)	loss 7.093 (7.059)	prob 3.551 (2.849)	GS 35.156 (31.945)	mem 74.979
Train: [27][160/1500]	BT 0.029 (0.445)	DT 0.000 (0.405)	loss 7.340 (7.079)	prob 3.261 (3.180)	GS 35.250 (35.589)	mem 74.984
Train: [27][170/1500]	BT 0.031 (0.420)	DT 0.000 (0.381)	loss 6.921 (7.040)	prob 3.260 (3.091)	GS 33.266 (33.795)	mem 74.983
Train: [27][180/1500]	BT 0.025 (0.398)	DT 0.000 (0.360)	loss 7.033 (7.061)	prob 3.238 (2.988)	GS 31.672 (33.115)	mem 74.984
Train: [27][190/1500]	BT 0.029 (0.405)	DT 0.000 (0.367)	loss 7.164 (7.085)	prob 2.546 (2.827)	GS 33.391 (33.048)	mem 74.996
Train: [27][200/1500]	BT 0.039 (0.387)	DT 0.001 (0.349)	loss 7.465 (7.089)	prob 3.086 (2.813)	GS 32.672 (33.072)	mem 74.997
Train: [27][210/1500]	BT 0.034 (0.385)	DT 0.001 (0.347)	loss 6.963 (7.044)	prob 3.345 (2.725)	GS 33.922 (32.278)	mem 75.001
Train: [27][220/1500]	BT 0.039 (0.369)	DT 0.001 (0.331)	loss 6.978 (7.084)	prob 2.215 (2.699)	GS 34.062 (32.634)	mem 75.001
Train: [27][230/1500]	BT 0.066 (0.367)	DT 0.007 (0.329)	loss 6.991 (7.130)	prob 2.703 (2.647)	GS 34.688 (32.916)	mem 75.001
Train: [27][240/1500]	BT 0.061 (0.354)	DT 0.001 (0.315)	loss 6.955 (7.111)	prob 2.463 (2.645)	GS 33.484 (32.714)	mem 75.001
Train: [27][250/1500]	BT 0.061 (0.342)	DT 0.004 (0.303)	loss 7.217 (7.099)	prob 2.453 (2.602)	GS 37.516 (32.752)	mem 75.001
Train: [27][260/1500]	BT 0.072 (0.357)	DT 0.006 (0.317)	loss 7.333 (7.244)	prob 2.341 (2.259)	GS 36.125 (31.772)	mem 75.004
Train: [27][270/1500]	BT 0.048 (0.354)	DT 0.000 (0.314)	loss 7.099 (7.245)	prob 2.417 (2.073)	GS 32.516 (31.562)	mem 75.005
Train: [27][280/1500]	BT 0.029 (0.390)	DT 0.000 (0.350)	loss 7.886 (7.259)	prob 1.993 (2.106)	GS 31.625 (31.998)	mem 75.005
Train: [27][290/1500]	BT 0.035 (0.378)	DT 0.000 (0.338)	loss 7.363 (7.255)	prob 2.230 (2.067)	GS 35.281 (31.956)	mem 75.007
Train: [27][300/1500]	BT 0.028 (0.394)	DT 0.000 (0.355)	loss 7.349 (7.274)	prob 1.116 (1.926)	GS 33.016 (31.992)	mem 75.016
Train: [27][310/1500]	BT 0.037 (0.382)	DT 0.001 (0.343)	loss 7.699 (7.497)	prob 1.907 (1.438)	GS 34.312 (31.334)	mem 75.018
Train: [27][320/1500]	BT 0.027 (0.384)	DT 0.000 (0.345)	loss 8.934 (7.600)	prob 0.845 (1.395)	GS 36.000 (31.766)	mem 75.070
Train: [27][330/1500]	BT 0.026 (0.373)	DT 0.000 (0.334)	loss 7.583 (7.575)	prob 2.151 (1.574)	GS 37.141 (31.837)	mem 75.080
Train: [27][340/1500]	BT 0.039 (0.363)	DT 0.001 (0.324)	loss 7.485 (7.589)	prob 1.682 (1.627)	GS 35.953 (32.048)	mem 75.080
Train: [27][350/1500]	BT 0.025 (0.366)	DT 0.000 (0.327)	loss 7.724 (7.577)	prob 2.774 (1.666)	GS 35.156 (31.992)	mem 75.520
Train: [27][360/1500]	BT 0.037 (0.357)	DT 0.000 (0.318)	loss 7.484 (7.590)	prob 3.110 (2.025)	GS 33.516 (33.053)	mem 75.522
Train: [27][370/1500]	BT 0.026 (0.358)	DT 0.000 (0.320)	loss 7.851 (7.672)	prob 2.120 (1.915)	GS 31.516 (32.869)	mem 76.057
Train: [27][380/1500]	BT 0.037 (0.350)	DT 0.000 (0.312)	loss 7.806 (7.701)	prob 2.306 (1.823)	GS 34.016 (32.862)	mem 76.107
Train: [27][390/1500]	BT 0.038 (0.342)	DT 0.000 (0.304)	loss 8.114 (7.700)	prob 2.686 (1.901)	GS 34.656 (32.701)	mem 76.106
Train: [27][400/1500]	BT 0.028 (0.346)	DT 0.000 (0.308)	loss 7.741 (7.698)	prob 2.138 (1.938)	GS 33.828 (32.739)	mem 76.111
Train: [27][410/1500]	BT 0.026 (0.338)	DT 0.000 (0.301)	loss 7.549 (7.694)	prob 2.074 (1.801)	GS 32.938 (32.667)	mem 76.110
Train: [27][420/1500]	BT 0.028 (0.342)	DT 0.000 (0.305)	loss 7.737 (7.674)	prob 2.293 (1.927)	GS 33.328 (32.580)	mem 76.118
Train: [27][430/1500]	BT 0.027 (0.335)	DT 0.000 (0.298)	loss 8.566 (7.650)	prob 1.898 (1.977)	GS 36.031 (32.230)	mem 76.130
Train: [27][440/1500]	BT 0.034 (0.338)	DT 0.001 (0.301)	loss 7.996 (7.654)	prob 2.540 (2.121)	GS 35.031 (32.121)	mem 76.135
Train: [27][450/1500]	BT 0.026 (0.331)	DT 0.000 (0.294)	loss 8.217 (7.687)	prob 2.414 (2.093)	GS 34.875 (32.352)	mem 76.136
Train: [27][460/1500]	BT 0.038 (0.325)	DT 0.001 (0.288)	loss 8.269 (7.746)	prob 2.756 (2.335)	GS 33.734 (32.877)	mem 76.136
Train: [27][470/1500]	BT 0.038 (0.325)	DT 0.001 (0.288)	loss 7.877 (7.817)	prob 2.416 (2.331)	GS 34.000 (33.047)	mem 76.137
Train: [27][480/1500]	BT 0.039 (0.319)	DT 0.001 (0.282)	loss 7.193 (7.752)	prob 2.545 (2.435)	GS 32.109 (32.663)	mem 76.138
Train: [27][490/1500]	BT 0.039 (0.318)	DT 0.001 (0.282)	loss 7.745 (7.741)	prob 3.051 (2.451)	GS 34.703 (32.595)	mem 76.138
Train: [27][500/1500]	BT 0.039 (0.313)	DT 0.001 (0.276)	loss 7.541 (7.757)	prob 1.986 (2.422)	GS 31.516 (32.603)	mem 76.138
Train: [27][510/1500]	BT 0.038 (0.307)	DT 0.001 (0.271)	loss 7.796 (7.748)	prob 2.903 (2.595)	GS 35.031 (32.533)	mem 76.138
Train: [27][520/1500]	BT 0.078 (0.312)	DT 0.018 (0.275)	loss 7.583 (7.799)	prob 2.658 (2.442)	GS 33.516 (33.089)	mem 76.124
Train: [27][530/1500]	BT 0.035 (0.308)	DT 0.001 (0.271)	loss 7.791 (7.766)	prob 2.918 (2.387)	GS 38.656 (33.157)	mem 76.125
Train: [27][540/1500]	BT 0.062 (0.315)	DT 0.002 (0.277)	loss 8.441 (7.775)	prob 3.131 (2.545)	GS 30.812 (32.821)	mem 76.126
Train: [27][550/1500]	BT 0.032 (0.324)	DT 0.000 (0.286)	loss 8.016 (7.788)	prob 2.986 (2.562)	GS 34.672 (33.439)	mem 76.126
Train: [27][560/1500]	BT 0.031 (0.319)	DT 0.000 (0.281)	loss 8.005 (7.758)	prob 3.709 (3.249)	GS 33.016 (32.648)	mem 76.126
Train: [27][570/1500]	BT 0.033 (0.314)	DT 0.001 (0.276)	loss 7.682 (7.722)	prob 3.841 (3.138)	GS 31.609 (32.541)	mem 76.127
Train: [27][580/1500]	BT 0.029 (0.318)	DT 0.000 (0.281)	loss 7.443 (7.743)	prob 3.860 (3.112)	GS 32.594 (32.885)	mem 76.140
Train: [27][590/1500]	BT 0.031 (0.313)	DT 0.000 (0.276)	loss 8.258 (7.739)	prob 2.502 (3.024)	GS 31.953 (32.999)	mem 76.141
Train: [27][600/1500]	BT 0.037 (0.313)	DT 0.001 (0.276)	loss 7.783 (7.726)	prob 3.546 (3.092)	GS 31.750 (32.719)	mem 76.144
Train: [27][610/1500]	BT 0.028 (0.309)	DT 0.000 (0.272)	loss 8.443 (7.608)	prob 3.363 (3.309)	GS 32.312 (30.644)	mem 76.145
Train: [27][620/1500]	BT 0.035 (0.312)	DT 0.000 (0.275)	loss 7.549 (7.625)	prob 3.518 (3.228)	GS 31.328 (30.920)	mem 76.150
Train: [27][630/1500]	BT 0.036 (0.307)	DT 0.000 (0.270)	loss 7.463 (7.600)	prob 3.799 (3.203)	GS 31.266 (31.395)	mem 76.150
Train: [27][640/1500]	BT 0.037 (0.303)	DT 0.000 (0.266)	loss 8.179 (7.611)	prob 2.893 (3.133)	GS 34.422 (31.586)	mem 76.151
Train: [27][650/1500]	BT 0.035 (0.304)	DT 0.000 (0.267)	loss 7.825 (7.607)	prob 3.951 (3.170)	GS 31.438 (31.611)	mem 76.153
Train: [27][660/1500]	BT 0.037 (0.300)	DT 0.000 (0.263)	loss 7.865 (7.595)	prob 3.314 (3.047)	GS 31.984 (32.164)	mem 76.156
Train: [27][670/1500]	BT 0.161 (0.300)	DT 0.124 (0.263)	loss 7.418 (7.533)	prob 3.383 (3.092)	GS 34.391 (32.703)	mem 76.157
Train: [27][680/1500]	BT 0.038 (0.296)	DT 0.001 (0.260)	loss 7.417 (7.541)	prob 3.159 (3.045)	GS 31.453 (32.518)	mem 76.157
Train: [27][690/1500]	BT 0.037 (0.293)	DT 0.001 (0.256)	loss 8.012 (7.532)	prob 2.922 (3.095)	GS 33.047 (32.455)	mem 76.157
Train: [27][700/1500]	BT 0.038 (0.296)	DT 0.000 (0.259)	loss 7.427 (7.531)	prob 3.273 (3.105)	GS 32.828 (32.183)	mem 76.161
Train: [27][710/1500]	BT 0.034 (0.293)	DT 0.000 (0.256)	loss 7.396 (7.377)	prob 3.886 (3.421)	GS 30.641 (31.230)	mem 76.162
Train: [27][720/1500]	BT 0.037 (0.298)	DT 0.001 (0.261)	loss 7.251 (7.413)	prob 3.567 (3.340)	GS 32.375 (31.765)	mem 76.162
Train: [27][730/1500]	BT 0.037 (0.295)	DT 0.001 (0.258)	loss 7.533 (7.418)	prob 2.935 (3.269)	GS 31.797 (32.029)	mem 76.162
Train: [27][740/1500]	BT 0.037 (0.291)	DT 0.001 (0.254)	loss 7.382 (7.438)	prob 4.047 (3.209)	GS 32.656 (32.418)	mem 76.163
Train: [27][750/1500]	BT 0.075 (0.296)	DT 0.010 (0.259)	loss 7.636 (7.443)	prob 3.826 (3.246)	GS 31.672 (32.405)	mem 76.164
Train: [27][760/1500]	BT 0.083 (0.294)	DT 0.014 (0.257)	loss 7.685 (7.462)	prob 3.281 (3.543)	GS 36.078 (31.636)	mem 76.165
Train: [27][770/1500]	BT 0.064 (0.298)	DT 0.008 (0.260)	loss 7.468 (7.485)	prob 3.758 (3.453)	GS 33.922 (31.941)	mem 76.168
Train: [27][780/1500]	BT 0.026 (0.314)	DT 0.000 (0.276)	loss 7.611 (7.471)	prob 3.556 (3.398)	GS 36.250 (32.042)	mem 76.170
Train: [27][790/1500]	BT 0.030 (0.310)	DT 0.000 (0.273)	loss 7.388 (7.472)	prob 3.296 (3.383)	GS 32.984 (32.064)	mem 76.170
Train: [27][800/1500]	BT 0.036 (0.307)	DT 0.000 (0.269)	loss 8.048 (7.437)	prob 2.904 (3.392)	GS 34.344 (32.011)	mem 76.170
Train: [27][810/1500]	BT 0.036 (0.308)	DT 0.000 (0.271)	loss 7.526 (7.410)	prob 2.594 (3.214)	GS 30.922 (32.736)	mem 76.175
Train: [27][820/1500]	BT 0.038 (0.305)	DT 0.000 (0.267)	loss 7.334 (7.383)	prob 3.755 (3.442)	GS 31.734 (32.630)	mem 76.175
Train: [27][830/1500]	BT 0.060 (0.307)	DT 0.000 (0.269)	loss 7.499 (7.389)	prob 4.178 (3.392)	GS 34.672 (32.674)	mem 76.175
Train: [27][840/1500]	BT 0.101 (0.304)	DT 0.004 (0.266)	loss 7.280 (7.374)	prob 3.434 (3.316)	GS 36.047 (32.881)	mem 76.176
Train: [27][850/1500]	BT 0.067 (0.310)	DT 0.011 (0.272)	loss 7.789 (7.385)	prob 2.793 (3.228)	GS 31.859 (32.792)	mem 76.176
Train: [27][860/1500]	BT 0.030 (0.314)	DT 0.000 (0.276)	loss 7.584 (7.357)	prob 3.396 (2.973)	GS 34.281 (32.986)	mem 76.175
Train: [27][870/1500]	BT 0.023 (0.311)	DT 0.000 (0.273)	loss 7.494 (7.335)	prob 2.494 (3.086)	GS 31.734 (32.865)	mem 76.175
Train: [27][880/1500]	BT 0.023 (0.313)	DT 0.000 (0.275)	loss 7.726 (7.361)	prob 2.147 (3.103)	GS 36.766 (33.123)	mem 76.179
Train: [27][890/1500]	BT 0.037 (0.310)	DT 0.001 (0.272)	loss 7.370 (7.338)	prob 3.279 (3.098)	GS 33.266 (33.169)	mem 76.181
Train: [27][900/1500]	BT 0.037 (0.307)	DT 0.001 (0.269)	loss 7.148 (7.345)	prob 3.368 (3.123)	GS 34.500 (32.968)	mem 76.182
Train: [27][910/1500]	BT 0.028 (0.308)	DT 0.000 (0.271)	loss 7.589 (7.298)	prob 2.572 (3.239)	GS 33.719 (32.398)	mem 76.214
Train: [27][920/1500]	BT 0.028 (0.305)	DT 0.000 (0.268)	loss 7.041 (7.278)	prob 3.512 (3.349)	GS 28.062 (31.973)	mem 76.214
Train: [27][930/1500]	BT 0.042 (0.305)	DT 0.001 (0.268)	loss 7.175 (7.303)	prob 3.262 (3.210)	GS 30.562 (32.335)	mem 76.216
Train: [27][940/1500]	BT 0.049 (0.303)	DT 0.014 (0.265)	loss 7.484 (7.310)	prob 3.416 (3.050)	GS 29.297 (32.269)	mem 76.217
Train: [27][950/1500]	BT 4.382 (0.305)	DT 4.341 (0.267)	loss 7.289 (7.284)	prob 2.914 (3.057)	GS 35.828 (32.457)	mem 76.215
Train: [27][960/1500]	BT 0.061 (0.302)	DT 0.006 (0.264)	loss 7.740 (7.183)	prob 2.939 (3.151)	GS 37.266 (32.191)	mem 76.215
Train: [27][970/1500]	BT 0.048 (0.300)	DT 0.000 (0.262)	loss 7.247 (7.191)	prob 3.121 (3.119)	GS 29.297 (31.728)	mem 76.216
Train: [27][980/1500]	BT 0.039 (0.302)	DT 0.001 (0.264)	loss 7.404 (7.215)	prob 3.064 (3.072)	GS 33.812 (32.447)	mem 76.217
Train: [27][990/1500]	BT 0.039 (0.300)	DT 0.001 (0.262)	loss 7.580 (7.230)	prob 2.991 (3.064)	GS 32.219 (32.466)	mem 76.216
Train: [27][1000/1500]	BT 0.044 (0.302)	DT 0.001 (0.264)	loss 7.098 (7.237)	prob 3.709 (3.097)	GS 31.688 (32.440)	mem 76.216
Train: [27][1010/1500]	BT 0.051 (0.300)	DT 0.000 (0.262)	loss 7.225 (7.150)	prob 3.394 (3.061)	GS 28.875 (32.205)	mem 76.217
Train: [27][1020/1500]	BT 0.040 (0.300)	DT 0.001 (0.262)	loss 7.346 (7.142)	prob 2.967 (2.988)	GS 33.719 (31.822)	mem 76.217
Train: [27][1030/1500]	BT 0.039 (0.300)	DT 0.001 (0.262)	loss 7.101 (7.146)	prob 3.255 (2.933)	GS 32.172 (31.794)	mem 76.215
Train: [27][1040/1500]	BT 0.039 (0.298)	DT 0.001 (0.260)	loss 7.262 (7.132)	prob 3.281 (2.920)	GS 35.234 (31.872)	mem 76.214
Train: [27][1050/1500]	BT 0.039 (0.300)	DT 0.001 (0.262)	loss 7.013 (7.131)	prob 2.819 (2.853)	GS 36.406 (32.101)	mem 76.214
Train: [27][1060/1500]	BT 0.039 (0.297)	DT 0.001 (0.259)	loss 7.259 (7.097)	prob 2.466 (2.803)	GS 30.062 (30.809)	mem 76.214
Train: [27][1070/1500]	BT 4.201 (0.299)	DT 4.164 (0.261)	loss 6.898 (7.124)	prob 3.097 (2.807)	GS 31.844 (30.977)	mem 76.215
Train: [27][1080/1500]	BT 0.039 (0.296)	DT 0.000 (0.258)	loss 7.248 (7.113)	prob 2.834 (2.863)	GS 37.828 (31.340)	mem 76.216
Train: [27][1090/1500]	BT 0.030 (0.294)	DT 0.001 (0.256)	loss 7.015 (7.126)	prob 2.980 (2.773)	GS 34.750 (31.777)	mem 76.217
Train: [27][1100/1500]	BT 0.031 (0.297)	DT 0.000 (0.259)	loss 7.285 (7.130)	prob 2.613 (2.706)	GS 33.688 (31.765)	mem 76.219
Train: [27][1110/1500]	BT 0.046 (0.295)	DT 0.008 (0.257)	loss 6.951 (7.032)	prob 3.263 (2.565)	GS 33.812 (31.200)	mem 76.219
Train: [27][1120/1500]	BT 0.062 (0.301)	DT 0.002 (0.263)	loss 7.359 (7.086)	prob 3.220 (2.677)	GS 33.188 (32.602)	mem 76.222
Train: [27][1130/1500]	BT 0.032 (0.299)	DT 0.000 (0.261)	loss 6.715 (7.047)	prob 3.260 (2.744)	GS 33.594 (32.461)	mem 76.220
Train: [27][1140/1500]	BT 0.032 (0.311)	DT 0.000 (0.273)	loss 7.202 (7.045)	prob 2.863 (2.752)	GS 32.000 (32.920)	mem 76.221
Train: [27][1150/1500]	BT 0.031 (0.309)	DT 0.000 (0.271)	loss 6.941 (7.037)	prob 2.809 (2.741)	GS 33.156 (32.906)	mem 76.223
Train: [27][1160/1500]	BT 2.758 (0.309)	DT 2.719 (0.271)	loss 6.917 (6.987)	prob 2.685 (2.631)	GS 29.109 (33.981)	mem 76.224
Train: [27][1170/1500]	BT 0.039 (0.307)	DT 0.001 (0.268)	loss 6.997 (7.027)	prob 3.484 (2.786)	GS 31.422 (33.382)	mem 76.223
Train: [27][1180/1500]	BT 0.039 (0.304)	DT 0.001 (0.266)	loss 6.925 (7.002)	prob 3.186 (2.889)	GS 35.641 (33.497)	mem 76.223
Train: [27][1190/1500]	BT 0.039 (0.304)	DT 0.001 (0.266)	loss 6.779 (6.975)	prob 3.271 (2.951)	GS 34.953 (33.261)	mem 76.222
Train: [27][1200/1500]	BT 0.036 (0.302)	DT 0.001 (0.264)	loss 6.977 (6.958)	prob 3.086 (2.985)	GS 33.234 (33.348)	mem 76.220
Train: [27][1210/1500]	BT 0.037 (0.303)	DT 0.001 (0.265)	loss 7.485 (7.046)	prob 2.202 (2.914)	GS 35.938 (33.567)	mem 76.226
Train: [27][1220/1500]	BT 0.037 (0.302)	DT 0.000 (0.264)	loss 6.750 (6.955)	prob 3.086 (2.972)	GS 36.266 (33.581)	mem 76.228
Train: [27][1230/1500]	BT 0.037 (0.299)	DT 0.000 (0.261)	loss 6.739 (6.904)	prob 2.606 (2.871)	GS 34.047 (33.160)	mem 76.227
Train: [27][1240/1500]	BT 0.038 (0.300)	DT 0.001 (0.262)	loss 6.695 (6.889)	prob 3.483 (2.870)	GS 34.797 (33.221)	mem 76.239
Train: [27][1250/1500]	BT 0.037 (0.299)	DT 0.001 (0.261)	loss 7.099 (6.891)	prob 3.063 (2.893)	GS 30.562 (33.008)	mem 76.257
Train: [27][1260/1500]	BT 0.854 (0.298)	DT 0.817 (0.260)	loss 6.876 (6.848)	prob 3.232 (3.126)	GS 32.484 (31.678)	mem 76.139
Train: [27][1270/1500]	BT 0.037 (0.299)	DT 0.000 (0.261)	loss 6.610 (6.834)	prob 3.289 (3.126)	GS 36.391 (32.460)	mem 76.141
Train: [27][1280/1500]	BT 0.037 (0.296)	DT 0.001 (0.259)	loss 6.807 (6.848)	prob 3.253 (3.176)	GS 35.250 (32.669)	mem 76.141
Train: [27][1290/1500]	BT 0.036 (0.297)	DT 0.001 (0.259)	loss 7.142 (6.879)	prob 3.061 (3.123)	GS 32.000 (32.652)	mem 76.140
Train: [27][1300/1500]	BT 0.028 (0.296)	DT 0.000 (0.258)	loss 6.760 (6.886)	prob 3.066 (3.148)	GS 33.219 (32.603)	mem 76.143
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [27][1310/1500]	BT 0.037 (0.294)	DT 0.001 (0.256)	loss 7.037 (7.075)	prob 3.682 (3.141)	GS 33.078 (31.764)	mem 76.143
Train: [27][1320/1500]	BT 0.047 (0.297)	DT 0.006 (0.259)	loss 7.048 (7.037)	prob 2.745 (3.123)	GS 32.438 (31.966)	mem 76.144
Train: [27][1330/1500]	BT 0.038 (0.295)	DT 0.001 (0.257)	loss 6.833 (7.022)	prob 3.309 (3.034)	GS 37.828 (32.252)	mem 76.144
Train: [27][1340/1500]	BT 0.031 (0.296)	DT 0.000 (0.258)	loss 6.936 (7.022)	prob 3.606 (3.004)	GS 34.453 (32.449)	mem 76.165
Train: [27][1350/1500]	BT 0.037 (0.295)	DT 0.001 (0.257)	loss 7.272 (7.021)	prob 2.771 (3.013)	GS 34.000 (32.775)	mem 76.164
Train: [27][1360/1500]	BT 0.039 (0.293)	DT 0.001 (0.255)	loss 7.066 (7.092)	prob 2.850 (2.968)	GS 30.062 (33.748)	mem 76.165
Train: [27][1370/1500]	BT 0.038 (0.294)	DT 0.001 (0.256)	loss 6.931 (7.067)	prob 3.181 (3.071)	GS 34.984 (33.740)	mem 76.165
Train: [27][1380/1500]	BT 0.038 (0.292)	DT 0.001 (0.254)	loss 7.101 (7.077)	prob 2.872 (3.131)	GS 34.047 (33.125)	mem 76.165
Train: [27][1390/1500]	BT 0.039 (0.292)	DT 0.001 (0.254)	loss 7.132 (7.060)	prob 2.850 (3.164)	GS 33.844 (33.026)	mem 76.152
Train: [27][1400/1500]	BT 0.081 (0.291)	DT 0.042 (0.253)	loss 7.051 (7.057)	prob 3.004 (3.146)	GS 28.906 (32.726)	mem 76.152
Train: [27][1410/1500]	BT 2.933 (0.291)	DT 2.894 (0.254)	loss 7.034 (6.980)	prob 2.374 (2.887)	GS 33.750 (32.052)	mem 76.152
Train: [27][1420/1500]	BT 0.039 (0.290)	DT 0.001 (0.253)	loss 6.935 (7.026)	prob 2.828 (2.897)	GS 35.297 (32.556)	mem 76.153
Train: [27][1430/1500]	BT 0.039 (0.289)	DT 0.001 (0.251)	loss 6.904 (7.000)	prob 3.351 (2.890)	GS 32.109 (32.597)	mem 76.152
Train: [27][1440/1500]	BT 0.038 (0.290)	DT 0.001 (0.252)	loss 6.916 (6.993)	prob 2.688 (2.880)	GS 35.391 (32.614)	mem 76.154
Train: [27][1450/1500]	BT 0.038 (0.288)	DT 0.001 (0.250)	loss 7.008 (7.007)	prob 3.141 (2.838)	GS 31.438 (32.260)	mem 76.153
Train: [27][1460/1500]	BT 0.024 (0.290)	DT 0.000 (0.252)	loss 6.943 (7.016)	prob 3.295 (2.956)	GS 32.781 (32.197)	mem 75.433
Train: [27][1470/1500]	BT 0.030 (0.288)	DT 0.000 (0.250)	loss 6.913 (6.998)	prob 2.711 (2.842)	GS 35.484 (32.437)	mem 75.362
Train: [27][1480/1500]	BT 0.023 (0.286)	DT 0.000 (0.249)	loss 6.681 (6.976)	prob 3.059 (2.878)	GS 32.656 (32.162)	mem 75.252
Train: [27][1490/1500]	BT 0.027 (0.286)	DT 0.000 (0.249)	loss 6.809 (6.974)	prob 1.908 (2.838)	GS 35.375 (32.235)	mem 16.810
Train: [27][1500/1500]	BT 0.030 (0.285)	DT 0.000 (0.247)	loss 6.843 (6.971)	prob 3.068 (2.822)	GS 39.438 (32.434)	mem 16.810
Train: [27][1510/1500]	BT 0.030 (0.283)	DT 0.000 (0.246)	loss 7.262 (6.854)	prob 1.953 (2.733)	GS 28.562 (31.484)	mem 11.083
epoch 27, total time 428.16
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [28][1/1500]	BT 20.743 (20.743)	DT 20.696 (20.696)	loss 6.644 (6.644)	prob 2.866 (2.866)	GS 29.609 (29.609)	mem 74.604
Train: [28][10/1500]	BT 0.075 (2.832)	DT 0.003 (2.783)	loss 6.527 (6.647)	prob 2.653 (2.682)	GS 35.812 (32.905)	mem 74.814
Train: [28][20/1500]	BT 0.112 (1.464)	DT 0.007 (1.395)	loss 6.754 (6.730)	prob 2.576 (2.589)	GS 34.859 (32.796)	mem 74.815
Train: [28][30/1500]	BT 0.075 (1.203)	DT 0.006 (1.133)	loss 6.835 (6.767)	prob 2.981 (2.650)	GS 32.734 (32.978)	mem 74.853
Train: [28][40/1500]	BT 0.039 (0.917)	DT 0.001 (0.852)	loss 6.912 (6.770)	prob 1.683 (2.637)	GS 33.016 (33.265)	mem 74.859
Train: [28][50/1500]	BT 0.028 (1.015)	DT 0.000 (0.956)	loss 6.495 (6.801)	prob 3.752 (2.685)	GS 30.094 (33.179)	mem 74.874
Train: [28][60/1500]	BT 0.027 (0.850)	DT 0.000 (0.797)	loss 6.850 (6.934)	prob 3.543 (3.138)	GS 35.031 (32.933)	mem 74.874
Train: [28][70/1500]	BT 0.030 (0.785)	DT 0.000 (0.735)	loss 7.139 (6.868)	prob 3.290 (3.105)	GS 33.875 (32.791)	mem 74.900
Train: [28][80/1500]	BT 0.037 (0.690)	DT 0.001 (0.643)	loss 6.664 (6.870)	prob 2.723 (2.980)	GS 32.406 (32.620)	mem 74.902
Train: [28][90/1500]	BT 0.027 (0.617)	DT 0.000 (0.571)	loss 6.857 (6.862)	prob 2.231 (2.858)	GS 38.859 (32.987)	mem 74.901
Train: [28][100/1500]	BT 0.054 (0.606)	DT 0.000 (0.560)	loss 7.263 (6.863)	prob 2.081 (2.799)	GS 33.562 (32.893)	mem 74.933
Train: [28][110/1500]	BT 0.052 (0.556)	DT 0.001 (0.510)	loss 6.941 (6.880)	prob 2.311 (2.613)	GS 30.000 (31.678)	mem 74.933
Train: [28][120/1500]	BT 0.090 (0.586)	DT 0.008 (0.539)	loss 6.817 (6.867)	prob 2.463 (2.486)	GS 31.984 (31.463)	mem 74.945
Train: [28][130/1500]	BT 0.027 (0.629)	DT 0.000 (0.583)	loss 6.712 (6.841)	prob 2.328 (2.432)	GS 35.328 (31.716)	mem 74.957
Train: [28][140/1500]	BT 0.034 (0.587)	DT 0.000 (0.541)	loss 7.016 (6.843)	prob 1.550 (2.270)	GS 32.188 (32.151)	mem 74.958
Train: [28][150/1500]	BT 0.065 (0.592)	DT 0.002 (0.547)	loss 7.089 (6.859)	prob 1.717 (2.188)	GS 33.750 (32.508)	mem 74.963
Train: [28][160/1500]	BT 0.072 (0.559)	DT 0.030 (0.514)	loss 7.479 (6.951)	prob 1.833 (1.528)	GS 36.906 (34.847)	mem 74.964
Train: [28][170/1500]	BT 0.037 (0.530)	DT 0.001 (0.484)	loss 6.791 (6.977)	prob 2.517 (1.774)	GS 35.516 (33.601)	mem 74.967
Train: [28][180/1500]	BT 0.031 (0.525)	DT 0.000 (0.481)	loss 7.736 (7.004)	prob 1.594 (1.806)	GS 35.359 (33.937)	mem 74.967
Train: [28][190/1500]	BT 0.056 (0.500)	DT 0.002 (0.455)	loss 6.883 (7.032)	prob 1.810 (1.800)	GS 28.391 (33.536)	mem 74.971
Train: [28][200/1500]	BT 0.046 (0.492)	DT 0.000 (0.447)	loss 6.853 (7.031)	prob 2.339 (1.808)	GS 34.359 (33.320)	mem 74.973
Train: [28][210/1500]	BT 0.038 (0.482)	DT 0.001 (0.438)	loss 7.391 (7.316)	prob 1.982 (1.508)	GS 31.953 (32.958)	mem 74.972
Train: [28][220/1500]	BT 4.780 (0.484)	DT 4.747 (0.439)	loss 8.370 (7.452)	prob 0.731 (1.239)	GS 33.641 (33.131)	mem 74.971
Train: [28][230/1500]	BT 0.029 (0.499)	DT 0.000 (0.456)	loss 7.183 (7.385)	prob 1.958 (1.301)	GS 33.969 (33.836)	mem 74.977
Train: [28][240/1500]	BT 0.035 (0.480)	DT 0.000 (0.437)	loss 7.931 (7.447)	prob 0.952 (1.273)	GS 34.688 (33.923)	mem 74.978
Train: [28][250/1500]	BT 0.024 (0.479)	DT 0.001 (0.436)	loss 7.869 (7.479)	prob 2.171 (1.383)	GS 33.000 (33.572)	mem 75.012
Train: [28][260/1500]	BT 0.026 (0.462)	DT 0.000 (0.420)	loss 8.244 (7.506)	prob 1.413 (1.721)	GS 35.891 (33.991)	mem 75.012
Train: [28][270/1500]	BT 0.030 (0.457)	DT 0.000 (0.415)	loss 7.692 (7.410)	prob 1.882 (1.798)	GS 29.672 (33.252)	mem 75.015
Train: [28][280/1500]	BT 0.032 (0.441)	DT 0.000 (0.400)	loss 7.363 (7.496)	prob 3.519 (2.049)	GS 27.656 (32.541)	mem 75.016
Train: [28][290/1500]	BT 0.039 (0.427)	DT 0.001 (0.386)	loss 8.014 (7.511)	prob 1.848 (2.066)	GS 37.609 (32.833)	mem 75.018
Train: [28][300/1500]	BT 0.036 (0.436)	DT 0.001 (0.395)	loss 7.453 (7.525)	prob 2.253 (2.079)	GS 31.344 (33.028)	mem 75.020
Train: [28][310/1500]	BT 0.038 (0.423)	DT 0.001 (0.382)	loss 8.176 (7.454)	prob 2.616 (2.867)	GS 34.594 (31.434)	mem 75.021
Train: [28][320/1500]	BT 0.039 (0.414)	DT 0.000 (0.373)	loss 8.082 (7.537)	prob 2.436 (2.545)	GS 35.250 (32.090)	mem 75.020
Train: [28][330/1500]	BT 0.039 (0.408)	DT 0.001 (0.367)	loss 7.480 (7.538)	prob 2.295 (2.526)	GS 32.688 (32.298)	mem 75.020
Train: [28][340/1500]	BT 0.040 (0.397)	DT 0.001 (0.357)	loss 8.374 (7.562)	prob 2.314 (2.500)	GS 33.422 (32.447)	mem 75.021
Train: [28][350/1500]	BT 0.039 (0.396)	DT 0.001 (0.355)	loss 7.409 (7.558)	prob 3.093 (2.512)	GS 32.359 (32.449)	mem 75.020
Train: [28][360/1500]	BT 0.039 (0.386)	DT 0.001 (0.345)	loss 8.306 (7.517)	prob 2.909 (2.964)	GS 34.719 (31.887)	mem 75.020
Train: [28][370/1500]	BT 0.069 (0.384)	DT 0.005 (0.343)	loss 7.577 (7.509)	prob 2.360 (2.862)	GS 33.438 (31.893)	mem 75.022
Train: [28][380/1500]	BT 0.031 (0.397)	DT 0.000 (0.357)	loss 7.616 (7.524)	prob 3.059 (2.908)	GS 28.781 (32.426)	mem 75.021
Train: [28][390/1500]	BT 0.038 (0.388)	DT 0.001 (0.347)	loss 8.037 (7.520)	prob 2.261 (2.892)	GS 34.578 (32.811)	mem 75.022
Train: [28][400/1500]	BT 0.038 (0.387)	DT 0.001 (0.346)	loss 7.878 (7.551)	prob 2.766 (2.877)	GS 34.625 (32.839)	mem 75.024
Train: [28][410/1500]	BT 0.058 (0.378)	DT 0.007 (0.338)	loss 7.658 (7.796)	prob 3.761 (2.910)	GS 33.562 (34.814)	mem 75.025
Train: [28][420/1500]	BT 0.028 (0.388)	DT 0.000 (0.347)	loss 7.901 (7.656)	prob 3.256 (3.132)	GS 33.641 (34.017)	mem 75.414
Train: [28][430/1500]	BT 0.038 (0.380)	DT 0.001 (0.339)	loss 8.189 (7.674)	prob 2.931 (3.047)	GS 34.047 (33.350)	mem 75.415
Train: [28][440/1500]	BT 0.040 (0.372)	DT 0.001 (0.331)	loss 7.574 (7.624)	prob 3.687 (3.098)	GS 35.031 (33.064)	mem 75.550
Train: [28][450/1500]	BT 0.035 (0.375)	DT 0.001 (0.334)	loss 7.139 (7.575)	prob 3.293 (3.117)	GS 35.984 (33.056)	mem 76.101
Train: [28][460/1500]	BT 0.039 (0.368)	DT 0.001 (0.327)	loss 7.871 (7.590)	prob 2.663 (2.994)	GS 32.203 (32.547)	mem 76.102
Train: [28][470/1500]	BT 0.037 (0.369)	DT 0.001 (0.328)	loss 7.655 (7.629)	prob 3.374 (2.961)	GS 32.797 (33.386)	mem 76.197
Train: [28][480/1500]	BT 0.037 (0.362)	DT 0.000 (0.322)	loss 7.482 (7.532)	prob 3.843 (3.109)	GS 31.375 (32.803)	mem 76.199
Train: [28][490/1500]	BT 0.058 (0.363)	DT 0.000 (0.323)	loss 8.036 (7.546)	prob 3.473 (3.102)	GS 34.906 (32.829)	mem 76.200
Train: [28][500/1500]	BT 0.027 (0.360)	DT 0.000 (0.320)	loss 8.841 (7.563)	prob 2.080 (3.105)	GS 32.859 (32.713)	mem 76.202
Train: [28][510/1500]	BT 0.037 (0.354)	DT 0.000 (0.314)	loss 7.062 (7.332)	prob 3.667 (3.499)	GS 34.188 (33.258)	mem 76.204
Train: [28][520/1500]	BT 0.030 (0.363)	DT 0.000 (0.323)	loss 7.320 (7.332)	prob 3.308 (3.374)	GS 34.594 (33.057)	mem 76.219
Train: [28][530/1500]	BT 0.027 (0.356)	DT 0.000 (0.317)	loss 7.432 (7.322)	prob 3.175 (3.351)	GS 31.250 (32.898)	mem 76.219
Train: [28][540/1500]	BT 0.033 (0.350)	DT 0.000 (0.311)	loss 7.706 (7.355)	prob 3.000 (3.233)	GS 33.297 (32.978)	mem 76.219
Train: [28][550/1500]	BT 0.069 (0.357)	DT 0.011 (0.318)	loss 7.193 (7.375)	prob 3.395 (3.157)	GS 33.781 (32.836)	mem 76.221
Train: [28][560/1500]	BT 0.039 (0.352)	DT 0.000 (0.312)	loss 7.285 (7.332)	prob 3.069 (3.529)	GS 32.938 (31.842)	mem 76.223
Train: [28][570/1500]	BT 0.024 (0.355)	DT 0.000 (0.315)	loss 7.449 (7.344)	prob 3.511 (3.435)	GS 27.922 (32.835)	mem 76.122
Train: [28][580/1500]	BT 0.024 (0.349)	DT 0.000 (0.309)	loss 7.761 (7.351)	prob 3.559 (3.422)	GS 33.812 (32.895)	mem 76.123
Train: [28][590/1500]	BT 0.037 (0.344)	DT 0.001 (0.304)	loss 7.176 (7.337)	prob 3.821 (3.420)	GS 34.672 (33.176)	mem 76.124
Train: [28][600/1500]	BT 0.039 (0.346)	DT 0.001 (0.306)	loss 7.462 (7.341)	prob 3.408 (3.474)	GS 32.125 (33.002)	mem 76.127
Train: [28][610/1500]	BT 0.034 (0.340)	DT 0.000 (0.301)	loss 7.251 (7.387)	prob 3.866 (3.604)	GS 34.328 (32.855)	mem 76.128
Train: [28][620/1500]	BT 0.031 (0.345)	DT 0.000 (0.306)	loss 7.368 (7.337)	prob 3.637 (3.608)	GS 32.562 (32.904)	mem 76.125
Train: [28][630/1500]	BT 0.058 (0.340)	DT 0.011 (0.301)	loss 7.249 (7.350)	prob 3.840 (3.585)	GS 32.047 (32.618)	mem 76.127
Train: [28][640/1500]	BT 0.030 (0.350)	DT 0.000 (0.311)	loss 7.546 (7.351)	prob 3.647 (3.522)	GS 33.750 (32.441)	mem 76.129
Train: [28][650/1500]	BT 0.025 (0.345)	DT 0.000 (0.306)	loss 7.322 (7.335)	prob 4.021 (3.516)	GS 31.328 (32.693)	mem 76.129
Train: [28][660/1500]	BT 0.034 (0.341)	DT 0.001 (0.302)	loss 7.254 (7.422)	prob 4.060 (3.738)	GS 31.406 (32.478)	mem 76.130
Train: [28][670/1500]	BT 0.036 (0.341)	DT 0.001 (0.302)	loss 7.179 (7.343)	prob 3.130 (3.613)	GS 32.438 (32.159)	mem 76.149
Train: [28][680/1500]	BT 0.037 (0.337)	DT 0.001 (0.298)	loss 7.494 (7.311)	prob 3.907 (3.597)	GS 32.000 (31.728)	mem 76.149
Train: [28][690/1500]	BT 0.024 (0.343)	DT 0.000 (0.305)	loss 7.225 (7.302)	prob 3.399 (3.530)	GS 33.469 (32.208)	mem 76.138
Train: [28][700/1500]	BT 0.031 (0.339)	DT 0.001 (0.300)	loss 7.248 (7.275)	prob 2.634 (3.470)	GS 33.609 (32.164)	mem 76.138
Train: [28][710/1500]	BT 0.035 (0.334)	DT 0.001 (0.296)	loss 7.333 (7.239)	prob 3.289 (3.546)	GS 35.328 (31.980)	mem 76.139
Train: [28][720/1500]	BT 0.038 (0.336)	DT 0.001 (0.297)	loss 6.920 (7.235)	prob 4.603 (3.582)	GS 26.891 (31.944)	mem 76.140
Train: [28][730/1500]	BT 0.039 (0.332)	DT 0.001 (0.293)	loss 7.207 (7.246)	prob 3.974 (3.616)	GS 33.703 (32.284)	mem 76.140
Train: [28][740/1500]	BT 0.052 (0.333)	DT 0.004 (0.295)	loss 7.292 (7.233)	prob 3.234 (3.597)	GS 34.953 (32.508)	mem 76.141
Train: [28][750/1500]	BT 0.063 (0.330)	DT 0.002 (0.291)	loss 7.326 (7.212)	prob 3.715 (3.535)	GS 34.766 (32.686)	mem 76.141
Train: [28][760/1500]	BT 0.048 (0.338)	DT 0.015 (0.299)	loss 7.158 (7.216)	prob 3.886 (3.637)	GS 33.062 (32.105)	mem 76.143
Train: [28][770/1500]	BT 0.061 (0.334)	DT 0.006 (0.295)	loss 7.675 (7.200)	prob 2.961 (3.344)	GS 34.016 (31.920)	mem 76.144
Train: [28][780/1500]	BT 0.028 (0.346)	DT 0.000 (0.307)	loss 6.971 (7.197)	prob 3.778 (3.274)	GS 29.938 (32.032)	mem 76.145
Train: [28][790/1500]	BT 0.031 (0.342)	DT 0.000 (0.304)	loss 7.391 (7.200)	prob 2.789 (3.269)	GS 35.031 (32.303)	mem 76.145
Train: [28][800/1500]	BT 0.038 (0.343)	DT 0.001 (0.305)	loss 7.108 (7.185)	prob 2.946 (3.273)	GS 37.297 (32.348)	mem 76.147
Train: [28][810/1500]	BT 0.039 (0.340)	DT 0.001 (0.301)	loss 7.126 (7.157)	prob 2.876 (2.935)	GS 35.969 (34.122)	mem 76.150
Train: [28][820/1500]	BT 0.039 (0.336)	DT 0.000 (0.297)	loss 7.194 (7.147)	prob 3.215 (3.182)	GS 31.797 (32.898)	mem 76.152
Train: [28][830/1500]	BT 0.030 (0.337)	DT 0.000 (0.299)	loss 7.274 (7.163)	prob 2.805 (3.150)	GS 31.266 (32.657)	mem 76.166
Train: [28][840/1500]	BT 0.037 (0.334)	DT 0.000 (0.295)	loss 7.070 (7.158)	prob 3.744 (3.161)	GS 32.453 (32.573)	mem 76.166
Train: [28][850/1500]	BT 0.028 (0.333)	DT 0.000 (0.295)	loss 7.387 (7.169)	prob 2.925 (3.115)	GS 34.391 (32.443)	mem 76.169
Train: [28][860/1500]	BT 0.037 (0.330)	DT 0.001 (0.291)	loss 7.319 (7.154)	prob 3.009 (2.962)	GS 33.750 (32.156)	mem 76.169
Train: [28][870/1500]	BT 0.037 (0.326)	DT 0.000 (0.288)	loss 7.427 (7.098)	prob 2.784 (2.976)	GS 33.875 (32.301)	mem 76.170
Train: [28][880/1500]	BT 0.037 (0.327)	DT 0.001 (0.288)	loss 7.067 (7.104)	prob 2.837 (2.977)	GS 34.984 (32.586)	mem 76.172
Train: [28][890/1500]	BT 0.037 (0.324)	DT 0.001 (0.285)	loss 7.536 (7.107)	prob 2.875 (2.979)	GS 35.656 (32.679)	mem 76.172
Train: [28][900/1500]	BT 0.162 (0.324)	DT 0.124 (0.285)	loss 7.194 (7.090)	prob 2.390 (3.000)	GS 34.812 (32.643)	mem 76.176
Train: [28][910/1500]	BT 0.038 (0.321)	DT 0.001 (0.282)	loss 7.063 (7.154)	prob 2.251 (3.159)	GS 32.969 (31.670)	mem 76.176
Train: [28][920/1500]	BT 1.369 (0.322)	DT 1.332 (0.283)	loss 7.285 (7.178)	prob 2.273 (2.912)	GS 32.297 (31.898)	mem 76.177
Train: [28][930/1500]	BT 0.038 (0.319)	DT 0.001 (0.281)	loss 7.406 (7.163)	prob 2.726 (2.972)	GS 35.062 (32.032)	mem 76.178
Train: [28][940/1500]	BT 0.033 (0.317)	DT 0.001 (0.279)	loss 6.893 (7.152)	prob 3.369 (3.019)	GS 32.531 (32.202)	mem 76.177
Train: [28][950/1500]	BT 0.081 (0.316)	DT 0.035 (0.278)	loss 7.121 (7.130)	prob 2.890 (2.985)	GS 35.484 (32.222)	mem 76.182
Train: [28][960/1500]	BT 0.058 (0.317)	DT 0.006 (0.279)	loss 6.695 (6.969)	prob 3.410 (2.952)	GS 31.453 (31.470)	mem 76.182
Train: [28][970/1500]	BT 0.047 (0.316)	DT 0.004 (0.278)	loss 6.919 (6.943)	prob 2.675 (3.004)	GS 36.656 (32.102)	mem 76.182
Train: [28][980/1500]	BT 0.031 (0.317)	DT 0.000 (0.278)	loss 7.040 (6.934)	prob 3.447 (3.021)	GS 30.812 (32.566)	mem 76.181
Train: [28][990/1500]	BT 0.063 (0.314)	DT 0.016 (0.275)	loss 6.779 (6.939)	prob 2.927 (3.004)	GS 39.422 (32.838)	mem 76.182
Train: [28][1000/1500]	BT 0.038 (0.321)	DT 0.000 (0.283)	loss 6.843 (6.936)	prob 3.432 (2.961)	GS 32.703 (32.755)	mem 76.181
Train: [28][1010/1500]	BT 0.027 (0.319)	DT 0.000 (0.280)	loss 6.748 (6.899)	prob 3.344 (2.932)	GS 36.547 (32.653)	mem 76.182
Train: [28][1020/1500]	BT 0.037 (0.316)	DT 0.001 (0.277)	loss 6.808 (6.898)	prob 2.734 (2.811)	GS 29.562 (32.685)	mem 76.183
Train: [28][1030/1500]	BT 0.022 (0.321)	DT 0.000 (0.283)	loss 6.561 (6.882)	prob 3.260 (2.846)	GS 30.250 (32.710)	mem 76.184
Train: [28][1040/1500]	BT 0.033 (0.319)	DT 0.001 (0.280)	loss 6.755 (6.870)	prob 2.184 (2.844)	GS 37.344 (33.098)	mem 76.185
Train: [28][1050/1500]	BT 0.028 (0.318)	DT 0.000 (0.280)	loss 7.053 (6.878)	prob 2.610 (2.874)	GS 35.312 (33.157)	mem 76.186
Train: [28][1060/1500]	BT 0.038 (0.316)	DT 0.001 (0.277)	loss 6.584 (6.852)	prob 3.316 (3.219)	GS 34.500 (32.984)	mem 76.186
Train: [28][1070/1500]	BT 0.037 (0.317)	DT 0.001 (0.279)	loss 6.810 (6.875)	prob 3.409 (3.239)	GS 35.469 (32.838)	mem 76.186
Train: [28][1080/1500]	BT 0.037 (0.315)	DT 0.000 (0.276)	loss 6.953 (6.858)	prob 2.981 (3.207)	GS 35.438 (32.203)	mem 76.186
Train: [28][1090/1500]	BT 0.037 (0.312)	DT 0.001 (0.274)	loss 6.809 (6.860)	prob 3.422 (3.163)	GS 32.891 (31.963)	mem 76.187
Train: [28][1100/1500]	BT 0.083 (0.313)	DT 0.004 (0.275)	loss 6.694 (6.876)	prob 2.813 (3.104)	GS 31.500 (32.094)	mem 76.186
Train: [28][1110/1500]	BT 0.055 (0.311)	DT 0.011 (0.272)	loss 6.879 (6.850)	prob 3.162 (3.248)	GS 32.391 (33.320)	mem 76.187
Train: [28][1120/1500]	BT 0.038 (0.315)	DT 0.001 (0.276)	loss 6.910 (6.844)	prob 2.702 (3.178)	GS 31.922 (33.145)	mem 76.186
Train: [28][1130/1500]	BT 0.030 (0.314)	DT 0.000 (0.275)	loss 7.012 (6.867)	prob 3.301 (3.269)	GS 40.000 (33.477)	mem 76.186
Train: [28][1140/1500]	BT 0.038 (0.312)	DT 0.000 (0.273)	loss 6.814 (6.891)	prob 3.315 (3.292)	GS 31.859 (32.951)	mem 76.187
Train: [28][1150/1500]	BT 0.037 (0.312)	DT 0.001 (0.273)	loss 7.025 (6.901)	prob 2.554 (3.259)	GS 33.516 (32.891)	mem 76.189
Train: [28][1160/1500]	BT 0.037 (0.309)	DT 0.001 (0.271)	loss 6.934 (6.887)	prob 3.171 (3.259)	GS 29.719 (31.545)	mem 76.189
Train: [28][1170/1500]	BT 0.039 (0.310)	DT 0.001 (0.272)	loss 6.849 (6.877)	prob 3.015 (3.032)	GS 37.531 (32.239)	mem 76.221
Train: [28][1180/1500]	BT 0.067 (0.308)	DT 0.008 (0.270)	loss 6.929 (6.890)	prob 3.207 (2.921)	GS 32.656 (32.328)	mem 76.222
Train: [28][1190/1500]	BT 0.039 (0.308)	DT 0.000 (0.270)	loss 6.956 (6.887)	prob 3.186 (2.983)	GS 32.203 (32.362)	mem 76.225
Train: [28][1200/1500]	BT 0.040 (0.308)	DT 0.001 (0.269)	loss 6.981 (6.913)	prob 3.045 (3.007)	GS 35.828 (32.515)	mem 76.226
Train: [28][1210/1500]	BT 0.038 (0.305)	DT 0.001 (0.267)	loss 6.971 (6.971)	prob 3.292 (2.862)	GS 35.484 (33.866)	mem 76.226
Train: [28][1220/1500]	BT 0.038 (0.305)	DT 0.001 (0.267)	loss 7.246 (6.968)	prob 2.609 (2.996)	GS 32.750 (33.490)	mem 76.226
Train: [28][1230/1500]	BT 0.038 (0.303)	DT 0.001 (0.265)	loss 7.049 (6.968)	prob 2.888 (2.978)	GS 34.219 (33.493)	mem 76.226
Train: [28][1240/1500]	BT 0.038 (0.304)	DT 0.001 (0.266)	loss 6.880 (6.974)	prob 2.606 (2.973)	GS 36.750 (33.229)	mem 76.227
Train: [28][1250/1500]	BT 0.038 (0.303)	DT 0.001 (0.264)	loss 6.901 (6.966)	prob 2.790 (2.959)	GS 33.578 (33.262)	mem 76.226
Train: [28][1260/1500]	BT 0.039 (0.301)	DT 0.001 (0.262)	loss 6.722 (6.944)	prob 3.289 (2.982)	GS 35.969 (32.248)	mem 76.226
Train: [28][1270/1500]	BT 0.037 (0.301)	DT 0.001 (0.263)	loss 6.879 (6.962)	prob 2.733 (2.873)	GS 35.125 (32.416)	mem 76.230
Train: [28][1280/1500]	BT 0.031 (0.299)	DT 0.000 (0.261)	loss 6.736 (6.951)	prob 3.089 (2.844)	GS 33.547 (32.509)	mem 76.231
Train: [28][1290/1500]	BT 0.039 (0.303)	DT 0.001 (0.264)	loss 6.836 (6.952)	prob 2.608 (2.853)	GS 34.297 (32.773)	mem 76.229
Train: [28][1300/1500]	BT 0.039 (0.301)	DT 0.001 (0.262)	loss 6.747 (6.953)	prob 3.149 (2.875)	GS 33.250 (32.820)	mem 76.229
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [28][1310/1500]	BT 0.046 (0.304)	DT 0.000 (0.265)	loss 6.833 (6.992)	prob 3.166 (2.938)	GS 37.359 (33.075)	mem 76.226
Train: [28][1320/1500]	BT 0.106 (0.302)	DT 0.024 (0.263)	loss 6.971 (6.964)	prob 2.679 (2.883)	GS 31.203 (32.396)	mem 76.226
Train: [28][1330/1500]	BT 0.039 (0.300)	DT 0.001 (0.261)	loss 6.842 (6.926)	prob 2.737 (2.886)	GS 28.719 (32.329)	mem 76.227
Train: [28][1340/1500]	BT 0.029 (0.302)	DT 0.000 (0.263)	loss 6.876 (6.905)	prob 2.737 (2.841)	GS 34.703 (32.620)	mem 76.228
Train: [28][1350/1500]	BT 0.039 (0.300)	DT 0.001 (0.261)	loss 6.836 (6.906)	prob 2.400 (2.851)	GS 33.656 (32.856)	mem 76.228
Train: [28][1360/1500]	BT 0.037 (0.301)	DT 0.001 (0.263)	loss 6.899 (6.878)	prob 3.104 (2.919)	GS 34.703 (33.053)	mem 76.228
Train: [28][1370/1500]	BT 0.037 (0.300)	DT 0.001 (0.261)	loss 6.771 (6.895)	prob 3.224 (3.070)	GS 32.750 (33.209)	mem 76.229
Train: [28][1380/1500]	BT 0.039 (0.299)	DT 0.001 (0.260)	loss 6.912 (6.904)	prob 2.709 (3.030)	GS 37.766 (33.149)	mem 76.229
Train: [28][1390/1500]	BT 0.036 (0.299)	DT 0.001 (0.261)	loss 6.764 (6.892)	prob 3.097 (2.969)	GS 29.656 (32.907)	mem 76.229
Train: [28][1400/1500]	BT 0.035 (0.298)	DT 0.001 (0.259)	loss 6.601 (6.870)	prob 3.206 (2.976)	GS 34.672 (33.014)	mem 76.229
Train: [28][1410/1500]	BT 0.039 (0.300)	DT 0.001 (0.261)	loss 6.989 (6.924)	prob 2.488 (2.671)	GS 30.500 (32.364)	mem 76.230
Train: [28][1420/1500]	BT 0.061 (0.299)	DT 0.003 (0.260)	loss 6.703 (6.908)	prob 3.606 (2.846)	GS 33.219 (33.664)	mem 76.231
Train: [28][1430/1500]	BT 0.054 (0.301)	DT 0.006 (0.262)	loss 6.909 (6.882)	prob 3.165 (2.874)	GS 33.812 (33.334)	mem 76.229
Train: [28][1440/1500]	BT 0.027 (0.306)	DT 0.000 (0.267)	loss 6.719 (6.858)	prob 3.710 (2.915)	GS 33.328 (33.018)	mem 76.228
Train: [28][1450/1500]	BT 0.033 (0.304)	DT 0.000 (0.265)	loss 6.650 (6.848)	prob 2.639 (2.885)	GS 35.672 (32.659)	mem 76.229
Train: [28][1460/1500]	BT 0.028 (0.304)	DT 0.000 (0.265)	loss 6.826 (6.839)	prob 3.158 (2.972)	GS 36.047 (32.728)	mem 75.334
Train: [28][1470/1500]	BT 0.028 (0.302)	DT 0.000 (0.263)	loss 6.934 (6.816)	prob 2.573 (3.146)	GS 32.781 (32.305)	mem 75.333
Train: [28][1480/1500]	BT 0.028 (0.300)	DT 0.000 (0.262)	loss 6.744 (6.792)	prob 3.142 (3.171)	GS 32.234 (32.210)	mem 75.333
Train: [28][1490/1500]	BT 0.026 (0.300)	DT 0.000 (0.261)	loss 6.810 (6.789)	prob 3.130 (3.132)	GS 35.750 (32.360)	mem 11.242
Train: [28][1500/1500]	BT 0.026 (0.298)	DT 0.000 (0.260)	loss 6.655 (6.793)	prob 2.098 (3.064)	GS 35.031 (32.351)	mem 11.242
Train: [28][1510/1500]	BT 0.025 (0.297)	DT 0.000 (0.258)	loss 6.806 (6.611)	prob 3.292 (3.096)	GS 36.312 (34.869)	mem 11.045
epoch 28, total time 448.23
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [29][1/1500]	BT 17.609 (17.609)	DT 17.551 (17.551)	loss 6.553 (6.553)	prob 2.440 (2.440)	GS 30.109 (30.109)	mem 74.537
Train: [29][10/1500]	BT 0.078 (2.385)	DT 0.011 (2.338)	loss 6.488 (6.609)	prob 3.410 (3.123)	GS 39.922 (33.788)	mem 74.896
Train: [29][20/1500]	BT 0.048 (1.244)	DT 0.002 (1.192)	loss 6.559 (6.604)	prob 3.127 (3.053)	GS 34.594 (33.886)	mem 74.903
Train: [29][30/1500]	BT 0.034 (1.009)	DT 0.001 (0.964)	loss 6.832 (6.670)	prob 2.983 (2.818)	GS 34.219 (33.649)	mem 74.944
Train: [29][40/1500]	BT 0.038 (0.765)	DT 0.000 (0.723)	loss 6.928 (6.718)	prob 2.844 (2.875)	GS 31.578 (33.252)	mem 74.954
Train: [29][50/1500]	BT 0.038 (0.675)	DT 0.001 (0.634)	loss 6.782 (6.742)	prob 2.454 (2.837)	GS 30.953 (32.718)	mem 74.972
Train: [29][60/1500]	BT 0.036 (0.642)	DT 0.001 (0.602)	loss 6.926 (6.913)	prob 2.749 (2.817)	GS 32.891 (34.172)	mem 75.000
Train: [29][70/1500]	BT 0.030 (0.554)	DT 0.000 (0.516)	loss 6.952 (6.873)	prob 3.073 (2.931)	GS 34.844 (33.083)	mem 75.000
Train: [29][80/1500]	BT 0.039 (0.499)	DT 0.001 (0.460)	loss 6.774 (6.877)	prob 2.471 (2.842)	GS 35.172 (32.630)	mem 75.002
Train: [29][90/1500]	BT 0.055 (0.481)	DT 0.001 (0.442)	loss 6.946 (6.877)	prob 2.777 (2.815)	GS 36.094 (32.899)	mem 75.013
Train: [29][100/1500]	BT 1.523 (0.478)	DT 1.443 (0.436)	loss 6.986 (6.885)	prob 2.784 (2.814)	GS 34.953 (32.816)	mem 75.016
Train: [29][110/1500]	BT 0.060 (0.509)	DT 0.004 (0.466)	loss 6.844 (6.854)	prob 2.914 (2.710)	GS 35.828 (31.169)	mem 75.019
Train: [29][120/1500]	BT 0.030 (0.573)	DT 0.001 (0.529)	loss 6.829 (6.858)	prob 2.591 (2.738)	GS 32.062 (31.344)	mem 75.029
Train: [29][130/1500]	BT 0.030 (0.532)	DT 0.000 (0.488)	loss 6.954 (6.873)	prob 2.894 (2.813)	GS 39.750 (32.074)	mem 75.029
Train: [29][140/1500]	BT 0.037 (0.496)	DT 0.001 (0.453)	loss 6.770 (6.863)	prob 2.589 (2.844)	GS 34.938 (32.243)	mem 75.030
Train: [29][150/1500]	BT 0.029 (0.492)	DT 0.000 (0.450)	loss 6.816 (6.859)	prob 3.257 (2.887)	GS 35.281 (32.297)	mem 75.038
Train: [29][160/1500]	BT 0.029 (0.463)	DT 0.000 (0.422)	loss 6.895 (6.884)	prob 2.972 (3.142)	GS 34.109 (33.089)	mem 75.040
Train: [29][170/1500]	BT 0.038 (0.455)	DT 0.001 (0.414)	loss 6.825 (6.877)	prob 3.279 (3.204)	GS 34.234 (32.885)	mem 75.055
Train: [29][180/1500]	BT 0.037 (0.432)	DT 0.001 (0.391)	loss 6.962 (6.898)	prob 3.498 (3.222)	GS 30.469 (32.952)	mem 75.055
Train: [29][190/1500]	BT 0.037 (0.411)	DT 0.000 (0.371)	loss 6.902 (6.907)	prob 3.476 (3.137)	GS 37.328 (32.993)	mem 75.056
Train: [29][200/1500]	BT 0.038 (0.406)	DT 0.001 (0.366)	loss 6.815 (6.901)	prob 3.297 (3.138)	GS 27.531 (33.094)	mem 75.059
Train: [29][210/1500]	BT 0.037 (0.389)	DT 0.000 (0.349)	loss 6.835 (6.849)	prob 2.598 (3.132)	GS 34.703 (33.413)	mem 75.059
Train: [29][220/1500]	BT 0.042 (0.393)	DT 0.009 (0.353)	loss 6.942 (6.864)	prob 2.747 (3.132)	GS 35.891 (33.719)	mem 75.064
Train: [29][230/1500]	BT 0.508 (0.379)	DT 0.465 (0.340)	loss 7.148 (6.872)	prob 2.364 (3.118)	GS 34.125 (33.040)	mem 75.064
Train: [29][240/1500]	BT 0.036 (0.411)	DT 0.000 (0.371)	loss 7.154 (6.881)	prob 3.108 (3.092)	GS 34.156 (33.339)	mem 75.072
Train: [29][250/1500]	BT 0.037 (0.396)	DT 0.000 (0.356)	loss 7.338 (6.903)	prob 3.073 (3.129)	GS 33.328 (33.506)	mem 75.072
Train: [29][260/1500]	BT 0.037 (0.384)	DT 0.001 (0.345)	loss 7.132 (6.906)	prob 3.164 (3.332)	GS 36.406 (33.919)	mem 75.071
Train: [29][270/1500]	BT 0.106 (0.388)	DT 0.012 (0.348)	loss 6.868 (6.915)	prob 3.144 (3.252)	GS 30.062 (32.730)	mem 75.077
Train: [29][280/1500]	BT 0.036 (0.375)	DT 0.000 (0.336)	loss 6.693 (6.899)	prob 2.892 (3.246)	GS 30.266 (32.311)	mem 75.080
Train: [29][290/1500]	BT 0.028 (0.392)	DT 0.000 (0.352)	loss 6.891 (6.895)	prob 2.473 (3.181)	GS 31.688 (32.638)	mem 75.089
Train: [29][300/1500]	BT 0.031 (0.380)	DT 0.000 (0.341)	loss 6.897 (6.897)	prob 3.168 (3.137)	GS 30.516 (32.353)	mem 75.090
Train: [29][310/1500]	BT 0.036 (0.370)	DT 0.001 (0.331)	loss 6.796 (6.819)	prob 2.927 (2.942)	GS 35.391 (32.742)	mem 75.090
Train: [29][320/1500]	BT 0.037 (0.367)	DT 0.000 (0.328)	loss 6.880 (6.845)	prob 3.098 (3.075)	GS 33.156 (32.610)	mem 75.093
Train: [29][330/1500]	BT 0.037 (0.357)	DT 0.000 (0.318)	loss 6.862 (6.851)	prob 2.681 (3.030)	GS 34.531 (32.204)	mem 75.093
Train: [29][340/1500]	BT 0.044 (0.358)	DT 0.000 (0.318)	loss 6.894 (6.859)	prob 4.284 (3.092)	GS 36.516 (32.850)	mem 75.097
Train: [29][350/1500]	BT 0.071 (0.349)	DT 0.003 (0.309)	loss 6.777 (6.869)	prob 2.639 (3.143)	GS 33.531 (32.931)	mem 75.096
Train: [29][360/1500]	BT 0.035 (0.357)	DT 0.000 (0.317)	loss 6.965 (6.878)	prob 2.442 (3.028)	GS 34.453 (32.489)	mem 75.096
Train: [29][370/1500]	BT 0.036 (0.348)	DT 0.000 (0.309)	loss 6.890 (6.869)	prob 3.118 (2.836)	GS 32.188 (32.344)	mem 75.099
Train: [29][380/1500]	BT 0.038 (0.340)	DT 0.001 (0.301)	loss 7.005 (6.866)	prob 3.059 (2.805)	GS 36.844 (32.290)	mem 75.100
Train: [29][390/1500]	BT 0.025 (0.344)	DT 0.000 (0.305)	loss 6.912 (6.869)	prob 2.465 (2.802)	GS 34.828 (32.461)	mem 75.100
Train: [29][400/1500]	BT 0.038 (0.336)	DT 0.001 (0.297)	loss 6.991 (6.871)	prob 2.285 (2.695)	GS 34.125 (32.647)	mem 75.103
Train: [29][410/1500]	BT 0.026 (0.339)	DT 0.000 (0.301)	loss 6.749 (6.798)	prob 2.557 (2.475)	GS 36.406 (34.591)	mem 75.103
Train: [29][420/1500]	BT 0.028 (0.332)	DT 0.000 (0.293)	loss 6.836 (6.793)	prob 2.721 (2.454)	GS 30.547 (33.151)	mem 75.103
Train: [29][430/1500]	BT 0.037 (0.335)	DT 0.000 (0.297)	loss 6.888 (6.789)	prob 1.236 (2.372)	GS 39.047 (33.324)	mem 75.107
Train: [29][440/1500]	BT 0.029 (0.328)	DT 0.000 (0.290)	loss 6.931 (6.787)	prob 2.140 (2.420)	GS 35.797 (33.383)	mem 75.107
Train: [29][450/1500]	BT 0.038 (0.322)	DT 0.000 (0.284)	loss 6.801 (6.777)	prob 2.719 (2.504)	GS 33.797 (33.633)	mem 75.106
Train: [29][460/1500]	BT 0.024 (0.336)	DT 0.000 (0.298)	loss 6.641 (6.774)	prob 3.170 (2.390)	GS 34.797 (33.714)	mem 75.252
Train: [29][470/1500]	BT 0.028 (0.330)	DT 0.000 (0.292)	loss 6.804 (6.783)	prob 3.102 (2.498)	GS 33.734 (33.035)	mem 75.254
Train: [29][480/1500]	BT 0.046 (0.336)	DT 0.006 (0.297)	loss 6.834 (6.778)	prob 2.518 (2.485)	GS 33.156 (33.096)	mem 75.939
Train: [29][490/1500]	BT 0.048 (0.330)	DT 0.001 (0.291)	loss 6.845 (6.786)	prob 1.655 (2.508)	GS 35.234 (32.764)	mem 75.938
Train: [29][500/1500]	BT 0.060 (0.324)	DT 0.011 (0.286)	loss 6.621 (6.759)	prob 1.977 (2.518)	GS 33.391 (32.674)	mem 76.078
Train: [29][510/1500]	BT 0.051 (0.337)	DT 0.006 (0.299)	loss 6.867 (6.784)	prob 2.000 (2.096)	GS 38.469 (33.447)	mem 76.234
Train: [29][520/1500]	BT 0.028 (0.349)	DT 0.000 (0.310)	loss 7.168 (6.813)	prob 1.436 (2.194)	GS 32.391 (32.804)	mem 76.282
Train: [29][530/1500]	BT 0.035 (0.343)	DT 0.001 (0.304)	loss 6.780 (6.807)	prob 2.852 (2.267)	GS 33.875 (32.986)	mem 76.284
Train: [29][540/1500]	BT 0.030 (0.347)	DT 0.000 (0.309)	loss 6.757 (6.791)	prob 2.631 (2.318)	GS 32.656 (32.987)	mem 76.284
Train: [29][550/1500]	BT 0.023 (0.341)	DT 0.000 (0.303)	loss 6.664 (6.796)	prob 3.016 (2.314)	GS 33.656 (33.117)	mem 76.285
Train: [29][560/1500]	BT 5.898 (0.346)	DT 5.839 (0.308)	loss 7.107 (6.808)	prob 2.037 (2.231)	GS 38.859 (33.067)	mem 76.315
Train: [29][570/1500]	BT 0.031 (0.341)	DT 0.000 (0.303)	loss 6.742 (6.824)	prob 2.865 (2.300)	GS 35.047 (33.229)	mem 76.317
Train: [29][580/1500]	BT 0.027 (0.335)	DT 0.000 (0.298)	loss 7.017 (6.819)	prob 2.574 (2.280)	GS 30.984 (33.065)	mem 76.316
Train: [29][590/1500]	BT 0.039 (0.335)	DT 0.001 (0.298)	loss 6.741 (6.824)	prob 3.030 (2.297)	GS 34.062 (33.149)	mem 76.318
Train: [29][600/1500]	BT 0.038 (0.330)	DT 0.000 (0.293)	loss 7.133 (6.853)	prob 2.728 (2.271)	GS 33.469 (32.789)	mem 76.317
Train: [29][610/1500]	BT 0.034 (0.331)	DT 0.000 (0.294)	loss 7.241 (6.888)	prob 0.985 (2.439)	GS 33.156 (31.462)	mem 76.318
Train: [29][620/1500]	BT 0.039 (0.326)	DT 0.001 (0.289)	loss 6.661 (6.870)	prob 1.667 (2.400)	GS 35.125 (31.799)	mem 76.318
Train: [29][630/1500]	BT 0.037 (0.322)	DT 0.001 (0.285)	loss 6.679 (6.846)	prob 2.520 (2.372)	GS 31.344 (31.543)	mem 76.318
Train: [29][640/1500]	BT 0.061 (0.326)	DT 0.016 (0.288)	loss 6.769 (6.845)	prob 3.008 (2.383)	GS 37.109 (32.004)	mem 76.318
Train: [29][650/1500]	BT 0.033 (0.331)	DT 0.000 (0.293)	loss 6.788 (6.831)	prob 2.435 (2.451)	GS 35.734 (32.355)	mem 76.322
Train: [29][660/1500]	BT 0.027 (0.336)	DT 0.000 (0.299)	loss 6.683 (6.771)	prob 2.613 (2.475)	GS 31.000 (32.786)	mem 76.327
Train: [29][670/1500]	BT 0.035 (0.332)	DT 0.001 (0.294)	loss 6.749 (6.762)	prob 2.108 (2.243)	GS 31.766 (32.827)	mem 76.327
Train: [29][680/1500]	BT 2.689 (0.331)	DT 2.639 (0.294)	loss 6.814 (6.739)	prob 2.482 (2.368)	GS 34.203 (32.508)	mem 76.328
Train: [29][690/1500]	BT 0.071 (0.339)	DT 0.014 (0.301)	loss 6.692 (6.738)	prob 3.060 (2.385)	GS 38.359 (32.903)	mem 76.328
Train: [29][700/1500]	BT 0.054 (0.335)	DT 0.006 (0.297)	loss 6.941 (6.753)	prob 2.083 (2.411)	GS 32.156 (32.641)	mem 76.328
Train: [29][710/1500]	BT 0.060 (0.345)	DT 0.005 (0.307)	loss 7.154 (6.828)	prob 2.467 (2.202)	GS 32.594 (30.416)	mem 76.327
Train: [29][720/1500]	BT 0.081 (0.341)	DT 0.006 (0.303)	loss 6.607 (6.844)	prob 3.726 (2.567)	GS 33.234 (31.331)	mem 76.327
Train: [29][730/1500]	BT 0.035 (0.355)	DT 0.000 (0.317)	loss 7.155 (6.877)	prob 2.428 (2.620)	GS 34.141 (31.436)	mem 76.327
Train: [29][740/1500]	BT 0.031 (0.351)	DT 0.001 (0.312)	loss 7.115 (6.862)	prob 3.203 (2.781)	GS 35.547 (32.232)	mem 76.329
Train: [29][750/1500]	BT 0.038 (0.347)	DT 0.001 (0.308)	loss 6.791 (6.868)	prob 3.249 (2.836)	GS 32.078 (32.212)	mem 76.330
Train: [29][760/1500]	BT 0.028 (0.349)	DT 0.000 (0.311)	loss 6.834 (6.863)	prob 2.471 (2.957)	GS 31.984 (34.344)	mem 76.332
Train: [29][770/1500]	BT 0.039 (0.345)	DT 0.000 (0.307)	loss 7.112 (6.935)	prob 2.862 (2.959)	GS 31.531 (33.294)	mem 76.333
Train: [29][780/1500]	BT 0.028 (0.347)	DT 0.000 (0.308)	loss 6.983 (6.944)	prob 3.353 (2.998)	GS 36.531 (33.026)	mem 76.334
Train: [29][790/1500]	BT 0.038 (0.343)	DT 0.001 (0.304)	loss 7.277 (6.966)	prob 4.089 (3.098)	GS 31.094 (32.755)	mem 76.334
Train: [29][800/1500]	BT 0.029 (0.344)	DT 0.000 (0.306)	loss 6.755 (6.976)	prob 3.248 (3.152)	GS 29.641 (32.670)	mem 76.335
Train: [29][810/1500]	BT 0.036 (0.340)	DT 0.001 (0.302)	loss 6.868 (7.073)	prob 2.938 (3.083)	GS 32.672 (31.808)	mem 76.335
Train: [29][820/1500]	BT 0.036 (0.337)	DT 0.001 (0.298)	loss 7.177 (7.047)	prob 2.928 (3.001)	GS 35.625 (32.684)	mem 76.336
Train: [29][830/1500]	BT 0.024 (0.338)	DT 0.000 (0.300)	loss 7.217 (7.054)	prob 2.666 (2.974)	GS 33.031 (32.331)	mem 76.343
Train: [29][840/1500]	BT 0.036 (0.334)	DT 0.000 (0.296)	loss 7.041 (7.065)	prob 3.075 (3.095)	GS 35.328 (32.893)	mem 76.342
Train: [29][850/1500]	BT 0.064 (0.335)	DT 0.003 (0.297)	loss 7.132 (7.077)	prob 3.503 (3.127)	GS 31.422 (32.636)	mem 76.354
Train: [29][860/1500]	BT 0.025 (0.335)	DT 0.000 (0.297)	loss 7.421 (7.217)	prob 2.880 (3.544)	GS 35.391 (34.592)	mem 76.353
Train: [29][870/1500]	BT 0.038 (0.332)	DT 0.001 (0.294)	loss 7.279 (7.154)	prob 3.606 (3.585)	GS 31.656 (33.925)	mem 76.352
Train: [29][880/1500]	BT 0.053 (0.337)	DT 0.003 (0.299)	loss 6.958 (7.160)	prob 3.540 (3.506)	GS 34.297 (33.255)	mem 76.353
Train: [29][890/1500]	BT 0.073 (0.334)	DT 0.009 (0.295)	loss 7.107 (7.137)	prob 2.629 (3.479)	GS 35.484 (33.179)	mem 76.353
Train: [29][900/1500]	BT 0.037 (0.331)	DT 0.001 (0.293)	loss 7.145 (7.123)	prob 2.859 (3.399)	GS 32.812 (32.881)	mem 76.355
Train: [29][910/1500]	BT 0.028 (0.334)	DT 0.000 (0.296)	loss 7.219 (7.177)	prob 2.911 (2.720)	GS 31.547 (33.486)	mem 76.254
Train: [29][920/1500]	BT 0.023 (0.331)	DT 0.000 (0.293)	loss 7.358 (7.123)	prob 2.745 (2.910)	GS 36.203 (33.076)	mem 76.254
Train: [29][930/1500]	BT 0.036 (0.331)	DT 0.001 (0.294)	loss 6.984 (7.146)	prob 3.406 (3.010)	GS 28.391 (33.070)	mem 76.258
Train: [29][940/1500]	BT 0.037 (0.328)	DT 0.000 (0.290)	loss 7.005 (7.141)	prob 3.325 (3.073)	GS 36.625 (32.973)	mem 76.257
Train: [29][950/1500]	BT 0.038 (0.327)	DT 0.001 (0.289)	loss 7.119 (7.135)	prob 3.856 (3.081)	GS 33.625 (32.617)	mem 76.257
Train: [29][960/1500]	BT 0.037 (0.325)	DT 0.001 (0.287)	loss 7.188 (7.091)	prob 3.628 (3.423)	GS 35.359 (32.212)	mem 76.257
Train: [29][970/1500]	BT 0.037 (0.322)	DT 0.000 (0.284)	loss 7.049 (7.079)	prob 3.666 (3.310)	GS 37.906 (32.459)	mem 76.257
Train: [29][980/1500]	BT 0.036 (0.323)	DT 0.001 (0.285)	loss 7.427 (7.085)	prob 2.967 (3.267)	GS 29.609 (32.701)	mem 76.257
Train: [29][990/1500]	BT 0.038 (0.320)	DT 0.001 (0.283)	loss 7.045 (7.085)	prob 3.823 (3.246)	GS 36.062 (33.245)	mem 76.258
Train: [29][1000/1500]	BT 0.052 (0.323)	DT 0.009 (0.285)	loss 7.138 (7.087)	prob 3.129 (3.267)	GS 33.531 (32.919)	mem 76.278
Train: [29][1010/1500]	BT 0.071 (0.320)	DT 0.000 (0.283)	loss 6.996 (7.129)	prob 2.390 (2.943)	GS 29.312 (32.788)	mem 76.278
Train: [29][1020/1500]	BT 0.090 (0.319)	DT 0.009 (0.281)	loss 7.098 (7.113)	prob 3.119 (3.092)	GS 36.234 (32.643)	mem 76.278
Train: [29][1030/1500]	BT 0.033 (0.325)	DT 0.000 (0.287)	loss 7.056 (7.118)	prob 3.158 (3.085)	GS 33.219 (32.368)	mem 76.262
Train: [29][1040/1500]	BT 0.032 (0.336)	DT 0.001 (0.298)	loss 6.941 (7.120)	prob 3.136 (3.061)	GS 31.266 (32.597)	mem 76.261
Train: [29][1050/1500]	BT 0.031 (0.333)	DT 0.000 (0.295)	loss 7.379 (7.122)	prob 3.362 (3.052)	GS 30.250 (32.687)	mem 76.262
Train: [29][1060/1500]	BT 0.027 (0.330)	DT 0.000 (0.292)	loss 6.889 (7.128)	prob 3.168 (2.948)	GS 31.438 (32.358)	mem 76.263
Train: [29][1070/1500]	BT 0.039 (0.331)	DT 0.001 (0.293)	loss 7.138 (7.093)	prob 2.624 (2.905)	GS 34.453 (33.428)	mem 76.263
Train: [29][1080/1500]	BT 0.039 (0.328)	DT 0.001 (0.290)	loss 7.031 (7.098)	prob 3.312 (2.890)	GS 33.609 (33.058)	mem 76.263
Train: [29][1090/1500]	BT 0.033 (0.329)	DT 0.001 (0.291)	loss 6.986 (7.072)	prob 2.874 (2.894)	GS 33.562 (32.860)	mem 76.263
Train: [29][1100/1500]	BT 0.040 (0.327)	DT 0.001 (0.289)	loss 7.018 (7.072)	prob 2.602 (2.887)	GS 35.312 (32.578)	mem 76.265
Train: [29][1110/1500]	BT 0.048 (0.324)	DT 0.001 (0.286)	loss 7.009 (7.145)	prob 3.490 (2.768)	GS 29.391 (31.970)	mem 76.264
Train: [29][1120/1500]	BT 0.078 (0.326)	DT 0.005 (0.287)	loss 7.466 (7.112)	prob 2.541 (2.705)	GS 30.938 (32.315)	mem 76.265
Train: [29][1130/1500]	BT 0.033 (0.327)	DT 0.000 (0.289)	loss 6.840 (7.074)	prob 2.870 (2.837)	GS 30.562 (32.308)	mem 76.264
Train: [29][1140/1500]	BT 0.064 (0.326)	DT 0.016 (0.288)	loss 7.105 (7.062)	prob 3.429 (2.825)	GS 36.234 (32.663)	mem 76.264
Train: [29][1150/1500]	BT 0.037 (0.330)	DT 0.001 (0.291)	loss 7.340 (7.054)	prob 2.363 (2.825)	GS 33.609 (32.714)	mem 76.265
Train: [29][1160/1500]	BT 0.039 (0.327)	DT 0.001 (0.289)	loss 6.941 (7.082)	prob 2.692 (3.014)	GS 34.484 (32.875)	mem 76.266
Train: [29][1170/1500]	BT 0.039 (0.326)	DT 0.001 (0.288)	loss 6.962 (7.037)	prob 3.225 (2.863)	GS 36.109 (32.403)	mem 76.267
Train: [29][1180/1500]	BT 0.039 (0.325)	DT 0.001 (0.286)	loss 6.996 (7.065)	prob 3.406 (2.807)	GS 37.062 (32.515)	mem 76.267
Train: [29][1190/1500]	BT 0.039 (0.322)	DT 0.001 (0.284)	loss 6.916 (7.049)	prob 2.916 (2.827)	GS 33.594 (32.583)	mem 76.267
Train: [29][1200/1500]	BT 0.036 (0.324)	DT 0.000 (0.286)	loss 6.931 (7.045)	prob 3.179 (2.819)	GS 36.625 (32.784)	mem 76.284
Train: [29][1210/1500]	BT 0.038 (0.322)	DT 0.000 (0.283)	loss 6.934 (6.978)	prob 2.704 (2.915)	GS 32.438 (32.625)	mem 76.285
Train: [29][1220/1500]	BT 0.037 (0.320)	DT 0.000 (0.282)	loss 6.973 (6.991)	prob 2.793 (2.919)	GS 33.266 (32.902)	mem 76.286
Train: [29][1230/1500]	BT 0.037 (0.319)	DT 0.001 (0.281)	loss 6.760 (6.981)	prob 3.060 (2.835)	GS 33.062 (32.982)	mem 76.288
Train: [29][1240/1500]	BT 0.038 (0.317)	DT 0.001 (0.279)	loss 6.841 (6.970)	prob 2.911 (2.850)	GS 33.609 (32.604)	mem 76.287
Train: [29][1250/1500]	BT 0.038 (0.318)	DT 0.001 (0.279)	loss 6.970 (6.978)	prob 2.596 (2.814)	GS 30.625 (32.734)	mem 76.289
Train: [29][1260/1500]	BT 0.037 (0.315)	DT 0.001 (0.277)	loss 7.023 (7.113)	prob 2.221 (2.535)	GS 32.250 (34.836)	mem 76.290
Train: [29][1270/1500]	BT 0.024 (0.319)	DT 0.000 (0.281)	loss 7.065 (7.031)	prob 2.473 (2.529)	GS 33.688 (33.998)	mem 76.293
Train: [29][1280/1500]	BT 0.026 (0.317)	DT 0.000 (0.279)	loss 7.350 (7.007)	prob 2.249 (2.607)	GS 31.719 (33.392)	mem 76.293
Train: [29][1290/1500]	BT 0.037 (0.318)	DT 0.000 (0.280)	loss 6.997 (6.988)	prob 2.877 (2.636)	GS 37.859 (33.389)	mem 76.295
Train: [29][1300/1500]	BT 0.037 (0.316)	DT 0.001 (0.278)	loss 7.105 (7.001)	prob 2.830 (2.648)	GS 34.312 (33.465)	mem 76.295
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [29][1310/1500]	BT 0.037 (0.314)	DT 0.001 (0.276)	loss 6.847 (6.967)	prob 2.191 (2.461)	GS 34.562 (33.119)	mem 76.295
Train: [29][1320/1500]	BT 0.037 (0.315)	DT 0.001 (0.277)	loss 6.918 (6.976)	prob 2.823 (2.551)	GS 34.734 (32.752)	mem 76.296
Train: [29][1330/1500]	BT 0.027 (0.313)	DT 0.000 (0.275)	loss 6.944 (6.981)	prob 2.607 (2.556)	GS 32.828 (32.384)	mem 76.297
Train: [29][1340/1500]	BT 0.030 (0.314)	DT 0.000 (0.276)	loss 6.973 (6.974)	prob 2.096 (2.539)	GS 31.422 (32.004)	mem 76.300
Train: [29][1350/1500]	BT 0.032 (0.312)	DT 0.000 (0.274)	loss 7.029 (6.962)	prob 3.338 (2.620)	GS 37.906 (32.382)	mem 76.300
Train: [29][1360/1500]	BT 0.038 (0.310)	DT 0.001 (0.272)	loss 6.503 (6.890)	prob 3.994 (2.949)	GS 30.609 (33.234)	mem 76.300
Train: [29][1370/1500]	BT 0.027 (0.313)	DT 0.000 (0.275)	loss 6.765 (6.922)	prob 3.355 (2.856)	GS 35.281 (33.459)	mem 76.302
Train: [29][1380/1500]	BT 0.036 (0.314)	DT 0.001 (0.276)	loss 6.891 (6.916)	prob 2.630 (2.790)	GS 35.359 (33.529)	mem 76.302
Train: [29][1390/1500]	BT 0.038 (0.312)	DT 0.001 (0.274)	loss 6.777 (6.918)	prob 3.184 (2.737)	GS 35.297 (33.132)	mem 76.304
Train: [29][1400/1500]	BT 0.037 (0.310)	DT 0.001 (0.272)	loss 6.748 (6.924)	prob 3.269 (2.749)	GS 32.297 (32.897)	mem 76.303
Train: [29][1410/1500]	BT 0.036 (0.311)	DT 0.000 (0.273)	loss 6.713 (6.831)	prob 2.590 (2.942)	GS 36.484 (33.045)	mem 76.304
Train: [29][1420/1500]	BT 0.037 (0.309)	DT 0.001 (0.271)	loss 6.730 (6.898)	prob 3.090 (2.795)	GS 36.188 (32.872)	mem 76.305
Train: [29][1430/1500]	BT 0.038 (0.312)	DT 0.001 (0.274)	loss 6.754 (6.894)	prob 2.399 (2.725)	GS 33.531 (32.352)	mem 76.305
Train: [29][1440/1500]	BT 0.037 (0.310)	DT 0.001 (0.272)	loss 7.004 (6.900)	prob 2.826 (2.689)	GS 34.969 (32.559)	mem 76.305
Train: [29][1450/1500]	BT 0.037 (0.309)	DT 0.001 (0.271)	loss 6.639 (6.887)	prob 2.443 (2.674)	GS 32.953 (32.633)	mem 76.305
Train: [29][1460/1500]	BT 0.024 (0.309)	DT 0.000 (0.272)	loss 7.061 (6.941)	prob 1.869 (2.194)	GS 33.031 (31.556)	mem 75.832
Train: [29][1470/1500]	BT 0.030 (0.307)	DT 0.000 (0.270)	loss 6.751 (6.896)	prob 1.867 (2.361)	GS 34.281 (33.052)	mem 75.833
Train: [29][1480/1500]	BT 0.021 (0.307)	DT 0.000 (0.269)	loss 6.795 (6.869)	prob 2.903 (2.430)	GS 33.172 (33.147)	mem 25.241
Train: [29][1490/1500]	BT 0.025 (0.305)	DT 0.000 (0.268)	loss 6.903 (6.848)	prob 1.687 (2.501)	GS 36.219 (33.192)	mem 16.806
Train: [29][1500/1500]	BT 0.031 (0.304)	DT 0.000 (0.266)	loss 7.240 (6.837)	prob 2.820 (2.494)	GS 41.344 (33.148)	mem 16.730
Train: [29][1510/1500]	BT 0.040 (0.302)	DT 0.000 (0.265)	loss 6.258 (6.617)	prob 2.768 (2.615)	GS 30.156 (32.362)	mem 11.104
epoch 29, total time 456.75
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [30][1/1500]	BT 21.837 (21.837)	DT 21.764 (21.764)	loss 6.349 (6.349)	prob 2.024 (2.024)	GS 30.344 (30.344)	mem 74.606
Train: [30][10/1500]	BT 0.067 (2.701)	DT 0.016 (2.642)	loss 6.463 (6.465)	prob 3.250 (2.592)	GS 33.859 (33.464)	mem 74.882
Train: [30][20/1500]	BT 12.674 (2.013)	DT 12.633 (1.958)	loss 6.944 (6.533)	prob 1.873 (2.567)	GS 38.750 (33.743)	mem 74.914
Train: [30][30/1500]	BT 0.030 (1.352)	DT 0.000 (1.306)	loss 6.708 (6.578)	prob 2.888 (2.691)	GS 34.781 (33.663)	mem 74.914
Train: [30][40/1500]	BT 0.025 (1.021)	DT 0.000 (0.979)	loss 6.945 (6.621)	prob 2.578 (2.667)	GS 30.172 (32.973)	mem 74.933
Train: [30][50/1500]	BT 0.023 (0.953)	DT 0.000 (0.915)	loss 6.855 (6.649)	prob 2.382 (2.634)	GS 33.734 (32.613)	mem 74.960
Train: [30][60/1500]	BT 0.038 (0.800)	DT 0.001 (0.763)	loss 6.441 (6.717)	prob 2.262 (2.506)	GS 28.828 (34.722)	mem 74.967
Train: [30][70/1500]	BT 0.043 (0.734)	DT 0.001 (0.697)	loss 6.938 (6.755)	prob 1.866 (2.592)	GS 29.812 (32.977)	mem 74.969
Train: [30][80/1500]	BT 0.064 (0.650)	DT 0.002 (0.611)	loss 6.643 (6.755)	prob 2.471 (2.445)	GS 34.938 (32.684)	mem 74.971
Train: [30][90/1500]	BT 0.063 (0.585)	DT 0.000 (0.543)	loss 6.758 (6.737)	prob 2.447 (2.473)	GS 38.266 (32.645)	mem 74.971
Train: [30][100/1500]	BT 0.038 (0.579)	DT 0.001 (0.537)	loss 6.793 (6.737)	prob 2.460 (2.440)	GS 33.172 (32.686)	mem 74.977
Train: [30][110/1500]	BT 0.038 (0.531)	DT 0.001 (0.490)	loss 6.886 (6.758)	prob 1.451 (2.577)	GS 33.109 (32.802)	mem 74.976
Train: [30][120/1500]	BT 0.029 (0.524)	DT 0.000 (0.484)	loss 6.623 (6.786)	prob 3.154 (2.502)	GS 35.578 (32.612)	mem 74.987
Train: [30][130/1500]	BT 0.038 (0.487)	DT 0.001 (0.447)	loss 6.587 (6.769)	prob 3.065 (2.620)	GS 38.672 (32.934)	mem 74.987
Train: [30][140/1500]	BT 3.567 (0.480)	DT 3.529 (0.440)	loss 6.603 (6.770)	prob 2.984 (2.752)	GS 37.219 (32.739)	mem 74.993
Train: [30][150/1500]	BT 0.038 (0.451)	DT 0.000 (0.411)	loss 6.957 (6.786)	prob 1.982 (2.710)	GS 33.234 (32.759)	mem 74.993
Train: [30][160/1500]	BT 0.039 (0.432)	DT 0.001 (0.392)	loss 6.900 (6.841)	prob 1.800 (2.138)	GS 35.453 (31.419)	mem 74.993
Train: [30][170/1500]	BT 0.039 (0.431)	DT 0.001 (0.391)	loss 6.750 (6.760)	prob 3.025 (2.518)	GS 33.109 (32.333)	mem 75.000
Train: [30][180/1500]	BT 0.035 (0.465)	DT 0.000 (0.425)	loss 6.799 (6.794)	prob 3.246 (2.620)	GS 35.578 (33.013)	mem 75.004
Train: [30][190/1500]	BT 0.098 (0.445)	DT 0.002 (0.403)	loss 7.112 (6.812)	prob 2.637 (2.646)	GS 31.391 (32.923)	mem 75.005
Train: [30][200/1500]	BT 0.077 (0.428)	DT 0.002 (0.383)	loss 7.213 (6.809)	prob 3.054 (2.686)	GS 37.281 (33.032)	mem 75.006
Train: [30][210/1500]	BT 0.029 (0.456)	DT 0.000 (0.412)	loss 7.174 (6.969)	prob 2.599 (2.650)	GS 34.156 (34.450)	mem 75.011
Train: [30][220/1500]	BT 0.039 (0.437)	DT 0.001 (0.393)	loss 6.861 (6.932)	prob 3.396 (2.832)	GS 36.641 (33.399)	mem 75.011
Train: [30][230/1500]	BT 0.070 (0.431)	DT 0.022 (0.388)	loss 6.807 (6.912)	prob 2.181 (2.831)	GS 30.734 (33.322)	mem 75.015
Train: [30][240/1500]	BT 0.039 (0.422)	DT 0.001 (0.379)	loss 6.601 (6.904)	prob 3.449 (2.872)	GS 37.359 (33.513)	mem 75.016
Train: [30][250/1500]	BT 0.029 (0.417)	DT 0.000 (0.374)	loss 6.844 (6.938)	prob 3.816 (2.949)	GS 33.000 (33.315)	mem 75.016
Train: [30][260/1500]	BT 0.075 (0.414)	DT 0.011 (0.371)	loss 6.947 (7.027)	prob 2.043 (3.172)	GS 34.484 (32.100)	mem 75.018
Train: [30][270/1500]	BT 0.031 (0.400)	DT 0.000 (0.357)	loss 6.888 (7.002)	prob 3.973 (3.259)	GS 34.266 (31.643)	mem 75.017
Train: [30][280/1500]	BT 0.029 (0.415)	DT 0.000 (0.372)	loss 6.986 (6.988)	prob 2.682 (3.414)	GS 34.438 (31.920)	mem 75.019
Train: [30][290/1500]	BT 0.038 (0.402)	DT 0.001 (0.359)	loss 7.466 (7.027)	prob 3.350 (3.415)	GS 29.734 (31.664)	mem 75.020
Train: [30][300/1500]	BT 0.064 (0.395)	DT 0.011 (0.352)	loss 6.931 (7.035)	prob 3.149 (3.449)	GS 33.375 (31.671)	mem 75.024
Train: [30][310/1500]	BT 0.037 (0.398)	DT 0.000 (0.355)	loss 7.172 (7.092)	prob 3.478 (3.031)	GS 33.047 (33.139)	mem 75.023
Train: [30][320/1500]	BT 0.038 (0.387)	DT 0.001 (0.344)	loss 6.999 (7.172)	prob 3.951 (3.161)	GS 32.766 (32.211)	mem 75.024
Train: [30][330/1500]	BT 0.026 (0.391)	DT 0.000 (0.349)	loss 7.246 (7.187)	prob 3.735 (3.202)	GS 29.234 (32.211)	mem 75.034
Train: [30][340/1500]	BT 0.034 (0.381)	DT 0.001 (0.339)	loss 7.523 (7.204)	prob 2.710 (3.341)	GS 35.625 (32.323)	mem 75.045
Train: [30][350/1500]	BT 0.037 (0.376)	DT 0.001 (0.334)	loss 7.198 (7.184)	prob 2.531 (3.341)	GS 35.922 (32.529)	mem 75.043
Train: [30][360/1500]	BT 0.040 (0.370)	DT 0.001 (0.328)	loss 7.153 (7.204)	prob 2.882 (3.243)	GS 35.422 (32.581)	mem 75.045
Train: [30][370/1500]	BT 0.037 (0.367)	DT 0.001 (0.325)	loss 7.185 (7.208)	prob 3.950 (3.452)	GS 33.938 (32.485)	mem 74.938
Train: [30][380/1500]	BT 0.036 (0.366)	DT 0.000 (0.324)	loss 7.172 (7.199)	prob 2.762 (3.371)	GS 31.375 (32.455)	mem 74.948
Train: [30][390/1500]	BT 0.037 (0.357)	DT 0.001 (0.316)	loss 7.641 (7.201)	prob 2.434 (3.292)	GS 34.500 (32.480)	mem 74.947
Train: [30][400/1500]	BT 0.039 (0.360)	DT 0.000 (0.319)	loss 7.026 (7.196)	prob 3.686 (3.287)	GS 32.375 (32.617)	mem 74.996
Train: [30][410/1500]	BT 0.036 (0.352)	DT 0.001 (0.311)	loss 6.926 (7.266)	prob 3.909 (3.106)	GS 30.172 (33.606)	mem 74.996
Train: [30][420/1500]	BT 0.037 (0.351)	DT 0.000 (0.310)	loss 7.060 (7.287)	prob 3.265 (3.199)	GS 35.703 (32.803)	mem 74.996
Train: [30][430/1500]	BT 0.036 (0.346)	DT 0.001 (0.305)	loss 7.327 (7.332)	prob 3.686 (3.358)	GS 31.453 (32.942)	mem 75.192
Train: [30][440/1500]	BT 0.038 (0.339)	DT 0.001 (0.298)	loss 7.181 (7.288)	prob 2.614 (3.343)	GS 32.578 (33.242)	mem 75.338
Train: [30][450/1500]	BT 0.028 (0.344)	DT 0.000 (0.303)	loss 7.241 (7.294)	prob 3.156 (3.330)	GS 33.906 (33.529)	mem 76.049
Train: [30][460/1500]	BT 0.036 (0.337)	DT 0.001 (0.296)	loss 7.306 (7.238)	prob 3.662 (3.364)	GS 31.969 (32.556)	mem 76.051
Train: [30][470/1500]	BT 0.039 (0.334)	DT 0.001 (0.293)	loss 7.082 (7.201)	prob 3.641 (3.632)	GS 32.453 (32.188)	mem 76.147
Train: [30][480/1500]	BT 0.031 (0.333)	DT 0.000 (0.292)	loss 7.430 (7.220)	prob 3.749 (3.604)	GS 33.547 (31.965)	mem 76.148
Train: [30][490/1500]	BT 0.046 (0.335)	DT 0.008 (0.294)	loss 7.149 (7.207)	prob 3.664 (3.549)	GS 34.156 (32.336)	mem 76.148
Train: [30][500/1500]	BT 0.038 (0.332)	DT 0.001 (0.292)	loss 7.236 (7.204)	prob 3.331 (3.472)	GS 34.625 (32.392)	mem 76.134
Train: [30][510/1500]	BT 0.037 (0.326)	DT 0.000 (0.286)	loss 7.295 (7.128)	prob 3.362 (3.181)	GS 35.359 (32.217)	mem 76.135
Train: [30][520/1500]	BT 0.043 (0.331)	DT 0.000 (0.291)	loss 7.263 (7.127)	prob 3.167 (3.245)	GS 31.875 (33.109)	mem 76.140
Train: [30][530/1500]	BT 0.034 (0.326)	DT 0.001 (0.286)	loss 7.034 (7.153)	prob 3.327 (3.207)	GS 32.422 (32.531)	mem 76.142
Train: [30][540/1500]	BT 0.039 (0.323)	DT 0.001 (0.283)	loss 6.948 (7.228)	prob 3.809 (3.152)	GS 33.281 (32.492)	mem 76.143
Train: [30][550/1500]	BT 0.025 (0.327)	DT 0.000 (0.287)	loss 7.197 (7.219)	prob 3.900 (3.169)	GS 34.000 (32.479)	mem 76.144
Train: [30][560/1500]	BT 0.039 (0.321)	DT 0.001 (0.282)	loss 7.470 (7.241)	prob 3.579 (3.077)	GS 32.125 (33.153)	mem 76.144
Train: [30][570/1500]	BT 0.032 (0.323)	DT 0.000 (0.283)	loss 7.244 (7.198)	prob 2.907 (2.984)	GS 34.609 (33.754)	mem 76.145
Train: [30][580/1500]	BT 0.066 (0.318)	DT 0.014 (0.279)	loss 7.037 (7.209)	prob 2.754 (2.934)	GS 32.875 (33.792)	mem 76.145
Train: [30][590/1500]	BT 0.049 (0.322)	DT 0.012 (0.282)	loss 7.659 (7.231)	prob 2.696 (2.927)	GS 33.625 (33.271)	mem 76.146
Train: [30][600/1500]	BT 0.039 (0.319)	DT 0.001 (0.279)	loss 7.666 (7.229)	prob 2.046 (2.965)	GS 38.531 (33.371)	mem 76.146
Train: [30][610/1500]	BT 0.048 (0.325)	DT 0.006 (0.285)	loss 7.582 (7.136)	prob 3.093 (3.070)	GS 35.031 (32.334)	mem 76.145
Train: [30][620/1500]	BT 0.031 (0.321)	DT 0.000 (0.281)	loss 7.738 (7.243)	prob 2.494 (2.771)	GS 33.922 (32.702)	mem 76.147
Train: [30][630/1500]	BT 0.029 (0.322)	DT 0.000 (0.282)	loss 8.171 (7.284)	prob 1.952 (2.624)	GS 34.156 (32.987)	mem 76.148
Train: [30][640/1500]	BT 0.039 (0.321)	DT 0.001 (0.281)	loss 7.320 (7.317)	prob 3.004 (2.519)	GS 32.938 (32.996)	mem 76.149
Train: [30][650/1500]	BT 0.026 (0.320)	DT 0.000 (0.281)	loss 7.803 (7.283)	prob 1.921 (2.474)	GS 35.750 (32.603)	mem 76.165
Train: [30][660/1500]	BT 0.031 (0.316)	DT 0.000 (0.276)	loss 7.581 (7.261)	prob 1.860 (1.842)	GS 34.328 (31.684)	mem 76.169
Train: [30][670/1500]	BT 0.037 (0.312)	DT 0.000 (0.272)	loss 8.068 (7.303)	prob 1.963 (1.840)	GS 33.969 (32.179)	mem 76.170
Train: [30][680/1500]	BT 0.057 (0.314)	DT 0.008 (0.274)	loss 7.668 (7.354)	prob 2.043 (1.796)	GS 32.828 (32.229)	mem 76.173
Train: [30][690/1500]	BT 0.061 (0.315)	DT 0.004 (0.274)	loss 7.396 (7.371)	prob 2.086 (1.824)	GS 32.656 (32.325)	mem 76.170
Train: [30][700/1500]	BT 0.056 (0.315)	DT 0.016 (0.274)	loss 7.717 (7.407)	prob 2.464 (1.891)	GS 33.906 (32.329)	mem 76.170
Train: [30][710/1500]	BT 0.037 (0.316)	DT 0.000 (0.275)	loss 7.650 (7.495)	prob 2.334 (2.138)	GS 34.078 (32.033)	mem 76.172
Train: [30][720/1500]	BT 0.036 (0.313)	DT 0.000 (0.273)	loss 7.770 (7.525)	prob 1.630 (2.010)	GS 35.250 (31.813)	mem 76.173
Train: [30][730/1500]	BT 0.027 (0.318)	DT 0.000 (0.278)	loss 8.070 (7.520)	prob 0.867 (1.873)	GS 35.594 (33.211)	mem 76.176
Train: [30][740/1500]	BT 0.025 (0.315)	DT 0.000 (0.275)	loss 7.558 (7.534)	prob 2.314 (1.754)	GS 33.719 (33.075)	mem 76.177
Train: [30][750/1500]	BT 0.039 (0.317)	DT 0.001 (0.278)	loss 7.439 (7.574)	prob 1.653 (1.706)	GS 34.844 (33.055)	mem 76.177
Train: [30][760/1500]	BT 0.037 (0.314)	DT 0.001 (0.274)	loss 7.797 (7.590)	prob 2.217 (1.181)	GS 34.703 (32.445)	mem 76.178
Train: [30][770/1500]	BT 0.038 (0.310)	DT 0.000 (0.270)	loss 7.098 (7.615)	prob 3.366 (1.471)	GS 31.047 (32.109)	mem 76.177
Train: [30][780/1500]	BT 0.029 (0.315)	DT 0.000 (0.275)	loss 7.910 (7.573)	prob 2.229 (1.713)	GS 33.188 (32.231)	mem 76.177
Train: [30][790/1500]	BT 0.026 (0.311)	DT 0.000 (0.272)	loss 7.861 (7.595)	prob 2.560 (1.824)	GS 34.125 (32.303)	mem 76.177
Train: [30][800/1500]	BT 0.037 (0.311)	DT 0.001 (0.272)	loss 7.869 (7.646)	prob 1.992 (1.863)	GS 34.375 (32.447)	mem 76.179
Train: [30][810/1500]	BT 0.038 (0.308)	DT 0.000 (0.269)	loss 7.618 (7.501)	prob 2.392 (2.726)	GS 33.297 (32.002)	mem 76.181
Train: [30][820/1500]	BT 0.038 (0.308)	DT 0.000 (0.269)	loss 8.327 (7.643)	prob 0.985 (2.294)	GS 32.641 (32.498)	mem 76.180
Train: [30][830/1500]	BT 0.038 (0.305)	DT 0.000 (0.265)	loss 7.688 (7.662)	prob 2.171 (2.177)	GS 35.266 (32.514)	mem 76.181
Train: [30][840/1500]	BT 0.037 (0.302)	DT 0.001 (0.263)	loss 7.745 (7.622)	prob 1.686 (2.369)	GS 33.531 (32.281)	mem 76.181
Train: [30][850/1500]	BT 0.037 (0.303)	DT 0.001 (0.264)	loss 7.305 (7.628)	prob 3.040 (2.402)	GS 34.766 (32.301)	mem 76.181
Train: [30][860/1500]	BT 0.037 (0.301)	DT 0.000 (0.262)	loss 8.092 (7.773)	prob 2.096 (2.427)	GS 36.703 (33.489)	mem 76.182
Train: [30][870/1500]	BT 0.046 (0.301)	DT 0.015 (0.262)	loss 7.724 (7.701)	prob 2.493 (2.371)	GS 37.766 (32.965)	mem 76.183
Train: [30][880/1500]	BT 0.054 (0.302)	DT 0.011 (0.263)	loss 8.009 (7.726)	prob 2.341 (2.281)	GS 37.297 (33.376)	mem 76.183
Train: [30][890/1500]	BT 0.075 (0.302)	DT 0.001 (0.262)	loss 7.603 (7.726)	prob 2.896 (2.335)	GS 34.547 (33.654)	mem 76.183
Train: [30][900/1500]	BT 0.035 (0.305)	DT 0.000 (0.266)	loss 8.319 (7.726)	prob 3.019 (2.463)	GS 36.766 (33.611)	mem 76.186
Train: [30][910/1500]	BT 0.037 (0.302)	DT 0.001 (0.263)	loss 8.098 (7.698)	prob 2.876 (2.959)	GS 33.625 (32.955)	mem 76.189
Train: [30][920/1500]	BT 0.036 (0.306)	DT 0.000 (0.267)	loss 7.194 (7.628)	prob 3.261 (2.958)	GS 35.562 (32.705)	mem 76.188
Train: [30][930/1500]	BT 0.028 (0.303)	DT 0.000 (0.264)	loss 7.658 (7.658)	prob 3.459 (2.948)	GS 34.984 (32.650)	mem 76.189
Train: [30][940/1500]	BT 0.038 (0.300)	DT 0.001 (0.261)	loss 7.644 (7.633)	prob 3.326 (2.923)	GS 34.516 (32.710)	mem 76.190
Train: [30][950/1500]	BT 0.038 (0.301)	DT 0.000 (0.262)	loss 7.893 (7.642)	prob 3.262 (2.948)	GS 32.594 (32.528)	mem 76.191
Train: [30][960/1500]	BT 0.037 (0.298)	DT 0.001 (0.259)	loss 7.615 (7.493)	prob 3.541 (3.490)	GS 33.172 (32.066)	mem 76.190
Train: [30][970/1500]	BT 0.038 (0.300)	DT 0.001 (0.261)	loss 8.746 (7.569)	prob 1.814 (3.136)	GS 35.578 (33.580)	mem 76.192
Train: [30][980/1500]	BT 0.029 (0.297)	DT 0.000 (0.259)	loss 7.451 (7.608)	prob 3.024 (2.992)	GS 36.391 (33.285)	mem 76.193
Train: [30][990/1500]	BT 0.039 (0.297)	DT 0.001 (0.258)	loss 7.817 (7.615)	prob 3.363 (3.000)	GS 29.938 (33.164)	mem 76.222
Train: [30][1000/1500]	BT 0.065 (0.298)	DT 0.003 (0.259)	loss 7.503 (7.585)	prob 4.186 (3.053)	GS 32.875 (33.066)	mem 76.225
Train: [30][1010/1500]	BT 0.038 (0.299)	DT 0.001 (0.260)	loss 7.651 (7.544)	prob 3.890 (3.533)	GS 29.469 (33.286)	mem 76.224
Train: [30][1020/1500]	BT 0.037 (0.297)	DT 0.000 (0.258)	loss 7.321 (7.529)	prob 3.975 (3.441)	GS 27.906 (31.848)	mem 76.223
Train: [30][1030/1500]	BT 0.038 (0.297)	DT 0.001 (0.258)	loss 7.396 (7.562)	prob 3.747 (3.361)	GS 30.672 (31.290)	mem 76.223
Train: [30][1040/1500]	BT 0.038 (0.296)	DT 0.001 (0.257)	loss 7.111 (7.547)	prob 2.927 (3.336)	GS 32.984 (31.466)	mem 76.223
Train: [30][1050/1500]	BT 0.038 (0.293)	DT 0.001 (0.254)	loss 7.342 (7.548)	prob 2.248 (3.372)	GS 30.531 (31.497)	mem 76.223
Train: [30][1060/1500]	BT 0.047 (0.292)	DT 0.001 (0.253)	loss 8.098 (7.623)	prob 3.380 (3.129)	GS 36.094 (33.939)	mem 76.224
Train: [30][1070/1500]	BT 0.039 (0.294)	DT 0.001 (0.255)	loss 7.517 (7.618)	prob 3.622 (3.328)	GS 34.328 (32.996)	mem 76.224
Train: [30][1080/1500]	BT 0.039 (0.293)	DT 0.001 (0.254)	loss 7.020 (7.582)	prob 4.622 (3.464)	GS 33.484 (32.919)	mem 76.225
Train: [30][1090/1500]	BT 0.063 (0.292)	DT 0.008 (0.253)	loss 7.382 (7.530)	prob 3.374 (3.521)	GS 28.312 (32.654)	mem 76.226
Train: [30][1100/1500]	BT 0.034 (0.292)	DT 0.000 (0.253)	loss 7.733 (7.539)	prob 3.190 (3.494)	GS 34.344 (32.517)	mem 76.227
Train: [30][1110/1500]	BT 0.059 (0.291)	DT 0.003 (0.252)	loss 7.183 (7.465)	prob 3.953 (3.435)	GS 37.656 (32.319)	mem 76.230
Train: [30][1120/1500]	BT 0.039 (0.294)	DT 0.000 (0.255)	loss 7.142 (7.405)	prob 4.480 (3.530)	GS 37.344 (32.394)	mem 76.228
Train: [30][1130/1500]	BT 0.039 (0.292)	DT 0.001 (0.253)	loss 7.805 (7.387)	prob 2.826 (3.518)	GS 35.594 (32.297)	mem 76.228
Train: [30][1140/1500]	BT 0.038 (0.293)	DT 0.001 (0.254)	loss 7.669 (7.380)	prob 3.235 (3.593)	GS 38.641 (32.309)	mem 76.227
Train: [30][1150/1500]	BT 0.035 (0.291)	DT 0.001 (0.252)	loss 8.040 (7.390)	prob 2.854 (3.547)	GS 35.094 (32.475)	mem 76.228
Train: [30][1160/1500]	BT 0.039 (0.289)	DT 0.001 (0.250)	loss 7.185 (7.377)	prob 4.020 (3.440)	GS 32.094 (31.650)	mem 76.226
Train: [30][1170/1500]	BT 0.051 (0.289)	DT 0.002 (0.250)	loss 7.322 (7.387)	prob 4.114 (3.529)	GS 34.922 (32.859)	mem 76.228
Train: [30][1180/1500]	BT 0.044 (0.288)	DT 0.011 (0.249)	loss 7.423 (7.452)	prob 3.725 (3.507)	GS 31.641 (33.285)	mem 76.228
Train: [30][1190/1500]	BT 1.368 (0.290)	DT 1.330 (0.251)	loss 7.208 (7.484)	prob 3.763 (3.479)	GS 33.141 (33.407)	mem 76.231
Train: [30][1200/1500]	BT 0.026 (0.295)	DT 0.001 (0.256)	loss 7.764 (7.485)	prob 3.354 (3.528)	GS 33.781 (33.645)	mem 76.232
Train: [30][1210/1500]	BT 0.028 (0.293)	DT 0.000 (0.254)	loss 7.223 (7.497)	prob 3.805 (3.766)	GS 34.031 (34.103)	mem 76.231
Train: [30][1220/1500]	BT 0.039 (0.291)	DT 0.001 (0.252)	loss 8.021 (7.531)	prob 3.684 (3.656)	GS 36.547 (33.710)	mem 76.232
Train: [30][1230/1500]	BT 0.032 (0.292)	DT 0.000 (0.254)	loss 7.443 (7.462)	prob 4.198 (3.778)	GS 34.359 (33.108)	mem 76.234
Train: [30][1240/1500]	BT 0.028 (0.290)	DT 0.000 (0.251)	loss 7.391 (7.432)	prob 3.867 (3.749)	GS 38.688 (33.111)	mem 76.235
Train: [30][1250/1500]	BT 0.033 (0.298)	DT 0.001 (0.259)	loss 7.658 (7.418)	prob 3.573 (3.659)	GS 35.109 (33.194)	mem 76.250
Train: [30][1260/1500]	BT 0.030 (0.296)	DT 0.000 (0.257)	loss 7.911 (7.499)	prob 3.839 (3.746)	GS 30.312 (31.744)	mem 76.250
Train: [30][1270/1500]	BT 0.036 (0.294)	DT 0.001 (0.255)	loss 7.258 (7.422)	prob 3.972 (3.855)	GS 31.453 (31.672)	mem 76.251
Train: [30][1280/1500]	BT 0.031 (0.296)	DT 0.000 (0.257)	loss 7.187 (7.402)	prob 3.950 (3.802)	GS 35.078 (31.788)	mem 76.146
Train: [30][1290/1500]	BT 0.035 (0.294)	DT 0.000 (0.255)	loss 7.373 (7.382)	prob 2.895 (3.752)	GS 34.641 (32.412)	mem 76.153
Train: [30][1300/1500]	BT 0.030 (0.298)	DT 0.000 (0.260)	loss 7.426 (7.370)	prob 3.128 (3.637)	GS 32.938 (32.166)	mem 76.150
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [30][1310/1500]	BT 0.028 (0.301)	DT 0.000 (0.262)	loss 7.300 (7.291)	prob 2.873 (2.837)	GS 33.984 (32.622)	mem 76.151
Train: [30][1320/1500]	BT 0.037 (0.299)	DT 0.000 (0.260)	loss 7.444 (7.263)	prob 2.529 (3.063)	GS 32.547 (32.497)	mem 76.153
Train: [30][1330/1500]	BT 0.037 (0.301)	DT 0.000 (0.263)	loss 7.220 (7.304)	prob 3.785 (3.158)	GS 32.891 (32.021)	mem 76.156
Train: [30][1340/1500]	BT 0.037 (0.299)	DT 0.001 (0.261)	loss 7.526 (7.352)	prob 3.518 (3.199)	GS 34.656 (32.379)	mem 76.156
Train: [30][1350/1500]	BT 0.057 (0.300)	DT 0.013 (0.261)	loss 7.678 (7.357)	prob 3.585 (3.134)	GS 34.703 (32.546)	mem 76.175
Train: [30][1360/1500]	BT 0.070 (0.300)	DT 0.011 (0.261)	loss 7.340 (7.259)	prob 3.185 (3.075)	GS 33.375 (33.831)	mem 76.176
Train: [30][1370/1500]	BT 0.062 (0.298)	DT 0.006 (0.259)	loss 7.488 (7.361)	prob 3.107 (3.130)	GS 31.938 (33.254)	mem 76.177
Train: [30][1380/1500]	BT 0.029 (0.302)	DT 0.000 (0.263)	loss 7.673 (7.300)	prob 2.974 (3.090)	GS 35.672 (33.155)	mem 76.157
Train: [30][1390/1500]	BT 0.024 (0.300)	DT 0.000 (0.261)	loss 7.624 (7.376)	prob 2.914 (2.877)	GS 32.375 (33.072)	mem 76.157
Train: [30][1400/1500]	BT 0.033 (0.303)	DT 0.000 (0.264)	loss 7.415 (7.398)	prob 3.075 (2.871)	GS 34.703 (33.148)	mem 76.159
Train: [30][1410/1500]	BT 0.030 (0.301)	DT 0.000 (0.262)	loss 7.362 (7.507)	prob 2.188 (2.175)	GS 35.062 (34.375)	mem 76.161
Train: [30][1420/1500]	BT 0.037 (0.299)	DT 0.001 (0.261)	loss 7.481 (7.482)	prob 2.644 (2.272)	GS 31.328 (32.912)	mem 76.162
Train: [30][1430/1500]	BT 0.031 (0.303)	DT 0.000 (0.265)	loss 7.478 (7.469)	prob 1.929 (2.179)	GS 31.766 (33.027)	mem 76.162
Train: [30][1440/1500]	BT 0.027 (0.301)	DT 0.000 (0.263)	loss 7.988 (7.473)	prob 2.399 (2.162)	GS 32.750 (33.027)	mem 76.163
Train: [30][1450/1500]	BT 0.025 (0.305)	DT 0.000 (0.266)	loss 7.602 (7.445)	prob 2.171 (2.122)	GS 35.750 (33.116)	mem 75.944
Train: [30][1460/1500]	BT 0.026 (0.303)	DT 0.000 (0.264)	loss 7.340 (7.456)	prob 3.157 (2.093)	GS 30.500 (32.494)	mem 75.945
Train: [30][1470/1500]	BT 0.030 (0.304)	DT 0.000 (0.265)	loss 7.365 (7.455)	prob 2.489 (2.439)	GS 32.375 (32.373)	mem 33.616
Train: [30][1480/1500]	BT 0.041 (0.302)	DT 0.000 (0.263)	loss 7.397 (7.510)	prob 3.063 (2.448)	GS 32.766 (32.059)	mem 33.542
Train: [30][1490/1500]	BT 0.026 (0.300)	DT 0.000 (0.262)	loss 7.246 (7.517)	prob 2.466 (2.445)	GS 35.000 (32.187)	mem 33.542
Train: [30][1500/1500]	BT 0.032 (0.299)	DT 0.000 (0.261)	loss 7.250 (7.534)	prob 2.800 (2.399)	GS 30.719 (32.273)	mem 11.068
Train: [30][1510/1500]	BT 0.032 (0.297)	DT 0.000 (0.259)	loss 8.025 (7.880)	prob 2.215 (1.992)	GS 32.875 (36.763)	mem 11.068
epoch 30, total time 448.62
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [31][1/1500]	BT 19.826 (19.826)	DT 19.775 (19.775)	loss 7.702 (7.702)	prob 1.825 (1.825)	GS 29.375 (29.375)	mem 74.749
Train: [31][10/1500]	BT 0.031 (2.465)	DT 0.000 (2.431)	loss 7.246 (7.622)	prob 2.893 (2.344)	GS 33.953 (32.641)	mem 74.859
Train: [31][20/1500]	BT 0.043 (1.275)	DT 0.011 (1.240)	loss 7.747 (7.553)	prob 3.691 (2.537)	GS 33.125 (32.796)	mem 74.865
Train: [31][30/1500]	BT 0.036 (1.021)	DT 0.000 (0.985)	loss 7.578 (7.582)	prob 3.316 (2.682)	GS 35.203 (33.013)	mem 74.900
Train: [31][40/1500]	BT 0.035 (0.775)	DT 0.000 (0.739)	loss 7.599 (7.594)	prob 3.645 (2.791)	GS 32.500 (32.767)	mem 74.901
Train: [31][50/1500]	BT 0.036 (0.627)	DT 0.000 (0.591)	loss 8.338 (7.635)	prob 3.223 (2.754)	GS 30.438 (32.640)	mem 74.901
Train: [31][60/1500]	BT 0.606 (0.594)	DT 0.569 (0.559)	loss 8.259 (8.021)	prob 3.078 (2.849)	GS 32.516 (33.206)	mem 74.916
Train: [31][70/1500]	BT 0.044 (0.515)	DT 0.010 (0.479)	loss 7.920 (7.828)	prob 3.306 (3.110)	GS 36.719 (32.805)	mem 74.918
Train: [31][80/1500]	BT 0.037 (0.531)	DT 0.000 (0.494)	loss 7.481 (7.781)	prob 3.787 (3.130)	GS 33.922 (32.597)	mem 74.922
Train: [31][90/1500]	BT 0.027 (0.517)	DT 0.000 (0.482)	loss 7.785 (7.738)	prob 3.211 (3.142)	GS 35.953 (32.627)	mem 74.927
Train: [31][100/1500]	BT 0.033 (0.469)	DT 0.000 (0.434)	loss 7.195 (7.700)	prob 4.154 (3.237)	GS 36.375 (32.718)	mem 74.927
Train: [31][110/1500]	BT 0.037 (0.456)	DT 0.000 (0.422)	loss 7.326 (7.789)	prob 4.385 (3.237)	GS 35.734 (32.753)	mem 74.934
Train: [31][120/1500]	BT 0.036 (0.421)	DT 0.000 (0.386)	loss 8.101 (7.835)	prob 3.484 (3.289)	GS 35.562 (32.773)	mem 74.933
Train: [31][130/1500]	BT 0.037 (0.396)	DT 0.001 (0.361)	loss 7.626 (7.788)	prob 3.820 (3.377)	GS 28.906 (32.513)	mem 74.936
Train: [31][140/1500]	BT 0.038 (0.386)	DT 0.001 (0.351)	loss 7.915 (7.763)	prob 3.972 (3.422)	GS 32.359 (32.111)	mem 74.940
Train: [31][150/1500]	BT 4.249 (0.391)	DT 4.186 (0.356)	loss 7.612 (7.768)	prob 4.172 (3.456)	GS 30.672 (32.103)	mem 74.942
Train: [31][160/1500]	BT 0.077 (0.425)	DT 0.005 (0.388)	loss 7.710 (7.720)	prob 3.228 (3.555)	GS 36.391 (32.747)	mem 74.953
Train: [31][170/1500]	BT 0.028 (0.481)	DT 0.000 (0.443)	loss 7.992 (7.768)	prob 3.780 (3.416)	GS 36.531 (33.361)	mem 74.958
Train: [31][180/1500]	BT 0.041 (0.456)	DT 0.000 (0.419)	loss 7.945 (7.750)	prob 3.452 (3.350)	GS 34.969 (33.554)	mem 74.959
Train: [31][190/1500]	BT 0.037 (0.448)	DT 0.001 (0.411)	loss 8.057 (7.717)	prob 3.087 (3.342)	GS 33.484 (33.388)	mem 74.965
Train: [31][200/1500]	BT 0.037 (0.427)	DT 0.001 (0.391)	loss 8.187 (7.756)	prob 3.056 (3.303)	GS 35.281 (33.553)	mem 74.965
Train: [31][210/1500]	BT 7.254 (0.443)	DT 7.208 (0.406)	loss 7.634 (7.706)	prob 3.139 (3.459)	GS 33.562 (33.002)	mem 74.971
Train: [31][220/1500]	BT 0.125 (0.427)	DT 0.030 (0.388)	loss 7.334 (7.612)	prob 4.030 (3.505)	GS 37.469 (33.527)	mem 74.970
Train: [31][230/1500]	BT 0.033 (0.450)	DT 0.001 (0.410)	loss 7.892 (7.646)	prob 3.983 (3.510)	GS 36.328 (34.391)	mem 74.974
Train: [31][240/1500]	BT 0.030 (0.432)	DT 0.000 (0.393)	loss 7.677 (7.670)	prob 3.804 (3.512)	GS 33.938 (34.339)	mem 74.975
Train: [31][250/1500]	BT 0.035 (0.416)	DT 0.000 (0.377)	loss 8.158 (7.686)	prob 4.354 (3.530)	GS 35.234 (34.063)	mem 74.975
Train: [31][260/1500]	BT 0.052 (0.418)	DT 0.004 (0.379)	loss 7.619 (7.435)	prob 3.987 (4.187)	GS 31.469 (31.934)	mem 74.979
Train: [31][270/1500]	BT 0.032 (0.405)	DT 0.000 (0.365)	loss 7.535 (7.526)	prob 4.175 (4.091)	GS 33.859 (32.675)	mem 74.978
Train: [31][280/1500]	BT 0.027 (0.430)	DT 0.000 (0.390)	loss 7.427 (7.535)	prob 4.279 (4.066)	GS 32.078 (32.698)	mem 74.982
Train: [31][290/1500]	BT 0.024 (0.416)	DT 0.000 (0.377)	loss 7.644 (7.554)	prob 3.979 (3.968)	GS 35.453 (32.643)	mem 74.982
Train: [31][300/1500]	BT 0.028 (0.403)	DT 0.000 (0.364)	loss 7.366 (7.556)	prob 4.049 (3.882)	GS 33.047 (32.630)	mem 74.982
Train: [31][310/1500]	BT 0.038 (0.400)	DT 0.001 (0.362)	loss 7.593 (7.537)	prob 4.082 (3.861)	GS 28.750 (32.434)	mem 74.986
Train: [31][320/1500]	BT 0.038 (0.389)	DT 0.000 (0.350)	loss 7.696 (7.489)	prob 4.002 (4.040)	GS 34.500 (31.879)	mem 74.986
Train: [31][330/1500]	BT 0.116 (0.387)	DT 0.008 (0.348)	loss 7.638 (7.484)	prob 4.393 (4.040)	GS 31.438 (32.107)	mem 74.988
Train: [31][340/1500]	BT 0.060 (0.378)	DT 0.001 (0.338)	loss 7.533 (7.483)	prob 4.319 (4.059)	GS 30.516 (32.086)	mem 74.989
Train: [31][350/1500]	BT 0.035 (0.391)	DT 0.000 (0.351)	loss 7.118 (7.484)	prob 3.989 (3.965)	GS 32.844 (32.108)	mem 74.994
Train: [31][360/1500]	BT 0.039 (0.387)	DT 0.001 (0.346)	loss 7.442 (7.508)	prob 3.376 (3.719)	GS 32.234 (32.441)	mem 75.025
Train: [31][370/1500]	BT 0.039 (0.378)	DT 0.001 (0.337)	loss 7.511 (7.452)	prob 4.422 (3.703)	GS 35.047 (32.845)	mem 75.025
Train: [31][380/1500]	BT 0.039 (0.385)	DT 0.001 (0.344)	loss 7.282 (7.478)	prob 3.863 (3.736)	GS 35.203 (32.996)	mem 75.026
Train: [31][390/1500]	BT 0.039 (0.376)	DT 0.001 (0.335)	loss 7.410 (7.457)	prob 3.753 (3.734)	GS 35.297 (33.236)	mem 75.026
Train: [31][400/1500]	BT 0.038 (0.378)	DT 0.001 (0.338)	loss 7.533 (7.455)	prob 3.739 (3.679)	GS 33.031 (33.430)	mem 75.025
Train: [31][410/1500]	BT 0.038 (0.370)	DT 0.001 (0.329)	loss 7.591 (7.358)	prob 4.303 (3.806)	GS 32.641 (32.905)	mem 75.025
Train: [31][420/1500]	BT 0.039 (0.362)	DT 0.001 (0.322)	loss 7.254 (7.345)	prob 4.744 (3.947)	GS 31.234 (32.434)	mem 75.026
Train: [31][430/1500]	BT 0.029 (0.365)	DT 0.000 (0.325)	loss 7.649 (7.373)	prob 4.479 (3.990)	GS 31.469 (32.297)	mem 75.028
Train: [31][440/1500]	BT 0.039 (0.358)	DT 0.001 (0.318)	loss 7.336 (7.379)	prob 3.174 (3.884)	GS 35.703 (32.163)	mem 75.031
Train: [31][450/1500]	BT 0.028 (0.368)	DT 0.000 (0.328)	loss 7.612 (7.402)	prob 2.834 (3.798)	GS 36.062 (32.397)	mem 75.031
Train: [31][460/1500]	BT 0.030 (0.361)	DT 0.000 (0.321)	loss 7.464 (7.405)	prob 4.202 (3.914)	GS 36.281 (31.462)	mem 75.031
Train: [31][470/1500]	BT 0.039 (0.359)	DT 0.001 (0.320)	loss 7.823 (7.419)	prob 3.418 (3.815)	GS 36.828 (32.734)	mem 75.032
Train: [31][480/1500]	BT 0.039 (0.354)	DT 0.001 (0.314)	loss 7.430 (7.370)	prob 4.211 (3.829)	GS 33.797 (32.229)	mem 75.033
Train: [31][490/1500]	BT 0.039 (0.347)	DT 0.001 (0.308)	loss 7.149 (7.349)	prob 3.506 (3.769)	GS 31.812 (32.184)	mem 75.032
Train: [31][500/1500]	BT 0.058 (0.350)	DT 0.009 (0.310)	loss 7.364 (7.348)	prob 3.462 (3.713)	GS 35.750 (32.266)	mem 75.034
Train: [31][510/1500]	BT 0.026 (0.357)	DT 0.000 (0.317)	loss 7.587 (7.375)	prob 2.847 (3.162)	GS 36.094 (35.433)	mem 75.228
Train: [31][520/1500]	BT 0.026 (0.351)	DT 0.000 (0.311)	loss 7.588 (7.334)	prob 3.365 (3.286)	GS 34.859 (34.285)	mem 75.326
Train: [31][530/1500]	BT 0.039 (0.350)	DT 0.001 (0.310)	loss 7.107 (7.313)	prob 3.784 (3.301)	GS 31.109 (33.843)	mem 75.717
Train: [31][540/1500]	BT 0.040 (0.344)	DT 0.001 (0.304)	loss 7.472 (7.318)	prob 3.662 (3.365)	GS 31.594 (33.412)	mem 75.766
Train: [31][550/1500]	BT 0.039 (0.339)	DT 0.001 (0.299)	loss 7.350 (7.302)	prob 3.341 (3.340)	GS 32.609 (33.243)	mem 75.766
Train: [31][560/1500]	BT 0.035 (0.340)	DT 0.001 (0.300)	loss 7.465 (7.246)	prob 2.589 (2.713)	GS 36.516 (33.417)	mem 76.112
Train: [31][570/1500]	BT 0.060 (0.337)	DT 0.002 (0.297)	loss 7.270 (7.254)	prob 2.731 (2.783)	GS 32.453 (32.821)	mem 76.112
Train: [31][580/1500]	BT 1.368 (0.340)	DT 1.331 (0.299)	loss 7.415 (7.260)	prob 2.936 (2.928)	GS 30.469 (33.039)	mem 76.208
Train: [31][590/1500]	BT 2.674 (0.339)	DT 2.635 (0.299)	loss 7.001 (7.237)	prob 3.408 (2.960)	GS 34.500 (33.025)	mem 76.207
Train: [31][600/1500]	BT 0.061 (0.335)	DT 0.022 (0.295)	loss 7.441 (7.245)	prob 3.621 (2.971)	GS 32.781 (33.034)	mem 76.208
Train: [31][610/1500]	BT 0.038 (0.334)	DT 0.001 (0.294)	loss 7.274 (7.159)	prob 2.506 (2.670)	GS 31.938 (32.822)	mem 76.209
Train: [31][620/1500]	BT 0.077 (0.339)	DT 0.011 (0.299)	loss 7.258 (7.186)	prob 3.299 (2.884)	GS 31.984 (32.234)	mem 76.211
Train: [31][630/1500]	BT 0.034 (0.343)	DT 0.001 (0.302)	loss 7.181 (7.181)	prob 3.332 (2.926)	GS 30.703 (32.567)	mem 76.210
Train: [31][640/1500]	BT 0.039 (0.338)	DT 0.001 (0.298)	loss 7.221 (7.208)	prob 2.871 (2.876)	GS 33.391 (32.341)	mem 76.211
Train: [31][650/1500]	BT 0.039 (0.333)	DT 0.001 (0.293)	loss 6.959 (7.201)	prob 3.181 (2.892)	GS 32.250 (32.101)	mem 76.211
Train: [31][660/1500]	BT 0.031 (0.335)	DT 0.000 (0.295)	loss 7.738 (7.229)	prob 1.868 (2.245)	GS 37.984 (33.569)	mem 76.216
Train: [31][670/1500]	BT 0.054 (0.333)	DT 0.006 (0.293)	loss 7.528 (7.261)	prob 2.431 (2.077)	GS 30.641 (33.650)	mem 76.219
Train: [31][680/1500]	BT 0.029 (0.332)	DT 0.000 (0.292)	loss 7.559 (7.333)	prob 2.385 (2.247)	GS 36.594 (33.377)	mem 76.235
Train: [31][690/1500]	BT 0.082 (0.330)	DT 0.003 (0.289)	loss 7.505 (7.337)	prob 2.429 (2.253)	GS 32.531 (33.381)	mem 76.235
Train: [31][700/1500]	BT 0.047 (0.334)	DT 0.002 (0.293)	loss 7.237 (7.332)	prob 2.159 (2.292)	GS 33.797 (33.027)	mem 76.233
Train: [31][710/1500]	BT 0.029 (0.341)	DT 0.000 (0.301)	loss 7.507 (7.454)	prob 2.847 (2.451)	GS 34.422 (33.716)	mem 76.231
Train: [31][720/1500]	BT 0.035 (0.337)	DT 0.000 (0.297)	loss 7.600 (7.478)	prob 2.871 (2.328)	GS 29.234 (33.432)	mem 76.232
Train: [31][730/1500]	BT 0.032 (0.333)	DT 0.000 (0.293)	loss 7.779 (7.536)	prob 2.060 (2.321)	GS 34.672 (33.297)	mem 76.249
Train: [31][740/1500]	BT 0.037 (0.333)	DT 0.000 (0.292)	loss 7.878 (7.540)	prob 2.293 (2.280)	GS 30.500 (33.138)	mem 76.132
Train: [31][750/1500]	BT 0.037 (0.329)	DT 0.001 (0.289)	loss 7.421 (7.549)	prob 2.711 (2.286)	GS 30.625 (32.982)	mem 76.131
Train: [31][760/1500]	BT 0.037 (0.328)	DT 0.001 (0.288)	loss 7.776 (7.685)	prob 2.304 (2.218)	GS 34.500 (33.339)	mem 76.131
Train: [31][770/1500]	BT 0.037 (0.325)	DT 0.000 (0.284)	loss 7.721 (7.663)	prob 3.396 (2.209)	GS 30.984 (33.059)	mem 76.131
Train: [31][780/1500]	BT 0.037 (0.324)	DT 0.001 (0.283)	loss 8.308 (7.798)	prob 3.241 (2.300)	GS 31.719 (33.223)	mem 76.130
Train: [31][790/1500]	BT 0.037 (0.322)	DT 0.000 (0.281)	loss 8.165 (7.814)	prob 2.545 (2.385)	GS 34.219 (32.922)	mem 76.129
Train: [31][800/1500]	BT 0.068 (0.320)	DT 0.002 (0.280)	loss 8.158 (7.794)	prob 2.006 (2.455)	GS 33.078 (32.913)	mem 76.130
Train: [31][810/1500]	BT 0.067 (0.324)	DT 0.016 (0.283)	loss 8.251 (7.702)	prob 2.157 (2.598)	GS 33.812 (33.211)	mem 76.132
Train: [31][820/1500]	BT 0.029 (0.330)	DT 0.000 (0.290)	loss 8.155 (7.725)	prob 2.587 (2.767)	GS 34.062 (33.030)	mem 76.154
Train: [31][830/1500]	BT 0.027 (0.326)	DT 0.000 (0.286)	loss 7.951 (7.751)	prob 3.068 (2.695)	GS 31.562 (33.059)	mem 76.156
Train: [31][840/1500]	BT 0.038 (0.328)	DT 0.000 (0.288)	loss 7.905 (7.762)	prob 3.833 (2.760)	GS 32.969 (32.655)	mem 76.146
Train: [31][850/1500]	BT 0.037 (0.324)	DT 0.000 (0.284)	loss 8.331 (7.770)	prob 2.127 (2.787)	GS 35.297 (32.648)	mem 76.147
Train: [31][860/1500]	BT 0.065 (0.322)	DT 0.006 (0.281)	loss 7.696 (7.528)	prob 3.323 (2.935)	GS 35.047 (33.302)	mem 76.147
Train: [31][870/1500]	BT 0.029 (0.342)	DT 0.000 (0.301)	loss 8.238 (7.674)	prob 3.541 (3.031)	GS 33.422 (33.686)	mem 76.144
Train: [31][880/1500]	BT 0.023 (0.338)	DT 0.000 (0.298)	loss 7.758 (7.732)	prob 3.180 (3.058)	GS 37.984 (33.329)	mem 76.144
Train: [31][890/1500]	BT 3.195 (0.338)	DT 3.147 (0.298)	loss 7.290 (7.741)	prob 3.637 (3.051)	GS 32.047 (33.072)	mem 76.146
Train: [31][900/1500]	BT 0.057 (0.335)	DT 0.011 (0.295)	loss 8.051 (7.752)	prob 3.776 (3.108)	GS 33.750 (32.925)	mem 76.146
Train: [31][910/1500]	BT 0.058 (0.332)	DT 0.011 (0.292)	loss 7.959 (7.758)	prob 2.969 (3.077)	GS 33.016 (32.273)	mem 76.146
Train: [31][920/1500]	BT 0.108 (0.336)	DT 0.021 (0.296)	loss 7.912 (7.738)	prob 2.784 (3.047)	GS 33.266 (32.610)	mem 76.144
Train: [31][930/1500]	BT 0.024 (0.339)	DT 0.000 (0.298)	loss 7.316 (7.705)	prob 4.122 (3.137)	GS 31.969 (32.930)	mem 76.142
Train: [31][940/1500]	BT 0.038 (0.336)	DT 0.001 (0.295)	loss 8.615 (7.737)	prob 3.583 (3.243)	GS 32.328 (32.396)	mem 76.143
Train: [31][950/1500]	BT 0.028 (0.337)	DT 0.000 (0.297)	loss 8.265 (7.778)	prob 3.127 (3.156)	GS 32.031 (32.579)	mem 76.143
Train: [31][960/1500]	BT 0.036 (0.334)	DT 0.000 (0.294)	loss 7.410 (7.583)	prob 4.241 (3.502)	GS 33.516 (31.683)	mem 76.143
Train: [31][970/1500]	BT 0.039 (0.331)	DT 0.001 (0.291)	loss 7.598 (7.673)	prob 4.143 (3.592)	GS 27.625 (31.523)	mem 76.143
Train: [31][980/1500]	BT 0.037 (0.331)	DT 0.001 (0.291)	loss 7.401 (7.702)	prob 3.147 (3.544)	GS 30.500 (31.929)	mem 76.156
Train: [31][990/1500]	BT 0.036 (0.328)	DT 0.001 (0.288)	loss 8.288 (7.722)	prob 2.937 (3.527)	GS 34.750 (32.385)	mem 76.158
Train: [31][1000/1500]	BT 0.062 (0.328)	DT 0.003 (0.288)	loss 7.650 (7.750)	prob 3.787 (3.517)	GS 33.469 (32.500)	mem 76.162
Train: [31][1010/1500]	BT 0.075 (0.326)	DT 0.021 (0.285)	loss 8.164 (7.716)	prob 2.919 (3.496)	GS 33.016 (33.011)	mem 76.164
Train: [31][1020/1500]	BT 0.071 (0.323)	DT 0.012 (0.282)	loss 7.603 (7.667)	prob 4.317 (3.630)	GS 30.422 (32.384)	mem 76.165
Train: [31][1030/1500]	BT 0.060 (0.327)	DT 0.012 (0.286)	loss 7.702 (7.669)	prob 3.399 (3.661)	GS 32.812 (32.362)	mem 76.166
Train: [31][1040/1500]	BT 0.038 (0.324)	DT 0.000 (0.283)	loss 8.240 (7.691)	prob 3.608 (3.674)	GS 34.219 (32.529)	mem 76.167
Train: [31][1050/1500]	BT 0.027 (0.327)	DT 0.000 (0.286)	loss 7.603 (7.698)	prob 3.842 (3.653)	GS 32.953 (32.473)	mem 76.169
Train: [31][1060/1500]	BT 0.037 (0.324)	DT 0.001 (0.283)	loss 7.505 (7.567)	prob 3.495 (3.862)	GS 32.844 (32.008)	mem 76.170
Train: [31][1070/1500]	BT 0.036 (0.325)	DT 0.000 (0.284)	loss 7.720 (7.593)	prob 3.363 (3.657)	GS 34.078 (32.725)	mem 76.172
Train: [31][1080/1500]	BT 0.028 (0.322)	DT 0.000 (0.282)	loss 7.694 (7.624)	prob 4.233 (3.737)	GS 33.500 (32.710)	mem 76.174
Train: [31][1090/1500]	BT 0.037 (0.320)	DT 0.001 (0.279)	loss 7.625 (7.594)	prob 4.141 (3.802)	GS 35.453 (32.638)	mem 76.175
Train: [31][1100/1500]	BT 1.215 (0.321)	DT 1.162 (0.281)	loss 7.579 (7.589)	prob 4.138 (3.790)	GS 35.891 (32.734)	mem 76.177
Train: [31][1110/1500]	BT 0.067 (0.319)	DT 0.011 (0.279)	loss 7.621 (7.507)	prob 4.191 (3.858)	GS 33.672 (32.164)	mem 76.180
Train: [31][1120/1500]	BT 0.037 (0.319)	DT 0.001 (0.279)	loss 8.006 (7.648)	prob 4.171 (3.993)	GS 33.938 (31.873)	mem 76.181
Train: [31][1130/1500]	BT 0.058 (0.319)	DT 0.007 (0.278)	loss 7.565 (7.593)	prob 3.715 (3.969)	GS 31.984 (32.413)	mem 76.181
Train: [31][1140/1500]	BT 0.083 (0.317)	DT 0.002 (0.276)	loss 7.449 (7.620)	prob 4.657 (3.846)	GS 33.281 (32.690)	mem 76.182
Train: [31][1150/1500]	BT 0.059 (0.318)	DT 0.008 (0.277)	loss 7.346 (7.599)	prob 3.938 (3.904)	GS 35.422 (32.481)	mem 76.183
Train: [31][1160/1500]	BT 0.028 (0.319)	DT 0.000 (0.278)	loss 7.575 (7.562)	prob 4.380 (3.738)	GS 31.922 (31.506)	mem 76.185
Train: [31][1170/1500]	BT 0.037 (0.318)	DT 0.001 (0.277)	loss 8.069 (7.587)	prob 3.099 (3.679)	GS 37.125 (32.756)	mem 76.185
Train: [31][1180/1500]	BT 0.037 (0.317)	DT 0.001 (0.276)	loss 7.432 (7.540)	prob 3.064 (3.718)	GS 35.922 (32.836)	mem 76.186
Train: [31][1190/1500]	BT 0.037 (0.316)	DT 0.001 (0.275)	loss 7.285 (7.539)	prob 3.824 (3.673)	GS 32.281 (32.825)	mem 76.186
Train: [31][1200/1500]	BT 0.068 (0.314)	DT 0.006 (0.274)	loss 7.714 (7.547)	prob 3.600 (3.636)	GS 33.578 (32.906)	mem 76.189
Train: [31][1210/1500]	BT 0.055 (0.315)	DT 0.001 (0.274)	loss 7.844 (7.421)	prob 4.140 (4.022)	GS 35.578 (34.066)	mem 76.188
Train: [31][1220/1500]	BT 0.038 (0.315)	DT 0.001 (0.273)	loss 7.171 (7.356)	prob 4.052 (4.026)	GS 38.047 (33.643)	mem 76.189
Train: [31][1230/1500]	BT 0.033 (0.315)	DT 0.001 (0.274)	loss 7.257 (7.334)	prob 4.430 (3.947)	GS 35.875 (33.381)	mem 76.187
Train: [31][1240/1500]	BT 0.093 (0.316)	DT 0.011 (0.275)	loss 7.960 (7.396)	prob 3.966 (3.990)	GS 33.250 (33.198)	mem 76.188
Train: [31][1250/1500]	BT 0.040 (0.317)	DT 0.000 (0.275)	loss 7.208 (7.382)	prob 4.346 (4.001)	GS 32.688 (33.011)	mem 76.187
Train: [31][1260/1500]	BT 0.038 (0.316)	DT 0.001 (0.275)	loss 7.590 (7.507)	prob 4.501 (3.783)	GS 38.281 (33.047)	mem 76.189
Train: [31][1270/1500]	BT 0.037 (0.314)	DT 0.001 (0.273)	loss 7.490 (7.477)	prob 4.443 (3.862)	GS 32.906 (32.521)	mem 76.189
Train: [31][1280/1500]	BT 0.029 (0.315)	DT 0.000 (0.274)	loss 7.191 (7.476)	prob 4.620 (3.890)	GS 29.078 (32.023)	mem 76.189
Train: [31][1290/1500]	BT 0.028 (0.313)	DT 0.000 (0.272)	loss 7.466 (7.470)	prob 3.506 (3.880)	GS 28.000 (31.851)	mem 76.188
Train: [31][1300/1500]	BT 0.025 (0.311)	DT 0.000 (0.270)	loss 7.673 (7.444)	prob 4.131 (3.847)	GS 35.500 (31.826)	mem 76.188
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [31][1310/1500]	BT 0.032 (0.312)	DT 0.000 (0.271)	loss 7.751 (7.438)	prob 3.611 (3.301)	GS 34.859 (32.980)	mem 76.188
Train: [31][1320/1500]	BT 0.036 (0.310)	DT 0.001 (0.269)	loss 7.403 (7.422)	prob 4.146 (3.540)	GS 30.672 (32.274)	mem 76.190
Train: [31][1330/1500]	BT 0.033 (0.310)	DT 0.000 (0.269)	loss 7.164 (7.395)	prob 4.031 (3.663)	GS 32.547 (31.911)	mem 76.221
Train: [31][1340/1500]	BT 0.039 (0.309)	DT 0.001 (0.268)	loss 7.068 (7.399)	prob 3.782 (3.679)	GS 38.172 (32.127)	mem 76.220
Train: [31][1350/1500]	BT 0.031 (0.310)	DT 0.001 (0.269)	loss 7.377 (7.389)	prob 3.501 (3.684)	GS 34.703 (32.230)	mem 76.220
Train: [31][1360/1500]	BT 0.028 (0.311)	DT 0.000 (0.270)	loss 7.575 (7.298)	prob 4.013 (3.765)	GS 34.344 (34.464)	mem 76.220
Train: [31][1370/1500]	BT 0.039 (0.309)	DT 0.001 (0.268)	loss 7.496 (7.301)	prob 3.681 (3.744)	GS 34.969 (33.466)	mem 76.221
Train: [31][1380/1500]	BT 0.036 (0.310)	DT 0.000 (0.270)	loss 7.594 (7.299)	prob 3.971 (3.669)	GS 30.266 (32.489)	mem 76.220
Train: [31][1390/1500]	BT 0.025 (0.308)	DT 0.000 (0.268)	loss 7.382 (7.289)	prob 3.564 (3.649)	GS 36.312 (32.344)	mem 76.222
Train: [31][1400/1500]	BT 0.035 (0.310)	DT 0.000 (0.270)	loss 7.773 (7.309)	prob 3.384 (3.569)	GS 34.875 (32.542)	mem 76.222
Train: [31][1410/1500]	BT 0.033 (0.308)	DT 0.000 (0.268)	loss 7.221 (7.225)	prob 3.494 (3.574)	GS 34.844 (34.905)	mem 76.223
Train: [31][1420/1500]	BT 0.054 (0.307)	DT 0.006 (0.266)	loss 7.325 (7.203)	prob 3.620 (3.629)	GS 35.953 (33.559)	mem 76.223
Train: [31][1430/1500]	BT 0.039 (0.308)	DT 0.001 (0.267)	loss 7.228 (7.223)	prob 3.802 (3.530)	GS 33.625 (33.406)	mem 76.223
Train: [31][1440/1500]	BT 0.038 (0.307)	DT 0.001 (0.266)	loss 7.621 (7.265)	prob 3.493 (3.510)	GS 34.281 (32.907)	mem 76.225
Train: [31][1450/1500]	BT 0.033 (0.310)	DT 0.001 (0.270)	loss 7.227 (7.284)	prob 3.111 (3.525)	GS 32.297 (33.082)	mem 75.929
Train: [31][1460/1500]	BT 0.030 (0.308)	DT 0.000 (0.268)	loss 7.519 (7.279)	prob 3.311 (3.571)	GS 35.797 (33.586)	mem 75.930
Train: [31][1470/1500]	BT 0.040 (0.307)	DT 0.001 (0.266)	loss 7.467 (7.250)	prob 3.647 (3.642)	GS 34.734 (33.257)	mem 75.895
Train: [31][1480/1500]	BT 0.024 (0.307)	DT 0.000 (0.267)	loss 7.081 (7.265)	prob 4.080 (3.667)	GS 34.531 (33.062)	mem 13.952
Train: [31][1490/1500]	BT 0.026 (0.305)	DT 0.000 (0.265)	loss 7.897 (7.278)	prob 2.726 (3.515)	GS 36.688 (32.931)	mem 13.952
Train: [31][1500/1500]	BT 0.031 (0.304)	DT 0.000 (0.264)	loss 7.430 (7.287)	prob 3.816 (3.507)	GS 33.906 (33.055)	mem 11.140
Train: [31][1510/1500]	BT 0.026 (0.302)	DT 0.000 (0.262)	loss 6.752 (7.111)	prob 2.785 (3.231)	GS 34.500 (33.009)	mem 11.140
epoch 31, total time 456.25
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [32][1/1500]	BT 18.702 (18.702)	DT 18.644 (18.644)	loss 7.112 (7.112)	prob 4.439 (4.439)	GS 33.078 (33.078)	mem 74.828
Train: [32][10/1500]	BT 0.038 (2.532)	DT 0.000 (2.483)	loss 7.231 (7.053)	prob 3.503 (3.194)	GS 33.859 (36.188)	mem 74.950
Train: [32][20/1500]	BT 0.055 (1.286)	DT 0.000 (1.242)	loss 7.162 (7.095)	prob 4.050 (3.427)	GS 34.328 (34.240)	mem 74.951
Train: [32][30/1500]	BT 0.066 (0.988)	DT 0.005 (0.943)	loss 7.350 (7.132)	prob 3.360 (3.460)	GS 32.672 (33.615)	mem 75.008
Train: [32][40/1500]	BT 0.037 (0.788)	DT 0.001 (0.743)	loss 7.324 (7.182)	prob 3.712 (3.414)	GS 29.547 (33.100)	mem 75.013
Train: [32][50/1500]	BT 1.626 (0.670)	DT 1.591 (0.626)	loss 7.288 (7.188)	prob 3.625 (3.451)	GS 33.141 (33.065)	mem 75.017
Train: [32][60/1500]	BT 0.034 (0.679)	DT 0.000 (0.635)	loss 7.081 (7.303)	prob 2.988 (3.421)	GS 36.234 (33.073)	mem 75.028
Train: [32][70/1500]	BT 0.028 (0.631)	DT 0.000 (0.589)	loss 7.253 (7.341)	prob 2.779 (3.223)	GS 34.812 (33.211)	mem 75.042
Train: [32][80/1500]	BT 0.038 (0.560)	DT 0.001 (0.518)	loss 7.018 (7.298)	prob 2.691 (3.110)	GS 30.734 (32.930)	mem 75.043
Train: [32][90/1500]	BT 0.026 (0.547)	DT 0.000 (0.506)	loss 7.465 (7.327)	prob 3.217 (3.082)	GS 33.594 (32.824)	mem 74.956
Train: [32][100/1500]	BT 0.066 (0.496)	DT 0.006 (0.455)	loss 7.225 (7.328)	prob 3.454 (3.027)	GS 31.312 (32.722)	mem 74.957
Train: [32][110/1500]	BT 0.053 (0.530)	DT 0.000 (0.489)	loss 7.200 (7.372)	prob 3.523 (3.060)	GS 29.250 (31.637)	mem 74.961
Train: [32][120/1500]	BT 0.030 (0.501)	DT 0.000 (0.462)	loss 7.284 (7.344)	prob 2.598 (2.781)	GS 32.672 (32.662)	mem 74.969
Train: [32][130/1500]	BT 0.036 (0.465)	DT 0.000 (0.426)	loss 7.411 (7.349)	prob 2.337 (2.804)	GS 30.688 (32.495)	mem 74.970
Train: [32][140/1500]	BT 0.029 (0.463)	DT 0.000 (0.424)	loss 7.598 (7.363)	prob 2.553 (2.695)	GS 35.016 (32.963)	mem 74.992
Train: [32][150/1500]	BT 0.038 (0.434)	DT 0.001 (0.396)	loss 7.552 (7.347)	prob 2.336 (2.599)	GS 28.578 (33.023)	mem 74.999
Train: [32][160/1500]	BT 0.037 (0.435)	DT 0.001 (0.397)	loss 7.669 (7.534)	prob 2.259 (2.411)	GS 31.438 (32.844)	mem 75.016
Train: [32][170/1500]	BT 0.060 (0.413)	DT 0.016 (0.374)	loss 7.709 (7.506)	prob 2.714 (2.310)	GS 35.969 (32.462)	mem 75.016
Train: [32][180/1500]	BT 0.061 (0.393)	DT 0.002 (0.354)	loss 8.031 (7.578)	prob 1.441 (2.182)	GS 37.312 (32.860)	mem 75.017
Train: [32][190/1500]	BT 0.036 (0.398)	DT 0.000 (0.359)	loss 7.497 (7.545)	prob 1.434 (2.170)	GS 34.484 (32.819)	mem 75.022
Train: [32][200/1500]	BT 0.041 (0.381)	DT 0.000 (0.341)	loss 8.420 (7.566)	prob 2.047 (2.142)	GS 32.844 (32.949)	mem 75.023
Train: [32][210/1500]	BT 0.060 (0.394)	DT 0.011 (0.354)	loss 8.200 (7.578)	prob 1.497 (2.202)	GS 33.328 (33.691)	mem 75.009
Train: [32][220/1500]	BT 0.028 (0.451)	DT 0.000 (0.411)	loss 7.679 (7.626)	prob 2.021 (2.234)	GS 34.688 (33.672)	mem 75.016
Train: [32][230/1500]	BT 0.026 (0.433)	DT 0.000 (0.393)	loss 8.417 (7.616)	prob 2.543 (2.266)	GS 35.125 (33.274)	mem 75.018
Train: [32][240/1500]	BT 0.039 (0.428)	DT 0.001 (0.388)	loss 7.729 (7.648)	prob 2.102 (2.226)	GS 30.438 (33.177)	mem 75.021
Train: [32][250/1500]	BT 0.039 (0.412)	DT 0.001 (0.373)	loss 7.830 (7.680)	prob 2.930 (2.196)	GS 32.750 (33.337)	mem 75.021
Train: [32][260/1500]	BT 0.035 (0.398)	DT 0.000 (0.359)	loss 7.631 (7.782)	prob 2.054 (2.273)	GS 35.016 (32.536)	mem 75.021
Train: [32][270/1500]	BT 0.032 (0.396)	DT 0.000 (0.356)	loss 8.331 (7.754)	prob 2.169 (2.245)	GS 35.938 (32.947)	mem 75.026
Train: [32][280/1500]	BT 0.045 (0.383)	DT 0.000 (0.344)	loss 8.228 (7.764)	prob 2.753 (2.238)	GS 34.156 (32.497)	mem 75.028
Train: [32][290/1500]	BT 0.064 (0.388)	DT 0.015 (0.348)	loss 7.666 (7.827)	prob 3.411 (2.367)	GS 31.688 (32.349)	mem 75.029
Train: [32][300/1500]	BT 0.054 (0.399)	DT 0.001 (0.359)	loss 8.745 (7.829)	prob 2.375 (2.441)	GS 36.047 (32.657)	mem 75.033
Train: [32][310/1500]	BT 0.039 (0.400)	DT 0.001 (0.359)	loss 8.518 (7.917)	prob 2.754 (2.628)	GS 30.422 (34.617)	mem 75.031
Train: [32][320/1500]	BT 0.030 (0.396)	DT 0.000 (0.356)	loss 7.667 (7.788)	prob 3.277 (2.669)	GS 30.328 (34.267)	mem 75.033
Train: [32][330/1500]	BT 0.040 (0.385)	DT 0.001 (0.345)	loss 7.500 (7.770)	prob 3.672 (2.731)	GS 30.438 (33.143)	mem 75.034
Train: [32][340/1500]	BT 0.035 (0.391)	DT 0.000 (0.350)	loss 8.148 (7.823)	prob 3.507 (2.828)	GS 35.547 (32.792)	mem 75.035
Train: [32][350/1500]	BT 0.037 (0.380)	DT 0.001 (0.340)	loss 7.869 (7.791)	prob 3.779 (2.890)	GS 36.625 (32.909)	mem 75.036
Train: [32][360/1500]	BT 0.039 (0.372)	DT 0.001 (0.332)	loss 8.566 (8.120)	prob 3.107 (2.824)	GS 31.547 (31.575)	mem 75.038
Train: [32][370/1500]	BT 0.060 (0.370)	DT 0.005 (0.329)	loss 8.257 (8.034)	prob 3.750 (3.045)	GS 35.188 (31.854)	mem 75.051
Train: [32][380/1500]	BT 0.038 (0.361)	DT 0.000 (0.321)	loss 7.712 (7.971)	prob 3.138 (3.161)	GS 36.984 (32.139)	mem 75.053
Train: [32][390/1500]	BT 0.028 (0.363)	DT 0.000 (0.322)	loss 7.841 (7.941)	prob 4.008 (3.101)	GS 34.766 (32.343)	mem 75.059
Train: [32][400/1500]	BT 0.037 (0.354)	DT 0.000 (0.314)	loss 7.817 (7.934)	prob 3.047 (3.096)	GS 31.906 (32.604)	mem 75.060
Train: [32][410/1500]	BT 0.060 (0.352)	DT 0.016 (0.312)	loss 7.799 (7.937)	prob 3.362 (2.916)	GS 35.297 (33.500)	mem 75.061
Train: [32][420/1500]	BT 0.034 (0.350)	DT 0.001 (0.310)	loss 8.201 (7.922)	prob 3.344 (3.110)	GS 33.016 (33.059)	mem 75.063
Train: [32][430/1500]	BT 2.345 (0.352)	DT 2.307 (0.312)	loss 7.866 (7.912)	prob 4.009 (3.246)	GS 37.953 (33.029)	mem 75.064
Train: [32][440/1500]	BT 0.028 (0.349)	DT 0.000 (0.309)	loss 8.696 (7.908)	prob 3.800 (3.333)	GS 33.094 (32.785)	mem 75.067
Train: [32][450/1500]	BT 0.037 (0.342)	DT 0.001 (0.303)	loss 7.423 (7.865)	prob 4.549 (3.387)	GS 32.375 (32.904)	mem 75.068
Train: [32][460/1500]	BT 0.028 (0.346)	DT 0.000 (0.307)	loss 8.395 (7.916)	prob 3.260 (3.409)	GS 35.016 (33.828)	mem 75.072
Train: [32][470/1500]	BT 0.038 (0.340)	DT 0.000 (0.300)	loss 8.232 (7.829)	prob 3.546 (3.496)	GS 37.188 (32.977)	mem 75.072
Train: [32][480/1500]	BT 0.026 (0.341)	DT 0.000 (0.301)	loss 7.819 (7.801)	prob 3.509 (3.551)	GS 30.859 (32.347)	mem 75.072
Train: [32][490/1500]	BT 0.028 (0.334)	DT 0.000 (0.295)	loss 7.945 (7.820)	prob 3.502 (3.517)	GS 36.953 (32.700)	mem 75.072
Train: [32][500/1500]	BT 0.024 (0.328)	DT 0.000 (0.289)	loss 8.600 (7.801)	prob 3.638 (3.526)	GS 36.422 (32.458)	mem 75.073
Train: [32][510/1500]	BT 0.037 (0.332)	DT 0.000 (0.293)	loss 7.647 (7.899)	prob 4.261 (3.715)	GS 35.484 (32.519)	mem 75.076
Train: [32][520/1500]	BT 0.038 (0.326)	DT 0.001 (0.287)	loss 7.688 (7.813)	prob 4.363 (3.838)	GS 31.984 (31.514)	mem 75.077
Train: [32][530/1500]	BT 0.027 (0.328)	DT 0.000 (0.290)	loss 8.195 (7.822)	prob 4.028 (3.830)	GS 35.547 (31.632)	mem 75.078
Train: [32][540/1500]	BT 0.027 (0.323)	DT 0.000 (0.285)	loss 7.823 (7.812)	prob 3.602 (3.761)	GS 34.188 (31.821)	mem 75.079
Train: [32][550/1500]	BT 4.167 (0.325)	DT 4.123 (0.287)	loss 7.652 (7.805)	prob 3.524 (3.732)	GS 34.312 (31.985)	mem 75.080
Train: [32][560/1500]	BT 0.027 (0.320)	DT 0.000 (0.282)	loss 7.687 (7.749)	prob 3.842 (3.687)	GS 30.312 (32.873)	mem 75.081
Train: [32][570/1500]	BT 0.031 (0.324)	DT 0.000 (0.286)	loss 8.072 (7.764)	prob 4.242 (3.730)	GS 34.234 (33.298)	mem 75.133
Train: [32][580/1500]	BT 0.028 (0.319)	DT 0.000 (0.281)	loss 7.846 (7.786)	prob 3.478 (3.788)	GS 35.062 (33.194)	mem 75.133
Train: [32][590/1500]	BT 0.035 (0.314)	DT 0.000 (0.276)	loss 7.748 (7.794)	prob 4.010 (3.771)	GS 34.219 (33.180)	mem 75.133
Train: [32][600/1500]	BT 0.028 (0.316)	DT 0.000 (0.278)	loss 7.873 (7.784)	prob 3.163 (3.730)	GS 33.984 (33.062)	mem 75.474
Train: [32][610/1500]	BT 0.027 (0.311)	DT 0.000 (0.274)	loss 8.449 (7.742)	prob 3.398 (3.311)	GS 37.531 (32.819)	mem 75.475
Train: [32][620/1500]	BT 0.054 (0.314)	DT 0.001 (0.277)	loss 7.841 (7.803)	prob 3.530 (3.245)	GS 34.688 (33.641)	mem 76.012
Train: [32][630/1500]	BT 0.029 (0.310)	DT 0.000 (0.272)	loss 7.862 (7.793)	prob 3.639 (3.484)	GS 33.438 (33.199)	mem 76.013
Train: [32][640/1500]	BT 0.038 (0.305)	DT 0.001 (0.268)	loss 7.909 (7.763)	prob 3.738 (3.555)	GS 31.859 (33.096)	mem 76.063
Train: [32][650/1500]	BT 0.028 (0.308)	DT 0.000 (0.271)	loss 7.368 (7.754)	prob 4.686 (3.626)	GS 31.500 (32.832)	mem 76.288
Train: [32][660/1500]	BT 0.039 (0.304)	DT 0.000 (0.266)	loss 7.901 (7.772)	prob 4.020 (3.508)	GS 35.250 (33.223)	mem 76.288
Train: [32][670/1500]	BT 0.039 (0.304)	DT 0.001 (0.267)	loss 7.366 (7.720)	prob 5.019 (3.743)	GS 36.969 (32.859)	mem 76.289
Train: [32][680/1500]	BT 0.040 (0.300)	DT 0.001 (0.263)	loss 7.519 (7.692)	prob 3.910 (3.643)	GS 32.875 (32.706)	mem 76.290
Train: [32][690/1500]	BT 0.039 (0.302)	DT 0.000 (0.265)	loss 7.705 (7.712)	prob 3.983 (3.602)	GS 31.672 (32.539)	mem 76.289
Train: [32][700/1500]	BT 0.039 (0.298)	DT 0.000 (0.261)	loss 8.164 (7.700)	prob 4.842 (3.749)	GS 29.203 (32.356)	mem 76.291
Train: [32][710/1500]	BT 0.040 (0.295)	DT 0.001 (0.257)	loss 7.545 (7.632)	prob 4.439 (4.148)	GS 33.250 (30.620)	mem 76.292
Train: [32][720/1500]	BT 0.038 (0.297)	DT 0.001 (0.260)	loss 7.176 (7.596)	prob 4.112 (4.082)	GS 30.594 (31.260)	mem 76.290
Train: [32][730/1500]	BT 0.038 (0.294)	DT 0.001 (0.257)	loss 7.529 (7.535)	prob 3.621 (3.987)	GS 33.438 (31.520)	mem 76.289
Train: [32][740/1500]	BT 0.033 (0.304)	DT 0.001 (0.267)	loss 9.106 (7.585)	prob 2.517 (3.847)	GS 31.781 (32.240)	mem 76.291
Train: [32][750/1500]	BT 0.031 (0.301)	DT 0.000 (0.264)	loss 7.516 (7.568)	prob 4.296 (3.825)	GS 37.016 (32.272)	mem 76.292
Train: [32][760/1500]	BT 0.028 (0.297)	DT 0.000 (0.260)	loss 7.947 (7.605)	prob 3.631 (3.387)	GS 30.328 (32.516)	mem 76.293
Train: [32][770/1500]	BT 0.048 (0.298)	DT 0.004 (0.261)	loss 7.391 (7.559)	prob 4.121 (3.485)	GS 30.641 (32.613)	mem 76.295
Train: [32][780/1500]	BT 0.039 (0.294)	DT 0.001 (0.257)	loss 7.570 (7.530)	prob 4.088 (3.493)	GS 34.391 (32.486)	mem 76.296
Train: [32][790/1500]	BT 0.039 (0.295)	DT 0.001 (0.258)	loss 7.483 (7.562)	prob 3.966 (3.458)	GS 27.453 (32.194)	mem 76.294
Train: [32][800/1500]	BT 0.039 (0.292)	DT 0.001 (0.255)	loss 7.942 (7.579)	prob 3.201 (3.465)	GS 34.656 (32.278)	mem 76.294
Train: [32][810/1500]	BT 0.047 (0.295)	DT 0.005 (0.258)	loss 7.541 (7.532)	prob 2.954 (3.646)	GS 34.062 (32.505)	mem 76.294
Train: [32][820/1500]	BT 0.030 (0.292)	DT 0.000 (0.255)	loss 7.363 (7.464)	prob 3.924 (3.501)	GS 33.516 (31.813)	mem 76.294
Train: [32][830/1500]	BT 0.046 (0.289)	DT 0.000 (0.252)	loss 7.836 (7.523)	prob 3.437 (3.491)	GS 31.453 (31.722)	mem 76.295
Train: [32][840/1500]	BT 0.072 (0.297)	DT 0.011 (0.260)	loss 7.633 (7.510)	prob 4.788 (3.512)	GS 33.312 (31.735)	mem 76.294
Train: [32][850/1500]	BT 0.062 (0.294)	DT 0.001 (0.257)	loss 7.509 (7.468)	prob 3.276 (3.495)	GS 35.234 (31.911)	mem 76.293
Train: [32][860/1500]	BT 0.028 (0.310)	DT 0.000 (0.273)	loss 7.318 (7.409)	prob 3.384 (3.199)	GS 32.375 (34.708)	mem 76.294
Train: [32][870/1500]	BT 0.028 (0.307)	DT 0.000 (0.270)	loss 7.529 (7.424)	prob 3.382 (3.247)	GS 33.375 (34.509)	mem 76.296
Train: [32][880/1500]	BT 0.029 (0.309)	DT 0.001 (0.271)	loss 7.743 (7.404)	prob 3.390 (3.338)	GS 35.125 (33.696)	mem 76.305
Train: [32][890/1500]	BT 0.024 (0.305)	DT 0.000 (0.268)	loss 7.209 (7.402)	prob 3.225 (3.354)	GS 35.156 (33.596)	mem 76.304
Train: [32][900/1500]	BT 0.037 (0.302)	DT 0.000 (0.265)	loss 7.527 (7.390)	prob 3.550 (3.339)	GS 35.500 (33.261)	mem 76.306
Train: [32][910/1500]	BT 0.067 (0.307)	DT 0.020 (0.270)	loss 7.683 (7.512)	prob 3.524 (3.291)	GS 33.656 (32.191)	mem 76.320
Train: [32][920/1500]	BT 0.025 (0.304)	DT 0.000 (0.267)	loss 7.900 (7.546)	prob 3.637 (3.419)	GS 32.766 (31.866)	mem 76.321
Train: [32][930/1500]	BT 0.027 (0.306)	DT 0.000 (0.269)	loss 7.938 (7.499)	prob 3.040 (3.438)	GS 46.672 (32.789)	mem 76.223
Train: [32][940/1500]	BT 0.028 (0.303)	DT 0.000 (0.266)	loss 7.530 (7.473)	prob 3.207 (3.299)	GS 37.328 (32.911)	mem 76.225
Train: [32][950/1500]	BT 0.039 (0.301)	DT 0.002 (0.264)	loss 7.570 (7.453)	prob 4.125 (3.320)	GS 34.562 (32.737)	mem 76.225
Train: [32][960/1500]	BT 0.037 (0.302)	DT 0.001 (0.265)	loss 7.496 (7.523)	prob 3.791 (3.042)	GS 33.016 (31.405)	mem 76.224
Train: [32][970/1500]	BT 0.037 (0.299)	DT 0.001 (0.262)	loss 7.180 (7.449)	prob 3.259 (3.155)	GS 30.953 (32.021)	mem 76.224
Train: [32][980/1500]	BT 0.064 (0.300)	DT 0.003 (0.263)	loss 7.756 (7.447)	prob 3.029 (3.163)	GS 32.734 (33.005)	mem 76.225
Train: [32][990/1500]	BT 0.035 (0.297)	DT 0.001 (0.260)	loss 7.374 (7.458)	prob 2.839 (3.082)	GS 33.516 (33.121)	mem 76.227
Train: [32][1000/1500]	BT 0.029 (0.299)	DT 0.000 (0.262)	loss 7.199 (7.471)	prob 2.967 (2.981)	GS 36.859 (33.334)	mem 76.227
Train: [32][1010/1500]	BT 0.037 (0.297)	DT 0.001 (0.260)	loss 7.279 (7.511)	prob 3.331 (3.319)	GS 32.812 (31.134)	mem 76.230
Train: [32][1020/1500]	BT 0.038 (0.295)	DT 0.001 (0.258)	loss 7.777 (7.490)	prob 3.105 (3.214)	GS 30.484 (30.900)	mem 76.230
Train: [32][1030/1500]	BT 0.048 (0.296)	DT 0.000 (0.259)	loss 7.516 (7.584)	prob 2.204 (2.920)	GS 34.766 (31.853)	mem 76.249
Train: [32][1040/1500]	BT 0.058 (0.294)	DT 0.011 (0.257)	loss 7.360 (7.596)	prob 3.149 (2.840)	GS 34.547 (32.073)	mem 76.249
Train: [32][1050/1500]	BT 0.068 (0.298)	DT 0.002 (0.260)	loss 7.954 (7.589)	prob 2.223 (2.700)	GS 37.594 (32.462)	mem 76.244
Train: [32][1060/1500]	BT 0.072 (0.295)	DT 0.005 (0.258)	loss 8.551 (7.873)	prob 1.903 (2.226)	GS 34.438 (31.450)	mem 76.243
Train: [32][1070/1500]	BT 0.033 (0.307)	DT 0.000 (0.270)	loss 8.038 (7.878)	prob 2.732 (2.394)	GS 36.281 (31.884)	mem 76.229
Train: [32][1080/1500]	BT 0.031 (0.305)	DT 0.000 (0.267)	loss 8.092 (7.811)	prob 1.999 (2.408)	GS 37.203 (32.061)	mem 76.229
Train: [32][1090/1500]	BT 0.032 (0.306)	DT 0.001 (0.268)	loss 8.467 (7.792)	prob 2.435 (2.553)	GS 32.891 (32.141)	mem 76.231
Train: [32][1100/1500]	BT 0.027 (0.304)	DT 0.000 (0.266)	loss 8.140 (7.807)	prob 3.218 (2.629)	GS 34.141 (32.285)	mem 76.233
Train: [32][1110/1500]	BT 0.029 (0.301)	DT 0.000 (0.264)	loss 8.416 (7.834)	prob 2.642 (2.855)	GS 30.656 (32.055)	mem 76.235
Train: [32][1120/1500]	BT 0.029 (0.302)	DT 0.000 (0.265)	loss 7.733 (7.830)	prob 2.844 (2.621)	GS 37.047 (32.895)	mem 76.234
Train: [32][1130/1500]	BT 0.026 (0.300)	DT 0.000 (0.263)	loss 7.909 (7.860)	prob 2.478 (2.397)	GS 36.906 (33.065)	mem 76.235
Train: [32][1140/1500]	BT 0.039 (0.300)	DT 0.001 (0.263)	loss 8.250 (7.861)	prob 3.179 (2.401)	GS 35.562 (33.120)	mem 76.235
Train: [32][1150/1500]	BT 0.037 (0.298)	DT 0.001 (0.261)	loss 8.647 (7.848)	prob 2.499 (2.638)	GS 34.406 (32.747)	mem 76.236
Train: [32][1160/1500]	BT 0.039 (0.296)	DT 0.000 (0.258)	loss 8.248 (7.831)	prob 1.820 (2.529)	GS 31.016 (31.372)	mem 76.233
Train: [32][1170/1500]	BT 0.039 (0.296)	DT 0.001 (0.259)	loss 8.596 (7.945)	prob 2.411 (2.510)	GS 32.922 (31.876)	mem 76.234
Train: [32][1180/1500]	BT 0.039 (0.294)	DT 0.001 (0.257)	loss 8.145 (7.929)	prob 2.749 (2.588)	GS 33.875 (32.146)	mem 76.234
Train: [32][1190/1500]	BT 0.037 (0.295)	DT 0.001 (0.257)	loss 8.479 (7.938)	prob 2.022 (2.587)	GS 38.031 (32.552)	mem 76.249
Train: [32][1200/1500]	BT 0.037 (0.293)	DT 0.001 (0.255)	loss 8.884 (7.939)	prob 3.111 (2.637)	GS 34.750 (32.569)	mem 76.252
Train: [32][1210/1500]	BT 0.037 (0.293)	DT 0.000 (0.255)	loss 8.777 (7.860)	prob 2.004 (3.101)	GS 31.672 (33.469)	mem 76.256
Train: [32][1220/1500]	BT 0.037 (0.292)	DT 0.001 (0.255)	loss 8.095 (7.899)	prob 3.718 (3.108)	GS 32.750 (32.946)	mem 76.257
Train: [32][1230/1500]	BT 0.038 (0.290)	DT 0.000 (0.253)	loss 8.103 (7.895)	prob 3.233 (3.127)	GS 30.922 (32.733)	mem 76.257
Train: [32][1240/1500]	BT 0.251 (0.290)	DT 0.214 (0.252)	loss 7.773 (7.967)	prob 3.030 (3.066)	GS 30.562 (32.708)	mem 76.259
Train: [32][1250/1500]	BT 0.037 (0.289)	DT 0.001 (0.251)	loss 8.255 (7.986)	prob 3.197 (3.049)	GS 31.141 (32.628)	mem 76.261
Train: [32][1260/1500]	BT 0.037 (0.290)	DT 0.001 (0.252)	loss 8.280 (8.077)	prob 2.991 (3.034)	GS 37.828 (32.550)	mem 76.263
Train: [32][1270/1500]	BT 0.038 (0.288)	DT 0.001 (0.250)	loss 8.337 (8.047)	prob 3.822 (3.128)	GS 38.297 (32.771)	mem 76.263
Train: [32][1280/1500]	BT 0.038 (0.286)	DT 0.001 (0.249)	loss 7.720 (8.028)	prob 3.081 (3.061)	GS 31.984 (33.019)	mem 76.263
Train: [32][1290/1500]	BT 0.886 (0.287)	DT 0.848 (0.250)	loss 7.818 (7.990)	prob 2.438 (3.184)	GS 35.422 (32.797)	mem 76.265
Train: [32][1300/1500]	BT 0.037 (0.285)	DT 0.001 (0.248)	loss 8.293 (7.993)	prob 4.771 (3.243)	GS 32.312 (32.558)	mem 76.265
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [32][1310/1500]	BT 0.038 (0.285)	DT 0.001 (0.248)	loss 8.754 (7.833)	prob 3.475 (4.029)	GS 35.750 (32.464)	mem 76.265
Train: [32][1320/1500]	BT 0.027 (0.285)	DT 0.000 (0.248)	loss 7.692 (7.900)	prob 4.904 (3.641)	GS 30.844 (31.976)	mem 76.267
Train: [32][1330/1500]	BT 0.030 (0.292)	DT 0.000 (0.255)	loss 7.823 (7.857)	prob 3.615 (3.736)	GS 30.594 (31.730)	mem 76.266
Train: [32][1340/1500]	BT 0.030 (0.290)	DT 0.000 (0.253)	loss 8.305 (7.904)	prob 3.701 (3.700)	GS 37.609 (32.014)	mem 76.266
Train: [32][1350/1500]	BT 0.035 (0.289)	DT 0.000 (0.251)	loss 8.767 (7.898)	prob 2.654 (3.706)	GS 33.281 (32.017)	mem 76.267
Train: [32][1360/1500]	BT 0.025 (0.290)	DT 0.000 (0.253)	loss 8.269 (7.939)	prob 2.970 (2.868)	GS 36.281 (33.539)	mem 76.267
Train: [32][1370/1500]	BT 0.035 (0.288)	DT 0.001 (0.251)	loss 7.981 (7.956)	prob 3.916 (3.228)	GS 34.625 (32.988)	mem 76.267
Train: [32][1380/1500]	BT 0.037 (0.288)	DT 0.001 (0.251)	loss 7.745 (7.916)	prob 4.034 (3.368)	GS 33.781 (32.879)	mem 76.270
Train: [32][1390/1500]	BT 0.038 (0.286)	DT 0.001 (0.249)	loss 7.713 (7.829)	prob 5.105 (3.608)	GS 36.344 (32.682)	mem 76.269
Train: [32][1400/1500]	BT 0.037 (0.284)	DT 0.000 (0.247)	loss 7.891 (7.823)	prob 3.791 (3.685)	GS 34.438 (32.384)	mem 76.269
Train: [32][1410/1500]	BT 0.064 (0.289)	DT 0.005 (0.252)	loss 7.648 (7.783)	prob 3.556 (3.487)	GS 31.297 (32.380)	mem 76.270
Train: [32][1420/1500]	BT 0.064 (0.287)	DT 0.005 (0.250)	loss 7.839 (7.797)	prob 3.431 (3.424)	GS 36.188 (32.675)	mem 76.270
Train: [32][1430/1500]	BT 0.037 (0.289)	DT 0.000 (0.252)	loss 7.923 (7.812)	prob 4.306 (3.476)	GS 30.797 (32.442)	mem 76.271
Train: [32][1440/1500]	BT 0.037 (0.288)	DT 0.001 (0.250)	loss 8.009 (7.801)	prob 3.525 (3.511)	GS 35.969 (32.418)	mem 76.271
Train: [32][1450/1500]	BT 0.025 (0.288)	DT 0.000 (0.251)	loss 8.005 (7.780)	prob 4.466 (3.559)	GS 33.500 (32.733)	mem 75.985
Train: [32][1460/1500]	BT 0.033 (0.287)	DT 0.000 (0.250)	loss 7.736 (7.840)	prob 4.271 (3.947)	GS 32.422 (31.377)	mem 75.768
Train: [32][1470/1500]	BT 0.039 (0.286)	DT 0.001 (0.248)	loss 7.970 (7.765)	prob 4.700 (3.937)	GS 33.719 (31.967)	mem 63.929
Train: [32][1480/1500]	BT 0.034 (0.287)	DT 0.000 (0.249)	loss 8.144 (7.789)	prob 3.877 (3.864)	GS 34.703 (32.543)	mem 14.000
Train: [32][1490/1500]	BT 0.043 (0.285)	DT 0.000 (0.248)	loss 7.187 (7.779)	prob 3.965 (3.818)	GS 29.125 (32.540)	mem 13.929
Train: [32][1500/1500]	BT 0.035 (0.284)	DT 0.000 (0.247)	loss 7.707 (7.748)	prob 3.568 (3.871)	GS 32.719 (32.365)	mem 11.145
Train: [32][1510/1500]	BT 0.033 (0.282)	DT 0.000 (0.245)	loss 7.210 (7.574)	prob 3.455 (3.903)	GS 37.438 (33.591)	mem 11.145
epoch 32, total time 426.09
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [33][1/1500]	BT 22.289 (22.289)	DT 22.213 (22.213)	loss 7.270 (7.270)	prob 3.874 (3.874)	GS 32.250 (32.250)	mem 74.844
Train: [33][10/1500]	BT 0.082 (2.817)	DT 0.007 (2.753)	loss 7.456 (7.493)	prob 3.776 (3.527)	GS 29.156 (32.087)	mem 74.889
Train: [33][20/1500]	BT 0.046 (1.634)	DT 0.001 (1.573)	loss 7.612 (7.458)	prob 3.449 (3.636)	GS 36.594 (32.892)	mem 74.914
Train: [33][30/1500]	BT 0.028 (1.673)	DT 0.000 (1.621)	loss 7.467 (7.502)	prob 3.656 (3.612)	GS 30.344 (32.993)	mem 74.954
Train: [33][40/1500]	BT 0.026 (1.262)	DT 0.000 (1.216)	loss 7.538 (7.498)	prob 3.174 (3.545)	GS 33.266 (32.749)	mem 74.954
Train: [33][50/1500]	BT 0.036 (1.072)	DT 0.000 (1.029)	loss 7.888 (7.511)	prob 4.082 (3.574)	GS 30.516 (32.679)	mem 74.970
Train: [33][60/1500]	BT 0.032 (0.900)	DT 0.000 (0.858)	loss 7.775 (7.642)	prob 3.704 (3.520)	GS 33.516 (32.802)	mem 74.971
Train: [33][70/1500]	BT 5.525 (0.854)	DT 5.489 (0.814)	loss 8.131 (7.612)	prob 3.542 (3.544)	GS 33.000 (32.560)	mem 74.980
Train: [33][80/1500]	BT 0.023 (0.750)	DT 0.000 (0.712)	loss 7.714 (7.555)	prob 4.035 (3.636)	GS 33.844 (32.920)	mem 74.980
Train: [33][90/1500]	BT 0.037 (0.670)	DT 0.001 (0.633)	loss 7.402 (7.520)	prob 3.435 (3.693)	GS 32.203 (32.817)	mem 74.981
Train: [33][100/1500]	BT 0.039 (0.638)	DT 0.001 (0.600)	loss 7.713 (7.516)	prob 3.239 (3.676)	GS 33.797 (32.627)	mem 75.003
Train: [33][110/1500]	BT 0.051 (0.583)	DT 0.005 (0.546)	loss 7.381 (7.553)	prob 4.020 (3.964)	GS 34.547 (32.373)	mem 75.005
Train: [33][120/1500]	BT 0.039 (0.583)	DT 0.001 (0.546)	loss 7.657 (7.499)	prob 3.606 (3.841)	GS 30.844 (31.842)	mem 75.009
Train: [33][130/1500]	BT 0.039 (0.542)	DT 0.001 (0.504)	loss 7.752 (7.508)	prob 3.894 (3.722)	GS 36.703 (32.489)	mem 75.009
Train: [33][140/1500]	BT 0.039 (0.506)	DT 0.001 (0.468)	loss 7.636 (7.513)	prob 2.938 (3.727)	GS 33.891 (32.641)	mem 75.009
Train: [33][150/1500]	BT 0.047 (0.504)	DT 0.000 (0.466)	loss 7.491 (7.501)	prob 3.759 (3.656)	GS 34.000 (32.711)	mem 75.013
Train: [33][160/1500]	BT 0.039 (0.474)	DT 0.001 (0.437)	loss 7.543 (7.414)	prob 4.175 (3.608)	GS 35.000 (32.664)	mem 75.015
Train: [33][170/1500]	BT 0.036 (0.508)	DT 0.006 (0.470)	loss 7.418 (7.429)	prob 3.739 (3.586)	GS 35.828 (33.483)	mem 75.018
Train: [33][180/1500]	BT 0.041 (0.482)	DT 0.003 (0.444)	loss 7.118 (7.404)	prob 4.486 (3.612)	GS 36.984 (33.469)	mem 75.019
Train: [33][190/1500]	BT 1.650 (0.467)	DT 1.615 (0.429)	loss 7.266 (7.409)	prob 4.575 (3.664)	GS 36.500 (33.279)	mem 75.020
Train: [33][200/1500]	BT 0.038 (0.472)	DT 0.000 (0.434)	loss 7.132 (7.407)	prob 4.499 (3.722)	GS 32.719 (33.260)	mem 75.025
Train: [33][210/1500]	BT 0.066 (0.452)	DT 0.003 (0.414)	loss 7.256 (7.285)	prob 3.226 (3.837)	GS 38.688 (33.006)	mem 75.026
Train: [33][220/1500]	BT 0.031 (0.462)	DT 0.000 (0.424)	loss 7.268 (7.318)	prob 3.904 (3.790)	GS 32.891 (33.687)	mem 75.032
Train: [33][230/1500]	BT 0.064 (0.445)	DT 0.004 (0.406)	loss 7.058 (7.285)	prob 3.891 (3.819)	GS 34.812 (33.276)	mem 75.032
Train: [33][240/1500]	BT 0.068 (0.432)	DT 0.006 (0.392)	loss 7.369 (7.279)	prob 4.111 (3.832)	GS 36.297 (33.348)	mem 75.033
Train: [33][250/1500]	BT 0.037 (0.439)	DT 0.000 (0.400)	loss 7.610 (7.296)	prob 3.867 (3.832)	GS 33.656 (33.550)	mem 75.037
Train: [33][260/1500]	BT 0.037 (0.424)	DT 0.000 (0.384)	loss 7.398 (7.301)	prob 3.774 (3.751)	GS 37.484 (32.769)	mem 75.049
Train: [33][270/1500]	BT 0.037 (0.419)	DT 0.000 (0.379)	loss 7.019 (7.272)	prob 4.455 (3.901)	GS 32.438 (32.366)	mem 75.050
Train: [33][280/1500]	BT 0.040 (0.420)	DT 0.001 (0.381)	loss 7.299 (7.272)	prob 4.237 (3.901)	GS 36.250 (32.281)	mem 75.052
Train: [33][290/1500]	BT 0.058 (0.419)	DT 0.000 (0.380)	loss 7.300 (7.281)	prob 4.297 (3.879)	GS 35.703 (32.448)	mem 75.053
Train: [33][300/1500]	BT 0.039 (0.418)	DT 0.000 (0.378)	loss 7.535 (7.296)	prob 4.026 (3.811)	GS 38.562 (32.714)	mem 75.053
Train: [33][310/1500]	BT 0.028 (0.411)	DT 0.000 (0.371)	loss 7.768 (7.381)	prob 3.149 (3.422)	GS 36.922 (33.239)	mem 74.955
Train: [33][320/1500]	BT 0.037 (0.399)	DT 0.001 (0.360)	loss 7.372 (7.387)	prob 3.808 (3.624)	GS 35.391 (33.284)	mem 74.956
Train: [33][330/1500]	BT 0.036 (0.402)	DT 0.000 (0.362)	loss 7.573 (7.355)	prob 3.802 (3.733)	GS 34.734 (32.639)	mem 74.954
Train: [33][340/1500]	BT 0.029 (0.395)	DT 0.000 (0.356)	loss 7.175 (7.338)	prob 4.078 (3.667)	GS 36.266 (32.396)	mem 74.954
Train: [33][350/1500]	BT 0.037 (0.391)	DT 0.000 (0.352)	loss 7.692 (7.335)	prob 3.626 (3.669)	GS 29.984 (32.443)	mem 74.955
Train: [33][360/1500]	BT 0.036 (0.381)	DT 0.001 (0.342)	loss 7.335 (7.394)	prob 3.446 (3.714)	GS 31.750 (32.030)	mem 74.954
Train: [33][370/1500]	BT 0.031 (0.384)	DT 0.000 (0.345)	loss 7.461 (7.344)	prob 3.181 (3.556)	GS 34.344 (31.462)	mem 74.956
Train: [33][380/1500]	BT 0.090 (0.383)	DT 0.011 (0.343)	loss 7.613 (7.356)	prob 3.671 (3.539)	GS 34.344 (31.655)	mem 74.960
Train: [33][390/1500]	BT 0.038 (0.386)	DT 0.001 (0.346)	loss 7.196 (7.356)	prob 3.405 (3.440)	GS 33.688 (31.981)	mem 74.962
Train: [33][400/1500]	BT 0.037 (0.380)	DT 0.001 (0.339)	loss 7.642 (7.350)	prob 3.617 (3.417)	GS 34.516 (32.071)	mem 74.977
Train: [33][410/1500]	BT 0.060 (0.393)	DT 0.002 (0.352)	loss 6.949 (7.320)	prob 3.782 (3.425)	GS 30.797 (32.886)	mem 74.966
Train: [33][420/1500]	BT 0.051 (0.392)	DT 0.001 (0.351)	loss 7.078 (7.319)	prob 3.552 (3.305)	GS 32.828 (33.304)	mem 74.966
Train: [33][430/1500]	BT 0.029 (0.403)	DT 0.000 (0.363)	loss 7.298 (7.362)	prob 3.118 (3.225)	GS 31.719 (33.958)	mem 74.965
Train: [33][440/1500]	BT 0.036 (0.394)	DT 0.001 (0.354)	loss 7.443 (7.351)	prob 3.211 (3.208)	GS 33.062 (33.765)	mem 74.966
Train: [33][450/1500]	BT 0.060 (0.394)	DT 0.014 (0.353)	loss 7.480 (7.357)	prob 3.301 (3.128)	GS 34.234 (33.310)	mem 74.969
Train: [33][460/1500]	BT 0.041 (0.386)	DT 0.006 (0.346)	loss 7.176 (7.439)	prob 3.475 (2.722)	GS 34.844 (32.938)	mem 74.970
Train: [33][470/1500]	BT 0.027 (0.386)	DT 0.000 (0.346)	loss 7.452 (7.320)	prob 2.480 (2.705)	GS 34.812 (32.351)	mem 74.972
Train: [33][480/1500]	BT 0.037 (0.379)	DT 0.001 (0.339)	loss 7.249 (7.357)	prob 2.883 (2.480)	GS 29.734 (32.015)	mem 74.974
Train: [33][490/1500]	BT 0.038 (0.373)	DT 0.001 (0.334)	loss 7.067 (7.397)	prob 2.776 (2.475)	GS 32.359 (32.201)	mem 74.974
Train: [33][500/1500]	BT 0.038 (0.373)	DT 0.001 (0.334)	loss 7.783 (7.420)	prob 2.482 (2.385)	GS 30.516 (32.055)	mem 74.975
Train: [33][510/1500]	BT 0.039 (0.369)	DT 0.001 (0.330)	loss 7.620 (7.547)	prob 2.113 (1.917)	GS 33.938 (32.436)	mem 74.975
Train: [33][520/1500]	BT 0.055 (0.370)	DT 0.001 (0.330)	loss 7.699 (7.574)	prob 2.292 (1.950)	GS 37.547 (32.772)	mem 74.976
Train: [33][530/1500]	BT 0.050 (0.364)	DT 0.016 (0.324)	loss 7.526 (7.633)	prob 2.839 (1.962)	GS 31.672 (32.865)	mem 74.978
Train: [33][540/1500]	BT 0.060 (0.366)	DT 0.003 (0.326)	loss 7.378 (7.638)	prob 2.229 (2.006)	GS 31.562 (32.760)	mem 74.979
Train: [33][550/1500]	BT 0.030 (0.373)	DT 0.000 (0.333)	loss 7.423 (7.706)	prob 2.923 (1.949)	GS 27.797 (32.829)	mem 74.975
Train: [33][560/1500]	BT 0.027 (0.367)	DT 0.000 (0.327)	loss 8.177 (7.823)	prob 1.073 (1.680)	GS 38.516 (33.978)	mem 74.976
Train: [33][570/1500]	BT 0.031 (0.365)	DT 0.000 (0.326)	loss 8.014 (7.798)	prob 2.735 (1.765)	GS 32.203 (33.031)	mem 74.978
Train: [33][580/1500]	BT 0.070 (0.360)	DT 0.016 (0.321)	loss 7.741 (7.756)	prob 1.101 (1.872)	GS 35.578 (32.926)	mem 74.981
Train: [33][590/1500]	BT 0.096 (0.366)	DT 0.006 (0.327)	loss 8.062 (7.776)	prob 3.264 (2.001)	GS 34.234 (32.657)	mem 75.028
Train: [33][600/1500]	BT 0.081 (0.362)	DT 0.005 (0.321)	loss 8.001 (7.753)	prob 2.943 (2.125)	GS 31.891 (32.798)	mem 75.029
Train: [33][610/1500]	BT 0.039 (0.360)	DT 0.001 (0.320)	loss 7.721 (7.845)	prob 2.289 (2.611)	GS 31.797 (33.642)	mem 75.078
Train: [33][620/1500]	BT 0.039 (0.361)	DT 0.001 (0.320)	loss 7.692 (7.926)	prob 2.463 (2.362)	GS 36.641 (33.165)	mem 75.386
Train: [33][630/1500]	BT 0.035 (0.355)	DT 0.000 (0.315)	loss 8.234 (7.974)	prob 2.336 (2.350)	GS 32.125 (32.819)	mem 75.390
Train: [33][640/1500]	BT 0.035 (0.358)	DT 0.000 (0.317)	loss 8.076 (7.975)	prob 3.114 (2.339)	GS 34.672 (32.953)	mem 76.125
Train: [33][650/1500]	BT 0.037 (0.353)	DT 0.000 (0.313)	loss 8.581 (7.984)	prob 3.353 (2.465)	GS 34.859 (32.566)	mem 76.125
Train: [33][660/1500]	BT 0.037 (0.348)	DT 0.001 (0.308)	loss 8.340 (7.824)	prob 2.667 (2.845)	GS 32.562 (32.316)	mem 76.125
Train: [33][670/1500]	BT 0.031 (0.349)	DT 0.000 (0.309)	loss 7.893 (7.875)	prob 2.648 (2.600)	GS 32.484 (32.720)	mem 76.177
Train: [33][680/1500]	BT 0.076 (0.345)	DT 0.004 (0.304)	loss 8.859 (7.883)	prob 2.700 (2.751)	GS 37.672 (32.770)	mem 76.179
Train: [33][690/1500]	BT 0.120 (0.360)	DT 0.060 (0.319)	loss 8.413 (7.896)	prob 3.644 (2.814)	GS 36.562 (32.545)	mem 76.181
Train: [33][700/1500]	BT 0.086 (0.363)	DT 0.005 (0.322)	loss 8.174 (7.887)	prob 3.233 (2.827)	GS 30.719 (32.562)	mem 76.183
Train: [33][710/1500]	BT 0.048 (0.359)	DT 0.006 (0.318)	loss 8.376 (7.808)	prob 3.870 (3.364)	GS 35.453 (32.023)	mem 76.184
Train: [33][720/1500]	BT 0.056 (0.363)	DT 0.008 (0.322)	loss 8.769 (7.876)	prob 2.397 (3.297)	GS 37.969 (32.135)	mem 76.187
Train: [33][730/1500]	BT 0.056 (0.364)	DT 0.011 (0.323)	loss 7.830 (7.801)	prob 2.835 (3.245)	GS 31.328 (32.911)	mem 76.184
Train: [33][740/1500]	BT 0.036 (0.365)	DT 0.001 (0.324)	loss 7.882 (7.808)	prob 3.438 (3.256)	GS 31.094 (32.950)	mem 76.186
Train: [33][750/1500]	BT 0.037 (0.361)	DT 0.000 (0.320)	loss 8.352 (7.829)	prob 3.175 (3.174)	GS 34.766 (32.908)	mem 76.187
Train: [33][760/1500]	BT 0.039 (0.362)	DT 0.004 (0.321)	loss 7.976 (7.886)	prob 4.001 (3.236)	GS 34.000 (33.091)	mem 76.189
Train: [33][770/1500]	BT 0.037 (0.358)	DT 0.000 (0.317)	loss 7.762 (7.808)	prob 4.248 (3.454)	GS 31.328 (32.522)	mem 76.189
Train: [33][780/1500]	BT 0.038 (0.354)	DT 0.000 (0.313)	loss 7.767 (7.796)	prob 2.546 (3.343)	GS 32.344 (33.138)	mem 76.190
Train: [33][790/1500]	BT 0.029 (0.366)	DT 0.000 (0.325)	loss 7.733 (7.784)	prob 4.187 (3.394)	GS 34.984 (32.992)	mem 76.192
Train: [33][800/1500]	BT 0.030 (0.362)	DT 0.000 (0.321)	loss 7.229 (7.775)	prob 4.144 (3.396)	GS 34.766 (32.717)	mem 76.191
Train: [33][810/1500]	BT 0.025 (0.364)	DT 0.000 (0.324)	loss 8.386 (7.727)	prob 2.647 (3.463)	GS 32.641 (31.580)	mem 76.191
Train: [33][820/1500]	BT 0.037 (0.360)	DT 0.000 (0.320)	loss 7.640 (7.707)	prob 4.475 (3.559)	GS 31.781 (31.798)	mem 76.193
Train: [33][830/1500]	BT 0.047 (0.357)	DT 0.006 (0.316)	loss 7.546 (7.698)	prob 3.841 (3.575)	GS 35.047 (31.933)	mem 76.193
Train: [33][840/1500]	BT 0.037 (0.357)	DT 0.000 (0.317)	loss 8.183 (7.711)	prob 2.935 (3.564)	GS 33.938 (32.211)	mem 76.195
Train: [33][850/1500]	BT 0.037 (0.353)	DT 0.001 (0.313)	loss 7.966 (7.736)	prob 4.087 (3.543)	GS 34.875 (32.291)	mem 76.195
Train: [33][860/1500]	BT 0.069 (0.355)	DT 0.002 (0.314)	loss 7.801 (7.744)	prob 2.977 (3.430)	GS 39.250 (34.014)	mem 76.197
Train: [33][870/1500]	BT 0.036 (0.352)	DT 0.000 (0.312)	loss 8.621 (7.736)	prob 2.919 (3.393)	GS 35.938 (33.780)	mem 76.197
Train: [33][880/1500]	BT 0.034 (0.349)	DT 0.000 (0.308)	loss 7.363 (7.666)	prob 3.979 (3.468)	GS 30.891 (33.301)	mem 76.197
Train: [33][890/1500]	BT 0.037 (0.352)	DT 0.001 (0.312)	loss 7.521 (7.639)	prob 3.674 (3.578)	GS 34.406 (33.393)	mem 76.195
Train: [33][900/1500]	BT 0.037 (0.349)	DT 0.001 (0.308)	loss 7.671 (7.659)	prob 4.404 (3.640)	GS 33.438 (33.042)	mem 76.197
Train: [33][910/1500]	BT 0.038 (0.349)	DT 0.001 (0.308)	loss 7.762 (7.832)	prob 4.317 (3.561)	GS 33.922 (33.802)	mem 76.194
Train: [33][920/1500]	BT 0.038 (0.345)	DT 0.001 (0.305)	loss 7.729 (7.737)	prob 3.879 (3.542)	GS 33.484 (32.930)	mem 76.194
Train: [33][930/1500]	BT 0.038 (0.346)	DT 0.001 (0.305)	loss 7.737 (7.681)	prob 3.913 (3.723)	GS 35.984 (32.971)	mem 76.195
Train: [33][940/1500]	BT 0.038 (0.342)	DT 0.001 (0.302)	loss 8.233 (7.670)	prob 3.568 (3.801)	GS 32.219 (32.866)	mem 76.195
Train: [33][950/1500]	BT 0.050 (0.346)	DT 0.003 (0.305)	loss 7.608 (7.706)	prob 4.319 (3.784)	GS 32.312 (32.775)	mem 76.195
Train: [33][960/1500]	BT 0.031 (0.351)	DT 0.001 (0.310)	loss 7.336 (7.578)	prob 3.963 (4.069)	GS 30.703 (34.038)	mem 76.200
Train: [33][970/1500]	BT 0.026 (0.347)	DT 0.000 (0.307)	loss 7.391 (7.587)	prob 4.244 (3.970)	GS 31.250 (33.374)	mem 76.200
Train: [33][980/1500]	BT 0.027 (0.344)	DT 0.000 (0.304)	loss 7.566 (7.557)	prob 4.071 (3.979)	GS 32.969 (32.821)	mem 76.200
Train: [33][990/1500]	BT 0.031 (0.345)	DT 0.000 (0.305)	loss 8.394 (7.577)	prob 3.569 (3.997)	GS 38.922 (32.673)	mem 76.202
Train: [33][1000/1500]	BT 0.027 (0.342)	DT 0.001 (0.302)	loss 7.669 (7.556)	prob 3.670 (3.976)	GS 33.016 (32.757)	mem 76.202
Train: [33][1010/1500]	BT 0.041 (0.342)	DT 0.000 (0.302)	loss 7.628 (7.410)	prob 3.732 (3.778)	GS 32.562 (32.358)	mem 76.205
Train: [33][1020/1500]	BT 0.067 (0.339)	DT 0.007 (0.299)	loss 7.745 (7.476)	prob 4.339 (3.834)	GS 30.578 (31.841)	mem 76.205
Train: [33][1030/1500]	BT 0.058 (0.338)	DT 0.011 (0.298)	loss 7.363 (7.458)	prob 4.121 (3.792)	GS 34.094 (31.834)	mem 76.207
Train: [33][1040/1500]	BT 0.058 (0.340)	DT 0.011 (0.300)	loss 7.328 (7.436)	prob 4.438 (3.852)	GS 34.156 (32.105)	mem 76.206
Train: [33][1050/1500]	BT 0.037 (0.343)	DT 0.001 (0.304)	loss 7.510 (7.438)	prob 3.100 (3.853)	GS 35.250 (32.394)	mem 76.235
Train: [33][1060/1500]	BT 0.025 (0.343)	DT 0.000 (0.303)	loss 7.395 (7.353)	prob 4.129 (3.908)	GS 31.766 (33.803)	mem 76.236
Train: [33][1070/1500]	BT 0.039 (0.342)	DT 0.001 (0.303)	loss 7.182 (7.347)	prob 4.545 (3.831)	GS 32.203 (33.056)	mem 76.239
Train: [33][1080/1500]	BT 0.038 (0.341)	DT 0.001 (0.301)	loss 7.590 (7.407)	prob 3.520 (3.751)	GS 36.938 (33.396)	mem 76.237
Train: [33][1090/1500]	BT 0.039 (0.338)	DT 0.001 (0.298)	loss 7.650 (7.388)	prob 4.124 (3.744)	GS 31.344 (33.173)	mem 76.238
Train: [33][1100/1500]	BT 0.037 (0.338)	DT 0.001 (0.299)	loss 7.636 (7.392)	prob 4.545 (3.853)	GS 32.828 (32.907)	mem 76.236
Train: [33][1110/1500]	BT 0.028 (0.338)	DT 0.000 (0.299)	loss 7.211 (7.299)	prob 4.242 (4.243)	GS 35.750 (33.730)	mem 76.238
Train: [33][1120/1500]	BT 0.039 (0.336)	DT 0.001 (0.297)	loss 6.823 (7.291)	prob 4.308 (4.074)	GS 35.344 (33.816)	mem 76.238
Train: [33][1130/1500]	BT 0.027 (0.337)	DT 0.000 (0.298)	loss 7.350 (7.271)	prob 3.134 (3.906)	GS 33.031 (33.583)	mem 76.239
Train: [33][1140/1500]	BT 0.036 (0.334)	DT 0.000 (0.295)	loss 7.420 (7.286)	prob 4.251 (3.989)	GS 30.406 (33.204)	mem 76.239
Train: [33][1150/1500]	BT 0.030 (0.332)	DT 0.000 (0.292)	loss 7.358 (7.298)	prob 4.062 (3.958)	GS 34.125 (33.055)	mem 76.239
Train: [33][1160/1500]	BT 0.033 (0.332)	DT 0.000 (0.293)	loss 7.372 (7.336)	prob 3.936 (4.195)	GS 32.500 (31.425)	mem 76.240
Train: [33][1170/1500]	BT 0.052 (0.330)	DT 0.005 (0.290)	loss 7.494 (7.347)	prob 4.130 (3.932)	GS 33.781 (31.945)	mem 76.240
Train: [33][1180/1500]	BT 0.059 (0.335)	DT 0.005 (0.295)	loss 7.334 (7.347)	prob 4.615 (3.833)	GS 35.688 (32.125)	mem 76.243
Train: [33][1190/1500]	BT 0.027 (0.345)	DT 0.000 (0.306)	loss 7.690 (7.342)	prob 3.300 (3.852)	GS 30.406 (32.617)	mem 76.241
Train: [33][1200/1500]	BT 0.030 (0.342)	DT 0.000 (0.303)	loss 7.314 (7.358)	prob 3.558 (3.806)	GS 33.281 (32.513)	mem 76.242
Train: [33][1210/1500]	BT 4.073 (0.343)	DT 4.047 (0.304)	loss 6.951 (7.264)	prob 4.577 (4.063)	GS 34.703 (32.745)	mem 76.242
Train: [33][1220/1500]	BT 0.028 (0.341)	DT 0.000 (0.301)	loss 7.432 (7.315)	prob 3.772 (3.847)	GS 36.578 (33.166)	mem 76.243
Train: [33][1230/1500]	BT 0.039 (0.338)	DT 0.001 (0.299)	loss 7.298 (7.335)	prob 4.106 (3.699)	GS 31.828 (33.048)	mem 76.244
Train: [33][1240/1500]	BT 0.026 (0.338)	DT 0.001 (0.299)	loss 7.214 (7.334)	prob 3.882 (3.647)	GS 34.609 (33.238)	mem 76.243
Train: [33][1250/1500]	BT 0.028 (0.336)	DT 0.000 (0.297)	loss 7.612 (7.332)	prob 3.458 (3.617)	GS 32.016 (33.074)	mem 76.243
Train: [33][1260/1500]	BT 0.037 (0.336)	DT 0.001 (0.297)	loss 7.337 (7.345)	prob 3.824 (3.204)	GS 34.828 (32.022)	mem 76.253
Train: [33][1270/1500]	BT 0.038 (0.333)	DT 0.000 (0.294)	loss 7.910 (7.354)	prob 3.085 (3.193)	GS 33.641 (31.486)	mem 76.252
Train: [33][1280/1500]	BT 0.037 (0.331)	DT 0.001 (0.292)	loss 7.480 (7.321)	prob 3.190 (3.269)	GS 31.578 (31.874)	mem 76.253
Train: [33][1290/1500]	BT 0.038 (0.332)	DT 0.000 (0.293)	loss 7.638 (7.321)	prob 3.069 (3.268)	GS 33.000 (32.222)	mem 76.261
Train: [33][1300/1500]	BT 0.048 (0.332)	DT 0.000 (0.293)	loss 7.533 (7.309)	prob 3.484 (3.258)	GS 35.984 (32.428)	mem 76.262
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [33][1310/1500]	BT 3.721 (0.333)	DT 3.684 (0.294)	loss 7.003 (7.239)	prob 3.596 (3.179)	GS 34.266 (31.519)	mem 76.281
Train: [33][1320/1500]	BT 0.028 (0.331)	DT 0.000 (0.292)	loss 7.326 (7.272)	prob 3.458 (3.275)	GS 32.203 (31.553)	mem 76.163
Train: [33][1330/1500]	BT 1.110 (0.330)	DT 1.073 (0.291)	loss 7.401 (7.282)	prob 3.255 (3.180)	GS 33.250 (32.026)	mem 76.162
Train: [33][1340/1500]	BT 0.038 (0.329)	DT 0.000 (0.290)	loss 6.992 (7.274)	prob 4.257 (3.159)	GS 31.656 (32.106)	mem 76.162
Train: [33][1350/1500]	BT 0.037 (0.328)	DT 0.001 (0.289)	loss 7.565 (7.266)	prob 3.447 (3.179)	GS 37.891 (32.415)	mem 76.163
Train: [33][1360/1500]	BT 0.038 (0.327)	DT 0.001 (0.288)	loss 7.398 (7.194)	prob 2.731 (3.098)	GS 36.109 (32.883)	mem 76.164
Train: [33][1370/1500]	BT 0.070 (0.326)	DT 0.002 (0.287)	loss 7.111 (7.182)	prob 4.023 (3.007)	GS 34.047 (32.759)	mem 76.164
Train: [33][1380/1500]	BT 0.037 (0.325)	DT 0.001 (0.286)	loss 7.063 (7.214)	prob 2.971 (2.971)	GS 34.297 (32.510)	mem 76.163
Train: [33][1390/1500]	BT 0.038 (0.325)	DT 0.001 (0.286)	loss 6.971 (7.198)	prob 2.697 (2.947)	GS 32.719 (32.526)	mem 76.163
Train: [33][1400/1500]	BT 0.487 (0.323)	DT 0.449 (0.284)	loss 6.972 (7.185)	prob 3.586 (2.945)	GS 34.281 (32.653)	mem 76.163
Train: [33][1410/1500]	BT 0.069 (0.322)	DT 0.011 (0.283)	loss 7.208 (7.235)	prob 2.783 (2.758)	GS 35.359 (33.595)	mem 76.166
Train: [33][1420/1500]	BT 0.038 (0.323)	DT 0.001 (0.284)	loss 7.083 (7.167)	prob 2.658 (2.803)	GS 33.688 (33.602)	mem 76.165
Train: [33][1430/1500]	BT 0.416 (0.322)	DT 0.378 (0.283)	loss 7.042 (7.155)	prob 2.593 (2.769)	GS 34.625 (33.433)	mem 76.184
Train: [33][1440/1500]	BT 0.038 (0.321)	DT 0.001 (0.282)	loss 7.208 (7.163)	prob 3.278 (2.840)	GS 30.984 (33.324)	mem 76.184
Train: [33][1450/1500]	BT 0.066 (0.322)	DT 0.016 (0.283)	loss 7.247 (7.167)	prob 2.921 (2.859)	GS 33.500 (33.194)	mem 76.185
Train: [33][1460/1500]	BT 0.063 (0.321)	DT 0.014 (0.281)	loss 7.145 (7.094)	prob 2.903 (2.875)	GS 36.438 (32.309)	mem 76.026
Train: [33][1470/1500]	BT 0.034 (0.320)	DT 0.001 (0.281)	loss 7.106 (7.127)	prob 3.250 (2.664)	GS 33.312 (32.045)	mem 58.890
Train: [33][1480/1500]	BT 0.027 (0.319)	DT 0.000 (0.280)	loss 6.939 (7.104)	prob 3.351 (2.748)	GS 30.391 (31.434)	mem 30.919
Train: [33][1490/1500]	BT 0.030 (0.317)	DT 0.000 (0.278)	loss 6.871 (7.078)	prob 2.807 (2.776)	GS 39.438 (31.603)	mem 30.733
Train: [33][1500/1500]	BT 0.029 (0.316)	DT 0.000 (0.277)	loss 7.415 (7.069)	prob 2.675 (2.755)	GS 33.281 (31.635)	mem 11.140
Train: [33][1510/1500]	BT 0.031 (0.314)	DT 0.000 (0.275)	loss 7.010 (6.840)	prob 2.714 (2.585)	GS 28.344 (32.531)	mem 11.140
epoch 33, total time 474.18
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [34][1/1500]	BT 22.209 (22.209)	DT 22.150 (22.150)	loss 6.562 (6.562)	prob 2.769 (2.769)	GS 28.375 (28.375)	mem 74.778
Train: [34][10/1500]	BT 0.038 (2.307)	DT 0.001 (2.266)	loss 6.860 (6.714)	prob 2.657 (2.545)	GS 29.672 (32.507)	mem 74.792
Train: [34][20/1500]	BT 0.038 (1.172)	DT 0.001 (1.133)	loss 6.737 (6.774)	prob 2.772 (2.715)	GS 32.734 (32.114)	mem 74.792
Train: [34][30/1500]	BT 0.064 (0.936)	DT 0.004 (0.895)	loss 6.496 (6.763)	prob 3.143 (2.829)	GS 28.688 (31.766)	mem 74.849
Train: [34][40/1500]	BT 0.037 (0.774)	DT 0.000 (0.734)	loss 6.814 (6.816)	prob 3.167 (2.846)	GS 35.172 (31.903)	mem 74.876
Train: [34][50/1500]	BT 0.037 (0.654)	DT 0.001 (0.615)	loss 6.924 (6.843)	prob 3.540 (2.793)	GS 30.594 (32.113)	mem 74.885
Train: [34][60/1500]	BT 0.038 (0.588)	DT 0.001 (0.549)	loss 6.920 (6.914)	prob 2.994 (2.517)	GS 33.719 (33.334)	mem 74.897
Train: [34][70/1500]	BT 0.038 (0.509)	DT 0.000 (0.471)	loss 7.006 (6.927)	prob 2.644 (2.570)	GS 30.422 (32.145)	mem 74.898
Train: [34][80/1500]	BT 0.037 (0.486)	DT 0.000 (0.448)	loss 6.943 (6.939)	prob 2.633 (2.513)	GS 36.953 (32.559)	mem 74.911
Train: [34][90/1500]	BT 0.038 (0.436)	DT 0.001 (0.398)	loss 7.127 (6.948)	prob 2.828 (2.472)	GS 35.516 (32.514)	mem 74.924
Train: [34][100/1500]	BT 0.036 (0.444)	DT 0.000 (0.406)	loss 7.090 (6.949)	prob 2.019 (2.497)	GS 32.109 (32.424)	mem 74.945
Train: [34][110/1500]	BT 0.033 (0.406)	DT 0.000 (0.369)	loss 7.067 (6.961)	prob 2.618 (2.379)	GS 34.766 (32.337)	mem 74.949
Train: [34][120/1500]	BT 0.037 (0.376)	DT 0.000 (0.339)	loss 6.769 (6.942)	prob 2.654 (2.534)	GS 31.812 (31.684)	mem 74.950
Train: [34][130/1500]	BT 0.059 (0.384)	DT 0.002 (0.347)	loss 6.963 (6.971)	prob 2.324 (2.539)	GS 32.000 (32.327)	mem 74.954
Train: [34][140/1500]	BT 0.037 (0.360)	DT 0.001 (0.322)	loss 6.889 (6.960)	prob 2.804 (2.537)	GS 30.406 (32.101)	mem 74.958
Train: [34][150/1500]	BT 0.038 (0.370)	DT 0.000 (0.332)	loss 6.825 (6.947)	prob 2.561 (2.509)	GS 37.250 (32.336)	mem 74.965
Train: [34][160/1500]	BT 0.067 (0.350)	DT 0.013 (0.312)	loss 6.968 (6.905)	prob 2.088 (2.542)	GS 34.781 (32.491)	mem 74.964
Train: [34][170/1500]	BT 0.029 (0.395)	DT 0.000 (0.356)	loss 7.045 (6.941)	prob 2.642 (2.702)	GS 34.906 (33.313)	mem 74.972
Train: [34][180/1500]	BT 0.025 (0.374)	DT 0.000 (0.337)	loss 7.078 (6.948)	prob 2.906 (2.798)	GS 31.781 (32.961)	mem 74.971
Train: [34][190/1500]	BT 0.030 (0.380)	DT 0.000 (0.343)	loss 6.764 (6.942)	prob 2.891 (2.808)	GS 37.859 (32.880)	mem 74.974
Train: [34][200/1500]	BT 0.030 (0.363)	DT 0.000 (0.326)	loss 6.939 (6.940)	prob 2.380 (2.758)	GS 38.312 (32.913)	mem 74.977
Train: [34][210/1500]	BT 0.038 (0.347)	DT 0.000 (0.310)	loss 6.898 (6.887)	prob 2.778 (2.552)	GS 38.000 (34.008)	mem 74.977
Train: [34][220/1500]	BT 0.029 (0.345)	DT 0.000 (0.309)	loss 6.916 (6.933)	prob 2.878 (2.474)	GS 35.922 (33.755)	mem 74.982
Train: [34][230/1500]	BT 0.037 (0.332)	DT 0.001 (0.296)	loss 6.853 (6.951)	prob 2.879 (2.539)	GS 33.375 (33.570)	mem 74.984
Train: [34][240/1500]	BT 0.028 (0.360)	DT 0.000 (0.324)	loss 7.043 (6.944)	prob 2.879 (2.569)	GS 33.188 (33.483)	mem 74.987
Train: [34][250/1500]	BT 0.037 (0.347)	DT 0.000 (0.311)	loss 6.896 (6.937)	prob 2.238 (2.519)	GS 33.859 (33.351)	mem 74.987
Train: [34][260/1500]	BT 0.036 (0.346)	DT 0.001 (0.310)	loss 7.003 (7.020)	prob 2.001 (1.913)	GS 30.109 (33.586)	mem 74.988
Train: [34][270/1500]	BT 0.037 (0.334)	DT 0.001 (0.298)	loss 7.116 (6.981)	prob 2.239 (2.087)	GS 35.219 (33.381)	mem 74.988
Train: [34][280/1500]	BT 0.037 (0.324)	DT 0.000 (0.288)	loss 7.139 (6.946)	prob 2.485 (2.166)	GS 34.469 (33.213)	mem 74.988
Train: [34][290/1500]	BT 0.028 (0.332)	DT 0.000 (0.296)	loss 6.710 (6.946)	prob 2.544 (2.170)	GS 34.203 (32.722)	mem 74.995
Train: [34][300/1500]	BT 0.037 (0.322)	DT 0.001 (0.286)	loss 7.456 (6.975)	prob 1.608 (2.076)	GS 32.797 (32.847)	mem 74.995
Train: [34][310/1500]	BT 0.037 (0.326)	DT 0.000 (0.290)	loss 7.200 (7.006)	prob 1.958 (1.893)	GS 33.578 (31.591)	mem 74.993
Train: [34][320/1500]	BT 0.037 (0.317)	DT 0.001 (0.281)	loss 6.794 (7.059)	prob 3.081 (2.133)	GS 31.438 (32.339)	mem 74.993
Train: [34][330/1500]	BT 0.037 (0.322)	DT 0.000 (0.286)	loss 6.802 (7.056)	prob 2.523 (2.047)	GS 33.781 (32.484)	mem 74.997
Train: [34][340/1500]	BT 0.038 (0.314)	DT 0.001 (0.278)	loss 7.219 (7.081)	prob 1.657 (2.027)	GS 33.141 (32.421)	mem 74.998
Train: [34][350/1500]	BT 0.034 (0.306)	DT 0.000 (0.270)	loss 7.319 (7.072)	prob 0.959 (2.022)	GS 31.375 (32.357)	mem 74.999
Train: [34][360/1500]	BT 0.028 (0.311)	DT 0.000 (0.275)	loss 7.660 (7.194)	prob 2.539 (2.195)	GS 29.688 (31.480)	mem 75.029
Train: [34][370/1500]	BT 0.040 (0.303)	DT 0.001 (0.268)	loss 7.138 (7.277)	prob 1.732 (2.198)	GS 35.891 (32.024)	mem 75.031
Train: [34][380/1500]	BT 0.026 (0.307)	DT 0.000 (0.271)	loss 7.445 (7.294)	prob 2.477 (2.079)	GS 34.125 (32.135)	mem 75.036
Train: [34][390/1500]	BT 0.039 (0.300)	DT 0.001 (0.264)	loss 7.633 (7.335)	prob 2.232 (1.971)	GS 30.922 (32.334)	mem 75.036
Train: [34][400/1500]	BT 0.039 (0.293)	DT 0.001 (0.257)	loss 7.165 (7.358)	prob 1.749 (1.930)	GS 34.031 (32.517)	mem 75.037
Train: [34][410/1500]	BT 0.039 (0.296)	DT 0.001 (0.261)	loss 8.429 (7.519)	prob 1.311 (1.657)	GS 33.375 (33.388)	mem 75.036
Train: [34][420/1500]	BT 0.036 (0.290)	DT 0.001 (0.254)	loss 7.876 (7.528)	prob 1.878 (1.896)	GS 30.469 (33.213)	mem 75.037
Train: [34][430/1500]	BT 0.039 (0.291)	DT 0.001 (0.255)	loss 7.566 (7.504)	prob 1.651 (1.891)	GS 30.812 (32.764)	mem 75.039
Train: [34][440/1500]	BT 0.038 (0.289)	DT 0.000 (0.253)	loss 7.387 (7.481)	prob 1.408 (1.789)	GS 36.859 (32.752)	mem 75.039
Train: [34][450/1500]	BT 0.039 (0.287)	DT 0.000 (0.250)	loss 7.439 (7.502)	prob 2.802 (1.819)	GS 32.188 (32.952)	mem 75.041
Train: [34][460/1500]	BT 0.039 (0.285)	DT 0.001 (0.249)	loss 7.329 (7.805)	prob 2.617 (2.043)	GS 35.734 (34.230)	mem 75.040
Train: [34][470/1500]	BT 0.039 (0.285)	DT 0.001 (0.249)	loss 8.090 (7.767)	prob 2.484 (2.133)	GS 33.609 (32.698)	mem 75.041
Train: [34][480/1500]	BT 0.039 (0.292)	DT 0.000 (0.256)	loss 7.780 (7.653)	prob 2.565 (2.292)	GS 35.609 (32.635)	mem 75.042
Train: [34][490/1500]	BT 0.027 (0.307)	DT 0.000 (0.271)	loss 7.546 (7.632)	prob 3.018 (2.343)	GS 36.312 (32.546)	mem 75.044
Train: [34][500/1500]	BT 0.041 (0.302)	DT 0.000 (0.266)	loss 8.049 (7.639)	prob 2.710 (2.327)	GS 34.328 (32.412)	mem 75.044
Train: [34][510/1500]	BT 0.038 (0.297)	DT 0.001 (0.261)	loss 7.571 (7.695)	prob 3.177 (2.614)	GS 34.016 (32.830)	mem 75.046
Train: [34][520/1500]	BT 0.038 (0.299)	DT 0.001 (0.263)	loss 7.583 (7.678)	prob 3.128 (2.479)	GS 34.453 (32.859)	mem 75.045
Train: [34][530/1500]	BT 0.040 (0.294)	DT 0.001 (0.258)	loss 8.467 (7.663)	prob 2.713 (2.629)	GS 31.438 (32.862)	mem 75.046
Train: [34][540/1500]	BT 0.031 (0.303)	DT 0.000 (0.267)	loss 7.448 (7.636)	prob 3.752 (2.773)	GS 32.766 (32.635)	mem 75.049
Train: [34][550/1500]	BT 0.093 (0.299)	DT 0.001 (0.262)	loss 7.410 (7.669)	prob 3.145 (2.811)	GS 33.859 (32.515)	mem 75.050
Train: [34][560/1500]	BT 0.092 (0.313)	DT 0.006 (0.275)	loss 7.435 (7.522)	prob 2.395 (2.893)	GS 33.281 (32.511)	mem 75.052
Train: [34][570/1500]	BT 0.077 (0.309)	DT 0.001 (0.271)	loss 7.520 (7.581)	prob 2.997 (2.852)	GS 34.922 (32.634)	mem 75.052
Train: [34][580/1500]	BT 0.064 (0.311)	DT 0.004 (0.273)	loss 7.290 (7.617)	prob 3.559 (2.801)	GS 30.922 (32.968)	mem 75.050
Train: [34][590/1500]	BT 0.037 (0.327)	DT 0.000 (0.289)	loss 7.698 (7.642)	prob 2.903 (2.792)	GS 36.906 (33.269)	mem 75.049
Train: [34][600/1500]	BT 0.061 (0.322)	DT 0.016 (0.284)	loss 7.592 (7.670)	prob 3.906 (2.828)	GS 34.016 (33.030)	mem 75.050
Train: [34][610/1500]	BT 0.038 (0.327)	DT 0.000 (0.289)	loss 7.680 (7.648)	prob 3.228 (3.382)	GS 36.406 (33.658)	mem 75.055
Train: [34][620/1500]	BT 0.034 (0.322)	DT 0.000 (0.284)	loss 7.799 (7.689)	prob 3.605 (3.234)	GS 32.312 (33.516)	mem 75.057
Train: [34][630/1500]	BT 0.028 (0.324)	DT 0.000 (0.286)	loss 7.403 (7.635)	prob 3.292 (3.198)	GS 32.438 (33.517)	mem 75.071
Train: [34][640/1500]	BT 0.027 (0.320)	DT 0.000 (0.282)	loss 7.482 (7.584)	prob 3.643 (3.281)	GS 31.484 (33.197)	mem 75.070
Train: [34][650/1500]	BT 0.035 (0.315)	DT 0.001 (0.278)	loss 7.426 (7.549)	prob 3.946 (3.309)	GS 36.250 (33.087)	mem 75.070
Train: [34][660/1500]	BT 0.037 (0.319)	DT 0.000 (0.281)	loss 7.860 (7.575)	prob 2.993 (3.273)	GS 36.000 (32.855)	mem 75.007
Train: [34][670/1500]	BT 0.028 (0.314)	DT 0.000 (0.277)	loss 7.381 (7.499)	prob 2.996 (3.280)	GS 34.797 (32.970)	mem 75.068
Train: [34][680/1500]	BT 0.026 (0.325)	DT 0.000 (0.287)	loss 7.493 (7.483)	prob 3.331 (3.165)	GS 35.734 (32.955)	mem 75.409
Train: [34][690/1500]	BT 0.030 (0.321)	DT 0.000 (0.283)	loss 8.101 (7.514)	prob 3.446 (3.225)	GS 35.656 (32.854)	mem 75.410
Train: [34][700/1500]	BT 0.038 (0.316)	DT 0.000 (0.279)	loss 7.413 (7.501)	prob 3.398 (3.233)	GS 33.328 (32.665)	mem 75.437
Train: [34][710/1500]	BT 0.033 (0.317)	DT 0.000 (0.279)	loss 7.592 (7.548)	prob 3.294 (2.921)	GS 32.750 (31.359)	mem 75.896
Train: [34][720/1500]	BT 0.027 (0.313)	DT 0.000 (0.275)	loss 7.517 (7.493)	prob 3.090 (3.218)	GS 36.312 (31.287)	mem 75.898
Train: [34][730/1500]	BT 0.057 (0.320)	DT 0.011 (0.283)	loss 7.340 (7.462)	prob 3.360 (3.266)	GS 32.516 (31.457)	mem 76.144
Train: [34][740/1500]	BT 0.026 (0.329)	DT 0.001 (0.292)	loss 7.731 (7.483)	prob 3.307 (3.218)	GS 33.016 (31.891)	mem 76.149
Train: [34][750/1500]	BT 0.048 (0.326)	DT 0.007 (0.288)	loss 7.300 (7.458)	prob 3.935 (3.312)	GS 31.859 (31.989)	mem 76.150
Train: [34][760/1500]	BT 0.080 (0.322)	DT 0.006 (0.285)	loss 7.518 (7.303)	prob 2.394 (3.161)	GS 33.078 (32.136)	mem 76.150
Train: [34][770/1500]	BT 0.026 (0.324)	DT 0.000 (0.286)	loss 7.473 (7.348)	prob 3.650 (3.069)	GS 31.344 (32.546)	mem 76.153
Train: [34][780/1500]	BT 0.038 (0.320)	DT 0.001 (0.283)	loss 7.526 (7.397)	prob 3.604 (3.138)	GS 31.422 (32.567)	mem 76.154
Train: [34][790/1500]	BT 0.072 (0.322)	DT 0.001 (0.285)	loss 7.671 (7.393)	prob 3.171 (3.115)	GS 33.578 (32.423)	mem 76.155
Train: [34][800/1500]	BT 0.028 (0.319)	DT 0.000 (0.281)	loss 7.519 (7.402)	prob 3.125 (3.066)	GS 32.328 (32.627)	mem 76.155
Train: [34][810/1500]	BT 0.033 (0.322)	DT 0.001 (0.285)	loss 7.940 (7.388)	prob 2.767 (2.937)	GS 32.016 (32.552)	mem 76.156
Train: [34][820/1500]	BT 0.038 (0.318)	DT 0.000 (0.281)	loss 7.911 (7.398)	prob 2.754 (2.935)	GS 36.578 (32.626)	mem 76.157
Train: [34][830/1500]	BT 0.039 (0.315)	DT 0.001 (0.278)	loss 7.746 (7.395)	prob 3.190 (3.091)	GS 34.797 (32.417)	mem 76.156
Train: [34][840/1500]	BT 0.063 (0.317)	DT 0.002 (0.280)	loss 7.163 (7.375)	prob 3.205 (3.019)	GS 34.312 (32.573)	mem 76.157
Train: [34][850/1500]	BT 0.029 (0.322)	DT 0.000 (0.285)	loss 6.990 (7.369)	prob 4.225 (3.091)	GS 31.656 (32.603)	mem 76.157
Train: [34][860/1500]	BT 0.039 (0.319)	DT 0.001 (0.281)	loss 7.791 (7.431)	prob 3.201 (3.148)	GS 38.250 (33.655)	mem 76.160
Train: [34][870/1500]	BT 0.039 (0.316)	DT 0.001 (0.278)	loss 7.721 (7.375)	prob 2.799 (3.082)	GS 35.531 (33.735)	mem 76.160
Train: [34][880/1500]	BT 0.039 (0.316)	DT 0.001 (0.279)	loss 7.481 (7.336)	prob 3.040 (3.104)	GS 36.188 (33.864)	mem 76.160
Train: [34][890/1500]	BT 0.040 (0.315)	DT 0.001 (0.277)	loss 7.424 (7.338)	prob 3.629 (3.078)	GS 34.438 (33.470)	mem 76.160
Train: [34][900/1500]	BT 0.039 (0.314)	DT 0.001 (0.276)	loss 7.595 (7.322)	prob 3.101 (3.063)	GS 35.172 (33.283)	mem 76.161
Train: [34][910/1500]	BT 0.056 (0.314)	DT 0.007 (0.276)	loss 7.213 (7.312)	prob 3.880 (3.525)	GS 36.188 (33.523)	mem 76.179
Train: [34][920/1500]	BT 0.037 (0.311)	DT 0.001 (0.273)	loss 7.415 (7.318)	prob 4.352 (3.441)	GS 32.000 (32.770)	mem 76.180
Train: [34][930/1500]	BT 0.035 (0.315)	DT 0.000 (0.278)	loss 7.388 (7.271)	prob 2.907 (3.310)	GS 34.234 (32.506)	mem 76.181
Train: [34][940/1500]	BT 0.025 (0.312)	DT 0.000 (0.275)	loss 7.237 (7.281)	prob 3.514 (3.305)	GS 34.406 (32.335)	mem 76.183
Train: [34][950/1500]	BT 0.037 (0.309)	DT 0.001 (0.272)	loss 7.251 (7.272)	prob 3.357 (3.304)	GS 34.969 (32.370)	mem 76.185
Train: [34][960/1500]	BT 0.038 (0.310)	DT 0.000 (0.272)	loss 7.232 (7.283)	prob 3.878 (3.305)	GS 33.422 (31.484)	mem 76.186
Train: [34][970/1500]	BT 0.038 (0.307)	DT 0.001 (0.269)	loss 7.378 (7.271)	prob 3.377 (3.320)	GS 34.719 (31.738)	mem 76.186
Train: [34][980/1500]	BT 0.037 (0.307)	DT 0.001 (0.269)	loss 7.271 (7.261)	prob 3.454 (3.313)	GS 34.062 (32.366)	mem 76.186
Train: [34][990/1500]	BT 0.037 (0.304)	DT 0.001 (0.266)	loss 7.082 (7.248)	prob 3.898 (3.350)	GS 33.359 (32.659)	mem 76.186
Train: [34][1000/1500]	BT 0.037 (0.304)	DT 0.001 (0.267)	loss 7.055 (7.231)	prob 3.483 (3.318)	GS 35.391 (32.770)	mem 76.188
Train: [34][1010/1500]	BT 0.037 (0.303)	DT 0.001 (0.265)	loss 7.345 (7.239)	prob 4.028 (3.236)	GS 33.578 (32.217)	mem 76.189
Train: [34][1020/1500]	BT 0.037 (0.303)	DT 0.001 (0.266)	loss 7.087 (7.245)	prob 3.422 (3.400)	GS 34.594 (31.679)	mem 76.191
Train: [34][1030/1500]	BT 0.038 (0.301)	DT 0.000 (0.263)	loss 7.121 (7.237)	prob 3.898 (3.387)	GS 31.469 (31.573)	mem 76.191
Train: [34][1040/1500]	BT 0.037 (0.299)	DT 0.001 (0.261)	loss 7.939 (7.250)	prob 2.688 (3.384)	GS 35.125 (31.993)	mem 76.191
Train: [34][1050/1500]	BT 0.038 (0.298)	DT 0.001 (0.261)	loss 7.701 (7.256)	prob 2.755 (3.319)	GS 30.812 (32.096)	mem 76.194
Train: [34][1060/1500]	BT 0.037 (0.298)	DT 0.000 (0.261)	loss 7.266 (7.197)	prob 2.859 (3.263)	GS 33.312 (32.438)	mem 76.195
Train: [34][1070/1500]	BT 0.037 (0.298)	DT 0.001 (0.260)	loss 7.403 (7.191)	prob 3.422 (3.191)	GS 36.656 (32.291)	mem 76.193
Train: [34][1080/1500]	BT 0.037 (0.296)	DT 0.001 (0.258)	loss 7.033 (7.222)	prob 2.812 (3.044)	GS 34.750 (33.276)	mem 76.192
Train: [34][1090/1500]	BT 0.038 (0.296)	DT 0.000 (0.258)	loss 7.474 (7.232)	prob 3.066 (3.066)	GS 32.812 (32.817)	mem 76.195
Train: [34][1100/1500]	BT 0.037 (0.294)	DT 0.001 (0.256)	loss 6.966 (7.223)	prob 2.968 (3.106)	GS 34.250 (32.950)	mem 76.195
Train: [34][1110/1500]	BT 0.038 (0.293)	DT 0.001 (0.255)	loss 7.083 (7.269)	prob 3.547 (2.731)	GS 31.250 (32.791)	mem 76.196
Train: [34][1120/1500]	BT 0.038 (0.295)	DT 0.001 (0.258)	loss 7.491 (7.223)	prob 2.991 (3.062)	GS 38.266 (32.895)	mem 76.198
Train: [34][1130/1500]	BT 0.028 (0.296)	DT 0.000 (0.258)	loss 7.024 (7.172)	prob 2.987 (3.025)	GS 32.406 (33.018)	mem 76.200
Train: [34][1140/1500]	BT 2.032 (0.295)	DT 2.005 (0.257)	loss 7.067 (7.168)	prob 3.218 (2.950)	GS 35.656 (32.957)	mem 76.201
Train: [34][1150/1500]	BT 0.038 (0.294)	DT 0.001 (0.256)	loss 7.091 (7.158)	prob 3.348 (2.990)	GS 32.578 (32.869)	mem 76.200
Train: [34][1160/1500]	BT 0.066 (0.292)	DT 0.011 (0.254)	loss 7.306 (7.068)	prob 2.474 (2.959)	GS 29.125 (31.609)	mem 76.202
Train: [34][1170/1500]	BT 0.034 (0.303)	DT 0.001 (0.265)	loss 6.962 (7.067)	prob 3.406 (3.003)	GS 32.250 (32.130)	mem 76.202
Train: [34][1180/1500]	BT 0.025 (0.300)	DT 0.000 (0.263)	loss 6.973 (7.051)	prob 2.301 (3.045)	GS 35.031 (32.303)	mem 76.202
Train: [34][1190/1500]	BT 0.055 (0.302)	DT 0.011 (0.265)	loss 7.227 (7.054)	prob 3.116 (2.990)	GS 31.781 (32.486)	mem 76.206
Train: [34][1200/1500]	BT 0.060 (0.300)	DT 0.001 (0.263)	loss 6.899 (7.059)	prob 2.395 (2.942)	GS 39.359 (33.173)	mem 76.206
Train: [34][1210/1500]	BT 0.064 (0.298)	DT 0.002 (0.261)	loss 7.014 (7.109)	prob 2.651 (2.801)	GS 35.750 (32.941)	mem 76.206
Train: [34][1220/1500]	BT 0.028 (0.305)	DT 0.000 (0.268)	loss 6.872 (7.062)	prob 3.427 (2.991)	GS 33.125 (33.039)	mem 76.231
Train: [34][1230/1500]	BT 0.033 (0.303)	DT 0.000 (0.265)	loss 7.220 (7.071)	prob 2.607 (2.962)	GS 36.469 (32.957)	mem 76.232
Train: [34][1240/1500]	BT 0.038 (0.301)	DT 0.001 (0.263)	loss 6.768 (7.066)	prob 3.122 (2.951)	GS 33.844 (33.065)	mem 76.234
Train: [34][1250/1500]	BT 0.033 (0.302)	DT 0.000 (0.264)	loss 7.147 (7.064)	prob 2.388 (2.932)	GS 36.062 (33.018)	mem 76.234
Train: [34][1260/1500]	BT 0.578 (0.300)	DT 0.545 (0.262)	loss 7.114 (7.025)	prob 3.048 (3.017)	GS 31.203 (32.775)	mem 76.233
Train: [34][1270/1500]	BT 0.039 (0.300)	DT 0.001 (0.263)	loss 7.048 (7.046)	prob 2.290 (2.827)	GS 32.516 (33.166)	mem 76.232
Train: [34][1280/1500]	BT 0.039 (0.299)	DT 0.001 (0.261)	loss 6.825 (7.012)	prob 2.906 (2.793)	GS 33.578 (32.618)	mem 76.233
Train: [34][1290/1500]	BT 0.038 (0.298)	DT 0.001 (0.261)	loss 6.885 (7.008)	prob 2.893 (2.713)	GS 31.453 (32.351)	mem 76.233
Train: [34][1300/1500]	BT 0.039 (0.298)	DT 0.001 (0.260)	loss 6.999 (7.009)	prob 2.933 (2.683)	GS 32.969 (32.246)	mem 76.235
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [34][1310/1500]	BT 0.039 (0.300)	DT 0.001 (0.262)	loss 6.917 (7.081)	prob 2.928 (2.939)	GS 33.516 (32.584)	mem 76.236
Train: [34][1320/1500]	BT 0.040 (0.298)	DT 0.001 (0.260)	loss 6.811 (7.019)	prob 3.261 (2.911)	GS 32.922 (32.023)	mem 76.236
Train: [34][1330/1500]	BT 0.054 (0.299)	DT 0.006 (0.262)	loss 6.753 (6.999)	prob 3.148 (2.889)	GS 34.219 (32.118)	mem 76.237
Train: [34][1340/1500]	BT 0.031 (0.300)	DT 0.000 (0.262)	loss 6.817 (6.957)	prob 2.478 (2.904)	GS 29.891 (32.402)	mem 76.237
Train: [34][1350/1500]	BT 0.060 (0.299)	DT 0.004 (0.261)	loss 6.875 (6.942)	prob 2.727 (2.874)	GS 32.859 (32.242)	mem 76.236
Train: [34][1360/1500]	BT 0.038 (0.301)	DT 0.001 (0.263)	loss 7.222 (6.896)	prob 2.547 (2.672)	GS 36.938 (33.716)	mem 76.237
Train: [34][1370/1500]	BT 0.039 (0.299)	DT 0.001 (0.261)	loss 6.813 (6.878)	prob 2.849 (2.796)	GS 34.766 (33.657)	mem 76.237
Train: [34][1380/1500]	BT 6.812 (0.302)	DT 6.774 (0.264)	loss 6.803 (6.886)	prob 3.167 (2.851)	GS 33.938 (33.431)	mem 76.236
Train: [34][1390/1500]	BT 0.039 (0.300)	DT 0.001 (0.262)	loss 6.572 (6.889)	prob 2.928 (2.832)	GS 37.094 (33.340)	mem 76.236
Train: [34][1400/1500]	BT 0.039 (0.300)	DT 0.001 (0.262)	loss 6.922 (6.902)	prob 2.727 (2.794)	GS 37.953 (33.524)	mem 76.236
Train: [34][1410/1500]	BT 0.040 (0.299)	DT 0.001 (0.261)	loss 6.880 (6.936)	prob 3.135 (3.256)	GS 35.797 (32.747)	mem 76.236
Train: [34][1420/1500]	BT 0.029 (0.300)	DT 0.000 (0.262)	loss 7.211 (6.927)	prob 3.478 (3.077)	GS 31.250 (32.905)	mem 76.235
Train: [34][1430/1500]	BT 0.029 (0.298)	DT 0.000 (0.260)	loss 6.795 (6.911)	prob 3.296 (3.113)	GS 29.594 (32.679)	mem 76.238
Train: [34][1440/1500]	BT 0.066 (0.298)	DT 0.008 (0.260)	loss 7.079 (6.940)	prob 2.971 (3.156)	GS 34.656 (32.614)	mem 76.238
Train: [34][1450/1500]	BT 0.063 (0.297)	DT 0.002 (0.259)	loss 6.752 (6.971)	prob 3.347 (3.107)	GS 30.984 (32.412)	mem 76.238
Train: [34][1460/1500]	BT 0.051 (0.295)	DT 0.002 (0.257)	loss 7.124 (7.044)	prob 3.096 (2.967)	GS 32.641 (33.359)	mem 76.240
Train: [34][1470/1500]	BT 0.027 (0.296)	DT 0.000 (0.258)	loss 7.390 (7.098)	prob 2.863 (2.943)	GS 31.062 (32.817)	mem 75.219
Train: [34][1480/1500]	BT 0.023 (0.294)	DT 0.000 (0.256)	loss 7.468 (7.143)	prob 2.984 (2.779)	GS 35.047 (32.769)	mem 68.821
Train: [34][1490/1500]	BT 0.024 (0.294)	DT 0.000 (0.256)	loss 7.335 (7.168)	prob 3.346 (2.889)	GS 25.375 (32.615)	mem 11.237
Train: [34][1500/1500]	BT 0.033 (0.292)	DT 0.000 (0.254)	loss 6.887 (7.178)	prob 2.584 (2.896)	GS 32.656 (32.615)	mem 11.236
Train: [34][1510/1500]	BT 0.027 (0.291)	DT 0.000 (0.252)	loss 7.756 (7.487)	prob 1.695 (2.153)	GS 40.500 (34.056)	mem 11.235
epoch 34, total time 439.60
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [35][1/1500]	BT 21.711 (21.711)	DT 21.619 (21.619)	loss 6.842 (6.842)	prob 2.116 (2.116)	GS 32.406 (32.406)	mem 75.646
Train: [35][10/1500]	BT 0.038 (2.460)	DT 0.001 (2.416)	loss 7.245 (7.127)	prob 2.901 (2.960)	GS 34.969 (32.120)	mem 76.103
Train: [35][20/1500]	BT 0.037 (1.245)	DT 0.001 (1.208)	loss 6.986 (7.193)	prob 3.333 (2.815)	GS 38.031 (32.483)	mem 76.154
Train: [35][30/1500]	BT 0.029 (1.022)	DT 0.001 (0.986)	loss 7.563 (7.219)	prob 3.376 (2.864)	GS 31.156 (32.061)	mem 76.170
Train: [35][40/1500]	BT 0.027 (0.773)	DT 0.000 (0.739)	loss 7.377 (7.234)	prob 3.437 (2.981)	GS 34.922 (32.131)	mem 76.171
Train: [35][50/1500]	BT 0.039 (0.626)	DT 0.001 (0.592)	loss 7.447 (7.261)	prob 2.637 (3.051)	GS 32.516 (31.941)	mem 76.171
Train: [35][60/1500]	BT 0.028 (0.638)	DT 0.000 (0.604)	loss 7.811 (7.494)	prob 3.382 (3.158)	GS 29.484 (33.317)	mem 76.189
Train: [35][70/1500]	BT 0.028 (0.551)	DT 0.000 (0.518)	loss 7.211 (7.516)	prob 3.184 (3.227)	GS 31.891 (33.021)	mem 76.188
Train: [35][80/1500]	BT 0.039 (0.525)	DT 0.001 (0.492)	loss 7.855 (7.535)	prob 3.427 (3.275)	GS 29.844 (32.763)	mem 76.195
Train: [35][90/1500]	BT 0.040 (0.471)	DT 0.001 (0.437)	loss 7.348 (7.506)	prob 3.621 (3.280)	GS 35.281 (32.756)	mem 76.195
Train: [35][100/1500]	BT 0.039 (0.428)	DT 0.001 (0.394)	loss 7.667 (7.516)	prob 3.337 (3.206)	GS 30.750 (32.861)	mem 76.194
Train: [35][110/1500]	BT 0.039 (0.417)	DT 0.001 (0.382)	loss 7.519 (7.639)	prob 3.425 (3.469)	GS 36.062 (32.636)	mem 76.197
Train: [35][120/1500]	BT 0.039 (0.385)	DT 0.001 (0.351)	loss 7.825 (7.610)	prob 2.023 (3.490)	GS 32.875 (31.867)	mem 76.197
Train: [35][130/1500]	BT 0.038 (0.431)	DT 0.001 (0.395)	loss 7.389 (7.602)	prob 3.818 (3.333)	GS 31.250 (32.211)	mem 76.200
Train: [35][140/1500]	BT 0.036 (0.403)	DT 0.000 (0.367)	loss 7.807 (7.586)	prob 2.850 (3.256)	GS 29.672 (32.344)	mem 76.201
Train: [35][150/1500]	BT 0.065 (0.396)	DT 0.015 (0.360)	loss 7.694 (7.576)	prob 3.052 (3.203)	GS 30.500 (32.198)	mem 76.212
Train: [35][160/1500]	BT 0.029 (0.411)	DT 0.000 (0.375)	loss 7.709 (7.654)	prob 2.966 (3.054)	GS 36.469 (33.089)	mem 76.221
Train: [35][170/1500]	BT 0.024 (0.389)	DT 0.000 (0.353)	loss 7.734 (7.624)	prob 2.643 (2.944)	GS 35.594 (33.986)	mem 76.221
Train: [35][180/1500]	BT 0.038 (0.385)	DT 0.000 (0.350)	loss 7.858 (7.629)	prob 3.232 (2.930)	GS 34.469 (33.608)	mem 76.226
Train: [35][190/1500]	BT 0.037 (0.367)	DT 0.000 (0.331)	loss 7.433 (7.590)	prob 3.182 (3.065)	GS 33.875 (33.650)	mem 76.226
Train: [35][200/1500]	BT 0.037 (0.350)	DT 0.001 (0.315)	loss 8.094 (7.580)	prob 3.468 (3.141)	GS 36.656 (33.418)	mem 76.226
Train: [35][210/1500]	BT 0.023 (0.373)	DT 0.000 (0.338)	loss 7.362 (7.580)	prob 4.213 (3.121)	GS 32.875 (34.270)	mem 76.233
Train: [35][220/1500]	BT 0.032 (0.357)	DT 0.000 (0.322)	loss 7.673 (7.579)	prob 3.250 (3.085)	GS 33.484 (33.741)	mem 76.235
Train: [35][230/1500]	BT 0.077 (0.362)	DT 0.002 (0.326)	loss 7.528 (7.539)	prob 4.466 (3.272)	GS 34.312 (33.072)	mem 76.237
Train: [35][240/1500]	BT 0.091 (0.351)	DT 0.002 (0.313)	loss 7.951 (7.596)	prob 3.050 (3.261)	GS 35.781 (32.997)	mem 76.236
Train: [35][250/1500]	BT 0.027 (0.397)	DT 0.000 (0.358)	loss 8.366 (7.608)	prob 2.009 (3.131)	GS 36.469 (33.354)	mem 76.239
Train: [35][260/1500]	BT 0.027 (0.383)	DT 0.000 (0.344)	loss 7.224 (7.455)	prob 4.055 (3.308)	GS 31.234 (32.305)	mem 76.241
Train: [35][270/1500]	BT 0.024 (0.369)	DT 0.000 (0.332)	loss 7.830 (7.543)	prob 3.599 (3.466)	GS 33.641 (32.305)	mem 76.241
Train: [35][280/1500]	BT 0.048 (0.383)	DT 0.007 (0.346)	loss 7.493 (7.516)	prob 2.819 (3.315)	GS 35.969 (32.711)	mem 76.249
Train: [35][290/1500]	BT 0.056 (0.372)	DT 0.002 (0.334)	loss 7.855 (7.545)	prob 3.738 (3.334)	GS 34.672 (32.189)	mem 76.251
Train: [35][300/1500]	BT 0.041 (0.388)	DT 0.000 (0.350)	loss 7.642 (7.547)	prob 3.299 (3.357)	GS 34.062 (32.269)	mem 76.249
Train: [35][310/1500]	BT 0.034 (0.398)	DT 0.000 (0.360)	loss 7.363 (7.552)	prob 3.661 (3.083)	GS 32.766 (34.044)	mem 76.251
Train: [35][320/1500]	BT 0.022 (0.386)	DT 0.000 (0.348)	loss 7.544 (7.536)	prob 2.973 (3.157)	GS 35.453 (34.009)	mem 76.252
Train: [35][330/1500]	BT 0.038 (0.376)	DT 0.001 (0.338)	loss 7.166 (7.499)	prob 3.614 (3.160)	GS 35.031 (33.192)	mem 76.253
Train: [35][340/1500]	BT 0.036 (0.375)	DT 0.001 (0.337)	loss 7.640 (7.507)	prob 2.853 (3.154)	GS 33.250 (32.864)	mem 76.255
Train: [35][350/1500]	BT 0.028 (0.365)	DT 0.000 (0.327)	loss 7.509 (7.501)	prob 2.987 (3.179)	GS 31.109 (32.710)	mem 76.255
Train: [35][360/1500]	BT 0.031 (0.384)	DT 0.001 (0.347)	loss 7.611 (7.603)	prob 2.539 (2.859)	GS 32.484 (33.872)	mem 76.258
Train: [35][370/1500]	BT 0.040 (0.374)	DT 0.000 (0.337)	loss 7.278 (7.529)	prob 3.636 (3.023)	GS 35.453 (32.948)	mem 76.259
Train: [35][380/1500]	BT 0.024 (0.365)	DT 0.000 (0.328)	loss 7.650 (7.583)	prob 3.863 (2.985)	GS 30.297 (32.691)	mem 76.259
Train: [35][390/1500]	BT 0.031 (0.365)	DT 0.000 (0.328)	loss 7.401 (7.534)	prob 2.418 (3.103)	GS 33.219 (32.669)	mem 76.260
Train: [35][400/1500]	BT 0.033 (0.357)	DT 0.000 (0.320)	loss 8.200 (7.548)	prob 1.867 (3.027)	GS 32.500 (32.898)	mem 76.262
Train: [35][410/1500]	BT 0.064 (0.367)	DT 0.003 (0.329)	loss 7.704 (7.625)	prob 3.273 (2.966)	GS 32.875 (32.584)	mem 76.263
Train: [35][420/1500]	BT 0.035 (0.359)	DT 0.000 (0.321)	loss 7.116 (7.584)	prob 3.264 (3.004)	GS 30.016 (32.055)	mem 76.263
Train: [35][430/1500]	BT 0.030 (0.370)	DT 0.000 (0.333)	loss 7.762 (7.585)	prob 3.612 (3.138)	GS 32.078 (32.267)	mem 76.265
Train: [35][440/1500]	BT 0.038 (0.363)	DT 0.000 (0.325)	loss 7.868 (7.563)	prob 2.538 (3.052)	GS 37.969 (32.551)	mem 76.266
Train: [35][450/1500]	BT 0.082 (0.367)	DT 0.002 (0.329)	loss 7.410 (7.559)	prob 2.774 (3.032)	GS 37.094 (32.674)	mem 76.268
Train: [35][460/1500]	BT 0.062 (0.360)	DT 0.000 (0.322)	loss 7.847 (7.436)	prob 2.923 (3.047)	GS 34.141 (34.619)	mem 76.268
Train: [35][470/1500]	BT 0.086 (0.360)	DT 0.010 (0.321)	loss 8.448 (7.460)	prob 2.963 (3.181)	GS 31.625 (33.298)	mem 76.270
Train: [35][480/1500]	BT 0.056 (0.398)	DT 0.009 (0.358)	loss 7.235 (7.498)	prob 4.023 (3.084)	GS 33.719 (33.148)	mem 76.268
Train: [35][490/1500]	BT 0.040 (0.391)	DT 0.010 (0.351)	loss 8.242 (7.508)	prob 3.196 (3.044)	GS 30.328 (32.768)	mem 76.271
Train: [35][500/1500]	BT 0.027 (0.409)	DT 0.000 (0.370)	loss 8.137 (7.528)	prob 2.645 (3.064)	GS 32.672 (32.765)	mem 76.271
Train: [35][510/1500]	BT 0.035 (0.402)	DT 0.000 (0.363)	loss 7.767 (7.555)	prob 2.068 (2.519)	GS 37.562 (35.128)	mem 76.272
Train: [35][520/1500]	BT 0.038 (0.406)	DT 0.000 (0.367)	loss 7.782 (7.569)	prob 2.327 (2.449)	GS 37.031 (33.940)	mem 76.275
Train: [35][530/1500]	BT 0.068 (0.400)	DT 0.011 (0.360)	loss 7.424 (7.555)	prob 3.198 (2.488)	GS 32.422 (33.913)	mem 76.275
Train: [35][540/1500]	BT 5.110 (0.403)	DT 5.023 (0.363)	loss 7.263 (7.581)	prob 2.904 (2.467)	GS 32.094 (33.883)	mem 76.273
Train: [35][550/1500]	BT 0.087 (0.397)	DT 0.010 (0.357)	loss 7.219 (7.601)	prob 2.308 (2.499)	GS 30.719 (33.627)	mem 76.273
Train: [35][560/1500]	BT 0.036 (0.398)	DT 0.001 (0.357)	loss 7.424 (7.473)	prob 2.827 (2.728)	GS 30.688 (33.508)	mem 76.276
Train: [35][570/1500]	BT 0.037 (0.392)	DT 0.001 (0.352)	loss 8.223 (7.583)	prob 2.790 (2.630)	GS 35.203 (32.788)	mem 76.277
Train: [35][580/1500]	BT 0.038 (0.390)	DT 0.001 (0.350)	loss 7.807 (7.568)	prob 2.482 (2.570)	GS 37.000 (33.298)	mem 76.277
Train: [35][590/1500]	BT 0.038 (0.386)	DT 0.001 (0.346)	loss 7.706 (7.617)	prob 3.261 (2.402)	GS 34.188 (33.459)	mem 76.279
Train: [35][600/1500]	BT 0.068 (0.386)	DT 0.016 (0.345)	loss 7.612 (7.624)	prob 3.257 (2.448)	GS 36.516 (33.777)	mem 76.279
Train: [35][610/1500]	BT 0.040 (0.384)	DT 0.001 (0.343)	loss 8.406 (7.504)	prob 1.525 (2.558)	GS 33.812 (32.711)	mem 76.280
Train: [35][620/1500]	BT 0.038 (0.383)	DT 0.000 (0.342)	loss 8.027 (7.627)	prob 2.811 (2.415)	GS 34.781 (32.634)	mem 76.278
Train: [35][630/1500]	BT 0.037 (0.380)	DT 0.001 (0.339)	loss 7.347 (7.635)	prob 3.183 (2.413)	GS 37.406 (33.199)	mem 76.278
Train: [35][640/1500]	BT 0.037 (0.377)	DT 0.000 (0.336)	loss 8.129 (7.664)	prob 2.887 (2.488)	GS 38.672 (33.164)	mem 76.310
Train: [35][650/1500]	BT 0.042 (0.375)	DT 0.001 (0.335)	loss 7.169 (7.610)	prob 3.713 (2.545)	GS 28.406 (32.712)	mem 76.312
Train: [35][660/1500]	BT 3.709 (0.376)	DT 3.677 (0.335)	loss 7.610 (7.576)	prob 3.251 (2.931)	GS 33.688 (31.483)	mem 76.311
Train: [35][670/1500]	BT 0.058 (0.372)	DT 0.001 (0.332)	loss 8.098 (7.612)	prob 2.092 (2.594)	GS 35.422 (31.912)	mem 76.314
Train: [35][680/1500]	BT 1.700 (0.371)	DT 1.652 (0.331)	loss 7.646 (7.662)	prob 2.818 (2.485)	GS 33.547 (31.774)	mem 76.314
Train: [35][690/1500]	BT 0.031 (0.379)	DT 0.000 (0.338)	loss 8.157 (7.691)	prob 1.850 (2.475)	GS 32.797 (32.132)	mem 76.311
Train: [35][700/1500]	BT 0.042 (0.374)	DT 0.001 (0.333)	loss 7.886 (7.693)	prob 2.788 (2.493)	GS 33.453 (32.146)	mem 76.312
Train: [35][710/1500]	BT 0.040 (0.369)	DT 0.001 (0.329)	loss 8.357 (7.911)	prob 2.586 (2.418)	GS 36.578 (30.636)	mem 76.312
Train: [35][720/1500]	BT 0.059 (0.372)	DT 0.002 (0.331)	loss 8.207 (7.827)	prob 1.856 (2.511)	GS 35.188 (31.515)	mem 76.313
Train: [35][730/1500]	BT 0.031 (0.380)	DT 0.000 (0.339)	loss 8.641 (7.794)	prob 3.056 (2.564)	GS 33.188 (32.501)	mem 76.314
Train: [35][740/1500]	BT 0.030 (0.375)	DT 0.000 (0.334)	loss 8.348 (7.807)	prob 2.983 (2.621)	GS 31.781 (32.189)	mem 76.316
Train: [35][750/1500]	BT 0.026 (0.371)	DT 0.000 (0.330)	loss 8.034 (7.788)	prob 3.009 (2.698)	GS 37.312 (32.271)	mem 76.315
Train: [35][760/1500]	BT 0.028 (0.376)	DT 0.000 (0.335)	loss 7.788 (7.897)	prob 3.292 (2.612)	GS 32.859 (33.730)	mem 76.316
Train: [35][770/1500]	BT 0.024 (0.371)	DT 0.000 (0.331)	loss 7.670 (7.924)	prob 3.103 (2.730)	GS 35.125 (32.472)	mem 76.316
Train: [35][780/1500]	BT 0.031 (0.372)	DT 0.001 (0.332)	loss 7.743 (7.863)	prob 2.938 (2.672)	GS 32.953 (32.903)	mem 76.315
Train: [35][790/1500]	BT 0.027 (0.368)	DT 0.000 (0.328)	loss 7.685 (7.843)	prob 3.470 (2.742)	GS 31.188 (32.381)	mem 76.315
Train: [35][800/1500]	BT 0.039 (0.364)	DT 0.001 (0.324)	loss 8.309 (7.847)	prob 3.063 (2.738)	GS 33.453 (32.419)	mem 76.317
Train: [35][810/1500]	BT 0.033 (0.367)	DT 0.003 (0.327)	loss 7.586 (7.737)	prob 3.591 (3.148)	GS 35.203 (32.445)	mem 76.319
Train: [35][820/1500]	BT 0.031 (0.363)	DT 0.000 (0.323)	loss 7.949 (7.852)	prob 3.984 (3.199)	GS 30.078 (32.093)	mem 76.317
Train: [35][830/1500]	BT 0.051 (0.369)	DT 0.002 (0.329)	loss 8.612 (7.932)	prob 2.429 (3.055)	GS 37.234 (32.842)	mem 76.320
Train: [35][840/1500]	BT 0.085 (0.365)	DT 0.016 (0.325)	loss 7.887 (7.900)	prob 4.406 (3.031)	GS 29.938 (32.561)	mem 76.319
Train: [35][850/1500]	BT 0.029 (0.377)	DT 0.000 (0.337)	loss 7.885 (7.932)	prob 2.489 (3.065)	GS 35.641 (32.708)	mem 76.319
Train: [35][860/1500]	BT 0.031 (0.373)	DT 0.000 (0.333)	loss 8.647 (7.852)	prob 3.114 (2.985)	GS 33.406 (33.480)	mem 76.319
Train: [35][870/1500]	BT 0.037 (0.373)	DT 0.000 (0.332)	loss 8.414 (7.951)	prob 3.925 (3.019)	GS 33.859 (32.874)	mem 76.321
Train: [35][880/1500]	BT 0.054 (0.369)	DT 0.003 (0.328)	loss 8.527 (7.906)	prob 3.648 (3.142)	GS 35.125 (32.930)	mem 76.322
Train: [35][890/1500]	BT 0.037 (0.365)	DT 0.000 (0.325)	loss 7.914 (7.884)	prob 3.592 (3.187)	GS 32.062 (33.244)	mem 76.322
Train: [35][900/1500]	BT 0.031 (0.368)	DT 0.000 (0.328)	loss 8.325 (7.872)	prob 2.378 (3.179)	GS 38.344 (33.372)	mem 76.327
Train: [35][910/1500]	BT 0.038 (0.364)	DT 0.001 (0.324)	loss 8.595 (8.141)	prob 2.839 (3.057)	GS 36.172 (32.191)	mem 76.327
Train: [35][920/1500]	BT 0.032 (0.369)	DT 0.000 (0.329)	loss 8.700 (7.961)	prob 3.801 (3.324)	GS 33.078 (32.766)	mem 76.329
Train: [35][930/1500]	BT 0.053 (0.366)	DT 0.006 (0.326)	loss 7.880 (7.881)	prob 3.489 (3.282)	GS 34.938 (33.062)	mem 76.329
Train: [35][940/1500]	BT 0.035 (0.363)	DT 0.001 (0.322)	loss 7.931 (7.930)	prob 3.871 (3.239)	GS 36.375 (33.262)	mem 76.330
Train: [35][950/1500]	BT 0.030 (0.370)	DT 0.000 (0.330)	loss 8.197 (7.944)	prob 4.309 (3.266)	GS 35.500 (33.223)	mem 76.329
Train: [35][960/1500]	BT 0.060 (0.367)	DT 0.016 (0.327)	loss 8.326 (8.099)	prob 3.688 (3.513)	GS 31.359 (32.686)	mem 76.328
Train: [35][970/1500]	BT 0.035 (0.381)	DT 0.000 (0.341)	loss 7.316 (7.944)	prob 4.058 (3.560)	GS 34.500 (32.498)	mem 76.218
Train: [35][980/1500]	BT 0.027 (0.378)	DT 0.000 (0.337)	loss 7.932 (7.921)	prob 3.774 (3.614)	GS 31.000 (32.180)	mem 76.237
Train: [35][990/1500]	BT 0.031 (0.379)	DT 0.000 (0.339)	loss 7.788 (7.871)	prob 3.663 (3.579)	GS 36.031 (32.453)	mem 76.241
Train: [35][1000/1500]	BT 0.059 (0.376)	DT 0.015 (0.335)	loss 8.328 (7.839)	prob 4.393 (3.637)	GS 34.656 (32.428)	mem 76.240
Train: [35][1010/1500]	BT 0.031 (0.372)	DT 0.000 (0.332)	loss 8.077 (7.698)	prob 3.894 (3.734)	GS 33.781 (32.683)	mem 76.240
Train: [35][1020/1500]	BT 0.036 (0.373)	DT 0.001 (0.333)	loss 7.399 (7.697)	prob 4.693 (3.955)	GS 28.344 (32.124)	mem 76.238
Train: [35][1030/1500]	BT 0.036 (0.370)	DT 0.001 (0.329)	loss 8.480 (7.773)	prob 2.398 (3.714)	GS 30.938 (32.755)	mem 76.239
Train: [35][1040/1500]	BT 0.067 (0.369)	DT 0.011 (0.329)	loss 7.247 (7.800)	prob 4.671 (3.671)	GS 29.219 (32.669)	mem 76.238
Train: [35][1050/1500]	BT 0.053 (0.366)	DT 0.014 (0.326)	loss 8.331 (7.818)	prob 3.980 (3.689)	GS 34.078 (32.840)	mem 76.238
Train: [35][1060/1500]	BT 6.494 (0.369)	DT 6.461 (0.329)	loss 8.580 (7.892)	prob 3.723 (3.723)	GS 35.328 (32.255)	mem 76.241
Train: [35][1070/1500]	BT 0.039 (0.368)	DT 0.000 (0.328)	loss 7.789 (7.931)	prob 3.636 (3.626)	GS 35.062 (33.152)	mem 76.263
Train: [35][1080/1500]	BT 0.038 (0.365)	DT 0.001 (0.325)	loss 7.905 (7.931)	prob 3.619 (3.397)	GS 31.328 (32.793)	mem 76.265
Train: [35][1090/1500]	BT 0.034 (0.363)	DT 0.001 (0.323)	loss 8.128 (7.880)	prob 4.158 (3.518)	GS 29.328 (32.754)	mem 76.265
Train: [35][1100/1500]	BT 0.037 (0.365)	DT 0.001 (0.325)	loss 7.430 (7.864)	prob 3.334 (3.508)	GS 32.703 (32.877)	mem 76.253
Train: [35][1110/1500]	BT 1.040 (0.363)	DT 1.002 (0.323)	loss 8.086 (7.708)	prob 4.172 (3.679)	GS 35.016 (33.250)	mem 76.254
Train: [35][1120/1500]	BT 0.028 (0.364)	DT 0.000 (0.324)	loss 8.404 (7.815)	prob 2.849 (3.594)	GS 33.484 (33.300)	mem 76.255
Train: [35][1130/1500]	BT 0.035 (0.361)	DT 0.001 (0.321)	loss 7.929 (7.786)	prob 3.432 (3.520)	GS 34.219 (33.528)	mem 76.256
Train: [35][1140/1500]	BT 0.039 (0.359)	DT 0.001 (0.319)	loss 7.430 (7.777)	prob 4.068 (3.503)	GS 32.812 (33.102)	mem 76.256
Train: [35][1150/1500]	BT 0.039 (0.358)	DT 0.001 (0.318)	loss 7.817 (7.780)	prob 4.033 (3.492)	GS 35.359 (32.911)	mem 76.259
Train: [35][1160/1500]	BT 0.040 (0.356)	DT 0.001 (0.316)	loss 7.538 (7.792)	prob 3.025 (3.080)	GS 36.234 (33.753)	mem 76.258
Train: [35][1170/1500]	BT 0.039 (0.356)	DT 0.001 (0.316)	loss 7.679 (7.795)	prob 3.658 (3.059)	GS 29.828 (32.625)	mem 76.258
Train: [35][1180/1500]	BT 0.083 (0.353)	DT 0.048 (0.314)	loss 8.003 (7.816)	prob 4.884 (3.246)	GS 35.312 (32.436)	mem 76.259
Train: [35][1190/1500]	BT 0.039 (0.353)	DT 0.001 (0.314)	loss 7.677 (7.822)	prob 3.068 (3.215)	GS 34.281 (32.594)	mem 76.261
Train: [35][1200/1500]	BT 0.039 (0.351)	DT 0.001 (0.311)	loss 7.567 (7.829)	prob 2.693 (3.198)	GS 34.156 (32.609)	mem 76.261
Train: [35][1210/1500]	BT 0.036 (0.351)	DT 0.000 (0.311)	loss 7.874 (7.628)	prob 3.223 (3.382)	GS 35.312 (32.211)	mem 76.275
Train: [35][1220/1500]	BT 0.042 (0.350)	DT 0.007 (0.310)	loss 8.103 (7.663)	prob 2.760 (3.237)	GS 36.078 (33.042)	mem 76.277
Train: [35][1230/1500]	BT 1.040 (0.349)	DT 0.977 (0.309)	loss 7.769 (7.696)	prob 3.717 (3.196)	GS 34.703 (33.104)	mem 76.277
Train: [35][1240/1500]	BT 1.806 (0.351)	DT 1.749 (0.311)	loss 8.431 (7.714)	prob 3.312 (3.139)	GS 33.766 (33.022)	mem 76.281
Train: [35][1250/1500]	BT 0.037 (0.349)	DT 0.000 (0.309)	loss 7.954 (7.721)	prob 2.971 (3.053)	GS 36.047 (33.339)	mem 76.281
Train: [35][1260/1500]	BT 0.037 (0.347)	DT 0.001 (0.307)	loss 7.289 (7.847)	prob 4.188 (3.007)	GS 27.172 (30.702)	mem 76.281
Train: [35][1270/1500]	BT 0.037 (0.347)	DT 0.000 (0.307)	loss 8.336 (7.761)	prob 3.628 (3.281)	GS 33.953 (31.198)	mem 76.282
Train: [35][1280/1500]	BT 0.037 (0.345)	DT 0.001 (0.305)	loss 7.641 (7.804)	prob 2.869 (3.187)	GS 34.469 (31.721)	mem 76.284
Train: [35][1290/1500]	BT 0.058 (0.346)	DT 0.011 (0.306)	loss 7.687 (7.774)	prob 3.654 (3.132)	GS 28.719 (32.052)	mem 76.285
Train: [35][1300/1500]	BT 0.025 (0.348)	DT 0.000 (0.308)	loss 7.997 (7.790)	prob 3.906 (3.087)	GS 29.141 (32.023)	mem 76.284
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [35][1310/1500]	BT 0.038 (0.346)	DT 0.001 (0.306)	loss 7.874 (7.804)	prob 3.477 (2.959)	GS 34.547 (32.141)	mem 76.285
Train: [35][1320/1500]	BT 0.037 (0.344)	DT 0.001 (0.304)	loss 8.627 (7.813)	prob 3.385 (2.899)	GS 35.891 (32.209)	mem 76.286
Train: [35][1330/1500]	BT 0.061 (0.344)	DT 0.001 (0.304)	loss 7.764 (7.827)	prob 3.625 (2.975)	GS 31.172 (31.587)	mem 76.287
Train: [35][1340/1500]	BT 0.031 (0.344)	DT 0.000 (0.304)	loss 7.689 (7.835)	prob 3.353 (2.920)	GS 37.938 (32.301)	mem 76.287
Train: [35][1350/1500]	BT 0.052 (0.345)	DT 0.010 (0.305)	loss 7.767 (7.855)	prob 4.010 (2.898)	GS 32.297 (32.266)	mem 76.286
Train: [35][1360/1500]	BT 0.072 (0.343)	DT 0.025 (0.303)	loss 8.933 (7.982)	prob 2.633 (3.050)	GS 33.812 (32.072)	mem 76.286
Train: [35][1370/1500]	BT 0.076 (0.348)	DT 0.012 (0.308)	loss 8.428 (8.060)	prob 2.607 (2.901)	GS 33.109 (32.234)	mem 76.287
Train: [35][1380/1500]	BT 0.027 (0.354)	DT 0.000 (0.314)	loss 8.389 (8.008)	prob 2.739 (2.863)	GS 34.188 (32.229)	mem 76.287
Train: [35][1390/1500]	BT 0.034 (0.352)	DT 0.000 (0.312)	loss 7.556 (7.997)	prob 2.610 (2.957)	GS 36.906 (32.310)	mem 76.289
Train: [35][1400/1500]	BT 0.038 (0.351)	DT 0.001 (0.312)	loss 7.821 (7.997)	prob 2.850 (2.853)	GS 34.312 (32.382)	mem 76.290
Train: [35][1410/1500]	BT 0.037 (0.349)	DT 0.001 (0.309)	loss 8.404 (8.019)	prob 2.140 (2.412)	GS 34.281 (34.230)	mem 76.290
Train: [35][1420/1500]	BT 3.942 (0.350)	DT 3.894 (0.310)	loss 8.514 (7.949)	prob 3.111 (2.880)	GS 31.750 (32.684)	mem 76.291
Train: [35][1430/1500]	BT 0.060 (0.347)	DT 0.011 (0.308)	loss 8.802 (8.070)	prob 3.471 (2.866)	GS 33.859 (32.532)	mem 76.292
Train: [35][1440/1500]	BT 0.058 (0.345)	DT 0.011 (0.306)	loss 8.257 (8.003)	prob 2.883 (2.962)	GS 32.328 (32.404)	mem 76.292
Train: [35][1450/1500]	BT 1.707 (0.350)	DT 1.667 (0.311)	loss 8.037 (7.980)	prob 2.639 (2.932)	GS 36.516 (32.484)	mem 75.924
Train: [35][1460/1500]	BT 0.029 (0.348)	DT 0.000 (0.309)	loss 8.087 (8.083)	prob 3.462 (2.405)	GS 33.156 (32.786)	mem 75.923
Train: [35][1470/1500]	BT 0.025 (0.347)	DT 0.000 (0.307)	loss 8.082 (7.968)	prob 3.383 (2.786)	GS 34.672 (32.395)	mem 53.698
Train: [35][1480/1500]	BT 0.032 (0.346)	DT 0.000 (0.306)	loss 9.305 (8.016)	prob 2.812 (2.798)	GS 35.172 (32.545)	mem 14.035
Train: [35][1490/1500]	BT 0.026 (0.344)	DT 0.000 (0.304)	loss 7.801 (8.006)	prob 4.093 (2.898)	GS 36.656 (32.479)	mem 14.035
Train: [35][1500/1500]	BT 0.036 (0.342)	DT 0.000 (0.303)	loss 8.222 (8.027)	prob 2.969 (2.920)	GS 33.812 (32.470)	mem 11.187
Train: [35][1510/1500]	BT 0.027 (0.340)	DT 0.001 (0.301)	loss 8.138 (8.146)	prob 2.116 (2.956)	GS 34.719 (35.987)	mem 11.187
epoch 35, total time 513.50
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [36][1/1500]	BT 20.750 (20.750)	DT 20.694 (20.694)	loss 8.258 (8.258)	prob 3.469 (3.469)	GS 32.984 (32.984)	mem 74.794
Train: [36][10/1500]	BT 0.037 (2.229)	DT 0.000 (2.194)	loss 8.117 (7.843)	prob 2.919 (3.155)	GS 33.188 (32.292)	mem 74.840
Train: [36][20/1500]	BT 0.036 (1.135)	DT 0.000 (1.098)	loss 7.641 (7.844)	prob 3.716 (3.279)	GS 31.250 (31.996)	mem 74.858
Train: [36][30/1500]	BT 0.038 (0.878)	DT 0.001 (0.841)	loss 7.711 (7.930)	prob 3.801 (3.183)	GS 32.188 (32.300)	mem 75.526
Train: [36][40/1500]	BT 0.037 (0.697)	DT 0.001 (0.660)	loss 8.025 (7.990)	prob 3.306 (3.157)	GS 35.281 (32.085)	mem 75.669
Train: [36][50/1500]	BT 0.038 (0.598)	DT 0.001 (0.563)	loss 7.655 (8.000)	prob 4.348 (3.183)	GS 31.016 (31.863)	mem 76.073
Train: [36][60/1500]	BT 0.038 (0.529)	DT 0.000 (0.493)	loss 8.507 (8.091)	prob 3.505 (2.922)	GS 32.156 (31.955)	mem 76.137
Train: [36][70/1500]	BT 0.039 (0.477)	DT 0.001 (0.441)	loss 7.664 (7.998)	prob 4.602 (3.295)	GS 32.203 (32.092)	mem 76.166
Train: [36][80/1500]	BT 0.039 (0.459)	DT 0.001 (0.422)	loss 8.407 (8.016)	prob 3.834 (3.373)	GS 37.031 (32.344)	mem 76.168
Train: [36][90/1500]	BT 0.039 (0.412)	DT 0.001 (0.375)	loss 8.564 (8.027)	prob 4.511 (3.393)	GS 28.500 (31.922)	mem 76.168
Train: [36][100/1500]	BT 0.875 (0.414)	DT 0.837 (0.377)	loss 8.366 (8.041)	prob 3.064 (3.462)	GS 35.688 (32.072)	mem 76.171
Train: [36][110/1500]	BT 0.038 (0.380)	DT 0.001 (0.343)	loss 7.957 (7.779)	prob 4.045 (3.617)	GS 34.172 (32.884)	mem 76.170
Train: [36][120/1500]	BT 0.038 (0.355)	DT 0.001 (0.318)	loss 8.623 (7.906)	prob 4.217 (3.454)	GS 37.094 (32.362)	mem 76.174
Train: [36][130/1500]	BT 0.030 (0.414)	DT 0.000 (0.377)	loss 7.968 (7.929)	prob 4.221 (3.417)	GS 33.188 (32.963)	mem 76.188
Train: [36][140/1500]	BT 0.025 (0.386)	DT 0.000 (0.350)	loss 7.691 (7.901)	prob 4.409 (3.469)	GS 30.750 (32.886)	mem 76.188
Train: [36][150/1500]	BT 0.039 (0.363)	DT 0.001 (0.327)	loss 7.701 (7.926)	prob 4.546 (3.418)	GS 35.234 (33.075)	mem 76.190
Train: [36][160/1500]	BT 0.061 (0.389)	DT 0.003 (0.351)	loss 8.248 (7.825)	prob 3.090 (3.623)	GS 36.875 (33.147)	mem 76.193
Train: [36][170/1500]	BT 0.091 (0.371)	DT 0.005 (0.331)	loss 8.006 (7.862)	prob 4.243 (3.707)	GS 32.156 (33.341)	mem 76.193
Train: [36][180/1500]	BT 4.353 (0.432)	DT 4.327 (0.392)	loss 7.906 (7.883)	prob 3.930 (3.781)	GS 33.719 (33.482)	mem 76.200
Train: [36][190/1500]	BT 0.030 (0.411)	DT 0.000 (0.371)	loss 7.576 (7.877)	prob 3.737 (3.672)	GS 31.469 (33.353)	mem 76.201
Train: [36][200/1500]	BT 0.038 (0.392)	DT 0.001 (0.353)	loss 9.269 (7.889)	prob 3.218 (3.687)	GS 34.828 (33.367)	mem 76.202
Train: [36][210/1500]	BT 0.033 (0.388)	DT 0.000 (0.349)	loss 7.567 (7.686)	prob 3.789 (3.584)	GS 35.766 (34.469)	mem 76.206
Train: [36][220/1500]	BT 0.038 (0.372)	DT 0.001 (0.334)	loss 8.094 (7.744)	prob 3.598 (3.342)	GS 34.656 (34.219)	mem 76.206
Train: [36][230/1500]	BT 0.040 (0.370)	DT 0.001 (0.331)	loss 8.141 (7.756)	prob 3.967 (3.427)	GS 36.562 (34.030)	mem 76.205
Train: [36][240/1500]	BT 0.039 (0.356)	DT 0.001 (0.317)	loss 8.043 (7.768)	prob 3.716 (3.462)	GS 35.703 (33.804)	mem 76.205
Train: [36][250/1500]	BT 0.062 (0.350)	DT 0.010 (0.311)	loss 8.336 (7.745)	prob 3.871 (3.502)	GS 35.578 (33.447)	mem 76.206
Train: [36][260/1500]	BT 0.055 (0.346)	DT 0.001 (0.307)	loss 8.187 (7.754)	prob 3.968 (3.492)	GS 30.391 (32.750)	mem 76.205
Train: [36][270/1500]	BT 0.039 (0.342)	DT 0.001 (0.303)	loss 7.502 (7.769)	prob 3.986 (3.556)	GS 31.938 (33.466)	mem 76.205
Train: [36][280/1500]	BT 0.199 (0.340)	DT 0.160 (0.301)	loss 7.556 (7.744)	prob 3.822 (3.618)	GS 36.766 (33.020)	mem 76.205
Train: [36][290/1500]	BT 0.038 (0.335)	DT 0.000 (0.295)	loss 7.665 (7.703)	prob 3.639 (3.559)	GS 33.828 (32.653)	mem 76.221
Train: [36][300/1500]	BT 2.848 (0.336)	DT 2.809 (0.297)	loss 7.522 (7.689)	prob 4.613 (3.609)	GS 32.734 (32.403)	mem 76.216
Train: [36][310/1500]	BT 0.039 (0.327)	DT 0.001 (0.288)	loss 7.728 (7.836)	prob 3.535 (3.502)	GS 32.172 (31.967)	mem 76.216
Train: [36][320/1500]	BT 0.037 (0.324)	DT 0.001 (0.285)	loss 7.562 (7.794)	prob 3.863 (3.507)	GS 28.344 (31.996)	mem 76.213
Train: [36][330/1500]	BT 0.062 (0.328)	DT 0.016 (0.289)	loss 7.933 (7.772)	prob 3.293 (3.489)	GS 33.422 (31.917)	mem 76.212
Train: [36][340/1500]	BT 0.036 (0.320)	DT 0.000 (0.280)	loss 7.931 (7.779)	prob 3.459 (3.388)	GS 35.734 (31.985)	mem 76.212
Train: [36][350/1500]	BT 0.030 (0.345)	DT 0.000 (0.305)	loss 7.498 (7.761)	prob 3.860 (3.402)	GS 29.531 (32.313)	mem 76.221
Train: [36][360/1500]	BT 0.030 (0.336)	DT 0.000 (0.297)	loss 7.750 (7.686)	prob 3.523 (3.617)	GS 32.547 (32.388)	mem 76.221
Train: [36][370/1500]	BT 0.035 (0.328)	DT 0.001 (0.289)	loss 8.029 (7.881)	prob 2.780 (3.339)	GS 32.562 (32.523)	mem 76.222
Train: [36][380/1500]	BT 0.032 (0.343)	DT 0.002 (0.304)	loss 7.833 (7.872)	prob 3.605 (3.348)	GS 37.375 (32.689)	mem 76.235
Train: [36][390/1500]	BT 0.031 (0.335)	DT 0.001 (0.296)	loss 7.998 (7.882)	prob 2.701 (3.189)	GS 34.781 (33.254)	mem 76.236
Train: [36][400/1500]	BT 0.038 (0.343)	DT 0.001 (0.304)	loss 8.285 (7.899)	prob 3.524 (3.227)	GS 33.656 (33.205)	mem 76.238
Train: [36][410/1500]	BT 0.030 (0.348)	DT 0.000 (0.309)	loss 8.251 (7.882)	prob 2.144 (2.873)	GS 36.094 (34.945)	mem 76.238
Train: [36][420/1500]	BT 0.040 (0.341)	DT 0.001 (0.302)	loss 8.526 (8.004)	prob 2.859 (2.955)	GS 34.781 (33.195)	mem 76.237
Train: [36][430/1500]	BT 0.024 (0.344)	DT 0.000 (0.305)	loss 7.778 (7.984)	prob 4.002 (2.946)	GS 29.734 (32.779)	mem 76.235
Train: [36][440/1500]	BT 0.027 (0.337)	DT 0.000 (0.298)	loss 7.839 (7.970)	prob 3.872 (3.085)	GS 30.906 (32.408)	mem 76.119
Train: [36][450/1500]	BT 3.083 (0.337)	DT 3.057 (0.299)	loss 8.539 (7.974)	prob 2.429 (3.096)	GS 33.562 (32.464)	mem 76.144
Train: [36][460/1500]	BT 0.027 (0.330)	DT 0.000 (0.292)	loss 8.116 (8.137)	prob 3.403 (3.006)	GS 32.703 (33.103)	mem 76.144
Train: [36][470/1500]	BT 0.037 (0.325)	DT 0.001 (0.287)	loss 7.887 (8.092)	prob 3.548 (3.150)	GS 34.438 (33.076)	mem 76.145
Train: [36][480/1500]	BT 0.028 (0.328)	DT 0.000 (0.290)	loss 8.339 (7.980)	prob 3.839 (3.202)	GS 33.641 (32.688)	mem 76.149
Train: [36][490/1500]	BT 0.038 (0.322)	DT 0.001 (0.285)	loss 8.221 (8.005)	prob 3.226 (3.235)	GS 31.391 (32.538)	mem 76.150
Train: [36][500/1500]	BT 0.036 (0.337)	DT 0.001 (0.299)	loss 8.049 (8.019)	prob 3.198 (3.156)	GS 33.188 (33.296)	mem 76.168
Train: [36][510/1500]	BT 0.031 (0.331)	DT 0.000 (0.293)	loss 8.129 (8.077)	prob 3.544 (3.091)	GS 35.578 (33.131)	mem 76.169
Train: [36][520/1500]	BT 0.030 (0.340)	DT 0.000 (0.303)	loss 8.332 (8.035)	prob 3.831 (3.241)	GS 34.688 (32.298)	mem 76.170
Train: [36][530/1500]	BT 0.066 (0.335)	DT 0.016 (0.297)	loss 8.373 (8.050)	prob 3.295 (3.177)	GS 33.828 (32.339)	mem 76.170
Train: [36][540/1500]	BT 0.091 (0.330)	DT 0.019 (0.292)	loss 7.648 (8.050)	prob 4.124 (3.197)	GS 32.172 (32.275)	mem 76.170
Train: [36][550/1500]	BT 0.027 (0.345)	DT 0.000 (0.307)	loss 7.498 (8.008)	prob 3.513 (3.216)	GS 34.391 (32.356)	mem 76.154
Train: [36][560/1500]	BT 0.026 (0.339)	DT 0.000 (0.302)	loss 7.743 (7.877)	prob 3.846 (3.424)	GS 32.078 (32.456)	mem 76.154
Train: [36][570/1500]	BT 0.038 (0.339)	DT 0.001 (0.301)	loss 7.580 (7.894)	prob 4.261 (3.275)	GS 32.953 (33.072)	mem 76.157
Train: [36][580/1500]	BT 0.041 (0.333)	DT 0.001 (0.296)	loss 8.010 (7.919)	prob 3.939 (3.165)	GS 36.281 (33.172)	mem 76.157
Train: [36][590/1500]	BT 0.035 (0.328)	DT 0.000 (0.291)	loss 7.929 (7.932)	prob 3.466 (3.107)	GS 27.641 (33.138)	mem 76.156
Train: [36][600/1500]	BT 0.044 (0.331)	DT 0.004 (0.293)	loss 8.531 (7.947)	prob 2.856 (3.072)	GS 37.109 (33.331)	mem 76.158
Train: [36][610/1500]	BT 0.029 (0.326)	DT 0.000 (0.288)	loss 7.914 (7.947)	prob 3.782 (3.306)	GS 31.422 (31.831)	mem 76.158
Train: [36][620/1500]	BT 0.027 (0.329)	DT 0.000 (0.292)	loss 8.137 (7.974)	prob 2.430 (3.231)	GS 31.953 (32.688)	mem 76.159
Train: [36][630/1500]	BT 0.025 (0.324)	DT 0.000 (0.287)	loss 8.037 (7.954)	prob 3.118 (3.403)	GS 33.797 (32.147)	mem 76.159
Train: [36][640/1500]	BT 0.027 (0.320)	DT 0.000 (0.283)	loss 8.030 (7.945)	prob 3.870 (3.422)	GS 31.609 (31.711)	mem 76.158
Train: [36][650/1500]	BT 0.029 (0.324)	DT 0.000 (0.287)	loss 7.882 (7.919)	prob 3.740 (3.422)	GS 35.172 (31.630)	mem 76.161
Train: [36][660/1500]	BT 0.026 (0.319)	DT 0.000 (0.282)	loss 8.125 (8.118)	prob 3.806 (2.644)	GS 29.688 (32.286)	mem 76.160
Train: [36][670/1500]	BT 0.027 (0.323)	DT 0.000 (0.286)	loss 8.161 (8.056)	prob 3.746 (3.051)	GS 36.750 (31.950)	mem 76.179
Train: [36][680/1500]	BT 0.023 (0.319)	DT 0.000 (0.282)	loss 8.045 (8.069)	prob 3.078 (3.022)	GS 30.391 (32.367)	mem 76.178
Train: [36][690/1500]	BT 0.038 (0.319)	DT 0.000 (0.282)	loss 8.553 (8.114)	prob 3.873 (2.949)	GS 32.016 (32.096)	mem 76.182
Train: [36][700/1500]	BT 0.034 (0.315)	DT 0.000 (0.278)	loss 7.451 (8.090)	prob 3.147 (2.900)	GS 35.797 (32.157)	mem 76.182
Train: [36][710/1500]	BT 0.034 (0.311)	DT 0.000 (0.274)	loss 8.278 (8.009)	prob 3.022 (2.605)	GS 33.641 (32.070)	mem 76.183
Train: [36][720/1500]	BT 0.037 (0.312)	DT 0.001 (0.275)	loss 8.043 (7.985)	prob 3.830 (2.709)	GS 34.250 (32.133)	mem 76.185
Train: [36][730/1500]	BT 0.037 (0.308)	DT 0.001 (0.271)	loss 8.159 (8.011)	prob 3.253 (2.826)	GS 35.266 (32.457)	mem 76.185
Train: [36][740/1500]	BT 0.065 (0.309)	DT 0.016 (0.272)	loss 8.542 (7.959)	prob 2.917 (2.847)	GS 33.297 (32.503)	mem 76.189
Train: [36][750/1500]	BT 0.063 (0.306)	DT 0.003 (0.269)	loss 7.700 (7.966)	prob 3.507 (2.802)	GS 33.188 (32.688)	mem 76.190
Train: [36][760/1500]	BT 0.069 (0.311)	DT 0.015 (0.273)	loss 7.356 (7.975)	prob 3.717 (2.942)	GS 33.594 (33.361)	mem 76.190
Train: [36][770/1500]	BT 0.067 (0.310)	DT 0.006 (0.273)	loss 7.682 (7.906)	prob 3.532 (3.177)	GS 32.391 (32.423)	mem 76.190
Train: [36][780/1500]	BT 0.037 (0.311)	DT 0.001 (0.274)	loss 7.731 (7.899)	prob 3.497 (2.973)	GS 30.734 (32.959)	mem 76.193
Train: [36][790/1500]	BT 0.037 (0.310)	DT 0.001 (0.273)	loss 8.242 (7.961)	prob 2.859 (2.920)	GS 32.453 (32.719)	mem 76.194
Train: [36][800/1500]	BT 0.055 (0.307)	DT 0.004 (0.270)	loss 7.952 (7.960)	prob 3.821 (2.948)	GS 32.359 (32.687)	mem 76.194
Train: [36][810/1500]	BT 0.097 (0.309)	DT 0.014 (0.271)	loss 7.997 (8.159)	prob 3.363 (2.769)	GS 32.797 (32.203)	mem 76.194
Train: [36][820/1500]	BT 0.029 (0.311)	DT 0.000 (0.274)	loss 8.652 (8.095)	prob 3.283 (2.687)	GS 30.891 (32.843)	mem 76.198
Train: [36][830/1500]	BT 0.037 (0.308)	DT 0.001 (0.270)	loss 7.944 (8.117)	prob 3.442 (2.767)	GS 34.562 (32.633)	mem 76.198
Train: [36][840/1500]	BT 0.035 (0.310)	DT 0.000 (0.272)	loss 8.282 (8.114)	prob 2.712 (2.682)	GS 30.938 (32.605)	mem 76.200
Train: [36][850/1500]	BT 0.036 (0.307)	DT 0.000 (0.269)	loss 7.996 (8.088)	prob 3.219 (2.710)	GS 29.188 (32.614)	mem 76.199
Train: [36][860/1500]	BT 0.038 (0.304)	DT 0.001 (0.266)	loss 8.031 (8.011)	prob 2.891 (2.988)	GS 30.938 (32.631)	mem 76.199
Train: [36][870/1500]	BT 0.037 (0.304)	DT 0.001 (0.267)	loss 8.888 (8.052)	prob 2.148 (2.950)	GS 38.203 (33.452)	mem 76.200
Train: [36][880/1500]	BT 0.034 (0.301)	DT 0.001 (0.264)	loss 7.993 (8.099)	prob 3.856 (2.918)	GS 34.203 (33.280)	mem 76.201
Train: [36][890/1500]	BT 0.063 (0.307)	DT 0.003 (0.270)	loss 7.969 (8.080)	prob 2.688 (2.906)	GS 36.031 (33.584)	mem 76.202
Train: [36][900/1500]	BT 0.031 (0.306)	DT 0.000 (0.269)	loss 7.989 (8.032)	prob 3.462 (2.880)	GS 35.531 (33.592)	mem 76.203
Train: [36][910/1500]	BT 0.030 (0.308)	DT 0.000 (0.271)	loss 7.837 (8.085)	prob 3.179 (2.819)	GS 34.656 (32.608)	mem 76.202
Train: [36][920/1500]	BT 0.028 (0.305)	DT 0.000 (0.268)	loss 8.483 (8.133)	prob 3.061 (2.838)	GS 30.750 (31.905)	mem 76.201
Train: [36][930/1500]	BT 0.038 (0.302)	DT 0.001 (0.265)	loss 7.373 (8.126)	prob 3.243 (2.794)	GS 33.062 (32.403)	mem 76.202
Train: [36][940/1500]	BT 0.046 (0.304)	DT 0.006 (0.266)	loss 9.061 (8.090)	prob 2.954 (2.812)	GS 31.953 (32.174)	mem 76.205
Train: [36][950/1500]	BT 0.069 (0.301)	DT 0.002 (0.263)	loss 7.817 (8.061)	prob 3.922 (2.845)	GS 29.719 (32.086)	mem 76.205
Train: [36][960/1500]	BT 0.068 (0.303)	DT 0.014 (0.265)	loss 7.783 (7.872)	prob 3.147 (3.172)	GS 30.125 (31.962)	mem 76.205
Train: [36][970/1500]	BT 0.066 (0.301)	DT 0.022 (0.263)	loss 8.335 (7.942)	prob 4.263 (3.122)	GS 30.328 (32.485)	mem 76.207
Train: [36][980/1500]	BT 0.038 (0.299)	DT 0.001 (0.261)	loss 7.779 (7.962)	prob 2.682 (3.056)	GS 33.109 (32.760)	mem 76.206
Train: [36][990/1500]	BT 0.035 (0.300)	DT 0.001 (0.262)	loss 8.322 (7.949)	prob 3.115 (2.998)	GS 36.156 (32.351)	mem 76.209
Train: [36][1000/1500]	BT 0.037 (0.297)	DT 0.001 (0.259)	loss 8.177 (7.943)	prob 3.359 (3.050)	GS 34.375 (32.698)	mem 76.209
Train: [36][1010/1500]	BT 0.038 (0.296)	DT 0.001 (0.258)	loss 7.537 (7.953)	prob 2.997 (2.853)	GS 29.641 (32.894)	mem 76.209
Train: [36][1020/1500]	BT 0.038 (0.295)	DT 0.001 (0.257)	loss 8.229 (7.932)	prob 2.703 (2.756)	GS 32.078 (32.332)	mem 76.210
Train: [36][1030/1500]	BT 0.038 (0.295)	DT 0.001 (0.257)	loss 8.106 (7.925)	prob 3.926 (2.855)	GS 33.750 (32.061)	mem 76.239
Train: [36][1040/1500]	BT 0.040 (0.293)	DT 0.001 (0.256)	loss 8.214 (7.975)	prob 3.870 (2.897)	GS 29.344 (31.811)	mem 76.239
Train: [36][1050/1500]	BT 0.039 (0.292)	DT 0.001 (0.255)	loss 7.394 (7.954)	prob 4.058 (2.980)	GS 32.500 (31.890)	mem 76.239
Train: [36][1060/1500]	BT 0.039 (0.293)	DT 0.001 (0.255)	loss 8.084 (7.863)	prob 2.394 (2.868)	GS 29.672 (31.986)	mem 76.239
Train: [36][1070/1500]	BT 0.040 (0.291)	DT 0.001 (0.253)	loss 8.602 (7.846)	prob 3.370 (2.947)	GS 34.969 (32.171)	mem 76.239
Train: [36][1080/1500]	BT 0.056 (0.289)	DT 0.001 (0.251)	loss 7.857 (7.848)	prob 3.442 (3.022)	GS 33.531 (32.120)	mem 76.238
Train: [36][1090/1500]	BT 0.084 (0.292)	DT 0.030 (0.254)	loss 7.538 (7.877)	prob 4.124 (2.999)	GS 33.094 (32.136)	mem 76.239
Train: [36][1100/1500]	BT 0.030 (0.296)	DT 0.000 (0.258)	loss 8.868 (7.927)	prob 3.045 (3.012)	GS 33.859 (32.399)	mem 76.239
Train: [36][1110/1500]	BT 0.058 (0.294)	DT 0.011 (0.256)	loss 7.913 (7.794)	prob 3.914 (3.397)	GS 34.391 (33.070)	mem 76.239
Train: [36][1120/1500]	BT 0.035 (0.292)	DT 0.000 (0.254)	loss 9.129 (7.902)	prob 2.989 (3.062)	GS 37.156 (32.888)	mem 76.239
Train: [36][1130/1500]	BT 0.031 (0.305)	DT 0.000 (0.267)	loss 8.082 (7.906)	prob 2.034 (3.000)	GS 38.359 (33.933)	mem 76.239
Train: [36][1140/1500]	BT 0.035 (0.303)	DT 0.001 (0.265)	loss 8.071 (7.870)	prob 3.950 (2.964)	GS 31.078 (33.327)	mem 76.241
Train: [36][1150/1500]	BT 0.031 (0.305)	DT 0.000 (0.267)	loss 7.908 (7.922)	prob 3.618 (2.947)	GS 32.344 (33.070)	mem 76.242
Train: [36][1160/1500]	BT 0.064 (0.302)	DT 0.016 (0.264)	loss 8.010 (8.099)	prob 3.222 (2.811)	GS 34.656 (32.477)	mem 76.242
Train: [36][1170/1500]	BT 0.035 (0.307)	DT 0.001 (0.269)	loss 7.942 (8.039)	prob 3.585 (2.816)	GS 32.031 (33.386)	mem 76.241
Train: [36][1180/1500]	BT 0.039 (0.306)	DT 0.001 (0.268)	loss 8.803 (8.084)	prob 2.153 (2.604)	GS 33.375 (34.054)	mem 76.241
Train: [36][1190/1500]	BT 0.039 (0.304)	DT 0.001 (0.266)	loss 9.548 (8.116)	prob 2.593 (2.603)	GS 32.906 (33.821)	mem 76.241
Train: [36][1200/1500]	BT 0.031 (0.305)	DT 0.000 (0.267)	loss 7.772 (8.111)	prob 2.952 (2.560)	GS 33.938 (33.771)	mem 76.241
Train: [36][1210/1500]	BT 0.044 (0.303)	DT 0.001 (0.265)	loss 8.481 (8.035)	prob 2.707 (2.242)	GS 34.328 (33.189)	mem 76.242
Train: [36][1220/1500]	BT 0.038 (0.307)	DT 0.001 (0.268)	loss 8.062 (7.991)	prob 3.006 (2.580)	GS 37.484 (33.207)	mem 76.243
Train: [36][1230/1500]	BT 0.031 (0.306)	DT 0.000 (0.268)	loss 8.159 (8.047)	prob 3.360 (2.568)	GS 34.422 (33.101)	mem 76.245
Train: [36][1240/1500]	BT 0.039 (0.304)	DT 0.001 (0.265)	loss 8.318 (8.071)	prob 3.373 (2.514)	GS 29.375 (33.089)	mem 76.245
Train: [36][1250/1500]	BT 0.040 (0.303)	DT 0.001 (0.265)	loss 8.130 (8.102)	prob 2.673 (2.519)	GS 34.609 (33.048)	mem 76.246
Train: [36][1260/1500]	BT 0.039 (0.302)	DT 0.001 (0.263)	loss 8.540 (8.071)	prob 3.641 (3.154)	GS 36.250 (31.163)	mem 76.247
Train: [36][1270/1500]	BT 0.061 (0.305)	DT 0.003 (0.266)	loss 10.110 (8.257)	prob 2.692 (2.839)	GS 36.828 (32.198)	mem 76.246
Train: [36][1280/1500]	BT 0.072 (0.303)	DT 0.006 (0.264)	loss 7.678 (8.116)	prob 3.117 (2.974)	GS 36.734 (32.335)	mem 76.246
Train: [36][1290/1500]	BT 0.023 (0.308)	DT 0.000 (0.269)	loss 9.295 (8.131)	prob 2.223 (2.955)	GS 36.312 (32.529)	mem 76.246
Train: [36][1300/1500]	BT 0.025 (0.306)	DT 0.000 (0.267)	loss 8.930 (8.139)	prob 3.100 (2.928)	GS 32.234 (32.424)	mem 76.247
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [36][1310/1500]	BT 0.039 (0.304)	DT 0.001 (0.265)	loss 8.980 (8.358)	prob 2.541 (2.681)	GS 30.266 (32.325)	mem 76.247
Train: [36][1320/1500]	BT 0.063 (0.304)	DT 0.004 (0.266)	loss 8.464 (8.247)	prob 3.491 (2.830)	GS 33.422 (32.177)	mem 76.248
Train: [36][1330/1500]	BT 0.077 (0.302)	DT 0.007 (0.264)	loss 8.242 (8.180)	prob 1.722 (2.936)	GS 36.484 (32.282)	mem 76.248
Train: [36][1340/1500]	BT 0.027 (0.305)	DT 0.000 (0.267)	loss 8.025 (8.205)	prob 3.062 (2.862)	GS 37.953 (32.338)	mem 76.255
Train: [36][1350/1500]	BT 0.037 (0.303)	DT 0.000 (0.265)	loss 8.514 (8.169)	prob 3.145 (2.901)	GS 38.094 (32.347)	mem 76.257
Train: [36][1360/1500]	BT 0.038 (0.303)	DT 0.001 (0.264)	loss 8.295 (8.244)	prob 2.474 (2.958)	GS 33.547 (32.875)	mem 76.267
Train: [36][1370/1500]	BT 0.066 (0.304)	DT 0.001 (0.265)	loss 8.950 (8.260)	prob 3.087 (3.004)	GS 31.984 (32.263)	mem 76.266
Train: [36][1380/1500]	BT 0.060 (0.302)	DT 0.002 (0.263)	loss 8.223 (8.210)	prob 4.257 (3.154)	GS 32.531 (32.702)	mem 76.268
Train: [36][1390/1500]	BT 0.022 (0.311)	DT 0.000 (0.272)	loss 8.227 (8.198)	prob 3.980 (3.271)	GS 30.422 (32.364)	mem 76.265
Train: [36][1400/1500]	BT 0.030 (0.309)	DT 0.000 (0.270)	loss 7.586 (8.170)	prob 3.294 (3.285)	GS 29.672 (32.181)	mem 76.271
Train: [36][1410/1500]	BT 2.934 (0.309)	DT 2.894 (0.270)	loss 8.045 (8.153)	prob 4.136 (3.175)	GS 32.000 (32.408)	mem 76.168
Train: [36][1420/1500]	BT 0.037 (0.307)	DT 0.000 (0.268)	loss 9.073 (8.201)	prob 2.447 (3.139)	GS 37.812 (33.165)	mem 76.169
Train: [36][1430/1500]	BT 0.037 (0.305)	DT 0.000 (0.267)	loss 8.196 (8.173)	prob 3.511 (3.122)	GS 30.641 (33.040)	mem 76.170
Train: [36][1440/1500]	BT 0.027 (0.306)	DT 0.000 (0.268)	loss 7.921 (8.164)	prob 4.501 (3.368)	GS 34.453 (32.656)	mem 76.173
Train: [36][1450/1500]	BT 0.037 (0.305)	DT 0.001 (0.266)	loss 7.947 (8.185)	prob 4.279 (3.397)	GS 33.141 (32.173)	mem 76.174
Train: [36][1460/1500]	BT 0.028 (0.305)	DT 0.000 (0.266)	loss 9.281 (8.110)	prob 2.888 (3.575)	GS 33.078 (32.011)	mem 75.294
Train: [36][1470/1500]	BT 0.026 (0.303)	DT 0.000 (0.264)	loss 8.913 (8.169)	prob 3.358 (3.564)	GS 31.016 (31.827)	mem 75.222
Train: [36][1480/1500]	BT 0.026 (0.301)	DT 0.000 (0.263)	loss 8.553 (8.251)	prob 3.892 (3.563)	GS 32.938 (31.938)	mem 75.221
Train: [36][1490/1500]	BT 0.025 (0.301)	DT 0.000 (0.263)	loss 8.163 (8.267)	prob 4.488 (3.536)	GS 35.250 (32.801)	mem 13.996
Train: [36][1500/1500]	BT 0.026 (0.299)	DT 0.000 (0.261)	loss 8.327 (8.242)	prob 4.331 (3.555)	GS 36.188 (32.651)	mem 13.996
Train: [36][1510/1500]	BT 0.024 (0.298)	DT 0.000 (0.260)	loss 7.997 (8.045)	prob 4.421 (4.238)	GS 33.938 (32.466)	mem 11.148
epoch 36, total time 449.89
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [37][1/1500]	BT 19.111 (19.111)	DT 19.053 (19.053)	loss 7.810 (7.810)	prob 4.288 (4.288)	GS 30.938 (30.938)	mem 74.799
Train: [37][10/1500]	BT 0.057 (2.615)	DT 0.016 (2.571)	loss 7.761 (7.849)	prob 3.114 (3.568)	GS 32.844 (34.387)	mem 74.905
Train: [37][20/1500]	BT 0.025 (1.322)	DT 0.000 (1.286)	loss 8.119 (7.913)	prob 4.690 (3.750)	GS 35.906 (33.595)	mem 74.912
Train: [37][30/1500]	BT 0.091 (1.170)	DT 0.001 (1.129)	loss 8.418 (7.921)	prob 4.246 (3.728)	GS 36.156 (33.794)	mem 75.172
Train: [37][40/1500]	BT 0.081 (0.900)	DT 0.006 (0.849)	loss 7.711 (7.866)	prob 4.920 (3.824)	GS 30.172 (33.200)	mem 75.222
Train: [37][50/1500]	BT 3.690 (0.810)	DT 3.617 (0.754)	loss 7.690 (7.921)	prob 4.369 (3.825)	GS 34.703 (33.325)	mem 75.765
Train: [37][60/1500]	BT 0.057 (0.749)	DT 0.011 (0.693)	loss 8.798 (8.118)	prob 4.205 (4.034)	GS 33.156 (32.519)	mem 76.016
Train: [37][70/1500]	BT 0.036 (0.865)	DT 0.000 (0.811)	loss 8.069 (8.115)	prob 4.682 (3.975)	GS 34.859 (33.164)	mem 76.127
Train: [37][80/1500]	BT 0.031 (0.760)	DT 0.000 (0.710)	loss 8.597 (8.119)	prob 4.610 (3.997)	GS 38.000 (33.148)	mem 76.128
Train: [37][90/1500]	BT 0.037 (0.680)	DT 0.001 (0.631)	loss 7.744 (8.059)	prob 4.861 (4.029)	GS 34.281 (33.420)	mem 76.130
Train: [37][100/1500]	BT 0.024 (0.653)	DT 0.000 (0.606)	loss 8.309 (8.062)	prob 3.947 (4.045)	GS 35.188 (33.483)	mem 76.155
Train: [37][110/1500]	BT 0.038 (0.597)	DT 0.001 (0.551)	loss 8.086 (7.945)	prob 4.727 (4.407)	GS 34.266 (32.964)	mem 76.156
Train: [37][120/1500]	BT 0.034 (0.576)	DT 0.000 (0.531)	loss 7.680 (7.929)	prob 4.677 (4.442)	GS 29.000 (32.479)	mem 76.158
Train: [37][130/1500]	BT 0.033 (0.534)	DT 0.000 (0.491)	loss 8.856 (7.954)	prob 3.347 (4.317)	GS 36.297 (32.702)	mem 76.159
Train: [37][140/1500]	BT 0.068 (0.499)	DT 0.012 (0.456)	loss 7.953 (7.952)	prob 5.155 (4.332)	GS 36.531 (32.654)	mem 76.162
Train: [37][150/1500]	BT 0.031 (0.507)	DT 0.000 (0.464)	loss 8.193 (7.958)	prob 3.954 (4.354)	GS 35.062 (32.548)	mem 76.165
Train: [37][160/1500]	BT 0.054 (0.479)	DT 0.007 (0.436)	loss 7.672 (7.789)	prob 4.391 (4.109)	GS 35.422 (32.491)	mem 76.167
Train: [37][170/1500]	BT 0.024 (0.564)	DT 0.000 (0.520)	loss 7.556 (7.755)	prob 4.946 (4.236)	GS 35.406 (33.339)	mem 76.185
Train: [37][180/1500]	BT 0.030 (0.534)	DT 0.000 (0.492)	loss 7.644 (7.776)	prob 4.785 (4.261)	GS 34.672 (33.248)	mem 76.186
Train: [37][190/1500]	BT 0.032 (0.508)	DT 0.000 (0.466)	loss 7.856 (7.808)	prob 5.145 (4.251)	GS 34.656 (33.192)	mem 76.187
Train: [37][200/1500]	BT 0.029 (0.498)	DT 0.000 (0.457)	loss 7.610 (7.823)	prob 5.006 (4.284)	GS 35.281 (33.377)	mem 76.197
Train: [37][210/1500]	BT 0.034 (0.476)	DT 0.000 (0.435)	loss 7.732 (7.693)	prob 4.870 (4.452)	GS 31.406 (32.422)	mem 76.198
Train: [37][220/1500]	BT 0.072 (0.476)	DT 0.014 (0.435)	loss 7.689 (7.700)	prob 3.208 (4.288)	GS 29.500 (33.302)	mem 76.202
Train: [37][230/1500]	BT 0.037 (0.457)	DT 0.000 (0.416)	loss 7.879 (7.770)	prob 4.595 (4.197)	GS 38.891 (33.316)	mem 76.204
Train: [37][240/1500]	BT 0.034 (0.453)	DT 0.001 (0.412)	loss 7.749 (7.775)	prob 5.375 (4.269)	GS 33.234 (33.613)	mem 76.208
Train: [37][250/1500]	BT 0.058 (0.443)	DT 0.011 (0.402)	loss 7.560 (7.767)	prob 5.442 (4.233)	GS 28.891 (33.113)	mem 76.208
Train: [37][260/1500]	BT 0.037 (0.445)	DT 0.000 (0.405)	loss 8.445 (7.749)	prob 4.545 (4.708)	GS 35.234 (32.770)	mem 76.208
Train: [37][270/1500]	BT 0.037 (0.430)	DT 0.000 (0.390)	loss 8.139 (7.731)	prob 4.136 (4.440)	GS 35.125 (32.793)	mem 76.209
Train: [37][280/1500]	BT 0.056 (0.429)	DT 0.006 (0.389)	loss 7.448 (7.758)	prob 4.545 (4.402)	GS 31.453 (32.581)	mem 76.213
Train: [37][290/1500]	BT 0.035 (0.423)	DT 0.001 (0.382)	loss 7.795 (7.728)	prob 4.755 (4.393)	GS 35.578 (32.588)	mem 76.212
Train: [37][300/1500]	BT 0.033 (0.421)	DT 0.000 (0.381)	loss 7.950 (7.719)	prob 4.173 (4.368)	GS 35.766 (32.623)	mem 76.214
Train: [37][310/1500]	BT 0.033 (0.409)	DT 0.001 (0.369)	loss 7.355 (7.676)	prob 4.552 (4.318)	GS 34.828 (31.797)	mem 76.215
Train: [37][320/1500]	BT 0.037 (0.409)	DT 0.000 (0.369)	loss 7.876 (7.664)	prob 4.405 (4.121)	GS 34.938 (32.364)	mem 76.217
Train: [37][330/1500]	BT 0.037 (0.398)	DT 0.000 (0.358)	loss 8.137 (7.686)	prob 3.840 (4.054)	GS 31.281 (32.557)	mem 76.217
Train: [37][340/1500]	BT 0.027 (0.401)	DT 0.000 (0.362)	loss 7.895 (7.681)	prob 3.820 (3.999)	GS 32.109 (32.664)	mem 76.220
Train: [37][350/1500]	BT 0.026 (0.390)	DT 0.000 (0.351)	loss 7.548 (7.670)	prob 4.805 (4.029)	GS 32.531 (32.514)	mem 76.221
Train: [37][360/1500]	BT 0.037 (0.382)	DT 0.000 (0.343)	loss 7.332 (7.787)	prob 4.968 (3.838)	GS 33.828 (32.431)	mem 76.222
Train: [37][370/1500]	BT 0.028 (0.380)	DT 0.000 (0.341)	loss 7.761 (7.695)	prob 4.669 (3.646)	GS 34.484 (32.172)	mem 76.225
Train: [37][380/1500]	BT 0.037 (0.371)	DT 0.001 (0.332)	loss 7.588 (7.706)	prob 3.175 (3.600)	GS 34.359 (32.501)	mem 76.226
Train: [37][390/1500]	BT 0.034 (0.377)	DT 0.000 (0.338)	loss 7.661 (7.704)	prob 3.637 (3.513)	GS 33.438 (32.371)	mem 76.230
Train: [37][400/1500]	BT 0.035 (0.368)	DT 0.000 (0.329)	loss 7.944 (7.703)	prob 3.295 (3.428)	GS 31.375 (32.444)	mem 76.230
Train: [37][410/1500]	BT 0.085 (0.362)	DT 0.009 (0.323)	loss 7.706 (7.744)	prob 3.042 (2.939)	GS 32.875 (33.509)	mem 76.232
Train: [37][420/1500]	BT 0.073 (0.373)	DT 0.005 (0.333)	loss 7.753 (7.766)	prob 3.223 (2.888)	GS 31.938 (33.331)	mem 76.232
Train: [37][430/1500]	BT 0.061 (0.365)	DT 0.015 (0.326)	loss 7.562 (7.760)	prob 2.469 (2.894)	GS 34.469 (33.208)	mem 76.235
Train: [37][440/1500]	BT 0.031 (0.370)	DT 0.000 (0.330)	loss 7.729 (7.770)	prob 3.672 (2.747)	GS 34.594 (33.225)	mem 76.240
Train: [37][450/1500]	BT 0.037 (0.362)	DT 0.000 (0.323)	loss 7.849 (7.768)	prob 3.079 (2.781)	GS 30.969 (33.015)	mem 76.268
Train: [37][460/1500]	BT 0.056 (0.366)	DT 0.002 (0.327)	loss 8.054 (7.824)	prob 2.200 (2.221)	GS 32.125 (33.033)	mem 76.270
Train: [37][470/1500]	BT 0.060 (0.360)	DT 0.007 (0.320)	loss 7.747 (7.911)	prob 2.784 (2.087)	GS 35.453 (32.770)	mem 76.269
Train: [37][480/1500]	BT 0.038 (0.367)	DT 0.001 (0.327)	loss 8.076 (7.854)	prob 1.622 (2.173)	GS 30.500 (32.436)	mem 76.268
Train: [37][490/1500]	BT 0.030 (0.360)	DT 0.001 (0.320)	loss 7.754 (7.822)	prob 2.553 (2.174)	GS 35.203 (32.713)	mem 76.268
Train: [37][500/1500]	BT 0.039 (0.353)	DT 0.001 (0.314)	loss 8.841 (7.856)	prob 2.097 (2.079)	GS 34.000 (33.126)	mem 76.269
Train: [37][510/1500]	BT 0.033 (0.356)	DT 0.000 (0.317)	loss 8.523 (7.951)	prob 2.432 (2.211)	GS 35.109 (32.569)	mem 76.268
Train: [37][520/1500]	BT 0.062 (0.350)	DT 0.023 (0.311)	loss 8.324 (8.030)	prob 1.703 (1.972)	GS 34.562 (33.568)	mem 76.268
Train: [37][530/1500]	BT 0.025 (0.353)	DT 0.001 (0.314)	loss 7.975 (8.088)	prob 2.136 (1.809)	GS 29.234 (33.630)	mem 76.288
Train: [37][540/1500]	BT 0.035 (0.347)	DT 0.000 (0.308)	loss 7.703 (8.061)	prob 3.007 (1.890)	GS 35.391 (33.640)	mem 76.290
Train: [37][550/1500]	BT 0.053 (0.342)	DT 0.006 (0.303)	loss 7.588 (8.083)	prob 3.392 (2.024)	GS 35.859 (33.283)	mem 76.289
Train: [37][560/1500]	BT 0.034 (0.350)	DT 0.000 (0.311)	loss 8.478 (8.109)	prob 2.473 (2.111)	GS 37.484 (33.211)	mem 76.277
Train: [37][570/1500]	BT 0.037 (0.352)	DT 0.001 (0.313)	loss 7.919 (7.994)	prob 3.254 (2.081)	GS 36.125 (33.632)	mem 76.277
Train: [37][580/1500]	BT 0.037 (0.347)	DT 0.001 (0.307)	loss 8.087 (7.974)	prob 2.056 (2.221)	GS 34.125 (33.498)	mem 76.278
Train: [37][590/1500]	BT 0.035 (0.341)	DT 0.001 (0.302)	loss 8.253 (7.950)	prob 3.603 (2.378)	GS 37.484 (33.259)	mem 76.278
Train: [37][600/1500]	BT 0.028 (0.345)	DT 0.000 (0.306)	loss 8.772 (7.971)	prob 3.024 (2.435)	GS 31.453 (33.007)	mem 76.279
Train: [37][610/1500]	BT 0.039 (0.340)	DT 0.001 (0.301)	loss 7.372 (7.897)	prob 3.139 (2.812)	GS 30.859 (33.645)	mem 76.279
Train: [37][620/1500]	BT 0.028 (0.343)	DT 0.000 (0.304)	loss 7.975 (7.920)	prob 3.183 (3.011)	GS 37.797 (32.916)	mem 76.279
Train: [37][630/1500]	BT 0.028 (0.339)	DT 0.000 (0.300)	loss 8.311 (7.945)	prob 3.157 (2.926)	GS 34.531 (32.883)	mem 76.281
Train: [37][640/1500]	BT 0.032 (0.334)	DT 0.000 (0.295)	loss 8.580 (7.946)	prob 2.650 (2.941)	GS 35.000 (32.699)	mem 76.280
Train: [37][650/1500]	BT 0.026 (0.337)	DT 0.000 (0.298)	loss 8.472 (7.972)	prob 2.712 (2.862)	GS 35.797 (32.629)	mem 76.297
Train: [37][660/1500]	BT 0.026 (0.332)	DT 0.000 (0.293)	loss 8.659 (8.032)	prob 3.066 (3.034)	GS 32.109 (32.347)	mem 76.296
Train: [37][670/1500]	BT 0.038 (0.333)	DT 0.001 (0.295)	loss 7.858 (8.046)	prob 4.320 (3.270)	GS 30.641 (31.705)	mem 76.289
Train: [37][680/1500]	BT 0.039 (0.329)	DT 0.001 (0.290)	loss 7.903 (8.043)	prob 2.501 (3.139)	GS 35.453 (31.843)	mem 76.289
Train: [37][690/1500]	BT 0.039 (0.329)	DT 0.001 (0.291)	loss 7.833 (8.055)	prob 2.750 (3.053)	GS 33.734 (32.025)	mem 76.285
Train: [37][700/1500]	BT 0.039 (0.325)	DT 0.001 (0.287)	loss 8.263 (7.977)	prob 2.751 (3.084)	GS 36.344 (31.917)	mem 76.286
Train: [37][710/1500]	BT 0.033 (0.321)	DT 0.001 (0.283)	loss 8.720 (7.910)	prob 2.763 (3.040)	GS 33.562 (33.203)	mem 76.285
Train: [37][720/1500]	BT 0.037 (0.322)	DT 0.001 (0.284)	loss 7.816 (7.960)	prob 2.517 (2.882)	GS 35.844 (32.956)	mem 76.284
Train: [37][730/1500]	BT 0.066 (0.321)	DT 0.002 (0.282)	loss 8.083 (7.933)	prob 3.417 (2.900)	GS 32.172 (33.035)	mem 76.283
Train: [37][740/1500]	BT 0.031 (0.335)	DT 0.000 (0.296)	loss 8.020 (7.911)	prob 3.493 (3.033)	GS 31.641 (33.248)	mem 76.290
Train: [37][750/1500]	BT 0.029 (0.331)	DT 0.000 (0.292)	loss 7.884 (7.930)	prob 4.019 (3.038)	GS 33.469 (33.152)	mem 76.290
Train: [37][760/1500]	BT 3.981 (0.332)	DT 3.942 (0.294)	loss 8.014 (7.823)	prob 4.329 (3.158)	GS 32.016 (32.694)	mem 76.301
Train: [37][770/1500]	BT 0.037 (0.328)	DT 0.001 (0.290)	loss 7.679 (7.805)	prob 4.115 (3.505)	GS 28.844 (32.867)	mem 76.301
Train: [37][780/1500]	BT 0.030 (0.325)	DT 0.000 (0.286)	loss 7.673 (7.819)	prob 4.230 (3.602)	GS 28.469 (32.184)	mem 76.292
Train: [37][790/1500]	BT 0.029 (0.327)	DT 0.000 (0.289)	loss 7.600 (7.797)	prob 2.697 (3.570)	GS 36.641 (32.604)	mem 76.193
Train: [37][800/1500]	BT 0.036 (0.323)	DT 0.000 (0.285)	loss 7.909 (7.796)	prob 3.931 (3.493)	GS 31.453 (32.275)	mem 76.193
Train: [37][810/1500]	BT 0.025 (0.325)	DT 0.000 (0.287)	loss 7.812 (7.755)	prob 3.725 (3.512)	GS 36.531 (31.938)	mem 76.193
Train: [37][820/1500]	BT 0.064 (0.321)	DT 0.014 (0.283)	loss 7.458 (7.815)	prob 3.402 (3.574)	GS 35.016 (31.583)	mem 76.194
Train: [37][830/1500]	BT 0.056 (0.318)	DT 0.007 (0.280)	loss 7.661 (7.773)	prob 3.826 (3.518)	GS 33.031 (31.836)	mem 76.196
Train: [37][840/1500]	BT 0.060 (0.323)	DT 0.002 (0.284)	loss 7.671 (7.763)	prob 3.441 (3.499)	GS 30.641 (31.857)	mem 76.198
Train: [37][850/1500]	BT 0.031 (0.323)	DT 0.001 (0.285)	loss 7.432 (7.742)	prob 3.665 (3.451)	GS 36.062 (32.292)	mem 76.200
Train: [37][860/1500]	BT 0.086 (0.322)	DT 0.016 (0.284)	loss 7.715 (7.923)	prob 3.675 (3.438)	GS 31.766 (33.808)	mem 76.219
Train: [37][870/1500]	BT 0.027 (0.330)	DT 0.000 (0.292)	loss 7.865 (7.859)	prob 3.826 (3.563)	GS 37.000 (33.230)	mem 76.209
Train: [37][880/1500]	BT 0.031 (0.327)	DT 0.000 (0.288)	loss 7.515 (7.786)	prob 4.202 (3.561)	GS 34.594 (33.433)	mem 76.209
Train: [37][890/1500]	BT 0.045 (0.330)	DT 0.000 (0.291)	loss 8.048 (7.756)	prob 3.330 (3.536)	GS 32.922 (33.534)	mem 76.209
Train: [37][900/1500]	BT 0.039 (0.326)	DT 0.000 (0.288)	loss 7.861 (7.742)	prob 3.676 (3.528)	GS 35.484 (33.344)	mem 76.210
Train: [37][910/1500]	BT 0.061 (0.323)	DT 0.003 (0.285)	loss 8.100 (7.715)	prob 3.473 (3.572)	GS 32.594 (32.227)	mem 76.210
Train: [37][920/1500]	BT 0.030 (0.330)	DT 0.000 (0.291)	loss 7.541 (7.740)	prob 3.732 (3.621)	GS 29.078 (32.069)	mem 76.208
Train: [37][930/1500]	BT 0.029 (0.327)	DT 0.001 (0.288)	loss 8.347 (7.747)	prob 3.869 (3.617)	GS 29.938 (32.357)	mem 76.208
Train: [37][940/1500]	BT 0.029 (0.329)	DT 0.000 (0.290)	loss 7.735 (7.758)	prob 4.244 (3.617)	GS 30.047 (32.741)	mem 76.209
Train: [37][950/1500]	BT 0.036 (0.326)	DT 0.001 (0.287)	loss 7.478 (7.732)	prob 3.789 (3.668)	GS 32.156 (32.558)	mem 76.209
Train: [37][960/1500]	BT 0.039 (0.323)	DT 0.001 (0.285)	loss 7.244 (7.571)	prob 4.166 (3.572)	GS 31.719 (32.498)	mem 76.210
Train: [37][970/1500]	BT 0.039 (0.323)	DT 0.001 (0.284)	loss 7.232 (7.522)	prob 3.990 (3.907)	GS 29.094 (31.866)	mem 76.212
Train: [37][980/1500]	BT 0.039 (0.323)	DT 0.001 (0.285)	loss 7.484 (7.558)	prob 4.225 (3.877)	GS 31.266 (32.181)	mem 76.210
Train: [37][990/1500]	BT 0.039 (0.320)	DT 0.001 (0.282)	loss 8.234 (7.601)	prob 3.519 (3.811)	GS 31.859 (32.400)	mem 76.209
Train: [37][1000/1500]	BT 0.039 (0.317)	DT 0.001 (0.279)	loss 7.810 (7.601)	prob 3.180 (3.754)	GS 34.438 (32.781)	mem 76.209
Train: [37][1010/1500]	BT 0.068 (0.320)	DT 0.002 (0.281)	loss 7.734 (7.592)	prob 4.245 (3.605)	GS 32.031 (32.497)	mem 76.209
Train: [37][1020/1500]	BT 0.030 (0.321)	DT 0.000 (0.283)	loss 8.075 (7.633)	prob 3.662 (3.683)	GS 30.344 (32.588)	mem 76.208
Train: [37][1030/1500]	BT 0.039 (0.320)	DT 0.001 (0.281)	loss 7.222 (7.584)	prob 4.620 (3.673)	GS 34.125 (32.716)	mem 76.209
Train: [37][1040/1500]	BT 0.025 (0.320)	DT 0.000 (0.281)	loss 7.540 (7.566)	prob 4.271 (3.744)	GS 34.031 (32.500)	mem 76.228
Train: [37][1050/1500]	BT 0.036 (0.317)	DT 0.001 (0.279)	loss 7.350 (7.528)	prob 3.479 (3.772)	GS 32.031 (32.227)	mem 76.230
Train: [37][1060/1500]	BT 0.036 (0.320)	DT 0.000 (0.281)	loss 7.299 (7.314)	prob 4.020 (4.037)	GS 34.953 (32.552)	mem 76.232
Train: [37][1070/1500]	BT 0.037 (0.317)	DT 0.000 (0.279)	loss 7.333 (7.398)	prob 4.480 (3.787)	GS 32.391 (32.489)	mem 76.232
Train: [37][1080/1500]	BT 0.038 (0.314)	DT 0.001 (0.276)	loss 7.449 (7.399)	prob 3.392 (3.757)	GS 35.703 (32.517)	mem 76.231
Train: [37][1090/1500]	BT 0.036 (0.315)	DT 0.001 (0.277)	loss 7.464 (7.424)	prob 3.322 (3.730)	GS 33.828 (32.395)	mem 76.234
Train: [37][1100/1500]	BT 0.037 (0.313)	DT 0.000 (0.274)	loss 7.573 (7.449)	prob 3.939 (3.706)	GS 31.703 (32.535)	mem 76.235
Train: [37][1110/1500]	BT 0.037 (0.318)	DT 0.000 (0.279)	loss 7.897 (7.405)	prob 3.775 (3.684)	GS 32.219 (32.164)	mem 76.234
Train: [37][1120/1500]	BT 0.068 (0.315)	DT 0.014 (0.277)	loss 7.288 (7.419)	prob 4.419 (3.587)	GS 28.672 (31.913)	mem 76.235
Train: [37][1130/1500]	BT 0.035 (0.316)	DT 0.000 (0.277)	loss 7.590 (7.409)	prob 3.631 (3.655)	GS 37.594 (32.292)	mem 76.236
Train: [37][1140/1500]	BT 0.036 (0.314)	DT 0.001 (0.275)	loss 7.467 (7.401)	prob 3.462 (3.625)	GS 31.906 (32.390)	mem 76.236
Train: [37][1150/1500]	BT 0.037 (0.311)	DT 0.001 (0.273)	loss 7.745 (7.410)	prob 3.481 (3.598)	GS 34.688 (32.430)	mem 76.236
Train: [37][1160/1500]	BT 0.037 (0.314)	DT 0.001 (0.275)	loss 7.435 (7.482)	prob 3.090 (3.303)	GS 33.297 (31.716)	mem 76.237
Train: [37][1170/1500]	BT 0.030 (0.318)	DT 0.000 (0.280)	loss 7.762 (7.465)	prob 3.016 (3.258)	GS 32.188 (32.835)	mem 76.240
Train: [37][1180/1500]	BT 0.036 (0.316)	DT 0.001 (0.277)	loss 7.331 (7.466)	prob 3.456 (3.337)	GS 35.641 (32.743)	mem 76.242
Train: [37][1190/1500]	BT 0.030 (0.317)	DT 0.000 (0.278)	loss 7.673 (7.467)	prob 3.068 (3.315)	GS 35.688 (32.703)	mem 76.244
Train: [37][1200/1500]	BT 0.037 (0.314)	DT 0.001 (0.276)	loss 7.784 (7.459)	prob 3.630 (3.344)	GS 34.812 (32.417)	mem 76.244
Train: [37][1210/1500]	BT 0.033 (0.315)	DT 0.000 (0.277)	loss 7.395 (7.291)	prob 3.616 (3.222)	GS 33.500 (33.250)	mem 76.243
Train: [37][1220/1500]	BT 0.024 (0.313)	DT 0.000 (0.275)	loss 7.449 (7.399)	prob 3.035 (3.140)	GS 33.891 (33.238)	mem 76.245
Train: [37][1230/1500]	BT 0.038 (0.311)	DT 0.001 (0.273)	loss 7.620 (7.396)	prob 3.289 (3.143)	GS 34.844 (33.128)	mem 76.248
Train: [37][1240/1500]	BT 0.028 (0.312)	DT 0.000 (0.274)	loss 7.584 (7.404)	prob 2.417 (3.010)	GS 35.312 (32.825)	mem 76.249
Train: [37][1250/1500]	BT 0.027 (0.310)	DT 0.000 (0.272)	loss 7.371 (7.389)	prob 2.968 (2.985)	GS 36.531 (32.779)	mem 76.248
Train: [37][1260/1500]	BT 0.030 (0.311)	DT 0.000 (0.273)	loss 7.607 (7.389)	prob 2.662 (2.627)	GS 34.234 (33.217)	mem 76.251
Train: [37][1270/1500]	BT 0.026 (0.309)	DT 0.000 (0.271)	loss 7.983 (7.352)	prob 2.495 (2.599)	GS 31.641 (32.728)	mem 76.253
Train: [37][1280/1500]	BT 0.038 (0.307)	DT 0.001 (0.269)	loss 7.356 (7.315)	prob 3.278 (2.566)	GS 33.984 (32.758)	mem 76.252
Train: [37][1290/1500]	BT 0.027 (0.308)	DT 0.000 (0.270)	loss 7.038 (7.347)	prob 2.581 (2.518)	GS 29.859 (32.382)	mem 76.253
Train: [37][1300/1500]	BT 0.028 (0.305)	DT 0.000 (0.268)	loss 6.946 (7.317)	prob 2.391 (2.467)	GS 32.875 (32.422)	mem 76.251
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [37][1310/1500]	BT 0.028 (0.309)	DT 0.000 (0.272)	loss 7.241 (7.411)	prob 1.672 (1.871)	GS 33.359 (33.256)	mem 76.251
Train: [37][1320/1500]	BT 0.028 (0.307)	DT 0.000 (0.269)	loss 7.085 (7.442)	prob 2.120 (1.830)	GS 35.094 (32.225)	mem 76.252
Train: [37][1330/1500]	BT 0.056 (0.309)	DT 0.011 (0.271)	loss 7.921 (7.458)	prob 1.696 (1.875)	GS 36.547 (32.905)	mem 76.254
Train: [37][1340/1500]	BT 0.052 (0.307)	DT 0.003 (0.269)	loss 8.039 (7.488)	prob 1.930 (1.856)	GS 33.297 (33.007)	mem 76.255
Train: [37][1350/1500]	BT 0.060 (0.305)	DT 0.016 (0.267)	loss 7.871 (7.491)	prob 2.495 (1.949)	GS 32.719 (32.567)	mem 76.255
Train: [37][1360/1500]	BT 0.027 (0.306)	DT 0.000 (0.269)	loss 7.799 (7.759)	prob 2.312 (2.048)	GS 32.656 (31.461)	mem 76.254
Train: [37][1370/1500]	BT 0.038 (0.305)	DT 0.001 (0.267)	loss 8.211 (7.676)	prob 2.675 (2.108)	GS 34.453 (32.676)	mem 76.254
Train: [37][1380/1500]	BT 0.038 (0.305)	DT 0.001 (0.267)	loss 7.702 (7.625)	prob 3.410 (2.274)	GS 34.125 (32.150)	mem 76.254
Train: [37][1390/1500]	BT 0.037 (0.303)	DT 0.001 (0.265)	loss 7.421 (7.631)	prob 1.860 (2.229)	GS 32.844 (32.511)	mem 76.260
Train: [37][1400/1500]	BT 0.038 (0.304)	DT 0.001 (0.266)	loss 7.367 (7.615)	prob 3.470 (2.317)	GS 32.688 (32.401)	mem 76.284
Train: [37][1410/1500]	BT 0.038 (0.302)	DT 0.001 (0.264)	loss 7.327 (7.602)	prob 1.736 (2.297)	GS 32.250 (33.494)	mem 76.285
Train: [37][1420/1500]	BT 0.029 (0.303)	DT 0.000 (0.266)	loss 7.943 (7.741)	prob 3.589 (2.411)	GS 31.719 (32.581)	mem 76.287
Train: [37][1430/1500]	BT 0.039 (0.301)	DT 0.000 (0.264)	loss 7.786 (7.743)	prob 3.334 (2.557)	GS 35.406 (32.484)	mem 76.287
Train: [37][1440/1500]	BT 0.052 (0.299)	DT 0.010 (0.262)	loss 7.529 (7.733)	prob 3.459 (2.598)	GS 31.375 (32.334)	mem 76.289
Train: [37][1450/1500]	BT 0.030 (0.305)	DT 0.000 (0.268)	loss 8.054 (7.733)	prob 2.931 (2.586)	GS 33.078 (32.636)	mem 76.289
Train: [37][1460/1500]	BT 0.024 (0.303)	DT 0.000 (0.266)	loss 7.943 (7.791)	prob 2.924 (2.652)	GS 31.750 (32.378)	mem 76.288
Train: [37][1470/1500]	BT 0.026 (0.304)	DT 0.000 (0.267)	loss 7.646 (7.669)	prob 3.245 (3.095)	GS 33.219 (31.877)	mem 75.044
Train: [37][1480/1500]	BT 0.026 (0.302)	DT 0.000 (0.265)	loss 7.755 (7.716)	prob 3.833 (3.030)	GS 31.188 (31.926)	mem 75.045
Train: [37][1490/1500]	BT 0.025 (0.302)	DT 0.000 (0.264)	loss 8.026 (7.724)	prob 2.241 (3.119)	GS 34.375 (32.046)	mem 11.157
Train: [37][1500/1500]	BT 0.034 (0.300)	DT 0.000 (0.263)	loss 8.353 (7.716)	prob 2.173 (3.140)	GS 36.062 (32.227)	mem 11.157
Train: [37][1510/1500]	BT 0.034 (0.298)	DT 0.000 (0.261)	loss 7.960 (7.830)	prob 2.260 (3.050)	GS 35.250 (32.188)	mem 11.157
epoch 37, total time 450.37
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [38][1/1500]	BT 18.214 (18.214)	DT 18.163 (18.163)	loss 7.466 (7.466)	prob 3.347 (3.347)	GS 28.953 (28.953)	mem 74.612
Train: [38][10/1500]	BT 0.056 (2.263)	DT 0.017 (2.222)	loss 9.013 (7.836)	prob 1.933 (2.983)	GS 34.453 (34.569)	mem 75.024
Train: [38][20/1500]	BT 0.031 (1.159)	DT 0.001 (1.119)	loss 7.719 (7.702)	prob 3.620 (3.106)	GS 31.656 (33.413)	mem 75.026
Train: [38][30/1500]	BT 1.585 (1.006)	DT 1.544 (0.966)	loss 7.819 (7.649)	prob 3.727 (3.114)	GS 35.297 (33.149)	mem 75.346
Train: [38][40/1500]	BT 0.045 (0.845)	DT 0.012 (0.804)	loss 7.923 (7.655)	prob 3.444 (3.190)	GS 33.578 (33.001)	mem 75.742
Train: [38][50/1500]	BT 0.028 (0.980)	DT 0.000 (0.940)	loss 8.186 (7.661)	prob 3.657 (3.238)	GS 34.000 (32.926)	mem 76.205
Train: [38][60/1500]	BT 0.032 (0.822)	DT 0.000 (0.783)	loss 7.799 (7.708)	prob 3.928 (3.505)	GS 35.781 (32.533)	mem 76.207
Train: [38][70/1500]	BT 0.037 (0.709)	DT 0.000 (0.671)	loss 7.340 (7.733)	prob 4.356 (3.663)	GS 29.281 (32.188)	mem 76.209
Train: [38][80/1500]	BT 0.060 (0.680)	DT 0.001 (0.640)	loss 7.634 (7.722)	prob 4.036 (3.773)	GS 36.578 (32.278)	mem 76.268
Train: [38][90/1500]	BT 0.062 (0.612)	DT 0.001 (0.569)	loss 8.391 (7.677)	prob 3.509 (3.814)	GS 34.062 (32.301)	mem 76.269
Train: [38][100/1500]	BT 0.037 (0.620)	DT 0.000 (0.577)	loss 8.185 (7.708)	prob 3.922 (3.779)	GS 34.734 (32.459)	mem 76.277
Train: [38][110/1500]	BT 0.037 (0.567)	DT 0.001 (0.525)	loss 7.843 (7.678)	prob 4.059 (3.682)	GS 35.156 (32.722)	mem 76.278
Train: [38][120/1500]	BT 3.822 (0.555)	DT 3.784 (0.512)	loss 8.028 (7.786)	prob 3.797 (3.665)	GS 32.547 (33.178)	mem 76.289
Train: [38][130/1500]	BT 0.038 (0.515)	DT 0.001 (0.473)	loss 8.253 (7.778)	prob 4.073 (3.689)	GS 33.734 (32.978)	mem 76.291
Train: [38][140/1500]	BT 0.038 (0.481)	DT 0.001 (0.439)	loss 7.899 (7.747)	prob 4.393 (3.698)	GS 32.891 (32.809)	mem 76.290
Train: [38][150/1500]	BT 0.026 (0.482)	DT 0.000 (0.441)	loss 7.562 (7.765)	prob 3.467 (3.714)	GS 33.000 (32.733)	mem 76.204
Train: [38][160/1500]	BT 0.037 (0.454)	DT 0.001 (0.414)	loss 7.577 (7.562)	prob 5.180 (3.970)	GS 31.234 (31.773)	mem 76.205
Train: [38][170/1500]	BT 0.039 (0.457)	DT 0.001 (0.417)	loss 7.648 (7.570)	prob 3.130 (4.082)	GS 33.969 (31.970)	mem 76.210
Train: [38][180/1500]	BT 0.035 (0.433)	DT 0.000 (0.394)	loss 7.452 (7.587)	prob 4.341 (3.952)	GS 32.000 (32.015)	mem 76.211
Train: [38][190/1500]	BT 0.037 (0.412)	DT 0.001 (0.373)	loss 7.871 (7.606)	prob 2.962 (3.864)	GS 37.672 (32.203)	mem 76.211
Train: [38][200/1500]	BT 0.030 (0.413)	DT 0.000 (0.374)	loss 7.250 (7.603)	prob 4.024 (3.837)	GS 34.641 (32.368)	mem 76.221
Train: [38][210/1500]	BT 0.036 (0.395)	DT 0.000 (0.357)	loss 7.643 (7.630)	prob 4.020 (3.888)	GS 29.719 (31.930)	mem 76.222
Train: [38][220/1500]	BT 0.031 (0.396)	DT 0.000 (0.358)	loss 7.773 (7.673)	prob 4.322 (3.847)	GS 35.203 (32.709)	mem 76.403
Train: [38][230/1500]	BT 0.057 (0.381)	DT 0.006 (0.343)	loss 7.036 (7.647)	prob 3.321 (3.700)	GS 35.297 (33.122)	mem 76.416
Train: [38][240/1500]	BT 4.491 (0.386)	DT 4.445 (0.347)	loss 7.501 (7.610)	prob 2.698 (3.686)	GS 34.953 (32.870)	mem 76.393
Train: [38][250/1500]	BT 0.030 (0.391)	DT 0.000 (0.353)	loss 7.601 (7.609)	prob 3.978 (3.711)	GS 32.828 (32.848)	mem 76.392
Train: [38][260/1500]	BT 0.077 (0.378)	DT 0.001 (0.340)	loss 7.338 (7.582)	prob 3.921 (3.928)	GS 35.828 (33.484)	mem 76.393
Train: [38][270/1500]	BT 0.055 (0.386)	DT 0.002 (0.347)	loss 7.317 (7.591)	prob 4.462 (4.006)	GS 33.812 (32.909)	mem 76.404
Train: [38][280/1500]	BT 0.058 (0.374)	DT 0.003 (0.335)	loss 7.657 (7.561)	prob 4.306 (4.047)	GS 32.609 (32.545)	mem 76.404
Train: [38][290/1500]	BT 0.040 (0.384)	DT 0.000 (0.345)	loss 7.988 (7.577)	prob 4.019 (3.886)	GS 30.172 (32.747)	mem 76.388
Train: [38][300/1500]	BT 0.034 (0.373)	DT 0.001 (0.333)	loss 7.668 (7.551)	prob 4.046 (3.880)	GS 32.500 (32.668)	mem 76.387
Train: [38][310/1500]	BT 0.038 (0.362)	DT 0.001 (0.323)	loss 7.708 (7.475)	prob 4.411 (3.587)	GS 31.219 (31.991)	mem 76.387
Train: [38][320/1500]	BT 0.036 (0.365)	DT 0.001 (0.326)	loss 7.714 (7.471)	prob 3.348 (3.650)	GS 33.641 (33.162)	mem 76.388
Train: [38][330/1500]	BT 0.038 (0.355)	DT 0.001 (0.316)	loss 7.181 (7.446)	prob 4.238 (3.707)	GS 28.453 (32.915)	mem 76.388
Train: [38][340/1500]	BT 0.037 (0.357)	DT 0.001 (0.319)	loss 7.208 (7.422)	prob 3.344 (3.653)	GS 34.844 (33.018)	mem 76.389
Train: [38][350/1500]	BT 0.036 (0.348)	DT 0.001 (0.310)	loss 7.439 (7.428)	prob 3.692 (3.629)	GS 32.422 (33.009)	mem 76.389
Train: [38][360/1500]	BT 0.065 (0.340)	DT 0.003 (0.301)	loss 7.416 (7.390)	prob 4.076 (3.639)	GS 35.594 (33.066)	mem 76.391
Train: [38][370/1500]	BT 0.025 (0.355)	DT 0.000 (0.316)	loss 7.276 (7.367)	prob 3.610 (3.598)	GS 36.938 (32.416)	mem 76.391
Train: [38][380/1500]	BT 0.039 (0.346)	DT 0.001 (0.308)	loss 7.624 (7.378)	prob 3.933 (3.489)	GS 32.281 (32.491)	mem 76.392
Train: [38][390/1500]	BT 0.025 (0.349)	DT 0.000 (0.311)	loss 7.531 (7.364)	prob 3.309 (3.494)	GS 32.844 (32.831)	mem 76.316
Train: [38][400/1500]	BT 0.040 (0.341)	DT 0.001 (0.303)	loss 7.679 (7.359)	prob 3.490 (3.481)	GS 30.547 (32.933)	mem 76.316
Train: [38][410/1500]	BT 0.033 (0.345)	DT 0.001 (0.307)	loss 7.764 (7.310)	prob 3.317 (3.703)	GS 29.641 (33.023)	mem 76.312
Train: [38][420/1500]	BT 0.041 (0.337)	DT 0.011 (0.299)	loss 7.151 (7.310)	prob 3.884 (3.647)	GS 35.078 (33.030)	mem 76.311
Train: [38][430/1500]	BT 0.039 (0.331)	DT 0.001 (0.292)	loss 7.247 (7.336)	prob 4.664 (3.617)	GS 32.672 (32.420)	mem 76.311
Train: [38][440/1500]	BT 0.037 (0.330)	DT 0.001 (0.292)	loss 7.305 (7.336)	prob 3.240 (3.607)	GS 37.406 (32.356)	mem 76.322
Train: [38][450/1500]	BT 0.052 (0.324)	DT 0.014 (0.286)	loss 7.190 (7.332)	prob 3.473 (3.572)	GS 35.328 (32.634)	mem 76.323
Train: [38][460/1500]	BT 0.037 (0.324)	DT 0.001 (0.286)	loss 7.129 (7.279)	prob 3.544 (3.288)	GS 36.516 (33.603)	mem 76.327
Train: [38][470/1500]	BT 0.076 (0.322)	DT 0.011 (0.283)	loss 7.294 (7.259)	prob 3.544 (3.371)	GS 27.312 (31.695)	mem 76.328
Train: [38][480/1500]	BT 0.070 (0.325)	DT 0.004 (0.287)	loss 7.079 (7.247)	prob 3.492 (3.384)	GS 32.188 (31.707)	mem 76.330
Train: [38][490/1500]	BT 0.023 (0.335)	DT 0.000 (0.296)	loss 7.151 (7.254)	prob 3.436 (3.387)	GS 31.578 (31.661)	mem 76.332
Train: [38][500/1500]	BT 0.036 (0.329)	DT 0.001 (0.290)	loss 7.225 (7.256)	prob 3.187 (3.292)	GS 33.438 (32.073)	mem 76.333
Train: [38][510/1500]	BT 0.037 (0.324)	DT 0.001 (0.286)	loss 7.078 (7.191)	prob 3.321 (3.289)	GS 35.734 (33.681)	mem 76.335
Train: [38][520/1500]	BT 0.024 (0.327)	DT 0.000 (0.288)	loss 7.236 (7.279)	prob 3.469 (3.086)	GS 30.531 (33.327)	mem 76.335
Train: [38][530/1500]	BT 0.037 (0.321)	DT 0.001 (0.283)	loss 7.167 (7.273)	prob 3.006 (3.191)	GS 34.438 (33.329)	mem 76.337
Train: [38][540/1500]	BT 0.027 (0.331)	DT 0.000 (0.293)	loss 7.181 (7.250)	prob 3.394 (3.274)	GS 38.344 (33.152)	mem 76.338
Train: [38][550/1500]	BT 0.037 (0.325)	DT 0.001 (0.287)	loss 7.277 (7.256)	prob 3.466 (3.245)	GS 33.328 (33.324)	mem 76.340
Train: [38][560/1500]	BT 0.030 (0.331)	DT 0.001 (0.293)	loss 7.219 (7.230)	prob 2.713 (3.298)	GS 35.734 (34.123)	mem 76.342
Train: [38][570/1500]	BT 0.025 (0.325)	DT 0.000 (0.287)	loss 7.697 (7.275)	prob 3.582 (3.374)	GS 36.594 (33.980)	mem 76.342
Train: [38][580/1500]	BT 0.038 (0.320)	DT 0.001 (0.283)	loss 7.158 (7.248)	prob 2.926 (3.362)	GS 33.422 (33.924)	mem 76.343
Train: [38][590/1500]	BT 0.037 (0.321)	DT 0.000 (0.283)	loss 7.173 (7.251)	prob 3.769 (3.345)	GS 28.188 (33.539)	mem 76.346
Train: [38][600/1500]	BT 0.038 (0.316)	DT 0.000 (0.278)	loss 7.183 (7.244)	prob 3.485 (3.309)	GS 29.875 (33.335)	mem 76.346
Train: [38][610/1500]	BT 0.031 (0.318)	DT 0.000 (0.280)	loss 6.949 (7.144)	prob 3.361 (3.221)	GS 33.188 (32.920)	mem 76.347
Train: [38][620/1500]	BT 0.029 (0.313)	DT 0.000 (0.276)	loss 7.106 (7.161)	prob 2.617 (3.055)	GS 32.547 (32.788)	mem 76.347
Train: [38][630/1500]	BT 0.097 (0.309)	DT 0.011 (0.271)	loss 7.018 (7.159)	prob 2.886 (3.007)	GS 36.812 (33.026)	mem 76.348
Train: [38][640/1500]	BT 0.031 (0.319)	DT 0.000 (0.282)	loss 7.086 (7.156)	prob 2.827 (3.022)	GS 33.594 (32.662)	mem 76.350
Train: [38][650/1500]	BT 0.026 (0.333)	DT 0.000 (0.295)	loss 7.294 (7.154)	prob 3.512 (2.987)	GS 30.078 (32.653)	mem 76.350
Train: [38][660/1500]	BT 0.022 (0.328)	DT 0.000 (0.291)	loss 7.260 (7.196)	prob 3.238 (3.148)	GS 32.859 (33.633)	mem 76.349
Train: [38][670/1500]	BT 0.035 (0.324)	DT 0.000 (0.286)	loss 7.076 (7.140)	prob 3.450 (3.218)	GS 34.812 (32.453)	mem 76.350
Train: [38][680/1500]	BT 0.036 (0.324)	DT 0.000 (0.286)	loss 7.261 (7.143)	prob 2.626 (3.087)	GS 33.156 (32.549)	mem 76.352
Train: [38][690/1500]	BT 0.036 (0.319)	DT 0.000 (0.282)	loss 7.547 (7.155)	prob 3.261 (3.000)	GS 37.000 (32.468)	mem 76.352
Train: [38][700/1500]	BT 0.033 (0.319)	DT 0.000 (0.282)	loss 6.996 (7.154)	prob 2.529 (2.939)	GS 35.844 (32.325)	mem 76.352
Train: [38][710/1500]	BT 0.032 (0.316)	DT 0.000 (0.279)	loss 6.954 (7.127)	prob 3.207 (2.435)	GS 33.500 (31.084)	mem 76.353
Train: [38][720/1500]	BT 0.037 (0.315)	DT 0.000 (0.278)	loss 7.278 (7.191)	prob 2.583 (2.470)	GS 35.094 (32.234)	mem 76.354
Train: [38][730/1500]	BT 0.038 (0.315)	DT 0.001 (0.278)	loss 8.059 (7.190)	prob 2.049 (2.507)	GS 31.938 (32.318)	mem 76.355
Train: [38][740/1500]	BT 0.037 (0.311)	DT 0.001 (0.274)	loss 7.121 (7.171)	prob 2.332 (2.446)	GS 37.516 (32.492)	mem 76.355
Train: [38][750/1500]	BT 0.033 (0.310)	DT 0.000 (0.273)	loss 6.975 (7.166)	prob 2.561 (2.368)	GS 35.594 (32.367)	mem 76.357
Train: [38][760/1500]	BT 0.032 (0.310)	DT 0.000 (0.273)	loss 7.128 (7.270)	prob 2.398 (2.046)	GS 33.469 (32.256)	mem 76.362
Train: [38][770/1500]	BT 0.037 (0.308)	DT 0.001 (0.271)	loss 6.944 (7.244)	prob 3.158 (1.960)	GS 31.281 (32.573)	mem 76.363
Train: [38][780/1500]	BT 0.036 (0.309)	DT 0.000 (0.272)	loss 7.758 (7.234)	prob 1.979 (2.018)	GS 36.422 (32.771)	mem 76.368
Train: [38][790/1500]	BT 0.037 (0.306)	DT 0.001 (0.268)	loss 7.566 (7.263)	prob 2.042 (1.990)	GS 30.156 (32.423)	mem 76.392
Train: [38][800/1500]	BT 0.039 (0.308)	DT 0.001 (0.271)	loss 7.234 (7.256)	prob 2.123 (2.009)	GS 34.297 (32.500)	mem 76.393
Train: [38][810/1500]	BT 0.039 (0.304)	DT 0.001 (0.267)	loss 7.548 (7.337)	prob 2.743 (2.001)	GS 37.875 (31.297)	mem 76.393
Train: [38][820/1500]	BT 0.131 (0.302)	DT 0.061 (0.264)	loss 7.572 (7.391)	prob 2.448 (1.941)	GS 32.031 (31.246)	mem 76.395
Train: [38][830/1500]	BT 0.033 (0.310)	DT 0.001 (0.272)	loss 6.987 (7.353)	prob 2.086 (2.002)	GS 29.719 (32.014)	mem 76.395
Train: [38][840/1500]	BT 0.026 (0.306)	DT 0.000 (0.269)	loss 7.924 (7.390)	prob 2.021 (1.938)	GS 32.844 (32.380)	mem 76.395
Train: [38][850/1500]	BT 0.039 (0.307)	DT 0.001 (0.269)	loss 8.342 (7.448)	prob 1.609 (1.896)	GS 34.234 (32.645)	mem 76.396
Train: [38][860/1500]	BT 0.039 (0.304)	DT 0.001 (0.266)	loss 7.563 (7.448)	prob 1.947 (2.083)	GS 36.938 (34.286)	mem 76.395
Train: [38][870/1500]	BT 0.054 (0.301)	DT 0.006 (0.263)	loss 7.371 (7.473)	prob 2.107 (1.998)	GS 33.703 (34.134)	mem 76.395
Train: [38][880/1500]	BT 0.040 (0.301)	DT 0.001 (0.264)	loss 7.868 (7.507)	prob 2.264 (2.070)	GS 30.562 (34.074)	mem 76.397
Train: [38][890/1500]	BT 0.040 (0.298)	DT 0.001 (0.261)	loss 7.882 (7.530)	prob 2.152 (2.125)	GS 38.516 (34.137)	mem 76.397
Train: [38][900/1500]	BT 0.056 (0.300)	DT 0.008 (0.262)	loss 7.505 (7.570)	prob 3.530 (2.230)	GS 38.578 (33.797)	mem 76.397
Train: [38][910/1500]	BT 0.028 (0.304)	DT 0.001 (0.266)	loss 8.107 (7.507)	prob 2.398 (2.790)	GS 33.375 (34.405)	mem 76.397
Train: [38][920/1500]	BT 0.039 (0.301)	DT 0.001 (0.264)	loss 7.830 (7.552)	prob 3.081 (2.902)	GS 34.266 (34.065)	mem 76.397
Train: [38][930/1500]	BT 0.039 (0.299)	DT 0.001 (0.262)	loss 7.998 (7.590)	prob 3.628 (2.953)	GS 29.703 (33.145)	mem 76.397
Train: [38][940/1500]	BT 0.039 (0.303)	DT 0.001 (0.265)	loss 7.497 (7.603)	prob 2.948 (2.878)	GS 32.078 (33.289)	mem 76.398
Train: [38][950/1500]	BT 0.039 (0.300)	DT 0.001 (0.262)	loss 8.186 (7.618)	prob 2.837 (2.844)	GS 35.766 (33.260)	mem 76.400
Train: [38][960/1500]	BT 0.030 (0.302)	DT 0.000 (0.264)	loss 7.870 (7.736)	prob 3.137 (3.039)	GS 32.250 (32.930)	mem 76.399
Train: [38][970/1500]	BT 0.064 (0.300)	DT 0.001 (0.263)	loss 7.965 (7.694)	prob 3.484 (3.059)	GS 31.281 (32.470)	mem 76.397
Train: [38][980/1500]	BT 0.042 (0.298)	DT 0.001 (0.260)	loss 8.159 (7.681)	prob 3.332 (3.151)	GS 34.109 (32.088)	mem 76.398
Train: [38][990/1500]	BT 0.031 (0.304)	DT 0.000 (0.266)	loss 7.575 (7.666)	prob 2.836 (3.133)	GS 36.609 (32.388)	mem 76.395
Train: [38][1000/1500]	BT 0.028 (0.301)	DT 0.000 (0.263)	loss 8.041 (7.674)	prob 3.377 (3.070)	GS 31.750 (32.549)	mem 76.395
Train: [38][1010/1500]	BT 0.039 (0.301)	DT 0.001 (0.263)	loss 7.516 (7.675)	prob 3.958 (3.201)	GS 38.234 (32.962)	mem 76.396
Train: [38][1020/1500]	BT 0.038 (0.299)	DT 0.001 (0.261)	loss 7.545 (7.660)	prob 3.434 (3.018)	GS 36.734 (33.161)	mem 76.396
Train: [38][1030/1500]	BT 0.039 (0.300)	DT 0.001 (0.262)	loss 7.542 (7.579)	prob 3.106 (2.898)	GS 35.797 (33.291)	mem 76.398
Train: [38][1040/1500]	BT 0.038 (0.297)	DT 0.001 (0.260)	loss 6.948 (7.571)	prob 3.850 (3.003)	GS 34.953 (33.094)	mem 76.396
Train: [38][1050/1500]	BT 0.037 (0.295)	DT 0.001 (0.257)	loss 7.874 (7.593)	prob 2.624 (2.995)	GS 32.766 (33.098)	mem 76.396
Train: [38][1060/1500]	BT 0.056 (0.296)	DT 0.006 (0.258)	loss 7.806 (7.622)	prob 3.415 (2.810)	GS 34.719 (34.289)	mem 76.403
Train: [38][1070/1500]	BT 0.044 (0.294)	DT 0.001 (0.256)	loss 7.157 (7.541)	prob 3.442 (3.035)	GS 30.953 (33.474)	mem 76.403
Train: [38][1080/1500]	BT 0.028 (0.295)	DT 0.000 (0.257)	loss 7.239 (7.542)	prob 3.756 (3.181)	GS 34.078 (33.177)	mem 76.418
Train: [38][1090/1500]	BT 0.038 (0.293)	DT 0.001 (0.255)	loss 7.341 (7.551)	prob 3.932 (3.231)	GS 32.094 (33.186)	mem 76.419
Train: [38][1100/1500]	BT 0.038 (0.291)	DT 0.001 (0.253)	loss 7.572 (7.544)	prob 3.549 (3.236)	GS 33.484 (33.142)	mem 76.419
Train: [38][1110/1500]	BT 0.026 (0.297)	DT 0.000 (0.259)	loss 7.125 (7.396)	prob 3.222 (2.910)	GS 34.875 (33.827)	mem 76.320
Train: [38][1120/1500]	BT 0.027 (0.294)	DT 0.000 (0.256)	loss 7.568 (7.510)	prob 4.146 (3.183)	GS 29.047 (33.087)	mem 76.321
Train: [38][1130/1500]	BT 0.037 (0.292)	DT 0.000 (0.254)	loss 7.599 (7.514)	prob 3.287 (3.310)	GS 36.688 (33.364)	mem 76.323
Train: [38][1140/1500]	BT 0.048 (0.293)	DT 0.007 (0.256)	loss 7.486 (7.491)	prob 3.092 (3.284)	GS 28.312 (33.282)	mem 76.321
Train: [38][1150/1500]	BT 0.037 (0.291)	DT 0.001 (0.253)	loss 7.232 (7.476)	prob 3.716 (3.251)	GS 36.031 (33.064)	mem 76.322
Train: [38][1160/1500]	BT 0.036 (0.293)	DT 0.000 (0.256)	loss 7.364 (7.257)	prob 3.177 (3.659)	GS 37.234 (32.258)	mem 76.322
Train: [38][1170/1500]	BT 0.041 (0.291)	DT 0.001 (0.253)	loss 7.848 (7.407)	prob 3.533 (3.358)	GS 28.641 (32.811)	mem 76.321
Train: [38][1180/1500]	BT 0.038 (0.294)	DT 0.000 (0.257)	loss 7.439 (7.439)	prob 3.093 (3.293)	GS 33.641 (32.686)	mem 76.332
Train: [38][1190/1500]	BT 0.068 (0.292)	DT 0.013 (0.255)	loss 7.597 (7.424)	prob 2.853 (3.258)	GS 35.406 (33.080)	mem 76.332
Train: [38][1200/1500]	BT 0.038 (0.290)	DT 0.001 (0.253)	loss 7.371 (7.408)	prob 3.370 (3.264)	GS 31.750 (33.138)	mem 76.331
Train: [38][1210/1500]	BT 0.057 (0.293)	DT 0.006 (0.255)	loss 7.128 (7.419)	prob 3.497 (3.251)	GS 34.188 (33.886)	mem 76.342
Train: [38][1220/1500]	BT 0.037 (0.292)	DT 0.000 (0.254)	loss 7.578 (7.398)	prob 3.263 (3.235)	GS 33.500 (34.078)	mem 76.344
Train: [38][1230/1500]	BT 0.038 (0.291)	DT 0.001 (0.253)	loss 7.221 (7.369)	prob 3.332 (3.331)	GS 33.812 (33.776)	mem 76.329
Train: [38][1240/1500]	BT 0.038 (0.294)	DT 0.001 (0.256)	loss 7.092 (7.403)	prob 4.110 (3.211)	GS 28.750 (34.340)	mem 76.328
Train: [38][1250/1500]	BT 0.065 (0.292)	DT 0.014 (0.254)	loss 7.620 (7.416)	prob 3.561 (3.235)	GS 33.625 (34.043)	mem 76.327
Train: [38][1260/1500]	BT 0.028 (0.296)	DT 0.000 (0.258)	loss 6.981 (7.338)	prob 4.225 (3.505)	GS 34.812 (33.583)	mem 76.329
Train: [38][1270/1500]	BT 0.032 (0.294)	DT 0.001 (0.256)	loss 7.239 (7.339)	prob 3.637 (3.533)	GS 32.281 (32.641)	mem 76.330
Train: [38][1280/1500]	BT 0.041 (0.295)	DT 0.001 (0.257)	loss 7.186 (7.351)	prob 3.289 (3.500)	GS 33.922 (33.100)	mem 76.332
Train: [38][1290/1500]	BT 0.039 (0.293)	DT 0.001 (0.255)	loss 7.765 (7.346)	prob 2.483 (3.399)	GS 40.859 (33.284)	mem 76.331
Train: [38][1300/1500]	BT 0.059 (0.295)	DT 0.002 (0.257)	loss 7.324 (7.337)	prob 3.039 (3.395)	GS 34.109 (33.227)	mem 76.333
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [38][1310/1500]	BT 0.055 (0.293)	DT 0.001 (0.255)	loss 7.389 (7.333)	prob 3.335 (3.239)	GS 33.344 (32.169)	mem 76.334
Train: [38][1320/1500]	BT 0.054 (0.292)	DT 0.001 (0.253)	loss 7.378 (7.290)	prob 2.781 (3.259)	GS 27.203 (31.998)	mem 76.334
Train: [38][1330/1500]	BT 0.033 (0.303)	DT 0.001 (0.264)	loss 7.631 (7.315)	prob 2.870 (3.197)	GS 33.047 (32.473)	mem 75.052
Train: [38][1340/1500]	BT 0.034 (0.301)	DT 0.001 (0.262)	loss 7.427 (7.339)	prob 3.707 (3.217)	GS 33.219 (32.555)	mem 75.054
Train: [38][1350/1500]	BT 0.026 (0.299)	DT 0.000 (0.260)	loss 7.411 (7.322)	prob 3.092 (3.171)	GS 33.141 (32.282)	mem 75.054
Train: [38][1360/1500]	BT 0.058 (0.299)	DT 0.011 (0.261)	loss 7.456 (7.291)	prob 3.142 (3.070)	GS 34.969 (32.189)	mem 75.056
Train: [38][1370/1500]	BT 0.058 (0.297)	DT 0.014 (0.259)	loss 7.089 (7.314)	prob 2.953 (3.184)	GS 33.391 (33.186)	mem 75.055
Train: [38][1380/1500]	BT 0.041 (0.307)	DT 0.001 (0.269)	loss 7.517 (7.304)	prob 3.378 (3.197)	GS 37.016 (32.931)	mem 75.056
Train: [38][1390/1500]	BT 0.030 (0.305)	DT 0.001 (0.267)	loss 7.228 (7.304)	prob 3.539 (3.119)	GS 32.641 (33.116)	mem 75.056
Train: [38][1400/1500]	BT 0.037 (0.303)	DT 0.001 (0.265)	loss 7.056 (7.301)	prob 3.700 (3.160)	GS 34.391 (33.107)	mem 75.057
Train: [38][1410/1500]	BT 0.029 (0.304)	DT 0.000 (0.266)	loss 7.139 (7.161)	prob 3.349 (3.607)	GS 30.656 (32.114)	mem 75.073
Train: [38][1420/1500]	BT 0.037 (0.302)	DT 0.000 (0.264)	loss 7.012 (7.145)	prob 3.391 (3.346)	GS 31.484 (32.438)	mem 75.073
Train: [38][1430/1500]	BT 0.050 (0.304)	DT 0.001 (0.266)	loss 7.357 (7.155)	prob 3.010 (3.321)	GS 38.297 (32.821)	mem 75.075
Train: [38][1440/1500]	BT 0.037 (0.302)	DT 0.001 (0.264)	loss 7.158 (7.164)	prob 3.283 (3.284)	GS 32.438 (32.766)	mem 75.076
Train: [38][1450/1500]	BT 0.077 (0.300)	DT 0.000 (0.262)	loss 7.021 (7.172)	prob 2.923 (3.227)	GS 33.797 (32.485)	mem 75.076
Train: [38][1460/1500]	BT 0.026 (0.300)	DT 0.000 (0.262)	loss 7.480 (7.160)	prob 3.713 (2.989)	GS 34.609 (33.198)	mem 74.715
Train: [38][1470/1500]	BT 0.035 (0.299)	DT 0.001 (0.261)	loss 6.896 (7.161)	prob 3.673 (3.046)	GS 32.766 (32.509)	mem 74.607
Train: [38][1480/1500]	BT 0.027 (0.299)	DT 0.000 (0.261)	loss 7.403 (7.168)	prob 3.089 (3.013)	GS 33.391 (32.221)	mem 26.803
Train: [38][1490/1500]	BT 0.027 (0.297)	DT 0.000 (0.259)	loss 7.141 (7.176)	prob 2.415 (2.990)	GS 40.656 (32.528)	mem 26.692
Train: [38][1500/1500]	BT 0.035 (0.296)	DT 0.000 (0.258)	loss 7.128 (7.184)	prob 3.668 (2.969)	GS 38.156 (33.070)	mem 12.697
Train: [38][1510/1500]	BT 0.022 (0.294)	DT 0.000 (0.256)	loss 6.705 (6.906)	prob 4.199 (3.477)	GS 34.344 (32.544)	mem 9.882
epoch 38, total time 444.53
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [39][1/1500]	BT 17.612 (17.612)	DT 17.562 (17.562)	loss 6.804 (6.804)	prob 2.716 (2.716)	GS 26.281 (26.281)	mem 73.381
Train: [39][10/1500]	BT 0.035 (2.300)	DT 0.000 (2.257)	loss 6.712 (6.902)	prob 3.369 (3.236)	GS 32.844 (32.828)	mem 73.743
Train: [39][20/1500]	BT 0.037 (1.169)	DT 0.000 (1.129)	loss 7.033 (6.934)	prob 2.871 (3.120)	GS 31.250 (32.431)	mem 73.742
Train: [39][30/1500]	BT 0.038 (0.800)	DT 0.001 (0.761)	loss 6.962 (6.941)	prob 2.756 (3.105)	GS 32.359 (31.982)	mem 73.744
Train: [39][40/1500]	BT 0.037 (0.720)	DT 0.001 (0.682)	loss 6.700 (6.925)	prob 3.608 (3.102)	GS 31.406 (31.855)	mem 73.773
Train: [39][50/1500]	BT 0.037 (0.583)	DT 0.001 (0.546)	loss 6.782 (6.941)	prob 3.714 (3.117)	GS 36.406 (32.133)	mem 73.773
Train: [39][60/1500]	BT 0.040 (0.572)	DT 0.001 (0.534)	loss 6.853 (6.871)	prob 2.284 (3.009)	GS 31.375 (32.581)	mem 73.927
Train: [39][70/1500]	BT 0.031 (0.495)	DT 0.000 (0.458)	loss 7.156 (6.952)	prob 2.469 (3.071)	GS 34.484 (32.660)	mem 73.930
Train: [39][80/1500]	BT 0.037 (0.438)	DT 0.001 (0.400)	loss 7.201 (6.968)	prob 2.635 (3.077)	GS 34.797 (32.922)	mem 74.030
Train: [39][90/1500]	BT 0.033 (0.464)	DT 0.000 (0.427)	loss 6.793 (6.964)	prob 3.833 (3.094)	GS 33.266 (32.491)	mem 74.787
Train: [39][100/1500]	BT 0.024 (0.420)	DT 0.000 (0.384)	loss 6.925 (6.956)	prob 3.652 (3.154)	GS 32.344 (32.319)	mem 74.788
Train: [39][110/1500]	BT 0.028 (0.436)	DT 0.000 (0.399)	loss 7.135 (7.005)	prob 3.006 (3.211)	GS 31.547 (33.366)	mem 74.992
Train: [39][120/1500]	BT 0.026 (0.402)	DT 0.000 (0.366)	loss 6.752 (6.975)	prob 2.760 (3.189)	GS 33.484 (32.681)	mem 74.992
Train: [39][130/1500]	BT 0.063 (0.394)	DT 0.004 (0.359)	loss 7.202 (6.999)	prob 2.774 (3.038)	GS 31.797 (32.702)	mem 75.001
Train: [39][140/1500]	BT 0.028 (0.448)	DT 0.000 (0.412)	loss 7.116 (7.012)	prob 3.475 (3.112)	GS 32.703 (32.814)	mem 75.021
Train: [39][150/1500]	BT 0.023 (0.421)	DT 0.000 (0.385)	loss 6.837 (6.987)	prob 3.238 (3.117)	GS 35.000 (33.207)	mem 75.023
Train: [39][160/1500]	BT 0.037 (0.401)	DT 0.001 (0.365)	loss 6.994 (6.981)	prob 2.883 (3.003)	GS 32.141 (33.203)	mem 75.025
Train: [39][170/1500]	BT 0.031 (0.398)	DT 0.000 (0.362)	loss 6.890 (7.040)	prob 3.493 (2.955)	GS 31.547 (34.682)	mem 75.026
Train: [39][180/1500]	BT 0.057 (0.399)	DT 0.014 (0.363)	loss 7.354 (7.064)	prob 3.266 (3.075)	GS 36.109 (34.370)	mem 75.025
Train: [39][190/1500]	BT 0.124 (0.397)	DT 0.024 (0.359)	loss 6.874 (7.051)	prob 2.935 (3.126)	GS 31.531 (33.637)	mem 75.028
Train: [39][200/1500]	BT 0.028 (0.438)	DT 0.000 (0.400)	loss 7.166 (7.077)	prob 3.156 (3.104)	GS 33.750 (33.386)	mem 75.031
Train: [39][210/1500]	BT 0.036 (0.418)	DT 0.001 (0.381)	loss 7.016 (7.025)	prob 3.966 (3.255)	GS 33.109 (33.438)	mem 75.033
Train: [39][220/1500]	BT 0.039 (0.415)	DT 0.001 (0.378)	loss 7.373 (7.065)	prob 3.339 (3.312)	GS 36.109 (34.516)	mem 75.073
Train: [39][230/1500]	BT 0.038 (0.399)	DT 0.001 (0.361)	loss 7.202 (7.064)	prob 3.991 (3.455)	GS 33.328 (34.024)	mem 75.073
Train: [39][240/1500]	BT 0.039 (0.394)	DT 0.001 (0.357)	loss 7.149 (7.086)	prob 3.140 (3.519)	GS 33.812 (33.691)	mem 75.074
Train: [39][250/1500]	BT 0.039 (0.380)	DT 0.001 (0.343)	loss 7.067 (7.090)	prob 3.524 (3.489)	GS 36.344 (33.333)	mem 75.074
Train: [39][260/1500]	BT 0.039 (0.367)	DT 0.001 (0.330)	loss 7.253 (7.070)	prob 2.997 (3.308)	GS 36.531 (32.664)	mem 75.074
Train: [39][270/1500]	BT 0.036 (0.399)	DT 0.001 (0.362)	loss 6.859 (7.055)	prob 2.554 (3.105)	GS 34.484 (33.077)	mem 75.071
Train: [39][280/1500]	BT 0.024 (0.386)	DT 0.000 (0.349)	loss 7.005 (7.042)	prob 3.731 (3.172)	GS 32.406 (32.632)	mem 75.072
Train: [39][290/1500]	BT 0.027 (0.399)	DT 0.000 (0.362)	loss 6.980 (7.046)	prob 3.521 (3.248)	GS 37.031 (32.620)	mem 75.076
Train: [39][300/1500]	BT 0.031 (0.387)	DT 0.000 (0.350)	loss 6.971 (7.045)	prob 3.250 (3.275)	GS 38.062 (32.664)	mem 75.076
Train: [39][310/1500]	BT 0.038 (0.375)	DT 0.001 (0.339)	loss 7.377 (7.006)	prob 3.136 (3.234)	GS 34.328 (31.559)	mem 75.076
Train: [39][320/1500]	BT 0.058 (0.378)	DT 0.011 (0.341)	loss 6.980 (7.004)	prob 3.326 (3.241)	GS 34.922 (31.999)	mem 75.078
Train: [39][330/1500]	BT 0.066 (0.369)	DT 0.008 (0.331)	loss 6.856 (6.983)	prob 3.483 (3.260)	GS 32.641 (31.837)	mem 75.079
Train: [39][340/1500]	BT 0.038 (0.371)	DT 0.000 (0.333)	loss 6.896 (6.976)	prob 3.062 (3.267)	GS 34.156 (31.961)	mem 75.078
Train: [39][350/1500]	BT 0.068 (0.362)	DT 0.014 (0.324)	loss 6.916 (6.980)	prob 4.158 (3.260)	GS 37.188 (32.435)	mem 75.080
Train: [39][360/1500]	BT 0.039 (0.361)	DT 0.001 (0.323)	loss 6.976 (6.993)	prob 3.679 (3.501)	GS 35.125 (31.997)	mem 75.078
Train: [39][370/1500]	BT 0.038 (0.353)	DT 0.001 (0.315)	loss 7.017 (6.966)	prob 3.004 (3.453)	GS 36.609 (32.261)	mem 75.078
Train: [39][380/1500]	BT 0.039 (0.344)	DT 0.001 (0.306)	loss 6.972 (6.984)	prob 3.732 (3.424)	GS 35.656 (32.552)	mem 75.079
Train: [39][390/1500]	BT 0.039 (0.347)	DT 0.001 (0.309)	loss 6.985 (6.972)	prob 3.284 (3.457)	GS 36.547 (32.910)	mem 75.080
Train: [39][400/1500]	BT 0.038 (0.339)	DT 0.001 (0.301)	loss 7.167 (6.970)	prob 3.510 (3.432)	GS 29.203 (32.764)	mem 75.080
Train: [39][410/1500]	BT 0.048 (0.347)	DT 0.000 (0.309)	loss 6.893 (6.874)	prob 4.021 (3.673)	GS 34.078 (32.733)	mem 75.081
Train: [39][420/1500]	BT 0.060 (0.341)	DT 0.011 (0.302)	loss 7.003 (6.926)	prob 3.040 (3.565)	GS 37.078 (32.902)	mem 75.081
Train: [39][430/1500]	BT 0.039 (0.337)	DT 0.001 (0.298)	loss 6.969 (6.931)	prob 3.523 (3.644)	GS 34.891 (32.989)	mem 75.083
Train: [39][440/1500]	BT 0.039 (0.336)	DT 0.001 (0.298)	loss 7.049 (6.937)	prob 3.930 (3.718)	GS 35.688 (32.786)	mem 75.085
Train: [39][450/1500]	BT 0.038 (0.330)	DT 0.001 (0.292)	loss 7.052 (6.951)	prob 4.314 (3.707)	GS 36.156 (32.713)	mem 75.084
Train: [39][460/1500]	BT 0.038 (0.334)	DT 0.001 (0.296)	loss 6.931 (6.968)	prob 3.694 (3.629)	GS 36.875 (33.842)	mem 75.085
Train: [39][470/1500]	BT 0.033 (0.328)	DT 0.000 (0.289)	loss 7.124 (7.001)	prob 3.505 (3.520)	GS 31.062 (33.038)	mem 75.086
Train: [39][480/1500]	BT 0.039 (0.328)	DT 0.001 (0.289)	loss 7.139 (7.014)	prob 2.811 (3.375)	GS 35.250 (32.592)	mem 75.087
Train: [39][490/1500]	BT 0.039 (0.322)	DT 0.001 (0.284)	loss 7.015 (6.999)	prob 3.340 (3.395)	GS 29.875 (32.531)	mem 75.087
Train: [39][500/1500]	BT 0.039 (0.320)	DT 0.001 (0.282)	loss 7.247 (7.014)	prob 3.118 (3.350)	GS 38.328 (32.697)	mem 75.086
Train: [39][510/1500]	BT 0.038 (0.319)	DT 0.000 (0.281)	loss 7.345 (7.082)	prob 3.000 (2.962)	GS 31.609 (32.639)	mem 75.088
Train: [39][520/1500]	BT 0.037 (0.314)	DT 0.001 (0.276)	loss 6.797 (7.097)	prob 3.155 (2.965)	GS 33.969 (32.898)	mem 75.091
Train: [39][530/1500]	BT 0.039 (0.318)	DT 0.001 (0.280)	loss 6.815 (7.102)	prob 3.022 (2.968)	GS 34.969 (33.067)	mem 75.105
Train: [39][540/1500]	BT 0.037 (0.313)	DT 0.001 (0.275)	loss 7.102 (7.105)	prob 3.522 (2.915)	GS 32.203 (33.167)	mem 75.107
Train: [39][550/1500]	BT 0.035 (0.323)	DT 0.000 (0.284)	loss 7.334 (7.132)	prob 2.440 (2.859)	GS 33.062 (33.422)	mem 75.105
Train: [39][560/1500]	BT 0.027 (0.317)	DT 0.000 (0.279)	loss 7.311 (7.197)	prob 2.731 (2.740)	GS 36.016 (32.689)	mem 75.105
Train: [39][570/1500]	BT 0.038 (0.312)	DT 0.001 (0.274)	loss 7.350 (7.321)	prob 2.864 (2.546)	GS 39.719 (32.881)	mem 75.106
Train: [39][580/1500]	BT 0.029 (0.315)	DT 0.000 (0.277)	loss 7.093 (7.331)	prob 2.622 (2.515)	GS 28.188 (32.952)	mem 75.010
Train: [39][590/1500]	BT 0.024 (0.310)	DT 0.000 (0.272)	loss 8.138 (7.369)	prob 1.908 (2.467)	GS 37.969 (33.070)	mem 75.010
Train: [39][600/1500]	BT 0.027 (0.310)	DT 0.000 (0.273)	loss 7.536 (7.397)	prob 2.363 (2.411)	GS 34.531 (33.212)	mem 75.009
Train: [39][610/1500]	BT 0.024 (0.306)	DT 0.000 (0.268)	loss 7.555 (7.494)	prob 2.094 (2.011)	GS 31.172 (33.163)	mem 75.009
Train: [39][620/1500]	BT 0.072 (0.306)	DT 0.005 (0.269)	loss 7.517 (7.537)	prob 2.894 (2.216)	GS 32.141 (32.416)	mem 75.008
Train: [39][630/1500]	BT 0.082 (0.306)	DT 0.012 (0.268)	loss 7.363 (7.502)	prob 2.563 (2.303)	GS 34.594 (32.358)	mem 75.012
Train: [39][640/1500]	BT 0.037 (0.302)	DT 0.001 (0.264)	loss 7.559 (7.515)	prob 1.574 (2.219)	GS 36.172 (32.707)	mem 75.012
Train: [39][650/1500]	BT 0.038 (0.303)	DT 0.001 (0.265)	loss 7.764 (7.529)	prob 2.285 (2.248)	GS 33.547 (32.465)	mem 75.013
Train: [39][660/1500]	BT 0.037 (0.299)	DT 0.001 (0.261)	loss 7.547 (7.489)	prob 2.874 (2.674)	GS 34.719 (32.942)	mem 75.014
Train: [39][670/1500]	BT 0.038 (0.300)	DT 0.001 (0.263)	loss 7.724 (7.544)	prob 2.533 (2.675)	GS 36.328 (32.831)	mem 75.035
Train: [39][680/1500]	BT 0.037 (0.296)	DT 0.001 (0.259)	loss 7.724 (7.590)	prob 2.469 (2.495)	GS 31.766 (33.070)	mem 75.036
Train: [39][690/1500]	BT 0.061 (0.293)	DT 0.003 (0.255)	loss 7.688 (7.574)	prob 2.959 (2.495)	GS 35.312 (32.809)	mem 75.035
Train: [39][700/1500]	BT 0.040 (0.296)	DT 0.001 (0.258)	loss 7.530 (7.556)	prob 2.231 (2.499)	GS 29.609 (32.505)	mem 75.037
Train: [39][710/1500]	BT 0.038 (0.292)	DT 0.001 (0.255)	loss 7.282 (7.594)	prob 3.018 (2.672)	GS 33.891 (31.767)	mem 75.037
Train: [39][720/1500]	BT 0.037 (0.295)	DT 0.001 (0.257)	loss 7.165 (7.578)	prob 3.514 (2.738)	GS 29.578 (31.948)	mem 75.023
Train: [39][730/1500]	BT 0.033 (0.291)	DT 0.001 (0.254)	loss 8.004 (7.596)	prob 3.033 (2.796)	GS 33.641 (31.815)	mem 75.023
Train: [39][740/1500]	BT 0.139 (0.298)	DT 0.020 (0.261)	loss 7.514 (7.625)	prob 3.810 (2.744)	GS 34.984 (31.901)	mem 75.025
Train: [39][750/1500]	BT 0.081 (0.295)	DT 0.009 (0.257)	loss 7.181 (7.606)	prob 3.336 (2.799)	GS 34.812 (32.107)	mem 75.028
Train: [39][760/1500]	BT 0.039 (0.296)	DT 0.001 (0.258)	loss 7.676 (7.625)	prob 2.685 (2.581)	GS 36.016 (34.202)	mem 75.029
Train: [39][770/1500]	BT 0.039 (0.296)	DT 0.001 (0.257)	loss 7.340 (7.551)	prob 3.314 (2.732)	GS 27.938 (33.295)	mem 75.030
Train: [39][780/1500]	BT 0.039 (0.294)	DT 0.001 (0.255)	loss 7.526 (7.510)	prob 2.914 (2.865)	GS 32.875 (32.957)	mem 75.030
Train: [39][790/1500]	BT 0.039 (0.293)	DT 0.001 (0.254)	loss 7.623 (7.531)	prob 2.881 (2.751)	GS 33.734 (33.070)	mem 75.029
Train: [39][800/1500]	BT 0.039 (0.291)	DT 0.001 (0.252)	loss 7.471 (7.506)	prob 2.627 (2.793)	GS 33.203 (32.910)	mem 75.029
Train: [39][810/1500]	BT 0.039 (0.291)	DT 0.001 (0.253)	loss 7.395 (7.502)	prob 3.702 (3.063)	GS 32.969 (32.805)	mem 75.030
Train: [39][820/1500]	BT 0.039 (0.289)	DT 0.001 (0.251)	loss 8.006 (7.488)	prob 3.040 (3.023)	GS 36.953 (32.726)	mem 75.031
Train: [39][830/1500]	BT 0.037 (0.288)	DT 0.001 (0.250)	loss 7.861 (7.457)	prob 2.138 (2.969)	GS 37.891 (33.033)	mem 75.042
Train: [39][840/1500]	BT 0.038 (0.286)	DT 0.001 (0.248)	loss 7.215 (7.414)	prob 3.645 (2.985)	GS 35.766 (32.800)	mem 75.045
Train: [39][850/1500]	BT 0.037 (0.286)	DT 0.001 (0.247)	loss 7.640 (7.423)	prob 3.388 (2.996)	GS 34.219 (32.854)	mem 75.046
Train: [39][860/1500]	BT 0.031 (0.289)	DT 0.001 (0.251)	loss 7.826 (7.612)	prob 2.846 (2.736)	GS 36.016 (33.380)	mem 75.047
Train: [39][870/1500]	BT 0.037 (0.286)	DT 0.001 (0.248)	loss 7.775 (7.537)	prob 3.083 (2.982)	GS 34.812 (33.535)	mem 75.048
Train: [39][880/1500]	BT 0.047 (0.284)	DT 0.010 (0.245)	loss 7.943 (7.544)	prob 3.304 (3.040)	GS 37.078 (33.489)	mem 75.049
Train: [39][890/1500]	BT 0.055 (0.287)	DT 0.001 (0.249)	loss 7.482 (7.502)	prob 3.344 (3.063)	GS 34.031 (33.459)	mem 75.051
Train: [39][900/1500]	BT 0.031 (0.286)	DT 0.000 (0.247)	loss 7.605 (7.488)	prob 3.647 (3.158)	GS 36.859 (33.087)	mem 75.052
Train: [39][910/1500]	BT 0.032 (0.287)	DT 0.001 (0.249)	loss 7.516 (7.292)	prob 3.135 (3.197)	GS 27.469 (31.025)	mem 75.056
Train: [39][920/1500]	BT 0.036 (0.289)	DT 0.000 (0.250)	loss 7.296 (7.379)	prob 3.353 (3.094)	GS 32.844 (32.335)	mem 75.055
Train: [39][930/1500]	BT 0.038 (0.286)	DT 0.001 (0.248)	loss 7.931 (7.416)	prob 2.840 (3.078)	GS 34.375 (32.530)	mem 75.056
Train: [39][940/1500]	BT 0.036 (0.288)	DT 0.000 (0.249)	loss 8.240 (7.437)	prob 3.300 (3.106)	GS 34.031 (32.295)	mem 75.058
Train: [39][950/1500]	BT 0.037 (0.285)	DT 0.001 (0.247)	loss 7.185 (7.440)	prob 3.240 (3.107)	GS 33.719 (32.577)	mem 75.057
Train: [39][960/1500]	BT 0.072 (0.283)	DT 0.005 (0.244)	loss 7.017 (7.268)	prob 3.317 (2.954)	GS 30.547 (31.714)	mem 75.057
Train: [39][970/1500]	BT 0.060 (0.286)	DT 0.003 (0.247)	loss 6.989 (7.346)	prob 3.709 (2.959)	GS 31.656 (32.639)	mem 75.059
Train: [39][980/1500]	BT 0.044 (0.283)	DT 0.000 (0.245)	loss 7.108 (7.314)	prob 3.406 (3.102)	GS 32.188 (32.125)	mem 75.059
Train: [39][990/1500]	BT 0.036 (0.287)	DT 0.001 (0.249)	loss 7.502 (7.291)	prob 3.196 (3.124)	GS 33.328 (32.278)	mem 75.060
Train: [39][1000/1500]	BT 0.037 (0.285)	DT 0.001 (0.246)	loss 7.447 (7.280)	prob 4.112 (3.213)	GS 34.453 (32.033)	mem 75.060
Train: [39][1010/1500]	BT 0.030 (0.288)	DT 0.000 (0.249)	loss 7.175 (7.395)	prob 3.045 (3.087)	GS 34.406 (33.684)	mem 75.056
Train: [39][1020/1500]	BT 0.027 (0.285)	DT 0.000 (0.247)	loss 7.384 (7.335)	prob 3.347 (3.115)	GS 34.906 (32.380)	mem 75.058
Train: [39][1030/1500]	BT 0.037 (0.284)	DT 0.001 (0.246)	loss 6.999 (7.334)	prob 3.061 (3.129)	GS 32.078 (32.255)	mem 75.057
Train: [39][1040/1500]	BT 0.037 (0.283)	DT 0.001 (0.245)	loss 7.212 (7.351)	prob 2.764 (3.095)	GS 35.906 (32.441)	mem 75.059
Train: [39][1050/1500]	BT 0.052 (0.281)	DT 0.014 (0.242)	loss 7.281 (7.335)	prob 2.815 (3.080)	GS 35.953 (32.563)	mem 75.060
Train: [39][1060/1500]	BT 0.037 (0.284)	DT 0.001 (0.245)	loss 6.923 (7.132)	prob 3.882 (2.937)	GS 32.844 (31.973)	mem 75.061
Train: [39][1070/1500]	BT 0.038 (0.281)	DT 0.001 (0.243)	loss 7.539 (7.212)	prob 3.261 (3.107)	GS 29.922 (32.264)	mem 75.061
Train: [39][1080/1500]	BT 0.037 (0.282)	DT 0.000 (0.243)	loss 7.300 (7.205)	prob 2.884 (3.171)	GS 31.016 (32.375)	mem 75.062
Train: [39][1090/1500]	BT 0.038 (0.279)	DT 0.001 (0.241)	loss 7.124 (7.209)	prob 3.512 (3.197)	GS 34.469 (32.465)	mem 75.062
Train: [39][1100/1500]	BT 1.123 (0.278)	DT 1.087 (0.240)	loss 6.901 (7.204)	prob 3.631 (3.211)	GS 28.688 (32.595)	mem 75.064
Train: [39][1110/1500]	BT 0.051 (0.279)	DT 0.008 (0.240)	loss 6.957 (7.218)	prob 2.726 (2.881)	GS 30.062 (33.002)	mem 75.064
Train: [39][1120/1500]	BT 0.060 (0.278)	DT 0.004 (0.240)	loss 7.067 (7.228)	prob 2.970 (3.018)	GS 35.938 (33.056)	mem 75.066
Train: [39][1130/1500]	BT 0.030 (0.286)	DT 0.000 (0.247)	loss 7.035 (7.205)	prob 2.909 (3.034)	GS 37.250 (33.129)	mem 75.068
Train: [39][1140/1500]	BT 0.025 (0.284)	DT 0.000 (0.245)	loss 7.441 (7.226)	prob 3.020 (3.026)	GS 36.141 (33.091)	mem 75.070
Train: [39][1150/1500]	BT 0.023 (0.285)	DT 0.000 (0.247)	loss 7.020 (7.214)	prob 3.392 (3.012)	GS 33.594 (33.322)	mem 75.071
Train: [39][1160/1500]	BT 0.037 (0.283)	DT 0.000 (0.245)	loss 7.154 (7.145)	prob 3.113 (3.190)	GS 34.531 (31.416)	mem 75.071
Train: [39][1170/1500]	BT 0.028 (0.284)	DT 0.000 (0.246)	loss 7.143 (7.113)	prob 3.570 (3.239)	GS 32.375 (31.431)	mem 75.073
Train: [39][1180/1500]	BT 0.038 (0.282)	DT 0.001 (0.244)	loss 7.204 (7.150)	prob 3.552 (3.249)	GS 37.375 (31.863)	mem 75.074
Train: [39][1190/1500]	BT 0.038 (0.280)	DT 0.001 (0.242)	loss 7.045 (7.132)	prob 3.497 (3.212)	GS 35.391 (32.622)	mem 75.074
Train: [39][1200/1500]	BT 0.038 (0.283)	DT 0.001 (0.245)	loss 7.040 (7.127)	prob 3.005 (3.227)	GS 34.438 (32.687)	mem 75.074
Train: [39][1210/1500]	BT 0.037 (0.281)	DT 0.001 (0.243)	loss 7.114 (7.150)	prob 3.734 (3.367)	GS 34.469 (34.344)	mem 75.073
Train: [39][1220/1500]	BT 0.029 (0.283)	DT 0.001 (0.245)	loss 7.578 (7.181)	prob 2.570 (3.312)	GS 36.734 (34.404)	mem 75.104
Train: [39][1230/1500]	BT 0.038 (0.281)	DT 0.001 (0.243)	loss 7.308 (7.188)	prob 3.485 (3.274)	GS 36.094 (33.855)	mem 75.105
Train: [39][1240/1500]	BT 0.039 (0.279)	DT 0.001 (0.241)	loss 7.317 (7.187)	prob 3.400 (3.322)	GS 32.391 (33.529)	mem 75.106
Train: [39][1250/1500]	BT 0.029 (0.282)	DT 0.001 (0.244)	loss 7.171 (7.181)	prob 3.398 (3.315)	GS 39.562 (33.712)	mem 75.106
Train: [39][1260/1500]	BT 0.039 (0.280)	DT 0.001 (0.242)	loss 7.186 (7.130)	prob 4.024 (3.561)	GS 34.766 (33.444)	mem 75.107
Train: [39][1270/1500]	BT 0.039 (0.281)	DT 0.001 (0.243)	loss 6.865 (7.106)	prob 3.962 (3.444)	GS 31.047 (32.108)	mem 75.108
Train: [39][1280/1500]	BT 0.028 (0.281)	DT 0.000 (0.243)	loss 7.169 (7.089)	prob 3.268 (3.419)	GS 30.781 (32.165)	mem 75.108
Train: [39][1290/1500]	BT 0.038 (0.280)	DT 0.000 (0.242)	loss 6.913 (7.088)	prob 3.311 (3.373)	GS 32.047 (31.916)	mem 75.110
Train: [39][1300/1500]	BT 0.062 (0.278)	DT 0.003 (0.240)	loss 7.044 (7.098)	prob 3.260 (3.402)	GS 30.641 (31.835)	mem 75.110
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [39][1310/1500]	BT 0.039 (0.278)	DT 0.001 (0.240)	loss 7.262 (7.093)	prob 3.302 (3.426)	GS 35.938 (32.698)	mem 75.110
Train: [39][1320/1500]	BT 0.038 (0.277)	DT 0.001 (0.239)	loss 7.030 (7.043)	prob 3.554 (3.445)	GS 31.281 (32.170)	mem 75.108
Train: [39][1330/1500]	BT 0.047 (0.276)	DT 0.009 (0.238)	loss 7.133 (7.034)	prob 2.153 (3.373)	GS 33.219 (32.221)	mem 75.107
Train: [39][1340/1500]	BT 0.038 (0.276)	DT 0.001 (0.238)	loss 7.262 (7.026)	prob 2.661 (3.339)	GS 35.406 (32.256)	mem 75.106
Train: [39][1350/1500]	BT 0.038 (0.274)	DT 0.001 (0.236)	loss 6.879 (7.019)	prob 3.779 (3.402)	GS 32.438 (32.467)	mem 75.106
Train: [39][1360/1500]	BT 0.038 (0.275)	DT 0.001 (0.237)	loss 7.296 (7.072)	prob 3.554 (3.547)	GS 38.234 (34.434)	mem 75.109
Train: [39][1370/1500]	BT 0.030 (0.278)	DT 0.000 (0.240)	loss 6.863 (7.043)	prob 3.852 (3.502)	GS 29.922 (33.562)	mem 75.109
Train: [39][1380/1500]	BT 0.039 (0.276)	DT 0.001 (0.238)	loss 7.180 (7.045)	prob 4.060 (3.414)	GS 38.766 (33.680)	mem 75.109
Train: [39][1390/1500]	BT 0.035 (0.282)	DT 0.001 (0.244)	loss 6.771 (7.023)	prob 3.418 (3.417)	GS 35.969 (33.995)	mem 75.109
Train: [39][1400/1500]	BT 0.031 (0.280)	DT 0.000 (0.242)	loss 6.812 (7.004)	prob 3.524 (3.361)	GS 33.672 (33.507)	mem 75.109
Train: [39][1410/1500]	BT 0.033 (0.279)	DT 0.000 (0.241)	loss 6.907 (6.958)	prob 3.437 (3.514)	GS 33.016 (31.236)	mem 75.110
Train: [39][1420/1500]	BT 0.029 (0.280)	DT 0.000 (0.242)	loss 7.204 (6.965)	prob 3.583 (3.449)	GS 36.125 (32.215)	mem 75.108
Train: [39][1430/1500]	BT 0.026 (0.278)	DT 0.000 (0.240)	loss 7.036 (6.963)	prob 3.071 (3.411)	GS 39.656 (32.749)	mem 75.108
Train: [39][1440/1500]	BT 0.037 (0.279)	DT 0.000 (0.241)	loss 6.785 (6.945)	prob 3.326 (3.343)	GS 33.984 (32.317)	mem 75.119
Train: [39][1450/1500]	BT 0.038 (0.277)	DT 0.001 (0.240)	loss 6.926 (6.938)	prob 2.902 (3.322)	GS 32.328 (32.339)	mem 75.128
Train: [39][1460/1500]	BT 0.029 (0.278)	DT 0.000 (0.240)	loss 6.896 (6.925)	prob 3.190 (2.849)	GS 31.594 (32.406)	mem 74.119
Train: [39][1470/1500]	BT 0.034 (0.277)	DT 0.000 (0.239)	loss 6.796 (6.951)	prob 3.550 (3.107)	GS 32.859 (32.280)	mem 74.139
Train: [39][1480/1500]	BT 0.025 (0.275)	DT 0.000 (0.237)	loss 7.001 (6.932)	prob 2.460 (3.084)	GS 34.703 (31.994)	mem 74.139
Train: [39][1490/1500]	BT 0.027 (0.275)	DT 0.000 (0.237)	loss 6.755 (6.931)	prob 2.577 (2.924)	GS 37.625 (32.549)	mem 9.923
Train: [39][1500/1500]	BT 0.031 (0.273)	DT 0.000 (0.236)	loss 6.948 (6.926)	prob 2.629 (2.925)	GS 33.469 (32.702)	mem 9.923
Train: [39][1510/1500]	BT 0.027 (0.272)	DT 0.000 (0.235)	loss 6.682 (6.718)	prob 2.283 (3.170)	GS 36.531 (33.759)	mem 9.850
epoch 39, total time 411.10
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [40][1/1500]	BT 22.987 (22.987)	DT 22.934 (22.934)	loss 6.501 (6.501)	prob 2.838 (2.838)	GS 31.641 (31.641)	mem 73.588
Train: [40][10/1500]	BT 0.040 (2.338)	DT 0.001 (2.297)	loss 6.602 (6.710)	prob 2.387 (3.121)	GS 37.938 (34.108)	mem 73.601
Train: [40][20/1500]	BT 0.039 (1.189)	DT 0.001 (1.149)	loss 6.990 (6.720)	prob 3.374 (3.225)	GS 34.219 (33.494)	mem 73.605
Train: [40][30/1500]	BT 0.037 (0.960)	DT 0.001 (0.921)	loss 6.797 (6.758)	prob 3.408 (3.127)	GS 34.078 (33.339)	mem 73.617
Train: [40][40/1500]	BT 0.037 (0.729)	DT 0.001 (0.691)	loss 6.851 (6.814)	prob 4.062 (3.209)	GS 32.766 (32.744)	mem 73.618
Train: [40][50/1500]	BT 0.068 (0.790)	DT 0.006 (0.752)	loss 6.881 (6.847)	prob 3.085 (3.206)	GS 37.359 (33.532)	mem 73.667
Train: [40][60/1500]	BT 0.032 (0.677)	DT 0.000 (0.640)	loss 6.995 (7.010)	prob 2.732 (3.047)	GS 31.828 (32.608)	mem 73.686
Train: [40][70/1500]	BT 0.039 (0.586)	DT 0.001 (0.549)	loss 7.066 (6.985)	prob 2.626 (2.863)	GS 33.750 (32.289)	mem 73.687
Train: [40][80/1500]	BT 0.038 (0.572)	DT 0.001 (0.535)	loss 6.780 (6.994)	prob 2.968 (2.793)	GS 34.953 (32.792)	mem 73.703
Train: [40][90/1500]	BT 0.039 (0.513)	DT 0.001 (0.475)	loss 6.851 (6.993)	prob 2.810 (2.831)	GS 36.656 (32.733)	mem 73.704
Train: [40][100/1500]	BT 0.038 (0.571)	DT 0.000 (0.533)	loss 6.950 (6.991)	prob 2.447 (2.802)	GS 33.297 (32.617)	mem 73.711
Train: [40][110/1500]	BT 0.032 (0.522)	DT 0.000 (0.484)	loss 6.869 (6.945)	prob 3.155 (2.896)	GS 34.219 (33.328)	mem 73.713
Train: [40][120/1500]	BT 0.040 (0.486)	DT 0.001 (0.448)	loss 7.209 (6.966)	prob 2.579 (2.883)	GS 32.000 (32.764)	mem 73.715
Train: [40][130/1500]	BT 0.038 (0.468)	DT 0.001 (0.431)	loss 6.796 (6.983)	prob 2.825 (2.845)	GS 36.656 (32.534)	mem 73.766
Train: [40][140/1500]	BT 0.065 (0.439)	DT 0.004 (0.400)	loss 6.945 (6.979)	prob 2.964 (2.841)	GS 33.578 (32.571)	mem 73.766
Train: [40][150/1500]	BT 0.039 (0.436)	DT 0.001 (0.398)	loss 6.842 (6.973)	prob 3.430 (2.884)	GS 35.250 (32.573)	mem 74.309
Train: [40][160/1500]	BT 0.039 (0.411)	DT 0.001 (0.373)	loss 7.235 (6.996)	prob 2.500 (2.922)	GS 33.359 (33.327)	mem 74.358
Train: [40][170/1500]	BT 0.039 (0.416)	DT 0.000 (0.377)	loss 7.019 (6.986)	prob 3.418 (2.834)	GS 32.297 (32.872)	mem 74.865
Train: [40][180/1500]	BT 0.038 (0.395)	DT 0.001 (0.356)	loss 6.939 (6.985)	prob 3.749 (2.985)	GS 31.672 (32.749)	mem 74.866
Train: [40][190/1500]	BT 0.037 (0.376)	DT 0.000 (0.338)	loss 6.853 (6.979)	prob 3.227 (2.951)	GS 35.922 (32.796)	mem 74.915
Train: [40][200/1500]	BT 0.037 (0.381)	DT 0.000 (0.343)	loss 6.957 (6.979)	prob 3.745 (2.951)	GS 34.234 (32.685)	mem 74.921
Train: [40][210/1500]	BT 0.037 (0.365)	DT 0.000 (0.327)	loss 7.060 (6.854)	prob 2.686 (3.056)	GS 32.734 (32.966)	mem 74.921
Train: [40][220/1500]	BT 0.078 (0.367)	DT 0.024 (0.329)	loss 7.062 (6.908)	prob 3.178 (3.137)	GS 33.219 (33.186)	mem 74.926
Train: [40][230/1500]	BT 0.037 (0.355)	DT 0.000 (0.317)	loss 7.301 (6.943)	prob 2.225 (3.016)	GS 37.297 (33.940)	mem 74.928
Train: [40][240/1500]	BT 0.037 (0.359)	DT 0.000 (0.320)	loss 6.945 (6.945)	prob 3.253 (3.003)	GS 33.328 (33.615)	mem 74.933
Train: [40][250/1500]	BT 0.099 (0.349)	DT 0.008 (0.310)	loss 6.853 (6.941)	prob 3.769 (3.034)	GS 33.781 (33.623)	mem 74.935
Train: [40][260/1500]	BT 0.061 (0.338)	DT 0.015 (0.298)	loss 6.830 (6.889)	prob 3.236 (3.230)	GS 32.953 (32.812)	mem 74.934
Train: [40][270/1500]	BT 0.029 (0.352)	DT 0.000 (0.312)	loss 6.978 (6.912)	prob 2.979 (3.112)	GS 33.266 (32.720)	mem 74.938
Train: [40][280/1500]	BT 0.037 (0.340)	DT 0.000 (0.301)	loss 7.098 (6.910)	prob 2.031 (3.007)	GS 33.594 (32.428)	mem 74.939
Train: [40][290/1500]	BT 0.042 (0.344)	DT 0.000 (0.305)	loss 6.970 (6.912)	prob 3.868 (3.004)	GS 32.984 (32.456)	mem 74.942
Train: [40][300/1500]	BT 0.029 (0.334)	DT 0.000 (0.295)	loss 6.890 (6.911)	prob 2.969 (3.033)	GS 31.703 (32.430)	mem 74.943
Train: [40][310/1500]	BT 0.038 (0.324)	DT 0.000 (0.286)	loss 6.880 (6.844)	prob 2.361 (2.975)	GS 33.609 (31.228)	mem 74.944
Train: [40][320/1500]	BT 0.037 (0.327)	DT 0.000 (0.289)	loss 6.831 (6.851)	prob 3.050 (2.830)	GS 34.516 (31.355)	mem 74.952
Train: [40][330/1500]	BT 0.038 (0.319)	DT 0.001 (0.280)	loss 6.741 (6.853)	prob 3.094 (2.879)	GS 34.047 (31.518)	mem 74.952
Train: [40][340/1500]	BT 0.068 (0.329)	DT 0.003 (0.290)	loss 6.863 (6.864)	prob 2.177 (2.845)	GS 35.969 (31.816)	mem 74.962
Train: [40][350/1500]	BT 0.027 (0.324)	DT 0.000 (0.285)	loss 6.877 (6.865)	prob 3.550 (2.856)	GS 32.094 (32.018)	mem 74.962
Train: [40][360/1500]	BT 0.037 (0.320)	DT 0.000 (0.282)	loss 6.857 (6.879)	prob 2.897 (2.924)	GS 37.688 (34.470)	mem 74.964
Train: [40][370/1500]	BT 0.038 (0.313)	DT 0.000 (0.274)	loss 6.867 (6.847)	prob 3.033 (2.936)	GS 31.797 (33.264)	mem 74.964
Train: [40][380/1500]	BT 0.036 (0.315)	DT 0.000 (0.276)	loss 6.781 (6.836)	prob 3.086 (2.981)	GS 32.859 (33.149)	mem 74.967
Train: [40][390/1500]	BT 0.037 (0.317)	DT 0.000 (0.278)	loss 6.832 (6.836)	prob 3.406 (2.984)	GS 34.078 (32.954)	mem 74.972
Train: [40][400/1500]	BT 0.038 (0.315)	DT 0.001 (0.277)	loss 6.821 (6.838)	prob 3.474 (2.962)	GS 27.250 (32.808)	mem 74.972
Train: [40][410/1500]	BT 0.037 (0.311)	DT 0.000 (0.273)	loss 6.889 (6.823)	prob 2.568 (2.767)	GS 32.609 (33.280)	mem 74.973
Train: [40][420/1500]	BT 0.038 (0.308)	DT 0.001 (0.270)	loss 6.876 (6.863)	prob 3.548 (2.868)	GS 33.188 (33.600)	mem 74.974
Train: [40][430/1500]	BT 0.038 (0.302)	DT 0.001 (0.264)	loss 6.776 (6.844)	prob 3.374 (2.921)	GS 33.484 (33.405)	mem 74.973
Train: [40][440/1500]	BT 0.037 (0.299)	DT 0.001 (0.261)	loss 6.871 (6.841)	prob 3.232 (2.921)	GS 36.406 (33.207)	mem 74.974
Train: [40][450/1500]	BT 0.037 (0.297)	DT 0.001 (0.258)	loss 6.753 (6.834)	prob 2.507 (2.928)	GS 33.812 (33.223)	mem 74.975
Train: [40][460/1500]	BT 0.028 (0.297)	DT 0.000 (0.259)	loss 6.829 (6.802)	prob 2.796 (3.055)	GS 33.859 (31.725)	mem 74.978
Train: [40][470/1500]	BT 0.040 (0.295)	DT 0.001 (0.257)	loss 6.750 (6.793)	prob 3.373 (2.982)	GS 31.438 (31.627)	mem 74.980
Train: [40][480/1500]	BT 0.032 (0.298)	DT 0.000 (0.260)	loss 6.821 (6.810)	prob 3.031 (2.930)	GS 31.609 (31.733)	mem 75.015
Train: [40][490/1500]	BT 0.062 (0.293)	DT 0.024 (0.255)	loss 6.636 (6.793)	prob 2.752 (2.900)	GS 34.266 (32.002)	mem 75.016
Train: [40][500/1500]	BT 0.039 (0.292)	DT 0.001 (0.254)	loss 6.725 (6.802)	prob 3.438 (2.881)	GS 35.078 (32.301)	mem 75.018
Train: [40][510/1500]	BT 0.038 (0.293)	DT 0.000 (0.255)	loss 6.720 (6.798)	prob 2.654 (2.617)	GS 34.750 (31.545)	mem 75.017
Train: [40][520/1500]	BT 0.039 (0.290)	DT 0.001 (0.252)	loss 6.779 (6.789)	prob 2.648 (2.787)	GS 28.562 (31.777)	mem 75.018
Train: [40][530/1500]	BT 0.039 (0.289)	DT 0.001 (0.251)	loss 6.755 (6.785)	prob 2.984 (2.910)	GS 30.641 (31.656)	mem 75.017
Train: [40][540/1500]	BT 0.039 (0.286)	DT 0.001 (0.249)	loss 6.660 (6.773)	prob 2.339 (2.831)	GS 34.750 (32.057)	mem 75.018
Train: [40][550/1500]	BT 0.038 (0.282)	DT 0.001 (0.244)	loss 7.029 (6.799)	prob 3.560 (2.838)	GS 30.297 (32.153)	mem 75.018
Train: [40][560/1500]	BT 0.038 (0.281)	DT 0.001 (0.243)	loss 6.819 (6.781)	prob 3.112 (3.092)	GS 32.188 (32.348)	mem 75.018
Train: [40][570/1500]	BT 0.030 (0.280)	DT 0.000 (0.242)	loss 6.818 (6.787)	prob 2.849 (3.050)	GS 33.266 (32.950)	mem 75.019
Train: [40][580/1500]	BT 0.144 (0.278)	DT 0.097 (0.240)	loss 6.730 (6.783)	prob 2.870 (2.955)	GS 33.234 (32.813)	mem 75.019
Train: [40][590/1500]	BT 0.031 (0.283)	DT 0.001 (0.245)	loss 6.926 (6.784)	prob 2.849 (2.900)	GS 33.453 (32.860)	mem 75.021
Train: [40][600/1500]	BT 0.038 (0.281)	DT 0.001 (0.243)	loss 6.591 (6.787)	prob 2.904 (2.886)	GS 32.375 (32.709)	mem 75.020
Train: [40][610/1500]	BT 0.039 (0.280)	DT 0.001 (0.242)	loss 6.837 (6.763)	prob 3.230 (3.078)	GS 37.062 (33.109)	mem 75.019
Train: [40][620/1500]	BT 0.039 (0.279)	DT 0.001 (0.241)	loss 6.742 (6.778)	prob 2.200 (2.884)	GS 36.094 (33.252)	mem 75.018
Train: [40][630/1500]	BT 0.039 (0.275)	DT 0.001 (0.238)	loss 6.911 (6.772)	prob 2.956 (2.891)	GS 33.703 (33.096)	mem 75.018
Train: [40][640/1500]	BT 0.029 (0.291)	DT 0.000 (0.253)	loss 6.745 (6.767)	prob 2.619 (2.792)	GS 32.641 (32.855)	mem 75.020
Train: [40][650/1500]	BT 0.033 (0.287)	DT 0.000 (0.249)	loss 6.788 (6.775)	prob 2.027 (2.724)	GS 33.734 (32.779)	mem 75.020
Train: [40][660/1500]	BT 0.030 (0.289)	DT 0.001 (0.252)	loss 7.085 (6.811)	prob 2.747 (2.448)	GS 29.766 (32.998)	mem 75.020
Train: [40][670/1500]	BT 0.039 (0.285)	DT 0.001 (0.248)	loss 6.841 (6.777)	prob 2.133 (2.394)	GS 31.234 (32.966)	mem 75.021
Train: [40][680/1500]	BT 0.039 (0.282)	DT 0.001 (0.244)	loss 6.584 (6.771)	prob 2.328 (2.356)	GS 33.812 (32.367)	mem 75.022
Train: [40][690/1500]	BT 0.056 (0.286)	DT 0.001 (0.249)	loss 6.744 (6.772)	prob 2.710 (2.371)	GS 35.344 (32.400)	mem 75.021
Train: [40][700/1500]	BT 0.031 (0.283)	DT 0.000 (0.245)	loss 6.791 (6.768)	prob 2.004 (2.342)	GS 28.469 (32.207)	mem 75.020
Train: [40][710/1500]	BT 0.067 (0.294)	DT 0.002 (0.257)	loss 6.628 (6.712)	prob 3.201 (2.283)	GS 32.391 (31.798)	mem 75.020
Train: [40][720/1500]	BT 0.033 (0.305)	DT 0.000 (0.267)	loss 6.637 (6.749)	prob 1.860 (2.249)	GS 33.703 (32.228)	mem 75.021
Train: [40][730/1500]	BT 0.033 (0.301)	DT 0.000 (0.263)	loss 6.662 (6.742)	prob 2.459 (2.312)	GS 33.953 (32.341)	mem 75.020
Train: [40][740/1500]	BT 0.033 (0.302)	DT 0.000 (0.265)	loss 6.641 (6.741)	prob 2.151 (2.339)	GS 35.344 (32.300)	mem 73.310
Train: [40][750/1500]	BT 0.053 (0.299)	DT 0.006 (0.261)	loss 6.655 (6.749)	prob 2.159 (2.313)	GS 32.984 (32.152)	mem 73.312
Train: [40][760/1500]	BT 0.041 (0.296)	DT 0.001 (0.258)	loss 6.665 (6.709)	prob 1.967 (2.162)	GS 35.703 (32.342)	mem 73.310
Train: [40][770/1500]	BT 0.039 (0.300)	DT 0.001 (0.262)	loss 6.777 (6.715)	prob 2.138 (2.202)	GS 34.562 (32.269)	mem 73.314
Train: [40][780/1500]	BT 0.035 (0.297)	DT 0.000 (0.259)	loss 6.815 (6.745)	prob 2.304 (2.183)	GS 33.156 (32.951)	mem 73.316
Train: [40][790/1500]	BT 0.038 (0.304)	DT 0.000 (0.266)	loss 6.682 (6.743)	prob 2.099 (2.230)	GS 32.719 (32.926)	mem 73.312
Train: [40][800/1500]	BT 0.027 (0.310)	DT 0.000 (0.272)	loss 6.749 (6.739)	prob 2.145 (2.294)	GS 35.078 (32.946)	mem 73.312
Train: [40][810/1500]	BT 0.030 (0.307)	DT 0.000 (0.269)	loss 6.613 (6.722)	prob 2.199 (2.672)	GS 30.094 (31.677)	mem 73.312
Train: [40][820/1500]	BT 0.037 (0.304)	DT 0.001 (0.266)	loss 6.793 (6.739)	prob 2.483 (2.607)	GS 35.797 (32.300)	mem 73.314
Train: [40][830/1500]	BT 0.044 (0.312)	DT 0.014 (0.274)	loss 7.439 (6.756)	prob 1.572 (2.650)	GS 29.281 (32.390)	mem 73.323
Train: [40][840/1500]	BT 0.062 (0.309)	DT 0.005 (0.271)	loss 6.848 (6.749)	prob 2.554 (2.644)	GS 31.719 (32.932)	mem 73.323
Train: [40][850/1500]	BT 0.032 (0.333)	DT 0.001 (0.295)	loss 6.852 (6.750)	prob 2.609 (2.630)	GS 29.797 (32.971)	mem 73.347
Train: [40][860/1500]	BT 0.038 (0.330)	DT 0.000 (0.291)	loss 6.715 (6.827)	prob 2.980 (2.851)	GS 32.531 (33.083)	mem 73.348
Train: [40][870/1500]	BT 0.048 (0.326)	DT 0.003 (0.288)	loss 6.898 (6.799)	prob 2.200 (2.810)	GS 32.984 (32.740)	mem 73.350
Train: [40][880/1500]	BT 0.052 (0.331)	DT 0.014 (0.292)	loss 6.863 (6.782)	prob 2.494 (2.788)	GS 35.266 (33.182)	mem 73.213
Train: [40][890/1500]	BT 0.052 (0.328)	DT 0.001 (0.289)	loss 6.976 (6.783)	prob 2.050 (2.708)	GS 30.750 (33.291)	mem 73.212
Train: [40][900/1500]	BT 0.028 (0.339)	DT 0.000 (0.300)	loss 7.197 (6.809)	prob 2.990 (2.626)	GS 31.891 (33.237)	mem 73.230
Train: [40][910/1500]	BT 0.026 (0.335)	DT 0.000 (0.297)	loss 6.964 (6.798)	prob 1.959 (2.564)	GS 32.219 (31.905)	mem 73.231
Train: [40][920/1500]	BT 0.028 (0.337)	DT 0.000 (0.298)	loss 6.792 (6.780)	prob 2.539 (2.586)	GS 32.719 (31.569)	mem 73.230
Train: [40][930/1500]	BT 0.027 (0.333)	DT 0.000 (0.295)	loss 6.596 (6.751)	prob 2.558 (2.576)	GS 33.344 (32.007)	mem 73.230
Train: [40][940/1500]	BT 0.037 (0.330)	DT 0.001 (0.292)	loss 6.750 (6.736)	prob 2.587 (2.529)	GS 32.750 (31.804)	mem 73.230
Train: [40][950/1500]	BT 0.037 (0.330)	DT 0.001 (0.292)	loss 6.449 (6.730)	prob 3.427 (2.523)	GS 33.281 (32.039)	mem 73.230
Train: [40][960/1500]	BT 0.028 (0.327)	DT 0.000 (0.289)	loss 6.766 (6.696)	prob 2.669 (2.701)	GS 33.984 (32.119)	mem 73.231
Train: [40][970/1500]	BT 0.037 (0.330)	DT 0.001 (0.292)	loss 6.535 (6.691)	prob 2.645 (2.592)	GS 30.047 (32.388)	mem 73.233
Train: [40][980/1500]	BT 0.038 (0.327)	DT 0.001 (0.289)	loss 6.690 (6.692)	prob 2.316 (2.483)	GS 33.312 (32.557)	mem 73.232
Train: [40][990/1500]	BT 0.058 (0.332)	DT 0.011 (0.293)	loss 6.503 (6.689)	prob 3.074 (2.431)	GS 38.203 (32.510)	mem 73.231
Train: [40][1000/1500]	BT 0.031 (0.329)	DT 0.000 (0.291)	loss 6.580 (6.704)	prob 2.663 (2.432)	GS 31.750 (32.484)	mem 73.232
Train: [40][1010/1500]	BT 0.027 (0.339)	DT 0.000 (0.301)	loss 6.821 (6.741)	prob 2.582 (2.600)	GS 32.953 (34.487)	mem 73.242
Train: [40][1020/1500]	BT 0.029 (0.336)	DT 0.000 (0.298)	loss 6.555 (6.729)	prob 2.868 (2.484)	GS 33.688 (33.379)	mem 73.242
Train: [40][1030/1500]	BT 0.039 (0.336)	DT 0.001 (0.297)	loss 6.659 (6.742)	prob 2.307 (2.490)	GS 29.562 (32.451)	mem 73.245
Train: [40][1040/1500]	BT 0.033 (0.333)	DT 0.000 (0.295)	loss 6.755 (6.738)	prob 2.285 (2.526)	GS 36.484 (32.317)	mem 73.245
Train: [40][1050/1500]	BT 0.034 (0.330)	DT 0.000 (0.292)	loss 6.928 (6.743)	prob 2.516 (2.497)	GS 36.531 (32.441)	mem 73.244
Train: [40][1060/1500]	BT 0.036 (0.335)	DT 0.001 (0.297)	loss 7.031 (6.806)	prob 2.247 (2.224)	GS 31.328 (31.564)	mem 73.239
Train: [40][1070/1500]	BT 0.037 (0.333)	DT 0.001 (0.295)	loss 6.978 (6.793)	prob 1.049 (2.372)	GS 33.781 (32.472)	mem 73.240
Train: [40][1080/1500]	BT 0.029 (0.334)	DT 0.000 (0.296)	loss 6.908 (6.784)	prob 1.662 (2.405)	GS 35.797 (33.130)	mem 73.242
Train: [40][1090/1500]	BT 0.038 (0.331)	DT 0.001 (0.293)	loss 6.724 (6.786)	prob 2.478 (2.396)	GS 31.219 (32.544)	mem 73.242
Train: [40][1100/1500]	BT 0.039 (0.329)	DT 0.001 (0.291)	loss 6.723 (6.779)	prob 2.577 (2.376)	GS 34.234 (32.932)	mem 73.242
Train: [40][1110/1500]	BT 0.039 (0.329)	DT 0.001 (0.291)	loss 7.114 (6.849)	prob 1.121 (2.259)	GS 40.031 (32.894)	mem 73.243
Train: [40][1120/1500]	BT 0.039 (0.326)	DT 0.001 (0.288)	loss 6.679 (6.791)	prob 2.424 (2.261)	GS 33.609 (33.198)	mem 73.243
Train: [40][1130/1500]	BT 0.035 (0.328)	DT 0.001 (0.290)	loss 6.794 (6.791)	prob 2.506 (2.307)	GS 34.422 (32.957)	mem 73.243
Train: [40][1140/1500]	BT 0.037 (0.326)	DT 0.001 (0.288)	loss 6.762 (6.795)	prob 1.782 (2.287)	GS 35.719 (33.095)	mem 73.242
Train: [40][1150/1500]	BT 0.039 (0.326)	DT 0.001 (0.288)	loss 6.639 (6.805)	prob 3.230 (2.288)	GS 36.156 (33.101)	mem 73.243
Train: [40][1160/1500]	BT 0.040 (0.323)	DT 0.001 (0.285)	loss 6.685 (6.848)	prob 2.921 (2.069)	GS 36.656 (31.180)	mem 73.244
Train: [40][1170/1500]	BT 0.040 (0.321)	DT 0.001 (0.283)	loss 6.780 (6.822)	prob 2.228 (2.271)	GS 30.703 (31.766)	mem 73.244
Train: [40][1180/1500]	BT 0.038 (0.321)	DT 0.001 (0.283)	loss 6.830 (6.807)	prob 2.730 (2.313)	GS 36.266 (32.197)	mem 73.261
Train: [40][1190/1500]	BT 0.037 (0.319)	DT 0.001 (0.281)	loss 6.723 (6.812)	prob 2.128 (2.342)	GS 32.141 (32.289)	mem 73.262
Train: [40][1200/1500]	BT 0.071 (0.319)	DT 0.034 (0.281)	loss 6.793 (6.800)	prob 1.697 (2.360)	GS 34.328 (32.683)	mem 73.264
Train: [40][1210/1500]	BT 0.037 (0.316)	DT 0.001 (0.279)	loss 6.964 (6.739)	prob 1.379 (2.172)	GS 35.719 (33.487)	mem 73.264
Train: [40][1220/1500]	BT 0.037 (0.315)	DT 0.001 (0.277)	loss 6.775 (6.759)	prob 2.028 (2.182)	GS 31.641 (33.129)	mem 73.264
Train: [40][1230/1500]	BT 0.080 (0.315)	DT 0.042 (0.277)	loss 6.687 (6.747)	prob 1.993 (2.273)	GS 35.469 (32.961)	mem 73.266
Train: [40][1240/1500]	BT 0.037 (0.314)	DT 0.000 (0.277)	loss 6.694 (6.752)	prob 1.885 (2.258)	GS 33.344 (32.816)	mem 73.268
Train: [40][1250/1500]	BT 0.528 (0.313)	DT 0.490 (0.276)	loss 6.733 (6.754)	prob 3.012 (2.281)	GS 37.594 (33.046)	mem 73.269
Train: [40][1260/1500]	BT 0.038 (0.314)	DT 0.001 (0.276)	loss 6.785 (6.750)	prob 2.191 (2.406)	GS 30.812 (31.694)	mem 73.271
Train: [40][1270/1500]	BT 0.037 (0.313)	DT 0.001 (0.275)	loss 6.619 (6.756)	prob 1.278 (2.242)	GS 30.891 (32.055)	mem 73.272
Train: [40][1280/1500]	BT 0.514 (0.312)	DT 0.477 (0.274)	loss 6.807 (6.748)	prob 2.106 (2.208)	GS 35.781 (32.392)	mem 73.271
Train: [40][1290/1500]	BT 0.037 (0.312)	DT 0.001 (0.274)	loss 6.854 (6.747)	prob 2.507 (2.203)	GS 34.203 (32.521)	mem 73.272
Train: [40][1300/1500]	BT 0.053 (0.311)	DT 0.006 (0.273)	loss 6.499 (6.728)	prob 1.849 (2.198)	GS 37.188 (32.609)	mem 73.272
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [40][1310/1500]	BT 0.065 (0.311)	DT 0.015 (0.273)	loss 6.712 (6.704)	prob 1.974 (2.225)	GS 32.047 (31.650)	mem 73.273
Train: [40][1320/1500]	BT 0.035 (0.313)	DT 0.001 (0.275)	loss 6.889 (6.731)	prob 1.756 (2.352)	GS 37.859 (32.186)	mem 73.274
Train: [40][1330/1500]	BT 0.048 (0.313)	DT 0.001 (0.274)	loss 6.804 (6.744)	prob 2.096 (2.386)	GS 32.188 (32.272)	mem 73.274
Train: [40][1340/1500]	BT 0.025 (0.314)	DT 0.000 (0.276)	loss 6.683 (6.725)	prob 2.071 (2.330)	GS 33.750 (32.468)	mem 73.273
Train: [40][1350/1500]	BT 0.025 (0.312)	DT 0.000 (0.274)	loss 6.987 (6.737)	prob 2.111 (2.257)	GS 31.000 (32.877)	mem 73.272
Train: [40][1360/1500]	BT 0.030 (0.314)	DT 0.000 (0.276)	loss 6.907 (6.825)	prob 1.859 (1.920)	GS 37.188 (31.905)	mem 73.274
Train: [40][1370/1500]	BT 0.028 (0.312)	DT 0.000 (0.274)	loss 6.840 (6.798)	prob 2.872 (2.155)	GS 34.031 (32.346)	mem 73.274
Train: [40][1380/1500]	BT 0.025 (0.310)	DT 0.000 (0.272)	loss 6.972 (6.812)	prob 3.118 (2.435)	GS 34.297 (32.957)	mem 73.275
Train: [40][1390/1500]	BT 0.037 (0.311)	DT 0.001 (0.274)	loss 6.901 (6.826)	prob 3.150 (2.472)	GS 33.438 (32.611)	mem 73.277
Train: [40][1400/1500]	BT 0.037 (0.309)	DT 0.001 (0.272)	loss 6.910 (6.844)	prob 2.808 (2.452)	GS 33.875 (32.649)	mem 73.278
Train: [40][1410/1500]	BT 0.072 (0.312)	DT 0.017 (0.274)	loss 7.037 (6.882)	prob 2.769 (2.896)	GS 35.562 (31.777)	mem 73.280
Train: [40][1420/1500]	BT 0.078 (0.310)	DT 0.006 (0.272)	loss 6.947 (6.913)	prob 3.531 (2.806)	GS 35.266 (32.352)	mem 73.281
Train: [40][1430/1500]	BT 0.031 (0.312)	DT 0.001 (0.274)	loss 6.968 (6.902)	prob 2.832 (2.851)	GS 38.312 (32.599)	mem 73.280
Train: [40][1440/1500]	BT 0.033 (0.310)	DT 0.001 (0.272)	loss 7.004 (6.907)	prob 2.876 (2.827)	GS 34.375 (32.692)	mem 73.280
Train: [40][1450/1500]	BT 0.028 (0.308)	DT 0.000 (0.270)	loss 7.109 (6.930)	prob 2.714 (2.813)	GS 32.531 (32.713)	mem 73.281
Train: [40][1460/1500]	BT 0.029 (0.308)	DT 0.000 (0.270)	loss 6.873 (6.866)	prob 2.571 (3.109)	GS 34.906 (31.712)	mem 72.625
Train: [40][1470/1500]	BT 0.029 (0.306)	DT 0.000 (0.268)	loss 7.082 (6.936)	prob 2.565 (3.032)	GS 31.391 (31.827)	mem 72.625
Train: [40][1480/1500]	BT 0.029 (0.306)	DT 0.000 (0.268)	loss 7.174 (6.966)	prob 3.007 (3.075)	GS 32.016 (31.968)	mem 13.941
Train: [40][1490/1500]	BT 0.035 (0.304)	DT 0.001 (0.267)	loss 6.932 (6.990)	prob 2.440 (3.110)	GS 37.906 (31.979)	mem 13.868
Train: [40][1500/1500]	BT 0.035 (0.303)	DT 0.000 (0.265)	loss 7.161 (6.985)	prob 2.259 (3.122)	GS 35.094 (32.295)	mem 13.830
Train: [40][1510/1500]	BT 0.025 (0.301)	DT 0.000 (0.264)	loss 7.170 (6.769)	prob 2.808 (3.358)	GS 34.781 (35.244)	mem 8.208
epoch 40, total time 455.11
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [41][1/1500]	BT 24.287 (24.287)	DT 24.227 (24.227)	loss 6.818 (6.818)	prob 3.031 (3.031)	GS 31.938 (31.938)	mem 71.937
Train: [41][10/1500]	BT 0.038 (2.522)	DT 0.001 (2.483)	loss 6.990 (6.793)	prob 2.317 (3.153)	GS 37.125 (33.111)	mem 71.967
Train: [41][20/1500]	BT 0.039 (1.280)	DT 0.001 (1.242)	loss 6.768 (6.898)	prob 3.479 (3.193)	GS 32.156 (32.897)	mem 71.967
Train: [41][30/1500]	BT 0.125 (1.159)	DT 0.013 (1.112)	loss 6.973 (6.902)	prob 3.837 (3.315)	GS 34.641 (32.920)	mem 71.991
Train: [41][40/1500]	BT 0.058 (1.033)	DT 0.007 (0.980)	loss 7.007 (6.907)	prob 3.125 (3.368)	GS 36.344 (32.957)	mem 72.024
Train: [41][50/1500]	BT 0.064 (0.881)	DT 0.011 (0.831)	loss 7.049 (6.919)	prob 3.478 (3.446)	GS 32.797 (32.631)	mem 72.032
Train: [41][60/1500]	BT 13.917 (1.019)	DT 13.872 (0.968)	loss 7.239 (7.098)	prob 2.235 (3.396)	GS 40.891 (34.092)	mem 72.049
Train: [41][70/1500]	BT 0.030 (0.877)	DT 0.001 (0.830)	loss 7.039 (7.090)	prob 3.438 (3.461)	GS 34.109 (33.517)	mem 72.051
Train: [41][80/1500]	BT 0.024 (0.771)	DT 0.000 (0.726)	loss 6.927 (7.089)	prob 3.160 (3.385)	GS 30.938 (33.221)	mem 72.052
Train: [41][90/1500]	BT 0.039 (0.719)	DT 0.001 (0.675)	loss 6.688 (7.081)	prob 2.989 (3.407)	GS 33.125 (32.743)	mem 72.063
Train: [41][100/1500]	BT 0.039 (0.651)	DT 0.001 (0.608)	loss 7.016 (7.073)	prob 4.515 (3.398)	GS 32.125 (32.552)	mem 72.063
Train: [41][110/1500]	BT 0.038 (0.654)	DT 0.001 (0.611)	loss 7.312 (7.125)	prob 2.743 (3.384)	GS 33.438 (32.594)	mem 71.882
Train: [41][120/1500]	BT 0.029 (0.603)	DT 0.000 (0.560)	loss 7.164 (7.075)	prob 3.876 (3.245)	GS 34.469 (32.383)	mem 71.883
Train: [41][130/1500]	BT 0.040 (0.559)	DT 0.001 (0.517)	loss 7.064 (7.084)	prob 3.195 (3.125)	GS 31.859 (32.360)	mem 71.885
Train: [41][140/1500]	BT 0.030 (0.557)	DT 0.000 (0.516)	loss 7.212 (7.088)	prob 4.161 (3.123)	GS 28.984 (32.180)	mem 71.886
Train: [41][150/1500]	BT 0.031 (0.522)	DT 0.000 (0.481)	loss 6.843 (7.069)	prob 4.027 (3.150)	GS 32.688 (32.064)	mem 71.885
Train: [41][160/1500]	BT 0.030 (0.536)	DT 0.000 (0.495)	loss 6.846 (7.015)	prob 3.187 (2.892)	GS 32.812 (33.669)	mem 71.895
Train: [41][170/1500]	BT 0.038 (0.506)	DT 0.001 (0.466)	loss 6.924 (7.037)	prob 3.404 (2.939)	GS 32.828 (33.124)	mem 71.896
Train: [41][180/1500]	BT 4.295 (0.504)	DT 4.257 (0.463)	loss 7.283 (7.067)	prob 3.217 (2.828)	GS 34.484 (32.977)	mem 71.897
Train: [41][190/1500]	BT 0.034 (0.479)	DT 0.000 (0.439)	loss 6.986 (7.037)	prob 3.147 (2.791)	GS 35.172 (32.931)	mem 71.899
Train: [41][200/1500]	BT 0.037 (0.457)	DT 0.001 (0.417)	loss 7.153 (7.028)	prob 2.238 (2.768)	GS 32.766 (33.039)	mem 71.902
Train: [41][210/1500]	BT 0.033 (0.458)	DT 0.000 (0.418)	loss 6.889 (7.032)	prob 2.801 (2.763)	GS 36.156 (34.527)	mem 72.115
Train: [41][220/1500]	BT 0.038 (0.439)	DT 0.001 (0.399)	loss 6.854 (7.032)	prob 2.402 (2.580)	GS 37.047 (34.052)	mem 72.118
Train: [41][230/1500]	BT 0.039 (0.433)	DT 0.001 (0.394)	loss 6.882 (6.997)	prob 2.799 (2.653)	GS 29.016 (33.530)	mem 72.752
Train: [41][240/1500]	BT 0.038 (0.417)	DT 0.001 (0.378)	loss 7.409 (7.018)	prob 2.413 (2.621)	GS 30.734 (33.117)	mem 72.829
Train: [41][250/1500]	BT 0.037 (0.402)	DT 0.001 (0.362)	loss 7.086 (7.019)	prob 2.310 (2.645)	GS 37.203 (32.959)	mem 72.851
Train: [41][260/1500]	BT 0.037 (0.399)	DT 0.001 (0.360)	loss 7.023 (6.966)	prob 2.830 (2.687)	GS 33.297 (32.920)	mem 72.948
Train: [41][270/1500]	BT 0.036 (0.391)	DT 0.001 (0.352)	loss 7.007 (6.948)	prob 3.810 (2.915)	GS 33.875 (32.155)	mem 72.996
Train: [41][280/1500]	BT 0.037 (0.386)	DT 0.001 (0.347)	loss 6.673 (6.936)	prob 2.843 (2.910)	GS 32.094 (32.120)	mem 72.998
Train: [41][290/1500]	BT 0.031 (0.383)	DT 0.000 (0.344)	loss 6.988 (6.929)	prob 2.783 (2.882)	GS 32.797 (32.375)	mem 72.998
Train: [41][300/1500]	BT 3.801 (0.384)	DT 3.765 (0.345)	loss 7.169 (6.949)	prob 2.877 (2.832)	GS 30.281 (32.299)	mem 73.001
Train: [41][310/1500]	BT 0.037 (0.380)	DT 0.001 (0.342)	loss 6.871 (6.939)	prob 2.718 (2.947)	GS 36.422 (32.684)	mem 73.006
Train: [41][320/1500]	BT 0.061 (0.370)	DT 0.005 (0.331)	loss 7.360 (6.995)	prob 1.864 (2.621)	GS 37.812 (32.905)	mem 73.006
Train: [41][330/1500]	BT 0.064 (0.381)	DT 0.000 (0.341)	loss 6.684 (6.978)	prob 3.019 (2.569)	GS 33.500 (32.562)	mem 73.008
Train: [41][340/1500]	BT 0.044 (0.377)	DT 0.001 (0.337)	loss 7.154 (6.972)	prob 2.801 (2.564)	GS 35.203 (32.740)	mem 73.010
Train: [41][350/1500]	BT 0.037 (0.377)	DT 0.001 (0.337)	loss 7.047 (6.964)	prob 2.576 (2.630)	GS 36.094 (32.983)	mem 73.029
Train: [41][360/1500]	BT 0.051 (0.371)	DT 0.016 (0.331)	loss 6.713 (6.892)	prob 2.184 (2.542)	GS 33.875 (34.048)	mem 73.029
Train: [41][370/1500]	BT 0.028 (0.368)	DT 0.000 (0.328)	loss 6.615 (6.928)	prob 3.132 (2.581)	GS 32.516 (33.533)	mem 73.019
Train: [41][380/1500]	BT 0.144 (0.369)	DT 0.018 (0.328)	loss 6.756 (6.958)	prob 2.791 (2.557)	GS 32.594 (33.400)	mem 73.022
Train: [41][390/1500]	BT 0.031 (0.390)	DT 0.000 (0.349)	loss 7.012 (6.955)	prob 2.733 (2.685)	GS 34.906 (33.902)	mem 73.022
Train: [41][400/1500]	BT 0.031 (0.382)	DT 0.000 (0.340)	loss 6.827 (6.963)	prob 2.094 (2.677)	GS 35.031 (33.944)	mem 73.023
Train: [41][410/1500]	BT 0.033 (0.408)	DT 0.000 (0.367)	loss 6.700 (6.924)	prob 2.914 (2.611)	GS 30.656 (33.872)	mem 73.024
Train: [41][420/1500]	BT 0.030 (0.399)	DT 0.000 (0.358)	loss 6.816 (6.938)	prob 3.248 (2.681)	GS 37.438 (32.952)	mem 73.025
Train: [41][430/1500]	BT 0.031 (0.400)	DT 0.000 (0.359)	loss 6.671 (6.911)	prob 2.992 (2.794)	GS 34.125 (32.878)	mem 73.028
Train: [41][440/1500]	BT 0.031 (0.391)	DT 0.000 (0.351)	loss 6.704 (6.903)	prob 2.421 (2.734)	GS 29.094 (33.117)	mem 73.028
Train: [41][450/1500]	BT 0.037 (0.383)	DT 0.001 (0.343)	loss 7.072 (6.916)	prob 1.740 (2.729)	GS 35.188 (33.079)	mem 73.028
Train: [41][460/1500]	BT 0.039 (0.385)	DT 0.001 (0.344)	loss 6.668 (6.792)	prob 2.681 (2.588)	GS 28.953 (32.223)	mem 73.027
Train: [41][470/1500]	BT 0.039 (0.377)	DT 0.001 (0.337)	loss 6.548 (6.811)	prob 3.093 (2.678)	GS 35.297 (32.255)	mem 73.027
Train: [41][480/1500]	BT 0.028 (0.379)	DT 0.000 (0.339)	loss 7.492 (6.836)	prob 1.989 (2.644)	GS 34.297 (31.914)	mem 73.028
Train: [41][490/1500]	BT 0.039 (0.372)	DT 0.001 (0.332)	loss 6.634 (6.849)	prob 2.895 (2.567)	GS 35.984 (32.223)	mem 73.030
Train: [41][500/1500]	BT 0.039 (0.365)	DT 0.001 (0.325)	loss 6.828 (6.845)	prob 2.387 (2.606)	GS 35.109 (32.564)	mem 73.030
Train: [41][510/1500]	BT 0.027 (0.367)	DT 0.000 (0.328)	loss 6.630 (6.855)	prob 3.054 (2.346)	GS 31.438 (31.927)	mem 73.046
Train: [41][520/1500]	BT 0.027 (0.361)	DT 0.000 (0.321)	loss 6.821 (6.846)	prob 2.559 (2.300)	GS 30.891 (32.382)	mem 73.047
Train: [41][530/1500]	BT 0.036 (0.362)	DT 0.000 (0.323)	loss 7.017 (6.843)	prob 1.398 (2.216)	GS 32.141 (32.391)	mem 73.050
Train: [41][540/1500]	BT 0.038 (0.356)	DT 0.001 (0.317)	loss 7.362 (6.857)	prob 2.190 (2.221)	GS 30.047 (32.292)	mem 73.051
Train: [41][550/1500]	BT 0.037 (0.356)	DT 0.001 (0.316)	loss 6.612 (6.878)	prob 2.780 (2.218)	GS 28.766 (32.200)	mem 73.055
Train: [41][560/1500]	BT 0.037 (0.350)	DT 0.001 (0.311)	loss 6.810 (7.066)	prob 3.715 (2.598)	GS 33.609 (33.197)	mem 73.056
Train: [41][570/1500]	BT 0.037 (0.344)	DT 0.001 (0.305)	loss 7.083 (7.028)	prob 2.432 (2.451)	GS 32.828 (33.037)	mem 73.056
Train: [41][580/1500]	BT 0.035 (0.351)	DT 0.003 (0.312)	loss 7.556 (7.051)	prob 2.048 (2.259)	GS 35.891 (33.417)	mem 73.056
Train: [41][590/1500]	BT 0.042 (0.355)	DT 0.011 (0.316)	loss 7.485 (7.067)	prob 2.621 (2.344)	GS 34.391 (33.777)	mem 73.056
Train: [41][600/1500]	BT 0.060 (0.350)	DT 0.016 (0.311)	loss 7.053 (7.071)	prob 1.889 (2.326)	GS 32.031 (33.736)	mem 73.058
Train: [41][610/1500]	BT 0.100 (0.356)	DT 0.021 (0.317)	loss 7.910 (7.181)	prob 2.041 (2.767)	GS 35.172 (32.322)	mem 73.056
Train: [41][620/1500]	BT 0.070 (0.357)	DT 0.002 (0.317)	loss 7.233 (7.160)	prob 2.640 (2.427)	GS 29.859 (32.523)	mem 73.056
Train: [41][630/1500]	BT 0.060 (0.388)	DT 0.004 (0.348)	loss 7.452 (7.194)	prob 2.949 (2.511)	GS 35.938 (32.660)	mem 73.054
Train: [41][640/1500]	BT 0.028 (0.388)	DT 0.000 (0.348)	loss 7.832 (7.206)	prob 2.238 (2.560)	GS 34.156 (32.200)	mem 73.056
Train: [41][650/1500]	BT 0.027 (0.383)	DT 0.000 (0.343)	loss 6.984 (7.232)	prob 2.729 (2.629)	GS 33.688 (32.488)	mem 73.056
Train: [41][660/1500]	BT 3.549 (0.383)	DT 3.522 (0.343)	loss 7.189 (7.247)	prob 3.651 (2.850)	GS 36.500 (31.927)	mem 73.060
Train: [41][670/1500]	BT 0.027 (0.378)	DT 0.000 (0.338)	loss 7.603 (7.217)	prob 2.780 (2.908)	GS 28.750 (31.620)	mem 73.062
Train: [41][680/1500]	BT 0.037 (0.373)	DT 0.001 (0.334)	loss 7.197 (7.252)	prob 3.704 (2.950)	GS 36.781 (31.771)	mem 73.062
Train: [41][690/1500]	BT 0.026 (0.378)	DT 0.000 (0.338)	loss 7.402 (7.235)	prob 3.466 (2.962)	GS 34.922 (31.586)	mem 73.063
Train: [41][700/1500]	BT 0.038 (0.375)	DT 0.000 (0.335)	loss 7.265 (7.241)	prob 3.216 (2.992)	GS 32.422 (31.692)	mem 73.063
Train: [41][710/1500]	BT 0.035 (0.375)	DT 0.001 (0.335)	loss 7.538 (7.387)	prob 2.878 (2.938)	GS 34.781 (32.728)	mem 73.067
Train: [41][720/1500]	BT 0.027 (0.370)	DT 0.000 (0.330)	loss 7.154 (7.354)	prob 3.109 (3.155)	GS 36.000 (32.798)	mem 73.068
Train: [41][730/1500]	BT 0.038 (0.365)	DT 0.001 (0.326)	loss 7.120 (7.297)	prob 3.462 (3.220)	GS 37.156 (32.746)	mem 73.068
Train: [41][740/1500]	BT 0.031 (0.367)	DT 0.000 (0.328)	loss 7.277 (7.293)	prob 3.445 (3.258)	GS 31.219 (32.396)	mem 73.069
Train: [41][750/1500]	BT 0.079 (0.363)	DT 0.008 (0.324)	loss 8.020 (7.325)	prob 2.925 (3.292)	GS 32.609 (32.370)	mem 73.069
Train: [41][760/1500]	BT 0.038 (0.363)	DT 0.000 (0.324)	loss 7.486 (7.549)	prob 2.893 (2.952)	GS 32.406 (33.244)	mem 73.071
Train: [41][770/1500]	BT 0.062 (0.359)	DT 0.005 (0.319)	loss 7.432 (7.520)	prob 3.626 (3.068)	GS 32.422 (32.896)	mem 73.071
Train: [41][780/1500]	BT 0.037 (0.360)	DT 0.001 (0.320)	loss 7.442 (7.439)	prob 3.340 (3.174)	GS 29.250 (32.613)	mem 73.074
Train: [41][790/1500]	BT 0.037 (0.356)	DT 0.000 (0.316)	loss 7.711 (7.402)	prob 2.983 (3.250)	GS 34.094 (32.364)	mem 73.072
Train: [41][800/1500]	BT 0.038 (0.353)	DT 0.001 (0.314)	loss 7.467 (7.378)	prob 3.046 (3.279)	GS 34.969 (32.312)	mem 73.073
Train: [41][810/1500]	BT 0.037 (0.353)	DT 0.001 (0.314)	loss 8.027 (7.381)	prob 2.555 (3.077)	GS 36.203 (31.702)	mem 73.076
Train: [41][820/1500]	BT 0.038 (0.350)	DT 0.001 (0.310)	loss 7.954 (7.406)	prob 2.434 (3.077)	GS 41.094 (32.301)	mem 73.077
Train: [41][830/1500]	BT 0.037 (0.350)	DT 0.000 (0.310)	loss 7.313 (7.377)	prob 3.198 (3.213)	GS 34.875 (32.277)	mem 73.077
Train: [41][840/1500]	BT 0.037 (0.346)	DT 0.001 (0.306)	loss 7.603 (7.370)	prob 3.310 (3.332)	GS 31.766 (32.139)	mem 73.078
Train: [41][850/1500]	BT 0.037 (0.345)	DT 0.001 (0.305)	loss 7.501 (7.363)	prob 3.427 (3.305)	GS 32.422 (32.380)	mem 73.077
Train: [41][860/1500]	BT 0.028 (0.344)	DT 0.001 (0.305)	loss 7.359 (7.464)	prob 2.679 (3.060)	GS 31.875 (33.223)	mem 73.109
Train: [41][870/1500]	BT 0.037 (0.342)	DT 0.001 (0.303)	loss 7.842 (7.403)	prob 3.811 (3.119)	GS 30.625 (32.853)	mem 73.109
Train: [41][880/1500]	BT 0.052 (0.341)	DT 0.011 (0.301)	loss 7.202 (7.369)	prob 3.228 (3.113)	GS 36.500 (32.766)	mem 73.110
Train: [41][890/1500]	BT 0.069 (0.337)	DT 0.004 (0.298)	loss 7.447 (7.406)	prob 3.456 (3.113)	GS 37.906 (33.230)	mem 73.111
Train: [41][900/1500]	BT 1.067 (0.338)	DT 1.022 (0.299)	loss 7.469 (7.417)	prob 2.817 (3.102)	GS 36.062 (33.312)	mem 73.108
Train: [41][910/1500]	BT 0.039 (0.340)	DT 0.001 (0.301)	loss 7.293 (7.286)	prob 2.808 (2.975)	GS 34.438 (32.886)	mem 73.110
Train: [41][920/1500]	BT 0.039 (0.337)	DT 0.001 (0.298)	loss 7.528 (7.237)	prob 2.973 (3.153)	GS 31.281 (32.124)	mem 73.110
Train: [41][930/1500]	BT 0.051 (0.335)	DT 0.008 (0.296)	loss 7.116 (7.282)	prob 3.818 (3.081)	GS 31.641 (32.288)	mem 73.110
Train: [41][940/1500]	BT 0.039 (0.336)	DT 0.001 (0.297)	loss 7.357 (7.300)	prob 3.421 (3.199)	GS 32.906 (32.178)	mem 73.110
Train: [41][950/1500]	BT 0.031 (0.341)	DT 0.000 (0.302)	loss 7.073 (7.301)	prob 3.830 (3.157)	GS 32.969 (32.298)	mem 73.112
Train: [41][960/1500]	BT 0.039 (0.338)	DT 0.001 (0.299)	loss 7.886 (7.467)	prob 2.731 (3.149)	GS 32.156 (32.322)	mem 73.113
Train: [41][970/1500]	BT 0.039 (0.335)	DT 0.001 (0.296)	loss 7.397 (7.346)	prob 3.737 (3.263)	GS 36.047 (32.394)	mem 73.114
Train: [41][980/1500]	BT 0.033 (0.337)	DT 0.000 (0.298)	loss 7.355 (7.361)	prob 3.454 (3.120)	GS 32.641 (32.779)	mem 73.112
Train: [41][990/1500]	BT 0.078 (0.334)	DT 0.011 (0.295)	loss 7.446 (7.371)	prob 2.947 (3.050)	GS 35.312 (32.818)	mem 73.111
Train: [41][1000/1500]	BT 0.028 (0.339)	DT 0.000 (0.300)	loss 7.082 (7.354)	prob 3.623 (3.090)	GS 34.969 (32.715)	mem 73.109
Train: [41][1010/1500]	BT 0.037 (0.338)	DT 0.001 (0.299)	loss 7.459 (7.348)	prob 3.356 (3.029)	GS 31.328 (35.033)	mem 73.110
Train: [41][1020/1500]	BT 0.039 (0.336)	DT 0.001 (0.297)	loss 7.341 (7.255)	prob 3.852 (3.198)	GS 33.375 (32.715)	mem 73.111
Train: [41][1030/1500]	BT 0.030 (0.333)	DT 0.000 (0.294)	loss 7.410 (7.258)	prob 3.034 (3.200)	GS 31.172 (32.114)	mem 73.111
Train: [41][1040/1500]	BT 0.040 (0.333)	DT 0.000 (0.295)	loss 7.483 (7.257)	prob 2.861 (3.122)	GS 32.906 (32.250)	mem 73.111
Train: [41][1050/1500]	BT 0.039 (0.331)	DT 0.001 (0.292)	loss 7.122 (7.278)	prob 2.902 (3.045)	GS 33.281 (32.503)	mem 73.112
Train: [41][1060/1500]	BT 0.039 (0.330)	DT 0.001 (0.292)	loss 7.360 (7.543)	prob 3.142 (2.653)	GS 32.312 (32.545)	mem 73.111
Train: [41][1070/1500]	BT 0.039 (0.328)	DT 0.001 (0.289)	loss 7.170 (7.474)	prob 3.160 (2.832)	GS 29.766 (32.233)	mem 73.110
Train: [41][1080/1500]	BT 0.036 (0.325)	DT 0.001 (0.287)	loss 7.213 (7.456)	prob 3.730 (2.796)	GS 31.219 (31.960)	mem 73.111
Train: [41][1090/1500]	BT 0.039 (0.326)	DT 0.001 (0.287)	loss 7.548 (7.448)	prob 2.867 (2.701)	GS 34.203 (31.903)	mem 73.112
Train: [41][1100/1500]	BT 0.037 (0.323)	DT 0.001 (0.284)	loss 7.180 (7.462)	prob 3.484 (2.719)	GS 32.656 (31.783)	mem 73.111
Train: [41][1110/1500]	BT 0.034 (0.324)	DT 0.000 (0.285)	loss 7.176 (7.417)	prob 2.101 (2.387)	GS 33.750 (32.730)	mem 73.117
Train: [41][1120/1500]	BT 0.033 (0.321)	DT 0.001 (0.283)	loss 7.998 (7.514)	prob 2.520 (2.180)	GS 34.938 (32.916)	mem 73.119
Train: [41][1130/1500]	BT 0.037 (0.322)	DT 0.000 (0.283)	loss 7.261 (7.447)	prob 2.259 (2.353)	GS 32.578 (32.643)	mem 73.132
Train: [41][1140/1500]	BT 0.037 (0.321)	DT 0.001 (0.282)	loss 7.273 (7.451)	prob 2.950 (2.310)	GS 30.766 (32.350)	mem 73.132
Train: [41][1150/1500]	BT 0.037 (0.318)	DT 0.001 (0.279)	loss 7.849 (7.465)	prob 2.774 (2.224)	GS 30.266 (32.508)	mem 73.125
Train: [41][1160/1500]	BT 0.031 (0.323)	DT 0.000 (0.284)	loss 7.479 (7.556)	prob 2.437 (2.092)	GS 31.047 (32.750)	mem 73.032
Train: [41][1170/1500]	BT 0.027 (0.320)	DT 0.000 (0.282)	loss 7.734 (7.636)	prob 2.833 (2.090)	GS 29.250 (32.391)	mem 73.032
Train: [41][1180/1500]	BT 0.074 (0.318)	DT 0.036 (0.279)	loss 7.812 (7.637)	prob 2.834 (2.088)	GS 35.703 (32.491)	mem 73.033
Train: [41][1190/1500]	BT 0.033 (0.319)	DT 0.001 (0.281)	loss 8.060 (7.591)	prob 2.451 (2.077)	GS 34.344 (32.728)	mem 73.035
Train: [41][1200/1500]	BT 0.037 (0.317)	DT 0.000 (0.279)	loss 7.998 (7.605)	prob 2.379 (2.058)	GS 35.500 (32.867)	mem 73.035
Train: [41][1210/1500]	BT 0.032 (0.318)	DT 0.000 (0.279)	loss 7.555 (7.488)	prob 2.278 (2.047)	GS 33.203 (32.847)	mem 73.038
Train: [41][1220/1500]	BT 0.032 (0.315)	DT 0.000 (0.277)	loss 7.796 (7.624)	prob 3.513 (2.249)	GS 32.203 (32.209)	mem 73.038
Train: [41][1230/1500]	BT 0.038 (0.320)	DT 0.000 (0.282)	loss 7.519 (7.600)	prob 2.827 (2.310)	GS 35.297 (32.352)	mem 73.057
Train: [41][1240/1500]	BT 0.078 (0.318)	DT 0.016 (0.280)	loss 7.504 (7.583)	prob 2.839 (2.316)	GS 33.406 (32.691)	mem 73.057
Train: [41][1250/1500]	BT 0.037 (0.316)	DT 0.001 (0.278)	loss 7.432 (7.611)	prob 2.777 (2.364)	GS 34.250 (32.636)	mem 73.057
Train: [41][1260/1500]	BT 0.037 (0.321)	DT 0.000 (0.283)	loss 7.923 (7.686)	prob 2.097 (2.407)	GS 36.156 (32.131)	mem 73.041
Train: [41][1270/1500]	BT 0.027 (0.328)	DT 0.000 (0.290)	loss 7.530 (7.612)	prob 2.773 (2.408)	GS 31.250 (32.891)	mem 73.040
Train: [41][1280/1500]	BT 0.027 (0.326)	DT 0.000 (0.287)	loss 8.036 (7.691)	prob 2.580 (2.381)	GS 30.141 (32.921)	mem 73.040
Train: [41][1290/1500]	BT 0.031 (0.327)	DT 0.000 (0.288)	loss 7.863 (7.655)	prob 3.194 (2.472)	GS 35.891 (32.445)	mem 73.040
Train: [41][1300/1500]	BT 0.033 (0.324)	DT 0.001 (0.286)	loss 7.154 (7.625)	prob 3.223 (2.554)	GS 31.484 (32.527)	mem 73.040
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [41][1310/1500]	BT 0.036 (0.322)	DT 0.000 (0.284)	loss 7.623 (7.658)	prob 3.727 (3.024)	GS 30.125 (31.116)	mem 73.041
Train: [41][1320/1500]	BT 0.040 (0.322)	DT 0.001 (0.284)	loss 8.354 (7.629)	prob 2.512 (2.842)	GS 36.016 (31.665)	mem 73.042
Train: [41][1330/1500]	BT 0.036 (0.320)	DT 0.000 (0.282)	loss 8.268 (7.632)	prob 3.474 (2.667)	GS 30.703 (31.685)	mem 73.042
Train: [41][1340/1500]	BT 0.040 (0.320)	DT 0.001 (0.282)	loss 7.741 (7.638)	prob 2.956 (2.673)	GS 33.641 (32.162)	mem 73.043
Train: [41][1350/1500]	BT 0.039 (0.318)	DT 0.001 (0.280)	loss 7.776 (7.640)	prob 3.446 (2.713)	GS 33.156 (32.264)	mem 73.044
Train: [41][1360/1500]	BT 3.031 (0.318)	DT 2.992 (0.280)	loss 7.345 (7.525)	prob 3.617 (2.840)	GS 32.891 (32.794)	mem 73.043
Train: [41][1370/1500]	BT 0.079 (0.316)	DT 0.041 (0.278)	loss 7.585 (7.563)	prob 3.086 (2.978)	GS 34.250 (31.913)	mem 73.045
Train: [41][1380/1500]	BT 0.039 (0.314)	DT 0.001 (0.276)	loss 7.439 (7.615)	prob 2.833 (2.910)	GS 32.391 (31.993)	mem 73.044
Train: [41][1390/1500]	BT 0.035 (0.316)	DT 0.001 (0.277)	loss 7.343 (7.571)	prob 3.139 (2.881)	GS 35.438 (32.320)	mem 73.057
Train: [41][1400/1500]	BT 0.057 (0.314)	DT 0.016 (0.276)	loss 7.142 (7.542)	prob 3.823 (3.028)	GS 30.031 (31.975)	mem 73.056
Train: [41][1410/1500]	BT 0.063 (0.315)	DT 0.016 (0.277)	loss 7.944 (7.668)	prob 3.102 (2.730)	GS 30.891 (32.523)	mem 73.059
Train: [41][1420/1500]	BT 0.038 (0.315)	DT 0.001 (0.276)	loss 7.314 (7.603)	prob 3.488 (2.847)	GS 35.031 (32.517)	mem 73.060
Train: [41][1430/1500]	BT 0.047 (0.313)	DT 0.014 (0.275)	loss 7.616 (7.616)	prob 3.684 (2.958)	GS 37.078 (32.902)	mem 73.063
Train: [41][1440/1500]	BT 0.037 (0.315)	DT 0.001 (0.277)	loss 8.796 (7.610)	prob 1.844 (2.931)	GS 35.781 (33.192)	mem 73.068
Train: [41][1450/1500]	BT 0.037 (0.314)	DT 0.001 (0.275)	loss 7.569 (7.618)	prob 4.093 (3.010)	GS 29.625 (32.828)	mem 73.069
Train: [41][1460/1500]	BT 0.131 (0.313)	DT 0.011 (0.275)	loss 8.139 (7.628)	prob 2.888 (3.467)	GS 34.391 (31.425)	mem 72.816
Train: [41][1470/1500]	BT 0.031 (0.312)	DT 0.000 (0.273)	loss 7.954 (7.592)	prob 2.709 (3.196)	GS 35.891 (32.463)	mem 72.634
Train: [41][1480/1500]	BT 0.029 (0.315)	DT 0.000 (0.277)	loss 8.039 (7.657)	prob 2.537 (3.069)	GS 28.734 (32.180)	mem 13.697
Train: [41][1490/1500]	BT 0.034 (0.313)	DT 0.000 (0.275)	loss 8.333 (7.702)	prob 3.144 (3.102)	GS 31.906 (32.329)	mem 13.623
Train: [41][1500/1500]	BT 0.027 (0.311)	DT 0.000 (0.273)	loss 8.179 (7.706)	prob 2.792 (3.083)	GS 33.312 (32.293)	mem 13.587
Train: [41][1510/1500]	BT 0.036 (0.310)	DT 0.000 (0.272)	loss 7.947 (7.511)	prob 3.012 (3.443)	GS 34.844 (34.494)	mem 7.969
epoch 41, total time 468.00
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [42][1/1500]	BT 20.915 (20.915)	DT 20.839 (20.839)	loss 6.910 (6.910)	prob 3.378 (3.378)	GS 27.047 (27.047)	mem 71.687
Train: [42][10/1500]	BT 0.033 (2.264)	DT 0.000 (2.210)	loss 7.499 (7.447)	prob 3.977 (3.185)	GS 32.375 (32.568)	mem 71.708
Train: [42][20/1500]	BT 0.036 (1.449)	DT 0.001 (1.406)	loss 7.998 (7.502)	prob 2.984 (3.141)	GS 34.250 (33.518)	mem 71.769
Train: [42][30/1500]	BT 0.052 (0.979)	DT 0.012 (0.938)	loss 7.539 (7.488)	prob 4.307 (3.254)	GS 35.516 (32.948)	mem 71.769
Train: [42][40/1500]	BT 0.030 (0.888)	DT 0.000 (0.848)	loss 7.336 (7.432)	prob 3.004 (3.312)	GS 33.250 (33.312)	mem 71.784
Train: [42][50/1500]	BT 0.033 (0.716)	DT 0.000 (0.679)	loss 7.859 (7.492)	prob 3.167 (3.266)	GS 32.875 (33.287)	mem 71.785
Train: [42][60/1500]	BT 0.037 (0.654)	DT 0.000 (0.618)	loss 7.864 (7.355)	prob 3.291 (3.762)	GS 34.297 (32.070)	mem 71.814
Train: [42][70/1500]	BT 0.037 (0.566)	DT 0.000 (0.530)	loss 8.236 (7.439)	prob 2.648 (3.559)	GS 36.641 (32.438)	mem 71.815
Train: [42][80/1500]	BT 0.068 (0.502)	DT 0.007 (0.464)	loss 7.239 (7.505)	prob 3.063 (3.361)	GS 36.641 (32.521)	mem 71.816
Train: [42][90/1500]	BT 0.030 (0.503)	DT 0.000 (0.466)	loss 7.990 (7.497)	prob 3.594 (3.456)	GS 34.172 (32.288)	mem 71.831
Train: [42][100/1500]	BT 0.047 (0.456)	DT 0.010 (0.420)	loss 7.193 (7.471)	prob 3.383 (3.427)	GS 32.016 (32.337)	mem 71.833
Train: [42][110/1500]	BT 0.037 (0.449)	DT 0.001 (0.414)	loss 7.518 (7.596)	prob 4.390 (3.504)	GS 33.938 (31.820)	mem 71.839
Train: [42][120/1500]	BT 0.038 (0.415)	DT 0.000 (0.379)	loss 8.154 (7.541)	prob 3.247 (3.544)	GS 30.578 (31.966)	mem 71.839
Train: [42][130/1500]	BT 0.037 (0.386)	DT 0.000 (0.350)	loss 7.115 (7.538)	prob 4.069 (3.437)	GS 29.375 (31.766)	mem 71.840
Train: [42][140/1500]	BT 0.058 (0.425)	DT 0.001 (0.389)	loss 7.523 (7.511)	prob 2.933 (3.432)	GS 39.297 (32.366)	mem 71.851
Train: [42][150/1500]	BT 0.071 (0.401)	DT 0.011 (0.363)	loss 8.163 (7.529)	prob 3.256 (3.319)	GS 36.750 (32.355)	mem 71.851
Train: [42][160/1500]	BT 0.026 (0.411)	DT 0.000 (0.373)	loss 7.144 (7.552)	prob 3.142 (3.067)	GS 30.812 (32.411)	mem 71.856
Train: [42][170/1500]	BT 0.026 (0.389)	DT 0.000 (0.351)	loss 8.006 (7.643)	prob 2.482 (3.033)	GS 36.141 (32.446)	mem 71.856
Train: [42][180/1500]	BT 0.037 (0.386)	DT 0.000 (0.349)	loss 8.249 (7.621)	prob 3.491 (3.123)	GS 35.594 (32.603)	mem 71.861
Train: [42][190/1500]	BT 0.037 (0.370)	DT 0.001 (0.332)	loss 7.451 (7.635)	prob 3.920 (3.061)	GS 34.453 (32.843)	mem 71.860
Train: [42][200/1500]	BT 0.024 (0.357)	DT 0.000 (0.320)	loss 7.320 (7.620)	prob 3.180 (3.014)	GS 33.812 (32.897)	mem 71.861
Train: [42][210/1500]	BT 0.029 (0.356)	DT 0.000 (0.319)	loss 7.597 (7.692)	prob 4.634 (2.889)	GS 36.188 (32.489)	mem 71.895
Train: [42][220/1500]	BT 0.039 (0.347)	DT 0.000 (0.311)	loss 7.861 (7.567)	prob 2.977 (3.019)	GS 37.125 (32.567)	mem 71.895
Train: [42][230/1500]	BT 0.037 (0.345)	DT 0.000 (0.308)	loss 7.573 (7.630)	prob 3.659 (3.033)	GS 34.156 (32.544)	mem 71.900
Train: [42][240/1500]	BT 0.040 (0.332)	DT 0.001 (0.295)	loss 7.820 (7.658)	prob 3.140 (2.942)	GS 32.922 (32.742)	mem 71.900
Train: [42][250/1500]	BT 0.081 (0.337)	DT 0.002 (0.299)	loss 7.453 (7.680)	prob 3.401 (2.875)	GS 30.422 (32.794)	mem 71.901
Train: [42][260/1500]	BT 0.039 (0.337)	DT 0.001 (0.299)	loss 7.588 (7.697)	prob 3.172 (2.829)	GS 33.234 (33.623)	mem 71.901
Train: [42][270/1500]	BT 0.039 (0.338)	DT 0.001 (0.300)	loss 7.970 (7.788)	prob 2.865 (2.410)	GS 33.578 (34.148)	mem 72.141
Train: [42][280/1500]	BT 0.039 (0.327)	DT 0.001 (0.289)	loss 9.316 (7.806)	prob 1.822 (2.456)	GS 31.594 (33.320)	mem 72.194
Train: [42][290/1500]	BT 0.039 (0.323)	DT 0.001 (0.285)	loss 7.486 (7.773)	prob 3.635 (2.568)	GS 31.250 (33.023)	mem 72.733
Train: [42][300/1500]	BT 0.039 (0.322)	DT 0.001 (0.284)	loss 7.895 (7.753)	prob 2.688 (2.673)	GS 33.703 (32.562)	mem 73.027
Train: [42][310/1500]	BT 0.039 (0.313)	DT 0.001 (0.275)	loss 7.671 (7.540)	prob 1.823 (2.299)	GS 32.812 (32.430)	mem 73.075
Train: [42][320/1500]	BT 0.040 (0.317)	DT 0.001 (0.279)	loss 7.657 (7.578)	prob 3.044 (2.637)	GS 34.031 (32.473)	mem 73.078
Train: [42][330/1500]	BT 0.039 (0.309)	DT 0.001 (0.271)	loss 8.060 (7.633)	prob 3.418 (2.628)	GS 36.094 (32.631)	mem 73.078
Train: [42][340/1500]	BT 0.038 (0.314)	DT 0.000 (0.276)	loss 8.395 (7.694)	prob 2.982 (2.593)	GS 35.891 (32.826)	mem 73.079
Train: [42][350/1500]	BT 0.028 (0.306)	DT 0.000 (0.268)	loss 8.359 (7.740)	prob 3.557 (2.645)	GS 35.109 (32.704)	mem 73.081
Train: [42][360/1500]	BT 0.040 (0.299)	DT 0.001 (0.260)	loss 7.637 (7.582)	prob 4.263 (3.341)	GS 31.562 (31.233)	mem 73.082
Train: [42][370/1500]	BT 0.040 (0.299)	DT 0.001 (0.261)	loss 7.727 (7.682)	prob 3.197 (3.078)	GS 36.656 (32.382)	mem 73.080
Train: [42][380/1500]	BT 0.061 (0.296)	DT 0.004 (0.258)	loss 7.844 (7.712)	prob 4.064 (3.053)	GS 34.031 (32.047)	mem 73.084
Train: [42][390/1500]	BT 0.086 (0.299)	DT 0.003 (0.260)	loss 8.003 (7.722)	prob 2.780 (2.965)	GS 42.094 (32.261)	mem 73.087
Train: [42][400/1500]	BT 0.028 (0.328)	DT 0.000 (0.289)	loss 7.924 (7.719)	prob 2.873 (3.016)	GS 33.953 (32.448)	mem 73.088
Train: [42][410/1500]	BT 0.039 (0.321)	DT 0.000 (0.282)	loss 7.557 (7.663)	prob 3.591 (3.235)	GS 33.078 (32.902)	mem 73.089
Train: [42][420/1500]	BT 3.997 (0.323)	DT 3.962 (0.285)	loss 8.081 (7.738)	prob 3.352 (3.284)	GS 33.688 (32.593)	mem 73.089
Train: [42][430/1500]	BT 0.026 (0.317)	DT 0.000 (0.278)	loss 8.299 (7.780)	prob 2.664 (3.210)	GS 34.188 (32.630)	mem 73.091
Train: [42][440/1500]	BT 0.038 (0.310)	DT 0.001 (0.272)	loss 8.518 (7.811)	prob 2.385 (3.122)	GS 34.969 (32.703)	mem 73.094
Train: [42][450/1500]	BT 0.037 (0.311)	DT 0.000 (0.272)	loss 8.376 (7.815)	prob 3.136 (3.166)	GS 34.844 (32.803)	mem 73.092
Train: [42][460/1500]	BT 0.037 (0.305)	DT 0.001 (0.266)	loss 7.726 (7.832)	prob 3.462 (3.336)	GS 34.344 (32.278)	mem 73.091
Train: [42][470/1500]	BT 0.037 (0.305)	DT 0.001 (0.267)	loss 7.607 (7.839)	prob 3.268 (3.270)	GS 31.312 (32.095)	mem 73.092
Train: [42][480/1500]	BT 0.037 (0.299)	DT 0.001 (0.261)	loss 7.591 (7.836)	prob 2.177 (3.134)	GS 33.938 (32.526)	mem 73.092
Train: [42][490/1500]	BT 0.037 (0.294)	DT 0.001 (0.256)	loss 7.917 (7.813)	prob 3.502 (3.096)	GS 30.719 (32.570)	mem 73.093
Train: [42][500/1500]	BT 0.037 (0.298)	DT 0.000 (0.260)	loss 8.386 (7.853)	prob 4.376 (3.109)	GS 34.891 (32.493)	mem 73.106
Train: [42][510/1500]	BT 0.039 (0.293)	DT 0.001 (0.255)	loss 8.581 (8.146)	prob 3.544 (3.397)	GS 38.625 (31.528)	mem 73.127
Train: [42][520/1500]	BT 0.028 (0.296)	DT 0.000 (0.257)	loss 7.535 (7.970)	prob 3.064 (3.402)	GS 32.672 (31.191)	mem 73.008
Train: [42][530/1500]	BT 0.037 (0.291)	DT 0.001 (0.253)	loss 7.896 (7.888)	prob 3.937 (3.451)	GS 33.062 (31.011)	mem 73.009
Train: [42][540/1500]	BT 4.218 (0.294)	DT 4.183 (0.256)	loss 8.603 (7.907)	prob 2.659 (3.437)	GS 35.719 (31.288)	mem 73.009
Train: [42][550/1500]	BT 0.036 (0.289)	DT 0.000 (0.251)	loss 8.451 (7.942)	prob 3.415 (3.349)	GS 32.359 (31.539)	mem 73.009
Train: [42][560/1500]	BT 0.037 (0.284)	DT 0.000 (0.247)	loss 8.128 (7.757)	prob 3.675 (3.321)	GS 33.031 (31.238)	mem 73.011
Train: [42][570/1500]	BT 0.035 (0.288)	DT 0.000 (0.250)	loss 8.392 (7.885)	prob 3.457 (3.139)	GS 36.062 (32.134)	mem 73.012
Train: [42][580/1500]	BT 0.030 (0.283)	DT 0.000 (0.245)	loss 8.004 (7.911)	prob 4.193 (3.253)	GS 32.594 (31.813)	mem 73.014
Train: [42][590/1500]	BT 0.051 (0.284)	DT 0.001 (0.246)	loss 8.085 (7.942)	prob 2.781 (3.222)	GS 31.875 (31.998)	mem 73.018
Train: [42][600/1500]	BT 0.064 (0.280)	DT 0.002 (0.242)	loss 7.766 (7.951)	prob 3.315 (3.218)	GS 32.656 (31.934)	mem 73.018
Train: [42][610/1500]	BT 0.060 (0.277)	DT 0.011 (0.238)	loss 7.242 (8.015)	prob 4.115 (3.069)	GS 37.250 (33.036)	mem 73.018
Train: [42][620/1500]	BT 0.037 (0.285)	DT 0.001 (0.247)	loss 7.890 (7.985)	prob 3.727 (2.972)	GS 33.531 (33.358)	mem 73.034
Train: [42][630/1500]	BT 0.037 (0.281)	DT 0.000 (0.243)	loss 8.203 (7.985)	prob 3.743 (3.138)	GS 33.672 (33.131)	mem 73.034
Train: [42][640/1500]	BT 0.041 (0.282)	DT 0.001 (0.244)	loss 8.552 (7.948)	prob 2.814 (3.182)	GS 34.578 (33.032)	mem 73.037
Train: [42][650/1500]	BT 0.038 (0.279)	DT 0.001 (0.241)	loss 7.582 (7.980)	prob 3.238 (3.163)	GS 36.125 (32.881)	mem 73.038
Train: [42][660/1500]	BT 9.091 (0.289)	DT 9.043 (0.251)	loss 7.706 (7.925)	prob 4.375 (3.152)	GS 32.859 (32.686)	mem 73.026
Train: [42][670/1500]	BT 0.036 (0.288)	DT 0.000 (0.250)	loss 7.782 (7.888)	prob 3.410 (3.295)	GS 31.109 (33.305)	mem 73.026
Train: [42][680/1500]	BT 0.064 (0.285)	DT 0.006 (0.246)	loss 8.254 (7.925)	prob 3.430 (3.117)	GS 30.031 (33.431)	mem 73.027
Train: [42][690/1500]	BT 0.034 (0.307)	DT 0.001 (0.268)	loss 7.441 (7.852)	prob 4.057 (3.150)	GS 31.547 (33.239)	mem 73.029
Train: [42][700/1500]	BT 0.036 (0.303)	DT 0.000 (0.264)	loss 7.828 (7.832)	prob 3.711 (3.178)	GS 34.781 (33.219)	mem 73.030
Train: [42][710/1500]	BT 0.029 (0.304)	DT 0.000 (0.266)	loss 7.863 (7.869)	prob 3.603 (3.351)	GS 33.703 (32.009)	mem 73.031
Train: [42][720/1500]	BT 0.039 (0.301)	DT 0.001 (0.262)	loss 8.547 (7.863)	prob 3.116 (3.462)	GS 33.328 (31.530)	mem 73.033
Train: [42][730/1500]	BT 0.030 (0.297)	DT 0.000 (0.259)	loss 7.317 (7.787)	prob 4.154 (3.519)	GS 28.297 (31.479)	mem 73.034
Train: [42][740/1500]	BT 0.039 (0.298)	DT 0.001 (0.260)	loss 7.709 (7.740)	prob 3.412 (3.505)	GS 36.391 (31.796)	mem 73.034
Train: [42][750/1500]	BT 0.039 (0.295)	DT 0.001 (0.256)	loss 8.313 (7.753)	prob 3.497 (3.457)	GS 33.109 (31.808)	mem 73.033
Train: [42][760/1500]	BT 0.038 (0.297)	DT 0.001 (0.258)	loss 7.622 (7.902)	prob 3.855 (3.224)	GS 36.703 (33.630)	mem 73.035
Train: [42][770/1500]	BT 0.039 (0.293)	DT 0.001 (0.255)	loss 7.989 (7.785)	prob 3.248 (3.131)	GS 35.969 (32.834)	mem 73.036
Train: [42][780/1500]	BT 0.036 (0.296)	DT 0.000 (0.258)	loss 7.639 (7.845)	prob 3.267 (3.116)	GS 32.000 (32.216)	mem 73.052
Train: [42][790/1500]	BT 0.037 (0.293)	DT 0.000 (0.254)	loss 8.152 (7.815)	prob 3.635 (3.161)	GS 30.969 (31.943)	mem 73.051
Train: [42][800/1500]	BT 0.037 (0.289)	DT 0.000 (0.251)	loss 7.885 (7.778)	prob 3.621 (3.225)	GS 34.438 (31.926)	mem 73.052
Train: [42][810/1500]	BT 0.028 (0.292)	DT 0.000 (0.254)	loss 7.039 (7.506)	prob 4.175 (3.193)	GS 28.359 (31.009)	mem 73.054
Train: [42][820/1500]	BT 0.034 (0.289)	DT 0.000 (0.251)	loss 8.404 (7.761)	prob 3.378 (3.178)	GS 31.438 (31.817)	mem 73.055
Train: [42][830/1500]	BT 0.039 (0.289)	DT 0.001 (0.251)	loss 8.205 (7.733)	prob 3.543 (3.153)	GS 34.766 (31.915)	mem 73.058
Train: [42][840/1500]	BT 0.039 (0.286)	DT 0.001 (0.248)	loss 8.056 (7.722)	prob 4.012 (3.167)	GS 32.328 (31.981)	mem 73.059
Train: [42][850/1500]	BT 0.039 (0.283)	DT 0.001 (0.245)	loss 7.665 (7.740)	prob 3.332 (3.085)	GS 33.969 (32.307)	mem 73.059
Train: [42][860/1500]	BT 0.060 (0.288)	DT 0.011 (0.250)	loss 7.948 (7.908)	prob 3.286 (2.710)	GS 31.844 (33.791)	mem 73.062
Train: [42][870/1500]	BT 0.062 (0.285)	DT 0.014 (0.247)	loss 7.694 (7.916)	prob 3.367 (2.685)	GS 33.266 (33.725)	mem 73.062
Train: [42][880/1500]	BT 0.059 (0.290)	DT 0.004 (0.251)	loss 8.148 (7.921)	prob 3.361 (2.829)	GS 36.656 (33.981)	mem 73.063
Train: [42][890/1500]	BT 0.060 (0.287)	DT 0.002 (0.249)	loss 7.611 (7.895)	prob 2.673 (2.846)	GS 31.719 (33.614)	mem 73.063
Train: [42][900/1500]	BT 0.030 (0.298)	DT 0.000 (0.260)	loss 8.093 (7.949)	prob 1.383 (2.745)	GS 32.312 (33.474)	mem 73.061
Train: [42][910/1500]	BT 0.031 (0.295)	DT 0.000 (0.257)	loss 8.615 (7.950)	prob 2.404 (2.373)	GS 34.266 (32.656)	mem 73.061
Train: [42][920/1500]	BT 0.037 (0.297)	DT 0.000 (0.258)	loss 7.720 (7.854)	prob 3.155 (2.612)	GS 31.875 (31.793)	mem 73.062
Train: [42][930/1500]	BT 0.031 (0.294)	DT 0.000 (0.256)	loss 8.102 (7.838)	prob 1.778 (2.705)	GS 34.047 (31.766)	mem 73.062
Train: [42][940/1500]	BT 0.039 (0.296)	DT 0.000 (0.257)	loss 7.989 (7.871)	prob 2.480 (2.616)	GS 34.531 (31.895)	mem 73.064
Train: [42][950/1500]	BT 0.037 (0.293)	DT 0.001 (0.254)	loss 7.552 (7.886)	prob 2.949 (2.626)	GS 34.781 (31.900)	mem 73.064
Train: [42][960/1500]	BT 0.037 (0.290)	DT 0.001 (0.252)	loss 8.856 (8.078)	prob 2.924 (2.196)	GS 36.656 (32.902)	mem 73.064
Train: [42][970/1500]	BT 0.032 (0.291)	DT 0.001 (0.252)	loss 8.844 (7.972)	prob 1.466 (2.122)	GS 33.703 (33.320)	mem 73.064
Train: [42][980/1500]	BT 0.037 (0.288)	DT 0.000 (0.250)	loss 9.059 (7.997)	prob 1.972 (2.263)	GS 33.766 (33.199)	mem 73.066
Train: [42][990/1500]	BT 0.037 (0.290)	DT 0.001 (0.251)	loss 7.885 (8.022)	prob 3.577 (2.212)	GS 37.328 (33.276)	mem 73.068
Train: [42][1000/1500]	BT 0.037 (0.287)	DT 0.000 (0.249)	loss 8.664 (8.018)	prob 3.135 (2.388)	GS 32.469 (32.839)	mem 73.068
Train: [42][1010/1500]	BT 0.062 (0.285)	DT 0.001 (0.246)	loss 8.146 (8.089)	prob 3.131 (2.622)	GS 33.453 (33.067)	mem 73.068
Train: [42][1020/1500]	BT 0.028 (0.295)	DT 0.000 (0.257)	loss 8.081 (8.142)	prob 3.649 (2.625)	GS 31.797 (33.013)	mem 73.071
Train: [42][1030/1500]	BT 0.025 (0.293)	DT 0.000 (0.255)	loss 7.795 (8.100)	prob 4.109 (2.849)	GS 32.297 (32.545)	mem 73.072
Train: [42][1040/1500]	BT 0.037 (0.294)	DT 0.000 (0.256)	loss 7.360 (8.056)	prob 3.395 (2.899)	GS 34.812 (32.592)	mem 73.072
Train: [42][1050/1500]	BT 0.037 (0.292)	DT 0.001 (0.254)	loss 8.048 (8.074)	prob 3.313 (2.868)	GS 34.016 (32.714)	mem 73.074
Train: [42][1060/1500]	BT 0.039 (0.289)	DT 0.001 (0.251)	loss 9.144 (7.984)	prob 3.447 (3.180)	GS 38.031 (32.378)	mem 73.075
Train: [42][1070/1500]	BT 0.052 (0.294)	DT 0.000 (0.256)	loss 8.586 (8.074)	prob 3.522 (3.372)	GS 32.250 (31.685)	mem 73.073
Train: [42][1080/1500]	BT 0.036 (0.291)	DT 0.000 (0.253)	loss 8.130 (8.095)	prob 3.568 (3.320)	GS 33.578 (31.663)	mem 73.074
Train: [42][1090/1500]	BT 0.037 (0.295)	DT 0.001 (0.256)	loss 8.150 (8.126)	prob 3.242 (3.168)	GS 35.562 (32.480)	mem 73.076
Train: [42][1100/1500]	BT 0.055 (0.296)	DT 0.007 (0.258)	loss 8.379 (8.136)	prob 3.786 (3.237)	GS 33.859 (32.550)	mem 73.074
Train: [42][1110/1500]	BT 0.035 (0.294)	DT 0.001 (0.256)	loss 8.405 (8.154)	prob 3.530 (3.372)	GS 35.047 (32.927)	mem 73.073
Train: [42][1120/1500]	BT 0.061 (0.295)	DT 0.003 (0.256)	loss 7.737 (8.125)	prob 4.309 (3.450)	GS 32.969 (32.798)	mem 73.074
Train: [42][1130/1500]	BT 0.035 (0.297)	DT 0.000 (0.259)	loss 8.128 (8.102)	prob 4.075 (3.440)	GS 33.109 (32.751)	mem 73.076
Train: [42][1140/1500]	BT 0.057 (0.298)	DT 0.003 (0.259)	loss 7.997 (8.115)	prob 4.190 (3.434)	GS 34.484 (32.895)	mem 73.075
Train: [42][1150/1500]	BT 0.077 (0.298)	DT 0.008 (0.260)	loss 8.629 (8.119)	prob 4.286 (3.486)	GS 31.453 (32.762)	mem 73.076
Train: [42][1160/1500]	BT 0.062 (0.304)	DT 0.013 (0.265)	loss 7.632 (7.994)	prob 4.388 (3.703)	GS 31.484 (32.077)	mem 73.077
Train: [42][1170/1500]	BT 0.041 (0.301)	DT 0.005 (0.263)	loss 8.332 (8.010)	prob 4.571 (3.922)	GS 32.484 (31.639)	mem 73.077
Train: [42][1180/1500]	BT 0.074 (0.306)	DT 0.009 (0.267)	loss 8.376 (8.009)	prob 3.407 (3.846)	GS 33.297 (32.103)	mem 73.078
Train: [42][1190/1500]	BT 0.029 (0.306)	DT 0.000 (0.267)	loss 8.085 (8.027)	prob 4.749 (3.838)	GS 33.219 (32.804)	mem 73.079
Train: [42][1200/1500]	BT 0.030 (0.304)	DT 0.000 (0.265)	loss 8.114 (8.032)	prob 4.646 (3.896)	GS 35.516 (32.722)	mem 73.079
Train: [42][1210/1500]	BT 0.037 (0.304)	DT 0.000 (0.265)	loss 8.315 (8.020)	prob 4.037 (3.676)	GS 35.109 (32.030)	mem 73.102
Train: [42][1220/1500]	BT 0.032 (0.302)	DT 0.000 (0.263)	loss 7.827 (8.079)	prob 4.557 (3.558)	GS 35.109 (32.542)	mem 73.112
Train: [42][1230/1500]	BT 0.034 (0.299)	DT 0.000 (0.261)	loss 7.894 (7.988)	prob 4.206 (3.782)	GS 29.625 (31.900)	mem 73.112
Train: [42][1240/1500]	BT 0.039 (0.301)	DT 0.001 (0.263)	loss 8.082 (8.024)	prob 4.543 (3.744)	GS 33.859 (32.236)	mem 73.112
Train: [42][1250/1500]	BT 0.039 (0.299)	DT 0.001 (0.261)	loss 7.849 (8.027)	prob 4.873 (3.765)	GS 33.078 (32.305)	mem 73.112
Train: [42][1260/1500]	BT 0.062 (0.303)	DT 0.014 (0.264)	loss 8.211 (7.983)	prob 5.224 (3.974)	GS 33.266 (32.078)	mem 73.112
Train: [42][1270/1500]	BT 0.060 (0.301)	DT 0.003 (0.262)	loss 7.962 (8.002)	prob 4.182 (4.093)	GS 29.047 (31.709)	mem 73.113
Train: [42][1280/1500]	BT 0.039 (0.303)	DT 0.000 (0.264)	loss 8.541 (7.985)	prob 3.983 (4.058)	GS 34.422 (32.061)	mem 73.112
Train: [42][1290/1500]	BT 0.038 (0.301)	DT 0.001 (0.263)	loss 7.901 (8.002)	prob 4.722 (4.109)	GS 32.922 (32.381)	mem 73.112
Train: [42][1300/1500]	BT 0.041 (0.299)	DT 0.001 (0.261)	loss 8.254 (7.963)	prob 4.543 (4.206)	GS 31.547 (32.083)	mem 73.113
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [42][1310/1500]	BT 0.031 (0.301)	DT 0.000 (0.262)	loss 7.703 (7.914)	prob 4.048 (3.722)	GS 33.875 (33.127)	mem 73.114
Train: [42][1320/1500]	BT 0.039 (0.299)	DT 0.001 (0.260)	loss 7.898 (7.933)	prob 4.909 (3.970)	GS 35.391 (32.869)	mem 73.115
Train: [42][1330/1500]	BT 0.068 (0.299)	DT 0.014 (0.260)	loss 7.751 (7.932)	prob 4.381 (4.060)	GS 25.375 (32.258)	mem 73.115
Train: [42][1340/1500]	BT 0.031 (0.301)	DT 0.000 (0.262)	loss 7.869 (7.942)	prob 4.511 (4.031)	GS 36.625 (32.535)	mem 73.116
Train: [42][1350/1500]	BT 0.037 (0.299)	DT 0.001 (0.260)	loss 8.240 (7.943)	prob 4.833 (4.057)	GS 30.766 (32.427)	mem 73.117
Train: [42][1360/1500]	BT 0.051 (0.300)	DT 0.000 (0.261)	loss 7.802 (7.786)	prob 4.921 (4.402)	GS 31.656 (32.306)	mem 73.117
Train: [42][1370/1500]	BT 0.068 (0.298)	DT 0.011 (0.259)	loss 7.825 (7.734)	prob 4.080 (4.364)	GS 32.109 (32.386)	mem 73.117
Train: [42][1380/1500]	BT 0.048 (0.302)	DT 0.001 (0.263)	loss 7.543 (7.678)	prob 4.348 (4.420)	GS 39.688 (32.310)	mem 73.116
Train: [42][1390/1500]	BT 0.084 (0.300)	DT 0.003 (0.261)	loss 7.723 (7.708)	prob 4.635 (4.318)	GS 35.203 (32.311)	mem 73.116
Train: [42][1400/1500]	BT 0.032 (0.308)	DT 0.001 (0.269)	loss 7.805 (7.746)	prob 4.409 (4.244)	GS 33.344 (32.278)	mem 73.118
Train: [42][1410/1500]	BT 0.026 (0.306)	DT 0.000 (0.267)	loss 7.779 (7.769)	prob 4.448 (4.201)	GS 33.312 (32.909)	mem 73.120
Train: [42][1420/1500]	BT 0.058 (0.308)	DT 0.013 (0.269)	loss 8.422 (7.890)	prob 4.295 (4.031)	GS 38.500 (32.666)	mem 73.122
Train: [42][1430/1500]	BT 0.060 (0.306)	DT 0.016 (0.267)	loss 8.031 (7.816)	prob 4.103 (4.033)	GS 35.531 (32.632)	mem 73.121
Train: [42][1440/1500]	BT 0.067 (0.304)	DT 0.011 (0.265)	loss 7.298 (7.807)	prob 4.186 (4.034)	GS 34.609 (32.633)	mem 73.121
Train: [42][1450/1500]	BT 0.039 (0.307)	DT 0.001 (0.268)	loss 7.455 (7.779)	prob 5.462 (4.078)	GS 31.312 (32.451)	mem 73.120
Train: [42][1460/1500]	BT 0.028 (0.306)	DT 0.001 (0.267)	loss 7.627 (7.634)	prob 4.304 (4.183)	GS 33.125 (34.239)	mem 72.938
Train: [42][1470/1500]	BT 0.027 (0.306)	DT 0.000 (0.267)	loss 7.845 (7.698)	prob 4.676 (4.059)	GS 31.703 (33.184)	mem 72.025
Train: [42][1480/1500]	BT 0.027 (0.304)	DT 0.001 (0.266)	loss 7.348 (7.675)	prob 4.643 (4.068)	GS 34.781 (33.276)	mem 50.336
Train: [42][1490/1500]	BT 0.022 (0.303)	DT 0.000 (0.264)	loss 7.870 (7.643)	prob 4.315 (4.088)	GS 31.969 (33.040)	mem 10.839
Train: [42][1500/1500]	BT 0.018 (0.301)	DT 0.000 (0.262)	loss 7.289 (7.639)	prob 3.771 (4.104)	GS 34.344 (33.019)	mem 10.839
Train: [42][1510/1500]	BT 0.035 (0.300)	DT 0.000 (0.261)	loss 8.191 (7.693)	prob 3.399 (3.285)	GS 36.656 (34.737)	mem 8.036
epoch 42, total time 453.18
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [43][1/1500]	BT 20.450 (20.450)	DT 20.400 (20.400)	loss 7.271 (7.271)	prob 3.833 (3.833)	GS 34.812 (34.812)	mem 71.623
Train: [43][10/1500]	BT 0.039 (2.213)	DT 0.000 (2.176)	loss 7.362 (7.257)	prob 3.975 (3.943)	GS 33.688 (32.781)	mem 71.707
Train: [43][20/1500]	BT 0.032 (1.126)	DT 0.000 (1.089)	loss 7.219 (7.235)	prob 4.767 (4.032)	GS 33.828 (32.961)	mem 71.709
Train: [43][30/1500]	BT 0.064 (0.921)	DT 0.000 (0.884)	loss 7.304 (7.262)	prob 3.768 (3.993)	GS 32.234 (32.804)	mem 71.727
Train: [43][40/1500]	BT 0.037 (0.701)	DT 0.000 (0.663)	loss 6.933 (7.265)	prob 4.413 (4.025)	GS 34.516 (32.783)	mem 71.734
Train: [43][50/1500]	BT 2.108 (0.630)	DT 2.070 (0.593)	loss 7.110 (7.269)	prob 4.074 (4.017)	GS 38.625 (32.604)	mem 71.753
Train: [43][60/1500]	BT 0.038 (0.550)	DT 0.000 (0.512)	loss 7.537 (7.305)	prob 4.071 (4.308)	GS 31.922 (31.238)	mem 71.758
Train: [43][70/1500]	BT 0.039 (0.507)	DT 0.001 (0.470)	loss 6.974 (7.277)	prob 4.482 (4.168)	GS 32.016 (31.812)	mem 71.747
Train: [43][80/1500]	BT 0.039 (0.467)	DT 0.001 (0.429)	loss 7.540 (7.278)	prob 3.715 (4.163)	GS 31.859 (32.001)	mem 71.763
Train: [43][90/1500]	BT 0.029 (0.451)	DT 0.001 (0.413)	loss 7.408 (7.281)	prob 4.521 (4.112)	GS 35.219 (31.769)	mem 71.781
Train: [43][100/1500]	BT 0.039 (0.409)	DT 0.000 (0.372)	loss 7.835 (7.281)	prob 3.890 (4.032)	GS 33.000 (31.896)	mem 71.783
Train: [43][110/1500]	BT 0.039 (0.381)	DT 0.001 (0.344)	loss 7.141 (7.345)	prob 4.304 (4.110)	GS 32.516 (32.419)	mem 71.786
Train: [43][120/1500]	BT 0.072 (0.383)	DT 0.004 (0.344)	loss 7.540 (7.392)	prob 3.898 (4.043)	GS 33.406 (32.619)	mem 71.804
Train: [43][130/1500]	BT 0.108 (0.359)	DT 0.049 (0.318)	loss 7.321 (7.362)	prob 3.914 (4.010)	GS 35.484 (32.628)	mem 71.804
Train: [43][140/1500]	BT 0.028 (0.403)	DT 0.000 (0.361)	loss 7.203 (7.334)	prob 3.988 (3.934)	GS 36.266 (32.810)	mem 71.818
Train: [43][150/1500]	BT 0.038 (0.379)	DT 0.001 (0.337)	loss 7.467 (7.339)	prob 3.703 (3.900)	GS 35.281 (33.027)	mem 71.822
Train: [43][160/1500]	BT 0.067 (0.358)	DT 0.006 (0.317)	loss 7.384 (7.404)	prob 4.121 (3.877)	GS 34.078 (32.886)	mem 71.824
Train: [43][170/1500]	BT 0.035 (0.384)	DT 0.000 (0.343)	loss 7.164 (7.370)	prob 4.344 (3.831)	GS 34.344 (32.670)	mem 71.834
Train: [43][180/1500]	BT 0.034 (0.364)	DT 0.000 (0.324)	loss 7.590 (7.376)	prob 3.449 (3.792)	GS 34.250 (32.361)	mem 71.834
Train: [43][190/1500]	BT 0.036 (0.362)	DT 0.001 (0.322)	loss 7.693 (7.366)	prob 3.372 (3.729)	GS 31.938 (32.321)	mem 71.837
Train: [43][200/1500]	BT 0.060 (0.348)	DT 0.012 (0.307)	loss 7.775 (7.355)	prob 2.926 (3.654)	GS 35.188 (32.393)	mem 71.837
Train: [43][210/1500]	BT 0.065 (0.334)	DT 0.009 (0.293)	loss 7.324 (7.286)	prob 4.423 (3.587)	GS 28.906 (33.055)	mem 71.837
Train: [43][220/1500]	BT 0.037 (0.358)	DT 0.001 (0.316)	loss 7.300 (7.342)	prob 3.428 (3.423)	GS 34.203 (33.968)	mem 71.840
Train: [43][230/1500]	BT 0.037 (0.344)	DT 0.001 (0.303)	loss 7.888 (7.410)	prob 3.030 (3.451)	GS 34.141 (33.146)	mem 71.841
Train: [43][240/1500]	BT 0.052 (0.346)	DT 0.006 (0.305)	loss 7.197 (7.392)	prob 3.072 (3.348)	GS 34.750 (33.422)	mem 71.851
Train: [43][250/1500]	BT 0.044 (0.334)	DT 0.006 (0.293)	loss 7.268 (7.389)	prob 2.783 (3.224)	GS 33.766 (33.346)	mem 71.851
Train: [43][260/1500]	BT 1.333 (0.353)	DT 1.292 (0.312)	loss 7.506 (7.651)	prob 3.500 (2.732)	GS 40.703 (35.166)	mem 71.856
Train: [43][270/1500]	BT 0.063 (0.344)	DT 0.005 (0.303)	loss 7.552 (7.608)	prob 3.666 (2.893)	GS 32.734 (34.112)	mem 71.857
Train: [43][280/1500]	BT 0.033 (0.390)	DT 0.000 (0.349)	loss 7.012 (7.560)	prob 3.826 (2.975)	GS 34.984 (33.662)	mem 71.859
Train: [43][290/1500]	BT 0.029 (0.378)	DT 0.000 (0.337)	loss 8.172 (7.579)	prob 2.486 (2.898)	GS 33.219 (33.579)	mem 71.860
Train: [43][300/1500]	BT 0.036 (0.366)	DT 0.001 (0.326)	loss 8.610 (7.635)	prob 2.199 (2.825)	GS 34.375 (33.553)	mem 71.861
Train: [43][310/1500]	BT 0.030 (0.369)	DT 0.000 (0.328)	loss 7.518 (7.817)	prob 3.651 (2.803)	GS 28.312 (31.336)	mem 71.862
Train: [43][320/1500]	BT 0.029 (0.358)	DT 0.000 (0.318)	loss 8.011 (7.728)	prob 1.731 (2.664)	GS 35.984 (32.731)	mem 71.863
Train: [43][330/1500]	BT 0.064 (0.370)	DT 0.004 (0.329)	loss 7.431 (7.665)	prob 2.445 (2.652)	GS 33.500 (32.635)	mem 72.500
Train: [43][340/1500]	BT 0.058 (0.361)	DT 0.014 (0.320)	loss 7.508 (7.646)	prob 3.319 (2.800)	GS 36.500 (32.259)	mem 72.501
Train: [43][350/1500]	BT 0.072 (0.352)	DT 0.002 (0.311)	loss 7.885 (7.666)	prob 1.488 (2.737)	GS 33.719 (32.232)	mem 72.501
Train: [43][360/1500]	BT 0.032 (0.395)	DT 0.000 (0.354)	loss 7.236 (7.589)	prob 3.100 (2.479)	GS 28.141 (32.078)	mem 72.995
Train: [43][370/1500]	BT 0.031 (0.385)	DT 0.000 (0.345)	loss 7.746 (7.719)	prob 2.381 (2.341)	GS 33.375 (33.073)	mem 72.996
Train: [43][380/1500]	BT 0.058 (0.389)	DT 0.014 (0.349)	loss 8.195 (7.704)	prob 2.380 (2.444)	GS 34.844 (32.719)	mem 73.047
Train: [43][390/1500]	BT 0.058 (0.381)	DT 0.011 (0.340)	loss 7.844 (7.780)	prob 2.622 (2.349)	GS 35.594 (33.095)	mem 73.047
Train: [43][400/1500]	BT 0.060 (0.373)	DT 0.016 (0.332)	loss 7.996 (7.764)	prob 3.368 (2.422)	GS 32.594 (33.041)	mem 73.047
Train: [43][410/1500]	BT 0.030 (0.383)	DT 0.000 (0.342)	loss 7.836 (7.705)	prob 3.197 (2.613)	GS 35.188 (35.114)	mem 73.048
Train: [43][420/1500]	BT 0.037 (0.374)	DT 0.001 (0.334)	loss 8.198 (7.788)	prob 2.925 (2.628)	GS 30.078 (33.397)	mem 73.049
Train: [43][430/1500]	BT 0.035 (0.376)	DT 0.000 (0.336)	loss 7.901 (7.785)	prob 2.170 (2.649)	GS 36.453 (33.216)	mem 73.051
Train: [43][440/1500]	BT 0.027 (0.378)	DT 0.000 (0.338)	loss 7.753 (7.761)	prob 2.651 (2.656)	GS 31.156 (33.330)	mem 73.052
Train: [43][450/1500]	BT 0.093 (0.371)	DT 0.056 (0.331)	loss 8.045 (7.755)	prob 2.642 (2.633)	GS 33.562 (33.481)	mem 73.053
Train: [43][460/1500]	BT 0.100 (0.374)	DT 0.031 (0.334)	loss 7.817 (7.841)	prob 2.636 (2.408)	GS 34.812 (32.195)	mem 73.053
Train: [43][470/1500]	BT 0.055 (0.367)	DT 0.001 (0.327)	loss 8.010 (7.846)	prob 3.041 (2.672)	GS 33.125 (32.671)	mem 73.054
Train: [43][480/1500]	BT 0.101 (0.378)	DT 0.008 (0.337)	loss 7.877 (7.866)	prob 2.666 (2.697)	GS 30.891 (31.937)	mem 73.056
Train: [43][490/1500]	BT 0.024 (0.388)	DT 0.000 (0.348)	loss 7.745 (7.883)	prob 2.201 (2.650)	GS 31.141 (31.902)	mem 73.053
Train: [43][500/1500]	BT 0.024 (0.381)	DT 0.000 (0.341)	loss 7.788 (7.886)	prob 2.517 (2.694)	GS 36.000 (32.094)	mem 73.054
Train: [43][510/1500]	BT 0.038 (0.379)	DT 0.001 (0.339)	loss 7.679 (7.923)	prob 2.787 (2.515)	GS 33.156 (32.450)	mem 73.056
Train: [43][520/1500]	BT 0.037 (0.373)	DT 0.001 (0.333)	loss 8.190 (7.937)	prob 2.360 (2.561)	GS 34.906 (33.118)	mem 73.056
Train: [43][530/1500]	BT 0.034 (0.372)	DT 0.000 (0.332)	loss 7.646 (7.936)	prob 3.766 (2.707)	GS 31.109 (32.860)	mem 73.056
Train: [43][540/1500]	BT 0.028 (0.365)	DT 0.000 (0.326)	loss 7.991 (7.934)	prob 4.085 (2.772)	GS 33.734 (32.698)	mem 73.057
Train: [43][550/1500]	BT 0.037 (0.359)	DT 0.000 (0.320)	loss 8.899 (7.937)	prob 3.821 (2.830)	GS 29.578 (32.453)	mem 73.058
Train: [43][560/1500]	BT 0.038 (0.362)	DT 0.001 (0.323)	loss 7.855 (7.861)	prob 2.766 (3.364)	GS 37.422 (33.233)	mem 73.061
Train: [43][570/1500]	BT 0.036 (0.357)	DT 0.000 (0.317)	loss 8.720 (7.916)	prob 2.326 (3.069)	GS 34.516 (33.611)	mem 73.061
Train: [43][580/1500]	BT 0.052 (0.362)	DT 0.001 (0.322)	loss 8.587 (7.895)	prob 3.082 (3.092)	GS 35.719 (33.561)	mem 73.063
Train: [43][590/1500]	BT 0.051 (0.357)	DT 0.005 (0.317)	loss 7.302 (7.831)	prob 3.795 (3.192)	GS 30.578 (33.449)	mem 73.066
Train: [43][600/1500]	BT 0.036 (0.363)	DT 0.001 (0.323)	loss 7.634 (7.775)	prob 3.985 (3.259)	GS 35.625 (33.456)	mem 73.063
Train: [43][610/1500]	BT 0.060 (0.360)	DT 0.016 (0.320)	loss 7.853 (7.642)	prob 3.365 (3.155)	GS 36.391 (34.264)	mem 73.064
Train: [43][620/1500]	BT 0.031 (0.355)	DT 0.000 (0.315)	loss 8.404 (7.710)	prob 3.164 (3.090)	GS 35.312 (33.648)	mem 73.064
Train: [43][630/1500]	BT 0.061 (0.363)	DT 0.006 (0.322)	loss 8.209 (7.754)	prob 3.023 (3.029)	GS 33.203 (33.501)	mem 73.064
Train: [43][640/1500]	BT 0.080 (0.367)	DT 0.001 (0.326)	loss 8.001 (7.778)	prob 3.183 (3.061)	GS 34.375 (33.479)	mem 73.066
Train: [43][650/1500]	BT 0.070 (0.366)	DT 0.010 (0.325)	loss 8.101 (7.758)	prob 3.809 (3.135)	GS 33.703 (32.943)	mem 73.067
Train: [43][660/1500]	BT 0.029 (0.374)	DT 0.000 (0.332)	loss 8.060 (7.759)	prob 4.185 (3.451)	GS 31.859 (33.877)	mem 73.066
Train: [43][670/1500]	BT 0.037 (0.369)	DT 0.000 (0.327)	loss 8.087 (7.808)	prob 3.968 (3.484)	GS 35.641 (33.736)	mem 73.067
Train: [43][680/1500]	BT 0.038 (0.364)	DT 0.001 (0.323)	loss 8.743 (7.787)	prob 4.261 (3.529)	GS 30.953 (32.786)	mem 73.067
Train: [43][690/1500]	BT 0.035 (0.363)	DT 0.001 (0.322)	loss 7.791 (7.761)	prob 3.743 (3.568)	GS 28.812 (32.690)	mem 73.100
Train: [43][700/1500]	BT 0.030 (0.359)	DT 0.000 (0.319)	loss 7.531 (7.745)	prob 4.660 (3.624)	GS 28.703 (32.145)	mem 73.102
Train: [43][710/1500]	BT 0.039 (0.358)	DT 0.001 (0.317)	loss 7.573 (7.821)	prob 4.129 (3.432)	GS 36.000 (32.811)	mem 73.101
Train: [43][720/1500]	BT 0.039 (0.354)	DT 0.001 (0.313)	loss 7.808 (7.703)	prob 3.351 (3.535)	GS 33.797 (31.563)	mem 73.101
Train: [43][730/1500]	BT 0.056 (0.350)	DT 0.004 (0.309)	loss 8.386 (7.735)	prob 2.944 (3.569)	GS 33.109 (31.597)	mem 73.101
Train: [43][740/1500]	BT 0.039 (0.354)	DT 0.001 (0.313)	loss 7.512 (7.737)	prob 4.405 (3.500)	GS 32.578 (31.696)	mem 73.101
Train: [43][750/1500]	BT 0.039 (0.350)	DT 0.001 (0.309)	loss 7.814 (7.748)	prob 3.596 (3.464)	GS 33.656 (31.978)	mem 73.101
Train: [43][760/1500]	BT 0.039 (0.349)	DT 0.001 (0.308)	loss 7.505 (7.684)	prob 3.557 (3.531)	GS 37.453 (34.373)	mem 73.104
Train: [43][770/1500]	BT 0.039 (0.347)	DT 0.001 (0.306)	loss 7.394 (7.590)	prob 3.338 (3.450)	GS 35.516 (32.977)	mem 73.106
Train: [43][780/1500]	BT 0.040 (0.345)	DT 0.001 (0.304)	loss 7.926 (7.597)	prob 3.564 (3.568)	GS 34.000 (32.978)	mem 73.106
Train: [43][790/1500]	BT 0.029 (0.346)	DT 0.000 (0.306)	loss 8.031 (7.591)	prob 3.792 (3.569)	GS 34.875 (32.634)	mem 73.107
Train: [43][800/1500]	BT 0.039 (0.342)	DT 0.001 (0.302)	loss 7.290 (7.587)	prob 4.333 (3.681)	GS 35.281 (32.499)	mem 73.107
Train: [43][810/1500]	BT 0.039 (0.341)	DT 0.001 (0.301)	loss 7.234 (7.647)	prob 3.822 (3.956)	GS 26.766 (31.295)	mem 73.106
Train: [43][820/1500]	BT 0.038 (0.339)	DT 0.000 (0.299)	loss 8.078 (7.703)	prob 3.766 (3.697)	GS 32.328 (31.566)	mem 73.106
Train: [43][830/1500]	BT 0.030 (0.336)	DT 0.000 (0.295)	loss 8.423 (7.709)	prob 3.519 (3.668)	GS 30.547 (31.832)	mem 73.107
Train: [43][840/1500]	BT 0.051 (0.337)	DT 0.001 (0.296)	loss 8.514 (7.688)	prob 2.911 (3.694)	GS 39.594 (32.034)	mem 73.108
Train: [43][850/1500]	BT 0.045 (0.334)	DT 0.016 (0.293)	loss 7.546 (7.680)	prob 4.208 (3.610)	GS 32.156 (32.013)	mem 73.109
Train: [43][860/1500]	BT 0.039 (0.332)	DT 0.001 (0.291)	loss 7.682 (7.697)	prob 4.326 (3.709)	GS 30.969 (32.347)	mem 73.110
Train: [43][870/1500]	BT 0.026 (0.338)	DT 0.000 (0.297)	loss 7.695 (7.718)	prob 3.542 (3.489)	GS 37.438 (33.545)	mem 73.106
Train: [43][880/1500]	BT 0.039 (0.334)	DT 0.001 (0.294)	loss 7.980 (7.695)	prob 3.539 (3.521)	GS 36.531 (33.192)	mem 73.107
Train: [43][890/1500]	BT 0.039 (0.334)	DT 0.001 (0.294)	loss 7.623 (7.659)	prob 3.249 (3.547)	GS 30.984 (33.520)	mem 73.106
Train: [43][900/1500]	BT 0.039 (0.331)	DT 0.001 (0.290)	loss 7.902 (7.620)	prob 3.613 (3.600)	GS 36.734 (33.323)	mem 73.104
Train: [43][910/1500]	BT 0.039 (0.330)	DT 0.001 (0.290)	loss 7.654 (7.543)	prob 4.065 (3.555)	GS 33.484 (32.050)	mem 73.105
Train: [43][920/1500]	BT 0.039 (0.327)	DT 0.001 (0.287)	loss 7.698 (7.507)	prob 3.803 (3.727)	GS 35.531 (32.532)	mem 73.105
Train: [43][930/1500]	BT 0.039 (0.327)	DT 0.001 (0.287)	loss 7.453 (7.517)	prob 4.006 (3.669)	GS 29.859 (32.751)	mem 73.105
Train: [43][940/1500]	BT 0.038 (0.326)	DT 0.001 (0.286)	loss 7.966 (7.520)	prob 3.889 (3.671)	GS 37.672 (32.623)	mem 73.103
Train: [43][950/1500]	BT 0.038 (0.323)	DT 0.001 (0.283)	loss 7.270 (7.505)	prob 3.755 (3.708)	GS 33.812 (32.293)	mem 73.103
Train: [43][960/1500]	BT 0.028 (0.328)	DT 0.000 (0.288)	loss 7.437 (7.405)	prob 3.304 (3.545)	GS 35.188 (33.169)	mem 73.122
Train: [43][970/1500]	BT 0.031 (0.325)	DT 0.001 (0.285)	loss 7.406 (7.440)	prob 4.035 (3.438)	GS 38.812 (33.339)	mem 73.121
Train: [43][980/1500]	BT 0.039 (0.322)	DT 0.001 (0.282)	loss 7.212 (7.476)	prob 3.867 (3.430)	GS 33.734 (33.280)	mem 73.098
Train: [43][990/1500]	BT 0.036 (0.322)	DT 0.001 (0.282)	loss 7.694 (7.520)	prob 2.969 (3.364)	GS 33.188 (33.289)	mem 73.023
Train: [43][1000/1500]	BT 0.058 (0.319)	DT 0.003 (0.279)	loss 7.523 (7.521)	prob 3.491 (3.374)	GS 38.531 (33.306)	mem 73.022
Train: [43][1010/1500]	BT 0.275 (0.320)	DT 0.238 (0.280)	loss 7.887 (7.435)	prob 2.920 (3.425)	GS 31.969 (32.678)	mem 73.022
Train: [43][1020/1500]	BT 0.037 (0.317)	DT 0.001 (0.277)	loss 7.575 (7.437)	prob 3.306 (3.456)	GS 28.672 (32.117)	mem 73.022
Train: [43][1030/1500]	BT 0.085 (0.315)	DT 0.002 (0.275)	loss 7.493 (7.483)	prob 3.009 (3.379)	GS 30.406 (31.869)	mem 73.022
Train: [43][1040/1500]	BT 0.033 (0.322)	DT 0.000 (0.282)	loss 7.482 (7.468)	prob 3.188 (3.334)	GS 34.578 (32.301)	mem 73.042
Train: [43][1050/1500]	BT 0.037 (0.320)	DT 0.000 (0.280)	loss 7.481 (7.476)	prob 3.447 (3.322)	GS 33.578 (32.346)	mem 73.044
Train: [43][1060/1500]	BT 0.038 (0.317)	DT 0.001 (0.277)	loss 7.437 (7.579)	prob 3.404 (2.921)	GS 33.078 (33.467)	mem 73.045
Train: [43][1070/1500]	BT 0.038 (0.317)	DT 0.001 (0.277)	loss 7.607 (7.529)	prob 2.987 (3.098)	GS 34.422 (32.559)	mem 73.047
Train: [43][1080/1500]	BT 0.039 (0.314)	DT 0.001 (0.274)	loss 7.947 (7.545)	prob 3.684 (3.087)	GS 33.234 (32.241)	mem 73.046
Train: [43][1090/1500]	BT 0.039 (0.317)	DT 0.001 (0.277)	loss 7.464 (7.493)	prob 3.694 (3.130)	GS 36.938 (32.277)	mem 73.047
Train: [43][1100/1500]	BT 0.039 (0.314)	DT 0.001 (0.274)	loss 7.753 (7.476)	prob 2.537 (3.065)	GS 32.984 (32.105)	mem 73.047
Train: [43][1110/1500]	BT 0.064 (0.314)	DT 0.016 (0.274)	loss 7.821 (7.550)	prob 2.571 (2.605)	GS 35.047 (32.786)	mem 73.046
Train: [43][1120/1500]	BT 0.029 (0.317)	DT 0.000 (0.277)	loss 7.815 (7.547)	prob 2.548 (2.646)	GS 38.828 (32.881)	mem 73.033
Train: [43][1130/1500]	BT 0.038 (0.317)	DT 0.001 (0.277)	loss 7.767 (7.516)	prob 2.878 (2.581)	GS 34.703 (32.901)	mem 73.034
Train: [43][1140/1500]	BT 0.039 (0.316)	DT 0.001 (0.276)	loss 7.796 (7.476)	prob 2.747 (2.641)	GS 36.281 (32.961)	mem 73.033
Train: [43][1150/1500]	BT 0.072 (0.314)	DT 0.003 (0.274)	loss 7.314 (7.474)	prob 3.310 (2.665)	GS 36.828 (32.843)	mem 73.033
Train: [43][1160/1500]	BT 0.037 (0.318)	DT 0.000 (0.278)	loss 8.296 (7.829)	prob 2.442 (2.521)	GS 32.516 (31.894)	mem 73.035
Train: [43][1170/1500]	BT 0.038 (0.316)	DT 0.000 (0.276)	loss 7.461 (7.721)	prob 2.974 (2.406)	GS 29.094 (32.130)	mem 73.037
Train: [43][1180/1500]	BT 0.048 (0.313)	DT 0.010 (0.273)	loss 8.220 (7.768)	prob 2.338 (2.419)	GS 35.203 (32.624)	mem 73.037
Train: [43][1190/1500]	BT 0.039 (0.314)	DT 0.001 (0.274)	loss 8.226 (7.778)	prob 3.132 (2.455)	GS 31.562 (32.621)	mem 73.036
Train: [43][1200/1500]	BT 0.040 (0.312)	DT 0.001 (0.272)	loss 8.065 (7.775)	prob 2.736 (2.475)	GS 33.891 (32.518)	mem 73.036
Train: [43][1210/1500]	BT 0.030 (0.320)	DT 0.000 (0.280)	loss 7.788 (7.666)	prob 3.360 (2.549)	GS 35.656 (32.884)	mem 73.037
Train: [43][1220/1500]	BT 0.031 (0.317)	DT 0.000 (0.277)	loss 8.089 (7.789)	prob 3.341 (2.631)	GS 35.078 (32.371)	mem 73.037
Train: [43][1230/1500]	BT 0.030 (0.323)	DT 0.000 (0.283)	loss 8.238 (7.778)	prob 3.057 (2.739)	GS 36.672 (32.571)	mem 73.038
Train: [43][1240/1500]	BT 0.037 (0.320)	DT 0.001 (0.281)	loss 7.647 (7.801)	prob 4.071 (2.692)	GS 32.375 (32.647)	mem 73.052
Train: [43][1250/1500]	BT 0.025 (0.321)	DT 0.000 (0.281)	loss 8.216 (7.790)	prob 3.335 (2.693)	GS 36.609 (32.992)	mem 73.057
Train: [43][1260/1500]	BT 0.024 (0.319)	DT 0.000 (0.279)	loss 7.692 (7.910)	prob 3.167 (2.691)	GS 31.438 (32.958)	mem 73.057
Train: [43][1270/1500]	BT 0.058 (0.320)	DT 0.011 (0.281)	loss 8.031 (7.870)	prob 3.164 (2.850)	GS 33.469 (33.167)	mem 73.060
Train: [43][1280/1500]	BT 0.066 (0.318)	DT 0.005 (0.279)	loss 8.013 (7.910)	prob 2.861 (2.854)	GS 38.203 (33.341)	mem 73.060
Train: [43][1290/1500]	BT 0.046 (0.316)	DT 0.000 (0.276)	loss 8.224 (7.939)	prob 3.778 (2.907)	GS 36.438 (32.991)	mem 73.061
Train: [43][1300/1500]	BT 0.021 (0.321)	DT 0.000 (0.281)	loss 8.406 (7.934)	prob 3.594 (2.930)	GS 37.500 (33.448)	mem 73.065
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [43][1310/1500]	BT 0.036 (0.319)	DT 0.000 (0.279)	loss 7.897 (7.793)	prob 4.026 (3.425)	GS 36.500 (34.494)	mem 73.065
Train: [43][1320/1500]	BT 0.024 (0.317)	DT 0.000 (0.278)	loss 8.464 (7.845)	prob 4.581 (3.695)	GS 29.562 (33.109)	mem 73.068
Train: [43][1330/1500]	BT 0.037 (0.318)	DT 0.001 (0.279)	loss 7.629 (7.833)	prob 3.954 (3.747)	GS 34.750 (32.810)	mem 73.068
Train: [43][1340/1500]	BT 0.038 (0.316)	DT 0.000 (0.277)	loss 8.196 (7.822)	prob 4.503 (3.695)	GS 35.922 (32.902)	mem 73.069
Train: [43][1350/1500]	BT 0.036 (0.318)	DT 0.001 (0.279)	loss 8.521 (7.845)	prob 3.510 (3.667)	GS 36.781 (33.039)	mem 73.071
Train: [43][1360/1500]	BT 0.037 (0.316)	DT 0.001 (0.277)	loss 7.954 (7.928)	prob 4.579 (3.696)	GS 30.953 (31.905)	mem 73.071
Train: [43][1370/1500]	BT 0.037 (0.316)	DT 0.000 (0.277)	loss 7.954 (7.958)	prob 4.460 (3.836)	GS 30.812 (32.136)	mem 73.074
Train: [43][1380/1500]	BT 0.035 (0.314)	DT 0.001 (0.275)	loss 7.608 (7.898)	prob 4.061 (3.916)	GS 34.359 (32.194)	mem 73.074
Train: [43][1390/1500]	BT 0.037 (0.312)	DT 0.001 (0.273)	loss 8.229 (7.931)	prob 4.184 (3.863)	GS 37.344 (32.310)	mem 73.075
Train: [43][1400/1500]	BT 0.040 (0.313)	DT 0.000 (0.273)	loss 8.639 (7.899)	prob 3.350 (3.815)	GS 34.328 (32.342)	mem 73.075
Train: [43][1410/1500]	BT 0.037 (0.311)	DT 0.000 (0.271)	loss 8.106 (7.778)	prob 4.821 (4.154)	GS 32.047 (32.788)	mem 73.075
Train: [43][1420/1500]	BT 0.028 (0.312)	DT 0.000 (0.273)	loss 8.830 (7.730)	prob 3.728 (4.453)	GS 32.828 (32.259)	mem 73.075
Train: [43][1430/1500]	BT 0.038 (0.310)	DT 0.001 (0.271)	loss 8.112 (7.789)	prob 4.222 (4.271)	GS 31.516 (32.555)	mem 73.077
Train: [43][1440/1500]	BT 0.037 (0.308)	DT 0.001 (0.269)	loss 7.676 (7.752)	prob 4.381 (4.331)	GS 34.547 (32.669)	mem 73.077
Train: [43][1450/1500]	BT 0.028 (0.313)	DT 0.000 (0.274)	loss 7.612 (7.755)	prob 4.067 (4.170)	GS 36.000 (32.837)	mem 73.006
Train: [43][1460/1500]	BT 0.030 (0.311)	DT 0.000 (0.272)	loss 7.890 (7.819)	prob 4.552 (4.199)	GS 36.406 (32.036)	mem 73.005
Train: [43][1470/1500]	BT 0.037 (0.310)	DT 0.000 (0.271)	loss 7.860 (7.792)	prob 4.744 (4.075)	GS 30.953 (32.248)	mem 61.747
Train: [43][1480/1500]	BT 0.029 (0.309)	DT 0.000 (0.270)	loss 7.592 (7.740)	prob 4.826 (4.115)	GS 33.766 (31.939)	mem 10.791
Train: [43][1490/1500]	BT 0.026 (0.307)	DT 0.000 (0.268)	loss 7.631 (7.727)	prob 4.299 (4.165)	GS 32.062 (31.737)	mem 10.790
Train: [43][1500/1500]	BT 0.033 (0.306)	DT 0.000 (0.267)	loss 7.567 (7.756)	prob 3.679 (4.111)	GS 33.031 (31.906)	mem 7.979
Train: [43][1510/1500]	BT 0.038 (0.304)	DT 0.001 (0.265)	loss 7.002 (7.408)	prob 4.371 (4.336)	GS 36.469 (33.719)	mem 7.979
epoch 43, total time 459.61
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [44][1/1500]	BT 22.177 (22.177)	DT 22.095 (22.095)	loss 7.188 (7.188)	prob 3.735 (3.735)	GS 29.938 (29.938)	mem 71.524
Train: [44][10/1500]	BT 0.026 (4.233)	DT 0.000 (4.193)	loss 7.367 (7.667)	prob 4.401 (3.662)	GS 32.953 (35.554)	mem 71.785
Train: [44][20/1500]	BT 0.030 (2.132)	DT 0.000 (2.097)	loss 7.653 (7.642)	prob 4.537 (3.784)	GS 33.766 (34.350)	mem 71.787
Train: [44][30/1500]	BT 4.908 (1.595)	DT 4.870 (1.560)	loss 7.646 (7.635)	prob 4.576 (3.845)	GS 39.047 (34.202)	mem 71.816
Train: [44][40/1500]	BT 0.037 (1.203)	DT 0.000 (1.170)	loss 7.864 (7.642)	prob 4.271 (3.988)	GS 37.281 (33.414)	mem 71.822
Train: [44][50/1500]	BT 0.037 (0.970)	DT 0.000 (0.936)	loss 8.165 (7.674)	prob 4.131 (3.968)	GS 35.172 (33.121)	mem 71.827
Train: [44][60/1500]	BT 0.038 (0.861)	DT 0.001 (0.827)	loss 7.809 (7.561)	prob 4.826 (4.236)	GS 32.234 (31.197)	mem 71.853
Train: [44][70/1500]	BT 0.039 (0.744)	DT 0.001 (0.709)	loss 7.705 (7.548)	prob 4.143 (4.250)	GS 33.641 (31.635)	mem 71.853
Train: [44][80/1500]	BT 0.039 (0.689)	DT 0.000 (0.654)	loss 7.420 (7.505)	prob 3.962 (4.170)	GS 36.297 (32.314)	mem 71.863
Train: [44][90/1500]	BT 0.039 (0.617)	DT 0.001 (0.581)	loss 8.075 (7.527)	prob 3.645 (4.143)	GS 35.969 (32.332)	mem 71.862
Train: [44][100/1500]	BT 0.039 (0.563)	DT 0.001 (0.527)	loss 7.529 (7.557)	prob 4.809 (4.164)	GS 34.062 (32.224)	mem 71.869
Train: [44][110/1500]	BT 0.038 (0.545)	DT 0.001 (0.509)	loss 7.535 (7.540)	prob 4.912 (4.275)	GS 33.562 (32.219)	mem 71.874
Train: [44][120/1500]	BT 0.049 (0.503)	DT 0.011 (0.466)	loss 7.188 (7.557)	prob 4.637 (4.209)	GS 34.141 (32.223)	mem 71.874
Train: [44][130/1500]	BT 0.038 (0.492)	DT 0.001 (0.456)	loss 7.467 (7.532)	prob 4.492 (4.134)	GS 33.500 (32.252)	mem 71.876
Train: [44][140/1500]	BT 0.040 (0.472)	DT 0.000 (0.436)	loss 7.422 (7.523)	prob 4.078 (4.063)	GS 33.266 (32.114)	mem 71.879
Train: [44][150/1500]	BT 0.040 (0.445)	DT 0.001 (0.409)	loss 7.707 (7.541)	prob 4.086 (4.046)	GS 31.516 (32.236)	mem 71.879
Train: [44][160/1500]	BT 0.039 (0.446)	DT 0.001 (0.409)	loss 7.366 (7.380)	prob 3.735 (3.879)	GS 34.578 (32.386)	mem 71.882
Train: [44][170/1500]	BT 0.040 (0.422)	DT 0.001 (0.385)	loss 7.103 (7.336)	prob 4.470 (4.052)	GS 30.078 (32.598)	mem 71.882
Train: [44][180/1500]	BT 2.640 (0.416)	DT 2.601 (0.379)	loss 7.332 (7.362)	prob 3.907 (4.027)	GS 33.203 (32.579)	mem 71.883
Train: [44][190/1500]	BT 0.040 (0.396)	DT 0.001 (0.359)	loss 7.400 (7.361)	prob 3.530 (3.913)	GS 34.156 (32.609)	mem 71.883
Train: [44][200/1500]	BT 0.039 (0.387)	DT 0.001 (0.350)	loss 7.549 (7.382)	prob 3.412 (3.805)	GS 37.344 (33.074)	mem 71.886
Train: [44][210/1500]	BT 0.063 (0.384)	DT 0.009 (0.347)	loss 7.090 (7.397)	prob 4.314 (3.766)	GS 36.031 (33.323)	mem 71.890
Train: [44][220/1500]	BT 0.073 (0.382)	DT 0.010 (0.344)	loss 7.581 (7.392)	prob 3.145 (3.826)	GS 34.125 (33.370)	mem 71.894
Train: [44][230/1500]	BT 0.037 (0.449)	DT 0.000 (0.410)	loss 8.055 (7.414)	prob 3.048 (3.694)	GS 34.250 (33.860)	mem 71.897
Train: [44][240/1500]	BT 0.031 (0.431)	DT 0.000 (0.393)	loss 7.173 (7.374)	prob 4.004 (3.725)	GS 30.406 (34.020)	mem 71.899
Train: [44][250/1500]	BT 2.835 (0.427)	DT 2.798 (0.389)	loss 7.159 (7.359)	prob 3.463 (3.704)	GS 31.000 (33.555)	mem 71.900
Train: [44][260/1500]	BT 0.038 (0.412)	DT 0.001 (0.374)	loss 7.321 (7.342)	prob 3.575 (3.733)	GS 36.469 (31.844)	mem 71.901
Train: [44][270/1500]	BT 0.038 (0.398)	DT 0.000 (0.360)	loss 7.297 (7.299)	prob 3.746 (3.754)	GS 35.234 (32.844)	mem 71.901
Train: [44][280/1500]	BT 0.037 (0.398)	DT 0.000 (0.360)	loss 7.512 (7.276)	prob 3.310 (3.761)	GS 28.328 (32.306)	mem 71.911
Train: [44][290/1500]	BT 0.037 (0.385)	DT 0.000 (0.347)	loss 7.727 (7.288)	prob 3.775 (3.742)	GS 30.953 (32.102)	mem 71.911
Train: [44][300/1500]	BT 0.038 (0.390)	DT 0.001 (0.352)	loss 7.104 (7.272)	prob 3.963 (3.780)	GS 35.562 (31.939)	mem 71.924
Train: [44][310/1500]	BT 0.038 (0.378)	DT 0.001 (0.341)	loss 7.195 (7.233)	prob 3.617 (3.561)	GS 32.344 (32.581)	mem 71.924
Train: [44][320/1500]	BT 0.037 (0.368)	DT 0.000 (0.330)	loss 7.068 (7.267)	prob 3.914 (3.483)	GS 33.344 (32.161)	mem 71.925
Train: [44][330/1500]	BT 0.036 (0.373)	DT 0.000 (0.335)	loss 7.359 (7.266)	prob 3.443 (3.571)	GS 33.078 (31.801)	mem 71.837
Train: [44][340/1500]	BT 0.037 (0.363)	DT 0.001 (0.325)	loss 7.439 (7.258)	prob 2.432 (3.548)	GS 34.672 (32.388)	mem 71.838
Train: [44][350/1500]	BT 0.037 (0.364)	DT 0.000 (0.327)	loss 7.055 (7.257)	prob 3.736 (3.499)	GS 37.797 (32.611)	mem 71.985
Train: [44][360/1500]	BT 0.034 (0.355)	DT 0.001 (0.318)	loss 7.151 (7.166)	prob 3.700 (3.363)	GS 35.797 (32.591)	mem 72.083
Train: [44][370/1500]	BT 3.838 (0.357)	DT 3.802 (0.320)	loss 7.380 (7.196)	prob 3.609 (3.546)	GS 32.969 (32.160)	mem 72.667
Train: [44][380/1500]	BT 0.036 (0.350)	DT 0.000 (0.313)	loss 7.110 (7.219)	prob 3.139 (3.509)	GS 35.422 (32.634)	mem 72.815
Train: [44][390/1500]	BT 0.037 (0.342)	DT 0.001 (0.305)	loss 7.182 (7.232)	prob 3.570 (3.476)	GS 38.562 (32.739)	mem 72.862
Train: [44][400/1500]	BT 0.037 (0.340)	DT 0.000 (0.303)	loss 8.299 (7.248)	prob 3.124 (3.423)	GS 35.594 (33.016)	mem 73.006
Train: [44][410/1500]	BT 0.038 (0.334)	DT 0.001 (0.297)	loss 7.182 (7.151)	prob 2.742 (3.581)	GS 31.750 (33.016)	mem 73.006
Train: [44][420/1500]	BT 0.038 (0.333)	DT 0.001 (0.296)	loss 7.238 (7.208)	prob 3.678 (3.387)	GS 33.828 (32.263)	mem 73.011
Train: [44][430/1500]	BT 0.037 (0.331)	DT 0.001 (0.294)	loss 7.275 (7.211)	prob 3.079 (3.328)	GS 33.391 (32.342)	mem 73.032
Train: [44][440/1500]	BT 0.038 (0.324)	DT 0.001 (0.287)	loss 7.158 (7.210)	prob 3.078 (3.293)	GS 37.078 (32.183)	mem 73.032
Train: [44][450/1500]	BT 0.376 (0.326)	DT 0.338 (0.288)	loss 7.289 (7.207)	prob 2.960 (3.261)	GS 32.703 (32.377)	mem 73.036
Train: [44][460/1500]	BT 0.038 (0.319)	DT 0.001 (0.282)	loss 7.393 (7.258)	prob 3.267 (2.776)	GS 32.219 (33.030)	mem 73.036
Train: [44][470/1500]	BT 0.038 (0.321)	DT 0.000 (0.284)	loss 7.628 (7.270)	prob 2.950 (2.912)	GS 35.562 (32.339)	mem 73.028
Train: [44][480/1500]	BT 0.039 (0.315)	DT 0.001 (0.278)	loss 7.283 (7.256)	prob 3.039 (2.928)	GS 26.969 (32.582)	mem 73.029
Train: [44][490/1500]	BT 1.371 (0.313)	DT 1.332 (0.275)	loss 7.443 (7.244)	prob 2.665 (2.885)	GS 32.844 (32.454)	mem 73.014
Train: [44][500/1500]	BT 0.039 (0.313)	DT 0.001 (0.275)	loss 7.441 (7.253)	prob 3.153 (2.814)	GS 33.609 (32.390)	mem 73.016
Train: [44][510/1500]	BT 0.039 (0.308)	DT 0.001 (0.271)	loss 7.385 (7.331)	prob 2.768 (2.402)	GS 33.938 (32.509)	mem 73.016
Train: [44][520/1500]	BT 0.040 (0.307)	DT 0.001 (0.269)	loss 7.345 (7.323)	prob 2.505 (2.580)	GS 33.609 (32.137)	mem 73.016
Train: [44][530/1500]	BT 0.384 (0.307)	DT 0.345 (0.270)	loss 7.408 (7.325)	prob 2.038 (2.401)	GS 35.078 (32.841)	mem 73.020
Train: [44][540/1500]	BT 0.040 (0.302)	DT 0.001 (0.265)	loss 7.426 (7.338)	prob 2.862 (2.414)	GS 30.828 (32.777)	mem 73.019
Train: [44][550/1500]	BT 0.048 (0.310)	DT 0.000 (0.273)	loss 7.500 (7.367)	prob 2.817 (2.406)	GS 33.391 (32.570)	mem 73.023
Train: [44][560/1500]	BT 0.035 (0.307)	DT 0.001 (0.269)	loss 7.362 (7.433)	prob 2.109 (2.268)	GS 33.938 (33.080)	mem 73.024
Train: [44][570/1500]	BT 2.559 (0.306)	DT 2.512 (0.269)	loss 7.420 (7.373)	prob 2.661 (2.316)	GS 33.391 (33.318)	mem 73.039
Train: [44][580/1500]	BT 0.039 (0.310)	DT 0.002 (0.272)	loss 7.911 (7.405)	prob 1.195 (2.165)	GS 35.500 (33.660)	mem 73.044
Train: [44][590/1500]	BT 0.027 (0.309)	DT 0.000 (0.271)	loss 7.637 (7.409)	prob 1.590 (2.094)	GS 33.000 (33.751)	mem 73.045
Train: [44][600/1500]	BT 0.037 (0.304)	DT 0.000 (0.267)	loss 7.472 (7.444)	prob 2.566 (2.060)	GS 36.422 (33.705)	mem 73.046
Train: [44][610/1500]	BT 0.029 (0.307)	DT 0.000 (0.270)	loss 7.555 (7.315)	prob 1.712 (1.992)	GS 30.281 (31.881)	mem 73.047
Train: [44][620/1500]	BT 0.027 (0.303)	DT 0.000 (0.265)	loss 7.447 (7.467)	prob 1.970 (1.933)	GS 31.906 (32.619)	mem 73.047
Train: [44][630/1500]	BT 0.038 (0.299)	DT 0.000 (0.261)	loss 8.360 (7.540)	prob 2.456 (1.858)	GS 31.250 (32.433)	mem 73.048
Train: [44][640/1500]	BT 0.029 (0.307)	DT 0.000 (0.270)	loss 8.103 (7.582)	prob 1.783 (1.877)	GS 29.797 (32.448)	mem 73.050
Train: [44][650/1500]	BT 0.033 (0.302)	DT 0.001 (0.265)	loss 7.656 (7.574)	prob 2.412 (1.920)	GS 34.594 (32.247)	mem 73.049
Train: [44][660/1500]	BT 0.031 (0.305)	DT 0.000 (0.268)	loss 7.307 (7.420)	prob 2.595 (2.351)	GS 31.047 (31.814)	mem 73.052
Train: [44][670/1500]	BT 0.037 (0.301)	DT 0.000 (0.264)	loss 7.589 (7.510)	prob 3.737 (2.295)	GS 29.969 (31.300)	mem 73.053
Train: [44][680/1500]	BT 0.037 (0.301)	DT 0.000 (0.264)	loss 7.500 (7.528)	prob 2.784 (2.298)	GS 29.406 (31.184)	mem 73.055
Train: [44][690/1500]	BT 0.048 (0.297)	DT 0.016 (0.260)	loss 7.774 (7.544)	prob 2.760 (2.293)	GS 34.781 (31.571)	mem 73.056
Train: [44][700/1500]	BT 0.025 (0.304)	DT 0.000 (0.267)	loss 7.582 (7.558)	prob 1.516 (2.285)	GS 29.156 (31.927)	mem 73.063
Train: [44][710/1500]	BT 0.037 (0.300)	DT 0.001 (0.263)	loss 7.876 (7.643)	prob 2.975 (2.256)	GS 28.641 (32.180)	mem 73.063
Train: [44][720/1500]	BT 0.038 (0.297)	DT 0.000 (0.260)	loss 7.671 (7.647)	prob 2.155 (2.295)	GS 31.188 (32.183)	mem 73.064
Train: [44][730/1500]	BT 0.026 (0.299)	DT 0.000 (0.262)	loss 7.498 (7.652)	prob 3.738 (2.262)	GS 34.234 (31.962)	mem 73.066
Train: [44][740/1500]	BT 0.037 (0.295)	DT 0.001 (0.259)	loss 7.412 (7.633)	prob 2.340 (2.322)	GS 33.188 (32.276)	mem 73.066
Train: [44][750/1500]	BT 0.031 (0.300)	DT 0.000 (0.263)	loss 7.631 (7.628)	prob 2.399 (2.366)	GS 33.031 (32.414)	mem 73.068
Train: [44][760/1500]	BT 0.052 (0.297)	DT 0.010 (0.260)	loss 7.718 (7.645)	prob 2.770 (2.545)	GS 35.281 (33.072)	mem 73.068
Train: [44][770/1500]	BT 0.033 (0.300)	DT 0.000 (0.263)	loss 8.333 (7.745)	prob 3.102 (2.597)	GS 35.969 (32.283)	mem 73.071
Train: [44][780/1500]	BT 0.024 (0.296)	DT 0.000 (0.260)	loss 7.272 (7.675)	prob 3.703 (2.734)	GS 42.562 (32.451)	mem 73.072
Train: [44][790/1500]	BT 0.037 (0.293)	DT 0.000 (0.256)	loss 7.386 (7.687)	prob 2.802 (2.715)	GS 32.328 (32.305)	mem 73.073
Train: [44][800/1500]	BT 0.037 (0.293)	DT 0.001 (0.257)	loss 7.423 (7.647)	prob 3.460 (2.850)	GS 33.641 (32.110)	mem 73.074
Train: [44][810/1500]	BT 0.038 (0.290)	DT 0.001 (0.254)	loss 7.508 (7.731)	prob 3.821 (2.856)	GS 33.891 (32.245)	mem 73.074
Train: [44][820/1500]	BT 0.037 (0.294)	DT 0.000 (0.257)	loss 7.737 (7.696)	prob 3.799 (2.944)	GS 33.609 (32.012)	mem 73.075
Train: [44][830/1500]	BT 0.038 (0.291)	DT 0.001 (0.254)	loss 7.940 (7.722)	prob 3.402 (2.940)	GS 35.328 (32.517)	mem 73.076
Train: [44][840/1500]	BT 0.066 (0.290)	DT 0.003 (0.253)	loss 8.445 (7.687)	prob 2.759 (2.962)	GS 34.938 (32.609)	mem 73.078
Train: [44][850/1500]	BT 0.037 (0.292)	DT 0.001 (0.255)	loss 7.731 (7.674)	prob 3.510 (2.993)	GS 35.984 (32.792)	mem 73.077
Train: [44][860/1500]	BT 0.037 (0.289)	DT 0.001 (0.252)	loss 7.715 (7.656)	prob 3.513 (3.132)	GS 32.594 (33.778)	mem 73.078
Train: [44][870/1500]	BT 0.054 (0.291)	DT 0.000 (0.254)	loss 8.838 (7.692)	prob 3.206 (3.039)	GS 34.250 (33.892)	mem 73.081
Train: [44][880/1500]	BT 2.034 (0.291)	DT 1.997 (0.254)	loss 7.872 (7.691)	prob 3.505 (3.160)	GS 32.766 (33.314)	mem 73.083
Train: [44][890/1500]	BT 1.157 (0.290)	DT 1.109 (0.253)	loss 7.340 (7.659)	prob 3.164 (3.196)	GS 34.438 (33.278)	mem 73.085
Train: [44][900/1500]	BT 0.068 (0.290)	DT 0.010 (0.253)	loss 7.765 (7.655)	prob 3.661 (3.205)	GS 32.922 (33.257)	mem 73.084
Train: [44][910/1500]	BT 0.037 (0.291)	DT 0.001 (0.254)	loss 8.038 (7.707)	prob 2.864 (3.235)	GS 33.906 (33.080)	mem 73.083
Train: [44][920/1500]	BT 0.046 (0.291)	DT 0.005 (0.254)	loss 8.003 (7.732)	prob 3.460 (3.146)	GS 30.891 (33.321)	mem 73.111
Train: [44][930/1500]	BT 0.039 (0.292)	DT 0.001 (0.254)	loss 7.775 (7.679)	prob 3.150 (3.221)	GS 32.484 (33.038)	mem 73.110
Train: [44][940/1500]	BT 0.039 (0.290)	DT 0.001 (0.253)	loss 8.369 (7.643)	prob 3.197 (3.307)	GS 30.500 (32.377)	mem 73.110
Train: [44][950/1500]	BT 0.038 (0.289)	DT 0.001 (0.252)	loss 8.435 (7.668)	prob 3.380 (3.302)	GS 33.125 (32.719)	mem 73.111
Train: [44][960/1500]	BT 0.039 (0.286)	DT 0.001 (0.249)	loss 7.678 (7.623)	prob 3.835 (3.792)	GS 35.219 (32.594)	mem 73.112
Train: [44][970/1500]	BT 0.041 (0.287)	DT 0.001 (0.250)	loss 7.451 (7.535)	prob 3.221 (3.539)	GS 33.203 (32.515)	mem 73.112
Train: [44][980/1500]	BT 0.039 (0.286)	DT 0.001 (0.249)	loss 7.354 (7.531)	prob 3.838 (3.400)	GS 36.172 (32.388)	mem 73.112
Train: [44][990/1500]	BT 1.853 (0.287)	DT 1.814 (0.249)	loss 8.001 (7.556)	prob 2.727 (3.314)	GS 38.766 (32.691)	mem 73.111
Train: [44][1000/1500]	BT 0.062 (0.286)	DT 0.006 (0.249)	loss 7.666 (7.547)	prob 4.058 (3.364)	GS 36.734 (32.665)	mem 73.112
Train: [44][1010/1500]	BT 0.029 (0.283)	DT 0.000 (0.246)	loss 7.243 (7.564)	prob 3.476 (3.426)	GS 35.672 (33.961)	mem 73.112
Train: [44][1020/1500]	BT 0.039 (0.284)	DT 0.001 (0.247)	loss 7.484 (7.508)	prob 3.380 (3.557)	GS 32.484 (32.516)	mem 73.115
Train: [44][1030/1500]	BT 0.039 (0.282)	DT 0.001 (0.245)	loss 7.489 (7.538)	prob 3.257 (3.392)	GS 34.219 (32.645)	mem 73.114
Train: [44][1040/1500]	BT 0.029 (0.284)	DT 0.000 (0.247)	loss 7.980 (7.554)	prob 2.985 (3.338)	GS 39.391 (32.786)	mem 73.114
Train: [44][1050/1500]	BT 0.041 (0.282)	DT 0.001 (0.244)	loss 7.449 (7.521)	prob 3.179 (3.315)	GS 33.453 (32.904)	mem 73.113
Train: [44][1060/1500]	BT 0.040 (0.280)	DT 0.001 (0.243)	loss 7.472 (7.527)	prob 3.445 (3.156)	GS 31.266 (32.102)	mem 73.115
Train: [44][1070/1500]	BT 0.039 (0.281)	DT 0.001 (0.244)	loss 7.982 (7.544)	prob 3.021 (3.238)	GS 35.469 (32.589)	mem 73.113
Train: [44][1080/1500]	BT 0.038 (0.279)	DT 0.001 (0.242)	loss 7.556 (7.579)	prob 3.919 (3.329)	GS 33.656 (32.174)	mem 73.113
Train: [44][1090/1500]	BT 0.039 (0.279)	DT 0.001 (0.242)	loss 7.750 (7.548)	prob 3.395 (3.321)	GS 31.062 (31.967)	mem 73.114
Train: [44][1100/1500]	BT 0.030 (0.277)	DT 0.000 (0.240)	loss 7.513 (7.551)	prob 3.219 (3.356)	GS 34.688 (31.917)	mem 73.114
Train: [44][1110/1500]	BT 0.421 (0.278)	DT 0.384 (0.241)	loss 7.650 (7.510)	prob 3.299 (2.878)	GS 29.828 (32.902)	mem 73.117
Train: [44][1120/1500]	BT 0.037 (0.277)	DT 0.001 (0.239)	loss 8.155 (7.555)	prob 2.675 (3.050)	GS 37.578 (32.583)	mem 73.121
Train: [44][1130/1500]	BT 0.662 (0.275)	DT 0.622 (0.238)	loss 7.974 (7.548)	prob 2.462 (3.041)	GS 39.438 (32.577)	mem 73.123
Train: [44][1140/1500]	BT 0.037 (0.275)	DT 0.001 (0.238)	loss 7.240 (7.503)	prob 3.049 (2.999)	GS 34.016 (32.891)	mem 73.125
Train: [44][1150/1500]	BT 0.050 (0.276)	DT 0.012 (0.238)	loss 7.198 (7.481)	prob 3.441 (3.060)	GS 32.547 (32.602)	mem 73.133
Train: [44][1160/1500]	BT 0.038 (0.281)	DT 0.001 (0.243)	loss 7.165 (7.393)	prob 3.961 (3.357)	GS 29.578 (34.536)	mem 73.132
Train: [44][1170/1500]	BT 0.028 (0.279)	DT 0.000 (0.241)	loss 7.287 (7.459)	prob 3.739 (3.373)	GS 30.266 (33.845)	mem 73.131
Train: [44][1180/1500]	BT 0.190 (0.277)	DT 0.164 (0.239)	loss 7.394 (7.433)	prob 3.126 (3.367)	GS 38.703 (33.502)	mem 73.134
Train: [44][1190/1500]	BT 0.060 (0.279)	DT 0.012 (0.242)	loss 7.427 (7.417)	prob 3.603 (3.285)	GS 32.812 (33.673)	mem 73.015
Train: [44][1200/1500]	BT 0.036 (0.281)	DT 0.001 (0.244)	loss 7.237 (7.399)	prob 3.318 (3.228)	GS 32.375 (34.002)	mem 73.031
Train: [44][1210/1500]	BT 0.026 (0.283)	DT 0.001 (0.245)	loss 7.434 (7.267)	prob 2.690 (3.148)	GS 35.219 (34.375)	mem 73.035
Train: [44][1220/1500]	BT 0.037 (0.281)	DT 0.001 (0.243)	loss 7.234 (7.285)	prob 4.089 (3.132)	GS 36.438 (33.837)	mem 73.036
Train: [44][1230/1500]	BT 0.037 (0.279)	DT 0.001 (0.241)	loss 7.524 (7.290)	prob 2.210 (3.182)	GS 35.766 (33.846)	mem 73.035
Train: [44][1240/1500]	BT 0.030 (0.282)	DT 0.000 (0.244)	loss 7.436 (7.293)	prob 2.455 (3.118)	GS 35.438 (33.774)	mem 73.035
Train: [44][1250/1500]	BT 0.036 (0.280)	DT 0.000 (0.242)	loss 7.100 (7.297)	prob 4.021 (3.161)	GS 30.688 (33.295)	mem 73.035
Train: [44][1260/1500]	BT 0.036 (0.281)	DT 0.000 (0.243)	loss 7.376 (7.292)	prob 3.939 (3.215)	GS 34.844 (31.700)	mem 73.037
Train: [44][1270/1500]	BT 0.062 (0.279)	DT 0.008 (0.241)	loss 7.425 (7.286)	prob 2.955 (3.144)	GS 32.688 (31.916)	mem 73.038
Train: [44][1280/1500]	BT 0.054 (0.281)	DT 0.016 (0.244)	loss 6.935 (7.229)	prob 3.045 (3.061)	GS 34.062 (32.031)	mem 73.059
Train: [44][1290/1500]	BT 0.037 (0.279)	DT 0.001 (0.242)	loss 7.408 (7.234)	prob 2.756 (3.055)	GS 33.234 (32.200)	mem 73.060
Train: [44][1300/1500]	BT 0.028 (0.277)	DT 0.000 (0.240)	loss 6.859 (7.209)	prob 2.962 (3.036)	GS 31.703 (32.478)	mem 73.061
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [44][1310/1500]	BT 0.027 (0.279)	DT 0.000 (0.241)	loss 7.063 (7.162)	prob 3.013 (2.999)	GS 33.750 (31.228)	mem 73.063
Train: [44][1320/1500]	BT 0.038 (0.277)	DT 0.001 (0.240)	loss 7.228 (7.193)	prob 3.021 (2.874)	GS 31.250 (32.095)	mem 73.065
Train: [44][1330/1500]	BT 0.058 (0.279)	DT 0.011 (0.241)	loss 7.279 (7.175)	prob 3.064 (2.952)	GS 31.547 (32.168)	mem 73.050
Train: [44][1340/1500]	BT 0.055 (0.277)	DT 0.011 (0.240)	loss 7.207 (7.168)	prob 3.337 (3.028)	GS 34.484 (32.015)	mem 73.049
Train: [44][1350/1500]	BT 0.039 (0.275)	DT 0.001 (0.238)	loss 7.095 (7.170)	prob 3.129 (2.970)	GS 33.469 (32.040)	mem 73.048
Train: [44][1360/1500]	BT 0.039 (0.277)	DT 0.001 (0.239)	loss 7.418 (7.276)	prob 2.650 (2.697)	GS 33.969 (34.223)	mem 73.048
Train: [44][1370/1500]	BT 0.039 (0.275)	DT 0.001 (0.237)	loss 7.288 (7.305)	prob 2.989 (2.899)	GS 32.328 (33.512)	mem 73.048
Train: [44][1380/1500]	BT 0.039 (0.275)	DT 0.001 (0.238)	loss 7.128 (7.246)	prob 2.760 (2.942)	GS 31.703 (33.148)	mem 73.047
Train: [44][1390/1500]	BT 0.065 (0.274)	DT 0.007 (0.237)	loss 7.653 (7.285)	prob 1.995 (2.809)	GS 31.125 (33.277)	mem 73.044
Train: [44][1400/1500]	BT 0.057 (0.276)	DT 0.013 (0.239)	loss 7.680 (7.295)	prob 2.397 (2.783)	GS 37.453 (33.139)	mem 73.047
Train: [44][1410/1500]	BT 0.038 (0.276)	DT 0.001 (0.239)	loss 7.189 (7.343)	prob 2.186 (2.466)	GS 34.125 (33.095)	mem 73.049
Train: [44][1420/1500]	BT 0.039 (0.275)	DT 0.001 (0.237)	loss 8.451 (7.393)	prob 2.812 (2.515)	GS 30.453 (32.374)	mem 73.048
Train: [44][1430/1500]	BT 0.038 (0.276)	DT 0.001 (0.239)	loss 7.150 (7.356)	prob 4.046 (2.824)	GS 33.031 (32.007)	mem 73.047
Train: [44][1440/1500]	BT 0.037 (0.275)	DT 0.001 (0.237)	loss 7.711 (7.364)	prob 2.966 (2.875)	GS 33.844 (32.139)	mem 73.058
Train: [44][1450/1500]	BT 0.037 (0.273)	DT 0.000 (0.236)	loss 7.395 (7.368)	prob 2.957 (2.888)	GS 34.562 (32.114)	mem 73.064
Train: [44][1460/1500]	BT 0.034 (0.273)	DT 0.000 (0.236)	loss 7.554 (7.519)	prob 3.004 (2.535)	GS 36.641 (32.147)	mem 72.740
Train: [44][1470/1500]	BT 0.026 (0.272)	DT 0.000 (0.234)	loss 7.816 (7.539)	prob 1.917 (2.424)	GS 41.234 (32.274)	mem 72.704
Train: [44][1480/1500]	BT 0.028 (0.272)	DT 0.000 (0.234)	loss 8.199 (7.553)	prob 2.275 (2.463)	GS 29.969 (31.949)	mem 27.563
Train: [44][1490/1500]	BT 0.023 (0.270)	DT 0.000 (0.233)	loss 7.536 (7.587)	prob 2.569 (2.495)	GS 32.406 (31.853)	mem 27.416
Train: [44][1500/1500]	BT 0.055 (0.269)	DT 0.018 (0.231)	loss 7.298 (7.580)	prob 4.094 (2.527)	GS 29.250 (31.801)	mem 19.172
Train: [44][1510/1500]	BT 0.033 (0.267)	DT 0.000 (0.230)	loss 8.129 (7.622)	prob 2.874 (2.887)	GS 33.688 (31.887)	mem 7.967
epoch 44, total time 404.06
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [45][1/1500]	BT 18.409 (18.409)	DT 18.327 (18.327)	loss 7.130 (7.130)	prob 2.894 (2.894)	GS 31.750 (31.750)	mem 71.472
Train: [45][10/1500]	BT 0.078 (2.649)	DT 0.002 (2.575)	loss 7.193 (7.432)	prob 3.521 (3.050)	GS 37.000 (33.649)	mem 71.738
Train: [45][20/1500]	BT 0.026 (2.516)	DT 0.000 (2.451)	loss 7.163 (7.436)	prob 3.777 (2.957)	GS 31.828 (33.433)	mem 71.790
Train: [45][30/1500]	BT 0.029 (1.687)	DT 0.000 (1.634)	loss 7.258 (7.424)	prob 4.119 (3.001)	GS 33.594 (32.854)	mem 71.790
Train: [45][40/1500]	BT 4.045 (1.373)	DT 4.001 (1.326)	loss 7.652 (7.506)	prob 2.906 (2.996)	GS 35.125 (32.772)	mem 71.802
Train: [45][50/1500]	BT 0.028 (1.104)	DT 0.000 (1.061)	loss 7.567 (7.510)	prob 4.750 (3.118)	GS 33.531 (32.846)	mem 71.803
Train: [45][60/1500]	BT 0.033 (0.925)	DT 0.001 (0.884)	loss 7.570 (7.542)	prob 3.997 (3.491)	GS 35.125 (31.955)	mem 71.806
Train: [45][70/1500]	BT 0.059 (0.839)	DT 0.008 (0.798)	loss 7.610 (7.636)	prob 4.249 (3.390)	GS 29.828 (32.272)	mem 71.812
Train: [45][80/1500]	BT 0.031 (0.740)	DT 0.000 (0.699)	loss 7.870 (7.655)	prob 4.162 (3.555)	GS 32.891 (31.701)	mem 71.813
Train: [45][90/1500]	BT 0.035 (0.729)	DT 0.001 (0.688)	loss 7.588 (7.619)	prob 3.621 (3.569)	GS 31.656 (31.764)	mem 71.834
Train: [45][100/1500]	BT 0.037 (0.659)	DT 0.000 (0.619)	loss 8.563 (7.617)	prob 3.377 (3.604)	GS 37.281 (31.927)	mem 71.836
Train: [45][110/1500]	BT 0.037 (0.602)	DT 0.000 (0.563)	loss 8.033 (7.719)	prob 3.394 (3.743)	GS 33.109 (31.688)	mem 71.836
Train: [45][120/1500]	BT 0.037 (0.578)	DT 0.001 (0.538)	loss 7.410 (7.661)	prob 3.629 (3.342)	GS 33.328 (32.131)	mem 71.839
Train: [45][130/1500]	BT 0.037 (0.536)	DT 0.000 (0.497)	loss 8.035 (7.683)	prob 3.710 (3.297)	GS 35.172 (32.102)	mem 71.838
Train: [45][140/1500]	BT 0.038 (0.519)	DT 0.001 (0.480)	loss 8.036 (7.682)	prob 4.125 (3.289)	GS 36.250 (32.289)	mem 71.841
Train: [45][150/1500]	BT 0.037 (0.492)	DT 0.001 (0.453)	loss 8.042 (7.676)	prob 3.238 (3.269)	GS 32.578 (32.455)	mem 71.841
Train: [45][160/1500]	BT 0.507 (0.476)	DT 0.468 (0.437)	loss 7.781 (7.713)	prob 3.371 (3.455)	GS 36.094 (33.230)	mem 71.864
Train: [45][170/1500]	BT 0.034 (0.490)	DT 0.001 (0.451)	loss 7.776 (7.666)	prob 3.932 (3.576)	GS 36.656 (32.884)	mem 71.876
Train: [45][180/1500]	BT 0.026 (0.464)	DT 0.000 (0.426)	loss 7.380 (7.573)	prob 3.446 (3.592)	GS 34.703 (33.045)	mem 71.878
Train: [45][190/1500]	BT 0.040 (0.441)	DT 0.001 (0.404)	loss 7.731 (7.541)	prob 3.354 (3.576)	GS 34.406 (32.969)	mem 71.879
Train: [45][200/1500]	BT 0.038 (0.444)	DT 0.000 (0.407)	loss 7.553 (7.560)	prob 3.506 (3.630)	GS 29.406 (32.749)	mem 71.896
Train: [45][210/1500]	BT 0.039 (0.425)	DT 0.001 (0.387)	loss 7.580 (7.691)	prob 3.015 (3.202)	GS 34.594 (35.059)	mem 71.896
Train: [45][220/1500]	BT 0.035 (0.421)	DT 0.001 (0.384)	loss 7.461 (7.656)	prob 3.825 (3.402)	GS 33.812 (33.677)	mem 71.896
Train: [45][230/1500]	BT 0.039 (0.404)	DT 0.001 (0.367)	loss 7.897 (7.644)	prob 3.243 (3.457)	GS 36.734 (33.977)	mem 71.896
Train: [45][240/1500]	BT 0.048 (0.406)	DT 0.000 (0.369)	loss 7.844 (7.614)	prob 4.200 (3.512)	GS 36.172 (33.451)	mem 71.896
Train: [45][250/1500]	BT 0.038 (0.402)	DT 0.001 (0.364)	loss 7.361 (7.585)	prob 4.536 (3.588)	GS 35.250 (33.409)	mem 71.899
Train: [45][260/1500]	BT 0.039 (0.388)	DT 0.000 (0.350)	loss 7.339 (7.579)	prob 3.967 (3.625)	GS 36.016 (32.655)	mem 71.901
Train: [45][270/1500]	BT 2.151 (0.387)	DT 2.113 (0.349)	loss 7.897 (7.573)	prob 4.008 (3.612)	GS 31.922 (32.384)	mem 71.903
Train: [45][280/1500]	BT 0.040 (0.375)	DT 0.001 (0.337)	loss 7.329 (7.587)	prob 4.456 (3.682)	GS 31.812 (32.267)	mem 71.904
Train: [45][290/1500]	BT 0.039 (0.370)	DT 0.001 (0.332)	loss 7.522 (7.574)	prob 4.399 (3.759)	GS 29.547 (32.184)	mem 71.905
Train: [45][300/1500]	BT 0.039 (0.365)	DT 0.001 (0.327)	loss 7.632 (7.586)	prob 2.972 (3.673)	GS 28.281 (32.310)	mem 71.905
Train: [45][310/1500]	BT 0.039 (0.356)	DT 0.001 (0.318)	loss 7.526 (7.407)	prob 3.853 (3.221)	GS 35.453 (31.672)	mem 71.905
Train: [45][320/1500]	BT 0.039 (0.354)	DT 0.001 (0.316)	loss 8.049 (7.468)	prob 3.439 (3.462)	GS 32.547 (32.003)	mem 71.907
Train: [45][330/1500]	BT 0.043 (0.351)	DT 0.001 (0.313)	loss 7.582 (7.469)	prob 4.065 (3.577)	GS 35.547 (32.210)	mem 71.907
Train: [45][340/1500]	BT 0.039 (0.342)	DT 0.001 (0.304)	loss 7.259 (7.495)	prob 3.882 (3.439)	GS 32.203 (32.384)	mem 71.908
Train: [45][350/1500]	BT 0.036 (0.347)	DT 0.000 (0.308)	loss 7.672 (7.494)	prob 3.614 (3.443)	GS 32.953 (32.322)	mem 71.911
Train: [45][360/1500]	BT 0.042 (0.343)	DT 0.000 (0.305)	loss 7.753 (7.658)	prob 2.998 (2.880)	GS 30.344 (33.898)	mem 71.913
Train: [45][370/1500]	BT 0.038 (0.334)	DT 0.001 (0.296)	loss 7.410 (7.638)	prob 2.930 (2.874)	GS 32.875 (33.559)	mem 71.915
Train: [45][380/1500]	BT 0.037 (0.332)	DT 0.000 (0.294)	loss 7.889 (7.608)	prob 2.966 (2.925)	GS 35.219 (33.226)	mem 71.919
Train: [45][390/1500]	BT 0.037 (0.327)	DT 0.001 (0.289)	loss 7.483 (7.584)	prob 2.398 (2.892)	GS 32.766 (33.257)	mem 71.929
Train: [45][400/1500]	BT 0.037 (0.326)	DT 0.001 (0.289)	loss 8.042 (7.593)	prob 2.073 (2.853)	GS 38.531 (33.367)	mem 71.931
Train: [45][410/1500]	BT 0.040 (0.320)	DT 0.001 (0.282)	loss 7.547 (7.620)	prob 3.579 (3.270)	GS 35.969 (32.180)	mem 71.936
Train: [45][420/1500]	BT 0.060 (0.313)	DT 0.003 (0.275)	loss 7.147 (7.520)	prob 3.214 (3.250)	GS 35.625 (32.911)	mem 71.952
Train: [45][430/1500]	BT 0.064 (0.325)	DT 0.006 (0.287)	loss 7.284 (7.463)	prob 3.155 (3.161)	GS 31.656 (32.521)	mem 71.839
Train: [45][440/1500]	BT 0.034 (0.321)	DT 0.000 (0.283)	loss 7.573 (7.473)	prob 2.563 (3.103)	GS 30.828 (32.908)	mem 71.841
Train: [45][450/1500]	BT 0.024 (0.320)	DT 0.000 (0.283)	loss 8.193 (7.478)	prob 3.088 (3.058)	GS 35.078 (33.091)	mem 71.842
Train: [45][460/1500]	BT 0.036 (0.319)	DT 0.000 (0.282)	loss 7.222 (7.469)	prob 3.919 (3.127)	GS 29.938 (32.731)	mem 71.844
Train: [45][470/1500]	BT 0.037 (0.315)	DT 0.000 (0.277)	loss 7.557 (7.471)	prob 3.724 (3.254)	GS 26.438 (31.533)	mem 71.844
Train: [45][480/1500]	BT 4.115 (0.318)	DT 4.083 (0.281)	loss 7.287 (7.461)	prob 2.443 (3.100)	GS 32.516 (31.917)	mem 71.846
Train: [45][490/1500]	BT 0.070 (0.313)	DT 0.007 (0.275)	loss 7.632 (7.450)	prob 3.154 (2.972)	GS 31.844 (32.089)	mem 71.845
Train: [45][500/1500]	BT 0.027 (0.331)	DT 0.000 (0.293)	loss 7.192 (7.476)	prob 2.621 (2.873)	GS 37.109 (32.463)	mem 71.844
Train: [45][510/1500]	BT 0.024 (0.325)	DT 0.000 (0.288)	loss 8.169 (7.495)	prob 2.861 (2.561)	GS 29.469 (32.553)	mem 71.854
Train: [45][520/1500]	BT 3.121 (0.326)	DT 3.076 (0.288)	loss 7.607 (7.509)	prob 2.532 (2.711)	GS 33.297 (32.016)	mem 72.244
Train: [45][530/1500]	BT 0.066 (0.320)	DT 0.001 (0.283)	loss 7.307 (7.504)	prob 2.535 (2.637)	GS 33.188 (32.063)	mem 72.246
Train: [45][540/1500]	BT 0.063 (0.316)	DT 0.005 (0.278)	loss 7.536 (7.495)	prob 1.926 (2.506)	GS 35.000 (32.251)	mem 72.245
Train: [45][550/1500]	BT 0.067 (0.320)	DT 0.007 (0.282)	loss 7.301 (7.534)	prob 3.061 (2.427)	GS 31.922 (32.426)	mem 73.025
Train: [45][560/1500]	BT 0.069 (0.316)	DT 0.009 (0.277)	loss 8.068 (7.513)	prob 1.883 (2.201)	GS 34.703 (33.402)	mem 73.026
Train: [45][570/1500]	BT 0.039 (0.319)	DT 0.001 (0.280)	loss 7.540 (7.541)	prob 3.547 (2.377)	GS 32.578 (33.121)	mem 73.027
Train: [45][580/1500]	BT 0.038 (0.314)	DT 0.001 (0.275)	loss 7.535 (7.619)	prob 2.109 (2.295)	GS 36.641 (33.712)	mem 73.027
Train: [45][590/1500]	BT 0.039 (0.309)	DT 0.001 (0.271)	loss 8.228 (7.653)	prob 1.958 (2.172)	GS 32.172 (33.553)	mem 73.028
Train: [45][600/1500]	BT 0.039 (0.310)	DT 0.001 (0.272)	loss 7.789 (7.692)	prob 2.203 (2.062)	GS 34.156 (33.772)	mem 73.029
Train: [45][610/1500]	BT 0.039 (0.306)	DT 0.001 (0.267)	loss 7.872 (7.691)	prob 2.905 (2.188)	GS 31.688 (31.564)	mem 73.030
Train: [45][620/1500]	BT 0.038 (0.309)	DT 0.001 (0.271)	loss 7.796 (7.704)	prob 2.944 (2.300)	GS 32.438 (32.089)	mem 73.030
Train: [45][630/1500]	BT 0.028 (0.305)	DT 0.000 (0.267)	loss 8.105 (7.707)	prob 4.065 (2.271)	GS 28.453 (31.707)	mem 73.031
Train: [45][640/1500]	BT 8.105 (0.313)	DT 8.065 (0.275)	loss 7.389 (7.652)	prob 2.959 (2.422)	GS 28.359 (31.719)	mem 73.030
Train: [45][650/1500]	BT 0.038 (0.309)	DT 0.001 (0.271)	loss 7.407 (7.677)	prob 3.166 (2.378)	GS 36.266 (31.820)	mem 73.030
Train: [45][660/1500]	BT 0.037 (0.305)	DT 0.001 (0.267)	loss 7.742 (7.719)	prob 3.799 (2.656)	GS 32.562 (32.303)	mem 73.030
Train: [45][670/1500]	BT 0.036 (0.306)	DT 0.000 (0.267)	loss 8.026 (7.779)	prob 1.998 (2.615)	GS 31.734 (32.464)	mem 73.043
Train: [45][680/1500]	BT 0.036 (0.302)	DT 0.000 (0.263)	loss 7.680 (7.756)	prob 2.189 (2.532)	GS 35.578 (32.184)	mem 73.045
Train: [45][690/1500]	BT 0.037 (0.302)	DT 0.001 (0.264)	loss 7.626 (7.776)	prob 3.505 (2.581)	GS 37.422 (32.431)	mem 73.049
Train: [45][700/1500]	BT 0.052 (0.300)	DT 0.006 (0.262)	loss 7.543 (7.783)	prob 2.713 (2.600)	GS 32.094 (32.389)	mem 73.051
Train: [45][710/1500]	BT 0.054 (0.297)	DT 0.000 (0.258)	loss 7.890 (7.823)	prob 2.618 (2.928)	GS 30.734 (31.369)	mem 73.050
Train: [45][720/1500]	BT 0.048 (0.302)	DT 0.006 (0.264)	loss 8.346 (7.867)	prob 3.659 (2.894)	GS 32.984 (32.089)	mem 73.052
Train: [45][730/1500]	BT 0.038 (0.302)	DT 0.000 (0.264)	loss 7.781 (7.828)	prob 3.940 (3.112)	GS 33.922 (32.356)	mem 73.054
Train: [45][740/1500]	BT 0.037 (0.302)	DT 0.001 (0.263)	loss 8.003 (7.798)	prob 3.285 (3.092)	GS 31.141 (32.322)	mem 73.056
Train: [45][750/1500]	BT 0.037 (0.301)	DT 0.000 (0.262)	loss 7.968 (7.837)	prob 3.296 (3.056)	GS 30.578 (32.371)	mem 73.057
Train: [45][760/1500]	BT 0.286 (0.298)	DT 0.248 (0.259)	loss 7.640 (7.657)	prob 2.552 (2.926)	GS 34.219 (31.959)	mem 73.060
Train: [45][770/1500]	BT 0.037 (0.300)	DT 0.000 (0.261)	loss 7.921 (7.748)	prob 3.556 (3.106)	GS 32.828 (31.732)	mem 73.063
Train: [45][780/1500]	BT 0.038 (0.297)	DT 0.001 (0.258)	loss 7.825 (7.757)	prob 3.977 (3.195)	GS 38.734 (32.144)	mem 73.063
Train: [45][790/1500]	BT 0.326 (0.295)	DT 0.283 (0.256)	loss 7.948 (7.757)	prob 3.275 (3.112)	GS 34.594 (32.450)	mem 73.065
Train: [45][800/1500]	BT 0.038 (0.298)	DT 0.001 (0.259)	loss 8.117 (7.775)	prob 3.678 (3.174)	GS 34.656 (32.490)	mem 73.066
Train: [45][810/1500]	BT 0.050 (0.298)	DT 0.016 (0.259)	loss 7.922 (7.515)	prob 4.056 (3.681)	GS 31.703 (31.086)	mem 73.066
Train: [45][820/1500]	BT 0.031 (0.301)	DT 0.001 (0.262)	loss 7.998 (7.708)	prob 3.693 (3.686)	GS 32.188 (31.780)	mem 73.066
Train: [45][830/1500]	BT 0.028 (0.304)	DT 0.000 (0.265)	loss 8.172 (7.794)	prob 3.939 (3.637)	GS 35.281 (32.798)	mem 73.068
Train: [45][840/1500]	BT 0.026 (0.301)	DT 0.000 (0.262)	loss 7.422 (7.824)	prob 4.076 (3.587)	GS 31.328 (32.682)	mem 73.068
Train: [45][850/1500]	BT 0.023 (0.298)	DT 0.000 (0.259)	loss 8.035 (7.827)	prob 3.514 (3.584)	GS 36.594 (32.806)	mem 73.069
Train: [45][860/1500]	BT 0.025 (0.299)	DT 0.000 (0.261)	loss 8.171 (7.875)	prob 4.313 (3.793)	GS 35.484 (33.941)	mem 73.073
Train: [45][870/1500]	BT 0.027 (0.296)	DT 0.000 (0.258)	loss 8.403 (7.853)	prob 3.591 (3.770)	GS 35.625 (34.057)	mem 73.075
Train: [45][880/1500]	BT 0.033 (0.303)	DT 0.001 (0.265)	loss 7.881 (7.824)	prob 3.785 (3.772)	GS 31.969 (34.089)	mem 73.079
Train: [45][890/1500]	BT 0.035 (0.300)	DT 0.000 (0.262)	loss 8.194 (7.810)	prob 3.495 (3.765)	GS 32.469 (34.336)	mem 73.080
Train: [45][900/1500]	BT 0.043 (0.302)	DT 0.001 (0.264)	loss 7.726 (7.797)	prob 4.374 (3.817)	GS 30.016 (33.898)	mem 73.084
Train: [45][910/1500]	BT 0.037 (0.299)	DT 0.000 (0.261)	loss 7.308 (7.773)	prob 4.706 (4.027)	GS 31.828 (32.903)	mem 73.085
Train: [45][920/1500]	BT 0.038 (0.296)	DT 0.000 (0.258)	loss 7.598 (7.765)	prob 4.853 (4.177)	GS 34.938 (32.144)	mem 73.084
Train: [45][930/1500]	BT 0.027 (0.297)	DT 0.000 (0.259)	loss 8.087 (7.713)	prob 4.262 (4.132)	GS 35.625 (32.489)	mem 73.086
Train: [45][940/1500]	BT 0.102 (0.295)	DT 0.001 (0.257)	loss 7.597 (7.726)	prob 4.431 (4.127)	GS 31.719 (32.678)	mem 73.087
Train: [45][950/1500]	BT 0.038 (0.295)	DT 0.001 (0.257)	loss 7.595 (7.731)	prob 4.331 (4.106)	GS 36.625 (32.897)	mem 73.089
Train: [45][960/1500]	BT 0.037 (0.292)	DT 0.001 (0.254)	loss 8.171 (7.780)	prob 4.491 (4.422)	GS 33.156 (32.127)	mem 73.089
Train: [45][970/1500]	BT 0.038 (0.290)	DT 0.001 (0.252)	loss 7.571 (7.771)	prob 4.208 (4.106)	GS 32.891 (32.409)	mem 73.089
Train: [45][980/1500]	BT 0.038 (0.290)	DT 0.001 (0.253)	loss 7.310 (7.718)	prob 3.966 (4.126)	GS 32.750 (32.360)	mem 73.091
Train: [45][990/1500]	BT 0.058 (0.288)	DT 0.021 (0.250)	loss 8.103 (7.706)	prob 4.357 (4.060)	GS 35.531 (32.351)	mem 73.091
Train: [45][1000/1500]	BT 0.029 (0.288)	DT 0.000 (0.250)	loss 8.372 (7.708)	prob 3.602 (4.051)	GS 31.281 (32.367)	mem 73.091
Train: [45][1010/1500]	BT 0.039 (0.293)	DT 0.000 (0.255)	loss 7.748 (7.597)	prob 4.161 (4.044)	GS 33.734 (32.933)	mem 73.120
Train: [45][1020/1500]	BT 0.039 (0.290)	DT 0.001 (0.252)	loss 7.167 (7.650)	prob 4.752 (4.064)	GS 29.844 (32.271)	mem 73.122
Train: [45][1030/1500]	BT 0.028 (0.292)	DT 0.000 (0.254)	loss 7.798 (7.651)	prob 4.520 (4.138)	GS 33.156 (32.034)	mem 73.123
Train: [45][1040/1500]	BT 0.039 (0.289)	DT 0.001 (0.251)	loss 7.667 (7.615)	prob 4.192 (4.198)	GS 36.516 (32.070)	mem 73.123
Train: [45][1050/1500]	BT 0.038 (0.289)	DT 0.000 (0.252)	loss 7.311 (7.591)	prob 4.953 (4.219)	GS 36.234 (32.185)	mem 73.125
Train: [45][1060/1500]	BT 0.039 (0.287)	DT 0.001 (0.249)	loss 8.268 (7.585)	prob 4.094 (4.096)	GS 37.656 (33.067)	mem 73.124
Train: [45][1070/1500]	BT 0.029 (0.285)	DT 0.000 (0.247)	loss 7.222 (7.530)	prob 4.851 (4.090)	GS 35.141 (32.848)	mem 73.126
Train: [45][1080/1500]	BT 0.028 (0.295)	DT 0.000 (0.258)	loss 7.501 (7.533)	prob 4.777 (4.182)	GS 31.406 (32.289)	mem 73.124
Train: [45][1090/1500]	BT 0.033 (0.293)	DT 0.001 (0.255)	loss 7.405 (7.527)	prob 5.057 (4.159)	GS 31.672 (32.592)	mem 73.124
Train: [45][1100/1500]	BT 0.032 (0.294)	DT 0.000 (0.257)	loss 7.382 (7.533)	prob 4.488 (4.174)	GS 33.547 (32.368)	mem 73.122
Train: [45][1110/1500]	BT 0.038 (0.292)	DT 0.000 (0.255)	loss 7.452 (7.521)	prob 4.485 (3.783)	GS 37.266 (33.414)	mem 73.123
Train: [45][1120/1500]	BT 0.038 (0.290)	DT 0.003 (0.252)	loss 7.457 (7.467)	prob 4.981 (4.065)	GS 29.516 (32.647)	mem 73.123
Train: [45][1130/1500]	BT 0.036 (0.291)	DT 0.000 (0.254)	loss 7.715 (7.460)	prob 4.429 (4.091)	GS 31.328 (32.523)	mem 73.123
Train: [45][1140/1500]	BT 0.039 (0.289)	DT 0.001 (0.252)	loss 7.184 (7.421)	prob 4.548 (4.095)	GS 36.875 (32.734)	mem 73.124
Train: [45][1150/1500]	BT 0.040 (0.289)	DT 0.001 (0.252)	loss 7.301 (7.417)	prob 4.183 (4.023)	GS 35.062 (32.862)	mem 73.125
Train: [45][1160/1500]	BT 0.039 (0.287)	DT 0.001 (0.250)	loss 7.223 (7.438)	prob 4.726 (4.135)	GS 31.109 (31.550)	mem 73.124
Train: [45][1170/1500]	BT 0.075 (0.290)	DT 0.006 (0.252)	loss 7.754 (7.414)	prob 4.002 (4.136)	GS 33.500 (32.359)	mem 73.121
Train: [45][1180/1500]	BT 0.037 (0.287)	DT 0.001 (0.250)	loss 7.598 (7.413)	prob 4.754 (4.114)	GS 35.500 (32.518)	mem 73.122
Train: [45][1190/1500]	BT 0.054 (0.285)	DT 0.001 (0.248)	loss 7.037 (7.403)	prob 4.901 (4.182)	GS 35.172 (32.614)	mem 73.122
Train: [45][1200/1500]	BT 0.047 (0.294)	DT 0.001 (0.256)	loss 7.350 (7.381)	prob 4.181 (4.135)	GS 33.969 (33.020)	mem 73.119
Train: [45][1210/1500]	BT 0.039 (0.292)	DT 0.001 (0.254)	loss 7.651 (7.385)	prob 3.148 (3.837)	GS 35.281 (35.508)	mem 73.120
Train: [45][1220/1500]	BT 0.034 (0.293)	DT 0.000 (0.255)	loss 7.315 (7.360)	prob 3.748 (3.641)	GS 35.609 (35.609)	mem 73.125
Train: [45][1230/1500]	BT 0.036 (0.291)	DT 0.001 (0.253)	loss 7.608 (7.352)	prob 4.093 (3.674)	GS 32.781 (34.872)	mem 73.127
Train: [45][1240/1500]	BT 0.037 (0.288)	DT 0.000 (0.251)	loss 7.877 (7.341)	prob 4.014 (3.808)	GS 36.609 (34.268)	mem 73.128
Train: [45][1250/1500]	BT 0.027 (0.289)	DT 0.000 (0.252)	loss 7.261 (7.342)	prob 3.253 (3.808)	GS 35.812 (34.266)	mem 73.137
Train: [45][1260/1500]	BT 0.038 (0.287)	DT 0.001 (0.250)	loss 7.019 (7.290)	prob 4.175 (3.966)	GS 33.969 (31.794)	mem 73.138
Train: [45][1270/1500]	BT 0.037 (0.288)	DT 0.001 (0.250)	loss 7.349 (7.294)	prob 3.733 (3.792)	GS 33.578 (32.636)	mem 73.038
Train: [45][1280/1500]	BT 0.037 (0.286)	DT 0.001 (0.248)	loss 7.124 (7.298)	prob 3.856 (3.785)	GS 32.344 (32.268)	mem 73.037
Train: [45][1290/1500]	BT 0.067 (0.284)	DT 0.006 (0.246)	loss 7.118 (7.301)	prob 3.826 (3.822)	GS 34.891 (32.439)	mem 73.037
Train: [45][1300/1500]	BT 0.064 (0.285)	DT 0.005 (0.248)	loss 7.197 (7.292)	prob 3.905 (3.794)	GS 27.750 (32.389)	mem 73.038
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [45][1310/1500]	BT 0.034 (0.283)	DT 0.001 (0.246)	loss 7.276 (7.263)	prob 3.833 (4.029)	GS 30.500 (30.395)	mem 73.038
Train: [45][1320/1500]	BT 0.094 (0.285)	DT 0.001 (0.247)	loss 7.087 (7.246)	prob 4.099 (3.757)	GS 34.297 (31.939)	mem 73.040
Train: [45][1330/1500]	BT 0.037 (0.284)	DT 0.001 (0.246)	loss 7.250 (7.233)	prob 3.471 (3.618)	GS 36.109 (31.847)	mem 73.040
Train: [45][1340/1500]	BT 0.037 (0.284)	DT 0.000 (0.246)	loss 7.419 (7.218)	prob 3.336 (3.603)	GS 35.391 (32.410)	mem 73.041
Train: [45][1350/1500]	BT 0.028 (0.283)	DT 0.000 (0.246)	loss 7.161 (7.212)	prob 3.447 (3.608)	GS 30.078 (32.546)	mem 73.045
Train: [45][1360/1500]	BT 0.040 (0.282)	DT 0.001 (0.244)	loss 6.951 (7.155)	prob 4.285 (3.400)	GS 33.734 (31.911)	mem 73.046
Train: [45][1370/1500]	BT 0.038 (0.282)	DT 0.001 (0.245)	loss 7.115 (7.161)	prob 3.130 (3.397)	GS 32.000 (32.346)	mem 73.065
Train: [45][1380/1500]	BT 0.038 (0.281)	DT 0.001 (0.243)	loss 7.417 (7.195)	prob 3.325 (3.336)	GS 29.141 (32.502)	mem 73.065
Train: [45][1390/1500]	BT 1.225 (0.281)	DT 1.187 (0.244)	loss 7.329 (7.197)	prob 3.806 (3.386)	GS 32.469 (32.067)	mem 73.065
Train: [45][1400/1500]	BT 0.038 (0.280)	DT 0.001 (0.243)	loss 6.900 (7.182)	prob 4.013 (3.348)	GS 34.609 (32.446)	mem 73.068
Train: [45][1410/1500]	BT 0.798 (0.279)	DT 0.697 (0.241)	loss 7.016 (7.110)	prob 3.486 (3.341)	GS 38.094 (32.931)	mem 73.068
Train: [45][1420/1500]	BT 0.039 (0.281)	DT 0.001 (0.243)	loss 7.486 (7.140)	prob 3.141 (3.312)	GS 34.891 (33.163)	mem 73.054
Train: [45][1430/1500]	BT 0.038 (0.279)	DT 0.001 (0.241)	loss 6.961 (7.159)	prob 4.300 (3.275)	GS 30.922 (32.754)	mem 73.054
Train: [45][1440/1500]	BT 0.036 (0.280)	DT 0.001 (0.242)	loss 7.294 (7.174)	prob 3.623 (3.323)	GS 32.141 (32.822)	mem 73.053
Train: [45][1450/1500]	BT 0.027 (0.281)	DT 0.000 (0.243)	loss 7.208 (7.179)	prob 3.021 (3.326)	GS 32.812 (32.594)	mem 73.053
Train: [45][1460/1500]	BT 0.039 (0.279)	DT 0.001 (0.241)	loss 6.943 (7.185)	prob 3.243 (2.993)	GS 31.453 (32.552)	mem 73.055
Train: [45][1470/1500]	BT 0.028 (0.280)	DT 0.000 (0.242)	loss 7.305 (7.141)	prob 3.176 (3.178)	GS 33.547 (31.945)	mem 72.031
Train: [45][1480/1500]	BT 0.028 (0.278)	DT 0.000 (0.240)	loss 6.938 (7.126)	prob 2.879 (3.053)	GS 33.062 (32.583)	mem 72.031
Train: [45][1490/1500]	BT 0.033 (0.277)	DT 0.000 (0.239)	loss 7.374 (7.128)	prob 3.747 (3.020)	GS 30.031 (32.186)	mem 10.794
Train: [45][1500/1500]	BT 0.026 (0.275)	DT 0.000 (0.238)	loss 6.886 (7.129)	prob 3.835 (2.984)	GS 34.531 (32.362)	mem 10.794
Train: [45][1510/1500]	BT 0.155 (0.274)	DT 0.118 (0.236)	loss 7.321 (6.954)	prob 3.067 (2.939)	GS 32.312 (31.934)	mem 8.529
epoch 45, total time 413.52
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [46][1/1500]	BT 18.970 (18.970)	DT 18.913 (18.913)	loss 6.729 (6.729)	prob 2.585 (2.585)	GS 28.469 (28.469)	mem 71.579
Train: [46][10/1500]	BT 0.048 (2.577)	DT 0.001 (2.521)	loss 7.151 (6.827)	prob 2.720 (3.053)	GS 38.000 (33.481)	mem 71.854
Train: [46][20/1500]	BT 0.032 (1.445)	DT 0.000 (1.401)	loss 6.970 (6.892)	prob 3.797 (3.207)	GS 36.141 (33.818)	mem 71.875
Train: [46][30/1500]	BT 0.037 (1.036)	DT 0.000 (0.994)	loss 7.010 (6.950)	prob 2.902 (3.100)	GS 33.172 (33.317)	mem 71.878
Train: [46][40/1500]	BT 0.036 (0.849)	DT 0.000 (0.809)	loss 7.065 (6.981)	prob 2.801 (3.063)	GS 29.609 (32.598)	mem 71.899
Train: [46][50/1500]	BT 0.072 (0.690)	DT 0.006 (0.648)	loss 7.131 (7.005)	prob 2.985 (2.970)	GS 32.703 (32.644)	mem 71.902
Train: [46][60/1500]	BT 0.050 (0.666)	DT 0.002 (0.624)	loss 7.317 (7.036)	prob 2.621 (2.784)	GS 35.172 (31.914)	mem 71.913
Train: [46][70/1500]	BT 0.032 (0.579)	DT 0.000 (0.536)	loss 7.028 (7.053)	prob 2.581 (2.770)	GS 36.797 (32.386)	mem 71.916
Train: [46][80/1500]	BT 0.064 (0.512)	DT 0.008 (0.469)	loss 7.445 (7.050)	prob 1.792 (2.715)	GS 35.359 (32.263)	mem 71.915
Train: [46][90/1500]	BT 0.050 (0.523)	DT 0.000 (0.479)	loss 7.338 (7.057)	prob 3.139 (2.676)	GS 35.453 (32.196)	mem 71.923
Train: [46][100/1500]	BT 0.060 (0.477)	DT 0.013 (0.432)	loss 7.100 (7.072)	prob 1.979 (2.599)	GS 32.453 (31.999)	mem 71.922
Train: [46][110/1500]	BT 0.032 (0.499)	DT 0.001 (0.454)	loss 7.661 (7.217)	prob 1.853 (2.016)	GS 33.078 (33.081)	mem 71.935
Train: [46][120/1500]	BT 0.036 (0.461)	DT 0.001 (0.416)	loss 7.442 (7.193)	prob 1.930 (2.121)	GS 30.281 (33.091)	mem 71.938
Train: [46][130/1500]	BT 0.037 (0.428)	DT 0.001 (0.385)	loss 7.043 (7.167)	prob 1.682 (2.134)	GS 33.203 (33.205)	mem 71.940
Train: [46][140/1500]	BT 0.037 (0.422)	DT 0.000 (0.379)	loss 6.771 (7.170)	prob 1.935 (2.044)	GS 31.953 (32.914)	mem 71.943
Train: [46][150/1500]	BT 0.038 (0.397)	DT 0.000 (0.354)	loss 7.709 (7.191)	prob 0.767 (1.999)	GS 31.797 (32.936)	mem 71.943
Train: [46][160/1500]	BT 0.037 (0.405)	DT 0.001 (0.363)	loss 7.319 (7.354)	prob 1.830 (1.626)	GS 33.703 (32.491)	mem 71.946
Train: [46][170/1500]	BT 0.037 (0.384)	DT 0.000 (0.342)	loss 7.267 (7.349)	prob 2.513 (1.703)	GS 29.359 (32.159)	mem 71.948
Train: [46][180/1500]	BT 0.037 (0.379)	DT 0.000 (0.338)	loss 7.603 (7.353)	prob 1.723 (1.856)	GS 34.484 (32.373)	mem 71.950
Train: [46][190/1500]	BT 0.037 (0.361)	DT 0.000 (0.320)	loss 7.467 (7.321)	prob 1.630 (1.859)	GS 34.469 (32.110)	mem 71.950
Train: [46][200/1500]	BT 0.037 (0.345)	DT 0.001 (0.304)	loss 7.125 (7.302)	prob 1.716 (1.837)	GS 34.281 (32.211)	mem 71.950
Train: [46][210/1500]	BT 0.027 (0.344)	DT 0.000 (0.304)	loss 7.669 (7.350)	prob 0.725 (1.573)	GS 34.438 (32.372)	mem 71.955
Train: [46][220/1500]	BT 0.047 (0.337)	DT 0.001 (0.297)	loss 7.487 (7.388)	prob 2.070 (1.662)	GS 32.641 (32.316)	mem 71.988
Train: [46][230/1500]	BT 0.029 (0.337)	DT 0.000 (0.297)	loss 7.163 (7.415)	prob 2.761 (1.671)	GS 30.734 (32.564)	mem 71.989
Train: [46][240/1500]	BT 0.039 (0.326)	DT 0.000 (0.286)	loss 7.266 (7.403)	prob 2.348 (1.738)	GS 38.203 (32.944)	mem 71.989
Train: [46][250/1500]	BT 0.039 (0.314)	DT 0.001 (0.274)	loss 7.748 (7.425)	prob 2.290 (1.759)	GS 34.484 (33.069)	mem 71.989
Train: [46][260/1500]	BT 0.039 (0.323)	DT 0.001 (0.283)	loss 7.533 (7.447)	prob 2.543 (1.617)	GS 29.422 (32.722)	mem 71.991
Train: [46][270/1500]	BT 0.067 (0.314)	DT 0.003 (0.274)	loss 7.035 (7.501)	prob 3.340 (1.716)	GS 32.125 (32.063)	mem 71.994
Train: [46][280/1500]	BT 0.028 (0.328)	DT 0.000 (0.288)	loss 7.682 (7.564)	prob 3.010 (1.945)	GS 36.312 (32.237)	mem 71.995
Train: [46][290/1500]	BT 0.031 (0.318)	DT 0.000 (0.278)	loss 7.733 (7.590)	prob 2.608 (1.918)	GS 33.344 (32.604)	mem 71.996
Train: [46][300/1500]	BT 0.075 (0.331)	DT 0.006 (0.291)	loss 7.339 (7.598)	prob 2.222 (1.955)	GS 32.703 (32.706)	mem 71.999
Train: [46][310/1500]	BT 0.028 (0.352)	DT 0.000 (0.312)	loss 7.870 (7.760)	prob 2.957 (2.145)	GS 35.375 (32.877)	mem 72.001
Train: [46][320/1500]	BT 0.034 (0.342)	DT 0.000 (0.303)	loss 7.471 (7.628)	prob 2.530 (2.484)	GS 32.297 (32.045)	mem 72.001
Train: [46][330/1500]	BT 0.038 (0.341)	DT 0.001 (0.302)	loss 8.219 (7.660)	prob 2.944 (2.402)	GS 33.906 (32.673)	mem 72.001
Train: [46][340/1500]	BT 0.090 (0.332)	DT 0.004 (0.293)	loss 7.755 (7.642)	prob 1.610 (2.396)	GS 32.531 (32.791)	mem 72.002
Train: [46][350/1500]	BT 0.038 (0.333)	DT 0.001 (0.293)	loss 7.897 (7.656)	prob 2.803 (2.372)	GS 38.234 (32.741)	mem 72.004
Train: [46][360/1500]	BT 0.039 (0.325)	DT 0.001 (0.285)	loss 7.768 (7.610)	prob 2.359 (2.334)	GS 31.969 (32.314)	mem 72.004
Train: [46][370/1500]	BT 0.052 (0.318)	DT 0.002 (0.278)	loss 7.541 (7.671)	prob 2.852 (2.343)	GS 35.062 (32.820)	mem 72.005
Train: [46][380/1500]	BT 0.038 (0.322)	DT 0.001 (0.282)	loss 7.695 (7.676)	prob 3.655 (2.442)	GS 36.219 (32.915)	mem 72.009
Train: [46][390/1500]	BT 0.039 (0.314)	DT 0.001 (0.275)	loss 7.424 (7.671)	prob 2.660 (2.606)	GS 38.750 (33.133)	mem 72.009
Train: [46][400/1500]	BT 0.049 (0.319)	DT 0.011 (0.279)	loss 7.454 (7.703)	prob 2.818 (2.595)	GS 34.438 (33.329)	mem 72.010
Train: [46][410/1500]	BT 0.039 (0.312)	DT 0.001 (0.272)	loss 7.887 (7.610)	prob 3.110 (3.027)	GS 35.266 (33.164)	mem 72.011
Train: [46][420/1500]	BT 0.036 (0.315)	DT 0.000 (0.275)	loss 7.737 (7.698)	prob 3.663 (2.904)	GS 30.031 (32.848)	mem 72.012
Train: [46][430/1500]	BT 0.048 (0.309)	DT 0.008 (0.269)	loss 7.673 (7.680)	prob 3.453 (2.907)	GS 31.031 (32.532)	mem 72.013
Train: [46][440/1500]	BT 0.060 (0.303)	DT 0.001 (0.263)	loss 8.026 (7.685)	prob 2.994 (3.013)	GS 33.672 (32.952)	mem 72.013
Train: [46][450/1500]	BT 0.035 (0.311)	DT 0.000 (0.271)	loss 7.839 (7.692)	prob 3.187 (2.981)	GS 31.984 (33.191)	mem 72.011
Train: [46][460/1500]	BT 0.037 (0.305)	DT 0.001 (0.265)	loss 7.575 (7.645)	prob 3.428 (3.326)	GS 35.281 (33.214)	mem 72.011
Train: [46][470/1500]	BT 0.036 (0.306)	DT 0.000 (0.266)	loss 7.856 (7.690)	prob 3.830 (3.360)	GS 31.359 (32.262)	mem 72.020
Train: [46][480/1500]	BT 0.038 (0.300)	DT 0.001 (0.260)	loss 8.000 (7.695)	prob 3.152 (3.228)	GS 33.844 (32.446)	mem 72.020
Train: [46][490/1500]	BT 0.037 (0.295)	DT 0.001 (0.255)	loss 7.418 (7.648)	prob 3.776 (3.330)	GS 33.125 (32.029)	mem 72.021
Train: [46][500/1500]	BT 0.033 (0.300)	DT 0.000 (0.261)	loss 7.256 (7.660)	prob 4.091 (3.228)	GS 31.531 (32.100)	mem 71.998
Train: [46][510/1500]	BT 0.060 (0.295)	DT 0.014 (0.256)	loss 7.407 (7.631)	prob 3.548 (3.276)	GS 32.109 (33.528)	mem 71.997
Train: [46][520/1500]	BT 0.267 (0.303)	DT 0.230 (0.263)	loss 7.568 (7.638)	prob 2.896 (3.316)	GS 34.469 (32.794)	mem 71.930
Train: [46][530/1500]	BT 0.037 (0.298)	DT 0.000 (0.259)	loss 7.258 (7.587)	prob 3.517 (3.199)	GS 32.562 (32.677)	mem 71.931
Train: [46][540/1500]	BT 0.039 (0.300)	DT 0.001 (0.260)	loss 7.534 (7.567)	prob 2.871 (3.126)	GS 34.250 (33.101)	mem 71.930
Train: [46][550/1500]	BT 0.037 (0.296)	DT 0.001 (0.256)	loss 7.356 (7.552)	prob 3.430 (3.096)	GS 34.844 (33.009)	mem 71.931
Train: [46][560/1500]	BT 0.045 (0.291)	DT 0.008 (0.252)	loss 7.536 (7.616)	prob 3.894 (3.528)	GS 34.594 (31.661)	mem 71.931
Train: [46][570/1500]	BT 0.037 (0.293)	DT 0.001 (0.254)	loss 7.934 (7.542)	prob 3.047 (3.514)	GS 35.891 (32.116)	mem 72.028
Train: [46][580/1500]	BT 0.038 (0.289)	DT 0.001 (0.249)	loss 7.300 (7.538)	prob 3.576 (3.412)	GS 29.859 (32.588)	mem 72.126
Train: [46][590/1500]	BT 0.039 (0.290)	DT 0.000 (0.250)	loss 7.759 (7.510)	prob 3.548 (3.466)	GS 37.375 (32.448)	mem 72.418
Train: [46][600/1500]	BT 0.564 (0.286)	DT 0.520 (0.247)	loss 7.895 (7.507)	prob 3.910 (3.436)	GS 34.797 (32.511)	mem 72.516
Train: [46][610/1500]	BT 0.037 (0.282)	DT 0.001 (0.243)	loss 7.168 (7.348)	prob 3.180 (3.533)	GS 31.703 (31.570)	mem 72.617
Train: [46][620/1500]	BT 0.038 (0.289)	DT 0.000 (0.249)	loss 6.949 (7.360)	prob 4.230 (3.519)	GS 34.094 (31.701)	mem 72.959
Train: [46][630/1500]	BT 0.037 (0.285)	DT 0.000 (0.246)	loss 7.800 (7.407)	prob 2.700 (3.318)	GS 36.062 (33.099)	mem 73.006
Train: [46][640/1500]	BT 0.038 (0.288)	DT 0.000 (0.249)	loss 7.513 (7.419)	prob 4.299 (3.348)	GS 37.484 (32.841)	mem 73.126
Train: [46][650/1500]	BT 0.038 (0.284)	DT 0.000 (0.245)	loss 7.586 (7.428)	prob 2.724 (3.343)	GS 34.031 (32.819)	mem 73.126
Train: [46][660/1500]	BT 0.052 (0.284)	DT 0.014 (0.245)	loss 7.449 (7.309)	prob 3.111 (3.414)	GS 33.375 (31.486)	mem 73.128
Train: [46][670/1500]	BT 0.030 (0.289)	DT 0.000 (0.249)	loss 7.181 (7.376)	prob 3.983 (3.346)	GS 31.422 (32.444)	mem 73.115
Train: [46][680/1500]	BT 0.035 (0.285)	DT 0.001 (0.245)	loss 7.413 (7.372)	prob 3.722 (3.334)	GS 32.562 (32.071)	mem 73.117
Train: [46][690/1500]	BT 0.023 (0.295)	DT 0.000 (0.256)	loss 7.062 (7.382)	prob 3.900 (3.350)	GS 32.297 (32.395)	mem 73.116
Train: [46][700/1500]	BT 0.027 (0.291)	DT 0.000 (0.252)	loss 7.328 (7.394)	prob 3.095 (3.316)	GS 36.078 (32.340)	mem 73.118
Train: [46][710/1500]	BT 0.030 (0.288)	DT 0.001 (0.249)	loss 7.571 (7.440)	prob 3.681 (3.230)	GS 35.656 (32.263)	mem 73.117
Train: [46][720/1500]	BT 0.029 (0.289)	DT 0.001 (0.250)	loss 7.192 (7.384)	prob 3.089 (3.246)	GS 29.219 (31.585)	mem 73.119
Train: [46][730/1500]	BT 0.025 (0.286)	DT 0.000 (0.247)	loss 7.613 (7.376)	prob 2.939 (3.212)	GS 36.469 (31.871)	mem 73.122
Train: [46][740/1500]	BT 0.040 (0.286)	DT 0.001 (0.247)	loss 7.509 (7.347)	prob 3.775 (3.271)	GS 36.000 (32.086)	mem 73.121
Train: [46][750/1500]	BT 0.040 (0.283)	DT 0.001 (0.244)	loss 7.651 (7.354)	prob 2.988 (3.286)	GS 35.750 (32.349)	mem 73.122
Train: [46][760/1500]	BT 0.028 (0.290)	DT 0.000 (0.251)	loss 7.075 (7.313)	prob 4.197 (3.371)	GS 35.516 (33.475)	mem 73.118
Train: [46][770/1500]	BT 0.039 (0.286)	DT 0.001 (0.247)	loss 7.446 (7.270)	prob 3.546 (3.413)	GS 32.984 (32.432)	mem 73.119
Train: [46][780/1500]	BT 0.039 (0.283)	DT 0.001 (0.244)	loss 7.157 (7.233)	prob 3.607 (3.452)	GS 33.625 (31.951)	mem 73.120
Train: [46][790/1500]	BT 0.030 (0.285)	DT 0.000 (0.246)	loss 7.060 (7.256)	prob 3.602 (3.339)	GS 35.562 (31.788)	mem 73.122
Train: [46][800/1500]	BT 0.037 (0.282)	DT 0.000 (0.243)	loss 7.279 (7.265)	prob 3.456 (3.308)	GS 32.531 (31.933)	mem 73.134
Train: [46][810/1500]	BT 0.047 (0.285)	DT 0.016 (0.246)	loss 7.318 (7.241)	prob 2.946 (3.061)	GS 32.672 (32.737)	mem 73.144
Train: [46][820/1500]	BT 0.064 (0.282)	DT 0.002 (0.243)	loss 7.203 (7.217)	prob 3.380 (2.918)	GS 38.219 (32.764)	mem 73.144
Train: [46][830/1500]	BT 0.084 (0.289)	DT 0.007 (0.249)	loss 7.601 (7.252)	prob 2.094 (2.873)	GS 31.828 (32.961)	mem 73.144
Train: [46][840/1500]	BT 0.038 (0.286)	DT 0.000 (0.246)	loss 7.057 (7.241)	prob 3.561 (2.961)	GS 35.047 (32.927)	mem 73.145
Train: [46][850/1500]	BT 0.036 (0.283)	DT 0.000 (0.244)	loss 6.935 (7.242)	prob 3.852 (3.023)	GS 30.594 (32.987)	mem 73.146
Train: [46][860/1500]	BT 0.034 (0.289)	DT 0.001 (0.250)	loss 7.305 (7.259)	prob 2.858 (3.062)	GS 31.406 (33.525)	mem 73.158
Train: [46][870/1500]	BT 0.101 (0.287)	DT 0.017 (0.247)	loss 7.034 (7.233)	prob 2.970 (3.127)	GS 32.250 (33.691)	mem 73.158
Train: [46][880/1500]	BT 0.078 (0.294)	DT 0.011 (0.253)	loss 7.484 (7.260)	prob 3.393 (3.070)	GS 39.094 (34.105)	mem 73.149
Train: [46][890/1500]	BT 0.030 (0.296)	DT 0.000 (0.256)	loss 7.204 (7.269)	prob 3.211 (3.123)	GS 33.031 (34.084)	mem 73.146
Train: [46][900/1500]	BT 0.037 (0.293)	DT 0.001 (0.253)	loss 6.887 (7.267)	prob 3.998 (3.120)	GS 31.094 (33.725)	mem 73.147
Train: [46][910/1500]	BT 0.032 (0.292)	DT 0.001 (0.252)	loss 6.979 (7.115)	prob 4.099 (3.292)	GS 31.547 (32.195)	mem 73.148
Train: [46][920/1500]	BT 0.029 (0.291)	DT 0.000 (0.251)	loss 7.558 (7.125)	prob 3.384 (3.232)	GS 31.984 (32.163)	mem 73.149
Train: [46][930/1500]	BT 0.068 (0.291)	DT 0.010 (0.251)	loss 7.424 (7.141)	prob 3.136 (3.248)	GS 35.812 (32.749)	mem 73.149
Train: [46][940/1500]	BT 0.035 (0.293)	DT 0.001 (0.253)	loss 7.104 (7.131)	prob 3.552 (3.215)	GS 32.953 (33.115)	mem 73.152
Train: [46][950/1500]	BT 0.037 (0.290)	DT 0.001 (0.250)	loss 6.890 (7.099)	prob 3.275 (3.230)	GS 31.688 (32.832)	mem 73.152
Train: [46][960/1500]	BT 0.037 (0.287)	DT 0.001 (0.248)	loss 7.248 (7.071)	prob 2.752 (3.246)	GS 34.734 (32.692)	mem 73.151
Train: [46][970/1500]	BT 0.037 (0.289)	DT 0.001 (0.249)	loss 7.278 (7.046)	prob 2.940 (3.123)	GS 32.219 (32.652)	mem 73.155
Train: [46][980/1500]	BT 0.037 (0.287)	DT 0.000 (0.247)	loss 6.862 (7.012)	prob 3.112 (3.089)	GS 33.516 (32.808)	mem 73.155
Train: [46][990/1500]	BT 0.022 (0.294)	DT 0.000 (0.254)	loss 6.627 (7.000)	prob 3.522 (3.046)	GS 32.047 (32.693)	mem 73.155
Train: [46][1000/1500]	BT 0.024 (0.291)	DT 0.000 (0.252)	loss 6.676 (6.988)	prob 3.465 (3.142)	GS 33.547 (32.886)	mem 73.156
Train: [46][1010/1500]	BT 0.042 (0.292)	DT 0.001 (0.252)	loss 6.856 (6.978)	prob 3.755 (3.205)	GS 33.797 (33.667)	mem 73.159
Train: [46][1020/1500]	BT 0.038 (0.289)	DT 0.001 (0.250)	loss 6.956 (7.029)	prob 3.054 (3.260)	GS 36.406 (32.646)	mem 73.160
Train: [46][1030/1500]	BT 0.038 (0.287)	DT 0.001 (0.247)	loss 6.916 (7.034)	prob 4.107 (3.302)	GS 36.141 (32.646)	mem 73.160
Train: [46][1040/1500]	BT 0.037 (0.287)	DT 0.001 (0.248)	loss 7.108 (7.059)	prob 3.543 (3.267)	GS 33.062 (32.528)	mem 73.159
Train: [46][1050/1500]	BT 0.037 (0.285)	DT 0.000 (0.245)	loss 7.042 (7.054)	prob 3.401 (3.282)	GS 34.641 (32.635)	mem 73.161
Train: [46][1060/1500]	BT 0.030 (0.287)	DT 0.001 (0.247)	loss 6.946 (7.003)	prob 3.021 (3.081)	GS 33.375 (32.477)	mem 73.162
Train: [46][1070/1500]	BT 0.038 (0.284)	DT 0.000 (0.245)	loss 7.015 (7.051)	prob 2.604 (3.106)	GS 37.000 (32.880)	mem 73.164
Train: [46][1080/1500]	BT 0.038 (0.282)	DT 0.000 (0.243)	loss 6.973 (7.069)	prob 3.321 (3.188)	GS 31.984 (32.568)	mem 73.164
Train: [46][1090/1500]	BT 0.029 (0.283)	DT 0.000 (0.244)	loss 7.099 (7.068)	prob 3.159 (3.169)	GS 31.078 (32.457)	mem 73.165
Train: [46][1100/1500]	BT 0.038 (0.281)	DT 0.001 (0.242)	loss 6.775 (7.064)	prob 3.477 (3.166)	GS 35.312 (32.298)	mem 73.165
Train: [46][1110/1500]	BT 0.072 (0.283)	DT 0.011 (0.244)	loss 7.105 (7.046)	prob 3.276 (3.101)	GS 36.359 (33.131)	mem 73.167
Train: [46][1120/1500]	BT 0.056 (0.281)	DT 0.012 (0.242)	loss 7.017 (7.052)	prob 2.976 (3.228)	GS 36.844 (32.651)	mem 73.168
Train: [46][1130/1500]	BT 0.038 (0.283)	DT 0.001 (0.244)	loss 6.820 (7.055)	prob 3.195 (3.240)	GS 36.484 (32.730)	mem 73.172
Train: [46][1140/1500]	BT 0.038 (0.282)	DT 0.001 (0.242)	loss 7.150 (7.067)	prob 3.578 (3.191)	GS 30.844 (32.829)	mem 73.173
Train: [46][1150/1500]	BT 1.085 (0.281)	DT 1.048 (0.242)	loss 7.145 (7.078)	prob 2.730 (3.112)	GS 32.453 (33.063)	mem 73.173
Train: [46][1160/1500]	BT 0.072 (0.281)	DT 0.001 (0.241)	loss 7.128 (7.051)	prob 3.382 (2.856)	GS 31.859 (32.972)	mem 73.174
Train: [46][1170/1500]	BT 2.239 (0.281)	DT 2.202 (0.241)	loss 7.058 (7.082)	prob 3.083 (2.932)	GS 33.234 (32.627)	mem 73.174
Train: [46][1180/1500]	BT 0.037 (0.282)	DT 0.000 (0.242)	loss 6.833 (7.087)	prob 3.617 (2.875)	GS 31.375 (32.705)	mem 73.173
Train: [46][1190/1500]	BT 0.037 (0.280)	DT 0.001 (0.240)	loss 6.923 (7.079)	prob 3.303 (2.903)	GS 31.891 (32.855)	mem 73.176
Train: [46][1200/1500]	BT 0.056 (0.281)	DT 0.012 (0.242)	loss 6.974 (7.063)	prob 2.583 (2.908)	GS 33.766 (33.245)	mem 73.201
Train: [46][1210/1500]	BT 0.040 (0.280)	DT 0.001 (0.241)	loss 7.001 (6.960)	prob 3.089 (2.999)	GS 33.766 (33.973)	mem 73.200
Train: [46][1220/1500]	BT 0.039 (0.284)	DT 0.000 (0.244)	loss 6.994 (6.986)	prob 2.981 (3.017)	GS 35.219 (33.091)	mem 73.201
Train: [46][1230/1500]	BT 0.027 (0.283)	DT 0.000 (0.243)	loss 6.972 (6.984)	prob 3.105 (2.926)	GS 37.250 (33.038)	mem 73.201
Train: [46][1240/1500]	BT 0.059 (0.281)	DT 0.002 (0.241)	loss 7.145 (6.980)	prob 3.427 (2.906)	GS 36.625 (33.041)	mem 73.202
Train: [46][1250/1500]	BT 0.039 (0.283)	DT 0.001 (0.243)	loss 7.313 (6.991)	prob 2.817 (2.916)	GS 32.422 (33.084)	mem 73.203
Train: [46][1260/1500]	BT 0.068 (0.281)	DT 0.011 (0.241)	loss 7.034 (7.011)	prob 3.157 (2.963)	GS 34.281 (34.170)	mem 73.203
Train: [46][1270/1500]	BT 0.035 (0.286)	DT 0.005 (0.246)	loss 6.971 (7.020)	prob 2.622 (2.929)	GS 31.062 (34.048)	mem 73.204
Train: [46][1280/1500]	BT 0.031 (0.286)	DT 0.000 (0.246)	loss 6.857 (7.003)	prob 3.014 (3.057)	GS 34.703 (34.671)	mem 73.203
Train: [46][1290/1500]	BT 0.032 (0.284)	DT 0.000 (0.244)	loss 6.950 (6.976)	prob 3.208 (3.043)	GS 34.562 (33.909)	mem 73.204
Train: [46][1300/1500]	BT 0.031 (0.288)	DT 0.000 (0.248)	loss 6.885 (6.961)	prob 3.243 (3.089)	GS 35.516 (33.775)	mem 73.205
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [46][1310/1500]	BT 0.060 (0.286)	DT 0.006 (0.246)	loss 6.918 (6.927)	prob 3.025 (3.265)	GS 31.922 (33.017)	mem 73.204
Train: [46][1320/1500]	BT 0.037 (0.290)	DT 0.006 (0.251)	loss 6.966 (6.967)	prob 3.390 (3.140)	GS 34.125 (32.584)	mem 73.205
Train: [46][1330/1500]	BT 0.047 (0.289)	DT 0.004 (0.249)	loss 6.963 (6.954)	prob 3.267 (3.071)	GS 32.219 (32.951)	mem 73.206
Train: [46][1340/1500]	BT 0.029 (0.293)	DT 0.000 (0.253)	loss 7.000 (6.965)	prob 3.036 (3.177)	GS 33.109 (32.782)	mem 73.204
Train: [46][1350/1500]	BT 0.031 (0.291)	DT 0.000 (0.252)	loss 6.647 (6.947)	prob 3.483 (3.161)	GS 37.312 (33.042)	mem 73.204
Train: [46][1360/1500]	BT 0.053 (0.289)	DT 0.001 (0.250)	loss 6.891 (6.986)	prob 4.121 (3.092)	GS 33.578 (32.700)	mem 73.205
Train: [46][1370/1500]	BT 0.036 (0.290)	DT 0.000 (0.251)	loss 6.972 (6.939)	prob 3.127 (3.081)	GS 31.219 (32.359)	mem 73.206
Train: [46][1380/1500]	BT 0.038 (0.288)	DT 0.000 (0.249)	loss 7.415 (6.968)	prob 3.608 (3.011)	GS 30.875 (33.004)	mem 73.205
Train: [46][1390/1500]	BT 0.039 (0.289)	DT 0.001 (0.249)	loss 6.689 (6.949)	prob 2.400 (3.012)	GS 33.297 (32.987)	mem 73.205
Train: [46][1400/1500]	BT 0.039 (0.288)	DT 0.001 (0.248)	loss 6.913 (6.944)	prob 2.809 (2.932)	GS 36.562 (32.932)	mem 73.204
Train: [46][1410/1500]	BT 3.875 (0.289)	DT 3.817 (0.249)	loss 6.983 (6.875)	prob 2.711 (2.730)	GS 34.891 (32.667)	mem 73.206
Train: [46][1420/1500]	BT 0.031 (0.290)	DT 0.000 (0.251)	loss 6.952 (6.904)	prob 2.781 (2.955)	GS 31.141 (33.401)	mem 73.207
Train: [46][1430/1500]	BT 0.026 (0.288)	DT 0.000 (0.249)	loss 7.304 (6.920)	prob 2.789 (2.853)	GS 29.359 (33.090)	mem 73.209
Train: [46][1440/1500]	BT 0.024 (0.290)	DT 0.000 (0.250)	loss 6.863 (6.897)	prob 3.513 (2.919)	GS 34.141 (33.345)	mem 73.209
Train: [46][1450/1500]	BT 0.037 (0.288)	DT 0.000 (0.249)	loss 6.870 (6.905)	prob 2.190 (2.912)	GS 38.312 (33.048)	mem 73.213
Train: [46][1460/1500]	BT 0.038 (0.286)	DT 0.001 (0.247)	loss 6.924 (6.911)	prob 2.589 (2.820)	GS 29.484 (30.289)	mem 73.214
Train: [46][1470/1500]	BT 0.027 (0.286)	DT 0.000 (0.247)	loss 6.918 (6.874)	prob 2.965 (2.876)	GS 38.625 (31.370)	mem 72.236
Train: [46][1480/1500]	BT 0.034 (0.284)	DT 0.001 (0.245)	loss 6.873 (6.864)	prob 2.558 (2.777)	GS 33.203 (31.858)	mem 72.160
Train: [46][1490/1500]	BT 0.026 (0.284)	DT 0.000 (0.245)	loss 6.803 (6.873)	prob 2.763 (2.732)	GS 37.375 (32.391)	mem 8.131
Train: [46][1500/1500]	BT 0.033 (0.283)	DT 0.000 (0.244)	loss 7.038 (6.855)	prob 3.389 (2.761)	GS 38.562 (32.480)	mem 7.989
Train: [46][1510/1500]	BT 0.033 (0.281)	DT 0.001 (0.242)	loss 6.418 (6.637)	prob 1.888 (2.735)	GS 33.031 (31.109)	mem 8.010
epoch 46, total time 425.16
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [47][1/1500]	BT 22.609 (22.609)	DT 22.555 (22.555)	loss 6.555 (6.555)	prob 3.034 (3.034)	GS 29.984 (29.984)	mem 71.813
Train: [47][10/1500]	BT 0.035 (2.297)	DT 0.001 (2.263)	loss 6.762 (6.521)	prob 2.332 (2.271)	GS 35.734 (32.766)	mem 71.818
Train: [47][20/1500]	BT 0.038 (1.167)	DT 0.001 (1.132)	loss 6.657 (6.568)	prob 2.494 (2.341)	GS 36.156 (33.442)	mem 71.820
Train: [47][30/1500]	BT 0.033 (0.955)	DT 0.000 (0.919)	loss 6.595 (6.622)	prob 3.027 (2.295)	GS 27.188 (32.795)	mem 71.843
Train: [47][40/1500]	BT 0.033 (0.726)	DT 0.000 (0.690)	loss 6.779 (6.679)	prob 2.705 (2.333)	GS 34.562 (32.814)	mem 71.844
Train: [47][50/1500]	BT 0.066 (0.704)	DT 0.012 (0.665)	loss 6.759 (6.706)	prob 2.618 (2.317)	GS 33.016 (32.657)	mem 71.858
Train: [47][60/1500]	BT 0.038 (0.595)	DT 0.001 (0.555)	loss 6.754 (6.841)	prob 1.573 (2.470)	GS 35.469 (31.742)	mem 71.866
Train: [47][70/1500]	BT 0.039 (0.516)	DT 0.000 (0.476)	loss 6.665 (6.885)	prob 2.448 (2.353)	GS 39.141 (32.441)	mem 71.866
Train: [47][80/1500]	BT 0.038 (0.508)	DT 0.001 (0.469)	loss 7.184 (6.909)	prob 2.715 (2.263)	GS 34.594 (32.449)	mem 71.876
Train: [47][90/1500]	BT 0.039 (0.456)	DT 0.001 (0.417)	loss 7.027 (6.926)	prob 2.087 (2.157)	GS 32.844 (32.775)	mem 71.876
Train: [47][100/1500]	BT 0.039 (0.442)	DT 0.001 (0.402)	loss 6.923 (6.935)	prob 2.441 (2.118)	GS 32.359 (32.754)	mem 71.879
Train: [47][110/1500]	BT 0.040 (0.405)	DT 0.001 (0.366)	loss 6.883 (6.997)	prob 1.675 (1.787)	GS 32.062 (31.483)	mem 71.879
Train: [47][120/1500]	BT 0.039 (0.375)	DT 0.001 (0.336)	loss 7.133 (7.049)	prob 2.088 (1.757)	GS 29.875 (31.665)	mem 71.879
Train: [47][130/1500]	BT 0.036 (0.381)	DT 0.000 (0.342)	loss 7.247 (7.087)	prob 1.839 (1.664)	GS 33.844 (31.868)	mem 71.905
Train: [47][140/1500]	BT 0.056 (0.357)	DT 0.006 (0.318)	loss 7.445 (7.104)	prob 2.133 (1.649)	GS 34.531 (32.058)	mem 71.907
Train: [47][150/1500]	BT 0.037 (0.358)	DT 0.000 (0.319)	loss 7.393 (7.132)	prob 1.640 (1.679)	GS 32.406 (32.152)	mem 71.912
Train: [47][160/1500]	BT 0.037 (0.358)	DT 0.001 (0.320)	loss 7.693 (7.362)	prob 1.801 (1.593)	GS 33.781 (32.789)	mem 71.919
Train: [47][170/1500]	BT 0.037 (0.344)	DT 0.000 (0.305)	loss 7.371 (7.274)	prob 2.281 (1.907)	GS 38.766 (32.775)	mem 71.921
Train: [47][180/1500]	BT 0.037 (0.342)	DT 0.001 (0.304)	loss 7.931 (7.324)	prob 1.573 (1.928)	GS 35.859 (32.260)	mem 71.924
Train: [47][190/1500]	BT 0.036 (0.337)	DT 0.000 (0.299)	loss 7.459 (7.337)	prob 2.269 (1.891)	GS 35.906 (32.560)	mem 71.928
Train: [47][200/1500]	BT 0.038 (0.329)	DT 0.000 (0.291)	loss 7.552 (7.373)	prob 2.583 (1.935)	GS 31.219 (32.489)	mem 71.929
Train: [47][210/1500]	BT 0.038 (0.321)	DT 0.001 (0.283)	loss 7.415 (7.418)	prob 2.531 (2.451)	GS 32.969 (32.803)	mem 71.931
Train: [47][220/1500]	BT 0.028 (0.308)	DT 0.000 (0.270)	loss 7.594 (7.473)	prob 2.887 (2.560)	GS 35.875 (32.559)	mem 71.932
Train: [47][230/1500]	BT 0.037 (0.302)	DT 0.000 (0.264)	loss 7.174 (7.485)	prob 3.093 (2.602)	GS 34.469 (32.416)	mem 71.932
Train: [47][240/1500]	BT 0.038 (0.298)	DT 0.001 (0.260)	loss 8.303 (7.485)	prob 1.919 (2.501)	GS 36.531 (32.651)	mem 71.934
Train: [47][250/1500]	BT 0.066 (0.297)	DT 0.031 (0.259)	loss 7.273 (7.462)	prob 2.570 (2.464)	GS 34.391 (32.750)	mem 71.938
Train: [47][260/1500]	BT 0.037 (0.294)	DT 0.001 (0.256)	loss 8.180 (7.626)	prob 3.052 (2.641)	GS 31.812 (32.689)	mem 71.938
Train: [47][270/1500]	BT 0.037 (0.297)	DT 0.001 (0.259)	loss 8.139 (7.591)	prob 2.968 (2.832)	GS 33.312 (32.943)	mem 71.941
Train: [47][280/1500]	BT 0.037 (0.291)	DT 0.000 (0.253)	loss 7.491 (7.537)	prob 3.506 (2.874)	GS 31.562 (32.679)	mem 71.943
Train: [47][290/1500]	BT 0.037 (0.287)	DT 0.001 (0.249)	loss 7.694 (7.498)	prob 3.344 (2.961)	GS 33.000 (32.686)	mem 71.942
Train: [47][300/1500]	BT 0.037 (0.286)	DT 0.001 (0.248)	loss 7.744 (7.522)	prob 2.906 (2.999)	GS 29.828 (32.763)	mem 71.947
Train: [47][310/1500]	BT 0.037 (0.283)	DT 0.001 (0.245)	loss 7.456 (7.442)	prob 3.586 (3.141)	GS 36.078 (32.441)	mem 71.947
Train: [47][320/1500]	BT 1.294 (0.281)	DT 1.257 (0.243)	loss 7.418 (7.490)	prob 3.682 (3.178)	GS 28.406 (31.937)	mem 71.949
Train: [47][330/1500]	BT 0.038 (0.276)	DT 0.000 (0.238)	loss 7.372 (7.431)	prob 2.445 (3.208)	GS 32.266 (32.074)	mem 71.952
Train: [47][340/1500]	BT 0.038 (0.275)	DT 0.000 (0.237)	loss 7.269 (7.421)	prob 3.993 (3.272)	GS 31.125 (31.974)	mem 71.954
Train: [47][350/1500]	BT 3.573 (0.279)	DT 3.518 (0.241)	loss 7.069 (7.407)	prob 3.362 (3.299)	GS 29.953 (31.949)	mem 71.957
Train: [47][360/1500]	BT 0.033 (0.279)	DT 0.001 (0.241)	loss 7.383 (7.526)	prob 4.194 (2.998)	GS 28.844 (33.044)	mem 71.958
Train: [47][370/1500]	BT 0.035 (0.278)	DT 0.000 (0.240)	loss 8.069 (7.567)	prob 2.525 (3.079)	GS 33.125 (33.281)	mem 71.961
Train: [47][380/1500]	BT 0.071 (0.274)	DT 0.006 (0.236)	loss 8.044 (7.593)	prob 3.159 (3.064)	GS 33.484 (33.194)	mem 71.960
Train: [47][390/1500]	BT 0.035 (0.276)	DT 0.000 (0.238)	loss 7.323 (7.504)	prob 3.886 (3.219)	GS 32.938 (32.893)	mem 71.964
Train: [47][400/1500]	BT 0.069 (0.275)	DT 0.001 (0.236)	loss 7.227 (7.475)	prob 4.134 (3.287)	GS 33.859 (32.703)	mem 71.965
Train: [47][410/1500]	BT 0.039 (0.289)	DT 0.001 (0.250)	loss 7.680 (7.348)	prob 2.937 (3.216)	GS 30.719 (34.525)	mem 71.967
Train: [47][420/1500]	BT 0.038 (0.283)	DT 0.001 (0.244)	loss 7.589 (7.396)	prob 3.622 (3.312)	GS 36.719 (33.456)	mem 71.967
Train: [47][430/1500]	BT 0.036 (0.287)	DT 0.000 (0.249)	loss 7.536 (7.392)	prob 3.433 (3.300)	GS 34.625 (33.067)	mem 71.973
Train: [47][440/1500]	BT 0.053 (0.281)	DT 0.014 (0.243)	loss 7.556 (7.366)	prob 3.627 (3.351)	GS 35.125 (32.696)	mem 71.973
Train: [47][450/1500]	BT 0.066 (0.276)	DT 0.005 (0.238)	loss 7.306 (7.363)	prob 3.527 (3.279)	GS 35.969 (33.079)	mem 71.974
Train: [47][460/1500]	BT 0.037 (0.280)	DT 0.001 (0.241)	loss 7.826 (7.531)	prob 3.115 (3.079)	GS 35.297 (32.711)	mem 71.979
Train: [47][470/1500]	BT 0.037 (0.274)	DT 0.000 (0.236)	loss 7.163 (7.427)	prob 3.743 (3.264)	GS 35.812 (33.173)	mem 71.991
Train: [47][480/1500]	BT 0.040 (0.283)	DT 0.001 (0.245)	loss 8.144 (7.398)	prob 3.755 (3.429)	GS 33.922 (32.939)	mem 72.009
Train: [47][490/1500]	BT 0.038 (0.281)	DT 0.001 (0.243)	loss 7.039 (7.378)	prob 3.440 (3.366)	GS 32.016 (32.563)	mem 72.011
Train: [47][500/1500]	BT 0.039 (0.279)	DT 0.001 (0.240)	loss 7.024 (7.342)	prob 3.379 (3.364)	GS 33.562 (32.394)	mem 72.010
Train: [47][510/1500]	BT 0.039 (0.274)	DT 0.001 (0.236)	loss 7.517 (7.321)	prob 3.033 (2.919)	GS 32.469 (32.633)	mem 72.011
Train: [47][520/1500]	BT 0.028 (0.277)	DT 0.000 (0.239)	loss 7.221 (7.287)	prob 3.200 (3.045)	GS 34.078 (32.544)	mem 72.012
Train: [47][530/1500]	BT 0.038 (0.273)	DT 0.001 (0.234)	loss 7.281 (7.275)	prob 3.625 (3.101)	GS 32.422 (32.686)	mem 72.013
Train: [47][540/1500]	BT 0.038 (0.275)	DT 0.001 (0.237)	loss 7.543 (7.310)	prob 2.792 (3.159)	GS 36.891 (32.509)	mem 72.014
Train: [47][550/1500]	BT 0.039 (0.272)	DT 0.001 (0.234)	loss 7.265 (7.316)	prob 3.212 (3.124)	GS 31.094 (32.436)	mem 72.014
Train: [47][560/1500]	BT 0.039 (0.268)	DT 0.001 (0.230)	loss 7.417 (7.318)	prob 3.234 (2.938)	GS 33.781 (33.319)	mem 72.014
Train: [47][570/1500]	BT 0.038 (0.270)	DT 0.001 (0.232)	loss 7.375 (7.289)	prob 2.755 (2.936)	GS 35.078 (33.127)	mem 72.016
Train: [47][580/1500]	BT 0.039 (0.266)	DT 0.001 (0.228)	loss 7.304 (7.275)	prob 3.217 (3.031)	GS 36.297 (32.806)	mem 72.016
Train: [47][590/1500]	BT 0.041 (0.291)	DT 0.013 (0.252)	loss 7.372 (7.299)	prob 3.268 (3.004)	GS 35.328 (33.479)	mem 72.015
Train: [47][600/1500]	BT 0.033 (0.286)	DT 0.000 (0.248)	loss 7.243 (7.282)	prob 3.909 (3.082)	GS 34.250 (33.499)	mem 72.019
Train: [47][610/1500]	BT 0.040 (0.282)	DT 0.001 (0.244)	loss 7.366 (7.237)	prob 3.701 (3.223)	GS 30.031 (33.758)	mem 72.020
Train: [47][620/1500]	BT 0.032 (0.299)	DT 0.000 (0.261)	loss 7.424 (7.198)	prob 2.799 (3.164)	GS 37.219 (34.528)	mem 72.118
Train: [47][630/1500]	BT 0.031 (0.295)	DT 0.000 (0.257)	loss 7.561 (7.209)	prob 3.048 (3.064)	GS 30.906 (34.312)	mem 72.117
Train: [47][640/1500]	BT 0.028 (0.297)	DT 0.000 (0.259)	loss 7.183 (7.210)	prob 3.065 (3.086)	GS 34.844 (34.218)	mem 72.167
Train: [47][650/1500]	BT 0.039 (0.293)	DT 0.001 (0.255)	loss 7.602 (7.219)	prob 2.737 (3.097)	GS 39.922 (34.274)	mem 72.216
Train: [47][660/1500]	BT 0.039 (0.289)	DT 0.001 (0.252)	loss 7.171 (7.199)	prob 3.869 (3.416)	GS 33.828 (33.184)	mem 72.215
Train: [47][670/1500]	BT 0.034 (0.290)	DT 0.001 (0.253)	loss 7.321 (7.177)	prob 3.557 (3.383)	GS 32.484 (33.272)	mem 72.509
Train: [47][680/1500]	BT 0.034 (0.287)	DT 0.001 (0.249)	loss 7.204 (7.186)	prob 2.513 (3.287)	GS 36.312 (33.085)	mem 72.508
Train: [47][690/1500]	BT 0.045 (0.299)	DT 0.003 (0.261)	loss 7.446 (7.184)	prob 2.824 (3.257)	GS 32.938 (32.899)	mem 73.142
Train: [47][700/1500]	BT 0.038 (0.295)	DT 0.001 (0.257)	loss 7.053 (7.167)	prob 3.569 (3.301)	GS 34.562 (33.003)	mem 73.144
Train: [47][710/1500]	BT 0.038 (0.294)	DT 0.001 (0.256)	loss 7.022 (7.208)	prob 3.841 (3.482)	GS 34.797 (33.703)	mem 73.190
Train: [47][720/1500]	BT 0.027 (0.293)	DT 0.000 (0.256)	loss 7.214 (7.177)	prob 3.368 (3.410)	GS 32.391 (33.093)	mem 73.198
Train: [47][730/1500]	BT 0.037 (0.292)	DT 0.000 (0.254)	loss 7.103 (7.153)	prob 3.309 (3.277)	GS 36.859 (32.806)	mem 73.200
Train: [47][740/1500]	BT 0.028 (0.292)	DT 0.000 (0.254)	loss 7.374 (7.123)	prob 2.826 (3.257)	GS 36.188 (32.574)	mem 73.209
Train: [47][750/1500]	BT 0.038 (0.289)	DT 0.000 (0.251)	loss 7.104 (7.115)	prob 2.968 (3.224)	GS 36.016 (32.603)	mem 73.210
Train: [47][760/1500]	BT 0.037 (0.285)	DT 0.001 (0.248)	loss 7.080 (7.025)	prob 3.042 (3.079)	GS 33.922 (32.152)	mem 73.220
Train: [47][770/1500]	BT 0.037 (0.288)	DT 0.000 (0.250)	loss 7.035 (7.051)	prob 2.896 (3.148)	GS 35.922 (32.836)	mem 73.109
Train: [47][780/1500]	BT 0.038 (0.285)	DT 0.001 (0.247)	loss 7.098 (7.036)	prob 3.396 (3.124)	GS 36.359 (32.645)	mem 73.110
Train: [47][790/1500]	BT 0.030 (0.287)	DT 0.000 (0.250)	loss 6.983 (7.040)	prob 2.587 (3.132)	GS 33.656 (32.307)	mem 73.109
Train: [47][800/1500]	BT 0.034 (0.284)	DT 0.000 (0.246)	loss 6.835 (7.040)	prob 3.415 (3.137)	GS 34.094 (32.309)	mem 73.109
Train: [47][810/1500]	BT 0.034 (0.285)	DT 0.001 (0.248)	loss 6.860 (6.970)	prob 3.441 (3.182)	GS 31.734 (32.136)	mem 73.113
Train: [47][820/1500]	BT 0.037 (0.282)	DT 0.000 (0.245)	loss 7.127 (6.993)	prob 2.996 (3.206)	GS 34.781 (32.082)	mem 73.114
Train: [47][830/1500]	BT 0.037 (0.279)	DT 0.001 (0.242)	loss 6.944 (6.990)	prob 3.200 (3.027)	GS 35.047 (32.151)	mem 73.113
Train: [47][840/1500]	BT 0.027 (0.281)	DT 0.000 (0.243)	loss 6.799 (6.991)	prob 3.236 (3.063)	GS 32.203 (32.119)	mem 73.114
Train: [47][850/1500]	BT 0.065 (0.281)	DT 0.006 (0.244)	loss 7.107 (7.003)	prob 2.929 (3.046)	GS 28.234 (32.102)	mem 73.117
Train: [47][860/1500]	BT 0.037 (0.282)	DT 0.001 (0.245)	loss 6.863 (6.980)	prob 3.099 (2.845)	GS 32.422 (32.444)	mem 73.139
Train: [47][870/1500]	BT 0.038 (0.279)	DT 0.001 (0.242)	loss 7.077 (6.984)	prob 2.752 (2.898)	GS 34.141 (32.725)	mem 73.139
Train: [47][880/1500]	BT 0.038 (0.277)	DT 0.000 (0.240)	loss 7.117 (7.001)	prob 3.109 (3.032)	GS 35.047 (32.809)	mem 73.139
Train: [47][890/1500]	BT 0.038 (0.278)	DT 0.001 (0.240)	loss 6.798 (6.992)	prob 3.303 (3.077)	GS 34.203 (32.730)	mem 73.139
Train: [47][900/1500]	BT 0.041 (0.275)	DT 0.001 (0.238)	loss 6.977 (6.996)	prob 3.411 (3.091)	GS 34.938 (32.979)	mem 73.139
Train: [47][910/1500]	BT 0.039 (0.277)	DT 0.001 (0.239)	loss 7.108 (7.001)	prob 2.918 (3.132)	GS 36.234 (32.530)	mem 73.126
Train: [47][920/1500]	BT 0.038 (0.276)	DT 0.001 (0.239)	loss 6.963 (6.972)	prob 4.160 (3.183)	GS 34.625 (32.598)	mem 73.125
Train: [47][930/1500]	BT 0.029 (0.275)	DT 0.000 (0.238)	loss 6.792 (6.965)	prob 3.530 (3.177)	GS 34.688 (32.567)	mem 73.126
Train: [47][940/1500]	BT 0.027 (0.279)	DT 0.001 (0.241)	loss 6.847 (6.965)	prob 2.585 (3.167)	GS 32.406 (32.491)	mem 73.124
Train: [47][950/1500]	BT 0.033 (0.276)	DT 0.001 (0.239)	loss 6.899 (6.943)	prob 2.862 (3.166)	GS 34.219 (32.185)	mem 73.124
Train: [47][960/1500]	BT 0.040 (0.274)	DT 0.001 (0.236)	loss 6.847 (6.837)	prob 3.727 (3.080)	GS 35.328 (32.292)	mem 73.125
Train: [47][970/1500]	BT 0.038 (0.279)	DT 0.000 (0.241)	loss 6.720 (6.840)	prob 2.951 (3.062)	GS 36.422 (32.396)	mem 73.126
Train: [47][980/1500]	BT 0.029 (0.276)	DT 0.000 (0.239)	loss 6.938 (6.842)	prob 3.545 (3.054)	GS 35.844 (33.017)	mem 73.128
Train: [47][990/1500]	BT 0.039 (0.277)	DT 0.001 (0.239)	loss 6.806 (6.846)	prob 2.963 (3.109)	GS 34.562 (32.791)	mem 73.128
Train: [47][1000/1500]	BT 0.039 (0.274)	DT 0.001 (0.237)	loss 6.733 (6.852)	prob 3.877 (3.154)	GS 37.000 (32.892)	mem 73.128
Train: [47][1010/1500]	BT 0.039 (0.272)	DT 0.001 (0.235)	loss 6.928 (6.850)	prob 3.278 (3.397)	GS 30.828 (31.956)	mem 73.128
Train: [47][1020/1500]	BT 0.037 (0.274)	DT 0.001 (0.237)	loss 6.880 (6.868)	prob 3.254 (3.316)	GS 31.500 (32.355)	mem 73.141
Train: [47][1030/1500]	BT 0.037 (0.272)	DT 0.000 (0.234)	loss 6.720 (6.849)	prob 2.858 (3.382)	GS 30.141 (32.028)	mem 73.143
Train: [47][1040/1500]	BT 0.038 (0.273)	DT 0.000 (0.236)	loss 6.995 (6.864)	prob 2.674 (3.324)	GS 30.672 (32.190)	mem 73.143
Train: [47][1050/1500]	BT 0.038 (0.271)	DT 0.001 (0.234)	loss 6.739 (6.853)	prob 3.070 (3.340)	GS 32.641 (32.098)	mem 73.146
Train: [47][1060/1500]	BT 0.056 (0.275)	DT 0.002 (0.238)	loss 7.017 (6.808)	prob 2.717 (3.186)	GS 30.781 (33.956)	mem 73.147
Train: [47][1070/1500]	BT 0.067 (0.273)	DT 0.008 (0.235)	loss 6.551 (6.801)	prob 4.024 (3.280)	GS 35.766 (33.334)	mem 73.149
Train: [47][1080/1500]	BT 0.036 (0.272)	DT 0.001 (0.235)	loss 6.692 (6.865)	prob 3.324 (3.268)	GS 38.375 (33.308)	mem 73.148
Train: [47][1090/1500]	BT 0.037 (0.273)	DT 0.000 (0.236)	loss 6.816 (6.863)	prob 3.036 (3.322)	GS 35.312 (33.186)	mem 73.148
Train: [47][1100/1500]	BT 0.037 (0.271)	DT 0.001 (0.233)	loss 7.079 (6.884)	prob 4.038 (3.338)	GS 33.625 (33.155)	mem 73.148
Train: [47][1110/1500]	BT 0.037 (0.274)	DT 0.000 (0.236)	loss 6.952 (6.959)	prob 3.960 (3.372)	GS 36.000 (33.111)	mem 73.150
Train: [47][1120/1500]	BT 0.037 (0.272)	DT 0.001 (0.234)	loss 7.174 (6.932)	prob 3.543 (3.375)	GS 32.219 (33.420)	mem 73.151
Train: [47][1130/1500]	BT 0.065 (0.272)	DT 0.014 (0.235)	loss 6.781 (6.921)	prob 3.740 (3.347)	GS 33.969 (33.227)	mem 73.152
Train: [47][1140/1500]	BT 0.060 (0.274)	DT 0.003 (0.236)	loss 7.062 (6.931)	prob 3.530 (3.291)	GS 33.328 (32.749)	mem 73.153
Train: [47][1150/1500]	BT 0.036 (0.274)	DT 0.000 (0.237)	loss 6.879 (6.939)	prob 3.444 (3.268)	GS 30.844 (32.784)	mem 73.156
Train: [47][1160/1500]	BT 0.032 (0.272)	DT 0.000 (0.235)	loss 7.054 (6.958)	prob 3.931 (3.629)	GS 30.016 (31.091)	mem 73.156
Train: [47][1170/1500]	BT 0.026 (0.276)	DT 0.000 (0.239)	loss 7.055 (6.929)	prob 2.704 (3.399)	GS 32.031 (31.780)	mem 73.156
Train: [47][1180/1500]	BT 0.037 (0.274)	DT 0.001 (0.237)	loss 6.901 (6.925)	prob 3.422 (3.357)	GS 36.375 (32.348)	mem 73.157
Train: [47][1190/1500]	BT 0.027 (0.276)	DT 0.000 (0.239)	loss 6.857 (6.932)	prob 4.346 (3.333)	GS 35.031 (32.787)	mem 73.158
Train: [47][1200/1500]	BT 0.025 (0.274)	DT 0.000 (0.237)	loss 6.803 (6.921)	prob 3.295 (3.331)	GS 37.031 (32.725)	mem 73.161
Train: [47][1210/1500]	BT 0.033 (0.272)	DT 0.000 (0.235)	loss 6.888 (6.902)	prob 3.530 (3.281)	GS 32.859 (32.608)	mem 73.161
Train: [47][1220/1500]	BT 0.072 (0.273)	DT 0.005 (0.236)	loss 6.933 (6.933)	prob 3.198 (3.267)	GS 34.578 (32.375)	mem 73.163
Train: [47][1230/1500]	BT 0.030 (0.275)	DT 0.000 (0.237)	loss 6.820 (6.928)	prob 2.367 (3.123)	GS 37.109 (32.702)	mem 73.165
Train: [47][1240/1500]	BT 0.038 (0.273)	DT 0.001 (0.235)	loss 6.836 (6.940)	prob 3.249 (3.094)	GS 34.219 (32.439)	mem 73.166
Train: [47][1250/1500]	BT 0.162 (0.271)	DT 0.126 (0.234)	loss 6.894 (6.947)	prob 2.479 (3.111)	GS 35.625 (32.372)	mem 73.166
Train: [47][1260/1500]	BT 0.038 (0.271)	DT 0.001 (0.234)	loss 6.924 (6.924)	prob 2.842 (2.827)	GS 32.594 (33.305)	mem 73.164
Train: [47][1270/1500]	BT 0.039 (0.271)	DT 0.001 (0.233)	loss 6.812 (6.877)	prob 2.902 (3.024)	GS 35.500 (33.384)	mem 73.167
Train: [47][1280/1500]	BT 0.086 (0.272)	DT 0.008 (0.234)	loss 6.882 (6.900)	prob 3.271 (3.014)	GS 34.141 (32.732)	mem 73.167
Train: [47][1290/1500]	BT 0.037 (0.274)	DT 0.001 (0.236)	loss 6.880 (6.887)	prob 2.661 (2.990)	GS 33.219 (32.818)	mem 73.164
Train: [47][1300/1500]	BT 0.037 (0.274)	DT 0.001 (0.237)	loss 7.046 (6.874)	prob 3.063 (2.955)	GS 30.688 (32.822)	mem 73.165
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [47][1310/1500]	BT 0.038 (0.273)	DT 0.001 (0.235)	loss 7.380 (6.954)	prob 2.337 (2.888)	GS 31.516 (31.337)	mem 73.165
Train: [47][1320/1500]	BT 0.038 (0.271)	DT 0.000 (0.234)	loss 6.794 (6.921)	prob 2.831 (2.847)	GS 35.484 (31.660)	mem 73.165
Train: [47][1330/1500]	BT 0.037 (0.272)	DT 0.001 (0.234)	loss 6.741 (6.899)	prob 2.533 (2.909)	GS 38.797 (32.413)	mem 73.168
Train: [47][1340/1500]	BT 0.038 (0.271)	DT 0.001 (0.233)	loss 6.935 (6.879)	prob 2.812 (2.856)	GS 31.594 (32.416)	mem 73.166
Train: [47][1350/1500]	BT 0.037 (0.271)	DT 0.001 (0.234)	loss 6.861 (6.879)	prob 3.356 (2.843)	GS 33.547 (32.455)	mem 73.168
Train: [47][1360/1500]	BT 0.038 (0.270)	DT 0.001 (0.232)	loss 6.844 (6.883)	prob 3.048 (3.184)	GS 30.297 (33.434)	mem 73.167
Train: [47][1370/1500]	BT 0.059 (0.269)	DT 0.021 (0.231)	loss 6.676 (6.853)	prob 3.081 (2.889)	GS 35.188 (32.776)	mem 73.168
Train: [47][1380/1500]	BT 0.035 (0.270)	DT 0.001 (0.232)	loss 6.765 (6.850)	prob 2.646 (2.815)	GS 33.609 (32.618)	mem 73.168
Train: [47][1390/1500]	BT 0.037 (0.269)	DT 0.001 (0.231)	loss 7.122 (6.857)	prob 2.839 (2.893)	GS 29.688 (32.520)	mem 73.170
Train: [47][1400/1500]	BT 0.036 (0.269)	DT 0.001 (0.232)	loss 6.846 (6.875)	prob 3.241 (2.891)	GS 35.078 (32.741)	mem 73.198
Train: [47][1410/1500]	BT 0.039 (0.268)	DT 0.001 (0.230)	loss 6.819 (6.832)	prob 2.733 (2.696)	GS 35.484 (31.652)	mem 73.200
Train: [47][1420/1500]	BT 0.037 (0.269)	DT 0.001 (0.232)	loss 6.906 (6.850)	prob 2.963 (2.507)	GS 35.391 (31.707)	mem 73.200
Train: [47][1430/1500]	BT 0.038 (0.268)	DT 0.001 (0.230)	loss 6.876 (6.853)	prob 2.219 (2.438)	GS 34.375 (32.017)	mem 73.200
Train: [47][1440/1500]	BT 0.061 (0.266)	DT 0.002 (0.228)	loss 6.716 (6.838)	prob 2.169 (2.432)	GS 33.984 (31.886)	mem 73.202
Train: [47][1450/1500]	BT 0.060 (0.268)	DT 0.003 (0.230)	loss 7.046 (6.836)	prob 1.584 (2.350)	GS 32.297 (32.066)	mem 73.128
Train: [47][1460/1500]	BT 0.039 (0.267)	DT 0.001 (0.229)	loss 6.764 (6.797)	prob 2.358 (2.323)	GS 35.969 (32.734)	mem 73.126
Train: [47][1470/1500]	BT 0.028 (0.267)	DT 0.000 (0.229)	loss 6.891 (6.825)	prob 1.969 (2.272)	GS 35.125 (32.882)	mem 30.563
Train: [47][1480/1500]	BT 0.028 (0.265)	DT 0.000 (0.227)	loss 6.661 (6.807)	prob 2.303 (2.327)	GS 32.344 (32.778)	mem 30.558
Train: [47][1490/1500]	BT 0.029 (0.264)	DT 0.000 (0.226)	loss 6.854 (6.812)	prob 2.341 (2.324)	GS 38.406 (32.707)	mem 10.832
Train: [47][1500/1500]	BT 0.031 (0.263)	DT 0.000 (0.225)	loss 6.661 (6.806)	prob 2.656 (2.324)	GS 34.062 (32.647)	mem 10.833
Train: [47][1510/1500]	BT 0.031 (0.262)	DT 0.000 (0.225)	loss 6.311 (6.532)	prob 2.086 (2.196)	GS 39.906 (33.600)	mem 8.018
epoch 47, total time 396.07
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [48][1/1500]	BT 21.905 (21.905)	DT 21.840 (21.840)	loss 6.419 (6.419)	prob 2.731 (2.731)	GS 31.875 (31.875)	mem 71.738
Train: [48][10/1500]	BT 0.028 (2.311)	DT 0.000 (2.274)	loss 6.583 (6.510)	prob 2.208 (2.268)	GS 34.703 (34.224)	mem 71.756
Train: [48][20/1500]	BT 0.039 (1.173)	DT 0.001 (1.137)	loss 6.792 (6.570)	prob 2.153 (2.313)	GS 32.812 (33.408)	mem 71.765
Train: [48][30/1500]	BT 0.032 (0.987)	DT 0.000 (0.951)	loss 6.700 (6.628)	prob 2.425 (2.276)	GS 32.984 (32.884)	mem 72.871
Train: [48][40/1500]	BT 0.031 (0.747)	DT 0.000 (0.713)	loss 6.794 (6.649)	prob 2.774 (2.276)	GS 34.219 (32.083)	mem 72.920
Train: [48][50/1500]	BT 0.036 (0.606)	DT 0.000 (0.571)	loss 6.736 (6.659)	prob 3.077 (2.341)	GS 27.172 (32.032)	mem 72.927
Train: [48][60/1500]	BT 0.037 (0.562)	DT 0.000 (0.527)	loss 6.706 (6.744)	prob 2.687 (2.501)	GS 34.203 (30.797)	mem 73.012
Train: [48][70/1500]	BT 0.036 (0.487)	DT 0.001 (0.452)	loss 6.879 (6.737)	prob 2.148 (2.439)	GS 31.047 (32.534)	mem 73.013
Train: [48][80/1500]	BT 0.052 (0.596)	DT 0.014 (0.560)	loss 6.756 (6.751)	prob 2.537 (2.486)	GS 30.656 (32.771)	mem 72.983
Train: [48][90/1500]	BT 0.052 (0.535)	DT 0.006 (0.499)	loss 6.745 (6.759)	prob 2.629 (2.445)	GS 34.047 (32.620)	mem 72.989
Train: [48][100/1500]	BT 0.063 (0.553)	DT 0.007 (0.515)	loss 6.820 (6.775)	prob 2.667 (2.487)	GS 33.766 (32.504)	mem 72.954
Train: [48][110/1500]	BT 0.053 (0.508)	DT 0.002 (0.469)	loss 6.958 (6.793)	prob 2.009 (2.434)	GS 29.969 (34.348)	mem 72.954
Train: [48][120/1500]	BT 9.322 (0.548)	DT 9.291 (0.508)	loss 6.707 (6.785)	prob 2.788 (2.623)	GS 36.016 (35.171)	mem 72.956
Train: [48][130/1500]	BT 0.028 (0.508)	DT 0.000 (0.469)	loss 6.783 (6.782)	prob 2.030 (2.686)	GS 39.047 (34.520)	mem 72.976
Train: [48][140/1500]	BT 0.037 (0.475)	DT 0.001 (0.435)	loss 6.632 (6.778)	prob 2.911 (2.664)	GS 33.375 (33.905)	mem 72.978
Train: [48][150/1500]	BT 0.026 (0.470)	DT 0.000 (0.431)	loss 6.792 (6.785)	prob 3.256 (2.692)	GS 34.828 (33.991)	mem 72.980
Train: [48][160/1500]	BT 0.024 (0.442)	DT 0.000 (0.404)	loss 6.708 (6.853)	prob 2.998 (2.575)	GS 36.344 (32.922)	mem 72.981
Train: [48][170/1500]	BT 0.037 (0.432)	DT 0.001 (0.394)	loss 6.766 (6.831)	prob 2.512 (2.680)	GS 37.016 (33.120)	mem 72.980
Train: [48][180/1500]	BT 0.027 (0.426)	DT 0.000 (0.389)	loss 6.767 (6.829)	prob 2.861 (2.788)	GS 33.297 (33.324)	mem 72.982
Train: [48][190/1500]	BT 0.037 (0.405)	DT 0.001 (0.369)	loss 6.758 (6.810)	prob 2.880 (2.763)	GS 35.719 (33.062)	mem 72.983
Train: [48][200/1500]	BT 0.036 (0.406)	DT 0.001 (0.368)	loss 6.896 (6.803)	prob 2.762 (2.742)	GS 30.531 (32.892)	mem 72.984
Train: [48][210/1500]	BT 0.037 (0.388)	DT 0.001 (0.351)	loss 6.820 (6.797)	prob 3.132 (2.732)	GS 30.156 (32.625)	mem 72.985
Train: [48][220/1500]	BT 0.048 (0.404)	DT 0.001 (0.366)	loss 6.661 (6.807)	prob 2.914 (2.752)	GS 36.391 (33.669)	mem 72.991
Train: [48][230/1500]	BT 0.053 (0.388)	DT 0.006 (0.351)	loss 6.812 (6.799)	prob 2.867 (2.761)	GS 38.344 (33.670)	mem 72.996
Train: [48][240/1500]	BT 0.059 (0.374)	DT 0.011 (0.336)	loss 6.779 (6.783)	prob 2.490 (2.718)	GS 33.453 (33.374)	mem 72.996
Train: [48][250/1500]	BT 0.032 (0.385)	DT 0.000 (0.347)	loss 6.926 (6.767)	prob 2.466 (2.739)	GS 37.094 (33.344)	mem 73.015
Train: [48][260/1500]	BT 0.034 (0.372)	DT 0.000 (0.334)	loss 6.718 (6.710)	prob 2.036 (2.547)	GS 38.453 (34.523)	mem 73.000
Train: [48][270/1500]	BT 0.048 (0.375)	DT 0.009 (0.338)	loss 6.883 (6.714)	prob 2.079 (2.744)	GS 32.062 (32.966)	mem 73.002
Train: [48][280/1500]	BT 0.033 (0.364)	DT 0.003 (0.326)	loss 6.807 (6.720)	prob 2.685 (2.725)	GS 34.609 (32.654)	mem 73.002
Train: [48][290/1500]	BT 0.064 (0.356)	DT 0.016 (0.318)	loss 6.819 (6.722)	prob 2.268 (2.703)	GS 32.297 (32.839)	mem 73.003
Train: [48][300/1500]	BT 0.077 (0.372)	DT 0.006 (0.334)	loss 6.617 (6.729)	prob 3.259 (2.738)	GS 34.656 (32.602)	mem 73.004
Train: [48][310/1500]	BT 0.038 (0.373)	DT 0.001 (0.335)	loss 6.678 (6.689)	prob 2.640 (2.802)	GS 32.250 (34.436)	mem 73.008
Train: [48][320/1500]	BT 0.038 (0.365)	DT 0.001 (0.327)	loss 6.764 (6.727)	prob 3.618 (3.102)	GS 35.938 (34.650)	mem 73.007
Train: [48][330/1500]	BT 0.065 (0.358)	DT 0.007 (0.320)	loss 6.595 (6.715)	prob 3.859 (3.199)	GS 35.828 (34.038)	mem 73.007
Train: [48][340/1500]	BT 0.028 (0.360)	DT 0.000 (0.321)	loss 6.647 (6.734)	prob 3.790 (3.224)	GS 37.094 (34.094)	mem 73.010
Train: [48][350/1500]	BT 0.029 (0.350)	DT 0.000 (0.312)	loss 6.942 (6.737)	prob 2.701 (3.241)	GS 36.953 (33.847)	mem 73.011
Train: [48][360/1500]	BT 0.038 (0.356)	DT 0.001 (0.318)	loss 6.913 (6.772)	prob 3.659 (3.042)	GS 29.156 (33.178)	mem 73.011
Train: [48][370/1500]	BT 0.041 (0.347)	DT 0.001 (0.309)	loss 6.570 (6.785)	prob 4.277 (3.194)	GS 36.031 (33.159)	mem 73.011
Train: [48][380/1500]	BT 0.054 (0.349)	DT 0.001 (0.311)	loss 6.688 (6.802)	prob 2.071 (3.092)	GS 39.328 (33.047)	mem 73.012
Train: [48][390/1500]	BT 0.066 (0.342)	DT 0.014 (0.304)	loss 6.993 (6.798)	prob 3.103 (3.118)	GS 35.703 (32.718)	mem 73.013
Train: [48][400/1500]	BT 0.067 (0.335)	DT 0.022 (0.296)	loss 6.744 (6.794)	prob 2.931 (3.129)	GS 32.438 (32.912)	mem 73.014
Train: [48][410/1500]	BT 0.034 (0.344)	DT 0.000 (0.305)	loss 6.821 (6.789)	prob 2.761 (2.718)	GS 31.500 (33.205)	mem 73.015
Train: [48][420/1500]	BT 0.035 (0.336)	DT 0.001 (0.298)	loss 6.814 (6.819)	prob 2.661 (2.794)	GS 31.625 (33.502)	mem 73.015
Train: [48][430/1500]	BT 0.039 (0.336)	DT 0.001 (0.297)	loss 6.701 (6.811)	prob 3.309 (2.877)	GS 33.359 (33.151)	mem 73.018
Train: [48][440/1500]	BT 0.039 (0.329)	DT 0.001 (0.291)	loss 6.848 (6.804)	prob 2.882 (2.859)	GS 33.922 (32.749)	mem 73.018
Train: [48][450/1500]	BT 0.039 (0.337)	DT 0.001 (0.299)	loss 6.737 (6.807)	prob 3.171 (2.860)	GS 37.547 (32.850)	mem 73.018
Train: [48][460/1500]	BT 0.039 (0.331)	DT 0.001 (0.293)	loss 6.687 (6.844)	prob 3.471 (3.128)	GS 35.453 (32.172)	mem 73.019
Train: [48][470/1500]	BT 0.034 (0.334)	DT 0.000 (0.296)	loss 6.890 (6.809)	prob 3.240 (2.930)	GS 33.297 (31.348)	mem 73.038
Train: [48][480/1500]	BT 0.036 (0.328)	DT 0.000 (0.290)	loss 6.898 (6.833)	prob 2.435 (2.901)	GS 33.016 (31.878)	mem 73.037
Train: [48][490/1500]	BT 0.037 (0.322)	DT 0.001 (0.284)	loss 6.778 (6.823)	prob 2.157 (2.858)	GS 34.703 (32.245)	mem 73.038
Train: [48][500/1500]	BT 0.037 (0.326)	DT 0.001 (0.287)	loss 6.801 (6.816)	prob 3.262 (2.821)	GS 36.281 (32.493)	mem 73.038
Train: [48][510/1500]	BT 0.037 (0.320)	DT 0.000 (0.282)	loss 6.756 (6.783)	prob 2.841 (2.865)	GS 29.922 (32.817)	mem 73.039
Train: [48][520/1500]	BT 0.031 (0.323)	DT 0.000 (0.285)	loss 7.033 (6.792)	prob 2.355 (2.659)	GS 36.516 (32.700)	mem 73.041
Train: [48][530/1500]	BT 0.057 (0.318)	DT 0.013 (0.280)	loss 6.775 (6.776)	prob 1.909 (2.594)	GS 32.406 (32.245)	mem 73.043
Train: [48][540/1500]	BT 0.064 (0.313)	DT 0.011 (0.275)	loss 6.841 (6.778)	prob 2.074 (2.559)	GS 32.719 (32.281)	mem 73.042
Train: [48][550/1500]	BT 0.037 (0.318)	DT 0.001 (0.279)	loss 6.706 (6.782)	prob 2.993 (2.527)	GS 33.125 (32.246)	mem 73.045
Train: [48][560/1500]	BT 0.037 (0.313)	DT 0.001 (0.275)	loss 6.762 (6.810)	prob 2.615 (2.548)	GS 31.297 (32.706)	mem 73.045
Train: [48][570/1500]	BT 0.034 (0.313)	DT 0.001 (0.275)	loss 6.664 (6.796)	prob 2.728 (2.493)	GS 34.469 (33.173)	mem 73.045
Train: [48][580/1500]	BT 0.034 (0.312)	DT 0.000 (0.274)	loss 6.681 (6.787)	prob 2.846 (2.544)	GS 32.234 (32.832)	mem 73.046
Train: [48][590/1500]	BT 0.028 (0.308)	DT 0.000 (0.270)	loss 6.758 (6.791)	prob 2.871 (2.520)	GS 35.875 (32.710)	mem 73.049
Train: [48][600/1500]	BT 0.034 (0.304)	DT 0.000 (0.266)	loss 6.708 (6.779)	prob 3.376 (2.568)	GS 35.344 (32.511)	mem 73.050
Train: [48][610/1500]	BT 0.060 (0.307)	DT 0.016 (0.269)	loss 6.798 (6.751)	prob 1.722 (2.635)	GS 34.141 (32.672)	mem 73.052
Train: [48][620/1500]	BT 0.054 (0.303)	DT 0.011 (0.264)	loss 6.968 (6.782)	prob 1.929 (2.485)	GS 31.438 (32.073)	mem 73.053
Train: [48][630/1500]	BT 0.035 (0.308)	DT 0.001 (0.270)	loss 6.709 (6.764)	prob 2.968 (2.510)	GS 36.047 (32.278)	mem 73.053
Train: [48][640/1500]	BT 0.037 (0.304)	DT 0.001 (0.266)	loss 6.915 (6.786)	prob 3.180 (2.508)	GS 31.203 (32.459)	mem 73.053
Train: [48][650/1500]	BT 0.037 (0.300)	DT 0.000 (0.262)	loss 6.716 (6.785)	prob 2.368 (2.462)	GS 30.172 (32.235)	mem 73.054
Train: [48][660/1500]	BT 0.037 (0.300)	DT 0.000 (0.262)	loss 6.713 (6.792)	prob 1.799 (2.421)	GS 31.734 (33.352)	mem 73.054
Train: [48][670/1500]	BT 0.038 (0.298)	DT 0.001 (0.260)	loss 6.847 (6.789)	prob 2.202 (2.397)	GS 36.578 (33.455)	mem 73.057
Train: [48][680/1500]	BT 0.038 (0.296)	DT 0.001 (0.258)	loss 6.788 (6.792)	prob 2.338 (2.318)	GS 33.594 (33.408)	mem 73.057
Train: [48][690/1500]	BT 0.037 (0.295)	DT 0.001 (0.257)	loss 6.942 (6.814)	prob 2.474 (2.391)	GS 32.016 (32.992)	mem 73.058
Train: [48][700/1500]	BT 0.036 (0.294)	DT 0.001 (0.256)	loss 6.744 (6.799)	prob 1.970 (2.397)	GS 29.703 (32.650)	mem 73.061
Train: [48][710/1500]	BT 0.038 (0.294)	DT 0.000 (0.256)	loss 6.888 (6.811)	prob 2.818 (2.350)	GS 35.250 (30.773)	mem 73.061
Train: [48][720/1500]	BT 0.037 (0.292)	DT 0.001 (0.254)	loss 6.698 (6.778)	prob 2.171 (2.408)	GS 32.281 (30.635)	mem 73.061
Train: [48][730/1500]	BT 0.035 (0.291)	DT 0.001 (0.253)	loss 6.828 (6.774)	prob 2.917 (2.474)	GS 36.141 (31.248)	mem 73.063
Train: [48][740/1500]	BT 0.033 (0.290)	DT 0.001 (0.252)	loss 6.625 (6.774)	prob 2.360 (2.473)	GS 30.750 (31.551)	mem 73.064
Train: [48][750/1500]	BT 0.040 (0.288)	DT 0.001 (0.250)	loss 6.683 (6.775)	prob 2.375 (2.489)	GS 32.031 (31.572)	mem 73.064
Train: [48][760/1500]	BT 0.072 (0.292)	DT 0.007 (0.254)	loss 6.843 (6.784)	prob 2.823 (2.444)	GS 33.969 (31.183)	mem 73.067
Train: [48][770/1500]	BT 0.075 (0.289)	DT 0.025 (0.251)	loss 6.742 (6.811)	prob 2.034 (2.562)	GS 35.234 (32.301)	mem 73.067
Train: [48][780/1500]	BT 0.043 (0.293)	DT 0.001 (0.255)	loss 6.958 (6.821)	prob 2.687 (2.524)	GS 31.938 (31.855)	mem 73.098
Train: [48][790/1500]	BT 0.042 (0.291)	DT 0.002 (0.253)	loss 6.844 (6.811)	prob 2.476 (2.509)	GS 35.016 (32.266)	mem 73.097
Train: [48][800/1500]	BT 0.060 (0.288)	DT 0.005 (0.250)	loss 6.894 (6.806)	prob 1.358 (2.500)	GS 37.281 (32.143)	mem 73.097
Train: [48][810/1500]	BT 0.058 (0.290)	DT 0.017 (0.251)	loss 6.947 (6.774)	prob 2.680 (2.560)	GS 31.812 (32.220)	mem 73.100
Train: [48][820/1500]	BT 0.047 (0.293)	DT 0.001 (0.254)	loss 6.675 (6.773)	prob 2.904 (2.501)	GS 36.312 (32.472)	mem 73.102
Train: [48][830/1500]	BT 0.051 (0.291)	DT 0.003 (0.252)	loss 6.777 (6.784)	prob 2.478 (2.452)	GS 31.750 (32.261)	mem 73.102
Train: [48][840/1500]	BT 0.034 (0.307)	DT 0.000 (0.268)	loss 6.937 (6.783)	prob 2.000 (2.417)	GS 30.938 (32.554)	mem 73.101
Train: [48][850/1500]	BT 0.037 (0.304)	DT 0.000 (0.265)	loss 6.760 (6.781)	prob 1.393 (2.368)	GS 36.203 (32.577)	mem 73.105
Train: [48][860/1500]	BT 0.041 (0.307)	DT 0.006 (0.268)	loss 6.571 (6.748)	prob 2.395 (1.936)	GS 32.109 (34.006)	mem 73.106
Train: [48][870/1500]	BT 0.050 (0.304)	DT 0.011 (0.265)	loss 6.735 (6.739)	prob 2.956 (2.088)	GS 32.188 (32.892)	mem 73.105
Train: [48][880/1500]	BT 6.114 (0.308)	DT 6.076 (0.269)	loss 6.843 (6.748)	prob 2.632 (2.205)	GS 36.703 (32.793)	mem 73.104
Train: [48][890/1500]	BT 0.024 (0.307)	DT 0.000 (0.268)	loss 6.574 (6.742)	prob 1.769 (2.206)	GS 33.641 (32.737)	mem 73.105
Train: [48][900/1500]	BT 0.026 (0.304)	DT 0.000 (0.265)	loss 7.018 (6.739)	prob 1.767 (2.251)	GS 33.109 (33.051)	mem 73.106
Train: [48][910/1500]	BT 0.039 (0.302)	DT 0.001 (0.263)	loss 6.679 (6.761)	prob 2.177 (2.168)	GS 35.141 (32.455)	mem 73.106
Train: [48][920/1500]	BT 0.030 (0.306)	DT 0.000 (0.267)	loss 6.596 (6.740)	prob 2.349 (2.362)	GS 33.078 (33.351)	mem 73.105
Train: [48][930/1500]	BT 0.027 (0.303)	DT 0.000 (0.264)	loss 6.801 (6.715)	prob 2.380 (2.372)	GS 34.078 (32.900)	mem 73.105
Train: [48][940/1500]	BT 0.028 (0.304)	DT 0.000 (0.266)	loss 6.715 (6.719)	prob 2.188 (2.306)	GS 34.750 (32.641)	mem 73.105
Train: [48][950/1500]	BT 0.029 (0.302)	DT 0.000 (0.263)	loss 6.831 (6.714)	prob 2.411 (2.338)	GS 27.703 (32.437)	mem 73.105
Train: [48][960/1500]	BT 0.039 (0.299)	DT 0.001 (0.261)	loss 6.753 (6.755)	prob 2.792 (2.374)	GS 29.781 (32.567)	mem 73.106
Train: [48][970/1500]	BT 0.032 (0.300)	DT 0.000 (0.262)	loss 6.596 (6.726)	prob 2.151 (2.276)	GS 31.906 (32.080)	mem 73.107
Train: [48][980/1500]	BT 0.038 (0.298)	DT 0.000 (0.259)	loss 6.851 (6.738)	prob 2.867 (2.326)	GS 32.891 (32.421)	mem 73.107
Train: [48][990/1500]	BT 0.042 (0.301)	DT 0.000 (0.263)	loss 6.737 (6.739)	prob 1.821 (2.307)	GS 33.703 (32.509)	mem 73.107
Train: [48][1000/1500]	BT 0.038 (0.298)	DT 0.000 (0.260)	loss 6.938 (6.750)	prob 1.847 (2.279)	GS 35.125 (32.556)	mem 73.107
Train: [48][1010/1500]	BT 0.037 (0.299)	DT 0.008 (0.261)	loss 6.824 (6.680)	prob 1.930 (2.473)	GS 32.969 (33.531)	mem 73.106
Train: [48][1020/1500]	BT 0.036 (0.296)	DT 0.001 (0.258)	loss 6.633 (6.703)	prob 2.872 (2.537)	GS 35.531 (33.181)	mem 73.107
Train: [48][1030/1500]	BT 0.035 (0.294)	DT 0.001 (0.256)	loss 6.948 (6.723)	prob 2.196 (2.473)	GS 32.094 (32.944)	mem 73.108
Train: [48][1040/1500]	BT 0.037 (0.295)	DT 0.001 (0.257)	loss 6.865 (6.731)	prob 2.267 (2.499)	GS 33.016 (32.737)	mem 73.107
Train: [48][1050/1500]	BT 0.037 (0.292)	DT 0.001 (0.254)	loss 6.817 (6.734)	prob 1.505 (2.460)	GS 34.688 (32.839)	mem 73.107
Train: [48][1060/1500]	BT 0.037 (0.292)	DT 0.000 (0.255)	loss 7.001 (6.666)	prob 2.958 (2.892)	GS 31.812 (33.891)	mem 73.128
Train: [48][1070/1500]	BT 0.038 (0.290)	DT 0.001 (0.253)	loss 6.832 (6.709)	prob 2.304 (2.509)	GS 39.328 (33.589)	mem 73.128
Train: [48][1080/1500]	BT 0.035 (0.289)	DT 0.000 (0.251)	loss 7.169 (6.742)	prob 1.817 (2.433)	GS 34.984 (33.096)	mem 73.128
Train: [48][1090/1500]	BT 0.065 (0.291)	DT 0.014 (0.253)	loss 6.906 (6.737)	prob 2.668 (2.495)	GS 35.109 (32.773)	mem 73.008
Train: [48][1100/1500]	BT 0.028 (0.296)	DT 0.000 (0.258)	loss 6.717 (6.746)	prob 3.249 (2.521)	GS 32.188 (32.658)	mem 73.025
Train: [48][1110/1500]	BT 0.027 (0.293)	DT 0.000 (0.255)	loss 6.690 (6.745)	prob 2.602 (2.242)	GS 38.281 (32.931)	mem 73.027
Train: [48][1120/1500]	BT 0.037 (0.291)	DT 0.001 (0.253)	loss 6.678 (6.763)	prob 2.740 (2.390)	GS 34.359 (33.704)	mem 73.028
Train: [48][1130/1500]	BT 0.037 (0.291)	DT 0.001 (0.253)	loss 6.937 (6.768)	prob 1.953 (2.430)	GS 36.531 (33.228)	mem 73.028
Train: [48][1140/1500]	BT 0.037 (0.289)	DT 0.000 (0.251)	loss 6.941 (6.759)	prob 1.885 (2.433)	GS 37.531 (33.061)	mem 73.028
Train: [48][1150/1500]	BT 0.036 (0.294)	DT 0.000 (0.256)	loss 6.776 (6.755)	prob 2.143 (2.463)	GS 30.938 (32.867)	mem 73.029
Train: [48][1160/1500]	BT 0.037 (0.292)	DT 0.001 (0.254)	loss 7.034 (6.758)	prob 2.515 (2.471)	GS 34.734 (33.106)	mem 73.039
Train: [48][1170/1500]	BT 0.038 (0.291)	DT 0.000 (0.253)	loss 6.760 (6.769)	prob 2.587 (2.501)	GS 33.625 (32.794)	mem 73.049
Train: [48][1180/1500]	BT 0.022 (0.300)	DT 0.000 (0.262)	loss 6.836 (6.783)	prob 3.118 (2.559)	GS 33.656 (32.640)	mem 73.033
Train: [48][1190/1500]	BT 0.024 (0.297)	DT 0.000 (0.260)	loss 6.571 (6.772)	prob 2.863 (2.531)	GS 34.031 (32.478)	mem 73.034
Train: [48][1200/1500]	BT 0.040 (0.299)	DT 0.001 (0.261)	loss 6.782 (6.778)	prob 2.463 (2.514)	GS 33.484 (32.396)	mem 73.035
Train: [48][1210/1500]	BT 0.034 (0.296)	DT 0.000 (0.259)	loss 6.671 (6.755)	prob 2.414 (2.692)	GS 33.250 (33.381)	mem 73.036
Train: [48][1220/1500]	BT 0.037 (0.294)	DT 0.001 (0.257)	loss 6.576 (6.748)	prob 2.128 (2.511)	GS 36.125 (34.148)	mem 73.035
Train: [48][1230/1500]	BT 0.063 (0.296)	DT 0.004 (0.259)	loss 6.653 (6.740)	prob 2.761 (2.575)	GS 32.859 (33.013)	mem 73.036
Train: [48][1240/1500]	BT 0.057 (0.294)	DT 0.005 (0.256)	loss 6.782 (6.741)	prob 3.813 (2.650)	GS 32.969 (33.286)	mem 73.038
Train: [48][1250/1500]	BT 0.020 (0.299)	DT 0.000 (0.261)	loss 6.853 (6.748)	prob 2.451 (2.722)	GS 36.000 (33.648)	mem 73.037
Train: [48][1260/1500]	BT 0.031 (0.297)	DT 0.000 (0.259)	loss 7.076 (6.715)	prob 1.818 (2.762)	GS 33.219 (32.930)	mem 73.039
Train: [48][1270/1500]	BT 0.028 (0.298)	DT 0.000 (0.261)	loss 6.683 (6.811)	prob 3.154 (2.819)	GS 32.219 (33.351)	mem 73.040
Train: [48][1280/1500]	BT 0.030 (0.296)	DT 0.000 (0.259)	loss 6.633 (6.766)	prob 2.864 (2.764)	GS 30.938 (33.215)	mem 73.042
Train: [48][1290/1500]	BT 0.029 (0.294)	DT 0.000 (0.257)	loss 6.711 (6.749)	prob 2.781 (2.752)	GS 36.531 (32.923)	mem 73.041
Train: [48][1300/1500]	BT 0.025 (0.295)	DT 0.000 (0.258)	loss 6.720 (6.728)	prob 3.241 (2.763)	GS 35.500 (33.057)	mem 73.056
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [48][1310/1500]	BT 0.048 (0.294)	DT 0.001 (0.256)	loss 6.792 (6.650)	prob 2.259 (2.960)	GS 32.344 (31.952)	mem 73.058
Train: [48][1320/1500]	BT 0.030 (0.298)	DT 0.000 (0.260)	loss 6.883 (6.658)	prob 2.174 (2.839)	GS 31.203 (31.538)	mem 73.058
Train: [48][1330/1500]	BT 0.060 (0.296)	DT 0.002 (0.258)	loss 6.799 (6.648)	prob 2.062 (2.790)	GS 35.672 (32.233)	mem 73.059
Train: [48][1340/1500]	BT 0.027 (0.301)	DT 0.000 (0.263)	loss 6.478 (6.652)	prob 2.061 (2.713)	GS 31.484 (32.545)	mem 73.059
Train: [48][1350/1500]	BT 0.034 (0.299)	DT 0.000 (0.261)	loss 6.442 (6.668)	prob 2.927 (2.698)	GS 32.625 (32.578)	mem 73.060
Train: [48][1360/1500]	BT 0.023 (0.300)	DT 0.000 (0.262)	loss 6.604 (6.663)	prob 3.330 (2.700)	GS 32.797 (31.264)	mem 73.063
Train: [48][1370/1500]	BT 0.027 (0.298)	DT 0.000 (0.260)	loss 6.943 (6.673)	prob 1.507 (2.642)	GS 35.641 (32.499)	mem 73.063
Train: [48][1380/1500]	BT 0.027 (0.296)	DT 0.000 (0.258)	loss 6.787 (6.670)	prob 2.485 (2.682)	GS 33.734 (32.496)	mem 73.063
Train: [48][1390/1500]	BT 0.037 (0.296)	DT 0.001 (0.259)	loss 6.834 (6.689)	prob 2.479 (2.684)	GS 32.406 (32.250)	mem 73.064
Train: [48][1400/1500]	BT 0.038 (0.295)	DT 0.001 (0.257)	loss 6.840 (6.703)	prob 2.671 (2.678)	GS 34.781 (32.433)	mem 73.064
Train: [48][1410/1500]	BT 0.035 (0.295)	DT 0.000 (0.258)	loss 6.581 (6.679)	prob 3.202 (2.745)	GS 31.656 (31.567)	mem 73.067
Train: [48][1420/1500]	BT 0.032 (0.293)	DT 0.000 (0.256)	loss 6.484 (6.705)	prob 2.933 (2.771)	GS 35.250 (32.020)	mem 73.068
Train: [48][1430/1500]	BT 0.026 (0.295)	DT 0.000 (0.257)	loss 6.723 (6.695)	prob 2.444 (2.781)	GS 32.672 (32.294)	mem 73.070
Train: [48][1440/1500]	BT 0.027 (0.293)	DT 0.000 (0.255)	loss 6.612 (6.697)	prob 2.200 (2.747)	GS 29.609 (32.404)	mem 73.070
Train: [48][1450/1500]	BT 0.037 (0.291)	DT 0.001 (0.254)	loss 6.658 (6.711)	prob 2.794 (2.711)	GS 36.328 (32.381)	mem 73.070
Train: [48][1460/1500]	BT 0.030 (0.292)	DT 0.000 (0.255)	loss 6.787 (6.871)	prob 2.516 (2.461)	GS 32.656 (31.762)	mem 72.486
Train: [48][1470/1500]	BT 0.030 (0.290)	DT 0.000 (0.253)	loss 6.952 (6.832)	prob 3.146 (2.510)	GS 36.484 (32.691)	mem 72.451
Train: [48][1480/1500]	BT 0.030 (0.290)	DT 0.001 (0.253)	loss 6.885 (6.823)	prob 3.141 (2.530)	GS 32.875 (32.681)	mem 10.864
Train: [48][1490/1500]	BT 0.026 (0.288)	DT 0.000 (0.251)	loss 7.019 (6.846)	prob 3.132 (2.607)	GS 36.406 (32.395)	mem 10.864
Train: [48][1500/1500]	BT 0.027 (0.287)	DT 0.000 (0.249)	loss 6.766 (6.839)	prob 3.489 (2.642)	GS 34.938 (32.415)	mem 10.791
Train: [48][1510/1500]	BT 0.025 (0.285)	DT 0.000 (0.248)	loss 6.480 (6.546)	prob 3.685 (3.136)	GS 35.594 (32.672)	mem 7.978
epoch 48, total time 431.05
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [49][1/1500]	BT 22.315 (22.315)	DT 22.235 (22.235)	loss 6.719 (6.719)	prob 1.906 (1.906)	GS 32.891 (32.891)	mem 71.710
Train: [49][10/1500]	BT 0.061 (2.286)	DT 0.017 (2.238)	loss 6.718 (6.619)	prob 2.626 (2.747)	GS 36.297 (32.983)	mem 71.714
Train: [49][20/1500]	BT 0.067 (1.176)	DT 0.008 (1.132)	loss 6.679 (6.642)	prob 2.245 (2.713)	GS 35.562 (33.349)	mem 71.721
Train: [49][30/1500]	BT 0.045 (0.981)	DT 0.001 (0.938)	loss 6.779 (6.712)	prob 2.951 (2.785)	GS 31.500 (32.824)	mem 71.754
Train: [49][40/1500]	BT 0.037 (0.830)	DT 0.000 (0.787)	loss 6.953 (6.765)	prob 2.692 (2.863)	GS 30.750 (32.942)	mem 71.761
Train: [49][50/1500]	BT 0.038 (0.672)	DT 0.001 (0.630)	loss 6.846 (6.790)	prob 2.642 (2.831)	GS 36.000 (32.920)	mem 71.780
Train: [49][60/1500]	BT 0.770 (0.632)	DT 0.714 (0.590)	loss 6.995 (6.866)	prob 2.882 (2.953)	GS 33.438 (31.636)	mem 71.809
Train: [49][70/1500]	BT 0.030 (0.626)	DT 0.000 (0.586)	loss 7.023 (6.908)	prob 3.427 (3.066)	GS 33.578 (32.491)	mem 71.918
Train: [49][80/1500]	BT 0.036 (0.552)	DT 0.001 (0.512)	loss 6.853 (6.896)	prob 2.606 (2.964)	GS 32.438 (32.559)	mem 71.920
Train: [49][90/1500]	BT 0.039 (0.525)	DT 0.001 (0.486)	loss 6.880 (6.912)	prob 2.232 (2.806)	GS 31.281 (32.701)	mem 72.413
Train: [49][100/1500]	BT 0.037 (0.477)	DT 0.001 (0.438)	loss 7.179 (6.921)	prob 2.266 (2.812)	GS 29.266 (32.396)	mem 72.464
Train: [49][110/1500]	BT 0.039 (0.462)	DT 0.001 (0.423)	loss 6.811 (6.951)	prob 3.719 (2.857)	GS 34.812 (31.689)	mem 72.838
Train: [49][120/1500]	BT 0.039 (0.427)	DT 0.001 (0.388)	loss 6.878 (6.904)	prob 3.707 (3.055)	GS 33.500 (31.229)	mem 72.937
Train: [49][130/1500]	BT 0.039 (0.397)	DT 0.001 (0.358)	loss 7.088 (6.889)	prob 2.465 (2.889)	GS 32.312 (31.810)	mem 73.013
Train: [49][140/1500]	BT 0.039 (0.393)	DT 0.000 (0.354)	loss 6.938 (6.909)	prob 2.457 (2.772)	GS 31.188 (31.904)	mem 73.039
Train: [49][150/1500]	BT 0.059 (0.373)	DT 0.021 (0.335)	loss 7.244 (6.922)	prob 2.037 (2.712)	GS 31.766 (32.026)	mem 73.040
Train: [49][160/1500]	BT 0.069 (0.379)	DT 0.010 (0.340)	loss 6.634 (6.897)	prob 3.065 (2.798)	GS 36.344 (32.350)	mem 73.044
Train: [49][170/1500]	BT 0.066 (0.369)	DT 0.000 (0.329)	loss 6.931 (6.880)	prob 3.469 (2.752)	GS 31.625 (32.339)	mem 73.048
Train: [49][180/1500]	BT 3.814 (0.394)	DT 3.783 (0.353)	loss 6.815 (6.916)	prob 2.732 (2.717)	GS 34.328 (32.695)	mem 73.061
Train: [49][190/1500]	BT 0.034 (0.385)	DT 0.001 (0.345)	loss 6.822 (6.919)	prob 2.784 (2.735)	GS 36.578 (33.064)	mem 73.062
Train: [49][200/1500]	BT 0.036 (0.368)	DT 0.001 (0.328)	loss 7.131 (6.906)	prob 1.738 (2.716)	GS 35.859 (33.078)	mem 73.063
Train: [49][210/1500]	BT 0.058 (0.373)	DT 0.000 (0.333)	loss 6.768 (6.795)	prob 2.145 (2.690)	GS 33.734 (32.731)	mem 73.071
Train: [49][220/1500]	BT 0.064 (0.363)	DT 0.006 (0.321)	loss 6.843 (6.846)	prob 3.070 (2.811)	GS 33.875 (33.434)	mem 73.072
Train: [49][230/1500]	BT 0.080 (0.373)	DT 0.009 (0.331)	loss 6.844 (6.855)	prob 2.479 (2.822)	GS 33.391 (33.178)	mem 73.078
Train: [49][240/1500]	BT 0.028 (0.374)	DT 0.001 (0.333)	loss 7.057 (6.853)	prob 2.512 (2.849)	GS 33.078 (33.525)	mem 73.077
Train: [49][250/1500]	BT 0.030 (0.361)	DT 0.000 (0.320)	loss 6.878 (6.852)	prob 3.443 (2.766)	GS 35.688 (33.423)	mem 73.078
Train: [49][260/1500]	BT 0.063 (0.365)	DT 0.016 (0.324)	loss 7.104 (6.828)	prob 2.500 (2.965)	GS 33.500 (32.884)	mem 73.081
Train: [49][270/1500]	BT 0.038 (0.353)	DT 0.001 (0.312)	loss 6.810 (6.831)	prob 1.510 (2.696)	GS 36.172 (32.655)	mem 73.084
Train: [49][280/1500]	BT 0.039 (0.350)	DT 0.001 (0.309)	loss 6.934 (6.859)	prob 2.651 (2.676)	GS 36.594 (33.116)	mem 73.083
Train: [49][290/1500]	BT 0.048 (0.344)	DT 0.003 (0.303)	loss 6.748 (6.847)	prob 2.843 (2.697)	GS 30.391 (32.726)	mem 73.083
Train: [49][300/1500]	BT 0.057 (0.335)	DT 0.001 (0.293)	loss 6.784 (6.848)	prob 2.572 (2.655)	GS 31.672 (32.435)	mem 73.084
Train: [49][310/1500]	BT 0.039 (0.343)	DT 0.000 (0.301)	loss 7.028 (6.858)	prob 1.839 (2.062)	GS 31.953 (31.086)	mem 73.082
Train: [49][320/1500]	BT 0.039 (0.333)	DT 0.001 (0.292)	loss 6.760 (6.867)	prob 2.376 (2.166)	GS 34.359 (32.776)	mem 73.082
Train: [49][330/1500]	BT 0.039 (0.333)	DT 0.001 (0.291)	loss 6.741 (6.851)	prob 2.835 (2.369)	GS 35.438 (32.837)	mem 73.082
Train: [49][340/1500]	BT 0.029 (0.326)	DT 0.000 (0.285)	loss 6.789 (6.833)	prob 2.255 (2.441)	GS 33.469 (32.829)	mem 73.084
Train: [49][350/1500]	BT 0.038 (0.320)	DT 0.000 (0.279)	loss 6.783 (6.829)	prob 3.018 (2.387)	GS 34.375 (32.623)	mem 73.086
Train: [49][360/1500]	BT 0.036 (0.322)	DT 0.001 (0.281)	loss 6.849 (6.825)	prob 2.035 (2.202)	GS 35.891 (33.333)	mem 73.082
Train: [49][370/1500]	BT 0.084 (0.320)	DT 0.022 (0.279)	loss 6.716 (6.810)	prob 2.827 (2.363)	GS 33.562 (33.315)	mem 73.082
Train: [49][380/1500]	BT 0.037 (0.323)	DT 0.001 (0.281)	loss 6.632 (6.824)	prob 3.543 (2.400)	GS 34.438 (33.523)	mem 73.086
Train: [49][390/1500]	BT 0.037 (0.320)	DT 0.000 (0.279)	loss 7.168 (6.827)	prob 2.423 (2.475)	GS 36.562 (33.341)	mem 73.091
Train: [49][400/1500]	BT 0.037 (0.313)	DT 0.001 (0.272)	loss 6.972 (6.818)	prob 2.483 (2.442)	GS 40.172 (33.618)	mem 73.093
Train: [49][410/1500]	BT 0.037 (0.319)	DT 0.001 (0.277)	loss 6.702 (6.819)	prob 2.357 (2.340)	GS 33.000 (33.664)	mem 73.102
Train: [49][420/1500]	BT 0.038 (0.312)	DT 0.001 (0.271)	loss 6.607 (6.815)	prob 3.126 (2.355)	GS 33.062 (33.020)	mem 73.102
Train: [49][430/1500]	BT 0.037 (0.310)	DT 0.001 (0.269)	loss 6.847 (6.779)	prob 2.418 (2.304)	GS 37.609 (32.646)	mem 73.103
Train: [49][440/1500]	BT 0.037 (0.311)	DT 0.001 (0.270)	loss 6.857 (6.782)	prob 2.403 (2.352)	GS 34.125 (32.916)	mem 73.104
Train: [49][450/1500]	BT 0.035 (0.309)	DT 0.001 (0.268)	loss 6.600 (6.786)	prob 3.232 (2.393)	GS 33.969 (33.040)	mem 72.985
Train: [49][460/1500]	BT 0.037 (0.306)	DT 0.001 (0.264)	loss 6.776 (6.803)	prob 2.229 (2.764)	GS 31.500 (32.120)	mem 73.004
Train: [49][470/1500]	BT 0.037 (0.308)	DT 0.000 (0.267)	loss 6.784 (6.786)	prob 2.062 (2.595)	GS 32.406 (31.520)	mem 73.005
Train: [49][480/1500]	BT 0.037 (0.302)	DT 0.001 (0.261)	loss 6.855 (6.800)	prob 2.902 (2.482)	GS 29.281 (31.685)	mem 73.004
Train: [49][490/1500]	BT 0.037 (0.300)	DT 0.001 (0.259)	loss 7.258 (6.841)	prob 2.961 (2.505)	GS 36.688 (31.713)	mem 73.006
Train: [49][500/1500]	BT 0.047 (0.298)	DT 0.011 (0.257)	loss 6.817 (6.837)	prob 2.634 (2.522)	GS 32.125 (31.888)	mem 73.006
Train: [49][510/1500]	BT 0.038 (0.297)	DT 0.001 (0.256)	loss 6.793 (6.854)	prob 1.964 (2.222)	GS 33.609 (32.422)	mem 73.009
Train: [49][520/1500]	BT 0.024 (0.297)	DT 0.000 (0.256)	loss 6.816 (6.851)	prob 1.128 (2.147)	GS 33.125 (33.027)	mem 73.010
Train: [49][530/1500]	BT 0.038 (0.292)	DT 0.001 (0.251)	loss 6.811 (6.856)	prob 2.668 (2.309)	GS 35.609 (32.439)	mem 73.012
Train: [49][540/1500]	BT 0.039 (0.288)	DT 0.001 (0.247)	loss 6.957 (6.889)	prob 2.807 (2.309)	GS 33.109 (32.324)	mem 73.014
Train: [49][550/1500]	BT 0.036 (0.291)	DT 0.001 (0.251)	loss 7.150 (6.906)	prob 3.043 (2.295)	GS 34.016 (32.674)	mem 73.039
Train: [49][560/1500]	BT 0.038 (0.287)	DT 0.001 (0.246)	loss 7.013 (6.965)	prob 2.438 (2.535)	GS 35.656 (32.272)	mem 73.039
Train: [49][570/1500]	BT 0.067 (0.290)	DT 0.001 (0.249)	loss 7.168 (6.978)	prob 2.493 (2.616)	GS 29.469 (31.921)	mem 73.040
Train: [49][580/1500]	BT 0.060 (0.286)	DT 0.009 (0.245)	loss 6.965 (6.997)	prob 3.049 (2.642)	GS 38.250 (32.814)	mem 73.040
Train: [49][590/1500]	BT 0.031 (0.300)	DT 0.000 (0.259)	loss 6.948 (6.976)	prob 1.609 (2.679)	GS 36.047 (33.345)	mem 73.023
Train: [49][600/1500]	BT 0.036 (0.295)	DT 0.000 (0.255)	loss 7.069 (6.976)	prob 2.566 (2.664)	GS 38.703 (33.225)	mem 73.027
Train: [49][610/1500]	BT 0.034 (0.291)	DT 0.001 (0.251)	loss 6.898 (7.018)	prob 3.320 (2.622)	GS 34.703 (32.573)	mem 73.027
Train: [49][620/1500]	BT 0.032 (0.292)	DT 0.000 (0.252)	loss 6.980 (7.025)	prob 3.163 (2.672)	GS 38.312 (32.929)	mem 73.029
Train: [49][630/1500]	BT 0.039 (0.288)	DT 0.001 (0.248)	loss 7.350 (7.005)	prob 1.625 (2.677)	GS 32.578 (32.601)	mem 73.031
Train: [49][640/1500]	BT 0.069 (0.291)	DT 0.009 (0.251)	loss 7.283 (6.993)	prob 2.415 (2.714)	GS 33.531 (32.541)	mem 73.028
Train: [49][650/1500]	BT 0.038 (0.287)	DT 0.003 (0.247)	loss 7.075 (7.000)	prob 2.868 (2.707)	GS 30.594 (32.407)	mem 73.028
Train: [49][660/1500]	BT 0.031 (0.296)	DT 0.000 (0.256)	loss 7.165 (6.963)	prob 3.635 (2.932)	GS 36.516 (33.194)	mem 73.026
Train: [49][670/1500]	BT 0.033 (0.292)	DT 0.001 (0.252)	loss 7.218 (6.972)	prob 2.781 (2.726)	GS 33.703 (32.834)	mem 73.028
Train: [49][680/1500]	BT 0.040 (0.292)	DT 0.001 (0.253)	loss 7.119 (6.995)	prob 3.210 (2.718)	GS 34.406 (32.627)	mem 73.029
Train: [49][690/1500]	BT 0.039 (0.289)	DT 0.001 (0.249)	loss 7.149 (7.021)	prob 2.095 (2.684)	GS 34.594 (32.897)	mem 73.030
Train: [49][700/1500]	BT 0.039 (0.293)	DT 0.001 (0.254)	loss 6.858 (7.016)	prob 2.606 (2.686)	GS 32.062 (32.681)	mem 73.029
Train: [49][710/1500]	BT 0.038 (0.290)	DT 0.001 (0.250)	loss 7.071 (7.038)	prob 3.155 (2.542)	GS 32.109 (31.553)	mem 73.036
Train: [49][720/1500]	BT 0.037 (0.286)	DT 0.001 (0.247)	loss 7.339 (7.044)	prob 2.678 (2.653)	GS 33.578 (31.945)	mem 73.041
Train: [49][730/1500]	BT 0.036 (0.293)	DT 0.000 (0.254)	loss 7.063 (7.079)	prob 2.322 (2.607)	GS 31.422 (32.155)	mem 73.044
Train: [49][740/1500]	BT 0.036 (0.290)	DT 0.001 (0.250)	loss 7.214 (7.101)	prob 2.627 (2.713)	GS 34.484 (32.240)	mem 73.045
Train: [49][750/1500]	BT 0.054 (0.299)	DT 0.015 (0.259)	loss 7.185 (7.089)	prob 3.139 (2.730)	GS 29.516 (32.553)	mem 73.049
Train: [49][760/1500]	BT 0.060 (0.295)	DT 0.013 (0.256)	loss 7.009 (7.167)	prob 3.467 (2.874)	GS 31.469 (33.217)	mem 73.049
Train: [49][770/1500]	BT 0.049 (0.299)	DT 0.000 (0.259)	loss 7.247 (7.113)	prob 3.346 (2.751)	GS 34.250 (32.747)	mem 73.049
Train: [49][780/1500]	BT 0.052 (0.302)	DT 0.001 (0.263)	loss 6.778 (7.111)	prob 3.103 (2.768)	GS 28.812 (32.211)	mem 73.051
Train: [49][790/1500]	BT 0.049 (0.299)	DT 0.002 (0.259)	loss 7.059 (7.119)	prob 2.831 (2.736)	GS 33.281 (32.315)	mem 73.050
Train: [49][800/1500]	BT 0.084 (0.308)	DT 0.006 (0.267)	loss 7.403 (7.135)	prob 2.608 (2.771)	GS 36.016 (32.241)	mem 73.051
Train: [49][810/1500]	BT 0.029 (0.317)	DT 0.000 (0.277)	loss 7.345 (7.117)	prob 2.313 (2.542)	GS 31.594 (32.148)	mem 73.051
Train: [49][820/1500]	BT 0.035 (0.313)	DT 0.000 (0.273)	loss 7.520 (7.137)	prob 2.592 (2.630)	GS 33.562 (32.108)	mem 73.052
Train: [49][830/1500]	BT 0.037 (0.313)	DT 0.001 (0.273)	loss 7.597 (7.151)	prob 2.248 (2.602)	GS 38.516 (31.726)	mem 73.055
Train: [49][840/1500]	BT 0.037 (0.310)	DT 0.001 (0.270)	loss 7.422 (7.160)	prob 3.288 (2.624)	GS 29.812 (31.561)	mem 73.055
Train: [49][850/1500]	BT 0.030 (0.317)	DT 0.001 (0.277)	loss 7.495 (7.178)	prob 2.723 (2.716)	GS 36.641 (31.747)	mem 73.054
Train: [49][860/1500]	BT 0.026 (0.314)	DT 0.000 (0.274)	loss 7.629 (7.432)	prob 2.885 (2.813)	GS 32.266 (32.303)	mem 73.055
Train: [49][870/1500]	BT 0.031 (0.310)	DT 0.000 (0.271)	loss 7.316 (7.345)	prob 2.575 (2.801)	GS 34.391 (32.814)	mem 73.055
Train: [49][880/1500]	BT 0.031 (0.312)	DT 0.000 (0.272)	loss 7.592 (7.340)	prob 3.067 (2.808)	GS 36.469 (33.033)	mem 73.056
Train: [49][890/1500]	BT 0.038 (0.309)	DT 0.001 (0.269)	loss 7.476 (7.361)	prob 3.017 (2.779)	GS 33.516 (32.932)	mem 73.057
Train: [49][900/1500]	BT 0.037 (0.309)	DT 0.001 (0.270)	loss 7.110 (7.333)	prob 3.612 (2.852)	GS 28.703 (32.763)	mem 73.057
Train: [49][910/1500]	BT 0.037 (0.306)	DT 0.001 (0.267)	loss 7.256 (7.391)	prob 3.038 (2.867)	GS 37.172 (32.691)	mem 73.058
Train: [49][920/1500]	BT 0.077 (0.304)	DT 0.015 (0.264)	loss 7.278 (7.344)	prob 2.787 (2.724)	GS 34.688 (32.453)	mem 73.058
Train: [49][930/1500]	BT 0.028 (0.312)	DT 0.000 (0.273)	loss 7.280 (7.344)	prob 2.438 (2.646)	GS 38.359 (33.170)	mem 73.061
Train: [49][940/1500]	BT 0.026 (0.309)	DT 0.000 (0.270)	loss 7.364 (7.345)	prob 2.525 (2.714)	GS 31.828 (32.682)	mem 73.061
Train: [49][950/1500]	BT 0.067 (0.307)	DT 0.006 (0.267)	loss 7.217 (7.371)	prob 3.403 (2.713)	GS 35.375 (32.577)	mem 73.063
Train: [49][960/1500]	BT 0.060 (0.310)	DT 0.000 (0.270)	loss 7.397 (7.428)	prob 2.634 (2.394)	GS 32.469 (32.692)	mem 73.064
Train: [49][970/1500]	BT 0.037 (0.309)	DT 0.000 (0.269)	loss 7.563 (7.480)	prob 3.007 (2.406)	GS 35.250 (33.159)	mem 73.066
Train: [49][980/1500]	BT 0.037 (0.308)	DT 0.001 (0.268)	loss 7.138 (7.430)	prob 3.526 (2.533)	GS 35.156 (33.229)	mem 73.067
Train: [49][990/1500]	BT 0.037 (0.305)	DT 0.001 (0.266)	loss 7.346 (7.422)	prob 2.604 (2.576)	GS 34.156 (33.170)	mem 73.066
Train: [49][1000/1500]	BT 0.032 (0.307)	DT 0.000 (0.268)	loss 7.106 (7.407)	prob 2.944 (2.616)	GS 29.875 (33.015)	mem 73.069
Train: [49][1010/1500]	BT 0.037 (0.305)	DT 0.001 (0.265)	loss 7.388 (7.367)	prob 2.338 (2.767)	GS 30.609 (32.486)	mem 73.069
Train: [49][1020/1500]	BT 0.031 (0.306)	DT 0.000 (0.267)	loss 7.613 (7.404)	prob 3.400 (2.799)	GS 31.812 (32.367)	mem 73.071
Train: [49][1030/1500]	BT 0.050 (0.304)	DT 0.009 (0.264)	loss 6.766 (7.354)	prob 3.200 (2.872)	GS 32.047 (32.236)	mem 73.072
Train: [49][1040/1500]	BT 0.037 (0.301)	DT 0.001 (0.262)	loss 7.597 (7.444)	prob 2.386 (2.724)	GS 31.484 (32.378)	mem 73.072
Train: [49][1050/1500]	BT 0.031 (0.304)	DT 0.000 (0.265)	loss 7.815 (7.453)	prob 3.177 (2.760)	GS 34.875 (32.633)	mem 73.073
Train: [49][1060/1500]	BT 0.034 (0.302)	DT 0.000 (0.262)	loss 8.517 (7.455)	prob 2.621 (3.140)	GS 31.594 (31.828)	mem 73.071
Train: [49][1070/1500]	BT 0.662 (0.302)	DT 0.624 (0.263)	loss 7.458 (7.476)	prob 3.631 (3.072)	GS 35.406 (32.018)	mem 73.071
Train: [49][1080/1500]	BT 0.039 (0.299)	DT 0.000 (0.260)	loss 7.679 (7.452)	prob 3.028 (3.114)	GS 35.406 (32.038)	mem 73.071
Train: [49][1090/1500]	BT 0.068 (0.301)	DT 0.004 (0.261)	loss 7.820 (7.461)	prob 2.921 (2.964)	GS 31.672 (32.142)	mem 73.072
Train: [49][1100/1500]	BT 0.055 (0.298)	DT 0.006 (0.259)	loss 7.764 (7.482)	prob 2.338 (2.945)	GS 32.156 (31.995)	mem 73.072
Train: [49][1110/1500]	BT 0.037 (0.300)	DT 0.000 (0.260)	loss 7.299 (7.413)	prob 3.661 (2.687)	GS 35.312 (33.830)	mem 73.071
Train: [49][1120/1500]	BT 0.037 (0.299)	DT 0.000 (0.259)	loss 7.807 (7.400)	prob 3.031 (2.977)	GS 36.734 (32.884)	mem 73.072
Train: [49][1130/1500]	BT 1.482 (0.298)	DT 1.445 (0.258)	loss 7.378 (7.367)	prob 3.367 (3.090)	GS 30.875 (32.919)	mem 73.073
Train: [49][1140/1500]	BT 0.038 (0.297)	DT 0.001 (0.257)	loss 6.911 (7.355)	prob 3.586 (3.111)	GS 31.625 (32.846)	mem 73.102
Train: [49][1150/1500]	BT 0.039 (0.296)	DT 0.001 (0.257)	loss 7.464 (7.356)	prob 3.647 (3.101)	GS 37.484 (32.809)	mem 73.102
Train: [49][1160/1500]	BT 0.050 (0.295)	DT 0.001 (0.256)	loss 7.327 (7.283)	prob 3.550 (2.951)	GS 36.438 (31.578)	mem 73.103
Train: [49][1170/1500]	BT 0.039 (0.295)	DT 0.001 (0.255)	loss 7.827 (7.318)	prob 3.358 (3.104)	GS 40.281 (32.581)	mem 73.102
Train: [49][1180/1500]	BT 0.042 (0.295)	DT 0.000 (0.256)	loss 7.150 (7.255)	prob 3.822 (3.188)	GS 33.359 (32.321)	mem 73.105
Train: [49][1190/1500]	BT 0.077 (0.296)	DT 0.005 (0.256)	loss 7.198 (7.268)	prob 3.049 (3.180)	GS 34.594 (32.447)	mem 73.106
Train: [49][1200/1500]	BT 0.038 (0.300)	DT 0.001 (0.260)	loss 7.321 (7.283)	prob 3.295 (3.152)	GS 32.438 (32.629)	mem 73.104
Train: [49][1210/1500]	BT 0.039 (0.298)	DT 0.001 (0.258)	loss 7.176 (7.349)	prob 3.610 (3.236)	GS 33.016 (33.517)	mem 73.104
Train: [49][1220/1500]	BT 0.039 (0.297)	DT 0.001 (0.257)	loss 7.640 (7.268)	prob 3.404 (3.322)	GS 35.375 (33.378)	mem 73.104
Train: [49][1230/1500]	BT 0.039 (0.296)	DT 0.001 (0.256)	loss 7.490 (7.276)	prob 3.368 (3.225)	GS 34.234 (33.116)	mem 73.103
Train: [49][1240/1500]	BT 0.039 (0.294)	DT 0.001 (0.254)	loss 7.292 (7.295)	prob 3.635 (3.251)	GS 37.125 (32.857)	mem 73.104
Train: [49][1250/1500]	BT 0.040 (0.295)	DT 0.001 (0.255)	loss 7.263 (7.291)	prob 3.349 (3.214)	GS 35.344 (32.950)	mem 73.104
Train: [49][1260/1500]	BT 0.039 (0.293)	DT 0.001 (0.253)	loss 7.262 (7.201)	prob 4.101 (3.750)	GS 32.906 (31.191)	mem 73.105
Train: [49][1270/1500]	BT 0.030 (0.294)	DT 0.000 (0.254)	loss 7.333 (7.209)	prob 3.472 (3.454)	GS 34.047 (31.597)	mem 73.105
Train: [49][1280/1500]	BT 0.039 (0.292)	DT 0.001 (0.252)	loss 7.471 (7.253)	prob 3.829 (3.408)	GS 38.906 (32.249)	mem 73.105
Train: [49][1290/1500]	BT 0.025 (0.292)	DT 0.000 (0.252)	loss 7.011 (7.246)	prob 3.076 (3.291)	GS 35.391 (32.586)	mem 73.108
Train: [49][1300/1500]	BT 0.039 (0.293)	DT 0.000 (0.253)	loss 7.173 (7.237)	prob 3.666 (3.322)	GS 31.156 (32.487)	mem 73.110
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [49][1310/1500]	BT 0.039 (0.291)	DT 0.001 (0.251)	loss 7.598 (7.323)	prob 2.834 (3.427)	GS 32.453 (32.467)	mem 73.109
Train: [49][1320/1500]	BT 0.037 (0.293)	DT 0.001 (0.253)	loss 7.311 (7.310)	prob 2.665 (3.098)	GS 32.062 (32.591)	mem 73.111
Train: [49][1330/1500]	BT 0.028 (0.296)	DT 0.000 (0.256)	loss 7.559 (7.300)	prob 3.417 (2.949)	GS 37.281 (32.948)	mem 73.111
Train: [49][1340/1500]	BT 0.038 (0.294)	DT 0.001 (0.255)	loss 7.366 (7.320)	prob 3.508 (2.938)	GS 27.734 (32.755)	mem 73.110
Train: [49][1350/1500]	BT 0.038 (0.297)	DT 0.001 (0.257)	loss 7.538 (7.305)	prob 2.765 (3.015)	GS 36.609 (32.551)	mem 73.112
Train: [49][1360/1500]	BT 0.039 (0.295)	DT 0.001 (0.255)	loss 7.289 (7.167)	prob 3.366 (3.328)	GS 33.109 (34.089)	mem 73.112
Train: [49][1370/1500]	BT 0.039 (0.296)	DT 0.001 (0.256)	loss 7.935 (7.308)	prob 2.379 (2.978)	GS 31.562 (34.108)	mem 73.110
Train: [49][1380/1500]	BT 0.040 (0.294)	DT 0.001 (0.254)	loss 7.680 (7.295)	prob 3.479 (3.058)	GS 29.453 (33.212)	mem 73.110
Train: [49][1390/1500]	BT 0.381 (0.293)	DT 0.342 (0.253)	loss 7.370 (7.296)	prob 2.944 (2.993)	GS 29.516 (32.884)	mem 73.111
Train: [49][1400/1500]	BT 0.057 (0.295)	DT 0.011 (0.255)	loss 7.054 (7.310)	prob 4.092 (2.986)	GS 32.672 (32.779)	mem 73.110
Train: [49][1410/1500]	BT 0.064 (0.295)	DT 0.004 (0.255)	loss 7.760 (7.349)	prob 2.829 (3.184)	GS 33.609 (32.416)	mem 73.110
Train: [49][1420/1500]	BT 0.026 (0.296)	DT 0.000 (0.256)	loss 7.152 (7.298)	prob 3.309 (3.080)	GS 31.844 (33.133)	mem 73.110
Train: [49][1430/1500]	BT 0.040 (0.294)	DT 0.001 (0.255)	loss 7.040 (7.247)	prob 3.664 (3.159)	GS 34.359 (32.733)	mem 73.111
Train: [49][1440/1500]	BT 0.072 (0.295)	DT 0.011 (0.255)	loss 7.580 (7.242)	prob 3.171 (3.184)	GS 33.969 (32.943)	mem 73.109
Train: [49][1450/1500]	BT 0.037 (0.295)	DT 0.001 (0.255)	loss 7.273 (7.231)	prob 3.315 (3.228)	GS 32.750 (32.694)	mem 73.117
Train: [49][1460/1500]	BT 0.037 (0.293)	DT 0.000 (0.253)	loss 7.456 (7.471)	prob 3.658 (2.933)	GS 35.125 (32.430)	mem 73.116
Train: [49][1470/1500]	BT 0.030 (0.293)	DT 0.000 (0.253)	loss 7.019 (7.384)	prob 3.092 (2.945)	GS 32.281 (31.930)	mem 72.507
Train: [49][1480/1500]	BT 0.036 (0.292)	DT 0.001 (0.252)	loss 8.024 (7.380)	prob 2.134 (2.820)	GS 33.984 (31.995)	mem 45.263
Train: [49][1490/1500]	BT 0.036 (0.290)	DT 0.000 (0.250)	loss 7.325 (7.351)	prob 2.306 (2.713)	GS 33.688 (32.028)	mem 20.042
Train: [49][1500/1500]	BT 0.022 (0.289)	DT 0.000 (0.249)	loss 7.088 (7.326)	prob 3.507 (2.723)	GS 27.375 (32.045)	mem 19.258
Train: [49][1510/1500]	BT 0.024 (0.287)	DT 0.000 (0.248)	loss 7.504 (7.396)	prob 1.524 (2.427)	GS 38.562 (35.141)	mem 8.028
epoch 49, total time 434.08
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [50][1/1500]	BT 21.745 (21.745)	DT 21.687 (21.687)	loss 6.813 (6.813)	prob 2.549 (2.549)	GS 27.875 (27.875)	mem 71.746
Train: [50][10/1500]	BT 0.060 (2.210)	DT 0.024 (2.172)	loss 7.788 (7.059)	prob 1.955 (2.482)	GS 33.484 (32.847)	mem 71.750
Train: [50][20/1500]	BT 0.037 (1.124)	DT 0.001 (1.086)	loss 7.566 (7.153)	prob 2.082 (2.444)	GS 33.547 (33.249)	mem 71.751
Train: [50][30/1500]	BT 0.060 (0.925)	DT 0.001 (0.883)	loss 6.863 (7.204)	prob 2.924 (2.580)	GS 31.922 (32.712)	mem 71.787
Train: [50][40/1500]	BT 0.050 (0.709)	DT 0.007 (0.664)	loss 7.684 (7.208)	prob 2.684 (2.641)	GS 30.469 (32.333)	mem 71.789
Train: [50][50/1500]	BT 0.088 (0.691)	DT 0.004 (0.647)	loss 7.490 (7.268)	prob 2.160 (2.629)	GS 35.453 (32.214)	mem 71.800
Train: [50][60/1500]	BT 0.089 (0.627)	DT 0.008 (0.577)	loss 7.612 (7.273)	prob 2.362 (2.727)	GS 34.516 (32.728)	mem 71.801
Train: [50][70/1500]	BT 0.026 (0.773)	DT 0.000 (0.725)	loss 7.647 (7.349)	prob 2.701 (2.684)	GS 31.500 (32.270)	mem 71.813
Train: [50][80/1500]	BT 0.028 (0.680)	DT 0.000 (0.634)	loss 7.431 (7.357)	prob 2.407 (2.613)	GS 35.969 (32.138)	mem 71.813
Train: [50][90/1500]	BT 0.048 (0.654)	DT 0.007 (0.609)	loss 7.576 (7.406)	prob 2.994 (2.571)	GS 38.062 (32.361)	mem 71.819
Train: [50][100/1500]	BT 0.031 (0.593)	DT 0.000 (0.549)	loss 7.592 (7.376)	prob 2.808 (2.625)	GS 32.859 (32.413)	mem 71.819
Train: [50][110/1500]	BT 0.057 (0.542)	DT 0.002 (0.499)	loss 7.563 (7.399)	prob 2.770 (2.671)	GS 33.609 (31.606)	mem 71.820
Train: [50][120/1500]	BT 0.056 (0.558)	DT 0.012 (0.514)	loss 8.635 (7.524)	prob 1.720 (2.522)	GS 35.406 (32.152)	mem 71.830
Train: [50][130/1500]	BT 0.031 (0.518)	DT 0.000 (0.475)	loss 7.475 (7.506)	prob 2.531 (2.400)	GS 37.844 (32.766)	mem 71.830
Train: [50][140/1500]	BT 0.030 (0.599)	DT 0.000 (0.557)	loss 7.358 (7.565)	prob 3.122 (2.324)	GS 31.344 (32.814)	mem 71.837
Train: [50][150/1500]	BT 0.037 (0.561)	DT 0.001 (0.520)	loss 7.392 (7.561)	prob 2.366 (2.390)	GS 32.578 (32.760)	mem 71.838
Train: [50][160/1500]	BT 0.026 (0.545)	DT 0.000 (0.504)	loss 7.880 (7.723)	prob 2.618 (2.286)	GS 29.906 (32.942)	mem 71.840
Train: [50][170/1500]	BT 0.026 (0.514)	DT 0.000 (0.474)	loss 9.093 (7.779)	prob 1.623 (2.206)	GS 35.156 (33.813)	mem 71.847
Train: [50][180/1500]	BT 0.038 (0.511)	DT 0.001 (0.472)	loss 7.767 (7.773)	prob 2.371 (2.175)	GS 32.828 (33.568)	mem 71.849
Train: [50][190/1500]	BT 0.038 (0.486)	DT 0.001 (0.447)	loss 8.008 (7.703)	prob 2.628 (2.357)	GS 33.734 (33.223)	mem 71.848
Train: [50][200/1500]	BT 0.039 (0.464)	DT 0.001 (0.425)	loss 7.349 (7.669)	prob 2.734 (2.456)	GS 34.766 (33.065)	mem 71.849
Train: [50][210/1500]	BT 0.054 (0.461)	DT 0.011 (0.421)	loss 7.901 (7.639)	prob 2.094 (2.320)	GS 34.609 (33.395)	mem 72.207
Train: [50][220/1500]	BT 0.060 (0.443)	DT 0.016 (0.403)	loss 7.954 (7.609)	prob 3.233 (2.599)	GS 35.375 (33.029)	mem 72.256
Train: [50][230/1500]	BT 0.072 (0.459)	DT 0.014 (0.418)	loss 7.987 (7.637)	prob 3.160 (2.726)	GS 35.953 (32.961)	mem 72.849
Train: [50][240/1500]	BT 0.044 (0.490)	DT 0.000 (0.449)	loss 7.801 (7.654)	prob 1.837 (2.706)	GS 31.188 (33.352)	mem 73.000
Train: [50][250/1500]	BT 0.082 (0.474)	DT 0.000 (0.432)	loss 7.691 (7.679)	prob 2.905 (2.698)	GS 35.203 (33.625)	mem 73.000
Train: [50][260/1500]	BT 0.027 (0.537)	DT 0.000 (0.496)	loss 7.729 (7.604)	prob 2.771 (2.959)	GS 35.703 (33.355)	mem 73.051
Train: [50][270/1500]	BT 0.034 (0.518)	DT 0.000 (0.477)	loss 8.100 (7.667)	prob 3.536 (3.088)	GS 28.031 (32.904)	mem 73.053
Train: [50][280/1500]	BT 0.034 (0.511)	DT 0.000 (0.470)	loss 7.871 (7.679)	prob 2.719 (3.100)	GS 32.375 (33.013)	mem 73.057
Train: [50][290/1500]	BT 0.030 (0.495)	DT 0.000 (0.455)	loss 7.612 (7.686)	prob 3.624 (3.039)	GS 30.547 (32.696)	mem 73.057
Train: [50][300/1500]	BT 0.038 (0.493)	DT 0.001 (0.452)	loss 7.738 (7.719)	prob 3.760 (3.010)	GS 31.266 (32.976)	mem 73.062
Train: [50][310/1500]	BT 1.189 (0.482)	DT 1.151 (0.441)	loss 7.629 (7.665)	prob 3.315 (3.065)	GS 31.438 (33.264)	mem 73.063
Train: [50][320/1500]	BT 0.037 (0.468)	DT 0.000 (0.428)	loss 7.209 (7.688)	prob 3.851 (3.156)	GS 34.031 (32.730)	mem 73.063
Train: [50][330/1500]	BT 0.036 (0.466)	DT 0.001 (0.426)	loss 7.601 (7.712)	prob 4.138 (3.279)	GS 32.391 (32.526)	mem 73.066
Train: [50][340/1500]	BT 0.037 (0.453)	DT 0.000 (0.413)	loss 8.487 (7.719)	prob 3.273 (3.279)	GS 33.234 (32.509)	mem 73.066
Train: [50][350/1500]	BT 0.037 (0.478)	DT 0.000 (0.438)	loss 7.690 (7.726)	prob 3.503 (3.291)	GS 35.156 (32.963)	mem 73.067
Train: [50][360/1500]	BT 0.047 (0.466)	DT 0.011 (0.426)	loss 7.769 (7.571)	prob 4.014 (3.469)	GS 32.422 (33.312)	mem 73.067
Train: [50][370/1500]	BT 0.027 (0.483)	DT 0.000 (0.443)	loss 7.661 (7.603)	prob 4.449 (3.604)	GS 30.000 (33.146)	mem 73.069
Train: [50][380/1500]	BT 0.030 (0.471)	DT 0.000 (0.432)	loss 8.564 (7.651)	prob 2.971 (3.574)	GS 36.344 (32.972)	mem 73.070
Train: [50][390/1500]	BT 3.103 (0.468)	DT 3.063 (0.428)	loss 7.962 (7.652)	prob 4.495 (3.625)	GS 35.875 (32.927)	mem 73.073
Train: [50][400/1500]	BT 0.038 (0.457)	DT 0.001 (0.418)	loss 8.086 (7.638)	prob 3.710 (3.671)	GS 38.438 (32.933)	mem 73.075
Train: [50][410/1500]	BT 0.037 (0.447)	DT 0.001 (0.407)	loss 7.315 (7.524)	prob 3.307 (3.387)	GS 30.266 (32.897)	mem 73.074
Train: [50][420/1500]	BT 0.024 (0.448)	DT 0.000 (0.409)	loss 7.195 (7.532)	prob 4.372 (3.518)	GS 31.672 (33.135)	mem 73.076
Train: [50][430/1500]	BT 0.038 (0.438)	DT 0.000 (0.399)	loss 7.659 (7.578)	prob 3.537 (3.627)	GS 34.969 (32.631)	mem 73.077
Train: [50][440/1500]	BT 0.037 (0.435)	DT 0.001 (0.397)	loss 7.762 (7.629)	prob 4.128 (3.608)	GS 37.578 (32.462)	mem 73.079
Train: [50][450/1500]	BT 0.038 (0.426)	DT 0.000 (0.388)	loss 7.152 (7.609)	prob 4.734 (3.564)	GS 33.094 (32.532)	mem 73.080
Train: [50][460/1500]	BT 0.037 (0.418)	DT 0.000 (0.379)	loss 8.489 (7.640)	prob 3.096 (3.564)	GS 32.875 (33.462)	mem 73.080
Train: [50][470/1500]	BT 0.038 (0.420)	DT 0.000 (0.381)	loss 7.691 (7.589)	prob 4.408 (3.493)	GS 36.031 (32.898)	mem 73.082
Train: [50][480/1500]	BT 0.037 (0.412)	DT 0.001 (0.373)	loss 7.262 (7.555)	prob 4.078 (3.635)	GS 32.281 (32.472)	mem 73.081
Train: [50][490/1500]	BT 0.037 (0.413)	DT 0.000 (0.374)	loss 7.574 (7.549)	prob 3.596 (3.645)	GS 34.469 (32.812)	mem 73.085
Train: [50][500/1500]	BT 0.036 (0.405)	DT 0.000 (0.367)	loss 7.827 (7.553)	prob 3.898 (3.636)	GS 32.859 (32.819)	mem 73.085
Train: [50][510/1500]	BT 4.783 (0.407)	DT 4.736 (0.369)	loss 7.405 (7.505)	prob 4.127 (3.884)	GS 31.500 (32.616)	mem 73.084
Train: [50][520/1500]	BT 0.052 (0.407)	DT 0.012 (0.368)	loss 8.153 (7.593)	prob 3.468 (3.777)	GS 33.781 (32.398)	mem 73.085
Train: [50][530/1500]	BT 0.031 (0.400)	DT 0.001 (0.361)	loss 7.461 (7.576)	prob 3.886 (3.679)	GS 34.391 (32.884)	mem 73.085
Train: [50][540/1500]	BT 0.060 (0.409)	DT 0.011 (0.370)	loss 7.446 (7.564)	prob 3.799 (3.721)	GS 30.156 (32.741)	mem 73.086
Train: [50][550/1500]	BT 0.035 (0.403)	DT 0.000 (0.364)	loss 7.414 (7.540)	prob 4.278 (3.805)	GS 35.516 (32.507)	mem 73.088
Train: [50][560/1500]	BT 0.028 (0.419)	DT 0.000 (0.380)	loss 7.792 (7.465)	prob 4.146 (4.077)	GS 34.734 (33.141)	mem 73.088
Train: [50][570/1500]	BT 0.030 (0.412)	DT 0.000 (0.373)	loss 7.655 (7.424)	prob 3.428 (3.822)	GS 37.031 (33.681)	mem 73.088
Train: [50][580/1500]	BT 0.037 (0.405)	DT 0.000 (0.367)	loss 7.153 (7.453)	prob 5.311 (3.801)	GS 32.859 (33.368)	mem 73.091
Train: [50][590/1500]	BT 0.026 (0.406)	DT 0.000 (0.367)	loss 7.616 (7.464)	prob 4.030 (3.888)	GS 35.125 (33.130)	mem 73.094
Train: [50][600/1500]	BT 0.037 (0.400)	DT 0.001 (0.361)	loss 7.199 (7.445)	prob 3.942 (3.846)	GS 34.953 (33.144)	mem 73.095
Train: [50][610/1500]	BT 0.054 (0.403)	DT 0.015 (0.364)	loss 8.123 (7.592)	prob 3.576 (3.651)	GS 37.328 (32.847)	mem 73.127
Train: [50][620/1500]	BT 0.038 (0.397)	DT 0.000 (0.359)	loss 7.039 (7.496)	prob 4.016 (3.834)	GS 34.422 (32.316)	mem 73.126
Train: [50][630/1500]	BT 0.035 (0.401)	DT 0.000 (0.363)	loss 7.588 (7.530)	prob 3.791 (3.832)	GS 34.984 (32.530)	mem 73.125
Train: [50][640/1500]	BT 0.038 (0.395)	DT 0.001 (0.357)	loss 7.765 (7.527)	prob 3.827 (3.894)	GS 31.375 (32.539)	mem 73.126
Train: [50][650/1500]	BT 0.038 (0.390)	DT 0.000 (0.351)	loss 7.384 (7.494)	prob 3.804 (3.871)	GS 32.984 (32.390)	mem 73.126
Train: [50][660/1500]	BT 0.047 (0.397)	DT 0.001 (0.359)	loss 7.860 (7.527)	prob 3.970 (4.094)	GS 35.422 (31.703)	mem 73.126
Train: [50][670/1500]	BT 0.040 (0.407)	DT 0.000 (0.368)	loss 7.535 (7.488)	prob 4.360 (4.171)	GS 35.703 (31.623)	mem 73.127
Train: [50][680/1500]	BT 0.031 (0.402)	DT 0.000 (0.363)	loss 7.167 (7.472)	prob 3.728 (4.121)	GS 32.328 (31.625)	mem 73.128
Train: [50][690/1500]	BT 4.155 (0.402)	DT 4.102 (0.364)	loss 7.554 (7.439)	prob 3.701 (4.084)	GS 33.516 (31.730)	mem 73.130
Train: [50][700/1500]	BT 0.063 (0.397)	DT 0.013 (0.359)	loss 7.625 (7.460)	prob 3.424 (3.977)	GS 34.500 (31.814)	mem 73.130
Train: [50][710/1500]	BT 0.081 (0.393)	DT 0.001 (0.354)	loss 7.438 (7.424)	prob 3.632 (3.564)	GS 36.406 (33.188)	mem 73.129
Train: [50][720/1500]	BT 0.033 (0.408)	DT 0.000 (0.369)	loss 7.655 (7.403)	prob 4.258 (3.695)	GS 33.781 (32.498)	mem 73.130
Train: [50][730/1500]	BT 0.031 (0.403)	DT 0.000 (0.364)	loss 7.835 (7.393)	prob 3.313 (3.583)	GS 34.172 (32.216)	mem 73.131
Train: [50][740/1500]	BT 0.038 (0.398)	DT 0.001 (0.359)	loss 7.287 (7.374)	prob 3.260 (3.613)	GS 36.969 (32.612)	mem 73.132
Train: [50][750/1500]	BT 0.038 (0.399)	DT 0.001 (0.359)	loss 7.364 (7.375)	prob 3.606 (3.636)	GS 28.656 (32.311)	mem 73.134
Train: [50][760/1500]	BT 0.040 (0.394)	DT 0.003 (0.355)	loss 7.212 (7.390)	prob 4.236 (3.646)	GS 34.844 (31.328)	mem 73.134
Train: [50][770/1500]	BT 0.060 (0.400)	DT 0.007 (0.361)	loss 7.258 (7.336)	prob 3.465 (3.538)	GS 34.516 (33.064)	mem 73.132
Train: [50][780/1500]	BT 0.026 (0.395)	DT 0.000 (0.356)	loss 7.245 (7.336)	prob 4.062 (3.515)	GS 32.344 (32.905)	mem 73.132
Train: [50][790/1500]	BT 0.043 (0.395)	DT 0.001 (0.356)	loss 7.419 (7.353)	prob 3.553 (3.535)	GS 35.422 (32.945)	mem 73.133
Train: [50][800/1500]	BT 0.035 (0.391)	DT 0.000 (0.352)	loss 7.177 (7.334)	prob 3.818 (3.489)	GS 28.281 (32.668)	mem 73.134
Train: [50][810/1500]	BT 0.029 (0.394)	DT 0.000 (0.355)	loss 7.213 (7.194)	prob 3.809 (3.535)	GS 34.953 (32.061)	mem 73.136
Train: [50][820/1500]	BT 0.030 (0.389)	DT 0.000 (0.350)	loss 7.378 (7.229)	prob 3.650 (3.519)	GS 32.906 (32.208)	mem 73.136
Train: [50][830/1500]	BT 0.051 (0.391)	DT 0.000 (0.352)	loss 7.899 (7.242)	prob 3.527 (3.466)	GS 33.828 (32.382)	mem 73.136
Train: [50][840/1500]	BT 0.031 (0.387)	DT 0.000 (0.348)	loss 6.848 (7.230)	prob 3.195 (3.431)	GS 33.594 (32.554)	mem 73.135
Train: [50][850/1500]	BT 0.065 (0.383)	DT 0.011 (0.344)	loss 7.032 (7.226)	prob 4.096 (3.491)	GS 30.484 (32.342)	mem 73.135
Train: [50][860/1500]	BT 0.035 (0.395)	DT 0.001 (0.357)	loss 7.391 (7.320)	prob 2.310 (3.131)	GS 39.109 (33.655)	mem 73.138
Train: [50][870/1500]	BT 0.025 (0.391)	DT 0.000 (0.353)	loss 7.359 (7.304)	prob 3.183 (3.023)	GS 34.594 (33.293)	mem 73.139
Train: [50][880/1500]	BT 0.031 (0.392)	DT 0.000 (0.353)	loss 7.062 (7.293)	prob 2.982 (3.029)	GS 36.797 (33.977)	mem 73.140
Train: [50][890/1500]	BT 0.027 (0.388)	DT 0.000 (0.349)	loss 7.359 (7.308)	prob 3.384 (2.984)	GS 32.188 (33.808)	mem 73.139
Train: [50][900/1500]	BT 0.030 (0.389)	DT 0.000 (0.351)	loss 7.605 (7.296)	prob 3.114 (2.999)	GS 33.250 (33.474)	mem 73.142
Train: [50][910/1500]	BT 0.056 (0.385)	DT 0.025 (0.347)	loss 7.157 (7.229)	prob 3.768 (3.134)	GS 34.328 (32.983)	mem 73.145
Train: [50][920/1500]	BT 0.035 (0.381)	DT 0.000 (0.343)	loss 7.333 (7.258)	prob 2.910 (3.082)	GS 34.359 (32.935)	mem 73.149
Train: [50][930/1500]	BT 0.033 (0.381)	DT 0.000 (0.343)	loss 7.667 (7.308)	prob 2.039 (2.905)	GS 34.078 (33.084)	mem 73.161
Train: [50][940/1500]	BT 0.029 (0.377)	DT 0.000 (0.339)	loss 7.384 (7.321)	prob 3.244 (2.814)	GS 30.625 (32.827)	mem 73.162
Train: [50][950/1500]	BT 0.038 (0.377)	DT 0.001 (0.338)	loss 8.091 (7.348)	prob 2.611 (2.877)	GS 34.266 (32.803)	mem 73.138
Train: [50][960/1500]	BT 0.037 (0.373)	DT 0.000 (0.335)	loss 7.429 (7.424)	prob 3.113 (2.635)	GS 30.109 (32.087)	mem 73.157
Train: [50][970/1500]	BT 0.035 (0.370)	DT 0.000 (0.331)	loss 7.863 (7.422)	prob 2.078 (2.446)	GS 35.312 (32.639)	mem 73.157
Train: [50][980/1500]	BT 0.030 (0.375)	DT 0.000 (0.337)	loss 7.205 (7.383)	prob 3.223 (2.518)	GS 33.500 (32.436)	mem 73.038
Train: [50][990/1500]	BT 15.067 (0.387)	DT 15.026 (0.349)	loss 7.874 (7.371)	prob 2.613 (2.588)	GS 37.406 (32.678)	mem 73.058
Train: [50][1000/1500]	BT 0.030 (0.383)	DT 0.000 (0.345)	loss 7.056 (7.394)	prob 3.311 (2.580)	GS 31.484 (32.763)	mem 73.059
Train: [50][1010/1500]	BT 0.028 (0.380)	DT 0.000 (0.342)	loss 7.759 (7.550)	prob 2.164 (2.354)	GS 31.734 (33.430)	mem 73.060
Train: [50][1020/1500]	BT 0.030 (0.381)	DT 0.000 (0.343)	loss 7.670 (7.504)	prob 2.717 (2.635)	GS 31.281 (31.847)	mem 73.060
Train: [50][1030/1500]	BT 0.038 (0.378)	DT 0.001 (0.340)	loss 7.257 (7.459)	prob 3.825 (2.650)	GS 35.625 (32.099)	mem 73.061
Train: [50][1040/1500]	BT 0.035 (0.377)	DT 0.001 (0.339)	loss 7.439 (7.479)	prob 2.827 (2.625)	GS 35.891 (32.333)	mem 73.060
Train: [50][1050/1500]	BT 0.028 (0.374)	DT 0.000 (0.336)	loss 7.998 (7.512)	prob 2.172 (2.628)	GS 30.625 (32.406)	mem 73.060
Train: [50][1060/1500]	BT 0.037 (0.371)	DT 0.001 (0.333)	loss 7.125 (7.424)	prob 3.472 (2.688)	GS 34.109 (34.153)	mem 73.062
Train: [50][1070/1500]	BT 0.037 (0.370)	DT 0.001 (0.332)	loss 7.355 (7.505)	prob 3.009 (2.890)	GS 34.344 (32.945)	mem 73.061
Train: [50][1080/1500]	BT 0.058 (0.367)	DT 0.022 (0.329)	loss 7.791 (7.523)	prob 2.822 (2.847)	GS 34.500 (32.443)	mem 73.061
Train: [50][1090/1500]	BT 0.028 (0.367)	DT 0.000 (0.329)	loss 7.967 (7.567)	prob 2.179 (2.712)	GS 32.781 (32.394)	mem 73.066
Train: [50][1100/1500]	BT 0.037 (0.365)	DT 0.001 (0.327)	loss 7.567 (7.577)	prob 3.856 (2.824)	GS 33.188 (32.072)	mem 73.087
Train: [50][1110/1500]	BT 1.093 (0.363)	DT 1.055 (0.325)	loss 7.574 (7.539)	prob 2.737 (2.766)	GS 32.797 (33.228)	mem 73.089
Train: [50][1120/1500]	BT 0.070 (0.364)	DT 0.016 (0.326)	loss 7.446 (7.534)	prob 3.106 (2.804)	GS 33.672 (33.094)	mem 73.088
Train: [50][1130/1500]	BT 0.052 (0.363)	DT 0.013 (0.325)	loss 7.439 (7.551)	prob 2.762 (2.787)	GS 32.859 (33.442)	mem 73.088
Train: [50][1140/1500]	BT 0.072 (0.364)	DT 0.003 (0.326)	loss 7.694 (7.566)	prob 4.194 (2.866)	GS 32.328 (33.022)	mem 73.073
Train: [50][1150/1500]	BT 0.039 (0.364)	DT 0.001 (0.326)	loss 7.478 (7.566)	prob 3.070 (2.922)	GS 33.766 (32.947)	mem 73.070
Train: [50][1160/1500]	BT 0.038 (0.364)	DT 0.001 (0.326)	loss 7.785 (7.666)	prob 3.351 (3.187)	GS 35.828 (35.120)	mem 73.070
Train: [50][1170/1500]	BT 0.040 (0.362)	DT 0.001 (0.323)	loss 7.942 (7.605)	prob 3.639 (3.215)	GS 31.359 (33.862)	mem 73.070
Train: [50][1180/1500]	BT 0.038 (0.363)	DT 0.000 (0.325)	loss 7.308 (7.561)	prob 3.984 (3.372)	GS 33.688 (32.871)	mem 73.069
Train: [50][1190/1500]	BT 0.038 (0.360)	DT 0.001 (0.322)	loss 7.671 (7.593)	prob 3.591 (3.370)	GS 31.969 (32.848)	mem 73.070
Train: [50][1200/1500]	BT 2.815 (0.360)	DT 2.777 (0.322)	loss 7.767 (7.619)	prob 3.550 (3.359)	GS 34.516 (32.767)	mem 73.070
Train: [50][1210/1500]	BT 0.038 (0.357)	DT 0.001 (0.319)	loss 7.220 (7.537)	prob 3.727 (3.383)	GS 34.438 (33.580)	mem 73.070
Train: [50][1220/1500]	BT 0.036 (0.357)	DT 0.001 (0.319)	loss 8.079 (7.611)	prob 2.787 (3.220)	GS 34.781 (33.888)	mem 73.073
Train: [50][1230/1500]	BT 0.037 (0.355)	DT 0.001 (0.316)	loss 7.380 (7.614)	prob 4.422 (3.331)	GS 33.641 (33.305)	mem 73.074
Train: [50][1240/1500]	BT 0.031 (0.360)	DT 0.000 (0.322)	loss 7.865 (7.633)	prob 3.638 (3.350)	GS 37.469 (33.885)	mem 73.073
Train: [50][1250/1500]	BT 0.026 (0.357)	DT 0.000 (0.319)	loss 7.578 (7.616)	prob 4.083 (3.357)	GS 32.078 (33.614)	mem 73.075
Train: [50][1260/1500]	BT 0.037 (0.354)	DT 0.001 (0.316)	loss 7.641 (7.629)	prob 3.722 (3.440)	GS 33.625 (32.039)	mem 73.075
Train: [50][1270/1500]	BT 0.048 (0.355)	DT 0.001 (0.317)	loss 7.852 (7.561)	prob 3.971 (3.593)	GS 35.234 (32.263)	mem 73.077
Train: [50][1280/1500]	BT 0.031 (0.353)	DT 0.000 (0.315)	loss 7.461 (7.544)	prob 4.510 (3.680)	GS 33.062 (32.334)	mem 73.077
Train: [50][1290/1500]	BT 0.056 (0.358)	DT 0.013 (0.320)	loss 7.614 (7.515)	prob 3.855 (3.669)	GS 34.047 (32.233)	mem 73.077
Train: [50][1300/1500]	BT 5.369 (0.360)	DT 5.331 (0.322)	loss 7.986 (7.534)	prob 3.458 (3.641)	GS 33.266 (32.252)	mem 73.090
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [50][1310/1500]	BT 0.039 (0.357)	DT 0.000 (0.319)	loss 7.174 (7.366)	prob 4.283 (3.652)	GS 33.938 (31.691)	mem 73.091
Train: [50][1320/1500]	BT 0.037 (0.355)	DT 0.000 (0.317)	loss 7.642 (7.454)	prob 3.830 (3.571)	GS 34.812 (32.670)	mem 73.094
Train: [50][1330/1500]	BT 0.040 (0.355)	DT 0.001 (0.318)	loss 7.195 (7.460)	prob 4.487 (3.610)	GS 30.562 (32.439)	mem 73.098
Train: [50][1340/1500]	BT 0.058 (0.353)	DT 0.011 (0.315)	loss 8.176 (7.464)	prob 3.519 (3.739)	GS 32.969 (32.163)	mem 73.098
Train: [50][1350/1500]	BT 0.057 (0.355)	DT 0.001 (0.317)	loss 7.382 (7.454)	prob 3.995 (3.751)	GS 35.453 (32.558)	mem 73.097
Train: [50][1360/1500]	BT 0.031 (0.357)	DT 0.000 (0.319)	loss 8.392 (7.450)	prob 2.699 (3.673)	GS 36.734 (34.622)	mem 73.097
Train: [50][1370/1500]	BT 0.037 (0.355)	DT 0.001 (0.317)	loss 7.940 (7.521)	prob 3.895 (3.670)	GS 29.844 (33.505)	mem 73.097
Train: [50][1380/1500]	BT 0.036 (0.353)	DT 0.001 (0.315)	loss 7.298 (7.518)	prob 4.825 (3.775)	GS 32.000 (33.175)	mem 73.098
Train: [50][1390/1500]	BT 0.066 (0.355)	DT 0.015 (0.317)	loss 7.293 (7.510)	prob 3.697 (3.777)	GS 33.031 (33.225)	mem 73.095
Train: [50][1400/1500]	BT 0.061 (0.353)	DT 0.003 (0.315)	loss 7.554 (7.480)	prob 4.225 (3.802)	GS 35.078 (33.049)	mem 73.097
Train: [50][1410/1500]	BT 0.039 (0.354)	DT 0.001 (0.316)	loss 7.498 (7.436)	prob 4.022 (4.082)	GS 32.859 (31.570)	mem 73.097
Train: [50][1420/1500]	BT 0.034 (0.361)	DT 0.000 (0.323)	loss 7.816 (7.428)	prob 2.649 (3.781)	GS 32.500 (32.738)	mem 73.100
Train: [50][1430/1500]	BT 0.030 (0.359)	DT 0.000 (0.321)	loss 7.469 (7.411)	prob 4.265 (3.816)	GS 27.594 (32.664)	mem 73.100
Train: [50][1440/1500]	BT 3.143 (0.359)	DT 3.073 (0.321)	loss 7.204 (7.465)	prob 4.432 (3.831)	GS 30.891 (33.058)	mem 73.104
Train: [50][1450/1500]	BT 0.056 (0.357)	DT 0.002 (0.318)	loss 7.773 (7.475)	prob 4.246 (3.928)	GS 34.922 (32.525)	mem 73.103
Train: [50][1460/1500]	BT 0.031 (0.355)	DT 0.000 (0.316)	loss 8.185 (7.559)	prob 3.767 (4.083)	GS 33.359 (31.242)	mem 73.103
Train: [50][1470/1500]	BT 0.018 (0.357)	DT 0.000 (0.319)	loss 7.202 (7.478)	prob 4.674 (3.934)	GS 34.266 (32.027)	mem 71.897
Train: [50][1480/1500]	BT 0.024 (0.355)	DT 0.000 (0.317)	loss 7.586 (7.445)	prob 3.899 (3.971)	GS 31.828 (31.949)	mem 71.897
Train: [50][1490/1500]	BT 0.029 (0.354)	DT 0.000 (0.316)	loss 7.149 (7.448)	prob 4.398 (3.959)	GS 29.688 (32.056)	mem 8.084
Train: [50][1500/1500]	BT 0.027 (0.352)	DT 0.000 (0.314)	loss 7.558 (7.435)	prob 3.973 (3.983)	GS 30.000 (32.074)	mem 8.084
Train: [50][1510/1500]	BT 0.032 (0.350)	DT 0.000 (0.312)	loss 7.228 (7.174)	prob 4.436 (4.374)	GS 33.438 (32.459)	mem 8.084
epoch 50, total time 529.09
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [51][1/1500]	BT 17.548 (17.548)	DT 17.492 (17.492)	loss 7.137 (7.137)	prob 4.836 (4.836)	GS 33.797 (33.797)	mem 71.499
Train: [51][10/1500]	BT 0.038 (2.415)	DT 0.000 (2.373)	loss 6.924 (7.271)	prob 3.292 (3.665)	GS 30.500 (33.106)	mem 71.722
Train: [51][20/1500]	BT 0.056 (1.311)	DT 0.005 (1.273)	loss 7.310 (7.311)	prob 4.702 (3.838)	GS 32.375 (33.049)	mem 71.760
Train: [51][30/1500]	BT 0.037 (0.961)	DT 0.000 (0.923)	loss 7.766 (7.292)	prob 4.024 (3.886)	GS 30.188 (32.750)	mem 71.785
Train: [51][40/1500]	BT 0.038 (0.744)	DT 0.001 (0.706)	loss 7.516 (7.304)	prob 3.703 (3.867)	GS 32.641 (32.728)	mem 71.788
Train: [51][50/1500]	BT 2.219 (0.646)	DT 2.183 (0.608)	loss 7.597 (7.337)	prob 3.795 (3.850)	GS 33.344 (32.686)	mem 71.793
Train: [51][60/1500]	BT 0.028 (0.587)	DT 0.000 (0.550)	loss 7.853 (7.507)	prob 3.271 (3.548)	GS 34.734 (33.181)	mem 71.813
Train: [51][70/1500]	BT 0.037 (0.508)	DT 0.001 (0.472)	loss 7.443 (7.466)	prob 4.026 (3.546)	GS 31.219 (32.911)	mem 71.814
Train: [51][80/1500]	BT 1.389 (0.527)	DT 1.351 (0.491)	loss 7.575 (7.422)	prob 3.808 (3.669)	GS 33.078 (32.093)	mem 71.824
Train: [51][90/1500]	BT 0.027 (0.472)	DT 0.000 (0.436)	loss 7.440 (7.427)	prob 4.301 (3.721)	GS 35.219 (32.122)	mem 71.828
Train: [51][100/1500]	BT 0.037 (0.429)	DT 0.001 (0.393)	loss 7.451 (7.406)	prob 3.741 (3.689)	GS 32.203 (32.328)	mem 71.833
Train: [51][110/1500]	BT 0.037 (0.435)	DT 0.000 (0.399)	loss 7.842 (7.501)	prob 3.523 (3.833)	GS 31.562 (31.914)	mem 71.845
Train: [51][120/1500]	BT 0.037 (0.402)	DT 0.000 (0.365)	loss 7.324 (7.467)	prob 3.287 (3.789)	GS 32.391 (32.113)	mem 71.846
Train: [51][130/1500]	BT 0.039 (0.394)	DT 0.000 (0.357)	loss 7.350 (7.418)	prob 3.542 (3.644)	GS 31.078 (32.205)	mem 71.875
Train: [51][140/1500]	BT 0.036 (0.377)	DT 0.001 (0.341)	loss 7.778 (7.436)	prob 2.709 (3.464)	GS 35.531 (32.801)	mem 71.877
Train: [51][150/1500]	BT 0.039 (0.365)	DT 0.001 (0.328)	loss 7.466 (7.428)	prob 3.507 (3.358)	GS 32.781 (32.813)	mem 71.877
Train: [51][160/1500]	BT 0.039 (0.366)	DT 0.001 (0.329)	loss 7.310 (7.283)	prob 4.003 (3.186)	GS 37.312 (32.900)	mem 71.884
Train: [51][170/1500]	BT 0.039 (0.349)	DT 0.001 (0.312)	loss 7.172 (7.272)	prob 3.055 (3.203)	GS 35.188 (32.476)	mem 71.934
Train: [51][180/1500]	BT 0.040 (0.385)	DT 0.001 (0.348)	loss 7.486 (7.297)	prob 3.438 (3.003)	GS 32.938 (33.210)	mem 72.866
Train: [51][190/1500]	BT 0.040 (0.367)	DT 0.000 (0.330)	loss 7.257 (7.324)	prob 3.456 (3.015)	GS 31.594 (32.935)	mem 72.867
Train: [51][200/1500]	BT 0.039 (0.350)	DT 0.001 (0.313)	loss 7.833 (7.345)	prob 3.144 (3.026)	GS 29.672 (33.033)	mem 72.917
Train: [51][210/1500]	BT 0.039 (0.368)	DT 0.001 (0.331)	loss 7.796 (7.299)	prob 2.401 (3.162)	GS 32.734 (31.661)	mem 73.067
Train: [51][220/1500]	BT 0.039 (0.353)	DT 0.001 (0.316)	loss 7.594 (7.323)	prob 2.367 (2.971)	GS 40.688 (33.280)	mem 73.066
Train: [51][230/1500]	BT 0.028 (0.359)	DT 0.000 (0.322)	loss 7.601 (7.333)	prob 2.789 (2.806)	GS 31.219 (33.239)	mem 73.067
Train: [51][240/1500]	BT 0.039 (0.345)	DT 0.001 (0.308)	loss 7.648 (7.334)	prob 2.955 (2.808)	GS 32.953 (33.139)	mem 73.067
Train: [51][250/1500]	BT 0.028 (0.350)	DT 0.000 (0.313)	loss 6.914 (7.322)	prob 2.513 (2.754)	GS 30.469 (33.154)	mem 73.071
Train: [51][260/1500]	BT 0.038 (0.338)	DT 0.001 (0.301)	loss 7.498 (7.391)	prob 2.948 (2.684)	GS 36.281 (32.722)	mem 73.072
Train: [51][270/1500]	BT 0.039 (0.327)	DT 0.001 (0.290)	loss 7.772 (7.373)	prob 2.331 (2.688)	GS 35.578 (32.250)	mem 73.072
Train: [51][280/1500]	BT 0.036 (0.327)	DT 0.001 (0.290)	loss 7.941 (7.412)	prob 2.222 (2.521)	GS 32.609 (32.152)	mem 73.073
Train: [51][290/1500]	BT 0.039 (0.317)	DT 0.001 (0.280)	loss 7.626 (7.433)	prob 2.319 (2.437)	GS 36.984 (32.036)	mem 73.074
Train: [51][300/1500]	BT 0.039 (0.317)	DT 0.001 (0.281)	loss 7.480 (7.430)	prob 2.074 (2.413)	GS 32.297 (32.153)	mem 73.076
Train: [51][310/1500]	BT 0.039 (0.308)	DT 0.001 (0.272)	loss 7.716 (7.557)	prob 2.153 (2.027)	GS 35.750 (32.839)	mem 73.076
Train: [51][320/1500]	BT 2.164 (0.307)	DT 2.115 (0.270)	loss 7.395 (7.582)	prob 2.623 (2.120)	GS 32.344 (32.797)	mem 73.076
Train: [51][330/1500]	BT 0.038 (0.320)	DT 0.001 (0.283)	loss 7.167 (7.529)	prob 2.776 (2.316)	GS 31.125 (32.741)	mem 73.077
Train: [51][340/1500]	BT 0.051 (0.312)	DT 0.016 (0.275)	loss 7.289 (7.502)	prob 2.011 (2.319)	GS 35.469 (32.754)	mem 73.078
Train: [51][350/1500]	BT 0.039 (0.317)	DT 0.001 (0.280)	loss 7.802 (7.510)	prob 2.358 (2.242)	GS 35.328 (32.871)	mem 73.081
Train: [51][360/1500]	BT 0.040 (0.310)	DT 0.001 (0.272)	loss 7.907 (7.668)	prob 2.409 (2.134)	GS 35.188 (33.256)	mem 73.081
Train: [51][370/1500]	BT 0.037 (0.310)	DT 0.000 (0.272)	loss 7.671 (7.650)	prob 2.151 (2.062)	GS 31.531 (33.301)	mem 73.082
Train: [51][380/1500]	BT 0.038 (0.305)	DT 0.000 (0.267)	loss 8.290 (7.675)	prob 2.529 (2.312)	GS 35.234 (32.952)	mem 73.081
Train: [51][390/1500]	BT 0.038 (0.299)	DT 0.001 (0.261)	loss 8.045 (7.682)	prob 2.406 (2.359)	GS 34.375 (32.830)	mem 73.080
Train: [51][400/1500]	BT 0.037 (0.302)	DT 0.001 (0.265)	loss 8.321 (7.680)	prob 2.763 (2.433)	GS 31.922 (32.800)	mem 73.090
Train: [51][410/1500]	BT 0.037 (0.296)	DT 0.001 (0.259)	loss 8.405 (7.691)	prob 2.614 (2.576)	GS 34.594 (31.172)	mem 73.099
Train: [51][420/1500]	BT 0.033 (0.324)	DT 0.001 (0.286)	loss 7.344 (7.622)	prob 2.638 (2.460)	GS 33.078 (32.333)	mem 73.103
Train: [51][430/1500]	BT 0.027 (0.317)	DT 0.000 (0.280)	loss 7.652 (7.615)	prob 3.535 (2.588)	GS 33.438 (31.735)	mem 73.123
Train: [51][440/1500]	BT 0.023 (0.310)	DT 0.000 (0.273)	loss 7.356 (7.611)	prob 2.117 (2.562)	GS 30.125 (32.240)	mem 73.124
Train: [51][450/1500]	BT 0.025 (0.329)	DT 0.000 (0.292)	loss 7.435 (7.596)	prob 2.714 (2.649)	GS 30.938 (32.317)	mem 73.010
Train: [51][460/1500]	BT 0.026 (0.322)	DT 0.000 (0.285)	loss 7.739 (7.656)	prob 3.283 (2.791)	GS 32.406 (32.500)	mem 73.011
Train: [51][470/1500]	BT 0.049 (0.327)	DT 0.009 (0.291)	loss 7.959 (7.764)	prob 2.783 (2.682)	GS 33.016 (32.208)	mem 73.012
Train: [51][480/1500]	BT 0.047 (0.321)	DT 0.000 (0.285)	loss 7.723 (7.744)	prob 3.920 (2.821)	GS 32.219 (31.864)	mem 73.012
Train: [51][490/1500]	BT 0.038 (0.316)	DT 0.001 (0.279)	loss 8.300 (7.769)	prob 3.400 (2.922)	GS 36.000 (32.135)	mem 73.012
Train: [51][500/1500]	BT 0.035 (0.316)	DT 0.001 (0.279)	loss 7.344 (7.703)	prob 3.652 (2.941)	GS 32.281 (32.313)	mem 73.012
Train: [51][510/1500]	BT 0.037 (0.311)	DT 0.001 (0.274)	loss 7.889 (7.836)	prob 3.326 (3.264)	GS 35.188 (33.356)	mem 73.012
Train: [51][520/1500]	BT 0.037 (0.311)	DT 0.000 (0.274)	loss 8.284 (7.733)	prob 2.890 (3.388)	GS 34.703 (33.250)	mem 73.014
Train: [51][530/1500]	BT 0.037 (0.305)	DT 0.001 (0.269)	loss 7.591 (7.698)	prob 4.379 (3.376)	GS 29.234 (33.167)	mem 73.014
Train: [51][540/1500]	BT 0.037 (0.312)	DT 0.001 (0.275)	loss 7.769 (7.702)	prob 4.647 (3.535)	GS 35.156 (32.893)	mem 73.014
Train: [51][550/1500]	BT 0.038 (0.307)	DT 0.000 (0.270)	loss 7.758 (7.696)	prob 3.657 (3.487)	GS 36.391 (32.953)	mem 73.023
Train: [51][560/1500]	BT 0.037 (0.302)	DT 0.001 (0.265)	loss 7.582 (7.713)	prob 3.606 (3.003)	GS 36.016 (32.969)	mem 73.033
Train: [51][570/1500]	BT 0.038 (0.305)	DT 0.001 (0.268)	loss 7.821 (7.774)	prob 3.220 (3.078)	GS 38.250 (33.570)	mem 73.036
Train: [51][580/1500]	BT 0.037 (0.300)	DT 0.001 (0.264)	loss 7.638 (7.702)	prob 3.958 (3.227)	GS 31.328 (33.574)	mem 73.036
Train: [51][590/1500]	BT 0.068 (0.301)	DT 0.009 (0.264)	loss 7.362 (7.707)	prob 3.798 (3.358)	GS 30.250 (33.534)	mem 73.023
Train: [51][600/1500]	BT 0.048 (0.303)	DT 0.011 (0.266)	loss 8.016 (7.693)	prob 3.912 (3.457)	GS 36.453 (33.013)	mem 73.023
Train: [51][610/1500]	BT 0.039 (0.309)	DT 0.001 (0.271)	loss 7.931 (7.716)	prob 3.680 (3.700)	GS 33.578 (34.772)	mem 73.025
Train: [51][620/1500]	BT 0.039 (0.304)	DT 0.001 (0.267)	loss 8.114 (7.736)	prob 3.144 (3.559)	GS 34.094 (33.723)	mem 73.025
Train: [51][630/1500]	BT 0.066 (0.311)	DT 0.002 (0.273)	loss 7.414 (7.684)	prob 3.722 (3.573)	GS 33.453 (33.216)	mem 73.027
Train: [51][640/1500]	BT 0.062 (0.307)	DT 0.001 (0.269)	loss 7.658 (7.663)	prob 3.950 (3.594)	GS 33.453 (33.030)	mem 73.027
Train: [51][650/1500]	BT 0.075 (0.321)	DT 0.007 (0.283)	loss 7.480 (7.674)	prob 4.024 (3.560)	GS 35.156 (33.208)	mem 73.030
Train: [51][660/1500]	BT 0.066 (0.317)	DT 0.012 (0.279)	loss 7.581 (7.647)	prob 3.782 (3.769)	GS 32.031 (32.091)	mem 73.031
Train: [51][670/1500]	BT 0.035 (0.332)	DT 0.000 (0.294)	loss 7.934 (7.678)	prob 3.900 (3.763)	GS 32.922 (32.637)	mem 73.031
Train: [51][680/1500]	BT 0.031 (0.328)	DT 0.000 (0.290)	loss 8.108 (7.686)	prob 3.306 (3.769)	GS 35.906 (32.738)	mem 73.032
Train: [51][690/1500]	BT 0.039 (0.327)	DT 0.001 (0.289)	loss 7.151 (7.682)	prob 4.112 (3.691)	GS 31.688 (33.025)	mem 73.033
Train: [51][700/1500]	BT 0.039 (0.323)	DT 0.001 (0.285)	loss 7.726 (7.658)	prob 3.857 (3.701)	GS 30.016 (32.739)	mem 73.033
Train: [51][710/1500]	BT 0.039 (0.319)	DT 0.001 (0.281)	loss 7.915 (7.519)	prob 3.358 (4.123)	GS 34.453 (31.845)	mem 73.034
Train: [51][720/1500]	BT 0.028 (0.325)	DT 0.000 (0.287)	loss 7.595 (7.580)	prob 4.325 (3.907)	GS 31.828 (32.456)	mem 73.050
Train: [51][730/1500]	BT 0.025 (0.321)	DT 0.000 (0.283)	loss 7.799 (7.580)	prob 3.920 (3.922)	GS 37.359 (32.943)	mem 73.050
Train: [51][740/1500]	BT 0.023 (0.323)	DT 0.000 (0.285)	loss 7.442 (7.544)	prob 4.492 (3.955)	GS 29.531 (32.575)	mem 73.053
Train: [51][750/1500]	BT 0.034 (0.319)	DT 0.000 (0.281)	loss 7.723 (7.543)	prob 3.628 (3.910)	GS 31.438 (32.599)	mem 73.055
Train: [51][760/1500]	BT 0.038 (0.315)	DT 0.001 (0.277)	loss 7.845 (7.470)	prob 3.709 (3.933)	GS 35.328 (31.795)	mem 73.056
Train: [51][770/1500]	BT 0.037 (0.317)	DT 0.001 (0.280)	loss 7.326 (7.519)	prob 4.087 (3.728)	GS 32.312 (32.440)	mem 73.058
Train: [51][780/1500]	BT 0.037 (0.314)	DT 0.001 (0.276)	loss 7.712 (7.510)	prob 3.867 (3.890)	GS 33.375 (32.202)	mem 73.058
Train: [51][790/1500]	BT 0.026 (0.319)	DT 0.000 (0.282)	loss 7.624 (7.523)	prob 3.659 (3.786)	GS 35.516 (32.830)	mem 73.060
Train: [51][800/1500]	BT 0.030 (0.316)	DT 0.000 (0.278)	loss 7.649 (7.517)	prob 3.023 (3.731)	GS 36.094 (32.691)	mem 73.061
Train: [51][810/1500]	BT 0.037 (0.315)	DT 0.001 (0.278)	loss 7.510 (7.439)	prob 3.323 (3.608)	GS 35.953 (31.673)	mem 73.063
Train: [51][820/1500]	BT 0.037 (0.312)	DT 0.000 (0.275)	loss 7.524 (7.478)	prob 3.541 (3.652)	GS 29.391 (31.448)	mem 73.063
Train: [51][830/1500]	BT 0.037 (0.309)	DT 0.000 (0.271)	loss 7.648 (7.459)	prob 3.590 (3.680)	GS 36.875 (31.584)	mem 73.064
Train: [51][840/1500]	BT 0.080 (0.311)	DT 0.011 (0.273)	loss 7.536 (7.464)	prob 3.363 (3.659)	GS 34.188 (32.000)	mem 73.065
Train: [51][850/1500]	BT 0.087 (0.308)	DT 0.012 (0.270)	loss 7.417 (7.473)	prob 3.399 (3.638)	GS 33.469 (32.228)	mem 73.067
Train: [51][860/1500]	BT 0.037 (0.309)	DT 0.001 (0.271)	loss 7.442 (7.465)	prob 3.309 (3.288)	GS 35.875 (33.922)	mem 73.066
Train: [51][870/1500]	BT 0.038 (0.306)	DT 0.001 (0.268)	loss 7.224 (7.473)	prob 3.285 (3.210)	GS 35.766 (33.588)	mem 73.068
Train: [51][880/1500]	BT 0.037 (0.305)	DT 0.000 (0.267)	loss 7.399 (7.479)	prob 3.295 (3.194)	GS 34.359 (33.213)	mem 73.070
Train: [51][890/1500]	BT 0.037 (0.307)	DT 0.001 (0.269)	loss 7.520 (7.468)	prob 3.565 (3.254)	GS 33.625 (32.904)	mem 73.073
Train: [51][900/1500]	BT 0.037 (0.306)	DT 0.000 (0.268)	loss 7.209 (7.432)	prob 3.602 (3.363)	GS 34.078 (32.764)	mem 73.073
Train: [51][910/1500]	BT 0.036 (0.306)	DT 0.000 (0.268)	loss 7.295 (7.330)	prob 3.083 (3.318)	GS 36.391 (34.769)	mem 73.074
Train: [51][920/1500]	BT 0.038 (0.303)	DT 0.001 (0.265)	loss 7.106 (7.360)	prob 4.072 (3.347)	GS 32.312 (33.493)	mem 73.075
Train: [51][930/1500]	BT 0.038 (0.304)	DT 0.001 (0.266)	loss 7.281 (7.341)	prob 3.376 (3.412)	GS 32.438 (33.065)	mem 73.076
Train: [51][940/1500]	BT 0.037 (0.302)	DT 0.001 (0.263)	loss 7.299 (7.315)	prob 3.208 (3.405)	GS 32.750 (32.845)	mem 73.076
Train: [51][950/1500]	BT 0.037 (0.301)	DT 0.001 (0.263)	loss 6.989 (7.308)	prob 4.136 (3.422)	GS 35.047 (32.833)	mem 73.079
Train: [51][960/1500]	BT 0.028 (0.301)	DT 0.000 (0.263)	loss 7.618 (7.248)	prob 3.612 (3.662)	GS 32.875 (31.805)	mem 73.080
Train: [51][970/1500]	BT 0.028 (0.298)	DT 0.000 (0.260)	loss 7.442 (7.245)	prob 3.429 (3.547)	GS 32.906 (32.479)	mem 73.081
Train: [51][980/1500]	BT 0.034 (0.300)	DT 0.000 (0.262)	loss 7.257 (7.265)	prob 3.531 (3.407)	GS 32.375 (32.796)	mem 73.085
Train: [51][990/1500]	BT 0.034 (0.297)	DT 0.000 (0.260)	loss 6.940 (7.229)	prob 3.972 (3.439)	GS 34.172 (32.836)	mem 73.086
Train: [51][1000/1500]	BT 0.031 (0.296)	DT 0.000 (0.259)	loss 7.234 (7.221)	prob 4.014 (3.436)	GS 35.047 (33.208)	mem 73.118
Train: [51][1010/1500]	BT 0.029 (0.299)	DT 0.000 (0.261)	loss 7.268 (7.153)	prob 4.107 (3.625)	GS 30.125 (33.153)	mem 73.118
Train: [51][1020/1500]	BT 0.038 (0.297)	DT 0.001 (0.260)	loss 6.927 (7.178)	prob 3.957 (3.615)	GS 33.172 (33.569)	mem 73.117
Train: [51][1030/1500]	BT 0.038 (0.297)	DT 0.000 (0.259)	loss 6.861 (7.177)	prob 3.178 (3.672)	GS 32.688 (32.456)	mem 73.119
Train: [51][1040/1500]	BT 0.038 (0.294)	DT 0.001 (0.257)	loss 7.048 (7.163)	prob 3.677 (3.587)	GS 34.828 (32.277)	mem 73.118
Train: [51][1050/1500]	BT 0.039 (0.294)	DT 0.001 (0.257)	loss 7.064 (7.151)	prob 3.770 (3.543)	GS 33.172 (32.631)	mem 73.120
Train: [51][1060/1500]	BT 0.038 (0.293)	DT 0.001 (0.255)	loss 7.152 (7.161)	prob 4.052 (3.714)	GS 33.531 (32.075)	mem 73.122
Train: [51][1070/1500]	BT 0.039 (0.293)	DT 0.001 (0.255)	loss 6.925 (7.117)	prob 3.710 (3.613)	GS 30.625 (31.998)	mem 73.120
Train: [51][1080/1500]	BT 0.039 (0.291)	DT 0.000 (0.253)	loss 7.018 (7.150)	prob 4.500 (3.557)	GS 35.266 (32.388)	mem 73.121
Train: [51][1090/1500]	BT 0.039 (0.291)	DT 0.001 (0.253)	loss 7.666 (7.169)	prob 2.904 (3.525)	GS 30.312 (32.578)	mem 73.121
Train: [51][1100/1500]	BT 0.038 (0.291)	DT 0.001 (0.253)	loss 6.855 (7.167)	prob 3.853 (3.499)	GS 35.703 (32.723)	mem 73.120
Train: [51][1110/1500]	BT 0.038 (0.289)	DT 0.001 (0.251)	loss 7.232 (7.162)	prob 3.816 (3.407)	GS 32.734 (32.039)	mem 73.120
Train: [51][1120/1500]	BT 0.039 (0.287)	DT 0.001 (0.250)	loss 7.020 (7.163)	prob 2.836 (3.441)	GS 30.797 (31.778)	mem 73.120
Train: [51][1130/1500]	BT 0.034 (0.291)	DT 0.001 (0.253)	loss 7.129 (7.168)	prob 3.641 (3.356)	GS 30.219 (32.067)	mem 73.121
Train: [51][1140/1500]	BT 0.033 (0.289)	DT 0.000 (0.251)	loss 7.330 (7.157)	prob 3.606 (3.365)	GS 32.609 (32.104)	mem 73.121
Train: [51][1150/1500]	BT 0.039 (0.289)	DT 0.001 (0.251)	loss 7.250 (7.160)	prob 2.821 (3.343)	GS 35.750 (32.121)	mem 73.121
Train: [51][1160/1500]	BT 0.039 (0.287)	DT 0.001 (0.249)	loss 7.209 (7.160)	prob 3.342 (2.881)	GS 32.484 (33.122)	mem 73.120
Train: [51][1170/1500]	BT 0.564 (0.286)	DT 0.526 (0.248)	loss 7.354 (7.178)	prob 2.625 (2.925)	GS 32.672 (32.752)	mem 73.120
Train: [51][1180/1500]	BT 0.040 (0.285)	DT 0.001 (0.247)	loss 7.208 (7.192)	prob 3.104 (3.019)	GS 35.859 (32.795)	mem 73.120
Train: [51][1190/1500]	BT 0.038 (0.283)	DT 0.001 (0.245)	loss 7.343 (7.196)	prob 3.185 (3.028)	GS 32.953 (32.823)	mem 73.120
Train: [51][1200/1500]	BT 0.039 (0.285)	DT 0.001 (0.247)	loss 7.123 (7.180)	prob 3.196 (3.080)	GS 37.031 (32.837)	mem 73.123
Train: [51][1210/1500]	BT 0.039 (0.283)	DT 0.001 (0.245)	loss 7.177 (7.134)	prob 3.050 (3.101)	GS 31.594 (33.645)	mem 73.123
Train: [51][1220/1500]	BT 0.038 (0.284)	DT 0.000 (0.246)	loss 7.114 (7.124)	prob 3.345 (3.040)	GS 32.594 (33.657)	mem 73.129
Train: [51][1230/1500]	BT 0.038 (0.282)	DT 0.000 (0.244)	loss 7.274 (7.117)	prob 3.287 (3.107)	GS 36.672 (33.170)	mem 73.130
Train: [51][1240/1500]	BT 0.062 (0.280)	DT 0.006 (0.242)	loss 7.058 (7.119)	prob 3.309 (3.112)	GS 33.531 (33.200)	mem 73.130
Train: [51][1250/1500]	BT 0.038 (0.283)	DT 0.001 (0.245)	loss 7.261 (7.134)	prob 3.032 (3.076)	GS 29.625 (32.884)	mem 73.139
Train: [51][1260/1500]	BT 0.039 (0.281)	DT 0.001 (0.243)	loss 6.989 (7.194)	prob 3.349 (2.912)	GS 33.656 (32.478)	mem 73.139
Train: [51][1270/1500]	BT 0.056 (0.283)	DT 0.012 (0.246)	loss 7.221 (7.165)	prob 2.523 (2.865)	GS 38.062 (32.078)	mem 73.036
Train: [51][1280/1500]	BT 0.055 (0.282)	DT 0.016 (0.244)	loss 7.130 (7.129)	prob 2.677 (2.872)	GS 36.078 (32.215)	mem 73.036
Train: [51][1290/1500]	BT 2.028 (0.282)	DT 1.991 (0.244)	loss 7.280 (7.135)	prob 2.450 (2.854)	GS 34.797 (32.446)	mem 73.038
Train: [51][1300/1500]	BT 0.029 (0.286)	DT 0.000 (0.248)	loss 6.960 (7.127)	prob 2.757 (2.859)	GS 37.406 (32.801)	mem 73.035
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [51][1310/1500]	BT 0.035 (0.284)	DT 0.000 (0.246)	loss 7.171 (7.134)	prob 2.849 (2.879)	GS 37.531 (33.220)	mem 73.036
Train: [51][1320/1500]	BT 0.037 (0.284)	DT 0.001 (0.247)	loss 7.224 (7.106)	prob 2.765 (2.880)	GS 35.484 (32.990)	mem 73.041
Train: [51][1330/1500]	BT 0.037 (0.283)	DT 0.000 (0.245)	loss 6.957 (7.132)	prob 2.780 (2.906)	GS 30.234 (32.132)	mem 73.058
Train: [51][1340/1500]	BT 0.038 (0.283)	DT 0.000 (0.245)	loss 7.017 (7.138)	prob 2.719 (2.858)	GS 32.875 (32.330)	mem 73.061
Train: [51][1350/1500]	BT 0.039 (0.281)	DT 0.001 (0.243)	loss 7.106 (7.133)	prob 2.535 (2.826)	GS 33.266 (32.309)	mem 73.061
Train: [51][1360/1500]	BT 0.038 (0.279)	DT 0.001 (0.242)	loss 6.845 (7.011)	prob 2.807 (2.877)	GS 33.000 (33.181)	mem 73.061
Train: [51][1370/1500]	BT 0.028 (0.284)	DT 0.000 (0.246)	loss 7.299 (7.032)	prob 3.184 (2.881)	GS 37.656 (33.919)	mem 73.046
Train: [51][1380/1500]	BT 0.060 (0.282)	DT 0.014 (0.244)	loss 6.955 (7.020)	prob 2.872 (2.988)	GS 32.562 (33.399)	mem 73.048
Train: [51][1390/1500]	BT 0.059 (0.285)	DT 0.015 (0.247)	loss 7.101 (7.043)	prob 2.648 (2.830)	GS 33.797 (33.448)	mem 73.049
Train: [51][1400/1500]	BT 0.038 (0.284)	DT 0.001 (0.246)	loss 7.287 (7.041)	prob 2.946 (2.880)	GS 35.078 (33.104)	mem 73.049
Train: [51][1410/1500]	BT 0.039 (0.284)	DT 0.001 (0.247)	loss 7.228 (7.102)	prob 2.996 (2.902)	GS 35.500 (33.717)	mem 73.048
Train: [51][1420/1500]	BT 0.028 (0.284)	DT 0.000 (0.246)	loss 6.835 (7.084)	prob 3.002 (2.888)	GS 32.062 (33.411)	mem 73.049
Train: [51][1430/1500]	BT 0.030 (0.282)	DT 0.001 (0.245)	loss 7.100 (7.086)	prob 2.932 (2.931)	GS 32.219 (33.276)	mem 73.049
Train: [51][1440/1500]	BT 0.039 (0.283)	DT 0.001 (0.245)	loss 7.040 (7.087)	prob 2.718 (2.859)	GS 31.703 (33.141)	mem 73.049
Train: [51][1450/1500]	BT 0.040 (0.282)	DT 0.001 (0.244)	loss 7.194 (7.089)	prob 2.697 (2.772)	GS 34.062 (33.078)	mem 73.049
Train: [51][1460/1500]	BT 0.028 (0.282)	DT 0.001 (0.244)	loss 7.505 (7.030)	prob 2.362 (2.645)	GS 31.359 (32.252)	mem 72.832
Train: [51][1470/1500]	BT 0.026 (0.280)	DT 0.000 (0.243)	loss 6.842 (7.026)	prob 2.710 (2.527)	GS 31.688 (32.061)	mem 72.436
Train: [51][1480/1500]	BT 0.029 (0.279)	DT 0.000 (0.241)	loss 7.143 (7.055)	prob 2.869 (2.439)	GS 33.531 (32.095)	mem 72.436
Train: [51][1490/1500]	BT 0.042 (0.279)	DT 0.001 (0.241)	loss 7.683 (7.095)	prob 1.966 (2.383)	GS 34.531 (31.901)	mem 10.777
Train: [51][1500/1500]	BT 0.028 (0.277)	DT 0.000 (0.239)	loss 6.623 (7.075)	prob 2.525 (2.383)	GS 32.438 (32.007)	mem 10.777
Train: [51][1510/1500]	BT 0.026 (0.276)	DT 0.000 (0.238)	loss 6.751 (6.887)	prob 2.439 (2.738)	GS 41.188 (35.694)	mem 7.967
epoch 51, total time 416.61
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [52][1/1500]	BT 17.950 (17.950)	DT 17.893 (17.893)	loss 6.755 (6.755)	prob 2.077 (2.077)	GS 31.000 (31.000)	mem 71.600
Train: [52][10/1500]	BT 0.060 (2.520)	DT 0.007 (2.481)	loss 6.969 (7.066)	prob 2.405 (2.631)	GS 35.781 (33.339)	mem 71.745
Train: [52][20/1500]	BT 0.034 (1.468)	DT 0.000 (1.434)	loss 7.652 (7.123)	prob 2.424 (2.598)	GS 34.328 (33.679)	mem 71.797
Train: [52][30/1500]	BT 0.037 (0.990)	DT 0.000 (0.956)	loss 7.103 (7.099)	prob 2.665 (2.576)	GS 33.906 (33.239)	mem 71.798
Train: [52][40/1500]	BT 0.045 (0.893)	DT 0.003 (0.856)	loss 7.135 (7.116)	prob 2.551 (2.532)	GS 35.141 (32.706)	mem 71.807
Train: [52][50/1500]	BT 0.047 (0.723)	DT 0.014 (0.686)	loss 6.648 (7.135)	prob 3.556 (2.561)	GS 29.922 (32.513)	mem 71.808
Train: [52][60/1500]	BT 0.029 (0.924)	DT 0.000 (0.886)	loss 7.244 (7.239)	prob 2.461 (2.650)	GS 32.297 (34.031)	mem 71.818
Train: [52][70/1500]	BT 0.030 (0.796)	DT 0.000 (0.759)	loss 7.407 (7.360)	prob 2.600 (2.497)	GS 33.891 (34.656)	mem 71.817
Train: [52][80/1500]	BT 3.397 (0.743)	DT 3.360 (0.706)	loss 7.157 (7.362)	prob 2.670 (2.505)	GS 32.766 (33.868)	mem 71.822
Train: [52][90/1500]	BT 0.028 (0.664)	DT 0.000 (0.628)	loss 7.478 (7.330)	prob 2.486 (2.518)	GS 36.047 (33.401)	mem 71.824
Train: [52][100/1500]	BT 0.037 (0.601)	DT 0.001 (0.565)	loss 7.142 (7.323)	prob 2.552 (2.470)	GS 28.328 (33.073)	mem 71.827
Train: [52][110/1500]	BT 0.037 (0.574)	DT 0.000 (0.539)	loss 8.023 (7.542)	prob 2.994 (2.482)	GS 31.859 (31.284)	mem 71.829
Train: [52][120/1500]	BT 0.027 (0.530)	DT 0.000 (0.494)	loss 7.403 (7.465)	prob 3.162 (2.597)	GS 30.953 (32.037)	mem 71.831
Train: [52][130/1500]	BT 0.037 (0.530)	DT 0.001 (0.493)	loss 7.330 (7.483)	prob 2.539 (2.524)	GS 32.047 (32.442)	mem 71.842
Train: [52][140/1500]	BT 0.028 (0.494)	DT 0.000 (0.458)	loss 7.957 (7.464)	prob 2.052 (2.461)	GS 33.859 (32.609)	mem 71.842
Train: [52][150/1500]	BT 0.037 (0.464)	DT 0.001 (0.428)	loss 7.271 (7.435)	prob 2.302 (2.409)	GS 30.891 (32.754)	mem 71.843
Train: [52][160/1500]	BT 0.026 (0.469)	DT 0.000 (0.434)	loss 7.545 (7.641)	prob 3.353 (2.928)	GS 33.984 (32.850)	mem 71.851
Train: [52][170/1500]	BT 0.036 (0.443)	DT 0.000 (0.408)	loss 8.145 (7.600)	prob 1.487 (2.688)	GS 37.109 (32.815)	mem 71.854
Train: [52][180/1500]	BT 0.027 (0.438)	DT 0.000 (0.403)	loss 7.508 (7.570)	prob 2.632 (2.607)	GS 32.000 (32.637)	mem 71.856
Train: [52][190/1500]	BT 0.032 (0.416)	DT 0.000 (0.382)	loss 7.800 (7.593)	prob 3.232 (2.604)	GS 37.391 (32.561)	mem 71.859
Train: [52][200/1500]	BT 2.786 (0.411)	DT 2.749 (0.376)	loss 7.465 (7.607)	prob 3.208 (2.589)	GS 33.453 (32.611)	mem 71.860
Train: [52][210/1500]	BT 0.037 (0.394)	DT 0.000 (0.359)	loss 7.567 (7.552)	prob 3.245 (2.710)	GS 34.078 (32.659)	mem 71.867
Train: [52][220/1500]	BT 0.038 (0.378)	DT 0.001 (0.343)	loss 7.809 (7.533)	prob 2.647 (2.704)	GS 36.688 (32.664)	mem 71.891
Train: [52][230/1500]	BT 0.038 (0.380)	DT 0.001 (0.344)	loss 7.632 (7.550)	prob 3.820 (2.733)	GS 30.562 (33.014)	mem 71.899
Train: [52][240/1500]	BT 0.038 (0.366)	DT 0.001 (0.330)	loss 7.462 (7.563)	prob 3.471 (2.797)	GS 29.828 (32.852)	mem 71.900
Train: [52][250/1500]	BT 0.038 (0.370)	DT 0.000 (0.335)	loss 7.595 (7.562)	prob 3.576 (2.862)	GS 33.594 (32.848)	mem 71.905
Train: [52][260/1500]	BT 0.038 (0.357)	DT 0.001 (0.322)	loss 7.970 (7.589)	prob 2.164 (3.022)	GS 35.000 (32.845)	mem 71.904
Train: [52][270/1500]	BT 0.038 (0.345)	DT 0.001 (0.310)	loss 7.745 (7.584)	prob 3.157 (2.926)	GS 35.375 (32.494)	mem 71.904
Train: [52][280/1500]	BT 0.038 (0.349)	DT 0.001 (0.313)	loss 8.048 (7.613)	prob 2.781 (2.846)	GS 34.906 (32.409)	mem 71.908
Train: [52][290/1500]	BT 0.039 (0.338)	DT 0.001 (0.303)	loss 7.659 (7.571)	prob 2.799 (2.866)	GS 32.438 (32.344)	mem 71.909
Train: [52][300/1500]	BT 0.059 (0.352)	DT 0.001 (0.316)	loss 7.566 (7.557)	prob 3.367 (2.917)	GS 33.828 (32.190)	mem 72.302
Train: [52][310/1500]	BT 0.037 (0.350)	DT 0.000 (0.313)	loss 7.461 (7.541)	prob 4.326 (2.905)	GS 31.078 (34.373)	mem 72.693
Train: [52][320/1500]	BT 0.040 (0.340)	DT 0.001 (0.303)	loss 7.884 (7.515)	prob 2.876 (3.067)	GS 33.969 (33.345)	mem 72.789
Train: [52][330/1500]	BT 0.039 (0.335)	DT 0.001 (0.299)	loss 7.503 (7.507)	prob 3.102 (3.060)	GS 35.125 (33.014)	mem 72.988
Train: [52][340/1500]	BT 0.039 (0.333)	DT 0.001 (0.296)	loss 7.234 (7.499)	prob 3.863 (3.205)	GS 37.156 (32.880)	mem 73.085
Train: [52][350/1500]	BT 0.038 (0.332)	DT 0.001 (0.295)	loss 7.517 (7.519)	prob 3.932 (3.209)	GS 37.172 (32.911)	mem 73.089
Train: [52][360/1500]	BT 0.039 (0.324)	DT 0.001 (0.287)	loss 7.705 (7.569)	prob 2.664 (3.412)	GS 36.547 (32.880)	mem 73.090
Train: [52][370/1500]	BT 0.030 (0.330)	DT 0.000 (0.294)	loss 7.510 (7.534)	prob 3.833 (3.441)	GS 34.328 (32.435)	mem 73.090
Train: [52][380/1500]	BT 0.033 (0.323)	DT 0.000 (0.286)	loss 7.838 (7.572)	prob 3.455 (3.349)	GS 30.656 (32.380)	mem 73.091
Train: [52][390/1500]	BT 0.034 (0.316)	DT 0.000 (0.279)	loss 8.380 (7.595)	prob 3.294 (3.328)	GS 33.547 (32.611)	mem 73.090
Train: [52][400/1500]	BT 0.041 (0.320)	DT 0.000 (0.283)	loss 7.958 (7.619)	prob 2.629 (3.201)	GS 31.828 (32.757)	mem 73.094
Train: [52][410/1500]	BT 0.039 (0.313)	DT 0.001 (0.276)	loss 7.890 (7.694)	prob 3.469 (3.249)	GS 31.672 (33.139)	mem 73.094
Train: [52][420/1500]	BT 0.038 (0.322)	DT 0.001 (0.285)	loss 7.491 (7.594)	prob 3.495 (3.203)	GS 30.562 (31.858)	mem 73.091
Train: [52][430/1500]	BT 0.030 (0.319)	DT 0.000 (0.282)	loss 7.347 (7.600)	prob 3.563 (3.202)	GS 31.703 (32.375)	mem 73.090
Train: [52][440/1500]	BT 0.062 (0.312)	DT 0.014 (0.275)	loss 7.670 (7.558)	prob 3.299 (3.239)	GS 31.828 (32.355)	mem 73.089
Train: [52][450/1500]	BT 0.034 (0.325)	DT 0.000 (0.288)	loss 8.170 (7.602)	prob 3.091 (3.199)	GS 33.641 (32.773)	mem 73.092
Train: [52][460/1500]	BT 0.075 (0.319)	DT 0.011 (0.282)	loss 7.821 (7.630)	prob 2.765 (2.972)	GS 39.266 (33.491)	mem 73.092
Train: [52][470/1500]	BT 0.067 (0.326)	DT 0.011 (0.289)	loss 7.346 (7.610)	prob 3.189 (3.157)	GS 31.719 (33.127)	mem 73.098
Train: [52][480/1500]	BT 0.043 (0.320)	DT 0.000 (0.283)	loss 7.441 (7.597)	prob 3.997 (3.177)	GS 35.219 (32.944)	mem 73.098
Train: [52][490/1500]	BT 0.037 (0.323)	DT 0.000 (0.285)	loss 8.006 (7.578)	prob 2.633 (3.113)	GS 33.703 (33.298)	mem 73.112
Train: [52][500/1500]	BT 0.038 (0.319)	DT 0.001 (0.281)	loss 7.182 (7.585)	prob 3.482 (3.134)	GS 31.328 (33.095)	mem 73.103
Train: [52][510/1500]	BT 0.037 (0.314)	DT 0.001 (0.277)	loss 7.919 (7.690)	prob 3.242 (3.356)	GS 31.125 (31.089)	mem 73.103
Train: [52][520/1500]	BT 0.037 (0.314)	DT 0.001 (0.276)	loss 7.619 (7.530)	prob 3.690 (3.495)	GS 33.000 (32.048)	mem 73.109
Train: [52][530/1500]	BT 0.037 (0.309)	DT 0.001 (0.271)	loss 7.227 (7.523)	prob 3.103 (3.298)	GS 32.828 (32.829)	mem 73.109
Train: [52][540/1500]	BT 0.038 (0.311)	DT 0.001 (0.274)	loss 7.828 (7.554)	prob 3.775 (3.241)	GS 35.750 (32.795)	mem 73.117
Train: [52][550/1500]	BT 0.038 (0.307)	DT 0.001 (0.270)	loss 7.698 (7.568)	prob 3.149 (3.185)	GS 33.609 (32.803)	mem 73.116
Train: [52][560/1500]	BT 0.039 (0.302)	DT 0.001 (0.265)	loss 7.508 (7.409)	prob 4.025 (3.404)	GS 37.641 (33.241)	mem 73.117
Train: [52][570/1500]	BT 0.031 (0.306)	DT 0.000 (0.269)	loss 7.315 (7.453)	prob 3.734 (3.204)	GS 34.000 (33.094)	mem 73.016
Train: [52][580/1500]	BT 0.037 (0.309)	DT 0.001 (0.272)	loss 7.431 (7.494)	prob 3.938 (3.235)	GS 38.531 (34.144)	mem 73.017
Train: [52][590/1500]	BT 0.025 (0.305)	DT 0.000 (0.268)	loss 7.459 (7.489)	prob 3.762 (3.198)	GS 34.359 (33.807)	mem 73.017
Train: [52][600/1500]	BT 0.048 (0.307)	DT 0.006 (0.270)	loss 7.126 (7.481)	prob 3.630 (3.239)	GS 37.812 (33.693)	mem 73.020
Train: [52][610/1500]	BT 0.069 (0.303)	DT 0.006 (0.266)	loss 7.370 (7.503)	prob 3.450 (3.029)	GS 36.250 (33.542)	mem 73.019
Train: [52][620/1500]	BT 0.061 (0.316)	DT 0.013 (0.279)	loss 7.703 (7.484)	prob 2.939 (3.084)	GS 33.688 (33.392)	mem 73.020
Train: [52][630/1500]	BT 0.028 (0.317)	DT 0.000 (0.280)	loss 7.441 (7.487)	prob 3.258 (3.133)	GS 35.266 (33.486)	mem 73.044
Train: [52][640/1500]	BT 0.026 (0.313)	DT 0.000 (0.276)	loss 7.478 (7.500)	prob 4.145 (3.185)	GS 31.469 (33.277)	mem 73.044
Train: [52][650/1500]	BT 0.039 (0.313)	DT 0.001 (0.276)	loss 7.080 (7.492)	prob 3.956 (3.230)	GS 31.828 (32.999)	mem 73.031
Train: [52][660/1500]	BT 0.038 (0.309)	DT 0.001 (0.272)	loss 7.559 (7.540)	prob 3.126 (3.278)	GS 36.875 (31.989)	mem 73.030
Train: [52][670/1500]	BT 6.445 (0.315)	DT 6.404 (0.278)	loss 7.862 (7.537)	prob 2.995 (3.261)	GS 34.578 (32.611)	mem 73.028
Train: [52][680/1500]	BT 0.038 (0.314)	DT 0.000 (0.277)	loss 8.247 (7.512)	prob 2.844 (3.086)	GS 29.688 (32.366)	mem 73.031
Train: [52][690/1500]	BT 0.026 (0.310)	DT 0.000 (0.273)	loss 7.171 (7.505)	prob 3.213 (3.026)	GS 31.250 (32.390)	mem 73.032
Train: [52][700/1500]	BT 0.022 (0.314)	DT 0.000 (0.277)	loss 8.080 (7.492)	prob 2.806 (2.984)	GS 29.641 (32.628)	mem 73.034
Train: [52][710/1500]	BT 0.038 (0.310)	DT 0.001 (0.273)	loss 7.309 (7.289)	prob 3.326 (3.161)	GS 28.047 (31.269)	mem 73.036
Train: [52][720/1500]	BT 0.048 (0.313)	DT 0.001 (0.276)	loss 7.867 (7.357)	prob 3.073 (3.044)	GS 31.203 (30.712)	mem 73.037
Train: [52][730/1500]	BT 0.031 (0.310)	DT 0.000 (0.273)	loss 7.483 (7.431)	prob 3.229 (2.937)	GS 36.109 (32.141)	mem 73.039
Train: [52][740/1500]	BT 0.030 (0.306)	DT 0.000 (0.270)	loss 7.704 (7.432)	prob 3.392 (2.945)	GS 34.359 (31.820)	mem 73.039
Train: [52][750/1500]	BT 0.052 (0.309)	DT 0.000 (0.272)	loss 7.356 (7.401)	prob 2.445 (2.947)	GS 34.781 (31.815)	mem 73.039
Train: [52][760/1500]	BT 0.039 (0.305)	DT 0.001 (0.269)	loss 7.584 (7.658)	prob 2.866 (2.298)	GS 36.031 (32.422)	mem 73.041
Train: [52][770/1500]	BT 0.029 (0.307)	DT 0.001 (0.271)	loss 7.687 (7.674)	prob 3.541 (2.514)	GS 27.234 (31.895)	mem 73.040
Train: [52][780/1500]	BT 0.039 (0.304)	DT 0.001 (0.267)	loss 7.030 (7.605)	prob 3.614 (2.665)	GS 30.703 (31.648)	mem 73.041
Train: [52][790/1500]	BT 0.039 (0.300)	DT 0.001 (0.264)	loss 7.285 (7.598)	prob 3.388 (2.627)	GS 31.578 (31.623)	mem 73.041
Train: [52][800/1500]	BT 0.037 (0.301)	DT 0.001 (0.264)	loss 7.355 (7.574)	prob 3.355 (2.678)	GS 28.438 (31.739)	mem 73.056
Train: [52][810/1500]	BT 0.027 (0.298)	DT 0.000 (0.261)	loss 7.265 (7.569)	prob 3.076 (3.001)	GS 31.703 (31.508)	mem 73.056
Train: [52][820/1500]	BT 0.033 (0.303)	DT 0.000 (0.267)	loss 7.980 (7.596)	prob 3.028 (2.993)	GS 32.297 (31.449)	mem 73.054
Train: [52][830/1500]	BT 0.029 (0.303)	DT 0.000 (0.266)	loss 7.665 (7.602)	prob 2.028 (2.833)	GS 35.281 (32.091)	mem 73.056
Train: [52][840/1500]	BT 0.036 (0.300)	DT 0.001 (0.263)	loss 7.684 (7.573)	prob 3.164 (2.748)	GS 35.234 (32.479)	mem 73.056
Train: [52][850/1500]	BT 0.028 (0.302)	DT 0.000 (0.266)	loss 7.680 (7.592)	prob 3.581 (2.774)	GS 34.844 (32.374)	mem 73.061
Train: [52][860/1500]	BT 0.023 (0.299)	DT 0.000 (0.263)	loss 7.674 (7.526)	prob 4.050 (3.597)	GS 35.953 (32.159)	mem 73.062
Train: [52][870/1500]	BT 0.037 (0.299)	DT 0.001 (0.263)	loss 7.851 (7.598)	prob 3.160 (3.280)	GS 35.172 (32.638)	mem 73.065
Train: [52][880/1500]	BT 0.036 (0.296)	DT 0.000 (0.260)	loss 8.207 (7.618)	prob 3.015 (3.176)	GS 38.578 (32.886)	mem 73.065
Train: [52][890/1500]	BT 0.078 (0.296)	DT 0.013 (0.260)	loss 8.067 (7.661)	prob 3.177 (3.179)	GS 31.734 (32.545)	mem 73.066
Train: [52][900/1500]	BT 0.037 (0.295)	DT 0.001 (0.259)	loss 7.799 (7.692)	prob 3.987 (3.207)	GS 33.047 (32.553)	mem 73.068
Train: [52][910/1500]	BT 0.038 (0.292)	DT 0.001 (0.256)	loss 7.482 (7.727)	prob 4.797 (3.834)	GS 33.359 (31.234)	mem 73.067
Train: [52][920/1500]	BT 0.027 (0.294)	DT 0.000 (0.258)	loss 8.262 (7.645)	prob 3.170 (3.760)	GS 37.609 (31.648)	mem 73.072
Train: [52][930/1500]	BT 0.027 (0.291)	DT 0.000 (0.255)	loss 7.491 (7.661)	prob 3.662 (3.546)	GS 36.453 (32.247)	mem 73.071
Train: [52][940/1500]	BT 0.037 (0.291)	DT 0.001 (0.255)	loss 7.235 (7.656)	prob 3.778 (3.396)	GS 37.047 (32.669)	mem 73.071
Train: [52][950/1500]	BT 0.037 (0.289)	DT 0.001 (0.253)	loss 7.684 (7.649)	prob 3.413 (3.341)	GS 31.547 (32.677)	mem 73.072
Train: [52][960/1500]	BT 0.047 (0.287)	DT 0.011 (0.250)	loss 7.217 (7.765)	prob 4.199 (3.555)	GS 30.891 (30.884)	mem 73.072
Train: [52][970/1500]	BT 0.030 (0.295)	DT 0.000 (0.259)	loss 7.709 (7.742)	prob 2.988 (3.494)	GS 36.859 (32.544)	mem 73.076
Train: [52][980/1500]	BT 0.024 (0.292)	DT 0.000 (0.256)	loss 7.438 (7.698)	prob 3.698 (3.533)	GS 32.781 (32.386)	mem 73.076
Train: [52][990/1500]	BT 0.037 (0.292)	DT 0.000 (0.256)	loss 7.457 (7.707)	prob 3.899 (3.466)	GS 36.688 (32.537)	mem 73.078
Train: [52][1000/1500]	BT 0.025 (0.290)	DT 0.000 (0.254)	loss 8.332 (7.706)	prob 4.239 (3.579)	GS 33.969 (32.607)	mem 73.077
Train: [52][1010/1500]	BT 0.035 (0.294)	DT 0.000 (0.258)	loss 7.424 (7.656)	prob 3.756 (3.409)	GS 35.500 (34.969)	mem 73.079
Train: [52][1020/1500]	BT 0.035 (0.292)	DT 0.000 (0.256)	loss 7.699 (7.691)	prob 4.001 (3.451)	GS 32.375 (33.243)	mem 73.080
Train: [52][1030/1500]	BT 0.031 (0.289)	DT 0.000 (0.253)	loss 8.792 (7.713)	prob 3.252 (3.528)	GS 33.312 (32.961)	mem 73.082
Train: [52][1040/1500]	BT 0.043 (0.299)	DT 0.000 (0.263)	loss 8.223 (7.707)	prob 3.626 (3.642)	GS 36.828 (32.871)	mem 73.081
Train: [52][1050/1500]	BT 0.026 (0.296)	DT 0.000 (0.260)	loss 8.784 (7.701)	prob 3.396 (3.652)	GS 33.234 (32.749)	mem 73.081
Train: [52][1060/1500]	BT 0.060 (0.297)	DT 0.003 (0.262)	loss 7.707 (7.665)	prob 4.242 (3.823)	GS 31.172 (32.461)	mem 73.083
Train: [52][1070/1500]	BT 0.067 (0.295)	DT 0.011 (0.259)	loss 7.218 (7.620)	prob 4.212 (3.818)	GS 29.500 (32.310)	mem 73.083
Train: [52][1080/1500]	BT 0.058 (0.293)	DT 0.011 (0.257)	loss 7.833 (7.654)	prob 3.757 (3.810)	GS 34.969 (32.377)	mem 73.083
Train: [52][1090/1500]	BT 0.037 (0.297)	DT 0.001 (0.260)	loss 7.827 (7.652)	prob 3.921 (3.729)	GS 31.219 (32.455)	mem 73.080
Train: [52][1100/1500]	BT 0.037 (0.296)	DT 0.001 (0.260)	loss 7.983 (7.636)	prob 4.568 (3.816)	GS 33.688 (32.235)	mem 73.083
Train: [52][1110/1500]	BT 0.037 (0.295)	DT 0.000 (0.258)	loss 7.234 (7.486)	prob 5.165 (4.329)	GS 32.953 (32.337)	mem 73.114
Train: [52][1120/1500]	BT 0.028 (0.298)	DT 0.000 (0.261)	loss 7.253 (7.496)	prob 3.869 (4.061)	GS 33.234 (32.424)	mem 73.117
Train: [52][1130/1500]	BT 0.038 (0.296)	DT 0.001 (0.259)	loss 7.618 (7.565)	prob 3.931 (3.868)	GS 31.016 (32.655)	mem 73.118
Train: [52][1140/1500]	BT 0.039 (0.293)	DT 0.001 (0.257)	loss 7.304 (7.548)	prob 3.864 (3.873)	GS 31.750 (32.527)	mem 73.118
Train: [52][1150/1500]	BT 0.039 (0.293)	DT 0.001 (0.257)	loss 7.640 (7.574)	prob 3.518 (3.801)	GS 34.578 (32.872)	mem 73.117
Train: [52][1160/1500]	BT 0.039 (0.292)	DT 0.001 (0.256)	loss 7.406 (7.490)	prob 4.987 (3.844)	GS 30.875 (31.755)	mem 73.117
Train: [52][1170/1500]	BT 0.040 (0.293)	DT 0.001 (0.256)	loss 7.867 (7.616)	prob 3.559 (3.883)	GS 34.297 (32.020)	mem 73.117
Train: [52][1180/1500]	BT 0.039 (0.293)	DT 0.001 (0.257)	loss 7.721 (7.608)	prob 4.335 (3.891)	GS 33.422 (32.062)	mem 73.116
Train: [52][1190/1500]	BT 0.059 (0.295)	DT 0.006 (0.258)	loss 7.531 (7.598)	prob 3.684 (3.824)	GS 35.500 (32.352)	mem 73.116
Train: [52][1200/1500]	BT 0.033 (0.293)	DT 0.000 (0.256)	loss 7.867 (7.596)	prob 4.157 (3.819)	GS 30.203 (32.318)	mem 73.117
Train: [52][1210/1500]	BT 0.028 (0.296)	DT 0.000 (0.260)	loss 7.847 (7.642)	prob 3.445 (3.632)	GS 32.672 (35.228)	mem 73.116
Train: [52][1220/1500]	BT 0.036 (0.294)	DT 0.001 (0.258)	loss 7.887 (7.526)	prob 3.936 (3.838)	GS 35.328 (33.896)	mem 73.117
Train: [52][1230/1500]	BT 0.036 (0.292)	DT 0.001 (0.256)	loss 7.970 (7.496)	prob 4.116 (3.963)	GS 35.109 (33.064)	mem 73.116
Train: [52][1240/1500]	BT 0.031 (0.293)	DT 0.000 (0.257)	loss 7.436 (7.519)	prob 3.275 (3.891)	GS 36.328 (33.234)	mem 73.117
Train: [52][1250/1500]	BT 0.054 (0.291)	DT 0.008 (0.255)	loss 7.294 (7.504)	prob 4.616 (3.854)	GS 35.781 (33.169)	mem 73.116
Train: [52][1260/1500]	BT 0.038 (0.292)	DT 0.001 (0.256)	loss 7.486 (7.585)	prob 4.181 (3.748)	GS 31.469 (33.236)	mem 73.117
Train: [52][1270/1500]	BT 0.039 (0.290)	DT 0.001 (0.254)	loss 7.379 (7.535)	prob 3.886 (3.781)	GS 36.625 (32.991)	mem 73.117
Train: [52][1280/1500]	BT 0.031 (0.292)	DT 0.000 (0.256)	loss 7.438 (7.551)	prob 4.070 (3.704)	GS 35.641 (33.196)	mem 73.120
Train: [52][1290/1500]	BT 0.029 (0.290)	DT 0.000 (0.254)	loss 7.459 (7.548)	prob 3.881 (3.697)	GS 31.766 (33.128)	mem 73.120
Train: [52][1300/1500]	BT 0.039 (0.288)	DT 0.001 (0.252)	loss 7.143 (7.530)	prob 3.953 (3.726)	GS 34.594 (33.049)	mem 73.120
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [52][1310/1500]	BT 0.072 (0.290)	DT 0.005 (0.254)	loss 7.842 (7.585)	prob 3.779 (3.668)	GS 31.359 (32.850)	mem 73.120
Train: [52][1320/1500]	BT 0.038 (0.289)	DT 0.001 (0.252)	loss 7.077 (7.498)	prob 3.596 (3.651)	GS 32.062 (33.059)	mem 73.121
Train: [52][1330/1500]	BT 0.031 (0.292)	DT 0.000 (0.256)	loss 7.749 (7.507)	prob 4.113 (3.631)	GS 32.188 (33.111)	mem 73.118
Train: [52][1340/1500]	BT 0.036 (0.290)	DT 0.001 (0.254)	loss 7.671 (7.475)	prob 4.277 (3.689)	GS 31.516 (32.798)	mem 73.118
Train: [52][1350/1500]	BT 0.068 (0.293)	DT 0.003 (0.257)	loss 7.343 (7.446)	prob 4.605 (3.728)	GS 34.578 (32.537)	mem 73.118
Train: [52][1360/1500]	BT 0.038 (0.291)	DT 0.000 (0.255)	loss 7.551 (7.361)	prob 3.380 (3.392)	GS 33.375 (33.598)	mem 73.121
Train: [52][1370/1500]	BT 0.035 (0.291)	DT 0.000 (0.255)	loss 7.161 (7.347)	prob 3.935 (3.638)	GS 34.766 (33.114)	mem 73.120
Train: [52][1380/1500]	BT 0.058 (0.290)	DT 0.011 (0.253)	loss 7.093 (7.378)	prob 3.964 (3.562)	GS 33.891 (33.388)	mem 73.120
Train: [52][1390/1500]	BT 0.046 (0.288)	DT 0.001 (0.252)	loss 7.149 (7.404)	prob 4.394 (3.587)	GS 33.656 (33.178)	mem 73.122
Train: [52][1400/1500]	BT 0.031 (0.290)	DT 0.000 (0.253)	loss 7.471 (7.429)	prob 3.666 (3.558)	GS 32.016 (33.200)	mem 73.128
Train: [52][1410/1500]	BT 0.039 (0.288)	DT 0.001 (0.252)	loss 7.692 (7.461)	prob 2.799 (3.109)	GS 34.141 (33.977)	mem 73.129
Train: [52][1420/1500]	BT 0.026 (0.292)	DT 0.000 (0.255)	loss 7.758 (7.427)	prob 3.696 (3.315)	GS 34.391 (33.908)	mem 73.038
Train: [52][1430/1500]	BT 0.029 (0.290)	DT 0.000 (0.254)	loss 7.370 (7.403)	prob 3.281 (3.341)	GS 33.594 (33.687)	mem 73.038
Train: [52][1440/1500]	BT 0.026 (0.288)	DT 0.000 (0.252)	loss 7.736 (7.405)	prob 3.381 (3.336)	GS 34.953 (33.733)	mem 73.038
Train: [52][1450/1500]	BT 0.026 (0.290)	DT 0.000 (0.253)	loss 7.346 (7.420)	prob 3.300 (3.336)	GS 35.234 (33.468)	mem 73.040
Train: [52][1460/1500]	BT 0.026 (0.288)	DT 0.000 (0.252)	loss 7.657 (7.553)	prob 3.545 (3.422)	GS 31.938 (32.553)	mem 73.040
Train: [52][1470/1500]	BT 0.031 (0.291)	DT 0.000 (0.255)	loss 7.835 (7.523)	prob 2.399 (3.401)	GS 30.469 (32.859)	mem 10.823
Train: [52][1480/1500]	BT 0.025 (0.289)	DT 0.000 (0.253)	loss 7.319 (7.507)	prob 3.526 (3.275)	GS 34.703 (33.192)	mem 10.823
Train: [52][1490/1500]	BT 0.031 (0.287)	DT 0.000 (0.251)	loss 7.067 (7.518)	prob 3.378 (3.235)	GS 32.469 (33.081)	mem 10.748
Train: [52][1500/1500]	BT 0.027 (0.286)	DT 0.000 (0.250)	loss 8.286 (7.522)	prob 2.127 (3.175)	GS 35.531 (33.088)	mem 7.936
Train: [52][1510/1500]	BT 0.023 (0.285)	DT 0.000 (0.248)	loss 8.199 (7.569)	prob 2.343 (2.801)	GS 35.250 (32.244)	mem 7.936
epoch 52, total time 429.83
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [53][1/1500]	BT 24.681 (24.681)	DT 24.614 (24.614)	loss 7.421 (7.421)	prob 3.045 (3.045)	GS 34.109 (34.109)	mem 71.711
Train: [53][10/1500]	BT 0.032 (2.863)	DT 0.000 (2.827)	loss 7.540 (7.484)	prob 3.261 (3.098)	GS 32.547 (33.056)	mem 71.739
Train: [53][20/1500]	BT 0.031 (1.449)	DT 0.000 (1.414)	loss 8.044 (7.447)	prob 3.541 (3.083)	GS 34.906 (33.466)	mem 71.739
Train: [53][30/1500]	BT 0.551 (1.041)	DT 0.513 (1.005)	loss 7.531 (7.477)	prob 3.442 (3.151)	GS 32.906 (32.844)	mem 71.742
Train: [53][40/1500]	BT 0.038 (0.908)	DT 0.001 (0.871)	loss 8.028 (7.524)	prob 3.058 (3.040)	GS 35.844 (33.071)	mem 71.751
Train: [53][50/1500]	BT 0.039 (0.757)	DT 0.001 (0.720)	loss 7.946 (7.554)	prob 2.738 (3.004)	GS 36.297 (32.948)	mem 71.762
Train: [53][60/1500]	BT 0.039 (0.665)	DT 0.001 (0.628)	loss 7.290 (7.606)	prob 3.675 (3.236)	GS 33.500 (32.027)	mem 71.769
Train: [53][70/1500]	BT 0.038 (0.576)	DT 0.001 (0.539)	loss 7.334 (7.600)	prob 3.991 (3.339)	GS 30.875 (31.349)	mem 71.770
Train: [53][80/1500]	BT 0.045 (0.561)	DT 0.002 (0.523)	loss 7.947 (7.564)	prob 1.882 (3.263)	GS 38.703 (31.463)	mem 71.787
Train: [53][90/1500]	BT 0.034 (0.518)	DT 0.001 (0.480)	loss 7.645 (7.569)	prob 3.513 (3.128)	GS 26.516 (31.310)	mem 71.788
Train: [53][100/1500]	BT 0.092 (0.535)	DT 0.010 (0.495)	loss 7.613 (7.578)	prob 2.267 (3.105)	GS 32.156 (31.498)	mem 71.814
Train: [53][110/1500]	BT 0.062 (0.500)	DT 0.002 (0.457)	loss 7.606 (7.682)	prob 3.129 (2.452)	GS 37.500 (33.300)	mem 71.816
Train: [53][120/1500]	BT 0.054 (0.477)	DT 0.001 (0.433)	loss 7.115 (7.635)	prob 2.484 (2.463)	GS 30.172 (33.439)	mem 71.826
Train: [53][130/1500]	BT 0.072 (0.495)	DT 0.003 (0.451)	loss 7.657 (7.624)	prob 2.313 (2.551)	GS 35.484 (33.360)	mem 71.828
Train: [53][140/1500]	BT 0.072 (0.464)	DT 0.006 (0.419)	loss 7.193 (7.641)	prob 2.564 (2.613)	GS 32.328 (32.934)	mem 71.830
Train: [53][150/1500]	BT 0.038 (0.510)	DT 0.000 (0.466)	loss 7.748 (7.655)	prob 2.543 (2.621)	GS 36.906 (33.014)	mem 71.835
Train: [53][160/1500]	BT 0.025 (0.480)	DT 0.000 (0.437)	loss 7.937 (7.703)	prob 2.295 (2.347)	GS 34.812 (33.087)	mem 71.837
Train: [53][170/1500]	BT 0.024 (0.485)	DT 0.000 (0.442)	loss 7.554 (7.677)	prob 2.852 (2.454)	GS 32.594 (32.327)	mem 71.845
Train: [53][180/1500]	BT 0.037 (0.460)	DT 0.000 (0.418)	loss 8.068 (7.652)	prob 2.673 (2.571)	GS 31.750 (32.180)	mem 71.846
Train: [53][190/1500]	BT 6.223 (0.470)	DT 6.180 (0.428)	loss 8.259 (7.656)	prob 2.355 (2.557)	GS 35.469 (32.095)	mem 71.849
Train: [53][200/1500]	BT 0.036 (0.449)	DT 0.000 (0.407)	loss 7.454 (7.628)	prob 3.075 (2.567)	GS 34.391 (32.118)	mem 71.851
Train: [53][210/1500]	BT 0.037 (0.429)	DT 0.000 (0.388)	loss 7.149 (7.575)	prob 3.209 (2.641)	GS 37.344 (33.436)	mem 71.854
Train: [53][220/1500]	BT 0.037 (0.426)	DT 0.001 (0.386)	loss 7.325 (7.610)	prob 2.139 (2.645)	GS 33.406 (33.064)	mem 71.854
Train: [53][230/1500]	BT 0.038 (0.409)	DT 0.001 (0.369)	loss 7.501 (7.640)	prob 2.419 (2.544)	GS 37.062 (33.096)	mem 71.858
Train: [53][240/1500]	BT 0.034 (0.405)	DT 0.000 (0.365)	loss 8.235 (7.605)	prob 2.986 (2.475)	GS 33.344 (33.011)	mem 71.859
Train: [53][250/1500]	BT 0.034 (0.391)	DT 0.001 (0.351)	loss 7.450 (7.629)	prob 2.762 (2.466)	GS 32.938 (33.170)	mem 71.859
Train: [53][260/1500]	BT 0.038 (0.377)	DT 0.000 (0.337)	loss 7.665 (7.611)	prob 3.676 (2.613)	GS 36.312 (33.395)	mem 71.862
Train: [53][270/1500]	BT 0.025 (0.383)	DT 0.000 (0.344)	loss 8.153 (7.601)	prob 3.433 (2.866)	GS 33.016 (32.087)	mem 71.862
Train: [53][280/1500]	BT 0.027 (0.371)	DT 0.000 (0.332)	loss 7.417 (7.613)	prob 4.139 (2.863)	GS 31.797 (32.179)	mem 71.864
Train: [53][290/1500]	BT 0.037 (0.370)	DT 0.001 (0.331)	loss 7.417 (7.602)	prob 3.126 (2.835)	GS 35.984 (32.006)	mem 71.916
Train: [53][300/1500]	BT 0.034 (0.359)	DT 0.001 (0.320)	loss 8.041 (7.622)	prob 2.038 (2.783)	GS 33.156 (32.195)	mem 71.917
Train: [53][310/1500]	BT 2.630 (0.357)	DT 2.593 (0.318)	loss 7.424 (7.519)	prob 3.245 (2.818)	GS 32.312 (33.472)	mem 72.066
Train: [53][320/1500]	BT 0.063 (0.350)	DT 0.004 (0.311)	loss 7.897 (7.686)	prob 2.954 (2.704)	GS 31.766 (33.064)	mem 72.165
Train: [53][330/1500]	BT 0.139 (0.341)	DT 0.093 (0.302)	loss 7.993 (7.680)	prob 3.472 (2.826)	GS 33.797 (33.086)	mem 72.164
Train: [53][340/1500]	BT 0.058 (0.351)	DT 0.003 (0.311)	loss 7.484 (7.642)	prob 2.969 (2.888)	GS 34.703 (33.106)	mem 72.706
Train: [53][350/1500]	BT 0.065 (0.345)	DT 0.016 (0.305)	loss 7.334 (7.628)	prob 4.129 (2.932)	GS 37.672 (33.169)	mem 72.901
Train: [53][360/1500]	BT 0.036 (0.362)	DT 0.000 (0.322)	loss 7.655 (7.720)	prob 4.044 (3.114)	GS 33.422 (33.955)	mem 73.053
Train: [53][370/1500]	BT 0.037 (0.353)	DT 0.001 (0.313)	loss 7.488 (7.636)	prob 3.231 (3.103)	GS 32.812 (32.838)	mem 73.052
Train: [53][380/1500]	BT 0.038 (0.350)	DT 0.001 (0.311)	loss 7.524 (7.614)	prob 3.030 (2.986)	GS 32.250 (33.709)	mem 73.053
Train: [53][390/1500]	BT 0.031 (0.350)	DT 0.000 (0.310)	loss 7.442 (7.633)	prob 3.556 (2.986)	GS 35.078 (33.519)	mem 73.055
Train: [53][400/1500]	BT 0.038 (0.342)	DT 0.001 (0.302)	loss 8.069 (7.665)	prob 3.313 (2.998)	GS 31.750 (33.341)	mem 73.056
Train: [53][410/1500]	BT 0.052 (0.346)	DT 0.009 (0.306)	loss 7.835 (7.606)	prob 2.988 (3.488)	GS 36.812 (33.391)	mem 73.056
Train: [53][420/1500]	BT 0.096 (0.339)	DT 0.020 (0.299)	loss 7.422 (7.520)	prob 3.497 (3.611)	GS 35.609 (32.695)	mem 73.058
Train: [53][430/1500]	BT 0.070 (0.332)	DT 0.004 (0.293)	loss 8.189 (7.519)	prob 3.343 (3.673)	GS 36.531 (32.935)	mem 73.058
Train: [53][440/1500]	BT 0.030 (0.346)	DT 0.000 (0.307)	loss 7.366 (7.526)	prob 3.657 (3.616)	GS 29.750 (32.792)	mem 73.059
Train: [53][450/1500]	BT 0.050 (0.339)	DT 0.000 (0.300)	loss 7.572 (7.562)	prob 2.641 (3.515)	GS 33.859 (32.786)	mem 73.059
Train: [53][460/1500]	BT 0.029 (0.360)	DT 0.000 (0.321)	loss 7.545 (7.582)	prob 2.839 (3.134)	GS 31.469 (33.972)	mem 73.062
Train: [53][470/1500]	BT 0.034 (0.353)	DT 0.000 (0.314)	loss 7.916 (7.705)	prob 3.310 (3.124)	GS 33.172 (32.331)	mem 73.063
Train: [53][480/1500]	BT 0.025 (0.357)	DT 0.000 (0.318)	loss 8.056 (7.713)	prob 3.184 (3.210)	GS 33.609 (32.402)	mem 73.063
Train: [53][490/1500]	BT 0.036 (0.350)	DT 0.000 (0.312)	loss 7.946 (7.721)	prob 3.199 (3.302)	GS 38.125 (32.507)	mem 73.063
Train: [53][500/1500]	BT 0.048 (0.344)	DT 0.016 (0.306)	loss 7.492 (7.732)	prob 3.732 (3.254)	GS 33.062 (32.428)	mem 73.064
Train: [53][510/1500]	BT 0.037 (0.348)	DT 0.001 (0.309)	loss 7.524 (7.570)	prob 3.207 (3.566)	GS 37.453 (33.695)	mem 73.066
Train: [53][520/1500]	BT 0.037 (0.342)	DT 0.001 (0.303)	loss 7.396 (7.589)	prob 3.270 (3.208)	GS 32.812 (33.707)	mem 73.065
Train: [53][530/1500]	BT 0.039 (0.342)	DT 0.001 (0.303)	loss 8.026 (7.630)	prob 3.087 (3.099)	GS 33.984 (34.099)	mem 73.097
Train: [53][540/1500]	BT 0.038 (0.337)	DT 0.001 (0.299)	loss 7.851 (7.634)	prob 4.074 (3.099)	GS 33.094 (33.552)	mem 73.096
Train: [53][550/1500]	BT 0.040 (0.335)	DT 0.001 (0.297)	loss 7.585 (7.650)	prob 3.178 (3.081)	GS 34.656 (33.387)	mem 73.098
Train: [53][560/1500]	BT 0.038 (0.334)	DT 0.001 (0.296)	loss 7.644 (7.627)	prob 3.495 (3.097)	GS 33.938 (31.727)	mem 73.101
Train: [53][570/1500]	BT 0.039 (0.329)	DT 0.001 (0.291)	loss 8.925 (7.766)	prob 2.550 (2.971)	GS 36.828 (32.821)	mem 73.100
Train: [53][580/1500]	BT 0.039 (0.330)	DT 0.001 (0.292)	loss 7.273 (7.699)	prob 3.447 (3.085)	GS 33.078 (32.670)	mem 73.102
Train: [53][590/1500]	BT 0.049 (0.326)	DT 0.000 (0.287)	loss 7.894 (7.718)	prob 4.082 (3.049)	GS 35.188 (32.914)	mem 73.102
Train: [53][600/1500]	BT 3.851 (0.328)	DT 3.801 (0.289)	loss 8.520 (7.727)	prob 2.423 (2.982)	GS 35.922 (32.903)	mem 73.100
Train: [53][610/1500]	BT 0.075 (0.332)	DT 0.007 (0.293)	loss 7.391 (7.541)	prob 3.664 (2.720)	GS 31.688 (33.300)	mem 73.099
Train: [53][620/1500]	BT 0.030 (0.351)	DT 0.001 (0.312)	loss 7.741 (7.662)	prob 3.419 (2.920)	GS 29.828 (32.423)	mem 73.099
Train: [53][630/1500]	BT 0.031 (0.346)	DT 0.000 (0.307)	loss 8.085 (7.687)	prob 2.983 (2.928)	GS 31.844 (32.473)	mem 73.100
Train: [53][640/1500]	BT 0.038 (0.341)	DT 0.001 (0.302)	loss 8.021 (7.720)	prob 3.248 (2.878)	GS 34.984 (32.486)	mem 73.101
Train: [53][650/1500]	BT 0.039 (0.340)	DT 0.001 (0.302)	loss 8.041 (7.730)	prob 3.036 (2.847)	GS 35.953 (32.693)	mem 73.100
Train: [53][660/1500]	BT 0.039 (0.336)	DT 0.001 (0.297)	loss 7.979 (7.687)	prob 3.032 (2.942)	GS 34.250 (32.392)	mem 73.099
Train: [53][670/1500]	BT 0.038 (0.336)	DT 0.001 (0.297)	loss 8.281 (7.668)	prob 2.843 (2.894)	GS 34.797 (32.710)	mem 73.101
Train: [53][680/1500]	BT 0.365 (0.332)	DT 0.328 (0.294)	loss 7.446 (7.632)	prob 3.848 (3.062)	GS 35.344 (32.324)	mem 73.101
Train: [53][690/1500]	BT 0.038 (0.328)	DT 0.001 (0.289)	loss 8.561 (7.646)	prob 2.814 (3.062)	GS 33.078 (32.414)	mem 73.101
Train: [53][700/1500]	BT 0.059 (0.333)	DT 0.003 (0.294)	loss 7.749 (7.654)	prob 2.366 (3.062)	GS 34.016 (32.567)	mem 73.100
Train: [53][710/1500]	BT 0.038 (0.334)	DT 0.001 (0.295)	loss 8.632 (7.830)	prob 1.915 (2.557)	GS 34.656 (34.131)	mem 73.104
Train: [53][720/1500]	BT 0.038 (0.330)	DT 0.001 (0.291)	loss 7.492 (7.736)	prob 4.003 (3.018)	GS 31.797 (32.703)	mem 73.103
Train: [53][730/1500]	BT 0.049 (0.326)	DT 0.010 (0.287)	loss 8.464 (7.759)	prob 1.927 (2.983)	GS 34.891 (32.372)	mem 73.103
Train: [53][740/1500]	BT 0.033 (0.328)	DT 0.001 (0.289)	loss 7.395 (7.754)	prob 3.934 (2.992)	GS 34.781 (32.355)	mem 73.103
Train: [53][750/1500]	BT 0.039 (0.324)	DT 0.001 (0.285)	loss 7.725 (7.700)	prob 3.289 (3.075)	GS 35.734 (32.332)	mem 73.104
Train: [53][760/1500]	BT 0.037 (0.324)	DT 0.001 (0.285)	loss 7.665 (7.777)	prob 3.830 (3.060)	GS 33.047 (32.709)	mem 73.110
Train: [53][770/1500]	BT 0.031 (0.325)	DT 0.000 (0.286)	loss 7.637 (7.815)	prob 3.651 (3.077)	GS 30.922 (32.733)	mem 73.110
Train: [53][780/1500]	BT 0.037 (0.323)	DT 0.001 (0.285)	loss 7.667 (7.832)	prob 3.599 (3.018)	GS 31.750 (32.827)	mem 73.113
Train: [53][790/1500]	BT 0.036 (0.321)	DT 0.001 (0.282)	loss 7.683 (7.833)	prob 4.380 (3.141)	GS 33.500 (32.600)	mem 73.122
Train: [53][800/1500]	BT 0.038 (0.320)	DT 0.001 (0.282)	loss 8.284 (7.848)	prob 3.363 (3.278)	GS 35.203 (32.233)	mem 73.122
Train: [53][810/1500]	BT 0.033 (0.322)	DT 0.000 (0.283)	loss 7.333 (7.626)	prob 3.574 (3.086)	GS 32.141 (32.452)	mem 73.045
Train: [53][820/1500]	BT 0.037 (0.318)	DT 0.001 (0.280)	loss 7.890 (7.669)	prob 3.713 (3.197)	GS 29.953 (31.729)	mem 73.046
Train: [53][830/1500]	BT 0.025 (0.321)	DT 0.000 (0.282)	loss 7.457 (7.748)	prob 3.982 (3.098)	GS 33.828 (32.057)	mem 73.032
Train: [53][840/1500]	BT 0.025 (0.317)	DT 0.000 (0.279)	loss 8.020 (7.772)	prob 3.488 (3.123)	GS 34.141 (32.100)	mem 73.031
Train: [53][850/1500]	BT 0.038 (0.314)	DT 0.000 (0.276)	loss 8.837 (7.757)	prob 3.092 (3.155)	GS 35.609 (32.210)	mem 73.032
Train: [53][860/1500]	BT 0.036 (0.314)	DT 0.001 (0.276)	loss 7.965 (7.628)	prob 3.107 (3.584)	GS 34.953 (32.461)	mem 73.032
Train: [53][870/1500]	BT 0.037 (0.311)	DT 0.001 (0.273)	loss 7.858 (7.668)	prob 3.742 (3.458)	GS 34.562 (32.100)	mem 73.032
Train: [53][880/1500]	BT 0.076 (0.313)	DT 0.021 (0.274)	loss 7.557 (7.675)	prob 3.570 (3.356)	GS 36.453 (32.549)	mem 73.033
Train: [53][890/1500]	BT 0.079 (0.310)	DT 0.002 (0.271)	loss 7.753 (7.707)	prob 3.670 (3.275)	GS 35.969 (32.973)	mem 73.032
Train: [53][900/1500]	BT 0.028 (0.322)	DT 0.000 (0.283)	loss 7.944 (7.693)	prob 3.227 (3.247)	GS 35.719 (33.362)	mem 73.052
Train: [53][910/1500]	BT 0.030 (0.319)	DT 0.000 (0.280)	loss 7.550 (7.765)	prob 4.380 (3.348)	GS 32.328 (32.831)	mem 73.054
Train: [53][920/1500]	BT 0.027 (0.316)	DT 0.000 (0.277)	loss 7.638 (7.748)	prob 4.429 (3.477)	GS 35.625 (32.188)	mem 73.039
Train: [53][930/1500]	BT 0.038 (0.316)	DT 0.001 (0.277)	loss 7.816 (7.703)	prob 3.778 (3.465)	GS 34.234 (32.565)	mem 73.040
Train: [53][940/1500]	BT 0.039 (0.313)	DT 0.001 (0.275)	loss 8.022 (7.686)	prob 3.410 (3.449)	GS 31.281 (32.344)	mem 73.040
Train: [53][950/1500]	BT 0.036 (0.315)	DT 0.001 (0.276)	loss 7.306 (7.634)	prob 3.662 (3.466)	GS 31.234 (32.316)	mem 73.040
Train: [53][960/1500]	BT 0.038 (0.312)	DT 0.001 (0.273)	loss 8.280 (7.732)	prob 3.424 (3.198)	GS 31.141 (32.259)	mem 73.040
Train: [53][970/1500]	BT 0.039 (0.309)	DT 0.001 (0.271)	loss 8.664 (7.673)	prob 2.332 (3.061)	GS 33.516 (32.711)	mem 73.041
Train: [53][980/1500]	BT 0.039 (0.311)	DT 0.001 (0.272)	loss 7.854 (7.642)	prob 3.638 (3.070)	GS 34.219 (32.832)	mem 73.042
Train: [53][990/1500]	BT 0.040 (0.308)	DT 0.001 (0.270)	loss 7.873 (7.690)	prob 3.359 (3.080)	GS 33.703 (32.752)	mem 73.043
Train: [53][1000/1500]	BT 0.037 (0.309)	DT 0.001 (0.270)	loss 7.771 (7.672)	prob 3.480 (3.111)	GS 39.625 (32.768)	mem 73.044
Train: [53][1010/1500]	BT 0.034 (0.306)	DT 0.000 (0.268)	loss 7.645 (7.603)	prob 3.381 (3.321)	GS 33.141 (32.191)	mem 73.045
Train: [53][1020/1500]	BT 0.033 (0.312)	DT 0.001 (0.274)	loss 7.629 (7.554)	prob 3.431 (3.313)	GS 33.812 (31.945)	mem 73.041
Train: [53][1030/1500]	BT 0.032 (0.309)	DT 0.000 (0.271)	loss 7.276 (7.531)	prob 4.514 (3.330)	GS 34.969 (31.538)	mem 73.041
Train: [53][1040/1500]	BT 0.033 (0.307)	DT 0.001 (0.268)	loss 8.082 (7.575)	prob 2.782 (3.162)	GS 29.484 (32.063)	mem 73.041
Train: [53][1050/1500]	BT 0.031 (0.307)	DT 0.000 (0.268)	loss 8.128 (7.585)	prob 2.857 (3.127)	GS 33.250 (32.370)	mem 73.056
Train: [53][1060/1500]	BT 0.027 (0.304)	DT 0.000 (0.266)	loss 7.920 (7.673)	prob 2.743 (2.873)	GS 32.891 (32.941)	mem 73.056
Train: [53][1070/1500]	BT 0.039 (0.304)	DT 0.000 (0.266)	loss 7.880 (7.609)	prob 3.756 (3.137)	GS 35.969 (33.305)	mem 73.061
Train: [53][1080/1500]	BT 0.068 (0.302)	DT 0.002 (0.264)	loss 7.784 (7.668)	prob 3.488 (3.029)	GS 34.688 (33.336)	mem 73.062
Train: [53][1090/1500]	BT 0.047 (0.301)	DT 0.003 (0.263)	loss 7.837 (7.699)	prob 2.838 (2.896)	GS 34.953 (33.520)	mem 73.061
Train: [53][1100/1500]	BT 0.081 (0.305)	DT 0.015 (0.267)	loss 7.448 (7.710)	prob 3.276 (2.941)	GS 32.844 (33.221)	mem 73.060
Train: [53][1110/1500]	BT 0.030 (0.308)	DT 0.000 (0.269)	loss 7.749 (7.758)	prob 4.108 (2.989)	GS 34.531 (34.734)	mem 73.060
Train: [53][1120/1500]	BT 0.024 (0.305)	DT 0.000 (0.267)	loss 8.049 (7.678)	prob 3.638 (3.087)	GS 34.031 (33.939)	mem 73.061
Train: [53][1130/1500]	BT 0.038 (0.303)	DT 0.001 (0.265)	loss 7.649 (7.751)	prob 3.563 (3.019)	GS 33.547 (33.617)	mem 73.063
Train: [53][1140/1500]	BT 0.029 (0.306)	DT 0.000 (0.268)	loss 7.992 (7.801)	prob 3.320 (3.009)	GS 35.312 (34.015)	mem 73.065
Train: [53][1150/1500]	BT 0.030 (0.304)	DT 0.000 (0.266)	loss 7.535 (7.790)	prob 4.083 (3.118)	GS 30.844 (33.463)	mem 73.066
Train: [53][1160/1500]	BT 0.038 (0.304)	DT 0.001 (0.266)	loss 7.855 (7.868)	prob 2.954 (3.311)	GS 36.500 (33.645)	mem 73.069
Train: [53][1170/1500]	BT 0.036 (0.301)	DT 0.001 (0.263)	loss 7.665 (7.859)	prob 4.019 (3.309)	GS 32.984 (33.298)	mem 73.068
Train: [53][1180/1500]	BT 0.038 (0.299)	DT 0.001 (0.261)	loss 7.993 (7.849)	prob 3.120 (3.308)	GS 32.641 (33.174)	mem 73.069
Train: [53][1190/1500]	BT 0.038 (0.299)	DT 0.001 (0.261)	loss 7.809 (7.810)	prob 4.300 (3.433)	GS 33.938 (32.868)	mem 73.071
Train: [53][1200/1500]	BT 0.038 (0.297)	DT 0.001 (0.259)	loss 7.844 (7.794)	prob 3.212 (3.438)	GS 34.484 (32.862)	mem 73.071
Train: [53][1210/1500]	BT 0.059 (0.299)	DT 0.009 (0.261)	loss 7.900 (7.953)	prob 2.945 (3.372)	GS 37.781 (33.300)	mem 73.071
Train: [53][1220/1500]	BT 0.078 (0.297)	DT 0.011 (0.259)	loss 7.759 (7.875)	prob 3.962 (3.338)	GS 32.125 (33.265)	mem 73.071
Train: [53][1230/1500]	BT 0.031 (0.302)	DT 0.000 (0.264)	loss 7.997 (7.894)	prob 3.594 (3.313)	GS 32.578 (33.239)	mem 73.073
Train: [53][1240/1500]	BT 0.031 (0.300)	DT 0.000 (0.262)	loss 7.702 (7.872)	prob 3.925 (3.416)	GS 34.938 (33.196)	mem 73.073
Train: [53][1250/1500]	BT 0.029 (0.309)	DT 0.000 (0.271)	loss 8.068 (7.874)	prob 2.752 (3.423)	GS 32.844 (33.090)	mem 73.073
Train: [53][1260/1500]	BT 0.030 (0.306)	DT 0.000 (0.268)	loss 7.626 (7.897)	prob 4.454 (3.395)	GS 31.031 (33.191)	mem 73.075
Train: [53][1270/1500]	BT 0.036 (0.304)	DT 0.001 (0.266)	loss 7.692 (7.950)	prob 4.226 (3.573)	GS 29.531 (33.033)	mem 73.075
Train: [53][1280/1500]	BT 0.065 (0.307)	DT 0.016 (0.269)	loss 8.513 (7.961)	prob 2.729 (3.533)	GS 38.188 (33.271)	mem 73.077
Train: [53][1290/1500]	BT 0.091 (0.305)	DT 0.002 (0.267)	loss 8.205 (7.965)	prob 3.248 (3.428)	GS 35.656 (33.142)	mem 73.076
Train: [53][1300/1500]	BT 0.078 (0.310)	DT 0.024 (0.272)	loss 8.420 (7.935)	prob 3.343 (3.437)	GS 31.891 (33.029)	mem 73.075
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [53][1310/1500]	BT 0.084 (0.309)	DT 0.015 (0.270)	loss 7.467 (7.779)	prob 3.296 (3.698)	GS 34.250 (34.428)	mem 73.077
Train: [53][1320/1500]	BT 0.033 (0.317)	DT 0.001 (0.279)	loss 7.506 (7.823)	prob 4.993 (3.593)	GS 35.250 (33.678)	mem 73.076
Train: [53][1330/1500]	BT 0.032 (0.315)	DT 0.000 (0.277)	loss 8.145 (7.874)	prob 3.605 (3.646)	GS 35.938 (34.002)	mem 73.077
Train: [53][1340/1500]	BT 0.036 (0.316)	DT 0.001 (0.278)	loss 8.688 (7.880)	prob 3.182 (3.628)	GS 35.172 (33.504)	mem 73.079
Train: [53][1350/1500]	BT 0.038 (0.314)	DT 0.001 (0.275)	loss 7.641 (7.901)	prob 4.302 (3.652)	GS 36.078 (33.704)	mem 73.078
Train: [53][1360/1500]	BT 0.034 (0.317)	DT 0.000 (0.279)	loss 7.641 (7.821)	prob 4.007 (3.395)	GS 32.688 (33.467)	mem 73.079
Train: [53][1370/1500]	BT 0.029 (0.315)	DT 0.000 (0.277)	loss 7.707 (7.845)	prob 4.637 (3.602)	GS 32.953 (32.634)	mem 73.079
Train: [53][1380/1500]	BT 0.029 (0.313)	DT 0.000 (0.275)	loss 9.066 (7.844)	prob 3.288 (3.614)	GS 34.141 (33.039)	mem 73.079
Train: [53][1390/1500]	BT 0.027 (0.316)	DT 0.000 (0.278)	loss 8.742 (7.809)	prob 3.091 (3.646)	GS 38.078 (33.563)	mem 73.081
Train: [53][1400/1500]	BT 0.035 (0.314)	DT 0.001 (0.276)	loss 7.473 (7.789)	prob 4.476 (3.638)	GS 32.047 (33.105)	mem 73.081
Train: [53][1410/1500]	BT 0.032 (0.315)	DT 0.000 (0.277)	loss 7.583 (7.787)	prob 3.877 (3.981)	GS 31.000 (32.759)	mem 73.114
Train: [53][1420/1500]	BT 0.038 (0.313)	DT 0.001 (0.275)	loss 7.303 (7.753)	prob 4.202 (3.973)	GS 32.766 (32.188)	mem 73.114
Train: [53][1430/1500]	BT 0.039 (0.311)	DT 0.001 (0.273)	loss 7.571 (7.699)	prob 4.483 (4.047)	GS 34.594 (32.158)	mem 73.114
Train: [53][1440/1500]	BT 0.038 (0.311)	DT 0.001 (0.273)	loss 8.172 (7.709)	prob 3.352 (3.990)	GS 40.031 (32.404)	mem 73.116
Train: [53][1450/1500]	BT 0.038 (0.309)	DT 0.001 (0.271)	loss 7.796 (7.700)	prob 3.805 (3.876)	GS 31.188 (32.404)	mem 73.116
Train: [53][1460/1500]	BT 0.029 (0.310)	DT 0.000 (0.271)	loss 7.692 (7.723)	prob 3.333 (3.684)	GS 38.484 (32.572)	mem 72.754
Train: [53][1470/1500]	BT 0.028 (0.308)	DT 0.000 (0.270)	loss 7.934 (7.767)	prob 3.886 (3.565)	GS 32.391 (32.359)	mem 72.754
Train: [53][1480/1500]	BT 0.036 (0.308)	DT 0.001 (0.270)	loss 7.289 (7.696)	prob 3.399 (3.639)	GS 33.125 (32.342)	mem 10.147
Train: [53][1490/1500]	BT 0.031 (0.306)	DT 0.000 (0.268)	loss 7.868 (7.644)	prob 4.250 (3.623)	GS 31.906 (32.367)	mem 8.096
Train: [53][1500/1500]	BT 0.030 (0.304)	DT 0.000 (0.266)	loss 7.280 (7.642)	prob 3.058 (3.615)	GS 39.656 (32.371)	mem 8.095
Train: [53][1510/1500]	BT 0.027 (0.303)	DT 0.000 (0.265)	loss 7.974 (7.623)	prob 3.257 (3.947)	GS 37.469 (30.972)	mem 8.020
epoch 53, total time 457.19
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [54][1/1500]	BT 18.124 (18.124)	DT 18.065 (18.065)	loss 7.580 (7.580)	prob 3.639 (3.639)	GS 32.484 (32.484)	mem 71.545
Train: [54][10/1500]	BT 0.039 (2.266)	DT 0.001 (2.226)	loss 7.753 (7.658)	prob 3.144 (3.329)	GS 32.828 (34.264)	mem 71.787
Train: [54][20/1500]	BT 0.030 (1.151)	DT 0.000 (1.114)	loss 7.892 (7.491)	prob 2.930 (3.522)	GS 32.797 (33.211)	mem 71.793
Train: [54][30/1500]	BT 1.179 (0.947)	DT 1.141 (0.910)	loss 7.860 (7.526)	prob 3.581 (3.435)	GS 35.484 (33.301)	mem 71.840
Train: [54][40/1500]	BT 0.039 (0.724)	DT 0.001 (0.686)	loss 7.915 (7.541)	prob 3.272 (3.474)	GS 35.625 (33.298)	mem 71.842
Train: [54][50/1500]	BT 0.164 (0.593)	DT 0.125 (0.555)	loss 7.541 (7.540)	prob 4.531 (3.482)	GS 33.953 (32.901)	mem 71.842
Train: [54][60/1500]	BT 0.039 (0.540)	DT 0.001 (0.502)	loss 8.059 (7.646)	prob 3.260 (3.886)	GS 35.875 (31.458)	mem 71.854
Train: [54][70/1500]	BT 0.039 (0.505)	DT 0.001 (0.467)	loss 8.334 (7.608)	prob 2.038 (3.690)	GS 36.125 (32.109)	mem 71.862
Train: [54][80/1500]	BT 0.076 (0.470)	DT 0.007 (0.431)	loss 7.586 (7.575)	prob 3.121 (3.576)	GS 35.500 (32.181)	mem 71.866
Train: [54][90/1500]	BT 0.064 (0.483)	DT 0.006 (0.443)	loss 7.811 (7.557)	prob 3.640 (3.597)	GS 36.250 (32.299)	mem 71.871
Train: [54][100/1500]	BT 0.029 (0.564)	DT 0.000 (0.523)	loss 7.509 (7.534)	prob 4.103 (3.566)	GS 33.203 (32.355)	mem 71.875
Train: [54][110/1500]	BT 0.029 (0.515)	DT 0.000 (0.476)	loss 7.499 (7.537)	prob 3.983 (3.456)	GS 31.234 (31.209)	mem 71.876
Train: [54][120/1500]	BT 0.037 (0.497)	DT 0.000 (0.458)	loss 8.302 (7.633)	prob 3.559 (3.526)	GS 31.891 (31.348)	mem 71.889
Train: [54][130/1500]	BT 0.037 (0.461)	DT 0.001 (0.422)	loss 7.413 (7.603)	prob 3.169 (3.385)	GS 35.062 (31.840)	mem 71.898
Train: [54][140/1500]	BT 0.037 (0.431)	DT 0.000 (0.392)	loss 7.748 (7.582)	prob 2.595 (3.351)	GS 34.688 (31.843)	mem 71.898
Train: [54][150/1500]	BT 0.029 (0.464)	DT 0.000 (0.426)	loss 7.596 (7.595)	prob 3.304 (3.271)	GS 32.531 (32.170)	mem 71.922
Train: [54][160/1500]	BT 0.034 (0.437)	DT 0.000 (0.399)	loss 7.568 (7.553)	prob 3.915 (3.115)	GS 36.031 (31.966)	mem 71.923
Train: [54][170/1500]	BT 0.037 (0.430)	DT 0.001 (0.392)	loss 7.971 (7.639)	prob 2.913 (3.008)	GS 36.719 (32.105)	mem 71.804
Train: [54][180/1500]	BT 0.027 (0.408)	DT 0.000 (0.370)	loss 7.625 (7.618)	prob 3.618 (3.153)	GS 35.703 (32.331)	mem 71.803
Train: [54][190/1500]	BT 0.027 (0.388)	DT 0.000 (0.351)	loss 7.221 (7.563)	prob 3.724 (3.138)	GS 33.047 (32.204)	mem 71.804
Train: [54][200/1500]	BT 0.048 (0.410)	DT 0.000 (0.372)	loss 7.396 (7.556)	prob 2.068 (3.062)	GS 33.031 (32.444)	mem 71.812
Train: [54][210/1500]	BT 0.037 (0.392)	DT 0.001 (0.355)	loss 7.157 (7.559)	prob 3.264 (2.696)	GS 33.641 (32.047)	mem 71.812
Train: [54][220/1500]	BT 0.026 (0.390)	DT 0.000 (0.353)	loss 7.936 (7.613)	prob 2.480 (2.733)	GS 33.734 (32.291)	mem 71.812
Train: [54][230/1500]	BT 0.037 (0.384)	DT 0.000 (0.347)	loss 7.210 (7.566)	prob 3.022 (2.820)	GS 33.719 (32.551)	mem 71.817
Train: [54][240/1500]	BT 0.037 (0.376)	DT 0.001 (0.339)	loss 7.444 (7.585)	prob 2.767 (2.775)	GS 35.531 (32.869)	mem 71.837
Train: [54][250/1500]	BT 0.038 (0.368)	DT 0.001 (0.331)	loss 7.397 (7.590)	prob 2.788 (2.791)	GS 33.234 (32.767)	mem 71.839
Train: [54][260/1500]	BT 0.038 (0.355)	DT 0.000 (0.319)	loss 7.462 (7.468)	prob 2.971 (2.612)	GS 35.391 (33.300)	mem 71.839
Train: [54][270/1500]	BT 0.037 (0.359)	DT 0.006 (0.323)	loss 7.851 (7.533)	prob 3.587 (2.577)	GS 34.469 (32.881)	mem 71.842
Train: [54][280/1500]	BT 0.040 (0.348)	DT 0.001 (0.311)	loss 7.353 (7.520)	prob 2.949 (2.596)	GS 35.266 (32.445)	mem 71.844
Train: [54][290/1500]	BT 0.039 (0.346)	DT 0.001 (0.309)	loss 8.018 (7.576)	prob 2.279 (2.607)	GS 33.719 (32.464)	mem 71.843
Train: [54][300/1500]	BT 0.037 (0.342)	DT 0.001 (0.305)	loss 8.321 (7.573)	prob 2.556 (2.646)	GS 36.016 (32.581)	mem 71.927
Train: [54][310/1500]	BT 0.064 (0.333)	DT 0.003 (0.295)	loss 7.395 (7.642)	prob 3.138 (2.838)	GS 34.234 (31.573)	mem 72.039
Train: [54][320/1500]	BT 0.026 (0.357)	DT 0.000 (0.320)	loss 7.822 (7.664)	prob 2.956 (2.667)	GS 31.672 (32.555)	mem 72.617
Train: [54][330/1500]	BT 0.029 (0.347)	DT 0.000 (0.310)	loss 8.063 (7.706)	prob 2.735 (2.633)	GS 31.781 (32.188)	mem 72.666
Train: [54][340/1500]	BT 0.028 (0.346)	DT 0.000 (0.310)	loss 8.255 (7.701)	prob 3.020 (2.629)	GS 32.109 (32.305)	mem 72.962
Train: [54][350/1500]	BT 0.038 (0.337)	DT 0.001 (0.301)	loss 8.633 (7.726)	prob 2.334 (2.567)	GS 35.797 (32.559)	mem 72.962
Train: [54][360/1500]	BT 0.037 (0.342)	DT 0.000 (0.305)	loss 7.397 (7.558)	prob 3.528 (2.975)	GS 35.094 (33.873)	mem 73.012
Train: [54][370/1500]	BT 0.039 (0.334)	DT 0.001 (0.297)	loss 7.556 (7.615)	prob 4.457 (2.968)	GS 27.344 (32.778)	mem 73.012
Train: [54][380/1500]	BT 0.039 (0.326)	DT 0.001 (0.289)	loss 8.061 (7.648)	prob 2.209 (2.872)	GS 34.297 (32.826)	mem 73.012
Train: [54][390/1500]	BT 0.031 (0.327)	DT 0.000 (0.290)	loss 7.890 (7.645)	prob 3.359 (2.873)	GS 30.688 (33.000)	mem 73.013
Train: [54][400/1500]	BT 0.052 (0.332)	DT 0.010 (0.295)	loss 7.721 (7.701)	prob 3.553 (2.892)	GS 33.531 (33.203)	mem 73.017
Train: [54][410/1500]	BT 0.048 (0.328)	DT 0.010 (0.291)	loss 7.453 (7.781)	prob 2.334 (2.407)	GS 29.109 (32.777)	mem 73.019
Train: [54][420/1500]	BT 0.048 (0.322)	DT 0.000 (0.285)	loss 7.919 (7.831)	prob 4.194 (2.787)	GS 31.906 (31.893)	mem 73.018
Train: [54][430/1500]	BT 0.083 (0.335)	DT 0.006 (0.298)	loss 7.514 (7.780)	prob 3.966 (2.952)	GS 31.391 (32.233)	mem 73.018
Train: [54][440/1500]	BT 22.461 (0.380)	DT 22.415 (0.342)	loss 8.005 (7.759)	prob 3.903 (3.133)	GS 37.656 (32.125)	mem 73.040
Train: [54][450/1500]	BT 0.029 (0.372)	DT 0.000 (0.335)	loss 8.834 (7.771)	prob 1.746 (3.116)	GS 37.719 (32.807)	mem 73.042
Train: [54][460/1500]	BT 0.035 (0.365)	DT 0.000 (0.327)	loss 9.099 (7.978)	prob 2.620 (3.137)	GS 36.891 (34.819)	mem 73.043
Train: [54][470/1500]	BT 0.035 (0.366)	DT 0.000 (0.329)	loss 7.837 (7.936)	prob 4.347 (3.244)	GS 34.078 (33.358)	mem 73.046
Train: [54][480/1500]	BT 0.054 (0.360)	DT 0.000 (0.322)	loss 7.423 (7.891)	prob 3.918 (3.334)	GS 38.266 (32.866)	mem 73.045
Train: [54][490/1500]	BT 0.062 (0.372)	DT 0.002 (0.334)	loss 8.146 (7.854)	prob 3.817 (3.262)	GS 35.062 (33.027)	mem 73.044
Train: [54][500/1500]	BT 0.030 (0.366)	DT 0.000 (0.328)	loss 7.685 (7.850)	prob 4.141 (3.215)	GS 27.547 (32.883)	mem 73.044
Train: [54][510/1500]	BT 0.031 (0.384)	DT 0.000 (0.346)	loss 7.817 (7.751)	prob 4.074 (3.618)	GS 35.344 (33.288)	mem 73.047
Train: [54][520/1500]	BT 0.029 (0.378)	DT 0.000 (0.340)	loss 7.711 (7.764)	prob 3.515 (3.454)	GS 32.953 (33.550)	mem 73.047
Train: [54][530/1500]	BT 0.036 (0.371)	DT 0.000 (0.333)	loss 8.277 (7.780)	prob 3.710 (3.445)	GS 32.219 (33.173)	mem 73.047
Train: [54][540/1500]	BT 0.065 (0.374)	DT 0.010 (0.336)	loss 8.132 (7.770)	prob 3.403 (3.518)	GS 34.078 (32.962)	mem 73.048
Train: [54][550/1500]	BT 0.048 (0.368)	DT 0.001 (0.330)	loss 7.965 (7.777)	prob 4.430 (3.509)	GS 34.234 (32.904)	mem 73.048
Train: [54][560/1500]	BT 0.034 (0.386)	DT 0.000 (0.348)	loss 7.870 (7.858)	prob 4.219 (3.624)	GS 36.703 (33.697)	mem 73.048
Train: [54][570/1500]	BT 0.024 (0.380)	DT 0.000 (0.342)	loss 8.198 (7.724)	prob 3.604 (3.676)	GS 35.047 (33.358)	mem 73.048
Train: [54][580/1500]	BT 0.028 (0.379)	DT 0.000 (0.341)	loss 7.658 (7.737)	prob 4.288 (3.697)	GS 30.312 (32.932)	mem 73.054
Train: [54][590/1500]	BT 0.037 (0.373)	DT 0.000 (0.335)	loss 7.747 (7.756)	prob 2.849 (3.510)	GS 32.203 (33.036)	mem 73.053
Train: [54][600/1500]	BT 0.058 (0.368)	DT 0.011 (0.330)	loss 7.878 (7.758)	prob 2.544 (3.518)	GS 35.219 (32.898)	mem 73.055
Train: [54][610/1500]	BT 0.028 (0.384)	DT 0.000 (0.346)	loss 7.910 (7.818)	prob 3.592 (3.162)	GS 30.219 (33.623)	mem 73.055
Train: [54][620/1500]	BT 0.029 (0.378)	DT 0.000 (0.340)	loss 7.780 (7.791)	prob 3.761 (3.384)	GS 36.953 (33.537)	mem 73.057
Train: [54][630/1500]	BT 0.036 (0.373)	DT 0.001 (0.335)	loss 7.803 (7.786)	prob 3.874 (3.439)	GS 31.875 (32.928)	mem 73.058
Train: [54][640/1500]	BT 0.033 (0.373)	DT 0.001 (0.335)	loss 8.349 (7.757)	prob 2.907 (3.403)	GS 32.797 (33.013)	mem 73.062
Train: [54][650/1500]	BT 0.033 (0.367)	DT 0.000 (0.330)	loss 8.122 (7.756)	prob 3.494 (3.389)	GS 30.625 (33.052)	mem 73.062
Train: [54][660/1500]	BT 0.078 (0.375)	DT 0.012 (0.337)	loss 7.702 (7.734)	prob 3.723 (3.830)	GS 36.062 (32.792)	mem 73.064
Train: [54][670/1500]	BT 0.067 (0.371)	DT 0.011 (0.332)	loss 8.135 (7.789)	prob 3.990 (3.674)	GS 33.781 (32.381)	mem 73.065
Train: [54][680/1500]	BT 0.037 (0.374)	DT 0.000 (0.336)	loss 7.530 (7.714)	prob 3.354 (3.740)	GS 33.359 (32.295)	mem 73.063
Train: [54][690/1500]	BT 0.037 (0.369)	DT 0.001 (0.331)	loss 7.705 (7.709)	prob 3.724 (3.727)	GS 36.672 (32.207)	mem 73.063
Train: [54][700/1500]	BT 0.037 (0.365)	DT 0.001 (0.326)	loss 7.276 (7.698)	prob 3.224 (3.742)	GS 36.359 (32.141)	mem 73.064
Train: [54][710/1500]	BT 0.033 (0.364)	DT 0.001 (0.326)	loss 7.530 (7.689)	prob 4.296 (3.455)	GS 33.250 (31.683)	mem 73.066
Train: [54][720/1500]	BT 0.053 (0.366)	DT 0.006 (0.328)	loss 7.572 (7.617)	prob 4.110 (3.723)	GS 32.594 (30.741)	mem 73.068
Train: [54][730/1500]	BT 0.031 (0.372)	DT 0.000 (0.333)	loss 7.524 (7.596)	prob 3.442 (3.699)	GS 36.078 (31.871)	mem 73.066
Train: [54][740/1500]	BT 0.037 (0.367)	DT 0.000 (0.329)	loss 8.015 (7.611)	prob 3.662 (3.571)	GS 28.281 (31.980)	mem 73.066
Train: [54][750/1500]	BT 0.060 (0.370)	DT 0.016 (0.332)	loss 8.266 (7.600)	prob 3.726 (3.564)	GS 37.031 (32.106)	mem 73.068
Train: [54][760/1500]	BT 0.052 (0.366)	DT 0.006 (0.328)	loss 7.775 (7.562)	prob 3.835 (3.475)	GS 34.078 (32.819)	mem 73.067
Train: [54][770/1500]	BT 0.060 (0.362)	DT 0.016 (0.324)	loss 7.555 (7.492)	prob 3.125 (3.491)	GS 31.578 (32.593)	mem 73.067
Train: [54][780/1500]	BT 0.030 (0.367)	DT 0.000 (0.329)	loss 8.486 (7.496)	prob 2.966 (3.429)	GS 34.531 (32.664)	mem 73.064
Train: [54][790/1500]	BT 0.033 (0.364)	DT 0.000 (0.326)	loss 7.776 (7.517)	prob 3.803 (3.303)	GS 32.266 (32.847)	mem 73.064
Train: [54][800/1500]	BT 0.036 (0.368)	DT 0.000 (0.330)	loss 7.701 (7.533)	prob 3.469 (3.345)	GS 34.906 (32.817)	mem 73.067
Train: [54][810/1500]	BT 0.026 (0.366)	DT 0.000 (0.328)	loss 7.156 (7.487)	prob 3.953 (3.211)	GS 32.156 (33.884)	mem 73.069
Train: [54][820/1500]	BT 0.037 (0.363)	DT 0.000 (0.325)	loss 7.651 (7.520)	prob 3.529 (3.224)	GS 34.406 (32.772)	mem 73.071
Train: [54][830/1500]	BT 0.038 (0.362)	DT 0.001 (0.324)	loss 7.549 (7.523)	prob 3.458 (3.221)	GS 33.594 (32.976)	mem 73.072
Train: [54][840/1500]	BT 0.038 (0.358)	DT 0.000 (0.320)	loss 7.691 (7.523)	prob 4.274 (3.291)	GS 29.375 (32.703)	mem 73.072
Train: [54][850/1500]	BT 0.053 (0.359)	DT 0.010 (0.321)	loss 7.561 (7.524)	prob 3.636 (3.334)	GS 33.484 (32.863)	mem 73.105
Train: [54][860/1500]	BT 0.039 (0.356)	DT 0.001 (0.318)	loss 7.502 (7.533)	prob 3.674 (3.374)	GS 33.625 (33.017)	mem 73.107
Train: [54][870/1500]	BT 0.039 (0.355)	DT 0.001 (0.317)	loss 7.387 (7.470)	prob 3.389 (3.487)	GS 35.969 (32.879)	mem 73.108
Train: [54][880/1500]	BT 0.039 (0.352)	DT 0.001 (0.314)	loss 7.674 (7.457)	prob 3.500 (3.389)	GS 36.203 (32.962)	mem 73.107
Train: [54][890/1500]	BT 0.040 (0.349)	DT 0.001 (0.311)	loss 7.611 (7.420)	prob 2.844 (3.383)	GS 34.172 (33.175)	mem 73.106
Train: [54][900/1500]	BT 0.039 (0.349)	DT 0.001 (0.311)	loss 7.364 (7.425)	prob 2.629 (3.279)	GS 36.688 (33.266)	mem 73.106
Train: [54][910/1500]	BT 0.038 (0.346)	DT 0.001 (0.308)	loss 7.322 (7.415)	prob 4.240 (3.326)	GS 28.422 (30.916)	mem 73.106
Train: [54][920/1500]	BT 0.084 (0.345)	DT 0.034 (0.307)	loss 7.490 (7.435)	prob 3.477 (3.345)	GS 34.016 (31.422)	mem 73.107
Train: [54][930/1500]	BT 0.037 (0.346)	DT 0.000 (0.308)	loss 7.356 (7.432)	prob 3.049 (3.181)	GS 31.141 (32.223)	mem 73.109
Train: [54][940/1500]	BT 0.039 (0.342)	DT 0.001 (0.304)	loss 7.700 (7.431)	prob 3.590 (3.129)	GS 31.828 (32.384)	mem 73.110
Train: [54][950/1500]	BT 0.038 (0.343)	DT 0.001 (0.305)	loss 8.352 (7.440)	prob 1.838 (3.071)	GS 35.688 (32.629)	mem 73.112
Train: [54][960/1500]	BT 0.039 (0.340)	DT 0.001 (0.302)	loss 7.890 (7.477)	prob 2.271 (2.888)	GS 34.422 (31.755)	mem 73.113
Train: [54][970/1500]	BT 0.040 (0.338)	DT 0.001 (0.300)	loss 7.854 (7.417)	prob 3.058 (2.769)	GS 35.406 (32.352)	mem 73.113
Train: [54][980/1500]	BT 0.052 (0.337)	DT 0.003 (0.299)	loss 7.722 (7.404)	prob 2.906 (2.765)	GS 36.625 (32.515)	mem 73.114
Train: [54][990/1500]	BT 1.491 (0.336)	DT 1.451 (0.297)	loss 7.294 (7.429)	prob 3.235 (2.777)	GS 36.672 (33.025)	mem 73.115
Train: [54][1000/1500]	BT 0.031 (0.335)	DT 0.001 (0.296)	loss 7.261 (7.434)	prob 3.061 (2.733)	GS 32.406 (33.171)	mem 73.115
Train: [54][1010/1500]	BT 0.026 (0.334)	DT 0.000 (0.296)	loss 7.521 (7.530)	prob 2.664 (2.481)	GS 34.484 (33.498)	mem 73.115
Train: [54][1020/1500]	BT 0.029 (0.342)	DT 0.000 (0.304)	loss 7.372 (7.599)	prob 3.295 (2.418)	GS 35.875 (33.154)	mem 73.113
Train: [54][1030/1500]	BT 0.030 (0.339)	DT 0.000 (0.301)	loss 7.198 (7.599)	prob 2.942 (2.385)	GS 29.359 (32.759)	mem 73.112
Train: [54][1040/1500]	BT 0.032 (0.336)	DT 0.000 (0.298)	loss 7.613 (7.599)	prob 2.209 (2.396)	GS 34.328 (32.716)	mem 73.112
Train: [54][1050/1500]	BT 0.029 (0.338)	DT 0.000 (0.300)	loss 7.460 (7.590)	prob 2.762 (2.434)	GS 34.344 (32.811)	mem 73.111
Train: [54][1060/1500]	BT 0.037 (0.335)	DT 0.001 (0.297)	loss 7.986 (7.557)	prob 1.916 (2.550)	GS 33.594 (32.316)	mem 73.115
Train: [54][1070/1500]	BT 0.027 (0.336)	DT 0.000 (0.298)	loss 7.240 (7.555)	prob 2.968 (2.698)	GS 34.078 (32.211)	mem 73.120
Train: [54][1080/1500]	BT 0.032 (0.333)	DT 0.000 (0.296)	loss 7.911 (7.607)	prob 3.046 (2.605)	GS 33.016 (32.503)	mem 73.120
Train: [54][1090/1500]	BT 0.038 (0.333)	DT 0.001 (0.296)	loss 7.535 (7.654)	prob 3.418 (2.582)	GS 34.719 (32.653)	mem 73.130
Train: [54][1100/1500]	BT 0.038 (0.331)	DT 0.000 (0.293)	loss 7.724 (7.673)	prob 2.784 (2.548)	GS 32.281 (32.518)	mem 73.131
Train: [54][1110/1500]	BT 0.038 (0.328)	DT 0.001 (0.290)	loss 7.614 (7.752)	prob 3.476 (2.611)	GS 29.531 (33.419)	mem 73.131
Train: [54][1120/1500]	BT 0.036 (0.329)	DT 0.001 (0.292)	loss 7.424 (7.692)	prob 2.606 (2.637)	GS 33.141 (33.862)	mem 73.032
Train: [54][1130/1500]	BT 0.056 (0.327)	DT 0.001 (0.289)	loss 8.086 (7.737)	prob 2.762 (2.679)	GS 32.516 (33.199)	mem 73.032
Train: [54][1140/1500]	BT 0.047 (0.328)	DT 0.000 (0.290)	loss 7.484 (7.717)	prob 3.504 (2.727)	GS 32.375 (33.281)	mem 73.032
Train: [54][1150/1500]	BT 0.053 (0.327)	DT 0.010 (0.289)	loss 8.070 (7.727)	prob 3.060 (2.812)	GS 35.188 (33.195)	mem 73.030
Train: [54][1160/1500]	BT 0.040 (0.324)	DT 0.009 (0.286)	loss 8.928 (7.686)	prob 2.539 (3.148)	GS 37.094 (32.583)	mem 73.030
Train: [54][1170/1500]	BT 0.037 (0.325)	DT 0.001 (0.287)	loss 7.787 (7.767)	prob 2.803 (2.890)	GS 34.047 (32.747)	mem 73.031
Train: [54][1180/1500]	BT 0.037 (0.323)	DT 0.001 (0.285)	loss 7.156 (7.742)	prob 4.210 (2.954)	GS 29.484 (32.771)	mem 73.031
Train: [54][1190/1500]	BT 0.028 (0.326)	DT 0.000 (0.288)	loss 8.460 (7.755)	prob 3.092 (2.988)	GS 34.234 (32.854)	mem 73.053
Train: [54][1200/1500]	BT 0.037 (0.324)	DT 0.001 (0.286)	loss 8.005 (7.737)	prob 3.677 (3.040)	GS 31.031 (32.813)	mem 73.055
Train: [54][1210/1500]	BT 0.038 (0.324)	DT 0.001 (0.286)	loss 7.637 (7.617)	prob 3.063 (3.399)	GS 34.016 (33.936)	mem 73.057
Train: [54][1220/1500]	BT 0.031 (0.323)	DT 0.000 (0.285)	loss 7.825 (7.687)	prob 3.690 (3.179)	GS 33.531 (33.855)	mem 73.057
Train: [54][1230/1500]	BT 0.031 (0.321)	DT 0.000 (0.283)	loss 8.547 (7.699)	prob 3.040 (3.135)	GS 34.125 (33.668)	mem 73.057
Train: [54][1240/1500]	BT 0.038 (0.320)	DT 0.001 (0.283)	loss 7.916 (7.700)	prob 3.360 (3.155)	GS 34.906 (33.561)	mem 73.045
Train: [54][1250/1500]	BT 0.028 (0.325)	DT 0.000 (0.287)	loss 7.706 (7.700)	prob 3.585 (3.177)	GS 35.781 (33.840)	mem 73.046
Train: [54][1260/1500]	BT 0.026 (0.322)	DT 0.000 (0.285)	loss 7.771 (7.507)	prob 3.830 (3.701)	GS 35.578 (32.877)	mem 73.046
Train: [54][1270/1500]	BT 0.040 (0.323)	DT 0.001 (0.285)	loss 7.856 (7.614)	prob 2.908 (3.590)	GS 36.469 (33.030)	mem 73.048
Train: [54][1280/1500]	BT 0.039 (0.321)	DT 0.001 (0.283)	loss 7.425 (7.605)	prob 3.891 (3.610)	GS 30.828 (32.834)	mem 73.048
Train: [54][1290/1500]	BT 0.040 (0.319)	DT 0.000 (0.281)	loss 7.830 (7.647)	prob 2.516 (3.521)	GS 36.938 (32.938)	mem 73.046
Train: [54][1300/1500]	BT 0.031 (0.323)	DT 0.000 (0.286)	loss 7.562 (7.630)	prob 4.613 (3.521)	GS 31.688 (32.899)	mem 73.046
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [54][1310/1500]	BT 0.031 (0.321)	DT 0.000 (0.283)	loss 8.373 (7.711)	prob 3.782 (3.783)	GS 39.375 (32.172)	mem 73.047
Train: [54][1320/1500]	BT 0.030 (0.331)	DT 0.000 (0.293)	loss 7.851 (7.687)	prob 4.453 (3.848)	GS 31.891 (32.064)	mem 73.047
Train: [54][1330/1500]	BT 0.039 (0.329)	DT 0.000 (0.291)	loss 7.818 (7.680)	prob 4.184 (3.758)	GS 31.297 (32.003)	mem 73.047
Train: [54][1340/1500]	BT 0.034 (0.326)	DT 0.001 (0.289)	loss 7.790 (7.663)	prob 3.601 (3.666)	GS 31.344 (32.257)	mem 73.048
Train: [54][1350/1500]	BT 0.034 (0.327)	DT 0.000 (0.289)	loss 8.176 (7.658)	prob 3.421 (3.652)	GS 34.938 (32.189)	mem 73.062
Train: [54][1360/1500]	BT 0.033 (0.325)	DT 0.001 (0.287)	loss 7.006 (7.481)	prob 3.520 (2.917)	GS 27.188 (34.672)	mem 73.064
Train: [54][1370/1500]	BT 0.037 (0.326)	DT 0.001 (0.288)	loss 7.983 (7.657)	prob 3.891 (3.072)	GS 34.156 (33.423)	mem 73.066
Train: [54][1380/1500]	BT 0.037 (0.324)	DT 0.001 (0.286)	loss 7.393 (7.606)	prob 4.061 (3.300)	GS 34.078 (32.795)	mem 73.066
Train: [54][1390/1500]	BT 0.036 (0.322)	DT 0.002 (0.284)	loss 8.408 (7.596)	prob 2.526 (3.288)	GS 32.672 (32.663)	mem 73.066
Train: [54][1400/1500]	BT 0.060 (0.328)	DT 0.003 (0.290)	loss 7.666 (7.611)	prob 3.536 (3.249)	GS 32.422 (32.955)	mem 73.066
Train: [54][1410/1500]	BT 0.033 (0.327)	DT 0.001 (0.289)	loss 7.420 (7.557)	prob 3.732 (3.167)	GS 30.875 (34.536)	mem 73.065
Train: [54][1420/1500]	BT 11.781 (0.337)	DT 11.739 (0.299)	loss 7.253 (7.522)	prob 3.729 (3.250)	GS 35.281 (33.934)	mem 73.066
Train: [54][1430/1500]	BT 0.028 (0.335)	DT 0.000 (0.297)	loss 7.565 (7.548)	prob 4.010 (3.327)	GS 29.500 (33.677)	mem 73.067
Train: [54][1440/1500]	BT 0.035 (0.333)	DT 0.000 (0.295)	loss 7.870 (7.563)	prob 3.382 (3.314)	GS 28.219 (33.660)	mem 73.068
Train: [54][1450/1500]	BT 0.028 (0.333)	DT 0.000 (0.295)	loss 7.216 (7.553)	prob 4.082 (3.373)	GS 31.156 (33.638)	mem 72.888
Train: [54][1460/1500]	BT 0.026 (0.331)	DT 0.000 (0.293)	loss 8.318 (7.568)	prob 2.898 (3.428)	GS 33.578 (33.539)	mem 72.888
Train: [54][1470/1500]	BT 0.025 (0.331)	DT 0.000 (0.294)	loss 7.267 (7.482)	prob 4.449 (3.590)	GS 29.297 (32.162)	mem 8.080
Train: [54][1480/1500]	BT 0.032 (0.329)	DT 0.000 (0.292)	loss 7.464 (7.456)	prob 4.054 (3.679)	GS 34.328 (32.239)	mem 8.080
Train: [54][1490/1500]	BT 0.025 (0.327)	DT 0.000 (0.290)	loss 7.783 (7.444)	prob 2.806 (3.605)	GS 33.719 (32.248)	mem 8.080
Train: [54][1500/1500]	BT 0.030 (0.326)	DT 0.000 (0.288)	loss 6.972 (7.441)	prob 4.082 (3.602)	GS 37.031 (32.372)	mem 8.046
Train: [54][1510/1500]	BT 0.029 (0.324)	DT 0.000 (0.286)	loss 7.642 (7.325)	prob 2.082 (3.074)	GS 31.938 (32.084)	mem 8.046
epoch 54, total time 489.39
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [55][1/1500]	BT 22.607 (22.607)	DT 22.554 (22.554)	loss 7.132 (7.132)	prob 3.145 (3.145)	GS 28.234 (28.234)	mem 71.816
Train: [55][10/1500]	BT 0.028 (2.296)	DT 0.000 (2.264)	loss 7.946 (7.289)	prob 3.063 (3.050)	GS 38.578 (33.623)	mem 71.820
Train: [55][20/1500]	BT 0.037 (1.166)	DT 0.001 (1.132)	loss 7.556 (7.264)	prob 2.937 (3.013)	GS 34.062 (33.691)	mem 71.822
Train: [55][30/1500]	BT 0.028 (0.938)	DT 0.000 (0.904)	loss 7.676 (7.254)	prob 2.980 (3.162)	GS 34.578 (33.399)	mem 71.844
Train: [55][40/1500]	BT 0.037 (0.713)	DT 0.001 (0.678)	loss 7.130 (7.248)	prob 3.506 (3.190)	GS 31.453 (33.288)	mem 71.844
Train: [55][50/1500]	BT 0.037 (0.602)	DT 0.000 (0.568)	loss 7.274 (7.276)	prob 3.471 (3.177)	GS 33.531 (32.983)	mem 71.846
Train: [55][60/1500]	BT 0.031 (0.565)	DT 0.000 (0.531)	loss 7.244 (7.335)	prob 3.685 (3.400)	GS 34.750 (31.459)	mem 71.876
Train: [55][70/1500]	BT 0.032 (0.488)	DT 0.000 (0.455)	loss 7.636 (7.348)	prob 3.404 (3.317)	GS 33.031 (32.244)	mem 71.878
Train: [55][80/1500]	BT 0.037 (0.488)	DT 0.001 (0.455)	loss 7.637 (7.365)	prob 3.032 (3.234)	GS 37.125 (32.529)	mem 71.896
Train: [55][90/1500]	BT 0.032 (0.460)	DT 0.000 (0.427)	loss 7.030 (7.350)	prob 3.756 (3.224)	GS 29.359 (32.578)	mem 71.898
Train: [55][100/1500]	BT 0.029 (0.431)	DT 0.000 (0.397)	loss 7.310 (7.353)	prob 3.358 (3.240)	GS 34.828 (32.820)	mem 71.901
Train: [55][110/1500]	BT 0.061 (0.412)	DT 0.011 (0.378)	loss 7.115 (7.246)	prob 3.999 (3.796)	GS 34.438 (30.795)	mem 71.903
Train: [55][120/1500]	BT 0.038 (0.382)	DT 0.000 (0.347)	loss 7.614 (7.271)	prob 2.693 (3.502)	GS 35.953 (32.227)	mem 71.903
Train: [55][130/1500]	BT 0.036 (0.392)	DT 0.000 (0.356)	loss 7.379 (7.301)	prob 2.470 (3.271)	GS 32.094 (32.477)	mem 71.916
Train: [55][140/1500]	BT 0.037 (0.366)	DT 0.001 (0.331)	loss 7.201 (7.298)	prob 2.957 (3.152)	GS 33.547 (32.601)	mem 71.918
Train: [55][150/1500]	BT 0.037 (0.352)	DT 0.000 (0.316)	loss 7.130 (7.274)	prob 3.678 (3.142)	GS 29.969 (32.537)	mem 71.951
Train: [55][160/1500]	BT 0.039 (0.348)	DT 0.001 (0.312)	loss 7.147 (7.235)	prob 3.986 (3.248)	GS 34.953 (32.927)	mem 71.956
Train: [55][170/1500]	BT 1.309 (0.338)	DT 1.271 (0.301)	loss 7.201 (7.267)	prob 3.772 (3.207)	GS 31.938 (33.015)	mem 71.959
Train: [55][180/1500]	BT 0.068 (0.356)	DT 0.015 (0.318)	loss 7.690 (7.306)	prob 2.405 (3.045)	GS 36.688 (33.415)	mem 71.967
Train: [55][190/1500]	BT 0.039 (0.344)	DT 0.001 (0.306)	loss 7.699 (7.314)	prob 2.330 (2.957)	GS 31.141 (33.122)	mem 71.970
Train: [55][200/1500]	BT 0.039 (0.351)	DT 0.000 (0.313)	loss 7.379 (7.305)	prob 3.177 (2.998)	GS 37.797 (33.400)	mem 71.971
Train: [55][210/1500]	BT 0.061 (0.346)	DT 0.002 (0.307)	loss 7.083 (7.259)	prob 3.068 (3.094)	GS 36.984 (34.480)	mem 71.975
Train: [55][220/1500]	BT 0.065 (0.350)	DT 0.011 (0.311)	loss 7.540 (7.266)	prob 3.572 (3.267)	GS 37.125 (34.288)	mem 71.978
Train: [55][230/1500]	BT 0.058 (0.345)	DT 0.001 (0.305)	loss 7.285 (7.289)	prob 3.404 (3.169)	GS 30.594 (34.171)	mem 71.986
Train: [55][240/1500]	BT 0.040 (0.336)	DT 0.001 (0.296)	loss 7.364 (7.308)	prob 3.493 (3.179)	GS 37.016 (33.855)	mem 71.986
Train: [55][250/1500]	BT 0.028 (0.393)	DT 0.000 (0.353)	loss 7.615 (7.301)	prob 3.356 (3.214)	GS 32.641 (33.572)	mem 71.990
Train: [55][260/1500]	BT 0.033 (0.386)	DT 0.000 (0.347)	loss 7.469 (7.397)	prob 2.865 (2.989)	GS 33.266 (32.847)	mem 71.990
Train: [55][270/1500]	BT 0.056 (0.374)	DT 0.002 (0.334)	loss 7.772 (7.387)	prob 3.905 (2.961)	GS 36.328 (32.655)	mem 71.991
Train: [55][280/1500]	BT 0.034 (0.371)	DT 0.001 (0.331)	loss 7.176 (7.344)	prob 3.622 (3.068)	GS 35.359 (32.712)	mem 71.993
Train: [55][290/1500]	BT 0.025 (0.386)	DT 0.000 (0.346)	loss 7.451 (7.342)	prob 3.160 (3.062)	GS 32.125 (32.847)	mem 71.996
Train: [55][300/1500]	BT 0.037 (0.374)	DT 0.001 (0.335)	loss 7.430 (7.348)	prob 3.166 (3.053)	GS 33.000 (32.772)	mem 71.996
Train: [55][310/1500]	BT 0.039 (0.377)	DT 0.001 (0.337)	loss 7.673 (7.517)	prob 3.063 (2.992)	GS 36.844 (33.086)	mem 71.996
Train: [55][320/1500]	BT 0.038 (0.367)	DT 0.001 (0.327)	loss 7.184 (7.472)	prob 3.431 (2.910)	GS 32.859 (32.960)	mem 71.998
Train: [55][330/1500]	BT 0.037 (0.365)	DT 0.000 (0.326)	loss 7.450 (7.466)	prob 3.475 (2.959)	GS 35.000 (32.629)	mem 72.142
Train: [55][340/1500]	BT 0.036 (0.355)	DT 0.001 (0.316)	loss 7.591 (7.439)	prob 2.936 (3.035)	GS 34.422 (32.718)	mem 72.191
Train: [55][350/1500]	BT 0.036 (0.346)	DT 0.001 (0.307)	loss 7.106 (7.417)	prob 3.408 (3.053)	GS 27.906 (32.655)	mem 72.191
Train: [55][360/1500]	BT 0.035 (0.349)	DT 0.000 (0.310)	loss 8.253 (7.583)	prob 2.924 (2.799)	GS 34.469 (33.036)	mem 72.536
Train: [55][370/1500]	BT 0.043 (0.344)	DT 0.001 (0.305)	loss 7.751 (7.597)	prob 2.783 (2.661)	GS 36.031 (33.188)	mem 72.635
Train: [55][380/1500]	BT 0.035 (0.357)	DT 0.000 (0.318)	loss 7.476 (7.540)	prob 2.889 (2.552)	GS 34.328 (33.063)	mem 73.177
Train: [55][390/1500]	BT 0.036 (0.349)	DT 0.002 (0.310)	loss 7.841 (7.530)	prob 2.724 (2.607)	GS 34.312 (33.110)	mem 73.177
Train: [55][400/1500]	BT 0.069 (0.342)	DT 0.006 (0.302)	loss 8.113 (7.558)	prob 2.336 (2.654)	GS 35.328 (33.027)	mem 73.179
Train: [55][410/1500]	BT 0.050 (0.361)	DT 0.004 (0.321)	loss 7.684 (7.536)	prob 3.918 (3.086)	GS 33.453 (32.781)	mem 73.179
Train: [55][420/1500]	BT 0.031 (0.376)	DT 0.001 (0.335)	loss 7.335 (7.572)	prob 3.693 (3.229)	GS 33.688 (32.430)	mem 73.178
Train: [55][430/1500]	BT 0.030 (0.368)	DT 0.000 (0.328)	loss 7.921 (7.572)	prob 3.327 (3.269)	GS 30.797 (32.015)	mem 73.179
Train: [55][440/1500]	BT 0.037 (0.360)	DT 0.001 (0.320)	loss 8.090 (7.590)	prob 3.177 (3.234)	GS 29.594 (32.050)	mem 73.182
Train: [55][450/1500]	BT 0.037 (0.360)	DT 0.000 (0.320)	loss 8.382 (7.620)	prob 3.002 (3.151)	GS 36.609 (32.318)	mem 73.180
Train: [55][460/1500]	BT 0.037 (0.353)	DT 0.000 (0.313)	loss 7.522 (7.495)	prob 3.300 (2.973)	GS 32.562 (31.934)	mem 73.180
Train: [55][470/1500]	BT 0.080 (0.356)	DT 0.020 (0.316)	loss 7.987 (7.550)	prob 2.787 (3.051)	GS 32.438 (31.144)	mem 73.183
Train: [55][480/1500]	BT 0.058 (0.360)	DT 0.010 (0.321)	loss 7.654 (7.571)	prob 2.735 (3.006)	GS 36.094 (31.902)	mem 73.186
Train: [55][490/1500]	BT 0.036 (0.366)	DT 0.001 (0.326)	loss 7.504 (7.560)	prob 2.487 (3.057)	GS 34.875 (32.305)	mem 73.186
Train: [55][500/1500]	BT 0.028 (0.363)	DT 0.000 (0.323)	loss 7.383 (7.575)	prob 2.753 (3.062)	GS 29.062 (32.441)	mem 73.191
Train: [55][510/1500]	BT 0.037 (0.356)	DT 0.000 (0.317)	loss 7.971 (7.621)	prob 3.624 (3.248)	GS 32.422 (33.069)	mem 73.193
Train: [55][520/1500]	BT 0.027 (0.358)	DT 0.001 (0.319)	loss 7.384 (7.625)	prob 4.125 (3.278)	GS 32.688 (32.784)	mem 73.200
Train: [55][530/1500]	BT 0.028 (0.352)	DT 0.000 (0.313)	loss 7.795 (7.682)	prob 3.685 (3.380)	GS 33.141 (32.650)	mem 73.201
Train: [55][540/1500]	BT 0.037 (0.348)	DT 0.000 (0.309)	loss 8.250 (7.708)	prob 3.237 (3.335)	GS 33.266 (32.655)	mem 73.223
Train: [55][550/1500]	BT 0.036 (0.346)	DT 0.000 (0.306)	loss 8.001 (7.726)	prob 4.111 (3.364)	GS 31.094 (32.547)	mem 73.103
Train: [55][560/1500]	BT 0.037 (0.340)	DT 0.001 (0.301)	loss 7.495 (7.609)	prob 4.282 (3.645)	GS 34.875 (32.519)	mem 73.103
Train: [55][570/1500]	BT 0.056 (0.345)	DT 0.012 (0.305)	loss 7.721 (7.615)	prob 3.739 (3.570)	GS 38.984 (33.003)	mem 73.103
Train: [55][580/1500]	BT 0.057 (0.340)	DT 0.013 (0.300)	loss 7.407 (7.618)	prob 3.776 (3.590)	GS 33.219 (32.976)	mem 73.104
Train: [55][590/1500]	BT 0.086 (0.341)	DT 0.016 (0.302)	loss 7.472 (7.586)	prob 4.162 (3.629)	GS 29.719 (32.930)	mem 73.105
Train: [55][600/1500]	BT 0.025 (0.362)	DT 0.000 (0.322)	loss 7.659 (7.607)	prob 3.720 (3.647)	GS 32.547 (33.210)	mem 73.125
Train: [55][610/1500]	BT 0.029 (0.357)	DT 0.000 (0.317)	loss 7.687 (7.809)	prob 3.828 (3.546)	GS 33.953 (32.755)	mem 73.126
Train: [55][620/1500]	BT 0.035 (0.352)	DT 0.000 (0.312)	loss 8.443 (7.868)	prob 3.469 (3.442)	GS 34.062 (32.786)	mem 73.127
Train: [55][630/1500]	BT 0.068 (0.356)	DT 0.004 (0.316)	loss 7.839 (7.812)	prob 4.107 (3.524)	GS 32.641 (32.613)	mem 73.116
Train: [55][640/1500]	BT 0.072 (0.351)	DT 0.012 (0.311)	loss 7.760 (7.807)	prob 3.591 (3.468)	GS 32.484 (32.651)	mem 73.115
Train: [55][650/1500]	BT 0.033 (0.360)	DT 0.000 (0.319)	loss 7.628 (7.786)	prob 3.341 (3.481)	GS 35.281 (32.502)	mem 73.111
Train: [55][660/1500]	BT 0.031 (0.357)	DT 0.000 (0.317)	loss 7.842 (7.694)	prob 3.587 (3.670)	GS 32.125 (33.327)	mem 73.113
Train: [55][670/1500]	BT 0.029 (0.352)	DT 0.001 (0.312)	loss 7.667 (7.696)	prob 3.901 (3.688)	GS 31.156 (33.071)	mem 73.113
Train: [55][680/1500]	BT 0.049 (0.351)	DT 0.000 (0.311)	loss 8.054 (7.705)	prob 3.073 (3.549)	GS 34.703 (33.096)	mem 73.115
Train: [55][690/1500]	BT 0.038 (0.353)	DT 0.000 (0.313)	loss 7.666 (7.685)	prob 4.459 (3.653)	GS 35.125 (32.210)	mem 73.114
Train: [55][700/1500]	BT 0.029 (0.353)	DT 0.000 (0.313)	loss 7.434 (7.669)	prob 3.200 (3.602)	GS 30.359 (32.509)	mem 73.114
Train: [55][710/1500]	BT 0.031 (0.351)	DT 0.000 (0.311)	loss 7.558 (7.681)	prob 3.971 (3.418)	GS 35.312 (31.966)	mem 73.118
Train: [55][720/1500]	BT 0.038 (0.355)	DT 0.000 (0.315)	loss 7.505 (7.641)	prob 4.227 (3.500)	GS 30.719 (32.634)	mem 73.117
Train: [55][730/1500]	BT 0.026 (0.351)	DT 0.000 (0.311)	loss 7.600 (7.654)	prob 3.938 (3.564)	GS 37.734 (32.922)	mem 73.118
Train: [55][740/1500]	BT 0.029 (0.347)	DT 0.000 (0.307)	loss 7.822 (7.624)	prob 3.397 (3.545)	GS 32.344 (32.951)	mem 73.121
Train: [55][750/1500]	BT 0.077 (0.355)	DT 0.009 (0.315)	loss 7.596 (7.591)	prob 4.103 (3.574)	GS 32.547 (32.944)	mem 73.124
Train: [55][760/1500]	BT 0.029 (0.365)	DT 0.000 (0.325)	loss 7.587 (7.521)	prob 3.958 (3.616)	GS 33.375 (32.459)	mem 73.124
Train: [55][770/1500]	BT 0.031 (0.361)	DT 0.000 (0.321)	loss 7.652 (7.549)	prob 3.329 (3.616)	GS 35.141 (32.171)	mem 73.124
Train: [55][780/1500]	BT 3.195 (0.361)	DT 3.160 (0.321)	loss 7.839 (7.529)	prob 3.191 (3.535)	GS 33.469 (32.215)	mem 73.126
Train: [55][790/1500]	BT 0.034 (0.357)	DT 0.000 (0.317)	loss 7.417 (7.514)	prob 4.243 (3.572)	GS 33.859 (32.443)	mem 73.127
Train: [55][800/1500]	BT 0.034 (0.353)	DT 0.000 (0.313)	loss 7.214 (7.510)	prob 3.275 (3.497)	GS 32.984 (32.428)	mem 73.127
Train: [55][810/1500]	BT 0.038 (0.355)	DT 0.000 (0.315)	loss 7.308 (7.473)	prob 4.469 (3.322)	GS 31.375 (31.978)	mem 73.124
Train: [55][820/1500]	BT 0.039 (0.356)	DT 0.001 (0.316)	loss 7.580 (7.547)	prob 2.543 (3.370)	GS 36.641 (32.555)	mem 73.125
Train: [55][830/1500]	BT 0.038 (0.354)	DT 0.001 (0.314)	loss 7.659 (7.530)	prob 3.083 (3.395)	GS 33.531 (32.628)	mem 73.126
Train: [55][840/1500]	BT 0.037 (0.354)	DT 0.001 (0.314)	loss 7.781 (7.522)	prob 3.240 (3.414)	GS 35.328 (32.604)	mem 73.143
Train: [55][850/1500]	BT 0.037 (0.350)	DT 0.001 (0.310)	loss 7.181 (7.506)	prob 3.373 (3.353)	GS 32.812 (32.962)	mem 73.144
Train: [55][860/1500]	BT 0.070 (0.347)	DT 0.008 (0.307)	loss 7.298 (7.436)	prob 4.339 (3.737)	GS 31.312 (31.902)	mem 73.143
Train: [55][870/1500]	BT 0.037 (0.349)	DT 0.001 (0.309)	loss 7.265 (7.430)	prob 3.527 (3.480)	GS 36.078 (32.899)	mem 73.148
Train: [55][880/1500]	BT 0.037 (0.345)	DT 0.001 (0.306)	loss 7.359 (7.467)	prob 2.787 (3.315)	GS 38.734 (33.245)	mem 73.149
Train: [55][890/1500]	BT 0.037 (0.349)	DT 0.000 (0.310)	loss 7.462 (7.481)	prob 3.208 (3.251)	GS 34.531 (33.254)	mem 73.148
Train: [55][900/1500]	BT 0.037 (0.346)	DT 0.001 (0.306)	loss 7.593 (7.480)	prob 3.925 (3.275)	GS 28.547 (33.014)	mem 73.148
Train: [55][910/1500]	BT 0.039 (0.348)	DT 0.000 (0.309)	loss 7.372 (7.315)	prob 3.272 (3.637)	GS 31.984 (31.956)	mem 73.149
Train: [55][920/1500]	BT 0.037 (0.345)	DT 0.001 (0.305)	loss 7.241 (7.368)	prob 3.589 (3.468)	GS 33.500 (32.248)	mem 73.149
Train: [55][930/1500]	BT 0.028 (0.341)	DT 0.000 (0.302)	loss 7.105 (7.382)	prob 3.733 (3.386)	GS 30.422 (32.441)	mem 73.149
Train: [55][940/1500]	BT 0.026 (0.344)	DT 0.000 (0.305)	loss 7.235 (7.373)	prob 4.184 (3.395)	GS 32.266 (32.257)	mem 73.153
Train: [55][950/1500]	BT 0.037 (0.341)	DT 0.001 (0.302)	loss 7.088 (7.363)	prob 3.806 (3.355)	GS 33.391 (32.443)	mem 73.156
Train: [55][960/1500]	BT 0.038 (0.342)	DT 0.001 (0.302)	loss 7.408 (7.355)	prob 3.076 (3.179)	GS 33.188 (32.653)	mem 73.156
Train: [55][970/1500]	BT 0.038 (0.338)	DT 0.000 (0.299)	loss 7.122 (7.300)	prob 3.704 (3.208)	GS 34.500 (32.524)	mem 73.157
Train: [55][980/1500]	BT 0.038 (0.335)	DT 0.000 (0.296)	loss 7.421 (7.356)	prob 2.807 (3.116)	GS 34.766 (32.867)	mem 73.156
Train: [55][990/1500]	BT 0.039 (0.337)	DT 0.000 (0.298)	loss 7.102 (7.316)	prob 3.575 (3.169)	GS 35.312 (32.795)	mem 73.158
Train: [55][1000/1500]	BT 0.037 (0.334)	DT 0.001 (0.295)	loss 7.387 (7.300)	prob 3.701 (3.195)	GS 34.500 (32.679)	mem 73.158
Train: [55][1010/1500]	BT 0.110 (0.335)	DT 0.011 (0.296)	loss 7.126 (7.136)	prob 2.764 (3.075)	GS 32.828 (31.275)	mem 73.160
Train: [55][1020/1500]	BT 0.039 (0.332)	DT 0.001 (0.293)	loss 7.125 (7.183)	prob 2.824 (3.009)	GS 33.766 (31.691)	mem 73.162
Train: [55][1030/1500]	BT 0.037 (0.334)	DT 0.000 (0.295)	loss 7.782 (7.212)	prob 3.001 (2.862)	GS 37.328 (31.542)	mem 73.163
Train: [55][1040/1500]	BT 0.037 (0.331)	DT 0.001 (0.292)	loss 7.256 (7.221)	prob 3.495 (2.961)	GS 31.969 (31.767)	mem 73.164
Train: [55][1050/1500]	BT 0.034 (0.328)	DT 0.001 (0.289)	loss 7.078 (7.217)	prob 3.139 (2.981)	GS 35.844 (32.110)	mem 73.165
Train: [55][1060/1500]	BT 0.026 (0.333)	DT 0.000 (0.294)	loss 6.999 (7.166)	prob 3.385 (3.151)	GS 30.844 (31.244)	mem 73.163
Train: [55][1070/1500]	BT 0.036 (0.330)	DT 0.000 (0.291)	loss 7.035 (7.128)	prob 3.125 (3.156)	GS 31.172 (32.708)	mem 73.165
Train: [55][1080/1500]	BT 0.038 (0.330)	DT 0.001 (0.291)	loss 7.411 (7.142)	prob 3.855 (3.244)	GS 31.188 (32.534)	mem 73.164
Train: [55][1090/1500]	BT 0.038 (0.328)	DT 0.001 (0.289)	loss 7.261 (7.143)	prob 3.825 (3.310)	GS 36.469 (32.680)	mem 73.164
Train: [55][1100/1500]	BT 0.037 (0.325)	DT 0.000 (0.286)	loss 7.227 (7.154)	prob 3.607 (3.318)	GS 30.609 (32.452)	mem 73.165
Train: [55][1110/1500]	BT 0.065 (0.331)	DT 0.006 (0.292)	loss 7.221 (7.233)	prob 3.493 (3.105)	GS 36.422 (34.266)	mem 73.166
Train: [55][1120/1500]	BT 0.048 (0.329)	DT 0.003 (0.289)	loss 7.016 (7.170)	prob 3.651 (3.317)	GS 28.500 (33.138)	mem 73.168
Train: [55][1130/1500]	BT 0.026 (0.335)	DT 0.000 (0.296)	loss 7.217 (7.150)	prob 3.984 (3.318)	GS 36.969 (33.658)	mem 73.167
Train: [55][1140/1500]	BT 0.038 (0.333)	DT 0.001 (0.293)	loss 7.016 (7.160)	prob 3.646 (3.358)	GS 36.359 (33.613)	mem 73.167
Train: [55][1150/1500]	BT 0.037 (0.330)	DT 0.001 (0.291)	loss 7.094 (7.154)	prob 3.872 (3.338)	GS 31.828 (33.572)	mem 73.168
Train: [55][1160/1500]	BT 0.043 (0.330)	DT 0.001 (0.291)	loss 7.306 (7.185)	prob 3.487 (3.387)	GS 35.109 (31.991)	mem 73.167
Train: [55][1170/1500]	BT 0.028 (0.327)	DT 0.000 (0.288)	loss 7.187 (7.177)	prob 4.343 (3.447)	GS 30.344 (31.891)	mem 73.169
Train: [55][1180/1500]	BT 0.038 (0.327)	DT 0.001 (0.288)	loss 7.159 (7.223)	prob 3.564 (3.469)	GS 33.375 (31.583)	mem 73.169
Train: [55][1190/1500]	BT 0.037 (0.325)	DT 0.001 (0.286)	loss 7.070 (7.193)	prob 3.721 (3.448)	GS 30.703 (31.865)	mem 73.170
Train: [55][1200/1500]	BT 0.051 (0.325)	DT 0.012 (0.286)	loss 6.961 (7.220)	prob 3.469 (3.407)	GS 37.906 (32.054)	mem 73.205
Train: [55][1210/1500]	BT 0.029 (0.323)	DT 0.001 (0.284)	loss 7.196 (7.286)	prob 3.353 (3.347)	GS 35.078 (31.625)	mem 73.206
Train: [55][1220/1500]	BT 0.040 (0.321)	DT 0.001 (0.282)	loss 7.172 (7.302)	prob 3.206 (3.082)	GS 34.547 (32.199)	mem 73.206
Train: [55][1230/1500]	BT 0.031 (0.325)	DT 0.000 (0.286)	loss 7.791 (7.302)	prob 2.706 (3.101)	GS 31.500 (32.343)	mem 73.206
Train: [55][1240/1500]	BT 0.028 (0.334)	DT 0.000 (0.295)	loss 7.275 (7.314)	prob 3.083 (3.110)	GS 30.188 (32.442)	mem 73.206
Train: [55][1250/1500]	BT 0.031 (0.332)	DT 0.000 (0.293)	loss 7.901 (7.338)	prob 2.238 (3.085)	GS 35.406 (32.198)	mem 73.206
Train: [55][1260/1500]	BT 0.037 (0.333)	DT 0.000 (0.294)	loss 7.202 (7.236)	prob 2.385 (2.618)	GS 34.359 (33.916)	mem 73.207
Train: [55][1270/1500]	BT 0.039 (0.330)	DT 0.001 (0.292)	loss 7.569 (7.288)	prob 2.845 (2.675)	GS 37.172 (33.037)	mem 73.207
Train: [55][1280/1500]	BT 0.039 (0.328)	DT 0.000 (0.289)	loss 7.080 (7.266)	prob 3.064 (2.680)	GS 36.500 (32.581)	mem 73.209
Train: [55][1290/1500]	BT 0.104 (0.331)	DT 0.010 (0.292)	loss 7.307 (7.325)	prob 2.910 (2.618)	GS 38.219 (32.709)	mem 73.209
Train: [55][1300/1500]	BT 0.070 (0.329)	DT 0.004 (0.290)	loss 7.358 (7.325)	prob 2.917 (2.612)	GS 34.422 (32.817)	mem 73.210
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [55][1310/1500]	BT 0.056 (0.333)	DT 0.011 (0.294)	loss 8.206 (7.447)	prob 2.328 (2.659)	GS 35.953 (32.867)	mem 73.210
Train: [55][1320/1500]	BT 0.023 (0.338)	DT 0.000 (0.298)	loss 7.993 (7.462)	prob 2.042 (2.584)	GS 35.734 (32.916)	mem 73.207
Train: [55][1330/1500]	BT 0.027 (0.335)	DT 0.000 (0.296)	loss 7.487 (7.441)	prob 2.336 (2.446)	GS 34.281 (33.115)	mem 73.209
Train: [55][1340/1500]	BT 0.039 (0.335)	DT 0.001 (0.296)	loss 7.757 (7.499)	prob 3.410 (2.444)	GS 28.859 (32.489)	mem 73.211
Train: [55][1350/1500]	BT 0.040 (0.333)	DT 0.001 (0.294)	loss 8.024 (7.522)	prob 2.147 (2.433)	GS 36.219 (32.890)	mem 73.210
Train: [55][1360/1500]	BT 0.039 (0.331)	DT 0.001 (0.291)	loss 7.435 (7.553)	prob 1.639 (2.221)	GS 37.047 (32.541)	mem 73.209
Train: [55][1370/1500]	BT 0.039 (0.332)	DT 0.001 (0.293)	loss 7.563 (7.558)	prob 2.862 (2.489)	GS 30.609 (32.700)	mem 73.209
Train: [55][1380/1500]	BT 0.039 (0.330)	DT 0.001 (0.291)	loss 7.736 (7.519)	prob 3.223 (2.572)	GS 30.594 (32.613)	mem 73.209
Train: [55][1390/1500]	BT 0.030 (0.330)	DT 0.000 (0.290)	loss 7.456 (7.522)	prob 2.489 (2.547)	GS 34.172 (32.811)	mem 73.211
Train: [55][1400/1500]	BT 0.058 (0.329)	DT 0.011 (0.290)	loss 7.892 (7.548)	prob 2.851 (2.523)	GS 31.016 (32.598)	mem 73.212
Train: [55][1410/1500]	BT 0.051 (0.327)	DT 0.000 (0.288)	loss 8.265 (7.618)	prob 3.532 (2.671)	GS 34.609 (31.808)	mem 73.212
Train: [55][1420/1500]	BT 0.039 (0.330)	DT 0.001 (0.290)	loss 7.459 (7.595)	prob 2.782 (2.786)	GS 31.875 (32.177)	mem 73.211
Train: [55][1430/1500]	BT 0.038 (0.330)	DT 0.001 (0.290)	loss 7.882 (7.604)	prob 2.588 (2.673)	GS 37.172 (32.856)	mem 73.204
Train: [55][1440/1500]	BT 0.037 (0.328)	DT 0.001 (0.288)	loss 7.702 (7.643)	prob 3.233 (2.723)	GS 31.531 (32.336)	mem 73.207
Train: [55][1450/1500]	BT 0.037 (0.327)	DT 0.000 (0.288)	loss 8.364 (7.624)	prob 2.276 (2.766)	GS 36.656 (32.451)	mem 73.211
Train: [55][1460/1500]	BT 0.037 (0.326)	DT 0.000 (0.287)	loss 7.500 (7.657)	prob 3.043 (2.424)	GS 31.391 (32.877)	mem 73.186
Train: [55][1470/1500]	BT 0.040 (0.324)	DT 0.001 (0.285)	loss 7.500 (7.616)	prob 3.563 (2.600)	GS 31.188 (32.647)	mem 72.929
Train: [55][1480/1500]	BT 0.150 (0.323)	DT 0.111 (0.284)	loss 8.184 (7.666)	prob 2.401 (2.688)	GS 33.828 (32.443)	mem 49.066
Train: [55][1490/1500]	BT 0.030 (0.322)	DT 0.000 (0.283)	loss 7.528 (7.612)	prob 2.340 (2.805)	GS 36.406 (32.197)	mem 19.376
Train: [55][1500/1500]	BT 0.027 (0.320)	DT 0.000 (0.281)	loss 7.696 (7.604)	prob 3.319 (2.835)	GS 35.156 (32.312)	mem 13.712
Train: [55][1510/1500]	BT 0.347 (0.319)	DT 0.319 (0.280)	loss 8.545 (7.876)	prob 1.643 (2.268)	GS 37.406 (32.706)	mem 8.006
epoch 55, total time 481.73
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [56][1/1500]	BT 17.930 (17.930)	DT 17.880 (17.880)	loss 7.304 (7.304)	prob 3.139 (3.139)	GS 31.594 (31.594)	mem 71.373
Train: [56][10/1500]	BT 0.036 (2.234)	DT 0.000 (2.195)	loss 7.779 (7.302)	prob 2.888 (3.060)	GS 34.969 (33.257)	mem 71.700
Train: [56][20/1500]	BT 0.038 (1.136)	DT 0.001 (1.098)	loss 7.152 (7.295)	prob 3.313 (3.101)	GS 35.922 (32.836)	mem 71.701
Train: [56][30/1500]	BT 0.027 (1.109)	DT 0.000 (1.070)	loss 7.894 (7.321)	prob 2.471 (3.103)	GS 33.656 (32.787)	mem 71.762
Train: [56][40/1500]	BT 0.032 (0.840)	DT 0.000 (0.803)	loss 7.490 (7.325)	prob 3.162 (3.144)	GS 29.406 (32.438)	mem 71.766
Train: [56][50/1500]	BT 0.039 (0.680)	DT 0.001 (0.642)	loss 7.496 (7.340)	prob 3.500 (3.132)	GS 30.672 (32.277)	mem 71.766
Train: [56][60/1500]	BT 0.076 (0.644)	DT 0.014 (0.605)	loss 7.672 (7.585)	prob 3.199 (2.974)	GS 38.422 (33.361)	mem 71.777
Train: [56][70/1500]	BT 0.063 (0.559)	DT 0.003 (0.519)	loss 7.372 (7.508)	prob 3.594 (3.066)	GS 31.297 (32.801)	mem 71.778
Train: [56][80/1500]	BT 0.059 (0.636)	DT 0.012 (0.595)	loss 7.428 (7.500)	prob 3.141 (3.117)	GS 28.438 (32.779)	mem 71.785
Train: [56][90/1500]	BT 0.027 (0.598)	DT 0.000 (0.558)	loss 7.392 (7.477)	prob 3.727 (3.180)	GS 32.578 (33.084)	mem 71.793
Train: [56][100/1500]	BT 0.039 (0.542)	DT 0.001 (0.503)	loss 7.168 (7.447)	prob 3.962 (3.208)	GS 35.250 (33.028)	mem 71.794
Train: [56][110/1500]	BT 0.029 (0.577)	DT 0.000 (0.538)	loss 7.499 (7.439)	prob 3.109 (3.289)	GS 34.328 (33.188)	mem 71.798
Train: [56][120/1500]	BT 0.030 (0.531)	DT 0.000 (0.493)	loss 7.633 (7.550)	prob 3.588 (3.417)	GS 34.047 (32.947)	mem 71.799
Train: [56][130/1500]	BT 0.039 (0.515)	DT 0.001 (0.477)	loss 7.630 (7.495)	prob 3.279 (3.423)	GS 35.062 (32.959)	mem 71.809
Train: [56][140/1500]	BT 0.038 (0.481)	DT 0.001 (0.443)	loss 7.876 (7.486)	prob 3.758 (3.461)	GS 39.469 (32.949)	mem 71.809
Train: [56][150/1500]	BT 0.039 (0.451)	DT 0.001 (0.413)	loss 7.367 (7.440)	prob 3.112 (3.483)	GS 34.922 (33.099)	mem 71.809
Train: [56][160/1500]	BT 0.058 (0.445)	DT 0.011 (0.406)	loss 7.336 (7.401)	prob 3.110 (3.644)	GS 32.531 (32.325)	mem 71.813
Train: [56][170/1500]	BT 0.063 (0.422)	DT 0.005 (0.383)	loss 7.467 (7.389)	prob 3.311 (3.489)	GS 33.812 (32.480)	mem 71.812
Train: [56][180/1500]	BT 0.060 (0.434)	DT 0.002 (0.394)	loss 7.275 (7.407)	prob 3.358 (3.412)	GS 37.812 (32.761)	mem 71.839
Train: [56][190/1500]	BT 0.041 (0.414)	DT 0.006 (0.373)	loss 7.326 (7.371)	prob 3.123 (3.379)	GS 34.969 (33.004)	mem 71.842
Train: [56][200/1500]	BT 0.035 (0.401)	DT 0.000 (0.360)	loss 7.480 (7.352)	prob 2.679 (3.424)	GS 32.078 (32.826)	mem 71.842
Train: [56][210/1500]	BT 0.037 (0.408)	DT 0.000 (0.367)	loss 7.657 (7.482)	prob 3.599 (3.547)	GS 34.781 (33.036)	mem 71.848
Train: [56][220/1500]	BT 0.037 (0.391)	DT 0.001 (0.351)	loss 7.433 (7.452)	prob 3.658 (3.542)	GS 32.750 (32.538)	mem 71.848
Train: [56][230/1500]	BT 0.037 (0.390)	DT 0.000 (0.350)	loss 7.255 (7.386)	prob 3.299 (3.557)	GS 32.828 (32.480)	mem 71.855
Train: [56][240/1500]	BT 0.037 (0.382)	DT 0.000 (0.342)	loss 7.395 (7.392)	prob 4.039 (3.574)	GS 35.266 (32.790)	mem 71.858
Train: [56][250/1500]	BT 0.468 (0.378)	DT 0.432 (0.338)	loss 7.263 (7.362)	prob 3.430 (3.572)	GS 32.125 (32.569)	mem 71.862
Train: [56][260/1500]	BT 0.037 (0.367)	DT 0.001 (0.327)	loss 7.334 (7.296)	prob 4.090 (3.245)	GS 35.953 (34.581)	mem 71.862
Train: [56][270/1500]	BT 0.037 (0.358)	DT 0.000 (0.318)	loss 7.687 (7.303)	prob 3.478 (3.279)	GS 35.391 (33.444)	mem 71.863
Train: [56][280/1500]	BT 0.030 (0.375)	DT 0.001 (0.335)	loss 7.067 (7.280)	prob 3.439 (3.308)	GS 36.062 (33.591)	mem 71.873
Train: [56][290/1500]	BT 0.029 (0.363)	DT 0.000 (0.324)	loss 7.225 (7.266)	prob 3.859 (3.280)	GS 32.609 (33.458)	mem 71.873
Train: [56][300/1500]	BT 0.035 (0.352)	DT 0.000 (0.313)	loss 7.085 (7.240)	prob 3.722 (3.307)	GS 36.953 (33.475)	mem 71.874
Train: [56][310/1500]	BT 0.038 (0.355)	DT 0.001 (0.316)	loss 7.043 (7.225)	prob 2.887 (3.144)	GS 33.531 (33.102)	mem 71.875
Train: [56][320/1500]	BT 0.038 (0.345)	DT 0.000 (0.306)	loss 7.130 (7.214)	prob 4.315 (3.160)	GS 32.953 (32.930)	mem 71.877
Train: [56][330/1500]	BT 0.037 (0.344)	DT 0.000 (0.305)	loss 7.399 (7.217)	prob 2.382 (3.194)	GS 32.766 (32.603)	mem 71.878
Train: [56][340/1500]	BT 0.038 (0.335)	DT 0.000 (0.296)	loss 7.389 (7.236)	prob 3.820 (3.222)	GS 33.297 (32.045)	mem 71.879
Train: [56][350/1500]	BT 0.027 (0.326)	DT 0.000 (0.287)	loss 7.053 (7.215)	prob 3.440 (3.225)	GS 34.703 (32.139)	mem 71.879
Train: [56][360/1500]	BT 0.024 (0.328)	DT 0.000 (0.289)	loss 6.876 (7.122)	prob 3.727 (3.164)	GS 31.172 (32.409)	mem 71.882
Train: [56][370/1500]	BT 0.025 (0.319)	DT 0.000 (0.282)	loss 6.770 (7.083)	prob 3.868 (3.292)	GS 35.188 (33.059)	mem 71.882
Train: [56][380/1500]	BT 0.030 (0.326)	DT 0.000 (0.288)	loss 7.067 (7.105)	prob 3.370 (3.225)	GS 34.297 (32.909)	mem 71.885
Train: [56][390/1500]	BT 0.025 (0.318)	DT 0.000 (0.281)	loss 6.809 (7.108)	prob 3.352 (3.246)	GS 36.547 (32.911)	mem 71.886
Train: [56][400/1500]	BT 0.029 (0.323)	DT 0.001 (0.286)	loss 6.885 (7.121)	prob 3.043 (3.201)	GS 34.562 (33.002)	mem 71.887
Train: [56][410/1500]	BT 0.031 (0.316)	DT 0.000 (0.279)	loss 7.003 (7.178)	prob 3.221 (3.286)	GS 35.844 (33.011)	mem 71.888
Train: [56][420/1500]	BT 0.034 (0.309)	DT 0.001 (0.272)	loss 6.935 (7.130)	prob 3.004 (3.311)	GS 31.938 (32.334)	mem 71.888
Train: [56][430/1500]	BT 0.032 (0.317)	DT 0.000 (0.280)	loss 7.373 (7.113)	prob 3.465 (3.275)	GS 33.344 (32.321)	mem 72.184
Train: [56][440/1500]	BT 0.025 (0.315)	DT 0.000 (0.278)	loss 7.009 (7.107)	prob 3.213 (3.250)	GS 35.391 (33.092)	mem 72.381
Train: [56][450/1500]	BT 0.027 (0.312)	DT 0.000 (0.275)	loss 7.046 (7.084)	prob 3.886 (3.319)	GS 29.781 (32.891)	mem 72.579
Train: [56][460/1500]	BT 0.040 (0.309)	DT 0.001 (0.273)	loss 7.035 (7.073)	prob 3.209 (2.986)	GS 32.922 (33.756)	mem 72.823
Train: [56][470/1500]	BT 0.037 (0.303)	DT 0.000 (0.267)	loss 7.117 (7.078)	prob 3.142 (3.028)	GS 32.969 (32.703)	mem 72.921
Train: [56][480/1500]	BT 0.039 (0.306)	DT 0.001 (0.270)	loss 7.006 (7.102)	prob 3.442 (3.063)	GS 33.984 (32.979)	mem 73.098
Train: [56][490/1500]	BT 0.039 (0.301)	DT 0.001 (0.264)	loss 6.931 (7.101)	prob 3.673 (3.149)	GS 34.859 (32.951)	mem 73.098
Train: [56][500/1500]	BT 0.039 (0.301)	DT 0.001 (0.265)	loss 7.061 (7.095)	prob 2.948 (3.157)	GS 34.703 (32.638)	mem 73.100
Train: [56][510/1500]	BT 0.039 (0.296)	DT 0.001 (0.259)	loss 7.142 (7.127)	prob 2.690 (2.998)	GS 32.047 (32.905)	mem 73.099
Train: [56][520/1500]	BT 0.064 (0.312)	DT 0.009 (0.275)	loss 7.009 (7.099)	prob 3.476 (3.055)	GS 29.359 (32.489)	mem 73.100
Train: [56][530/1500]	BT 0.093 (0.308)	DT 0.020 (0.270)	loss 6.902 (7.090)	prob 2.873 (3.132)	GS 34.375 (32.197)	mem 73.102
Train: [56][540/1500]	BT 0.036 (0.316)	DT 0.001 (0.278)	loss 7.131 (7.098)	prob 3.078 (3.029)	GS 36.359 (33.208)	mem 73.102
Train: [56][550/1500]	BT 0.039 (0.311)	DT 0.001 (0.273)	loss 7.080 (7.096)	prob 3.038 (3.076)	GS 33.703 (32.909)	mem 73.102
Train: [56][560/1500]	BT 0.038 (0.309)	DT 0.001 (0.271)	loss 6.892 (7.103)	prob 2.922 (2.876)	GS 31.750 (33.322)	mem 73.102
Train: [56][570/1500]	BT 0.033 (0.314)	DT 0.000 (0.277)	loss 7.125 (7.127)	prob 3.564 (3.028)	GS 29.344 (34.047)	mem 73.102
Train: [56][580/1500]	BT 0.037 (0.309)	DT 0.001 (0.272)	loss 6.923 (7.103)	prob 2.811 (3.162)	GS 31.109 (34.078)	mem 73.103
Train: [56][590/1500]	BT 0.050 (0.306)	DT 0.002 (0.269)	loss 7.185 (7.104)	prob 3.070 (3.162)	GS 32.016 (33.975)	mem 73.103
Train: [56][600/1500]	BT 0.031 (0.317)	DT 0.000 (0.279)	loss 7.272 (7.106)	prob 3.157 (3.138)	GS 34.844 (34.049)	mem 73.107
Train: [56][610/1500]	BT 0.036 (0.312)	DT 0.001 (0.275)	loss 7.080 (7.103)	prob 3.282 (3.378)	GS 30.688 (32.695)	mem 73.110
Train: [56][620/1500]	BT 0.041 (0.312)	DT 0.001 (0.275)	loss 6.964 (7.096)	prob 3.185 (3.235)	GS 34.266 (33.124)	mem 73.111
Train: [56][630/1500]	BT 0.039 (0.308)	DT 0.001 (0.270)	loss 7.254 (7.092)	prob 2.947 (3.210)	GS 38.094 (32.895)	mem 73.110
Train: [56][640/1500]	BT 0.060 (0.312)	DT 0.003 (0.275)	loss 7.185 (7.090)	prob 3.137 (3.129)	GS 34.797 (32.706)	mem 73.110
Train: [56][650/1500]	BT 0.083 (0.308)	DT 0.015 (0.271)	loss 7.612 (7.095)	prob 3.843 (3.119)	GS 33.141 (32.805)	mem 73.111
Train: [56][660/1500]	BT 0.041 (0.304)	DT 0.000 (0.267)	loss 7.070 (6.992)	prob 3.282 (3.330)	GS 32.516 (32.373)	mem 73.111
Train: [56][670/1500]	BT 0.064 (0.308)	DT 0.005 (0.271)	loss 6.914 (7.023)	prob 3.164 (3.136)	GS 36.438 (32.178)	mem 73.109
Train: [56][680/1500]	BT 0.059 (0.305)	DT 0.002 (0.267)	loss 7.146 (7.029)	prob 2.249 (3.111)	GS 35.312 (32.511)	mem 73.110
Train: [56][690/1500]	BT 0.031 (0.318)	DT 0.001 (0.280)	loss 6.977 (7.041)	prob 3.096 (3.140)	GS 33.531 (32.968)	mem 73.111
Train: [56][700/1500]	BT 0.037 (0.314)	DT 0.001 (0.276)	loss 6.884 (7.042)	prob 2.747 (3.148)	GS 34.422 (32.822)	mem 73.111
Train: [56][710/1500]	BT 0.026 (0.316)	DT 0.000 (0.279)	loss 6.980 (7.104)	prob 2.420 (2.994)	GS 33.734 (32.598)	mem 73.119
Train: [56][720/1500]	BT 0.027 (0.312)	DT 0.000 (0.275)	loss 6.778 (7.064)	prob 3.203 (3.129)	GS 30.000 (32.519)	mem 73.121
Train: [56][730/1500]	BT 0.037 (0.313)	DT 0.000 (0.276)	loss 7.051 (7.055)	prob 2.701 (3.153)	GS 33.016 (32.736)	mem 73.131
Train: [56][740/1500]	BT 0.028 (0.310)	DT 0.000 (0.272)	loss 7.067 (7.038)	prob 3.014 (3.115)	GS 31.406 (32.622)	mem 73.132
Train: [56][750/1500]	BT 0.032 (0.306)	DT 0.000 (0.268)	loss 7.033 (7.036)	prob 3.116 (3.041)	GS 35.766 (32.769)	mem 73.132
Train: [56][760/1500]	BT 0.029 (0.308)	DT 0.000 (0.271)	loss 7.002 (7.068)	prob 3.589 (2.684)	GS 33.766 (31.820)	mem 73.032
Train: [56][770/1500]	BT 0.030 (0.304)	DT 0.000 (0.267)	loss 6.892 (7.039)	prob 3.977 (2.909)	GS 33.828 (31.915)	mem 73.032
Train: [56][780/1500]	BT 0.051 (0.308)	DT 0.005 (0.270)	loss 6.884 (7.019)	prob 3.151 (2.880)	GS 31.531 (31.872)	mem 73.034
Train: [56][790/1500]	BT 0.025 (0.308)	DT 0.000 (0.271)	loss 7.317 (7.014)	prob 2.162 (2.854)	GS 33.828 (32.185)	mem 73.035
Train: [56][800/1500]	BT 0.024 (0.304)	DT 0.000 (0.267)	loss 6.999 (7.005)	prob 2.714 (2.821)	GS 34.422 (32.201)	mem 73.034
Train: [56][810/1500]	BT 0.055 (0.307)	DT 0.006 (0.270)	loss 6.988 (7.084)	prob 2.661 (2.523)	GS 33.250 (32.953)	mem 73.037
Train: [56][820/1500]	BT 0.084 (0.304)	DT 0.006 (0.266)	loss 7.011 (7.062)	prob 2.971 (2.625)	GS 34.484 (32.826)	mem 73.037
Train: [56][830/1500]	BT 0.075 (0.313)	DT 0.001 (0.275)	loss 7.105 (7.033)	prob 2.792 (2.635)	GS 31.250 (32.536)	mem 73.036
Train: [56][840/1500]	BT 0.029 (0.329)	DT 0.000 (0.291)	loss 7.179 (7.027)	prob 2.087 (2.594)	GS 34.781 (32.851)	mem 73.040
Train: [56][850/1500]	BT 0.024 (0.325)	DT 0.000 (0.287)	loss 6.716 (7.010)	prob 3.101 (2.602)	GS 31.734 (33.004)	mem 73.041
Train: [56][860/1500]	BT 0.029 (0.329)	DT 0.000 (0.291)	loss 6.966 (6.917)	prob 2.856 (2.463)	GS 32.141 (32.759)	mem 73.044
Train: [56][870/1500]	BT 0.038 (0.326)	DT 0.001 (0.288)	loss 7.167 (6.927)	prob 2.596 (2.526)	GS 35.172 (32.695)	mem 73.044
Train: [56][880/1500]	BT 0.039 (0.322)	DT 0.001 (0.285)	loss 6.924 (6.936)	prob 2.915 (2.451)	GS 36.875 (33.353)	mem 73.044
Train: [56][890/1500]	BT 0.072 (0.325)	DT 0.007 (0.287)	loss 6.955 (6.936)	prob 2.648 (2.481)	GS 34.719 (33.173)	mem 73.044
Train: [56][900/1500]	BT 0.033 (0.322)	DT 0.000 (0.284)	loss 6.869 (6.928)	prob 2.825 (2.470)	GS 34.047 (33.160)	mem 73.044
Train: [56][910/1500]	BT 0.052 (0.325)	DT 0.008 (0.287)	loss 6.700 (6.868)	prob 2.709 (2.866)	GS 34.391 (31.020)	mem 73.044
Train: [56][920/1500]	BT 0.053 (0.322)	DT 0.009 (0.284)	loss 6.821 (6.904)	prob 3.779 (2.778)	GS 33.797 (32.203)	mem 73.044
Train: [56][930/1500]	BT 0.031 (0.336)	DT 0.000 (0.298)	loss 6.822 (6.899)	prob 2.449 (2.700)	GS 32.672 (32.585)	mem 73.045
Train: [56][940/1500]	BT 0.036 (0.336)	DT 0.001 (0.298)	loss 6.882 (6.892)	prob 2.697 (2.732)	GS 35.859 (32.771)	mem 73.044
Train: [56][950/1500]	BT 0.034 (0.333)	DT 0.001 (0.295)	loss 6.905 (6.878)	prob 2.404 (2.717)	GS 32.672 (32.407)	mem 73.045
Train: [56][960/1500]	BT 0.041 (0.331)	DT 0.001 (0.293)	loss 6.854 (6.831)	prob 2.514 (2.664)	GS 32.547 (31.633)	mem 73.046
Train: [56][970/1500]	BT 0.039 (0.331)	DT 0.001 (0.293)	loss 6.764 (6.813)	prob 2.787 (2.629)	GS 29.438 (32.355)	mem 73.043
Train: [56][980/1500]	BT 0.031 (0.333)	DT 0.001 (0.295)	loss 6.769 (6.839)	prob 3.037 (2.659)	GS 33.750 (32.755)	mem 73.045
Train: [56][990/1500]	BT 0.031 (0.330)	DT 0.000 (0.293)	loss 6.670 (6.843)	prob 3.015 (2.622)	GS 34.500 (32.555)	mem 73.045
Train: [56][1000/1500]	BT 0.041 (0.327)	DT 0.001 (0.290)	loss 6.919 (6.854)	prob 2.566 (2.597)	GS 37.391 (32.745)	mem 73.046
Train: [56][1010/1500]	BT 0.026 (0.330)	DT 0.000 (0.293)	loss 7.039 (6.859)	prob 2.575 (2.512)	GS 34.078 (33.641)	mem 73.046
Train: [56][1020/1500]	BT 0.029 (0.328)	DT 0.000 (0.290)	loss 6.703 (6.837)	prob 2.175 (2.563)	GS 31.031 (32.521)	mem 73.047
Train: [56][1030/1500]	BT 0.026 (0.329)	DT 0.000 (0.291)	loss 6.910 (6.851)	prob 2.711 (2.574)	GS 31.328 (32.264)	mem 73.065
Train: [56][1040/1500]	BT 0.033 (0.326)	DT 0.000 (0.288)	loss 6.884 (6.855)	prob 1.982 (2.573)	GS 34.172 (32.580)	mem 73.066
Train: [56][1050/1500]	BT 0.033 (0.327)	DT 0.000 (0.290)	loss 6.708 (6.856)	prob 3.325 (2.617)	GS 33.812 (32.606)	mem 73.070
Train: [56][1060/1500]	BT 0.028 (0.325)	DT 0.000 (0.287)	loss 6.872 (6.882)	prob 2.674 (2.754)	GS 35.062 (32.825)	mem 73.069
Train: [56][1070/1500]	BT 0.033 (0.322)	DT 0.000 (0.284)	loss 6.860 (6.841)	prob 2.217 (2.574)	GS 31.500 (32.314)	mem 73.070
Train: [56][1080/1500]	BT 0.091 (0.324)	DT 0.011 (0.286)	loss 6.872 (6.825)	prob 2.993 (2.645)	GS 33.969 (32.698)	mem 73.070
Train: [56][1090/1500]	BT 0.052 (0.321)	DT 0.003 (0.284)	loss 6.974 (6.830)	prob 2.298 (2.630)	GS 35.016 (32.464)	mem 73.070
Train: [56][1100/1500]	BT 0.064 (0.326)	DT 0.004 (0.288)	loss 6.912 (6.837)	prob 2.542 (2.566)	GS 33.109 (32.652)	mem 73.071
Train: [56][1110/1500]	BT 0.051 (0.326)	DT 0.001 (0.288)	loss 6.803 (6.820)	prob 3.110 (2.883)	GS 33.859 (33.936)	mem 73.072
Train: [56][1120/1500]	BT 0.061 (0.324)	DT 0.003 (0.286)	loss 7.027 (6.846)	prob 2.625 (2.827)	GS 35.906 (34.341)	mem 73.070
Train: [56][1130/1500]	BT 0.037 (0.324)	DT 0.001 (0.286)	loss 6.731 (6.843)	prob 2.908 (2.780)	GS 35.859 (34.476)	mem 73.073
Train: [56][1140/1500]	BT 0.037 (0.323)	DT 0.001 (0.285)	loss 6.732 (6.837)	prob 3.383 (2.765)	GS 35.000 (33.861)	mem 73.071
Train: [56][1150/1500]	BT 0.037 (0.323)	DT 0.001 (0.285)	loss 6.704 (6.831)	prob 2.858 (2.769)	GS 34.531 (33.677)	mem 73.073
Train: [56][1160/1500]	BT 0.026 (0.323)	DT 0.000 (0.284)	loss 7.162 (6.781)	prob 2.447 (2.418)	GS 33.141 (32.984)	mem 73.076
Train: [56][1170/1500]	BT 0.038 (0.321)	DT 0.000 (0.283)	loss 6.781 (6.813)	prob 2.016 (2.363)	GS 29.469 (31.504)	mem 73.079
Train: [56][1180/1500]	BT 0.034 (0.320)	DT 0.000 (0.282)	loss 6.700 (6.801)	prob 2.406 (2.330)	GS 32.594 (31.449)	mem 73.080
Train: [56][1190/1500]	BT 0.035 (0.318)	DT 0.001 (0.280)	loss 6.934 (6.804)	prob 2.514 (2.477)	GS 37.031 (31.961)	mem 73.080
Train: [56][1200/1500]	BT 0.035 (0.321)	DT 0.001 (0.282)	loss 7.112 (6.836)	prob 2.923 (2.476)	GS 35.938 (32.504)	mem 73.080
Train: [56][1210/1500]	BT 0.038 (0.318)	DT 0.001 (0.280)	loss 6.761 (6.882)	prob 2.593 (2.727)	GS 30.219 (34.145)	mem 73.082
Train: [56][1220/1500]	BT 0.037 (0.316)	DT 0.001 (0.278)	loss 7.013 (6.998)	prob 1.874 (2.473)	GS 33.672 (33.941)	mem 73.083
Train: [56][1230/1500]	BT 0.037 (0.319)	DT 0.001 (0.281)	loss 7.084 (7.038)	prob 2.370 (2.332)	GS 37.234 (33.795)	mem 73.085
Train: [56][1240/1500]	BT 0.040 (0.317)	DT 0.001 (0.279)	loss 7.213 (7.044)	prob 2.527 (2.344)	GS 35.688 (33.564)	mem 73.084
Train: [56][1250/1500]	BT 0.063 (0.320)	DT 0.011 (0.282)	loss 7.324 (7.056)	prob 2.097 (2.372)	GS 30.000 (33.388)	mem 73.084
Train: [56][1260/1500]	BT 0.033 (0.326)	DT 0.001 (0.288)	loss 7.081 (7.096)	prob 1.751 (2.329)	GS 31.625 (32.986)	mem 73.083
Train: [56][1270/1500]	BT 0.034 (0.324)	DT 0.000 (0.286)	loss 7.405 (7.138)	prob 3.089 (2.471)	GS 30.953 (32.658)	mem 73.084
Train: [56][1280/1500]	BT 0.029 (0.324)	DT 0.000 (0.286)	loss 7.531 (7.193)	prob 2.323 (2.465)	GS 34.531 (33.165)	mem 73.085
Train: [56][1290/1500]	BT 0.044 (0.322)	DT 0.001 (0.284)	loss 6.931 (7.205)	prob 3.289 (2.513)	GS 31.141 (32.947)	mem 73.087
Train: [56][1300/1500]	BT 0.031 (0.319)	DT 0.000 (0.282)	loss 7.376 (7.237)	prob 2.859 (2.556)	GS 33.203 (32.702)	mem 73.089
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [56][1310/1500]	BT 0.093 (0.323)	DT 0.010 (0.285)	loss 7.310 (7.293)	prob 3.263 (2.874)	GS 31.578 (32.450)	mem 73.087
Train: [56][1320/1500]	BT 0.027 (0.330)	DT 0.000 (0.292)	loss 7.664 (7.233)	prob 2.897 (2.829)	GS 32.078 (32.237)	mem 73.089
Train: [56][1330/1500]	BT 0.031 (0.327)	DT 0.000 (0.290)	loss 7.189 (7.309)	prob 3.418 (2.772)	GS 32.906 (32.133)	mem 73.090
Train: [56][1340/1500]	BT 0.038 (0.327)	DT 0.000 (0.290)	loss 8.011 (7.321)	prob 2.912 (2.789)	GS 33.219 (31.963)	mem 73.092
Train: [56][1350/1500]	BT 0.038 (0.325)	DT 0.001 (0.287)	loss 7.944 (7.357)	prob 2.406 (2.725)	GS 34.453 (32.446)	mem 73.090
Train: [56][1360/1500]	BT 0.033 (0.323)	DT 0.000 (0.285)	loss 8.504 (7.442)	prob 1.156 (2.305)	GS 39.188 (32.820)	mem 73.091
Train: [56][1370/1500]	BT 0.031 (0.325)	DT 0.000 (0.287)	loss 8.323 (7.445)	prob 2.387 (2.573)	GS 35.781 (32.703)	mem 73.094
Train: [56][1380/1500]	BT 0.037 (0.323)	DT 0.001 (0.285)	loss 7.626 (7.397)	prob 2.261 (2.735)	GS 34.750 (32.376)	mem 73.093
Train: [56][1390/1500]	BT 0.062 (0.323)	DT 0.007 (0.285)	loss 7.523 (7.411)	prob 3.381 (2.649)	GS 33.391 (32.473)	mem 73.124
Train: [56][1400/1500]	BT 0.060 (0.321)	DT 0.001 (0.283)	loss 7.402 (7.398)	prob 3.164 (2.669)	GS 32.984 (32.617)	mem 73.125
Train: [56][1410/1500]	BT 0.066 (0.319)	DT 0.004 (0.281)	loss 7.294 (7.317)	prob 1.885 (2.560)	GS 33.672 (33.028)	mem 73.126
Train: [56][1420/1500]	BT 0.039 (0.322)	DT 0.001 (0.284)	loss 7.233 (7.380)	prob 2.195 (2.295)	GS 36.734 (32.691)	mem 73.124
Train: [56][1430/1500]	BT 0.039 (0.320)	DT 0.001 (0.282)	loss 7.555 (7.350)	prob 2.631 (2.432)	GS 35.328 (32.947)	mem 73.123
Train: [56][1440/1500]	BT 0.939 (0.320)	DT 0.901 (0.282)	loss 7.361 (7.360)	prob 2.534 (2.517)	GS 36.453 (32.989)	mem 73.124
Train: [56][1450/1500]	BT 0.039 (0.319)	DT 0.001 (0.280)	loss 7.408 (7.376)	prob 3.229 (2.561)	GS 30.422 (33.073)	mem 73.124
Train: [56][1460/1500]	BT 0.029 (0.318)	DT 0.001 (0.280)	loss 7.092 (7.286)	prob 3.417 (3.101)	GS 30.500 (31.673)	mem 73.015
Train: [56][1470/1500]	BT 0.031 (0.318)	DT 0.000 (0.280)	loss 7.691 (7.269)	prob 3.385 (3.293)	GS 36.281 (31.650)	mem 72.542
Train: [56][1480/1500]	BT 0.030 (0.316)	DT 0.000 (0.278)	loss 7.605 (7.275)	prob 2.545 (3.176)	GS 34.516 (31.971)	mem 72.359
Train: [56][1490/1500]	BT 0.032 (0.315)	DT 0.000 (0.277)	loss 7.200 (7.303)	prob 3.747 (3.155)	GS 28.312 (32.054)	mem 8.119
Train: [56][1500/1500]	BT 0.026 (0.313)	DT 0.000 (0.276)	loss 7.101 (7.308)	prob 3.225 (3.178)	GS 33.625 (32.066)	mem 8.119
Train: [56][1510/1500]	BT 0.026 (0.312)	DT 0.000 (0.274)	loss 6.602 (7.066)	prob 3.701 (3.020)	GS 32.844 (32.009)	mem 8.119
epoch 56, total time 471.43
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [57][1/1500]	BT 24.521 (24.521)	DT 24.441 (24.441)	loss 6.843 (6.843)	prob 3.872 (3.872)	GS 39.984 (39.984)	mem 71.764
Train: [57][10/1500]	BT 0.037 (2.547)	DT 0.000 (2.501)	loss 7.551 (6.995)	prob 3.288 (3.391)	GS 34.844 (33.438)	mem 71.775
Train: [57][20/1500]	BT 0.067 (1.299)	DT 0.013 (1.254)	loss 6.850 (7.002)	prob 3.491 (3.049)	GS 36.281 (33.218)	mem 71.778
Train: [57][30/1500]	BT 0.122 (1.233)	DT 0.003 (1.185)	loss 7.162 (7.065)	prob 3.449 (2.972)	GS 33.141 (33.131)	mem 71.840
Train: [57][40/1500]	BT 0.028 (1.330)	DT 0.000 (1.282)	loss 7.572 (7.103)	prob 3.372 (3.019)	GS 33.531 (33.438)	mem 71.871
Train: [57][50/1500]	BT 0.027 (1.069)	DT 0.000 (1.026)	loss 7.222 (7.128)	prob 2.844 (3.032)	GS 31.953 (33.055)	mem 71.878
Train: [57][60/1500]	BT 0.035 (0.896)	DT 0.000 (0.855)	loss 7.080 (7.096)	prob 2.960 (2.869)	GS 36.672 (32.478)	mem 71.879
Train: [57][70/1500]	BT 0.037 (0.828)	DT 0.000 (0.788)	loss 7.227 (7.159)	prob 3.272 (2.889)	GS 31.594 (32.123)	mem 71.922
Train: [57][80/1500]	BT 0.037 (0.729)	DT 0.001 (0.690)	loss 7.167 (7.143)	prob 3.004 (2.909)	GS 35.188 (32.500)	mem 71.922
Train: [57][90/1500]	BT 0.041 (0.691)	DT 0.001 (0.652)	loss 7.556 (7.172)	prob 3.424 (2.896)	GS 33.109 (32.446)	mem 71.941
Train: [57][100/1500]	BT 0.038 (0.625)	DT 0.001 (0.587)	loss 7.289 (7.201)	prob 3.523 (2.955)	GS 33.906 (32.606)	mem 71.940
Train: [57][110/1500]	BT 0.030 (0.638)	DT 0.000 (0.599)	loss 7.116 (7.226)	prob 3.568 (3.254)	GS 35.875 (30.908)	mem 71.835
Train: [57][120/1500]	BT 0.037 (0.588)	DT 0.001 (0.549)	loss 7.494 (7.268)	prob 2.493 (2.931)	GS 32.828 (31.919)	mem 71.835
Train: [57][130/1500]	BT 0.034 (0.546)	DT 0.001 (0.507)	loss 7.249 (7.239)	prob 3.426 (2.976)	GS 30.891 (32.443)	mem 71.835
Train: [57][140/1500]	BT 0.041 (0.609)	DT 0.001 (0.571)	loss 7.363 (7.230)	prob 3.084 (2.963)	GS 36.922 (32.532)	mem 71.861
Train: [57][150/1500]	BT 0.030 (0.571)	DT 0.000 (0.533)	loss 7.353 (7.224)	prob 3.446 (2.986)	GS 36.016 (32.712)	mem 71.861
Train: [57][160/1500]	BT 3.449 (0.559)	DT 3.410 (0.521)	loss 7.525 (7.273)	prob 2.556 (2.533)	GS 34.891 (34.620)	mem 71.866
Train: [57][170/1500]	BT 0.037 (0.527)	DT 0.001 (0.491)	loss 7.279 (7.285)	prob 3.187 (2.752)	GS 38.562 (33.620)	mem 71.867
Train: [57][180/1500]	BT 0.038 (0.500)	DT 0.000 (0.464)	loss 7.131 (7.231)	prob 2.932 (2.827)	GS 31.438 (33.187)	mem 71.866
Train: [57][190/1500]	BT 0.040 (0.498)	DT 0.000 (0.461)	loss 7.546 (7.233)	prob 3.075 (2.811)	GS 33.125 (33.334)	mem 71.867
Train: [57][200/1500]	BT 0.037 (0.475)	DT 0.001 (0.438)	loss 7.202 (7.212)	prob 2.491 (2.858)	GS 34.672 (33.600)	mem 71.868
Train: [57][210/1500]	BT 0.038 (0.468)	DT 0.001 (0.432)	loss 7.175 (7.133)	prob 3.749 (3.170)	GS 30.953 (31.589)	mem 71.869
Train: [57][220/1500]	BT 0.037 (0.449)	DT 0.001 (0.413)	loss 7.296 (7.135)	prob 2.931 (2.952)	GS 36.250 (32.182)	mem 71.870
Train: [57][230/1500]	BT 0.037 (0.432)	DT 0.001 (0.396)	loss 7.532 (7.142)	prob 2.556 (2.815)	GS 36.281 (32.503)	mem 71.871
Train: [57][240/1500]	BT 0.035 (0.430)	DT 0.001 (0.394)	loss 6.864 (7.150)	prob 3.090 (2.798)	GS 33.984 (32.736)	mem 71.895
Train: [57][250/1500]	BT 0.035 (0.415)	DT 0.000 (0.379)	loss 7.323 (7.148)	prob 2.879 (2.789)	GS 35.922 (32.740)	mem 71.896
Train: [57][260/1500]	BT 0.033 (0.425)	DT 0.000 (0.389)	loss 6.924 (7.222)	prob 3.842 (2.681)	GS 38.141 (31.495)	mem 71.895
Train: [57][270/1500]	BT 0.037 (0.424)	DT 0.001 (0.387)	loss 7.222 (7.211)	prob 3.179 (2.846)	GS 33.891 (32.528)	mem 71.882
Train: [57][280/1500]	BT 1.475 (0.416)	DT 1.433 (0.379)	loss 6.999 (7.167)	prob 2.772 (2.917)	GS 28.422 (31.988)	mem 71.883
Train: [57][290/1500]	BT 0.039 (0.411)	DT 0.001 (0.374)	loss 7.059 (7.164)	prob 3.463 (2.997)	GS 35.609 (32.115)	mem 71.883
Train: [57][300/1500]	BT 0.038 (0.401)	DT 0.001 (0.364)	loss 7.181 (7.175)	prob 3.240 (2.949)	GS 32.562 (32.017)	mem 71.884
Train: [57][310/1500]	BT 0.031 (0.413)	DT 0.000 (0.376)	loss 7.127 (7.061)	prob 3.038 (2.896)	GS 37.250 (33.364)	mem 71.889
Train: [57][320/1500]	BT 0.040 (0.401)	DT 0.001 (0.364)	loss 7.305 (7.091)	prob 3.132 (2.884)	GS 34.406 (32.455)	mem 71.892
Train: [57][330/1500]	BT 1.712 (0.396)	DT 1.679 (0.359)	loss 7.017 (7.092)	prob 3.638 (2.922)	GS 35.516 (32.812)	mem 71.892
Train: [57][340/1500]	BT 0.039 (0.390)	DT 0.001 (0.353)	loss 7.104 (7.096)	prob 2.952 (2.953)	GS 31.500 (32.686)	mem 71.893
Train: [57][350/1500]	BT 0.038 (0.380)	DT 0.001 (0.343)	loss 7.075 (7.094)	prob 3.278 (2.965)	GS 31.328 (32.423)	mem 71.893
Train: [57][360/1500]	BT 0.051 (0.388)	DT 0.012 (0.351)	loss 7.020 (7.085)	prob 2.633 (2.521)	GS 35.156 (33.100)	mem 71.896
Train: [57][370/1500]	BT 0.066 (0.379)	DT 0.006 (0.341)	loss 6.984 (7.078)	prob 2.716 (2.645)	GS 35.938 (32.901)	mem 71.895
Train: [57][380/1500]	BT 0.048 (0.397)	DT 0.007 (0.358)	loss 7.431 (7.110)	prob 2.552 (2.581)	GS 33.875 (32.801)	mem 72.043
Train: [57][390/1500]	BT 0.040 (0.393)	DT 0.001 (0.355)	loss 7.681 (7.104)	prob 2.617 (2.642)	GS 37.969 (32.744)	mem 72.045
Train: [57][400/1500]	BT 0.039 (0.385)	DT 0.001 (0.346)	loss 7.501 (7.119)	prob 2.551 (2.641)	GS 28.672 (32.856)	mem 72.075
Train: [57][410/1500]	BT 0.025 (0.385)	DT 0.000 (0.347)	loss 7.105 (7.022)	prob 3.827 (2.952)	GS 34.047 (33.694)	mem 72.829
Train: [57][420/1500]	BT 0.040 (0.377)	DT 0.001 (0.339)	loss 6.829 (7.024)	prob 3.223 (2.886)	GS 29.594 (32.857)	mem 72.879
Train: [57][430/1500]	BT 0.039 (0.374)	DT 0.001 (0.336)	loss 7.014 (7.020)	prob 3.074 (2.958)	GS 30.688 (33.098)	mem 73.025
Train: [57][440/1500]	BT 0.039 (0.368)	DT 0.001 (0.330)	loss 7.260 (7.018)	prob 3.054 (2.866)	GS 31.859 (32.827)	mem 73.074
Train: [57][450/1500]	BT 0.646 (0.362)	DT 0.610 (0.324)	loss 7.149 (7.011)	prob 3.237 (2.857)	GS 31.453 (32.719)	mem 73.089
Train: [57][460/1500]	BT 0.037 (0.364)	DT 0.000 (0.326)	loss 7.345 (7.080)	prob 2.778 (2.590)	GS 37.094 (32.908)	mem 73.095
Train: [57][470/1500]	BT 0.037 (0.357)	DT 0.000 (0.319)	loss 6.971 (7.010)	prob 2.660 (2.577)	GS 37.391 (32.899)	mem 73.094
Train: [57][480/1500]	BT 0.038 (0.355)	DT 0.000 (0.317)	loss 7.216 (7.034)	prob 3.365 (2.715)	GS 36.281 (32.599)	mem 73.096
Train: [57][490/1500]	BT 0.037 (0.354)	DT 0.000 (0.316)	loss 7.330 (7.038)	prob 3.041 (2.772)	GS 33.719 (32.427)	mem 73.101
Train: [57][500/1500]	BT 0.036 (0.352)	DT 0.000 (0.314)	loss 7.070 (7.027)	prob 2.973 (2.801)	GS 33.844 (32.388)	mem 73.103
Train: [57][510/1500]	BT 0.034 (0.351)	DT 0.000 (0.313)	loss 6.978 (7.040)	prob 3.410 (2.843)	GS 32.625 (31.580)	mem 73.106
Train: [57][520/1500]	BT 0.037 (0.345)	DT 0.001 (0.307)	loss 6.989 (6.997)	prob 2.677 (2.890)	GS 30.281 (31.208)	mem 73.106
Train: [57][530/1500]	BT 0.083 (0.347)	DT 0.006 (0.309)	loss 6.688 (6.980)	prob 3.323 (2.954)	GS 34.297 (31.534)	mem 73.107
Train: [57][540/1500]	BT 0.080 (0.355)	DT 0.006 (0.316)	loss 7.171 (6.997)	prob 2.904 (2.882)	GS 34.719 (31.596)	mem 73.107
Train: [57][550/1500]	BT 0.035 (0.357)	DT 0.001 (0.319)	loss 6.977 (6.982)	prob 3.302 (2.953)	GS 36.922 (32.776)	mem 73.111
Train: [57][560/1500]	BT 0.027 (0.352)	DT 0.000 (0.313)	loss 7.049 (6.911)	prob 2.716 (3.014)	GS 34.172 (33.552)	mem 73.112
Train: [57][570/1500]	BT 0.037 (0.350)	DT 0.001 (0.312)	loss 7.108 (6.971)	prob 2.871 (2.793)	GS 32.766 (32.815)	mem 73.114
Train: [57][580/1500]	BT 0.037 (0.348)	DT 0.000 (0.310)	loss 7.266 (6.956)	prob 3.250 (2.836)	GS 36.859 (32.628)	mem 73.117
Train: [57][590/1500]	BT 0.038 (0.343)	DT 0.001 (0.305)	loss 6.900 (6.951)	prob 3.110 (2.826)	GS 35.016 (32.514)	mem 73.116
Train: [57][600/1500]	BT 0.026 (0.346)	DT 0.000 (0.308)	loss 7.050 (6.976)	prob 3.036 (2.775)	GS 34.656 (32.734)	mem 73.119
Train: [57][610/1500]	BT 0.038 (0.341)	DT 0.001 (0.303)	loss 7.085 (7.031)	prob 2.611 (2.696)	GS 35.406 (32.361)	mem 73.120
Train: [57][620/1500]	BT 0.037 (0.336)	DT 0.000 (0.299)	loss 6.785 (7.027)	prob 3.329 (2.687)	GS 32.891 (32.471)	mem 73.120
Train: [57][630/1500]	BT 0.038 (0.337)	DT 0.001 (0.299)	loss 7.288 (7.082)	prob 2.548 (2.623)	GS 34.406 (32.598)	mem 73.119
Train: [57][640/1500]	BT 0.038 (0.334)	DT 0.000 (0.296)	loss 7.177 (7.120)	prob 2.569 (2.580)	GS 34.484 (32.163)	mem 73.121
Train: [57][650/1500]	BT 0.036 (0.334)	DT 0.001 (0.296)	loss 6.964 (7.103)	prob 2.254 (2.614)	GS 32.406 (32.027)	mem 73.122
Train: [57][660/1500]	BT 0.037 (0.329)	DT 0.000 (0.292)	loss 7.944 (7.290)	prob 2.217 (2.450)	GS 35.156 (32.700)	mem 73.122
Train: [57][670/1500]	BT 0.038 (0.329)	DT 0.001 (0.292)	loss 7.379 (7.214)	prob 2.957 (2.642)	GS 31.188 (32.312)	mem 73.122
Train: [57][680/1500]	BT 0.038 (0.325)	DT 0.001 (0.287)	loss 7.356 (7.232)	prob 2.037 (2.536)	GS 36.031 (32.509)	mem 73.122
Train: [57][690/1500]	BT 0.038 (0.321)	DT 0.001 (0.283)	loss 7.492 (7.223)	prob 3.377 (2.545)	GS 35.656 (32.225)	mem 73.123
Train: [57][700/1500]	BT 0.037 (0.324)	DT 0.000 (0.286)	loss 7.058 (7.205)	prob 3.449 (2.661)	GS 30.359 (32.003)	mem 73.122
Train: [57][710/1500]	BT 0.037 (0.320)	DT 0.000 (0.282)	loss 7.313 (7.323)	prob 2.389 (2.679)	GS 31.250 (32.116)	mem 73.122
Train: [57][720/1500]	BT 0.037 (0.320)	DT 0.001 (0.282)	loss 7.764 (7.320)	prob 2.239 (2.584)	GS 28.953 (31.491)	mem 73.124
Train: [57][730/1500]	BT 0.038 (0.318)	DT 0.000 (0.281)	loss 7.311 (7.335)	prob 3.412 (2.441)	GS 32.688 (31.910)	mem 73.126
Train: [57][740/1500]	BT 0.039 (0.315)	DT 0.001 (0.277)	loss 7.188 (7.348)	prob 3.470 (2.563)	GS 34.609 (32.057)	mem 73.125
Train: [57][750/1500]	BT 0.039 (0.325)	DT 0.001 (0.287)	loss 7.249 (7.362)	prob 3.589 (2.650)	GS 35.453 (32.479)	mem 73.157
Train: [57][760/1500]	BT 0.039 (0.321)	DT 0.001 (0.283)	loss 7.407 (7.405)	prob 3.477 (3.121)	GS 31.062 (32.123)	mem 73.157
Train: [57][770/1500]	BT 0.029 (0.318)	DT 0.000 (0.280)	loss 7.239 (7.361)	prob 2.735 (3.179)	GS 34.781 (32.083)	mem 73.158
Train: [57][780/1500]	BT 0.038 (0.320)	DT 0.001 (0.282)	loss 7.289 (7.344)	prob 4.235 (3.287)	GS 32.094 (31.971)	mem 73.159
Train: [57][790/1500]	BT 0.039 (0.316)	DT 0.001 (0.278)	loss 7.359 (7.365)	prob 3.626 (3.365)	GS 38.109 (31.770)	mem 73.159
Train: [57][800/1500]	BT 0.037 (0.322)	DT 0.000 (0.284)	loss 7.722 (7.372)	prob 4.028 (3.409)	GS 34.109 (31.649)	mem 73.161
Train: [57][810/1500]	BT 0.033 (0.319)	DT 0.000 (0.282)	loss 7.386 (7.484)	prob 3.530 (3.031)	GS 35.453 (33.456)	mem 73.162
Train: [57][820/1500]	BT 0.039 (0.319)	DT 0.001 (0.281)	loss 7.356 (7.370)	prob 4.509 (3.181)	GS 29.656 (32.612)	mem 73.164
Train: [57][830/1500]	BT 0.063 (0.319)	DT 0.004 (0.281)	loss 7.719 (7.370)	prob 3.888 (3.364)	GS 32.219 (32.402)	mem 73.165
Train: [57][840/1500]	BT 0.028 (0.316)	DT 0.000 (0.278)	loss 7.674 (7.396)	prob 3.665 (3.369)	GS 32.031 (32.701)	mem 73.165
Train: [57][850/1500]	BT 0.038 (0.314)	DT 0.001 (0.276)	loss 7.377 (7.422)	prob 3.922 (3.454)	GS 30.422 (32.718)	mem 73.166
Train: [57][860/1500]	BT 0.039 (0.315)	DT 0.000 (0.277)	loss 7.290 (7.468)	prob 4.369 (3.827)	GS 35.625 (32.602)	mem 73.165
Train: [57][870/1500]	BT 0.038 (0.312)	DT 0.001 (0.274)	loss 6.961 (7.412)	prob 4.372 (3.736)	GS 35.328 (33.398)	mem 73.166
Train: [57][880/1500]	BT 0.039 (0.312)	DT 0.001 (0.274)	loss 7.325 (7.369)	prob 4.033 (3.818)	GS 35.766 (33.485)	mem 73.167
Train: [57][890/1500]	BT 0.039 (0.309)	DT 0.000 (0.271)	loss 7.575 (7.353)	prob 3.623 (3.801)	GS 36.047 (33.631)	mem 73.167
Train: [57][900/1500]	BT 0.038 (0.311)	DT 0.000 (0.273)	loss 7.629 (7.367)	prob 4.395 (3.809)	GS 37.812 (33.719)	mem 73.167
Train: [57][910/1500]	BT 0.039 (0.308)	DT 0.001 (0.270)	loss 7.146 (7.440)	prob 4.125 (3.790)	GS 36.062 (33.775)	mem 73.169
Train: [57][920/1500]	BT 0.038 (0.309)	DT 0.001 (0.272)	loss 7.341 (7.367)	prob 4.071 (3.865)	GS 30.422 (33.309)	mem 73.170
Train: [57][930/1500]	BT 0.030 (0.306)	DT 0.000 (0.269)	loss 7.964 (7.419)	prob 3.498 (3.823)	GS 37.297 (33.292)	mem 73.168
Train: [57][940/1500]	BT 0.037 (0.309)	DT 0.000 (0.271)	loss 7.667 (7.387)	prob 3.726 (3.747)	GS 31.516 (33.220)	mem 73.170
Train: [57][950/1500]	BT 0.036 (0.306)	DT 0.000 (0.268)	loss 7.301 (7.386)	prob 4.189 (3.761)	GS 32.812 (32.977)	mem 73.170
Train: [57][960/1500]	BT 0.039 (0.303)	DT 0.001 (0.265)	loss 7.511 (7.257)	prob 4.112 (4.076)	GS 31.406 (31.816)	mem 73.170
Train: [57][970/1500]	BT 0.036 (0.304)	DT 0.000 (0.266)	loss 6.911 (7.306)	prob 4.340 (3.826)	GS 36.828 (32.473)	mem 73.170
Train: [57][980/1500]	BT 0.030 (0.301)	DT 0.000 (0.264)	loss 7.267 (7.302)	prob 4.093 (3.819)	GS 32.453 (32.627)	mem 73.170
Train: [57][990/1500]	BT 0.033 (0.302)	DT 0.001 (0.264)	loss 7.173 (7.304)	prob 4.071 (3.753)	GS 32.344 (33.176)	mem 73.177
Train: [57][1000/1500]	BT 0.032 (0.299)	DT 0.001 (0.261)	loss 7.385 (7.309)	prob 3.860 (3.737)	GS 34.406 (33.076)	mem 73.177
Train: [57][1010/1500]	BT 0.048 (0.296)	DT 0.016 (0.259)	loss 6.979 (7.262)	prob 4.046 (3.780)	GS 34.828 (33.130)	mem 73.180
Train: [57][1020/1500]	BT 0.027 (0.298)	DT 0.000 (0.261)	loss 6.939 (7.274)	prob 4.094 (3.854)	GS 29.500 (32.112)	mem 73.184
Train: [57][1030/1500]	BT 0.027 (0.296)	DT 0.000 (0.258)	loss 7.239 (7.276)	prob 3.777 (3.805)	GS 32.797 (31.795)	mem 73.184
Train: [57][1040/1500]	BT 0.037 (0.296)	DT 0.000 (0.258)	loss 6.693 (7.241)	prob 4.541 (3.860)	GS 36.281 (31.930)	mem 73.089
Train: [57][1050/1500]	BT 0.052 (0.294)	DT 0.002 (0.256)	loss 7.343 (7.239)	prob 4.447 (3.806)	GS 33.250 (32.069)	mem 73.089
Train: [57][1060/1500]	BT 0.080 (0.297)	DT 0.005 (0.259)	loss 7.403 (7.196)	prob 4.033 (3.938)	GS 31.344 (31.778)	mem 73.090
Train: [57][1070/1500]	BT 0.030 (0.318)	DT 0.000 (0.280)	loss 6.953 (7.207)	prob 3.800 (3.739)	GS 34.141 (32.664)	mem 73.099
Train: [57][1080/1500]	BT 0.033 (0.315)	DT 0.001 (0.277)	loss 6.958 (7.173)	prob 3.678 (3.633)	GS 32.156 (32.890)	mem 73.100
Train: [57][1090/1500]	BT 0.036 (0.315)	DT 0.001 (0.277)	loss 7.605 (7.218)	prob 2.964 (3.492)	GS 33.328 (32.972)	mem 73.101
Train: [57][1100/1500]	BT 0.039 (0.312)	DT 0.001 (0.275)	loss 7.240 (7.217)	prob 3.756 (3.517)	GS 33.016 (32.802)	mem 73.101
Train: [57][1110/1500]	BT 0.032 (0.313)	DT 0.000 (0.275)	loss 7.224 (7.110)	prob 3.057 (3.731)	GS 36.656 (33.314)	mem 73.101
Train: [57][1120/1500]	BT 0.031 (0.311)	DT 0.000 (0.273)	loss 7.231 (7.096)	prob 4.112 (3.703)	GS 31.469 (32.763)	mem 73.101
Train: [57][1130/1500]	BT 0.041 (0.308)	DT 0.000 (0.271)	loss 7.146 (7.105)	prob 3.513 (3.650)	GS 35.953 (32.673)	mem 73.101
Train: [57][1140/1500]	BT 0.038 (0.311)	DT 0.001 (0.273)	loss 7.263 (7.140)	prob 4.072 (3.544)	GS 33.328 (32.613)	mem 73.102
Train: [57][1150/1500]	BT 0.039 (0.309)	DT 0.001 (0.271)	loss 7.086 (7.135)	prob 3.627 (3.565)	GS 29.234 (32.701)	mem 73.102
Train: [57][1160/1500]	BT 0.040 (0.311)	DT 0.001 (0.273)	loss 7.072 (7.088)	prob 2.738 (3.452)	GS 32.859 (34.969)	mem 73.102
Train: [57][1170/1500]	BT 0.039 (0.308)	DT 0.001 (0.271)	loss 7.143 (7.131)	prob 2.950 (3.384)	GS 36.406 (33.937)	mem 73.102
Train: [57][1180/1500]	BT 0.039 (0.307)	DT 0.001 (0.269)	loss 6.833 (7.130)	prob 3.406 (3.364)	GS 36.875 (33.672)	mem 73.101
Train: [57][1190/1500]	BT 0.038 (0.308)	DT 0.001 (0.271)	loss 6.834 (7.149)	prob 3.080 (3.353)	GS 38.797 (33.646)	mem 73.102
Train: [57][1200/1500]	BT 0.048 (0.306)	DT 0.001 (0.269)	loss 7.303 (7.158)	prob 3.805 (3.271)	GS 34.094 (33.397)	mem 73.102
Train: [57][1210/1500]	BT 0.028 (0.308)	DT 0.001 (0.270)	loss 7.123 (7.169)	prob 3.544 (3.433)	GS 30.234 (33.342)	mem 73.105
Train: [57][1220/1500]	BT 0.039 (0.306)	DT 0.000 (0.268)	loss 7.371 (7.165)	prob 3.096 (3.274)	GS 38.875 (34.254)	mem 73.105
Train: [57][1230/1500]	BT 0.036 (0.306)	DT 0.000 (0.268)	loss 6.967 (7.129)	prob 3.184 (3.260)	GS 32.000 (33.711)	mem 73.121
Train: [57][1240/1500]	BT 0.032 (0.304)	DT 0.000 (0.266)	loss 6.902 (7.130)	prob 3.018 (3.165)	GS 33.875 (33.729)	mem 73.123
Train: [57][1250/1500]	BT 0.495 (0.302)	DT 0.458 (0.264)	loss 7.016 (7.127)	prob 2.840 (3.121)	GS 35.422 (33.800)	mem 73.122
Train: [57][1260/1500]	BT 0.038 (0.303)	DT 0.001 (0.265)	loss 7.010 (7.053)	prob 3.516 (3.310)	GS 35.219 (32.019)	mem 73.124
Train: [57][1270/1500]	BT 0.038 (0.301)	DT 0.000 (0.263)	loss 7.008 (7.044)	prob 3.480 (3.317)	GS 34.281 (31.687)	mem 73.123
Train: [57][1280/1500]	BT 0.067 (0.303)	DT 0.011 (0.266)	loss 6.873 (7.081)	prob 2.767 (3.140)	GS 35.516 (32.322)	mem 73.124
Train: [57][1290/1500]	BT 0.064 (0.301)	DT 0.011 (0.264)	loss 6.929 (7.080)	prob 3.706 (3.137)	GS 37.625 (32.038)	mem 73.123
Train: [57][1300/1500]	BT 0.110 (0.305)	DT 0.038 (0.267)	loss 7.297 (7.077)	prob 2.583 (3.117)	GS 32.219 (31.815)	mem 73.123
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [57][1310/1500]	BT 0.060 (0.303)	DT 0.011 (0.265)	loss 7.386 (7.033)	prob 2.795 (2.919)	GS 32.812 (31.894)	mem 73.122
Train: [57][1320/1500]	BT 0.033 (0.314)	DT 0.000 (0.276)	loss 7.377 (7.037)	prob 2.879 (2.888)	GS 33.953 (31.770)	mem 73.124
Train: [57][1330/1500]	BT 0.023 (0.311)	DT 0.000 (0.274)	loss 6.918 (7.035)	prob 3.661 (2.959)	GS 30.984 (32.297)	mem 73.125
Train: [57][1340/1500]	BT 0.024 (0.312)	DT 0.000 (0.274)	loss 7.106 (7.045)	prob 2.408 (2.949)	GS 32.688 (32.245)	mem 73.128
Train: [57][1350/1500]	BT 0.035 (0.309)	DT 0.000 (0.272)	loss 6.938 (7.029)	prob 2.883 (2.907)	GS 36.906 (32.398)	mem 73.128
Train: [57][1360/1500]	BT 0.036 (0.307)	DT 0.000 (0.270)	loss 6.932 (7.069)	prob 2.834 (2.487)	GS 29.562 (32.000)	mem 73.129
Train: [57][1370/1500]	BT 0.028 (0.308)	DT 0.000 (0.270)	loss 6.963 (7.026)	prob 2.870 (2.542)	GS 36.812 (31.986)	mem 73.133
Train: [57][1380/1500]	BT 0.029 (0.306)	DT 0.000 (0.268)	loss 7.012 (7.028)	prob 3.161 (2.621)	GS 29.516 (32.552)	mem 73.133
Train: [57][1390/1500]	BT 0.034 (0.307)	DT 0.000 (0.269)	loss 7.144 (7.027)	prob 2.591 (2.623)	GS 32.562 (32.451)	mem 73.136
Train: [57][1400/1500]	BT 0.037 (0.305)	DT 0.001 (0.267)	loss 7.231 (7.021)	prob 1.933 (2.634)	GS 31.656 (32.016)	mem 73.137
Train: [57][1410/1500]	BT 0.037 (0.303)	DT 0.001 (0.266)	loss 6.963 (7.012)	prob 3.162 (2.820)	GS 28.016 (31.803)	mem 73.136
Train: [57][1420/1500]	BT 0.062 (0.304)	DT 0.011 (0.267)	loss 7.394 (7.005)	prob 2.316 (2.816)	GS 34.047 (31.706)	mem 73.139
Train: [57][1430/1500]	BT 0.063 (0.303)	DT 0.013 (0.265)	loss 6.987 (7.007)	prob 3.065 (2.825)	GS 33.750 (32.281)	mem 73.139
Train: [57][1440/1500]	BT 0.038 (0.304)	DT 0.001 (0.266)	loss 6.964 (7.015)	prob 2.145 (2.736)	GS 32.781 (32.396)	mem 73.139
Train: [57][1450/1500]	BT 0.025 (0.303)	DT 0.000 (0.265)	loss 6.791 (6.986)	prob 3.121 (2.725)	GS 34.281 (32.531)	mem 73.139
Train: [57][1460/1500]	BT 0.030 (0.305)	DT 0.001 (0.268)	loss 7.180 (6.951)	prob 1.874 (2.542)	GS 34.750 (32.848)	mem 72.298
Train: [57][1470/1500]	BT 0.028 (0.303)	DT 0.000 (0.266)	loss 6.932 (6.979)	prob 2.627 (2.594)	GS 29.453 (31.938)	mem 72.224
Train: [57][1480/1500]	BT 0.027 (0.301)	DT 0.000 (0.264)	loss 6.948 (6.979)	prob 2.728 (2.612)	GS 36.531 (32.147)	mem 72.224
Train: [57][1490/1500]	BT 0.025 (0.301)	DT 0.000 (0.264)	loss 6.964 (6.993)	prob 2.742 (2.605)	GS 33.000 (32.591)	mem 8.055
Train: [57][1500/1500]	BT 0.024 (0.299)	DT 0.000 (0.262)	loss 6.565 (6.989)	prob 2.787 (2.628)	GS 33.781 (32.609)	mem 8.055
Train: [57][1510/1500]	BT 0.034 (0.298)	DT 0.000 (0.261)	loss 6.939 (6.756)	prob 1.614 (2.679)	GS 32.969 (31.509)	mem 7.982
epoch 57, total time 450.55
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [58][1/1500]	BT 19.179 (19.179)	DT 19.121 (19.121)	loss 6.599 (6.599)	prob 3.387 (3.387)	GS 34.172 (34.172)	mem 71.610
Train: [58][10/1500]	BT 0.037 (2.151)	DT 0.001 (2.112)	loss 6.680 (6.667)	prob 2.755 (2.564)	GS 34.781 (33.608)	mem 71.672
Train: [58][20/1500]	BT 0.039 (1.119)	DT 0.001 (1.080)	loss 7.161 (6.758)	prob 2.896 (2.547)	GS 39.609 (33.854)	mem 71.796
Train: [58][30/1500]	BT 0.056 (0.859)	DT 0.012 (0.821)	loss 6.618 (6.768)	prob 3.071 (2.560)	GS 30.000 (33.249)	mem 71.861
Train: [58][40/1500]	BT 0.061 (0.707)	DT 0.007 (0.667)	loss 6.799 (6.804)	prob 2.205 (2.547)	GS 30.422 (32.803)	mem 71.865
Train: [58][50/1500]	BT 0.030 (0.806)	DT 0.000 (0.768)	loss 6.995 (6.823)	prob 2.981 (2.498)	GS 34.000 (32.729)	mem 71.891
Train: [58][60/1500]	BT 0.024 (0.676)	DT 0.000 (0.640)	loss 6.884 (6.868)	prob 2.248 (2.462)	GS 31.781 (33.089)	mem 71.892
Train: [58][70/1500]	BT 0.038 (0.639)	DT 0.001 (0.603)	loss 6.790 (6.903)	prob 2.782 (2.598)	GS 34.547 (32.602)	mem 71.901
Train: [58][80/1500]	BT 0.083 (0.565)	DT 0.012 (0.528)	loss 6.818 (6.887)	prob 3.129 (2.580)	GS 31.031 (32.325)	mem 71.901
Train: [58][90/1500]	BT 4.848 (0.562)	DT 4.802 (0.523)	loss 7.255 (6.889)	prob 2.202 (2.554)	GS 32.172 (32.475)	mem 71.924
Train: [58][100/1500]	BT 0.041 (0.572)	DT 0.000 (0.534)	loss 6.807 (6.883)	prob 2.763 (2.511)	GS 33.812 (32.485)	mem 71.930
Train: [58][110/1500]	BT 0.037 (0.523)	DT 0.000 (0.485)	loss 6.840 (6.887)	prob 2.481 (2.488)	GS 35.078 (32.002)	mem 71.933
Train: [58][120/1500]	BT 0.048 (0.506)	DT 0.016 (0.469)	loss 6.922 (6.904)	prob 2.218 (2.415)	GS 32.578 (31.886)	mem 71.937
Train: [58][130/1500]	BT 0.049 (0.471)	DT 0.000 (0.433)	loss 7.073 (6.891)	prob 1.856 (2.367)	GS 35.609 (32.093)	mem 71.937
Train: [58][140/1500]	BT 0.082 (0.442)	DT 0.006 (0.403)	loss 6.986 (6.895)	prob 1.918 (2.365)	GS 30.625 (32.303)	mem 71.938
Train: [58][150/1500]	BT 0.034 (0.456)	DT 0.001 (0.417)	loss 6.868 (6.894)	prob 2.487 (2.386)	GS 36.781 (32.503)	mem 71.945
Train: [58][160/1500]	BT 0.039 (0.430)	DT 0.001 (0.391)	loss 6.867 (6.866)	prob 2.111 (2.128)	GS 36.125 (33.630)	mem 71.945
Train: [58][170/1500]	BT 0.038 (0.427)	DT 0.001 (0.389)	loss 7.047 (6.897)	prob 2.151 (2.190)	GS 34.688 (33.612)	mem 71.953
Train: [58][180/1500]	BT 0.039 (0.406)	DT 0.001 (0.367)	loss 6.781 (6.886)	prob 2.571 (2.227)	GS 34.031 (33.456)	mem 71.954
Train: [58][190/1500]	BT 0.039 (0.401)	DT 0.001 (0.363)	loss 6.761 (6.897)	prob 2.805 (2.266)	GS 32.516 (33.254)	mem 71.956
Train: [58][200/1500]	BT 0.038 (0.393)	DT 0.001 (0.355)	loss 6.841 (6.882)	prob 2.608 (2.355)	GS 30.688 (33.045)	mem 71.959
Train: [58][210/1500]	BT 0.038 (0.383)	DT 0.001 (0.344)	loss 6.888 (6.889)	prob 2.620 (2.344)	GS 35.047 (32.853)	mem 71.961
Train: [58][220/1500]	BT 0.039 (0.374)	DT 0.000 (0.335)	loss 7.017 (6.869)	prob 2.495 (2.329)	GS 33.797 (32.591)	mem 71.965
Train: [58][230/1500]	BT 0.036 (0.382)	DT 0.001 (0.343)	loss 6.917 (6.879)	prob 2.169 (2.374)	GS 35.766 (33.066)	mem 71.964
Train: [58][240/1500]	BT 0.039 (0.373)	DT 0.001 (0.334)	loss 6.815 (6.880)	prob 2.944 (2.277)	GS 33.250 (32.861)	mem 71.964
Train: [58][250/1500]	BT 0.039 (0.373)	DT 0.001 (0.335)	loss 6.999 (6.897)	prob 2.482 (2.285)	GS 29.406 (32.924)	mem 71.969
Train: [58][260/1500]	BT 0.039 (0.361)	DT 0.001 (0.322)	loss 6.826 (6.930)	prob 2.470 (2.317)	GS 31.219 (32.147)	mem 71.972
Train: [58][270/1500]	BT 0.059 (0.357)	DT 0.021 (0.318)	loss 6.947 (6.878)	prob 2.383 (2.340)	GS 34.297 (32.090)	mem 71.972
Train: [58][280/1500]	BT 0.040 (0.354)	DT 0.001 (0.315)	loss 6.897 (6.884)	prob 2.477 (2.276)	GS 36.203 (32.354)	mem 71.974
Train: [58][290/1500]	BT 0.039 (0.343)	DT 0.000 (0.304)	loss 7.334 (6.891)	prob 1.559 (2.264)	GS 32.953 (32.464)	mem 71.973
Train: [58][300/1500]	BT 0.027 (0.348)	DT 0.000 (0.310)	loss 6.913 (6.904)	prob 1.763 (2.263)	GS 35.312 (32.730)	mem 71.975
Train: [58][310/1500]	BT 0.037 (0.338)	DT 0.000 (0.300)	loss 6.723 (6.919)	prob 1.985 (2.263)	GS 30.594 (32.059)	mem 71.976
Train: [58][320/1500]	BT 3.470 (0.342)	DT 3.430 (0.304)	loss 6.993 (6.891)	prob 2.100 (2.234)	GS 28.891 (31.859)	mem 71.999
Train: [58][330/1500]	BT 0.028 (0.333)	DT 0.000 (0.295)	loss 6.895 (6.864)	prob 1.491 (2.228)	GS 32.547 (31.985)	mem 72.002
Train: [58][340/1500]	BT 0.038 (0.324)	DT 0.001 (0.286)	loss 6.888 (6.859)	prob 1.886 (2.182)	GS 35.094 (32.000)	mem 72.002
Train: [58][350/1500]	BT 0.037 (0.324)	DT 0.001 (0.286)	loss 6.755 (6.861)	prob 2.172 (2.192)	GS 32.250 (31.871)	mem 72.004
Train: [58][360/1500]	BT 0.037 (0.316)	DT 0.001 (0.278)	loss 6.758 (6.817)	prob 2.789 (2.234)	GS 37.062 (32.727)	mem 72.003
Train: [58][370/1500]	BT 0.037 (0.318)	DT 0.000 (0.280)	loss 6.811 (6.870)	prob 3.040 (2.322)	GS 31.625 (32.135)	mem 71.904
Train: [58][380/1500]	BT 0.036 (0.310)	DT 0.001 (0.273)	loss 6.824 (6.878)	prob 1.973 (2.235)	GS 35.906 (32.505)	mem 71.904
Train: [58][390/1500]	BT 0.051 (0.316)	DT 0.007 (0.279)	loss 6.941 (6.876)	prob 2.649 (2.261)	GS 35.125 (32.577)	mem 71.907
Train: [58][400/1500]	BT 0.031 (0.314)	DT 0.000 (0.276)	loss 6.822 (6.864)	prob 2.604 (2.274)	GS 34.688 (32.899)	mem 71.906
Train: [58][410/1500]	BT 0.059 (0.309)	DT 0.001 (0.271)	loss 6.693 (6.817)	prob 2.570 (2.464)	GS 31.406 (33.470)	mem 71.907
Train: [58][420/1500]	BT 0.024 (0.339)	DT 0.000 (0.300)	loss 6.776 (6.847)	prob 3.200 (2.320)	GS 31.891 (32.776)	mem 71.931
Train: [58][430/1500]	BT 0.031 (0.332)	DT 0.000 (0.293)	loss 6.782 (6.826)	prob 2.699 (2.329)	GS 31.750 (32.415)	mem 71.931
Train: [58][440/1500]	BT 0.033 (0.334)	DT 0.001 (0.296)	loss 6.808 (6.817)	prob 2.288 (2.361)	GS 38.422 (32.583)	mem 71.923
Train: [58][450/1500]	BT 0.038 (0.327)	DT 0.001 (0.289)	loss 6.702 (6.815)	prob 2.418 (2.378)	GS 33.922 (32.576)	mem 71.924
Train: [58][460/1500]	BT 0.035 (0.321)	DT 0.001 (0.283)	loss 6.812 (6.841)	prob 2.313 (2.381)	GS 33.250 (34.150)	mem 71.924
Train: [58][470/1500]	BT 0.028 (0.324)	DT 0.000 (0.286)	loss 6.713 (6.814)	prob 2.102 (2.274)	GS 32.688 (33.188)	mem 71.926
Train: [58][480/1500]	BT 0.038 (0.318)	DT 0.001 (0.280)	loss 7.022 (6.805)	prob 1.889 (2.334)	GS 36.266 (32.741)	mem 71.926
Train: [58][490/1500]	BT 0.038 (0.318)	DT 0.001 (0.281)	loss 6.764 (6.825)	prob 2.606 (2.313)	GS 34.391 (32.861)	mem 71.925
Train: [58][500/1500]	BT 0.026 (0.313)	DT 0.001 (0.275)	loss 6.872 (6.815)	prob 1.692 (2.271)	GS 32.812 (32.678)	mem 71.926
Train: [58][510/1500]	BT 0.031 (0.307)	DT 0.000 (0.270)	loss 6.874 (6.772)	prob 2.129 (2.222)	GS 32.984 (31.828)	mem 71.926
Train: [58][520/1500]	BT 0.054 (0.314)	DT 0.000 (0.276)	loss 6.997 (6.773)	prob 1.918 (2.309)	GS 32.969 (31.560)	mem 72.119
Train: [58][530/1500]	BT 0.062 (0.309)	DT 0.003 (0.271)	loss 6.722 (6.763)	prob 2.454 (2.297)	GS 32.984 (31.734)	mem 72.169
Train: [58][540/1500]	BT 0.064 (0.320)	DT 0.012 (0.283)	loss 6.967 (6.769)	prob 2.354 (2.338)	GS 35.812 (31.891)	mem 72.704
Train: [58][550/1500]	BT 0.031 (0.321)	DT 0.000 (0.283)	loss 6.767 (6.765)	prob 2.672 (2.383)	GS 32.922 (32.342)	mem 72.904
Train: [58][560/1500]	BT 0.039 (0.316)	DT 0.001 (0.279)	loss 6.787 (6.799)	prob 2.141 (2.680)	GS 34.500 (32.916)	mem 72.905
Train: [58][570/1500]	BT 0.031 (0.318)	DT 0.000 (0.280)	loss 6.744 (6.797)	prob 2.734 (2.718)	GS 35.844 (33.493)	mem 73.052
Train: [58][580/1500]	BT 0.039 (0.313)	DT 0.001 (0.275)	loss 6.740 (6.796)	prob 2.751 (2.727)	GS 38.000 (33.342)	mem 73.053
Train: [58][590/1500]	BT 0.037 (0.314)	DT 0.000 (0.277)	loss 6.886 (6.798)	prob 2.237 (2.678)	GS 35.828 (33.256)	mem 73.099
Train: [58][600/1500]	BT 0.038 (0.309)	DT 0.001 (0.272)	loss 6.980 (6.786)	prob 2.372 (2.658)	GS 32.859 (33.028)	mem 73.100
Train: [58][610/1500]	BT 0.033 (0.311)	DT 0.000 (0.274)	loss 6.774 (6.671)	prob 2.191 (2.732)	GS 36.062 (32.869)	mem 73.119
Train: [58][620/1500]	BT 0.037 (0.306)	DT 0.001 (0.269)	loss 6.862 (6.746)	prob 2.564 (2.690)	GS 26.438 (31.752)	mem 73.121
Train: [58][630/1500]	BT 0.037 (0.302)	DT 0.000 (0.265)	loss 6.751 (6.755)	prob 1.866 (2.574)	GS 31.375 (32.069)	mem 73.121
Train: [58][640/1500]	BT 0.030 (0.305)	DT 0.000 (0.268)	loss 6.921 (6.762)	prob 2.288 (2.529)	GS 30.781 (32.124)	mem 73.126
Train: [58][650/1500]	BT 0.037 (0.301)	DT 0.000 (0.264)	loss 6.781 (6.770)	prob 2.420 (2.552)	GS 33.359 (32.095)	mem 73.127
Train: [58][660/1500]	BT 0.086 (0.305)	DT 0.016 (0.268)	loss 6.840 (6.755)	prob 2.074 (2.697)	GS 34.516 (32.009)	mem 73.129
Train: [58][670/1500]	BT 0.024 (0.304)	DT 0.000 (0.267)	loss 6.898 (6.751)	prob 2.695 (2.812)	GS 34.328 (32.849)	mem 73.129
Train: [58][680/1500]	BT 0.037 (0.302)	DT 0.001 (0.265)	loss 6.706 (6.749)	prob 2.638 (2.769)	GS 31.625 (32.210)	mem 73.131
Train: [58][690/1500]	BT 0.038 (0.301)	DT 0.001 (0.263)	loss 6.843 (6.741)	prob 2.332 (2.753)	GS 34.969 (32.178)	mem 73.134
Train: [58][700/1500]	BT 0.037 (0.297)	DT 0.000 (0.260)	loss 6.885 (6.726)	prob 2.076 (2.692)	GS 33.438 (32.158)	mem 73.135
Train: [58][710/1500]	BT 0.035 (0.298)	DT 0.000 (0.261)	loss 6.549 (6.753)	prob 2.467 (3.037)	GS 35.047 (32.595)	mem 73.138
Train: [58][720/1500]	BT 0.036 (0.295)	DT 0.000 (0.257)	loss 6.547 (6.717)	prob 3.784 (2.989)	GS 30.094 (32.371)	mem 73.138
Train: [58][730/1500]	BT 0.038 (0.295)	DT 0.001 (0.258)	loss 6.757 (6.717)	prob 3.006 (2.950)	GS 35.719 (32.379)	mem 73.140
Train: [58][740/1500]	BT 0.028 (0.298)	DT 0.000 (0.261)	loss 6.923 (6.725)	prob 2.303 (2.950)	GS 31.969 (32.673)	mem 73.140
Train: [58][750/1500]	BT 0.025 (0.295)	DT 0.000 (0.258)	loss 6.571 (6.724)	prob 2.465 (2.904)	GS 28.438 (32.297)	mem 73.140
Train: [58][760/1500]	BT 0.037 (0.297)	DT 0.001 (0.260)	loss 6.736 (6.726)	prob 2.543 (2.863)	GS 36.531 (32.692)	mem 73.143
Train: [58][770/1500]	BT 0.035 (0.293)	DT 0.000 (0.257)	loss 6.993 (6.774)	prob 3.304 (2.819)	GS 33.188 (32.600)	mem 73.143
Train: [58][780/1500]	BT 0.036 (0.290)	DT 0.001 (0.253)	loss 6.687 (6.786)	prob 2.553 (2.862)	GS 32.719 (32.311)	mem 73.144
Train: [58][790/1500]	BT 0.048 (0.293)	DT 0.000 (0.256)	loss 6.698 (6.775)	prob 2.806 (2.812)	GS 29.562 (32.068)	mem 73.147
Train: [58][800/1500]	BT 0.081 (0.290)	DT 0.019 (0.253)	loss 6.802 (6.786)	prob 2.358 (2.762)	GS 33.062 (32.148)	mem 73.146
Train: [58][810/1500]	BT 0.029 (0.315)	DT 0.000 (0.278)	loss 6.761 (6.807)	prob 3.870 (2.828)	GS 39.562 (32.691)	mem 73.145
Train: [58][820/1500]	BT 0.031 (0.311)	DT 0.000 (0.274)	loss 6.896 (6.813)	prob 2.490 (2.800)	GS 34.109 (33.022)	mem 73.146
Train: [58][830/1500]	BT 0.038 (0.311)	DT 0.001 (0.274)	loss 6.683 (6.812)	prob 3.718 (2.856)	GS 37.469 (33.249)	mem 73.149
Train: [58][840/1500]	BT 0.036 (0.308)	DT 0.001 (0.271)	loss 6.682 (6.793)	prob 2.616 (2.924)	GS 34.156 (33.088)	mem 73.148
Train: [58][850/1500]	BT 0.038 (0.305)	DT 0.001 (0.268)	loss 7.074 (6.803)	prob 2.588 (2.941)	GS 33.250 (33.505)	mem 73.149
Train: [58][860/1500]	BT 0.037 (0.305)	DT 0.001 (0.268)	loss 7.012 (6.838)	prob 3.658 (2.894)	GS 37.625 (33.055)	mem 73.149
Train: [58][870/1500]	BT 0.037 (0.304)	DT 0.000 (0.267)	loss 6.606 (6.799)	prob 2.843 (2.982)	GS 33.016 (32.491)	mem 73.150
Train: [58][880/1500]	BT 0.039 (0.303)	DT 0.001 (0.266)	loss 6.880 (6.814)	prob 2.522 (2.916)	GS 34.078 (32.799)	mem 73.150
Train: [58][890/1500]	BT 0.059 (0.303)	DT 0.011 (0.266)	loss 6.699 (6.811)	prob 2.652 (2.851)	GS 33.094 (32.886)	mem 73.151
Train: [58][900/1500]	BT 0.079 (0.300)	DT 0.006 (0.263)	loss 6.917 (6.825)	prob 2.794 (2.837)	GS 32.406 (32.869)	mem 73.152
Train: [58][910/1500]	BT 0.093 (0.309)	DT 0.018 (0.272)	loss 6.796 (6.793)	prob 3.090 (2.730)	GS 35.562 (33.992)	mem 73.154
Train: [58][920/1500]	BT 0.031 (0.317)	DT 0.000 (0.279)	loss 6.954 (6.806)	prob 3.319 (2.761)	GS 33.047 (34.278)	mem 73.152
Train: [58][930/1500]	BT 0.113 (0.315)	DT 0.040 (0.276)	loss 6.868 (6.810)	prob 2.355 (2.817)	GS 35.484 (33.631)	mem 73.153
Train: [58][940/1500]	BT 0.038 (0.326)	DT 0.001 (0.288)	loss 6.690 (6.805)	prob 3.421 (2.849)	GS 32.688 (32.973)	mem 73.183
Train: [58][950/1500]	BT 0.027 (0.323)	DT 0.001 (0.285)	loss 6.869 (6.806)	prob 3.311 (2.889)	GS 33.500 (32.806)	mem 73.185
Train: [58][960/1500]	BT 0.028 (0.326)	DT 0.000 (0.288)	loss 6.682 (6.786)	prob 3.265 (3.009)	GS 36.141 (31.641)	mem 73.186
Train: [58][970/1500]	BT 0.031 (0.323)	DT 0.000 (0.285)	loss 6.698 (6.783)	prob 3.372 (2.967)	GS 39.125 (32.357)	mem 73.186
Train: [58][980/1500]	BT 0.064 (0.320)	DT 0.003 (0.282)	loss 6.908 (6.791)	prob 2.683 (3.005)	GS 29.859 (32.597)	mem 73.186
Train: [58][990/1500]	BT 0.044 (0.325)	DT 0.011 (0.287)	loss 6.904 (6.789)	prob 2.901 (2.986)	GS 33.547 (32.710)	mem 73.185
Train: [58][1000/1500]	BT 0.030 (0.329)	DT 0.000 (0.291)	loss 6.964 (6.802)	prob 2.220 (2.977)	GS 35.312 (32.504)	mem 73.186
Train: [58][1010/1500]	BT 0.028 (0.326)	DT 0.000 (0.288)	loss 6.823 (6.825)	prob 2.527 (2.848)	GS 33.797 (34.033)	mem 73.184
Train: [58][1020/1500]	BT 0.061 (0.328)	DT 0.011 (0.290)	loss 6.894 (6.791)	prob 2.828 (2.818)	GS 33.203 (32.823)	mem 73.184
Train: [58][1030/1500]	BT 0.033 (0.326)	DT 0.001 (0.287)	loss 6.953 (6.787)	prob 2.972 (2.788)	GS 32.359 (32.474)	mem 73.185
Train: [58][1040/1500]	BT 0.031 (0.330)	DT 0.000 (0.292)	loss 6.936 (6.792)	prob 2.918 (2.779)	GS 33.266 (32.312)	mem 73.185
Train: [58][1050/1500]	BT 0.053 (0.327)	DT 0.014 (0.289)	loss 6.789 (6.787)	prob 2.792 (2.789)	GS 38.438 (32.583)	mem 73.184
Train: [58][1060/1500]	BT 0.044 (0.342)	DT 0.001 (0.304)	loss 6.744 (6.781)	prob 2.668 (2.823)	GS 35.766 (33.397)	mem 73.182
Train: [58][1070/1500]	BT 0.031 (0.340)	DT 0.000 (0.301)	loss 6.834 (6.782)	prob 2.284 (2.765)	GS 33.375 (33.030)	mem 73.183
Train: [58][1080/1500]	BT 0.027 (0.337)	DT 0.000 (0.299)	loss 6.726 (6.790)	prob 3.101 (2.722)	GS 37.188 (32.958)	mem 73.183
Train: [58][1090/1500]	BT 0.030 (0.338)	DT 0.000 (0.300)	loss 6.710 (6.786)	prob 2.554 (2.718)	GS 33.000 (32.641)	mem 73.185
Train: [58][1100/1500]	BT 0.037 (0.335)	DT 0.000 (0.297)	loss 6.589 (6.799)	prob 2.577 (2.716)	GS 36.562 (32.561)	mem 73.187
Train: [58][1110/1500]	BT 0.025 (0.337)	DT 0.000 (0.300)	loss 6.959 (6.728)	prob 2.658 (2.906)	GS 36.875 (32.627)	mem 73.186
Train: [58][1120/1500]	BT 0.030 (0.335)	DT 0.000 (0.297)	loss 6.703 (6.788)	prob 2.733 (2.652)	GS 35.500 (33.309)	mem 73.186
Train: [58][1130/1500]	BT 0.039 (0.332)	DT 0.001 (0.294)	loss 6.683 (6.789)	prob 2.142 (2.689)	GS 36.391 (33.289)	mem 73.186
Train: [58][1140/1500]	BT 0.039 (0.332)	DT 0.001 (0.294)	loss 6.681 (6.786)	prob 2.976 (2.683)	GS 34.266 (33.297)	mem 73.188
Train: [58][1150/1500]	BT 0.039 (0.329)	DT 0.001 (0.292)	loss 6.836 (6.784)	prob 2.677 (2.654)	GS 31.328 (33.312)	mem 73.189
Train: [58][1160/1500]	BT 0.053 (0.330)	DT 0.004 (0.292)	loss 6.740 (6.762)	prob 2.170 (2.618)	GS 34.156 (32.878)	mem 73.188
Train: [58][1170/1500]	BT 0.052 (0.327)	DT 0.001 (0.289)	loss 6.660 (6.754)	prob 2.590 (2.566)	GS 30.812 (31.911)	mem 73.187
Train: [58][1180/1500]	BT 0.853 (0.331)	DT 0.805 (0.293)	loss 6.786 (6.764)	prob 2.985 (2.586)	GS 30.469 (31.952)	mem 73.188
Train: [58][1190/1500]	BT 0.048 (0.331)	DT 0.001 (0.292)	loss 6.900 (6.767)	prob 2.131 (2.612)	GS 32.984 (31.907)	mem 73.189
Train: [58][1200/1500]	BT 0.062 (0.329)	DT 0.002 (0.290)	loss 6.686 (6.777)	prob 2.995 (2.579)	GS 30.891 (32.248)	mem 73.189
Train: [58][1210/1500]	BT 0.039 (0.331)	DT 0.001 (0.292)	loss 6.603 (6.819)	prob 3.202 (2.689)	GS 33.844 (34.487)	mem 73.189
Train: [58][1220/1500]	BT 0.039 (0.328)	DT 0.001 (0.290)	loss 6.729 (6.800)	prob 2.492 (2.683)	GS 34.047 (34.084)	mem 73.190
Train: [58][1230/1500]	BT 0.038 (0.329)	DT 0.000 (0.290)	loss 6.692 (6.763)	prob 2.821 (2.639)	GS 35.297 (34.002)	mem 73.187
Train: [58][1240/1500]	BT 0.036 (0.326)	DT 0.001 (0.288)	loss 6.627 (6.761)	prob 2.404 (2.590)	GS 33.484 (33.759)	mem 73.186
Train: [58][1250/1500]	BT 2.559 (0.326)	DT 2.515 (0.288)	loss 6.807 (6.764)	prob 2.225 (2.554)	GS 33.406 (33.556)	mem 73.188
Train: [58][1260/1500]	BT 0.081 (0.330)	DT 0.016 (0.292)	loss 6.630 (6.754)	prob 2.397 (2.340)	GS 31.188 (32.414)	mem 73.192
Train: [58][1270/1500]	BT 0.065 (0.331)	DT 0.002 (0.292)	loss 6.721 (6.756)	prob 2.450 (2.396)	GS 32.391 (32.425)	mem 73.191
Train: [58][1280/1500]	BT 0.027 (0.339)	DT 0.000 (0.301)	loss 6.609 (6.767)	prob 2.082 (2.399)	GS 29.812 (32.553)	mem 73.201
Train: [58][1290/1500]	BT 0.024 (0.337)	DT 0.000 (0.298)	loss 6.694 (6.756)	prob 2.713 (2.435)	GS 29.062 (32.278)	mem 73.209
Train: [58][1300/1500]	BT 0.022 (0.338)	DT 0.000 (0.299)	loss 6.705 (6.744)	prob 2.658 (2.506)	GS 35.953 (32.511)	mem 73.229
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [58][1310/1500]	BT 0.037 (0.336)	DT 0.000 (0.297)	loss 6.580 (6.736)	prob 2.420 (2.327)	GS 37.891 (32.541)	mem 73.229
Train: [58][1320/1500]	BT 0.039 (0.333)	DT 0.000 (0.295)	loss 6.737 (6.721)	prob 3.060 (2.516)	GS 34.344 (32.674)	mem 73.098
Train: [58][1330/1500]	BT 0.029 (0.334)	DT 0.000 (0.296)	loss 6.729 (6.721)	prob 2.097 (2.509)	GS 35.031 (32.865)	mem 73.107
Train: [58][1340/1500]	BT 0.036 (0.332)	DT 0.000 (0.294)	loss 6.627 (6.716)	prob 2.785 (2.505)	GS 32.859 (32.984)	mem 73.108
Train: [58][1350/1500]	BT 0.031 (0.333)	DT 0.000 (0.294)	loss 6.630 (6.721)	prob 1.752 (2.528)	GS 32.078 (33.055)	mem 73.107
Train: [58][1360/1500]	BT 0.033 (0.330)	DT 0.000 (0.292)	loss 6.813 (6.707)	prob 2.619 (2.626)	GS 34.406 (32.292)	mem 73.106
Train: [58][1370/1500]	BT 6.632 (0.333)	DT 6.584 (0.295)	loss 6.477 (6.671)	prob 2.282 (2.604)	GS 34.594 (32.312)	mem 73.106
Train: [58][1380/1500]	BT 0.051 (0.331)	DT 0.000 (0.293)	loss 6.815 (6.676)	prob 1.842 (2.531)	GS 32.859 (31.943)	mem 73.107
Train: [58][1390/1500]	BT 0.030 (0.336)	DT 0.000 (0.298)	loss 6.636 (6.683)	prob 2.478 (2.527)	GS 32.688 (32.665)	mem 73.129
Train: [58][1400/1500]	BT 0.028 (0.334)	DT 0.000 (0.296)	loss 6.572 (6.670)	prob 2.332 (2.464)	GS 35.219 (32.665)	mem 73.130
Train: [58][1410/1500]	BT 0.066 (0.335)	DT 0.004 (0.296)	loss 6.717 (6.644)	prob 2.065 (2.511)	GS 30.266 (33.628)	mem 73.117
Train: [58][1420/1500]	BT 0.060 (0.333)	DT 0.011 (0.294)	loss 6.634 (6.622)	prob 3.190 (2.502)	GS 34.062 (33.312)	mem 73.117
Train: [58][1430/1500]	BT 0.068 (0.337)	DT 0.010 (0.298)	loss 6.872 (6.616)	prob 2.302 (2.617)	GS 33.047 (33.164)	mem 73.116
Train: [58][1440/1500]	BT 0.029 (0.343)	DT 0.000 (0.305)	loss 6.548 (6.606)	prob 2.449 (2.670)	GS 32.656 (33.075)	mem 73.117
Train: [58][1450/1500]	BT 0.030 (0.341)	DT 0.000 (0.303)	loss 6.968 (6.636)	prob 2.512 (2.621)	GS 32.484 (32.813)	mem 73.118
Train: [58][1460/1500]	BT 0.037 (0.339)	DT 0.001 (0.301)	loss 7.152 (6.694)	prob 1.312 (2.494)	GS 32.812 (32.494)	mem 73.119
Train: [58][1470/1500]	BT 0.028 (0.339)	DT 0.000 (0.300)	loss 6.972 (6.707)	prob 2.191 (2.496)	GS 30.016 (32.066)	mem 71.947
Train: [58][1480/1500]	BT 0.028 (0.337)	DT 0.001 (0.298)	loss 6.749 (6.720)	prob 3.253 (2.589)	GS 36.062 (32.208)	mem 71.947
Train: [58][1490/1500]	BT 0.027 (0.336)	DT 0.000 (0.298)	loss 6.910 (6.743)	prob 2.314 (2.587)	GS 32.875 (32.278)	mem 8.048
Train: [58][1500/1500]	BT 0.025 (0.334)	DT 0.000 (0.296)	loss 6.646 (6.735)	prob 2.659 (2.568)	GS 38.500 (32.289)	mem 8.048
Train: [58][1510/1500]	BT 0.828 (0.333)	DT 0.790 (0.295)	loss 6.458 (6.589)	prob 1.628 (2.640)	GS 40.594 (32.941)	mem 8.014
epoch 58, total time 502.91
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [59][1/1500]	BT 24.479 (24.479)	DT 24.416 (24.416)	loss 6.278 (6.278)	prob 2.203 (2.203)	GS 36.188 (36.188)	mem 71.765
Train: [59][10/1500]	BT 0.036 (2.483)	DT 0.000 (2.443)	loss 6.489 (6.528)	prob 2.854 (2.706)	GS 28.203 (32.991)	mem 71.778
Train: [59][20/1500]	BT 0.037 (1.603)	DT 0.000 (1.559)	loss 6.899 (6.598)	prob 2.576 (2.648)	GS 34.812 (32.898)	mem 71.809
Train: [59][30/1500]	BT 0.097 (1.095)	DT 0.042 (1.045)	loss 6.832 (6.646)	prob 2.523 (2.746)	GS 31.156 (32.778)	mem 71.812
Train: [59][40/1500]	BT 0.028 (0.960)	DT 0.000 (0.913)	loss 6.940 (6.691)	prob 2.680 (2.915)	GS 30.578 (33.248)	mem 71.846
Train: [59][50/1500]	BT 0.037 (0.774)	DT 0.000 (0.730)	loss 6.942 (6.731)	prob 2.475 (2.918)	GS 34.234 (33.018)	mem 71.848
Train: [59][60/1500]	BT 0.073 (0.661)	DT 0.006 (0.616)	loss 7.034 (6.735)	prob 2.918 (3.108)	GS 31.891 (32.967)	mem 71.851
Train: [59][70/1500]	BT 0.037 (0.658)	DT 0.001 (0.615)	loss 6.890 (6.831)	prob 2.606 (2.927)	GS 33.969 (33.472)	mem 71.869
Train: [59][80/1500]	BT 0.033 (0.581)	DT 0.000 (0.538)	loss 6.954 (6.827)	prob 2.492 (2.848)	GS 32.094 (32.920)	mem 71.873
Train: [59][90/1500]	BT 0.063 (0.555)	DT 0.004 (0.511)	loss 6.928 (6.815)	prob 2.656 (2.833)	GS 32.047 (32.511)	mem 71.879
Train: [59][100/1500]	BT 0.037 (0.518)	DT 0.000 (0.474)	loss 6.962 (6.820)	prob 2.141 (2.804)	GS 34.750 (32.557)	mem 71.886
Train: [59][110/1500]	BT 0.038 (0.502)	DT 0.001 (0.460)	loss 7.104 (6.831)	prob 1.757 (2.472)	GS 35.297 (33.141)	mem 71.899
Train: [59][120/1500]	BT 0.037 (0.467)	DT 0.001 (0.425)	loss 6.861 (6.832)	prob 2.646 (2.515)	GS 32.516 (32.344)	mem 71.899
Train: [59][130/1500]	BT 0.037 (0.442)	DT 0.000 (0.400)	loss 6.778 (6.839)	prob 3.158 (2.561)	GS 35.938 (32.604)	mem 71.902
Train: [59][140/1500]	BT 0.057 (0.431)	DT 0.006 (0.390)	loss 6.811 (6.822)	prob 3.045 (2.669)	GS 32.234 (32.595)	mem 71.906
Train: [59][150/1500]	BT 0.037 (0.415)	DT 0.000 (0.374)	loss 6.813 (6.822)	prob 2.017 (2.720)	GS 40.062 (32.735)	mem 71.915
Train: [59][160/1500]	BT 0.037 (0.405)	DT 0.001 (0.364)	loss 6.732 (6.761)	prob 3.293 (2.599)	GS 35.156 (32.513)	mem 71.918
Train: [59][170/1500]	BT 0.037 (0.393)	DT 0.000 (0.352)	loss 6.679 (6.769)	prob 2.841 (2.661)	GS 33.016 (32.105)	mem 71.921
Train: [59][180/1500]	BT 0.027 (0.381)	DT 0.001 (0.340)	loss 6.878 (6.759)	prob 2.848 (2.612)	GS 31.969 (32.510)	mem 71.922
Train: [59][190/1500]	BT 0.037 (0.371)	DT 0.000 (0.331)	loss 6.832 (6.784)	prob 2.809 (2.616)	GS 34.047 (32.727)	mem 71.923
Train: [59][200/1500]	BT 0.037 (0.368)	DT 0.000 (0.327)	loss 7.087 (6.795)	prob 2.205 (2.604)	GS 38.781 (32.890)	mem 71.928
Train: [59][210/1500]	BT 0.061 (0.364)	DT 0.005 (0.323)	loss 6.881 (6.804)	prob 2.508 (2.587)	GS 34.016 (32.355)	mem 71.931
Train: [59][220/1500]	BT 3.514 (0.369)	DT 3.483 (0.328)	loss 6.889 (6.834)	prob 2.745 (2.554)	GS 35.219 (33.317)	mem 71.933
Train: [59][230/1500]	BT 0.036 (0.368)	DT 0.000 (0.327)	loss 6.771 (6.824)	prob 3.392 (2.566)	GS 34.859 (33.054)	mem 71.934
Train: [59][240/1500]	BT 0.037 (0.354)	DT 0.001 (0.313)	loss 7.075 (6.830)	prob 3.088 (2.580)	GS 30.719 (32.864)	mem 71.934
Train: [59][250/1500]	BT 0.038 (0.345)	DT 0.001 (0.305)	loss 6.770 (6.808)	prob 2.864 (2.596)	GS 33.547 (32.810)	mem 71.934
Train: [59][260/1500]	BT 0.037 (0.340)	DT 0.000 (0.300)	loss 6.788 (6.785)	prob 2.161 (2.652)	GS 35.281 (32.034)	mem 71.937
Train: [59][270/1500]	BT 0.064 (0.339)	DT 0.004 (0.299)	loss 6.854 (6.810)	prob 1.837 (2.418)	GS 33.172 (32.121)	mem 71.939
Train: [59][280/1500]	BT 0.079 (0.344)	DT 0.002 (0.303)	loss 6.979 (6.805)	prob 2.170 (2.418)	GS 30.922 (32.056)	mem 71.942
Train: [59][290/1500]	BT 0.060 (0.351)	DT 0.016 (0.309)	loss 7.287 (6.817)	prob 2.328 (2.396)	GS 35.453 (32.212)	mem 71.943
Train: [59][300/1500]	BT 0.052 (0.342)	DT 0.005 (0.300)	loss 6.724 (6.806)	prob 2.850 (2.447)	GS 32.375 (32.225)	mem 71.944
Train: [59][310/1500]	BT 0.034 (0.364)	DT 0.001 (0.322)	loss 7.115 (6.912)	prob 1.626 (2.295)	GS 30.547 (33.220)	mem 71.947
Train: [59][320/1500]	BT 0.036 (0.354)	DT 0.001 (0.312)	loss 7.101 (6.861)	prob 1.901 (2.340)	GS 31.328 (32.484)	mem 71.949
Train: [59][330/1500]	BT 0.033 (0.355)	DT 0.000 (0.313)	loss 6.734 (6.914)	prob 2.594 (2.334)	GS 34.156 (32.900)	mem 71.950
Train: [59][340/1500]	BT 0.063 (0.346)	DT 0.005 (0.304)	loss 6.824 (6.897)	prob 2.329 (2.376)	GS 33.312 (32.670)	mem 71.951
Train: [59][350/1500]	BT 0.064 (0.346)	DT 0.003 (0.305)	loss 7.195 (6.886)	prob 2.867 (2.368)	GS 30.906 (32.567)	mem 71.950
Train: [59][360/1500]	BT 0.049 (0.353)	DT 0.014 (0.311)	loss 7.028 (6.845)	prob 2.327 (2.635)	GS 32.609 (32.772)	mem 71.953
Train: [59][370/1500]	BT 0.037 (0.355)	DT 0.000 (0.313)	loss 6.838 (6.871)	prob 3.104 (2.632)	GS 30.250 (32.425)	mem 71.950
Train: [59][380/1500]	BT 0.037 (0.348)	DT 0.001 (0.306)	loss 7.243 (6.883)	prob 1.650 (2.676)	GS 36.281 (32.357)	mem 71.950
Train: [59][390/1500]	BT 0.038 (0.344)	DT 0.001 (0.303)	loss 6.700 (6.878)	prob 3.109 (2.643)	GS 34.781 (32.679)	mem 71.951
Train: [59][400/1500]	BT 0.028 (0.344)	DT 0.000 (0.302)	loss 6.961 (6.884)	prob 3.525 (2.673)	GS 32.094 (32.789)	mem 71.953
Train: [59][410/1500]	BT 0.036 (0.338)	DT 0.001 (0.297)	loss 7.167 (7.004)	prob 2.488 (2.622)	GS 34.391 (34.688)	mem 71.954
Train: [59][420/1500]	BT 0.035 (0.336)	DT 0.001 (0.295)	loss 6.902 (6.966)	prob 3.445 (2.773)	GS 31.828 (33.688)	mem 71.962
Train: [59][430/1500]	BT 0.039 (0.332)	DT 0.001 (0.291)	loss 7.181 (6.957)	prob 2.445 (2.771)	GS 31.359 (32.926)	mem 71.990
Train: [59][440/1500]	BT 0.039 (0.326)	DT 0.001 (0.285)	loss 6.866 (6.975)	prob 3.087 (2.744)	GS 30.500 (32.411)	mem 71.991
Train: [59][450/1500]	BT 0.038 (0.329)	DT 0.001 (0.288)	loss 7.119 (6.983)	prob 2.825 (2.772)	GS 35.703 (32.477)	mem 71.991
Train: [59][460/1500]	BT 0.039 (0.323)	DT 0.001 (0.282)	loss 6.772 (6.915)	prob 3.756 (2.483)	GS 39.219 (33.028)	mem 71.991
Train: [59][470/1500]	BT 0.032 (0.329)	DT 0.000 (0.288)	loss 6.864 (6.907)	prob 2.945 (2.568)	GS 35.281 (31.988)	mem 71.994
Train: [59][480/1500]	BT 0.059 (0.323)	DT 0.016 (0.282)	loss 6.833 (6.915)	prob 3.059 (2.539)	GS 37.094 (32.245)	mem 71.994
Train: [59][490/1500]	BT 0.039 (0.324)	DT 0.001 (0.283)	loss 7.268 (6.960)	prob 2.418 (2.584)	GS 29.594 (32.318)	mem 71.997
Train: [59][500/1500]	BT 0.038 (0.321)	DT 0.001 (0.280)	loss 7.076 (6.979)	prob 2.962 (2.568)	GS 34.188 (32.377)	mem 72.095
Train: [59][510/1500]	BT 0.038 (0.316)	DT 0.001 (0.275)	loss 6.814 (6.898)	prob 3.012 (2.525)	GS 32.547 (31.391)	mem 72.144
Train: [59][520/1500]	BT 0.037 (0.324)	DT 0.001 (0.283)	loss 6.967 (6.977)	prob 2.624 (2.712)	GS 34.422 (32.635)	mem 72.928
Train: [59][530/1500]	BT 0.038 (0.319)	DT 0.001 (0.278)	loss 7.173 (7.013)	prob 2.795 (2.693)	GS 37.719 (32.633)	mem 72.928
Train: [59][540/1500]	BT 0.029 (0.326)	DT 0.000 (0.285)	loss 6.668 (7.008)	prob 2.370 (2.683)	GS 29.297 (32.674)	mem 73.178
Train: [59][550/1500]	BT 0.037 (0.321)	DT 0.001 (0.280)	loss 6.708 (7.022)	prob 2.865 (2.621)	GS 33.938 (32.546)	mem 73.178
Train: [59][560/1500]	BT 0.038 (0.323)	DT 0.001 (0.283)	loss 6.848 (7.019)	prob 2.174 (2.524)	GS 29.781 (32.950)	mem 73.179
Train: [59][570/1500]	BT 0.060 (0.318)	DT 0.000 (0.278)	loss 7.290 (7.088)	prob 3.012 (2.441)	GS 33.438 (33.104)	mem 73.179
Train: [59][580/1500]	BT 0.039 (0.313)	DT 0.001 (0.273)	loss 7.197 (7.101)	prob 1.460 (2.379)	GS 37.766 (33.478)	mem 73.178
Train: [59][590/1500]	BT 0.037 (0.316)	DT 0.001 (0.276)	loss 7.009 (7.079)	prob 1.798 (2.357)	GS 36.078 (33.502)	mem 73.178
Train: [59][600/1500]	BT 0.039 (0.311)	DT 0.001 (0.271)	loss 6.990 (7.067)	prob 2.716 (2.377)	GS 34.016 (33.275)	mem 73.179
Train: [59][610/1500]	BT 0.038 (0.313)	DT 0.001 (0.273)	loss 7.534 (7.100)	prob 2.364 (2.526)	GS 32.438 (31.556)	mem 73.178
Train: [59][620/1500]	BT 0.039 (0.309)	DT 0.001 (0.269)	loss 6.870 (7.043)	prob 2.133 (2.449)	GS 32.656 (32.273)	mem 73.178
Train: [59][630/1500]	BT 0.030 (0.314)	DT 0.000 (0.274)	loss 7.143 (7.096)	prob 2.726 (2.371)	GS 33.219 (31.820)	mem 73.179
Train: [59][640/1500]	BT 0.043 (0.310)	DT 0.001 (0.270)	loss 7.291 (7.113)	prob 2.774 (2.459)	GS 35.000 (31.901)	mem 73.179
Train: [59][650/1500]	BT 0.038 (0.306)	DT 0.000 (0.266)	loss 6.730 (7.110)	prob 2.328 (2.465)	GS 34.422 (31.990)	mem 73.179
Train: [59][660/1500]	BT 0.049 (0.315)	DT 0.000 (0.275)	loss 6.834 (7.032)	prob 3.138 (2.138)	GS 30.203 (32.019)	mem 73.178
Train: [59][670/1500]	BT 0.038 (0.311)	DT 0.001 (0.271)	loss 7.628 (7.060)	prob 1.145 (2.259)	GS 34.750 (31.960)	mem 73.179
Train: [59][680/1500]	BT 0.033 (0.328)	DT 0.000 (0.288)	loss 7.354 (7.089)	prob 2.311 (2.215)	GS 36.188 (32.127)	mem 73.184
Train: [59][690/1500]	BT 0.030 (0.324)	DT 0.000 (0.284)	loss 6.817 (7.117)	prob 3.573 (2.213)	GS 33.500 (31.760)	mem 73.187
Train: [59][700/1500]	BT 0.031 (0.325)	DT 0.000 (0.285)	loss 7.035 (7.096)	prob 2.216 (2.184)	GS 32.406 (31.858)	mem 73.200
Train: [59][710/1500]	BT 0.031 (0.320)	DT 0.000 (0.281)	loss 7.113 (7.062)	prob 2.047 (1.948)	GS 34.688 (31.464)	mem 73.200
Train: [59][720/1500]	BT 0.031 (0.316)	DT 0.000 (0.277)	loss 7.405 (7.118)	prob 2.040 (2.048)	GS 33.281 (31.572)	mem 73.198
Train: [59][730/1500]	BT 0.026 (0.320)	DT 0.000 (0.281)	loss 7.291 (7.158)	prob 2.921 (2.217)	GS 32.062 (32.008)	mem 73.097
Train: [59][740/1500]	BT 0.038 (0.316)	DT 0.000 (0.277)	loss 7.340 (7.177)	prob 2.636 (2.257)	GS 35.469 (32.222)	mem 73.100
Train: [59][750/1500]	BT 0.080 (0.321)	DT 0.007 (0.281)	loss 7.286 (7.180)	prob 2.200 (2.316)	GS 32.766 (32.487)	mem 73.100
Train: [59][760/1500]	BT 0.031 (0.325)	DT 0.001 (0.285)	loss 6.825 (7.260)	prob 3.064 (2.171)	GS 33.312 (34.594)	mem 73.100
Train: [59][770/1500]	BT 0.035 (0.323)	DT 0.000 (0.283)	loss 7.206 (7.234)	prob 2.543 (2.399)	GS 33.031 (33.464)	mem 73.103
Train: [59][780/1500]	BT 0.035 (0.321)	DT 0.000 (0.282)	loss 7.394 (7.228)	prob 3.126 (2.587)	GS 33.594 (33.092)	mem 73.125
Train: [59][790/1500]	BT 0.036 (0.318)	DT 0.001 (0.278)	loss 6.787 (7.217)	prob 2.919 (2.631)	GS 29.531 (32.918)	mem 73.124
Train: [59][800/1500]	BT 0.064 (0.320)	DT 0.004 (0.280)	loss 7.283 (7.194)	prob 3.034 (2.702)	GS 30.641 (32.545)	mem 73.125
Train: [59][810/1500]	BT 0.040 (0.318)	DT 0.001 (0.278)	loss 7.214 (7.405)	prob 3.140 (2.804)	GS 33.203 (31.500)	mem 73.124
Train: [59][820/1500]	BT 0.029 (0.318)	DT 0.000 (0.278)	loss 6.998 (7.289)	prob 3.047 (2.661)	GS 33.500 (31.677)	mem 73.126
Train: [59][830/1500]	BT 0.039 (0.314)	DT 0.001 (0.275)	loss 7.352 (7.279)	prob 1.770 (2.653)	GS 34.531 (32.112)	mem 73.126
Train: [59][840/1500]	BT 0.038 (0.315)	DT 0.001 (0.276)	loss 7.273 (7.305)	prob 2.471 (2.573)	GS 33.594 (32.103)	mem 73.113
Train: [59][850/1500]	BT 0.038 (0.313)	DT 0.001 (0.273)	loss 7.676 (7.291)	prob 2.741 (2.598)	GS 33.234 (31.894)	mem 73.112
Train: [59][860/1500]	BT 0.025 (0.312)	DT 0.000 (0.272)	loss 7.000 (7.296)	prob 2.774 (2.663)	GS 34.094 (33.548)	mem 73.114
Train: [59][870/1500]	BT 0.031 (0.313)	DT 0.000 (0.273)	loss 7.239 (7.332)	prob 2.490 (2.609)	GS 37.125 (33.348)	mem 73.116
Train: [59][880/1500]	BT 0.039 (0.311)	DT 0.000 (0.271)	loss 7.607 (7.338)	prob 3.203 (2.588)	GS 37.016 (33.378)	mem 73.118
Train: [59][890/1500]	BT 0.039 (0.309)	DT 0.001 (0.269)	loss 7.188 (7.305)	prob 2.681 (2.649)	GS 33.047 (33.466)	mem 73.117
Train: [59][900/1500]	BT 0.039 (0.308)	DT 0.001 (0.268)	loss 7.787 (7.310)	prob 3.436 (2.698)	GS 37.656 (33.389)	mem 73.119
Train: [59][910/1500]	BT 0.039 (0.305)	DT 0.001 (0.265)	loss 7.137 (7.200)	prob 3.030 (2.672)	GS 35.344 (32.663)	mem 73.119
Train: [59][920/1500]	BT 0.039 (0.308)	DT 0.001 (0.268)	loss 7.317 (7.323)	prob 3.155 (2.677)	GS 34.891 (32.777)	mem 73.118
Train: [59][930/1500]	BT 0.039 (0.305)	DT 0.001 (0.266)	loss 7.861 (7.312)	prob 2.721 (2.688)	GS 32.250 (32.740)	mem 73.118
Train: [59][940/1500]	BT 0.037 (0.307)	DT 0.001 (0.267)	loss 7.108 (7.340)	prob 3.425 (2.738)	GS 36.734 (32.734)	mem 73.135
Train: [59][950/1500]	BT 0.026 (0.304)	DT 0.000 (0.265)	loss 6.969 (7.324)	prob 3.771 (2.805)	GS 33.125 (32.601)	mem 73.135
Train: [59][960/1500]	BT 0.032 (0.301)	DT 0.000 (0.262)	loss 7.321 (7.451)	prob 2.330 (2.578)	GS 33.828 (32.530)	mem 73.135
Train: [59][970/1500]	BT 0.027 (0.301)	DT 0.000 (0.262)	loss 7.447 (7.333)	prob 2.608 (2.776)	GS 30.844 (32.562)	mem 73.139
Train: [59][980/1500]	BT 0.037 (0.298)	DT 0.001 (0.259)	loss 7.299 (7.360)	prob 2.703 (2.757)	GS 33.312 (32.744)	mem 73.140
Train: [59][990/1500]	BT 0.037 (0.299)	DT 0.000 (0.259)	loss 7.055 (7.353)	prob 2.910 (2.752)	GS 32.641 (32.604)	mem 73.143
Train: [59][1000/1500]	BT 0.037 (0.296)	DT 0.001 (0.257)	loss 7.288 (7.366)	prob 3.023 (2.773)	GS 31.344 (32.466)	mem 73.143
Train: [59][1010/1500]	BT 0.037 (0.298)	DT 0.000 (0.259)	loss 7.436 (7.356)	prob 3.550 (3.004)	GS 34.078 (32.523)	mem 73.145
Train: [59][1020/1500]	BT 0.038 (0.295)	DT 0.001 (0.256)	loss 6.932 (7.416)	prob 3.364 (3.135)	GS 30.922 (31.399)	mem 73.145
Train: [59][1030/1500]	BT 0.038 (0.294)	DT 0.001 (0.255)	loss 7.217 (7.450)	prob 3.918 (3.109)	GS 30.469 (31.497)	mem 73.147
Train: [59][1040/1500]	BT 0.029 (0.294)	DT 0.000 (0.255)	loss 7.355 (7.450)	prob 3.333 (3.069)	GS 36.750 (31.868)	mem 73.148
Train: [59][1050/1500]	BT 1.199 (0.292)	DT 1.166 (0.254)	loss 7.829 (7.454)	prob 3.036 (3.046)	GS 35.828 (31.823)	mem 73.150
Train: [59][1060/1500]	BT 0.070 (0.296)	DT 0.011 (0.257)	loss 7.843 (7.352)	prob 2.851 (2.762)	GS 37.438 (32.709)	mem 73.150
Train: [59][1070/1500]	BT 0.060 (0.301)	DT 0.001 (0.262)	loss 7.438 (7.393)	prob 3.450 (2.855)	GS 34.109 (32.891)	mem 73.148
Train: [59][1080/1500]	BT 0.037 (0.303)	DT 0.001 (0.264)	loss 7.371 (7.368)	prob 3.676 (3.054)	GS 32.188 (32.816)	mem 73.150
Train: [59][1090/1500]	BT 0.037 (0.300)	DT 0.001 (0.261)	loss 7.660 (7.428)	prob 2.704 (2.981)	GS 33.781 (33.060)	mem 73.150
Train: [59][1100/1500]	BT 0.038 (0.298)	DT 0.001 (0.259)	loss 7.361 (7.454)	prob 3.256 (2.910)	GS 34.922 (32.994)	mem 73.150
Train: [59][1110/1500]	BT 0.026 (0.305)	DT 0.000 (0.265)	loss 7.548 (7.386)	prob 3.798 (2.864)	GS 33.969 (34.614)	mem 73.151
Train: [59][1120/1500]	BT 0.038 (0.302)	DT 0.001 (0.263)	loss 7.774 (7.404)	prob 3.014 (3.091)	GS 38.281 (33.390)	mem 73.151
Train: [59][1130/1500]	BT 0.067 (0.302)	DT 0.013 (0.263)	loss 7.247 (7.369)	prob 3.218 (3.064)	GS 38.766 (33.257)	mem 73.150
Train: [59][1140/1500]	BT 0.037 (0.301)	DT 0.001 (0.262)	loss 7.643 (7.415)	prob 2.855 (2.965)	GS 34.625 (33.346)	mem 73.151
Train: [59][1150/1500]	BT 0.058 (0.302)	DT 0.001 (0.263)	loss 7.302 (7.408)	prob 3.149 (3.000)	GS 34.859 (33.095)	mem 73.152
Train: [59][1160/1500]	BT 0.064 (0.301)	DT 0.002 (0.262)	loss 7.416 (7.385)	prob 3.042 (3.000)	GS 36.641 (32.828)	mem 73.153
Train: [59][1170/1500]	BT 0.034 (0.299)	DT 0.000 (0.260)	loss 7.237 (7.439)	prob 3.501 (2.934)	GS 31.344 (32.366)	mem 73.152
Train: [59][1180/1500]	BT 0.088 (0.303)	DT 0.012 (0.264)	loss 7.362 (7.424)	prob 3.222 (2.990)	GS 32.922 (32.815)	mem 73.154
Train: [59][1190/1500]	BT 0.079 (0.302)	DT 0.013 (0.263)	loss 7.421 (7.432)	prob 3.878 (3.007)	GS 32.047 (32.887)	mem 73.155
Train: [59][1200/1500]	BT 0.037 (0.305)	DT 0.001 (0.265)	loss 7.895 (7.415)	prob 2.592 (2.994)	GS 34.688 (33.137)	mem 73.156
Train: [59][1210/1500]	BT 0.037 (0.303)	DT 0.001 (0.263)	loss 7.830 (7.514)	prob 2.593 (2.484)	GS 35.047 (34.998)	mem 73.157
Train: [59][1220/1500]	BT 0.038 (0.302)	DT 0.001 (0.263)	loss 7.454 (7.576)	prob 2.947 (2.502)	GS 33.406 (34.621)	mem 73.156
Train: [59][1230/1500]	BT 0.030 (0.302)	DT 0.001 (0.262)	loss 7.481 (7.533)	prob 3.558 (2.671)	GS 32.766 (34.101)	mem 73.157
Train: [59][1240/1500]	BT 0.057 (0.300)	DT 0.000 (0.260)	loss 7.576 (7.545)	prob 3.293 (2.819)	GS 34.625 (33.525)	mem 73.158
Train: [59][1250/1500]	BT 0.051 (0.303)	DT 0.008 (0.263)	loss 7.718 (7.522)	prob 2.687 (2.805)	GS 32.484 (33.304)	mem 73.160
Train: [59][1260/1500]	BT 0.083 (0.301)	DT 0.016 (0.261)	loss 7.172 (7.420)	prob 2.920 (2.963)	GS 32.984 (31.722)	mem 73.161
Train: [59][1270/1500]	BT 0.034 (0.306)	DT 0.000 (0.267)	loss 7.571 (7.458)	prob 2.869 (2.828)	GS 38.375 (32.262)	mem 73.158
Train: [59][1280/1500]	BT 0.035 (0.304)	DT 0.000 (0.265)	loss 7.925 (7.503)	prob 2.428 (2.694)	GS 31.125 (32.181)	mem 73.158
Train: [59][1290/1500]	BT 0.027 (0.311)	DT 0.000 (0.272)	loss 7.097 (7.491)	prob 3.329 (2.771)	GS 32.234 (32.346)	mem 73.156
Train: [59][1300/1500]	BT 0.029 (0.309)	DT 0.000 (0.270)	loss 8.098 (7.487)	prob 3.187 (2.796)	GS 33.828 (32.383)	mem 73.156
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [59][1310/1500]	BT 0.032 (0.309)	DT 0.000 (0.270)	loss 7.474 (7.401)	prob 3.439 (3.151)	GS 30.266 (30.105)	mem 73.162
Train: [59][1320/1500]	BT 0.025 (0.307)	DT 0.000 (0.268)	loss 7.343 (7.493)	prob 3.239 (3.021)	GS 32.734 (31.485)	mem 73.167
Train: [59][1330/1500]	BT 0.025 (0.305)	DT 0.000 (0.266)	loss 7.568 (7.494)	prob 2.568 (2.920)	GS 32.547 (31.631)	mem 73.189
Train: [59][1340/1500]	BT 0.030 (0.310)	DT 0.000 (0.271)	loss 7.286 (7.447)	prob 2.919 (2.937)	GS 36.891 (32.172)	mem 73.190
Train: [59][1350/1500]	BT 0.034 (0.308)	DT 0.000 (0.269)	loss 7.926 (7.468)	prob 2.768 (2.816)	GS 37.375 (32.331)	mem 73.192
Train: [59][1360/1500]	BT 0.027 (0.311)	DT 0.000 (0.272)	loss 7.198 (7.406)	prob 2.280 (2.558)	GS 33.156 (33.013)	mem 73.193
Train: [59][1370/1500]	BT 0.039 (0.309)	DT 0.001 (0.270)	loss 8.161 (7.453)	prob 2.339 (2.491)	GS 36.000 (34.337)	mem 73.193
Train: [59][1380/1500]	BT 0.047 (0.307)	DT 0.001 (0.268)	loss 7.406 (7.385)	prob 3.136 (2.695)	GS 35.375 (34.155)	mem 73.193
Train: [59][1390/1500]	BT 0.038 (0.309)	DT 0.001 (0.270)	loss 7.627 (7.391)	prob 3.077 (2.867)	GS 34.172 (33.965)	mem 73.194
Train: [59][1400/1500]	BT 0.028 (0.308)	DT 0.000 (0.269)	loss 7.187 (7.402)	prob 2.234 (2.840)	GS 33.094 (34.037)	mem 73.194
Train: [59][1410/1500]	BT 0.064 (0.310)	DT 0.015 (0.271)	loss 7.769 (7.665)	prob 3.228 (2.804)	GS 34.172 (33.697)	mem 73.195
Train: [59][1420/1500]	BT 0.081 (0.309)	DT 0.026 (0.270)	loss 7.512 (7.550)	prob 3.545 (3.017)	GS 31.328 (33.175)	mem 73.194
Train: [59][1430/1500]	BT 0.117 (0.308)	DT 0.015 (0.269)	loss 7.852 (7.576)	prob 3.116 (3.030)	GS 32.016 (32.760)	mem 73.194
Train: [59][1440/1500]	BT 0.056 (0.311)	DT 0.011 (0.272)	loss 7.396 (7.551)	prob 4.157 (3.056)	GS 33.828 (32.774)	mem 73.195
Train: [59][1450/1500]	BT 0.040 (0.317)	DT 0.001 (0.277)	loss 7.979 (7.562)	prob 3.324 (3.058)	GS 36.922 (32.952)	mem 72.755
Train: [59][1460/1500]	BT 0.031 (0.315)	DT 0.000 (0.276)	loss 7.088 (7.593)	prob 4.146 (3.306)	GS 36.141 (32.084)	mem 72.755
Train: [59][1470/1500]	BT 0.028 (0.313)	DT 0.000 (0.274)	loss 7.937 (7.604)	prob 3.330 (3.111)	GS 32.016 (32.695)	mem 72.754
Train: [59][1480/1500]	BT 0.025 (0.313)	DT 0.000 (0.274)	loss 7.449 (7.603)	prob 3.454 (3.154)	GS 33.391 (32.701)	mem 8.094
Train: [59][1490/1500]	BT 0.025 (0.311)	DT 0.000 (0.272)	loss 7.883 (7.593)	prob 3.381 (3.276)	GS 31.406 (32.557)	mem 8.094
Train: [59][1500/1500]	BT 0.034 (0.309)	DT 0.000 (0.270)	loss 7.062 (7.558)	prob 3.683 (3.368)	GS 32.562 (32.431)	mem 8.020
Train: [59][1510/1500]	BT 0.026 (0.308)	DT 0.000 (0.269)	loss 7.397 (7.498)	prob 4.345 (3.407)	GS 30.438 (34.819)	mem 8.019
epoch 59, total time 464.70
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [60][1/1500]	BT 22.001 (22.001)	DT 21.943 (21.943)	loss 7.449 (7.449)	prob 3.878 (3.878)	GS 31.047 (31.047)	mem 71.858
Train: [60][10/1500]	BT 0.038 (2.258)	DT 0.001 (2.218)	loss 7.723 (7.303)	prob 4.206 (3.817)	GS 28.156 (32.168)	mem 71.871
Train: [60][20/1500]	BT 0.039 (1.237)	DT 0.000 (1.197)	loss 7.531 (7.314)	prob 3.261 (3.706)	GS 33.047 (32.998)	mem 71.907
Train: [60][30/1500]	BT 0.039 (0.900)	DT 0.001 (0.861)	loss 7.415 (7.354)	prob 3.807 (3.681)	GS 31.219 (32.554)	mem 71.933
Train: [60][40/1500]	BT 0.039 (0.741)	DT 0.001 (0.702)	loss 7.447 (7.394)	prob 3.477 (3.669)	GS 34.766 (32.498)	mem 71.944
Train: [60][50/1500]	BT 0.038 (0.620)	DT 0.001 (0.581)	loss 7.662 (7.396)	prob 4.309 (3.673)	GS 30.172 (32.293)	mem 71.946
Train: [60][60/1500]	BT 0.036 (0.587)	DT 0.000 (0.549)	loss 7.688 (7.597)	prob 3.617 (3.386)	GS 31.828 (32.078)	mem 71.961
Train: [60][70/1500]	BT 0.035 (0.509)	DT 0.000 (0.471)	loss 7.835 (7.610)	prob 2.960 (3.319)	GS 36.188 (31.977)	mem 71.962
Train: [60][80/1500]	BT 0.053 (0.477)	DT 0.015 (0.437)	loss 7.562 (7.573)	prob 3.411 (3.281)	GS 34.422 (32.280)	mem 71.966
Train: [60][90/1500]	BT 0.027 (0.520)	DT 0.000 (0.482)	loss 7.493 (7.592)	prob 3.873 (3.240)	GS 26.750 (32.789)	mem 71.969
Train: [60][100/1500]	BT 0.028 (0.471)	DT 0.000 (0.434)	loss 7.928 (7.603)	prob 2.998 (3.276)	GS 38.469 (32.867)	mem 71.973
Train: [60][110/1500]	BT 0.028 (0.474)	DT 0.000 (0.437)	loss 7.558 (7.550)	prob 3.686 (3.715)	GS 33.453 (32.117)	mem 71.981
Train: [60][120/1500]	BT 0.035 (0.438)	DT 0.000 (0.401)	loss 7.678 (7.517)	prob 4.194 (3.660)	GS 37.938 (32.359)	mem 71.982
Train: [60][130/1500]	BT 0.037 (0.449)	DT 0.000 (0.411)	loss 7.259 (7.474)	prob 3.696 (3.642)	GS 33.203 (32.646)	mem 71.983
Train: [60][140/1500]	BT 0.038 (0.423)	DT 0.001 (0.385)	loss 7.769 (7.488)	prob 3.463 (3.601)	GS 30.609 (32.998)	mem 71.996
Train: [60][150/1500]	BT 0.029 (0.398)	DT 0.000 (0.361)	loss 8.020 (7.507)	prob 2.893 (3.552)	GS 36.219 (33.210)	mem 71.996
Train: [60][160/1500]	BT 0.036 (0.394)	DT 0.000 (0.356)	loss 7.869 (7.520)	prob 3.529 (3.214)	GS 34.734 (32.508)	mem 72.019
Train: [60][170/1500]	BT 0.059 (0.381)	DT 0.003 (0.343)	loss 7.574 (7.485)	prob 3.931 (3.343)	GS 34.828 (32.407)	mem 71.964
Train: [60][180/1500]	BT 0.072 (0.388)	DT 0.005 (0.350)	loss 7.362 (7.502)	prob 3.091 (3.311)	GS 36.703 (32.518)	mem 71.901
Train: [60][190/1500]	BT 0.065 (0.372)	DT 0.011 (0.332)	loss 7.347 (7.460)	prob 3.696 (3.318)	GS 33.359 (32.522)	mem 71.901
Train: [60][200/1500]	BT 0.057 (0.386)	DT 0.001 (0.346)	loss 7.659 (7.478)	prob 3.686 (3.291)	GS 33.344 (32.730)	mem 71.905
Train: [60][210/1500]	BT 0.060 (0.410)	DT 0.001 (0.369)	loss 7.711 (7.522)	prob 3.342 (3.358)	GS 33.578 (36.014)	mem 71.909
Train: [60][220/1500]	BT 0.033 (0.409)	DT 0.000 (0.367)	loss 7.098 (7.472)	prob 2.943 (3.112)	GS 34.688 (36.315)	mem 71.934
Train: [60][230/1500]	BT 0.035 (0.392)	DT 0.000 (0.352)	loss 7.671 (7.429)	prob 4.309 (3.225)	GS 34.406 (35.286)	mem 71.934
Train: [60][240/1500]	BT 0.038 (0.377)	DT 0.001 (0.337)	loss 7.470 (7.442)	prob 3.492 (3.333)	GS 36.703 (34.641)	mem 71.934
Train: [60][250/1500]	BT 0.031 (0.383)	DT 0.000 (0.342)	loss 7.494 (7.424)	prob 3.813 (3.385)	GS 36.484 (34.184)	mem 71.936
Train: [60][260/1500]	BT 0.041 (0.369)	DT 0.001 (0.329)	loss 7.248 (7.370)	prob 3.194 (3.301)	GS 34.438 (33.930)	mem 71.922
Train: [60][270/1500]	BT 0.038 (0.369)	DT 0.001 (0.329)	loss 7.695 (7.367)	prob 3.747 (3.294)	GS 33.172 (33.341)	mem 71.924
Train: [60][280/1500]	BT 0.038 (0.357)	DT 0.001 (0.317)	loss 7.070 (7.421)	prob 3.117 (3.208)	GS 32.141 (33.266)	mem 71.923
Train: [60][290/1500]	BT 0.039 (0.348)	DT 0.001 (0.308)	loss 7.351 (7.448)	prob 3.760 (3.215)	GS 33.094 (33.205)	mem 71.924
Train: [60][300/1500]	BT 0.029 (0.350)	DT 0.000 (0.311)	loss 7.017 (7.437)	prob 4.016 (3.202)	GS 33.969 (32.952)	mem 71.927
Train: [60][310/1500]	BT 0.058 (0.340)	DT 0.001 (0.301)	loss 7.188 (7.372)	prob 4.103 (3.455)	GS 29.047 (31.156)	mem 71.929
Train: [60][320/1500]	BT 0.035 (0.345)	DT 0.000 (0.305)	loss 6.909 (7.357)	prob 3.606 (3.620)	GS 35.594 (31.222)	mem 71.930
Train: [60][330/1500]	BT 0.034 (0.336)	DT 0.001 (0.296)	loss 7.170 (7.386)	prob 2.617 (3.352)	GS 33.609 (31.787)	mem 71.929
Train: [60][340/1500]	BT 0.066 (0.331)	DT 0.006 (0.291)	loss 7.319 (7.387)	prob 3.126 (3.310)	GS 34.094 (31.749)	mem 71.932
Train: [60][350/1500]	BT 0.039 (0.335)	DT 0.001 (0.296)	loss 7.278 (7.383)	prob 2.922 (3.281)	GS 31.281 (32.193)	mem 71.931
Train: [60][360/1500]	BT 0.039 (0.327)	DT 0.001 (0.287)	loss 7.614 (7.515)	prob 2.927 (2.882)	GS 34.344 (32.612)	mem 71.932
Train: [60][370/1500]	BT 0.039 (0.327)	DT 0.001 (0.287)	loss 7.161 (7.465)	prob 4.354 (3.141)	GS 32.578 (32.425)	mem 71.935
Train: [60][380/1500]	BT 0.045 (0.320)	DT 0.001 (0.281)	loss 7.391 (7.415)	prob 3.485 (3.341)	GS 32.641 (31.785)	mem 71.936
Train: [60][390/1500]	BT 0.039 (0.316)	DT 0.001 (0.277)	loss 7.381 (7.427)	prob 2.984 (3.189)	GS 36.938 (32.269)	mem 71.936
Train: [60][400/1500]	BT 0.076 (0.320)	DT 0.011 (0.281)	loss 8.234 (7.442)	prob 3.161 (3.171)	GS 34.828 (32.323)	mem 71.937
Train: [60][410/1500]	BT 0.031 (0.319)	DT 0.000 (0.280)	loss 7.754 (7.570)	prob 2.547 (2.579)	GS 32.266 (35.097)	mem 71.937
Train: [60][420/1500]	BT 0.084 (0.330)	DT 0.019 (0.290)	loss 7.268 (7.552)	prob 3.702 (2.591)	GS 30.859 (33.487)	mem 71.938
Train: [60][430/1500]	BT 0.035 (0.339)	DT 0.000 (0.299)	loss 7.397 (7.490)	prob 3.070 (2.684)	GS 34.094 (34.297)	mem 71.954
Train: [60][440/1500]	BT 0.426 (0.333)	DT 0.368 (0.294)	loss 7.418 (7.459)	prob 3.433 (2.734)	GS 32.391 (34.075)	mem 71.955
Train: [60][450/1500]	BT 0.029 (0.355)	DT 0.000 (0.316)	loss 7.929 (7.505)	prob 2.422 (2.678)	GS 34.047 (34.001)	mem 71.959
Train: [60][460/1500]	BT 0.028 (0.348)	DT 0.000 (0.309)	loss 7.498 (7.500)	prob 3.629 (2.862)	GS 33.000 (32.878)	mem 71.960
Train: [60][470/1500]	BT 0.038 (0.347)	DT 0.001 (0.308)	loss 7.560 (7.507)	prob 3.481 (2.993)	GS 33.016 (32.897)	mem 71.967
Train: [60][480/1500]	BT 0.071 (0.342)	DT 0.000 (0.302)	loss 7.859 (7.512)	prob 3.255 (2.948)	GS 35.734 (32.899)	mem 71.969
Train: [60][490/1500]	BT 0.085 (0.336)	DT 0.016 (0.296)	loss 8.366 (7.533)	prob 2.923 (2.991)	GS 34.766 (32.514)	mem 71.968
Train: [60][500/1500]	BT 0.030 (0.347)	DT 0.000 (0.307)	loss 7.796 (7.557)	prob 3.578 (2.967)	GS 31.719 (32.667)	mem 71.966
Train: [60][510/1500]	BT 0.037 (0.341)	DT 0.001 (0.301)	loss 7.430 (7.450)	prob 3.499 (3.165)	GS 34.359 (32.308)	mem 71.967
Train: [60][520/1500]	BT 0.037 (0.340)	DT 0.001 (0.301)	loss 7.494 (7.433)	prob 2.643 (3.075)	GS 34.750 (32.573)	mem 71.969
Train: [60][530/1500]	BT 0.037 (0.334)	DT 0.001 (0.295)	loss 8.021 (7.463)	prob 3.021 (3.046)	GS 30.453 (32.230)	mem 71.970
Train: [60][540/1500]	BT 0.065 (0.334)	DT 0.015 (0.295)	loss 8.435 (7.497)	prob 2.628 (2.947)	GS 32.906 (32.355)	mem 71.971
Train: [60][550/1500]	BT 0.074 (0.329)	DT 0.011 (0.290)	loss 7.693 (7.510)	prob 2.522 (2.931)	GS 38.312 (32.586)	mem 71.971
Train: [60][560/1500]	BT 0.038 (0.329)	DT 0.001 (0.289)	loss 7.990 (7.697)	prob 2.436 (2.627)	GS 33.688 (33.736)	mem 71.971
Train: [60][570/1500]	BT 0.037 (0.328)	DT 0.000 (0.288)	loss 7.768 (7.688)	prob 3.299 (2.811)	GS 34.562 (32.892)	mem 71.971
Train: [60][580/1500]	BT 0.038 (0.323)	DT 0.001 (0.283)	loss 7.815 (7.708)	prob 2.914 (2.819)	GS 33.766 (33.094)	mem 71.971
Train: [60][590/1500]	BT 0.037 (0.324)	DT 0.000 (0.284)	loss 7.763 (7.708)	prob 3.913 (2.898)	GS 32.031 (32.668)	mem 71.972
Train: [60][600/1500]	BT 0.037 (0.322)	DT 0.001 (0.282)	loss 7.382 (7.683)	prob 3.627 (2.952)	GS 32.312 (32.559)	mem 71.975
Train: [60][610/1500]	BT 0.038 (0.317)	DT 0.001 (0.278)	loss 8.003 (7.688)	prob 2.134 (3.147)	GS 34.844 (32.797)	mem 71.975
Train: [60][620/1500]	BT 0.038 (0.322)	DT 0.001 (0.283)	loss 7.087 (7.597)	prob 3.336 (3.031)	GS 34.609 (32.541)	mem 71.980
Train: [60][630/1500]	BT 0.038 (0.319)	DT 0.001 (0.279)	loss 7.523 (7.598)	prob 3.389 (2.967)	GS 31.344 (32.938)	mem 71.980
Train: [60][640/1500]	BT 0.038 (0.321)	DT 0.000 (0.281)	loss 7.927 (7.599)	prob 3.755 (3.087)	GS 33.469 (32.656)	mem 71.980
Train: [60][650/1500]	BT 0.241 (0.318)	DT 0.204 (0.278)	loss 7.340 (7.593)	prob 3.638 (3.064)	GS 36.234 (32.780)	mem 71.981
Train: [60][660/1500]	BT 0.037 (0.317)	DT 0.000 (0.277)	loss 7.486 (7.628)	prob 3.697 (3.279)	GS 29.688 (32.352)	mem 71.982
Train: [60][670/1500]	BT 0.052 (0.316)	DT 0.001 (0.276)	loss 7.537 (7.531)	prob 2.922 (3.408)	GS 32.734 (33.077)	mem 71.985
Train: [60][680/1500]	BT 0.290 (0.316)	DT 0.241 (0.276)	loss 7.634 (7.483)	prob 2.843 (3.389)	GS 35.031 (32.812)	mem 72.182
Train: [60][690/1500]	BT 0.037 (0.319)	DT 0.000 (0.279)	loss 7.926 (7.519)	prob 3.323 (3.314)	GS 33.172 (32.671)	mem 72.524
Train: [60][700/1500]	BT 0.025 (0.323)	DT 0.000 (0.283)	loss 7.633 (7.525)	prob 3.596 (3.292)	GS 29.234 (32.620)	mem 72.915
Train: [60][710/1500]	BT 0.034 (0.319)	DT 0.000 (0.279)	loss 7.304 (7.574)	prob 4.366 (3.667)	GS 31.125 (30.652)	mem 73.015
Train: [60][720/1500]	BT 0.065 (0.321)	DT 0.012 (0.281)	loss 7.298 (7.536)	prob 3.494 (3.725)	GS 32.938 (31.389)	mem 73.115
Train: [60][730/1500]	BT 0.058 (0.317)	DT 0.014 (0.277)	loss 8.135 (7.550)	prob 3.632 (3.576)	GS 33.297 (31.803)	mem 73.163
Train: [60][740/1500]	BT 0.064 (0.314)	DT 0.005 (0.274)	loss 7.852 (7.553)	prob 3.669 (3.579)	GS 30.562 (31.777)	mem 73.163
Train: [60][750/1500]	BT 0.038 (0.316)	DT 0.001 (0.276)	loss 7.886 (7.562)	prob 2.908 (3.515)	GS 37.266 (32.361)	mem 73.165
Train: [60][760/1500]	BT 0.037 (0.313)	DT 0.001 (0.273)	loss 8.156 (7.514)	prob 3.548 (3.311)	GS 31.703 (31.542)	mem 73.168
Train: [60][770/1500]	BT 0.039 (0.313)	DT 0.001 (0.273)	loss 7.632 (7.524)	prob 3.658 (3.393)	GS 31.234 (32.231)	mem 73.193
Train: [60][780/1500]	BT 0.034 (0.312)	DT 0.000 (0.272)	loss 7.762 (7.568)	prob 3.442 (3.374)	GS 37.562 (32.473)	mem 73.368
Train: [60][790/1500]	BT 0.031 (0.309)	DT 0.000 (0.269)	loss 7.332 (7.546)	prob 4.508 (3.443)	GS 36.234 (32.463)	mem 73.424
Train: [60][800/1500]	BT 0.034 (0.311)	DT 0.001 (0.271)	loss 7.708 (7.549)	prob 3.536 (3.491)	GS 35.516 (32.465)	mem 73.608
Train: [60][810/1500]	BT 0.035 (0.318)	DT 0.001 (0.278)	loss 8.232 (7.476)	prob 3.432 (3.547)	GS 36.797 (32.816)	mem 74.584
Train: [60][820/1500]	BT 0.040 (0.315)	DT 0.001 (0.275)	loss 7.576 (7.582)	prob 3.964 (3.360)	GS 31.766 (32.961)	mem 74.782
Train: [60][830/1500]	BT 0.052 (0.323)	DT 0.001 (0.283)	loss 7.774 (7.581)	prob 4.008 (3.409)	GS 34.219 (33.217)	mem 75.089
Train: [60][840/1500]	BT 0.097 (0.320)	DT 0.002 (0.280)	loss 7.397 (7.570)	prob 3.629 (3.462)	GS 34.312 (33.418)	mem 75.106
Train: [60][850/1500]	BT 0.038 (0.319)	DT 0.001 (0.279)	loss 7.521 (7.564)	prob 3.451 (3.465)	GS 34.406 (33.700)	mem 74.689
Train: [60][860/1500]	BT 0.027 (0.319)	DT 0.000 (0.279)	loss 8.171 (7.537)	prob 3.877 (3.655)	GS 32.781 (33.525)	mem 74.688
Train: [60][870/1500]	BT 0.036 (0.316)	DT 0.001 (0.276)	loss 7.777 (7.459)	prob 3.831 (3.845)	GS 33.734 (33.191)	mem 74.689
Train: [60][880/1500]	BT 0.038 (0.317)	DT 0.001 (0.277)	loss 8.631 (7.479)	prob 2.335 (3.812)	GS 34.688 (33.119)	mem 74.702
Train: [60][890/1500]	BT 0.040 (0.314)	DT 0.001 (0.274)	loss 7.979 (7.490)	prob 3.740 (3.801)	GS 33.906 (33.125)	mem 74.702
Train: [60][900/1500]	BT 0.029 (0.316)	DT 0.000 (0.276)	loss 7.866 (7.480)	prob 3.678 (3.828)	GS 35.031 (32.989)	mem 74.703
Train: [60][910/1500]	BT 0.039 (0.312)	DT 0.001 (0.273)	loss 7.436 (7.338)	prob 3.716 (3.878)	GS 31.469 (32.402)	mem 74.704
Train: [60][920/1500]	BT 0.039 (0.309)	DT 0.001 (0.270)	loss 7.912 (7.333)	prob 3.926 (3.785)	GS 31.359 (33.051)	mem 74.705
Train: [60][930/1500]	BT 0.039 (0.310)	DT 0.001 (0.270)	loss 7.449 (7.344)	prob 4.718 (3.942)	GS 37.906 (32.896)	mem 74.705
Train: [60][940/1500]	BT 0.033 (0.307)	DT 0.000 (0.267)	loss 7.760 (7.357)	prob 5.296 (4.022)	GS 31.828 (32.577)	mem 74.705
Train: [60][950/1500]	BT 0.039 (0.308)	DT 0.001 (0.268)	loss 7.326 (7.371)	prob 3.819 (4.058)	GS 30.781 (32.375)	mem 74.666
Train: [60][960/1500]	BT 0.029 (0.305)	DT 0.001 (0.265)	loss 7.542 (7.523)	prob 3.696 (3.496)	GS 29.391 (33.036)	mem 74.667
Train: [60][970/1500]	BT 0.047 (0.302)	DT 0.002 (0.262)	loss 7.318 (7.506)	prob 3.476 (3.529)	GS 31.797 (32.983)	mem 74.666
Train: [60][980/1500]	BT 0.035 (0.307)	DT 0.001 (0.267)	loss 7.587 (7.449)	prob 4.118 (3.601)	GS 34.422 (33.263)	mem 74.586
Train: [60][990/1500]	BT 0.041 (0.304)	DT 0.001 (0.265)	loss 7.361 (7.453)	prob 4.080 (3.701)	GS 33.375 (33.182)	mem 74.566
Train: [60][1000/1500]	BT 0.046 (0.308)	DT 0.002 (0.268)	loss 7.375 (7.460)	prob 3.824 (3.669)	GS 33.766 (32.943)	mem 74.553
Train: [60][1010/1500]	BT 0.132 (0.306)	DT 0.031 (0.266)	loss 7.447 (7.377)	prob 4.218 (3.782)	GS 37.812 (32.712)	mem 74.553
Train: [60][1020/1500]	BT 0.081 (0.308)	DT 0.006 (0.268)	loss 7.462 (7.428)	prob 4.019 (3.582)	GS 36.109 (32.443)	mem 74.550
Train: [60][1030/1500]	BT 0.033 (0.306)	DT 0.000 (0.266)	loss 7.392 (7.422)	prob 3.573 (3.516)	GS 32.344 (32.272)	mem 74.550
Train: [60][1040/1500]	BT 0.063 (0.306)	DT 0.016 (0.266)	loss 7.471 (7.431)	prob 3.595 (3.453)	GS 32.219 (32.347)	mem 74.554
Train: [60][1050/1500]	BT 0.052 (0.310)	DT 0.014 (0.270)	loss 7.431 (7.437)	prob 3.583 (3.426)	GS 32.234 (32.437)	mem 74.557
Train: [60][1060/1500]	BT 0.058 (0.307)	DT 0.011 (0.267)	loss 8.000 (7.525)	prob 2.691 (3.268)	GS 31.172 (33.019)	mem 74.557
Train: [60][1070/1500]	BT 0.052 (0.310)	DT 0.001 (0.270)	loss 7.701 (7.445)	prob 3.506 (3.319)	GS 34.469 (32.690)	mem 74.452
Train: [60][1080/1500]	BT 0.035 (0.314)	DT 0.000 (0.274)	loss 7.536 (7.452)	prob 3.589 (3.356)	GS 34.922 (32.892)	mem 74.450
Train: [60][1090/1500]	BT 0.040 (0.313)	DT 0.001 (0.273)	loss 7.333 (7.457)	prob 3.757 (3.313)	GS 36.812 (32.852)	mem 74.450
Train: [60][1100/1500]	BT 0.031 (0.313)	DT 0.001 (0.273)	loss 7.158 (7.448)	prob 4.284 (3.306)	GS 32.031 (32.624)	mem 74.452
Train: [60][1110/1500]	BT 0.031 (0.310)	DT 0.000 (0.270)	loss 7.272 (7.513)	prob 3.349 (3.466)	GS 36.016 (32.556)	mem 74.452
Train: [60][1120/1500]	BT 0.029 (0.313)	DT 0.001 (0.273)	loss 7.586 (7.505)	prob 3.548 (3.396)	GS 34.875 (32.882)	mem 74.451
Train: [60][1130/1500]	BT 0.030 (0.310)	DT 0.000 (0.270)	loss 7.453 (7.423)	prob 3.503 (3.418)	GS 35.562 (33.041)	mem 74.451
Train: [60][1140/1500]	BT 0.040 (0.309)	DT 0.001 (0.269)	loss 7.599 (7.449)	prob 2.601 (3.222)	GS 39.359 (33.491)	mem 74.452
Train: [60][1150/1500]	BT 0.037 (0.309)	DT 0.001 (0.269)	loss 7.371 (7.410)	prob 3.354 (3.229)	GS 31.031 (32.947)	mem 74.451
Train: [60][1160/1500]	BT 0.039 (0.307)	DT 0.001 (0.268)	loss 7.484 (7.404)	prob 2.729 (2.952)	GS 32.578 (32.289)	mem 74.453
Train: [60][1170/1500]	BT 0.050 (0.309)	DT 0.009 (0.269)	loss 7.810 (7.470)	prob 2.806 (2.885)	GS 33.344 (32.758)	mem 74.454
Train: [60][1180/1500]	BT 0.030 (0.315)	DT 0.000 (0.275)	loss 7.477 (7.522)	prob 3.681 (2.988)	GS 34.188 (33.027)	mem 74.454
Train: [60][1190/1500]	BT 0.029 (0.312)	DT 0.001 (0.273)	loss 7.300 (7.541)	prob 2.899 (2.853)	GS 32.438 (33.121)	mem 74.452
Train: [60][1200/1500]	BT 0.031 (0.313)	DT 0.001 (0.273)	loss 7.736 (7.524)	prob 3.124 (2.885)	GS 35.312 (33.182)	mem 74.452
Train: [60][1210/1500]	BT 0.037 (0.311)	DT 0.001 (0.271)	loss 7.276 (7.544)	prob 3.328 (2.761)	GS 31.859 (32.617)	mem 74.452
Train: [60][1220/1500]	BT 0.038 (0.309)	DT 0.001 (0.269)	loss 7.855 (7.469)	prob 2.695 (2.684)	GS 37.891 (33.121)	mem 74.454
Train: [60][1230/1500]	BT 0.031 (0.311)	DT 0.000 (0.271)	loss 7.364 (7.516)	prob 3.170 (2.663)	GS 36.625 (32.939)	mem 74.451
Train: [60][1240/1500]	BT 0.037 (0.309)	DT 0.001 (0.269)	loss 7.670 (7.531)	prob 1.878 (2.713)	GS 35.875 (33.128)	mem 74.455
Train: [60][1250/1500]	BT 0.032 (0.310)	DT 0.000 (0.271)	loss 7.420 (7.548)	prob 2.752 (2.673)	GS 34.750 (33.267)	mem 74.455
Train: [60][1260/1500]	BT 0.028 (0.309)	DT 0.000 (0.270)	loss 8.229 (7.659)	prob 2.286 (2.403)	GS 34.328 (32.752)	mem 74.460
Train: [60][1270/1500]	BT 0.037 (0.307)	DT 0.001 (0.268)	loss 7.916 (7.646)	prob 3.867 (2.673)	GS 34.469 (32.603)	mem 74.464
Train: [60][1280/1500]	BT 0.037 (0.308)	DT 0.000 (0.268)	loss 7.833 (7.617)	prob 3.125 (2.746)	GS 35.656 (32.438)	mem 74.474
Train: [60][1290/1500]	BT 0.038 (0.306)	DT 0.001 (0.267)	loss 8.145 (7.614)	prob 2.224 (2.773)	GS 35.500 (32.322)	mem 74.468
Train: [60][1300/1500]	BT 0.037 (0.306)	DT 0.001 (0.267)	loss 7.558 (7.603)	prob 2.798 (2.707)	GS 35.844 (32.422)	mem 74.372
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [60][1310/1500]	BT 0.037 (0.305)	DT 0.001 (0.266)	loss 7.408 (7.593)	prob 3.842 (2.865)	GS 32.406 (32.038)	mem 74.371
Train: [60][1320/1500]	BT 0.037 (0.305)	DT 0.000 (0.265)	loss 8.143 (7.671)	prob 2.393 (2.703)	GS 33.516 (32.396)	mem 74.373
Train: [60][1330/1500]	BT 0.037 (0.304)	DT 0.001 (0.264)	loss 7.867 (7.664)	prob 2.292 (2.751)	GS 36.484 (32.803)	mem 74.375
Train: [60][1340/1500]	BT 0.040 (0.303)	DT 0.001 (0.263)	loss 7.271 (7.664)	prob 3.611 (2.674)	GS 32.109 (32.570)	mem 74.375
Train: [60][1350/1500]	BT 0.037 (0.302)	DT 0.001 (0.262)	loss 7.457 (7.647)	prob 2.563 (2.701)	GS 34.234 (32.682)	mem 74.375
Train: [60][1360/1500]	BT 0.031 (0.303)	DT 0.000 (0.264)	loss 7.466 (7.699)	prob 3.684 (2.524)	GS 34.469 (33.689)	mem 74.378
Train: [60][1370/1500]	BT 0.058 (0.302)	DT 0.011 (0.262)	loss 8.090 (7.647)	prob 3.030 (2.665)	GS 35.297 (33.521)	mem 74.377
Train: [60][1380/1500]	BT 0.029 (0.307)	DT 0.000 (0.268)	loss 7.415 (7.626)	prob 2.859 (2.756)	GS 34.922 (33.277)	mem 74.393
Train: [60][1390/1500]	BT 0.024 (0.305)	DT 0.000 (0.266)	loss 7.931 (7.603)	prob 2.981 (2.819)	GS 36.312 (32.959)	mem 74.394
Train: [60][1400/1500]	BT 0.062 (0.306)	DT 0.014 (0.267)	loss 7.679 (7.623)	prob 3.731 (2.798)	GS 36.828 (32.972)	mem 74.383
Train: [60][1410/1500]	BT 0.031 (0.304)	DT 0.001 (0.265)	loss 7.164 (7.548)	prob 3.711 (2.978)	GS 29.344 (31.642)	mem 74.382
Train: [60][1420/1500]	BT 0.031 (0.302)	DT 0.000 (0.263)	loss 7.174 (7.628)	prob 3.365 (3.014)	GS 35.750 (31.962)	mem 74.382
Train: [60][1430/1500]	BT 0.061 (0.304)	DT 0.011 (0.265)	loss 7.810 (7.683)	prob 2.816 (2.985)	GS 33.672 (32.118)	mem 74.382
Train: [60][1440/1500]	BT 0.051 (0.302)	DT 0.001 (0.263)	loss 7.839 (7.688)	prob 3.769 (2.984)	GS 33.281 (32.311)	mem 74.382
Train: [60][1450/1500]	BT 0.032 (0.306)	DT 0.001 (0.266)	loss 7.400 (7.678)	prob 3.482 (2.985)	GS 28.250 (32.084)	mem 74.240
Train: [60][1460/1500]	BT 0.030 (0.304)	DT 0.000 (0.264)	loss 8.411 (7.764)	prob 2.783 (2.858)	GS 34.000 (32.167)	mem 74.241
Train: [60][1470/1500]	BT 0.058 (0.304)	DT 0.014 (0.265)	loss 8.275 (7.762)	prob 2.746 (2.989)	GS 32.922 (32.459)	mem 61.274
Train: [60][1480/1500]	BT 0.038 (0.302)	DT 0.001 (0.263)	loss 7.535 (7.730)	prob 3.204 (2.955)	GS 33.906 (32.509)	mem 58.143
Train: [60][1490/1500]	BT 0.027 (0.301)	DT 0.000 (0.262)	loss 7.441 (7.750)	prob 3.751 (2.943)	GS 38.094 (32.616)	mem 17.623
Train: [60][1500/1500]	BT 0.046 (0.299)	DT 0.001 (0.260)	loss 8.071 (7.741)	prob 3.207 (2.963)	GS 32.312 (32.855)	mem 10.956
Train: [60][1510/1500]	BT 0.026 (0.298)	DT 0.000 (0.259)	loss 7.846 (7.909)	prob 2.682 (2.852)	GS 36.625 (33.559)	mem 9.187
epoch 60, total time 449.61
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [61][1/1500]	BT 22.433 (22.433)	DT 22.390 (22.390)	loss 7.540 (7.540)	prob 2.701 (2.701)	GS 33.562 (33.562)	mem 73.049
Train: [61][10/1500]	BT 0.033 (2.268)	DT 0.000 (2.240)	loss 7.479 (7.437)	prob 4.099 (3.158)	GS 33.375 (32.911)	mem 73.053
Train: [61][20/1500]	BT 0.038 (1.153)	DT 0.001 (1.120)	loss 7.799 (7.439)	prob 3.698 (3.078)	GS 38.125 (32.891)	mem 73.055
Train: [61][30/1500]	BT 0.032 (1.058)	DT 0.000 (1.023)	loss 7.499 (7.448)	prob 3.196 (3.184)	GS 31.797 (32.916)	mem 73.119
Train: [61][40/1500]	BT 0.037 (0.801)	DT 0.000 (0.767)	loss 8.241 (7.511)	prob 3.833 (3.281)	GS 39.047 (32.595)	mem 73.131
Train: [61][50/1500]	BT 0.034 (0.738)	DT 0.000 (0.704)	loss 7.388 (7.529)	prob 3.411 (3.239)	GS 33.344 (32.567)	mem 73.157
Train: [61][60/1500]	BT 0.036 (0.620)	DT 0.000 (0.586)	loss 8.337 (7.835)	prob 3.175 (3.094)	GS 33.641 (32.722)	mem 73.159
Train: [61][70/1500]	BT 0.037 (0.536)	DT 0.000 (0.503)	loss 7.847 (7.665)	prob 3.964 (3.453)	GS 34.484 (32.288)	mem 73.159
Train: [61][80/1500]	BT 0.028 (0.519)	DT 0.000 (0.486)	loss 7.604 (7.669)	prob 4.221 (3.422)	GS 32.500 (32.355)	mem 73.805
Train: [61][90/1500]	BT 0.048 (0.467)	DT 0.001 (0.434)	loss 7.349 (7.638)	prob 3.542 (3.431)	GS 36.375 (32.677)	mem 73.904
Train: [61][100/1500]	BT 0.039 (0.456)	DT 0.000 (0.422)	loss 7.897 (7.669)	prob 3.302 (3.435)	GS 39.578 (32.447)	mem 74.361
Train: [61][110/1500]	BT 0.037 (0.418)	DT 0.001 (0.384)	loss 7.852 (7.586)	prob 3.838 (3.357)	GS 32.328 (32.597)	mem 74.362
Train: [61][120/1500]	BT 0.038 (0.405)	DT 0.001 (0.371)	loss 7.363 (7.534)	prob 3.735 (3.377)	GS 35.500 (32.148)	mem 74.365
Train: [61][130/1500]	BT 0.034 (0.388)	DT 0.000 (0.354)	loss 7.664 (7.550)	prob 3.379 (3.429)	GS 38.547 (32.661)	mem 74.369
Train: [61][140/1500]	BT 0.033 (0.363)	DT 0.000 (0.329)	loss 8.018 (7.567)	prob 3.627 (3.344)	GS 32.547 (32.996)	mem 74.370
Train: [61][150/1500]	BT 0.028 (0.379)	DT 0.000 (0.345)	loss 7.980 (7.569)	prob 3.637 (3.418)	GS 35.906 (32.993)	mem 74.376
Train: [61][160/1500]	BT 0.037 (0.358)	DT 0.000 (0.324)	loss 7.595 (7.571)	prob 3.493 (3.677)	GS 35.562 (32.805)	mem 74.378
Train: [61][170/1500]	BT 0.036 (0.368)	DT 0.000 (0.334)	loss 7.750 (7.559)	prob 3.445 (3.457)	GS 30.531 (32.352)	mem 74.384
Train: [61][180/1500]	BT 0.027 (0.353)	DT 0.000 (0.319)	loss 7.355 (7.540)	prob 3.528 (3.459)	GS 37.094 (33.322)	mem 74.383
Train: [61][190/1500]	BT 0.037 (0.347)	DT 0.000 (0.312)	loss 7.509 (7.540)	prob 3.431 (3.460)	GS 33.016 (33.181)	mem 74.385
Train: [61][200/1500]	BT 0.059 (0.334)	DT 0.001 (0.299)	loss 7.415 (7.526)	prob 3.621 (3.476)	GS 31.859 (32.981)	mem 74.385
Train: [61][210/1500]	BT 0.035 (0.330)	DT 0.001 (0.295)	loss 7.424 (7.383)	prob 3.780 (3.500)	GS 34.469 (33.852)	mem 74.390
Train: [61][220/1500]	BT 0.033 (0.358)	DT 0.001 (0.323)	loss 7.070 (7.380)	prob 3.850 (3.567)	GS 36.516 (34.159)	mem 74.396
Train: [61][230/1500]	BT 0.030 (0.344)	DT 0.000 (0.309)	loss 7.906 (7.430)	prob 3.415 (3.353)	GS 34.719 (33.935)	mem 74.396
Train: [61][240/1500]	BT 0.037 (0.339)	DT 0.001 (0.304)	loss 7.436 (7.461)	prob 4.085 (3.389)	GS 33.438 (34.088)	mem 74.397
Train: [61][250/1500]	BT 0.037 (0.335)	DT 0.000 (0.300)	loss 7.637 (7.467)	prob 4.367 (3.452)	GS 33.828 (33.891)	mem 74.399
Train: [61][260/1500]	BT 0.024 (0.338)	DT 0.000 (0.303)	loss 7.869 (7.540)	prob 3.042 (3.502)	GS 36.391 (34.848)	mem 74.401
Train: [61][270/1500]	BT 0.033 (0.327)	DT 0.000 (0.292)	loss 7.617 (7.556)	prob 3.737 (3.471)	GS 32.031 (33.309)	mem 74.401
Train: [61][280/1500]	BT 0.037 (0.317)	DT 0.001 (0.282)	loss 7.218 (7.485)	prob 3.397 (3.536)	GS 35.422 (32.789)	mem 74.402
Train: [61][290/1500]	BT 0.038 (0.320)	DT 0.000 (0.286)	loss 7.646 (7.456)	prob 3.920 (3.532)	GS 35.469 (32.131)	mem 74.362
Train: [61][300/1500]	BT 0.038 (0.311)	DT 0.001 (0.276)	loss 7.361 (7.448)	prob 3.409 (3.558)	GS 29.938 (31.986)	mem 74.363
Train: [61][310/1500]	BT 0.033 (0.315)	DT 0.001 (0.280)	loss 7.831 (7.366)	prob 3.686 (3.584)	GS 32.531 (32.292)	mem 74.365
Train: [61][320/1500]	BT 0.033 (0.315)	DT 0.000 (0.280)	loss 7.087 (7.355)	prob 3.785 (3.547)	GS 33.703 (31.988)	mem 74.368
Train: [61][330/1500]	BT 0.095 (0.326)	DT 0.001 (0.290)	loss 6.932 (7.333)	prob 4.039 (3.551)	GS 32.516 (31.907)	mem 74.370
Train: [61][340/1500]	BT 0.096 (0.335)	DT 0.004 (0.298)	loss 7.658 (7.349)	prob 3.908 (3.555)	GS 34.594 (31.928)	mem 74.369
Train: [61][350/1500]	BT 22.055 (0.390)	DT 22.000 (0.352)	loss 7.716 (7.360)	prob 3.812 (3.530)	GS 42.844 (32.253)	mem 74.403
Train: [61][360/1500]	BT 0.029 (0.380)	DT 0.000 (0.343)	loss 7.536 (7.372)	prob 3.243 (3.327)	GS 31.438 (33.669)	mem 74.405
Train: [61][370/1500]	BT 0.037 (0.371)	DT 0.000 (0.333)	loss 7.562 (7.322)	prob 4.031 (3.361)	GS 34.312 (33.177)	mem 74.406
Train: [61][380/1500]	BT 0.029 (0.369)	DT 0.000 (0.332)	loss 7.554 (7.288)	prob 3.650 (3.479)	GS 32.125 (33.417)	mem 74.409
Train: [61][390/1500]	BT 0.032 (0.361)	DT 0.001 (0.323)	loss 7.121 (7.267)	prob 2.979 (3.467)	GS 40.188 (33.595)	mem 74.410
Train: [61][400/1500]	BT 0.051 (0.364)	DT 0.001 (0.327)	loss 6.909 (7.284)	prob 3.844 (3.439)	GS 29.219 (33.437)	mem 74.409
Train: [61][410/1500]	BT 0.054 (0.358)	DT 0.005 (0.320)	loss 7.510 (7.269)	prob 3.854 (3.677)	GS 29.328 (32.462)	mem 74.412
Train: [61][420/1500]	BT 0.060 (0.351)	DT 0.001 (0.313)	loss 7.292 (7.228)	prob 3.507 (3.561)	GS 31.188 (31.909)	mem 74.412
Train: [61][430/1500]	BT 0.029 (0.378)	DT 0.000 (0.340)	loss 7.275 (7.228)	prob 3.818 (3.586)	GS 32.969 (31.988)	mem 74.411
Train: [61][440/1500]	BT 0.037 (0.370)	DT 0.001 (0.332)	loss 7.117 (7.227)	prob 4.043 (3.573)	GS 34.328 (32.128)	mem 74.412
Train: [61][450/1500]	BT 0.060 (0.363)	DT 0.021 (0.325)	loss 7.405 (7.236)	prob 4.011 (3.485)	GS 35.453 (32.298)	mem 74.411
Train: [61][460/1500]	BT 0.029 (0.362)	DT 0.000 (0.324)	loss 7.682 (7.243)	prob 3.493 (3.369)	GS 33.562 (34.078)	mem 74.412
Train: [61][470/1500]	BT 0.780 (0.356)	DT 0.742 (0.318)	loss 7.111 (7.160)	prob 3.880 (3.530)	GS 29.188 (32.882)	mem 74.414
Train: [61][480/1500]	BT 0.039 (0.354)	DT 0.001 (0.316)	loss 7.214 (7.211)	prob 3.755 (3.526)	GS 33.344 (32.520)	mem 74.415
Train: [61][490/1500]	BT 0.040 (0.347)	DT 0.001 (0.309)	loss 7.119 (7.208)	prob 3.212 (3.445)	GS 35.984 (32.548)	mem 74.415
Train: [61][500/1500]	BT 0.039 (0.351)	DT 0.001 (0.313)	loss 7.324 (7.246)	prob 3.181 (3.341)	GS 32.812 (32.480)	mem 74.415
Train: [61][510/1500]	BT 0.038 (0.345)	DT 0.001 (0.307)	loss 7.103 (7.265)	prob 3.087 (3.297)	GS 31.469 (32.353)	mem 74.416
Train: [61][520/1500]	BT 0.039 (0.339)	DT 0.001 (0.301)	loss 7.106 (7.292)	prob 3.520 (3.328)	GS 29.172 (31.477)	mem 74.415
Train: [61][530/1500]	BT 0.027 (0.342)	DT 0.001 (0.304)	loss 7.080 (7.290)	prob 3.236 (3.266)	GS 30.312 (31.489)	mem 74.417
Train: [61][540/1500]	BT 0.040 (0.336)	DT 0.001 (0.298)	loss 7.294 (7.271)	prob 2.466 (3.199)	GS 33.969 (31.578)	mem 74.417
Train: [61][550/1500]	BT 0.031 (0.340)	DT 0.000 (0.302)	loss 7.139 (7.268)	prob 2.945 (3.126)	GS 32.969 (31.938)	mem 74.418
Train: [61][560/1500]	BT 0.048 (0.335)	DT 0.002 (0.297)	loss 7.441 (7.408)	prob 3.874 (2.721)	GS 35.859 (32.625)	mem 74.418
Train: [61][570/1500]	BT 0.039 (0.332)	DT 0.001 (0.294)	loss 7.409 (7.313)	prob 2.752 (2.829)	GS 33.500 (32.934)	mem 74.419
Train: [61][580/1500]	BT 0.029 (0.336)	DT 0.000 (0.298)	loss 7.328 (7.340)	prob 2.612 (2.765)	GS 36.297 (33.160)	mem 74.416
Train: [61][590/1500]	BT 0.025 (0.330)	DT 0.000 (0.293)	loss 7.262 (7.339)	prob 3.215 (2.708)	GS 39.344 (33.038)	mem 74.417
Train: [61][600/1500]	BT 0.028 (0.334)	DT 0.000 (0.296)	loss 7.853 (7.384)	prob 2.981 (2.700)	GS 32.672 (32.996)	mem 74.419
Train: [61][610/1500]	BT 0.027 (0.329)	DT 0.000 (0.291)	loss 7.325 (7.449)	prob 3.734 (2.863)	GS 30.156 (33.333)	mem 74.421
Train: [61][620/1500]	BT 0.037 (0.331)	DT 0.000 (0.294)	loss 7.488 (7.481)	prob 2.945 (2.721)	GS 36.547 (32.833)	mem 74.440
Train: [61][630/1500]	BT 0.025 (0.326)	DT 0.000 (0.289)	loss 7.354 (7.465)	prob 2.580 (2.717)	GS 40.156 (32.848)	mem 74.440
Train: [61][640/1500]	BT 0.036 (0.322)	DT 0.001 (0.285)	loss 7.297 (7.477)	prob 3.946 (2.769)	GS 34.203 (32.916)	mem 74.440
Train: [61][650/1500]	BT 0.037 (0.323)	DT 0.000 (0.286)	loss 8.373 (7.472)	prob 1.923 (2.859)	GS 39.344 (32.788)	mem 74.460
Train: [61][660/1500]	BT 0.038 (0.319)	DT 0.001 (0.282)	loss 7.925 (7.627)	prob 3.417 (2.734)	GS 34.109 (32.464)	mem 74.329
Train: [61][670/1500]	BT 0.031 (0.323)	DT 0.000 (0.286)	loss 7.704 (7.564)	prob 2.369 (2.892)	GS 31.938 (31.776)	mem 74.338
Train: [61][680/1500]	BT 0.060 (0.319)	DT 0.014 (0.282)	loss 7.538 (7.546)	prob 3.182 (2.888)	GS 37.125 (31.756)	mem 74.338
Train: [61][690/1500]	BT 0.063 (0.315)	DT 0.007 (0.278)	loss 8.246 (7.543)	prob 2.658 (2.883)	GS 34.625 (31.799)	mem 74.337
Train: [61][700/1500]	BT 0.081 (0.321)	DT 0.013 (0.284)	loss 7.421 (7.511)	prob 2.830 (2.863)	GS 32.969 (31.684)	mem 74.340
Train: [61][710/1500]	BT 0.026 (0.331)	DT 0.000 (0.294)	loss 7.577 (7.504)	prob 2.874 (3.208)	GS 32.281 (31.516)	mem 74.340
Train: [61][720/1500]	BT 0.031 (0.327)	DT 0.000 (0.290)	loss 7.795 (7.556)	prob 2.942 (3.115)	GS 38.797 (31.677)	mem 74.342
Train: [61][730/1500]	BT 0.033 (0.323)	DT 0.000 (0.286)	loss 7.458 (7.514)	prob 3.129 (3.063)	GS 32.062 (31.868)	mem 74.342
Train: [61][740/1500]	BT 0.028 (0.324)	DT 0.000 (0.287)	loss 7.294 (7.516)	prob 3.131 (3.022)	GS 33.547 (32.490)	mem 74.362
Train: [61][750/1500]	BT 0.038 (0.320)	DT 0.001 (0.283)	loss 7.790 (7.535)	prob 3.371 (3.067)	GS 30.234 (32.407)	mem 74.363
Train: [61][760/1500]	BT 0.029 (0.321)	DT 0.000 (0.284)	loss 7.586 (7.562)	prob 2.844 (2.805)	GS 31.797 (32.567)	mem 74.348
Train: [61][770/1500]	BT 0.032 (0.318)	DT 0.000 (0.281)	loss 7.289 (7.526)	prob 4.410 (3.043)	GS 33.250 (32.503)	mem 74.349
Train: [61][780/1500]	BT 0.065 (0.321)	DT 0.002 (0.285)	loss 7.944 (7.579)	prob 2.869 (3.120)	GS 33.625 (32.442)	mem 74.348
Train: [61][790/1500]	BT 0.028 (0.325)	DT 0.000 (0.288)	loss 8.383 (7.592)	prob 3.337 (3.130)	GS 32.500 (32.448)	mem 74.348
Train: [61][800/1500]	BT 0.039 (0.322)	DT 0.001 (0.285)	loss 7.846 (7.590)	prob 3.459 (3.171)	GS 32.531 (32.382)	mem 74.348
Train: [61][810/1500]	BT 0.048 (0.323)	DT 0.000 (0.286)	loss 7.967 (7.678)	prob 4.063 (3.515)	GS 35.547 (32.013)	mem 74.351
Train: [61][820/1500]	BT 0.031 (0.319)	DT 0.000 (0.282)	loss 7.880 (7.656)	prob 4.027 (3.478)	GS 31.656 (32.910)	mem 74.350
Train: [61][830/1500]	BT 0.058 (0.319)	DT 0.011 (0.282)	loss 8.263 (7.675)	prob 3.293 (3.597)	GS 37.594 (32.877)	mem 74.348
Train: [61][840/1500]	BT 0.067 (0.323)	DT 0.002 (0.285)	loss 8.143 (7.663)	prob 3.444 (3.534)	GS 40.375 (32.895)	mem 74.347
Train: [61][850/1500]	BT 0.032 (0.325)	DT 0.000 (0.288)	loss 7.811 (7.626)	prob 4.233 (3.555)	GS 38.250 (33.142)	mem 74.347
Train: [61][860/1500]	BT 0.029 (0.322)	DT 0.001 (0.285)	loss 8.046 (7.634)	prob 2.670 (3.589)	GS 36.234 (32.895)	mem 74.350
Train: [61][870/1500]	BT 0.029 (0.319)	DT 0.000 (0.281)	loss 7.688 (7.614)	prob 4.082 (3.624)	GS 34.781 (32.828)	mem 74.350
Train: [61][880/1500]	BT 0.047 (0.319)	DT 0.000 (0.282)	loss 7.299 (7.578)	prob 4.027 (3.655)	GS 35.047 (32.827)	mem 74.353
Train: [61][890/1500]	BT 0.086 (0.321)	DT 0.016 (0.283)	loss 7.894 (7.602)	prob 3.397 (3.630)	GS 31.969 (32.860)	mem 74.354
Train: [61][900/1500]	BT 0.041 (0.318)	DT 0.000 (0.281)	loss 7.849 (7.570)	prob 3.667 (3.664)	GS 35.406 (32.945)	mem 74.354
Train: [61][910/1500]	BT 0.038 (0.320)	DT 0.001 (0.282)	loss 7.495 (7.688)	prob 3.900 (3.614)	GS 35.781 (33.848)	mem 74.357
Train: [61][920/1500]	BT 0.038 (0.320)	DT 0.001 (0.283)	loss 7.341 (7.608)	prob 4.136 (3.555)	GS 35.203 (33.180)	mem 74.356
Train: [61][930/1500]	BT 0.038 (0.317)	DT 0.001 (0.280)	loss 7.282 (7.620)	prob 4.746 (3.670)	GS 35.062 (32.882)	mem 74.358
Train: [61][940/1500]	BT 0.063 (0.315)	DT 0.013 (0.278)	loss 7.480 (7.602)	prob 3.961 (3.664)	GS 33.484 (33.004)	mem 74.357
Train: [61][950/1500]	BT 0.026 (0.319)	DT 0.000 (0.281)	loss 7.561 (7.597)	prob 3.325 (3.625)	GS 36.906 (32.889)	mem 74.379
Train: [61][960/1500]	BT 0.027 (0.316)	DT 0.000 (0.278)	loss 7.370 (7.557)	prob 3.429 (4.157)	GS 31.969 (31.081)	mem 74.380
Train: [61][970/1500]	BT 0.035 (0.318)	DT 0.001 (0.280)	loss 7.619 (7.550)	prob 3.941 (3.769)	GS 34.328 (32.132)	mem 74.379
Train: [61][980/1500]	BT 0.036 (0.315)	DT 0.000 (0.278)	loss 7.720 (7.516)	prob 3.970 (3.811)	GS 35.922 (32.029)	mem 74.379
Train: [61][990/1500]	BT 0.061 (0.312)	DT 0.004 (0.275)	loss 8.087 (7.507)	prob 3.444 (3.793)	GS 34.203 (32.213)	mem 74.378
Train: [61][1000/1500]	BT 0.063 (0.314)	DT 0.016 (0.277)	loss 7.570 (7.505)	prob 3.806 (3.798)	GS 30.141 (32.083)	mem 74.428
Train: [61][1010/1500]	BT 0.069 (0.313)	DT 0.006 (0.276)	loss 7.323 (7.593)	prob 3.245 (3.528)	GS 32.672 (32.805)	mem 74.437
Train: [61][1020/1500]	BT 0.034 (0.316)	DT 0.000 (0.278)	loss 7.486 (7.601)	prob 3.899 (3.390)	GS 32.938 (32.676)	mem 74.441
Train: [61][1030/1500]	BT 0.053 (0.315)	DT 0.006 (0.277)	loss 7.461 (7.577)	prob 3.874 (3.460)	GS 34.875 (32.042)	mem 74.442
Train: [61][1040/1500]	BT 0.028 (0.325)	DT 0.000 (0.288)	loss 7.719 (7.512)	prob 3.141 (3.452)	GS 35.375 (32.186)	mem 74.439
Train: [61][1050/1500]	BT 0.023 (0.323)	DT 0.000 (0.285)	loss 7.504 (7.493)	prob 4.123 (3.408)	GS 32.297 (32.589)	mem 74.440
Train: [61][1060/1500]	BT 0.036 (0.322)	DT 0.001 (0.285)	loss 8.553 (7.621)	prob 3.320 (3.407)	GS 36.969 (32.425)	mem 74.443
Train: [61][1070/1500]	BT 0.036 (0.320)	DT 0.001 (0.282)	loss 7.511 (7.504)	prob 3.745 (3.576)	GS 34.359 (32.420)	mem 74.442
Train: [61][1080/1500]	BT 0.036 (0.317)	DT 0.000 (0.279)	loss 7.783 (7.481)	prob 3.137 (3.504)	GS 35.828 (32.715)	mem 74.443
Train: [61][1090/1500]	BT 0.037 (0.319)	DT 0.001 (0.281)	loss 8.057 (7.502)	prob 3.608 (3.447)	GS 36.406 (32.849)	mem 74.434
Train: [61][1100/1500]	BT 0.038 (0.316)	DT 0.001 (0.279)	loss 8.334 (7.522)	prob 2.799 (3.474)	GS 31.953 (32.696)	mem 74.435
Train: [61][1110/1500]	BT 0.035 (0.317)	DT 0.001 (0.280)	loss 7.749 (7.498)	prob 3.575 (3.427)	GS 34.219 (31.833)	mem 74.436
Train: [61][1120/1500]	BT 0.037 (0.315)	DT 0.001 (0.277)	loss 7.940 (7.469)	prob 2.773 (3.185)	GS 35.172 (32.354)	mem 74.436
Train: [61][1130/1500]	BT 0.038 (0.315)	DT 0.000 (0.277)	loss 7.289 (7.456)	prob 3.433 (3.249)	GS 34.922 (31.855)	mem 74.436
Train: [61][1140/1500]	BT 0.038 (0.313)	DT 0.001 (0.275)	loss 7.458 (7.396)	prob 2.607 (3.230)	GS 32.781 (31.796)	mem 74.435
Train: [61][1150/1500]	BT 0.038 (0.310)	DT 0.001 (0.273)	loss 7.455 (7.421)	prob 3.661 (3.173)	GS 32.875 (31.843)	mem 74.435
Train: [61][1160/1500]	BT 0.024 (0.315)	DT 0.000 (0.277)	loss 7.455 (7.370)	prob 3.212 (2.912)	GS 30.469 (32.544)	mem 74.438
Train: [61][1170/1500]	BT 0.035 (0.312)	DT 0.001 (0.275)	loss 7.796 (7.407)	prob 2.569 (2.838)	GS 36.016 (33.235)	mem 74.440
Train: [61][1180/1500]	BT 0.063 (0.315)	DT 0.013 (0.277)	loss 7.325 (7.405)	prob 3.911 (2.907)	GS 34.922 (33.217)	mem 74.442
Train: [61][1190/1500]	BT 0.037 (0.313)	DT 0.001 (0.275)	loss 8.286 (7.414)	prob 2.345 (2.891)	GS 29.922 (33.255)	mem 74.441
Train: [61][1200/1500]	BT 0.038 (0.312)	DT 0.001 (0.274)	loss 7.060 (7.386)	prob 3.290 (2.939)	GS 31.750 (33.126)	mem 74.442
Train: [61][1210/1500]	BT 0.037 (0.311)	DT 0.000 (0.273)	loss 7.409 (7.316)	prob 3.331 (3.008)	GS 31.359 (31.755)	mem 74.442
Train: [61][1220/1500]	BT 0.038 (0.309)	DT 0.001 (0.272)	loss 7.327 (7.317)	prob 3.212 (2.866)	GS 34.438 (32.365)	mem 74.443
Train: [61][1230/1500]	BT 0.038 (0.309)	DT 0.001 (0.271)	loss 7.213 (7.326)	prob 2.692 (2.917)	GS 30.969 (32.474)	mem 74.444
Train: [61][1240/1500]	BT 0.038 (0.309)	DT 0.000 (0.272)	loss 7.096 (7.313)	prob 2.885 (2.875)	GS 34.109 (32.688)	mem 74.442
Train: [61][1250/1500]	BT 0.029 (0.308)	DT 0.000 (0.271)	loss 7.471 (7.288)	prob 2.772 (2.813)	GS 33.609 (32.631)	mem 74.443
Train: [61][1260/1500]	BT 0.037 (0.306)	DT 0.000 (0.268)	loss 7.194 (7.337)	prob 3.588 (2.916)	GS 34.578 (32.438)	mem 74.444
Train: [61][1270/1500]	BT 0.036 (0.307)	DT 0.001 (0.270)	loss 7.566 (7.348)	prob 2.650 (2.825)	GS 30.438 (32.795)	mem 74.445
Train: [61][1280/1500]	BT 0.025 (0.305)	DT 0.000 (0.268)	loss 7.615 (7.334)	prob 3.158 (2.819)	GS 33.750 (32.674)	mem 74.445
Train: [61][1290/1500]	BT 0.022 (0.310)	DT 0.000 (0.272)	loss 7.275 (7.346)	prob 2.947 (2.789)	GS 33.141 (32.908)	mem 74.461
Train: [61][1300/1500]	BT 0.026 (0.307)	DT 0.000 (0.270)	loss 7.337 (7.345)	prob 2.066 (2.730)	GS 31.344 (32.813)	mem 74.485
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [61][1310/1500]	BT 0.040 (0.305)	DT 0.001 (0.268)	loss 7.374 (7.400)	prob 3.036 (2.328)	GS 30.891 (31.688)	mem 74.488
Train: [61][1320/1500]	BT 0.068 (0.307)	DT 0.011 (0.270)	loss 7.679 (7.419)	prob 3.127 (2.483)	GS 35.672 (31.854)	mem 74.488
Train: [61][1330/1500]	BT 0.033 (0.305)	DT 0.001 (0.268)	loss 7.287 (7.416)	prob 2.513 (2.548)	GS 32.719 (31.991)	mem 74.488
Train: [61][1340/1500]	BT 0.033 (0.310)	DT 0.001 (0.273)	loss 7.555 (7.436)	prob 2.100 (2.498)	GS 35.297 (32.333)	mem 74.531
Train: [61][1350/1500]	BT 0.027 (0.308)	DT 0.000 (0.271)	loss 7.545 (7.416)	prob 2.251 (2.529)	GS 33.953 (32.331)	mem 74.531
Train: [61][1360/1500]	BT 0.034 (0.309)	DT 0.001 (0.272)	loss 7.669 (7.636)	prob 3.223 (2.305)	GS 30.359 (32.806)	mem 74.596
Train: [61][1370/1500]	BT 0.029 (0.307)	DT 0.000 (0.270)	loss 7.298 (7.546)	prob 2.933 (2.650)	GS 35.062 (32.489)	mem 74.623
Train: [61][1380/1500]	BT 0.100 (0.306)	DT 0.004 (0.268)	loss 7.096 (7.455)	prob 2.675 (2.678)	GS 31.562 (32.504)	mem 74.938
Train: [61][1390/1500]	BT 0.037 (0.309)	DT 0.000 (0.272)	loss 7.712 (7.485)	prob 3.392 (2.662)	GS 32.047 (32.352)	mem 77.213
Train: [61][1400/1500]	BT 0.042 (0.308)	DT 0.001 (0.270)	loss 8.049 (7.492)	prob 2.648 (2.712)	GS 30.250 (32.234)	mem 77.221
Train: [61][1410/1500]	BT 0.038 (0.310)	DT 0.001 (0.272)	loss 7.443 (7.409)	prob 2.312 (2.825)	GS 30.938 (32.786)	mem 95.708
Train: [61][1420/1500]	BT 0.055 (0.308)	DT 0.001 (0.270)	loss 7.367 (7.519)	prob 3.194 (2.592)	GS 35.672 (33.619)	mem 97.518
Train: [61][1430/1500]	BT 0.033 (0.306)	DT 0.001 (0.268)	loss 7.248 (7.525)	prob 2.829 (2.652)	GS 33.391 (33.463)	mem 97.842
Train: [61][1440/1500]	BT 0.033 (0.310)	DT 0.000 (0.273)	loss 7.998 (7.534)	prob 2.419 (2.664)	GS 36.750 (33.429)	mem 106.178
Train: [61][1450/1500]	BT 0.073 (0.312)	DT 0.001 (0.274)	loss 7.596 (7.542)	prob 3.423 (2.721)	GS 32.969 (33.380)	mem 111.123
Train: [61][1460/1500]	BT 0.030 (0.312)	DT 0.000 (0.275)	loss 7.290 (7.591)	prob 3.764 (3.089)	GS 37.328 (34.062)	mem 110.400
Train: [61][1470/1500]	BT 0.040 (0.311)	DT 0.001 (0.274)	loss 7.839 (7.629)	prob 4.006 (3.268)	GS 36.031 (32.846)	mem 79.965
Train: [61][1480/1500]	BT 0.029 (0.311)	DT 0.000 (0.273)	loss 7.751 (7.617)	prob 2.923 (3.258)	GS 34.375 (32.769)	mem 51.593
Train: [61][1490/1500]	BT 0.031 (0.309)	DT 0.001 (0.271)	loss 7.555 (7.638)	prob 2.238 (3.197)	GS 33.219 (32.665)	mem 51.595
Train: [61][1500/1500]	BT 0.037 (0.307)	DT 0.000 (0.270)	loss 7.547 (7.633)	prob 3.152 (3.191)	GS 30.750 (32.644)	mem 51.598
Train: [61][1510/1500]	BT 0.030 (0.306)	DT 0.000 (0.269)	loss 7.439 (7.707)	prob 2.990 (2.905)	GS 30.562 (33.469)	mem 45.902
epoch 61, total time 462.52
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [62][1/1500]	BT 24.963 (24.963)	DT 24.904 (24.904)	loss 7.682 (7.682)	prob 3.367 (3.367)	GS 38.344 (38.344)	mem 73.067
Train: [62][10/1500]	BT 0.035 (2.542)	DT 0.001 (2.492)	loss 7.150 (7.463)	prob 4.477 (3.784)	GS 30.031 (30.573)	mem 73.087
Train: [62][20/1500]	BT 0.069 (1.303)	DT 0.011 (1.248)	loss 7.549 (7.497)	prob 3.870 (3.589)	GS 32.109 (31.137)	mem 73.090
Train: [62][30/1500]	BT 0.031 (1.180)	DT 0.000 (1.129)	loss 7.755 (7.525)	prob 3.527 (3.477)	GS 35.359 (31.689)	mem 73.133
Train: [62][40/1500]	BT 0.037 (0.911)	DT 0.001 (0.862)	loss 7.322 (7.567)	prob 4.264 (3.472)	GS 34.609 (31.920)	mem 73.134
Train: [62][50/1500]	BT 0.064 (0.842)	DT 0.008 (0.796)	loss 7.666 (7.560)	prob 3.242 (3.352)	GS 38.641 (32.320)	mem 73.154
Train: [62][60/1500]	BT 0.036 (0.710)	DT 0.000 (0.663)	loss 7.972 (7.657)	prob 4.135 (3.420)	GS 34.562 (31.491)	mem 73.157
Train: [62][70/1500]	BT 0.037 (0.618)	DT 0.000 (0.573)	loss 7.191 (7.566)	prob 3.311 (3.586)	GS 34.469 (31.414)	mem 73.156
Train: [62][80/1500]	BT 0.027 (0.600)	DT 0.000 (0.556)	loss 7.940 (7.622)	prob 2.831 (3.394)	GS 31.641 (32.108)	mem 73.172
Train: [62][90/1500]	BT 0.037 (0.540)	DT 0.001 (0.498)	loss 8.061 (7.611)	prob 3.141 (3.471)	GS 36.109 (31.963)	mem 73.172
Train: [62][100/1500]	BT 0.031 (0.526)	DT 0.000 (0.485)	loss 7.328 (7.599)	prob 4.086 (3.464)	GS 30.969 (31.999)	mem 73.104
Train: [62][110/1500]	BT 0.062 (0.483)	DT 0.011 (0.441)	loss 8.284 (7.556)	prob 3.105 (3.804)	GS 36.375 (32.075)	mem 73.101
Train: [62][120/1500]	BT 0.054 (0.471)	DT 0.007 (0.429)	loss 7.284 (7.554)	prob 5.205 (3.759)	GS 36.141 (32.040)	mem 73.235
Train: [62][130/1500]	BT 0.037 (0.457)	DT 0.001 (0.415)	loss 7.495 (7.530)	prob 4.319 (3.637)	GS 33.812 (32.712)	mem 73.908
Train: [62][140/1500]	BT 0.026 (0.490)	DT 0.000 (0.449)	loss 7.547 (7.542)	prob 3.243 (3.486)	GS 36.641 (32.913)	mem 74.216
Train: [62][150/1500]	BT 0.028 (0.459)	DT 0.000 (0.419)	loss 7.465 (7.539)	prob 3.263 (3.468)	GS 34.797 (32.747)	mem 74.216
Train: [62][160/1500]	BT 0.025 (0.456)	DT 0.000 (0.416)	loss 7.173 (7.560)	prob 4.374 (3.547)	GS 31.609 (32.180)	mem 74.265
Train: [62][170/1500]	BT 0.038 (0.431)	DT 0.000 (0.391)	loss 7.928 (7.609)	prob 3.771 (3.565)	GS 33.500 (32.113)	mem 74.268
Train: [62][180/1500]	BT 0.064 (0.410)	DT 0.014 (0.370)	loss 7.531 (7.561)	prob 3.747 (3.573)	GS 33.109 (32.119)	mem 74.269
Train: [62][190/1500]	BT 0.050 (0.413)	DT 0.014 (0.372)	loss 7.903 (7.550)	prob 3.471 (3.621)	GS 32.766 (32.100)	mem 74.300
Train: [62][200/1500]	BT 0.038 (0.394)	DT 0.000 (0.354)	loss 7.586 (7.540)	prob 3.871 (3.589)	GS 34.219 (32.382)	mem 74.300
Train: [62][210/1500]	BT 0.038 (0.396)	DT 0.001 (0.356)	loss 7.551 (7.596)	prob 3.612 (3.328)	GS 31.969 (33.414)	mem 74.314
Train: [62][220/1500]	BT 0.038 (0.380)	DT 0.001 (0.340)	loss 7.689 (7.565)	prob 4.333 (3.406)	GS 33.516 (33.248)	mem 74.314
Train: [62][230/1500]	BT 0.038 (0.365)	DT 0.001 (0.325)	loss 7.450 (7.545)	prob 3.892 (3.467)	GS 34.203 (33.347)	mem 74.314
Train: [62][240/1500]	BT 0.040 (0.371)	DT 0.001 (0.331)	loss 7.590 (7.542)	prob 3.323 (3.547)	GS 36.859 (33.369)	mem 74.302
Train: [62][250/1500]	BT 0.071 (0.358)	DT 0.001 (0.318)	loss 7.666 (7.522)	prob 3.530 (3.575)	GS 30.297 (33.052)	mem 74.305
Train: [62][260/1500]	BT 0.039 (0.358)	DT 0.001 (0.318)	loss 7.512 (7.398)	prob 3.171 (3.618)	GS 34.062 (32.494)	mem 74.288
Train: [62][270/1500]	BT 0.038 (0.347)	DT 0.001 (0.306)	loss 7.940 (7.412)	prob 3.091 (3.489)	GS 30.250 (32.291)	mem 74.289
Train: [62][280/1500]	BT 0.038 (0.350)	DT 0.001 (0.310)	loss 7.979 (7.436)	prob 3.623 (3.435)	GS 35.484 (32.413)	mem 74.291
Train: [62][290/1500]	BT 0.038 (0.340)	DT 0.001 (0.300)	loss 7.455 (7.432)	prob 3.770 (3.459)	GS 31.156 (32.384)	mem 74.291
Train: [62][300/1500]	BT 0.039 (0.330)	DT 0.001 (0.290)	loss 7.757 (7.404)	prob 3.014 (3.476)	GS 34.312 (32.207)	mem 74.291
Train: [62][310/1500]	BT 0.038 (0.336)	DT 0.000 (0.296)	loss 7.822 (7.586)	prob 2.964 (2.981)	GS 33.016 (33.858)	mem 74.299
Train: [62][320/1500]	BT 0.039 (0.327)	DT 0.001 (0.287)	loss 7.478 (7.488)	prob 3.397 (3.279)	GS 32.750 (33.240)	mem 74.298
Train: [62][330/1500]	BT 0.035 (0.327)	DT 0.000 (0.287)	loss 7.450 (7.462)	prob 3.280 (3.283)	GS 28.484 (32.801)	mem 74.314
Train: [62][340/1500]	BT 0.033 (0.319)	DT 0.000 (0.279)	loss 7.368 (7.420)	prob 3.777 (3.323)	GS 35.531 (32.785)	mem 74.314
Train: [62][350/1500]	BT 0.034 (0.311)	DT 0.000 (0.271)	loss 7.491 (7.412)	prob 3.158 (3.399)	GS 39.797 (32.743)	mem 74.315
Train: [62][360/1500]	BT 0.112 (0.326)	DT 0.010 (0.286)	loss 7.497 (7.410)	prob 3.304 (3.344)	GS 32.344 (32.255)	mem 74.315
Train: [62][370/1500]	BT 0.025 (0.339)	DT 0.000 (0.299)	loss 6.886 (7.365)	prob 4.351 (3.510)	GS 36.672 (33.017)	mem 74.321
Train: [62][380/1500]	BT 0.031 (0.331)	DT 0.000 (0.291)	loss 7.290 (7.354)	prob 3.517 (3.469)	GS 33.688 (33.143)	mem 74.322
Train: [62][390/1500]	BT 0.027 (0.333)	DT 0.000 (0.294)	loss 7.234 (7.361)	prob 3.413 (3.347)	GS 33.062 (33.170)	mem 74.318
Train: [62][400/1500]	BT 0.036 (0.326)	DT 0.001 (0.286)	loss 7.394 (7.384)	prob 3.258 (3.303)	GS 32.766 (33.289)	mem 74.319
Train: [62][410/1500]	BT 0.037 (0.319)	DT 0.001 (0.279)	loss 7.310 (7.288)	prob 3.640 (3.299)	GS 33.688 (32.989)	mem 74.318
Train: [62][420/1500]	BT 0.029 (0.328)	DT 0.000 (0.289)	loss 7.357 (7.301)	prob 2.906 (3.192)	GS 32.906 (32.609)	mem 74.322
Train: [62][430/1500]	BT 0.036 (0.321)	DT 0.000 (0.282)	loss 7.571 (7.340)	prob 3.416 (3.136)	GS 34.750 (32.706)	mem 74.322
Train: [62][440/1500]	BT 0.026 (0.325)	DT 0.000 (0.287)	loss 7.127 (7.338)	prob 3.033 (3.168)	GS 34.656 (32.881)	mem 74.327
Train: [62][450/1500]	BT 0.031 (0.319)	DT 0.000 (0.280)	loss 6.973 (7.309)	prob 4.474 (3.187)	GS 33.906 (33.001)	mem 74.327
Train: [62][460/1500]	BT 0.026 (0.320)	DT 0.000 (0.282)	loss 7.194 (7.289)	prob 3.250 (3.210)	GS 35.016 (32.392)	mem 74.326
Train: [62][470/1500]	BT 0.027 (0.314)	DT 0.000 (0.276)	loss 7.290 (7.277)	prob 3.473 (3.280)	GS 37.188 (32.348)	mem 74.328
Train: [62][480/1500]	BT 0.028 (0.308)	DT 0.000 (0.270)	loss 7.134 (7.270)	prob 3.489 (3.291)	GS 36.703 (32.731)	mem 74.328
Train: [62][490/1500]	BT 0.037 (0.310)	DT 0.001 (0.272)	loss 7.354 (7.262)	prob 3.100 (3.281)	GS 31.109 (32.701)	mem 74.330
Train: [62][500/1500]	BT 0.037 (0.304)	DT 0.001 (0.266)	loss 7.358 (7.244)	prob 3.687 (3.362)	GS 34.562 (32.915)	mem 74.330
Train: [62][510/1500]	BT 0.027 (0.309)	DT 0.000 (0.271)	loss 7.060 (7.179)	prob 3.904 (3.543)	GS 34.344 (33.681)	mem 74.333
Train: [62][520/1500]	BT 0.037 (0.303)	DT 0.001 (0.266)	loss 7.099 (7.232)	prob 3.438 (3.333)	GS 31.219 (33.316)	mem 74.334
Train: [62][530/1500]	BT 0.038 (0.298)	DT 0.000 (0.261)	loss 7.418 (7.224)	prob 3.627 (3.282)	GS 38.344 (33.409)	mem 74.334
Train: [62][540/1500]	BT 0.026 (0.305)	DT 0.000 (0.267)	loss 7.421 (7.239)	prob 3.089 (3.260)	GS 36.422 (33.333)	mem 74.336
Train: [62][550/1500]	BT 0.038 (0.300)	DT 0.001 (0.263)	loss 7.026 (7.250)	prob 3.479 (3.230)	GS 35.188 (33.405)	mem 74.337
Train: [62][560/1500]	BT 0.048 (0.302)	DT 0.000 (0.264)	loss 7.560 (7.271)	prob 3.614 (3.211)	GS 35.328 (32.105)	mem 74.339
Train: [62][570/1500]	BT 0.038 (0.297)	DT 0.000 (0.259)	loss 7.003 (7.203)	prob 3.435 (3.379)	GS 32.234 (32.342)	mem 74.342
Train: [62][580/1500]	BT 0.030 (0.298)	DT 0.000 (0.261)	loss 7.400 (7.216)	prob 2.720 (3.314)	GS 35.938 (32.468)	mem 74.343
Train: [62][590/1500]	BT 0.037 (0.294)	DT 0.001 (0.256)	loss 7.028 (7.210)	prob 3.349 (3.361)	GS 32.922 (32.312)	mem 74.345
Train: [62][600/1500]	BT 0.037 (0.290)	DT 0.001 (0.252)	loss 7.423 (7.215)	prob 3.474 (3.320)	GS 31.359 (32.539)	mem 74.345
Train: [62][610/1500]	BT 0.032 (0.290)	DT 0.000 (0.253)	loss 7.117 (7.165)	prob 3.300 (3.077)	GS 34.469 (32.231)	mem 74.345
Train: [62][620/1500]	BT 0.037 (0.296)	DT 0.000 (0.259)	loss 7.068 (7.218)	prob 2.695 (2.920)	GS 34.953 (32.420)	mem 74.348
Train: [62][630/1500]	BT 0.028 (0.292)	DT 0.000 (0.255)	loss 7.285 (7.247)	prob 3.080 (2.798)	GS 35.375 (32.533)	mem 74.349
Train: [62][640/1500]	BT 0.031 (0.296)	DT 0.000 (0.259)	loss 7.263 (7.276)	prob 2.519 (2.781)	GS 35.438 (32.439)	mem 74.376
Train: [62][650/1500]	BT 0.034 (0.292)	DT 0.000 (0.255)	loss 7.692 (7.296)	prob 2.482 (2.785)	GS 29.953 (32.484)	mem 74.376
Train: [62][660/1500]	BT 0.063 (0.295)	DT 0.003 (0.258)	loss 7.488 (7.251)	prob 2.810 (2.900)	GS 35.766 (33.116)	mem 74.379
Train: [62][670/1500]	BT 0.058 (0.292)	DT 0.002 (0.254)	loss 7.769 (7.327)	prob 2.708 (2.707)	GS 28.828 (33.030)	mem 74.380
Train: [62][680/1500]	BT 0.049 (0.292)	DT 0.000 (0.254)	loss 7.241 (7.303)	prob 2.633 (2.660)	GS 36.594 (32.949)	mem 74.378
Train: [62][690/1500]	BT 0.041 (0.290)	DT 0.001 (0.252)	loss 7.159 (7.313)	prob 1.868 (2.540)	GS 30.656 (33.064)	mem 74.387
Train: [62][700/1500]	BT 0.040 (0.296)	DT 0.001 (0.258)	loss 7.010 (7.300)	prob 3.431 (2.606)	GS 33.797 (33.048)	mem 74.441
Train: [62][710/1500]	BT 0.039 (0.293)	DT 0.006 (0.255)	loss 7.003 (7.289)	prob 3.051 (2.709)	GS 32.906 (31.623)	mem 74.442
Train: [62][720/1500]	BT 0.064 (0.291)	DT 0.017 (0.253)	loss 7.248 (7.268)	prob 2.703 (2.912)	GS 34.125 (31.127)	mem 74.446
Train: [62][730/1500]	BT 0.030 (0.301)	DT 0.000 (0.263)	loss 7.658 (7.269)	prob 2.218 (2.779)	GS 34.781 (32.083)	mem 74.461
Train: [62][740/1500]	BT 0.030 (0.297)	DT 0.000 (0.259)	loss 7.157 (7.272)	prob 3.228 (2.758)	GS 33.562 (31.939)	mem 74.461
Train: [62][750/1500]	BT 0.039 (0.294)	DT 0.001 (0.256)	loss 7.784 (7.316)	prob 2.070 (2.681)	GS 33.172 (32.330)	mem 74.463
Train: [62][760/1500]	BT 0.037 (0.296)	DT 0.008 (0.258)	loss 7.562 (7.484)	prob 2.166 (2.232)	GS 35.625 (34.675)	mem 74.453
Train: [62][770/1500]	BT 0.036 (0.293)	DT 0.001 (0.255)	loss 7.438 (7.502)	prob 2.686 (2.453)	GS 35.016 (33.118)	mem 74.452
Train: [62][780/1500]	BT 0.026 (0.298)	DT 0.000 (0.260)	loss 7.140 (7.461)	prob 3.478 (2.532)	GS 29.500 (32.697)	mem 74.456
Train: [62][790/1500]	BT 0.029 (0.295)	DT 0.000 (0.257)	loss 7.216 (7.436)	prob 3.504 (2.660)	GS 34.344 (32.490)	mem 74.458
Train: [62][800/1500]	BT 0.039 (0.293)	DT 0.001 (0.255)	loss 7.599 (7.434)	prob 2.123 (2.683)	GS 34.812 (32.860)	mem 74.459
Train: [62][810/1500]	BT 0.064 (0.293)	DT 0.006 (0.255)	loss 7.542 (7.462)	prob 3.987 (3.052)	GS 32.938 (31.917)	mem 74.696
Train: [62][820/1500]	BT 0.041 (0.298)	DT 0.001 (0.259)	loss 7.326 (7.461)	prob 2.917 (3.025)	GS 35.125 (32.900)	mem 76.514
Train: [62][830/1500]	BT 0.042 (0.295)	DT 0.001 (0.257)	loss 7.618 (7.447)	prob 2.728 (2.967)	GS 35.203 (32.542)	mem 76.770
Train: [62][840/1500]	BT 0.042 (0.292)	DT 0.001 (0.254)	loss 7.628 (7.438)	prob 2.211 (2.910)	GS 32.953 (32.523)	mem 76.886
Train: [62][850/1500]	BT 0.049 (0.298)	DT 0.001 (0.259)	loss 7.747 (7.440)	prob 2.413 (2.870)	GS 34.625 (32.703)	mem 82.983
Train: [62][860/1500]	BT 0.030 (0.303)	DT 0.000 (0.264)	loss 7.723 (7.443)	prob 2.833 (3.115)	GS 39.750 (34.739)	mem 97.418
Train: [62][870/1500]	BT 0.048 (0.300)	DT 0.001 (0.262)	loss 8.203 (7.482)	prob 2.921 (2.944)	GS 30.172 (33.888)	mem 101.353
Train: [62][880/1500]	BT 0.043 (0.302)	DT 0.001 (0.264)	loss 8.049 (7.545)	prob 3.079 (2.939)	GS 37.312 (34.055)	mem 111.091
Train: [62][890/1500]	BT 0.043 (0.300)	DT 0.001 (0.261)	loss 7.691 (7.553)	prob 3.698 (2.910)	GS 35.234 (34.181)	mem 111.089
Train: [62][900/1500]	BT 0.069 (0.303)	DT 0.001 (0.264)	loss 7.943 (7.559)	prob 2.570 (2.927)	GS 35.781 (34.137)	mem 111.096
Train: [62][910/1500]	BT 0.073 (0.300)	DT 0.001 (0.261)	loss 7.664 (7.600)	prob 3.113 (3.159)	GS 36.422 (32.234)	mem 111.099
Train: [62][920/1500]	BT 0.101 (0.300)	DT 0.011 (0.260)	loss 7.642 (7.641)	prob 3.226 (3.211)	GS 34.453 (32.345)	mem 111.093
Train: [62][930/1500]	BT 0.025 (0.325)	DT 0.000 (0.285)	loss 7.659 (7.642)	prob 2.273 (3.008)	GS 34.516 (33.461)	mem 90.265
Train: [62][940/1500]	BT 0.031 (0.322)	DT 0.000 (0.282)	loss 7.671 (7.601)	prob 4.105 (3.064)	GS 29.500 (33.056)	mem 90.265
Train: [62][950/1500]	BT 0.039 (0.319)	DT 0.001 (0.279)	loss 7.465 (7.551)	prob 2.768 (3.150)	GS 30.641 (32.701)	mem 90.155
Train: [62][960/1500]	BT 0.035 (0.320)	DT 0.001 (0.280)	loss 7.735 (7.478)	prob 2.825 (3.177)	GS 33.016 (32.455)	mem 74.491
Train: [62][970/1500]	BT 0.039 (0.317)	DT 0.001 (0.277)	loss 7.083 (7.461)	prob 3.202 (3.096)	GS 34.109 (32.717)	mem 74.490
Train: [62][980/1500]	BT 0.028 (0.319)	DT 0.000 (0.279)	loss 7.375 (7.459)	prob 3.344 (3.228)	GS 34.109 (32.326)	mem 74.442
Train: [62][990/1500]	BT 0.038 (0.316)	DT 0.001 (0.276)	loss 7.295 (7.438)	prob 3.775 (3.318)	GS 29.688 (32.334)	mem 74.439
Train: [62][1000/1500]	BT 2.883 (0.316)	DT 2.846 (0.277)	loss 7.430 (7.460)	prob 3.592 (3.322)	GS 33.609 (32.643)	mem 74.435
Train: [62][1010/1500]	BT 0.038 (0.313)	DT 0.001 (0.274)	loss 7.592 (7.540)	prob 3.621 (3.314)	GS 32.281 (32.053)	mem 74.437
Train: [62][1020/1500]	BT 0.038 (0.311)	DT 0.001 (0.271)	loss 7.569 (7.494)	prob 3.122 (3.314)	GS 34.078 (32.077)	mem 74.436
Train: [62][1030/1500]	BT 0.036 (0.314)	DT 0.001 (0.275)	loss 7.559 (7.457)	prob 3.420 (3.368)	GS 29.797 (31.861)	mem 74.439
Train: [62][1040/1500]	BT 0.037 (0.311)	DT 0.001 (0.272)	loss 7.255 (7.467)	prob 3.982 (3.356)	GS 35.250 (32.143)	mem 74.441
Train: [62][1050/1500]	BT 0.038 (0.311)	DT 0.001 (0.272)	loss 7.586 (7.480)	prob 3.314 (3.339)	GS 34.359 (32.489)	mem 74.451
Train: [62][1060/1500]	BT 0.048 (0.309)	DT 0.011 (0.270)	loss 7.381 (7.418)	prob 3.353 (3.065)	GS 33.547 (33.005)	mem 74.451
Train: [62][1070/1500]	BT 0.038 (0.306)	DT 0.001 (0.267)	loss 7.304 (7.435)	prob 3.958 (3.288)	GS 34.328 (32.671)	mem 74.451
Train: [62][1080/1500]	BT 0.037 (0.308)	DT 0.001 (0.269)	loss 7.644 (7.451)	prob 3.433 (3.281)	GS 32.266 (32.797)	mem 74.344
Train: [62][1090/1500]	BT 0.037 (0.307)	DT 0.001 (0.267)	loss 7.641 (7.479)	prob 3.087 (3.270)	GS 35.609 (32.710)	mem 74.352
Train: [62][1100/1500]	BT 0.191 (0.306)	DT 0.154 (0.266)	loss 7.484 (7.458)	prob 2.860 (3.302)	GS 34.578 (32.620)	mem 74.351
Train: [62][1110/1500]	BT 0.037 (0.304)	DT 0.000 (0.265)	loss 7.752 (7.505)	prob 3.840 (3.621)	GS 36.172 (30.920)	mem 74.351
Train: [62][1120/1500]	BT 3.296 (0.305)	DT 3.259 (0.266)	loss 7.532 (7.429)	prob 3.826 (3.650)	GS 35.141 (31.485)	mem 74.350
Train: [62][1130/1500]	BT 0.028 (0.302)	DT 0.000 (0.263)	loss 7.315 (7.439)	prob 3.459 (3.472)	GS 34.125 (32.103)	mem 74.350
Train: [62][1140/1500]	BT 0.037 (0.300)	DT 0.001 (0.261)	loss 7.565 (7.463)	prob 3.511 (3.390)	GS 30.406 (31.955)	mem 74.351
Train: [62][1150/1500]	BT 0.035 (0.302)	DT 0.001 (0.263)	loss 7.278 (7.437)	prob 3.532 (3.390)	GS 30.891 (31.966)	mem 74.351
Train: [62][1160/1500]	BT 0.052 (0.300)	DT 0.001 (0.261)	loss 7.472 (7.479)	prob 3.549 (3.228)	GS 34.844 (33.077)	mem 74.353
Train: [62][1170/1500]	BT 0.072 (0.300)	DT 0.004 (0.261)	loss 7.809 (7.479)	prob 3.184 (3.278)	GS 35.875 (32.716)	mem 74.345
Train: [62][1180/1500]	BT 0.038 (0.303)	DT 0.001 (0.264)	loss 7.614 (7.487)	prob 3.386 (3.313)	GS 36.969 (32.757)	mem 74.345
Train: [62][1190/1500]	BT 0.024 (0.302)	DT 0.000 (0.263)	loss 7.274 (7.444)	prob 3.372 (3.284)	GS 35.719 (33.130)	mem 74.362
Train: [62][1200/1500]	BT 0.041 (0.301)	DT 0.001 (0.262)	loss 7.231 (7.475)	prob 3.420 (3.237)	GS 32.719 (33.171)	mem 74.364
Train: [62][1210/1500]	BT 0.037 (0.300)	DT 0.001 (0.261)	loss 7.494 (7.480)	prob 2.643 (3.149)	GS 38.344 (35.291)	mem 74.364
Train: [62][1220/1500]	BT 1.792 (0.300)	DT 1.754 (0.261)	loss 7.177 (7.436)	prob 4.292 (3.178)	GS 31.547 (34.197)	mem 74.351
Train: [62][1230/1500]	BT 0.037 (0.300)	DT 0.001 (0.261)	loss 7.350 (7.430)	prob 3.209 (3.211)	GS 33.469 (33.595)	mem 74.349
Train: [62][1240/1500]	BT 0.039 (0.298)	DT 0.001 (0.259)	loss 7.482 (7.429)	prob 3.872 (3.221)	GS 30.906 (33.121)	mem 74.349
Train: [62][1250/1500]	BT 0.038 (0.296)	DT 0.001 (0.257)	loss 7.128 (7.434)	prob 3.425 (3.215)	GS 33.641 (33.077)	mem 74.349
Train: [62][1260/1500]	BT 0.037 (0.298)	DT 0.001 (0.259)	loss 7.417 (7.409)	prob 3.204 (3.021)	GS 35.266 (32.477)	mem 74.350
Train: [62][1270/1500]	BT 0.037 (0.296)	DT 0.001 (0.257)	loss 7.466 (7.363)	prob 3.224 (3.030)	GS 33.094 (32.163)	mem 74.350
Train: [62][1280/1500]	BT 0.040 (0.296)	DT 0.001 (0.257)	loss 7.172 (7.349)	prob 3.311 (3.121)	GS 35.094 (32.177)	mem 74.351
Train: [62][1290/1500]	BT 0.039 (0.294)	DT 0.001 (0.255)	loss 7.826 (7.368)	prob 3.359 (3.062)	GS 35.031 (32.111)	mem 74.351
Train: [62][1300/1500]	BT 0.031 (0.294)	DT 0.000 (0.255)	loss 7.270 (7.351)	prob 3.900 (3.055)	GS 36.203 (32.390)	mem 74.349
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [62][1310/1500]	BT 0.039 (0.294)	DT 0.001 (0.255)	loss 7.578 (7.346)	prob 3.004 (3.051)	GS 33.891 (32.066)	mem 74.350
Train: [62][1320/1500]	BT 0.055 (0.294)	DT 0.016 (0.255)	loss 7.064 (7.341)	prob 3.792 (3.266)	GS 30.250 (31.517)	mem 74.351
Train: [62][1330/1500]	BT 0.036 (0.294)	DT 0.001 (0.255)	loss 7.477 (7.309)	prob 3.083 (3.138)	GS 31.797 (31.964)	mem 74.353
Train: [62][1340/1500]	BT 0.060 (0.294)	DT 0.003 (0.255)	loss 7.406 (7.309)	prob 2.684 (3.092)	GS 31.391 (32.190)	mem 74.353
Train: [62][1350/1500]	BT 0.039 (0.295)	DT 0.001 (0.256)	loss 7.623 (7.303)	prob 2.164 (3.028)	GS 36.422 (32.500)	mem 74.352
Train: [62][1360/1500]	BT 0.037 (0.293)	DT 0.001 (0.254)	loss 7.520 (7.482)	prob 3.019 (2.447)	GS 33.875 (32.913)	mem 74.364
Train: [62][1370/1500]	BT 0.034 (0.296)	DT 0.001 (0.257)	loss 7.253 (7.307)	prob 2.654 (2.636)	GS 33.078 (32.763)	mem 74.366
Train: [62][1380/1500]	BT 0.033 (0.295)	DT 0.001 (0.256)	loss 7.217 (7.292)	prob 2.849 (2.741)	GS 29.516 (32.545)	mem 74.369
Train: [62][1390/1500]	BT 0.077 (0.293)	DT 0.011 (0.254)	loss 7.977 (7.305)	prob 2.259 (2.709)	GS 31.297 (32.518)	mem 74.369
Train: [62][1400/1500]	BT 0.029 (0.296)	DT 0.000 (0.257)	loss 7.536 (7.305)	prob 2.631 (2.779)	GS 35.594 (32.443)	mem 74.372
Train: [62][1410/1500]	BT 0.023 (0.294)	DT 0.000 (0.255)	loss 6.848 (7.203)	prob 2.398 (2.934)	GS 33.734 (32.506)	mem 74.373
Train: [62][1420/1500]	BT 0.036 (0.297)	DT 0.000 (0.258)	loss 7.716 (7.247)	prob 2.706 (2.746)	GS 31.922 (32.442)	mem 74.373
Train: [62][1430/1500]	BT 0.026 (0.296)	DT 0.000 (0.257)	loss 7.050 (7.248)	prob 2.839 (2.724)	GS 34.922 (32.715)	mem 74.373
Train: [62][1440/1500]	BT 0.037 (0.295)	DT 0.000 (0.257)	loss 6.884 (7.225)	prob 3.654 (2.767)	GS 33.016 (32.509)	mem 74.376
Train: [62][1450/1500]	BT 0.045 (0.296)	DT 0.014 (0.257)	loss 7.179 (7.221)	prob 2.743 (2.769)	GS 35.203 (32.684)	mem 74.157
Train: [62][1460/1500]	BT 0.058 (0.294)	DT 0.014 (0.255)	loss 6.904 (7.311)	prob 2.517 (2.250)	GS 31.812 (31.311)	mem 74.157
Train: [62][1470/1500]	BT 0.092 (0.293)	DT 0.014 (0.254)	loss 7.439 (7.286)	prob 2.827 (2.431)	GS 33.031 (31.711)	mem 74.122
Train: [62][1480/1500]	BT 0.021 (0.294)	DT 0.000 (0.255)	loss 7.348 (7.280)	prob 2.082 (2.442)	GS 29.875 (32.233)	mem 20.626
Train: [62][1490/1500]	BT 0.027 (0.293)	DT 0.000 (0.254)	loss 7.491 (7.302)	prob 2.362 (2.472)	GS 36.938 (32.612)	mem 17.783
Train: [62][1500/1500]	BT 0.031 (0.291)	DT 0.000 (0.252)	loss 7.612 (7.299)	prob 2.656 (2.467)	GS 33.344 (32.641)	mem 14.898
Train: [62][1510/1500]	BT 0.024 (0.290)	DT 0.000 (0.251)	loss 7.185 (7.210)	prob 3.147 (3.197)	GS 35.125 (31.306)	mem 12.086
epoch 62, total time 437.94
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [63][1/1500]	BT 21.066 (21.066)	DT 21.011 (21.011)	loss 6.858 (6.858)	prob 3.481 (3.481)	GS 33.906 (33.906)	mem 72.788
Train: [63][10/1500]	BT 0.038 (2.234)	DT 0.001 (2.198)	loss 6.928 (7.078)	prob 2.567 (2.519)	GS 31.281 (32.903)	mem 72.858
Train: [63][20/1500]	BT 0.037 (1.135)	DT 0.000 (1.099)	loss 7.124 (7.116)	prob 2.647 (2.576)	GS 31.812 (33.465)	mem 72.858
Train: [63][30/1500]	BT 0.037 (0.865)	DT 0.000 (0.829)	loss 7.281 (7.131)	prob 3.573 (2.707)	GS 33.047 (32.983)	mem 72.966
Train: [63][40/1500]	BT 0.037 (0.659)	DT 0.000 (0.622)	loss 7.875 (7.159)	prob 2.421 (2.698)	GS 34.656 (32.986)	mem 72.965
Train: [63][50/1500]	BT 0.037 (0.626)	DT 0.000 (0.590)	loss 7.059 (7.175)	prob 3.423 (2.767)	GS 31.406 (32.757)	mem 73.103
Train: [63][60/1500]	BT 0.058 (0.530)	DT 0.014 (0.493)	loss 7.187 (7.323)	prob 3.488 (3.517)	GS 33.594 (32.820)	mem 73.104
Train: [63][70/1500]	BT 0.060 (0.489)	DT 0.000 (0.451)	loss 7.138 (7.382)	prob 3.328 (3.172)	GS 31.391 (32.536)	mem 73.137
Train: [63][80/1500]	BT 0.038 (0.495)	DT 0.001 (0.456)	loss 7.669 (7.422)	prob 2.953 (3.057)	GS 35.141 (32.810)	mem 73.142
Train: [63][90/1500]	BT 0.038 (0.457)	DT 0.000 (0.418)	loss 7.575 (7.421)	prob 2.950 (3.073)	GS 31.969 (32.824)	mem 73.144
Train: [63][100/1500]	BT 0.083 (0.436)	DT 0.002 (0.396)	loss 7.359 (7.417)	prob 3.799 (3.135)	GS 34.844 (32.736)	mem 73.146
Train: [63][110/1500]	BT 0.057 (0.441)	DT 0.009 (0.399)	loss 7.407 (7.431)	prob 3.505 (3.543)	GS 32.641 (31.398)	mem 73.149
Train: [63][120/1500]	BT 0.037 (0.451)	DT 0.001 (0.410)	loss 7.565 (7.466)	prob 2.770 (3.348)	GS 33.484 (31.718)	mem 73.159
Train: [63][130/1500]	BT 0.029 (0.435)	DT 0.000 (0.394)	loss 7.483 (7.437)	prob 2.996 (3.223)	GS 32.578 (31.865)	mem 73.171
Train: [63][140/1500]	BT 0.038 (0.406)	DT 0.000 (0.366)	loss 7.053 (7.438)	prob 3.699 (3.157)	GS 31.969 (32.296)	mem 73.172
Train: [63][150/1500]	BT 0.028 (0.451)	DT 0.000 (0.411)	loss 7.301 (7.481)	prob 3.462 (3.088)	GS 32.422 (32.536)	mem 73.475
Train: [63][160/1500]	BT 0.030 (0.424)	DT 0.000 (0.385)	loss 7.146 (7.294)	prob 3.454 (3.150)	GS 28.547 (31.861)	mem 73.476
Train: [63][170/1500]	BT 0.023 (0.401)	DT 0.000 (0.363)	loss 7.073 (7.322)	prob 3.943 (3.075)	GS 34.625 (32.334)	mem 73.476
Train: [63][180/1500]	BT 0.099 (0.405)	DT 0.010 (0.367)	loss 7.443 (7.390)	prob 2.703 (2.994)	GS 35.000 (32.591)	mem 74.348
Train: [63][190/1500]	BT 0.040 (0.386)	DT 0.000 (0.348)	loss 7.535 (7.448)	prob 4.427 (3.053)	GS 33.812 (32.262)	mem 74.349
Train: [63][200/1500]	BT 0.038 (0.383)	DT 0.001 (0.344)	loss 8.252 (7.460)	prob 3.256 (3.012)	GS 31.141 (32.574)	mem 74.401
Train: [63][210/1500]	BT 0.030 (0.366)	DT 0.000 (0.328)	loss 7.376 (7.489)	prob 2.864 (2.745)	GS 36.328 (32.478)	mem 74.402
Train: [63][220/1500]	BT 0.039 (0.351)	DT 0.001 (0.313)	loss 7.335 (7.494)	prob 3.725 (2.950)	GS 35.766 (32.610)	mem 74.402
Train: [63][230/1500]	BT 0.039 (0.351)	DT 0.001 (0.313)	loss 7.129 (7.532)	prob 3.319 (3.034)	GS 31.125 (32.615)	mem 74.405
Train: [63][240/1500]	BT 0.068 (0.341)	DT 0.004 (0.303)	loss 7.488 (7.564)	prob 3.228 (2.950)	GS 33.547 (33.025)	mem 74.406
Train: [63][250/1500]	BT 0.038 (0.366)	DT 0.001 (0.327)	loss 8.065 (7.585)	prob 2.376 (2.910)	GS 34.797 (33.211)	mem 74.407
Train: [63][260/1500]	BT 0.059 (0.365)	DT 0.011 (0.326)	loss 7.552 (7.540)	prob 2.786 (3.018)	GS 31.844 (33.013)	mem 74.412
Train: [63][270/1500]	BT 0.050 (0.357)	DT 0.012 (0.317)	loss 7.794 (7.513)	prob 3.037 (3.093)	GS 35.875 (32.184)	mem 74.414
Train: [63][280/1500]	BT 0.081 (0.377)	DT 0.015 (0.337)	loss 7.239 (7.510)	prob 3.512 (3.051)	GS 34.641 (32.572)	mem 74.420
Train: [63][290/1500]	BT 0.035 (0.371)	DT 0.000 (0.329)	loss 7.253 (7.515)	prob 3.775 (3.111)	GS 34.969 (32.406)	mem 74.423
Train: [63][300/1500]	BT 0.055 (0.390)	DT 0.001 (0.348)	loss 7.747 (7.518)	prob 3.196 (3.170)	GS 33.938 (32.549)	mem 74.416
Train: [63][310/1500]	BT 16.295 (0.432)	DT 16.262 (0.390)	loss 7.388 (7.484)	prob 4.069 (3.140)	GS 36.391 (33.233)	mem 74.415
Train: [63][320/1500]	BT 0.028 (0.419)	DT 0.000 (0.378)	loss 7.018 (7.481)	prob 3.200 (3.162)	GS 31.094 (33.323)	mem 74.417
Train: [63][330/1500]	BT 0.037 (0.408)	DT 0.000 (0.367)	loss 7.657 (7.528)	prob 3.578 (3.200)	GS 34.625 (33.281)	mem 74.420
Train: [63][340/1500]	BT 0.033 (0.406)	DT 0.000 (0.365)	loss 7.920 (7.584)	prob 3.594 (3.123)	GS 32.672 (33.368)	mem 74.422
Train: [63][350/1500]	BT 0.025 (0.395)	DT 0.000 (0.355)	loss 7.579 (7.572)	prob 3.517 (3.092)	GS 38.500 (33.472)	mem 74.423
Train: [63][360/1500]	BT 0.055 (0.399)	DT 0.008 (0.359)	loss 7.755 (7.540)	prob 2.567 (3.034)	GS 35.312 (34.830)	mem 74.424
Train: [63][370/1500]	BT 0.093 (0.390)	DT 0.013 (0.349)	loss 8.013 (7.582)	prob 3.405 (3.205)	GS 33.016 (33.415)	mem 74.425
Train: [63][380/1500]	BT 0.050 (0.387)	DT 0.006 (0.344)	loss 7.271 (7.522)	prob 3.383 (3.313)	GS 35.562 (33.237)	mem 74.424
Train: [63][390/1500]	BT 0.054 (0.399)	DT 0.008 (0.356)	loss 7.511 (7.495)	prob 2.555 (3.373)	GS 36.859 (33.716)	mem 74.423
Train: [63][400/1500]	BT 0.061 (0.406)	DT 0.005 (0.364)	loss 7.636 (7.496)	prob 3.056 (3.343)	GS 34.828 (33.680)	mem 74.422
Train: [63][410/1500]	BT 0.059 (0.399)	DT 0.014 (0.357)	loss 7.853 (7.541)	prob 3.122 (2.860)	GS 31.828 (34.022)	mem 74.423
Train: [63][420/1500]	BT 0.037 (0.405)	DT 0.001 (0.362)	loss 7.286 (7.523)	prob 4.052 (3.129)	GS 37.391 (33.150)	mem 74.420
Train: [63][430/1500]	BT 0.042 (0.396)	DT 0.001 (0.353)	loss 8.046 (7.480)	prob 3.649 (3.323)	GS 32.703 (33.142)	mem 74.419
Train: [63][440/1500]	BT 0.040 (0.389)	DT 0.001 (0.346)	loss 7.779 (7.506)	prob 3.687 (3.383)	GS 34.984 (33.264)	mem 74.421
Train: [63][450/1500]	BT 0.039 (0.389)	DT 0.001 (0.346)	loss 7.281 (7.499)	prob 3.923 (3.372)	GS 34.172 (33.203)	mem 74.421
Train: [63][460/1500]	BT 0.040 (0.382)	DT 0.001 (0.339)	loss 7.691 (7.495)	prob 3.163 (3.304)	GS 34.234 (31.484)	mem 74.421
Train: [63][470/1500]	BT 0.027 (0.385)	DT 0.000 (0.342)	loss 8.397 (7.495)	prob 2.811 (3.259)	GS 32.953 (31.973)	mem 74.434
Train: [63][480/1500]	BT 0.039 (0.377)	DT 0.001 (0.335)	loss 7.489 (7.502)	prob 3.730 (3.406)	GS 32.797 (31.567)	mem 74.436
Train: [63][490/1500]	BT 0.039 (0.371)	DT 0.001 (0.328)	loss 7.779 (7.492)	prob 3.667 (3.338)	GS 34.578 (31.883)	mem 74.436
Train: [63][500/1500]	BT 0.037 (0.369)	DT 0.001 (0.327)	loss 7.450 (7.491)	prob 3.106 (3.275)	GS 35.859 (32.013)	mem 74.441
Train: [63][510/1500]	BT 0.069 (0.368)	DT 0.002 (0.326)	loss 7.492 (7.507)	prob 3.619 (3.456)	GS 31.156 (32.081)	mem 74.443
Train: [63][520/1500]	BT 0.037 (0.368)	DT 0.001 (0.326)	loss 7.559 (7.526)	prob 3.688 (3.298)	GS 36.797 (31.977)	mem 74.437
Train: [63][530/1500]	BT 0.037 (0.362)	DT 0.001 (0.320)	loss 7.744 (7.545)	prob 3.270 (3.254)	GS 37.969 (32.551)	mem 74.437
Train: [63][540/1500]	BT 0.038 (0.361)	DT 0.000 (0.320)	loss 7.659 (7.556)	prob 3.236 (3.262)	GS 35.016 (32.519)	mem 74.447
Train: [63][550/1500]	BT 0.037 (0.358)	DT 0.001 (0.317)	loss 7.587 (7.581)	prob 3.161 (3.240)	GS 36.500 (32.705)	mem 74.467
Train: [63][560/1500]	BT 0.037 (0.354)	DT 0.001 (0.312)	loss 7.689 (7.391)	prob 3.574 (3.588)	GS 34.172 (32.606)	mem 74.324
Train: [63][570/1500]	BT 0.036 (0.349)	DT 0.001 (0.308)	loss 7.359 (7.429)	prob 3.230 (3.500)	GS 34.297 (33.052)	mem 74.343
Train: [63][580/1500]	BT 0.038 (0.348)	DT 0.001 (0.307)	loss 7.307 (7.426)	prob 4.217 (3.471)	GS 30.250 (32.908)	mem 74.346
Train: [63][590/1500]	BT 0.037 (0.345)	DT 0.001 (0.303)	loss 7.480 (7.483)	prob 3.209 (3.438)	GS 35.406 (32.917)	mem 74.346
Train: [63][600/1500]	BT 0.036 (0.342)	DT 0.001 (0.301)	loss 7.530 (7.487)	prob 3.148 (3.368)	GS 33.906 (32.792)	mem 74.346
Train: [63][610/1500]	BT 0.037 (0.340)	DT 0.001 (0.298)	loss 7.233 (7.369)	prob 4.204 (3.508)	GS 33.328 (33.144)	mem 74.345
Train: [63][620/1500]	BT 0.161 (0.338)	DT 0.114 (0.297)	loss 7.716 (7.387)	prob 3.818 (3.675)	GS 36.734 (32.766)	mem 74.349
Train: [63][630/1500]	BT 0.029 (0.353)	DT 0.000 (0.312)	loss 7.431 (7.380)	prob 3.397 (3.548)	GS 29.984 (32.739)	mem 74.357
Train: [63][640/1500]	BT 0.027 (0.348)	DT 0.000 (0.307)	loss 7.403 (7.420)	prob 2.863 (3.495)	GS 28.531 (32.547)	mem 74.365
Train: [63][650/1500]	BT 0.038 (0.348)	DT 0.001 (0.307)	loss 7.658 (7.409)	prob 3.634 (3.474)	GS 32.797 (32.465)	mem 74.369
Train: [63][660/1500]	BT 0.038 (0.343)	DT 0.001 (0.302)	loss 7.633 (7.476)	prob 3.145 (3.116)	GS 30.703 (32.112)	mem 74.368
Train: [63][670/1500]	BT 0.038 (0.338)	DT 0.000 (0.298)	loss 7.245 (7.399)	prob 3.433 (3.247)	GS 31.484 (31.447)	mem 74.369
Train: [63][680/1500]	BT 0.039 (0.338)	DT 0.001 (0.297)	loss 7.318 (7.396)	prob 3.163 (3.321)	GS 34.125 (31.646)	mem 74.354
Train: [63][690/1500]	BT 0.039 (0.334)	DT 0.001 (0.293)	loss 7.879 (7.400)	prob 3.799 (3.275)	GS 33.891 (31.618)	mem 74.354
Train: [63][700/1500]	BT 0.028 (0.336)	DT 0.000 (0.295)	loss 7.375 (7.410)	prob 3.489 (3.317)	GS 34.906 (31.538)	mem 74.356
Train: [63][710/1500]	BT 0.039 (0.332)	DT 0.001 (0.291)	loss 7.332 (7.327)	prob 2.961 (2.995)	GS 31.594 (31.586)	mem 74.357
Train: [63][720/1500]	BT 3.422 (0.332)	DT 3.384 (0.292)	loss 7.675 (7.387)	prob 3.147 (2.999)	GS 31.844 (31.718)	mem 74.356
Train: [63][730/1500]	BT 0.039 (0.328)	DT 0.001 (0.288)	loss 7.351 (7.388)	prob 3.025 (3.054)	GS 31.078 (31.899)	mem 74.356
Train: [63][740/1500]	BT 0.039 (0.325)	DT 0.001 (0.284)	loss 7.032 (7.359)	prob 3.945 (3.128)	GS 36.406 (32.025)	mem 74.356
Train: [63][750/1500]	BT 0.028 (0.333)	DT 0.001 (0.292)	loss 7.079 (7.329)	prob 4.140 (3.192)	GS 37.391 (32.045)	mem 74.357
Train: [63][760/1500]	BT 0.052 (0.329)	DT 0.001 (0.288)	loss 7.187 (7.307)	prob 4.009 (2.890)	GS 35.266 (31.814)	mem 74.359
Train: [63][770/1500]	BT 0.031 (0.325)	DT 0.000 (0.285)	loss 7.185 (7.295)	prob 3.316 (2.856)	GS 34.000 (32.560)	mem 74.361
Train: [63][780/1500]	BT 0.029 (0.334)	DT 0.001 (0.294)	loss 7.422 (7.297)	prob 2.541 (2.785)	GS 35.250 (32.444)	mem 74.358
Train: [63][790/1500]	BT 0.039 (0.331)	DT 0.001 (0.290)	loss 7.583 (7.302)	prob 2.984 (2.858)	GS 36.859 (32.888)	mem 74.359
Train: [63][800/1500]	BT 0.059 (0.331)	DT 0.002 (0.291)	loss 7.691 (7.324)	prob 3.169 (2.895)	GS 31.562 (33.012)	mem 74.360
Train: [63][810/1500]	BT 0.052 (0.328)	DT 0.014 (0.288)	loss 7.563 (7.222)	prob 3.242 (2.958)	GS 33.641 (33.964)	mem 74.359
Train: [63][820/1500]	BT 0.039 (0.326)	DT 0.001 (0.286)	loss 7.844 (7.306)	prob 3.260 (2.870)	GS 35.141 (33.318)	mem 74.361
Train: [63][830/1500]	BT 0.027 (0.327)	DT 0.000 (0.286)	loss 7.398 (7.335)	prob 3.681 (2.993)	GS 32.828 (32.850)	mem 74.377
Train: [63][840/1500]	BT 0.038 (0.323)	DT 0.001 (0.283)	loss 7.095 (7.350)	prob 2.876 (2.891)	GS 30.969 (32.977)	mem 74.377
Train: [63][850/1500]	BT 0.026 (0.332)	DT 0.000 (0.292)	loss 7.950 (7.359)	prob 2.878 (2.827)	GS 32.312 (33.393)	mem 74.378
Train: [63][860/1500]	BT 0.037 (0.328)	DT 0.000 (0.288)	loss 7.120 (7.263)	prob 3.095 (2.895)	GS 36.250 (32.916)	mem 74.379
Train: [63][870/1500]	BT 0.101 (0.330)	DT 0.000 (0.290)	loss 7.413 (7.339)	prob 2.609 (2.619)	GS 36.000 (33.484)	mem 74.382
Train: [63][880/1500]	BT 0.078 (0.327)	DT 0.005 (0.287)	loss 7.594 (7.352)	prob 2.865 (2.564)	GS 29.828 (33.829)	mem 74.382
Train: [63][890/1500]	BT 0.080 (0.334)	DT 0.007 (0.294)	loss 7.231 (7.336)	prob 2.778 (2.653)	GS 29.750 (33.833)	mem 74.380
Train: [63][900/1500]	BT 0.023 (0.343)	DT 0.000 (0.302)	loss 6.991 (7.351)	prob 2.735 (2.619)	GS 30.266 (33.411)	mem 74.379
Train: [63][910/1500]	BT 0.030 (0.339)	DT 0.000 (0.299)	loss 7.437 (7.420)	prob 2.601 (2.557)	GS 34.062 (32.330)	mem 74.380
Train: [63][920/1500]	BT 0.060 (0.336)	DT 0.002 (0.295)	loss 7.254 (7.421)	prob 3.007 (2.560)	GS 34.266 (32.630)	mem 74.382
Train: [63][930/1500]	BT 0.030 (0.340)	DT 0.000 (0.300)	loss 7.547 (7.451)	prob 3.583 (2.559)	GS 31.953 (32.195)	mem 74.382
Train: [63][940/1500]	BT 0.037 (0.337)	DT 0.000 (0.297)	loss 7.517 (7.480)	prob 3.366 (2.606)	GS 31.172 (32.217)	mem 74.385
Train: [63][950/1500]	BT 0.032 (0.339)	DT 0.000 (0.299)	loss 7.675 (7.522)	prob 2.939 (2.500)	GS 32.109 (32.503)	mem 74.385
Train: [63][960/1500]	BT 0.032 (0.336)	DT 0.000 (0.296)	loss 7.313 (7.577)	prob 3.310 (2.660)	GS 32.391 (34.128)	mem 74.387
Train: [63][970/1500]	BT 0.036 (0.333)	DT 0.001 (0.293)	loss 7.652 (7.494)	prob 3.416 (2.854)	GS 31.453 (32.885)	mem 74.389
Train: [63][980/1500]	BT 0.027 (0.334)	DT 0.000 (0.295)	loss 7.813 (7.508)	prob 3.164 (2.899)	GS 35.391 (32.860)	mem 74.388
Train: [63][990/1500]	BT 0.038 (0.331)	DT 0.001 (0.292)	loss 7.893 (7.516)	prob 2.971 (2.940)	GS 35.922 (32.695)	mem 74.390
Train: [63][1000/1500]	BT 0.037 (0.331)	DT 0.001 (0.291)	loss 7.662 (7.533)	prob 3.085 (2.931)	GS 32.188 (32.885)	mem 74.391
Train: [63][1010/1500]	BT 0.037 (0.328)	DT 0.001 (0.289)	loss 7.684 (7.571)	prob 4.151 (3.292)	GS 31.062 (30.823)	mem 74.391
Train: [63][1020/1500]	BT 0.038 (0.328)	DT 0.000 (0.288)	loss 8.002 (7.561)	prob 3.285 (3.234)	GS 32.203 (31.617)	mem 74.392
Train: [63][1030/1500]	BT 0.037 (0.325)	DT 0.001 (0.286)	loss 7.609 (7.612)	prob 3.332 (3.164)	GS 32.734 (31.858)	mem 74.393
Train: [63][1040/1500]	BT 0.061 (0.323)	DT 0.004 (0.283)	loss 7.530 (7.598)	prob 4.220 (3.220)	GS 32.859 (31.860)	mem 74.393
Train: [63][1050/1500]	BT 0.036 (0.324)	DT 0.001 (0.285)	loss 7.556 (7.591)	prob 1.961 (3.160)	GS 35.406 (32.198)	mem 74.395
Train: [63][1060/1500]	BT 0.037 (0.322)	DT 0.001 (0.282)	loss 8.122 (7.779)	prob 3.173 (2.544)	GS 33.797 (32.725)	mem 74.395
Train: [63][1070/1500]	BT 0.027 (0.328)	DT 0.000 (0.289)	loss 7.297 (7.627)	prob 3.885 (2.990)	GS 34.500 (33.506)	mem 74.399
Train: [63][1080/1500]	BT 0.038 (0.326)	DT 0.001 (0.286)	loss 7.719 (7.602)	prob 4.121 (3.233)	GS 38.641 (33.715)	mem 74.400
Train: [63][1090/1500]	BT 0.038 (0.323)	DT 0.001 (0.283)	loss 7.583 (7.572)	prob 3.762 (3.276)	GS 31.359 (33.384)	mem 74.400
Train: [63][1100/1500]	BT 0.027 (0.325)	DT 0.001 (0.285)	loss 7.460 (7.597)	prob 3.482 (3.287)	GS 35.938 (33.171)	mem 74.402
Train: [63][1110/1500]	BT 0.038 (0.322)	DT 0.001 (0.283)	loss 7.966 (7.586)	prob 3.755 (3.386)	GS 33.156 (33.033)	mem 74.402
Train: [63][1120/1500]	BT 0.038 (0.323)	DT 0.001 (0.284)	loss 7.383 (7.545)	prob 3.168 (3.433)	GS 28.406 (32.356)	mem 74.404
Train: [63][1130/1500]	BT 0.038 (0.321)	DT 0.001 (0.281)	loss 8.272 (7.558)	prob 2.914 (3.454)	GS 34.922 (32.660)	mem 74.403
Train: [63][1140/1500]	BT 0.027 (0.321)	DT 0.000 (0.281)	loss 7.489 (7.539)	prob 3.781 (3.474)	GS 31.781 (32.592)	mem 74.402
Train: [63][1150/1500]	BT 0.031 (0.321)	DT 0.000 (0.281)	loss 7.675 (7.555)	prob 4.449 (3.505)	GS 34.359 (32.407)	mem 74.404
Train: [63][1160/1500]	BT 0.042 (0.318)	DT 0.011 (0.279)	loss 7.202 (7.379)	prob 4.035 (3.734)	GS 31.531 (31.825)	mem 74.406
Train: [63][1170/1500]	BT 0.029 (0.323)	DT 0.000 (0.284)	loss 7.488 (7.480)	prob 3.819 (3.720)	GS 31.688 (32.311)	mem 74.403
Train: [63][1180/1500]	BT 0.029 (0.321)	DT 0.000 (0.281)	loss 7.295 (7.455)	prob 3.619 (3.711)	GS 35.578 (32.281)	mem 74.403
Train: [63][1190/1500]	BT 0.039 (0.321)	DT 0.001 (0.281)	loss 6.970 (7.471)	prob 3.828 (3.583)	GS 32.969 (32.482)	mem 74.432
Train: [63][1200/1500]	BT 0.039 (0.318)	DT 0.001 (0.279)	loss 7.685 (7.484)	prob 3.919 (3.576)	GS 33.984 (32.577)	mem 74.432
Train: [63][1210/1500]	BT 0.040 (0.316)	DT 0.001 (0.277)	loss 7.497 (7.416)	prob 3.387 (3.712)	GS 36.094 (32.414)	mem 74.432
Train: [63][1220/1500]	BT 0.039 (0.317)	DT 0.001 (0.278)	loss 7.572 (7.456)	prob 3.570 (3.559)	GS 35.906 (33.435)	mem 74.433
Train: [63][1230/1500]	BT 0.038 (0.315)	DT 0.001 (0.276)	loss 7.863 (7.454)	prob 3.091 (3.592)	GS 36.094 (33.290)	mem 74.434
Train: [63][1240/1500]	BT 0.035 (0.319)	DT 0.000 (0.279)	loss 7.503 (7.429)	prob 3.892 (3.628)	GS 31.359 (33.001)	mem 74.435
Train: [63][1250/1500]	BT 0.061 (0.317)	DT 0.004 (0.277)	loss 7.391 (7.433)	prob 3.783 (3.569)	GS 34.250 (32.937)	mem 74.435
Train: [63][1260/1500]	BT 0.032 (0.319)	DT 0.001 (0.280)	loss 7.466 (7.495)	prob 3.547 (3.153)	GS 37.297 (33.513)	mem 74.434
Train: [63][1270/1500]	BT 0.031 (0.317)	DT 0.000 (0.278)	loss 7.784 (7.535)	prob 3.504 (3.297)	GS 37.500 (33.970)	mem 74.435
Train: [63][1280/1500]	BT 0.032 (0.315)	DT 0.001 (0.276)	loss 7.179 (7.519)	prob 3.007 (3.302)	GS 36.656 (33.531)	mem 74.436
Train: [63][1290/1500]	BT 0.026 (0.318)	DT 0.000 (0.279)	loss 7.381 (7.497)	prob 3.251 (3.318)	GS 32.922 (33.386)	mem 74.437
Train: [63][1300/1500]	BT 0.029 (0.315)	DT 0.000 (0.276)	loss 7.310 (7.494)	prob 3.255 (3.292)	GS 32.422 (33.138)	mem 74.438
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [63][1310/1500]	BT 0.039 (0.314)	DT 0.001 (0.275)	loss 7.161 (7.324)	prob 4.033 (3.649)	GS 34.641 (31.653)	mem 74.440
Train: [63][1320/1500]	BT 0.039 (0.313)	DT 0.001 (0.274)	loss 7.491 (7.422)	prob 3.663 (3.595)	GS 33.031 (31.784)	mem 74.440
Train: [63][1330/1500]	BT 0.040 (0.311)	DT 0.001 (0.272)	loss 7.073 (7.415)	prob 3.405 (3.599)	GS 32.562 (32.347)	mem 74.440
Train: [63][1340/1500]	BT 0.044 (0.314)	DT 0.000 (0.275)	loss 7.441 (7.388)	prob 3.681 (3.598)	GS 33.844 (32.402)	mem 74.438
Train: [63][1350/1500]	BT 0.038 (0.315)	DT 0.001 (0.276)	loss 7.275 (7.391)	prob 4.019 (3.575)	GS 34.000 (32.820)	mem 74.436
Train: [63][1360/1500]	BT 0.039 (0.314)	DT 0.001 (0.274)	loss 7.209 (7.210)	prob 3.812 (3.824)	GS 35.062 (33.434)	mem 74.436
Train: [63][1370/1500]	BT 0.097 (0.313)	DT 0.001 (0.274)	loss 7.058 (7.235)	prob 3.755 (3.758)	GS 33.734 (32.470)	mem 74.435
Train: [63][1380/1500]	BT 0.039 (0.313)	DT 0.001 (0.274)	loss 7.063 (7.255)	prob 3.384 (3.596)	GS 33.641 (32.352)	mem 74.438
Train: [63][1390/1500]	BT 0.039 (0.311)	DT 0.001 (0.272)	loss 7.274 (7.283)	prob 4.067 (3.553)	GS 30.266 (32.014)	mem 74.438
Train: [63][1400/1500]	BT 0.055 (0.311)	DT 0.001 (0.272)	loss 7.213 (7.281)	prob 3.616 (3.540)	GS 34.734 (31.887)	mem 74.438
Train: [63][1410/1500]	BT 0.027 (0.315)	DT 0.000 (0.275)	loss 7.128 (7.211)	prob 3.270 (3.389)	GS 34.188 (31.522)	mem 74.436
Train: [63][1420/1500]	BT 0.039 (0.313)	DT 0.001 (0.273)	loss 7.584 (7.258)	prob 2.874 (3.463)	GS 36.016 (32.295)	mem 74.438
Train: [63][1430/1500]	BT 0.039 (0.311)	DT 0.001 (0.271)	loss 7.657 (7.265)	prob 3.122 (3.430)	GS 31.875 (32.502)	mem 74.438
Train: [63][1440/1500]	BT 0.028 (0.311)	DT 0.000 (0.272)	loss 7.386 (7.277)	prob 3.735 (3.440)	GS 33.828 (32.362)	mem 74.438
Train: [63][1450/1500]	BT 0.039 (0.309)	DT 0.001 (0.270)	loss 7.237 (7.256)	prob 3.127 (3.429)	GS 34.734 (32.082)	mem 74.440
Train: [63][1460/1500]	BT 0.030 (0.312)	DT 0.000 (0.273)	loss 7.399 (7.227)	prob 3.674 (3.699)	GS 37.234 (32.383)	mem 73.708
Train: [63][1470/1500]	BT 0.025 (0.312)	DT 0.000 (0.273)	loss 7.093 (7.239)	prob 3.160 (3.514)	GS 31.219 (32.899)	mem 48.258
Train: [63][1480/1500]	BT 0.025 (0.310)	DT 0.000 (0.271)	loss 7.535 (7.231)	prob 3.586 (3.492)	GS 31.062 (32.503)	mem 48.184
Train: [63][1490/1500]	BT 0.031 (0.308)	DT 0.000 (0.269)	loss 7.712 (7.208)	prob 2.626 (3.455)	GS 27.344 (32.202)	mem 14.944
Train: [63][1500/1500]	BT 0.026 (0.307)	DT 0.000 (0.268)	loss 7.007 (7.197)	prob 2.471 (3.423)	GS 32.719 (32.541)	mem 9.331
Train: [63][1510/1500]	BT 0.024 (0.305)	DT 0.000 (0.266)	loss 6.646 (7.020)	prob 3.672 (3.107)	GS 37.281 (33.525)	mem 9.331
epoch 63, total time 461.33
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [64][1/1500]	BT 24.192 (24.192)	DT 24.129 (24.129)	loss 6.749 (6.749)	prob 3.187 (3.187)	GS 32.562 (32.562)	mem 72.965
Train: [64][10/1500]	BT 0.028 (2.462)	DT 0.000 (2.427)	loss 6.717 (6.889)	prob 3.477 (3.461)	GS 34.531 (33.201)	mem 72.977
Train: [64][20/1500]	BT 0.038 (1.249)	DT 0.001 (1.214)	loss 6.831 (6.934)	prob 3.310 (3.504)	GS 32.266 (32.808)	mem 72.979
Train: [64][30/1500]	BT 0.642 (0.982)	DT 0.594 (0.945)	loss 6.881 (6.943)	prob 3.972 (3.547)	GS 35.953 (32.671)	mem 73.067
Train: [64][40/1500]	BT 0.049 (0.749)	DT 0.000 (0.710)	loss 7.075 (6.961)	prob 3.310 (3.528)	GS 34.453 (32.129)	mem 73.069
Train: [64][50/1500]	BT 0.056 (0.716)	DT 0.014 (0.676)	loss 7.296 (6.993)	prob 4.066 (3.525)	GS 34.922 (32.196)	mem 73.089
Train: [64][60/1500]	BT 0.032 (0.608)	DT 0.000 (0.567)	loss 7.060 (7.037)	prob 3.237 (3.421)	GS 29.250 (32.359)	mem 73.091
Train: [64][70/1500]	BT 0.029 (0.526)	DT 0.000 (0.486)	loss 7.300 (7.067)	prob 3.143 (3.558)	GS 31.031 (31.834)	mem 73.091
Train: [64][80/1500]	BT 0.362 (0.519)	DT 0.325 (0.481)	loss 6.985 (7.080)	prob 4.355 (3.546)	GS 33.094 (31.514)	mem 73.091
Train: [64][90/1500]	BT 0.036 (0.465)	DT 0.001 (0.427)	loss 7.022 (7.083)	prob 3.266 (3.471)	GS 35.672 (31.942)	mem 73.092
Train: [64][100/1500]	BT 0.036 (0.468)	DT 0.001 (0.430)	loss 6.921 (7.069)	prob 3.057 (3.393)	GS 31.328 (31.724)	mem 73.096
Train: [64][110/1500]	BT 0.035 (0.428)	DT 0.000 (0.391)	loss 7.181 (7.033)	prob 3.541 (3.084)	GS 34.188 (32.361)	mem 73.095
Train: [64][120/1500]	BT 0.039 (0.396)	DT 0.000 (0.359)	loss 7.353 (7.057)	prob 2.775 (3.095)	GS 35.266 (31.957)	mem 73.097
Train: [64][130/1500]	BT 0.039 (0.390)	DT 0.001 (0.353)	loss 6.954 (7.072)	prob 2.723 (2.907)	GS 32.875 (31.952)	mem 73.098
Train: [64][140/1500]	BT 0.040 (0.369)	DT 0.001 (0.332)	loss 6.850 (7.065)	prob 3.536 (2.977)	GS 33.281 (31.855)	mem 73.099
Train: [64][150/1500]	BT 0.040 (0.361)	DT 0.001 (0.324)	loss 7.080 (7.061)	prob 2.588 (2.955)	GS 33.078 (32.037)	mem 73.101
Train: [64][160/1500]	BT 0.039 (0.348)	DT 0.001 (0.311)	loss 7.269 (7.024)	prob 3.059 (3.020)	GS 36.594 (32.603)	mem 73.102
Train: [64][170/1500]	BT 0.041 (0.340)	DT 0.001 (0.303)	loss 7.131 (7.017)	prob 2.147 (2.894)	GS 34.188 (32.696)	mem 73.104
Train: [64][180/1500]	BT 0.070 (0.337)	DT 0.001 (0.299)	loss 6.981 (7.029)	prob 3.026 (2.866)	GS 30.719 (32.744)	mem 73.106
Train: [64][190/1500]	BT 0.027 (0.352)	DT 0.000 (0.315)	loss 7.293 (7.045)	prob 2.658 (2.788)	GS 31.719 (32.951)	mem 73.126
Train: [64][200/1500]	BT 0.038 (0.337)	DT 0.001 (0.299)	loss 6.863 (7.043)	prob 3.264 (2.836)	GS 36.531 (33.089)	mem 73.127
Train: [64][210/1500]	BT 0.037 (0.335)	DT 0.000 (0.298)	loss 7.197 (7.077)	prob 3.840 (3.057)	GS 34.297 (33.795)	mem 73.135
Train: [64][220/1500]	BT 0.039 (0.322)	DT 0.001 (0.285)	loss 7.250 (7.048)	prob 2.756 (3.012)	GS 33.250 (33.080)	mem 73.135
Train: [64][230/1500]	BT 0.037 (0.315)	DT 0.001 (0.278)	loss 6.872 (7.030)	prob 3.710 (3.019)	GS 37.047 (33.004)	mem 73.138
Train: [64][240/1500]	BT 0.038 (0.317)	DT 0.001 (0.280)	loss 7.130 (7.016)	prob 2.843 (3.010)	GS 28.656 (32.797)	mem 73.139
Train: [64][250/1500]	BT 0.038 (0.307)	DT 0.000 (0.270)	loss 7.016 (7.019)	prob 3.121 (3.032)	GS 34.562 (32.817)	mem 73.141
Train: [64][260/1500]	BT 0.037 (0.315)	DT 0.001 (0.278)	loss 6.985 (6.941)	prob 3.203 (2.981)	GS 37.250 (32.211)	mem 73.245
Train: [64][270/1500]	BT 0.038 (0.305)	DT 0.001 (0.268)	loss 7.209 (6.996)	prob 2.727 (2.946)	GS 33.125 (32.216)	mem 73.295
Train: [64][280/1500]	BT 0.036 (0.310)	DT 0.000 (0.273)	loss 6.886 (6.998)	prob 3.284 (2.959)	GS 31.922 (32.086)	mem 73.985
Train: [64][290/1500]	BT 0.037 (0.301)	DT 0.001 (0.264)	loss 6.948 (6.990)	prob 2.783 (2.862)	GS 28.406 (32.141)	mem 73.987
Train: [64][300/1500]	BT 0.038 (0.292)	DT 0.001 (0.255)	loss 6.834 (6.986)	prob 3.199 (2.895)	GS 33.781 (32.182)	mem 74.037
Train: [64][310/1500]	BT 0.037 (0.295)	DT 0.000 (0.258)	loss 7.221 (7.004)	prob 2.496 (2.644)	GS 33.703 (32.230)	mem 74.283
Train: [64][320/1500]	BT 0.037 (0.287)	DT 0.001 (0.250)	loss 7.394 (7.017)	prob 2.536 (2.652)	GS 34.312 (31.981)	mem 74.284
Train: [64][330/1500]	BT 0.038 (0.288)	DT 0.001 (0.250)	loss 6.905 (7.022)	prob 3.124 (2.783)	GS 34.094 (31.834)	mem 74.333
Train: [64][340/1500]	BT 0.038 (0.280)	DT 0.001 (0.243)	loss 7.090 (7.014)	prob 2.882 (2.728)	GS 34.375 (32.068)	mem 74.334
Train: [64][350/1500]	BT 0.037 (0.279)	DT 0.001 (0.242)	loss 7.057 (7.004)	prob 2.753 (2.750)	GS 30.047 (31.835)	mem 74.335
Train: [64][360/1500]	BT 0.037 (0.282)	DT 0.001 (0.245)	loss 7.089 (6.955)	prob 2.530 (2.969)	GS 28.547 (33.172)	mem 74.338
Train: [64][370/1500]	BT 0.028 (0.279)	DT 0.000 (0.242)	loss 6.835 (6.954)	prob 2.301 (2.681)	GS 31.656 (32.567)	mem 74.339
Train: [64][380/1500]	BT 0.039 (0.277)	DT 0.001 (0.240)	loss 6.794 (6.942)	prob 2.702 (2.636)	GS 35.609 (32.574)	mem 74.342
Train: [64][390/1500]	BT 0.038 (0.271)	DT 0.001 (0.234)	loss 6.779 (6.932)	prob 2.413 (2.634)	GS 35.156 (32.626)	mem 74.342
Train: [64][400/1500]	BT 0.067 (0.275)	DT 0.013 (0.238)	loss 7.037 (6.941)	prob 1.968 (2.613)	GS 33.594 (32.712)	mem 74.345
Train: [64][410/1500]	BT 0.054 (0.270)	DT 0.000 (0.232)	loss 6.965 (6.948)	prob 2.554 (2.389)	GS 33.875 (33.177)	mem 74.345
Train: [64][420/1500]	BT 0.037 (0.276)	DT 0.000 (0.238)	loss 6.778 (6.946)	prob 3.315 (2.451)	GS 34.250 (32.407)	mem 74.346
Train: [64][430/1500]	BT 0.037 (0.272)	DT 0.000 (0.234)	loss 6.960 (6.942)	prob 2.577 (2.512)	GS 33.344 (32.711)	mem 74.346
Train: [64][440/1500]	BT 0.036 (0.282)	DT 0.001 (0.244)	loss 7.030 (6.952)	prob 3.184 (2.550)	GS 32.469 (32.735)	mem 74.347
Train: [64][450/1500]	BT 0.028 (0.280)	DT 0.000 (0.242)	loss 6.856 (6.939)	prob 3.206 (2.602)	GS 39.312 (32.955)	mem 74.349
Train: [64][460/1500]	BT 0.038 (0.274)	DT 0.001 (0.237)	loss 6.777 (6.899)	prob 2.789 (2.574)	GS 38.344 (33.341)	mem 74.350
Train: [64][470/1500]	BT 0.038 (0.275)	DT 0.001 (0.237)	loss 6.771 (6.903)	prob 2.992 (2.604)	GS 31.094 (32.271)	mem 74.351
Train: [64][480/1500]	BT 0.038 (0.270)	DT 0.001 (0.232)	loss 6.893 (6.905)	prob 2.358 (2.542)	GS 30.219 (32.039)	mem 74.351
Train: [64][490/1500]	BT 0.038 (0.275)	DT 0.001 (0.237)	loss 7.061 (6.897)	prob 2.382 (2.531)	GS 33.078 (32.072)	mem 74.385
Train: [64][500/1500]	BT 0.035 (0.271)	DT 0.000 (0.233)	loss 6.806 (6.890)	prob 2.639 (2.572)	GS 39.531 (32.523)	mem 74.386
Train: [64][510/1500]	BT 0.039 (0.266)	DT 0.001 (0.229)	loss 6.889 (6.888)	prob 2.212 (2.444)	GS 37.188 (33.225)	mem 74.386
Train: [64][520/1500]	BT 0.040 (0.266)	DT 0.001 (0.229)	loss 6.781 (6.836)	prob 2.861 (2.519)	GS 35.578 (33.414)	mem 74.388
Train: [64][530/1500]	BT 0.037 (0.266)	DT 0.001 (0.228)	loss 6.914 (6.838)	prob 2.009 (2.452)	GS 31.438 (33.251)	mem 74.388
Train: [64][540/1500]	BT 0.037 (0.264)	DT 0.001 (0.227)	loss 6.662 (6.848)	prob 2.315 (2.417)	GS 33.828 (33.105)	mem 74.390
Train: [64][550/1500]	BT 0.039 (0.265)	DT 0.001 (0.227)	loss 6.816 (6.860)	prob 2.044 (2.353)	GS 32.078 (33.028)	mem 74.390
Train: [64][560/1500]	BT 0.038 (0.265)	DT 0.001 (0.227)	loss 6.778 (6.839)	prob 3.177 (2.284)	GS 36.766 (33.712)	mem 74.391
Train: [64][570/1500]	BT 0.029 (0.266)	DT 0.000 (0.229)	loss 6.786 (6.816)	prob 2.233 (2.342)	GS 34.328 (33.157)	mem 74.390
Train: [64][580/1500]	BT 0.036 (0.262)	DT 0.001 (0.225)	loss 6.859 (6.847)	prob 2.294 (2.214)	GS 33.766 (33.081)	mem 74.392
Train: [64][590/1500]	BT 0.052 (0.263)	DT 0.009 (0.225)	loss 6.953 (6.858)	prob 2.013 (2.227)	GS 33.562 (33.292)	mem 74.393
Train: [64][600/1500]	BT 0.030 (0.263)	DT 0.000 (0.225)	loss 6.968 (6.857)	prob 2.343 (2.247)	GS 31.812 (33.269)	mem 74.394
Train: [64][610/1500]	BT 0.038 (0.264)	DT 0.000 (0.227)	loss 6.916 (6.926)	prob 1.689 (2.222)	GS 34.297 (31.758)	mem 74.395
Train: [64][620/1500]	BT 0.038 (0.260)	DT 0.001 (0.223)	loss 6.659 (6.891)	prob 2.594 (2.267)	GS 30.656 (32.187)	mem 74.395
Train: [64][630/1500]	BT 0.040 (0.257)	DT 0.001 (0.219)	loss 6.923 (6.881)	prob 1.873 (2.380)	GS 34.125 (32.791)	mem 74.395
Train: [64][640/1500]	BT 0.040 (0.258)	DT 0.001 (0.220)	loss 6.988 (6.881)	prob 2.316 (2.441)	GS 32.688 (32.604)	mem 74.396
Train: [64][650/1500]	BT 0.035 (0.257)	DT 0.001 (0.220)	loss 6.885 (6.879)	prob 2.424 (2.459)	GS 31.422 (32.422)	mem 74.396
Train: [64][660/1500]	BT 0.039 (0.256)	DT 0.001 (0.218)	loss 6.853 (6.871)	prob 2.622 (2.264)	GS 33.094 (32.450)	mem 74.396
Train: [64][670/1500]	BT 0.031 (0.258)	DT 0.000 (0.220)	loss 6.666 (6.858)	prob 2.574 (2.202)	GS 33.641 (32.360)	mem 74.398
Train: [64][680/1500]	BT 0.048 (0.261)	DT 0.006 (0.224)	loss 6.762 (6.846)	prob 2.337 (2.107)	GS 33.969 (32.364)	mem 74.396
Train: [64][690/1500]	BT 0.029 (0.265)	DT 0.000 (0.227)	loss 6.884 (6.875)	prob 2.855 (2.146)	GS 34.141 (32.317)	mem 74.396
Train: [64][700/1500]	BT 0.037 (0.264)	DT 0.001 (0.226)	loss 7.040 (6.869)	prob 2.113 (2.215)	GS 33.797 (32.448)	mem 74.400
Train: [64][710/1500]	BT 0.027 (0.264)	DT 0.000 (0.226)	loss 7.114 (6.867)	prob 2.316 (2.437)	GS 30.062 (31.725)	mem 74.407
Train: [64][720/1500]	BT 0.038 (0.263)	DT 0.000 (0.225)	loss 7.134 (6.905)	prob 2.642 (2.395)	GS 33.766 (31.960)	mem 74.419
Train: [64][730/1500]	BT 0.037 (0.259)	DT 0.001 (0.222)	loss 6.820 (6.931)	prob 2.760 (2.360)	GS 31.984 (31.991)	mem 74.421
Train: [64][740/1500]	BT 0.037 (0.258)	DT 0.001 (0.221)	loss 6.829 (6.926)	prob 2.887 (2.379)	GS 36.328 (32.151)	mem 74.422
Train: [64][750/1500]	BT 0.029 (0.259)	DT 0.000 (0.222)	loss 6.936 (6.920)	prob 2.476 (2.373)	GS 32.297 (32.403)	mem 74.318
Train: [64][760/1500]	BT 0.047 (0.261)	DT 0.011 (0.223)	loss 7.212 (6.991)	prob 2.356 (2.518)	GS 35.391 (33.914)	mem 74.319
Train: [64][770/1500]	BT 0.036 (0.258)	DT 0.001 (0.221)	loss 6.945 (6.991)	prob 2.467 (2.417)	GS 35.641 (33.795)	mem 74.318
Train: [64][780/1500]	BT 0.037 (0.259)	DT 0.000 (0.222)	loss 6.893 (6.969)	prob 2.741 (2.433)	GS 34.688 (33.828)	mem 74.319
Train: [64][790/1500]	BT 0.027 (0.256)	DT 0.000 (0.219)	loss 7.250 (6.995)	prob 2.780 (2.399)	GS 35.016 (33.756)	mem 74.322
Train: [64][800/1500]	BT 0.030 (0.265)	DT 0.001 (0.228)	loss 7.281 (7.023)	prob 2.717 (2.387)	GS 32.406 (33.702)	mem 74.321
Train: [64][810/1500]	BT 0.032 (0.262)	DT 0.000 (0.225)	loss 7.682 (7.159)	prob 2.161 (2.449)	GS 35.266 (33.005)	mem 74.321
Train: [64][820/1500]	BT 0.036 (0.259)	DT 0.000 (0.222)	loss 6.848 (7.102)	prob 1.985 (2.442)	GS 28.734 (32.157)	mem 74.339
Train: [64][830/1500]	BT 0.037 (0.261)	DT 0.000 (0.224)	loss 7.382 (7.144)	prob 2.950 (2.432)	GS 31.812 (32.183)	mem 74.342
Train: [64][840/1500]	BT 0.038 (0.259)	DT 0.001 (0.222)	loss 7.197 (7.141)	prob 2.685 (2.542)	GS 33.234 (32.805)	mem 74.344
Train: [64][850/1500]	BT 0.038 (0.259)	DT 0.001 (0.222)	loss 7.324 (7.145)	prob 3.490 (2.495)	GS 31.703 (32.594)	mem 74.344
Train: [64][860/1500]	BT 0.039 (0.257)	DT 0.001 (0.220)	loss 7.972 (7.157)	prob 2.450 (2.677)	GS 35.891 (32.906)	mem 74.344
Train: [64][870/1500]	BT 0.039 (0.254)	DT 0.001 (0.217)	loss 7.753 (7.151)	prob 1.797 (2.466)	GS 37.531 (32.909)	mem 74.344
Train: [64][880/1500]	BT 0.028 (0.256)	DT 0.000 (0.219)	loss 7.287 (7.195)	prob 2.150 (2.437)	GS 33.281 (32.916)	mem 74.330
Train: [64][890/1500]	BT 0.038 (0.254)	DT 0.001 (0.217)	loss 7.496 (7.237)	prob 2.748 (2.498)	GS 31.734 (33.057)	mem 74.332
Train: [64][900/1500]	BT 0.026 (0.257)	DT 0.000 (0.220)	loss 7.594 (7.244)	prob 2.764 (2.468)	GS 35.125 (33.056)	mem 74.330
Train: [64][910/1500]	BT 0.027 (0.255)	DT 0.000 (0.218)	loss 7.339 (7.304)	prob 2.564 (2.736)	GS 30.344 (31.567)	mem 74.332
Train: [64][920/1500]	BT 0.031 (0.260)	DT 0.000 (0.223)	loss 7.072 (7.259)	prob 2.519 (2.700)	GS 35.547 (31.538)	mem 74.334
Train: [64][930/1500]	BT 0.033 (0.257)	DT 0.000 (0.221)	loss 7.302 (7.220)	prob 1.561 (2.589)	GS 29.812 (31.747)	mem 74.333
Train: [64][940/1500]	BT 0.031 (0.255)	DT 0.000 (0.218)	loss 7.607 (7.205)	prob 2.751 (2.584)	GS 31.828 (31.457)	mem 74.335
Train: [64][950/1500]	BT 0.041 (0.260)	DT 0.001 (0.223)	loss 7.354 (7.243)	prob 3.533 (2.599)	GS 32.172 (31.857)	mem 74.332
Train: [64][960/1500]	BT 0.026 (0.260)	DT 0.000 (0.224)	loss 7.350 (7.240)	prob 2.686 (2.505)	GS 34.188 (33.591)	mem 74.344
Train: [64][970/1500]	BT 0.025 (0.258)	DT 0.000 (0.222)	loss 7.378 (7.254)	prob 2.426 (2.483)	GS 32.984 (32.355)	mem 74.345
Train: [64][980/1500]	BT 0.048 (0.259)	DT 0.000 (0.222)	loss 7.287 (7.262)	prob 3.532 (2.607)	GS 33.625 (32.250)	mem 74.348
Train: [64][990/1500]	BT 0.034 (0.257)	DT 0.000 (0.220)	loss 7.061 (7.248)	prob 2.947 (2.569)	GS 34.656 (32.291)	mem 74.348
Train: [64][1000/1500]	BT 0.038 (0.259)	DT 0.001 (0.223)	loss 7.613 (7.261)	prob 2.124 (2.566)	GS 37.359 (32.425)	mem 74.349
Train: [64][1010/1500]	BT 0.043 (0.257)	DT 0.000 (0.221)	loss 7.185 (7.347)	prob 3.497 (2.581)	GS 30.734 (32.638)	mem 74.349
Train: [64][1020/1500]	BT 0.026 (0.263)	DT 0.000 (0.226)	loss 7.340 (7.332)	prob 3.082 (2.716)	GS 34.844 (32.834)	mem 74.352
Train: [64][1030/1500]	BT 0.026 (0.261)	DT 0.000 (0.224)	loss 7.516 (7.318)	prob 3.739 (2.702)	GS 32.906 (33.171)	mem 74.353
Train: [64][1040/1500]	BT 0.047 (0.263)	DT 0.007 (0.227)	loss 7.472 (7.289)	prob 2.790 (2.822)	GS 34.516 (32.907)	mem 74.354
Train: [64][1050/1500]	BT 0.030 (0.261)	DT 0.000 (0.225)	loss 7.679 (7.279)	prob 2.332 (2.764)	GS 34.422 (33.129)	mem 74.353
Train: [64][1060/1500]	BT 0.036 (0.262)	DT 0.001 (0.226)	loss 7.417 (7.181)	prob 3.757 (2.952)	GS 31.594 (35.028)	mem 74.357
Train: [64][1070/1500]	BT 0.067 (0.261)	DT 0.011 (0.224)	loss 7.493 (7.202)	prob 3.174 (2.991)	GS 35.312 (33.400)	mem 74.356
Train: [64][1080/1500]	BT 0.057 (0.264)	DT 0.013 (0.228)	loss 7.240 (7.182)	prob 3.905 (3.064)	GS 32.750 (32.797)	mem 74.357
Train: [64][1090/1500]	BT 0.057 (0.264)	DT 0.000 (0.228)	loss 7.350 (7.193)	prob 3.242 (3.026)	GS 31.953 (32.776)	mem 74.357
Train: [64][1100/1500]	BT 0.087 (0.267)	DT 0.007 (0.230)	loss 7.156 (7.184)	prob 3.006 (3.029)	GS 31.969 (32.623)	mem 74.356
Train: [64][1110/1500]	BT 0.028 (0.280)	DT 0.000 (0.243)	loss 6.969 (7.219)	prob 2.800 (2.844)	GS 32.781 (33.219)	mem 74.360
Train: [64][1120/1500]	BT 0.029 (0.278)	DT 0.000 (0.241)	loss 7.200 (7.183)	prob 2.888 (3.143)	GS 35.000 (32.973)	mem 74.361
Train: [64][1130/1500]	BT 2.649 (0.278)	DT 2.612 (0.241)	loss 7.260 (7.169)	prob 2.901 (3.153)	GS 36.969 (33.728)	mem 74.364
Train: [64][1140/1500]	BT 0.038 (0.276)	DT 0.001 (0.239)	loss 7.616 (7.178)	prob 2.376 (3.141)	GS 31.953 (33.509)	mem 74.365
Train: [64][1150/1500]	BT 0.038 (0.274)	DT 0.000 (0.237)	loss 6.930 (7.164)	prob 3.665 (3.087)	GS 39.312 (33.385)	mem 74.366
Train: [64][1160/1500]	BT 0.027 (0.277)	DT 0.000 (0.240)	loss 7.582 (7.188)	prob 2.430 (2.725)	GS 33.594 (33.692)	mem 74.369
Train: [64][1170/1500]	BT 0.037 (0.275)	DT 0.001 (0.238)	loss 6.893 (7.114)	prob 3.721 (2.959)	GS 36.453 (32.845)	mem 74.369
Train: [64][1180/1500]	BT 0.038 (0.275)	DT 0.001 (0.238)	loss 7.177 (7.111)	prob 3.210 (2.928)	GS 34.578 (32.995)	mem 74.372
Train: [64][1190/1500]	BT 0.038 (0.273)	DT 0.001 (0.236)	loss 7.252 (7.106)	prob 3.656 (3.075)	GS 35.656 (33.019)	mem 74.372
Train: [64][1200/1500]	BT 0.038 (0.271)	DT 0.001 (0.234)	loss 7.307 (7.121)	prob 3.141 (3.083)	GS 33.031 (33.338)	mem 74.373
Train: [64][1210/1500]	BT 0.073 (0.274)	DT 0.005 (0.236)	loss 6.936 (7.142)	prob 3.912 (3.263)	GS 32.641 (33.073)	mem 74.374
Train: [64][1220/1500]	BT 0.042 (0.272)	DT 0.000 (0.234)	loss 7.483 (7.152)	prob 3.069 (3.327)	GS 31.641 (32.948)	mem 74.374
Train: [64][1230/1500]	BT 0.036 (0.280)	DT 0.002 (0.242)	loss 7.101 (7.165)	prob 3.337 (3.372)	GS 35.891 (33.721)	mem 74.373
Train: [64][1240/1500]	BT 0.076 (0.278)	DT 0.011 (0.240)	loss 6.849 (7.161)	prob 3.644 (3.396)	GS 32.000 (33.397)	mem 74.374
Train: [64][1250/1500]	BT 0.027 (0.290)	DT 0.000 (0.253)	loss 7.522 (7.157)	prob 3.846 (3.391)	GS 32.188 (33.353)	mem 74.373
Train: [64][1260/1500]	BT 0.026 (0.288)	DT 0.000 (0.251)	loss 6.897 (7.116)	prob 3.007 (3.412)	GS 33.688 (32.205)	mem 74.373
Train: [64][1270/1500]	BT 0.027 (0.289)	DT 0.000 (0.252)	loss 7.236 (7.198)	prob 3.239 (3.261)	GS 34.375 (32.277)	mem 74.372
Train: [64][1280/1500]	BT 0.025 (0.287)	DT 0.000 (0.250)	loss 7.288 (7.207)	prob 3.826 (3.184)	GS 31.875 (32.970)	mem 74.372
Train: [64][1290/1500]	BT 0.037 (0.289)	DT 0.001 (0.251)	loss 6.995 (7.165)	prob 3.659 (3.263)	GS 33.703 (32.946)	mem 74.374
Train: [64][1300/1500]	BT 0.037 (0.287)	DT 0.001 (0.249)	loss 6.829 (7.167)	prob 3.537 (3.262)	GS 35.062 (32.864)	mem 74.374
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [64][1310/1500]	BT 0.038 (0.285)	DT 0.001 (0.248)	loss 7.173 (7.132)	prob 3.454 (3.313)	GS 29.000 (32.114)	mem 74.373
Train: [64][1320/1500]	BT 0.038 (0.285)	DT 0.000 (0.248)	loss 6.973 (7.161)	prob 3.791 (3.320)	GS 34.422 (31.642)	mem 74.373
Train: [64][1330/1500]	BT 0.038 (0.283)	DT 0.001 (0.246)	loss 6.931 (7.145)	prob 3.483 (3.258)	GS 36.859 (32.315)	mem 74.373
Train: [64][1340/1500]	BT 0.059 (0.287)	DT 0.011 (0.249)	loss 7.612 (7.137)	prob 2.501 (3.244)	GS 34.625 (32.354)	mem 74.376
Train: [64][1350/1500]	BT 0.083 (0.285)	DT 0.009 (0.248)	loss 7.213 (7.120)	prob 3.269 (3.252)	GS 35.625 (32.516)	mem 74.376
Train: [64][1360/1500]	BT 0.083 (0.284)	DT 0.003 (0.246)	loss 6.796 (7.045)	prob 3.417 (3.143)	GS 36.500 (33.394)	mem 74.377
Train: [64][1370/1500]	BT 0.034 (0.288)	DT 0.000 (0.250)	loss 6.862 (7.074)	prob 3.217 (3.111)	GS 33.891 (33.019)	mem 74.378
Train: [64][1380/1500]	BT 0.039 (0.291)	DT 0.000 (0.253)	loss 7.200 (7.065)	prob 3.229 (3.076)	GS 34.156 (33.491)	mem 74.409
Train: [64][1390/1500]	BT 0.038 (0.289)	DT 0.000 (0.251)	loss 7.141 (7.071)	prob 2.571 (2.978)	GS 37.125 (33.382)	mem 74.410
Train: [64][1400/1500]	BT 0.039 (0.287)	DT 0.001 (0.249)	loss 7.259 (7.076)	prob 2.620 (2.978)	GS 28.688 (33.038)	mem 74.409
Train: [64][1410/1500]	BT 0.039 (0.288)	DT 0.001 (0.250)	loss 7.176 (7.126)	prob 2.961 (3.168)	GS 36.391 (32.797)	mem 74.411
Train: [64][1420/1500]	BT 0.039 (0.286)	DT 0.001 (0.248)	loss 7.146 (7.123)	prob 2.917 (3.090)	GS 35.688 (32.904)	mem 74.410
Train: [64][1430/1500]	BT 0.039 (0.287)	DT 0.001 (0.249)	loss 7.008 (7.094)	prob 3.200 (3.073)	GS 35.969 (32.846)	mem 74.410
Train: [64][1440/1500]	BT 0.038 (0.285)	DT 0.001 (0.247)	loss 7.093 (7.106)	prob 3.030 (3.065)	GS 30.625 (32.575)	mem 74.411
Train: [64][1450/1500]	BT 0.038 (0.286)	DT 0.001 (0.248)	loss 7.245 (7.113)	prob 3.225 (3.043)	GS 33.031 (32.474)	mem 74.305
Train: [64][1460/1500]	BT 0.027 (0.285)	DT 0.000 (0.247)	loss 7.202 (7.027)	prob 2.154 (2.766)	GS 36.203 (33.206)	mem 74.199
Train: [64][1470/1500]	BT 0.038 (0.283)	DT 0.001 (0.245)	loss 6.952 (7.023)	prob 3.299 (2.932)	GS 32.797 (32.552)	mem 74.126
Train: [64][1480/1500]	BT 0.026 (0.283)	DT 0.000 (0.245)	loss 7.081 (7.073)	prob 2.856 (2.908)	GS 33.047 (32.455)	mem 20.522
Train: [64][1490/1500]	BT 0.021 (0.281)	DT 0.000 (0.244)	loss 6.877 (7.070)	prob 2.938 (2.869)	GS 34.688 (32.234)	mem 15.010
Train: [64][1500/1500]	BT 0.034 (0.280)	DT 0.000 (0.242)	loss 6.692 (7.059)	prob 3.094 (2.914)	GS 34.094 (32.235)	mem 12.132
Train: [64][1510/1500]	BT 0.025 (0.279)	DT 0.000 (0.241)	loss 7.156 (6.871)	prob 2.612 (2.778)	GS 41.562 (33.903)	mem 9.319
epoch 64, total time 420.97
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [65][1/1500]	BT 21.334 (21.334)	DT 21.276 (21.276)	loss 6.654 (6.654)	prob 3.279 (3.279)	GS 34.453 (34.453)	mem 73.121
Train: [65][10/1500]	BT 0.083 (2.381)	DT 0.014 (2.325)	loss 6.563 (6.787)	prob 2.061 (2.487)	GS 33.938 (32.097)	mem 73.173
Train: [65][20/1500]	BT 0.029 (1.218)	DT 0.000 (1.167)	loss 6.927 (6.762)	prob 2.663 (2.678)	GS 32.609 (33.674)	mem 73.173
Train: [65][30/1500]	BT 0.331 (0.938)	DT 0.292 (0.893)	loss 6.897 (6.810)	prob 3.004 (2.750)	GS 29.422 (32.951)	mem 73.212
Train: [65][40/1500]	BT 0.037 (0.735)	DT 0.000 (0.692)	loss 6.951 (6.827)	prob 2.662 (2.703)	GS 27.469 (32.526)	mem 73.206
Train: [65][50/1500]	BT 0.033 (0.654)	DT 0.000 (0.612)	loss 6.909 (6.834)	prob 2.893 (2.723)	GS 31.625 (32.157)	mem 73.223
Train: [65][60/1500]	BT 0.037 (0.576)	DT 0.000 (0.534)	loss 6.763 (6.951)	prob 2.695 (2.898)	GS 30.156 (31.178)	mem 73.254
Train: [65][70/1500]	BT 0.028 (0.504)	DT 0.000 (0.464)	loss 6.846 (6.951)	prob 2.948 (2.930)	GS 31.375 (31.115)	mem 73.261
Train: [65][80/1500]	BT 0.037 (0.494)	DT 0.001 (0.455)	loss 6.790 (6.908)	prob 2.762 (2.848)	GS 32.531 (31.366)	mem 73.176
Train: [65][90/1500]	BT 0.064 (0.444)	DT 0.004 (0.404)	loss 6.990 (6.900)	prob 2.709 (2.803)	GS 28.641 (31.258)	mem 73.183
Train: [65][100/1500]	BT 0.032 (0.423)	DT 0.000 (0.381)	loss 6.667 (6.896)	prob 2.961 (2.762)	GS 37.375 (31.721)	mem 73.186
Train: [65][110/1500]	BT 0.063 (0.414)	DT 0.011 (0.372)	loss 6.975 (6.835)	prob 2.488 (2.680)	GS 32.984 (30.758)	mem 73.191
Train: [65][120/1500]	BT 0.036 (0.384)	DT 0.000 (0.342)	loss 6.662 (6.834)	prob 3.043 (2.621)	GS 31.703 (31.892)	mem 73.193
Train: [65][130/1500]	BT 0.061 (0.398)	DT 0.006 (0.356)	loss 6.748 (6.842)	prob 3.006 (2.494)	GS 34.078 (31.901)	mem 73.197
Train: [65][140/1500]	BT 0.060 (0.373)	DT 0.001 (0.331)	loss 7.039 (6.865)	prob 2.310 (2.468)	GS 36.156 (32.004)	mem 73.198
Train: [65][150/1500]	BT 0.055 (0.376)	DT 0.006 (0.334)	loss 6.785 (6.869)	prob 3.032 (2.528)	GS 33.531 (32.349)	mem 73.202
Train: [65][160/1500]	BT 0.028 (0.379)	DT 0.000 (0.337)	loss 7.182 (7.000)	prob 2.885 (2.563)	GS 29.297 (33.391)	mem 73.221
Train: [65][170/1500]	BT 0.038 (0.359)	DT 0.001 (0.317)	loss 7.039 (6.987)	prob 3.109 (2.782)	GS 29.719 (32.938)	mem 73.222
Train: [65][180/1500]	BT 0.083 (0.374)	DT 0.007 (0.332)	loss 6.836 (6.938)	prob 2.810 (2.845)	GS 32.422 (32.832)	mem 73.226
Train: [65][190/1500]	BT 0.068 (0.359)	DT 0.004 (0.315)	loss 7.010 (6.938)	prob 2.875 (2.847)	GS 29.781 (32.701)	mem 73.228
Train: [65][200/1500]	BT 0.066 (0.345)	DT 0.006 (0.299)	loss 6.884 (6.916)	prob 2.877 (2.871)	GS 35.812 (32.696)	mem 73.227
Train: [65][210/1500]	BT 0.029 (0.407)	DT 0.000 (0.362)	loss 6.984 (6.895)	prob 2.360 (2.579)	GS 36.203 (33.331)	mem 73.217
Train: [65][220/1500]	BT 0.028 (0.390)	DT 0.000 (0.346)	loss 6.842 (6.920)	prob 2.578 (2.542)	GS 37.281 (33.181)	mem 73.218
Train: [65][230/1500]	BT 0.028 (0.387)	DT 0.001 (0.343)	loss 6.743 (6.911)	prob 3.267 (2.537)	GS 34.781 (33.386)	mem 73.221
Train: [65][240/1500]	BT 0.025 (0.372)	DT 0.000 (0.329)	loss 6.629 (6.906)	prob 2.984 (2.494)	GS 33.906 (33.312)	mem 73.223
Train: [65][250/1500]	BT 0.033 (0.359)	DT 0.000 (0.316)	loss 6.793 (6.904)	prob 2.808 (2.592)	GS 33.141 (33.401)	mem 73.223
Train: [65][260/1500]	BT 0.039 (0.357)	DT 0.001 (0.315)	loss 6.744 (6.906)	prob 3.067 (2.725)	GS 36.000 (33.472)	mem 73.227
Train: [65][270/1500]	BT 0.039 (0.346)	DT 0.001 (0.303)	loss 6.811 (6.934)	prob 2.572 (2.566)	GS 33.391 (32.930)	mem 73.227
Train: [65][280/1500]	BT 0.039 (0.347)	DT 0.001 (0.304)	loss 6.892 (6.916)	prob 2.547 (2.662)	GS 31.812 (32.170)	mem 73.229
Train: [65][290/1500]	BT 0.060 (0.336)	DT 0.022 (0.294)	loss 6.870 (6.900)	prob 2.373 (2.572)	GS 31.656 (32.086)	mem 73.229
Train: [65][300/1500]	BT 0.037 (0.343)	DT 0.000 (0.301)	loss 7.027 (6.902)	prob 2.796 (2.567)	GS 33.828 (32.056)	mem 73.243
Train: [65][310/1500]	BT 0.037 (0.333)	DT 0.001 (0.291)	loss 6.827 (6.803)	prob 3.015 (2.603)	GS 29.203 (32.366)	mem 73.245
Train: [65][320/1500]	BT 0.038 (0.324)	DT 0.001 (0.282)	loss 6.785 (6.832)	prob 2.570 (2.626)	GS 34.875 (32.048)	mem 73.247
Train: [65][330/1500]	BT 0.037 (0.334)	DT 0.001 (0.293)	loss 6.609 (6.815)	prob 2.943 (2.726)	GS 33.312 (31.853)	mem 73.250
Train: [65][340/1500]	BT 0.038 (0.326)	DT 0.000 (0.284)	loss 6.741 (6.821)	prob 2.757 (2.637)	GS 34.172 (32.002)	mem 73.250
Train: [65][350/1500]	BT 0.037 (0.327)	DT 0.001 (0.286)	loss 6.910 (6.830)	prob 2.175 (2.600)	GS 38.328 (32.154)	mem 73.253
Train: [65][360/1500]	BT 0.182 (0.320)	DT 0.145 (0.279)	loss 6.814 (6.887)	prob 2.378 (2.306)	GS 32.297 (32.216)	mem 73.254
Train: [65][370/1500]	BT 0.037 (0.312)	DT 0.000 (0.271)	loss 6.940 (6.868)	prob 2.659 (2.463)	GS 32.969 (32.502)	mem 73.255
Train: [65][380/1500]	BT 0.037 (0.312)	DT 0.001 (0.271)	loss 6.835 (6.858)	prob 2.734 (2.461)	GS 32.719 (32.433)	mem 73.257
Train: [65][390/1500]	BT 0.037 (0.309)	DT 0.001 (0.269)	loss 6.828 (6.856)	prob 2.469 (2.405)	GS 37.266 (32.757)	mem 73.259
Train: [65][400/1500]	BT 0.037 (0.306)	DT 0.001 (0.265)	loss 6.920 (6.848)	prob 2.348 (2.434)	GS 36.266 (32.972)	mem 73.311
Train: [65][410/1500]	BT 0.033 (0.305)	DT 0.000 (0.264)	loss 6.879 (6.897)	prob 2.578 (2.367)	GS 33.688 (32.158)	mem 73.460
Train: [65][420/1500]	BT 0.037 (0.299)	DT 0.001 (0.259)	loss 6.776 (6.869)	prob 2.484 (2.398)	GS 33.328 (32.006)	mem 73.461
Train: [65][430/1500]	BT 0.038 (0.301)	DT 0.001 (0.261)	loss 6.709 (6.833)	prob 2.852 (2.413)	GS 32.203 (31.702)	mem 73.936
Train: [65][440/1500]	BT 0.038 (0.295)	DT 0.001 (0.255)	loss 6.800 (6.835)	prob 2.117 (2.339)	GS 37.672 (31.771)	mem 74.150
Train: [65][450/1500]	BT 0.061 (0.298)	DT 0.023 (0.258)	loss 6.812 (6.830)	prob 2.327 (2.314)	GS 38.375 (31.985)	mem 74.399
Train: [65][460/1500]	BT 0.025 (0.323)	DT 0.000 (0.283)	loss 6.817 (6.819)	prob 2.196 (2.409)	GS 32.688 (32.822)	mem 74.450
Train: [65][470/1500]	BT 0.030 (0.317)	DT 0.000 (0.277)	loss 6.657 (6.795)	prob 2.449 (2.478)	GS 34.031 (32.595)	mem 74.453
Train: [65][480/1500]	BT 0.024 (0.311)	DT 0.000 (0.271)	loss 7.024 (6.796)	prob 1.965 (2.420)	GS 31.219 (32.647)	mem 74.452
Train: [65][490/1500]	BT 0.029 (0.313)	DT 0.000 (0.273)	loss 6.791 (6.794)	prob 2.348 (2.423)	GS 36.531 (33.162)	mem 74.454
Train: [65][500/1500]	BT 0.037 (0.308)	DT 0.000 (0.268)	loss 6.750 (6.791)	prob 1.969 (2.394)	GS 35.156 (33.033)	mem 74.456
Train: [65][510/1500]	BT 0.035 (0.309)	DT 0.000 (0.269)	loss 6.938 (6.856)	prob 2.824 (2.805)	GS 30.516 (31.806)	mem 74.458
Train: [65][520/1500]	BT 0.034 (0.304)	DT 0.000 (0.264)	loss 6.679 (6.824)	prob 2.168 (2.647)	GS 31.891 (32.109)	mem 74.458
Train: [65][530/1500]	BT 0.033 (0.298)	DT 0.000 (0.259)	loss 6.850 (6.815)	prob 1.710 (2.459)	GS 37.938 (32.465)	mem 74.458
Train: [65][540/1500]	BT 0.038 (0.306)	DT 0.000 (0.267)	loss 6.823 (6.807)	prob 2.404 (2.444)	GS 32.031 (32.554)	mem 74.457
Train: [65][550/1500]	BT 0.038 (0.301)	DT 0.000 (0.262)	loss 6.781 (6.806)	prob 2.123 (2.439)	GS 36.688 (32.516)	mem 74.458
Train: [65][560/1500]	BT 0.045 (0.307)	DT 0.000 (0.267)	loss 6.843 (6.802)	prob 1.900 (2.288)	GS 37.594 (33.341)	mem 74.460
Train: [65][570/1500]	BT 0.037 (0.302)	DT 0.000 (0.262)	loss 6.864 (6.814)	prob 2.186 (2.381)	GS 35.781 (33.659)	mem 74.462
Train: [65][580/1500]	BT 0.037 (0.302)	DT 0.001 (0.263)	loss 6.907 (6.809)	prob 2.742 (2.475)	GS 32.406 (33.391)	mem 74.464
Train: [65][590/1500]	BT 0.038 (0.298)	DT 0.000 (0.258)	loss 6.631 (6.786)	prob 2.625 (2.501)	GS 33.672 (32.889)	mem 74.463
Train: [65][600/1500]	BT 0.038 (0.293)	DT 0.001 (0.254)	loss 6.770 (6.784)	prob 2.347 (2.504)	GS 35.828 (33.029)	mem 74.463
Train: [65][610/1500]	BT 0.053 (0.302)	DT 0.009 (0.262)	loss 6.818 (6.803)	prob 2.289 (2.511)	GS 35.875 (32.773)	mem 74.462
Train: [65][620/1500]	BT 0.115 (0.298)	DT 0.003 (0.258)	loss 6.916 (6.800)	prob 2.233 (2.329)	GS 36.781 (32.416)	mem 74.462
Train: [65][630/1500]	BT 0.061 (0.314)	DT 0.003 (0.274)	loss 6.720 (6.799)	prob 2.301 (2.369)	GS 32.250 (32.308)	mem 74.464
Train: [65][640/1500]	BT 0.030 (0.325)	DT 0.000 (0.285)	loss 6.741 (6.796)	prob 2.478 (2.391)	GS 34.328 (32.556)	mem 74.498
Train: [65][650/1500]	BT 0.028 (0.323)	DT 0.000 (0.283)	loss 7.047 (6.810)	prob 2.361 (2.415)	GS 35.000 (32.839)	mem 74.498
Train: [65][660/1500]	BT 0.038 (0.321)	DT 0.001 (0.281)	loss 6.692 (6.810)	prob 3.548 (2.578)	GS 34.891 (32.945)	mem 74.500
Train: [65][670/1500]	BT 0.052 (0.323)	DT 0.009 (0.284)	loss 6.693 (6.826)	prob 3.116 (2.574)	GS 33.328 (33.488)	mem 74.499
Train: [65][680/1500]	BT 0.048 (0.321)	DT 0.016 (0.281)	loss 6.802 (6.803)	prob 2.475 (2.603)	GS 31.578 (32.885)	mem 74.500
Train: [65][690/1500]	BT 0.039 (0.320)	DT 0.001 (0.280)	loss 6.642 (6.778)	prob 2.220 (2.618)	GS 33.703 (33.014)	mem 74.499
Train: [65][700/1500]	BT 0.038 (0.319)	DT 0.001 (0.279)	loss 6.843 (6.777)	prob 2.507 (2.585)	GS 33.453 (32.729)	mem 74.499
Train: [65][710/1500]	BT 0.052 (0.320)	DT 0.000 (0.280)	loss 6.738 (6.701)	prob 2.696 (2.459)	GS 38.406 (31.980)	mem 74.499
Train: [65][720/1500]	BT 0.060 (0.317)	DT 0.001 (0.277)	loss 6.901 (6.732)	prob 2.529 (2.542)	GS 35.172 (31.692)	mem 74.498
Train: [65][730/1500]	BT 0.043 (0.326)	DT 0.000 (0.286)	loss 6.967 (6.731)	prob 2.239 (2.477)	GS 36.609 (31.731)	mem 74.499
Train: [65][740/1500]	BT 0.062 (0.322)	DT 0.011 (0.282)	loss 6.808 (6.720)	prob 2.891 (2.476)	GS 31.594 (31.914)	mem 74.501
Train: [65][750/1500]	BT 0.033 (0.337)	DT 0.000 (0.297)	loss 6.762 (6.736)	prob 3.021 (2.555)	GS 33.078 (32.382)	mem 74.502
Train: [65][760/1500]	BT 0.034 (0.333)	DT 0.001 (0.293)	loss 6.718 (6.730)	prob 3.415 (2.725)	GS 33.484 (32.300)	mem 74.502
Train: [65][770/1500]	BT 0.038 (0.329)	DT 0.001 (0.289)	loss 6.511 (6.717)	prob 3.093 (2.764)	GS 34.688 (33.574)	mem 74.502
Train: [65][780/1500]	BT 0.038 (0.329)	DT 0.001 (0.289)	loss 6.907 (6.734)	prob 2.179 (2.799)	GS 32.359 (33.342)	mem 74.502
Train: [65][790/1500]	BT 0.039 (0.325)	DT 0.000 (0.285)	loss 6.695 (6.745)	prob 2.347 (2.753)	GS 30.703 (32.946)	mem 74.503
Train: [65][800/1500]	BT 0.028 (0.327)	DT 0.000 (0.288)	loss 6.733 (6.748)	prob 2.197 (2.710)	GS 33.562 (32.757)	mem 74.504
Train: [65][810/1500]	BT 0.026 (0.324)	DT 0.000 (0.284)	loss 7.067 (6.815)	prob 2.116 (2.380)	GS 31.266 (32.623)	mem 74.505
Train: [65][820/1500]	BT 0.053 (0.325)	DT 0.001 (0.286)	loss 6.804 (6.773)	prob 2.201 (2.492)	GS 33.125 (31.913)	mem 74.505
Train: [65][830/1500]	BT 0.029 (0.322)	DT 0.000 (0.282)	loss 6.636 (6.747)	prob 2.381 (2.476)	GS 28.500 (31.790)	mem 74.507
Train: [65][840/1500]	BT 0.039 (0.318)	DT 0.001 (0.279)	loss 6.541 (6.737)	prob 2.122 (2.505)	GS 33.656 (31.946)	mem 74.510
Train: [65][850/1500]	BT 0.038 (0.319)	DT 0.001 (0.280)	loss 6.717 (6.731)	prob 2.081 (2.492)	GS 35.438 (31.847)	mem 74.511
Train: [65][860/1500]	BT 0.039 (0.316)	DT 0.001 (0.277)	loss 6.998 (6.768)	prob 1.980 (2.699)	GS 33.188 (33.473)	mem 74.510
Train: [65][870/1500]	BT 0.031 (0.317)	DT 0.001 (0.278)	loss 6.761 (6.740)	prob 2.783 (2.600)	GS 31.875 (33.078)	mem 74.516
Train: [65][880/1500]	BT 0.028 (0.314)	DT 0.000 (0.275)	loss 6.959 (6.749)	prob 2.073 (2.502)	GS 38.031 (33.025)	mem 74.517
Train: [65][890/1500]	BT 0.025 (0.311)	DT 0.000 (0.272)	loss 6.679 (6.741)	prob 3.105 (2.468)	GS 32.078 (32.772)	mem 74.517
Train: [65][900/1500]	BT 0.040 (0.327)	DT 0.000 (0.288)	loss 6.906 (6.755)	prob 1.972 (2.497)	GS 34.609 (32.832)	mem 74.526
Train: [65][910/1500]	BT 0.022 (0.324)	DT 0.000 (0.285)	loss 6.585 (6.688)	prob 2.993 (2.617)	GS 38.297 (31.972)	mem 74.527
Train: [65][920/1500]	BT 0.033 (0.321)	DT 0.000 (0.282)	loss 6.653 (6.693)	prob 2.219 (2.727)	GS 36.828 (32.277)	mem 74.527
Train: [65][930/1500]	BT 0.037 (0.321)	DT 0.000 (0.282)	loss 6.545 (6.699)	prob 2.744 (2.655)	GS 33.703 (32.289)	mem 74.548
Train: [65][940/1500]	BT 0.066 (0.318)	DT 0.007 (0.279)	loss 6.712 (6.704)	prob 2.377 (2.691)	GS 30.109 (32.377)	mem 74.547
Train: [65][950/1500]	BT 0.037 (0.322)	DT 0.000 (0.283)	loss 6.849 (6.706)	prob 2.009 (2.702)	GS 29.297 (32.308)	mem 74.426
Train: [65][960/1500]	BT 0.037 (0.319)	DT 0.000 (0.280)	loss 6.686 (6.756)	prob 2.375 (2.287)	GS 32.109 (32.837)	mem 74.427
Train: [65][970/1500]	BT 3.155 (0.319)	DT 3.118 (0.280)	loss 6.626 (6.744)	prob 2.803 (2.443)	GS 33.703 (33.155)	mem 74.426
Train: [65][980/1500]	BT 0.037 (0.316)	DT 0.001 (0.277)	loss 6.805 (6.752)	prob 2.497 (2.536)	GS 35.469 (33.565)	mem 74.426
Train: [65][990/1500]	BT 0.037 (0.314)	DT 0.001 (0.275)	loss 6.610 (6.744)	prob 2.964 (2.571)	GS 34.703 (33.370)	mem 74.426
Train: [65][1000/1500]	BT 0.035 (0.316)	DT 0.000 (0.277)	loss 6.858 (6.742)	prob 2.670 (2.555)	GS 35.219 (33.327)	mem 74.425
Train: [65][1010/1500]	BT 0.026 (0.314)	DT 0.000 (0.275)	loss 6.745 (6.763)	prob 2.687 (2.797)	GS 34.203 (32.911)	mem 74.426
Train: [65][1020/1500]	BT 0.038 (0.314)	DT 0.001 (0.275)	loss 6.792 (6.762)	prob 3.067 (2.671)	GS 33.812 (32.462)	mem 74.447
Train: [65][1030/1500]	BT 0.037 (0.312)	DT 0.001 (0.273)	loss 6.736 (6.744)	prob 1.949 (2.559)	GS 32.688 (32.278)	mem 74.448
Train: [65][1040/1500]	BT 0.037 (0.309)	DT 0.001 (0.270)	loss 6.903 (6.742)	prob 2.057 (2.559)	GS 34.000 (32.850)	mem 74.448
Train: [65][1050/1500]	BT 0.054 (0.310)	DT 0.001 (0.272)	loss 6.588 (6.728)	prob 3.679 (2.640)	GS 32.875 (33.098)	mem 74.452
Train: [65][1060/1500]	BT 0.029 (0.312)	DT 0.000 (0.273)	loss 6.895 (6.778)	prob 2.816 (2.686)	GS 34.094 (32.948)	mem 74.450
Train: [65][1070/1500]	BT 0.039 (0.310)	DT 0.001 (0.271)	loss 7.042 (6.763)	prob 2.336 (2.539)	GS 35.109 (32.875)	mem 74.450
Train: [65][1080/1500]	BT 0.039 (0.311)	DT 0.001 (0.272)	loss 6.596 (6.720)	prob 3.094 (2.537)	GS 32.188 (32.530)	mem 74.435
Train: [65][1090/1500]	BT 1.032 (0.309)	DT 0.995 (0.270)	loss 6.636 (6.706)	prob 3.125 (2.562)	GS 32.328 (32.631)	mem 74.436
Train: [65][1100/1500]	BT 0.039 (0.307)	DT 0.001 (0.268)	loss 6.715 (6.707)	prob 2.013 (2.515)	GS 32.625 (32.657)	mem 74.436
Train: [65][1110/1500]	BT 0.024 (0.312)	DT 0.000 (0.274)	loss 6.745 (6.721)	prob 3.411 (3.208)	GS 35.984 (35.205)	mem 74.437
Train: [65][1120/1500]	BT 0.039 (0.310)	DT 0.001 (0.271)	loss 6.679 (6.694)	prob 2.299 (2.868)	GS 32.516 (33.602)	mem 74.438
Train: [65][1130/1500]	BT 0.028 (0.310)	DT 0.000 (0.272)	loss 7.012 (6.690)	prob 2.111 (2.813)	GS 33.141 (33.222)	mem 74.439
Train: [65][1140/1500]	BT 0.040 (0.308)	DT 0.001 (0.269)	loss 6.553 (6.674)	prob 3.165 (2.743)	GS 33.828 (32.990)	mem 74.441
Train: [65][1150/1500]	BT 0.040 (0.306)	DT 0.001 (0.267)	loss 6.617 (6.673)	prob 2.236 (2.715)	GS 34.656 (32.984)	mem 74.441
Train: [65][1160/1500]	BT 0.036 (0.309)	DT 0.001 (0.270)	loss 6.713 (6.657)	prob 2.052 (2.379)	GS 29.641 (32.892)	mem 74.442
Train: [65][1170/1500]	BT 0.028 (0.306)	DT 0.000 (0.268)	loss 6.694 (6.667)	prob 2.145 (2.503)	GS 33.031 (32.775)	mem 74.443
Train: [65][1180/1500]	BT 0.030 (0.308)	DT 0.000 (0.269)	loss 6.730 (6.667)	prob 2.169 (2.501)	GS 35.891 (33.013)	mem 74.460
Train: [65][1190/1500]	BT 0.026 (0.305)	DT 0.000 (0.267)	loss 6.664 (6.671)	prob 3.083 (2.492)	GS 35.281 (33.321)	mem 74.459
Train: [65][1200/1500]	BT 0.037 (0.303)	DT 0.001 (0.265)	loss 6.699 (6.671)	prob 2.555 (2.528)	GS 39.078 (33.317)	mem 74.461
Train: [65][1210/1500]	BT 0.023 (0.304)	DT 0.000 (0.266)	loss 6.696 (6.700)	prob 2.851 (2.740)	GS 31.297 (33.381)	mem 74.463
Train: [65][1220/1500]	BT 0.024 (0.302)	DT 0.000 (0.264)	loss 6.704 (6.678)	prob 3.087 (2.612)	GS 37.312 (32.909)	mem 74.464
Train: [65][1230/1500]	BT 0.026 (0.303)	DT 0.000 (0.265)	loss 6.559 (6.665)	prob 2.620 (2.652)	GS 33.328 (33.166)	mem 74.465
Train: [65][1240/1500]	BT 0.036 (0.301)	DT 0.000 (0.263)	loss 6.791 (6.668)	prob 2.185 (2.598)	GS 35.453 (33.284)	mem 74.466
Train: [65][1250/1500]	BT 0.030 (0.302)	DT 0.000 (0.265)	loss 6.687 (6.667)	prob 2.412 (2.550)	GS 29.234 (33.287)	mem 74.466
Train: [65][1260/1500]	BT 0.031 (0.300)	DT 0.000 (0.262)	loss 6.653 (6.701)	prob 2.639 (2.418)	GS 37.734 (32.153)	mem 74.467
Train: [65][1270/1500]	BT 0.037 (0.298)	DT 0.000 (0.260)	loss 6.597 (6.673)	prob 2.156 (2.497)	GS 31.297 (31.652)	mem 74.469
Train: [65][1280/1500]	BT 0.029 (0.300)	DT 0.000 (0.262)	loss 6.837 (6.674)	prob 2.206 (2.453)	GS 33.750 (32.165)	mem 74.472
Train: [65][1290/1500]	BT 0.026 (0.298)	DT 0.000 (0.260)	loss 6.813 (6.679)	prob 1.990 (2.413)	GS 37.469 (32.052)	mem 74.471
Train: [65][1300/1500]	BT 0.031 (0.299)	DT 0.000 (0.261)	loss 6.808 (6.682)	prob 2.485 (2.407)	GS 37.891 (32.112)	mem 74.475
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [65][1310/1500]	BT 0.062 (0.297)	DT 0.007 (0.259)	loss 6.695 (6.683)	prob 2.658 (2.440)	GS 30.172 (30.708)	mem 74.474
Train: [65][1320/1500]	BT 0.031 (0.295)	DT 0.000 (0.257)	loss 7.060 (6.696)	prob 1.803 (2.505)	GS 33.344 (31.402)	mem 74.474
Train: [65][1330/1500]	BT 0.026 (0.314)	DT 0.000 (0.276)	loss 6.793 (6.690)	prob 2.293 (2.470)	GS 34.188 (31.877)	mem 74.474
Train: [65][1340/1500]	BT 0.030 (0.312)	DT 0.000 (0.274)	loss 6.595 (6.696)	prob 2.970 (2.430)	GS 33.328 (31.941)	mem 74.474
Train: [65][1350/1500]	BT 0.037 (0.311)	DT 0.001 (0.273)	loss 6.779 (6.704)	prob 2.346 (2.457)	GS 36.062 (32.378)	mem 74.476
Train: [65][1360/1500]	BT 0.037 (0.310)	DT 0.000 (0.272)	loss 6.743 (6.673)	prob 2.452 (2.613)	GS 33.047 (33.509)	mem 74.478
Train: [65][1370/1500]	BT 0.027 (0.308)	DT 0.000 (0.270)	loss 6.587 (6.684)	prob 2.635 (2.560)	GS 34.547 (33.165)	mem 74.479
Train: [65][1380/1500]	BT 0.037 (0.308)	DT 0.001 (0.271)	loss 6.597 (6.665)	prob 2.346 (2.522)	GS 33.781 (33.228)	mem 74.481
Train: [65][1390/1500]	BT 0.038 (0.306)	DT 0.001 (0.269)	loss 6.538 (6.678)	prob 2.992 (2.576)	GS 32.172 (32.910)	mem 74.481
Train: [65][1400/1500]	BT 0.037 (0.307)	DT 0.001 (0.270)	loss 6.640 (6.688)	prob 2.649 (2.539)	GS 33.016 (32.616)	mem 74.483
Train: [65][1410/1500]	BT 0.038 (0.305)	DT 0.001 (0.268)	loss 6.678 (6.635)	prob 2.638 (2.574)	GS 34.250 (34.431)	mem 74.483
Train: [65][1420/1500]	BT 2.483 (0.305)	DT 2.436 (0.268)	loss 6.560 (6.665)	prob 2.236 (2.500)	GS 34.125 (33.473)	mem 74.483
Train: [65][1430/1500]	BT 0.028 (0.306)	DT 0.000 (0.269)	loss 6.733 (6.680)	prob 2.762 (2.439)	GS 32.125 (32.941)	mem 74.483
Train: [65][1440/1500]	BT 0.038 (0.304)	DT 0.001 (0.267)	loss 6.646 (6.685)	prob 2.198 (2.419)	GS 32.750 (32.797)	mem 74.483
Train: [65][1450/1500]	BT 0.041 (0.306)	DT 0.001 (0.268)	loss 6.577 (6.668)	prob 2.615 (2.450)	GS 36.359 (32.669)	mem 74.263
Train: [65][1460/1500]	BT 0.032 (0.304)	DT 0.000 (0.267)	loss 6.616 (6.673)	prob 2.304 (2.353)	GS 30.609 (30.378)	mem 74.263
Train: [65][1470/1500]	BT 0.041 (0.302)	DT 0.001 (0.265)	loss 6.572 (6.689)	prob 3.028 (2.420)	GS 33.062 (31.450)	mem 70.122
Train: [65][1480/1500]	BT 0.021 (0.302)	DT 0.000 (0.265)	loss 6.513 (6.681)	prob 2.979 (2.395)	GS 29.406 (31.644)	mem 17.718
Train: [65][1490/1500]	BT 0.032 (0.301)	DT 0.000 (0.263)	loss 6.641 (6.679)	prob 2.713 (2.371)	GS 32.281 (31.784)	mem 17.718
Train: [65][1500/1500]	BT 0.033 (0.299)	DT 0.000 (0.262)	loss 6.381 (6.678)	prob 3.447 (2.399)	GS 38.594 (32.266)	mem 9.313
Train: [65][1510/1500]	BT 0.023 (0.298)	DT 0.000 (0.260)	loss 6.132 (6.432)	prob 2.672 (2.614)	GS 36.000 (31.709)	mem 9.312
epoch 65, total time 449.49
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [66][1/1500]	BT 18.041 (18.041)	DT 17.980 (17.980)	loss 6.208 (6.208)	prob 2.290 (2.290)	GS 34.422 (34.422)	mem 72.924
Train: [66][10/1500]	BT 0.039 (2.275)	DT 0.001 (2.237)	loss 6.438 (6.387)	prob 2.068 (2.414)	GS 31.734 (32.689)	mem 73.063
Train: [66][20/1500]	BT 0.038 (1.176)	DT 0.001 (1.138)	loss 6.626 (6.448)	prob 2.428 (2.424)	GS 36.359 (32.379)	mem 73.094
Train: [66][30/1500]	BT 0.038 (0.930)	DT 0.001 (0.892)	loss 6.583 (6.494)	prob 1.910 (2.332)	GS 32.453 (32.442)	mem 73.150
Train: [66][40/1500]	BT 0.041 (0.705)	DT 0.000 (0.669)	loss 6.571 (6.533)	prob 1.692 (2.296)	GS 35.688 (32.731)	mem 73.152
Train: [66][50/1500]	BT 4.036 (0.674)	DT 3.978 (0.637)	loss 6.615 (6.560)	prob 3.403 (2.323)	GS 32.266 (32.462)	mem 73.157
Train: [66][60/1500]	BT 0.077 (0.792)	DT 0.015 (0.750)	loss 7.004 (6.691)	prob 2.426 (2.432)	GS 31.047 (33.284)	mem 73.163
Train: [66][70/1500]	BT 0.060 (0.687)	DT 0.011 (0.644)	loss 6.781 (6.695)	prob 2.039 (2.355)	GS 33.547 (32.139)	mem 73.164
Train: [66][80/1500]	BT 0.076 (0.610)	DT 0.001 (0.565)	loss 6.670 (6.693)	prob 2.730 (2.371)	GS 33.109 (31.858)	mem 73.164
Train: [66][90/1500]	BT 0.031 (0.622)	DT 0.000 (0.577)	loss 6.764 (6.686)	prob 2.374 (2.366)	GS 33.656 (31.982)	mem 73.170
Train: [66][100/1500]	BT 0.031 (0.563)	DT 0.000 (0.520)	loss 6.868 (6.688)	prob 2.703 (2.397)	GS 32.391 (32.127)	mem 73.170
Train: [66][110/1500]	BT 0.027 (0.652)	DT 0.000 (0.609)	loss 6.683 (6.693)	prob 2.774 (2.183)	GS 32.719 (32.878)	mem 73.175
Train: [66][120/1500]	BT 0.024 (0.600)	DT 0.000 (0.558)	loss 6.783 (6.685)	prob 2.062 (2.219)	GS 39.312 (32.666)	mem 73.177
Train: [66][130/1500]	BT 0.038 (0.586)	DT 0.001 (0.546)	loss 6.491 (6.674)	prob 2.518 (2.235)	GS 32.156 (32.826)	mem 73.188
Train: [66][140/1500]	BT 0.042 (0.547)	DT 0.001 (0.507)	loss 6.505 (6.675)	prob 1.916 (2.213)	GS 32.641 (32.668)	mem 73.190
Train: [66][150/1500]	BT 0.037 (0.513)	DT 0.001 (0.473)	loss 6.555 (6.694)	prob 2.493 (2.187)	GS 32.312 (32.905)	mem 73.189
Train: [66][160/1500]	BT 0.031 (0.524)	DT 0.000 (0.485)	loss 6.631 (6.635)	prob 2.635 (2.221)	GS 31.562 (31.577)	mem 73.201
Train: [66][170/1500]	BT 0.039 (0.495)	DT 0.000 (0.456)	loss 6.661 (6.649)	prob 2.758 (2.170)	GS 30.484 (31.574)	mem 73.202
Train: [66][180/1500]	BT 0.038 (0.492)	DT 0.001 (0.454)	loss 6.592 (6.606)	prob 2.327 (2.257)	GS 32.609 (31.155)	mem 73.206
Train: [66][190/1500]	BT 0.055 (0.469)	DT 0.005 (0.430)	loss 6.483 (6.600)	prob 2.530 (2.306)	GS 31.391 (31.486)	mem 73.207
Train: [66][200/1500]	BT 0.031 (0.475)	DT 0.000 (0.437)	loss 6.657 (6.600)	prob 2.371 (2.326)	GS 32.484 (31.681)	mem 73.210
Train: [66][210/1500]	BT 0.056 (0.455)	DT 0.001 (0.416)	loss 6.533 (6.557)	prob 2.421 (2.413)	GS 34.000 (33.175)	mem 73.217
Train: [66][220/1500]	BT 0.059 (0.437)	DT 0.004 (0.397)	loss 6.751 (6.584)	prob 2.525 (2.524)	GS 34.922 (33.506)	mem 73.219
Train: [66][230/1500]	BT 0.030 (0.453)	DT 0.000 (0.413)	loss 6.462 (6.588)	prob 1.972 (2.461)	GS 36.719 (33.868)	mem 73.216
Train: [66][240/1500]	BT 0.037 (0.436)	DT 0.000 (0.396)	loss 6.609 (6.609)	prob 2.737 (2.486)	GS 35.391 (33.557)	mem 73.217
Train: [66][250/1500]	BT 0.047 (0.469)	DT 0.001 (0.429)	loss 6.667 (6.622)	prob 3.057 (2.513)	GS 34.734 (34.105)	mem 73.228
Train: [66][260/1500]	BT 0.031 (0.452)	DT 0.000 (0.413)	loss 6.655 (6.704)	prob 3.018 (2.929)	GS 29.656 (30.711)	mem 73.232
Train: [66][270/1500]	BT 0.027 (0.439)	DT 0.000 (0.400)	loss 6.815 (6.730)	prob 3.007 (3.013)	GS 38.109 (32.784)	mem 73.235
Train: [66][280/1500]	BT 0.064 (0.442)	DT 0.004 (0.402)	loss 6.875 (6.724)	prob 2.520 (3.061)	GS 32.859 (32.899)	mem 73.243
Train: [66][290/1500]	BT 0.068 (0.430)	DT 0.009 (0.390)	loss 6.946 (6.728)	prob 2.829 (3.050)	GS 33.578 (32.381)	mem 73.243
Train: [66][300/1500]	BT 0.036 (0.433)	DT 0.000 (0.393)	loss 6.600 (6.742)	prob 2.752 (3.025)	GS 34.906 (32.042)	mem 73.249
Train: [66][310/1500]	BT 0.037 (0.420)	DT 0.001 (0.380)	loss 6.574 (6.707)	prob 2.936 (2.769)	GS 31.609 (32.397)	mem 73.247
Train: [66][320/1500]	BT 0.037 (0.408)	DT 0.000 (0.368)	loss 6.916 (6.777)	prob 2.903 (2.784)	GS 31.797 (32.663)	mem 73.132
Train: [66][330/1500]	BT 0.060 (0.413)	DT 0.002 (0.373)	loss 6.827 (6.783)	prob 3.097 (2.780)	GS 32.016 (32.672)	mem 73.156
Train: [66][340/1500]	BT 0.070 (0.403)	DT 0.005 (0.362)	loss 6.853 (6.782)	prob 2.440 (2.757)	GS 36.016 (32.452)	mem 73.156
Train: [66][350/1500]	BT 2.309 (0.424)	DT 2.256 (0.382)	loss 7.150 (6.796)	prob 3.054 (2.740)	GS 36.781 (32.696)	mem 73.159
Train: [66][360/1500]	BT 1.942 (0.419)	DT 1.906 (0.377)	loss 6.685 (6.813)	prob 2.881 (3.075)	GS 39.328 (32.855)	mem 73.160
Train: [66][370/1500]	BT 0.040 (0.413)	DT 0.001 (0.371)	loss 7.041 (6.795)	prob 2.119 (3.007)	GS 36.312 (32.727)	mem 73.164
Train: [66][380/1500]	BT 0.028 (0.405)	DT 0.000 (0.363)	loss 6.561 (6.808)	prob 3.042 (2.949)	GS 31.125 (32.980)	mem 73.181
Train: [66][390/1500]	BT 0.037 (0.397)	DT 0.001 (0.355)	loss 6.887 (6.824)	prob 3.251 (2.971)	GS 32.234 (33.014)	mem 73.184
Train: [66][400/1500]	BT 0.038 (0.393)	DT 0.001 (0.352)	loss 6.724 (6.829)	prob 3.591 (3.065)	GS 34.734 (33.201)	mem 73.184
Train: [66][410/1500]	BT 0.038 (0.390)	DT 0.001 (0.348)	loss 7.040 (6.762)	prob 2.888 (2.994)	GS 35.016 (31.756)	mem 73.184
Train: [66][420/1500]	BT 0.038 (0.382)	DT 0.001 (0.341)	loss 6.751 (6.768)	prob 3.137 (3.101)	GS 30.797 (31.200)	mem 73.185
Train: [66][430/1500]	BT 0.028 (0.384)	DT 0.000 (0.342)	loss 6.829 (6.780)	prob 2.596 (2.932)	GS 31.344 (31.410)	mem 73.371
Train: [66][440/1500]	BT 0.030 (0.376)	DT 0.001 (0.335)	loss 6.794 (6.776)	prob 2.735 (2.895)	GS 33.828 (31.790)	mem 73.469
Train: [66][450/1500]	BT 0.039 (0.375)	DT 0.001 (0.334)	loss 6.627 (6.779)	prob 2.977 (2.850)	GS 31.859 (32.052)	mem 73.908
Train: [66][460/1500]	BT 0.036 (0.369)	DT 0.001 (0.328)	loss 6.914 (6.820)	prob 2.820 (2.888)	GS 36.578 (32.300)	mem 74.007
Train: [66][470/1500]	BT 0.038 (0.364)	DT 0.001 (0.323)	loss 6.888 (6.803)	prob 3.519 (2.812)	GS 34.188 (32.418)	mem 74.007
Train: [66][480/1500]	BT 0.039 (0.363)	DT 0.001 (0.323)	loss 6.672 (6.801)	prob 2.635 (2.833)	GS 30.922 (32.029)	mem 74.349
Train: [66][490/1500]	BT 0.039 (0.357)	DT 0.001 (0.316)	loss 6.750 (6.793)	prob 2.512 (2.821)	GS 35.547 (32.179)	mem 74.350
Train: [66][500/1500]	BT 0.029 (0.374)	DT 0.000 (0.334)	loss 7.175 (6.816)	prob 2.414 (2.761)	GS 33.109 (32.311)	mem 74.354
Train: [66][510/1500]	BT 0.038 (0.367)	DT 0.001 (0.327)	loss 6.895 (6.831)	prob 2.385 (2.773)	GS 33.812 (31.809)	mem 74.355
Train: [66][520/1500]	BT 0.036 (0.365)	DT 0.000 (0.325)	loss 6.916 (6.829)	prob 2.727 (2.771)	GS 34.109 (31.773)	mem 74.371
Train: [66][530/1500]	BT 0.026 (0.360)	DT 0.000 (0.320)	loss 6.724 (6.832)	prob 3.281 (2.737)	GS 30.625 (31.845)	mem 74.375
Train: [66][540/1500]	BT 0.037 (0.354)	DT 0.000 (0.314)	loss 6.691 (6.838)	prob 2.818 (2.716)	GS 29.453 (31.886)	mem 74.376
Train: [66][550/1500]	BT 0.041 (0.357)	DT 0.000 (0.317)	loss 6.734 (6.846)	prob 2.906 (2.673)	GS 33.406 (32.233)	mem 74.380
Train: [66][560/1500]	BT 0.036 (0.352)	DT 0.000 (0.312)	loss 6.735 (6.827)	prob 2.469 (2.517)	GS 29.141 (32.553)	mem 74.382
Train: [66][570/1500]	BT 0.037 (0.359)	DT 0.001 (0.319)	loss 6.620 (6.859)	prob 2.694 (2.437)	GS 34.703 (32.998)	mem 74.384
Train: [66][580/1500]	BT 0.027 (0.353)	DT 0.000 (0.313)	loss 6.816 (6.829)	prob 2.699 (2.419)	GS 34.625 (33.232)	mem 74.386
Train: [66][590/1500]	BT 0.033 (0.348)	DT 0.000 (0.308)	loss 6.629 (6.832)	prob 3.157 (2.453)	GS 30.891 (33.293)	mem 74.387
Train: [66][600/1500]	BT 0.024 (0.349)	DT 0.000 (0.310)	loss 6.895 (6.827)	prob 2.477 (2.489)	GS 31.359 (33.046)	mem 74.390
Train: [66][610/1500]	BT 0.024 (0.344)	DT 0.000 (0.305)	loss 6.807 (6.812)	prob 2.117 (2.682)	GS 32.031 (31.670)	mem 74.390
Train: [66][620/1500]	BT 0.060 (0.348)	DT 0.016 (0.309)	loss 7.056 (6.797)	prob 1.831 (2.505)	GS 37.078 (32.225)	mem 74.389
Train: [66][630/1500]	BT 0.048 (0.344)	DT 0.000 (0.304)	loss 6.876 (6.830)	prob 2.470 (2.566)	GS 33.641 (32.229)	mem 74.389
Train: [66][640/1500]	BT 0.057 (0.339)	DT 0.013 (0.299)	loss 6.597 (6.830)	prob 2.854 (2.551)	GS 35.000 (32.393)	mem 74.390
Train: [66][650/1500]	BT 0.026 (0.357)	DT 0.000 (0.317)	loss 7.079 (6.838)	prob 3.259 (2.552)	GS 31.438 (32.453)	mem 74.392
Train: [66][660/1500]	BT 0.023 (0.352)	DT 0.000 (0.312)	loss 7.356 (6.867)	prob 2.211 (2.632)	GS 31.188 (32.002)	mem 74.392
Train: [66][670/1500]	BT 0.038 (0.351)	DT 0.001 (0.312)	loss 6.865 (6.895)	prob 2.481 (2.433)	GS 34.938 (32.462)	mem 74.395
Train: [66][680/1500]	BT 0.036 (0.346)	DT 0.000 (0.307)	loss 6.826 (6.902)	prob 2.754 (2.393)	GS 37.719 (32.548)	mem 74.396
Train: [66][690/1500]	BT 0.038 (0.342)	DT 0.000 (0.303)	loss 6.871 (6.885)	prob 1.741 (2.405)	GS 31.250 (31.995)	mem 74.397
Train: [66][700/1500]	BT 0.110 (0.345)	DT 0.007 (0.305)	loss 7.050 (6.890)	prob 2.632 (2.411)	GS 33.734 (32.103)	mem 74.397
Train: [66][710/1500]	BT 0.096 (0.342)	DT 0.005 (0.301)	loss 6.773 (6.910)	prob 2.452 (2.544)	GS 31.406 (31.903)	mem 74.397
Train: [66][720/1500]	BT 0.068 (0.343)	DT 0.012 (0.303)	loss 6.893 (6.931)	prob 2.696 (2.369)	GS 33.359 (31.512)	mem 74.398
Train: [66][730/1500]	BT 0.037 (0.347)	DT 0.000 (0.307)	loss 7.319 (6.955)	prob 2.175 (2.361)	GS 30.516 (32.349)	mem 74.399
Train: [66][740/1500]	BT 0.037 (0.344)	DT 0.001 (0.303)	loss 7.117 (6.987)	prob 2.387 (2.380)	GS 35.719 (32.255)	mem 74.400
Train: [66][750/1500]	BT 0.037 (0.344)	DT 0.000 (0.304)	loss 7.002 (6.993)	prob 2.255 (2.442)	GS 33.016 (32.252)	mem 74.399
Train: [66][760/1500]	BT 0.037 (0.340)	DT 0.001 (0.300)	loss 6.994 (7.041)	prob 2.569 (2.036)	GS 33.062 (33.242)	mem 74.399
Train: [66][770/1500]	BT 0.037 (0.340)	DT 0.001 (0.300)	loss 6.893 (7.027)	prob 3.068 (2.293)	GS 33.109 (32.750)	mem 74.398
Train: [66][780/1500]	BT 0.028 (0.338)	DT 0.000 (0.298)	loss 7.091 (7.005)	prob 3.023 (2.336)	GS 35.078 (32.552)	mem 74.400
Train: [66][790/1500]	BT 0.038 (0.336)	DT 0.001 (0.296)	loss 7.160 (7.034)	prob 2.839 (2.435)	GS 31.703 (32.378)	mem 74.402
Train: [66][800/1500]	BT 0.037 (0.336)	DT 0.000 (0.296)	loss 7.318 (7.051)	prob 2.564 (2.497)	GS 34.328 (32.301)	mem 74.405
Train: [66][810/1500]	BT 0.038 (0.332)	DT 0.001 (0.292)	loss 7.163 (7.105)	prob 2.648 (2.407)	GS 35.438 (32.152)	mem 74.405
Train: [66][820/1500]	BT 0.037 (0.329)	DT 0.000 (0.289)	loss 7.344 (7.096)	prob 2.963 (2.471)	GS 30.609 (32.154)	mem 74.405
Train: [66][830/1500]	BT 0.037 (0.331)	DT 0.000 (0.290)	loss 7.133 (7.165)	prob 2.550 (2.462)	GS 36.078 (32.433)	mem 74.407
Train: [66][840/1500]	BT 0.037 (0.327)	DT 0.001 (0.287)	loss 7.354 (7.160)	prob 2.476 (2.513)	GS 34.688 (32.003)	mem 74.408
Train: [66][850/1500]	BT 0.030 (0.329)	DT 0.000 (0.289)	loss 7.279 (7.147)	prob 2.561 (2.513)	GS 28.516 (32.093)	mem 74.441
Train: [66][860/1500]	BT 0.039 (0.326)	DT 0.000 (0.286)	loss 6.973 (6.992)	prob 3.154 (2.957)	GS 37.891 (34.552)	mem 74.440
Train: [66][870/1500]	BT 0.032 (0.327)	DT 0.000 (0.288)	loss 6.909 (7.097)	prob 3.864 (2.831)	GS 36.828 (33.927)	mem 74.440
Train: [66][880/1500]	BT 0.029 (0.324)	DT 0.000 (0.284)	loss 7.462 (7.125)	prob 2.313 (2.770)	GS 35.594 (33.955)	mem 74.439
Train: [66][890/1500]	BT 0.036 (0.321)	DT 0.001 (0.281)	loss 7.417 (7.138)	prob 2.574 (2.804)	GS 31.734 (33.702)	mem 74.439
Train: [66][900/1500]	BT 0.039 (0.321)	DT 0.001 (0.281)	loss 7.469 (7.138)	prob 2.923 (2.755)	GS 32.641 (33.719)	mem 74.440
Train: [66][910/1500]	BT 0.039 (0.318)	DT 0.001 (0.278)	loss 7.117 (7.062)	prob 3.260 (2.575)	GS 33.719 (33.267)	mem 74.440
Train: [66][920/1500]	BT 0.062 (0.318)	DT 0.014 (0.279)	loss 6.749 (7.135)	prob 2.578 (2.519)	GS 33.922 (33.293)	mem 74.441
Train: [66][930/1500]	BT 0.063 (0.315)	DT 0.001 (0.276)	loss 7.091 (7.150)	prob 3.144 (2.562)	GS 40.516 (32.983)	mem 74.441
Train: [66][940/1500]	BT 0.035 (0.313)	DT 0.000 (0.273)	loss 7.003 (7.116)	prob 2.712 (2.595)	GS 32.453 (32.709)	mem 74.442
Train: [66][950/1500]	BT 0.057 (0.318)	DT 0.001 (0.278)	loss 7.209 (7.125)	prob 2.682 (2.648)	GS 33.875 (32.699)	mem 74.442
Train: [66][960/1500]	BT 0.034 (0.315)	DT 0.001 (0.275)	loss 7.279 (7.190)	prob 2.988 (2.773)	GS 35.719 (33.478)	mem 74.442
Train: [66][970/1500]	BT 0.056 (0.320)	DT 0.005 (0.280)	loss 7.285 (7.121)	prob 2.628 (2.774)	GS 33.578 (32.716)	mem 74.443
Train: [66][980/1500]	BT 0.052 (0.319)	DT 0.014 (0.279)	loss 7.071 (7.090)	prob 2.392 (2.838)	GS 33.031 (32.760)	mem 74.446
Train: [66][990/1500]	BT 0.029 (0.326)	DT 0.000 (0.286)	loss 6.829 (7.075)	prob 2.848 (2.865)	GS 32.531 (32.517)	mem 74.447
Train: [66][1000/1500]	BT 0.031 (0.323)	DT 0.001 (0.283)	loss 7.407 (7.089)	prob 2.805 (2.896)	GS 32.531 (32.521)	mem 74.447
Train: [66][1010/1500]	BT 0.039 (0.324)	DT 0.001 (0.284)	loss 7.024 (7.135)	prob 3.814 (2.674)	GS 32.719 (32.706)	mem 74.448
Train: [66][1020/1500]	BT 0.064 (0.321)	DT 0.003 (0.281)	loss 7.078 (7.119)	prob 2.793 (2.978)	GS 32.297 (32.084)	mem 74.446
Train: [66][1030/1500]	BT 0.026 (0.318)	DT 0.000 (0.278)	loss 7.052 (7.099)	prob 2.758 (2.939)	GS 31.984 (32.402)	mem 74.447
Train: [66][1040/1500]	BT 0.021 (0.323)	DT 0.000 (0.284)	loss 7.359 (7.128)	prob 2.227 (2.812)	GS 35.359 (32.730)	mem 74.443
Train: [66][1050/1500]	BT 0.028 (0.321)	DT 0.000 (0.281)	loss 7.102 (7.121)	prob 2.476 (2.792)	GS 34.172 (32.652)	mem 74.444
Train: [66][1060/1500]	BT 0.029 (0.322)	DT 0.000 (0.282)	loss 7.255 (6.997)	prob 2.459 (2.670)	GS 32.359 (33.097)	mem 74.446
Train: [66][1070/1500]	BT 0.026 (0.319)	DT 0.001 (0.279)	loss 7.084 (7.045)	prob 3.306 (2.779)	GS 34.906 (32.867)	mem 74.446
Train: [66][1080/1500]	BT 0.031 (0.319)	DT 0.001 (0.280)	loss 7.471 (7.059)	prob 3.243 (2.865)	GS 33.453 (32.955)	mem 74.446
Train: [66][1090/1500]	BT 0.038 (0.317)	DT 0.001 (0.277)	loss 6.827 (7.050)	prob 3.624 (2.916)	GS 36.453 (32.851)	mem 74.448
Train: [66][1100/1500]	BT 0.039 (0.314)	DT 0.001 (0.275)	loss 6.879 (7.044)	prob 2.870 (2.908)	GS 33.969 (32.562)	mem 74.448
Train: [66][1110/1500]	BT 0.028 (0.315)	DT 0.000 (0.275)	loss 7.111 (7.055)	prob 2.031 (2.481)	GS 34.406 (33.672)	mem 74.444
Train: [66][1120/1500]	BT 0.038 (0.312)	DT 0.001 (0.273)	loss 6.864 (7.022)	prob 2.985 (2.677)	GS 36.000 (33.204)	mem 74.445
Train: [66][1130/1500]	BT 0.073 (0.315)	DT 0.012 (0.276)	loss 6.862 (7.002)	prob 3.370 (2.735)	GS 32.859 (33.084)	mem 74.447
Train: [66][1140/1500]	BT 0.034 (0.313)	DT 0.000 (0.274)	loss 6.972 (7.019)	prob 2.870 (2.723)	GS 35.359 (33.031)	mem 74.446
Train: [66][1150/1500]	BT 0.036 (0.314)	DT 0.001 (0.275)	loss 6.953 (7.029)	prob 3.516 (2.725)	GS 35.016 (33.188)	mem 74.449
Train: [66][1160/1500]	BT 0.056 (0.313)	DT 0.002 (0.274)	loss 7.058 (7.059)	prob 2.649 (2.887)	GS 32.594 (33.980)	mem 74.452
Train: [66][1170/1500]	BT 0.053 (0.314)	DT 0.010 (0.274)	loss 6.763 (7.017)	prob 3.350 (2.851)	GS 35.891 (33.825)	mem 74.463
Train: [66][1180/1500]	BT 0.067 (0.313)	DT 0.011 (0.274)	loss 7.308 (7.040)	prob 2.695 (2.843)	GS 34.547 (33.989)	mem 74.463
Train: [66][1190/1500]	BT 0.029 (0.320)	DT 0.000 (0.280)	loss 7.565 (7.052)	prob 2.771 (2.835)	GS 31.391 (34.005)	mem 74.439
Train: [66][1200/1500]	BT 0.026 (0.317)	DT 0.000 (0.278)	loss 7.231 (7.064)	prob 2.671 (2.816)	GS 36.094 (33.833)	mem 74.460
Train: [66][1210/1500]	BT 0.028 (0.320)	DT 0.000 (0.281)	loss 6.772 (6.941)	prob 2.854 (2.824)	GS 27.938 (32.378)	mem 74.365
Train: [66][1220/1500]	BT 0.029 (0.318)	DT 0.000 (0.279)	loss 7.027 (6.966)	prob 3.104 (2.736)	GS 29.734 (32.065)	mem 74.365
Train: [66][1230/1500]	BT 0.036 (0.316)	DT 0.000 (0.276)	loss 6.898 (6.956)	prob 2.288 (2.719)	GS 35.250 (32.605)	mem 74.366
Train: [66][1240/1500]	BT 0.027 (0.316)	DT 0.000 (0.277)	loss 6.795 (6.959)	prob 2.624 (2.635)	GS 33.094 (32.652)	mem 74.365
Train: [66][1250/1500]	BT 0.037 (0.314)	DT 0.000 (0.275)	loss 7.243 (6.970)	prob 2.752 (2.660)	GS 36.672 (32.581)	mem 74.365
Train: [66][1260/1500]	BT 0.037 (0.316)	DT 0.000 (0.277)	loss 6.926 (6.982)	prob 3.256 (2.796)	GS 35.062 (32.644)	mem 74.365
Train: [66][1270/1500]	BT 0.038 (0.313)	DT 0.001 (0.274)	loss 7.018 (6.990)	prob 2.812 (2.817)	GS 37.594 (32.208)	mem 74.365
Train: [66][1280/1500]	BT 0.038 (0.313)	DT 0.000 (0.274)	loss 6.715 (6.993)	prob 3.385 (2.717)	GS 29.141 (32.228)	mem 74.366
Train: [66][1290/1500]	BT 0.038 (0.311)	DT 0.001 (0.272)	loss 6.782 (6.974)	prob 2.995 (2.718)	GS 31.359 (32.193)	mem 74.366
Train: [66][1300/1500]	BT 0.038 (0.309)	DT 0.001 (0.270)	loss 7.174 (6.969)	prob 3.094 (2.772)	GS 31.828 (32.378)	mem 74.365
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [66][1310/1500]	BT 0.059 (0.311)	DT 0.011 (0.272)	loss 7.175 (7.003)	prob 3.095 (3.197)	GS 28.031 (32.008)	mem 74.368
Train: [66][1320/1500]	BT 0.027 (0.314)	DT 0.000 (0.275)	loss 7.049 (7.010)	prob 2.601 (2.912)	GS 30.531 (32.773)	mem 74.386
Train: [66][1330/1500]	BT 0.038 (0.312)	DT 0.001 (0.273)	loss 7.087 (7.004)	prob 2.416 (2.828)	GS 36.594 (32.889)	mem 74.387
Train: [66][1340/1500]	BT 0.038 (0.312)	DT 0.001 (0.273)	loss 6.851 (6.980)	prob 2.848 (2.884)	GS 34.734 (32.998)	mem 74.374
Train: [66][1350/1500]	BT 0.038 (0.310)	DT 0.001 (0.271)	loss 6.923 (6.988)	prob 2.753 (2.901)	GS 36.266 (32.851)	mem 74.373
Train: [66][1360/1500]	BT 0.039 (0.308)	DT 0.001 (0.269)	loss 7.105 (6.953)	prob 2.815 (2.862)	GS 36.641 (33.661)	mem 74.373
Train: [66][1370/1500]	BT 0.039 (0.309)	DT 0.006 (0.270)	loss 6.696 (6.960)	prob 3.320 (2.749)	GS 30.078 (32.201)	mem 74.377
Train: [66][1380/1500]	BT 0.065 (0.307)	DT 0.003 (0.268)	loss 7.075 (6.982)	prob 3.153 (2.941)	GS 36.516 (32.351)	mem 74.377
Train: [66][1390/1500]	BT 0.084 (0.309)	DT 0.011 (0.270)	loss 7.211 (6.993)	prob 3.050 (3.000)	GS 32.625 (32.273)	mem 74.376
Train: [66][1400/1500]	BT 0.028 (0.314)	DT 0.000 (0.274)	loss 7.012 (6.982)	prob 2.299 (2.991)	GS 36.172 (32.436)	mem 74.376
Train: [66][1410/1500]	BT 0.039 (0.312)	DT 0.001 (0.273)	loss 7.269 (7.170)	prob 2.987 (2.744)	GS 37.875 (33.181)	mem 74.376
Train: [66][1420/1500]	BT 0.040 (0.314)	DT 0.001 (0.274)	loss 7.170 (7.116)	prob 3.473 (2.833)	GS 35.219 (33.383)	mem 74.376
Train: [66][1430/1500]	BT 0.038 (0.312)	DT 0.001 (0.273)	loss 6.993 (7.090)	prob 3.269 (2.935)	GS 35.156 (33.320)	mem 74.376
Train: [66][1440/1500]	BT 0.039 (0.310)	DT 0.001 (0.271)	loss 6.851 (7.099)	prob 3.198 (2.880)	GS 33.969 (33.137)	mem 74.377
Train: [66][1450/1500]	BT 0.027 (0.312)	DT 0.000 (0.273)	loss 6.859 (7.077)	prob 3.117 (2.939)	GS 34.312 (32.940)	mem 74.378
Train: [66][1460/1500]	BT 0.038 (0.310)	DT 0.001 (0.271)	loss 6.853 (6.953)	prob 2.441 (2.826)	GS 36.156 (32.859)	mem 74.379
Train: [66][1470/1500]	BT 0.034 (0.310)	DT 0.000 (0.271)	loss 7.132 (6.978)	prob 3.423 (2.914)	GS 34.594 (32.375)	mem 65.192
Train: [66][1480/1500]	BT 0.028 (0.309)	DT 0.000 (0.270)	loss 7.227 (7.023)	prob 2.871 (2.774)	GS 31.719 (32.741)	mem 65.082
Train: [66][1490/1500]	BT 0.026 (0.307)	DT 0.001 (0.268)	loss 7.237 (7.043)	prob 2.912 (2.790)	GS 37.531 (32.498)	mem 50.680
Train: [66][1500/1500]	BT 0.026 (0.305)	DT 0.000 (0.267)	loss 7.294 (7.057)	prob 2.867 (2.773)	GS 37.750 (32.581)	mem 14.798
Train: [66][1510/1500]	BT 0.030 (0.304)	DT 0.001 (0.265)	loss 6.574 (6.840)	prob 3.340 (2.798)	GS 38.344 (33.312)	mem 12.182
epoch 66, total time 458.70
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [67][1/1500]	BT 17.891 (17.891)	DT 17.833 (17.833)	loss 6.809 (6.809)	prob 3.130 (3.130)	GS 31.578 (31.578)	mem 72.428
Train: [67][10/1500]	BT 0.035 (2.318)	DT 0.000 (2.278)	loss 6.495 (6.826)	prob 3.226 (2.675)	GS 32.328 (33.391)	mem 73.022
Train: [67][20/1500]	BT 0.037 (1.178)	DT 0.000 (1.140)	loss 6.751 (6.781)	prob 3.521 (2.871)	GS 31.109 (32.542)	mem 73.025
Train: [67][30/1500]	BT 1.009 (0.831)	DT 0.974 (0.793)	loss 7.086 (6.882)	prob 3.348 (2.963)	GS 32.672 (32.605)	mem 73.059
Train: [67][40/1500]	BT 0.036 (0.754)	DT 0.001 (0.717)	loss 7.411 (6.915)	prob 2.399 (2.935)	GS 29.781 (32.750)	mem 73.083
Train: [67][50/1500]	BT 0.038 (0.623)	DT 0.000 (0.586)	loss 7.107 (6.998)	prob 2.554 (2.822)	GS 35.094 (32.797)	mem 73.085
Train: [67][60/1500]	BT 0.026 (0.654)	DT 0.000 (0.617)	loss 6.817 (7.112)	prob 3.548 (3.130)	GS 33.625 (33.841)	mem 73.099
Train: [67][70/1500]	BT 0.037 (0.565)	DT 0.000 (0.529)	loss 7.034 (7.143)	prob 3.338 (2.991)	GS 33.516 (33.523)	mem 73.101
Train: [67][80/1500]	BT 0.029 (0.551)	DT 0.000 (0.515)	loss 7.485 (7.134)	prob 2.497 (2.968)	GS 33.344 (33.134)	mem 73.113
Train: [67][90/1500]	BT 0.037 (0.494)	DT 0.000 (0.458)	loss 7.037 (7.144)	prob 3.406 (2.964)	GS 37.078 (32.944)	mem 73.115
Train: [67][100/1500]	BT 0.037 (0.448)	DT 0.000 (0.412)	loss 7.189 (7.153)	prob 2.938 (2.929)	GS 30.891 (32.721)	mem 73.115
Train: [67][110/1500]	BT 0.030 (0.486)	DT 0.000 (0.451)	loss 7.201 (7.159)	prob 2.866 (2.801)	GS 31.828 (31.675)	mem 73.128
Train: [67][120/1500]	BT 0.039 (0.449)	DT 0.001 (0.414)	loss 7.574 (7.261)	prob 2.526 (2.864)	GS 34.406 (32.756)	mem 73.129
Train: [67][130/1500]	BT 0.027 (0.439)	DT 0.000 (0.403)	loss 7.347 (7.220)	prob 1.696 (2.708)	GS 31.141 (32.698)	mem 73.133
Train: [67][140/1500]	BT 0.032 (0.409)	DT 0.000 (0.375)	loss 7.093 (7.219)	prob 2.717 (2.736)	GS 31.297 (32.613)	mem 73.135
Train: [67][150/1500]	BT 0.038 (0.399)	DT 0.001 (0.364)	loss 7.442 (7.193)	prob 2.801 (2.803)	GS 33.328 (32.485)	mem 73.138
Train: [67][160/1500]	BT 0.038 (0.383)	DT 0.001 (0.348)	loss 7.136 (7.395)	prob 3.114 (2.802)	GS 33.672 (32.483)	mem 73.139
Train: [67][170/1500]	BT 0.038 (0.372)	DT 0.001 (0.337)	loss 7.241 (7.323)	prob 2.727 (2.757)	GS 34.500 (33.138)	mem 73.140
Train: [67][180/1500]	BT 0.037 (0.359)	DT 0.001 (0.324)	loss 7.320 (7.328)	prob 3.164 (2.795)	GS 33.375 (33.139)	mem 73.142
Train: [67][190/1500]	BT 0.037 (0.357)	DT 0.000 (0.322)	loss 7.455 (7.334)	prob 3.226 (2.832)	GS 35.500 (32.995)	mem 73.145
Train: [67][200/1500]	BT 0.038 (0.341)	DT 0.001 (0.306)	loss 8.020 (7.353)	prob 3.007 (2.847)	GS 33.297 (32.977)	mem 73.145
Train: [67][210/1500]	BT 0.305 (0.331)	DT 0.251 (0.296)	loss 7.049 (7.330)	prob 3.803 (3.277)	GS 31.953 (32.312)	mem 73.148
Train: [67][220/1500]	BT 0.032 (0.339)	DT 0.001 (0.302)	loss 7.869 (7.328)	prob 2.219 (3.174)	GS 38.531 (33.166)	mem 73.149
Train: [67][230/1500]	BT 0.072 (0.327)	DT 0.005 (0.289)	loss 7.329 (7.353)	prob 2.967 (3.045)	GS 35.828 (33.145)	mem 73.150
Train: [67][240/1500]	BT 0.068 (0.341)	DT 0.002 (0.304)	loss 7.628 (7.360)	prob 2.427 (3.004)	GS 38.359 (33.216)	mem 73.151
Train: [67][250/1500]	BT 0.028 (0.377)	DT 0.000 (0.339)	loss 7.479 (7.377)	prob 3.616 (3.043)	GS 33.188 (33.176)	mem 73.154
Train: [67][260/1500]	BT 0.034 (0.364)	DT 0.000 (0.326)	loss 8.175 (7.465)	prob 2.687 (3.238)	GS 32.375 (33.802)	mem 73.156
Train: [67][270/1500]	BT 0.036 (0.351)	DT 0.000 (0.314)	loss 7.540 (7.379)	prob 3.521 (3.268)	GS 34.547 (33.119)	mem 73.157
Train: [67][280/1500]	BT 0.028 (0.354)	DT 0.000 (0.317)	loss 7.768 (7.438)	prob 3.672 (3.409)	GS 36.500 (32.705)	mem 73.159
Train: [67][290/1500]	BT 0.025 (0.343)	DT 0.000 (0.306)	loss 6.971 (7.401)	prob 3.277 (3.305)	GS 32.547 (32.584)	mem 73.160
Train: [67][300/1500]	BT 0.027 (0.366)	DT 0.000 (0.329)	loss 7.569 (7.439)	prob 2.711 (3.196)	GS 30.234 (32.926)	mem 73.162
Train: [67][310/1500]	BT 0.030 (0.355)	DT 0.000 (0.319)	loss 8.144 (7.658)	prob 3.252 (3.158)	GS 33.375 (32.855)	mem 73.166
Train: [67][320/1500]	BT 0.030 (0.354)	DT 0.000 (0.318)	loss 7.178 (7.503)	prob 4.221 (3.317)	GS 31.906 (32.805)	mem 73.197
Train: [67][330/1500]	BT 0.029 (0.344)	DT 0.000 (0.308)	loss 7.322 (7.471)	prob 4.415 (3.416)	GS 31.344 (31.961)	mem 73.199
Train: [67][340/1500]	BT 0.038 (0.335)	DT 0.001 (0.299)	loss 8.295 (7.498)	prob 3.530 (3.476)	GS 36.250 (32.228)	mem 73.198
Train: [67][350/1500]	BT 0.029 (0.338)	DT 0.000 (0.303)	loss 7.679 (7.510)	prob 3.365 (3.510)	GS 34.719 (32.257)	mem 73.205
Train: [67][360/1500]	BT 0.038 (0.330)	DT 0.001 (0.294)	loss 7.221 (7.412)	prob 3.630 (3.480)	GS 36.125 (33.087)	mem 73.208
Train: [67][370/1500]	BT 0.039 (0.330)	DT 0.001 (0.294)	loss 7.321 (7.375)	prob 4.454 (3.571)	GS 38.531 (33.204)	mem 73.207
Train: [67][380/1500]	BT 0.039 (0.322)	DT 0.001 (0.287)	loss 8.170 (7.444)	prob 3.403 (3.605)	GS 32.156 (33.186)	mem 73.207
Train: [67][390/1500]	BT 0.039 (0.315)	DT 0.001 (0.279)	loss 7.778 (7.456)	prob 3.420 (3.707)	GS 33.656 (33.178)	mem 73.207
Train: [67][400/1500]	BT 0.057 (0.319)	DT 0.013 (0.283)	loss 7.118 (7.433)	prob 3.729 (3.726)	GS 34.625 (33.175)	mem 73.207
Train: [67][410/1500]	BT 0.058 (0.313)	DT 0.011 (0.276)	loss 8.033 (7.605)	prob 3.902 (3.788)	GS 33.750 (32.163)	mem 73.208
Train: [67][420/1500]	BT 0.031 (0.373)	DT 0.000 (0.336)	loss 7.531 (7.557)	prob 4.366 (3.913)	GS 35.891 (32.384)	mem 73.211
Train: [67][430/1500]	BT 0.030 (0.365)	DT 0.000 (0.329)	loss 7.687 (7.474)	prob 3.483 (3.870)	GS 34.750 (32.630)	mem 73.211
Train: [67][440/1500]	BT 0.025 (0.358)	DT 0.000 (0.321)	loss 7.620 (7.471)	prob 3.486 (3.802)	GS 31.906 (32.296)	mem 73.211
Train: [67][450/1500]	BT 0.085 (0.359)	DT 0.025 (0.322)	loss 7.603 (7.444)	prob 3.850 (3.762)	GS 35.500 (32.821)	mem 73.213
Train: [67][460/1500]	BT 0.066 (0.352)	DT 0.006 (0.315)	loss 7.191 (7.424)	prob 3.982 (3.867)	GS 33.953 (33.248)	mem 73.213
Train: [67][470/1500]	BT 0.038 (0.360)	DT 0.000 (0.323)	loss 7.304 (7.398)	prob 3.812 (3.953)	GS 34.047 (32.763)	mem 73.263
Train: [67][480/1500]	BT 0.028 (0.356)	DT 0.001 (0.319)	loss 7.631 (7.391)	prob 4.179 (3.928)	GS 31.562 (33.290)	mem 73.311
Train: [67][490/1500]	BT 0.063 (0.349)	DT 0.002 (0.312)	loss 7.638 (7.423)	prob 3.452 (3.816)	GS 36.594 (33.232)	mem 73.313
Train: [67][500/1500]	BT 0.031 (0.354)	DT 0.000 (0.317)	loss 7.834 (7.419)	prob 3.611 (3.783)	GS 37.234 (33.286)	mem 73.656
Train: [67][510/1500]	BT 0.039 (0.353)	DT 0.001 (0.316)	loss 7.881 (7.428)	prob 3.548 (3.466)	GS 31.141 (33.420)	mem 73.756
Train: [67][520/1500]	BT 0.039 (0.352)	DT 0.001 (0.314)	loss 7.725 (7.490)	prob 4.258 (3.638)	GS 33.297 (32.710)	mem 74.147
Train: [67][530/1500]	BT 0.039 (0.350)	DT 0.001 (0.313)	loss 7.847 (7.502)	prob 3.970 (3.752)	GS 34.891 (32.825)	mem 74.391
Train: [67][540/1500]	BT 0.038 (0.350)	DT 0.001 (0.313)	loss 8.124 (7.522)	prob 3.192 (3.779)	GS 35.750 (32.941)	mem 74.394
Train: [67][550/1500]	BT 0.040 (0.345)	DT 0.001 (0.307)	loss 7.607 (7.486)	prob 3.763 (3.801)	GS 31.562 (32.859)	mem 74.395
Train: [67][560/1500]	BT 0.039 (0.342)	DT 0.001 (0.305)	loss 7.684 (7.415)	prob 4.061 (3.918)	GS 33.500 (34.030)	mem 74.396
Train: [67][570/1500]	BT 0.039 (0.339)	DT 0.001 (0.302)	loss 7.554 (7.381)	prob 3.523 (3.925)	GS 39.312 (33.523)	mem 74.396
Train: [67][580/1500]	BT 0.039 (0.337)	DT 0.001 (0.299)	loss 7.370 (7.420)	prob 4.400 (3.864)	GS 33.484 (33.256)	mem 74.394
Train: [67][590/1500]	BT 0.069 (0.337)	DT 0.014 (0.300)	loss 7.740 (7.406)	prob 3.929 (3.824)	GS 37.000 (33.063)	mem 74.392
Train: [67][600/1500]	BT 1.651 (0.335)	DT 1.583 (0.297)	loss 7.840 (7.408)	prob 3.598 (3.697)	GS 37.500 (33.269)	mem 74.393
Train: [67][610/1500]	BT 0.047 (0.330)	DT 0.001 (0.293)	loss 7.418 (7.350)	prob 4.332 (3.742)	GS 30.562 (31.962)	mem 74.393
Train: [67][620/1500]	BT 0.033 (0.334)	DT 0.000 (0.296)	loss 7.624 (7.453)	prob 4.329 (3.832)	GS 33.781 (32.173)	mem 74.393
Train: [67][630/1500]	BT 0.029 (0.350)	DT 0.000 (0.312)	loss 7.603 (7.418)	prob 3.807 (3.764)	GS 35.312 (32.437)	mem 74.398
Train: [67][640/1500]	BT 0.034 (0.345)	DT 0.000 (0.308)	loss 7.533 (7.384)	prob 3.490 (3.734)	GS 34.125 (32.708)	mem 74.399
Train: [67][650/1500]	BT 0.044 (0.347)	DT 0.014 (0.309)	loss 7.803 (7.365)	prob 3.234 (3.710)	GS 36.938 (32.671)	mem 74.406
Train: [67][660/1500]	BT 0.033 (0.342)	DT 0.000 (0.305)	loss 7.766 (7.471)	prob 3.154 (3.514)	GS 31.766 (32.648)	mem 74.409
Train: [67][670/1500]	BT 0.037 (0.343)	DT 0.001 (0.305)	loss 7.762 (7.443)	prob 3.768 (3.614)	GS 33.250 (33.162)	mem 74.300
Train: [67][680/1500]	BT 0.037 (0.339)	DT 0.000 (0.301)	loss 7.269 (7.402)	prob 4.375 (3.714)	GS 29.500 (32.960)	mem 74.317
Train: [67][690/1500]	BT 0.037 (0.334)	DT 0.000 (0.296)	loss 7.630 (7.393)	prob 3.518 (3.674)	GS 32.547 (32.894)	mem 74.317
Train: [67][700/1500]	BT 0.036 (0.341)	DT 0.000 (0.303)	loss 7.556 (7.387)	prob 4.135 (3.647)	GS 31.016 (32.857)	mem 74.315
Train: [67][710/1500]	BT 0.036 (0.337)	DT 0.000 (0.299)	loss 7.458 (7.269)	prob 4.002 (3.603)	GS 32.156 (30.552)	mem 74.315
Train: [67][720/1500]	BT 0.034 (0.334)	DT 0.001 (0.296)	loss 7.265 (7.296)	prob 3.603 (3.451)	GS 33.859 (31.578)	mem 74.316
Train: [67][730/1500]	BT 0.060 (0.334)	DT 0.000 (0.296)	loss 7.550 (7.298)	prob 3.284 (3.492)	GS 31.047 (31.617)	mem 74.315
Train: [67][740/1500]	BT 0.047 (0.330)	DT 0.004 (0.292)	loss 7.623 (7.299)	prob 3.077 (3.430)	GS 32.391 (31.635)	mem 74.317
Train: [67][750/1500]	BT 0.028 (0.333)	DT 0.000 (0.295)	loss 7.195 (7.305)	prob 3.649 (3.402)	GS 32.672 (31.914)	mem 74.340
Train: [67][760/1500]	BT 0.036 (0.329)	DT 0.001 (0.291)	loss 7.907 (7.407)	prob 2.579 (3.193)	GS 31.953 (33.181)	mem 74.341
Train: [67][770/1500]	BT 0.026 (0.339)	DT 0.000 (0.301)	loss 7.341 (7.418)	prob 4.154 (3.291)	GS 34.969 (33.373)	mem 74.328
Train: [67][780/1500]	BT 0.029 (0.335)	DT 0.000 (0.297)	loss 7.049 (7.335)	prob 3.397 (3.345)	GS 36.344 (33.309)	mem 74.328
Train: [67][790/1500]	BT 0.031 (0.337)	DT 0.001 (0.299)	loss 7.403 (7.337)	prob 3.503 (3.299)	GS 34.938 (33.070)	mem 74.329
Train: [67][800/1500]	BT 0.037 (0.333)	DT 0.001 (0.295)	loss 7.230 (7.350)	prob 3.897 (3.246)	GS 33.766 (33.007)	mem 74.328
Train: [67][810/1500]	BT 0.026 (0.329)	DT 0.001 (0.292)	loss 7.047 (7.288)	prob 2.969 (3.089)	GS 35.281 (32.341)	mem 74.329
Train: [67][820/1500]	BT 0.037 (0.329)	DT 0.001 (0.292)	loss 6.982 (7.286)	prob 3.042 (2.943)	GS 35.922 (32.777)	mem 74.330
Train: [67][830/1500]	BT 0.031 (0.326)	DT 0.000 (0.288)	loss 7.843 (7.308)	prob 3.064 (2.936)	GS 30.875 (32.422)	mem 74.331
Train: [67][840/1500]	BT 0.063 (0.331)	DT 0.013 (0.294)	loss 7.668 (7.347)	prob 3.260 (2.920)	GS 32.234 (32.309)	mem 74.331
Train: [67][850/1500]	BT 0.060 (0.332)	DT 0.002 (0.294)	loss 7.474 (7.346)	prob 3.207 (2.958)	GS 34.516 (32.748)	mem 74.332
Train: [67][860/1500]	BT 0.054 (0.328)	DT 0.006 (0.291)	loss 7.059 (7.255)	prob 3.557 (3.180)	GS 28.391 (32.198)	mem 74.331
Train: [67][870/1500]	BT 0.071 (0.333)	DT 0.002 (0.295)	loss 7.031 (7.195)	prob 3.140 (3.086)	GS 34.875 (32.962)	mem 74.333
Train: [67][880/1500]	BT 0.064 (0.330)	DT 0.002 (0.291)	loss 7.222 (7.271)	prob 2.876 (2.977)	GS 31.938 (33.150)	mem 74.333
Train: [67][890/1500]	BT 0.021 (0.354)	DT 0.000 (0.315)	loss 8.180 (7.291)	prob 2.379 (2.902)	GS 35.922 (33.401)	mem 74.334
Train: [67][900/1500]	BT 0.023 (0.350)	DT 0.000 (0.312)	loss 7.279 (7.310)	prob 3.124 (2.916)	GS 35.891 (33.187)	mem 74.335
Train: [67][910/1500]	BT 0.024 (0.351)	DT 0.000 (0.313)	loss 7.323 (7.368)	prob 2.051 (2.729)	GS 38.375 (32.891)	mem 74.336
Train: [67][920/1500]	BT 0.035 (0.347)	DT 0.001 (0.309)	loss 7.247 (7.357)	prob 2.435 (2.706)	GS 30.328 (32.409)	mem 74.336
Train: [67][930/1500]	BT 0.035 (0.344)	DT 0.001 (0.306)	loss 7.453 (7.361)	prob 2.537 (2.638)	GS 30.016 (32.488)	mem 74.336
Train: [67][940/1500]	BT 0.029 (0.346)	DT 0.000 (0.308)	loss 7.504 (7.332)	prob 3.466 (2.785)	GS 33.328 (32.409)	mem 74.352
Train: [67][950/1500]	BT 0.035 (0.342)	DT 0.001 (0.304)	loss 7.740 (7.355)	prob 2.323 (2.851)	GS 31.938 (32.299)	mem 74.353
Train: [67][960/1500]	BT 0.029 (0.343)	DT 0.000 (0.305)	loss 7.560 (7.438)	prob 2.900 (2.604)	GS 30.766 (32.169)	mem 74.357
Train: [67][970/1500]	BT 0.036 (0.340)	DT 0.001 (0.302)	loss 6.999 (7.343)	prob 3.216 (2.742)	GS 33.641 (31.926)	mem 74.357
Train: [67][980/1500]	BT 3.174 (0.340)	DT 3.125 (0.302)	loss 8.116 (7.367)	prob 3.024 (2.819)	GS 34.266 (32.426)	mem 74.360
Train: [67][990/1500]	BT 0.068 (0.337)	DT 0.002 (0.299)	loss 7.548 (7.398)	prob 3.022 (2.847)	GS 32.938 (32.925)	mem 74.361
Train: [67][1000/1500]	BT 0.040 (0.335)	DT 0.006 (0.296)	loss 7.453 (7.398)	prob 2.276 (2.817)	GS 32.875 (33.036)	mem 74.361
Train: [67][1010/1500]	BT 0.020 (0.344)	DT 0.000 (0.306)	loss 7.395 (7.450)	prob 2.648 (2.662)	GS 36.578 (34.289)	mem 74.359
Train: [67][1020/1500]	BT 0.034 (0.341)	DT 0.001 (0.303)	loss 7.257 (7.451)	prob 3.817 (2.879)	GS 30.500 (34.494)	mem 74.361
Train: [67][1030/1500]	BT 0.038 (0.339)	DT 0.001 (0.301)	loss 7.186 (7.431)	prob 3.539 (2.981)	GS 37.109 (34.010)	mem 74.362
Train: [67][1040/1500]	BT 0.037 (0.338)	DT 0.001 (0.300)	loss 7.282 (7.428)	prob 2.786 (3.022)	GS 31.188 (33.427)	mem 74.361
Train: [67][1050/1500]	BT 0.087 (0.338)	DT 0.000 (0.300)	loss 7.630 (7.439)	prob 3.233 (2.995)	GS 30.078 (33.123)	mem 74.363
Train: [67][1060/1500]	BT 0.079 (0.337)	DT 0.001 (0.298)	loss 7.219 (7.418)	prob 3.055 (3.004)	GS 32.688 (33.894)	mem 74.364
Train: [67][1070/1500]	BT 0.046 (0.341)	DT 0.005 (0.302)	loss 7.446 (7.393)	prob 2.933 (2.955)	GS 31.797 (32.906)	mem 74.362
Train: [67][1080/1500]	BT 0.061 (0.338)	DT 0.001 (0.299)	loss 8.511 (7.466)	prob 3.098 (2.946)	GS 39.703 (33.049)	mem 74.362
Train: [67][1090/1500]	BT 0.030 (0.344)	DT 0.000 (0.305)	loss 7.169 (7.491)	prob 3.175 (2.926)	GS 34.297 (32.890)	mem 74.363
Train: [67][1100/1500]	BT 0.026 (0.341)	DT 0.000 (0.302)	loss 7.227 (7.489)	prob 3.720 (2.981)	GS 35.219 (32.902)	mem 74.363
Train: [67][1110/1500]	BT 0.034 (0.341)	DT 0.001 (0.302)	loss 8.603 (7.465)	prob 2.378 (2.719)	GS 35.375 (33.483)	mem 74.365
Train: [67][1120/1500]	BT 0.034 (0.338)	DT 0.000 (0.300)	loss 7.480 (7.483)	prob 3.924 (2.851)	GS 32.969 (33.502)	mem 74.365
Train: [67][1130/1500]	BT 0.031 (0.335)	DT 0.001 (0.297)	loss 7.222 (7.465)	prob 3.347 (2.975)	GS 26.922 (33.177)	mem 74.365
Train: [67][1140/1500]	BT 0.060 (0.336)	DT 0.006 (0.298)	loss 7.668 (7.467)	prob 2.640 (3.075)	GS 33.094 (33.102)	mem 74.367
Train: [67][1150/1500]	BT 0.037 (0.339)	DT 0.000 (0.300)	loss 7.468 (7.475)	prob 3.948 (3.054)	GS 29.172 (33.197)	mem 74.369
Train: [67][1160/1500]	BT 0.037 (0.336)	DT 0.001 (0.298)	loss 7.688 (7.625)	prob 3.326 (3.270)	GS 30.328 (31.898)	mem 74.368
Train: [67][1170/1500]	BT 0.038 (0.338)	DT 0.000 (0.299)	loss 7.894 (7.672)	prob 2.483 (3.098)	GS 35.719 (31.767)	mem 74.370
Train: [67][1180/1500]	BT 0.037 (0.336)	DT 0.001 (0.297)	loss 7.468 (7.580)	prob 3.445 (3.113)	GS 37.562 (31.964)	mem 74.370
Train: [67][1190/1500]	BT 0.037 (0.335)	DT 0.001 (0.296)	loss 7.524 (7.542)	prob 3.102 (3.185)	GS 31.734 (32.052)	mem 74.370
Train: [67][1200/1500]	BT 0.040 (0.334)	DT 0.001 (0.295)	loss 8.134 (7.573)	prob 3.108 (3.089)	GS 33.484 (32.006)	mem 74.371
Train: [67][1210/1500]	BT 0.038 (0.332)	DT 0.001 (0.293)	loss 7.440 (7.457)	prob 3.186 (3.034)	GS 37.641 (33.733)	mem 74.372
Train: [67][1220/1500]	BT 0.027 (0.332)	DT 0.000 (0.293)	loss 7.168 (7.366)	prob 3.368 (3.109)	GS 35.359 (33.110)	mem 74.375
Train: [67][1230/1500]	BT 0.037 (0.330)	DT 0.000 (0.291)	loss 7.338 (7.387)	prob 3.205 (3.132)	GS 36.500 (32.652)	mem 74.376
Train: [67][1240/1500]	BT 0.038 (0.328)	DT 0.001 (0.289)	loss 7.636 (7.406)	prob 2.576 (3.052)	GS 32.812 (32.748)	mem 74.375
Train: [67][1250/1500]	BT 0.037 (0.329)	DT 0.000 (0.290)	loss 7.774 (7.427)	prob 3.882 (3.140)	GS 32.859 (32.721)	mem 74.375
Train: [67][1260/1500]	BT 0.038 (0.327)	DT 0.001 (0.288)	loss 7.420 (7.451)	prob 3.760 (3.228)	GS 33.750 (32.702)	mem 74.376
Train: [67][1270/1500]	BT 0.038 (0.326)	DT 0.001 (0.288)	loss 7.335 (7.412)	prob 3.483 (3.288)	GS 34.734 (32.666)	mem 74.375
Train: [67][1280/1500]	BT 0.037 (0.326)	DT 0.001 (0.288)	loss 7.385 (7.442)	prob 3.623 (3.182)	GS 32.688 (32.867)	mem 74.377
Train: [67][1290/1500]	BT 0.038 (0.324)	DT 0.001 (0.286)	loss 7.569 (7.466)	prob 2.768 (3.193)	GS 35.328 (32.869)	mem 74.377
Train: [67][1300/1500]	BT 0.037 (0.322)	DT 0.000 (0.283)	loss 7.873 (7.433)	prob 2.800 (3.180)	GS 35.344 (32.743)	mem 74.377
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [67][1310/1500]	BT 0.053 (0.324)	DT 0.006 (0.285)	loss 7.478 (7.400)	prob 3.676 (3.457)	GS 34.531 (32.316)	mem 74.377
Train: [67][1320/1500]	BT 0.061 (0.324)	DT 0.006 (0.285)	loss 7.041 (7.358)	prob 4.025 (3.468)	GS 35.859 (32.284)	mem 74.377
Train: [67][1330/1500]	BT 0.029 (0.332)	DT 0.001 (0.294)	loss 7.001 (7.355)	prob 3.884 (3.240)	GS 35.844 (32.705)	mem 74.408
Train: [67][1340/1500]	BT 0.028 (0.330)	DT 0.000 (0.291)	loss 7.728 (7.346)	prob 2.917 (3.220)	GS 33.922 (32.741)	mem 74.408
Train: [67][1350/1500]	BT 0.039 (0.330)	DT 0.001 (0.291)	loss 7.255 (7.344)	prob 3.612 (3.172)	GS 31.406 (32.440)	mem 74.410
Train: [67][1360/1500]	BT 0.036 (0.328)	DT 0.001 (0.289)	loss 7.487 (7.264)	prob 3.840 (3.307)	GS 30.047 (31.400)	mem 74.410
Train: [67][1370/1500]	BT 0.039 (0.325)	DT 0.001 (0.287)	loss 7.130 (7.303)	prob 3.173 (3.240)	GS 31.906 (32.865)	mem 74.410
Train: [67][1380/1500]	BT 0.039 (0.325)	DT 0.001 (0.287)	loss 8.191 (7.356)	prob 2.405 (3.134)	GS 34.062 (32.723)	mem 74.411
Train: [67][1390/1500]	BT 0.039 (0.323)	DT 0.001 (0.285)	loss 7.722 (7.379)	prob 3.101 (3.117)	GS 34.844 (32.838)	mem 74.412
Train: [67][1400/1500]	BT 0.028 (0.325)	DT 0.000 (0.286)	loss 6.969 (7.368)	prob 3.832 (3.126)	GS 33.656 (32.699)	mem 74.412
Train: [67][1410/1500]	BT 0.039 (0.323)	DT 0.001 (0.284)	loss 7.231 (7.275)	prob 3.607 (3.310)	GS 37.547 (33.255)	mem 74.412
Train: [67][1420/1500]	BT 6.092 (0.325)	DT 6.052 (0.287)	loss 7.293 (7.319)	prob 3.286 (3.185)	GS 36.562 (32.741)	mem 74.412
Train: [67][1430/1500]	BT 0.047 (0.323)	DT 0.016 (0.285)	loss 7.335 (7.330)	prob 3.305 (3.155)	GS 31.438 (32.699)	mem 74.413
Train: [67][1440/1500]	BT 0.057 (0.321)	DT 0.010 (0.283)	loss 7.549 (7.318)	prob 3.486 (3.250)	GS 34.047 (32.644)	mem 74.413
Train: [67][1450/1500]	BT 0.108 (0.326)	DT 0.024 (0.287)	loss 7.228 (7.315)	prob 3.292 (3.199)	GS 29.844 (32.478)	mem 74.379
Train: [67][1460/1500]	BT 0.030 (0.329)	DT 0.001 (0.290)	loss 8.093 (7.480)	prob 3.181 (2.979)	GS 34.422 (32.616)	mem 73.573
Train: [67][1470/1500]	BT 0.028 (0.326)	DT 0.000 (0.288)	loss 7.126 (7.339)	prob 3.409 (3.367)	GS 36.234 (32.606)	mem 73.538
Train: [67][1480/1500]	BT 0.028 (0.324)	DT 0.000 (0.286)	loss 7.304 (7.345)	prob 3.428 (3.317)	GS 31.719 (32.547)	mem 73.538
Train: [67][1490/1500]	BT 0.035 (0.324)	DT 0.000 (0.286)	loss 7.129 (7.358)	prob 2.546 (3.237)	GS 36.250 (32.651)	mem 9.391
Train: [67][1500/1500]	BT 0.038 (0.322)	DT 0.000 (0.284)	loss 6.919 (7.358)	prob 2.971 (3.197)	GS 35.312 (32.787)	mem 9.390
Train: [67][1510/1500]	BT 0.032 (0.321)	DT 0.000 (0.282)	loss 6.952 (7.246)	prob 2.499 (2.809)	GS 39.562 (32.097)	mem 9.317
epoch 67, total time 484.47
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [68][1/1500]	BT 18.244 (18.244)	DT 18.151 (18.151)	loss 6.966 (6.966)	prob 2.613 (2.613)	GS 30.078 (30.078)	mem 72.452
Train: [68][10/1500]	BT 0.048 (2.631)	DT 0.010 (2.590)	loss 7.780 (7.132)	prob 3.310 (3.065)	GS 32.047 (33.590)	mem 73.085
Train: [68][20/1500]	BT 0.037 (1.334)	DT 0.000 (1.295)	loss 7.803 (7.171)	prob 2.987 (3.195)	GS 32.578 (32.979)	mem 73.092
Train: [68][30/1500]	BT 0.037 (0.995)	DT 0.001 (0.957)	loss 8.041 (7.238)	prob 3.055 (3.155)	GS 35.562 (33.194)	mem 73.142
Train: [68][40/1500]	BT 0.026 (0.853)	DT 0.000 (0.817)	loss 7.252 (7.244)	prob 3.740 (3.267)	GS 39.188 (33.465)	mem 73.037
Train: [68][50/1500]	BT 0.029 (0.688)	DT 0.000 (0.654)	loss 7.206 (7.262)	prob 2.745 (3.283)	GS 37.047 (33.164)	mem 73.037
Train: [68][60/1500]	BT 0.037 (0.629)	DT 0.001 (0.594)	loss 7.112 (7.235)	prob 3.255 (3.043)	GS 34.031 (32.691)	mem 73.050
Train: [68][70/1500]	BT 0.036 (0.547)	DT 0.001 (0.510)	loss 6.940 (7.300)	prob 3.516 (3.103)	GS 32.500 (32.756)	mem 73.053
Train: [68][80/1500]	BT 0.473 (0.532)	DT 0.437 (0.495)	loss 7.058 (7.296)	prob 2.994 (3.071)	GS 35.344 (32.878)	mem 73.064
Train: [68][90/1500]	BT 0.031 (0.476)	DT 0.000 (0.440)	loss 7.252 (7.314)	prob 3.380 (3.100)	GS 35.500 (33.075)	mem 73.064
Train: [68][100/1500]	BT 0.037 (0.482)	DT 0.000 (0.445)	loss 7.107 (7.299)	prob 3.749 (3.152)	GS 33.516 (32.722)	mem 73.079
Train: [68][110/1500]	BT 0.037 (0.448)	DT 0.001 (0.411)	loss 7.319 (7.292)	prob 3.014 (3.047)	GS 34.328 (31.514)	mem 73.099
Train: [68][120/1500]	BT 0.037 (0.414)	DT 0.000 (0.377)	loss 7.389 (7.297)	prob 3.482 (3.105)	GS 35.344 (31.379)	mem 73.102
Train: [68][130/1500]	BT 0.038 (0.406)	DT 0.001 (0.370)	loss 7.378 (7.321)	prob 2.513 (3.034)	GS 33.078 (31.843)	mem 73.106
Train: [68][140/1500]	BT 0.038 (0.380)	DT 0.000 (0.343)	loss 7.462 (7.348)	prob 3.306 (2.991)	GS 35.266 (31.862)	mem 73.107
Train: [68][150/1500]	BT 0.037 (0.377)	DT 0.001 (0.340)	loss 7.675 (7.338)	prob 3.152 (2.958)	GS 36.922 (31.964)	mem 73.111
Train: [68][160/1500]	BT 0.037 (0.357)	DT 0.001 (0.321)	loss 7.649 (7.190)	prob 3.035 (2.824)	GS 33.016 (32.325)	mem 73.117
Train: [68][170/1500]	BT 0.037 (0.341)	DT 0.001 (0.304)	loss 7.480 (7.240)	prob 2.172 (2.747)	GS 29.781 (31.584)	mem 73.118
Train: [68][180/1500]	BT 0.027 (0.359)	DT 0.000 (0.323)	loss 7.323 (7.275)	prob 3.268 (2.813)	GS 31.594 (31.979)	mem 73.110
Train: [68][190/1500]	BT 0.035 (0.344)	DT 0.000 (0.308)	loss 7.119 (7.269)	prob 3.064 (2.882)	GS 32.547 (32.032)	mem 73.112
Train: [68][200/1500]	BT 0.122 (0.368)	DT 0.087 (0.331)	loss 7.634 (7.299)	prob 2.739 (2.863)	GS 34.688 (32.663)	mem 73.118
Train: [68][210/1500]	BT 0.034 (0.358)	DT 0.000 (0.320)	loss 7.384 (7.215)	prob 2.923 (3.239)	GS 30.250 (31.363)	mem 73.119
Train: [68][220/1500]	BT 0.053 (0.366)	DT 0.006 (0.328)	loss 7.753 (7.298)	prob 2.741 (3.066)	GS 34.328 (32.120)	mem 73.122
Train: [68][230/1500]	BT 0.029 (0.398)	DT 0.000 (0.360)	loss 8.086 (7.324)	prob 2.639 (3.043)	GS 37.344 (32.548)	mem 73.136
Train: [68][240/1500]	BT 0.027 (0.382)	DT 0.000 (0.345)	loss 7.459 (7.313)	prob 3.516 (3.052)	GS 31.859 (32.959)	mem 73.137
Train: [68][250/1500]	BT 0.039 (0.380)	DT 0.001 (0.342)	loss 7.797 (7.337)	prob 2.908 (2.993)	GS 33.000 (32.881)	mem 73.130
Train: [68][260/1500]	BT 0.039 (0.366)	DT 0.001 (0.329)	loss 7.327 (7.140)	prob 2.831 (3.109)	GS 28.516 (31.606)	mem 73.129
Train: [68][270/1500]	BT 0.039 (0.354)	DT 0.001 (0.317)	loss 7.200 (7.237)	prob 3.301 (3.031)	GS 31.750 (32.171)	mem 73.128
Train: [68][280/1500]	BT 0.039 (0.357)	DT 0.001 (0.320)	loss 7.631 (7.270)	prob 3.272 (2.994)	GS 35.719 (32.448)	mem 73.126
Train: [68][290/1500]	BT 0.039 (0.346)	DT 0.001 (0.309)	loss 7.369 (7.258)	prob 3.359 (2.995)	GS 31.922 (32.206)	mem 73.125
Train: [68][300/1500]	BT 0.039 (0.350)	DT 0.001 (0.312)	loss 7.497 (7.272)	prob 2.978 (3.019)	GS 30.094 (32.236)	mem 73.128
Train: [68][310/1500]	BT 0.038 (0.340)	DT 0.001 (0.302)	loss 6.888 (7.232)	prob 2.972 (2.795)	GS 35.812 (32.513)	mem 73.133
Train: [68][320/1500]	BT 0.037 (0.331)	DT 0.001 (0.293)	loss 7.629 (7.389)	prob 3.418 (2.746)	GS 35.109 (32.587)	mem 73.139
Train: [68][330/1500]	BT 0.028 (0.351)	DT 0.000 (0.314)	loss 7.101 (7.362)	prob 2.706 (2.744)	GS 30.078 (33.095)	mem 73.149
Train: [68][340/1500]	BT 0.037 (0.344)	DT 0.001 (0.307)	loss 7.389 (7.363)	prob 3.855 (2.854)	GS 38.922 (33.105)	mem 73.151
Train: [68][350/1500]	BT 0.031 (0.344)	DT 0.000 (0.307)	loss 7.328 (7.348)	prob 2.856 (2.822)	GS 35.938 (33.043)	mem 73.154
Train: [68][360/1500]	BT 0.037 (0.335)	DT 0.001 (0.298)	loss 7.122 (7.309)	prob 2.570 (2.588)	GS 31.562 (33.784)	mem 73.155
Train: [68][370/1500]	BT 0.034 (0.340)	DT 0.000 (0.303)	loss 8.189 (7.365)	prob 3.216 (2.771)	GS 32.391 (32.688)	mem 73.159
Train: [68][380/1500]	BT 0.036 (0.332)	DT 0.000 (0.295)	loss 7.512 (7.398)	prob 2.531 (2.852)	GS 36.578 (32.820)	mem 73.160
Train: [68][390/1500]	BT 0.034 (0.325)	DT 0.001 (0.288)	loss 7.138 (7.393)	prob 2.990 (2.898)	GS 32.156 (32.835)	mem 73.161
Train: [68][400/1500]	BT 0.068 (0.328)	DT 0.013 (0.291)	loss 7.453 (7.414)	prob 3.423 (2.881)	GS 34.547 (33.002)	mem 73.163
Train: [68][410/1500]	BT 0.064 (0.321)	DT 0.006 (0.284)	loss 7.295 (7.483)	prob 4.082 (3.133)	GS 28.750 (32.764)	mem 73.164
Train: [68][420/1500]	BT 0.037 (0.325)	DT 0.001 (0.287)	loss 7.504 (7.521)	prob 3.174 (3.146)	GS 33.469 (32.719)	mem 73.167
Train: [68][430/1500]	BT 0.038 (0.318)	DT 0.001 (0.281)	loss 7.484 (7.536)	prob 3.395 (3.078)	GS 38.859 (33.367)	mem 73.168
Train: [68][440/1500]	BT 0.037 (0.317)	DT 0.000 (0.280)	loss 7.464 (7.523)	prob 4.510 (3.162)	GS 36.109 (33.304)	mem 73.168
Train: [68][450/1500]	BT 0.038 (0.315)	DT 0.000 (0.277)	loss 7.729 (7.521)	prob 3.317 (3.202)	GS 37.812 (33.341)	mem 73.171
Train: [68][460/1500]	BT 0.037 (0.311)	DT 0.000 (0.274)	loss 7.536 (7.512)	prob 4.072 (3.363)	GS 31.141 (31.364)	mem 73.170
Train: [68][470/1500]	BT 0.038 (0.309)	DT 0.001 (0.271)	loss 7.338 (7.527)	prob 3.506 (3.289)	GS 36.203 (31.165)	mem 73.172
Train: [68][480/1500]	BT 0.027 (0.307)	DT 0.000 (0.269)	loss 7.220 (7.542)	prob 3.422 (3.314)	GS 33.797 (31.142)	mem 73.224
Train: [68][490/1500]	BT 0.037 (0.304)	DT 0.000 (0.267)	loss 7.810 (7.553)	prob 3.747 (3.281)	GS 29.406 (31.232)	mem 73.517
Train: [68][500/1500]	BT 0.038 (0.309)	DT 0.001 (0.271)	loss 7.419 (7.551)	prob 3.555 (3.288)	GS 35.281 (31.432)	mem 74.156
Train: [68][510/1500]	BT 0.038 (0.303)	DT 0.001 (0.266)	loss 7.820 (7.572)	prob 3.619 (3.545)	GS 33.625 (31.994)	mem 74.206
Train: [68][520/1500]	BT 0.032 (0.308)	DT 0.000 (0.271)	loss 7.496 (7.584)	prob 3.983 (3.368)	GS 34.297 (32.431)	mem 74.356
Train: [68][530/1500]	BT 0.052 (0.303)	DT 0.009 (0.266)	loss 7.719 (7.638)	prob 3.878 (3.334)	GS 35.531 (32.523)	mem 74.359
Train: [68][540/1500]	BT 0.038 (0.298)	DT 0.001 (0.261)	loss 7.651 (7.610)	prob 2.825 (3.330)	GS 34.844 (32.708)	mem 74.360
Train: [68][550/1500]	BT 0.033 (0.300)	DT 0.000 (0.263)	loss 7.688 (7.622)	prob 4.016 (3.290)	GS 36.062 (32.489)	mem 74.362
Train: [68][560/1500]	BT 0.081 (0.296)	DT 0.016 (0.258)	loss 7.343 (7.472)	prob 3.292 (2.999)	GS 34.859 (32.352)	mem 74.363
Train: [68][570/1500]	BT 0.026 (0.322)	DT 0.000 (0.284)	loss 8.303 (7.500)	prob 3.075 (3.180)	GS 31.656 (32.883)	mem 74.364
Train: [68][580/1500]	BT 0.027 (0.317)	DT 0.001 (0.279)	loss 7.700 (7.478)	prob 3.412 (3.346)	GS 34.172 (32.873)	mem 74.364
Train: [68][590/1500]	BT 5.039 (0.320)	DT 5.007 (0.283)	loss 7.444 (7.520)	prob 3.001 (3.332)	GS 34.453 (33.312)	mem 74.366
Train: [68][600/1500]	BT 0.031 (0.315)	DT 0.000 (0.278)	loss 7.808 (7.537)	prob 4.302 (3.376)	GS 28.516 (32.970)	mem 74.366
Train: [68][610/1500]	BT 0.060 (0.311)	DT 0.016 (0.274)	loss 7.343 (7.431)	prob 3.476 (3.687)	GS 33.109 (31.598)	mem 74.367
Train: [68][620/1500]	BT 0.038 (0.313)	DT 0.001 (0.276)	loss 7.330 (7.468)	prob 3.413 (3.656)	GS 30.969 (32.514)	mem 74.367
Train: [68][630/1500]	BT 0.037 (0.309)	DT 0.001 (0.272)	loss 7.820 (7.501)	prob 3.991 (3.492)	GS 34.359 (32.691)	mem 74.367
Train: [68][640/1500]	BT 0.037 (0.311)	DT 0.001 (0.273)	loss 7.629 (7.501)	prob 3.681 (3.559)	GS 38.234 (32.430)	mem 74.368
Train: [68][650/1500]	BT 0.036 (0.307)	DT 0.001 (0.269)	loss 7.386 (7.510)	prob 4.461 (3.572)	GS 30.297 (32.319)	mem 74.368
Train: [68][660/1500]	BT 0.068 (0.303)	DT 0.009 (0.265)	loss 7.417 (7.434)	prob 4.334 (4.080)	GS 34.906 (32.536)	mem 74.392
Train: [68][670/1500]	BT 0.036 (0.314)	DT 0.000 (0.276)	loss 7.609 (7.453)	prob 3.884 (3.894)	GS 32.734 (32.230)	mem 74.373
Train: [68][680/1500]	BT 0.027 (0.310)	DT 0.000 (0.272)	loss 7.425 (7.464)	prob 3.592 (3.835)	GS 31.453 (32.228)	mem 74.374
Train: [68][690/1500]	BT 0.037 (0.307)	DT 0.001 (0.270)	loss 7.401 (7.467)	prob 3.630 (3.690)	GS 32.938 (32.319)	mem 74.375
Train: [68][700/1500]	BT 0.036 (0.309)	DT 0.000 (0.271)	loss 7.469 (7.470)	prob 2.796 (3.632)	GS 35.281 (32.704)	mem 74.407
Train: [68][710/1500]	BT 0.038 (0.305)	DT 0.001 (0.267)	loss 7.685 (7.496)	prob 3.739 (3.519)	GS 31.203 (31.714)	mem 74.407
Train: [68][720/1500]	BT 0.031 (0.312)	DT 0.000 (0.275)	loss 8.827 (7.496)	prob 2.052 (3.528)	GS 36.141 (32.700)	mem 74.407
Train: [68][730/1500]	BT 0.038 (0.308)	DT 0.001 (0.271)	loss 7.737 (7.456)	prob 3.037 (3.591)	GS 34.688 (32.540)	mem 74.408
Train: [68][740/1500]	BT 0.040 (0.306)	DT 0.001 (0.268)	loss 7.141 (7.434)	prob 3.720 (3.530)	GS 32.188 (32.848)	mem 74.408
Train: [68][750/1500]	BT 0.068 (0.308)	DT 0.016 (0.270)	loss 7.587 (7.450)	prob 3.778 (3.563)	GS 35.359 (32.815)	mem 74.406
Train: [68][760/1500]	BT 0.059 (0.306)	DT 0.015 (0.268)	loss 7.408 (7.290)	prob 3.670 (3.568)	GS 37.641 (31.809)	mem 74.406
Train: [68][770/1500]	BT 0.030 (0.324)	DT 0.000 (0.286)	loss 7.870 (7.423)	prob 3.343 (3.443)	GS 33.312 (32.639)	mem 74.405
Train: [68][780/1500]	BT 0.034 (0.320)	DT 0.001 (0.283)	loss 7.376 (7.463)	prob 3.874 (3.431)	GS 32.203 (32.688)	mem 74.405
Train: [68][790/1500]	BT 0.037 (0.317)	DT 0.000 (0.279)	loss 7.251 (7.457)	prob 4.121 (3.538)	GS 32.781 (32.769)	mem 74.406
Train: [68][800/1500]	BT 0.031 (0.319)	DT 0.000 (0.282)	loss 7.288 (7.436)	prob 4.063 (3.554)	GS 33.609 (33.002)	mem 74.406
Train: [68][810/1500]	BT 0.035 (0.316)	DT 0.000 (0.278)	loss 7.692 (7.329)	prob 4.034 (3.993)	GS 29.344 (31.773)	mem 74.405
Train: [68][820/1500]	BT 0.033 (0.317)	DT 0.001 (0.280)	loss 7.320 (7.349)	prob 3.913 (3.937)	GS 33.469 (31.772)	mem 74.407
Train: [68][830/1500]	BT 0.038 (0.314)	DT 0.001 (0.276)	loss 7.376 (7.389)	prob 4.365 (3.932)	GS 35.109 (32.569)	mem 74.408
Train: [68][840/1500]	BT 0.056 (0.316)	DT 0.002 (0.279)	loss 7.435 (7.370)	prob 3.058 (3.918)	GS 35.422 (32.587)	mem 74.411
Train: [68][850/1500]	BT 0.065 (0.313)	DT 0.006 (0.276)	loss 7.638 (7.391)	prob 4.131 (3.876)	GS 32.000 (32.601)	mem 74.411
Train: [68][860/1500]	BT 0.084 (0.311)	DT 0.005 (0.273)	loss 7.314 (7.226)	prob 3.915 (3.775)	GS 36.406 (32.767)	mem 74.411
Train: [68][870/1500]	BT 0.030 (0.318)	DT 0.000 (0.280)	loss 7.624 (7.359)	prob 3.543 (3.773)	GS 35.328 (34.745)	mem 74.409
Train: [68][880/1500]	BT 0.033 (0.315)	DT 0.001 (0.277)	loss 7.577 (7.347)	prob 2.873 (3.786)	GS 39.359 (34.849)	mem 74.409
Train: [68][890/1500]	BT 0.041 (0.315)	DT 0.001 (0.277)	loss 8.234 (7.354)	prob 3.041 (3.819)	GS 34.875 (34.266)	mem 74.413
Train: [68][900/1500]	BT 0.030 (0.312)	DT 0.000 (0.274)	loss 7.443 (7.371)	prob 4.097 (3.781)	GS 31.328 (34.060)	mem 74.415
Train: [68][910/1500]	BT 0.033 (0.309)	DT 0.001 (0.271)	loss 7.118 (7.180)	prob 4.591 (3.936)	GS 32.875 (31.731)	mem 74.416
Train: [68][920/1500]	BT 0.029 (0.313)	DT 0.000 (0.276)	loss 7.373 (7.242)	prob 4.058 (3.923)	GS 31.297 (31.637)	mem 74.413
Train: [68][930/1500]	BT 0.025 (0.310)	DT 0.000 (0.273)	loss 7.490 (7.242)	prob 3.828 (3.881)	GS 31.109 (31.722)	mem 74.414
Train: [68][940/1500]	BT 0.036 (0.311)	DT 0.000 (0.274)	loss 7.268 (7.234)	prob 3.490 (3.894)	GS 31.844 (31.772)	mem 74.416
Train: [68][950/1500]	BT 0.037 (0.309)	DT 0.001 (0.271)	loss 7.258 (7.223)	prob 3.288 (3.854)	GS 31.219 (31.413)	mem 74.416
Train: [68][960/1500]	BT 0.053 (0.310)	DT 0.006 (0.273)	loss 7.340 (7.223)	prob 3.437 (3.311)	GS 35.281 (32.280)	mem 74.418
Train: [68][970/1500]	BT 0.062 (0.308)	DT 0.004 (0.271)	loss 7.385 (7.250)	prob 3.358 (3.467)	GS 32.516 (32.162)	mem 74.419
Train: [68][980/1500]	BT 0.063 (0.306)	DT 0.004 (0.269)	loss 7.183 (7.209)	prob 3.564 (3.480)	GS 32.312 (32.165)	mem 74.420
Train: [68][990/1500]	BT 0.029 (0.315)	DT 0.000 (0.278)	loss 7.183 (7.217)	prob 3.560 (3.540)	GS 32.750 (32.315)	mem 74.422
Train: [68][1000/1500]	BT 0.036 (0.313)	DT 0.000 (0.275)	loss 7.094 (7.208)	prob 3.368 (3.527)	GS 34.891 (32.310)	mem 74.433
Train: [68][1010/1500]	BT 0.056 (0.313)	DT 0.005 (0.276)	loss 6.982 (7.122)	prob 3.862 (3.457)	GS 33.750 (33.066)	mem 74.434
Train: [68][1020/1500]	BT 0.031 (0.311)	DT 0.000 (0.273)	loss 7.264 (7.192)	prob 3.858 (3.412)	GS 35.656 (32.827)	mem 74.434
Train: [68][1030/1500]	BT 0.036 (0.326)	DT 0.001 (0.288)	loss 7.114 (7.183)	prob 3.427 (3.489)	GS 30.938 (32.703)	mem 74.331
Train: [68][1040/1500]	BT 0.029 (0.323)	DT 0.000 (0.285)	loss 7.370 (7.204)	prob 3.807 (3.496)	GS 31.469 (32.844)	mem 74.335
Train: [68][1050/1500]	BT 0.035 (0.320)	DT 0.001 (0.283)	loss 7.544 (7.195)	prob 2.521 (3.427)	GS 31.906 (33.143)	mem 74.336
Train: [68][1060/1500]	BT 0.037 (0.320)	DT 0.000 (0.283)	loss 7.232 (7.252)	prob 3.769 (3.413)	GS 36.906 (33.092)	mem 74.336
Train: [68][1070/1500]	BT 0.038 (0.317)	DT 0.000 (0.280)	loss 7.246 (7.228)	prob 3.392 (3.514)	GS 31.734 (32.941)	mem 74.336
Train: [68][1080/1500]	BT 0.039 (0.317)	DT 0.001 (0.280)	loss 6.886 (7.220)	prob 3.502 (3.463)	GS 37.094 (32.746)	mem 74.336
Train: [68][1090/1500]	BT 0.037 (0.315)	DT 0.000 (0.277)	loss 7.219 (7.196)	prob 2.933 (3.349)	GS 31.062 (32.413)	mem 74.335
Train: [68][1100/1500]	BT 0.037 (0.312)	DT 0.001 (0.275)	loss 7.142 (7.210)	prob 3.674 (3.346)	GS 37.484 (32.322)	mem 74.335
Train: [68][1110/1500]	BT 0.037 (0.313)	DT 0.001 (0.276)	loss 7.001 (7.079)	prob 3.288 (3.184)	GS 31.531 (33.159)	mem 74.335
Train: [68][1120/1500]	BT 0.042 (0.312)	DT 0.000 (0.275)	loss 7.317 (7.198)	prob 3.148 (3.051)	GS 33.531 (33.458)	mem 74.335
Train: [68][1130/1500]	BT 0.031 (0.314)	DT 0.000 (0.276)	loss 7.205 (7.211)	prob 3.247 (3.125)	GS 35.250 (33.177)	mem 74.336
Train: [68][1140/1500]	BT 0.053 (0.314)	DT 0.006 (0.276)	loss 7.342 (7.180)	prob 3.032 (3.144)	GS 35.781 (33.524)	mem 74.339
Train: [68][1150/1500]	BT 0.664 (0.314)	DT 0.629 (0.276)	loss 7.111 (7.182)	prob 3.711 (3.181)	GS 31.766 (33.135)	mem 74.341
Train: [68][1160/1500]	BT 0.036 (0.311)	DT 0.001 (0.274)	loss 7.092 (7.162)	prob 3.054 (3.215)	GS 35.672 (34.467)	mem 74.340
Train: [68][1170/1500]	BT 0.028 (0.311)	DT 0.000 (0.274)	loss 7.153 (7.248)	prob 2.865 (3.072)	GS 33.062 (33.685)	mem 74.360
Train: [68][1180/1500]	BT 0.037 (0.310)	DT 0.001 (0.272)	loss 6.939 (7.261)	prob 4.163 (3.125)	GS 33.578 (33.286)	mem 74.347
Train: [68][1190/1500]	BT 0.038 (0.310)	DT 0.001 (0.272)	loss 7.217 (7.243)	prob 2.835 (3.128)	GS 34.750 (33.155)	mem 74.349
Train: [68][1200/1500]	BT 0.072 (0.308)	DT 0.006 (0.271)	loss 7.277 (7.241)	prob 3.004 (3.060)	GS 34.203 (33.080)	mem 74.349
Train: [68][1210/1500]	BT 0.038 (0.310)	DT 0.001 (0.272)	loss 7.274 (7.246)	prob 2.077 (2.760)	GS 33.781 (34.047)	mem 74.349
Train: [68][1220/1500]	BT 0.039 (0.307)	DT 0.001 (0.270)	loss 7.330 (7.255)	prob 3.203 (3.055)	GS 30.734 (33.759)	mem 74.348
Train: [68][1230/1500]	BT 0.039 (0.307)	DT 0.001 (0.269)	loss 7.451 (7.244)	prob 3.448 (3.117)	GS 36.812 (33.447)	mem 74.349
Train: [68][1240/1500]	BT 0.040 (0.306)	DT 0.001 (0.269)	loss 7.365 (7.249)	prob 3.283 (3.085)	GS 35.844 (33.014)	mem 74.350
Train: [68][1250/1500]	BT 0.039 (0.304)	DT 0.001 (0.267)	loss 7.174 (7.249)	prob 3.170 (3.057)	GS 32.328 (33.086)	mem 74.350
Train: [68][1260/1500]	BT 0.039 (0.305)	DT 0.001 (0.267)	loss 7.451 (7.317)	prob 2.467 (2.813)	GS 34.641 (33.139)	mem 74.351
Train: [68][1270/1500]	BT 0.039 (0.303)	DT 0.001 (0.266)	loss 7.630 (7.348)	prob 3.319 (3.001)	GS 34.375 (32.471)	mem 74.351
Train: [68][1280/1500]	BT 0.040 (0.304)	DT 0.001 (0.267)	loss 7.528 (7.348)	prob 2.441 (3.028)	GS 32.703 (32.091)	mem 74.350
Train: [68][1290/1500]	BT 0.067 (0.302)	DT 0.001 (0.265)	loss 7.836 (7.338)	prob 2.795 (3.033)	GS 35.719 (32.019)	mem 74.350
Train: [68][1300/1500]	BT 0.066 (0.303)	DT 0.007 (0.266)	loss 7.256 (7.338)	prob 2.789 (2.964)	GS 35.719 (32.325)	mem 74.362
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [68][1310/1500]	BT 0.049 (0.303)	DT 0.015 (0.265)	loss 7.183 (7.348)	prob 3.746 (3.168)	GS 35.109 (32.652)	mem 74.365
Train: [68][1320/1500]	BT 0.037 (0.301)	DT 0.001 (0.263)	loss 7.540 (7.427)	prob 2.368 (2.979)	GS 35.016 (32.312)	mem 74.366
Train: [68][1330/1500]	BT 0.034 (0.305)	DT 0.000 (0.267)	loss 7.082 (7.420)	prob 3.130 (2.782)	GS 37.047 (33.313)	mem 74.367
Train: [68][1340/1500]	BT 0.034 (0.303)	DT 0.001 (0.265)	loss 7.574 (7.413)	prob 2.804 (2.847)	GS 34.922 (33.371)	mem 74.368
Train: [68][1350/1500]	BT 0.037 (0.302)	DT 0.001 (0.265)	loss 7.935 (7.432)	prob 2.378 (2.794)	GS 34.281 (33.283)	mem 74.370
Train: [68][1360/1500]	BT 0.035 (0.301)	DT 0.001 (0.263)	loss 8.000 (7.485)	prob 2.859 (3.175)	GS 35.281 (32.973)	mem 74.372
Train: [68][1370/1500]	BT 0.034 (0.299)	DT 0.001 (0.262)	loss 8.058 (7.594)	prob 3.329 (3.085)	GS 31.531 (32.654)	mem 74.372
Train: [68][1380/1500]	BT 0.038 (0.300)	DT 0.001 (0.263)	loss 7.864 (7.544)	prob 2.622 (3.138)	GS 32.656 (32.349)	mem 74.373
Train: [68][1390/1500]	BT 0.038 (0.298)	DT 0.001 (0.261)	loss 7.298 (7.521)	prob 3.732 (3.192)	GS 29.641 (32.457)	mem 74.373
Train: [68][1400/1500]	BT 0.037 (0.299)	DT 0.000 (0.262)	loss 8.106 (7.508)	prob 2.525 (3.176)	GS 35.266 (32.453)	mem 74.375
Train: [68][1410/1500]	BT 0.037 (0.297)	DT 0.001 (0.260)	loss 7.343 (7.528)	prob 3.144 (2.630)	GS 36.766 (32.888)	mem 74.375
Train: [68][1420/1500]	BT 0.051 (0.299)	DT 0.000 (0.261)	loss 8.194 (7.539)	prob 2.918 (2.894)	GS 39.078 (32.468)	mem 74.375
Train: [68][1430/1500]	BT 0.038 (0.297)	DT 0.001 (0.260)	loss 7.520 (7.496)	prob 3.071 (3.005)	GS 34.844 (32.457)	mem 74.375
Train: [68][1440/1500]	BT 0.037 (0.296)	DT 0.000 (0.258)	loss 7.563 (7.484)	prob 3.696 (3.055)	GS 34.094 (32.238)	mem 74.375
Train: [68][1450/1500]	BT 0.054 (0.298)	DT 0.006 (0.261)	loss 6.997 (7.486)	prob 3.898 (3.088)	GS 31.891 (32.394)	mem 74.267
Train: [68][1460/1500]	BT 0.034 (0.303)	DT 0.001 (0.265)	loss 7.286 (7.399)	prob 3.206 (3.327)	GS 33.062 (31.614)	mem 73.607
Train: [68][1470/1500]	BT 0.029 (0.301)	DT 0.000 (0.263)	loss 7.681 (7.507)	prob 3.541 (3.322)	GS 32.984 (31.521)	mem 73.607
Train: [68][1480/1500]	BT 0.037 (0.301)	DT 0.001 (0.263)	loss 7.615 (7.508)	prob 3.449 (3.326)	GS 33.641 (31.930)	mem 9.354
Train: [68][1490/1500]	BT 0.024 (0.299)	DT 0.000 (0.262)	loss 8.010 (7.518)	prob 2.966 (3.290)	GS 34.688 (31.843)	mem 9.354
Train: [68][1500/1500]	BT 0.024 (0.297)	DT 0.000 (0.260)	loss 7.689 (7.516)	prob 2.994 (3.299)	GS 30.625 (32.063)	mem 9.354
Train: [68][1510/1500]	BT 0.034 (0.296)	DT 0.000 (0.259)	loss 7.107 (7.463)	prob 3.825 (2.920)	GS 32.656 (32.975)	mem 9.280
epoch 68, total time 447.40
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [69][1/1500]	BT 18.165 (18.165)	DT 18.110 (18.110)	loss 7.126 (7.126)	prob 3.213 (3.213)	GS 28.812 (28.812)	mem 72.878
Train: [69][10/1500]	BT 0.030 (2.424)	DT 0.000 (2.386)	loss 7.059 (7.266)	prob 3.404 (3.408)	GS 31.250 (32.278)	mem 73.141
Train: [69][20/1500]	BT 0.038 (1.232)	DT 0.001 (1.194)	loss 7.236 (7.325)	prob 3.253 (3.256)	GS 34.422 (32.920)	mem 73.144
Train: [69][30/1500]	BT 0.051 (0.853)	DT 0.013 (0.812)	loss 7.151 (7.349)	prob 4.309 (3.305)	GS 29.641 (32.631)	mem 73.147
Train: [69][40/1500]	BT 0.083 (0.836)	DT 0.011 (0.795)	loss 7.441 (7.362)	prob 3.405 (3.373)	GS 31.031 (32.510)	mem 73.185
Train: [69][50/1500]	BT 0.038 (0.723)	DT 0.001 (0.681)	loss 7.080 (7.391)	prob 3.867 (3.373)	GS 33.031 (32.666)	mem 73.201
Train: [69][60/1500]	BT 0.037 (0.661)	DT 0.001 (0.620)	loss 7.730 (7.419)	prob 3.504 (3.503)	GS 34.188 (32.164)	mem 73.211
Train: [69][70/1500]	BT 0.038 (0.573)	DT 0.000 (0.533)	loss 7.437 (7.467)	prob 3.896 (3.340)	GS 29.250 (31.766)	mem 73.212
Train: [69][80/1500]	BT 0.037 (0.522)	DT 0.000 (0.482)	loss 7.806 (7.461)	prob 3.801 (3.386)	GS 34.422 (32.113)	mem 73.221
Train: [69][90/1500]	BT 0.064 (0.499)	DT 0.004 (0.458)	loss 7.209 (7.448)	prob 3.699 (3.430)	GS 33.688 (31.962)	mem 73.234
Train: [69][100/1500]	BT 0.028 (0.460)	DT 0.000 (0.420)	loss 7.766 (7.447)	prob 3.699 (3.437)	GS 33.219 (32.231)	mem 73.235
Train: [69][110/1500]	BT 0.038 (0.461)	DT 0.001 (0.421)	loss 7.813 (7.383)	prob 2.695 (3.486)	GS 34.156 (31.859)	mem 73.240
Train: [69][120/1500]	BT 0.037 (0.426)	DT 0.000 (0.386)	loss 7.329 (7.370)	prob 3.356 (3.553)	GS 32.781 (31.705)	mem 73.244
Train: [69][130/1500]	BT 0.038 (0.417)	DT 0.001 (0.378)	loss 7.427 (7.354)	prob 3.237 (3.448)	GS 34.109 (32.014)	mem 73.271
Train: [69][140/1500]	BT 0.038 (0.402)	DT 0.001 (0.363)	loss 7.525 (7.343)	prob 3.263 (3.477)	GS 32.828 (31.730)	mem 73.273
Train: [69][150/1500]	BT 0.039 (0.378)	DT 0.001 (0.339)	loss 7.335 (7.358)	prob 3.481 (3.428)	GS 34.781 (31.665)	mem 73.275
Train: [69][160/1500]	BT 0.039 (0.366)	DT 0.001 (0.326)	loss 7.724 (7.404)	prob 2.722 (3.383)	GS 31.469 (31.944)	mem 73.274
Train: [69][170/1500]	BT 0.032 (0.376)	DT 0.000 (0.337)	loss 7.465 (7.361)	prob 3.845 (3.367)	GS 30.766 (31.459)	mem 73.276
Train: [69][180/1500]	BT 0.038 (0.395)	DT 0.001 (0.356)	loss 7.320 (7.345)	prob 2.670 (3.371)	GS 34.234 (31.646)	mem 73.282
Train: [69][190/1500]	BT 0.038 (0.384)	DT 0.001 (0.345)	loss 7.338 (7.331)	prob 4.040 (3.417)	GS 30.969 (31.754)	mem 73.285
Train: [69][200/1500]	BT 0.030 (0.366)	DT 0.000 (0.328)	loss 7.240 (7.326)	prob 3.364 (3.350)	GS 36.812 (31.969)	mem 73.288
Train: [69][210/1500]	BT 0.039 (0.361)	DT 0.000 (0.322)	loss 7.474 (7.371)	prob 3.486 (3.076)	GS 30.812 (32.422)	mem 73.291
Train: [69][220/1500]	BT 0.039 (0.362)	DT 0.001 (0.322)	loss 7.204 (7.336)	prob 3.675 (3.228)	GS 30.188 (32.688)	mem 73.292
Train: [69][230/1500]	BT 0.039 (0.359)	DT 0.001 (0.320)	loss 6.993 (7.310)	prob 3.816 (3.318)	GS 32.000 (32.874)	mem 73.294
Train: [69][240/1500]	BT 0.039 (0.346)	DT 0.001 (0.307)	loss 7.282 (7.284)	prob 3.370 (3.315)	GS 35.234 (33.109)	mem 73.294
Train: [69][250/1500]	BT 0.031 (0.366)	DT 0.000 (0.327)	loss 7.058 (7.283)	prob 3.524 (3.314)	GS 31.281 (33.008)	mem 73.300
Train: [69][260/1500]	BT 0.060 (0.355)	DT 0.004 (0.315)	loss 7.531 (7.309)	prob 2.902 (3.092)	GS 37.312 (32.663)	mem 73.300
Train: [69][270/1500]	BT 0.076 (0.356)	DT 0.006 (0.315)	loss 7.007 (7.264)	prob 3.444 (3.214)	GS 34.859 (33.311)	mem 73.301
Train: [69][280/1500]	BT 0.038 (0.355)	DT 0.000 (0.314)	loss 7.615 (7.286)	prob 3.246 (3.224)	GS 32.859 (32.630)	mem 73.305
Train: [69][290/1500]	BT 0.031 (0.370)	DT 0.001 (0.329)	loss 7.349 (7.255)	prob 3.336 (3.217)	GS 36.250 (33.273)	mem 73.303
Train: [69][300/1500]	BT 0.031 (0.359)	DT 0.000 (0.318)	loss 7.426 (7.281)	prob 3.346 (3.181)	GS 37.078 (33.339)	mem 73.303
Train: [69][310/1500]	BT 0.037 (0.348)	DT 0.000 (0.307)	loss 7.452 (7.265)	prob 2.966 (3.236)	GS 31.094 (32.259)	mem 73.304
Train: [69][320/1500]	BT 0.031 (0.362)	DT 0.001 (0.322)	loss 7.174 (7.214)	prob 2.846 (3.283)	GS 36.484 (32.096)	mem 73.305
Train: [69][330/1500]	BT 0.028 (0.352)	DT 0.000 (0.312)	loss 7.407 (7.224)	prob 2.664 (3.249)	GS 31.812 (32.233)	mem 73.305
Train: [69][340/1500]	BT 0.039 (0.351)	DT 0.001 (0.311)	loss 7.046 (7.212)	prob 3.197 (3.224)	GS 43.766 (32.653)	mem 73.307
Train: [69][350/1500]	BT 0.038 (0.345)	DT 0.001 (0.305)	loss 7.086 (7.215)	prob 3.644 (3.284)	GS 32.797 (32.930)	mem 73.308
Train: [69][360/1500]	BT 0.039 (0.336)	DT 0.001 (0.297)	loss 7.081 (7.160)	prob 3.141 (3.333)	GS 36.688 (33.419)	mem 73.308
Train: [69][370/1500]	BT 0.039 (0.345)	DT 0.000 (0.305)	loss 7.287 (7.175)	prob 3.152 (3.199)	GS 34.406 (32.828)	mem 73.307
Train: [69][380/1500]	BT 0.041 (0.337)	DT 0.001 (0.297)	loss 7.189 (7.184)	prob 2.859 (3.154)	GS 35.297 (32.861)	mem 73.307
Train: [69][390/1500]	BT 0.038 (0.337)	DT 0.001 (0.297)	loss 7.071 (7.148)	prob 3.822 (3.162)	GS 36.312 (32.749)	mem 73.309
Train: [69][400/1500]	BT 0.027 (0.331)	DT 0.000 (0.292)	loss 7.563 (7.148)	prob 3.462 (3.168)	GS 31.531 (32.746)	mem 73.311
Train: [69][410/1500]	BT 0.061 (0.330)	DT 0.014 (0.290)	loss 7.260 (7.154)	prob 3.600 (3.080)	GS 30.000 (32.367)	mem 73.312
Train: [69][420/1500]	BT 0.053 (0.328)	DT 0.002 (0.288)	loss 7.025 (7.113)	prob 3.422 (3.171)	GS 32.172 (32.509)	mem 73.312
Train: [69][430/1500]	BT 0.034 (0.321)	DT 0.000 (0.282)	loss 7.138 (7.116)	prob 3.421 (3.117)	GS 35.547 (32.476)	mem 73.313
Train: [69][440/1500]	BT 0.072 (0.325)	DT 0.003 (0.285)	loss 6.980 (7.087)	prob 3.630 (3.095)	GS 37.156 (32.615)	mem 73.317
Train: [69][450/1500]	BT 0.037 (0.319)	DT 0.001 (0.280)	loss 7.018 (7.081)	prob 3.476 (3.153)	GS 34.453 (32.664)	mem 73.320
Train: [69][460/1500]	BT 0.029 (0.320)	DT 0.000 (0.281)	loss 7.419 (7.069)	prob 3.866 (3.166)	GS 28.906 (32.708)	mem 73.333
Train: [69][470/1500]	BT 0.037 (0.317)	DT 0.001 (0.278)	loss 6.897 (7.055)	prob 3.487 (3.234)	GS 35.484 (32.750)	mem 73.335
Train: [69][480/1500]	BT 0.048 (0.312)	DT 0.013 (0.272)	loss 6.825 (7.041)	prob 2.987 (3.151)	GS 33.328 (32.245)	mem 73.336
Train: [69][490/1500]	BT 0.036 (0.315)	DT 0.000 (0.276)	loss 7.189 (7.038)	prob 3.920 (3.195)	GS 29.703 (32.197)	mem 73.238
Train: [69][500/1500]	BT 0.037 (0.310)	DT 0.000 (0.271)	loss 6.899 (7.018)	prob 2.785 (3.214)	GS 33.328 (32.424)	mem 73.238
Train: [69][510/1500]	BT 0.038 (0.308)	DT 0.001 (0.269)	loss 6.939 (6.934)	prob 2.388 (3.288)	GS 37.609 (32.723)	mem 73.237
Train: [69][520/1500]	BT 0.036 (0.304)	DT 0.001 (0.265)	loss 6.855 (6.967)	prob 3.670 (3.272)	GS 34.656 (32.553)	mem 73.237
Train: [69][530/1500]	BT 0.036 (0.308)	DT 0.001 (0.268)	loss 6.943 (6.964)	prob 3.827 (3.228)	GS 35.109 (33.100)	mem 73.241
Train: [69][540/1500]	BT 0.033 (0.303)	DT 0.001 (0.263)	loss 6.823 (6.975)	prob 3.975 (3.263)	GS 33.109 (32.850)	mem 73.290
Train: [69][550/1500]	BT 0.037 (0.305)	DT 0.001 (0.266)	loss 7.005 (6.981)	prob 2.775 (3.307)	GS 32.797 (33.155)	mem 73.587
Train: [69][560/1500]	BT 0.037 (0.302)	DT 0.000 (0.263)	loss 6.920 (7.006)	prob 3.391 (3.453)	GS 33.125 (32.306)	mem 73.789
Train: [69][570/1500]	BT 0.037 (0.297)	DT 0.000 (0.258)	loss 7.115 (7.010)	prob 2.494 (3.319)	GS 36.719 (33.230)	mem 73.805
Train: [69][580/1500]	BT 0.045 (0.304)	DT 0.010 (0.265)	loss 7.109 (7.028)	prob 3.802 (3.409)	GS 33.859 (33.238)	mem 74.392
Train: [69][590/1500]	BT 0.057 (0.299)	DT 0.006 (0.260)	loss 6.963 (7.026)	prob 3.065 (3.399)	GS 32.906 (33.130)	mem 74.395
Train: [69][600/1500]	BT 0.037 (0.303)	DT 0.001 (0.264)	loss 7.111 (7.041)	prob 3.894 (3.373)	GS 31.281 (33.413)	mem 74.445
Train: [69][610/1500]	BT 0.038 (0.299)	DT 0.001 (0.260)	loss 6.990 (7.012)	prob 3.690 (3.398)	GS 33.281 (31.702)	mem 74.445
Train: [69][620/1500]	BT 0.027 (0.301)	DT 0.000 (0.262)	loss 7.021 (7.005)	prob 3.292 (3.425)	GS 34.328 (32.132)	mem 74.430
Train: [69][630/1500]	BT 0.039 (0.297)	DT 0.001 (0.258)	loss 7.141 (7.021)	prob 3.871 (3.370)	GS 34.141 (32.058)	mem 74.431
Train: [69][640/1500]	BT 0.039 (0.293)	DT 0.001 (0.254)	loss 6.858 (7.028)	prob 3.683 (3.417)	GS 33.453 (31.793)	mem 74.431
Train: [69][650/1500]	BT 0.042 (0.293)	DT 0.001 (0.254)	loss 7.109 (7.035)	prob 3.719 (3.394)	GS 34.250 (32.023)	mem 74.432
Train: [69][660/1500]	BT 0.041 (0.289)	DT 0.001 (0.250)	loss 6.854 (6.985)	prob 3.036 (3.275)	GS 35.266 (32.981)	mem 74.432
Train: [69][670/1500]	BT 0.039 (0.297)	DT 0.001 (0.258)	loss 7.237 (7.032)	prob 2.787 (3.104)	GS 36.859 (33.522)	mem 74.432
Train: [69][680/1500]	BT 0.028 (0.293)	DT 0.000 (0.255)	loss 6.896 (7.013)	prob 3.908 (3.369)	GS 34.406 (33.179)	mem 74.434
Train: [69][690/1500]	BT 0.055 (0.290)	DT 0.016 (0.251)	loss 6.946 (7.001)	prob 3.733 (3.359)	GS 35.062 (32.852)	mem 74.434
Train: [69][700/1500]	BT 0.038 (0.290)	DT 0.001 (0.252)	loss 6.838 (7.006)	prob 3.172 (3.330)	GS 35.625 (32.792)	mem 74.435
Train: [69][710/1500]	BT 0.030 (0.287)	DT 0.000 (0.248)	loss 6.936 (6.994)	prob 3.479 (3.144)	GS 33.953 (30.930)	mem 74.436
Train: [69][720/1500]	BT 0.029 (0.300)	DT 0.000 (0.261)	loss 7.243 (6.987)	prob 3.655 (3.118)	GS 34.562 (31.768)	mem 74.433
Train: [69][730/1500]	BT 0.026 (0.296)	DT 0.000 (0.257)	loss 7.015 (6.997)	prob 3.390 (3.146)	GS 35.391 (32.347)	mem 74.439
Train: [69][740/1500]	BT 0.036 (0.292)	DT 0.000 (0.254)	loss 7.011 (6.983)	prob 3.350 (3.207)	GS 32.188 (32.568)	mem 74.445
Train: [69][750/1500]	BT 0.024 (0.296)	DT 0.000 (0.257)	loss 7.036 (6.997)	prob 2.779 (3.215)	GS 37.641 (32.679)	mem 74.456
Train: [69][760/1500]	BT 0.037 (0.292)	DT 0.000 (0.254)	loss 6.812 (6.907)	prob 2.839 (3.229)	GS 31.594 (30.984)	mem 74.456
Train: [69][770/1500]	BT 0.035 (0.293)	DT 0.000 (0.255)	loss 6.973 (6.964)	prob 3.118 (3.118)	GS 34.203 (31.505)	mem 74.460
Train: [69][780/1500]	BT 0.058 (0.290)	DT 0.013 (0.252)	loss 7.312 (7.000)	prob 3.457 (3.032)	GS 29.000 (31.831)	mem 74.459
Train: [69][790/1500]	BT 0.037 (0.291)	DT 0.000 (0.253)	loss 6.879 (7.001)	prob 3.521 (3.096)	GS 33.641 (32.205)	mem 74.463
Train: [69][800/1500]	BT 0.037 (0.288)	DT 0.001 (0.250)	loss 6.831 (7.004)	prob 3.122 (3.054)	GS 38.656 (32.269)	mem 74.463
Train: [69][810/1500]	BT 0.097 (0.285)	DT 0.059 (0.247)	loss 7.025 (6.981)	prob 3.280 (3.162)	GS 31.203 (31.592)	mem 74.462
Train: [69][820/1500]	BT 0.027 (0.286)	DT 0.000 (0.248)	loss 7.039 (6.980)	prob 3.030 (3.007)	GS 30.844 (31.409)	mem 74.464
Train: [69][830/1500]	BT 0.037 (0.284)	DT 0.001 (0.246)	loss 7.145 (6.974)	prob 2.764 (3.003)	GS 37.234 (32.204)	mem 74.467
Train: [69][840/1500]	BT 0.031 (0.287)	DT 0.000 (0.249)	loss 7.255 (6.990)	prob 2.742 (2.918)	GS 31.172 (32.128)	mem 74.470
Train: [69][850/1500]	BT 0.064 (0.284)	DT 0.011 (0.246)	loss 6.970 (6.989)	prob 2.436 (2.879)	GS 34.344 (32.475)	mem 74.468
Train: [69][860/1500]	BT 0.070 (0.292)	DT 0.012 (0.253)	loss 7.262 (7.018)	prob 2.536 (2.611)	GS 36.828 (35.742)	mem 74.469
Train: [69][870/1500]	BT 0.091 (0.291)	DT 0.015 (0.253)	loss 7.067 (7.025)	prob 2.611 (2.640)	GS 34.594 (34.836)	mem 74.470
Train: [69][880/1500]	BT 0.097 (0.290)	DT 0.009 (0.251)	loss 7.089 (7.005)	prob 2.626 (2.664)	GS 36.609 (34.504)	mem 74.470
Train: [69][890/1500]	BT 0.061 (0.294)	DT 0.013 (0.255)	loss 6.965 (7.002)	prob 2.649 (2.665)	GS 36.188 (34.527)	mem 74.470
Train: [69][900/1500]	BT 0.048 (0.294)	DT 0.001 (0.255)	loss 6.878 (6.977)	prob 2.965 (2.615)	GS 32.562 (34.461)	mem 74.471
Train: [69][910/1500]	BT 0.053 (0.297)	DT 0.002 (0.258)	loss 6.805 (6.940)	prob 2.046 (2.654)	GS 34.156 (33.400)	mem 74.472
Train: [69][920/1500]	BT 0.028 (0.306)	DT 0.000 (0.266)	loss 6.881 (6.939)	prob 3.516 (2.696)	GS 34.062 (33.627)	mem 74.471
Train: [69][930/1500]	BT 0.023 (0.303)	DT 0.000 (0.264)	loss 7.122 (6.939)	prob 2.320 (2.631)	GS 33.844 (33.087)	mem 74.472
Train: [69][940/1500]	BT 0.024 (0.300)	DT 0.000 (0.261)	loss 7.097 (6.944)	prob 2.726 (2.659)	GS 33.172 (33.268)	mem 74.472
Train: [69][950/1500]	BT 0.037 (0.302)	DT 0.000 (0.264)	loss 6.857 (6.930)	prob 2.598 (2.624)	GS 33.250 (33.310)	mem 74.477
Train: [69][960/1500]	BT 0.023 (0.300)	DT 0.000 (0.261)	loss 6.762 (6.897)	prob 2.540 (2.885)	GS 34.516 (32.142)	mem 74.478
Train: [69][970/1500]	BT 0.037 (0.300)	DT 0.001 (0.261)	loss 7.121 (6.907)	prob 2.086 (2.666)	GS 38.141 (32.608)	mem 74.479
Train: [69][980/1500]	BT 0.065 (0.297)	DT 0.006 (0.258)	loss 6.999 (6.944)	prob 2.522 (2.576)	GS 35.359 (33.120)	mem 74.478
Train: [69][990/1500]	BT 0.036 (0.302)	DT 0.000 (0.263)	loss 6.827 (6.936)	prob 2.625 (2.562)	GS 36.781 (32.957)	mem 74.478
Train: [69][1000/1500]	BT 0.025 (0.299)	DT 0.000 (0.260)	loss 6.780 (6.926)	prob 2.926 (2.544)	GS 37.000 (32.888)	mem 74.481
Train: [69][1010/1500]	BT 0.040 (0.296)	DT 0.001 (0.258)	loss 7.162 (6.939)	prob 1.643 (2.360)	GS 34.969 (32.219)	mem 74.482
Train: [69][1020/1500]	BT 0.037 (0.297)	DT 0.000 (0.258)	loss 6.969 (6.919)	prob 2.949 (2.569)	GS 34.375 (33.052)	mem 74.483
Train: [69][1030/1500]	BT 0.037 (0.294)	DT 0.000 (0.255)	loss 6.883 (6.895)	prob 2.903 (2.655)	GS 32.453 (32.692)	mem 74.482
Train: [69][1040/1500]	BT 0.037 (0.295)	DT 0.001 (0.256)	loss 6.837 (6.900)	prob 2.694 (2.630)	GS 33.297 (32.711)	mem 74.486
Train: [69][1050/1500]	BT 0.037 (0.293)	DT 0.000 (0.255)	loss 7.165 (6.911)	prob 2.013 (2.554)	GS 36.172 (32.790)	mem 74.488
Train: [69][1060/1500]	BT 0.037 (0.291)	DT 0.001 (0.253)	loss 6.964 (6.870)	prob 2.006 (2.332)	GS 34.953 (32.759)	mem 74.488
Train: [69][1070/1500]	BT 0.037 (0.293)	DT 0.001 (0.254)	loss 6.923 (6.872)	prob 2.407 (2.209)	GS 37.094 (32.429)	mem 74.489
Train: [69][1080/1500]	BT 0.036 (0.290)	DT 0.001 (0.252)	loss 6.914 (6.865)	prob 1.342 (2.240)	GS 29.828 (32.027)	mem 74.488
Train: [69][1090/1500]	BT 0.038 (0.290)	DT 0.001 (0.252)	loss 6.688 (6.861)	prob 1.831 (2.296)	GS 29.859 (31.468)	mem 74.490
Train: [69][1100/1500]	BT 0.039 (0.290)	DT 0.001 (0.252)	loss 6.768 (6.865)	prob 2.991 (2.282)	GS 32.141 (31.417)	mem 74.519
Train: [69][1110/1500]	BT 0.039 (0.289)	DT 0.001 (0.250)	loss 6.902 (6.875)	prob 2.435 (2.365)	GS 35.766 (32.786)	mem 74.517
Train: [69][1120/1500]	BT 0.040 (0.288)	DT 0.001 (0.250)	loss 7.061 (6.865)	prob 1.858 (2.156)	GS 33.250 (33.084)	mem 74.518
Train: [69][1130/1500]	BT 0.039 (0.286)	DT 0.001 (0.248)	loss 6.793 (6.843)	prob 1.332 (2.030)	GS 35.891 (33.234)	mem 74.519
Train: [69][1140/1500]	BT 0.034 (0.288)	DT 0.000 (0.250)	loss 6.884 (6.854)	prob 1.849 (2.031)	GS 34.016 (33.007)	mem 74.517
Train: [69][1150/1500]	BT 0.039 (0.286)	DT 0.001 (0.248)	loss 6.789 (6.844)	prob 2.328 (2.026)	GS 32.172 (33.102)	mem 74.518
Train: [69][1160/1500]	BT 0.038 (0.287)	DT 0.001 (0.249)	loss 6.818 (6.783)	prob 1.853 (1.929)	GS 34.703 (33.405)	mem 74.519
Train: [69][1170/1500]	BT 0.038 (0.286)	DT 0.001 (0.248)	loss 6.881 (6.823)	prob 2.129 (1.948)	GS 34.938 (33.317)	mem 74.518
Train: [69][1180/1500]	BT 0.039 (0.284)	DT 0.001 (0.246)	loss 6.726 (6.792)	prob 2.726 (2.052)	GS 32.500 (32.470)	mem 74.518
Train: [69][1190/1500]	BT 0.039 (0.283)	DT 0.001 (0.245)	loss 6.663 (6.779)	prob 2.098 (2.076)	GS 34.766 (32.173)	mem 74.517
Train: [69][1200/1500]	BT 0.868 (0.283)	DT 0.830 (0.244)	loss 7.051 (6.796)	prob 2.274 (2.037)	GS 31.578 (32.207)	mem 74.517
Train: [69][1210/1500]	BT 0.031 (0.283)	DT 0.000 (0.244)	loss 6.665 (6.816)	prob 2.439 (2.137)	GS 33.109 (31.475)	mem 74.517
Train: [69][1220/1500]	BT 0.060 (0.282)	DT 0.010 (0.244)	loss 6.887 (6.842)	prob 2.390 (2.020)	GS 34.703 (33.202)	mem 74.518
Train: [69][1230/1500]	BT 0.030 (0.293)	DT 0.000 (0.254)	loss 6.964 (6.877)	prob 2.358 (2.028)	GS 34.688 (33.037)	mem 74.521
Train: [69][1240/1500]	BT 0.037 (0.291)	DT 0.000 (0.252)	loss 7.389 (6.907)	prob 1.148 (2.013)	GS 35.344 (33.232)	mem 74.522
Train: [69][1250/1500]	BT 0.038 (0.292)	DT 0.001 (0.254)	loss 7.197 (6.925)	prob 1.926 (2.027)	GS 32.891 (33.185)	mem 74.522
Train: [69][1260/1500]	BT 0.039 (0.290)	DT 0.001 (0.252)	loss 6.978 (6.975)	prob 2.534 (2.265)	GS 37.625 (32.709)	mem 74.520
Train: [69][1270/1500]	BT 0.039 (0.290)	DT 0.001 (0.252)	loss 7.212 (7.039)	prob 2.548 (2.154)	GS 33.125 (32.259)	mem 74.522
Train: [69][1280/1500]	BT 0.039 (0.288)	DT 0.001 (0.250)	loss 7.432 (7.068)	prob 1.650 (2.121)	GS 33.906 (32.397)	mem 74.521
Train: [69][1290/1500]	BT 0.039 (0.286)	DT 0.001 (0.248)	loss 7.044 (7.036)	prob 1.974 (2.088)	GS 35.969 (32.547)	mem 74.521
Train: [69][1300/1500]	BT 0.038 (0.286)	DT 0.001 (0.248)	loss 7.003 (7.043)	prob 2.378 (2.149)	GS 33.859 (32.676)	mem 74.520
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [69][1310/1500]	BT 0.038 (0.284)	DT 0.001 (0.246)	loss 7.135 (7.167)	prob 2.449 (2.250)	GS 31.484 (31.942)	mem 74.520
Train: [69][1320/1500]	BT 0.024 (0.291)	DT 0.000 (0.252)	loss 7.058 (7.168)	prob 2.725 (2.175)	GS 39.359 (33.358)	mem 74.537
Train: [69][1330/1500]	BT 0.025 (0.289)	DT 0.000 (0.250)	loss 6.978 (7.134)	prob 2.424 (2.236)	GS 33.219 (32.771)	mem 74.537
Train: [69][1340/1500]	BT 0.038 (0.287)	DT 0.001 (0.249)	loss 7.140 (7.119)	prob 2.783 (2.245)	GS 36.234 (32.813)	mem 74.539
Train: [69][1350/1500]	BT 0.037 (0.288)	DT 0.003 (0.250)	loss 7.484 (7.121)	prob 2.993 (2.329)	GS 33.062 (32.518)	mem 74.537
Train: [69][1360/1500]	BT 0.056 (0.287)	DT 0.006 (0.248)	loss 7.197 (7.236)	prob 2.799 (2.297)	GS 32.109 (33.042)	mem 74.539
Train: [69][1370/1500]	BT 0.036 (0.288)	DT 0.001 (0.249)	loss 7.768 (7.186)	prob 2.018 (2.436)	GS 33.453 (32.709)	mem 74.437
Train: [69][1380/1500]	BT 0.036 (0.286)	DT 0.001 (0.248)	loss 7.269 (7.170)	prob 2.061 (2.397)	GS 33.203 (32.785)	mem 74.436
Train: [69][1390/1500]	BT 0.037 (0.285)	DT 0.000 (0.247)	loss 7.085 (7.169)	prob 2.596 (2.355)	GS 33.906 (32.847)	mem 74.435
Train: [69][1400/1500]	BT 0.030 (0.286)	DT 0.000 (0.248)	loss 7.290 (7.171)	prob 2.716 (2.408)	GS 34.109 (32.899)	mem 74.437
Train: [69][1410/1500]	BT 0.030 (0.284)	DT 0.000 (0.246)	loss 7.154 (7.105)	prob 2.377 (2.621)	GS 33.938 (33.206)	mem 74.438
Train: [69][1420/1500]	BT 0.028 (0.286)	DT 0.000 (0.248)	loss 7.096 (7.088)	prob 3.094 (2.618)	GS 32.312 (32.736)	mem 74.439
Train: [69][1430/1500]	BT 0.030 (0.285)	DT 0.000 (0.247)	loss 6.821 (7.110)	prob 2.664 (2.645)	GS 33.812 (32.685)	mem 74.439
Train: [69][1440/1500]	BT 3.281 (0.285)	DT 3.254 (0.247)	loss 7.237 (7.094)	prob 2.963 (2.652)	GS 33.844 (32.829)	mem 74.441
Train: [69][1450/1500]	BT 0.027 (0.283)	DT 0.000 (0.245)	loss 7.228 (7.081)	prob 2.479 (2.635)	GS 31.656 (32.597)	mem 74.442
Train: [69][1460/1500]	BT 0.038 (0.282)	DT 0.000 (0.244)	loss 6.895 (7.151)	prob 2.843 (2.986)	GS 34.203 (31.733)	mem 74.451
Train: [69][1470/1500]	BT 0.028 (0.282)	DT 0.000 (0.244)	loss 6.891 (7.106)	prob 2.828 (2.888)	GS 30.859 (31.580)	mem 73.401
Train: [69][1480/1500]	BT 0.023 (0.280)	DT 0.000 (0.242)	loss 7.339 (7.103)	prob 2.910 (2.868)	GS 36.344 (31.284)	mem 73.328
Train: [69][1490/1500]	BT 0.023 (0.280)	DT 0.000 (0.242)	loss 7.055 (7.103)	prob 3.112 (2.915)	GS 31.125 (31.417)	mem 9.367
Train: [69][1500/1500]	BT 0.025 (0.278)	DT 0.000 (0.241)	loss 7.039 (7.082)	prob 2.750 (2.932)	GS 36.344 (31.679)	mem 9.367
Train: [69][1510/1500]	BT 0.025 (0.277)	DT 0.000 (0.239)	loss 7.367 (6.807)	prob 3.151 (3.078)	GS 29.906 (32.566)	mem 9.367
epoch 69, total time 418.73
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [70][1/1500]	BT 25.591 (25.591)	DT 25.534 (25.534)	loss 6.731 (6.731)	prob 2.895 (2.895)	GS 28.922 (28.922)	mem 72.956
Train: [70][10/1500]	BT 0.211 (2.621)	DT 0.173 (2.579)	loss 7.163 (6.847)	prob 3.071 (3.014)	GS 38.109 (33.976)	mem 72.973
Train: [70][20/1500]	BT 0.038 (1.453)	DT 0.001 (1.413)	loss 7.074 (6.888)	prob 2.524 (2.977)	GS 35.266 (33.799)	mem 73.016
Train: [70][30/1500]	BT 0.039 (1.031)	DT 0.001 (0.993)	loss 7.168 (6.927)	prob 3.541 (3.087)	GS 31.562 (32.985)	mem 73.040
Train: [70][40/1500]	BT 0.028 (0.866)	DT 0.000 (0.829)	loss 6.785 (6.927)	prob 3.412 (3.138)	GS 34.062 (33.225)	mem 73.053
Train: [70][50/1500]	BT 0.036 (0.700)	DT 0.001 (0.664)	loss 7.226 (6.969)	prob 3.578 (3.072)	GS 32.344 (33.189)	mem 73.054
Train: [70][60/1500]	BT 0.033 (0.634)	DT 0.000 (0.599)	loss 6.981 (7.121)	prob 3.431 (3.138)	GS 34.328 (31.747)	mem 73.082
Train: [70][70/1500]	BT 0.033 (0.548)	DT 0.000 (0.513)	loss 7.100 (7.090)	prob 3.323 (2.983)	GS 31.125 (32.142)	mem 73.082
Train: [70][80/1500]	BT 0.036 (0.551)	DT 0.000 (0.516)	loss 7.342 (7.115)	prob 3.581 (3.040)	GS 35.484 (32.218)	mem 73.111
Train: [70][90/1500]	BT 0.054 (0.495)	DT 0.003 (0.459)	loss 6.924 (7.095)	prob 3.308 (3.089)	GS 33.672 (32.043)	mem 73.112
Train: [70][100/1500]	BT 0.054 (0.514)	DT 0.014 (0.476)	loss 7.160 (7.108)	prob 3.004 (2.996)	GS 35.906 (32.272)	mem 73.116
Train: [70][110/1500]	BT 0.061 (0.487)	DT 0.011 (0.448)	loss 7.315 (7.008)	prob 3.035 (2.972)	GS 36.219 (32.453)	mem 73.119
Train: [70][120/1500]	BT 0.065 (0.451)	DT 0.015 (0.411)	loss 7.121 (7.053)	prob 3.475 (2.932)	GS 34.422 (32.684)	mem 73.119
Train: [70][130/1500]	BT 0.033 (0.540)	DT 0.000 (0.499)	loss 6.854 (7.093)	prob 3.021 (2.913)	GS 37.578 (32.884)	mem 73.131
Train: [70][140/1500]	BT 0.030 (0.503)	DT 0.000 (0.463)	loss 6.971 (7.083)	prob 2.829 (2.926)	GS 28.750 (32.521)	mem 73.132
Train: [70][150/1500]	BT 2.692 (0.489)	DT 2.659 (0.450)	loss 6.828 (7.079)	prob 3.625 (2.935)	GS 33.312 (32.669)	mem 73.133
Train: [70][160/1500]	BT 0.038 (0.461)	DT 0.001 (0.422)	loss 6.868 (7.039)	prob 3.142 (2.890)	GS 32.531 (33.011)	mem 73.135
Train: [70][170/1500]	BT 0.038 (0.436)	DT 0.001 (0.397)	loss 7.013 (7.055)	prob 3.087 (2.973)	GS 32.812 (32.705)	mem 73.134
Train: [70][180/1500]	BT 0.039 (0.430)	DT 0.000 (0.391)	loss 6.997 (7.042)	prob 3.567 (2.990)	GS 33.406 (32.614)	mem 73.134
Train: [70][190/1500]	BT 0.052 (0.410)	DT 0.014 (0.371)	loss 7.405 (7.046)	prob 2.348 (2.970)	GS 34.469 (32.788)	mem 73.134
Train: [70][200/1500]	BT 0.037 (0.438)	DT 0.000 (0.399)	loss 6.875 (7.033)	prob 3.530 (2.950)	GS 32.844 (32.477)	mem 73.139
Train: [70][210/1500]	BT 0.027 (0.428)	DT 0.000 (0.389)	loss 7.130 (7.009)	prob 2.848 (2.719)	GS 32.672 (33.567)	mem 73.141
Train: [70][220/1500]	BT 0.034 (0.410)	DT 0.000 (0.372)	loss 7.003 (7.037)	prob 2.797 (2.924)	GS 36.500 (33.580)	mem 73.142
Train: [70][230/1500]	BT 0.038 (0.402)	DT 0.001 (0.363)	loss 7.131 (7.054)	prob 3.235 (2.818)	GS 34.172 (33.642)	mem 73.143
Train: [70][240/1500]	BT 0.036 (0.391)	DT 0.001 (0.353)	loss 7.505 (7.058)	prob 2.955 (2.876)	GS 31.391 (33.323)	mem 73.146
Train: [70][250/1500]	BT 0.056 (0.396)	DT 0.006 (0.357)	loss 7.100 (7.064)	prob 2.933 (2.924)	GS 36.875 (33.374)	mem 73.148
Train: [70][260/1500]	BT 0.028 (0.384)	DT 0.000 (0.345)	loss 6.747 (7.077)	prob 3.367 (2.816)	GS 32.312 (32.447)	mem 73.149
Train: [70][270/1500]	BT 0.037 (0.384)	DT 0.001 (0.345)	loss 6.836 (7.067)	prob 3.561 (2.846)	GS 28.422 (32.658)	mem 73.151
Train: [70][280/1500]	BT 0.037 (0.373)	DT 0.001 (0.334)	loss 6.903 (7.050)	prob 2.703 (2.861)	GS 37.453 (32.426)	mem 73.151
Train: [70][290/1500]	BT 0.036 (0.376)	DT 0.000 (0.337)	loss 7.452 (7.044)	prob 2.354 (2.862)	GS 29.562 (32.109)	mem 73.155
Train: [70][300/1500]	BT 0.026 (0.369)	DT 0.000 (0.331)	loss 7.014 (7.042)	prob 2.448 (2.811)	GS 32.438 (32.204)	mem 73.157
Train: [70][310/1500]	BT 0.037 (0.359)	DT 0.000 (0.320)	loss 7.439 (7.031)	prob 2.377 (2.699)	GS 30.750 (31.983)	mem 73.158
Train: [70][320/1500]	BT 0.102 (0.353)	DT 0.018 (0.315)	loss 6.709 (7.020)	prob 2.778 (2.576)	GS 30.516 (32.260)	mem 73.160
Train: [70][330/1500]	BT 0.037 (0.354)	DT 0.001 (0.315)	loss 7.004 (7.029)	prob 2.226 (2.546)	GS 32.406 (32.426)	mem 73.162
Train: [70][340/1500]	BT 0.037 (0.349)	DT 0.000 (0.310)	loss 7.175 (7.058)	prob 2.780 (2.573)	GS 28.609 (32.293)	mem 73.162
Train: [70][350/1500]	BT 0.037 (0.346)	DT 0.001 (0.308)	loss 6.775 (7.048)	prob 3.497 (2.635)	GS 32.812 (32.518)	mem 73.163
Train: [70][360/1500]	BT 0.038 (0.338)	DT 0.001 (0.299)	loss 7.206 (6.986)	prob 1.950 (2.895)	GS 34.609 (32.330)	mem 73.163
Train: [70][370/1500]	BT 0.037 (0.343)	DT 0.000 (0.304)	loss 6.938 (6.971)	prob 3.198 (2.923)	GS 34.688 (32.938)	mem 73.165
Train: [70][380/1500]	BT 0.038 (0.335)	DT 0.001 (0.296)	loss 6.896 (6.978)	prob 3.195 (2.906)	GS 33.406 (32.602)	mem 73.166
Train: [70][390/1500]	BT 0.064 (0.332)	DT 0.013 (0.293)	loss 6.738 (6.964)	prob 2.759 (2.897)	GS 33.156 (32.716)	mem 73.165
Train: [70][400/1500]	BT 0.036 (0.333)	DT 0.001 (0.295)	loss 7.225 (6.960)	prob 2.467 (2.862)	GS 28.922 (32.822)	mem 73.166
Train: [70][410/1500]	BT 0.038 (0.326)	DT 0.001 (0.288)	loss 6.694 (6.913)	prob 3.259 (2.885)	GS 32.672 (31.936)	mem 73.166
Train: [70][420/1500]	BT 0.028 (0.331)	DT 0.000 (0.292)	loss 6.727 (6.967)	prob 3.425 (2.892)	GS 31.281 (32.087)	mem 73.200
Train: [70][430/1500]	BT 0.039 (0.324)	DT 0.001 (0.286)	loss 7.327 (6.980)	prob 2.590 (2.951)	GS 35.438 (32.181)	mem 73.200
Train: [70][440/1500]	BT 0.029 (0.317)	DT 0.000 (0.279)	loss 6.986 (6.988)	prob 3.007 (2.914)	GS 34.797 (32.530)	mem 73.200
Train: [70][450/1500]	BT 0.077 (0.327)	DT 0.013 (0.288)	loss 6.674 (6.962)	prob 2.288 (2.907)	GS 36.766 (32.642)	mem 73.206
Train: [70][460/1500]	BT 0.039 (0.324)	DT 0.001 (0.285)	loss 6.958 (6.894)	prob 2.306 (2.743)	GS 34.875 (33.056)	mem 73.208
Train: [70][470/1500]	BT 0.038 (0.323)	DT 0.001 (0.284)	loss 6.900 (6.907)	prob 2.933 (2.898)	GS 32.328 (32.567)	mem 73.209
Train: [70][480/1500]	BT 0.038 (0.317)	DT 0.001 (0.278)	loss 6.979 (6.935)	prob 3.070 (2.837)	GS 31.750 (32.957)	mem 73.210
Train: [70][490/1500]	BT 0.039 (0.317)	DT 0.001 (0.278)	loss 6.836 (6.907)	prob 2.675 (2.853)	GS 29.453 (32.524)	mem 73.212
Train: [70][500/1500]	BT 0.032 (0.312)	DT 0.000 (0.274)	loss 6.951 (6.916)	prob 2.520 (2.762)	GS 32.469 (32.609)	mem 73.212
Train: [70][510/1500]	BT 0.038 (0.316)	DT 0.001 (0.277)	loss 7.216 (6.841)	prob 3.118 (2.936)	GS 34.906 (32.552)	mem 73.214
Train: [70][520/1500]	BT 0.041 (0.311)	DT 0.001 (0.272)	loss 6.900 (6.881)	prob 2.893 (2.849)	GS 33.594 (32.566)	mem 73.214
Train: [70][530/1500]	BT 0.039 (0.306)	DT 0.001 (0.267)	loss 6.870 (6.890)	prob 2.953 (2.781)	GS 35.531 (32.243)	mem 73.214
Train: [70][540/1500]	BT 0.036 (0.308)	DT 0.001 (0.269)	loss 6.716 (6.876)	prob 2.905 (2.760)	GS 33.047 (32.340)	mem 73.215
Train: [70][550/1500]	BT 0.040 (0.303)	DT 0.001 (0.264)	loss 6.973 (6.869)	prob 2.307 (2.746)	GS 32.062 (32.591)	mem 73.215
Train: [70][560/1500]	BT 0.039 (0.303)	DT 0.001 (0.265)	loss 6.929 (6.948)	prob 2.155 (2.644)	GS 33.969 (32.053)	mem 73.215
Train: [70][570/1500]	BT 0.039 (0.300)	DT 0.001 (0.261)	loss 6.989 (6.941)	prob 3.252 (2.575)	GS 31.797 (31.407)	mem 73.215
Train: [70][580/1500]	BT 0.096 (0.305)	DT 0.028 (0.266)	loss 6.845 (6.892)	prob 3.109 (2.612)	GS 32.906 (31.977)	mem 73.215
Train: [70][590/1500]	BT 0.028 (0.308)	DT 0.000 (0.269)	loss 6.892 (6.894)	prob 2.611 (2.593)	GS 34.688 (32.154)	mem 73.216
Train: [70][600/1500]	BT 0.029 (0.304)	DT 0.000 (0.265)	loss 6.712 (6.878)	prob 2.578 (2.619)	GS 36.422 (32.437)	mem 73.216
Train: [70][610/1500]	BT 0.039 (0.299)	DT 0.001 (0.261)	loss 7.094 (6.829)	prob 1.991 (2.543)	GS 36.062 (32.430)	mem 73.216
Train: [70][620/1500]	BT 0.032 (0.303)	DT 0.000 (0.264)	loss 6.835 (6.885)	prob 3.122 (2.670)	GS 33.062 (31.545)	mem 73.610
Train: [70][630/1500]	BT 0.039 (0.298)	DT 0.001 (0.260)	loss 7.022 (6.871)	prob 2.620 (2.662)	GS 27.328 (31.234)	mem 73.611
Train: [70][640/1500]	BT 0.029 (0.300)	DT 0.001 (0.261)	loss 6.648 (6.858)	prob 2.730 (2.671)	GS 36.359 (31.520)	mem 73.906
Train: [70][650/1500]	BT 0.038 (0.296)	DT 0.000 (0.257)	loss 6.602 (6.855)	prob 2.508 (2.638)	GS 34.125 (31.253)	mem 73.906
Train: [70][660/1500]	BT 0.037 (0.292)	DT 0.001 (0.254)	loss 7.185 (6.868)	prob 2.702 (2.453)	GS 30.516 (32.350)	mem 73.906
Train: [70][670/1500]	BT 0.037 (0.292)	DT 0.000 (0.254)	loss 6.890 (6.861)	prob 2.621 (2.454)	GS 29.266 (32.322)	mem 74.204
Train: [70][680/1500]	BT 0.037 (0.289)	DT 0.000 (0.251)	loss 6.754 (6.837)	prob 2.281 (2.397)	GS 36.031 (32.543)	mem 74.255
Train: [70][690/1500]	BT 0.941 (0.290)	DT 0.904 (0.252)	loss 6.791 (6.832)	prob 3.438 (2.453)	GS 32.297 (32.105)	mem 74.413
Train: [70][700/1500]	BT 0.037 (0.288)	DT 0.000 (0.250)	loss 6.840 (6.843)	prob 1.873 (2.433)	GS 32.609 (32.011)	mem 74.413
Train: [70][710/1500]	BT 0.037 (0.289)	DT 0.000 (0.251)	loss 6.865 (6.946)	prob 2.764 (2.278)	GS 36.000 (31.683)	mem 74.406
Train: [70][720/1500]	BT 0.027 (0.285)	DT 0.000 (0.247)	loss 6.820 (6.876)	prob 1.687 (2.255)	GS 31.359 (31.595)	mem 74.291
Train: [70][730/1500]	BT 0.038 (0.284)	DT 0.001 (0.246)	loss 6.917 (6.874)	prob 2.295 (2.332)	GS 31.891 (31.841)	mem 74.314
Train: [70][740/1500]	BT 0.028 (0.283)	DT 0.000 (0.245)	loss 6.819 (6.855)	prob 1.921 (2.374)	GS 30.281 (31.759)	mem 74.314
Train: [70][750/1500]	BT 0.036 (0.283)	DT 0.001 (0.246)	loss 6.852 (6.846)	prob 2.327 (2.348)	GS 33.797 (31.808)	mem 74.314
Train: [70][760/1500]	BT 0.038 (0.280)	DT 0.001 (0.242)	loss 6.847 (6.910)	prob 2.599 (2.419)	GS 35.344 (32.592)	mem 74.316
Train: [70][770/1500]	BT 0.037 (0.280)	DT 0.000 (0.242)	loss 6.753 (6.858)	prob 2.939 (2.529)	GS 36.922 (32.313)	mem 74.316
Train: [70][780/1500]	BT 0.037 (0.278)	DT 0.001 (0.240)	loss 6.820 (6.851)	prob 2.137 (2.434)	GS 31.625 (32.603)	mem 74.316
Train: [70][790/1500]	BT 0.068 (0.279)	DT 0.014 (0.241)	loss 6.872 (6.858)	prob 2.105 (2.422)	GS 28.203 (32.209)	mem 74.316
Train: [70][800/1500]	BT 0.038 (0.278)	DT 0.001 (0.240)	loss 6.845 (6.855)	prob 1.684 (2.377)	GS 32.141 (32.212)	mem 74.321
Train: [70][810/1500]	BT 0.038 (0.275)	DT 0.001 (0.237)	loss 6.658 (6.797)	prob 3.130 (2.429)	GS 32.172 (32.500)	mem 74.320
Train: [70][820/1500]	BT 1.779 (0.276)	DT 1.740 (0.238)	loss 6.799 (6.845)	prob 2.990 (2.700)	GS 31.109 (32.093)	mem 74.340
Train: [70][830/1500]	BT 0.038 (0.276)	DT 0.000 (0.238)	loss 6.662 (6.832)	prob 2.237 (2.642)	GS 31.406 (31.974)	mem 74.342
Train: [70][840/1500]	BT 0.039 (0.274)	DT 0.001 (0.236)	loss 6.742 (6.823)	prob 3.139 (2.639)	GS 34.125 (32.177)	mem 74.343
Train: [70][850/1500]	BT 0.050 (0.274)	DT 0.002 (0.236)	loss 6.829 (6.829)	prob 2.225 (2.563)	GS 35.172 (32.444)	mem 74.343
Train: [70][860/1500]	BT 0.762 (0.274)	DT 0.725 (0.236)	loss 6.894 (6.780)	prob 2.199 (2.496)	GS 34.156 (32.817)	mem 74.342
Train: [70][870/1500]	BT 0.038 (0.274)	DT 0.001 (0.235)	loss 6.751 (6.824)	prob 1.845 (2.571)	GS 36.672 (33.934)	mem 74.329
Train: [70][880/1500]	BT 0.044 (0.273)	DT 0.000 (0.235)	loss 6.846 (6.833)	prob 2.279 (2.547)	GS 32.359 (33.347)	mem 74.330
Train: [70][890/1500]	BT 0.052 (0.271)	DT 0.004 (0.233)	loss 7.111 (6.821)	prob 1.710 (2.559)	GS 27.484 (33.376)	mem 74.331
Train: [70][900/1500]	BT 0.077 (0.272)	DT 0.011 (0.234)	loss 6.800 (6.817)	prob 2.451 (2.548)	GS 34.828 (32.916)	mem 74.329
Train: [70][910/1500]	BT 0.033 (0.276)	DT 0.001 (0.237)	loss 6.726 (6.809)	prob 2.414 (2.466)	GS 31.578 (31.325)	mem 74.330
Train: [70][920/1500]	BT 0.028 (0.297)	DT 0.001 (0.259)	loss 6.915 (6.827)	prob 3.062 (2.517)	GS 32.641 (32.716)	mem 74.332
Train: [70][930/1500]	BT 0.035 (0.294)	DT 0.000 (0.256)	loss 6.869 (6.833)	prob 2.768 (2.645)	GS 29.297 (32.119)	mem 74.331
Train: [70][940/1500]	BT 0.059 (0.298)	DT 0.001 (0.259)	loss 7.009 (6.848)	prob 3.502 (2.665)	GS 32.516 (32.668)	mem 74.333
Train: [70][950/1500]	BT 0.061 (0.295)	DT 0.013 (0.257)	loss 6.853 (6.860)	prob 2.101 (2.671)	GS 33.766 (32.660)	mem 74.332
Train: [70][960/1500]	BT 0.074 (0.293)	DT 0.011 (0.254)	loss 6.755 (6.815)	prob 3.010 (3.005)	GS 28.859 (32.042)	mem 74.335
Train: [70][970/1500]	BT 0.031 (0.296)	DT 0.000 (0.257)	loss 6.792 (6.864)	prob 3.426 (3.066)	GS 32.344 (34.214)	mem 74.339
Train: [70][980/1500]	BT 0.027 (0.293)	DT 0.000 (0.255)	loss 6.923 (6.841)	prob 2.612 (2.966)	GS 29.766 (33.376)	mem 74.346
Train: [70][990/1500]	BT 0.049 (0.296)	DT 0.007 (0.257)	loss 6.806 (6.834)	prob 2.750 (2.956)	GS 30.719 (33.213)	mem 74.351
Train: [70][1000/1500]	BT 0.027 (0.295)	DT 0.000 (0.257)	loss 6.730 (6.826)	prob 2.947 (2.982)	GS 33.500 (33.470)	mem 74.352
Train: [70][1010/1500]	BT 0.875 (0.293)	DT 0.837 (0.255)	loss 6.838 (6.837)	prob 2.979 (3.097)	GS 32.172 (33.342)	mem 74.354
Train: [70][1020/1500]	BT 0.037 (0.292)	DT 0.001 (0.254)	loss 6.753 (6.846)	prob 3.038 (2.864)	GS 30.156 (32.263)	mem 74.359
Train: [70][1030/1500]	BT 0.037 (0.291)	DT 0.001 (0.253)	loss 7.050 (6.848)	prob 1.572 (2.805)	GS 31.250 (32.379)	mem 74.359
Train: [70][1040/1500]	BT 0.038 (0.291)	DT 0.001 (0.253)	loss 6.738 (6.857)	prob 2.917 (2.881)	GS 34.953 (32.304)	mem 74.363
Train: [70][1050/1500]	BT 0.038 (0.291)	DT 0.001 (0.253)	loss 6.822 (6.853)	prob 2.424 (2.834)	GS 33.453 (32.607)	mem 74.360
Train: [70][1060/1500]	BT 0.019 (0.301)	DT 0.000 (0.262)	loss 6.934 (6.860)	prob 3.292 (2.905)	GS 35.891 (33.009)	mem 74.360
Train: [70][1070/1500]	BT 0.030 (0.298)	DT 0.000 (0.260)	loss 6.918 (6.841)	prob 2.258 (2.896)	GS 35.047 (32.134)	mem 74.360
Train: [70][1080/1500]	BT 0.027 (0.300)	DT 0.000 (0.262)	loss 6.792 (6.803)	prob 3.962 (2.908)	GS 37.469 (32.915)	mem 74.362
Train: [70][1090/1500]	BT 0.030 (0.297)	DT 0.000 (0.259)	loss 6.683 (6.787)	prob 2.358 (2.943)	GS 35.766 (32.543)	mem 74.362
Train: [70][1100/1500]	BT 0.035 (0.295)	DT 0.000 (0.257)	loss 6.788 (6.789)	prob 2.812 (2.911)	GS 30.531 (32.498)	mem 74.363
Train: [70][1110/1500]	BT 0.037 (0.296)	DT 0.000 (0.258)	loss 6.645 (6.728)	prob 3.928 (3.131)	GS 32.703 (32.081)	mem 74.364
Train: [70][1120/1500]	BT 0.038 (0.293)	DT 0.001 (0.255)	loss 6.836 (6.730)	prob 3.236 (2.863)	GS 35.484 (32.298)	mem 74.364
Train: [70][1130/1500]	BT 0.038 (0.294)	DT 0.001 (0.256)	loss 6.753 (6.746)	prob 3.106 (2.911)	GS 36.047 (32.620)	mem 74.364
Train: [70][1140/1500]	BT 0.037 (0.291)	DT 0.001 (0.253)	loss 7.035 (6.756)	prob 1.954 (2.840)	GS 36.906 (32.542)	mem 74.365
Train: [70][1150/1500]	BT 2.586 (0.291)	DT 2.552 (0.253)	loss 6.561 (6.755)	prob 2.567 (2.813)	GS 32.016 (32.247)	mem 74.366
Train: [70][1160/1500]	BT 0.048 (0.289)	DT 0.001 (0.251)	loss 6.696 (6.743)	prob 2.589 (3.023)	GS 31.188 (33.031)	mem 74.368
Train: [70][1170/1500]	BT 0.038 (0.288)	DT 0.001 (0.250)	loss 6.829 (6.742)	prob 2.810 (2.944)	GS 35.594 (32.476)	mem 74.370
Train: [70][1180/1500]	BT 0.059 (0.292)	DT 0.011 (0.254)	loss 6.818 (6.757)	prob 3.750 (2.924)	GS 34.875 (32.464)	mem 74.372
Train: [70][1190/1500]	BT 0.078 (0.290)	DT 0.030 (0.252)	loss 6.753 (6.765)	prob 2.878 (2.909)	GS 31.703 (32.218)	mem 74.370
Train: [70][1200/1500]	BT 0.030 (0.300)	DT 0.000 (0.261)	loss 6.817 (6.768)	prob 3.124 (2.960)	GS 37.406 (32.632)	mem 74.371
Train: [70][1210/1500]	BT 0.030 (0.297)	DT 0.000 (0.259)	loss 6.684 (6.795)	prob 3.353 (2.886)	GS 34.203 (34.505)	mem 74.371
Train: [70][1220/1500]	BT 0.035 (0.295)	DT 0.000 (0.257)	loss 6.822 (6.780)	prob 2.510 (2.907)	GS 32.578 (33.753)	mem 74.372
Train: [70][1230/1500]	BT 0.067 (0.297)	DT 0.014 (0.259)	loss 6.800 (6.770)	prob 3.104 (2.871)	GS 35.609 (33.327)	mem 74.375
Train: [70][1240/1500]	BT 0.060 (0.295)	DT 0.000 (0.257)	loss 6.835 (6.769)	prob 2.288 (2.904)	GS 29.547 (33.208)	mem 74.375
Train: [70][1250/1500]	BT 0.054 (0.301)	DT 0.011 (0.263)	loss 6.689 (6.764)	prob 3.336 (2.897)	GS 33.672 (33.062)	mem 74.373
Train: [70][1260/1500]	BT 0.029 (0.305)	DT 0.000 (0.267)	loss 6.742 (6.789)	prob 2.728 (2.737)	GS 30.953 (32.156)	mem 74.373
Train: [70][1270/1500]	BT 0.030 (0.303)	DT 0.000 (0.265)	loss 6.823 (6.754)	prob 3.122 (2.838)	GS 33.828 (32.966)	mem 74.373
Train: [70][1280/1500]	BT 0.033 (0.304)	DT 0.000 (0.266)	loss 6.637 (6.748)	prob 2.362 (2.908)	GS 28.953 (32.536)	mem 74.377
Train: [70][1290/1500]	BT 0.037 (0.302)	DT 0.001 (0.263)	loss 6.919 (6.760)	prob 2.615 (2.937)	GS 37.297 (32.333)	mem 74.378
Train: [70][1300/1500]	BT 0.064 (0.300)	DT 0.002 (0.261)	loss 6.686 (6.750)	prob 2.361 (2.962)	GS 34.531 (32.147)	mem 74.378
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [70][1310/1500]	BT 0.046 (0.302)	DT 0.012 (0.264)	loss 6.748 (6.787)	prob 3.212 (3.099)	GS 32.125 (32.837)	mem 74.378
Train: [70][1320/1500]	BT 0.066 (0.300)	DT 0.005 (0.262)	loss 6.657 (6.755)	prob 2.969 (3.036)	GS 33.484 (32.599)	mem 74.378
Train: [70][1330/1500]	BT 0.031 (0.303)	DT 0.000 (0.265)	loss 7.167 (6.782)	prob 2.642 (2.950)	GS 34.734 (32.043)	mem 74.379
Train: [70][1340/1500]	BT 0.022 (0.306)	DT 0.000 (0.267)	loss 6.823 (6.790)	prob 3.866 (2.945)	GS 32.672 (32.384)	mem 74.380
Train: [70][1350/1500]	BT 0.041 (0.304)	DT 0.001 (0.265)	loss 6.817 (6.800)	prob 2.960 (2.945)	GS 33.734 (32.634)	mem 74.380
Train: [70][1360/1500]	BT 0.042 (0.305)	DT 0.011 (0.267)	loss 6.903 (6.796)	prob 3.185 (3.229)	GS 38.344 (33.917)	mem 74.381
Train: [70][1370/1500]	BT 0.057 (0.303)	DT 0.011 (0.265)	loss 6.781 (6.776)	prob 2.645 (3.158)	GS 34.812 (33.327)	mem 74.381
Train: [70][1380/1500]	BT 0.052 (0.301)	DT 0.001 (0.263)	loss 6.873 (6.785)	prob 2.613 (3.131)	GS 33.562 (33.161)	mem 74.382
Train: [70][1390/1500]	BT 0.068 (0.305)	DT 0.011 (0.266)	loss 6.819 (6.792)	prob 2.423 (3.103)	GS 35.500 (33.121)	mem 74.381
Train: [70][1400/1500]	BT 0.031 (0.303)	DT 0.000 (0.264)	loss 7.020 (6.791)	prob 2.642 (3.026)	GS 35.828 (33.115)	mem 74.381
Train: [70][1410/1500]	BT 0.028 (0.315)	DT 0.000 (0.277)	loss 6.699 (6.791)	prob 3.286 (2.820)	GS 35.000 (32.503)	mem 74.380
Train: [70][1420/1500]	BT 0.036 (0.313)	DT 0.000 (0.275)	loss 6.850 (6.757)	prob 2.560 (2.886)	GS 36.062 (32.589)	mem 74.388
Train: [70][1430/1500]	BT 0.025 (0.314)	DT 0.000 (0.276)	loss 6.736 (6.759)	prob 2.776 (2.802)	GS 32.797 (32.622)	mem 74.414
Train: [70][1440/1500]	BT 0.030 (0.312)	DT 0.000 (0.274)	loss 6.715 (6.753)	prob 2.845 (2.806)	GS 32.453 (32.752)	mem 74.416
Train: [70][1450/1500]	BT 0.027 (0.312)	DT 0.000 (0.274)	loss 6.846 (6.754)	prob 2.224 (2.774)	GS 33.656 (32.406)	mem 73.976
Train: [70][1460/1500]	BT 0.033 (0.310)	DT 0.000 (0.272)	loss 7.021 (6.767)	prob 2.560 (2.925)	GS 33.266 (31.892)	mem 73.978
Train: [70][1470/1500]	BT 0.025 (0.308)	DT 0.000 (0.271)	loss 6.777 (6.769)	prob 2.268 (2.792)	GS 34.891 (31.634)	mem 73.979
Train: [70][1480/1500]	BT 0.037 (0.309)	DT 0.001 (0.271)	loss 6.847 (6.780)	prob 2.566 (2.841)	GS 30.750 (32.194)	mem 12.210
Train: [70][1490/1500]	BT 0.026 (0.307)	DT 0.000 (0.269)	loss 6.926 (6.781)	prob 2.125 (2.846)	GS 34.812 (32.315)	mem 12.136
Train: [70][1500/1500]	BT 0.019 (0.305)	DT 0.000 (0.268)	loss 6.537 (6.773)	prob 1.422 (2.865)	GS 35.156 (32.575)	mem 9.323
Train: [70][1510/1500]	BT 0.019 (0.303)	DT 0.000 (0.266)	loss 6.459 (6.595)	prob 3.012 (2.947)	GS 36.406 (34.188)	mem 9.324
epoch 70, total time 458.29
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [71][1/1500]	BT 24.265 (24.265)	DT 24.193 (24.193)	loss 6.293 (6.293)	prob 3.301 (3.301)	GS 31.891 (31.891)	mem 74.267
Train: [71][10/1500]	BT 0.045 (2.674)	DT 0.014 (2.624)	loss 6.503 (6.510)	prob 3.341 (2.841)	GS 35.219 (32.783)	mem 74.282
Train: [71][20/1500]	BT 0.038 (1.356)	DT 0.001 (1.312)	loss 6.469 (6.526)	prob 2.754 (2.845)	GS 37.094 (32.983)	mem 74.288
Train: [71][30/1500]	BT 0.038 (1.042)	DT 0.001 (1.001)	loss 6.717 (6.580)	prob 3.116 (2.862)	GS 30.719 (32.974)	mem 74.298
Train: [71][40/1500]	BT 0.028 (0.791)	DT 0.001 (0.751)	loss 6.707 (6.607)	prob 2.777 (2.842)	GS 31.328 (32.659)	mem 74.303
Train: [71][50/1500]	BT 0.036 (0.725)	DT 0.000 (0.687)	loss 6.674 (6.625)	prob 2.619 (2.730)	GS 37.797 (32.553)	mem 74.325
Train: [71][60/1500]	BT 0.037 (0.610)	DT 0.001 (0.572)	loss 6.850 (6.688)	prob 1.667 (2.664)	GS 30.250 (31.605)	mem 74.327
Train: [71][70/1500]	BT 0.034 (0.637)	DT 0.000 (0.598)	loss 6.711 (6.718)	prob 2.140 (2.535)	GS 36.031 (32.068)	mem 74.352
Train: [71][80/1500]	BT 0.037 (0.562)	DT 0.000 (0.523)	loss 6.838 (6.716)	prob 2.194 (2.527)	GS 34.531 (31.918)	mem 74.355
Train: [71][90/1500]	BT 0.067 (0.505)	DT 0.003 (0.465)	loss 6.706 (6.726)	prob 2.198 (2.421)	GS 37.141 (32.214)	mem 74.361
Train: [71][100/1500]	BT 0.037 (0.499)	DT 0.001 (0.460)	loss 6.803 (6.735)	prob 2.281 (2.469)	GS 32.656 (32.515)	mem 74.356
Train: [71][110/1500]	BT 0.038 (0.457)	DT 0.000 (0.418)	loss 6.713 (6.763)	prob 3.167 (2.928)	GS 36.078 (31.616)	mem 74.247
Train: [71][120/1500]	BT 0.028 (0.462)	DT 0.000 (0.423)	loss 6.672 (6.758)	prob 1.908 (2.663)	GS 31.188 (31.415)	mem 74.261
Train: [71][130/1500]	BT 0.036 (0.429)	DT 0.000 (0.391)	loss 6.645 (6.748)	prob 2.752 (2.627)	GS 29.219 (31.489)	mem 74.263
Train: [71][140/1500]	BT 0.037 (0.410)	DT 0.001 (0.372)	loss 6.897 (6.739)	prob 2.482 (2.681)	GS 35.344 (31.938)	mem 74.265
Train: [71][150/1500]	BT 0.037 (0.407)	DT 0.001 (0.369)	loss 6.658 (6.739)	prob 2.561 (2.683)	GS 32.250 (32.080)	mem 74.267
Train: [71][160/1500]	BT 0.036 (0.384)	DT 0.000 (0.346)	loss 6.760 (6.711)	prob 2.953 (2.854)	GS 33.250 (32.336)	mem 74.267
Train: [71][170/1500]	BT 0.023 (0.398)	DT 0.000 (0.360)	loss 6.683 (6.713)	prob 3.454 (2.830)	GS 33.031 (32.184)	mem 74.271
Train: [71][180/1500]	BT 0.029 (0.377)	DT 0.000 (0.340)	loss 6.685 (6.713)	prob 3.156 (2.818)	GS 34.750 (32.340)	mem 74.272
Train: [71][190/1500]	BT 0.074 (0.392)	DT 0.008 (0.356)	loss 6.559 (6.706)	prob 3.096 (2.822)	GS 33.516 (32.454)	mem 74.284
Train: [71][200/1500]	BT 0.031 (0.374)	DT 0.000 (0.338)	loss 6.812 (6.702)	prob 2.584 (2.740)	GS 31.688 (32.502)	mem 74.291
Train: [71][210/1500]	BT 0.031 (0.358)	DT 0.000 (0.322)	loss 6.661 (6.702)	prob 2.374 (2.496)	GS 34.984 (33.056)	mem 74.291
Train: [71][220/1500]	BT 0.038 (0.382)	DT 0.001 (0.345)	loss 6.655 (6.709)	prob 2.671 (2.611)	GS 34.469 (33.319)	mem 74.280
Train: [71][230/1500]	BT 0.033 (0.412)	DT 0.001 (0.375)	loss 6.680 (6.718)	prob 2.259 (2.586)	GS 32.297 (33.417)	mem 74.303
Train: [71][240/1500]	BT 0.026 (0.396)	DT 0.000 (0.360)	loss 6.952 (6.714)	prob 2.497 (2.571)	GS 34.984 (33.932)	mem 74.303
Train: [71][250/1500]	BT 0.036 (0.401)	DT 0.000 (0.365)	loss 6.668 (6.708)	prob 2.715 (2.624)	GS 32.984 (33.732)	mem 74.309
Train: [71][260/1500]	BT 0.031 (0.387)	DT 0.000 (0.351)	loss 6.795 (6.710)	prob 2.685 (2.422)	GS 33.812 (32.747)	mem 74.309
Train: [71][270/1500]	BT 0.067 (0.375)	DT 0.006 (0.338)	loss 6.701 (6.719)	prob 2.482 (2.528)	GS 34.453 (32.275)	mem 74.310
Train: [71][280/1500]	BT 0.039 (0.376)	DT 0.001 (0.340)	loss 6.931 (6.741)	prob 2.404 (2.558)	GS 38.297 (32.823)	mem 74.313
Train: [71][290/1500]	BT 0.038 (0.364)	DT 0.001 (0.328)	loss 6.831 (6.729)	prob 2.596 (2.562)	GS 28.781 (32.629)	mem 74.312
Train: [71][300/1500]	BT 0.067 (0.375)	DT 0.011 (0.338)	loss 6.714 (6.742)	prob 2.832 (2.575)	GS 31.875 (32.678)	mem 74.315
Train: [71][310/1500]	BT 0.030 (0.384)	DT 0.000 (0.347)	loss 6.667 (6.686)	prob 2.468 (2.679)	GS 29.172 (32.442)	mem 74.318
Train: [71][320/1500]	BT 0.037 (0.373)	DT 0.001 (0.337)	loss 6.513 (6.678)	prob 2.990 (2.618)	GS 32.031 (32.080)	mem 74.319
Train: [71][330/1500]	BT 0.064 (0.374)	DT 0.009 (0.337)	loss 6.714 (6.703)	prob 2.731 (2.575)	GS 32.531 (32.247)	mem 74.321
Train: [71][340/1500]	BT 0.038 (0.364)	DT 0.001 (0.327)	loss 6.719 (6.711)	prob 1.841 (2.532)	GS 34.891 (32.359)	mem 74.322
Train: [71][350/1500]	BT 0.038 (0.362)	DT 0.001 (0.325)	loss 6.858 (6.720)	prob 1.841 (2.493)	GS 33.672 (32.487)	mem 74.322
Train: [71][360/1500]	BT 0.036 (0.353)	DT 0.000 (0.316)	loss 6.640 (6.652)	prob 2.773 (2.627)	GS 32.281 (31.673)	mem 74.322
Train: [71][370/1500]	BT 0.059 (0.345)	DT 0.003 (0.308)	loss 6.545 (6.690)	prob 2.573 (2.561)	GS 32.484 (32.387)	mem 74.322
Train: [71][380/1500]	BT 0.030 (0.343)	DT 0.001 (0.306)	loss 6.837 (6.718)	prob 2.372 (2.525)	GS 31.266 (32.546)	mem 74.322
Train: [71][390/1500]	BT 0.030 (0.360)	DT 0.000 (0.323)	loss 6.868 (6.723)	prob 2.539 (2.476)	GS 34.016 (32.799)	mem 74.341
Train: [71][400/1500]	BT 0.023 (0.352)	DT 0.000 (0.315)	loss 6.735 (6.732)	prob 2.288 (2.445)	GS 33.984 (32.941)	mem 74.342
Train: [71][410/1500]	BT 0.033 (0.351)	DT 0.001 (0.314)	loss 6.741 (6.719)	prob 2.538 (2.360)	GS 30.672 (31.913)	mem 74.344
Train: [71][420/1500]	BT 0.038 (0.343)	DT 0.000 (0.307)	loss 6.676 (6.703)	prob 2.180 (2.338)	GS 38.781 (31.678)	mem 74.346
Train: [71][430/1500]	BT 0.033 (0.336)	DT 0.000 (0.300)	loss 6.660 (6.702)	prob 2.428 (2.299)	GS 31.516 (31.500)	mem 74.347
Train: [71][440/1500]	BT 0.063 (0.342)	DT 0.013 (0.306)	loss 6.784 (6.702)	prob 1.475 (2.247)	GS 37.297 (31.801)	mem 74.346
Train: [71][450/1500]	BT 0.029 (0.357)	DT 0.000 (0.320)	loss 6.770 (6.709)	prob 2.812 (2.269)	GS 35.000 (32.114)	mem 74.352
Train: [71][460/1500]	BT 0.025 (0.349)	DT 0.000 (0.313)	loss 6.823 (6.722)	prob 2.556 (2.612)	GS 34.047 (33.014)	mem 74.354
Train: [71][470/1500]	BT 0.037 (0.349)	DT 0.000 (0.312)	loss 6.679 (6.711)	prob 2.531 (2.454)	GS 34.281 (32.509)	mem 74.357
Train: [71][480/1500]	BT 0.037 (0.342)	DT 0.000 (0.306)	loss 6.796 (6.699)	prob 2.385 (2.368)	GS 36.219 (32.665)	mem 74.358
Train: [71][490/1500]	BT 4.505 (0.345)	DT 4.450 (0.309)	loss 6.677 (6.699)	prob 2.154 (2.403)	GS 31.125 (32.485)	mem 74.358
Train: [71][500/1500]	BT 0.035 (0.339)	DT 0.001 (0.302)	loss 6.835 (6.705)	prob 2.289 (2.360)	GS 36.938 (32.662)	mem 74.360
Train: [71][510/1500]	BT 0.037 (0.344)	DT 0.000 (0.307)	loss 6.507 (6.738)	prob 2.157 (2.149)	GS 34.328 (34.256)	mem 74.359
Train: [71][520/1500]	BT 0.037 (0.338)	DT 0.001 (0.301)	loss 6.846 (6.745)	prob 1.563 (2.138)	GS 37.609 (33.579)	mem 74.358
Train: [71][530/1500]	BT 0.027 (0.338)	DT 0.000 (0.301)	loss 6.619 (6.732)	prob 2.003 (2.261)	GS 34.531 (33.165)	mem 74.361
Train: [71][540/1500]	BT 0.049 (0.337)	DT 0.002 (0.300)	loss 6.790 (6.742)	prob 2.460 (2.311)	GS 39.188 (33.357)	mem 74.362
Train: [71][550/1500]	BT 0.075 (0.332)	DT 0.011 (0.295)	loss 6.816 (6.728)	prob 1.506 (2.284)	GS 34.672 (32.963)	mem 74.363
Train: [71][560/1500]	BT 0.092 (0.334)	DT 0.005 (0.296)	loss 6.856 (6.705)	prob 2.346 (2.409)	GS 34.266 (32.702)	mem 74.365
Train: [71][570/1500]	BT 0.029 (0.349)	DT 0.000 (0.311)	loss 6.721 (6.736)	prob 2.529 (2.480)	GS 35.984 (33.162)	mem 74.366
Train: [71][580/1500]	BT 0.027 (0.343)	DT 0.000 (0.305)	loss 6.695 (6.728)	prob 3.042 (2.500)	GS 30.828 (33.635)	mem 74.366
Train: [71][590/1500]	BT 0.035 (0.338)	DT 0.001 (0.300)	loss 6.844 (6.729)	prob 2.503 (2.502)	GS 36.219 (34.102)	mem 74.366
Train: [71][600/1500]	BT 0.033 (0.346)	DT 0.001 (0.309)	loss 7.211 (6.728)	prob 1.754 (2.529)	GS 38.375 (34.096)	mem 74.369
Train: [71][610/1500]	BT 0.078 (0.341)	DT 0.041 (0.304)	loss 6.700 (6.675)	prob 2.376 (2.982)	GS 37.266 (34.398)	mem 74.371
Train: [71][620/1500]	BT 0.052 (0.343)	DT 0.010 (0.306)	loss 6.955 (6.727)	prob 2.711 (2.702)	GS 35.797 (34.998)	mem 74.371
Train: [71][630/1500]	BT 0.030 (0.338)	DT 0.000 (0.301)	loss 6.686 (6.722)	prob 2.593 (2.798)	GS 30.094 (34.155)	mem 74.371
Train: [71][640/1500]	BT 0.038 (0.336)	DT 0.001 (0.299)	loss 6.721 (6.706)	prob 2.679 (2.699)	GS 32.203 (33.563)	mem 74.373
Train: [71][650/1500]	BT 0.051 (0.336)	DT 0.003 (0.298)	loss 6.651 (6.702)	prob 2.015 (2.651)	GS 33.656 (33.291)	mem 74.374
Train: [71][660/1500]	BT 0.037 (0.331)	DT 0.000 (0.294)	loss 6.636 (6.719)	prob 2.230 (2.460)	GS 34.719 (31.895)	mem 74.374
Train: [71][670/1500]	BT 0.034 (0.336)	DT 0.001 (0.298)	loss 6.677 (6.690)	prob 2.548 (2.454)	GS 33.703 (32.006)	mem 74.375
Train: [71][680/1500]	BT 0.037 (0.340)	DT 0.000 (0.302)	loss 6.802 (6.684)	prob 2.108 (2.561)	GS 34.516 (32.849)	mem 74.372
Train: [71][690/1500]	BT 0.035 (0.336)	DT 0.001 (0.298)	loss 6.740 (6.694)	prob 2.521 (2.499)	GS 27.516 (32.471)	mem 74.373
Train: [71][700/1500]	BT 0.035 (0.337)	DT 0.000 (0.299)	loss 6.608 (6.691)	prob 2.415 (2.530)	GS 32.406 (32.362)	mem 74.375
Train: [71][710/1500]	BT 0.038 (0.332)	DT 0.001 (0.295)	loss 6.651 (6.648)	prob 2.623 (2.610)	GS 34.375 (31.177)	mem 74.375
Train: [71][720/1500]	BT 0.037 (0.328)	DT 0.001 (0.290)	loss 6.835 (6.703)	prob 2.624 (2.562)	GS 27.922 (31.401)	mem 74.375
Train: [71][730/1500]	BT 0.028 (0.328)	DT 0.000 (0.290)	loss 6.697 (6.703)	prob 2.906 (2.594)	GS 32.297 (31.894)	mem 74.378
Train: [71][740/1500]	BT 0.038 (0.324)	DT 0.001 (0.287)	loss 6.881 (6.710)	prob 2.088 (2.595)	GS 35.438 (31.925)	mem 74.379
Train: [71][750/1500]	BT 0.061 (0.325)	DT 0.003 (0.288)	loss 6.674 (6.713)	prob 2.642 (2.577)	GS 32.734 (32.103)	mem 74.379
Train: [71][760/1500]	BT 0.035 (0.322)	DT 0.001 (0.284)	loss 6.788 (6.725)	prob 2.403 (2.844)	GS 34.922 (33.366)	mem 74.380
Train: [71][770/1500]	BT 0.060 (0.318)	DT 0.002 (0.280)	loss 6.750 (6.720)	prob 1.528 (2.662)	GS 32.906 (33.117)	mem 74.380
Train: [71][780/1500]	BT 0.062 (0.325)	DT 0.014 (0.287)	loss 6.637 (6.699)	prob 2.894 (2.615)	GS 29.297 (33.119)	mem 74.377
Train: [71][790/1500]	BT 0.039 (0.327)	DT 0.001 (0.289)	loss 6.621 (6.697)	prob 2.450 (2.585)	GS 33.000 (33.468)	mem 74.411
Train: [71][800/1500]	BT 0.039 (0.324)	DT 0.001 (0.286)	loss 6.679 (6.689)	prob 2.778 (2.592)	GS 34.609 (32.941)	mem 74.410
Train: [71][810/1500]	BT 0.038 (0.325)	DT 0.001 (0.287)	loss 6.734 (6.636)	prob 2.618 (2.448)	GS 32.438 (32.180)	mem 74.410
Train: [71][820/1500]	BT 0.039 (0.322)	DT 0.001 (0.284)	loss 6.512 (6.628)	prob 2.801 (2.555)	GS 33.234 (32.128)	mem 74.410
Train: [71][830/1500]	BT 0.028 (0.324)	DT 0.000 (0.286)	loss 6.482 (6.617)	prob 2.294 (2.535)	GS 33.844 (32.895)	mem 74.412
Train: [71][840/1500]	BT 0.033 (0.320)	DT 0.000 (0.282)	loss 6.468 (6.624)	prob 2.300 (2.612)	GS 33.016 (32.605)	mem 74.412
Train: [71][850/1500]	BT 0.040 (0.317)	DT 0.001 (0.279)	loss 6.775 (6.611)	prob 2.947 (2.649)	GS 35.234 (32.807)	mem 74.413
Train: [71][860/1500]	BT 0.033 (0.319)	DT 0.001 (0.281)	loss 6.693 (6.628)	prob 2.532 (2.716)	GS 34.953 (33.089)	mem 74.414
Train: [71][870/1500]	BT 0.036 (0.315)	DT 0.001 (0.278)	loss 6.700 (6.629)	prob 2.423 (2.504)	GS 36.531 (32.993)	mem 74.414
Train: [71][880/1500]	BT 0.030 (0.317)	DT 0.000 (0.280)	loss 6.728 (6.641)	prob 1.929 (2.461)	GS 31.438 (32.883)	mem 74.416
Train: [71][890/1500]	BT 0.053 (0.314)	DT 0.011 (0.276)	loss 6.552 (6.652)	prob 2.222 (2.521)	GS 33.234 (32.945)	mem 74.416
Train: [71][900/1500]	BT 0.069 (0.311)	DT 0.012 (0.274)	loss 6.773 (6.635)	prob 2.512 (2.549)	GS 30.844 (33.075)	mem 74.417
Train: [71][910/1500]	BT 0.055 (0.321)	DT 0.006 (0.283)	loss 6.741 (6.638)	prob 1.847 (2.486)	GS 31.562 (33.942)	mem 74.414
Train: [71][920/1500]	BT 0.060 (0.318)	DT 0.011 (0.280)	loss 6.900 (6.640)	prob 2.129 (2.449)	GS 32.578 (32.681)	mem 74.415
Train: [71][930/1500]	BT 0.075 (0.323)	DT 0.004 (0.285)	loss 6.534 (6.634)	prob 2.480 (2.354)	GS 35.203 (32.549)	mem 74.418
Train: [71][940/1500]	BT 0.031 (0.328)	DT 0.000 (0.290)	loss 6.600 (6.630)	prob 2.663 (2.373)	GS 28.844 (32.123)	mem 74.416
Train: [71][950/1500]	BT 0.037 (0.325)	DT 0.000 (0.287)	loss 6.706 (6.638)	prob 2.211 (2.408)	GS 33.688 (32.098)	mem 74.416
Train: [71][960/1500]	BT 0.030 (0.326)	DT 0.000 (0.288)	loss 6.668 (6.644)	prob 3.380 (3.017)	GS 33.500 (32.325)	mem 74.416
Train: [71][970/1500]	BT 0.038 (0.323)	DT 0.001 (0.285)	loss 6.586 (6.640)	prob 2.136 (2.756)	GS 36.750 (32.909)	mem 74.415
Train: [71][980/1500]	BT 0.040 (0.320)	DT 0.001 (0.282)	loss 6.736 (6.637)	prob 2.394 (2.722)	GS 34.609 (32.974)	mem 74.415
Train: [71][990/1500]	BT 0.039 (0.320)	DT 0.001 (0.282)	loss 6.950 (6.648)	prob 1.904 (2.550)	GS 36.781 (33.002)	mem 74.416
Train: [71][1000/1500]	BT 0.039 (0.317)	DT 0.001 (0.279)	loss 6.674 (6.654)	prob 2.492 (2.547)	GS 36.938 (32.983)	mem 74.416
Train: [71][1010/1500]	BT 0.069 (0.319)	DT 0.013 (0.281)	loss 6.935 (6.691)	prob 2.233 (2.306)	GS 31.203 (31.622)	mem 74.418
Train: [71][1020/1500]	BT 0.055 (0.316)	DT 0.008 (0.278)	loss 6.859 (6.682)	prob 1.853 (2.360)	GS 35.203 (31.734)	mem 74.417
Train: [71][1030/1500]	BT 0.097 (0.321)	DT 0.022 (0.282)	loss 6.852 (6.672)	prob 2.079 (2.380)	GS 32.672 (31.798)	mem 74.416
Train: [71][1040/1500]	BT 0.024 (0.326)	DT 0.000 (0.288)	loss 6.777 (6.681)	prob 2.177 (2.396)	GS 35.906 (32.013)	mem 74.413
Train: [71][1050/1500]	BT 0.036 (0.323)	DT 0.000 (0.285)	loss 6.555 (6.665)	prob 2.289 (2.412)	GS 38.422 (32.331)	mem 74.414
Train: [71][1060/1500]	BT 0.030 (0.324)	DT 0.000 (0.286)	loss 6.662 (6.816)	prob 1.676 (2.346)	GS 35.922 (31.814)	mem 74.420
Train: [71][1070/1500]	BT 0.024 (0.321)	DT 0.000 (0.283)	loss 6.728 (6.768)	prob 2.623 (2.237)	GS 33.828 (31.611)	mem 74.421
Train: [71][1080/1500]	BT 0.036 (0.323)	DT 0.000 (0.285)	loss 6.795 (6.759)	prob 2.879 (2.278)	GS 36.422 (31.333)	mem 74.431
Train: [71][1090/1500]	BT 0.031 (0.320)	DT 0.000 (0.282)	loss 6.725 (6.727)	prob 2.750 (2.359)	GS 31.750 (32.022)	mem 74.432
Train: [71][1100/1500]	BT 0.037 (0.318)	DT 0.001 (0.280)	loss 6.829 (6.733)	prob 1.187 (2.328)	GS 29.344 (32.328)	mem 74.433
Train: [71][1110/1500]	BT 0.026 (0.318)	DT 0.000 (0.280)	loss 6.902 (6.770)	prob 2.427 (2.550)	GS 32.922 (33.622)	mem 74.334
Train: [71][1120/1500]	BT 0.034 (0.316)	DT 0.000 (0.278)	loss 6.610 (6.740)	prob 2.803 (2.416)	GS 36.391 (33.282)	mem 74.335
Train: [71][1130/1500]	BT 0.047 (0.316)	DT 0.002 (0.278)	loss 6.823 (6.732)	prob 2.564 (2.368)	GS 37.469 (33.413)	mem 74.337
Train: [71][1140/1500]	BT 0.037 (0.314)	DT 0.001 (0.276)	loss 6.784 (6.737)	prob 1.389 (2.284)	GS 34.203 (33.159)	mem 74.338
Train: [71][1150/1500]	BT 0.036 (0.314)	DT 0.000 (0.276)	loss 6.764 (6.744)	prob 2.514 (2.307)	GS 37.797 (33.125)	mem 74.337
Train: [71][1160/1500]	BT 0.037 (0.312)	DT 0.001 (0.274)	loss 6.486 (6.672)	prob 3.160 (2.757)	GS 35.859 (32.175)	mem 74.336
Train: [71][1170/1500]	BT 0.037 (0.310)	DT 0.001 (0.272)	loss 6.946 (6.734)	prob 2.256 (2.402)	GS 34.391 (32.333)	mem 74.337
Train: [71][1180/1500]	BT 0.038 (0.313)	DT 0.001 (0.275)	loss 7.076 (6.733)	prob 2.436 (2.424)	GS 31.109 (32.354)	mem 74.337
Train: [71][1190/1500]	BT 0.038 (0.311)	DT 0.001 (0.274)	loss 6.575 (6.726)	prob 2.040 (2.397)	GS 34.484 (32.661)	mem 74.338
Train: [71][1200/1500]	BT 0.028 (0.314)	DT 0.000 (0.276)	loss 6.760 (6.736)	prob 2.503 (2.383)	GS 38.750 (33.210)	mem 74.349
Train: [71][1210/1500]	BT 0.037 (0.311)	DT 0.001 (0.274)	loss 6.814 (6.706)	prob 2.487 (2.381)	GS 31.609 (33.242)	mem 74.359
Train: [71][1220/1500]	BT 0.033 (0.313)	DT 0.000 (0.275)	loss 6.600 (6.705)	prob 2.567 (2.186)	GS 35.109 (33.430)	mem 74.358
Train: [71][1230/1500]	BT 0.038 (0.311)	DT 0.001 (0.273)	loss 7.174 (6.748)	prob 2.328 (2.179)	GS 34.328 (32.624)	mem 74.360
Train: [71][1240/1500]	BT 0.039 (0.309)	DT 0.001 (0.271)	loss 6.765 (6.733)	prob 1.938 (2.275)	GS 35.297 (33.070)	mem 74.347
Train: [71][1250/1500]	BT 0.040 (0.309)	DT 0.001 (0.271)	loss 6.757 (6.736)	prob 2.868 (2.259)	GS 31.141 (33.112)	mem 74.347
Train: [71][1260/1500]	BT 0.040 (0.307)	DT 0.001 (0.269)	loss 6.820 (6.745)	prob 2.065 (2.488)	GS 31.750 (33.128)	mem 74.347
Train: [71][1270/1500]	BT 0.043 (0.307)	DT 0.000 (0.269)	loss 6.787 (6.754)	prob 2.434 (2.429)	GS 30.922 (32.338)	mem 74.346
Train: [71][1280/1500]	BT 0.039 (0.305)	DT 0.001 (0.267)	loss 6.956 (6.778)	prob 2.197 (2.413)	GS 39.500 (32.407)	mem 74.346
Train: [71][1290/1500]	BT 0.050 (0.303)	DT 0.005 (0.265)	loss 6.553 (6.773)	prob 2.423 (2.428)	GS 35.375 (32.512)	mem 74.347
Train: [71][1300/1500]	BT 0.031 (0.310)	DT 0.000 (0.272)	loss 6.927 (6.784)	prob 2.552 (2.406)	GS 31.844 (32.498)	mem 74.343
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [71][1310/1500]	BT 0.024 (0.308)	DT 0.000 (0.270)	loss 6.811 (6.740)	prob 2.182 (2.359)	GS 32.906 (31.712)	mem 74.343
Train: [71][1320/1500]	BT 0.034 (0.309)	DT 0.001 (0.271)	loss 6.915 (6.792)	prob 2.213 (2.365)	GS 33.719 (31.456)	mem 74.345
Train: [71][1330/1500]	BT 0.036 (0.307)	DT 0.001 (0.269)	loss 6.701 (6.766)	prob 2.751 (2.335)	GS 30.031 (31.507)	mem 74.346
Train: [71][1340/1500]	BT 0.035 (0.305)	DT 0.001 (0.267)	loss 6.558 (6.775)	prob 2.029 (2.268)	GS 31.875 (31.409)	mem 74.345
Train: [71][1350/1500]	BT 0.029 (0.306)	DT 0.001 (0.268)	loss 6.841 (6.784)	prob 1.715 (2.274)	GS 34.672 (31.374)	mem 74.347
Train: [71][1360/1500]	BT 0.039 (0.304)	DT 0.001 (0.266)	loss 6.775 (6.802)	prob 2.504 (2.283)	GS 35.250 (32.194)	mem 74.347
Train: [71][1370/1500]	BT 0.037 (0.304)	DT 0.001 (0.266)	loss 6.870 (6.775)	prob 1.924 (2.416)	GS 33.656 (32.509)	mem 74.361
Train: [71][1380/1500]	BT 0.037 (0.302)	DT 0.001 (0.265)	loss 6.839 (6.823)	prob 2.489 (2.254)	GS 34.812 (32.756)	mem 74.362
Train: [71][1390/1500]	BT 0.057 (0.304)	DT 0.015 (0.266)	loss 6.742 (6.827)	prob 3.267 (2.264)	GS 36.141 (32.691)	mem 74.366
Train: [71][1400/1500]	BT 0.058 (0.302)	DT 0.026 (0.264)	loss 6.801 (6.814)	prob 2.430 (2.297)	GS 32.266 (32.574)	mem 74.365
Train: [71][1410/1500]	BT 0.037 (0.301)	DT 0.001 (0.264)	loss 6.779 (6.822)	prob 2.989 (2.058)	GS 29.828 (31.436)	mem 74.365
Train: [71][1420/1500]	BT 0.038 (0.302)	DT 0.000 (0.264)	loss 6.575 (6.860)	prob 1.894 (2.243)	GS 30.312 (31.632)	mem 74.367
Train: [71][1430/1500]	BT 0.069 (0.303)	DT 0.011 (0.265)	loss 6.899 (6.888)	prob 3.072 (2.242)	GS 32.484 (31.878)	mem 74.368
Train: [71][1440/1500]	BT 0.038 (0.304)	DT 0.001 (0.266)	loss 7.010 (6.900)	prob 2.818 (2.286)	GS 34.453 (31.893)	mem 74.403
Train: [71][1450/1500]	BT 0.038 (0.302)	DT 0.001 (0.264)	loss 7.133 (6.901)	prob 2.422 (2.299)	GS 35.047 (32.160)	mem 74.403
Train: [71][1460/1500]	BT 0.047 (0.303)	DT 0.001 (0.265)	loss 7.100 (7.052)	prob 2.409 (2.340)	GS 36.250 (34.461)	mem 74.272
Train: [71][1470/1500]	BT 0.052 (0.303)	DT 0.011 (0.265)	loss 6.967 (7.020)	prob 2.229 (2.195)	GS 31.203 (33.021)	mem 73.757
Train: [71][1480/1500]	BT 0.027 (0.303)	DT 0.000 (0.265)	loss 6.939 (7.002)	prob 2.819 (2.225)	GS 33.203 (32.805)	mem 20.650
Train: [71][1490/1500]	BT 0.026 (0.303)	DT 0.000 (0.265)	loss 6.742 (6.991)	prob 2.873 (2.342)	GS 32.750 (32.858)	mem 9.349
Train: [71][1500/1500]	BT 0.025 (0.301)	DT 0.000 (0.264)	loss 6.923 (6.984)	prob 2.145 (2.339)	GS 31.312 (32.883)	mem 9.349
Train: [71][1510/1500]	BT 0.035 (0.300)	DT 0.000 (0.262)	loss 6.295 (6.788)	prob 3.319 (2.556)	GS 35.219 (33.444)	mem 9.275
epoch 71, total time 453.37
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [72][1/1500]	BT 17.759 (17.759)	DT 17.702 (17.702)	loss 6.495 (6.495)	prob 2.851 (2.851)	GS 30.469 (30.469)	mem 72.872
Train: [72][10/1500]	BT 0.037 (2.445)	DT 0.000 (2.408)	loss 6.514 (6.713)	prob 3.098 (2.475)	GS 35.891 (34.924)	mem 73.922
Train: [72][20/1500]	BT 0.039 (1.278)	DT 0.001 (1.237)	loss 6.827 (6.768)	prob 2.868 (2.471)	GS 37.531 (35.472)	mem 74.252
Train: [72][30/1500]	BT 0.028 (0.992)	DT 0.000 (0.953)	loss 6.787 (6.786)	prob 2.433 (2.499)	GS 33.375 (34.643)	mem 74.389
Train: [72][40/1500]	BT 0.051 (0.753)	DT 0.013 (0.716)	loss 7.398 (6.834)	prob 2.348 (2.544)	GS 32.234 (33.764)	mem 74.390
Train: [72][50/1500]	BT 0.038 (0.610)	DT 0.000 (0.573)	loss 6.889 (6.843)	prob 2.442 (2.622)	GS 33.656 (33.349)	mem 74.390
Train: [72][60/1500]	BT 0.038 (0.607)	DT 0.000 (0.570)	loss 6.780 (6.983)	prob 2.331 (2.213)	GS 31.719 (33.544)	mem 74.397
Train: [72][70/1500]	BT 0.038 (0.526)	DT 0.001 (0.489)	loss 6.917 (6.997)	prob 3.084 (2.374)	GS 33.484 (33.113)	mem 74.398
Train: [72][80/1500]	BT 0.058 (0.505)	DT 0.011 (0.468)	loss 6.859 (6.985)	prob 2.856 (2.449)	GS 35.406 (32.683)	mem 74.401
Train: [72][90/1500]	BT 0.039 (0.476)	DT 0.001 (0.438)	loss 6.892 (6.978)	prob 2.705 (2.468)	GS 34.750 (32.469)	mem 74.404
Train: [72][100/1500]	BT 0.062 (0.457)	DT 0.008 (0.420)	loss 6.718 (6.977)	prob 3.015 (2.467)	GS 37.344 (32.713)	mem 74.405
Train: [72][110/1500]	BT 0.037 (0.439)	DT 0.001 (0.402)	loss 7.043 (7.012)	prob 2.437 (2.437)	GS 33.672 (33.023)	mem 74.410
Train: [72][120/1500]	BT 0.037 (0.412)	DT 0.001 (0.375)	loss 6.884 (7.028)	prob 3.274 (2.387)	GS 38.062 (32.462)	mem 74.417
Train: [72][130/1500]	BT 0.038 (0.400)	DT 0.001 (0.362)	loss 7.039 (7.032)	prob 2.495 (2.484)	GS 32.109 (32.308)	mem 74.418
Train: [72][140/1500]	BT 0.037 (0.378)	DT 0.001 (0.341)	loss 7.110 (7.023)	prob 1.944 (2.455)	GS 34.422 (31.977)	mem 74.418
Train: [72][150/1500]	BT 0.053 (0.367)	DT 0.001 (0.329)	loss 7.000 (7.026)	prob 2.589 (2.439)	GS 34.672 (31.921)	mem 74.421
Train: [72][160/1500]	BT 0.541 (0.366)	DT 0.512 (0.328)	loss 6.900 (6.955)	prob 3.255 (2.562)	GS 34.953 (32.248)	mem 74.463
Train: [72][170/1500]	BT 0.039 (0.347)	DT 0.001 (0.309)	loss 7.065 (6.983)	prob 2.011 (2.560)	GS 38.312 (32.538)	mem 74.464
Train: [72][180/1500]	BT 0.039 (0.341)	DT 0.001 (0.303)	loss 6.904 (6.957)	prob 2.812 (2.492)	GS 36.031 (32.784)	mem 74.465
Train: [72][190/1500]	BT 0.039 (0.341)	DT 0.001 (0.303)	loss 7.512 (6.965)	prob 2.539 (2.438)	GS 35.203 (32.873)	mem 74.467
Train: [72][200/1500]	BT 1.254 (0.332)	DT 1.199 (0.294)	loss 7.097 (6.968)	prob 2.932 (2.515)	GS 33.469 (32.750)	mem 74.475
Train: [72][210/1500]	BT 0.039 (0.337)	DT 0.001 (0.298)	loss 6.909 (6.954)	prob 1.744 (2.161)	GS 32.984 (33.177)	mem 74.476
Train: [72][220/1500]	BT 0.039 (0.323)	DT 0.001 (0.285)	loss 6.944 (6.958)	prob 1.734 (2.346)	GS 35.531 (32.962)	mem 74.477
Train: [72][230/1500]	BT 0.038 (0.349)	DT 0.000 (0.311)	loss 7.055 (7.001)	prob 2.664 (2.328)	GS 37.516 (33.339)	mem 74.483
Train: [72][240/1500]	BT 0.039 (0.343)	DT 0.001 (0.304)	loss 6.880 (7.034)	prob 2.717 (2.273)	GS 33.438 (33.764)	mem 74.484
Train: [72][250/1500]	BT 0.039 (0.331)	DT 0.001 (0.292)	loss 7.064 (7.012)	prob 2.540 (2.375)	GS 31.000 (33.562)	mem 74.485
Train: [72][260/1500]	BT 0.039 (0.330)	DT 0.001 (0.291)	loss 6.792 (7.002)	prob 3.462 (2.680)	GS 34.938 (32.186)	mem 74.484
Train: [72][270/1500]	BT 0.040 (0.320)	DT 0.001 (0.282)	loss 7.130 (7.051)	prob 2.593 (2.590)	GS 33.453 (32.286)	mem 74.484
Train: [72][280/1500]	BT 0.039 (0.317)	DT 0.001 (0.278)	loss 7.256 (7.011)	prob 3.062 (2.575)	GS 35.281 (32.380)	mem 74.487
Train: [72][290/1500]	BT 0.041 (0.312)	DT 0.001 (0.273)	loss 6.751 (7.015)	prob 3.262 (2.572)	GS 32.656 (32.224)	mem 74.487
Train: [72][300/1500]	BT 0.039 (0.327)	DT 0.001 (0.288)	loss 7.327 (7.016)	prob 2.454 (2.454)	GS 35.156 (32.484)	mem 74.488
Train: [72][310/1500]	BT 0.038 (0.318)	DT 0.001 (0.279)	loss 7.174 (6.986)	prob 2.249 (2.225)	GS 33.281 (33.464)	mem 74.489
Train: [72][320/1500]	BT 0.038 (0.318)	DT 0.001 (0.279)	loss 6.906 (6.975)	prob 3.506 (2.289)	GS 30.344 (32.548)	mem 74.489
Train: [72][330/1500]	BT 0.029 (0.310)	DT 0.000 (0.271)	loss 7.456 (6.973)	prob 2.198 (2.418)	GS 34.344 (32.477)	mem 74.491
Train: [72][340/1500]	BT 0.037 (0.314)	DT 0.000 (0.275)	loss 7.205 (7.021)	prob 2.017 (2.416)	GS 32.000 (32.596)	mem 74.491
Train: [72][350/1500]	BT 0.048 (0.306)	DT 0.011 (0.267)	loss 7.444 (7.072)	prob 2.098 (2.355)	GS 31.828 (32.812)	mem 74.491
Train: [72][360/1500]	BT 0.038 (0.298)	DT 0.001 (0.260)	loss 6.969 (7.110)	prob 2.675 (2.656)	GS 31.922 (31.161)	mem 74.491
Train: [72][370/1500]	BT 0.103 (0.300)	DT 0.003 (0.261)	loss 7.353 (7.133)	prob 2.517 (2.701)	GS 35.516 (31.659)	mem 74.499
Train: [72][380/1500]	BT 0.072 (0.294)	DT 0.006 (0.255)	loss 7.166 (7.102)	prob 2.546 (2.622)	GS 36.125 (31.589)	mem 74.499
Train: [72][390/1500]	BT 0.067 (0.305)	DT 0.001 (0.264)	loss 7.327 (7.114)	prob 1.836 (2.629)	GS 33.688 (31.836)	mem 74.503
Train: [72][400/1500]	BT 0.034 (0.301)	DT 0.000 (0.261)	loss 6.832 (7.133)	prob 3.266 (2.649)	GS 35.516 (32.282)	mem 74.502
Train: [72][410/1500]	BT 0.029 (0.331)	DT 0.000 (0.291)	loss 7.248 (7.233)	prob 2.221 (2.611)	GS 32.125 (34.481)	mem 74.512
Train: [72][420/1500]	BT 0.024 (0.324)	DT 0.000 (0.284)	loss 7.315 (7.185)	prob 3.502 (2.788)	GS 32.375 (33.185)	mem 74.513
Train: [72][430/1500]	BT 0.036 (0.317)	DT 0.000 (0.277)	loss 7.482 (7.174)	prob 3.692 (2.993)	GS 31.312 (33.104)	mem 74.513
Train: [72][440/1500]	BT 0.023 (0.320)	DT 0.000 (0.280)	loss 6.805 (7.183)	prob 3.821 (3.088)	GS 32.438 (33.126)	mem 74.534
Train: [72][450/1500]	BT 0.025 (0.313)	DT 0.000 (0.274)	loss 7.242 (7.174)	prob 3.275 (3.100)	GS 34.922 (33.006)	mem 74.534
Train: [72][460/1500]	BT 0.030 (0.318)	DT 0.000 (0.279)	loss 7.314 (7.156)	prob 3.305 (3.291)	GS 33.766 (32.473)	mem 74.415
Train: [72][470/1500]	BT 0.066 (0.312)	DT 0.008 (0.273)	loss 6.945 (7.171)	prob 3.533 (3.182)	GS 35.031 (32.548)	mem 74.415
Train: [72][480/1500]	BT 0.064 (0.306)	DT 0.004 (0.267)	loss 6.940 (7.172)	prob 3.628 (3.145)	GS 33.859 (32.569)	mem 74.415
Train: [72][490/1500]	BT 0.037 (0.307)	DT 0.001 (0.268)	loss 7.235 (7.166)	prob 3.538 (3.216)	GS 36.562 (32.614)	mem 74.416
Train: [72][500/1500]	BT 0.027 (0.302)	DT 0.001 (0.263)	loss 7.154 (7.164)	prob 3.054 (3.204)	GS 31.453 (32.758)	mem 74.417
Train: [72][510/1500]	BT 0.037 (0.302)	DT 0.001 (0.263)	loss 7.333 (7.181)	prob 2.943 (2.792)	GS 34.141 (31.831)	mem 74.419
Train: [72][520/1500]	BT 0.037 (0.299)	DT 0.001 (0.260)	loss 6.927 (7.090)	prob 2.462 (2.908)	GS 31.547 (32.036)	mem 74.418
Train: [72][530/1500]	BT 0.037 (0.297)	DT 0.001 (0.258)	loss 7.219 (7.116)	prob 3.536 (3.027)	GS 34.781 (32.155)	mem 74.420
Train: [72][540/1500]	BT 0.036 (0.298)	DT 0.000 (0.259)	loss 7.357 (7.136)	prob 3.254 (3.093)	GS 34.438 (32.204)	mem 74.442
Train: [72][550/1500]	BT 0.028 (0.293)	DT 0.000 (0.254)	loss 6.740 (7.136)	prob 3.737 (3.147)	GS 33.312 (31.992)	mem 74.442
Train: [72][560/1500]	BT 0.038 (0.295)	DT 0.000 (0.257)	loss 7.705 (7.241)	prob 2.932 (3.188)	GS 37.500 (33.622)	mem 74.444
Train: [72][570/1500]	BT 0.684 (0.292)	DT 0.650 (0.253)	loss 7.357 (7.166)	prob 3.949 (3.388)	GS 34.188 (33.248)	mem 74.445
Train: [72][580/1500]	BT 0.029 (0.288)	DT 0.001 (0.249)	loss 7.334 (7.205)	prob 2.952 (3.335)	GS 34.500 (32.915)	mem 74.445
Train: [72][590/1500]	BT 0.038 (0.291)	DT 0.000 (0.252)	loss 7.267 (7.239)	prob 3.209 (3.286)	GS 34.531 (33.072)	mem 74.447
Train: [72][600/1500]	BT 0.037 (0.287)	DT 0.001 (0.248)	loss 7.863 (7.237)	prob 2.555 (3.207)	GS 32.859 (33.200)	mem 74.447
Train: [72][610/1500]	BT 0.036 (0.289)	DT 0.001 (0.251)	loss 7.196 (7.208)	prob 3.084 (2.978)	GS 31.031 (33.416)	mem 74.432
Train: [72][620/1500]	BT 0.037 (0.285)	DT 0.001 (0.247)	loss 7.017 (7.134)	prob 2.236 (2.914)	GS 35.969 (33.544)	mem 74.432
Train: [72][630/1500]	BT 1.346 (0.284)	DT 1.296 (0.245)	loss 7.266 (7.135)	prob 3.162 (2.945)	GS 36.500 (33.073)	mem 74.433
Train: [72][640/1500]	BT 0.056 (0.287)	DT 0.016 (0.248)	loss 7.209 (7.112)	prob 3.077 (3.040)	GS 34.688 (32.824)	mem 74.431
Train: [72][650/1500]	BT 0.066 (0.283)	DT 0.011 (0.245)	loss 7.361 (7.105)	prob 3.342 (3.129)	GS 33.328 (32.748)	mem 74.430
Train: [72][660/1500]	BT 0.038 (0.287)	DT 0.001 (0.248)	loss 7.480 (7.072)	prob 3.051 (2.947)	GS 34.156 (31.594)	mem 74.433
Train: [72][670/1500]	BT 0.038 (0.283)	DT 0.001 (0.244)	loss 7.389 (7.115)	prob 3.514 (3.038)	GS 29.625 (31.637)	mem 74.435
Train: [72][680/1500]	BT 0.027 (0.286)	DT 0.000 (0.247)	loss 7.202 (7.120)	prob 3.703 (3.208)	GS 32.969 (31.989)	mem 74.449
Train: [72][690/1500]	BT 0.036 (0.282)	DT 0.001 (0.243)	loss 7.120 (7.136)	prob 3.290 (3.207)	GS 32.453 (31.891)	mem 74.450
Train: [72][700/1500]	BT 0.037 (0.279)	DT 0.001 (0.240)	loss 6.974 (7.107)	prob 3.079 (3.150)	GS 34.281 (32.191)	mem 74.451
Train: [72][710/1500]	BT 0.033 (0.280)	DT 0.000 (0.241)	loss 7.651 (7.053)	prob 2.901 (3.365)	GS 32.438 (31.562)	mem 74.456
Train: [72][720/1500]	BT 0.037 (0.276)	DT 0.001 (0.238)	loss 7.412 (7.030)	prob 3.450 (3.305)	GS 31.266 (31.259)	mem 74.457
Train: [72][730/1500]	BT 0.037 (0.277)	DT 0.000 (0.239)	loss 7.385 (7.072)	prob 3.234 (3.295)	GS 34.641 (31.639)	mem 74.459
Train: [72][740/1500]	BT 0.067 (0.274)	DT 0.030 (0.236)	loss 6.927 (7.051)	prob 3.599 (3.295)	GS 27.000 (31.786)	mem 74.460
Train: [72][750/1500]	BT 0.038 (0.273)	DT 0.001 (0.235)	loss 6.940 (7.046)	prob 3.057 (3.294)	GS 37.500 (31.889)	mem 74.460
Train: [72][760/1500]	BT 0.036 (0.276)	DT 0.000 (0.238)	loss 7.066 (7.014)	prob 2.467 (2.857)	GS 36.359 (33.895)	mem 74.463
Train: [72][770/1500]	BT 0.038 (0.273)	DT 0.001 (0.235)	loss 6.795 (7.043)	prob 3.584 (2.875)	GS 34.562 (32.979)	mem 74.464
Train: [72][780/1500]	BT 0.038 (0.275)	DT 0.001 (0.236)	loss 7.313 (7.030)	prob 3.251 (3.038)	GS 35.625 (32.592)	mem 74.466
Train: [72][790/1500]	BT 0.038 (0.272)	DT 0.001 (0.233)	loss 7.002 (7.004)	prob 3.593 (3.098)	GS 36.453 (32.356)	mem 74.467
Train: [72][800/1500]	BT 0.036 (0.275)	DT 0.000 (0.237)	loss 6.861 (7.013)	prob 2.742 (3.075)	GS 33.641 (32.249)	mem 74.470
Train: [72][810/1500]	BT 0.038 (0.272)	DT 0.000 (0.234)	loss 7.266 (6.985)	prob 2.634 (3.088)	GS 33.250 (32.273)	mem 74.470
Train: [72][820/1500]	BT 0.028 (0.269)	DT 0.000 (0.231)	loss 6.840 (7.041)	prob 3.231 (2.838)	GS 32.031 (31.861)	mem 74.470
Train: [72][830/1500]	BT 0.054 (0.272)	DT 0.011 (0.234)	loss 7.055 (7.049)	prob 3.278 (2.841)	GS 35.297 (31.763)	mem 74.472
Train: [72][840/1500]	BT 0.062 (0.270)	DT 0.003 (0.231)	loss 6.994 (7.048)	prob 3.422 (2.941)	GS 31.578 (31.841)	mem 74.472
Train: [72][850/1500]	BT 0.031 (0.273)	DT 0.000 (0.234)	loss 7.019 (7.044)	prob 3.193 (2.943)	GS 29.078 (31.942)	mem 74.471
Train: [72][860/1500]	BT 0.077 (0.270)	DT 0.002 (0.232)	loss 7.176 (7.083)	prob 3.568 (2.777)	GS 35.422 (35.706)	mem 74.471
Train: [72][870/1500]	BT 0.077 (0.267)	DT 0.011 (0.229)	loss 6.811 (7.054)	prob 3.286 (2.800)	GS 35.516 (35.060)	mem 74.471
Train: [72][880/1500]	BT 0.032 (0.273)	DT 0.001 (0.234)	loss 7.122 (7.032)	prob 3.622 (2.885)	GS 29.281 (34.521)	mem 74.473
Train: [72][890/1500]	BT 0.031 (0.270)	DT 0.000 (0.232)	loss 6.994 (7.031)	prob 3.012 (2.912)	GS 33.438 (34.209)	mem 74.475
Train: [72][900/1500]	BT 0.114 (0.275)	DT 0.011 (0.236)	loss 7.453 (7.046)	prob 3.550 (2.981)	GS 32.922 (33.961)	mem 74.477
Train: [72][910/1500]	BT 0.037 (0.273)	DT 0.001 (0.234)	loss 7.057 (6.971)	prob 2.449 (3.280)	GS 30.828 (32.769)	mem 74.481
Train: [72][920/1500]	BT 0.027 (0.276)	DT 0.000 (0.237)	loss 7.053 (6.977)	prob 2.636 (3.020)	GS 39.109 (32.691)	mem 74.480
Train: [72][930/1500]	BT 0.037 (0.273)	DT 0.001 (0.234)	loss 7.004 (6.973)	prob 2.768 (2.968)	GS 32.234 (32.771)	mem 74.482
Train: [72][940/1500]	BT 0.037 (0.271)	DT 0.000 (0.232)	loss 6.972 (7.005)	prob 3.050 (2.929)	GS 32.141 (32.579)	mem 74.482
Train: [72][950/1500]	BT 0.038 (0.271)	DT 0.001 (0.233)	loss 6.553 (6.979)	prob 3.702 (2.985)	GS 36.047 (32.489)	mem 74.482
Train: [72][960/1500]	BT 0.032 (0.269)	DT 0.000 (0.230)	loss 6.759 (6.915)	prob 3.239 (3.367)	GS 30.141 (31.303)	mem 74.481
Train: [72][970/1500]	BT 0.072 (0.270)	DT 0.007 (0.232)	loss 7.321 (6.965)	prob 2.812 (3.208)	GS 35.047 (32.395)	mem 74.484
Train: [72][980/1500]	BT 0.034 (0.268)	DT 0.000 (0.229)	loss 6.839 (6.954)	prob 3.128 (3.153)	GS 31.391 (32.590)	mem 74.484
Train: [72][990/1500]	BT 0.093 (0.266)	DT 0.006 (0.227)	loss 7.176 (6.940)	prob 2.520 (3.049)	GS 33.234 (32.456)	mem 74.484
Train: [72][1000/1500]	BT 0.030 (0.275)	DT 0.000 (0.236)	loss 6.662 (6.946)	prob 3.390 (3.009)	GS 36.500 (32.774)	mem 74.513
Train: [72][1010/1500]	BT 0.029 (0.272)	DT 0.001 (0.233)	loss 6.876 (7.027)	prob 3.155 (2.972)	GS 30.000 (31.709)	mem 74.512
Train: [72][1020/1500]	BT 0.039 (0.271)	DT 0.001 (0.232)	loss 7.012 (7.017)	prob 2.456 (2.794)	GS 34.359 (31.679)	mem 74.514
Train: [72][1030/1500]	BT 0.049 (0.271)	DT 0.009 (0.232)	loss 6.613 (6.977)	prob 3.294 (2.847)	GS 32.125 (31.227)	mem 74.517
Train: [72][1040/1500]	BT 0.040 (0.271)	DT 0.001 (0.233)	loss 7.028 (6.954)	prob 2.485 (2.813)	GS 32.438 (31.851)	mem 74.518
Train: [72][1050/1500]	BT 0.064 (0.269)	DT 0.005 (0.230)	loss 7.229 (6.939)	prob 2.819 (2.883)	GS 34.781 (32.030)	mem 74.518
Train: [72][1060/1500]	BT 0.056 (0.268)	DT 0.004 (0.228)	loss 7.037 (6.953)	prob 3.006 (2.970)	GS 33.438 (32.484)	mem 74.519
Train: [72][1070/1500]	BT 0.037 (0.274)	DT 0.001 (0.234)	loss 7.050 (6.929)	prob 3.124 (3.040)	GS 32.578 (32.998)	mem 74.516
Train: [72][1080/1500]	BT 0.038 (0.272)	DT 0.001 (0.232)	loss 6.824 (6.906)	prob 3.043 (2.988)	GS 31.203 (32.515)	mem 74.516
Train: [72][1090/1500]	BT 0.038 (0.271)	DT 0.001 (0.232)	loss 7.249 (6.912)	prob 2.310 (2.959)	GS 35.875 (32.595)	mem 74.514
Train: [72][1100/1500]	BT 0.028 (0.270)	DT 0.000 (0.231)	loss 6.886 (6.887)	prob 2.665 (2.955)	GS 36.781 (32.703)	mem 74.516
Train: [72][1110/1500]	BT 0.039 (0.268)	DT 0.001 (0.229)	loss 6.725 (6.800)	prob 2.356 (2.721)	GS 36.625 (32.545)	mem 74.517
Train: [72][1120/1500]	BT 0.038 (0.270)	DT 0.001 (0.230)	loss 6.680 (6.812)	prob 3.290 (2.754)	GS 35.031 (32.802)	mem 74.515
Train: [72][1130/1500]	BT 0.039 (0.268)	DT 0.001 (0.228)	loss 6.911 (6.793)	prob 2.733 (2.824)	GS 36.797 (32.973)	mem 74.515
Train: [72][1140/1500]	BT 0.039 (0.269)	DT 0.001 (0.230)	loss 6.752 (6.827)	prob 2.962 (2.861)	GS 31.281 (32.797)	mem 74.515
Train: [72][1150/1500]	BT 0.041 (0.267)	DT 0.001 (0.228)	loss 6.809 (6.827)	prob 2.849 (2.889)	GS 30.344 (32.820)	mem 74.515
Train: [72][1160/1500]	BT 0.055 (0.271)	DT 0.004 (0.231)	loss 6.771 (6.916)	prob 2.901 (2.842)	GS 32.859 (32.352)	mem 74.517
Train: [72][1170/1500]	BT 0.048 (0.269)	DT 0.003 (0.229)	loss 7.064 (6.864)	prob 2.476 (2.817)	GS 32.125 (32.298)	mem 74.517
Train: [72][1180/1500]	BT 0.031 (0.267)	DT 0.001 (0.228)	loss 6.860 (6.854)	prob 3.096 (2.766)	GS 34.594 (32.645)	mem 74.517
Train: [72][1190/1500]	BT 0.061 (0.270)	DT 0.013 (0.231)	loss 6.866 (6.850)	prob 2.966 (2.762)	GS 36.969 (32.796)	mem 74.517
Train: [72][1200/1500]	BT 0.050 (0.270)	DT 0.004 (0.231)	loss 6.749 (6.873)	prob 3.005 (2.717)	GS 30.656 (32.954)	mem 74.517
Train: [72][1210/1500]	BT 0.038 (0.269)	DT 0.001 (0.230)	loss 7.142 (6.868)	prob 1.957 (2.822)	GS 36.641 (33.773)	mem 74.519
Train: [72][1220/1500]	BT 0.039 (0.271)	DT 0.001 (0.232)	loss 7.109 (6.925)	prob 2.992 (2.881)	GS 36.547 (34.946)	mem 74.518
Train: [72][1230/1500]	BT 0.038 (0.269)	DT 0.001 (0.230)	loss 6.715 (6.910)	prob 2.729 (2.919)	GS 35.312 (34.201)	mem 74.519
Train: [72][1240/1500]	BT 0.037 (0.272)	DT 0.000 (0.233)	loss 7.168 (6.929)	prob 2.987 (2.921)	GS 36.547 (34.013)	mem 74.518
Train: [72][1250/1500]	BT 0.036 (0.270)	DT 0.001 (0.231)	loss 7.128 (6.923)	prob 2.739 (2.964)	GS 31.219 (33.835)	mem 74.518
Train: [72][1260/1500]	BT 0.031 (0.273)	DT 0.000 (0.234)	loss 7.014 (6.890)	prob 2.718 (2.940)	GS 31.781 (31.127)	mem 74.518
Train: [72][1270/1500]	BT 0.041 (0.272)	DT 0.011 (0.232)	loss 6.797 (6.868)	prob 2.886 (2.868)	GS 34.031 (31.712)	mem 74.520
Train: [72][1280/1500]	BT 0.057 (0.270)	DT 0.016 (0.230)	loss 6.791 (6.888)	prob 3.056 (2.821)	GS 36.109 (32.208)	mem 74.520
Train: [72][1290/1500]	BT 0.021 (0.283)	DT 0.000 (0.244)	loss 6.927 (6.890)	prob 2.803 (2.772)	GS 33.031 (31.976)	mem 74.519
Train: [72][1300/1500]	BT 0.035 (0.281)	DT 0.001 (0.242)	loss 6.847 (6.898)	prob 3.209 (2.826)	GS 33.516 (32.128)	mem 74.519
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [72][1310/1500]	BT 0.028 (0.281)	DT 0.000 (0.242)	loss 6.794 (6.965)	prob 3.229 (2.647)	GS 31.562 (31.984)	mem 74.523
Train: [72][1320/1500]	BT 0.037 (0.279)	DT 0.001 (0.240)	loss 6.878 (6.941)	prob 2.377 (2.718)	GS 32.562 (32.223)	mem 74.524
Train: [72][1330/1500]	BT 0.038 (0.280)	DT 0.000 (0.241)	loss 6.704 (6.944)	prob 2.398 (2.802)	GS 34.734 (31.916)	mem 74.537
Train: [72][1340/1500]	BT 0.037 (0.278)	DT 0.000 (0.239)	loss 7.141 (6.956)	prob 2.304 (2.666)	GS 34.703 (32.074)	mem 74.537
Train: [72][1350/1500]	BT 0.091 (0.276)	DT 0.002 (0.237)	loss 7.051 (6.958)	prob 2.953 (2.672)	GS 31.703 (31.874)	mem 74.538
Train: [72][1360/1500]	BT 0.028 (0.278)	DT 0.000 (0.238)	loss 6.977 (6.969)	prob 2.942 (2.489)	GS 35.703 (33.419)	mem 74.431
Train: [72][1370/1500]	BT 0.037 (0.276)	DT 0.001 (0.237)	loss 7.105 (6.969)	prob 2.062 (2.323)	GS 30.578 (32.914)	mem 74.439
Train: [72][1380/1500]	BT 0.039 (0.276)	DT 0.001 (0.237)	loss 7.177 (6.963)	prob 2.358 (2.303)	GS 35.703 (32.634)	mem 74.439
Train: [72][1390/1500]	BT 0.028 (0.277)	DT 0.000 (0.238)	loss 7.431 (6.947)	prob 2.018 (2.282)	GS 38.750 (32.642)	mem 74.440
Train: [72][1400/1500]	BT 0.037 (0.275)	DT 0.001 (0.236)	loss 7.259 (6.966)	prob 2.200 (2.350)	GS 29.484 (32.673)	mem 74.441
Train: [72][1410/1500]	BT 0.037 (0.274)	DT 0.001 (0.235)	loss 6.864 (6.995)	prob 3.023 (2.586)	GS 36.016 (32.570)	mem 74.442
Train: [72][1420/1500]	BT 0.037 (0.275)	DT 0.001 (0.236)	loss 7.053 (7.011)	prob 3.093 (2.447)	GS 35.875 (32.907)	mem 74.444
Train: [72][1430/1500]	BT 0.037 (0.273)	DT 0.001 (0.234)	loss 7.229 (7.018)	prob 3.292 (2.496)	GS 28.391 (32.603)	mem 74.444
Train: [72][1440/1500]	BT 0.036 (0.275)	DT 0.001 (0.236)	loss 7.325 (7.039)	prob 2.442 (2.419)	GS 34.297 (32.517)	mem 74.466
Train: [72][1450/1500]	BT 0.038 (0.273)	DT 0.001 (0.234)	loss 6.845 (7.035)	prob 2.014 (2.399)	GS 34.625 (32.520)	mem 74.466
Train: [72][1460/1500]	BT 0.026 (0.273)	DT 0.000 (0.234)	loss 7.149 (6.905)	prob 2.120 (2.381)	GS 35.781 (32.002)	mem 73.809
Train: [72][1470/1500]	BT 0.030 (0.272)	DT 0.000 (0.233)	loss 7.179 (6.937)	prob 2.052 (2.291)	GS 32.047 (32.314)	mem 73.660
Train: [72][1480/1500]	BT 0.026 (0.272)	DT 0.000 (0.233)	loss 7.530 (7.027)	prob 2.913 (2.265)	GS 31.000 (32.531)	mem 23.374
Train: [72][1490/1500]	BT 0.033 (0.271)	DT 0.000 (0.232)	loss 7.124 (7.078)	prob 1.430 (2.180)	GS 33.969 (32.575)	mem 14.894
Train: [72][1500/1500]	BT 0.041 (0.270)	DT 0.001 (0.231)	loss 7.211 (7.074)	prob 1.781 (2.164)	GS 33.625 (32.706)	mem 12.081
Train: [72][1510/1500]	BT 0.024 (0.268)	DT 0.000 (0.229)	loss 6.871 (6.973)	prob 2.394 (2.291)	GS 39.000 (32.681)	mem 9.268
epoch 72, total time 405.18
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [73][1/1500]	BT 19.600 (19.600)	DT 19.541 (19.541)	loss 6.858 (6.858)	prob 2.842 (2.842)	GS 36.719 (36.719)	mem 72.756
Train: [73][10/1500]	BT 0.038 (2.336)	DT 0.000 (2.297)	loss 7.118 (6.972)	prob 2.885 (2.753)	GS 34.938 (32.186)	mem 72.893
Train: [73][20/1500]	BT 0.034 (1.187)	DT 0.001 (1.149)	loss 7.708 (6.983)	prob 2.251 (2.578)	GS 35.047 (32.085)	mem 72.907
Train: [73][30/1500]	BT 0.036 (0.939)	DT 0.000 (0.903)	loss 7.237 (6.994)	prob 3.018 (2.693)	GS 32.875 (31.744)	mem 73.055
Train: [73][40/1500]	BT 0.036 (0.714)	DT 0.000 (0.677)	loss 7.440 (7.030)	prob 1.860 (2.678)	GS 28.562 (31.631)	mem 73.057
Train: [73][50/1500]	BT 0.036 (0.579)	DT 0.001 (0.542)	loss 7.231 (7.059)	prob 3.556 (2.682)	GS 32.859 (31.710)	mem 73.063
Train: [73][60/1500]	BT 0.406 (0.559)	DT 0.369 (0.523)	loss 7.323 (7.183)	prob 3.352 (3.047)	GS 33.500 (32.683)	mem 73.076
Train: [73][70/1500]	BT 0.071 (0.486)	DT 0.005 (0.448)	loss 7.121 (7.162)	prob 2.384 (2.682)	GS 36.203 (32.487)	mem 73.077
Train: [73][80/1500]	BT 0.030 (0.515)	DT 0.000 (0.478)	loss 7.139 (7.167)	prob 1.864 (2.654)	GS 36.297 (32.600)	mem 73.089
Train: [73][90/1500]	BT 0.038 (0.461)	DT 0.000 (0.425)	loss 7.571 (7.172)	prob 2.238 (2.583)	GS 41.109 (32.967)	mem 73.090
Train: [73][100/1500]	BT 0.036 (0.463)	DT 0.000 (0.427)	loss 7.189 (7.197)	prob 3.280 (2.589)	GS 31.891 (33.010)	mem 73.108
Train: [73][110/1500]	BT 0.026 (0.424)	DT 0.000 (0.388)	loss 6.855 (7.217)	prob 3.344 (2.950)	GS 32.984 (32.967)	mem 73.109
Train: [73][120/1500]	BT 0.028 (0.391)	DT 0.000 (0.356)	loss 6.864 (7.181)	prob 3.058 (3.026)	GS 29.578 (32.363)	mem 73.110
Train: [73][130/1500]	BT 0.082 (0.406)	DT 0.001 (0.369)	loss 7.135 (7.202)	prob 3.447 (3.018)	GS 34.688 (31.927)	mem 73.213
Train: [73][140/1500]	BT 0.078 (0.382)	DT 0.011 (0.343)	loss 6.875 (7.203)	prob 3.305 (2.939)	GS 32.609 (32.214)	mem 73.262
Train: [73][150/1500]	BT 0.035 (0.429)	DT 0.000 (0.390)	loss 7.322 (7.188)	prob 3.146 (2.936)	GS 33.500 (32.291)	mem 74.210
Train: [73][160/1500]	BT 0.026 (0.455)	DT 0.000 (0.416)	loss 7.163 (7.226)	prob 3.247 (2.770)	GS 31.750 (33.247)	mem 74.264
Train: [73][170/1500]	BT 0.027 (0.430)	DT 0.000 (0.391)	loss 7.243 (7.247)	prob 3.075 (2.821)	GS 39.125 (33.773)	mem 74.265
Train: [73][180/1500]	BT 0.030 (0.443)	DT 0.000 (0.405)	loss 6.983 (7.223)	prob 3.332 (2.865)	GS 30.719 (33.596)	mem 74.318
Train: [73][190/1500]	BT 0.025 (0.421)	DT 0.000 (0.383)	loss 7.548 (7.207)	prob 2.797 (2.836)	GS 36.750 (33.514)	mem 74.317
Train: [73][200/1500]	BT 0.037 (0.401)	DT 0.000 (0.364)	loss 7.357 (7.189)	prob 3.159 (2.854)	GS 32.641 (33.507)	mem 74.318
Train: [73][210/1500]	BT 0.031 (0.401)	DT 0.000 (0.364)	loss 7.013 (7.248)	prob 3.530 (3.104)	GS 35.625 (31.914)	mem 74.320
Train: [73][220/1500]	BT 0.037 (0.384)	DT 0.001 (0.347)	loss 7.336 (7.201)	prob 2.733 (3.011)	GS 30.172 (32.058)	mem 74.323
Train: [73][230/1500]	BT 0.033 (0.393)	DT 0.000 (0.357)	loss 6.900 (7.152)	prob 3.613 (3.011)	GS 35.531 (32.395)	mem 74.326
Train: [73][240/1500]	BT 0.026 (0.378)	DT 0.000 (0.342)	loss 7.119 (7.138)	prob 3.846 (3.055)	GS 33.016 (32.454)	mem 74.327
Train: [73][250/1500]	BT 0.067 (0.372)	DT 0.002 (0.336)	loss 7.768 (7.144)	prob 2.021 (3.053)	GS 36.031 (32.719)	mem 74.338
Train: [73][260/1500]	BT 0.038 (0.368)	DT 0.001 (0.331)	loss 7.182 (7.180)	prob 3.350 (2.724)	GS 34.000 (33.191)	mem 74.339
Train: [73][270/1500]	BT 0.037 (0.355)	DT 0.001 (0.319)	loss 6.847 (7.103)	prob 2.978 (2.787)	GS 32.734 (32.278)	mem 74.338
Train: [73][280/1500]	BT 0.038 (0.355)	DT 0.001 (0.319)	loss 6.889 (7.084)	prob 3.137 (2.860)	GS 31.141 (32.438)	mem 74.339
Train: [73][290/1500]	BT 0.038 (0.344)	DT 0.001 (0.308)	loss 7.247 (7.100)	prob 3.162 (2.902)	GS 34.656 (32.511)	mem 74.340
Train: [73][300/1500]	BT 0.031 (0.356)	DT 0.000 (0.320)	loss 6.922 (7.098)	prob 3.170 (2.867)	GS 27.891 (32.537)	mem 74.342
Train: [73][310/1500]	BT 0.045 (0.346)	DT 0.006 (0.310)	loss 7.050 (7.035)	prob 2.782 (2.924)	GS 35.297 (32.892)	mem 74.343
Train: [73][320/1500]	BT 0.051 (0.340)	DT 0.005 (0.304)	loss 6.839 (7.028)	prob 2.803 (2.844)	GS 33.391 (32.991)	mem 74.342
Train: [73][330/1500]	BT 0.044 (0.368)	DT 0.000 (0.332)	loss 7.266 (7.021)	prob 2.471 (2.819)	GS 31.359 (32.581)	mem 74.346
Train: [73][340/1500]	BT 0.027 (0.358)	DT 0.000 (0.322)	loss 7.161 (7.032)	prob 2.924 (2.830)	GS 31.156 (32.418)	mem 74.347
Train: [73][350/1500]	BT 0.032 (0.360)	DT 0.000 (0.324)	loss 6.769 (7.036)	prob 2.898 (2.844)	GS 32.844 (32.642)	mem 74.350
Train: [73][360/1500]	BT 0.036 (0.351)	DT 0.000 (0.315)	loss 6.767 (6.965)	prob 3.058 (3.020)	GS 33.875 (32.427)	mem 74.352
Train: [73][370/1500]	BT 0.036 (0.342)	DT 0.001 (0.306)	loss 6.987 (6.996)	prob 2.547 (2.805)	GS 31.281 (33.058)	mem 74.351
Train: [73][380/1500]	BT 0.082 (0.347)	DT 0.016 (0.311)	loss 7.097 (7.043)	prob 2.461 (2.761)	GS 33.766 (33.115)	mem 74.354
Train: [73][390/1500]	BT 0.070 (0.340)	DT 0.000 (0.304)	loss 7.256 (7.043)	prob 2.404 (2.730)	GS 34.562 (33.035)	mem 74.354
Train: [73][400/1500]	BT 0.059 (0.351)	DT 0.016 (0.314)	loss 6.957 (7.041)	prob 3.127 (2.666)	GS 35.984 (32.963)	mem 74.352
Train: [73][410/1500]	BT 0.029 (0.356)	DT 0.000 (0.319)	loss 7.253 (7.030)	prob 3.039 (2.916)	GS 31.250 (33.423)	mem 74.354
Train: [73][420/1500]	BT 0.027 (0.348)	DT 0.000 (0.312)	loss 7.211 (6.994)	prob 2.921 (2.904)	GS 31.688 (33.224)	mem 74.355
Train: [73][430/1500]	BT 0.106 (0.349)	DT 0.014 (0.312)	loss 7.044 (7.012)	prob 3.951 (2.920)	GS 31.766 (32.872)	mem 74.388
Train: [73][440/1500]	BT 0.057 (0.343)	DT 0.014 (0.305)	loss 7.188 (7.004)	prob 3.048 (2.864)	GS 35.812 (32.857)	mem 74.388
Train: [73][450/1500]	BT 0.064 (0.344)	DT 0.011 (0.306)	loss 6.859 (6.971)	prob 3.792 (2.951)	GS 35.141 (32.484)	mem 74.391
Train: [73][460/1500]	BT 0.041 (0.346)	DT 0.001 (0.309)	loss 7.125 (6.963)	prob 2.563 (3.103)	GS 32.969 (32.795)	mem 74.392
Train: [73][470/1500]	BT 0.039 (0.341)	DT 0.001 (0.304)	loss 7.229 (6.957)	prob 3.366 (2.871)	GS 31.297 (32.499)	mem 74.392
Train: [73][480/1500]	BT 0.038 (0.343)	DT 0.000 (0.305)	loss 7.180 (6.949)	prob 2.738 (2.866)	GS 34.219 (31.836)	mem 74.390
Train: [73][490/1500]	BT 0.032 (0.336)	DT 0.000 (0.299)	loss 7.014 (6.938)	prob 2.758 (2.884)	GS 35.875 (31.942)	mem 74.392
Train: [73][500/1500]	BT 0.039 (0.331)	DT 0.001 (0.293)	loss 6.865 (6.953)	prob 3.279 (2.886)	GS 32.703 (31.918)	mem 74.393
Train: [73][510/1500]	BT 0.045 (0.331)	DT 0.000 (0.293)	loss 7.010 (6.993)	prob 3.645 (3.084)	GS 30.516 (30.877)	mem 74.396
Train: [73][520/1500]	BT 0.038 (0.328)	DT 0.001 (0.291)	loss 6.881 (6.913)	prob 3.068 (2.923)	GS 35.031 (31.468)	mem 74.396
Train: [73][530/1500]	BT 0.039 (0.328)	DT 0.001 (0.290)	loss 7.316 (6.947)	prob 3.556 (2.883)	GS 29.609 (31.566)	mem 74.398
Train: [73][540/1500]	BT 0.039 (0.324)	DT 0.001 (0.286)	loss 6.853 (6.953)	prob 2.553 (2.907)	GS 32.656 (31.694)	mem 74.398
Train: [73][550/1500]	BT 0.030 (0.322)	DT 0.000 (0.285)	loss 6.870 (6.956)	prob 3.072 (2.872)	GS 36.078 (31.982)	mem 74.399
Train: [73][560/1500]	BT 0.059 (0.319)	DT 0.002 (0.281)	loss 7.066 (6.919)	prob 2.542 (2.848)	GS 34.094 (32.498)	mem 74.400
Train: [73][570/1500]	BT 0.030 (0.320)	DT 0.000 (0.282)	loss 6.868 (6.916)	prob 3.179 (2.889)	GS 35.250 (32.548)	mem 74.399
Train: [73][580/1500]	BT 0.038 (0.319)	DT 0.001 (0.282)	loss 7.280 (6.944)	prob 2.369 (2.871)	GS 35.672 (32.383)	mem 74.396
Train: [73][590/1500]	BT 0.038 (0.316)	DT 0.001 (0.278)	loss 6.855 (6.953)	prob 3.401 (2.880)	GS 36.406 (32.819)	mem 74.397
Train: [73][600/1500]	BT 0.039 (0.318)	DT 0.001 (0.280)	loss 6.841 (6.955)	prob 2.371 (2.858)	GS 30.688 (32.755)	mem 74.396
Train: [73][610/1500]	BT 0.039 (0.314)	DT 0.000 (0.276)	loss 6.985 (6.957)	prob 2.445 (2.515)	GS 34.875 (32.445)	mem 74.396
Train: [73][620/1500]	BT 0.039 (0.309)	DT 0.001 (0.271)	loss 6.919 (6.965)	prob 2.847 (2.644)	GS 33.531 (32.660)	mem 74.396
Train: [73][630/1500]	BT 0.029 (0.310)	DT 0.000 (0.272)	loss 6.983 (6.981)	prob 3.060 (2.691)	GS 31.406 (32.244)	mem 74.395
Train: [73][640/1500]	BT 0.040 (0.310)	DT 0.001 (0.273)	loss 7.003 (6.971)	prob 3.097 (2.715)	GS 35.125 (32.542)	mem 74.396
Train: [73][650/1500]	BT 0.039 (0.307)	DT 0.001 (0.270)	loss 7.420 (6.958)	prob 2.031 (2.762)	GS 36.594 (32.498)	mem 74.396
Train: [73][660/1500]	BT 0.032 (0.308)	DT 0.000 (0.270)	loss 6.802 (6.928)	prob 3.080 (2.607)	GS 34.031 (32.500)	mem 74.397
Train: [73][670/1500]	BT 0.037 (0.317)	DT 0.001 (0.280)	loss 6.815 (6.899)	prob 2.497 (2.596)	GS 34.625 (33.365)	mem 74.397
Train: [73][680/1500]	BT 0.052 (0.314)	DT 0.014 (0.276)	loss 6.786 (6.910)	prob 3.071 (2.554)	GS 33.906 (32.687)	mem 74.395
Train: [73][690/1500]	BT 0.036 (0.313)	DT 0.000 (0.275)	loss 6.953 (6.898)	prob 2.745 (2.570)	GS 34.547 (33.127)	mem 74.394
Train: [73][700/1500]	BT 0.028 (0.311)	DT 0.000 (0.273)	loss 6.849 (6.883)	prob 2.408 (2.550)	GS 34.484 (33.013)	mem 74.401
Train: [73][710/1500]	BT 0.037 (0.308)	DT 0.001 (0.271)	loss 7.054 (6.897)	prob 2.805 (2.929)	GS 33.594 (32.327)	mem 74.403
Train: [73][720/1500]	BT 0.038 (0.307)	DT 0.001 (0.269)	loss 6.731 (6.868)	prob 2.366 (2.818)	GS 36.812 (32.347)	mem 74.415
Train: [73][730/1500]	BT 0.038 (0.305)	DT 0.001 (0.267)	loss 6.841 (6.880)	prob 3.138 (2.745)	GS 34.688 (32.433)	mem 74.414
Train: [73][740/1500]	BT 2.346 (0.305)	DT 2.314 (0.267)	loss 6.750 (6.891)	prob 2.713 (2.698)	GS 34.797 (32.531)	mem 74.389
Train: [73][750/1500]	BT 0.030 (0.301)	DT 0.000 (0.263)	loss 6.623 (6.872)	prob 2.969 (2.769)	GS 34.594 (32.675)	mem 74.409
Train: [73][760/1500]	BT 0.037 (0.301)	DT 0.001 (0.263)	loss 6.789 (6.787)	prob 2.139 (2.423)	GS 33.438 (33.130)	mem 74.318
Train: [73][770/1500]	BT 0.027 (0.300)	DT 0.000 (0.262)	loss 6.765 (6.745)	prob 3.056 (2.702)	GS 30.188 (32.502)	mem 74.317
Train: [73][780/1500]	BT 0.037 (0.296)	DT 0.000 (0.259)	loss 6.782 (6.770)	prob 2.779 (2.648)	GS 32.781 (32.166)	mem 74.318
Train: [73][790/1500]	BT 0.037 (0.297)	DT 0.001 (0.260)	loss 7.039 (6.788)	prob 1.991 (2.601)	GS 36.297 (32.236)	mem 74.320
Train: [73][800/1500]	BT 0.037 (0.295)	DT 0.001 (0.257)	loss 6.807 (6.808)	prob 2.379 (2.562)	GS 28.406 (32.261)	mem 74.320
Train: [73][810/1500]	BT 0.038 (0.294)	DT 0.001 (0.257)	loss 6.472 (6.760)	prob 2.897 (2.962)	GS 32.203 (33.570)	mem 74.319
Train: [73][820/1500]	BT 0.036 (0.294)	DT 0.001 (0.257)	loss 6.784 (6.828)	prob 2.392 (2.725)	GS 31.672 (32.780)	mem 74.319
Train: [73][830/1500]	BT 0.322 (0.292)	DT 0.268 (0.254)	loss 6.644 (6.813)	prob 2.957 (2.669)	GS 33.781 (32.590)	mem 74.321
Train: [73][840/1500]	BT 0.037 (0.293)	DT 0.001 (0.255)	loss 6.765 (6.818)	prob 3.069 (2.630)	GS 31.250 (32.840)	mem 74.324
Train: [73][850/1500]	BT 0.028 (0.292)	DT 0.000 (0.254)	loss 6.723 (6.818)	prob 2.146 (2.631)	GS 36.047 (32.837)	mem 74.347
Train: [73][860/1500]	BT 0.033 (0.291)	DT 0.001 (0.254)	loss 6.863 (6.921)	prob 2.311 (2.042)	GS 32.359 (32.150)	mem 74.349
Train: [73][870/1500]	BT 0.038 (0.290)	DT 0.001 (0.252)	loss 6.684 (6.864)	prob 2.580 (2.395)	GS 33.000 (32.577)	mem 74.348
Train: [73][880/1500]	BT 0.038 (0.290)	DT 0.000 (0.253)	loss 6.928 (6.834)	prob 2.460 (2.416)	GS 33.594 (32.886)	mem 74.348
Train: [73][890/1500]	BT 0.038 (0.289)	DT 0.001 (0.252)	loss 6.886 (6.829)	prob 1.941 (2.425)	GS 37.031 (33.016)	mem 74.349
Train: [73][900/1500]	BT 0.095 (0.287)	DT 0.008 (0.249)	loss 6.558 (6.824)	prob 3.037 (2.473)	GS 34.219 (32.742)	mem 74.335
Train: [73][910/1500]	BT 0.040 (0.287)	DT 0.001 (0.249)	loss 6.924 (6.758)	prob 2.457 (2.758)	GS 34.375 (32.478)	mem 74.334
Train: [73][920/1500]	BT 0.038 (0.286)	DT 0.001 (0.248)	loss 6.617 (6.748)	prob 2.261 (2.479)	GS 29.406 (32.652)	mem 74.335
Train: [73][930/1500]	BT 0.033 (0.290)	DT 0.001 (0.253)	loss 6.796 (6.769)	prob 2.459 (2.454)	GS 31.266 (32.517)	mem 74.336
Train: [73][940/1500]	BT 0.029 (0.287)	DT 0.000 (0.250)	loss 6.822 (6.760)	prob 2.768 (2.510)	GS 31.453 (32.364)	mem 74.336
Train: [73][950/1500]	BT 0.039 (0.285)	DT 0.001 (0.247)	loss 6.843 (6.751)	prob 1.949 (2.511)	GS 28.344 (32.279)	mem 74.338
Train: [73][960/1500]	BT 0.039 (0.287)	DT 0.001 (0.249)	loss 6.785 (6.750)	prob 1.630 (2.546)	GS 32.953 (32.061)	mem 74.338
Train: [73][970/1500]	BT 0.039 (0.284)	DT 0.001 (0.247)	loss 6.648 (6.760)	prob 2.691 (2.592)	GS 33.250 (32.564)	mem 74.341
Train: [73][980/1500]	BT 0.038 (0.284)	DT 0.001 (0.247)	loss 6.761 (6.762)	prob 2.439 (2.598)	GS 35.875 (32.576)	mem 74.353
Train: [73][990/1500]	BT 0.037 (0.282)	DT 0.001 (0.244)	loss 6.803 (6.760)	prob 2.038 (2.562)	GS 32.531 (32.685)	mem 74.353
Train: [73][1000/1500]	BT 0.037 (0.282)	DT 0.001 (0.245)	loss 6.783 (6.766)	prob 2.200 (2.512)	GS 33.719 (32.722)	mem 74.357
Train: [73][1010/1500]	BT 0.037 (0.281)	DT 0.001 (0.244)	loss 6.594 (6.745)	prob 2.534 (2.422)	GS 33.719 (33.983)	mem 74.358
Train: [73][1020/1500]	BT 0.037 (0.279)	DT 0.000 (0.241)	loss 6.673 (6.786)	prob 3.023 (2.546)	GS 32.359 (32.562)	mem 74.359
Train: [73][1030/1500]	BT 0.058 (0.280)	DT 0.006 (0.243)	loss 6.709 (6.776)	prob 2.405 (2.476)	GS 29.234 (31.796)	mem 74.359
Train: [73][1040/1500]	BT 0.037 (0.282)	DT 0.000 (0.245)	loss 6.929 (6.796)	prob 2.016 (2.416)	GS 29.562 (31.949)	mem 74.361
Train: [73][1050/1500]	BT 0.037 (0.280)	DT 0.001 (0.243)	loss 6.921 (6.786)	prob 2.587 (2.444)	GS 36.781 (32.317)	mem 74.362
Train: [73][1060/1500]	BT 0.037 (0.281)	DT 0.001 (0.243)	loss 6.798 (6.768)	prob 2.030 (2.568)	GS 35.891 (30.938)	mem 74.361
Train: [73][1070/1500]	BT 0.037 (0.279)	DT 0.001 (0.241)	loss 6.585 (6.741)	prob 2.321 (2.449)	GS 35.547 (32.152)	mem 74.361
Train: [73][1080/1500]	BT 0.038 (0.279)	DT 0.001 (0.242)	loss 6.700 (6.747)	prob 2.493 (2.466)	GS 33.562 (32.420)	mem 74.363
Train: [73][1090/1500]	BT 1.297 (0.278)	DT 1.260 (0.241)	loss 6.888 (6.753)	prob 2.196 (2.442)	GS 37.266 (32.930)	mem 74.362
Train: [73][1100/1500]	BT 0.038 (0.277)	DT 0.001 (0.239)	loss 6.842 (6.755)	prob 2.685 (2.428)	GS 34.344 (32.729)	mem 74.362
Train: [73][1110/1500]	BT 0.027 (0.278)	DT 0.000 (0.241)	loss 6.516 (6.733)	prob 2.605 (2.468)	GS 38.531 (33.680)	mem 74.366
Train: [73][1120/1500]	BT 0.038 (0.276)	DT 0.000 (0.238)	loss 6.797 (6.729)	prob 2.416 (2.468)	GS 34.672 (33.512)	mem 74.367
Train: [73][1130/1500]	BT 0.034 (0.277)	DT 0.001 (0.240)	loss 6.769 (6.722)	prob 2.183 (2.354)	GS 33.641 (33.392)	mem 74.369
Train: [73][1140/1500]	BT 0.038 (0.275)	DT 0.001 (0.238)	loss 6.739 (6.720)	prob 2.710 (2.380)	GS 36.391 (33.179)	mem 74.370
Train: [73][1150/1500]	BT 0.035 (0.277)	DT 0.000 (0.240)	loss 6.627 (6.711)	prob 2.419 (2.355)	GS 35.875 (33.040)	mem 74.371
Train: [73][1160/1500]	BT 0.037 (0.275)	DT 0.000 (0.238)	loss 6.692 (6.754)	prob 1.927 (2.308)	GS 32.797 (32.803)	mem 74.373
Train: [73][1170/1500]	BT 0.036 (0.273)	DT 0.001 (0.236)	loss 6.712 (6.752)	prob 1.999 (2.313)	GS 29.594 (32.216)	mem 74.373
Train: [73][1180/1500]	BT 0.035 (0.278)	DT 0.001 (0.240)	loss 6.765 (6.734)	prob 2.230 (2.445)	GS 36.609 (32.877)	mem 74.371
Train: [73][1190/1500]	BT 0.033 (0.275)	DT 0.001 (0.238)	loss 6.629 (6.734)	prob 2.784 (2.478)	GS 38.656 (33.025)	mem 74.373
Train: [73][1200/1500]	BT 0.037 (0.276)	DT 0.001 (0.239)	loss 6.787 (6.744)	prob 2.293 (2.460)	GS 35.125 (32.843)	mem 74.375
Train: [73][1210/1500]	BT 0.038 (0.274)	DT 0.001 (0.237)	loss 6.791 (6.726)	prob 2.421 (2.016)	GS 35.438 (32.603)	mem 74.377
Train: [73][1220/1500]	BT 0.038 (0.272)	DT 0.001 (0.235)	loss 6.749 (6.681)	prob 2.141 (2.174)	GS 36.594 (33.688)	mem 74.376
Train: [73][1230/1500]	BT 0.028 (0.273)	DT 0.000 (0.236)	loss 6.901 (6.706)	prob 2.605 (2.188)	GS 36.047 (33.214)	mem 74.376
Train: [73][1240/1500]	BT 0.030 (0.272)	DT 0.001 (0.235)	loss 6.642 (6.691)	prob 2.623 (2.255)	GS 34.375 (33.024)	mem 74.377
Train: [73][1250/1500]	BT 0.027 (0.274)	DT 0.000 (0.237)	loss 6.932 (6.711)	prob 3.605 (2.296)	GS 31.328 (33.009)	mem 74.380
Train: [73][1260/1500]	BT 0.027 (0.272)	DT 0.000 (0.235)	loss 6.826 (6.759)	prob 2.596 (2.567)	GS 32.875 (31.570)	mem 74.383
Train: [73][1270/1500]	BT 0.040 (0.273)	DT 0.001 (0.236)	loss 6.788 (6.752)	prob 1.891 (2.554)	GS 31.062 (32.193)	mem 74.412
Train: [73][1280/1500]	BT 0.033 (0.271)	DT 0.000 (0.234)	loss 6.889 (6.745)	prob 2.034 (2.502)	GS 29.781 (32.345)	mem 74.414
Train: [73][1290/1500]	BT 0.030 (0.269)	DT 0.000 (0.232)	loss 6.796 (6.745)	prob 2.183 (2.521)	GS 35.766 (32.701)	mem 74.413
Train: [73][1300/1500]	BT 0.074 (0.272)	DT 0.009 (0.235)	loss 6.726 (6.754)	prob 2.538 (2.487)	GS 34.953 (32.748)	mem 74.411
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [73][1310/1500]	BT 0.067 (0.270)	DT 0.011 (0.233)	loss 6.730 (6.724)	prob 2.158 (2.392)	GS 29.844 (32.622)	mem 74.413
Train: [73][1320/1500]	BT 0.052 (0.272)	DT 0.014 (0.235)	loss 6.762 (6.756)	prob 2.589 (2.491)	GS 35.234 (32.382)	mem 74.413
Train: [73][1330/1500]	BT 0.067 (0.270)	DT 0.001 (0.233)	loss 6.770 (6.755)	prob 2.407 (2.589)	GS 32.438 (32.403)	mem 74.413
Train: [73][1340/1500]	BT 0.035 (0.269)	DT 0.000 (0.232)	loss 6.790 (6.731)	prob 2.333 (2.597)	GS 37.172 (32.341)	mem 74.414
Train: [73][1350/1500]	BT 0.062 (0.272)	DT 0.006 (0.235)	loss 6.765 (6.733)	prob 2.415 (2.587)	GS 36.969 (32.389)	mem 74.414
Train: [73][1360/1500]	BT 0.069 (0.272)	DT 0.006 (0.234)	loss 6.701 (6.730)	prob 2.136 (2.492)	GS 35.438 (35.175)	mem 74.413
Train: [73][1370/1500]	BT 0.031 (0.271)	DT 0.000 (0.234)	loss 6.727 (6.732)	prob 2.975 (2.476)	GS 32.141 (34.055)	mem 74.415
Train: [73][1380/1500]	BT 0.057 (0.273)	DT 0.015 (0.236)	loss 6.592 (6.723)	prob 2.569 (2.508)	GS 32.688 (33.329)	mem 74.414
Train: [73][1390/1500]	BT 0.031 (0.272)	DT 0.000 (0.235)	loss 6.586 (6.716)	prob 2.845 (2.521)	GS 32.141 (32.872)	mem 74.413
Train: [73][1400/1500]	BT 0.030 (0.282)	DT 0.000 (0.245)	loss 6.661 (6.713)	prob 2.462 (2.481)	GS 34.641 (32.880)	mem 74.409
Train: [73][1410/1500]	BT 0.037 (0.280)	DT 0.000 (0.243)	loss 6.848 (6.702)	prob 2.889 (2.750)	GS 36.938 (31.897)	mem 74.410
Train: [73][1420/1500]	BT 0.025 (0.281)	DT 0.000 (0.244)	loss 6.721 (6.710)	prob 2.499 (2.590)	GS 35.438 (33.138)	mem 74.411
Train: [73][1430/1500]	BT 0.042 (0.280)	DT 0.001 (0.243)	loss 6.635 (6.705)	prob 2.262 (2.610)	GS 33.625 (32.585)	mem 74.412
Train: [73][1440/1500]	BT 0.039 (0.280)	DT 0.001 (0.243)	loss 6.872 (6.699)	prob 2.097 (2.638)	GS 31.781 (32.452)	mem 74.412
Train: [73][1450/1500]	BT 0.042 (0.278)	DT 0.001 (0.241)	loss 6.732 (6.710)	prob 2.701 (2.613)	GS 32.281 (32.637)	mem 74.413
Train: [73][1460/1500]	BT 0.034 (0.277)	DT 0.000 (0.240)	loss 6.613 (6.762)	prob 3.387 (2.645)	GS 32.906 (32.194)	mem 74.412
Train: [73][1470/1500]	BT 0.030 (0.277)	DT 0.000 (0.240)	loss 6.670 (6.723)	prob 3.407 (2.687)	GS 33.719 (31.962)	mem 73.793
Train: [73][1480/1500]	BT 0.029 (0.275)	DT 0.000 (0.238)	loss 6.579 (6.714)	prob 2.415 (2.643)	GS 37.250 (31.842)	mem 73.501
Train: [73][1490/1500]	BT 0.041 (0.276)	DT 0.000 (0.239)	loss 6.578 (6.696)	prob 1.766 (2.588)	GS 33.469 (31.746)	mem 9.395
Train: [73][1500/1500]	BT 0.036 (0.274)	DT 0.000 (0.237)	loss 6.570 (6.687)	prob 1.947 (2.607)	GS 36.938 (31.993)	mem 9.395
Train: [73][1510/1500]	BT 0.034 (0.272)	DT 0.000 (0.235)	loss 6.308 (6.426)	prob 2.915 (2.857)	GS 33.500 (31.294)	mem 9.395
epoch 73, total time 412.29
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [74][1/1500]	BT 23.578 (23.578)	DT 23.526 (23.526)	loss 6.353 (6.353)	prob 3.205 (3.205)	GS 30.766 (30.766)	mem 73.167
Train: [74][10/1500]	BT 0.058 (2.501)	DT 0.014 (2.449)	loss 6.533 (6.455)	prob 2.498 (2.835)	GS 33.938 (33.300)	mem 73.177
Train: [74][20/1500]	BT 0.056 (1.287)	DT 0.002 (1.238)	loss 6.415 (6.465)	prob 2.560 (2.773)	GS 30.312 (32.710)	mem 73.184
Train: [74][30/1500]	BT 0.081 (1.206)	DT 0.002 (1.150)	loss 6.737 (6.507)	prob 2.131 (2.697)	GS 30.906 (32.616)	mem 73.230
Train: [74][40/1500]	BT 0.028 (1.427)	DT 0.000 (1.376)	loss 6.642 (6.544)	prob 2.627 (2.635)	GS 32.719 (32.464)	mem 73.249
Train: [74][50/1500]	BT 0.026 (1.147)	DT 0.000 (1.101)	loss 6.542 (6.550)	prob 3.232 (2.674)	GS 33.297 (32.361)	mem 73.248
Train: [74][60/1500]	BT 0.035 (1.098)	DT 0.003 (1.052)	loss 6.687 (6.632)	prob 2.659 (2.747)	GS 36.469 (33.572)	mem 73.271
Train: [74][70/1500]	BT 0.059 (0.947)	DT 0.013 (0.903)	loss 6.718 (6.637)	prob 2.528 (2.655)	GS 34.562 (33.459)	mem 73.272
Train: [74][80/1500]	BT 0.091 (0.877)	DT 0.001 (0.831)	loss 6.693 (6.659)	prob 2.872 (2.639)	GS 33.250 (33.269)	mem 73.280
Train: [74][90/1500]	BT 0.028 (0.940)	DT 0.000 (0.895)	loss 6.575 (6.653)	prob 3.097 (2.678)	GS 29.906 (33.353)	mem 73.314
Train: [74][100/1500]	BT 0.042 (0.849)	DT 0.000 (0.806)	loss 6.762 (6.665)	prob 3.439 (2.660)	GS 37.453 (33.381)	mem 73.176
Train: [74][110/1500]	BT 0.030 (0.810)	DT 0.000 (0.768)	loss 6.643 (6.668)	prob 2.757 (2.894)	GS 38.469 (32.997)	mem 73.203
Train: [74][120/1500]	BT 0.027 (0.745)	DT 0.000 (0.704)	loss 6.981 (6.712)	prob 1.973 (2.748)	GS 34.234 (34.078)	mem 73.203
Train: [74][130/1500]	BT 0.038 (0.691)	DT 0.001 (0.650)	loss 6.813 (6.711)	prob 2.123 (2.765)	GS 31.844 (33.982)	mem 73.203
Train: [74][140/1500]	BT 0.030 (0.693)	DT 0.000 (0.653)	loss 6.982 (6.728)	prob 2.511 (2.833)	GS 32.656 (33.540)	mem 73.206
Train: [74][150/1500]	BT 0.032 (0.649)	DT 0.000 (0.610)	loss 6.702 (6.720)	prob 2.432 (2.802)	GS 31.156 (33.229)	mem 73.206
Train: [74][160/1500]	BT 0.029 (0.638)	DT 0.001 (0.599)	loss 6.770 (6.687)	prob 1.815 (2.543)	GS 36.062 (33.308)	mem 73.211
Train: [74][170/1500]	BT 0.030 (0.602)	DT 0.000 (0.564)	loss 6.740 (6.664)	prob 1.815 (2.658)	GS 34.406 (33.256)	mem 73.211
Train: [74][180/1500]	BT 4.192 (0.594)	DT 4.158 (0.556)	loss 6.889 (6.667)	prob 2.204 (2.581)	GS 29.875 (33.078)	mem 73.234
Train: [74][190/1500]	BT 0.026 (0.564)	DT 0.000 (0.526)	loss 6.565 (6.673)	prob 3.581 (2.644)	GS 36.500 (33.229)	mem 73.236
Train: [74][200/1500]	BT 0.031 (0.537)	DT 0.000 (0.500)	loss 6.779 (6.682)	prob 2.264 (2.661)	GS 31.359 (32.977)	mem 73.237
Train: [74][210/1500]	BT 0.038 (0.527)	DT 0.001 (0.490)	loss 6.801 (6.724)	prob 2.684 (2.525)	GS 34.625 (33.252)	mem 73.237
Train: [74][220/1500]	BT 0.039 (0.505)	DT 0.001 (0.468)	loss 6.827 (6.694)	prob 2.635 (2.553)	GS 39.266 (32.695)	mem 73.238
Train: [74][230/1500]	BT 0.038 (0.496)	DT 0.001 (0.459)	loss 6.802 (6.680)	prob 2.317 (2.585)	GS 32.766 (32.618)	mem 73.288
Train: [74][240/1500]	BT 0.039 (0.477)	DT 0.001 (0.440)	loss 6.634 (6.677)	prob 1.872 (2.542)	GS 33.781 (32.520)	mem 73.288
Train: [74][250/1500]	BT 0.039 (0.459)	DT 0.001 (0.422)	loss 6.661 (6.688)	prob 2.599 (2.509)	GS 35.891 (32.612)	mem 73.289
Train: [74][260/1500]	BT 0.039 (0.461)	DT 0.001 (0.424)	loss 6.693 (6.687)	prob 1.558 (2.355)	GS 36.594 (31.761)	mem 73.423
Train: [74][270/1500]	BT 0.030 (0.445)	DT 0.000 (0.408)	loss 6.593 (6.663)	prob 2.342 (2.344)	GS 32.609 (32.521)	mem 73.423
Train: [74][280/1500]	BT 0.038 (0.447)	DT 0.001 (0.410)	loss 6.753 (6.683)	prob 2.636 (2.396)	GS 31.297 (32.012)	mem 74.270
Train: [74][290/1500]	BT 0.039 (0.433)	DT 0.001 (0.396)	loss 6.814 (6.680)	prob 1.534 (2.424)	GS 34.859 (31.914)	mem 74.328
Train: [74][300/1500]	BT 2.906 (0.430)	DT 2.868 (0.392)	loss 6.658 (6.685)	prob 2.447 (2.460)	GS 30.531 (31.958)	mem 74.410
Train: [74][310/1500]	BT 0.037 (0.417)	DT 0.001 (0.380)	loss 6.692 (6.617)	prob 2.695 (2.657)	GS 31.641 (31.867)	mem 74.420
Train: [74][320/1500]	BT 0.058 (0.405)	DT 0.021 (0.368)	loss 6.704 (6.630)	prob 2.215 (2.536)	GS 34.578 (32.372)	mem 74.423
Train: [74][330/1500]	BT 0.037 (0.402)	DT 0.001 (0.365)	loss 6.845 (6.657)	prob 2.187 (2.601)	GS 34.391 (32.080)	mem 74.427
Train: [74][340/1500]	BT 0.037 (0.397)	DT 0.000 (0.360)	loss 6.676 (6.661)	prob 2.239 (2.554)	GS 34.281 (32.315)	mem 74.430
Train: [74][350/1500]	BT 1.193 (0.394)	DT 1.160 (0.357)	loss 6.633 (6.670)	prob 1.560 (2.497)	GS 32.828 (32.399)	mem 74.432
Train: [74][360/1500]	BT 0.033 (0.385)	DT 0.001 (0.348)	loss 6.762 (6.674)	prob 2.112 (2.208)	GS 31.062 (31.208)	mem 74.435
Train: [74][370/1500]	BT 0.034 (0.378)	DT 0.000 (0.341)	loss 6.756 (6.673)	prob 2.509 (2.010)	GS 33.562 (31.872)	mem 74.436
Train: [74][380/1500]	BT 0.025 (0.376)	DT 0.000 (0.339)	loss 7.018 (6.671)	prob 1.889 (2.115)	GS 32.453 (32.018)	mem 74.438
Train: [74][390/1500]	BT 0.037 (0.370)	DT 0.001 (0.334)	loss 6.664 (6.674)	prob 2.649 (2.136)	GS 34.906 (32.333)	mem 74.441
Train: [74][400/1500]	BT 0.038 (0.370)	DT 0.001 (0.333)	loss 6.636 (6.675)	prob 2.413 (2.219)	GS 32.719 (32.164)	mem 74.446
Train: [74][410/1500]	BT 0.037 (0.367)	DT 0.000 (0.331)	loss 6.732 (6.638)	prob 2.010 (2.385)	GS 29.969 (33.906)	mem 74.447
Train: [74][420/1500]	BT 0.047 (0.359)	DT 0.010 (0.323)	loss 6.603 (6.630)	prob 2.328 (2.269)	GS 32.109 (32.736)	mem 74.447
Train: [74][430/1500]	BT 0.037 (0.356)	DT 0.000 (0.319)	loss 6.609 (6.650)	prob 2.312 (2.293)	GS 30.047 (32.177)	mem 74.451
Train: [74][440/1500]	BT 0.037 (0.354)	DT 0.001 (0.318)	loss 6.709 (6.660)	prob 1.877 (2.303)	GS 31.594 (32.320)	mem 74.452
Train: [74][450/1500]	BT 0.037 (0.348)	DT 0.000 (0.311)	loss 6.671 (6.663)	prob 2.768 (2.304)	GS 29.047 (32.518)	mem 74.454
Train: [74][460/1500]	BT 0.031 (0.356)	DT 0.000 (0.319)	loss 6.702 (6.657)	prob 2.079 (2.381)	GS 32.766 (31.269)	mem 74.455
Train: [74][470/1500]	BT 0.033 (0.372)	DT 0.000 (0.335)	loss 6.713 (6.697)	prob 2.082 (2.376)	GS 28.938 (31.887)	mem 74.456
Train: [74][480/1500]	BT 0.028 (0.365)	DT 0.000 (0.328)	loss 6.727 (6.702)	prob 2.424 (2.464)	GS 36.938 (31.755)	mem 74.458
Train: [74][490/1500]	BT 0.036 (0.358)	DT 0.000 (0.321)	loss 6.806 (6.697)	prob 2.400 (2.454)	GS 34.578 (31.972)	mem 74.459
Train: [74][500/1500]	BT 0.029 (0.368)	DT 0.000 (0.332)	loss 6.815 (6.707)	prob 2.405 (2.443)	GS 34.031 (32.377)	mem 74.463
Train: [74][510/1500]	BT 0.027 (0.361)	DT 0.000 (0.325)	loss 6.623 (6.704)	prob 2.793 (2.620)	GS 32.438 (31.761)	mem 74.463
Train: [74][520/1500]	BT 0.030 (0.363)	DT 0.000 (0.327)	loss 6.541 (6.705)	prob 3.030 (2.554)	GS 33.094 (32.082)	mem 74.467
Train: [74][530/1500]	BT 0.067 (0.357)	DT 0.002 (0.321)	loss 6.816 (6.714)	prob 2.444 (2.603)	GS 29.750 (32.336)	mem 74.465
Train: [74][540/1500]	BT 0.042 (0.352)	DT 0.000 (0.315)	loss 6.746 (6.717)	prob 1.915 (2.545)	GS 32.750 (32.425)	mem 74.466
Train: [74][550/1500]	BT 0.032 (0.369)	DT 0.000 (0.332)	loss 6.886 (6.727)	prob 2.697 (2.516)	GS 31.906 (32.663)	mem 74.468
Train: [74][560/1500]	BT 0.029 (0.363)	DT 0.000 (0.326)	loss 6.773 (6.727)	prob 2.622 (2.573)	GS 32.547 (31.300)	mem 74.469
Train: [74][570/1500]	BT 0.036 (0.357)	DT 0.001 (0.321)	loss 6.564 (6.744)	prob 3.181 (2.725)	GS 36.953 (32.366)	mem 74.471
Train: [74][580/1500]	BT 0.046 (0.359)	DT 0.013 (0.322)	loss 6.733 (6.744)	prob 1.776 (2.709)	GS 35.859 (32.285)	mem 74.472
Train: [74][590/1500]	BT 0.073 (0.354)	DT 0.006 (0.317)	loss 6.723 (6.750)	prob 2.863 (2.779)	GS 37.734 (32.871)	mem 74.472
Train: [74][600/1500]	BT 0.026 (0.358)	DT 0.000 (0.321)	loss 6.814 (6.750)	prob 2.308 (2.701)	GS 31.281 (32.777)	mem 74.473
Train: [74][610/1500]	BT 0.032 (0.353)	DT 0.000 (0.316)	loss 6.674 (6.740)	prob 3.402 (3.030)	GS 36.344 (33.353)	mem 74.474
Train: [74][620/1500]	BT 2.794 (0.352)	DT 2.756 (0.315)	loss 6.737 (6.735)	prob 2.351 (2.785)	GS 31.188 (32.703)	mem 74.508
Train: [74][630/1500]	BT 0.039 (0.347)	DT 0.001 (0.310)	loss 6.942 (6.753)	prob 2.312 (2.643)	GS 33.328 (32.158)	mem 74.508
Train: [74][640/1500]	BT 0.039 (0.342)	DT 0.001 (0.305)	loss 6.791 (6.753)	prob 2.564 (2.657)	GS 34.000 (32.020)	mem 74.509
Train: [74][650/1500]	BT 0.071 (0.346)	DT 0.003 (0.309)	loss 6.794 (6.758)	prob 2.874 (2.673)	GS 36.312 (32.056)	mem 74.512
Train: [74][660/1500]	BT 0.078 (0.342)	DT 0.001 (0.305)	loss 6.679 (6.692)	prob 2.725 (2.680)	GS 34.562 (32.820)	mem 74.512
Train: [74][670/1500]	BT 0.085 (0.357)	DT 0.009 (0.318)	loss 6.829 (6.714)	prob 2.309 (2.713)	GS 35.688 (32.277)	mem 74.511
Train: [74][680/1500]	BT 0.047 (0.387)	DT 0.001 (0.348)	loss 6.746 (6.708)	prob 2.540 (2.652)	GS 36.641 (32.970)	mem 74.510
Train: [74][690/1500]	BT 0.027 (0.381)	DT 0.000 (0.343)	loss 6.808 (6.716)	prob 1.946 (2.590)	GS 32.688 (32.661)	mem 74.511
Train: [74][700/1500]	BT 0.039 (0.381)	DT 0.001 (0.343)	loss 6.831 (6.713)	prob 2.394 (2.563)	GS 30.594 (32.706)	mem 74.512
Train: [74][710/1500]	BT 0.038 (0.376)	DT 0.001 (0.338)	loss 6.630 (6.686)	prob 2.516 (2.382)	GS 32.297 (30.620)	mem 74.511
Train: [74][720/1500]	BT 0.039 (0.371)	DT 0.000 (0.333)	loss 6.895 (6.716)	prob 1.753 (2.378)	GS 32.359 (31.202)	mem 74.513
Train: [74][730/1500]	BT 0.030 (0.373)	DT 0.000 (0.335)	loss 6.552 (6.703)	prob 3.033 (2.430)	GS 26.156 (31.387)	mem 74.510
Train: [74][740/1500]	BT 0.039 (0.369)	DT 0.001 (0.331)	loss 6.728 (6.693)	prob 1.806 (2.441)	GS 35.156 (31.580)	mem 74.511
Train: [74][750/1500]	BT 0.056 (0.371)	DT 0.002 (0.333)	loss 6.840 (6.693)	prob 2.621 (2.427)	GS 35.625 (31.692)	mem 74.512
Train: [74][760/1500]	BT 0.110 (0.367)	DT 0.001 (0.329)	loss 6.680 (6.615)	prob 2.590 (2.273)	GS 36.828 (32.839)	mem 74.512
Train: [74][770/1500]	BT 1.367 (0.374)	DT 1.329 (0.335)	loss 6.514 (6.603)	prob 2.421 (2.241)	GS 30.750 (32.962)	mem 74.513
Train: [74][780/1500]	BT 0.039 (0.369)	DT 0.000 (0.331)	loss 6.894 (6.643)	prob 2.234 (2.145)	GS 35.359 (32.947)	mem 74.514
Train: [74][790/1500]	BT 0.038 (0.370)	DT 0.001 (0.331)	loss 6.644 (6.644)	prob 2.257 (2.224)	GS 32.938 (32.773)	mem 74.514
Train: [74][800/1500]	BT 0.029 (0.366)	DT 0.000 (0.327)	loss 6.718 (6.647)	prob 2.658 (2.227)	GS 32.609 (32.609)	mem 74.514
Train: [74][810/1500]	BT 0.039 (0.362)	DT 0.001 (0.323)	loss 6.717 (6.725)	prob 2.355 (2.272)	GS 37.156 (33.633)	mem 74.517
Train: [74][820/1500]	BT 0.040 (0.361)	DT 0.001 (0.323)	loss 6.574 (6.669)	prob 2.606 (2.442)	GS 35.984 (33.789)	mem 74.516
Train: [74][830/1500]	BT 0.039 (0.358)	DT 0.001 (0.319)	loss 6.613 (6.648)	prob 2.504 (2.487)	GS 34.281 (33.122)	mem 74.516
Train: [74][840/1500]	BT 0.064 (0.363)	DT 0.010 (0.324)	loss 6.720 (6.645)	prob 2.865 (2.520)	GS 32.984 (32.781)	mem 74.515
Train: [74][850/1500]	BT 0.035 (0.359)	DT 0.000 (0.320)	loss 6.555 (6.633)	prob 2.362 (2.495)	GS 36.438 (33.136)	mem 74.515
Train: [74][860/1500]	BT 0.040 (0.355)	DT 0.001 (0.316)	loss 6.520 (6.631)	prob 2.672 (2.739)	GS 37.750 (33.244)	mem 74.517
Train: [74][870/1500]	BT 0.030 (0.359)	DT 0.000 (0.321)	loss 6.766 (6.645)	prob 2.686 (2.592)	GS 36.047 (33.814)	mem 74.514
Train: [74][880/1500]	BT 0.037 (0.356)	DT 0.001 (0.317)	loss 6.477 (6.627)	prob 2.745 (2.583)	GS 36.328 (33.712)	mem 74.515
Train: [74][890/1500]	BT 0.075 (0.358)	DT 0.006 (0.319)	loss 6.794 (6.627)	prob 2.754 (2.605)	GS 34.906 (34.100)	mem 74.522
Train: [74][900/1500]	BT 0.067 (0.354)	DT 0.006 (0.315)	loss 6.737 (6.619)	prob 2.345 (2.633)	GS 35.750 (33.798)	mem 74.523
Train: [74][910/1500]	BT 0.037 (0.352)	DT 0.000 (0.313)	loss 6.570 (6.583)	prob 2.532 (2.600)	GS 37.141 (32.644)	mem 74.525
Train: [74][920/1500]	BT 0.037 (0.352)	DT 0.001 (0.313)	loss 6.727 (6.606)	prob 2.949 (2.639)	GS 34.188 (32.823)	mem 74.533
Train: [74][930/1500]	BT 0.037 (0.349)	DT 0.001 (0.310)	loss 6.522 (6.603)	prob 1.988 (2.636)	GS 30.219 (32.546)	mem 74.533
Train: [74][940/1500]	BT 0.071 (0.352)	DT 0.001 (0.313)	loss 6.769 (6.596)	prob 2.359 (2.598)	GS 35.344 (32.344)	mem 74.438
Train: [74][950/1500]	BT 0.074 (0.349)	DT 0.010 (0.309)	loss 6.793 (6.602)	prob 2.538 (2.565)	GS 33.062 (32.335)	mem 74.439
Train: [74][960/1500]	BT 0.060 (0.346)	DT 0.002 (0.306)	loss 6.546 (6.639)	prob 3.041 (3.014)	GS 33.203 (32.856)	mem 74.437
Train: [74][970/1500]	BT 0.046 (0.348)	DT 0.001 (0.309)	loss 6.733 (6.638)	prob 2.932 (2.941)	GS 31.703 (32.964)	mem 74.435
Train: [74][980/1500]	BT 0.061 (0.346)	DT 0.001 (0.306)	loss 6.553 (6.619)	prob 2.969 (3.035)	GS 35.609 (33.299)	mem 74.435
Train: [74][990/1500]	BT 0.048 (0.349)	DT 0.000 (0.310)	loss 6.441 (6.622)	prob 2.467 (2.969)	GS 37.281 (33.309)	mem 74.436
Train: [74][1000/1500]	BT 0.065 (0.356)	DT 0.000 (0.316)	loss 6.695 (6.625)	prob 2.637 (2.924)	GS 37.016 (33.216)	mem 74.437
Train: [74][1010/1500]	BT 0.101 (0.353)	DT 0.001 (0.313)	loss 6.589 (6.661)	prob 2.125 (2.927)	GS 30.359 (33.631)	mem 74.425
Train: [74][1020/1500]	BT 0.031 (0.350)	DT 0.000 (0.310)	loss 6.586 (6.662)	prob 2.667 (2.713)	GS 34.125 (32.942)	mem 74.424
Train: [74][1030/1500]	BT 0.038 (0.351)	DT 0.001 (0.311)	loss 6.586 (6.634)	prob 2.886 (2.714)	GS 32.469 (32.676)	mem 74.446
Train: [74][1040/1500]	BT 0.038 (0.348)	DT 0.001 (0.308)	loss 6.748 (6.654)	prob 2.332 (2.709)	GS 31.125 (32.991)	mem 74.446
Train: [74][1050/1500]	BT 0.037 (0.349)	DT 0.001 (0.310)	loss 6.511 (6.647)	prob 2.995 (2.742)	GS 31.609 (32.966)	mem 74.445
Train: [74][1060/1500]	BT 0.038 (0.346)	DT 0.001 (0.307)	loss 6.670 (6.693)	prob 2.476 (2.751)	GS 28.125 (32.288)	mem 74.447
Train: [74][1070/1500]	BT 0.039 (0.344)	DT 0.001 (0.304)	loss 6.706 (6.695)	prob 2.450 (2.641)	GS 32.688 (32.270)	mem 74.446
Train: [74][1080/1500]	BT 0.038 (0.345)	DT 0.001 (0.305)	loss 6.569 (6.692)	prob 3.412 (2.640)	GS 33.922 (32.342)	mem 74.448
Train: [74][1090/1500]	BT 0.039 (0.342)	DT 0.001 (0.302)	loss 6.778 (6.685)	prob 2.283 (2.688)	GS 30.766 (32.383)	mem 74.448
Train: [74][1100/1500]	BT 0.039 (0.343)	DT 0.001 (0.303)	loss 6.669 (6.686)	prob 3.030 (2.700)	GS 32.094 (32.521)	mem 74.451
Train: [74][1110/1500]	BT 0.038 (0.340)	DT 0.001 (0.301)	loss 6.786 (6.676)	prob 2.776 (2.718)	GS 34.781 (32.575)	mem 74.451
Train: [74][1120/1500]	BT 0.038 (0.341)	DT 0.000 (0.301)	loss 6.712 (6.693)	prob 2.122 (2.698)	GS 32.234 (32.867)	mem 74.451
Train: [74][1130/1500]	BT 0.039 (0.338)	DT 0.001 (0.299)	loss 6.840 (6.710)	prob 2.828 (2.733)	GS 38.938 (33.194)	mem 74.451
Train: [74][1140/1500]	BT 0.039 (0.336)	DT 0.001 (0.296)	loss 6.626 (6.703)	prob 3.410 (2.748)	GS 34.156 (32.972)	mem 74.451
Train: [74][1150/1500]	BT 0.037 (0.336)	DT 0.001 (0.297)	loss 6.699 (6.704)	prob 2.342 (2.737)	GS 35.047 (32.764)	mem 74.464
Train: [74][1160/1500]	BT 0.037 (0.334)	DT 0.000 (0.294)	loss 6.747 (6.677)	prob 2.486 (2.662)	GS 33.188 (31.781)	mem 74.465
Train: [74][1170/1500]	BT 0.037 (0.335)	DT 0.001 (0.295)	loss 6.668 (6.677)	prob 2.878 (2.675)	GS 31.359 (32.126)	mem 74.469
Train: [74][1180/1500]	BT 0.037 (0.332)	DT 0.000 (0.293)	loss 6.523 (6.672)	prob 3.077 (2.703)	GS 36.109 (32.424)	mem 74.470
Train: [74][1190/1500]	BT 0.054 (0.330)	DT 0.000 (0.290)	loss 6.504 (6.667)	prob 1.834 (2.647)	GS 31.812 (32.622)	mem 74.471
Train: [74][1200/1500]	BT 0.035 (0.335)	DT 0.000 (0.296)	loss 6.657 (6.678)	prob 3.057 (2.635)	GS 36.719 (33.243)	mem 74.473
Train: [74][1210/1500]	BT 0.068 (0.333)	DT 0.016 (0.293)	loss 6.736 (6.706)	prob 2.205 (2.609)	GS 38.062 (34.580)	mem 74.473
Train: [74][1220/1500]	BT 0.058 (0.332)	DT 0.011 (0.293)	loss 6.564 (6.671)	prob 2.428 (2.474)	GS 30.297 (33.345)	mem 74.475
Train: [74][1230/1500]	BT 0.056 (0.334)	DT 0.000 (0.294)	loss 6.698 (6.704)	prob 2.539 (2.347)	GS 34.281 (33.080)	mem 74.476
Train: [74][1240/1500]	BT 0.046 (0.343)	DT 0.000 (0.304)	loss 6.720 (6.706)	prob 2.140 (2.425)	GS 37.719 (33.269)	mem 74.473
Train: [74][1250/1500]	BT 0.080 (0.341)	DT 0.014 (0.301)	loss 6.752 (6.706)	prob 2.246 (2.470)	GS 34.312 (33.132)	mem 74.473
Train: [74][1260/1500]	BT 0.038 (0.344)	DT 0.000 (0.304)	loss 6.673 (6.669)	prob 2.551 (2.680)	GS 37.141 (32.531)	mem 74.473
Train: [74][1270/1500]	BT 0.037 (0.342)	DT 0.000 (0.302)	loss 6.541 (6.674)	prob 2.715 (2.564)	GS 33.453 (32.888)	mem 74.472
Train: [74][1280/1500]	BT 0.048 (0.343)	DT 0.007 (0.303)	loss 6.835 (6.680)	prob 2.367 (2.498)	GS 32.391 (32.819)	mem 74.471
Train: [74][1290/1500]	BT 0.039 (0.343)	DT 0.009 (0.303)	loss 6.565 (6.686)	prob 2.995 (2.532)	GS 35.250 (33.206)	mem 74.474
Train: [74][1300/1500]	BT 0.033 (0.343)	DT 0.000 (0.303)	loss 6.516 (6.679)	prob 2.831 (2.502)	GS 31.906 (33.039)	mem 74.473
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [74][1310/1500]	BT 0.056 (0.345)	DT 0.003 (0.305)	loss 6.615 (6.599)	prob 2.178 (2.404)	GS 37.141 (33.230)	mem 74.475
Train: [74][1320/1500]	BT 0.060 (0.343)	DT 0.001 (0.303)	loss 6.566 (6.628)	prob 2.438 (2.272)	GS 35.047 (32.373)	mem 74.475
Train: [74][1330/1500]	BT 0.057 (0.341)	DT 0.002 (0.301)	loss 6.702 (6.621)	prob 2.331 (2.330)	GS 33.812 (32.362)	mem 74.474
Train: [74][1340/1500]	BT 0.037 (0.354)	DT 0.000 (0.314)	loss 6.673 (6.637)	prob 3.050 (2.455)	GS 33.906 (32.455)	mem 74.474
Train: [74][1350/1500]	BT 0.029 (0.352)	DT 0.000 (0.311)	loss 6.610 (6.635)	prob 2.100 (2.518)	GS 32.688 (32.452)	mem 74.475
Train: [74][1360/1500]	BT 7.384 (0.355)	DT 7.341 (0.315)	loss 6.535 (6.549)	prob 2.536 (2.803)	GS 35.266 (32.236)	mem 74.478
Train: [74][1370/1500]	BT 0.068 (0.352)	DT 0.005 (0.312)	loss 6.541 (6.575)	prob 2.828 (2.631)	GS 34.234 (32.095)	mem 74.481
Train: [74][1380/1500]	BT 0.045 (0.350)	DT 0.000 (0.310)	loss 6.662 (6.597)	prob 2.606 (2.654)	GS 35.188 (32.514)	mem 74.482
Train: [74][1390/1500]	BT 0.030 (0.356)	DT 0.000 (0.315)	loss 6.579 (6.605)	prob 2.486 (2.648)	GS 35.891 (32.763)	mem 74.479
Train: [74][1400/1500]	BT 0.030 (0.353)	DT 0.000 (0.313)	loss 6.573 (6.609)	prob 2.435 (2.675)	GS 36.359 (33.303)	mem 74.481
Train: [74][1410/1500]	BT 0.069 (0.355)	DT 0.006 (0.315)	loss 6.581 (6.579)	prob 2.636 (2.674)	GS 33.703 (32.508)	mem 74.482
Train: [74][1420/1500]	BT 0.029 (0.356)	DT 0.000 (0.316)	loss 6.713 (6.624)	prob 2.578 (2.635)	GS 31.531 (32.670)	mem 74.483
Train: [74][1430/1500]	BT 0.027 (0.354)	DT 0.000 (0.314)	loss 6.617 (6.614)	prob 2.751 (2.674)	GS 34.562 (32.728)	mem 74.483
Train: [74][1440/1500]	BT 0.038 (0.353)	DT 0.001 (0.313)	loss 6.606 (6.601)	prob 2.588 (2.707)	GS 28.625 (32.645)	mem 74.484
Train: [74][1450/1500]	BT 0.038 (0.351)	DT 0.001 (0.311)	loss 6.635 (6.616)	prob 3.270 (2.732)	GS 34.016 (32.734)	mem 74.485
Train: [74][1460/1500]	BT 0.035 (0.351)	DT 0.000 (0.311)	loss 6.644 (6.626)	prob 2.513 (2.719)	GS 36.203 (32.950)	mem 74.197
Train: [74][1470/1500]	BT 0.032 (0.349)	DT 0.001 (0.309)	loss 6.664 (6.646)	prob 2.684 (2.844)	GS 30.906 (32.703)	mem 73.831
Train: [74][1480/1500]	BT 1.460 (0.348)	DT 1.417 (0.308)	loss 6.688 (6.659)	prob 3.446 (2.770)	GS 33.891 (32.935)	mem 22.901
Train: [74][1490/1500]	BT 0.028 (0.346)	DT 0.000 (0.307)	loss 6.403 (6.646)	prob 3.261 (2.868)	GS 35.156 (32.483)	mem 20.694
Train: [74][1500/1500]	BT 0.027 (0.344)	DT 0.000 (0.305)	loss 6.443 (6.636)	prob 2.856 (2.869)	GS 29.406 (32.581)	mem 20.658
Train: [74][1510/1500]	BT 0.036 (0.343)	DT 0.000 (0.303)	loss 6.299 (6.452)	prob 2.671 (2.796)	GS 34.312 (34.647)	mem 9.288
epoch 74, total time 517.60
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [75][1/1500]	BT 19.001 (19.001)	DT 18.881 (18.881)	loss 6.239 (6.239)	prob 3.110 (3.110)	GS 31.453 (31.453)	mem 72.852
Train: [75][10/1500]	BT 0.036 (2.608)	DT 0.001 (2.563)	loss 6.568 (6.393)	prob 2.837 (3.005)	GS 32.906 (32.293)	mem 72.976
Train: [75][20/1500]	BT 0.067 (1.333)	DT 0.011 (1.287)	loss 6.539 (6.460)	prob 3.664 (3.085)	GS 33.188 (33.348)	mem 72.982
Train: [75][30/1500]	BT 0.037 (1.055)	DT 0.000 (1.010)	loss 6.713 (6.485)	prob 3.139 (3.077)	GS 30.562 (32.827)	mem 73.006
Train: [75][40/1500]	BT 0.038 (0.807)	DT 0.001 (0.764)	loss 6.561 (6.511)	prob 2.576 (3.048)	GS 34.109 (32.567)	mem 73.044
Train: [75][50/1500]	BT 1.605 (0.686)	DT 1.538 (0.642)	loss 6.746 (6.546)	prob 3.071 (3.049)	GS 32.547 (32.324)	mem 73.059
Train: [75][60/1500]	BT 0.037 (0.628)	DT 0.000 (0.585)	loss 6.690 (6.713)	prob 2.790 (2.840)	GS 33.188 (31.848)	mem 73.084
Train: [75][70/1500]	BT 0.038 (0.543)	DT 0.000 (0.501)	loss 6.630 (6.691)	prob 2.857 (2.916)	GS 34.844 (32.445)	mem 73.085
Train: [75][80/1500]	BT 0.035 (0.554)	DT 0.000 (0.513)	loss 6.538 (6.676)	prob 3.546 (3.021)	GS 35.469 (32.531)	mem 73.098
Train: [75][90/1500]	BT 0.031 (0.497)	DT 0.000 (0.456)	loss 7.181 (6.695)	prob 2.436 (3.030)	GS 32.672 (32.566)	mem 73.098
Train: [75][100/1500]	BT 6.269 (0.527)	DT 6.233 (0.487)	loss 6.559 (6.685)	prob 4.133 (3.090)	GS 31.312 (32.696)	mem 73.109
Train: [75][110/1500]	BT 0.037 (0.482)	DT 0.001 (0.443)	loss 6.649 (6.669)	prob 2.927 (2.923)	GS 34.516 (32.156)	mem 73.113
Train: [75][120/1500]	BT 0.037 (0.445)	DT 0.001 (0.406)	loss 6.627 (6.664)	prob 3.258 (2.977)	GS 35.656 (32.394)	mem 73.118
Train: [75][130/1500]	BT 0.038 (0.440)	DT 0.000 (0.400)	loss 6.443 (6.645)	prob 3.523 (3.020)	GS 31.469 (32.340)	mem 73.164
Train: [75][140/1500]	BT 0.038 (0.411)	DT 0.000 (0.372)	loss 6.603 (6.645)	prob 2.379 (2.971)	GS 32.578 (32.318)	mem 73.164
Train: [75][150/1500]	BT 0.039 (0.429)	DT 0.001 (0.390)	loss 6.652 (6.664)	prob 3.237 (2.926)	GS 36.797 (32.620)	mem 73.177
Train: [75][160/1500]	BT 0.039 (0.405)	DT 0.001 (0.365)	loss 6.622 (6.640)	prob 2.089 (2.897)	GS 30.141 (31.902)	mem 73.177
Train: [75][170/1500]	BT 0.039 (0.393)	DT 0.000 (0.353)	loss 6.774 (6.666)	prob 2.713 (2.776)	GS 36.125 (32.966)	mem 73.179
Train: [75][180/1500]	BT 0.032 (0.391)	DT 0.000 (0.353)	loss 6.737 (6.681)	prob 2.761 (2.810)	GS 32.562 (32.945)	mem 73.183
Train: [75][190/1500]	BT 0.039 (0.373)	DT 0.001 (0.334)	loss 6.870 (6.681)	prob 2.747 (2.794)	GS 32.719 (32.913)	mem 73.184
Train: [75][200/1500]	BT 0.039 (0.370)	DT 0.001 (0.331)	loss 6.745 (6.674)	prob 2.881 (2.800)	GS 32.609 (32.927)	mem 73.191
Train: [75][210/1500]	BT 0.529 (0.357)	DT 0.491 (0.319)	loss 6.570 (6.671)	prob 2.918 (3.349)	GS 33.656 (33.070)	mem 73.192
Train: [75][220/1500]	BT 1.818 (0.353)	DT 1.779 (0.314)	loss 6.734 (6.675)	prob 2.555 (3.061)	GS 35.484 (33.648)	mem 73.193
Train: [75][230/1500]	BT 1.930 (0.348)	DT 1.892 (0.309)	loss 6.955 (6.675)	prob 2.856 (3.086)	GS 34.953 (33.314)	mem 73.194
Train: [75][240/1500]	BT 0.039 (0.338)	DT 0.001 (0.299)	loss 6.680 (6.681)	prob 2.633 (3.116)	GS 34.297 (33.175)	mem 73.195
Train: [75][250/1500]	BT 0.039 (0.330)	DT 0.000 (0.292)	loss 6.728 (6.676)	prob 2.178 (3.030)	GS 33.234 (33.038)	mem 73.295
Train: [75][260/1500]	BT 0.061 (0.328)	DT 0.014 (0.289)	loss 6.757 (6.644)	prob 2.646 (2.872)	GS 35.188 (33.172)	mem 73.592
Train: [75][270/1500]	BT 0.037 (0.321)	DT 0.001 (0.282)	loss 6.636 (6.702)	prob 2.987 (2.891)	GS 35.969 (32.987)	mem 73.790
Train: [75][280/1500]	BT 0.039 (0.321)	DT 0.001 (0.283)	loss 6.585 (6.672)	prob 2.257 (2.836)	GS 35.453 (32.260)	mem 74.134
Train: [75][290/1500]	BT 0.040 (0.317)	DT 0.001 (0.278)	loss 6.651 (6.679)	prob 2.871 (2.758)	GS 32.219 (32.428)	mem 74.379
Train: [75][300/1500]	BT 0.039 (0.307)	DT 0.001 (0.269)	loss 6.653 (6.691)	prob 4.150 (2.769)	GS 35.812 (32.489)	mem 74.379
Train: [75][310/1500]	BT 0.039 (0.323)	DT 0.001 (0.285)	loss 6.688 (6.714)	prob 2.033 (2.642)	GS 32.094 (33.114)	mem 74.381
Train: [75][320/1500]	BT 0.038 (0.315)	DT 0.001 (0.276)	loss 6.679 (6.712)	prob 2.020 (2.586)	GS 33.875 (32.469)	mem 74.380
Train: [75][330/1500]	BT 1.105 (0.319)	DT 1.066 (0.280)	loss 6.883 (6.697)	prob 2.188 (2.623)	GS 36.656 (32.585)	mem 74.383
Train: [75][340/1500]	BT 0.030 (0.320)	DT 0.000 (0.281)	loss 6.998 (6.707)	prob 2.273 (2.648)	GS 31.469 (33.273)	mem 74.385
Train: [75][350/1500]	BT 0.061 (0.312)	DT 0.021 (0.273)	loss 6.586 (6.704)	prob 2.601 (2.691)	GS 34.203 (33.331)	mem 74.384
Train: [75][360/1500]	BT 0.027 (0.315)	DT 0.000 (0.277)	loss 6.656 (6.708)	prob 2.903 (2.700)	GS 32.984 (33.211)	mem 74.399
Train: [75][370/1500]	BT 0.037 (0.307)	DT 0.000 (0.269)	loss 6.971 (6.712)	prob 2.559 (2.765)	GS 27.484 (32.427)	mem 74.400
Train: [75][380/1500]	BT 0.052 (0.314)	DT 0.007 (0.276)	loss 6.815 (6.705)	prob 2.390 (2.797)	GS 32.453 (32.659)	mem 74.401
Train: [75][390/1500]	BT 0.033 (0.307)	DT 0.000 (0.269)	loss 6.654 (6.692)	prob 2.520 (2.700)	GS 35.000 (32.793)	mem 74.401
Train: [75][400/1500]	BT 0.061 (0.301)	DT 0.004 (0.263)	loss 6.608 (6.698)	prob 2.977 (2.673)	GS 41.234 (33.040)	mem 74.401
Train: [75][410/1500]	BT 18.621 (0.378)	DT 18.572 (0.339)	loss 6.903 (6.740)	prob 2.328 (2.130)	GS 37.312 (31.883)	mem 74.409
Train: [75][420/1500]	BT 0.088 (0.370)	DT 0.013 (0.331)	loss 6.820 (6.751)	prob 2.259 (2.165)	GS 34.969 (31.621)	mem 74.409
Train: [75][430/1500]	BT 0.029 (0.395)	DT 0.000 (0.355)	loss 6.801 (6.729)	prob 2.053 (2.246)	GS 33.859 (31.537)	mem 74.296
Train: [75][440/1500]	BT 0.030 (0.386)	DT 0.000 (0.347)	loss 6.612 (6.723)	prob 2.080 (2.305)	GS 35.094 (31.869)	mem 74.311
Train: [75][450/1500]	BT 4.437 (0.388)	DT 4.403 (0.349)	loss 6.789 (6.714)	prob 2.251 (2.308)	GS 33.375 (32.269)	mem 74.313
Train: [75][460/1500]	BT 0.026 (0.381)	DT 0.000 (0.341)	loss 6.629 (6.703)	prob 2.490 (2.563)	GS 34.641 (33.402)	mem 74.313
Train: [75][470/1500]	BT 0.038 (0.373)	DT 0.000 (0.334)	loss 6.583 (6.706)	prob 2.552 (2.580)	GS 36.109 (33.400)	mem 74.316
Train: [75][480/1500]	BT 0.034 (0.375)	DT 0.000 (0.336)	loss 6.763 (6.718)	prob 2.867 (2.634)	GS 31.578 (32.743)	mem 74.315
Train: [75][490/1500]	BT 0.027 (0.368)	DT 0.000 (0.329)	loss 6.667 (6.714)	prob 3.070 (2.614)	GS 33.562 (32.984)	mem 74.314
Train: [75][500/1500]	BT 0.042 (0.372)	DT 0.009 (0.334)	loss 6.559 (6.711)	prob 3.117 (2.648)	GS 35.547 (32.831)	mem 74.317
Train: [75][510/1500]	BT 0.056 (0.366)	DT 0.003 (0.327)	loss 6.900 (6.649)	prob 2.424 (2.959)	GS 32.953 (32.392)	mem 74.315
Train: [75][520/1500]	BT 0.048 (0.360)	DT 0.001 (0.321)	loss 6.799 (6.701)	prob 2.018 (2.711)	GS 38.250 (32.486)	mem 74.315
Train: [75][530/1500]	BT 0.037 (0.367)	DT 0.001 (0.328)	loss 6.621 (6.740)	prob 2.971 (2.622)	GS 32.844 (32.534)	mem 74.317
Train: [75][540/1500]	BT 0.034 (0.363)	DT 0.000 (0.325)	loss 6.704 (6.756)	prob 2.852 (2.611)	GS 34.750 (32.491)	mem 74.336
Train: [75][550/1500]	BT 0.038 (0.360)	DT 0.001 (0.322)	loss 6.859 (6.763)	prob 2.481 (2.580)	GS 34.469 (32.427)	mem 74.338
Train: [75][560/1500]	BT 0.038 (0.357)	DT 0.000 (0.318)	loss 6.639 (6.693)	prob 1.589 (2.661)	GS 30.422 (33.239)	mem 74.339
Train: [75][570/1500]	BT 2.484 (0.355)	DT 2.443 (0.317)	loss 6.679 (6.745)	prob 2.742 (2.534)	GS 31.578 (33.073)	mem 74.323
Train: [75][580/1500]	BT 0.036 (0.352)	DT 0.000 (0.314)	loss 6.642 (6.747)	prob 3.042 (2.542)	GS 34.453 (33.341)	mem 74.325
Train: [75][590/1500]	BT 0.039 (0.347)	DT 0.001 (0.308)	loss 6.676 (6.751)	prob 2.604 (2.508)	GS 34.688 (33.177)	mem 74.325
Train: [75][600/1500]	BT 0.038 (0.346)	DT 0.001 (0.307)	loss 6.684 (6.763)	prob 2.742 (2.471)	GS 36.250 (33.061)	mem 74.325
Train: [75][610/1500]	BT 0.039 (0.341)	DT 0.001 (0.303)	loss 6.744 (6.770)	prob 1.584 (2.471)	GS 34.422 (32.550)	mem 74.325
Train: [75][620/1500]	BT 0.023 (0.352)	DT 0.000 (0.313)	loss 6.815 (6.770)	prob 2.912 (2.561)	GS 33.844 (33.886)	mem 74.329
Train: [75][630/1500]	BT 0.035 (0.347)	DT 0.000 (0.308)	loss 6.862 (6.784)	prob 2.402 (2.665)	GS 36.469 (33.115)	mem 74.330
Train: [75][640/1500]	BT 0.028 (0.342)	DT 0.000 (0.304)	loss 6.692 (6.804)	prob 2.308 (2.621)	GS 30.141 (32.828)	mem 74.332
Train: [75][650/1500]	BT 0.033 (0.344)	DT 0.000 (0.306)	loss 6.718 (6.813)	prob 2.772 (2.649)	GS 34.109 (32.705)	mem 74.333
Train: [75][660/1500]	BT 0.039 (0.340)	DT 0.001 (0.302)	loss 6.944 (6.775)	prob 2.338 (2.649)	GS 34.125 (31.795)	mem 74.334
Train: [75][670/1500]	BT 0.026 (0.341)	DT 0.000 (0.303)	loss 6.559 (6.775)	prob 2.457 (2.598)	GS 33.609 (31.976)	mem 74.347
Train: [75][680/1500]	BT 0.026 (0.336)	DT 0.000 (0.299)	loss 6.821 (6.806)	prob 2.492 (2.527)	GS 32.234 (32.171)	mem 74.350
Train: [75][690/1500]	BT 0.044 (0.332)	DT 0.017 (0.294)	loss 7.117 (6.808)	prob 2.511 (2.566)	GS 33.625 (31.909)	mem 74.352
Train: [75][700/1500]	BT 0.029 (0.340)	DT 0.000 (0.302)	loss 6.753 (6.828)	prob 3.209 (2.565)	GS 32.547 (31.593)	mem 74.354
Train: [75][710/1500]	BT 0.035 (0.335)	DT 0.000 (0.298)	loss 6.951 (6.882)	prob 3.086 (2.903)	GS 31.859 (32.136)	mem 74.355
Train: [75][720/1500]	BT 0.028 (0.340)	DT 0.000 (0.303)	loss 6.896 (6.842)	prob 2.382 (2.850)	GS 33.641 (31.973)	mem 74.357
Train: [75][730/1500]	BT 0.026 (0.336)	DT 0.000 (0.298)	loss 6.811 (6.825)	prob 2.871 (2.832)	GS 31.656 (32.368)	mem 74.357
Train: [75][740/1500]	BT 0.037 (0.336)	DT 0.000 (0.299)	loss 6.916 (6.849)	prob 3.013 (2.799)	GS 29.781 (32.404)	mem 74.357
Train: [75][750/1500]	BT 0.026 (0.332)	DT 0.000 (0.295)	loss 6.743 (6.839)	prob 2.608 (2.729)	GS 30.469 (32.292)	mem 74.358
Train: [75][760/1500]	BT 0.024 (0.328)	DT 0.000 (0.291)	loss 6.579 (6.827)	prob 2.848 (2.614)	GS 34.234 (33.495)	mem 74.357
Train: [75][770/1500]	BT 0.037 (0.328)	DT 0.001 (0.291)	loss 6.827 (6.873)	prob 2.321 (2.633)	GS 33.656 (32.438)	mem 74.358
Train: [75][780/1500]	BT 0.037 (0.324)	DT 0.001 (0.287)	loss 6.659 (6.825)	prob 2.037 (2.550)	GS 33.125 (31.841)	mem 74.359
Train: [75][790/1500]	BT 0.031 (0.326)	DT 0.000 (0.290)	loss 6.740 (6.826)	prob 3.131 (2.571)	GS 32.672 (31.770)	mem 74.359
Train: [75][800/1500]	BT 0.036 (0.323)	DT 0.000 (0.286)	loss 6.900 (6.831)	prob 2.649 (2.498)	GS 34.844 (31.812)	mem 74.360
Train: [75][810/1500]	BT 0.038 (0.319)	DT 0.000 (0.282)	loss 6.850 (6.882)	prob 1.821 (2.498)	GS 34.062 (32.439)	mem 74.361
Train: [75][820/1500]	BT 0.037 (0.323)	DT 0.001 (0.287)	loss 6.942 (6.891)	prob 2.952 (2.520)	GS 33.047 (31.891)	mem 74.362
Train: [75][830/1500]	BT 0.034 (0.321)	DT 0.001 (0.284)	loss 6.633 (6.854)	prob 2.951 (2.497)	GS 35.031 (31.874)	mem 74.363
Train: [75][840/1500]	BT 0.038 (0.321)	DT 0.001 (0.285)	loss 6.663 (6.847)	prob 2.747 (2.514)	GS 32.797 (31.824)	mem 74.363
Train: [75][850/1500]	BT 0.037 (0.318)	DT 0.001 (0.281)	loss 6.807 (6.849)	prob 2.333 (2.573)	GS 33.672 (32.089)	mem 74.363
Train: [75][860/1500]	BT 0.036 (0.322)	DT 0.001 (0.285)	loss 7.036 (6.867)	prob 2.804 (2.455)	GS 31.359 (33.269)	mem 74.365
Train: [75][870/1500]	BT 0.030 (0.323)	DT 0.000 (0.287)	loss 6.825 (6.920)	prob 2.686 (2.397)	GS 35.969 (33.655)	mem 74.366
Train: [75][880/1500]	BT 0.035 (0.320)	DT 0.001 (0.283)	loss 6.729 (6.922)	prob 2.806 (2.455)	GS 34.953 (33.273)	mem 74.366
Train: [75][890/1500]	BT 0.037 (0.322)	DT 0.000 (0.286)	loss 7.225 (6.929)	prob 1.841 (2.533)	GS 38.484 (33.449)	mem 74.370
Train: [75][900/1500]	BT 0.036 (0.319)	DT 0.000 (0.283)	loss 7.027 (6.941)	prob 2.939 (2.494)	GS 35.250 (32.940)	mem 74.370
Train: [75][910/1500]	BT 0.037 (0.316)	DT 0.000 (0.280)	loss 6.777 (6.843)	prob 2.284 (2.652)	GS 33.109 (33.600)	mem 74.370
Train: [75][920/1500]	BT 0.106 (0.322)	DT 0.020 (0.285)	loss 7.091 (6.888)	prob 2.564 (2.640)	GS 33.078 (32.953)	mem 74.369
Train: [75][930/1500]	BT 0.029 (0.332)	DT 0.000 (0.295)	loss 6.670 (6.907)	prob 3.167 (2.647)	GS 35.297 (33.235)	mem 74.370
Train: [75][940/1500]	BT 0.032 (0.329)	DT 0.001 (0.292)	loss 6.957 (6.910)	prob 2.482 (2.631)	GS 33.328 (32.512)	mem 74.370
Train: [75][950/1500]	BT 0.032 (0.326)	DT 0.000 (0.289)	loss 7.055 (6.895)	prob 2.234 (2.603)	GS 28.250 (32.178)	mem 74.371
Train: [75][960/1500]	BT 0.031 (0.328)	DT 0.000 (0.291)	loss 7.053 (6.991)	prob 2.542 (2.424)	GS 34.188 (31.856)	mem 74.372
Train: [75][970/1500]	BT 0.037 (0.325)	DT 0.001 (0.288)	loss 6.942 (7.023)	prob 2.795 (2.611)	GS 33.484 (32.904)	mem 74.372
Train: [75][980/1500]	BT 0.033 (0.328)	DT 0.000 (0.292)	loss 6.912 (6.995)	prob 2.814 (2.517)	GS 34.109 (32.905)	mem 74.371
Train: [75][990/1500]	BT 0.038 (0.325)	DT 0.001 (0.289)	loss 6.764 (6.967)	prob 2.797 (2.578)	GS 33.828 (32.731)	mem 74.372
Train: [75][1000/1500]	BT 0.038 (0.323)	DT 0.001 (0.286)	loss 6.943 (6.971)	prob 2.824 (2.567)	GS 33.141 (32.745)	mem 74.373
Train: [75][1010/1500]	BT 0.030 (0.327)	DT 0.000 (0.290)	loss 7.005 (6.916)	prob 2.821 (2.573)	GS 31.938 (31.606)	mem 74.374
Train: [75][1020/1500]	BT 0.037 (0.324)	DT 0.001 (0.287)	loss 7.243 (6.970)	prob 3.399 (2.466)	GS 30.172 (31.937)	mem 74.375
Train: [75][1030/1500]	BT 0.035 (0.325)	DT 0.000 (0.288)	loss 6.763 (6.951)	prob 2.052 (2.435)	GS 27.641 (31.921)	mem 74.375
Train: [75][1040/1500]	BT 0.063 (0.323)	DT 0.014 (0.286)	loss 7.324 (6.950)	prob 2.670 (2.480)	GS 33.547 (32.256)	mem 74.375
Train: [75][1050/1500]	BT 0.030 (0.327)	DT 0.000 (0.291)	loss 6.871 (6.973)	prob 2.840 (2.467)	GS 32.875 (32.727)	mem 74.403
Train: [75][1060/1500]	BT 0.028 (0.325)	DT 0.000 (0.288)	loss 7.067 (6.848)	prob 2.649 (2.606)	GS 36.891 (32.409)	mem 74.404
Train: [75][1070/1500]	BT 0.040 (0.326)	DT 0.001 (0.289)	loss 6.715 (6.900)	prob 2.675 (2.502)	GS 30.469 (32.051)	mem 74.405
Train: [75][1080/1500]	BT 0.039 (0.323)	DT 0.001 (0.287)	loss 7.043 (6.958)	prob 2.607 (2.392)	GS 35.688 (32.715)	mem 74.405
Train: [75][1090/1500]	BT 0.038 (0.324)	DT 0.000 (0.287)	loss 6.966 (6.998)	prob 2.377 (2.451)	GS 32.250 (32.441)	mem 74.406
Train: [75][1100/1500]	BT 0.038 (0.322)	DT 0.001 (0.285)	loss 7.129 (6.999)	prob 2.685 (2.465)	GS 32.219 (32.475)	mem 74.406
Train: [75][1110/1500]	BT 0.039 (0.319)	DT 0.001 (0.282)	loss 7.572 (7.147)	prob 1.089 (2.176)	GS 36.984 (33.166)	mem 74.407
Train: [75][1120/1500]	BT 0.040 (0.319)	DT 0.001 (0.282)	loss 7.005 (7.104)	prob 3.078 (2.345)	GS 35.234 (32.756)	mem 74.407
Train: [75][1130/1500]	BT 0.039 (0.317)	DT 0.001 (0.280)	loss 6.910 (7.080)	prob 2.137 (2.396)	GS 32.938 (32.456)	mem 74.408
Train: [75][1140/1500]	BT 0.032 (0.317)	DT 0.000 (0.280)	loss 7.638 (7.084)	prob 2.339 (2.279)	GS 32.750 (32.764)	mem 74.408
Train: [75][1150/1500]	BT 0.037 (0.315)	DT 0.000 (0.279)	loss 7.057 (7.063)	prob 3.327 (2.277)	GS 30.641 (32.407)	mem 74.409
Train: [75][1160/1500]	BT 0.040 (0.314)	DT 0.001 (0.277)	loss 7.286 (7.109)	prob 1.592 (2.613)	GS 32.984 (32.569)	mem 74.408
Train: [75][1170/1500]	BT 0.039 (0.313)	DT 0.001 (0.276)	loss 6.930 (7.087)	prob 3.088 (2.555)	GS 31.922 (32.446)	mem 74.409
Train: [75][1180/1500]	BT 0.039 (0.315)	DT 0.001 (0.278)	loss 7.138 (7.150)	prob 3.111 (2.545)	GS 39.359 (32.532)	mem 74.409
Train: [75][1190/1500]	BT 0.039 (0.313)	DT 0.001 (0.276)	loss 6.925 (7.140)	prob 2.330 (2.566)	GS 38.891 (32.650)	mem 74.408
Train: [75][1200/1500]	BT 0.037 (0.313)	DT 0.000 (0.277)	loss 6.986 (7.101)	prob 3.414 (2.596)	GS 35.750 (32.683)	mem 74.408
Train: [75][1210/1500]	BT 0.093 (0.311)	DT 0.001 (0.274)	loss 7.884 (7.193)	prob 2.344 (2.525)	GS 28.719 (32.545)	mem 74.408
Train: [75][1220/1500]	BT 0.039 (0.310)	DT 0.001 (0.273)	loss 7.021 (7.177)	prob 2.610 (2.581)	GS 33.391 (32.670)	mem 74.409
Train: [75][1230/1500]	BT 0.039 (0.310)	DT 0.001 (0.273)	loss 7.198 (7.170)	prob 2.937 (2.581)	GS 36.266 (32.555)	mem 74.408
Train: [75][1240/1500]	BT 0.058 (0.308)	DT 0.002 (0.271)	loss 7.177 (7.130)	prob 3.028 (2.721)	GS 31.344 (32.246)	mem 74.411
Train: [75][1250/1500]	BT 0.038 (0.311)	DT 0.001 (0.274)	loss 6.783 (7.120)	prob 3.070 (2.788)	GS 28.547 (32.176)	mem 74.413
Train: [75][1260/1500]	BT 0.694 (0.309)	DT 0.656 (0.272)	loss 7.263 (7.154)	prob 2.949 (2.839)	GS 32.484 (32.280)	mem 74.412
Train: [75][1270/1500]	BT 0.039 (0.307)	DT 0.001 (0.270)	loss 7.227 (7.067)	prob 2.981 (2.886)	GS 32.391 (32.595)	mem 74.411
Train: [75][1280/1500]	BT 0.052 (0.309)	DT 0.003 (0.272)	loss 6.758 (7.033)	prob 3.042 (2.824)	GS 31.750 (32.696)	mem 74.413
Train: [75][1290/1500]	BT 0.052 (0.309)	DT 0.012 (0.272)	loss 6.971 (7.028)	prob 3.513 (2.854)	GS 34.156 (32.628)	mem 74.413
Train: [75][1300/1500]	BT 0.037 (0.311)	DT 0.001 (0.274)	loss 7.015 (7.048)	prob 3.113 (2.848)	GS 32.641 (32.799)	mem 74.414
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [75][1310/1500]	BT 0.037 (0.310)	DT 0.001 (0.272)	loss 7.152 (7.052)	prob 3.122 (3.117)	GS 34.938 (32.638)	mem 74.416
Train: [75][1320/1500]	BT 0.037 (0.310)	DT 0.001 (0.273)	loss 7.015 (7.081)	prob 3.233 (3.167)	GS 35.438 (32.158)	mem 74.422
Train: [75][1330/1500]	BT 0.036 (0.308)	DT 0.001 (0.271)	loss 7.312 (7.064)	prob 2.534 (3.072)	GS 37.047 (32.423)	mem 74.422
Train: [75][1340/1500]	BT 0.029 (0.312)	DT 0.000 (0.274)	loss 7.043 (7.064)	prob 2.454 (3.032)	GS 33.656 (32.697)	mem 74.434
Train: [75][1350/1500]	BT 0.037 (0.310)	DT 0.001 (0.272)	loss 7.011 (7.063)	prob 2.852 (3.039)	GS 33.859 (32.770)	mem 74.434
Train: [75][1360/1500]	BT 0.038 (0.308)	DT 0.001 (0.270)	loss 7.658 (7.117)	prob 2.910 (2.776)	GS 34.172 (34.039)	mem 74.435
Train: [75][1370/1500]	BT 0.037 (0.308)	DT 0.001 (0.270)	loss 7.087 (7.061)	prob 3.579 (2.947)	GS 33.969 (34.235)	mem 74.325
Train: [75][1380/1500]	BT 0.037 (0.306)	DT 0.001 (0.269)	loss 7.148 (7.057)	prob 3.463 (3.059)	GS 29.859 (33.551)	mem 74.332
Train: [75][1390/1500]	BT 0.026 (0.307)	DT 0.000 (0.270)	loss 7.341 (7.081)	prob 2.618 (3.021)	GS 36.594 (33.332)	mem 74.332
Train: [75][1400/1500]	BT 0.037 (0.305)	DT 0.001 (0.268)	loss 7.254 (7.060)	prob 3.257 (3.023)	GS 31.500 (32.943)	mem 74.334
Train: [75][1410/1500]	BT 0.037 (0.304)	DT 0.001 (0.266)	loss 7.024 (7.064)	prob 3.569 (2.805)	GS 34.891 (34.087)	mem 74.333
Train: [75][1420/1500]	BT 0.028 (0.305)	DT 0.000 (0.268)	loss 7.053 (7.059)	prob 3.628 (2.998)	GS 37.094 (32.977)	mem 74.333
Train: [75][1430/1500]	BT 0.024 (0.303)	DT 0.000 (0.266)	loss 7.081 (7.059)	prob 2.861 (2.971)	GS 32.781 (33.056)	mem 74.332
Train: [75][1440/1500]	BT 0.038 (0.304)	DT 0.001 (0.266)	loss 6.904 (7.047)	prob 2.813 (3.025)	GS 35.297 (32.857)	mem 74.335
Train: [75][1450/1500]	BT 0.028 (0.302)	DT 0.000 (0.264)	loss 7.350 (7.042)	prob 3.479 (3.051)	GS 31.688 (32.797)	mem 74.335
Train: [75][1460/1500]	BT 0.033 (0.302)	DT 0.000 (0.265)	loss 7.476 (6.999)	prob 2.806 (3.027)	GS 34.656 (33.150)	mem 73.882
Train: [75][1470/1500]	BT 0.056 (0.300)	DT 0.001 (0.263)	loss 6.810 (7.003)	prob 3.050 (3.037)	GS 31.828 (31.757)	mem 73.664
Train: [75][1480/1500]	BT 0.030 (0.300)	DT 0.000 (0.262)	loss 7.131 (6.991)	prob 3.263 (3.091)	GS 30.844 (31.514)	mem 31.955
Train: [75][1490/1500]	BT 0.031 (0.300)	DT 0.000 (0.263)	loss 7.411 (6.989)	prob 2.456 (3.082)	GS 32.688 (31.779)	mem 9.337
Train: [75][1500/1500]	BT 0.023 (0.299)	DT 0.000 (0.261)	loss 6.666 (6.979)	prob 2.745 (3.068)	GS 32.812 (32.023)	mem 9.337
Train: [75][1510/1500]	BT 0.027 (0.297)	DT 0.000 (0.260)	loss 6.979 (6.916)	prob 2.607 (2.651)	GS 36.625 (34.612)	mem 9.263
epoch 75, total time 449.23
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [76][1/1500]	BT 18.162 (18.162)	DT 18.104 (18.104)	loss 7.055 (7.055)	prob 2.727 (2.727)	GS 31.781 (31.781)	mem 72.638
Train: [76][10/1500]	BT 0.029 (2.310)	DT 0.000 (2.275)	loss 6.966 (6.780)	prob 3.328 (3.414)	GS 31.891 (31.321)	mem 73.031
Train: [76][20/1500]	BT 0.039 (1.174)	DT 0.001 (1.138)	loss 6.768 (6.798)	prob 3.441 (3.355)	GS 35.203 (32.193)	mem 73.033
Train: [76][30/1500]	BT 0.033 (1.220)	DT 0.001 (1.180)	loss 6.887 (6.823)	prob 3.646 (3.340)	GS 33.828 (31.835)	mem 73.081
Train: [76][40/1500]	BT 0.028 (0.924)	DT 0.000 (0.885)	loss 7.211 (6.858)	prob 3.027 (3.218)	GS 30.172 (31.915)	mem 73.083
Train: [76][50/1500]	BT 0.026 (0.745)	DT 0.000 (0.708)	loss 6.755 (6.869)	prob 3.608 (3.198)	GS 30.078 (32.061)	mem 73.084
Train: [76][60/1500]	BT 0.026 (0.702)	DT 0.000 (0.666)	loss 6.984 (7.040)	prob 3.611 (3.468)	GS 35.188 (32.955)	mem 73.112
Train: [76][70/1500]	BT 0.024 (0.605)	DT 0.000 (0.571)	loss 6.914 (7.053)	prob 2.940 (3.258)	GS 33.547 (32.762)	mem 73.115
Train: [76][80/1500]	BT 0.031 (0.614)	DT 0.000 (0.581)	loss 7.149 (7.018)	prob 3.569 (3.211)	GS 34.312 (32.571)	mem 73.124
Train: [76][90/1500]	BT 0.044 (0.552)	DT 0.001 (0.517)	loss 7.088 (7.024)	prob 2.378 (3.217)	GS 36.906 (32.777)	mem 73.127
Train: [76][100/1500]	BT 0.053 (0.504)	DT 0.001 (0.466)	loss 6.891 (7.032)	prob 3.206 (3.118)	GS 31.328 (32.822)	mem 73.126
Train: [76][110/1500]	BT 0.029 (0.591)	DT 0.000 (0.553)	loss 7.050 (7.052)	prob 2.706 (2.809)	GS 35.656 (32.878)	mem 73.130
Train: [76][120/1500]	BT 0.028 (0.545)	DT 0.000 (0.507)	loss 7.292 (7.030)	prob 3.558 (2.873)	GS 32.953 (31.638)	mem 73.131
Train: [76][130/1500]	BT 0.023 (0.505)	DT 0.000 (0.468)	loss 6.832 (7.015)	prob 3.305 (2.949)	GS 36.844 (32.217)	mem 73.132
Train: [76][140/1500]	BT 0.037 (0.490)	DT 0.001 (0.454)	loss 7.128 (7.002)	prob 3.343 (2.938)	GS 33.656 (32.336)	mem 73.135
Train: [76][150/1500]	BT 0.037 (0.460)	DT 0.001 (0.423)	loss 7.081 (7.023)	prob 2.965 (2.982)	GS 34.891 (32.338)	mem 73.136
Train: [76][160/1500]	BT 0.092 (0.458)	DT 0.002 (0.420)	loss 7.160 (6.969)	prob 2.529 (2.545)	GS 33.109 (33.069)	mem 73.148
Train: [76][170/1500]	BT 0.052 (0.462)	DT 0.003 (0.423)	loss 7.102 (7.029)	prob 3.178 (2.595)	GS 38.422 (33.486)	mem 73.152
Train: [76][180/1500]	BT 0.060 (0.441)	DT 0.002 (0.400)	loss 6.860 (7.037)	prob 2.851 (2.615)	GS 34.797 (33.122)	mem 73.152
Train: [76][190/1500]	BT 0.056 (0.436)	DT 0.014 (0.395)	loss 7.249 (7.036)	prob 2.613 (2.591)	GS 35.406 (33.263)	mem 73.151
Train: [76][200/1500]	BT 0.064 (0.434)	DT 0.004 (0.393)	loss 7.035 (7.061)	prob 2.204 (2.576)	GS 36.734 (33.217)	mem 73.152
Train: [76][210/1500]	BT 0.030 (0.476)	DT 0.000 (0.435)	loss 7.118 (7.035)	prob 3.255 (2.725)	GS 32.094 (32.038)	mem 73.154
Train: [76][220/1500]	BT 0.029 (0.455)	DT 0.000 (0.415)	loss 6.918 (7.061)	prob 3.290 (2.793)	GS 35.438 (32.798)	mem 73.157
Train: [76][230/1500]	BT 0.039 (0.451)	DT 0.000 (0.411)	loss 7.256 (7.033)	prob 3.274 (2.724)	GS 36.156 (33.193)	mem 73.160
Train: [76][240/1500]	BT 0.037 (0.433)	DT 0.001 (0.394)	loss 7.044 (7.045)	prob 2.911 (2.668)	GS 33.656 (33.314)	mem 73.160
Train: [76][250/1500]	BT 0.037 (0.417)	DT 0.000 (0.378)	loss 7.185 (7.042)	prob 3.531 (2.687)	GS 34.594 (33.352)	mem 73.160
Train: [76][260/1500]	BT 0.038 (0.417)	DT 0.001 (0.378)	loss 7.309 (7.202)	prob 3.311 (3.175)	GS 32.047 (32.438)	mem 73.798
Train: [76][270/1500]	BT 0.033 (0.404)	DT 0.000 (0.364)	loss 7.386 (7.166)	prob 2.660 (2.982)	GS 32.703 (32.308)	mem 73.799
Train: [76][280/1500]	BT 0.026 (0.419)	DT 0.000 (0.379)	loss 7.065 (7.097)	prob 3.126 (2.882)	GS 29.875 (32.340)	mem 74.341
Train: [76][290/1500]	BT 0.037 (0.405)	DT 0.000 (0.366)	loss 7.111 (7.078)	prob 2.878 (2.826)	GS 27.656 (32.169)	mem 74.342
Train: [76][300/1500]	BT 4.302 (0.407)	DT 4.269 (0.368)	loss 7.034 (7.055)	prob 3.051 (2.844)	GS 33.312 (32.404)	mem 74.346
Train: [76][310/1500]	BT 0.034 (0.395)	DT 0.001 (0.356)	loss 7.505 (7.154)	prob 2.589 (2.859)	GS 35.359 (32.791)	mem 74.347
Train: [76][320/1500]	BT 0.038 (0.384)	DT 0.001 (0.345)	loss 6.994 (7.082)	prob 2.398 (2.841)	GS 34.797 (33.102)	mem 74.347
Train: [76][330/1500]	BT 0.055 (0.402)	DT 0.008 (0.363)	loss 7.118 (7.075)	prob 3.227 (2.759)	GS 34.156 (32.804)	mem 74.351
Train: [76][340/1500]	BT 0.026 (0.415)	DT 0.000 (0.376)	loss 7.453 (7.071)	prob 2.186 (2.741)	GS 32.219 (32.757)	mem 74.354
Train: [76][350/1500]	BT 0.035 (0.404)	DT 0.001 (0.366)	loss 8.064 (7.103)	prob 3.094 (2.722)	GS 33.422 (32.895)	mem 74.357
Train: [76][360/1500]	BT 0.035 (0.394)	DT 0.000 (0.355)	loss 7.225 (7.112)	prob 2.507 (2.930)	GS 33.766 (33.788)	mem 74.359
Train: [76][370/1500]	BT 0.037 (0.392)	DT 0.001 (0.353)	loss 7.439 (7.164)	prob 3.130 (2.726)	GS 34.141 (33.347)	mem 74.362
Train: [76][380/1500]	BT 0.028 (0.382)	DT 0.000 (0.344)	loss 7.160 (7.118)	prob 2.880 (2.806)	GS 27.406 (32.766)	mem 74.362
Train: [76][390/1500]	BT 0.034 (0.381)	DT 0.001 (0.343)	loss 7.149 (7.135)	prob 3.395 (2.834)	GS 31.875 (32.871)	mem 74.363
Train: [76][400/1500]	BT 0.038 (0.374)	DT 0.001 (0.336)	loss 7.151 (7.137)	prob 3.459 (2.858)	GS 37.422 (33.303)	mem 74.364
Train: [76][410/1500]	BT 4.709 (0.377)	DT 4.671 (0.339)	loss 6.938 (7.063)	prob 3.658 (2.596)	GS 34.188 (33.025)	mem 74.362
Train: [76][420/1500]	BT 3.255 (0.377)	DT 3.222 (0.339)	loss 7.141 (7.098)	prob 2.735 (2.483)	GS 37.656 (33.473)	mem 74.362
Train: [76][430/1500]	BT 0.058 (0.370)	DT 0.001 (0.331)	loss 7.144 (7.105)	prob 3.662 (2.807)	GS 33.656 (32.657)	mem 74.363
Train: [76][440/1500]	BT 0.033 (0.400)	DT 0.001 (0.361)	loss 7.084 (7.143)	prob 3.388 (2.879)	GS 36.797 (33.099)	mem 74.362
Train: [76][450/1500]	BT 0.027 (0.392)	DT 0.000 (0.353)	loss 7.731 (7.169)	prob 2.896 (2.887)	GS 36.609 (33.279)	mem 74.363
Train: [76][460/1500]	BT 0.024 (0.384)	DT 0.000 (0.345)	loss 6.906 (7.170)	prob 3.139 (2.956)	GS 31.312 (31.800)	mem 74.365
Train: [76][470/1500]	BT 0.030 (0.390)	DT 0.000 (0.351)	loss 7.417 (7.244)	prob 2.926 (2.998)	GS 36.344 (32.754)	mem 74.393
Train: [76][480/1500]	BT 0.029 (0.382)	DT 0.000 (0.344)	loss 7.012 (7.253)	prob 4.063 (3.028)	GS 33.312 (32.423)	mem 74.394
Train: [76][490/1500]	BT 0.029 (0.384)	DT 0.000 (0.346)	loss 7.227 (7.219)	prob 4.102 (3.155)	GS 33.062 (32.825)	mem 74.395
Train: [76][500/1500]	BT 0.038 (0.378)	DT 0.001 (0.339)	loss 7.192 (7.226)	prob 3.566 (3.219)	GS 31.578 (32.687)	mem 74.396
Train: [76][510/1500]	BT 0.030 (0.387)	DT 0.000 (0.349)	loss 8.069 (7.411)	prob 2.977 (3.230)	GS 33.328 (33.878)	mem 74.399
Train: [76][520/1500]	BT 0.025 (0.380)	DT 0.000 (0.342)	loss 7.261 (7.345)	prob 2.928 (3.166)	GS 34.234 (33.173)	mem 74.398
Train: [76][530/1500]	BT 0.028 (0.373)	DT 0.000 (0.336)	loss 7.408 (7.360)	prob 3.407 (3.140)	GS 30.750 (32.992)	mem 74.399
Train: [76][540/1500]	BT 0.037 (0.375)	DT 0.000 (0.337)	loss 7.222 (7.376)	prob 4.163 (3.185)	GS 34.109 (33.107)	mem 74.401
Train: [76][550/1500]	BT 0.029 (0.379)	DT 0.000 (0.341)	loss 7.202 (7.362)	prob 2.945 (3.219)	GS 33.906 (33.748)	mem 74.398
Train: [76][560/1500]	BT 0.031 (0.376)	DT 0.001 (0.338)	loss 7.434 (7.226)	prob 3.162 (3.527)	GS 32.891 (32.673)	mem 74.398
Train: [76][570/1500]	BT 0.039 (0.372)	DT 0.001 (0.334)	loss 7.435 (7.272)	prob 4.006 (3.633)	GS 36.578 (33.122)	mem 74.401
Train: [76][580/1500]	BT 0.039 (0.366)	DT 0.001 (0.329)	loss 7.458 (7.278)	prob 3.858 (3.619)	GS 37.656 (33.760)	mem 74.401
Train: [76][590/1500]	BT 0.035 (0.363)	DT 0.001 (0.326)	loss 7.437 (7.252)	prob 3.455 (3.626)	GS 31.000 (33.629)	mem 74.401
Train: [76][600/1500]	BT 0.056 (0.361)	DT 0.001 (0.323)	loss 7.273 (7.261)	prob 4.254 (3.646)	GS 37.266 (33.426)	mem 74.400
Train: [76][610/1500]	BT 0.039 (0.364)	DT 0.006 (0.326)	loss 7.004 (7.174)	prob 4.269 (3.546)	GS 31.297 (32.375)	mem 74.402
Train: [76][620/1500]	BT 0.030 (0.378)	DT 0.000 (0.340)	loss 7.121 (7.236)	prob 3.121 (3.408)	GS 33.688 (33.328)	mem 74.401
Train: [76][630/1500]	BT 0.034 (0.372)	DT 0.000 (0.335)	loss 7.122 (7.330)	prob 3.618 (3.328)	GS 35.609 (33.201)	mem 74.401
Train: [76][640/1500]	BT 0.034 (0.371)	DT 0.001 (0.334)	loss 7.194 (7.316)	prob 3.167 (3.296)	GS 31.641 (32.932)	mem 74.401
Train: [76][650/1500]	BT 0.038 (0.366)	DT 0.000 (0.329)	loss 6.902 (7.296)	prob 4.440 (3.323)	GS 31.562 (32.639)	mem 74.402
Train: [76][660/1500]	BT 6.939 (0.371)	DT 6.899 (0.334)	loss 7.363 (7.201)	prob 3.220 (3.719)	GS 36.391 (33.173)	mem 74.402
Train: [76][670/1500]	BT 0.038 (0.366)	DT 0.001 (0.329)	loss 7.121 (7.169)	prob 3.763 (3.605)	GS 31.047 (32.449)	mem 74.404
Train: [76][680/1500]	BT 0.039 (0.362)	DT 0.001 (0.325)	loss 7.372 (7.157)	prob 3.439 (3.630)	GS 29.391 (32.084)	mem 74.404
Train: [76][690/1500]	BT 0.039 (0.361)	DT 0.001 (0.324)	loss 6.909 (7.174)	prob 3.683 (3.524)	GS 32.797 (32.257)	mem 74.405
Train: [76][700/1500]	BT 0.038 (0.356)	DT 0.001 (0.319)	loss 7.739 (7.201)	prob 2.611 (3.424)	GS 35.641 (32.465)	mem 74.405
Train: [76][710/1500]	BT 0.038 (0.356)	DT 0.001 (0.319)	loss 7.157 (7.067)	prob 3.691 (3.485)	GS 35.250 (32.666)	mem 74.406
Train: [76][720/1500]	BT 0.031 (0.352)	DT 0.000 (0.315)	loss 7.142 (7.106)	prob 3.681 (3.452)	GS 31.797 (32.421)	mem 74.408
Train: [76][730/1500]	BT 0.031 (0.347)	DT 0.000 (0.310)	loss 7.253 (7.089)	prob 3.022 (3.454)	GS 36.047 (31.722)	mem 74.408
Train: [76][740/1500]	BT 0.033 (0.358)	DT 0.000 (0.320)	loss 7.543 (7.118)	prob 3.358 (3.342)	GS 36.969 (32.775)	mem 74.413
Train: [76][750/1500]	BT 0.034 (0.353)	DT 0.000 (0.316)	loss 7.180 (7.122)	prob 2.969 (3.374)	GS 34.922 (32.799)	mem 74.413
Train: [76][760/1500]	BT 0.074 (0.360)	DT 0.006 (0.322)	loss 7.207 (7.138)	prob 3.379 (3.298)	GS 32.781 (32.434)	mem 74.413
Train: [76][770/1500]	BT 0.030 (0.371)	DT 0.001 (0.333)	loss 6.876 (7.112)	prob 3.783 (3.127)	GS 33.562 (32.629)	mem 74.414
Train: [76][780/1500]	BT 0.026 (0.366)	DT 0.000 (0.329)	loss 6.894 (7.093)	prob 3.221 (3.116)	GS 32.469 (32.222)	mem 74.413
Train: [76][790/1500]	BT 0.024 (0.368)	DT 0.000 (0.330)	loss 6.838 (7.076)	prob 3.863 (3.086)	GS 33.359 (32.405)	mem 74.421
Train: [76][800/1500]	BT 0.027 (0.364)	DT 0.000 (0.326)	loss 7.325 (7.060)	prob 3.683 (3.135)	GS 33.531 (32.388)	mem 74.421
Train: [76][810/1500]	BT 0.036 (0.360)	DT 0.000 (0.322)	loss 7.641 (7.144)	prob 2.974 (3.000)	GS 33.250 (32.152)	mem 74.422
Train: [76][820/1500]	BT 0.038 (0.361)	DT 0.000 (0.324)	loss 7.001 (7.092)	prob 3.867 (3.242)	GS 32.500 (32.109)	mem 74.435
Train: [76][830/1500]	BT 0.038 (0.357)	DT 0.000 (0.320)	loss 7.176 (7.101)	prob 2.996 (3.204)	GS 34.625 (32.063)	mem 74.434
Train: [76][840/1500]	BT 0.038 (0.359)	DT 0.001 (0.322)	loss 7.342 (7.078)	prob 2.795 (3.123)	GS 30.969 (31.961)	mem 74.426
Train: [76][850/1500]	BT 0.027 (0.355)	DT 0.000 (0.318)	loss 7.013 (7.082)	prob 2.927 (3.120)	GS 32.469 (32.256)	mem 74.427
Train: [76][860/1500]	BT 0.037 (0.351)	DT 0.001 (0.314)	loss 6.996 (7.026)	prob 2.969 (2.867)	GS 33.672 (33.322)	mem 74.428
Train: [76][870/1500]	BT 0.064 (0.354)	DT 0.004 (0.317)	loss 6.948 (7.060)	prob 2.354 (2.927)	GS 37.312 (33.510)	mem 74.335
Train: [76][880/1500]	BT 0.055 (0.351)	DT 0.006 (0.313)	loss 7.017 (7.059)	prob 3.014 (2.940)	GS 39.375 (33.654)	mem 74.334
Train: [76][890/1500]	BT 0.025 (0.356)	DT 0.000 (0.318)	loss 7.176 (7.059)	prob 3.160 (2.882)	GS 34.094 (34.066)	mem 74.334
Train: [76][900/1500]	BT 0.027 (0.352)	DT 0.000 (0.315)	loss 7.159 (7.060)	prob 2.628 (2.925)	GS 34.797 (33.707)	mem 74.335
Train: [76][910/1500]	BT 0.037 (0.350)	DT 0.001 (0.313)	loss 6.994 (7.069)	prob 3.208 (3.085)	GS 31.859 (31.961)	mem 74.335
Train: [76][920/1500]	BT 0.049 (0.351)	DT 0.003 (0.314)	loss 7.122 (7.084)	prob 2.950 (3.015)	GS 34.281 (32.531)	mem 74.333
Train: [76][930/1500]	BT 0.050 (0.348)	DT 0.008 (0.310)	loss 6.968 (7.044)	prob 3.520 (2.992)	GS 35.000 (32.566)	mem 74.335
Train: [76][940/1500]	BT 0.037 (0.349)	DT 0.001 (0.311)	loss 7.014 (7.038)	prob 2.642 (2.936)	GS 34.281 (32.321)	mem 74.350
Train: [76][950/1500]	BT 0.037 (0.345)	DT 0.001 (0.308)	loss 7.001 (7.016)	prob 2.930 (2.959)	GS 34.000 (32.364)	mem 74.352
Train: [76][960/1500]	BT 0.038 (0.347)	DT 0.000 (0.309)	loss 7.038 (7.011)	prob 3.319 (2.955)	GS 31.906 (33.647)	mem 74.354
Train: [76][970/1500]	BT 0.037 (0.345)	DT 0.001 (0.308)	loss 7.046 (7.009)	prob 2.957 (2.959)	GS 32.859 (32.977)	mem 74.338
Train: [76][980/1500]	BT 0.064 (0.342)	DT 0.003 (0.305)	loss 6.981 (7.006)	prob 2.915 (2.901)	GS 33.281 (32.818)	mem 74.339
Train: [76][990/1500]	BT 0.039 (0.343)	DT 0.001 (0.305)	loss 6.991 (6.991)	prob 2.267 (2.855)	GS 38.219 (32.782)	mem 74.341
Train: [76][1000/1500]	BT 0.038 (0.340)	DT 0.001 (0.302)	loss 6.795 (6.986)	prob 3.242 (2.825)	GS 26.969 (32.842)	mem 74.341
Train: [76][1010/1500]	BT 0.026 (0.344)	DT 0.000 (0.307)	loss 7.334 (6.978)	prob 2.584 (2.651)	GS 33.797 (32.188)	mem 74.339
Train: [76][1020/1500]	BT 0.026 (0.341)	DT 0.000 (0.304)	loss 6.806 (6.938)	prob 2.577 (2.765)	GS 34.781 (31.738)	mem 74.341
Train: [76][1030/1500]	BT 0.030 (0.338)	DT 0.000 (0.301)	loss 6.768 (6.916)	prob 3.183 (2.809)	GS 36.297 (31.766)	mem 74.340
Train: [76][1040/1500]	BT 0.035 (0.345)	DT 0.001 (0.307)	loss 6.772 (6.934)	prob 3.119 (2.783)	GS 32.828 (31.868)	mem 74.341
Train: [76][1050/1500]	BT 0.027 (0.342)	DT 0.000 (0.304)	loss 6.912 (6.919)	prob 2.418 (2.784)	GS 33.109 (31.998)	mem 74.341
Train: [76][1060/1500]	BT 0.038 (0.341)	DT 0.001 (0.304)	loss 6.732 (6.925)	prob 1.992 (2.281)	GS 31.375 (34.022)	mem 74.342
Train: [76][1070/1500]	BT 0.031 (0.339)	DT 0.000 (0.302)	loss 6.901 (6.955)	prob 2.070 (2.362)	GS 33.344 (32.669)	mem 74.343
Train: [76][1080/1500]	BT 0.056 (0.336)	DT 0.004 (0.299)	loss 7.168 (6.936)	prob 2.346 (2.554)	GS 35.703 (33.303)	mem 74.343
Train: [76][1090/1500]	BT 0.033 (0.342)	DT 0.000 (0.305)	loss 6.813 (6.945)	prob 3.043 (2.565)	GS 35.062 (33.314)	mem 74.341
Train: [76][1100/1500]	BT 0.037 (0.340)	DT 0.001 (0.302)	loss 7.123 (6.943)	prob 3.019 (2.623)	GS 32.016 (33.235)	mem 74.343
Train: [76][1110/1500]	BT 0.028 (0.340)	DT 0.000 (0.303)	loss 6.872 (6.962)	prob 2.144 (2.400)	GS 33.750 (32.972)	mem 74.360
Train: [76][1120/1500]	BT 0.037 (0.338)	DT 0.001 (0.301)	loss 6.874 (6.920)	prob 2.670 (2.677)	GS 34.766 (33.490)	mem 74.361
Train: [76][1130/1500]	BT 0.037 (0.339)	DT 0.000 (0.302)	loss 6.873 (6.891)	prob 2.670 (2.682)	GS 36.469 (33.101)	mem 74.365
Train: [76][1140/1500]	BT 0.036 (0.336)	DT 0.001 (0.299)	loss 6.982 (6.935)	prob 2.627 (2.655)	GS 32.797 (33.216)	mem 74.366
Train: [76][1150/1500]	BT 0.037 (0.334)	DT 0.000 (0.296)	loss 7.087 (6.946)	prob 2.629 (2.583)	GS 33.500 (32.837)	mem 74.365
Train: [76][1160/1500]	BT 0.038 (0.335)	DT 0.001 (0.298)	loss 6.840 (6.865)	prob 2.689 (2.955)	GS 37.672 (33.400)	mem 74.370
Train: [76][1170/1500]	BT 0.036 (0.333)	DT 0.001 (0.295)	loss 6.859 (6.883)	prob 2.508 (2.858)	GS 35.828 (33.179)	mem 74.371
Train: [76][1180/1500]	BT 0.025 (0.333)	DT 0.000 (0.295)	loss 6.804 (6.903)	prob 2.275 (2.724)	GS 34.422 (32.922)	mem 74.372
Train: [76][1190/1500]	BT 0.038 (0.330)	DT 0.001 (0.293)	loss 6.764 (6.900)	prob 1.973 (2.646)	GS 30.406 (33.261)	mem 74.373
Train: [76][1200/1500]	BT 0.039 (0.328)	DT 0.001 (0.290)	loss 6.679 (6.901)	prob 2.808 (2.602)	GS 34.281 (33.220)	mem 74.373
Train: [76][1210/1500]	BT 0.037 (0.329)	DT 0.001 (0.292)	loss 6.874 (6.965)	prob 2.794 (2.550)	GS 36.344 (33.669)	mem 74.375
Train: [76][1220/1500]	BT 0.037 (0.327)	DT 0.001 (0.290)	loss 6.621 (6.924)	prob 2.815 (2.564)	GS 33.250 (33.243)	mem 74.375
Train: [76][1230/1500]	BT 0.032 (0.328)	DT 0.000 (0.291)	loss 6.967 (6.910)	prob 2.680 (2.631)	GS 36.000 (33.156)	mem 74.376
Train: [76][1240/1500]	BT 0.036 (0.326)	DT 0.000 (0.288)	loss 6.740 (6.902)	prob 3.191 (2.625)	GS 33.109 (32.955)	mem 74.377
Train: [76][1250/1500]	BT 0.032 (0.327)	DT 0.000 (0.289)	loss 6.925 (6.905)	prob 2.729 (2.634)	GS 31.406 (33.026)	mem 74.376
Train: [76][1260/1500]	BT 0.037 (0.324)	DT 0.001 (0.287)	loss 7.110 (6.877)	prob 1.705 (2.326)	GS 35.297 (33.220)	mem 74.378
Train: [76][1270/1500]	BT 0.052 (0.322)	DT 0.001 (0.285)	loss 7.055 (6.851)	prob 2.959 (2.421)	GS 31.922 (33.302)	mem 74.377
Train: [76][1280/1500]	BT 0.032 (0.322)	DT 0.000 (0.285)	loss 6.716 (6.851)	prob 2.532 (2.498)	GS 33.281 (32.781)	mem 74.379
Train: [76][1290/1500]	BT 0.038 (0.320)	DT 0.001 (0.283)	loss 6.914 (6.883)	prob 2.642 (2.478)	GS 32.906 (32.818)	mem 74.380
Train: [76][1300/1500]	BT 0.038 (0.321)	DT 0.000 (0.284)	loss 6.958 (6.890)	prob 3.175 (2.498)	GS 36.453 (32.958)	mem 74.378
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [76][1310/1500]	BT 0.037 (0.319)	DT 0.001 (0.282)	loss 6.819 (6.763)	prob 2.766 (2.947)	GS 37.391 (31.073)	mem 74.379
Train: [76][1320/1500]	BT 0.037 (0.317)	DT 0.000 (0.280)	loss 6.839 (6.806)	prob 2.734 (2.879)	GS 36.875 (32.486)	mem 74.380
Train: [76][1330/1500]	BT 0.026 (0.318)	DT 0.000 (0.281)	loss 6.910 (6.841)	prob 1.710 (2.812)	GS 31.078 (32.648)	mem 74.381
Train: [76][1340/1500]	BT 0.032 (0.316)	DT 0.000 (0.279)	loss 6.740 (6.860)	prob 3.079 (2.825)	GS 35.219 (32.315)	mem 74.382
Train: [76][1350/1500]	BT 0.030 (0.317)	DT 0.000 (0.280)	loss 6.863 (6.860)	prob 2.698 (2.807)	GS 36.516 (32.237)	mem 74.385
Train: [76][1360/1500]	BT 0.037 (0.315)	DT 0.000 (0.278)	loss 6.752 (6.837)	prob 2.989 (2.821)	GS 37.516 (31.828)	mem 74.386
Train: [76][1370/1500]	BT 0.030 (0.315)	DT 0.000 (0.278)	loss 6.782 (6.816)	prob 2.467 (2.793)	GS 32.219 (31.787)	mem 74.388
Train: [76][1380/1500]	BT 0.037 (0.313)	DT 0.000 (0.276)	loss 7.005 (6.823)	prob 2.195 (2.665)	GS 32.531 (31.861)	mem 74.394
Train: [76][1390/1500]	BT 0.037 (0.311)	DT 0.001 (0.274)	loss 6.720 (6.822)	prob 2.623 (2.723)	GS 35.859 (31.658)	mem 74.420
Train: [76][1400/1500]	BT 0.030 (0.314)	DT 0.000 (0.277)	loss 6.886 (6.823)	prob 3.035 (2.720)	GS 32.656 (31.952)	mem 74.419
Train: [76][1410/1500]	BT 0.027 (0.312)	DT 0.000 (0.275)	loss 6.832 (6.930)	prob 2.809 (3.032)	GS 36.281 (33.073)	mem 74.421
Train: [76][1420/1500]	BT 0.039 (0.312)	DT 0.001 (0.275)	loss 6.753 (6.873)	prob 2.873 (3.052)	GS 35.703 (32.709)	mem 74.423
Train: [76][1430/1500]	BT 0.039 (0.310)	DT 0.001 (0.273)	loss 6.939 (6.843)	prob 2.520 (2.915)	GS 34.672 (32.558)	mem 74.423
Train: [76][1440/1500]	BT 0.039 (0.308)	DT 0.001 (0.271)	loss 6.694 (6.837)	prob 3.314 (2.887)	GS 31.406 (32.659)	mem 74.423
Train: [76][1450/1500]	BT 0.046 (0.310)	DT 0.001 (0.273)	loss 6.922 (6.842)	prob 2.937 (2.855)	GS 33.781 (32.404)	mem 74.420
Train: [76][1460/1500]	BT 0.078 (0.308)	DT 0.011 (0.271)	loss 6.808 (6.873)	prob 2.442 (2.693)	GS 33.219 (31.856)	mem 74.420
Train: [76][1470/1500]	BT 0.020 (0.310)	DT 0.000 (0.273)	loss 6.780 (6.867)	prob 3.966 (2.868)	GS 31.594 (33.247)	mem 73.547
Train: [76][1480/1500]	BT 0.028 (0.308)	DT 0.000 (0.271)	loss 6.898 (6.865)	prob 3.573 (3.004)	GS 29.438 (33.253)	mem 73.511
Train: [76][1490/1500]	BT 0.024 (0.308)	DT 0.000 (0.271)	loss 6.652 (6.864)	prob 3.244 (3.024)	GS 39.969 (33.435)	mem 9.401
Train: [76][1500/1500]	BT 0.025 (0.306)	DT 0.000 (0.270)	loss 6.658 (6.863)	prob 2.268 (3.016)	GS 33.000 (33.434)	mem 9.401
Train: [76][1510/1500]	BT 0.025 (0.305)	DT 0.000 (0.268)	loss 6.770 (6.635)	prob 2.904 (2.959)	GS 35.781 (35.941)	mem 9.401
epoch 76, total time 460.93
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [77][1/1500]	BT 18.415 (18.415)	DT 18.358 (18.358)	loss 6.621 (6.621)	prob 3.349 (3.349)	GS 28.531 (28.531)	mem 72.865
Train: [77][10/1500]	BT 0.065 (2.297)	DT 0.014 (2.247)	loss 6.514 (6.620)	prob 3.006 (3.104)	GS 36.938 (33.399)	mem 73.059
Train: [77][20/1500]	BT 0.039 (1.378)	DT 0.001 (1.333)	loss 6.689 (6.681)	prob 3.414 (3.042)	GS 34.500 (34.382)	mem 73.112
Train: [77][30/1500]	BT 0.039 (0.967)	DT 0.001 (0.924)	loss 6.801 (6.705)	prob 2.956 (3.073)	GS 30.781 (33.571)	mem 73.114
Train: [77][40/1500]	BT 0.038 (0.802)	DT 0.001 (0.760)	loss 6.789 (6.726)	prob 2.762 (2.956)	GS 34.219 (33.090)	mem 73.125
Train: [77][50/1500]	BT 0.037 (0.669)	DT 0.001 (0.628)	loss 6.833 (6.750)	prob 2.673 (2.947)	GS 31.188 (32.846)	mem 73.140
Train: [77][60/1500]	BT 0.037 (0.565)	DT 0.000 (0.524)	loss 6.886 (6.808)	prob 3.379 (2.909)	GS 33.047 (31.247)	mem 73.141
Train: [77][70/1500]	BT 0.037 (0.527)	DT 0.001 (0.487)	loss 6.709 (6.844)	prob 4.342 (2.997)	GS 35.109 (31.712)	mem 73.156
Train: [77][80/1500]	BT 0.036 (0.503)	DT 0.001 (0.463)	loss 6.817 (6.839)	prob 3.280 (2.937)	GS 30.344 (31.510)	mem 73.163
Train: [77][90/1500]	BT 0.109 (0.470)	DT 0.026 (0.430)	loss 6.869 (6.845)	prob 3.543 (2.986)	GS 31.359 (31.671)	mem 73.167
Train: [77][100/1500]	BT 0.037 (0.472)	DT 0.001 (0.432)	loss 6.748 (6.838)	prob 2.267 (2.881)	GS 32.297 (31.832)	mem 73.180
Train: [77][110/1500]	BT 0.037 (0.432)	DT 0.001 (0.393)	loss 7.000 (6.828)	prob 2.591 (2.542)	GS 31.109 (31.492)	mem 73.180
Train: [77][120/1500]	BT 0.038 (0.403)	DT 0.001 (0.363)	loss 6.716 (6.818)	prob 2.941 (2.606)	GS 28.891 (31.336)	mem 73.182
Train: [77][130/1500]	BT 0.038 (0.393)	DT 0.001 (0.354)	loss 6.895 (6.825)	prob 2.736 (2.692)	GS 39.328 (32.253)	mem 73.080
Train: [77][140/1500]	BT 0.038 (0.381)	DT 0.001 (0.342)	loss 6.992 (6.832)	prob 3.085 (2.676)	GS 36.078 (32.383)	mem 73.084
Train: [77][150/1500]	BT 0.038 (0.365)	DT 0.001 (0.326)	loss 6.805 (6.821)	prob 2.627 (2.678)	GS 37.156 (32.552)	mem 73.085
Train: [77][160/1500]	BT 0.037 (0.362)	DT 0.000 (0.323)	loss 7.172 (6.867)	prob 2.429 (2.610)	GS 32.266 (32.752)	mem 73.089
Train: [77][170/1500]	BT 0.037 (0.342)	DT 0.001 (0.304)	loss 6.817 (6.858)	prob 3.160 (2.656)	GS 32.047 (33.005)	mem 73.090
Train: [77][180/1500]	BT 0.037 (0.328)	DT 0.000 (0.289)	loss 6.713 (6.832)	prob 2.117 (2.580)	GS 38.297 (32.666)	mem 73.090
Train: [77][190/1500]	BT 0.037 (0.336)	DT 0.001 (0.298)	loss 6.712 (6.812)	prob 3.399 (2.597)	GS 34.922 (32.295)	mem 73.094
Train: [77][200/1500]	BT 0.037 (0.321)	DT 0.001 (0.283)	loss 6.671 (6.796)	prob 2.713 (2.570)	GS 35.062 (32.483)	mem 73.094
Train: [77][210/1500]	BT 0.064 (0.329)	DT 0.004 (0.291)	loss 6.957 (6.798)	prob 2.818 (2.703)	GS 33.047 (31.714)	mem 73.097
Train: [77][220/1500]	BT 0.035 (0.317)	DT 0.000 (0.278)	loss 6.966 (6.792)	prob 2.614 (2.593)	GS 35.141 (32.497)	mem 73.097
Train: [77][230/1500]	BT 0.066 (0.326)	DT 0.016 (0.287)	loss 6.792 (6.817)	prob 2.726 (2.663)	GS 37.297 (33.111)	mem 73.099
Train: [77][240/1500]	BT 0.028 (0.362)	DT 0.000 (0.324)	loss 6.736 (6.826)	prob 2.934 (2.705)	GS 34.578 (33.414)	mem 73.120
Train: [77][250/1500]	BT 0.026 (0.349)	DT 0.000 (0.311)	loss 6.720 (6.816)	prob 2.875 (2.729)	GS 36.984 (33.486)	mem 73.122
Train: [77][260/1500]	BT 0.028 (0.348)	DT 0.000 (0.310)	loss 6.807 (6.822)	prob 2.141 (2.505)	GS 30.000 (31.350)	mem 73.812
Train: [77][270/1500]	BT 0.038 (0.337)	DT 0.001 (0.299)	loss 6.993 (6.804)	prob 2.282 (2.696)	GS 36.734 (32.427)	mem 73.814
Train: [77][280/1500]	BT 0.039 (0.326)	DT 0.001 (0.288)	loss 6.736 (6.784)	prob 2.638 (2.708)	GS 33.750 (32.759)	mem 73.832
Train: [77][290/1500]	BT 0.039 (0.328)	DT 0.001 (0.291)	loss 6.761 (6.783)	prob 3.161 (2.766)	GS 32.297 (32.396)	mem 74.259
Train: [77][300/1500]	BT 0.039 (0.319)	DT 0.001 (0.281)	loss 6.894 (6.781)	prob 2.568 (2.740)	GS 33.781 (32.285)	mem 74.259
Train: [77][310/1500]	BT 0.039 (0.322)	DT 0.000 (0.285)	loss 6.871 (6.794)	prob 3.248 (3.036)	GS 30.734 (31.681)	mem 74.309
Train: [77][320/1500]	BT 0.039 (0.314)	DT 0.001 (0.276)	loss 6.794 (6.792)	prob 3.376 (3.077)	GS 32.594 (31.523)	mem 74.310
Train: [77][330/1500]	BT 0.039 (0.320)	DT 0.000 (0.282)	loss 6.749 (6.788)	prob 3.365 (3.129)	GS 31.844 (32.117)	mem 74.312
Train: [77][340/1500]	BT 0.039 (0.312)	DT 0.001 (0.274)	loss 6.876 (6.804)	prob 2.924 (3.150)	GS 35.938 (32.300)	mem 74.312
Train: [77][350/1500]	BT 0.039 (0.305)	DT 0.001 (0.267)	loss 6.480 (6.792)	prob 3.068 (3.077)	GS 32.141 (32.201)	mem 74.313
Train: [77][360/1500]	BT 0.037 (0.318)	DT 0.003 (0.280)	loss 6.681 (6.799)	prob 2.467 (2.575)	GS 32.516 (33.547)	mem 74.314
Train: [77][370/1500]	BT 0.035 (0.310)	DT 0.000 (0.272)	loss 6.954 (6.790)	prob 3.456 (2.685)	GS 32.141 (32.823)	mem 74.314
Train: [77][380/1500]	BT 1.929 (0.310)	DT 1.860 (0.272)	loss 6.935 (6.812)	prob 2.715 (2.742)	GS 35.359 (32.958)	mem 74.314
Train: [77][390/1500]	BT 0.031 (0.340)	DT 0.000 (0.302)	loss 6.924 (6.827)	prob 3.029 (2.869)	GS 32.359 (33.016)	mem 74.315
Train: [77][400/1500]	BT 0.031 (0.333)	DT 0.000 (0.295)	loss 7.238 (6.837)	prob 2.493 (2.878)	GS 31.047 (32.991)	mem 74.315
Train: [77][410/1500]	BT 0.029 (0.346)	DT 0.000 (0.308)	loss 6.843 (6.806)	prob 2.954 (3.275)	GS 38.141 (33.048)	mem 74.316
Train: [77][420/1500]	BT 0.051 (0.339)	DT 0.000 (0.300)	loss 6.898 (6.808)	prob 2.528 (3.245)	GS 33.438 (32.515)	mem 74.318
Train: [77][430/1500]	BT 0.028 (0.358)	DT 0.000 (0.320)	loss 6.704 (6.813)	prob 2.511 (3.196)	GS 32.297 (32.281)	mem 74.337
Train: [77][440/1500]	BT 0.029 (0.350)	DT 0.000 (0.312)	loss 6.763 (6.813)	prob 2.998 (3.111)	GS 32.828 (32.525)	mem 74.339
Train: [77][450/1500]	BT 0.028 (0.355)	DT 0.000 (0.317)	loss 7.059 (6.810)	prob 2.774 (3.105)	GS 36.609 (32.545)	mem 74.345
Train: [77][460/1500]	BT 0.033 (0.348)	DT 0.000 (0.310)	loss 6.729 (6.819)	prob 2.984 (3.146)	GS 31.469 (32.230)	mem 74.345
Train: [77][470/1500]	BT 0.034 (0.341)	DT 0.001 (0.304)	loss 6.783 (6.799)	prob 1.874 (3.105)	GS 36.141 (32.216)	mem 74.344
Train: [77][480/1500]	BT 0.030 (0.344)	DT 0.000 (0.307)	loss 6.607 (6.797)	prob 3.244 (3.009)	GS 34.281 (31.926)	mem 74.347
Train: [77][490/1500]	BT 0.025 (0.338)	DT 0.000 (0.301)	loss 6.751 (6.794)	prob 1.915 (2.870)	GS 27.703 (31.930)	mem 74.347
Train: [77][500/1500]	BT 0.031 (0.337)	DT 0.000 (0.300)	loss 6.841 (6.795)	prob 2.162 (2.770)	GS 29.719 (31.978)	mem 74.351
Train: [77][510/1500]	BT 0.037 (0.331)	DT 0.001 (0.294)	loss 6.748 (6.771)	prob 2.525 (2.270)	GS 33.453 (31.505)	mem 74.351
Train: [77][520/1500]	BT 0.027 (0.335)	DT 0.000 (0.298)	loss 6.797 (6.787)	prob 2.694 (2.409)	GS 35.688 (32.089)	mem 74.353
Train: [77][530/1500]	BT 0.031 (0.329)	DT 0.000 (0.292)	loss 6.680 (6.779)	prob 2.614 (2.423)	GS 33.562 (32.419)	mem 74.353
Train: [77][540/1500]	BT 0.037 (0.323)	DT 0.001 (0.287)	loss 6.876 (6.773)	prob 2.472 (2.427)	GS 34.719 (32.350)	mem 74.356
Train: [77][550/1500]	BT 0.031 (0.324)	DT 0.000 (0.287)	loss 6.960 (6.768)	prob 1.615 (2.430)	GS 29.922 (32.443)	mem 74.359
Train: [77][560/1500]	BT 0.056 (0.319)	DT 0.011 (0.282)	loss 6.802 (6.733)	prob 2.054 (2.479)	GS 36.594 (32.777)	mem 74.359
Train: [77][570/1500]	BT 0.039 (0.322)	DT 0.001 (0.284)	loss 6.744 (6.744)	prob 1.846 (2.349)	GS 39.125 (33.720)	mem 74.361
Train: [77][580/1500]	BT 0.038 (0.317)	DT 0.001 (0.279)	loss 6.877 (6.742)	prob 2.305 (2.374)	GS 34.016 (33.137)	mem 74.361
Train: [77][590/1500]	BT 0.037 (0.312)	DT 0.001 (0.275)	loss 6.664 (6.746)	prob 2.078 (2.395)	GS 33.625 (33.237)	mem 74.361
Train: [77][600/1500]	BT 0.070 (0.319)	DT 0.011 (0.282)	loss 6.887 (6.743)	prob 2.088 (2.417)	GS 34.422 (33.180)	mem 74.364
Train: [77][610/1500]	BT 0.046 (0.315)	DT 0.016 (0.277)	loss 6.657 (6.723)	prob 2.804 (2.695)	GS 34.828 (33.047)	mem 74.364
Train: [77][620/1500]	BT 0.030 (0.326)	DT 0.000 (0.288)	loss 6.800 (6.749)	prob 2.801 (2.633)	GS 37.469 (33.535)	mem 74.366
Train: [77][630/1500]	BT 0.033 (0.321)	DT 0.000 (0.284)	loss 6.833 (6.756)	prob 3.522 (2.609)	GS 32.438 (33.477)	mem 74.365
Train: [77][640/1500]	BT 0.052 (0.325)	DT 0.006 (0.287)	loss 6.889 (6.753)	prob 1.803 (2.524)	GS 33.078 (33.248)	mem 74.365
Train: [77][650/1500]	BT 0.032 (0.320)	DT 0.000 (0.283)	loss 6.761 (6.748)	prob 2.466 (2.489)	GS 37.234 (33.152)	mem 74.366
Train: [77][660/1500]	BT 0.048 (0.316)	DT 0.006 (0.279)	loss 6.860 (6.745)	prob 2.021 (2.695)	GS 31.031 (31.870)	mem 74.367
Train: [77][670/1500]	BT 0.025 (0.322)	DT 0.000 (0.285)	loss 6.895 (6.750)	prob 2.205 (2.553)	GS 37.172 (32.416)	mem 74.368
Train: [77][680/1500]	BT 0.036 (0.318)	DT 0.001 (0.281)	loss 6.583 (6.759)	prob 2.640 (2.508)	GS 32.406 (32.332)	mem 74.369
Train: [77][690/1500]	BT 0.069 (0.321)	DT 0.025 (0.284)	loss 6.593 (6.757)	prob 2.114 (2.400)	GS 30.734 (32.355)	mem 74.370
Train: [77][700/1500]	BT 0.058 (0.317)	DT 0.011 (0.280)	loss 6.697 (6.762)	prob 2.421 (2.378)	GS 34.812 (32.294)	mem 74.370
Train: [77][710/1500]	BT 0.037 (0.313)	DT 0.000 (0.276)	loss 6.765 (6.744)	prob 2.378 (2.269)	GS 33.734 (33.002)	mem 74.370
Train: [77][720/1500]	BT 0.062 (0.317)	DT 0.012 (0.279)	loss 6.722 (6.733)	prob 2.376 (2.124)	GS 32.500 (32.848)	mem 74.370
Train: [77][730/1500]	BT 1.204 (0.315)	DT 1.167 (0.277)	loss 6.752 (6.746)	prob 2.197 (2.137)	GS 41.297 (32.804)	mem 74.372
Train: [77][740/1500]	BT 0.037 (0.316)	DT 0.001 (0.278)	loss 6.703 (6.740)	prob 2.195 (2.102)	GS 31.406 (32.232)	mem 74.372
Train: [77][750/1500]	BT 0.037 (0.312)	DT 0.000 (0.275)	loss 6.792 (6.754)	prob 2.255 (2.134)	GS 33.906 (32.148)	mem 74.373
Train: [77][760/1500]	BT 0.037 (0.314)	DT 0.000 (0.276)	loss 6.806 (6.756)	prob 2.221 (2.561)	GS 32.469 (31.880)	mem 74.374
Train: [77][770/1500]	BT 0.034 (0.310)	DT 0.000 (0.273)	loss 6.918 (6.768)	prob 2.331 (2.317)	GS 35.453 (32.583)	mem 74.374
Train: [77][780/1500]	BT 0.037 (0.307)	DT 0.001 (0.269)	loss 6.756 (6.759)	prob 2.776 (2.247)	GS 33.016 (32.230)	mem 74.377
Train: [77][790/1500]	BT 0.039 (0.307)	DT 0.001 (0.270)	loss 6.738 (6.763)	prob 2.269 (2.317)	GS 29.781 (31.878)	mem 74.405
Train: [77][800/1500]	BT 0.040 (0.304)	DT 0.001 (0.266)	loss 6.648 (6.751)	prob 2.016 (2.271)	GS 30.391 (31.847)	mem 74.405
Train: [77][810/1500]	BT 0.039 (0.304)	DT 0.001 (0.266)	loss 6.736 (6.756)	prob 1.928 (2.048)	GS 33.969 (32.383)	mem 74.406
Train: [77][820/1500]	BT 0.039 (0.301)	DT 0.001 (0.263)	loss 6.724 (6.741)	prob 2.146 (2.149)	GS 31.234 (31.936)	mem 74.407
Train: [77][830/1500]	BT 0.039 (0.301)	DT 0.001 (0.263)	loss 7.036 (6.787)	prob 2.955 (2.241)	GS 34.984 (32.097)	mem 74.408
Train: [77][840/1500]	BT 0.032 (0.301)	DT 0.000 (0.263)	loss 6.877 (6.776)	prob 1.485 (2.219)	GS 36.297 (31.915)	mem 74.408
Train: [77][850/1500]	BT 1.900 (0.301)	DT 1.862 (0.263)	loss 6.693 (6.772)	prob 2.292 (2.273)	GS 35.500 (32.101)	mem 74.408
Train: [77][860/1500]	BT 0.027 (0.308)	DT 0.000 (0.270)	loss 6.749 (6.735)	prob 1.814 (2.361)	GS 34.656 (34.653)	mem 74.406
Train: [77][870/1500]	BT 0.039 (0.305)	DT 0.001 (0.267)	loss 6.755 (6.738)	prob 2.417 (2.504)	GS 33.859 (34.485)	mem 74.406
Train: [77][880/1500]	BT 0.039 (0.302)	DT 0.001 (0.264)	loss 6.738 (6.739)	prob 2.131 (2.422)	GS 34.031 (34.217)	mem 74.407
Train: [77][890/1500]	BT 0.052 (0.302)	DT 0.003 (0.265)	loss 6.794 (6.750)	prob 1.993 (2.397)	GS 32.562 (34.097)	mem 74.409
Train: [77][900/1500]	BT 0.066 (0.300)	DT 0.015 (0.262)	loss 6.726 (6.760)	prob 2.425 (2.365)	GS 33.188 (33.764)	mem 74.409
Train: [77][910/1500]	BT 0.039 (0.305)	DT 0.001 (0.267)	loss 6.698 (6.749)	prob 2.051 (2.344)	GS 36.875 (32.739)	mem 74.408
Train: [77][920/1500]	BT 0.039 (0.302)	DT 0.001 (0.264)	loss 6.732 (6.748)	prob 1.945 (2.340)	GS 35.094 (32.924)	mem 74.408
Train: [77][930/1500]	BT 0.039 (0.301)	DT 0.001 (0.263)	loss 6.730 (6.746)	prob 2.732 (2.343)	GS 32.125 (32.923)	mem 74.409
Train: [77][940/1500]	BT 0.031 (0.301)	DT 0.000 (0.263)	loss 6.761 (6.737)	prob 2.483 (2.349)	GS 30.703 (32.641)	mem 74.410
Train: [77][950/1500]	BT 0.052 (0.298)	DT 0.002 (0.260)	loss 6.871 (6.741)	prob 2.212 (2.351)	GS 32.594 (32.403)	mem 74.411
Train: [77][960/1500]	BT 0.066 (0.303)	DT 0.015 (0.264)	loss 6.595 (6.688)	prob 2.563 (2.344)	GS 32.844 (31.883)	mem 74.411
Train: [77][970/1500]	BT 0.034 (0.300)	DT 0.000 (0.262)	loss 6.671 (6.675)	prob 2.326 (2.392)	GS 29.312 (32.794)	mem 74.412
Train: [77][980/1500]	BT 0.048 (0.306)	DT 0.000 (0.267)	loss 6.926 (6.724)	prob 2.575 (2.332)	GS 36.391 (33.170)	mem 74.411
Train: [77][990/1500]	BT 0.053 (0.303)	DT 0.003 (0.265)	loss 6.550 (6.709)	prob 2.339 (2.333)	GS 35.828 (32.905)	mem 74.411
Train: [77][1000/1500]	BT 0.049 (0.303)	DT 0.003 (0.264)	loss 6.756 (6.716)	prob 3.042 (2.367)	GS 31.094 (33.110)	mem 74.410
Train: [77][1010/1500]	BT 0.049 (0.304)	DT 0.003 (0.266)	loss 6.572 (6.689)	prob 2.321 (2.417)	GS 29.547 (31.805)	mem 74.414
Train: [77][1020/1500]	BT 0.026 (0.319)	DT 0.000 (0.280)	loss 6.801 (6.703)	prob 2.894 (2.473)	GS 33.609 (32.523)	mem 74.412
Train: [77][1030/1500]	BT 0.030 (0.316)	DT 0.000 (0.277)	loss 6.974 (6.714)	prob 2.113 (2.488)	GS 31.000 (32.938)	mem 74.413
Train: [77][1040/1500]	BT 0.037 (0.313)	DT 0.001 (0.275)	loss 6.606 (6.707)	prob 2.954 (2.582)	GS 36.312 (32.963)	mem 74.414
Train: [77][1050/1500]	BT 0.032 (0.316)	DT 0.000 (0.278)	loss 6.783 (6.707)	prob 2.453 (2.534)	GS 33.750 (32.991)	mem 74.415
Train: [77][1060/1500]	BT 0.039 (0.314)	DT 0.001 (0.275)	loss 6.725 (6.750)	prob 2.378 (2.618)	GS 33.344 (32.820)	mem 74.417
Train: [77][1070/1500]	BT 0.031 (0.315)	DT 0.000 (0.277)	loss 6.768 (6.747)	prob 2.487 (2.724)	GS 30.188 (32.930)	mem 74.416
Train: [77][1080/1500]	BT 0.031 (0.312)	DT 0.001 (0.274)	loss 6.742 (6.737)	prob 2.594 (2.611)	GS 36.750 (33.307)	mem 74.416
Train: [77][1090/1500]	BT 0.038 (0.317)	DT 0.001 (0.279)	loss 6.719 (6.726)	prob 2.182 (2.605)	GS 32.672 (33.357)	mem 74.412
Train: [77][1100/1500]	BT 0.036 (0.314)	DT 0.000 (0.276)	loss 6.717 (6.724)	prob 2.285 (2.632)	GS 34.688 (33.281)	mem 74.415
Train: [77][1110/1500]	BT 0.037 (0.312)	DT 0.000 (0.274)	loss 6.829 (6.778)	prob 2.661 (2.881)	GS 30.375 (31.533)	mem 74.419
Train: [77][1120/1500]	BT 0.034 (0.314)	DT 0.000 (0.275)	loss 6.646 (6.714)	prob 2.605 (2.694)	GS 30.547 (31.906)	mem 74.432
Train: [77][1130/1500]	BT 0.037 (0.311)	DT 0.000 (0.273)	loss 6.704 (6.707)	prob 2.257 (2.658)	GS 37.328 (32.201)	mem 74.433
Train: [77][1140/1500]	BT 0.030 (0.312)	DT 0.000 (0.274)	loss 6.677 (6.706)	prob 2.405 (2.687)	GS 33.781 (32.202)	mem 74.334
Train: [77][1150/1500]	BT 0.036 (0.310)	DT 0.000 (0.272)	loss 6.708 (6.702)	prob 2.283 (2.647)	GS 28.359 (32.078)	mem 74.336
Train: [77][1160/1500]	BT 0.073 (0.308)	DT 0.005 (0.269)	loss 6.701 (6.673)	prob 2.513 (2.671)	GS 28.469 (31.747)	mem 74.336
Train: [77][1170/1500]	BT 0.027 (0.311)	DT 0.000 (0.273)	loss 6.636 (6.692)	prob 3.401 (2.736)	GS 34.156 (32.370)	mem 74.332
Train: [77][1180/1500]	BT 0.035 (0.309)	DT 0.000 (0.271)	loss 6.759 (6.703)	prob 2.172 (2.673)	GS 35.266 (32.679)	mem 74.333
Train: [77][1190/1500]	BT 0.037 (0.312)	DT 0.000 (0.274)	loss 6.680 (6.719)	prob 2.857 (2.609)	GS 32.875 (32.480)	mem 74.334
Train: [77][1200/1500]	BT 0.031 (0.310)	DT 0.000 (0.271)	loss 6.640 (6.717)	prob 2.993 (2.620)	GS 33.859 (32.642)	mem 74.335
Train: [77][1210/1500]	BT 0.035 (0.316)	DT 0.000 (0.278)	loss 6.636 (6.707)	prob 2.545 (2.499)	GS 31.422 (33.161)	mem 74.337
Train: [77][1220/1500]	BT 0.036 (0.314)	DT 0.000 (0.276)	loss 6.820 (6.710)	prob 2.322 (2.472)	GS 34.797 (32.803)	mem 74.337
Train: [77][1230/1500]	BT 0.030 (0.318)	DT 0.000 (0.280)	loss 6.760 (6.698)	prob 2.077 (2.576)	GS 35.500 (33.844)	mem 74.344
Train: [77][1240/1500]	BT 0.028 (0.316)	DT 0.000 (0.277)	loss 6.565 (6.705)	prob 2.893 (2.619)	GS 34.359 (33.788)	mem 74.348
Train: [77][1250/1500]	BT 0.031 (0.316)	DT 0.001 (0.277)	loss 6.597 (6.688)	prob 2.914 (2.596)	GS 33.219 (33.449)	mem 74.351
Train: [77][1260/1500]	BT 0.038 (0.313)	DT 0.001 (0.275)	loss 6.794 (6.630)	prob 2.683 (2.617)	GS 32.672 (31.284)	mem 74.352
Train: [77][1270/1500]	BT 0.054 (0.311)	DT 0.001 (0.273)	loss 6.520 (6.643)	prob 2.567 (2.581)	GS 32.453 (31.384)	mem 74.351
Train: [77][1280/1500]	BT 0.028 (0.313)	DT 0.001 (0.275)	loss 6.623 (6.649)	prob 2.326 (2.548)	GS 30.062 (31.834)	mem 74.349
Train: [77][1290/1500]	BT 0.025 (0.311)	DT 0.000 (0.272)	loss 6.661 (6.652)	prob 3.008 (2.546)	GS 36.297 (31.978)	mem 74.351
Train: [77][1300/1500]	BT 0.038 (0.311)	DT 0.001 (0.273)	loss 6.968 (6.663)	prob 1.792 (2.539)	GS 34.156 (31.896)	mem 74.351
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [77][1310/1500]	BT 0.039 (0.309)	DT 0.001 (0.271)	loss 6.610 (6.632)	prob 2.604 (2.638)	GS 30.531 (31.773)	mem 74.352
Train: [77][1320/1500]	BT 2.233 (0.309)	DT 2.168 (0.271)	loss 6.496 (6.639)	prob 2.810 (2.419)	GS 36.406 (31.881)	mem 74.353
Train: [77][1330/1500]	BT 0.038 (0.312)	DT 0.000 (0.273)	loss 6.653 (6.636)	prob 2.461 (2.508)	GS 34.109 (31.307)	mem 74.352
Train: [77][1340/1500]	BT 0.038 (0.310)	DT 0.001 (0.271)	loss 6.581 (6.639)	prob 2.399 (2.569)	GS 35.969 (31.716)	mem 74.352
Train: [77][1350/1500]	BT 0.029 (0.310)	DT 0.000 (0.271)	loss 6.562 (6.636)	prob 3.406 (2.607)	GS 35.156 (31.958)	mem 74.351
Train: [77][1360/1500]	BT 0.039 (0.309)	DT 0.001 (0.271)	loss 6.567 (6.665)	prob 2.927 (2.801)	GS 33.969 (32.420)	mem 74.352
Train: [77][1370/1500]	BT 0.038 (0.309)	DT 0.001 (0.271)	loss 6.639 (6.665)	prob 2.810 (2.699)	GS 36.609 (33.093)	mem 74.352
Train: [77][1380/1500]	BT 0.042 (0.309)	DT 0.001 (0.271)	loss 6.700 (6.663)	prob 1.987 (2.554)	GS 36.078 (32.277)	mem 74.351
Train: [77][1390/1500]	BT 0.039 (0.307)	DT 0.001 (0.269)	loss 6.650 (6.645)	prob 3.469 (2.645)	GS 33.688 (32.467)	mem 74.351
Train: [77][1400/1500]	BT 0.040 (0.305)	DT 0.001 (0.267)	loss 6.682 (6.646)	prob 2.165 (2.570)	GS 34.172 (32.661)	mem 74.351
Train: [77][1410/1500]	BT 0.047 (0.306)	DT 0.000 (0.267)	loss 6.756 (6.644)	prob 3.184 (2.597)	GS 35.203 (31.573)	mem 74.362
Train: [77][1420/1500]	BT 0.078 (0.306)	DT 0.011 (0.267)	loss 6.699 (6.667)	prob 1.893 (2.614)	GS 40.516 (32.134)	mem 74.364
Train: [77][1430/1500]	BT 0.027 (0.308)	DT 0.000 (0.270)	loss 6.752 (6.665)	prob 2.139 (2.543)	GS 40.781 (32.809)	mem 74.368
Train: [77][1440/1500]	BT 0.037 (0.306)	DT 0.001 (0.268)	loss 6.749 (6.672)	prob 2.198 (2.528)	GS 32.578 (32.721)	mem 74.369
Train: [77][1450/1500]	BT 0.040 (0.310)	DT 0.010 (0.272)	loss 6.740 (6.664)	prob 2.604 (2.551)	GS 31.828 (32.571)	mem 74.224
Train: [77][1460/1500]	BT 0.060 (0.309)	DT 0.001 (0.270)	loss 6.646 (6.628)	prob 1.631 (2.183)	GS 30.609 (32.281)	mem 74.152
Train: [77][1470/1500]	BT 0.035 (0.312)	DT 0.001 (0.273)	loss 6.665 (6.648)	prob 2.125 (2.266)	GS 35.047 (33.474)	mem 12.160
Train: [77][1480/1500]	BT 0.027 (0.310)	DT 0.000 (0.272)	loss 6.595 (6.652)	prob 3.281 (2.381)	GS 35.672 (32.956)	mem 12.160
Train: [77][1490/1500]	BT 0.025 (0.309)	DT 0.000 (0.270)	loss 6.699 (6.655)	prob 2.165 (2.436)	GS 35.625 (32.920)	mem 12.161
Train: [77][1500/1500]	BT 0.038 (0.307)	DT 0.000 (0.268)	loss 6.406 (6.644)	prob 1.790 (2.398)	GS 38.062 (32.909)	mem 12.088
Train: [77][1510/1500]	BT 0.020 (0.305)	DT 0.000 (0.267)	loss 6.438 (6.414)	prob 3.010 (2.543)	GS 32.688 (33.038)	mem 9.277
epoch 77, total time 461.22
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [78][1/1500]	BT 18.583 (18.583)	DT 18.484 (18.484)	loss 6.213 (6.213)	prob 3.346 (3.346)	GS 32.641 (32.641)	mem 72.874
Train: [78][10/1500]	BT 0.028 (2.355)	DT 0.000 (2.315)	loss 6.517 (6.295)	prob 2.591 (2.513)	GS 35.453 (34.080)	mem 73.121
Train: [78][20/1500]	BT 0.034 (1.194)	DT 0.000 (1.158)	loss 6.506 (6.405)	prob 2.521 (2.498)	GS 34.781 (33.352)	mem 73.124
Train: [78][30/1500]	BT 0.462 (0.895)	DT 0.425 (0.859)	loss 6.734 (6.435)	prob 2.659 (2.490)	GS 31.281 (32.904)	mem 73.145
Train: [78][40/1500]	BT 0.037 (0.767)	DT 0.000 (0.730)	loss 6.569 (6.469)	prob 2.629 (2.488)	GS 34.078 (32.814)	mem 73.176
Train: [78][50/1500]	BT 0.071 (0.621)	DT 0.033 (0.585)	loss 6.817 (6.508)	prob 3.374 (2.525)	GS 31.312 (32.962)	mem 73.178
Train: [78][60/1500]	BT 0.043 (0.637)	DT 0.013 (0.601)	loss 6.616 (6.600)	prob 1.459 (2.400)	GS 34.531 (32.545)	mem 73.194
Train: [78][70/1500]	BT 0.036 (0.551)	DT 0.000 (0.515)	loss 6.596 (6.621)	prob 2.996 (2.424)	GS 34.141 (32.100)	mem 73.195
Train: [78][80/1500]	BT 0.038 (0.491)	DT 0.001 (0.456)	loss 6.731 (6.621)	prob 2.464 (2.468)	GS 33.938 (32.563)	mem 73.197
Train: [78][90/1500]	BT 0.036 (0.484)	DT 0.001 (0.450)	loss 6.538 (6.623)	prob 1.786 (2.429)	GS 33.547 (32.685)	mem 73.216
Train: [78][100/1500]	BT 0.037 (0.440)	DT 0.001 (0.405)	loss 6.532 (6.625)	prob 2.402 (2.425)	GS 36.922 (32.863)	mem 73.218
Train: [78][110/1500]	BT 0.036 (0.449)	DT 0.001 (0.413)	loss 6.759 (6.623)	prob 2.050 (2.487)	GS 33.500 (32.916)	mem 73.234
Train: [78][120/1500]	BT 0.037 (0.414)	DT 0.001 (0.379)	loss 6.754 (6.647)	prob 2.000 (2.571)	GS 33.250 (32.879)	mem 73.234
Train: [78][130/1500]	BT 0.038 (0.386)	DT 0.001 (0.350)	loss 6.639 (6.638)	prob 3.044 (2.661)	GS 29.922 (32.566)	mem 73.235
Train: [78][140/1500]	BT 0.037 (0.379)	DT 0.001 (0.344)	loss 6.528 (6.629)	prob 2.935 (2.588)	GS 30.734 (32.606)	mem 73.243
Train: [78][150/1500]	BT 1.580 (0.367)	DT 1.549 (0.331)	loss 6.531 (6.627)	prob 2.419 (2.570)	GS 31.453 (32.473)	mem 73.272
Train: [78][160/1500]	BT 0.039 (0.376)	DT 0.001 (0.341)	loss 6.543 (6.645)	prob 2.669 (2.304)	GS 30.484 (30.891)	mem 73.277
Train: [78][170/1500]	BT 0.037 (0.356)	DT 0.001 (0.321)	loss 6.879 (6.624)	prob 2.010 (2.329)	GS 34.859 (32.505)	mem 73.277
Train: [78][180/1500]	BT 0.039 (0.354)	DT 0.001 (0.318)	loss 6.996 (6.647)	prob 1.642 (2.225)	GS 37.859 (32.467)	mem 73.282
Train: [78][190/1500]	BT 0.039 (0.337)	DT 0.001 (0.301)	loss 6.438 (6.636)	prob 2.763 (2.290)	GS 38.781 (32.343)	mem 73.283
Train: [78][200/1500]	BT 0.038 (0.322)	DT 0.001 (0.286)	loss 6.744 (6.634)	prob 2.368 (2.313)	GS 30.125 (32.158)	mem 73.283
Train: [78][210/1500]	BT 0.039 (0.325)	DT 0.001 (0.289)	loss 6.423 (6.590)	prob 3.222 (2.745)	GS 31.609 (32.622)	mem 73.285
Train: [78][220/1500]	BT 0.054 (0.312)	DT 0.011 (0.276)	loss 6.730 (6.609)	prob 2.598 (2.569)	GS 32.656 (33.079)	mem 73.286
Train: [78][230/1500]	BT 0.038 (0.327)	DT 0.001 (0.290)	loss 6.624 (6.613)	prob 3.062 (2.528)	GS 28.141 (32.889)	mem 73.289
Train: [78][240/1500]	BT 0.029 (0.322)	DT 0.000 (0.286)	loss 6.835 (6.628)	prob 1.751 (2.543)	GS 35.906 (33.226)	mem 73.288
Train: [78][250/1500]	BT 0.029 (0.311)	DT 0.000 (0.274)	loss 6.867 (6.625)	prob 1.502 (2.554)	GS 33.750 (33.171)	mem 73.288
Train: [78][260/1500]	BT 3.205 (0.319)	DT 3.169 (0.283)	loss 6.777 (6.659)	prob 1.608 (2.182)	GS 30.281 (31.897)	mem 73.291
Train: [78][270/1500]	BT 0.039 (0.309)	DT 0.001 (0.273)	loss 6.855 (6.651)	prob 1.913 (2.170)	GS 33.484 (32.169)	mem 73.291
Train: [78][280/1500]	BT 0.074 (0.306)	DT 0.011 (0.269)	loss 6.748 (6.646)	prob 1.377 (2.215)	GS 35.516 (32.410)	mem 73.292
Train: [78][290/1500]	BT 0.033 (0.308)	DT 0.000 (0.271)	loss 6.650 (6.646)	prob 2.896 (2.310)	GS 29.516 (32.375)	mem 73.735
Train: [78][300/1500]	BT 0.038 (0.300)	DT 0.000 (0.263)	loss 6.650 (6.647)	prob 1.841 (2.324)	GS 33.766 (32.334)	mem 73.787
Train: [78][310/1500]	BT 0.040 (0.305)	DT 0.000 (0.268)	loss 6.594 (6.676)	prob 2.931 (2.308)	GS 31.266 (31.431)	mem 74.379
Train: [78][320/1500]	BT 0.029 (0.296)	DT 0.000 (0.260)	loss 6.719 (6.649)	prob 3.005 (2.488)	GS 33.875 (31.990)	mem 74.381
Train: [78][330/1500]	BT 0.039 (0.288)	DT 0.001 (0.252)	loss 6.672 (6.662)	prob 2.021 (2.513)	GS 33.094 (31.766)	mem 74.383
Train: [78][340/1500]	BT 0.025 (0.298)	DT 0.000 (0.262)	loss 6.721 (6.662)	prob 2.912 (2.546)	GS 35.594 (32.178)	mem 74.480
Train: [78][350/1500]	BT 0.030 (0.290)	DT 0.000 (0.254)	loss 6.719 (6.671)	prob 3.525 (2.610)	GS 36.812 (32.725)	mem 74.482
Train: [78][360/1500]	BT 0.037 (0.291)	DT 0.000 (0.255)	loss 6.656 (6.667)	prob 2.816 (2.978)	GS 31.844 (32.466)	mem 74.483
Train: [78][370/1500]	BT 0.027 (0.284)	DT 0.000 (0.248)	loss 6.667 (6.670)	prob 2.144 (2.738)	GS 32.703 (32.125)	mem 74.485
Train: [78][380/1500]	BT 2.861 (0.288)	DT 2.824 (0.252)	loss 6.609 (6.661)	prob 2.694 (2.741)	GS 34.484 (32.476)	mem 74.501
Train: [78][390/1500]	BT 0.037 (0.281)	DT 0.000 (0.245)	loss 6.566 (6.649)	prob 3.259 (2.665)	GS 33.156 (32.697)	mem 74.501
Train: [78][400/1500]	BT 0.028 (0.280)	DT 0.000 (0.244)	loss 6.592 (6.651)	prob 3.170 (2.712)	GS 33.422 (32.761)	mem 74.497
Train: [78][410/1500]	BT 0.036 (0.278)	DT 0.000 (0.242)	loss 6.642 (6.734)	prob 2.658 (2.437)	GS 33.031 (32.381)	mem 74.401
Train: [78][420/1500]	BT 0.051 (0.283)	DT 0.006 (0.248)	loss 6.732 (6.700)	prob 1.980 (2.564)	GS 34.203 (32.735)	mem 74.401
Train: [78][430/1500]	BT 0.035 (0.277)	DT 0.000 (0.242)	loss 6.687 (6.701)	prob 2.226 (2.499)	GS 33.594 (32.399)	mem 74.402
Train: [78][440/1500]	BT 0.061 (0.273)	DT 0.008 (0.236)	loss 6.914 (6.709)	prob 2.349 (2.508)	GS 35.016 (32.586)	mem 74.402
Train: [78][450/1500]	BT 0.031 (0.286)	DT 0.000 (0.250)	loss 6.646 (6.713)	prob 3.009 (2.539)	GS 38.562 (33.162)	mem 74.403
Train: [78][460/1500]	BT 0.061 (0.281)	DT 0.003 (0.245)	loss 6.795 (6.768)	prob 2.947 (2.613)	GS 31.219 (32.677)	mem 74.403
Train: [78][470/1500]	BT 0.020 (0.305)	DT 0.000 (0.268)	loss 6.836 (6.734)	prob 2.874 (2.644)	GS 34.516 (32.751)	mem 74.423
Train: [78][480/1500]	BT 0.037 (0.299)	DT 0.001 (0.263)	loss 6.784 (6.731)	prob 2.637 (2.691)	GS 34.922 (32.605)	mem 74.411
Train: [78][490/1500]	BT 0.031 (0.304)	DT 0.001 (0.268)	loss 7.149 (6.753)	prob 2.311 (2.655)	GS 31.656 (32.802)	mem 74.413
Train: [78][500/1500]	BT 0.035 (0.299)	DT 0.000 (0.263)	loss 7.032 (6.750)	prob 2.652 (2.699)	GS 31.578 (32.773)	mem 74.413
Train: [78][510/1500]	BT 0.064 (0.294)	DT 0.005 (0.258)	loss 6.910 (6.746)	prob 1.688 (2.622)	GS 36.391 (32.403)	mem 74.414
Train: [78][520/1500]	BT 0.028 (0.311)	DT 0.000 (0.275)	loss 6.644 (6.741)	prob 1.907 (2.453)	GS 29.984 (32.073)	mem 74.414
Train: [78][530/1500]	BT 0.034 (0.306)	DT 0.000 (0.270)	loss 6.823 (6.756)	prob 3.096 (2.499)	GS 37.172 (32.120)	mem 74.415
Train: [78][540/1500]	BT 0.031 (0.309)	DT 0.000 (0.273)	loss 6.732 (6.740)	prob 2.808 (2.606)	GS 34.859 (32.108)	mem 74.418
Train: [78][550/1500]	BT 0.065 (0.305)	DT 0.002 (0.268)	loss 6.835 (6.754)	prob 2.877 (2.615)	GS 34.562 (32.223)	mem 74.420
Train: [78][560/1500]	BT 0.034 (0.300)	DT 0.001 (0.263)	loss 6.830 (6.765)	prob 2.223 (2.423)	GS 32.609 (32.006)	mem 74.419
Train: [78][570/1500]	BT 0.086 (0.313)	DT 0.009 (0.276)	loss 6.926 (6.780)	prob 2.456 (2.478)	GS 33.562 (32.369)	mem 74.420
Train: [78][580/1500]	BT 0.029 (0.335)	DT 0.000 (0.298)	loss 7.066 (6.785)	prob 2.987 (2.549)	GS 33.641 (32.998)	mem 74.420
Train: [78][590/1500]	BT 0.026 (0.330)	DT 0.000 (0.293)	loss 6.622 (6.778)	prob 2.401 (2.572)	GS 32.172 (32.959)	mem 74.421
Train: [78][600/1500]	BT 2.727 (0.330)	DT 2.688 (0.292)	loss 6.911 (6.776)	prob 2.279 (2.545)	GS 31.719 (32.924)	mem 74.422
Train: [78][610/1500]	BT 0.039 (0.325)	DT 0.001 (0.288)	loss 7.026 (6.846)	prob 2.451 (2.651)	GS 31.641 (31.113)	mem 74.421
Train: [78][620/1500]	BT 0.039 (0.320)	DT 0.001 (0.283)	loss 6.632 (6.800)	prob 2.966 (2.581)	GS 35.984 (32.246)	mem 74.421
Train: [78][630/1500]	BT 0.038 (0.320)	DT 0.001 (0.283)	loss 6.785 (6.807)	prob 2.530 (2.561)	GS 27.234 (31.913)	mem 74.421
Train: [78][640/1500]	BT 0.039 (0.316)	DT 0.001 (0.278)	loss 6.851 (6.799)	prob 1.731 (2.544)	GS 29.641 (31.336)	mem 74.421
Train: [78][650/1500]	BT 0.033 (0.323)	DT 0.001 (0.285)	loss 6.883 (6.802)	prob 2.850 (2.548)	GS 33.172 (31.468)	mem 74.421
Train: [78][660/1500]	BT 0.029 (0.323)	DT 0.000 (0.285)	loss 6.674 (6.774)	prob 2.184 (2.586)	GS 32.422 (33.702)	mem 74.423
Train: [78][670/1500]	BT 0.039 (0.318)	DT 0.001 (0.281)	loss 6.998 (6.790)	prob 2.822 (2.464)	GS 38.234 (32.788)	mem 74.424
Train: [78][680/1500]	BT 0.039 (0.317)	DT 0.001 (0.279)	loss 6.694 (6.793)	prob 2.699 (2.532)	GS 30.703 (32.671)	mem 74.424
Train: [78][690/1500]	BT 0.037 (0.314)	DT 0.001 (0.277)	loss 6.739 (6.841)	prob 3.193 (2.599)	GS 33.906 (32.521)	mem 74.436
Train: [78][700/1500]	BT 0.027 (0.316)	DT 0.000 (0.278)	loss 6.764 (6.848)	prob 2.304 (2.644)	GS 35.562 (32.632)	mem 74.440
Train: [78][710/1500]	BT 0.037 (0.312)	DT 0.000 (0.275)	loss 6.816 (6.843)	prob 2.876 (2.502)	GS 32.750 (31.245)	mem 74.441
Train: [78][720/1500]	BT 4.182 (0.315)	DT 4.150 (0.278)	loss 6.651 (6.843)	prob 2.687 (2.460)	GS 32.094 (31.902)	mem 74.445
Train: [78][730/1500]	BT 0.054 (0.311)	DT 0.009 (0.274)	loss 6.852 (6.857)	prob 2.051 (2.516)	GS 33.531 (31.893)	mem 74.445
Train: [78][740/1500]	BT 0.087 (0.309)	DT 0.007 (0.272)	loss 7.053 (6.897)	prob 2.130 (2.430)	GS 34.969 (32.155)	mem 74.446
Train: [78][750/1500]	BT 0.073 (0.317)	DT 0.012 (0.279)	loss 6.737 (6.893)	prob 2.752 (2.452)	GS 35.953 (32.204)	mem 74.449
Train: [78][760/1500]	BT 0.031 (0.313)	DT 0.000 (0.276)	loss 6.958 (6.895)	prob 2.843 (2.648)	GS 34.078 (32.811)	mem 74.448
Train: [78][770/1500]	BT 0.028 (0.329)	DT 0.000 (0.291)	loss 6.970 (6.860)	prob 1.864 (2.512)	GS 32.641 (32.592)	mem 74.450
Train: [78][780/1500]	BT 0.030 (0.325)	DT 0.000 (0.288)	loss 7.043 (6.866)	prob 2.146 (2.454)	GS 30.734 (32.508)	mem 74.450
Train: [78][790/1500]	BT 0.025 (0.321)	DT 0.000 (0.284)	loss 6.863 (6.868)	prob 2.913 (2.555)	GS 30.812 (32.575)	mem 74.451
Train: [78][800/1500]	BT 0.037 (0.321)	DT 0.001 (0.284)	loss 6.870 (6.880)	prob 2.347 (2.513)	GS 35.797 (32.605)	mem 74.453
Train: [78][810/1500]	BT 0.024 (0.317)	DT 0.000 (0.280)	loss 6.875 (6.930)	prob 2.126 (1.920)	GS 35.078 (32.331)	mem 74.456
Train: [78][820/1500]	BT 0.038 (0.318)	DT 0.001 (0.281)	loss 6.814 (6.899)	prob 2.157 (1.950)	GS 31.875 (32.400)	mem 74.457
Train: [78][830/1500]	BT 0.038 (0.314)	DT 0.000 (0.277)	loss 6.960 (6.939)	prob 2.524 (2.117)	GS 32.984 (32.428)	mem 74.456
Train: [78][840/1500]	BT 1.349 (0.316)	DT 1.314 (0.279)	loss 7.078 (6.938)	prob 2.359 (2.149)	GS 31.750 (32.307)	mem 74.459
Train: [78][850/1500]	BT 0.036 (0.312)	DT 0.000 (0.275)	loss 6.732 (6.920)	prob 2.185 (2.211)	GS 28.047 (32.209)	mem 74.459
Train: [78][860/1500]	BT 0.096 (0.309)	DT 0.047 (0.272)	loss 6.878 (7.003)	prob 2.427 (2.185)	GS 34.922 (32.802)	mem 74.461
Train: [78][870/1500]	BT 0.026 (0.315)	DT 0.000 (0.278)	loss 7.039 (7.057)	prob 2.570 (2.193)	GS 35.688 (33.663)	mem 74.462
Train: [78][880/1500]	BT 0.041 (0.311)	DT 0.001 (0.274)	loss 7.216 (7.053)	prob 1.865 (2.146)	GS 35.641 (33.684)	mem 74.462
Train: [78][890/1500]	BT 0.038 (0.312)	DT 0.001 (0.275)	loss 7.090 (7.045)	prob 2.174 (2.067)	GS 32.625 (33.363)	mem 74.462
Train: [78][900/1500]	BT 0.036 (0.312)	DT 0.000 (0.275)	loss 6.914 (7.039)	prob 3.006 (2.114)	GS 33.859 (33.161)	mem 74.463
Train: [78][910/1500]	BT 0.037 (0.309)	DT 0.001 (0.272)	loss 6.886 (6.944)	prob 1.975 (2.190)	GS 32.578 (31.080)	mem 74.463
Train: [78][920/1500]	BT 0.037 (0.309)	DT 0.001 (0.272)	loss 6.724 (6.972)	prob 2.279 (2.138)	GS 35.391 (31.441)	mem 74.466
Train: [78][930/1500]	BT 0.037 (0.307)	DT 0.001 (0.270)	loss 7.032 (7.014)	prob 2.775 (2.241)	GS 30.609 (32.038)	mem 74.467
Train: [78][940/1500]	BT 0.034 (0.307)	DT 0.001 (0.270)	loss 7.506 (7.017)	prob 2.331 (2.268)	GS 35.125 (32.543)	mem 74.469
Train: [78][950/1500]	BT 0.038 (0.304)	DT 0.001 (0.267)	loss 7.233 (7.014)	prob 3.019 (2.335)	GS 29.641 (32.305)	mem 74.471
Train: [78][960/1500]	BT 0.038 (0.305)	DT 0.000 (0.268)	loss 7.040 (6.956)	prob 3.403 (3.049)	GS 29.703 (30.772)	mem 74.470
Train: [78][970/1500]	BT 0.050 (0.305)	DT 0.011 (0.268)	loss 6.944 (6.995)	prob 1.722 (2.761)	GS 35.953 (31.688)	mem 74.469
Train: [78][980/1500]	BT 0.037 (0.305)	DT 0.000 (0.268)	loss 7.270 (6.993)	prob 2.362 (2.689)	GS 30.781 (32.133)	mem 74.472
Train: [78][990/1500]	BT 0.036 (0.305)	DT 0.000 (0.268)	loss 7.201 (7.000)	prob 1.531 (2.608)	GS 34.672 (32.106)	mem 74.474
Train: [78][1000/1500]	BT 0.052 (0.302)	DT 0.001 (0.265)	loss 7.074 (7.006)	prob 2.577 (2.576)	GS 36.672 (32.604)	mem 74.474
Train: [78][1010/1500]	BT 0.036 (0.309)	DT 0.000 (0.272)	loss 6.945 (6.959)	prob 2.475 (2.527)	GS 29.688 (31.291)	mem 74.473
Train: [78][1020/1500]	BT 0.037 (0.306)	DT 0.001 (0.269)	loss 6.720 (6.916)	prob 2.785 (2.667)	GS 31.891 (31.072)	mem 74.475
Train: [78][1030/1500]	BT 0.038 (0.304)	DT 0.001 (0.267)	loss 7.716 (6.987)	prob 2.466 (2.641)	GS 30.562 (31.875)	mem 74.476
Train: [78][1040/1500]	BT 0.038 (0.307)	DT 0.001 (0.270)	loss 6.883 (6.981)	prob 3.529 (2.710)	GS 36.688 (31.974)	mem 74.473
Train: [78][1050/1500]	BT 0.038 (0.304)	DT 0.000 (0.267)	loss 7.604 (7.013)	prob 2.565 (2.672)	GS 36.703 (32.292)	mem 74.474
Train: [78][1060/1500]	BT 0.054 (0.308)	DT 0.005 (0.271)	loss 6.862 (6.970)	prob 2.299 (2.836)	GS 29.172 (31.864)	mem 74.511
Train: [78][1070/1500]	BT 0.034 (0.306)	DT 0.000 (0.269)	loss 7.158 (6.980)	prob 3.423 (2.834)	GS 37.844 (32.617)	mem 74.510
Train: [78][1080/1500]	BT 5.020 (0.309)	DT 4.981 (0.271)	loss 7.305 (6.967)	prob 2.462 (2.776)	GS 31.812 (32.183)	mem 74.508
Train: [78][1090/1500]	BT 0.038 (0.307)	DT 0.001 (0.269)	loss 6.930 (6.959)	prob 2.629 (2.800)	GS 31.953 (32.107)	mem 74.508
Train: [78][1100/1500]	BT 0.038 (0.304)	DT 0.001 (0.267)	loss 7.604 (6.979)	prob 2.914 (2.755)	GS 27.328 (32.306)	mem 74.511
Train: [78][1110/1500]	BT 0.042 (0.307)	DT 0.000 (0.270)	loss 7.086 (7.127)	prob 3.641 (2.908)	GS 33.844 (32.831)	mem 74.511
Train: [78][1120/1500]	BT 0.025 (0.305)	DT 0.000 (0.267)	loss 6.797 (7.045)	prob 3.242 (2.893)	GS 36.875 (32.730)	mem 74.512
Train: [78][1130/1500]	BT 0.038 (0.303)	DT 0.001 (0.265)	loss 7.007 (7.046)	prob 2.856 (2.950)	GS 35.594 (32.929)	mem 74.515
Train: [78][1140/1500]	BT 0.039 (0.303)	DT 0.001 (0.265)	loss 7.013 (7.020)	prob 2.559 (2.886)	GS 40.438 (32.968)	mem 74.516
Train: [78][1150/1500]	BT 0.039 (0.300)	DT 0.001 (0.263)	loss 7.161 (7.017)	prob 3.062 (2.849)	GS 33.625 (33.177)	mem 74.515
Train: [78][1160/1500]	BT 0.058 (0.302)	DT 0.011 (0.264)	loss 7.080 (6.985)	prob 2.340 (2.603)	GS 33.078 (32.428)	mem 74.514
Train: [78][1170/1500]	BT 0.060 (0.301)	DT 0.004 (0.263)	loss 7.278 (6.963)	prob 2.695 (2.693)	GS 31.562 (32.089)	mem 74.516
Train: [78][1180/1500]	BT 0.038 (0.304)	DT 0.001 (0.266)	loss 6.770 (6.956)	prob 3.147 (2.786)	GS 35.703 (31.975)	mem 74.514
Train: [78][1190/1500]	BT 0.039 (0.302)	DT 0.001 (0.264)	loss 7.127 (6.962)	prob 3.035 (2.722)	GS 33.469 (31.680)	mem 74.515
Train: [78][1200/1500]	BT 0.039 (0.299)	DT 0.001 (0.262)	loss 6.694 (6.949)	prob 3.393 (2.769)	GS 35.375 (32.324)	mem 74.515
Train: [78][1210/1500]	BT 0.042 (0.302)	DT 0.001 (0.264)	loss 6.859 (6.979)	prob 2.954 (3.186)	GS 32.938 (32.116)	mem 74.514
Train: [78][1220/1500]	BT 0.025 (0.300)	DT 0.000 (0.262)	loss 6.891 (7.013)	prob 3.405 (3.081)	GS 35.391 (32.853)	mem 74.514
Train: [78][1230/1500]	BT 0.023 (0.302)	DT 0.000 (0.265)	loss 6.950 (7.002)	prob 2.807 (2.977)	GS 32.188 (32.599)	mem 74.515
Train: [78][1240/1500]	BT 0.029 (0.300)	DT 0.000 (0.263)	loss 6.946 (7.021)	prob 3.074 (2.849)	GS 31.406 (32.611)	mem 74.514
Train: [78][1250/1500]	BT 0.025 (0.303)	DT 0.000 (0.265)	loss 7.399 (7.019)	prob 3.225 (2.898)	GS 31.297 (32.519)	mem 74.516
Train: [78][1260/1500]	BT 0.038 (0.301)	DT 0.001 (0.263)	loss 7.334 (6.981)	prob 2.688 (3.038)	GS 33.547 (33.244)	mem 74.516
Train: [78][1270/1500]	BT 0.038 (0.298)	DT 0.001 (0.261)	loss 6.767 (6.955)	prob 2.993 (3.068)	GS 36.938 (32.392)	mem 74.516
Train: [78][1280/1500]	BT 0.028 (0.305)	DT 0.000 (0.268)	loss 7.194 (6.943)	prob 2.889 (3.002)	GS 35.078 (33.530)	mem 74.517
Train: [78][1290/1500]	BT 0.026 (0.303)	DT 0.000 (0.266)	loss 6.798 (6.925)	prob 3.371 (3.086)	GS 36.359 (33.406)	mem 74.518
Train: [78][1300/1500]	BT 0.038 (0.301)	DT 0.001 (0.264)	loss 6.812 (6.935)	prob 2.731 (2.996)	GS 35.266 (33.526)	mem 74.508
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [78][1310/1500]	BT 0.031 (0.302)	DT 0.000 (0.265)	loss 6.801 (6.886)	prob 4.112 (3.162)	GS 34.156 (32.873)	mem 74.517
Train: [78][1320/1500]	BT 0.028 (0.300)	DT 0.000 (0.263)	loss 6.924 (6.872)	prob 3.375 (3.207)	GS 35.438 (32.620)	mem 74.518
Train: [78][1330/1500]	BT 0.059 (0.304)	DT 0.016 (0.267)	loss 7.131 (6.911)	prob 2.818 (3.121)	GS 33.312 (32.578)	mem 74.527
Train: [78][1340/1500]	BT 0.032 (0.303)	DT 0.000 (0.266)	loss 7.029 (6.914)	prob 3.237 (3.052)	GS 35.797 (32.889)	mem 74.529
Train: [78][1350/1500]	BT 0.036 (0.305)	DT 0.000 (0.268)	loss 7.143 (6.912)	prob 3.437 (3.080)	GS 30.703 (32.680)	mem 74.529
Train: [78][1360/1500]	BT 0.044 (0.304)	DT 0.006 (0.267)	loss 6.818 (6.900)	prob 2.600 (2.981)	GS 34.531 (33.352)	mem 74.529
Train: [78][1370/1500]	BT 0.038 (0.302)	DT 0.001 (0.265)	loss 6.975 (6.868)	prob 2.741 (2.964)	GS 34.172 (32.945)	mem 74.533
Train: [78][1380/1500]	BT 0.057 (0.302)	DT 0.003 (0.264)	loss 6.805 (6.872)	prob 2.875 (2.949)	GS 30.859 (32.777)	mem 74.461
Train: [78][1390/1500]	BT 0.024 (0.301)	DT 0.000 (0.264)	loss 7.209 (6.882)	prob 2.510 (2.907)	GS 33.875 (33.010)	mem 74.434
Train: [78][1400/1500]	BT 0.037 (0.300)	DT 0.001 (0.263)	loss 6.835 (6.882)	prob 2.131 (2.905)	GS 37.844 (32.985)	mem 74.432
Train: [78][1410/1500]	BT 0.037 (0.300)	DT 0.000 (0.263)	loss 6.935 (6.858)	prob 2.990 (2.868)	GS 32.766 (32.483)	mem 74.433
Train: [78][1420/1500]	BT 0.066 (0.298)	DT 0.014 (0.261)	loss 6.865 (6.829)	prob 3.075 (3.018)	GS 35.828 (32.245)	mem 74.434
Train: [78][1430/1500]	BT 0.035 (0.299)	DT 0.000 (0.261)	loss 6.891 (6.836)	prob 3.068 (3.049)	GS 35.766 (32.295)	mem 74.435
Train: [78][1440/1500]	BT 0.034 (0.299)	DT 0.001 (0.262)	loss 7.108 (6.816)	prob 2.568 (3.026)	GS 34.250 (32.447)	mem 74.434
Train: [78][1450/1500]	BT 0.063 (0.301)	DT 0.011 (0.263)	loss 6.689 (6.799)	prob 3.085 (3.017)	GS 35.328 (32.239)	mem 74.361
Train: [78][1460/1500]	BT 0.028 (0.306)	DT 0.000 (0.268)	loss 6.952 (6.798)	prob 2.814 (3.031)	GS 34.328 (31.283)	mem 73.578
Train: [78][1470/1500]	BT 0.029 (0.304)	DT 0.000 (0.266)	loss 7.236 (6.825)	prob 2.766 (2.886)	GS 30.625 (31.591)	mem 73.579
Train: [78][1480/1500]	BT 0.030 (0.304)	DT 0.000 (0.266)	loss 7.054 (6.848)	prob 2.960 (2.874)	GS 34.172 (31.699)	mem 9.327
Train: [78][1490/1500]	BT 0.031 (0.302)	DT 0.000 (0.264)	loss 6.799 (6.848)	prob 2.913 (2.877)	GS 37.312 (31.936)	mem 9.327
Train: [78][1500/1500]	BT 0.034 (0.300)	DT 0.000 (0.263)	loss 6.491 (6.842)	prob 3.717 (2.915)	GS 38.031 (31.979)	mem 9.328
Train: [78][1510/1500]	BT 0.024 (0.299)	DT 0.000 (0.261)	loss 6.608 (6.739)	prob 2.702 (3.142)	GS 41.625 (33.906)	mem 9.252
epoch 78, total time 451.33
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [79][1/1500]	BT 19.031 (19.031)	DT 18.972 (18.972)	loss 6.453 (6.453)	prob 3.431 (3.431)	GS 35.125 (35.125)	mem 72.880
Train: [79][10/1500]	BT 0.031 (2.258)	DT 0.000 (2.220)	loss 6.621 (6.610)	prob 3.418 (3.023)	GS 36.109 (34.061)	mem 73.107
Train: [79][20/1500]	BT 0.031 (1.150)	DT 0.001 (1.110)	loss 6.671 (6.658)	prob 3.039 (2.973)	GS 35.781 (34.165)	mem 73.109
Train: [79][30/1500]	BT 0.039 (0.876)	DT 0.001 (0.839)	loss 7.099 (6.674)	prob 2.544 (3.024)	GS 31.797 (33.879)	mem 73.112
Train: [79][40/1500]	BT 1.298 (0.720)	DT 1.260 (0.682)	loss 6.742 (6.699)	prob 3.271 (3.021)	GS 27.938 (33.134)	mem 73.125
Train: [79][50/1500]	BT 3.003 (0.647)	DT 2.966 (0.609)	loss 6.960 (6.714)	prob 2.625 (2.988)	GS 31.328 (32.876)	mem 73.194
Train: [79][60/1500]	BT 0.037 (0.549)	DT 0.000 (0.511)	loss 6.915 (6.859)	prob 2.820 (2.909)	GS 34.656 (32.977)	mem 73.196
Train: [79][70/1500]	BT 0.037 (0.482)	DT 0.001 (0.445)	loss 6.618 (6.851)	prob 2.044 (2.777)	GS 33.438 (32.676)	mem 73.199
Train: [79][80/1500]	BT 0.038 (0.453)	DT 0.001 (0.416)	loss 6.699 (6.837)	prob 2.933 (2.788)	GS 32.047 (32.851)	mem 73.208
Train: [79][90/1500]	BT 0.486 (0.439)	DT 0.449 (0.402)	loss 6.766 (6.844)	prob 2.701 (2.662)	GS 36.375 (32.807)	mem 73.214
Train: [79][100/1500]	BT 0.038 (0.399)	DT 0.000 (0.362)	loss 6.783 (6.840)	prob 2.484 (2.714)	GS 31.781 (32.571)	mem 73.216
Train: [79][110/1500]	BT 0.036 (0.407)	DT 0.000 (0.369)	loss 6.776 (6.783)	prob 2.495 (2.711)	GS 33.391 (30.606)	mem 73.224
Train: [79][120/1500]	BT 0.038 (0.376)	DT 0.001 (0.338)	loss 6.759 (6.770)	prob 3.430 (2.883)	GS 28.812 (31.011)	mem 73.224
Train: [79][130/1500]	BT 0.038 (0.379)	DT 0.000 (0.341)	loss 6.746 (6.762)	prob 2.776 (2.865)	GS 35.047 (31.653)	mem 73.231
Train: [79][140/1500]	BT 0.033 (0.374)	DT 0.001 (0.336)	loss 6.705 (6.770)	prob 2.503 (2.771)	GS 36.562 (32.524)	mem 73.236
Train: [79][150/1500]	BT 0.026 (0.351)	DT 0.000 (0.314)	loss 7.046 (6.790)	prob 2.949 (2.819)	GS 34.672 (32.603)	mem 73.238
Train: [79][160/1500]	BT 0.037 (0.338)	DT 0.001 (0.301)	loss 6.822 (6.820)	prob 2.599 (2.813)	GS 37.266 (33.333)	mem 73.240
Train: [79][170/1500]	BT 0.037 (0.330)	DT 0.001 (0.294)	loss 6.705 (6.858)	prob 2.806 (2.917)	GS 33.438 (33.121)	mem 73.240
Train: [79][180/1500]	BT 0.038 (0.325)	DT 0.001 (0.288)	loss 6.977 (6.876)	prob 2.843 (2.945)	GS 36.109 (33.239)	mem 73.241
Train: [79][190/1500]	BT 0.058 (0.317)	DT 0.011 (0.280)	loss 6.839 (6.859)	prob 3.377 (2.935)	GS 35.516 (32.964)	mem 73.245
Train: [79][200/1500]	BT 0.027 (0.337)	DT 0.000 (0.300)	loss 6.734 (6.851)	prob 2.850 (2.941)	GS 34.500 (33.064)	mem 73.259
Train: [79][210/1500]	BT 0.037 (0.323)	DT 0.001 (0.286)	loss 6.723 (6.760)	prob 2.941 (2.733)	GS 34.625 (32.558)	mem 73.260
Train: [79][220/1500]	BT 0.037 (0.325)	DT 0.001 (0.289)	loss 6.955 (6.802)	prob 3.114 (2.858)	GS 33.594 (33.209)	mem 73.263
Train: [79][230/1500]	BT 0.038 (0.313)	DT 0.000 (0.276)	loss 6.746 (6.804)	prob 2.833 (2.862)	GS 30.422 (33.038)	mem 73.264
Train: [79][240/1500]	BT 0.037 (0.305)	DT 0.000 (0.268)	loss 6.893 (6.808)	prob 2.804 (2.870)	GS 34.391 (32.896)	mem 73.265
Train: [79][250/1500]	BT 0.031 (0.323)	DT 0.000 (0.287)	loss 6.852 (6.802)	prob 2.766 (2.869)	GS 32.625 (32.915)	mem 73.269
Train: [79][260/1500]	BT 0.050 (0.314)	DT 0.008 (0.277)	loss 6.936 (6.816)	prob 3.425 (3.028)	GS 31.172 (33.286)	mem 73.269
Train: [79][270/1500]	BT 0.033 (0.338)	DT 0.000 (0.301)	loss 6.659 (6.836)	prob 3.317 (2.997)	GS 35.594 (32.664)	mem 73.273
Train: [79][280/1500]	BT 0.060 (0.328)	DT 0.001 (0.290)	loss 6.806 (6.801)	prob 2.607 (3.077)	GS 33.094 (32.168)	mem 73.274
Train: [79][290/1500]	BT 0.020 (0.359)	DT 0.000 (0.322)	loss 6.787 (6.799)	prob 2.937 (2.973)	GS 33.922 (32.295)	mem 73.276
Train: [79][300/1500]	BT 0.035 (0.348)	DT 0.001 (0.311)	loss 6.912 (6.810)	prob 2.616 (2.963)	GS 33.812 (32.246)	mem 73.278
Train: [79][310/1500]	BT 0.033 (0.347)	DT 0.001 (0.310)	loss 6.809 (6.813)	prob 2.647 (2.912)	GS 33.484 (33.047)	mem 73.281
Train: [79][320/1500]	BT 0.026 (0.337)	DT 0.000 (0.300)	loss 6.735 (6.828)	prob 3.425 (2.865)	GS 33.812 (32.766)	mem 73.281
Train: [79][330/1500]	BT 0.032 (0.342)	DT 0.000 (0.306)	loss 6.685 (6.829)	prob 2.815 (2.793)	GS 28.891 (32.764)	mem 73.284
Train: [79][340/1500]	BT 0.028 (0.333)	DT 0.000 (0.297)	loss 6.709 (6.862)	prob 3.159 (2.801)	GS 32.828 (33.075)	mem 73.285
Train: [79][350/1500]	BT 0.038 (0.324)	DT 0.001 (0.288)	loss 6.907 (6.858)	prob 2.357 (2.799)	GS 35.281 (33.029)	mem 73.285
Train: [79][360/1500]	BT 0.025 (0.339)	DT 0.000 (0.303)	loss 6.786 (6.830)	prob 2.252 (2.403)	GS 33.703 (33.288)	mem 73.482
Train: [79][370/1500]	BT 0.033 (0.331)	DT 0.000 (0.295)	loss 6.780 (6.810)	prob 2.829 (2.556)	GS 33.938 (32.645)	mem 73.530
Train: [79][380/1500]	BT 0.036 (0.334)	DT 0.000 (0.298)	loss 6.791 (6.791)	prob 1.760 (2.553)	GS 33.578 (32.334)	mem 74.073
Train: [79][390/1500]	BT 0.032 (0.326)	DT 0.000 (0.291)	loss 6.805 (6.790)	prob 1.782 (2.548)	GS 38.359 (32.454)	mem 74.123
Train: [79][400/1500]	BT 0.038 (0.319)	DT 0.001 (0.283)	loss 6.734 (6.780)	prob 2.072 (2.538)	GS 35.016 (32.701)	mem 74.271
Train: [79][410/1500]	BT 0.037 (0.319)	DT 0.001 (0.283)	loss 6.732 (6.792)	prob 2.455 (2.220)	GS 34.672 (33.050)	mem 74.453
Train: [79][420/1500]	BT 0.039 (0.312)	DT 0.001 (0.276)	loss 6.544 (6.755)	prob 3.205 (2.282)	GS 34.562 (32.497)	mem 74.453
Train: [79][430/1500]	BT 0.034 (0.327)	DT 0.001 (0.291)	loss 6.665 (6.786)	prob 1.882 (2.329)	GS 36.406 (32.922)	mem 74.503
Train: [79][440/1500]	BT 0.031 (0.320)	DT 0.000 (0.285)	loss 6.813 (6.805)	prob 1.523 (2.306)	GS 35.750 (32.921)	mem 74.503
Train: [79][450/1500]	BT 0.039 (0.314)	DT 0.001 (0.278)	loss 6.585 (6.813)	prob 2.666 (2.360)	GS 32.016 (32.948)	mem 74.504
Train: [79][460/1500]	BT 0.038 (0.317)	DT 0.000 (0.281)	loss 6.904 (6.807)	prob 2.150 (2.492)	GS 34.969 (32.548)	mem 74.505
Train: [79][470/1500]	BT 0.039 (0.311)	DT 0.001 (0.275)	loss 7.016 (6.776)	prob 2.369 (2.446)	GS 32.141 (31.648)	mem 74.505
Train: [79][480/1500]	BT 0.039 (0.311)	DT 0.001 (0.275)	loss 6.715 (6.766)	prob 2.378 (2.481)	GS 32.578 (32.172)	mem 74.505
Train: [79][490/1500]	BT 0.040 (0.306)	DT 0.001 (0.270)	loss 6.864 (6.760)	prob 2.282 (2.462)	GS 34.641 (32.282)	mem 74.504
Train: [79][500/1500]	BT 0.030 (0.315)	DT 0.000 (0.279)	loss 6.682 (6.752)	prob 2.741 (2.424)	GS 33.578 (32.405)	mem 74.507
Train: [79][510/1500]	BT 0.031 (0.314)	DT 0.000 (0.278)	loss 6.907 (6.818)	prob 2.156 (2.591)	GS 39.281 (34.027)	mem 74.506
Train: [79][520/1500]	BT 0.039 (0.309)	DT 0.001 (0.273)	loss 6.978 (6.801)	prob 1.682 (2.484)	GS 35.859 (33.773)	mem 74.508
Train: [79][530/1500]	BT 0.033 (0.309)	DT 0.001 (0.273)	loss 6.841 (6.789)	prob 2.551 (2.501)	GS 34.656 (33.336)	mem 74.510
Train: [79][540/1500]	BT 0.028 (0.303)	DT 0.000 (0.268)	loss 6.659 (6.791)	prob 1.700 (2.447)	GS 30.047 (32.984)	mem 74.511
Train: [79][550/1500]	BT 0.039 (0.300)	DT 0.001 (0.264)	loss 6.755 (6.799)	prob 2.515 (2.488)	GS 33.812 (33.288)	mem 74.512
Train: [79][560/1500]	BT 0.039 (0.300)	DT 0.001 (0.264)	loss 6.640 (6.715)	prob 2.538 (2.465)	GS 34.391 (32.639)	mem 74.512
Train: [79][570/1500]	BT 0.040 (0.296)	DT 0.001 (0.261)	loss 7.266 (6.773)	prob 2.411 (2.506)	GS 33.125 (33.259)	mem 74.513
Train: [79][580/1500]	BT 0.039 (0.299)	DT 0.001 (0.263)	loss 7.046 (6.757)	prob 2.328 (2.479)	GS 29.453 (32.611)	mem 74.514
Train: [79][590/1500]	BT 0.076 (0.295)	DT 0.003 (0.259)	loss 6.721 (6.739)	prob 2.495 (2.472)	GS 35.844 (32.744)	mem 74.516
Train: [79][600/1500]	BT 0.039 (0.300)	DT 0.000 (0.263)	loss 6.679 (6.743)	prob 2.301 (2.472)	GS 30.031 (32.745)	mem 74.516
Train: [79][610/1500]	BT 0.037 (0.296)	DT 0.000 (0.259)	loss 6.741 (6.683)	prob 3.209 (2.508)	GS 35.922 (33.784)	mem 74.516
Train: [79][620/1500]	BT 0.038 (0.294)	DT 0.001 (0.257)	loss 6.692 (6.686)	prob 2.632 (2.655)	GS 33.891 (32.970)	mem 74.516
Train: [79][630/1500]	BT 0.059 (0.293)	DT 0.009 (0.257)	loss 6.906 (6.685)	prob 2.916 (2.669)	GS 34.062 (32.992)	mem 74.521
Train: [79][640/1500]	BT 0.091 (0.292)	DT 0.001 (0.255)	loss 6.835 (6.695)	prob 2.084 (2.618)	GS 35.000 (32.660)	mem 74.524
Train: [79][650/1500]	BT 11.959 (0.322)	DT 11.899 (0.284)	loss 6.827 (6.712)	prob 3.016 (2.620)	GS 38.922 (32.819)	mem 74.522
Train: [79][660/1500]	BT 0.038 (0.317)	DT 0.000 (0.280)	loss 6.660 (6.745)	prob 1.524 (2.688)	GS 29.859 (32.622)	mem 74.523
Train: [79][670/1500]	BT 0.031 (0.313)	DT 0.000 (0.276)	loss 6.809 (6.776)	prob 3.156 (2.780)	GS 34.812 (31.916)	mem 74.523
Train: [79][680/1500]	BT 0.025 (0.317)	DT 0.000 (0.280)	loss 6.815 (6.768)	prob 2.842 (2.800)	GS 31.547 (31.970)	mem 74.535
Train: [79][690/1500]	BT 0.037 (0.313)	DT 0.000 (0.276)	loss 6.760 (6.757)	prob 2.975 (2.782)	GS 31.422 (31.708)	mem 74.536
Train: [79][700/1500]	BT 0.037 (0.313)	DT 0.001 (0.276)	loss 6.608 (6.762)	prob 2.455 (2.738)	GS 36.609 (31.891)	mem 74.530
Train: [79][710/1500]	BT 0.041 (0.309)	DT 0.000 (0.272)	loss 6.545 (6.682)	prob 3.045 (2.583)	GS 31.031 (30.134)	mem 74.529
Train: [79][720/1500]	BT 0.037 (0.306)	DT 0.000 (0.269)	loss 6.624 (6.652)	prob 2.170 (2.568)	GS 30.141 (31.498)	mem 74.530
Train: [79][730/1500]	BT 0.026 (0.306)	DT 0.000 (0.269)	loss 6.849 (6.683)	prob 2.014 (2.520)	GS 35.406 (31.636)	mem 74.433
Train: [79][740/1500]	BT 0.027 (0.302)	DT 0.000 (0.265)	loss 6.650 (6.703)	prob 2.923 (2.511)	GS 35.344 (32.041)	mem 74.435
Train: [79][750/1500]	BT 0.051 (0.304)	DT 0.002 (0.267)	loss 6.767 (6.713)	prob 2.406 (2.485)	GS 33.969 (32.169)	mem 74.437
Train: [79][760/1500]	BT 0.037 (0.300)	DT 0.001 (0.263)	loss 6.557 (6.676)	prob 2.216 (2.567)	GS 30.688 (31.352)	mem 74.437
Train: [79][770/1500]	BT 2.720 (0.300)	DT 2.683 (0.264)	loss 6.727 (6.682)	prob 2.156 (2.327)	GS 33.719 (31.580)	mem 74.438
Train: [79][780/1500]	BT 0.037 (0.298)	DT 0.001 (0.262)	loss 6.846 (6.680)	prob 2.479 (2.423)	GS 34.156 (31.815)	mem 74.438
Train: [79][790/1500]	BT 0.038 (0.295)	DT 0.001 (0.258)	loss 6.843 (6.686)	prob 2.271 (2.433)	GS 35.266 (31.921)	mem 74.438
Train: [79][800/1500]	BT 0.038 (0.295)	DT 0.001 (0.259)	loss 6.607 (6.681)	prob 2.424 (2.405)	GS 35.188 (31.927)	mem 74.439
Train: [79][810/1500]	BT 0.510 (0.294)	DT 0.471 (0.257)	loss 6.899 (6.689)	prob 2.155 (2.399)	GS 27.984 (31.059)	mem 74.440
Train: [79][820/1500]	BT 0.038 (0.293)	DT 0.001 (0.257)	loss 6.825 (6.701)	prob 2.746 (2.368)	GS 32.656 (31.137)	mem 74.460
Train: [79][830/1500]	BT 2.806 (0.295)	DT 2.775 (0.258)	loss 6.627 (6.666)	prob 2.422 (2.437)	GS 33.172 (31.261)	mem 74.461
Train: [79][840/1500]	BT 0.032 (0.292)	DT 0.001 (0.255)	loss 6.686 (6.666)	prob 2.729 (2.449)	GS 33.531 (31.566)	mem 74.462
Train: [79][850/1500]	BT 0.064 (0.296)	DT 0.004 (0.259)	loss 6.406 (6.663)	prob 2.130 (2.467)	GS 33.234 (31.820)	mem 74.446
Train: [79][860/1500]	BT 0.028 (0.305)	DT 0.000 (0.268)	loss 6.683 (6.673)	prob 2.406 (2.042)	GS 35.594 (33.123)	mem 74.449
Train: [79][870/1500]	BT 0.027 (0.302)	DT 0.000 (0.265)	loss 6.664 (6.685)	prob 2.790 (2.318)	GS 31.656 (33.898)	mem 74.450
Train: [79][880/1500]	BT 0.031 (0.303)	DT 0.000 (0.267)	loss 6.746 (6.677)	prob 2.425 (2.383)	GS 35.078 (34.101)	mem 74.452
Train: [79][890/1500]	BT 0.025 (0.300)	DT 0.000 (0.264)	loss 6.881 (6.677)	prob 2.080 (2.332)	GS 32.547 (33.886)	mem 74.452
Train: [79][900/1500]	BT 0.025 (0.297)	DT 0.000 (0.261)	loss 6.543 (6.684)	prob 2.258 (2.361)	GS 34.938 (33.758)	mem 74.453
Train: [79][910/1500]	BT 0.031 (0.306)	DT 0.000 (0.269)	loss 6.623 (6.694)	prob 2.264 (2.410)	GS 35.281 (33.348)	mem 74.453
Train: [79][920/1500]	BT 0.042 (0.315)	DT 0.006 (0.279)	loss 6.748 (6.686)	prob 1.770 (2.477)	GS 33.688 (32.637)	mem 74.450
Train: [79][930/1500]	BT 0.025 (0.312)	DT 0.000 (0.276)	loss 6.687 (6.693)	prob 2.172 (2.506)	GS 31.016 (32.651)	mem 74.451
Train: [79][940/1500]	BT 0.026 (0.309)	DT 0.000 (0.273)	loss 6.649 (6.686)	prob 3.410 (2.574)	GS 33.844 (32.540)	mem 74.452
Train: [79][950/1500]	BT 0.028 (0.313)	DT 0.000 (0.277)	loss 6.667 (6.673)	prob 2.297 (2.580)	GS 34.250 (32.574)	mem 74.449
Train: [79][960/1500]	BT 0.030 (0.310)	DT 0.000 (0.274)	loss 6.559 (6.655)	prob 2.443 (2.400)	GS 30.906 (31.033)	mem 74.448
Train: [79][970/1500]	BT 0.048 (0.310)	DT 0.006 (0.274)	loss 6.680 (6.656)	prob 2.522 (2.402)	GS 32.984 (32.115)	mem 74.449
Train: [79][980/1500]	BT 0.039 (0.308)	DT 0.001 (0.271)	loss 6.741 (6.661)	prob 2.986 (2.485)	GS 36.141 (32.896)	mem 74.450
Train: [79][990/1500]	BT 0.039 (0.305)	DT 0.001 (0.269)	loss 7.110 (6.670)	prob 1.863 (2.481)	GS 33.047 (32.928)	mem 74.450
Train: [79][1000/1500]	BT 0.037 (0.306)	DT 0.001 (0.269)	loss 6.633 (6.670)	prob 2.700 (2.468)	GS 31.938 (32.818)	mem 74.467
Train: [79][1010/1500]	BT 0.037 (0.303)	DT 0.001 (0.267)	loss 6.678 (6.701)	prob 1.965 (2.368)	GS 31.578 (31.880)	mem 74.468
Train: [79][1020/1500]	BT 0.036 (0.304)	DT 0.000 (0.268)	loss 6.432 (6.653)	prob 2.389 (2.388)	GS 34.875 (31.223)	mem 74.472
Train: [79][1030/1500]	BT 0.034 (0.302)	DT 0.001 (0.265)	loss 6.727 (6.652)	prob 2.381 (2.432)	GS 32.562 (31.396)	mem 74.473
Train: [79][1040/1500]	BT 0.039 (0.304)	DT 0.000 (0.267)	loss 6.786 (6.640)	prob 1.766 (2.422)	GS 33.109 (31.646)	mem 74.476
Train: [79][1050/1500]	BT 0.031 (0.301)	DT 0.000 (0.265)	loss 6.661 (6.651)	prob 2.130 (2.419)	GS 35.562 (32.003)	mem 74.477
Train: [79][1060/1500]	BT 0.037 (0.299)	DT 0.001 (0.262)	loss 6.651 (6.658)	prob 2.591 (2.417)	GS 34.281 (31.772)	mem 74.478
Train: [79][1070/1500]	BT 0.029 (0.300)	DT 0.001 (0.264)	loss 6.606 (6.642)	prob 2.159 (2.372)	GS 34.078 (32.174)	mem 74.480
Train: [79][1080/1500]	BT 0.027 (0.298)	DT 0.000 (0.261)	loss 6.766 (6.653)	prob 2.306 (2.288)	GS 34.906 (32.274)	mem 74.480
Train: [79][1090/1500]	BT 0.038 (0.298)	DT 0.001 (0.262)	loss 6.632 (6.641)	prob 2.505 (2.311)	GS 32.766 (32.407)	mem 74.481
Train: [79][1100/1500]	BT 0.038 (0.296)	DT 0.001 (0.260)	loss 6.676 (6.653)	prob 2.162 (2.235)	GS 32.391 (32.573)	mem 74.482
Train: [79][1110/1500]	BT 0.038 (0.294)	DT 0.001 (0.258)	loss 6.503 (6.632)	prob 2.322 (2.260)	GS 35.266 (33.469)	mem 74.484
Train: [79][1120/1500]	BT 0.038 (0.294)	DT 0.001 (0.258)	loss 6.680 (6.656)	prob 1.107 (2.149)	GS 32.250 (33.084)	mem 74.484
Train: [79][1130/1500]	BT 0.038 (0.292)	DT 0.001 (0.256)	loss 6.735 (6.650)	prob 2.098 (2.188)	GS 35.953 (33.270)	mem 74.485
Train: [79][1140/1500]	BT 0.037 (0.293)	DT 0.001 (0.257)	loss 6.625 (6.645)	prob 1.807 (2.205)	GS 32.609 (33.095)	mem 74.485
Train: [79][1150/1500]	BT 0.029 (0.295)	DT 0.000 (0.258)	loss 6.539 (6.639)	prob 2.542 (2.222)	GS 34.438 (33.321)	mem 74.482
Train: [79][1160/1500]	BT 0.034 (0.292)	DT 0.001 (0.256)	loss 6.687 (6.669)	prob 2.417 (2.219)	GS 32.281 (33.327)	mem 74.482
Train: [79][1170/1500]	BT 0.024 (0.294)	DT 0.001 (0.258)	loss 6.592 (6.662)	prob 1.879 (2.104)	GS 32.422 (32.938)	mem 74.481
Train: [79][1180/1500]	BT 0.049 (0.292)	DT 0.003 (0.256)	loss 6.684 (6.643)	prob 2.096 (2.119)	GS 35.875 (33.082)	mem 74.483
Train: [79][1190/1500]	BT 0.064 (0.290)	DT 0.014 (0.254)	loss 6.776 (6.637)	prob 2.265 (2.115)	GS 25.734 (32.924)	mem 74.483
Train: [79][1200/1500]	BT 0.063 (0.292)	DT 0.011 (0.255)	loss 6.697 (6.642)	prob 2.483 (2.044)	GS 33.938 (32.829)	mem 74.484
Train: [79][1210/1500]	BT 0.063 (0.290)	DT 0.002 (0.253)	loss 6.750 (6.666)	prob 2.131 (2.220)	GS 30.250 (31.706)	mem 74.484
Train: [79][1220/1500]	BT 0.053 (0.293)	DT 0.006 (0.256)	loss 6.498 (6.622)	prob 2.775 (2.342)	GS 32.781 (32.404)	mem 74.481
Train: [79][1230/1500]	BT 0.058 (0.291)	DT 0.011 (0.254)	loss 6.601 (6.616)	prob 2.681 (2.384)	GS 37.141 (33.002)	mem 74.482
Train: [79][1240/1500]	BT 0.053 (0.294)	DT 0.006 (0.257)	loss 6.386 (6.610)	prob 2.453 (2.344)	GS 34.719 (32.611)	mem 74.482
Train: [79][1250/1500]	BT 0.039 (0.292)	DT 0.001 (0.255)	loss 6.537 (6.613)	prob 2.140 (2.277)	GS 34.969 (32.601)	mem 74.482
Train: [79][1260/1500]	BT 0.062 (0.291)	DT 0.004 (0.253)	loss 6.602 (6.598)	prob 2.274 (2.321)	GS 32.375 (31.702)	mem 74.483
Train: [79][1270/1500]	BT 0.039 (0.306)	DT 0.001 (0.269)	loss 6.546 (6.616)	prob 2.973 (2.298)	GS 29.828 (31.730)	mem 74.486
Train: [79][1280/1500]	BT 0.026 (0.304)	DT 0.000 (0.267)	loss 6.701 (6.608)	prob 1.785 (2.369)	GS 34.547 (32.574)	mem 74.488
Train: [79][1290/1500]	BT 0.038 (0.304)	DT 0.001 (0.267)	loss 6.656 (6.603)	prob 2.255 (2.374)	GS 35.141 (32.878)	mem 74.490
Train: [79][1300/1500]	BT 0.029 (0.302)	DT 0.001 (0.265)	loss 6.569 (6.608)	prob 2.245 (2.377)	GS 37.391 (32.868)	mem 74.491
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [79][1310/1500]	BT 0.047 (0.302)	DT 0.014 (0.265)	loss 6.609 (6.625)	prob 2.240 (2.436)	GS 29.109 (32.780)	mem 74.491
Train: [79][1320/1500]	BT 0.053 (0.301)	DT 0.006 (0.263)	loss 6.715 (6.657)	prob 2.019 (2.314)	GS 34.875 (32.641)	mem 74.491
Train: [79][1330/1500]	BT 0.038 (0.299)	DT 0.001 (0.262)	loss 6.755 (6.670)	prob 2.649 (2.419)	GS 35.734 (32.970)	mem 74.491
Train: [79][1340/1500]	BT 0.349 (0.299)	DT 0.311 (0.262)	loss 6.640 (6.652)	prob 2.712 (2.443)	GS 31.047 (32.686)	mem 74.491
Train: [79][1350/1500]	BT 0.037 (0.298)	DT 0.001 (0.261)	loss 6.691 (6.657)	prob 2.319 (2.453)	GS 29.422 (32.912)	mem 74.492
Train: [79][1360/1500]	BT 0.038 (0.299)	DT 0.001 (0.262)	loss 6.570 (6.620)	prob 1.967 (2.645)	GS 34.875 (32.798)	mem 74.521
Train: [79][1370/1500]	BT 0.039 (0.297)	DT 0.001 (0.260)	loss 6.576 (6.620)	prob 2.873 (2.408)	GS 36.203 (32.436)	mem 74.520
Train: [79][1380/1500]	BT 0.039 (0.295)	DT 0.001 (0.258)	loss 6.559 (6.623)	prob 2.515 (2.395)	GS 31.797 (32.269)	mem 74.521
Train: [79][1390/1500]	BT 0.029 (0.297)	DT 0.001 (0.260)	loss 6.591 (6.616)	prob 2.316 (2.383)	GS 33.953 (31.984)	mem 74.521
Train: [79][1400/1500]	BT 0.040 (0.295)	DT 0.001 (0.258)	loss 6.641 (6.618)	prob 2.919 (2.361)	GS 36.859 (32.165)	mem 74.522
Train: [79][1410/1500]	BT 0.053 (0.296)	DT 0.006 (0.259)	loss 6.579 (6.614)	prob 2.506 (2.339)	GS 34.891 (31.356)	mem 74.522
Train: [79][1420/1500]	BT 0.039 (0.295)	DT 0.001 (0.257)	loss 6.715 (6.602)	prob 1.733 (2.222)	GS 31.281 (31.880)	mem 74.523
Train: [79][1430/1500]	BT 0.039 (0.296)	DT 0.001 (0.259)	loss 6.572 (6.606)	prob 2.583 (2.271)	GS 31.344 (32.227)	mem 74.522
Train: [79][1440/1500]	BT 0.039 (0.294)	DT 0.001 (0.257)	loss 6.645 (6.613)	prob 1.750 (2.238)	GS 31.844 (32.357)	mem 74.522
Train: [79][1450/1500]	BT 0.039 (0.293)	DT 0.001 (0.256)	loss 6.620 (6.607)	prob 1.986 (2.255)	GS 37.812 (32.312)	mem 74.522
Train: [79][1460/1500]	BT 0.030 (0.294)	DT 0.000 (0.256)	loss 6.642 (6.627)	prob 2.126 (2.797)	GS 31.531 (32.361)	mem 73.940
Train: [79][1470/1500]	BT 0.030 (0.292)	DT 0.001 (0.255)	loss 6.485 (6.622)	prob 3.067 (2.595)	GS 37.062 (32.236)	mem 73.866
Train: [79][1480/1500]	BT 0.034 (0.292)	DT 0.000 (0.255)	loss 6.414 (6.607)	prob 2.829 (2.547)	GS 34.953 (32.339)	mem 9.394
Train: [79][1490/1500]	BT 0.034 (0.290)	DT 0.000 (0.253)	loss 6.676 (6.603)	prob 1.988 (2.498)	GS 34.906 (32.361)	mem 9.395
Train: [79][1500/1500]	BT 0.034 (0.288)	DT 0.000 (0.251)	loss 6.470 (6.596)	prob 2.302 (2.485)	GS 37.438 (32.290)	mem 9.394
Train: [79][1510/1500]	BT 0.042 (0.288)	DT 0.000 (0.251)	loss 6.242 (6.506)	prob 3.051 (2.537)	GS 35.781 (35.163)	mem 9.321
epoch 79, total time 434.47
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [80][1/1500]	BT 18.918 (18.918)	DT 18.862 (18.862)	loss 6.386 (6.386)	prob 2.464 (2.464)	GS 35.953 (35.953)	mem 72.882
Train: [80][10/1500]	BT 0.236 (2.474)	DT 0.190 (2.427)	loss 6.353 (6.315)	prob 3.355 (2.753)	GS 37.234 (34.363)	mem 72.981
Train: [80][20/1500]	BT 0.061 (1.298)	DT 0.002 (1.251)	loss 6.684 (6.406)	prob 2.621 (2.597)	GS 34.156 (33.989)	mem 73.009
Train: [80][30/1500]	BT 0.063 (0.933)	DT 0.005 (0.880)	loss 6.364 (6.456)	prob 1.837 (2.564)	GS 27.078 (33.103)	mem 73.030
Train: [80][40/1500]	BT 0.038 (0.967)	DT 0.001 (0.917)	loss 6.587 (6.489)	prob 1.957 (2.472)	GS 29.531 (33.092)	mem 73.076
Train: [80][50/1500]	BT 0.038 (0.781)	DT 0.001 (0.734)	loss 6.572 (6.515)	prob 2.606 (2.483)	GS 32.922 (32.888)	mem 73.083
Train: [80][60/1500]	BT 0.037 (0.705)	DT 0.001 (0.660)	loss 6.680 (6.648)	prob 2.048 (2.422)	GS 31.219 (32.422)	mem 73.106
Train: [80][70/1500]	BT 0.038 (0.610)	DT 0.001 (0.566)	loss 6.727 (6.656)	prob 2.352 (2.333)	GS 34.797 (32.680)	mem 73.106
Train: [80][80/1500]	BT 0.053 (0.560)	DT 0.006 (0.517)	loss 6.554 (6.642)	prob 2.030 (2.303)	GS 31.859 (32.242)	mem 73.120
Train: [80][90/1500]	BT 0.039 (0.527)	DT 0.001 (0.484)	loss 6.757 (6.649)	prob 2.288 (2.403)	GS 34.703 (32.228)	mem 73.122
Train: [80][100/1500]	BT 0.497 (0.496)	DT 0.446 (0.454)	loss 6.573 (6.644)	prob 2.523 (2.425)	GS 30.047 (31.978)	mem 73.125
Train: [80][110/1500]	BT 0.344 (0.475)	DT 0.306 (0.432)	loss 6.549 (6.606)	prob 2.511 (2.447)	GS 32.375 (31.717)	mem 73.128
Train: [80][120/1500]	BT 0.038 (0.467)	DT 0.001 (0.425)	loss 6.683 (6.630)	prob 2.963 (2.464)	GS 29.203 (31.875)	mem 73.116
Train: [80][130/1500]	BT 0.039 (0.434)	DT 0.000 (0.392)	loss 6.859 (6.646)	prob 1.594 (2.415)	GS 31.312 (31.449)	mem 73.115
Train: [80][140/1500]	BT 0.038 (0.418)	DT 0.001 (0.377)	loss 6.650 (6.641)	prob 2.525 (2.472)	GS 34.281 (31.675)	mem 73.117
Train: [80][150/1500]	BT 0.056 (0.428)	DT 0.006 (0.386)	loss 6.739 (6.642)	prob 1.807 (2.435)	GS 34.891 (32.028)	mem 73.135
Train: [80][160/1500]	BT 0.041 (0.408)	DT 0.001 (0.366)	loss 6.634 (6.714)	prob 2.783 (2.249)	GS 35.250 (32.683)	mem 73.135
Train: [80][170/1500]	BT 0.056 (0.425)	DT 0.005 (0.382)	loss 6.722 (6.666)	prob 2.605 (2.411)	GS 35.000 (32.549)	mem 73.141
Train: [80][180/1500]	BT 0.038 (0.419)	DT 0.001 (0.378)	loss 6.636 (6.676)	prob 2.692 (2.359)	GS 30.281 (32.783)	mem 73.145
Train: [80][190/1500]	BT 0.038 (0.409)	DT 0.001 (0.367)	loss 6.657 (6.689)	prob 1.919 (2.327)	GS 32.828 (32.691)	mem 73.146
Train: [80][200/1500]	BT 0.039 (0.395)	DT 0.001 (0.353)	loss 6.725 (6.678)	prob 1.921 (2.290)	GS 33.172 (32.667)	mem 73.146
Train: [80][210/1500]	BT 1.837 (0.386)	DT 1.799 (0.345)	loss 6.565 (6.610)	prob 2.647 (2.427)	GS 32.594 (33.152)	mem 73.147
Train: [80][220/1500]	BT 0.039 (0.381)	DT 0.001 (0.339)	loss 6.624 (6.595)	prob 3.158 (2.466)	GS 30.844 (32.620)	mem 73.150
Train: [80][230/1500]	BT 0.039 (0.369)	DT 0.001 (0.327)	loss 6.512 (6.607)	prob 2.355 (2.413)	GS 35.750 (32.682)	mem 73.151
Train: [80][240/1500]	BT 0.039 (0.369)	DT 0.001 (0.327)	loss 6.717 (6.606)	prob 2.627 (2.355)	GS 35.078 (33.056)	mem 73.153
Train: [80][250/1500]	BT 0.036 (0.359)	DT 0.000 (0.317)	loss 6.673 (6.602)	prob 1.967 (2.325)	GS 32.109 (32.725)	mem 73.166
Train: [80][260/1500]	BT 0.037 (0.348)	DT 0.001 (0.307)	loss 6.646 (6.582)	prob 1.933 (2.222)	GS 36.359 (34.622)	mem 73.165
Train: [80][270/1500]	BT 0.087 (0.351)	DT 0.008 (0.310)	loss 6.576 (6.575)	prob 2.222 (2.158)	GS 32.000 (32.965)	mem 73.171
Train: [80][280/1500]	BT 0.036 (0.368)	DT 0.001 (0.326)	loss 6.612 (6.586)	prob 2.451 (2.242)	GS 34.031 (33.604)	mem 73.175
Train: [80][290/1500]	BT 0.029 (0.358)	DT 0.000 (0.316)	loss 6.627 (6.590)	prob 3.425 (2.343)	GS 32.625 (33.132)	mem 73.176
Train: [80][300/1500]	BT 0.037 (0.349)	DT 0.000 (0.307)	loss 6.578 (6.581)	prob 1.770 (2.419)	GS 32.000 (32.807)	mem 73.178
Train: [80][310/1500]	BT 0.071 (0.358)	DT 0.008 (0.316)	loss 6.626 (6.601)	prob 2.620 (2.501)	GS 32.359 (31.350)	mem 73.183
Train: [80][320/1500]	BT 0.036 (0.361)	DT 0.001 (0.319)	loss 6.686 (6.627)	prob 1.863 (2.466)	GS 31.531 (32.525)	mem 73.182
Train: [80][330/1500]	BT 0.028 (0.355)	DT 0.000 (0.313)	loss 6.581 (6.622)	prob 2.511 (2.515)	GS 35.891 (32.594)	mem 73.184
Train: [80][340/1500]	BT 0.037 (0.346)	DT 0.001 (0.304)	loss 6.524 (6.612)	prob 2.482 (2.520)	GS 37.781 (32.688)	mem 73.185
Train: [80][350/1500]	BT 0.026 (0.356)	DT 0.000 (0.315)	loss 6.524 (6.616)	prob 2.795 (2.561)	GS 38.641 (33.000)	mem 73.189
Train: [80][360/1500]	BT 0.036 (0.347)	DT 0.000 (0.306)	loss 6.532 (6.618)	prob 2.814 (2.523)	GS 34.750 (31.655)	mem 73.189
Train: [80][370/1500]	BT 0.037 (0.346)	DT 0.001 (0.306)	loss 6.658 (6.604)	prob 2.534 (2.527)	GS 31.312 (31.866)	mem 73.192
Train: [80][380/1500]	BT 0.034 (0.339)	DT 0.000 (0.298)	loss 6.569 (6.638)	prob 3.726 (2.684)	GS 27.562 (32.256)	mem 73.192
Train: [80][390/1500]	BT 0.025 (0.341)	DT 0.000 (0.300)	loss 6.530 (6.633)	prob 3.043 (2.704)	GS 37.281 (32.440)	mem 73.194
Train: [80][400/1500]	BT 0.027 (0.333)	DT 0.000 (0.293)	loss 6.765 (6.639)	prob 2.670 (2.688)	GS 29.906 (32.647)	mem 73.193
Train: [80][410/1500]	BT 0.037 (0.326)	DT 0.001 (0.286)	loss 6.476 (6.697)	prob 3.068 (2.705)	GS 33.688 (32.470)	mem 73.195
Train: [80][420/1500]	BT 0.024 (0.330)	DT 0.000 (0.290)	loss 6.677 (6.652)	prob 3.425 (2.858)	GS 34.828 (32.332)	mem 73.295
Train: [80][430/1500]	BT 0.036 (0.324)	DT 0.001 (0.284)	loss 6.752 (6.636)	prob 1.833 (2.841)	GS 34.812 (32.307)	mem 73.296
Train: [80][440/1500]	BT 0.037 (0.327)	DT 0.000 (0.287)	loss 6.678 (6.636)	prob 2.542 (2.825)	GS 32.562 (32.349)	mem 73.935
Train: [80][450/1500]	BT 0.037 (0.320)	DT 0.001 (0.280)	loss 6.568 (6.635)	prob 2.791 (2.787)	GS 35.047 (32.502)	mem 74.032
Train: [80][460/1500]	BT 0.037 (0.314)	DT 0.000 (0.274)	loss 6.483 (6.632)	prob 2.790 (2.453)	GS 31.422 (30.822)	mem 74.081
Train: [80][470/1500]	BT 0.049 (0.317)	DT 0.006 (0.277)	loss 6.579 (6.605)	prob 2.054 (2.488)	GS 31.438 (31.783)	mem 74.379
Train: [80][480/1500]	BT 0.058 (0.311)	DT 0.011 (0.271)	loss 6.479 (6.611)	prob 2.734 (2.403)	GS 31.234 (31.539)	mem 74.379
Train: [80][490/1500]	BT 0.079 (0.328)	DT 0.021 (0.288)	loss 6.461 (6.623)	prob 2.723 (2.398)	GS 32.750 (32.029)	mem 74.381
Train: [80][500/1500]	BT 0.046 (0.323)	DT 0.002 (0.282)	loss 6.746 (6.622)	prob 2.527 (2.418)	GS 35.922 (32.340)	mem 74.383
Train: [80][510/1500]	BT 0.036 (0.362)	DT 0.000 (0.321)	loss 6.594 (6.606)	prob 2.780 (2.487)	GS 35.250 (32.525)	mem 74.384
Train: [80][520/1500]	BT 0.030 (0.356)	DT 0.000 (0.315)	loss 6.839 (6.640)	prob 2.248 (2.404)	GS 29.547 (32.144)	mem 74.386
Train: [80][530/1500]	BT 0.057 (0.356)	DT 0.006 (0.315)	loss 6.586 (6.643)	prob 2.361 (2.431)	GS 32.359 (32.435)	mem 74.390
Train: [80][540/1500]	BT 0.034 (0.350)	DT 0.000 (0.309)	loss 6.559 (6.649)	prob 3.082 (2.547)	GS 33.641 (32.532)	mem 74.390
Train: [80][550/1500]	BT 0.072 (0.345)	DT 0.012 (0.304)	loss 6.588 (6.639)	prob 3.572 (2.574)	GS 36.875 (32.819)	mem 74.389
Train: [80][560/1500]	BT 0.036 (0.354)	DT 0.001 (0.314)	loss 6.688 (6.626)	prob 2.788 (2.664)	GS 32.812 (34.153)	mem 74.390
Train: [80][570/1500]	BT 0.037 (0.349)	DT 0.001 (0.308)	loss 6.603 (6.621)	prob 2.201 (2.738)	GS 35.125 (33.650)	mem 74.391
Train: [80][580/1500]	BT 0.037 (0.346)	DT 0.001 (0.305)	loss 6.750 (6.630)	prob 1.798 (2.639)	GS 33.953 (33.502)	mem 74.391
Train: [80][590/1500]	BT 0.037 (0.345)	DT 0.001 (0.304)	loss 6.610 (6.622)	prob 1.898 (2.587)	GS 33.766 (33.186)	mem 74.392
Train: [80][600/1500]	BT 0.261 (0.340)	DT 0.227 (0.300)	loss 6.682 (6.625)	prob 2.805 (2.588)	GS 31.766 (33.094)	mem 74.396
Train: [80][610/1500]	BT 0.038 (0.339)	DT 0.001 (0.299)	loss 6.903 (6.652)	prob 2.185 (2.287)	GS 36.547 (33.309)	mem 74.396
Train: [80][620/1500]	BT 0.037 (0.335)	DT 0.001 (0.294)	loss 6.730 (6.674)	prob 2.005 (2.326)	GS 32.641 (32.519)	mem 74.396
Train: [80][630/1500]	BT 0.039 (0.336)	DT 0.001 (0.296)	loss 6.748 (6.659)	prob 1.975 (2.471)	GS 34.797 (32.695)	mem 74.427
Train: [80][640/1500]	BT 0.038 (0.332)	DT 0.001 (0.291)	loss 6.479 (6.648)	prob 2.934 (2.531)	GS 29.266 (32.531)	mem 74.428
Train: [80][650/1500]	BT 0.038 (0.327)	DT 0.000 (0.287)	loss 6.650 (6.641)	prob 1.050 (2.438)	GS 31.938 (32.312)	mem 74.428
Train: [80][660/1500]	BT 0.030 (0.342)	DT 0.000 (0.302)	loss 6.510 (6.654)	prob 2.421 (2.388)	GS 32.125 (35.480)	mem 74.429
Train: [80][670/1500]	BT 0.029 (0.338)	DT 0.000 (0.297)	loss 6.741 (6.633)	prob 2.948 (2.579)	GS 35.047 (34.108)	mem 74.429
Train: [80][680/1500]	BT 0.028 (0.341)	DT 0.001 (0.301)	loss 6.592 (6.640)	prob 2.234 (2.586)	GS 36.172 (33.727)	mem 74.430
Train: [80][690/1500]	BT 0.028 (0.337)	DT 0.000 (0.297)	loss 6.621 (6.637)	prob 2.937 (2.610)	GS 34.859 (33.989)	mem 74.430
Train: [80][700/1500]	BT 0.035 (0.332)	DT 0.001 (0.293)	loss 6.666 (6.636)	prob 1.791 (2.581)	GS 33.688 (33.601)	mem 74.432
Train: [80][710/1500]	BT 0.039 (0.332)	DT 0.001 (0.292)	loss 6.765 (6.601)	prob 2.529 (2.731)	GS 32.250 (32.917)	mem 74.433
Train: [80][720/1500]	BT 0.039 (0.328)	DT 0.001 (0.288)	loss 6.705 (6.597)	prob 2.558 (2.670)	GS 29.656 (32.305)	mem 74.433
Train: [80][730/1500]	BT 0.039 (0.329)	DT 0.001 (0.289)	loss 6.581 (6.601)	prob 2.829 (2.580)	GS 38.188 (32.533)	mem 74.433
Train: [80][740/1500]	BT 0.039 (0.325)	DT 0.001 (0.285)	loss 6.871 (6.595)	prob 2.123 (2.585)	GS 35.281 (32.265)	mem 74.433
Train: [80][750/1500]	BT 0.042 (0.321)	DT 0.001 (0.281)	loss 6.471 (6.587)	prob 2.211 (2.528)	GS 36.281 (32.350)	mem 74.434
Train: [80][760/1500]	BT 0.039 (0.324)	DT 0.001 (0.284)	loss 6.700 (6.609)	prob 2.563 (2.732)	GS 34.391 (32.872)	mem 74.434
Train: [80][770/1500]	BT 0.039 (0.321)	DT 0.001 (0.281)	loss 6.560 (6.603)	prob 3.279 (2.797)	GS 33.562 (32.508)	mem 74.435
Train: [80][780/1500]	BT 0.039 (0.321)	DT 0.001 (0.281)	loss 6.605 (6.598)	prob 3.141 (2.869)	GS 31.984 (32.381)	mem 74.437
Train: [80][790/1500]	BT 0.039 (0.318)	DT 0.001 (0.278)	loss 6.438 (6.592)	prob 2.995 (2.788)	GS 33.562 (32.402)	mem 74.437
Train: [80][800/1500]	BT 0.046 (0.319)	DT 0.014 (0.279)	loss 6.494 (6.585)	prob 2.284 (2.753)	GS 31.875 (32.494)	mem 74.435
Train: [80][810/1500]	BT 0.045 (0.320)	DT 0.000 (0.280)	loss 6.768 (6.610)	prob 2.297 (2.448)	GS 33.297 (31.717)	mem 74.433
Train: [80][820/1500]	BT 0.047 (0.317)	DT 0.000 (0.277)	loss 6.790 (6.609)	prob 1.931 (2.410)	GS 32.859 (31.625)	mem 74.435
Train: [80][830/1500]	BT 0.077 (0.324)	DT 0.003 (0.284)	loss 6.730 (6.593)	prob 2.413 (2.618)	GS 34.234 (32.606)	mem 74.436
Train: [80][840/1500]	BT 0.092 (0.321)	DT 0.011 (0.280)	loss 6.634 (6.591)	prob 1.554 (2.619)	GS 36.422 (32.486)	mem 74.435
Train: [80][850/1500]	BT 0.057 (0.325)	DT 0.000 (0.284)	loss 6.667 (6.597)	prob 1.941 (2.564)	GS 32.953 (32.643)	mem 74.434
Train: [80][860/1500]	BT 0.033 (0.327)	DT 0.000 (0.286)	loss 6.627 (6.599)	prob 1.922 (2.236)	GS 35.797 (33.427)	mem 74.434
Train: [80][870/1500]	BT 0.029 (0.341)	DT 0.000 (0.300)	loss 6.658 (6.625)	prob 2.881 (2.457)	GS 37.031 (34.062)	mem 74.431
Train: [80][880/1500]	BT 0.026 (0.337)	DT 0.000 (0.296)	loss 6.541 (6.619)	prob 2.895 (2.617)	GS 37.000 (35.319)	mem 74.432
Train: [80][890/1500]	BT 0.037 (0.337)	DT 0.000 (0.296)	loss 6.676 (6.621)	prob 1.871 (2.678)	GS 30.875 (34.577)	mem 74.440
Train: [80][900/1500]	BT 0.037 (0.333)	DT 0.001 (0.293)	loss 6.433 (6.616)	prob 2.902 (2.644)	GS 36.844 (34.191)	mem 74.441
Train: [80][910/1500]	BT 2.815 (0.333)	DT 2.778 (0.293)	loss 6.616 (6.585)	prob 1.638 (2.517)	GS 33.500 (32.294)	mem 74.443
Train: [80][920/1500]	BT 0.038 (0.330)	DT 0.000 (0.289)	loss 6.641 (6.596)	prob 2.611 (2.531)	GS 31.219 (31.722)	mem 74.453
Train: [80][930/1500]	BT 0.038 (0.327)	DT 0.000 (0.286)	loss 6.531 (6.594)	prob 2.773 (2.556)	GS 33.281 (31.438)	mem 74.453
Train: [80][940/1500]	BT 0.039 (0.327)	DT 0.013 (0.287)	loss 6.784 (6.609)	prob 2.136 (2.575)	GS 35.266 (31.680)	mem 74.473
Train: [80][950/1500]	BT 0.048 (0.324)	DT 0.011 (0.284)	loss 6.687 (6.617)	prob 3.190 (2.522)	GS 32.953 (31.661)	mem 74.335
Train: [80][960/1500]	BT 0.059 (0.324)	DT 0.000 (0.284)	loss 6.484 (6.619)	prob 2.263 (2.712)	GS 36.516 (31.587)	mem 74.357
Train: [80][970/1500]	BT 0.037 (0.324)	DT 0.001 (0.283)	loss 6.755 (6.617)	prob 1.953 (2.694)	GS 33.844 (32.237)	mem 74.355
Train: [80][980/1500]	BT 0.036 (0.322)	DT 0.001 (0.281)	loss 6.614 (6.624)	prob 2.539 (2.702)	GS 35.031 (32.561)	mem 74.356
Train: [80][990/1500]	BT 0.037 (0.322)	DT 0.001 (0.281)	loss 6.801 (6.641)	prob 1.920 (2.630)	GS 32.688 (32.444)	mem 74.356
Train: [80][1000/1500]	BT 0.036 (0.321)	DT 0.001 (0.280)	loss 6.648 (6.636)	prob 2.235 (2.600)	GS 31.062 (32.446)	mem 74.355
Train: [80][1010/1500]	BT 0.060 (0.320)	DT 0.002 (0.279)	loss 6.743 (6.599)	prob 2.001 (2.298)	GS 32.141 (32.420)	mem 74.356
Train: [80][1020/1500]	BT 0.051 (0.320)	DT 0.002 (0.279)	loss 6.751 (6.609)	prob 2.484 (2.377)	GS 25.469 (31.620)	mem 74.356
Train: [80][1030/1500]	BT 5.934 (0.324)	DT 5.901 (0.283)	loss 6.518 (6.602)	prob 2.711 (2.463)	GS 33.406 (31.927)	mem 74.355
Train: [80][1040/1500]	BT 0.061 (0.321)	DT 0.001 (0.280)	loss 6.422 (6.600)	prob 2.550 (2.485)	GS 32.391 (31.960)	mem 74.356
Train: [80][1050/1500]	BT 0.028 (0.321)	DT 0.000 (0.281)	loss 6.635 (6.599)	prob 2.472 (2.451)	GS 38.281 (32.538)	mem 74.374
Train: [80][1060/1500]	BT 0.037 (0.319)	DT 0.000 (0.279)	loss 6.592 (6.605)	prob 2.354 (2.625)	GS 33.922 (32.848)	mem 74.375
Train: [80][1070/1500]	BT 0.038 (0.319)	DT 0.001 (0.278)	loss 6.548 (6.637)	prob 3.304 (2.665)	GS 30.406 (32.136)	mem 74.364
Train: [80][1080/1500]	BT 0.038 (0.316)	DT 0.001 (0.276)	loss 6.602 (6.616)	prob 1.794 (2.563)	GS 31.938 (32.041)	mem 74.366
Train: [80][1090/1500]	BT 0.027 (0.314)	DT 0.000 (0.274)	loss 6.997 (6.623)	prob 1.553 (2.471)	GS 35.562 (31.889)	mem 74.367
Train: [80][1100/1500]	BT 0.062 (0.314)	DT 0.001 (0.274)	loss 6.478 (6.614)	prob 2.520 (2.438)	GS 33.094 (32.044)	mem 74.366
Train: [80][1110/1500]	BT 0.695 (0.314)	DT 0.657 (0.273)	loss 6.574 (6.626)	prob 2.968 (2.529)	GS 35.641 (32.797)	mem 74.367
Train: [80][1120/1500]	BT 0.039 (0.314)	DT 0.001 (0.273)	loss 6.654 (6.617)	prob 2.564 (2.577)	GS 35.922 (33.320)	mem 74.366
Train: [80][1130/1500]	BT 0.039 (0.312)	DT 0.001 (0.271)	loss 6.697 (6.613)	prob 2.283 (2.568)	GS 30.906 (33.057)	mem 74.365
Train: [80][1140/1500]	BT 0.039 (0.311)	DT 0.001 (0.271)	loss 6.968 (6.631)	prob 2.283 (2.668)	GS 32.000 (33.412)	mem 74.366
Train: [80][1150/1500]	BT 1.043 (0.311)	DT 1.005 (0.270)	loss 6.556 (6.625)	prob 2.484 (2.605)	GS 31.672 (33.289)	mem 74.367
Train: [80][1160/1500]	BT 0.039 (0.309)	DT 0.001 (0.268)	loss 6.491 (6.620)	prob 2.188 (2.199)	GS 33.828 (33.389)	mem 74.368
Train: [80][1170/1500]	BT 0.038 (0.310)	DT 0.001 (0.269)	loss 6.614 (6.641)	prob 2.241 (2.094)	GS 33.453 (32.490)	mem 74.369
Train: [80][1180/1500]	BT 0.039 (0.308)	DT 0.001 (0.268)	loss 6.453 (6.630)	prob 2.274 (2.084)	GS 34.562 (32.084)	mem 74.368
Train: [80][1190/1500]	BT 0.044 (0.307)	DT 0.011 (0.267)	loss 6.620 (6.610)	prob 2.753 (2.166)	GS 32.219 (32.487)	mem 74.370
Train: [80][1200/1500]	BT 0.035 (0.307)	DT 0.001 (0.267)	loss 6.681 (6.609)	prob 2.212 (2.171)	GS 34.844 (32.777)	mem 74.388
Train: [80][1210/1500]	BT 0.036 (0.306)	DT 0.000 (0.266)	loss 6.565 (6.659)	prob 2.456 (2.128)	GS 37.094 (32.920)	mem 74.390
Train: [80][1220/1500]	BT 0.027 (0.306)	DT 0.000 (0.266)	loss 6.526 (6.623)	prob 2.256 (2.239)	GS 37.141 (32.908)	mem 74.391
Train: [80][1230/1500]	BT 0.038 (0.304)	DT 0.001 (0.264)	loss 6.592 (6.606)	prob 2.142 (2.187)	GS 36.062 (32.866)	mem 74.392
Train: [80][1240/1500]	BT 0.037 (0.305)	DT 0.000 (0.265)	loss 6.584 (6.615)	prob 2.201 (2.225)	GS 33.125 (33.043)	mem 74.393
Train: [80][1250/1500]	BT 0.038 (0.303)	DT 0.001 (0.263)	loss 6.479 (6.607)	prob 1.968 (2.243)	GS 32.984 (33.027)	mem 74.393
Train: [80][1260/1500]	BT 0.038 (0.301)	DT 0.000 (0.261)	loss 6.611 (6.626)	prob 2.400 (2.021)	GS 35.219 (32.141)	mem 74.393
Train: [80][1270/1500]	BT 0.028 (0.303)	DT 0.000 (0.263)	loss 6.625 (6.609)	prob 1.706 (2.016)	GS 32.438 (31.875)	mem 74.396
Train: [80][1280/1500]	BT 0.025 (0.301)	DT 0.000 (0.261)	loss 6.736 (6.620)	prob 1.908 (2.043)	GS 35.891 (32.191)	mem 74.396
Train: [80][1290/1500]	BT 0.033 (0.302)	DT 0.000 (0.262)	loss 6.548 (6.630)	prob 2.068 (2.156)	GS 33.594 (32.210)	mem 74.398
Train: [80][1300/1500]	BT 0.037 (0.300)	DT 0.000 (0.260)	loss 6.785 (6.632)	prob 2.627 (2.146)	GS 34.734 (32.137)	mem 74.399
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [80][1310/1500]	BT 0.038 (0.298)	DT 0.001 (0.258)	loss 6.592 (6.643)	prob 2.819 (2.286)	GS 32.172 (32.534)	mem 74.398
Train: [80][1320/1500]	BT 0.038 (0.298)	DT 0.001 (0.258)	loss 6.536 (6.665)	prob 2.545 (2.361)	GS 26.750 (32.147)	mem 74.399
Train: [80][1330/1500]	BT 0.037 (0.296)	DT 0.001 (0.256)	loss 6.341 (6.637)	prob 2.240 (2.305)	GS 30.906 (32.390)	mem 74.399
Train: [80][1340/1500]	BT 0.038 (0.296)	DT 0.001 (0.257)	loss 6.768 (6.647)	prob 1.839 (2.245)	GS 35.609 (32.270)	mem 74.401
Train: [80][1350/1500]	BT 0.038 (0.294)	DT 0.001 (0.255)	loss 6.676 (6.637)	prob 2.080 (2.236)	GS 34.406 (32.657)	mem 74.400
Train: [80][1360/1500]	BT 0.037 (0.295)	DT 0.000 (0.255)	loss 6.613 (6.679)	prob 2.471 (2.498)	GS 31.266 (33.298)	mem 74.401
Train: [80][1370/1500]	BT 0.037 (0.294)	DT 0.001 (0.255)	loss 6.753 (6.674)	prob 2.381 (2.320)	GS 31.625 (32.926)	mem 74.401
Train: [80][1380/1500]	BT 0.037 (0.292)	DT 0.000 (0.253)	loss 6.530 (6.655)	prob 2.087 (2.298)	GS 32.703 (32.747)	mem 74.400
Train: [80][1390/1500]	BT 0.038 (0.292)	DT 0.001 (0.253)	loss 6.615 (6.650)	prob 1.717 (2.271)	GS 34.453 (32.885)	mem 74.400
Train: [80][1400/1500]	BT 0.038 (0.291)	DT 0.001 (0.252)	loss 6.570 (6.649)	prob 1.612 (2.198)	GS 33.594 (32.697)	mem 74.400
Train: [80][1410/1500]	BT 0.028 (0.292)	DT 0.000 (0.253)	loss 6.666 (6.756)	prob 2.178 (2.184)	GS 35.844 (32.959)	mem 74.401
Train: [80][1420/1500]	BT 0.037 (0.291)	DT 0.001 (0.251)	loss 6.769 (6.729)	prob 2.196 (2.117)	GS 33.859 (32.691)	mem 74.403
Train: [80][1430/1500]	BT 0.038 (0.289)	DT 0.001 (0.250)	loss 6.716 (6.704)	prob 1.895 (2.087)	GS 33.719 (32.717)	mem 74.404
Train: [80][1440/1500]	BT 0.060 (0.291)	DT 0.002 (0.252)	loss 6.515 (6.703)	prob 2.739 (2.069)	GS 31.328 (32.682)	mem 74.407
Train: [80][1450/1500]	BT 0.068 (0.289)	DT 0.006 (0.250)	loss 6.628 (6.707)	prob 2.420 (2.113)	GS 36.422 (32.592)	mem 74.407
Train: [80][1460/1500]	BT 0.076 (0.290)	DT 0.010 (0.251)	loss 6.671 (6.628)	prob 1.913 (2.450)	GS 35.859 (31.464)	mem 74.373
Train: [80][1470/1500]	BT 0.060 (0.291)	DT 0.006 (0.251)	loss 6.535 (6.676)	prob 2.880 (2.298)	GS 33.500 (31.963)	mem 73.643
Train: [80][1480/1500]	BT 0.027 (0.292)	DT 0.000 (0.252)	loss 6.965 (6.717)	prob 1.532 (2.180)	GS 33.500 (32.542)	mem 15.019
Train: [80][1490/1500]	BT 0.030 (0.290)	DT 0.000 (0.250)	loss 6.645 (6.726)	prob 2.431 (2.204)	GS 38.531 (32.519)	mem 15.019
Train: [80][1500/1500]	BT 0.027 (0.289)	DT 0.000 (0.249)	loss 7.174 (6.730)	prob 1.576 (2.243)	GS 34.594 (32.669)	mem 12.130
Train: [80][1510/1500]	BT 0.024 (0.287)	DT 0.000 (0.248)	loss 6.795 (6.550)	prob 2.147 (2.372)	GS 31.250 (33.291)	mem 12.057
epoch 80, total time 433.44
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [81][1/1500]	BT 18.284 (18.284)	DT 18.215 (18.215)	loss 6.396 (6.396)	prob 2.934 (2.934)	GS 32.984 (32.984)	mem 72.772
Train: [81][10/1500]	BT 0.039 (2.300)	DT 0.001 (2.262)	loss 6.441 (6.502)	prob 2.728 (2.238)	GS 38.438 (32.773)	mem 72.997
Train: [81][20/1500]	BT 0.039 (1.170)	DT 0.001 (1.132)	loss 6.862 (6.548)	prob 2.319 (2.363)	GS 35.312 (32.282)	mem 73.019
Train: [81][30/1500]	BT 1.338 (0.952)	DT 1.292 (0.912)	loss 6.656 (6.560)	prob 2.566 (2.395)	GS 33.125 (32.529)	mem 73.100
Train: [81][40/1500]	BT 0.096 (0.739)	DT 0.012 (0.692)	loss 6.922 (6.606)	prob 1.668 (2.362)	GS 36.312 (32.095)	mem 73.104
Train: [81][50/1500]	BT 0.034 (0.795)	DT 0.001 (0.749)	loss 6.611 (6.635)	prob 3.462 (2.394)	GS 32.266 (32.247)	mem 73.149
Train: [81][60/1500]	BT 0.029 (0.668)	DT 0.000 (0.624)	loss 6.815 (6.832)	prob 2.429 (2.491)	GS 35.172 (33.212)	mem 73.150
Train: [81][70/1500]	BT 0.034 (0.647)	DT 0.000 (0.605)	loss 6.668 (6.827)	prob 3.571 (2.521)	GS 35.438 (32.324)	mem 73.164
Train: [81][80/1500]	BT 0.031 (0.570)	DT 0.000 (0.530)	loss 6.702 (6.817)	prob 2.323 (2.497)	GS 33.547 (32.374)	mem 73.165
Train: [81][90/1500]	BT 0.037 (0.510)	DT 0.000 (0.471)	loss 6.923 (6.815)	prob 2.938 (2.484)	GS 34.703 (32.250)	mem 73.166
Train: [81][100/1500]	BT 0.031 (0.501)	DT 0.000 (0.462)	loss 6.872 (6.822)	prob 3.043 (2.560)	GS 32.266 (32.483)	mem 73.174
Train: [81][110/1500]	BT 0.034 (0.458)	DT 0.001 (0.420)	loss 6.849 (6.757)	prob 2.767 (2.986)	GS 34.953 (31.306)	mem 73.176
Train: [81][120/1500]	BT 0.030 (0.469)	DT 0.001 (0.432)	loss 6.793 (6.777)	prob 2.998 (2.811)	GS 29.453 (31.742)	mem 73.185
Train: [81][130/1500]	BT 0.039 (0.437)	DT 0.004 (0.399)	loss 6.883 (6.754)	prob 2.442 (2.726)	GS 35.672 (31.822)	mem 73.187
Train: [81][140/1500]	BT 0.069 (0.450)	DT 0.012 (0.412)	loss 6.812 (6.764)	prob 2.687 (2.669)	GS 39.547 (32.303)	mem 73.187
Train: [81][150/1500]	BT 0.058 (0.433)	DT 0.011 (0.394)	loss 6.806 (6.774)	prob 2.880 (2.713)	GS 33.234 (32.493)	mem 73.189
Train: [81][160/1500]	BT 0.033 (0.409)	DT 0.000 (0.370)	loss 6.709 (6.782)	prob 2.204 (2.613)	GS 36.125 (33.362)	mem 73.189
Train: [81][170/1500]	BT 0.035 (0.421)	DT 0.003 (0.381)	loss 7.012 (6.817)	prob 2.510 (2.499)	GS 34.969 (32.566)	mem 73.196
Train: [81][180/1500]	BT 0.029 (0.400)	DT 0.000 (0.361)	loss 7.042 (6.833)	prob 2.879 (2.506)	GS 38.234 (33.028)	mem 73.196
Train: [81][190/1500]	BT 0.036 (0.409)	DT 0.000 (0.369)	loss 6.641 (6.831)	prob 2.999 (2.556)	GS 31.391 (32.668)	mem 73.208
Train: [81][200/1500]	BT 0.030 (0.395)	DT 0.000 (0.356)	loss 6.896 (6.835)	prob 3.761 (2.612)	GS 35.938 (32.937)	mem 73.208
Train: [81][210/1500]	BT 0.034 (0.379)	DT 0.001 (0.339)	loss 6.566 (6.823)	prob 2.618 (2.820)	GS 30.281 (33.384)	mem 73.211
Train: [81][220/1500]	BT 0.027 (0.385)	DT 0.000 (0.346)	loss 6.720 (6.824)	prob 3.816 (2.849)	GS 33.250 (33.348)	mem 73.114
Train: [81][230/1500]	BT 0.037 (0.369)	DT 0.000 (0.331)	loss 6.863 (6.810)	prob 2.718 (2.840)	GS 34.484 (33.076)	mem 73.114
Train: [81][240/1500]	BT 0.035 (0.371)	DT 0.000 (0.333)	loss 6.954 (6.818)	prob 3.391 (2.815)	GS 38.219 (33.276)	mem 73.113
Train: [81][250/1500]	BT 0.048 (0.361)	DT 0.014 (0.323)	loss 6.958 (6.808)	prob 2.459 (2.795)	GS 35.125 (33.086)	mem 73.115
Train: [81][260/1500]	BT 0.053 (0.368)	DT 0.006 (0.329)	loss 6.883 (6.802)	prob 3.071 (2.823)	GS 34.062 (31.761)	mem 73.116
Train: [81][270/1500]	BT 0.057 (0.368)	DT 0.011 (0.328)	loss 6.624 (6.787)	prob 2.748 (2.845)	GS 36.125 (32.564)	mem 73.117
Train: [81][280/1500]	BT 0.060 (0.357)	DT 0.011 (0.317)	loss 6.692 (6.817)	prob 3.228 (2.839)	GS 32.344 (32.239)	mem 73.116
Train: [81][290/1500]	BT 0.026 (0.394)	DT 0.000 (0.354)	loss 6.991 (6.810)	prob 2.829 (2.805)	GS 34.547 (32.499)	mem 73.142
Train: [81][300/1500]	BT 0.023 (0.381)	DT 0.000 (0.342)	loss 6.748 (6.810)	prob 3.338 (2.833)	GS 29.609 (32.536)	mem 73.144
Train: [81][310/1500]	BT 0.026 (0.383)	DT 0.000 (0.344)	loss 6.770 (6.840)	prob 2.641 (2.651)	GS 30.672 (31.417)	mem 73.131
Train: [81][320/1500]	BT 0.038 (0.372)	DT 0.001 (0.333)	loss 6.672 (6.832)	prob 4.183 (2.888)	GS 34.703 (32.329)	mem 73.132
Train: [81][330/1500]	BT 0.039 (0.362)	DT 0.001 (0.323)	loss 6.945 (6.819)	prob 2.572 (2.795)	GS 34.484 (32.159)	mem 73.133
Train: [81][340/1500]	BT 0.038 (0.363)	DT 0.001 (0.324)	loss 7.149 (6.807)	prob 2.417 (2.786)	GS 34.375 (32.443)	mem 73.134
Train: [81][350/1500]	BT 0.040 (0.353)	DT 0.001 (0.315)	loss 6.769 (6.791)	prob 2.519 (2.757)	GS 35.688 (32.484)	mem 73.134
Train: [81][360/1500]	BT 0.053 (0.352)	DT 0.006 (0.314)	loss 6.979 (6.803)	prob 3.169 (2.809)	GS 34.672 (32.814)	mem 73.136
Train: [81][370/1500]	BT 0.055 (0.344)	DT 0.005 (0.306)	loss 6.935 (6.831)	prob 3.015 (2.767)	GS 34.391 (32.991)	mem 73.136
Train: [81][380/1500]	BT 0.072 (0.337)	DT 0.012 (0.298)	loss 6.774 (6.815)	prob 2.973 (2.799)	GS 30.656 (32.529)	mem 73.136
Train: [81][390/1500]	BT 0.031 (0.343)	DT 0.000 (0.304)	loss 6.935 (6.832)	prob 2.322 (2.760)	GS 31.922 (32.615)	mem 73.141
Train: [81][400/1500]	BT 0.081 (0.336)	DT 0.003 (0.297)	loss 7.031 (6.832)	prob 2.161 (2.714)	GS 31.375 (32.926)	mem 73.141
Train: [81][410/1500]	BT 0.027 (0.351)	DT 0.004 (0.311)	loss 6.609 (6.798)	prob 2.713 (2.629)	GS 35.062 (34.656)	mem 73.144
Train: [81][420/1500]	BT 0.038 (0.343)	DT 0.001 (0.304)	loss 6.825 (6.814)	prob 2.860 (2.782)	GS 33.312 (34.408)	mem 73.144
Train: [81][430/1500]	BT 0.039 (0.339)	DT 0.001 (0.299)	loss 6.652 (6.820)	prob 3.658 (2.814)	GS 35.531 (33.751)	mem 73.145
Train: [81][440/1500]	BT 0.053 (0.338)	DT 0.010 (0.299)	loss 6.773 (6.803)	prob 3.009 (2.823)	GS 37.938 (33.353)	mem 73.162
Train: [81][450/1500]	BT 0.071 (0.332)	DT 0.003 (0.293)	loss 6.818 (6.832)	prob 3.202 (2.805)	GS 32.219 (33.319)	mem 73.162
Train: [81][460/1500]	BT 0.090 (0.350)	DT 0.009 (0.310)	loss 6.691 (6.828)	prob 2.745 (2.789)	GS 32.500 (34.311)	mem 73.163
Train: [81][470/1500]	BT 0.060 (0.344)	DT 0.006 (0.303)	loss 6.667 (6.793)	prob 3.411 (2.792)	GS 29.891 (32.780)	mem 73.163
Train: [81][480/1500]	BT 0.034 (0.373)	DT 0.000 (0.332)	loss 6.679 (6.798)	prob 3.158 (2.769)	GS 26.453 (32.418)	mem 73.168
Train: [81][490/1500]	BT 0.029 (0.366)	DT 0.000 (0.325)	loss 6.822 (6.798)	prob 2.973 (2.799)	GS 31.938 (33.145)	mem 73.168
Train: [81][500/1500]	BT 0.036 (0.359)	DT 0.001 (0.319)	loss 6.517 (6.798)	prob 3.293 (2.840)	GS 34.156 (33.234)	mem 73.169
Train: [81][510/1500]	BT 0.027 (0.360)	DT 0.000 (0.320)	loss 6.631 (6.840)	prob 3.643 (3.044)	GS 33.219 (32.931)	mem 73.172
Train: [81][520/1500]	BT 0.027 (0.354)	DT 0.000 (0.314)	loss 6.694 (6.826)	prob 2.466 (2.887)	GS 31.625 (33.068)	mem 73.173
Train: [81][530/1500]	BT 0.043 (0.357)	DT 0.001 (0.317)	loss 6.939 (6.804)	prob 2.224 (2.891)	GS 35.391 (32.480)	mem 73.175
Train: [81][540/1500]	BT 0.059 (0.352)	DT 0.011 (0.312)	loss 6.892 (6.794)	prob 2.834 (2.891)	GS 34.719 (32.317)	mem 73.175
Train: [81][550/1500]	BT 0.097 (0.359)	DT 0.011 (0.319)	loss 6.864 (6.789)	prob 2.529 (2.830)	GS 33.625 (32.346)	mem 73.176
Train: [81][560/1500]	BT 0.052 (0.354)	DT 0.000 (0.313)	loss 6.841 (6.831)	prob 2.693 (2.515)	GS 31.297 (33.647)	mem 73.178
Train: [81][570/1500]	BT 0.038 (0.357)	DT 0.001 (0.316)	loss 6.656 (6.799)	prob 3.070 (2.580)	GS 31.375 (33.685)	mem 73.180
Train: [81][580/1500]	BT 0.028 (0.361)	DT 0.000 (0.321)	loss 6.831 (6.784)	prob 2.403 (2.596)	GS 35.484 (33.854)	mem 73.230
Train: [81][590/1500]	BT 0.026 (0.356)	DT 0.000 (0.315)	loss 6.790 (6.795)	prob 2.675 (2.622)	GS 34.906 (33.413)	mem 73.230
Train: [81][600/1500]	BT 0.040 (0.355)	DT 0.000 (0.315)	loss 6.720 (6.798)	prob 3.521 (2.694)	GS 31.312 (33.334)	mem 73.332
Train: [81][610/1500]	BT 0.027 (0.350)	DT 0.000 (0.310)	loss 6.748 (6.758)	prob 2.152 (2.495)	GS 35.203 (32.047)	mem 73.331
Train: [81][620/1500]	BT 0.031 (0.345)	DT 0.000 (0.305)	loss 6.875 (6.784)	prob 3.056 (2.556)	GS 34.844 (31.918)	mem 73.381
Train: [81][630/1500]	BT 0.037 (0.348)	DT 0.000 (0.308)	loss 6.712 (6.773)	prob 2.595 (2.665)	GS 37.609 (32.440)	mem 74.169
Train: [81][640/1500]	BT 0.037 (0.343)	DT 0.000 (0.303)	loss 6.860 (6.783)	prob 2.686 (2.668)	GS 36.734 (32.698)	mem 74.169
Train: [81][650/1500]	BT 0.037 (0.343)	DT 0.001 (0.303)	loss 7.032 (6.778)	prob 1.809 (2.659)	GS 31.375 (32.410)	mem 74.269
Train: [81][660/1500]	BT 0.038 (0.338)	DT 0.000 (0.298)	loss 6.956 (6.772)	prob 2.788 (2.726)	GS 32.047 (32.906)	mem 74.319
Train: [81][670/1500]	BT 0.037 (0.340)	DT 0.000 (0.300)	loss 6.756 (6.712)	prob 2.150 (2.727)	GS 32.234 (32.704)	mem 74.368
Train: [81][680/1500]	BT 0.037 (0.335)	DT 0.000 (0.295)	loss 6.623 (6.718)	prob 1.900 (2.613)	GS 33.250 (32.593)	mem 74.368
Train: [81][690/1500]	BT 0.038 (0.331)	DT 0.001 (0.291)	loss 6.614 (6.745)	prob 3.233 (2.678)	GS 32.391 (32.311)	mem 74.368
Train: [81][700/1500]	BT 0.037 (0.335)	DT 0.001 (0.296)	loss 6.775 (6.744)	prob 3.002 (2.722)	GS 33.734 (32.273)	mem 74.369
Train: [81][710/1500]	BT 0.038 (0.331)	DT 0.001 (0.291)	loss 6.925 (6.739)	prob 2.329 (2.898)	GS 35.312 (32.377)	mem 74.369
Train: [81][720/1500]	BT 0.024 (0.333)	DT 0.000 (0.293)	loss 6.578 (6.725)	prob 2.717 (2.649)	GS 31.156 (32.062)	mem 74.371
Train: [81][730/1500]	BT 0.037 (0.329)	DT 0.001 (0.289)	loss 6.676 (6.713)	prob 2.920 (2.633)	GS 31.078 (32.039)	mem 74.371
Train: [81][740/1500]	BT 0.069 (0.325)	DT 0.031 (0.285)	loss 6.815 (6.718)	prob 3.271 (2.593)	GS 32.516 (31.795)	mem 74.371
Train: [81][750/1500]	BT 0.030 (0.333)	DT 0.001 (0.293)	loss 6.978 (6.734)	prob 2.734 (2.625)	GS 34.031 (32.381)	mem 74.375
Train: [81][760/1500]	BT 0.037 (0.329)	DT 0.000 (0.289)	loss 7.059 (6.761)	prob 2.395 (2.511)	GS 32.844 (32.455)	mem 74.376
Train: [81][770/1500]	BT 0.037 (0.331)	DT 0.000 (0.291)	loss 6.926 (6.750)	prob 2.963 (2.508)	GS 33.703 (31.848)	mem 74.376
Train: [81][780/1500]	BT 0.038 (0.328)	DT 0.001 (0.288)	loss 6.486 (6.755)	prob 3.307 (2.541)	GS 35.781 (32.255)	mem 74.376
Train: [81][790/1500]	BT 0.038 (0.327)	DT 0.000 (0.288)	loss 6.839 (6.755)	prob 2.328 (2.480)	GS 33.469 (32.539)	mem 74.377
Train: [81][800/1500]	BT 0.039 (0.326)	DT 0.001 (0.287)	loss 6.740 (6.748)	prob 2.189 (2.509)	GS 30.922 (32.391)	mem 74.409
Train: [81][810/1500]	BT 0.039 (0.323)	DT 0.001 (0.283)	loss 6.851 (6.724)	prob 2.806 (2.888)	GS 34.469 (32.448)	mem 74.409
Train: [81][820/1500]	BT 0.036 (0.321)	DT 0.001 (0.282)	loss 6.730 (6.709)	prob 2.358 (2.915)	GS 29.859 (31.857)	mem 74.409
Train: [81][830/1500]	BT 0.029 (0.321)	DT 0.000 (0.282)	loss 6.708 (6.691)	prob 2.195 (2.821)	GS 30.625 (32.013)	mem 74.410
Train: [81][840/1500]	BT 0.025 (0.319)	DT 0.000 (0.280)	loss 6.792 (6.703)	prob 2.833 (2.793)	GS 34.219 (32.228)	mem 74.412
Train: [81][850/1500]	BT 0.039 (0.318)	DT 0.001 (0.279)	loss 6.838 (6.708)	prob 2.388 (2.779)	GS 36.828 (32.410)	mem 74.415
Train: [81][860/1500]	BT 0.040 (0.315)	DT 0.001 (0.276)	loss 6.571 (6.718)	prob 2.752 (3.041)	GS 39.297 (32.987)	mem 74.414
Train: [81][870/1500]	BT 0.038 (0.318)	DT 0.001 (0.279)	loss 6.732 (6.680)	prob 2.723 (3.016)	GS 34.359 (33.199)	mem 74.414
Train: [81][880/1500]	BT 0.039 (0.315)	DT 0.001 (0.276)	loss 6.761 (6.705)	prob 2.829 (3.034)	GS 39.875 (33.511)	mem 74.416
Train: [81][890/1500]	BT 0.032 (0.315)	DT 0.000 (0.276)	loss 6.706 (6.697)	prob 2.601 (2.964)	GS 31.203 (33.514)	mem 74.413
Train: [81][900/1500]	BT 0.035 (0.320)	DT 0.000 (0.281)	loss 6.719 (6.711)	prob 2.714 (2.982)	GS 33.953 (33.837)	mem 74.412
Train: [81][910/1500]	BT 0.036 (0.317)	DT 0.001 (0.277)	loss 6.607 (6.757)	prob 2.641 (2.767)	GS 40.531 (34.027)	mem 74.413
Train: [81][920/1500]	BT 0.032 (0.318)	DT 0.000 (0.278)	loss 6.667 (6.746)	prob 2.594 (2.684)	GS 36.859 (33.079)	mem 74.411
Train: [81][930/1500]	BT 0.037 (0.315)	DT 0.001 (0.276)	loss 6.865 (6.726)	prob 3.491 (2.770)	GS 35.219 (32.963)	mem 74.413
Train: [81][940/1500]	BT 0.039 (0.312)	DT 0.001 (0.273)	loss 6.564 (6.712)	prob 2.787 (2.814)	GS 33.547 (32.600)	mem 74.413
Train: [81][950/1500]	BT 0.039 (0.319)	DT 0.000 (0.280)	loss 6.564 (6.709)	prob 2.332 (2.790)	GS 33.297 (32.618)	mem 74.411
Train: [81][960/1500]	BT 0.033 (0.316)	DT 0.001 (0.277)	loss 6.628 (6.682)	prob 2.560 (2.653)	GS 36.875 (31.959)	mem 74.412
Train: [81][970/1500]	BT 0.040 (0.316)	DT 0.001 (0.277)	loss 6.676 (6.683)	prob 2.747 (2.776)	GS 35.250 (32.945)	mem 74.413
Train: [81][980/1500]	BT 0.038 (0.313)	DT 0.001 (0.274)	loss 6.831 (6.697)	prob 3.429 (2.837)	GS 37.266 (33.146)	mem 74.413
Train: [81][990/1500]	BT 0.039 (0.313)	DT 0.001 (0.274)	loss 6.895 (6.702)	prob 2.376 (2.892)	GS 31.000 (33.206)	mem 74.415
Train: [81][1000/1500]	BT 0.040 (0.311)	DT 0.001 (0.272)	loss 6.665 (6.701)	prob 2.644 (2.846)	GS 35.094 (33.017)	mem 74.415
Train: [81][1010/1500]	BT 0.039 (0.308)	DT 0.001 (0.269)	loss 6.690 (6.723)	prob 2.645 (2.943)	GS 24.562 (32.648)	mem 74.415
Train: [81][1020/1500]	BT 0.039 (0.309)	DT 0.001 (0.270)	loss 6.542 (6.742)	prob 2.546 (2.898)	GS 34.344 (32.264)	mem 74.417
Train: [81][1030/1500]	BT 0.035 (0.309)	DT 0.001 (0.270)	loss 6.549 (6.727)	prob 2.479 (2.838)	GS 31.641 (32.019)	mem 74.416
Train: [81][1040/1500]	BT 0.056 (0.311)	DT 0.004 (0.273)	loss 6.570 (6.749)	prob 4.181 (2.828)	GS 33.906 (31.862)	mem 74.415
Train: [81][1050/1500]	BT 0.092 (0.309)	DT 0.039 (0.270)	loss 6.886 (6.755)	prob 2.284 (2.843)	GS 32.828 (32.047)	mem 74.416
Train: [81][1060/1500]	BT 0.083 (0.313)	DT 0.002 (0.273)	loss 6.811 (6.808)	prob 3.016 (3.243)	GS 35.594 (33.433)	mem 74.415
Train: [81][1070/1500]	BT 0.019 (0.325)	DT 0.000 (0.285)	loss 6.930 (6.818)	prob 2.515 (3.090)	GS 37.078 (33.880)	mem 74.422
Train: [81][1080/1500]	BT 0.021 (0.322)	DT 0.000 (0.283)	loss 6.806 (6.806)	prob 2.436 (3.072)	GS 33.625 (33.474)	mem 74.423
Train: [81][1090/1500]	BT 0.035 (0.319)	DT 0.000 (0.280)	loss 6.737 (6.805)	prob 2.714 (2.998)	GS 33.016 (33.018)	mem 74.424
Train: [81][1100/1500]	BT 0.027 (0.323)	DT 0.000 (0.284)	loss 6.685 (6.798)	prob 3.686 (3.041)	GS 33.297 (33.208)	mem 74.436
Train: [81][1110/1500]	BT 0.024 (0.320)	DT 0.000 (0.281)	loss 6.622 (6.808)	prob 3.128 (2.695)	GS 33.688 (32.066)	mem 74.437
Train: [81][1120/1500]	BT 0.038 (0.320)	DT 0.001 (0.281)	loss 6.739 (6.822)	prob 2.280 (2.755)	GS 30.625 (32.628)	mem 74.324
Train: [81][1130/1500]	BT 0.037 (0.318)	DT 0.001 (0.279)	loss 6.727 (6.813)	prob 2.692 (2.917)	GS 32.047 (33.034)	mem 74.333
Train: [81][1140/1500]	BT 0.037 (0.315)	DT 0.001 (0.276)	loss 6.809 (6.809)	prob 2.600 (2.961)	GS 36.188 (33.411)	mem 74.333
Train: [81][1150/1500]	BT 0.037 (0.318)	DT 0.000 (0.279)	loss 6.792 (6.808)	prob 2.460 (2.958)	GS 28.766 (33.017)	mem 74.333
Train: [81][1160/1500]	BT 0.038 (0.317)	DT 0.001 (0.279)	loss 6.933 (6.802)	prob 2.701 (2.687)	GS 33.312 (32.872)	mem 74.332
Train: [81][1170/1500]	BT 0.037 (0.316)	DT 0.001 (0.278)	loss 6.827 (6.811)	prob 2.483 (2.681)	GS 34.984 (32.712)	mem 74.331
Train: [81][1180/1500]	BT 0.036 (0.317)	DT 0.000 (0.278)	loss 6.803 (6.805)	prob 2.604 (2.721)	GS 38.125 (33.006)	mem 74.330
Train: [81][1190/1500]	BT 0.037 (0.314)	DT 0.001 (0.275)	loss 6.782 (6.794)	prob 2.429 (2.733)	GS 31.500 (33.013)	mem 74.332
Train: [81][1200/1500]	BT 0.037 (0.312)	DT 0.001 (0.273)	loss 6.700 (6.786)	prob 2.826 (2.681)	GS 32.672 (33.005)	mem 74.331
Train: [81][1210/1500]	BT 0.038 (0.312)	DT 0.001 (0.273)	loss 6.776 (6.752)	prob 1.955 (2.422)	GS 31.531 (33.337)	mem 74.353
Train: [81][1220/1500]	BT 0.038 (0.311)	DT 0.001 (0.272)	loss 6.839 (6.757)	prob 3.050 (2.557)	GS 32.359 (32.910)	mem 74.355
Train: [81][1230/1500]	BT 0.038 (0.312)	DT 0.001 (0.273)	loss 6.673 (6.760)	prob 2.409 (2.543)	GS 34.625 (32.987)	mem 74.357
Train: [81][1240/1500]	BT 0.037 (0.310)	DT 0.000 (0.272)	loss 6.465 (6.751)	prob 3.721 (2.580)	GS 31.453 (32.706)	mem 74.357
Train: [81][1250/1500]	BT 0.039 (0.308)	DT 0.001 (0.269)	loss 6.775 (6.747)	prob 2.141 (2.635)	GS 30.203 (32.193)	mem 74.357
Train: [81][1260/1500]	BT 0.039 (0.308)	DT 0.001 (0.270)	loss 6.733 (6.787)	prob 2.655 (2.665)	GS 28.438 (31.150)	mem 74.358
Train: [81][1270/1500]	BT 0.039 (0.306)	DT 0.001 (0.268)	loss 6.819 (6.748)	prob 2.654 (2.660)	GS 34.953 (32.091)	mem 74.358
Train: [81][1280/1500]	BT 0.039 (0.306)	DT 0.001 (0.268)	loss 6.749 (6.717)	prob 2.363 (2.585)	GS 32.500 (31.742)	mem 74.345
Train: [81][1290/1500]	BT 0.058 (0.306)	DT 0.011 (0.267)	loss 6.953 (6.736)	prob 2.589 (2.621)	GS 32.484 (32.068)	mem 74.346
Train: [81][1300/1500]	BT 0.034 (0.312)	DT 0.001 (0.273)	loss 6.820 (6.738)	prob 2.342 (2.645)	GS 34.484 (32.344)	mem 74.345
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [81][1310/1500]	BT 0.031 (0.309)	DT 0.000 (0.271)	loss 6.765 (6.733)	prob 1.991 (2.497)	GS 32.281 (32.191)	mem 74.345
Train: [81][1320/1500]	BT 0.039 (0.307)	DT 0.001 (0.269)	loss 6.846 (6.723)	prob 2.265 (2.460)	GS 36.125 (32.698)	mem 74.348
Train: [81][1330/1500]	BT 0.038 (0.308)	DT 0.001 (0.270)	loss 6.868 (6.743)	prob 2.219 (2.386)	GS 33.953 (32.654)	mem 74.349
Train: [81][1340/1500]	BT 0.025 (0.306)	DT 0.000 (0.268)	loss 6.768 (6.734)	prob 2.480 (2.423)	GS 32.016 (32.508)	mem 74.361
Train: [81][1350/1500]	BT 0.054 (0.309)	DT 0.016 (0.271)	loss 6.852 (6.743)	prob 2.479 (2.421)	GS 38.094 (32.653)	mem 74.364
Train: [81][1360/1500]	BT 0.029 (0.309)	DT 0.000 (0.271)	loss 7.064 (6.773)	prob 2.110 (2.526)	GS 34.234 (34.533)	mem 74.368
Train: [81][1370/1500]	BT 0.048 (0.307)	DT 0.006 (0.269)	loss 6.796 (6.752)	prob 2.483 (2.508)	GS 32.484 (33.285)	mem 74.370
Train: [81][1380/1500]	BT 0.027 (0.308)	DT 0.000 (0.270)	loss 6.674 (6.743)	prob 3.256 (2.480)	GS 31.531 (33.289)	mem 74.372
Train: [81][1390/1500]	BT 0.038 (0.306)	DT 0.001 (0.268)	loss 6.860 (6.735)	prob 1.604 (2.437)	GS 32.922 (32.910)	mem 74.372
Train: [81][1400/1500]	BT 0.037 (0.306)	DT 0.000 (0.268)	loss 6.935 (6.738)	prob 2.369 (2.395)	GS 27.562 (32.782)	mem 74.375
Train: [81][1410/1500]	BT 0.037 (0.304)	DT 0.001 (0.266)	loss 6.695 (6.673)	prob 2.444 (2.321)	GS 34.844 (32.188)	mem 74.373
Train: [81][1420/1500]	BT 0.037 (0.303)	DT 0.000 (0.265)	loss 6.688 (6.671)	prob 2.671 (2.416)	GS 36.578 (32.937)	mem 74.376
Train: [81][1430/1500]	BT 0.038 (0.303)	DT 0.001 (0.264)	loss 6.671 (6.678)	prob 2.698 (2.387)	GS 34.094 (32.927)	mem 74.377
Train: [81][1440/1500]	BT 0.038 (0.301)	DT 0.001 (0.262)	loss 6.742 (6.697)	prob 2.203 (2.410)	GS 34.375 (32.817)	mem 74.376
Train: [81][1450/1500]	BT 0.024 (0.303)	DT 0.000 (0.265)	loss 6.636 (6.696)	prob 2.817 (2.428)	GS 37.219 (32.633)	mem 74.303
Train: [81][1460/1500]	BT 0.037 (0.302)	DT 0.001 (0.263)	loss 6.999 (6.719)	prob 2.629 (2.200)	GS 35.906 (32.509)	mem 74.231
Train: [81][1470/1500]	BT 0.037 (0.300)	DT 0.001 (0.262)	loss 6.607 (6.722)	prob 2.431 (2.287)	GS 30.078 (31.898)	mem 74.231
Train: [81][1480/1500]	BT 0.029 (0.300)	DT 0.000 (0.262)	loss 6.750 (6.745)	prob 2.538 (2.299)	GS 32.906 (32.241)	mem 43.199
Train: [81][1490/1500]	BT 0.017 (0.298)	DT 0.000 (0.260)	loss 6.609 (6.739)	prob 3.227 (2.391)	GS 27.344 (32.458)	mem 28.972
Train: [81][1500/1500]	BT 0.030 (0.297)	DT 0.001 (0.259)	loss 6.794 (6.721)	prob 2.067 (2.440)	GS 38.031 (32.654)	mem 12.123
Train: [81][1510/1500]	BT 0.025 (0.295)	DT 0.000 (0.257)	loss 6.214 (6.494)	prob 2.174 (2.413)	GS 32.125 (32.322)	mem 9.346
epoch 81, total time 445.77
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [82][1/1500]	BT 23.810 (23.810)	DT 23.758 (23.758)	loss 6.316 (6.316)	prob 2.608 (2.608)	GS 28.859 (28.859)	mem 73.097
Train: [82][10/1500]	BT 0.036 (2.410)	DT 0.000 (2.376)	loss 6.588 (6.403)	prob 2.503 (2.430)	GS 37.688 (32.818)	mem 73.102
Train: [82][20/1500]	BT 0.034 (1.220)	DT 0.000 (1.189)	loss 6.637 (6.455)	prob 2.655 (2.391)	GS 34.156 (32.886)	mem 73.104
Train: [82][30/1500]	BT 0.030 (1.040)	DT 0.000 (1.008)	loss 6.747 (6.507)	prob 2.441 (2.455)	GS 35.453 (33.410)	mem 73.178
Train: [82][40/1500]	BT 0.037 (0.787)	DT 0.000 (0.756)	loss 6.873 (6.526)	prob 2.379 (2.462)	GS 31.656 (32.915)	mem 73.179
Train: [82][50/1500]	BT 0.048 (0.752)	DT 0.006 (0.718)	loss 6.700 (6.560)	prob 2.549 (2.449)	GS 32.906 (32.603)	mem 73.193
Train: [82][60/1500]	BT 0.034 (0.765)	DT 0.000 (0.730)	loss 6.733 (6.787)	prob 2.632 (2.360)	GS 37.875 (33.681)	mem 73.207
Train: [82][70/1500]	BT 0.037 (0.660)	DT 0.000 (0.626)	loss 6.508 (6.745)	prob 3.152 (2.399)	GS 34.359 (32.541)	mem 73.207
Train: [82][80/1500]	BT 0.037 (0.649)	DT 0.000 (0.615)	loss 6.697 (6.713)	prob 2.568 (2.406)	GS 32.688 (32.456)	mem 73.237
Train: [82][90/1500]	BT 0.037 (0.581)	DT 0.000 (0.547)	loss 6.818 (6.703)	prob 2.725 (2.474)	GS 32.453 (32.746)	mem 73.238
Train: [82][100/1500]	BT 0.037 (0.527)	DT 0.001 (0.493)	loss 6.989 (6.705)	prob 2.553 (2.481)	GS 35.047 (32.596)	mem 73.237
Train: [82][110/1500]	BT 0.028 (0.521)	DT 0.000 (0.487)	loss 6.654 (6.660)	prob 2.284 (2.563)	GS 36.016 (33.459)	mem 73.254
Train: [82][120/1500]	BT 0.038 (0.481)	DT 0.001 (0.447)	loss 6.537 (6.662)	prob 2.846 (2.439)	GS 33.453 (32.402)	mem 73.255
Train: [82][130/1500]	BT 0.038 (0.466)	DT 0.001 (0.432)	loss 6.739 (6.685)	prob 2.495 (2.357)	GS 30.578 (32.466)	mem 73.265
Train: [82][140/1500]	BT 0.036 (0.450)	DT 0.001 (0.416)	loss 6.713 (6.676)	prob 2.554 (2.334)	GS 34.781 (32.660)	mem 73.268
Train: [82][150/1500]	BT 0.037 (0.423)	DT 0.001 (0.388)	loss 6.677 (6.669)	prob 2.198 (2.274)	GS 31.953 (32.443)	mem 73.268
Train: [82][160/1500]	BT 0.038 (0.425)	DT 0.001 (0.391)	loss 6.563 (6.638)	prob 1.473 (2.064)	GS 33.062 (32.177)	mem 73.304
Train: [82][170/1500]	BT 0.066 (0.404)	DT 0.004 (0.368)	loss 6.499 (6.647)	prob 2.613 (2.150)	GS 34.844 (32.530)	mem 73.305
Train: [82][180/1500]	BT 0.030 (0.427)	DT 0.000 (0.390)	loss 6.714 (6.647)	prob 2.465 (2.251)	GS 34.547 (32.766)	mem 73.307
Train: [82][190/1500]	BT 0.028 (0.406)	DT 0.000 (0.370)	loss 6.707 (6.663)	prob 2.980 (2.274)	GS 30.609 (32.790)	mem 73.307
Train: [82][200/1500]	BT 0.039 (0.397)	DT 0.001 (0.361)	loss 6.654 (6.687)	prob 2.357 (2.250)	GS 33.641 (33.034)	mem 73.308
Train: [82][210/1500]	BT 0.039 (0.384)	DT 0.001 (0.348)	loss 6.904 (6.675)	prob 1.906 (2.358)	GS 36.531 (32.748)	mem 73.309
Train: [82][220/1500]	BT 0.028 (0.380)	DT 0.000 (0.343)	loss 6.698 (6.687)	prob 2.338 (2.152)	GS 34.562 (33.364)	mem 73.312
Train: [82][230/1500]	BT 0.027 (0.375)	DT 0.000 (0.339)	loss 6.804 (6.693)	prob 2.445 (2.218)	GS 31.594 (33.090)	mem 73.312
Train: [82][240/1500]	BT 0.039 (0.360)	DT 0.000 (0.325)	loss 6.607 (6.683)	prob 2.106 (2.256)	GS 31.656 (33.212)	mem 73.312
Train: [82][250/1500]	BT 0.039 (0.351)	DT 0.001 (0.315)	loss 6.778 (6.684)	prob 2.089 (2.220)	GS 32.828 (33.101)	mem 73.313
Train: [82][260/1500]	BT 0.039 (0.350)	DT 0.001 (0.314)	loss 6.701 (6.745)	prob 2.435 (2.350)	GS 36.188 (31.878)	mem 73.317
Train: [82][270/1500]	BT 0.038 (0.342)	DT 0.001 (0.306)	loss 6.989 (6.764)	prob 2.317 (2.217)	GS 32.609 (31.934)	mem 73.317
Train: [82][280/1500]	BT 0.039 (0.341)	DT 0.001 (0.305)	loss 6.767 (6.763)	prob 2.503 (2.216)	GS 32.781 (31.785)	mem 73.319
Train: [82][290/1500]	BT 0.039 (0.331)	DT 0.001 (0.295)	loss 6.832 (6.791)	prob 2.095 (2.162)	GS 34.078 (31.950)	mem 73.318
Train: [82][300/1500]	BT 0.034 (0.334)	DT 0.001 (0.298)	loss 6.727 (6.785)	prob 2.089 (2.195)	GS 34.094 (32.026)	mem 73.319
Train: [82][310/1500]	BT 0.062 (0.325)	DT 0.006 (0.289)	loss 6.695 (6.845)	prob 2.494 (2.246)	GS 37.688 (34.145)	mem 73.320
Train: [82][320/1500]	BT 0.028 (0.346)	DT 0.000 (0.310)	loss 6.936 (6.807)	prob 2.012 (2.309)	GS 34.125 (34.394)	mem 73.322
Train: [82][330/1500]	BT 0.039 (0.337)	DT 0.001 (0.300)	loss 6.839 (6.831)	prob 2.697 (2.336)	GS 34.047 (33.440)	mem 73.324
Train: [82][340/1500]	BT 0.039 (0.336)	DT 0.001 (0.300)	loss 6.682 (6.825)	prob 2.933 (2.423)	GS 30.438 (32.805)	mem 73.325
Train: [82][350/1500]	BT 0.038 (0.328)	DT 0.001 (0.292)	loss 6.604 (6.836)	prob 2.826 (2.427)	GS 37.078 (32.910)	mem 73.324
Train: [82][360/1500]	BT 0.035 (0.333)	DT 0.000 (0.296)	loss 6.809 (6.831)	prob 2.269 (2.463)	GS 29.422 (31.541)	mem 73.326
Train: [82][370/1500]	BT 0.039 (0.325)	DT 0.001 (0.288)	loss 6.923 (6.872)	prob 3.667 (2.459)	GS 36.828 (31.773)	mem 73.328
Train: [82][380/1500]	BT 0.039 (0.317)	DT 0.000 (0.281)	loss 6.792 (6.851)	prob 1.989 (2.472)	GS 31.172 (31.690)	mem 73.328
Train: [82][390/1500]	BT 0.038 (0.326)	DT 0.001 (0.289)	loss 7.221 (6.861)	prob 1.866 (2.377)	GS 37.875 (32.182)	mem 73.328
Train: [82][400/1500]	BT 0.037 (0.319)	DT 0.001 (0.282)	loss 6.955 (6.857)	prob 3.253 (2.426)	GS 36.016 (32.575)	mem 73.326
Train: [82][410/1500]	BT 0.028 (0.333)	DT 0.000 (0.297)	loss 6.739 (6.945)	prob 2.451 (2.309)	GS 34.547 (34.564)	mem 73.336
Train: [82][420/1500]	BT 0.029 (0.326)	DT 0.000 (0.290)	loss 6.820 (6.938)	prob 2.605 (2.440)	GS 32.812 (33.222)	mem 73.346
Train: [82][430/1500]	BT 0.052 (0.319)	DT 0.014 (0.283)	loss 6.973 (6.916)	prob 2.572 (2.579)	GS 33.094 (33.081)	mem 73.347
Train: [82][440/1500]	BT 0.028 (0.326)	DT 0.000 (0.290)	loss 6.760 (6.903)	prob 2.926 (2.544)	GS 32.031 (33.237)	mem 73.345
Train: [82][450/1500]	BT 0.034 (0.320)	DT 0.000 (0.284)	loss 6.975 (6.900)	prob 2.333 (2.493)	GS 34.266 (33.348)	mem 73.346
Train: [82][460/1500]	BT 0.064 (0.322)	DT 0.005 (0.286)	loss 6.816 (6.754)	prob 1.992 (2.568)	GS 32.797 (31.306)	mem 73.252
Train: [82][470/1500]	BT 0.072 (0.317)	DT 0.006 (0.280)	loss 6.586 (6.758)	prob 2.577 (2.560)	GS 33.344 (31.754)	mem 73.253
Train: [82][480/1500]	BT 0.048 (0.321)	DT 0.006 (0.284)	loss 6.706 (6.780)	prob 2.645 (2.675)	GS 33.297 (31.818)	mem 73.252
Train: [82][490/1500]	BT 0.064 (0.318)	DT 0.004 (0.281)	loss 7.559 (6.820)	prob 2.168 (2.688)	GS 33.141 (32.068)	mem 73.253
Train: [82][500/1500]	BT 0.064 (0.313)	DT 0.006 (0.275)	loss 6.976 (6.842)	prob 3.025 (2.686)	GS 29.141 (32.220)	mem 73.252
Train: [82][510/1500]	BT 0.037 (0.319)	DT 0.001 (0.282)	loss 6.903 (6.796)	prob 2.117 (2.587)	GS 33.938 (32.659)	mem 73.252
Train: [82][520/1500]	BT 0.028 (0.314)	DT 0.000 (0.276)	loss 6.703 (6.762)	prob 3.348 (2.647)	GS 35.297 (33.205)	mem 73.254
Train: [82][530/1500]	BT 0.258 (0.316)	DT 0.222 (0.279)	loss 6.623 (6.754)	prob 2.754 (2.607)	GS 29.531 (33.528)	mem 73.276
Train: [82][540/1500]	BT 0.037 (0.311)	DT 0.000 (0.274)	loss 6.965 (6.769)	prob 2.574 (2.602)	GS 35.141 (33.671)	mem 73.278
Train: [82][550/1500]	BT 0.038 (0.306)	DT 0.001 (0.269)	loss 6.970 (6.775)	prob 2.933 (2.596)	GS 35.922 (33.531)	mem 73.278
Train: [82][560/1500]	BT 0.039 (0.310)	DT 0.001 (0.272)	loss 6.766 (6.790)	prob 2.922 (2.761)	GS 33.500 (31.602)	mem 73.278
Train: [82][570/1500]	BT 0.032 (0.305)	DT 0.001 (0.268)	loss 6.524 (6.813)	prob 2.689 (2.734)	GS 36.594 (32.731)	mem 73.315
Train: [82][580/1500]	BT 0.055 (0.325)	DT 0.004 (0.288)	loss 6.602 (6.792)	prob 2.255 (2.682)	GS 34.891 (32.795)	mem 73.511
Train: [82][590/1500]	BT 0.064 (0.322)	DT 0.005 (0.284)	loss 6.800 (6.805)	prob 2.587 (2.587)	GS 33.469 (32.874)	mem 73.659
Train: [82][600/1500]	BT 0.033 (0.353)	DT 0.001 (0.314)	loss 6.846 (6.808)	prob 3.170 (2.591)	GS 32.688 (33.106)	mem 74.102
Train: [82][610/1500]	BT 0.042 (0.347)	DT 0.001 (0.309)	loss 6.783 (6.796)	prob 3.500 (2.900)	GS 33.469 (31.562)	mem 74.102
Train: [82][620/1500]	BT 4.038 (0.349)	DT 4.000 (0.311)	loss 6.807 (6.840)	prob 3.561 (2.864)	GS 34.469 (32.414)	mem 74.443
Train: [82][630/1500]	BT 0.029 (0.344)	DT 0.000 (0.306)	loss 6.623 (6.801)	prob 2.856 (2.812)	GS 34.312 (32.341)	mem 74.443
Train: [82][640/1500]	BT 0.039 (0.339)	DT 0.001 (0.301)	loss 6.703 (6.797)	prob 2.808 (2.777)	GS 33.719 (32.118)	mem 74.445
Train: [82][650/1500]	BT 0.039 (0.339)	DT 0.001 (0.301)	loss 6.815 (6.796)	prob 3.160 (2.789)	GS 31.875 (32.131)	mem 74.445
Train: [82][660/1500]	BT 0.039 (0.334)	DT 0.001 (0.296)	loss 6.726 (6.867)	prob 3.154 (2.787)	GS 30.969 (31.117)	mem 74.446
Train: [82][670/1500]	BT 0.061 (0.337)	DT 0.003 (0.299)	loss 6.772 (6.821)	prob 2.892 (2.801)	GS 34.078 (31.883)	mem 74.444
Train: [82][680/1500]	BT 0.051 (0.333)	DT 0.001 (0.295)	loss 6.561 (6.782)	prob 3.237 (2.783)	GS 34.234 (31.918)	mem 74.445
Train: [82][690/1500]	BT 0.074 (0.336)	DT 0.007 (0.297)	loss 6.689 (6.785)	prob 2.300 (2.755)	GS 32.828 (31.861)	mem 74.446
Train: [82][700/1500]	BT 0.063 (0.332)	DT 0.006 (0.293)	loss 6.828 (6.775)	prob 2.365 (2.757)	GS 37.031 (31.822)	mem 74.447
Train: [82][710/1500]	BT 0.039 (0.333)	DT 0.001 (0.294)	loss 6.808 (6.740)	prob 2.647 (2.773)	GS 36.500 (32.836)	mem 74.447
Train: [82][720/1500]	BT 0.039 (0.331)	DT 0.001 (0.293)	loss 6.888 (6.809)	prob 3.065 (2.733)	GS 33.797 (32.237)	mem 74.448
Train: [82][730/1500]	BT 0.034 (0.329)	DT 0.000 (0.290)	loss 6.777 (6.803)	prob 2.907 (2.695)	GS 37.672 (32.443)	mem 74.450
Train: [82][740/1500]	BT 0.037 (0.332)	DT 0.001 (0.293)	loss 6.508 (6.786)	prob 3.264 (2.728)	GS 30.875 (32.615)	mem 74.462
Train: [82][750/1500]	BT 0.059 (0.330)	DT 0.003 (0.291)	loss 6.966 (6.781)	prob 2.784 (2.724)	GS 39.516 (32.969)	mem 74.463
Train: [82][760/1500]	BT 0.031 (0.327)	DT 0.000 (0.288)	loss 6.922 (6.834)	prob 2.694 (2.541)	GS 37.016 (31.800)	mem 74.464
Train: [82][770/1500]	BT 0.037 (0.328)	DT 0.001 (0.289)	loss 6.784 (6.822)	prob 3.170 (2.556)	GS 32.500 (32.254)	mem 74.466
Train: [82][780/1500]	BT 0.037 (0.324)	DT 0.000 (0.285)	loss 6.672 (6.809)	prob 3.071 (2.629)	GS 33.281 (32.101)	mem 74.467
Train: [82][790/1500]	BT 0.037 (0.328)	DT 0.000 (0.290)	loss 6.900 (6.820)	prob 2.808 (2.668)	GS 31.562 (32.148)	mem 74.468
Train: [82][800/1500]	BT 0.037 (0.325)	DT 0.000 (0.286)	loss 6.799 (6.833)	prob 3.255 (2.677)	GS 34.500 (32.480)	mem 74.468
Train: [82][810/1500]	BT 0.038 (0.324)	DT 0.000 (0.286)	loss 6.596 (6.775)	prob 2.847 (2.695)	GS 36.969 (32.967)	mem 74.470
Train: [82][820/1500]	BT 0.037 (0.323)	DT 0.000 (0.285)	loss 6.707 (6.778)	prob 2.347 (2.740)	GS 32.875 (32.763)	mem 74.471
Train: [82][830/1500]	BT 0.037 (0.320)	DT 0.001 (0.281)	loss 6.765 (6.797)	prob 2.663 (2.718)	GS 31.812 (32.214)	mem 74.472
Train: [82][840/1500]	BT 0.029 (0.322)	DT 0.000 (0.283)	loss 6.683 (6.775)	prob 2.781 (2.619)	GS 30.312 (32.109)	mem 74.477
Train: [82][850/1500]	BT 0.037 (0.319)	DT 0.000 (0.280)	loss 6.871 (6.767)	prob 2.647 (2.622)	GS 29.922 (32.117)	mem 74.478
Train: [82][860/1500]	BT 0.039 (0.316)	DT 0.001 (0.278)	loss 6.618 (6.781)	prob 2.341 (2.691)	GS 36.000 (31.392)	mem 74.478
Train: [82][870/1500]	BT 0.037 (0.316)	DT 0.000 (0.277)	loss 6.649 (6.762)	prob 2.523 (2.473)	GS 34.391 (32.480)	mem 74.480
Train: [82][880/1500]	BT 0.037 (0.312)	DT 0.000 (0.274)	loss 6.660 (6.776)	prob 2.346 (2.437)	GS 33.516 (32.770)	mem 74.482
Train: [82][890/1500]	BT 0.074 (0.317)	DT 0.009 (0.278)	loss 6.720 (6.773)	prob 3.282 (2.485)	GS 29.672 (32.692)	mem 74.483
Train: [82][900/1500]	BT 0.038 (0.314)	DT 0.001 (0.275)	loss 7.170 (6.775)	prob 1.988 (2.471)	GS 34.812 (32.713)	mem 74.484
Train: [82][910/1500]	BT 0.034 (0.314)	DT 0.000 (0.276)	loss 6.948 (6.816)	prob 2.488 (2.504)	GS 32.344 (33.405)	mem 74.485
Train: [82][920/1500]	BT 0.037 (0.313)	DT 0.000 (0.275)	loss 6.869 (6.798)	prob 2.712 (2.426)	GS 31.906 (33.117)	mem 74.487
Train: [82][930/1500]	BT 0.037 (0.311)	DT 0.001 (0.273)	loss 6.684 (6.776)	prob 2.533 (2.509)	GS 32.531 (32.598)	mem 74.490
Train: [82][940/1500]	BT 0.037 (0.312)	DT 0.001 (0.273)	loss 6.790 (6.760)	prob 2.232 (2.536)	GS 31.453 (32.591)	mem 74.491
Train: [82][950/1500]	BT 0.038 (0.310)	DT 0.000 (0.271)	loss 6.853 (6.762)	prob 2.204 (2.478)	GS 33.484 (32.474)	mem 74.492
Train: [82][960/1500]	BT 0.037 (0.309)	DT 0.000 (0.270)	loss 6.502 (6.780)	prob 2.073 (2.498)	GS 32.906 (32.288)	mem 74.494
Train: [82][970/1500]	BT 0.031 (0.308)	DT 0.000 (0.269)	loss 6.612 (6.764)	prob 3.229 (2.579)	GS 30.641 (32.692)	mem 74.495
Train: [82][980/1500]	BT 0.060 (0.311)	DT 0.004 (0.273)	loss 6.734 (6.756)	prob 2.417 (2.555)	GS 36.375 (33.528)	mem 74.495
Train: [82][990/1500]	BT 0.031 (0.309)	DT 0.000 (0.270)	loss 6.633 (6.753)	prob 3.239 (2.619)	GS 29.641 (33.277)	mem 74.496
Train: [82][1000/1500]	BT 0.028 (0.317)	DT 0.000 (0.279)	loss 6.827 (6.751)	prob 2.413 (2.597)	GS 33.359 (33.117)	mem 74.496
Train: [82][1010/1500]	BT 0.025 (0.314)	DT 0.000 (0.276)	loss 6.599 (6.762)	prob 2.823 (2.838)	GS 31.875 (32.181)	mem 74.496
Train: [82][1020/1500]	BT 0.040 (0.314)	DT 0.001 (0.276)	loss 6.824 (6.796)	prob 2.335 (2.677)	GS 35.250 (32.091)	mem 74.499
Train: [82][1030/1500]	BT 0.038 (0.312)	DT 0.001 (0.273)	loss 6.785 (6.778)	prob 2.431 (2.647)	GS 33.156 (31.943)	mem 74.499
Train: [82][1040/1500]	BT 0.038 (0.309)	DT 0.001 (0.270)	loss 6.728 (6.780)	prob 2.764 (2.577)	GS 36.688 (32.332)	mem 74.499
Train: [82][1050/1500]	BT 0.063 (0.310)	DT 0.002 (0.271)	loss 6.635 (6.770)	prob 2.635 (2.571)	GS 34.578 (32.560)	mem 74.499
Train: [82][1060/1500]	BT 0.061 (0.308)	DT 0.002 (0.269)	loss 6.806 (6.847)	prob 2.036 (2.141)	GS 35.109 (33.108)	mem 74.498
Train: [82][1070/1500]	BT 0.037 (0.311)	DT 0.001 (0.272)	loss 6.911 (6.813)	prob 1.918 (2.212)	GS 31.469 (33.566)	mem 74.499
Train: [82][1080/1500]	BT 0.037 (0.309)	DT 0.001 (0.270)	loss 6.682 (6.795)	prob 2.085 (2.203)	GS 34.656 (33.333)	mem 74.499
Train: [82][1090/1500]	BT 0.037 (0.309)	DT 0.000 (0.270)	loss 6.590 (6.768)	prob 2.373 (2.250)	GS 32.250 (33.036)	mem 74.502
Train: [82][1100/1500]	BT 0.037 (0.306)	DT 0.000 (0.268)	loss 6.915 (6.760)	prob 2.751 (2.248)	GS 32.531 (32.756)	mem 74.527
Train: [82][1110/1500]	BT 0.053 (0.309)	DT 0.006 (0.270)	loss 6.659 (6.758)	prob 1.996 (2.371)	GS 32.828 (32.359)	mem 74.527
Train: [82][1120/1500]	BT 0.066 (0.308)	DT 0.002 (0.269)	loss 6.613 (6.731)	prob 2.805 (2.438)	GS 31.875 (32.734)	mem 74.527
Train: [82][1130/1500]	BT 0.076 (0.307)	DT 0.013 (0.268)	loss 6.506 (6.726)	prob 2.512 (2.443)	GS 33.594 (32.901)	mem 74.529
Train: [82][1140/1500]	BT 0.031 (0.315)	DT 0.000 (0.276)	loss 6.733 (6.734)	prob 2.102 (2.493)	GS 33.641 (33.194)	mem 74.531
Train: [82][1150/1500]	BT 0.038 (0.313)	DT 0.001 (0.273)	loss 6.654 (6.733)	prob 2.597 (2.519)	GS 35.266 (33.028)	mem 74.531
Train: [82][1160/1500]	BT 0.039 (0.311)	DT 0.001 (0.271)	loss 6.770 (6.746)	prob 2.889 (2.301)	GS 34.172 (32.430)	mem 74.531
Train: [82][1170/1500]	BT 0.038 (0.311)	DT 0.001 (0.272)	loss 7.164 (6.762)	prob 2.666 (2.385)	GS 33.766 (32.959)	mem 74.532
Train: [82][1180/1500]	BT 0.039 (0.308)	DT 0.001 (0.269)	loss 6.847 (6.746)	prob 2.302 (2.427)	GS 33.875 (33.078)	mem 74.531
Train: [82][1190/1500]	BT 0.096 (0.309)	DT 0.029 (0.270)	loss 6.895 (6.744)	prob 2.867 (2.428)	GS 34.000 (33.168)	mem 74.533
Train: [82][1200/1500]	BT 0.040 (0.308)	DT 0.001 (0.269)	loss 6.837 (6.730)	prob 2.398 (2.493)	GS 36.484 (33.290)	mem 74.533
Train: [82][1210/1500]	BT 0.354 (0.307)	DT 0.317 (0.268)	loss 6.591 (6.740)	prob 3.134 (2.408)	GS 29.484 (32.192)	mem 74.532
Train: [82][1220/1500]	BT 0.038 (0.308)	DT 0.001 (0.269)	loss 6.810 (6.746)	prob 2.702 (2.670)	GS 33.516 (32.520)	mem 74.533
Train: [82][1230/1500]	BT 0.039 (0.306)	DT 0.001 (0.267)	loss 6.577 (6.730)	prob 3.134 (2.801)	GS 34.203 (32.597)	mem 74.533
Train: [82][1240/1500]	BT 0.038 (0.307)	DT 0.000 (0.268)	loss 6.573 (6.740)	prob 3.238 (2.827)	GS 35.875 (32.786)	mem 74.533
Train: [82][1250/1500]	BT 0.037 (0.305)	DT 0.001 (0.266)	loss 6.833 (6.732)	prob 2.299 (2.763)	GS 35.797 (32.920)	mem 74.535
Train: [82][1260/1500]	BT 0.030 (0.303)	DT 0.000 (0.264)	loss 6.600 (6.686)	prob 2.843 (2.483)	GS 33.344 (31.847)	mem 74.534
Train: [82][1270/1500]	BT 0.059 (0.306)	DT 0.016 (0.267)	loss 6.519 (6.678)	prob 2.995 (2.564)	GS 32.672 (31.645)	mem 74.534
Train: [82][1280/1500]	BT 0.065 (0.304)	DT 0.001 (0.265)	loss 6.791 (6.689)	prob 1.911 (2.506)	GS 36.328 (31.734)	mem 74.535
Train: [82][1290/1500]	BT 0.030 (0.307)	DT 0.000 (0.268)	loss 6.680 (6.692)	prob 3.078 (2.472)	GS 38.562 (32.062)	mem 74.533
Train: [82][1300/1500]	BT 0.066 (0.305)	DT 0.011 (0.266)	loss 6.601 (6.696)	prob 2.936 (2.473)	GS 36.250 (31.959)	mem 74.532
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [82][1310/1500]	BT 0.020 (0.317)	DT 0.000 (0.277)	loss 6.752 (6.776)	prob 2.778 (2.297)	GS 35.188 (33.330)	mem 74.534
Train: [82][1320/1500]	BT 0.028 (0.314)	DT 0.001 (0.275)	loss 6.628 (6.718)	prob 2.837 (2.403)	GS 39.188 (32.784)	mem 74.534
Train: [82][1330/1500]	BT 0.028 (0.317)	DT 0.000 (0.278)	loss 6.608 (6.699)	prob 2.898 (2.503)	GS 32.094 (33.038)	mem 74.540
Train: [82][1340/1500]	BT 0.029 (0.315)	DT 0.000 (0.276)	loss 6.763 (6.706)	prob 2.564 (2.488)	GS 36.359 (32.658)	mem 74.540
Train: [82][1350/1500]	BT 0.032 (0.312)	DT 0.000 (0.273)	loss 6.578 (6.692)	prob 2.651 (2.446)	GS 34.641 (33.033)	mem 74.539
Train: [82][1360/1500]	BT 0.033 (0.314)	DT 0.000 (0.275)	loss 6.534 (6.680)	prob 2.171 (2.117)	GS 33.578 (31.762)	mem 74.553
Train: [82][1370/1500]	BT 0.026 (0.312)	DT 0.000 (0.273)	loss 6.557 (6.659)	prob 2.065 (2.344)	GS 31.734 (31.927)	mem 74.553
Train: [82][1380/1500]	BT 0.030 (0.313)	DT 0.000 (0.274)	loss 6.747 (6.666)	prob 2.087 (2.359)	GS 34.391 (31.836)	mem 74.455
Train: [82][1390/1500]	BT 0.027 (0.311)	DT 0.000 (0.272)	loss 6.703 (6.658)	prob 2.195 (2.317)	GS 29.094 (31.428)	mem 74.454
Train: [82][1400/1500]	BT 0.029 (0.309)	DT 0.000 (0.270)	loss 6.597 (6.661)	prob 2.543 (2.321)	GS 36.562 (31.530)	mem 74.454
Train: [82][1410/1500]	BT 0.027 (0.310)	DT 0.000 (0.271)	loss 6.665 (6.675)	prob 2.442 (2.259)	GS 31.578 (32.727)	mem 74.453
Train: [82][1420/1500]	BT 0.027 (0.308)	DT 0.000 (0.269)	loss 6.899 (6.694)	prob 2.373 (2.462)	GS 34.000 (32.438)	mem 74.453
Train: [82][1430/1500]	BT 0.075 (0.310)	DT 0.005 (0.272)	loss 6.626 (6.693)	prob 3.499 (2.636)	GS 30.469 (32.443)	mem 74.453
Train: [82][1440/1500]	BT 0.029 (0.308)	DT 0.000 (0.270)	loss 6.578 (6.689)	prob 3.313 (2.739)	GS 31.531 (32.339)	mem 74.454
Train: [82][1450/1500]	BT 0.037 (0.310)	DT 0.001 (0.272)	loss 6.699 (6.692)	prob 2.838 (2.718)	GS 34.984 (32.585)	mem 74.238
Train: [82][1460/1500]	BT 0.037 (0.309)	DT 0.001 (0.270)	loss 6.504 (6.690)	prob 2.917 (3.024)	GS 35.594 (31.592)	mem 74.237
Train: [82][1470/1500]	BT 0.026 (0.309)	DT 0.000 (0.270)	loss 6.810 (6.729)	prob 1.794 (2.793)	GS 32.094 (32.581)	mem 65.527
Train: [82][1480/1500]	BT 0.026 (0.308)	DT 0.000 (0.269)	loss 6.477 (6.730)	prob 3.485 (2.829)	GS 33.469 (32.551)	mem 14.961
Train: [82][1490/1500]	BT 0.032 (0.306)	DT 0.000 (0.267)	loss 6.835 (6.717)	prob 2.238 (2.800)	GS 32.094 (32.841)	mem 14.886
Train: [82][1500/1500]	BT 0.035 (0.304)	DT 0.001 (0.266)	loss 6.921 (6.726)	prob 2.610 (2.781)	GS 32.875 (32.821)	mem 9.263
Train: [82][1510/1500]	BT 0.037 (0.303)	DT 0.000 (0.264)	loss 6.201 (6.456)	prob 2.717 (2.844)	GS 32.719 (31.144)	mem 9.264
epoch 82, total time 457.11
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [83][1/1500]	BT 18.144 (18.144)	DT 18.085 (18.085)	loss 6.215 (6.215)	prob 2.608 (2.608)	GS 35.828 (35.828)	mem 72.195
Train: [83][10/1500]	BT 0.059 (2.409)	DT 0.009 (2.356)	loss 6.337 (6.380)	prob 3.530 (2.898)	GS 35.344 (34.705)	mem 73.017
Train: [83][20/1500]	BT 0.030 (1.718)	DT 0.000 (1.677)	loss 6.539 (6.483)	prob 3.232 (2.812)	GS 37.969 (34.786)	mem 73.071
Train: [83][30/1500]	BT 0.037 (1.156)	DT 0.001 (1.118)	loss 6.584 (6.520)	prob 3.089 (2.904)	GS 36.062 (34.067)	mem 73.072
Train: [83][40/1500]	BT 0.022 (1.072)	DT 0.000 (1.036)	loss 6.821 (6.539)	prob 3.011 (2.835)	GS 30.766 (33.502)	mem 73.082
Train: [83][50/1500]	BT 0.037 (0.864)	DT 0.000 (0.829)	loss 6.577 (6.574)	prob 2.860 (2.843)	GS 31.906 (33.140)	mem 73.083
Train: [83][60/1500]	BT 0.031 (0.879)	DT 0.000 (0.845)	loss 6.945 (6.751)	prob 2.771 (2.656)	GS 39.141 (31.931)	mem 73.089
Train: [83][70/1500]	BT 0.027 (0.834)	DT 0.000 (0.800)	loss 6.543 (6.730)	prob 2.607 (2.549)	GS 35.812 (32.702)	mem 73.119
Train: [83][80/1500]	BT 0.029 (0.733)	DT 0.000 (0.700)	loss 6.593 (6.720)	prob 2.703 (2.600)	GS 31.906 (32.948)	mem 73.122
Train: [83][90/1500]	BT 0.040 (0.662)	DT 0.001 (0.628)	loss 6.793 (6.710)	prob 2.918 (2.748)	GS 35.500 (32.837)	mem 73.124
Train: [83][100/1500]	BT 0.024 (0.636)	DT 0.000 (0.602)	loss 6.719 (6.717)	prob 2.930 (2.792)	GS 38.859 (32.840)	mem 73.145
Train: [83][110/1500]	BT 0.035 (0.581)	DT 0.000 (0.548)	loss 7.033 (6.741)	prob 2.551 (3.216)	GS 30.188 (32.739)	mem 73.147
Train: [83][120/1500]	BT 0.050 (0.580)	DT 0.000 (0.546)	loss 6.680 (6.734)	prob 3.481 (3.338)	GS 28.938 (32.513)	mem 73.153
Train: [83][130/1500]	BT 0.071 (0.541)	DT 0.006 (0.504)	loss 6.817 (6.739)	prob 3.049 (3.294)	GS 30.516 (32.771)	mem 73.153
Train: [83][140/1500]	BT 0.038 (0.530)	DT 0.000 (0.493)	loss 6.635 (6.739)	prob 2.409 (3.190)	GS 36.688 (33.273)	mem 73.157
Train: [83][150/1500]	BT 0.071 (0.513)	DT 0.011 (0.476)	loss 6.755 (6.730)	prob 3.156 (3.210)	GS 33.891 (33.248)	mem 73.158
Train: [83][160/1500]	BT 0.066 (0.504)	DT 0.015 (0.466)	loss 6.554 (6.685)	prob 2.544 (2.606)	GS 33.641 (32.634)	mem 73.167
Train: [83][170/1500]	BT 0.027 (0.486)	DT 0.000 (0.447)	loss 6.595 (6.676)	prob 2.663 (2.699)	GS 30.688 (31.988)	mem 73.170
Train: [83][180/1500]	BT 0.037 (0.465)	DT 0.000 (0.426)	loss 6.720 (6.687)	prob 2.135 (2.645)	GS 34.453 (32.790)	mem 73.172
Train: [83][190/1500]	BT 0.059 (0.456)	DT 0.006 (0.418)	loss 6.721 (6.690)	prob 2.553 (2.717)	GS 34.422 (33.016)	mem 73.175
Train: [83][200/1500]	BT 0.064 (0.437)	DT 0.003 (0.397)	loss 6.796 (6.701)	prob 2.604 (2.694)	GS 30.875 (33.038)	mem 73.175
Train: [83][210/1500]	BT 0.037 (0.425)	DT 0.000 (0.385)	loss 6.675 (6.697)	prob 2.617 (2.812)	GS 37.016 (33.678)	mem 73.175
Train: [83][220/1500]	BT 0.074 (0.418)	DT 0.004 (0.377)	loss 6.699 (6.694)	prob 2.958 (2.654)	GS 37.062 (33.468)	mem 73.178
Train: [83][230/1500]	BT 0.037 (0.414)	DT 0.001 (0.373)	loss 6.934 (6.724)	prob 2.451 (2.630)	GS 35.219 (33.428)	mem 73.181
Train: [83][240/1500]	BT 0.037 (0.404)	DT 0.000 (0.364)	loss 6.714 (6.726)	prob 2.861 (2.675)	GS 32.516 (33.372)	mem 73.182
Train: [83][250/1500]	BT 0.037 (0.391)	DT 0.001 (0.351)	loss 6.765 (6.724)	prob 2.875 (2.710)	GS 34.203 (33.281)	mem 73.182
Train: [83][260/1500]	BT 0.036 (0.401)	DT 0.000 (0.361)	loss 6.738 (6.702)	prob 2.479 (2.503)	GS 32.562 (32.402)	mem 73.187
Train: [83][270/1500]	BT 0.036 (0.387)	DT 0.001 (0.348)	loss 6.725 (6.723)	prob 2.562 (2.687)	GS 36.062 (32.636)	mem 73.189
Train: [83][280/1500]	BT 0.037 (0.378)	DT 0.001 (0.338)	loss 6.736 (6.724)	prob 3.527 (2.744)	GS 32.500 (32.836)	mem 73.189
Train: [83][290/1500]	BT 0.037 (0.380)	DT 0.001 (0.340)	loss 6.724 (6.723)	prob 3.260 (2.775)	GS 32.344 (32.570)	mem 73.193
Train: [83][300/1500]	BT 0.038 (0.369)	DT 0.000 (0.329)	loss 6.699 (6.727)	prob 2.922 (2.787)	GS 34.703 (32.512)	mem 73.194
Train: [83][310/1500]	BT 0.039 (0.371)	DT 0.000 (0.332)	loss 6.536 (6.648)	prob 2.508 (2.704)	GS 36.156 (33.041)	mem 73.196
Train: [83][320/1500]	BT 0.038 (0.361)	DT 0.001 (0.322)	loss 6.623 (6.684)	prob 2.552 (2.649)	GS 34.703 (32.466)	mem 73.196
Train: [83][330/1500]	BT 0.038 (0.351)	DT 0.001 (0.312)	loss 6.582 (6.680)	prob 3.010 (2.719)	GS 29.594 (32.326)	mem 73.196
Train: [83][340/1500]	BT 0.027 (0.353)	DT 0.000 (0.314)	loss 6.773 (6.681)	prob 2.507 (2.769)	GS 36.812 (32.375)	mem 73.199
Train: [83][350/1500]	BT 0.037 (0.344)	DT 0.000 (0.306)	loss 6.690 (6.682)	prob 2.824 (2.736)	GS 32.562 (32.457)	mem 73.199
Train: [83][360/1500]	BT 0.029 (0.349)	DT 0.000 (0.311)	loss 6.752 (6.671)	prob 2.692 (2.721)	GS 34.328 (34.053)	mem 73.204
Train: [83][370/1500]	BT 0.025 (0.341)	DT 0.000 (0.303)	loss 6.580 (6.680)	prob 2.628 (2.696)	GS 32.438 (33.211)	mem 73.204
Train: [83][380/1500]	BT 0.036 (0.342)	DT 0.000 (0.304)	loss 6.721 (6.674)	prob 2.025 (2.603)	GS 33.766 (32.520)	mem 73.208
Train: [83][390/1500]	BT 0.036 (0.335)	DT 0.000 (0.297)	loss 6.553 (6.678)	prob 2.789 (2.573)	GS 33.562 (32.384)	mem 73.208
Train: [83][400/1500]	BT 0.036 (0.327)	DT 0.000 (0.289)	loss 6.797 (6.686)	prob 2.134 (2.585)	GS 33.672 (32.356)	mem 73.210
Train: [83][410/1500]	BT 0.032 (0.330)	DT 0.000 (0.292)	loss 6.609 (6.720)	prob 2.832 (2.841)	GS 29.609 (33.014)	mem 73.210
Train: [83][420/1500]	BT 0.069 (0.324)	DT 0.004 (0.286)	loss 6.536 (6.705)	prob 2.853 (2.729)	GS 32.438 (32.504)	mem 73.212
Train: [83][430/1500]	BT 0.039 (0.333)	DT 0.001 (0.295)	loss 6.596 (6.681)	prob 2.605 (2.662)	GS 35.141 (32.391)	mem 73.244
Train: [83][440/1500]	BT 0.039 (0.326)	DT 0.001 (0.288)	loss 6.662 (6.700)	prob 2.695 (2.641)	GS 33.922 (32.632)	mem 73.244
Train: [83][450/1500]	BT 0.039 (0.320)	DT 0.001 (0.282)	loss 6.623 (6.687)	prob 3.006 (2.743)	GS 34.562 (32.687)	mem 73.244
Train: [83][460/1500]	BT 0.039 (0.324)	DT 0.001 (0.286)	loss 6.614 (6.680)	prob 2.496 (3.211)	GS 29.891 (32.628)	mem 73.245
Train: [83][470/1500]	BT 0.039 (0.318)	DT 0.001 (0.280)	loss 6.660 (6.688)	prob 2.754 (2.935)	GS 32.797 (32.048)	mem 73.244
Train: [83][480/1500]	BT 0.039 (0.318)	DT 0.001 (0.280)	loss 6.902 (6.681)	prob 2.492 (2.845)	GS 35.875 (32.284)	mem 73.246
Train: [83][490/1500]	BT 0.029 (0.317)	DT 0.000 (0.279)	loss 6.770 (6.688)	prob 2.049 (2.818)	GS 34.047 (32.288)	mem 73.249
Train: [83][500/1500]	BT 0.039 (0.313)	DT 0.001 (0.275)	loss 6.750 (6.682)	prob 1.693 (2.783)	GS 32.734 (32.242)	mem 73.250
Train: [83][510/1500]	BT 0.039 (0.312)	DT 0.001 (0.274)	loss 6.819 (6.656)	prob 2.266 (2.721)	GS 36.172 (33.311)	mem 73.250
Train: [83][520/1500]	BT 0.039 (0.307)	DT 0.001 (0.268)	loss 6.686 (6.668)	prob 3.322 (2.514)	GS 34.984 (32.573)	mem 73.250
Train: [83][530/1500]	BT 0.039 (0.310)	DT 0.001 (0.272)	loss 6.778 (6.682)	prob 1.626 (2.521)	GS 32.953 (32.454)	mem 73.250
Train: [83][540/1500]	BT 0.039 (0.305)	DT 0.001 (0.267)	loss 6.604 (6.674)	prob 2.650 (2.508)	GS 33.172 (32.570)	mem 73.250
Train: [83][550/1500]	BT 0.034 (0.302)	DT 0.000 (0.264)	loss 6.785 (6.677)	prob 2.682 (2.527)	GS 35.391 (32.388)	mem 73.251
Train: [83][560/1500]	BT 0.097 (0.312)	DT 0.001 (0.273)	loss 6.633 (6.670)	prob 2.857 (2.778)	GS 35.062 (33.045)	mem 73.253
Train: [83][570/1500]	BT 0.066 (0.308)	DT 0.013 (0.268)	loss 6.764 (6.699)	prob 2.261 (2.749)	GS 34.656 (33.191)	mem 73.254
Train: [83][580/1500]	BT 0.036 (0.332)	DT 0.000 (0.293)	loss 6.693 (6.681)	prob 2.465 (2.720)	GS 34.469 (33.132)	mem 73.254
Train: [83][590/1500]	BT 0.031 (0.327)	DT 0.000 (0.288)	loss 6.654 (6.694)	prob 2.689 (2.703)	GS 35.156 (33.004)	mem 73.255
Train: [83][600/1500]	BT 0.037 (0.322)	DT 0.000 (0.283)	loss 6.617 (6.693)	prob 3.314 (2.664)	GS 35.156 (32.816)	mem 73.255
Train: [83][610/1500]	BT 0.036 (0.324)	DT 0.000 (0.285)	loss 6.766 (6.671)	prob 1.919 (2.479)	GS 36.125 (33.008)	mem 73.256
Train: [83][620/1500]	BT 0.037 (0.319)	DT 0.001 (0.280)	loss 6.593 (6.636)	prob 2.809 (2.427)	GS 32.969 (32.839)	mem 73.257
Train: [83][630/1500]	BT 0.039 (0.319)	DT 0.001 (0.280)	loss 6.615 (6.635)	prob 1.828 (2.294)	GS 34.969 (32.916)	mem 73.306
Train: [83][640/1500]	BT 0.040 (0.315)	DT 0.001 (0.276)	loss 6.822 (6.639)	prob 1.852 (2.258)	GS 33.547 (32.763)	mem 73.305
Train: [83][650/1500]	BT 5.407 (0.319)	DT 5.317 (0.280)	loss 6.728 (6.649)	prob 2.114 (2.241)	GS 31.688 (32.478)	mem 73.695
Train: [83][660/1500]	BT 0.045 (0.315)	DT 0.000 (0.276)	loss 6.617 (6.586)	prob 1.961 (2.298)	GS 31.141 (31.684)	mem 73.746
Train: [83][670/1500]	BT 0.038 (0.316)	DT 0.001 (0.277)	loss 6.619 (6.614)	prob 2.772 (2.242)	GS 35.406 (32.138)	mem 73.894
Train: [83][680/1500]	BT 0.038 (0.315)	DT 0.001 (0.276)	loss 6.487 (6.602)	prob 1.814 (2.239)	GS 31.188 (32.084)	mem 74.188
Train: [83][690/1500]	BT 0.064 (0.313)	DT 0.007 (0.273)	loss 6.604 (6.610)	prob 2.048 (2.212)	GS 36.359 (32.091)	mem 74.287
Train: [83][700/1500]	BT 0.059 (0.314)	DT 0.016 (0.275)	loss 6.558 (6.617)	prob 2.161 (2.148)	GS 29.438 (32.106)	mem 74.433
Train: [83][710/1500]	BT 0.044 (0.312)	DT 0.000 (0.273)	loss 6.487 (6.645)	prob 2.648 (2.144)	GS 32.969 (32.114)	mem 74.433
Train: [83][720/1500]	BT 0.039 (0.308)	DT 0.001 (0.269)	loss 6.649 (6.633)	prob 2.352 (2.178)	GS 31.125 (31.930)	mem 74.434
Train: [83][730/1500]	BT 0.028 (0.310)	DT 0.000 (0.270)	loss 6.570 (6.621)	prob 2.066 (2.329)	GS 31.781 (32.330)	mem 74.434
Train: [83][740/1500]	BT 0.056 (0.306)	DT 0.001 (0.267)	loss 6.600 (6.619)	prob 2.480 (2.319)	GS 33.031 (32.512)	mem 74.435
Train: [83][750/1500]	BT 0.028 (0.308)	DT 0.000 (0.269)	loss 6.784 (6.618)	prob 1.928 (2.313)	GS 36.484 (32.673)	mem 74.455
Train: [83][760/1500]	BT 0.052 (0.305)	DT 0.010 (0.265)	loss 6.624 (6.609)	prob 2.598 (2.138)	GS 35.750 (32.036)	mem 74.456
Train: [83][770/1500]	BT 0.032 (0.324)	DT 0.000 (0.285)	loss 6.521 (6.608)	prob 2.086 (2.151)	GS 35.031 (32.564)	mem 74.474
Train: [83][780/1500]	BT 0.027 (0.321)	DT 0.000 (0.281)	loss 6.572 (6.601)	prob 3.069 (2.310)	GS 30.516 (32.124)	mem 74.475
Train: [83][790/1500]	BT 0.026 (0.317)	DT 0.000 (0.278)	loss 6.750 (6.604)	prob 2.425 (2.325)	GS 35.344 (31.895)	mem 74.475
Train: [83][800/1500]	BT 0.037 (0.317)	DT 0.001 (0.278)	loss 6.597 (6.610)	prob 2.475 (2.370)	GS 30.828 (31.873)	mem 74.356
Train: [83][810/1500]	BT 0.037 (0.313)	DT 0.001 (0.274)	loss 6.461 (6.565)	prob 2.404 (2.285)	GS 29.531 (32.506)	mem 74.356
Train: [83][820/1500]	BT 0.049 (0.316)	DT 0.009 (0.277)	loss 6.711 (6.607)	prob 2.511 (2.383)	GS 33.000 (32.420)	mem 74.356
Train: [83][830/1500]	BT 0.034 (0.313)	DT 0.000 (0.274)	loss 6.584 (6.613)	prob 2.828 (2.472)	GS 35.406 (32.520)	mem 74.355
Train: [83][840/1500]	BT 0.035 (0.310)	DT 0.001 (0.271)	loss 6.592 (6.612)	prob 2.376 (2.479)	GS 36.750 (32.529)	mem 74.355
Train: [83][850/1500]	BT 0.068 (0.314)	DT 0.023 (0.275)	loss 6.896 (6.621)	prob 2.104 (2.456)	GS 38.188 (32.693)	mem 74.356
Train: [83][860/1500]	BT 0.038 (0.311)	DT 0.001 (0.271)	loss 6.600 (6.658)	prob 1.876 (2.469)	GS 36.656 (33.986)	mem 74.360
Train: [83][870/1500]	BT 0.037 (0.313)	DT 0.000 (0.274)	loss 6.537 (6.616)	prob 3.282 (2.422)	GS 36.781 (33.439)	mem 74.381
Train: [83][880/1500]	BT 0.038 (0.310)	DT 0.001 (0.271)	loss 6.713 (6.611)	prob 2.334 (2.423)	GS 35.219 (33.159)	mem 74.381
Train: [83][890/1500]	BT 0.028 (0.311)	DT 0.000 (0.272)	loss 6.631 (6.616)	prob 1.989 (2.423)	GS 35.453 (33.322)	mem 74.380
Train: [83][900/1500]	BT 0.035 (0.311)	DT 0.000 (0.273)	loss 6.584 (6.624)	prob 1.435 (2.432)	GS 38.859 (33.526)	mem 74.382
Train: [83][910/1500]	BT 0.039 (0.308)	DT 0.001 (0.270)	loss 6.678 (6.605)	prob 2.762 (2.549)	GS 33.656 (33.036)	mem 74.385
Train: [83][920/1500]	BT 0.036 (0.310)	DT 0.001 (0.272)	loss 6.495 (6.643)	prob 3.168 (2.648)	GS 28.656 (33.179)	mem 74.369
Train: [83][930/1500]	BT 0.039 (0.308)	DT 0.001 (0.269)	loss 6.641 (6.652)	prob 3.240 (2.622)	GS 30.125 (33.118)	mem 74.371
Train: [83][940/1500]	BT 0.039 (0.305)	DT 0.001 (0.266)	loss 6.593 (6.643)	prob 3.126 (2.599)	GS 38.062 (32.862)	mem 74.372
Train: [83][950/1500]	BT 0.031 (0.307)	DT 0.001 (0.268)	loss 6.618 (6.649)	prob 3.066 (2.668)	GS 28.609 (33.095)	mem 74.371
Train: [83][960/1500]	BT 0.030 (0.304)	DT 0.000 (0.265)	loss 6.669 (6.696)	prob 3.397 (2.938)	GS 36.188 (33.569)	mem 74.371
Train: [83][970/1500]	BT 0.031 (0.305)	DT 0.000 (0.267)	loss 6.530 (6.678)	prob 3.292 (2.909)	GS 36.469 (33.805)	mem 74.371
Train: [83][980/1500]	BT 0.031 (0.302)	DT 0.001 (0.264)	loss 6.664 (6.654)	prob 2.569 (2.760)	GS 35.016 (33.658)	mem 74.373
Train: [83][990/1500]	BT 0.035 (0.303)	DT 0.000 (0.265)	loss 6.651 (6.644)	prob 2.248 (2.710)	GS 35.016 (33.568)	mem 74.391
Train: [83][1000/1500]	BT 0.037 (0.300)	DT 0.001 (0.262)	loss 6.818 (6.641)	prob 2.516 (2.687)	GS 34.031 (33.345)	mem 74.391
Train: [83][1010/1500]	BT 0.037 (0.298)	DT 0.001 (0.259)	loss 6.712 (6.602)	prob 2.606 (2.345)	GS 32.750 (32.517)	mem 74.392
Train: [83][1020/1500]	BT 0.037 (0.299)	DT 0.001 (0.261)	loss 6.541 (6.612)	prob 2.900 (2.304)	GS 33.469 (31.623)	mem 74.392
Train: [83][1030/1500]	BT 0.037 (0.297)	DT 0.001 (0.258)	loss 6.605 (6.592)	prob 2.534 (2.431)	GS 34.969 (32.094)	mem 74.392
Train: [83][1040/1500]	BT 0.029 (0.299)	DT 0.000 (0.260)	loss 6.637 (6.599)	prob 2.558 (2.541)	GS 30.984 (32.080)	mem 74.396
Train: [83][1050/1500]	BT 0.037 (0.296)	DT 0.001 (0.258)	loss 6.584 (6.613)	prob 2.539 (2.559)	GS 33.547 (32.417)	mem 74.398
Train: [83][1060/1500]	BT 0.037 (0.294)	DT 0.001 (0.256)	loss 6.473 (6.640)	prob 2.351 (2.494)	GS 34.578 (32.589)	mem 74.399
Train: [83][1070/1500]	BT 0.029 (0.300)	DT 0.000 (0.262)	loss 6.626 (6.647)	prob 3.279 (2.481)	GS 32.469 (32.921)	mem 74.403
Train: [83][1080/1500]	BT 0.025 (0.298)	DT 0.000 (0.260)	loss 6.722 (6.635)	prob 2.228 (2.579)	GS 37.656 (32.976)	mem 74.404
Train: [83][1090/1500]	BT 0.069 (0.298)	DT 0.005 (0.260)	loss 6.652 (6.650)	prob 3.403 (2.571)	GS 35.312 (32.836)	mem 74.405
Train: [83][1100/1500]	BT 0.038 (0.296)	DT 0.001 (0.258)	loss 6.501 (6.652)	prob 2.248 (2.527)	GS 33.750 (32.674)	mem 74.405
Train: [83][1110/1500]	BT 0.042 (0.299)	DT 0.001 (0.261)	loss 6.557 (6.627)	prob 2.451 (2.365)	GS 31.422 (32.925)	mem 74.404
Train: [83][1120/1500]	BT 0.037 (0.297)	DT 0.001 (0.259)	loss 6.572 (6.634)	prob 2.304 (2.573)	GS 31.484 (33.176)	mem 74.407
Train: [83][1130/1500]	BT 0.027 (0.295)	DT 0.000 (0.257)	loss 6.616 (6.636)	prob 2.567 (2.638)	GS 34.438 (33.137)	mem 74.408
Train: [83][1140/1500]	BT 0.027 (0.296)	DT 0.000 (0.258)	loss 6.568 (6.625)	prob 3.064 (2.649)	GS 35.547 (33.111)	mem 74.409
Train: [83][1150/1500]	BT 0.037 (0.294)	DT 0.000 (0.256)	loss 6.670 (6.626)	prob 2.249 (2.570)	GS 36.016 (32.744)	mem 74.410
Train: [83][1160/1500]	BT 0.028 (0.298)	DT 0.000 (0.260)	loss 6.670 (6.667)	prob 2.266 (2.524)	GS 29.781 (31.575)	mem 74.409
Train: [83][1170/1500]	BT 0.030 (0.296)	DT 0.000 (0.258)	loss 6.590 (6.624)	prob 2.320 (2.556)	GS 34.219 (32.365)	mem 74.411
Train: [83][1180/1500]	BT 0.038 (0.294)	DT 0.001 (0.256)	loss 6.726 (6.637)	prob 2.310 (2.566)	GS 35.812 (33.031)	mem 74.411
Train: [83][1190/1500]	BT 0.039 (0.294)	DT 0.000 (0.256)	loss 6.682 (6.651)	prob 2.595 (2.524)	GS 37.594 (32.933)	mem 74.412
Train: [83][1200/1500]	BT 0.033 (0.291)	DT 0.001 (0.254)	loss 6.757 (6.664)	prob 2.112 (2.490)	GS 31.797 (33.192)	mem 74.413
Train: [83][1210/1500]	BT 0.037 (0.293)	DT 0.000 (0.255)	loss 6.614 (6.649)	prob 4.084 (3.036)	GS 34.609 (33.792)	mem 74.415
Train: [83][1220/1500]	BT 0.037 (0.291)	DT 0.000 (0.253)	loss 6.663 (6.660)	prob 1.673 (2.800)	GS 37.094 (33.202)	mem 74.415
Train: [83][1230/1500]	BT 0.057 (0.291)	DT 0.006 (0.253)	loss 6.637 (6.654)	prob 3.065 (2.734)	GS 36.719 (33.260)	mem 74.415
Train: [83][1240/1500]	BT 0.060 (0.289)	DT 0.003 (0.251)	loss 6.743 (6.661)	prob 2.148 (2.684)	GS 29.844 (32.947)	mem 74.415
Train: [83][1250/1500]	BT 0.071 (0.288)	DT 0.004 (0.250)	loss 6.524 (6.659)	prob 2.621 (2.655)	GS 31.531 (32.834)	mem 74.416
Train: [83][1260/1500]	BT 0.029 (0.294)	DT 0.000 (0.256)	loss 6.761 (6.720)	prob 3.175 (2.277)	GS 36.781 (33.150)	mem 74.414
Train: [83][1270/1500]	BT 0.027 (0.292)	DT 0.000 (0.254)	loss 6.649 (6.655)	prob 2.193 (2.382)	GS 34.484 (32.607)	mem 74.415
Train: [83][1280/1500]	BT 0.036 (0.293)	DT 0.000 (0.255)	loss 6.505 (6.657)	prob 2.865 (2.381)	GS 33.250 (32.142)	mem 74.418
Train: [83][1290/1500]	BT 0.037 (0.291)	DT 0.001 (0.253)	loss 6.681 (6.675)	prob 2.455 (2.419)	GS 40.312 (32.365)	mem 74.418
Train: [83][1300/1500]	BT 0.038 (0.295)	DT 0.008 (0.257)	loss 6.635 (6.676)	prob 2.545 (2.467)	GS 34.359 (32.498)	mem 74.419
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [83][1310/1500]	BT 0.031 (0.293)	DT 0.000 (0.255)	loss 6.535 (6.624)	prob 3.438 (2.562)	GS 33.266 (31.916)	mem 74.420
Train: [83][1320/1500]	BT 0.031 (0.295)	DT 0.000 (0.257)	loss 6.553 (6.618)	prob 2.736 (2.595)	GS 31.172 (32.615)	mem 74.451
Train: [83][1330/1500]	BT 0.030 (0.293)	DT 0.000 (0.255)	loss 6.648 (6.616)	prob 1.734 (2.530)	GS 34.547 (32.465)	mem 74.452
Train: [83][1340/1500]	BT 0.033 (0.291)	DT 0.000 (0.254)	loss 6.719 (6.612)	prob 2.632 (2.537)	GS 32.469 (32.452)	mem 74.454
Train: [83][1350/1500]	BT 0.029 (0.293)	DT 0.000 (0.255)	loss 6.793 (6.620)	prob 2.176 (2.506)	GS 34.938 (32.402)	mem 74.454
Train: [83][1360/1500]	BT 0.045 (0.291)	DT 0.004 (0.253)	loss 6.592 (6.621)	prob 2.147 (2.400)	GS 35.047 (31.970)	mem 74.454
Train: [83][1370/1500]	BT 0.029 (0.292)	DT 0.000 (0.254)	loss 6.556 (6.625)	prob 2.369 (2.437)	GS 34.828 (31.927)	mem 74.456
Train: [83][1380/1500]	BT 0.030 (0.290)	DT 0.001 (0.252)	loss 6.561 (6.630)	prob 2.612 (2.458)	GS 30.453 (32.335)	mem 74.456
Train: [83][1390/1500]	BT 0.030 (0.288)	DT 0.001 (0.251)	loss 6.895 (6.649)	prob 2.805 (2.479)	GS 34.562 (32.385)	mem 74.456
Train: [83][1400/1500]	BT 0.095 (0.290)	DT 0.013 (0.252)	loss 6.645 (6.643)	prob 2.839 (2.468)	GS 40.250 (32.501)	mem 74.455
Train: [83][1410/1500]	BT 0.052 (0.288)	DT 0.001 (0.250)	loss 6.648 (6.607)	prob 2.256 (2.331)	GS 34.000 (31.283)	mem 74.456
Train: [83][1420/1500]	BT 0.039 (0.290)	DT 0.001 (0.252)	loss 6.564 (6.598)	prob 2.306 (2.446)	GS 32.641 (32.903)	mem 74.455
Train: [83][1430/1500]	BT 0.039 (0.288)	DT 0.001 (0.250)	loss 6.642 (6.626)	prob 1.767 (2.509)	GS 37.281 (32.920)	mem 74.454
Train: [83][1440/1500]	BT 0.082 (0.291)	DT 0.008 (0.253)	loss 6.690 (6.621)	prob 2.790 (2.542)	GS 35.875 (33.047)	mem 74.454
Train: [83][1450/1500]	BT 0.068 (0.290)	DT 0.009 (0.252)	loss 6.483 (6.619)	prob 2.414 (2.540)	GS 28.984 (32.698)	mem 74.457
Train: [83][1460/1500]	BT 0.051 (0.288)	DT 0.012 (0.250)	loss 6.810 (6.633)	prob 2.217 (2.555)	GS 34.734 (31.139)	mem 74.456
Train: [83][1470/1500]	BT 0.042 (0.291)	DT 0.001 (0.252)	loss 6.787 (6.611)	prob 2.637 (2.635)	GS 32.406 (32.084)	mem 65.268
Train: [83][1480/1500]	BT 0.035 (0.289)	DT 0.001 (0.251)	loss 6.600 (6.615)	prob 2.575 (2.599)	GS 34.125 (32.479)	mem 47.775
Train: [83][1490/1500]	BT 0.025 (0.289)	DT 0.000 (0.250)	loss 6.596 (6.609)	prob 2.742 (2.654)	GS 41.781 (32.533)	mem 9.398
Train: [83][1500/1500]	BT 0.025 (0.287)	DT 0.000 (0.249)	loss 6.546 (6.595)	prob 3.296 (2.717)	GS 38.031 (32.659)	mem 9.398
Train: [83][1510/1500]	BT 0.025 (0.285)	DT 0.000 (0.247)	loss 6.321 (6.335)	prob 3.003 (2.998)	GS 32.812 (35.847)	mem 9.398
epoch 83, total time 431.92
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [84][1/1500]	BT 18.672 (18.672)	DT 18.616 (18.616)	loss 6.454 (6.454)	prob 2.567 (2.567)	GS 32.125 (32.125)	mem 73.055
Train: [84][10/1500]	BT 0.037 (2.277)	DT 0.001 (2.239)	loss 6.270 (6.306)	prob 2.794 (2.923)	GS 32.578 (33.780)	mem 73.143
Train: [84][20/1500]	BT 0.036 (1.157)	DT 0.001 (1.120)	loss 6.332 (6.347)	prob 3.182 (2.962)	GS 31.703 (33.656)	mem 73.152
Train: [84][30/1500]	BT 0.069 (1.027)	DT 0.002 (0.988)	loss 6.586 (6.402)	prob 2.582 (2.880)	GS 34.094 (33.209)	mem 73.203
Train: [84][40/1500]	BT 0.024 (0.807)	DT 0.000 (0.769)	loss 6.617 (6.449)	prob 2.722 (2.856)	GS 30.547 (32.508)	mem 73.206
Train: [84][50/1500]	BT 0.037 (0.668)	DT 0.000 (0.632)	loss 6.610 (6.485)	prob 2.965 (2.820)	GS 37.547 (32.673)	mem 73.210
Train: [84][60/1500]	BT 0.035 (0.617)	DT 0.000 (0.581)	loss 6.792 (6.583)	prob 2.325 (2.639)	GS 33.109 (31.577)	mem 73.232
Train: [84][70/1500]	BT 0.037 (0.534)	DT 0.000 (0.498)	loss 6.771 (6.624)	prob 3.300 (2.695)	GS 34.156 (31.680)	mem 73.232
Train: [84][80/1500]	BT 0.035 (0.588)	DT 0.000 (0.551)	loss 6.807 (6.641)	prob 1.992 (2.702)	GS 33.297 (32.069)	mem 73.263
Train: [84][90/1500]	BT 0.027 (0.535)	DT 0.000 (0.499)	loss 6.679 (6.651)	prob 2.901 (2.727)	GS 32.578 (32.509)	mem 73.150
Train: [84][100/1500]	BT 0.036 (0.493)	DT 0.001 (0.458)	loss 6.727 (6.657)	prob 2.316 (2.701)	GS 33.125 (32.456)	mem 73.171
Train: [84][110/1500]	BT 0.028 (0.479)	DT 0.000 (0.443)	loss 7.007 (6.717)	prob 2.253 (2.568)	GS 31.531 (32.284)	mem 73.173
Train: [84][120/1500]	BT 0.037 (0.442)	DT 0.001 (0.407)	loss 6.839 (6.710)	prob 2.981 (2.571)	GS 28.578 (32.209)	mem 73.174
Train: [84][130/1500]	BT 0.039 (0.435)	DT 0.001 (0.400)	loss 6.700 (6.709)	prob 2.650 (2.601)	GS 29.578 (32.017)	mem 73.176
Train: [84][140/1500]	BT 0.037 (0.407)	DT 0.001 (0.371)	loss 6.754 (6.701)	prob 2.575 (2.590)	GS 31.781 (31.986)	mem 73.185
Train: [84][150/1500]	BT 0.036 (0.391)	DT 0.001 (0.356)	loss 6.889 (6.705)	prob 3.108 (2.558)	GS 32.719 (32.218)	mem 73.195
Train: [84][160/1500]	BT 0.036 (0.387)	DT 0.000 (0.352)	loss 6.723 (6.646)	prob 2.142 (2.536)	GS 31.938 (32.509)	mem 73.196
Train: [84][170/1500]	BT 0.028 (0.367)	DT 0.000 (0.331)	loss 6.500 (6.641)	prob 2.403 (2.466)	GS 37.844 (33.116)	mem 73.196
Train: [84][180/1500]	BT 0.037 (0.366)	DT 0.001 (0.330)	loss 6.559 (6.634)	prob 2.475 (2.438)	GS 33.172 (32.803)	mem 73.199
Train: [84][190/1500]	BT 0.037 (0.349)	DT 0.000 (0.313)	loss 6.777 (6.629)	prob 2.706 (2.457)	GS 32.094 (32.648)	mem 73.211
Train: [84][200/1500]	BT 0.038 (0.370)	DT 0.000 (0.334)	loss 6.493 (6.626)	prob 2.299 (2.444)	GS 34.328 (32.902)	mem 73.226
Train: [84][210/1500]	BT 0.068 (0.355)	DT 0.001 (0.319)	loss 6.525 (6.601)	prob 2.729 (2.528)	GS 36.641 (34.169)	mem 73.227
Train: [84][220/1500]	BT 0.090 (0.370)	DT 0.012 (0.332)	loss 6.579 (6.619)	prob 2.777 (2.541)	GS 33.844 (33.895)	mem 73.215
Train: [84][230/1500]	BT 0.080 (0.380)	DT 0.014 (0.341)	loss 6.630 (6.617)	prob 2.605 (2.484)	GS 33.859 (33.445)	mem 73.218
Train: [84][240/1500]	BT 0.028 (0.413)	DT 0.000 (0.373)	loss 6.715 (6.623)	prob 2.248 (2.464)	GS 37.438 (33.725)	mem 73.219
Train: [84][250/1500]	BT 0.031 (0.398)	DT 0.000 (0.358)	loss 6.710 (6.624)	prob 2.338 (2.491)	GS 32.594 (33.458)	mem 73.220
Train: [84][260/1500]	BT 0.024 (0.384)	DT 0.000 (0.344)	loss 6.616 (6.628)	prob 1.811 (2.464)	GS 36.969 (32.869)	mem 73.220
Train: [84][270/1500]	BT 0.038 (0.384)	DT 0.001 (0.344)	loss 6.699 (6.628)	prob 1.999 (2.387)	GS 29.094 (32.663)	mem 73.225
Train: [84][280/1500]	BT 0.038 (0.371)	DT 0.001 (0.332)	loss 6.566 (6.642)	prob 2.710 (2.416)	GS 35.297 (32.853)	mem 73.225
Train: [84][290/1500]	BT 0.039 (0.369)	DT 0.001 (0.330)	loss 6.750 (6.647)	prob 2.529 (2.423)	GS 36.219 (32.761)	mem 73.225
Train: [84][300/1500]	BT 0.038 (0.358)	DT 0.001 (0.319)	loss 6.538 (6.644)	prob 2.154 (2.349)	GS 30.484 (32.586)	mem 73.225
Train: [84][310/1500]	BT 6.240 (0.368)	DT 6.208 (0.329)	loss 6.718 (6.680)	prob 1.812 (2.335)	GS 35.312 (33.062)	mem 73.226
Train: [84][320/1500]	BT 0.039 (0.358)	DT 0.001 (0.318)	loss 6.612 (6.648)	prob 2.539 (2.442)	GS 30.875 (32.928)	mem 73.228
Train: [84][330/1500]	BT 0.040 (0.348)	DT 0.001 (0.309)	loss 6.755 (6.664)	prob 1.084 (2.466)	GS 35.109 (33.139)	mem 73.228
Train: [84][340/1500]	BT 0.048 (0.351)	DT 0.001 (0.312)	loss 6.676 (6.669)	prob 3.011 (2.449)	GS 33.094 (33.224)	mem 73.232
Train: [84][350/1500]	BT 0.040 (0.347)	DT 0.001 (0.308)	loss 6.640 (6.676)	prob 1.877 (2.396)	GS 38.031 (33.110)	mem 73.234
Train: [84][360/1500]	BT 0.029 (0.342)	DT 0.000 (0.302)	loss 6.520 (6.743)	prob 2.876 (2.496)	GS 34.016 (32.780)	mem 73.235
Train: [84][370/1500]	BT 0.043 (0.339)	DT 0.001 (0.300)	loss 6.634 (6.738)	prob 2.530 (2.399)	GS 34.391 (32.948)	mem 73.237
Train: [84][380/1500]	BT 0.037 (0.335)	DT 0.000 (0.296)	loss 6.799 (6.710)	prob 2.160 (2.339)	GS 31.875 (32.761)	mem 73.253
Train: [84][390/1500]	BT 0.049 (0.331)	DT 0.010 (0.292)	loss 7.056 (6.706)	prob 2.352 (2.304)	GS 34.906 (32.696)	mem 73.254
Train: [84][400/1500]	BT 0.027 (0.332)	DT 0.000 (0.293)	loss 6.556 (6.697)	prob 2.677 (2.318)	GS 32.719 (33.040)	mem 73.257
Train: [84][410/1500]	BT 0.037 (0.325)	DT 0.001 (0.286)	loss 6.633 (6.666)	prob 1.421 (2.104)	GS 36.781 (33.616)	mem 73.258
Train: [84][420/1500]	BT 0.028 (0.320)	DT 0.000 (0.281)	loss 6.639 (6.678)	prob 2.074 (2.095)	GS 30.328 (32.158)	mem 73.258
Train: [84][430/1500]	BT 0.087 (0.324)	DT 0.006 (0.285)	loss 6.805 (6.664)	prob 1.922 (2.005)	GS 35.422 (31.778)	mem 73.261
Train: [84][440/1500]	BT 0.042 (0.321)	DT 0.009 (0.282)	loss 6.447 (6.652)	prob 2.371 (2.039)	GS 32.797 (31.873)	mem 73.261
Train: [84][450/1500]	BT 0.034 (0.331)	DT 0.000 (0.291)	loss 6.713 (6.650)	prob 1.852 (1.977)	GS 36.391 (32.045)	mem 73.263
Train: [84][460/1500]	BT 0.037 (0.324)	DT 0.000 (0.285)	loss 6.751 (6.668)	prob 2.493 (2.206)	GS 33.859 (34.078)	mem 73.262
Train: [84][470/1500]	BT 0.037 (0.324)	DT 0.001 (0.285)	loss 6.530 (6.661)	prob 2.295 (2.289)	GS 28.609 (33.295)	mem 73.265
Train: [84][480/1500]	BT 0.037 (0.318)	DT 0.000 (0.279)	loss 6.516 (6.658)	prob 1.793 (2.202)	GS 33.094 (32.796)	mem 73.265
Train: [84][490/1500]	BT 0.059 (0.325)	DT 0.011 (0.286)	loss 6.693 (6.652)	prob 2.069 (2.162)	GS 38.172 (33.000)	mem 73.267
Train: [84][500/1500]	BT 0.080 (0.323)	DT 0.012 (0.283)	loss 6.581 (6.650)	prob 2.272 (2.147)	GS 31.219 (32.781)	mem 73.268
Train: [84][510/1500]	BT 5.694 (0.332)	DT 5.634 (0.291)	loss 6.566 (6.627)	prob 1.946 (2.246)	GS 36.141 (33.464)	mem 73.271
Train: [84][520/1500]	BT 0.088 (0.334)	DT 0.018 (0.293)	loss 6.547 (6.627)	prob 2.344 (2.186)	GS 35.969 (33.788)	mem 73.272
Train: [84][530/1500]	BT 9.046 (0.362)	DT 9.006 (0.321)	loss 6.804 (6.648)	prob 2.458 (2.274)	GS 41.797 (34.103)	mem 73.272
Train: [84][540/1500]	BT 0.035 (0.356)	DT 0.000 (0.315)	loss 6.731 (6.676)	prob 2.639 (2.298)	GS 33.125 (33.621)	mem 73.274
Train: [84][550/1500]	BT 0.035 (0.350)	DT 0.001 (0.309)	loss 6.476 (6.674)	prob 3.230 (2.370)	GS 33.016 (33.609)	mem 73.275
Train: [84][560/1500]	BT 0.026 (0.350)	DT 0.000 (0.310)	loss 6.611 (6.670)	prob 2.616 (2.520)	GS 35.781 (31.781)	mem 73.279
Train: [84][570/1500]	BT 0.037 (0.345)	DT 0.000 (0.304)	loss 6.750 (6.682)	prob 2.084 (2.409)	GS 36.188 (32.175)	mem 73.280
Train: [84][580/1500]	BT 0.038 (0.344)	DT 0.000 (0.304)	loss 6.689 (6.671)	prob 2.315 (2.455)	GS 34.859 (32.732)	mem 73.281
Train: [84][590/1500]	BT 0.038 (0.339)	DT 0.001 (0.299)	loss 6.715 (6.675)	prob 2.771 (2.446)	GS 30.453 (32.570)	mem 73.280
Train: [84][600/1500]	BT 0.038 (0.334)	DT 0.001 (0.294)	loss 6.802 (6.676)	prob 2.799 (2.425)	GS 33.484 (32.697)	mem 73.280
Train: [84][610/1500]	BT 0.058 (0.334)	DT 0.011 (0.294)	loss 6.706 (6.647)	prob 2.492 (2.508)	GS 31.484 (32.720)	mem 73.280
Train: [84][620/1500]	BT 0.034 (0.330)	DT 0.000 (0.289)	loss 6.650 (6.650)	prob 2.162 (2.359)	GS 32.094 (32.775)	mem 73.281
Train: [84][630/1500]	BT 0.029 (0.352)	DT 0.000 (0.311)	loss 6.803 (6.664)	prob 1.918 (2.370)	GS 34.906 (33.078)	mem 73.428
Train: [84][640/1500]	BT 0.026 (0.347)	DT 0.000 (0.307)	loss 6.683 (6.656)	prob 2.828 (2.361)	GS 31.734 (32.743)	mem 73.452
Train: [84][650/1500]	BT 0.026 (0.348)	DT 0.000 (0.308)	loss 6.680 (6.655)	prob 2.678 (2.394)	GS 31.641 (32.773)	mem 73.727
Train: [84][660/1500]	BT 0.039 (0.343)	DT 0.000 (0.303)	loss 6.661 (6.652)	prob 2.717 (2.481)	GS 33.141 (34.247)	mem 73.776
Train: [84][670/1500]	BT 0.038 (0.339)	DT 0.001 (0.299)	loss 6.579 (6.663)	prob 3.173 (2.567)	GS 32.031 (33.748)	mem 73.776
Train: [84][680/1500]	BT 0.037 (0.338)	DT 0.001 (0.299)	loss 6.599 (6.679)	prob 3.007 (2.508)	GS 29.594 (33.133)	mem 74.265
Train: [84][690/1500]	BT 0.037 (0.334)	DT 0.000 (0.294)	loss 6.524 (6.671)	prob 2.684 (2.475)	GS 31.406 (32.836)	mem 74.266
Train: [84][700/1500]	BT 0.037 (0.334)	DT 0.000 (0.294)	loss 6.687 (6.659)	prob 3.074 (2.533)	GS 31.969 (32.684)	mem 74.463
Train: [84][710/1500]	BT 0.038 (0.330)	DT 0.000 (0.290)	loss 6.905 (6.734)	prob 2.547 (2.602)	GS 31.766 (32.159)	mem 74.464
Train: [84][720/1500]	BT 0.047 (0.331)	DT 0.000 (0.291)	loss 6.775 (6.717)	prob 1.924 (2.577)	GS 29.375 (32.309)	mem 74.464
Train: [84][730/1500]	BT 0.038 (0.327)	DT 0.001 (0.287)	loss 6.598 (6.690)	prob 2.104 (2.504)	GS 35.906 (32.248)	mem 74.465
Train: [84][740/1500]	BT 0.077 (0.325)	DT 0.010 (0.285)	loss 6.700 (6.687)	prob 2.377 (2.527)	GS 33.156 (32.527)	mem 74.464
Train: [84][750/1500]	BT 0.032 (0.331)	DT 0.001 (0.291)	loss 6.867 (6.689)	prob 2.829 (2.487)	GS 32.812 (32.550)	mem 74.498
Train: [84][760/1500]	BT 0.039 (0.327)	DT 0.001 (0.287)	loss 6.733 (6.712)	prob 2.586 (2.679)	GS 35.359 (33.242)	mem 74.498
Train: [84][770/1500]	BT 0.035 (0.332)	DT 0.000 (0.292)	loss 6.691 (6.709)	prob 3.289 (2.703)	GS 32.922 (33.110)	mem 74.500
Train: [84][780/1500]	BT 0.082 (0.328)	DT 0.013 (0.289)	loss 6.614 (6.705)	prob 2.229 (2.729)	GS 36.406 (33.222)	mem 74.501
Train: [84][790/1500]	BT 0.045 (0.325)	DT 0.006 (0.285)	loss 6.820 (6.738)	prob 2.518 (2.710)	GS 30.953 (32.652)	mem 74.501
Train: [84][800/1500]	BT 0.027 (0.340)	DT 0.000 (0.300)	loss 6.939 (6.745)	prob 1.823 (2.659)	GS 36.016 (32.719)	mem 74.499
Train: [84][810/1500]	BT 0.024 (0.336)	DT 0.000 (0.296)	loss 6.776 (6.751)	prob 3.046 (2.856)	GS 31.141 (31.586)	mem 74.499
Train: [84][820/1500]	BT 0.035 (0.337)	DT 0.001 (0.297)	loss 6.994 (6.722)	prob 2.696 (2.683)	GS 32.516 (32.185)	mem 74.500
Train: [84][830/1500]	BT 0.030 (0.333)	DT 0.000 (0.294)	loss 6.843 (6.733)	prob 1.913 (2.743)	GS 37.891 (32.216)	mem 74.499
Train: [84][840/1500]	BT 0.039 (0.329)	DT 0.001 (0.290)	loss 6.511 (6.731)	prob 2.628 (2.707)	GS 32.969 (32.647)	mem 74.500
Train: [84][850/1500]	BT 0.028 (0.333)	DT 0.000 (0.294)	loss 6.833 (6.745)	prob 2.711 (2.722)	GS 36.562 (32.842)	mem 74.501
Train: [84][860/1500]	BT 0.030 (0.330)	DT 0.000 (0.291)	loss 6.665 (6.674)	prob 2.781 (2.907)	GS 32.812 (32.555)	mem 74.503
Train: [84][870/1500]	BT 0.038 (0.331)	DT 0.001 (0.292)	loss 7.226 (6.685)	prob 2.072 (2.785)	GS 28.469 (32.770)	mem 74.504
Train: [84][880/1500]	BT 0.040 (0.328)	DT 0.001 (0.289)	loss 6.863 (6.675)	prob 2.276 (2.731)	GS 36.031 (32.858)	mem 74.504
Train: [84][890/1500]	BT 0.039 (0.324)	DT 0.001 (0.285)	loss 7.100 (6.706)	prob 2.928 (2.680)	GS 34.031 (33.004)	mem 74.504
Train: [84][900/1500]	BT 0.038 (0.325)	DT 0.001 (0.286)	loss 6.738 (6.702)	prob 2.401 (2.704)	GS 38.469 (32.902)	mem 74.505
Train: [84][910/1500]	BT 0.039 (0.322)	DT 0.001 (0.283)	loss 6.550 (6.716)	prob 2.974 (2.813)	GS 31.766 (32.709)	mem 74.505
Train: [84][920/1500]	BT 0.040 (0.321)	DT 0.001 (0.282)	loss 6.737 (6.710)	prob 2.870 (2.712)	GS 35.922 (32.827)	mem 74.506
Train: [84][930/1500]	BT 0.039 (0.321)	DT 0.001 (0.282)	loss 6.740 (6.700)	prob 2.378 (2.641)	GS 36.047 (32.760)	mem 74.507
Train: [84][940/1500]	BT 0.039 (0.319)	DT 0.001 (0.280)	loss 6.685 (6.694)	prob 1.772 (2.532)	GS 33.781 (32.605)	mem 74.507
Train: [84][950/1500]	BT 0.040 (0.318)	DT 0.001 (0.279)	loss 6.802 (6.683)	prob 2.599 (2.513)	GS 37.406 (32.538)	mem 74.507
Train: [84][960/1500]	BT 0.039 (0.315)	DT 0.001 (0.276)	loss 6.848 (6.652)	prob 2.337 (2.465)	GS 34.047 (32.434)	mem 74.507
Train: [84][970/1500]	BT 0.038 (0.317)	DT 0.001 (0.278)	loss 6.647 (6.673)	prob 2.536 (2.492)	GS 37.141 (32.745)	mem 74.507
Train: [84][980/1500]	BT 0.039 (0.315)	DT 0.001 (0.275)	loss 6.861 (6.669)	prob 2.603 (2.413)	GS 33.562 (33.134)	mem 74.509
Train: [84][990/1500]	BT 0.039 (0.314)	DT 0.001 (0.275)	loss 6.795 (6.666)	prob 2.598 (2.427)	GS 31.719 (33.144)	mem 74.509
Train: [84][1000/1500]	BT 0.037 (0.312)	DT 0.001 (0.273)	loss 6.653 (6.671)	prob 2.152 (2.396)	GS 36.422 (33.108)	mem 74.509
Train: [84][1010/1500]	BT 0.037 (0.309)	DT 0.001 (0.270)	loss 6.649 (6.666)	prob 2.883 (2.459)	GS 33.516 (31.739)	mem 74.509
Train: [84][1020/1500]	BT 0.038 (0.310)	DT 0.001 (0.271)	loss 6.791 (6.689)	prob 1.942 (2.387)	GS 31.453 (32.030)	mem 74.525
Train: [84][1030/1500]	BT 0.037 (0.308)	DT 0.000 (0.269)	loss 6.603 (6.692)	prob 2.843 (2.425)	GS 32.156 (32.122)	mem 74.525
Train: [84][1040/1500]	BT 0.040 (0.308)	DT 0.001 (0.269)	loss 6.938 (6.701)	prob 2.775 (2.373)	GS 31.969 (32.164)	mem 74.527
Train: [84][1050/1500]	BT 0.037 (0.307)	DT 0.000 (0.268)	loss 6.594 (6.691)	prob 2.641 (2.359)	GS 36.172 (32.160)	mem 74.520
Train: [84][1060/1500]	BT 2.581 (0.308)	DT 2.525 (0.269)	loss 7.131 (6.818)	prob 2.536 (2.530)	GS 38.375 (33.194)	mem 74.429
Train: [84][1070/1500]	BT 0.027 (0.312)	DT 0.000 (0.273)	loss 6.915 (6.768)	prob 3.514 (2.644)	GS 32.281 (33.143)	mem 74.430
Train: [84][1080/1500]	BT 0.024 (0.310)	DT 0.000 (0.271)	loss 6.671 (6.753)	prob 3.062 (2.748)	GS 34.344 (32.643)	mem 74.431
Train: [84][1090/1500]	BT 0.043 (0.307)	DT 0.017 (0.268)	loss 6.768 (6.730)	prob 2.337 (2.748)	GS 35.172 (33.006)	mem 74.430
Train: [84][1100/1500]	BT 0.037 (0.309)	DT 0.000 (0.270)	loss 6.721 (6.725)	prob 2.089 (2.736)	GS 31.250 (32.841)	mem 74.433
Train: [84][1110/1500]	BT 0.037 (0.307)	DT 0.001 (0.268)	loss 6.849 (6.760)	prob 1.888 (2.552)	GS 33.016 (31.836)	mem 74.434
Train: [84][1120/1500]	BT 0.066 (0.311)	DT 0.011 (0.272)	loss 6.640 (6.755)	prob 2.939 (2.615)	GS 36.625 (32.637)	mem 74.432
Train: [84][1130/1500]	BT 0.029 (0.314)	DT 0.000 (0.275)	loss 6.937 (6.783)	prob 2.485 (2.585)	GS 35.109 (33.339)	mem 74.437
Train: [84][1140/1500]	BT 0.031 (0.311)	DT 0.000 (0.272)	loss 6.788 (6.811)	prob 2.700 (2.703)	GS 32.906 (33.005)	mem 74.439
Train: [84][1150/1500]	BT 0.038 (0.309)	DT 0.001 (0.270)	loss 6.738 (6.804)	prob 2.833 (2.714)	GS 31.875 (32.664)	mem 74.439
Train: [84][1160/1500]	BT 0.031 (0.310)	DT 0.000 (0.271)	loss 6.817 (6.793)	prob 3.019 (2.808)	GS 32.609 (32.686)	mem 74.440
Train: [84][1170/1500]	BT 0.064 (0.309)	DT 0.013 (0.270)	loss 6.926 (6.801)	prob 2.903 (2.833)	GS 35.266 (32.716)	mem 74.440
Train: [84][1180/1500]	BT 0.038 (0.312)	DT 0.001 (0.273)	loss 6.941 (6.819)	prob 2.928 (2.791)	GS 33.641 (32.843)	mem 74.441
Train: [84][1190/1500]	BT 0.038 (0.310)	DT 0.001 (0.271)	loss 6.847 (6.822)	prob 3.311 (2.865)	GS 33.281 (32.906)	mem 74.443
Train: [84][1200/1500]	BT 0.064 (0.309)	DT 0.002 (0.270)	loss 6.548 (6.822)	prob 2.802 (2.867)	GS 34.812 (32.961)	mem 74.443
Train: [84][1210/1500]	BT 0.039 (0.310)	DT 0.001 (0.271)	loss 6.912 (6.943)	prob 2.337 (2.845)	GS 36.469 (32.767)	mem 74.444
Train: [84][1220/1500]	BT 0.039 (0.307)	DT 0.001 (0.268)	loss 7.447 (6.911)	prob 2.170 (2.864)	GS 35.891 (32.652)	mem 74.444
Train: [84][1230/1500]	BT 0.039 (0.308)	DT 0.001 (0.269)	loss 6.707 (6.899)	prob 2.900 (2.793)	GS 33.406 (33.024)	mem 74.441
Train: [84][1240/1500]	BT 0.039 (0.306)	DT 0.001 (0.267)	loss 6.925 (6.907)	prob 2.308 (2.767)	GS 28.312 (32.662)	mem 74.441
Train: [84][1250/1500]	BT 0.039 (0.304)	DT 0.001 (0.265)	loss 7.180 (6.909)	prob 3.180 (2.775)	GS 37.984 (32.756)	mem 74.443
Train: [84][1260/1500]	BT 0.033 (0.306)	DT 0.001 (0.268)	loss 6.927 (6.873)	prob 2.620 (2.813)	GS 32.547 (33.273)	mem 74.443
Train: [84][1270/1500]	BT 0.038 (0.304)	DT 0.001 (0.265)	loss 6.631 (6.869)	prob 2.961 (2.845)	GS 34.250 (32.230)	mem 74.445
Train: [84][1280/1500]	BT 0.039 (0.302)	DT 0.001 (0.263)	loss 6.869 (6.845)	prob 3.124 (2.883)	GS 38.188 (32.478)	mem 74.445
Train: [84][1290/1500]	BT 0.037 (0.303)	DT 0.001 (0.264)	loss 6.881 (6.865)	prob 2.999 (3.002)	GS 30.688 (32.248)	mem 74.458
Train: [84][1300/1500]	BT 0.036 (0.301)	DT 0.000 (0.262)	loss 7.048 (6.869)	prob 2.569 (2.946)	GS 34.094 (32.090)	mem 74.459
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [84][1310/1500]	BT 0.053 (0.303)	DT 0.003 (0.264)	loss 6.835 (6.887)	prob 2.699 (2.664)	GS 30.844 (31.298)	mem 74.461
Train: [84][1320/1500]	BT 0.036 (0.303)	DT 0.000 (0.264)	loss 7.060 (6.900)	prob 3.057 (2.697)	GS 31.453 (32.302)	mem 74.463
Train: [84][1330/1500]	BT 0.037 (0.301)	DT 0.001 (0.262)	loss 6.852 (6.875)	prob 2.992 (2.781)	GS 34.750 (31.984)	mem 74.463
Train: [84][1340/1500]	BT 0.036 (0.301)	DT 0.001 (0.262)	loss 6.835 (6.876)	prob 3.192 (2.830)	GS 33.266 (31.818)	mem 74.465
Train: [84][1350/1500]	BT 0.037 (0.299)	DT 0.000 (0.260)	loss 6.628 (6.858)	prob 3.597 (2.846)	GS 37.844 (32.011)	mem 74.467
Train: [84][1360/1500]	BT 0.036 (0.300)	DT 0.000 (0.261)	loss 6.799 (6.789)	prob 2.360 (2.691)	GS 36.203 (32.159)	mem 74.469
Train: [84][1370/1500]	BT 0.038 (0.298)	DT 0.001 (0.259)	loss 6.745 (6.793)	prob 2.448 (2.675)	GS 31.188 (32.601)	mem 74.471
Train: [84][1380/1500]	BT 0.038 (0.299)	DT 0.000 (0.260)	loss 6.782 (6.796)	prob 2.660 (2.693)	GS 34.250 (32.566)	mem 74.473
Train: [84][1390/1500]	BT 0.037 (0.297)	DT 0.001 (0.258)	loss 6.996 (6.812)	prob 3.020 (2.740)	GS 32.859 (32.461)	mem 74.473
Train: [84][1400/1500]	BT 0.037 (0.298)	DT 0.001 (0.259)	loss 6.712 (6.819)	prob 3.251 (2.806)	GS 35.906 (32.913)	mem 74.472
Train: [84][1410/1500]	BT 0.039 (0.296)	DT 0.001 (0.258)	loss 6.959 (6.859)	prob 2.123 (2.598)	GS 35.594 (31.680)	mem 74.472
Train: [84][1420/1500]	BT 0.032 (0.298)	DT 0.000 (0.259)	loss 6.832 (6.845)	prob 2.383 (2.557)	GS 34.047 (32.249)	mem 74.473
Train: [84][1430/1500]	BT 0.026 (0.296)	DT 0.000 (0.257)	loss 7.093 (6.831)	prob 2.784 (2.567)	GS 32.188 (32.042)	mem 74.474
Train: [84][1440/1500]	BT 0.038 (0.295)	DT 0.001 (0.256)	loss 6.820 (6.829)	prob 2.403 (2.656)	GS 32.281 (32.309)	mem 74.476
Train: [84][1450/1500]	BT 0.036 (0.295)	DT 0.001 (0.257)	loss 6.739 (6.829)	prob 2.231 (2.628)	GS 32.594 (32.143)	mem 74.403
Train: [84][1460/1500]	BT 0.037 (0.293)	DT 0.001 (0.255)	loss 6.757 (6.753)	prob 2.856 (2.747)	GS 31.125 (31.738)	mem 74.405
Train: [84][1470/1500]	BT 0.029 (0.293)	DT 0.000 (0.255)	loss 6.750 (6.753)	prob 2.350 (2.669)	GS 35.125 (31.980)	mem 53.916
Train: [84][1480/1500]	BT 0.027 (0.292)	DT 0.000 (0.253)	loss 6.793 (6.759)	prob 2.568 (2.589)	GS 37.203 (32.253)	mem 53.842
Train: [84][1490/1500]	BT 0.024 (0.290)	DT 0.001 (0.252)	loss 6.837 (6.763)	prob 2.674 (2.669)	GS 35.469 (32.408)	mem 25.576
Train: [84][1500/1500]	BT 0.025 (0.289)	DT 0.000 (0.250)	loss 6.946 (6.763)	prob 2.196 (2.682)	GS 37.156 (32.493)	mem 12.095
Train: [84][1510/1500]	BT 0.018 (0.287)	DT 0.000 (0.249)	loss 6.628 (6.610)	prob 2.712 (2.929)	GS 37.250 (32.866)	mem 12.095
epoch 84, total time 433.86
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [85][1/1500]	BT 17.481 (17.481)	DT 17.424 (17.424)	loss 6.488 (6.488)	prob 2.635 (2.635)	GS 28.484 (28.484)	mem 72.842
Train: [85][10/1500]	BT 0.047 (2.244)	DT 0.010 (2.210)	loss 6.512 (6.569)	prob 2.951 (2.798)	GS 31.984 (32.715)	mem 74.148
Train: [85][20/1500]	BT 0.027 (1.137)	DT 0.000 (1.105)	loss 6.529 (6.603)	prob 2.626 (2.821)	GS 35.297 (33.305)	mem 74.152
Train: [85][30/1500]	BT 0.039 (0.942)	DT 0.000 (0.909)	loss 6.651 (6.628)	prob 2.815 (2.751)	GS 37.141 (33.205)	mem 74.247
Train: [85][40/1500]	BT 0.039 (0.717)	DT 0.001 (0.682)	loss 6.685 (6.663)	prob 2.370 (2.721)	GS 33.297 (32.725)	mem 74.249
Train: [85][50/1500]	BT 1.515 (0.611)	DT 1.475 (0.575)	loss 7.009 (6.685)	prob 2.165 (2.763)	GS 27.797 (32.621)	mem 74.255
Train: [85][60/1500]	BT 0.040 (0.535)	DT 0.001 (0.499)	loss 6.714 (6.751)	prob 2.530 (2.971)	GS 36.016 (32.850)	mem 74.297
Train: [85][70/1500]	BT 0.039 (0.464)	DT 0.001 (0.428)	loss 6.824 (6.793)	prob 2.689 (2.946)	GS 31.672 (32.309)	mem 74.297
Train: [85][80/1500]	BT 0.039 (0.455)	DT 0.001 (0.418)	loss 6.963 (6.793)	prob 2.289 (2.792)	GS 33.188 (32.118)	mem 74.298
Train: [85][90/1500]	BT 0.039 (0.414)	DT 0.001 (0.377)	loss 6.802 (6.785)	prob 2.265 (2.725)	GS 36.188 (32.298)	mem 74.302
Train: [85][100/1500]	BT 0.038 (0.448)	DT 0.000 (0.409)	loss 6.925 (6.781)	prob 2.771 (2.680)	GS 34.125 (32.267)	mem 74.315
Train: [85][110/1500]	BT 0.039 (0.410)	DT 0.001 (0.372)	loss 6.769 (6.713)	prob 2.793 (2.697)	GS 32.859 (32.153)	mem 74.316
Train: [85][120/1500]	BT 0.039 (0.384)	DT 0.001 (0.346)	loss 6.793 (6.729)	prob 2.541 (2.471)	GS 33.516 (32.634)	mem 74.316
Train: [85][130/1500]	BT 0.095 (0.404)	DT 0.004 (0.363)	loss 7.004 (6.771)	prob 2.338 (2.412)	GS 29.594 (32.156)	mem 74.322
Train: [85][140/1500]	BT 0.101 (0.395)	DT 0.024 (0.353)	loss 6.800 (6.767)	prob 2.983 (2.421)	GS 34.250 (32.333)	mem 74.324
Train: [85][150/1500]	BT 0.037 (0.398)	DT 0.000 (0.357)	loss 6.604 (6.785)	prob 2.244 (2.430)	GS 33.438 (32.922)	mem 74.327
Train: [85][160/1500]	BT 0.043 (0.382)	DT 0.001 (0.342)	loss 6.768 (6.826)	prob 2.542 (2.292)	GS 35.516 (33.897)	mem 74.334
Train: [85][170/1500]	BT 0.041 (0.365)	DT 0.001 (0.324)	loss 7.171 (6.835)	prob 2.298 (2.471)	GS 35.906 (33.006)	mem 74.335
Train: [85][180/1500]	BT 0.038 (0.361)	DT 0.001 (0.320)	loss 7.372 (6.831)	prob 2.202 (2.533)	GS 33.766 (32.688)	mem 74.337
Train: [85][190/1500]	BT 0.069 (0.357)	DT 0.016 (0.317)	loss 6.733 (6.829)	prob 2.646 (2.576)	GS 25.859 (32.643)	mem 74.348
Train: [85][200/1500]	BT 0.022 (0.424)	DT 0.000 (0.383)	loss 6.771 (6.817)	prob 2.656 (2.558)	GS 36.062 (32.416)	mem 74.352
Train: [85][210/1500]	BT 0.041 (0.406)	DT 0.000 (0.365)	loss 6.895 (6.786)	prob 2.240 (2.417)	GS 33.688 (32.850)	mem 74.354
Train: [85][220/1500]	BT 3.878 (0.406)	DT 3.848 (0.366)	loss 6.872 (6.757)	prob 2.144 (2.486)	GS 35.391 (33.051)	mem 74.363
Train: [85][230/1500]	BT 0.038 (0.390)	DT 0.000 (0.350)	loss 6.859 (6.761)	prob 2.669 (2.586)	GS 38.594 (33.419)	mem 74.365
Train: [85][240/1500]	BT 0.039 (0.375)	DT 0.001 (0.336)	loss 6.895 (6.793)	prob 2.608 (2.531)	GS 34.672 (33.699)	mem 74.365
Train: [85][250/1500]	BT 0.028 (0.379)	DT 0.000 (0.340)	loss 6.837 (6.794)	prob 3.081 (2.552)	GS 36.062 (33.507)	mem 74.365
Train: [85][260/1500]	BT 0.036 (0.366)	DT 0.001 (0.327)	loss 6.781 (6.701)	prob 2.741 (2.645)	GS 31.688 (30.975)	mem 74.365
Train: [85][270/1500]	BT 0.039 (0.364)	DT 0.001 (0.325)	loss 6.742 (6.741)	prob 2.309 (2.717)	GS 36.703 (32.087)	mem 74.365
Train: [85][280/1500]	BT 0.038 (0.352)	DT 0.001 (0.314)	loss 6.865 (6.779)	prob 3.217 (2.741)	GS 36.547 (32.090)	mem 74.366
Train: [85][290/1500]	BT 0.034 (0.342)	DT 0.000 (0.303)	loss 6.565 (6.773)	prob 2.789 (2.751)	GS 33.312 (32.305)	mem 74.366
Train: [85][300/1500]	BT 0.037 (0.353)	DT 0.001 (0.314)	loss 6.719 (6.763)	prob 2.743 (2.749)	GS 32.109 (32.258)	mem 74.366
Train: [85][310/1500]	BT 0.039 (0.343)	DT 0.000 (0.304)	loss 6.647 (6.692)	prob 2.781 (2.757)	GS 32.125 (31.656)	mem 74.366
Train: [85][320/1500]	BT 0.036 (0.348)	DT 0.000 (0.309)	loss 6.670 (6.714)	prob 2.664 (2.750)	GS 31.406 (32.525)	mem 74.371
Train: [85][330/1500]	BT 0.038 (0.339)	DT 0.001 (0.300)	loss 6.842 (6.718)	prob 2.182 (2.723)	GS 34.438 (32.475)	mem 74.371
Train: [85][340/1500]	BT 1.884 (0.339)	DT 1.850 (0.300)	loss 6.724 (6.731)	prob 2.581 (2.658)	GS 34.875 (32.647)	mem 74.374
Train: [85][350/1500]	BT 0.027 (0.345)	DT 0.000 (0.307)	loss 7.003 (6.745)	prob 3.005 (2.656)	GS 36.469 (32.732)	mem 74.377
Train: [85][360/1500]	BT 0.601 (0.338)	DT 0.564 (0.300)	loss 6.790 (6.788)	prob 2.287 (2.703)	GS 27.484 (32.297)	mem 74.377
Train: [85][370/1500]	BT 0.029 (0.340)	DT 0.000 (0.302)	loss 6.708 (6.733)	prob 2.442 (2.551)	GS 35.484 (32.305)	mem 74.390
Train: [85][380/1500]	BT 0.037 (0.332)	DT 0.001 (0.294)	loss 6.757 (6.725)	prob 1.950 (2.582)	GS 34.516 (32.728)	mem 74.390
Train: [85][390/1500]	BT 8.238 (0.345)	DT 8.190 (0.307)	loss 6.961 (6.737)	prob 2.254 (2.549)	GS 35.891 (32.930)	mem 74.292
Train: [85][400/1500]	BT 0.055 (0.338)	DT 0.006 (0.300)	loss 6.767 (6.728)	prob 2.844 (2.601)	GS 31.375 (32.778)	mem 74.294
Train: [85][410/1500]	BT 0.063 (0.331)	DT 0.013 (0.293)	loss 6.661 (6.767)	prob 2.549 (2.626)	GS 29.328 (32.987)	mem 74.293
Train: [85][420/1500]	BT 0.027 (0.356)	DT 0.000 (0.317)	loss 7.065 (6.786)	prob 2.704 (2.546)	GS 32.656 (33.084)	mem 74.308
Train: [85][430/1500]	BT 0.028 (0.348)	DT 0.000 (0.310)	loss 6.751 (6.782)	prob 2.568 (2.732)	GS 32.969 (33.174)	mem 74.318
Train: [85][440/1500]	BT 0.027 (0.341)	DT 0.000 (0.303)	loss 6.858 (6.773)	prob 3.057 (2.829)	GS 31.969 (32.940)	mem 74.318
Train: [85][450/1500]	BT 0.038 (0.343)	DT 0.001 (0.305)	loss 6.751 (6.770)	prob 2.511 (2.765)	GS 30.000 (32.687)	mem 74.323
Train: [85][460/1500]	BT 0.029 (0.336)	DT 0.000 (0.299)	loss 6.829 (6.763)	prob 2.332 (2.789)	GS 34.000 (32.320)	mem 74.323
Train: [85][470/1500]	BT 0.072 (0.344)	DT 0.012 (0.306)	loss 6.685 (6.743)	prob 3.334 (2.829)	GS 32.953 (32.290)	mem 74.326
Train: [85][480/1500]	BT 0.035 (0.338)	DT 0.000 (0.299)	loss 6.772 (6.742)	prob 3.525 (2.798)	GS 32.328 (31.781)	mem 74.327
Train: [85][490/1500]	BT 0.046 (0.347)	DT 0.000 (0.309)	loss 6.722 (6.731)	prob 2.693 (2.793)	GS 34.844 (32.029)	mem 74.311
Train: [85][500/1500]	BT 0.052 (0.341)	DT 0.006 (0.303)	loss 6.722 (6.732)	prob 2.998 (2.739)	GS 36.234 (32.214)	mem 74.311
Train: [85][510/1500]	BT 0.030 (0.366)	DT 0.000 (0.327)	loss 6.849 (6.849)	prob 3.084 (2.736)	GS 32.547 (33.280)	mem 74.312
Train: [85][520/1500]	BT 0.031 (0.360)	DT 0.000 (0.321)	loss 6.803 (6.799)	prob 2.903 (2.638)	GS 30.500 (33.091)	mem 74.313
Train: [85][530/1500]	BT 0.037 (0.354)	DT 0.001 (0.315)	loss 6.529 (6.769)	prob 2.729 (2.599)	GS 35.109 (32.661)	mem 74.314
Train: [85][540/1500]	BT 0.031 (0.356)	DT 0.000 (0.317)	loss 6.622 (6.748)	prob 2.381 (2.611)	GS 32.953 (33.114)	mem 74.315
Train: [85][550/1500]	BT 0.033 (0.350)	DT 0.001 (0.312)	loss 6.875 (6.746)	prob 2.511 (2.622)	GS 32.828 (32.766)	mem 74.316
Train: [85][560/1500]	BT 0.029 (0.351)	DT 0.000 (0.313)	loss 6.841 (6.784)	prob 2.130 (2.510)	GS 37.938 (32.261)	mem 74.315
Train: [85][570/1500]	BT 0.039 (0.346)	DT 0.001 (0.308)	loss 6.578 (6.750)	prob 3.344 (2.553)	GS 31.031 (32.466)	mem 74.316
Train: [85][580/1500]	BT 0.038 (0.349)	DT 0.001 (0.311)	loss 6.678 (6.727)	prob 2.412 (2.581)	GS 35.328 (32.529)	mem 74.316
Train: [85][590/1500]	BT 0.039 (0.343)	DT 0.001 (0.305)	loss 6.567 (6.748)	prob 2.962 (2.565)	GS 32.688 (32.210)	mem 74.316
Train: [85][600/1500]	BT 0.039 (0.338)	DT 0.001 (0.300)	loss 6.618 (6.742)	prob 2.232 (2.572)	GS 32.703 (32.296)	mem 74.315
Train: [85][610/1500]	BT 0.036 (0.340)	DT 0.001 (0.302)	loss 6.793 (6.708)	prob 2.548 (2.622)	GS 37.250 (33.167)	mem 74.333
Train: [85][620/1500]	BT 0.037 (0.335)	DT 0.001 (0.297)	loss 6.860 (6.717)	prob 2.516 (2.607)	GS 37.906 (32.930)	mem 74.334
Train: [85][630/1500]	BT 0.024 (0.339)	DT 0.000 (0.301)	loss 6.451 (6.707)	prob 3.891 (2.704)	GS 31.891 (32.861)	mem 74.339
Train: [85][640/1500]	BT 0.024 (0.334)	DT 0.000 (0.296)	loss 6.719 (6.715)	prob 1.966 (2.697)	GS 33.625 (33.058)	mem 74.341
Train: [85][650/1500]	BT 0.038 (0.329)	DT 0.001 (0.292)	loss 6.719 (6.710)	prob 2.569 (2.660)	GS 34.156 (33.124)	mem 74.342
Train: [85][660/1500]	BT 0.026 (0.336)	DT 0.000 (0.299)	loss 6.625 (6.657)	prob 2.509 (2.544)	GS 34.734 (32.625)	mem 74.343
Train: [85][670/1500]	BT 0.037 (0.332)	DT 0.000 (0.295)	loss 6.662 (6.685)	prob 2.133 (2.482)	GS 37.812 (32.476)	mem 74.344
Train: [85][680/1500]	BT 0.026 (0.333)	DT 0.000 (0.296)	loss 6.640 (6.679)	prob 2.446 (2.479)	GS 32.141 (32.341)	mem 74.344
Train: [85][690/1500]	BT 0.037 (0.329)	DT 0.001 (0.292)	loss 6.631 (6.682)	prob 2.724 (2.551)	GS 33.594 (32.504)	mem 74.346
Train: [85][700/1500]	BT 0.037 (0.329)	DT 0.000 (0.292)	loss 6.667 (6.699)	prob 3.374 (2.571)	GS 37.562 (32.522)	mem 74.348
Train: [85][710/1500]	BT 0.037 (0.325)	DT 0.000 (0.288)	loss 6.616 (6.769)	prob 1.946 (2.481)	GS 33.047 (30.328)	mem 74.349
Train: [85][720/1500]	BT 0.037 (0.321)	DT 0.000 (0.284)	loss 6.881 (6.723)	prob 1.033 (2.415)	GS 31.938 (30.168)	mem 74.349
Train: [85][730/1500]	BT 0.037 (0.321)	DT 0.000 (0.283)	loss 6.524 (6.684)	prob 2.599 (2.378)	GS 31.953 (30.602)	mem 74.352
Train: [85][740/1500]	BT 0.058 (0.318)	DT 0.000 (0.280)	loss 6.572 (6.670)	prob 2.240 (2.404)	GS 34.547 (30.978)	mem 74.351
Train: [85][750/1500]	BT 0.037 (0.320)	DT 0.000 (0.282)	loss 6.581 (6.675)	prob 3.033 (2.444)	GS 34.969 (31.378)	mem 74.352
Train: [85][760/1500]	BT 0.030 (0.326)	DT 0.000 (0.289)	loss 6.681 (6.668)	prob 2.272 (2.222)	GS 38.203 (33.820)	mem 74.353
Train: [85][770/1500]	BT 0.029 (0.322)	DT 0.000 (0.285)	loss 6.599 (6.688)	prob 2.296 (2.311)	GS 33.781 (33.348)	mem 74.353
Train: [85][780/1500]	BT 0.026 (0.318)	DT 0.000 (0.281)	loss 6.579 (6.673)	prob 2.116 (2.369)	GS 33.812 (33.294)	mem 74.353
Train: [85][790/1500]	BT 0.037 (0.319)	DT 0.001 (0.282)	loss 6.599 (6.670)	prob 2.721 (2.414)	GS 35.547 (33.167)	mem 74.354
Train: [85][800/1500]	BT 0.037 (0.315)	DT 0.000 (0.278)	loss 6.620 (6.669)	prob 2.293 (2.406)	GS 34.219 (32.955)	mem 74.354
Train: [85][810/1500]	BT 0.037 (0.316)	DT 0.000 (0.279)	loss 6.842 (6.755)	prob 1.724 (2.302)	GS 33.875 (32.305)	mem 74.356
Train: [85][820/1500]	BT 0.037 (0.312)	DT 0.001 (0.275)	loss 6.648 (6.733)	prob 2.602 (2.415)	GS 35.828 (32.539)	mem 74.356
Train: [85][830/1500]	BT 0.037 (0.309)	DT 0.000 (0.272)	loss 6.807 (6.708)	prob 2.340 (2.418)	GS 33.297 (32.285)	mem 74.356
Train: [85][840/1500]	BT 0.034 (0.311)	DT 0.001 (0.274)	loss 6.783 (6.700)	prob 2.118 (2.376)	GS 33.484 (32.363)	mem 74.355
Train: [85][850/1500]	BT 0.047 (0.308)	DT 0.000 (0.271)	loss 6.750 (6.703)	prob 2.324 (2.379)	GS 30.641 (32.410)	mem 74.357
Train: [85][860/1500]	BT 0.034 (0.308)	DT 0.000 (0.271)	loss 6.705 (6.674)	prob 1.800 (2.484)	GS 35.219 (32.959)	mem 74.360
Train: [85][870/1500]	BT 0.037 (0.307)	DT 0.001 (0.270)	loss 6.561 (6.677)	prob 2.820 (2.499)	GS 32.094 (32.868)	mem 74.363
Train: [85][880/1500]	BT 0.039 (0.307)	DT 0.000 (0.270)	loss 6.758 (6.684)	prob 2.864 (2.475)	GS 31.766 (33.219)	mem 74.363
Train: [85][890/1500]	BT 0.141 (0.304)	DT 0.103 (0.267)	loss 6.781 (6.683)	prob 2.651 (2.433)	GS 31.797 (33.250)	mem 74.362
Train: [85][900/1500]	BT 0.034 (0.304)	DT 0.001 (0.267)	loss 6.627 (6.679)	prob 3.098 (2.429)	GS 34.969 (33.441)	mem 74.395
Train: [85][910/1500]	BT 0.039 (0.304)	DT 0.001 (0.267)	loss 6.612 (6.679)	prob 1.954 (2.424)	GS 35.312 (31.844)	mem 74.395
Train: [85][920/1500]	BT 0.038 (0.302)	DT 0.001 (0.264)	loss 6.655 (6.720)	prob 2.228 (2.380)	GS 39.750 (32.087)	mem 74.397
Train: [85][930/1500]	BT 0.039 (0.302)	DT 0.001 (0.265)	loss 6.837 (6.719)	prob 2.456 (2.376)	GS 33.359 (31.931)	mem 74.397
Train: [85][940/1500]	BT 0.039 (0.300)	DT 0.001 (0.263)	loss 6.656 (6.702)	prob 1.837 (2.327)	GS 32.078 (32.114)	mem 74.397
Train: [85][950/1500]	BT 0.024 (0.307)	DT 0.000 (0.270)	loss 6.629 (6.686)	prob 1.869 (2.347)	GS 31.750 (32.333)	mem 74.396
Train: [85][960/1500]	BT 0.028 (0.304)	DT 0.000 (0.267)	loss 6.698 (6.662)	prob 1.679 (2.029)	GS 31.859 (32.331)	mem 74.395
Train: [85][970/1500]	BT 0.037 (0.305)	DT 0.001 (0.269)	loss 6.670 (6.656)	prob 1.895 (1.949)	GS 36.047 (32.370)	mem 74.396
Train: [85][980/1500]	BT 0.029 (0.303)	DT 0.000 (0.266)	loss 6.724 (6.656)	prob 1.872 (2.020)	GS 29.625 (31.996)	mem 74.398
Train: [85][990/1500]	BT 0.038 (0.300)	DT 0.001 (0.263)	loss 6.657 (6.682)	prob 2.519 (2.113)	GS 35.891 (32.211)	mem 74.398
Train: [85][1000/1500]	BT 0.030 (0.300)	DT 0.000 (0.263)	loss 6.531 (6.670)	prob 2.368 (2.107)	GS 34.641 (32.404)	mem 74.395
Train: [85][1010/1500]	BT 0.026 (0.297)	DT 0.000 (0.261)	loss 6.871 (6.642)	prob 1.464 (1.966)	GS 34.375 (32.903)	mem 74.397
Train: [85][1020/1500]	BT 0.038 (0.299)	DT 0.001 (0.263)	loss 6.645 (6.652)	prob 2.377 (2.066)	GS 31.875 (31.991)	mem 74.399
Train: [85][1030/1500]	BT 0.039 (0.297)	DT 0.001 (0.260)	loss 6.728 (6.665)	prob 1.682 (2.023)	GS 32.516 (31.568)	mem 74.399
Train: [85][1040/1500]	BT 0.092 (0.300)	DT 0.022 (0.264)	loss 6.723 (6.660)	prob 2.119 (1.990)	GS 31.844 (31.470)	mem 74.399
Train: [85][1050/1500]	BT 0.052 (0.298)	DT 0.001 (0.261)	loss 6.699 (6.662)	prob 2.320 (2.041)	GS 35.438 (32.053)	mem 74.399
Train: [85][1060/1500]	BT 0.055 (0.296)	DT 0.005 (0.259)	loss 6.928 (6.677)	prob 1.534 (2.242)	GS 34.125 (32.952)	mem 74.399
Train: [85][1070/1500]	BT 0.033 (0.308)	DT 0.000 (0.271)	loss 6.709 (6.719)	prob 2.137 (2.162)	GS 35.266 (34.379)	mem 74.399
Train: [85][1080/1500]	BT 0.032 (0.306)	DT 0.000 (0.268)	loss 6.777 (6.705)	prob 1.808 (2.261)	GS 38.016 (33.963)	mem 74.398
Train: [85][1090/1500]	BT 0.027 (0.314)	DT 0.000 (0.277)	loss 6.896 (6.706)	prob 2.131 (2.280)	GS 31.812 (33.647)	mem 74.398
Train: [85][1100/1500]	BT 0.035 (0.312)	DT 0.000 (0.274)	loss 6.659 (6.711)	prob 2.714 (2.324)	GS 31.125 (33.356)	mem 74.401
Train: [85][1110/1500]	BT 0.026 (0.313)	DT 0.000 (0.276)	loss 6.573 (6.677)	prob 2.840 (2.513)	GS 38.281 (33.516)	mem 74.403
Train: [85][1120/1500]	BT 0.039 (0.311)	DT 0.001 (0.273)	loss 6.554 (6.643)	prob 3.463 (2.584)	GS 33.500 (32.923)	mem 74.403
Train: [85][1130/1500]	BT 0.039 (0.308)	DT 0.001 (0.271)	loss 6.651 (6.666)	prob 2.728 (2.534)	GS 34.578 (32.859)	mem 74.402
Train: [85][1140/1500]	BT 0.027 (0.309)	DT 0.000 (0.272)	loss 6.548 (6.661)	prob 3.056 (2.572)	GS 34.422 (32.876)	mem 74.401
Train: [85][1150/1500]	BT 0.029 (0.307)	DT 0.000 (0.270)	loss 6.532 (6.659)	prob 2.991 (2.555)	GS 30.594 (32.979)	mem 74.402
Train: [85][1160/1500]	BT 0.029 (0.312)	DT 0.000 (0.275)	loss 6.637 (6.635)	prob 2.832 (2.648)	GS 33.781 (32.172)	mem 74.401
Train: [85][1170/1500]	BT 0.037 (0.309)	DT 0.000 (0.272)	loss 6.734 (6.653)	prob 2.242 (2.479)	GS 35.047 (32.852)	mem 74.401
Train: [85][1180/1500]	BT 0.036 (0.311)	DT 0.000 (0.274)	loss 6.661 (6.661)	prob 2.602 (2.503)	GS 33.750 (33.218)	mem 74.409
Train: [85][1190/1500]	BT 0.036 (0.309)	DT 0.000 (0.272)	loss 6.746 (6.673)	prob 3.804 (2.600)	GS 36.250 (33.282)	mem 74.410
Train: [85][1200/1500]	BT 0.037 (0.307)	DT 0.001 (0.270)	loss 6.610 (6.684)	prob 1.827 (2.584)	GS 33.781 (33.258)	mem 74.412
Train: [85][1210/1500]	BT 0.048 (0.309)	DT 0.006 (0.272)	loss 6.848 (6.690)	prob 2.437 (2.699)	GS 34.891 (32.708)	mem 74.422
Train: [85][1220/1500]	BT 0.047 (0.307)	DT 0.000 (0.270)	loss 6.733 (6.710)	prob 2.723 (2.629)	GS 33.766 (33.350)	mem 74.422
Train: [85][1230/1500]	BT 0.040 (0.312)	DT 0.010 (0.275)	loss 6.581 (6.714)	prob 2.926 (2.592)	GS 35.016 (33.304)	mem 74.422
Train: [85][1240/1500]	BT 0.021 (0.318)	DT 0.000 (0.281)	loss 6.803 (6.706)	prob 2.053 (2.561)	GS 37.266 (33.529)	mem 74.421
Train: [85][1250/1500]	BT 0.029 (0.315)	DT 0.000 (0.278)	loss 6.621 (6.702)	prob 3.021 (2.567)	GS 30.406 (33.362)	mem 74.422
Train: [85][1260/1500]	BT 0.036 (0.313)	DT 0.000 (0.276)	loss 6.819 (6.698)	prob 2.758 (2.902)	GS 35.906 (32.322)	mem 74.422
Train: [85][1270/1500]	BT 0.035 (0.314)	DT 0.000 (0.277)	loss 6.720 (6.667)	prob 2.691 (2.807)	GS 34.625 (32.212)	mem 74.322
Train: [85][1280/1500]	BT 0.027 (0.312)	DT 0.000 (0.275)	loss 6.582 (6.680)	prob 2.089 (2.840)	GS 30.125 (32.246)	mem 74.323
Train: [85][1290/1500]	BT 0.035 (0.312)	DT 0.001 (0.275)	loss 6.910 (6.682)	prob 2.404 (2.799)	GS 31.562 (32.226)	mem 74.323
Train: [85][1300/1500]	BT 0.037 (0.310)	DT 0.000 (0.273)	loss 6.666 (6.676)	prob 2.925 (2.801)	GS 34.266 (32.102)	mem 74.324
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [85][1310/1500]	BT 0.037 (0.308)	DT 0.000 (0.271)	loss 6.756 (6.654)	prob 1.606 (2.411)	GS 31.250 (31.161)	mem 74.325
Train: [85][1320/1500]	BT 0.031 (0.308)	DT 0.000 (0.272)	loss 6.762 (6.675)	prob 1.731 (2.652)	GS 37.484 (32.224)	mem 74.325
Train: [85][1330/1500]	BT 0.025 (0.314)	DT 0.001 (0.277)	loss 6.544 (6.672)	prob 2.175 (2.592)	GS 30.625 (32.616)	mem 74.323
Train: [85][1340/1500]	BT 0.024 (0.312)	DT 0.000 (0.275)	loss 6.651 (6.686)	prob 3.479 (2.711)	GS 32.562 (32.796)	mem 74.323
Train: [85][1350/1500]	BT 0.033 (0.310)	DT 0.000 (0.273)	loss 6.830 (6.689)	prob 2.213 (2.685)	GS 35.406 (32.613)	mem 74.324
Train: [85][1360/1500]	BT 0.022 (0.311)	DT 0.000 (0.275)	loss 6.716 (6.650)	prob 2.665 (2.621)	GS 36.609 (32.355)	mem 74.342
Train: [85][1370/1500]	BT 0.047 (0.309)	DT 0.000 (0.273)	loss 6.556 (6.675)	prob 2.475 (2.657)	GS 34.578 (33.694)	mem 74.343
Train: [85][1380/1500]	BT 0.031 (0.310)	DT 0.000 (0.274)	loss 6.626 (6.675)	prob 2.984 (2.694)	GS 32.891 (33.349)	mem 74.333
Train: [85][1390/1500]	BT 0.041 (0.308)	DT 0.001 (0.272)	loss 6.789 (6.677)	prob 2.752 (2.667)	GS 37.312 (33.011)	mem 74.335
Train: [85][1400/1500]	BT 0.040 (0.306)	DT 0.001 (0.270)	loss 6.619 (6.670)	prob 3.313 (2.735)	GS 35.062 (32.888)	mem 74.335
Train: [85][1410/1500]	BT 0.025 (0.307)	DT 0.000 (0.271)	loss 6.578 (6.715)	prob 2.852 (2.891)	GS 33.750 (33.634)	mem 74.337
Train: [85][1420/1500]	BT 0.039 (0.305)	DT 0.001 (0.269)	loss 6.724 (6.687)	prob 2.105 (2.734)	GS 32.750 (33.062)	mem 74.338
Train: [85][1430/1500]	BT 0.030 (0.306)	DT 0.001 (0.270)	loss 6.715 (6.673)	prob 2.717 (2.689)	GS 35.906 (32.712)	mem 74.338
Train: [85][1440/1500]	BT 0.040 (0.304)	DT 0.001 (0.268)	loss 6.773 (6.679)	prob 2.767 (2.673)	GS 34.297 (33.115)	mem 74.339
Train: [85][1450/1500]	BT 0.029 (0.305)	DT 0.000 (0.269)	loss 6.576 (6.674)	prob 2.773 (2.670)	GS 35.391 (33.108)	mem 73.828
Train: [85][1460/1500]	BT 0.031 (0.303)	DT 0.000 (0.267)	loss 6.810 (6.686)	prob 1.959 (2.475)	GS 35.125 (32.131)	mem 73.829
Train: [85][1470/1500]	BT 0.029 (0.302)	DT 0.000 (0.265)	loss 6.467 (6.667)	prob 2.949 (2.577)	GS 25.422 (32.356)	mem 73.757
Train: [85][1480/1500]	BT 0.027 (0.302)	DT 0.000 (0.265)	loss 6.689 (6.643)	prob 2.250 (2.491)	GS 29.531 (32.140)	mem 14.999
Train: [85][1490/1500]	BT 0.025 (0.300)	DT 0.000 (0.264)	loss 6.503 (6.638)	prob 2.387 (2.541)	GS 37.125 (32.007)	mem 14.999
Train: [85][1500/1500]	BT 0.037 (0.299)	DT 0.000 (0.263)	loss 6.409 (6.626)	prob 3.233 (2.577)	GS 36.031 (32.128)	mem 9.272
Train: [85][1510/1500]	BT 0.037 (0.297)	DT 0.000 (0.261)	loss 6.491 (6.475)	prob 2.604 (2.532)	GS 31.094 (33.013)	mem 9.272
epoch 85, total time 448.53
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [86][1/1500]	BT 17.807 (17.807)	DT 17.751 (17.751)	loss 6.358 (6.358)	prob 2.143 (2.143)	GS 32.391 (32.391)	mem 72.839
Train: [86][10/1500]	BT 0.038 (2.181)	DT 0.001 (2.142)	loss 6.474 (6.377)	prob 3.160 (2.982)	GS 35.891 (33.594)	mem 73.533
Train: [86][20/1500]	BT 0.038 (1.155)	DT 0.001 (1.118)	loss 6.421 (6.432)	prob 2.809 (2.857)	GS 35.312 (33.525)	mem 73.595
Train: [86][30/1500]	BT 0.037 (0.875)	DT 0.000 (0.838)	loss 6.565 (6.479)	prob 2.757 (2.784)	GS 32.562 (33.076)	mem 74.241
Train: [86][40/1500]	BT 1.487 (0.717)	DT 1.459 (0.680)	loss 6.647 (6.511)	prob 2.956 (2.747)	GS 35.156 (32.490)	mem 74.261
Train: [86][50/1500]	BT 3.009 (0.640)	DT 2.971 (0.604)	loss 6.864 (6.538)	prob 2.470 (2.727)	GS 38.312 (32.571)	mem 74.265
Train: [86][60/1500]	BT 0.038 (0.539)	DT 0.001 (0.503)	loss 6.534 (6.564)	prob 2.407 (2.704)	GS 33.281 (32.717)	mem 74.266
Train: [86][70/1500]	BT 0.065 (0.498)	DT 0.008 (0.460)	loss 6.677 (6.574)	prob 2.358 (2.572)	GS 32.844 (32.605)	mem 74.287
Train: [86][80/1500]	BT 0.038 (0.457)	DT 0.001 (0.418)	loss 6.621 (6.606)	prob 2.095 (2.618)	GS 37.391 (33.236)	mem 74.288
Train: [86][90/1500]	BT 0.037 (0.444)	DT 0.000 (0.406)	loss 6.704 (6.613)	prob 2.370 (2.649)	GS 37.812 (33.186)	mem 74.300
Train: [86][100/1500]	BT 0.037 (0.409)	DT 0.001 (0.371)	loss 6.768 (6.621)	prob 2.283 (2.587)	GS 39.234 (33.453)	mem 74.301
Train: [86][110/1500]	BT 0.037 (0.389)	DT 0.000 (0.351)	loss 6.631 (6.638)	prob 2.172 (2.320)	GS 34.641 (32.209)	mem 74.313
Train: [86][120/1500]	BT 0.037 (0.377)	DT 0.001 (0.339)	loss 6.436 (6.645)	prob 2.652 (2.324)	GS 34.281 (32.294)	mem 74.315
Train: [86][130/1500]	BT 0.028 (0.356)	DT 0.000 (0.318)	loss 6.534 (6.628)	prob 2.141 (2.365)	GS 36.453 (32.531)	mem 74.317
Train: [86][140/1500]	BT 0.037 (0.362)	DT 0.000 (0.324)	loss 6.619 (6.618)	prob 2.063 (2.373)	GS 34.500 (32.532)	mem 74.321
Train: [86][150/1500]	BT 0.039 (0.352)	DT 0.001 (0.314)	loss 6.654 (6.624)	prob 2.710 (2.397)	GS 34.359 (32.572)	mem 74.323
Train: [86][160/1500]	BT 4.848 (0.374)	DT 4.816 (0.337)	loss 6.751 (6.653)	prob 2.648 (2.561)	GS 37.797 (33.700)	mem 74.326
Train: [86][170/1500]	BT 0.031 (0.354)	DT 0.000 (0.317)	loss 6.494 (6.661)	prob 2.856 (2.505)	GS 34.453 (33.675)	mem 74.327
Train: [86][180/1500]	BT 0.048 (0.337)	DT 0.000 (0.300)	loss 6.434 (6.641)	prob 2.706 (2.450)	GS 37.641 (33.333)	mem 74.327
Train: [86][190/1500]	BT 0.069 (0.359)	DT 0.012 (0.321)	loss 6.680 (6.633)	prob 2.339 (2.446)	GS 31.250 (33.242)	mem 74.328
Train: [86][200/1500]	BT 0.030 (0.397)	DT 0.000 (0.359)	loss 6.570 (6.633)	prob 2.616 (2.482)	GS 34.703 (33.270)	mem 74.335
Train: [86][210/1500]	BT 0.025 (0.379)	DT 0.000 (0.342)	loss 6.778 (6.677)	prob 2.101 (2.388)	GS 32.859 (32.834)	mem 74.336
Train: [86][220/1500]	BT 0.035 (0.376)	DT 0.001 (0.339)	loss 6.641 (6.671)	prob 2.703 (2.456)	GS 31.688 (33.421)	mem 74.369
Train: [86][230/1500]	BT 0.039 (0.361)	DT 0.001 (0.324)	loss 6.694 (6.660)	prob 2.566 (2.551)	GS 35.016 (33.180)	mem 74.370
Train: [86][240/1500]	BT 0.039 (0.348)	DT 0.001 (0.311)	loss 6.703 (6.655)	prob 2.193 (2.546)	GS 34.750 (33.225)	mem 74.369
Train: [86][250/1500]	BT 0.039 (0.347)	DT 0.001 (0.310)	loss 6.537 (6.646)	prob 2.553 (2.535)	GS 34.781 (32.958)	mem 74.370
Train: [86][260/1500]	BT 0.039 (0.335)	DT 0.001 (0.298)	loss 6.964 (6.682)	prob 2.413 (2.742)	GS 33.609 (33.456)	mem 74.370
Train: [86][270/1500]	BT 0.031 (0.352)	DT 0.001 (0.315)	loss 6.956 (6.653)	prob 1.810 (2.544)	GS 31.734 (33.212)	mem 74.374
Train: [86][280/1500]	BT 0.039 (0.340)	DT 0.001 (0.304)	loss 6.793 (6.659)	prob 2.887 (2.557)	GS 31.750 (32.910)	mem 74.375
Train: [86][290/1500]	BT 0.834 (0.334)	DT 0.796 (0.297)	loss 6.589 (6.649)	prob 2.237 (2.550)	GS 31.859 (32.636)	mem 74.373
Train: [86][300/1500]	BT 0.038 (0.334)	DT 0.001 (0.297)	loss 6.621 (6.648)	prob 2.667 (2.543)	GS 33.453 (32.787)	mem 74.374
Train: [86][310/1500]	BT 0.040 (0.324)	DT 0.001 (0.287)	loss 6.716 (6.702)	prob 2.273 (2.569)	GS 29.875 (32.667)	mem 74.375
Train: [86][320/1500]	BT 0.035 (0.331)	DT 0.000 (0.294)	loss 6.632 (6.664)	prob 2.119 (2.444)	GS 35.859 (33.035)	mem 74.378
Train: [86][330/1500]	BT 0.064 (0.323)	DT 0.002 (0.285)	loss 6.641 (6.652)	prob 2.703 (2.472)	GS 33.875 (32.780)	mem 74.377
Train: [86][340/1500]	BT 0.117 (0.335)	DT 0.014 (0.297)	loss 6.609 (6.665)	prob 1.671 (2.395)	GS 34.250 (32.885)	mem 74.380
Train: [86][350/1500]	BT 6.860 (0.358)	DT 6.817 (0.319)	loss 6.891 (6.664)	prob 2.239 (2.451)	GS 36.531 (33.073)	mem 74.382
Train: [86][360/1500]	BT 0.030 (0.349)	DT 0.000 (0.311)	loss 6.512 (6.655)	prob 2.764 (2.522)	GS 32.406 (33.191)	mem 74.382
Train: [86][370/1500]	BT 0.038 (0.340)	DT 0.001 (0.302)	loss 6.581 (6.631)	prob 2.127 (2.373)	GS 33.172 (33.483)	mem 74.382
Train: [86][380/1500]	BT 0.031 (0.344)	DT 0.000 (0.306)	loss 6.665 (6.633)	prob 2.302 (2.347)	GS 31.797 (33.259)	mem 74.382
Train: [86][390/1500]	BT 0.039 (0.336)	DT 0.001 (0.298)	loss 6.663 (6.634)	prob 2.236 (2.330)	GS 38.203 (33.425)	mem 74.385
Train: [86][400/1500]	BT 0.038 (0.339)	DT 0.001 (0.301)	loss 6.641 (6.637)	prob 1.567 (2.295)	GS 37.438 (33.445)	mem 74.385
Train: [86][410/1500]	BT 0.039 (0.332)	DT 0.001 (0.293)	loss 6.591 (6.615)	prob 2.537 (2.492)	GS 35.109 (33.789)	mem 74.385
Train: [86][420/1500]	BT 0.039 (0.325)	DT 0.001 (0.286)	loss 6.715 (6.649)	prob 2.332 (2.424)	GS 35.391 (32.896)	mem 74.385
Train: [86][430/1500]	BT 0.029 (0.327)	DT 0.000 (0.289)	loss 6.499 (6.632)	prob 2.401 (2.442)	GS 34.234 (32.460)	mem 74.385
Train: [86][440/1500]	BT 0.039 (0.320)	DT 0.001 (0.282)	loss 6.581 (6.633)	prob 2.488 (2.365)	GS 37.125 (32.771)	mem 74.385
Train: [86][450/1500]	BT 0.039 (0.320)	DT 0.001 (0.282)	loss 6.517 (6.645)	prob 2.371 (2.335)	GS 33.906 (32.847)	mem 74.384
Train: [86][460/1500]	BT 0.039 (0.314)	DT 0.001 (0.276)	loss 6.626 (6.683)	prob 2.447 (2.093)	GS 36.016 (33.658)	mem 74.384
Train: [86][470/1500]	BT 2.757 (0.314)	DT 2.717 (0.276)	loss 6.635 (6.650)	prob 2.039 (2.129)	GS 34.422 (32.570)	mem 74.384
Train: [86][480/1500]	BT 0.023 (0.328)	DT 0.001 (0.290)	loss 6.835 (6.624)	prob 1.749 (2.192)	GS 31.672 (33.182)	mem 74.408
Train: [86][490/1500]	BT 0.025 (0.322)	DT 0.000 (0.284)	loss 6.609 (6.624)	prob 2.489 (2.238)	GS 29.984 (33.048)	mem 74.409
Train: [86][500/1500]	BT 0.028 (0.316)	DT 0.000 (0.278)	loss 6.489 (6.629)	prob 2.020 (2.246)	GS 35.219 (32.889)	mem 74.410
Train: [86][510/1500]	BT 0.037 (0.316)	DT 0.001 (0.279)	loss 6.641 (6.632)	prob 2.085 (1.976)	GS 34.203 (32.928)	mem 74.300
Train: [86][520/1500]	BT 0.053 (0.311)	DT 0.001 (0.273)	loss 6.554 (6.640)	prob 2.680 (2.178)	GS 34.203 (33.128)	mem 74.310
Train: [86][530/1500]	BT 0.064 (0.314)	DT 0.013 (0.277)	loss 6.658 (6.647)	prob 1.931 (2.246)	GS 32.141 (32.942)	mem 74.308
Train: [86][540/1500]	BT 0.066 (0.310)	DT 0.011 (0.272)	loss 6.535 (6.638)	prob 2.263 (2.215)	GS 30.641 (32.831)	mem 74.307
Train: [86][550/1500]	BT 0.036 (0.311)	DT 0.001 (0.273)	loss 6.806 (6.652)	prob 2.642 (2.292)	GS 35.406 (33.109)	mem 74.311
Train: [86][560/1500]	BT 0.037 (0.309)	DT 0.001 (0.271)	loss 6.582 (6.595)	prob 2.292 (2.678)	GS 30.844 (33.069)	mem 74.310
Train: [86][570/1500]	BT 0.065 (0.304)	DT 0.000 (0.266)	loss 6.673 (6.623)	prob 2.654 (2.351)	GS 36.141 (33.031)	mem 74.311
Train: [86][580/1500]	BT 0.027 (0.309)	DT 0.000 (0.271)	loss 6.743 (6.624)	prob 2.093 (2.328)	GS 30.609 (32.834)	mem 74.314
Train: [86][590/1500]	BT 0.038 (0.304)	DT 0.001 (0.267)	loss 6.603 (6.622)	prob 3.369 (2.423)	GS 30.359 (33.062)	mem 74.331
Train: [86][600/1500]	BT 0.036 (0.308)	DT 0.001 (0.271)	loss 6.499 (6.623)	prob 3.164 (2.389)	GS 34.688 (33.056)	mem 74.335
Train: [86][610/1500]	BT 0.027 (0.315)	DT 0.000 (0.277)	loss 6.564 (6.558)	prob 2.265 (2.198)	GS 35.078 (31.627)	mem 74.338
Train: [86][620/1500]	BT 0.027 (0.310)	DT 0.000 (0.272)	loss 6.589 (6.574)	prob 3.191 (2.410)	GS 38.141 (32.498)	mem 74.325
Train: [86][630/1500]	BT 0.038 (0.306)	DT 0.001 (0.268)	loss 6.640 (6.594)	prob 2.337 (2.459)	GS 31.375 (32.201)	mem 74.327
Train: [86][640/1500]	BT 0.038 (0.306)	DT 0.001 (0.268)	loss 6.929 (6.621)	prob 1.802 (2.390)	GS 31.984 (32.218)	mem 74.329
Train: [86][650/1500]	BT 0.074 (0.303)	DT 0.005 (0.266)	loss 6.532 (6.620)	prob 2.114 (2.383)	GS 31.656 (32.380)	mem 74.331
Train: [86][660/1500]	BT 0.038 (0.302)	DT 0.001 (0.264)	loss 6.779 (6.628)	prob 1.751 (2.262)	GS 36.641 (32.492)	mem 74.330
Train: [86][670/1500]	BT 0.039 (0.301)	DT 0.001 (0.263)	loss 6.551 (6.629)	prob 2.747 (2.357)	GS 33.516 (32.206)	mem 74.330
Train: [86][680/1500]	BT 0.039 (0.297)	DT 0.001 (0.259)	loss 6.594 (6.632)	prob 2.088 (2.315)	GS 30.297 (31.717)	mem 74.330
Train: [86][690/1500]	BT 0.030 (0.306)	DT 0.000 (0.268)	loss 6.639 (6.624)	prob 2.883 (2.359)	GS 29.750 (32.114)	mem 74.330
Train: [86][700/1500]	BT 0.040 (0.302)	DT 0.001 (0.264)	loss 6.561 (6.615)	prob 2.251 (2.307)	GS 35.172 (32.090)	mem 74.330
Train: [86][710/1500]	BT 0.039 (0.302)	DT 0.001 (0.265)	loss 6.574 (6.573)	prob 2.545 (2.375)	GS 31.234 (30.520)	mem 74.331
Train: [86][720/1500]	BT 0.039 (0.299)	DT 0.001 (0.261)	loss 6.604 (6.576)	prob 2.369 (2.344)	GS 33.312 (31.337)	mem 74.331
Train: [86][730/1500]	BT 0.038 (0.305)	DT 0.001 (0.267)	loss 6.440 (6.567)	prob 2.102 (2.310)	GS 30.875 (31.131)	mem 74.330
Train: [86][740/1500]	BT 0.053 (0.302)	DT 0.006 (0.264)	loss 6.588 (6.578)	prob 3.220 (2.360)	GS 31.094 (31.269)	mem 74.331
Train: [86][750/1500]	BT 0.040 (0.299)	DT 0.001 (0.261)	loss 6.655 (6.579)	prob 2.476 (2.322)	GS 35.031 (31.421)	mem 74.333
Train: [86][760/1500]	BT 0.037 (0.298)	DT 0.000 (0.260)	loss 6.562 (6.573)	prob 2.205 (2.396)	GS 35.875 (33.839)	mem 74.350
Train: [86][770/1500]	BT 0.038 (0.296)	DT 0.001 (0.258)	loss 6.571 (6.583)	prob 2.134 (2.344)	GS 32.172 (32.325)	mem 74.351
Train: [86][780/1500]	BT 0.047 (0.300)	DT 0.014 (0.262)	loss 6.486 (6.575)	prob 2.548 (2.283)	GS 37.031 (32.354)	mem 74.350
Train: [86][790/1500]	BT 0.037 (0.298)	DT 0.001 (0.260)	loss 6.658 (6.579)	prob 2.271 (2.246)	GS 28.484 (32.166)	mem 74.353
Train: [86][800/1500]	BT 0.036 (0.295)	DT 0.001 (0.257)	loss 6.640 (6.580)	prob 2.826 (2.239)	GS 36.984 (32.016)	mem 74.353
Train: [86][810/1500]	BT 0.061 (0.297)	DT 0.006 (0.259)	loss 6.487 (6.513)	prob 3.026 (2.314)	GS 33.062 (32.684)	mem 74.357
Train: [86][820/1500]	BT 0.058 (0.294)	DT 0.011 (0.256)	loss 6.559 (6.537)	prob 2.737 (2.379)	GS 27.781 (32.138)	mem 74.357
Train: [86][830/1500]	BT 0.029 (0.305)	DT 0.000 (0.267)	loss 6.531 (6.541)	prob 2.311 (2.395)	GS 27.969 (32.252)	mem 74.355
Train: [86][840/1500]	BT 0.030 (0.301)	DT 0.000 (0.264)	loss 6.510 (6.533)	prob 2.978 (2.464)	GS 29.969 (32.136)	mem 74.355
Train: [86][850/1500]	BT 0.024 (0.298)	DT 0.000 (0.261)	loss 6.665 (6.539)	prob 2.399 (2.447)	GS 32.797 (32.400)	mem 74.356
Train: [86][860/1500]	BT 0.027 (0.300)	DT 0.000 (0.263)	loss 6.609 (6.540)	prob 2.797 (3.102)	GS 33.734 (34.214)	mem 74.363
Train: [86][870/1500]	BT 0.027 (0.297)	DT 0.000 (0.260)	loss 6.614 (6.561)	prob 2.098 (2.842)	GS 35.562 (33.182)	mem 74.363
Train: [86][880/1500]	BT 0.037 (0.298)	DT 0.000 (0.261)	loss 6.936 (6.581)	prob 2.489 (2.752)	GS 31.422 (33.161)	mem 74.366
Train: [86][890/1500]	BT 0.030 (0.295)	DT 0.000 (0.258)	loss 6.773 (6.595)	prob 2.842 (2.741)	GS 29.578 (33.204)	mem 74.366
Train: [86][900/1500]	BT 0.037 (0.297)	DT 0.001 (0.260)	loss 6.476 (6.591)	prob 2.028 (2.682)	GS 32.391 (33.108)	mem 74.363
Train: [86][910/1500]	BT 0.034 (0.294)	DT 0.000 (0.257)	loss 6.407 (6.561)	prob 2.472 (2.561)	GS 33.891 (33.880)	mem 74.365
Train: [86][920/1500]	BT 0.048 (0.294)	DT 0.003 (0.257)	loss 6.620 (6.571)	prob 2.957 (2.577)	GS 31.688 (33.227)	mem 74.364
Train: [86][930/1500]	BT 0.027 (0.305)	DT 0.000 (0.267)	loss 6.635 (6.592)	prob 2.146 (2.549)	GS 35.328 (34.026)	mem 74.365
Train: [86][940/1500]	BT 0.034 (0.302)	DT 0.000 (0.264)	loss 6.614 (6.597)	prob 3.124 (2.612)	GS 32.781 (33.541)	mem 74.365
Train: [86][950/1500]	BT 0.038 (0.303)	DT 0.000 (0.266)	loss 6.707 (6.602)	prob 3.050 (2.607)	GS 30.844 (33.293)	mem 74.368
Train: [86][960/1500]	BT 0.038 (0.300)	DT 0.000 (0.263)	loss 6.707 (6.666)	prob 2.770 (2.774)	GS 37.125 (33.259)	mem 74.368
Train: [86][970/1500]	BT 0.028 (0.297)	DT 0.000 (0.260)	loss 6.676 (6.648)	prob 2.421 (2.875)	GS 32.984 (33.561)	mem 74.368
Train: [86][980/1500]	BT 0.063 (0.298)	DT 0.005 (0.261)	loss 6.639 (6.644)	prob 2.558 (2.777)	GS 35.312 (33.044)	mem 74.371
Train: [86][990/1500]	BT 0.059 (0.295)	DT 0.015 (0.258)	loss 6.531 (6.652)	prob 3.027 (2.694)	GS 33.766 (33.251)	mem 74.372
Train: [86][1000/1500]	BT 0.028 (0.301)	DT 0.000 (0.264)	loss 6.575 (6.660)	prob 2.814 (2.723)	GS 34.094 (33.477)	mem 74.371
Train: [86][1010/1500]	BT 0.037 (0.299)	DT 0.001 (0.262)	loss 6.800 (6.619)	prob 2.344 (2.803)	GS 32.719 (32.139)	mem 74.372
Train: [86][1020/1500]	BT 0.037 (0.302)	DT 0.000 (0.265)	loss 6.951 (6.630)	prob 2.715 (2.918)	GS 29.516 (32.840)	mem 74.371
Train: [86][1030/1500]	BT 0.037 (0.300)	DT 0.001 (0.263)	loss 6.600 (6.627)	prob 2.123 (2.919)	GS 32.562 (32.727)	mem 74.371
Train: [86][1040/1500]	BT 0.031 (0.302)	DT 0.000 (0.265)	loss 6.532 (6.624)	prob 2.338 (2.879)	GS 31.109 (32.418)	mem 74.371
Train: [86][1050/1500]	BT 0.025 (0.299)	DT 0.000 (0.262)	loss 6.465 (6.624)	prob 3.370 (2.793)	GS 33.172 (32.150)	mem 74.371
Train: [86][1060/1500]	BT 0.038 (0.297)	DT 0.001 (0.260)	loss 6.566 (6.673)	prob 2.646 (2.544)	GS 36.891 (31.728)	mem 74.372
Train: [86][1070/1500]	BT 0.024 (0.298)	DT 0.000 (0.261)	loss 6.545 (6.657)	prob 2.049 (2.643)	GS 34.359 (32.406)	mem 74.373
Train: [86][1080/1500]	BT 0.024 (0.296)	DT 0.000 (0.259)	loss 6.532 (6.640)	prob 2.751 (2.591)	GS 36.047 (32.529)	mem 74.372
Train: [86][1090/1500]	BT 0.030 (0.299)	DT 0.000 (0.262)	loss 6.730 (6.634)	prob 2.293 (2.709)	GS 32.031 (32.513)	mem 74.374
Train: [86][1100/1500]	BT 0.025 (0.296)	DT 0.000 (0.260)	loss 6.673 (6.630)	prob 1.750 (2.695)	GS 32.969 (32.458)	mem 74.374
Train: [86][1110/1500]	BT 0.038 (0.294)	DT 0.000 (0.257)	loss 6.660 (6.667)	prob 2.571 (2.497)	GS 33.531 (32.873)	mem 74.374
Train: [86][1120/1500]	BT 0.026 (0.297)	DT 0.000 (0.260)	loss 6.640 (6.670)	prob 2.114 (2.663)	GS 35.094 (33.170)	mem 74.379
Train: [86][1130/1500]	BT 0.037 (0.294)	DT 0.001 (0.258)	loss 6.732 (6.659)	prob 2.297 (2.539)	GS 36.359 (33.230)	mem 74.383
Train: [86][1140/1500]	BT 0.033 (0.301)	DT 0.001 (0.265)	loss 7.139 (6.676)	prob 2.813 (2.619)	GS 30.312 (33.237)	mem 74.408
Train: [86][1150/1500]	BT 0.031 (0.299)	DT 0.000 (0.263)	loss 6.594 (6.670)	prob 3.517 (2.716)	GS 34.953 (32.971)	mem 74.408
Train: [86][1160/1500]	BT 0.038 (0.297)	DT 0.001 (0.260)	loss 6.731 (6.637)	prob 2.143 (2.891)	GS 38.656 (33.461)	mem 74.409
Train: [86][1170/1500]	BT 0.039 (0.297)	DT 0.001 (0.261)	loss 6.664 (6.643)	prob 2.568 (2.851)	GS 30.938 (33.027)	mem 74.409
Train: [86][1180/1500]	BT 0.039 (0.295)	DT 0.001 (0.259)	loss 6.594 (6.651)	prob 2.587 (2.814)	GS 33.984 (32.680)	mem 74.408
Train: [86][1190/1500]	BT 0.030 (0.297)	DT 0.000 (0.260)	loss 6.550 (6.653)	prob 2.420 (2.802)	GS 36.656 (33.049)	mem 74.409
Train: [86][1200/1500]	BT 0.039 (0.294)	DT 0.001 (0.258)	loss 6.531 (6.645)	prob 2.825 (2.812)	GS 33.891 (32.880)	mem 74.409
Train: [86][1210/1500]	BT 0.036 (0.296)	DT 0.000 (0.260)	loss 6.712 (6.639)	prob 2.536 (2.655)	GS 31.953 (32.652)	mem 74.409
Train: [86][1220/1500]	BT 0.030 (0.294)	DT 0.000 (0.258)	loss 6.658 (6.648)	prob 2.861 (2.703)	GS 29.875 (33.127)	mem 74.410
Train: [86][1230/1500]	BT 0.030 (0.292)	DT 0.000 (0.256)	loss 6.852 (6.680)	prob 3.267 (2.623)	GS 39.047 (33.621)	mem 74.409
Train: [86][1240/1500]	BT 0.039 (0.293)	DT 0.000 (0.257)	loss 6.754 (6.689)	prob 3.012 (2.659)	GS 32.750 (33.422)	mem 74.412
Train: [86][1250/1500]	BT 0.040 (0.291)	DT 0.001 (0.255)	loss 6.632 (6.691)	prob 2.673 (2.646)	GS 33.969 (33.473)	mem 74.412
Train: [86][1260/1500]	BT 0.038 (0.292)	DT 0.001 (0.256)	loss 6.678 (6.684)	prob 2.361 (2.441)	GS 35.234 (32.059)	mem 74.411
Train: [86][1270/1500]	BT 0.039 (0.290)	DT 0.001 (0.254)	loss 6.652 (6.678)	prob 3.282 (2.502)	GS 34.203 (32.073)	mem 74.412
Train: [86][1280/1500]	BT 0.029 (0.288)	DT 0.000 (0.252)	loss 6.649 (6.685)	prob 3.680 (2.619)	GS 36.344 (32.259)	mem 74.411
Train: [86][1290/1500]	BT 0.040 (0.289)	DT 0.001 (0.252)	loss 6.625 (6.682)	prob 2.289 (2.562)	GS 32.812 (32.059)	mem 74.412
Train: [86][1300/1500]	BT 0.039 (0.287)	DT 0.001 (0.251)	loss 6.604 (6.681)	prob 2.765 (2.510)	GS 29.750 (32.218)	mem 74.413
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [86][1310/1500]	BT 0.037 (0.287)	DT 0.001 (0.251)	loss 6.529 (6.618)	prob 2.972 (2.468)	GS 34.531 (31.825)	mem 74.415
Train: [86][1320/1500]	BT 0.037 (0.285)	DT 0.000 (0.249)	loss 6.672 (6.635)	prob 2.333 (2.462)	GS 35.609 (31.975)	mem 74.416
Train: [86][1330/1500]	BT 0.914 (0.287)	DT 0.877 (0.251)	loss 6.607 (6.639)	prob 2.444 (2.590)	GS 35.656 (32.381)	mem 74.429
Train: [86][1340/1500]	BT 0.038 (0.285)	DT 0.001 (0.249)	loss 6.626 (6.643)	prob 2.569 (2.616)	GS 33.453 (32.395)	mem 74.430
Train: [86][1350/1500]	BT 0.038 (0.283)	DT 0.001 (0.247)	loss 6.777 (6.652)	prob 3.225 (2.609)	GS 29.734 (32.419)	mem 74.429
Train: [86][1360/1500]	BT 0.068 (0.287)	DT 0.011 (0.250)	loss 6.755 (6.692)	prob 2.471 (2.787)	GS 36.812 (32.450)	mem 74.430
Train: [86][1370/1500]	BT 0.030 (0.292)	DT 0.000 (0.256)	loss 6.756 (6.680)	prob 2.533 (2.751)	GS 33.062 (32.903)	mem 74.430
Train: [86][1380/1500]	BT 0.025 (0.291)	DT 0.000 (0.254)	loss 6.643 (6.657)	prob 2.011 (2.553)	GS 34.516 (32.560)	mem 74.448
Train: [86][1390/1500]	BT 0.037 (0.291)	DT 0.001 (0.254)	loss 6.684 (6.649)	prob 2.029 (2.541)	GS 36.781 (32.472)	mem 74.330
Train: [86][1400/1500]	BT 0.038 (0.289)	DT 0.000 (0.253)	loss 6.747 (6.648)	prob 2.043 (2.549)	GS 35.562 (32.510)	mem 74.329
Train: [86][1410/1500]	BT 0.037 (0.287)	DT 0.001 (0.251)	loss 6.549 (6.648)	prob 1.996 (2.309)	GS 34.703 (32.839)	mem 74.329
Train: [86][1420/1500]	BT 0.037 (0.287)	DT 0.001 (0.251)	loss 6.706 (6.660)	prob 2.135 (2.196)	GS 34.672 (32.823)	mem 74.329
Train: [86][1430/1500]	BT 0.037 (0.285)	DT 0.001 (0.249)	loss 6.529 (6.664)	prob 2.317 (2.150)	GS 30.562 (32.701)	mem 74.329
Train: [86][1440/1500]	BT 0.069 (0.286)	DT 0.015 (0.250)	loss 6.983 (6.663)	prob 1.420 (2.173)	GS 36.188 (32.833)	mem 74.329
Train: [86][1450/1500]	BT 0.026 (0.289)	DT 0.000 (0.252)	loss 6.959 (6.669)	prob 2.319 (2.198)	GS 38.094 (33.006)	mem 74.256
Train: [86][1460/1500]	BT 0.038 (0.287)	DT 0.001 (0.251)	loss 6.700 (6.666)	prob 2.118 (2.462)	GS 30.078 (30.902)	mem 74.257
Train: [86][1470/1500]	BT 0.025 (0.288)	DT 0.000 (0.251)	loss 6.698 (6.671)	prob 2.877 (2.391)	GS 34.859 (32.129)	mem 29.721
Train: [86][1480/1500]	BT 0.028 (0.286)	DT 0.001 (0.249)	loss 6.696 (6.659)	prob 1.892 (2.293)	GS 34.828 (32.064)	mem 26.152
Train: [86][1490/1500]	BT 0.023 (0.284)	DT 0.000 (0.248)	loss 6.640 (6.646)	prob 2.436 (2.280)	GS 31.438 (32.227)	mem 26.041
Train: [86][1500/1500]	BT 0.026 (0.283)	DT 0.000 (0.247)	loss 6.626 (6.642)	prob 2.113 (2.245)	GS 45.344 (32.299)	mem 9.261
Train: [86][1510/1500]	BT 0.034 (0.281)	DT 0.000 (0.245)	loss 6.760 (6.479)	prob 1.645 (2.315)	GS 35.656 (33.737)	mem 9.261
epoch 86, total time 424.95
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [87][1/1500]	BT 27.349 (27.349)	DT 27.308 (27.308)	loss 6.428 (6.428)	prob 1.995 (1.995)	GS 38.312 (38.312)	mem 73.113
Train: [87][10/1500]	BT 0.036 (2.765)	DT 0.001 (2.731)	loss 6.304 (6.388)	prob 2.865 (2.271)	GS 28.406 (31.333)	mem 73.125
Train: [87][20/1500]	BT 0.029 (1.399)	DT 0.000 (1.366)	loss 6.530 (6.414)	prob 1.949 (2.226)	GS 34.703 (32.332)	mem 73.127
Train: [87][30/1500]	BT 0.039 (1.040)	DT 0.001 (1.006)	loss 6.519 (6.451)	prob 3.222 (2.342)	GS 33.938 (32.415)	mem 73.474
Train: [87][40/1500]	BT 0.039 (0.791)	DT 0.001 (0.755)	loss 6.485 (6.490)	prob 2.528 (2.298)	GS 34.375 (32.283)	mem 73.475
Train: [87][50/1500]	BT 0.039 (0.729)	DT 0.001 (0.693)	loss 6.625 (6.527)	prob 2.186 (2.238)	GS 32.391 (32.341)	mem 74.303
Train: [87][60/1500]	BT 0.039 (0.616)	DT 0.001 (0.580)	loss 6.617 (6.596)	prob 2.331 (2.220)	GS 34.656 (31.613)	mem 74.349
Train: [87][70/1500]	BT 0.039 (0.534)	DT 0.001 (0.497)	loss 6.642 (6.645)	prob 2.051 (2.099)	GS 36.328 (32.160)	mem 74.350
Train: [87][80/1500]	BT 0.033 (0.557)	DT 0.000 (0.520)	loss 6.520 (6.634)	prob 1.317 (2.116)	GS 34.922 (32.301)	mem 74.358
Train: [87][90/1500]	BT 0.035 (0.500)	DT 0.000 (0.463)	loss 6.436 (6.622)	prob 2.636 (2.154)	GS 32.484 (32.296)	mem 74.358
Train: [87][100/1500]	BT 0.038 (0.563)	DT 0.005 (0.525)	loss 6.626 (6.617)	prob 2.202 (2.107)	GS 36.438 (32.367)	mem 74.388
Train: [87][110/1500]	BT 0.060 (0.518)	DT 0.005 (0.478)	loss 6.495 (6.639)	prob 2.557 (2.292)	GS 29.828 (32.255)	mem 74.389
Train: [87][120/1500]	BT 0.029 (0.549)	DT 0.000 (0.510)	loss 6.618 (6.640)	prob 2.821 (2.223)	GS 33.859 (32.934)	mem 74.406
Train: [87][130/1500]	BT 0.031 (0.509)	DT 0.000 (0.471)	loss 6.598 (6.597)	prob 2.131 (2.255)	GS 36.312 (32.259)	mem 74.409
Train: [87][140/1500]	BT 0.029 (0.579)	DT 0.000 (0.541)	loss 6.588 (6.594)	prob 2.961 (2.341)	GS 29.844 (32.544)	mem 74.419
Train: [87][150/1500]	BT 0.030 (0.543)	DT 0.000 (0.505)	loss 6.856 (6.603)	prob 1.651 (2.350)	GS 28.578 (32.534)	mem 74.420
Train: [87][160/1500]	BT 0.036 (0.527)	DT 0.001 (0.490)	loss 6.490 (6.582)	prob 2.192 (2.133)	GS 35.141 (32.491)	mem 74.422
Train: [87][170/1500]	BT 0.027 (0.498)	DT 0.000 (0.461)	loss 6.551 (6.627)	prob 2.879 (2.194)	GS 30.266 (32.904)	mem 74.423
Train: [87][180/1500]	BT 0.037 (0.472)	DT 0.000 (0.435)	loss 6.874 (6.626)	prob 2.218 (2.350)	GS 36.703 (33.569)	mem 74.424
Train: [87][190/1500]	BT 0.066 (0.479)	DT 0.009 (0.442)	loss 6.850 (6.630)	prob 1.949 (2.343)	GS 35.188 (33.192)	mem 74.424
Train: [87][200/1500]	BT 0.033 (0.457)	DT 0.000 (0.420)	loss 6.620 (6.625)	prob 2.178 (2.345)	GS 33.484 (33.000)	mem 74.425
Train: [87][210/1500]	BT 0.046 (0.482)	DT 0.000 (0.444)	loss 6.558 (6.666)	prob 2.846 (2.474)	GS 30.250 (33.678)	mem 74.428
Train: [87][220/1500]	BT 0.031 (0.462)	DT 0.000 (0.424)	loss 6.590 (6.666)	prob 2.471 (2.469)	GS 33.156 (34.008)	mem 74.429
Train: [87][230/1500]	BT 0.028 (0.491)	DT 0.000 (0.454)	loss 6.696 (6.648)	prob 1.704 (2.380)	GS 35.812 (33.834)	mem 74.431
Train: [87][240/1500]	BT 0.027 (0.472)	DT 0.000 (0.435)	loss 6.665 (6.638)	prob 1.972 (2.424)	GS 34.484 (33.562)	mem 74.431
Train: [87][250/1500]	BT 0.037 (0.465)	DT 0.001 (0.429)	loss 6.747 (6.634)	prob 1.661 (2.425)	GS 33.438 (33.400)	mem 74.434
Train: [87][260/1500]	BT 0.037 (0.449)	DT 0.001 (0.412)	loss 6.594 (6.541)	prob 2.256 (2.593)	GS 31.984 (32.892)	mem 74.436
Train: [87][270/1500]	BT 0.037 (0.434)	DT 0.001 (0.397)	loss 6.716 (6.564)	prob 2.345 (2.471)	GS 35.750 (31.957)	mem 74.435
Train: [87][280/1500]	BT 0.056 (0.451)	DT 0.011 (0.415)	loss 6.639 (6.559)	prob 2.296 (2.532)	GS 31.375 (31.991)	mem 74.439
Train: [87][290/1500]	BT 0.060 (0.438)	DT 0.001 (0.400)	loss 6.404 (6.550)	prob 1.888 (2.525)	GS 35.219 (32.296)	mem 74.439
Train: [87][300/1500]	BT 0.063 (0.462)	DT 0.016 (0.423)	loss 6.834 (6.564)	prob 1.932 (2.485)	GS 31.875 (32.517)	mem 74.441
Train: [87][310/1500]	BT 0.048 (0.449)	DT 0.003 (0.410)	loss 6.514 (6.559)	prob 2.524 (2.564)	GS 33.453 (32.802)	mem 74.440
Train: [87][320/1500]	BT 0.030 (0.472)	DT 0.001 (0.433)	loss 6.552 (6.608)	prob 2.542 (2.523)	GS 36.469 (34.027)	mem 74.440
Train: [87][330/1500]	BT 0.034 (0.459)	DT 0.000 (0.420)	loss 6.608 (6.614)	prob 2.166 (2.506)	GS 34.531 (33.760)	mem 74.440
Train: [87][340/1500]	BT 0.034 (0.454)	DT 0.001 (0.415)	loss 6.681 (6.608)	prob 2.393 (2.526)	GS 31.156 (33.596)	mem 74.443
Train: [87][350/1500]	BT 0.036 (0.448)	DT 0.001 (0.409)	loss 6.460 (6.601)	prob 2.741 (2.500)	GS 33.734 (33.440)	mem 74.446
Train: [87][360/1500]	BT 0.037 (0.439)	DT 0.001 (0.401)	loss 6.452 (6.603)	prob 2.468 (2.269)	GS 33.828 (32.102)	mem 74.444
Train: [87][370/1500]	BT 0.037 (0.437)	DT 0.000 (0.399)	loss 6.686 (6.619)	prob 2.753 (2.387)	GS 31.469 (31.776)	mem 74.447
Train: [87][380/1500]	BT 0.028 (0.427)	DT 0.000 (0.389)	loss 6.553 (6.611)	prob 2.579 (2.479)	GS 37.750 (32.642)	mem 74.448
Train: [87][390/1500]	BT 0.038 (0.418)	DT 0.000 (0.380)	loss 6.526 (6.611)	prob 2.774 (2.471)	GS 34.047 (32.452)	mem 74.448
Train: [87][400/1500]	BT 0.032 (0.421)	DT 0.000 (0.383)	loss 6.685 (6.621)	prob 2.544 (2.488)	GS 32.328 (32.468)	mem 74.449
Train: [87][410/1500]	BT 0.038 (0.412)	DT 0.001 (0.374)	loss 6.598 (6.586)	prob 2.249 (2.426)	GS 32.281 (32.611)	mem 74.450
Train: [87][420/1500]	BT 0.038 (0.410)	DT 0.001 (0.372)	loss 6.453 (6.576)	prob 2.148 (2.356)	GS 32.953 (32.098)	mem 74.456
Train: [87][430/1500]	BT 0.038 (0.401)	DT 0.001 (0.363)	loss 6.858 (6.597)	prob 1.678 (2.332)	GS 34.469 (32.605)	mem 74.456
Train: [87][440/1500]	BT 0.037 (0.402)	DT 0.000 (0.365)	loss 6.752 (6.606)	prob 2.200 (2.437)	GS 39.188 (32.867)	mem 74.456
Train: [87][450/1500]	BT 0.038 (0.394)	DT 0.001 (0.356)	loss 6.525 (6.616)	prob 1.655 (2.391)	GS 34.984 (32.693)	mem 74.456
Train: [87][460/1500]	BT 0.066 (0.388)	DT 0.001 (0.350)	loss 6.741 (6.701)	prob 3.377 (2.852)	GS 35.594 (33.606)	mem 74.488
Train: [87][470/1500]	BT 0.039 (0.394)	DT 0.001 (0.356)	loss 6.652 (6.664)	prob 3.110 (2.861)	GS 35.719 (33.565)	mem 74.491
Train: [87][480/1500]	BT 0.048 (0.390)	DT 0.002 (0.352)	loss 6.590 (6.662)	prob 2.373 (2.795)	GS 37.953 (33.167)	mem 74.492
Train: [87][490/1500]	BT 0.054 (0.391)	DT 0.001 (0.353)	loss 6.519 (6.648)	prob 2.455 (2.770)	GS 33.375 (33.626)	mem 74.497
Train: [87][500/1500]	BT 0.033 (0.405)	DT 0.001 (0.366)	loss 6.499 (6.652)	prob 3.248 (2.741)	GS 29.469 (33.371)	mem 74.496
Train: [87][510/1500]	BT 0.027 (0.397)	DT 0.000 (0.359)	loss 6.608 (6.659)	prob 2.954 (2.906)	GS 33.797 (31.688)	mem 74.498
Train: [87][520/1500]	BT 0.052 (0.400)	DT 0.011 (0.362)	loss 6.785 (6.644)	prob 2.664 (2.695)	GS 35.984 (32.049)	mem 74.501
Train: [87][530/1500]	BT 0.062 (0.394)	DT 0.005 (0.356)	loss 6.814 (6.653)	prob 3.063 (2.660)	GS 34.766 (32.309)	mem 74.501
Train: [87][540/1500]	BT 0.090 (0.388)	DT 0.004 (0.349)	loss 6.740 (6.649)	prob 2.267 (2.663)	GS 34.234 (32.538)	mem 74.502
Train: [87][550/1500]	BT 0.028 (0.397)	DT 0.001 (0.358)	loss 6.589 (6.658)	prob 3.145 (2.691)	GS 34.141 (32.791)	mem 74.501
Train: [87][560/1500]	BT 0.039 (0.391)	DT 0.001 (0.352)	loss 6.731 (6.635)	prob 3.210 (2.735)	GS 37.922 (34.148)	mem 74.502
Train: [87][570/1500]	BT 0.039 (0.386)	DT 0.001 (0.347)	loss 6.524 (6.636)	prob 2.762 (2.861)	GS 36.578 (33.884)	mem 74.502
Train: [87][580/1500]	BT 0.038 (0.383)	DT 0.000 (0.345)	loss 6.678 (6.649)	prob 2.492 (2.795)	GS 32.734 (33.464)	mem 74.503
Train: [87][590/1500]	BT 0.069 (0.381)	DT 0.004 (0.342)	loss 6.673 (6.655)	prob 2.661 (2.777)	GS 32.266 (33.320)	mem 74.504
Train: [87][600/1500]	BT 0.031 (0.385)	DT 0.000 (0.345)	loss 6.745 (6.652)	prob 2.438 (2.767)	GS 33.562 (33.366)	mem 74.504
Train: [87][610/1500]	BT 0.151 (0.379)	DT 0.003 (0.340)	loss 6.830 (6.664)	prob 2.439 (2.621)	GS 33.531 (31.870)	mem 74.504
Train: [87][620/1500]	BT 0.030 (0.412)	DT 0.000 (0.373)	loss 6.704 (6.685)	prob 3.171 (2.774)	GS 31.094 (32.084)	mem 74.506
Train: [87][630/1500]	BT 0.028 (0.406)	DT 0.000 (0.367)	loss 6.671 (6.678)	prob 3.242 (2.827)	GS 36.797 (32.577)	mem 74.507
Train: [87][640/1500]	BT 0.030 (0.404)	DT 0.000 (0.365)	loss 6.904 (6.692)	prob 3.104 (2.776)	GS 31.109 (32.417)	mem 74.508
Train: [87][650/1500]	BT 0.029 (0.398)	DT 0.000 (0.360)	loss 6.718 (6.696)	prob 2.219 (2.758)	GS 34.250 (32.648)	mem 74.509
Train: [87][660/1500]	BT 0.030 (0.406)	DT 0.001 (0.367)	loss 6.544 (6.700)	prob 2.756 (2.806)	GS 29.203 (33.737)	mem 73.200
Train: [87][670/1500]	BT 0.030 (0.400)	DT 0.000 (0.362)	loss 6.774 (6.689)	prob 2.380 (2.795)	GS 37.312 (33.319)	mem 73.199
Train: [87][680/1500]	BT 0.027 (0.395)	DT 0.000 (0.356)	loss 6.626 (6.687)	prob 2.300 (2.820)	GS 33.938 (32.603)	mem 73.199
Train: [87][690/1500]	BT 0.028 (0.395)	DT 0.000 (0.357)	loss 6.788 (6.686)	prob 3.116 (2.775)	GS 33.125 (32.403)	mem 73.198
Train: [87][700/1500]	BT 0.039 (0.390)	DT 0.001 (0.352)	loss 6.698 (6.678)	prob 2.879 (2.767)	GS 29.891 (32.019)	mem 73.199
Train: [87][710/1500]	BT 0.038 (0.389)	DT 0.001 (0.351)	loss 6.474 (6.581)	prob 2.614 (2.500)	GS 29.812 (30.770)	mem 73.199
Train: [87][720/1500]	BT 0.039 (0.384)	DT 0.001 (0.346)	loss 6.615 (6.601)	prob 2.827 (2.559)	GS 36.750 (30.680)	mem 73.199
Train: [87][730/1500]	BT 0.028 (0.380)	DT 0.000 (0.341)	loss 6.583 (6.615)	prob 2.508 (2.619)	GS 36.953 (31.603)	mem 73.199
Train: [87][740/1500]	BT 0.037 (0.379)	DT 0.001 (0.341)	loss 6.693 (6.653)	prob 2.666 (2.552)	GS 36.062 (32.071)	mem 73.207
Train: [87][750/1500]	BT 0.064 (0.374)	DT 0.012 (0.336)	loss 6.739 (6.660)	prob 2.669 (2.549)	GS 32.438 (32.043)	mem 73.208
Train: [87][760/1500]	BT 0.063 (0.379)	DT 0.004 (0.340)	loss 6.585 (6.644)	prob 2.248 (2.459)	GS 36.469 (32.748)	mem 73.207
Train: [87][770/1500]	BT 0.038 (0.379)	DT 0.001 (0.341)	loss 6.761 (6.666)	prob 2.541 (2.240)	GS 33.219 (33.486)	mem 73.217
Train: [87][780/1500]	BT 0.038 (0.376)	DT 0.001 (0.337)	loss 6.651 (6.661)	prob 2.417 (2.328)	GS 36.297 (33.484)	mem 73.210
Train: [87][790/1500]	BT 0.027 (0.375)	DT 0.000 (0.337)	loss 6.697 (6.669)	prob 2.471 (2.403)	GS 33.203 (33.069)	mem 73.117
Train: [87][800/1500]	BT 0.028 (0.371)	DT 0.000 (0.332)	loss 6.772 (6.667)	prob 2.085 (2.376)	GS 30.031 (32.904)	mem 73.118
Train: [87][810/1500]	BT 0.037 (0.368)	DT 0.001 (0.330)	loss 6.620 (6.665)	prob 2.682 (2.503)	GS 33.656 (31.994)	mem 73.119
Train: [87][820/1500]	BT 0.029 (0.367)	DT 0.000 (0.329)	loss 6.598 (6.679)	prob 3.033 (2.458)	GS 33.266 (32.091)	mem 73.116
Train: [87][830/1500]	BT 0.066 (0.365)	DT 0.011 (0.326)	loss 6.865 (6.693)	prob 2.054 (2.478)	GS 31.031 (32.117)	mem 73.116
Train: [87][840/1500]	BT 0.068 (0.367)	DT 0.001 (0.328)	loss 6.773 (6.682)	prob 2.631 (2.447)	GS 33.359 (32.060)	mem 73.116
Train: [87][850/1500]	BT 0.028 (0.383)	DT 0.000 (0.345)	loss 6.704 (6.680)	prob 2.336 (2.437)	GS 31.344 (32.324)	mem 73.121
Train: [87][860/1500]	BT 0.028 (0.379)	DT 0.000 (0.341)	loss 6.611 (6.730)	prob 2.672 (2.446)	GS 34.141 (34.492)	mem 73.124
Train: [87][870/1500]	BT 0.035 (0.375)	DT 0.000 (0.337)	loss 6.656 (6.677)	prob 1.938 (2.530)	GS 33.641 (33.662)	mem 73.125
Train: [87][880/1500]	BT 0.039 (0.374)	DT 0.001 (0.336)	loss 6.905 (6.691)	prob 2.196 (2.420)	GS 35.625 (33.641)	mem 73.127
Train: [87][890/1500]	BT 0.039 (0.370)	DT 0.001 (0.332)	loss 7.075 (6.691)	prob 1.457 (2.405)	GS 39.297 (33.768)	mem 73.129
Train: [87][900/1500]	BT 0.031 (0.377)	DT 0.001 (0.339)	loss 6.757 (6.689)	prob 2.796 (2.412)	GS 32.688 (33.698)	mem 73.130
Train: [87][910/1500]	BT 0.057 (0.373)	DT 0.002 (0.335)	loss 6.834 (6.742)	prob 1.991 (2.357)	GS 33.453 (31.967)	mem 73.130
Train: [87][920/1500]	BT 0.029 (0.379)	DT 0.000 (0.341)	loss 6.675 (6.721)	prob 2.676 (2.424)	GS 34.703 (32.568)	mem 73.132
Train: [87][930/1500]	BT 0.023 (0.376)	DT 0.000 (0.338)	loss 6.610 (6.701)	prob 2.720 (2.442)	GS 31.375 (32.530)	mem 73.132
Train: [87][940/1500]	BT 0.038 (0.377)	DT 0.001 (0.338)	loss 6.670 (6.707)	prob 3.047 (2.479)	GS 32.766 (32.771)	mem 73.134
Train: [87][950/1500]	BT 0.039 (0.373)	DT 0.001 (0.335)	loss 6.684 (6.695)	prob 2.310 (2.548)	GS 33.328 (32.714)	mem 73.136
Train: [87][960/1500]	BT 0.039 (0.369)	DT 0.001 (0.331)	loss 6.703 (6.670)	prob 2.367 (2.389)	GS 35.797 (33.072)	mem 73.136
Train: [87][970/1500]	BT 0.061 (0.371)	DT 0.012 (0.333)	loss 6.621 (6.658)	prob 3.214 (2.451)	GS 32.484 (33.016)	mem 73.135
Train: [87][980/1500]	BT 0.078 (0.368)	DT 0.011 (0.329)	loss 6.850 (6.640)	prob 2.018 (2.499)	GS 38.953 (33.051)	mem 73.135
Train: [87][990/1500]	BT 0.030 (0.375)	DT 0.000 (0.337)	loss 7.015 (6.664)	prob 1.544 (2.466)	GS 36.062 (33.330)	mem 73.136
Train: [87][1000/1500]	BT 0.031 (0.377)	DT 0.000 (0.339)	loss 6.735 (6.663)	prob 2.052 (2.436)	GS 34.250 (33.288)	mem 73.135
Train: [87][1010/1500]	BT 0.038 (0.374)	DT 0.000 (0.335)	loss 6.732 (6.729)	prob 2.002 (2.290)	GS 31.062 (32.527)	mem 73.136
Train: [87][1020/1500]	BT 0.028 (0.376)	DT 0.000 (0.338)	loss 6.540 (6.702)	prob 2.782 (2.372)	GS 31.734 (32.694)	mem 73.138
Train: [87][1030/1500]	BT 0.038 (0.373)	DT 0.001 (0.335)	loss 6.956 (6.695)	prob 2.931 (2.484)	GS 32.906 (32.325)	mem 73.139
Train: [87][1040/1500]	BT 0.037 (0.372)	DT 0.001 (0.334)	loss 6.902 (6.686)	prob 1.630 (2.555)	GS 35.500 (32.287)	mem 73.149
Train: [87][1050/1500]	BT 0.028 (0.369)	DT 0.000 (0.331)	loss 6.718 (6.697)	prob 2.944 (2.570)	GS 32.797 (32.481)	mem 73.151
Train: [87][1060/1500]	BT 0.037 (0.367)	DT 0.001 (0.329)	loss 6.709 (6.708)	prob 3.035 (2.656)	GS 34.188 (32.023)	mem 73.152
Train: [87][1070/1500]	BT 0.037 (0.365)	DT 0.001 (0.328)	loss 6.912 (6.725)	prob 2.169 (2.627)	GS 37.000 (33.068)	mem 73.154
Train: [87][1080/1500]	BT 0.065 (0.363)	DT 0.002 (0.325)	loss 6.765 (6.724)	prob 2.460 (2.658)	GS 31.969 (32.835)	mem 73.153
Train: [87][1090/1500]	BT 0.027 (0.371)	DT 0.000 (0.332)	loss 6.592 (6.709)	prob 4.340 (2.659)	GS 34.141 (32.801)	mem 73.154
Train: [87][1100/1500]	BT 0.035 (0.367)	DT 0.000 (0.329)	loss 6.801 (6.726)	prob 1.940 (2.653)	GS 32.750 (32.553)	mem 73.153
Train: [87][1110/1500]	BT 0.037 (0.364)	DT 0.001 (0.326)	loss 6.997 (6.798)	prob 2.249 (2.680)	GS 31.422 (32.677)	mem 73.155
Train: [87][1120/1500]	BT 0.037 (0.365)	DT 0.000 (0.327)	loss 6.769 (6.753)	prob 2.545 (2.827)	GS 31.625 (32.373)	mem 73.159
Train: [87][1130/1500]	BT 0.028 (0.362)	DT 0.000 (0.324)	loss 6.779 (6.754)	prob 3.504 (2.866)	GS 34.000 (32.511)	mem 73.160
Train: [87][1140/1500]	BT 0.037 (0.363)	DT 0.000 (0.325)	loss 6.916 (6.757)	prob 2.241 (2.766)	GS 35.703 (32.427)	mem 73.163
Train: [87][1150/1500]	BT 0.053 (0.360)	DT 0.011 (0.322)	loss 6.621 (6.741)	prob 2.227 (2.793)	GS 37.266 (32.626)	mem 73.164
Train: [87][1160/1500]	BT 0.033 (0.365)	DT 0.001 (0.327)	loss 6.593 (6.721)	prob 2.718 (2.555)	GS 35.125 (33.061)	mem 73.162
Train: [87][1170/1500]	BT 0.029 (0.362)	DT 0.000 (0.325)	loss 6.617 (6.739)	prob 2.482 (2.580)	GS 34.641 (33.316)	mem 73.163
Train: [87][1180/1500]	BT 0.036 (0.360)	DT 0.000 (0.322)	loss 6.751 (6.738)	prob 2.756 (2.631)	GS 28.297 (33.137)	mem 73.163
Train: [87][1190/1500]	BT 0.027 (0.360)	DT 0.000 (0.322)	loss 6.714 (6.738)	prob 2.191 (2.591)	GS 33.484 (32.566)	mem 73.166
Train: [87][1200/1500]	BT 0.037 (0.357)	DT 0.001 (0.320)	loss 6.753 (6.729)	prob 3.240 (2.628)	GS 31.578 (32.407)	mem 73.167
Train: [87][1210/1500]	BT 0.030 (0.358)	DT 0.000 (0.320)	loss 6.554 (6.723)	prob 2.635 (2.655)	GS 35.734 (32.419)	mem 73.168
Train: [87][1220/1500]	BT 0.055 (0.355)	DT 0.000 (0.318)	loss 6.616 (6.717)	prob 3.808 (2.744)	GS 28.219 (32.459)	mem 73.168
Train: [87][1230/1500]	BT 0.052 (0.353)	DT 0.002 (0.315)	loss 6.824 (6.725)	prob 1.835 (2.748)	GS 32.094 (32.359)	mem 73.170
Train: [87][1240/1500]	BT 0.037 (0.355)	DT 0.000 (0.317)	loss 6.851 (6.719)	prob 2.355 (2.753)	GS 35.031 (32.621)	mem 73.174
Train: [87][1250/1500]	BT 0.037 (0.352)	DT 0.001 (0.315)	loss 6.727 (6.717)	prob 2.694 (2.686)	GS 31.797 (32.622)	mem 73.173
Train: [87][1260/1500]	BT 0.027 (0.361)	DT 0.000 (0.323)	loss 6.640 (6.718)	prob 2.536 (2.499)	GS 33.391 (33.550)	mem 73.176
Train: [87][1270/1500]	BT 0.029 (0.358)	DT 0.000 (0.321)	loss 6.753 (6.762)	prob 2.248 (2.688)	GS 32.312 (33.431)	mem 73.177
Train: [87][1280/1500]	BT 0.037 (0.356)	DT 0.001 (0.318)	loss 6.844 (6.749)	prob 2.795 (2.656)	GS 34.609 (33.607)	mem 73.178
Train: [87][1290/1500]	BT 0.027 (0.357)	DT 0.000 (0.319)	loss 6.827 (6.758)	prob 2.267 (2.664)	GS 27.547 (33.163)	mem 73.178
Train: [87][1300/1500]	BT 0.038 (0.354)	DT 0.001 (0.317)	loss 6.867 (6.743)	prob 2.515 (2.684)	GS 34.797 (32.907)	mem 73.179
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [87][1310/1500]	BT 0.092 (0.354)	DT 0.013 (0.317)	loss 6.817 (6.680)	prob 2.590 (2.596)	GS 33.594 (31.817)	mem 73.180
Train: [87][1320/1500]	BT 0.029 (0.359)	DT 0.000 (0.321)	loss 6.627 (6.701)	prob 2.257 (2.591)	GS 27.672 (32.764)	mem 73.178
Train: [87][1330/1500]	BT 0.038 (0.356)	DT 0.001 (0.319)	loss 6.665 (6.731)	prob 2.243 (2.549)	GS 29.391 (32.488)	mem 73.179
Train: [87][1340/1500]	BT 0.042 (0.357)	DT 0.001 (0.319)	loss 6.734 (6.747)	prob 2.369 (2.503)	GS 32.875 (32.889)	mem 73.181
Train: [87][1350/1500]	BT 0.025 (0.355)	DT 0.000 (0.317)	loss 6.664 (6.738)	prob 2.859 (2.595)	GS 33.109 (33.077)	mem 73.182
Train: [87][1360/1500]	BT 0.028 (0.352)	DT 0.000 (0.315)	loss 6.786 (6.741)	prob 2.965 (2.783)	GS 30.125 (32.023)	mem 73.181
Train: [87][1370/1500]	BT 0.037 (0.352)	DT 0.001 (0.315)	loss 6.802 (6.709)	prob 3.256 (2.749)	GS 32.797 (32.692)	mem 73.183
Train: [87][1380/1500]	BT 0.038 (0.350)	DT 0.000 (0.313)	loss 7.222 (6.707)	prob 2.042 (2.646)	GS 36.016 (32.293)	mem 73.183
Train: [87][1390/1500]	BT 0.038 (0.350)	DT 0.001 (0.313)	loss 6.548 (6.699)	prob 2.950 (2.593)	GS 34.203 (32.038)	mem 73.185
Train: [87][1400/1500]	BT 0.051 (0.348)	DT 0.002 (0.311)	loss 6.874 (6.710)	prob 1.969 (2.600)	GS 31.047 (32.021)	mem 73.186
Train: [87][1410/1500]	BT 0.048 (0.346)	DT 0.002 (0.308)	loss 6.852 (6.739)	prob 2.401 (2.699)	GS 31.297 (32.725)	mem 73.185
Train: [87][1420/1500]	BT 0.038 (0.348)	DT 0.001 (0.310)	loss 6.595 (6.735)	prob 2.984 (2.594)	GS 34.094 (32.956)	mem 73.183
Train: [87][1430/1500]	BT 0.037 (0.347)	DT 0.001 (0.309)	loss 6.648 (6.747)	prob 3.049 (2.626)	GS 35.938 (33.277)	mem 73.213
Train: [87][1440/1500]	BT 0.039 (0.346)	DT 0.001 (0.308)	loss 6.766 (6.731)	prob 2.445 (2.593)	GS 32.250 (33.147)	mem 73.213
Train: [87][1450/1500]	BT 0.039 (0.344)	DT 0.001 (0.306)	loss 6.643 (6.735)	prob 2.764 (2.583)	GS 34.406 (33.053)	mem 73.212
Train: [87][1460/1500]	BT 0.065 (0.344)	DT 0.002 (0.306)	loss 6.562 (6.677)	prob 2.280 (2.460)	GS 36.062 (32.073)	mem 73.177
Train: [87][1470/1500]	BT 0.032 (0.345)	DT 0.001 (0.307)	loss 6.850 (6.715)	prob 2.246 (2.442)	GS 36.500 (32.690)	mem 43.823
Train: [87][1480/1500]	BT 0.028 (0.344)	DT 0.000 (0.306)	loss 6.737 (6.736)	prob 3.194 (2.565)	GS 31.719 (32.518)	mem 22.112
Train: [87][1490/1500]	BT 0.029 (0.342)	DT 0.000 (0.304)	loss 6.501 (6.723)	prob 2.601 (2.587)	GS 33.062 (32.490)	mem 22.037
Train: [87][1500/1500]	BT 0.035 (0.340)	DT 0.000 (0.303)	loss 6.419 (6.721)	prob 2.302 (2.584)	GS 31.625 (32.331)	mem 8.008
Train: [87][1510/1500]	BT 0.026 (0.338)	DT 0.000 (0.301)	loss 6.174 (6.431)	prob 1.899 (2.561)	GS 29.219 (32.094)	mem 8.008
epoch 87, total time 511.19
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [88][1/1500]	BT 19.023 (19.023)	DT 18.966 (18.966)	loss 6.497 (6.497)	prob 2.666 (2.666)	GS 28.969 (28.969)	mem 71.690
Train: [88][10/1500]	BT 0.051 (2.470)	DT 0.003 (2.422)	loss 6.715 (6.506)	prob 2.996 (2.430)	GS 32.594 (33.165)	mem 71.771
Train: [88][20/1500]	BT 0.064 (1.266)	DT 0.003 (1.214)	loss 6.502 (6.567)	prob 3.585 (2.589)	GS 37.234 (33.385)	mem 71.771
Train: [88][30/1500]	BT 0.031 (1.179)	DT 0.000 (1.132)	loss 6.652 (6.595)	prob 3.012 (2.561)	GS 31.516 (33.450)	mem 71.812
Train: [88][40/1500]	BT 0.027 (0.891)	DT 0.000 (0.849)	loss 6.677 (6.613)	prob 2.195 (2.575)	GS 31.922 (33.046)	mem 71.813
Train: [88][50/1500]	BT 0.036 (0.802)	DT 0.001 (0.760)	loss 6.778 (6.638)	prob 2.773 (2.598)	GS 36.422 (32.822)	mem 72.850
Train: [88][60/1500]	BT 0.039 (0.673)	DT 0.001 (0.634)	loss 6.626 (6.716)	prob 2.285 (2.576)	GS 27.922 (32.116)	mem 72.851
Train: [88][70/1500]	BT 0.039 (0.583)	DT 0.001 (0.543)	loss 6.775 (6.751)	prob 2.383 (2.507)	GS 35.562 (32.011)	mem 72.852
Train: [88][80/1500]	BT 0.061 (0.550)	DT 0.011 (0.511)	loss 6.720 (6.754)	prob 2.828 (2.521)	GS 34.141 (32.443)	mem 72.971
Train: [88][90/1500]	BT 0.062 (0.498)	DT 0.004 (0.455)	loss 6.759 (6.746)	prob 2.401 (2.549)	GS 33.719 (32.435)	mem 72.973
Train: [88][100/1500]	BT 0.038 (0.522)	DT 0.000 (0.479)	loss 6.989 (6.747)	prob 2.461 (2.498)	GS 36.984 (32.627)	mem 73.031
Train: [88][110/1500]	BT 0.075 (0.480)	DT 0.006 (0.437)	loss 7.043 (6.765)	prob 2.491 (2.482)	GS 30.578 (33.741)	mem 73.033
Train: [88][120/1500]	BT 0.053 (0.468)	DT 0.000 (0.423)	loss 6.605 (6.775)	prob 2.241 (2.528)	GS 30.547 (33.273)	mem 72.613
Train: [88][130/1500]	BT 0.031 (0.489)	DT 0.001 (0.445)	loss 6.961 (6.773)	prob 2.541 (2.447)	GS 33.141 (33.893)	mem 72.604
Train: [88][140/1500]	BT 0.036 (0.456)	DT 0.001 (0.413)	loss 6.723 (6.762)	prob 2.528 (2.478)	GS 34.078 (33.721)	mem 72.603
Train: [88][150/1500]	BT 0.061 (0.455)	DT 0.004 (0.412)	loss 6.772 (6.761)	prob 2.334 (2.541)	GS 36.391 (33.656)	mem 72.585
Train: [88][160/1500]	BT 0.034 (0.430)	DT 0.001 (0.387)	loss 6.648 (6.786)	prob 2.969 (2.478)	GS 35.500 (32.706)	mem 72.586
Train: [88][170/1500]	BT 0.060 (0.448)	DT 0.001 (0.405)	loss 6.977 (6.789)	prob 2.976 (2.665)	GS 32.266 (33.259)	mem 72.560
Train: [88][180/1500]	BT 0.031 (0.424)	DT 0.000 (0.382)	loss 7.017 (6.782)	prob 3.224 (2.796)	GS 35.125 (33.385)	mem 72.560
Train: [88][190/1500]	BT 0.036 (0.404)	DT 0.001 (0.362)	loss 7.067 (6.804)	prob 2.523 (2.783)	GS 36.172 (33.344)	mem 72.560
Train: [88][200/1500]	BT 0.068 (0.432)	DT 0.011 (0.390)	loss 6.762 (6.803)	prob 2.500 (2.798)	GS 30.156 (33.005)	mem 72.560
Train: [88][210/1500]	BT 0.029 (0.458)	DT 0.000 (0.416)	loss 6.707 (6.781)	prob 3.035 (2.802)	GS 32.250 (33.264)	mem 72.570
Train: [88][220/1500]	BT 0.038 (0.439)	DT 0.001 (0.397)	loss 6.997 (6.784)	prob 2.312 (2.859)	GS 37.438 (34.040)	mem 72.581
Train: [88][230/1500]	BT 0.037 (0.434)	DT 0.001 (0.393)	loss 6.938 (6.791)	prob 2.414 (2.726)	GS 34.344 (33.957)	mem 72.582
Train: [88][240/1500]	BT 0.038 (0.417)	DT 0.001 (0.376)	loss 6.967 (6.815)	prob 3.337 (2.678)	GS 33.281 (33.675)	mem 72.583
Train: [88][250/1500]	BT 0.038 (0.402)	DT 0.001 (0.361)	loss 6.688 (6.806)	prob 3.313 (2.687)	GS 34.000 (33.485)	mem 72.583
Train: [88][260/1500]	BT 0.038 (0.400)	DT 0.001 (0.359)	loss 6.590 (6.706)	prob 2.755 (2.645)	GS 31.047 (32.089)	mem 72.486
Train: [88][270/1500]	BT 0.038 (0.387)	DT 0.001 (0.346)	loss 6.795 (6.692)	prob 2.134 (2.567)	GS 31.172 (31.735)	mem 72.486
Train: [88][280/1500]	BT 0.028 (0.412)	DT 0.000 (0.372)	loss 6.850 (6.743)	prob 2.868 (2.489)	GS 37.109 (31.717)	mem 72.484
Train: [88][290/1500]	BT 0.029 (0.399)	DT 0.000 (0.359)	loss 7.123 (6.772)	prob 2.898 (2.484)	GS 33.781 (32.010)	mem 72.485
Train: [88][300/1500]	BT 0.037 (0.396)	DT 0.001 (0.356)	loss 6.905 (6.781)	prob 2.889 (2.492)	GS 30.109 (32.048)	mem 72.490
Train: [88][310/1500]	BT 0.038 (0.384)	DT 0.001 (0.345)	loss 6.942 (6.900)	prob 2.013 (2.417)	GS 36.594 (31.605)	mem 72.489
Train: [88][320/1500]	BT 0.037 (0.374)	DT 0.000 (0.334)	loss 6.895 (6.888)	prob 3.228 (2.522)	GS 34.719 (32.192)	mem 72.489
Train: [88][330/1500]	BT 0.028 (0.383)	DT 0.000 (0.344)	loss 6.797 (6.837)	prob 3.402 (2.612)	GS 32.688 (32.459)	mem 72.513
Train: [88][340/1500]	BT 0.038 (0.373)	DT 0.001 (0.334)	loss 6.763 (6.854)	prob 2.957 (2.667)	GS 32.750 (32.658)	mem 72.515
Train: [88][350/1500]	BT 0.032 (0.374)	DT 0.000 (0.335)	loss 7.016 (6.853)	prob 2.574 (2.640)	GS 33.344 (32.679)	mem 72.515
Train: [88][360/1500]	BT 0.029 (0.365)	DT 0.000 (0.326)	loss 7.239 (6.847)	prob 2.575 (2.619)	GS 33.078 (31.698)	mem 72.516
Train: [88][370/1500]	BT 0.029 (0.356)	DT 0.001 (0.317)	loss 6.624 (6.865)	prob 2.716 (2.738)	GS 34.359 (32.073)	mem 72.516
Train: [88][380/1500]	BT 0.039 (0.358)	DT 0.001 (0.320)	loss 6.825 (6.848)	prob 3.209 (2.750)	GS 34.812 (31.971)	mem 72.504
Train: [88][390/1500]	BT 0.039 (0.350)	DT 0.001 (0.312)	loss 6.832 (6.837)	prob 2.736 (2.797)	GS 35.438 (32.377)	mem 72.504
Train: [88][400/1500]	BT 0.029 (0.353)	DT 0.000 (0.315)	loss 6.892 (6.831)	prob 3.368 (2.835)	GS 37.484 (32.328)	mem 72.507
Train: [88][410/1500]	BT 0.039 (0.345)	DT 0.001 (0.307)	loss 6.762 (6.755)	prob 2.766 (2.843)	GS 34.547 (33.827)	mem 72.507
Train: [88][420/1500]	BT 0.039 (0.346)	DT 0.001 (0.308)	loss 6.833 (6.777)	prob 2.935 (2.743)	GS 37.391 (33.760)	mem 72.508
Train: [88][430/1500]	BT 0.042 (0.339)	DT 0.001 (0.301)	loss 6.727 (6.791)	prob 2.136 (2.706)	GS 34.891 (33.241)	mem 72.508
Train: [88][440/1500]	BT 0.039 (0.332)	DT 0.001 (0.294)	loss 6.774 (6.801)	prob 1.886 (2.623)	GS 31.734 (32.729)	mem 72.508
Train: [88][450/1500]	BT 0.025 (0.334)	DT 0.000 (0.296)	loss 6.692 (6.805)	prob 2.487 (2.606)	GS 35.609 (32.866)	mem 72.510
Train: [88][460/1500]	BT 0.039 (0.328)	DT 0.001 (0.290)	loss 6.758 (6.751)	prob 3.259 (2.776)	GS 32.594 (31.730)	mem 72.512
Train: [88][470/1500]	BT 0.037 (0.327)	DT 0.001 (0.289)	loss 6.845 (6.803)	prob 2.526 (2.534)	GS 33.547 (32.099)	mem 72.525
Train: [88][480/1500]	BT 0.037 (0.321)	DT 0.001 (0.283)	loss 6.874 (6.815)	prob 3.378 (2.492)	GS 33.219 (31.902)	mem 72.525
Train: [88][490/1500]	BT 0.038 (0.318)	DT 0.001 (0.280)	loss 6.623 (6.817)	prob 2.309 (2.547)	GS 30.672 (31.663)	mem 72.525
Train: [88][500/1500]	BT 0.038 (0.317)	DT 0.001 (0.279)	loss 6.697 (6.830)	prob 2.800 (2.475)	GS 34.781 (31.893)	mem 72.529
Train: [88][510/1500]	BT 0.042 (0.316)	DT 0.001 (0.278)	loss 6.742 (6.813)	prob 2.823 (2.552)	GS 34.562 (33.686)	mem 72.532
Train: [88][520/1500]	BT 0.038 (0.313)	DT 0.001 (0.276)	loss 6.643 (6.839)	prob 3.010 (2.647)	GS 30.719 (32.690)	mem 72.532
Train: [88][530/1500]	BT 0.038 (0.308)	DT 0.001 (0.270)	loss 7.094 (6.867)	prob 2.265 (2.548)	GS 34.797 (32.819)	mem 72.533
Train: [88][540/1500]	BT 0.049 (0.317)	DT 0.006 (0.279)	loss 6.990 (6.847)	prob 2.851 (2.545)	GS 30.719 (32.629)	mem 72.535
Train: [88][550/1500]	BT 0.025 (0.318)	DT 0.000 (0.280)	loss 6.908 (6.844)	prob 2.863 (2.600)	GS 37.828 (32.781)	mem 72.535
Train: [88][560/1500]	BT 0.037 (0.313)	DT 0.001 (0.275)	loss 6.874 (6.918)	prob 2.575 (2.359)	GS 36.094 (34.208)	mem 72.537
Train: [88][570/1500]	BT 0.029 (0.316)	DT 0.000 (0.278)	loss 6.844 (6.914)	prob 2.982 (2.497)	GS 34.312 (33.506)	mem 72.538
Train: [88][580/1500]	BT 0.037 (0.312)	DT 0.001 (0.274)	loss 6.966 (6.882)	prob 2.504 (2.527)	GS 33.641 (33.145)	mem 72.537
Train: [88][590/1500]	BT 0.034 (0.314)	DT 0.000 (0.276)	loss 6.674 (6.869)	prob 3.006 (2.532)	GS 29.812 (32.694)	mem 72.541
Train: [88][600/1500]	BT 0.027 (0.309)	DT 0.000 (0.271)	loss 7.144 (6.855)	prob 1.908 (2.526)	GS 35.531 (32.837)	mem 72.542
Train: [88][610/1500]	BT 0.037 (0.305)	DT 0.001 (0.267)	loss 6.946 (6.931)	prob 1.840 (2.289)	GS 31.234 (33.506)	mem 72.543
Train: [88][620/1500]	BT 0.037 (0.305)	DT 0.001 (0.267)	loss 6.857 (6.937)	prob 2.747 (2.382)	GS 31.406 (32.688)	mem 72.544
Train: [88][630/1500]	BT 0.038 (0.301)	DT 0.001 (0.263)	loss 6.726 (6.930)	prob 2.848 (2.383)	GS 34.844 (32.314)	mem 72.545
Train: [88][640/1500]	BT 0.037 (0.301)	DT 0.001 (0.264)	loss 6.896 (6.906)	prob 2.432 (2.408)	GS 36.953 (32.398)	mem 72.546
Train: [88][650/1500]	BT 0.037 (0.297)	DT 0.001 (0.259)	loss 6.773 (6.900)	prob 3.201 (2.434)	GS 32.500 (32.282)	mem 72.545
Train: [88][660/1500]	BT 0.037 (0.293)	DT 0.001 (0.256)	loss 6.951 (6.889)	prob 2.253 (2.396)	GS 35.859 (32.705)	mem 72.544
Train: [88][670/1500]	BT 0.038 (0.297)	DT 0.001 (0.259)	loss 6.601 (6.922)	prob 2.760 (2.314)	GS 32.594 (32.259)	mem 72.546
Train: [88][680/1500]	BT 0.036 (0.294)	DT 0.001 (0.257)	loss 6.751 (6.880)	prob 2.449 (2.355)	GS 33.969 (32.052)	mem 72.544
Train: [88][690/1500]	BT 0.037 (0.293)	DT 0.001 (0.256)	loss 6.678 (6.851)	prob 2.574 (2.371)	GS 32.234 (32.277)	mem 72.545
Train: [88][700/1500]	BT 0.029 (0.294)	DT 0.000 (0.257)	loss 6.675 (6.829)	prob 2.610 (2.421)	GS 32.328 (32.218)	mem 72.548
Train: [88][710/1500]	BT 0.058 (0.290)	DT 0.001 (0.253)	loss 6.883 (6.788)	prob 2.583 (2.414)	GS 31.406 (30.941)	mem 72.549
Train: [88][720/1500]	BT 0.030 (0.298)	DT 0.000 (0.261)	loss 7.013 (6.806)	prob 2.824 (2.515)	GS 32.953 (31.983)	mem 72.550
Train: [88][730/1500]	BT 0.038 (0.295)	DT 0.001 (0.257)	loss 6.918 (6.825)	prob 2.219 (2.553)	GS 31.969 (31.865)	mem 72.552
Train: [88][740/1500]	BT 0.038 (0.295)	DT 0.001 (0.258)	loss 6.681 (6.832)	prob 2.373 (2.525)	GS 35.406 (32.284)	mem 72.553
Train: [88][750/1500]	BT 0.037 (0.291)	DT 0.001 (0.254)	loss 6.553 (6.831)	prob 2.519 (2.486)	GS 34.500 (32.535)	mem 72.553
Train: [88][760/1500]	BT 0.037 (0.289)	DT 0.001 (0.252)	loss 6.916 (6.842)	prob 2.246 (2.441)	GS 34.703 (32.538)	mem 72.553
Train: [88][770/1500]	BT 0.029 (0.297)	DT 0.000 (0.260)	loss 6.591 (6.838)	prob 2.933 (2.598)	GS 32.406 (32.877)	mem 72.553
Train: [88][780/1500]	BT 0.027 (0.294)	DT 0.000 (0.257)	loss 6.737 (6.825)	prob 2.218 (2.521)	GS 31.766 (32.506)	mem 72.553
Train: [88][790/1500]	BT 0.084 (0.301)	DT 0.022 (0.264)	loss 6.923 (6.826)	prob 1.680 (2.506)	GS 36.281 (32.796)	mem 72.583
Train: [88][800/1500]	BT 0.114 (0.299)	DT 0.011 (0.261)	loss 6.757 (6.823)	prob 2.744 (2.546)	GS 35.891 (32.695)	mem 72.586
Train: [88][810/1500]	BT 0.068 (0.312)	DT 0.008 (0.274)	loss 7.020 (6.817)	prob 2.233 (2.607)	GS 36.016 (32.181)	mem 72.587
Train: [88][820/1500]	BT 0.096 (0.310)	DT 0.002 (0.271)	loss 6.717 (6.861)	prob 2.944 (2.670)	GS 35.125 (33.409)	mem 72.589
Train: [88][830/1500]	BT 0.031 (0.322)	DT 0.001 (0.283)	loss 6.892 (6.892)	prob 2.293 (2.731)	GS 34.750 (33.521)	mem 72.587
Train: [88][840/1500]	BT 0.029 (0.321)	DT 0.000 (0.282)	loss 6.806 (6.896)	prob 2.157 (2.720)	GS 33.016 (33.599)	mem 72.589
Train: [88][850/1500]	BT 0.039 (0.319)	DT 0.001 (0.280)	loss 7.281 (6.898)	prob 2.295 (2.721)	GS 34.422 (33.665)	mem 72.589
Train: [88][860/1500]	BT 0.030 (0.321)	DT 0.000 (0.282)	loss 6.839 (6.822)	prob 3.268 (2.913)	GS 36.781 (32.934)	mem 72.589
Train: [88][870/1500]	BT 0.038 (0.318)	DT 0.001 (0.279)	loss 6.913 (6.861)	prob 2.975 (2.873)	GS 34.953 (32.709)	mem 72.589
Train: [88][880/1500]	BT 0.039 (0.320)	DT 0.001 (0.281)	loss 6.811 (6.869)	prob 2.628 (2.857)	GS 38.406 (32.628)	mem 72.590
Train: [88][890/1500]	BT 0.039 (0.316)	DT 0.001 (0.278)	loss 6.691 (6.880)	prob 2.616 (2.772)	GS 32.594 (32.727)	mem 72.590
Train: [88][900/1500]	BT 0.042 (0.313)	DT 0.001 (0.275)	loss 6.889 (6.871)	prob 2.860 (2.783)	GS 34.312 (32.753)	mem 72.591
Train: [88][910/1500]	BT 0.028 (0.320)	DT 0.000 (0.281)	loss 6.979 (6.814)	prob 2.594 (2.495)	GS 35.688 (35.089)	mem 72.591
Train: [88][920/1500]	BT 0.027 (0.317)	DT 0.001 (0.278)	loss 7.093 (6.850)	prob 3.325 (2.646)	GS 32.609 (33.691)	mem 72.591
Train: [88][930/1500]	BT 0.031 (0.322)	DT 0.000 (0.283)	loss 6.585 (6.871)	prob 2.436 (2.546)	GS 34.375 (33.458)	mem 72.592
Train: [88][940/1500]	BT 0.031 (0.319)	DT 0.000 (0.280)	loss 6.845 (6.882)	prob 2.710 (2.644)	GS 32.328 (33.102)	mem 72.589
Train: [88][950/1500]	BT 0.039 (0.316)	DT 0.001 (0.277)	loss 6.728 (6.863)	prob 3.299 (2.639)	GS 31.125 (33.005)	mem 72.591
Train: [88][960/1500]	BT 0.030 (0.319)	DT 0.000 (0.280)	loss 7.046 (6.907)	prob 2.569 (2.577)	GS 31.922 (33.944)	mem 72.590
Train: [88][970/1500]	BT 0.028 (0.316)	DT 0.001 (0.278)	loss 6.733 (6.866)	prob 3.311 (2.593)	GS 34.688 (33.457)	mem 72.590
Train: [88][980/1500]	BT 0.028 (0.316)	DT 0.000 (0.278)	loss 7.289 (6.898)	prob 2.421 (2.613)	GS 34.734 (33.325)	mem 72.592
Train: [88][990/1500]	BT 0.039 (0.313)	DT 0.001 (0.275)	loss 6.976 (6.899)	prob 2.903 (2.638)	GS 33.062 (33.336)	mem 72.592
Train: [88][1000/1500]	BT 0.040 (0.313)	DT 0.001 (0.275)	loss 6.852 (6.888)	prob 2.172 (2.608)	GS 38.688 (33.107)	mem 72.593
Train: [88][1010/1500]	BT 0.039 (0.311)	DT 0.001 (0.273)	loss 6.945 (6.900)	prob 2.758 (2.531)	GS 33.078 (32.827)	mem 72.592
Train: [88][1020/1500]	BT 0.039 (0.308)	DT 0.001 (0.270)	loss 6.705 (6.857)	prob 2.730 (2.562)	GS 31.906 (31.897)	mem 72.592
Train: [88][1030/1500]	BT 0.037 (0.308)	DT 0.001 (0.270)	loss 6.852 (6.868)	prob 2.874 (2.508)	GS 35.016 (31.879)	mem 72.589
Train: [88][1040/1500]	BT 0.038 (0.306)	DT 0.001 (0.268)	loss 6.778 (6.891)	prob 2.994 (2.540)	GS 31.984 (31.884)	mem 72.589
Train: [88][1050/1500]	BT 0.036 (0.309)	DT 0.001 (0.271)	loss 7.048 (6.874)	prob 2.290 (2.502)	GS 36.891 (32.126)	mem 72.612
Train: [88][1060/1500]	BT 0.038 (0.306)	DT 0.001 (0.268)	loss 7.161 (6.794)	prob 2.330 (2.646)	GS 34.844 (33.366)	mem 72.612
Train: [88][1070/1500]	BT 0.037 (0.304)	DT 0.001 (0.266)	loss 7.099 (6.819)	prob 2.044 (2.538)	GS 32.953 (32.490)	mem 72.613
Train: [88][1080/1500]	BT 0.037 (0.304)	DT 0.001 (0.266)	loss 7.207 (6.828)	prob 2.241 (2.551)	GS 33.438 (32.850)	mem 72.631
Train: [88][1090/1500]	BT 0.037 (0.302)	DT 0.001 (0.264)	loss 6.942 (6.857)	prob 2.371 (2.522)	GS 34.203 (32.932)	mem 72.631
Train: [88][1100/1500]	BT 0.037 (0.302)	DT 0.001 (0.264)	loss 6.767 (6.856)	prob 2.394 (2.427)	GS 30.812 (32.781)	mem 72.513
Train: [88][1110/1500]	BT 0.100 (0.301)	DT 0.001 (0.262)	loss 6.819 (6.879)	prob 3.192 (2.691)	GS 35.250 (33.062)	mem 72.513
Train: [88][1120/1500]	BT 0.058 (0.301)	DT 0.002 (0.263)	loss 6.826 (6.897)	prob 3.061 (2.707)	GS 34.156 (33.384)	mem 72.515
Train: [88][1130/1500]	BT 0.072 (0.299)	DT 0.002 (0.260)	loss 6.821 (6.863)	prob 3.016 (2.683)	GS 33.266 (33.133)	mem 72.517
Train: [88][1140/1500]	BT 0.028 (0.299)	DT 0.000 (0.261)	loss 6.866 (6.843)	prob 1.896 (2.648)	GS 40.141 (33.049)	mem 72.515
Train: [88][1150/1500]	BT 0.037 (0.299)	DT 0.001 (0.261)	loss 6.857 (6.827)	prob 2.405 (2.666)	GS 34.703 (33.055)	mem 72.516
Train: [88][1160/1500]	BT 0.064 (0.299)	DT 0.014 (0.261)	loss 6.701 (6.840)	prob 2.649 (2.674)	GS 31.766 (32.405)	mem 72.518
Train: [88][1170/1500]	BT 1.087 (0.298)	DT 1.048 (0.260)	loss 6.841 (6.827)	prob 3.978 (2.796)	GS 32.500 (32.299)	mem 72.518
Train: [88][1180/1500]	BT 0.037 (0.299)	DT 0.001 (0.261)	loss 7.070 (6.847)	prob 2.436 (2.760)	GS 35.391 (32.835)	mem 72.538
Train: [88][1190/1500]	BT 0.038 (0.297)	DT 0.000 (0.259)	loss 6.799 (6.863)	prob 3.055 (2.750)	GS 33.219 (32.787)	mem 72.539
Train: [88][1200/1500]	BT 0.038 (0.297)	DT 0.001 (0.258)	loss 7.097 (6.848)	prob 1.994 (2.792)	GS 34.484 (32.843)	mem 72.539
Train: [88][1210/1500]	BT 0.038 (0.295)	DT 0.001 (0.257)	loss 6.763 (6.789)	prob 2.936 (2.725)	GS 29.547 (33.709)	mem 72.540
Train: [88][1220/1500]	BT 0.038 (0.297)	DT 0.001 (0.258)	loss 6.714 (6.812)	prob 3.380 (2.727)	GS 36.250 (34.046)	mem 72.525
Train: [88][1230/1500]	BT 0.031 (0.295)	DT 0.001 (0.256)	loss 7.205 (6.828)	prob 2.583 (2.661)	GS 30.062 (33.749)	mem 72.525
Train: [88][1240/1500]	BT 0.039 (0.293)	DT 0.001 (0.255)	loss 7.059 (6.853)	prob 3.086 (2.691)	GS 33.734 (33.630)	mem 72.527
Train: [88][1250/1500]	BT 0.039 (0.296)	DT 0.001 (0.258)	loss 6.861 (6.830)	prob 2.524 (2.753)	GS 29.500 (33.249)	mem 72.527
Train: [88][1260/1500]	BT 0.039 (0.294)	DT 0.001 (0.256)	loss 7.002 (6.929)	prob 2.188 (2.413)	GS 34.156 (32.703)	mem 72.527
Train: [88][1270/1500]	BT 0.031 (0.298)	DT 0.000 (0.260)	loss 6.831 (6.880)	prob 2.464 (2.518)	GS 29.703 (32.128)	mem 72.527
Train: [88][1280/1500]	BT 0.077 (0.296)	DT 0.004 (0.258)	loss 6.616 (6.851)	prob 2.774 (2.536)	GS 34.922 (31.951)	mem 72.528
Train: [88][1290/1500]	BT 0.029 (0.298)	DT 0.000 (0.259)	loss 6.657 (6.840)	prob 3.034 (2.624)	GS 37.453 (32.439)	mem 72.527
Train: [88][1300/1500]	BT 0.064 (0.296)	DT 0.006 (0.257)	loss 6.752 (6.852)	prob 2.863 (2.620)	GS 31.172 (32.193)	mem 72.526
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [88][1310/1500]	BT 0.048 (0.294)	DT 0.001 (0.256)	loss 6.698 (6.821)	prob 2.735 (2.729)	GS 33.406 (32.398)	mem 72.526
Train: [88][1320/1500]	BT 0.033 (0.299)	DT 0.000 (0.261)	loss 6.949 (6.810)	prob 2.792 (2.698)	GS 32.484 (32.040)	mem 72.524
Train: [88][1330/1500]	BT 0.022 (0.306)	DT 0.000 (0.267)	loss 6.708 (6.792)	prob 2.818 (2.827)	GS 33.391 (32.269)	mem 72.525
Train: [88][1340/1500]	BT 0.030 (0.304)	DT 0.000 (0.265)	loss 6.775 (6.817)	prob 2.399 (2.783)	GS 32.703 (32.636)	mem 72.526
Train: [88][1350/1500]	BT 0.039 (0.302)	DT 0.001 (0.263)	loss 6.962 (6.845)	prob 2.905 (2.708)	GS 33.141 (32.483)	mem 72.528
Train: [88][1360/1500]	BT 0.034 (0.303)	DT 0.000 (0.264)	loss 6.705 (6.842)	prob 2.025 (2.507)	GS 36.859 (32.045)	mem 72.541
Train: [88][1370/1500]	BT 0.037 (0.301)	DT 0.001 (0.262)	loss 6.724 (6.868)	prob 2.607 (2.691)	GS 34.953 (32.613)	mem 72.542
Train: [88][1380/1500]	BT 0.036 (0.301)	DT 0.001 (0.263)	loss 6.850 (6.845)	prob 2.781 (2.742)	GS 36.219 (32.451)	mem 72.546
Train: [88][1390/1500]	BT 0.078 (0.299)	DT 0.008 (0.261)	loss 6.879 (6.827)	prob 2.196 (2.692)	GS 33.516 (32.913)	mem 72.547
Train: [88][1400/1500]	BT 5.741 (0.302)	DT 5.712 (0.263)	loss 6.858 (6.832)	prob 2.723 (2.625)	GS 36.375 (32.943)	mem 72.548
Train: [88][1410/1500]	BT 0.035 (0.300)	DT 0.000 (0.261)	loss 6.853 (6.777)	prob 2.625 (2.744)	GS 34.172 (32.245)	mem 72.550
Train: [88][1420/1500]	BT 0.036 (0.298)	DT 0.001 (0.259)	loss 6.880 (6.805)	prob 3.058 (2.744)	GS 35.328 (32.805)	mem 72.551
Train: [88][1430/1500]	BT 0.036 (0.298)	DT 0.001 (0.260)	loss 6.885 (6.809)	prob 2.626 (2.716)	GS 36.812 (32.417)	mem 72.553
Train: [88][1440/1500]	BT 0.040 (0.296)	DT 0.001 (0.258)	loss 6.805 (6.798)	prob 3.201 (2.739)	GS 32.500 (32.387)	mem 72.554
Train: [88][1450/1500]	BT 0.053 (0.298)	DT 0.014 (0.260)	loss 7.008 (6.814)	prob 1.993 (2.725)	GS 36.750 (32.586)	mem 72.481
Train: [88][1460/1500]	BT 0.033 (0.297)	DT 0.001 (0.258)	loss 6.999 (6.805)	prob 2.476 (2.587)	GS 35.609 (31.355)	mem 72.481
Train: [88][1470/1500]	BT 0.027 (0.301)	DT 0.000 (0.262)	loss 6.745 (6.815)	prob 2.590 (2.598)	GS 35.828 (32.114)	mem 71.416
Train: [88][1480/1500]	BT 0.019 (0.299)	DT 0.000 (0.260)	loss 6.741 (6.815)	prob 2.225 (2.574)	GS 31.859 (32.224)	mem 71.379
Train: [88][1490/1500]	BT 0.025 (0.299)	DT 0.000 (0.260)	loss 6.520 (6.822)	prob 2.860 (2.524)	GS 38.531 (32.301)	mem 7.534
Train: [88][1500/1500]	BT 0.026 (0.297)	DT 0.000 (0.258)	loss 6.522 (6.815)	prob 2.548 (2.518)	GS 37.375 (32.472)	mem 7.534
Train: [88][1510/1500]	BT 0.023 (0.295)	DT 0.000 (0.257)	loss 6.967 (6.667)	prob 1.885 (2.571)	GS 33.844 (31.472)	mem 7.533
epoch 88, total time 446.47
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [89][1/1500]	BT 27.637 (27.637)	DT 27.567 (27.567)	loss 6.731 (6.731)	prob 2.803 (2.803)	GS 35.172 (35.172)	mem 71.193
Train: [89][10/1500]	BT 0.066 (2.822)	DT 0.014 (2.768)	loss 6.697 (6.563)	prob 2.520 (2.757)	GS 36.938 (34.297)	mem 71.210
Train: [89][20/1500]	BT 8.988 (1.888)	DT 8.946 (1.837)	loss 6.713 (6.607)	prob 2.552 (2.668)	GS 39.703 (34.400)	mem 71.275
Train: [89][30/1500]	BT 0.023 (1.270)	DT 0.000 (1.225)	loss 6.776 (6.642)	prob 3.262 (2.625)	GS 37.609 (33.649)	mem 71.280
Train: [89][40/1500]	BT 0.025 (0.959)	DT 0.000 (0.919)	loss 6.608 (6.669)	prob 2.389 (2.610)	GS 32.703 (33.208)	mem 71.281
Train: [89][50/1500]	BT 0.033 (0.943)	DT 0.001 (0.905)	loss 6.526 (6.677)	prob 2.992 (2.627)	GS 33.297 (33.001)	mem 71.334
Train: [89][60/1500]	BT 0.050 (0.792)	DT 0.008 (0.754)	loss 6.702 (6.803)	prob 3.363 (2.401)	GS 27.547 (33.212)	mem 71.334
Train: [89][70/1500]	BT 0.029 (0.774)	DT 0.000 (0.736)	loss 7.037 (6.837)	prob 3.021 (2.669)	GS 31.359 (32.459)	mem 71.342
Train: [89][80/1500]	BT 0.033 (0.681)	DT 0.000 (0.644)	loss 7.007 (6.838)	prob 2.197 (2.644)	GS 35.734 (32.511)	mem 71.343
Train: [89][90/1500]	BT 0.049 (0.610)	DT 0.003 (0.573)	loss 6.840 (6.849)	prob 3.154 (2.642)	GS 33.750 (32.518)	mem 71.343
Train: [89][100/1500]	BT 0.030 (0.621)	DT 0.000 (0.584)	loss 6.706 (6.839)	prob 2.449 (2.654)	GS 35.391 (32.648)	mem 72.186
Train: [89][110/1500]	BT 0.064 (0.568)	DT 0.003 (0.531)	loss 6.820 (6.770)	prob 2.928 (2.740)	GS 36.109 (31.491)	mem 72.287
Train: [89][120/1500]	BT 0.031 (0.584)	DT 0.000 (0.547)	loss 6.822 (6.761)	prob 2.796 (2.654)	GS 34.281 (32.219)	mem 72.438
Train: [89][130/1500]	BT 0.047 (0.542)	DT 0.001 (0.505)	loss 6.744 (6.766)	prob 2.413 (2.621)	GS 33.062 (32.420)	mem 72.439
Train: [89][140/1500]	BT 0.028 (0.550)	DT 0.000 (0.513)	loss 6.711 (6.768)	prob 2.719 (2.645)	GS 31.703 (32.788)	mem 72.537
Train: [89][150/1500]	BT 0.036 (0.515)	DT 0.000 (0.479)	loss 6.820 (6.784)	prob 2.692 (2.715)	GS 32.766 (32.727)	mem 72.538
Train: [89][160/1500]	BT 0.024 (0.503)	DT 0.000 (0.467)	loss 6.668 (6.818)	prob 3.278 (2.839)	GS 33.297 (33.481)	mem 72.543
Train: [89][170/1500]	BT 0.034 (0.475)	DT 0.000 (0.439)	loss 6.767 (6.791)	prob 2.942 (2.729)	GS 31.797 (32.700)	mem 72.544
Train: [89][180/1500]	BT 0.037 (0.450)	DT 0.001 (0.415)	loss 6.884 (6.802)	prob 2.750 (2.854)	GS 34.719 (32.418)	mem 72.544
Train: [89][190/1500]	BT 0.036 (0.448)	DT 0.000 (0.412)	loss 7.151 (6.802)	prob 2.214 (2.836)	GS 36.578 (32.686)	mem 72.551
Train: [89][200/1500]	BT 0.075 (0.430)	DT 0.001 (0.392)	loss 7.123 (6.804)	prob 1.410 (2.823)	GS 32.156 (32.568)	mem 72.552
Train: [89][210/1500]	BT 0.064 (0.475)	DT 0.011 (0.437)	loss 6.708 (6.784)	prob 2.814 (3.049)	GS 36.406 (32.248)	mem 72.552
Train: [89][220/1500]	BT 0.032 (0.510)	DT 0.000 (0.473)	loss 6.977 (6.801)	prob 2.834 (3.088)	GS 35.938 (32.861)	mem 72.559
Train: [89][230/1500]	BT 0.032 (0.489)	DT 0.000 (0.452)	loss 6.761 (6.810)	prob 3.302 (3.126)	GS 35.609 (33.351)	mem 72.562
Train: [89][240/1500]	BT 0.038 (0.481)	DT 0.001 (0.444)	loss 6.958 (6.812)	prob 2.251 (3.105)	GS 36.250 (33.437)	mem 72.566
Train: [89][250/1500]	BT 0.038 (0.463)	DT 0.001 (0.426)	loss 6.694 (6.802)	prob 3.006 (3.062)	GS 32.438 (33.181)	mem 72.566
Train: [89][260/1500]	BT 0.031 (0.475)	DT 0.001 (0.437)	loss 6.823 (6.846)	prob 2.953 (2.719)	GS 34.219 (34.697)	mem 72.597
Train: [89][270/1500]	BT 0.030 (0.458)	DT 0.000 (0.421)	loss 6.806 (6.825)	prob 2.015 (2.851)	GS 33.578 (33.498)	mem 72.600
Train: [89][280/1500]	BT 0.080 (0.443)	DT 0.007 (0.406)	loss 6.788 (6.824)	prob 3.545 (3.023)	GS 33.250 (33.242)	mem 72.600
Train: [89][290/1500]	BT 0.034 (0.456)	DT 0.001 (0.419)	loss 6.703 (6.811)	prob 3.472 (3.045)	GS 29.562 (33.120)	mem 72.600
Train: [89][300/1500]	BT 0.038 (0.443)	DT 0.001 (0.405)	loss 6.776 (6.820)	prob 3.057 (3.115)	GS 29.453 (33.184)	mem 72.602
Train: [89][310/1500]	BT 0.062 (0.443)	DT 0.001 (0.405)	loss 6.601 (6.774)	prob 3.486 (3.291)	GS 36.156 (31.633)	mem 72.606
Train: [89][320/1500]	BT 0.071 (0.431)	DT 0.011 (0.392)	loss 6.938 (6.797)	prob 2.506 (3.224)	GS 35.156 (32.453)	mem 72.606
Train: [89][330/1500]	BT 0.051 (0.422)	DT 0.001 (0.384)	loss 6.928 (6.782)	prob 2.921 (3.221)	GS 30.344 (31.929)	mem 72.606
Train: [89][340/1500]	BT 0.033 (0.430)	DT 0.001 (0.391)	loss 6.741 (6.771)	prob 3.140 (3.225)	GS 32.406 (32.309)	mem 72.609
Train: [89][350/1500]	BT 0.084 (0.420)	DT 0.004 (0.381)	loss 6.944 (6.783)	prob 3.023 (3.193)	GS 31.047 (32.572)	mem 72.608
Train: [89][360/1500]	BT 0.025 (0.430)	DT 0.000 (0.390)	loss 6.658 (6.807)	prob 3.518 (3.649)	GS 33.375 (32.758)	mem 72.610
Train: [89][370/1500]	BT 0.048 (0.419)	DT 0.001 (0.380)	loss 6.713 (6.844)	prob 4.393 (3.522)	GS 30.516 (33.642)	mem 72.611
Train: [89][380/1500]	BT 0.039 (0.421)	DT 0.001 (0.381)	loss 6.870 (6.861)	prob 3.790 (3.467)	GS 34.031 (32.731)	mem 72.611
Train: [89][390/1500]	BT 0.028 (0.416)	DT 0.000 (0.376)	loss 7.117 (6.879)	prob 3.370 (3.387)	GS 39.281 (33.226)	mem 72.612
Train: [89][400/1500]	BT 0.038 (0.406)	DT 0.000 (0.367)	loss 6.828 (6.876)	prob 4.571 (3.374)	GS 35.578 (33.236)	mem 72.613
Train: [89][410/1500]	BT 0.038 (0.399)	DT 0.001 (0.360)	loss 6.718 (6.837)	prob 3.691 (3.504)	GS 29.703 (33.413)	mem 72.614
Train: [89][420/1500]	BT 0.040 (0.397)	DT 0.001 (0.358)	loss 6.694 (6.874)	prob 3.308 (3.366)	GS 32.656 (32.491)	mem 72.612
Train: [89][430/1500]	BT 0.041 (0.392)	DT 0.001 (0.353)	loss 6.943 (6.864)	prob 2.997 (3.365)	GS 28.641 (32.723)	mem 72.613
Train: [89][440/1500]	BT 0.043 (0.394)	DT 0.000 (0.355)	loss 6.740 (6.861)	prob 3.044 (3.418)	GS 36.969 (33.032)	mem 72.614
Train: [89][450/1500]	BT 0.039 (0.386)	DT 0.001 (0.347)	loss 6.809 (6.855)	prob 3.412 (3.385)	GS 33.359 (32.999)	mem 72.616
Train: [89][460/1500]	BT 0.039 (0.384)	DT 0.000 (0.345)	loss 6.998 (6.834)	prob 3.510 (3.492)	GS 36.875 (31.845)	mem 72.616
Train: [89][470/1500]	BT 0.028 (0.381)	DT 0.000 (0.342)	loss 6.966 (6.829)	prob 3.356 (3.362)	GS 32.281 (31.395)	mem 72.615
Train: [89][480/1500]	BT 0.039 (0.374)	DT 0.001 (0.335)	loss 6.756 (6.836)	prob 3.061 (3.250)	GS 28.297 (30.808)	mem 72.617
Train: [89][490/1500]	BT 0.038 (0.373)	DT 0.001 (0.334)	loss 6.906 (6.839)	prob 3.472 (3.251)	GS 35.016 (31.411)	mem 72.617
Train: [89][500/1500]	BT 0.039 (0.366)	DT 0.001 (0.328)	loss 6.824 (6.832)	prob 2.080 (3.192)	GS 32.391 (31.335)	mem 72.617
Train: [89][510/1500]	BT 0.034 (0.367)	DT 0.001 (0.329)	loss 7.259 (6.843)	prob 3.195 (2.956)	GS 34.125 (32.036)	mem 72.619
Train: [89][520/1500]	BT 0.036 (0.361)	DT 0.000 (0.322)	loss 6.742 (6.859)	prob 2.552 (3.100)	GS 38.297 (32.602)	mem 72.618
Train: [89][530/1500]	BT 0.035 (0.356)	DT 0.001 (0.317)	loss 6.848 (6.853)	prob 2.879 (3.100)	GS 34.484 (32.757)	mem 72.619
Train: [89][540/1500]	BT 0.037 (0.355)	DT 0.001 (0.316)	loss 6.783 (6.839)	prob 2.834 (3.121)	GS 35.047 (32.903)	mem 72.619
Train: [89][550/1500]	BT 0.037 (0.351)	DT 0.001 (0.312)	loss 6.744 (6.838)	prob 2.275 (3.106)	GS 32.859 (32.941)	mem 72.621
Train: [89][560/1500]	BT 0.034 (0.356)	DT 0.001 (0.318)	loss 6.687 (6.861)	prob 3.651 (3.157)	GS 32.812 (33.025)	mem 72.626
Train: [89][570/1500]	BT 0.037 (0.350)	DT 0.000 (0.312)	loss 6.692 (6.824)	prob 3.086 (3.119)	GS 35.031 (32.545)	mem 72.627
Train: [89][580/1500]	BT 3.651 (0.351)	DT 3.615 (0.313)	loss 6.865 (6.815)	prob 2.983 (3.088)	GS 35.562 (32.487)	mem 72.636
Train: [89][590/1500]	BT 0.038 (0.351)	DT 0.000 (0.313)	loss 7.159 (6.819)	prob 2.133 (3.022)	GS 38.609 (32.723)	mem 72.638
Train: [89][600/1500]	BT 0.038 (0.346)	DT 0.001 (0.307)	loss 6.715 (6.799)	prob 3.616 (3.074)	GS 36.266 (32.992)	mem 72.638
Train: [89][610/1500]	BT 0.037 (0.348)	DT 0.001 (0.309)	loss 6.679 (6.802)	prob 2.473 (2.909)	GS 31.922 (32.906)	mem 72.536
Train: [89][620/1500]	BT 0.031 (0.343)	DT 0.000 (0.304)	loss 6.843 (6.829)	prob 2.717 (2.971)	GS 35.016 (32.966)	mem 72.537
Train: [89][630/1500]	BT 0.038 (0.342)	DT 0.001 (0.304)	loss 6.655 (6.813)	prob 3.340 (2.994)	GS 36.797 (32.947)	mem 72.537
Train: [89][640/1500]	BT 0.037 (0.338)	DT 0.000 (0.300)	loss 6.908 (6.823)	prob 2.706 (2.991)	GS 33.312 (32.867)	mem 72.537
Train: [89][650/1500]	BT 0.037 (0.334)	DT 0.001 (0.296)	loss 6.761 (6.813)	prob 2.135 (2.947)	GS 35.406 (32.596)	mem 72.537
Train: [89][660/1500]	BT 0.037 (0.334)	DT 0.001 (0.295)	loss 6.786 (6.835)	prob 2.653 (2.727)	GS 32.875 (32.072)	mem 72.535
Train: [89][670/1500]	BT 0.041 (0.331)	DT 0.001 (0.293)	loss 6.790 (6.827)	prob 3.084 (2.607)	GS 37.703 (32.622)	mem 72.537
Train: [89][680/1500]	BT 0.034 (0.332)	DT 0.001 (0.294)	loss 6.888 (6.802)	prob 2.909 (2.601)	GS 37.375 (32.616)	mem 72.540
Train: [89][690/1500]	BT 0.057 (0.330)	DT 0.011 (0.292)	loss 6.600 (6.791)	prob 2.808 (2.567)	GS 34.359 (32.404)	mem 72.541
Train: [89][700/1500]	BT 0.038 (0.330)	DT 0.000 (0.292)	loss 6.938 (6.799)	prob 2.322 (2.501)	GS 35.562 (32.383)	mem 72.562
Train: [89][710/1500]	BT 0.031 (0.328)	DT 0.000 (0.289)	loss 6.646 (6.755)	prob 2.520 (2.587)	GS 35.438 (31.669)	mem 72.563
Train: [89][720/1500]	BT 0.036 (0.324)	DT 0.001 (0.285)	loss 6.716 (6.758)	prob 2.827 (2.585)	GS 36.250 (31.970)	mem 72.563
Train: [89][730/1500]	BT 0.036 (0.324)	DT 0.001 (0.285)	loss 6.862 (6.758)	prob 2.887 (2.573)	GS 36.859 (32.859)	mem 72.563
Train: [89][740/1500]	BT 0.065 (0.323)	DT 0.013 (0.284)	loss 6.843 (6.772)	prob 1.599 (2.517)	GS 31.016 (32.747)	mem 72.567
Train: [89][750/1500]	BT 0.064 (0.324)	DT 0.006 (0.285)	loss 6.759 (6.783)	prob 2.722 (2.474)	GS 32.641 (32.797)	mem 72.550
Train: [89][760/1500]	BT 0.038 (0.324)	DT 0.001 (0.286)	loss 6.800 (6.790)	prob 2.133 (2.453)	GS 36.031 (33.827)	mem 72.552
Train: [89][770/1500]	BT 0.038 (0.322)	DT 0.001 (0.283)	loss 6.785 (6.800)	prob 2.355 (2.489)	GS 33.719 (32.697)	mem 72.553
Train: [89][780/1500]	BT 0.039 (0.318)	DT 0.001 (0.280)	loss 6.757 (6.780)	prob 2.607 (2.453)	GS 30.641 (32.487)	mem 72.554
Train: [89][790/1500]	BT 0.038 (0.320)	DT 0.001 (0.281)	loss 6.952 (6.772)	prob 1.838 (2.376)	GS 31.031 (32.477)	mem 72.556
Train: [89][800/1500]	BT 0.040 (0.316)	DT 0.001 (0.278)	loss 6.733 (6.772)	prob 1.848 (2.397)	GS 32.359 (32.244)	mem 72.557
Train: [89][810/1500]	BT 0.038 (0.319)	DT 0.000 (0.281)	loss 6.781 (6.771)	prob 1.959 (2.409)	GS 33.125 (31.144)	mem 72.555
Train: [89][820/1500]	BT 0.039 (0.316)	DT 0.001 (0.277)	loss 6.742 (6.775)	prob 2.341 (2.352)	GS 38.422 (31.674)	mem 72.556
Train: [89][830/1500]	BT 0.040 (0.313)	DT 0.001 (0.274)	loss 6.804 (6.772)	prob 2.338 (2.327)	GS 34.797 (32.049)	mem 72.556
Train: [89][840/1500]	BT 0.052 (0.313)	DT 0.014 (0.275)	loss 6.716 (6.783)	prob 3.031 (2.304)	GS 30.188 (32.252)	mem 72.556
Train: [89][850/1500]	BT 0.077 (0.310)	DT 0.001 (0.272)	loss 6.694 (6.789)	prob 2.818 (2.315)	GS 32.016 (32.260)	mem 72.555
Train: [89][860/1500]	BT 0.072 (0.317)	DT 0.013 (0.279)	loss 6.642 (6.749)	prob 2.171 (2.388)	GS 33.141 (32.436)	mem 72.554
Train: [89][870/1500]	BT 0.058 (0.315)	DT 0.011 (0.276)	loss 6.737 (6.751)	prob 2.029 (2.287)	GS 38.156 (32.762)	mem 72.554
Train: [89][880/1500]	BT 0.045 (0.322)	DT 0.000 (0.283)	loss 6.551 (6.752)	prob 3.028 (2.330)	GS 35.125 (32.940)	mem 72.551
Train: [89][890/1500]	BT 0.029 (0.319)	DT 0.000 (0.280)	loss 6.830 (6.751)	prob 2.517 (2.389)	GS 32.641 (32.760)	mem 72.552
Train: [89][900/1500]	BT 0.072 (0.324)	DT 0.005 (0.285)	loss 6.706 (6.760)	prob 2.751 (2.378)	GS 32.734 (32.854)	mem 72.554
Train: [89][910/1500]	BT 0.071 (0.321)	DT 0.006 (0.282)	loss 6.738 (6.765)	prob 2.536 (2.392)	GS 35.500 (32.541)	mem 72.554
Train: [89][920/1500]	BT 0.063 (0.338)	DT 0.006 (0.298)	loss 6.883 (6.774)	prob 2.514 (2.349)	GS 32.953 (32.695)	mem 72.553
Train: [89][930/1500]	BT 0.075 (0.335)	DT 0.002 (0.295)	loss 6.845 (6.786)	prob 2.262 (2.443)	GS 32.938 (32.899)	mem 72.554
Train: [89][940/1500]	BT 0.116 (0.345)	DT 0.011 (0.305)	loss 6.847 (6.779)	prob 1.921 (2.444)	GS 34.391 (32.991)	mem 72.557
Train: [89][950/1500]	BT 0.118 (0.343)	DT 0.006 (0.302)	loss 6.643 (6.765)	prob 2.224 (2.437)	GS 33.953 (32.970)	mem 72.557
Train: [89][960/1500]	BT 0.029 (0.358)	DT 0.000 (0.317)	loss 6.808 (6.769)	prob 2.358 (2.188)	GS 30.906 (32.386)	mem 72.572
Train: [89][970/1500]	BT 0.030 (0.355)	DT 0.000 (0.314)	loss 6.776 (6.794)	prob 3.298 (2.427)	GS 32.375 (33.836)	mem 72.574
Train: [89][980/1500]	BT 3.104 (0.355)	DT 3.067 (0.314)	loss 6.640 (6.776)	prob 2.717 (2.473)	GS 35.109 (33.799)	mem 72.577
Train: [89][990/1500]	BT 0.037 (0.351)	DT 0.000 (0.311)	loss 6.787 (6.773)	prob 2.343 (2.433)	GS 34.141 (33.507)	mem 72.577
Train: [89][1000/1500]	BT 0.028 (0.348)	DT 0.000 (0.307)	loss 6.662 (6.767)	prob 1.935 (2.413)	GS 35.891 (33.278)	mem 72.578
Train: [89][1010/1500]	BT 0.036 (0.351)	DT 0.001 (0.310)	loss 6.900 (6.714)	prob 2.375 (2.526)	GS 29.766 (32.527)	mem 72.579
Train: [89][1020/1500]	BT 0.037 (0.348)	DT 0.000 (0.307)	loss 6.781 (6.722)	prob 1.998 (2.415)	GS 33.516 (32.217)	mem 72.579
Train: [89][1030/1500]	BT 0.041 (0.348)	DT 0.001 (0.307)	loss 6.862 (6.721)	prob 2.823 (2.410)	GS 28.406 (31.876)	mem 72.582
Train: [89][1040/1500]	BT 0.080 (0.345)	DT 0.006 (0.304)	loss 6.725 (6.735)	prob 2.652 (2.405)	GS 35.234 (32.112)	mem 72.583
Train: [89][1050/1500]	BT 0.059 (0.342)	DT 0.011 (0.301)	loss 6.769 (6.748)	prob 3.354 (2.452)	GS 36.500 (32.371)	mem 72.583
Train: [89][1060/1500]	BT 0.050 (0.343)	DT 0.015 (0.302)	loss 6.772 (6.716)	prob 2.760 (2.729)	GS 33.438 (31.811)	mem 72.585
Train: [89][1070/1500]	BT 0.040 (0.340)	DT 0.011 (0.299)	loss 7.048 (6.737)	prob 2.495 (2.722)	GS 34.906 (31.925)	mem 72.586
Train: [89][1080/1500]	BT 0.037 (0.342)	DT 0.001 (0.301)	loss 6.750 (6.736)	prob 2.520 (2.718)	GS 38.297 (32.309)	mem 72.589
Train: [89][1090/1500]	BT 0.037 (0.339)	DT 0.001 (0.298)	loss 6.708 (6.754)	prob 2.358 (2.753)	GS 34.641 (32.578)	mem 72.590
Train: [89][1100/1500]	BT 2.909 (0.339)	DT 2.871 (0.298)	loss 6.755 (6.756)	prob 3.079 (2.763)	GS 32.156 (32.504)	mem 72.591
Train: [89][1110/1500]	BT 0.037 (0.336)	DT 0.000 (0.296)	loss 6.740 (6.715)	prob 2.592 (2.782)	GS 31.234 (30.998)	mem 72.592
Train: [89][1120/1500]	BT 0.047 (0.334)	DT 0.010 (0.293)	loss 6.662 (6.721)	prob 3.512 (2.713)	GS 31.734 (32.225)	mem 72.592
Train: [89][1130/1500]	BT 0.037 (0.334)	DT 0.001 (0.293)	loss 6.780 (6.714)	prob 2.728 (2.653)	GS 31.766 (32.210)	mem 72.593
Train: [89][1140/1500]	BT 0.038 (0.331)	DT 0.001 (0.290)	loss 6.630 (6.712)	prob 2.369 (2.626)	GS 37.609 (32.187)	mem 72.593
Train: [89][1150/1500]	BT 2.143 (0.333)	DT 2.107 (0.292)	loss 6.646 (6.718)	prob 2.373 (2.599)	GS 32.219 (32.040)	mem 72.595
Train: [89][1160/1500]	BT 0.037 (0.330)	DT 0.000 (0.290)	loss 6.654 (6.749)	prob 1.836 (2.388)	GS 37.344 (33.178)	mem 72.596
Train: [89][1170/1500]	BT 0.058 (0.328)	DT 0.021 (0.287)	loss 6.624 (6.716)	prob 2.641 (2.448)	GS 37.594 (32.871)	mem 72.595
Train: [89][1180/1500]	BT 0.039 (0.330)	DT 0.001 (0.289)	loss 6.832 (6.728)	prob 2.808 (2.510)	GS 34.719 (32.640)	mem 72.599
Train: [89][1190/1500]	BT 0.024 (0.327)	DT 0.000 (0.287)	loss 6.901 (6.740)	prob 2.552 (2.507)	GS 32.984 (32.823)	mem 72.602
Train: [89][1200/1500]	BT 0.036 (0.329)	DT 0.001 (0.289)	loss 6.903 (6.742)	prob 2.224 (2.437)	GS 34.031 (32.724)	mem 72.602
Train: [89][1210/1500]	BT 0.028 (0.327)	DT 0.000 (0.286)	loss 6.851 (6.683)	prob 2.428 (2.426)	GS 31.625 (32.420)	mem 72.603
Train: [89][1220/1500]	BT 0.038 (0.324)	DT 0.001 (0.284)	loss 6.850 (6.722)	prob 1.707 (2.246)	GS 36.828 (33.904)	mem 72.604
Train: [89][1230/1500]	BT 0.038 (0.325)	DT 0.001 (0.284)	loss 7.081 (6.729)	prob 1.967 (2.219)	GS 35.594 (33.851)	mem 72.606
Train: [89][1240/1500]	BT 0.037 (0.322)	DT 0.001 (0.282)	loss 6.746 (6.728)	prob 2.051 (2.201)	GS 32.609 (33.380)	mem 72.606
Train: [89][1250/1500]	BT 0.052 (0.325)	DT 0.010 (0.285)	loss 6.767 (6.738)	prob 2.835 (2.220)	GS 29.250 (33.256)	mem 72.603
Train: [89][1260/1500]	BT 0.035 (0.327)	DT 0.000 (0.287)	loss 6.674 (6.686)	prob 2.297 (2.713)	GS 34.969 (34.692)	mem 72.603
Train: [89][1270/1500]	BT 0.038 (0.325)	DT 0.001 (0.285)	loss 6.711 (6.702)	prob 2.399 (2.569)	GS 32.109 (33.123)	mem 72.602
Train: [89][1280/1500]	BT 0.038 (0.323)	DT 0.000 (0.283)	loss 6.746 (6.683)	prob 1.782 (2.547)	GS 34.891 (33.330)	mem 72.602
Train: [89][1290/1500]	BT 0.049 (0.323)	DT 0.001 (0.283)	loss 6.877 (6.684)	prob 2.524 (2.513)	GS 32.531 (33.418)	mem 72.635
Train: [89][1300/1500]	BT 0.040 (0.322)	DT 0.001 (0.282)	loss 6.580 (6.693)	prob 2.551 (2.491)	GS 34.078 (33.131)	mem 72.636
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [89][1310/1500]	BT 0.041 (0.322)	DT 0.001 (0.282)	loss 6.627 (6.671)	prob 2.568 (2.466)	GS 33.922 (31.820)	mem 72.636
Train: [89][1320/1500]	BT 0.038 (0.321)	DT 0.001 (0.281)	loss 6.645 (6.701)	prob 2.361 (2.460)	GS 32.547 (31.702)	mem 72.636
Train: [89][1330/1500]	BT 0.039 (0.319)	DT 0.000 (0.279)	loss 6.692 (6.698)	prob 1.960 (2.366)	GS 37.438 (31.758)	mem 72.636
Train: [89][1340/1500]	BT 0.032 (0.320)	DT 0.001 (0.281)	loss 6.610 (6.694)	prob 2.522 (2.335)	GS 34.969 (31.561)	mem 72.637
Train: [89][1350/1500]	BT 0.039 (0.320)	DT 0.001 (0.280)	loss 6.593 (6.687)	prob 2.346 (2.321)	GS 34.141 (32.316)	mem 72.637
Train: [89][1360/1500]	BT 0.037 (0.320)	DT 0.001 (0.280)	loss 6.673 (6.675)	prob 1.936 (2.445)	GS 33.312 (32.783)	mem 72.639
Train: [89][1370/1500]	BT 0.039 (0.318)	DT 0.001 (0.279)	loss 6.834 (6.686)	prob 1.815 (2.333)	GS 33.734 (33.444)	mem 72.639
Train: [89][1380/1500]	BT 0.032 (0.321)	DT 0.001 (0.281)	loss 6.839 (6.694)	prob 2.452 (2.405)	GS 32.719 (33.457)	mem 72.641
Train: [89][1390/1500]	BT 0.027 (0.319)	DT 0.000 (0.279)	loss 6.634 (6.702)	prob 2.160 (2.404)	GS 33.812 (33.344)	mem 72.642
Train: [89][1400/1500]	BT 0.032 (0.317)	DT 0.000 (0.277)	loss 6.642 (6.704)	prob 3.224 (2.434)	GS 38.266 (33.439)	mem 72.643
Train: [89][1410/1500]	BT 0.038 (0.317)	DT 0.001 (0.277)	loss 6.590 (6.678)	prob 2.457 (2.478)	GS 32.906 (31.878)	mem 72.643
Train: [89][1420/1500]	BT 0.028 (0.315)	DT 0.001 (0.276)	loss 6.651 (6.677)	prob 2.915 (2.472)	GS 30.078 (32.059)	mem 72.644
Train: [89][1430/1500]	BT 0.039 (0.315)	DT 0.001 (0.276)	loss 7.128 (6.700)	prob 1.786 (2.453)	GS 33.703 (32.515)	mem 72.645
Train: [89][1440/1500]	BT 0.038 (0.315)	DT 0.002 (0.275)	loss 6.862 (6.702)	prob 1.982 (2.419)	GS 35.297 (32.900)	mem 72.646
Train: [89][1450/1500]	BT 0.034 (0.313)	DT 0.001 (0.273)	loss 6.570 (6.691)	prob 2.910 (2.444)	GS 34.016 (32.654)	mem 72.646
Train: [89][1460/1500]	BT 0.063 (0.313)	DT 0.001 (0.273)	loss 6.617 (6.669)	prob 2.119 (2.121)	GS 33.578 (31.856)	mem 72.609
Train: [89][1470/1500]	BT 0.031 (0.313)	DT 0.001 (0.273)	loss 6.778 (6.666)	prob 2.490 (2.251)	GS 34.016 (32.163)	mem 72.137
Train: [89][1480/1500]	BT 0.030 (0.312)	DT 0.000 (0.272)	loss 6.733 (6.664)	prob 2.764 (2.341)	GS 30.906 (31.573)	mem 41.459
Train: [89][1490/1500]	BT 0.035 (0.310)	DT 0.000 (0.271)	loss 6.571 (6.660)	prob 2.482 (2.367)	GS 31.781 (31.547)	mem 15.977
Train: [89][1500/1500]	BT 0.046 (0.308)	DT 0.000 (0.269)	loss 6.561 (6.660)	prob 2.104 (2.379)	GS 35.812 (31.727)	mem 14.889
Train: [89][1510/1500]	BT 0.026 (0.307)	DT 0.000 (0.268)	loss 6.492 (6.472)	prob 1.956 (2.219)	GS 38.250 (35.038)	mem 7.512
epoch 89, total time 463.95
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [90][1/1500]	BT 21.686 (21.686)	DT 21.628 (21.628)	loss 6.320 (6.320)	prob 1.770 (1.770)	GS 26.531 (26.531)	mem 71.171
Train: [90][10/1500]	BT 0.027 (2.236)	DT 0.000 (2.204)	loss 6.528 (6.375)	prob 2.098 (2.067)	GS 36.312 (33.587)	mem 71.192
Train: [90][20/1500]	BT 0.037 (1.136)	DT 0.001 (1.103)	loss 6.461 (6.428)	prob 2.966 (2.383)	GS 37.422 (33.480)	mem 71.200
Train: [90][30/1500]	BT 0.026 (0.979)	DT 0.000 (0.942)	loss 6.623 (6.482)	prob 2.376 (2.346)	GS 36.016 (33.335)	mem 71.256
Train: [90][40/1500]	BT 0.038 (0.743)	DT 0.000 (0.707)	loss 6.806 (6.522)	prob 2.209 (2.392)	GS 32.422 (32.816)	mem 71.257
Train: [90][50/1500]	BT 0.033 (0.764)	DT 0.001 (0.728)	loss 6.643 (6.541)	prob 2.267 (2.348)	GS 31.953 (33.100)	mem 71.286
Train: [90][60/1500]	BT 0.027 (0.642)	DT 0.000 (0.607)	loss 6.575 (6.612)	prob 2.710 (2.570)	GS 32.922 (31.808)	mem 71.286
Train: [90][70/1500]	BT 0.039 (0.555)	DT 0.001 (0.520)	loss 6.776 (6.625)	prob 1.513 (2.505)	GS 35.516 (31.916)	mem 71.287
Train: [90][80/1500]	BT 0.031 (0.541)	DT 0.000 (0.506)	loss 6.732 (6.656)	prob 2.906 (2.451)	GS 31.578 (32.038)	mem 71.292
Train: [90][90/1500]	BT 0.038 (0.485)	DT 0.001 (0.450)	loss 6.569 (6.663)	prob 2.299 (2.342)	GS 29.469 (31.943)	mem 71.293
Train: [90][100/1500]	BT 0.030 (0.501)	DT 0.000 (0.466)	loss 6.635 (6.664)	prob 1.921 (2.324)	GS 32.328 (31.977)	mem 71.296
Train: [90][110/1500]	BT 0.029 (0.458)	DT 0.000 (0.424)	loss 6.649 (6.629)	prob 2.069 (2.251)	GS 33.641 (31.791)	mem 71.297
Train: [90][120/1500]	BT 0.039 (0.432)	DT 0.000 (0.398)	loss 6.715 (6.627)	prob 2.178 (2.361)	GS 32.484 (32.650)	mem 71.304
Train: [90][130/1500]	BT 0.039 (0.415)	DT 0.000 (0.380)	loss 6.789 (6.651)	prob 2.990 (2.402)	GS 35.188 (32.852)	mem 71.306
Train: [90][140/1500]	BT 0.039 (0.388)	DT 0.001 (0.353)	loss 6.668 (6.650)	prob 1.664 (2.411)	GS 29.297 (32.812)	mem 71.305
Train: [90][150/1500]	BT 0.039 (0.386)	DT 0.001 (0.351)	loss 6.588 (6.638)	prob 2.464 (2.405)	GS 35.500 (32.851)	mem 71.358
Train: [90][160/1500]	BT 0.039 (0.365)	DT 0.001 (0.329)	loss 6.545 (6.642)	prob 2.449 (2.080)	GS 32.750 (32.453)	mem 71.358
Train: [90][170/1500]	BT 0.037 (0.374)	DT 0.000 (0.339)	loss 6.634 (6.655)	prob 3.051 (2.290)	GS 34.156 (32.242)	mem 72.317
Train: [90][180/1500]	BT 0.037 (0.355)	DT 0.001 (0.320)	loss 6.584 (6.631)	prob 1.670 (2.329)	GS 37.812 (32.754)	mem 72.318
Train: [90][190/1500]	BT 0.038 (0.338)	DT 0.001 (0.303)	loss 6.423 (6.624)	prob 2.979 (2.329)	GS 28.234 (32.990)	mem 72.368
Train: [90][200/1500]	BT 0.027 (0.344)	DT 0.000 (0.309)	loss 6.535 (6.626)	prob 2.200 (2.299)	GS 32.484 (32.759)	mem 72.477
Train: [90][210/1500]	BT 0.028 (0.329)	DT 0.000 (0.294)	loss 6.752 (6.590)	prob 1.923 (2.358)	GS 37.766 (33.519)	mem 72.477
Train: [90][220/1500]	BT 0.027 (0.338)	DT 0.000 (0.304)	loss 6.691 (6.632)	prob 2.535 (2.410)	GS 36.156 (33.866)	mem 72.531
Train: [90][230/1500]	BT 0.027 (0.325)	DT 0.000 (0.291)	loss 6.626 (6.648)	prob 2.580 (2.470)	GS 32.312 (33.748)	mem 72.534
Train: [90][240/1500]	BT 0.089 (0.334)	DT 0.024 (0.300)	loss 6.721 (6.645)	prob 2.463 (2.421)	GS 34.297 (33.609)	mem 72.540
Train: [90][250/1500]	BT 0.030 (0.323)	DT 0.000 (0.288)	loss 6.475 (6.643)	prob 3.152 (2.447)	GS 32.156 (33.465)	mem 72.539
Train: [90][260/1500]	BT 0.029 (0.312)	DT 0.000 (0.277)	loss 6.555 (6.616)	prob 2.777 (2.243)	GS 30.906 (33.069)	mem 72.540
Train: [90][270/1500]	BT 0.030 (0.319)	DT 0.000 (0.284)	loss 6.540 (6.634)	prob 2.410 (2.250)	GS 34.484 (33.051)	mem 72.542
Train: [90][280/1500]	BT 0.024 (0.308)	DT 0.000 (0.274)	loss 6.563 (6.620)	prob 2.589 (2.222)	GS 37.562 (32.861)	mem 72.543
Train: [90][290/1500]	BT 0.027 (0.323)	DT 0.000 (0.289)	loss 6.771 (6.635)	prob 2.086 (2.244)	GS 37.344 (33.194)	mem 72.544
Train: [90][300/1500]	BT 0.030 (0.313)	DT 0.000 (0.279)	loss 6.721 (6.634)	prob 2.353 (2.195)	GS 32.797 (33.372)	mem 72.546
Train: [90][310/1500]	BT 0.038 (0.304)	DT 0.001 (0.270)	loss 6.640 (6.677)	prob 2.012 (2.270)	GS 38.078 (33.680)	mem 72.547
Train: [90][320/1500]	BT 0.037 (0.304)	DT 0.001 (0.270)	loss 6.502 (6.645)	prob 2.341 (2.114)	GS 35.562 (33.257)	mem 72.548
Train: [90][330/1500]	BT 0.035 (0.296)	DT 0.000 (0.262)	loss 6.826 (6.645)	prob 2.177 (2.139)	GS 32.656 (33.067)	mem 72.549
Train: [90][340/1500]	BT 0.037 (0.296)	DT 0.001 (0.262)	loss 6.883 (6.650)	prob 1.611 (2.119)	GS 29.453 (32.945)	mem 72.552
Train: [90][350/1500]	BT 0.037 (0.289)	DT 0.001 (0.255)	loss 6.610 (6.641)	prob 1.995 (2.107)	GS 35.297 (32.800)	mem 72.552
Train: [90][360/1500]	BT 0.037 (0.297)	DT 0.000 (0.263)	loss 6.739 (6.617)	prob 1.465 (2.150)	GS 31.922 (32.814)	mem 72.556
Train: [90][370/1500]	BT 0.037 (0.291)	DT 0.000 (0.256)	loss 6.532 (6.619)	prob 1.610 (2.182)	GS 34.141 (32.836)	mem 72.558
Train: [90][380/1500]	BT 0.032 (0.284)	DT 0.000 (0.250)	loss 6.606 (6.621)	prob 2.321 (2.199)	GS 33.500 (32.511)	mem 72.560
Train: [90][390/1500]	BT 0.026 (0.315)	DT 0.000 (0.280)	loss 6.560 (6.616)	prob 2.604 (2.231)	GS 36.438 (32.916)	mem 72.561
Train: [90][400/1500]	BT 0.026 (0.308)	DT 0.000 (0.273)	loss 6.636 (6.620)	prob 3.145 (2.245)	GS 33.812 (32.894)	mem 72.563
Train: [90][410/1500]	BT 0.037 (0.301)	DT 0.000 (0.266)	loss 6.566 (6.611)	prob 2.523 (2.526)	GS 37.125 (36.177)	mem 72.564
Train: [90][420/1500]	BT 0.029 (0.311)	DT 0.000 (0.276)	loss 6.640 (6.616)	prob 2.494 (2.500)	GS 34.391 (33.648)	mem 72.564
Train: [90][430/1500]	BT 0.038 (0.304)	DT 0.001 (0.270)	loss 6.565 (6.625)	prob 2.879 (2.532)	GS 35.500 (33.651)	mem 72.566
Train: [90][440/1500]	BT 0.037 (0.304)	DT 0.001 (0.270)	loss 6.623 (6.619)	prob 2.418 (2.504)	GS 35.828 (33.481)	mem 72.568
Train: [90][450/1500]	BT 0.037 (0.298)	DT 0.001 (0.264)	loss 6.699 (6.615)	prob 2.126 (2.473)	GS 32.281 (33.358)	mem 72.569
Train: [90][460/1500]	BT 0.038 (0.298)	DT 0.001 (0.264)	loss 6.622 (6.618)	prob 2.329 (2.597)	GS 34.281 (33.275)	mem 72.570
Train: [90][470/1500]	BT 0.039 (0.293)	DT 0.000 (0.258)	loss 6.497 (6.601)	prob 1.731 (2.377)	GS 34.344 (32.826)	mem 72.570
Train: [90][480/1500]	BT 0.038 (0.288)	DT 0.001 (0.253)	loss 6.589 (6.590)	prob 2.838 (2.265)	GS 30.969 (32.943)	mem 72.573
Train: [90][490/1500]	BT 0.059 (0.295)	DT 0.006 (0.260)	loss 6.745 (6.588)	prob 1.767 (2.274)	GS 34.328 (32.982)	mem 72.573
Train: [90][500/1500]	BT 0.031 (0.294)	DT 0.000 (0.260)	loss 6.504 (6.587)	prob 1.861 (2.248)	GS 32.297 (32.896)	mem 72.573
Train: [90][510/1500]	BT 0.037 (0.300)	DT 0.001 (0.265)	loss 6.468 (6.634)	prob 2.573 (2.132)	GS 31.266 (33.477)	mem 72.573
Train: [90][520/1500]	BT 0.039 (0.295)	DT 0.001 (0.260)	loss 6.471 (6.599)	prob 2.160 (2.223)	GS 33.641 (33.010)	mem 72.573
Train: [90][530/1500]	BT 0.079 (0.303)	DT 0.003 (0.268)	loss 6.750 (6.595)	prob 2.149 (2.179)	GS 35.078 (33.349)	mem 72.577
Train: [90][540/1500]	BT 0.038 (0.299)	DT 0.001 (0.263)	loss 6.677 (6.593)	prob 2.375 (2.216)	GS 34.781 (32.839)	mem 72.578
Train: [90][550/1500]	BT 0.079 (0.308)	DT 0.004 (0.272)	loss 6.891 (6.601)	prob 2.001 (2.251)	GS 31.609 (32.803)	mem 72.612
Train: [90][560/1500]	BT 0.089 (0.303)	DT 0.004 (0.267)	loss 6.840 (6.594)	prob 2.534 (2.611)	GS 33.344 (34.248)	mem 72.612
Train: [90][570/1500]	BT 0.089 (0.299)	DT 0.004 (0.263)	loss 6.752 (6.616)	prob 1.589 (2.669)	GS 32.375 (33.727)	mem 72.612
Train: [90][580/1500]	BT 0.072 (0.310)	DT 0.011 (0.273)	loss 6.526 (6.601)	prob 2.345 (2.667)	GS 32.297 (33.414)	mem 72.614
Train: [90][590/1500]	BT 17.890 (0.336)	DT 17.848 (0.298)	loss 6.887 (6.609)	prob 2.669 (2.642)	GS 37.641 (33.198)	mem 72.612
Train: [90][600/1500]	BT 0.022 (0.330)	DT 0.000 (0.293)	loss 6.532 (6.606)	prob 2.588 (2.648)	GS 37.812 (33.198)	mem 72.612
Train: [90][610/1500]	BT 0.030 (0.325)	DT 0.000 (0.289)	loss 6.709 (6.626)	prob 2.483 (2.563)	GS 33.812 (33.108)	mem 72.612
Train: [90][620/1500]	BT 0.036 (0.325)	DT 0.001 (0.288)	loss 6.694 (6.634)	prob 1.859 (2.520)	GS 31.641 (32.788)	mem 72.614
Train: [90][630/1500]	BT 0.037 (0.321)	DT 0.000 (0.284)	loss 6.688 (6.633)	prob 2.223 (2.587)	GS 35.359 (32.850)	mem 72.613
Train: [90][640/1500]	BT 0.040 (0.323)	DT 0.001 (0.286)	loss 6.731 (6.636)	prob 2.173 (2.592)	GS 35.938 (32.608)	mem 72.613
Train: [90][650/1500]	BT 0.039 (0.319)	DT 0.001 (0.282)	loss 6.555 (6.622)	prob 1.890 (2.607)	GS 33.094 (32.517)	mem 72.616
Train: [90][660/1500]	BT 0.040 (0.314)	DT 0.001 (0.277)	loss 6.778 (6.581)	prob 2.741 (2.684)	GS 36.859 (32.564)	mem 72.616
Train: [90][670/1500]	BT 0.052 (0.318)	DT 0.011 (0.281)	loss 6.680 (6.610)	prob 2.328 (2.630)	GS 31.859 (32.169)	mem 72.615
Train: [90][680/1500]	BT 0.060 (0.314)	DT 0.011 (0.277)	loss 6.649 (6.612)	prob 2.442 (2.646)	GS 35.000 (32.070)	mem 72.614
Train: [90][690/1500]	BT 0.030 (0.319)	DT 0.001 (0.282)	loss 6.643 (6.611)	prob 2.871 (2.617)	GS 31.281 (32.017)	mem 72.615
Train: [90][700/1500]	BT 0.027 (0.316)	DT 0.000 (0.279)	loss 6.655 (6.610)	prob 3.097 (2.681)	GS 30.859 (32.332)	mem 72.617
Train: [90][710/1500]	BT 2.480 (0.315)	DT 2.442 (0.278)	loss 6.593 (6.599)	prob 2.362 (2.697)	GS 29.156 (31.420)	mem 72.619
Train: [90][720/1500]	BT 0.028 (0.314)	DT 0.000 (0.277)	loss 6.703 (6.603)	prob 2.490 (2.663)	GS 32.500 (31.681)	mem 72.621
Train: [90][730/1500]	BT 0.036 (0.310)	DT 0.001 (0.273)	loss 6.804 (6.602)	prob 1.940 (2.629)	GS 29.531 (31.969)	mem 72.620
Train: [90][740/1500]	BT 0.039 (0.308)	DT 0.001 (0.271)	loss 6.636 (6.606)	prob 2.176 (2.599)	GS 35.281 (32.313)	mem 72.621
Train: [90][750/1500]	BT 0.031 (0.310)	DT 0.000 (0.273)	loss 6.801 (6.616)	prob 2.163 (2.540)	GS 32.828 (32.157)	mem 72.621
Train: [90][760/1500]	BT 0.037 (0.306)	DT 0.000 (0.269)	loss 6.525 (6.632)	prob 2.984 (2.627)	GS 35.531 (32.458)	mem 72.620
Train: [90][770/1500]	BT 0.036 (0.307)	DT 0.000 (0.271)	loss 6.677 (6.591)	prob 2.388 (2.490)	GS 29.891 (32.362)	mem 72.619
Train: [90][780/1500]	BT 0.037 (0.304)	DT 0.000 (0.267)	loss 6.687 (6.591)	prob 1.822 (2.476)	GS 31.031 (32.105)	mem 72.619
Train: [90][790/1500]	BT 0.061 (0.308)	DT 0.002 (0.271)	loss 6.791 (6.598)	prob 2.954 (2.497)	GS 28.984 (32.156)	mem 72.619
Train: [90][800/1500]	BT 0.055 (0.305)	DT 0.004 (0.268)	loss 6.726 (6.598)	prob 2.682 (2.527)	GS 35.484 (32.071)	mem 72.620
Train: [90][810/1500]	BT 0.052 (0.302)	DT 0.014 (0.265)	loss 6.589 (6.568)	prob 3.093 (2.628)	GS 31.719 (33.102)	mem 72.620
Train: [90][820/1500]	BT 0.056 (0.305)	DT 0.010 (0.268)	loss 6.673 (6.582)	prob 1.818 (2.577)	GS 33.984 (33.044)	mem 72.621
Train: [90][830/1500]	BT 15.364 (0.320)	DT 15.316 (0.283)	loss 6.618 (6.600)	prob 3.129 (2.634)	GS 40.641 (33.095)	mem 72.636
Train: [90][840/1500]	BT 0.028 (0.317)	DT 0.000 (0.280)	loss 6.440 (6.592)	prob 2.594 (2.578)	GS 33.047 (32.691)	mem 72.638
Train: [90][850/1500]	BT 0.036 (0.313)	DT 0.001 (0.277)	loss 6.581 (6.601)	prob 2.513 (2.584)	GS 35.594 (32.938)	mem 72.640
Train: [90][860/1500]	BT 0.067 (0.314)	DT 0.017 (0.277)	loss 6.597 (6.599)	prob 2.485 (2.741)	GS 33.281 (32.711)	mem 72.539
Train: [90][870/1500]	BT 0.068 (0.311)	DT 0.006 (0.273)	loss 6.613 (6.636)	prob 2.478 (2.646)	GS 34.609 (32.733)	mem 72.539
Train: [90][880/1500]	BT 0.035 (0.313)	DT 0.001 (0.276)	loss 6.699 (6.642)	prob 2.285 (2.526)	GS 34.141 (33.172)	mem 72.539
Train: [90][890/1500]	BT 0.037 (0.310)	DT 0.001 (0.273)	loss 6.769 (6.650)	prob 2.900 (2.538)	GS 33.969 (33.445)	mem 72.539
Train: [90][900/1500]	BT 0.137 (0.307)	DT 0.039 (0.270)	loss 6.529 (6.643)	prob 2.315 (2.535)	GS 31.688 (33.180)	mem 72.540
Train: [90][910/1500]	BT 0.037 (0.308)	DT 0.000 (0.270)	loss 6.600 (6.602)	prob 1.957 (2.163)	GS 36.547 (33.667)	mem 72.542
Train: [90][920/1500]	BT 0.038 (0.305)	DT 0.001 (0.267)	loss 6.684 (6.620)	prob 2.719 (2.365)	GS 30.828 (33.079)	mem 72.542
Train: [90][930/1500]	BT 0.038 (0.305)	DT 0.001 (0.267)	loss 6.583 (6.596)	prob 2.844 (2.456)	GS 31.828 (33.023)	mem 72.542
Train: [90][940/1500]	BT 0.037 (0.304)	DT 0.000 (0.266)	loss 6.597 (6.593)	prob 2.465 (2.477)	GS 33.141 (32.739)	mem 72.562
Train: [90][950/1500]	BT 1.220 (0.302)	DT 1.183 (0.265)	loss 6.716 (6.595)	prob 2.765 (2.481)	GS 36.734 (32.440)	mem 72.564
Train: [90][960/1500]	BT 0.086 (0.304)	DT 0.018 (0.266)	loss 6.504 (6.624)	prob 2.038 (2.436)	GS 33.828 (31.417)	mem 72.566
Train: [90][970/1500]	BT 0.060 (0.301)	DT 0.004 (0.263)	loss 6.618 (6.635)	prob 2.897 (2.573)	GS 34.734 (31.675)	mem 72.566
Train: [90][980/1500]	BT 0.038 (0.303)	DT 0.001 (0.265)	loss 6.734 (6.645)	prob 2.951 (2.636)	GS 39.234 (32.666)	mem 72.566
Train: [90][990/1500]	BT 0.038 (0.301)	DT 0.001 (0.263)	loss 6.626 (6.632)	prob 2.601 (2.623)	GS 34.125 (32.573)	mem 72.566
Train: [90][1000/1500]	BT 0.038 (0.301)	DT 0.001 (0.263)	loss 6.617 (6.618)	prob 2.158 (2.571)	GS 34.312 (32.554)	mem 72.552
Train: [90][1010/1500]	BT 0.026 (0.302)	DT 0.000 (0.264)	loss 6.497 (6.602)	prob 2.303 (2.345)	GS 31.109 (31.723)	mem 72.551
Train: [90][1020/1500]	BT 0.038 (0.299)	DT 0.001 (0.261)	loss 6.569 (6.592)	prob 1.814 (2.420)	GS 35.641 (31.726)	mem 72.550
Train: [90][1030/1500]	BT 0.038 (0.302)	DT 0.001 (0.264)	loss 6.430 (6.585)	prob 2.399 (2.399)	GS 33.609 (32.321)	mem 72.550
Train: [90][1040/1500]	BT 0.038 (0.300)	DT 0.001 (0.262)	loss 6.652 (6.583)	prob 2.313 (2.393)	GS 35.625 (32.349)	mem 72.551
Train: [90][1050/1500]	BT 0.039 (0.298)	DT 0.001 (0.260)	loss 6.720 (6.586)	prob 1.912 (2.402)	GS 32.125 (32.141)	mem 72.552
Train: [90][1060/1500]	BT 0.040 (0.301)	DT 0.000 (0.263)	loss 6.582 (6.648)	prob 2.064 (2.501)	GS 36.031 (33.658)	mem 72.556
Train: [90][1070/1500]	BT 0.039 (0.299)	DT 0.001 (0.261)	loss 6.659 (6.642)	prob 2.463 (2.360)	GS 33.000 (33.164)	mem 72.556
Train: [90][1080/1500]	BT 0.034 (0.301)	DT 0.000 (0.263)	loss 6.914 (6.650)	prob 1.578 (2.273)	GS 35.297 (32.978)	mem 72.556
Train: [90][1090/1500]	BT 0.042 (0.298)	DT 0.001 (0.260)	loss 6.629 (6.648)	prob 2.129 (2.266)	GS 34.453 (32.928)	mem 72.556
Train: [90][1100/1500]	BT 0.041 (0.296)	DT 0.001 (0.258)	loss 6.662 (6.638)	prob 2.304 (2.287)	GS 33.859 (32.783)	mem 72.557
Train: [90][1110/1500]	BT 0.031 (0.302)	DT 0.000 (0.264)	loss 6.537 (6.590)	prob 2.246 (2.142)	GS 37.172 (32.886)	mem 72.556
Train: [90][1120/1500]	BT 0.040 (0.300)	DT 0.001 (0.262)	loss 6.509 (6.604)	prob 2.748 (2.407)	GS 34.781 (33.130)	mem 72.557
Train: [90][1130/1500]	BT 0.026 (0.300)	DT 0.000 (0.262)	loss 6.633 (6.619)	prob 3.017 (2.397)	GS 29.703 (33.034)	mem 72.570
Train: [90][1140/1500]	BT 0.037 (0.298)	DT 0.001 (0.260)	loss 6.696 (6.625)	prob 1.796 (2.354)	GS 34.922 (32.692)	mem 72.572
Train: [90][1150/1500]	BT 5.413 (0.300)	DT 5.340 (0.263)	loss 6.699 (6.627)	prob 2.096 (2.344)	GS 37.047 (32.745)	mem 72.571
Train: [90][1160/1500]	BT 0.056 (0.298)	DT 0.000 (0.260)	loss 6.615 (6.632)	prob 2.352 (2.197)	GS 28.344 (32.681)	mem 72.572
Train: [90][1170/1500]	BT 0.036 (0.301)	DT 0.000 (0.263)	loss 6.605 (6.606)	prob 2.577 (2.222)	GS 32.125 (32.942)	mem 72.573
Train: [90][1180/1500]	BT 0.037 (0.299)	DT 0.000 (0.261)	loss 6.705 (6.612)	prob 1.697 (2.290)	GS 36.531 (33.062)	mem 72.575
Train: [90][1190/1500]	BT 0.037 (0.297)	DT 0.001 (0.259)	loss 6.744 (6.603)	prob 2.437 (2.271)	GS 34.141 (33.013)	mem 72.575
Train: [90][1200/1500]	BT 0.060 (0.299)	DT 0.010 (0.261)	loss 6.607 (6.595)	prob 2.642 (2.268)	GS 35.188 (32.969)	mem 72.573
Train: [90][1210/1500]	BT 0.031 (0.300)	DT 0.000 (0.262)	loss 6.582 (6.605)	prob 2.036 (2.131)	GS 33.875 (33.641)	mem 72.574
Train: [90][1220/1500]	BT 0.035 (0.301)	DT 0.000 (0.262)	loss 6.628 (6.612)	prob 2.711 (2.231)	GS 36.625 (33.554)	mem 72.576
Train: [90][1230/1500]	BT 0.709 (0.299)	DT 0.661 (0.261)	loss 6.605 (6.597)	prob 1.890 (2.216)	GS 34.641 (33.058)	mem 72.577
Train: [90][1240/1500]	BT 0.072 (0.298)	DT 0.004 (0.260)	loss 6.686 (6.591)	prob 2.053 (2.191)	GS 33.219 (33.075)	mem 72.578
Train: [90][1250/1500]	BT 0.038 (0.298)	DT 0.001 (0.259)	loss 6.851 (6.594)	prob 1.324 (2.202)	GS 33.391 (32.968)	mem 72.577
Train: [90][1260/1500]	BT 0.037 (0.297)	DT 0.000 (0.259)	loss 6.610 (6.632)	prob 2.253 (2.212)	GS 32.125 (32.014)	mem 72.581
Train: [90][1270/1500]	BT 0.055 (0.305)	DT 0.003 (0.266)	loss 6.700 (6.617)	prob 2.916 (2.286)	GS 33.938 (32.570)	mem 72.581
Train: [90][1280/1500]	BT 0.060 (0.303)	DT 0.003 (0.264)	loss 6.513 (6.594)	prob 2.031 (2.322)	GS 36.578 (32.475)	mem 72.581
Train: [90][1290/1500]	BT 0.056 (0.305)	DT 0.006 (0.266)	loss 6.680 (6.613)	prob 2.261 (2.278)	GS 32.938 (32.696)	mem 72.582
Train: [90][1300/1500]	BT 0.021 (0.310)	DT 0.000 (0.271)	loss 6.653 (6.629)	prob 2.448 (2.238)	GS 41.891 (32.860)	mem 72.581
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [90][1310/1500]	BT 0.023 (0.308)	DT 0.000 (0.269)	loss 6.536 (6.615)	prob 3.198 (2.312)	GS 36.578 (32.739)	mem 72.581
Train: [90][1320/1500]	BT 0.036 (0.308)	DT 0.000 (0.269)	loss 6.633 (6.584)	prob 1.245 (2.323)	GS 31.969 (32.420)	mem 72.584
Train: [90][1330/1500]	BT 0.043 (0.306)	DT 0.001 (0.267)	loss 6.541 (6.601)	prob 2.220 (2.341)	GS 34.266 (32.888)	mem 72.585
Train: [90][1340/1500]	BT 0.037 (0.304)	DT 0.000 (0.265)	loss 6.636 (6.598)	prob 2.023 (2.331)	GS 32.453 (32.684)	mem 72.585
Train: [90][1350/1500]	BT 0.037 (0.305)	DT 0.001 (0.267)	loss 6.522 (6.590)	prob 2.251 (2.316)	GS 34.969 (32.740)	mem 72.585
Train: [90][1360/1500]	BT 0.037 (0.303)	DT 0.001 (0.265)	loss 6.586 (6.612)	prob 2.400 (2.413)	GS 32.328 (32.553)	mem 72.585
Train: [90][1370/1500]	BT 0.027 (0.305)	DT 0.000 (0.266)	loss 6.711 (6.607)	prob 1.884 (2.336)	GS 35.500 (32.903)	mem 72.589
Train: [90][1380/1500]	BT 0.027 (0.303)	DT 0.000 (0.264)	loss 6.458 (6.594)	prob 2.839 (2.384)	GS 29.750 (32.348)	mem 72.590
Train: [90][1390/1500]	BT 0.037 (0.301)	DT 0.001 (0.262)	loss 6.558 (6.583)	prob 2.682 (2.416)	GS 35.234 (32.280)	mem 72.590
Train: [90][1400/1500]	BT 0.038 (0.303)	DT 0.000 (0.265)	loss 6.902 (6.592)	prob 2.596 (2.412)	GS 35.516 (32.354)	mem 72.589
Train: [90][1410/1500]	BT 0.038 (0.301)	DT 0.000 (0.263)	loss 6.577 (6.544)	prob 2.696 (2.453)	GS 34.875 (32.153)	mem 72.589
Train: [90][1420/1500]	BT 0.031 (0.303)	DT 0.000 (0.265)	loss 6.494 (6.573)	prob 2.343 (2.449)	GS 33.922 (32.752)	mem 72.590
Train: [90][1430/1500]	BT 0.039 (0.301)	DT 0.001 (0.263)	loss 6.855 (6.584)	prob 2.131 (2.396)	GS 33.047 (32.837)	mem 72.590
Train: [90][1440/1500]	BT 0.037 (0.302)	DT 0.000 (0.263)	loss 6.393 (6.580)	prob 2.327 (2.393)	GS 32.828 (32.866)	mem 72.591
Train: [90][1450/1500]	BT 0.039 (0.300)	DT 0.000 (0.262)	loss 6.676 (6.584)	prob 2.020 (2.337)	GS 34.906 (32.527)	mem 72.592
Train: [90][1460/1500]	BT 0.032 (0.298)	DT 0.000 (0.260)	loss 6.555 (6.603)	prob 2.152 (2.337)	GS 35.328 (30.870)	mem 72.592
Train: [90][1470/1500]	BT 0.028 (0.301)	DT 0.000 (0.263)	loss 6.819 (6.603)	prob 2.138 (2.328)	GS 30.562 (32.939)	mem 71.899
Train: [90][1480/1500]	BT 0.034 (0.299)	DT 0.001 (0.261)	loss 6.778 (6.626)	prob 1.390 (2.338)	GS 33.219 (32.786)	mem 66.871
Train: [90][1490/1500]	BT 0.031 (0.299)	DT 0.000 (0.261)	loss 6.834 (6.621)	prob 1.930 (2.299)	GS 33.375 (32.585)	mem 10.284
Train: [90][1500/1500]	BT 0.023 (0.297)	DT 0.000 (0.259)	loss 6.403 (6.606)	prob 2.918 (2.303)	GS 27.062 (32.390)	mem 10.285
Train: [90][1510/1500]	BT 0.026 (0.296)	DT 0.000 (0.258)	loss 6.040 (6.381)	prob 2.533 (2.409)	GS 28.781 (32.763)	mem 7.469
epoch 90, total time 446.82
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [91][1/1500]	BT 22.024 (22.024)	DT 21.939 (21.939)	loss 6.232 (6.232)	prob 1.879 (1.879)	GS 29.797 (29.797)	mem 71.276
Train: [91][10/1500]	BT 0.033 (2.243)	DT 0.000 (2.199)	loss 6.362 (6.276)	prob 2.537 (2.511)	GS 34.453 (33.438)	mem 71.285
Train: [91][20/1500]	BT 0.067 (1.147)	DT 0.000 (1.103)	loss 6.510 (6.337)	prob 2.042 (2.551)	GS 36.641 (33.331)	mem 71.286
Train: [91][30/1500]	BT 0.048 (1.272)	DT 0.007 (1.228)	loss 6.678 (6.404)	prob 2.426 (2.521)	GS 32.344 (33.448)	mem 71.341
Train: [91][40/1500]	BT 0.027 (1.180)	DT 0.000 (1.139)	loss 6.694 (6.448)	prob 2.794 (2.560)	GS 29.672 (33.110)	mem 71.359
Train: [91][50/1500]	BT 0.024 (0.950)	DT 0.000 (0.912)	loss 6.578 (6.468)	prob 2.390 (2.605)	GS 37.516 (33.188)	mem 71.359
Train: [91][60/1500]	BT 0.035 (0.864)	DT 0.000 (0.826)	loss 6.521 (6.576)	prob 2.896 (2.662)	GS 33.891 (31.836)	mem 71.363
Train: [91][70/1500]	BT 0.038 (0.746)	DT 0.001 (0.708)	loss 6.702 (6.579)	prob 2.442 (2.631)	GS 32.859 (31.720)	mem 71.364
Train: [91][80/1500]	BT 0.036 (0.657)	DT 0.001 (0.620)	loss 6.644 (6.591)	prob 1.854 (2.532)	GS 35.344 (32.065)	mem 71.364
Train: [91][90/1500]	BT 0.039 (0.622)	DT 0.001 (0.584)	loss 6.635 (6.585)	prob 2.007 (2.467)	GS 33.703 (32.201)	mem 71.372
Train: [91][100/1500]	BT 0.039 (0.563)	DT 0.001 (0.526)	loss 6.566 (6.592)	prob 2.814 (2.461)	GS 37.125 (32.174)	mem 71.374
Train: [91][110/1500]	BT 0.048 (0.594)	DT 0.000 (0.556)	loss 6.601 (6.625)	prob 2.297 (2.557)	GS 30.406 (33.514)	mem 71.378
Train: [91][120/1500]	BT 0.032 (0.547)	DT 0.000 (0.510)	loss 6.753 (6.639)	prob 2.417 (2.472)	GS 34.453 (32.664)	mem 71.380
Train: [91][130/1500]	BT 0.039 (0.508)	DT 0.001 (0.471)	loss 6.589 (6.626)	prob 2.817 (2.548)	GS 34.781 (32.816)	mem 71.381
Train: [91][140/1500]	BT 0.039 (0.494)	DT 0.001 (0.456)	loss 6.764 (6.624)	prob 2.622 (2.644)	GS 34.953 (32.876)	mem 71.383
Train: [91][150/1500]	BT 0.040 (0.464)	DT 0.001 (0.427)	loss 6.615 (6.623)	prob 2.816 (2.656)	GS 33.906 (32.831)	mem 71.383
Train: [91][160/1500]	BT 0.095 (0.465)	DT 0.007 (0.426)	loss 6.678 (6.573)	prob 2.299 (2.613)	GS 34.562 (32.934)	mem 71.828
Train: [91][170/1500]	BT 0.096 (0.442)	DT 0.012 (0.402)	loss 6.477 (6.559)	prob 3.777 (2.639)	GS 36.703 (33.366)	mem 71.827
Train: [91][180/1500]	BT 0.039 (0.458)	DT 0.001 (0.415)	loss 6.638 (6.548)	prob 2.680 (2.571)	GS 33.594 (33.038)	mem 72.473
Train: [91][190/1500]	BT 0.037 (0.436)	DT 0.000 (0.394)	loss 6.538 (6.549)	prob 2.148 (2.591)	GS 36.328 (33.265)	mem 72.473
Train: [91][200/1500]	BT 0.033 (0.416)	DT 0.000 (0.374)	loss 6.637 (6.559)	prob 2.223 (2.600)	GS 31.922 (33.217)	mem 72.475
Train: [91][210/1500]	BT 0.057 (0.422)	DT 0.011 (0.380)	loss 6.496 (6.537)	prob 2.721 (2.811)	GS 31.703 (32.550)	mem 72.571
Train: [91][220/1500]	BT 0.031 (0.405)	DT 0.000 (0.363)	loss 6.624 (6.574)	prob 2.739 (2.643)	GS 34.016 (32.687)	mem 72.573
Train: [91][230/1500]	BT 0.048 (0.439)	DT 0.002 (0.397)	loss 6.724 (6.586)	prob 2.385 (2.593)	GS 33.062 (33.096)	mem 72.579
Train: [91][240/1500]	BT 0.091 (0.423)	DT 0.011 (0.381)	loss 6.662 (6.594)	prob 2.130 (2.616)	GS 31.953 (33.269)	mem 72.579
Train: [91][250/1500]	BT 0.031 (0.457)	DT 0.000 (0.414)	loss 6.785 (6.602)	prob 2.623 (2.612)	GS 36.562 (33.413)	mem 72.581
Train: [91][260/1500]	BT 0.063 (0.441)	DT 0.027 (0.398)	loss 6.554 (6.614)	prob 2.291 (2.662)	GS 36.500 (31.738)	mem 72.581
Train: [91][270/1500]	BT 0.030 (0.466)	DT 0.000 (0.424)	loss 6.561 (6.592)	prob 2.882 (2.660)	GS 38.328 (32.805)	mem 72.582
Train: [91][280/1500]	BT 0.028 (0.450)	DT 0.000 (0.408)	loss 6.601 (6.578)	prob 2.547 (2.647)	GS 32.078 (32.597)	mem 72.582
Train: [91][290/1500]	BT 0.028 (0.455)	DT 0.000 (0.414)	loss 6.523 (6.567)	prob 2.669 (2.608)	GS 39.219 (32.484)	mem 72.580
Train: [91][300/1500]	BT 0.040 (0.441)	DT 0.000 (0.400)	loss 6.703 (6.573)	prob 2.445 (2.604)	GS 35.859 (32.645)	mem 72.581
Train: [91][310/1500]	BT 0.037 (0.438)	DT 0.000 (0.397)	loss 6.827 (6.637)	prob 2.658 (2.496)	GS 32.172 (33.880)	mem 72.591
Train: [91][320/1500]	BT 0.037 (0.425)	DT 0.001 (0.384)	loss 6.565 (6.636)	prob 2.848 (2.558)	GS 35.062 (33.578)	mem 72.592
Train: [91][330/1500]	BT 0.037 (0.413)	DT 0.000 (0.373)	loss 6.686 (6.617)	prob 2.424 (2.574)	GS 33.375 (33.019)	mem 72.591
Train: [91][340/1500]	BT 0.037 (0.415)	DT 0.001 (0.374)	loss 6.496 (6.601)	prob 2.793 (2.560)	GS 33.844 (32.645)	mem 72.603
Train: [91][350/1500]	BT 0.037 (0.404)	DT 0.000 (0.364)	loss 6.850 (6.597)	prob 1.818 (2.530)	GS 32.641 (32.642)	mem 72.603
Train: [91][360/1500]	BT 0.038 (0.404)	DT 0.000 (0.364)	loss 6.697 (6.602)	prob 2.401 (2.559)	GS 33.234 (31.992)	mem 72.508
Train: [91][370/1500]	BT 0.033 (0.394)	DT 0.000 (0.354)	loss 6.486 (6.596)	prob 2.769 (2.513)	GS 31.797 (32.225)	mem 72.507
Train: [91][380/1500]	BT 0.037 (0.385)	DT 0.001 (0.345)	loss 6.558 (6.621)	prob 3.147 (2.576)	GS 32.094 (32.781)	mem 72.509
Train: [91][390/1500]	BT 0.037 (0.383)	DT 0.001 (0.343)	loss 6.664 (6.623)	prob 2.869 (2.587)	GS 37.281 (32.537)	mem 72.509
Train: [91][400/1500]	BT 0.028 (0.374)	DT 0.000 (0.335)	loss 6.510 (6.620)	prob 2.871 (2.588)	GS 31.109 (32.686)	mem 72.510
Train: [91][410/1500]	BT 0.055 (0.375)	DT 0.001 (0.335)	loss 6.423 (6.580)	prob 3.438 (2.664)	GS 32.500 (32.533)	mem 72.514
Train: [91][420/1500]	BT 1.140 (0.369)	DT 1.085 (0.330)	loss 6.544 (6.570)	prob 1.836 (2.596)	GS 34.781 (32.391)	mem 72.514
Train: [91][430/1500]	BT 0.039 (0.371)	DT 0.000 (0.331)	loss 6.730 (6.591)	prob 2.306 (2.575)	GS 34.906 (32.339)	mem 72.514
Train: [91][440/1500]	BT 0.037 (0.364)	DT 0.001 (0.324)	loss 6.561 (6.595)	prob 2.744 (2.515)	GS 31.969 (32.403)	mem 72.515
Train: [91][450/1500]	BT 0.064 (0.358)	DT 0.011 (0.319)	loss 6.601 (6.586)	prob 2.254 (2.501)	GS 35.438 (32.847)	mem 72.516
Train: [91][460/1500]	BT 0.038 (0.364)	DT 0.001 (0.324)	loss 6.504 (6.574)	prob 2.728 (2.465)	GS 36.531 (32.322)	mem 72.518
Train: [91][470/1500]	BT 0.037 (0.357)	DT 0.001 (0.317)	loss 6.462 (6.583)	prob 2.070 (2.415)	GS 35.641 (31.795)	mem 72.519
Train: [91][480/1500]	BT 0.037 (0.359)	DT 0.001 (0.320)	loss 6.607 (6.599)	prob 3.196 (2.466)	GS 33.281 (32.159)	mem 72.540
Train: [91][490/1500]	BT 0.038 (0.353)	DT 0.001 (0.313)	loss 6.558 (6.605)	prob 2.599 (2.478)	GS 35.484 (32.625)	mem 72.540
Train: [91][500/1500]	BT 0.038 (0.349)	DT 0.001 (0.310)	loss 6.377 (6.620)	prob 2.564 (2.532)	GS 31.922 (32.778)	mem 72.540
Train: [91][510/1500]	BT 0.064 (0.348)	DT 0.005 (0.309)	loss 6.645 (6.580)	prob 1.913 (2.410)	GS 35.922 (32.964)	mem 72.529
Train: [91][520/1500]	BT 0.035 (0.345)	DT 0.000 (0.305)	loss 6.564 (6.573)	prob 2.011 (2.460)	GS 33.688 (32.202)	mem 72.531
Train: [91][530/1500]	BT 0.030 (0.356)	DT 0.000 (0.317)	loss 6.606 (6.583)	prob 2.289 (2.542)	GS 29.969 (32.401)	mem 72.528
Train: [91][540/1500]	BT 0.027 (0.350)	DT 0.000 (0.311)	loss 6.504 (6.587)	prob 2.546 (2.535)	GS 32.172 (32.648)	mem 72.528
Train: [91][550/1500]	BT 0.035 (0.352)	DT 0.001 (0.313)	loss 6.624 (6.599)	prob 2.659 (2.515)	GS 35.516 (32.738)	mem 72.531
Train: [91][560/1500]	BT 0.036 (0.346)	DT 0.001 (0.307)	loss 6.616 (6.572)	prob 2.081 (2.511)	GS 34.828 (33.005)	mem 72.531
Train: [91][570/1500]	BT 0.033 (0.348)	DT 0.000 (0.309)	loss 6.618 (6.605)	prob 3.406 (2.598)	GS 34.938 (32.775)	mem 72.531
Train: [91][580/1500]	BT 0.038 (0.342)	DT 0.001 (0.303)	loss 6.904 (6.619)	prob 1.752 (2.565)	GS 29.609 (32.421)	mem 72.532
Train: [91][590/1500]	BT 0.029 (0.337)	DT 0.001 (0.298)	loss 6.536 (6.623)	prob 2.172 (2.559)	GS 32.969 (32.965)	mem 72.532
Train: [91][600/1500]	BT 0.064 (0.348)	DT 0.002 (0.308)	loss 6.571 (6.611)	prob 2.891 (2.532)	GS 34.891 (32.844)	mem 72.535
Train: [91][610/1500]	BT 0.064 (0.343)	DT 0.002 (0.304)	loss 6.715 (6.669)	prob 2.793 (2.637)	GS 33.922 (33.072)	mem 72.535
Train: [91][620/1500]	BT 0.038 (0.347)	DT 0.001 (0.307)	loss 6.682 (6.650)	prob 2.684 (2.703)	GS 36.312 (33.580)	mem 72.536
Train: [91][630/1500]	BT 0.040 (0.342)	DT 0.001 (0.302)	loss 6.555 (6.626)	prob 2.448 (2.668)	GS 34.297 (33.309)	mem 72.535
Train: [91][640/1500]	BT 0.039 (0.337)	DT 0.001 (0.298)	loss 6.593 (6.624)	prob 2.928 (2.692)	GS 35.484 (32.512)	mem 72.535
Train: [91][650/1500]	BT 0.036 (0.340)	DT 0.000 (0.301)	loss 6.598 (6.629)	prob 2.114 (2.687)	GS 36.578 (32.593)	mem 72.549
Train: [91][660/1500]	BT 0.037 (0.335)	DT 0.001 (0.296)	loss 6.614 (6.643)	prob 2.483 (2.719)	GS 31.891 (32.519)	mem 72.551
Train: [91][670/1500]	BT 0.026 (0.337)	DT 0.000 (0.297)	loss 6.590 (6.637)	prob 2.286 (2.613)	GS 34.047 (32.122)	mem 72.556
Train: [91][680/1500]	BT 0.038 (0.332)	DT 0.001 (0.293)	loss 6.540 (6.641)	prob 3.249 (2.660)	GS 32.438 (32.323)	mem 72.557
Train: [91][690/1500]	BT 0.037 (0.332)	DT 0.000 (0.293)	loss 6.525 (6.628)	prob 3.246 (2.645)	GS 31.500 (32.645)	mem 72.558
Train: [91][700/1500]	BT 0.037 (0.328)	DT 0.001 (0.288)	loss 6.738 (6.633)	prob 2.408 (2.644)	GS 34.359 (32.610)	mem 72.559
Train: [91][710/1500]	BT 0.038 (0.324)	DT 0.001 (0.284)	loss 6.669 (6.628)	prob 2.338 (2.521)	GS 34.469 (31.303)	mem 72.560
Train: [91][720/1500]	BT 0.037 (0.324)	DT 0.000 (0.284)	loss 6.649 (6.614)	prob 2.612 (2.336)	GS 32.156 (31.509)	mem 72.560
Train: [91][730/1500]	BT 0.038 (0.320)	DT 0.000 (0.280)	loss 6.532 (6.615)	prob 2.086 (2.366)	GS 35.984 (32.117)	mem 72.561
Train: [91][740/1500]	BT 0.035 (0.322)	DT 0.000 (0.282)	loss 6.641 (6.616)	prob 3.194 (2.353)	GS 34.797 (32.205)	mem 72.564
Train: [91][750/1500]	BT 0.036 (0.318)	DT 0.000 (0.279)	loss 6.570 (6.618)	prob 2.172 (2.367)	GS 32.609 (32.179)	mem 72.564
Train: [91][760/1500]	BT 0.025 (0.318)	DT 0.000 (0.279)	loss 6.572 (6.576)	prob 2.584 (2.415)	GS 33.203 (31.597)	mem 72.565
Train: [91][770/1500]	BT 0.025 (0.327)	DT 0.001 (0.288)	loss 6.658 (6.619)	prob 2.569 (2.294)	GS 34.594 (33.038)	mem 72.570
Train: [91][780/1500]	BT 0.035 (0.323)	DT 0.000 (0.284)	loss 6.665 (6.613)	prob 2.174 (2.291)	GS 33.562 (32.634)	mem 72.571
Train: [91][790/1500]	BT 0.068 (0.326)	DT 0.015 (0.287)	loss 6.622 (6.610)	prob 2.352 (2.317)	GS 34.203 (32.546)	mem 72.573
Train: [91][800/1500]	BT 0.037 (0.323)	DT 0.000 (0.284)	loss 6.704 (6.599)	prob 1.949 (2.299)	GS 33.688 (32.503)	mem 72.573
Train: [91][810/1500]	BT 0.037 (0.319)	DT 0.000 (0.280)	loss 6.352 (6.584)	prob 2.087 (2.222)	GS 33.281 (33.136)	mem 72.573
Train: [91][820/1500]	BT 0.066 (0.329)	DT 0.015 (0.290)	loss 6.483 (6.600)	prob 2.982 (2.254)	GS 33.562 (32.471)	mem 72.571
Train: [91][830/1500]	BT 0.023 (0.336)	DT 0.000 (0.297)	loss 6.639 (6.601)	prob 2.166 (2.377)	GS 35.031 (32.801)	mem 72.571
Train: [91][840/1500]	BT 0.030 (0.333)	DT 0.000 (0.294)	loss 6.647 (6.619)	prob 2.556 (2.340)	GS 30.641 (32.921)	mem 72.571
Train: [91][850/1500]	BT 0.038 (0.332)	DT 0.001 (0.294)	loss 6.621 (6.622)	prob 3.032 (2.340)	GS 35.359 (33.028)	mem 72.573
Train: [91][860/1500]	BT 0.037 (0.330)	DT 0.000 (0.291)	loss 6.732 (6.611)	prob 2.243 (2.445)	GS 34.391 (33.006)	mem 72.573
Train: [91][870/1500]	BT 0.071 (0.326)	DT 0.018 (0.288)	loss 6.618 (6.612)	prob 2.245 (2.376)	GS 36.156 (33.031)	mem 72.575
Train: [91][880/1500]	BT 0.028 (0.328)	DT 0.000 (0.290)	loss 6.802 (6.635)	prob 2.160 (2.283)	GS 35.438 (33.185)	mem 72.574
Train: [91][890/1500]	BT 0.049 (0.325)	DT 0.001 (0.286)	loss 6.554 (6.612)	prob 2.698 (2.315)	GS 32.016 (33.256)	mem 72.576
Train: [91][900/1500]	BT 0.038 (0.330)	DT 0.001 (0.291)	loss 6.568 (6.609)	prob 1.942 (2.304)	GS 33.516 (33.144)	mem 72.575
Train: [91][910/1500]	BT 0.039 (0.327)	DT 0.001 (0.288)	loss 6.717 (6.528)	prob 1.637 (2.220)	GS 33.781 (33.822)	mem 72.574
Train: [91][920/1500]	BT 0.091 (0.325)	DT 0.006 (0.286)	loss 6.569 (6.579)	prob 2.197 (2.231)	GS 36.484 (34.026)	mem 72.576
Train: [91][930/1500]	BT 0.062 (0.328)	DT 0.011 (0.289)	loss 6.600 (6.585)	prob 2.913 (2.322)	GS 33.203 (33.127)	mem 72.577
Train: [91][940/1500]	BT 0.026 (0.338)	DT 0.000 (0.298)	loss 6.981 (6.593)	prob 2.283 (2.364)	GS 36.078 (33.084)	mem 72.574
Train: [91][950/1500]	BT 0.029 (0.334)	DT 0.000 (0.295)	loss 6.657 (6.580)	prob 2.360 (2.400)	GS 34.031 (32.913)	mem 72.576
Train: [91][960/1500]	BT 0.036 (0.331)	DT 0.000 (0.292)	loss 6.503 (6.607)	prob 2.912 (2.503)	GS 33.656 (31.933)	mem 72.577
Train: [91][970/1500]	BT 0.061 (0.333)	DT 0.013 (0.294)	loss 6.615 (6.586)	prob 2.133 (2.450)	GS 33.266 (32.103)	mem 72.578
Train: [91][980/1500]	BT 0.056 (0.330)	DT 0.010 (0.291)	loss 6.637 (6.584)	prob 2.748 (2.375)	GS 35.906 (32.225)	mem 72.577
Train: [91][990/1500]	BT 0.079 (0.335)	DT 0.002 (0.295)	loss 6.572 (6.577)	prob 1.989 (2.378)	GS 37.344 (32.293)	mem 72.579
Train: [91][1000/1500]	BT 0.056 (0.332)	DT 0.002 (0.293)	loss 6.518 (6.595)	prob 3.048 (2.398)	GS 39.203 (32.484)	mem 72.578
Train: [91][1010/1500]	BT 0.057 (0.334)	DT 0.013 (0.294)	loss 6.668 (6.608)	prob 2.781 (2.386)	GS 32.469 (32.928)	mem 72.579
Train: [91][1020/1500]	BT 0.033 (0.335)	DT 0.000 (0.296)	loss 6.734 (6.592)	prob 2.183 (2.593)	GS 36.156 (33.673)	mem 72.580
Train: [91][1030/1500]	BT 0.033 (0.332)	DT 0.000 (0.293)	loss 6.970 (6.595)	prob 2.345 (2.547)	GS 35.250 (32.915)	mem 72.580
Train: [91][1040/1500]	BT 0.058 (0.334)	DT 0.014 (0.294)	loss 6.648 (6.587)	prob 2.174 (2.527)	GS 33.797 (32.586)	mem 72.581
Train: [91][1050/1500]	BT 0.032 (0.331)	DT 0.001 (0.292)	loss 6.677 (6.588)	prob 2.306 (2.489)	GS 35.203 (32.799)	mem 72.580
Train: [91][1060/1500]	BT 0.049 (0.335)	DT 0.010 (0.295)	loss 6.554 (6.650)	prob 2.540 (2.746)	GS 31.000 (32.606)	mem 72.581
Train: [91][1070/1500]	BT 0.058 (0.332)	DT 0.014 (0.293)	loss 6.456 (6.637)	prob 2.713 (2.550)	GS 34.469 (31.956)	mem 72.581
Train: [91][1080/1500]	BT 0.038 (0.334)	DT 0.001 (0.294)	loss 6.550 (6.618)	prob 1.992 (2.414)	GS 36.656 (32.377)	mem 72.581
Train: [91][1090/1500]	BT 0.069 (0.331)	DT 0.014 (0.292)	loss 6.742 (6.612)	prob 1.947 (2.400)	GS 35.094 (32.336)	mem 72.582
Train: [91][1100/1500]	BT 0.025 (0.335)	DT 0.000 (0.295)	loss 6.613 (6.596)	prob 2.529 (2.391)	GS 34.328 (32.468)	mem 72.583
Train: [91][1110/1500]	BT 0.037 (0.332)	DT 0.001 (0.292)	loss 6.601 (6.604)	prob 2.443 (2.575)	GS 33.859 (32.056)	mem 72.582
Train: [91][1120/1500]	BT 0.039 (0.333)	DT 0.001 (0.294)	loss 6.525 (6.602)	prob 2.360 (2.515)	GS 33.500 (32.230)	mem 72.616
Train: [91][1130/1500]	BT 0.028 (0.331)	DT 0.000 (0.291)	loss 6.587 (6.584)	prob 1.744 (2.442)	GS 31.078 (32.502)	mem 72.616
Train: [91][1140/1500]	BT 0.039 (0.328)	DT 0.001 (0.289)	loss 6.561 (6.585)	prob 2.545 (2.400)	GS 36.922 (32.555)	mem 72.617
Train: [91][1150/1500]	BT 0.040 (0.328)	DT 0.001 (0.289)	loss 6.642 (6.583)	prob 2.426 (2.349)	GS 36.234 (32.672)	mem 72.616
Train: [91][1160/1500]	BT 0.039 (0.326)	DT 0.001 (0.286)	loss 6.503 (6.549)	prob 2.517 (2.296)	GS 34.875 (33.925)	mem 72.616
Train: [91][1170/1500]	BT 0.060 (0.329)	DT 0.016 (0.290)	loss 6.850 (6.599)	prob 2.158 (2.220)	GS 38.422 (32.902)	mem 72.615
Train: [91][1180/1500]	BT 0.031 (0.327)	DT 0.000 (0.288)	loss 6.738 (6.602)	prob 1.859 (2.182)	GS 30.578 (32.338)	mem 72.615
Train: [91][1190/1500]	BT 0.033 (0.334)	DT 0.000 (0.294)	loss 6.499 (6.591)	prob 1.891 (2.246)	GS 32.250 (32.473)	mem 72.614
Train: [91][1200/1500]	BT 0.032 (0.331)	DT 0.001 (0.292)	loss 6.484 (6.581)	prob 2.549 (2.297)	GS 38.312 (32.555)	mem 72.614
Train: [91][1210/1500]	BT 0.042 (0.331)	DT 0.001 (0.292)	loss 6.505 (6.633)	prob 1.837 (2.233)	GS 33.719 (33.827)	mem 72.616
Train: [91][1220/1500]	BT 0.039 (0.328)	DT 0.001 (0.289)	loss 6.497 (6.609)	prob 2.534 (2.297)	GS 30.094 (33.629)	mem 72.616
Train: [91][1230/1500]	BT 4.161 (0.329)	DT 4.124 (0.290)	loss 6.557 (6.591)	prob 2.417 (2.373)	GS 36.766 (33.565)	mem 72.616
Train: [91][1240/1500]	BT 0.038 (0.327)	DT 0.001 (0.288)	loss 6.564 (6.589)	prob 2.699 (2.361)	GS 34.375 (33.589)	mem 72.619
Train: [91][1250/1500]	BT 0.038 (0.325)	DT 0.001 (0.286)	loss 6.573 (6.594)	prob 2.116 (2.302)	GS 34.312 (33.417)	mem 72.619
Train: [91][1260/1500]	BT 0.023 (0.326)	DT 0.000 (0.287)	loss 6.574 (6.623)	prob 2.666 (2.140)	GS 34.984 (32.591)	mem 72.618
Train: [91][1270/1500]	BT 0.026 (0.324)	DT 0.000 (0.285)	loss 6.771 (6.612)	prob 2.560 (2.295)	GS 35.469 (32.670)	mem 72.618
Train: [91][1280/1500]	BT 0.027 (0.327)	DT 0.000 (0.288)	loss 6.665 (6.610)	prob 2.673 (2.366)	GS 29.984 (32.602)	mem 72.617
Train: [91][1290/1500]	BT 0.038 (0.325)	DT 0.000 (0.286)	loss 6.663 (6.605)	prob 2.411 (2.417)	GS 36.312 (32.445)	mem 72.618
Train: [91][1300/1500]	BT 0.040 (0.323)	DT 0.001 (0.284)	loss 6.707 (6.608)	prob 1.749 (2.354)	GS 36.469 (32.336)	mem 72.618
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [91][1310/1500]	BT 0.038 (0.323)	DT 0.001 (0.285)	loss 6.497 (6.628)	prob 2.331 (2.123)	GS 36.375 (33.198)	mem 72.617
Train: [91][1320/1500]	BT 0.039 (0.321)	DT 0.000 (0.283)	loss 6.600 (6.598)	prob 2.253 (2.248)	GS 34.078 (32.737)	mem 72.617
Train: [91][1330/1500]	BT 0.031 (0.325)	DT 0.000 (0.286)	loss 6.530 (6.585)	prob 2.036 (2.357)	GS 28.078 (32.197)	mem 72.618
Train: [91][1340/1500]	BT 0.035 (0.323)	DT 0.001 (0.284)	loss 6.665 (6.587)	prob 2.152 (2.318)	GS 36.656 (32.187)	mem 72.617
Train: [91][1350/1500]	BT 4.166 (0.324)	DT 4.127 (0.285)	loss 6.474 (6.577)	prob 2.182 (2.339)	GS 35.781 (32.439)	mem 72.618
Train: [91][1360/1500]	BT 0.041 (0.322)	DT 0.001 (0.283)	loss 6.716 (6.615)	prob 1.470 (2.014)	GS 36.469 (32.633)	mem 72.621
Train: [91][1370/1500]	BT 0.054 (0.323)	DT 0.008 (0.284)	loss 6.444 (6.572)	prob 2.225 (2.027)	GS 32.656 (32.613)	mem 72.622
Train: [91][1380/1500]	BT 0.065 (0.324)	DT 0.003 (0.285)	loss 6.605 (6.571)	prob 1.628 (2.000)	GS 34.406 (32.759)	mem 72.621
Train: [91][1390/1500]	BT 0.034 (0.324)	DT 0.000 (0.285)	loss 6.433 (6.573)	prob 2.442 (2.106)	GS 36.828 (33.263)	mem 72.618
Train: [91][1400/1500]	BT 0.036 (0.322)	DT 0.001 (0.283)	loss 6.516 (6.574)	prob 1.561 (2.110)	GS 32.109 (33.044)	mem 72.618
Train: [91][1410/1500]	BT 0.035 (0.323)	DT 0.000 (0.284)	loss 6.482 (6.569)	prob 2.110 (2.124)	GS 33.656 (33.334)	mem 72.625
Train: [91][1420/1500]	BT 0.032 (0.321)	DT 0.000 (0.282)	loss 6.578 (6.556)	prob 2.328 (2.267)	GS 34.031 (33.077)	mem 72.626
Train: [91][1430/1500]	BT 0.031 (0.319)	DT 0.000 (0.280)	loss 6.543 (6.562)	prob 2.390 (2.266)	GS 33.219 (32.514)	mem 72.628
Train: [91][1440/1500]	BT 0.038 (0.319)	DT 0.001 (0.280)	loss 6.598 (6.577)	prob 2.334 (2.252)	GS 32.547 (32.858)	mem 72.640
Train: [91][1450/1500]	BT 0.038 (0.318)	DT 0.001 (0.279)	loss 6.706 (6.573)	prob 1.801 (2.245)	GS 35.031 (32.868)	mem 72.640
Train: [91][1460/1500]	BT 0.047 (0.319)	DT 0.016 (0.281)	loss 6.606 (6.560)	prob 2.354 (2.417)	GS 31.031 (32.636)	mem 72.198
Train: [91][1470/1500]	BT 0.027 (0.319)	DT 0.000 (0.280)	loss 6.671 (6.591)	prob 2.371 (2.283)	GS 30.719 (31.797)	mem 71.853
Train: [91][1480/1500]	BT 0.030 (0.318)	DT 0.000 (0.279)	loss 6.527 (6.577)	prob 1.785 (2.166)	GS 33.391 (32.055)	mem 21.611
Train: [91][1490/1500]	BT 0.029 (0.316)	DT 0.000 (0.277)	loss 6.710 (6.588)	prob 1.927 (2.205)	GS 37.469 (32.371)	mem 13.152
Train: [91][1500/1500]	BT 0.033 (0.314)	DT 0.000 (0.276)	loss 6.240 (6.570)	prob 2.988 (2.243)	GS 29.250 (32.481)	mem 13.116
Train: [91][1510/1500]	BT 0.026 (0.312)	DT 0.000 (0.274)	loss 6.697 (6.283)	prob 2.034 (2.596)	GS 35.562 (33.416)	mem 10.234
epoch 91, total time 472.39
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [92][1/1500]	BT 24.009 (24.009)	DT 23.922 (23.922)	loss 6.167 (6.167)	prob 2.995 (2.995)	GS 33.812 (33.812)	mem 71.207
Train: [92][10/1500]	BT 0.038 (2.742)	DT 0.001 (2.695)	loss 6.335 (6.260)	prob 2.354 (2.442)	GS 30.891 (33.878)	mem 71.235
Train: [92][20/1500]	BT 0.038 (1.390)	DT 0.001 (1.348)	loss 6.377 (6.304)	prob 2.907 (2.462)	GS 30.891 (32.652)	mem 71.228
Train: [92][30/1500]	BT 0.038 (0.981)	DT 0.001 (0.940)	loss 6.451 (6.369)	prob 2.299 (2.490)	GS 36.922 (32.510)	mem 71.260
Train: [92][40/1500]	BT 0.040 (0.821)	DT 0.000 (0.781)	loss 6.553 (6.416)	prob 2.582 (2.480)	GS 32.500 (32.052)	mem 71.281
Train: [92][50/1500]	BT 0.039 (0.675)	DT 0.000 (0.635)	loss 6.601 (6.438)	prob 2.784 (2.498)	GS 35.797 (32.081)	mem 71.283
Train: [92][60/1500]	BT 0.039 (0.607)	DT 0.000 (0.567)	loss 6.636 (6.576)	prob 2.247 (2.512)	GS 31.141 (31.230)	mem 71.294
Train: [92][70/1500]	BT 0.038 (0.526)	DT 0.001 (0.486)	loss 6.575 (6.592)	prob 2.412 (2.408)	GS 32.094 (32.673)	mem 71.295
Train: [92][80/1500]	BT 0.038 (0.489)	DT 0.001 (0.449)	loss 6.853 (6.611)	prob 1.847 (2.373)	GS 32.094 (32.485)	mem 71.298
Train: [92][90/1500]	BT 0.070 (0.461)	DT 0.000 (0.420)	loss 6.771 (6.610)	prob 1.943 (2.420)	GS 32.266 (32.354)	mem 71.301
Train: [92][100/1500]	BT 0.082 (0.456)	DT 0.014 (0.414)	loss 6.640 (6.592)	prob 1.874 (2.417)	GS 34.281 (32.325)	mem 71.308
Train: [92][110/1500]	BT 0.031 (0.556)	DT 0.001 (0.515)	loss 6.541 (6.568)	prob 2.527 (2.336)	GS 30.172 (32.766)	mem 71.317
Train: [92][120/1500]	BT 0.037 (0.512)	DT 0.000 (0.472)	loss 6.489 (6.570)	prob 2.246 (2.244)	GS 30.734 (32.305)	mem 71.318
Train: [92][130/1500]	BT 0.027 (0.505)	DT 0.000 (0.465)	loss 6.504 (6.561)	prob 2.300 (2.223)	GS 31.922 (32.226)	mem 71.324
Train: [92][140/1500]	BT 0.039 (0.472)	DT 0.001 (0.432)	loss 6.653 (6.557)	prob 2.103 (2.213)	GS 34.109 (32.694)	mem 71.323
Train: [92][150/1500]	BT 0.039 (0.443)	DT 0.001 (0.403)	loss 6.528 (6.565)	prob 2.229 (2.244)	GS 36.312 (32.851)	mem 71.323
Train: [92][160/1500]	BT 0.038 (0.436)	DT 0.000 (0.397)	loss 6.458 (6.530)	prob 2.704 (2.076)	GS 34.844 (30.548)	mem 71.344
Train: [92][170/1500]	BT 0.055 (0.414)	DT 0.006 (0.374)	loss 6.514 (6.539)	prob 2.092 (2.157)	GS 32.109 (31.477)	mem 71.343
Train: [92][180/1500]	BT 0.037 (0.414)	DT 0.000 (0.374)	loss 6.677 (6.557)	prob 2.671 (2.176)	GS 31.469 (32.203)	mem 71.346
Train: [92][190/1500]	BT 0.037 (0.394)	DT 0.001 (0.354)	loss 6.456 (6.552)	prob 2.831 (2.208)	GS 36.141 (32.579)	mem 71.347
Train: [92][200/1500]	BT 6.862 (0.412)	DT 6.816 (0.372)	loss 6.489 (6.557)	prob 2.284 (2.211)	GS 34.000 (32.800)	mem 71.351
Train: [92][210/1500]	BT 0.033 (0.401)	DT 0.000 (0.361)	loss 6.691 (6.541)	prob 2.353 (2.247)	GS 32.656 (32.305)	mem 71.355
Train: [92][220/1500]	BT 0.039 (0.384)	DT 0.000 (0.345)	loss 6.534 (6.538)	prob 2.035 (2.325)	GS 30.219 (32.142)	mem 71.356
Train: [92][230/1500]	BT 0.031 (0.412)	DT 0.000 (0.372)	loss 6.709 (6.552)	prob 2.365 (2.208)	GS 35.344 (32.757)	mem 71.604
Train: [92][240/1500]	BT 0.031 (0.396)	DT 0.000 (0.356)	loss 6.475 (6.549)	prob 2.871 (2.286)	GS 34.828 (33.099)	mem 71.605
Train: [92][250/1500]	BT 0.048 (0.412)	DT 0.015 (0.372)	loss 6.423 (6.540)	prob 2.726 (2.356)	GS 33.375 (33.040)	mem 72.389
Train: [92][260/1500]	BT 0.031 (0.427)	DT 0.001 (0.387)	loss 6.541 (6.565)	prob 2.094 (2.058)	GS 38.703 (31.597)	mem 72.491
Train: [92][270/1500]	BT 0.027 (0.412)	DT 0.000 (0.373)	loss 6.445 (6.530)	prob 2.364 (2.139)	GS 31.000 (31.871)	mem 72.540
Train: [92][280/1500]	BT 0.039 (0.408)	DT 0.001 (0.370)	loss 6.671 (6.533)	prob 1.977 (2.133)	GS 26.688 (31.784)	mem 72.545
Train: [92][290/1500]	BT 0.037 (0.395)	DT 0.000 (0.357)	loss 6.454 (6.533)	prob 2.223 (2.175)	GS 34.922 (31.775)	mem 72.547
Train: [92][300/1500]	BT 0.037 (0.383)	DT 0.000 (0.345)	loss 6.685 (6.533)	prob 1.990 (2.191)	GS 33.250 (31.884)	mem 72.547
Train: [92][310/1500]	BT 0.029 (0.392)	DT 0.000 (0.354)	loss 6.443 (6.541)	prob 2.847 (2.390)	GS 32.422 (32.795)	mem 72.552
Train: [92][320/1500]	BT 0.037 (0.381)	DT 0.001 (0.343)	loss 6.501 (6.574)	prob 2.590 (2.401)	GS 31.438 (32.825)	mem 72.553
Train: [92][330/1500]	BT 0.034 (0.380)	DT 0.000 (0.342)	loss 6.598 (6.576)	prob 2.474 (2.393)	GS 36.938 (33.076)	mem 72.555
Train: [92][340/1500]	BT 0.034 (0.370)	DT 0.000 (0.332)	loss 6.578 (6.567)	prob 2.349 (2.419)	GS 32.000 (32.875)	mem 72.556
Train: [92][350/1500]	BT 3.139 (0.369)	DT 3.102 (0.331)	loss 6.605 (6.565)	prob 1.979 (2.401)	GS 33.812 (32.760)	mem 72.557
Train: [92][360/1500]	BT 0.037 (0.360)	DT 0.000 (0.322)	loss 6.608 (6.543)	prob 2.002 (2.011)	GS 36.297 (33.117)	mem 72.559
Train: [92][370/1500]	BT 0.037 (0.351)	DT 0.000 (0.313)	loss 6.513 (6.543)	prob 2.382 (2.160)	GS 34.234 (32.425)	mem 72.559
Train: [92][380/1500]	BT 0.036 (0.353)	DT 0.001 (0.316)	loss 6.886 (6.550)	prob 2.237 (2.125)	GS 35.750 (32.571)	mem 72.559
Train: [92][390/1500]	BT 0.037 (0.345)	DT 0.001 (0.307)	loss 6.720 (6.557)	prob 2.146 (2.158)	GS 35.672 (32.802)	mem 72.559
Train: [92][400/1500]	BT 0.040 (0.347)	DT 0.005 (0.310)	loss 6.728 (6.549)	prob 1.903 (2.151)	GS 33.875 (32.875)	mem 72.561
Train: [92][410/1500]	BT 0.038 (0.342)	DT 0.001 (0.304)	loss 6.709 (6.592)	prob 1.857 (2.137)	GS 33.656 (33.358)	mem 72.561
Train: [92][420/1500]	BT 0.032 (0.340)	DT 0.000 (0.302)	loss 6.612 (6.566)	prob 2.416 (2.283)	GS 32.578 (33.441)	mem 72.562
Train: [92][430/1500]	BT 0.038 (0.338)	DT 0.001 (0.300)	loss 6.556 (6.566)	prob 2.766 (2.298)	GS 31.734 (33.036)	mem 72.565
Train: [92][440/1500]	BT 0.037 (0.331)	DT 0.001 (0.293)	loss 6.614 (6.559)	prob 1.911 (2.268)	GS 35.062 (32.857)	mem 72.564
Train: [92][450/1500]	BT 0.063 (0.332)	DT 0.025 (0.294)	loss 6.471 (6.557)	prob 2.465 (2.258)	GS 36.094 (32.844)	mem 72.567
Train: [92][460/1500]	BT 0.076 (0.326)	DT 0.007 (0.288)	loss 6.539 (6.550)	prob 1.952 (2.323)	GS 33.109 (32.906)	mem 72.568
Train: [92][470/1500]	BT 0.686 (0.329)	DT 0.649 (0.291)	loss 6.692 (6.546)	prob 1.939 (2.218)	GS 30.016 (32.154)	mem 72.570
Train: [92][480/1500]	BT 0.037 (0.323)	DT 0.001 (0.286)	loss 6.436 (6.554)	prob 2.567 (2.244)	GS 32.688 (32.330)	mem 72.570
Train: [92][490/1500]	BT 0.052 (0.323)	DT 0.013 (0.285)	loss 6.508 (6.575)	prob 2.728 (2.235)	GS 31.625 (32.405)	mem 72.573
Train: [92][500/1500]	BT 0.123 (0.320)	DT 0.089 (0.282)	loss 6.721 (6.580)	prob 2.066 (2.244)	GS 35.203 (32.781)	mem 72.573
Train: [92][510/1500]	BT 0.038 (0.321)	DT 0.001 (0.283)	loss 6.710 (6.579)	prob 2.060 (1.952)	GS 37.578 (32.325)	mem 72.606
Train: [92][520/1500]	BT 0.060 (0.319)	DT 0.006 (0.281)	loss 6.473 (6.598)	prob 1.912 (2.145)	GS 29.469 (32.698)	mem 72.607
Train: [92][530/1500]	BT 0.048 (0.323)	DT 0.007 (0.285)	loss 6.621 (6.611)	prob 1.985 (2.204)	GS 36.328 (33.086)	mem 72.608
Train: [92][540/1500]	BT 0.039 (0.319)	DT 0.001 (0.281)	loss 6.509 (6.601)	prob 2.641 (2.276)	GS 37.125 (33.021)	mem 72.607
Train: [92][550/1500]	BT 0.039 (0.316)	DT 0.001 (0.278)	loss 6.609 (6.601)	prob 2.129 (2.306)	GS 37.281 (33.333)	mem 72.608
Train: [92][560/1500]	BT 0.039 (0.313)	DT 0.001 (0.275)	loss 6.518 (6.561)	prob 2.607 (2.374)	GS 30.656 (32.395)	mem 72.608
Train: [92][570/1500]	BT 0.039 (0.311)	DT 0.000 (0.273)	loss 6.523 (6.561)	prob 2.482 (2.333)	GS 30.141 (32.044)	mem 72.609
Train: [92][580/1500]	BT 0.039 (0.310)	DT 0.001 (0.272)	loss 6.428 (6.549)	prob 2.098 (2.221)	GS 30.406 (32.233)	mem 72.610
Train: [92][590/1500]	BT 0.039 (0.309)	DT 0.001 (0.270)	loss 6.493 (6.543)	prob 2.282 (2.267)	GS 36.453 (32.502)	mem 72.610
Train: [92][600/1500]	BT 0.039 (0.306)	DT 0.001 (0.267)	loss 6.616 (6.544)	prob 1.888 (2.236)	GS 29.578 (32.393)	mem 72.611
Train: [92][610/1500]	BT 0.038 (0.304)	DT 0.001 (0.266)	loss 6.472 (6.521)	prob 2.205 (2.309)	GS 34.562 (32.345)	mem 72.614
Train: [92][620/1500]	BT 0.039 (0.304)	DT 0.001 (0.265)	loss 6.691 (6.558)	prob 2.213 (2.074)	GS 36.141 (32.980)	mem 72.615
Train: [92][630/1500]	BT 0.034 (0.321)	DT 0.001 (0.283)	loss 6.594 (6.558)	prob 2.042 (2.132)	GS 34.156 (33.530)	mem 72.614
Train: [92][640/1500]	BT 0.040 (0.317)	DT 0.001 (0.279)	loss 6.528 (6.561)	prob 2.465 (2.258)	GS 33.203 (33.157)	mem 72.617
Train: [92][650/1500]	BT 0.039 (0.313)	DT 0.001 (0.274)	loss 6.521 (6.553)	prob 2.134 (2.250)	GS 33.594 (33.341)	mem 72.617
Train: [92][660/1500]	BT 0.038 (0.313)	DT 0.001 (0.274)	loss 6.378 (6.508)	prob 2.418 (2.329)	GS 35.797 (32.030)	mem 72.617
Train: [92][670/1500]	BT 0.039 (0.309)	DT 0.001 (0.270)	loss 6.556 (6.548)	prob 2.470 (2.420)	GS 33.703 (33.034)	mem 72.618
Train: [92][680/1500]	BT 0.039 (0.311)	DT 0.001 (0.272)	loss 6.467 (6.549)	prob 2.731 (2.389)	GS 33.609 (32.589)	mem 72.618
Train: [92][690/1500]	BT 0.036 (0.308)	DT 0.001 (0.269)	loss 6.578 (6.556)	prob 2.869 (2.413)	GS 31.719 (32.479)	mem 72.618
Train: [92][700/1500]	BT 0.035 (0.304)	DT 0.001 (0.266)	loss 6.546 (6.554)	prob 3.114 (2.475)	GS 33.375 (32.720)	mem 72.620
Train: [92][710/1500]	BT 1.560 (0.306)	DT 1.509 (0.268)	loss 6.606 (6.572)	prob 2.959 (2.630)	GS 34.000 (30.934)	mem 72.619
Train: [92][720/1500]	BT 0.042 (0.303)	DT 0.001 (0.264)	loss 6.639 (6.580)	prob 2.228 (2.553)	GS 33.359 (30.534)	mem 72.618
Train: [92][730/1500]	BT 0.060 (0.308)	DT 0.001 (0.269)	loss 6.622 (6.560)	prob 2.641 (2.534)	GS 26.609 (30.878)	mem 72.617
Train: [92][740/1500]	BT 0.039 (0.308)	DT 0.001 (0.270)	loss 6.524 (6.565)	prob 2.546 (2.449)	GS 33.547 (31.182)	mem 72.620
Train: [92][750/1500]	BT 0.038 (0.309)	DT 0.000 (0.270)	loss 6.613 (6.567)	prob 1.955 (2.442)	GS 32.094 (31.669)	mem 72.617
Train: [92][760/1500]	BT 0.039 (0.305)	DT 0.001 (0.267)	loss 6.670 (6.643)	prob 2.037 (2.355)	GS 33.766 (34.091)	mem 72.618
Train: [92][770/1500]	BT 0.751 (0.303)	DT 0.712 (0.264)	loss 6.542 (6.602)	prob 2.579 (2.432)	GS 35.203 (33.153)	mem 72.618
Train: [92][780/1500]	BT 0.029 (0.305)	DT 0.000 (0.266)	loss 6.675 (6.620)	prob 2.755 (2.522)	GS 32.703 (32.960)	mem 72.617
Train: [92][790/1500]	BT 0.037 (0.301)	DT 0.001 (0.263)	loss 6.504 (6.596)	prob 2.326 (2.440)	GS 35.875 (32.947)	mem 72.617
Train: [92][800/1500]	BT 0.058 (0.302)	DT 0.006 (0.263)	loss 6.529 (6.586)	prob 2.178 (2.390)	GS 36.172 (32.856)	mem 72.619
Train: [92][810/1500]	BT 0.031 (0.301)	DT 0.000 (0.263)	loss 6.487 (6.545)	prob 2.762 (2.211)	GS 33.750 (32.703)	mem 72.623
Train: [92][820/1500]	BT 0.037 (0.298)	DT 0.001 (0.259)	loss 6.552 (6.543)	prob 2.538 (2.298)	GS 30.203 (32.418)	mem 72.626
Train: [92][830/1500]	BT 0.566 (0.299)	DT 0.530 (0.260)	loss 6.455 (6.563)	prob 2.270 (2.217)	GS 35.641 (32.462)	mem 72.638
Train: [92][840/1500]	BT 0.038 (0.295)	DT 0.000 (0.257)	loss 6.544 (6.551)	prob 2.821 (2.312)	GS 35.047 (32.245)	mem 72.640
Train: [92][850/1500]	BT 0.036 (0.298)	DT 0.000 (0.259)	loss 6.498 (6.560)	prob 2.064 (2.303)	GS 30.391 (32.554)	mem 72.536
Train: [92][860/1500]	BT 0.037 (0.295)	DT 0.000 (0.256)	loss 6.389 (6.553)	prob 2.563 (2.177)	GS 32.938 (31.986)	mem 72.536
Train: [92][870/1500]	BT 0.038 (0.292)	DT 0.001 (0.253)	loss 6.535 (6.525)	prob 2.624 (2.320)	GS 31.969 (31.830)	mem 72.536
Train: [92][880/1500]	BT 0.032 (0.294)	DT 0.000 (0.255)	loss 6.516 (6.551)	prob 2.177 (2.414)	GS 35.062 (32.367)	mem 72.537
Train: [92][890/1500]	BT 0.025 (0.291)	DT 0.000 (0.252)	loss 6.526 (6.545)	prob 2.536 (2.390)	GS 33.359 (32.307)	mem 72.540
Train: [92][900/1500]	BT 0.711 (0.292)	DT 0.675 (0.254)	loss 6.701 (6.552)	prob 2.252 (2.399)	GS 35.797 (32.467)	mem 72.540
Train: [92][910/1500]	BT 0.037 (0.289)	DT 0.000 (0.251)	loss 6.585 (6.553)	prob 2.051 (2.171)	GS 35.234 (33.728)	mem 72.539
Train: [92][920/1500]	BT 0.027 (0.290)	DT 0.000 (0.252)	loss 6.628 (6.573)	prob 2.131 (2.251)	GS 35.172 (33.355)	mem 72.540
Train: [92][930/1500]	BT 0.038 (0.287)	DT 0.001 (0.249)	loss 6.370 (6.559)	prob 2.750 (2.289)	GS 30.797 (32.709)	mem 72.543
Train: [92][940/1500]	BT 0.038 (0.285)	DT 0.001 (0.247)	loss 6.452 (6.548)	prob 2.110 (2.297)	GS 27.766 (32.339)	mem 72.544
Train: [92][950/1500]	BT 0.048 (0.291)	DT 0.000 (0.253)	loss 6.968 (6.547)	prob 1.776 (2.216)	GS 35.094 (32.224)	mem 72.543
Train: [92][960/1500]	BT 0.024 (0.290)	DT 0.000 (0.252)	loss 6.569 (6.558)	prob 2.193 (2.536)	GS 30.453 (32.372)	mem 72.561
Train: [92][970/1500]	BT 0.029 (0.288)	DT 0.000 (0.250)	loss 6.460 (6.560)	prob 2.494 (2.421)	GS 34.688 (32.749)	mem 72.562
Train: [92][980/1500]	BT 0.067 (0.290)	DT 0.011 (0.252)	loss 6.613 (6.561)	prob 2.718 (2.478)	GS 34.922 (33.194)	mem 72.551
Train: [92][990/1500]	BT 0.055 (0.288)	DT 0.013 (0.250)	loss 6.571 (6.558)	prob 2.632 (2.488)	GS 34.953 (33.263)	mem 72.551
Train: [92][1000/1500]	BT 0.037 (0.288)	DT 0.000 (0.249)	loss 6.681 (6.560)	prob 2.110 (2.522)	GS 33.625 (33.426)	mem 72.550
Train: [92][1010/1500]	BT 0.029 (0.290)	DT 0.000 (0.251)	loss 6.602 (6.539)	prob 2.300 (2.279)	GS 29.875 (32.981)	mem 72.550
Train: [92][1020/1500]	BT 0.435 (0.288)	DT 0.398 (0.249)	loss 6.574 (6.527)	prob 2.000 (2.374)	GS 31.031 (32.291)	mem 72.551
Train: [92][1030/1500]	BT 0.064 (0.289)	DT 0.004 (0.251)	loss 6.485 (6.524)	prob 2.872 (2.448)	GS 30.641 (32.136)	mem 72.553
Train: [92][1040/1500]	BT 0.039 (0.286)	DT 0.001 (0.248)	loss 6.395 (6.520)	prob 2.477 (2.406)	GS 36.672 (32.257)	mem 72.551
Train: [92][1050/1500]	BT 0.039 (0.289)	DT 0.001 (0.251)	loss 6.609 (6.528)	prob 2.282 (2.384)	GS 35.453 (32.641)	mem 72.550
Train: [92][1060/1500]	BT 0.053 (0.287)	DT 0.001 (0.249)	loss 6.482 (6.484)	prob 2.426 (2.554)	GS 35.250 (32.998)	mem 72.550
Train: [92][1070/1500]	BT 0.031 (0.285)	DT 0.000 (0.247)	loss 6.493 (6.508)	prob 2.173 (2.500)	GS 34.359 (32.531)	mem 72.549
Train: [92][1080/1500]	BT 0.061 (0.288)	DT 0.001 (0.250)	loss 6.573 (6.514)	prob 1.747 (2.400)	GS 36.562 (32.019)	mem 72.552
Train: [92][1090/1500]	BT 0.038 (0.287)	DT 0.000 (0.249)	loss 6.397 (6.510)	prob 2.668 (2.374)	GS 28.250 (32.145)	mem 72.550
Train: [92][1100/1500]	BT 0.039 (0.288)	DT 0.001 (0.250)	loss 6.554 (6.519)	prob 2.223 (2.339)	GS 31.672 (32.065)	mem 72.551
Train: [92][1110/1500]	BT 0.040 (0.286)	DT 0.001 (0.247)	loss 6.543 (6.577)	prob 2.421 (2.491)	GS 36.719 (33.333)	mem 72.552
Train: [92][1120/1500]	BT 0.116 (0.284)	DT 0.014 (0.246)	loss 6.656 (6.570)	prob 2.140 (2.434)	GS 32.359 (33.241)	mem 72.551
Train: [92][1130/1500]	BT 0.028 (0.292)	DT 0.000 (0.253)	loss 6.646 (6.586)	prob 2.738 (2.509)	GS 34.062 (34.120)	mem 72.566
Train: [92][1140/1500]	BT 0.035 (0.290)	DT 0.000 (0.251)	loss 6.483 (6.570)	prob 2.869 (2.614)	GS 36.266 (34.227)	mem 72.570
Train: [92][1150/1500]	BT 0.037 (0.290)	DT 0.001 (0.252)	loss 6.697 (6.559)	prob 1.828 (2.600)	GS 43.141 (33.921)	mem 72.575
Train: [92][1160/1500]	BT 0.037 (0.288)	DT 0.000 (0.250)	loss 6.588 (6.592)	prob 2.322 (2.503)	GS 28.281 (32.697)	mem 72.576
Train: [92][1170/1500]	BT 0.030 (0.291)	DT 0.000 (0.253)	loss 6.436 (6.566)	prob 2.881 (2.433)	GS 34.328 (31.871)	mem 72.577
Train: [92][1180/1500]	BT 0.029 (0.288)	DT 0.000 (0.250)	loss 6.631 (6.573)	prob 2.566 (2.486)	GS 34.109 (32.322)	mem 72.577
Train: [92][1190/1500]	BT 0.037 (0.286)	DT 0.000 (0.248)	loss 6.710 (6.559)	prob 2.366 (2.547)	GS 34.109 (33.098)	mem 72.579
Train: [92][1200/1500]	BT 0.034 (0.288)	DT 0.000 (0.250)	loss 6.430 (6.554)	prob 2.244 (2.516)	GS 31.656 (32.998)	mem 72.580
Train: [92][1210/1500]	BT 0.064 (0.286)	DT 0.013 (0.248)	loss 6.503 (6.502)	prob 2.207 (2.275)	GS 34.219 (32.542)	mem 72.583
Train: [92][1220/1500]	BT 0.031 (0.291)	DT 0.000 (0.253)	loss 6.592 (6.508)	prob 2.403 (2.474)	GS 32.609 (33.512)	mem 72.583
Train: [92][1230/1500]	BT 0.034 (0.289)	DT 0.000 (0.251)	loss 6.461 (6.512)	prob 2.825 (2.497)	GS 31.562 (32.795)	mem 72.586
Train: [92][1240/1500]	BT 0.032 (0.292)	DT 0.000 (0.254)	loss 6.401 (6.517)	prob 2.403 (2.471)	GS 32.906 (33.013)	mem 72.586
Train: [92][1250/1500]	BT 0.022 (0.290)	DT 0.000 (0.252)	loss 6.596 (6.509)	prob 2.400 (2.431)	GS 33.156 (33.027)	mem 72.588
Train: [92][1260/1500]	BT 0.039 (0.288)	DT 0.001 (0.250)	loss 6.535 (6.502)	prob 2.360 (2.637)	GS 35.156 (32.967)	mem 72.588
Train: [92][1270/1500]	BT 0.094 (0.291)	DT 0.006 (0.253)	loss 6.515 (6.527)	prob 1.824 (2.533)	GS 34.516 (32.408)	mem 72.587
Train: [92][1280/1500]	BT 0.050 (0.290)	DT 0.008 (0.251)	loss 6.553 (6.550)	prob 2.677 (2.346)	GS 32.969 (32.200)	mem 72.587
Train: [92][1290/1500]	BT 0.031 (0.294)	DT 0.000 (0.256)	loss 6.566 (6.553)	prob 2.139 (2.355)	GS 31.547 (32.638)	mem 72.588
Train: [92][1300/1500]	BT 0.030 (0.293)	DT 0.000 (0.255)	loss 6.466 (6.543)	prob 2.841 (2.402)	GS 33.844 (33.231)	mem 72.589
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [92][1310/1500]	BT 0.037 (0.295)	DT 0.001 (0.257)	loss 6.627 (6.510)	prob 1.947 (2.473)	GS 36.312 (32.100)	mem 72.589
Train: [92][1320/1500]	BT 0.037 (0.293)	DT 0.000 (0.255)	loss 6.533 (6.515)	prob 2.092 (2.320)	GS 36.578 (32.170)	mem 72.590
Train: [92][1330/1500]	BT 0.037 (0.291)	DT 0.000 (0.253)	loss 6.430 (6.530)	prob 2.908 (2.313)	GS 31.422 (32.142)	mem 72.589
Train: [92][1340/1500]	BT 0.031 (0.294)	DT 0.000 (0.255)	loss 6.393 (6.525)	prob 3.075 (2.421)	GS 34.969 (32.335)	mem 72.590
Train: [92][1350/1500]	BT 0.060 (0.292)	DT 0.001 (0.254)	loss 6.621 (6.524)	prob 1.888 (2.466)	GS 34.625 (32.647)	mem 72.590
Train: [92][1360/1500]	BT 0.029 (0.294)	DT 0.000 (0.256)	loss 6.427 (6.568)	prob 2.342 (2.406)	GS 35.422 (32.477)	mem 72.591
Train: [92][1370/1500]	BT 0.028 (0.292)	DT 0.000 (0.254)	loss 6.460 (6.530)	prob 2.576 (2.431)	GS 34.469 (32.671)	mem 72.591
Train: [92][1380/1500]	BT 0.033 (0.291)	DT 0.000 (0.252)	loss 6.870 (6.533)	prob 1.929 (2.461)	GS 32.406 (32.728)	mem 72.591
Train: [92][1390/1500]	BT 0.024 (0.292)	DT 0.000 (0.253)	loss 6.465 (6.527)	prob 2.745 (2.477)	GS 32.203 (32.440)	mem 72.594
Train: [92][1400/1500]	BT 0.024 (0.290)	DT 0.000 (0.252)	loss 6.392 (6.525)	prob 2.184 (2.438)	GS 35.750 (32.397)	mem 72.594
Train: [92][1410/1500]	BT 0.039 (0.290)	DT 0.000 (0.252)	loss 6.553 (6.536)	prob 3.184 (2.789)	GS 33.031 (33.927)	mem 72.595
Train: [92][1420/1500]	BT 0.037 (0.289)	DT 0.001 (0.251)	loss 6.513 (6.564)	prob 2.986 (2.741)	GS 32.344 (33.165)	mem 72.595
Train: [92][1430/1500]	BT 0.040 (0.289)	DT 0.001 (0.251)	loss 6.479 (6.545)	prob 2.904 (2.693)	GS 32.328 (32.658)	mem 72.597
Train: [92][1440/1500]	BT 0.051 (0.288)	DT 0.001 (0.250)	loss 6.533 (6.541)	prob 2.730 (2.690)	GS 33.938 (32.484)	mem 72.597
Train: [92][1450/1500]	BT 0.050 (0.287)	DT 0.003 (0.248)	loss 6.489 (6.534)	prob 2.298 (2.637)	GS 31.328 (32.322)	mem 72.597
Train: [92][1460/1500]	BT 0.036 (0.288)	DT 0.000 (0.250)	loss 6.516 (6.528)	prob 3.361 (2.730)	GS 34.797 (33.683)	mem 72.274
Train: [92][1470/1500]	BT 0.032 (0.286)	DT 0.000 (0.248)	loss 6.562 (6.533)	prob 2.666 (2.684)	GS 31.891 (33.334)	mem 72.274
Train: [92][1480/1500]	BT 0.029 (0.288)	DT 0.001 (0.250)	loss 6.520 (6.531)	prob 2.431 (2.651)	GS 32.500 (33.327)	mem 7.969
Train: [92][1490/1500]	BT 0.024 (0.286)	DT 0.000 (0.248)	loss 6.611 (6.538)	prob 2.241 (2.638)	GS 35.625 (33.145)	mem 7.545
Train: [92][1500/1500]	BT 0.024 (0.284)	DT 0.000 (0.246)	loss 6.592 (6.541)	prob 2.410 (2.636)	GS 34.438 (32.851)	mem 7.545
Train: [92][1510/1500]	BT 0.034 (0.283)	DT 0.000 (0.245)	loss 6.456 (6.366)	prob 3.373 (2.484)	GS 36.719 (35.516)	mem 7.471
epoch 92, total time 427.70
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [93][1/1500]	BT 25.107 (25.107)	DT 25.050 (25.050)	loss 6.151 (6.151)	prob 2.800 (2.800)	GS 33.594 (33.594)	mem 71.239
Train: [93][10/1500]	BT 0.048 (2.833)	DT 0.009 (2.787)	loss 6.319 (6.251)	prob 1.897 (2.585)	GS 35.938 (32.675)	mem 71.275
Train: [93][20/1500]	BT 0.057 (1.436)	DT 0.009 (1.395)	loss 6.253 (6.322)	prob 2.514 (2.623)	GS 31.969 (32.979)	mem 71.292
Train: [93][30/1500]	BT 0.029 (1.492)	DT 0.000 (1.453)	loss 6.461 (6.374)	prob 3.239 (2.539)	GS 29.969 (32.887)	mem 71.341
Train: [93][40/1500]	BT 0.027 (1.126)	DT 0.000 (1.090)	loss 6.579 (6.401)	prob 3.067 (2.589)	GS 32.578 (32.920)	mem 71.341
Train: [93][50/1500]	BT 0.070 (1.008)	DT 0.015 (0.971)	loss 6.510 (6.423)	prob 2.538 (2.621)	GS 38.203 (32.920)	mem 71.361
Train: [93][60/1500]	BT 0.091 (0.850)	DT 0.004 (0.811)	loss 6.440 (6.470)	prob 2.660 (2.659)	GS 31.000 (31.505)	mem 71.361
Train: [93][70/1500]	BT 0.051 (0.738)	DT 0.003 (0.695)	loss 6.397 (6.493)	prob 2.609 (2.661)	GS 35.391 (32.353)	mem 71.361
Train: [93][80/1500]	BT 0.030 (0.751)	DT 0.000 (0.710)	loss 6.705 (6.515)	prob 2.123 (2.597)	GS 30.734 (33.189)	mem 71.380
Train: [93][90/1500]	BT 0.029 (0.671)	DT 0.000 (0.631)	loss 6.598 (6.527)	prob 2.847 (2.594)	GS 35.312 (33.188)	mem 71.381
Train: [93][100/1500]	BT 0.035 (0.648)	DT 0.000 (0.610)	loss 6.573 (6.525)	prob 2.271 (2.568)	GS 37.266 (33.048)	mem 71.392
Train: [93][110/1500]	BT 0.039 (0.593)	DT 0.001 (0.555)	loss 6.431 (6.546)	prob 2.204 (2.728)	GS 28.547 (32.434)	mem 71.392
Train: [93][120/1500]	BT 0.052 (0.576)	DT 0.013 (0.537)	loss 6.473 (6.545)	prob 2.422 (2.670)	GS 34.062 (32.705)	mem 71.398
Train: [93][130/1500]	BT 0.039 (0.535)	DT 0.001 (0.496)	loss 6.557 (6.545)	prob 2.762 (2.752)	GS 33.781 (33.010)	mem 71.400
Train: [93][140/1500]	BT 0.039 (0.500)	DT 0.001 (0.460)	loss 6.560 (6.549)	prob 2.860 (2.726)	GS 26.547 (32.626)	mem 71.400
Train: [93][150/1500]	BT 0.039 (0.494)	DT 0.000 (0.455)	loss 6.599 (6.548)	prob 2.258 (2.684)	GS 37.750 (32.600)	mem 71.404
Train: [93][160/1500]	BT 0.039 (0.465)	DT 0.001 (0.426)	loss 6.823 (6.570)	prob 2.481 (2.627)	GS 37.562 (34.130)	mem 71.404
Train: [93][170/1500]	BT 0.038 (0.467)	DT 0.000 (0.428)	loss 6.566 (6.561)	prob 2.512 (2.595)	GS 35.531 (33.855)	mem 71.409
Train: [93][180/1500]	BT 0.031 (0.443)	DT 0.000 (0.404)	loss 6.429 (6.565)	prob 2.465 (2.599)	GS 37.281 (33.930)	mem 71.412
Train: [93][190/1500]	BT 0.039 (0.422)	DT 0.001 (0.383)	loss 6.676 (6.573)	prob 2.883 (2.555)	GS 33.266 (33.485)	mem 71.412
Train: [93][200/1500]	BT 0.032 (0.426)	DT 0.000 (0.387)	loss 6.542 (6.567)	prob 3.363 (2.586)	GS 36.391 (33.400)	mem 71.415
Train: [93][210/1500]	BT 0.064 (0.409)	DT 0.003 (0.369)	loss 6.518 (6.595)	prob 2.828 (2.914)	GS 34.359 (33.442)	mem 71.415
Train: [93][220/1500]	BT 0.029 (0.419)	DT 0.000 (0.380)	loss 6.548 (6.594)	prob 2.611 (2.850)	GS 32.938 (33.754)	mem 71.417
Train: [93][230/1500]	BT 0.027 (0.402)	DT 0.000 (0.363)	loss 6.659 (6.584)	prob 2.670 (2.806)	GS 36.625 (33.889)	mem 71.417
Train: [93][240/1500]	BT 0.031 (0.403)	DT 0.000 (0.365)	loss 6.514 (6.586)	prob 3.478 (2.810)	GS 34.078 (33.614)	mem 71.437
Train: [93][250/1500]	BT 0.037 (0.388)	DT 0.001 (0.350)	loss 6.515 (6.583)	prob 2.037 (2.773)	GS 35.328 (33.593)	mem 71.438
Train: [93][260/1500]	BT 0.038 (0.375)	DT 0.001 (0.337)	loss 6.513 (6.538)	prob 3.124 (2.735)	GS 32.609 (31.648)	mem 71.439
Train: [93][270/1500]	BT 0.059 (0.378)	DT 0.011 (0.340)	loss 6.578 (6.536)	prob 2.268 (2.753)	GS 31.141 (31.841)	mem 71.441
Train: [93][280/1500]	BT 0.052 (0.367)	DT 0.013 (0.328)	loss 6.579 (6.524)	prob 2.478 (2.740)	GS 34.406 (31.932)	mem 71.442
Train: [93][290/1500]	BT 0.031 (0.380)	DT 0.000 (0.341)	loss 6.583 (6.521)	prob 2.318 (2.658)	GS 29.203 (31.559)	mem 71.440
Train: [93][300/1500]	BT 0.050 (0.369)	DT 0.011 (0.330)	loss 6.490 (6.519)	prob 2.613 (2.636)	GS 34.203 (31.750)	mem 71.440
Train: [93][310/1500]	BT 0.030 (0.397)	DT 0.001 (0.359)	loss 6.484 (6.561)	prob 2.111 (2.471)	GS 36.359 (34.330)	mem 71.336
Train: [93][320/1500]	BT 0.034 (0.386)	DT 0.000 (0.347)	loss 6.491 (6.558)	prob 2.764 (2.461)	GS 37.250 (33.100)	mem 71.343
Train: [93][330/1500]	BT 0.035 (0.375)	DT 0.000 (0.337)	loss 6.447 (6.547)	prob 3.032 (2.503)	GS 29.828 (32.654)	mem 71.346
Train: [93][340/1500]	BT 0.037 (0.373)	DT 0.000 (0.335)	loss 6.666 (6.543)	prob 2.196 (2.538)	GS 32.250 (32.387)	mem 71.346
Train: [93][350/1500]	BT 0.037 (0.363)	DT 0.000 (0.325)	loss 6.510 (6.536)	prob 2.868 (2.569)	GS 35.922 (32.409)	mem 71.346
Train: [93][360/1500]	BT 0.036 (0.364)	DT 0.000 (0.326)	loss 6.504 (6.508)	prob 2.233 (2.642)	GS 32.328 (32.508)	mem 71.443
Train: [93][370/1500]	BT 0.037 (0.355)	DT 0.000 (0.317)	loss 6.603 (6.515)	prob 2.535 (2.645)	GS 31.406 (32.829)	mem 71.443
Train: [93][380/1500]	BT 0.028 (0.377)	DT 0.000 (0.339)	loss 6.434 (6.528)	prob 2.419 (2.599)	GS 33.984 (33.303)	mem 72.200
Train: [93][390/1500]	BT 0.044 (0.368)	DT 0.000 (0.330)	loss 6.591 (6.537)	prob 3.234 (2.592)	GS 33.859 (33.132)	mem 72.201
Train: [93][400/1500]	BT 0.036 (0.360)	DT 0.000 (0.322)	loss 6.465 (6.537)	prob 2.730 (2.612)	GS 36.625 (32.768)	mem 72.348
Train: [93][410/1500]	BT 0.038 (0.358)	DT 0.001 (0.321)	loss 6.376 (6.566)	prob 2.286 (2.477)	GS 35.688 (33.798)	mem 72.498
Train: [93][420/1500]	BT 0.038 (0.351)	DT 0.001 (0.313)	loss 6.568 (6.553)	prob 2.287 (2.429)	GS 32.234 (32.554)	mem 72.499
Train: [93][430/1500]	BT 0.027 (0.362)	DT 0.000 (0.324)	loss 6.550 (6.540)	prob 2.535 (2.395)	GS 36.672 (33.389)	mem 72.536
Train: [93][440/1500]	BT 0.030 (0.354)	DT 0.000 (0.317)	loss 6.403 (6.528)	prob 2.523 (2.440)	GS 32.438 (32.952)	mem 72.537
Train: [93][450/1500]	BT 0.038 (0.347)	DT 0.001 (0.310)	loss 6.624 (6.532)	prob 1.994 (2.448)	GS 32.781 (33.073)	mem 72.537
Train: [93][460/1500]	BT 0.037 (0.347)	DT 0.000 (0.310)	loss 6.509 (6.525)	prob 2.805 (2.435)	GS 31.594 (32.828)	mem 72.538
Train: [93][470/1500]	BT 0.039 (0.340)	DT 0.001 (0.303)	loss 6.475 (6.523)	prob 2.755 (2.522)	GS 30.438 (31.558)	mem 72.537
Train: [93][480/1500]	BT 0.072 (0.344)	DT 0.005 (0.307)	loss 6.537 (6.513)	prob 2.548 (2.508)	GS 35.203 (31.909)	mem 72.539
Train: [93][490/1500]	BT 0.066 (0.338)	DT 0.005 (0.300)	loss 6.490 (6.509)	prob 2.621 (2.470)	GS 33.047 (32.005)	mem 72.538
Train: [93][500/1500]	BT 0.039 (0.343)	DT 0.000 (0.305)	loss 6.502 (6.515)	prob 2.415 (2.431)	GS 35.016 (32.191)	mem 72.539
Train: [93][510/1500]	BT 0.060 (0.337)	DT 0.011 (0.299)	loss 6.446 (6.485)	prob 2.883 (2.339)	GS 31.953 (32.503)	mem 72.540
Train: [93][520/1500]	BT 0.061 (0.332)	DT 0.011 (0.293)	loss 6.600 (6.565)	prob 1.854 (2.258)	GS 32.688 (33.066)	mem 72.540
Train: [93][530/1500]	BT 0.028 (0.344)	DT 0.000 (0.306)	loss 6.441 (6.550)	prob 2.498 (2.236)	GS 36.625 (33.542)	mem 72.559
Train: [93][540/1500]	BT 0.029 (0.338)	DT 0.000 (0.300)	loss 6.667 (6.543)	prob 1.937 (2.253)	GS 36.719 (33.464)	mem 72.560
Train: [93][550/1500]	BT 0.028 (0.340)	DT 0.000 (0.302)	loss 6.475 (6.534)	prob 2.729 (2.281)	GS 30.172 (33.323)	mem 72.565
Train: [93][560/1500]	BT 0.040 (0.334)	DT 0.001 (0.296)	loss 6.689 (6.566)	prob 2.167 (2.061)	GS 36.984 (32.406)	mem 72.566
Train: [93][570/1500]	BT 0.038 (0.329)	DT 0.000 (0.291)	loss 6.549 (6.537)	prob 2.105 (1.994)	GS 30.828 (32.552)	mem 72.565
Train: [93][580/1500]	BT 0.029 (0.332)	DT 0.000 (0.294)	loss 6.530 (6.532)	prob 2.109 (2.027)	GS 33.656 (32.765)	mem 72.571
Train: [93][590/1500]	BT 0.031 (0.326)	DT 0.000 (0.289)	loss 6.444 (6.528)	prob 2.293 (2.061)	GS 33.891 (32.534)	mem 72.572
Train: [93][600/1500]	BT 0.036 (0.327)	DT 0.000 (0.289)	loss 6.441 (6.519)	prob 2.177 (2.115)	GS 34.750 (32.537)	mem 72.575
Train: [93][610/1500]	BT 0.026 (0.322)	DT 0.000 (0.284)	loss 6.494 (6.521)	prob 2.257 (2.184)	GS 30.500 (32.242)	mem 72.575
Train: [93][620/1500]	BT 0.037 (0.322)	DT 0.001 (0.285)	loss 6.576 (6.533)	prob 2.428 (2.136)	GS 37.719 (32.852)	mem 72.574
Train: [93][630/1500]	BT 0.037 (0.318)	DT 0.000 (0.280)	loss 6.470 (6.521)	prob 2.115 (2.202)	GS 35.000 (32.996)	mem 72.574
Train: [93][640/1500]	BT 0.025 (0.313)	DT 0.000 (0.276)	loss 6.484 (6.528)	prob 2.233 (2.214)	GS 33.938 (32.672)	mem 72.576
Train: [93][650/1500]	BT 0.038 (0.317)	DT 0.001 (0.279)	loss 6.381 (6.518)	prob 2.345 (2.217)	GS 35.609 (32.744)	mem 72.575
Train: [93][660/1500]	BT 0.038 (0.313)	DT 0.000 (0.276)	loss 6.616 (6.500)	prob 2.282 (2.241)	GS 40.594 (31.945)	mem 72.575
Train: [93][670/1500]	BT 0.024 (0.318)	DT 0.000 (0.281)	loss 6.529 (6.527)	prob 2.514 (2.354)	GS 38.203 (32.816)	mem 72.578
Train: [93][680/1500]	BT 0.037 (0.314)	DT 0.001 (0.277)	loss 6.432 (6.522)	prob 2.461 (2.394)	GS 33.719 (32.501)	mem 72.578
Train: [93][690/1500]	BT 0.037 (0.316)	DT 0.001 (0.278)	loss 6.567 (6.522)	prob 2.854 (2.412)	GS 33.703 (32.778)	mem 72.579
Train: [93][700/1500]	BT 0.037 (0.312)	DT 0.001 (0.274)	loss 6.462 (6.516)	prob 2.131 (2.403)	GS 33.047 (32.465)	mem 72.580
Train: [93][710/1500]	BT 0.030 (0.314)	DT 0.000 (0.276)	loss 6.430 (6.498)	prob 2.543 (2.516)	GS 29.703 (31.695)	mem 72.585
Train: [93][720/1500]	BT 0.037 (0.311)	DT 0.001 (0.273)	loss 6.465 (6.497)	prob 2.697 (2.295)	GS 37.188 (31.144)	mem 72.586
Train: [93][730/1500]	BT 0.082 (0.310)	DT 0.000 (0.272)	loss 6.467 (6.498)	prob 2.562 (2.371)	GS 29.766 (31.778)	mem 72.586
Train: [93][740/1500]	BT 0.032 (0.311)	DT 0.000 (0.274)	loss 6.387 (6.488)	prob 2.160 (2.341)	GS 34.312 (31.756)	mem 72.586
Train: [93][750/1500]	BT 0.034 (0.307)	DT 0.001 (0.270)	loss 6.512 (6.494)	prob 2.565 (2.326)	GS 35.781 (31.929)	mem 72.586
Train: [93][760/1500]	BT 0.051 (0.306)	DT 0.016 (0.269)	loss 6.667 (6.527)	prob 1.875 (2.208)	GS 35.609 (33.350)	mem 72.587
Train: [93][770/1500]	BT 0.031 (0.307)	DT 0.000 (0.270)	loss 6.448 (6.508)	prob 2.078 (2.239)	GS 31.609 (33.566)	mem 72.589
Train: [93][780/1500]	BT 0.037 (0.310)	DT 0.001 (0.272)	loss 6.509 (6.505)	prob 2.966 (2.262)	GS 32.125 (33.556)	mem 72.587
Train: [93][790/1500]	BT 0.037 (0.308)	DT 0.001 (0.271)	loss 6.465 (6.499)	prob 1.701 (2.284)	GS 33.516 (33.336)	mem 72.586
Train: [93][800/1500]	BT 0.037 (0.305)	DT 0.001 (0.267)	loss 6.465 (6.502)	prob 1.910 (2.240)	GS 31.953 (33.237)	mem 72.586
Train: [93][810/1500]	BT 0.053 (0.318)	DT 0.006 (0.281)	loss 6.507 (6.511)	prob 2.823 (2.511)	GS 34.016 (32.848)	mem 72.589
Train: [93][820/1500]	BT 0.084 (0.315)	DT 0.011 (0.277)	loss 6.352 (6.485)	prob 2.341 (2.376)	GS 28.250 (31.909)	mem 72.590
Train: [93][830/1500]	BT 0.072 (0.312)	DT 0.005 (0.274)	loss 6.535 (6.482)	prob 2.551 (2.372)	GS 29.109 (32.448)	mem 72.590
Train: [93][840/1500]	BT 0.043 (0.323)	DT 0.000 (0.285)	loss 6.489 (6.505)	prob 3.119 (2.407)	GS 32.266 (32.870)	mem 72.592
Train: [93][850/1500]	BT 0.026 (0.320)	DT 0.000 (0.282)	loss 6.547 (6.506)	prob 3.005 (2.463)	GS 37.750 (33.020)	mem 72.594
Train: [93][860/1500]	BT 0.058 (0.322)	DT 0.011 (0.284)	loss 6.358 (6.481)	prob 2.645 (2.840)	GS 30.469 (33.348)	mem 72.596
Train: [93][870/1500]	BT 0.030 (0.325)	DT 0.001 (0.287)	loss 6.491 (6.499)	prob 2.089 (2.625)	GS 35.453 (34.607)	mem 72.629
Train: [93][880/1500]	BT 0.029 (0.322)	DT 0.000 (0.283)	loss 6.588 (6.525)	prob 3.041 (2.652)	GS 35.609 (34.134)	mem 72.628
Train: [93][890/1500]	BT 0.039 (0.318)	DT 0.001 (0.280)	loss 6.540 (6.520)	prob 2.412 (2.615)	GS 34.328 (34.176)	mem 72.629
Train: [93][900/1500]	BT 0.044 (0.322)	DT 0.006 (0.284)	loss 6.447 (6.511)	prob 2.709 (2.649)	GS 33.844 (33.820)	mem 72.628
Train: [93][910/1500]	BT 0.073 (0.328)	DT 0.012 (0.290)	loss 6.566 (6.507)	prob 2.945 (2.800)	GS 31.203 (34.534)	mem 72.630
Train: [93][920/1500]	BT 0.072 (0.326)	DT 0.008 (0.287)	loss 6.455 (6.509)	prob 2.340 (2.716)	GS 32.125 (33.809)	mem 72.630
Train: [93][930/1500]	BT 0.100 (0.329)	DT 0.023 (0.290)	loss 6.394 (6.507)	prob 2.540 (2.566)	GS 34.641 (33.177)	mem 72.631
Train: [93][940/1500]	BT 0.031 (0.333)	DT 0.000 (0.294)	loss 6.420 (6.504)	prob 2.325 (2.623)	GS 31.297 (33.337)	mem 72.628
Train: [93][950/1500]	BT 0.040 (0.329)	DT 0.001 (0.290)	loss 6.479 (6.516)	prob 3.185 (2.658)	GS 33.359 (33.230)	mem 72.628
Train: [93][960/1500]	BT 0.039 (0.329)	DT 0.001 (0.290)	loss 6.685 (6.558)	prob 2.914 (2.826)	GS 35.312 (33.253)	mem 72.630
Train: [93][970/1500]	BT 0.039 (0.326)	DT 0.001 (0.287)	loss 6.542 (6.555)	prob 2.307 (2.650)	GS 34.109 (33.687)	mem 72.630
Train: [93][980/1500]	BT 0.039 (0.326)	DT 0.001 (0.287)	loss 6.530 (6.542)	prob 2.282 (2.597)	GS 31.609 (33.180)	mem 72.629
Train: [93][990/1500]	BT 0.039 (0.323)	DT 0.001 (0.284)	loss 6.436 (6.536)	prob 2.916 (2.570)	GS 34.500 (32.880)	mem 72.629
Train: [93][1000/1500]	BT 0.039 (0.323)	DT 0.001 (0.284)	loss 6.659 (6.530)	prob 2.837 (2.595)	GS 39.109 (32.846)	mem 72.629
Train: [93][1010/1500]	BT 0.039 (0.321)	DT 0.001 (0.282)	loss 6.564 (6.495)	prob 2.376 (2.711)	GS 28.922 (31.952)	mem 72.630
Train: [93][1020/1500]	BT 0.040 (0.318)	DT 0.010 (0.280)	loss 6.415 (6.510)	prob 1.939 (2.591)	GS 31.016 (32.217)	mem 72.631
Train: [93][1030/1500]	BT 0.039 (0.318)	DT 0.001 (0.279)	loss 6.420 (6.508)	prob 2.949 (2.611)	GS 32.484 (32.528)	mem 72.632
Train: [93][1040/1500]	BT 0.030 (0.318)	DT 0.000 (0.279)	loss 6.469 (6.497)	prob 2.569 (2.581)	GS 35.250 (32.671)	mem 72.633
Train: [93][1050/1500]	BT 0.040 (0.316)	DT 0.001 (0.277)	loss 6.640 (6.496)	prob 2.590 (2.585)	GS 36.328 (32.855)	mem 72.634
Train: [93][1060/1500]	BT 0.038 (0.317)	DT 0.001 (0.278)	loss 6.499 (6.509)	prob 2.119 (2.697)	GS 32.203 (33.216)	mem 72.633
Train: [93][1070/1500]	BT 0.039 (0.314)	DT 0.001 (0.276)	loss 6.572 (6.516)	prob 2.798 (2.599)	GS 29.953 (33.281)	mem 72.633
Train: [93][1080/1500]	BT 3.369 (0.316)	DT 3.334 (0.277)	loss 6.576 (6.505)	prob 2.216 (2.535)	GS 36.203 (32.862)	mem 72.636
Train: [93][1090/1500]	BT 0.037 (0.313)	DT 0.001 (0.274)	loss 6.452 (6.502)	prob 2.804 (2.566)	GS 39.281 (32.764)	mem 72.637
Train: [93][1100/1500]	BT 0.062 (0.311)	DT 0.011 (0.272)	loss 6.289 (6.490)	prob 2.790 (2.588)	GS 30.062 (32.514)	mem 72.637
Train: [93][1110/1500]	BT 0.093 (0.316)	DT 0.001 (0.276)	loss 6.536 (6.566)	prob 2.926 (2.817)	GS 37.094 (34.534)	mem 72.634
Train: [93][1120/1500]	BT 0.062 (0.315)	DT 0.006 (0.275)	loss 6.566 (6.560)	prob 2.189 (2.661)	GS 38.734 (33.788)	mem 72.635
Train: [93][1130/1500]	BT 0.030 (0.321)	DT 0.000 (0.281)	loss 6.712 (6.545)	prob 2.429 (2.754)	GS 34.141 (34.297)	mem 72.634
Train: [93][1140/1500]	BT 0.025 (0.318)	DT 0.000 (0.279)	loss 6.543 (6.544)	prob 3.515 (2.905)	GS 30.656 (34.405)	mem 72.635
Train: [93][1150/1500]	BT 0.036 (0.316)	DT 0.001 (0.276)	loss 6.573 (6.542)	prob 2.938 (2.925)	GS 37.828 (34.416)	mem 72.635
Train: [93][1160/1500]	BT 0.054 (0.318)	DT 0.001 (0.278)	loss 6.420 (6.522)	prob 2.651 (2.938)	GS 35.750 (33.013)	mem 72.637
Train: [93][1170/1500]	BT 0.065 (0.316)	DT 0.004 (0.276)	loss 6.621 (6.518)	prob 2.701 (3.012)	GS 32.656 (32.470)	mem 72.636
Train: [93][1180/1500]	BT 0.033 (0.320)	DT 0.000 (0.280)	loss 6.573 (6.515)	prob 3.016 (2.964)	GS 29.297 (32.060)	mem 72.637
Train: [93][1190/1500]	BT 0.027 (0.318)	DT 0.000 (0.279)	loss 6.460 (6.524)	prob 3.401 (2.988)	GS 41.641 (32.671)	mem 72.638
Train: [93][1200/1500]	BT 0.038 (0.316)	DT 0.000 (0.276)	loss 6.566 (6.521)	prob 3.377 (3.020)	GS 33.781 (32.581)	mem 72.639
Train: [93][1210/1500]	BT 0.030 (0.317)	DT 0.000 (0.278)	loss 6.657 (6.534)	prob 2.597 (2.828)	GS 37.109 (33.278)	mem 72.650
Train: [93][1220/1500]	BT 0.038 (0.315)	DT 0.001 (0.275)	loss 6.545 (6.550)	prob 2.598 (2.863)	GS 33.922 (33.838)	mem 72.627
Train: [93][1230/1500]	BT 0.027 (0.315)	DT 0.000 (0.275)	loss 6.486 (6.556)	prob 3.192 (2.793)	GS 30.953 (33.136)	mem 72.552
Train: [93][1240/1500]	BT 0.028 (0.312)	DT 0.000 (0.273)	loss 6.724 (6.567)	prob 2.867 (2.848)	GS 35.500 (33.173)	mem 72.551
Train: [93][1250/1500]	BT 0.038 (0.313)	DT 0.000 (0.273)	loss 6.613 (6.565)	prob 2.960 (2.834)	GS 31.516 (32.904)	mem 72.551
Train: [93][1260/1500]	BT 0.038 (0.310)	DT 0.001 (0.271)	loss 6.482 (6.562)	prob 3.049 (2.827)	GS 30.328 (32.697)	mem 72.550
Train: [93][1270/1500]	BT 0.038 (0.308)	DT 0.001 (0.269)	loss 6.420 (6.547)	prob 3.789 (2.869)	GS 37.016 (32.737)	mem 72.550
Train: [93][1280/1500]	BT 0.037 (0.309)	DT 0.001 (0.269)	loss 6.470 (6.549)	prob 2.552 (2.869)	GS 33.703 (32.819)	mem 72.550
Train: [93][1290/1500]	BT 0.037 (0.307)	DT 0.001 (0.268)	loss 6.615 (6.548)	prob 2.409 (2.845)	GS 33.859 (32.837)	mem 72.550
Train: [93][1300/1500]	BT 0.037 (0.308)	DT 0.001 (0.269)	loss 6.611 (6.553)	prob 2.532 (2.803)	GS 34.844 (32.711)	mem 72.551
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [93][1310/1500]	BT 0.038 (0.307)	DT 0.001 (0.268)	loss 6.608 (6.488)	prob 2.971 (2.660)	GS 36.844 (32.153)	mem 72.554
Train: [93][1320/1500]	BT 0.029 (0.305)	DT 0.000 (0.266)	loss 6.537 (6.539)	prob 2.675 (2.675)	GS 36.172 (32.523)	mem 72.555
Train: [93][1330/1500]	BT 0.035 (0.308)	DT 0.001 (0.269)	loss 6.570 (6.532)	prob 2.838 (2.692)	GS 32.422 (32.016)	mem 72.575
Train: [93][1340/1500]	BT 0.038 (0.306)	DT 0.001 (0.267)	loss 6.443 (6.537)	prob 2.522 (2.691)	GS 34.188 (32.229)	mem 72.575
Train: [93][1350/1500]	BT 0.037 (0.307)	DT 0.001 (0.268)	loss 6.603 (6.530)	prob 2.227 (2.642)	GS 34.531 (32.180)	mem 72.575
Train: [93][1360/1500]	BT 0.039 (0.305)	DT 0.001 (0.266)	loss 6.690 (6.540)	prob 1.801 (2.557)	GS 33.703 (31.623)	mem 72.577
Train: [93][1370/1500]	BT 0.033 (0.305)	DT 0.001 (0.266)	loss 6.614 (6.545)	prob 2.574 (2.512)	GS 34.219 (32.505)	mem 72.565
Train: [93][1380/1500]	BT 0.032 (0.304)	DT 0.000 (0.265)	loss 6.611 (6.570)	prob 2.500 (2.539)	GS 35.453 (32.619)	mem 72.565
Train: [93][1390/1500]	BT 0.039 (0.302)	DT 0.001 (0.264)	loss 6.594 (6.579)	prob 2.712 (2.560)	GS 33.188 (32.821)	mem 72.567
Train: [93][1400/1500]	BT 0.035 (0.303)	DT 0.000 (0.264)	loss 6.492 (6.572)	prob 2.303 (2.581)	GS 34.906 (32.842)	mem 72.567
Train: [93][1410/1500]	BT 0.063 (0.303)	DT 0.013 (0.264)	loss 6.629 (6.581)	prob 2.834 (2.721)	GS 30.578 (32.408)	mem 72.567
Train: [93][1420/1500]	BT 0.052 (0.306)	DT 0.015 (0.267)	loss 6.539 (6.555)	prob 2.361 (2.618)	GS 27.828 (32.007)	mem 72.563
Train: [93][1430/1500]	BT 0.043 (0.305)	DT 0.002 (0.266)	loss 6.452 (6.559)	prob 2.735 (2.566)	GS 32.344 (32.260)	mem 72.562
Train: [93][1440/1500]	BT 0.058 (0.304)	DT 0.011 (0.265)	loss 6.517 (6.546)	prob 2.131 (2.540)	GS 32.844 (32.285)	mem 72.562
Train: [93][1450/1500]	BT 0.028 (0.308)	DT 0.000 (0.269)	loss 6.425 (6.544)	prob 2.373 (2.498)	GS 35.266 (32.333)	mem 72.561
Train: [93][1460/1500]	BT 0.039 (0.306)	DT 0.001 (0.267)	loss 6.538 (6.530)	prob 1.541 (2.076)	GS 28.969 (30.844)	mem 72.562
Train: [93][1470/1500]	BT 0.029 (0.306)	DT 0.000 (0.267)	loss 6.515 (6.531)	prob 1.929 (2.159)	GS 35.469 (31.906)	mem 71.693
Train: [93][1480/1500]	BT 0.027 (0.304)	DT 0.000 (0.265)	loss 6.442 (6.528)	prob 2.132 (2.201)	GS 37.188 (32.238)	mem 71.544
Train: [93][1490/1500]	BT 0.032 (0.303)	DT 0.000 (0.264)	loss 6.399 (6.528)	prob 2.573 (2.240)	GS 37.500 (32.405)	mem 10.251
Train: [93][1500/1500]	BT 0.032 (0.301)	DT 0.000 (0.262)	loss 6.373 (6.520)	prob 2.685 (2.241)	GS 33.688 (32.308)	mem 10.251
Train: [93][1510/1500]	BT 0.033 (0.299)	DT 0.001 (0.260)	loss 6.276 (6.295)	prob 2.137 (2.348)	GS 30.781 (34.322)	mem 9.465
epoch 93, total time 452.13
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [94][1/1500]	BT 19.885 (19.885)	DT 19.818 (19.818)	loss 6.226 (6.226)	prob 2.375 (2.375)	GS 36.047 (36.047)	mem 71.108
Train: [94][10/1500]	BT 0.062 (2.543)	DT 0.008 (2.485)	loss 6.304 (6.233)	prob 2.454 (2.526)	GS 31.297 (33.448)	mem 71.247
Train: [94][20/1500]	BT 0.045 (1.846)	DT 0.013 (1.793)	loss 6.416 (6.318)	prob 2.521 (2.579)	GS 32.344 (34.658)	mem 71.297
Train: [94][30/1500]	BT 0.034 (1.247)	DT 0.000 (1.198)	loss 6.503 (6.351)	prob 2.332 (2.507)	GS 33.750 (33.587)	mem 71.299
Train: [94][40/1500]	BT 0.027 (1.181)	DT 0.000 (1.136)	loss 6.645 (6.395)	prob 2.524 (2.473)	GS 33.219 (33.292)	mem 71.311
Train: [94][50/1500]	BT 0.035 (0.950)	DT 0.000 (0.909)	loss 6.443 (6.412)	prob 2.869 (2.537)	GS 30.672 (33.072)	mem 71.317
Train: [94][60/1500]	BT 0.034 (0.868)	DT 0.000 (0.828)	loss 6.440 (6.476)	prob 3.211 (2.717)	GS 32.281 (31.820)	mem 71.335
Train: [94][70/1500]	BT 0.034 (0.749)	DT 0.000 (0.710)	loss 6.539 (6.505)	prob 2.374 (2.624)	GS 27.188 (31.543)	mem 71.335
Train: [94][80/1500]	BT 0.052 (0.660)	DT 0.010 (0.621)	loss 6.478 (6.516)	prob 2.897 (2.548)	GS 35.047 (31.521)	mem 71.337
Train: [94][90/1500]	BT 0.121 (0.681)	DT 0.033 (0.638)	loss 6.441 (6.516)	prob 2.360 (2.501)	GS 33.234 (31.914)	mem 71.339
Train: [94][100/1500]	BT 0.075 (0.621)	DT 0.001 (0.575)	loss 6.433 (6.508)	prob 2.527 (2.501)	GS 36.125 (31.899)	mem 71.339
Train: [94][110/1500]	BT 0.027 (0.632)	DT 0.000 (0.586)	loss 6.444 (6.514)	prob 2.462 (2.529)	GS 36.141 (32.709)	mem 71.344
Train: [94][120/1500]	BT 0.024 (0.586)	DT 0.000 (0.541)	loss 6.526 (6.527)	prob 2.706 (2.488)	GS 32.875 (32.973)	mem 71.347
Train: [94][130/1500]	BT 4.003 (0.573)	DT 3.950 (0.530)	loss 6.510 (6.529)	prob 2.626 (2.576)	GS 30.359 (32.493)	mem 71.348
Train: [94][140/1500]	BT 0.037 (0.555)	DT 0.000 (0.511)	loss 6.437 (6.527)	prob 2.868 (2.579)	GS 34.984 (32.843)	mem 71.351
Train: [94][150/1500]	BT 0.024 (0.520)	DT 0.000 (0.477)	loss 6.522 (6.525)	prob 1.559 (2.502)	GS 36.719 (32.984)	mem 71.352
Train: [94][160/1500]	BT 0.040 (0.510)	DT 0.001 (0.468)	loss 6.595 (6.529)	prob 2.193 (2.191)	GS 34.562 (33.048)	mem 71.356
Train: [94][170/1500]	BT 0.060 (0.488)	DT 0.011 (0.446)	loss 6.499 (6.510)	prob 2.131 (2.269)	GS 32.422 (32.432)	mem 71.356
Train: [94][180/1500]	BT 0.031 (0.474)	DT 0.000 (0.432)	loss 6.434 (6.496)	prob 2.550 (2.272)	GS 33.500 (32.299)	mem 71.356
Train: [94][190/1500]	BT 0.034 (0.470)	DT 0.000 (0.429)	loss 6.533 (6.524)	prob 2.613 (2.276)	GS 35.047 (32.697)	mem 71.360
Train: [94][200/1500]	BT 0.037 (0.448)	DT 0.001 (0.407)	loss 6.716 (6.539)	prob 2.257 (2.310)	GS 35.562 (32.984)	mem 71.361
Train: [94][210/1500]	BT 0.066 (0.454)	DT 0.006 (0.412)	loss 6.378 (6.512)	prob 2.582 (2.276)	GS 31.250 (33.720)	mem 71.366
Train: [94][220/1500]	BT 0.058 (0.436)	DT 0.014 (0.394)	loss 6.569 (6.517)	prob 2.524 (2.238)	GS 38.266 (33.882)	mem 71.367
Train: [94][230/1500]	BT 0.041 (0.443)	DT 0.001 (0.401)	loss 6.424 (6.511)	prob 2.439 (2.227)	GS 34.109 (33.656)	mem 71.371
Train: [94][240/1500]	BT 0.037 (0.426)	DT 0.001 (0.385)	loss 6.499 (6.506)	prob 1.976 (2.213)	GS 34.953 (33.722)	mem 71.375
Train: [94][250/1500]	BT 0.038 (0.411)	DT 0.001 (0.369)	loss 6.555 (6.513)	prob 2.080 (2.235)	GS 33.797 (33.922)	mem 71.375
Train: [94][260/1500]	BT 0.056 (0.412)	DT 0.006 (0.371)	loss 6.482 (6.498)	prob 2.261 (2.234)	GS 31.656 (32.895)	mem 71.378
Train: [94][270/1500]	BT 0.111 (0.399)	DT 0.031 (0.358)	loss 6.519 (6.479)	prob 1.915 (2.171)	GS 37.812 (32.848)	mem 71.380
Train: [94][280/1500]	BT 0.030 (0.411)	DT 0.000 (0.370)	loss 6.375 (6.478)	prob 2.094 (2.138)	GS 31.500 (32.798)	mem 71.383
Train: [94][290/1500]	BT 0.026 (0.398)	DT 0.000 (0.357)	loss 6.531 (6.479)	prob 2.217 (2.160)	GS 29.547 (32.577)	mem 71.384
Train: [94][300/1500]	BT 0.038 (0.386)	DT 0.001 (0.345)	loss 6.508 (6.484)	prob 2.175 (2.151)	GS 34.641 (32.692)	mem 71.385
Train: [94][310/1500]	BT 0.038 (0.398)	DT 0.000 (0.357)	loss 6.565 (6.465)	prob 2.530 (2.159)	GS 33.812 (31.589)	mem 71.385
Train: [94][320/1500]	BT 0.036 (0.395)	DT 0.000 (0.354)	loss 6.409 (6.459)	prob 2.336 (2.207)	GS 33.500 (32.671)	mem 71.387
Train: [94][330/1500]	BT 0.039 (0.387)	DT 0.001 (0.347)	loss 6.583 (6.462)	prob 2.162 (2.249)	GS 30.156 (32.160)	mem 71.416
Train: [94][340/1500]	BT 0.039 (0.382)	DT 0.001 (0.342)	loss 6.392 (6.469)	prob 2.165 (2.206)	GS 33.938 (32.196)	mem 71.417
Train: [94][350/1500]	BT 0.033 (0.372)	DT 0.001 (0.332)	loss 6.458 (6.469)	prob 2.144 (2.213)	GS 35.078 (32.026)	mem 71.418
Train: [94][360/1500]	BT 0.037 (0.372)	DT 0.001 (0.332)	loss 6.316 (6.430)	prob 2.008 (2.186)	GS 29.688 (32.108)	mem 71.420
Train: [94][370/1500]	BT 0.080 (0.364)	DT 0.009 (0.323)	loss 6.516 (6.462)	prob 1.807 (2.138)	GS 31.250 (32.377)	mem 71.421
Train: [94][380/1500]	BT 0.039 (0.358)	DT 0.001 (0.318)	loss 6.390 (6.450)	prob 1.459 (2.086)	GS 29.984 (32.045)	mem 71.423
Train: [94][390/1500]	BT 0.049 (0.370)	DT 0.006 (0.330)	loss 6.414 (6.461)	prob 2.353 (2.080)	GS 35.219 (32.393)	mem 71.422
Train: [94][400/1500]	BT 0.064 (0.362)	DT 0.008 (0.322)	loss 6.619 (6.463)	prob 2.140 (2.121)	GS 35.594 (32.565)	mem 71.423
Train: [94][410/1500]	BT 0.038 (0.363)	DT 0.001 (0.322)	loss 6.359 (6.429)	prob 2.366 (2.192)	GS 32.062 (32.416)	mem 71.423
Train: [94][420/1500]	BT 0.039 (0.360)	DT 0.001 (0.319)	loss 6.434 (6.476)	prob 2.207 (2.199)	GS 34.578 (32.702)	mem 71.423
Train: [94][430/1500]	BT 0.039 (0.353)	DT 0.001 (0.312)	loss 6.370 (6.464)	prob 2.831 (2.210)	GS 33.375 (32.432)	mem 71.424
Train: [94][440/1500]	BT 0.040 (0.354)	DT 0.001 (0.313)	loss 6.441 (6.467)	prob 2.591 (2.242)	GS 34.422 (32.772)	mem 71.619
Train: [94][450/1500]	BT 0.040 (0.347)	DT 0.001 (0.307)	loss 6.495 (6.475)	prob 2.023 (2.243)	GS 30.344 (32.735)	mem 71.670
Train: [94][460/1500]	BT 0.023 (0.359)	DT 0.000 (0.319)	loss 6.382 (6.416)	prob 1.987 (1.913)	GS 33.703 (33.298)	mem 72.457
Train: [94][470/1500]	BT 0.027 (0.352)	DT 0.000 (0.312)	loss 6.380 (6.418)	prob 2.011 (2.047)	GS 37.172 (33.270)	mem 72.457
Train: [94][480/1500]	BT 0.039 (0.346)	DT 0.001 (0.305)	loss 6.357 (6.424)	prob 2.504 (2.180)	GS 30.047 (32.716)	mem 72.506
Train: [94][490/1500]	BT 0.039 (0.345)	DT 0.001 (0.305)	loss 6.344 (6.419)	prob 2.093 (2.154)	GS 38.922 (32.764)	mem 72.604
Train: [94][500/1500]	BT 0.038 (0.339)	DT 0.001 (0.299)	loss 6.375 (6.414)	prob 2.056 (2.170)	GS 34.203 (32.459)	mem 72.604
Train: [94][510/1500]	BT 0.039 (0.339)	DT 0.001 (0.299)	loss 6.373 (6.422)	prob 1.795 (2.061)	GS 33.359 (33.477)	mem 72.605
Train: [94][520/1500]	BT 0.039 (0.333)	DT 0.001 (0.293)	loss 6.429 (6.429)	prob 2.702 (1.991)	GS 31.562 (33.173)	mem 72.605
Train: [94][530/1500]	BT 0.039 (0.329)	DT 0.001 (0.289)	loss 6.291 (6.445)	prob 2.030 (2.083)	GS 34.172 (32.942)	mem 72.605
Train: [94][540/1500]	BT 0.031 (0.337)	DT 0.000 (0.297)	loss 6.469 (6.459)	prob 2.137 (2.091)	GS 34.078 (33.200)	mem 72.608
Train: [94][550/1500]	BT 0.044 (0.331)	DT 0.012 (0.291)	loss 6.364 (6.453)	prob 2.079 (2.076)	GS 32.094 (32.952)	mem 72.608
Train: [94][560/1500]	BT 0.038 (0.337)	DT 0.001 (0.298)	loss 6.490 (6.488)	prob 1.707 (1.875)	GS 36.328 (31.994)	mem 72.606
Train: [94][570/1500]	BT 0.042 (0.333)	DT 0.001 (0.293)	loss 6.446 (6.499)	prob 2.459 (2.067)	GS 36.469 (33.260)	mem 72.608
Train: [94][580/1500]	BT 0.036 (0.334)	DT 0.000 (0.295)	loss 6.404 (6.467)	prob 2.198 (2.138)	GS 32.375 (32.775)	mem 72.607
Train: [94][590/1500]	BT 0.038 (0.329)	DT 0.000 (0.290)	loss 6.438 (6.458)	prob 2.181 (2.107)	GS 34.156 (32.697)	mem 72.607
Train: [94][600/1500]	BT 0.038 (0.325)	DT 0.001 (0.285)	loss 6.462 (6.451)	prob 2.241 (2.132)	GS 30.844 (32.951)	mem 72.607
Train: [94][610/1500]	BT 0.027 (0.326)	DT 0.000 (0.287)	loss 6.514 (6.390)	prob 2.256 (2.027)	GS 32.484 (31.950)	mem 72.616
Train: [94][620/1500]	BT 0.037 (0.321)	DT 0.001 (0.282)	loss 6.420 (6.387)	prob 2.553 (2.099)	GS 30.891 (32.550)	mem 72.618
Train: [94][630/1500]	BT 0.039 (0.325)	DT 0.000 (0.285)	loss 6.350 (6.403)	prob 2.286 (2.125)	GS 30.688 (32.713)	mem 72.629
Train: [94][640/1500]	BT 0.027 (0.320)	DT 0.000 (0.281)	loss 6.450 (6.407)	prob 2.179 (2.104)	GS 35.562 (32.843)	mem 72.629
Train: [94][650/1500]	BT 0.057 (0.316)	DT 0.004 (0.277)	loss 6.436 (6.413)	prob 1.704 (2.065)	GS 38.078 (32.584)	mem 72.631
Train: [94][660/1500]	BT 0.029 (0.319)	DT 0.000 (0.280)	loss 6.439 (6.442)	prob 2.240 (2.153)	GS 35.438 (33.253)	mem 72.534
Train: [94][670/1500]	BT 0.037 (0.315)	DT 0.001 (0.276)	loss 6.464 (6.419)	prob 2.014 (2.158)	GS 30.016 (32.450)	mem 72.534
Train: [94][680/1500]	BT 0.028 (0.319)	DT 0.000 (0.280)	loss 6.453 (6.426)	prob 1.861 (2.053)	GS 36.250 (32.155)	mem 72.533
Train: [94][690/1500]	BT 0.031 (0.315)	DT 0.000 (0.276)	loss 6.468 (6.421)	prob 2.066 (2.059)	GS 34.266 (31.764)	mem 72.533
Train: [94][700/1500]	BT 0.049 (0.317)	DT 0.006 (0.278)	loss 6.390 (6.413)	prob 2.291 (2.116)	GS 31.938 (31.819)	mem 72.535
Train: [94][710/1500]	BT 0.031 (0.313)	DT 0.000 (0.274)	loss 6.384 (6.378)	prob 2.556 (2.014)	GS 34.031 (32.075)	mem 72.536
Train: [94][720/1500]	BT 0.057 (0.309)	DT 0.013 (0.270)	loss 6.475 (6.380)	prob 1.591 (1.868)	GS 32.031 (31.493)	mem 72.535
Train: [94][730/1500]	BT 0.068 (0.317)	DT 0.012 (0.278)	loss 6.347 (6.389)	prob 2.374 (1.941)	GS 31.938 (31.688)	mem 72.536
Train: [94][740/1500]	BT 0.068 (0.314)	DT 0.004 (0.274)	loss 6.412 (6.405)	prob 2.099 (1.974)	GS 31.094 (31.902)	mem 72.536
Train: [94][750/1500]	BT 0.057 (0.327)	DT 0.009 (0.287)	loss 6.576 (6.413)	prob 2.093 (2.023)	GS 33.203 (32.088)	mem 72.523
Train: [94][760/1500]	BT 0.053 (0.323)	DT 0.015 (0.284)	loss 6.437 (6.433)	prob 2.219 (2.192)	GS 34.703 (33.538)	mem 72.523
Train: [94][770/1500]	BT 0.029 (0.331)	DT 0.000 (0.291)	loss 6.397 (6.441)	prob 2.007 (2.228)	GS 34.391 (33.005)	mem 72.542
Train: [94][780/1500]	BT 0.027 (0.327)	DT 0.000 (0.288)	loss 6.524 (6.440)	prob 2.026 (2.259)	GS 32.703 (32.814)	mem 72.545
Train: [94][790/1500]	BT 0.030 (0.328)	DT 0.000 (0.289)	loss 6.459 (6.436)	prob 1.883 (2.246)	GS 36.391 (32.627)	mem 72.547
Train: [94][800/1500]	BT 0.039 (0.325)	DT 0.001 (0.286)	loss 6.304 (6.432)	prob 2.630 (2.237)	GS 29.531 (32.395)	mem 72.548
Train: [94][810/1500]	BT 0.031 (0.328)	DT 0.000 (0.288)	loss 6.608 (6.425)	prob 1.431 (1.971)	GS 38.719 (32.114)	mem 72.548
Train: [94][820/1500]	BT 0.035 (0.324)	DT 0.000 (0.285)	loss 6.421 (6.435)	prob 2.258 (2.106)	GS 31.453 (32.932)	mem 72.548
Train: [94][830/1500]	BT 0.066 (0.321)	DT 0.015 (0.282)	loss 6.388 (6.421)	prob 2.125 (2.178)	GS 32.562 (32.930)	mem 72.549
Train: [94][840/1500]	BT 0.053 (0.323)	DT 0.006 (0.284)	loss 6.473 (6.418)	prob 2.233 (2.221)	GS 33.172 (32.739)	mem 72.551
Train: [94][850/1500]	BT 0.030 (0.329)	DT 0.000 (0.290)	loss 6.389 (6.424)	prob 2.590 (2.278)	GS 30.344 (32.707)	mem 72.549
Train: [94][860/1500]	BT 0.023 (0.326)	DT 0.000 (0.286)	loss 6.462 (6.482)	prob 2.607 (2.387)	GS 31.812 (32.598)	mem 72.550
Train: [94][870/1500]	BT 0.027 (0.328)	DT 0.001 (0.289)	loss 6.491 (6.468)	prob 2.634 (2.445)	GS 32.578 (33.170)	mem 72.552
Train: [94][880/1500]	BT 0.027 (0.324)	DT 0.000 (0.285)	loss 6.448 (6.474)	prob 2.612 (2.443)	GS 34.344 (32.790)	mem 72.553
Train: [94][890/1500]	BT 0.027 (0.321)	DT 0.001 (0.282)	loss 6.326 (6.462)	prob 2.473 (2.517)	GS 31.281 (32.788)	mem 72.553
Train: [94][900/1500]	BT 0.039 (0.321)	DT 0.001 (0.282)	loss 6.467 (6.464)	prob 2.871 (2.521)	GS 28.141 (32.883)	mem 72.554
Train: [94][910/1500]	BT 0.039 (0.318)	DT 0.001 (0.279)	loss 6.449 (6.433)	prob 2.615 (2.780)	GS 29.719 (31.831)	mem 72.556
Train: [94][920/1500]	BT 0.036 (0.319)	DT 0.000 (0.281)	loss 6.340 (6.441)	prob 2.955 (2.746)	GS 32.625 (32.694)	mem 72.572
Train: [94][930/1500]	BT 0.037 (0.316)	DT 0.001 (0.278)	loss 6.423 (6.436)	prob 2.760 (2.732)	GS 32.719 (32.608)	mem 72.572
Train: [94][940/1500]	BT 0.036 (0.318)	DT 0.000 (0.279)	loss 6.450 (6.442)	prob 2.395 (2.687)	GS 31.938 (32.461)	mem 72.574
Train: [94][950/1500]	BT 0.036 (0.315)	DT 0.000 (0.276)	loss 6.353 (6.434)	prob 2.551 (2.678)	GS 31.141 (32.208)	mem 72.574
Train: [94][960/1500]	BT 0.061 (0.312)	DT 0.006 (0.273)	loss 6.388 (6.446)	prob 3.163 (2.782)	GS 36.344 (34.567)	mem 72.574
Train: [94][970/1500]	BT 0.036 (0.314)	DT 0.001 (0.275)	loss 6.654 (6.474)	prob 2.457 (2.817)	GS 31.875 (33.892)	mem 72.579
Train: [94][980/1500]	BT 0.037 (0.311)	DT 0.001 (0.272)	loss 6.487 (6.478)	prob 3.243 (2.991)	GS 31.578 (33.812)	mem 72.578
Train: [94][990/1500]	BT 0.064 (0.311)	DT 0.003 (0.272)	loss 6.479 (6.473)	prob 2.719 (2.986)	GS 32.609 (33.225)	mem 72.581
Train: [94][1000/1500]	BT 0.037 (0.311)	DT 0.000 (0.272)	loss 6.596 (6.472)	prob 2.826 (2.972)	GS 39.516 (33.362)	mem 72.583
Train: [94][1010/1500]	BT 0.036 (0.308)	DT 0.000 (0.269)	loss 6.490 (6.489)	prob 3.513 (3.057)	GS 30.578 (31.811)	mem 72.584
Train: [94][1020/1500]	BT 0.027 (0.314)	DT 0.000 (0.276)	loss 6.441 (6.497)	prob 2.694 (3.078)	GS 32.062 (32.783)	mem 72.582
Train: [94][1030/1500]	BT 0.031 (0.311)	DT 0.000 (0.273)	loss 6.466 (6.487)	prob 3.096 (3.016)	GS 31.688 (32.023)	mem 72.583
Train: [94][1040/1500]	BT 0.033 (0.309)	DT 0.000 (0.270)	loss 6.460 (6.480)	prob 3.453 (3.053)	GS 33.016 (32.048)	mem 72.583
Train: [94][1050/1500]	BT 0.029 (0.311)	DT 0.000 (0.273)	loss 6.570 (6.485)	prob 2.898 (3.044)	GS 31.516 (32.170)	mem 72.585
Train: [94][1060/1500]	BT 0.026 (0.308)	DT 0.000 (0.270)	loss 6.391 (6.449)	prob 3.066 (3.178)	GS 30.859 (32.795)	mem 72.586
Train: [94][1070/1500]	BT 0.040 (0.309)	DT 0.001 (0.270)	loss 6.462 (6.462)	prob 2.584 (2.986)	GS 33.203 (31.446)	mem 72.587
Train: [94][1080/1500]	BT 0.035 (0.306)	DT 0.000 (0.268)	loss 6.495 (6.457)	prob 2.997 (2.960)	GS 34.406 (31.404)	mem 72.588
Train: [94][1090/1500]	BT 0.051 (0.309)	DT 0.013 (0.270)	loss 6.575 (6.464)	prob 2.727 (2.916)	GS 33.500 (31.406)	mem 72.588
Train: [94][1100/1500]	BT 0.048 (0.307)	DT 0.000 (0.268)	loss 6.543 (6.466)	prob 2.620 (2.920)	GS 35.359 (31.711)	mem 72.589
Train: [94][1110/1500]	BT 0.044 (0.304)	DT 0.006 (0.266)	loss 6.457 (6.469)	prob 3.160 (3.043)	GS 31.156 (33.788)	mem 72.588
Train: [94][1120/1500]	BT 0.029 (0.311)	DT 0.000 (0.273)	loss 6.455 (6.482)	prob 2.986 (3.038)	GS 33.906 (35.173)	mem 72.589
Train: [94][1130/1500]	BT 0.027 (0.309)	DT 0.000 (0.270)	loss 6.496 (6.480)	prob 2.710 (2.981)	GS 35.094 (34.054)	mem 72.589
Train: [94][1140/1500]	BT 0.026 (0.310)	DT 0.000 (0.272)	loss 6.490 (6.479)	prob 2.597 (2.941)	GS 36.734 (33.900)	mem 72.588
Train: [94][1150/1500]	BT 0.023 (0.308)	DT 0.000 (0.269)	loss 6.536 (6.477)	prob 2.770 (2.866)	GS 34.703 (33.617)	mem 72.589
Train: [94][1160/1500]	BT 0.037 (0.308)	DT 0.000 (0.270)	loss 6.612 (6.490)	prob 2.572 (2.814)	GS 32.219 (31.878)	mem 72.591
Train: [94][1170/1500]	BT 0.040 (0.306)	DT 0.001 (0.267)	loss 6.417 (6.484)	prob 2.932 (2.737)	GS 35.344 (32.516)	mem 72.593
Train: [94][1180/1500]	BT 0.032 (0.303)	DT 0.000 (0.265)	loss 6.477 (6.487)	prob 2.615 (2.765)	GS 37.500 (32.470)	mem 72.595
Train: [94][1190/1500]	BT 0.039 (0.304)	DT 0.001 (0.266)	loss 6.549 (6.475)	prob 2.239 (2.718)	GS 34.656 (32.688)	mem 72.597
Train: [94][1200/1500]	BT 0.037 (0.302)	DT 0.001 (0.264)	loss 6.702 (6.474)	prob 1.939 (2.674)	GS 36.344 (32.631)	mem 72.596
Train: [94][1210/1500]	BT 0.034 (0.305)	DT 0.000 (0.267)	loss 6.403 (6.461)	prob 2.496 (2.526)	GS 31.875 (32.648)	mem 72.597
Train: [94][1220/1500]	BT 0.037 (0.303)	DT 0.000 (0.265)	loss 6.404 (6.465)	prob 2.656 (2.545)	GS 36.859 (33.405)	mem 72.597
Train: [94][1230/1500]	BT 0.037 (0.301)	DT 0.000 (0.263)	loss 6.439 (6.471)	prob 2.069 (2.531)	GS 33.500 (32.999)	mem 72.600
Train: [94][1240/1500]	BT 0.038 (0.301)	DT 0.001 (0.263)	loss 6.370 (6.460)	prob 2.292 (2.572)	GS 37.781 (32.927)	mem 72.627
Train: [94][1250/1500]	BT 0.039 (0.299)	DT 0.001 (0.261)	loss 6.509 (6.460)	prob 2.767 (2.535)	GS 31.781 (32.858)	mem 72.627
Train: [94][1260/1500]	BT 0.039 (0.300)	DT 0.001 (0.262)	loss 6.533 (6.476)	prob 2.302 (2.437)	GS 38.250 (33.220)	mem 72.629
Train: [94][1270/1500]	BT 0.039 (0.298)	DT 0.001 (0.260)	loss 6.403 (6.465)	prob 1.930 (2.212)	GS 35.672 (32.880)	mem 72.629
Train: [94][1280/1500]	BT 0.051 (0.303)	DT 0.011 (0.265)	loss 6.441 (6.470)	prob 1.882 (2.074)	GS 35.719 (33.219)	mem 72.628
Train: [94][1290/1500]	BT 0.039 (0.303)	DT 0.001 (0.265)	loss 6.493 (6.466)	prob 2.031 (2.069)	GS 32.500 (33.177)	mem 72.628
Train: [94][1300/1500]	BT 0.040 (0.301)	DT 0.001 (0.263)	loss 6.417 (6.461)	prob 2.061 (2.027)	GS 35.094 (33.323)	mem 72.628
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [94][1310/1500]	BT 0.038 (0.302)	DT 0.000 (0.264)	loss 6.411 (6.460)	prob 1.923 (2.074)	GS 31.750 (32.366)	mem 72.628
Train: [94][1320/1500]	BT 0.029 (0.300)	DT 0.000 (0.262)	loss 6.402 (6.426)	prob 1.811 (2.010)	GS 31.562 (32.034)	mem 72.631
Train: [94][1330/1500]	BT 0.037 (0.300)	DT 0.001 (0.262)	loss 6.378 (6.444)	prob 1.792 (2.004)	GS 35.188 (32.383)	mem 72.629
Train: [94][1340/1500]	BT 0.034 (0.299)	DT 0.001 (0.261)	loss 6.468 (6.441)	prob 1.580 (2.000)	GS 30.922 (32.377)	mem 72.629
Train: [94][1350/1500]	BT 0.035 (0.297)	DT 0.001 (0.259)	loss 6.333 (6.430)	prob 2.283 (2.040)	GS 35.812 (32.561)	mem 72.628
Train: [94][1360/1500]	BT 0.038 (0.298)	DT 0.001 (0.260)	loss 6.483 (6.443)	prob 2.196 (2.142)	GS 37.859 (32.808)	mem 72.632
Train: [94][1370/1500]	BT 0.040 (0.296)	DT 0.001 (0.258)	loss 6.365 (6.417)	prob 1.741 (2.128)	GS 32.578 (32.411)	mem 72.632
Train: [94][1380/1500]	BT 0.042 (0.296)	DT 0.001 (0.258)	loss 6.473 (6.411)	prob 1.629 (2.028)	GS 34.375 (32.016)	mem 72.631
Train: [94][1390/1500]	BT 0.040 (0.297)	DT 0.009 (0.259)	loss 6.421 (6.416)	prob 1.961 (1.982)	GS 30.188 (32.020)	mem 72.632
Train: [94][1400/1500]	BT 0.039 (0.296)	DT 0.001 (0.258)	loss 6.351 (6.420)	prob 1.888 (1.989)	GS 36.156 (32.155)	mem 72.632
Train: [94][1410/1500]	BT 0.040 (0.298)	DT 0.010 (0.260)	loss 6.456 (6.471)	prob 2.136 (1.978)	GS 33.469 (34.125)	mem 72.635
Train: [94][1420/1500]	BT 0.072 (0.296)	DT 0.009 (0.258)	loss 6.493 (6.454)	prob 2.241 (2.101)	GS 31.031 (33.470)	mem 72.634
Train: [94][1430/1500]	BT 0.039 (0.296)	DT 0.001 (0.258)	loss 6.561 (6.458)	prob 2.179 (2.214)	GS 34.547 (33.367)	mem 72.634
Train: [94][1440/1500]	BT 0.032 (0.295)	DT 0.000 (0.256)	loss 6.447 (6.460)	prob 2.161 (2.227)	GS 32.391 (33.027)	mem 72.631
Train: [94][1450/1500]	BT 0.028 (0.295)	DT 0.000 (0.257)	loss 6.474 (6.452)	prob 2.277 (2.247)	GS 33.672 (32.906)	mem 72.309
Train: [94][1460/1500]	BT 0.036 (0.294)	DT 0.000 (0.256)	loss 6.500 (6.403)	prob 1.893 (1.988)	GS 32.234 (32.200)	mem 72.309
Train: [94][1470/1500]	BT 0.037 (0.292)	DT 0.001 (0.254)	loss 6.395 (6.418)	prob 2.267 (2.024)	GS 32.609 (31.723)	mem 72.311
Train: [94][1480/1500]	BT 0.028 (0.292)	DT 0.000 (0.254)	loss 6.387 (6.418)	prob 2.031 (2.028)	GS 35.641 (31.924)	mem 16.032
Train: [94][1490/1500]	BT 0.022 (0.291)	DT 0.000 (0.253)	loss 6.480 (6.429)	prob 2.068 (2.045)	GS 34.031 (31.962)	mem 10.409
Train: [94][1500/1500]	BT 0.032 (0.289)	DT 0.000 (0.251)	loss 6.387 (6.417)	prob 2.193 (2.086)	GS 40.719 (32.049)	mem 10.349
Train: [94][1510/1500]	BT 0.032 (0.288)	DT 0.000 (0.250)	loss 6.063 (6.126)	prob 2.200 (2.240)	GS 28.250 (32.822)	mem 10.349
epoch 94, total time 435.06
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [95][1/1500]	BT 17.614 (17.614)	DT 17.555 (17.555)	loss 6.008 (6.008)	prob 2.486 (2.486)	GS 32.984 (32.984)	mem 70.916
Train: [95][10/1500]	BT 0.037 (2.170)	DT 0.000 (2.131)	loss 6.128 (6.103)	prob 2.214 (2.383)	GS 34.750 (32.276)	mem 71.257
Train: [95][20/1500]	BT 0.068 (1.152)	DT 0.013 (1.113)	loss 6.245 (6.171)	prob 2.702 (2.363)	GS 37.234 (32.801)	mem 71.312
Train: [95][30/1500]	BT 0.072 (0.919)	DT 0.006 (0.879)	loss 6.323 (6.224)	prob 2.947 (2.428)	GS 31.828 (32.249)	mem 71.340
Train: [95][40/1500]	BT 0.028 (0.754)	DT 0.000 (0.715)	loss 6.385 (6.275)	prob 2.114 (2.396)	GS 34.422 (32.376)	mem 71.348
Train: [95][50/1500]	BT 2.594 (0.661)	DT 2.536 (0.622)	loss 6.335 (6.297)	prob 2.276 (2.366)	GS 31.609 (32.291)	mem 71.359
Train: [95][60/1500]	BT 0.037 (0.611)	DT 0.000 (0.571)	loss 6.215 (6.349)	prob 2.291 (2.145)	GS 34.938 (32.380)	mem 71.370
Train: [95][70/1500]	BT 0.038 (0.531)	DT 0.000 (0.490)	loss 6.432 (6.388)	prob 1.961 (2.218)	GS 30.141 (32.144)	mem 71.371
Train: [95][80/1500]	BT 0.029 (0.577)	DT 0.000 (0.536)	loss 6.412 (6.401)	prob 3.129 (2.288)	GS 31.531 (32.568)	mem 71.381
Train: [95][90/1500]	BT 0.036 (0.516)	DT 0.000 (0.477)	loss 6.431 (6.395)	prob 2.409 (2.309)	GS 28.547 (32.150)	mem 71.384
Train: [95][100/1500]	BT 0.039 (0.469)	DT 0.001 (0.429)	loss 6.405 (6.401)	prob 2.715 (2.343)	GS 34.172 (32.276)	mem 71.384
Train: [95][110/1500]	BT 0.039 (0.468)	DT 0.001 (0.428)	loss 6.361 (6.416)	prob 2.710 (2.395)	GS 28.953 (31.570)	mem 71.388
Train: [95][120/1500]	BT 0.039 (0.431)	DT 0.001 (0.393)	loss 6.295 (6.396)	prob 2.123 (2.404)	GS 28.094 (31.369)	mem 71.388
Train: [95][130/1500]	BT 0.028 (0.425)	DT 0.000 (0.387)	loss 6.511 (6.419)	prob 2.166 (2.298)	GS 35.359 (32.079)	mem 71.391
Train: [95][140/1500]	BT 0.039 (0.397)	DT 0.001 (0.359)	loss 6.428 (6.423)	prob 2.109 (2.270)	GS 32.859 (31.998)	mem 71.391
Train: [95][150/1500]	BT 0.031 (0.436)	DT 0.001 (0.398)	loss 6.353 (6.413)	prob 2.550 (2.263)	GS 32.016 (32.196)	mem 71.408
Train: [95][160/1500]	BT 0.030 (0.410)	DT 0.000 (0.373)	loss 6.415 (6.437)	prob 2.020 (2.068)	GS 33.703 (31.970)	mem 71.408
Train: [95][170/1500]	BT 0.031 (0.388)	DT 0.001 (0.351)	loss 6.267 (6.422)	prob 2.547 (2.114)	GS 36.469 (32.627)	mem 71.409
Train: [95][180/1500]	BT 0.039 (0.384)	DT 0.000 (0.348)	loss 6.326 (6.426)	prob 2.355 (2.164)	GS 32.922 (32.440)	mem 71.420
Train: [95][190/1500]	BT 0.037 (0.366)	DT 0.001 (0.329)	loss 6.404 (6.420)	prob 1.982 (2.157)	GS 34.078 (32.620)	mem 71.421
Train: [95][200/1500]	BT 0.060 (0.368)	DT 0.006 (0.331)	loss 6.358 (6.410)	prob 2.108 (2.127)	GS 33.750 (32.321)	mem 71.432
Train: [95][210/1500]	BT 0.037 (0.353)	DT 0.000 (0.316)	loss 6.333 (6.374)	prob 1.928 (1.968)	GS 28.172 (31.123)	mem 71.434
Train: [95][220/1500]	BT 0.069 (0.352)	DT 0.016 (0.315)	loss 6.382 (6.374)	prob 1.721 (1.983)	GS 36.641 (32.118)	mem 71.437
Train: [95][230/1500]	BT 0.028 (0.342)	DT 0.000 (0.305)	loss 6.470 (6.387)	prob 2.146 (2.052)	GS 34.906 (32.557)	mem 71.437
Train: [95][240/1500]	BT 0.037 (0.335)	DT 0.001 (0.298)	loss 6.473 (6.391)	prob 1.881 (2.090)	GS 31.234 (32.408)	mem 71.440
Train: [95][250/1500]	BT 0.037 (0.336)	DT 0.000 (0.299)	loss 6.376 (6.395)	prob 2.450 (2.110)	GS 31.812 (32.447)	mem 71.443
Train: [95][260/1500]	BT 0.036 (0.330)	DT 0.000 (0.293)	loss 6.447 (6.419)	prob 1.853 (2.007)	GS 34.297 (32.591)	mem 71.445
Train: [95][270/1500]	BT 0.037 (0.330)	DT 0.000 (0.293)	loss 6.365 (6.404)	prob 1.577 (1.990)	GS 32.703 (32.192)	mem 71.449
Train: [95][280/1500]	BT 0.037 (0.319)	DT 0.001 (0.282)	loss 6.473 (6.400)	prob 1.896 (1.977)	GS 31.766 (32.242)	mem 71.449
Train: [95][290/1500]	BT 0.037 (0.311)	DT 0.001 (0.274)	loss 6.346 (6.392)	prob 1.961 (1.994)	GS 36.188 (32.515)	mem 71.449
Train: [95][300/1500]	BT 0.029 (0.328)	DT 0.000 (0.292)	loss 6.450 (6.397)	prob 1.658 (2.000)	GS 32.203 (32.405)	mem 71.456
Train: [95][310/1500]	BT 0.032 (0.319)	DT 0.000 (0.282)	loss 6.375 (6.406)	prob 1.900 (2.021)	GS 36.469 (33.314)	mem 71.456
Train: [95][320/1500]	BT 0.037 (0.319)	DT 0.000 (0.282)	loss 6.472 (6.388)	prob 1.811 (1.990)	GS 34.672 (33.206)	mem 71.460
Train: [95][330/1500]	BT 0.038 (0.310)	DT 0.001 (0.274)	loss 6.404 (6.377)	prob 1.736 (1.969)	GS 33.922 (32.430)	mem 71.461
Train: [95][340/1500]	BT 0.035 (0.314)	DT 0.001 (0.278)	loss 6.461 (6.370)	prob 2.055 (1.986)	GS 30.500 (32.278)	mem 71.464
Train: [95][350/1500]	BT 0.037 (0.306)	DT 0.000 (0.270)	loss 6.484 (6.367)	prob 1.847 (1.954)	GS 31.609 (32.341)	mem 71.466
Train: [95][360/1500]	BT 0.037 (0.299)	DT 0.001 (0.263)	loss 6.455 (6.380)	prob 1.690 (1.807)	GS 35.953 (32.434)	mem 71.466
Train: [95][370/1500]	BT 0.036 (0.303)	DT 0.000 (0.267)	loss 6.418 (6.412)	prob 2.439 (1.853)	GS 30.750 (32.800)	mem 71.467
Train: [95][380/1500]	BT 0.037 (0.299)	DT 0.000 (0.262)	loss 6.419 (6.410)	prob 2.082 (1.954)	GS 37.422 (32.940)	mem 71.469
Train: [95][390/1500]	BT 0.027 (0.303)	DT 0.000 (0.266)	loss 6.419 (6.401)	prob 2.392 (2.032)	GS 38.281 (32.987)	mem 71.471
Train: [95][400/1500]	BT 0.037 (0.296)	DT 0.001 (0.260)	loss 6.437 (6.396)	prob 2.131 (2.052)	GS 30.312 (32.941)	mem 71.471
Train: [95][410/1500]	BT 0.029 (0.302)	DT 0.000 (0.266)	loss 6.565 (6.444)	prob 2.012 (2.152)	GS 31.750 (34.388)	mem 71.470
Train: [95][420/1500]	BT 0.034 (0.297)	DT 0.000 (0.261)	loss 6.412 (6.431)	prob 2.350 (2.093)	GS 32.594 (33.308)	mem 71.470
Train: [95][430/1500]	BT 0.061 (0.299)	DT 0.011 (0.263)	loss 6.340 (6.432)	prob 2.162 (2.192)	GS 29.906 (33.163)	mem 71.472
Train: [95][440/1500]	BT 0.037 (0.302)	DT 0.001 (0.266)	loss 6.397 (6.417)	prob 2.073 (2.204)	GS 32.469 (33.237)	mem 71.472
Train: [95][450/1500]	BT 0.037 (0.296)	DT 0.001 (0.260)	loss 6.295 (6.417)	prob 2.511 (2.208)	GS 32.859 (33.563)	mem 71.473
Train: [95][460/1500]	BT 0.045 (0.303)	DT 0.004 (0.267)	loss 6.462 (6.387)	prob 2.305 (2.147)	GS 35.125 (32.197)	mem 71.506
Train: [95][470/1500]	BT 0.071 (0.298)	DT 0.002 (0.261)	loss 6.498 (6.374)	prob 2.100 (2.193)	GS 34.594 (32.360)	mem 71.506
Train: [95][480/1500]	BT 0.060 (0.293)	DT 0.009 (0.256)	loss 6.294 (6.377)	prob 2.333 (2.155)	GS 35.312 (32.223)	mem 71.506
Train: [95][490/1500]	BT 0.047 (0.301)	DT 0.001 (0.263)	loss 6.364 (6.368)	prob 1.861 (2.132)	GS 34.797 (32.282)	mem 71.508
Train: [95][500/1500]	BT 0.065 (0.295)	DT 0.007 (0.258)	loss 6.365 (6.374)	prob 2.121 (2.117)	GS 34.422 (32.516)	mem 71.509
Train: [95][510/1500]	BT 0.028 (0.318)	DT 0.000 (0.280)	loss 6.460 (6.393)	prob 2.074 (2.216)	GS 34.250 (33.336)	mem 71.510
Train: [95][520/1500]	BT 0.038 (0.312)	DT 0.000 (0.275)	loss 6.334 (6.374)	prob 2.202 (2.185)	GS 35.109 (32.868)	mem 71.512
Train: [95][530/1500]	BT 0.040 (0.312)	DT 0.001 (0.275)	loss 6.225 (6.359)	prob 2.272 (2.180)	GS 30.578 (32.858)	mem 72.003
Train: [95][540/1500]	BT 0.039 (0.307)	DT 0.000 (0.270)	loss 6.351 (6.364)	prob 2.289 (2.194)	GS 32.797 (32.753)	mem 72.050
Train: [95][550/1500]	BT 0.039 (0.302)	DT 0.001 (0.265)	loss 6.337 (6.361)	prob 2.403 (2.196)	GS 33.734 (32.843)	mem 72.098
Train: [95][560/1500]	BT 0.039 (0.305)	DT 0.001 (0.267)	loss 6.515 (6.398)	prob 2.061 (2.115)	GS 35.781 (32.403)	mem 72.489
Train: [95][570/1500]	BT 0.039 (0.300)	DT 0.001 (0.263)	loss 6.436 (6.384)	prob 2.047 (2.067)	GS 28.922 (32.295)	mem 72.538
Train: [95][580/1500]	BT 0.039 (0.301)	DT 0.001 (0.264)	loss 6.446 (6.378)	prob 1.911 (2.071)	GS 36.625 (32.419)	mem 72.686
Train: [95][590/1500]	BT 0.039 (0.297)	DT 0.001 (0.259)	loss 6.380 (6.371)	prob 2.129 (2.093)	GS 33.719 (32.476)	mem 72.686
Train: [95][600/1500]	BT 0.068 (0.297)	DT 0.014 (0.260)	loss 6.186 (6.362)	prob 2.564 (2.127)	GS 31.016 (32.285)	mem 72.689
Train: [95][610/1500]	BT 0.039 (0.297)	DT 0.000 (0.259)	loss 6.273 (6.356)	prob 2.103 (2.062)	GS 31.766 (31.702)	mem 72.694
Train: [95][620/1500]	BT 0.039 (0.293)	DT 0.001 (0.255)	loss 6.473 (6.356)	prob 1.950 (2.039)	GS 37.922 (32.705)	mem 72.695
Train: [95][630/1500]	BT 0.039 (0.293)	DT 0.001 (0.256)	loss 6.337 (6.361)	prob 1.974 (2.071)	GS 30.641 (32.582)	mem 72.692
Train: [95][640/1500]	BT 0.039 (0.290)	DT 0.001 (0.252)	loss 6.368 (6.365)	prob 2.348 (2.068)	GS 36.531 (32.775)	mem 72.693
Train: [95][650/1500]	BT 0.039 (0.291)	DT 0.001 (0.253)	loss 6.377 (6.367)	prob 1.843 (2.037)	GS 34.562 (32.500)	mem 72.693
Train: [95][660/1500]	BT 0.039 (0.287)	DT 0.000 (0.249)	loss 6.357 (6.345)	prob 1.767 (1.914)	GS 35.281 (32.933)	mem 72.694
Train: [95][670/1500]	BT 0.040 (0.284)	DT 0.001 (0.246)	loss 6.255 (6.333)	prob 2.179 (1.949)	GS 36.062 (32.696)	mem 72.693
Train: [95][680/1500]	BT 0.053 (0.286)	DT 0.006 (0.249)	loss 6.408 (6.334)	prob 1.810 (1.964)	GS 33.438 (32.486)	mem 72.693
Train: [95][690/1500]	BT 0.029 (0.298)	DT 0.000 (0.261)	loss 6.351 (6.333)	prob 1.656 (1.899)	GS 33.062 (32.380)	mem 72.692
Train: [95][700/1500]	BT 0.037 (0.295)	DT 0.000 (0.257)	loss 6.217 (6.324)	prob 1.838 (1.881)	GS 31.703 (32.188)	mem 72.693
Train: [95][710/1500]	BT 0.074 (0.298)	DT 0.008 (0.260)	loss 6.282 (6.322)	prob 1.935 (1.759)	GS 35.719 (32.388)	mem 72.694
Train: [95][720/1500]	BT 0.081 (0.294)	DT 0.010 (0.256)	loss 6.342 (6.331)	prob 1.631 (1.721)	GS 34.047 (32.148)	mem 72.694
Train: [95][730/1500]	BT 0.070 (0.291)	DT 0.011 (0.253)	loss 6.282 (6.324)	prob 2.000 (1.734)	GS 33.109 (32.048)	mem 72.693
Train: [95][740/1500]	BT 0.035 (0.299)	DT 0.000 (0.261)	loss 6.332 (6.324)	prob 1.828 (1.753)	GS 31.047 (32.368)	mem 72.694
Train: [95][750/1500]	BT 0.036 (0.295)	DT 0.001 (0.257)	loss 6.222 (6.321)	prob 1.975 (1.781)	GS 31.953 (32.517)	mem 72.696
Train: [95][760/1500]	BT 0.036 (0.295)	DT 0.001 (0.258)	loss 6.328 (6.302)	prob 1.867 (1.967)	GS 31.828 (32.653)	mem 72.693
Train: [95][770/1500]	BT 0.054 (0.292)	DT 0.001 (0.254)	loss 6.322 (6.306)	prob 1.902 (1.912)	GS 31.406 (32.262)	mem 72.693
Train: [95][780/1500]	BT 0.036 (0.293)	DT 0.001 (0.256)	loss 6.385 (6.315)	prob 1.566 (1.923)	GS 29.516 (32.242)	mem 72.698
Train: [95][790/1500]	BT 0.034 (0.291)	DT 0.001 (0.253)	loss 6.234 (6.314)	prob 2.272 (1.975)	GS 36.047 (32.548)	mem 72.701
Train: [95][800/1500]	BT 0.031 (0.287)	DT 0.000 (0.250)	loss 6.428 (6.319)	prob 1.812 (1.982)	GS 33.812 (32.197)	mem 72.701
Train: [95][810/1500]	BT 0.037 (0.291)	DT 0.001 (0.253)	loss 6.257 (6.283)	prob 1.896 (1.993)	GS 33.672 (32.816)	mem 72.713
Train: [95][820/1500]	BT 0.037 (0.288)	DT 0.000 (0.250)	loss 6.430 (6.312)	prob 2.382 (1.954)	GS 36.109 (32.891)	mem 72.713
Train: [95][830/1500]	BT 0.034 (0.292)	DT 0.001 (0.254)	loss 6.380 (6.321)	prob 1.825 (1.969)	GS 34.562 (32.767)	mem 72.615
Train: [95][840/1500]	BT 0.069 (0.289)	DT 0.001 (0.251)	loss 6.370 (6.322)	prob 1.736 (1.986)	GS 35.641 (33.014)	mem 72.615
Train: [95][850/1500]	BT 0.032 (0.294)	DT 0.000 (0.256)	loss 6.421 (6.331)	prob 2.054 (1.980)	GS 37.484 (33.302)	mem 72.617
Train: [95][860/1500]	BT 0.024 (0.291)	DT 0.000 (0.254)	loss 6.399 (6.397)	prob 2.208 (2.141)	GS 37.281 (33.675)	mem 72.618
Train: [95][870/1500]	BT 0.037 (0.291)	DT 0.001 (0.253)	loss 6.258 (6.370)	prob 2.398 (2.212)	GS 33.578 (33.578)	mem 72.619
Train: [95][880/1500]	BT 0.037 (0.289)	DT 0.001 (0.251)	loss 6.273 (6.354)	prob 1.928 (2.222)	GS 34.984 (33.955)	mem 72.620
Train: [95][890/1500]	BT 0.037 (0.286)	DT 0.001 (0.249)	loss 6.268 (6.344)	prob 2.315 (2.181)	GS 31.234 (33.611)	mem 72.621
Train: [95][900/1500]	BT 0.065 (0.287)	DT 0.001 (0.249)	loss 6.303 (6.341)	prob 2.312 (2.173)	GS 34.047 (33.213)	mem 72.625
Train: [95][910/1500]	BT 0.028 (0.290)	DT 0.000 (0.252)	loss 6.231 (6.310)	prob 2.390 (2.264)	GS 39.109 (35.206)	mem 72.646
Train: [95][920/1500]	BT 0.038 (0.287)	DT 0.000 (0.249)	loss 6.304 (6.313)	prob 2.148 (2.227)	GS 36.547 (34.089)	mem 72.647
Train: [95][930/1500]	BT 0.048 (0.284)	DT 0.010 (0.247)	loss 6.315 (6.305)	prob 1.473 (2.150)	GS 35.891 (33.569)	mem 72.647
Train: [95][940/1500]	BT 0.040 (0.286)	DT 0.001 (0.248)	loss 6.324 (6.303)	prob 2.069 (2.101)	GS 35.375 (33.175)	mem 72.647
Train: [95][950/1500]	BT 0.060 (0.284)	DT 0.006 (0.247)	loss 6.342 (6.304)	prob 1.607 (2.063)	GS 33.375 (32.912)	mem 72.646
Train: [95][960/1500]	BT 0.093 (0.288)	DT 0.016 (0.251)	loss 6.407 (6.265)	prob 1.824 (1.792)	GS 35.984 (32.058)	mem 72.635
Train: [95][970/1500]	BT 0.075 (0.286)	DT 0.007 (0.248)	loss 6.385 (6.290)	prob 1.974 (1.865)	GS 35.359 (31.616)	mem 72.635
Train: [95][980/1500]	BT 0.030 (0.293)	DT 0.000 (0.255)	loss 6.459 (6.315)	prob 1.909 (1.901)	GS 32.797 (32.573)	mem 72.636
Train: [95][990/1500]	BT 0.026 (0.290)	DT 0.000 (0.252)	loss 6.259 (6.314)	prob 2.318 (1.965)	GS 31.719 (32.856)	mem 72.636
Train: [95][1000/1500]	BT 0.029 (0.292)	DT 0.000 (0.255)	loss 6.259 (6.312)	prob 2.240 (2.007)	GS 35.953 (32.791)	mem 72.638
Train: [95][1010/1500]	BT 0.027 (0.290)	DT 0.000 (0.252)	loss 6.320 (6.284)	prob 2.413 (2.342)	GS 32.859 (33.694)	mem 72.637
Train: [95][1020/1500]	BT 0.026 (0.287)	DT 0.000 (0.250)	loss 6.393 (6.298)	prob 2.050 (2.142)	GS 36.062 (32.712)	mem 72.637
Train: [95][1030/1500]	BT 0.039 (0.287)	DT 0.001 (0.250)	loss 6.324 (6.301)	prob 2.088 (2.141)	GS 33.344 (31.981)	mem 72.639
Train: [95][1040/1500]	BT 0.039 (0.285)	DT 0.001 (0.248)	loss 6.283 (6.303)	prob 2.256 (2.134)	GS 31.891 (31.951)	mem 72.640
Train: [95][1050/1500]	BT 0.039 (0.285)	DT 0.001 (0.248)	loss 6.325 (6.307)	prob 1.712 (2.103)	GS 32.078 (32.210)	mem 72.637
Train: [95][1060/1500]	BT 0.039 (0.283)	DT 0.001 (0.246)	loss 6.426 (6.310)	prob 1.954 (1.984)	GS 32.797 (31.814)	mem 72.638
Train: [95][1070/1500]	BT 0.038 (0.283)	DT 0.000 (0.246)	loss 6.254 (6.306)	prob 2.089 (2.058)	GS 33.609 (32.190)	mem 72.651
Train: [95][1080/1500]	BT 0.037 (0.282)	DT 0.001 (0.244)	loss 6.319 (6.310)	prob 2.182 (2.059)	GS 35.750 (32.443)	mem 72.652
Train: [95][1090/1500]	BT 0.037 (0.280)	DT 0.001 (0.242)	loss 6.305 (6.320)	prob 2.250 (2.069)	GS 38.094 (32.759)	mem 72.653
Train: [95][1100/1500]	BT 0.038 (0.280)	DT 0.000 (0.242)	loss 6.282 (6.317)	prob 1.837 (2.026)	GS 34.281 (32.481)	mem 72.654
Train: [95][1110/1500]	BT 0.037 (0.281)	DT 0.001 (0.244)	loss 6.318 (6.320)	prob 2.281 (1.953)	GS 35.203 (33.708)	mem 72.658
Train: [95][1120/1500]	BT 0.037 (0.279)	DT 0.001 (0.241)	loss 6.250 (6.314)	prob 2.141 (2.016)	GS 35.672 (33.295)	mem 72.659
Train: [95][1130/1500]	BT 0.037 (0.278)	DT 0.001 (0.241)	loss 6.287 (6.311)	prob 2.030 (1.988)	GS 38.469 (33.558)	mem 72.661
Train: [95][1140/1500]	BT 0.060 (0.279)	DT 0.012 (0.241)	loss 6.374 (6.317)	prob 1.931 (2.000)	GS 32.203 (33.330)	mem 72.663
Train: [95][1150/1500]	BT 0.031 (0.278)	DT 0.000 (0.240)	loss 6.362 (6.323)	prob 1.963 (2.030)	GS 37.750 (33.157)	mem 72.664
Train: [95][1160/1500]	BT 0.037 (0.279)	DT 0.001 (0.242)	loss 6.310 (6.352)	prob 1.753 (1.988)	GS 34.906 (31.688)	mem 72.666
Train: [95][1170/1500]	BT 2.083 (0.279)	DT 2.045 (0.241)	loss 6.275 (6.331)	prob 2.323 (2.114)	GS 35.703 (32.202)	mem 72.668
Train: [95][1180/1500]	BT 2.815 (0.280)	DT 2.778 (0.242)	loss 6.261 (6.339)	prob 2.365 (2.073)	GS 30.031 (32.237)	mem 72.668
Train: [95][1190/1500]	BT 0.027 (0.278)	DT 0.000 (0.241)	loss 6.364 (6.347)	prob 2.133 (2.031)	GS 36.047 (32.737)	mem 72.671
Train: [95][1200/1500]	BT 0.037 (0.277)	DT 0.001 (0.239)	loss 6.302 (6.340)	prob 1.783 (2.018)	GS 38.266 (32.808)	mem 72.672
Train: [95][1210/1500]	BT 0.048 (0.278)	DT 0.000 (0.240)	loss 6.267 (6.309)	prob 2.139 (2.008)	GS 32.984 (33.241)	mem 72.674
Train: [95][1220/1500]	BT 0.026 (0.276)	DT 0.000 (0.239)	loss 6.314 (6.318)	prob 2.198 (2.035)	GS 33.078 (33.677)	mem 72.675
Train: [95][1230/1500]	BT 0.037 (0.276)	DT 0.001 (0.239)	loss 6.225 (6.318)	prob 2.031 (2.009)	GS 33.812 (33.370)	mem 72.678
Train: [95][1240/1500]	BT 0.038 (0.275)	DT 0.001 (0.238)	loss 6.643 (6.319)	prob 1.610 (1.987)	GS 35.266 (32.989)	mem 72.677
Train: [95][1250/1500]	BT 0.061 (0.274)	DT 0.001 (0.236)	loss 6.307 (6.317)	prob 2.331 (2.025)	GS 35.453 (32.843)	mem 72.677
Train: [95][1260/1500]	BT 0.025 (0.274)	DT 0.000 (0.236)	loss 6.316 (6.334)	prob 1.931 (1.937)	GS 34.953 (33.455)	mem 72.680
Train: [95][1270/1500]	BT 0.038 (0.274)	DT 0.001 (0.236)	loss 6.299 (6.336)	prob 2.382 (2.026)	GS 37.469 (33.444)	mem 72.679
Train: [95][1280/1500]	BT 0.038 (0.274)	DT 0.001 (0.236)	loss 6.435 (6.335)	prob 2.030 (2.076)	GS 39.172 (33.177)	mem 72.679
Train: [95][1290/1500]	BT 2.575 (0.274)	DT 2.538 (0.236)	loss 6.294 (6.330)	prob 2.079 (2.126)	GS 35.609 (33.054)	mem 72.678
Train: [95][1300/1500]	BT 0.480 (0.272)	DT 0.443 (0.235)	loss 6.282 (6.329)	prob 1.965 (2.100)	GS 33.375 (32.881)	mem 72.678
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [95][1310/1500]	BT 0.037 (0.271)	DT 0.000 (0.234)	loss 6.326 (6.342)	prob 2.036 (1.998)	GS 34.109 (32.083)	mem 72.678
Train: [95][1320/1500]	BT 0.037 (0.272)	DT 0.001 (0.235)	loss 6.264 (6.326)	prob 2.409 (2.068)	GS 28.984 (31.973)	mem 72.681
Train: [95][1330/1500]	BT 0.037 (0.272)	DT 0.001 (0.234)	loss 6.365 (6.329)	prob 2.226 (2.105)	GS 34.703 (32.234)	mem 72.680
Train: [95][1340/1500]	BT 0.026 (0.272)	DT 0.000 (0.235)	loss 6.377 (6.330)	prob 2.100 (2.149)	GS 28.234 (32.259)	mem 72.682
Train: [95][1350/1500]	BT 0.037 (0.270)	DT 0.000 (0.233)	loss 6.386 (6.335)	prob 2.246 (2.159)	GS 32.203 (32.157)	mem 72.683
Train: [95][1360/1500]	BT 0.038 (0.269)	DT 0.001 (0.231)	loss 6.378 (6.367)	prob 1.974 (2.149)	GS 31.156 (31.817)	mem 72.684
Train: [95][1370/1500]	BT 0.039 (0.269)	DT 0.001 (0.232)	loss 6.352 (6.358)	prob 2.293 (2.170)	GS 32.828 (31.745)	mem 72.714
Train: [95][1380/1500]	BT 0.039 (0.268)	DT 0.001 (0.230)	loss 6.289 (6.352)	prob 2.360 (2.159)	GS 33.266 (31.649)	mem 72.713
Train: [95][1390/1500]	BT 0.039 (0.268)	DT 0.001 (0.230)	loss 6.333 (6.340)	prob 2.197 (2.173)	GS 35.406 (32.166)	mem 72.714
Train: [95][1400/1500]	BT 0.039 (0.266)	DT 0.001 (0.229)	loss 6.454 (6.338)	prob 1.936 (2.145)	GS 32.688 (32.235)	mem 72.714
Train: [95][1410/1500]	BT 5.243 (0.269)	DT 5.203 (0.232)	loss 6.361 (6.309)	prob 2.015 (1.967)	GS 34.344 (32.669)	mem 72.712
Train: [95][1420/1500]	BT 0.026 (0.269)	DT 0.000 (0.231)	loss 6.326 (6.323)	prob 2.325 (2.017)	GS 34.609 (32.723)	mem 72.713
Train: [95][1430/1500]	BT 0.028 (0.267)	DT 0.000 (0.229)	loss 6.246 (6.323)	prob 2.004 (2.055)	GS 34.109 (32.377)	mem 72.714
Train: [95][1440/1500]	BT 0.028 (0.268)	DT 0.000 (0.231)	loss 6.415 (6.330)	prob 2.091 (2.083)	GS 33.391 (32.415)	mem 72.716
Train: [95][1450/1500]	BT 0.038 (0.267)	DT 0.001 (0.229)	loss 6.298 (6.329)	prob 2.264 (2.135)	GS 33.109 (32.530)	mem 72.716
Train: [95][1460/1500]	BT 0.033 (0.273)	DT 0.000 (0.235)	loss 6.295 (6.340)	prob 2.250 (2.304)	GS 34.562 (33.741)	mem 71.761
Train: [95][1470/1500]	BT 0.020 (0.271)	DT 0.000 (0.234)	loss 6.357 (6.309)	prob 2.222 (2.259)	GS 33.016 (32.960)	mem 71.762
Train: [95][1480/1500]	BT 0.021 (0.269)	DT 0.000 (0.232)	loss 6.387 (6.305)	prob 2.048 (2.230)	GS 31.953 (32.841)	mem 71.762
Train: [95][1490/1500]	BT 0.033 (0.270)	DT 0.000 (0.232)	loss 6.270 (6.307)	prob 1.985 (2.146)	GS 36.312 (32.750)	mem 7.621
Train: [95][1500/1500]	BT 0.029 (0.268)	DT 0.000 (0.231)	loss 6.073 (6.292)	prob 1.536 (2.127)	GS 32.188 (32.665)	mem 7.621
Train: [95][1510/1500]	BT 0.018 (0.267)	DT 0.000 (0.230)	loss 5.953 (5.982)	prob 2.177 (2.114)	GS 36.719 (33.928)	mem 7.584
epoch 95, total time 403.15
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [96][1/1500]	BT 18.059 (18.059)	DT 18.003 (18.003)	loss 5.888 (5.888)	prob 1.636 (1.636)	GS 30.625 (30.625)	mem 70.919
Train: [96][10/1500]	BT 0.034 (2.955)	DT 0.000 (2.909)	loss 6.100 (6.006)	prob 2.164 (2.208)	GS 29.062 (33.719)	mem 71.345
Train: [96][20/1500]	BT 0.026 (1.493)	DT 0.000 (1.455)	loss 6.223 (6.082)	prob 2.374 (2.220)	GS 34.578 (33.815)	mem 71.345
Train: [96][30/1500]	BT 0.036 (1.007)	DT 0.001 (0.970)	loss 6.247 (6.127)	prob 2.308 (2.229)	GS 35.922 (33.268)	mem 71.346
Train: [96][40/1500]	BT 0.029 (0.970)	DT 0.000 (0.934)	loss 6.322 (6.165)	prob 2.083 (2.221)	GS 37.797 (33.697)	mem 71.391
Train: [96][50/1500]	BT 0.026 (0.782)	DT 0.000 (0.747)	loss 6.287 (6.192)	prob 2.298 (2.207)	GS 30.312 (33.194)	mem 71.391
Train: [96][60/1500]	BT 0.029 (0.714)	DT 0.000 (0.680)	loss 6.347 (6.359)	prob 1.747 (1.993)	GS 31.812 (31.558)	mem 71.299
Train: [96][70/1500]	BT 0.037 (0.617)	DT 0.000 (0.583)	loss 6.279 (6.322)	prob 2.336 (2.110)	GS 34.891 (32.042)	mem 71.301
Train: [96][80/1500]	BT 0.036 (0.544)	DT 0.000 (0.510)	loss 6.440 (6.329)	prob 2.263 (2.162)	GS 34.938 (32.314)	mem 71.301
Train: [96][90/1500]	BT 0.027 (0.518)	DT 0.000 (0.484)	loss 6.335 (6.328)	prob 2.341 (2.191)	GS 33.406 (32.199)	mem 71.303
Train: [96][100/1500]	BT 0.037 (0.469)	DT 0.001 (0.436)	loss 6.334 (6.326)	prob 1.895 (2.187)	GS 34.594 (32.078)	mem 71.304
Train: [96][110/1500]	BT 0.036 (0.465)	DT 0.001 (0.431)	loss 6.337 (6.330)	prob 2.197 (2.286)	GS 34.188 (32.406)	mem 71.307
Train: [96][120/1500]	BT 0.026 (0.429)	DT 0.000 (0.395)	loss 6.312 (6.317)	prob 2.721 (2.367)	GS 31.781 (32.102)	mem 71.308
Train: [96][130/1500]	BT 0.037 (0.420)	DT 0.001 (0.386)	loss 6.311 (6.312)	prob 2.230 (2.357)	GS 35.750 (32.392)	mem 71.313
Train: [96][140/1500]	BT 0.062 (0.398)	DT 0.002 (0.363)	loss 6.404 (6.311)	prob 2.339 (2.365)	GS 35.156 (32.400)	mem 71.313
Train: [96][150/1500]	BT 0.030 (0.374)	DT 0.000 (0.339)	loss 6.223 (6.311)	prob 2.173 (2.357)	GS 29.328 (32.323)	mem 71.315
Train: [96][160/1500]	BT 0.022 (0.452)	DT 0.000 (0.417)	loss 6.324 (6.330)	prob 2.315 (2.253)	GS 35.875 (33.094)	mem 71.339
Train: [96][170/1500]	BT 0.026 (0.427)	DT 0.000 (0.393)	loss 6.359 (6.348)	prob 2.154 (2.342)	GS 33.453 (33.765)	mem 71.340
Train: [96][180/1500]	BT 0.038 (0.420)	DT 0.000 (0.386)	loss 6.472 (6.351)	prob 2.274 (2.391)	GS 36.812 (33.042)	mem 71.331
Train: [96][190/1500]	BT 0.038 (0.400)	DT 0.000 (0.366)	loss 6.328 (6.354)	prob 2.200 (2.366)	GS 30.688 (33.016)	mem 71.330
Train: [96][200/1500]	BT 0.038 (0.382)	DT 0.001 (0.348)	loss 6.492 (6.351)	prob 2.048 (2.358)	GS 36.859 (32.991)	mem 71.330
Train: [96][210/1500]	BT 0.036 (0.384)	DT 0.001 (0.350)	loss 6.476 (6.371)	prob 2.360 (2.580)	GS 36.922 (33.312)	mem 71.333
Train: [96][220/1500]	BT 0.029 (0.368)	DT 0.000 (0.334)	loss 6.373 (6.370)	prob 2.592 (2.610)	GS 31.047 (32.912)	mem 71.332
Train: [96][230/1500]	BT 0.039 (0.373)	DT 0.001 (0.339)	loss 6.286 (6.362)	prob 2.608 (2.548)	GS 36.406 (33.229)	mem 71.337
Train: [96][240/1500]	BT 0.025 (0.359)	DT 0.000 (0.325)	loss 6.339 (6.355)	prob 2.575 (2.537)	GS 30.812 (32.941)	mem 71.337
Train: [96][250/1500]	BT 0.039 (0.346)	DT 0.000 (0.312)	loss 6.231 (6.350)	prob 2.561 (2.518)	GS 34.641 (32.792)	mem 71.338
Train: [96][260/1500]	BT 0.039 (0.347)	DT 0.001 (0.313)	loss 6.321 (6.345)	prob 2.607 (2.439)	GS 37.734 (33.167)	mem 71.340
Train: [96][270/1500]	BT 0.039 (0.335)	DT 0.001 (0.301)	loss 6.349 (6.330)	prob 2.650 (2.551)	GS 32.062 (32.327)	mem 71.340
Train: [96][280/1500]	BT 0.039 (0.335)	DT 0.001 (0.300)	loss 6.341 (6.319)	prob 2.429 (2.529)	GS 34.453 (32.211)	mem 71.342
Train: [96][290/1500]	BT 0.036 (0.326)	DT 0.001 (0.292)	loss 6.275 (6.318)	prob 2.647 (2.568)	GS 34.656 (32.255)	mem 71.342
Train: [96][300/1500]	BT 0.058 (0.327)	DT 0.000 (0.292)	loss 6.295 (6.312)	prob 2.227 (2.558)	GS 33.594 (32.130)	mem 71.360
Train: [96][310/1500]	BT 0.038 (0.326)	DT 0.001 (0.291)	loss 6.374 (6.305)	prob 2.449 (2.606)	GS 34.484 (32.481)	mem 71.363
Train: [96][320/1500]	BT 0.075 (0.320)	DT 0.012 (0.284)	loss 6.291 (6.314)	prob 2.426 (2.588)	GS 37.031 (32.516)	mem 71.363
Train: [96][330/1500]	BT 0.057 (0.350)	DT 0.001 (0.314)	loss 6.509 (6.336)	prob 2.327 (2.540)	GS 35.844 (32.840)	mem 71.367
Train: [96][340/1500]	BT 0.054 (0.341)	DT 0.003 (0.305)	loss 6.425 (6.346)	prob 2.344 (2.505)	GS 31.641 (32.491)	mem 71.367
Train: [96][350/1500]	BT 0.034 (0.360)	DT 0.000 (0.324)	loss 6.370 (6.361)	prob 2.741 (2.524)	GS 34.969 (32.836)	mem 71.369
Train: [96][360/1500]	BT 0.066 (0.352)	DT 0.005 (0.315)	loss 6.366 (6.358)	prob 2.357 (2.451)	GS 35.812 (33.714)	mem 71.371
Train: [96][370/1500]	BT 0.029 (0.369)	DT 0.000 (0.333)	loss 6.344 (6.365)	prob 2.814 (2.482)	GS 33.328 (33.508)	mem 71.375
Train: [96][380/1500]	BT 0.023 (0.360)	DT 0.000 (0.324)	loss 6.247 (6.363)	prob 2.597 (2.457)	GS 33.125 (32.931)	mem 71.375
Train: [96][390/1500]	BT 0.025 (0.362)	DT 0.000 (0.326)	loss 6.301 (6.352)	prob 2.484 (2.459)	GS 30.078 (32.669)	mem 71.379
Train: [96][400/1500]	BT 0.038 (0.354)	DT 0.000 (0.318)	loss 6.364 (6.356)	prob 2.067 (2.413)	GS 32.344 (32.663)	mem 71.380
Train: [96][410/1500]	BT 0.033 (0.353)	DT 0.000 (0.317)	loss 6.390 (6.383)	prob 2.502 (2.437)	GS 28.344 (33.552)	mem 71.380
Train: [96][420/1500]	BT 0.032 (0.345)	DT 0.000 (0.310)	loss 6.458 (6.383)	prob 2.442 (2.432)	GS 28.078 (32.953)	mem 71.381
Train: [96][430/1500]	BT 0.031 (0.338)	DT 0.001 (0.302)	loss 6.352 (6.364)	prob 2.204 (2.395)	GS 35.281 (32.307)	mem 71.381
Train: [96][440/1500]	BT 0.037 (0.338)	DT 0.001 (0.302)	loss 6.404 (6.362)	prob 2.394 (2.438)	GS 34.641 (32.398)	mem 71.382
Train: [96][450/1500]	BT 0.037 (0.331)	DT 0.001 (0.295)	loss 6.414 (6.363)	prob 2.536 (2.433)	GS 36.000 (32.504)	mem 71.381
Train: [96][460/1500]	BT 0.059 (0.339)	DT 0.006 (0.304)	loss 6.452 (6.343)	prob 2.041 (2.397)	GS 32.625 (32.352)	mem 71.383
Train: [96][470/1500]	BT 0.044 (0.334)	DT 0.000 (0.298)	loss 6.335 (6.349)	prob 2.330 (2.349)	GS 31.859 (32.586)	mem 71.382
Train: [96][480/1500]	BT 0.038 (0.346)	DT 0.000 (0.310)	loss 6.456 (6.353)	prob 2.286 (2.291)	GS 32.625 (32.927)	mem 71.385
Train: [96][490/1500]	BT 0.036 (0.340)	DT 0.000 (0.304)	loss 6.270 (6.351)	prob 2.201 (2.273)	GS 34.641 (32.829)	mem 71.386
Train: [96][500/1500]	BT 0.037 (0.343)	DT 0.001 (0.306)	loss 6.350 (6.354)	prob 2.274 (2.269)	GS 34.031 (32.841)	mem 71.390
Train: [96][510/1500]	BT 0.038 (0.337)	DT 0.001 (0.300)	loss 6.317 (6.356)	prob 2.274 (2.191)	GS 30.047 (31.036)	mem 71.389
Train: [96][520/1500]	BT 0.064 (0.331)	DT 0.006 (0.295)	loss 6.401 (6.344)	prob 1.920 (2.149)	GS 30.953 (32.459)	mem 71.390
Train: [96][530/1500]	BT 0.034 (0.343)	DT 0.001 (0.306)	loss 6.373 (6.380)	prob 2.342 (2.163)	GS 33.172 (32.703)	mem 71.393
Train: [96][540/1500]	BT 0.032 (0.337)	DT 0.000 (0.300)	loss 6.369 (6.378)	prob 2.053 (2.177)	GS 33.703 (32.602)	mem 71.393
Train: [96][550/1500]	BT 0.032 (0.341)	DT 0.000 (0.305)	loss 6.301 (6.370)	prob 2.056 (2.160)	GS 37.266 (32.693)	mem 71.396
Train: [96][560/1500]	BT 0.026 (0.336)	DT 0.000 (0.300)	loss 6.306 (6.373)	prob 2.213 (2.091)	GS 35.594 (32.075)	mem 71.399
Train: [96][570/1500]	BT 0.038 (0.331)	DT 0.001 (0.295)	loss 6.429 (6.383)	prob 1.875 (2.071)	GS 34.922 (32.293)	mem 71.399
Train: [96][580/1500]	BT 0.027 (0.336)	DT 0.000 (0.300)	loss 6.406 (6.408)	prob 2.693 (2.166)	GS 36.922 (32.840)	mem 71.400
Train: [96][590/1500]	BT 0.037 (0.331)	DT 0.000 (0.295)	loss 6.357 (6.405)	prob 2.523 (2.214)	GS 32.875 (32.918)	mem 71.401
Train: [96][600/1500]	BT 0.031 (0.333)	DT 0.000 (0.297)	loss 6.438 (6.400)	prob 1.668 (2.211)	GS 31.344 (32.912)	mem 71.402
Train: [96][610/1500]	BT 0.036 (0.328)	DT 0.001 (0.292)	loss 6.426 (6.389)	prob 2.208 (2.384)	GS 36.906 (32.592)	mem 71.404
Train: [96][620/1500]	BT 0.038 (0.326)	DT 0.001 (0.290)	loss 6.491 (6.371)	prob 2.251 (2.391)	GS 36.344 (33.056)	mem 71.404
Train: [96][630/1500]	BT 0.037 (0.323)	DT 0.001 (0.287)	loss 6.294 (6.370)	prob 2.798 (2.434)	GS 33.766 (32.951)	mem 71.404
Train: [96][640/1500]	BT 0.038 (0.319)	DT 0.001 (0.283)	loss 6.300 (6.358)	prob 2.241 (2.437)	GS 36.734 (32.899)	mem 71.404
Train: [96][650/1500]	BT 0.037 (0.324)	DT 0.001 (0.288)	loss 6.343 (6.353)	prob 2.479 (2.439)	GS 34.016 (32.863)	mem 71.550
Train: [96][660/1500]	BT 0.037 (0.320)	DT 0.000 (0.284)	loss 6.398 (6.331)	prob 2.506 (2.507)	GS 33.578 (32.070)	mem 71.550
Train: [96][670/1500]	BT 0.034 (0.334)	DT 0.000 (0.298)	loss 6.261 (6.329)	prob 2.637 (2.530)	GS 35.453 (33.380)	mem 72.416
Train: [96][680/1500]	BT 0.032 (0.329)	DT 0.000 (0.293)	loss 6.393 (6.365)	prob 2.668 (2.569)	GS 32.688 (33.476)	mem 72.465
Train: [96][690/1500]	BT 0.038 (0.325)	DT 0.001 (0.289)	loss 6.498 (6.384)	prob 2.542 (2.536)	GS 37.078 (33.470)	mem 72.515
Train: [96][700/1500]	BT 0.038 (0.325)	DT 0.000 (0.289)	loss 6.487 (6.392)	prob 2.435 (2.507)	GS 33.641 (33.402)	mem 72.613
Train: [96][710/1500]	BT 0.039 (0.321)	DT 0.001 (0.285)	loss 6.351 (6.392)	prob 2.896 (2.877)	GS 33.750 (31.781)	mem 72.614
Train: [96][720/1500]	BT 0.039 (0.322)	DT 0.001 (0.286)	loss 6.435 (6.388)	prob 2.292 (2.755)	GS 37.922 (32.108)	mem 72.614
Train: [96][730/1500]	BT 0.039 (0.318)	DT 0.001 (0.282)	loss 6.412 (6.390)	prob 2.461 (2.732)	GS 31.859 (32.680)	mem 72.615
Train: [96][740/1500]	BT 0.038 (0.319)	DT 0.000 (0.283)	loss 6.484 (6.404)	prob 2.548 (2.688)	GS 33.250 (33.223)	mem 72.616
Train: [96][750/1500]	BT 0.039 (0.315)	DT 0.001 (0.279)	loss 6.386 (6.404)	prob 2.371 (2.655)	GS 33.000 (33.195)	mem 72.616
Train: [96][760/1500]	BT 0.039 (0.311)	DT 0.001 (0.275)	loss 6.393 (6.425)	prob 2.890 (2.720)	GS 33.750 (32.708)	mem 72.616
Train: [96][770/1500]	BT 0.044 (0.315)	DT 0.006 (0.279)	loss 6.413 (6.418)	prob 2.591 (2.673)	GS 35.688 (33.152)	mem 72.616
Train: [96][780/1500]	BT 0.052 (0.312)	DT 0.011 (0.276)	loss 6.314 (6.404)	prob 2.796 (2.655)	GS 34.234 (32.465)	mem 72.618
Train: [96][790/1500]	BT 0.060 (0.313)	DT 0.006 (0.276)	loss 6.324 (6.401)	prob 3.041 (2.721)	GS 35.438 (32.522)	mem 72.620
Train: [96][800/1500]	BT 0.039 (0.313)	DT 0.000 (0.277)	loss 6.379 (6.404)	prob 2.546 (2.688)	GS 31.672 (32.470)	mem 72.620
Train: [96][810/1500]	BT 0.039 (0.313)	DT 0.001 (0.276)	loss 6.536 (6.446)	prob 2.619 (2.442)	GS 33.984 (32.659)	mem 72.619
Train: [96][820/1500]	BT 0.039 (0.311)	DT 0.001 (0.274)	loss 6.404 (6.424)	prob 2.579 (2.552)	GS 32.531 (32.137)	mem 72.618
Train: [96][830/1500]	BT 0.038 (0.311)	DT 0.001 (0.275)	loss 6.353 (6.423)	prob 2.650 (2.536)	GS 35.203 (32.023)	mem 72.618
Train: [96][840/1500]	BT 0.438 (0.310)	DT 0.399 (0.273)	loss 6.429 (6.424)	prob 2.492 (2.597)	GS 30.953 (32.036)	mem 72.620
Train: [96][850/1500]	BT 0.039 (0.307)	DT 0.001 (0.270)	loss 6.387 (6.420)	prob 2.817 (2.614)	GS 31.359 (32.246)	mem 72.620
Train: [96][860/1500]	BT 0.035 (0.308)	DT 0.001 (0.271)	loss 6.416 (6.433)	prob 2.711 (2.666)	GS 34.438 (33.764)	mem 72.620
Train: [96][870/1500]	BT 0.036 (0.307)	DT 0.001 (0.271)	loss 6.389 (6.453)	prob 2.644 (2.502)	GS 33.766 (33.220)	mem 72.622
Train: [96][880/1500]	BT 0.037 (0.307)	DT 0.001 (0.271)	loss 6.383 (6.440)	prob 2.665 (2.549)	GS 35.094 (33.518)	mem 72.622
Train: [96][890/1500]	BT 0.037 (0.305)	DT 0.001 (0.268)	loss 6.367 (6.438)	prob 2.585 (2.562)	GS 33.281 (33.287)	mem 72.624
Train: [96][900/1500]	BT 0.033 (0.307)	DT 0.001 (0.270)	loss 6.340 (6.430)	prob 2.737 (2.546)	GS 32.250 (33.100)	mem 72.624
Train: [96][910/1500]	BT 0.091 (0.304)	DT 0.052 (0.268)	loss 6.370 (6.427)	prob 2.508 (2.520)	GS 32.766 (33.325)	mem 72.624
Train: [96][920/1500]	BT 0.037 (0.301)	DT 0.001 (0.265)	loss 6.533 (6.420)	prob 2.029 (2.428)	GS 33.797 (32.392)	mem 72.627
Train: [96][930/1500]	BT 0.024 (0.303)	DT 0.000 (0.267)	loss 6.403 (6.419)	prob 2.267 (2.369)	GS 30.750 (32.106)	mem 72.643
Train: [96][940/1500]	BT 0.037 (0.301)	DT 0.000 (0.264)	loss 6.418 (6.425)	prob 2.443 (2.378)	GS 29.703 (31.902)	mem 72.663
Train: [96][950/1500]	BT 0.028 (0.301)	DT 0.000 (0.264)	loss 6.376 (6.423)	prob 2.417 (2.360)	GS 37.188 (31.856)	mem 72.547
Train: [96][960/1500]	BT 0.037 (0.298)	DT 0.000 (0.262)	loss 6.408 (6.407)	prob 2.405 (2.359)	GS 28.047 (31.108)	mem 72.547
Train: [96][970/1500]	BT 0.028 (0.296)	DT 0.000 (0.259)	loss 6.393 (6.398)	prob 2.003 (2.354)	GS 38.078 (31.880)	mem 72.546
Train: [96][980/1500]	BT 0.037 (0.296)	DT 0.000 (0.259)	loss 6.383 (6.408)	prob 2.337 (2.321)	GS 34.219 (31.500)	mem 72.547
Train: [96][990/1500]	BT 0.036 (0.293)	DT 0.000 (0.257)	loss 6.319 (6.408)	prob 2.677 (2.342)	GS 35.609 (31.868)	mem 72.547
Train: [96][1000/1500]	BT 0.037 (0.293)	DT 0.001 (0.257)	loss 6.464 (6.409)	prob 2.143 (2.342)	GS 31.938 (32.074)	mem 72.549
Train: [96][1010/1500]	BT 0.037 (0.291)	DT 0.001 (0.255)	loss 6.323 (6.385)	prob 2.369 (2.218)	GS 32.422 (32.655)	mem 72.548
Train: [96][1020/1500]	BT 0.037 (0.291)	DT 0.001 (0.254)	loss 6.431 (6.391)	prob 2.213 (2.162)	GS 33.406 (32.409)	mem 72.547
Train: [96][1030/1500]	BT 0.037 (0.291)	DT 0.001 (0.255)	loss 6.305 (6.387)	prob 2.152 (2.160)	GS 33.141 (32.139)	mem 72.547
Train: [96][1040/1500]	BT 0.037 (0.289)	DT 0.000 (0.252)	loss 6.356 (6.381)	prob 2.074 (2.122)	GS 34.734 (32.173)	mem 72.546
Train: [96][1050/1500]	BT 3.011 (0.293)	DT 2.953 (0.256)	loss 6.445 (6.382)	prob 2.039 (2.095)	GS 36.594 (32.463)	mem 72.567
Train: [96][1060/1500]	BT 0.093 (0.291)	DT 0.007 (0.254)	loss 6.375 (6.398)	prob 2.022 (2.035)	GS 36.125 (31.623)	mem 72.568
Train: [96][1070/1500]	BT 0.060 (0.290)	DT 0.013 (0.253)	loss 6.465 (6.390)	prob 1.739 (2.053)	GS 35.500 (32.277)	mem 72.569
Train: [96][1080/1500]	BT 0.064 (0.294)	DT 0.003 (0.257)	loss 6.325 (6.398)	prob 2.292 (2.057)	GS 33.531 (32.307)	mem 72.555
Train: [96][1090/1500]	BT 0.031 (0.296)	DT 0.000 (0.258)	loss 6.347 (6.399)	prob 1.979 (2.035)	GS 34.016 (32.519)	mem 72.554
Train: [96][1100/1500]	BT 0.029 (0.308)	DT 0.000 (0.270)	loss 6.424 (6.409)	prob 1.762 (2.014)	GS 34.844 (33.064)	mem 72.553
Train: [96][1110/1500]	BT 0.031 (0.305)	DT 0.000 (0.268)	loss 6.442 (6.437)	prob 1.682 (1.814)	GS 36.266 (31.995)	mem 72.553
Train: [96][1120/1500]	BT 0.038 (0.305)	DT 0.001 (0.268)	loss 6.352 (6.401)	prob 1.857 (1.922)	GS 34.406 (32.196)	mem 72.556
Train: [96][1130/1500]	BT 0.036 (0.303)	DT 0.001 (0.266)	loss 6.375 (6.403)	prob 1.806 (1.876)	GS 32.141 (32.277)	mem 72.557
Train: [96][1140/1500]	BT 0.039 (0.301)	DT 0.001 (0.263)	loss 6.374 (6.393)	prob 1.936 (1.906)	GS 35.062 (32.079)	mem 72.557
Train: [96][1150/1500]	BT 0.039 (0.301)	DT 0.001 (0.263)	loss 6.385 (6.397)	prob 2.062 (1.920)	GS 33.469 (32.314)	mem 72.557
Train: [96][1160/1500]	BT 0.041 (0.299)	DT 0.001 (0.261)	loss 6.390 (6.458)	prob 1.908 (1.922)	GS 33.594 (31.125)	mem 72.555
Train: [96][1170/1500]	BT 0.039 (0.301)	DT 0.001 (0.264)	loss 6.335 (6.426)	prob 2.405 (2.005)	GS 32.922 (31.895)	mem 72.558
Train: [96][1180/1500]	BT 0.027 (0.299)	DT 0.000 (0.261)	loss 6.306 (6.404)	prob 1.989 (2.036)	GS 36.562 (32.219)	mem 72.559
Train: [96][1190/1500]	BT 0.051 (0.296)	DT 0.012 (0.259)	loss 6.414 (6.402)	prob 1.747 (2.029)	GS 36.062 (32.430)	mem 72.559
Train: [96][1200/1500]	BT 0.031 (0.300)	DT 0.000 (0.263)	loss 6.292 (6.396)	prob 1.975 (2.024)	GS 30.953 (32.553)	mem 72.559
Train: [96][1210/1500]	BT 0.058 (0.298)	DT 0.011 (0.260)	loss 6.328 (6.384)	prob 2.055 (1.868)	GS 35.734 (33.442)	mem 72.559
Train: [96][1220/1500]	BT 0.063 (0.303)	DT 0.000 (0.265)	loss 6.349 (6.382)	prob 2.089 (1.894)	GS 36.234 (33.338)	mem 72.558
Train: [96][1230/1500]	BT 0.029 (0.309)	DT 0.000 (0.272)	loss 6.427 (6.385)	prob 1.831 (1.873)	GS 32.547 (33.087)	mem 72.555
Train: [96][1240/1500]	BT 0.098 (0.307)	DT 0.011 (0.269)	loss 6.424 (6.393)	prob 1.692 (1.854)	GS 33.797 (33.089)	mem 72.557
Train: [96][1250/1500]	BT 0.086 (0.311)	DT 0.006 (0.273)	loss 6.337 (6.389)	prob 2.190 (1.900)	GS 34.672 (32.996)	mem 72.559
Train: [96][1260/1500]	BT 0.088 (0.309)	DT 0.013 (0.271)	loss 6.359 (6.415)	prob 2.087 (1.878)	GS 31.922 (32.556)	mem 72.559
Train: [96][1270/1500]	BT 3.962 (0.310)	DT 3.928 (0.272)	loss 6.397 (6.425)	prob 2.121 (1.873)	GS 31.078 (33.439)	mem 72.571
Train: [96][1280/1500]	BT 0.031 (0.308)	DT 0.001 (0.270)	loss 6.295 (6.406)	prob 1.975 (1.864)	GS 33.094 (33.010)	mem 72.573
Train: [96][1290/1500]	BT 0.040 (0.306)	DT 0.001 (0.268)	loss 6.391 (6.411)	prob 1.909 (1.830)	GS 35.828 (33.155)	mem 72.576
Train: [96][1300/1500]	BT 0.038 (0.306)	DT 0.001 (0.268)	loss 6.348 (6.407)	prob 2.073 (1.858)	GS 34.766 (32.923)	mem 72.579
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [96][1310/1500]	BT 0.036 (0.305)	DT 0.000 (0.267)	loss 6.296 (6.379)	prob 2.280 (1.937)	GS 34.312 (31.806)	mem 72.578
Train: [96][1320/1500]	BT 0.038 (0.304)	DT 0.001 (0.266)	loss 6.397 (6.372)	prob 2.126 (1.943)	GS 35.172 (31.772)	mem 72.580
Train: [96][1330/1500]	BT 0.027 (0.303)	DT 0.000 (0.265)	loss 6.395 (6.375)	prob 2.058 (1.969)	GS 34.484 (32.024)	mem 72.582
Train: [96][1340/1500]	BT 0.050 (0.305)	DT 0.012 (0.267)	loss 6.406 (6.377)	prob 1.964 (1.959)	GS 34.594 (31.969)	mem 72.583
Train: [96][1350/1500]	BT 0.046 (0.306)	DT 0.000 (0.268)	loss 6.440 (6.384)	prob 1.841 (1.912)	GS 35.031 (32.328)	mem 72.582
Train: [96][1360/1500]	BT 0.049 (0.304)	DT 0.001 (0.266)	loss 6.405 (6.447)	prob 1.994 (1.913)	GS 32.859 (33.144)	mem 72.583
Train: [96][1370/1500]	BT 0.039 (0.307)	DT 0.001 (0.269)	loss 6.389 (6.456)	prob 1.951 (1.865)	GS 33.203 (33.192)	mem 72.586
Train: [96][1380/1500]	BT 0.027 (0.305)	DT 0.000 (0.267)	loss 6.373 (6.436)	prob 1.989 (1.873)	GS 32.266 (32.878)	mem 72.586
Train: [96][1390/1500]	BT 0.093 (0.306)	DT 0.006 (0.268)	loss 6.507 (6.427)	prob 1.812 (1.908)	GS 29.516 (32.879)	mem 72.587
Train: [96][1400/1500]	BT 0.072 (0.304)	DT 0.004 (0.266)	loss 6.274 (6.417)	prob 2.233 (1.911)	GS 32.203 (32.706)	mem 72.589
Train: [96][1410/1500]	BT 0.072 (0.303)	DT 0.006 (0.265)	loss 6.426 (6.375)	prob 2.077 (1.990)	GS 34.422 (32.913)	mem 72.589
Train: [96][1420/1500]	BT 0.027 (0.305)	DT 0.000 (0.267)	loss 6.442 (6.387)	prob 1.854 (1.947)	GS 27.688 (33.224)	mem 72.589
Train: [96][1430/1500]	BT 0.037 (0.304)	DT 0.001 (0.266)	loss 6.424 (6.397)	prob 1.999 (1.976)	GS 36.438 (33.685)	mem 72.590
Train: [96][1440/1500]	BT 0.031 (0.310)	DT 0.000 (0.271)	loss 6.377 (6.407)	prob 2.218 (1.981)	GS 34.609 (33.613)	mem 72.588
Train: [96][1450/1500]	BT 0.025 (0.308)	DT 0.000 (0.270)	loss 6.388 (6.413)	prob 1.898 (1.975)	GS 37.125 (33.133)	mem 72.590
Train: [96][1460/1500]	BT 0.029 (0.308)	DT 0.000 (0.270)	loss 6.429 (6.481)	prob 2.020 (2.000)	GS 35.828 (31.939)	mem 71.600
Train: [96][1470/1500]	BT 0.019 (0.306)	DT 0.000 (0.268)	loss 6.408 (6.462)	prob 2.075 (2.011)	GS 36.641 (31.897)	mem 71.600
Train: [96][1480/1500]	BT 0.033 (0.304)	DT 0.000 (0.266)	loss 6.431 (6.448)	prob 2.312 (2.058)	GS 33.156 (32.046)	mem 71.600
Train: [96][1490/1500]	BT 0.026 (0.304)	DT 0.000 (0.266)	loss 6.388 (6.437)	prob 2.074 (2.077)	GS 30.688 (32.089)	mem 7.541
Train: [96][1500/1500]	BT 0.026 (0.302)	DT 0.000 (0.264)	loss 6.226 (6.423)	prob 1.975 (2.063)	GS 31.688 (32.153)	mem 7.541
Train: [96][1510/1500]	BT 0.042 (0.301)	DT 0.000 (0.263)	loss 6.207 (6.161)	prob 1.654 (2.082)	GS 36.969 (33.741)	mem 7.467
epoch 96, total time 454.32
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [97][1/1500]	BT 21.170 (21.170)	DT 21.117 (21.117)	loss 6.125 (6.125)	prob 1.973 (1.973)	GS 32.000 (32.000)	mem 72.196
Train: [97][10/1500]	BT 0.031 (2.645)	DT 0.000 (2.611)	loss 6.208 (6.155)	prob 1.979 (1.993)	GS 36.344 (32.816)	mem 72.430
Train: [97][20/1500]	BT 0.053 (1.592)	DT 0.015 (1.556)	loss 6.398 (6.279)	prob 2.468 (1.998)	GS 34.828 (33.889)	mem 72.471
Train: [97][30/1500]	BT 0.038 (1.146)	DT 0.000 (1.108)	loss 6.452 (6.319)	prob 2.144 (2.093)	GS 36.656 (33.527)	mem 72.498
Train: [97][40/1500]	BT 1.308 (0.917)	DT 1.268 (0.879)	loss 6.463 (6.358)	prob 1.772 (2.048)	GS 30.391 (33.064)	mem 72.505
Train: [97][50/1500]	BT 4.539 (0.836)	DT 4.499 (0.794)	loss 6.418 (6.367)	prob 1.914 (2.011)	GS 33.625 (32.861)	mem 72.513
Train: [97][60/1500]	BT 0.037 (0.777)	DT 0.000 (0.735)	loss 6.479 (6.450)	prob 1.980 (2.030)	GS 31.281 (33.094)	mem 72.516
Train: [97][70/1500]	BT 0.038 (0.671)	DT 0.000 (0.630)	loss 6.448 (6.465)	prob 2.064 (1.980)	GS 36.078 (33.146)	mem 72.516
Train: [97][80/1500]	BT 0.052 (0.612)	DT 0.014 (0.571)	loss 6.407 (6.453)	prob 2.100 (1.948)	GS 31.922 (32.661)	mem 72.517
Train: [97][90/1500]	BT 0.033 (0.585)	DT 0.000 (0.544)	loss 6.400 (6.440)	prob 1.947 (1.927)	GS 33.141 (32.738)	mem 72.519
Train: [97][100/1500]	BT 0.067 (0.599)	DT 0.011 (0.557)	loss 6.481 (6.434)	prob 1.614 (1.927)	GS 32.406 (32.682)	mem 72.526
Train: [97][110/1500]	BT 0.038 (0.565)	DT 0.000 (0.523)	loss 6.410 (6.411)	prob 2.162 (1.881)	GS 31.906 (32.542)	mem 72.526
Train: [97][120/1500]	BT 0.038 (0.528)	DT 0.001 (0.487)	loss 6.397 (6.427)	prob 1.820 (1.864)	GS 31.250 (33.444)	mem 72.528
Train: [97][130/1500]	BT 0.049 (0.554)	DT 0.007 (0.513)	loss 6.529 (6.440)	prob 1.790 (1.891)	GS 34.531 (33.595)	mem 72.532
Train: [97][140/1500]	BT 0.055 (0.517)	DT 0.010 (0.477)	loss 6.442 (6.442)	prob 2.007 (1.962)	GS 33.516 (33.277)	mem 72.532
Train: [97][150/1500]	BT 0.068 (0.506)	DT 0.011 (0.465)	loss 6.382 (6.445)	prob 2.187 (1.970)	GS 32.750 (33.058)	mem 72.540
Train: [97][160/1500]	BT 0.023 (0.510)	DT 0.000 (0.469)	loss 6.425 (6.486)	prob 2.034 (1.865)	GS 32.188 (34.467)	mem 72.569
Train: [97][170/1500]	BT 0.052 (0.481)	DT 0.021 (0.441)	loss 6.432 (6.458)	prob 1.889 (1.937)	GS 36.484 (33.572)	mem 72.570
Train: [97][180/1500]	BT 0.079 (0.482)	DT 0.003 (0.442)	loss 6.481 (6.461)	prob 2.092 (1.970)	GS 30.969 (33.341)	mem 72.577
Train: [97][190/1500]	BT 0.031 (0.460)	DT 0.000 (0.419)	loss 6.418 (6.448)	prob 2.328 (2.007)	GS 38.234 (33.219)	mem 72.577
Train: [97][200/1500]	BT 0.060 (0.440)	DT 0.016 (0.398)	loss 6.377 (6.441)	prob 2.154 (2.022)	GS 38.266 (33.182)	mem 72.578
Train: [97][210/1500]	BT 0.039 (0.443)	DT 0.001 (0.402)	loss 6.537 (6.444)	prob 1.920 (2.028)	GS 34.891 (34.241)	mem 72.581
Train: [97][220/1500]	BT 0.039 (0.425)	DT 0.001 (0.384)	loss 6.435 (6.441)	prob 2.122 (2.081)	GS 32.844 (33.291)	mem 72.581
Train: [97][230/1500]	BT 0.039 (0.423)	DT 0.001 (0.382)	loss 6.451 (6.456)	prob 2.068 (2.053)	GS 33.109 (33.559)	mem 72.581
Train: [97][240/1500]	BT 0.039 (0.407)	DT 0.001 (0.367)	loss 6.399 (6.458)	prob 2.286 (2.064)	GS 35.938 (33.755)	mem 72.582
Train: [97][250/1500]	BT 0.039 (0.393)	DT 0.001 (0.352)	loss 6.409 (6.453)	prob 2.463 (2.105)	GS 32.469 (33.489)	mem 72.582
Train: [97][260/1500]	BT 0.081 (0.408)	DT 0.005 (0.366)	loss 6.354 (6.405)	prob 2.191 (2.327)	GS 35.156 (32.952)	mem 72.581
Train: [97][270/1500]	BT 0.060 (0.399)	DT 0.001 (0.357)	loss 6.574 (6.431)	prob 2.496 (2.349)	GS 34.703 (33.215)	mem 72.583
Train: [97][280/1500]	BT 0.031 (0.412)	DT 0.000 (0.370)	loss 6.533 (6.454)	prob 2.279 (2.371)	GS 33.547 (33.126)	mem 72.585
Train: [97][290/1500]	BT 0.057 (0.400)	DT 0.011 (0.357)	loss 6.445 (6.459)	prob 2.487 (2.386)	GS 35.453 (32.954)	mem 72.585
Train: [97][300/1500]	BT 0.029 (0.432)	DT 0.000 (0.390)	loss 6.535 (6.470)	prob 2.700 (2.400)	GS 35.062 (33.135)	mem 72.588
Train: [97][310/1500]	BT 0.026 (0.419)	DT 0.000 (0.377)	loss 6.493 (6.570)	prob 2.641 (2.446)	GS 33.922 (34.737)	mem 72.588
Train: [97][320/1500]	BT 0.039 (0.416)	DT 0.001 (0.374)	loss 6.389 (6.531)	prob 2.478 (2.457)	GS 29.578 (33.062)	mem 72.588
Train: [97][330/1500]	BT 0.039 (0.404)	DT 0.001 (0.363)	loss 6.518 (6.508)	prob 2.413 (2.496)	GS 29.094 (32.557)	mem 72.588
Train: [97][340/1500]	BT 0.040 (0.394)	DT 0.001 (0.352)	loss 6.496 (6.505)	prob 2.708 (2.523)	GS 35.281 (32.606)	mem 72.589
Train: [97][350/1500]	BT 0.039 (0.391)	DT 0.001 (0.350)	loss 6.496 (6.502)	prob 2.781 (2.547)	GS 30.594 (32.528)	mem 72.589
Train: [97][360/1500]	BT 0.039 (0.384)	DT 0.001 (0.343)	loss 6.455 (6.476)	prob 2.687 (2.743)	GS 28.359 (32.158)	mem 72.590
Train: [97][370/1500]	BT 0.069 (0.392)	DT 0.003 (0.350)	loss 6.530 (6.500)	prob 2.447 (2.703)	GS 30.547 (32.380)	mem 72.590
Train: [97][380/1500]	BT 0.027 (0.392)	DT 0.000 (0.351)	loss 6.505 (6.527)	prob 2.654 (2.669)	GS 33.422 (32.972)	mem 72.591
Train: [97][390/1500]	BT 0.037 (0.386)	DT 0.001 (0.345)	loss 6.662 (6.530)	prob 2.447 (2.665)	GS 35.375 (33.132)	mem 72.591
Train: [97][400/1500]	BT 0.063 (0.383)	DT 0.006 (0.342)	loss 6.687 (6.538)	prob 2.284 (2.664)	GS 33.625 (33.197)	mem 72.592
Train: [97][410/1500]	BT 0.039 (0.375)	DT 0.001 (0.333)	loss 6.555 (6.590)	prob 2.464 (2.524)	GS 35.469 (33.798)	mem 72.593
Train: [97][420/1500]	BT 0.057 (0.384)	DT 0.014 (0.342)	loss 6.592 (6.599)	prob 2.541 (2.501)	GS 33.828 (34.090)	mem 72.595
Train: [97][430/1500]	BT 0.051 (0.381)	DT 0.000 (0.339)	loss 6.583 (6.601)	prob 2.627 (2.543)	GS 34.750 (33.669)	mem 72.596
Train: [97][440/1500]	BT 0.039 (0.385)	DT 0.001 (0.343)	loss 6.558 (6.599)	prob 2.432 (2.541)	GS 35.375 (33.712)	mem 72.596
Train: [97][450/1500]	BT 0.035 (0.383)	DT 0.000 (0.342)	loss 6.646 (6.596)	prob 2.316 (2.547)	GS 36.109 (33.474)	mem 72.597
Train: [97][460/1500]	BT 0.064 (0.376)	DT 0.014 (0.334)	loss 6.638 (6.702)	prob 2.273 (2.282)	GS 33.438 (34.169)	mem 72.599
Train: [97][470/1500]	BT 0.038 (0.386)	DT 0.000 (0.344)	loss 6.682 (6.680)	prob 2.559 (2.379)	GS 34.781 (33.699)	mem 72.601
Train: [97][480/1500]	BT 0.038 (0.379)	DT 0.001 (0.337)	loss 6.614 (6.664)	prob 2.703 (2.390)	GS 36.625 (33.377)	mem 72.601
Train: [97][490/1500]	BT 0.051 (0.382)	DT 0.004 (0.340)	loss 6.617 (6.650)	prob 2.425 (2.416)	GS 35.281 (33.529)	mem 72.602
Train: [97][500/1500]	BT 0.034 (0.382)	DT 0.001 (0.341)	loss 6.537 (6.637)	prob 2.612 (2.457)	GS 35.047 (33.289)	mem 72.603
Train: [97][510/1500]	BT 0.030 (0.392)	DT 0.000 (0.351)	loss 6.636 (6.614)	prob 2.316 (2.404)	GS 34.875 (32.458)	mem 72.603
Train: [97][520/1500]	BT 0.032 (0.385)	DT 0.000 (0.344)	loss 6.587 (6.597)	prob 2.379 (2.415)	GS 35.297 (33.031)	mem 72.602
Train: [97][530/1500]	BT 4.420 (0.387)	DT 4.380 (0.346)	loss 6.700 (6.603)	prob 2.311 (2.404)	GS 38.453 (33.355)	mem 72.602
Train: [97][540/1500]	BT 0.034 (0.380)	DT 0.001 (0.339)	loss 6.516 (6.598)	prob 2.314 (2.391)	GS 36.609 (33.218)	mem 72.604
Train: [97][550/1500]	BT 0.034 (0.374)	DT 0.001 (0.333)	loss 6.631 (6.594)	prob 2.162 (2.394)	GS 31.609 (33.118)	mem 72.603
Train: [97][560/1500]	BT 0.034 (0.380)	DT 0.000 (0.339)	loss 6.583 (6.581)	prob 2.233 (2.233)	GS 28.750 (32.977)	mem 72.603
Train: [97][570/1500]	BT 0.035 (0.374)	DT 0.000 (0.334)	loss 6.544 (6.613)	prob 2.297 (2.192)	GS 33.641 (32.855)	mem 72.605
Train: [97][580/1500]	BT 0.056 (0.376)	DT 0.001 (0.336)	loss 6.720 (6.629)	prob 2.009 (2.163)	GS 36.312 (32.957)	mem 72.607
Train: [97][590/1500]	BT 0.056 (0.371)	DT 0.000 (0.330)	loss 6.589 (6.631)	prob 2.390 (2.178)	GS 34.375 (33.105)	mem 72.607
Train: [97][600/1500]	BT 0.037 (0.368)	DT 0.001 (0.327)	loss 6.729 (6.640)	prob 2.089 (2.169)	GS 33.000 (33.016)	mem 72.607
Train: [97][610/1500]	BT 0.038 (0.366)	DT 0.001 (0.325)	loss 6.606 (6.646)	prob 2.192 (2.134)	GS 28.453 (33.027)	mem 72.614
Train: [97][620/1500]	BT 0.034 (0.369)	DT 0.000 (0.329)	loss 6.716 (6.644)	prob 1.879 (2.065)	GS 32.594 (33.110)	mem 72.617
Train: [97][630/1500]	BT 0.037 (0.367)	DT 0.001 (0.326)	loss 6.612 (6.645)	prob 2.205 (2.058)	GS 39.688 (33.183)	mem 72.617
Train: [97][640/1500]	BT 0.060 (0.364)	DT 0.009 (0.323)	loss 6.615 (6.645)	prob 2.044 (2.073)	GS 33.797 (32.946)	mem 72.620
Train: [97][650/1500]	BT 1.444 (0.364)	DT 1.407 (0.324)	loss 6.766 (6.660)	prob 2.003 (2.054)	GS 32.812 (33.062)	mem 72.628
Train: [97][660/1500]	BT 0.038 (0.360)	DT 0.001 (0.319)	loss 6.587 (6.675)	prob 1.970 (1.999)	GS 33.750 (32.184)	mem 72.628
Train: [97][670/1500]	BT 0.037 (0.358)	DT 0.000 (0.318)	loss 6.614 (6.655)	prob 1.846 (1.988)	GS 29.953 (31.740)	mem 72.623
Train: [97][680/1500]	BT 0.041 (0.357)	DT 0.001 (0.316)	loss 6.590 (6.637)	prob 1.700 (1.934)	GS 32.297 (31.938)	mem 72.530
Train: [97][690/1500]	BT 0.037 (0.356)	DT 0.000 (0.315)	loss 6.570 (6.622)	prob 2.066 (1.898)	GS 32.062 (31.661)	mem 72.529
Train: [97][700/1500]	BT 0.037 (0.352)	DT 0.000 (0.312)	loss 6.571 (6.612)	prob 2.041 (1.889)	GS 33.891 (31.739)	mem 72.531
Train: [97][710/1500]	BT 0.040 (0.348)	DT 0.001 (0.307)	loss 6.558 (6.548)	prob 1.908 (1.948)	GS 34.609 (32.348)	mem 72.530
Train: [97][720/1500]	BT 0.029 (0.353)	DT 0.000 (0.313)	loss 6.626 (6.574)	prob 1.889 (1.883)	GS 34.047 (32.670)	mem 72.528
Train: [97][730/1500]	BT 0.025 (0.349)	DT 0.000 (0.309)	loss 6.650 (6.590)	prob 1.679 (1.848)	GS 32.734 (32.693)	mem 72.529
Train: [97][740/1500]	BT 0.064 (0.349)	DT 0.005 (0.309)	loss 6.782 (6.624)	prob 1.465 (1.789)	GS 34.719 (32.791)	mem 72.532
Train: [97][750/1500]	BT 0.062 (0.345)	DT 0.002 (0.305)	loss 6.656 (6.631)	prob 1.846 (1.798)	GS 31.609 (32.543)	mem 72.532
Train: [97][760/1500]	BT 0.058 (0.341)	DT 0.011 (0.301)	loss 6.592 (6.619)	prob 1.744 (1.804)	GS 36.172 (32.320)	mem 72.532
Train: [97][770/1500]	BT 0.037 (0.343)	DT 0.001 (0.303)	loss 6.621 (6.600)	prob 1.857 (1.848)	GS 34.484 (32.058)	mem 72.553
Train: [97][780/1500]	BT 0.038 (0.339)	DT 0.001 (0.299)	loss 6.747 (6.604)	prob 1.648 (1.829)	GS 32.875 (32.067)	mem 72.553
Train: [97][790/1500]	BT 0.039 (0.339)	DT 0.001 (0.299)	loss 6.561 (6.612)	prob 1.975 (1.865)	GS 35.719 (31.941)	mem 72.553
Train: [97][800/1500]	BT 0.045 (0.338)	DT 0.005 (0.298)	loss 6.589 (6.605)	prob 1.920 (1.883)	GS 37.531 (32.107)	mem 72.555
Train: [97][810/1500]	BT 0.039 (0.336)	DT 0.001 (0.297)	loss 6.515 (6.575)	prob 2.162 (2.034)	GS 36.531 (32.195)	mem 72.544
Train: [97][820/1500]	BT 0.038 (0.333)	DT 0.001 (0.293)	loss 6.584 (6.580)	prob 2.030 (1.990)	GS 34.031 (32.105)	mem 72.545
Train: [97][830/1500]	BT 0.039 (0.331)	DT 0.001 (0.291)	loss 6.570 (6.597)	prob 1.771 (1.952)	GS 36.719 (32.033)	mem 72.545
Train: [97][840/1500]	BT 0.039 (0.331)	DT 0.001 (0.291)	loss 6.691 (6.606)	prob 1.949 (1.943)	GS 32.766 (31.878)	mem 72.548
Train: [97][850/1500]	BT 0.038 (0.330)	DT 0.001 (0.290)	loss 6.723 (6.616)	prob 1.857 (1.955)	GS 28.297 (32.097)	mem 72.548
Train: [97][860/1500]	BT 0.039 (0.328)	DT 0.001 (0.289)	loss 6.667 (6.684)	prob 2.063 (1.974)	GS 30.578 (32.188)	mem 72.549
Train: [97][870/1500]	BT 0.039 (0.325)	DT 0.001 (0.285)	loss 6.770 (6.681)	prob 1.904 (1.990)	GS 32.578 (31.975)	mem 72.550
Train: [97][880/1500]	BT 0.039 (0.325)	DT 0.001 (0.285)	loss 6.687 (6.683)	prob 1.921 (1.964)	GS 36.844 (32.443)	mem 72.549
Train: [97][890/1500]	BT 0.040 (0.325)	DT 0.001 (0.285)	loss 6.614 (6.677)	prob 1.978 (1.965)	GS 32.156 (32.328)	mem 72.549
Train: [97][900/1500]	BT 0.041 (0.323)	DT 0.003 (0.283)	loss 6.643 (6.677)	prob 1.867 (1.950)	GS 29.625 (31.973)	mem 72.548
Train: [97][910/1500]	BT 0.033 (0.324)	DT 0.000 (0.285)	loss 6.665 (6.654)	prob 2.024 (2.003)	GS 37.766 (32.148)	mem 72.567
Train: [97][920/1500]	BT 0.717 (0.322)	DT 0.666 (0.282)	loss 6.680 (6.664)	prob 1.752 (1.927)	GS 33.953 (31.615)	mem 72.567
Train: [97][930/1500]	BT 0.045 (0.326)	DT 0.013 (0.286)	loss 6.699 (6.664)	prob 1.920 (1.932)	GS 29.672 (31.467)	mem 72.567
Train: [97][940/1500]	BT 0.038 (0.323)	DT 0.003 (0.283)	loss 6.691 (6.661)	prob 2.096 (1.934)	GS 27.219 (31.875)	mem 72.566
Train: [97][950/1500]	BT 0.023 (0.330)	DT 0.000 (0.290)	loss 6.740 (6.689)	prob 1.795 (1.902)	GS 31.703 (32.132)	mem 72.565
Train: [97][960/1500]	BT 0.030 (0.327)	DT 0.000 (0.287)	loss 6.759 (6.688)	prob 1.724 (1.915)	GS 32.750 (31.039)	mem 72.567
Train: [97][970/1500]	BT 0.030 (0.328)	DT 0.000 (0.289)	loss 6.716 (6.705)	prob 1.805 (1.825)	GS 38.250 (32.395)	mem 72.572
Train: [97][980/1500]	BT 0.051 (0.325)	DT 0.013 (0.286)	loss 6.750 (6.716)	prob 1.808 (1.829)	GS 32.250 (32.859)	mem 72.571
Train: [97][990/1500]	BT 0.038 (0.322)	DT 0.000 (0.283)	loss 6.691 (6.714)	prob 1.591 (1.785)	GS 34.891 (32.834)	mem 72.573
Train: [97][1000/1500]	BT 0.037 (0.323)	DT 0.001 (0.284)	loss 6.665 (6.711)	prob 1.578 (1.752)	GS 34.422 (32.910)	mem 72.574
Train: [97][1010/1500]	BT 0.038 (0.320)	DT 0.001 (0.281)	loss 6.744 (6.711)	prob 1.423 (1.516)	GS 34.875 (33.255)	mem 72.573
Train: [97][1020/1500]	BT 0.037 (0.320)	DT 0.000 (0.281)	loss 6.729 (6.735)	prob 1.502 (1.483)	GS 37.719 (32.945)	mem 72.572
Train: [97][1030/1500]	BT 0.038 (0.317)	DT 0.001 (0.278)	loss 6.677 (6.720)	prob 1.601 (1.499)	GS 31.875 (32.226)	mem 72.573
Train: [97][1040/1500]	BT 0.038 (0.315)	DT 0.001 (0.275)	loss 6.701 (6.709)	prob 1.482 (1.504)	GS 37.891 (32.490)	mem 72.573
Train: [97][1050/1500]	BT 0.036 (0.316)	DT 0.000 (0.276)	loss 6.682 (6.710)	prob 1.708 (1.513)	GS 35.453 (32.491)	mem 72.575
Train: [97][1060/1500]	BT 0.038 (0.314)	DT 0.000 (0.275)	loss 6.688 (6.757)	prob 1.606 (1.576)	GS 30.016 (32.139)	mem 72.577
Train: [97][1070/1500]	BT 0.038 (0.313)	DT 0.001 (0.274)	loss 6.687 (6.725)	prob 1.556 (1.602)	GS 36.344 (32.210)	mem 72.576
Train: [97][1080/1500]	BT 0.037 (0.313)	DT 0.001 (0.273)	loss 6.735 (6.711)	prob 1.280 (1.577)	GS 31.203 (32.089)	mem 72.576
Train: [97][1090/1500]	BT 0.038 (0.311)	DT 0.001 (0.272)	loss 6.723 (6.720)	prob 1.574 (1.563)	GS 35.578 (32.120)	mem 72.577
Train: [97][1100/1500]	BT 0.039 (0.312)	DT 0.001 (0.272)	loss 6.717 (6.729)	prob 1.547 (1.561)	GS 33.625 (32.125)	mem 72.579
Train: [97][1110/1500]	BT 0.037 (0.309)	DT 0.000 (0.270)	loss 6.764 (6.761)	prob 1.690 (1.558)	GS 29.969 (31.928)	mem 72.582
Train: [97][1120/1500]	BT 0.098 (0.311)	DT 0.011 (0.272)	loss 6.763 (6.755)	prob 1.579 (1.546)	GS 30.891 (32.264)	mem 72.584
Train: [97][1130/1500]	BT 0.038 (0.310)	DT 0.001 (0.271)	loss 6.844 (6.781)	prob 1.502 (1.530)	GS 31.422 (32.272)	mem 72.584
Train: [97][1140/1500]	BT 0.038 (0.310)	DT 0.001 (0.271)	loss 6.908 (6.801)	prob 1.497 (1.537)	GS 34.969 (32.485)	mem 72.584
Train: [97][1150/1500]	BT 0.037 (0.309)	DT 0.001 (0.270)	loss 6.842 (6.804)	prob 1.495 (1.565)	GS 30.672 (32.377)	mem 72.585
Train: [97][1160/1500]	BT 0.038 (0.307)	DT 0.001 (0.267)	loss 6.888 (6.833)	prob 1.554 (1.617)	GS 34.406 (33.497)	mem 72.585
Train: [97][1170/1500]	BT 0.038 (0.311)	DT 0.003 (0.272)	loss 6.816 (6.807)	prob 1.672 (1.626)	GS 31.828 (32.857)	mem 72.586
Train: [97][1180/1500]	BT 0.067 (0.309)	DT 0.011 (0.269)	loss 6.791 (6.810)	prob 1.742 (1.621)	GS 36.438 (33.273)	mem 72.588
Train: [97][1190/1500]	BT 0.034 (0.314)	DT 0.000 (0.274)	loss 6.712 (6.800)	prob 1.929 (1.647)	GS 32.438 (33.350)	mem 72.586
Train: [97][1200/1500]	BT 0.028 (0.320)	DT 0.000 (0.280)	loss 6.888 (6.803)	prob 1.856 (1.654)	GS 32.656 (33.479)	mem 72.589
Train: [97][1210/1500]	BT 0.036 (0.318)	DT 0.000 (0.278)	loss 6.740 (6.801)	prob 1.732 (1.690)	GS 33.328 (32.617)	mem 72.589
Train: [97][1220/1500]	BT 0.054 (0.318)	DT 0.001 (0.279)	loss 6.867 (6.848)	prob 1.596 (1.611)	GS 30.469 (32.957)	mem 72.591
Train: [97][1230/1500]	BT 0.040 (0.316)	DT 0.001 (0.277)	loss 6.744 (6.837)	prob 1.614 (1.621)	GS 34.406 (32.880)	mem 72.590
Train: [97][1240/1500]	BT 0.027 (0.317)	DT 0.000 (0.278)	loss 6.857 (6.834)	prob 1.616 (1.629)	GS 33.141 (32.875)	mem 72.591
Train: [97][1250/1500]	BT 0.032 (0.315)	DT 0.001 (0.275)	loss 6.906 (6.840)	prob 1.521 (1.623)	GS 32.672 (32.871)	mem 72.594
Train: [97][1260/1500]	BT 0.025 (0.312)	DT 0.000 (0.273)	loss 6.924 (6.861)	prob 1.547 (1.618)	GS 33.688 (32.317)	mem 72.594
Train: [97][1270/1500]	BT 0.031 (0.314)	DT 0.000 (0.275)	loss 6.938 (6.863)	prob 1.360 (1.577)	GS 34.188 (32.084)	mem 72.621
Train: [97][1280/1500]	BT 0.027 (0.312)	DT 0.000 (0.273)	loss 6.886 (6.870)	prob 1.503 (1.550)	GS 35.812 (32.430)	mem 72.622
Train: [97][1290/1500]	BT 0.028 (0.313)	DT 0.000 (0.274)	loss 6.954 (6.868)	prob 1.489 (1.539)	GS 29.016 (32.388)	mem 72.623
Train: [97][1300/1500]	BT 0.031 (0.311)	DT 0.000 (0.272)	loss 6.891 (6.871)	prob 1.634 (1.535)	GS 33.203 (32.535)	mem 72.623
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [97][1310/1500]	BT 0.040 (0.309)	DT 0.001 (0.270)	loss 6.862 (6.872)	prob 1.371 (1.532)	GS 33.297 (31.055)	mem 72.624
Train: [97][1320/1500]	BT 0.039 (0.309)	DT 0.001 (0.271)	loss 6.866 (6.879)	prob 1.450 (1.490)	GS 34.047 (31.705)	mem 72.624
Train: [97][1330/1500]	BT 0.039 (0.307)	DT 0.001 (0.269)	loss 6.775 (6.871)	prob 1.709 (1.509)	GS 32.531 (31.981)	mem 72.624
Train: [97][1340/1500]	BT 0.072 (0.308)	DT 0.006 (0.270)	loss 6.821 (6.857)	prob 1.522 (1.536)	GS 32.969 (32.155)	mem 72.622
Train: [97][1350/1500]	BT 0.066 (0.307)	DT 0.001 (0.268)	loss 6.777 (6.854)	prob 1.647 (1.530)	GS 35.625 (32.303)	mem 72.621
Train: [97][1360/1500]	BT 0.039 (0.309)	DT 0.001 (0.270)	loss 6.804 (6.834)	prob 1.532 (1.499)	GS 36.422 (33.212)	mem 72.621
Train: [97][1370/1500]	BT 0.039 (0.307)	DT 0.001 (0.268)	loss 7.024 (6.880)	prob 1.294 (1.439)	GS 34.406 (33.046)	mem 72.621
Train: [97][1380/1500]	BT 0.039 (0.305)	DT 0.001 (0.266)	loss 6.921 (6.881)	prob 1.615 (1.492)	GS 32.812 (32.922)	mem 72.620
Train: [97][1390/1500]	BT 0.039 (0.305)	DT 0.001 (0.266)	loss 6.798 (6.867)	prob 1.600 (1.538)	GS 35.484 (32.980)	mem 72.619
Train: [97][1400/1500]	BT 0.084 (0.305)	DT 0.006 (0.265)	loss 6.886 (6.867)	prob 1.559 (1.549)	GS 35.750 (33.098)	mem 72.619
Train: [97][1410/1500]	BT 0.039 (0.306)	DT 0.000 (0.267)	loss 6.849 (6.870)	prob 1.463 (1.468)	GS 34.891 (33.848)	mem 72.621
Train: [97][1420/1500]	BT 0.039 (0.307)	DT 0.000 (0.267)	loss 6.798 (6.907)	prob 1.779 (1.465)	GS 34.719 (33.566)	mem 72.622
Train: [97][1430/1500]	BT 0.039 (0.305)	DT 0.001 (0.266)	loss 6.928 (6.905)	prob 1.325 (1.468)	GS 36.359 (33.240)	mem 72.622
Train: [97][1440/1500]	BT 0.060 (0.306)	DT 0.004 (0.266)	loss 6.994 (6.931)	prob 1.528 (1.485)	GS 34.078 (33.068)	mem 72.622
Train: [97][1450/1500]	BT 0.036 (0.307)	DT 0.001 (0.268)	loss 6.929 (6.934)	prob 1.564 (1.504)	GS 36.062 (33.080)	mem 72.622
Train: [97][1460/1500]	BT 0.035 (0.306)	DT 0.001 (0.267)	loss 6.861 (6.853)	prob 1.588 (1.682)	GS 36.797 (31.409)	mem 72.550
Train: [97][1470/1500]	BT 0.037 (0.306)	DT 0.001 (0.267)	loss 6.910 (6.861)	prob 1.522 (1.642)	GS 34.531 (32.588)	mem 38.530
Train: [97][1480/1500]	BT 0.030 (0.304)	DT 0.000 (0.265)	loss 6.955 (6.909)	prob 1.641 (1.599)	GS 33.766 (32.723)	mem 35.644
Train: [97][1490/1500]	BT 0.020 (0.302)	DT 0.000 (0.263)	loss 6.949 (6.919)	prob 1.652 (1.576)	GS 39.344 (32.742)	mem 24.552
Train: [97][1500/1500]	BT 0.024 (0.301)	DT 0.000 (0.262)	loss 6.945 (6.917)	prob 1.583 (1.570)	GS 32.000 (32.786)	mem 10.319
Train: [97][1510/1500]	BT 0.018 (0.299)	DT 0.000 (0.260)	loss 6.792 (6.934)	prob 1.637 (1.447)	GS 31.688 (32.528)	mem 7.506
epoch 97, total time 452.27
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [98][1/1500]	BT 22.243 (22.243)	DT 22.191 (22.191)	loss 6.781 (6.781)	prob 1.605 (1.605)	GS 26.422 (26.422)	mem 71.233
Train: [98][10/1500]	BT 0.036 (2.252)	DT 0.000 (2.220)	loss 6.700 (6.754)	prob 1.663 (1.633)	GS 34.234 (33.161)	mem 71.242
Train: [98][20/1500]	BT 0.037 (1.145)	DT 0.000 (1.111)	loss 6.884 (6.759)	prob 1.528 (1.643)	GS 30.438 (32.250)	mem 71.242
Train: [98][30/1500]	BT 0.037 (0.865)	DT 0.000 (0.830)	loss 6.787 (6.793)	prob 1.798 (1.639)	GS 26.812 (32.395)	mem 71.265
Train: [98][40/1500]	BT 0.038 (0.659)	DT 0.001 (0.623)	loss 6.891 (6.807)	prob 1.706 (1.650)	GS 32.203 (32.234)	mem 71.268
Train: [98][50/1500]	BT 0.040 (0.598)	DT 0.000 (0.564)	loss 6.899 (6.822)	prob 1.767 (1.651)	GS 32.141 (31.896)	mem 71.305
Train: [98][60/1500]	BT 0.038 (0.531)	DT 0.001 (0.497)	loss 6.919 (6.874)	prob 1.619 (1.710)	GS 34.172 (33.250)	mem 71.357
Train: [98][70/1500]	BT 0.037 (0.489)	DT 0.000 (0.454)	loss 6.894 (6.863)	prob 1.645 (1.707)	GS 34.578 (32.423)	mem 71.657
Train: [98][80/1500]	BT 0.030 (0.555)	DT 0.000 (0.520)	loss 6.940 (6.882)	prob 1.607 (1.666)	GS 31.031 (32.903)	mem 72.337
Train: [98][90/1500]	BT 0.038 (0.506)	DT 0.001 (0.471)	loss 7.020 (6.908)	prob 1.554 (1.641)	GS 34.672 (33.536)	mem 72.439
Train: [98][100/1500]	BT 0.038 (0.487)	DT 0.001 (0.452)	loss 6.979 (6.926)	prob 1.581 (1.628)	GS 28.375 (32.850)	mem 72.494
Train: [98][110/1500]	BT 0.032 (0.446)	DT 0.000 (0.411)	loss 6.858 (6.929)	prob 1.667 (1.557)	GS 33.312 (31.137)	mem 72.497
Train: [98][120/1500]	BT 0.063 (0.417)	DT 0.010 (0.381)	loss 6.902 (6.942)	prob 1.611 (1.546)	GS 31.109 (31.790)	mem 72.501
Train: [98][130/1500]	BT 0.054 (0.452)	DT 0.016 (0.416)	loss 7.030 (6.945)	prob 1.283 (1.532)	GS 31.438 (32.032)	mem 72.502
Train: [98][140/1500]	BT 0.056 (0.428)	DT 0.005 (0.391)	loss 6.953 (6.954)	prob 1.364 (1.507)	GS 31.938 (32.254)	mem 72.502
Train: [98][150/1500]	BT 0.051 (0.432)	DT 0.003 (0.394)	loss 7.084 (6.972)	prob 1.190 (1.469)	GS 35.031 (32.470)	mem 72.507
Train: [98][160/1500]	BT 0.049 (0.409)	DT 0.002 (0.370)	loss 7.010 (7.047)	prob 1.353 (1.346)	GS 38.109 (32.244)	mem 72.507
Train: [98][170/1500]	BT 0.052 (0.402)	DT 0.002 (0.362)	loss 7.061 (7.066)	prob 1.526 (1.353)	GS 36.078 (33.496)	mem 72.506
Train: [98][180/1500]	BT 0.064 (0.407)	DT 0.020 (0.368)	loss 7.085 (7.057)	prob 1.542 (1.404)	GS 35.531 (33.415)	mem 72.507
Train: [98][190/1500]	BT 0.030 (0.487)	DT 0.000 (0.447)	loss 7.059 (7.051)	prob 1.296 (1.418)	GS 28.297 (33.240)	mem 72.514
Train: [98][200/1500]	BT 0.031 (0.464)	DT 0.000 (0.425)	loss 6.996 (7.036)	prob 1.410 (1.418)	GS 36.578 (32.960)	mem 72.515
Train: [98][210/1500]	BT 0.033 (0.443)	DT 0.001 (0.405)	loss 6.992 (6.978)	prob 1.349 (1.380)	GS 33.469 (34.319)	mem 72.515
Train: [98][220/1500]	BT 0.035 (0.437)	DT 0.000 (0.399)	loss 6.996 (6.981)	prob 1.402 (1.403)	GS 36.906 (33.663)	mem 72.516
Train: [98][230/1500]	BT 0.030 (0.419)	DT 0.000 (0.381)	loss 6.943 (6.987)	prob 1.384 (1.401)	GS 37.625 (33.594)	mem 72.515
Train: [98][240/1500]	BT 0.031 (0.454)	DT 0.000 (0.416)	loss 7.130 (7.001)	prob 1.303 (1.394)	GS 31.469 (33.418)	mem 72.516
Train: [98][250/1500]	BT 0.036 (0.438)	DT 0.000 (0.400)	loss 6.978 (7.006)	prob 1.534 (1.399)	GS 36.625 (33.005)	mem 72.520
Train: [98][260/1500]	BT 0.669 (0.425)	DT 0.630 (0.387)	loss 6.986 (7.012)	prob 1.417 (1.423)	GS 35.922 (33.052)	mem 72.522
Train: [98][270/1500]	BT 0.044 (0.422)	DT 0.000 (0.384)	loss 7.012 (7.021)	prob 1.319 (1.368)	GS 34.062 (32.509)	mem 72.526
Train: [98][280/1500]	BT 0.053 (0.410)	DT 0.016 (0.371)	loss 7.006 (7.009)	prob 1.507 (1.394)	GS 33.094 (32.272)	mem 72.527
Train: [98][290/1500]	BT 0.037 (0.411)	DT 0.000 (0.372)	loss 6.940 (7.000)	prob 1.506 (1.417)	GS 28.266 (32.091)	mem 72.540
Train: [98][300/1500]	BT 5.777 (0.418)	DT 5.730 (0.379)	loss 7.027 (6.993)	prob 1.447 (1.445)	GS 40.000 (32.122)	mem 72.541
Train: [98][310/1500]	BT 0.038 (0.418)	DT 0.000 (0.379)	loss 6.970 (6.984)	prob 1.388 (1.478)	GS 31.531 (32.647)	mem 72.547
Train: [98][320/1500]	BT 0.037 (0.406)	DT 0.001 (0.367)	loss 7.157 (7.022)	prob 1.200 (1.465)	GS 35.172 (33.348)	mem 72.547
Train: [98][330/1500]	BT 0.052 (0.405)	DT 0.006 (0.366)	loss 7.118 (7.048)	prob 1.428 (1.465)	GS 31.781 (33.364)	mem 72.548
Train: [98][340/1500]	BT 0.065 (0.395)	DT 0.011 (0.356)	loss 7.019 (7.062)	prob 1.602 (1.473)	GS 29.156 (32.952)	mem 72.548
Train: [98][350/1500]	BT 0.037 (0.397)	DT 0.000 (0.358)	loss 7.073 (7.071)	prob 1.595 (1.485)	GS 32.453 (33.134)	mem 72.549
Train: [98][360/1500]	BT 0.027 (0.393)	DT 0.000 (0.354)	loss 7.049 (7.094)	prob 1.603 (1.594)	GS 39.422 (33.136)	mem 72.551
Train: [98][370/1500]	BT 0.038 (0.388)	DT 0.000 (0.349)	loss 7.158 (7.082)	prob 1.464 (1.626)	GS 32.703 (32.564)	mem 72.552
Train: [98][380/1500]	BT 0.047 (0.381)	DT 0.010 (0.342)	loss 7.008 (7.080)	prob 1.655 (1.615)	GS 34.141 (32.367)	mem 72.552
Train: [98][390/1500]	BT 0.038 (0.373)	DT 0.000 (0.334)	loss 6.981 (7.067)	prob 1.734 (1.629)	GS 34.078 (32.616)	mem 72.553
Train: [98][400/1500]	BT 0.060 (0.376)	DT 0.002 (0.337)	loss 7.081 (7.066)	prob 1.623 (1.641)	GS 35.672 (32.820)	mem 72.557
Train: [98][410/1500]	BT 0.064 (0.368)	DT 0.005 (0.329)	loss 7.037 (7.067)	prob 1.722 (1.737)	GS 33.875 (32.786)	mem 72.558
Train: [98][420/1500]	BT 1.216 (0.371)	DT 1.180 (0.332)	loss 7.132 (7.083)	prob 1.622 (1.728)	GS 33.531 (32.780)	mem 72.563
Train: [98][430/1500]	BT 0.037 (0.363)	DT 0.000 (0.324)	loss 7.131 (7.093)	prob 1.680 (1.716)	GS 32.719 (32.565)	mem 72.563
Train: [98][440/1500]	BT 0.028 (0.364)	DT 0.001 (0.325)	loss 7.032 (7.095)	prob 1.854 (1.726)	GS 35.078 (32.905)	mem 72.566
Train: [98][450/1500]	BT 0.044 (0.358)	DT 0.001 (0.319)	loss 7.207 (7.117)	prob 1.702 (1.708)	GS 34.125 (33.027)	mem 72.568
Train: [98][460/1500]	BT 0.034 (0.351)	DT 0.000 (0.312)	loss 7.088 (7.146)	prob 1.813 (1.724)	GS 29.234 (30.727)	mem 72.569
Train: [98][470/1500]	BT 0.089 (0.366)	DT 0.009 (0.327)	loss 7.131 (7.119)	prob 1.830 (1.759)	GS 33.406 (31.708)	mem 72.572
Train: [98][480/1500]	BT 0.088 (0.361)	DT 0.002 (0.321)	loss 7.094 (7.125)	prob 1.776 (1.745)	GS 35.766 (31.923)	mem 72.571
Train: [98][490/1500]	BT 0.035 (0.364)	DT 0.000 (0.324)	loss 7.133 (7.123)	prob 1.828 (1.772)	GS 35.578 (32.019)	mem 72.569
Train: [98][500/1500]	BT 0.028 (0.377)	DT 0.000 (0.337)	loss 7.328 (7.148)	prob 1.455 (1.749)	GS 34.281 (32.456)	mem 72.568
Train: [98][510/1500]	BT 0.025 (0.370)	DT 0.000 (0.330)	loss 7.377 (7.345)	prob 1.576 (1.552)	GS 36.094 (34.448)	mem 72.568
Train: [98][520/1500]	BT 0.029 (0.369)	DT 0.000 (0.329)	loss 7.147 (7.274)	prob 1.791 (1.660)	GS 36.172 (33.134)	mem 72.571
Train: [98][530/1500]	BT 0.027 (0.363)	DT 0.000 (0.323)	loss 7.172 (7.248)	prob 1.868 (1.688)	GS 35.516 (33.127)	mem 72.571
Train: [98][540/1500]	BT 0.065 (0.372)	DT 0.002 (0.332)	loss 7.207 (7.232)	prob 1.638 (1.709)	GS 37.438 (33.200)	mem 72.570
Train: [98][550/1500]	BT 0.032 (0.366)	DT 0.000 (0.326)	loss 7.158 (7.224)	prob 1.792 (1.708)	GS 33.609 (33.035)	mem 72.571
Train: [98][560/1500]	BT 0.060 (0.360)	DT 0.003 (0.320)	loss 7.198 (7.187)	prob 1.783 (1.706)	GS 35.094 (33.089)	mem 72.571
Train: [98][570/1500]	BT 0.031 (0.366)	DT 0.000 (0.326)	loss 7.283 (7.199)	prob 1.591 (1.730)	GS 36.766 (32.763)	mem 72.572
Train: [98][580/1500]	BT 0.028 (0.382)	DT 0.001 (0.342)	loss 7.107 (7.186)	prob 1.766 (1.743)	GS 33.594 (32.672)	mem 72.576
Train: [98][590/1500]	BT 0.024 (0.376)	DT 0.000 (0.336)	loss 7.239 (7.195)	prob 1.602 (1.732)	GS 32.641 (32.616)	mem 72.576
Train: [98][600/1500]	BT 0.033 (0.379)	DT 0.000 (0.339)	loss 7.198 (7.204)	prob 1.718 (1.721)	GS 32.719 (32.576)	mem 72.577
Train: [98][610/1500]	BT 0.032 (0.373)	DT 0.001 (0.334)	loss 7.245 (7.247)	prob 1.675 (1.682)	GS 34.094 (33.889)	mem 72.578
Train: [98][620/1500]	BT 0.039 (0.367)	DT 0.000 (0.328)	loss 7.180 (7.244)	prob 1.831 (1.697)	GS 38.969 (33.655)	mem 72.577
Train: [98][630/1500]	BT 0.028 (0.371)	DT 0.000 (0.332)	loss 7.237 (7.244)	prob 1.743 (1.703)	GS 33.484 (33.294)	mem 72.578
Train: [98][640/1500]	BT 0.038 (0.366)	DT 0.000 (0.327)	loss 7.184 (7.234)	prob 1.746 (1.714)	GS 32.672 (33.048)	mem 72.578
Train: [98][650/1500]	BT 0.037 (0.365)	DT 0.000 (0.326)	loss 7.212 (7.233)	prob 1.669 (1.702)	GS 36.859 (33.086)	mem 72.582
Train: [98][660/1500]	BT 0.025 (0.360)	DT 0.000 (0.321)	loss 7.196 (7.229)	prob 1.539 (1.613)	GS 34.812 (33.466)	mem 72.583
Train: [98][670/1500]	BT 0.037 (0.355)	DT 0.000 (0.317)	loss 7.317 (7.257)	prob 1.297 (1.504)	GS 35.953 (32.695)	mem 72.583
Train: [98][680/1500]	BT 0.039 (0.357)	DT 0.000 (0.319)	loss 7.240 (7.265)	prob 1.356 (1.434)	GS 29.781 (32.228)	mem 72.614
Train: [98][690/1500]	BT 0.038 (0.353)	DT 0.001 (0.314)	loss 7.190 (7.257)	prob 1.549 (1.423)	GS 32.781 (32.234)	mem 72.614
Train: [98][700/1500]	BT 0.028 (0.358)	DT 0.000 (0.320)	loss 7.236 (7.249)	prob 1.398 (1.427)	GS 35.219 (32.118)	mem 72.614
Train: [98][710/1500]	BT 0.028 (0.354)	DT 0.000 (0.316)	loss 7.206 (7.221)	prob 1.321 (1.419)	GS 31.859 (32.839)	mem 72.616
Train: [98][720/1500]	BT 0.025 (0.353)	DT 0.000 (0.315)	loss 7.283 (7.239)	prob 1.413 (1.400)	GS 35.703 (32.200)	mem 72.615
Train: [98][730/1500]	BT 0.025 (0.349)	DT 0.000 (0.311)	loss 7.250 (7.248)	prob 1.374 (1.394)	GS 33.609 (32.374)	mem 72.616
Train: [98][740/1500]	BT 0.034 (0.344)	DT 0.001 (0.307)	loss 7.243 (7.244)	prob 1.358 (1.403)	GS 30.984 (32.075)	mem 72.615
Train: [98][750/1500]	BT 0.031 (0.351)	DT 0.000 (0.313)	loss 7.320 (7.252)	prob 1.373 (1.410)	GS 33.484 (32.522)	mem 72.613
Train: [98][760/1500]	BT 0.055 (0.347)	DT 0.000 (0.309)	loss 7.283 (7.272)	prob 1.319 (1.418)	GS 33.844 (32.603)	mem 72.613
Train: [98][770/1500]	BT 0.043 (0.351)	DT 0.012 (0.313)	loss 7.326 (7.265)	prob 1.241 (1.429)	GS 31.125 (32.078)	mem 72.614
Train: [98][780/1500]	BT 0.029 (0.347)	DT 0.000 (0.309)	loss 7.312 (7.280)	prob 1.319 (1.401)	GS 35.641 (32.331)	mem 72.615
Train: [98][790/1500]	BT 0.040 (0.343)	DT 0.001 (0.305)	loss 7.409 (7.304)	prob 1.314 (1.386)	GS 34.531 (32.663)	mem 72.616
Train: [98][800/1500]	BT 0.040 (0.346)	DT 0.001 (0.308)	loss 7.328 (7.313)	prob 1.404 (1.380)	GS 34.938 (32.900)	mem 72.618
Train: [98][810/1500]	BT 0.030 (0.342)	DT 0.000 (0.304)	loss 7.357 (7.387)	prob 1.432 (1.356)	GS 34.156 (32.736)	mem 72.619
Train: [98][820/1500]	BT 0.031 (0.344)	DT 0.000 (0.307)	loss 7.346 (7.365)	prob 1.479 (1.413)	GS 33.656 (32.844)	mem 72.620
Train: [98][830/1500]	BT 0.052 (0.341)	DT 0.010 (0.303)	loss 7.393 (7.372)	prob 1.336 (1.412)	GS 34.844 (33.011)	mem 72.621
Train: [98][840/1500]	BT 0.029 (0.344)	DT 0.000 (0.306)	loss 7.522 (7.386)	prob 1.118 (1.377)	GS 32.328 (32.736)	mem 72.621
Train: [98][850/1500]	BT 0.033 (0.340)	DT 0.001 (0.302)	loss 7.315 (7.380)	prob 1.199 (1.354)	GS 30.828 (32.453)	mem 72.622
Train: [98][860/1500]	BT 0.031 (0.337)	DT 0.001 (0.299)	loss 7.503 (7.456)	prob 1.089 (1.128)	GS 35.891 (33.977)	mem 72.623
Train: [98][870/1500]	BT 0.038 (0.341)	DT 0.000 (0.303)	loss 7.442 (7.446)	prob 1.193 (1.152)	GS 36.609 (33.641)	mem 72.620
Train: [98][880/1500]	BT 0.041 (0.337)	DT 0.001 (0.300)	loss 7.418 (7.449)	prob 1.201 (1.145)	GS 34.281 (33.537)	mem 72.621
Train: [98][890/1500]	BT 0.030 (0.351)	DT 0.000 (0.313)	loss 7.424 (7.442)	prob 1.206 (1.156)	GS 32.406 (33.761)	mem 72.621
Train: [98][900/1500]	BT 0.029 (0.347)	DT 0.000 (0.310)	loss 7.388 (7.437)	prob 1.338 (1.176)	GS 32.766 (33.740)	mem 72.622
Train: [98][910/1500]	BT 0.026 (0.344)	DT 0.000 (0.307)	loss 7.404 (7.375)	prob 1.182 (1.255)	GS 34.172 (32.473)	mem 72.623
Train: [98][920/1500]	BT 0.034 (0.343)	DT 0.000 (0.306)	loss 7.333 (7.384)	prob 1.230 (1.234)	GS 29.891 (31.987)	mem 72.625
Train: [98][930/1500]	BT 0.035 (0.340)	DT 0.000 (0.303)	loss 7.539 (7.402)	prob 1.199 (1.224)	GS 33.688 (32.269)	mem 72.628
Train: [98][940/1500]	BT 0.037 (0.343)	DT 0.001 (0.305)	loss 7.388 (7.413)	prob 1.257 (1.229)	GS 33.141 (31.947)	mem 72.643
Train: [98][950/1500]	BT 0.037 (0.339)	DT 0.001 (0.302)	loss 7.526 (7.433)	prob 1.151 (1.216)	GS 33.109 (32.415)	mem 72.642
Train: [98][960/1500]	BT 0.028 (0.340)	DT 0.000 (0.303)	loss 7.504 (7.515)	prob 1.291 (1.217)	GS 31.719 (32.298)	mem 72.625
Train: [98][970/1500]	BT 0.029 (0.340)	DT 0.000 (0.303)	loss 7.530 (7.497)	prob 1.241 (1.235)	GS 32.359 (32.409)	mem 72.539
Train: [98][980/1500]	BT 0.030 (0.337)	DT 0.000 (0.300)	loss 7.477 (7.492)	prob 1.237 (1.237)	GS 35.875 (32.821)	mem 72.538
Train: [98][990/1500]	BT 0.036 (0.337)	DT 0.000 (0.300)	loss 7.366 (7.482)	prob 1.404 (1.256)	GS 33.688 (32.824)	mem 72.541
Train: [98][1000/1500]	BT 0.037 (0.334)	DT 0.000 (0.297)	loss 7.369 (7.472)	prob 1.354 (1.265)	GS 35.422 (32.807)	mem 72.541
Train: [98][1010/1500]	BT 0.037 (0.333)	DT 0.000 (0.296)	loss 7.423 (7.442)	prob 1.305 (1.283)	GS 31.922 (31.580)	mem 72.540
Train: [98][1020/1500]	BT 0.037 (0.331)	DT 0.001 (0.294)	loss 7.412 (7.423)	prob 1.351 (1.299)	GS 33.094 (31.569)	mem 72.541
Train: [98][1030/1500]	BT 0.037 (0.328)	DT 0.001 (0.291)	loss 7.450 (7.421)	prob 1.278 (1.311)	GS 30.375 (31.371)	mem 72.541
Train: [98][1040/1500]	BT 0.038 (0.328)	DT 0.000 (0.291)	loss 7.401 (7.420)	prob 1.367 (1.316)	GS 36.469 (31.623)	mem 72.541
Train: [98][1050/1500]	BT 0.037 (0.325)	DT 0.000 (0.288)	loss 7.439 (7.417)	prob 1.311 (1.328)	GS 36.844 (31.680)	mem 72.541
Train: [98][1060/1500]	BT 0.037 (0.324)	DT 0.001 (0.287)	loss 7.404 (7.432)	prob 1.444 (1.301)	GS 30.109 (31.780)	mem 72.542
Train: [98][1070/1500]	BT 0.037 (0.324)	DT 0.000 (0.287)	loss 7.484 (7.443)	prob 1.326 (1.314)	GS 32.516 (31.714)	mem 72.562
Train: [98][1080/1500]	BT 0.037 (0.322)	DT 0.001 (0.285)	loss 7.473 (7.448)	prob 1.361 (1.315)	GS 31.844 (31.654)	mem 72.563
Train: [98][1090/1500]	BT 0.037 (0.323)	DT 0.000 (0.286)	loss 7.481 (7.456)	prob 1.391 (1.317)	GS 32.562 (31.710)	mem 72.564
Train: [98][1100/1500]	BT 0.038 (0.321)	DT 0.000 (0.284)	loss 7.467 (7.461)	prob 1.428 (1.326)	GS 38.250 (31.927)	mem 72.565
Train: [98][1110/1500]	BT 0.039 (0.319)	DT 0.001 (0.282)	loss 7.535 (7.546)	prob 1.312 (1.296)	GS 32.125 (32.525)	mem 72.566
Train: [98][1120/1500]	BT 0.038 (0.318)	DT 0.001 (0.281)	loss 7.542 (7.546)	prob 1.381 (1.316)	GS 37.281 (33.146)	mem 72.567
Train: [98][1130/1500]	BT 0.343 (0.318)	DT 0.303 (0.281)	loss 7.591 (7.541)	prob 1.201 (1.327)	GS 32.438 (32.938)	mem 72.557
Train: [98][1140/1500]	BT 0.039 (0.317)	DT 0.001 (0.280)	loss 7.525 (7.536)	prob 1.368 (1.326)	GS 35.344 (32.773)	mem 72.555
Train: [98][1150/1500]	BT 0.064 (0.316)	DT 0.006 (0.279)	loss 7.517 (7.543)	prob 1.382 (1.317)	GS 34.578 (32.954)	mem 72.555
Train: [98][1160/1500]	BT 0.025 (0.324)	DT 0.000 (0.287)	loss 7.685 (7.638)	prob 1.270 (1.264)	GS 33.703 (33.523)	mem 72.554
Train: [98][1170/1500]	BT 0.026 (0.322)	DT 0.000 (0.285)	loss 7.626 (7.656)	prob 1.301 (1.259)	GS 32.484 (32.948)	mem 72.553
Train: [98][1180/1500]	BT 0.038 (0.319)	DT 0.001 (0.282)	loss 7.630 (7.642)	prob 1.401 (1.273)	GS 37.672 (33.008)	mem 72.554
Train: [98][1190/1500]	BT 0.026 (0.322)	DT 0.000 (0.285)	loss 7.603 (7.632)	prob 1.311 (1.295)	GS 34.516 (33.131)	mem 72.566
Train: [98][1200/1500]	BT 0.025 (0.320)	DT 0.000 (0.283)	loss 7.567 (7.626)	prob 1.483 (1.297)	GS 35.047 (33.187)	mem 72.568
Train: [98][1210/1500]	BT 0.031 (0.321)	DT 0.001 (0.284)	loss 7.671 (7.621)	prob 1.250 (1.288)	GS 34.469 (33.933)	mem 72.572
Train: [98][1220/1500]	BT 0.038 (0.319)	DT 0.001 (0.282)	loss 7.682 (7.666)	prob 1.243 (1.268)	GS 37.203 (33.739)	mem 72.574
Train: [98][1230/1500]	BT 0.037 (0.319)	DT 0.000 (0.282)	loss 7.765 (7.679)	prob 1.182 (1.265)	GS 34.422 (33.299)	mem 72.572
Train: [98][1240/1500]	BT 0.036 (0.318)	DT 0.001 (0.281)	loss 7.749 (7.692)	prob 1.228 (1.261)	GS 31.016 (33.397)	mem 72.573
Train: [98][1250/1500]	BT 0.038 (0.315)	DT 0.001 (0.278)	loss 7.688 (7.693)	prob 1.231 (1.262)	GS 35.500 (33.482)	mem 72.574
Train: [98][1260/1500]	BT 0.049 (0.315)	DT 0.012 (0.278)	loss 7.674 (7.681)	prob 1.292 (1.273)	GS 34.047 (32.847)	mem 72.575
Train: [98][1270/1500]	BT 0.038 (0.313)	DT 0.001 (0.276)	loss 7.698 (7.689)	prob 1.371 (1.272)	GS 34.094 (32.742)	mem 72.574
Train: [98][1280/1500]	BT 0.036 (0.315)	DT 0.001 (0.278)	loss 7.668 (7.692)	prob 1.207 (1.269)	GS 32.141 (32.536)	mem 72.577
Train: [98][1290/1500]	BT 0.035 (0.315)	DT 0.001 (0.278)	loss 7.699 (7.686)	prob 1.192 (1.278)	GS 36.109 (32.512)	mem 72.575
Train: [98][1300/1500]	BT 0.066 (0.313)	DT 0.005 (0.276)	loss 7.691 (7.700)	prob 1.280 (1.270)	GS 32.312 (32.497)	mem 72.576
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [98][1310/1500]	BT 0.038 (0.317)	DT 0.001 (0.280)	loss 7.751 (7.730)	prob 1.150 (1.178)	GS 30.500 (31.756)	mem 72.580
Train: [98][1320/1500]	BT 0.037 (0.315)	DT 0.000 (0.278)	loss 7.770 (7.741)	prob 1.038 (1.135)	GS 33.266 (32.319)	mem 72.581
Train: [98][1330/1500]	BT 0.040 (0.314)	DT 0.004 (0.277)	loss 7.736 (7.737)	prob 1.023 (1.121)	GS 36.922 (32.227)	mem 72.580
Train: [98][1340/1500]	BT 0.067 (0.313)	DT 0.023 (0.276)	loss 7.706 (7.730)	prob 1.083 (1.111)	GS 33.359 (32.259)	mem 72.581
Train: [98][1350/1500]	BT 0.060 (0.315)	DT 0.016 (0.278)	loss 7.740 (7.726)	prob 1.045 (1.104)	GS 33.125 (32.153)	mem 72.583
Train: [98][1360/1500]	BT 0.059 (0.315)	DT 0.015 (0.278)	loss 7.822 (7.784)	prob 0.979 (0.997)	GS 29.156 (33.875)	mem 72.587
Train: [98][1370/1500]	BT 0.031 (0.316)	DT 0.000 (0.278)	loss 7.839 (7.784)	prob 0.917 (1.019)	GS 35.500 (33.404)	mem 72.588
Train: [98][1380/1500]	BT 0.052 (0.318)	DT 0.012 (0.280)	loss 7.809 (7.799)	prob 1.133 (1.009)	GS 35.750 (33.131)	mem 72.587
Train: [98][1390/1500]	BT 0.034 (0.316)	DT 0.001 (0.278)	loss 7.838 (7.817)	prob 1.031 (1.005)	GS 33.875 (32.995)	mem 72.586
Train: [98][1400/1500]	BT 0.052 (0.318)	DT 0.006 (0.280)	loss 7.906 (7.827)	prob 0.893 (1.003)	GS 33.953 (32.791)	mem 72.587
Train: [98][1410/1500]	BT 0.037 (0.317)	DT 0.000 (0.280)	loss 7.917 (7.919)	prob 1.016 (1.026)	GS 33.312 (32.697)	mem 72.591
Train: [98][1420/1500]	BT 0.038 (0.315)	DT 0.001 (0.278)	loss 7.970 (7.914)	prob 0.894 (1.013)	GS 31.219 (33.095)	mem 72.591
Train: [98][1430/1500]	BT 0.058 (0.315)	DT 0.011 (0.277)	loss 7.885 (7.901)	prob 1.069 (1.008)	GS 35.500 (33.016)	mem 72.592
Train: [98][1440/1500]	BT 0.038 (0.316)	DT 0.000 (0.279)	loss 7.899 (7.897)	prob 1.052 (1.009)	GS 31.594 (32.869)	mem 72.590
Train: [98][1450/1500]	BT 0.027 (0.317)	DT 0.000 (0.279)	loss 7.926 (7.912)	prob 1.068 (1.004)	GS 34.156 (33.097)	mem 72.517
Train: [98][1460/1500]	BT 0.037 (0.315)	DT 0.001 (0.278)	loss 7.905 (7.968)	prob 1.037 (0.990)	GS 35.125 (33.484)	mem 72.443
Train: [98][1470/1500]	BT 0.031 (0.315)	DT 0.000 (0.278)	loss 7.894 (7.942)	prob 1.033 (1.021)	GS 31.703 (32.841)	mem 35.754
Train: [98][1480/1500]	BT 0.030 (0.314)	DT 0.000 (0.277)	loss 7.920 (7.926)	prob 0.955 (1.024)	GS 37.312 (32.503)	mem 15.975
Train: [98][1490/1500]	BT 0.027 (0.312)	DT 0.000 (0.275)	loss 7.956 (7.931)	prob 0.956 (1.016)	GS 35.469 (32.513)	mem 15.976
Train: [98][1500/1500]	BT 0.028 (0.311)	DT 0.000 (0.274)	loss 8.015 (7.944)	prob 0.867 (0.996)	GS 35.125 (32.967)	mem 12.941
Train: [98][1510/1500]	BT 0.032 (0.309)	DT 0.000 (0.272)	loss 7.938 (8.003)	prob 0.994 (0.936)	GS 38.312 (32.791)	mem 7.467
epoch 98, total time 466.92
==> Saving...
==> Saving...
==> training...
moco1
moco2
moco3
moco4
Train: [99][1/1500]	BT 18.151 (18.151)	DT 18.060 (18.060)	loss 7.985 (7.985)	prob 0.956 (0.956)	GS 34.234 (34.234)	mem 71.177
Train: [99][10/1500]	BT 0.037 (2.273)	DT 0.001 (2.231)	loss 7.855 (7.910)	prob 1.085 (1.043)	GS 36.562 (32.861)	mem 71.314
Train: [99][20/1500]	BT 0.039 (1.156)	DT 0.001 (1.116)	loss 8.051 (7.919)	prob 0.914 (1.036)	GS 32.031 (32.924)	mem 71.342
Train: [99][30/1500]	BT 0.038 (0.872)	DT 0.001 (0.834)	loss 7.947 (7.931)	prob 1.053 (1.014)	GS 34.422 (32.638)	mem 71.379
Train: [99][40/1500]	BT 0.037 (0.664)	DT 0.000 (0.626)	loss 7.917 (7.922)	prob 0.953 (1.025)	GS 33.234 (32.255)	mem 71.380
Train: [99][50/1500]	BT 0.031 (0.628)	DT 0.000 (0.591)	loss 7.968 (7.920)	prob 0.972 (1.023)	GS 34.703 (32.318)	mem 71.403
Train: [99][60/1500]	BT 0.033 (0.584)	DT 0.000 (0.547)	loss 7.985 (7.957)	prob 0.949 (1.015)	GS 37.328 (32.133)	mem 71.415
Train: [99][70/1500]	BT 0.037 (0.541)	DT 0.000 (0.504)	loss 8.001 (7.945)	prob 0.972 (1.021)	GS 36.719 (32.616)	mem 71.420
Train: [99][80/1500]	BT 0.064 (0.513)	DT 0.005 (0.476)	loss 7.995 (7.974)	prob 0.944 (1.009)	GS 35.656 (32.833)	mem 71.422
Train: [99][90/1500]	BT 0.038 (0.484)	DT 0.000 (0.447)	loss 8.027 (7.989)	prob 0.982 (0.997)	GS 35.703 (33.073)	mem 71.453
Train: [99][100/1500]	BT 0.038 (0.482)	DT 0.000 (0.444)	loss 8.043 (8.007)	prob 0.989 (0.991)	GS 33.656 (32.899)	mem 71.466
Train: [99][110/1500]	BT 0.040 (0.442)	DT 0.001 (0.404)	loss 8.121 (8.046)	prob 0.962 (0.994)	GS 36.297 (32.714)	mem 71.467
Train: [99][120/1500]	BT 0.032 (0.421)	DT 0.000 (0.383)	loss 8.038 (8.043)	prob 1.019 (1.002)	GS 32.000 (32.275)	mem 71.469
Train: [99][130/1500]	BT 0.040 (0.417)	DT 0.001 (0.379)	loss 8.087 (8.064)	prob 1.033 (0.981)	GS 35.547 (32.916)	mem 71.470
Train: [99][140/1500]	BT 0.040 (0.390)	DT 0.001 (0.352)	loss 8.076 (8.068)	prob 1.035 (0.989)	GS 27.141 (32.633)	mem 71.470
Train: [99][150/1500]	BT 0.039 (0.385)	DT 0.001 (0.346)	loss 8.126 (8.070)	prob 0.956 (0.991)	GS 34.156 (32.819)	mem 71.474
Train: [99][160/1500]	BT 0.039 (0.373)	DT 0.001 (0.335)	loss 8.169 (8.144)	prob 0.927 (0.949)	GS 33.734 (31.933)	mem 71.476
Train: [99][170/1500]	BT 0.038 (0.367)	DT 0.001 (0.328)	loss 8.116 (8.131)	prob 0.983 (0.960)	GS 36.750 (32.573)	mem 71.478
Train: [99][180/1500]	BT 2.802 (0.364)	DT 2.770 (0.325)	loss 8.060 (8.120)	prob 1.000 (0.970)	GS 33.672 (32.110)	mem 71.480
Train: [99][190/1500]	BT 0.031 (0.347)	DT 0.001 (0.308)	loss 8.087 (8.114)	prob 1.053 (0.974)	GS 33.219 (32.216)	mem 71.482
Train: [99][200/1500]	BT 0.056 (0.349)	DT 0.006 (0.311)	loss 8.065 (8.110)	prob 0.978 (0.974)	GS 32.844 (32.549)	mem 71.533
Train: [99][210/1500]	BT 0.039 (0.341)	DT 0.001 (0.302)	loss 8.146 (8.109)	prob 0.962 (0.969)	GS 32.375 (33.311)	mem 71.630
Train: [99][220/1500]	BT 0.058 (0.358)	DT 0.006 (0.319)	loss 8.110 (8.124)	prob 0.982 (0.960)	GS 32.500 (32.821)	mem 72.170
Train: [99][230/1500]	BT 0.030 (0.388)	DT 0.000 (0.349)	loss 8.175 (8.139)	prob 0.965 (0.959)	GS 33.281 (32.986)	mem 72.614
Train: [99][240/1500]	BT 0.039 (0.373)	DT 0.000 (0.334)	loss 8.192 (8.144)	prob 0.908 (0.960)	GS 31.281 (32.794)	mem 72.617
Train: [99][250/1500]	BT 0.029 (0.383)	DT 0.000 (0.344)	loss 8.175 (8.152)	prob 0.935 (0.957)	GS 36.062 (32.981)	mem 72.668
Train: [99][260/1500]	BT 0.033 (0.369)	DT 0.000 (0.331)	loss 8.192 (8.185)	prob 0.988 (0.937)	GS 31.203 (31.712)	mem 72.667
Train: [99][270/1500]	BT 0.039 (0.357)	DT 0.001 (0.318)	loss 8.153 (8.185)	prob 0.940 (0.938)	GS 33.297 (31.886)	mem 72.669
Train: [99][280/1500]	BT 0.028 (0.363)	DT 0.000 (0.324)	loss 8.187 (8.191)	prob 0.919 (0.929)	GS 30.500 (32.264)	mem 72.669
Train: [99][290/1500]	BT 0.032 (0.351)	DT 0.000 (0.313)	loss 8.292 (8.203)	prob 0.882 (0.925)	GS 33.812 (32.155)	mem 72.669
Train: [99][300/1500]	BT 0.029 (0.364)	DT 0.000 (0.326)	loss 8.210 (8.218)	prob 0.917 (0.916)	GS 35.484 (32.391)	mem 72.673
Train: [99][310/1500]	BT 0.046 (0.353)	DT 0.001 (0.315)	loss 8.252 (8.257)	prob 0.881 (0.892)	GS 32.047 (32.234)	mem 72.673
Train: [99][320/1500]	BT 0.038 (0.343)	DT 0.001 (0.305)	loss 8.297 (8.269)	prob 0.862 (0.882)	GS 34.250 (32.037)	mem 72.676
Train: [99][330/1500]	BT 0.029 (0.352)	DT 0.000 (0.315)	loss 8.353 (8.299)	prob 0.839 (0.865)	GS 31.391 (32.942)	mem 72.694
Train: [99][340/1500]	BT 0.026 (0.342)	DT 0.000 (0.305)	loss 8.279 (8.307)	prob 0.898 (0.857)	GS 34.531 (32.834)	mem 72.694
Train: [99][350/1500]	BT 0.037 (0.341)	DT 0.001 (0.304)	loss 8.284 (8.304)	prob 0.915 (0.858)	GS 32.453 (32.515)	mem 72.715
Train: [99][360/1500]	BT 0.037 (0.333)	DT 0.001 (0.296)	loss 8.250 (8.289)	prob 0.900 (0.882)	GS 35.344 (32.678)	mem 72.717
Train: [99][370/1500]	BT 0.069 (0.336)	DT 0.009 (0.299)	loss 8.287 (8.296)	prob 0.890 (0.875)	GS 34.031 (32.201)	mem 72.599
Train: [99][380/1500]	BT 0.072 (0.329)	DT 0.006 (0.291)	loss 8.382 (8.304)	prob 0.817 (0.871)	GS 34.438 (32.719)	mem 72.600
Train: [99][390/1500]	BT 0.076 (0.322)	DT 0.010 (0.284)	loss 8.413 (8.327)	prob 0.735 (0.851)	GS 32.688 (32.758)	mem 72.599
Train: [99][400/1500]	BT 0.053 (0.344)	DT 0.000 (0.305)	loss 8.420 (8.346)	prob 0.790 (0.837)	GS 29.953 (32.806)	mem 72.599
Train: [99][410/1500]	BT 0.044 (0.337)	DT 0.001 (0.298)	loss 8.423 (8.437)	prob 0.798 (0.756)	GS 36.000 (34.978)	mem 72.600
Train: [99][420/1500]	BT 0.038 (0.341)	DT 0.001 (0.302)	loss 8.372 (8.427)	prob 0.805 (0.769)	GS 36.922 (33.212)	mem 72.605
Train: [99][430/1500]	BT 0.067 (0.338)	DT 0.020 (0.299)	loss 8.334 (8.416)	prob 0.835 (0.779)	GS 33.859 (32.586)	mem 72.609
Train: [99][440/1500]	BT 0.052 (0.331)	DT 0.000 (0.292)	loss 8.437 (8.426)	prob 0.720 (0.768)	GS 36.125 (32.657)	mem 72.608
Train: [99][450/1500]	BT 0.038 (0.339)	DT 0.001 (0.299)	loss 8.456 (8.430)	prob 0.748 (0.761)	GS 34.375 (33.011)	mem 72.612
Train: [99][460/1500]	BT 0.038 (0.333)	DT 0.001 (0.294)	loss 8.436 (8.488)	prob 0.772 (0.737)	GS 34.750 (34.036)	mem 72.612
Train: [99][470/1500]	BT 0.036 (0.334)	DT 0.001 (0.295)	loss 8.502 (8.497)	prob 0.683 (0.709)	GS 36.953 (33.274)	mem 72.615
Train: [99][480/1500]	BT 0.038 (0.329)	DT 0.000 (0.290)	loss 8.486 (8.506)	prob 0.720 (0.712)	GS 31.984 (32.811)	mem 72.616
Train: [99][490/1500]	BT 0.038 (0.326)	DT 0.001 (0.287)	loss 8.495 (8.502)	prob 0.751 (0.718)	GS 40.391 (33.179)	mem 72.616
Train: [99][500/1500]	BT 0.028 (0.328)	DT 0.000 (0.290)	loss 8.556 (8.511)	prob 0.679 (0.712)	GS 32.375 (32.770)	mem 72.617
Train: [99][510/1500]	BT 0.039 (0.323)	DT 0.001 (0.284)	loss 8.561 (8.520)	prob 0.687 (0.724)	GS 33.469 (32.328)	mem 72.618
Train: [99][520/1500]	BT 0.054 (0.329)	DT 0.016 (0.291)	loss 8.522 (8.521)	prob 0.685 (0.724)	GS 33.625 (32.540)	mem 72.620
Train: [99][530/1500]	BT 0.068 (0.324)	DT 0.010 (0.285)	loss 8.553 (8.524)	prob 0.687 (0.719)	GS 33.312 (32.585)	mem 72.619
Train: [99][540/1500]	BT 0.038 (0.327)	DT 0.000 (0.288)	loss 8.531 (8.534)	prob 0.673 (0.709)	GS 30.750 (32.469)	mem 72.620
Train: [99][550/1500]	BT 0.039 (0.322)	DT 0.001 (0.283)	loss 8.584 (8.543)	prob 0.692 (0.707)	GS 36.391 (32.617)	mem 72.622
Train: [99][560/1500]	BT 0.030 (0.319)	DT 0.000 (0.280)	loss 8.609 (8.592)	prob 0.662 (0.672)	GS 33.594 (34.567)	mem 72.621
Train: [99][570/1500]	BT 0.033 (0.319)	DT 0.001 (0.280)	loss 8.605 (8.595)	prob 0.668 (0.671)	GS 35.250 (33.658)	mem 72.624
Train: [99][580/1500]	BT 0.051 (0.326)	DT 0.013 (0.287)	loss 8.644 (8.603)	prob 0.644 (0.666)	GS 34.109 (33.528)	mem 72.626
Train: [99][590/1500]	BT 0.059 (0.321)	DT 0.009 (0.282)	loss 8.656 (8.615)	prob 0.630 (0.661)	GS 35.156 (33.525)	mem 72.625
Train: [99][600/1500]	BT 0.020 (0.341)	DT 0.000 (0.302)	loss 8.686 (8.631)	prob 0.586 (0.650)	GS 33.656 (33.645)	mem 72.623
Train: [99][610/1500]	BT 0.030 (0.336)	DT 0.000 (0.297)	loss 8.600 (8.660)	prob 0.644 (0.635)	GS 34.656 (32.067)	mem 72.624
Train: [99][620/1500]	BT 0.034 (0.331)	DT 0.001 (0.292)	loss 8.674 (8.675)	prob 0.574 (0.623)	GS 36.922 (32.609)	mem 72.624
Train: [99][630/1500]	BT 0.033 (0.331)	DT 0.000 (0.292)	loss 8.680 (8.682)	prob 0.664 (0.621)	GS 34.562 (32.514)	mem 72.626
Train: [99][640/1500]	BT 0.035 (0.327)	DT 0.000 (0.288)	loss 8.658 (8.684)	prob 0.642 (0.620)	GS 35.734 (32.342)	mem 72.626
Train: [99][650/1500]	BT 0.031 (0.337)	DT 0.000 (0.298)	loss 8.697 (8.684)	prob 0.591 (0.620)	GS 33.266 (32.281)	mem 72.623
Train: [99][660/1500]	BT 0.058 (0.332)	DT 0.010 (0.293)	loss 8.734 (8.696)	prob 0.574 (0.625)	GS 33.703 (31.961)	mem 72.623
Train: [99][670/1500]	BT 0.039 (0.331)	DT 0.001 (0.292)	loss 8.778 (8.718)	prob 0.552 (0.603)	GS 32.109 (33.009)	mem 72.623
Train: [99][680/1500]	BT 0.063 (0.328)	DT 0.004 (0.289)	loss 8.712 (8.729)	prob 0.617 (0.597)	GS 33.391 (32.448)	mem 72.624
Train: [99][690/1500]	BT 0.032 (0.324)	DT 0.001 (0.285)	loss 8.745 (8.733)	prob 0.571 (0.592)	GS 33.078 (32.254)	mem 72.624
Train: [99][700/1500]	BT 0.030 (0.329)	DT 0.000 (0.290)	loss 8.799 (8.738)	prob 0.511 (0.586)	GS 34.094 (32.139)	mem 72.641
Train: [99][710/1500]	BT 0.028 (0.328)	DT 0.000 (0.289)	loss 8.869 (8.825)	prob 0.468 (0.527)	GS 32.484 (32.708)	mem 72.644
Train: [99][720/1500]	BT 0.057 (0.327)	DT 0.000 (0.288)	loss 8.833 (8.832)	prob 0.515 (0.513)	GS 36.984 (32.055)	mem 72.647
Train: [99][730/1500]	BT 0.033 (0.327)	DT 0.000 (0.287)	loss 8.799 (8.829)	prob 0.539 (0.518)	GS 31.281 (32.168)	mem 72.647
Train: [99][740/1500]	BT 0.037 (0.324)	DT 0.000 (0.285)	loss 8.917 (8.829)	prob 0.477 (0.519)	GS 31.062 (31.977)	mem 72.650
Train: [99][750/1500]	BT 0.036 (0.330)	DT 0.000 (0.291)	loss 8.922 (8.839)	prob 0.449 (0.511)	GS 34.281 (32.364)	mem 72.650
Train: [99][760/1500]	BT 0.037 (0.326)	DT 0.001 (0.287)	loss 8.877 (8.912)	prob 0.501 (0.480)	GS 30.953 (33.147)	mem 72.651
Train: [99][770/1500]	BT 0.037 (0.330)	DT 0.000 (0.291)	loss 8.882 (8.899)	prob 0.541 (0.487)	GS 35.344 (32.955)	mem 72.652
Train: [99][780/1500]	BT 0.028 (0.326)	DT 0.000 (0.287)	loss 8.957 (8.889)	prob 0.486 (0.493)	GS 32.484 (32.556)	mem 72.653
Train: [99][790/1500]	BT 0.037 (0.326)	DT 0.000 (0.287)	loss 8.952 (8.912)	prob 0.435 (0.473)	GS 35.797 (32.986)	mem 72.655
Train: [99][800/1500]	BT 0.034 (0.323)	DT 0.001 (0.285)	loss 8.909 (8.917)	prob 0.456 (0.466)	GS 40.000 (32.975)	mem 72.657
Train: [99][810/1500]	BT 0.037 (0.324)	DT 0.001 (0.285)	loss 8.960 (8.938)	prob 0.433 (0.463)	GS 30.719 (32.473)	mem 72.657
Train: [99][820/1500]	BT 0.036 (0.322)	DT 0.000 (0.283)	loss 8.986 (8.938)	prob 0.445 (0.460)	GS 33.219 (32.152)	mem 72.657
Train: [99][830/1500]	BT 0.024 (0.326)	DT 0.000 (0.287)	loss 8.917 (8.938)	prob 0.467 (0.457)	GS 35.391 (31.851)	mem 72.657
Train: [99][840/1500]	BT 0.037 (0.323)	DT 0.001 (0.284)	loss 8.946 (8.940)	prob 0.458 (0.454)	GS 34.641 (32.221)	mem 72.658
Train: [99][850/1500]	BT 0.037 (0.319)	DT 0.001 (0.281)	loss 8.966 (8.944)	prob 0.453 (0.453)	GS 34.734 (32.696)	mem 72.658
Train: [99][860/1500]	BT 0.103 (0.322)	DT 0.010 (0.283)	loss 9.003 (9.011)	prob 0.429 (0.396)	GS 36.750 (32.728)	mem 72.662
Train: [99][870/1500]	BT 0.069 (0.319)	DT 0.011 (0.280)	loss 9.016 (9.018)	prob 0.348 (0.394)	GS 36.359 (33.164)	mem 72.663
Train: [99][880/1500]	BT 0.052 (0.323)	DT 0.001 (0.284)	loss 9.057 (9.015)	prob 0.384 (0.397)	GS 34.094 (33.181)	mem 72.662
Train: [99][890/1500]	BT 0.030 (0.324)	DT 0.000 (0.285)	loss 9.072 (9.040)	prob 0.373 (0.386)	GS 34.188 (33.822)	mem 72.660
Train: [99][900/1500]	BT 0.038 (0.321)	DT 0.001 (0.282)	loss 9.042 (9.048)	prob 0.402 (0.381)	GS 34.797 (33.454)	mem 72.662
Train: [99][910/1500]	BT 0.026 (0.322)	DT 0.000 (0.283)	loss 9.092 (9.074)	prob 0.349 (0.367)	GS 33.359 (33.239)	mem 72.662
Train: [99][920/1500]	BT 0.025 (0.319)	DT 0.000 (0.280)	loss 9.127 (9.075)	prob 0.333 (0.365)	GS 33.094 (32.298)	mem 72.664
Train: [99][930/1500]	BT 0.031 (0.316)	DT 0.000 (0.277)	loss 9.080 (9.081)	prob 0.377 (0.361)	GS 33.781 (32.131)	mem 72.664
Train: [99][940/1500]	BT 0.038 (0.316)	DT 0.001 (0.277)	loss 9.103 (9.080)	prob 0.332 (0.363)	GS 33.812 (32.013)	mem 72.663
Train: [99][950/1500]	BT 0.037 (0.315)	DT 0.000 (0.276)	loss 9.099 (9.085)	prob 0.346 (0.358)	GS 31.172 (31.770)	mem 72.665
Train: [99][960/1500]	BT 0.038 (0.313)	DT 0.001 (0.275)	loss 9.113 (9.117)	prob 0.332 (0.329)	GS 35.266 (32.628)	mem 72.665
Train: [99][970/1500]	BT 0.038 (0.311)	DT 0.001 (0.272)	loss 9.138 (9.120)	prob 0.305 (0.329)	GS 31.547 (32.969)	mem 72.665
Train: [99][980/1500]	BT 0.035 (0.312)	DT 0.000 (0.273)	loss 9.137 (9.128)	prob 0.359 (0.323)	GS 31.969 (32.807)	mem 72.667
Train: [99][990/1500]	BT 0.034 (0.313)	DT 0.001 (0.274)	loss 9.187 (9.140)	prob 0.285 (0.316)	GS 33.750 (33.168)	mem 72.667
Train: [99][1000/1500]	BT 0.038 (0.312)	DT 0.001 (0.273)	loss 9.171 (9.149)	prob 0.309 (0.311)	GS 33.625 (32.921)	mem 72.668
Train: [99][1010/1500]	BT 0.069 (0.312)	DT 0.004 (0.273)	loss 9.166 (9.185)	prob 0.308 (0.296)	GS 31.078 (33.747)	mem 72.668
Train: [99][1020/1500]	BT 0.054 (0.310)	DT 0.001 (0.271)	loss 9.185 (9.191)	prob 0.316 (0.296)	GS 34.250 (32.745)	mem 72.668
Train: [99][1030/1500]	BT 0.048 (0.314)	DT 0.005 (0.276)	loss 9.221 (9.209)	prob 0.301 (0.285)	GS 35.281 (32.997)	mem 72.667
Train: [99][1040/1500]	BT 0.059 (0.312)	DT 0.001 (0.273)	loss 9.206 (9.215)	prob 0.301 (0.282)	GS 31.766 (32.753)	mem 72.667
Train: [99][1050/1500]	BT 0.038 (0.313)	DT 0.001 (0.274)	loss 9.267 (9.218)	prob 0.240 (0.279)	GS 33.688 (32.585)	mem 72.668
Train: [99][1060/1500]	BT 0.037 (0.311)	DT 0.001 (0.272)	loss 9.265 (9.255)	prob 0.248 (0.247)	GS 35.578 (31.902)	mem 72.668
Train: [99][1070/1500]	BT 0.037 (0.308)	DT 0.001 (0.269)	loss 9.265 (9.272)	prob 0.249 (0.241)	GS 33.344 (32.312)	mem 72.668
Train: [99][1080/1500]	BT 0.029 (0.314)	DT 0.000 (0.276)	loss 9.298 (9.284)	prob 0.256 (0.234)	GS 33.094 (32.623)	mem 72.703
Train: [99][1090/1500]	BT 0.028 (0.312)	DT 0.000 (0.273)	loss 9.311 (9.292)	prob 0.241 (0.232)	GS 37.578 (32.760)	mem 72.704
Train: [99][1100/1500]	BT 0.039 (0.312)	DT 0.001 (0.273)	loss 9.328 (9.300)	prob 0.219 (0.228)	GS 31.844 (32.351)	mem 72.705
Train: [99][1110/1500]	BT 0.039 (0.309)	DT 0.000 (0.271)	loss 9.308 (9.322)	prob 0.224 (0.218)	GS 33.047 (31.628)	mem 72.705
Train: [99][1120/1500]	BT 0.030 (0.311)	DT 0.001 (0.272)	loss 9.358 (9.336)	prob 0.199 (0.208)	GS 34.406 (32.433)	mem 72.705
Train: [99][1130/1500]	BT 0.039 (0.308)	DT 0.001 (0.270)	loss 9.339 (9.340)	prob 0.208 (0.204)	GS 30.688 (32.258)	mem 72.707
Train: [99][1140/1500]	BT 0.034 (0.306)	DT 0.001 (0.267)	loss 9.348 (9.344)	prob 0.203 (0.201)	GS 36.625 (32.069)	mem 72.706
Train: [99][1150/1500]	BT 0.039 (0.307)	DT 0.001 (0.269)	loss 9.374 (9.349)	prob 0.191 (0.198)	GS 33.594 (32.173)	mem 72.708
Train: [99][1160/1500]	BT 0.028 (0.305)	DT 0.000 (0.266)	loss 9.391 (9.383)	prob 0.187 (0.180)	GS 36.094 (31.527)	mem 72.709
Train: [99][1170/1500]	BT 0.039 (0.305)	DT 0.001 (0.267)	loss 9.414 (9.392)	prob 0.148 (0.173)	GS 34.500 (31.785)	mem 72.710
Train: [99][1180/1500]	BT 0.039 (0.303)	DT 0.000 (0.265)	loss 9.409 (9.400)	prob 0.172 (0.167)	GS 32.359 (32.076)	mem 72.711
Train: [99][1190/1500]	BT 0.039 (0.301)	DT 0.001 (0.262)	loss 9.433 (9.407)	prob 0.151 (0.163)	GS 34.281 (32.577)	mem 72.712
Train: [99][1200/1500]	BT 0.029 (0.304)	DT 0.000 (0.265)	loss 9.454 (9.416)	prob 0.139 (0.160)	GS 35.750 (32.549)	mem 72.707
Train: [99][1210/1500]	BT 0.039 (0.302)	DT 0.001 (0.263)	loss 9.463 (9.473)	prob 0.144 (0.128)	GS 35.234 (33.544)	mem 72.708
Train: [99][1220/1500]	BT 0.025 (0.305)	DT 0.000 (0.267)	loss 9.521 (9.471)	prob 0.096 (0.127)	GS 39.891 (34.224)	mem 72.706
Train: [99][1230/1500]	BT 0.038 (0.303)	DT 0.001 (0.265)	loss 9.497 (9.479)	prob 0.120 (0.122)	GS 35.047 (33.487)	mem 72.708
Train: [99][1240/1500]	BT 0.046 (0.304)	DT 0.008 (0.265)	loss 9.485 (9.482)	prob 0.115 (0.119)	GS 34.328 (33.135)	mem 72.709
Train: [99][1250/1500]	BT 0.039 (0.302)	DT 0.001 (0.263)	loss 9.506 (9.485)	prob 0.091 (0.116)	GS 35.828 (33.117)	mem 72.709
Train: [99][1260/1500]	BT 0.039 (0.299)	DT 0.001 (0.261)	loss 9.499 (9.503)	prob 0.103 (0.109)	GS 37.406 (32.334)	mem 72.708
Train: [99][1270/1500]	BT 0.025 (0.300)	DT 0.000 (0.262)	loss 9.535 (9.512)	prob 0.090 (0.104)	GS 31.219 (33.229)	mem 72.708
Train: [99][1280/1500]	BT 0.039 (0.298)	DT 0.000 (0.260)	loss 9.525 (9.520)	prob 0.088 (0.099)	GS 36.359 (32.774)	mem 72.709
Train: [99][1290/1500]	BT 0.027 (0.314)	DT 0.000 (0.276)	loss 9.552 (9.524)	prob 0.079 (0.098)	GS 34.516 (32.869)	mem 72.710
Train: [99][1300/1500]	BT 0.028 (0.312)	DT 0.000 (0.274)	loss 9.565 (9.530)	prob 0.074 (0.094)	GS 31.969 (32.746)	mem 72.709
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
/home/shakir/.venv/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.
  dgl_warning(
Train: [99][1310/1500]	BT 0.036 (0.310)	DT 0.000 (0.272)	loss 9.562 (9.565)	prob 0.069 (0.073)	GS 34.312 (33.402)	mem 72.709
Train: [99][1320/1500]	BT 0.040 (0.310)	DT 0.000 (0.272)	loss 9.580 (9.570)	prob 0.066 (0.070)	GS 32.344 (32.527)	mem 72.716
Train: [99][1330/1500]	BT 0.029 (0.310)	DT 0.000 (0.271)	loss 9.589 (9.574)	prob 0.047 (0.067)	GS 32.719 (32.673)	mem 72.726
Train: [99][1340/1500]	BT 0.036 (0.308)	DT 0.001 (0.270)	loss 9.581 (9.578)	prob 0.065 (0.065)	GS 31.781 (32.574)	mem 72.728
Train: [99][1350/1500]	BT 0.038 (0.306)	DT 0.000 (0.268)	loss 9.604 (9.582)	prob 0.055 (0.063)	GS 36.250 (32.466)	mem 72.728
Train: [99][1360/1500]	BT 0.050 (0.311)	DT 0.000 (0.273)	loss 9.622 (9.617)	prob 0.048 (0.046)	GS 36.781 (33.948)	mem 72.730
Train: [99][1370/1500]	BT 0.064 (0.310)	DT 0.001 (0.271)	loss 9.621 (9.619)	prob 0.043 (0.044)	GS 31.797 (33.080)	mem 72.730
Train: [99][1380/1500]	BT 0.040 (0.318)	DT 0.000 (0.279)	loss 9.629 (9.622)	prob 0.037 (0.042)	GS 35.156 (33.199)	mem 72.727
Train: [99][1390/1500]	BT 0.026 (0.316)	DT 0.000 (0.277)	loss 9.645 (9.626)	prob 0.034 (0.040)	GS 36.812 (33.368)	mem 72.727
Train: [99][1400/1500]	BT 0.030 (0.317)	DT 0.000 (0.278)	loss 9.645 (9.631)	prob 0.031 (0.038)	GS 36.500 (33.403)	mem 72.624
Train: [99][1410/1500]	BT 0.037 (0.315)	DT 0.001 (0.276)	loss 9.655 (9.654)	prob 0.024 (0.024)	GS 30.672 (33.469)	mem 72.625
Train: [99][1420/1500]	BT 4.620 (0.316)	DT 4.577 (0.278)	loss 9.661 (9.656)	prob 0.020 (0.024)	GS 33.234 (32.693)	mem 72.625
Train: [99][1430/1500]	BT 0.028 (0.314)	DT 0.000 (0.276)	loss 9.667 (9.658)	prob 0.016 (0.023)	GS 32.016 (32.490)	mem 72.624
Train: [99][1440/1500]	BT 0.024 (0.312)	DT 0.000 (0.274)	loss 9.672 (9.661)	prob 0.014 (0.022)	GS 32.203 (32.434)	mem 72.624
Train: [99][1450/1500]	BT 0.029 (0.313)	DT 0.000 (0.275)	loss 9.679 (9.664)	prob 0.013 (0.020)	GS 34.969 (32.486)	mem 72.443
Train: [99][1460/1500]	BT 0.026 (0.311)	DT 0.000 (0.273)	loss 9.685 (9.682)	prob 0.010 (0.010)	GS 35.297 (31.083)	mem 72.443
Train: [99][1470/1500]	BT 0.034 (0.311)	DT 0.001 (0.273)	loss 9.690 (9.684)	prob 0.005 (0.009)	GS 34.938 (31.227)	mem 7.536
Train: [99][1480/1500]	BT 0.031 (0.309)	DT 0.001 (0.271)	loss 9.695 (9.687)	prob 0.005 (0.008)	GS 35.219 (31.650)	mem 7.536
Train: [99][1490/1500]	BT 0.027 (0.307)	DT 0.000 (0.269)	loss 9.700 (9.689)	prob 0.002 (0.007)	GS 34.344 (31.804)	mem 7.540
Train: [99][1500/1500]	BT 0.025 (0.305)	DT 0.000 (0.268)	loss 9.704 (9.691)	prob 0.000 (0.006)	GS 33.625 (32.015)	mem 7.520
Train: [99][1510/1500]	BT 0.026 (0.304)	DT 0.000 (0.266)	loss 9.704 (9.704)	prob 0.000 (0.000)	GS 37.281 (33.494)	mem 7.521
epoch 99, total time 458.59
==> Saving...
==> Saving...
